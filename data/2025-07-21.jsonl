{"id": "2507.13481", "pdf": "https://arxiv.org/pdf/2507.13481", "abs": "https://arxiv.org/abs/2507.13481", "authors": ["Arthur Bueno", "Bruno Cafeo", "Maria Cagnin", "Awdren Fontão"], "title": "Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence", "categories": ["cs.SE", "cs.CY"], "comment": "12 pages; 2 figures; Preprint with the original submission accepted\n  for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "summary": "Code samples play a pivotal role in open-source ecosystems (OSSECO), serving\nas lightweight artifacts that support knowledge transfer, onboarding, and\nframework adoption. Despite their instructional relevance, these samples are\noften governed informally, with minimal review and unclear ownership, which\nincreases their exposure to socio-technical degradation. In this context, the\nco-occurrence and longitudinal interplay of code smells (e.g., large classes,\npoor modularity) and community smells (e.g., lone contributors, fragmented\ncommunication) become particularly critical. While each type of smell has been\nstudied in isolation, little is known about how community-level dysfunctions\nanticipate or exacerbate technical anomalies in code samples over time. This\nstudy investigates how code and community smells emerge, co-occur, and evolve\nwithin code samples maintained in OSSECOs. A Multivocal Literature Review\nprotocol was applied, encompassing 30 peer-reviewed papers and 17\npractitioner-oriented sources (2013-2024). Thematic synthesis was conducted to\nidentify recurring socio-technical patterns related to smell dynamics. Nine\npatterns were identified, showing that community smells often precede or\nreinforce technical degradation in code samples. Symptoms such as \"radio\nsilence\" and centralized ownership were frequently associated with persistent\nstructural anomalies. Additionally, limited onboarding, the absence of\ncontinuous refactoring, and informal collaboration emerged as recurring\nconditions for smell accumulation. Conclusion: In OSSECOs, particularly within\ncode samples, community-level dysfunctions not only correlate with but often\nsignal maintainability decay. These findings underscore the need for\nsocio-technical quality indicators and lightweight governance mechanisms\ntailored to shared instructional artifacts."}
{"id": "2507.13499", "pdf": "https://arxiv.org/pdf/2507.13499", "abs": "https://arxiv.org/abs/2507.13499", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "title": "AI-Assisted Fixes to Code Review Comments at Scale", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale."}
{"id": "2507.13553", "pdf": "https://arxiv.org/pdf/2507.13553", "abs": "https://arxiv.org/abs/2507.13553", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software", "categories": ["cs.SE"], "comment": "Accepted at the 9th International Workshop on Crowd-Based\n  Requirements Engineering (CrowdRE'25)", "summary": "As user demands evolve, effectively incorporating feature requests is crucial\nfor maintaining software relevance and user satisfaction. Feature requests,\ntypically expressed in natural language, often suffer from ambiguity or\nincomplete information due to communication gaps or the requester's limited\ntechnical expertise. These issues can lead to misinterpretation, faulty\nimplementation, and reduced software quality. While seeking clarification from\nrequesters is a common strategy to mitigate these risks, little is known about\nhow developers engage in this clarification process in practice-how they\nformulate clarifying questions, seek technical or contextual details, align on\ngoals and use cases, or decide to close requests without attempting\nclarification. This study investigates how feature requests are prone to NL\ndefects (i.e. ambiguous or incomplete) and the conversational dynamics of\nclarification in open-source software (OSS) development, aiming to understand\nhow developers handle ambiguous or incomplete feature requests. Our findings\nsuggest that feature requests published on the OSS platforms do possess\nambiguity and incompleteness, and in some cases, both. We also find that\nexplicit clarification for the resolution of these defects is uncommon;\ndevelopers usually focus on aligning with project goals rather than resolving\nunclear text. When clarification occurs, it emphasizes understanding user\nintent/goal and feasibility, rather than technical details. By characterizing\nthe dynamics of clarification in open-source issue trackers, this work\nidentifies patterns that can improve user-developer collaboration and inform\nbest practices for handling feature requests effectively."}
{"id": "2507.13555", "pdf": "https://arxiv.org/pdf/2507.13555", "abs": "https://arxiv.org/abs/2507.13555", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software", "categories": ["cs.SE"], "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025", "summary": "The growing popularity and widespread use of software applications (apps)\nacross various domains have driven rapid industry growth. Along with this\ngrowth, fast-paced market changes have led to constantly evolving software\nrequirements. Such requirements are often grounded in feature requests and\nenhancement suggestions, typically provided by users in natural language (NL).\nHowever, these requests often suffer from defects such as ambiguity and\nincompleteness, making them challenging to interpret. Traditional validation\nmethods (e.g., interviews and workshops) help clarify such defects but are\nimpractical in decentralized environments like open-source software (OSS),\nwhere change requests originate from diverse users on platforms like GitHub.\nThis paper proposes a novel approach leveraging Large Language Models (LLMs) to\ndetect and refine NL defects in feature requests. Our approach automates the\nidentification of ambiguous and incomplete requests and generates clarification\nquestions (CQs) to enhance their usefulness for developers. To evaluate its\neffectiveness, we apply our method to real-world OSS feature requests and\ncompare its performance against human annotations. In addition, we conduct\ninterviews with GitHub developers to gain deeper insights into their\nperceptions of NL defects, the strategies they use to address these defects,\nand the impact of defects on downstream software engineering (SE) tasks."}
{"id": "2507.13524", "pdf": "https://arxiv.org/pdf/2507.13524", "abs": "https://arxiv.org/abs/2507.13524", "authors": ["Yaomin Jiang", "Levin Brinkmann", "Anne-Marie Nussberger", "Ivan Soraperra", "Jean-François Bonnefon", "Iyad Rahwan"], "title": "Humans learn to prefer trustworthy AI over human partners", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Partner selection is crucial for cooperation and hinges on communication. As\nartificial agents, especially those powered by large language models (LLMs),\nbecome more autonomous, intelligent, and persuasive, they compete with humans\nfor partnerships. Yet little is known about how humans select between human and\nAI partners and adapt under AI-induced competition pressure. We constructed a\ncommunication-based partner selection game and examined the dynamics in hybrid\nmini-societies of humans and bots powered by a state-of-the-art LLM. Through\nthree experiments (N = 975), we found that bots, though more prosocial than\nhumans and linguistically distinguishable, were not selected preferentially\nwhen their identity was hidden. Instead, humans misattributed bots' behaviour\nto humans and vice versa. Disclosing bots' identity induced a dual effect: it\nreduced bots' initial chances of being selected but allowed them to gradually\noutcompete humans by facilitating human learning about the behaviour of each\npartner type. These findings show how AI can reshape social interaction in\nmixed societies and inform the design of more effective and cooperative hybrid\nsystems."}
{"id": "2507.13494", "pdf": "https://arxiv.org/pdf/2507.13494", "abs": "https://arxiv.org/abs/2507.13494", "authors": ["Feras A. Saad", "Wonyeol Lee"], "title": "Random Variate Generation with Formal Guarantees", "categories": ["cs.PL", "stat.CO"], "comment": null, "summary": "This article introduces a new approach to principled and practical random\nvariate generation with formal guarantees. The key idea is to first specify the\ndesired probability distribution in terms of a finite-precision numerical\nprogram that defines its cumulative distribution function (CDF), and then\ngenerate exact random variates according to this CDF. We present a universal\nand fully automated method to synthesize exact random variate generators given\nany numerical CDF implemented in any binary number format, such as\nfloating-point, fixed-point, and posits. The method is guaranteed to operate\nwith the same precision used to specify the CDF, does not overflow, avoids\nexpensive arbitrary-precision arithmetic, and exposes a consistent API. The\nmethod rests on a novel space-time optimal implementation for the class of\ngenerators that attain the information-theoretically optimal Knuth and Yao\nentropy rate, consuming the least possible number of input random bits per\noutput variate. We develop a random variate generation library using our method\nin C and evaluate it on a diverse set of ``continuous'' and ``discrete''\ndistributions, showing competitive runtime with the state-of-the-art GNU\nScientific Library while delivering higher accuracy, entropy efficiency, and\nautomation."}
{"id": "2507.13377", "pdf": "https://arxiv.org/pdf/2507.13377", "abs": "https://arxiv.org/abs/2507.13377", "authors": ["Zhenglin Pan", "Haoran Xie"], "title": "StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation", "categories": ["cs.GR", "cs.CV"], "comment": "3 pages, 3 figures. SIGGRAPH 2025 Poster", "summary": "In this paper, we propose StructInbet, an inbetweening system designed to\ngenerate controllable transitions over explicit structural guidance.\nStructInbet introduces two key contributions. First, we propose explicit\nstructural guidance to the inbetweening problem to reduce the ambiguity\ninherent in pixel trajectories. Second, we adopt a temporal attention mechanism\nthat incorporates visual identity from both the preceding and succeeding\nkeyframes, ensuring consistency in character appearance."}
{"id": "2507.14000", "pdf": "https://arxiv.org/pdf/2507.14000", "abs": "https://arxiv.org/abs/2507.14000", "authors": ["Jing Ding", "Trung Diep"], "title": "Photonic Fabric Platform for AI Accelerators", "categories": ["cs.PF", "cs.AI", "C.4"], "comment": "12 pages, 14 figures, 5 tables", "summary": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM\n(PFA), a photonic-enabled switch and memory subsystem that delivers low\nlatency, high bandwidth, and low per-bit energy. By integrating high-bandwidth\nHBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D\nelectro-optical system-in-package, the PFA offers up to 32 TB of shared memory\nalongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM\nenables distributed AI training and inference to execute parallelism strategies\nmore efficiently. The Photonic Fabric removes the silicon beachfront constraint\nthat limits the fixed memory-to-compute ratio observed in virtually all current\nXPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet\nthat connects to the Photonic Fabric increases its memory capacity and\ncorrespondingly its memory bandwidth by offering a flexible path to scaling\nwell beyond the limitations of on-package HBM alone. We introduce CelestiSim, a\nlightweight analytical simulator validated on NVIDIA H100 and H200 systems. It\nis used to evaluate the performance of LLM reference and energy savings on PFA,\nwithout any significant change to the GPU core design. With the PFA, the\nsimulation results show that up to 3.66x throughput and 1.40x latency\nimprovements in LLM inference at 405B parameters, up to 7.04x throughput and\n1.41x latency improvements at 1T parameters, and 60-90% energy savings in data\nmovement for heavy collective operations in all LLM training scenarios. While\nthese results are shown for NVIDIA GPUs, they can be applied similarly to other\nAI accelerator designs (XPUs) that share the same fundamental limitation of\nfixed memory to compute."}
{"id": "2507.13710", "pdf": "https://arxiv.org/pdf/2507.13710", "abs": "https://arxiv.org/abs/2507.13710", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "title": "CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Data preparation is a foundational yet notoriously challenging component of\nthe machine learning lifecycle, characterized by a vast combinatorial search\nspace of potential operator sequences. While reinforcement learning (RL) offers\na promising direction, existing approaches are inefficient as they fail to\ncapture the structured, hierarchical nature of the problem. We argue that\nHierarchical Reinforcement Learning (HRL), a paradigm that has been successful\nin other domains, provides a conceptually ideal yet previously unexplored\nframework for this task. However, a naive HRL implementation with a `hard\nhierarchy' is prone to suboptimal, irreversible decisions. To address this, we\nintroduce CogniQ-H, the first framework to implement a soft hierarchical\nparadigm for robust, end-to-end automated data preparation. CogniQ-H formulates\naction selection as a Bayesian inference problem. A high-level strategic prior,\ngenerated by a Large Language Model (LLM), guides exploration\nprobabilistically. This prior is synergistically combined with a fine-grained\noperator quality score from a supervised Learning-to-Rank (LTR) model and a\nlong-term value estimate from the agent's own Q-function. This hybrid\narchitecture allows CogniQ-H to balance strategic guidance with adaptive,\nevidence-based decision-making. Through extensive experiments on 18 diverse\ndatasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to\n13.9\\% improvement in pipeline quality and 2.8$\\times$ faster convergence\ncompared to state-of-the-art RL-based methods."}
{"id": "2507.13476", "pdf": "https://arxiv.org/pdf/2507.13476", "abs": "https://arxiv.org/abs/2507.13476", "authors": ["Jaber Daneshamooz", "Jessica Nguyen", "William Chen", "Sanjay Chandrasekaran", "Satyandra Guthula", "Ankit Gupta", "Arpit Gupta", "Walter Willinger"], "title": "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica", "categories": ["cs.NI"], "comment": null, "summary": "Machine learning models in networking suffer from the domain adaptation\nproblem; models trained in one domain often fail when deployed in different\nproduction environments. This paper presents the design and implementation of\nNetReplica, a system that addresses this challenge by generating training\ndatasets with two critical properties: realism in protocol dynamics and\ncontrollability of network conditions. NetReplica models networks as\ncollections of bottleneck links with specific attributes, achieves realism by\nleveraging production network traces, and enables controllability through fine\ngrained control knobs for each link attribute. Our evaluation using Puffer\ndemonstrates that NetReplica not only matches existing data characteristics but\ngenerates realistic samples that are underrepresented in or absent from Puffer\ndata. Models trained on NetReplica augmented datasets show substantially\nimproved generalizability, reducing transmission time prediction error by up to\n47% for challenging network conditions compared to models trained solely on\nPuffer data. This work represents a significant step toward solving the domain\nadaptation problem that has limited the effectiveness of ML based networking\nsystems."}
{"id": "2507.13601", "pdf": "https://arxiv.org/pdf/2507.13601", "abs": "https://arxiv.org/abs/2507.13601", "authors": ["Jorge Villarrubia", "Luis Costero", "Francisco D. Igual", "Katzalin Olcoz"], "title": "Leveraging Multi-Instance GPUs through moldable task scheduling", "categories": ["cs.DC", "cs.ET", "cs.PF", "90B36, 90C27, 68M14, 68W40", "C.1.2; C.1.4; C.3.1; D.1.3; G.1.6"], "comment": null, "summary": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into\nmultiple logical instances with fully-isolated resources, which can be\ndynamically reconfigured. This work highlights the untapped potential of MIG\nthrough moldable task scheduling with dynamic reconfigurations. Specifically,\nwe propose a makespan minimization problem for multi-task execution under MIG\nconstraints. Our profiling shows that assuming monotonicity in task work with\nrespect to resources is not viable, as is usual in multicore scheduling.\nRelying on a state-of-the-art proposal that does not require such an\nassumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1\nof FAR builds on a classical task moldability method, phase 2 combines Longest\nProcessing Time First and List Scheduling with a novel repartitioning tree\nheuristic tailored to MIG constraints, and phase 3 employs local search via\ntask moves and swaps. FAR schedules tasks in batches offline, concatenating\ntheir schedules on the fly in an improved way that favors resource reuse.\nExcluding reconfiguration costs, the List Scheduling proof shows an\napproximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to\nthe particular constraints of an NVIDIA A100/H100 to obtain an approximation\nfactor of 2. Including the reconfiguration cost, our real-world experiments\nreveal a makespan with respect to the optimum no worse than 1.22x for a\nwell-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real\nkernels. We obtain good experimental results for each batch of tasks, but also\nin the concatenation of batches, with large improvements over the\nstate-of-the-art and proposals without GPU reconfiguration. Beyond the\nalgorithm, the paper demonstrates the research potential of the MIG technology\nand suggests useful metrics, workload characterizations and evaluation\ntechniques for future work in this field."}
{"id": "2507.13355", "pdf": "https://arxiv.org/pdf/2507.13355", "abs": "https://arxiv.org/abs/2507.13355", "authors": ["Riadul Islam", "Dhandeep Challagundla"], "title": "PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Leveraging artificial intelligence (AI)-driven electronic design and\nautomation (EDA) tools, high-performance computing, and parallelized algorithms\nare essential for next-generation microprocessor innovation, ensuring continued\nprogress in computing, AI, and semiconductor technology. Machine learning-based\ndesign rule checking (DRC) and lithography hotspot detection can improve\nfirst-pass silicon success. However, conventional ML and neural network\n(NN)-based models use supervised learning and require a large balanced dataset\n(in terms of positive and negative classes) and training time. This research\naddresses those key challenges by proposing the first-ever unsupervised DRC\nviolation prediction methodology. The proposed model can be built using any\nunbalanced dataset using only one class and set a threshold for it, then\nfitting any new data querying if they are within the boundary of the model for\nclassification. This research verified the proposed model by implementing\ndifferent computational cores using CMOS 28 nm technology and Synopsys Design\nCompiler and IC Compiler II tools. Then, layouts were divided into virtual\ngrids to collect about 60k data for analysis and verification. The proposed\nmethod has 99.95% prediction test accuracy, while the existing support vector\nmachine (SVM) and neural network (NN) models have 85.44\\% and 98.74\\% accuracy,\nrespectively. In addition, the proposed methodology has about 26.3x and up to\n6003x lower training times compared to SVM and NN-models, respectively."}
{"id": "2507.13522", "pdf": "https://arxiv.org/pdf/2507.13522", "abs": "https://arxiv.org/abs/2507.13522", "authors": ["Ankit Bhardwaj", "Weiyang Wang", "Jeremy Carin", "Adam Belay", "Manya Ghobadi"], "title": "Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication", "categories": ["cs.DC"], "comment": "18 pages, 11 figures", "summary": "This paper presents Checkmate, a system that enables per-iteration\ncheckpointing in DNN training without any training slowdown. The traditional\napproach to checkpointing requires a pause in training to copy model states to\na separate location, allowing the state to be restored in the event of failure.\nThis approach fundamentally has a tradeoff between the frequency of checkpoints\nand the cost of a failure. We avoid this tradeoff; our key insight is that in\ndata-parallel training, all information necessary to create a checkpoint\nalready exists in the network as gradients. Our core contribution is a new\nmulticast abstraction that simultaneously delivers gradients to a separate\nCPU-based shadow cluster. The shadow maintains a checkpoint by applying those\ngradients to a copy of the model. Our evaluation shows that Checkmate performs\nper-iteration checkpointing with training throughput comparable to an ideal\nno-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent\ncheckpointing compared to state-of-the-art checkpointing systems, resulting in\n80% to 97.1% reduction in repeated work per failure. At the same checkpointing\nfrequency, Checkmate delivers 1.3x to 6.5x throughput compared to other\nsystems."}
{"id": "2507.13847", "pdf": "https://arxiv.org/pdf/2507.13847", "abs": "https://arxiv.org/abs/2507.13847", "authors": ["Katsumi Inoue", "Daniil Kozhemiachenko"], "title": "Complexity of Abduction in Łukasiewicz Logic", "categories": ["cs.LO"], "comment": null, "summary": "We explore the problem of explaining observations in contexts involving\nstatements with truth degrees such as `the lift is loaded', `the symptoms are\nsevere', etc. To formalise these contexts, we consider infinitely-valued\n{\\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction\nproblems and explanations in the language of {\\L}ukasiewicz logic expanded with\n`interval literals' of the form $p\\geq\\mathbf{c}$, $p\\leq\\mathbf{c}$, and their\nnegations that express the set of values a variable can have. We analyse the\ncomplexity of standard abductive reasoning tasks (solution recognition,\nsolution existence, and relevance / necessity of hypotheses) in {\\L}ukasiewicz\nlogic for the case of the full language and for the case of theories containing\nonly disjunctive clauses and show that in contrast to classical propositional\nlogic, the abduction in the clausal fragment has lower complexity than in the\ngeneral case."}
{"id": "2507.13415", "pdf": "https://arxiv.org/pdf/2507.13415", "abs": "https://arxiv.org/abs/2507.13415", "authors": ["Peican Zhu", "Yubo Jing", "Le Cheng", "Bin Chen", "Xiaodong Cui", "Lianwei Wu", "Keke Tang"], "title": "SEER: Semantic Enhancement and Emotional Reasoning Network for Multimodal Fake News Detection", "categories": ["cs.MM", "cs.AI"], "comment": "Accepted by SMC 2025", "summary": "Previous studies on multimodal fake news detection mainly focus on the\nalignment and integration of cross-modal features, as well as the application\nof text-image consistency. However, they overlook the semantic enhancement\neffects of large multimodal models and pay little attention to the emotional\nfeatures of news. In addition, people find that fake news is more inclined to\ncontain negative emotions than real ones. Therefore, we propose a novel\nSemantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake\nnews detection. We generate summarized captions for image semantic\nunderstanding and utilize the products of large multimodal models for semantic\nenhancement. Inspired by the perceived relationship between news authenticity\nand emotional tendencies, we propose an expert emotional reasoning module that\nsimulates real-life scenarios to optimize emotional features and infer the\nauthenticity of news. Extensive experiments on two real-world datasets\ndemonstrate the superiority of our SEER over state-of-the-art baselines."}
{"id": "2507.13661", "pdf": "https://arxiv.org/pdf/2507.13661", "abs": "https://arxiv.org/abs/2507.13661", "authors": ["Changwen Li", "Joseph Sifakis", "Rongjie Yan", "Jian Zhang"], "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't", "categories": ["cs.SE"], "comment": null, "summary": "Despite extensive research, the testing of autonomous driving systems (ADS)\nlandscape remains fragmented, and there is currently no basis for an informed\ntechnical assessment of the importance and contribution of the current state of\nthe art. This paper attempts to address this problem by exploring two\ncomplementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms\nof their intrinsic effectiveness and validity. It shows that many methods do\nnot meet both of these requirements. Either because they are based on criteria\nthat do not allow for rapid, inexpensive, and comprehensive detection of\nfailures, or because the degree of validity of the properties tested cannot be\naccurately estimated. In particular, it is shown that most critical test\nmethods do not take into account the nominal operational capabilities of\nautopilots and generate scenarios that are impossible for the tested vehicles\nto handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly\ndependent on how autopilots are designed: how they choose between different\ncontrol policies to perform maneuvers, as well as on the reproducibility of the\nresults. In fact, most test methods take for granted two principles underlying\ntraditional methods, but do not generally apply to ADS. We maintain that the\nabsence of rationality and determinacy significantly impairs the effectiveness\nand validity of test methods, and provide test results on eight open\nautopilots, in which most do not satisfy these properties, thereby illustrating\nthis fact.\n  We conclude that under the current state of the art, it is impossible to\nobtain strong enough guarantees for essential autopilot properties and\nrecommend that autopilots be developed with a view to both rationality and\ndeterminacy."}
{"id": "2507.13528", "pdf": "https://arxiv.org/pdf/2507.13528", "abs": "https://arxiv.org/abs/2507.13528", "authors": ["Daniele Masti", "Stefano Menchetti", "Çağrı Erdem", "Giorgio Gnecco", "Davide Rocchesso"], "title": "Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface", "categories": ["cs.HC", "cs.SY", "eess.SY"], "comment": null, "summary": "TickTacking is a rhythm-based interface that allows users to control a\npointer in a two-dimensional space through dual-button tapping. This paper\ninvestigates the generation of human-like trajectories using a receding horizon\napproach applied to the TickTacking interface in a target-tracking task. By\nanalyzing user-generated trajectories, we identify key human behavioral\nfeatures and incorporate them in a controller that mimics these behaviors. The\nperformance of this human-inspired controller is evaluated against a baseline\noptimal-control-based agent, demonstrating the importance of specific control\nfeatures for achieving human-like interaction. These findings contribute to the\nbroader goal of developing rhythm-based human-machine interfaces by offering\ndesign insights that enhance user performance, improve intuitiveness, and\nreduce interaction frustration"}
{"id": "2507.13533", "pdf": "https://arxiv.org/pdf/2507.13533", "abs": "https://arxiv.org/abs/2507.13533", "authors": ["Priyam Gupta"], "title": "Increasing the Expressiveness of a Gradual Verifier", "categories": ["cs.PL"], "comment": "Presented at the 52nd ACM SIGPLAN Symposium on Principles of\n  Programming Languages (POPL 2025) Student Research Competition", "summary": "Static verification provides strong correctness guarantees for code; however,\nfully specifying programs for static verification is a complex, burdensome\nprocess for users. Gradual verification was introduced to make this process\neasier by supporting the verification of partially specified programs. The only\ncurrently working gradual verifier, Gradual C0, successfully verifies heap\nmanipulating programs, but lacks expressiveness in its specification language.\nThis paper describes the design and implementation of an extension to Gradual\nC0 that supports unfolding expressions, which allow more intuitive\nspecifications of recursive heap data structures."}
{"id": "2507.13388", "pdf": "https://arxiv.org/pdf/2507.13388", "abs": "https://arxiv.org/abs/2507.13388", "authors": ["Zhen-Qi Chen", "Yuan-Fu Yang"], "title": "DLSF: Dual-Layer Synergistic Fusion for High-Fidelity Image Syn-thesis", "categories": ["cs.GR"], "comment": null, "summary": "With the rapid advancement of diffusion-based generative models, Stable\nDiffusion (SD) has emerged as a state-of-the-art framework for high-fidelity\nim-age synthesis. However, existing SD models suffer from suboptimal feature\naggregation, leading to in-complete semantic alignment and loss of fine-grained\ndetails, especially in highly textured and complex scenes. To address these\nlimitations, we propose a novel dual-latent integration framework that\nen-hances feature interactions between the base latent and refined latent\nrepresentations. Our approach em-ploys a feature concatenation strategy\nfollowed by an adaptive fusion module, which can be instantiated as either (i)\nan Adaptive Global Fusion (AGF) for hier-archical feature harmonization, or\n(ii) a Dynamic Spatial Fusion (DSF) for spatially-aware refinement. This design\nenables more effective cross-latent com-munication, preserving both global\ncoherence and local texture fidelity. Our GitHub page:\nhttps://anonymous.4open.science/r/MVA2025-22 ."}
{"id": "2507.13712", "pdf": "https://arxiv.org/pdf/2507.13712", "abs": "https://arxiv.org/abs/2507.13712", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "title": "LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Automated data preparation is crucial for democratizing machine learning, yet\nexisting reinforcement learning (RL) based approaches suffer from inefficient\nexploration in the vast space of possible preprocessing pipelines. We present\nLLaPipe, a novel framework that addresses this exploration bottleneck by\nintegrating Large Language Models (LLMs) as intelligent policy advisors. Unlike\ntraditional methods that rely solely on statistical features and blind\ntrial-and-error, LLaPipe leverages the semantic understanding capabilities of\nLLMs to provide contextually relevant exploration guidance. Our framework\nintroduces three key innovations: (1) an LLM Policy Advisor that analyzes\ndataset semantics and pipeline history to suggest promising preprocessing\noperations, (2) an Experience Distillation mechanism that mines successful\npatterns from past pipelines and transfers this knowledge to guide future\nexploration, and (3) an Adaptive Advisor Triggering strategy\n(Advisor\\textsuperscript{+}) that dynamically determines when LLM intervention\nis most beneficial, balancing exploration effectiveness with computational\ncost. Through extensive experiments on 18 diverse datasets spanning multiple\ndomains, we demonstrate that LLaPipe achieves up to 22.4\\% improvement in\npipeline quality and 2.3$\\times$ faster convergence compared to\nstate-of-the-art RL-based methods, while maintaining computational efficiency\nthrough selective LLM usage (averaging only 19.0\\% of total exploration steps)."}
{"id": "2507.13676", "pdf": "https://arxiv.org/pdf/2507.13676", "abs": "https://arxiv.org/abs/2507.13676", "authors": ["Cheng Jiang", "Yihe Yan", "Yanxiang Wang", "Jiawei Hu", "Chun Tung Chou", "Wen Hu"], "title": "CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to\nprovide Integrated Sensing and Communication (ISAC) services. The performance\nof both communication and sensing fundamentally depends on the availability of\naccurate and up-to-date channel state information (CSI). In modern 5G networks,\nuplink CSI is derived from two reference signals: the demodulation reference\nsignal (DMRS) and the sounding reference signal (SRS). However, current base\nstation implementations treat these CSI measurements as separate information\nstreams. The key innovation of CARTS is to fuse these two CSI streams, thereby\nincreasing the frequency of CSI updates and extending sensing opportunities to\nmore users. CARTS addresses two key challenges: (i) a novel channel stitching\nand compensation method that integrates asynchronous CSI estimates from DMRS\nand SRS, despite their different time and frequency allocations, and (ii) a\nreal-time SRS triggering algorithm that complements the inherently\nuncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing\nopportunities for all users. Our trace-driven evaluation shows that CARTS\nsignificantly improves scalability, achieving a channel estimation error (NMSE)\nof 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of\nusers as a periodic SRS-only baseline with similar performance. By\nopportunistically combining DMRS and SRS, CARTS therefore provides a practical,\nstandard-compliant solution to improve CSI availability for ISAC without\nrequiring additional radio resources."}
{"id": "2507.13616", "pdf": "https://arxiv.org/pdf/2507.13616", "abs": "https://arxiv.org/abs/2507.13616", "authors": ["Michael S. Harre"], "title": "From Firms to Computation: AI Governance and the Evolution of Institutions", "categories": ["cs.HC", "cs.CY", "cs.ET", "cs.IT", "cs.MA", "math.IT", "J.4; J.3; I.2.11"], "comment": "44 pages", "summary": "The integration of agential artificial intelligence into socioeconomic\nsystems requires us to reexamine the evolutionary processes that describe\nchanges in our economic institutions. This article synthesizes three\nframeworks: multi-level selection theory, Aoki's view of firms as computational\nprocesses, and Ostrom's design principles for robust institutions. We develop a\nframework where selection operates concurrently across organizational levels,\nfirms implement distributed inference via game-theoretic architectures, and\nOstrom-style rules evolve as alignment mechanisms that address AI-related\nrisks. This synthesis yields a multi-level Price equation expressed over nested\ngames, providing quantitative metrics for how selection and governance\nco-determine economic outcomes. We examine connections to Acemoglu's work on\ninclusive institutions, analyze how institutional structures shape AI\ndeployment, and demonstrate the framework's explanatory power via case studies.\nWe conclude by proposing a set of design principles that operationalize\nalignment between humans and AI across institutional layers, enabling scalable,\nadaptive, and inclusive governance of agential AI systems. We conclude with\npractical policy recommendations and further research to extend these\nprinciples into real-world implementation."}
{"id": "2507.13369", "pdf": "https://arxiv.org/pdf/2507.13369", "abs": "https://arxiv.org/abs/2507.13369", "authors": ["Paul E. Calzada", "Zahin Ibnat", "Tanvir Rahman", "Kamal Kandula", "Danyu Lu", "Sujan Kumar Saha", "Farimah Farahmandi", "Mark Tehranipoor"], "title": "VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are gaining popularity for hardware design\nautomation, particularly through Register Transfer Level (RTL) code generation.\nIn this work, we examine the current literature on RTL generation using LLMs\nand identify key requirements for training and fine-tuning datasets. We\nconstruct a robust Verilog dataset through an automated three-pronged process\ninvolving database (DB) creation and management with PostgreSQL, data\ncollection from code hosting sites like OpenCores and GitHub, and data\npreprocessing to verify the codes' syntax, run logic synthesis, and extract\nrelevant module metadata. We implement a scalable and efficient DB\ninfrastructure to support analysis and detail our preprocessing pipeline to\nenforce high-quality data before DB insertion. The resulting dataset comprises\n20,392 Verilog samples, 751 MB of Verilog code data, which is the largest\nhigh-quality Verilog dataset for LLM fine-tuning to our knowledge. We further\nevaluate the dataset, address associated challenges, and explore potential\napplications for future research and development in LLM-based hardware\ngeneration."}
{"id": "2507.13601", "pdf": "https://arxiv.org/pdf/2507.13601", "abs": "https://arxiv.org/abs/2507.13601", "authors": ["Jorge Villarrubia", "Luis Costero", "Francisco D. Igual", "Katzalin Olcoz"], "title": "Leveraging Multi-Instance GPUs through moldable task scheduling", "categories": ["cs.DC", "cs.ET", "cs.PF", "90B36, 90C27, 68M14, 68W40", "C.1.2; C.1.4; C.3.1; D.1.3; G.1.6"], "comment": null, "summary": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into\nmultiple logical instances with fully-isolated resources, which can be\ndynamically reconfigured. This work highlights the untapped potential of MIG\nthrough moldable task scheduling with dynamic reconfigurations. Specifically,\nwe propose a makespan minimization problem for multi-task execution under MIG\nconstraints. Our profiling shows that assuming monotonicity in task work with\nrespect to resources is not viable, as is usual in multicore scheduling.\nRelying on a state-of-the-art proposal that does not require such an\nassumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1\nof FAR builds on a classical task moldability method, phase 2 combines Longest\nProcessing Time First and List Scheduling with a novel repartitioning tree\nheuristic tailored to MIG constraints, and phase 3 employs local search via\ntask moves and swaps. FAR schedules tasks in batches offline, concatenating\ntheir schedules on the fly in an improved way that favors resource reuse.\nExcluding reconfiguration costs, the List Scheduling proof shows an\napproximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to\nthe particular constraints of an NVIDIA A100/H100 to obtain an approximation\nfactor of 2. Including the reconfiguration cost, our real-world experiments\nreveal a makespan with respect to the optimum no worse than 1.22x for a\nwell-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real\nkernels. We obtain good experimental results for each batch of tasks, but also\nin the concatenation of batches, with large improvements over the\nstate-of-the-art and proposals without GPU reconfiguration. Beyond the\nalgorithm, the paper demonstrates the research potential of the MIG technology\nand suggests useful metrics, workload characterizations and evaluation\ntechniques for future work in this field."}
{"id": "2507.13895", "pdf": "https://arxiv.org/pdf/2507.13895", "abs": "https://arxiv.org/abs/2507.13895", "authors": ["Damiano Azzolini", "Marco Duca", "Stefano Forti", "Francesco Gallo", "Antonio Ielo"], "title": "Application Placement with Constraint Relaxation", "categories": ["cs.LO", "cs.DC"], "comment": null, "summary": "Novel utility computing paradigms rely upon the deployment of multi-service\napplications to pervasive and highly distributed cloud-edge infrastructure\nresources. Deciding onto which computational nodes to place services in\ncloud-edge networks, as per their functional and non-functional constraints,\ncan be formulated as a combinatorial optimisation problem. Most existing\nsolutions in this space are not able to deal with \\emph{unsatisfiable} problem\ninstances, nor preferences, i.e. requirements that DevOps may agree to relax to\nobtain a solution. In this article, we exploit Answer Set Programming\noptimisation capabilities to tackle this problem. Experimental results in\nsimulated settings show that our approach is effective on lifelike networks and\napplications."}
{"id": "2507.13367", "pdf": "https://arxiv.org/pdf/2507.13367", "abs": "https://arxiv.org/abs/2507.13367", "authors": ["Mehrab Hosain", "Rajiv Kapoor"], "title": "A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security", "categories": ["cs.CR", "cs.CV", "cs.MM", "eess.IV", "68Q80", "I.4.2"], "comment": "Accepted COMITCON 2023. Lecture Notes in Electrical Engineering, vol\n  1191. Springer", "summary": "Steganography is the process of embedding secret information discreetly\nwithin a carrier, ensuring secure exchange of confidential data. The Adaptive\nPixel Value Differencing (APVD) steganography method, while effective,\nencounters certain challenges like the \"unused blocks\" issue. This problem can\ncause a decrease in security, compromise the embedding capacity, and lead to\nlower visual quality. This research presents a novel steganographic strategy\nthat integrates APVD with pseudorandom pixel selection to effectively mitigate\nthese issues. The results indicate that the new method outperforms existing\ntechniques in aspects of security, data hiding capacity, and the preservation\nof image quality. Empirical results reveal that the combination of APVD with\npseudorandom pixel selection significantly enhances key image quality metrics\nsuch as Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQ),\nand Structural Similarity Index (SSIM), surpassing other contemporary methods\nin performance. The newly proposed method is versatile, able to handle a\nvariety of cover and secret images in both color and grayscale, thereby\nensuring secure data transmission without compromising the aesthetic quality of\nthe image."}
{"id": "2507.13578", "pdf": "https://arxiv.org/pdf/2507.13578", "abs": "https://arxiv.org/abs/2507.13578", "authors": ["Emmanuel Akinrintoyo", "Nicole Salomons"], "title": "In-Home Social Robots Design for Cognitive Stimulation Therapy in Dementia Care", "categories": ["cs.HC"], "comment": "Submitted to RO-MAN 2025 (Accepted)", "summary": "Individual cognitive stimulation therapy (iCST) is a non-pharmacological\nintervention for improving the cognition and quality of life of persons with\ndementia (PwDs); however, its effectiveness is limited by low adherence to\ndelivery by their family members. In this work, we present the user-centered\ndesign and evaluation of a novel socially assistive robotic system to provide\niCST therapy to PwDs in their homes for long-term use. We consulted with 16\ndementia caregivers and professionals. Through these consultations, we gathered\ndesign guidelines and developed the prototype. The prototype was validated by\ntesting it with three dementia professionals and five PwDs. The evaluation\nrevealed PwDs enjoyed using the system and are willing to adopt its use over\nthe long term. One shortcoming was the system's speech-to-text capabilities,\nwhere it frequently failed to understand the PwDs."}
{"id": "2507.13774", "pdf": "https://arxiv.org/pdf/2507.13774", "abs": "https://arxiv.org/abs/2507.13774", "authors": ["Arthur Adjedj", "Meven Lennon-Bertrand", "Thibaut Benjamin", "Kenji Maillard"], "title": "AdapTT: Functoriality for Dependent Type Casts", "categories": ["cs.PL", "cs.LO", "D.3.1; F.3.2; F.4.1"], "comment": null, "summary": "The ability to cast values between related types is a leitmotiv of many\nflavors of dependent type theory, such as observational type theories,\nsubtyping, or cast calculi for gradual typing. These casts all exhibit a common\nstructural behavior that boils down to the pervasive functoriality of type\nformers. We propose and extensively study a type theory, called AdapTT, which\nmakes systematic and precise this idea of functorial type formers, with respect\nto an abstract notion of adapters relating types. Leveraging descriptions for\nfunctorial inductive types in AdapTT, we derive structural laws for type casts\non general inductive type formers."}
{"id": "2507.13419", "pdf": "https://arxiv.org/pdf/2507.13419", "abs": "https://arxiv.org/abs/2507.13419", "authors": ["Joost Mertens", "Joachim Denil"], "title": "Lab-Scale Gantry Crane Digital Twin Exemplar", "categories": ["cs.GR"], "comment": "6 pages, 8 figures, associated GitHub repository:\n  https://github.com/Cosys-Lab/lab-scale-gantry-crane", "summary": "The research topic of digital twins has attracted a large amount of interest\nover the past decade. However, publicly available exemplars remain scarce. In\nthe interest of open and reproducible science, in this exemplar paper we\npresent a lab-scale gantry crane and its digital twin. The exemplar comprises\nboth the physical and digital side of the twin system. The physical side\nconsists of the physical crane and its controller. The digital side covers the\nCAD models and kinematic model of the crane, and provides services for optimal\ncontrol, historical data logging, data visualization and continuous validation.\nWe used this setup as use case in several previous publications where its\nfunctionality was validated. It is publicly available and only relies on other\nfreely available and commonly used software, this way we hope it can be used\nfor future research or education on the topic of digital twins."}
{"id": "2507.13757", "pdf": "https://arxiv.org/pdf/2507.13757", "abs": "https://arxiv.org/abs/2507.13757", "authors": ["Joydeep Chandra", "Prabal Manhas"], "title": "Efficient and Scalable Self-Healing Databases Using Meta-Learning and Dependency-Driven Recovery", "categories": ["cs.DB"], "comment": null, "summary": "This study explored the development of a novel self-healing framework for\ndatabases using meta-learning and reinforcement learning techniques. The\nprimary objective was to address the challenges of real-time adaptability and\nminimal retraining in dynamic workload environments. The proposed approach\nintegrated Model-Agnostic Meta-Learning (MAML) with reinforcement learning to\nenable anomaly detection and corrective actions that adapted swiftly to\nevolving database conditions. Multi-objective optimization was employed to\nbalance performance, resource utilization, and cost efficiency during the\nhealing process. Graph Neural Networks (GNNs) were incorporated to model\ninterdependencies within database components, ensuring holistic recovery\nstrategies. Data efficiency was enhanced through synthetic task augmentation\nand self-supervised learning, enabling effective training in sparse data\nregimes. To promote trust and transparency, explainable AI techniques were\nintegrated to provide interpretable insights into anomaly detection and healing\nactions. Federated meta-learning further enabled privacy-preserving\nadaptability in distributed database environments. The framework demonstrated\nsignificant improvements in adaptability, efficiency, and reliability,\ncontributing to advancements in database management and self-healing systems."}
{"id": "2507.13717", "pdf": "https://arxiv.org/pdf/2507.13717", "abs": "https://arxiv.org/abs/2507.13717", "authors": ["Yingming Mao", "Qiaozhu Zhai", "Zhen Yao", "Xia Zhu", "Ximeng Liu", "Xinchi Han"], "title": "ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks", "categories": ["cs.NI", "C.2.3"], "comment": null, "summary": "The growing scale and complexity of reconfigurable data center networks\n(DCNs) demand more scalable and efficient algorithms for computing logical\ntopologies and routing. Reconfigurable DCNs typically operate in two modes:\none-hop configurations that require frequent topology optimization (TO), and\nmulti-hop scenarios that involve joint topology and routing optimization (TRO).\nIn both cases, the combinatorial nature of topology decisions makes it\ndifficult for existing methods to balance solution quality and runtime\nefficiency. To address this, we introduce Alternating Topology and Routing\nOptimization (ATRO), a solver-free framework that alternates between TO and\nrouting optimization (RO). This decomposition exploits two key insights: first,\neach alternating update step monotonically reduces maximum link utilization\n(MLU), ensuring consistent performance improvement across iterations; second,\nthe TO subproblem, equivalent to one-hop optimization, exhibits a monotonic\nstructure that enables optimal solutions via an efficient Accelerated Binary\nSearch Method (ABSM). To preserve the solver-free design, RO is solved using\nexisting Traffic Engineering accelerators. ATRO attains the global optimum in\none-hop scenarios and significantly outperforms baselines in multi-hop settings\nin terms of both runtime and solution quality. Evaluations confirm its\nscalability and robustness across diverse DCNs."}
{"id": "2507.13720", "pdf": "https://arxiv.org/pdf/2507.13720", "abs": "https://arxiv.org/abs/2507.13720", "authors": ["Saurav Ghosh"], "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "comment": "12 Pages, 4 figures", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era."}
{"id": "2507.13375", "pdf": "https://arxiv.org/pdf/2507.13375", "abs": "https://arxiv.org/abs/2507.13375", "authors": ["Chunyuan Zhao", "Zizheng Guo", "Zuodong Zhang", "Yibo Lin"], "title": "GAP-LA: GPU-Accelerated Performance-Driven Layer Assignment", "categories": ["cs.AR"], "comment": null, "summary": "Layer assignment is critical for global routing of VLSI circuits. It converts\n2D routing paths into 3D routing solutions by determining the proper metal\nlayer for each routing segments to minimize congestion and via count. As\ndifferent layers have different unit resistance and capacitance, layer\nassignment also has significant impacts to timing and power. With growing\ndesign complexity, it becomes increasingly challenging to simultaneously\noptimize timing, power, and congestion efficiently. Existing studies are mostly\nlimited to a subset of objectives. In this paper, we propose a GPU-accelerated\nperformance-driven layer assignment framework, GAP-LA, for holistic\noptimization the aforementioned objectives. Experimental results demonstrate\nthat we can achieve 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4%\nbetter total negative slack (TNS) while maintaining power and congestion with\ncompetitive runtime compared with ISPD 2025 contest winners, especially on\ndesigns with up to 12 millions of nets."}
{"id": "2507.13833", "pdf": "https://arxiv.org/pdf/2507.13833", "abs": "https://arxiv.org/abs/2507.13833", "authors": ["Zhixin Wang", "Tianyi Zhou", "Liming Liu", "Ao Li", "Jiarui Hu", "Dian Yang", "Jinlong Hou", "Siyuan Feng", "Yuan Cheng", "Yuan Qi"], "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training", "categories": ["cs.DC"], "comment": null, "summary": "Reinforcement learning (RL) has become the pivotal post-training technique\nfor large language model. Effectively scaling reinforcement learning is now the\nkey to unlocking advanced reasoning capabilities and ensuring safe,\ngoal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually\nemploy a hybrid-controller architecture where a single-controller dispatches\nthe overall execution logic and manages overall data transfer and the\nmulti-controller executes distributed computation. For large-scale\nreinforcement learning, minor load imbalances can introduce significant\nbottlenecks, ultimately constraining the scalability of the system. To address\nthis limitation, we introduce DistFlow, a novel, fully distributed RL framework\ndesigned to break scaling barrier. We adopt a multi-controller paradigm that\ndispatches data transfer and execution tasks to all workers, which eliminates\nthe centralized node. This allows each worker to operate independently, leading\nto near-linear scalability up to thousands of GPUs and dramatic efficiency\ngains. Furthermore, our architecture decouples resource configuration from\nexecution logic, allowing each worker to have a unique execution flow, offering\nsignificant flexibility for rapid and cost-effective algorithmic\nexperimentation. Extensive experiments show that DistFlow achieves excellent\nlinear scalability and up to a 7x end-to-end throughput improvement over\nstate-of-the-art (SOTA) frameworks."}
{"id": "2507.13946", "pdf": "https://arxiv.org/pdf/2507.13946", "abs": "https://arxiv.org/abs/2507.13946", "authors": ["Tadeusz Litak", "Katsuhiko Sano"], "title": "Bounded Inquisitive Logics: Sequent Calculi and Schematic Validity", "categories": ["cs.LO"], "comment": "This is a modified and expanded version of a paper accepted for\n  TABLEAUX 2025. In particular, readers should note that the numeration of\n  environments is different in the conference version", "summary": "Propositional inquisitive logic is the limit of its $n$-bounded\napproximations. In the predicate setting, however, this does not hold anymore,\nas discovered by Ciardelli and Grilletti, who also found complete\naxiomatizations of $n$-bounded inquisitive logics $\\mathsf{InqBQ}_{n}$, for\nevery fixed $n$. We introduce cut-free labelled sequent calculi for these\nlogics. We illustrate the intricacies of \\textit{schematic validity} in such\nsystems by showing that the well-known Casari formula is \\textit{atomically}\nvalid in (a weak sublogic of) predicate inquisitive logic $\\mathsf{InqBQ}$,\nfails to be schematically valid in it, and yet is schematically valid under the\nfinite boundedness assumption. The derivations in our calculi, however, are\nguaranteed to be schematically valid whenever a single specific rule is not\nused."}
{"id": "2507.13677", "pdf": "https://arxiv.org/pdf/2507.13677", "abs": "https://arxiv.org/abs/2507.13677", "authors": ["Chuheng Wei", "Ziye Qin", "Walter Zimmer", "Guoyuan Wu", "Matthew J. Barth"], "title": "HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "Ranked first in CVPR DriveX workshop TUM-Traf V2X challenge. Accepted\n  by ITSC2025", "summary": "Real-world Vehicle-to-Everything (V2X) cooperative perception systems often\noperate under heterogeneous sensor configurations due to cost constraints and\ndeployment variability across vehicles and infrastructure. This heterogeneity\nposes significant challenges for feature fusion and perception reliability. To\naddress these issues, we propose HeCoFuse, a unified framework designed for\ncooperative perception across mixed sensor setups where nodes may carry Cameras\n(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that\nadaptively weights features through a combination of channel-wise and spatial\nattention, HeCoFuse can tackle critical challenges such as cross-modality\nfeature misalignment and imbalanced representation quality. In addition, an\nadaptive spatial resolution adjustment module is employed to balance\ncomputational cost and fusion effectiveness. To enhance robustness across\ndifferent configurations, we further implement a cooperative learning strategy\nthat dynamically adjusts fusion type based on available modalities. Experiments\non the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%\n3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D\nbaseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC\nscenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine\nheterogeneous sensor configurations. These results, validated by our\nfirst-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the\ncurrent state-of-the-art on TUM-Traf V2X dataset while demonstrating robust\nperformance across diverse sensor deployments."}
{"id": "2507.13616", "pdf": "https://arxiv.org/pdf/2507.13616", "abs": "https://arxiv.org/abs/2507.13616", "authors": ["Michael S. Harre"], "title": "From Firms to Computation: AI Governance and the Evolution of Institutions", "categories": ["cs.HC", "cs.CY", "cs.ET", "cs.IT", "cs.MA", "math.IT", "J.4; J.3; I.2.11"], "comment": "44 pages", "summary": "The integration of agential artificial intelligence into socioeconomic\nsystems requires us to reexamine the evolutionary processes that describe\nchanges in our economic institutions. This article synthesizes three\nframeworks: multi-level selection theory, Aoki's view of firms as computational\nprocesses, and Ostrom's design principles for robust institutions. We develop a\nframework where selection operates concurrently across organizational levels,\nfirms implement distributed inference via game-theoretic architectures, and\nOstrom-style rules evolve as alignment mechanisms that address AI-related\nrisks. This synthesis yields a multi-level Price equation expressed over nested\ngames, providing quantitative metrics for how selection and governance\nco-determine economic outcomes. We examine connections to Acemoglu's work on\ninclusive institutions, analyze how institutional structures shape AI\ndeployment, and demonstrate the framework's explanatory power via case studies.\nWe conclude by proposing a set of design principles that operationalize\nalignment between humans and AI across institutional layers, enabling scalable,\nadaptive, and inclusive governance of agential AI systems. We conclude with\npractical policy recommendations and further research to extend these\nprinciples into real-world implementation."}
{"id": "2507.13792", "pdf": "https://arxiv.org/pdf/2507.13792", "abs": "https://arxiv.org/abs/2507.13792", "authors": ["Riccardo Bianchini", "Francesco Dagnino", "Paola Giannini", "Elena Zucca"], "title": "Don't exhaust, don't waste", "categories": ["cs.PL"], "comment": "Submitted to JFP (Journal of Functional Programming)", "summary": "We extend the semantics and type system of a lambda calculus equipped with\ncommon constructs to be resource-aware. That is, the semantics keep tracks of\nthe usage of resources, and is stuck, besides in case of type errors, if either\na needed resource is exhausted, or a provided resource would be wasted. In such\nway, the type system guarantees, besides standard soundness, that for\nwell-typed programs there is a computation where no resource gets either\nexhausted or wasted.\n  The no-waste extension is parametric on an arbitrary grade algebra, modeling\nan arbitrary assortment of possible usages, and does not require ad-hoc changes\nto the underlying language. To this end, the semantics needs to be formalized\nin big-step style; as a consequence, expressing and proving (resource-aware)\nsoundness is challenging, and is achieved by applying recent techniques based\non coinductive reasoning."}
{"id": "2507.13586", "pdf": "https://arxiv.org/pdf/2507.13586", "abs": "https://arxiv.org/abs/2507.13586", "authors": ["Kaiyuan Tang", "Kuangshi Ai", "Jun Han", "Chaoli Wang"], "title": "TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting", "categories": ["cs.GR", "cs.CL", "cs.CV"], "comment": "Accepted by IEEE VIS 2025", "summary": "Advancements in volume visualization (VolVis) focus on extracting insights\nfrom 3D volumetric data by generating visually compelling renderings that\nreveal complex internal structures. Existing VolVis approaches have explored\nnon-photorealistic rendering techniques to enhance the clarity, expressiveness,\nand informativeness of visual communication. While effective, these methods\noften rely on complex predefined rules and are limited to transferring a single\nstyle, restricting their flexibility. To overcome these limitations, we\nadvocate the representation of VolVis scenes using differentiable Gaussian\nprimitives combined with pretrained large models to enable arbitrary style\ntransfer and real-time rendering. However, conventional 3D Gaussian primitives\ntightly couple geometry and appearance, leading to suboptimal stylization\nresults. To address this, we introduce TexGS-VolVis, a textured Gaussian\nsplatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,\nextending each Gaussian with additional texture and shading attributes,\nresulting in higher-quality, geometry-consistent stylization and enhanced\nlighting control during inference. Despite these improvements, achieving\nflexible and controllable scene editing remains challenging. To further enhance\nstylization, we develop image- and text-driven non-photorealistic scene editing\ntailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing\nwith fine-grained control. We evaluate TexGS-VolVis both qualitatively and\nquantitatively across various volume rendering scenes, demonstrating its\nsuperiority over existing methods in terms of efficiency, visual quality, and\nediting flexibility."}
{"id": "2507.13892", "pdf": "https://arxiv.org/pdf/2507.13892", "abs": "https://arxiv.org/abs/2507.13892", "authors": ["Kevin M. Kramer", "Valerie Restat", "Sebastian Strasser", "Uta Störl", "Meike Klettke"], "title": "Towards Next Generation Data Engineering Pipelines", "categories": ["cs.DB"], "comment": null, "summary": "Data engineering pipelines are a widespread way to provide high-quality data\nfor all kinds of data science applications. However, numerous challenges still\nremain in the composition and operation of such pipelines. Data engineering\npipelines do not always deliver high-quality data. By default, they are also\nnot reactive to changes. When new data is coming in which deviates from prior\ndata, the pipeline could crash or output undesired results. We therefore\nenvision three levels of next generation data engineering pipelines: optimized\ndata pipelines, self-aware data pipelines, and self-adapting data pipelines.\nPipeline optimization addresses the composition of operators and their\nparametrization in order to achieve the highest possible data quality.\nSelf-aware data engineering pipelines enable a continuous monitoring of its\ncurrent state, notifying data engineers on significant changes. Self-adapting\ndata engineering pipelines are then even able to automatically react to those\nchanges. We propose approaches to achieve each of these levels."}
{"id": "2507.13889", "pdf": "https://arxiv.org/pdf/2507.13889", "abs": "https://arxiv.org/abs/2507.13889", "authors": ["Bilal Karaman", "Ilhan Basturk", "Ferdi Kara", "Metin Ozturk", "Sezai Taskin", "Halil Yanikomeroglu"], "title": "On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies", "categories": ["cs.NI", "eess.SP"], "comment": "accepted in PIMRC2025", "summary": "This paper investigates the integration of active reconfigurable intelligent\nsurfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance\nnon-terrestrial network (NTN) performance in next-generation wireless systems.\nWhile prior studies focused on passive RIS architectures, the severe path loss\nand double fading in long-distance HAPS links make active RIS a more suitable\nalternative due to its inherent signal amplification capabilities. We formulate\na sum-rate maximization problem to jointly optimize power allocation and RIS\nelement assignment for ground user equipments (UEs) supported by a HAPS-based\nactive RIS-assisted communication system. To reduce power consumption and\nhardware complexity, several sub-connected active RIS architectures are also\nexplored. Simulation results reveal that active RIS configurations\nsignificantly outperform passive RIS in terms of quality of service (QoS).\nMoreover, although fully-connected architectures achieve the highest\nthroughput, sub-connected schemes demonstrate superior energy efficiency under\npractical power constraints. These findings highlight the potential of active\nRIS-enabled HAPS systems to meet the growing demands of beyond-cellular\ncoverage and green networking."}
{"id": "2507.13775", "pdf": "https://arxiv.org/pdf/2507.13775", "abs": "https://arxiv.org/abs/2507.13775", "authors": ["Emiliano Staffoli", "Elisabetta Ferri", "Stefano Gretter", "Lorenzo Pavesi"], "title": "Nonlinear Distortion Equalization in Multi-Span Optical Links Via a Feed-Forward Photonic Neural Network", "categories": ["physics.optics", "cs.ET", "eess.SP"], "comment": "21 pages, 14 figures, 2 tables", "summary": "Linear and nonlinear distortions in optical communication signals are\nequalized using an integrated feed-forward Photonic Neural Network (PNN). The\nPNN is based on a linear stage made of an 8-tap Finite Impulse Response (FIR)\nfilter, featuring tunable amplitude and phase weights at each tap, and of a\nnonlinear stage achieved through the square modulus operation at the\nend-of-line photodetector. Within an Intensity Modulation/Direct Detection\n(IMDD) system, the PNN is applied to 2-level Pulse Amplitude Modulated (PAM2)\noptical signals undergoing multi-span propagation. Each 50 km segment includes\nfiber transmission, optical power restoration, and optional chromatic\ndispersion compensation via a Tunable Dispersion Compensator. Positioned at the\nreceiver, the PNN enables fully optical signal processing with minimal latency\nand power consumption. Experimental validation is conducted using a\nSilicon-On-Insulator device operating on 10 Gbps signals. It demonstrates\nchromatic dispersion equalization over distances up to 200 km and self-phase\nmodulation (with dispersion removed) up to 450 km. Simulations explore PNN\nadaptation for 100 Gbps modulations and its potential for cross-phase\nmodulation equalization."}
{"id": "2507.13631", "pdf": "https://arxiv.org/pdf/2507.13631", "abs": "https://arxiv.org/abs/2507.13631", "authors": ["Fuyuki Kihara", "Seiji Uenohara", "Satoshi Awamura", "Naoko Misawa", "Chihiro Matsui", "Ken Takeuchi"], "title": "4T2R X-ReRAM CiM Array for Variation-tolerant, Low-power, Massively Parallel MAC Operation", "categories": ["cs.AR"], "comment": "4 pages", "summary": "Computation-in-Memory (CiM) is attracting attention as a technology that can\nperform MAC calculations required for AI accelerators, at high speed with low\npower consumption. However, there is a problem regarding power consumption and\ndevice-derived errors that increase as row parallelism increases. In this\npaper, a 4T2R ReRAM cell and an 8T SRAM CiM suitable for CiM is proposed. It is\nshown that adopting the proposed 4T2R ReRAM cell reduces the errors due to\nvariation in ReRAM devices compared to conventional 4T4R ReRAM cells."}
{"id": "2507.14069", "pdf": "https://arxiv.org/pdf/2507.14069", "abs": "https://arxiv.org/abs/2507.14069", "authors": ["Shuiguang Deng", "Di Yu", "Changze Lv", "Xin Du", "Linshan Jiang", "Xiaofan Zhao", "Wentao Tong", "Xiaoqing Zheng", "Weijia Fang", "Peng Zhao", "Gang Pan", "Schahram Dustdar", "Albert Y. Zomaya"], "title": "Edge Intelligence with Spiking Neural Networks", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NE"], "comment": "This work has been submitted to Proceeding of IEEE for possible\n  publication", "summary": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence."}
{"id": "2507.13987", "pdf": "https://arxiv.org/pdf/2507.13987", "abs": "https://arxiv.org/abs/2507.13987", "authors": ["Simon Flügel", "Martin Glauer", "Till Mossakowski", "Fabian Neuhaus"], "title": "ChemLog: Making MSOL Viable for Ontological Classification and Learning", "categories": ["cs.LO"], "comment": null, "summary": "Despite its prevalence, in many domains, OWL is not expressive enough to\ndefine ontology classes. In this paper, we present an approach that allows to\nuse monadic second-order formalisations for ontology classification. As a case\nstudy, we have applied our approach to 14 peptide-related classes from the\nchemistry ontology ChEBI. For these classes, a monadic second-order logic\nformalisation has been developed and applied both to ChEBI as well as to 119\nmillion molecules from the chemistry database PubChem. While this logical\napproach alone is limited to classification for the specified classes (in our\ncase, (sub)classes of peptides), transformer deep learning models scale\nclassification to the whole of the ChEBI ontology. We show that when using the\nclassifications obtained by the logical approach as training data, the\nperformance of the deep learning models can be significantly enhanced."}
{"id": "2507.13737", "pdf": "https://arxiv.org/pdf/2507.13737", "abs": "https://arxiv.org/abs/2507.13737", "authors": ["Ye Tian", "Xiaoyuan Ren", "Zihao Wang", "Onat Gungor", "Xiaofan Yu", "Tajana Rosing"], "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MM"], "comment": null, "summary": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed."}
{"id": "2507.13660", "pdf": "https://arxiv.org/pdf/2507.13660", "abs": "https://arxiv.org/abs/2507.13660", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges", "Aileen Worden"], "title": "Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "Two user studies were performed to evaluate the effect of level-of-detail\n(LOD) degradation in the periphery of head-mounted displays on visual search\nperformance. In the first study, spatial detail was degraded by reducing\nresolution. In the second study, detail was degraded in the color domain by\nusing grayscale in the periphery. In each study, 10 subjects were given a\ncomplex search task that required users to indicate whether or not a target\nobject was present among distracters. Subjects used several different displays\nvarying in the amount of detail presented. Frame rate, object location, subject\ninput method, and order of display use were all controlled. The primary\ndependent measures were search time on correctly performed trials and the\npercentage of all trials correctly performed. Results indicated that peripheral\nLOD degradation can be used to reduce color or spatial visual complexity by\nalmost half in some search tasks with out significantly reducing performance."}
{"id": "2507.13499", "pdf": "https://arxiv.org/pdf/2507.13499", "abs": "https://arxiv.org/abs/2507.13499", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "title": "AI-Assisted Fixes to Code Review Comments at Scale", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale."}
{"id": "2507.13917", "pdf": "https://arxiv.org/pdf/2507.13917", "abs": "https://arxiv.org/abs/2507.13917", "authors": ["Efstratios Geronikolakis", "Manos Kamarianakis", "Antonis Protopsaltis", "George Papagiannakis"], "title": "Neural-GASh: A CGA-based neural radiance prediction pipeline for real-time shading", "categories": ["cs.GR"], "comment": "11 pages, 10 figures", "summary": "This paper presents Neural-GASh, a novel real-time shading pipeline for 3D\nmeshes, that leverages a neural radiance field architecture to perform\nimage-based rendering (IBR) using Conformal Geometric Algebra (CGA)-encoded\nvertex information as input. Unlike traditional Precomputed Radiance Transfer\n(PRT) methods, that require expensive offline precomputations, our learned\nmodel directly consumes CGA-based representations of vertex positions and\nnormals, enabling dynamic scene shading without precomputation. Integrated\nseamlessly into the Unity engine, Neural-GASh facilitates accurate shading of\nanimated and deformed 3D meshes - capabilities essential for dynamic,\ninteractive environments. The shading of the scene is implemented within Unity,\nwhere rotation of scene lights in terms of Spherical Harmonics is also\nperformed optimally using CGA. This neural field approach is designed to\ndeliver fast and efficient light transport simulation across diverse platforms,\nincluding mobile and VR, while preserving high rendering quality. Additionally,\nwe evaluate our method on scenes generated via 3D Gaussian splats, further\ndemonstrating the flexibility and robustness of Neural-GASh in diverse\nscenarios. Performance is evaluated in comparison to conventional PRT,\ndemonstrating competitive rendering speeds even with complex geometries."}
{"id": "2507.14101", "pdf": "https://arxiv.org/pdf/2507.14101", "abs": "https://arxiv.org/abs/2507.14101", "authors": ["Diego Figueira", "Cibele Freire"], "title": "Project-connex Decompositions and Tractability of Aggregate Group-by Conjunctive Queries", "categories": ["cs.DB"], "comment": "34 pages, 5 figures", "summary": "We introduce 'project-connex' tree-width as a measure of tractability for\ncounting and aggregate conjunctive queries over semirings with 'group-by'\nprojection (also known as 'AJAR' or 'FAQ' queries). This elementary measure\nallows to obtain comparable complexity bounds to the ones obtained by previous\nstructural conditions tailored for efficient evaluation of semiring aggregate\nqueries, enumeration algorithms of conjunctive queries, and tractability of\ncounting answers to conjunctive queries.\n  Project-connex tree decompositions are defined as the natural extension of\nthe known notion of 'free-connex' decompositions. They allow for a unified,\nsimple and intuitive algorithmic manipulation for evaluation of aggregate\nqueries and explain some existing tractability results on conjunctive query\nenumeration, counting conjunctive query evaluation, and evaluation of semiring\naggregate queries. Using this measure we also recover results relating\ntractable classes of counting conjunctive queries and bounded free-connex\ntree-width, or the constant-time delay enumeration of semiring aggregate\nqueries over bounded project-connex classes. We further show that\nproject-connex tree decompositions can be obtained via algorithms for computing\nclassical tree decompositions."}
{"id": "2507.13933", "pdf": "https://arxiv.org/pdf/2507.13933", "abs": "https://arxiv.org/abs/2507.13933", "authors": ["Sichang \"Steven\" He", "Ramesh Govindan", "Harsha V. Madhyastha"], "title": "Preprint: Did I Just Browse A Website Written by LLMs?", "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.IR"], "comment": "In submission. 2 pages. 3 figures", "summary": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem."}
{"id": "2507.14007", "pdf": "https://arxiv.org/pdf/2507.14007", "abs": "https://arxiv.org/abs/2507.14007", "authors": ["Serhan W. Bahar"], "title": "The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems", "categories": ["cs.CR", "cs.ET"], "comment": null, "summary": "The rapid integration of blockchain, cryptocurrency, and Web3 technologies\ninto digital banks and fintech operations has created an integrated environment\nblending traditional financial systems with decentralised elements. This paper\nintroduces the CryptoNeo Threat Modelling Framework (CNTMF), a proposed\nframework designed to address the risks in these ecosystems, such as oracle\nmanipulation and cross-chain exploits. CNTMF represents a proposed extension of\nestablished methodologies like STRIDE, OWASP Top 10, NIST frameworks, LINDDUN,\nand PASTA, while incorporating tailored components including Hybrid Layer\nAnalysis, the CRYPTOQ mnemonic for cryptocurrency-specific risks, and an\nAI-Augmented Feedback Loop. Drawing on real-world data from 2025 incidents,\nCNTMF supports data-driven mitigation to reduce losses, which totalled\napproximately $2.47 billion in the first half of 2025 across 344 security\nevents (CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025). Its\nphases guide asset mapping, risk profiling, prioritisation, mitigation, and\niterative feedback. This supports security against evolving risks like\nstate-sponsored attacks."}
{"id": "2507.13736", "pdf": "https://arxiv.org/pdf/2507.13736", "abs": "https://arxiv.org/abs/2507.13736", "authors": ["Matthias Jobst", "Tim Langer", "Chen Liu", "Mehmet Alici", "Hector A. Gonzalez", "Christian Mayr"], "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": "Poster at ACM ICONS 2025 - International Conference on Neuromorphic\n  Systems", "summary": "This work presents a multi-layer DNN scheduling framework as an extension of\nOctopuScheduler, providing an end-to-end flow from PyTorch models to inference\non a single SpiNNaker2 chip. Together with a front-end comprised of\nquantization and lowering steps, the proposed framework enables the edge-based\nexecution of large and complex DNNs up to transformer scale using the\nneuromorphic platform SpiNNaker2."}
{"id": "2507.14080", "pdf": "https://arxiv.org/pdf/2507.14080", "abs": "https://arxiv.org/abs/2507.14080", "authors": ["Derek Leung", "Nickolai Zeldovich", "Frans Kaashoek"], "title": "Shipwright: Proving liveness of distributed systems with Byzantine participants", "categories": ["cs.DC", "D.2.4; C.2.4"], "comment": "14 pages, 13 figures", "summary": "Ensuring liveness in a decentralized system, such as PBFT, is critical,\nbecause there may not be any single administrator that can restart the system\nif it encounters a liveness bug. At the same time, liveness is challenging to\nachieve because any single participant could be malicious, and yet the overall\nsystem must make forward progress. While verification is a promising approach\nfor ensuring the absence of bugs, no prior work has been able to verify\nliveness for an executable implementation of PBFT.\n  Shipwright is a verification framework for proving correctness and liveness\nof distributed systems where some participants might be malicious. Shipwright\nintroduces three techniques that enable formal reasoning about decentralized\nsettings with malicious participants, allow developers to decompose their\nsystem and proof in a modular fashion into sub-protocols and sub-proofs, and\nsupport sound reasoning about cryptographic signatures that may be embedded in\nmessages. We used Shipwright to implement and verify an initial prototype of\nagreement on a single log entry in PBFT (with a few limitations) and translate\nit to an executable implementation in Go. We experimentally demonstrate its\noperation and liveness both in the common case and in several failure\nscenarios."}
{"id": "2507.13635", "pdf": "https://arxiv.org/pdf/2507.13635", "abs": "https://arxiv.org/abs/2507.13635", "authors": ["Nengkun Yu", "Jens Palsberg", "Thomas Reps"], "title": "SAQR-QC: A Logic for Scalable but Approximate Quantitative Reasoning about Quantum Circuits", "categories": ["quant-ph", "cs.LO", "cs.PL"], "comment": "Comments are welcome", "summary": "Reasoning about quantum programs remains a fundamental challenge, regardless\nof the programming model or computational paradigm. Despite extensive research,\nexisting verification techniques are insufficient--even for quantum circuits, a\ndeliberately restricted model that lacks classical control, but still underpins\nmany current quantum algorithms. Many existing formal methods require\nexponential time and space to represent and manipulate (representations of)\nassertions and judgments, making them impractical for quantum circuits with\nmany qubits. This paper presents a logic for reasoning in such settings, called\nSAQR-QC. The logic supports Scalable but Approximate Quantitative Reasoning\nabout Quantum Circuits, whence the name. SAQR-QC has three characteristics: (i)\nsome (deliberate) loss of precision is built into it; (ii) it has a mechanism\nto help the accumulated loss of precision during a sequence of reasoning steps\nremain small; and (iii) most importantly, to make reasoning scalable, all\nreasoning steps are local--i.e., they each involve just a small number of\nqubits. We demonstrate the effectiveness of SAQR-QC via two case studies: the\nverification of GHZ circuits involving non-Clifford gates, and the analysis of\nquantum phase estimation--a core subroutine in Shor's factoring algorithm."}
{"id": "2507.13929", "pdf": "https://arxiv.org/pdf/2507.13929", "abs": "https://arxiv.org/abs/2507.13929", "authors": ["Hsiang-Hui Hung", "Huu-Phu Do", "Yung-Hui Li", "Ching-Chun Huang"], "title": "TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted by MM 2024", "summary": "We present TimeNeRF, a generalizable neural rendering approach for rendering\nnovel views at arbitrary viewpoints and at arbitrary times, even with few input\nviews. For real-world applications, it is expensive to collect multiple views\nand inefficient to re-optimize for unseen scenes. Moreover, as the digital\nrealm, particularly the metaverse, strives for increasingly immersive\nexperiences, the ability to model 3D environments that naturally transition\nbetween day and night becomes paramount. While current techniques based on\nNeural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing\nnovel views, the exploration of NeRF's potential for temporal 3D scene modeling\nremains limited, with no dedicated datasets available for this purpose. To this\nend, our approach harnesses the strengths of multi-view stereo, neural radiance\nfields, and disentanglement strategies across diverse datasets. This equips our\nmodel with the capability for generalizability in a few-shot setting, allows us\nto construct an implicit content radiance field for scene representation, and\nfurther enables the building of neural radiance fields at any arbitrary time.\nFinally, we synthesize novel views of that time via volume rendering.\nExperiments show that TimeNeRF can render novel views in a few-shot setting\nwithout per-scene optimization. Most notably, it excels in creating realistic\nnovel views that transition smoothly across different times, adeptly capturing\nintricate natural scene changes from dawn to dusk."}
{"id": "2507.13795", "pdf": "https://arxiv.org/pdf/2507.13795", "abs": "https://arxiv.org/abs/2507.13795", "authors": ["Florian Grensing", "Vanessa Schmücker", "Anne Sophie Hildebrand", "Tim Klucken", "Maria Maleshkova"], "title": "Regression-Based Approach to Anxiety Estimation of Spider Phobics During Behavioural Avoidance Tasks", "categories": ["cs.HC", "I.2.6; J.3"], "comment": "9 Pages, 4 Figures (3 consisting of 3 subfigures each)", "summary": "Phobias significantly impact the quality of life of affected persons. Two\nmethods of assessing anxiety responses are questionnaires and behavioural\navoidance tests (BAT). While these can be used in a clinical environment they\nonly record momentary insights into anxiety measures. In this study, we\nestimate the intensity of anxiety during these BATs, using physiological data\ncollected from unobtrusive, wrist-worn sensors. Twenty-five participants\nperformed four different BATs in a single session, while periodically being\nasked how anxious they currently are. Using heart rate, heart rate variability,\nelectrodermal activity, and skin temperature, we trained regression models to\npredict anxiety ratings from three types of input data: (1) using only\nphysiological signals, (2) adding computed features (e.g., min, max, range,\nvariability), and (3) computed features combined with contextual task\ninformation. Adding contextual information increased the effectiveness of the\nmodel, leading to a root mean squared error (RMSE) of 0.197 and a mean absolute\nerror (MAE) of 0.041. Overall, this study shows, that data obtained from\nwearables can continuously provide meaningful estimations of anxiety, which can\nassist in therapy planning and enable more personalised treatment."}
{"id": "2507.13635", "pdf": "https://arxiv.org/pdf/2507.13635", "abs": "https://arxiv.org/abs/2507.13635", "authors": ["Nengkun Yu", "Jens Palsberg", "Thomas Reps"], "title": "SAQR-QC: A Logic for Scalable but Approximate Quantitative Reasoning about Quantum Circuits", "categories": ["quant-ph", "cs.LO", "cs.PL"], "comment": "Comments are welcome", "summary": "Reasoning about quantum programs remains a fundamental challenge, regardless\nof the programming model or computational paradigm. Despite extensive research,\nexisting verification techniques are insufficient--even for quantum circuits, a\ndeliberately restricted model that lacks classical control, but still underpins\nmany current quantum algorithms. Many existing formal methods require\nexponential time and space to represent and manipulate (representations of)\nassertions and judgments, making them impractical for quantum circuits with\nmany qubits. This paper presents a logic for reasoning in such settings, called\nSAQR-QC. The logic supports Scalable but Approximate Quantitative Reasoning\nabout Quantum Circuits, whence the name. SAQR-QC has three characteristics: (i)\nsome (deliberate) loss of precision is built into it; (ii) it has a mechanism\nto help the accumulated loss of precision during a sequence of reasoning steps\nremain small; and (iii) most importantly, to make reasoning scalable, all\nreasoning steps are local--i.e., they each involve just a small number of\nqubits. We demonstrate the effectiveness of SAQR-QC via two case studies: the\nverification of GHZ circuits involving non-Clifford gates, and the analysis of\nquantum phase estimation--a core subroutine in Shor's factoring algorithm."}
{"id": "2507.13660", "pdf": "https://arxiv.org/pdf/2507.13660", "abs": "https://arxiv.org/abs/2507.13660", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges", "Aileen Worden"], "title": "Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "Two user studies were performed to evaluate the effect of level-of-detail\n(LOD) degradation in the periphery of head-mounted displays on visual search\nperformance. In the first study, spatial detail was degraded by reducing\nresolution. In the second study, detail was degraded in the color domain by\nusing grayscale in the periphery. In each study, 10 subjects were given a\ncomplex search task that required users to indicate whether or not a target\nobject was present among distracters. Subjects used several different displays\nvarying in the amount of detail presented. Frame rate, object location, subject\ninput method, and order of display use were all controlled. The primary\ndependent measures were search time on correctly performed trials and the\npercentage of all trials correctly performed. Results indicated that peripheral\nLOD degradation can be used to reduce color or spatial visual complexity by\nalmost half in some search tasks with out significantly reducing performance."}
{"id": "2507.13505", "pdf": "https://arxiv.org/pdf/2507.13505", "abs": "https://arxiv.org/abs/2507.13505", "authors": ["Steven Lamp", "Jason D. Hiser", "Anh Nguyen-Tuong", "Jack W. Davidson"], "title": "PHASE: Passive Human Activity Simulation Evaluation", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "Cybersecurity simulation environments, such as cyber ranges, honeypots, and\nsandboxes, require realistic human behavior to be effective, yet no\nquantitative method exists to assess the behavioral fidelity of synthetic user\npersonas. This paper presents PHASE (Passive Human Activity Simulation\nEvaluation), a machine learning framework that analyzes Zeek connection logs\nand distinguishes human from non-human activity with over 90\\% accuracy. PHASE\noperates entirely passively, relying on standard network monitoring without any\nuser-side instrumentation or visible signs of surveillance. All network\nactivity used for machine learning is collected via a Zeek network appliance to\navoid introducing unnecessary network traffic or artifacts that could disrupt\nthe fidelity of the simulation environment. The paper also proposes a novel\nlabeling approach that utilizes local DNS records to classify network traffic,\nthereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley\nAdditive exPlanations) analysis to uncover temporal and behavioral signatures\nindicative of genuine human users. In a case study, we evaluate a synthetic\nuser persona and identify distinct non-human patterns that undermine behavioral\nrealism. Based on these insights, we develop a revised behavioral configuration\nthat significantly improves the human-likeness of synthetic activity yielding a\nmore realistic and effective synthetic user persona."}
{"id": "2507.14031", "pdf": "https://arxiv.org/pdf/2507.14031", "abs": "https://arxiv.org/abs/2507.14031", "authors": ["Hao Fang", "Sihao Teng", "Hao Yu", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "title": "QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography", "categories": ["cs.CV", "cs.ET", "cs.LG"], "comment": "10 pages, 12 figures", "summary": "Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside\nimaging modality with high temporal resolution, making it suitable for bedside\nmonitoring. However, its inherently ill-posed inverse problem poses significant\nchallenges for accurate image reconstruction. Deep learning (DL)-based\napproaches have shown promise but often rely on complex network architectures\nwith a large number of parameters, limiting efficiency and scalability. Here,\nwe propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework\nfor EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network\n(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive\nlatent representations that serve as implicit nonlinear priors, followed by a\nsingle linear layer for conductivity reconstruction. This design drastically\nreduces model complexity and parameter number. Uniquely, QuantEIT operates in\nan unsupervised, training-data-free manner and represents the first integration\nof quantum circuits into EIT image reconstruction. Extensive experiments on\nsimulated and real-world 2D and 3D EIT lung imaging data demonstrate that\nQuantEIT outperforms conventional methods, achieving comparable or superior\nreconstruction accuracy using only 0.2% of the parameters, with enhanced\nrobustness to noise."}
{"id": "2507.13470", "pdf": "https://arxiv.org/pdf/2507.13470", "abs": "https://arxiv.org/abs/2507.13470", "authors": ["Michael Elkin", "Chhaya Trehan"], "title": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication", "categories": ["cs.DS", "cs.DC"], "comment": null, "summary": "Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$\nof $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the\n$S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of\nvertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms\nrun BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$'s\ntransitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le\n2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known\nbound is $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$. Leveraging shortcut\nconstructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a\ncentralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3}\n\\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix\nmultiplication exponent. Using current estimates on $\\omega(\\sigma)$, our\nexponent improves upon $\\min \\{2 + \\sigma, \\omega \\}$ for $\\tilde \\sigma \\leq\n\\sigma \\leq 0.53$, where $1/3 < \\tilde \\sigma < 0.3336$ is a universal\nconstant.\n  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel\nalgorithms for $S \\times V$ reachability on graphs admitting balanced recursive\nseparators of size $n^{\\rho}$ for $\\rho < 1$, requiring polylogarithmic time\nand work $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$. We significantly\nimprove, extend, and generalize Cohen's result. First, our parallel algorithm\nfor graphs with small recursive separators has lower work complexity than\nCohen's in boraod paramater ranges. Second, we generalize our algorithm to\ngraphs of treewidth at most $n^{\\rho}$ ($\\rho < 1$) and provide a centralized\nalgorithm that outperforms existing bounds for $S \\times V$ reachability on\nsuch graphs. We also do this for some other graph familes with small\nseparators. Finally, we extend these results to $(1 + \\epsilon)$-approximate\ndistance computation."}
{"id": "2507.13746", "pdf": "https://arxiv.org/pdf/2507.13746", "abs": "https://arxiv.org/abs/2507.13746", "authors": ["Jim de Groot"], "title": "Intuitionistic monotone modal logic via translation", "categories": ["math.LO", "cs.LO"], "comment": null, "summary": "We introduce a monotone modal analogue of the intuitionistic (normal) modal\nlogic IK using a translation into a suitable (intuitionistic) first-order\nlogic. We axiomatise the logic and give a semantics by means of intuitionistic\nneighbourhood models, which contain neighbourhoods whose value can change when\nmoving along the intuitionistic accessibility relation. We compare the\nresulting logic with other intuitionistic monotone modal logics and show how it\ncan be embedded into a multimodal version of IK."}
{"id": "2507.13956", "pdf": "https://arxiv.org/pdf/2507.13956", "abs": "https://arxiv.org/abs/2507.13956", "authors": ["Yutao Jin", "Haowen Xiao", "Jielei Chu", "Fengmao Lv", "Yuxiao Li", "Tianrui Li"], "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "categories": ["cs.AI", "cs.CV", "cs.MM"], "comment": null, "summary": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's\nDisease (AD), where early identification and intervention can effectively slow\nthe progression to dementia. However, diagnosing AD remains a significant\nchallenge in neurology due to the confounders caused mainly by the selection\nbias of multimodal data and the complex relationships between variables. To\naddress these issues, we propose a novel visual-language causal intervention\nframework named Alzheimer's Disease Prediction with Cross-modal Causal\nIntervention (ADPC) for diagnostic assistance. Our ADPC employs large language\nmodel (LLM) to summarize clinical data under strict templates, maintaining\nstructured text outputs even with incomplete or unevenly distributed datasets.\nThe ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)\nimages and textual data generated by LLM to classify participants into\nCognitively Normal (CN), MCI, and AD categories. Because of the presence of\nconfounders, such as neuroimaging artifacts and age-related biomarkers,\nnon-causal models are likely to capture spurious input-output correlations,\ngenerating less reliable results. Our framework implicitly eliminates\nconfounders through causal intervention. Experimental results demonstrate the\noutstanding performance of our method in distinguishing CN/MCI/AD cases,\nachieving state-of-the-art (SOTA) metrics across most evaluation metrics. The\nstudy showcases the potential of integrating causal reasoning with multi-modal\nlearning for neurological disease diagnosis."}
{"id": "2507.13886", "pdf": "https://arxiv.org/pdf/2507.13886", "abs": "https://arxiv.org/abs/2507.13886", "authors": ["Anaïs Halin", "Marc Van Droogenbroeck", "Christel Devue"], "title": "Effects of Cognitive Distraction and Driving Environment Complexity on Adaptive Cruise Control Use and Its Impact on Driving Performance: A Simulator Study", "categories": ["cs.HC"], "comment": null, "summary": "In this simulator study, we adopt a human-centered approach to explore\nwhether and how drivers' cognitive state and driving environment complexity\ninfluence reliance on driving automation features. Besides, we examine whether\nsuch reliance affects driving performance. Participants operated a vehicle\nequipped with adaptive cruise control (ACC) in a simulator across six\npredefined driving scenarios varying in traffic conditions while either\nperforming a cognitively demanding task (i.e., responding to mental\ncalculations) or not. Throughout the experiment, participants had to respect\nspeed limits and were free to activate or deactivate ACC. In complex driving\nenvironments, we found that the overall ACC engagement time was lower compared\nto less complex driving environments. We observed no significant effect of\ncognitive load on ACC use. Furthermore, while ACC use had no effect on the\nnumber of lane changes, it impacted the speed limits compliance and improved\nlateral control."}
{"id": "2507.13624", "pdf": "https://arxiv.org/pdf/2507.13624", "abs": "https://arxiv.org/abs/2507.13624", "authors": ["Daniel Commey", "Kamel Abbad", "Garth V. Crosby", "Lyes Khoukhi"], "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Communication overhead remains a primary bottleneck in federated learning\n(FL), particularly for applications involving mobile and IoT devices with\nconstrained bandwidth. This work introduces FedSkipTwin, a novel\nclient-skipping algorithm driven by lightweight, server-side digital twins.\nEach twin, implemented as a simple LSTM, observes a client's historical\nsequence of gradient norms to forecast both the magnitude and the epistemic\nuncertainty of its next update. The server leverages these predictions,\nrequesting communication only when either value exceeds a predefined threshold;\notherwise, it instructs the client to skip the round, thereby saving bandwidth.\nExperiments are conducted on the UCI-HAR and MNIST datasets with 10 clients\nunder a non-IID data distribution. The results demonstrate that FedSkipTwin\nreduces total communication by 12-15.5% across 20 rounds while simultaneously\nimproving final model accuracy by up to 0.5 percentage points compared to the\nstandard FedAvg algorithm. These findings establish that prediction-guided\nskipping is a practical and effective strategy for resource-aware FL in\nbandwidth-constrained edge environments."}
{"id": "2507.14069", "pdf": "https://arxiv.org/pdf/2507.14069", "abs": "https://arxiv.org/abs/2507.14069", "authors": ["Shuiguang Deng", "Di Yu", "Changze Lv", "Xin Du", "Linshan Jiang", "Xiaofan Zhao", "Wentao Tong", "Xiaoqing Zheng", "Weijia Fang", "Peng Zhao", "Gang Pan", "Schahram Dustdar", "Albert Y. Zomaya"], "title": "Edge Intelligence with Spiking Neural Networks", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NE"], "comment": "This work has been submitted to Proceeding of IEEE for possible\n  publication", "summary": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence."}
{"id": "2507.13624", "pdf": "https://arxiv.org/pdf/2507.13624", "abs": "https://arxiv.org/abs/2507.13624", "authors": ["Daniel Commey", "Kamel Abbad", "Garth V. Crosby", "Lyes Khoukhi"], "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Communication overhead remains a primary bottleneck in federated learning\n(FL), particularly for applications involving mobile and IoT devices with\nconstrained bandwidth. This work introduces FedSkipTwin, a novel\nclient-skipping algorithm driven by lightweight, server-side digital twins.\nEach twin, implemented as a simple LSTM, observes a client's historical\nsequence of gradient norms to forecast both the magnitude and the epistemic\nuncertainty of its next update. The server leverages these predictions,\nrequesting communication only when either value exceeds a predefined threshold;\notherwise, it instructs the client to skip the round, thereby saving bandwidth.\nExperiments are conducted on the UCI-HAR and MNIST datasets with 10 clients\nunder a non-IID data distribution. The results demonstrate that FedSkipTwin\nreduces total communication by 12-15.5% across 20 rounds while simultaneously\nimproving final model accuracy by up to 0.5 percentage points compared to the\nstandard FedAvg algorithm. These findings establish that prediction-guided\nskipping is a practical and effective strategy for resource-aware FL in\nbandwidth-constrained edge environments."}
{"id": "2507.13774", "pdf": "https://arxiv.org/pdf/2507.13774", "abs": "https://arxiv.org/abs/2507.13774", "authors": ["Arthur Adjedj", "Meven Lennon-Bertrand", "Thibaut Benjamin", "Kenji Maillard"], "title": "AdapTT: Functoriality for Dependent Type Casts", "categories": ["cs.PL", "cs.LO", "D.3.1; F.3.2; F.4.1"], "comment": null, "summary": "The ability to cast values between related types is a leitmotiv of many\nflavors of dependent type theory, such as observational type theories,\nsubtyping, or cast calculi for gradual typing. These casts all exhibit a common\nstructural behavior that boils down to the pervasive functoriality of type\nformers. We propose and extensively study a type theory, called AdapTT, which\nmakes systematic and precise this idea of functorial type formers, with respect\nto an abstract notion of adapters relating types. Leveraging descriptions for\nfunctorial inductive types in AdapTT, we derive structural laws for type casts\non general inductive type formers."}
{"id": "2507.13923", "pdf": "https://arxiv.org/pdf/2507.13923", "abs": "https://arxiv.org/abs/2507.13923", "authors": ["Guillaume Rivière"], "title": "Initiating and Replicating the Observations of Interactional Properties by User Studies Optimizing Applicative Prototypes", "categories": ["cs.HC", "H.5.2"], "comment": "Written in French. 22 pages. Approximately 11700 words. 10 figures\n  and 6 tables", "summary": "The science of Human-Computer Interaction (HCI) is populated by isolated\nempirical findings, often tied to specific technologies, designs, and tasks.\nThis paper proposes a formalization of user interaction observations (instead\nof user interfaces) and an associated revealing method (interaction loop\ndiffraction). The resulting interactional properties that are studied in a\ncalibrated manner, are well suited to replication across various conditions\n(prototypes, technologies, tasks, and user profiles). In particular,\ninteractional properties can emerge and be replicated within the workflow of\napplicative cases, which in return benefit from the optimization of applicative\nprototypes. Applicative cases' publications will then contribute to\ndemonstrating technology utility, along with providing empirical results that\nwill lead future work to theory consolidation and theory building, and finally\nto a catalog and a science of relevant interactional properties. These\nproperties will contribute to better user interactions, especially for the\nvariety of ubiquitous user interfaces."}
{"id": "2507.13720", "pdf": "https://arxiv.org/pdf/2507.13720", "abs": "https://arxiv.org/abs/2507.13720", "authors": ["Saurav Ghosh"], "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "comment": "12 Pages, 4 figures", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era."}
{"id": "2507.14116", "pdf": "https://arxiv.org/pdf/2507.14116", "abs": "https://arxiv.org/abs/2507.14116", "authors": ["Daniëlle Schuman", "Mark V. Seebode", "Tobias Rohe", "Maximilian Balthasar Mansky", "Michael Schroedl-Baumann", "Jonas Stein", "Claudia Linnhoff-Popien", "Florian Krellner"], "title": "Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "12 pages, 5 figures (10 if counting subfigures), 2 tables. To be\n  published in the proceedings of the 2025 IEEE International Conference on\n  Quantum Computing and Engineering (QCE)", "summary": "Exploiting the fact that samples drawn from a quantum annealer inherently\nfollow a Boltzmann-like distribution, annealing-based Quantum Boltzmann\nMachines (QBMs) have gained increasing popularity in the quantum research\ncommunity. While they harbor great promises for quantum speed-up, their usage\ncurrently stays a costly endeavor, as large amounts of QPU time are required to\ntrain them. This limits their applicability in the NISQ era. Following the idea\nof No\\`e et al. (2024), who tried to alleviate this cost by incorporating\nparallel quantum annealing into their unsupervised training of QBMs, this paper\npresents an improved version of parallel quantum annealing that we employ to\ntrain QBMs in a supervised setting. Saving qubits to encode the inputs, the\nlatter setting allows us to test our approach on medical images from the\nMedMNIST data set (Yang et al., 2023), thereby moving closer to real-world\napplicability of the technology. Our experiments show that QBMs using our\napproach already achieve reasonable results, comparable to those of\nsimilarly-sized Convolutional Neural Networks (CNNs), with markedly smaller\nnumbers of epochs than these classical models. Our parallel annealing technique\nleads to a speed-up of almost 70 % compared to regular annealing-based BM\nexecutions."}
{"id": "2507.13720", "pdf": "https://arxiv.org/pdf/2507.13720", "abs": "https://arxiv.org/abs/2507.13720", "authors": ["Saurav Ghosh"], "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "comment": "12 Pages, 4 figures", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era."}
{"id": "2507.13958", "pdf": "https://arxiv.org/pdf/2507.13958", "abs": "https://arxiv.org/abs/2507.13958", "authors": ["Pedro Cabalar", "Martín Diéguez", "François Olivier", "Torsten Schaub", "Igor Stéphan"], "title": "Towards Constraint Temporal Answer Set Programming", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Reasoning about dynamic systems with a fine-grained temporal and numeric\nresolution presents significant challenges for logic-based approaches like\nAnswer Set Programming (ASP). To address this, we introduce and elaborate upon\na novel temporal and constraint-based extension of the logic of Here-and-There\nand its nonmonotonic equilibrium extension, representing, to the best of our\nknowledge, the first approach to nonmonotonic temporal reasoning with\nconstraints specifically tailored for ASP. This expressive system is achieved\nby a synergistic combination of two foundational ASP extensions: the\nlinear-time logic of Here-and-There, providing robust nonmonotonic temporal\nreasoning capabilities, and the logic of Here-and-There with constraints,\nenabling the direct integration and manipulation of numeric constraints, among\nothers. This work establishes the foundational logical framework for tackling\ncomplex dynamic systems with high resolution within the ASP paradigm."}
{"id": "2507.13951", "pdf": "https://arxiv.org/pdf/2507.13951", "abs": "https://arxiv.org/abs/2507.13951", "authors": ["Hamid Zand Miralvand", "Mohammad Ronagh Nikghalb", "Mohammad Darandeh", "Abidullah Khan", "Ian Arawjo", "Jinghui Cheng"], "title": "Democratizing Game Modding with GenAI: A Case Study of StarCharM, a Stardew Valley Character Maker", "categories": ["cs.HC"], "comment": "Accepted to CHI Play 2025, 35 pages, 4 figures", "summary": "Game modding offers unique and personalized gaming experiences, but the\ntechnical complexity of creating mods often limits participation to skilled\nusers. We envision a future where every player can create personalized mods for\ntheir games. To explore this space, we designed StarCharM, a GenAI-based\nnon-player character (NPC) creator for Stardew Valley. Our tool enables players\nto iteratively create new NPC mods, requiring minimal user input while allowing\nfor fine-grained adjustments through user control. We conducted a user study\nwith ten Stardew Valley players who had varied mod usage experiences to\nunderstand the impacts of StarCharM and provide insights into how GenAI tools\nmay reshape modding, particularly in NPC creation. Participants expressed\nexcitement in bringing their character ideas to life, although they noted\nchallenges in generating rich content to fulfill complex visions. While they\nbelieved GenAI tools like StarCharM can foster a more diverse modding\ncommunity, some voiced concerns about diminished originality and community\nengagement that may come with such technology. Our findings provided\nimplications and guidelines for the future of GenAI-powered modding tools and\nco-creative modding practices."}
{"id": "2507.13999", "pdf": "https://arxiv.org/pdf/2507.13999", "abs": "https://arxiv.org/abs/2507.13999", "authors": ["Sanidhay Bhambay", "Siddarth Koduru Joshi", "Thirupathaiah Vasantam", "Neil Walton"], "title": "The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks", "categories": ["quant-ph", "cs.NI", "cs.PF"], "comment": null, "summary": "We address the problem of optimal pumping strategies in quantum networks.\nThese networks enable secure communication by distributing entangled photon\npairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like\nBBM92, generate secret keys from entangled photons. While secure communication\nand error correction are essential for any quantum communication channel,\nresource contention, optimization, and fairness issues are critical for\nnetworks. In this article, we analyze the performance of quantum networks,\nproposing simple distributed algorithms for QKD networks generating secret\nkeys.\n  There are significant advantages of pumping entangled photons in QKD\nnetworks, but challenges arise in practical implementations. The underlying\nchannels are inherently time-varying, and thus data rates fluctuate between\nnodes. Moreover, multiple edges (node pairs) can be pumped simultaneously,\nalbeit at the cost of a reduced secret key rate (SKR). These temporal and\nspatial constraints yield a complex decision-making problem whose solutions may\nfavor a small set of user pairs to the detriment of overall, long-run network\nperformance.\n  We design adaptive pumping strategies that address these challenges in QKD\nnetworks. In particular, we find that a proportional fairness pumping strategy\n(PF-PS) stands out by dynamically prioritizing users with lower average secret\nkey rates and optimally balancing fairness with throughput. The proposed\nalgorithm is a natural extension to quantum networks of the Proportional Fair\nScheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis\nand numerical simulations confirm that PF-PS is optimal for entangled state\ndistribution, and thus, when adapted appropriately, proportional fair pumping\nis a strong candidate for efficient resource allocation in quantum networks."}
{"id": "2507.13736", "pdf": "https://arxiv.org/pdf/2507.13736", "abs": "https://arxiv.org/abs/2507.13736", "authors": ["Matthias Jobst", "Tim Langer", "Chen Liu", "Mehmet Alici", "Hector A. Gonzalez", "Christian Mayr"], "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": "Poster at ACM ICONS 2025 - International Conference on Neuromorphic\n  Systems", "summary": "This work presents a multi-layer DNN scheduling framework as an extension of\nOctopuScheduler, providing an end-to-end flow from PyTorch models to inference\non a single SpiNNaker2 chip. Together with a front-end comprised of\nquantization and lowering steps, the proposed framework enables the edge-based\nexecution of large and complex DNNs up to transformer scale using the\nneuromorphic platform SpiNNaker2."}
{"id": "2507.13952", "pdf": "https://arxiv.org/pdf/2507.13952", "abs": "https://arxiv.org/abs/2507.13952", "authors": ["Shayla Sharmin", "Roghayeh Leila Barmaki"], "title": "Estimating Cognitive Effort from Functional Near-Infrared Spectroscopy (fNIRS) Signals using Machine Learning", "categories": ["cs.HC"], "comment": "arXiv admin note: text overlap with arXiv:2504.13883", "summary": "The estimation of cognitive effort could potentially help educators to modify\nmaterial to enhance learning effectiveness and student engagement. Where\ncognitive load refers how much work the brain is doing while someone is\nlearning or doing a task cognitive effort consider both load and behavioral\nperformance. Cognitive effort can be captured by measuring oxygen flow and\nbehavioral performance during a task. This study infers cognitive effort\nmetrics using machine learning models based on oxygenated hemoglobin collected\nby using functional near-infrared spectroscopy from the prefrontal cortex\nduring an educational gameplay. In our study, sixteen participants responded to\nsixteen questions in an in-house Unity-based educational game. The quiz was\ndivided into two sessions, each session consisting of two task segments. We\nextracted temporal statistical and functional connectivity features from\ncollected oxygenated hemoglobin and analyzed their correlation with quiz\nperformance. We trained multiple machine learning models to predict quiz\nperformance from oxygenated hemoglobin features and achieved accuracies ranging\nfrom 58\\% to 67\\% accuracy. These predictions were used to calculate cognitive\neffort via relative neural involvement and efficiency, which consider both\nbrain activation and behavioral performance. Although quiz score predictions\nachieved moderate accuracy, the derived relative neural efficiency and\ninvolvement values remained robust. Since both metrics are based on the\nrelative positions of standardized brain activation and performance scores,\neven small misclassifications in predicted scores preserved the overall\ncognitive effort trends observed during gameplay."}
{"id": "2507.13895", "pdf": "https://arxiv.org/pdf/2507.13895", "abs": "https://arxiv.org/abs/2507.13895", "authors": ["Damiano Azzolini", "Marco Duca", "Stefano Forti", "Francesco Gallo", "Antonio Ielo"], "title": "Application Placement with Constraint Relaxation", "categories": ["cs.LO", "cs.DC"], "comment": null, "summary": "Novel utility computing paradigms rely upon the deployment of multi-service\napplications to pervasive and highly distributed cloud-edge infrastructure\nresources. Deciding onto which computational nodes to place services in\ncloud-edge networks, as per their functional and non-functional constraints,\ncan be formulated as a combinatorial optimisation problem. Most existing\nsolutions in this space are not able to deal with \\emph{unsatisfiable} problem\ninstances, nor preferences, i.e. requirements that DevOps may agree to relax to\nobtain a solution. In this article, we exploit Answer Set Programming\noptimisation capabilities to tackle this problem. Experimental results in\nsimulated settings show that our approach is effective on lifelike networks and\napplications."}
{"id": "2507.14034", "pdf": "https://arxiv.org/pdf/2507.14034", "abs": "https://arxiv.org/abs/2507.14034", "authors": ["Jochen Wulf", "Jurg Meierhofer", "Frank Hannich"], "title": "Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors", "categories": ["cs.HC"], "comment": null, "summary": "Agentic AI systems, powered by Large Language Models (LLMs), offer\ntransformative potential for value co-creation in technical services. However,\npersistent challenges like hallucinations and operational brittleness limit\ntheir autonomous use, creating a critical need for robust frameworks to guide\nhuman-AI collaboration. Drawing on established Human-AI teaming research and\nanalogies from fields like autonomous driving, this paper develops a structured\ntaxonomy of human-agent interaction. Based on case study research within\ntechnical support platforms, we propose a six-mode taxonomy that organizes\ncollaboration across a spectrum of AI autonomy. This spectrum is anchored by\nthe Human-Out-of-the-Loop (HOOTL) model for full automation and the\nHuman-Augmented Model (HAM) for passive AI assistance. Between these poles, the\nframework specifies four distinct intermediate structures. These include the\nHuman-in-Command (HIC) model, where AI proposals re-quire mandatory human\napproval, and the Human-in-the-Process (HITP) model for structured work-flows\nwith deterministic human tasks. The taxonomy further delineates the\nHuman-in-the-Loop (HITL) model, which facilitates agent-initiated escalation\nupon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables\ndiscretionary human oversight of an autonomous AI. The primary contribution of\nthis work is a comprehensive framework that connects this taxonomy to key\ncontingency factors -- such as task complexity, operational risk, and system\nreliability -- and their corresponding conceptual architectures. By providing a\nsystematic method for selecting and designing an appropriate level of human\noversight, our framework offers practitioners a crucial tool to navigate the\ntrade-offs between automation and control, thereby fostering the development of\nsafer, more effective, and context-aware technical service systems."}
{"id": "2507.14111", "pdf": "https://arxiv.org/pdf/2507.14111", "abs": "https://arxiv.org/abs/2507.14111", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "categories": ["cs.AI", "cs.DC", "cs.LG"], "comment": "Preprint Version", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources."}
{"id": "2507.14084", "pdf": "https://arxiv.org/pdf/2507.14084", "abs": "https://arxiv.org/abs/2507.14084", "authors": ["Maria Tsfasman", "Ramin Ghorbani", "Catholijn M. Jonker", "Bernd Dudzik"], "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Humans have a selective memory, remembering relevant episodes and forgetting\nthe less relevant information. Possessing awareness of event memorability for a\nuser could help intelligent systems in more accurate user modelling, especially\nfor such applications as meeting support systems, memory augmentation, and\nmeeting summarisation. Emotion recognition has been widely studied, since\nemotions are thought to signal moments of high personal relevance to users. The\nemotional experience of situations and their memorability have traditionally\nbeen considered to be closely tied to one another: moments that are experienced\nas highly emotional are considered to also be highly memorable. This\nrelationship suggests that emotional annotations could serve as proxies for\nmemorability. However, existing emotion recognition systems rely heavily on\nthird-party annotations, which may not accurately represent the first-person\nexperience of emotional relevance and memorability. This is why, in this study,\nwe empirically examine the relationship between perceived group emotions\n(Pleasure-Arousal) and group memorability in the context of conversational\ninteractions. Our investigation involves continuous time-based annotations of\nboth emotions and memorability in dynamic, unstructured group settings,\napproximating conditions of real-world conversational AI applications such as\nonline meeting support systems. Our results show that the observed relationship\nbetween affect and memorability annotations cannot be reliably distinguished\nfrom what might be expected under random chance. We discuss the implications of\nthis surprising finding for the development and applications of Affective\nComputing technology. In addition, we contextualise our findings in broader\ndiscourses in the Affective Computing and point out important targets for\nfuture research efforts."}
{"id": "2507.14114", "pdf": "https://arxiv.org/pdf/2507.14114", "abs": "https://arxiv.org/abs/2507.14114", "authors": ["Ahammed Ullah", "S. M. Ferdous", "Alex Pothen"], "title": "Weighted Matching in a Poly-Streaming Model", "categories": ["cs.DS", "cs.DC"], "comment": "40 pages, ESA 2025", "summary": "We introduce the poly-streaming model, a generalization of streaming models\nof computation in which $k$ processors process $k$ data streams containing a\ntotal of $N$ items. The algorithm is allowed $O\\left(f(k)\\cdot M_1\\right)$\nspace, where $M_1$ is either $o\\left(N\\right)$ or the space bound for a\nsequential streaming algorithm. Processors may communicate as needed.\nAlgorithms are assessed by the number of passes, per-item processing time,\ntotal runtime, space usage, communication cost, and solution quality.\n  We design a single-pass algorithm in this model for approximating the maximum\nweight matching (MWM) problem. Given $k$ edge streams and a parameter\n$\\varepsilon > 0$, the algorithm computes a\n$\\left(2+\\epsilon\\right)$-approximate MWM. We analyze its performance in a\nshared-memory parallel setting: for any constant $\\varepsilon > 0$, it runs in\ntime $\\widetilde{O}\\left(L_{\\max}+n\\right)$, where $n$ is the number of\nvertices and $L_{\\max}$ is the maximum stream length. It supports\n$O\\left(1\\right)$ per-edge processing time using $\\widetilde{O}\\left(k\\cdot\nn\\right)$ space. We further generalize the design to hierarchical\narchitectures, in which $k$ processors are partitioned into $r$ groups, each\nwith its own shared local memory. The total intergroup communication is\n$\\widetilde{O}\\left(r \\cdot n\\right)$ bits, while all other performance\nguarantees are preserved.\n  We evaluate the algorithm on a shared-memory system using graphs with\ntrillions of edges. It achieves substantial speedups as $k$ increases and\nproduces matchings with weights significantly exceeding the theoretical\nguarantee. On our largest test graph, it reduces runtime by nearly two orders\nof magnitude and memory usage by five orders of magnitude compared to an\noffline algorithm."}
{"id": "2507.13468", "pdf": "https://arxiv.org/pdf/2507.13468", "abs": "https://arxiv.org/abs/2507.13468", "authors": ["Shiye Cao", "Maia Stiber", "Amama Mahmood", "Maria Teresa Parreira", "Wendy Ju", "Micol Spitale", "Hatice Gunes", "Chien-Ming Huang"], "title": "ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "The integration of large language models (LLMs) into conversational robots\nhas made human-robot conversations more dynamic. Yet, LLM-powered\nconversational robots remain prone to errors, e.g., misunderstanding user\nintent, prematurely interrupting users, or failing to respond altogether.\nDetecting and addressing these failures is critical for preventing\nconversational breakdowns, avoiding task disruptions, and sustaining user\ntrust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal\ndataset of LLM-powered conversational robot failures during human-robot\nconversations and encourages researchers to benchmark machine learning models\ndesigned to detect robot failures. The dataset includes 16 hours of dyadic\nhuman-robot interactions, incorporating facial, speech, and head movement\nfeatures. Each interaction is annotated with the presence or absence of robot\nerrors from the system perspective, and perceived user intention to correct for\na mismatch between robot behavior and user expectation. Participants are\ninvited to form teams and develop machine learning models that detect these\nfailures using multimodal data. Submissions will be evaluated using various\nperformance metrics, including detection accuracy and false positive rate. This\nchallenge represents another key step toward improving failure detection in\nhuman-robot interaction through social signal analysis."}
{"id": "2507.13602", "pdf": "https://arxiv.org/pdf/2507.13602", "abs": "https://arxiv.org/abs/2507.13602", "authors": ["Shivakanth Sujit", "Luca Nunziante", "Dan Ogawa Lillrank", "Rousslan Fernand Julien Dossa", "Kai Arulkumaran"], "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force", "categories": ["cs.RO", "cs.HC", "cs.LG"], "comment": "Accepted at the 2025 IEEE/SICE International Symposium on System\n  Integration", "summary": "In this work we extend the low-cost GELLO teleoperation system, initially\ndesigned for joint position control, with additional force information. Our\nfirst extension is to implement force feedback, allowing users to feel\nresistance when interacting with the environment. Our second extension is to\nadd force information into the data collection process and training of\nimitation learning models. We validate our additions by implementing these on a\nGELLO system with a Franka Panda arm as the follower robot, performing a user\nstudy, and comparing the performance of policies trained with and without force\ninformation on a range of simulated and real dexterous manipulation tasks.\nQualitatively, users with robotics experience preferred our controller, and the\naddition of force inputs improved task success on the majority of tasks."}
{"id": "2507.13737", "pdf": "https://arxiv.org/pdf/2507.13737", "abs": "https://arxiv.org/abs/2507.13737", "authors": ["Ye Tian", "Xiaoyuan Ren", "Zihao Wang", "Onat Gungor", "Xiaofan Yu", "Tajana Rosing"], "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MM"], "comment": null, "summary": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed."}
{"id": "2507.13839", "pdf": "https://arxiv.org/pdf/2507.13839", "abs": "https://arxiv.org/abs/2507.13839", "authors": ["Lizhi Ma", "Tong Zhao", "Shuai Zhang", "Nirui Song", "Hongliang He", "Anqi Li", "Ran Feng", "Huachuan Qiu", "Jingsong Ma", "Zhenzhong Lan"], "title": "The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "This study explores the relationship between linguistic expressions and\npsychological states of depression and anxiety within Chinese psycho-counseling\ninteractions, focusing specifically on the usage of first-person singular\npronouns and negative emotional words. Utilizing a corpus derived from 735\nonline counseling sessions, the analysis employed a general linear mixed-effect\nmodel to assess linguistic patterns quantified by the Linguistic Inquiry and\nWord Count (LIWC) software. Results indicate a significant positive correlation\nbetween the frequency of negative emotional words and the severity of both\ndepressive and anxious states among clients. However, contrary to prior\nfindings predominantly derived from English-language contexts, the usage\nfrequency of first-person singular pronouns did not vary significantly with the\nclients' psychological conditions. These outcomes are discussed within the\nframework of cultural distinctions between collectivist Chinese contexts and\nindividualistic Western settings, as well as the interactive dynamics unique to\npsycho-counseling conversations. The findings highlight the nuanced influence\nof cultural and conversational contexts on language use in mental health\ncommunications, providing insights into psycholinguistic markers relevant to\ntherapeutic practices in Chinese-speaking populations."}
{"id": "2507.13919", "pdf": "https://arxiv.org/pdf/2507.13919", "abs": "https://arxiv.org/abs/2507.13919", "authors": ["Kobi Hackenburg", "Ben M. Tappin", "Luke Hewitt", "Ed Saunders", "Sid Black", "Hause Lin", "Catherine Fist", "Helen Margetts", "David G. Rand", "Christopher Summerfield"], "title": "The Levers of Political Persuasion with Conversational AI", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": "19 pages, 4 figures. Our supplementary materials file can be found at\n  https://github.com/kobihackenburg/scaling-conversational-AI", "summary": "There are widespread fears that conversational AI could soon exert\nunprecedented influence over human beliefs. Here, in three large-scale\nexperiments (N=76,977), we deployed 19 LLMs-including some post-trained\nexplicitly for persuasion-to evaluate their persuasiveness on 707 political\nissues. We then checked the factual accuracy of 466,769 resulting LLM claims.\nContrary to popular concerns, we show that the persuasive power of current and\nnear-future AI is likely to stem more from post-training and prompting\nmethods-which boosted persuasiveness by as much as 51% and 27%\nrespectively-than from personalization or increasing model scale. We further\nshow that these methods increased persuasion by exploiting LLMs' unique ability\nto rapidly access and strategically deploy information and that, strikingly,\nwhere they increased AI persuasiveness they also systematically decreased\nfactual accuracy."}
