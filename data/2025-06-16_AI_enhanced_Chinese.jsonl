{"id": "2506.10984", "pdf": "https://arxiv.org/pdf/2506.10984", "abs": "https://arxiv.org/abs/2506.10984", "authors": ["Ahilan Ayyachamy Nadar Ponnusamy"], "title": "Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "AI-assisted code generation tools have revolutionized software development,\noffering unprecedented efficiency and scalability. However, multiple studies\nhave consistently highlighted challenges such as security vulnerabilities,\nreliability issues, and inconsistencies in the generated code. Addressing these\nconcerns is crucial to unlocking the full potential of this transformative\ntechnology. While advancements in foundational and code-specialized language\nmodels have made notable progress in mitigating some of these issues,\nsignificant gaps remain, particularly in ensuring high-quality, trustworthy\noutputs.\n  This paper builds upon existing research on leveraging large language models\n(LLMs) for application modernization. It explores an opinionated approach that\nemphasizes two core capabilities of LLMs: code reasoning and code generation.\nThe proposed framework integrates these capabilities with human expertise to\ntackle application modernization challenges effectively. It highlights the\nindispensable role of human involvement and guidance in ensuring the success of\nAI-assisted processes.\n  To demonstrate the framework's utility, this paper presents a detailed case\nstudy, walking through its application in a real-world scenario. The analysis\nincludes a step-by-step breakdown, assessing alternative approaches where\napplicable. This work aims to provide actionable insights and a robust\nfoundation for future research in AI-driven application modernization. The\nreference implementation created for this paper is available on GitHub.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u8f85\u52a9\u4ee3\u7801\u751f\u6210\u5de5\u5177\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408LLM\u4ee3\u7801\u63a8\u7406\u4e0e\u751f\u6210\u80fd\u529b\u53ca\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7684\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3AI\u8f85\u52a9\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u3001\u53ef\u9760\u6027\u95ee\u9898\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u4ee5\u91ca\u653e\u5176\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408LLM\u7684\u4ee3\u7801\u63a8\u7406\u4e0e\u751f\u6210\u80fd\u529b\u53ca\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7684\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6846\u67b6\u5728\u5e94\u7528\u73b0\u4ee3\u5316\u4e2d\u7684\u5b9e\u9645\u6548\u7528\u3002", "conclusion": "\u5f3a\u8c03\u4eba\u7c7b\u53c2\u4e0e\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u6846\u67b6\u548c\u5b9e\u7528\u6d1e\u89c1\u3002"}}
{"id": "2506.10985", "pdf": "https://arxiv.org/pdf/2506.10985", "abs": "https://arxiv.org/abs/2506.10985", "authors": ["Raman Mohammed Hussein", "Bryar A. Hassan"], "title": "Collaboration Tools and their Role in Agile Software Projects", "categories": ["cs.SE"], "comment": "https://www.middleeastconference.org/_files/ugd/614b1f_82fa5f91169a44278723a921b27e2864.pdf\n  ISBN: 979-8-89695-015-8", "summary": "The purpose of this review is to understand the importance of collaboration\ntools which are Slack, Microsoft Teams, Confluence in Agile and software\nprojects. Agile methodologies rely on flexibility, using cycles and integration\nthroughout various levels of developing cycles. However, it is still a great\nproblem for many teams to collaborate and communicate even if staff members and\nteams are working remotely. In terms of collaboration, the applications and\ntechnologies mean better organization of work, increased mutually\nunderstandable openness and fast and efficient inter team and interpersonal\ninteractions to enhance results of projects into productivity. This paper\nexamines how these tools fit the Agile principles, how they facilitate\niterative development, and encouraging effective initiation and tracking of\ntasks in small and large projects. The insights focus on how Slack, Microsoft\nTeams, and Confluence are essential for gaining better task coordination,\nsupporting knowledge sharing, and adopting agile values across cross-functional\ncontexts.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u63a2\u8ba8\u4e86\u534f\u4f5c\u5de5\u5177\uff08\u5982Slack\u3001Microsoft Teams\u548cConfluence\uff09\u5728\u654f\u6377\u548c\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5f3a\u8c03\u4e86\u5b83\u4eec\u5982\u4f55\u4fc3\u8fdb\u56e2\u961f\u534f\u4f5c\u548c\u6c9f\u901a\u3002", "motivation": "\u7531\u4e8e\u56e2\u961f\u534f\u4f5c\u548c\u6c9f\u901a\u5728\u8fdc\u7a0b\u5de5\u4f5c\u4e2d\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u7814\u7a76\u8fd9\u4e9b\u5de5\u5177\u5982\u4f55\u652f\u6301\u654f\u6377\u65b9\u6cd5\u8bba\u7684\u5b9e\u65bd\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5206\u6790Slack\u3001Microsoft Teams\u548cConfluence\u5982\u4f55\u7b26\u5408\u654f\u6377\u539f\u5219\uff0c\u5e76\u4fc3\u8fdb\u8fed\u4ee3\u5f00\u53d1\u548c\u4efb\u52a1\u7ba1\u7406\u3002", "result": "\u8fd9\u4e9b\u5de5\u5177\u6539\u5584\u4e86\u4efb\u52a1\u534f\u8c03\u3001\u77e5\u8bc6\u5171\u4eab\uff0c\u5e76\u5e2e\u52a9\u56e2\u961f\u5728\u8de8\u804c\u80fd\u73af\u5883\u4e2d\u66f4\u597d\u5730\u91c7\u7528\u654f\u6377\u4ef7\u503c\u89c2\u3002", "conclusion": "\u534f\u4f5c\u5de5\u5177\u5bf9\u63d0\u5347\u654f\u6377\u9879\u76ee\u7684\u6548\u7387\u548c\u56e2\u961f\u534f\u4f5c\u5177\u6709\u663e\u8457\u4f5c\u7528\u3002"}}
{"id": "2506.10986", "pdf": "https://arxiv.org/pdf/2506.10986", "abs": "https://arxiv.org/abs/2506.10986", "authors": ["Mouna Dhaouadi", "Bentley James Oakes", "Michalis Famelis"], "title": "CoMRAT: Commit Message Rationale Analysis Tool", "categories": ["cs.SE"], "comment": null, "summary": "In collaborative open-source development, the rationale for code changes is\noften captured in commit messages, making them a rich source of valuable\ninformation. However, research on rationale in commit messages remains limited.\nIn this paper, we present CoMRAT, a tool for analyzing decision and rationale\nsentences rationale in commit messages. CoMRAT enables a) researchers to\nproduce metrics and analyses on rationale information in any Github module, and\nb) developers to check the amount of rationale in their commit messages. A\npreliminary evaluation suggests the tool's usefulness and usability in both\nthese research and development contexts.", "AI": {"tldr": "CoMRAT \u662f\u4e00\u6b3e\u7528\u4e8e\u5206\u6790\u63d0\u4ea4\u6d88\u606f\u4e2d\u51b3\u7b56\u548c\u7406\u7531\u53e5\u7684\u5de5\u5177\uff0c\u65e8\u5728\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u66f4\u597d\u5730\u7406\u89e3\u548c\u5229\u7528\u63d0\u4ea4\u6d88\u606f\u4e2d\u7684\u7406\u7531\u4fe1\u606f\u3002\u521d\u6b65\u8bc4\u4f30\u8868\u660e\u8be5\u5de5\u5177\u5728\u7814\u7a76\u4e0e\u5f00\u53d1\u4e2d\u5747\u6709\u5b9e\u7528\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "\u63d0\u4ea4\u6d88\u606f\u4e2d\u5e38\u5305\u542b\u4ee3\u7801\u53d8\u66f4\u7684\u7406\u7531\uff0c\u4f46\u5173\u4e8e\u8fd9\u4e00\u4e3b\u9898\u7684\u7814\u7a76\u5374\u8f83\u4e3a\u6709\u9650\u3002", "method": "\u5f00\u53d1\u4e86 CoMRAT \u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790 GitHub \u6a21\u5757\u4e2d\u63d0\u4ea4\u6d88\u606f\u4e2d\u7684\u7406\u7531\u4fe1\u606f\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u8868\u660e\u5de5\u5177\u5728\u7814\u7a76\uff08\u63d0\u4f9b\u6307\u6807\u548c\u5206\u6790\uff09\u548c\u5f00\u53d1\uff08\u68c0\u67e5\u63d0\u4ea4\u6d88\u606f\u4e2d\u7684\u7406\u7531\u91cf\uff09\u4e2d\u5747\u6709\u7528\u3002", "conclusion": "CoMRAT \u4e3a\u7814\u7a76\u63d0\u4ea4\u6d88\u606f\u4e2d\u7684\u7406\u7531\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u6f5c\u5728\u4ef7\u503c\u3002"}}
{"id": "2506.10987", "pdf": "https://arxiv.org/pdf/2506.10987", "abs": "https://arxiv.org/abs/2506.10987", "authors": ["Shaoyi Yang"], "title": "Chain of Draft for Software Engineering: Challenges in Applying Concise Reasoning to Code Tasks", "categories": ["cs.SE"], "comment": null, "summary": "Large language models (LLMs) have become vital tools for software\ndevelopment, but they often require verbose intermediate reasoning for complex\ncode tasks, leading to high latency and costs. This research extends the Chain\nof Draft (CoD) method to software engineering, designing and evaluating\nmultiple CoD variants tailored for code tasks. Through comprehensive\nexperiments on all 300 samples from the SWE-bench benchmark, we found that all\nCoD variants used significantly fewer tokens than Chain of Thought (CoT), with\nBaseline CoD being most efficient at 55.4% of CoT's tokens. While this\nrepresents substantial efficiency gains - translating to approximately 45%\nreduction in processing time and API costs - it differs from the extreme 7.6%\nreported in the original CoD paper for mathematical reasoning. This difference\nstems from the inherent complexity and context-dependency of software tasks,\nwhich require more detailed reasoning to maintain solution quality. Our\nmulti-dimensional quality assessment revealed that CoD variants maintain over\n90% of CoT's code quality across key metrics including correctness,\ncompatibility, and maintainability, making them practical alternatives for\nreal-world development scenarios where efficiency matters. This research\ndemonstrates how domain-specific characteristics influence prompting strategy\neffectiveness and provides a framework for balancing efficiency with solution\nquality in software engineering applications. Our findings offer practical\nguidance for optimizing LLM-based development workflows through appropriate\nprompting strategy selection based on project requirements.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06Chain of Draft\uff08CoD\uff09\u65b9\u6cd5\u6269\u5c55\u5230\u8f6f\u4ef6\u5de5\u7a0b\uff0c\u53d1\u73b0CoD\u53d8\u4f53\u5728\u4ee3\u7801\u4efb\u52a1\u4e2d\u4f7f\u7528\u6bd4Chain of Thought\uff08CoT\uff09\u66f4\u5c11\u7684\u4ee4\u724c\u6570\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e8690%\u4ee5\u4e0a\u7684\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u590d\u6742\u4ee3\u7801\u4efb\u52a1\u9700\u8981\u5197\u957f\u7684\u4e2d\u95f4\u63a8\u7406\uff0c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u6210\u672c\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7CoD\u65b9\u6cd5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u548c\u8bc4\u4f30\u4e86\u9488\u5bf9\u4ee3\u7801\u4efb\u52a1\u7684\u591a\u79cdCoD\u53d8\u4f53\uff0c\u5e76\u5728SWE-bench\u7684300\u4e2a\u6837\u672c\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86CoD\u4e0eCoT\u7684\u6027\u80fd\u3002", "result": "CoD\u53d8\u4f53\u4f7f\u7528\u663e\u8457\u5c11\u4e8eCoT\u7684\u4ee4\u724c\u6570\uff08Baseline CoD\u4ec5\u536055.4%\uff09\uff0c\u6548\u7387\u63d0\u5347\u7ea6\u4e3a45%\uff0c\u540c\u65f6\u4ee3\u7801\u8d28\u91cf\u4fdd\u6301\u572890%\u4ee5\u4e0a\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u9886\u57df\u7279\u5b9a\u7279\u6027\u4f1a\u5f71\u54cd\u63d0\u793a\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u7528\u63d0\u4f9b\u5e73\u8861\u6548\u7387\u4e0e\u8d28\u91cf\u7684\u6846\u67b6\uff0c\u4f18\u5316\u57fa\u4e8eLLM\u7684\u5f00\u53d1\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2506.11017", "pdf": "https://arxiv.org/pdf/2506.11017", "abs": "https://arxiv.org/abs/2506.11017", "authors": ["Yanyan Wang", "Yingying Wang", "Junli Liang", "Yin Xu", "Yunlong Liu", "Yiming Xu", "Zhengwang Jiang", "Zhehe Li", "Fei Li", "Long Zhao", "Kuang Xu", "Qi Song", "Xiangyang Li"], "title": "TeleEval-OS: Performance evaluations of large language models for operations scheduling", "categories": ["cs.CL", "cs.AI", "cs.PF"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has significantly\npropelled progress in artificial intelligence, demonstrating substantial\napplication potential across multiple specialized domains. Telecommunications\noperation scheduling (OS) is a critical aspect of the telecommunications\nindustry, involving the coordinated management of networks, services, risks,\nand human resources to optimize production scheduling and ensure unified\nservice control. However, the inherent complexity and domain-specific nature of\nOS tasks, coupled with the absence of comprehensive evaluation benchmarks, have\nhindered thorough exploration of LLMs' application potential in this critical\nfield. To address this research gap, we propose the first Telecommunications\nOperation Scheduling Evaluation Benchmark (TeleEval-OS). Specifically, this\nbenchmark comprises 15 datasets across 13 subtasks, comprehensively simulating\nfour key operational stages: intelligent ticket creation, intelligent ticket\nhandling, intelligent ticket closure, and intelligent evaluation. To\nsystematically assess the performance of LLMs on tasks of varying complexity,\nwe categorize their capabilities in telecommunications operation scheduling\ninto four hierarchical levels, arranged in ascending order of difficulty: basic\nNLP, knowledge Q&A, report generation, and report analysis. On TeleEval-OS, we\nleverage zero-shot and few-shot evaluation methods to comprehensively assess 10\nopen-source LLMs (e.g., DeepSeek-V3) and 4 closed-source LLMs (e.g., GPT-4o)\nacross diverse scenarios. Experimental results demonstrate that open-source\nLLMs can outperform closed-source LLMs in specific scenarios, highlighting\ntheir significant potential and value in the field of telecommunications\noperation scheduling.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7535\u4fe1\u8fd0\u8425\u8c03\u5ea6\u8bc4\u4f30\u57fa\u51c6\uff08TeleEval-OS\uff09\uff0c\u5305\u542b15\u4e2a\u6570\u636e\u96c6\u548c13\u4e2a\u5b50\u4efb\u52a1\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u4fe1\u9886\u57df\u7684\u6f5c\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f00\u6e90\u6a21\u578b\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u53ef\u4f18\u4e8e\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u7535\u4fe1\u8fd0\u8425\u8c03\u5ea6\u7684\u590d\u6742\u6027\u548c\u7f3a\u4e4f\u8bc4\u4f30\u57fa\u51c6\u9650\u5236\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u63d0\u51faTeleEval-OS\u57fa\u51c6\uff0c\u6db5\u76d6\u56db\u4e2a\u5173\u952e\u64cd\u4f5c\u9636\u6bb5\uff0c\u5e76\u901a\u8fc7\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u65b9\u6cd5\u8bc4\u4f3014\u79cd\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "TeleEval-OS\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u4fe1\u8fd0\u8425\u8c03\u5ea6\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u8bc4\u4f30\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5f00\u6e90\u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.11036", "pdf": "https://arxiv.org/pdf/2506.11036", "abs": "https://arxiv.org/abs/2506.11036", "authors": ["Yang Qin", "Chao Chen", "Zhihang Fu", "Dezhong Peng", "Xi Peng", "Peng Hu"], "title": "Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "Despite remarkable advancements in text-to-image person re-identification\n(TIReID) facilitated by the breakthrough of cross-modal embedding models,\nexisting methods often struggle to distinguish challenging candidate images due\nto intrinsic limitations, such as network architecture and data quality. To\naddress these issues, we propose an Interactive Cross-modal Learning framework\n(ICL), which leverages human-centered interaction to enhance the\ndiscriminability of text queries through external multimodal knowledge. To\nachieve this, we propose a plug-and-play Test-time Humane-centered Interaction\n(THI) module, which performs visual question answering focused on human\ncharacteristics, facilitating multi-round interactions with a multimodal large\nlanguage model (MLLM) to align query intent with latent target images.\nSpecifically, THI refines user queries based on the MLLM responses to reduce\nthe gap to the best-matching images, thereby boosting ranking accuracy.\nAdditionally, to address the limitation of low-quality training texts, we\nintroduce a novel Reorganization Data Augmentation (RDA) strategy based on\ninformation enrichment and diversity enhancement to enhance query\ndiscriminability by enriching, decomposing, and reorganizing person\ndescriptions. Extensive experiments on four TIReID benchmarks, i.e.,\nCUHK-PEDES, ICFG-PEDES, RSTPReid, and UFine6926, demonstrate that our method\nachieves remarkable performance with substantial improvement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u4e92\u5f0f\u8de8\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff08ICL\uff09\uff0c\u901a\u8fc7\u4eba\u673a\u4ea4\u4e92\u548c\u591a\u6a21\u6001\u5b66\u4e60\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u4eba\u7269\u91cd\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5f15\u5165\u6570\u636e\u589e\u5f3a\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u6587\u672c\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u4eba\u7269\u91cd\u8bc6\u522b\u65b9\u6cd5\u56e0\u7f51\u7edc\u7ed3\u6784\u548c\u6570\u636e\u8d28\u91cf\u7684\u9650\u5236\uff0c\u96be\u4ee5\u533a\u5206\u590d\u6742\u5019\u9009\u56fe\u50cf\uff0c\u9700\u901a\u8fc7\u4ea4\u4e92\u548c\u591a\u6a21\u6001\u77e5\u8bc6\u589e\u5f3a\u67e5\u8be2\u610f\u56fe\u5bf9\u9f50\u3002", "method": "\u63d0\u51faICL\u6846\u67b6\uff0c\u5305\u542bTest-time Humane-centered Interaction\uff08THI\uff09\u6a21\u5757\u548c\u591a\u8f6e\u4ea4\u4e92\u7684MLLM\u6a21\u578b\uff0c\u4ee5\u53caReorganization Data Augmentation\uff08RDA\uff09\u6570\u636e\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "ICL\u901a\u8fc7\u4ea4\u4e92\u548c\u6570\u636e\u589e\u5f3a\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u5230\u56fe\u50cf\u4eba\u7269\u91cd\u8bc6\u522b\u7684\u6548\u679c\u3002"}}
{"id": "2506.11209", "pdf": "https://arxiv.org/pdf/2506.11209", "abs": "https://arxiv.org/abs/2506.11209", "authors": ["Zhengyang Liu", "Vinod Grover"], "title": "A Performance Model for Warp Specialization Kernels", "categories": ["cs.PL"], "comment": null, "summary": "This paper presents a performance model tailored for warp specialization\nkernels, focusing on factors such as warp size, tilling size, input matrix\nsize, memory bandwidth, and thread divergence. Our model offers accurate\npredictions of execution time by leveraging differential equations validated\nthrough simulations and experiments. The insights gained from this model not\nonly enhance our understanding of warp specialization techniques but also have\npractical implications for optimizing GPU-accelerated applications through\ncompiler optimizations, kernel parameter tuning, and algorithm design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9warp specialization kernels\u7684\u6027\u80fd\u6a21\u578b\uff0c\u901a\u8fc7\u5fae\u5206\u65b9\u7a0b\u51c6\u786e\u9884\u6d4b\u6267\u884c\u65f6\u95f4\uff0c\u5bf9GPU\u52a0\u901f\u5e94\u7528\u4f18\u5316\u6709\u5b9e\u9645\u610f\u4e49\u3002", "motivation": "\u65e8\u5728\u7406\u89e3\u548c\u4f18\u5316warp specialization\u6280\u672f\u5728GPU\u52a0\u901f\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u5347\u6267\u884c\u6548\u7387\u3002", "method": "\u5229\u7528\u5fae\u5206\u65b9\u7a0b\u5e76\u7ed3\u5408\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5206\u6790warp\u5927\u5c0f\u3001tilling\u5927\u5c0f\u7b49\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u6a21\u578b\u80fd\u51c6\u786e\u9884\u6d4b\u6267\u884c\u65f6\u95f4\uff0c\u4e3a\u7f16\u8bd1\u5668\u4f18\u5316\u3001\u53c2\u6570\u8c03\u6574\u548c\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4f9d\u636e\u3002", "conclusion": "\u6a21\u578b\u4e0d\u4ec5\u6df1\u5316\u4e86\u5bf9warp specialization\u7684\u7406\u89e3\uff0c\u8fd8\u4e3aGPU\u5e94\u7528\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.11319", "pdf": "https://arxiv.org/pdf/2506.11319", "abs": "https://arxiv.org/abs/2506.11319", "authors": ["Adel Chehade", "Edoardo Ragusa", "Paolo Gastaldo", "Rodolfo Zunino"], "title": "Efficient Traffic Classification using HW-NAS: Advanced Analysis and Optimization for Cybersecurity on Resource-Constrained Devices", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "This paper presents a hardware-efficient deep neural network (DNN), optimized\nthrough hardware-aware neural architecture search (HW-NAS); the DNN supports\nthe classification of session-level encrypted traffic on resource-constrained\nInternet of Things (IoT) and edge devices. Thanks to HW-NAS, a 1D convolutional\nneural network (CNN) is tailored on the ISCX VPN-nonVPN dataset to meet strict\nmemory and computational limits while achieving robust performance. The\noptimized model attains an accuracy of 96.59% with just 88.26K parameters,\n10.08M FLOPs, and a maximum tensor size of 20.12K. Compared to state-of-the-art\nmodels, it achieves reductions of up to 444-fold, 312-fold, and 15.6-fold in\nthese metrics, respectively, significantly minimizing memory footprint and\nruntime requirements. The model also demonstrates versatility in classification\ntasks, achieving accuracies of up to 99.64% in VPN differentiation, VPN-type\nclassification, broader traffic categories, and application identification. In\naddition, an in-depth approach to header-level preprocessing strategies\nconfirms that the optimized model can provide notable performances across a\nwide range of configurations, even in scenarios with stricter privacy\nconsiderations. Likewise, a reduction in the length of sessions of up to 75%\nyields significant improvements in efficiency, while maintaining high accuracy\nwith only a negligible drop of 1-2%. However, the importance of careful\npreprocessing and session length selection in the classification of raw traffic\ndata is still present, as improper settings or aggressive reductions can bring\nabout a 7% reduction in overall accuracy. Those results highlight the method's\neffectiveness in enforcing cybersecurity for IoT networks, by providing\nscalable, efficient solutions for the real-time analysis of encrypted traffic\nwithin strict hardware limitations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u9ad8\u6548\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\uff0c\u901a\u8fc7\u786c\u4ef6\u611f\u77e5\u7684\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08HW-NAS\uff09\u4f18\u5316\uff0c\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\uff08IoT\uff09\u548c\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u52a0\u5bc6\u6d41\u91cf\u5206\u7c7b\u3002\u4f18\u5316\u76841D CNN\u6a21\u578b\u5728ISCX VPN-nonVPN\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\u5927\u5e45\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u7684IoT\u548c\u8fb9\u7f18\u8bbe\u5907\uff0c\u8bbe\u8ba1\u4e00\u79cd\u786c\u4ef6\u9ad8\u6548\u7684DNN\u6a21\u578b\uff0c\u4ee5\u652f\u6301\u52a0\u5bc6\u6d41\u91cf\u5206\u7c7b\uff0c\u4ece\u800c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u5185\u5b58\u548c\u8ba1\u7b97\u8d44\u6e90\u5360\u7528\u3002", "method": "\u91c7\u7528\u786c\u4ef6\u611f\u77e5\u7684\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08HW-NAS\uff09\u4f18\u53161D CNN\u6a21\u578b\uff0c\u5bf9ISCX VPN-nonVPN\u6570\u636e\u96c6\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u9884\u5904\u7406\u7b56\u7565\u548c\u4f1a\u8bdd\u957f\u5ea6\u8c03\u6574\u63d0\u5347\u6548\u7387\u3002", "result": "\u4f18\u5316\u6a21\u578b\u5b9e\u73b0\u4e8696.59%\u7684\u51c6\u786e\u7387\uff0c\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\u5927\u5e45\u51cf\u5c11\uff08\u6700\u591a\u5206\u522b\u51cf\u5c11444\u500d\u548c312\u500d\uff09\uff0c\u540c\u65f6\u5728\u591a\u79cd\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff08\u5982VPN\u5206\u7c7b\u51c6\u786e\u7387\u8fbe99.64%\uff09\u3002\u9884\u5904\u7406\u548c\u4f1a\u8bdd\u957f\u5ea6\u8c03\u6574\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aIoT\u7f51\u7edc\u4e2d\u7684\u52a0\u5bc6\u6d41\u91cf\u5b9e\u65f6\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9884\u5904\u7406\u548c\u4f1a\u8bdd\u957f\u5ea6\u9009\u62e9\u4ecd\u9700\u8c28\u614e\uff0c\u4ee5\u907f\u514d\u6027\u80fd\u635f\u5931\u3002"}}
{"id": "2506.11517", "pdf": "https://arxiv.org/pdf/2506.11517", "abs": "https://arxiv.org/abs/2506.11517", "authors": ["Roberto Gorrieri", "Ivan Lanese"], "title": "Decidable Reversible Equivalences for Finite Petri Nets", "categories": ["cs.LO", "68Q85", "F.1.1; D.2.4; F.3.1"], "comment": "arXiv admin note: text overlap with arXiv:2305.04222", "summary": "In the setting of Petri nets, we prove that {\\em causal-net bisimilarity}\n\\cite{G15,Gor22,Gor25a}, which is a refinement of history-preserving\nbisimilarity \\cite{RT88,vGG89,DDM89}, and the novel {\\em hereditary} causal-net\nbisimilarity, which is a refinement of hereditary history-preserving\nbisimilarity \\cite{Bed91,JNW96}, do coincide. This means that causal-net\nbisimilarity is a {\\em reversible behavioral equivalence}, as causal-net\nbisimilar markings not only are able to match each other's forward transitions,\nbut also backward transitions by undoing performed events. Causal-net\nbisimilarity can be equivalently formulated as {\\em structure-preserving\nbisimilarity} \\cite{G15,Gor25a}, that is decidable on finite bounded Petri nets\n\\cite{CG21a}. Moreover, place bisimilarity \\cite{ABS91}, that we prove to be\nfiner than causal-net bisimilarity, is also reversible and it was proved\ndecidable for finite Petri nets in \\cite{Gor21decid,Gor25a}. These results\noffer two decidable reversible behavioral equivalences in the true concurrency\nspectrum, which are alternative to the coarser hereditary history-preserving\nbisimilarity \\cite{Bed91,JNW96}, that, unfortunately, is undecidable even for\nsafe Petri nets \\cite{JNS03}.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86\u56e0\u679c\u7f51\u53cc\u6a21\u62df\u548c\u9057\u4f20\u56e0\u679c\u7f51\u53cc\u6a21\u62df\u7684\u7b49\u4ef7\u6027\uff0c\u5c55\u793a\u5176\u53ef\u9006\u884c\u4e3a\u7b49\u4ef7\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u79cd\u53ef\u5224\u5b9a\u7684\u5e76\u53d1\u884c\u4e3a\u7b49\u4ef7\u6027\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u76ee\u6807\u662f\u9a8c\u8bc1\u56e0\u679c\u7f51\u53cc\u6a21\u62df\u7684\u53ef\u9006\u6027\uff0c\u5e76\u63d0\u4f9b\u53ef\u5224\u5b9a\u7684\u5e76\u53d1\u884c\u4e3a\u7b49\u4ef7\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u5f25\u8865\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\u7f3a\u9677\u3002", "method": "\u901a\u8fc7\u5728Petri\u7f51\u4e2d\u5206\u6790\u56e0\u679c\u7f51\u53cc\u6a21\u62df\u4e0e\u7ed3\u6784\u4fdd\u6301\u53cc\u6a21\u62df\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u7ed3\u5408\u5df2\u6709\u7684\u53cc\u6a21\u62df\u7406\u8bba\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u8bc1\u660e\u56e0\u679c\u7f51\u53cc\u6a21\u62df\u662f\u53ef\u9006\u7684\u884c\u4e3a\u7b49\u4ef7\u6027\uff0c\u4e14\u5728\u6709\u9650\u6709\u754cPetri\u7f51\u4e0a\u662f\u53ef\u5224\u5b9a\u7684\uff1b\u540c\u65f6\u9a8c\u8bc1\u4e86\u4f4d\u7f6e\u53cc\u6a21\u62df\u7684\u53ef\u5224\u5b9a\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e24\u79cd\u53ef\u5224\u5b9a\u7684\u5e76\u53d1\u884c\u4e3a\u7b49\u4ef7\u6027\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4e86\u4e0d\u53ef\u5224\u5b9a\u7684\u9057\u4f20\u5386\u53f2\u4fdd\u6301\u53cc\u6a21\u62df\uff0c\u62d3\u5c55\u4e86Petri\u7f51\u7684\u884c\u4e3a\u7b49\u4ef7\u6027\u7406\u8bba\u3002"}}
{"id": "2506.11252", "pdf": "https://arxiv.org/pdf/2506.11252", "abs": "https://arxiv.org/abs/2506.11252", "authors": ["Mae Younes", "Adnane Boukhayma"], "title": "Anti-Aliased 2D Gaussian Splatting", "categories": ["cs.GR", "cs.CV"], "comment": "Code will be available at https://github.com/maeyounes/AA-2DGS", "summary": "2D Gaussian Splatting (2DGS) has recently emerged as a promising method for\nnovel view synthesis and surface reconstruction, offering better\nview-consistency and geometric accuracy than volumetric 3DGS. However, 2DGS\nsuffers from severe aliasing artifacts when rendering at different sampling\nrates than those used during training, limiting its practical applications in\nscenarios requiring camera zoom or varying fields of view. We identify that\nthese artifacts stem from two key limitations: the lack of frequency\nconstraints in the representation and an ineffective screen-space clamping\napproach. To address these issues, we present AA-2DGS, an antialiased\nformulation of 2D Gaussian Splatting that maintains its geometric benefits\nwhile significantly enhancing rendering quality across different scales. Our\nmethod introduces a world space flat smoothing kernel that constrains the\nfrequency content of 2D Gaussian primitives based on the maximal sampling\nfrequency from training views, effectively eliminating high-frequency artifacts\nwhen zooming in. Additionally, we derive a novel object space Mip filter by\nleveraging an affine approximation of the ray-splat intersection mapping, which\nallows us to efficiently apply proper anti-aliasing directly in the local space\nof each splat.", "AI": {"tldr": "AA-2DGS\u6539\u8fdb2D\u9ad8\u65af\u6e85\u5c04\u65b9\u6cd5\uff0c\u89e3\u51b3\u591a\u5c3a\u5ea6\u6e32\u67d3\u4e2d\u7684\u8d70\u6837\u95ee\u9898\uff0c\u63d0\u5347\u6e32\u67d3\u8d28\u91cf\u3002", "motivation": "2DGS\u5728\u591a\u5c3a\u5ea6\u6e32\u67d3\u4e2d\u56e0\u7f3a\u4e4f\u9891\u7387\u7ea6\u675f\u548c\u65e0\u6548\u7684\u5c4f\u5e55\u7a7a\u95f4\u5939\u7d27\u65b9\u6cd5\u800c\u51fa\u73b0\u8d70\u6837\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e16\u754c\u7a7a\u95f4\u5e73\u6ed1\u6838\u548c\u5bf9\u8c61\u7a7a\u95f4Mip\u6ee4\u6ce2\u5668\u6765\u7ea6\u675f\u9891\u7387\u5185\u5bb9\u5e76\u6d88\u9664\u9ad8\u9891\u4f2a\u5f71\u3002", "result": "AA-2DGS\u5728\u4fdd\u6301\u51e0\u4f55\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u591a\u5c3a\u5ea6\u6e32\u67d3\u8d28\u91cf\u3002", "conclusion": "AA-2DGS\u6709\u6548\u89e3\u51b3\u4e862DGS\u7684\u8d70\u6837\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.11565", "pdf": "https://arxiv.org/pdf/2506.11565", "abs": "https://arxiv.org/abs/2506.11565", "authors": ["Jinzhe Jiang", "Yaqian Zhao", "Xin Zhang", "Chen Li", "Yunlong Yu", "Hailing Liu"], "title": "Gradients of unitary optical neural networks using parameter-shift rule", "categories": ["cs.ET", "cs.LG", "physics.optics"], "comment": "8 pages, 3 figures", "summary": "This paper explores the application of the parameter-shift rule (PSR) for\ncomputing gradients in unitary optical neural networks (UONNs). While\nbackpropagation has been fundamental to training conventional neural networks,\nits implementation in optical neural networks faces significant challenges due\nto the physical constraints of optical systems. We demonstrate how PSR, which\ncalculates gradients by evaluating functions at shifted parameter values, can\nbe effectively adapted for training UONNs constructed from Mach-Zehnder\ninterferometer meshes. The method leverages the inherent Fourier series nature\nof optical interference in these systems to compute exact analytical gradients\ndirectly from hardware measurements. This approach offers a promising\nalternative to traditional in silico training methods and circumvents the\nlimitations of both finite difference approximations and all-optical\nbackpropagation implementations. We present the theoretical framework and\npractical methodology for applying PSR to optimize phase parameters in optical\nneural networks, potentially advancing the development of efficient\nhardware-based training strategies for optical computing systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53c2\u6570\u504f\u79fb\u89c4\u5219\uff08PSR\uff09\u5728\u9149\u5149\u5b66\u795e\u7ecf\u7f51\u7edc\uff08UONN\uff09\u4e2d\u8ba1\u7b97\u68af\u5ea6\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u514b\u670d\u5149\u5b66\u7cfb\u7edf\u7269\u7406\u9650\u5236\u7684\u6709\u6548\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u53cd\u5411\u4f20\u64ad\u5728\u5149\u5b66\u795e\u7ecf\u7f51\u7edc\u4e2d\u5b9e\u73b0\u56f0\u96be\uff0cPSR\u4e3a\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8c03\u6574\u53c2\u6570\u503c\u8ba1\u7b97\u68af\u5ea6\uff0c\u5229\u7528\u9a6c\u8d6b-\u66fe\u5fb7\u5c14\u5e72\u6d89\u4eea\u7f51\u683c\u6784\u5efaUONN\uff0c\u76f4\u63a5\u4ece\u786c\u4ef6\u6d4b\u91cf\u4e2d\u83b7\u53d6\u7cbe\u786e\u89e3\u6790\u68af\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u6709\u9650\u5dee\u5206\u8fd1\u4f3c\u548c\u5168\u5149\u5b66\u53cd\u5411\u4f20\u64ad\u7684\u9650\u5236\uff0c\u4e3a\u5149\u5b66\u8ba1\u7b97\u7cfb\u7edf\u7684\u9ad8\u6548\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "conclusion": "PSR\u4e3a\u5149\u5b66\u795e\u7ecf\u7f51\u7edc\u7684\u786c\u4ef6\u8bad\u7ec3\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\uff0c\u6709\u671b\u63a8\u52a8\u5149\u5b66\u8ba1\u7b97\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.11276", "pdf": "https://arxiv.org/pdf/2506.11276", "abs": "https://arxiv.org/abs/2506.11276", "authors": ["Yijun Liu", "Frederick Choi", "Eshwar Chandrasekharan"], "title": "Needling Through the Threads: A Visualization Tool for Navigating Threaded Online Discussions", "categories": ["cs.HC"], "comment": null, "summary": "Navigating large-scale online discussions is difficult due to the rapid pace\nand large volume of user-generated content. Prior work in CSCW has shown that\nmoderators often struggle to follow multiple simultaneous discussions, track\nevolving conversations, and maintain contextual understanding--all of which\nhinder timely and effective moderation. While platforms like Reddit use\nthreaded structures to organize discourse, deeply nested threads can still\nobscure discussions and make it difficult to grasp the overall trajectory of\nconversations. In this paper, we present an interactive system called Needle to\nsupport better navigation and comprehension of complex discourse within\nthreaded discussions. Needle uses visual analytics to summarize key\nconversational metrics--such as activity, toxicity levels, and voting\ntrends--over time, offering both high-level insights and detailed breakdowns of\ndiscussion threads. Through a user study with ten Reddit moderators, we find\nthat Needle supports moderation by reducing cognitive load in making sense of\nlarge discussion, helping prioritize areas that need attention, and providing\ndecision-making supports. Based on our findings, we provide a set of design\nguidelines to inform future visualization-driven moderation tools and\nsociotechnical systems. To the best of our knowledge, Needle is one of the\nfirst systems to combine interactive visual analytics with human-in-the-loop\nmoderation for threaded online discussions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aNeedle\u7684\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9\u5206\u6790\u5e2e\u52a9\u7ba1\u7406\u590d\u6742\u7684\u5728\u7ebf\u8ba8\u8bba\uff0c\u5c24\u5176\u662f\u5d4c\u5957\u5f0f\u8bc4\u8bba\u3002", "motivation": "\u5927\u578b\u5728\u7ebf\u8ba8\u8bba\u56e0\u5185\u5bb9\u91cf\u5927\u4e14\u901f\u5ea6\u5feb\uff0c\u5bfc\u81f4\u7ba1\u7406\u5458\u96be\u4ee5\u8ddf\u8e2a\u548c\u6709\u6548\u7ba1\u7406\u3002\u73b0\u6709\u7684\u7ebf\u7a0b\u7ed3\u6784\u4ecd\u5b58\u5728\u95ee\u9898\uff0c\u65e0\u6cd5\u6e05\u6670\u5c55\u793a\u8ba8\u8bba\u7684\u5168\u8c8c\u3002", "method": "Needle\u5229\u7528\u89c6\u89c9\u5206\u6790\u6280\u672f\uff0c\u603b\u7ed3\u5173\u952e\u5bf9\u8bdd\u6307\u6807\uff08\u5982\u6d3b\u8dc3\u5ea6\u3001\u6bd2\u6027\u6c34\u5e73\u3001\u6295\u7968\u8d8b\u52bf\uff09\uff0c\u5e76\u63d0\u4f9b\u9ad8\u5c42\u6b21\u7684\u6d1e\u5bdf\u548c\u8be6\u7ec6\u7684\u5206\u6790\u3002\u901a\u8fc710\u4f4dReddit\u7ba1\u7406\u5458\u8fdb\u884c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cNeedle\u80fd\u51cf\u8f7b\u8ba4\u77e5\u8d1f\u62c5\uff0c\u5e2e\u52a9\u7ba1\u7406\u5458\u5feb\u901f\u5b9a\u4f4d\u9700\u5173\u6ce8\u7684\u533a\u57df\uff0c\u5e76\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u8bbe\u8ba1\u6307\u5357\uff0c\u5e76\u8ba4\u4e3aNeedle\u662f\u9996\u4e2a\u5c06\u4ea4\u4e92\u5f0f\u89c6\u89c9\u5206\u6790\u4e0e\u4eba\u5de5\u5ba1\u6838\u7ed3\u5408\u7684\u5728\u7ebf\u8ba8\u8bba\u7ba1\u7406\u7cfb\u7edf\u3002"}}
{"id": "2506.11287", "pdf": "https://arxiv.org/pdf/2506.11287", "abs": "https://arxiv.org/abs/2506.11287", "authors": ["Norman Stites", "D. G. Perera"], "title": "Design and Implementation of Washing Machine HUD Using FPGAs", "categories": ["cs.AR"], "comment": "16 pages, 4 figures", "summary": "In contemporary digital design education, practical field programmable gate\narray (FPGA) projects are indispensable for bridging theoretical concepts with\nreal-world applications. This project focuses on developing a hardware-based\nsimulation of a domestic washing machine controller using the Xilinx Spartan-3E\ndevelopment board. A critical component of the design is the graphical heads-up\ndisplay (HUD), which renders real-time information about the machine's\noperational state and cycle selections via a VGA interface.", "AI": {"tldr": "\u8be5\u9879\u76ee\u901a\u8fc7FPGA\u5f00\u53d1\u677f\u6a21\u62df\u5bb6\u7528\u6d17\u8863\u673a\u63a7\u5236\u5668\uff0c\u91cd\u70b9\u662f\u56fe\u5f62\u663e\u793a\u529f\u80fd\u3002", "motivation": "\u5c06\u6570\u5b57\u8bbe\u8ba1\u6559\u80b2\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\u7ed3\u5408\uff0c\u901a\u8fc7\u5b9e\u9645\u9879\u76ee\u589e\u5f3a\u5b66\u4e60\u6548\u679c\u3002", "method": "\u4f7f\u7528Xilinx Spartan-3E\u5f00\u53d1\u677f\uff0c\u8bbe\u8ba1\u786c\u4ef6\u6a21\u62df\u6d17\u8863\u673a\u63a7\u5236\u5668\uff0c\u5e76\u7ed3\u5408VGA\u63a5\u53e3\u5b9e\u73b0\u56fe\u5f62\u663e\u793a\u3002", "result": "\u6210\u529f\u5f00\u53d1\u51fa\u80fd\u591f\u5b9e\u65f6\u663e\u793a\u6d17\u8863\u673a\u64cd\u4f5c\u72b6\u6001\u548c\u5faa\u73af\u9009\u62e9\u7684\u786c\u4ef6\u63a7\u5236\u7cfb\u7edf\u3002", "conclusion": "FPGA\u9879\u76ee\u662f\u6570\u5b57\u8bbe\u8ba1\u6559\u80b2\u4e2d\u7406\u8bba\u4e0e\u5b9e\u8df5\u7ed3\u5408\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.11298", "pdf": "https://arxiv.org/pdf/2506.11298", "abs": "https://arxiv.org/abs/2506.11298", "authors": ["Piotr Sowinski", "Karolina Bogacka", "Anastasiya Danilenka", "Nikita Kozlov"], "title": "Jelly: a fast and convenient RDF serialization format", "categories": ["cs.DB", "cs.NI"], "comment": null, "summary": "Existing RDF serialization formats such as Turtle, N-Triples, and JSON-LD are\nwidely used for communication and storage in knowledge graph and Semantic Web\napplications. However, they suffer from limitations in performance, compression\nratio, and lack of native support for RDF streams. To address these\nshortcomings, we introduce Jelly, a fast and convenient binary serialization\nformat for RDF data that supports both batch and streaming use cases. Jelly is\ndesigned to maximize serialization throughput, reduce file size with\nlightweight streaming compression, and minimize compute resource usage. Built\non Protocol Buffers, Jelly is easy to integrate with modern programming\nlanguages and RDF libraries. To maximize reusability, Jelly has an open\nprotocol specification, open-source implementations in Java and Python\nintegrated with popular RDF libraries, and a versatile command-line tool. To\nillustrate its usefulness, we outline concrete use cases where Jelly can\nprovide tangible benefits. By combining practical usability with\nstate-of-the-art efficiency, Jelly is an important contribution to the Semantic\nWeb tool stack.", "AI": {"tldr": "Jelly\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u4e8c\u8fdb\u5236RDF\u5e8f\u5217\u5316\u683c\u5f0f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u683c\u5f0f\u6027\u80fd\u4e0d\u8db3\u3001\u538b\u7f29\u7387\u4f4e\u548c\u7f3a\u4e4f\u6d41\u652f\u6301\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709RDF\u5e8f\u5217\u5316\u683c\u5f0f\uff08\u5982Turtle\u3001N-Triples\u548cJSON-LD\uff09\u5728\u6027\u80fd\u3001\u538b\u7f29\u6bd4\u53ca\u6d41\u652f\u6301\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u57fa\u4e8eProtocol Buffers\u8bbe\u8ba1Jelly\uff0c\u652f\u6301\u6279\u91cf\u548c\u6d41\u5f0f\u5904\u7406\uff0c\u4f18\u5316\u5e8f\u5217\u5316\u541e\u5410\u91cf\u3001\u6587\u4ef6\u5927\u5c0f\u548c\u8ba1\u7b97\u8d44\u6e90\u4f7f\u7528\uff0c\u5e76\u63d0\u4f9b\u5f00\u6e90\u5b9e\u73b0\u548c\u5de5\u5177\u3002", "result": "Jelly\u63d0\u5347\u4e86\u6548\u7387\uff0c\u652f\u6301\u73b0\u4ee3\u7f16\u7a0b\u8bed\u8a00\u4e0eRDF\u5e93\u7684\u96c6\u6210\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u7528\u4f8b\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "Jelly\u7ed3\u5408\u5b9e\u7528\u6027\u4e0e\u9ad8\u6548\u6027\uff0c\u662f\u8bed\u4e49\u7f51\u5de5\u5177\u6808\u7684\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2506.11309", "pdf": "https://arxiv.org/pdf/2506.11309", "abs": "https://arxiv.org/abs/2506.11309", "authors": ["Ziyi Zhang", "Ziheng Jiang", "Chengquan Jiang", "Menghan Yu", "Size Zheng", "Haibin Lin", "Henry Hoffmann", "Xin Liu"], "title": "SwiftSpec: Ultra-Low Latency LLM Decoding by Scaling Asynchronous Speculative Decoding", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Low-latency decoding for large language models (LLMs) is crucial for\napplications like chatbots and code assistants, yet generating long outputs\nremains slow in single-query settings. Prior work on speculative decoding\n(which combines a small draft model with a larger target model) and tensor\nparallelism has each accelerated decoding. However, conventional approaches\nfail to apply both simultaneously due to imbalanced compute requirements\n(between draft and target models), KV-cache inconsistencies, and communication\noverheads under small-batch tensor-parallelism. This paper introduces\nSwiftSpec, a system that targets ultra-low latency for LLM decoding. SwiftSpec\nredesigns the speculative decoding pipeline in an asynchronous and\ndisaggregated manner, so that each component can be scaled flexibly and remove\ndraft overhead from the critical path. To realize this design, SwiftSpec\nproposes parallel tree generation, tree-aware KV cache management, and fused,\nlatency-optimized kernels to overcome the challenges listed above. Across 5\nmodel families and 6 datasets, SwiftSpec achieves an average of 1.75x speedup\nover state-of-the-art speculative decoding systems and, as a highlight, serves\nLlama3-70B at 348 tokens/s on 8 Nvidia Hopper GPUs, making it the fastest known\nsystem for low-latency LLM serving at this scale.", "AI": {"tldr": "SwiftSpec\u901a\u8fc7\u5f02\u6b65\u548c\u5206\u6563\u8bbe\u8ba1\u7684\u63a8\u6d4b\u89e3\u7801\u6280\u672f\u5927\u5e45\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u5b9e\u73b0\u4e861.75\u500d\u52a0\u901f\uff0c\u5e76\u57288\u5757GPU\u4e0a\u8fbe\u5230348 tokens/s\u7684\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u4e3a\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982\u804a\u5929\u673a\u5668\u4eba\u548c\u4ee3\u7801\u52a9\u624b\uff09\u5728\u5355\u67e5\u8be2\u8bbe\u7f6e\u4e2d\u751f\u6210\u957f\u8f93\u51fa\u7684\u901f\u5ea6\uff0c\u73b0\u6709\u7684\u63a8\u6d4b\u89e3\u7801\u6280\u672f\u548c\u5f20\u91cf\u5e76\u884c\u65b9\u6cd5\u56e0\u8ba1\u7b97\u9700\u6c42\u4e0d\u5e73\u8861\u548c\u901a\u4fe1\u5f00\u9500\u7b49\u95ee\u9898\u65e0\u6cd5\u540c\u65f6\u5e94\u7528\u3002SwiftSpec\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5b9e\u73b0\u8d85\u4f4e\u5ef6\u8fdf\u89e3\u7801\u3002", "method": "SwiftSpec\u91cd\u65b0\u8bbe\u8ba1\u63a8\u6d4b\u89e3\u7801\u6d41\u7a0b\uff0c\u91c7\u7528\u5f02\u6b65\u548c\u5206\u6563\u5f0f\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u5e76\u884c\u6811\u751f\u6210\u3001\u6811\u611f\u77e5KV\u7f13\u5b58\u7ba1\u7406\u4ee5\u53ca\u878d\u5408\u7684\u5ef6\u8fdf\u4f18\u5316\u5185\u6838\uff0c\u4ee5\u7075\u6d3b\u6269\u5c55\u5404\u7ec4\u4ef6\u5e76\u51cf\u5c11\u5173\u952e\u8def\u5f84\u4e0a\u7684\u5f00\u9500\u3002", "result": "\u57285\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c6\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0cSwiftSpec\u5e73\u5747\u6bd4\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u7cfb\u7edf\u5feb1.75\u500d\uff0c\u5c24\u5176\u57288\u5757Nvidia Hopper GPU\u4e0a\u5b9e\u73b0\u4e86348 tokens/s\u7684\u9ad8\u541e\u5410\u91cf\u3002", "conclusion": "SwiftSpec\u662f\u76ee\u524d\u5df2\u77e5\u7684\u5728\u4f4e\u5ef6\u8fdf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u4e2d\u6700\u5feb\u7684\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89e3\u7801\u6548\u7387\u3002"}}
{"id": "2506.10988", "pdf": "https://arxiv.org/pdf/2506.10988", "abs": "https://arxiv.org/abs/2506.10988", "authors": ["Bowen Tian", "Zhengyang Xu", "Mingqiang Wu", "Songning Lai", "Yutai Yue"], "title": "You Only Train Once: A Flexible Training Framework for Code Vulnerability Detection Driven by Vul-Vector", "categories": ["cs.SE", "cs.LG"], "comment": "Under Review", "summary": "With the pervasive integration of computer applications across industries,\nthe presence of vulnerabilities within code bases poses significant risks. The\ndiversity of software ecosystems coupled with the intricate nature of modern\nsoftware engineering has led to a shift from manual code vulnerability\nidentification towards the adoption of automated tools. Among these, deep\nlearning-based approaches have risen to prominence due to their superior\naccuracy; however, these methodologies encounter several obstacles. Primarily,\nthey necessitate extensive labeled datasets and prolonged training periods, and\ngiven the rapid emergence of new vulnerabilities, the frequent retraining of\nmodels becomes a resource-intensive endeavor, thereby limiting their\napplicability in cutting-edge scenarios. To mitigate these challenges, this\npaper introduces the \\underline{\\textbf{YOTO}}--\\underline{\\textbf{Y}}ou\n\\underline{\\textbf{O}}nly \\underline{\\textbf{T}}rain \\underline{\\textbf{O}}nce\nframework. This innovative approach facilitates the integration of multiple\ntypes of vulnerability detection models via parameter fusion, eliminating the\nneed for joint training. Consequently, YOTO enables swift adaptation to newly\ndiscovered vulnerabilities, significantly reducing both the time and\ncomputational resources required for model updates.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faYOTO\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u878d\u5408\u6574\u5408\u591a\u79cd\u6f0f\u6d1e\u68c0\u6d4b\u6a21\u578b\uff0c\u907f\u514d\u8054\u5408\u8bad\u7ec3\uff0c\u5feb\u901f\u9002\u5e94\u65b0\u6f0f\u6d1e\uff0c\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u5de5\u7a0b\u590d\u6742\u591a\u6837\uff0c\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u957f\u65f6\u95f4\u8bad\u7ec3\uff0c\u96be\u4ee5\u5e94\u5bf9\u65b0\u6f0f\u6d1e\u7684\u5feb\u901f\u51fa\u73b0\u3002", "method": "\u5f15\u5165YOTO\u6846\u67b6\uff0c\u5229\u7528\u53c2\u6570\u878d\u5408\u6280\u672f\u6574\u5408\u591a\u7c7b\u578b\u6f0f\u6d1e\u68c0\u6d4b\u6a21\u578b\uff0c\u65e0\u9700\u8054\u5408\u8bad\u7ec3\u3002", "result": "YOTO\u80fd\u5feb\u901f\u9002\u914d\u65b0\u6f0f\u6d1e\uff0c\u663e\u8457\u964d\u4f4e\u6a21\u578b\u66f4\u65b0\u7684\u65f6\u95f4\u548c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "conclusion": "YOTO\u4e3a\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u65b0\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5feb\u901f\u53d8\u5316\u7684\u8f6f\u4ef6\u73af\u5883\u3002"}}
{"id": "2506.11521", "pdf": "https://arxiv.org/pdf/2506.11521", "abs": "https://arxiv.org/abs/2506.11521", "authors": ["Jinming Wen", "Xinyi Wu", "Shuai Zhao", "Yanhao Jia", "Yuwen Li"], "title": "Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models", "categories": ["cs.CR", "cs.AI", "cs.MM"], "comment": null, "summary": "Multimodal large language models (MLLMs), which bridge the gap between\naudio-visual and natural language processing, achieve state-of-the-art\nperformance on several audio-visual tasks. Despite the superior performance of\nMLLMs, the scarcity of high-quality audio-visual training data and\ncomputational resources necessitates the utilization of third-party data and\nopen-source MLLMs, a trend that is increasingly observed in contemporary\nresearch. This prosperity masks significant security risks. Empirical studies\ndemonstrate that the latest MLLMs can be manipulated to produce malicious or\nharmful content. This manipulation is facilitated exclusively through\ninstructions or inputs, including adversarial perturbations and malevolent\nqueries, effectively bypassing the internal security mechanisms embedded within\nthe models. To gain a deeper comprehension of the inherent security\nvulnerabilities associated with audio-visual-based multimodal models, a series\nof surveys investigates various types of attacks, including adversarial and\nbackdoor attacks. While existing surveys on audio-visual attacks provide a\ncomprehensive overview, they are limited to specific types of attacks, which\nlack a unified review of various types of attacks. To address this issue and\ngain insights into the latest trends in the field, this paper presents a\ncomprehensive and systematic review of audio-visual attacks, which include\nadversarial attacks, backdoor attacks, and jailbreak attacks. Furthermore, this\npaper also reviews various types of attacks in the latest audio-visual-based\nMLLMs, a dimension notably absent in existing surveys. Drawing upon\ncomprehensive insights from a substantial review, this paper delineates both\nchallenges and emergent trends for future research on audio-visual attacks and\ndefense.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u97f3\u9891-\u89c6\u89c9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u5b89\u5168\u6f0f\u6d1e\u53ca\u653b\u51fb\u7c7b\u578b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u7f3a\u4e4f\u7edf\u4e00\u5168\u9762\u5206\u6790\u7684\u7a7a\u767d\u3002", "motivation": "\u5c3d\u7ba1MLLMs\u5728\u97f3\u9891-\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u4f9d\u8d56\u7b2c\u4e09\u65b9\u6570\u636e\u548c\u5f00\u6e90\u6a21\u578b\u5e26\u6765\u4e86\u5b89\u5168\u9690\u60a3\uff0c\u9700\u8981\u901a\u8fc7\u7cfb\u7edf\u7814\u7a76\u63ed\u793a\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u8bba\u6587\u5bf9\u97f3\u9891-\u89c6\u89c9\u653b\u51fb\uff08\u5982\u5bf9\u6297\u653b\u51fb\u3001\u540e\u95e8\u653b\u51fb\u548c\u8d8a\u72f1\u653b\u51fb\uff09\u8fdb\u884c\u5168\u9762\u7cfb\u7edf\u56de\u987e\uff0c\u5e76\u5206\u6790\u6700\u65b0MLLMs\u7684\u653b\u51fb\u7c7b\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0MLLMs\u6613\u53d7\u6307\u4ee4\u6216\u8f93\u5165\u64cd\u7eb5\u4ea7\u751f\u6076\u610f\u5185\u5bb9\uff0c\u73b0\u6709\u7814\u7a76\u5bf9\u653b\u51fb\u7c7b\u578b\u8986\u76d6\u4e0d\u8db3\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u97f3\u9891-\u89c6\u89c9\u653b\u51fb\u7684\u6311\u6218\u4e0e\u8d8b\u52bf\uff0c\u4e3a\u672a\u6765\u9632\u5fa1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.11701", "pdf": "https://arxiv.org/pdf/2506.11701", "abs": "https://arxiv.org/abs/2506.11701", "authors": ["Lukas Gehring", "Sebastian Rehms", "Florian Tschorsch"], "title": "PermRust: A Token-based Permission System for Rust", "categories": ["cs.PL", "cs.CR"], "comment": "11 pages", "summary": "Permission systems which restrict access to system resources are a\nwell-established technology in operating systems, especially for smartphones.\nHowever, as such systems are implemented in the operating system they can at\nmost manage access on the process-level. Since moderns software often (re)uses\ncode from third-parties libraries, a permission system for libraries can be\ndesirable to enhance security. In this short-paper, we adapt concepts from\ncapability systems building a novel theoretical foundation for permission\nsystem at the level of the programming language. This leads to PermRust, a\ntoken-based permission system for the Rust programming language as a zero cost\nabstraction on top of its type-system. With it access to system resources can\nbe managed per library.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Rust\u7f16\u7a0b\u8bed\u8a00\u7684\u5e93\u7ea7\u6743\u9650\u7cfb\u7edfPermRust\uff0c\u57fa\u4e8e\u80fd\u529b\u7cfb\u7edf\u6982\u5ff5\uff0c\u5b9e\u73b0\u4e86\u96f6\u6210\u672c\u62bd\u8c61\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u5e38\u4f7f\u7528\u7b2c\u4e09\u65b9\u5e93\u4ee3\u7801\uff0c\u4f46\u64cd\u4f5c\u7cfb\u7edf\u6743\u9650\u7cfb\u7edf\u4ec5\u80fd\u7ba1\u7406\u8fdb\u7a0b\u7ea7\u8bbf\u95ee\uff0c\u56e0\u6b64\u9700\u8981\u5e93\u7ea7\u6743\u9650\u7cfb\u7edf\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\u3002", "method": "\u501f\u9274\u80fd\u529b\u7cfb\u7edf\u6982\u5ff5\uff0c\u6784\u5efa\u7f16\u7a0b\u8bed\u8a00\u7ea7\u522b\u7684\u6743\u9650\u7cfb\u7edf\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5728Rust\u7c7b\u578b\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u96f6\u6210\u672c\u62bd\u8c61\u7684\u4ee4\u724c\u6743\u9650\u7cfb\u7edfPermRust\u3002", "result": "\u5b9e\u73b0\u4e86PermRust\u7cfb\u7edf\uff0c\u80fd\u591f\u6309\u5e93\u7ba1\u7406\u5bf9\u7cfb\u7edf\u8d44\u6e90\u7684\u8bbf\u95ee\u3002", "conclusion": "PermRust\u4e3a\u7f16\u7a0b\u8bed\u8a00\u7ea7\u522b\u7684\u6743\u9650\u7ba1\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u6027\u4e0e\u7075\u6d3b\u6027\u3002"}}
{"id": "2506.11556", "pdf": "https://arxiv.org/pdf/2506.11556", "abs": "https://arxiv.org/abs/2506.11556", "authors": ["Antonio M. Mercado-Mart\u00ednez", "Beatriz Soret", "Antonio Jurado-Navas"], "title": "Scheduling Agile Earth Observation Satellites with Onboard Processing and Real-Time Monitoring", "categories": ["cs.NI", "cs.RO"], "comment": "This paper has been submitted to GLOBECOM 2025", "summary": "The emergence of Agile Earth Observation Satellites (AEOSs) has marked a\nsignificant turning point in the field of Earth Observation (EO), offering\nenhanced flexibility in data acquisition. Concurrently, advancements in onboard\nsatellite computing and communication technologies have greatly enhanced data\ncompression efficiency, reducing network latency and congestion while\nsupporting near real-time information delivery. In this paper, we address the\nAgile Earth Observation Satellite Scheduling Problem (AEOSSP), which involves\ndetermining the optimal sequence of target observations to maximize overall\nobservation profit. Our approach integrates onboard data processing for\nreal-time remote monitoring into the multi-satellite optimization problem. To\nthis end, we define a set of priority indicators and develop a constructive\nheuristic method, further enhanced with a Local Search (LS) strategy. The\nresults show that the proposed algorithm provides high-quality information by\nincreasing the resolution of the collected frames by up to 10% on average,\nwhile reducing the variance in the monitoring frequency of the targets within\nthe instance by up to 83%, ensuring more up-to-date information across the\nentire set compared to a First-In First-Out (FIFO) method.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u654f\u6377\u5730\u7403\u89c2\u6d4b\u536b\u661f\u8c03\u5ea6\u95ee\u9898\uff08AEOSSP\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5b9e\u65f6\u6570\u636e\u5904\u7406\u548c\u591a\u536b\u661f\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5148\u7ea7\u6307\u6807\u548c\u5c40\u90e8\u641c\u7d22\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89c2\u6d4b\u5206\u8fa8\u7387\u548c\u76ee\u6807\u76d1\u6d4b\u9891\u7387\u7684\u5747\u5300\u6027\u3002", "motivation": "\u654f\u6377\u5730\u7403\u89c2\u6d4b\u536b\u661f\uff08AEOSs\uff09\u7684\u51fa\u73b0\u63d0\u9ad8\u4e86\u6570\u636e\u91c7\u96c6\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u5982\u4f55\u4f18\u5316\u89c2\u6d4b\u5e8f\u5217\u4ee5\u6700\u5927\u5316\u6536\u76ca\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u5b9e\u65f6\u6570\u636e\u5904\u7406\u6280\u672f\u4f18\u5316\u591a\u536b\u661f\u8c03\u5ea6\u3002", "method": "\u5b9a\u4e49\u4f18\u5148\u7ea7\u6307\u6807\uff0c\u5f00\u53d1\u6784\u9020\u6027\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5e76\u8f85\u4ee5\u5c40\u90e8\u641c\u7d22\u7b56\u7565\uff0c\u4f18\u5316\u591a\u536b\u661f\u89c2\u6d4b\u5e8f\u5217\u3002", "result": "\u7b97\u6cd5\u5c06\u91c7\u96c6\u5e27\u5206\u8fa8\u7387\u5e73\u5747\u63d0\u9ad8\u4e8610%\uff0c\u76ee\u6807\u76d1\u6d4b\u9891\u7387\u7684\u65b9\u5dee\u51cf\u5c11\u4e8683%\uff0c\u4f18\u4e8eFIFO\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u654f\u6377\u536b\u661f\u7684\u89c2\u6d4b\u6548\u7387\u548c\u5b9e\u65f6\u6027\uff0c\u4e3a\u591a\u536b\u661f\u8c03\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.11085", "pdf": "https://arxiv.org/pdf/2506.11085", "abs": "https://arxiv.org/abs/2506.11085", "authors": ["Justin Asher"], "title": "LeanExplore: A search engine for Lean 4 declarations", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR", "cs.LG", "cs.LO", "I.2.6; H.3.3; I.2.3"], "comment": "16 pages, 1 figure. Project website: https://www.leanexplore.com/ ,\n  Code: https://github.com/justincasher/lean-explore", "summary": "The expanding Lean 4 ecosystem poses challenges for navigating its vast\nlibraries. This paper introduces LeanExplore, a search engine for Lean 4\ndeclarations. LeanExplore enables users to semantically search for statements,\nboth formally and informally, across select Lean 4 packages (including\nBatteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is\npowered by a hybrid ranking strategy, integrating scores from a multi-source\nsemantic embedding model (capturing conceptual meaning from formal Lean code,\ndocstrings, AI-generated informal translations, and declaration titles), BM25+\nfor keyword-based lexical relevance, and a PageRank-based score reflecting\ndeclaration importance and interconnectedness. The search engine is accessible\nvia a dedicated website (https://www.leanexplore.com/) and a Python API\n(https://github.com/justincasher/lean-explore). Furthermore, the database can\nbe downloaded, allowing users to self-host the service. LeanExplore integrates\neasily with LLMs via the model context protocol (MCP), enabling users to chat\nwith an AI assistant about Lean declarations or utilize the search engine for\nbuilding theorem-proving agents. This work details LeanExplore's architecture,\ndata processing, functionalities, and its potential to enhance Lean 4 workflows\nand AI-driven mathematical research", "AI": {"tldr": "LeanExplore\u662f\u4e00\u4e2a\u4e3aLean 4\u751f\u6001\u7cfb\u7edf\u8bbe\u8ba1\u7684\u8bed\u4e49\u641c\u7d22\u5f15\u64ce\uff0c\u652f\u6301\u8de8\u591a\u4e2a\u5305\u7684\u5f62\u5f0f\u5316\u4e0e\u975e\u5f62\u5f0f\u5316\u641c\u7d22\u3002", "motivation": "\u968f\u7740Lean 4\u751f\u6001\u7cfb\u7edf\u7684\u6269\u5c55\uff0c\u5176\u5e9e\u5927\u7684\u5e93\u4f7f\u5f97\u5bfc\u822a\u53d8\u5f97\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u9ad8\u6548\u7684\u641c\u7d22\u5de5\u5177\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6392\u5e8f\u7b56\u7565\uff0c\u7ed3\u5408\u591a\u6e90\u8bed\u4e49\u5d4c\u5165\u6a21\u578b\u3001BM25+\u5173\u952e\u8bcd\u8bc4\u5206\u548c\u57fa\u4e8ePageRank\u7684\u58f0\u660e\u91cd\u8981\u6027\u8bc4\u5206\u3002", "result": "\u5b9e\u73b0\u4e86LeanExplore\u641c\u7d22\u5f15\u64ce\uff0c\u63d0\u4f9b\u7f51\u7ad9\u548cPython API\u8bbf\u95ee\uff0c\u652f\u6301LLM\u96c6\u6210\u4ee5\u589e\u5f3a\u4ea4\u4e92\u6027\u548c\u7814\u7a76\u6548\u7387\u3002", "conclusion": "LeanExplore\u80fd\u591f\u663e\u8457\u63d0\u5347Lean 4\u5de5\u4f5c\u6d41\u548cAI\u9a71\u52a8\u7684\u6570\u5b66\u7814\u7a76\u6548\u7387\u3002"}}
{"id": "2506.11273", "pdf": "https://arxiv.org/pdf/2506.11273", "abs": "https://arxiv.org/abs/2506.11273", "authors": ["Daniel Meister", "Jakub Bok\u0161ansk\u00fd", "Michael Guthe", "Ji\u0159\u00ed Bittner"], "title": "On Ray Reordering Techniques for Faster GPU Ray Tracing", "categories": ["cs.GR"], "comment": null, "summary": "We study ray reordering as a tool for increasing the performance of existing\nGPU ray tracing implementations. We focus on ray reordering that is fully\nagnostic to the particular trace kernel. We summarize the existing methods for\ncomputing the ray sorting keys and discuss their properties. We propose a novel\nmodification of a previously proposed method using the termination point\nestimation that is well-suited to tracing secondary rays. We evaluate the ray\nreordering techniques in the context of the wavefront path tracing using the\nRTX trace kernels. We show that ray reordering yields significantly higher\ntrace speed on recent GPUs (1.3-2.0x), but to recover the reordering overhead\nin the hardware-accelerated trace phase is problematic.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5149\u7ebf\u91cd\u6392\u5e8f\u63d0\u5347GPU\u5149\u7ebf\u8ffd\u8e2a\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5728\u6ce2\u524d\u8def\u5f84\u8ffd\u8e2a\u4e2d\u7684\u6548\u679c\u3002", "motivation": "\u63a2\u8ba8\u5149\u7ebf\u91cd\u6392\u5e8f\u5bf9\u73b0\u6709GPU\u5149\u7ebf\u8ffd\u8e2a\u5b9e\u73b0\u7684\u6027\u80fd\u63d0\u5347\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5bf9\u4e8c\u6b21\u5149\u7ebf\u7684\u9002\u7528\u6027\u3002", "method": "\u603b\u7ed3\u4e86\u73b0\u6709\u7684\u5149\u7ebf\u6392\u5e8f\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ec8\u6b62\u70b9\u4f30\u8ba1\u7684\u65b0\u6539\u8fdb\u65b9\u6cd5\uff0c\u5e76\u5728RTX\u8ffd\u8e2a\u5185\u6838\u4e2d\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u6280\u672f\u3002", "result": "\u5149\u7ebf\u91cd\u6392\u5e8f\u5728\u6700\u65b0GPU\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u8ffd\u8e2a\u901f\u5ea6\uff081.3-2.0\u500d\uff09\uff0c\u4f46\u786c\u4ef6\u52a0\u901f\u9636\u6bb5\u7684\u6392\u5e8f\u5f00\u9500\u6062\u590d\u5b58\u5728\u95ee\u9898\u3002", "conclusion": "\u5149\u7ebf\u91cd\u6392\u5e8f\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u6743\u8861\u6392\u5e8f\u5f00\u9500\u4e0e\u6027\u80fd\u589e\u76ca\u3002"}}
{"id": "2506.11040", "pdf": "https://arxiv.org/pdf/2506.11040", "abs": "https://arxiv.org/abs/2506.11040", "authors": ["Feifei Shi", "Xueyan Yin", "Kang Wang", "Wanyu Tu", "Qifu Sun", "Huansheng Ning"], "title": "Large Language models for Time Series Analysis: Techniques, Applications, and Challenges", "categories": ["cs.LG", "cs.CL", "cs.ET"], "comment": null, "summary": "Time series analysis is pivotal in domains like financial forecasting and\nbiomedical monitoring, yet traditional methods are constrained by limited\nnonlinear feature representation and long-term dependency capture. The\nemergence of Large Language Models (LLMs) offers transformative potential by\nleveraging their cross-modal knowledge integration and inherent attention\nmechanisms for time series analysis. However, the development of\ngeneral-purpose LLMs for time series from scratch is still hindered by data\ndiversity, annotation scarcity, and computational requirements. This paper\npresents a systematic review of pre-trained LLM-driven time series analysis,\nfocusing on enabling techniques, potential applications, and open challenges.\nFirst, it establishes an evolutionary roadmap of AI-driven time series\nanalysis, from the early machine learning era, through the emerging LLM-driven\nparadigm, to the development of native temporal foundation models. Second, it\norganizes and systematizes the technical landscape of LLM-driven time series\nanalysis from a workflow perspective, covering LLMs' input, optimization, and\nlightweight stages. Finally, it critically examines novel real-world\napplications and highlights key open challenges that can guide future research\nand innovation. The work not only provides valuable insights into current\nadvances but also outlines promising directions for future development. It\nserves as a foundational reference for both academic and industrial\nresearchers, paving the way for the development of more efficient,\ngeneralizable, and interpretable systems of LLM-driven time series analysis.", "AI": {"tldr": "LLMs\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5c55\u73b0\u51fa\u8de8\u6a21\u6001\u77e5\u8bc6\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u4f18\u52bf\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u591a\u6837\u6027\u3001\u6807\u6ce8\u7a00\u7f3a\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u901a\u7528LLMs\u7684\u5f00\u53d1\u4ecd\u53d7\u9650\u3002\u672c\u6587\u7cfb\u7edf\u56de\u987e\u4e86\u9884\u8bad\u7ec3LLMs\u9a71\u52a8\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u68b3\u7406\u6280\u672f\u8def\u7ebf\u548c\u5e94\u7528\u6311\u6218\uff0c\u4e3a\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u7279\u5f81\u8868\u793a\u548c\u957f\u671f\u4f9d\u8d56\u6355\u6349\u65b9\u9762\u53d7\u9650\uff0c\u800cLLMs\u7684\u8de8\u6a21\u6001\u77e5\u8bc6\u548c\u6ce8\u610f\u529b\u673a\u5236\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u5e26\u6765\u65b0\u6f5c\u529b\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u56de\u987e\u548c\u603b\u7ed3\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u7684\u6280\u672f\u3001\u5e94\u7528\u53ca\u6311\u6218\u3002", "method": "1. \u5efa\u7acbAI\u9a71\u52a8\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u53d1\u5c55\u8def\u7ebf\u56fe\uff1b2. \u4ece\u8f93\u5165\u3001\u4f18\u5316\u548c\u8f7b\u91cf\u5316\u4e09\u9636\u6bb5\u68b3\u7406\u6280\u672f\uff1b3. \u5206\u6790\u5b9e\u9645\u5e94\u7528\u548c\u5f00\u653e\u6311\u6218\u3002", "result": "\u63ed\u793a\u4e86LLMs\u9a71\u52a8\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u6280\u672f\u6846\u67b6\u3001\u5e94\u7528\u6f5c\u529b\u548c\u5173\u952e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u4e3a\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u63d0\u4f9b\u4e86LLMs\u9a71\u52a8\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u5168\u9762\u53c2\u8003\uff0c\u63a8\u52a8\u66f4\u9ad8\u6548\u3001\u6cdb\u5316\u548c\u53ef\u89e3\u91ca\u7cfb\u7edf\u7684\u5f00\u53d1\u3002"}}
{"id": "2506.11326", "pdf": "https://arxiv.org/pdf/2506.11326", "abs": "https://arxiv.org/abs/2506.11326", "authors": ["Conrad Borchers", "Xiaoyi Tian", "Kristy Elizabeth Boyer", "Maya Israel"], "title": "Combining Log Data and Collaborative Dialogue Features to Predict Project Quality in Middle School AI Education", "categories": ["cs.HC"], "comment": "Research paper accepted to the 9th Educational Data Mining in\n  Computer Science Education (CSEDM) Workshop", "summary": "Project-based learning plays a crucial role in computing education. However,\nits open-ended nature makes tracking project development and assessing success\nchallenging. We investigate how dialogue and system interaction logs predict\nproject quality during collaborative, project-based AI learning of 94 middle\nschool students working in pairs. We used linguistic features from dialogue\ntranscripts and behavioral features from system logs to predict three project\nquality outcomes: productivity (number of training phrases), content richness\n(word density), and lexical variation (word diversity) of chatbot training\nphrases. We compared the predictive accuracy of each modality and a fusion of\nthe modalities. Results indicate log data better predicts productivity, while\ndialogue data is more effective for content richness. Both modalities modestly\npredict lexical variation. Multimodal fusion improved predictions for\nproductivity and lexical variation of training phrases but not content\nrichness. These findings suggest that the value of multimodal fusion depends on\nthe specific learning outcome. The study contributes to multimodal learning\nanalytics by demonstrating the nuanced interplay between behavioral and\nlinguistic data in assessing student learning progress in open-ended AI\nlearning environments.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5bf9\u8bdd\u548c\u7cfb\u7edf\u4ea4\u4e92\u65e5\u5fd7\u9884\u6d4b\u4e2d\u5b66\u751fAI\u9879\u76ee\u5b66\u4e60\u4e2d\u7684\u9879\u76ee\u8d28\u91cf\uff0c\u53d1\u73b0\u4e0d\u540c\u6570\u636e\u6a21\u6001\u5bf9\u9884\u6d4b\u7279\u5b9a\u5b66\u4e60\u7ed3\u679c\u6709\u72ec\u7279\u4ef7\u503c\u3002", "motivation": "\u7531\u4e8e\u9879\u76ee\u5b66\u4e60\u7684\u5f00\u653e\u6027\uff0c\u8ffd\u8e2a\u548c\u8bc4\u4f30\u9879\u76ee\u8fdb\u5c55\u5177\u6709\u6311\u6218\u6027\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u9884\u6d4b\u9879\u76ee\u8d28\u91cf\u3002", "method": "\u5206\u679094\u540d\u4e2d\u5b66\u751f\u5728\u7ed3\u5bf9\u5b66\u4e60\u4e2d\u7684\u5bf9\u8bdd\u548c\u7cfb\u7edf\u65e5\u5fd7\u6570\u636e\uff0c\u9884\u6d4b\u9879\u76ee\u8d28\u91cf\u7684\u4e09\u4e2a\u6307\u6807\uff08\u751f\u4ea7\u529b\u3001\u5185\u5bb9\u4e30\u5bcc\u5ea6\u548c\u8bcd\u6c47\u591a\u6837\u6027\uff09\u3002", "result": "\u65e5\u5fd7\u6570\u636e\u66f4\u64c5\u957f\u9884\u6d4b\u751f\u4ea7\u529b\uff0c\u5bf9\u8bdd\u6570\u636e\u5bf9\u5185\u5bb9\u4e30\u5bcc\u5ea6\u66f4\u6709\u6548\uff0c\u591a\u6a21\u6001\u878d\u5408\u5bf9\u751f\u4ea7\u529b\u548c\u8bcd\u6c47\u591a\u6837\u6027\u9884\u6d4b\u6709\u63d0\u5347\u3002", "conclusion": "\u591a\u6a21\u6001\u6570\u636e\u7684\u4ef7\u503c\u53d6\u51b3\u4e8e\u5177\u4f53\u5b66\u4e60\u76ee\u6807\uff0c\u7814\u7a76\u4e3a\u5f00\u653e\u5f0fAI\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2506.11329", "pdf": "https://arxiv.org/pdf/2506.11329", "abs": "https://arxiv.org/abs/2506.11329", "authors": ["Haneul Park", "Jiaqi Lou", "Sangjin Lee", "Yifan Yuan", "Kyoung Soo Park", "Yongseok Son", "Ipoom Jeong", "Nam Sung Kim"], "title": "A4: Microarchitecture-Aware LLC Management for Datacenter Servers with Emerging I/O Devices", "categories": ["cs.AR"], "comment": null, "summary": "In modern server CPUs, the Last-Level Cache (LLC) serves not only as a victim\ncache for higher-level private caches but also as a buffer for low-latency DMA\ntransfers between CPU cores and I/O devices through Direct Cache Access (DCA).\nHowever, prior work has shown that high-bandwidth network-I/O devices can\nrapidly flood the LLC with packets, often causing significant contention with\nco-running workloads. One step further, this work explores hidden\nmicroarchitectural properties of the Intel Xeon CPUs, uncovering two previously\nunrecognized LLC contentions triggered by emerging high-bandwidth I/O devices.\nSpecifically, (C1) DMA-written cache lines in LLC ways designated for DCA\n(referred to as DCA ways) are migrated to certain LLC ways (denoted as\ninclusive ways) when accessed by CPU cores, unexpectedly contending with\nnon-I/O cache lines within the inclusive ways. In addition, (C2) high-bandwidth\nstorage-I/O devices, which are increasingly common in datacenter servers,\nbenefit little from DCA while contending with (latency-sensitive) network-I/O\ndevices within DCA ways. To this end, we present \\design, a runtime LLC\nmanagement framework designed to alleviate both (C1) and (C2) among diverse\nco-running workloads, using a hidden knob and other hardware features\nimplemented in those CPUs. Additionally, we demonstrate that \\design can also\nalleviate other previously known network-I/O-driven LLC contentions. Overall,\nit improves the performance of latency-sensitive, high-priority workloads by\n51\\% without notably compromising that of low-priority workloads.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u73b0\u4ee3\u670d\u52a1\u5668CPU\u4e2dLLC\u7684\u9690\u85cf\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8fd0\u884c\u65f6\u7ba1\u7406\u6846\u67b6\\design\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u4f18\u5148\u7ea7\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22Intel Xeon CPU\u4e2d\u56e0\u9ad8\u5e26\u5bbdI/O\u8bbe\u5907\u5f15\u53d1\u7684LLC\u7ade\u4e89\u95ee\u9898\uff0c\u5c24\u5176\u662f\u6b64\u524d\u672a\u88ab\u53d1\u73b0\u7684\u4e24\u7c7b\u9690\u85cf\u7ade\u4e89\uff08C1\u548cC2\uff09\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5fae\u67b6\u6784\u7279\u6027\uff0c\u63d0\u51fa\\design\u6846\u67b6\uff0c\u5229\u7528\u9690\u85cf\u7684\u786c\u4ef6\u529f\u80fd\u52a8\u6001\u7ba1\u7406LLC\u8d44\u6e90\u3002", "result": "\\design\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u4f18\u5148\u7ea7\u4efb\u52a1\u7684\u6027\u80fd\uff0851%\uff09\uff0c\u540c\u65f6\u5bf9\u4f4e\u4f18\u5148\u7ea7\u4efb\u52a1\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\\design\u6709\u6548\u89e3\u51b3\u4e86LLC\u7ade\u4e89\u95ee\u9898\uff0c\u4e3a\u591a\u5de5\u4f5c\u8d1f\u8f7d\u73af\u5883\u63d0\u4f9b\u4e86\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2506.11541", "pdf": "https://arxiv.org/pdf/2506.11541", "abs": "https://arxiv.org/abs/2506.11541", "authors": ["Aaron K\u00fcsters", "Wil M. P. van der Aalst"], "title": "OCPQ: Object-Centric Process Querying & Constraints", "categories": ["cs.DB"], "comment": null, "summary": "Process querying is used to extract information and insights from process\nexecution data. Similarly, process constraints can be checked against input\ndata, yielding information on which process instances violate them.\nTraditionally, such process mining techniques use case-centric event data as\ninput. However, with the uptake of Object-Centric Process Mining (OCPM),\nexisting querying and constraint checking techniques are no longer applicable.\nObject-Centric Event Data (OCED) removes the requirement to pick a single case\nnotion (i.e., requiring that events belong to exactly one case) and can thus\nrepresent many real-life processes much more accurately. In this paper, we\npresent a novel highly-expressive approach for object-centric process querying,\ncalled OCPQ. It supports a wide variety of applications, including OCED-based\nconstraint checking and filtering. The visual representation of nested queries\nin OCPQ allows users to intuitively read and create queries and constraints. We\nimplemented our approach using (1) a high-performance execution engine backend\nand (2) an easy-to-use editor frontend. Additionally, we evaluated our approach\non a real-life dataset, showing the lack in expressiveness of prior work and\nruntime performance significantly better than the general querying solutions\nSQLite and Neo4j, as well as comparable to the performance-focused DuckDB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOCPQ\u7684\u65b0\u578b\u5bf9\u8c61\u4e2d\u5fc3\u6d41\u7a0b\u67e5\u8be2\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6d41\u7a0b\u6316\u6398\u6280\u672f\u4e0d\u9002\u7528\u4e8e\u5bf9\u8c61\u4e2d\u5fc3\u4e8b\u4ef6\u6570\u636e\u7684\u95ee\u9898\uff0c\u652f\u6301\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\uff0c\u5e76\u5728\u6027\u80fd\u548c\u6613\u7528\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u6d41\u7a0b\u6316\u6398\u6280\u672f\u57fa\u4e8e\u6848\u4f8b\u4e2d\u5fc3\u4e8b\u4ef6\u6570\u636e\uff0c\u65e0\u6cd5\u9002\u7528\u4e8e\u5bf9\u8c61\u4e2d\u5fc3\u8fc7\u7a0b\u6316\u6398\uff08OCPM\uff09\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u67e5\u8be2\u548c\u7ea6\u675f\u68c0\u67e5\u65b9\u6cd5\u3002", "method": "\u63d0\u51faOCPQ\u65b9\u6cd5\uff0c\u652f\u6301\u5bf9\u8c61\u4e2d\u5fc3\u4e8b\u4ef6\u6570\u636e\u7684\u67e5\u8be2\u548c\u7ea6\u675f\u68c0\u67e5\uff0c\u5305\u62ec\u9ad8\u6027\u80fd\u6267\u884c\u5f15\u64ce\u548c\u6613\u7528\u7f16\u8f91\u5668\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cOCPQ\u5728\u8868\u8fbe\u80fd\u529b\u548c\u8fd0\u884c\u65f6\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\uff08\u5982SQLite\u548cNeo4j\uff09\uff0c\u4e0e\u6027\u80fd\u4f18\u5316\u7684DuckDB\u76f8\u5f53\u3002", "conclusion": "OCPQ\u662f\u4e00\u79cd\u9ad8\u5ea6\u8868\u8fbe\u529b\u7684\u5bf9\u8c61\u4e2d\u5fc3\u6d41\u7a0b\u67e5\u8be2\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u548c\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2506.11483", "pdf": "https://arxiv.org/pdf/2506.11483", "abs": "https://arxiv.org/abs/2506.11483", "authors": ["Zhouheng Du", "Nima Davari", "Li Li", "Nodir Kodirov"], "title": "Capsule: Efficient Player Isolation for Datacenters", "categories": ["cs.DC", "cs.GR"], "comment": null, "summary": "Cloud gaming is increasingly popular. A challenge for cloud provider is to\nkeep datacenter utilization high: a non-trivial task due to application\nvariety. These applications come in different shapes and sizes. So do cloud\ndatacenter resources, e.g., CPUs, GPUs, NPUs.\n  Part of the challenge stems from game engines being predominantly designed to\nrun only one player. One player in a lightweight game might utilize only a\nfraction of the cloud server GPU. The remaining GPU capacity will be left\nunderutilized, an undesired outcome for the cloud provider. We introduce\nCapsule, a mechanism that allows multiple players to seamlessly share one GPU.\n  We implemented Capsule in O3DE, a popular open source game engine. Our\nevaluations show that Capsule can increase datacenter resource utilization by\naccommodating up to 2.25x more players, without degrading player gaming\nexperience. Capsule is also application agnostic. We ran four applications on\nCapsule-based O3DE with no application changes. Our experiences show that\nCapsule design can be adopted by other game engines to increase datacenter\nutilization across cloud providers.", "AI": {"tldr": "Capsule\u662f\u4e00\u79cd\u673a\u5236\uff0c\u5141\u8bb8\u591a\u4e2a\u73a9\u5bb6\u5171\u4eab\u4e00\u4e2aGPU\uff0c\u663e\u8457\u63d0\u9ad8\u6570\u636e\u4e2d\u5fc3\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u4e91\u6e38\u620f\u65e5\u76ca\u6d41\u884c\uff0c\u4f46\u6570\u636e\u4e2d\u5fc3\u8d44\u6e90\u5229\u7528\u7387\u4f4e\uff0c\u5c24\u5176\u662f\u5728GPU\u4e0a\uff0c\u56e0\u4e3a\u6e38\u620f\u5f15\u64ce\u901a\u5e38\u53ea\u652f\u6301\u5355\u73a9\u5bb6\u8fd0\u884c\u3002", "method": "\u5f00\u53d1\u4e86Capsule\u673a\u5236\uff0c\u5e76\u5728\u5f00\u6e90\u6e38\u620f\u5f15\u64ceO3DE\u4e2d\u5b9e\u73b0\uff0c\u652f\u6301\u591a\u73a9\u5bb6\u5171\u4eabGPU\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCapsule\u80fd\u5bb9\u7eb3\u6700\u591a2.25\u500d\u73a9\u5bb6\uff0c\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u4e14\u4e0d\u5f71\u54cd\u6e38\u620f\u4f53\u9a8c\u3002", "conclusion": "Capsule\u8bbe\u8ba1\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u6e38\u620f\u5f15\u64ce\uff0c\u5e2e\u52a9\u4e91\u63d0\u4f9b\u5546\u63d0\u9ad8\u6570\u636e\u4e2d\u5fc3\u5229\u7528\u7387\u3002"}}
{"id": "2506.10989", "pdf": "https://arxiv.org/pdf/2506.10989", "abs": "https://arxiv.org/abs/2506.10989", "authors": ["Rogelio Cruz", "Jonatan Contreras", "Francisco Guerrero", "Ezequiel Rodriguez", "Carlos Valdez", "Citlali Carrillo"], "title": "Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "In this paper, we propose a novel prompting approach aimed at enhancing the\nability of Large Language Models (LLMs) to generate accurate Python code.\nSpecifically, we introduce a prompt template designed to improve the quality\nand correctness of generated code snippets, enabling them to pass tests and\nproduce reliable results. Through experiments conducted on two state-of-the-art\nLLMs using the HumanEval dataset, we demonstrate that our approach outperforms\nwidely studied zero-shot and Chain-of-Thought (CoT) methods in terms of the\nPass@k metric. Furthermore, our method achieves these improvements with\nsignificantly reduced token usage compared to the CoT approach, making it both\neffective and resource-efficient, thereby lowering the computational demands\nand improving the eco-footprint of LLM capabilities. These findings highlight\nthe potential of tailored prompting strategies to optimize code generation\nperformance, paving the way for broader applications in AI-driven programming\ntasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u51c6\u786ePython\u4ee3\u7801\u7684\u80fd\u529b\u3002", "motivation": "\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u63d0\u793a\u6a21\u677f\uff0c\u4f18\u5316\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7HumanEval\u6570\u636e\u96c6\u5728\u4e24\u79cd\u5148\u8fdbLLM\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728Pass@k\u6307\u6807\u4e0a\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u601d\u7ef4\u94fe\u65b9\u6cd5\uff0c\u4e14\u663e\u8457\u51cf\u5c11token\u4f7f\u7528\u91cf\u3002", "conclusion": "\u5b9a\u5236\u5316\u63d0\u793a\u7b56\u7565\u80fd\u4f18\u5316\u4ee3\u7801\u751f\u6210\u6027\u80fd\uff0c\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\uff0c\u62d3\u5bbdAI\u7f16\u7a0b\u5e94\u7528\u3002"}}
{"id": "2506.11737", "pdf": "https://arxiv.org/pdf/2506.11737", "abs": "https://arxiv.org/abs/2506.11737", "authors": ["Dinh Viet Cuong", "Hoang-Bao Le", "An Pham Ngoc Nguyen", "Liting Zhou", "Cathal Gurrin"], "title": "Quizzard@INOVA Challenge 2025 -- Track A: Plug-and-Play Technique in Interleaved Multi-Image Model", "categories": ["cs.CV", "cs.CL", "cs.MM"], "comment": null, "summary": "This paper addresses two main objectives. Firstly, we demonstrate the\nimpressive performance of the LLaVA-NeXT-interleave on 22 datasets across three\ndifferent tasks: Multi-Image Reasoning, Documents and Knowledge-Based\nUnderstanding and Interactive Multi-Modal Communication. Secondly, we add the\nDense Channel Integration (DCI) connector to the LLaVA-NeXT-Interleave and\ncompare its performance against the standard model. We find that the standard\nmodel achieves the highest overall accuracy, excelling in vision-heavy tasks\nlike VISION, NLVR2, and Fashion200K. Meanwhile, the DCI-enhanced version shows\nparticular strength on datasets requiring deeper semantic coherence or\nstructured change understanding such as MIT-States_PropertyCoherence and\nSlideVQA. Our results highlight the potential of combining powerful foundation\nmodels with plug-and-play techniques for Interleave tasks. The code is\navailable at https://github.com/dinhvietcuong1996/icme25-inova.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86LLaVA-NeXT-interleave\u572822\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u5f02\u8868\u73b0\uff0c\u5e76\u6bd4\u8f83\u4e86\u52a0\u5165DCI\u6a21\u5757\u540e\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8LLaVA-NeXT-interleave\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u53caDCI\u6a21\u5757\u5bf9\u5176\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5728\u6807\u51c6\u6a21\u578b\u4e2d\u52a0\u5165Dense Channel Integration (DCI)\u8fde\u63a5\u5668\uff0c\u5e76\u572822\u4e2a\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u6027\u80fd\u3002", "result": "\u6807\u51c6\u6a21\u578b\u5728\u89c6\u89c9\u4efb\u52a1\u8868\u73b0\u6700\u4f73\uff0cDCI\u7248\u672c\u5728\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u7ed3\u6784\u5316\u53d8\u5316\u7406\u89e3\u4e0a\u66f4\u5f3a\u3002", "conclusion": "\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u4e0e\u5373\u63d2\u5373\u7528\u6280\u672f\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u6f5c\u529b\u5de8\u5927\u3002"}}
{"id": "2506.11794", "pdf": "https://arxiv.org/pdf/2506.11794", "abs": "https://arxiv.org/abs/2506.11794", "authors": ["Baltasar Tranc\u00f3n y Widemann", "Markus Lepper"], "title": "ALEA IACTA EST: A Declarative Domain-Specific Language for Manually Performable Random Experiments", "categories": ["cs.PL", "math.PR"], "comment": null, "summary": "Random experiments that are simple and clear enough to be performed by human\nagents feature prominently in the teaching of elementary stochastics as well as\nin games. We present Alea, a domain-specific language for the specification of\nrandom experiments. Alea code can either be analyzed statically to obtain and\ninspect probability distributions of outcomes, or be executed with a source\npseudo-randomness for simulation or as a game assistant. The language is\nintended for ease of use by non-expert programmers, in particular students of\nelementary stochastics, and players and designers of games of chance, by\nfocusing on concepts common to functional programming and basic mathematics.\nBoth the design of the language and the implementation of runtime environments\nare work in progress.", "AI": {"tldr": "Alea\u662f\u4e00\u79cd\u7528\u4e8e\u6307\u5b9a\u968f\u673a\u5b9e\u9a8c\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u9002\u5408\u975e\u4e13\u4e1a\u7a0b\u5e8f\u5458\u4f7f\u7528\uff0c\u652f\u6301\u9759\u6001\u5206\u6790\u548c\u52a8\u6001\u6267\u884c\u3002", "motivation": "\u968f\u673a\u5b9e\u9a8c\u5728\u6559\u5b66\u548c\u6e38\u620f\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u4e00\u79cd\u7b80\u5355\u4e14\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u63cf\u8ff0\u548c\u5206\u6790\u8fd9\u4e9b\u5b9e\u9a8c\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0Alea\u8bed\u8a00\uff0c\u652f\u6301\u9759\u6001\u5206\u6790\u6982\u7387\u5206\u5e03\u548c\u52a8\u6001\u6267\u884c\u6a21\u62df\uff0c\u6ce8\u91cd\u529f\u80fd\u6027\u548c\u6570\u5b66\u57fa\u7840\u7684\u7ed3\u5408\u3002", "result": "Alea\u8bed\u8a00\u4e3a\u521d\u5b66\u8005\u548c\u6e38\u620f\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u6613\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\uff0c\u4f46\u76ee\u524d\u4ecd\u5728\u5f00\u53d1\u548c\u6539\u8fdb\u4e2d\u3002", "conclusion": "Alea\u8bed\u8a00\u6709\u671b\u6210\u4e3a\u6559\u5b66\u548c\u6e38\u620f\u8bbe\u8ba1\u4e2d\u63cf\u8ff0\u968f\u673a\u5b9e\u9a8c\u7684\u6709\u7528\u5de5\u5177\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6269\u5c55\u3002"}}
{"id": "2506.11710", "pdf": "https://arxiv.org/pdf/2506.11710", "abs": "https://arxiv.org/abs/2506.11710", "authors": ["Ziren Xiao"], "title": "Generalised Rate Control Approach For Stream Processing Applications", "categories": ["cs.NI"], "comment": null, "summary": "Distributed stream processing systems are widely deployed to process\nreal-time data generated by various devices, such as sensors and software\nsystems. A key challenge in the system is overloading, which leads to an\nunstable system status and consumes additional system resources. In this paper,\nwe use a graph neural network-based deep reinforcement learning to\ncollaboratively control the data emission rate at which the data is generated\nin the stream source to proactively avoid overloading scenarios. Instead of\nusing a traditional multi-layer perceptron-styled network to control the rate,\nthe graph neural network is used to process system metrics collected from the\nstream processing engine. Consequently, the learning agent (i) avoids storing\npast states where previous actions may affect the current state, (ii) is\nwithout waiting a long interval until the current action has been fully\neffective and reflected in the system's specific metrics, and more importantly,\n(iii) is able to adapt multiple stream applications in multiple scenarios. We\ndeploy the rate control approach on three applications, and the experimental\nresults demonstrate that the throughput and end-to-end latency are improved by\nup to 13.5% and 30%, respectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u53d1\u5c04\u7387\u63a7\u5236\uff0c\u4ee5\u907f\u514d\u7cfb\u7edf\u8fc7\u8f7d\uff0c\u63d0\u5347\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u6027\u80fd\u3002", "motivation": "\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u7cfb\u7edf\u5728\u5904\u7406\u5b9e\u65f6\u6570\u636e\u65f6\u5bb9\u6613\u56e0\u8fc7\u8f7d\u5bfc\u81f4\u7cfb\u7edf\u4e0d\u7a33\u5b9a\u548c\u8d44\u6e90\u6d6a\u8d39\uff0c\u4f20\u7edf\u7684\u591a\u5c42\u611f\u77e5\u673a\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u6d41\u5904\u7406\u5f15\u64ce\u7684\u7cfb\u7edf\u6307\u6807\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u534f\u540c\u63a7\u5236\u6570\u636e\u53d1\u5c04\u7387\uff0c\u907f\u514d\u5b58\u50a8\u8fc7\u53bb\u72b6\u6001\u548c\u957f\u65f6\u95f4\u7b49\u5f85\u52a8\u4f5c\u53cd\u9988\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u5e94\u7528\u4e2d\u4f7f\u541e\u5410\u91cf\u548c\u7aef\u5230\u7aef\u5ef6\u8fdf\u5206\u522b\u63d0\u5347\u81f3\u591a13.5%\u548c30%\u3002", "conclusion": "\u56fe\u795e\u7ecf\u7f51\u7edc\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\u80fd\u6709\u6548\u4f18\u5316\u6d41\u5904\u7406\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u9002\u5e94\u591a\u573a\u666f\u591a\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2506.11118", "pdf": "https://arxiv.org/pdf/2506.11118", "abs": "https://arxiv.org/abs/2506.11118", "authors": ["Prajval Koul", "Satyadev Nandakumar"], "title": "On Effective Banach-Mazur Games and an application to the Poincar\u00e9 Recurrence Theorem for Category", "categories": ["math.LO", "cs.LO", "math.DS"], "comment": null, "summary": "The classical Banach-Mazur game characterizes sets of first category in a\ntopological space. In this work, we show that an effectivized version of the\ngame yields a characterization of sets of effective first category. Using this,\nwe give a proof for the effective Banach Category Theorem. Further, we provide\na game-theoretic proof of an effective theorem in dynamical systems, namely the\ncategory version of Poincar\\'e Recurrence. The Poincar\\'e Recurrence Theorem\nfor category states that for a homeomorphism without open wandering sets, the\nset of non recurrent points forms a first category (meager) set. As an\napplication of the effectivization of the Banach-Mazur game, we show that such\na result holds true in effective settings as well.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u6709\u6548\u5316Banach-Mazur\u6e38\u620f\uff0c\u8bc1\u660e\u4e86\u6709\u6548\u7b2c\u4e00\u8303\u7574\u96c6\u7684\u63cf\u8ff0\uff0c\u5e76\u5e94\u7528\u4e8e\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u6709\u6548Poincar\u00e9\u56de\u5f52\u5b9a\u7406\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5c06\u7ecf\u5178\u62d3\u6251\u7a7a\u95f4\u4e2d\u7684\u8303\u7574\u7406\u8bba\u6269\u5c55\u5230\u6709\u6548\u8ba1\u7b97\u9886\u57df\uff0c\u7279\u522b\u662f\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u56de\u5f52\u6027\u8d28\u3002", "method": "\u901a\u8fc7\u6709\u6548\u5316Banach-Mazur\u6e38\u620f\uff0c\u5e76\u7ed3\u5408\u52a8\u6001\u7cfb\u7edf\u7406\u8bba\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86\u6709\u6548Banach\u8303\u7574\u5b9a\u7406\u53ca\u6709\u6548Poincar\u00e9\u56de\u5f52\u5b9a\u7406\u7684\u6709\u6548\u7248\u672c\u3002", "conclusion": "\u6709\u6548\u5316\u6e38\u620f\u7406\u8bba\u4e3a\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u8303\u7574\u6027\u8d28\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u5de5\u5177\u3002"}}
{"id": "2506.11510", "pdf": "https://arxiv.org/pdf/2506.11510", "abs": "https://arxiv.org/abs/2506.11510", "authors": ["Anis Benyoub", "Jonathan Dupuy"], "title": "Adaptive Tetrahedral Grids for Volumetric Path-Tracing", "categories": ["cs.GR"], "comment": null, "summary": "We advertise the use of tetrahedral grids constructed via the longest edge\nbisection algorithm for rendering volumetric data with path tracing. The key\nbenefits of such grids is two-fold. First, they provide a highly adaptive\nspace-partitioning representation that limits the memory footprint of\nvolumetric assets. Second, each (tetrahedral) cell has exactly 4 neighbors\nwithin the volume (one per face of each tetrahedron) or less at boundaries. We\nleverage these properties to devise optimized algorithms and data-structures to\ncompute and path-trace adaptive tetrahedral grids on the GPU. In practice, our\nGPU implementation outperforms regular grids by up to x30 and renders\nproduction assets in real time at 32 samples per pixel.", "AI": {"tldr": "\u4f7f\u7528\u6700\u957f\u8fb9\u4e8c\u5206\u6cd5\u6784\u5efa\u7684\u56db\u9762\u4f53\u7f51\u683c\u7528\u4e8e\u4f53\u79ef\u6570\u636e\u8def\u5f84\u8ffd\u8e2a\uff0cGPU\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u8fbe30\u500d\u3002", "motivation": "\u89e3\u51b3\u4f53\u79ef\u6570\u636e\u6e32\u67d3\u4e2d\u5185\u5b58\u5360\u7528\u9ad8\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6700\u957f\u8fb9\u4e8c\u5206\u6cd5\u6784\u5efa\u81ea\u9002\u5e94\u56db\u9762\u4f53\u7f51\u683c\uff0c\u4f18\u5316GPU\u4e0a\u7684\u8def\u5f84\u8ffd\u8e2a\u7b97\u6cd5\u548c\u6570\u636e\u7ed3\u6784\u3002", "result": "GPU\u5b9e\u73b0\u6027\u80fd\u6bd4\u89c4\u5219\u7f51\u683c\u63d0\u534730\u500d\uff0c\u652f\u6301\u5b9e\u65f6\u6e32\u67d332\u6837\u672c/\u50cf\u7d20\u7684\u751f\u4ea7\u8d44\u4ea7\u3002", "conclusion": "\u56db\u9762\u4f53\u7f51\u683c\u5728\u4f53\u79ef\u6570\u636e\u8def\u5f84\u8ffd\u8e2a\u4e2d\u9ad8\u6548\u4e14\u8282\u7701\u5185\u5b58\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u6e32\u67d3\u3002"}}
{"id": "2506.11141", "pdf": "https://arxiv.org/pdf/2506.11141", "abs": "https://arxiv.org/abs/2506.11141", "authors": ["Philippe J. Giabbanelli", "John Beverley", "Istvan David", "Andreas Tolk"], "title": "From over-reliance to smart integration: using Large-Language Models as translators between specialized modeling and simulation tools", "categories": ["cs.SE", "cs.ET"], "comment": "Accepted at the Winter Simulation conference 2025, December, Seattle\n  USA", "summary": "Large Language Models (LLMs) offer transformative potential for Modeling &\nSimulation (M&S) through natural language interfaces that simplify workflows.\nHowever, over-reliance risks compromising quality due to ambiguities, logical\nshortcuts, and hallucinations. This paper advocates integrating LLMs as\nmiddleware or translators between specialized tools to mitigate complexity in\nM&S tasks. Acting as translators, LLMs can enhance interoperability across\nmulti-formalism, multi-semantics, and multi-paradigm systems. We address two\nkey challenges: identifying appropriate languages and tools for modeling and\nsimulation tasks, and developing efficient software architectures that\nintegrate LLMs without performance bottlenecks. To this end, the paper explores\nLLM-mediated workflows, emphasizes structured tool integration, and recommends\nLow-Rank Adaptation-based architectures for efficient task-specific\nadaptations. This approach ensures LLMs complement rather than replace\nspecialized tools, fostering high-quality, reliable M&S processes.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u4e2d\u95f4\u4ef6\u6216\u7ffb\u8bd1\u5de5\u5177\uff0c\u4ee5\u7b80\u5316\u5efa\u6a21\u4e0e\u4eff\u771f\uff08M&S\uff09\u4efb\u52a1\uff0c\u540c\u65f6\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\u5e26\u6765\u7684\u8d28\u91cf\u95ee\u9898\u3002", "motivation": "\u5229\u7528LLMs\u7684\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7b80\u5316M&S\u5de5\u4f5c\u6d41\uff0c\u4f46\u9700\u907f\u514d\u56e0\u5176\u6a21\u7cca\u6027\u3001\u903b\u8f91\u6377\u5f84\u548c\u5e7b\u89c9\u95ee\u9898\u800c\u5f71\u54cd\u8d28\u91cf\u3002", "method": "\u5c06LLMs\u4f5c\u4e3a\u4e2d\u95f4\u4ef6\u6216\u7ffb\u8bd1\u5de5\u5177\u96c6\u6210\u5230\u4e13\u95e8\u5de5\u5177\u4e2d\uff0c\u5f00\u53d1\u9ad8\u6548\u8f6f\u4ef6\u67b6\u6784\uff0c\u5e76\u91c7\u7528\u4f4e\u79e9\u9002\u5e94\uff08Low-Rank Adaptation\uff09\u65b9\u6cd5\u8fdb\u884c\u4efb\u52a1\u9002\u914d\u3002", "result": "LLMs\u80fd\u591f\u63d0\u5347\u4e0d\u540c\u5f62\u5f0f\u3001\u8bed\u4e49\u548c\u8303\u5f0f\u7cfb\u7edf\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u540c\u65f6\u4f18\u5316M&S\u4efb\u52a1\u7684\u5de5\u4f5c\u6548\u7387\u3002", "conclusion": "LLMs\u5e94\u4f5c\u4e3a\u4e13\u95e8\u5de5\u5177\u7684\u8865\u5145\u800c\u975e\u66ff\u4ee3\uff0c\u4ee5\u786e\u4fdd\u9ad8\u8d28\u91cf\u548c\u53ef\u9760\u7684M&S\u6d41\u7a0b\u3002"}}
{"id": "2506.11366", "pdf": "https://arxiv.org/pdf/2506.11366", "abs": "https://arxiv.org/abs/2506.11366", "authors": ["Alemitu Bezabih", "Shadi Nourriz", "Anne-Marie Snider", "Rosalie Rauenzahn", "C. Estelle Smith"], "title": "Meeting Patients Where They're At: Toward the Expansion of Chaplaincy Care into Online Spiritual Care Communities", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Despite a growing need for spiritual care in the US, it is often\nunder-served, inaccessible, or misunderstood, while almost no prior work in\nCSCW/HCI research has engaged with professional chaplains and spiritual care\nproviders. This interdisciplinary study aims to develop a foundational\nunderstanding of how spiritual care may (or may not) be expanded into online\nspaces -- especially focusing on anonymous, asynchronous, and text-based online\ncommunities. We conducted an exploratory mixed-methods study with chaplains\n(N=22) involving interviews and user testing sessions centered around Reddit\nsupport communities to understand participants' perspectives on technology and\ntheir ideations about the role of chaplaincy in prospective Online Spiritual\nCare Communities (OSCCs). Our Grounded Theory Method analysis highlighted\nbenefits of OSCCs including: meeting patients where they are at; accessibility\nand scalability; and facilitating patient-initiated care. Chaplains highlighted\nhow their presence in OSCCs could help with shaping peer interactions,\nmoderation, synchronous chats for group care, and redirecting to external\nresources, while also raising important feasibility concerns, risks, and needs\nfor future design and research. We used an existing taxonomy of chaplaincy\ntechniques to show that some spiritual care strategies may be amenable to\nonline spaces, yet we also exposed the limitations of technology to fully\nmediate spiritual care and the need to develop new online chaplaincy\ninterventions. Based on these findings, we contribute the model of a ``Care\nLoop'' between institutionally-based formal care and platform-based community\ncare to expand access and drive greater awareness and utilization of spiritual\ncare. We also contribute design implications to guide future work in online\nspiritual care.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u5c06\u7cbe\u795e\u62a4\u7406\u6269\u5c55\u5230\u5728\u7ebf\u7a7a\u95f4\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7814\u7a7622\u540d\u7267\u5e08\uff0c\u53d1\u73b0\u5728\u7ebf\u7cbe\u795e\u62a4\u7406\u793e\u533a\uff08OSCCs\uff09\u7684\u6f5c\u5728\u597d\u5904\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u6280\u672f\u9650\u5236\u548c\u672a\u6765\u8bbe\u8ba1\u9700\u6c42\uff0c\u63d0\u51fa\u4e86\u201c\u62a4\u7406\u5faa\u73af\u201d\u6a21\u578b\u548c\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u7cbe\u795e\u62a4\u7406\u5728\u7f8e\u56fd\u9700\u6c42\u589e\u957f\u4f46\u670d\u52a1\u4e0d\u8db3\uff0c\u4e14CSCW/HCI\u7814\u7a76\u5c11\u6709\u6d89\u53ca\u4e13\u4e1a\u7267\u5e08\u548c\u7cbe\u795e\u62a4\u7406\u63d0\u4f9b\u8005\uff0c\u7814\u7a76\u65e8\u5728\u7406\u89e3\u5982\u4f55\u5c06\u7cbe\u795e\u62a4\u7406\u62d3\u5c55\u5230\u5728\u7ebf\u7a7a\u95f4\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u8bbf\u8c08\u548c\u7528\u6237\u6d4b\u8bd5\uff0c\u5bf922\u540d\u7267\u5e08\u8fdb\u884c\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u4f7f\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\u5206\u6790\u6570\u636e\u3002", "result": "\u53d1\u73b0OSCCs\u7684\u597d\u5904\uff08\u5982\u53ef\u8bbf\u95ee\u6027\u3001\u53ef\u6269\u5c55\u6027\uff09\u548c\u6311\u6218\uff08\u5982\u6280\u672f\u9650\u5236\uff09\uff0c\u63d0\u51fa\u201c\u62a4\u7406\u5faa\u73af\u201d\u6a21\u578b\u548c\u65b0\u5e72\u9884\u63aa\u65bd\u7684\u8bbe\u8ba1\u9700\u6c42\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u7ebf\u7cbe\u795e\u62a4\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u8bbe\u8ba1\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u6280\u672f\u4e0e\u793e\u533a\u62a4\u7406\u7ed3\u5408\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.11441", "pdf": "https://arxiv.org/pdf/2506.11441", "abs": "https://arxiv.org/abs/2506.11441", "authors": ["Guoyu Li", "Pengbo Zheng", "Jian Weng", "Enshan Yang"], "title": "DPUV4E: High-Throughput DPU Architecture Design for CNN on Versal ACAP", "categories": ["cs.AR", "cs.AI"], "comment": "10 pages, 9 figures", "summary": "Convolutional Neural Networks (CNNs) remain prevalent in computer vision\napplications, and FPGAs, known for their flexibility and energy efficiency,\nhave become essential components in heterogeneous acceleration systems.\nHowever, traditional FPGAs face challenges in balancing performance and\nversatility due to limited on-chip resources. AMD's Versal ACAP architecture,\ntailored for AI applications, incorporates AI Engines (AIEs) to deliver high\ncomputational power. Nevertheless, the platform suffers from insufficient\nmemory bandwidth, hindering the full utilization of the AIEs' theoretical\nperformance. In this paper, we present DPUV4E for the Versal architecture,\nproviding configurations ranging from 2PE ($32.6$ TOPS) to 8PE ($131.0$ TOPS).\nWe design two computation units, Conv PE and DWC PE, to support different\ncomputational patterns. Each computation unit's data flow efficiently utilizes\nthe data reuse opportunities to mitigate bandwidth bottlenecks. Additionally,\nwe extend the functionality of each PE to utilize AIEs for non-convolutional\noperations, reducing resource overhead. Experiments on over 50 models show that\ncompared to previous designs, our design provides $8.6\\times$ the TOPS/W of\ntraditional FPGA-based DPU designs, while reducing DSP usage by $95.8\\%$, LUT\nusage by $44.7\\%$, and latency to $68.5\\%$ under single-batch conditions. For\nend-to-end inference, our design improving throughput by up to $2.2\\times$ for\ndepth-wise convolution models and up to $1.3\\times$ for standard models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDPUV4E\u7684\u65b0\u8bbe\u8ba1\uff0c\u9488\u5bf9AMD Versal ACAP\u67b6\u6784\uff0c\u901a\u8fc7\u4f18\u5316\u8ba1\u7b97\u5355\u5143\u548c\u6570\u636e\u6d41\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u4e0e\u80fd\u6548\u6bd4\u3002", "motivation": "\u4f20\u7edfFPGA\u5728\u6027\u80fd\u548c\u7075\u6d3b\u6027\u4e4b\u95f4\u5b58\u5728\u8d44\u6e90\u9650\u5236\uff0c\u800cAMD Versal ACAP\u67b6\u6784\u7684AI Engines\u867d\u5177\u5907\u9ad8\u8ba1\u7b97\u80fd\u529b\uff0c\u5374\u53d7\u9650\u4e8e\u5185\u5b58\u5e26\u5bbd\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bbe\u8ba1\u6765\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u79cd\u8ba1\u7b97\u5355\u5143\uff08Conv PE\u548cDWC PE\uff09\u4ee5\u652f\u6301\u4e0d\u540c\u8ba1\u7b97\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u9ad8\u6548\u6570\u636e\u6d41\u51cf\u5c11\u5e26\u5bbd\u74f6\u9888\u3002\u540c\u65f6\uff0c\u6269\u5c55\u4e86PE\u7684\u529f\u80fd\u4ee5\u5229\u7528AIEs\u6267\u884c\u975e\u5377\u79ef\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u8bbe\u8ba1\u5728\u80fd\u6548\u6bd4\uff08TOPS/W\uff09\u4e0a\u63d0\u5347\u4e868.6\u500d\uff0c\u8d44\u6e90\u5360\u7528\u663e\u8457\u964d\u4f4e\uff08DSP\u51cf\u5c1195.8%\uff0cLUT\u51cf\u5c1144.7%\uff09\uff0c\u5e76\u7f29\u77ed\u4e86\u5ef6\u8fdf\u3002\u7aef\u5230\u7aef\u63a8\u7406\u541e\u5410\u91cf\u63d0\u5347\u4e861.3\u81f32.2\u500d\u3002", "conclusion": "DPUV4E\u8bbe\u8ba1\u6210\u529f\u89e3\u51b3\u4e86AMD Versal ACAP\u67b6\u6784\u7684\u5185\u5b58\u5e26\u5bbd\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u3002"}}
{"id": "2506.11870", "pdf": "https://arxiv.org/pdf/2506.11870", "abs": "https://arxiv.org/abs/2506.11870", "authors": ["Ce Lyu", "Minghao Zhao", "Yanhao Wang", "Liang Jie"], "title": "LLM-based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection", "categories": ["cs.DB", "68N99", "H.2.4; D.2.5"], "comment": "5 pages", "summary": "Database connectors are critical components enabling applications to interact\nwith underlying database management systems (DBMS), yet their security\nvulnerabilities often remain overlooked. Unlike traditional software defects,\nconnector vulnerabilities exhibit subtle behavioral patterns and are inherently\nchallenging to detect. Besides, nonstandardized implementation of connectors\nleaves potential risks (a.k.a. unsafe implementations) but is more elusive. As\na result, traditional fuzzing methods are incapable of finding such\nvulnerabilities. Even for LLM-enable test case generation, due to a lack of\ndomain knowledge, they are also incapable of generating test cases that invoke\nall interface and internal logic of connectors. In this paper, we propose\nreinforcement learning (RL)-guided LLM test-case generation for database\nconnector testing. Specifically, to equip the LLM with sufficient and\nappropriate domain knowledge, a parameterized prompt template is composed which\ncan be utilized to generate numerous prompts. Test cases are generated via LLM\nwith a prompt, and are dynamically evaluated through differential testing\nacross multiple connectors. The testing is iteratively conducted, with each\nround RL is adopted to select optimal prompt based on prior-round behavioral\nfeedback, so as to maximize control flow coverage. We implement aforementioned\nmethodology in a practical tool and evaluate it on two widely used JDBC\nconnectors: MySQL Connector/J and OceanBase Connector/J. In total, we reported\n16 bugs, among them 10 are officially confirmed and the rest are acknowledged\nas unsafe implementations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5f15\u5bfc\u7684LLM\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u6570\u636e\u5e93\u8fde\u63a5\u5668\u6f0f\u6d1e\u3002", "motivation": "\u6570\u636e\u5e93\u8fde\u63a5\u5668\u7684\u5b89\u5168\u6f0f\u6d1e\u5e38\u88ab\u5ffd\u89c6\uff0c\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u548cLLM\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u3002", "method": "\u901a\u8fc7\u53c2\u6570\u5316\u63d0\u793a\u6a21\u677f\u4e3aLLM\u63d0\u4f9b\u9886\u57df\u77e5\u8bc6\uff0c\u7ed3\u5408\u52a8\u6001\u5dee\u5f02\u6d4b\u8bd5\u548cRL\u4f18\u5316\u63d0\u793a\u9009\u62e9\uff0c\u6700\u5927\u5316\u63a7\u5236\u6d41\u8986\u76d6\u7387\u3002", "result": "\u5728MySQL\u548cOceanBase\u7684JDBC\u8fde\u63a5\u5668\u4e0a\u53d1\u73b0\u4e8616\u4e2a\u6f0f\u6d1e\uff0c\u5176\u4e2d10\u4e2a\u88ab\u5b98\u65b9\u786e\u8ba4\u3002", "conclusion": "RL\u5f15\u5bfc\u7684LLM\u6d4b\u8bd5\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u8fde\u63a5\u5668\u6f0f\u6d1e\uff0c\u5f25\u8865\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.11644", "pdf": "https://arxiv.org/pdf/2506.11644", "abs": "https://arxiv.org/abs/2506.11644", "authors": ["Ran Ben Basat", "Keren Censor-Hillel", "Yi-Jun Chang", "Wenchen Han", "Dean Leitersdorf", "Gregory Schwartzman"], "title": "Bounded Memory in Distributed Networks", "categories": ["cs.DC", "cs.DS"], "comment": "Accepted at The 37th ACM Symposium on Parallelism in Algorithms and\n  Architectures (SPAA '25). 22 pages", "summary": "The recent advent of programmable switches makes distributed algorithms\nreadily deployable in real-world datacenter networks. However, there are still\ngaps between theory and practice that prevent the smooth adaptation of CONGEST\nalgorithms to these environments. In this paper, we focus on the memory\nrestrictions that arise in real-world deployments. We introduce the\n$\\mu$-CONGEST model where on top of the bandwidth restriction, the memory of\nnodes is also limited to $\\mu$ words, in line with real-world systems. We\nprovide fast algorithms of two main flavors.\n  First, we observe that many algorithms in the CONGEST model are\nmemory-intensive and do not work in $\\mu$-CONGEST. A prime example of a family\nof algorithms that use large memory is clique-listing algorithms. We show that\nthe memory issue that arises here cannot be resolved without incurring a cost\nin the round complexity, by establishing a lower bound on the round complexity\nof listing cliques in $\\mu$-CONGEST. We introduce novel techniques to overcome\nthese issues and generalize the algorithms to work within a given memory bound.\nCombined with our lower bound, these provide tight tradeoffs between the\nrunning time and memory of nodes.\n  Second, we show that it is possible to efficiently simulate various families\nof streaming algorithms in $\\mu$-CONGEST. These include fast simulations of\n$p$-pass algorithms, random order streams, and various types of mergeable\nstreaming algorithms.\n  Combining our contributions, we show that we can use streaming algorithms to\nefficiently generate statistics regarding combinatorial structures in the\nnetwork. An example of an end result of this type is that we can efficiently\nidentify and provide the per-color frequencies of the frequent monochromatic\ntriangles in $\\mu$-CONGEST.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u03bc-CONGEST\u6a21\u578b\uff0c\u89e3\u51b3\u4e86CONGEST\u7b97\u6cd5\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u56e0\u5185\u5b58\u9650\u5236\u5f15\u8d77\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5feb\u901f\u7b97\u6cd5\uff1a\u6539\u8fdb\u5185\u5b58\u5bc6\u96c6\u578b\u7b97\u6cd5\u548c\u9ad8\u6548\u6a21\u62df\u6d41\u7b97\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u4e2d\u7684\u53ef\u7f16\u7a0b\u4ea4\u6362\u673a\u867d\u7136\u4fbf\u4e8e\u90e8\u7f72\u5206\u5e03\u5f0f\u7b97\u6cd5\uff0c\u4f46CONGEST\u7b97\u6cd5\u4ecd\u9762\u4e34\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u5c24\u5176\u662f\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u03bc-CONGEST\u6a21\u578b\uff0c\u7ed3\u5408\u5e26\u5bbd\u548c\u5185\u5b58\u9650\u5236\uff08\u03bc\u5b57\uff09\uff1b\u8bbe\u8ba1\u6539\u8fdb\u7684\u5185\u5b58\u5bc6\u96c6\u578b\u7b97\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e0b\u9650\u8bc1\u660e\uff1b\u9ad8\u6548\u6a21\u62df\u591a\u79cd\u6d41\u7b97\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u7b97\u6cd5\u8fd0\u884c\u65f6\u95f4\u4e0e\u8282\u70b9\u5185\u5b58\u4e4b\u95f4\u7684\u7d27\u81f4\u6743\u8861\u5173\u7cfb\uff1b\u5c55\u793a\u4e86\u6d41\u7b97\u6cd5\u5728\u03bc-CONGEST\u4e2d\u7684\u9ad8\u6548\u6a21\u62df\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u03bc-CONGEST\u6a21\u578b\u53ca\u76f8\u5e94\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u5185\u5b58\u9650\u5236\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u4e86\u6d41\u7b97\u6cd5\u5728\u7f51\u7edc\u7edf\u8ba1\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2506.10990", "pdf": "https://arxiv.org/pdf/2506.10990", "abs": "https://arxiv.org/abs/2506.10990", "authors": ["Roberto Vergallo", "Lu\u00eds Cruz", "Alessio Errico", "Luca Mainetti"], "title": "On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.DC", "I.2.0"], "comment": "24 pages, 4 figures, 10 tables", "summary": "'Follow-the-Sun' (FtS) is a theoretical computational model aimed at\nminimizing the carbon footprint of computer workloads. It involves dynamically\nmoving workloads to regions with cleaner energy sources as demand increases and\nenergy production relies more on fossil fuels. With the significant power\nconsumption of Artificial Intelligence (AI) being a subject of extensive\ndebate, FtS is proposed as a strategy to mitigate the carbon footprint of\ntraining AI models. However, the literature lacks scientific evidence on the\nadvantages of FtS to mitigate the carbon footprint of AI workloads. In this\npaper, we present the results of an experiment conducted in a partial synthetic\nscenario to address this research gap. We benchmarked four AI algorithms in the\nanomaly detection domain and measured the differences in carbon emissions in\nfour cases: no strategy, FtS, and two strategies previously introduced in the\nstate of the art, namely Flexible Start and Pause and Resume. To conduct our\nexperiment, we utilized historical carbon intensity data from the year 2021 for\nseven European cities. Our results demonstrate that the FtS strategy not only\nachieves average reductions of up to 14.6% in carbon emissions (with peaks of\n16.3%) but also helps in preserving the time needed for training.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86'Follow-the-Sun' (FtS)\u7b56\u7565\u5728\u964d\u4f4eAI\u5de5\u4f5c\u8d1f\u8f7d\u78b3\u8db3\u8ff9\u65b9\u9762\u7684\u6548\u679c\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u5176\u4ed6\u7b56\u7565\u3002", "motivation": "AI\u7684\u9ad8\u80fd\u8017\u95ee\u9898\u5f15\u53d1\u5e7f\u6cdb\u8ba8\u8bba\uff0c\u4f46\u7f3a\u4e4f\u79d1\u5b66\u8bc1\u636e\u652f\u6301FtS\u7b56\u7565\u5728\u51cf\u5c11\u78b3\u8db3\u8ff9\u65b9\u9762\u7684\u4f18\u52bf\u3002", "method": "\u5728\u90e8\u5206\u5408\u6210\u573a\u666f\u4e0b\uff0c\u5bf9\u56db\u79cd\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u65e0\u7b56\u7565\u3001FtS\u53ca\u4e24\u79cd\u73b0\u6709\u7b56\u7565\u7684\u78b3\u6392\u653e\u5dee\u5f02\u3002", "result": "FtS\u7b56\u7565\u5e73\u5747\u51cf\u5c1114.6%\u78b3\u6392\u653e\uff08\u5cf0\u503c\u8fbe16.3%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u8bad\u7ec3\u65f6\u95f4\u4e0d\u53d8\u3002", "conclusion": "FtS\u7b56\u7565\u80fd\u6709\u6548\u964d\u4f4eAI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u78b3\u8db3\u8ff9\uff0c\u4e3a\u53ef\u6301\u7eed\u53d1\u5c55\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2506.11934", "pdf": "https://arxiv.org/pdf/2506.11934", "abs": "https://arxiv.org/abs/2506.11934", "authors": ["Salvatore Citraro", "Giovanni Mauro", "Emanuele Ferragina"], "title": "Temporal Dynamics of Emotions in Italian Online Soccer Fandoms", "categories": ["cs.SI", "cs.MM"], "comment": null, "summary": "This study investigates the emotional dynamics of Italian soccer fandoms\nthrough computational analysis of user-generated content from official\nInstagram accounts of 83 teams across Serie A, Serie B, and Lega Pro during the\n2023-24 season. By applying sentiment analysis to fan comments, we extract\ntemporal emotional patterns and identify distinct clusters of fan bases with\nsimilar preseason expectations. Drawing from complex systems theory, we\ncharacterize joy as displaying anti-bursty temporal distributions, while anger\nis marked by pronounced bursty patterns. Our analysis reveals significant\ncorrelations between these emotional signals, preseason expectations,\nsocioeconomic factors, and final league rankings. In particular, the burstiness\nmetric emerges as a meaningful correlate of team performance; statistical\nmodels excluding this parameter show a decrease in the coefficient of\ndetermination of 32%. These findings offer novel insights into the relationship\nbetween fan emotional expression and team outcomes, suggesting potential\navenues for research in sports analytics, social media dynamics, and fan\nengagement studies.", "AI": {"tldr": "\u901a\u8fc7\u8ba1\u7b97\u5206\u67902023-24\u8d5b\u5b63\u610f\u5927\u5229\u8db3\u7403\u8054\u8d5b\u7c89\u4e1d\u5728Instagram\u4e0a\u7684\u8bc4\u8bba\uff0c\u7814\u7a76\u53d1\u73b0\u60c5\u7eea\u52a8\u6001\u4e0e\u7403\u961f\u8868\u73b0\u76f8\u5173\uff0c\u6124\u6012\u60c5\u7eea\u7206\u53d1\u6027\u663e\u8457\u76f8\u5173\u3002", "motivation": "\u63a2\u7a76\u8db3\u7403\u7c89\u4e1d\u60c5\u7eea\u52a8\u6001\u4e0e\u7403\u961f\u8868\u73b0\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u60c5\u611f\u8868\u8fbe\u6a21\u5f0f\u3002", "method": "\u5bf983\u652f\u7403\u961f\u5b98\u65b9Instagram\u7684\u7c89\u4e1d\u8bc4\u8bba\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0c\u63d0\u53d6\u60c5\u7eea\u65f6\u95f4\u5206\u5e03\u6a21\u5f0f\uff0c\u5e76\u7ed3\u5408\u590d\u6742\u7cfb\u7edf\u7406\u8bba\u5206\u6790\u3002", "result": "\u6124\u6012\u60c5\u7eea\u7206\u53d1\u6027\u4e0e\u7403\u961f\u8868\u73b0\u663e\u8457\u76f8\u5173\uff0c\u6392\u9664\u6b64\u53c2\u6570\u540e\u7edf\u8ba1\u6a21\u578b\u89e3\u91ca\u529b\u4e0b\u964d32%\u3002", "conclusion": "\u7c89\u4e1d\u60c5\u7eea\u8868\u8fbe\u4e0e\u7403\u961f\u6210\u7ee9\u76f8\u5173\uff0c\u4e3a\u4f53\u80b2\u5206\u6790\u548c\u7c89\u4e1d\u4e92\u52a8\u7814\u7a76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.11027", "pdf": "https://arxiv.org/pdf/2506.11027", "abs": "https://arxiv.org/abs/2506.11027", "authors": ["Federico Pennino", "Bianca Raimondi", "Massimo Rondelli", "Andrea Gurioli", "Maurizio Gabbrielli"], "title": "From Reasoning to Code: GRPO Optimization for Underrepresented Languages", "categories": ["cs.LG", "cs.AI", "cs.PL"], "comment": "Preprint. Under review", "summary": "Generating accurate and executable code using large language models (LLMs) is\nchallenging for languages with limited public training data compared to popular\nlanguages such as Python. This paper introduces a generalizable approach that\nuses small-scale code versions of the Qwen 2.5 model combined with Group\nRelative Policy Optimization (GRPO) to enable effective code generation through\nexplicit reasoning steps, which is particularly beneficial for languages with\nsmaller source code databases. Using Prolog as a representative use case --\ngiven its limited online presence -- the initial model faced challenges in\ngenerating executable code. After some training steps, the model successfully\nproduces logically consistent and syntactically accurate code by directly\nintegrating reasoning-driven feedback into the reinforcement learning loop.\nExperimental evaluations using mathematical logic problem benchmarks illustrate\nsignificant improvements in reasoning quality, code accuracy, and logical\ncorrectness, underscoring the potential of this approach to benefit a wide\nrange of programming languages lacking extensive training resources.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7ed3\u5408\u5c0f\u89c4\u6a21\u4ee3\u7801\u6a21\u578b\u548cGRPO\u65b9\u6cd5\uff0c\u4e3a\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Prolog\uff09\u751f\u6210\u9ad8\u8d28\u91cf\u53ef\u6267\u884c\u4ee3\u7801\u7684\u901a\u7528\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u56e0\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u800c\u96be\u4ee5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u5c0f\u4f17\u7f16\u7a0b\u8bed\u8a00\u751f\u6210\u51c6\u786e\u53ef\u6267\u884c\u4ee3\u7801\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528Qwen 2.5\u7684\u5c0f\u89c4\u6a21\u4ee3\u7801\u6a21\u578b\u7ed3\u5408GRPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u751f\u6210\u4ee3\u7801\uff0c\u5e76\u5728\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4e2d\u6574\u5408\u63a8\u7406\u9a71\u52a8\u7684\u53cd\u9988\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6570\u5b66\u903b\u8f91\u95ee\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u7684\u51c6\u786e\u6027\u3001\u903b\u8f91\u6b63\u786e\u6027\u548c\u63a8\u7406\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7f3a\u4e4f\u5927\u89c4\u6a21\u8bad\u7ec3\u8d44\u6e90\u7684\u7f16\u7a0b\u8bed\u8a00\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4ee3\u7801\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.11738", "pdf": "https://arxiv.org/pdf/2506.11738", "abs": "https://arxiv.org/abs/2506.11738", "authors": ["H. P. Keeler", "B. B\u0142aszczyszyn"], "title": "Adaptive determinantal scheduling with fairness in wireless networks", "categories": ["cs.NI", "cs.DS"], "comment": "8 pages, 2 plots, 1 diagram. WiOpt 2025", "summary": "We propose a novel framework for wireless network scheduling with fairness\nusing determinantal (point) processes. Our approach incorporates the repulsive\nnature of determinantal processes, generalizing traditional Aloha protocols\nthat schedule transmissions independently. We formulate the scheduling problem\nwith an utility function representing fairness. We then recast this formulation\nas a convex optimization problem over a certain class of determinantal point\nprocesses called $L$-ensembles, which are particularly suited for statistical\nand numerical treatments. These determinantal processes, which have already\nproven valuable in subset learning, offer an attractive approach to network\nresource scheduling and allocating. We demonstrate the suitability of\ndeterminantal processes for network models based on the\nsignal-to-interference-plus-noise ratio (SINR). Our results highlight the\npotential of determinantal scheduling coupled with fairness. This work bridges\nrecent advances in machine learning with wireless communications, providing a\nmathematically elegant and computationally tractable approach to network\nscheduling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u7684\u65e0\u7ebf\u7f51\u7edc\u8c03\u5ea6\u6846\u67b6\uff0c\u7ed3\u5408\u516c\u5e73\u6027\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u95ee\u9898\u89e3\u51b3\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684Aloha\u534f\u8bae\u72ec\u7acb\u8c03\u5ea6\u4f20\u8f93\uff0c\u7f3a\u4e4f\u516c\u5e73\u6027\u3002\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u7684\u6392\u65a5\u7279\u6027\u9002\u5408\u7f51\u7edc\u8d44\u6e90\u8c03\u5ea6\u3002", "method": "\u5c06\u8c03\u5ea6\u95ee\u9898\u8f6c\u5316\u4e3a\u9488\u5bf9\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528$L$-ensembles\u8fdb\u884c\u7edf\u8ba1\u548c\u6570\u503c\u5904\u7406\u3002", "result": "\u8bc1\u660e\u4e86\u884c\u5217\u5f0f\u8c03\u5ea6\u5728\u57fa\u4e8eSINR\u7684\u7f51\u7edc\u6a21\u578b\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u516c\u5e73\u6027\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u673a\u5668\u5b66\u4e60\u4e0e\u65e0\u7ebf\u901a\u4fe1\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u6570\u5b66\u4f18\u96c5\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u7f51\u7edc\u8c03\u5ea6\u65b9\u6cd5\u3002"}}
{"id": "2506.11221", "pdf": "https://arxiv.org/pdf/2506.11221", "abs": "https://arxiv.org/abs/2506.11221", "authors": ["Weibing Zheng", "Laurah Turner", "Jess Kropczynski", "Murat Ozer", "Tri Nguyen", "Shane Halse"], "title": "LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical Evaluation Judge with Fuzzy Logic", "categories": ["cs.AI", "cs.CL", "cs.LO", "D.2.4; K.3.1; C.3; I.2.6"], "comment": "12 pages, 1 figure, 2025 IFSA World Congress NAFIPS Annual Meeting", "summary": "Clinical communication skills are critical in medical education, and\npracticing and assessing clinical communication skills on a scale is\nchallenging. Although LLM-powered clinical scenario simulations have shown\npromise in enhancing medical students' clinical practice, providing automated\nand scalable clinical evaluation that follows nuanced physician judgment is\ndifficult. This paper combines fuzzy logic and Large Language Model (LLM) and\nproposes LLM-as-a-Fuzzy-Judge to address the challenge of aligning the\nautomated evaluation of medical students' clinical skills with subjective\nphysicians' preferences. LLM-as-a-Fuzzy-Judge is an approach that LLM is\nfine-tuned to evaluate medical students' utterances within student-AI patient\nconversation scripts based on human annotations from four fuzzy sets, including\nProfessionalism, Medical Relevance, Ethical Behavior, and Contextual\nDistraction. The methodology of this paper started from data collection from\nthe LLM-powered medical education system, data annotation based on\nmultidimensional fuzzy sets, followed by prompt engineering and the supervised\nfine-tuning (SFT) of the pre-trained LLMs using these human annotations. The\nresults show that the LLM-as-a-Fuzzy-Judge achieves over 80\\% accuracy, with\nmajor criteria items over 90\\%, effectively leveraging fuzzy logic and LLM as a\nsolution to deliver interpretable, human-aligned assessment. This work suggests\nthe viability of leveraging fuzzy logic and LLM to align with human\npreferences, advances automated evaluation in medical education, and supports\nmore robust assessment and judgment practices. The GitHub repository of this\nwork is available at https://github.com/2sigmaEdTech/LLMAsAJudge", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u7cca\u903b\u8f91\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5LLM-as-a-Fuzzy-Judge\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bc4\u4f30\u533b\u5b66\u751f\u7684\u4e34\u5e8a\u6c9f\u901a\u6280\u80fd\uff0c\u5e76\u4f7f\u5176\u66f4\u7b26\u5408\u533b\u751f\u7684\u4e3b\u89c2\u5224\u65ad\u3002", "motivation": "\u4e34\u5e8a\u6c9f\u901a\u6280\u80fd\u5bf9\u533b\u5b66\u6559\u80b2\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5927\u89c4\u6a21\u5b9e\u8df5\u548c\u8bc4\u4f30\u8fd9\u4e9b\u6280\u80fd\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u7684LLM\u9a71\u52a8\u7684\u4e34\u5e8a\u573a\u666f\u6a21\u62df\u867d\u6709\u4e00\u5b9a\u6548\u679c\uff0c\u4f46\u5728\u63d0\u4f9b\u7b26\u5408\u533b\u751f\u4e3b\u89c2\u5224\u65ad\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "method": "\u901a\u8fc7\u6570\u636e\u6536\u96c6\u3001\u57fa\u4e8e\u591a\u7ef4\u6a21\u7cca\u96c6\u7684\u6570\u636e\u6807\u6ce8\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u9884\u8bad\u7ec3\u7684LLM\uff0c\u6784\u5efa\u4e86LLM-as-a-Fuzzy-Judge\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u4e3b\u8981\u8bc4\u4f30\u9879\u76ee\u4e0a\u51c6\u786e\u7387\u8d85\u8fc790%\uff0c\u6574\u4f53\u51c6\u786e\u7387\u8d85\u8fc780%\uff0c\u80fd\u591f\u63d0\u4f9b\u53ef\u89e3\u91ca\u4e14\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u7684\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u5b9e\u4e86\u7ed3\u5408\u6a21\u7cca\u903b\u8f91\u548cLLM\u7684\u53ef\u884c\u6027\uff0c\u63a8\u52a8\u4e86\u533b\u5b66\u6559\u80b2\u4e2d\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u652f\u6301\u66f4\u7a33\u5065\u7684\u8bc4\u4f30\u5b9e\u8df5\u3002"}}
{"id": "2506.11546", "pdf": "https://arxiv.org/pdf/2506.11546", "abs": "https://arxiv.org/abs/2506.11546", "authors": ["Akshay Jindal", "Nabil Sadaka", "Manu Mathew Thomas", "Anton Sochenov", "Anton Kaplanyan"], "title": "CGVQM+D: Computer Graphics Video Quality Metric and Dataset", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "While existing video and image quality datasets have extensively studied\nnatural videos and traditional distortions, the perception of synthetic content\nand modern rendering artifacts remains underexplored. We present a novel video\nquality dataset focused on distortions introduced by advanced rendering\ntechniques, including neural supersampling, novel-view synthesis, path tracing,\nneural denoising, frame interpolation, and variable rate shading. Our\nevaluations show that existing full-reference quality metrics perform\nsub-optimally on these distortions, with a maximum Pearson correlation of 0.78.\nAdditionally, we find that the feature space of pre-trained 3D CNNs aligns\nstrongly with human perception of visual quality. We propose CGVQM, a\nfull-reference video quality metric that significantly outperforms existing\nmetrics while generating both per-pixel error maps and global quality scores.\nOur dataset and metric implementation is available at\nhttps://github.com/IntelLabs/CGVQM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u9ad8\u7ea7\u6e32\u67d3\u6280\u672f\u5f15\u5165\u7684\u5931\u771f\u7684\u89c6\u9891\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u7684\u8d28\u91cf\u5ea6\u91cf\u6807\u51c6CGVQM\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u5408\u6210\u5185\u5bb9\u548c\u73b0\u4ee3\u6e32\u67d3\u5931\u771f\u7684\u89c6\u89c9\u8d28\u91cf\uff0c\u586b\u8865\u73b0\u6709\u6570\u636e\u96c6\u5728\u81ea\u7136\u89c6\u9891\u548c\u4f20\u7edf\u5931\u771f\u4e4b\u5916\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u65b0\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u73b0\u6709\u6307\u6807\uff0c\u63d0\u51fa\u57fa\u4e8e\u9884\u8bad\u7ec33D CNN\u7279\u5f81\u7684CGVQM\u5ea6\u91cf\u6807\u51c6\u3002", "result": "CGVQM\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6307\u6807\uff0cPearson\u76f8\u5173\u7cfb\u6570\u6700\u9ad8\u8fbe0.78\u3002", "conclusion": "\u65b0\u578b\u6570\u636e\u96c6\u548cCGVQM\u4e3a\u5408\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.11176", "pdf": "https://arxiv.org/pdf/2506.11176", "abs": "https://arxiv.org/abs/2506.11176", "authors": ["Anatoly A. Krasnovsky", "Alexander Zorkin"], "title": "Model Discovery and Graph Simulation: A Lightweight Alternative to Chaos Engineering", "categories": ["cs.SE", "cs.DC", "cs.DM", "cs.ET"], "comment": null, "summary": "Microservice applications are prone to cascading failures because of dense\ninter-service dependencies. Ensuring resilience usually demands fault-injection\nexperiments in production-like setups. We propose \\textit{model discovery} --\nan automated CI/CD step that extracts a live dependency graph from trace data\n-- and show that this lightweight representation is sufficient for accurate\nresilience prediction. Using the DeathStarBench Social Network, we build the\ngraph, simulate failures via Monte-Carlo, and run matching chaos experiments on\nthe real system. The graph model closely matches reality: with no replication,\n16 trials yield an observed resilience of 0.186 versus a predicted 0.161; with\nreplication, both observed and predicted values converge to 0.305 (mean\nabsolute error \\leq 0.0004). These results indicate that even a simple,\nautomatically discovered graph can estimate microservice availability with high\nfidelity, offering rapid design-time insight without full-scale failure\ntesting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6a21\u578b\u53d1\u73b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u8ddf\u8e2a\u6570\u636e\u4e2d\u63d0\u53d6\u5b9e\u65f6\u4f9d\u8d56\u56fe\u6765\u9884\u6d4b\u5fae\u670d\u52a1\u5e94\u7528\u7684\u5f39\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u51c6\u786e\u4e14\u9ad8\u6548\u3002", "motivation": "\u5fae\u670d\u52a1\u5e94\u7528\u56e0\u5bc6\u96c6\u7684\u670d\u52a1\u95f4\u4f9d\u8d56\u5bb9\u6613\u53d1\u751f\u7ea7\u8054\u6545\u969c\uff0c\u4f20\u7edf\u5f39\u6027\u6d4b\u8bd5\u9700\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u8fdb\u884c\u6545\u969c\u6ce8\u5165\u5b9e\u9a8c\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u8017\u65f6\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u81ea\u52a8\u5316\u6a21\u578b\u53d1\u73b0\u6280\u672f\uff0c\u4ece\u8ddf\u8e2a\u6570\u636e\u4e2d\u63d0\u53d6\u4f9d\u8d56\u56fe\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9884\u6d4b\u5f39\u6027\uff0c\u518d\u901a\u8fc7\u5b9e\u9645\u6df7\u6c8c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f9d\u8d56\u56fe\u6a21\u578b\u7684\u9884\u6d4b\u4e0e\u5b9e\u9645\u89c2\u6d4b\u7ed3\u679c\u9ad8\u5ea6\u543b\u5408\uff0c\u65e0\u590d\u5236\u60c5\u51b5\u4e0b\u9884\u6d4b\u5f39\u6027\u4e3a0.161\uff0c\u5b9e\u9645\u4e3a0.186\uff1b\u6709\u590d\u5236\u65f6\u4e24\u8005\u5747\u4e3a0.305\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u7b80\u5355\u7684\u81ea\u52a8\u53d1\u73b0\u4f9d\u8d56\u56fe\u4e5f\u80fd\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u5fae\u670d\u52a1\u53ef\u7528\u6027\uff0c\u4e3a\u8bbe\u8ba1\u9636\u6bb5\u63d0\u4f9b\u5feb\u901f\u6d1e\u5bdf\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u6545\u969c\u6d4b\u8bd5\u3002"}}
{"id": "2506.11393", "pdf": "https://arxiv.org/pdf/2506.11393", "abs": "https://arxiv.org/abs/2506.11393", "authors": ["Sandro Radovanovi\u0107", "Shuangyu Li"], "title": "Co-Designing a Chatbot for Culturally Competent Clinical Communication: Experience and Reflections", "categories": ["cs.HC", "cs.CY"], "comment": "19 pages, 7 figures", "summary": "Clinical communication skills are essential for preparing healthcare\nprofessionals to provide equitable care across cultures. However, traditional\ntraining with simulated patients can be resource intensive and difficult to\nscale, especially in under-resourced settings. In this project, we explore the\nuse of an AI-driven chatbot to support culturally competent communication\ntraining for medical students. The chatbot was designed to simulate realistic\npatient conversations and provide structured feedback based on the ACT Cultural\nCompetence model. We piloted the chatbot with a small group of third-year\nmedical students at a UK medical school in 2024. Although we did not follow a\nformal experimental design, our experience suggests that the chatbot offered\nuseful opportunities for students to reflect on their communication,\nparticularly around empathy and interpersonal understanding. More challenging\nareas included addressing systemic issues and historical context. Although this\nearly version of the chatbot helped surface some interesting patterns,\nlimitations were also clear, such as the absence of nonverbal cues and the\ntendency for virtual patients to be overly agreeable. In general, this\nreflection highlights both the potential and the current limitations of AI\ntools in communication training. More work is needed to better understand their\nimpact and improve the learning experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4f7f\u7528AI\u804a\u5929\u673a\u5668\u4eba\u652f\u6301\u8de8\u6587\u5316\u6c9f\u901a\u57f9\u8bad\uff0c\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\u5176\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\u5e76\u5b58\u3002", "motivation": "\u4f20\u7edf\u6a21\u62df\u75c5\u4eba\u8bad\u7ec3\u8d44\u6e90\u5bc6\u96c6\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u5c24\u5176\u5728\u8d44\u6e90\u532e\u4e4f\u5730\u533a\uff0cAI\u804a\u5929\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8eACT\u6587\u5316\u80fd\u529b\u6a21\u578b\u7684AI\u804a\u5929\u673a\u5668\u4eba\uff0c\u6a21\u62df\u771f\u5b9e\u60a3\u8005\u5bf9\u8bdd\u5e76\u63d0\u4f9b\u7ed3\u6784\u5316\u53cd\u9988\uff0c\u5e76\u5728\u533b\u5b66\u751f\u4e2d\u8bd5\u70b9\u3002", "result": "\u804a\u5929\u673a\u5668\u4eba\u5e2e\u52a9\u5b66\u751f\u53cd\u601d\u6c9f\u901a\u6280\u5de7\uff0c\u4f46\u672a\u80fd\u8986\u76d6\u7cfb\u7edf\u6027\u95ee\u9898\u548c\u5386\u53f2\u80cc\u666f\u7b49\u590d\u6742\u8bae\u9898\uff0c\u4e14\u7f3a\u4e4f\u975e\u8bed\u8a00\u7ebf\u7d22\u3002", "conclusion": "AI\u5de5\u5177\u5728\u6c9f\u901a\u57f9\u8bad\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2506.11446", "pdf": "https://arxiv.org/pdf/2506.11446", "abs": "https://arxiv.org/abs/2506.11446", "authors": ["Dahu Feng", "Erhu Feng", "Dong Du", "Pinjie Xu", "Yubin Xia", "Haibo Chen", "Rong Zhao"], "title": "Topology-Aware Virtualization over Inter-Core Connected Neural Processing Units", "categories": ["cs.AR", "cs.DC"], "comment": null, "summary": "With the rapid development of artificial intelligence (AI) applications, an\nemerging class of AI accelerators, termed Inter-core Connected Neural\nProcessing Units (NPU), has been adopted in both cloud and edge computing\nenvironments, like Graphcore IPU, Tenstorrent, etc. Despite their innovative\ndesign, these NPUs often demand substantial hardware resources, leading to\nsuboptimal resource utilization due to the imbalance of hardware requirements\nacross various tasks. To address this issue, prior research has explored\nvirtualization techniques for monolithic NPUs, but has neglected inter-core\nconnected NPUs with the hardware topology.\n  This paper introduces vNPU, the first comprehensive virtualization design for\ninter-core connected NPUs, integrating three novel techniques: (1) NPU route\nvirtualization, which redirects instruction and data flow from virtual NPU\ncores to physical ones, creating a virtual topology; (2) NPU memory\nvirtualization, designed to minimize translation stalls for SRAM-centric and\nNoC-equipped NPU cores, thereby maximizing the memory bandwidth; and (3)\nBest-effort topology mapping, which determines the optimal mapping from all\ncandidate virtual topologies, balancing resource utilization with end-to-end\nperformance. We have developed a prototype of vNPU on both an FPGA platform\n(Chipyard+FireSim) and a simulator (DCRA). Evaluation results indicate that,\ncompared to other virtualization approaches such as unified virtual memory and\nMIG, vNPU achieves up to a 2x performance improvement across various ML models,\nwith only 2% hardware cost.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86vNPU\uff0c\u4e00\u79cd\u9488\u5bf9\u4e92\u8054\u6838\u5fc3NPU\u7684\u865a\u62df\u5316\u8bbe\u8ba1\uff0c\u901a\u8fc7\u8def\u7531\u3001\u5185\u5b58\u865a\u62df\u5316\u548c\u6700\u4f73\u62d3\u6251\u6620\u5c04\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u964d\u4f4e\u4e86\u786c\u4ef6\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684NPU\u865a\u62df\u5316\u6280\u672f\u672a\u8003\u8651\u4e92\u8054\u6838\u5fc3NPU\u7684\u786c\u4ef6\u62d3\u6251\u95ee\u9898\uff0c\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u4e0d\u8db3\u3002", "method": "vNPU\u63d0\u51fa\u4e09\u79cd\u6280\u672f\uff1a\u8def\u7531\u865a\u62df\u5316\u3001\u5185\u5b58\u865a\u62df\u5316\u548c\u6700\u4f73\u62d3\u6251\u6620\u5c04\uff0c\u4ee5\u4f18\u5316\u8d44\u6e90\u5206\u914d\u548c\u6027\u80fd\u3002", "result": "\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\uff0cvNPU\u6027\u80fd\u63d0\u53472\u500d\uff0c\u786c\u4ef6\u6210\u672c\u4ec5\u589e\u52a02%\u3002", "conclusion": "vNPU\u4e3a\u4e92\u8054\u6838\u5fc3NPU\u63d0\u4f9b\u4e86\u9ad8\u6548\u865a\u62df\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u8d44\u6e90\u5229\u7528\u4e0e\u6027\u80fd\u3002"}}
{"id": "2506.11010", "pdf": "https://arxiv.org/pdf/2506.11010", "abs": "https://arxiv.org/abs/2506.11010", "authors": ["Emilio Porcu", "Roy El Moukari", "Laurent Najman", "Francisco Herrera", "Horst Simon"], "title": "Data Science: a Natural Ecosystem", "categories": ["cs.LG", "cs.AI", "cs.DB", "stat.ML"], "comment": null, "summary": "This manuscript provides a holistic (data-centric) view of what we term\nessential data science, as a natural ecosystem with challenges and missions\nstemming from the data universe with its multiple combinations of the 5D\ncomplexities (data structure, domain, cardinality, causality, and ethics) with\nthe phases of the data life cycle. Data agents perform tasks driven by specific\ngoals. The data scientist is an abstract entity that comes from the logical\norganization of data agents with their actions. Data scientists face challenges\nthat are defined according to the missions. We define specific\ndiscipline-induced data science, which in turn allows for the definition of\npan-data science, a natural ecosystem that integrates specific disciplines with\nthe essential data science. We semantically split the essential data science\ninto computational, and foundational. We claim that there is a serious threat\nof divergence between computational and foundational data science. Especially,\nif no approach is taken to rate whether a data universe discovery should be\nuseful or not. We suggest that rigorous approaches to measure the usefulness of\ndata universe discoveries might mitigate such a divergence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u4f53\u6027\u7684\u6570\u636e\u79d1\u5b66\u89c6\u89d2\uff0c\u5f3a\u8c03\u6570\u636e\u79d1\u5b66\u7684\u751f\u6001\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u6311\u6218\u4e0e\u4f7f\u547d\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4f30\u6570\u636e\u53d1\u73b0\u6709\u7528\u6027\u7684\u65b9\u6cd5\u4ee5\u907f\u514d\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5206\u6b67\u3002", "motivation": "\u63a2\u8ba8\u6570\u636e\u79d1\u5b66\u7684\u672c\u8d28\u53ca\u5176\u5728\u591a\u7ef4\u590d\u6742\u6027\uff08\u6570\u636e\u7ed3\u6784\u3001\u9886\u57df\u3001\u57fa\u6570\u3001\u56e0\u679c\u6027\u548c\u4f26\u7406\uff09\u4e0e\u6570\u636e\u751f\u547d\u5468\u671f\u9636\u6bb5\u4e2d\u7684\u81ea\u7136\u751f\u6001\uff0c\u540c\u65f6\u5173\u6ce8\u8ba1\u7b97\u4e0e\u57fa\u7840\u6570\u636e\u79d1\u5b66\u4e4b\u95f4\u7684\u6f5c\u5728\u5206\u6b67\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u4ee3\u7406\u548c\u903b\u8f91\u7ec4\u7ec7\u7684\u6570\u636e\u79d1\u5b66\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u4e49\u7279\u5b9a\u5b66\u79d1\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u4e0e\u6cdb\u6570\u636e\u79d1\u5b66\u6765\u6574\u5408\u5b66\u79d1\u4e0e\u57fa\u672c\u6570\u636e\u79d1\u5b66\u3002", "result": "\u6307\u51fa\u8ba1\u7b97\u4e0e\u57fa\u7840\u6570\u636e\u79d1\u5b66\u53ef\u80fd\u5b58\u5728\u7684\u5206\u6b67\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4f30\u6570\u636e\u53d1\u73b0\u6709\u7528\u6027\u7684\u65b9\u6cd5\u4ee5\u51cf\u5c11\u8fd9\u79cd\u5206\u6b67\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u8bc4\u4f30\u6570\u636e\u53d1\u73b0\u7684\u6709\u7528\u6027\u5bf9\u7edf\u4e00\u6570\u636e\u79d1\u5b66\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u4fc3\u8fdb\u6570\u636e\u79d1\u5b66\u7684\u5065\u5eb7\u53d1\u5c55\u3002"}}
{"id": "2506.11800", "pdf": "https://arxiv.org/pdf/2506.11800", "abs": "https://arxiv.org/abs/2506.11800", "authors": ["Vincent Lannurien", "Cam\u00e9lia Slimani", "Louis Morge-Rollet", "Laurent Lemarchand", "David Espes", "Fr\u00e9d\u00e9ric Le Roy", "Jalil Boukhobza"], "title": "A retrospective on DISPEED -- Leveraging heterogeneity in a drone swarm for IDS execution", "categories": ["cs.DC"], "comment": null, "summary": "Swarms of drones are gaining more and more autonomy and efficiency during\ntheir missions. However, security threats can disrupt their missions'\nprogression. To overcome this problem, Network Intrusion Detection Systems\n((N)IDS) are promising solutions to detect malicious behavior on network\ntraffic. However, modern NIDS rely on resource-hungry machine learning\ntechniques, that can be difficult to deploy on a swarm of drones. The goal of\nthe DISPEED project is to leverage the heterogeneity (execution platforms,\nmemory) of the drones composing a swarm to deploy NIDS. It is decomposed in two\nphases: (1) a characterization phase that consists in characterizing various\nIDS implementations on diverse embedded platforms, and (2) an IDS\nimplementation mapping phase that seeks to develop selection strategies to\nchoose the most relevant NIDS depending on the context. On the one hand, the\ncharacterization phase allowed us to identify 36 relevant IDS implementations\non three different embedded platforms: a Raspberry Pi 4B, a Jetson Xavier, and\na Pynq-Z2. On the other hand, the IDS implementation mapping phase allowed us\nto design both standalone and distributed strategies to choose the best NIDSs\nto deploy depending on the context. The results of the project have led to\nthree publications in international conferences, and one publication in a\njournal.", "AI": {"tldr": "\u65e0\u4eba\u673a\u7fa4\u7684\u81ea\u4e3b\u6027\u548c\u4efb\u52a1\u6548\u7387\u63d0\u5347\uff0c\u4f46\u9762\u4e34\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u3002DISPEED\u9879\u76ee\u901a\u8fc7\u5229\u7528\u65e0\u4eba\u673a\u5f02\u6784\u6027\u90e8\u7f72\u8f7b\u91cf\u7ea7NIDS\uff0c\u5305\u62ec\u6027\u80fd\u8bc4\u4f30\u548c\u7b56\u7565\u9009\u62e9\u4e24\u4e2a\u9636\u6bb5\uff0c\u6210\u679c\u5df2\u53d1\u8868\u591a\u7bc7\u8bba\u6587\u3002", "motivation": "\u65e0\u4eba\u673a\u7fa4\u9762\u4e34\u5b89\u5168\u5a01\u80c1\uff0c\u4f20\u7edfNIDS\u56e0\u8d44\u6e90\u6d88\u8017\u5927\u96be\u4ee5\u90e8\u7f72\uff0c\u9700\u5f00\u53d1\u9002\u5408\u5f02\u6784\u5e73\u53f0\u7684\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u9879\u76ee\u5206\u4e3a\u4e24\u9636\u6bb5\uff1a1. \u5728\u4e0d\u540c\u5d4c\u5165\u5f0f\u5e73\u53f0\u4e0a\u8bc4\u4f3036\u79cdIDS\u5b9e\u73b0\uff1b2. \u8bbe\u8ba1\u72ec\u7acb\u548c\u5206\u5e03\u5f0f\u7b56\u7565\uff0c\u6839\u636e\u4e0a\u4e0b\u6587\u9009\u62e9\u6700\u4f18NIDS\u3002", "result": "\u5728\u6811\u8393\u6d3e\u3001Jetson Xavier\u548cPynq-Z2\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e8636\u79cdIDS\uff0c\u5e76\u63d0\u51fa\u4e86\u7b56\u7565\u9009\u62e9\u65b9\u6cd5\u3002\u9879\u76ee\u6210\u679c\u5df2\u53d1\u8868\u4e8e\u56fd\u9645\u4f1a\u8bae\u548c\u671f\u520a\u3002", "conclusion": "DISPEED\u9879\u76ee\u6210\u529f\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u7fa4\u90e8\u7f72NIDS\u7684\u6311\u6218\uff0c\u4e3a\u5f02\u6784\u5e73\u53f0\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u5b89\u5168\u65b9\u6848\u3002"}}
{"id": "2506.10991", "pdf": "https://arxiv.org/pdf/2506.10991", "abs": "https://arxiv.org/abs/2506.10991", "authors": ["Hoang Vu", "Henrik Leopold", "Han van der Aa"], "title": "What is Business Process Automation Anyway?", "categories": ["cs.SE", "D.2.9; H.4.1"], "comment": "Accepted at HICSS 2023", "summary": "Many organizations strive to increase the level of automation in their\nbusiness processes. While automation historically was mainly concerned with\nautomating physical labor, current automation efforts mostly focus on\nautomation in a digital manner, thus targeting work that is related to the\ninteraction between humans and computers. This type of automation, commonly\nreferred to as business process automation, has many facets. Yet, academic\nliterature mainly focuses on Robotic Process Automation, a specific automation\ncapability. Recognizing that leading vendors offer automation capabilities\ngoing way beyond that, we use this paper to develop a detailed understanding of\nbusiness process automation in industry. To this end, we conduct a structured\nmarket analysis of the 18 predominant vendors of business process automation\nsolutions as identified by Gartner. As a result, we provide a comprehensive\noverview of the business process automation capabilities currently offered by\nindustrial vendors. We show which types and facets of automation exist and\nwhich aspects represent promising directions for the future.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u679018\u5bb6\u4e3b\u8981\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u4f9b\u5e94\u5546\u7684\u5e02\u573a\u60c5\u51b5\uff0c\u5168\u9762\u6982\u8ff0\u4e86\u5f53\u524d\u5de5\u4e1a\u754c\u7684\u81ea\u52a8\u5316\u80fd\u529b\u53ca\u5176\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u5b66\u672f\u754c\u4e3b\u8981\u5173\u6ce8\u673a\u5668\u4eba\u6d41\u7a0b\u81ea\u52a8\u5316\uff08RPA\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u5de5\u4e1a\u754c\u63d0\u4f9b\u7684\u66f4\u5e7f\u6cdb\u7684\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u5e02\u573a\u5206\u6790\uff0c\u7814\u7a76\u4e86Gartner\u8ba4\u5b9a\u768418\u5bb6\u4e3b\u8981\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u4f9b\u5e94\u5546\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u63d0\u4f9b\u4e86\u5f53\u524d\u5de5\u4e1a\u754c\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u80fd\u529b\u7684\u5168\u9762\u6982\u8ff0\uff0c\u5e76\u5206\u6790\u4e86\u81ea\u52a8\u5316\u7c7b\u578b\u53ca\u5176\u672a\u6765\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u7684\u591a\u6837\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u4e0e\u5b9e\u8df5\u7684\u6f5c\u5728\u65b9\u5411\u3002"}}
{"id": "2506.11744", "pdf": "https://arxiv.org/pdf/2506.11744", "abs": "https://arxiv.org/abs/2506.11744", "authors": ["Ozan Karaali", "Hossam Farag", "Strahinja Dosen", "Cedomir Stefanovic"], "title": "Enabling Next-Generation Cloud-Connected Bionic Limbs Through 5G Connectivity", "categories": ["cs.NI"], "comment": null, "summary": "Despite the recent advancements in human-machine interfacing, contemporary\nassistive bionic limbs face critical challenges, including limited\ncomputational capabilities, high latency, and unintuitive control mechanisms,\nleading to suboptimal user experience and abandonment rates. Addressing these\nchallenges requires a shift toward intelligent, interconnected solutions\npowered by advances in Internet of Things systems, particularly wireless\nconnectivity and edge/cloud computing. This article presents a conceptual\napproach to transform bionic limbs by harnessing the pervasive connectivity of\n5G and the significant computational power of cloud and edge servers, equipping\nthem with capabilities not available hitherto. The system leverages a\nhierarchical distributed-computing architecture that integrates local, edge,\nand cloud computing layers. Time-critical tasks are handled by a local\nprocessing unit, while compute-intensive tasks are offloaded to edge and cloud\nservers, leveraging the high data rate, reliable and low latency capabilities\nof advanced cellular networks. We perform a proof-of-concept validation in a 5G\ntestbed showing that such networks are capable of achieving data rates and\nfulfilling latency requirements for a natural prosthetic control, allowing for\noffloading of compute-intensive jobs to the edge/cloud servers. This is the\nfirst step towards the realization and real-world validation of cloud-connected\nbionic limb systems.", "AI": {"tldr": "5G\u548c\u8fb9\u7f18/\u4e91\u8ba1\u7b97\u8d4b\u80fd\u667a\u80fd\u5047\u80a2\uff0c\u89e3\u51b3\u73b0\u6709\u8bbe\u5907\u7684\u5ef6\u8fdf\u548c\u8ba1\u7b97\u80fd\u529b\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u8ba1\u7b97\u67b6\u6784\u5b9e\u73b0\u9ad8\u6548\u63a7\u5236\u3002", "motivation": "\u5f53\u524d\u5047\u80a2\u5b58\u5728\u8ba1\u7b97\u80fd\u529b\u4e0d\u8db3\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc75G\u548c\u4e91\u8ba1\u7b97\u6280\u672f\u63d0\u5347\u5047\u80a2\u6027\u80fd\uff0c\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u91c7\u7528\u5206\u5c42\u5206\u5e03\u5f0f\u8ba1\u7b97\u67b6\u6784\uff0c\u7ed3\u5408\u672c\u5730\u3001\u8fb9\u7f18\u548c\u4e91\u8ba1\u7b97\u5c42\uff0c\u5229\u75285G\u7f51\u7edc\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u6570\u636e\u7387\u3002", "result": "\u57285G\u6d4b\u8bd5\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u67b6\u6784\u80fd\u591f\u6ee1\u8db3\u81ea\u7136\u5047\u80a2\u63a7\u5236\u7684\u9700\u6c42\uff0c\u5b9e\u73b0\u8ba1\u7b97\u4efb\u52a1\u7684\u8fb9\u7f18/\u4e91\u7aef\u5378\u8f7d\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4e91\u7aef\u4e92\u8054\u667a\u80fd\u5047\u80a2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u521d\u6b65\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u672a\u6765\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.11133", "pdf": "https://arxiv.org/pdf/2506.11133", "abs": "https://arxiv.org/abs/2506.11133", "authors": ["Christos Pantazopoulos", "Spyridon Thermos", "Gerasimos Potamianos"], "title": "Monocular 3D Hand Pose Estimation with Implicit Camera Alignment", "categories": ["cs.CV", "cs.GR", "cs.LG", "eess.IV"], "comment": "Code is available at https://github.com/cpantazop/HandRepo", "summary": "Estimating the 3D hand articulation from a single color image is a\ncontinuously investigated problem with applications in Augmented Reality (AR),\nVirtual Reality (VR), Human-Computer Interaction (HCI), and robotics. Apart\nfrom the absence of depth information, occlusions, articulation complexity, and\nthe need for camera parameters knowledge pose additional challenges. In this\nwork, we propose an optimization pipeline for estimating the 3D hand\narticulation from 2D keypoint input, which includes a keypoint alignment step\nand a fingertip loss to overcome the need to know or estimate the camera\nparameters. We evaluate our approach on the EgoDexter and Dexter+Object\nbenchmarks to showcase that our approach performs competitively with the SotA,\nwhile also demonstrating its robustness when processing \"in-the-wild\" images\nwithout any prior camera knowledge. Our quantitative analysis highlights the\nsensitivity of the 2D keypoint estimation accuracy, despite the use of hand\npriors. Code is available at https://github.com/cpantazop/HandRepo", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u6d41\u7a0b\uff0c\u901a\u8fc72D\u5173\u952e\u70b9\u8f93\u5165\u4f30\u8ba13D\u624b\u90e8\u5173\u8282\uff0c\u65e0\u9700\u76f8\u673a\u53c2\u6570\uff0c\u5e76\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u5355\u5e45\u5f69\u8272\u56fe\u50cf\u4f30\u8ba13D\u624b\u90e8\u5173\u8282\u5728AR\u3001VR\u3001HCI\u548c\u673a\u5668\u4eba\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6df1\u5ea6\u4fe1\u606f\u7f3a\u5931\u3001\u906e\u6321\u3001\u5173\u8282\u590d\u6742\u6027\u548c\u76f8\u673a\u53c2\u6570\u9700\u6c42\u7b49\u95ee\u9898\u589e\u52a0\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f18\u5316\u6d41\u7a0b\uff0c\u5305\u62ec\u5173\u952e\u70b9\u5bf9\u9f50\u6b65\u9aa4\u548c\u6307\u5c16\u635f\u5931\u51fd\u6570\uff0c\u6446\u8131\u4e86\u5bf9\u76f8\u673a\u53c2\u6570\u7684\u4f9d\u8d56\u3002", "result": "\u5728EgoDexter\u548cDexter+Object\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u5728\u5904\u7406\"\u91ce\u5916\"\u56fe\u50cf\u65f6\u663e\u793a\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u4f7f\u7528\u4e86\u624b\u90e8\u5148\u9a8c\uff0c2D\u5173\u952e\u70b9\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u5bf9\u7ed3\u679c\u8f83\u4e3a\u654f\u611f\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.11180", "pdf": "https://arxiv.org/pdf/2506.11180", "abs": "https://arxiv.org/abs/2506.11180", "authors": ["Luis Miguel Vieira da Silva", "Aljosha K\u00f6cher", "Felix Gehlhoff"], "title": "Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing", "categories": ["cs.SE", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "comment": null, "summary": "Explicit modeling of capabilities and skills -- whether based on ontologies,\nAsset Administration Shells, or other technologies -- requires considerable\nmanual effort and often results in representations that are not easily\naccessible to Large Language Models (LLMs). In this work-in-progress paper, we\npresent an alternative approach based on the recently introduced Model Context\nProtocol (MCP). MCP allows systems to expose functionality through a\nstandardized interface that is directly consumable by LLM-based agents. We\nconduct a prototypical evaluation on a laboratory-scale manufacturing system,\nwhere resource functions are made available via MCP. A general-purpose LLM is\nthen tasked with planning and executing a multi-step process, including\nconstraint handling and the invocation of resource functions via MCP. The\nresults indicate that such an approach can enable flexible industrial\nautomation without relying on explicit semantic models. This work lays the\nbasis for further exploration of external tool integration in LLM-driven\nproduction systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u63a5\u53e3\u4f7f\u529f\u80fd\u5bf9LLM\u66f4\u6613\u8bbf\u95ee\uff0c\u65e0\u9700\u590d\u6742\u7684\u624b\u52a8\u5efa\u6a21\u3002", "motivation": "\u4f20\u7edf\u7684\u80fd\u529b\u548c\u6280\u80fd\u5efa\u6a21\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u4e14\u96be\u4ee5\u88abLLM\u8bbf\u95ee\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u5f0f\u3002", "method": "\u4f7f\u7528MCP\u6807\u51c6\u5316\u63a5\u53e3\uff0c\u5c06\u8d44\u6e90\u529f\u80fd\u76f4\u63a5\u66b4\u9732\u7ed9LLM\u4ee3\u7406\uff0c\u5e76\u5728\u5b9e\u9a8c\u5ba4\u89c4\u6a21\u7684\u5236\u9020\u7cfb\u7edf\u4e2d\u8fdb\u884c\u539f\u578b\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7075\u6d3b\u5de5\u4e1a\u81ea\u52a8\u5316\uff0c\u65e0\u9700\u4f9d\u8d56\u663e\u5f0f\u8bed\u4e49\u6a21\u578b\u3002", "conclusion": "\u4e3aLLM\u9a71\u52a8\u7684\u751f\u4ea7\u7cfb\u7edf\u4e2d\u5916\u90e8\u5de5\u5177\u96c6\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.11536", "pdf": "https://arxiv.org/pdf/2506.11536", "abs": "https://arxiv.org/abs/2506.11536", "authors": ["Daniel Zielasko", "Ben Rehling", "Bernadette von Dawans", "Gregor Domes"], "title": "Do Not Immerse and Drive? Prolonged Effects of Cybersickness on Physiological Stress Markers And Cognitive Performance", "categories": ["cs.HC"], "comment": null, "summary": "Extended exposure to virtual reality environments can induce motion sickness,\noften referred to as cybersickness, which may lead to physiological stress\nresponses and impaired cognitive performance. This study investigates the\naftereffects of VR-induced motion sickness with a focus on physiological stress\nmarkers and working memory performance. Using a carousel simulation to elicit\ncybersickness, we assessed subjective discomfort (SSQ, FMS), physiological\nstress (salivary cortisol, alpha-amylase, electrodermal activity, heart rate),\nand cognitive performance (n-Back task) over a 90-minute post-exposure period.\nOur findings demonstrate a significant increase in both subjective and\nphysiological stress indicators following VR exposure, accompanied by a decline\nin working memory performance. Notably, delayed symptom progression was\nobserved in a substantial proportion of participants, with some reporting peak\nsymptoms up to 90 minutes post-stimulation. Salivary cortisol levels remained\nelevated throughout the observation period, indicating prolonged stress\nrecovery. These results highlight the need for longer washout phases in XR\nresearch and raise safety concerns for professional applications involving\npost-exposure task performance.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u5f15\u53d1\u7684\u6655\u52a8\u75c7\u540e\u6548\uff0c\u53d1\u73b0\u5176\u663e\u8457\u589e\u52a0\u4e3b\u89c2\u548c\u751f\u7406\u538b\u529b\u6307\u6807\uff0c\u5e76\u5bfc\u81f4\u5de5\u4f5c\u8bb0\u5fc6\u80fd\u529b\u4e0b\u964d\uff0c\u75c7\u72b6\u5ef6\u8fdf\u8fdb\u5c55\u4e14\u538b\u529b\u6062\u590d\u65f6\u95f4\u8f83\u957f\uff0c\u63d0\u793a\u9700\u5ef6\u957fXR\u7814\u7a76\u7684\u6d17\u8131\u671f\u3002", "motivation": "\u63a2\u7a76VR\u8bf1\u53d1\u7684\u6655\u52a8\u75c7\u5bf9\u751f\u7406\u538b\u529b\u548c\u8ba4\u77e5\u80fd\u529b\u7684\u6301\u7eed\u5f71\u54cd\uff0c\u4e3aXR\u7814\u7a76\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u901a\u8fc7\u65cb\u8f6c\u6a21\u62df\u8bf1\u53d1\u6655\u52a8\u75c7\uff0c\u6d4b\u91cf\u4e3b\u89c2\u4e0d\u9002\u3001\u751f\u7406\u538b\u529b\u6307\u6807\uff08\u553e\u6db2\u76ae\u8d28\u9187\u7b49\uff09\u548c\u8ba4\u77e5\u4efb\u52a1\u8868\u73b0\uff0c\u89c2\u5bdf90\u5206\u949f\u540e\u6548\u3002", "result": "VR\u66b4\u9732\u540e\u4e3b\u89c2\u548c\u751f\u7406\u538b\u529b\u663e\u8457\u589e\u52a0\uff0c\u5de5\u4f5c\u8bb0\u5fc6\u4e0b\u964d\uff0c\u75c7\u72b6\u5ef6\u8fdf\u51fa\u73b0\uff0c\u553e\u6db2\u76ae\u8d28\u9187\u6301\u7eed\u5347\u9ad8\u3002", "conclusion": "\u9700\u5ef6\u957fXR\u7814\u7a76\u7684\u6d17\u8131\u671f\uff0c\u5e76\u5173\u6ce8\u4e13\u4e1a\u5e94\u7528\u4e2d\u7684\u540e\u6548\u5b89\u5168\u6027\u3002"}}
{"id": "2506.11668", "pdf": "https://arxiv.org/pdf/2506.11668", "abs": "https://arxiv.org/abs/2506.11668", "authors": ["Victor Isachi", "Alessandro Nadalini", "Riccardo Fiorani Gallotta", "Angelo Garofalo", "Francesco Conti", "Davide Rossi"], "title": "FractalSync: Lightweight Scalable Global Synchronization of Massive Bulk Synchronous Parallel AI Accelerators", "categories": ["cs.AR"], "comment": null, "summary": "The slow-down of technology scaling and the emergence of Artificial\nIntelligence (AI) workloads have led computer architects to increasingly\nexploit parallelization coupled with hardware acceleration to keep pushing the\nperformance envelope. However, this solution comes with the challenge of\nsynchronization of processing elements (PEs) in massive heterogeneous many-core\nplatforms. To address this challenge, we propose FractalSync, a hardware\naccelerated synchronization mechanism for Bulk Synchronous Parallel (BSP)\nsystems. We integrate FractalSync in MAGIA, a scalable tile-based AI\naccelerator, with each tile featuring a RISC-V-coupled matrix-multiplication\n(MatMul) accelerator, scratchpad memory (SPM), and a DMA connected to a global\nmesh Network-on-Chip (NoC). We study the scalability of the proposed barrier\nsynchronization scheme on tile meshes ranging from 2x2 PEs to 16x16 PEs to\nevaluate its design boundaries. Compared to a synchronization scheme based on\nsoftware atomic memory operations (AMOs), the proposed solution achieves up to\n43x speedup on synchronization, introducing a negligible area overhead\n(<0.01%). FractalSync closes timing at MAGIA's target 1GHz frequency.", "AI": {"tldr": "\u63d0\u51fa\u4e86FractalSync\uff0c\u4e00\u79cd\u7528\u4e8eBSP\u7cfb\u7edf\u7684\u786c\u4ef6\u52a0\u901f\u540c\u6b65\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5f02\u6784\u591a\u6838\u5e73\u53f0\u4e2d\u5904\u7406\u5143\u7d20\u540c\u6b65\u7684\u6311\u6218\u3002", "motivation": "\u968f\u6280\u672f\u8fdb\u6b65\u653e\u7f13\u53caAI\u5de5\u4f5c\u8d1f\u8f7d\u589e\u52a0\uff0c\u8ba1\u7b97\u673a\u67b6\u6784\u5e08\u9700\u5229\u7528\u5e76\u884c\u5316\u548c\u786c\u4ef6\u52a0\u901f\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u540c\u6b65\u5904\u7406\u5143\u7d20\u662f\u4e00\u5927\u6311\u6218\u3002", "method": "\u5728MAGIA\uff08\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u74e6\u7247\u7684AI\u52a0\u901f\u5668\uff09\u4e2d\u96c6\u6210\u4e86FractalSync\uff0c\u7814\u7a76\u4e86\u5176\u5728\u4e0d\u540c\u89c4\u6a21\u74e6\u7247\u7f51\u683c\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u3002", "result": "\u76f8\u6bd4\u57fa\u4e8e\u8f6f\u4ef6\u539f\u5b50\u5185\u5b58\u64cd\u4f5c\u7684\u540c\u6b65\u65b9\u6848\uff0cFractalSync\u540c\u6b65\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe43\u500d\uff0c\u4e14\u9762\u79ef\u5f00\u9500\u6781\u5c0f\uff08<0.01%\uff09\u3002", "conclusion": "FractalSync\u57281GHz\u9891\u7387\u4e0b\u5b9e\u73b0\u4e86\u65f6\u5e8f\u95ed\u5408\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u540c\u6b65\u65b9\u6848\u3002"}}
{"id": "2506.11986", "pdf": "https://arxiv.org/pdf/2506.11986", "abs": "https://arxiv.org/abs/2506.11986", "authors": ["Wuzhenghong Wen", "Su Pan", "yuwei Sun"], "title": "Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task", "categories": ["cs.AI", "cs.CL", "cs.DB"], "comment": "11 pages, 3 figures, conference", "summary": "Schema linking is a critical step in Text-to-SQL task, aiming to accurately\npredict the table names and column names required for the SQL query based on\nthe given question. However, current fine-tuning approaches for schema linking\nmodels employ a rote-learning paradigm, excessively optimizing for ground truth\nschema linking outcomes while compromising reasoning ability. This limitation\narises because of the difficulty in acquiring a high-quality reasoning sample\nfor downstream tasks. To address this, we propose Schema-R1, a reasoning schema\nlinking model trained using reinforcement learning. Specifically, Schema-R1\nconsists of three key steps: constructing small batches of high-quality\nreasoning samples, supervised fine-tuning for cold-start initialization, and\nrule-based reinforcement learning training. The final results demonstrate that\nour method effectively enhances the reasoning ability of the schema linking\nmodel, achieving a 10\\% improvement in filter accuracy compared to the existing\nmethod. Our code is available at https://github.com/hongWin/Schema-R1/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684Schema-R1\u6a21\u578b\uff0c\u7528\u4e8e\u6539\u8fdbText-to-SQL\u4efb\u52a1\u4e2d\u7684\u6a21\u5f0f\u94fe\u63a5\uff0c\u901a\u8fc7\u6784\u9020\u9ad8\u8d28\u91cf\u63a8\u7406\u6837\u672c\u548c\u89c4\u5219\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u6a21\u5f0f\u94fe\u63a5\u6a21\u578b\u7684\u5fae\u8c03\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u6b7b\u8bb0\u786c\u80cc\uff0c\u7f3a\u4e4f\u63a8\u7406\u80fd\u529b\uff0c\u96be\u4ee5\u83b7\u53d6\u9ad8\u8d28\u91cf\u63a8\u7406\u6837\u672c\u3002", "method": "Schema-R1\u901a\u8fc7\u6784\u9020\u9ad8\u8d28\u91cf\u63a8\u7406\u6837\u672c\u3001\u76d1\u7763\u5fae\u8c03\u521d\u59cb\u5316\u548c\u89c4\u5219\u5f3a\u5316\u5b66\u4e60\u4e09\u4e2a\u6b65\u9aa4\u5b9e\u73b0\u6539\u8fdb\u3002", "result": "\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0cSchema-R1\u5728\u8fc7\u6ee4\u51c6\u786e\u7387\u4e0a\u63d0\u5347\u4e8610%\u3002", "conclusion": "Schema-R1\u6709\u6548\u63d0\u5347\u4e86\u6a21\u5f0f\u94fe\u63a5\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3aText-to-SQL\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.11950", "pdf": "https://arxiv.org/pdf/2506.11950", "abs": "https://arxiv.org/abs/2506.11950", "authors": ["Tyler J. Skluzacek", "Paul Bryant", "A. J. Ruckman", "Daniel Rosendo", "Suzanne Prentice", "Michael J. Brim", "Ryan Adamson", "Sarp Oral", "Mallikarjun Shankar", "Rafael Ferreira da Silva"], "title": "Secure API-Driven Research Automation to Accelerate Scientific Discovery", "categories": ["cs.DC"], "comment": "PEARC 2025, 5 pages", "summary": "The Secure Scientific Service Mesh (S3M) provides API-driven infrastructure\nto accelerate scientific discovery through automated research workflows. By\nintegrating near real-time streaming capabilities, intelligent workflow\norchestration, and fine-grained authorization within a service mesh\narchitecture, S3M revolutionizes programmatic access to high performance\ncomputing (HPC) while maintaining uncompromising security. This framework\nallows intelligent agents and experimental facilities to dynamically provision\nresources and execute complex workflows, accelerating experimental lifecycles,\nand unlocking the full potential of AI-augmented autonomous science. S3M\nsignals a new era in scientific computing infrastructure that eliminates\ntraditional barriers between researchers, computational resources, and\nexperimental facilities.", "AI": {"tldr": "S3M\u662f\u4e00\u79cd\u901a\u8fc7\u670d\u52a1\u7f51\u683c\u67b6\u6784\u6574\u5408\u5b9e\u65f6\u6d41\u3001\u667a\u80fd\u5de5\u4f5c\u6d41\u7f16\u6392\u548c\u7ec6\u7c92\u5ea6\u6388\u6743\u7684\u6846\u67b6\uff0c\u65e8\u5728\u52a0\u901f\u79d1\u5b66\u7814\u7a76\u5e76\u4fdd\u969c\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edf\u79d1\u5b66\u8ba1\u7b97\u4e2d\u5b58\u5728\u7814\u7a76\u8005\u3001\u8ba1\u7b97\u8d44\u6e90\u548c\u5b9e\u9a8c\u8bbe\u65bd\u4e4b\u95f4\u7684\u58c1\u5792\uff0cS3M\u65e8\u5728\u6d88\u9664\u8fd9\u4e9b\u969c\u788d\uff0c\u52a0\u901f\u5b9e\u9a8c\u751f\u547d\u5468\u671f\u3002", "method": "\u901a\u8fc7\u670d\u52a1\u7f51\u683c\u67b6\u6784\u6574\u5408\u5b9e\u65f6\u6d41\u3001\u667a\u80fd\u5de5\u4f5c\u6d41\u7f16\u6392\u548c\u7ec6\u7c92\u5ea6\u6388\u6743\uff0c\u52a8\u6001\u63d0\u4f9b\u8d44\u6e90\u5e76\u6267\u884c\u590d\u6742\u5de5\u4f5c\u6d41\u3002", "result": "S3M\u5b9e\u73b0\u4e86\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u7684\u7a0b\u5e8f\u5316\u8bbf\u95ee\uff0c\u63d0\u5347AI\u589e\u5f3a\u81ea\u4e3b\u79d1\u5b66\u7684\u6f5c\u529b\u3002", "conclusion": "S3M\u6807\u5fd7\u7740\u79d1\u5b66\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u65b0\u65f6\u4ee3\uff0c\u6d88\u9664\u4e86\u4f20\u7edf\u58c1\u5792\uff0c\u63a8\u52a8\u4e86\u79d1\u7814\u7684\u81ea\u52a8\u5316\u4e0e\u9ad8\u6548\u6027\u3002"}}
{"id": "2506.10992", "pdf": "https://arxiv.org/pdf/2506.10992", "abs": "https://arxiv.org/abs/2506.10992", "authors": ["Hoang Vu", "Jennifer Haase", "Henrik Leopold", "Jan Mendling"], "title": "Towards a Theory on Process Automation Effects", "categories": ["cs.SE", "D.2.9"], "comment": "Accepted at HICSS 2023", "summary": "Process automation is a crucial strategy for improving business processes,\nbut little attention has been paid to the effects that automation has once it\nis operational. This paper addresses this research problem by reviewing the\nliterature on human-automation interaction. Although many of the studies in\nthis field have been conducted in different domains, they provide a foundation\nfor developing propositions about process automation effects. Our analysis\nfocuses on how humans perceive automation technology when working within a\nprocess, allowing us to propose an effective engagement model between\ntechnology, process participants, process managers, and software developers.\nThis paper offers insights and recommendations that can help organizations\noptimize their use of process automation. We further derive novel research\nquestions for a discourse within the process automation community.", "AI": {"tldr": "\u63a2\u8ba8\u81ea\u52a8\u5316\u5bf9\u4e1a\u52a1\u6d41\u7a0b\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4f18\u5316\u81ea\u52a8\u5316\u4f7f\u7528\u7684\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u81ea\u52a8\u5316\u6280\u672f\u7684\u5b9e\u9645\u6548\u679c\u53ca\u5176\u5bf9\u4eba\u7c7b\u5de5\u4f5c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4eba\u673a\u4ea4\u4e92\uff0c\u63d0\u51fa\u6280\u672f\u3001\u53c2\u4e0e\u8005\u3001\u7ba1\u7406\u8005\u548c\u5f00\u53d1\u8005\u4e4b\u95f4\u7684\u4e92\u52a8\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86\u4f18\u5316\u81ea\u52a8\u5316\u7684\u5efa\u8bae\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7814\u7a76\u95ee\u9898\u3002", "conclusion": "\u81ea\u52a8\u5316\u9700\u8981\u66f4\u597d\u7684\u4e92\u52a8\u6a21\u578b\u4ee5\u63d0\u5347\u6548\u679c\uff0c\u5e76\u9f13\u52b1\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.11745", "pdf": "https://arxiv.org/pdf/2506.11745", "abs": "https://arxiv.org/abs/2506.11745", "authors": ["Peng Wang", "Suman Sourav", "Binbin Chen", "Hongyan Li", "Feng Wang", "Fan Zhang"], "title": "The Throughput Gain of Hypercycle-level Resource Reservation for Time-Triggered Ethernet", "categories": ["cs.NI"], "comment": null, "summary": "Time-Triggered Communication is a key technology for many safety-critical\nsystems, with applications spanning the areas of aerospace and industrial\ncontrol. Such communication relies on time-triggered flows, with each flow\nconsisting of periodic packets originating from a source and destined for a\ndestination node. Each packet needs to reach its destination before its\ndeadline. Different flows can have different cycle lengths. To achieve assured\ntransmission of time-triggered flows, existing efforts constrain the packets of\na flow to be cyclically transmitted along the same path. Under such Fixed\nCyclic Scheduling (FCS), reservation for flows with different cycle lengths can\nbecome incompatible over a shared link, limiting the total number of admissible\nflows. Considering the cycle lengths of different flows, a hyper-cycle has\nlength equal to their least common multiple (LCM). It determines the time\nduration over which the scheduling compatibility of the different flows can be\nchecked. In this work, we propose a more flexible schedule scheme called the\nHypercycle-level Flexible Schedule (HFS) scheme, where a flow's resource\nreservation can change across cycles within a hypercycle. HFS can significantly\nincrease the number of admitted flows by providing more scheduling options\nwhile remaining perfectly compatible with existing Time-Triggered Ethernet\nsystem. We show that, theoretically the possible capacity gain provided by HFS\nover FCS can be unbounded. We formulate the joint pathfinding and scheduling\nproblem under HFS as an ILP problem which we prove to be NP-Hard. To solve HFS\nefficiently, we further propose a least-load-first heuristic (HFS-LLF), solving\nHFS as a sequence of shortest path problems. Extensive study shows that HFS\nadmits up to 6 times the number of flows achieved by FCS. Moreover, our\nproposed HFS-LLF can run 104 times faster than solving HFS using a generic\nsolver.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u8d85\u5468\u671f\u7ea7\u522b\u7075\u6d3b\u8c03\u5ea6\uff08HFS\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u89e6\u53d1\u901a\u4fe1\u4e2d\u53ef\u63a5\u53d7\u7684\u6d41\u6570\u91cf\uff0c\u76f8\u6bd4\u56fa\u5b9a\u5468\u671f\u8c03\u5ea6\uff08FCS\uff09\u6709\u9ad8\u8fbe6\u500d\u7684\u63d0\u5347\u3002", "motivation": "\u65f6\u95f4\u89e6\u53d1\u901a\u4fe1\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u56fa\u5b9a\u5468\u671f\u8c03\u5ea6\u65b9\u6cd5\u56e0\u8d44\u6e90\u5206\u914d\u4e0d\u517c\u5bb9\u9650\u5236\u4e86\u53ef\u63a5\u53d7\u7684\u6d41\u6570\u91cf\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u8c03\u5ea6\u65b9\u6848\u3002", "method": "\u63d0\u51faHFS\u65b9\u6848\uff0c\u5141\u8bb8\u6d41\u5728\u6bcf\u4e2a\u8d85\u5468\u671f\u5185\u8de8\u5468\u671f\u7075\u6d3b\u5206\u914d\u8d44\u6e90\uff0c\u5c06\u5176\u5efa\u6a21\u4e3aILP\u95ee\u9898\u5e76\u63d0\u51fa\u542f\u53d1\u5f0f\u7b97\u6cd5HFS-LLF\uff0c\u901a\u8fc7\u6700\u77ed\u8def\u5f84\u95ee\u9898\u5e8f\u5217\u89e3\u51b3\u3002", "result": "HFS\u7406\u8bba\u4e0a\u53ef\u63d0\u4f9b\u65e0\u9650\u5bb9\u91cf\u589e\u76ca\uff0c\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u53ef\u63a5\u53d7\u6d41\u6570\u91cf\u662fFCS\u76846\u500d\uff0c\u4e14HFS-LLF\u8fd0\u884c\u901f\u5ea6\u6bd4\u901a\u7528\u6c42\u89e3\u5668\u5feb104\u500d\u3002", "conclusion": "HFS\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u89e6\u53d1\u901a\u4fe1\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\uff0c\u517c\u5bb9\u73b0\u6709\u6280\u672f\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.11163", "pdf": "https://arxiv.org/pdf/2506.11163", "abs": "https://arxiv.org/abs/2506.11163", "authors": ["James Batten", "Michiel Schaap", "Matthew Sinclair", "Ying Bai", "Ben Glocker"], "title": "Vector Representations of Vessel Trees", "categories": ["eess.IV", "cs.CV", "cs.GR"], "comment": null, "summary": "We introduce a novel framework for learning vector representations of\ntree-structured geometric data focusing on 3D vascular networks. Our approach\nemploys two sequentially trained Transformer-based autoencoders. In the first\nstage, the Vessel Autoencoder captures continuous geometric details of\nindividual vessel segments by learning embeddings from sampled points along\neach curve. In the second stage, the Vessel Tree Autoencoder encodes the\ntopology of the vascular network as a single vector representation, leveraging\nthe segment-level embeddings from the first model. A recursive decoding process\nensures that the reconstructed topology is a valid tree structure. Compared to\n3D convolutional models, this proposed approach substantially lowers GPU memory\nrequirements, facilitating large-scale training. Experimental results on a 2D\nsynthetic tree dataset and a 3D coronary artery dataset demonstrate superior\nreconstruction fidelity, accurate topology preservation, and realistic\ninterpolations in latent space. Our scalable framework, named VeTTA, offers\nprecise, flexible, and topologically consistent modeling of anatomical tree\nstructures in medical imaging.", "AI": {"tldr": "VeTTA\u6846\u67b6\u901a\u8fc7\u4e24\u4e2aTransformer\u81ea\u7f16\u7801\u5668\u5206\u9636\u6bb5\u5b66\u4e603D\u8840\u7ba1\u7f51\u7edc\u7684\u51e0\u4f55\u548c\u62d3\u6251\u7279\u5f81\uff0c\u964d\u4f4e\u4e86GPU\u5185\u5b58\u9700\u6c42\uff0c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u91cd\u5efa\u548c\u62d3\u6251\u4e00\u81f4\u6027\u3002", "motivation": "\u4e3a\u533b\u7597\u5f71\u50cf\u4e2d\u7684\u6811\u72b6\u89e3\u5256\u7ed3\u6784\u63d0\u4f9b\u4e00\u79cd\u7cbe\u786e\u3001\u7075\u6d3b\u4e14\u62d3\u6251\u4e00\u81f4\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5Transformer\u81ea\u7f16\u7801\u5668\uff1a\u7b2c\u4e00\u9636\u6bb5\u7684Vessel Autoencoder\u5b66\u4e60\u8840\u7ba1\u6bb5\u7684\u51e0\u4f55\u7279\u5f81\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7684Vessel Tree Autoencoder\u7f16\u7801\u6574\u4e2a\u8840\u7ba1\u7f51\u7edc\u7684\u62d3\u6251\u7ed3\u6784\u3002", "result": "\u57282D\u5408\u6210\u6811\u6570\u636e\u96c6\u548c3D\u51a0\u72b6\u52a8\u8109\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u4f18\u4e8e3D\u5377\u79ef\u6a21\u578b\u7684\u91cd\u5efa\u4fdd\u771f\u5ea6\u3001\u62d3\u6251\u51c6\u786e\u6027\u548c\u6f5c\u5728\u7a7a\u95f4\u63d2\u503c\u6548\u679c\u3002", "conclusion": "VeTTA\u6846\u67b6\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u5b9e\u9645\u533b\u7597\u5f71\u50cf\u5e94\u7528\u3002"}}
{"id": "2506.11423", "pdf": "https://arxiv.org/pdf/2506.11423", "abs": "https://arxiv.org/abs/2506.11423", "authors": ["Manish Bhatt"], "title": "Bhatt Conjectures: On Necessary-But-Not-Sufficient Benchmark Tautology for Human Like Reasoning", "categories": ["cs.CR", "cs.ET"], "comment": null, "summary": "Debates about whether Large Language or Reasoning Models (LLMs/LRMs) truly\nreason or merely pattern-match suffer from shifting goal posts. In my personal\nopinion, two analytic--hence \"tautological\"--benchmarks cut through that fog in\nmy mental model. In this paper, I attempt to write down my mental model in\nconcrete terms.", "AI": {"tldr": "\u6458\u8981\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6216\u63a8\u7406\u6a21\u578b\uff08LLMs/LRMs\uff09\u662f\u771f\u6b63\u63a8\u7406\u8fd8\u662f\u6a21\u5f0f\u5339\u914d\u7684\u8fa9\u8bba\uff0c\u5e76\u63d0\u51fa\u4e24\u4e2a\u5206\u6790\u6027\u57fa\u51c6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u660e\u786e\u8868\u8fbe\u5176\u601d\u7ef4\u6a21\u578b\uff0c\u4e3a\u89e3\u51b3LLMs/LRMs\u662f\u5426\u771f\u6b63\u63a8\u7406\u7684\u4e89\u8bba\u63d0\u4f9b\u6e05\u6670\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e24\u4e2a\u201c\u5206\u6790\u6027\u201d\uff08\u5373\u201c\u91cd\u8a00\u5f0f\u201d\uff09\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u533a\u5206\u63a8\u7406\u4e0e\u6a21\u5f0f\u5339\u914d\u3002", "result": "\u867d\u7136\u672a\u5177\u4f53\u63cf\u8ff0\u7ed3\u679c\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e24\u4e2a\u57fa\u51c6\u80fd\u591f\u7a7f\u900f\u6a21\u7cca\u6027\uff0c\u63d0\u4f9b\u660e\u786e\u7684\u5206\u6790\u5de5\u5177\u3002", "conclusion": "\u4f5c\u8005\u603b\u7ed3\u8ba4\u4e3a\uff0c\u901a\u8fc7\u8fd9\u4e24\u4e2a\u57fa\u51c6\u53ef\u4ee5\u66f4\u6e05\u6670\u5730\u5206\u6790LLMs/LRMs\u7684\u884c\u4e3a\uff0c\u4ece\u800c\u89e3\u51b3\u76f8\u5173\u4e89\u8bba\u3002"}}
{"id": "2506.11610", "pdf": "https://arxiv.org/pdf/2506.11610", "abs": "https://arxiv.org/abs/2506.11610", "authors": ["Daniel Hove Paludan", "Julie Fredsg\u00e5rd", "Kasper Patrick B\u00e4hrentz", "Ilhan Aslan"], "title": "\"If we misunderstand the client, we misspend 100 hours\": Exploring conversational AI and response types for information elicitation", "categories": ["cs.HC"], "comment": "27 pages, 8 figures", "summary": "Client-designer alignment is crucial to the success of design projects, yet\nlittle research has explored how digital technologies might influence this\nalignment. To address this gap, this paper presents a three-phase study\ninvestigating how digital systems can support requirements elicitation in\nprofessional design practice. Specifically, it examines how integrating a\nconversational agent and choice-based response formats into a digital\nelicitation tool affects early-stage client-designer collaboration. The first\nphase of the study inquired into the current practices of 10 design companies\nthrough semi-structured interviews, informing the system's design. The second\nphase evaluated the system using a 2x2 factorial design with 50 mock clients,\nquantifying the effects of conversational AI and response type on user\nexperience and perceived preparedness. In phase three, the system was presented\nto seven of the original 10 companies to gather reflections on its value,\nlimitations, and potential integration into practice. Findings show that both\nconversational AI and choice-based responses lead to lower dependability scores\non the User Experience Questionnaire, yet result in client input with greater\nclarity. We contribute design implications for integrating conversational AI\nand choice-based responses into elicitation tools to support mutual\nunderstanding in early-stage client-designer collaboration.", "AI": {"tldr": "\u7814\u7a76\u4e86\u6570\u5b57\u6280\u672f\uff08\u5982\u5bf9\u8bddAI\u548c\u9009\u62e9\u5f0f\u54cd\u5e94\uff09\u5982\u4f55\u6539\u5584\u5ba2\u6237\u4e0e\u8bbe\u8ba1\u5e08\u7684\u5408\u4f5c\uff0c\u53d1\u73b0\u5c3d\u7ba1\u7528\u6237\u4f53\u9a8c\u8bc4\u5206\u964d\u4f4e\uff0c\u4f46\u5ba2\u6237\u8f93\u5165\u7684\u6e05\u6670\u5ea6\u63d0\u9ad8\u3002", "motivation": "\u586b\u8865\u6570\u5b57\u6280\u672f\u5bf9\u5ba2\u6237\u4e0e\u8bbe\u8ba1\u5e08\u534f\u4f5c\u5f71\u54cd\u7684\u7a7a\u767d\u7814\u7a76\u3002", "method": "\u5206\u4e09\u9636\u6bb5\u7814\u7a76\uff1a\u8bbf\u8c0810\u5bb6\u8bbe\u8ba1\u516c\u53f8\u300150\u540d\u6a21\u62df\u7528\u6237\u76842x2\u5b9e\u9a8c\u3001\u7cfb\u7edf\u53cd\u9988\u6536\u96c6\u3002", "result": "\u5bf9\u8bddAI\u548c\u9009\u62e9\u5f0f\u54cd\u5e94\u964d\u4f4e\u4e86\u7528\u6237\u4f53\u9a8c\u8bc4\u5206\uff0c\u4f46\u63d0\u5347\u4e86\u5ba2\u6237\u8f93\u5165\u7684\u6e05\u6670\u5ea6\u3002", "conclusion": "\u8bbe\u8ba1\u5efa\u8bae\uff1a\u6574\u5408\u5bf9\u8bddAI\u548c\u9009\u62e9\u5f0f\u54cd\u5e94\u5de5\u5177\u4ee5\u4fc3\u8fdb\u521d\u671f\u5408\u4f5c\u7684\u76f8\u4e92\u7406\u89e3\u3002"}}
{"id": "2506.11925", "pdf": "https://arxiv.org/pdf/2506.11925", "abs": "https://arxiv.org/abs/2506.11925", "authors": ["M. Manzour", "Catherine M. Elias", "Omar M. Shehata", "R. Izquierdo", "M. A. Sotelo"], "title": "Real-World Deployment of a Lane Change Prediction Architecture Based on Knowledge Graph Embeddings and Bayesian Inference", "categories": ["cs.AR", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Research on lane change prediction has gained a lot of momentum in the last\ncouple of years. However, most research is confined to simulation or results\nobtained from datasets, leaving a gap between algorithmic advances and on-road\ndeployment. This work closes that gap by demonstrating, on real hardware, a\nlane-change prediction system based on Knowledge Graph Embeddings (KGEs) and\nBayesian inference. Moreover, the ego-vehicle employs a longitudinal braking\naction to ensure the safety of both itself and the surrounding vehicles. Our\narchitecture consists of two modules: (i) a perception module that senses the\nenvironment, derives input numerical features, and converts them into\nlinguistic categories; and communicates them to the prediction module; (ii) a\npretrained prediction module that executes a KGE and Bayesian inference model\nto anticipate the target vehicle's maneuver and transforms the prediction into\nlongitudinal braking action. Real-world hardware experimental validation\ndemonstrates that our prediction system anticipates the target vehicle's lane\nchange three to four seconds in advance, providing the ego vehicle sufficient\ntime to react and allowing the target vehicle to make the lane change safely.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\uff08KGE\uff09\u548c\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u8f66\u9053\u53d8\u6362\u9884\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9e\u9645\u786c\u4ef6\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u8f66\u9053\u53d8\u6362\u9884\u6d4b\u7814\u7a76\u591a\u5c40\u9650\u4e8e\u4eff\u771f\u6216\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u611f\u77e5\u6a21\u5757\u63d0\u53d6\u73af\u5883\u7279\u5f81\u5e76\u8f6c\u6362\u4e3a\u8bed\u8a00\u7c7b\u522b\uff0c\u9884\u6d4b\u6a21\u5757\u7ed3\u5408KGE\u548c\u8d1d\u53f6\u65af\u63a8\u65ad\u9884\u6d4b\u76ee\u6807\u8f66\u8f86\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u7eb5\u5411\u5236\u52a8\u786e\u4fdd\u5b89\u5168\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7cfb\u7edf\u80fd\u63d0\u524d3\u52304\u79d2\u9884\u6d4b\u8f66\u9053\u53d8\u6362\uff0c\u4e3a\u76ee\u6807\u8f66\u8f86\u548c\u81ea\u8f66\u63d0\u4f9b\u5145\u8db3\u53cd\u5e94\u65f6\u95f4\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u5b9e\u9645\u786c\u4ef6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8f66\u9053\u53d8\u6362\u9884\u6d4b\u548c\u5b89\u5168\u6027\u4fdd\u969c\u3002"}}
{"id": "2506.10993", "pdf": "https://arxiv.org/pdf/2506.10993", "abs": "https://arxiv.org/abs/2506.10993", "authors": ["Muhammad Naeem", "Cristina Seceleanu"], "title": "Contract-based Verification of Digital Twins", "categories": ["cs.SE", "cs.FL", "68N30, 68Q60", "D.2.4; D.2.1; F.3.1"], "comment": "Accepted at ICECCS 2025, to appear in Lecture Notes in Computer\n  Science (LNCS), Springer", "summary": "Digital twins are becoming powerful tools in industrial applications,\noffering virtual representations of cyber-physical systems. However,\nverification of these models remains a significant challenge due to the\npotentially large datasets used by the digital twin. This paper introduces an\ninnovative methodology for verifying neural network-based digital twin models,\nin a black-box fashion, by integrating model checking into the process. The\nlatter relies on defining and applying system-level contracts that capture the\nsystem's requirements, to verify the behavior of digital twin models,\nimplemented in Simulink. We develop an automated solution that simulates the\ndigital twin model for certain inputs, and feeds the predicted outputs together\nwith the inputs to the contract model described as a network of timed automata\nin the UPPAAL model checker. The latter verifies whether the predicted outputs\nfulfill the specified contracts. This approach allows us to identify scenarios\nwhere the digital twin's behavior fails to meet the contracts, without\nrequiring the digital twin's design technicalities. We apply our method to a\nboiler system case study for which we identify prediction errors via contract\nverification. Our work demonstrates the effectiveness of integrating model\nchecking with digital twin models for continuous improvement.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u96c6\u6210\u6a21\u578b\u68c0\u67e5\u6765\u9a8c\u8bc1\u795e\u7ecf\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u7cfb\u7edf\u7ea7\u5408\u7ea6\u548cUPPAAL\u6a21\u578b\u68c0\u67e5\u5668\u81ea\u52a8\u8bc6\u522b\u6a21\u578b\u884c\u4e3a\u4e0d\u7b26\u5408\u5408\u7ea6\u7684\u573a\u666f\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u5176\u6a21\u578b\u7684\u9a8c\u8bc1\u56e0\u5927\u6570\u636e\u96c6\u800c\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4e86\u89e3\u6280\u672f\u7ec6\u8282\u7684\u9ed1\u76d2\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u6a21\u578b\u68c0\u67e5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728Simulink\u4e2d\u5b9e\u73b0\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u5e76\u57fa\u4e8eUPPAAL\u6a21\u578b\u68c0\u67e5\u5668\u9a8c\u8bc1\u5176\u884c\u4e3a\u662f\u5426\u7b26\u5408\u7cfb\u7edf\u7ea7\u5408\u7ea6\u3002", "result": "\u5728\u9505\u7089\u7cfb\u7edf\u6848\u4f8b\u4e2d\u6210\u529f\u8bc6\u522b\u9884\u6d4b\u9519\u8bef\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6a21\u578b\u68c0\u67e5\u4e0e\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u7684\u7ed3\u5408\u53ef\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb\uff0c\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u3002"}}
{"id": "2506.11749", "pdf": "https://arxiv.org/pdf/2506.11749", "abs": "https://arxiv.org/abs/2506.11749", "authors": ["Samira Abdelrahman", "Hossam Farag", "Gilberto Berardinelli"], "title": "Distributed Learning for Reliable and Timely Communication in 6G Industrial Subnetworks", "categories": ["cs.NI"], "comment": null, "summary": "Emerging 6G industrial networks envision autonomous in-X subnetworks to\nsupport efficient and cost-effective short range, localized connectivity for\nautonomous control operations. Supporting timely transmission of event-driven,\ncritical control traffic is challenging in such networks is challenging due to\nlimited radio resources, dynamic device activity, and high mobility. In this\npaper, we propose a distributed, learning-based random access protocol that\nestablishes implicit inter-subnetwork coordination to minimize the collision\nprobability and improves timely delivery. Each subnetwork independently learns\nand selects access configurations based on a contention signature signal\nbroadcast by a central access point, enabling adaptive, collision-aware access\nunder dynamic traffic and mobility conditions. The proposed approach features\nlightweight neural models and online training, making it suitable for\ndeployment in constrained industrial subnetworks. Simulation results show that\nour method significantly improves the probability of timely packet delivery\ncompared to baseline methods, particularly in dense and high-load scenarios.\nFor instance, our proposed method achieves 21% gain in the probability of\ntimely packet delivery compared to a classical Multi-Armed Bandit (MAB) for an\nindustrial setting of 60 subnetworks and 5 radio channels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u3001\u57fa\u4e8e\u5b66\u4e60\u7684\u968f\u673a\u63a5\u5165\u534f\u8bae\uff0c\u7528\u4e8e6G\u5de5\u4e1a\u7f51\u7edc\u4e2d\u81ea\u4e3b\u5b50\u7f51\u7edc\u7684\u534f\u8c03\uff0c\u4ee5\u63d0\u9ad8\u4e8b\u4ef6\u9a71\u52a8\u63a7\u5236\u6d41\u91cf\u7684\u53ca\u65f6\u4f20\u8f93\u3002", "motivation": "\u57286G\u5de5\u4e1a\u7f51\u7edc\u4e2d\uff0c\u7531\u4e8e\u65e0\u7ebf\u8d44\u6e90\u6709\u9650\u3001\u8bbe\u5907\u6d3b\u52a8\u52a8\u6001\u6027\u548c\u9ad8\u79fb\u52a8\u6027\uff0c\u652f\u6301\u4e8b\u4ef6\u9a71\u52a8\u7684\u5173\u952e\u63a7\u5236\u6d41\u91cf\u7684\u53ca\u65f6\u4f20\u8f93\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u795e\u7ecf\u6a21\u578b\u548c\u5728\u7ebf\u8bad\u7ec3\uff0c\u57fa\u4e8e\u7ade\u4e89\u7b7e\u540d\u4fe1\u53f7\u5206\u5e03\u5f0f\u5b66\u4e60\u9009\u62e9\u63a5\u5165\u914d\u7f6e\uff0c\u4ee5\u51cf\u5c11\u78b0\u649e\u6982\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u5305\u53ca\u65f6\u4ea4\u4ed8\u7684\u6982\u7387\uff0c\u5728\u9ad8\u5bc6\u5ea6\u548c\u9ad8\u8d1f\u8f7d\u573a\u666f\u4e0b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u57286G\u5de5\u4e1a\u7f51\u7edc\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff08\u5982MAB\uff09\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2506.11711", "pdf": "https://arxiv.org/pdf/2506.11711", "abs": "https://arxiv.org/abs/2506.11711", "authors": ["Sergio Mu\u00f1iz Subi\u00f1as", "Jorge Mart\u00ednez Mart\u00edn", "Alejandro Mata Ali", "Javier Sedano", "\u00c1ngel Miguel Garc\u00eda-Vico"], "title": "Knapsack and Shortest Path Problems Generalizations From A Quantum-Inspired Tensor Network Perspective", "categories": ["quant-ph", "cs.ET", "68Q25, 90C27, 15A69"], "comment": "14 pages, 14 figures, extended version of the presented and published\n  at the 1st International Conference on Quantum Software (IQSOFT)", "summary": "In this paper, we present two tensor network quantum-inspired algorithms to\nsolve the knapsack and the shortest path problems, and enables to solve some of\nits variations. These methods provide an exact equation which returns the\noptimal solution of the problems. As in other tensor network algorithms for\ncombinatorial optimization problems, the method is based on imaginary time\nevolution and the implementation of restrictions in the tensor network. In\naddition, we introduce the use of symmetries and the reutilization of\nintermediate calculations, reducing the computational complexity for both\nproblems. To show the efficiency of our implementations, we carry out some\nperformance experiments and compare the results with those obtained by other\nclassical algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u5f20\u91cf\u7f51\u7edc\u7684\u91cf\u5b50\u542f\u53d1\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u80cc\u5305\u95ee\u9898\u548c\u6700\u77ed\u8def\u5f84\u95ee\u9898\u53ca\u5176\u53d8\u4f53\uff0c\u63d0\u4f9b\u7cbe\u786e\u7684\u6700\u4f18\u89e3\u3002\u65b9\u6cd5\u7ed3\u5408\u865a\u65f6\u95f4\u6f14\u5316\u548c\u5f20\u91cf\u7f51\u7edc\u7684\u9650\u5236\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7\u5bf9\u79f0\u6027\u548c\u4e2d\u95f4\u8ba1\u7b97\u91cd\u7528\u964d\u4f4e\u590d\u6742\u5ea6\u3002\u6027\u80fd\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff08\u5982\u80cc\u5305\u95ee\u9898\u548c\u6700\u77ed\u8def\u5f84\u95ee\u9898\uff09\u7684\u7ecf\u5178\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u5e0c\u671b\u901a\u8fc7\u91cf\u5b50\u542f\u53d1\u7b97\u6cd5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u57fa\u4e8e\u5f20\u91cf\u7f51\u7edc\u7684\u7b97\u6cd5\uff0c\u7ed3\u5408\u865a\u65f6\u95f4\u6f14\u5316\u548c\u9650\u5236\u6761\u4ef6\uff0c\u5229\u7528\u5bf9\u79f0\u6027\u548c\u4e2d\u95f4\u8ba1\u7b97\u7ed3\u679c\u91cd\u7528\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u7cbe\u786e\u6c42\u89e3\u6700\u4f18\u89e3\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u76f8\u5bf9\u4e8e\u7ecf\u5178\u65b9\u6cd5\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u91cf\u5b50\u542f\u53d1\u5f20\u91cf\u7f51\u7edc\u7b97\u6cd5\u4e3a\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u9014\u5f84\u3002"}}
{"id": "2506.11665", "pdf": "https://arxiv.org/pdf/2506.11665", "abs": "https://arxiv.org/abs/2506.11665", "authors": ["Mengisti Berihu Girmay", "Felix M\u00f6hrle"], "title": "Perspectives on Explanation Formats From Two Stakeholder Groups in Germany: Software Providers and Dairy Farmers", "categories": ["cs.HC"], "comment": "Accepted at IJCAI 2024, Explainable AI Workshop", "summary": "This paper examines the views of software providers in the German dairy\nindustry with regard to dairy farmers' needs for explanation of digital\ndecision support systems. The study is based on mastitis detection in dairy\ncows using a hypothetical herd management system. We designed four exemplary\nexplanation formats for mastitis assessments with different types of\npresentation (textual, rule-based, herd comparison, and time series). In our\nprevious study, 14 dairy farmers in Germany had rated these formats in terms of\ncomprehensibility and the trust they would have in a system providing each\nformat. In this study, we repeat the survey with 13 software providers active\nin the German dairy industry. We ask them how well they think the formats would\nbe received by farmers. We hypothesized that there may be discrepancies between\nthe views of both groups that are worth investigating, partly to find reasons\nfor the reluctance to adopt digital systems. A comparison of the feedback from\nboth groups supports the hypothesis and calls for further investigation. The\nresults show that software providers tend to make assumptions about farmers'\npreferences that are not necessarily accurate. Our study, although not\nrepresentative due to the small sample size, highlights the potential benefits\nof a thorough user requirements analysis (farmers' needs) to improve software\nadaptation and user acceptance.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u5fb7\u56fd\u5976\u519c\u548c\u8f6f\u4ef6\u63d0\u4f9b\u5546\u5bf9\u6570\u5b57\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u89e3\u91ca\u683c\u5f0f\u7684\u770b\u6cd5\uff0c\u53d1\u73b0\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8\u5976\u519c\u548c\u8f6f\u4ef6\u63d0\u4f9b\u5546\u5bf9\u89e3\u91ca\u683c\u5f0f\u7684\u4e0d\u540c\u89c2\u70b9\uff0c\u4ee5\u627e\u51fa\u6570\u5b57\u7cfb\u7edf\u91c7\u7528\u7387\u4f4e\u7684\u539f\u56e0\u3002", "method": "\u8bbe\u8ba1\u56db\u79cd\u89e3\u91ca\u683c\u5f0f\uff08\u6587\u672c\u3001\u89c4\u5219\u3001\u755c\u7fa4\u6bd4\u8f83\u3001\u65f6\u95f4\u5e8f\u5217\uff09\uff0c\u5206\u522b\u8c03\u67e5\u5976\u519c\u548c\u8f6f\u4ef6\u63d0\u4f9b\u5546\u7684\u53cd\u9988\u3002", "result": "\u8f6f\u4ef6\u63d0\u4f9b\u5546\u5bf9\u5976\u519c\u504f\u597d\u7684\u5047\u8bbe\u4e0d\u51c6\u786e\uff0c\u8868\u660e\u9700\u66f4\u6df1\u5165\u7684\u7528\u6237\u9700\u6c42\u5206\u6790\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u7528\u6237\u9700\u6c42\u5206\u6790\u5bf9\u6539\u8fdb\u8f6f\u4ef6\u9002\u5e94\u6027\u548c\u7528\u6237\u63a5\u53d7\u5ea6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.11105", "pdf": "https://arxiv.org/pdf/2506.11105", "abs": "https://arxiv.org/abs/2506.11105", "authors": ["Uttej Kallakurik", "Edward Humes", "Rithvik Jonna", "Xiaomin Lin", "Tinoosh Mohsenin"], "title": "Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation", "categories": ["cs.CL", "cs.AI", "cs.AR", "cs.SY", "eess.SY"], "comment": null, "summary": "Large Language Models (LLMs) have significant impact on the healthcare\nscenarios but remain prohibitively large for deployment in real-time,\nresource-constrained environments such as edge devices. In this work, we\nintroduce a novel medical assistant system, optimized through our\ngeneral-purpose compression framework, which tailors Large Language Models\n(LLMs) for deployment in specialized domains. By measuring neuron saliency on\ndomain-specific data, our method can aggressively prune irrelevant neurons,\nreducing model size while preserving performance. Following pruning, we apply\npost-training quantization to further reduce the memory footprint, and evaluate\nthe compressed model across medical benchmarks including MedMCQA, MedQA, and\nPubMedQA. We also deploy the 50\\% compressed Gemma and the 67\\% compressed\nLLaMA3 models on Jetson Orin Nano (18.7W peak) and Raspberry Pi 5 (6.3W peak),\nachieving real-time, energy-efficient inference under hardware constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u901a\u7528\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u526a\u679d\u548c\u91cf\u5316\u6280\u672f\uff0c\u5728\u4e0d\u635f\u5931\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u533b\u7597\u9886\u57df\u7684\u8fb9\u7f18\u8bbe\u5907\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u56e0\u6a21\u578b\u8fc7\u5927\u96be\u4ee5\u5728\u8d44\u6e90\u6709\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u65f6\u8fd0\u884c\u3002", "method": "\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u6570\u636e\u6d4b\u91cf\u795e\u7ecf\u5143\u91cd\u8981\u6027\uff0c\u8fdb\u884c\u526a\u679d\u548c\u91cf\u5316\uff0c\u4ee5\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "result": "\u6210\u529f\u538b\u7f29Gemma\u548cLLaMA3\u6a21\u578b\uff0c\u5728Jetson Orin Nano\u548cRaspberry Pi 5\u4e0a\u5b9e\u73b0\u4e86\u5b9e\u65f6\u9ad8\u6548\u7684\u63a8\u7406\u3002", "conclusion": "\u63d0\u51fa\u7684\u538b\u7f29\u65b9\u6cd5\u6709\u6548\u652f\u6301\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2506.11024", "pdf": "https://arxiv.org/pdf/2506.11024", "abs": "https://arxiv.org/abs/2506.11024", "authors": ["Minhyuk Seo", "Taeheon Kim", "Hankook Lee", "Jonghyun Choi", "Tinne Tuytelaars"], "title": "Not All Clients Are Equal: Personalized Federated Learning on Heterogeneous Multi-Modal Clients", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Foundation models have shown remarkable capabilities across diverse\nmulti-modal tasks, but their centralized training raises privacy concerns and\ninduces high transmission costs. In contrast, federated learning (FL) offers a\ndistributed alternative without the need to share data. Recently, for the\ngrowing demand for personalizing AI models for different user purposes,\npersonalized federated learning (PFL) has emerged. PFL allows each client to\nleverage the knowledge of other clients for further adaptation to individual\nuser preferences, again without the need to share data. Despite its potential,\nmost PFL studies remain confined to simulated environments, overlooking the\ndata and model heterogeneity that arise in real-world scenarios. In contrast,\nwe first consider large data heterogeneity, evaluating on a new benchmark for\nmulti-modal PFL, spanning 40 distinct tasks with realistic data distribution\nshifts. We then consider model heterogeneity in that we do not assume that all\nclients share similar model architectures. To address data heterogeneity, we\npropose a task-similarity-aware model aggregation method that provides\ncustomized global models to each client. For model heterogeneity, we propose a\ndimension-invariant module that enables knowledge sharing across heterogeneous\nmodels. Empirical validations demonstrate that the proposed approach\noutperforms the state-of-the-art, excelling in both personalization and\ngeneralization capabilities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\uff08PFL\uff09\u4e2d\u5904\u7406\u6570\u636e\u548c\u6a21\u578b\u5f02\u8d28\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4efb\u52a1\u76f8\u4f3c\u6027\u611f\u77e5\u7684\u6a21\u578b\u805a\u5408\u65b9\u6cd5\u548c\u7ef4\u5ea6\u4e0d\u53d8\u6a21\u5757\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u7684\u9690\u79c1\u548c\u4f20\u8f93\u6210\u672c\u95ee\u9898\uff0c\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\uff08PFL\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u6570\u636e\u548c\u6a21\u578b\u5f02\u8d28\u6027\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4efb\u52a1\u76f8\u4f3c\u6027\u611f\u77e5\u7684\u6a21\u578b\u805a\u5408\u65b9\u6cd5\u5904\u7406\u6570\u636e\u5f02\u8d28\u6027\uff0c\u4ee5\u53ca\u7ef4\u5ea6\u4e0d\u53d8\u6a21\u5757\u89e3\u51b3\u6a21\u578b\u5f02\u8d28\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u572840\u4e2a\u591a\u6a21\u6001PFL\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728PFL\u4e2d\u6709\u6548\u5e94\u5bf9\u4e86\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5f02\u8d28\u6027\u6311\u6218\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4e2a\u6027\u5316\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.10994", "pdf": "https://arxiv.org/pdf/2506.10994", "abs": "https://arxiv.org/abs/2506.10994", "authors": ["April Clarke"], "title": "Improving Software Team Communication Through Social Interventions in Project Management Tools", "categories": ["cs.SE"], "comment": "ICSE 2025 Doctoral Track. arXiv admin note: substantial text overlap\n  with arXiv:2502.01923", "summary": "Productive software engineering teams require effective communication and\nbalanced contributions between team members. However, teams are often\nineffective at these skills, which is detrimental to project success.\nProject-based university courses are an opportunity for students to practise\nthese skills, but we have yet to establish how we can guide students towards\nimproving their communication and coordination. We aim to develop project\nmanagement tool features, informed by social network analysis, that nudge\nstudents in software engineering group projects towards beneficial behaviours.\nTo do this, we will first evaluate the suitability of social network analysis\ntechniques for identifying areas of improvement in teams' communication. Then,\nwe will develop features in a project management tool that aid students in\nidentifying and addressing these areas of improvement, and evaluate them in the\ncontext of a software engineering group project.", "AI": {"tldr": "\u5229\u7528\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u6280\u672f\u5f00\u53d1\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u529f\u80fd\uff0c\u5e2e\u52a9\u5b66\u751f\u6539\u5584\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u9879\u76ee\u4e2d\u7684\u6c9f\u901a\u4e0e\u534f\u8c03\u884c\u4e3a\u3002", "motivation": "\u63d0\u9ad8\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u6210\u5458\u95f4\u7684\u6c9f\u901a\u6548\u7387\u548c\u8d21\u732e\u5e73\u8861\uff0c\u4fc3\u8fdb\u9879\u76ee\u6210\u529f\uff0c\u5c24\u5176\u662f\u5728\u5b66\u751f\u56e2\u961f\u9879\u76ee\u4e2d\u3002", "method": "\u9996\u5148\u8bc4\u4f30\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u6280\u672f\u5bf9\u8bc6\u522b\u56e2\u961f\u6c9f\u901a\u6539\u8fdb\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u968f\u540e\u5f00\u53d1\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u529f\u80fd\u5e76\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "\u5c1a\u672a\u660e\u786e\uff08\u7814\u7a76\u8fdb\u884c\u4e2d\uff09\u3002", "conclusion": "\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u53ef\u80fd\u6210\u4e3a\u6539\u5584\u5b66\u751f\u56e2\u961f\u6c9f\u901a\u4e0e\u534f\u8c03\u7684\u6709\u6548\u5de5\u5177\uff0c\u9700\u8fdb\u4e00\u6b65\u5f00\u53d1\u5e76\u9a8c\u8bc1\u5176\u9879\u76ee\u7ba1\u7406\u529f\u80fd\u3002"}}
{"id": "2506.11828", "pdf": "https://arxiv.org/pdf/2506.11828", "abs": "https://arxiv.org/abs/2506.11828", "authors": ["Xingqin Lin"], "title": "A Tale of Two Mobile Generations: 5G-Advanced and 6G in 3GPP Release 20", "categories": ["cs.NI"], "comment": "9 pages, 5 figures, 1 table, submitted for possible publication", "summary": "As the telecommunications industry stands at the crossroads between the fifth\ngeneration (5G) and sixth generation (6G) of mobile communications, the 3rd\ngeneration partnership project (3GPP) Release 20 emerges as a pivotal point of\ntransition. By striking a balance between enhancing 5G-Advanced capabilities\nand setting the stage for 6G, Release 20 provides the crucial foundation upon\nwhich future mobile communication standards and deployments will be built. This\narticle examines these dual objectives, outlining the key enhancements, the\nmotivations behind them, and their implications for the future of mobile\ncommunications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e863GPP Release 20\u57285G\u548c6G\u8fc7\u6e21\u9636\u6bb5\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5f3a\u8c03\u4e86\u5176\u5e73\u88615G-Advanced\u4e0e6G\u53d1\u5c55\u7684\u53cc\u91cd\u76ee\u6807\u3002", "motivation": "\u7535\u4fe1\u884c\u4e1a\u6b63\u9762\u4e345G\u54116G\u8fc7\u6e21\u7684\u5173\u952e\u65f6\u671f\uff0c3GPP Release 20\u4f5c\u4e3a\u8f6c\u6298\u70b9\uff0c\u9700\u8981\u5e73\u88615G-Advanced\u7684\u589e\u5f3a\u4e0e6G\u7684\u57fa\u7840\u5efa\u8bbe\u3002", "method": "\u6587\u7ae0\u901a\u8fc7\u5206\u6790Release 20\u7684\u5173\u952e\u6539\u8fdb\uff0c\u63a2\u8ba8\u5176\u8bbe\u8ba1\u52a8\u673a\u53ca\u5176\u5bf9\u79fb\u52a8\u901a\u4fe1\u672a\u6765\u7684\u5f71\u54cd\u3002", "result": "Release 20\u4e3a\u672a\u6765\u79fb\u52a8\u901a\u4fe1\u6807\u51c6\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002", "conclusion": "Release 20\u57285G\u548c6G\u8fc7\u6e21\u9636\u6bb5\u53d1\u6325\u4e86\u6865\u6881\u4f5c\u7528\uff0c\u4e3a\u672a\u6765\u6280\u672f\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.11718", "pdf": "https://arxiv.org/pdf/2506.11718", "abs": "https://arxiv.org/abs/2506.11718", "authors": ["Yun Wang", "Yan Lu"], "title": "Interaction, Process, Infrastructure: A Unified Architecture for Human-Agent Collaboration", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "As AI tools proliferate across domains, from chatbots and copilots to\nemerging agents, they increasingly support professional knowledge work. Yet\ndespite their growing capabilities, these systems remain fragmented: they\nassist with isolated tasks but lack the architectural scaffolding for\nsustained, adaptive collaboration. We propose a layered framework for\nhuman-agent systems that integrates three interdependent dimensions:\ninteraction, process, and infrastructure. Crucially, our architecture elevates\nprocess to a primary focus by making it explicit, inspectable, and adaptable,\nenabling humans and agents to align with evolving goals and coordinate over\ntime. This model clarifies limitations of current tools, unifies emerging\nsystem design approaches, and reveals new opportunities for researchers and AI\nsystem builders. By grounding intelligent behavior in structured collaboration,\nwe reimagine human-agent collaboration not as task-specific augmentation, but\nas a form of coherent and aligned system for real-world work.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u6846\u67b6\uff0c\u6574\u5408\u4e86\u4ea4\u4e92\u3001\u6d41\u7a0b\u548c\u57fa\u7840\u8bbe\u65bd\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u4ee5\u89e3\u51b3\u5f53\u524dAI\u5de5\u5177\u5728\u4e13\u4e1a\u5de5\u4f5c\u4e2d\u534f\u4f5c\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u5de5\u5177\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u7f3a\u4e4f\u6301\u7eed\u7684\u3001\u9002\u5e94\u6027\u5f3a\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u96be\u4ee5\u6ee1\u8db3\u4e13\u4e1a\u77e5\u8bc6\u7684\u957f\u671f\u534f\u4f5c\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8\u6d41\u7a0b\u7684\u663e\u5f0f\u5316\u3001\u53ef\u68c0\u67e5\u548c\u53ef\u9002\u5e94\u6027\uff0c\u4ee5\u4fc3\u8fdb\u4eba\u7c7b\u4e0eAI\u7684\u957f\u671f\u534f\u4f5c\u3002", "result": "\u8be5\u6846\u67b6\u63ed\u793a\u4e86\u5f53\u524d\u5de5\u5177\u7684\u5c40\u9650\u6027\uff0c\u7edf\u4e00\u4e86\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5e76\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u534f\u4f5c\uff0c\u4eba\u7c7b\u4e0eAI\u7684\u534f\u4f5c\u4e0d\u518d\u662f\u4efb\u52a1\u7279\u5b9a\u589e\u5f3a\uff0c\u800c\u662f\u5b9e\u73b0\u73b0\u5b9e\u5de5\u4f5c\u4e2d\u4e00\u81f4\u7684\u3001\u5bf9\u9f50\u7684\u7cfb\u7edf\u3002"}}
{"id": "2506.11225", "pdf": "https://arxiv.org/pdf/2506.11225", "abs": "https://arxiv.org/abs/2506.11225", "authors": ["Aditi Rath", "Dinesh Kumar Panda", "Colin Benjamin"], "title": "Controlling quantum chaos via Parrondo strategies on NISQ hardware", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.AR", "nlin.CD"], "comment": "18 pages, 22 figures, 6 tables", "summary": "Advancements in Noisy Intermediate-Scale Quantum (NISQ) computing are\nsteadily pushing these systems toward outperforming classical supercomputers on\nspecific, well-defined computational tasks. In this work, we explore and\ncontrol quantum chaos in NISQ systems using discrete-time quantum walks (DTQW)\non cyclic graphs. To efficiently implement quantum walks on NISQ hardware, we\nemploy the quantum Fourier transform (QFT) to diagonalize the conditional shift\noperator, optimizing circuit depth and fidelity. We experimentally realize the\ntransition from quantum chaos to order via DTQW dynamics on both odd and even\ncyclic graphs, specifically 3- and 4-cycle graphs, using the counterintuitive\nParrondo's paradox strategy across three different NISQ devices. While the\n4-cycle graphs exhibit high-fidelity quantum evolution, the 3-cycle\nimplementation shows significant fidelity improvement when augmented with\ndynamical decoupling pulses. Our results demonstrate a practical approach to\nprobing and harnessing controlled chaotic dynamics on real quantum hardware,\nlaying the groundwork for future quantum algorithms and cryptographic protocols\nbased on quantum walks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728NISQ\u7cfb\u7edf\u4e2d\u5229\u7528\u79bb\u6563\u65f6\u95f4\u91cf\u5b50\u884c\u8d70\uff08DTQW\uff09\u63a2\u7d22\u548c\u63a7\u5236\u91cf\u5b50\u6df7\u6c8c\uff0c\u901a\u8fc7\u91cf\u5b50\u5085\u91cc\u53f6\u53d8\u6362\u4f18\u5316\u7535\u8def\u5b9e\u73b0\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u89c2\u5bdf\u5230\u91cf\u5b50\u6df7\u6c8c\u5230\u6709\u5e8f\u7684\u8f6c\u53d8\u3002", "motivation": "\u968f\u7740NISQ\u8ba1\u7b97\u7684\u8fdb\u6b65\uff0c\u7814\u7a76\u5982\u4f55\u5728\u8fd9\u79cd\u7cfb\u7edf\u4e2d\u6709\u6548\u63a7\u5236\u91cf\u5b50\u6df7\u6c8c\uff0c\u4ee5\u63a2\u7d22\u5176\u6f5c\u5728\u5e94\u7528\u3002", "method": "\u4f7f\u7528DTQW\u548c\u91cf\u5b50\u5085\u91cc\u53f6\u53d8\u6362\uff08QFT\uff09\u4f18\u5316\u7535\u8def\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u57283-\u548c4-\u5faa\u73af\u56fe\u4e0a\u7684\u91cf\u5b50\u884c\u8d70\u3002", "result": "4-\u5faa\u73af\u56fe\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5ea6\u91cf\u5b50\u6f14\u5316\uff0c\u800c3-\u5faa\u73af\u56fe\u901a\u8fc7\u52a8\u6001\u89e3\u8026\u8109\u51b2\u663e\u8457\u63d0\u5347\u4e86\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u57fa\u4e8e\u91cf\u5b50\u884c\u8d70\u7684\u7b97\u6cd5\u548c\u5bc6\u7801\u534f\u8bae\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2506.11100", "pdf": "https://arxiv.org/pdf/2506.11100", "abs": "https://arxiv.org/abs/2506.11100", "authors": ["Tianle Wang", "Jorge Ramirez", "Cristina Garcia-Cardona", "Thomas Proffen", "Shantenu Jha", "Sudip K. Seal"], "title": "An Active Learning-Based Streaming Pipeline for Reduced Data Training of Structure Finding Models in Neutron Diffractometry", "categories": ["cs.LG", "cs.AI", "cs.DC", "physics.atm-clus", "physics.data-an"], "comment": null, "summary": "Structure determination workloads in neutron diffractometry are\ncomputationally expensive and routinely require several hours to many days to\ndetermine the structure of a material from its neutron diffraction patterns.\nThe potential for machine learning models trained on simulated neutron\nscattering patterns to significantly speed up these tasks have been reported\nrecently. However, the amount of simulated data needed to train these models\ngrows exponentially with the number of structural parameters to be predicted\nand poses a significant computational challenge. To overcome this challenge, we\nintroduce a novel batch-mode active learning (AL) policy that uses uncertainty\nsampling to simulate training data drawn from a probability distribution that\nprefers labelled examples about which the model is least certain. We confirm\nits efficacy in training the same models with about 75% less training data\nwhile improving the accuracy. We then discuss the design of an efficient\nstream-based training workflow that uses this AL policy and present a\nperformance study on two heterogeneous platforms to demonstrate that, compared\nwith a conventional training workflow, the streaming workflow delivers about\n20% shorter training time without any loss of accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u6279\u6b21\u6a21\u5f0f\u7b56\u7565\uff0c\u663e\u8457\u51cf\u5c11\u4e2d\u5b50\u884d\u5c04\u7ed3\u6784\u5206\u6790\u6240\u9700\u7684\u8bad\u7ec3\u6570\u636e\u91cf\uff0c\u540c\u65f6\u63d0\u5347\u51c6\u786e\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u6d41\u5f0f\u8bad\u7ec3\u6d41\u7a0b\u3002", "motivation": "\u4e2d\u5b50\u884d\u5c04\u7ed3\u6784\u5206\u6790\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u8f83\u957f\uff0c\u800c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6a21\u62df\u6570\u636e\uff0c\u6570\u636e\u91cf\u968f\u7ed3\u6784\u53c2\u6570\u589e\u957f\u800c\u6307\u6570\u7ea7\u589e\u52a0\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u91c7\u6837\u7684\u6279\u6b21\u6a21\u5f0f\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u4f18\u5148\u9009\u62e9\u6a21\u578b\u6700\u4e0d\u786e\u5b9a\u7684\u6807\u8bb0\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684\u6d41\u5f0f\u8bad\u7ec3\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u51cf\u5c11\u7ea675%\u7684\u8bad\u7ec3\u6570\u636e\u9700\u6c42\uff0c\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u6027\uff1b\u6d41\u5f0f\u8bad\u7ec3\u6d41\u7a0b\u5728\u5f02\u6784\u5e73\u53f0\u4e0a\u7f29\u77ed20%\u8bad\u7ec3\u65f6\u95f4\uff0c\u4e14\u65e0\u51c6\u786e\u7387\u635f\u5931\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\u548c\u6d41\u5f0f\u8bad\u7ec3\u6d41\u7a0b\u663e\u8457\u964d\u4f4e\u4e86\u4e2d\u5b50\u884d\u5c04\u7ed3\u6784\u5206\u6790\u7684\u8bad\u7ec3\u6210\u672c\u548c\u65f6\u95f4\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.10995", "pdf": "https://arxiv.org/pdf/2506.10995", "abs": "https://arxiv.org/abs/2506.10995", "authors": ["Jorge Martinez-Gil"], "title": "Evaluating Small-Scale Code Models for Code Clone Detection", "categories": ["cs.SE"], "comment": "20 pages", "summary": "Detecting code clones is relevant to software maintenance and code\nrefactoring. This challenge still presents unresolved cases, mainly when\nstructural similarity does not reflect functional equivalence, though recent\ncode models show promise. Therefore, this research aims to systematically\nmeasure the performance of several newly introduced small code models in\nclassifying code pairs as clones or non-clones. The evaluation is based on five\ndatasets: BigCloneBench, CodeJam, Karnalim, POJ104, and PoolC, as well as six\ncode models: CodeBERT, GraphCodeBERT, Salesforce T5, UniXCoder, PLBART, and\nPolycoder. Most models performed well across standard metrics, including\naccuracy, precision, recall, and F1-score. However, a marginal fraction of\nclones remains challenging to detect, especially when the code looks similar\nbut performs different operations. The source code that illustrates our\napproach is available at:\nhttps://github.com/jorge-martinez-gil/small-code-models", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5c0f\u578b\u4ee3\u7801\u6a21\u578b\u5728\u68c0\u6d4b\u4ee3\u7801\u514b\u9686\u4e2d\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u8868\u660e\u5927\u90e8\u5206\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u67d0\u4e9b\u76f8\u4f3c\u4f46\u529f\u80fd\u4e0d\u540c\u7684\u4ee3\u7801\u4ecd\u96be\u4ee5\u68c0\u6d4b\u3002", "motivation": "\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u5bf9\u8f6f\u4ef6\u7ef4\u62a4\u548c\u91cd\u6784\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u7ed3\u6784\u76f8\u4f3c\u4f46\u529f\u80fd\u4e0d\u7b49\u540c\u7684\u60c5\u51b5\u4e0b\u4ecd\u6709\u6311\u6218\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86\u516d\u79cd\u5c0f\u578b\u4ee3\u7801\u6a21\u578b\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u5305\u62ec\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u7b49\u6307\u6807\u3002", "result": "\u591a\u6570\u6a21\u578b\u5728\u6807\u51c6\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u76f8\u4f3c\u4f46\u529f\u80fd\u4e0d\u540c\u7684\u4ee3\u7801\u514b\u9686\u4ecd\u96be\u4ee5\u68c0\u6d4b\u3002", "conclusion": "\u5c0f\u578b\u4ee3\u7801\u6a21\u578b\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u89e3\u51b3\u7279\u5b9a\u6311\u6218\u3002"}}
{"id": "2506.11947", "pdf": "https://arxiv.org/pdf/2506.11947", "abs": "https://arxiv.org/abs/2506.11947", "authors": ["Ali Rasaii", "Ha Dao", "Anja Feldmann", "Mohammadmadi Javid", "Oliver Gasser", "Devashish Gosain"], "title": "Intractable Cookie Crumbs: Unveiling the Nexus of Stateful Banner Interaction and Tracking Cookies", "categories": ["cs.NI"], "comment": "Code, analysis scripts, and datasets available at:\n  https://bannerclick.github.io", "summary": "In response to the ePrivacy Directive and the consent requirements introduced\nby the GDPR, websites began deploying consent banners to obtain user permission\nfor data collection and processing. However, due to shared third-party services\nand technical loopholes, non-consensual cross-site tracking can still occur. In\nfact, contrary to user expectations of seemingly isolated consent, a user's\ndecision on one website may affect tracking behavior on others. In this study,\nwe investigate the technical and behavioral mechanisms behind these\ndiscrepancies. Specifically, we disclose a persistent tracking mechanism\nexploiting web cookies. These cookies, which we refer to as intractable, are\ninitially set on websites with accepted banners, persist in the browser, and\nare subsequently sent to trackers before the user provides explicit consent on\nother websites. To meticulously analyze this covert tracking behavior, we\nconduct an extensive measurement study performing stateful crawls on over 20k\ndomains from the Tranco top list, strategically accepting banners in the first\nhalf of domains and measuring intractable cookies in the second half. Our\nfindings reveal that around 50% of websites send at least one intractable\ncookie, with the majority set to expire after more than 10 days. In addition,\nenabling the Global Privacy Control (GPC) signal initially reduces the number\nof intractable cookies by 30% on average, with a further 32% reduction possible\non subsequent visits by rejecting the banners. Moreover, websites with Consent\nManagement Platform (CMP) banners, on average, send 6.9 times more intractable\ncookies compared to those with native banners. Our research further reveals\nthat even if users reject all other banners, they still receive a large number\nof intractable cookies set by websites with cookie paywalls.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86\u7f51\u7ad9\u5982\u4f55\u5728\u7528\u6237\u672a\u540c\u610f\u7684\u60c5\u51b5\u4e0b\u901a\u8fc7\u6280\u672f\u6f0f\u6d1e\u8fdb\u884c\u8de8\u7ad9\u8ffd\u8e2a\uff0c\u5c24\u5176\u662f\u5229\u7528\u6301\u4e45\u6027Cookie\u3002", "motivation": "\u8c03\u67e5ePrivacy\u6307\u4ee4\u548cGDPR\u6846\u67b6\u4e0b\uff0c\u7f51\u7ad9\u5982\u4f55\u7ed5\u8fc7\u7528\u6237\u540c\u610f\u8fdb\u884c\u6570\u636e\u8ffd\u8e2a\u3002", "method": "\u5bf9Tranco\u6392\u884c\u699c\u4e0a\u76842\u4e07\u591a\u4e2a\u57df\u540d\u8fdb\u884c\u6709\u72b6\u6001\u722c\u53d6\u548c\u5206\u6790\u3002", "result": "\u7ea650%\u7684\u7f51\u7ad9\u53d1\u9001\u81f3\u5c11\u4e00\u4e2a\u6301\u4e45\u6027Cookie\uff0c\u542f\u7528GPC\u4fe1\u53f7\u53ef\u663e\u8457\u51cf\u5c11\u6570\u91cf\u3002", "conclusion": "\u5f53\u524d\u7684\u9690\u79c1\u4fdd\u62a4\u63aa\u65bd\u5b58\u5728\u6f0f\u6d1e\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u6280\u672f\u548c\u653f\u7b56\u5e72\u9884\u3002"}}
{"id": "2506.11781", "pdf": "https://arxiv.org/pdf/2506.11781", "abs": "https://arxiv.org/abs/2506.11781", "authors": ["Gaspard Merten", "Gilles Dejaegere", "Mahmoud Sakr"], "title": "GeoPandas-AI: A Smart Class Bringing LLM as Stateful AI Code Assistant", "categories": ["cs.HC", "cs.SE"], "comment": "Submitted to ACM SIGSPATIAL 2025", "summary": "Geospatial data analysis plays a crucial role in tackling intricate societal\nchallenges such as urban planning and climate modeling. However, employing\ntools like GeoPandas, a prominent Python library for geospatial data\nmanipulation, necessitates expertise in complex domain-specific syntax and\nworkflows. GeoPandas-AI addresses this gap by integrating LLMs directly into\nthe GeoPandas workflow, transforming the GeoDataFrame class into an\nintelligent, stateful class for both data analysis and geospatial code\ndevelopment. This paper formalizes the design of such a smart class and\nprovides an open-source implementation of GeoPandas-AI in PyPI package manager.\nThrough its innovative combination of conversational interfaces and stateful\nexploitation of LLMs for code generation and data analysis, GeoPandas-AI\nintroduces a new paradigm for code-copilots and instantiates it for geospatial\ndevelopment.", "AI": {"tldr": "GeoPandas-AI\u901a\u8fc7\u96c6\u6210LLM\u5230GeoPandas\u5de5\u4f5c\u6d41\u4e2d\uff0c\u7b80\u5316\u4e86\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u6790\uff0c\u4e3a\u4e13\u5bb6\u548c\u521d\u5b66\u8005\u63d0\u4f9b\u4e86\u667a\u80fd\u5316\u7684\u4ee3\u7801\u751f\u6210\u548c\u5206\u6790\u5de5\u5177\u3002", "motivation": "\u9488\u5bf9\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u6790\u5de5\u5177\uff08\u5982GeoPandas\uff09\u4f7f\u7528\u590d\u6742\u3001\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u5229\u7528LLM\u6280\u672f\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0GeoPandas-AI\uff0c\u901a\u8fc7\u667a\u80fd\u5316\u7684GeoDataFrame\u7c7b\u548c\u5bf9\u8bdd\u754c\u9762\uff0c\u5229\u7528LLM\u751f\u6210\u4ee3\u7801\u548c\u5206\u6790\u6570\u636e\u3002", "result": "\u5f00\u6e90\u4e86GeoPandas-AI\u7684PyPI\u5305\uff0c\u4e3a\u5730\u7406\u7a7a\u95f4\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u4ee3\u7801\u8f85\u52a9\u8303\u5f0f\u3002", "conclusion": "GeoPandas-AI\u901a\u8fc7\u7ed3\u5408\u5bf9\u8bdd\u754c\u9762\u548cLLM\u6280\u672f\uff0c\u5f00\u521b\u4e86\u5730\u7406\u7a7a\u95f4\u5f00\u53d1\u7684\u65b0\u65b9\u5f0f\uff0c\u964d\u4f4e\u4e86\u6280\u672f\u95e8\u69db\u3002"}}
{"id": "2506.11760", "pdf": "https://arxiv.org/pdf/2506.11760", "abs": "https://arxiv.org/abs/2506.11760", "authors": ["Zainab Aizaz", "James C. Knight", "Thomas Nowotny"], "title": "FeNN: A RISC-V vector processor for Spiking Neural Network acceleration", "categories": ["cs.NE", "cs.AI", "cs.AR"], "comment": "7 pages, 4 figures. Accepted in Proceedings of Neuro Inspired\n  Computational Elements Conference 2025", "summary": "Spiking Neural Networks (SNNs) have the potential to drastically reduce the\nenergy requirements of AI systems. However, mainstream accelerators like GPUs\nand TPUs are designed for the high arithmetic intensity of standard ANNs so are\nnot well-suited to SNN simulation. FPGAs are well-suited to applications with\nlow arithmetic intensity as they have high off-chip memory bandwidth and large\namounts of on-chip memory. Here, we present a novel RISC-V-based soft vector\nprocessor (FeNN), tailored to simulating SNNs on FPGAs. Unlike most dedicated\nneuromorphic hardware, FeNN is fully programmable and designed to be integrated\nwith applications running on standard computers from the edge to the cloud. We\ndemonstrate that, by using stochastic rounding and saturation, FeNN can achieve\nhigh numerical precision with low hardware utilisation and that a single FeNN\ncore can simulate an SNN classifier faster than both an embedded GPU and the\nLoihi neuromorphic system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRISC-V\u7684\u8f6f\u5411\u91cf\u5904\u7406\u5668\uff08FeNN\uff09\uff0c\u7528\u4e8e\u5728FPGA\u4e0a\u9ad8\u6548\u6a21\u62df\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\uff0c\u5c55\u793a\u4e86\u5176\u5728\u80fd\u8017\u548c\u6027\u80fd\u4e0a\u7684\u4f18\u52bf\u3002", "motivation": "\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u80fd\u663e\u8457\u964d\u4f4eAI\u7cfb\u7edf\u7684\u80fd\u8017\uff0c\u4f46\u4e3b\u6d41\u52a0\u901f\u5668\uff08\u5982GPU\u548cTPU\uff09\u4e0d\u9002\u5408SNN\u6a21\u62df\u3002FPGA\u56e0\u5176\u9ad8\u5185\u5b58\u5e26\u5bbd\u548c\u7247\u4e0a\u5b58\u50a8\u5bb9\u91cf\uff0c\u66f4\u9002\u7528\u4e8e\u4f4e\u7b97\u672f\u5f3a\u5ea6\u7684SNN\u6a21\u62df\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eRISC-V\u7684\u8f6f\u5411\u91cf\u5904\u7406\u5668FeNN\uff0c\u7ed3\u5408\u968f\u673a\u820d\u5165\u548c\u9971\u548c\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6570\u503c\u7cbe\u5ea6\u548c\u4f4e\u786c\u4ef6\u5229\u7528\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5355\u4e2aFeNN\u6838\u5fc3\u5728\u6a21\u62dfSNN\u5206\u7c7b\u5668\u65f6\uff0c\u901f\u5ea6\u4f18\u4e8e\u5d4c\u5165\u5f0fGPU\u548cLoihi\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\u3002", "conclusion": "FeNN\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u7f16\u7a0b\u7684SNN\u6a21\u62df\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4ece\u8fb9\u7f18\u5230\u4e91\u7aef\u7684\u5404\u79cd\u5e94\u7528\u3002"}}
{"id": "2506.10996", "pdf": "https://arxiv.org/pdf/2506.10996", "abs": "https://arxiv.org/abs/2506.10996", "authors": ["Saadiq Rauf Khan", "Vinit Chandak", "Sougata Mukherjea"], "title": "Evaluating LLMs for Visualization Tasks", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Information Visualization has been utilized to gain insights from complex\ndata. In recent times, Large Language Models (LLMs) have performed very well in\nmany tasks. In this paper, we showcase the capabilities of different popular\nLLMs to generate code for visualization based on simple prompts. We also\nanalyze the power of LLMs to understand some common visualizations by answering\nsimple questions. Our study shows that LLMs could generate code for some\nvisualizations as well as answer questions about them. However, LLMs also have\nseveral limitations. We believe that our insights can be used to improve both\nLLMs and Information Visualization systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u53ef\u89c6\u5316\u4ee3\u7801\u548c\u7406\u89e3\u5e38\u89c1\u56fe\u8868\u65b9\u9762\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5176\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u4fe1\u606f\u53ef\u89c6\u5316\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u63a2\u7d22\u5176\u80fd\u5426\u901a\u8fc7\u7b80\u5355\u63d0\u793a\u751f\u6210\u53ef\u89c6\u5316\u4ee3\u7801\u5e76\u7406\u89e3\u56fe\u8868\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u591a\u79cd\u6d41\u884cLLMs\uff0c\u6d4b\u8bd5\u5176\u751f\u6210\u53ef\u89c6\u5316\u4ee3\u7801\u548c\u56de\u7b54\u56fe\u8868\u76f8\u5173\u95ee\u9898\u7684\u80fd\u529b\u3002", "result": "LLMs\u80fd\u591f\u751f\u6210\u90e8\u5206\u53ef\u89c6\u5316\u4ee3\u7801\u5e76\u56de\u7b54\u76f8\u5173\u95ee\u9898\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6539\u8fdbLLMs\u548c\u4fe1\u606f\u53ef\u89c6\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.11995", "pdf": "https://arxiv.org/pdf/2506.11995", "abs": "https://arxiv.org/abs/2506.11995", "authors": ["Chirag Rao", "Eytan Modiano"], "title": "Minimum-hop Constellation Design for Low Earth Orbit Satellite Networks", "categories": ["cs.NI"], "comment": "To be published at IEEE INFOCOM 2025", "summary": "We consider a Low Earth Orbit (LEO) satellite network with each satellite\ncapable of establishing inter-satellite link (ISL) connections for\nsatellite-to-satellite communication. Since ISLs can be reoriented to change\nthe topology, we optimize the topology to minimize the average shortest path\nlength (ASPL). We characterize the optimal ASPL ISL topology in two families of\ntopologies, 1) vertex-symmetric in which the ISL connections at a satellite\nnode represent a motif that is repeated at all other satellite nodes, and 2)\ngeneral regular topologies in which no such repeating pattern need exist. We\nestablish ASPL lower bounds for both scenarios and show constructions for which\nthey are achievable assuming each satellite makes 3 or 4 ISL connections. For\nthe symmetric case, we show that the mesh grid is suboptimal in both ASPL and\ndiameter. Additionally, we show there are constructions that maintain\nintra-orbital ISL connections while still achieving near-optimal ASPL\nperformance. For the general case we show it is possible to construct networks\nwith ASPL close to the general lower bound when the network is sufficiently\ndense. Simulation results show that for both scenarios, one can find topologies\nthat are very close to the lower bounds as the network size scales.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7f51\u7edc\u4e2d\u4f18\u5316\u661f\u95f4\u94fe\u8def\uff08ISL\uff09\u62d3\u6251\u4ee5\u6700\u5c0f\u5316\u5e73\u5747\u6700\u77ed\u8def\u5f84\u957f\u5ea6\uff08ASPL\uff09\uff0c\u5e76\u5206\u6790\u4e86\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u62d3\u6251\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u536b\u661f\u7f51\u7edc\u7684\u901a\u4fe1\u6548\u7387\uff0c\u9700\u8981\u4f18\u5316ISL\u7684\u62d3\u6251\u7ed3\u6784\u4ee5\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u7684\u5ef6\u8fdf\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5efa\u7acbASPL\u7684\u4e0b\u754c\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u62d3\u6251\uff08\u9876\u70b9\u5bf9\u79f0\u548c\u4e00\u822c\u89c4\u5219\u62d3\u6251\uff09\u4ee5\u9a8c\u8bc1\u4e0b\u754c\u53ef\u8fbe\u5230\u6027\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0c\u901a\u8fc7\u5408\u7406\u8bbe\u8ba1\u62d3\u6251\uff0cASPL\u53ef\u63a5\u8fd1\u7406\u8bba\u4e0b\u754c\uff0c\u7f51\u683c\u7ed3\u6784\u5728ASPL\u548c\u76f4\u5f84\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u4f18\u5316\u540e\u7684ISL\u62d3\u6251\u80fd\u663e\u8457\u63d0\u5347\u536b\u661f\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u5bc6\u5ea6\u7f51\u7edc\u4e2d\u63a5\u8fd1\u7406\u8bba\u6700\u4f18\u3002"}}
{"id": "2506.11788", "pdf": "https://arxiv.org/pdf/2506.11788", "abs": "https://arxiv.org/abs/2506.11788", "authors": ["ATM Mizanur Rahman", "Sharifa Sultana"], "title": "Digital Labor: Challenges, Ethical Insights, and Implications", "categories": ["cs.HC"], "comment": null, "summary": "Digital workers on crowdsourcing platforms (e.g., Amazon Mechanical Turk,\nAppen, Clickworker, Prolific) play a crucial role in training and improving AI\nsystems, yet they often face low pay, unfair conditions, and a lack of\nrecognition for their contributions. To map these issues in the existing\nliterature of computer science, AI, and related scholarship, we selected over\n300 research papers on digital labor published between 2015 and 2024, narrowing\nthem down to 143 on digital gig-labor for a detailed analysis. This analysis\nprovides a broad overview of the key challenges, concerns, and trends in the\nfield. Our synthesis reveals how the persistent patterns of representation and\nvoices of gig workers in digital labor are structured and governed. We offer\nnew insights for researchers, platform designers, and policymakers, helping\nthem better understand the experiences of digital workers and pointing to key\nareas where interventions and future investigations are promptly needed. By\nmapping the findings from the past ten years' growth of the domain and possible\nimplications, this paper contributes to a more coherent and critical\nunderstanding of digital labor in contemporary and future AI ecosystems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e862015\u5e74\u81f32024\u5e74\u95f4300\u591a\u7bc7\u5173\u4e8e\u6570\u5b57\u52b3\u52a8\u7684\u7814\u7a76\u8bba\u6587\uff0c\u91cd\u70b9\u5173\u6ce8\u4e86\u5176\u4e2d\u7684143\u7bc7\uff0c\u63ed\u793a\u4e86\u6570\u5b57\u5de5\u4eba\u9762\u4e34\u7684\u4f4e\u62a5\u916c\u3001\u4e0d\u516c\u5e73\u6761\u4ef6\u53ca\u7f3a\u4e4f\u8ba4\u53ef\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5bf9\u7814\u7a76\u8005\u3001\u5e73\u53f0\u8bbe\u8ba1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u7684\u65b0\u89c1\u89e3\u3002", "motivation": "\u6570\u5b57\u5de5\u4eba\u5728AI\u7cfb\u7edf\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u4f46\u5176\u5f85\u9047\u548c\u8ba4\u53ef\u5ea6\u4e0d\u8db3\uff0c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u68b3\u7406\u76f8\u5173\u95ee\u9898\u3002", "method": "\u7b5b\u9009\u5e76\u8be6\u7ec6\u5206\u6790\u4e86143\u7bc7\u5173\u4e8e\u6570\u5b57\u96f6\u5de5\u52b3\u52a8\u7684\u8bba\u6587\uff0c\u7efc\u5408\u4e86\u9886\u57df\u5185\u7684\u5173\u952e\u95ee\u9898\u548c\u8d8b\u52bf\u3002", "result": "\u63ed\u793a\u4e86\u6570\u5b57\u96f6\u5de5\u52b3\u52a8\u7684\u73b0\u72b6\u548c\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9700\u8981\u5e72\u9884\u548c\u672a\u6765\u7814\u7a76\u7684\u91cd\u70b9\u9886\u57df\u3002", "conclusion": "\u8bba\u6587\u4e3a\u7406\u89e3\u548c\u6539\u5584\u6570\u5b57\u52b3\u52a8\u5728AI\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\u63d0\u4f9b\u4e86\u6279\u5224\u6027\u89c6\u89d2\u3002"}}
{"id": "2506.10997", "pdf": "https://arxiv.org/pdf/2506.10997", "abs": "https://arxiv.org/abs/2506.10997", "authors": ["Hanumanthrao Kannan", "Alejandro Salado"], "title": "A Theory-driven Interpretation and Elaboration of Verification and Validation", "categories": ["cs.SE", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents a formal theory of verification and validation (V&V)\nwithin systems engineering, grounded in the axiom that V&V are fundamentally\nknowledge-building activities. Using dynamic epistemic modal logic, we develop\nprecise definitions of verification and validation, articulating their roles in\nconfirming and contextualizing knowledge about systems. The theory formalizes\nthe interplay between epistemic states, evidence, and reasoning processes,\nallowing for the derivation of theorems that clarify the conceptual\nunderpinnings of V&V. By providing a formal foundation, this work addresses\nambiguities in traditional V&V practices, offering a structured framework to\nenhance precision and consistency in systems engineering methodologies. The\ninsights gained have implications for both academic research and practical\napplications, fostering a deeper understanding of V&V as critical components of\nengineering knowledge generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u6784\u5efa\u7684\u9a8c\u8bc1\u4e0e\u786e\u8ba4\uff08V&V\uff09\u5f62\u5f0f\u5316\u7406\u8bba\uff0c\u5229\u7528\u52a8\u6001\u8ba4\u77e5\u6a21\u6001\u903b\u8f91\u5b9a\u4e49V&V\uff0c\u5e76\u9610\u660e\u5176\u5728\u7cfb\u7edf\u77e5\u8bc6\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edfV&V\u5b9e\u8df5\u4e2d\u5b58\u5728\u6a21\u7cca\u6027\uff0c\u9700\u8981\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5\u63d0\u9ad8\u7cfb\u7edf\u5de5\u7a0b\u65b9\u6cd5\u7684\u7cbe\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u8ba4\u77e5\u6a21\u6001\u903b\u8f91\uff0c\u5f62\u5f0f\u5316V&V\u7684\u5b9a\u4e49\u548c\u89d2\u8272\uff0c\u5206\u6790\u8ba4\u77e5\u72b6\u6001\u3001\u8bc1\u636e\u548c\u63a8\u7406\u8fc7\u7a0b\u7684\u4e92\u52a8\u3002", "result": "\u5efa\u7acb\u4e86V&V\u7684\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u63a8\u5bfc\u51fa\u6f84\u6e05\u5176\u6982\u5ff5\u57fa\u7840\u7684\u5b9a\u7406\uff0c\u4e3a\u7cfb\u7edf\u5de5\u7a0b\u63d0\u4f9b\u7ed3\u6784\u5316\u6846\u67b6\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5b9e\u8df5\u4e2d\u7684\u6a21\u7cca\u6027\uff0c\u8fd8\u4fc3\u8fdb\u4e86V&V\u4f5c\u4e3a\u5de5\u7a0b\u77e5\u8bc6\u751f\u6210\u5173\u952e\u7ec4\u6210\u90e8\u5206\u7684\u6df1\u5165\u7406\u89e3\u3002"}}
{"id": "2506.12003", "pdf": "https://arxiv.org/pdf/2506.12003", "abs": "https://arxiv.org/abs/2506.12003", "authors": ["Ramesh Raskar", "Pradyumna Chari", "Jared James Grogan", "Mahesh Lambe", "Robert Lincourt", "Raghu Bala", "Abhishek Singh", "Ayush Chopra", "Rajesh Ranjan", "Shailja Gupta", "Dimitris Stripelis", "Maria Gorskikh", "Sichao Wang"], "title": "Upgrade or Switch: Do We Need a New Registry Architecture for the Internet of AI Agents?", "categories": ["cs.NI", "cs.AI", "cs.MA"], "comment": null, "summary": "The emerging Internet of AI Agents challenges existing web infrastructure\ndesigned for human-scale, reactive interactions. Unlike traditional web\nresources, autonomous AI agents initiate actions, maintain persistent state,\nspawn sub-agents, and negotiate directly with peers: demanding\nmillisecond-level discovery, instant credential revocation, and cryptographic\nbehavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes\nwhether to upgrade existing infrastructure or implement purpose-built registry\narchitectures for autonomous agents. We identify critical failure points: DNS\npropagation (24-48 hours vs. required milliseconds), certificate revocation\nunable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate\nfor agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2)\nSwitch options, (3) Hybrid registries. Drawing parallels to dialup-to-broadband\ntransitions, we find that agent requirements constitute qualitative, and not\nincremental, changes. While upgrades offer compatibility and faster deployment,\nclean-slate solutions provide better performance but require longer for\nadoption. Our analysis suggests hybrid approaches will emerge, with centralized\nregistries for critical agents and federated meshes for specialized use cases.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u73b0\u6709\u7684\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u662f\u5426\u80fd\u591f\u652f\u6301\u65b0\u5174\u7684AI\u4ee3\u7406\u4e92\u8054\u7f51\uff0c\u5206\u6790\u4e86\u5347\u7ea7\u73b0\u6709\u7cfb\u7edf\u6216\u6784\u5efa\u65b0\u67b6\u6784\u7684\u53ef\u884c\u6027\uff0c\u6700\u7ec8\u5efa\u8bae\u91c7\u7528\u6df7\u5408\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u662f\u4e3a\u4eba\u7c7b\u4ea4\u4e92\u8bbe\u8ba1\u7684\uff0c\u65e0\u6cd5\u6ee1\u8db3\u81ea\u4e3bAI\u4ee3\u7406\u5bf9\u901f\u5ea6\u3001\u89c4\u6a21\u548c\u5b89\u5168\u6027\uff08\u5982\u6beb\u79d2\u7ea7\u53d1\u73b0\u3001\u5373\u65f6\u51ed\u8bc1\u64a4\u9500\u7b49\uff09\u7684\u9ad8\u8981\u6c42\u3002", "method": "\u5206\u6790\u73b0\u6709DNS/PKI\u7684\u4e0d\u8db3\uff0c\u8bc4\u4f30\u4e09\u79cd\u89e3\u51b3\u65b9\u6848\uff1a\u5347\u7ea7\u73b0\u6709\u7cfb\u7edf\u3001\u66ff\u6362\u4e3a\u5168\u65b0\u67b6\u6784\u3001\u91c7\u7528\u6df7\u5408\u6ce8\u518c\u8868\u67b6\u6784\u3002", "result": "\u5347\u7ea7\u63d0\u4f9b\u517c\u5bb9\u6027\u548c\u5feb\u901f\u90e8\u7f72\uff0c\u4f46\u5168\u65b0\u67b6\u6784\u6027\u80fd\u66f4\u597d\uff1b\u7531\u4e8e\u9700\u6c42\u662f\u8d28\u53d8\u800c\u975e\u91cf\u53d8\uff0c\u6df7\u5408\u65b9\u6848\u66f4\u53ef\u80fd\u6210\u4e3a\u4e3b\u6d41\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u6df7\u5408\u6ce8\u518c\u8868\u67b6\u6784\uff0c\u96c6\u4e2d\u5316\u5904\u7406\u5173\u952e\u4ee3\u7406\uff0c\u5206\u6743\u5316\u5e94\u5bf9\u7279\u5b9a\u7528\u4f8b\u3002"}}
{"id": "2506.11789", "pdf": "https://arxiv.org/pdf/2506.11789", "abs": "https://arxiv.org/abs/2506.11789", "authors": ["Na\u0111a Terzimehi\u0107", "Babette B\u00fchler", "Enkelejda Kasneci"], "title": "Conversational AI as a Catalyst for Informal Learning: An Empirical Large-Scale Study on LLM Use in Everyday Learning", "categories": ["cs.HC"], "comment": null, "summary": "Large language models have not only captivated the public imagination but\nhave also sparked a profound rethinking of how we learn. In the third year\nfollowing the breakthrough launch of ChatGPT, everyday informal learning has\nbeen transformed as diverse user groups explore these novel tools. Who is\nembracing LLMs for self-directed learning, and who remains hesitant? What are\ntheir reasons for adoption or avoidance? What learning patterns emerge with\nthis novel technological landscape? We present an in-depth analysis from a\nlarge-scale survey of 776 participants, showcasing that 88% of our respondents\nalready incorporate LLMs into their everyday learning routines for a wide\nvariety of (learning) tasks. Young adults are at the forefront of adopting\nLLMs, primarily to enhance their learning experiences independently of time and\nspace. Four types of learners emerge across learning contexts, depending on the\ntasks they perform with LLMs and the devices they use to access them.\nInterestingly, our respondents exhibit paradoxical behaviours regarding their\ntrust in LLMs' accuracy and privacy protection measures. Our implications\nemphasize the importance of including different media types for learning,\nenabling collaborative learning, providing sources and meeting the needs of\ndifferent types of learners and learning by design.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u6210\u4e3a\u81ea\u5bfc\u5411\u5b66\u4e60\u7684\u91cd\u8981\u5de5\u5177\uff0c88%\u7684\u8c03\u67e5\u53c2\u4e0e\u8005\u5df2\u5c06\u5176\u878d\u5165\u65e5\u5e38\u5b66\u4e60\u3002\u5e74\u8f7b\u4eba\u662f\u4e3b\u8981\u4f7f\u7528\u8005\uff0c\u4f46\u7528\u6237\u5bf9\u5176\u51c6\u786e\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u8868\u73b0\u51fa\u77db\u76fe\u6001\u5ea6\u3002", "motivation": "\u63a2\u8ba8LLMs\u5982\u4f55\u6539\u53d8\u975e\u6b63\u5f0f\u5b66\u4e60\u65b9\u5f0f\uff0c\u4e86\u89e3\u7528\u6237\u91c7\u7eb3\u6216\u907f\u514d\u4f7f\u7528\u7684\u539f\u56e0\uff0c\u4ee5\u53ca\u65b0\u5174\u7684\u5b66\u4e60\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7776\u540d\u53c2\u4e0e\u8005\u7684\u5927\u89c4\u6a21\u8c03\u67e5\uff0c\u5206\u6790LLMs\u5728\u4e0d\u540c\u5b66\u4e60\u4efb\u52a1\u548c\u8bbe\u5907\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "result": "88%\u7684\u53d7\u8bbf\u8005\u5df2\u5c06LLMs\u7528\u4e8e\u65e5\u5e38\u5b66\u4e60\uff0c\u5e74\u8f7b\u4eba\u662f\u4e3b\u8981\u7528\u6237\u3002\u7528\u6237\u5bf9LLMs\u7684\u4fe1\u4efb\u548c\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u8868\u73b0\u51fa\u77db\u76fe\u3002", "conclusion": "\u672a\u6765\u8bbe\u8ba1LLMs\u5b66\u4e60\u5de5\u5177\u65f6\uff0c\u9700\u8003\u8651\u591a\u6837\u5316\u5a92\u4f53\u652f\u6301\u3001\u534f\u4f5c\u5b66\u4e60\u3001\u4fe1\u606f\u6765\u6e90\u4ee5\u53ca\u6ee1\u8db3\u4e0d\u540c\u5b66\u4e60\u8005\u9700\u6c42\u3002"}}
{"id": "2506.10998", "pdf": "https://arxiv.org/pdf/2506.10998", "abs": "https://arxiv.org/abs/2506.10998", "authors": ["Kangping Xu", "Yifan Luo", "Yang Yuan", "Andrew Chi-Chih Yao"], "title": "Towards Automated Formal Verification of Backend Systems with LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Software testing plays a critical role in ensuring that systems behave as\nintended. However, existing automated testing approaches struggle to match the\ncapabilities of human engineers due to key limitations such as test locality,\nlack of general reliability, and business logic blindness. In this work, we\npropose a novel framework that leverages functional programming and type\nsystems to translate Scala backend code into formal Lean representations. Our\npipeline automatically generates theorems that specify the intended behavior of\nAPIs and database operations, and uses LLM-based provers to verify them. When a\ntheorem is proved, the corresponding logic is guaranteed to be correct and no\nfurther testing is needed. If the negation of a theorem is proved instead, it\nconfirms a bug. In cases where neither can be proved, human intervention is\nrequired. We evaluate our method on realistic backend systems and find that it\ncan formally verify over 50% of the test requirements, which suggests that half\nof a testing engineer's workload can be automated. Additionally, with an\naverage cost of only $2.19 per API, LLM-based verification is significantly\nmore cost-effective than manual testing and can be scaled easily through\nparallel execution. Our results indicate a promising direction for scalable,\nAI-powered software testing, with the potential to greatly improve engineering\nproductivity as models continue to advance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u51fd\u6570\u5f0f\u7f16\u7a0b\u548c\u7c7b\u578b\u7cfb\u7edf\u5c06Scala\u540e\u7aef\u4ee3\u7801\u8f6c\u6362\u4e3a\u5f62\u5f0f\u5316Lean\u8868\u793a\u7684\u6846\u67b6\uff0c\u81ea\u52a8\u751f\u6210\u5e76\u9a8c\u8bc1API\u884c\u4e3a\u5b9a\u7406\uff0c\u5927\u5e45\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\u5728\u6d4b\u8bd5\u5c40\u90e8\u6027\u3001\u901a\u7528\u53ef\u9760\u6027\u548c\u4e1a\u52a1\u903b\u8f91\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u5ab2\u7f8e\u4eba\u5de5\u6d4b\u8bd5\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u529f\u80fd\u7f16\u7a0b\u548c\u7c7b\u578b\u7cfb\u7edf\u5c06\u4ee3\u7801\u8f6c\u4e3a\u5f62\u5f0f\u5316\u8868\u793a\uff0c\u81ea\u52a8\u751f\u6210\u5b9a\u7406\u5e76\u4f7f\u7528LLM\u9a8c\u8bc1\uff0c\u65e0\u6cd5\u9a8c\u8bc1\u65f6\u9700\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u9a8c\u8bc150%\u4ee5\u4e0a\u7684\u6d4b\u8bd5\u9700\u6c42\uff0c\u6bcfAPI\u5e73\u5747\u6210\u672c\u4ec52.19\u7f8e\u5143\uff0c\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u7684AI\u9a71\u52a8\u8f6f\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u6709\u671b\u663e\u8457\u63d0\u5347\u5de5\u7a0b\u6548\u7387\u3002"}}
{"id": "2506.11284", "pdf": "https://arxiv.org/pdf/2506.11284", "abs": "https://arxiv.org/abs/2506.11284", "authors": ["Zehua Li", "Jingjie Wei", "Raviraj Adve"], "title": "Decentralized Uplink Adaptive Compression for Cell-Free MIMO with Limited Fronthaul", "categories": ["cs.IT", "cs.NI", "cs.SY", "eess.SP", "eess.SY", "math.IT", "math.OC"], "comment": "Presented in IEEE International Conference on Communications (ICC)\n  2025, 6 pages, 2 figures", "summary": "We study the problem of uplink compression for cell-free multi-input\nmulti-output networks with limited fronthaul capacity. In compress-forward\nmode, remote radio heads (RRHs) compress the received signal and forward it to\na central unit for joint processing. While previous work has focused on a\ntransform-based approach, which optimizes the transform matrix that reduces\nsignals of high dimension to a static pre-determined lower dimension, we\npropose a rate-based approach that simultaneously finds both dimension and\ncompression adaptively. Our approach accommodates for changes to network\ntraffic and fronthaul limits. Using mutual information as the objective, we\nobtain the theoretical network capacity for adaptive compression and decouple\nthe expression to enable decentralization. Furthermore, using channel\nstatistics and user traffic density, we show different approaches to compute an\nefficient representation of side information that summarizes global channel\nstate information and is shared with RRHs to assist compression. While keeping\nthe information exchange overhead low, our decentralized implementation of\nadaptive compression shows competitive overall network performance compared to\na centralized approach.", "AI": {"tldr": "\u7814\u7a76\u5728\u6709\u9650\u524d\u4f20\u5bb9\u91cf\u4e0b\uff0c\u5c0f\u533a\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7f51\u7edc\u7684\u4e0a\u884c\u538b\u7f29\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u901f\u7387\u7684\u81ea\u9002\u5e94\u538b\u7f29\u65b9\u6cd5\uff0c\u4f18\u4e8e\u4f20\u7edf\u53d8\u6362\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u53d8\u6362\u77e9\u9635\u65b9\u6cd5\u5728\u538b\u7f29\u9ad8\u7ef4\u4fe1\u53f7\u65f6\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u9002\u5e94\u7f51\u7edc\u6d41\u91cf\u548c\u524d\u4f20\u5bb9\u91cf\u7684\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u901f\u7387\u7684\u81ea\u9002\u5e94\u538b\u7f29\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e92\u4fe1\u606f\u4f18\u5316\u7406\u8bba\u7f51\u7edc\u5bb9\u91cf\uff0c\u5e76\u901a\u8fc7\u4fe1\u9053\u7edf\u8ba1\u548c\u7528\u6237\u6d41\u91cf\u5bc6\u5ea6\u9ad8\u6548\u751f\u6210\u5168\u5c40\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u4fa7\u4fe1\u606f\u3002", "result": "\u53bb\u4e2d\u5fc3\u5316\u5b9e\u73b0\u7684\u81ea\u9002\u5e94\u538b\u7f29\u65b9\u6cd5\u5728\u7f51\u7edc\u6027\u80fd\u4e0a\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u4fe1\u606f\u4ea4\u6362\u5f00\u9500\u3002", "conclusion": "\u81ea\u9002\u5e94\u538b\u7f29\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u5408\u52a8\u6001\u7f51\u7edc\u73af\u5883\u3002"}}
{"id": "2506.11890", "pdf": "https://arxiv.org/pdf/2506.11890", "abs": "https://arxiv.org/abs/2506.11890", "authors": ["Judson Leroy Dean Haynes IV"], "title": "Enter: Graduated Realism: A Pedagogical Framework for AI-Powered Avatars in Virtual Reality Teacher Training", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Virtual Reality simulators offer a powerful tool for teacher training, yet\nthe integration of AI-powered student avatars presents a critical challenge:\ndetermining the optimal level of avatar realism for effective pedagogy. This\nliterature review examines the evolution of avatar realism in VR teacher\ntraining, synthesizes its theoretical implications, and proposes a new\npedagogical framework to guide future design. Through a systematic review, this\npaper traces the progression from human-controlled avatars to generative AI\nprototypes. Applying learning theories like Cognitive Load Theory, we argue\nthat hyper-realism is not always optimal, as high-fidelity avatars can impose\nexcessive extraneous cognitive load on novices, a stance supported by recent\nempirical findings. A significant gap exists between the technological drive\nfor photorealism and the pedagogical need for scaffolded learning. To address\nthis gap, we propose Graduated Realism, a framework advocating for starting\ntrainees with lower-fidelity avatars and progressively increasing behavioral\ncomplexity as skills develop. To make this computationally feasible, we outline\na novel single-call architecture, Crazy Slots, which uses a probabilistic\nengine and a Retrieval-Augmented Generation database to generate authentic,\nreal-time responses without the latency and cost of multi-step reasoning\nmodels. This review provides evidence-based principles for designing the next\ngeneration of AI simulators, arguing that a pedagogically grounded approach to\nrealism is essential for creating scalable and effective teacher education\ntools.", "AI": {"tldr": "\u63a2\u7a76VR\u6559\u5e08\u57f9\u8bad\u4e2dAI\u865a\u62df\u5b66\u751f\u6700\u4f73\u903c\u771f\u5ea6\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u57fa\u4e8e\u6559\u5b66\u7406\u8bba\u7684\u5206\u9636\u6bb5\u903c\u771f\u5ea6\u6846\u67b6\uff08Graduated Realism\uff09\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7684\u5355\u8c03\u7528\u67b6\u6784Crazy Slots\u3002", "motivation": "VR\u4eff\u771f\u6280\u672f\u4e3a\u6559\u5e08\u57f9\u8bad\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\uff0c\u4f46AI\u9a71\u52a8\u7684\u865a\u62df\u5b66\u751f\u903c\u771f\u5ea6\u5bf9\u6559\u5b66\u6548\u679c\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u5e73\u8861\u6280\u672f\u8ffd\u6c42\u4e0e\u6559\u5b66\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u5206\u6790VR\u6559\u5e08\u57f9\u8bad\u4e2d\u865a\u62df\u903c\u771f\u5ea6\u7684\u6f14\u53d8\uff0c\u7ed3\u5408\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\uff0c\u63d0\u51fa\u5206\u9636\u6bb5\u903c\u771f\u5ea6\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1Crazy Slots\u67b6\u6784\u5b9e\u73b0\u5b9e\u65f6\u54cd\u5e94\u3002", "result": "\u7814\u7a76\u652f\u6301\u903c\u771f\u5ea6\u5e76\u975e\u8d8a\u9ad8\u8d8a\u597d\uff0c\u5206\u9636\u6bb5\u63d0\u5347\u903c\u771f\u5ea6\u6709\u52a9\u4e8e\u51cf\u5c11\u65b0\u624b\u8ba4\u77e5\u8d1f\u8377\uff0cCrazy Slots\u67b6\u6784\u6709\u6548\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u6559\u5b66\u9a71\u52a8\u7684\u903c\u771f\u5ea6\u8bbe\u8ba1\u539f\u5219\uff0cGraduated Realism\u6846\u67b6\u548cCrazy Slots\u67b6\u6784\u4e3a\u4e0b\u4e00\u4ee3AI\u6a21\u62df\u5668\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.10999", "pdf": "https://arxiv.org/pdf/2506.10999", "abs": "https://arxiv.org/abs/2506.10999", "authors": ["Atul Kumar", "Diptikalyan Saha", "Toshikai Yasue", "Kohichi Ono", "Saravanan Krishnan", "Sandeep Hans", "Fumiko Satoh", "Gerald Mitchell", "Sachin Kumar"], "title": "Automated Validation of COBOL to Java Transformation", "categories": ["cs.SE", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2504.10548", "summary": "Recent advances in Large Language Model (LLM) based Generative AI techniques\nhave made it feasible to translate enterpriselevel code from legacy languages\nsuch as COBOL to modern languages such as Java or Python. While the results of\nLLM-based automatic transformation are encouraging, the resulting code cannot\nbe trusted to correctly translate the original code. We propose a framework and\na tool to help validate the equivalence of COBOL and translated Java. The\nresults can also help repair the code if there are some issues and provide\nfeedback to the AI model to improve. We have developed a\nsymbolic-execution-based test generation to automatically generate unit tests\nfor the source COBOL programs which also mocks the external resource calls. We\ngenerate equivalent JUnit test cases with equivalent mocking as COBOL and run\nthem to check semantic equivalence between original and translated programs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\u548c\u5de5\u5177\uff0c\u7528\u4e8e\u9a8c\u8bc1COBOL\u4ee3\u7801\u4e0e\u7ffb\u8bd1\u540e\u7684Java\u4ee3\u7801\u7684\u7b49\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u751f\u6210\u7684\u5355\u5143\u6d4b\u8bd5\u6765\u4fee\u590d\u95ee\u9898\u5e76\u63d0\u4f9b\u6a21\u578b\u53cd\u9988\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u4ee3\u7801\u8f6c\u6362\u7ed3\u679c\u867d\u4ee4\u4eba\u9f13\u821e\uff0c\u4f46\u7ffb\u8bd1\u540e\u7684\u4ee3\u7801\u65e0\u6cd5\u4fdd\u8bc1\u51c6\u786e\u6027\uff0c\u56e0\u6b64\u9700\u8981\u9a8c\u8bc1\u548c\u4fee\u590d\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u6267\u884c\u751f\u6210COBOL\u7a0b\u5e8f\u7684\u5355\u5143\u6d4b\u8bd5\uff0c\u5e76\u751f\u6210\u7b49\u6548\u7684JUnit\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u8fd0\u884c\u6d4b\u8bd5\u6765\u9a8c\u8bc1\u8bed\u4e49\u7b49\u6548\u6027\u3002", "result": "\u5de5\u5177\u53ef\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u9a8c\u8bc1\u5e76\u4fee\u590d\u7ffb\u8bd1\u540e\u7684\u4ee3\u7801\uff0c\u540c\u65f6\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u53cd\u9988\u4ee5\u6539\u8fdb\u7ffb\u8bd1\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u4ee3\u7801\u8f6c\u6362\u4e2d\u7684\u53ef\u4fe1\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9a8c\u8bc1\u6846\u67b6\u3002"}}
{"id": "2506.11004", "pdf": "https://arxiv.org/pdf/2506.11004", "abs": "https://arxiv.org/abs/2506.11004", "authors": ["Kevin Cogan", "Vuong M. Ngo", "Mark Roantree"], "title": "Developing a Dyslexia Indicator Using Eye Tracking", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": "The 23rd International Conference on Artificial Intelligence in\n  Medicine (AIME 2025), LNAI, Springer, 11 pages", "summary": "Dyslexia, affecting an estimated 10% to 20% of the global population,\nsignificantly impairs learning capabilities, highlighting the need for\ninnovative and accessible diagnostic methods. This paper investigates the\neffectiveness of eye-tracking technology combined with machine learning\nalgorithms as a cost-effective alternative for early dyslexia detection. By\nanalyzing general eye movement patterns, including prolonged fixation durations\nand erratic saccades, we proposed an enhanced solution for determining\neye-tracking-based dyslexia features. A Random Forest Classifier was then\nemployed to detect dyslexia, achieving an accuracy of 88.58\\%. Additionally,\nhierarchical clustering methods were applied to identify varying severity\nlevels of dyslexia. The analysis incorporates diverse methodologies across\nvarious populations and settings, demonstrating the potential of this\ntechnology to identify individuals with dyslexia, including those with\nborderline traits, through non-invasive means. Integrating eye-tracking with\nmachine learning represents a significant advancement in the diagnostic\nprocess, offering a highly accurate and accessible method in clinical research.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u7ed3\u5408\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u548c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4f5c\u4e3a\u7ecf\u6d4e\u9ad8\u6548\u7684\u65e9\u671f\u9605\u8bfb\u969c\u788d\u8bca\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u773c\u52a8\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5168\u740310%\u81f320%\u7684\u4eba\u53e3\u53d7\u5230\u9605\u8bfb\u969c\u788d\u7684\u5f71\u54cd\uff0c\u4e9f\u9700\u521b\u65b0\u7684\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u548c\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u5206\u6790\u773c\u52a8\u6a21\u5f0f\uff08\u5982\u6ce8\u89c6\u65f6\u957f\u548c\u626b\u89c6\u5f02\u5e38\uff09\u4ee5\u68c0\u6d4b\u9605\u8bfb\u969c\u788d\u53ca\u5176\u4e25\u91cd\u7a0b\u5ea6\u3002", "result": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7684\u51c6\u786e\u7387\u8fbe\u523088.58%\uff0c\u5e76\u80fd\u8bc6\u522b\u4e0d\u540c\u7a0b\u5ea6\u9605\u8bfb\u969c\u788d\u3002", "conclusion": "\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u7ed3\u5408\u4e3a\u9605\u8bfb\u969c\u788d\u8bca\u65ad\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u3001\u975e\u4fb5\u5165\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.11000", "pdf": "https://arxiv.org/pdf/2506.11000", "abs": "https://arxiv.org/abs/2506.11000", "authors": ["Ketai Qiu"], "title": "Ever-Improving Test Suite by Leveraging Large Language Models", "categories": ["cs.SE"], "comment": "Accepted by 33rd ACM International Conference on the Foundations of\n  Software Engineering (FSE Companion '25), June 23--28, 2025, Trondheim,\n  Norway", "summary": "Augmenting test suites with test cases that reflect the actual usage of the\nsoftware system is extremely important to sustain the quality of long lasting\nsoftware systems. In this paper, we propose E-Test, an approach that\nincrementally augments a test suite with test cases that exercise behaviors\nthat emerge in production and that are not been tested yet. E-Test leverages\nLarge Language Models to identify already-tested, not-yet-tested, and\nerror-prone unit execution scenarios, and augment the test suite accordingly.\nOur experimental evaluation shows that E-Test outperforms the main\nstate-of-the-art approaches to identify inadequately tested behaviors and\noptimize test suites.", "AI": {"tldr": "E-Test\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u5e76\u8865\u5145\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u672a\u8986\u76d6\u7684\u751f\u4ea7\u884c\u4e3a\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7ef4\u6301\u957f\u671f\u8f6f\u4ef6\u7cfb\u7edf\u7684\u8d28\u91cf\u9700\u8981\u6d4b\u8bd5\u5957\u4ef6\u80fd\u591f\u53cd\u6620\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u3002", "method": "E-Test\u9010\u6b65\u8865\u5145\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u5df2\u6d4b\u8bd5\u3001\u672a\u6d4b\u8bd5\u548c\u6613\u51fa\u9519\u7684\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660eE-Test\u5728\u8bc6\u522b\u6d4b\u8bd5\u4e0d\u8db3\u884c\u4e3a\u548c\u4f18\u5316\u6d4b\u8bd5\u5957\u4ef6\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "E-Test\u80fd\u6709\u6548\u63d0\u5347\u6d4b\u8bd5\u5957\u4ef6\u7684\u8986\u76d6\u7387\uff0c\u6709\u52a9\u4e8e\u8f6f\u4ef6\u8d28\u91cf\u7684\u6301\u7eed\u6539\u8fdb\u3002"}}
{"id": "2506.11391", "pdf": "https://arxiv.org/pdf/2506.11391", "abs": "https://arxiv.org/abs/2506.11391", "authors": ["Anders E. Kal\u00f8r", "Tomoaki Ohtsuki"], "title": "Black-Box Edge AI Model Selection with Conformal Latency and Accuracy Guarantees", "categories": ["cs.IT", "cs.NI", "math.IT"], "comment": "Submitted to IEEE for publication", "summary": "Edge artificial intelligence (AI) will be a central part of 6G, with powerful\nedge servers supporting devices in performing machine learning (ML) inference.\nHowever, it is challenging to deliver the latency and accuracy guarantees\nrequired by 6G applications, such as automated driving and robotics. This stems\nfrom the black-box nature of ML models, the complexities of the tasks, and the\ninterplay between transmitted data quality, chosen inference model, and the\nrandom wireless channel. This paper proposes a novel black-box model selection\nframework for reliable real-time wireless edge AI designed to meet predefined\nrequirements on both deadline violation probability and expected loss.\nLeveraging conformal risk control and non-parametric statistics, our framework\nintelligently selects the optimal model combination from a collection of\nblack-box feature-extraction and inference models of varying complexities and\ncomputation times. We present both a fixed (relying on channel statistics) and\na dynamic (channel-adaptive) model selection scheme. Numerical results validate\nthe framework on a deadline-constrained image classification task while\nsatisfying a maximum misclassification probability requirement. These results\nindicate that the proposed framework has the potential to provide reliable\nreal-time edge AI services in 6G.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9ed1\u76d2\u6a21\u578b\u9009\u62e9\u6846\u67b6\uff0c\u65e8\u5728\u6ee1\u8db3\u9884\u5b9a\u4e49\u7684\u5ef6\u8fdf\u8fdd\u89c4\u6982\u7387\u548c\u9884\u671f\u635f\u5931\u8981\u6c42\uff0c\u4e3a6G\u4e2d\u7684\u8fb9\u7f18AI\u63d0\u4f9b\u53ef\u9760\u5b9e\u65f6\u670d\u52a1\u3002", "motivation": "6G\u5e94\u7528\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u548c\u673a\u5668\u4eba\u6280\u672f\uff09\u9700\u8981\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u7cbe\u5ea6\u7684\u8fb9\u7f18AI\u670d\u52a1\uff0c\u4f46\u7531\u4e8eML\u6a21\u578b\u7684\u9ed1\u76d2\u6027\u3001\u4efb\u52a1\u590d\u6742\u6027\u53ca\u65e0\u7ebf\u4fe1\u9053\u7684\u968f\u673a\u6027\uff0c\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5229\u7528\u5171\u5f62\u98ce\u9669\u63a7\u5236\u548c\u975e\u53c2\u6570\u7edf\u8ba1\uff0c\u4ece\u4e00\u7ec4\u4e0d\u540c\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u65f6\u95f4\u7684\u9ed1\u76d2\u7279\u5f81\u63d0\u53d6\u4e0e\u63a8\u7406\u6a21\u578b\u4e2d\u667a\u80fd\u9009\u62e9\u6700\u4f18\u7ec4\u5408\u3002\u5305\u62ec\u56fa\u5b9a\uff08\u4f9d\u8d56\u4fe1\u9053\u7edf\u8ba1\uff09\u548c\u52a8\u6001\uff08\u4fe1\u9053\u81ea\u9002\u5e94\uff09\u4e24\u79cd\u6a21\u578b\u9009\u62e9\u65b9\u6848\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u6ee1\u8db3\u6700\u5927\u8bef\u5206\u7c7b\u6982\u7387\u8981\u6c42\u7684\u540c\u65f6\uff0c\u5b8c\u6210\u4e86\u5177\u6709\u622a\u6b62\u65f6\u95f4\u7ea6\u675f\u7684\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u671b\u4e3a6G\u63d0\u4f9b\u53ef\u9760\u7684\u5b9e\u65f6\u8fb9\u7f18AI\u670d\u52a1\u3002"}}
{"id": "2506.11015", "pdf": "https://arxiv.org/pdf/2506.11015", "abs": "https://arxiv.org/abs/2506.11015", "authors": ["Barbara Oakley", "Michael Johnston", "Ken-Zen Chen", "Eulho Jung", "Terrence J. Sejnowski"], "title": "The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI", "categories": ["cs.CY", "cs.AI", "cs.HC", "q-bio.NC"], "comment": "50 pages, 8 figures", "summary": "In the age of generative AI and ubiquitous digital tools, human cognition\nfaces a structural paradox: as external aids become more capable, internal\nmemory systems risk atrophy. Drawing on neuroscience and cognitive psychology,\nthis paper examines how heavy reliance on AI systems and discovery-based\npedagogies may impair the consolidation of declarative and procedural memory --\nsystems essential for expertise, critical thinking, and long-term retention. We\nreview how tools like ChatGPT and calculators can short-circuit the retrieval,\nerror correction, and schema-building processes necessary for robust neural\nencoding. Notably, we highlight striking parallels between deep learning\nphenomena such as \"grokking\" and the neuroscience of overlearning and\nintuition. Empirical studies are discussed showing how premature reliance on AI\nduring learning inhibits proceduralization and intuitive mastery. We argue that\neffective human-AI interaction depends on strong internal models -- biological\n\"schemata\" and neural manifolds -- that enable users to evaluate, refine, and\nguide AI output. The paper concludes with policy implications for education and\nworkforce training in the age of large language models.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8AI\u5de5\u5177\u8fc7\u5ea6\u4f9d\u8d56\u5bf9\u4eba\u7c7b\u8ba4\u77e5\u8bb0\u5fc6\u7cfb\u7edf\u7684\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\uff0c\u5f3a\u8c03\u5f3a\u5065\u5185\u90e8\u6a21\u578b\u7684\u91cd\u8981\u6027\u53ca\u5176\u653f\u7b56\u610f\u4e49\u3002", "motivation": "\u7814\u7a76\u5728AI\u666e\u904d\u5e94\u7528\u7684\u80cc\u666f\u4e0b\uff0c\u4eba\u7c7b\u8bb0\u5fc6\u7cfb\u7edf\u53ef\u80fd\u56e0\u5916\u90e8\u5de5\u5177\u4f9d\u8d56\u800c\u9000\u5316\u7684\u7ed3\u6784\u6027\u77db\u76fe\u3002", "method": "\u7ed3\u5408\u795e\u7ecf\u79d1\u5b66\u4e0e\u8ba4\u77e5\u5fc3\u7406\u5b66\u7406\u8bba\uff0c\u5206\u6790AI\u5de5\u5177\u5982\u4f55\u5e72\u6270\u8bb0\u5fc6\u5de9\u56fa\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u5f71\u54cd\u3002", "result": "\u53d1\u73b0AI\u5de5\u5177\u4f9d\u8d56\u4f1a\u524a\u5f31\u957f\u671f\u8bb0\u5fc6\u548c\u76f4\u89c9\u638c\u63e1\u80fd\u529b\uff0c\u5f3a\u8c03\u5185\u90e8\u6a21\u578b\u5bf9AI\u8f93\u51fa\u7684\u8bc4\u4f30\u4e0e\u6307\u5bfc\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u6559\u80b2\u548c\u5de5\u4f5c\u57f9\u8bad\u4e2d\u5e94\u57f9\u517b\u5f3a\u5065\u5185\u90e8\u8ba4\u77e5\u6a21\u578b\uff0c\u4ee5\u4f18\u5316\u4eba\u7c7b\u4e0eAI\u7684\u534f\u4f5c\u3002"}}
{"id": "2506.11001", "pdf": "https://arxiv.org/pdf/2506.11001", "abs": "https://arxiv.org/abs/2506.11001", "authors": ["S. Tucker Browne", "Mark M. Bailey"], "title": "Rethinking Technological Readiness in the Era of AI Uncertainty", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.LG"], "comment": "12 pages", "summary": "Artificial intelligence (AI) is poised to revolutionize military combat\nsystems, but ensuring these AI-enabled capabilities are truly mission-ready\npresents new challenges. We argue that current technology readiness assessments\nfail to capture critical AI-specific factors, leading to potential risks in\ndeployment. We propose a new AI Readiness Framework to evaluate the maturity\nand trustworthiness of AI components in military systems. The central thesis is\nthat a tailored framework - analogous to traditional Technology Readiness\nLevels (TRL) but expanded for AI - can better gauge an AI system's reliability,\nsafety, and suitability for combat use. Using current data evaluation tools and\ntesting practices, we demonstrate the framework's feasibility for near-term\nimplementation. This structured approach provides military decision-makers with\nclearer insight into whether an AI-enabled system has met the necessary\nstandards of performance, transparency, and human integration to be deployed\nwith confidence, thus advancing the field of defense technology management and\nrisk assessment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u519b\u4e8bAI\u7cfb\u7edf\u7684\u65b0\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u5f25\u8865\u73b0\u6709\u6280\u672f\u51c6\u5907\u5ea6\u8bc4\u4f30\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u51c6\u5907\u5ea6\u8bc4\u4f30\u672a\u80fd\u6db5\u76d6AI\u7279\u6709\u56e0\u7d20\uff0c\u53ef\u80fd\u5bfc\u81f4\u519b\u4e8b\u90e8\u7f72\u4e2d\u7684\u98ce\u9669\u3002", "method": "\u63d0\u51faAI Readiness Framework\uff0c\u7c7b\u4f3c\u4f20\u7edfTRL\u4f46\u4e13\u4e3aAI\u6269\u5c55\uff0c\u8bc4\u4f30\u6210\u719f\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002", "result": "\u6846\u67b6\u80fd\u6709\u6548\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u9002\u7528\u6027\uff0c\u4e3a\u51b3\u7b56\u8005\u63d0\u4f9b\u6e05\u6670\u4f9d\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u519b\u4e8bAI\u7cfb\u7edf\u7684\u5b89\u5168\u90e8\u7f72\uff0c\u63a8\u52a8\u56fd\u9632\u6280\u672f\u7ba1\u7406\u548c\u98ce\u9669\u8bc4\u4f30\u7684\u8fdb\u6b65\u3002"}}
{"id": "2506.11729", "pdf": "https://arxiv.org/pdf/2506.11729", "abs": "https://arxiv.org/abs/2506.11729", "authors": ["Ozan Karaali", "Hossam Farag", "Strahinja Dosen", "Cedomir Stefanovic"], "title": "5G-Enabled Smart Prosthetic Hand: Connectivity Analysis and Assessment", "categories": ["eess.SY", "cs.NI", "cs.SY"], "comment": null, "summary": "In this paper, we demonstrate a proof-of-concept implementation of a\nframework for the development of edge-connected prosthetic systems. The\nframework is composed of a bionic hand equipped with a camera and connected to\na Jetson device that establishes a wireless connection to the edge server,\nprocessing the received video stream and feeding back the inferred information\nabout the environment. The hand-edge server connection is obtained either\nthrough a direct 5G link, where the edge server also functions as a 5G base\nstation, or through a WiFi link. We evaluate the latency of closing the control\nloop in the system, showing that, in a realistic usage scenario, the\nconnectivity and computation delays combined are well below 125 ms, which falls\ninto the natural control range. To the best of our knowledge, this is the first\nanalysis showcasing the feasibility of a 5G-enabled prosthetic system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fb9\u7f18\u8fde\u63a5\u7684\u5047\u80a2\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc75G\u6216WiFi\u8fde\u63a5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u63a7\u5236\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5b9e\u65f6\u5904\u7406\u73af\u5883\u4fe1\u606f\u7684\u8fb9\u7f18\u8fde\u63a5\u5047\u80a2\u7cfb\u7edf\uff0c\u4ee5\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u4f7f\u7528\u914d\u5907\u6444\u50cf\u5934\u7684\u4eba\u4f53\u5047\u80a2\u4e0eJetson\u8bbe\u5907\u8fde\u63a5\uff0c\u901a\u8fc75G\u6216WiFi\u5c06\u89c6\u9891\u6d41\u4f20\u8f93\u5230\u8fb9\u7f18\u670d\u52a1\u5668\u8fdb\u884c\u5904\u7406\u3002", "result": "\u7cfb\u7edf\u5ef6\u8fdf\u4f4e\u4e8e125\u6beb\u79d2\uff0c\u6ee1\u8db3\u81ea\u7136\u63a7\u5236\u9700\u6c42\u3002", "conclusion": "\u9996\u6b21\u5c55\u793a\u4e86\u57fa\u4e8e5G\u7684\u5047\u80a2\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.11047", "pdf": "https://arxiv.org/pdf/2506.11047", "abs": "https://arxiv.org/abs/2506.11047", "authors": ["Chirudeep Tupakula", "Rittika Shamsuddin"], "title": "Perception-Driven Bias Detection in Machine Learning via Crowdsourced Visual Judgment", "categories": ["cs.LG", "cs.HC"], "comment": "Pilot Study. 12 pages. 4 Figures", "summary": "Machine learning systems are increasingly deployed in high-stakes domains,\nyet they remain vulnerable to bias systematic disparities that\ndisproportionately impact specific demographic groups. Traditional bias\ndetection methods often depend on access to sensitive labels or rely on rigid\nfairness metrics, limiting their applicability in real-world settings. This\npaper introduces a novel, perception-driven framework for bias detection that\nleverages crowdsourced human judgment. Inspired by reCAPTCHA and other\ncrowd-powered systems, we present a lightweight web platform that displays\nstripped-down visualizations of numeric data (for example-salary distributions\nacross demographic clusters) and collects binary judgments on group similarity.\nWe explore how users' visual perception-shaped by layout, spacing, and question\nphrasing can signal potential disparities. User feedback is aggregated to flag\ndata segments as biased, which are then validated through statistical tests and\nmachine learning cross-evaluations. Our findings show that perceptual signals\nfrom non-expert users reliably correlate with known bias cases, suggesting that\nvisual intuition can serve as a powerful, scalable proxy for fairness auditing.\nThis approach offers a label-efficient, interpretable alternative to\nconventional fairness diagnostics, paving the way toward human-aligned,\ncrowdsourced bias detection pipelines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f17\u5305\u4eba\u7c7b\u5224\u65ad\u7684\u504f\u89c1\u68c0\u6d4b\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u975e\u4e13\u5bb6\u7528\u6237\u7684\u89c6\u89c9\u611f\u77e5\u4fe1\u53f7\u53d1\u73b0\u6f5c\u5728\u7684\u7cfb\u7edf\u504f\u89c1\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6807\u7b7e\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u65f6\u5b58\u5728\u504f\u89c1\u95ee\u9898\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u654f\u611f\u6807\u7b7e\u6216\u50f5\u5316\u7684\u516c\u5e73\u6027\u6307\u6807\uff0c\u9002\u7528\u6027\u53d7\u9650\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7f51\u7edc\u5e73\u53f0\uff0c\u5c55\u793a\u7b80\u5316\u540e\u7684\u6570\u636e\u53ef\u89c6\u5316\uff08\u5982\u85aa\u8d44\u5206\u5e03\uff09\uff0c\u5e76\u6536\u96c6\u7528\u6237\u5bf9\u7fa4\u4f53\u76f8\u4f3c\u6027\u7684\u4e8c\u5143\u5224\u65ad\u3002\u901a\u8fc7\u5206\u6790\u7528\u6237\u7684\u89c6\u89c9\u611f\u77e5\u4fe1\u53f7\uff08\u5982\u5e03\u5c40\u3001\u95f4\u8ddd\u7b49\uff09\uff0c\u7ed3\u5408\u7edf\u8ba1\u6d4b\u8bd5\u548c\u673a\u5668\u5b66\u4e60\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u68c0\u6d4b\u6f5c\u5728\u504f\u89c1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u975e\u4e13\u5bb6\u7528\u6237\u7684\u611f\u77e5\u4fe1\u53f7\u4e0e\u5df2\u77e5\u504f\u89c1\u6848\u4f8b\u663e\u8457\u76f8\u5173\uff0c\u8868\u660e\u89c6\u89c9\u76f4\u89c9\u53ef\u4ee5\u4f5c\u4e3a\u516c\u5e73\u6027\u5ba1\u8ba1\u7684\u6709\u6548\u4ee3\u7406\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u516c\u5e73\u6027\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u7b7e\u4f9d\u8d56\u3001\u6613\u4e8e\u7406\u89e3\u7684\u65b0\u601d\u8def\uff0c\u6709\u671b\u63a8\u52a8\u57fa\u4e8e\u4f17\u5305\u7684\u504f\u89c1\u68c0\u6d4b\u6d41\u7a0b\u53d1\u5c55\u3002"}}
{"id": "2506.11002", "pdf": "https://arxiv.org/pdf/2506.11002", "abs": "https://arxiv.org/abs/2506.11002", "authors": ["Roberto Verdecchia", "Justus Bogner"], "title": "Notes On Writing Effective Empirical Software Engineering Papers: An Opinionated Primer", "categories": ["cs.SE"], "comment": null, "summary": "While mastered by some, good scientific writing practices within Empirical\nSoftware Engineering (ESE) research appear to be seldom discussed and\ndocumented. Despite this, these practices are implicit or even explicit\nevaluation criteria of typical software engineering conferences and journals.\nIn this pragmatic, educational-first document, we want to provide guidance to\nthose who may feel overwhelmed or confused by writing ESE papers, but also\nthose more experienced who still might find an opinionated collection of\nwriting advice useful. The primary audience we had in mind for this paper were\nour own BSc, MSc, and PhD students, but also students of others. Our documented\nadvice therefore reflects a subjective and personal vision of writing ESE\npapers. By no means do we claim to be fully objective, generalizable, or\nrepresentative of the whole discipline. With that being said, writing papers in\nthis way has worked pretty well for us so far. We hope that this guide can at\nleast partially do the same for others.", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u4e3a\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u8bba\u6587\u5199\u4f5c\u63d0\u4f9b\u6307\u5bfc\uff0c\u5e2e\u52a9\u521d\u5b66\u8005\u548c\u6709\u4e00\u5b9a\u7ecf\u9a8c\u7684\u7814\u7a76\u8005\u3002", "motivation": "\u7531\u4e8e\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u826f\u597d\u7684\u79d1\u5b66\u5199\u4f5c\u5b9e\u8df5\u8f83\u5c11\u88ab\u8ba8\u8bba\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u672c\u6587\u4e3a\u611f\u5230\u56f0\u60d1\u6216\u538b\u529b\u5927\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u5e2e\u52a9\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u4e3b\u89c2\u548c\u4e2a\u4eba\u613f\u666f\uff0c\u603b\u7ed3\u4e86\u5199\u4f5c\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u8bba\u6587\u7684\u5efa\u8bae\u3002", "result": "\u867d\u7136\u8fd9\u4e9b\u5efa\u8bae\u4e0d\u5177\u5907\u5b8c\u5168\u5ba2\u89c2\u6027\u6216\u666e\u904d\u6027\uff0c\u4f46\u5bf9\u4f5c\u8005\u56e2\u961f\u548c\u5b66\u751f\u5df2\u7ecf\u6709\u6548\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u7684\u6307\u5bfc\u6709\u671b\u5e2e\u52a9\u5176\u4ed6\u7814\u7a76\u8005\u5728\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u8bba\u6587\u5199\u4f5c\u4e2d\u53d7\u76ca\u3002"}}
{"id": "2506.11804", "pdf": "https://arxiv.org/pdf/2506.11804", "abs": "https://arxiv.org/abs/2506.11804", "authors": ["Filippo Bragato", "Michael Neri", "Paolo Testolina", "Marco Giordani", "Federica Battisti"], "title": "Teleoperated Driving: a New Challenge for 3D Object Detection in Compressed Point Clouds", "categories": ["cs.CV", "cs.NI", "eess.IV"], "comment": "Submitted to IEEE Transactions on Intelligent Transportation Systems", "summary": "In recent years, the development of interconnected devices has expanded in\nmany fields, from infotainment to education and industrial applications. This\ntrend has been accelerated by the increased number of sensors and accessibility\nto powerful hardware and software. One area that significantly benefits from\nthese advancements is Teleoperated Driving (TD). In this scenario, a controller\ndrives safely a vehicle from remote leveraging sensors data generated onboard\nthe vehicle, and exchanged via Vehicle-to-Everything (V2X) communications. In\nthis work, we tackle the problem of detecting the presence of cars and\npedestrians from point cloud data to enable safe TD operations. More\nspecifically, we exploit the SELMA dataset, a multimodal, open-source,\nsynthetic dataset for autonomous driving, that we expanded by including the\nground-truth bounding boxes of 3D objects to support object detection. We\nanalyze the performance of state-of-the-art compression algorithms and object\ndetectors under several metrics, including compression efficiency,\n(de)compression and inference time, and detection accuracy. Moreover, we\nmeasure the impact of compression and detection on the V2X network in terms of\ndata rate and latency with respect to 3GPP requirements for TD applications.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u70b9\u4e91\u6570\u636e\u68c0\u6d4b\u8f66\u8f86\u548c\u884c\u4eba\u4ee5\u652f\u6301\u8fdc\u7a0b\u9a7e\u9a76\uff08TD\uff09\uff0c\u5229\u7528\u6269\u5c55\u7684SELMA\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u538b\u7f29\u7b97\u6cd5\u548c\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u53ca\u5176\u5bf9V2X\u7f51\u7edc\u7684\u5f71\u54cd\u3002", "motivation": "\u4e92\u8054\u8bbe\u5907\u7684\u5feb\u901f\u53d1\u5c55\u4e3a\u8fdc\u7a0b\u9a7e\u9a76\uff08TD\uff09\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6301\uff0c\u4f46\u9700\u8981\u9ad8\u6548\u7684\u70b9\u4e91\u6570\u636e\u5904\u7406\u548c\u76ee\u6807\u68c0\u6d4b\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u3002", "method": "\u5229\u7528\u6269\u5c55\u7684SELMA\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u538b\u7f29\u7b97\u6cd5\u548c\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u6027\u80fd\uff0c\u5305\u62ec\u538b\u7f29\u6548\u7387\u3001\u5904\u7406\u65f6\u95f4\u3001\u68c0\u6d4b\u7cbe\u5ea6\u53ca\u5bf9V2X\u7f51\u7edc\u7684\u5f71\u54cd\u3002", "result": "\u5206\u6790\u4e86\u538b\u7f29\u548c\u76ee\u6807\u68c0\u6d4b\u5bf9V2X\u7f51\u7edc\u6570\u636e\u901f\u7387\u548c\u5ef6\u8fdf\u7684\u5f71\u54cd\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u7b97\u6cd5\u7684\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8fdc\u7a0b\u9a7e\u9a76\u4e2d\u7684\u70b9\u4e91\u6570\u636e\u5904\u7406\u548c\u76ee\u6807\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u5206\u6790\uff0c\u652f\u6301\u672a\u6765TD\u5e94\u7528\u7684\u6280\u672f\u4f18\u5316\u3002"}}
{"id": "2506.11092", "pdf": "https://arxiv.org/pdf/2506.11092", "abs": "https://arxiv.org/abs/2506.11092", "authors": ["Jubin Abhishek Soni", "Amit Anand", "Rajesh Kumar Pandey", "Aniket Abhishek Soni"], "title": "Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "6 pages, 5 figures, 3 tables. This manuscript has been submitted to\n  IEEE conference. Researchers are welcome to read and build upon this work;\n  please cite it appropriately. For questions or clarifications, feel free to\n  contact me", "summary": "Retrieval-Augmented Generation (RAG) has significantly advanced large\nlanguage models (LLMs) by grounding their outputs in external tools and\nknowledge sources. However, existing RAG systems are typically constrained to\nstatic, single-turn interactions with fixed toolsets, making them ill-suited\nfor dynamic domains such as healthcare and smart homes, where user intent,\navailable tools, and contextual factors evolve over time. We present Dynamic\nContext Tuning (DCT), a lightweight framework that extends RAG to support\nmulti-turn dialogue and evolving tool environments without requiring\nretraining. DCT integrates an attention-based context cache to track relevant\npast information, LoRA-based retrieval to dynamically select domain-specific\ntools, and efficient context compression to maintain inputs within LLM context\nlimits. Experiments on both synthetic and real-world benchmarks show that DCT\nimproves plan accuracy by 14% and reduces hallucinations by 37%, while matching\nGPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to\npreviously unseen tools, enabling scalable and adaptable AI assistants across a\nwide range of dynamic environments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u4e0a\u4e0b\u6587\u8c03\u6574\uff08DCT\uff09\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4ee5\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u548c\u52a8\u6001\u5de5\u5177\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u7684RAG\u7cfb\u7edf\u901a\u5e38\u53d7\u9650\u4e8e\u9759\u6001\u3001\u5355\u8f6e\u4ea4\u4e92\u548c\u56fa\u5b9a\u5de5\u5177\u96c6\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u9886\u57df\uff08\u5982\u533b\u7597\u548c\u667a\u80fd\u5bb6\u5c45\uff09\u4e2d\u7528\u6237\u610f\u56fe\u548c\u5de5\u5177\u7684\u6f14\u53d8\u3002", "method": "DCT\u901a\u8fc7\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u4e0a\u4e0b\u6587\u7f13\u5b58\u8ddf\u8e2a\u5386\u53f2\u4fe1\u606f\uff0c\u4f7f\u7528LoRA\u52a8\u6001\u9009\u62e9\u5de5\u5177\uff0c\u5e76\u538b\u7f29\u8f93\u5165\u4ee5\u4fdd\u6301\u5728LLM\u4e0a\u4e0b\u6587\u9650\u5236\u5185\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDCT\u5728\u8ba1\u5212\u51c6\u786e\u6027\u4e0a\u63d0\u534714%\uff0c\u51cf\u5c11\u5e7b\u89c937%\uff0c\u4e14\u5728\u6210\u672c\u66f4\u4f4e\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230GPT-4\u6027\u80fd\u3002", "conclusion": "DCT\u80fd\u591f\u6cdb\u5316\u5230\u672a\u89c1\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u52a8\u6001\u73af\u5883\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u9002\u5e94\u6027\u5f3a\u7684AI\u52a9\u624b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.11003", "pdf": "https://arxiv.org/pdf/2506.11003", "abs": "https://arxiv.org/abs/2506.11003", "authors": ["Ruiyang Xu", "Jialun Cao", "Mingyuan Wu", "Wenliang Zhong", "Yaojie Lu", "Ben He", "Xianpei Han", "Shing-Chi Cheung", "Le Sun"], "title": "EmbedAgent: Benchmarking Large Language Models in Embedded System Development", "categories": ["cs.SE", "cs.AI"], "comment": "21 pages", "summary": "Large Language Models (LLMs) have shown promise in various tasks, yet few\nbenchmarks assess their capabilities in embedded system development.In this\npaper, we introduce EmbedAgent, a paradigm designed to simulate real-world\nroles in embedded system development, such as Embedded System Programmer,\nArchitect, and Integrator. This paradigm enables LLMs to be tested in tasks\nthat bridge the gap between digital and physical systems, allowing for a more\ncomprehensive assessment of their capabilities. To evaluate LLMs on these\ntasks, we propose Embedbench, the first comprehensive benchmark for embedded\nsystem programming, circuit design, and cross-platform migration.Embedbench\nconsists of 126 cases, covering 9 electronic components across 3 hardware\nplatforms. Through extensive experiments on 10 mainstream LLMs, we uncover\nseveral key findings. Surprisingly, despite the simplicity of the cases,\nDeepSeek-R1 achieves only a 55.6% pass@1 rate when provided with schematic\ninformation, and 50.0% when tasked with generating the schematics itself. In\nthe cross-platform migration tasks, LLMs show relatively strong performance\nwith MicroPython on the Raspberry Pi Pico (with the top model achieving 73.8%\npass@1), but perform poorly on ESP-IDF, where the best model reaches only 29.4%\npass@1.Interestingly, we observe that general-purpose chat LLMs like\nDeepSeek-V3 often fail to utilize relevant pre-trained knowledge in this\ndomain, while reasoning LLMs tend to overthink and overlook efficient knowledge\nduring pretraining. Based on these insights, we propose two strategies:\nretrieval augmented generation and compiler feedback-to enhance LLM\nperformance. These strategies result in significant improvements, with\nDeepseek-R1 reaching a 65.1% pass@1 with correct schematics, and 53.1% without.\nAdditionally, the accuracy of the Arduino to ESP32 migration task improves from\n21.4% to 27.8%.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86EmbedAgent\u548cEmbedbench\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u8868\u73b0\u4e0d\u4e00\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u8f83\u5c11\u8bc4\u4f30LLMs\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u4e2d\u7684\u80fd\u529b\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faEmbedAgent\u6a21\u62df\u5d4c\u5165\u5f0f\u5f00\u53d1\u89d2\u8272\uff0cEmbedbench\u5305\u542b126\u4e2a\u6d4b\u8bd5\u6848\u4f8b\uff0c\u8bc4\u4f3010\u79cd\u4e3b\u6d41LLMs\u3002", "result": "LLMs\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff08\u5982DeepSeek-R1\u4ec555.6%\u901a\u8fc7\u7387\uff09\uff0c\u4f46\u5728\u90e8\u5206\u4efb\u52a1\uff08\u5982MicroPython\uff09\u4e2d\u8868\u73b0\u8f83\u597d\u3002\u63d0\u51fa\u7684\u6539\u8fdb\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "LLMs\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u4e2d\u6f5c\u529b\u5f85\u6316\u6398\uff0c\u9700\u9488\u5bf9\u6027\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2506.11112", "pdf": "https://arxiv.org/pdf/2506.11112", "abs": "https://arxiv.org/abs/2506.11112", "authors": ["Christine Bauer", "Li Chen", "Nicola Ferro", "Norbert Fuhr", "Avishek Anand", "Timo Breuer", "Guglielmo Faggioli", "Ophir Frieder", "Hideo Joho", "Jussi Karlgren", "Johannes Kiesel", "Bart P. Knijnenburg", "Aldo Lipani", "Lien Michiels", "Andrea Papenmeier", "Maria Soledad Pera", "Mark Sanderson", "Scott Sanner", "Benno Stein", "Johanne R. Trippas", "Karin Verspoor", "Martijn C Willemsen"], "title": "Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE)", "categories": ["cs.CL", "cs.HC", "cs.IR"], "comment": "43 pages; 10 figures; Dagstuhl manifesto", "summary": "During the workshop, we deeply discussed what CONversational Information\nACcess (CONIAC) is and its unique features, proposing a world model abstracting\nit, and defined the Conversational Agents Framework for Evaluation (CAFE) for\nthe evaluation of CONIAC systems, consisting of six major components: 1) goals\nof the system's stakeholders, 2) user tasks to be studied in the evaluation, 3)\naspects of the users carrying out the tasks, 4) evaluation criteria to be\nconsidered, 5) evaluation methodology to be applied, and 6) measures for the\nquantitative criteria chosen.", "AI": {"tldr": "\u8ba8\u8bbaCONIAC\u5b9a\u4e49\u53ca\u5176\u4e16\u754c\u6a21\u578b\uff0c\u63d0\u51fa\u8bc4\u4f30\u6846\u67b6CAFE\uff0c\u5305\u542b\u516d\u5927\u7ec4\u4ef6\u3002", "motivation": "\u660e\u786eCONIAC\u7684\u72ec\u7279\u6027\u5e76\u5efa\u7acb\u7cfb\u7edf\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u63d0\u51faCAFE\u6846\u67b6\uff0c\u5305\u542b\u76ee\u6807\u3001\u4efb\u52a1\u3001\u7528\u6237\u7279\u6027\u3001\u6807\u51c6\u3001\u65b9\u6cd5\u8bba\u548c\u91cf\u5316\u6307\u6807\u3002", "result": "\u5b9a\u4e49\u4e86CONIAC\u7684\u8bc4\u4f30\u6846\u67b6CAFE\u3002", "conclusion": "CAFE\u4e3aCONIAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2506.11005", "pdf": "https://arxiv.org/pdf/2506.11005", "abs": "https://arxiv.org/abs/2506.11005", "authors": ["Mouna Dhaouadi", "Bentley Oakes", "Michalis Famelis"], "title": "Automated Extraction and Analysis of Developer's Rationale in Open Source Software", "categories": ["cs.SE"], "comment": null, "summary": "Contributors to open source software must deeply understand a project's\nhistory to make coherent decisions which do not conflict with past reasoning.\nHowever, inspecting all related changes to a proposed contribution requires\nintensive manual effort, and previous research has not yet produced an\nautomated mechanism to expose and analyze these conflicts. In this article, we\npropose such an automated approach for rationale analyses, based on an\ninstantiation of Kantara, an existing high-level rationale extraction and\nmanagement architecture. Our implementation leverages pre-trained models and\nLarge Language Models, and includes structure-based mechanisms to detect\nreasoning conflicts and problems which could cause design erosion in a project\nover time. We show the feasibility of our extraction and analysis approach\nusing the OOM-Killer module of the Linux Kernel project, and investigate the\napproach's generalization to five other highly active open source projects. The\nresults confirm that our automated approach can support rationale analyses with\nreasonable performance, by finding interesting relationships and to detect\npotential conflicts and reasoning problems. We also show the effectiveness of\nthe automated extraction of decision and rationale sentences and the prospects\nfor generalizing this to other open source projects. This automated approach\ncould therefore be used by open source software developers to proactively\naddress hidden issues and to ensure that new changes do not conflict with past\ndecisions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f00\u6e90\u9879\u76ee\u7684\u7406\u6027\u5206\u6790\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u5386\u53f2\u51b3\u7b56\u5e76\u907f\u514d\u51b2\u7a81\u3002", "motivation": "\u5f00\u6e90\u8d21\u732e\u8005\u9700\u8981\u7406\u89e3\u9879\u76ee\u5386\u53f2\u4ee5\u907f\u514d\u51b3\u7b56\u51b2\u7a81\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u81ea\u52a8\u5316\u5de5\u5177\u652f\u6301\u3002", "method": "\u57fa\u4e8eKantara\u67b6\u6784\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u68c0\u6d4b\u8bbe\u8ba1\u51b2\u7a81\u548c\u63a8\u7406\u95ee\u9898\u3002", "result": "\u5728Linux\u5185\u6838\u7b49\u9879\u76ee\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u80fd\u6709\u6548\u63d0\u53d6\u7406\u6027\u548c\u68c0\u6d4b\u51b2\u7a81\u3002", "conclusion": "\u81ea\u52a8\u5316\u5de5\u5177\u53ef\u5e2e\u52a9\u5f00\u53d1\u8005\u4e3b\u52a8\u89e3\u51b3\u9690\u85cf\u95ee\u9898\uff0c\u786e\u4fdd\u65b0\u53d8\u66f4\u4e0e\u5386\u53f2\u4e00\u81f4\u3002"}}
{"id": "2506.11151", "pdf": "https://arxiv.org/pdf/2506.11151", "abs": "https://arxiv.org/abs/2506.11151", "authors": ["Jonathan Grizou", "Carlos de la Torre-Ortiz", "Tuukka Ruotsalo"], "title": "Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels", "categories": ["cs.CV", "cs.HC"], "comment": "10 pages, 4 figures, 11 appendix pages, 7 appendix figures", "summary": "We consider the problem of recovering a mental target (e.g., an image of a\nface) that a participant has in mind from paired EEG (i.e., brain responses)\nand image (i.e., perceived faces) data collected during interactive sessions\nwithout access to labeled information. The problem has been previously explored\nwith labeled data but not via self-calibration, where labeled data is\nunavailable. Here, we present the first framework and an algorithm, CURSOR,\nthat learns to recover unknown mental targets without access to labeled data or\npre-trained decoders. Our experiments on naturalistic images of faces\ndemonstrate that CURSOR can (1) predict image similarity scores that correlate\nwith human perceptual judgments without any label information, (2) use these\nscores to rank stimuli against an unknown mental target, and (3) generate new\nstimuli indistinguishable from the unknown mental target (validated via a user\nstudy, N=53).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCURSOR\u7684\u7b97\u6cd5\uff0c\u9996\u6b21\u5728\u6ca1\u6709\u6807\u6ce8\u6570\u636e\u6216\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u81ea\u6821\u51c6\u65b9\u6cd5\u4eceEEG\u548c\u56fe\u50cf\u6570\u636e\u4e2d\u6062\u590d\u672a\u77e5\u7684\u5fc3\u7406\u76ee\u6807\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u4f9d\u8d56\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u5b9e\u9645\u573a\u666f\u4e2d\u6807\u6ce8\u6570\u636e\u53ef\u80fd\u4e0d\u53ef\u7528\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5728\u6ca1\u6709\u6807\u6ce8\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u4ece\u8111\u7535\u4fe1\u53f7\u4e2d\u6062\u590d\u5fc3\u7406\u76ee\u6807\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86CURSOR\u6846\u67b6\u548c\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u6821\u51c6\u5b66\u4e60\u4ece\u65e0\u6807\u6ce8\u7684EEG\u548c\u56fe\u50cf\u6570\u636e\u4e2d\u6062\u590d\u5fc3\u7406\u76ee\u6807\u3002", "result": "CURSOR\u80fd\u591f\u9884\u6d4b\u4e0e\u4eba\u7c7b\u611f\u77e5\u5224\u65ad\u76f8\u5173\u7684\u56fe\u50cf\u76f8\u4f3c\u6027\u5206\u6570\uff0c\u5e76\u751f\u6210\u4e0e\u672a\u77e5\u5fc3\u7406\u76ee\u6807\u96be\u4ee5\u533a\u5206\u7684\u65b0\u523a\u6fc0\uff08\u9a8c\u8bc1\u901a\u8fc7N=53\u7684\u7528\u6237\u7814\u7a76\uff09\u3002", "conclusion": "CURSOR\u5728\u65e0\u76d1\u7763\u6761\u4ef6\u4e0b\u5c55\u793a\u4e86\u4ece\u8111\u7535\u4fe1\u53f7\u4e2d\u6062\u590d\u5fc3\u7406\u76ee\u6807\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.11006", "pdf": "https://arxiv.org/pdf/2506.11006", "abs": "https://arxiv.org/abs/2506.11006", "authors": ["Sai Krishna", "Balvinder Singh", "Sujoy Roychowdhury", "Giriprasad Sridhara", "Sourav Mazumdar", "Magnus Sandelin", "Dimitris Rentas", "Maciej Nalepa", "Karol Sawicki", "Jakub Gajda"], "title": "Test code generation at Ericsson using Program Analysis Augmented Fine Tuned LLMs", "categories": ["cs.SE"], "comment": "Accepted at International Conference on Evaluation and Assessment in\n  Software Engineering (EASE), 2025", "summary": "We describe test code generation using Large Language Models (LLMs) in\nEricsson. Our input is a test step in natural language (English) and our output\nis code (Java) which accomplishes the test step. We describe how straight\nforward prompting does not suffice and results in LLM assuming functions and\nsignatures which are not present in the code repository. We then show how we\nalleviate the problem by a combination of Retrieval Augmented Generation (RAG)\nalong with prompt engineering that expanded the simple prompt with additional\ncontextual information using static program analysis. We then describe further\nimprovements that we obtained by fine-tuning the underlying LLM. The fine\ntuning is done based on a custom designed prompt template which has\npre-dependent classes, their public methods as well two exemplar outputs\nobtained from RAG. Our results establish that our fine tuned models help\nimprove the correspondence or conformity with the original developer written\ntest code as measured by the traditional metrics of F1-score based on the\nmethods used in the generated code. Fine tuning of a 8x7b Mixture of Experts\n(MoE) model leads to an average improvement of 8\\% over the base model and is\ncomparable to the scores on a much larger 8x22b MoE model.", "AI": {"tldr": "\u8bba\u6587\u63cf\u8ff0\u4e86\u5728\u7231\u7acb\u4fe1\u4e2d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u63d0\u793a\u5de5\u7a0b\u548c\u6a21\u578b\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u7684\u6d4b\u8bd5\u4ee3\u7801\u4e0e\u539f\u59cb\u5f00\u53d1\u8005\u4ee3\u7801\u7684\u5339\u914d\u5ea6\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u6d4b\u8bd5\u6b65\u9aa4\u76f4\u63a5\u901a\u8fc7\u7b80\u5355\u63d0\u793a\u751f\u6210Java\u4ee3\u7801\u65f6\uff0cLLM\u5047\u8bbe\u7684\u51fd\u6570\u548c\u7b7e\u540d\u4e0e\u4ee3\u7801\u5e93\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u901a\u8fc7\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u6269\u5c55\u63d0\u793a\u4fe1\u606f\uff0c\u5e76\u57fa\u4e8e\u81ea\u5b9a\u4e49\u63d0\u793a\u6a21\u677f\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5fae\u8c03\u540e\u76848x7b\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u6a21\u578b\u5728F1\u5206\u6570\u4e0a\u5e73\u5747\u63d0\u5347\u4e868%\uff0c\u4e0e\u66f4\u5927\u76848x22b MoE\u6a21\u578b\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u901a\u8fc7RAG\u548c\u6a21\u578b\u5fae\u8c03\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347LLM\u751f\u6210\u7684\u6d4b\u8bd5\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u5339\u914d\u5ea6\u3002"}}
{"id": "2506.11179", "pdf": "https://arxiv.org/pdf/2506.11179", "abs": "https://arxiv.org/abs/2506.11179", "authors": ["Md Mynoddin", "Troyee Dev", "Rishita Chakma"], "title": "Brain2Vec: A Deep Learning Framework for EEG-Based Stress Detection Using CNN-LSTM-Attention", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.NE", "q-bio.NC"], "comment": null, "summary": "Mental stress has become a pervasive factor affecting cognitive health and\noverall well-being, necessitating the development of robust, non-invasive\ndiagnostic tools. Electroencephalogram (EEG) signals provide a direct window\ninto neural activity, yet their non-stationary and high-dimensional nature\nposes significant modeling challenges. Here we introduce Brain2Vec, a new deep\nlearning tool that classifies stress states from raw EEG recordings using a\nhybrid architecture of convolutional, recurrent, and attention mechanisms. The\nmodel begins with a series of convolutional layers to capture localized spatial\ndependencies, followed by an LSTM layer to model sequential temporal patterns,\nand concludes with an attention mechanism to emphasize informative temporal\nregions. We evaluate Brain2Vec on the DEAP dataset, applying bandpass\nfiltering, z-score normalization, and epoch segmentation as part of a\ncomprehensive preprocessing pipeline. Compared to traditional CNN-LSTM\nbaselines, our proposed model achieves an AUC score of 0.68 and a validation\naccuracy of 81.25%. These findings demonstrate Brain2Vec's potential for\nintegration into wearable stress monitoring platforms and personalized\nhealthcare systems.", "AI": {"tldr": "Brain2Vec\u662f\u4e00\u79cd\u7ed3\u5408\u5377\u79ef\u3001LSTM\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u5de5\u5177\uff0c\u7528\u4e8e\u4ece\u539f\u59cbEEG\u4fe1\u53f7\u5206\u7c7b\u5fc3\u7406\u538b\u529b\u72b6\u6001\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u7cbe\u795e\u538b\u529b\u5f71\u54cd\u8ba4\u77e5\u5065\u5eb7\u548c\u6574\u4f53\u798f\u7949\uff0c\u9700\u8981\u5f00\u53d1\u975e\u4fb5\u5165\u6027\u8bca\u65ad\u5de5\u5177\u3002EEG\u4fe1\u53f7\u56e0\u975e\u5e73\u7a33\u6027\u548c\u9ad8\u7ef4\u5ea6\u7279\u6027\u5efa\u6a21\u6311\u6218\u5927\u3002", "method": "Brain2Vec\u91c7\u7528\u5377\u79ef\u5c42\u6355\u83b7\u7a7a\u95f4\u4f9d\u8d56\uff0cLSTM\u5efa\u6a21\u65f6\u95f4\u6a21\u5f0f\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7a81\u51fa\u5173\u952e\u65f6\u95f4\u533a\u57df\u3002\u9884\u5904\u7406\u5305\u62ec\u5e26\u901a\u6ee4\u6ce2\u3001z-score\u6807\u51c6\u5316\u548c\u5206\u6bb5\u3002", "result": "\u5728DEAP\u6570\u636e\u96c6\u4e0a\uff0cBrain2Vec\u7684AUC\u4e3a0.68\uff0c\u9a8c\u8bc1\u51c6\u786e\u7387\u4e3a81.25%\uff0c\u4f18\u4e8e\u4f20\u7edfCNN-LSTM\u57fa\u7ebf\u3002", "conclusion": "Brain2Vec\u5c55\u73b0\u51fa\u5728\u53ef\u7a7f\u6234\u538b\u529b\u76d1\u6d4b\u548c\u4e2a\u6027\u5316\u533b\u7597\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.11007", "pdf": "https://arxiv.org/pdf/2506.11007", "abs": "https://arxiv.org/abs/2506.11007", "authors": ["Rock Sabetto", "Emily Escamilla", "Devesh Agarwal", "Sujay Kandwal", "Justin F. Brunelle", "Scott Rosen", "Nitin Naik", "Samruddhi Thaker", "Eric O. Scott", "Jacob Zimmer", "Amit Madan", "Arun Sridharan", "Doug Wendt", "Michael Doyle", "Christopher Glasz", "Jasper Phillips", "William Macke", "Colin Diggs", "Michael Bartholf", "Zachary Robin", "Paul Ursino"], "title": "Impact of Comments on LLM Comprehension of Legacy Code", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been increasingly integrated into software\nengineering and maintenance tasks due to their high performance with software\nengineering tasks and robust understanding of modern programming languages.\nHowever, the ability of LLMs to comprehend code written with legacy languages\nremains a research gap challenged by real-world legacy systems lacking or\ncontaining inaccurate documentation that may impact LLM comprehension. To\nassess LLM comprehension of legacy languages, there is a need for objective LLM\nevaluation. In order to objectively measure LLM comprehension of legacy\nlanguages, we need an efficient, quantitative evaluation method. We leverage\nmultiple-choice question answering (MCQA), an emerging LLM evaluation\nmethodology, to evaluate LLM comprehension of legacy code and the impact of\ncomment prevalence and inaccurate comments. In this work, we present\npreliminary findings on the impact of documentation on LLM comprehension of\nlegacy code and outline strategic objectives for future work.", "AI": {"tldr": "\u603b\u7ed3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u548c\u7ef4\u62a4\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u5176\u5728\u7406\u89e3\u9057\u7559\u8bed\u8a00\u4ee3\u7801\u65b9\u9762\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u591a\u9879\u9009\u62e9\u9898\u56de\u7b54\uff08MCQA\uff09\u65b9\u6cd5\u8bc4\u4f30LLM\u5bf9\u9057\u7559\u4ee3\u7801\u7406\u89e3\u7684\u65b0\u9014\u5f84\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u7406\u89e3\u9057\u7559\u8bed\u8a00\u4ee3\u7801\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u7f3a\u4e4f\u6216\u6587\u6863\u4e0d\u51c6\u786e\u7684\u60c5\u51b5\u4e0b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u5229\u7528\u591a\u9879\u9009\u62e9\u9898\u56de\u7b54\uff08MCQA\uff09\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\uff0c\u91cf\u5316LLM\u5bf9\u9057\u7559\u4ee3\u7801\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5206\u6790\u6587\u6863\u6ce8\u91ca\u7684\u666e\u904d\u6027\u548c\u51c6\u786e\u6027\u5bf9\u7406\u89e3\u7684\u5f71\u54cd\u3002", "result": "\u521d\u6b65\u7814\u7a76\u4e86\u6587\u6863\u5bf9LLM\u7406\u89e3\u9057\u7559\u4ee3\u7801\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u5de5\u4f5c\u7684\u6218\u7565\u76ee\u6807\u3002", "conclusion": "MCQA\u65b9\u6cd5\u4e3a\u8bc4\u4f30LLM\u5bf9\u9057\u7559\u4ee3\u7801\u7684\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u672a\u6765\u7814\u7a76\u9700\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u548c\u4f18\u5316\u8be5\u65b9\u6cd5\u3002"}}
{"id": "2506.11212", "pdf": "https://arxiv.org/pdf/2506.11212", "abs": "https://arxiv.org/abs/2506.11212", "authors": ["Carla F. Griggio", "Boel Nelson", "Zefan Sramek", "Aslan Askarov"], "title": "User Perceptions and Attitudes Toward Untraceability in Messaging Platforms", "categories": ["cs.CR", "cs.HC"], "comment": null, "summary": "Mainstream messaging platforms offer a variety of features designed to\nenhance user privacy, such as disappearing messages, password-protected chats,\nand end-to-end encryption (E2EE), which primarily protect message contents.\nBeyond contents, the transmission of messages generates metadata that can\nreveal who communicates with whom, when and how often. In this paper, we study\nuser perceptions of \"untraceability\", i.e., preventing third parties from\ntracing who communicates with whom, with the goal of informing the design of\nprivacy-enhancing features in messaging platforms and untraceable communication\nprotocols that depend on large anonymity sets and widespread user adoption. We\nexplore this from a broad conceptual standpoint: rather than studying mental\nmodels of a particular solution, we analyze how users reason about what\nfeatures should be incorporated by two fictitious platforms, Texty and Chatty,\nto prevent third parties from knowing who communicates with whom. Through a\nvignette-based survey with 189 participants, we found that users associate the\nconcept of untraceability with a wide range of privacy enhancing technologies,\nimplying a diverse set of threat models. Overall, the features suggested by\nparticipants show awareness of privacy threats stemming from forms of\nsurveillance and unauthorized access to message contents. Many participants\nalso associated untraceability with the notion of anonymity, but interpreted it\nas senders and receivers concealing their identity from each other rather than\nonly from third parties. We discuss the gap between users' perceptions of\nuntraceability and the threat models addressed by untraceable communication\nprotocols, as well as how different privacy attitudes point to challenges and\nopportunities for the adoption of untraceable communication tools in messaging\nplatforms.", "AI": {"tldr": "\u7814\u7a76\u7528\u6237\u5bf9\u6d88\u606f\u5e73\u53f0\u4e2d\u201c\u4e0d\u53ef\u8ffd\u8e2a\u6027\u201d\u7684\u611f\u77e5\uff0c\u63a2\u8ba8\u5176\u5bf9\u9690\u79c1\u589e\u5f3a\u529f\u80fd\u548c\u533f\u540d\u901a\u4fe1\u534f\u8bae\u8bbe\u8ba1\u7684\u542f\u793a\u3002", "motivation": "\u6d88\u606f\u5e73\u53f0\u901a\u8fc7\u73b0\u6709\u529f\u80fd\u4fdd\u62a4\u5185\u5bb9\u9690\u79c1\uff0c\u4f46\u5143\u6570\u636e\u4ecd\u53ef\u80fd\u6cc4\u9732\u901a\u4fe1\u5173\u7cfb\u3002\u7814\u7a76\u7528\u6237\u5bf9\u201c\u4e0d\u53ef\u8ffd\u8e2a\u6027\u201d\u7684\u7406\u89e3\uff0c\u4ee5\u6307\u5bfc\u672a\u6765\u9690\u79c1\u529f\u80fd\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u865a\u6784\u5e73\u53f0Texty\u548cChatty\u7684\u6848\u4f8b\u8c03\u67e5189\u540d\u53c2\u4e0e\u8005\uff0c\u5206\u6790\u5176\u5bf9\u201c\u4e0d\u53ef\u8ffd\u8e2a\u6027\u201d\u529f\u80fd\u7684\u5efa\u8bae\u548c\u5a01\u80c1\u6a21\u578b\u7684\u591a\u6837\u6027\u3002", "result": "\u7528\u6237\u5bf9\u201c\u4e0d\u53ef\u8ffd\u8e2a\u6027\u201d\u7684\u7406\u89e3\u591a\u6837\uff0c\u5305\u62ec\u533f\u540d\u6027\u548c\u9690\u79c1\u5a01\u80c1\u9632\u8303\uff0c\u4f46\u4e0e\u6280\u672f\u534f\u8bae\u7684\u5b9e\u9645\u5a01\u80c1\u6a21\u578b\u5b58\u5728\u5dee\u8ddd\u3002", "conclusion": "\u7528\u6237\u8ba4\u77e5\u4e0e\u9690\u79c1\u6280\u672f\u8bbe\u8ba1\u5b58\u5728\u5dee\u5f02\uff0c\u4e3a\u6d88\u606f\u5e73\u53f0\u96c6\u6210\u4e0d\u53ef\u8ffd\u8e2a\u5de5\u5177\u63d0\u4f9b\u4e86\u6311\u6218\u4e0e\u673a\u9047\u3002"}}
{"id": "2506.11008", "pdf": "https://arxiv.org/pdf/2506.11008", "abs": "https://arxiv.org/abs/2506.11008", "authors": ["David Noever"], "title": "Encoding Software For Perpetuity: A Compact Representation Of Apollo 11 Guidance Code", "categories": ["cs.SE"], "comment": null, "summary": "This brief note presents a novel method for encoding historic Apollo 11 Lunar\nModule guidance computer code into a single, compact Quick Response Code (QR\ncode) format, creating an accessible digital artifact for transmission and\narchival purposes. By applying tokenization, selective content preservation,\nand minimal HTML/JavaScript techniques, we successfully compressed key\ncomponents of the original Assembly Language Code (AGC) into a shareable,\npreservable, and scannable 3 kilobyte (KB) image. We evaluate multiple\ncompression strategies and their tradeoffs in terms of size, readability, and\nhistorical significance. This method addresses the challenge of making\nhistorically significant software artifacts available through modern mobile\ndevices without requiring specialized hardware or internet connectivity. While\nnumerous digital preservation methods exist for historic software, this\napproach balances accessibility with historical significance, offering a\ncomplementary method to traditional archival techniques. This work contributes\nto the broader field of computing heritage preservation by demonstrating how\nlandmark software can be made accessible instantly through contemporary mobile\ntechnologies.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5c06\u963f\u6ce2\u7f5711\u53f7\u767b\u6708\u8231\u5f15\u5bfc\u8ba1\u7b97\u673a\u4ee3\u7801\u538b\u7f29\u4e3aQR\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u5176\u53ef\u901a\u8fc7\u73b0\u4ee3\u79fb\u52a8\u8bbe\u5907\u8bbf\u95ee\u4e14\u65e0\u9700\u4e13\u95e8\u786c\u4ef6\u6216\u4e92\u8054\u7f51\u8fde\u63a5\u3002", "motivation": "\u76ee\u6807\u662f\u4e3a\u5386\u53f2\u6027\u8f6f\u4ef6\u9057\u4ea7\u63d0\u4f9b\u4e00\u79cd\u4fbf\u6377\u4e14\u6613\u4e8e\u4fdd\u5b58\u7684\u6570\u5b57\u5316\u65b9\u6cd5\uff0c\u4f7f\u5176\u5728\u73b0\u4ee3\u79fb\u52a8\u8bbe\u5907\u4e0a\u53ef\u8bbf\u95ee\u3002", "method": "\u901a\u8fc7\u4ee4\u724c\u5316\u3001\u9009\u62e9\u6027\u5185\u5bb9\u4fdd\u7559\u548c\u6700\u5c0f\u5316HTML/JavaScript\u6280\u672f\uff0c\u5c06\u539f\u59cb\u6c47\u7f16\u8bed\u8a00\u4ee3\u7801\u538b\u7f29\u4e3a3KB\u7684QR\u7801\u3002", "result": "\u6210\u529f\u5c06\u5173\u952e\u7ec4\u4ef6\u538b\u7f29\u4e3a\u53ef\u5206\u4eab\u3001\u4fdd\u5b58\u548c\u626b\u63cf\u7684\u56fe\u50cf\uff0c\u540c\u65f6\u8bc4\u4f30\u4e86\u4e0d\u540c\u538b\u7f29\u7b56\u7565\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8ba1\u7b97\u9057\u4ea7\u4fdd\u62a4\u63d0\u4f9b\u4e86\u4e00\u79cd\u8865\u5145\u4f20\u7edf\u5b58\u6863\u7684\u6280\u672f\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u73b0\u4ee3\u79fb\u52a8\u6280\u672f\u5373\u65f6\u8bbf\u95ee\u91cd\u8981\u8f6f\u4ef6\u3002"}}
{"id": "2506.11376", "pdf": "https://arxiv.org/pdf/2506.11376", "abs": "https://arxiv.org/abs/2506.11376", "authors": ["Liying Wang", "Ph. D.", "Daffodil Carrington", "M. S.", "Daniil Filienko", "M. S.", "Caroline El Jazmi", "M. S.", "Serena Jinchen Xie", "M. S.", "Martine De Cock", "Ph. D.", "Sarah Iribarren", "Ph. D.", "Weichao Yuwen", "Ph. D"], "title": "Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Family caregivers often face substantial mental health challenges due to\ntheir multifaceted roles and limited resources. This study explored the\npotential of a large language model (LLM)-powered conversational agent to\ndeliver evidence-based mental health support for caregivers, specifically\nProblem-Solving Therapy (PST) integrated with Motivational Interviewing (MI)\nand Behavioral Chain Analysis (BCA). A within-subject experiment was conducted\nwith 28 caregivers interacting with four LLM configurations to evaluate empathy\nand therapeutic alliance. The best-performing models incorporated Few-Shot and\nRetrieval-Augmented Generation (RAG) prompting techniques, alongside\nclinician-curated examples. The models showed improved contextual understanding\nand personalized support, as reflected by qualitative responses and\nquantitative ratings on perceived empathy and therapeutic alliances.\nParticipants valued the model's ability to validate emotions, explore\nunexpressed feelings, and provide actionable strategies. However, balancing\nthorough assessment with efficient advice delivery remains a challenge. This\nwork highlights the potential of LLMs in delivering empathetic and tailored\nsupport for family caregivers.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u5bf9\u8bdd\u4ee3\u7406\u5728\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u5fc3\u7406\u5065\u5eb7\u652f\u6301\uff08\u5982PST\u3001MI\u548cBCA\u7597\u6cd5\uff09\u7ed9\u5bb6\u5ead\u62a4\u7406\u4eba\u5458\u4e2d\u7684\u6f5c\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408Few-Shot\u548cRAG\u63d0\u793a\u6280\u672f\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5bb6\u5ead\u62a4\u7406\u4eba\u5458\u56e0\u89d2\u8272\u590d\u6742\u4e14\u8d44\u6e90\u6709\u9650\u800c\u9762\u4e34\u5fc3\u7406\u5065\u5eb7\u6311\u6218\uff0c\u4e9f\u9700\u6709\u6548\u652f\u6301\u3002", "method": "\u901a\u8fc728\u540d\u62a4\u7406\u4eba\u5458\u4e0e\u56db\u79cdLLM\u914d\u7f6e\u4ea4\u4e92\u7684\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5171\u60c5\u548c\u6cbb\u7597\u8054\u76df\u3002", "result": "\u6700\u4f73\u6a21\u578b\u80fd\u63d0\u5347\u60c5\u5883\u7406\u89e3\u548c\u4e2a\u6027\u5316\u652f\u6301\uff0c\u53c2\u4e0e\u8005\u5bf9\u5176\u60c5\u611f\u9a8c\u8bc1\u548c\u7b56\u7565\u63d0\u4f9b\u8868\u793a\u8ba4\u53ef\u3002", "conclusion": "LLM\u5728\u63d0\u4f9b\u5171\u60c5\u548c\u5b9a\u5236\u5316\u652f\u6301\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u5e73\u8861\u8bc4\u4f30\u4e0e\u5efa\u8bae\u6548\u7387\u3002"}}
{"id": "2506.11009", "pdf": "https://arxiv.org/pdf/2506.11009", "abs": "https://arxiv.org/abs/2506.11009", "authors": ["Jirat Pasuksmit", "Wannita Takerngsaksiri", "Patanamon Thongtanunam", "Chakkrit Tantithamthavorn", "Ruixiong Zhang", "Shiyan Wang", "Fan Jiang", "Jing Li", "Evan Cook", "Kun Chen", "Ming Wu"], "title": "Human-In-The-Loop Software Development Agents: Challenges and Future Directions", "categories": ["cs.SE"], "comment": "The International Conference on Mining Software Repositories (MSR)\n  2025, Industry track", "summary": "Multi-agent LLM-driven systems for software development are rapidly gaining\ntraction, offering new opportunities to enhance productivity. At Atlassian, we\ndeployed Human-in-the-Loop Software Development Agents to resolve Jira work\nitems and evaluated the generated code quality using functional correctness\ntesting and GPT-based similarity scoring. This paper highlights two major\nchallenges: the high computational costs of unit testing and the variability in\nLLM-based evaluations. We also propose future research directions to improve\nevaluation frameworks for Human-In-The-Loop software development tools.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u591a\u667a\u80fd\u4f53LLM\u9a71\u52a8\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u8bc4\u4f30\u4e0d\u4e00\u81f4\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5229\u7528\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\uff0c\u7279\u522b\u662f\u5728Jira\u5de5\u4f5c\u9879\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u529f\u80fd\u6b63\u786e\u6027\u6d4b\u8bd5\u548c\u57fa\u4e8eGPT\u7684\u76f8\u4f3c\u6027\u8bc4\u5206\u8bc4\u4f30\u751f\u6210\u4ee3\u7801\u8d28\u91cf\uff0c\u5e76\u5206\u6790\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "result": "\u53d1\u73b0\u5355\u5143\u6d4b\u8bd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548cLLM\u8bc4\u4f30\u7684\u53d8\u5f02\u6027\u662f\u4e3b\u8981\u6311\u6218\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u9700\u6539\u8fdb\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u4f18\u5316\u4eba\u673a\u534f\u540c\u7684\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u3002"}}
{"id": "2506.11727", "pdf": "https://arxiv.org/pdf/2506.11727", "abs": "https://arxiv.org/abs/2506.11727", "authors": ["Bernhard Rieder", "Adrian Padilla", "Oscar Coromina"], "title": "Forgetful by Design? A Critical Audit of YouTube's Search API for Academic Research", "categories": ["cs.IR", "cs.HC", "cs.SI"], "comment": "34 pages, 2 tables and 4 figures", "summary": "This paper critically audits the search endpoint of YouTube's Data API (v3),\na common tool for academic research. Through systematic weekly searches over\nsix months using eleven queries, we identify major limitations regarding\ncompleteness, representativeness, consistency, and bias. Our findings reveal\nsubstantial differences between ranking parameters like relevance and date in\nterms of video recall and precision, with relevance often retrieving numerous\noff-topic videos. We also find severe temporal decay, as the number of findable\nvideos for a specific period dramatically decreases after just 20-60 days from\nthe publication date, potentially hampering many different research designs.\nFurthermore, search results lack consistency, with identical queries yielding\ndifferent video sets over time, compromising replicability. A case study on the\nEuropean Parliament elections highlights how these issues impact research\noutcomes. While the paper offers several mitigation strategies, it concludes\nthat the API's search function, potentially prioritizing \"freshness\" over\ncomprehensive retrieval, is not adequate for robust academic research,\nespecially concerning Digital Services Act requirements.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6279\u5224\u6027\u5730\u5206\u6790\u4e86YouTube Data API (v3) \u7684\u641c\u7d22\u7aef\u70b9\uff0c\u53d1\u73b0\u5176\u5728\u5b8c\u6574\u6027\u3001\u4ee3\u8868\u6027\u3001\u4e00\u81f4\u6027\u548c\u504f\u89c1\u65b9\u9762\u5b58\u5728\u663e\u8457\u95ee\u9898\uff0c\u5e76\u63ed\u793a\u4e86\u6392\u540d\u53c2\u6570\u5bf9\u89c6\u9891\u53ec\u56de\u7387\u548c\u7cbe\u786e\u5ea6\u7684\u5f71\u54cd\u4ee5\u53ca\u65f6\u95f4\u8870\u51cf\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30YouTube API\u7684\u641c\u7d22\u529f\u80fd\uff0c\u63ed\u793a\u5176\u5728\u5b66\u672f\u7814\u7a76\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u6b27\u76df\u300a\u6570\u5b57\u670d\u52a1\u6cd5\u300b\u8981\u6c42\u7684\u6f5c\u5728\u4e0d\u9002\u5e94\u6027\u3002", "method": "\u901a\u8fc7\u516d\u4e2a\u6708\u7684\u7cfb\u7edf\u6027\u6bcf\u5468\u641c\u7d22\uff0c\u4f7f\u752811\u4e2a\u67e5\u8be2\u8bcd\uff0c\u5bf9API\u7684\u641c\u7d22\u7ed3\u679c\u7684\u5b8c\u6574\u6027\u3001\u4e00\u81f4\u6027\u3001\u65f6\u95f4\u8870\u51cf\u7b49\u6307\u6807\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cAPI\u7684\u641c\u7d22\u7ed3\u679c\u5b58\u5728\u65f6\u95f4\u8870\u51cf\uff0820-60\u5929\u5185\u89c6\u9891\u53ef\u68c0\u7d22\u6027\u5927\u5e45\u4e0b\u964d\uff09\u3001\u4e00\u81f4\u6027\u5dee\uff08\u76f8\u540c\u67e5\u8be2\u8fd4\u56de\u4e0d\u540c\u7ed3\u679c\uff09\u3001\u53c2\u6570\u9009\u62e9\uff08\u5982\u76f8\u5173\u6027\uff09\u5bfc\u81f4\u5927\u91cf\u65e0\u5173\u89c6\u9891\u3002", "conclusion": "\u5c3d\u7ba1\u63d0\u51fa\u4e86\u7f13\u89e3\u7b56\u7565\uff0c\u4f46\u7814\u7a76\u8005\u8ba4\u4e3aYouTube API\u7684\u641c\u7d22\u529f\u80fd\u56e0\u4f18\u5148\u8003\u8651\u201c\u65b0\u9c9c\u5ea6\u201d\u800c\u975e\u5168\u9762\u68c0\u7d22\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b66\u672f\u7814\u7a76\u7684\u4e25\u8c28\u6027\u8981\u6c42\u3002"}}
{"id": "2506.11011", "pdf": "https://arxiv.org/pdf/2506.11011", "abs": "https://arxiv.org/abs/2506.11011", "authors": ["Abhi Desai"], "title": "Enhancing Inventory Management with Progressive Web Applications (PWAs): A Scalable Solution for Small and Large Enterprises", "categories": ["cs.SE"], "comment": null, "summary": "Efficient inventory management is crucial for both small and large\nenterprises to optimize operational workflows and reduce overhead costs. This\npaper explores the development and implementation of a Progressive Web\nApplication (PWA) designed to enhance the inventory management experience. The\napplication integrates key functionalities such as barcode and QR code\nscanning, geolocation-based warehouse identification, and cross-device\naccessibility. By leveraging PWA technology, the solution ensures offline\ncapabilities, responsive user experience, and seamless adaptability across\nvarious platforms. The study discusses the challenges and benefits of\nimplementing PWA in inventory management systems, including its limitations in\nperformance compared to native applications. Insights from the development\nprocess provide a roadmap for future developers looking to integrate PWA\ntechnology into enterprise applications. This research contributes to the\ngrowing domain of web-based inventory solutions, offering a scalable and\ncost-effective alternative to traditional inventory management software.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6e10\u8fdb\u5f0fWeb\u5e94\u7528\uff08PWA\uff09\u5728\u5e93\u5b58\u7ba1\u7406\u4e2d\u7684\u5f00\u53d1\u4e0e\u5b9e\u65bd\uff0c\u65e8\u5728\u4f18\u5316\u64cd\u4f5c\u6d41\u7a0b\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u901a\u8fc7\u6574\u5408\u6761\u7801\u626b\u63cf\u3001\u5730\u7406\u4f4d\u7f6e\u8bc6\u522b\u7b49\u529f\u80fd\uff0c\u63d0\u5347\u5e93\u5b58\u7ba1\u7406\u6548\u7387\uff0c\u7814\u7a76PWA\u6280\u672f\u7684\u6f5c\u529b\u4e0e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e00\u6b3ePWA\u5e94\u7528\uff0c\u652f\u6301\u79bb\u7ebf\u529f\u80fd\u3001\u8de8\u5e73\u53f0\u9002\u914d\u53ca\u54cd\u5e94\u5f0f\u7528\u6237\u4f53\u9a8c\uff0c\u5e76\u5206\u6790\u5176\u6027\u80fd\u3002", "result": "PWA\u5728\u63d0\u4f9b\u8de8\u5e73\u53f0\u548c\u79bb\u7ebf\u529f\u80fd\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u4f46\u5728\u6027\u80fd\u4e0a\u53ef\u80fd\u900a\u4e8e\u539f\u751f\u5e94\u7528\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u63d0\u4f9b\u53c2\u8003\u3002", "conclusion": "PWA\u4e3a\u5e93\u5b58\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2506.11773", "pdf": "https://arxiv.org/pdf/2506.11773", "abs": "https://arxiv.org/abs/2506.11773", "authors": ["Zikang Leng", "Megha Thukral", "Yaqi Liu", "Hrudhai Rajasekhar", "Shruthi K. Hiremath", "Thomas Pl\u00f6tz"], "title": "AgentSense: Virtual Sensor Data Generation Using LLM Agent in Simulated Home Environments", "categories": ["cs.CV", "cs.HC"], "comment": null, "summary": "A major obstacle in developing robust and generalizable smart home-based\nHuman Activity Recognition (HAR) systems is the lack of large-scale, diverse\nlabeled datasets. Variability in home layouts, sensor configurations, and user\nbehavior adds further complexity, as individuals follow varied routines and\nperform activities in distinct ways. Building HAR systems that generalize well\nrequires training data that captures the diversity across users and\nenvironments. To address these challenges, we introduce AgentSense, a virtual\ndata generation pipeline where diverse personas are generated by leveraging\nLarge Language Models. These personas are used to create daily routines, which\nare then decomposed into low-level action sequences. Subsequently, the actions\nare executed in a simulated home environment called VirtualHome that we\nextended with virtual ambient sensors capable of recording the agents\nactivities as they unfold. Overall, AgentSense enables the generation of rich,\nvirtual sensor datasets that represent a wide range of users and home settings.\nAcross five benchmark HAR datasets, we show that leveraging our virtual sensor\ndata substantially improves performance, particularly when real data are\nlimited. Notably, models trained on a combination of virtual data and just a\nfew days of real data achieve performance comparable to those trained on the\nentire real datasets. These results demonstrate and prove the potential of\nvirtual data to address one of the most pressing challenges in ambient sensing,\nwhich is the distinct lack of large-scale, annotated datasets without requiring\nany manual data collection efforts.", "AI": {"tldr": "AgentSense\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u865a\u62df\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u667a\u80fd\u5bb6\u5c45\u4e2d\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u667a\u80fd\u5bb6\u5c45\u4e2d\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u7cfb\u7edf\u56e0\u7f3a\u4e4f\u5927\u89c4\u6a21\u591a\u6837\u5316\u6807\u6ce8\u6570\u636e\u800c\u96be\u4ee5\u6cdb\u5316\uff0c\u9700\u89e3\u51b3\u6570\u636e\u591a\u6837\u6027\u548c\u73af\u5883\u5dee\u5f02\u95ee\u9898\u3002", "method": "\u5f00\u53d1AgentSense\u6d41\u7a0b\uff0c\u901a\u8fc7\u865a\u62df\u89d2\u8272\u751f\u6210\u65e5\u5e38\u884c\u4e3a\u5e8f\u5217\uff0c\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8bb0\u5f55\u4f20\u611f\u5668\u6570\u636e\u3002", "result": "\u865a\u62df\u6570\u636e\u4e0e\u5c11\u91cf\u771f\u5b9e\u6570\u636e\u7ed3\u5408\u8bad\u7ec3\u6a21\u578b\uff0c\u6027\u80fd\u63a5\u8fd1\u5b8c\u5168\u771f\u5b9e\u6570\u636e\u8bad\u7ec3\u7684\u7ed3\u679c\u3002", "conclusion": "\u865a\u62df\u6570\u636e\u53ef\u6709\u6548\u7f13\u89e3\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u65e0\u9700\u624b\u52a8\u6536\u96c6\u6570\u636e\u3002"}}
{"id": "2506.11013", "pdf": "https://arxiv.org/pdf/2506.11013", "abs": "https://arxiv.org/abs/2506.11013", "authors": ["Filipe Fernandes", "Cl\u00e1udia Werner"], "title": "Toward a Brazilian Research Agenda in Quantum Software Engineering: A Systematic Mapping Study", "categories": ["cs.SE"], "comment": "11 pages, 13 figures", "summary": "Context: Quantum Software Engineering (QSE) has emerged as a key field to\nsupport the development of reliable, maintainable, and scalable quantum\napplications, bridging advances in quantum computing with established practices\nin software engineering. Problem: Despite its growth, the field still suffers\nfrom fragmented knowledge, with a lack of standardized methodologies, tools,\nand guidelines tailored to the unique features of the quantum paradigm.\nAdditionally, countries like Brazil have had limited participation in the\ndevelopment of this emerging domain. Objective: This study aims to map the\nstate of the art in QSE by identifying current research trends, recurring\ncontributions, and existing gaps that can guide future investigations and\nstrategic initiatives. Methodology: A systematic mapping study was conducted\nanalyzing selected publications based on inclusion and exclusion criteria.\nArticles were categorized by study type, research type, and alignment with the\nSWEBOK knowledge areas. Results: Most of the reviewed studies are primary\nresearch articles written in English, with a strong focus on Software\nEngineering Models and Methods, Software Architecture, and Software Testing.\nConceptual proposals and technical solutions predominate, while empirical\nvalidations remain limited. Conclusions: Findings confirm that QSE is a\npromising but still maturing field. The standardization of practices, expansion\nof empirical studies, and inclusion of researchers from developing countries\nare crucial for advancing the discipline. Additionally, Brazilian contributions\nare still scarce, highlighting the urgent need to establish a national research\nagenda. As a main contribution, this study proposes a Brazilian Research Agenda\nin QSE, outlining priority areas and opportunities to foster a local scientific\ncommunity and accelerate progress in this emerging field.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\uff08QSE\uff09\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u63d0\u51fa\u5df4\u897f\u7814\u7a76\u8bae\u7a0b\u4ee5\u586b\u8865\u8be5\u9886\u57df\u7684\u7a7a\u767d\u3002", "motivation": "\u5c3d\u7ba1QSE\u9886\u57df\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u77e5\u8bc6\u788e\u7247\u5316\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u5df4\u897f\u7b49\u56fd\u7684\u53c2\u4e0e\u5ea6\u8f83\u4f4e\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\uff0c\u5206\u6790\u6587\u732e\u7684\u5206\u7c7b\u3001\u7814\u7a76\u7c7b\u578b\u53ca\u5176\u4e0eSWEBOK\u77e5\u8bc6\u9886\u57df\u7684\u8054\u7cfb\u3002", "result": "\u591a\u6570\u7814\u7a76\u96c6\u4e2d\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6a21\u578b\u3001\u67b6\u6784\u548c\u6d4b\u8bd5\uff0c\u4f46\u5b9e\u8bc1\u9a8c\u8bc1\u8f83\u5c11\uff1b\u5df4\u897f\u7684\u7814\u7a76\u8d21\u732e\u7a00\u7f3a\u3002", "conclusion": "QSE\u662f\u4e00\u4e2a\u6709\u524d\u666f\u4f46\u4ecd\u5728\u53d1\u5c55\u7684\u9886\u57df\uff0c\u9700\u6807\u51c6\u5316\u5b9e\u8df5\u3001\u6269\u5927\u5b9e\u8bc1\u7814\u7a76\u5e76\u63d0\u5347\u53d1\u5c55\u4e2d\u56fd\u5bb6\u53c2\u4e0e\u5ea6\u3002"}}
{"id": "2506.11774", "pdf": "https://arxiv.org/pdf/2506.11774", "abs": "https://arxiv.org/abs/2506.11774", "authors": ["Abhishek Jaiswal", "Armeet Singh Luthra", "Purav Jangir", "Bhavya Garg", "Nisheeth Srivastava"], "title": "Real-Time Feedback and Benchmark Dataset for Isometric Pose Evaluation", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Isometric exercises appeal to individuals seeking convenience, privacy, and\nminimal dependence on equipments. However, such fitness training is often\noverdependent on unreliable digital media content instead of expert\nsupervision, introducing serious risks, including incorrect posture, injury,\nand disengagement due to lack of corrective feedback. To address these\nchallenges, we present a real-time feedback system for assessing isometric\nposes. Our contributions include the release of the largest multiclass\nisometric exercise video dataset to date, comprising over 3,600 clips across\nsix poses with correct and incorrect variations. To support robust evaluation,\nwe benchmark state-of-the-art models-including graph-based networks-on this\ndataset and introduce a novel three-part metric that captures classification\naccuracy, mistake localization, and model confidence. Our results enhance the\nfeasibility of intelligent and personalized exercise training systems for home\nworkouts. This expert-level diagnosis, delivered directly to the users, also\nexpands the potential applications of these systems to rehabilitation,\nphysiotherapy, and various other fitness disciplines that involve physical\nmotion.", "AI": {"tldr": "\u5f00\u53d1\u5b9e\u65f6\u53cd\u9988\u7cfb\u7edf\uff0c\u8bc4\u4f30\u7b49\u957f\u8fd0\u52a8\u59ff\u52bf\uff0c\u53d1\u5e03\u5927\u578b\u6570\u636e\u96c6\u5e76\u5f15\u5165\u65b0\u6307\u6807\uff0c\u63d0\u5347\u667a\u80fd\u5bb6\u5ead\u5065\u8eab\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u89e3\u51b3\u7b49\u957f\u8fd0\u52a8\u4f9d\u8d56\u4e0d\u53ef\u9760\u6570\u5b57\u5185\u5bb9\u5bfc\u81f4\u7684\u98ce\u9669\uff0c\u5982\u9519\u8bef\u59ff\u52bf\u548c\u53d7\u4f24\u3002", "method": "\u53d1\u5e03\u5927\u578b\u591a\u7c7b\u522b\u89c6\u9891\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5f15\u5165\u4e09\u90e8\u5206\u65b0\u6307\u6807\u3002", "result": "\u589e\u5f3a\u667a\u80fd\u5bb6\u5ead\u5065\u8eab\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u6269\u5c55\u81f3\u5eb7\u590d\u548c\u7269\u7406\u6cbb\u7597\u7b49\u9886\u57df\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u63d0\u4f9b\u4e13\u5bb6\u7ea7\u8bca\u65ad\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5065\u8eab\u548c\u533b\u7597\u573a\u666f\u3002"}}
{"id": "2506.11014", "pdf": "https://arxiv.org/pdf/2506.11014", "abs": "https://arxiv.org/abs/2506.11014", "authors": ["Benedetta Donato", "Leonardo Mariani", "Daniela Micucci", "Oliviero Riganelli", "Marco Somaschini"], "title": "MultiMind: A Plug-in for the Implementation of Development Tasks Aided by AI Assistants", "categories": ["cs.SE"], "comment": null, "summary": "The integration of AI assistants into software development workflows is\nrapidly evolving, shifting from automation-assisted tasks to collaborative\ninteractions between developers and AI. Large Language Models (LLMs) have\ndemonstrated their effectiveness in several development activities, including\ncode completion, test case generation, and documentation production. However,\nembedding AI-assisted tasks within Integrated Development Environments (IDEs)\npresents significant challenges. It requires designing mechanisms to invoke AI\nassistants at the appropriate time, coordinate interactions with multiple\nassistants, process the generated outputs, and present feedback in a way that\nseamlessly integrates with the development workflow. To address these issues,\nwe introduce MultiMind, a Visual Studio Code plug-in that streamlines the\ncreation of AI-assisted development tasks. MultiMind provides a modular and\nextensible framework, enabling developers to cost-effectively implement and\nexperiment with new AI-powered interactions without the need for complex IDE\ncustomizations. MultiMind has been tested in two use cases: one for the\nautomatic generation of code comments and the other about the definition of\nAI-powered chat.", "AI": {"tldr": "MultiMind\u662f\u4e00\u4e2aVS Code\u63d2\u4ef6\uff0c\u65e8\u5728\u7b80\u5316AI\u8f85\u52a9\u5f00\u53d1\u4efb\u52a1\uff0c\u89e3\u51b3IDE\u4e2d\u5d4c\u5165AI\u52a9\u624b\u65f6\u7684\u6311\u6218\u3002", "motivation": "AI\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u4f46\u5728IDE\u4e2d\u5d4c\u5165AI\u52a9\u624b\u4ecd\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5982\u9002\u65f6\u8c03\u7528\u3001\u534f\u8c03\u4ea4\u4e92\u548c\u5904\u7406\u8f93\u51fa\u7b49\u3002", "method": "\u63d0\u51fa\u4e86MultiMind\u63d2\u4ef6\uff0c\u63d0\u4f9b\u4e00\u4e2a\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u4f4e\u6210\u672c\u5b9e\u73b0\u548c\u5b9e\u9a8c\u65b0\u7684AI\u4ea4\u4e92\u529f\u80fd\u3002", "result": "MultiMind\u5728\u4ee3\u7801\u6ce8\u91ca\u81ea\u52a8\u751f\u6210\u548cAI\u804a\u5929\u529f\u80fd\u4e24\u4e2a\u7528\u4f8b\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "MultiMind\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u7075\u6d3b\u7684AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u3002"}}
{"id": "2506.11827", "pdf": "https://arxiv.org/pdf/2506.11827", "abs": "https://arxiv.org/abs/2506.11827", "authors": ["Saitarun Nadipineni", "Chapa Sirithunge", "Yue Xie", "Fumiya Iida", "Thilina Dulantha Lalitharatne"], "title": "Auditory-Tactile Congruence for Synthesis of Adaptive Pain Expressions in RoboPatients", "categories": ["cs.RO", "cs.HC"], "comment": "17 pages, 9 figures, journal", "summary": "Misdiagnosis can lead to delayed treatments and harm. Robotic patients offer\na controlled way to train and evaluate clinicians in rare, subtle, or complex\ncases, reducing diagnostic errors. We present RoboPatient, a medical robotic\nsimulator aimed at multimodal pain synthesis based on haptic and auditory\nfeedback during palpation-based training scenarios. The robopatient functions\nas an adaptive intermediary, capable of synthesizing plausible pain expressions\nvocal and facial in response to tactile stimuli generated during palpation.\nUsing an abdominal phantom, robopatient captures and processes haptic input via\nan internal palpation-to-pain mapping model. To evaluate perceptual congruence\nbetween palpation and the corresponding auditory output, we conducted a study\ninvolving 7680 trials across 20 participants, where they evaluated pain\nintensity through sound. Results show that amplitude and pitch significantly\ninfluence agreement with the robot's pain expressions, irrespective of pain\nsounds. Stronger palpation forces elicited stronger agreement, aligning with\npsychophysical patterns. The study revealed two key dimensions: pitch and\namplitude are central to how people perceive pain sounds, with pitch being the\nmost influential cue. These acoustic features shape how well the sound matches\nthe applied force during palpation, impacting perceived realism. This approach\nlays the groundwork for high-fidelity robotic patients in clinical education\nand diagnostic simulation.", "AI": {"tldr": "RoboPatient\u662f\u4e00\u4e2a\u57fa\u4e8e\u89e6\u89c9\u548c\u542c\u89c9\u53cd\u9988\u7684\u533b\u7597\u673a\u5668\u4eba\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u57f9\u8bad\u4e34\u5e8a\u533b\u751f\u8bca\u65ad\u7f55\u89c1\u3001\u5fae\u5999\u6216\u590d\u6742\u7684\u75c5\u4f8b\uff0c\u4ee5\u51cf\u5c11\u8bef\u8bca\u3002\u7814\u7a76\u663e\u793a\uff0c\u58f0\u97f3\u7684\u632f\u5e45\u548c\u97f3\u9ad8\u663e\u8457\u5f71\u54cd\u5bf9\u75bc\u75db\u8868\u8fbe\u7684\u611f\u77e5\u3002", "motivation": "\u8bef\u8bca\u53ef\u80fd\u5bfc\u81f4\u5ef6\u8bef\u6cbb\u7597\u548c\u4f24\u5bb3\u3002\u901a\u8fc7\u673a\u5668\u4eba\u60a3\u8005\u63d0\u4f9b\u53ef\u63a7\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u73af\u5883\uff0c\u51cf\u5c11\u8bca\u65ad\u9519\u8bef\u3002", "method": "\u5f00\u53d1RoboPatient\uff0c\u901a\u8fc7\u89e6\u89c9\u548c\u542c\u89c9\u53cd\u9988\u6a21\u62df\u75bc\u75db\u8868\u8fbe\uff0c\u5e76\u5bf97680\u6b21\u8bd5\u9a8c\u8fdb\u884c\u7814\u7a76\uff0c\u5206\u6790\u53c2\u4e0e\u8005\u5bf9\u75bc\u75db\u58f0\u97f3\u7684\u611f\u77e5\u3002", "result": "\u632f\u5e45\u548c\u97f3\u9ad8\u662f\u611f\u77e5\u75bc\u75db\u58f0\u97f3\u7684\u5173\u952e\u56e0\u7d20\uff0c\u97f3\u9ad8\u662f\u6700\u5177\u5f71\u54cd\u529b\u7684\u7ebf\u7d22\u3002\u66f4\u5f3a\u7684\u89e6\u538b\u529b\u5ea6\u5f15\u53d1\u66f4\u9ad8\u7684\u611f\u77e5\u4e00\u81f4\u6027\u3002", "conclusion": "\u8fd9\u4e00\u65b9\u6cd5\u4e3a\u4e34\u5e8a\u6559\u80b2\u548c\u8bca\u65ad\u6a21\u62df\u4e2d\u7684\u9ad8\u4fdd\u771f\u673a\u5668\u4eba\u60a3\u8005\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.11016", "pdf": "https://arxiv.org/pdf/2506.11016", "abs": "https://arxiv.org/abs/2506.11016", "authors": ["Lelanthran Manickum"], "title": "ZjsComponent: A Pragmatic Approach to Modular, Reusable UI Fragments for Web Development", "categories": ["cs.SE"], "comment": "12 pages, 7 figures", "summary": "In this paper, I present ZjsComponent, a lightweight and framework-agnostic\nweb component designed for creating modular, reusable UI elements with minimal\ndeveloper overhead. ZjsComponent is an example implementation of an approach to\ncreating components and object instances that can be used purely from HTML.\nUnlike traditional approaches to components, the approach implemented by\nZjsComponent does not require build-steps, transpiling, pre-compilation, any\nspecific ecosystem or any other dependency. All that is required is that the\nbrowser can load and execute Javascript as needed by Web Components.\nZjsComponent allows dynamic loading and isolation of HTML+JS fragments,\noffering developers a simple way to build reusable interfaces with ease. This\napproach is dependency-free, provides significant DOM and code isolation, and\nsupports simple lifecycle hooks as well as traditional methods expected of an\ninstance of a class.", "AI": {"tldr": "ZjsComponent\u662f\u4e00\u4e2a\u8f7b\u91cf\u3001\u6846\u67b6\u65e0\u5173\u7684Web\u7ec4\u4ef6\uff0c\u7528\u4e8e\u521b\u5efa\u6a21\u5757\u5316\u548c\u53ef\u91cd\u7528\u7684UI\u5143\u7d20\uff0c\u65e0\u9700\u6784\u5efa\u6b65\u9aa4\u6216\u4f9d\u8d56\u9879\u3002", "motivation": "\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u7b80\u5355\u3001\u65e0\u4f9d\u8d56\u7684\u65b9\u6cd5\u6765\u521b\u5efa\u548c\u590d\u7528Web\u7ec4\u4ef6\uff0c\u51cf\u5c11\u5f00\u53d1\u8005\u7684\u8d1f\u62c5\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u52a0\u8f7d\u548c\u9694\u79bbHTML+JS\u7247\u6bb5\uff0cZjsComponent\u5b9e\u73b0\u4e86\u65e0\u6784\u5efa\u6b65\u9aa4\u3001\u65e0\u9884\u7f16\u8bd1\u7684\u7ec4\u4ef6\u5f00\u53d1\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u3001\u72ec\u7acb\u7684\u7ec4\u4ef6\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u4ee3\u7801\u9694\u79bb\u548c\u751f\u547d\u5468\u671f\u94a9\u5b50\u3002", "conclusion": "ZjsComponent\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7b80\u5355\u7684Web\u7ec4\u4ef6\u5f00\u53d1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u65e0\u9700\u590d\u6742\u5de5\u5177\u7684\u8f7b\u91cf\u7ea7\u573a\u666f\u3002"}}
{"id": "2506.11829", "pdf": "https://arxiv.org/pdf/2506.11829", "abs": "https://arxiv.org/abs/2506.11829", "authors": ["Ana M\u00fcller", "Anja Richert"], "title": "The Space Between Us: A Methodological Framework for Researching Bonding and Proxemics in Situated Group-Agent Interactions", "categories": ["cs.RO", "cs.HC", "stat.ME"], "comment": "Accepted for presentation at the Workshop on Advancing Group\n  Understanding and Robots' Adaptive Behavior (GROUND), held at the Intelligent\n  Autonomous Systems (IAS) Conference 2025, Genoa, Italy", "summary": "This paper introduces a multimethod framework for studying spatial and social\ndynamics in real-world group-agent interactions with socially interactive\nagents. Drawing on proxemics and bonding theories, the method combines\nsubjective self-reports and objective spatial tracking. Applied in two field\nstudies in a museum (N = 187) with a robot and a virtual agent, the paper\naddresses the challenges in aligning human perception and behavior. We focus on\npresenting an open source, scalable, and field-tested toolkit for future\nstudies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u65b9\u6cd5\u6846\u67b6\uff0c\u7ed3\u5408\u5fc3\u7406\u8ddd\u79bb\u548c\u793e\u4ea4\u7ed1\u5b9a\u7406\u8bba\uff0c\u7814\u7a76\u771f\u5b9e\u4e16\u754c\u4e2d\u4eba\u4e0e\u667a\u80fd\u4f53\u7684\u7a7a\u95f4\u548c\u793e\u4ea4\u52a8\u6001\u3002", "motivation": "\u89e3\u51b3\u4eba\u4e0e\u667a\u80fd\u4f53\u4e92\u52a8\u4e2d\u611f\u77e5\u4e0e\u884c\u4e3a\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u4e3b\u89c2\u81ea\u6211\u62a5\u544a\u548c\u5ba2\u89c2\u7a7a\u95f4\u8ffd\u8e2a\uff0c\u5728\u535a\u7269\u9986\u7684\u4e24\u4e2a\u73b0\u573a\u7814\u7a76\u4e2d\u6d4b\u8bd5\u673a\u5668\u4eba\u53ca\u865a\u62df\u667a\u80fd\u4f53\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u6e90\u3001\u53ef\u6269\u5c55\u4e14\u7ecf\u8fc7\u73b0\u573a\u6d4b\u8bd5\u7684\u5de5\u5177\u5305\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u63a2\u7d22\u4eba\u673a\u4e92\u52a8\u4e2d\u7684\u7a7a\u95f4\u4e0e\u793e\u4ea4\u52a8\u6001\u3002"}}
{"id": "2506.11018", "pdf": "https://arxiv.org/pdf/2506.11018", "abs": "https://arxiv.org/abs/2506.11018", "authors": ["Grigory Tsiperman"], "title": "Formation of requirements traceability in the process of information systems design", "categories": ["cs.SE"], "comment": "12 pages, 4 figures, 2025 the 8th International Conference on\n  Information Management", "summary": "The traceability of requirements in the information system design process is\nconsidered an essential property of the project, one of its quality\ncharacteristics. The point here is that traceability provides the methods of\nvalidation and verification of software systems, and that the system model\nbased on requirements traceability reduces the system's dependence on\ndevelopers and, in general, makes it as straightforward as possible. One of the\nchallenges of the traceability process, dubbed \"The grand challenge of\ntraceability\" among traceability researchers, is its integration into the\ndesign process. In this paper, to achieve this goal, we propose the application\nof the Adaptive Clustering Method (ACM) of Information Systems developed by the\nauthor, which is based on the idea of a seamless system architecture that\nprovides explicit interconnection of project artifacts of different levels of\nabstraction.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u9700\u6c42\u8ddf\u8e2a\u5728\u4fe1\u606f\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u81ea\u9002\u5e94\u805a\u7c7b\u65b9\u6cd5\uff08ACM\uff09\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5b9e\u73b0\u9700\u6c42\u8ddf\u8e2a\u4e0e\u8bbe\u8ba1\u8fc7\u7a0b\u7684\u65e0\u7f1d\u96c6\u6210\u3002", "motivation": "\u9700\u6c42\u8ddf\u8e2a\u662f\u4fe1\u606f\u7cfb\u7edf\u8bbe\u8ba1\u7684\u5173\u952e\u8d28\u91cf\u7279\u6027\uff0c\u4f46\u5982\u4f55\u5c06\u5176\u65e0\u7f1d\u96c6\u6210\u5230\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u91c7\u7528\u4f5c\u8005\u5f00\u53d1\u7684\u81ea\u9002\u5e94\u805a\u7c7b\u65b9\u6cd5\uff08ACM\uff09\uff0c\u901a\u8fc7\u65e0\u7f1d\u7cfb\u7edf\u67b6\u6784\u5b9e\u73b0\u4e0d\u540c\u62bd\u8c61\u7ea7\u522b\u9879\u76ee\u5de5\u4ef6\u7684\u663e\u5f0f\u4e92\u8054\u3002", "result": "ACM\u65b9\u6cd5\u80fd\u591f\u663e\u5f0f\u8fde\u63a5\u9879\u76ee\u5de5\u4ef6\uff0c\u4ece\u800c\u7b80\u5316\u7cfb\u7edf\u9a8c\u8bc1\u4e0e\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u5e76\u51cf\u5c11\u5bf9\u5f00\u53d1\u4eba\u5458\u7684\u4f9d\u8d56\u3002", "conclusion": "ACM\u65b9\u6cd5\u4e3a\u9700\u6c42\u8ddf\u8e2a\u4e0e\u8bbe\u8ba1\u8fc7\u7a0b\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2506.11932", "pdf": "https://arxiv.org/pdf/2506.11932", "abs": "https://arxiv.org/abs/2506.11932", "authors": ["Nishan Gunawardena", "Gough Yumu Lui", "Jeewani Anupama Ginige", "Bahman Javadi"], "title": "Evaluating Sensitivity Parameters in Smartphone-Based Gaze Estimation: A Comparative Study of Appearance-Based and Infrared Eye Trackers", "categories": ["cs.CV", "cs.HC"], "comment": null, "summary": "This study evaluates a smartphone-based, deep-learning eye-tracking algorithm\nby comparing its performance against a commercial infrared-based eye tracker,\nthe Tobii Pro Nano. The aim is to investigate the feasibility of\nappearance-based gaze estimation under realistic mobile usage conditions. Key\nsensitivity factors, including age, gender, vision correction, lighting\nconditions, device type, and head position, were systematically analysed. The\nappearance-based algorithm integrates a lightweight convolutional neural\nnetwork (MobileNet-V3) with a recurrent structure (Long Short-Term Memory) to\npredict gaze coordinates from grayscale facial images. Gaze data were collected\nfrom 51 participants using dynamic visual stimuli, and accuracy was measured\nusing Euclidean distance. The deep learning model produced a mean error of\n17.76 mm, compared to 16.53 mm for the Tobii Pro Nano. While overall accuracy\ndifferences were small, the deep learning-based method was more sensitive to\nfactors such as lighting, vision correction, and age, with higher failure rates\nobserved under low-light conditions among participants using glasses and in\nolder age groups. Device-specific and positional factors also influenced\ntracking performance. These results highlight the potential of appearance-based\napproaches for mobile eye tracking and offer a reference framework for\nevaluating gaze estimation systems across varied usage conditions.", "AI": {"tldr": "\u6bd4\u8f83\u667a\u80fd\u624b\u673a\u6df1\u5ea6\u5b66\u4e60\u773c\u52a8\u7b97\u6cd5\u4e0e\u5546\u7528\u7ea2\u5916\u773c\u52a8\u4eea\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u663e\u793a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u591a\u79cd\u6761\u4ef6\u4e0b\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5bf9\u5149\u7167\u3001\u5e74\u9f84\u548c\u89c6\u529b\u77eb\u6b63\u66f4\u654f\u611f\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8e\u5916\u89c2\u7684\u89c6\u7ebf\u4f30\u8ba1\u5728\u79fb\u52a8\u8bbe\u5907\u4f7f\u7528\u6761\u4ef6\u4e0b\u7684\u53ef\u884c\u6027\u3002", "method": "\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08MobileNet-V3\uff09\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u4ece\u7070\u5ea6\u9762\u90e8\u56fe\u50cf\u9884\u6d4b\u89c6\u7ebf\u5750\u6807\uff0c\u5e76\u4e0e\u5546\u7528\u8bbe\u5907Tobii Pro Nano\u5bf9\u6bd4\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5747\u8bef\u5dee17.76 mm\uff0c\u7565\u9ad8\u4e8eTobii\u768416.53 mm\uff0c\u4f46\u5bf9\u5149\u7167\u3001\u89c6\u529b\u77eb\u6b63\u548c\u5e74\u9f84\u66f4\u654f\u611f\u3002", "conclusion": "\u5916\u89c2\u57fa\u65b9\u6cd5\u5728\u79fb\u52a8\u773c\u52a8\u8ffd\u8e2a\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u9488\u5bf9\u4e0d\u540c\u4f7f\u7528\u6761\u4ef6\u4f18\u5316\u3002"}}
{"id": "2506.11019", "pdf": "https://arxiv.org/pdf/2506.11019", "abs": "https://arxiv.org/abs/2506.11019", "authors": ["Vincent Koc", "Jacques Verre", "Douglas Blank", "Abigail Morgan"], "title": "Mind the Metrics: Patterns for Telemetry-Aware In-IDE AI Application Development using the Model Context Protocol (MCP)", "categories": ["cs.SE", "68T01, 68N30", "I.2.6; D.2.7"], "comment": "16 pages, 5 figures, conference preprint submission. Conceptual\n  systems architecture paper on telemetry-driven prompt optimization and IDE\n  design patterns for AI development. Builds on Opik MCP open-source\n  architecture and Comet trace infrastructure", "summary": "AI development environments are evolving into observability first platforms\nthat integrate real time telemetry, prompt traces, and evaluation feedback into\nthe developer workflow. This paper introduces telemetry aware integrated\ndevelopment environments (IDEs) enabled by the Model Context Protocol (MCP), a\nsystem that connects IDEs with prompt metrics, trace logs, and versioned\ncontrol for real time refinement. We present design patterns for local prompt\niteration, CI based optimization, and autonomous agents that adapt behavior\nusing telemetry. Rather than focusing on a single algorithm, we describe an\narchitecture that supports integration with frameworks like DSPy, PromptWizard,\nand Prompts as Programs. We demonstrate this through Opik, an open source MCP\nserver for LLM telemetry, and position our approach within the emerging LLMOps\necosystem. This work lays a foundation for future research on prompt\noptimization, IDE agent tooling, and empirical benchmarking in telemetry rich\nAI development workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684\u9065\u6d4b\u611f\u77e5\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDEs\uff09\uff0c\u652f\u6301\u5b9e\u65f6\u4f18\u5316\u548c\u96c6\u6210\u591a\u79cd\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5f00\u6e90MCP\u670d\u52a1\u5668Opik\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u63d0\u793a\u4f18\u5316\u548cLLMOps\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "AI\u5f00\u53d1\u73af\u5883\u6b63\u671d\u7740\u4ee5\u53ef\u89c2\u5bdf\u6027\u4e3a\u9996\u7684\u5e73\u53f0\u53d1\u5c55\uff0c\u9700\u8981\u6574\u5408\u5b9e\u65f6\u9065\u6d4b\u3001\u63d0\u793a\u8ffd\u8e2a\u548c\u8bc4\u4f30\u53cd\u9988\u4ee5\u4f18\u5316\u5f00\u53d1\u6d41\u7a0b\u3002", "method": "\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u8fde\u63a5IDEs\u4e0e\u63d0\u793a\u6307\u6807\u3001\u8ffd\u8e2a\u65e5\u5fd7\u548c\u7248\u672c\u63a7\u5236\uff0c\u63d0\u51fa\u672c\u5730\u63d0\u793a\u8fed\u4ee3\u3001\u57fa\u4e8eCI\u7684\u4f18\u5316\u548c\u81ea\u9002\u5e94\u4ee3\u7406\u7684\u8bbe\u8ba1\u6a21\u5f0f\u3002", "result": "\u5c55\u793a\u4e86\u5f00\u6e90MCP\u670d\u52a1\u5668Opik\uff0c\u5e76\u9a8c\u8bc1\u4e86\u67b6\u6784\u4e0e\u591a\u79cd\u6846\u67b6\u7684\u96c6\u6210\u80fd\u529b\uff0c\u4e3aLLMOps\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u672a\u6765\u63d0\u793a\u4f18\u5316\u3001IDE\u4ee3\u7406\u5de5\u5177\u548c\u9065\u6d4b\u4e30\u5bcc\u7684AI\u5f00\u53d1\u6d41\u7a0b\u7684\u5b9e\u8bc1\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.12008", "pdf": "https://arxiv.org/pdf/2506.12008", "abs": "https://arxiv.org/abs/2506.12008", "authors": ["Olga Vechtomova", "Jeff Bos"], "title": "Reimagining Dance: Real-time Music Co-creation between Dancers and AI", "categories": ["cs.SD", "cs.AI", "cs.HC", "eess.AS"], "comment": "Accepted for publication at ICCC 2025 (International Conference on\n  Computational Creativity)", "summary": "Dance performance traditionally follows a unidirectional relationship where\nmovement responds to music. While AI has advanced in various creative domains,\nits application in dance has primarily focused on generating choreography from\nmusical input. We present a system that enables dancers to dynamically shape\nmusical environments through their movements. Our multi-modal architecture\ncreates a coherent musical composition by intelligently combining pre-recorded\nmusical clips in response to dance movements, establishing a bidirectional\ncreative partnership where dancers function as both performers and composers.\nThrough correlation analysis of performance data, we demonstrate emergent\ncommunication patterns between movement qualities and audio features. This\napproach reconceptualizes the role of AI in performing arts as a responsive\ncollaborator that expands possibilities for both professional dance performance\nand improvisational artistic expression across broader populations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u6a21\u6001\u7cfb\u7edf\uff0c\u8ba9\u821e\u8005\u901a\u8fc7\u52a8\u4f5c\u52a8\u6001\u5851\u9020\u97f3\u4e50\u73af\u5883\uff0c\u5b9e\u73b0\u821e\u8e48\u4e0e\u97f3\u4e50\u7684\u53cc\u5411\u4e92\u52a8\u3002", "motivation": "\u4f20\u7edf\u821e\u8e48\u8868\u6f14\u4e2d\u52a8\u4f5c\u5355\u5411\u54cd\u5e94\u97f3\u4e50\uff0c\u7f3a\u4e4f\u53cc\u5411\u4e92\u52a8\uff0c\u5e0c\u671b\u5229\u7528AI\u6269\u5c55\u821e\u8e48\u4e0e\u97f3\u4e50\u7684\u521b\u9020\u6027\u5408\u4f5c\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u67b6\u6784\uff0c\u901a\u8fc7\u821e\u8005\u52a8\u4f5c\u667a\u80fd\u7ec4\u5408\u9884\u5f55\u97f3\u4e50\u7247\u6bb5\uff0c\u5f62\u6210\u8fde\u8d2f\u7684\u97f3\u4e50\u521b\u4f5c\u3002", "result": "\u901a\u8fc7\u6027\u80fd\u6570\u636e\u5206\u6790\uff0c\u5c55\u793a\u4e86\u52a8\u4f5c\u7279\u6027\u4e0e\u97f3\u9891\u7279\u5f81\u4e4b\u95f4\u7684\u65b0\u5174\u901a\u4fe1\u6a21\u5f0f\u3002", "conclusion": "AI\u53ef\u4f5c\u4e3a\u54cd\u5e94\u6027\u5408\u4f5c\u8005\uff0c\u91cd\u65b0\u5b9a\u4e49\u5176\u5728\u8868\u6f14\u827a\u672f\u4e2d\u7684\u89d2\u8272\uff0c\u6269\u5c55\u821e\u8e48\u8868\u6f14\u548c\u5373\u5174\u827a\u672f\u8868\u8fbe\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.11020", "pdf": "https://arxiv.org/pdf/2506.11020", "abs": "https://arxiv.org/abs/2506.11020", "authors": ["Thayn\u00e1 Camargo da Silva"], "title": "Extracting Knowledge Graphs from User Stories using LangChain", "categories": ["cs.SE", "cs.AI"], "comment": "Master thesis work", "summary": "This thesis introduces a novel methodology for the automated generation of\nknowledge graphs from user stories by leveraging the advanced capabilities of\nLarge Language Models. Utilizing the LangChain framework as a basis, the User\nStory Graph Transformer module was developed to extract nodes and relationships\nfrom user stories using an LLM to construct accurate knowledge graphs.This\ninnovative technique was implemented in a script to fully automate the\nknowledge graph extraction process. Additionally, the evaluation was automated\nthrough a dedicated evaluation script, utilizing an annotated dataset for\nassessment. By enhancing the visualization and understanding of user\nrequirements and domain concepts, this method fosters better alignment between\nsoftware functionalities and user expectations, ultimately contributing to more\neffective and user-centric software development processes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7528\u6237\u6545\u4e8b\u81ea\u52a8\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7LangChain\u6846\u67b6\u5f00\u53d1\u6a21\u5757\uff0c\u5b9e\u73b0\u5168\u81ea\u52a8\u63d0\u53d6\u548c\u8bc4\u4f30\u3002", "motivation": "\u63d0\u5347\u7528\u6237\u9700\u6c42\u548c\u9886\u57df\u6982\u5ff5\u7684\u53ef\u89c6\u5316\u4e0e\u7406\u89e3\uff0c\u4ee5\u66f4\u597d\u5730\u5bf9\u9f50\u8f6f\u4ef6\u529f\u80fd\u548c\u7528\u6237\u671f\u671b\u3002", "method": "\u5229\u7528LangChain\u6846\u67b6\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1User Story Graph Transformer\u6a21\u5757\uff0c\u81ea\u52a8\u5316\u63d0\u53d6\u77e5\u8bc6\u56fe\u8c31\u8282\u70b9\u548c\u5173\u7cfb\u3002", "result": "\u5b9e\u73b0\u4e86\u5168\u81ea\u52a8\u7684\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u548c\u8bc4\u4f30\uff0c\u589e\u5f3a\u4e86\u8f6f\u4ef6\u5f00\u53d1\u7684\u7528\u6237\u4e2d\u5fc3\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6539\u8fdb\u4e86\u8f6f\u4ef6\u529f\u80fd\u4e0e\u7528\u6237\u671f\u671b\u7684\u5bf9\u9f50\uff0c\u4fc3\u8fdb\u66f4\u9ad8\u6548\u7684\u7528\u6237\u4e2d\u5fc3\u5f00\u53d1\u6d41\u7a0b\u3002"}}
{"id": "2506.11021", "pdf": "https://arxiv.org/pdf/2506.11021", "abs": "https://arxiv.org/abs/2506.11021", "authors": ["Chaitanya Ravuri", "Saman Amarasinghe"], "title": "Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering", "categories": ["cs.SE", "cs.AI"], "comment": "9 pages, 1 figure", "summary": "Modern code-generation LLMs can already solve a large fraction of programming\nproblems, yet they still hallucinate subtle bugs that make their outputs unsafe\nfor autonomous deployment. We present functional clustering, a black-box\nwrapper that eliminates nearly all hallucination-induced errors while providing\na tunable confidence score. The wrapper samples many candidate programs,\nexecutes each on a self-generated test suite, and clusters candidates whose I/O\nbehavior is identical; the empirical mass of the largest cluster serves as an\nexact confidence estimate. A single scalar threshold on this estimate lets\nusers trade coverage for reliability with exponential guarantees. On\nLiveCodeBench our verifier preserves baseline pass@1 on solvable tasks yet\nslashes the error rate of returned answers from ~65% to 2%, and drives it to 0%\nat a conservative threshold while still answering 15.6% of prompts. Manual\naudits show that the few residual mistakes stem from prompt misinterpretation,\nnot random generation noise, narrowing future work to specification clarity.\nBecause the method requires only sampling and sandbox execution, it applies\nunchanged to closed-source APIs and future models, offering a practical path\ntoward dependable, autonomous code generation. Our code is available on Github\n(https://github.com/20ChaituR/functional-clustering).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u529f\u80fd\u6027\u805a\u7c7b\u7684\u9ed1\u76d2\u5305\u88c5\u5668\uff0c\u6709\u6548\u51cf\u5c11LLM\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u5e7b\u89c9\u9519\u8bef\uff0c\u5e76\u63d0\u4f9b\u53ef\u8c03\u7f6e\u4fe1\u5ea6\u3002\u65b9\u6cd5\u901a\u8fc7\u91c7\u6837\u3001\u6d4b\u8bd5\u548c\u805a\u7c7b\u5019\u9009\u7a0b\u5e8f\uff0c\u663e\u8457\u964d\u4f4e\u9519\u8bef\u7387\u3002", "motivation": "\u867d\u7136\u73b0\u4ee3\u4ee3\u7801\u751f\u6210LLM\u80fd\u89e3\u51b3\u8bb8\u591a\u7f16\u7a0b\u95ee\u9898\uff0c\u4f46\u4ecd\u6709\u5e7b\u89c9\u5bfc\u81f4\u7684\u7ec6\u5fae\u9519\u8bef\uff0c\u5f71\u54cd\u4ee3\u7801\u7684\u81ea\u4e3b\u90e8\u7f72\u5b89\u5168\u6027\u3002", "method": "\u901a\u8fc7\u91c7\u6837\u591a\u4e2a\u5019\u9009\u7a0b\u5e8f\uff0c\u8fd0\u884c\u81ea\u751f\u6210\u6d4b\u8bd5\u5957\u4ef6\uff0c\u805a\u7c7bI/O\u884c\u4e3a\u76f8\u540c\u7684\u5019\u9009\u7a0b\u5e8f\uff0c\u5229\u7528\u6700\u5927\u805a\u7c7b\u7684\u7ecf\u9a8c\u8d28\u91cf\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728LiveCodeBench\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4fdd\u6301\u57fa\u7ebf\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5c06\u9519\u8bef\u7387\u4ece65%\u964d\u81f32%\uff0c\u4fdd\u5b88\u9608\u503c\u4e0b\u53ef\u964d\u81f30%\u3002", "conclusion": "\u529f\u80fd\u6027\u805a\u7c7b\u662f\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u95ed\u6e90API\u548c\u672a\u6765\u6a21\u578b\uff0c\u4e3a\u81ea\u4e3b\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u9760\u8def\u5f84\u3002"}}
{"id": "2506.11022", "pdf": "https://arxiv.org/pdf/2506.11022", "abs": "https://arxiv.org/abs/2506.11022", "authors": ["Shivani Shukla", "Himanshu Joshi", "Romilla Syed"], "title": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": "Keywords - Large Language Models, Security Vulnerabilities,\n  AI-Generated Code, Iterative Feedback, Software Security, Secure Coding\n  Practices, Feedback Loops, LLM Prompting Strategies", "summary": "The rapid adoption of Large Language Models(LLMs) for code generation has\ntransformed software development, yet little attention has been given to how\nsecurity vulnerabilities evolve through iterative LLM feedback. This paper\nanalyzes security degradation in AI-generated code through a controlled\nexperiment with 400 code samples across 40 rounds of \"improvements\" using four\ndistinct prompting strategies. Our findings show a 37.6% increase in critical\nvulnerabilities after just five iterations, with distinct vulnerability\npatterns emerging across different prompting approaches. This evidence\nchallenges the assumption that iterative LLM refinement improves code security\nand highlights the essential role of human expertise in the loop. We propose\npractical guidelines for developers to mitigate these risks, emphasizing the\nneed for robust human validation between LLM iterations to prevent the\nparadoxical introduction of new security issues during supposedly beneficial\ncode \"improvements\".", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u901a\u8fc7LLM\u8fed\u4ee3\u53cd\u9988\u751f\u6210\u7684\u4ee3\u7801\u4e2d\u5b89\u5168\u6f0f\u6d1e\u663e\u8457\u589e\u52a0\uff0c\u6311\u6218\u4e86\u8fed\u4ee3\u6539\u8fdb\u80fd\u63d0\u5347\u4ee3\u7801\u5b89\u5168\u6027\u7684\u5047\u8bbe\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2d\u8fed\u4ee3\u53cd\u9988\u5982\u4f55\u5bfc\u81f4\u5b89\u5168\u6f0f\u6d1e\u7684\u589e\u52a0\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u5206\u6790400\u4e2a\u4ee3\u7801\u6837\u672c\u572840\u8f6e\u201c\u6539\u8fdb\u201d\u4e2d\u4f7f\u7528\u56db\u79cd\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u5728\u4e94\u8f6e\u8fed\u4ee3\u540e\uff0c\u5173\u952e\u6f0f\u6d1e\u589e\u52a0\u4e8637.6%\uff0c\u4e14\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u5bfc\u81f4\u72ec\u7279\u6f0f\u6d1e\u6a21\u5f0f\u3002", "conclusion": "\u5f3a\u8c03\u4eba\u7c7b\u4e13\u5bb6\u5728\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u5f00\u53d1\u8005\u7684\u5b9e\u8df5\u6307\u5357\u4ee5\u51cf\u5c11\u98ce\u9669\u3002"}}
{"id": "2506.11051", "pdf": "https://arxiv.org/pdf/2506.11051", "abs": "https://arxiv.org/abs/2506.11051", "authors": ["Sung Une Lee", "Liming Dong", "Zhenchang Xing", "Muhammad Ejaz Ahmed", "Stefan Avgoustakis"], "title": "Software Security Mapping Framework: Operationalization of Security Requirements", "categories": ["cs.SE"], "comment": "28 pages, 13 figures, 6 tables", "summary": "The escalating complexity of modern software development environments has\nheightened concerns around supply chain security. However, existing frameworks\noften fall short in translating abstract security principles into concrete,\nactionable practices. This paper introduces the Software Security Mapping\nFramework, a structured solution designed to operationalize security\nrequirements across hierarchical levels -- from high-level regulatory standards\n(e.g., ISM, Australia cybersecurity standard published by the Australian\nSignals Directorate), through mid-level frameworks (e.g., NIST SSDF, the U.S.\nSecure Software Development Framework), to fine-grained technical activities\n(e.g., SLSA, a software supply chain security framework). Developed through\ncollaborative research with academic experts and industry practitioners, the\nframework systematically maps 131 refined security requirements to over 400\nactionable operational steps spanning the software development lifecycle. It is\ngrounded in four core security goals: Secure Software Environment, Secure\nSoftware Development, Software Traceability, and Vulnerability Management. Our\napproach leverages the KAOS goal modeling methodology to establish traceable\nlinkages between strategic goals and tactical operations, enhancing clarity,\naccountability, and practical implementation. To facilitate adoption, we\nprovide a web-based navigation tool for interactive exploration of the\nframework. A real-world case study based on the Log4j vulnerability illustrates\nthe framework's utility by generating a tailored checklist aligned with\nindustry best practices. Additionally, we offer a structured, machine-readable\nOSCAL Catalog Model of the Software Security Mapping Framework, enabling\norganizations to automate implementation, streamline compliance processes, and\nrespond effectively to evolving security risks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f6f\u4ef6\u5b89\u5168\u6620\u5c04\u6846\u67b6\uff0c\u5c06\u62bd\u8c61\u7684\u5b89\u5168\u539f\u5219\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u64cd\u4f5c\u6b65\u9aa4\uff0c\u8986\u76d6\u4ece\u76d1\u7ba1\u6807\u51c6\u5230\u6280\u672f\u6d3b\u52a8\u7684\u591a\u5c42\u6b21\u9700\u6c42\uff0c\u5e76\u901a\u8fc7Log4j\u6f0f\u6d1e\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u73af\u5883\u7684\u590d\u6742\u6027\u589e\u52a0\u4e86\u4f9b\u5e94\u94fe\u5b89\u5168\u7684\u98ce\u9669\uff0c\u73b0\u6709\u6846\u67b6\u96be\u4ee5\u5c06\u62bd\u8c61\u5b89\u5168\u539f\u5219\u8f6c\u5316\u4e3a\u5177\u4f53\u5b9e\u8df5\uff0c\u4e9f\u9700\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u7ed3\u5408KAOS\u76ee\u6807\u5efa\u6a21\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u5c42\u6620\u5c04\u6846\u67b6\uff0c\u5305\u542b131\u9879\u5b89\u5168\u9700\u6c42\u548c400\u591a\u4e2a\u64cd\u4f5c\u6b65\u9aa4\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8eWeb\u7684\u5bfc\u822a\u5de5\u5177\u548c\u673a\u5668\u53ef\u8bfb\u7684OSCAL\u6a21\u578b\u3002", "result": "\u6846\u67b6\u6210\u529f\u5c06\u5b89\u5168\u76ee\u6807\u4e0e\u64cd\u4f5c\u6b65\u9aa4\u5173\u8054\uff0c\u5e76\u901a\u8fc7Log4j\u6848\u4f8b\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u652f\u6301\u81ea\u52a8\u5316\u5b9e\u65bd\u548c\u5408\u89c4\u6d41\u7a0b\u7b80\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u4e00\u79cd\u6e05\u6670\u3001\u53ef\u64cd\u4f5c\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u4f9b\u5e94\u94fe\u5b89\u5168\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u5de5\u5177\u652f\u6301\u4fc3\u8fdb\u4e86\u5e7f\u6cdb\u91c7\u7528\u3002"}}
{"id": "2506.11058", "pdf": "https://arxiv.org/pdf/2506.11058", "abs": "https://arxiv.org/abs/2506.11058", "authors": ["Ziga Kovacic", "Celine Lee", "Justin Chiu", "Wenting Zhao", "Kevin Ellis"], "title": "Refactoring Codebases through Library Design", "categories": ["cs.SE", "cs.AI"], "comment": "26 pages", "summary": "Maintainable and general software allows developers to build robust\napplications efficiently, yet achieving these qualities often requires\nrefactoring specialized solutions into reusable components. This challenge\nbecomes particularly relevant as code agents become increasingly accurate at\nsolving isolated programming problems. We investigate code agents' capacity to\nrefactor code in ways supporting growth and reusability. We present both a\nmethod and a benchmark for refactoring: Librarian, a sample-and-rerank method\nfor generating reusable libraries, and Minicode, a benchmark where code agents\nmust minimize and refactor multiple independent solutions into a joint library.\nCompared to state-of-the-art code agents, Librarian achieves strong results on\nboth compression and correctness on Minicode, obtaining compression rates\n1.6-2x better than coding agents while also improving correctness. We\nopen-source our code and benchmark at https://code-refactor.github.io/.", "AI": {"tldr": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLibrarian\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u91cd\u7528\u7684\u4ee3\u7801\u5e93\uff0c\u5e76\u521b\u5efa\u4e86Minicode\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u7684\u4ee3\u7801\u91cd\u6784\u80fd\u529b\u3002Librarian\u5728\u538b\u7f29\u7387\u548c\u6b63\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u4ee3\u7406\u5728\u89e3\u51b3\u72ec\u7acb\u7f16\u7a0b\u95ee\u9898\u4e0a\u7684\u51c6\u786e\u6027\u63d0\u9ad8\uff0c\u5982\u4f55\u901a\u8fc7\u91cd\u6784\u652f\u6301\u4ee3\u7801\u7684\u589e\u957f\u548c\u53ef\u91cd\u7528\u6027\u6210\u4e3a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Librarian\u65b9\u6cd5\uff08\u4e00\u79cd\u62bd\u6837-\u91cd\u65b0\u6392\u5e8f\u6280\u672f\uff09\u548cMinicode\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u7684\u91cd\u6784\u80fd\u529b\u3002", "result": "Librarian\u5728\u538b\u7f29\u7387\u548c\u6b63\u786e\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u4ee3\u7801\u4ee3\u7406\uff0c\u538b\u7f29\u7387\u63d0\u9ad8\u4e861.6-2\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ca\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u4ee3\u7801\u91cd\u6784\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u652f\u6301\u4ee3\u7801\u7684\u53ef\u91cd\u7528\u6027\u548c\u7ef4\u62a4\u6027\u3002"}}
{"id": "2506.11059", "pdf": "https://arxiv.org/pdf/2506.11059", "abs": "https://arxiv.org/abs/2506.11059", "authors": ["Hanxi Guo", "Siyuan Cheng", "Kaiyuan Zhang", "Guangyu Shen", "Xiangyu Zhang"], "title": "CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs", "categories": ["cs.SE", "cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have become integral to modern software\ndevelopment, producing vast amounts of AI-generated source code. While these\nmodels boost programming productivity, their misuse introduces critical risks,\nincluding code plagiarism, license violations, and the propagation of insecure\nprograms. As a result, robust detection of AI-generated code is essential. To\nsupport the development of such detectors, a comprehensive benchmark that\nreflects real-world conditions is crucial. However, existing benchmarks fall\nshort -- most cover only a limited set of programming languages and rely on\nless capable generative models. In this paper, we present CodeMirage, a\ncomprehensive benchmark that addresses these limitations through three major\nadvancements: (1) it spans ten widely used programming languages, (2) includes\nboth original and paraphrased code samples, and (3) incorporates outputs from\nten state-of-the-art production-level LLMs, including both reasoning and\nnon-reasoning models from six major providers. Using CodeMirage, we evaluate\nten representative detectors across four methodological paradigms under four\nrealistic evaluation configurations, reporting results using three\ncomplementary metrics. Our analysis reveals nine key findings that uncover the\nstrengths and weaknesses of current detectors, and identify critical challenges\nfor future work. We believe CodeMirage offers a rigorous and practical testbed\nto advance the development of robust and generalizable AI-generated code\ndetectors.", "AI": {"tldr": "CodeMirage\u662f\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u751f\u6210\u4ee3\u7801\u7684\u68c0\u6d4b\u5668\uff0c\u8986\u76d610\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c10\u79cd\u5148\u8fdbLLM\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u68c0\u6d4b\u5668\u7684\u4f18\u7f3a\u70b9\u3002", "motivation": "\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0cAI\u751f\u6210\u4ee3\u7801\u7684\u98ce\u9669\uff08\u5982\u6284\u88ad\u3001\u8bb8\u53ef\u8bc1\u8fdd\u89c4\u548c\u4e0d\u5b89\u5168\u7a0b\u5e8f\uff09\u65e5\u76ca\u51f8\u663e\uff0c\u9700\u8981\u6709\u6548\u7684\u68c0\u6d4b\u5668\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u8986\u76d6\u8303\u56f4\u6709\u9650\u4e14\u4f9d\u8d56\u8f83\u5f31\u751f\u6210\u6a21\u578b\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u63d0\u51faCodeMirage\u57fa\u51c6\uff0c\u5305\u62ec10\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u539f\u59cb\u548c\u6539\u5199\u4ee3\u7801\u6837\u672c\uff0c\u6574\u5408\u4e866\u5bb6\u63d0\u4f9b\u5546\u768410\u79cd\u5148\u8fdbLLM\u8f93\u51fa\u3002\u8bc4\u4f3010\u79cd\u68c0\u6d4b\u5668\uff0c\u91c7\u75284\u79cd\u65b9\u6cd5\u8303\u5f0f\u30014\u79cd\u914d\u7f6e\u548c3\u79cd\u6307\u6807\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e869\u4e2a\u5173\u952e\u53d1\u73b0\uff0c\u5c55\u793a\u5f53\u524d\u68c0\u6d4b\u5668\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u7684\u6311\u6218\u3002", "conclusion": "CodeMirage\u4e3a\u5f00\u53d1\u9c81\u68d2\u4e14\u901a\u7528\u7684AI\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u5668\u63d0\u4f9b\u4e86\u4e25\u683c\u5b9e\u7528\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2506.11060", "pdf": "https://arxiv.org/pdf/2506.11060", "abs": "https://arxiv.org/abs/2506.11060", "authors": ["Ramneet Singh", "Sathvik Joel", "Abhav Mehrotra", "Nalin Wadhwa", "Ramakrishna B Bairi", "Aditya Kanade", "Nagarajan Natarajan"], "title": "Code Researcher: Deep Research Agent for Large Systems Code and Commit History", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM)-based coding agents have shown promising results\non coding benchmarks, but their effectiveness on systems code remains\nunderexplored. Due to the size and complexities of systems code, making changes\nto a systems codebase is a daunting task, even for humans. It requires\nresearching about many pieces of context, derived from the large codebase and\nits massive commit history, before making changes. Inspired by the recent\nprogress on deep research agents, we design the first deep research agent for\ncode, called Code Researcher, and apply it to the problem of generating patches\nfor mitigating crashes reported in systems code. Code Researcher performs\nmulti-step reasoning about semantics, patterns, and commit history of code to\ngather sufficient context. The context is stored in a structured memory which\nis used for synthesizing a patch. We evaluate Code Researcher on kBenchSyz, a\nbenchmark of Linux kernel crashes, and show that it significantly outperforms\nstrong baselines, achieving a crash-resolution rate of 58%, compared to 37.5%\nby SWE-agent. On an average, Code Researcher explores 10 files in each\ntrajectory whereas SWE-agent explores only 1.33 files, highlighting Code\nResearcher's ability to deeply explore the codebase. Through another experiment\non an open-source multimedia software, we show the generalizability of Code\nResearcher. Our experiments highlight the importance of global context\ngathering and multi-faceted reasoning for large codebases.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8eLLM\u7684\u7f16\u7801\u4ee3\u7406\u5728\u7cfb\u7edf\u4ee3\u7801\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCode Researcher\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff0c\u7528\u4e8e\u4fee\u590d\u7cfb\u7edf\u4ee3\u7801\u4e2d\u7684\u5d29\u6e83\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1LLM\u4ee3\u7406\u5728\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u5728\u7cfb\u7edf\u4ee3\u7801\u4e2d\u7684\u5e94\u7528\u4ecd\u672a\u5145\u5206\u63a2\u7d22\u3002\u7cfb\u7edf\u4ee3\u7801\u7684\u89c4\u6a21\u548c\u590d\u6742\u6027\u4f7f\u5176\u4fee\u6539\u6210\u4e3a\u5de8\u5927\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3aCode Researcher\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff0c\u901a\u8fc7\u591a\u6b65\u9aa4\u63a8\u7406\u6536\u96c6\u4ee3\u7801\u7684\u8bed\u4e49\u3001\u6a21\u5f0f\u548c\u63d0\u4ea4\u5386\u53f2\u7b49\u4e0a\u4e0b\u6587\uff0c\u5e76\u5229\u7528\u7ed3\u6784\u5316\u8bb0\u5fc6\u5408\u6210\u8865\u4e01\u3002", "result": "\u5728Linux\u5185\u6838\u5d29\u6e83\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCode Researcher\u7684\u4fee\u590d\u7387\uff0858%\uff09\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0837.5%\uff09\uff0c\u4e14\u80fd\u6df1\u5ea6\u63a2\u7d22\u4ee3\u7801\u5e93\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5168\u5c40\u4e0a\u4e0b\u6587\u6536\u96c6\u548c\u591a\u9762\u63a8\u7406\u5bf9\u5927\u578b\u4ee3\u7801\u5e93\u81f3\u5173\u91cd\u8981\uff0cCode Researcher\u5c55\u793a\u4e86\u5728\u8be5\u9886\u57df\u7684\u4f18\u8d8a\u6027\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2506.11066", "pdf": "https://arxiv.org/pdf/2506.11066", "abs": "https://arxiv.org/abs/2506.11066", "authors": ["Jiahui Geng", "Fengyu Cai", "Shaobo Cui", "Qing Li", "Liangwei Chen", "Chenyang Lyu", "Haonan Li", "Derui Zhu", "Walter Pretschner", "Heinz Koeppl", "Fakhri Karray"], "title": "CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code retrieval is essential in modern software development, as it boosts code\nreuse and accelerates debugging. However, current benchmarks primarily\nemphasize functional relevance while neglecting critical dimensions of software\nquality. Motivated by this gap, we introduce CoQuIR, the first large-scale,\nmultilingual benchmark specifically designed to evaluate quality-aware code\nretrieval across four key dimensions: correctness, efficiency, security, and\nmaintainability. CoQuIR provides fine-grained quality annotations for 42,725\nqueries and 134,907 code snippets in 11 programming languages, and is\naccompanied by two quality-centric evaluation metrics: Pairwise Preference\nAccuracy and Margin-based Ranking Score. Using CoQuIR, we benchmark 23\nretrieval models, covering both open-source and proprietary systems, and find\nthat even top-performing models frequently fail to distinguish buggy or\ninsecure code from their more robust counterparts. Furthermore, we conduct\npreliminary investigations into training methods that explicitly encourage\nretrievers to recognize code quality. Using synthetic datasets, we demonstrate\npromising improvements in quality-aware metrics across various models, without\nsacrificing semantic relevance. Downstream code generation experiments further\nvalidate the effectiveness of our approach. Overall, our work highlights the\nimportance of integrating quality signals into code retrieval systems, laying\nthe groundwork for more trustworthy and robust software development tools.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CoQuIR\uff0c\u4e00\u4e2a\u591a\u8bed\u8a00\u3001\u8d28\u91cf\u611f\u77e5\u7684\u4ee3\u7801\u68c0\u7d22\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3001\u6548\u7387\u3001\u5b89\u5168\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7801\u68c0\u7d22\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u529f\u80fd\u76f8\u5173\u6027\uff0c\u5ffd\u7565\u4e86\u4ee3\u7801\u8d28\u91cf\u7684\u5173\u952e\u7ef4\u5ea6\u3002", "method": "\u5f15\u5165CoQuIR\u57fa\u51c6\uff0c\u5305\u542b42,725\u4e2a\u67e5\u8be2\u548c134,907\u4e2a\u4ee3\u7801\u7247\u6bb5\u7684\u8d28\u91cf\u6807\u6ce8\uff0c\u5e76\u4f7f\u7528\u4e24\u79cd\u8d28\u91cf\u4e2d\u5fc3\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u6d4b\u8bd5\u4e8623\u79cd\u68c0\u7d22\u6a21\u578b\uff0c\u53d1\u73b0\u5373\u4f7f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u4e5f\u96be\u4ee5\u533a\u5206\u6709\u7f3a\u9677\u6216\u4e0d\u5b89\u5168\u7684\u4ee3\u7801\u3002\u901a\u8fc7\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u8d28\u91cf\u611f\u77e5\u80fd\u529b\u800c\u4e0d\u727a\u7272\u8bed\u4e49\u76f8\u5173\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5c06\u8d28\u91cf\u4fe1\u53f7\u6574\u5408\u5230\u4ee3\u7801\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u66f4\u53ef\u4fe1\u548c\u9c81\u68d2\u7684\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.11076", "pdf": "https://arxiv.org/pdf/2506.11076", "abs": "https://arxiv.org/abs/2506.11076", "authors": ["Minyu Chen", "Guoqiang Li", "Ling-I Wu", "Ruibang Liu"], "title": "DCE-LLM: Dead Code Elimination with Large Language Models", "categories": ["cs.SE"], "comment": "Accepted by regular paper in NAACL 2025, with 13 pages, 5 figures", "summary": "Dead code introduces several challenges in software development, such as\nincreased binary size and maintenance difficulties. It can also obscure logical\nerrors and be exploited for obfuscation in malware. For LLM-based code-related\ntasks, dead code introduces vulnerabilities that can mislead these models,\nraising security concerns. Although modern compilers and IDEs offer dead code\nelimination, sophisticated patterns can bypass these tools. A universal\napproach that includes classification, location, explanation, and correction is\nneeded, yet current tools often require significant manual effort. We present\nDCE-LLM, a framework for automated dead code elimination using a small CodeBERT\nmodel with an attribution-based line selector to efficiently locate suspect\ncode. LLMs then generate judgments and explanations, fine-tuned on a\nlarge-scale, annotated dead code dataset to provide detailed explanations and\npatches. DCE-LLM outperforms existing tools, with advanced unreachability\ndetection, automated correction, and support for multiple programming\nlanguages. Experimental results show DCE-LLM achieves over 94% F1 scores for\nunused and unreachable code, significantly surpassing GPT-4o by 30%.", "AI": {"tldr": "DCE-LLM\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u6b7b\u4ee3\u7801\u6d88\u9664\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u4ee3\u7801\u5b9a\u4f4d\u548c\u4fee\u6b63\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u6b7b\u4ee3\u7801\u4f1a\u5e26\u6765\u4e8c\u8fdb\u5236\u5927\u5c0f\u3001\u7ef4\u62a4\u548c\u5b89\u5168\u6027\u95ee\u9898\uff0c\u73b0\u6709\u5de5\u5177\u96be\u4ee5\u5168\u9762\u89e3\u51b3\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6848\u3002", "method": "\u7ed3\u5408CodeBERT\u6a21\u578b\u548cLLM\uff0c\u901a\u8fc7\u6807\u6ce8\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4ee3\u7801\u5206\u7c7b\u3001\u5b9a\u4f4d\u3001\u89e3\u91ca\u548c\u4fee\u6b63\u3002", "result": "DCE-LLM\u7684F1\u5206\u6570\u8d85\u8fc794%\uff0c\u6bd4GPT-4o\u63d0\u9ad830%\uff0c\u652f\u6301\u591a\u8bed\u8a00\u3002", "conclusion": "DCE-LLM\u5728\u6b7b\u4ee3\u7801\u68c0\u6d4b\u548c\u4fee\u6b63\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u5f00\u53d1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.11084", "pdf": "https://arxiv.org/pdf/2506.11084", "abs": "https://arxiv.org/abs/2506.11084", "authors": ["Yordan Kalmukov"], "title": "Research and Analysis of Employers' Opinion on the Necessary Skills that Students in the Field of Web Programming Should Possess", "categories": ["cs.SE"], "comment": null, "summary": "In the era of artificial intelligence (AI) and chatbots, based on large\nlanguage models that can generate programming code in any language, write texts\nand summarize information, it is obvious that the requirements of employers for\ngraduating students have already changed. The modern IT world offers\nsignificant automation of programming through software frameworks and a huge\nset of third-party libraries and application programming interfaces (APIs). All\nthese tools provide most of the necessary functionality out of the box (already\nimplemented), and quite naturally the question arises as to what is more useful\nfor students - to teach how to use these ready-made tools or the basic\nprinciples of working and development of web applications from scratch. This\npaper analyzes the results of a survey conducted among IT employers, aimed to\nidentify what, in their opinion, are the necessary technical skills that\ngraduating students in the field of Web Programming should possess in order to\njoin the company's work as quickly and effectively as possible.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8AI\u65f6\u4ee3\u96c7\u4e3b\u5bf9\u6bd5\u4e1a\u751f\u7684\u6280\u80fd\u9700\u6c42\u53d8\u5316\uff0c\u91cd\u70b9\u5206\u6790\u5b66\u751f\u5e94\u5b66\u4e60\u4f7f\u7528\u73b0\u6210\u5de5\u5177\u8fd8\u662f\u638c\u63e1\u57fa\u7840\u5f00\u53d1\u539f\u5219\u3002", "motivation": "\u63a2\u8ba8\u73b0\u4ee3IT\u73af\u5883\u4e0b\u96c7\u4e3b\u5bf9\u6bd5\u4e1a\u751f\u6280\u80fd\u7684\u9700\u6c42\u53d8\u5316\uff0c\u4ee5\u786e\u5b9a\u6559\u80b2\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u95ee\u5377\u8c03\u67e5IT\u96c7\u4e3b\uff0c\u4e86\u89e3\u5176\u5bf9\u6bd5\u4e1a\u751f\u6280\u80fd\u7684\u9700\u6c42\u3002", "result": "\u96c7\u4e3b\u66f4\u770b\u91cd\u54ea\u4e9b\u6280\u80fd\uff0c\u4ee5\u5e2e\u52a9\u5b66\u751f\u5feb\u901f\u9002\u5e94\u5de5\u4f5c\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6559\u80b2\u8005\u63d0\u4f9b\u6307\u5bfc\uff0c\u5e2e\u52a9\u5b66\u751f\u638c\u63e1\u96c7\u4e3b\u6240\u9700\u7684\u5b9e\u7528\u6280\u80fd\u3002"}}
{"id": "2506.11107", "pdf": "https://arxiv.org/pdf/2506.11107", "abs": "https://arxiv.org/abs/2506.11107", "authors": ["Weibo Gao", "Qi Liu", "Rui Li", "Yuze Zhao", "Hao Wang", "Linan Yre", "Fangzhou Yao", "Zheng Zhang"], "title": "Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by KDD August 2025", "summary": "Programming Knowledge Tracking (PKT) aims to dynamically diagnose learners'\nmastery levels of programming knowledge based on their coding activities,\nfacilitating more effective and personalized programming education. However,\ncurrent PKT studies primarily focus on the implicit relationship between code\ncontent and knowledge assessment, often overlooking two types of noise signals\nin long-term programming activities: unwanted signals from unrelated\nsubmissions and weak signals from minor modifications. This practical challenge\nsignificantly limits model performance and application. To address this issue,\nwe propose Coda, a Code graph-based tuning adaptor designed to enhance existing\nPKT models by identifying and mitigating the impact of noise. Specifically,\nCoda first transforms the loose code sequences submitted by each learner into a\ncompact code graph. By leveraging this code graph, unwanted signals can be\nidentified from a semantic similarity perspective. We then apply a\ncluster-aware GCN to the code graph, which improves the discrimination of weak\nsignals and enables their clustering for identification. Finally, a lightweight\nyet effective adaptor is incorporated into the PKT task through optimization\nwith two noise feature-based constraints and a navigational regularization\nterm, to correct knowledge states affected by noise. It is worth mentioning\nthat the Coda framework is model-agnostic and can be adapted to most existing\nPKT solutions. Extensive experimental results on four real-world datasets\ndemonstrate that Coda effectively performs the PKT task in the presence of\nnoisy programming records, outperforming typical baselines.", "AI": {"tldr": "Coda\u901a\u8fc7\u5c06\u677e\u6563\u4ee3\u7801\u5e8f\u5217\u8f6c\u6362\u4e3a\u7d27\u51d1\u4ee3\u7801\u56fe\uff0c\u5e76\u5229\u7528\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u805a\u7c7b\u611f\u77e5GCN\u8bc6\u522b\u5e76\u51cf\u8f7b\u566a\u58f0\u5f71\u54cd\uff0c\u4ece\u800c\u63d0\u5347PKT\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524dPKT\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u5185\u5bb9\u4e0e\u77e5\u8bc6\u8bc4\u4f30\u7684\u9690\u5f0f\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u957f\u671f\u7f16\u7a0b\u6d3b\u52a8\u4e2d\u7684\u566a\u58f0\u4fe1\u53f7\uff08\u5982\u65e0\u5173\u63d0\u4ea4\u548c\u5fae\u5c0f\u4fee\u6539\uff09\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51faCoda\u6846\u67b6\uff0c\u5305\u62ec\u4ee3\u7801\u56fe\u8f6c\u6362\u3001\u566a\u58f0\u4fe1\u53f7\u8bc6\u522b\uff08\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\uff09\u3001\u5f31\u4fe1\u53f7\u805a\u7c7b\uff08\u4f7f\u7528GCN\uff09\u53ca\u8f7b\u91cf\u9002\u914d\u5668\u4f18\u5316\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cCoda\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u6709\u6548\u5904\u7406\u4e86\u566a\u58f0\u7f16\u7a0b\u8bb0\u5f55\u3002", "conclusion": "Coda\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u80fd\u63d0\u5347\u73b0\u6709PKT\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u566a\u58f0\u73af\u5883\u4e0b\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.11153", "pdf": "https://arxiv.org/pdf/2506.11153", "abs": "https://arxiv.org/abs/2506.11153", "authors": ["Changxin Ke", "Rui Zhang", "Shuo Wang", "Li Ding", "Guangli Li", "Yuanbo Wen", "Shuoming Zhang", "Ruiyuan Xu", "Jin Qin", "Jiaming Guo", "Chenxi Wang", "Ling Li", "Qi Guo", "Yunji Chen"], "title": "Mutual-Supervised Learning for Sequential-to-Parallel Code Translation", "categories": ["cs.SE", "cs.LG"], "comment": "28 pages", "summary": "The rise of GPU-based high-performance computing (HPC) has driven the\nwidespread adoption of parallel programming models such as CUDA. Yet, the\ninherent complexity of parallel programming creates a demand for the automated\nsequential-to-parallel approaches. However, data scarcity poses a significant\nchallenge for machine learning-based sequential-to-parallel code translation.\nAlthough recent back-translation methods show promise, they still fail to\nensure functional equivalence in the translated code. In this paper, we propose\na novel Mutual-Supervised Learning (MSL) framework for sequential-to-parallel\ncode translation to address the functional equivalence issue. MSL consists of\ntwo models, a Translator and a Tester. Through an iterative loop consisting of\nCo-verify and Co-evolve steps, the Translator and the Tester mutually generate\ndata for each other and improve collectively. The Tester generates unit tests\nto verify and filter functionally equivalent translated code, thereby evolving\nthe Translator, while the Translator generates translated code as augmented\ninput to evolve the Tester. Experimental results demonstrate that MuSL\nsignificantly enhances the performance of the base model: when applied to\nQwen2.5-Coder, it not only improves Pass@1 by up to 28.91% and boosts Tester\nperformance by 68.90%, but also outperforms the previous state-of-the-art\nmethod CodeRosetta by 1.56 and 6.92 in BLEU and CodeBLEU scores, while\nachieving performance comparable to DeepSeek-R1 and GPT-4.1. Our code is\navailable at https://github.com/kcxain/musl.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684Mutual-Supervised Learning\u6846\u67b6\uff08MSL\uff09\uff0c\u901a\u8fc7Translator\u548cTester\u7684\u534f\u540c\u9a8c\u8bc1\u548c\u8fdb\u5316\uff0c\u89e3\u51b3\u4e86\u5e8f\u5217\u4ee3\u7801\u5230\u5e76\u884c\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u529f\u80fd\u7b49\u4ef7\u6027\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u5e76\u884c\u7f16\u7a0b\u7684\u590d\u6742\u6027\u4ee5\u53ca\u6570\u636e\u7a00\u7f3a\u6027\u6311\u6218\uff0c\u73b0\u6709\u7684\u5e8f\u5217\u5230\u5e76\u884c\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\u96be\u4ee5\u4fdd\u8bc1\u529f\u80fd\u7b49\u4ef7\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "MSL\u6846\u67b6\u5305\u542bTranslator\u548cTester\u4e24\u4e2a\u6a21\u578b\uff0c\u901a\u8fc7\u8fed\u4ee3\u7684Co-verify\u548cCo-evolve\u6b65\u9aa4\uff0c\u6a21\u578b\u76f8\u4e92\u751f\u6210\u6570\u636e\u5e76\u5171\u540c\u63d0\u5347\u3002Tester\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u9a8c\u8bc1\u529f\u80fd\u7b49\u4ef7\u6027\uff0cTranslator\u751f\u6210\u7ffb\u8bd1\u4ee3\u7801\u4f5c\u4e3aTester\u7684\u8f93\u5165\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMSL\u663e\u8457\u63d0\u5347\u4e86\u57fa\u7840\u6a21\u578b\u7684\u6027\u80fd\uff0cPass@1\u63d0\u9ad8\u4e8628.91%\uff0cTester\u6027\u80fd\u63d0\u534768.90%\uff0c\u4e14\u5728BLEU\u548cCodeBLEU\u5206\u6570\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MSL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5e8f\u5217\u5230\u5e76\u884c\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u529f\u80fd\u7b49\u4ef7\u6027\u95ee\u9898\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.11237", "pdf": "https://arxiv.org/pdf/2506.11237", "abs": "https://arxiv.org/abs/2506.11237", "authors": ["Ngoc Phuoc An Vo", "Brent Paulovicks", "Vadim Sheinin"], "title": "LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation", "categories": ["cs.SE", "cs.CL"], "comment": "10 pages", "summary": "In an effort to automatically evaluate and select the best model and improve\ncode quality for automatic incident remediation in IT Automation, it is crucial\nto verify if the generated code for remediation action is syntactically and\nsemantically correct and whether it can be executed correctly as intended.\nThere are three approaches: 1) conventional methods use surface form similarity\nmetrics (token match, exact match, etc.) which have numerous limitations, 2)\nexecution-based evaluation focuses more on code functionality based on\npass/fail judgments for given test-cases, and 3) LLM-as-a-Judge employs LLMs\nfor automated evaluation to judge if it is a correct answer for a given problem\nbased on pre-defined metrics. In this work, we focused on enhancing\nLLM-as-a-Judge using bidirectional functionality matching and logic\nrepresentation for reference-less automatic validation and refinement for Bash\ncode generation to select the best model for automatic incident remediation in\nIT Automation. We used execution-based evaluation as ground-truth to evaluate\nour LLM-as-a-Judge metrics. Results show high accuracy and agreement with\nexecution-based evaluation (and up to 8% over baseline). Finally, we built\nReflection code agents to utilize judgments and feedback from our evaluation\nmetrics which achieved significant improvement (up to 24% increase in accuracy)\nfor automatic code refinement.", "AI": {"tldr": "", "motivation": "", "method": "", "result": "", "conclusion": ""}}
{"id": "2506.11266", "pdf": "https://arxiv.org/pdf/2506.11266", "abs": "https://arxiv.org/abs/2506.11266", "authors": ["Benjamin Elder", "Anupama Murthi", "Jungkoo Kang", "Ankita Rajaram Naik", "Kiran Kate", "Kinjal Basu", "Danish Contractor"], "title": "Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation", "categories": ["cs.SE", "cs.AI"], "comment": "10+32 pages, 5 figures", "summary": "Large language models (LLMs) are routinely deployed as agentic systems, with\naccess to tools that interact with live environments to accomplish tasks. In\nenterprise deployments these systems need to interact with API collections that\ncan be extremely large and complex, often backed by databases. In order to\ncreate datasets with such characteristics, we explore how existing NL2SQL\n(Natural Language to SQL query) datasets can be used to automatically create\nNL2API datasets. Specifically, this work describes a novel data generation\npipeline that exploits the syntax of SQL queries to construct a functionally\nequivalent sequence of API calls. We apply this pipeline to one of the largest\nNL2SQL datasets, BIRD-SQL to create a collection of over 2500 APIs that can be\nserved as invocable tools or REST-endpoints. We pair natural language queries\nfrom BIRD-SQL to ground-truth API sequences based on this API pool. We use this\ncollection to study the performance of 10 public LLMs and find that all models\nstruggle to determine the right set of tools (consisting of tasks of intent\ndetection, sequencing with nested function calls, and slot-filling). We find\nthat models have extremely low task completion rates (7-47 percent - depending\non the dataset) which marginally improves to 50 percent when models are\nemployed as ReACT agents that interact with the live API environment. The best\ntask completion rates are far below what may be required for effective\ngeneral-use tool-calling agents, suggesting substantial scope for improvement\nin current state-of-the-art tool-calling LLMs. We also conduct detailed\nablation studies, such as assessing the impact of the number of tools available\nas well as the impact of tool and slot-name obfuscation. We compare the\nperformance of models on the original SQL generation tasks and find that\ncurrent models are sometimes able to exploit SQL better than APIs.", "AI": {"tldr": "\u8be5\u6587\u63a2\u8ba8\u4e86\u5229\u7528NL2SQL\u6570\u636e\u96c6\u81ea\u52a8\u751f\u6210NL2API\u6570\u636e\u96c6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7SQL\u8bed\u6cd5\u6784\u5efa\u7b49\u6548\u7684API\u8c03\u7528\u5e8f\u5217\uff0c\u5e76\u6d4b\u8bd5\u4e8610\u79cdLLM\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5176\u5de5\u5177\u8c03\u7528\u80fd\u529b\u6709\u9650\uff0c\u4ecd\u6709\u8f83\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u4e0e\u590d\u6742API\u96c6\u5408\u4ea4\u4e92\u7684\u80fd\u529b\uff0c\u901a\u8fc7NL2SQL\u6570\u636e\u96c6\u751f\u6210NL2API\u6570\u636e\u96c6\uff0c\u4ee5\u8bc4\u4f30LLM\u7684\u5de5\u5177\u8c03\u7528\u8868\u73b0\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5229\u7528SQL\u67e5\u8be2\u7684\u8bed\u6cd5\u6784\u5efa\u7b49\u6548\u7684API\u8c03\u7528\u5e8f\u5217\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eBIRD-SQL\u6570\u636e\u96c6\uff0c\u751f\u62102500\u591a\u4e2a\u53ef\u8c03\u7528\u7684API\u5de5\u5177\u3002", "result": "\u6d4b\u8bd5\u4e8610\u79cd\u516c\u5171LLM\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5b83\u4eec\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u8f83\u4f4e\uff087-47%\uff09\uff0c\u901a\u8fc7ReACT\u4ee3\u7406\u4e0e\u73af\u5883\u4ea4\u4e92\u540e\u4ec5\u63d0\u5347\u81f350%\u3002\u6a21\u578b\u5728SQL\u751f\u6210\u4e0a\u7684\u8868\u73b0\u4f18\u4e8eAPI\u8c03\u7528\u3002", "conclusion": "\u5f53\u524d\u5de5\u5177\u8c03\u7528\u7684LLM\u6027\u80fd\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u4ee5\u9002\u5e94\u901a\u7528\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u7684\u9700\u6c42\u3002"}}
{"id": "2506.11295", "pdf": "https://arxiv.org/pdf/2506.11295", "abs": "https://arxiv.org/abs/2506.11295", "authors": ["Renato Cordeiro Ferreira"], "title": "A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.8; I.2.0"], "comment": "8 pages, 3 figures (3 diagrams), submitted to the ECSA2025. arXiv\n  admin note: substantial text overlap with arXiv:2506.08153", "summary": "How can the complexity of ML-enabled systems be managed effectively? The goal\nof this research is to investigate how complexity affects ML-Enabled Systems\n(MLES). To address this question, this research aims to introduce a\nmetrics-based architectural model to characterize the complexity of MLES. The\ngoal is to support architectural decisions, providing a guideline for the\ninception and growth of these systems. This paper brings, side-by-side, the\narchitecture representation of two systems that can be used as case studies for\ncreating the metrics-based architectural model: the SPIRA and the Ocean Guard\nMLES.", "AI": {"tldr": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u57fa\u4e8e\u6307\u6807\u7684\u67b6\u6784\u6a21\u578b\u6765\u7ba1\u7406ML\u7cfb\u7edf\u7684\u590d\u6742\u6027\u3002", "motivation": "\u63a2\u8ba8\u590d\u6742\u6027\u5982\u4f55\u5f71\u54cdML\u7cfb\u7edf\uff0c\u5e76\u4e3a\u67b6\u6784\u51b3\u7b56\u63d0\u4f9b\u652f\u6301\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6307\u6807\u7684\u67b6\u6784\u6a21\u578b\uff0c\u5e76\u4ee5SPIRA\u548cOcean Guard MLES\u4e3a\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30ML\u7cfb\u7edf\u590d\u6742\u6027\u7684\u6a21\u578b\u3002", "conclusion": "\u8be5\u6a21\u578b\u6709\u52a9\u4e8e\u6307\u5bfcML\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u6269\u5c55\u3002"}}
{"id": "2506.11400", "pdf": "https://arxiv.org/pdf/2506.11400", "abs": "https://arxiv.org/abs/2506.11400", "authors": ["Yupeng Jiang", "Yao Deng", "Sebastian Schroder", "Linfeng Liang", "Suhaas Gambhir", "Alice James", "Avishkar Seth", "James Pirrie", "Yihao Zhang", "Xi Zheng"], "title": "A Step-by-Step Guide to Creating a Robust Autonomous Drone Testing Pipeline", "categories": ["cs.SE", "cs.RO"], "comment": null, "summary": "Autonomous drones are rapidly reshaping industries ranging from aerial\ndelivery and infrastructure inspection to environmental monitoring and disaster\nresponse. Ensuring the safety, reliability, and efficiency of these systems is\nparamount as they transition from research prototypes to mission-critical\nplatforms. This paper presents a step-by-step guide to establishing a robust\nautonomous drone testing pipeline, covering each critical stage:\nSoftware-in-the-Loop (SIL) Simulation Testing, Hardware-in-the-Loop (HIL)\nTesting, Controlled Real-World Testing, and In-Field Testing. Using practical\nexamples, including the marker-based autonomous landing system, we demonstrate\nhow to systematically verify drone system behaviors, identify integration\nissues, and optimize performance. Furthermore, we highlight emerging trends\nshaping the future of drone testing, including the integration of Neurosymbolic\nand LLMs, creating co-simulation environments, and Digital Twin-enabled\nsimulation-based testing techniques. By following this pipeline, developers and\nresearchers can achieve comprehensive validation, minimize deployment risks,\nand prepare autonomous drones for safe and reliable real-world operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u81ea\u4e3b\u65e0\u4eba\u673a\u6d4b\u8bd5\u7ba1\u9053\u7684\u9010\u6b65\u6307\u5357\uff0c\u6db5\u76d6\u4ece\u6a21\u62df\u5230\u5b9e\u9645\u6d4b\u8bd5\u7684\u5173\u952e\u9636\u6bb5\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u65e0\u4eba\u673a\u4ece\u7814\u7a76\u539f\u578b\u8f6c\u5411\u5173\u952e\u4efb\u52a1\u5e73\u53f0\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u3001\u53ef\u9760\u548c\u9ad8\u6548\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u5206\u9636\u6bb5\u7684\u6d4b\u8bd5\u7ba1\u9053\uff0c\u5305\u62ecSIL\u6a21\u62df\u3001HIL\u6d4b\u8bd5\u3001\u53d7\u63a7\u5b9e\u9645\u6d4b\u8bd5\u548c\u73b0\u573a\u6d4b\u8bd5\uff0c\u5e76\u7ed3\u5408\u5b9e\u4f8b\u6f14\u793a\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u9a8c\u8bc1\u548c\u6027\u80fd\u4f18\u5316\uff0c\u51cf\u5c11\u4e86\u90e8\u7f72\u98ce\u9669\uff0c\u4e3a\u65e0\u4eba\u673a\u5b9e\u9645\u64cd\u4f5c\u505a\u597d\u51c6\u5907\u3002", "conclusion": "\u8be5\u6d4b\u8bd5\u7ba1\u9053\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5168\u9762\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u52a9\u529b\u65e0\u4eba\u673a\u5b89\u5168\u53ef\u9760\u5730\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u3002"}}
{"id": "2506.11442", "pdf": "https://arxiv.org/pdf/2506.11442", "abs": "https://arxiv.org/abs/2506.11442", "authors": ["Yiyang Jin", "Kunzhao Xu", "Hang Li", "Xueting Han", "Yanmin Zhou", "Cheng Li", "Jing Bai"], "title": "ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Recent advances in reinforcement learning (RL) with verifiable outcome\nrewards have significantly improved the reasoning capabilities of large\nlanguage models (LLMs), especially when combined with multi-turn tool\ninteractions. However, existing methods lack both meaningful verification\nsignals from realistic environments and explicit optimization for verification,\nleading to unreliable self-verification. To address these limitations, we\npropose ReVeal, a multi-turn reinforcement learning framework that interleaves\ncode generation with explicit self-verification and tool-based evaluation.\nReVeal enables LLMs to autonomously generate test cases, invoke external tools\nfor precise feedback, and improves performance via a customized RL algorithm\nwith dense, per-turn rewards. As a result, ReVeal fosters the co-evolution of a\nmodel's generation and verification capabilities through RL training, expanding\nthe reasoning boundaries of the base model, demonstrated by significant gains\nin Pass@k on LiveCodeBench. It also enables test-time scaling into deeper\ninference regimes, with code consistently evolving as the number of turns\nincreases during inference, ultimately surpassing DeepSeek-R1-Zero-Qwen-32B.\nThese findings highlight the promise of ReVeal as a scalable and effective\nparadigm for building more robust and autonomous AI agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86ReVeal\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u4ee3\u7801\u751f\u6210\u4e0e\u81ea\u6211\u9a8c\u8bc1\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u771f\u5b9e\u7684\u9a8c\u8bc1\u4fe1\u53f7\u548c\u5bf9\u9a8c\u8bc1\u7684\u660e\u786e\u4f18\u5316\uff0c\u5bfc\u81f4\u81ea\u6211\u9a8c\u8bc1\u4e0d\u53ef\u9760\u3002", "method": "ReVeal\u6846\u67b6\u901a\u8fc7\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\uff0c\u7ed3\u5408\u4ee3\u7801\u751f\u6210\u3001\u6d4b\u8bd5\u7528\u4f8b\u81ea\u52a8\u751f\u6210\u3001\u5916\u90e8\u5de5\u5177\u8c03\u7528\u53ca\u5b9a\u5236RL\u7b97\u6cd5\u4f18\u5316\u9a8c\u8bc1\u80fd\u529b\u3002", "result": "\u5728LiveCodeBench\u4e0aPass@k\u663e\u8457\u63d0\u5347\uff0c\u63a8\u7406\u6df1\u5ea6\u589e\u52a0\u65f6\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u6301\u7eed\u63d0\u5347\uff0c\u8d85\u8d8aDeepSeek-R1-Zero-Qwen-32B\u3002", "conclusion": "ReVeal\u4f5c\u4e3a\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u8303\u5f0f\uff0c\u80fd\u591f\u6784\u5efa\u66f4\u7a33\u5065\u548c\u81ea\u4e3b\u7684AI\u667a\u80fd\u4f53\u3002"}}
{"id": "2506.11451", "pdf": "https://arxiv.org/pdf/2506.11451", "abs": "https://arxiv.org/abs/2506.11451", "authors": ["Md Nahidul Islam Opu", "Md Shahidul Islam", "Sara Rouhani", "Shaiful Chowdhury"], "title": "Understanding the Issue Types in Open Source Blockchain-based Software Projects with the Transformer-based BERTopic", "categories": ["cs.SE"], "comment": null, "summary": "Blockchain-based software systems are increasingly deployed across diverse\ndomains, yet a systematic understanding of their development challenges remains\nlimited. This paper presents a large-scale empirical study of 497,742 issues\nmined from 1,209 open-source blockchain projects hosted on GitHub. Employing\nBERTopic, a transformer-based topic modeling technique, we identify 49 distinct\nissue topics and organize them hierarchically into 11 major subcategories. Our\nanalysis reveals that both general software development issues and\nblockchain-specific concerns are nearly equally represented, with Wallet\nManagement and UI Enhancement emerging as the most prominent topics. We further\nexamine the temporal evolution of issue categories and resolution times,\nfinding that Wallet issues not only dominate in frequency but also exhibit the\nlongest resolution time. Conversely, Mechanisms issues are resolved\nsignificantly faster. Issue frequency surged after 2016 with the rise of\nEthereum and decentralized applications, but declined after 2022. These\nfindings enhance our understanding of blockchain software maintenance,\ninforming the development of specialized tools and practices to improve\nrobustness and maintainability.", "AI": {"tldr": "\u5bf91,209\u4e2a\u533a\u5757\u94fe\u9879\u76ee\u7684497,742\u4e2a\u95ee\u9898\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u94b1\u5305\u7ba1\u7406\u548cUI\u589e\u5f3a\u662f\u6700\u5e38\u89c1\u7684\u95ee\u9898\uff0c\u4e14\u94b1\u5305\u95ee\u9898\u89e3\u51b3\u65f6\u95f4\u6700\u957f\u3002", "motivation": "\u7406\u89e3\u533a\u5757\u94fe\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6311\u6218\uff0c\u4ee5\u6539\u8fdb\u5176\u9c81\u68d2\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "method": "\u4f7f\u7528BERTopic\u5bf9GitHub\u4e0a\u7684\u5f00\u6e90\u533a\u5757\u94fe\u9879\u76ee\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\u548c\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa49\u4e2a\u95ee\u9898\u4e3b\u9898\uff0c\u5206\u4e3a11\u4e2a\u5b50\u7c7b\uff0c\u94b1\u5305\u95ee\u9898\u9891\u7387\u6700\u9ad8\u4e14\u89e3\u51b3\u6700\u6162\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u533a\u5757\u94fe\u8f6f\u4ef6\u7ef4\u62a4\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u4e13\u95e8\u5de5\u5177\u548c\u5b9e\u8df5\u3002"}}
{"id": "2506.11484", "pdf": "https://arxiv.org/pdf/2506.11484", "abs": "https://arxiv.org/abs/2506.11484", "authors": ["Haoshen", "Ming Hu", "Xiaofei Xie", "Jiaye Li", "Mingsong Chen"], "title": "VulStamp: Vulnerability Assessment using Large Language Model", "categories": ["cs.SE"], "comment": null, "summary": "Although modern vulnerability detection tools enable developers to\nefficiently identify numerous security flaws, indiscriminate remediation\nefforts often lead to superfluous development expenses. This is particularly\ntrue given that a substantial portion of detected vulnerabilities either\npossess low exploitability or would incur negligible impact in practical\noperational environments. Consequently, vulnerability severity assessment has\nemerged as a critical component in optimizing software development efficiency.\nExisting vulnerability assessment methods typically rely on manually crafted\ndescriptions associated with source code artifacts. However, due to variability\nin description quality and subjectivity in intention interpretation, the\nperformance of these methods is seriously limited. To address this issue, this\npaper introduces VulStamp, a novel intention-guided framework, to facilitate\ndescription-free vulnerability assessment. Specifically, VulStamp adopts static\nanalysis together with Large Language Model (LLM) to extract the intention\ninformation of vulnerable code. Based on the intention information, VulStamp\nuses a prompt-tuned model for vulnerability assessment. Furthermore, to\nmitigate the problem of imbalanced data associated with vulnerability types,\nVulStamp integrates a Reinforcement Learning (RL)-based prompt-tuning method to\ntrain the assessment model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVulStamp\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u6f0f\u6d1e\u4ee3\u7801\u610f\u56fe\uff0c\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8bc4\u4f30\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u63cf\u8ff0\u7684\u5c40\u9650\u6027\u548c\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u63cf\u8ff0\uff0c\u4f46\u63cf\u8ff0\u8d28\u91cf\u4e0d\u4e00\u4e14\u4e3b\u89c2\u6027\u5f3a\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u63cf\u8ff0\u7684\u6f0f\u6d1e\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "VulStamp\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u6f0f\u6d1e\u4ee3\u7801\u610f\u56fe\uff0c\u4f7f\u7528\u63d0\u793a\u8c03\u4f18\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "VulStamp\u5b9e\u73b0\u4e86\u65e0\u9700\u4eba\u5de5\u63cf\u8ff0\u7684\u6f0f\u6d1e\u4e25\u91cd\u6027\u8bc4\u4f30\uff0c\u4f18\u5316\u4e86\u5f00\u53d1\u6548\u7387\u3002", "conclusion": "VulStamp\u4e3a\u6f0f\u6d1e\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u4e86\u8bc4\u4f30\u6027\u80fd\u3002"}}
{"id": "2506.11525", "pdf": "https://arxiv.org/pdf/2506.11525", "abs": "https://arxiv.org/abs/2506.11525", "authors": ["Michael Grohs", "Nadine Cordes", "Jana-Rebecca Rehse"], "title": "A Procedural Framework for Assessing the Desirability of Process Deviations", "categories": ["cs.SE"], "comment": null, "summary": "Conformance checking techniques help process analysts to identify where and\nhow process executions deviate from a process model. However, they cannot\ndetermine the desirability of these deviations, i.e., whether they are\nproblematic, acceptable or even beneficial for the process. Such desirability\nassessments are crucial to derive actions, but process analysts typically\nconduct them in a manual, ad-hoc way, which can be time-consuming, subjective,\nand irreplicable. To address this problem, this paper presents a procedural\nframework to guide process analysts in systematically assessing deviation\ndesirability. It provides a step-by-step approach for identifying which input\nfactors to consider in what order to categorize deviations into mutually\nexclusive desirability categories, each linked to action recommendations. The\nframework is based on a review and conceptualization of existing literature on\ndeviation desirability, which is complemented by empirical insights from\ninterviews with process analysis practitioners and researchers. We evaluate the\nframework through a desirability assessment task conducted with practitioners,\nindicating that the framework effectively enables them to streamline the\nassessment for a thorough yet concise evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u8bc4\u4f30\u6d41\u7a0b\u504f\u5dee\u53ef\u53d6\u6027\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u6587\u732e\u548c\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u5e2e\u52a9\u5206\u6790\u5e08\u66f4\u9ad8\u6548\u5730\u5206\u7c7b\u504f\u5dee\u5e76\u63d0\u51fa\u884c\u52a8\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u4e00\u81f4\u6027\u68c0\u67e5\u6280\u672f\u65e0\u6cd5\u8bc4\u4f30\u6d41\u7a0b\u504f\u5dee\u7684\u53ef\u53d6\u6027\uff0c\u624b\u52a8\u8bc4\u4f30\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u4e3b\u89c2\u6027\u5f3a\u3002", "method": "\u57fa\u4e8e\u6587\u732e\u7efc\u8ff0\u548c\u5b9e\u8bc1\u8bbf\u8c08\uff0c\u63d0\u51fa\u4e86\u9010\u6b65\u8bc4\u4f30\u6846\u67b6\uff0c\u6307\u5bfc\u5206\u6790\u5e08\u7cfb\u7edf\u5206\u7c7b\u504f\u5dee\u5e76\u94fe\u63a5\u884c\u52a8\u5efa\u8bae\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u7b80\u5316\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u5168\u9762\u4e14\u7b80\u6d01\u7684\u504f\u5dee\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6d41\u7a0b\u504f\u5dee\u7684\u53ef\u53d6\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u671b\u63d0\u5347\u6d41\u7a0b\u5206\u6790\u7684\u6548\u7387\u548c\u4e00\u81f4\u6027\u3002"}}
{"id": "2506.11548", "pdf": "https://arxiv.org/pdf/2506.11548", "abs": "https://arxiv.org/abs/2506.11548", "authors": ["Fabian C. Pe\u00f1a"], "title": "Augmenting the Generality and Performance of Large Language Models for Software Engineering", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) are revolutionizing software engineering (SE),\nwith special emphasis on code generation and analysis. However, their\napplications to broader SE practices including conceptualization, design, and\nother non-code tasks, remain partially underexplored. This research aims to\naugment the generality and performance of LLMs for SE by (1) advancing the\nunderstanding of how LLMs with different characteristics perform on various\nnon-code tasks, (2) evaluating them as sources of foundational knowledge in SE,\nand (3) effectively detecting hallucinations on SE statements. The expected\ncontributions include a variety of LLMs trained and evaluated on\ndomain-specific datasets, new benchmarks on foundational knowledge in SE, and\nmethods for detecting hallucinations. Initial results in terms of performance\nimprovements on various non-code tasks are promising.", "AI": {"tldr": "\u7814\u7a76\u65e8\u5728\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u4e2d\u7684\u901a\u7528\u6027\u548c\u6027\u80fd\uff0c\u7279\u522b\u5173\u6ce8\u975e\u4ee3\u7801\u4efb\u52a1\u3001\u57fa\u7840\u77e5\u8bc6\u548c\u5e7b\u89c9\u68c0\u6d4b\u3002", "motivation": "LLMs\u5728\u4ee3\u7801\u751f\u6210\u548c\u5206\u6790\u65b9\u9762\u5df2\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u5728SE\u4e2d\u7684\u975e\u4ee3\u7801\u4efb\u52a1\uff08\u5982\u6982\u5ff5\u5316\u548c\u8bbe\u8ba1\uff09\u5e94\u7528\u4ecd\u4e0d\u8db3\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u4e0d\u540cLLMs\u5728\u975e\u4ee3\u7801\u4efb\u52a1\u7684\u8868\u73b0\u3001\u8bc4\u4f30\u5176\u4f5c\u4e3aSE\u57fa\u7840\u77e5\u8bc6\u6765\u6e90\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u68c0\u6d4bSE\u9648\u8ff0\u4e2d\u7684\u5e7b\u89c9\u6765\u5b9e\u73b0\u76ee\u6807\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5728\u591a\u79cd\u975e\u4ee3\u7801\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u7814\u7a76\u6709\u671b\u63d0\u4f9b\u9886\u57df\u7279\u5b9a\u7684LLMs\u3001\u65b0\u57fa\u51c6\u548c\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63a8\u52a8LLMs\u5728SE\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2506.11559", "pdf": "https://arxiv.org/pdf/2506.11559", "abs": "https://arxiv.org/abs/2506.11559", "authors": ["G\u00e1bor Antal", "D\u00e9nes B\u00e1n", "Martin Isztin", "Rudolf Ferenc", "P\u00e9ter Heged\u0171s"], "title": "Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "In the life-cycle of software development, testing plays a crucial role in\nquality assurance. Proper testing not only increases code coverage and prevents\nregressions but it can also ensure that any potential vulnerabilities in the\nsoftware are identified and effectively fixed. However, creating such tests is\na complex, resource-consuming manual process. To help developers and security\nexperts, this paper explores the automatic unit test generation capability of\none of the most widely used large language models, GPT-4, from the perspective\nof vulnerabilities. We examine a subset of the VUL4J dataset containing real\nvulnerabilities and their corresponding fixes to determine whether GPT-4 can\ngenerate syntactically and/or semantically correct unit tests based on the code\nbefore and after the fixes as evidence of vulnerability mitigation. We focus on\nthe impact of code contexts, the effectiveness of GPT-4's self-correction\nability, and the subjective usability of the generated test cases. Our results\nindicate that GPT-4 can generate syntactically correct test cases 66.5\\% of the\ntime without domain-specific pre-training. Although the semantic correctness of\nthe fixes could be automatically validated in only 7. 5\\% of the cases, our\nsubjective evaluation shows that GPT-4 generally produces test templates that\ncan be further developed into fully functional vulnerability-witnessing tests\nwith relatively minimal manual effort.\n  Therefore, despite the limited data, our initial findings suggest that GPT-4\ncan be effectively used in the generation of vulnerability-witnessing tests. It\nmay not operate entirely autonomously, but it certainly plays a significant\nrole in a partially automated process.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86GPT-4\u5728\u81ea\u52a8\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u5173\u6ce8\u6f0f\u6d1e\u4fee\u590d\u3002\u7ed3\u679c\u8868\u660e\uff0cGPT-4\u80fd\u591f\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f46\u5728\u8bed\u4e49\u6b63\u786e\u6027\u65b9\u9762\u8868\u73b0\u4e00\u822c\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u8986\u76d6\u5ea6\uff0c\u51cf\u5c11\u624b\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u590d\u6742\u6027\uff0c\u63a2\u7d22GPT-4\u5728\u6f0f\u6d1e\u4fee\u590d\u65b9\u9762\u7684\u6d4b\u8bd5\u751f\u6210\u80fd\u529b\u3002", "method": "\u4f7f\u7528VUL4J\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u6f0f\u6d1e\u53ca\u5176\u4fee\u590d\u4ee3\u7801\uff0c\u8bc4\u4f30GPT-4\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u5e76\u8003\u5bdf\u5176\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u3002", "result": "GPT-4\u572866.5%\u7684\u60c5\u51b5\u4e0b\u80fd\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f46\u8bed\u4e49\u6b63\u786e\u6027\u4ec5\u53607.5%\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u751f\u6210\u7684\u6d4b\u8bd5\u6a21\u677f\u53ef\u8fdb\u4e00\u6b65\u5f00\u53d1\u4e3a\u529f\u80fd\u5b8c\u6574\u7684\u6d4b\u8bd5\u3002", "conclusion": "GPT-4\u5728\u90e8\u5206\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u867d\u9700\u4eba\u5de5\u4ecb\u5165\uff0c\u4f46\u80fd\u663e\u8457\u51cf\u5c11\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2506.11561", "pdf": "https://arxiv.org/pdf/2506.11561", "abs": "https://arxiv.org/abs/2506.11561", "authors": ["G\u00e1bor Antal", "Bence Bogenf\u00fcrst", "Rudolf Ferenc", "P\u00e9ter Heged\u0171s"], "title": "Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have shown promise for\nautomated vulnerability detection and repair in software systems. This paper\ninvestigates the performance of GPT-4o in repairing Java vulnerabilities from a\nwidely used dataset (Vul4J), exploring how different contextual information\naffects automated vulnerability repair (AVR) capabilities. We compare the\nlatest GPT-4o's performance against previous results with GPT-4 using identical\nprompts. We evaluated nine additional prompts crafted by us that contain\nvarious contextual information such as CWE or CVE information, and manually\nextracted code contexts. Each prompt was executed three times on 42\nvulnerabilities, and the resulting fix candidates were validated using Vul4J's\nautomated testing framework.\n  Our results show that GPT-4o performed 11.9\\% worse on average than GPT-4\nwith the same prompt, but was able to fix 10.5\\% more distinct vulnerabilities\nin the three runs together. CVE information significantly improved repair\nrates, while the length of the task description had minimal impact. Combining\nCVE guidance with manually extracted code context resulted in the best\nperformance. Using our \\textsc{Top}-3 prompts together, GPT-4o repaired 26\n(62\\%) vulnerabilities at least once, outperforming both the original baseline\n(40\\%) and its reproduction (45\\%), suggesting that ensemble prompt strategies\ncould improve vulnerability repair in zero-shot settings.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cGPT-4o\u5728\u4fee\u590dJava\u6f0f\u6d1e\u65f6\u6027\u80fd\u8f83GPT-4\u4e0b\u964d11.9%\uff0c\u4f46\u80fd\u4fee\u590d\u66f4\u591a\u6f0f\u6d1e\uff1bCVE\u4fe1\u606f\u663e\u8457\u63d0\u5347\u4fee\u590d\u7387\uff0c\u800c\u4efb\u52a1\u63cf\u8ff0\u957f\u5ea6\u5f71\u54cd\u8f83\u5c0f\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\uff09\u5728\u6f0f\u6d1e\u4fee\u590d\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4ee5\u53ca\u4e0d\u540c\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u5176\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528Vul4J\u6570\u636e\u96c6\uff0c\u6bd4\u8f83GPT-4o\u548cGPT-4\u5728\u76f8\u540c\u63d0\u793a\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u6d4b\u8bd59\u79cd\u5305\u542b\u4e0d\u540c\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u63d0\u793a\u5bf9\u4fee\u590d\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "GPT-4o\u5e73\u5747\u6027\u80fd\u4e0b\u964d11.9%\uff0c\u4f46\u80fd\u4fee\u590d\u66f4\u591a\u6f0f\u6d1e\uff1bCVE\u4fe1\u606f\u548c\u624b\u52a8\u63d0\u53d6\u7684\u4ee3\u7801\u4e0a\u4e0b\u6587\u7ed3\u5408\u6548\u679c\u6700\u4f73\u3002", "conclusion": "\u96f6\u6837\u672c\u573a\u666f\u4e0b\uff0c\u96c6\u6210\u591a\u79cd\u63d0\u793a\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u6f0f\u6d1e\u4fee\u590d\u80fd\u529b\u3002"}}
{"id": "2506.11588", "pdf": "https://arxiv.org/pdf/2506.11588", "abs": "https://arxiv.org/abs/2506.11588", "authors": ["Simone Romano", "Alberto Conforti", "Gloria Guidetti", "Sara Viotti", "Rachele Ceschin", "Giuseppe Scanniello"], "title": "MBSR at Work: Perspectives from an Instructor and Software Developers", "categories": ["cs.SE"], "comment": null, "summary": "In this paper, we present the preliminary findings from a qualitative study\n(i.e., semi-structured interviews) on how a Mindfulness-Based Stress Reduction\n(MBSR) program, carried out in the Software Development (SD) working context,\nis perceived by the software developers of a multinational company who\nparticipated in the MBSR program and by the instructor who led it. MBSR is a\ndeeply personal and experiential practice in helping individuals manage stress,\nparticularly in high-pressure environments such as workplaces, healthcare\nsettings, education, and other demanding professional or personal situations.\nAlthough MBSR has been experimented in different working contexts;\nsurprisingly, it has never been studied in the SD working context where there\nare several stress factors that developers experience (e.g., time pressure and\nuncertainty about the content of a particular task and its outcome). In this\nrespect, qualitative research can generate valuable insights into the\napplication of MBSR in the SD working context that cannot be captured by\nstandardized quantitative measures. Being MBSR instructors and software\ndevelopers the key stakeholders in delivering an MBSR program in the SD working\ncontext, understanding their first-hand experiences can provide a more detailed\npicture of the investigated phenomenon. The most important takeaway result of\nour research can be summarized as follows: despite initial skepticism, the\ndevelopers recognized personal improvements due to the MBSR practice, though\nthe integration of MBSR techniques in the working context remained challenging.", "AI": {"tldr": "\u5b9a\u6027\u7814\u7a76\u53d1\u73b0\uff0c\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u53c2\u4e0e\u6b63\u5ff5\u51cf\u538b\u8bfe\u7a0b\uff08MBSR\uff09\u540e\u867d\u6301\u6000\u7591\u6001\u5ea6\uff0c\u4f46\u8ba4\u53ef\u4e2a\u4eba\u6539\u5584\uff1b\u7136\u800c\u5de5\u4f5c\u73af\u5883\u4e2d\u6574\u5408MBSR\u6280\u672f\u4ecd\u5177\u6311\u6218\u3002", "motivation": "\u63a2\u7d22MBSR\u5728\u8f6f\u4ef6\u5f00\u53d1\uff08SD\uff09\u8fd9\u4e00\u9ad8\u538b\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u6536\u96c6\u8f6f\u4ef6\u5f00\u53d1\u8005\u548cMBSR\u5bfc\u5e08\u7684\u7b2c\u4e00\u624b\u7ecf\u9a8c\u3002", "result": "\u5f00\u53d1\u8005\u5bf9MBSR\u6301\u6000\u7591\u6001\u5ea6\u4f46\u627f\u8ba4\u4e2a\u4eba\u83b7\u76ca\uff1b\u5de5\u4f5c\u73af\u5883\u4e2d\u5b9e\u8df5MBSR\u6280\u672f\u4ecd\u6709\u96be\u5ea6\u3002", "conclusion": "MBSR\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u8005\u7684\u51cf\u538b\u6709\u6548\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5982\u4f55\u66f4\u597d\u5730\u878d\u5165\u5de5\u4f5c\u73af\u5883\u3002"}}
{"id": "2506.11591", "pdf": "https://arxiv.org/pdf/2506.11591", "abs": "https://arxiv.org/abs/2506.11591", "authors": ["Hyunsun Hong", "Jongmoon Baik"], "title": "Retrieval-Augmented Code Review Comment Generation", "categories": ["cs.SE"], "comment": null, "summary": "Automated code review comment generation (RCG) aims to assist developers by\nautomatically producing natural language feedback for code changes. Existing\napproaches are primarily either generation-based, using pretrained language\nmodels, or information retrieval-based (IR), reusing comments from similar past\nexamples. While generation-based methods leverage code-specific pretraining on\nlarge code-natural language corpora to learn semantic relationships between\ncode and natural language, they often struggle to generate low-frequency but\nsemantically important tokens due to their probabilistic nature. In contrast,\nIR-based methods excel at recovering such rare tokens by copying from existing\nexamples but lack flexibility in adapting to new code contexts-for example,\nwhen input code contains identifiers or structures not found in the retrieval\ndatabase. To bridge the gap between generation-based and IR-based methods, this\nwork proposes to leverage retrieval-augmented generation (RAG) for RCG by\nconditioning pretrained language models on retrieved code-review exemplars. By\nproviding relevant examples that illustrate how similar code has been\npreviously reviewed, the model is better guided to generate accurate review\ncomments. Our evaluation on the Tufano et al. benchmark shows that RAG-based\nRCG outperforms both generation-based and IR-based RCG. It achieves up to\n+1.67% higher exact match and +4.25% higher BLEU scores compared to\ngeneration-based RCG. It also improves the generation of low-frequency\nground-truth tokens by up to 24.01%. We additionally find that performance\nimproves as the number of retrieved exemplars increases.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u751f\u6210\u5f0f\u4e0e\u68c0\u7d22\u5f0f\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u8bba\u751f\u6210\u7684\u8d28\u91cf\u4e0e\u4f4e\u9891\u8bed\u4e49\u6807\u8bb0\u7684\u8986\u76d6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u751f\u6210\u5f0f\u6a21\u578b\u96be\u4ee5\u5904\u7406\u4f4e\u9891\u8bed\u4e49\u6807\u8bb0\uff0c\u800c\u68c0\u7d22\u5f0f\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u65b0\u4ee3\u7801\u7684\u9002\u5e94\u6027\u3002\u56e0\u6b64\uff0c\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u63d0\u5347\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u5229\u7528\u68c0\u7d22\u5230\u7684\u4ee3\u7801\u5ba1\u67e5\u793a\u4f8b\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u8f93\u5165\uff0c\u6307\u5bfc\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u751f\u6210\u66f4\u51c6\u786e\u7684\u5ba1\u67e5\u8bc4\u8bba\u3002", "result": "\u5728Tufano\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAG\u65b9\u6cd5\u6bd4\u751f\u6210\u5f0f\u65b9\u6cd5\u63d0\u9ad8\u4e861.67%\u7684\u7cbe\u786e\u5339\u914d\u7387\u548c4.25%\u7684BLEU\u5206\u6570\uff0c\u5e76\u5728\u4f4e\u9891\u6807\u8bb0\u751f\u6210\u4e0a\u63d0\u5347\u4e8624.01%\u3002", "conclusion": "RAG\u65b9\u6cd5\u6709\u6548\u7ed3\u5408\u4e86\u751f\u6210\u4e0e\u68c0\u7d22\u7684\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u7684\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5bf9\u4f4e\u9891\u8bed\u4e49\u6807\u8bb0\u7684\u8986\u76d6\u3002"}}
{"id": "2506.11597", "pdf": "https://arxiv.org/pdf/2506.11597", "abs": "https://arxiv.org/abs/2506.11597", "authors": ["Simone Romano", "Francesco Paolo Sferratore", "Giuseppe Scanniello"], "title": "Further Evidence on a Controversial Topic about Human-Based Experiments: Professionals vs. Students", "categories": ["cs.SE"], "comment": null, "summary": "Most Software Engineering (SE) human-based controlled experiments rely on\nstudents as participants, raising concerns about their external validity.\nSpecifically, the realism of results obtained from students and their\napplicability to the software industry remains in question. In this short\npaper, we bring further evidence on this controversial point. To do so, we\ncompare 62 students and 42 software professionals on a bug-fixing task on the\nsame Java program. The students were enrolled in a Bachelor's program in\nComputer Science, while the professionals were employed by two multinational\ncompanies (for one of them, the professionals were from two offices). Some\nvariations in the experimental settings of the two groups (students and\nprofessionals) were present. For instance, the experimental environment of the\nexperiment with professionals was more realistic; i.e., they faced some stress\nfactors such as interruptions during the bug-fixing task. Considering the\ndifferences between the two groups of participants, the gathered data show that\nthe students outperformed the professionals in fixing bugs. This diverges to\nsome extent from past empirical evidence. Rather than presenting definitive\nconclusions, our results aim to catalyze the discussion on the use of students\nin experiments and pave the way for future investigations. Specifically, our\nresults encourage us to examine the complex factors influencing SE tasks,\nmaking experiments as more realistic as possible.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5b66\u751f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u9a8c\u4e2d\u7684\u8868\u73b0\u662f\u5426\u4f18\u4e8e\u4e13\u4e1a\u5f00\u53d1\u8005\uff0c\u5f15\u53d1\u5173\u4e8e\u5b9e\u9a8c\u5916\u90e8\u6709\u6548\u6027\u7684\u8ba8\u8bba\u3002", "motivation": "\u9a8c\u8bc1\u5b66\u751f\u4f5c\u4e3a\u5b9e\u9a8c\u53c2\u4e0e\u8005\u4e0e\u8f6f\u4ef6\u884c\u4e1a\u4e13\u4e1a\u4eba\u58eb\u5728Bug\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u4ee5\u8bc4\u4f30\u5b9e\u9a8c\u7ed3\u679c\u7684\u73b0\u5b9e\u9002\u7528\u6027\u3002", "method": "\u6bd4\u8f8362\u540d\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u751f\u4e0e42\u540d\u6765\u81ea\u8de8\u56fd\u516c\u53f8\u7684\u4e13\u4e1a\u4eba\u58eb\uff0c\u5728\u540c\u4e00Java\u7a0b\u5e8fBug\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u4e13\u4e1a\u4eba\u58eb\u5b9e\u9a8c\u73af\u5883\u66f4\u8d34\u8fd1\u73b0\u5b9e\uff08\u5982\u4e2d\u65ad\u538b\u529b\uff09\u3002", "result": "\u5b66\u751f\u8868\u73b0\u4f18\u4e8e\u4e13\u4e1a\u4eba\u58eb\uff0c\u4e0e\u8fc7\u5f80\u7814\u7a76\u7ed3\u679c\u90e8\u5206\u51b2\u7a81\u3002", "conclusion": "\u7814\u7a76\u547c\u5401\u8fdb\u4e00\u6b65\u63a2\u8ba8\u5f71\u54cd\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u591a\u56e0\u7d20\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u5b9e\u9a8c\u8bbe\u8ba1\u5e94\u66f4\u8d34\u8fd1\u73b0\u5b9e\u3002"}}
{"id": "2506.11598", "pdf": "https://arxiv.org/pdf/2506.11598", "abs": "https://arxiv.org/abs/2506.11598", "authors": ["Ahmed Zaki", "Cristian Cadar"], "title": "Understanding API Usage and Testing: An Empirical Study of C Libraries", "categories": ["cs.SE"], "comment": "The 29th International Conference on Evaluation and Assessment in\n  Software Engineering, 17 to 20 June, 2025, Istanbul, Turkey", "summary": "For library developers, understanding how their Application Programming\nInterfaces (APIs) are used in the field can be invaluable. Knowing how clients\nare using their APIs allows for data-driven decisions on prioritising bug\nreports, feature requests, and testing activities. For example, the priority of\na bug report concerning an API can be partly determined by how widely that API\nis used.\n  In this paper, we present an empirical study in which we analyse API usage\nacross 21 popular open-source C libraries, such as OpenSSL and SQLite, with a\ncombined total of 3,061 C/C++ clients. We compare API usage by clients with how\nwell library test suites exercise the APIs to offer actionable insights for\nlibrary developers. To our knowledge, this is the first study that compares API\nusage and API testing at scale for the C/C++ ecosystem. Our study shows that\nlibrary developers do not prioritise their effort based on how clients use\ntheir API, with popular APIs often poorly tested. For example, in LMDB, a\npopular key-value store, 45% of the APIs are used by clients but not tested by\nthe library test suite. We further show that client test suites can be\nleveraged to improve library testing e.g., improving coverage in LMDB by 14.7%\nwith the important advantage that those tests are representative of how the\nAPIs are used in the field.\n  For our empirical study, we have developed LibProbe, a framework that can be\nused to analyse a large corpus of clients for a given library and produce\nvarious metrics useful to library developers.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e8621\u4e2aC\u5e93\u7684API\u4f7f\u7528\u60c5\u51b5\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u672a\u6839\u636e\u5ba2\u6237\u7aef\u4f7f\u7528\u60c5\u51b5\u4f18\u5148\u6d4b\u8bd5API\uff0c\u5e76\u63d0\u51fa\u5229\u7528\u5ba2\u6237\u7aef\u6d4b\u8bd5\u63d0\u5347\u5e93\u6d4b\u8bd5\u8986\u76d6\u7387\u7684\u6846\u67b6LibProbe\u3002", "motivation": "\u5e2e\u52a9\u5e93\u5f00\u53d1\u8005\u901a\u8fc7\u4e86\u89e3API\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\uff0c\u505a\u51fa\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\uff0c\u5982\u4f18\u5316\u6d4b\u8bd5\u548c\u4f18\u5148\u5904\u7406\u95ee\u9898\u3002", "method": "\u5bf921\u4e2aC\u5e93\u53ca\u51763061\u4e2a\u5ba2\u6237\u7aef\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83API\u4f7f\u7528\u4e0e\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u5e76\u5f00\u53d1\u4e86LibProbe\u6846\u67b6\u3002", "result": "\u53d1\u73b0\u5e93\u5f00\u53d1\u8005\u672a\u6309\u5ba2\u6237\u7aef\u4f7f\u7528\u60c5\u51b5\u6d4b\u8bd5API\uff0c\u5ba2\u6237\u6d4b\u8bd5\u53ef\u63d0\u5347\u5e93\u6d4b\u8bd5\u8986\u76d6\u7387\uff08\u5982LMDB\u63d0\u5347\u4e8614.7%\uff09\u3002", "conclusion": "\u5efa\u8bae\u5e93\u5f00\u53d1\u8005\u5229\u7528\u5ba2\u6237\u7aef\u6d4b\u8bd5\u6570\u636e\u4f18\u5316\u6d4b\u8bd5\u7b56\u7565\uff0cLibProbe\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.11614", "pdf": "https://arxiv.org/pdf/2506.11614", "abs": "https://arxiv.org/abs/2506.11614", "authors": ["Yonggang Tao", "Jingling Xue"], "title": "Accelerating Delta Debugging through Probabilistic Monotonicity Assessment", "categories": ["cs.SE"], "comment": "Accepted by EASE 2025 (The 29th International Conference on\n  Evaluation and Assessment in Software Engineering), 17-20 June 2025,\n  Istanbul, Turkey. 11 pages", "summary": "Delta debugging assumes search space monotonicity: if a program causes a\nfailure, any supersets of that program will also induce the same failure,\npermitting the exclusion of subsets of non-failure-inducing programs. However,\nthis assumption does not always hold in practice. This paper introduces\nProbabilistic Monotonicity Assessment (PMA), enhancing the efficiency of\nDDMIN-style algorithms without sacrificing effectiveness. PMA dynamically\nmodels and assesses the search space's monotonicity based on prior tests tried\nduring the debugging process and uses a confidence function to quantify\nmonotonicity, thereby enabling the probabilistic exclusion of subsets of\nnon-failure-inducing programs. Our approach significantly reduces redundant\ntests that would otherwise be performed, without compromising the quality of\nthe reduction.\n  We evaluated PMA against two leading DDMIN-style tools, CHISEL and ProbDD.\nOur findings indicate that PMA cuts processing time by 59.2% compared to\nCHISEL, accelerates the reduction process (i.e., the number of tokens deleted\nper second) by 3.32x, and decreases the sizes of the final reduced programs by\n6.7%. Against ProbDD, PMA reduces processing time by 22.0%, achieves a 1.34x\nspeedup in the reduction process, and further decreases the sizes of the final\nreduced programs by 3.0%. These findings affirm PMA's role in significantly\nimproving delta debugging's efficiency while maintaining or enhancing its\neffectiveness.", "AI": {"tldr": "PMA\u901a\u8fc7\u6982\u7387\u5355\u8c03\u6027\u8bc4\u4f30\u63d0\u5347DDMIN\u7b97\u6cd5\u7684\u6548\u7387\uff0c\u51cf\u5c11\u5197\u4f59\u6d4b\u8bd5\uff0c\u540c\u65f6\u4fdd\u6301\u6548\u679c\uff0c\u663e\u8457\u4f18\u4e8eCHISEL\u548cProbDD\u3002", "motivation": "\u5b9e\u8df5\u4e2dDelta\u8c03\u8bd5\u7684\u5355\u8c03\u6027\u5047\u8bbe\u4e0d\u6210\u7acb\uff0cPMA\u901a\u8fc7\u52a8\u6001\u8bc4\u4f30\u5355\u8c03\u6027\u63d0\u5347\u6548\u7387\u3002", "method": "PMA\u52a8\u6001\u5efa\u6a21\u5e76\u8bc4\u4f30\u641c\u7d22\u7a7a\u95f4\u7684\u5355\u8c03\u6027\uff0c\u4f7f\u7528\u7f6e\u4fe1\u51fd\u6570\u91cf\u5316\uff0c\u6982\u7387\u6027\u6392\u9664\u975e\u6545\u969c\u8bf1\u5bfc\u5b50\u96c6\u3002", "result": "PMA\u8f83CHISEL\u5904\u7406\u65f6\u95f4\u51cf\u5c1159.2%\uff0c\u901f\u5ea6\u63d0\u53473.32x\uff0c\u7ed3\u679c\u7a0b\u5e8f\u5927\u5c0f\u51cf\u5c116.7%\uff1b\u8f83ProbDD\u65f6\u95f4\u51cf\u5c1122.0%\uff0c\u901f\u5ea6\u63d0\u53471.34x\uff0c\u7a0b\u5e8f\u5927\u5c0f\u51cf\u5c113.0%\u3002", "conclusion": "PMA\u663e\u8457\u63d0\u5347Delta\u8c03\u8bd5\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u6548\u679c\u3002"}}
{"id": "2506.11659", "pdf": "https://arxiv.org/pdf/2506.11659", "abs": "https://arxiv.org/abs/2506.11659", "authors": ["Simin Sun", "Yuchuan Jin", "Miroslaw Staron"], "title": "An Empirical study on LLM-based Log Retrieval for Software Engineering Metadata Management", "categories": ["cs.SE"], "comment": null, "summary": "Developing autonomous driving systems (ADSs) involves generating and storing\nextensive log data from test drives, which is essential for verification,\nresearch, and simulation. However, these high-frequency logs, recorded over\nvarying durations, pose challenges for developers attempting to locate specific\ndriving scenarios. This difficulty arises due to the wide range of signals\nrepresenting various vehicle components and driving conditions, as well as\nunfamiliarity of some developers' with the detailed meaning of these signals.\nTraditional SQL-based querying exacerbates this challenge by demanding both\ndomain expertise and database knowledge, often yielding results that are\ndifficult to verify for accuracy.\n  This paper introduces a Large Language Model (LLM)-supported approach that\ncombines signal log data with video recordings from test drives, enabling\nnatural language based scenario searches while reducing the need for\nspecialized knowledge. By leveraging scenario distance graphs and relative gap\nindicators, it provides quantifiable metrics to evaluate the reliability of\nquery results. The method is implemented as an API for efficient database\nquerying and retrieval of relevant records, paired with video frames for\nintuitive visualization. Evaluation on an open industrial dataset demonstrates\nimproved efficiency and reliability in scenario retrieval, eliminating\ndependency on a single data source and conventional SQL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4fe1\u53f7\u65e5\u5fd7\u6570\u636e\u548c\u6d4b\u8bd5\u9a7e\u9a76\u7684\u89c6\u9891\u8bb0\u5f55\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u573a\u666f\u641c\u7d22\uff0c\u51cf\u5c11\u4e86\u5bf9\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\uff0c\u5e76\u901a\u8fc7\u91cf\u5316\u6307\u6807\u8bc4\u4f30\u67e5\u8be2\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5f00\u53d1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u65f6\uff0c\u5927\u91cf\u9ad8\u9891\u65e5\u5fd7\u6570\u636e\u96be\u4ee5\u67e5\u8be2\u548c\u5b9a\u4f4d\u7279\u5b9a\u9a7e\u9a76\u573a\u666f\uff0c\u4f20\u7edf\u57fa\u4e8eSQL\u7684\u67e5\u8be2\u65b9\u6cd5\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u6570\u636e\u5e93\u6280\u80fd\uff0c\u7ed3\u679c\u51c6\u786e\u6027\u96be\u4ee5\u9a8c\u8bc1\u3002", "method": "\u7ed3\u5408\u4fe1\u53f7\u65e5\u5fd7\u6570\u636e\u548c\u89c6\u9891\u8bb0\u5f55\uff0c\u5229\u7528\u573a\u666f\u8ddd\u79bb\u56fe\u548c\u76f8\u5bf9\u95f4\u9699\u6307\u6807\uff0c\u63d0\u4f9b\u91cf\u5316\u6307\u6807\u8bc4\u4f30\u67e5\u8be2\u53ef\u9760\u6027\uff0c\u5b9e\u73b0\u4e3aAPI\u4ee5\u9ad8\u6548\u67e5\u8be2\u548c\u68c0\u7d22\u8bb0\u5f55\u3002", "result": "\u5728\u5f00\u653e\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u573a\u666f\u68c0\u7d22\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u4e86\u5bf9\u5355\u4e00\u6570\u636e\u6e90\u548c\u4f20\u7edfSQL\u7684\u4f9d\u8d56\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u641c\u7d22\u548c\u76f4\u89c2\u53ef\u89c6\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u9a7e\u9a76\u65e5\u5fd7\u6570\u636e\u67e5\u8be2\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u5f00\u53d1\u8005\u7684\u5de5\u4f5c\u6548\u7387\u3002"}}
{"id": "2506.11697", "pdf": "https://arxiv.org/pdf/2506.11697", "abs": "https://arxiv.org/abs/2506.11697", "authors": ["Yiwei Hu", "Zhen Li", "Kedie Shu", "Shenghua Guan", "Deqing Zou", "Shouhuai Xu", "Bin Yuan", "Hai Jin"], "title": "SoK: Automated Vulnerability Repair: Methods, Tools, and Assessments", "categories": ["cs.SE"], "comment": "The full version of \"SoK: Automated Vulnerability Repair: Methods,\n  Tools, and Assessments\" accepted by the 34th USENIX Security Symposium\n  (USENIX Security 2025)", "summary": "The increasing complexity of software has led to the steady growth of\nvulnerabilities. Vulnerability repair investigates how to fix software\nvulnerabilities. Manual vulnerability repair is labor-intensive and\ntime-consuming because it relies on human experts, highlighting the importance\nof Automated Vulnerability Repair (AVR). In this SoK, we present the\nsystematization of AVR methods through the three steps of AVR workflow:\nvulnerability analysis, patch generation, and patch validation. We assess AVR\ntools for C/C++ and Java programs as they have been widely studied by the\ncommunity. Since existing AVR tools for C/C++ programs are evaluated with\ndifferent datasets, which often consist of a few vulnerabilities, we construct\nthe first C/C++ vulnerability repair benchmark dataset, dubbed Vul4C, which\ncontains 144 vulnerabilities as well as their exploits and patches. We use\nVul4C to evaluate seven AVR tools for C/C++ programs and use the third-party\nVul4J dataset to evaluate two AVR tools for Java programs. We also discuss\nfuture research directions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5316\u603b\u7ed3\u4e86\u81ea\u52a8\u5316\u6f0f\u6d1e\u4fee\u590d\uff08AVR\uff09\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u9996\u4e2aC/C++\u6f0f\u6d1e\u4fee\u590d\u57fa\u51c6\u6570\u636e\u96c6Vul4C\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cdAVR\u5de5\u5177\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u8f6f\u4ef6\u590d\u6742\u6027\u589e\u52a0\u5bfc\u81f4\u6f0f\u6d1e\u589e\u591a\uff0c\u624b\u52a8\u4fee\u590d\u6548\u7387\u4f4e\uff0c\u81ea\u52a8\u5316\u6f0f\u6d1e\u4fee\u590d\uff08AVR\uff09\u6210\u4e3a\u91cd\u8981\u7814\u7a76\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u6f0f\u6d1e\u5206\u6790\u3001\u8865\u4e01\u751f\u6210\u548c\u8865\u4e01\u9a8c\u8bc1\u4e09\u4e2a\u6b65\u9aa4\u7cfb\u7edf\u5316AVR\u65b9\u6cd5\uff0c\u6784\u5efaVul4C\u6570\u636e\u96c6\u5e76\u8bc4\u4f30\u591a\u6b3eAVR\u5de5\u5177\u3002", "result": "Vul4C\u6570\u636e\u96c6\u5305\u542b144\u4e2a\u6f0f\u6d1e\uff0c\u7528\u4e8e\u8bc4\u4f307\u6b3eC/C++ AVR\u5de5\u5177\uff1bVul4J\u6570\u636e\u96c6\u8bc4\u4f302\u6b3eJava AVR\u5de5\u5177\u3002", "conclusion": "\u8bba\u6587\u4e3aAVR\u7814\u7a76\u63d0\u4f9b\u7cfb\u7edf\u548c\u6570\u636e\u652f\u6301\uff0c\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.11722", "pdf": "https://arxiv.org/pdf/2506.11722", "abs": "https://arxiv.org/abs/2506.11722", "authors": ["Eduard C. Groen", "Fabiano Dalpiaz", "Martijn van Vliet", "Boris Winter", "Joerg Doerr", "Sjaak Brinkkemper"], "title": "Classification of Quality Characteristics in Online User Feedback using Linguistic Analysis, Crowdsourcing and LLMs", "categories": ["cs.SE"], "comment": "Accepted at the Journal of Systems and Software (JSS); online\n  appendix and supplementary material available at\n  https://doi.org/10.5281/zenodo.15604749", "summary": "Software qualities such as usability or reliability are among the strongest\ndeterminants of mobile app user satisfaction and constitute a significant\nportion of online user feedback on software products, making it a valuable\nsource of quality-related feedback to guide the development process. The\nabundance of online user feedback warrants the automated identification of\nquality characteristics, but the online user feedback's heterogeneity and the\nlack of appropriate training corpora limit the applicability of supervised\nmachine learning. We therefore investigate the viability of three approaches\nthat could be effective in low-data settings: language patterns (LPs) based on\nquality-related keywords, instructions for crowdsourced micro-tasks, and large\nlanguage model (LLM) prompts. We determined the feasibility of each approach\nand then compared their accuracy. For the complex multiclass classification of\nquality characteristics, the LP-based approach achieved a varied precision\n(0.38-0.92) depending on the quality characteristic, and low recall;\ncrowdsourcing achieved the best average accuracy in two consecutive phases\n(0.63, 0.72), which could be matched by the best-performing LLM condition\n(0.66) and a prediction based on the LLMs' majority vote (0.68). Our findings\nshow that in this low-data setting, the two approaches that use crowdsourcing\nor LLMs instead of involving experts achieve accurate classifications, while\nthe LP-based approach has only limited potential. The promise of crowdsourcing\nand LLMs in this context might even extend to building training corpora.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\uff0c\u5982\u4f55\u81ea\u52a8\u8bc6\u522b\u79fb\u52a8\u5e94\u7528\u7528\u6237\u53cd\u9988\u4e2d\u7684\u8d28\u91cf\u7279\u5f81\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8e\u8bed\u8a00\u6a21\u5f0f\u3001\u4f17\u5305\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e09\u79cd\u65b9\u6cd5\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u7684\u7528\u6237\u6ee1\u610f\u5ea6\u53d7\u8f6f\u4ef6\u8d28\u91cf\uff08\u5982\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\uff09\u5f71\u54cd\uff0c\u7528\u6237\u53cd\u9988\u662f\u91cd\u8981\u7684\u8d28\u91cf\u4fe1\u606f\u6765\u6e90\uff0c\u4f46\u6570\u636e\u7684\u5f02\u8d28\u6027\u548c\u7f3a\u4e4f\u8bad\u7ec3\u96c6\u9650\u5236\u4e86\u76d1\u7763\u5b66\u4e60\u7684\u5e94\u7528\u3002", "method": "\u7814\u7a76\u4e86\u4e09\u79cd\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u7684\u65b9\u6cd5\uff1a\u57fa\u4e8e\u8d28\u91cf\u5173\u952e\u8bcd\u7684\u8bed\u8a00\u6a21\u5f0f\u3001\u4f17\u5305\u5fae\u4efb\u52a1\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u793a\uff0c\u5e76\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u51c6\u786e\u6027\u3002", "result": "\u8bed\u8a00\u6a21\u5f0f\u65b9\u6cd5\u7684\u7cbe\u786e\u5ea6\u56e0\u8d28\u91cf\u7279\u5f81\u800c\u5f02\uff080.38-0.92\uff09\uff0c\u4f46\u53ec\u56de\u7387\u4f4e\uff1b\u4f17\u5305\u65b9\u6cd5\u5728\u4e24\u9636\u6bb5\u4e2d\u8868\u73b0\u6700\u4f73\uff080.63, 0.72\uff09\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u63a5\u8fd1\uff080.66\uff09\u3002", "conclusion": "\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\uff0c\u4f17\u5305\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u7684\u5206\u7c7b\uff0c\u800c\u8bed\u8a00\u6a21\u5f0f\u65b9\u6cd5\u6f5c\u529b\u6709\u9650\uff1b\u4f17\u5305\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fd8\u53ef\u7528\u4e8e\u6784\u5efa\u8bad\u7ec3\u96c6\u3002"}}
{"id": "2506.11874", "pdf": "https://arxiv.org/pdf/2506.11874", "abs": "https://arxiv.org/abs/2506.11874", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "A Short Survey on Formalising Software Requirements using Large Language Models", "categories": ["cs.SE", "D.2.1; D.2.4; D.2.10; F.4.1; F.4.3"], "comment": "Submitted to SAIV 2025 as extended abstract and received valuable\n  comments improving our draft. This version is the improved one after\n  addressing suggestions from reviewers for improving the draft", "summary": "This paper presents a focused literature survey on the use of large language\nmodels (LLM) to assist in writing formal specifications for software. A summary\nof thirty-five key papers is presented, including examples for specifying\nprograms written in Dafny, C and Java. This paper arose from the project\nVERIFAI - Traceability and verification of natural language requirements that\naddresses the challenges in writing formal specifications from requirements\nthat are expressed in natural language. Our methodology employed multiple\nacademic databases to identify relevant research. The AI-assisted tool Elicit\nfacilitated the initial paper selection, which were manually screened for final\nselection. The survey provides valuable insights and future directions for\nutilising LLMs while formalising software requirements.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f85\u52a9\u7f16\u5199\u8f6f\u4ef6\u5f62\u5f0f\u5316\u89c4\u8303\u4e2d\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u4e8635\u7bc7\u5173\u952e\u8bba\u6587\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5173\u6848\u4f8b\u3002", "motivation": "\u7814\u7a76\u6e90\u4e8eVERIFAI\u9879\u76ee\uff0c\u65e8\u5728\u89e3\u51b3\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e2d\u7f16\u5199\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u591a\u4e2a\u5b66\u672f\u6570\u636e\u5e93\u7b5b\u9009\u76f8\u5173\u7814\u7a76\uff0c\u5e76\u501f\u52a9AI\u5de5\u5177Elicit\u8fdb\u884c\u521d\u6b65\u9009\u62e9\uff0c\u6700\u7ec8\u4eba\u5de5\u7b5b\u9009\u786e\u5b9a\u4e8635\u7bc7\u5173\u952e\u8bba\u6587\u3002", "result": "\u7efc\u8ff0\u63d0\u4f9b\u4e86\u5229\u7528LLM\u5f62\u5f0f\u5316\u8f6f\u4ef6\u9700\u6c42\u7684\u5b9d\u8d35\u89c1\u89e3\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "LLM\u5728\u8f85\u52a9\u5f62\u5f0f\u5316\u89c4\u8303\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.11928", "pdf": "https://arxiv.org/pdf/2506.11928", "abs": "https://arxiv.org/abs/2506.11928", "authors": ["Zihan Zheng", "Zerui Cheng", "Zeyu Shen", "Shang Zhou", "Kaiyuan Liu", "Hansen He", "Dongruixuan Li", "Stanley Wei", "Hangyi Hao", "Jianzhu Yao", "Peiyao Sheng", "Zixuan Wang", "Wenhao Chai", "Aleksandra Korolova", "Peter Henderson", "Sanjeev Arora", "Pramod Viswanath", "Jingbo Shang", "Saining Xie"], "title": "LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": "Project Page at https://livecodebenchpro.com/", "summary": "Recent reports claim that large language models (LLMs) now outperform elite\nhumans in competitive programming. Drawing on knowledge from a group of\nmedalists in international algorithmic contests, we revisit this claim,\nexamining how LLMs differ from human experts and where limitations still\nremain. We introduce LiveCodeBench Pro, a benchmark composed of problems from\nCodeforces, ICPC, and IOI that are continuously updated to reduce the\nlikelihood of data contamination. A team of Olympiad medalists annotates every\nproblem for algorithmic categories and conducts a line-by-line analysis of\nfailed model-generated submissions. Using this new data and benchmark, we find\nthat frontier models still have significant limitations: without external\ntools, the best model achieves only 53% pass@1 on medium-difficulty problems\nand 0% on hard problems, domains where expert humans still excel. We also find\nthat LLMs succeed at implementation-heavy problems but struggle with nuanced\nalgorithmic reasoning and complex case analysis, often generating confidently\nincorrect justifications. High performance appears largely driven by\nimplementation precision and tool augmentation, not superior reasoning.\nLiveCodeBench Pro thus highlights the significant gap to human grandmaster\nlevels, while offering fine-grained diagnostics to steer future improvements in\ncode-centric LLM reasoning.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7f16\u7a0b\u7ade\u8d5b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u7b97\u6cd5\u63a8\u7406\u65b9\u9762\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5dee\u8ddd\u663e\u8457\u3002", "motivation": "\u91cd\u65b0\u8bc4\u4f30LLM\u5728\u7f16\u7a0b\u7ade\u8d5b\u4e2d\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u5176\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7684\u5dee\u5f02\uff0c\u5e76\u8bc6\u522b\u5176\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165LiveCodeBench Pro\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7531\u56fd\u9645\u7ade\u8d5b\u5956\u724c\u5f97\u4e3b\u8fdb\u884c\u95ee\u9898\u6807\u6ce8\u548c\u5206\u6790\uff0c\u8bc4\u4f30LLM\u5728\u4e0d\u540c\u96be\u5ea6\u95ee\u9898\u7684\u8868\u73b0\u3002", "result": "\u524d\u6cbfLLM\u5728\u4e2d\u7b49\u96be\u5ea6\u95ee\u9898\u4e2d\u901a\u8fc7\u7387\u4e3a53%\uff0c\u9ad8\u96be\u5ea6\u95ee\u9898\u4e3a0%\uff0c\u4e14\u4f9d\u8d56\u5de5\u5177\u8f85\u52a9\u800c\u975e\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "LLM\u5728\u5b9e\u73b0\u7ec6\u8282\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u590d\u6742\u7b97\u6cd5\u63a8\u7406\u4e0a\u4ecd\u6709\u663e\u8457\u4e0d\u8db3\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2506.11023", "pdf": "https://arxiv.org/pdf/2506.11023", "abs": "https://arxiv.org/abs/2506.11023", "authors": ["Tomas Bueno Momcilovic", "Barbara Gallina", "Ingmar Kessler", "Dian Balta"], "title": "OntoGSN: An Ontology for Dynamic Management of Assurance Cases", "categories": ["cs.AI", "cs.SE"], "comment": "Submitted to the ISWC 2025 Resources track", "summary": "Assurance cases (ACs) are a common artifact for building and maintaining\nconfidence in system properties such as safety or robustness. Constructing an\nAC can be challenging, although existing tools provide support in static,\ndocument-centric applications and methods for dynamic contexts (e.g.,\nautonomous driving) are emerging. Unfortunately, managing ACs remains a\nchallenge, since maintaining the embedded knowledge in the face of changes\nrequires substantial effort, in the process deterring developers - or worse,\nproducing poorly managed cases that instill false confidence. To address this,\nwe present OntoGSN: an ontology and supporting middleware for managing ACs in\nthe Goal Structuring Notation (GSN) standard. OntoGSN offers a knowledge\nrepresentation and a queryable graph that can be automatically populated,\nevaluated, and updated. Our contributions include: a 1:1 formalization of the\nGSN Community Standard v3 in an OWL ontology with SWRL rules; a helper ontology\nand parser for integration with a widely used AC tool; a repository and\ndocumentation of design decisions for OntoGSN maintenance; a SPARQL query\nlibrary with automation patterns; and a prototypical interface. The ontology\nstrictly adheres to the standard's text and has been evaluated according to\nFAIR principles, the OOPS framework, competency questions, and community\nfeedback. The development of other middleware elements is guided by the\ncommunity needs and subject to ongoing evaluations. To demonstrate the utility\nof our contributions, we illustrate dynamic AC management in an example\ninvolving assurance of adversarial robustness in large language models.", "AI": {"tldr": "OntoGSN\u662f\u4e00\u4e2a\u57fa\u4e8eGSN\u6807\u51c6\u7684\u672c\u4f53\u8bba\u548c\u4e2d\u95f4\u4ef6\uff0c\u7528\u4e8e\u7ba1\u7406\u4fdd\u8bc1\u6848\u4f8b\uff08ACs\uff09\uff0c\u63d0\u4f9b\u77e5\u8bc6\u8868\u793a\u548c\u53ef\u67e5\u8be2\u56fe\uff0c\u652f\u6301\u81ea\u52a8\u586b\u5145\u3001\u8bc4\u4f30\u548c\u66f4\u65b0\u3002", "motivation": "\u7ba1\u7406\u4fdd\u8bc1\u6848\u4f8b\uff08ACs\uff09\u9700\u8981\u5927\u91cf\u7cbe\u529b\uff0c\u73b0\u6709\u5de5\u5177\u96be\u4ee5\u5e94\u5bf9\u52a8\u6001\u73af\u5883\u7684\u53d8\u5316\uff0c\u53ef\u80fd\u5bfc\u81f4\u865a\u5047\u4fe1\u5fc3\u3002", "method": "\u63d0\u51faOntoGSN\uff0c\u5305\u62ecOWL\u672c\u4f53\u3001\u8f85\u52a9\u5de5\u5177\u3001\u8bbe\u8ba1\u6587\u6863\u3001SPARQL\u67e5\u8be2\u5e93\u548c\u539f\u578b\u754c\u9762\uff0c\u4e25\u683c\u9075\u5faaGSN\u6807\u51c6\u5e76\u7ecf\u8fc7\u591a\u79cd\u8bc4\u4f30\u3002", "result": "OntoGSN\u80fd\u591f\u52a8\u6001\u7ba1\u7406ACs\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u9c81\u68d2\u6027\u4fdd\u8bc1\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "OntoGSN\u4e3a\u52a8\u6001\u73af\u5883\u4e0bACs\u7684\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u652f\u6301\u81ea\u52a8\u5316\u7ef4\u62a4\u548c\u66f4\u65b0\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.11124", "pdf": "https://arxiv.org/pdf/2506.11124", "abs": "https://arxiv.org/abs/2506.11124", "authors": ["Yifei Chen", "Ross Greer"], "title": "Technical Report for Argoverse2 Scenario Mining Challenges on Iterative Error Correction and Spatially-Aware Prompting", "categories": ["cs.CV", "cs.SE"], "comment": null, "summary": "Scenario mining from extensive autonomous driving datasets, such as Argoverse\n2, is crucial for the development and validation of self-driving systems. The\nRefAV framework represents a promising approach by employing Large Language\nModels (LLMs) to translate natural-language queries into executable code for\nidentifying relevant scenarios. However, this method faces challenges,\nincluding runtime errors stemming from LLM-generated code and inaccuracies in\ninterpreting parameters for functions that describe complex multi-object\nspatial relationships. This technical report introduces two key enhancements to\naddress these limitations: (1) a fault-tolerant iterative code-generation\nmechanism that refines code by re-prompting the LLM with error feedback, and\n(2) specialized prompt engineering that improves the LLM's comprehension and\ncorrect application of spatial-relationship functions. Experiments on the\nArgoverse 2 validation set with diverse LLMs-Qwen2.5-VL-7B, Gemini 2.5 Flash,\nand Gemini 2.5 Pro-show consistent gains across multiple metrics; most notably,\nthe proposed system achieves a HOTA-Temporal score of 52.37 on the official\ntest set using Gemini 2.5 Pro. These results underline the efficacy of the\nproposed techniques for reliable, high-precision scenario mining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RefAV\u6846\u67b6\u7684\u4e24\u9879\u6539\u8fdb\uff1a\u5bb9\u9519\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u673a\u5236\u548c\u4e13\u95e8\u63d0\u793a\u5de5\u7a0b\uff0c\u4ee5\u89e3\u51b3LLMs\u5728\u573a\u666f\u6316\u6398\u4e2d\u7684\u8fd0\u884c\u65f6\u9519\u8bef\u548c\u53c2\u6570\u89e3\u91ca\u4e0d\u51c6\u786e\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3RefAV\u6846\u67b6\u4e2dLLMs\u751f\u6210\u4ee3\u7801\u7684\u8fd0\u884c\u65f6\u9519\u8bef\u548c\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u53c2\u6570\u89e3\u91ca\u4e0d\u51c6\u786e\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u573a\u666f\u6316\u6398\u7684\u53ef\u9760\u6027\u548c\u7cbe\u5ea6\u3002", "method": "\u5f15\u5165\u4e86\u5bb9\u9519\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u673a\u5236\u548c\u4e13\u95e8\u63d0\u793a\u5de5\u7a0b\uff0c\u4f18\u5316\u4e86LLMs\u7684\u4ee3\u7801\u751f\u6210\u548c\u53c2\u6570\u7406\u89e3\u80fd\u529b\u3002", "result": "\u5728Argoverse 2\u9a8c\u8bc1\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u7cfb\u7edf\u5728\u591a\u6307\u6807\u4e0a\u8868\u73b0\u4e00\u81f4\u63d0\u5347\uff0cHOTA-Temporal\u5f97\u5206\u8fbe\u523052.37\u3002", "conclusion": "\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9ad8\u7cbe\u5ea6\u9a8c\u8bc1\u4e86\u5176\u5728\u53ef\u9760\u573a\u666f\u6316\u6398\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.11612", "pdf": "https://arxiv.org/pdf/2506.11612", "abs": "https://arxiv.org/abs/2506.11612", "authors": ["Zhijie Liu", "Qiyi Tang", "Sen Nie", "Shi Wu", "Liang Feng Zhang", "Yutian Tang"], "title": "KEENHash: Hashing Programs into Function-Aware Embeddings for Large-Scale Binary Code Similarity Analysis", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Binary code similarity analysis (BCSA) is a crucial research area in many\nfields such as cybersecurity. Specifically, function-level diffing tools are\nthe most widely used in BCSA: they perform function matching one by one for\nevaluating the similarity between binary programs. However, such methods need a\nhigh time complexity, making them unscalable in large-scale scenarios (e.g.,\n1/n-to-n search). Towards effective and efficient program-level BCSA, we\npropose KEENHash, a novel hashing approach that hashes binaries into\nprogram-level representations through large language model (LLM)-generated\nfunction embeddings. KEENHash condenses a binary into one compact and\nfixed-length program embedding using K-Means and Feature Hashing, allowing us\nto do effective and efficient large-scale program-level BCSA, surpassing the\nprevious state-of-the-art methods. The experimental results show that KEENHash\nis at least 215 times faster than the state-of-the-art function matching tools\nwhile maintaining effectiveness. Furthermore, in a large-scale scenario with\n5.3 billion similarity evaluations, KEENHash takes only 395.83 seconds while\nthese tools will cost at least 56 days. We also evaluate KEENHash on the\nprogram clone search of large-scale BCSA across extensive datasets in 202,305\nbinaries. Compared with 4 state-of-the-art methods, KEENHash outperforms all of\nthem by at least 23.16%, and displays remarkable superiority over them in the\nlarge-scale BCSA security scenario of malware detection.", "AI": {"tldr": "KEENHash\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u51fd\u6570\u5d4c\u5165\u7684\u54c8\u5e0c\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u548c\u5927\u89c4\u6a21\u7684\u4e8c\u8fdb\u5236\u4ee3\u7801\u76f8\u4f3c\u6027\u5206\u6790\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4e8c\u8fdb\u5236\u4ee3\u7801\u76f8\u4f3c\u6027\u5206\u6790\u65b9\u6cd5\uff08\u5c24\u5176\u662f\u51fd\u6570\u7ea7\u6bd4\u5bf9\u5de5\u5177\uff09\u5728\u5904\u7406\u5927\u89c4\u6a21\u573a\u666f\u65f6\u5b58\u5728\u9ad8\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u6269\u5c55\u5230\u59821/n-to-n\u641c\u7d22\u7b49\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u3002", "method": "\u63d0\u51faKEENHash\uff0c\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u51fd\u6570\u5d4c\u5165\uff0c\u5e76\u5229\u7528K-Means\u548c\u7279\u5f81\u54c8\u5e0c\u5c06\u4e8c\u8fdb\u5236\u4ee3\u7801\u538b\u7f29\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u7a0b\u5e8f\u7ea7\u8868\u793a\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u4e8c\u8fdb\u5236\u4ee3\u7801\u76f8\u4f3c\u6027\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cKEENHash\u6bd4\u73b0\u6709\u51fd\u6570\u5339\u914d\u5de5\u5177\u5feb\u81f3\u5c11215\u500d\uff0c\u540c\u65f6\u572853\u4ebf\u6b21\u76f8\u4f3c\u6027\u8bc4\u4f30\u4e2d\u4ec5\u8017\u65f6395.83\u79d2\uff0c\u800c\u73b0\u6709\u5de5\u5177\u81f3\u5c11\u9700\u898156\u5929\u3002\u572820\u591a\u4e07\u4e2a\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u7a0b\u5e8f\u514b\u9686\u641c\u7d22\u4e2d\uff0cKEENHash\u6bd44\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u6548\u679c\u63d0\u5347\u81f3\u5c1123.16%\u3002", "conclusion": "KEENHash\u5728\u5927\u89c4\u6a21\u4e8c\u8fdb\u5236\u4ee3\u7801\u76f8\u4f3c\u6027\u5206\u6790\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u7684\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\uff0c\u5c24\u5176\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7b49\u5b89\u5168\u573a\u666f\u4e2d\u8868\u73b0\u5353\u8d8a\u3002"}}
{"id": "2506.12014", "pdf": "https://arxiv.org/pdf/2506.12014", "abs": "https://arxiv.org/abs/2506.12014", "authors": ["Yuliang Xu", "Siming Huang", "Mingmeng Geng", "Yao Wan", "Xuanhua Shi", "Dongping Chen"], "title": "code_transformed: The Influence of Large Language Models on Code", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "We release all the experimental dataset and source code at:\n  https://github.com/ignorancex/LLM_code", "summary": "Coding remains one of the most fundamental modes of interaction between\nhumans and machines. With the rapid advancement of Large Language Models\n(LLMs), code generation capabilities have begun to significantly reshape\nprogramming practices. This development prompts a central question: Have LLMs\ntransformed code style, and how can such transformation be characterized? In\nthis paper, we present a pioneering study that investigates the impact of LLMs\non code style, with a focus on naming conventions, complexity, maintainability,\nand similarity. By analyzing code from over 19,000 GitHub repositories linked\nto arXiv papers published between 2020 and 2025, we identify measurable trends\nin the evolution of coding style that align with characteristics of\nLLM-generated code. For instance, the proportion of snake\\_case variable names\nin Python code increased from 47% in Q1 2023 to 51% in Q1 2025. Furthermore, we\ninvestigate how LLMs approach algorithmic problems by examining their reasoning\nprocesses. Given the diversity of LLMs and usage scenarios, among other\nfactors, it is difficult or even impossible to precisely estimate the\nproportion of code generated or assisted by LLMs. Our experimental results\nprovide the first large-scale empirical evidence that LLMs affect real-world\nprogramming style.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u4ee3\u7801\u98ce\u683c\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u547d\u540d\u89c4\u8303\u3001\u590d\u6742\u6027\u548c\u7ef4\u62a4\u6027\uff0c\u5e76\u57fa\u4e8eGitHub\u4ed3\u5e93\u6570\u636e\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u3002", "motivation": "\u63a2\u8ba8LLM\u662f\u5426\u6539\u53d8\u4e86\u4ee3\u7801\u98ce\u683c\u53ca\u5176\u5982\u4f55\u88ab\u8868\u5f81\uff0c\u4ee5\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u5206\u67902020\u81f32025\u5e74\u95f419,000\u591a\u4e2a\u4e0earXiv\u8bba\u6587\u5173\u8054\u7684GitHub\u4ed3\u5e93\u4e2d\u7684\u4ee3\u7801\uff0c\u8003\u5bdf\u547d\u540d\u3001\u590d\u6742\u6027\u7b49\u6307\u6807\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u5f71\u54cd\u4e86\u4ee3\u7801\u98ce\u683c\uff0c\u4f8b\u5982Python\u4e2dsnake_case\u53d8\u91cf\u540d\u7684\u6bd4\u4f8b\u4ece47%\u4e0a\u5347\u81f351%\u3002", "conclusion": "LLM\u786e\u5b9e\u5f71\u54cd\u4e86\u5b9e\u9645\u7f16\u7a0b\u98ce\u683c\uff0c\u4f46\u5177\u4f53\u6bd4\u4f8b\u96be\u4ee5\u7cbe\u786e\u91cf\u5316\u3002"}}
