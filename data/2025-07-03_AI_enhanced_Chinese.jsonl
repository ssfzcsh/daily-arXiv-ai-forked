{"id": "2507.01065", "pdf": "https://arxiv.org/pdf/2507.01065", "abs": "https://arxiv.org/abs/2507.01065", "authors": ["Christiaan Verwijs", "Evelien Acun-Roos", "Daniel Russo"], "title": "Is It Safe To Learn And Share? On Psychological Safety and Social Learning in (Agile) Communities of Practice", "categories": ["cs.SE"], "comment": null, "summary": "As hybrid, distributed, and asynchronous work models become more prevalent,\ncontinuous learning in Agile Software Development (ASD) gains renewed\nimportance. Communities of Practice (CoPs) are increasingly adopted to support\nsocial learning beyond formal education, often relying on virtual\ncommunication. Psychological safety, a prerequisite for effective learning,\nremains insufficiently understood in these settings. This mixed-methods study\ninvestigates psychological safety within Agile CoPs through survey data from\n143 participants. Results indicate that psychological safety is significantly\nlower in online interactions compared to face-to-face settings. Moreover, low\npsychological safety reduces participants' intent to continue contributing and\navoidance of interpersonal risk. No significant differences emerged based on\ngender, community seniority, or content creation activity. However, differences\nby role and age group suggest potential generational or role-related effects.\nThematic analysis revealed exclusionary behavior, negative interaction\npatterns, and hostility as primary threats to psychological safety, often\nreinforced by tribalism and specific community dynamics. Suggested\ninterventions include establishing explicit norms, structured facilitation, and\nactive moderation. The findings were validated through member checking with 30\nparticipants. This study provides a comparative perspective on interaction\nmodalities and offers practical guidance for organizers seeking to cultivate\ninclusive, high-impact CoPs and similarly structured virtual or hybrid work\nenvironments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u654f\u6377\u793e\u533a\u7684\u5728\u7ebf\u4e92\u52a8\u4e2d\uff0c\u5fc3\u7406\u5b89\u5168\u611f\u663e\u8457\u4f4e\u4e8e\u9762\u5bf9\u9762\u73af\u5883\uff0c\u5f71\u54cd\u4e86\u53c2\u4e0e\u610f\u613f\u548c\u98ce\u9669\u89c4\u907f\u884c\u4e3a\u3002", "motivation": "\u968f\u7740\u6df7\u5408\u3001\u5206\u5e03\u5f0f\u548c\u5f02\u6b65\u5de5\u4f5c\u6a21\u5f0f\u7684\u666e\u53ca\uff0c\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u53d8\u5f97\u66f4\u91cd\u8981\uff0c\u4f46\u5fc3\u7406\u5b89\u5168\u611f\u5728\u8fd9\u4e9b\u73af\u5883\u4e2d\u7684\u4f5c\u7528\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7143\u540d\u53c2\u4e0e\u8005\u7684\u8c03\u67e5\u6570\u636e\u548c\u4e3b\u9898\u5206\u6790\uff0c\u7814\u7a76\u654f\u6377\u793e\u533a\u4e2d\u7684\u5fc3\u7406\u5b89\u5168\u611f\u95ee\u9898\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5fc3\u7406\u5b89\u5168\u611f\u5728\u5728\u7ebf\u73af\u5883\u4e2d\u8f83\u4f4e\uff0c\u4e14\u4e0e\u6027\u522b\u3001\u793e\u533a\u8d44\u5386\u6216\u5185\u5bb9\u521b\u4f5c\u6d3b\u52a8\u65e0\u5173\uff0c\u4f46\u5728\u89d2\u8272\u548c\u5e74\u9f84\u7ec4\u4e2d\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u5efa\u8bae\u901a\u8fc7\u660e\u786e\u89c4\u8303\u3001\u7ed3\u6784\u5316\u5f15\u5bfc\u548c\u4e3b\u52a8\u5e72\u9884\u6765\u63d0\u5347\u5fc3\u7406\u5b89\u5168\u611f\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u865a\u62df\u6216\u6df7\u5408\u793e\u533a\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.01103", "pdf": "https://arxiv.org/pdf/2507.01103", "abs": "https://arxiv.org/abs/2507.01103", "authors": ["Jonhnanthan Oliveira", "Rohit Gheyi", "M\u00e1rcio Ribeiro", "Alessandro Garcia"], "title": "Bugs in the Shadows: Static Detection of Faulty Python Refactorings", "categories": ["cs.SE"], "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "summary": "Python is a widely adopted programming language, valued for its simplicity\nand flexibility. However, its dynamic type system poses significant challenges\nfor automated refactoring - an essential practice in software evolution aimed\nat improving internal code structure without changing external behavior.\nUnderstanding how type errors are introduced during refactoring is crucial, as\nsuch errors can compromise software reliability and reduce developer\nproductivity. In this work, we propose a static analysis technique to detect\ntype errors introduced by refactoring implementations for Python. We evaluated\nour technique on Rope refactoring implementations, applying them to open-source\nPython projects. Our analysis uncovered 29 bugs across four refactoring types\nfrom a total of 1,152 refactoring attempts. Several of these issues were also\nfound in widely used IDEs such as PyCharm and PyDev. All reported bugs were\nsubmitted to the respective developers, and some of them were acknowledged and\naccepted. These results highlight the need to improve the robustness of current\nPython refactoring tools to ensure the correctness of automated code\ntransformations and support reliable software maintenance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u5206\u6790\u6280\u672f\uff0c\u7528\u4e8e\u68c0\u6d4bPython\u91cd\u6784\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u7c7b\u578b\u9519\u8bef\uff0c\u5e76\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u53d1\u73b0\u4e86\u73b0\u6709\u5de5\u5177\u7684\u7f3a\u9677\u3002", "motivation": "Python\u7684\u52a8\u6001\u7c7b\u578b\u7cfb\u7edf\u7ed9\u81ea\u52a8\u5316\u91cd\u6784\u5e26\u6765\u4e86\u6311\u6218\uff0c\u53ef\u80fd\u5bfc\u81f4\u7c7b\u578b\u9519\u8bef\uff0c\u5f71\u54cd\u8f6f\u4ef6\u53ef\u9760\u6027\u548c\u5f00\u53d1\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u5206\u6790\u6280\u672f\uff0c\u5e76\u5728Rope\u91cd\u6784\u5b9e\u73b0\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e94\u7528\u4e8e\u5f00\u6e90Python\u9879\u76ee\u3002", "result": "\u57281,152\u6b21\u91cd\u6784\u5c1d\u8bd5\u4e2d\uff0c\u53d1\u73b0\u4e8629\u4e2a\u9519\u8bef\uff0c\u90e8\u5206\u95ee\u9898\u4e5f\u5b58\u5728\u4e8e\u6d41\u884c\u7684IDE\u4e2d\u3002\u90e8\u5206\u95ee\u9898\u5df2\u88ab\u5f00\u53d1\u8005\u8ba4\u53ef\u548c\u4fee\u590d\u3002", "conclusion": "\u73b0\u6709Python\u91cd\u6784\u5de5\u5177\u9700\u8981\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u4ee5\u786e\u4fdd\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u548c\u8f6f\u4ef6\u7684\u53ef\u9760\u7ef4\u62a4\u3002"}}
{"id": "2507.01315", "pdf": "https://arxiv.org/pdf/2507.01315", "abs": "https://arxiv.org/abs/2507.01315", "authors": ["Taiming Wang", "Yanjie Jiang", "Chunhao Dong", "Yuxia Zhang", "Hui Liu"], "title": "Context-Aware Code Wiring Recommendation with LLM-based Agent", "categories": ["cs.SE"], "comment": null, "summary": "Copy-paste-modify is a widespread and pragmatic practice in software\ndevelopment, where developers adapt reused code snippets, sourced from\nplatforms such as Stack Overflow, GitHub, or LLM outputs, into their local\ncodebase. A critical yet underexplored aspect of this adaptation is code\nwiring, which involves substituting unresolved variables in the pasted code\nwith suitable ones from the surrounding context. Existing solutions either rely\non heuristic rules or historical templates, often failing to effectively\nutilize contextual information, despite studies showing that over half of\nadaptation cases are context-dependent. In this paper, we introduce WIRL, an\nLLM-based agent for code wiring framed as a Retrieval-Augmented Generation\n(RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an\norchestration module to identify unresolved variables, retrieve context, and\nperform context-aware substitutions. To balance efficiency and autonomy, the\nagent adopts a mixed strategy: deterministic rule-based steps for common\npatterns, and a state-machine-guided decision process for intelligent\nexploration. We evaluate WIRL on a carefully curated, high-quality dataset\nconsisting of real-world code adaptation scenarios. Our approach achieves an\nexact match precision of 91.7% and a recall of 90.0%, outperforming advanced\nLLMs by 22.6 and 13.7 percentage points in precision and recall, respectively,\nand surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results\nunderscore its practical utility, particularly in contexts with complex\nvariable dependencies or multiple unresolved variables. We believe WIRL paves\nthe way for more intelligent and context-aware developer assistance in modern\nIDEs.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86WIRL\uff0c\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u63a5\u7ebf\u4ee3\u7406\uff0c\u7528\u4e8e\u89e3\u51b3\u4ee3\u7801\u7c98\u8d34\u4e2d\u7684\u53d8\u91cf\u9002\u914d\u95ee\u9898\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4ee3\u7801\u7c98\u8d34\u662f\u5e38\u89c1\u5b9e\u8df5\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u9002\u914d\u6548\u679c\u4e0d\u4f73\u3002", "method": "WIRL\u7ed3\u5408LLM\u3001\u5b9a\u5236\u5de5\u5177\u548c\u7f16\u6392\u6a21\u5757\uff0c\u91c7\u7528\u6df7\u5408\u7b56\u7565\u8fdb\u884c\u786e\u5b9a\u6027\u89c4\u5219\u548c\u667a\u80fd\u63a2\u7d22\u7684\u53d8\u91cf\u4ee3\u6362\u3002", "result": "WIRL\u7684\u7cbe\u786e\u5339\u914d\u7cbe\u5ea6\u4e3a91.7%\uff0c\u53ec\u56de\u7387\u4e3a90.0%\uff0c\u8fdc\u8d85LLMs\u548cIntelliJ IDEA\u3002", "conclusion": "WIRL\u4e3a\u73b0\u4ee3IDE\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u5f00\u53d1\u8f85\u52a9\u5de5\u5177\u3002"}}
{"id": "2507.01477", "pdf": "https://arxiv.org/pdf/2507.01477", "abs": "https://arxiv.org/abs/2507.01477", "authors": ["Lukas Krodinger", "Stephan Lukasczyk", "Gordon Fraser"], "title": "Combining Type Inference and Automated Unit Test Generation for Python", "categories": ["cs.SE"], "comment": null, "summary": "Automated unit test generation is an established research field that has so\nfar focused on statically-typed programming languages. The lack of type\ninformation in dynamically-typed programming languages, such as Python,\ninhibits test generators, which heavily rely on information about parameter and\nreturn types of functions to select suitable arguments when constructing test\ncases. Since automated test generators inherently rely on frequent execution of\ncandidate tests, we make use of these frequent executions to address this\nproblem by introducing type tracing, which extracts type-related information\nduring execution and gradually refines the available type information. We\nimplement type tracing as an extension of the Pynguin test-generation framework\nfor Python, allowing it (i) to infer parameter types by observing how\nparameters are used during runtime, (ii) to record the types of values that\nfunction calls return, and (iii) to use this type information to increase code\ncoverage. The approach leads to up to 90.0% more branch coverage, improved\nmutation scores, and to type information of similar quality to that produced by\nother state-of-the-art type-inference tools.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7c7b\u578b\u8ffd\u8e2a\u7684\u6280\u672f\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u63d0\u53d6\u7c7b\u578b\u4fe1\u606f\u6765\u6539\u5584\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\uff08\u5982Python\uff09\u7684\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u6548\u679c\u3002", "motivation": "\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u7f3a\u4e4f\u9759\u6001\u7c7b\u578b\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u73b0\u6709\u6d4b\u8bd5\u751f\u6210\u5668\u7684\u6548\u80fd\uff0c\u5c24\u5176\u662f\u5728\u53c2\u6570\u548c\u8fd4\u56de\u503c\u7c7b\u578b\u63a8\u65ad\u65b9\u9762\u3002", "method": "\u901a\u8fc7\u7c7b\u578b\u8ffd\u8e2a\u6280\u672f\u5728\u8fd0\u884c\u65f6\u63d0\u53d6\u548c\u9010\u6b65\u4f18\u5316\u7c7b\u578b\u4fe1\u606f\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230Pynguin\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\u4e2d\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe90%\u7684\u5206\u652f\u8986\u76d6\u63d0\u5347\uff0c\u6539\u5584\u4e86\u53d8\u5f02\u5f97\u5206\uff0c\u4e14\u7c7b\u578b\u4fe1\u606f\u8d28\u91cf\u5ab2\u7f8e\u73b0\u6709\u5148\u8fdb\u7c7b\u578b\u63a8\u65ad\u5de5\u5177\u3002", "conclusion": "\u7c7b\u578b\u8ffd\u8e2a\u6709\u6548\u63d0\u5347\u4e86\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u7684\u6d4b\u8bd5\u751f\u6210\u6548\u679c\uff0c\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.01110", "pdf": "https://arxiv.org/pdf/2507.01110", "abs": "https://arxiv.org/abs/2507.01110", "authors": ["Felix Windisch", "Lukas Radl", "Thomas K\u00f6hler", "Michael Steiner", "Dieter Schmalstieg", "Markus Steinberger"], "title": "A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory", "categories": ["cs.GR", "cs.LG"], "comment": null, "summary": "Gaussian Splatting has emerged as a high-performance technique for novel view\nsynthesis, enabling real-time rendering and high-quality reconstruction of\nsmall scenes. However, scaling to larger environments has so far relied on\npartitioning the scene into chunks -- a strategy that introduces artifacts at\nchunk boundaries, complicates training across varying scales, and is poorly\nsuited to unstructured scenarios such as city-scale flyovers combined with\nstreet-level views. Moreover, rendering remains fundamentally limited by GPU\nmemory, as all visible chunks must reside in VRAM simultaneously. We introduce\nA LoD of Gaussians, a framework for training and rendering ultra-large-scale\nGaussian scenes on a single consumer-grade GPU -- without partitioning. Our\nmethod stores the full scene out-of-core (e.g., in CPU memory) and trains a\nLevel-of-Detail (LoD) representation directly, dynamically streaming only the\nrelevant Gaussians. A hybrid data structure combining Gaussian hierarchies with\nSequential Point Trees enables efficient, view-dependent LoD selection, while a\nlightweight caching and view scheduling system exploits temporal coherence to\nsupport real-time streaming and rendering. Together, these innovations enable\nseamless multi-scale reconstruction and interactive visualization of complex\nscenes -- from broad aerial views to fine-grained ground-level details.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5206\u5757\u7684Gaussian Splatting\u65b9\u6cd5\uff0c\u901a\u8fc7LoD\u6280\u672f\u548c\u52a8\u6001\u6d41\u5f0f\u5904\u7406\u5b9e\u73b0\u5927\u89c4\u6a21\u573a\u666f\u7684\u9ad8\u6548\u8bad\u7ec3\u4e0e\u6e32\u67d3\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5206\u5757\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u5f15\u5165\u7684\u8fb9\u754c\u4f2a\u5f71\u3001\u8bad\u7ec3\u590d\u6742\u5ea6\u9ad8\u53ca\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "method": "\u91c7\u7528LoD\u8868\u793a\u548c\u6df7\u5408\u6570\u636e\u7ed3\u6784\uff0c\u7ed3\u5408\u52a8\u6001\u6d41\u5f0f\u4f20\u8f93\u548c\u7f13\u5b58\u4f18\u5316\uff0c\u5b9e\u73b0\u5355GPU\u4e0a\u7684\u9ad8\u6548\u6e32\u67d3\u3002", "result": "\u5b9e\u73b0\u4e86\u5355\u6d88\u8d39\u7ea7GPU\u4e0b\u7684\u5927\u89c4\u6a21\u573a\u666f\u65e0\u7f1d\u591a\u5c3a\u5ea6\u91cd\u5efa\u4e0e\u5b9e\u65f6\u4ea4\u4e92\u53ef\u89c6\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u6e32\u67d3\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01272", "pdf": "https://arxiv.org/pdf/2507.01272", "abs": "https://arxiv.org/abs/2507.01272", "authors": ["Zixuan Zhu"], "title": "Advanced LPeg techniques: A dual case study approach", "categories": ["cs.PL"], "comment": null, "summary": "This paper presents advanced optimization techniques for Lua Parsing\nExpression Grammars (LPeg) through two complementary case studies: a\nhigh-performance JSON parser and a sophisticated Glob-to-LPeg pattern\nconverter. We demonstrate how strategic grammar construction can dramatically\nimprove parsing performance without modifying the underlying LPeg library. For\nthe JSON parser, we implement substitution capture and table construction\noptimization to reduce memory allocation overhead and improve object\nprocessing. For the Glob converter, we introduce segment-boundary separation,\nimplement Cox's flattened search strategy, and develop optimized braced\ncondition handling to prevent exponential backtracking. Comprehensive\nbenchmarks demonstrate that our JSON parser achieves processing speeds up to\n125 MB/s on complex documents, consistently outperforming dkjson and showing\ncompetitive results against rxi_json across most test cases. Our Glob-to-LPeg\nconverter exhibits 14-92% better performance than Bun.Glob and runs 3-14 times\nfaster than Minimatch across diverse pattern matching scenarios. This research\nprovides practical optimization techniques for LPeg-based parsers, contributing\nvaluable strategies to the text processing ecosystem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u4f18\u5316Lua\u89e3\u6790\u8868\u8fbe\u5f0f\u6587\u6cd5\uff08LPeg\uff09\uff0c\u5728\u4e0d\u4fee\u6539LPeg\u5e93\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u89e3\u6790\u6027\u80fd\u3002", "motivation": "\u901a\u8fc7\u4f18\u5316LPeg\u8bed\u6cd5\u7ed3\u6784\uff0c\u89e3\u51b3JSON\u89e3\u6790\u548cGlob\u6a21\u5f0f\u8f6c\u6362\u4e2d\u7684\u6027\u80fd\u95ee\u9898\u3002", "method": "\u9488\u5bf9JSON\u89e3\u6790\u5668\uff0c\u91c7\u7528\u66ff\u4ee3\u6355\u83b7\u548c\u8868\u683c\u6784\u5efa\u4f18\u5316\uff1b\u9488\u5bf9Glob\u8f6c\u6362\u5668\uff0c\u5f15\u5165\u6bb5\u8fb9\u754c\u5206\u79bb\u3001Cox\u6241\u5e73\u641c\u7d22\u7b56\u7565\u548c\u4f18\u5316\u7684\u5927\u62ec\u53f7\u6761\u4ef6\u5904\u7406\u3002", "result": "JSON\u89e3\u6790\u5668\u901f\u5ea6\u8fbe125 MB/s\uff0c\u4f18\u4e8edkjson\u548crxi_json\uff1bGlob\u8f6c\u6362\u5668\u6027\u80fd\u63d0\u534714-92%\uff0c\u6bd4Bun.Glob\u548cMinimatch\u66f4\u5feb\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86LPeg\u89e3\u6790\u5668\u7684\u5b9e\u7528\u4f18\u5316\u6280\u672f\uff0c\u4e3a\u6587\u672c\u5904\u7406\u751f\u6001\u7cfb\u7edf\u8d21\u732e\u4e86\u6709\u4ef7\u503c\u7684\u7b56\u7565\u3002"}}
{"id": "2507.01577", "pdf": "https://arxiv.org/pdf/2507.01577", "abs": "https://arxiv.org/abs/2507.01577", "authors": ["Christoph Wernhard"], "title": "Interpolation with Automated First-Order Reasoning", "categories": ["cs.LO"], "comment": "This is a chapter of the forthcoming book \"Theory and Applications of\n  Craig Interpolation\", edited by Balder ten Cate, Jean Christoph Jung, Patrick\n  Koopmann, Christoph Wernhard and Frank Wolter", "summary": "We consider interpolation from the viewpoint of fully automated theorem\nproving in first-order logic as a general core technique for mechanized\nknowledge processing. For Craig interpolation, our focus is on the two-stage\napproach, where first an essentially propositional ground interpolant is\ncalculated that is then lifted to a quantified first-order formula. We discuss\ntwo possibilities to obtain a ground interpolant from a proof, with clausal\ntableaux, and with resolution. Established preprocessing techniques for\nfirst-order proving can also be applied for Craig interpolation if they are\nrestricted in specific ways. Equality encodings from automated reasoning\njustify strengthened variations of Craig interpolation. Also further\ncontributions to Craig interpolation emerged from automated reasoning. As an\napproach to uniform interpolation we introduce second-order quantifier\nelimination with examples and describe the basic algorithms DLS and SCAN.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4e00\u9636\u903b\u8f91\u4e2d\u5b8c\u5168\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u7684\u63d2\u503c\u65b9\u6cd5\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86Craig\u63d2\u503c\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u8868\u76d8\u548c\u5206\u8fa8\u7387\u7684\u5730\u9762\u63d2\u503c\u83b7\u53d6\u65b9\u5f0f\u3002\u8fd8\u6d89\u53ca\u4e86\u9884\u5904\u7406\u6280\u672f\u3001\u7b49\u5f0f\u7f16\u7801\u4ee5\u53ca\u4e8c\u9636\u91cf\u8bcd\u6d88\u9664\u7b49\u5185\u5bb9\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u63a2\u7d22\u4e00\u9636\u903b\u8f91\u4e2d\u63d2\u503c\u65b9\u6cd5\u5728\u673a\u68b0\u5316\u77e5\u8bc6\u5904\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u5b9e\u73b0Craig\u63d2\u503c\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5148\u8ba1\u7b97\u547d\u9898\u5730\u9762\u63d2\u503c\uff0c\u518d\u63d0\u5347\u4e3a\u91cf\u8bcd\u5316\u4e00\u9636\u516c\u5f0f\u3002\u4f7f\u7528\u8868\u76d8\u548c\u5206\u8fa8\u7387\u83b7\u53d6\u5730\u9762\u63d2\u503c\uff0c\u5e76\u7ed3\u5408\u9884\u5904\u7406\u6280\u672f\u548c\u7b49\u5f0f\u7f16\u7801\u3002", "result": "\u63d0\u51fa\u4e86\u5b9e\u73b0Craig\u63d2\u503c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4e8c\u9636\u91cf\u8bcd\u6d88\u9664\u8fdb\u884c\u5747\u5300\u63d2\u503c\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u63a8\u7406\u4e2d\u63d2\u503c\u65b9\u6cd5\u7684\u591a\u6837\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u77e5\u8bc6\u5904\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.01320", "pdf": "https://arxiv.org/pdf/2507.01320", "abs": "https://arxiv.org/abs/2507.01320", "authors": ["Xiangzuo Liu", "Zhikai Liu", "PengPeng Yu", "Ruishan Huang", "Fan Liang"], "title": "Robust Multi-generation Learned Compression of Point Cloud Attribute", "categories": ["cs.MM"], "comment": null, "summary": "Existing learned point cloud attribute compression methods primarily focus on\nsingle-pass rate-distortion optimization, while overlooking the issue of\ncumulative distortion in multi-generation compression scenarios. This paper,\nfor the first time, investigates the multi-generation issue in learned point\ncloud attribute compression. We identify two primary factors contributing to\nquality degradation in multi-generation compression: quantization-induced\nnon-idempotency and transformation irreversibility. To address the former, we\npropose a Mapping Idempotency Constraint, that enables the network to learn the\ncomplete compression-decompression mapping, enhancing its robustness to\nrepeated processes. To address the latter, we introduce a Transformation\nReversibility Constraint, which preserves reversible information flow via a\nquantization-free training path. Further, we propose a Latent Variable\nConsistency Constraint which enhances the multi-generation compression\nrobustness by incorporating a decompression-compression cross-generation path\nand a latent variable consistency loss term. Extensive experiments conducted on\nthe Owlii and 8iVFB datasets verify that the proposed methods can effectively\nsuppress multi-generation loss while maintaining single-pass rate-distortion\nperformance comparable to baseline models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7814\u7a76\u4e86\u5b66\u4e60\u70b9\u4e91\u5c5e\u6027\u538b\u7f29\u4e2d\u7684\u591a\u4ee3\u95ee\u9898\uff0c\u63d0\u51fa\u4e09\u79cd\u7ea6\u675f\u65b9\u6cd5\u4ee5\u6291\u5236\u591a\u4ee3\u5931\u771f\uff0c\u540c\u65f6\u4fdd\u6301\u5355\u6b21\u7387\u5931\u771f\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5ffd\u89c6\u591a\u4ee3\u538b\u7f29\u4e2d\u7684\u7d2f\u79ef\u5931\u771f\u95ee\u9898\uff0c\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6620\u5c04\u5e42\u7b49\u6027\u7ea6\u675f\u3001\u53d8\u6362\u53ef\u9006\u6027\u7ea6\u675f\u548c\u6f5c\u5728\u53d8\u91cf\u4e00\u81f4\u6027\u7ea6\u675f\u3002", "result": "\u5728Owlii\u548c8iVFB\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u6709\u6548\u6291\u5236\u591a\u4ee3\u5931\u771f\u3002", "conclusion": "\u65b9\u6cd5\u5728\u591a\u4ee3\u538b\u7f29\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u4e0d\u5f71\u54cd\u5355\u6b21\u538b\u7f29\u6027\u80fd\u3002"}}
{"id": "2507.01239", "pdf": "https://arxiv.org/pdf/2507.01239", "abs": "https://arxiv.org/abs/2507.01239", "authors": ["Matthew Scott", "Jeremy Pitt"], "title": "A Full-Stack Platform Architecture for Self-Organised Social Coordination", "categories": ["cs.NI"], "comment": "10 pages, 10 figures, 2 tables", "summary": "To mitigate the restrictive centralising and monopolistic tendencies of\nplatformisation, we aim to empower local communities by democratising platforms\nfor self-organised social coordination. Our approach is to develop an\nopen-source, full-stack architecture for platform development that supports\nease of distribution and cloning, generativity, and a variety of hosting\noptions. The architecture consists of a meta-platform that is used to\ninstantiate a base platform with supporting libraries for generic functions,\nand plugins (intended to be supplied by third parties) for customisation of\napplication-specification functionality for self-organised social coordination.\nAssociated developer- and user-oriented toolchains support the instantiation\nand customisation of a platform in a two-stage process. This is demonstrated\nthrough the proof-of-concept implementation of two case studies: a platform for\nregular sporting association, and a platform for collective group study. We\nconclude by arguing that self-organisation at the application layer can be\nachieved by the specific supporting functionality of a full-stack architecture\nwith complimentary developer and user toolchains.", "AI": {"tldr": "\u901a\u8fc7\u5f00\u53d1\u5f00\u6e90\u3001\u5168\u6808\u7684\u5e73\u53f0\u67b6\u6784\uff0c\u65e8\u5728\u8d4b\u6743\u672c\u5730\u793e\u533a\uff0c\u652f\u6301\u81ea\u6211\u7ec4\u7ec7\u7684\u793e\u4f1a\u534f\u8c03\uff0c\u5bf9\u6297\u5e73\u53f0\u5316\u7684\u5784\u65ad\u8d8b\u52bf\u3002", "motivation": "\u5e94\u5bf9\u5e73\u53f0\u5316\u5e26\u6765\u7684\u96c6\u4e2d\u5316\u548c\u5784\u65ad\u503e\u5411\uff0c\u9700\u4e3a\u672c\u5730\u793e\u533a\u63d0\u4f9b\u6c11\u4e3b\u5316\u7684\u5e73\u53f0\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e00\u79cd\u652f\u6301\u5206\u5e03\u5f0f\u90e8\u7f72\u3001\u514b\u9686\u548c\u591a\u6837\u6258\u7ba1\u9009\u9879\u7684\u5168\u6808\u67b6\u6784\uff0c\u5305\u62ec\u5143\u5e73\u53f0\u3001\u57fa\u7840\u5e73\u53f0\u548c\u652f\u6301\u5e93\uff0c\u4ee5\u53ca\u7b2c\u4e09\u65b9\u63d2\u4ef6\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u4f53\u80b2\u7ec4\u7ec7\u548c\u96c6\u4f53\u5b66\u4e60\u5e73\u53f0\uff09\u9a8c\u8bc1\u4e86\u67b6\u6784\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u5168\u6808\u67b6\u6784\u53ca\u914d\u5957\u5de5\u5177\u94fe\u53ef\u652f\u6301\u5e94\u7528\u5c42\u7684\u81ea\u6211\u7ec4\u7ec7\u3002"}}
{"id": "2507.01081", "pdf": "https://arxiv.org/pdf/2507.01081", "abs": "https://arxiv.org/abs/2507.01081", "authors": ["Megan T. deBettencourt", "Sruthi Sakthivel", "Emily A. Holmes", "Mark Chevillet"], "title": "AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Trauma prevalence is vast globally. Evidence-based digital treatments can\nhelp, but most require human guidance. Human guides provide tailored\ninstructions and responsiveness to internal cognitive states, but limit\nscalability. Can generative AI and neurotechnology provide a scalable\nalternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to\nautomatically deliver and monitor an evidence-based digital treatment,\nspecifically the Imagery Competing Task Intervention (ICTI), to reduce\nintrusive memories after psychological trauma. One hundred healthy volunteers\nwere exposed to videos of traumatic events and randomly assigned to an\nintervention or active control condition. As predicted, intervention\nparticipants reported significantly fewer intrusive memories over the following\nweek. Post-hoc assessment against clinical rubrics confirmed the AI guide\ndelivered the intervention successfully. Additionally, pupil size tracked\nintervention engagement and predicted symptom reduction, providing a candidate\nbiomarker of intervention effectiveness. These findings open a path toward\nrigorous AI-guided digital interventions that can scale to trauma prevalence.", "AI": {"tldr": "ANTIDOTE\u7ed3\u5408AI\u5f15\u5bfc\u548c\u77b3\u5b54\u6d4b\u91cf\u6280\u672f\uff0c\u81ea\u52a8\u63d0\u4f9b\u5e76\u76d1\u6d4b\u57fa\u4e8e\u8bc1\u636e\u7684\u6570\u5b57\u6cbb\u7597\uff08ICTI\uff09\uff0c\u663e\u8457\u51cf\u5c11\u521b\u4f24\u540e\u4fb5\u5165\u6027\u8bb0\u5fc6\uff0c\u77b3\u5b54\u5927\u5c0f\u53ef\u4f5c\u4e3a\u5e72\u9884\u6548\u679c\u7684\u751f\u7269\u6807\u5fd7\u7269\u3002", "motivation": "\u5168\u7403\u521b\u4f24\u666e\u904d\uff0c\u4f46\u73b0\u6709\u7684\u6570\u5b57\u6cbb\u7597\u4f9d\u8d56\u4eba\u5de5\u6307\u5bfc\uff0c\u9650\u5236\u53ef\u6269\u5c55\u6027\u3002\u7814\u7a76\u63a2\u7d22\u751f\u6210\u5f0fAI\u548c\u795e\u7ecf\u6280\u672f\u662f\u5426\u80fd\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "100\u540d\u5065\u5eb7\u5fd7\u613f\u8005\u89c2\u770b\u521b\u4f24\u89c6\u9891\uff0c\u968f\u673a\u5206\u914d\u81f3\u5e72\u9884\u7ec4\u6216\u5bf9\u7167\u7ec4\u3002ANTIDOTE\u7cfb\u7edf\u7ed3\u5408AI\u5f15\u5bfc\u548c\u77b3\u5b54\u6d4b\u91cf\u6280\u672f\uff0c\u81ea\u52a8\u63d0\u4f9bICTI\u5e72\u9884\u3002", "result": "\u5e72\u9884\u7ec4\u62a5\u544a\u660e\u663e\u51cf\u5c11\u7684\u4fb5\u5165\u6027\u8bb0\u5fc6\u3002AI\u6307\u5bfc\u6210\u529f\u5b9e\u65bd\u5e72\u9884\uff0c\u77b3\u5b54\u5927\u5c0f\u4e0e\u5e72\u9884\u53c2\u4e0e\u5ea6\u53ca\u75c7\u72b6\u51cf\u8f7b\u76f8\u5173\u3002", "conclusion": "ANTIDOTE\u4e3a\u53ef\u6269\u5c55\u7684AI\u5f15\u5bfc\u6570\u5b57\u5e72\u9884\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u77b3\u5b54\u6d4b\u91cf\u53ef\u4f5c\u4e3a\u6709\u6548\u6027\u751f\u7269\u6807\u5fd7\u7269\u3002"}}
{"id": "2507.01429", "pdf": "https://arxiv.org/pdf/2507.01429", "abs": "https://arxiv.org/abs/2507.01429", "authors": ["Benjamin Chen Ming Choong", "Tao Luo", "Cheng Liu", "Bingsheng He", "Wei Zhang", "Joey Tianyi Zhou"], "title": "Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems", "categories": ["cs.ET", "cs.AI", "cs.AR"], "comment": null, "summary": "Deep neural networks generate and process large volumes of data, posing\nchallenges for low-resource embedded systems. In-memory computing has been\ndemonstrated as an efficient computing infrastructure and shows promise for\nembedded AI applications. Among newly-researched memory technologies, racetrack\nmemory is a non-volatile technology that allows high data density fabrication,\nmaking it a good fit for in-memory computing. However, integrating in-memory\narithmetic circuits with memory cells affects both the memory density and power\nefficiency. It remains challenging to build efficient in-memory arithmetic\ncircuits on racetrack memory within area and energy constraints. To this end,\nwe present an efficient in-memory convolutional neural network (CNN)\naccelerator optimized for use with racetrack memory. We design a series of\nfundamental arithmetic circuits as in-memory computing cells suited for\nmultiply-and-accumulate operations. Moreover, we explore the design space of\nracetrack memory based systems and CNN model architectures, employing co-design\nto improve the efficiency and performance of performing CNN inference in\nracetrack memory while maintaining model accuracy. Our designed circuits and\nmodel-system co-optimization strategies achieve a small memory bank area with\nsignificant improvements in energy and performance for racetrack memory based\nembedded systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8d5b\u9053\u5185\u5b58\u7684\u9ad8\u6548\u5185\u5b58\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4f18\u5316\u7b97\u672f\u7535\u8def\u548c\u6a21\u578b-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff0c\u63d0\u5347\u4e86\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u8fd0\u884c\u65f6\u9762\u4e34\u8d44\u6e90\u9650\u5236\uff0c\u8d5b\u9053\u5185\u5b58\u56e0\u5176\u9ad8\u5bc6\u5ea6\u7279\u6027\u9002\u5408\u5185\u5b58\u8ba1\u7b97\uff0c\u4f46\u5982\u4f55\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u89e3\u51b3\u9762\u79ef\u548c\u80fd\u8017\u6311\u6218\u662f\u5173\u952e\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u9002\u5408\u4e58\u52a0\u64cd\u4f5c\u7684\u5e95\u5c42\u7b97\u672f\u7535\u8def\uff0c\u5e76\u63a2\u7d22\u4e86\u8d5b\u9053\u5185\u5b58\u7cfb\u7edf\u548cCNN\u67b6\u6784\u7684\u534f\u540c\u8bbe\u8ba1\u7a7a\u95f4\u3002", "result": "\u5b9e\u73b0\u4e86\u5c0f\u9762\u79ef\u5185\u5b58\u5e93\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d5b\u9053\u5185\u5b58\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u80fd\u91cf\u548c\u6027\u80fd\u8868\u73b0\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u7684\u7535\u8def\u8bbe\u8ba1\u548c\u534f\u540c\u7b56\u7565\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u8d5b\u9053\u5185\u5b58\u5728\u9ad8\u6027\u80fd\u5d4c\u5165\u5f0fAI\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.01145", "pdf": "https://arxiv.org/pdf/2507.01145", "abs": "https://arxiv.org/abs/2507.01145", "authors": ["Xuesi Chen", "Leo Han", "Anvita Bhagavathula", "Udit Gupta"], "title": "CarbonClarity: Understanding and Addressing Uncertainty in Embodied Carbon for Sustainable Computing", "categories": ["cs.AR"], "comment": null, "summary": "Embodied carbon footprint modeling has become an area of growing interest due\nto its significant contribution to carbon emissions in computing. However, the\ndeterministic nature of the existing models fail to account for the spatial and\ntemporal variability in the semiconductor supply chain. The absence of\nuncertainty modeling limits system designers' ability to make informed,\ncarbon-aware decisions. We introduce CarbonClarity, a probabilistic framework\ndesigned to model embodied carbon footprints through distributions that reflect\nuncertainties in energy-per-area, gas-per-area, yield, and carbon intensity\nacross different technology nodes. Our framework enables a deeper understanding\nof how design choices, such as chiplet architectures and new vs. old technology\nnode selection, impact emissions and their associated uncertainties. For\nexample, we show that the gap between the mean and 95th percentile of embodied\ncarbon per cm$^2$ can reach up to 1.6X for the 7nm technology node.\nAdditionally, we demonstrate through case studies that: (i) CarbonClarity is a\nvaluable resource for device provisioning, help maintaining performance under a\ntight carbon budget; and (ii) chiplet technology and mature nodes not only\nreduce embodied carbon but also significantly lower its associated uncertainty,\nachieving an 18% reduction in the 95th percentile compared to monolithic\ndesigns for the mobile application.", "AI": {"tldr": "CarbonClarity\u662f\u4e00\u4e2a\u6982\u7387\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u534a\u5bfc\u4f53\u4f9b\u5e94\u94fe\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u78b3\u6392\u653e\uff0c\u5e2e\u52a9\u8bbe\u8ba1\u5e08\u505a\u51fa\u66f4\u660e\u667a\u7684\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u78b3\u6392\u653e\u6a21\u578b\u7684\u786e\u5b9a\u6027\u65e0\u6cd5\u53cd\u6620\u534a\u5bfc\u4f53\u4f9b\u5e94\u94fe\u7684\u65f6\u7a7a\u53d8\u5f02\u6027\uff0c\u9650\u5236\u4e86\u8bbe\u8ba1\u5e08\u7684\u78b3\u611f\u77e5\u51b3\u7b56\u80fd\u529b\u3002", "method": "\u5f15\u5165CarbonClarity\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u6a21\u578b\u91cf\u5316\u80fd\u6e90\u3001\u6c14\u4f53\u3001\u826f\u7387\u548c\u78b3\u5f3a\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c7nm\u6280\u672f\u8282\u70b9\u7684\u78b3\u6392\u653e\u5dee\u5f02\u53ef\u8fbe1.6\u500d\uff0c\u82af\u7247\u6280\u672f\u548c\u6210\u719f\u8282\u70b9\u80fd\u663e\u8457\u964d\u4f4e\u78b3\u6392\u653e\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "CarbonClarity\u4e3a\u8bbe\u5907\u914d\u7f6e\u548c\u8bbe\u8ba1\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u82af\u7247\u6280\u672f\u548c\u6210\u719f\u8282\u70b9\u5728\u51cf\u6392\u548c\u964d\u4f4e\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.01113", "pdf": "https://arxiv.org/pdf/2507.01113", "abs": "https://arxiv.org/abs/2507.01113", "authors": ["Vairavan Palaniappan", "Adam H. Ross", "Amit Ranjan Trivedi", "Debjit Pal"], "title": "HERCULES: Hardware accElerator foR stoChastic schedULing in hEterogeneous Systems", "categories": ["cs.DC", "cs.SY", "eess.SY"], "comment": "10 pages, 10 figures, accepted for publication in in Int'l Conference\n  on Computer Aided Design (ICCAD) 2025", "summary": "Efficient workload scheduling is a critical challenge in modern heterogeneous\ncomputing environments, particularly in high-performance computing (HPC)\nsystems. Traditional software-based schedulers struggle to efficiently balance\nworkload distribution due to high scheduling overhead, lack of adaptability to\ndynamic workloads, and suboptimal resource utilization. These pitfalls are\ncompounded in heterogeneous systems, where differing computational elements can\nhave vastly different performance profiles. To resolve these hindrances, we\npresent a novel FPGA-based accelerator for stochastic online scheduling (SOS).\nWe modify a greedy cost selection assignment policy by adapting existing cost\nequations to engage with discretized time before implementing them into a\nhardware accelerator design. Our design leverages hardware parallelism,\nprecalculation, and precision quantization to reduce job scheduling latency. By\nintroducing a hardware-accelerated approach to real-time scheduling, this paper\nestablishes a new paradigm for adaptive scheduling mechanisms in heterogeneous\ncomputing systems. The proposed design achieves high throughput, low latency,\nand energy-efficient operation, offering a scalable alternative to traditional\nsoftware scheduling methods. Experimental results demonstrate consistent\nworkload distribution, fair machine utilization, and up to 1060x speedup over\nsingle-threaded software scheduling policy implementations. This makes the SOS\naccelerator a strong candidate for deployment in high-performance computing\nsystem, deeplearning pipelines, and other performance-critical applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u968f\u673a\u5728\u7ebf\u8c03\u5ea6\uff08SOS\uff09\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u786c\u4ef6\u5e76\u884c\u6027\u548c\u91cf\u5316\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8c03\u5ea6\u5ef6\u8fdf\uff0c\u63d0\u5347\u4e86\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u8c03\u5ea6\u5668\u5728\u9ad8\u6027\u80fd\u5f02\u6784\u8ba1\u7b97\u73af\u5883\u4e2d\u5b58\u5728\u8c03\u5ea6\u5f00\u9500\u9ad8\u3001\u52a8\u6001\u8d1f\u8f7d\u9002\u5e94\u6027\u5dee\u548c\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4fee\u6539\u8d2a\u5a6a\u6210\u672c\u9009\u62e9\u7b56\u7565\uff0c\u7ed3\u5408\u79bb\u6563\u5316\u65f6\u95f4\u548c\u786c\u4ef6\u52a0\u901f\u8bbe\u8ba1\uff0c\u5229\u7528\u786c\u4ef6\u5e76\u884c\u6027\u548c\u91cf\u5316\u6280\u672f\u4f18\u5316\u8c03\u5ea6\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cSOS\u52a0\u901f\u5668\u5b9e\u73b0\u4e86\u9ad8\u541e\u5410\u3001\u4f4e\u5ef6\u8fdf\u548c\u8282\u80fd\u8fd0\u884c\uff0c\u6bd4\u5355\u7ebf\u7a0b\u8f6f\u4ef6\u8c03\u5ea6\u5feb1060\u500d\uff0c\u5e76\u663e\u8457\u6539\u5584\u4e86\u8d1f\u8f7d\u5206\u5e03\u548c\u8d44\u6e90\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u786c\u4ef6\u52a0\u901f\u8c03\u5ea6\u65b9\u6848\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u7b49\u5173\u952e\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.01079", "pdf": "https://arxiv.org/pdf/2507.01079", "abs": "https://arxiv.org/abs/2507.01079", "authors": ["Taehwan Park", "Geonho Lee", "Min-Soo Kim"], "title": "MobileRAG: A Fast, Memory-Efficient, and Energy-Efficient Method for On-Device RAG", "categories": ["cs.DB"], "comment": "14 pages", "summary": "Retrieval-Augmented Generation (RAG) has proven effective on server\ninfrastructures, but its application on mobile devices is still underexplored\ndue to limited memory and power resources. Existing vector search and RAG\nsolutions largely assume abundant computation resources, making them\nimpractical for on-device scenarios. In this paper, we propose MobileRAG, a\nfully on-device pipeline that overcomes these limitations by combining a\nmobile-friendly vector search algorithm, \\textit{EcoVector}, with a lightweight\n\\textit{Selective Content Reduction} (SCR) method. By partitioning and\npartially loading index data, EcoVector drastically reduces both memory\nfootprint and CPU usage, while the SCR method filters out irrelevant text to\ndiminish Language Model (LM) input size without degrading accuracy. Extensive\nexperiments demonstrated that MobileRAG significantly outperforms conventional\nvector search and RAG methods in terms of latency, memory usage, and power\nconsumption, while maintaining accuracy and enabling offline operation to\nsafeguard privacy in resource-constrained environments.", "AI": {"tldr": "MobileRAG\u662f\u4e00\u79cd\u5b8c\u5168\u5728\u8bbe\u5907\u4e0a\u8fd0\u884c\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7EcoVector\u548cSCR\u65b9\u6cd5\u89e3\u51b3\u4e86\u79fb\u52a8\u8bbe\u5907\u8d44\u6e90\u53d7\u9650\u7684\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3001\u5185\u5b58\u548c\u529f\u8017\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u5047\u8bbe\u8ba1\u7b97\u8d44\u6e90\u5145\u8db3\uff0c\u4e0d\u9002\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u7684\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002", "method": "\u7ed3\u5408\u4e86\u79fb\u52a8\u53cb\u597d\u7684EcoVector\u5411\u91cf\u641c\u7d22\u7b97\u6cd5\u548c\u8f7b\u91cf\u7ea7SCR\u65b9\u6cd5\uff0c\u90e8\u5206\u52a0\u8f7d\u7d22\u5f15\u6570\u636e\u5e76\u8fc7\u6ee4\u65e0\u5173\u6587\u672c\u3002", "result": "\u5728\u5ef6\u8fdf\u3001\u5185\u5b58\u548c\u529f\u8017\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u5e76\u652f\u6301\u79bb\u7ebf\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "MobileRAG\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684RAG\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01628", "pdf": "https://arxiv.org/pdf/2507.01628", "abs": "https://arxiv.org/abs/2507.01628", "authors": ["Zilong He", "Pengfei Chen", "Hongyu Zhang", "Xiaoyun Li", "Guangba Yu", "Hongyang Chen", "Zibin Zheng"], "title": "DaiFu: In-Situ Crash Recovery for Deep Learning Systems", "categories": ["cs.SE"], "comment": null, "summary": "Deep learning (DL) systems have been widely adopted in many areas, and are\nbecoming even more popular with the emergence of large language models.\nHowever, due to the complex software stacks involved in their development and\nexecution, crashes are unavoidable and common. Crashes severely waste computing\nresources and hinder development productivity, so efficient crash recovery is\ncrucial. Existing solutions, such as checkpoint-retry, are too heavyweight for\nfast recovery from crashes caused by minor programming errors or transient\nruntime errors. Therefore, we present DaiFu, an in-situ recovery framework for\nDL systems. Through a lightweight code transformation to a given DL system,\nDaiFu augments it to intercept crashes in situ and enables dynamic and instant\nupdates to its program running context (e.g., code, configurations, and other\ndata) for agile crash recovery. Our evaluation shows that DaiFu helps reduce\nthe restore time for crash recovery, achieving a 1372x speedup compared with\nstate-of-the-art solutions. Meanwhile, the overhead of DaiFu is negligible\n(under 0.40%). We also construct a benchmark spanning 7 distinct crash\nscenarios in DL systems, and show the effectiveness of DaiFu in diverse\nsituations.", "AI": {"tldr": "DaiFu\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5373\u65f6\u6062\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u8f6c\u6362\u5b9e\u73b0\u5feb\u901f\u6062\u590d\uff0c\u663e\u8457\u51cf\u5c11\u6062\u590d\u65f6\u95f4\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u56e0\u590d\u6742\u7684\u8f6f\u4ef6\u5806\u6808\u800c\u6613\u5d29\u6e83\uff0c\u73b0\u6709\u6062\u590d\u65b9\u6cd5\uff08\u5982\u68c0\u67e5\u70b9\u91cd\u8bd5\uff09\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4ee3\u7801\u8f6c\u6362\uff0cDaiFu\u80fd\u591f\u62e6\u622a\u5d29\u6e83\u5e76\u52a8\u6001\u66f4\u65b0\u7a0b\u5e8f\u8fd0\u884c\u4e0a\u4e0b\u6587\uff0c\u5b9e\u73b0\u654f\u6377\u6062\u590d\u3002", "result": "DaiFu\u5c06\u6062\u590d\u65f6\u95f4\u7f29\u77ed\u4e861372\u500d\uff0c\u5f00\u9500\u4f4e\u4e8e0.40%\uff0c\u5e76\u5728\u591a\u79cd\u5d29\u6e83\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "DaiFu\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5d29\u6e83\u6062\u590d\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2507.01116", "pdf": "https://arxiv.org/pdf/2507.01116", "abs": "https://arxiv.org/abs/2507.01116", "authors": ["Gong Li", "Benjamin Watson"], "title": "Semiautomatic Simplification", "categories": ["cs.GR"], "comment": null, "summary": "We present semisimp, a tool for semiautomatic simplification of three\ndimensional polygonal models. Existing automatic simplification technology is\nquite mature, but is not sensitive to the heightened importance of distinct\nsemantic model regions such as faces and limbs, nor to simplification\nconstraints imposed by model usage such as animation. semisimp allows users to\npreserve such regions by intervening in the simplification process. Users can\nmanipulate the order in which basic simplifications are applied to redistribute\nmodel detail, improve the simplified models themselves by repositioning\nvertices with propagation to neighboring levels of detail, and adjust the\nhierarchical partitioning of the model surface to segment simplification and\nimprove control of reordering and position propagation.", "AI": {"tldr": "semisimp\u662f\u4e00\u6b3e\u534a\u81ea\u52a8\u7b80\u5316\u4e09\u7ef4\u591a\u8fb9\u5f62\u6a21\u578b\u7684\u5de5\u5177\uff0c\u7528\u6237\u5728\u7b80\u5316\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5e72\u9884\u4ee5\u4fdd\u7559\u91cd\u8981\u533a\u57df\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u7b80\u5316\u6280\u672f\u867d\u7136\u6210\u719f\uff0c\u4f46\u5bf9\u6a21\u578b\u7684\u8bed\u4e49\u533a\u57df\uff08\u5982\u9762\u90e8\u548c\u80a2\u4f53\uff09\u91cd\u8981\u6027\u53ca\u4f7f\u7528\u7ea6\u675f\uff08\u5982\u52a8\u753b\uff09\u4e0d\u654f\u611f\u3002", "method": "semisimp\u5141\u8bb8\u7528\u6237\u8c03\u6574\u7b80\u5316\u64cd\u4f5c\u7684\u987a\u5e8f\uff0c\u91cd\u65b0\u5206\u5e03\u6a21\u578b\u7ec6\u8282\uff0c\u5e76\u901a\u8fc7\u9876\u70b9\u91cd\u5b9a\u4f4d\u548c\u5c42\u6b21\u5206\u533a\u6539\u8fdb\u7b80\u5316\u6a21\u578b\u3002", "result": "\u5de5\u5177\u80fd\u591f\u66f4\u597d\u5730\u4fdd\u7559\u6a21\u578b\u7684\u8bed\u4e49\u533a\u57df\uff0c\u540c\u65f6\u6ee1\u8db3\u7279\u5b9a\u7684\u4f7f\u7528\u7ea6\u675f\u3002", "conclusion": "semisimp\u901a\u8fc7\u7528\u6237\u5e72\u9884\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u6a21\u578b\u7b80\u5316\u63a7\u5236\uff0c\u9002\u7528\u4e8e\u9700\u4fdd\u7559\u5173\u952e\u7ec6\u8282\u7684\u573a\u666f\u3002"}}
{"id": "2507.01664", "pdf": "https://arxiv.org/pdf/2507.01664", "abs": "https://arxiv.org/abs/2507.01664", "authors": ["Hector Gramaglia"], "title": "Globality and Regions", "categories": ["cs.PL", "D.3.1; F.3.2"], "comment": null, "summary": "We obtain a characterization of global variables by unifying abstraction with\nregion abstraction in a region-based language. More precisely, in a previous\nwork a language called global was presented, whose virtue is to provide a\nconceptually clear way of introducing imperative operations in a functional\nlanguage. Memory safety is provided by the concept of linear protection, which\nconnects the global system to a linear one. In this paper we show that the\nconcept of global variable provided by the global language arises from the\nTofte and Talping's region language through the unification of abstraction and\nregion abstraction.", "AI": {"tldr": "\u901a\u8fc7\u7edf\u4e00\u62bd\u8c61\u4e0e\u533a\u57df\u62bd\u8c61\uff0c\u63ed\u793a\u4e86\u5168\u5c40\u53d8\u91cf\u7684\u8868\u5f81\u6765\u6e90\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u51fd\u6570\u5f0f\u8bed\u8a00\u4e2d\u6e05\u6670\u5f15\u5165\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u4fdd\u62a4\u5b9e\u73b0\u5185\u5b58\u5b89\u5168\u3002", "method": "\u7edf\u4e00\u62bd\u8c61\u4e0e\u533a\u57df\u62bd\u8c61\uff0c\u8fde\u63a5\u5168\u5c40\u7cfb\u7edf\u4e0e\u7ebf\u6027\u7cfb\u7edf\u3002", "result": "\u8bc1\u660e\u5168\u5c40\u53d8\u91cf\u6982\u5ff5\u6765\u6e90\u4e8eTofte\u548cTalping\u7684\u533a\u57df\u8bed\u8a00\u3002", "conclusion": "\u5168\u5c40\u53d8\u91cf\u7684\u5b9a\u4e49\u6e90\u4e8e\u533a\u57df\u8bed\u8a00\u4e2d\u7684\u62bd\u8c61\u7edf\u4e00\u3002"}}
{"id": "2507.01780", "pdf": "https://arxiv.org/pdf/2507.01780", "abs": "https://arxiv.org/abs/2507.01780", "authors": ["Eric Vin", "Kyle A. Miller", "Daniel J. Fremont"], "title": "LeanLTL: A unifying framework for linear temporal logics in Lean", "categories": ["cs.LO", "cs.PL", "F.3.1; F.4.1; F.3.3"], "comment": "9 pages, 3 figures; for associated project files see\n  https://github.com/UCSCFormalMethods/LeanLTL; to be published in LIPIcs for\n  ITP '25", "summary": "We propose LeanLTL, a unifying framework for linear temporal logics in Lean\n4. LeanLTL supports reasoning about traces that represent either infinite or\nfinite linear time. The library allows traditional LTL syntax to be combined\nwith arbitrary Lean expressions, making it straightforward to define properties\ninvolving numerical or other types. We prove that standard flavors of LTL can\nbe embedded in our framework. The library also provides automation for\nreasoning about LeanLTL formulas in a way that facilitates using Lean's\nexisting tactics. Finally, we provide examples illustrating the utility of the\nlibrary in reasoning about systems that come from applications.", "AI": {"tldr": "LeanLTL\u662f\u4e00\u4e2a\u5728Lean 4\u4e2d\u7edf\u4e00\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u7684\u6846\u67b6\uff0c\u652f\u6301\u65e0\u9650\u6216\u6709\u9650\u7ebf\u6027\u65f6\u95f4\u7684\u63a8\u7406\uff0c\u5e76\u5141\u8bb8\u7ed3\u5408Lean\u8868\u8fbe\u5f0f\u5b9a\u4e49\u590d\u6742\u5c5e\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u652f\u6301\u591a\u79cd\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u7684\u63a8\u7406\uff0c\u5e76\u7b80\u5316\u6d89\u53ca\u6570\u503c\u6216\u5176\u4ed6\u7c7b\u578b\u7684\u5c5e\u6027\u5b9a\u4e49\u3002", "method": "\u5f00\u53d1\u4e86LeanLTL\u5e93\uff0c\u652f\u6301\u4f20\u7edfLTL\u8bed\u6cd5\u4e0eLean\u8868\u8fbe\u5f0f\u7684\u7ed3\u5408\uff0c\u5e76\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u63a8\u7406\u5de5\u5177\u3002", "result": "\u8bc1\u660e\u6807\u51c6LTL\u53ef\u5d4c\u5165\u6846\u67b6\u4e2d\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u5728\u5e94\u7528\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "LeanLTL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u4e14\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u7cfb\u7edf\u63a8\u7406\uff0c\u5e76\u652f\u6301Lean\u73b0\u6709\u5de5\u5177\u7684\u96c6\u6210\u3002"}}
{"id": "2507.01022", "pdf": "https://arxiv.org/pdf/2507.01022", "abs": "https://arxiv.org/abs/2507.01022", "authors": ["Shayan Dadman", "Bernt Arild Bremdal", "Andreas Bergsland"], "title": "Workflow-Based Evaluation of Music Generation Systems", "categories": ["eess.AS", "cs.HC", "cs.LG", "cs.MM", "cs.SD"], "comment": "54 pages, 3 figures, 6 tables, 5 appendices", "summary": "This study presents an exploratory evaluation of Music Generation Systems\n(MGS) within contemporary music production workflows by examining eight\nopen-source systems. The evaluation framework combines technical insights with\npractical experimentation through criteria specifically designed to investigate\nthe practical and creative affordances of the systems within the iterative,\nnon-linear nature of music production. Employing a single-evaluator methodology\nas a preliminary phase, this research adopts a mixed approach utilizing\nqualitative methods to form hypotheses subsequently assessed through\nquantitative metrics. The selected systems represent architectural diversity\nacross both symbolic and audio-based music generation approaches, spanning\ncomposition, arrangement, and sound design tasks. The investigation addresses\nlimitations of current MGS in music production, challenges and opportunities\nfor workflow integration, and development potential as collaborative tools\nwhile maintaining artistic authenticity. Findings reveal these systems function\nprimarily as complementary tools enhancing rather than replacing human\nexpertise. They exhibit limitations in maintaining thematic and structural\ncoherence that emphasize the indispensable role of human creativity in tasks\ndemanding emotional depth and complex decision-making. This study contributes a\nstructured evaluation framework that considers the iterative nature of music\ncreation. It identifies methodological refinements necessary for subsequent\ncomprehensive evaluations and determines viable areas for AI integration as\ncollaborative tools in creative workflows. The research provides\nempirically-grounded insights to guide future development in the field.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u516b\u79cd\u5f00\u6e90\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\uff08MGS\uff09\u5728\u5f53\u4ee3\u97f3\u4e50\u5236\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6280\u672f\u548c\u5b9e\u8df5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0MGS\u4e3b\u8981\u4e3a\u8f85\u52a9\u5de5\u5177\u800c\u975e\u66ff\u4ee3\u54c1\uff0c\u7a81\u663e\u4e86\u4eba\u7c7b\u521b\u4f5c\u7684\u5173\u952e\u4f5c\u7528\u3002", "motivation": "\u63a2\u8ba8\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u5728\u97f3\u4e50\u5236\u4f5c\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4ee5\u53ca\u5982\u4f55\u5c06\u5176\u4f5c\u4e3a\u534f\u4f5c\u5de5\u5177\u878d\u5165\u975e\u7ebf\u6027\u521b\u4f5c\u6d41\u7a0b\u4e2d\u3002", "method": "\u91c7\u7528\u5355\u8bc4\u4f30\u8005\u65b9\u6cd5\u8bba\uff0c\u7ed3\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\uff0c\u5bf9\u516b\u79cd\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\uff0c\u6db5\u76d6\u4f5c\u66f2\u3001\u7f16\u66f2\u548c\u97f3\u6548\u8bbe\u8ba1\u4efb\u52a1\u3002", "result": "MGS\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u4fdd\u6301\u4e3b\u9898\u548c\u7ed3\u6784\u4e00\u81f4\u6027\u4e0a\u6709\u5c40\u9650\uff0c\u5f3a\u8c03\u4e86\u4eba\u7c7b\u521b\u9020\u529b\u5728\u590d\u6742\u51b3\u7b56\u4e2d\u7684\u4e0d\u53ef\u66ff\u4ee3\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u4e3a\u672a\u6765AI\u5728\u521b\u610f\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u534f\u4f5c\u5e94\u7528\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.01289", "pdf": "https://arxiv.org/pdf/2507.01289", "abs": "https://arxiv.org/abs/2507.01289", "authors": ["Enzhi Zhou", "Yue Xiao", "Ziyue Liu", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis", "George K. Karagiannidis"], "title": "Fluid Aerial Networks: UAV Rotation for Inter-Cell Interference Mitigation", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "With the rapid development of aerial infrastructure, unmanned aerial vehicles\n(UAVs) that function as aerial base stations (ABSs) extend terrestrial network\nservices into the sky, enabling on-demand connectivity and enhancing emergency\ncommunication capabilities in cellular networks by leveraging the flexibility\nand mobility of UAVs. In such a UAV-assisted network, this paper investigates\nposition-based beamforming between ABSs and ground users (GUs). To mitigate\ninter-cell interference, we propose a novel fluid aerial network that leverages\nABS rotation to increase multi-cell capacity and overall network efficiency.\nSpecifically, considering the line-of-sight channel model, the spatial\nbeamforming weights are determined by the orientation angles of the GUs. In\nthis direction, we examine the beamforming gain of a two-dimensional\nmultiple-input multiple-output (MIMO) array at various ground positions,\nrevealing that ABS rotation significantly affects multi-user channel\ncorrelation and inter-cell interference. Based on these findings, we propose an\nalternative low-complexity algorithm to design the optimal rotation angle for\nABSs, aiming to reduce inter-cell interference and thus maximize the sum rate\nof multi-cell systems. In simulations, exhaustive search serves as a benchmark\nto validate the optimization performance of the proposed sequential ABS\nrotation scheme. Moreover, simulation results demonstrate that, in\ninterference-limited regions, the proposed ABS rotation paradigm can\nsignificantly reduce inter-cell interference in terrestrial networks and\nimprove the multi-cell sum rate by approximately 10\\% compared to\nfixed-direction ABSs without rotation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65e0\u4eba\u673a\u8f85\u52a9\u7f51\u7edc\u4e2d\u57fa\u4e8e\u4f4d\u7f6e\u7684\u6ce2\u675f\u6210\u5f62\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u65e0\u4eba\u673a\u65cb\u8f6c\u51cf\u5c11\u5c0f\u533a\u95f4\u5e72\u6270\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f51\u7edc\u6548\u7387\u548c\u5bb9\u91cf\u3002", "motivation": "\u4e3a\u4e86\u6269\u5c55\u5730\u9762\u7f51\u7edc\u670d\u52a1\u5e76\u63d0\u5347\u5e94\u6025\u901a\u4fe1\u80fd\u529b\uff0c\u65e0\u4eba\u673a\u4f5c\u4e3a\u7a7a\u4e2d\u57fa\u7ad9\u88ab\u5e7f\u6cdb\u5e94\u7528\u3002\u7136\u800c\uff0c\u5c0f\u533a\u95f4\u5e72\u6270\u662f\u5f71\u54cd\u7f51\u7edc\u6548\u7387\u7684\u4e3b\u8981\u6311\u6218\u4e4b\u4e00\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u4f53\u7a7a\u4e2d\u7f51\u7edc\u65b9\u6848\uff0c\u5229\u7528\u65e0\u4eba\u673a\u65cb\u8f6c\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u6743\u91cd\uff0c\u5e76\u901a\u8fc7\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u8bbe\u8ba1\u6700\u4f73\u65cb\u8f6c\u89d2\u5ea6\u4ee5\u51cf\u5c11\u5e72\u6270\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5e72\u6270\u53d7\u9650\u533a\u57df\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u5e72\u6270\uff0c\u5e76\u5c06\u591a\u5c0f\u533a\u603b\u548c\u901f\u7387\u63d0\u5347\u7ea610%\u3002", "conclusion": "\u65e0\u4eba\u673a\u65cb\u8f6c\u65b9\u6848\u662f\u4e00\u79cd\u6709\u6548\u51cf\u5c11\u5c0f\u533a\u95f4\u5e72\u6270\u5e76\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u7684\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01121", "pdf": "https://arxiv.org/pdf/2507.01121", "abs": "https://arxiv.org/abs/2507.01121", "authors": ["Hafsah Mahzabin Chowdhury", "Sharifa Sultana"], "title": "From Literature to ReWA: Discussing Reproductive Well-being in HCI", "categories": ["cs.HC", "cs.CY"], "comment": "23 pages", "summary": "Reproductive well-being is shaped by intersecting cultural, religious,\ngendered, and political contexts, yet current technologies often reflect\nnarrow, Western-centric assumptions. In this literature review, we synthesize\nfindings from 147 peer-reviewed papers published between 2015 and 2025 across\nHCI, CSCW and social computing, ICTD, digital and public health, and AI for\nwell-being scholarship to map the evolving reproductive well-being landscape.\nWe identify three thematic waves that focused on early access and education,\ncultural sensitivity and privacy, and AI integration with policy-aware design,\nand highlight how technologies support or constrain diverse reproductive\nexperiences. Our analysis reveals critical gaps in inclusivity, with persistent\nexclusions of men and non-binary users, migrants, and users in the Global\nSouth. Additionally, we surfaced the significant absence of literature on the\nrole of stakeholders (e.g., husband and family members, household maids and\ncleaning helping hands, midwife, etc.) in the reproductive well-being space.\nDrawing on the findings from the literature, we propose the ReWA framework to\nsupport reproductive well-being for all agendas through six design orientations\nassociated with: location, culture, and history; polyvocality and agency;\nrationality, temporality, distributive roles, and methodology.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86147\u7bc72015-2025\u5e74\u7684\u6587\u732e\uff0c\u63ed\u793a\u4e86\u751f\u6b96\u798f\u7949\u6280\u672f\u7684\u6f14\u53d8\u53ca\u5176\u5728\u6587\u5316\u654f\u611f\u6027\u3001\u9690\u79c1\u548cAI\u6574\u5408\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u4f46\u6307\u51fa\u4e86\u5168\u7403\u5357\u65b9\u3001\u7537\u6027\u548c\u975e\u4e8c\u5143\u7528\u6237\u7b49\u7fa4\u4f53\u7684\u7f3a\u5931\u95ee\u9898\uff0c\u5e76\u63d0\u51faReWA\u6846\u67b6\u4ee5\u6539\u8fdb\u8bbe\u8ba1\u3002", "motivation": "\u63a2\u8ba8\u751f\u6b96\u798f\u7949\u6280\u672f\u5982\u4f55\u53d7\u6587\u5316\u3001\u5b97\u6559\u3001\u6027\u522b\u548c\u653f\u6cbb\u56e0\u7d20\u5f71\u54cd\uff0c\u5e76\u63ed\u793a\u5f53\u524d\u6280\u672f\u7684\u897f\u65b9\u4e2d\u5fc3\u4e3b\u4e49\u5c40\u9650\u53ca\u5176\u5bf9\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u6392\u65a5\u3002", "method": "\u901a\u8fc7\u5bf9HCI\u3001CSCW\u3001\u793e\u4f1a\u8ba1\u7b97\u7b49\u9886\u57df\u7684147\u7bc7\u6587\u732e\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u4e09\u4e2a\u4e3b\u9898\u6d6a\u6f6e\uff0c\u5e76\u63d0\u51faReWA\u6846\u67b6\u3002", "result": "\u53d1\u73b0\u6280\u672f\u8bbe\u8ba1\u5728\u5305\u5bb9\u6027\u4e0a\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u5c24\u5176\u662f\u5bf9\u5168\u7403\u5357\u65b9\u3001\u7537\u6027\u3001\u975e\u4e8c\u5143\u7528\u6237\u548c\u5229\u76ca\u76f8\u5173\u8005\u7684\u5ffd\u89c6\u3002", "conclusion": "\u63d0\u51faReWA\u6846\u67b6\uff0c\u5f3a\u8c03\u8bbe\u8ba1\u5e94\u8003\u8651\u5730\u7406\u4f4d\u7f6e\u3001\u6587\u5316\u5386\u53f2\u3001\u591a\u5143\u58f0\u97f3\u548c\u4ee3\u7406\u6743\u7b49\u56e0\u7d20\uff0c\u4ee5\u63d0\u5347\u751f\u6b96\u798f\u7949\u6280\u672f\u7684\u5305\u5bb9\u6027\u3002"}}
{"id": "2507.01195", "pdf": "https://arxiv.org/pdf/2507.01195", "abs": "https://arxiv.org/abs/2507.01195", "authors": ["Yuqian Huo", "Jinbiao Wei", "Christopher Kverne", "Mayur Akewar", "Janki Bhimani", "Tirthak Patel"], "title": "Revisiting Noise-adaptive Transpilation in Quantum Computing: How Much Impact Does it Have?", "categories": ["quant-ph", "cs.ET"], "comment": "This paper will appear in the Proceedings of the International\n  Conference on Computer-Aided Design (ICCAD), 2025", "summary": "Transpilation, particularly noise-aware optimization, is widely regarded as\nessential for maximizing the performance of quantum circuits on superconducting\nquantum computers. The common wisdom is that each circuit should be transpiled\nusing up-to-date noise calibration data to optimize fidelity. In this work, we\nrevisit the necessity of frequent noise-adaptive transpilation, conducting an\nin-depth empirical study across five IBM 127-qubit quantum computers and 16\ndiverse quantum algorithms. Our findings reveal novel and interesting insights:\n(1) noise-aware transpilation leads to a heavy concentration of workloads on a\nsmall subset of qubits, which increases output error variability; (2) using\nrandom mapping can mitigate this effect while maintaining comparable average\nfidelity; and (3) circuits compiled once with calibration data can be reliably\nreused across multiple calibration cycles and time periods without significant\nloss in fidelity. These results suggest that the classical overhead associated\nwith daily, per-circuit noise-aware transpilation may not be justified. We\npropose lightweight alternatives that reduce this overhead without sacrificing\nfidelity -- offering a path to more efficient and scalable quantum workflows.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u9891\u7e41\u7684\u566a\u58f0\u611f\u77e5\u8f6c\u8bd1\u5e76\u975e\u5fc5\u8981\uff0c\u968f\u673a\u6620\u5c04\u548c\u4e00\u6b21\u6027\u7f16\u8bd1\u53ef\u4ee5\u9ad8\u6548\u66ff\u4ee3\u3002", "motivation": "\u63a2\u8ba8\u566a\u58f0\u611f\u77e5\u8f6c\u8bd1\u7684\u5fc5\u8981\u6027\u53ca\u5176\u5bf9\u91cf\u5b50\u7535\u8def\u6027\u80fd\u548c\u6548\u7387\u7684\u5f71\u54cd\u3002", "method": "\u5728\u4e94\u53f0IBM 127\u91cf\u5b50\u4f4d\u7684\u8ba1\u7b97\u673a\u4e0a\uff0c\u5bf916\u79cd\u91cf\u5b50\u7b97\u6cd5\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u566a\u58f0\u611f\u77e5\u8f6c\u8bd1\u4f1a\u5bfc\u81f4\u5de5\u4f5c\u8d1f\u8f7d\u96c6\u4e2d\u5728\u5c11\u6570\u91cf\u5b50\u4f4d\u4e0a\uff0c\u589e\u52a0\u8bef\u5dee\u53d8\u5f02\u6027\uff1b\u968f\u673a\u6620\u5c04\u548c\u4e00\u6b21\u6027\u7f16\u8bd1\u53ef\u4fdd\u6301\u76f8\u8fd1\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\uff0c\u51cf\u5c11\u8f6c\u8bd1\u5f00\u9500\u800c\u4e0d\u727a\u7272\u4fdd\u771f\u5ea6\uff0c\u63d0\u5347\u91cf\u5b50\u5de5\u4f5c\u6d41\u7684\u6548\u7387\u3002"}}
{"id": "2507.01309", "pdf": "https://arxiv.org/pdf/2507.01309", "abs": "https://arxiv.org/abs/2507.01309", "authors": ["Zhican Wang", "Guanghui He", "Hongxiang Fan"], "title": "SD-Acc: Accelerating Stable Diffusion through Phase-aware Sampling and Hardware Co-Optimizations", "categories": ["cs.AR"], "comment": "Under Review", "summary": "The emergence of diffusion models has significantly advanced generative AI,\nimproving the quality, realism, and creativity of image and video generation.\nAmong them, Stable Diffusion (StableDiff) stands out as a key model for\ntext-to-image generation and a foundation for next-generation multi-modal\nalgorithms. However, its high computational and memory demands hinder inference\nspeed and energy efficiency. To address these challenges, we identify three\ncore issues: (1) intensive and often redundant computations, (2) heterogeneous\noperations involving convolutions and attention mechanisms, and (3) diverse\nweight and activation sizes.\n  We present SD-Acc, a novel algorithm and hardware co-optimization framework.\nAt the algorithm level, we observe that high-level features in certain\ndenoising phases show significant similarity, enabling approximate computation.\nLeveraging this, we propose an adaptive, phase-aware sampling strategy that\nreduces compute and memory loads. This framework automatically balances image\nquality and complexity based on the StableDiff model and user requirements. At\nthe hardware level, we design an address-centric dataflow to efficiently handle\nheterogeneous operations within a simple systolic array. We address the\nbottleneck of nonlinear functions via a two-stage streaming architecture and a\nreconfigurable vector processing unit. Additionally, we implement adaptive\ndataflow optimizations by combining dynamic reuse and operator fusion tailored\nto StableDiff workloads, significantly reducing memory access. Across multiple\nStableDiff models, our method achieves up to a 3x reduction in computational\ndemand without compromising image quality. Combined with our optimized hardware\naccelerator, SD-Acc delivers higher speed and energy efficiency than\ntraditional CPU and GPU implementations.", "AI": {"tldr": "SD-Acc\u662f\u4e00\u79cd\u9488\u5bf9Stable Diffusion\u6a21\u578b\u7684\u7b97\u6cd5\u4e0e\u786c\u4ef6\u534f\u540c\u4f18\u5316\u6846\u67b6\uff0c\u53ef\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u4e0e\u80fd\u6e90\u5229\u7528\u7387\u3002", "motivation": "Stable Diffusion\u6a21\u578b\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u4e0a\u7684\u9ad8\u8d1f\u62c5\u9650\u5236\u4e86\u5176\u63a8\u7406\u901f\u5ea6\u548c\u80fd\u6e90\u6548\u7387\u3002", "method": "\u7b97\u6cd5\u5c42\u901a\u8fc7\u81ea\u9002\u5e94\u76f8\u4f4d\u611f\u77e5\u91c7\u6837\u51cf\u5c11\u8ba1\u7b97\u548c\u5185\u5b58\u8d1f\u8f7d\uff1b\u786c\u4ef6\u5c42\u91c7\u7528\u5730\u5740\u4e2d\u5fc3\u6570\u636e\u6d41\u548c\u4e24\u9636\u6bb5\u6d41\u5f0f\u67b6\u6784\u4f18\u5316\u975e\u7ebf\u6027\u548c\u5f02\u6784\u64cd\u4f5c\u3002", "result": "SD-Acc\u5728\u51cf\u5c113\u500d\u8ba1\u7b97\u9700\u6c42\u7684\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\uff0c\u786c\u4ef6\u52a0\u901f\u5668\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edfCPU/GPU\u66f4\u9ad8\u7684\u901f\u5ea6\u548c\u80fd\u6548\u3002", "conclusion": "SD-Acc\u901a\u8fc7\u7b97\u6cd5\u4e0e\u786c\u4ef6\u534f\u540c\u4f18\u5316\uff0c\u4e3aStable Diffusion\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01224", "pdf": "https://arxiv.org/pdf/2507.01224", "abs": "https://arxiv.org/abs/2507.01224", "authors": ["Wenqi Jia", "Ying Huang", "Jian Xu", "Zhewen Hu", "Sian Jin", "Jiannan Tian", "Yuede Ji", "Miao Yin"], "title": "FLARE: A Dataflow-Aware and Scalable Hardware Architecture for Neural-Hybrid Scientific Lossy Compression", "categories": ["cs.DC"], "comment": null, "summary": "Scientific simulation leveraging high-performance computing (HPC) systems is\ncrucial for modeling complex systems and phenomena in fields such as\nastrophysics, climate science, and fluid dynamics, generating massive datasets\nthat often reach petabyte to exabyte scales. However, managing these vast data\nvolumes introduces significant I/O and network bottlenecks, limiting practical\nperformance and scalability. While cutting-edge lossy compression frameworks\npowered by deep neural networks (DNNs) have demonstrated superior compression\nratios by capturing complex data correlations, their integration into HPC\nworkflows poses substantial challenges due to the hybrid non-neural and neural\ncomputation patterns, causing excessive memory access overhead, large\nsequential stalls, and limited adaptability to varying data sizes and workloads\nin existing hardware platforms. To overcome these challenges and push the limit\nof high-performance scientific computing, we for the first time propose FLARE,\na dataflow-aware and scalable hardware architecture for neural-hybrid\nscientific lossy compression. FLARE minimizes off-chip data access, reduces\nbubble overhead through efficient dataflow, and adopts a modular design that\nprovides both scalability and flexibility, significantly enhancing throughput\nand energy efficiency on modern HPC systems. Particularly, the proposed FLARE\nachieves runtime speedups ranging from $3.50 \\times$ to $96.07 \\times$, and\nenergy efficiency improvements ranging from $24.51 \\times$ to $520.68 \\times$,\nacross various datasets and hardware platforms.", "AI": {"tldr": "FLARE\u662f\u4e00\u79cd\u9488\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u795e\u7ecf\u6df7\u5408\u65e0\u635f\u538b\u7f29\u7684\u6570\u636e\u6d41\u611f\u77e5\u786c\u4ef6\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u548c\u80fd\u6548\u3002", "motivation": "\u79d1\u5b66\u6a21\u62df\u4ea7\u751f\u6d77\u91cf\u6570\u636e\uff0c\u4f46\u73b0\u6709\u538b\u7f29\u6846\u67b6\u5b58\u5728I/O\u548c\u7f51\u7edc\u74f6\u9888\uff0cFLARE\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faFLARE\u67b6\u6784\uff0c\u901a\u8fc7\u51cf\u5c11\u7247\u5916\u6570\u636e\u8bbf\u95ee\u548c\u4f18\u5316\u6570\u636e\u6d41\u6765\u63d0\u9ad8\u6548\u7387\u3002", "result": "FLARE\u5728\u8fd0\u884c\u901f\u5ea6\u548c\u80fd\u6548\u4e0a\u5206\u522b\u63d0\u5347\u4e863.5\u81f396.07\u500d\u548c24.51\u81f3520.68\u500d\u3002", "conclusion": "FLARE\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u6570\u636e\u538b\u7f29\u7684\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2507.01461", "pdf": "https://arxiv.org/pdf/2507.01461", "abs": "https://arxiv.org/abs/2507.01461", "authors": ["Styliani Kyrama", "Anastasios Gounaris"], "title": "Handling out-of-order input arrival in CEP engines on the edge combining optimistic, pessimistic and lazy evaluation", "categories": ["cs.DB"], "comment": null, "summary": "In Complex Event Processing, handling out-of-order, late, and duplicate\nevents is critical for real-time analytics, especially on resource-constrained\ndevices that process heterogeneous data from multiple sources. We present\nLimeCEP, a hybrid CEP approach that combines lazy evaluation, buffering, and\nspeculative processing to efficiently handle data inconsistencies while\nsupporting multi-pattern detection under relaxed semantics. LimeCEP integrates\nKafka for efficient message ordering, retention, and duplicate elimination, and\noffers configurable strategies to trade off between accuracy, latency, and\nresource consumption. Compared to state-of-the-art systems like SASE and\nFlinkCEP, LimeCEP achieves up to six orders of magnitude lower latency, with up\nto 10 times lower memory usage and 6 times lower CPU utilization, while\nmaintaining near-perfect precision and recall under high-disorder input\nstreams, making it well-suited for non-cloud deployments.", "AI": {"tldr": "LimeCEP\u662f\u4e00\u79cd\u6df7\u5408CEP\u65b9\u6cd5\uff0c\u901a\u8fc7\u61d2\u60f0\u8bc4\u4f30\u3001\u7f13\u51b2\u548c\u63a8\u6d4b\u5904\u7406\u9ad8\u6548\u5904\u7406\u6570\u636e\u4e0d\u4e00\u81f4\u6027\uff0c\u652f\u6301\u591a\u6a21\u5f0f\u68c0\u6d4b\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u4e8b\u4ef6\u5904\u7406\u4e2d\u4e71\u5e8f\u3001\u5ef6\u8fdf\u548c\u91cd\u590d\u4e8b\u4ef6\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u3002", "method": "\u7ed3\u5408\u61d2\u60f0\u8bc4\u4f30\u3001\u7f13\u51b2\u548c\u63a8\u6d4b\u5904\u7406\uff0c\u96c6\u6210Kafka\u4f18\u5316\u6d88\u606f\u987a\u5e8f\u548c\u53bb\u91cd\uff0c\u63d0\u4f9b\u53ef\u914d\u7f6e\u7b56\u7565\u3002", "result": "\u76f8\u6bd4SASE\u548cFlinkCEP\uff0c\u5ef6\u8fdf\u964d\u4f4e\u516d\u4e2a\u6570\u91cf\u7ea7\uff0c\u5185\u5b58\u548cCPU\u4f7f\u7528\u663e\u8457\u51cf\u5c11\uff0c\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u3002", "conclusion": "LimeCEP\u9002\u5408\u975e\u4e91\u7aef\u90e8\u7f72\uff0c\u9ad8\u6548\u5904\u7406\u9ad8\u4e71\u5e8f\u8f93\u5165\u6d41\u3002"}}
{"id": "2507.01827", "pdf": "https://arxiv.org/pdf/2507.01827", "abs": "https://arxiv.org/abs/2507.01827", "authors": ["Haichuan Hu", "Congqing He", "Hao Zhang", "Xiaochen Xie", "Quanjun Zhang"], "title": "APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search", "categories": ["cs.SE"], "comment": null, "summary": "Automated Program Repair (APR) attempts to fix software bugs without human\nintervention, which plays a crucial role in software development and\nmaintenance. Recently, with the advances in Large Language Models (LLMs), a\nrapidly increasing number of APR techniques have been proposed with remarkable\nperformance. However, existing LLM-based APR techniques typically adopt\ntrial-and-error strategies, which suffer from two major drawbacks: (1)\ninherently limited patch effectiveness due to local exploration, and (2) low\nsearch efficiency due to redundant exploration. In this paper, we propose\nAPRMCTS, which uses iterative tree search to improve LLM-based APR. APRMCTS\nincorporates Monte Carlo Tree Search (MCTS) into patch searching by performing\na global evaluation of the explored patches and selecting the most promising\none for subsequent refinement and generation. APRMCTS effectively resolves the\nproblems of falling into local optima and thus helps improve the efficiency of\npatch searching. Our experiments on 835 bugs from Defects4J demonstrate that,\nwhen integrated with GPT-3.5, APRMCTS can fix a total of 201 bugs, which\noutperforms all state-of-the-art baselines. Besides, APRMCTS helps GPT-4o-mini,\nGPT-3.5, Yi-Coder-9B, and Qwen2.5-Coder-7B to fix 30, 27, 37, and 28 more bugs,\nrespectively. More importantly, APRMCTS boasts a significant performance\nadvantage while employing small patch size (16 and 32), notably fewer than the\n500 and 10,000 patches adopted in previous studies. In terms of cost, compared\nto existing state-of-the-art LLM-based APR methods, APRMCTS has time and\nmonetary costs of less than 20% and 50%, respectively. Our extensive study\ndemonstrates that APRMCTS exhibits good effectiveness and efficiency, with\nparticular advantages in addressing complex bugs.", "AI": {"tldr": "APRMCTS\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6539\u8fdb\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff0c\u89e3\u51b3\u4e86\u5c40\u90e8\u63a2\u7d22\u548c\u5197\u4f59\u641c\u7d22\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u6280\u672f\u5b58\u5728\u5c40\u90e8\u63a2\u7d22\u548c\u5197\u4f59\u641c\u7d22\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u4fee\u8865\u6548\u679c\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faAPRMCTS\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u8fdb\u884c\u5168\u5c40\u8bc4\u4f30\u548c\u8fed\u4ee3\u6811\u641c\u7d22\uff0c\u4f18\u5316\u4fee\u8865\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728Defects4J\u7684835\u4e2abug\u4e0a\uff0cAPRMCTS\u4fee\u590d\u4e86201\u4e2abug\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u6210\u672c\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "APRMCTS\u5728\u590d\u6742bug\u4fee\u590d\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM-based APR\u7684\u6027\u80fd\u3002"}}
{"id": "2507.01140", "pdf": "https://arxiv.org/pdf/2507.01140", "abs": "https://arxiv.org/abs/2507.01140", "authors": ["Eric Zimmermann", "Stefan Bruckner"], "title": "Multi-Focus Probes for Context-Preserving Network Exploration and Interaction in Immersive Analytics", "categories": ["cs.GR"], "comment": "5 pages, 3 figures, IEEE Vis 2025", "summary": "Immersive visualization of network data enables users to physically navigate\nand interact with complex structures, but managing transitions between detailed\nlocal (egocentric) views and global (exocentric) overviews remains a major\nchallenge. We present a multifocus probe technique for immersive environments\nthat allows users to instantiate multiple egocentric subgraph views while\nmaintaining persistent links to the global network context. Each probe acts as\na portable local focus, enabling fine-grained inspection and editing of distant\nor occluded regions. Visual and haptic guidance mechanisms ensure context\npreservation during multi-scale interaction. We demonstrate and discuss the\nusability of our technique for the editing of network data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6c89\u6d78\u5f0f\u73af\u5883\u7684\u591a\u7126\u70b9\u63a2\u9488\u6280\u672f\uff0c\u65e8\u5728\u89e3\u51b3\u7528\u6237\u5728\u5c40\u90e8\u548c\u5168\u5c40\u89c6\u56fe\u4e4b\u95f4\u5207\u6362\u65f6\u7684\u6311\u6218\u3002", "motivation": "\u7ba1\u7406\u590d\u6742\u7f51\u7edc\u6570\u636e\u7684\u5c40\u90e8\u548c\u5168\u5c40\u89c6\u56fe\u4e4b\u95f4\u7684\u8fc7\u6e21\u662f\u4e3b\u8981\u96be\u9898\uff0c\u9700\u8981\u4e00\u79cd\u6280\u672f\u6765\u540c\u65f6\u652f\u6301\u591a\u5c3a\u5ea6\u4ea4\u4e92\u3002", "method": "\u91c7\u7528\u591a\u7126\u70b9\u63a2\u9488\u6280\u672f\uff0c\u5141\u8bb8\u7528\u6237\u5728\u6c89\u6d78\u5f0f\u73af\u5883\u4e2d\u5b9e\u4f8b\u5316\u591a\u4e2a\u5c40\u90e8\u89c6\u56fe\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5168\u5c40\u4e0a\u4e0b\u6587\u7684\u94fe\u63a5\uff1b\u540c\u65f6\u5229\u7528\u89c6\u89c9\u548c\u89e6\u89c9\u5f15\u5bfc\u673a\u5236\u786e\u4fdd\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u652f\u6301\u7528\u6237\u5728\u7f16\u8f91\u7f51\u7edc\u6570\u636e\u65f6\u8fdb\u884c\u591a\u5c3a\u5ea6\u4ea4\u4e92\uff0c\u5e76\u4fdd\u6301\u4e0a\u4e0b\u6587\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u591a\u7126\u70b9\u63a2\u9488\u6280\u672f\u5728\u6c89\u6d78\u5f0f\u73af\u5883\u4e2d\u6709\u6548\u89e3\u51b3\u4e86\u5c40\u90e8\u4e0e\u5168\u5c40\u89c6\u56fe\u5207\u6362\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u7f51\u7edc\u6570\u636e\u7684\u53ef\u7f16\u8f91\u6027\u548c\u4ea4\u4e92\u4f53\u9a8c\u3002"}}
{"id": "2507.01459", "pdf": "https://arxiv.org/pdf/2507.01459", "abs": "https://arxiv.org/abs/2507.01459", "authors": ["Yijia Chen", "J\u00f6rg Flum", "Mingjun Liu"], "title": "Some remarks on the uncolored versions of the original CFI-graphs", "categories": ["cs.DM", "cs.LO", "math.CO"], "comment": "46 pages", "summary": "The CFI-graphs, named after Cai, F\\\"urer, and Immerman, are central to the\nstudy of the graph isomorphism testing and of first-order logic with counting.\nThey are colored graphs, and the coloring plays a role in many of their\napplications. As usual, it is not hard to remove the coloring by some extra\ngraph gadgets, but at the cost of blowing up the size of the graphs and\nchanging some parameters of them as well. This might lead to suboptimal\ncombinatorial bounds important to their applications. Since then for some\nuncolored variants of the CFI-graphs it has been shown that they serve the same\npurposes. We show that this already applies to the graphs obtained from the\noriginal CFI-graphs by forgetting the colors. Moreover, we will see that there\nis a first-order formula $\\varphi(x,y)$ expressing in almost all uncolored\nCFI-graphs that $x$ and $y$ have the same color in the corresponding colored\ngraphs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u53bb\u9664CFI\u56fe\u7684\u989c\u8272\u540e\uff0c\u5176\u6838\u5fc3\u6027\u8d28\u4ecd\u80fd\u4fdd\u7559\uff0c\u4e14\u53ef\u4ee5\u901a\u8fc7\u4e00\u9636\u516c\u5f0f\u6062\u590d\u989c\u8272\u4fe1\u606f\u3002", "motivation": "CFI\u56fe\u5728\u56fe\u540c\u6784\u6d4b\u8bd5\u548c\u5e26\u8ba1\u6570\u7684\u903b\u8f91\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u53bb\u9664\u989c\u8272\u4f1a\u6539\u53d8\u56fe\u7684\u53c2\u6570\u548c\u89c4\u6a21\uff0c\u53ef\u80fd\u5f71\u54cd\u5e94\u7528\u4e2d\u7684\u7ec4\u5408\u8fb9\u754c\u3002\u7814\u7a76\u53d1\u73b0\u65e0\u9700\u989c\u8272\u7684CFI\u53d8\u4f53\u4e5f\u80fd\u8fbe\u5230\u76f8\u540c\u6548\u679c\u3002", "method": "\u901a\u8fc7\u53bb\u9664\u539f\u59cbCFI\u56fe\u7684\u989c\u8272\uff0c\u7814\u7a76\u5176\u6027\u8d28\u662f\u5426\u4fdd\u7559\uff0c\u5e76\u6784\u9020\u4e00\u9636\u516c\u5f0f\u03c6(x,y)\uff0c\u5728\u5927\u591a\u6570\u53bb\u8272CFI\u56fe\u4e2d\u6062\u590d\u989c\u8272\u4fe1\u606f\u3002", "result": "\u53bb\u8272\u540e\u7684CFI\u56fe\u4ecd\u80fd\u4fdd\u7559\u539f\u59cb\u56fe\u7684\u6838\u5fc3\u6027\u8d28\uff0c\u4e14\u53ef\u4ee5\u901a\u8fc7\u4e00\u9636\u516c\u5f0f\u03c6(x,y)\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u91cd\u65b0\u8868\u8fbe\u989c\u8272\u5173\u7cfb\u3002", "conclusion": "CFI\u56fe\u7684\u989c\u8272\u5e76\u975e\u5fc5\u9700\uff0c\u53bb\u8272\u540e\u4ecd\u80fd\u6ee1\u8db3\u5e94\u7528\u9700\u6c42\uff0c\u4e14\u989c\u8272\u4fe1\u606f\u53ef\u4ee5\u901a\u8fc7\u903b\u8f91\u516c\u5f0f\u6062\u590d\u3002"}}
{"id": "2507.01582", "pdf": "https://arxiv.org/pdf/2507.01582", "abs": "https://arxiv.org/abs/2507.01582", "authors": ["Jing Luo", "Xinyu Yang", "Jie Wei"], "title": "Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "comment": "Accepted by IEEE SMC 2025", "summary": "The creativity of classical music arises not only from composers who craft\nthe musical sheets but also from performers who interpret the static notations\nwith expressive nuances. This paper addresses the challenge of generating\nclassical piano performances from scratch, aiming to emulate the dual roles of\ncomposer and pianist in the creative process. We introduce the Expressive\nCompound Word (ECP) representation, which effectively captures both the\nmetrical structure and expressive nuances of classical performances. Building\non this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a\nmodel featuring two branches: a Vector Quantized Variational AutoEncoder\n(VQ-VAE) branch that generates score-related content, representing the\nComposer, and a vanilla VAE branch that produces expressive details, fulfilling\nthe role of Pianist. These branches are jointly trained with similar Seq2Seq\narchitectures, leveraging a multiscale encoder to capture beat-level contextual\ninformation and an orthogonal Transformer decoder for efficient compound tokens\ndecoding. Both objective and subjective evaluations demonstrate that XMVAE\ngenerates classical performances with superior musical quality compared to\nstate-of-the-art models. Furthermore, pretraining the Composer branch on extra\nmusical score datasets contribute to a significant performance gain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ECP\u8868\u793a\u548cXMVAE\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u8868\u73b0\u529b\u7684\u53e4\u5178\u94a2\u7434\u6f14\u594f\uff0c\u6a21\u62df\u4f5c\u66f2\u5bb6\u548c\u94a2\u7434\u5bb6\u7684\u53cc\u91cd\u89d2\u8272\u3002", "motivation": "\u89e3\u51b3\u4ece\u96f6\u5f00\u59cb\u751f\u6210\u53e4\u5178\u94a2\u7434\u6f14\u594f\u7684\u6311\u6218\uff0c\u6355\u6349\u4f5c\u66f2\u5bb6\u548c\u94a2\u7434\u5bb6\u5728\u521b\u4f5c\u8fc7\u7a0b\u4e2d\u7684\u53cc\u91cd\u89d2\u8272\u3002", "method": "\u5f15\u5165ECP\u8868\u793a\u6355\u83b7\u97f3\u4e50\u7ed3\u6784\u548c\u8868\u73b0\u7ec6\u8282\uff1b\u63d0\u51faXMVAE\u6a21\u578b\uff0c\u5305\u542bVQ-VAE\u5206\u652f\uff08\u4f5c\u66f2\u5bb6\uff09\u548cVAE\u5206\u652f\uff08\u94a2\u7434\u5bb6\uff09\uff0c\u8054\u5408\u8bad\u7ec3\u5e76\u5229\u7528\u591a\u5c3a\u5ea6\u7f16\u7801\u5668\u548cTransformer\u89e3\u7801\u5668\u3002", "result": "XMVAE\u751f\u6210\u7684\u6f14\u594f\u5728\u5ba2\u89c2\u548c\u4e3b\u89c2\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u9884\u8bad\u7ec3\u4f5c\u66f2\u5bb6\u5206\u652f\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "XMVAE\u6709\u6548\u6a21\u62df\u4e86\u4f5c\u66f2\u5bb6\u548c\u94a2\u7434\u5bb6\u7684\u521b\u4f5c\u8fc7\u7a0b\uff0c\u751f\u6210\u4e86\u9ad8\u8d28\u91cf\u7684\u53e4\u5178\u94a2\u7434\u6f14\u594f\u3002"}}
{"id": "2507.01333", "pdf": "https://arxiv.org/pdf/2507.01333", "abs": "https://arxiv.org/abs/2507.01333", "authors": ["Jiayi Lu", "Wanting Yang", "Zehui Xiong", "Rahim Tafazolli", "Tony Q. S. Quek", "M\u00e9rouane Debbah", "Dong In Kim"], "title": "Multi-User Generative Semantic Communication with Intent-Aware Semantic-Splitting Multiple Access", "categories": ["cs.NI", "cs.IT", "math.IT"], "comment": null, "summary": "With the booming development of generative artificial intelligence (GAI),\nsemantic communication (SemCom) has emerged as a new paradigm for reliable and\nefficient communication. This paper considers a multi-user downlink SemCom\nsystem, using vehicular networks as the representative scenario for multi-user\ncontent dissemination. To address diverse yet overlapping user demands, we\npropose a multi-user Generative SemCom-enhanced intent-aware semantic-splitting\nmultiple access (SS-MGSC) framework. In the framework, we construct an\nintent-aware shared knowledge base (SKB) that incorporates prior knowledge of\nsemantic information (SI) and user-specific preferences. Then, we designate the\ncommon SI as a one-hot semantic map that is broadcast to all users, while the\nprivate SI is delivered as personalized text for each user. On the receiver\nside, a diffusion model enhanced with ControlNet is adopted to generate\nhigh-quality personalized images. To capture both semantic relevance and\nperceptual similarity, we design a novel semantic efficiency score (SES) metric\nas the optimization objective. Building on this, we formulate a joint\noptimization problem for multi-user semantic extraction and beamforming, solved\nusing a reinforcement learning-based algorithm due to its robustness in\nhigh-dimensional settings. Simulation results demonstrate the effectiveness of\nthe proposed scheme.", "AI": {"tldr": "\u591a\u7528\u6237\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff08SS-MGSC\uff09\u901a\u8fc7\u610f\u56fe\u611f\u77e5\u77e5\u8bc6\u5e93\u548c\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u9ad8\u6548\u4e2a\u6027\u5316\u5185\u5bb9\u5206\u53d1\uff0c\u4f18\u5316\u6307\u6807\u4e3a\u8bed\u4e49\u6548\u7387\u5206\u6570\uff08SES\uff09\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u53d1\u5c55\u63a8\u52a8\u8bed\u4e49\u901a\u4fe1\u6210\u4e3a\u9ad8\u6548\u53ef\u9760\u7684\u65b0\u8303\u5f0f\uff0c\u5982\u4f55\u6ee1\u8db3\u591a\u7528\u6237\u591a\u6837\u5316\u4e14\u91cd\u53e0\u7684\u9700\u6c42\u662f\u5173\u952e\u6311\u6218\u3002", "method": "\u6784\u5efa\u610f\u56fe\u611f\u77e5\u5171\u4eab\u77e5\u8bc6\u5e93\uff08SKB\uff09\uff0c\u5e7f\u64ad\u516c\u5171\u8bed\u4e49\u4fe1\u606f\uff0c\u4e2a\u6027\u5316\u5206\u53d1\u79c1\u6709\u8bed\u4e49\u4fe1\u606f\uff0c\u63a5\u6536\u7aef\u91c7\u7528ControlNet\u589e\u5f3a\u7684\u6269\u6563\u6a21\u578b\u751f\u6210\u56fe\u50cf\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8bed\u4e49\u63d0\u53d6\u4e0e\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u6846\u67b6\u5728\u591a\u7528\u6237\u8bed\u4e49\u901a\u4fe1\u4e2d\u8868\u73b0\u6709\u6548\u3002", "conclusion": "SS-MGSC\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u4e0e\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u63d0\u5347\u4e86\u591a\u7528\u6237\u8bed\u4e49\u901a\u4fe1\u7684\u6548\u7387\u548c\u4f53\u9a8c\u3002"}}
{"id": "2507.01134", "pdf": "https://arxiv.org/pdf/2507.01134", "abs": "https://arxiv.org/abs/2507.01134", "authors": ["Braden Roper", "William Thompson", "Chris Weaver"], "title": "Animated Visual Encoding and Layer Blending for Identification of Educational Game Strategies", "categories": ["cs.HC"], "comment": "To be published in IEEE Visualization and Visual Analytics (VIS),\n  2025", "summary": "Game-Based Learning has proven to be an effective method for enhancing\nengagement with educational material. However, gaining a deeper understanding\nof player strategies remains challenging. Sequential game-state and\naction-based tracking tools often gather extensive data that can be difficult\nto interpret as long-term strategy. This data presents unique problems to\nvisualization, as it can be fairly natural, noisy data but is constrained\nwithin synthetic, controlled environments, leading to issues such as\noverplotting which can make interpretation complicated. We propose an animated\nvisual encoding tool that utilizes kinetic visualization to address these\nissues. This tool enables researchers to construct animated data narratives\nthrough the configuration of parameter interpolation curves and blending\nlayers. Finally, we demonstrate the usefulness of the tool while addressing\nspecific interests as outlined by a domain expert collaborator.", "AI": {"tldr": "\u57fa\u4e8e\u6e38\u620f\u7684\u5b66\u4e60\u80fd\u63d0\u5347\u5b66\u4e60\u53c2\u4e0e\u5ea6\uff0c\u4f46\u73a9\u5bb6\u7b56\u7565\u5206\u6790\u8f83\u96be\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u52a8\u753b\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u89e3\u51b3\u590d\u6742\u6570\u636e\u7684\u89e3\u8bfb\u95ee\u9898\u3002", "motivation": "\u6e38\u620f\u72b6\u6001\u548c\u884c\u52a8\u6570\u636e\u96be\u4ee5\u89e3\u8bfb\u4e3a\u957f\u671f\u7b56\u7565\uff0c\u4f20\u7edf\u53ef\u89c6\u5316\u5de5\u5177\u5b58\u5728\u8fc7\u5ea6\u7ed8\u56fe\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u89e3\u8bfb\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u52a8\u753b\u89c6\u89c9\u7f16\u7801\u5de5\u5177\uff0c\u5229\u7528\u52a8\u6001\u53ef\u89c6\u5316\u6280\u672f\uff0c\u652f\u6301\u53c2\u6570\u63d2\u503c\u66f2\u7ebf\u548c\u6df7\u5408\u5c42\u7684\u914d\u7f6e\u3002", "result": "\u5de5\u5177\u80fd\u6709\u6548\u5e2e\u52a9\u7814\u7a76\u8005\u6784\u5efa\u52a8\u753b\u6570\u636e\u53d9\u4e8b\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u5408\u4f5c\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "\u52a8\u753b\u53ef\u89c6\u5316\u5de5\u5177\u4e3a\u6e38\u620f\u5b66\u4e60\u4e2d\u7684\u7b56\u7565\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01284", "pdf": "https://arxiv.org/pdf/2507.01284", "abs": "https://arxiv.org/abs/2507.01284", "authors": ["Cristian Gariboldi", "Hayato Tokida", "Ken Kinjo", "Yuki Asada", "Alexander Carballo"], "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.LG"], "comment": "2025 IEEE 28th International Conference on Intelligent Transportation\n  Systems (ITSC)", "summary": "Recent advancements in open-source Visual Language Models (VLMs) such as\nLLaVA, Qwen-VL, and Llama have catalyzed extensive research on their\nintegration with diverse systems. The internet-scale general knowledge\nencapsulated within these models presents significant opportunities for\nenhancing autonomous driving perception, prediction, and planning capabilities.\nIn this paper we propose VLAD, a vision-language autonomous driving model,\nwhich integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end\nsystem. We implement a specialized fine-tuning approach using custom\nquestion-answer datasets designed specifically to improve the spatial reasoning\ncapabilities of the model. The enhanced VLM generates high-level navigational\ncommands that VAD subsequently processes to guide vehicle operation.\nAdditionally, our system produces interpretable natural language explanations\nof driving decisions, thereby increasing transparency and trustworthiness of\nthe traditionally black-box end-to-end architecture. Comprehensive evaluation\non the real-world nuScenes dataset demonstrates that our integrated system\nreduces average collision rates by 31.82% compared to baseline methodologies,\nestablishing a new benchmark for VLM-augmented autonomous driving systems.", "AI": {"tldr": "VLAD\u662f\u4e00\u79cd\u89c6\u89c9\u8bed\u8a00\u81ea\u52a8\u9a7e\u9a76\u6a21\u578b\uff0c\u901a\u8fc7\u5fae\u8c03VLM\u4e0eVAD\u96c6\u6210\uff0c\u63d0\u5347\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u51cf\u5c11\u78b0\u649e\u738731.82%\u3002", "motivation": "\u5229\u7528\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e92\u8054\u7f51\u89c4\u6a21\u77e5\u8bc6\uff0c\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7684\u611f\u77e5\u3001\u9884\u6d4b\u548c\u89c4\u5212\u80fd\u529b\u3002", "method": "\u91c7\u7528\u81ea\u5b9a\u4e49\u95ee\u7b54\u6570\u636e\u96c6\u5fae\u8c03VLM\uff0c\u751f\u6210\u9ad8\u7ea7\u5bfc\u822a\u6307\u4ee4\uff0c\u7ed3\u5408VAD\u7cfb\u7edf\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76\u3002", "result": "\u5728nuScenes\u6570\u636e\u96c6\u4e0a\uff0c\u78b0\u649e\u7387\u5e73\u5747\u964d\u4f4e31.82%\u3002", "conclusion": "VLAD\u4e3aVLM\u589e\u5f3a\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8bbe\u7acb\u4e86\u65b0\u57fa\u51c6\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u9a7e\u9a76\u51b3\u7b56\u3002"}}
{"id": "2507.01225", "pdf": "https://arxiv.org/pdf/2507.01225", "abs": "https://arxiv.org/abs/2507.01225", "authors": ["Sunandita Patra", "Mehtab Pathan", "Mahmoud Mahfouz", "Parisa Zehtabi", "Wided Ouaja", "Daniele Magazzeni", "Manuela Veloso"], "title": "Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration", "categories": ["cs.DC", "cs.AI"], "comment": "Please cite as: Sunandita Patra, Mehtab Pathan, Mahmoud Mahfouz,\n  Parisa Zehtabi, Wided Ouaja, Daniele Magazzeni, and Manuela Veloso. \"Capacity\n  planning and scheduling for jobs with uncertainty in resource usage and\n  duration.\" The Journal of Supercomputing 80, no. 15 (2024): 22428-22461", "summary": "Organizations around the world schedule jobs (programs) regularly to perform\nvarious tasks dictated by their end users. With the major movement towards\nusing a cloud computing infrastructure, our organization follows a hybrid\napproach with both cloud and on-prem servers. The objective of this work is to\nperform capacity planning, i.e., estimate resource requirements, and job\nscheduling for on-prem grid computing environments. A key contribution of our\napproach is handling uncertainty in both resource usage and duration of the\njobs, a critical aspect in the finance industry where stochastic market\nconditions significantly influence job characteristics. For capacity planning\nand scheduling, we simultaneously balance two conflicting objectives: (a)\nminimize resource usage, and (b) provide high quality-of-service to the end\nusers by completing jobs by their requested deadlines. We propose approximate\napproaches using deterministic estimators and pair sampling-based constraint\nprogramming. Our best approach (pair sampling-based) achieves much lower peak\nresource usage compared to manual scheduling without compromising on the\nquality-of-service.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u4e91\u548c\u672c\u5730\u670d\u52a1\u5668\u7684\u8d44\u6e90\u5bb9\u91cf\u89c4\u5212\u4e0e\u4f5c\u4e1a\u8c03\u5ea6\u65b9\u6cd5\uff0c\u91cd\u70b9\u5904\u7406\u8d44\u6e90\u4f7f\u7528\u548c\u4f5c\u4e1a\u6301\u7eed\u65f6\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e73\u8861\u8d44\u6e90\u6700\u5c0f\u5316\u548c\u670d\u52a1\u8d28\u91cf\u3002", "motivation": "\u5728\u91d1\u878d\u884c\u4e1a\u4e2d\uff0c\u5e02\u573a\u6761\u4ef6\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u4f5c\u4e1a\u7279\u6027\u5f71\u54cd\u663e\u8457\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\u548c\u6ee1\u8db3\u7528\u6237\u670d\u52a1\u8d28\u91cf\u9700\u6c42\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u786e\u5b9a\u6027\u4f30\u8ba1\u5668\u548c\u57fa\u4e8e\u914d\u5bf9\u91c7\u6837\u7684\u7ea6\u675f\u7f16\u7a0b\u65b9\u6cd5\u8fdb\u884c\u8fd1\u4f3c\u5904\u7406\u3002", "result": "\u57fa\u4e8e\u914d\u5bf9\u91c7\u6837\u7684\u65b9\u6cd5\u5728\u964d\u4f4e\u5cf0\u503c\u8d44\u6e90\u4f7f\u7528\u7684\u540c\u65f6\uff0c\u672a\u5f71\u54cd\u670d\u52a1\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6df7\u5408\u73af\u5883\u4e2d\u6709\u6548\u89e3\u51b3\u4e86\u8d44\u6e90\u89c4\u5212\u548c\u8c03\u5236\u7684\u53cc\u91cd\u6311\u6218\u3002"}}
{"id": "2507.01599", "pdf": "https://arxiv.org/pdf/2507.01599", "abs": "https://arxiv.org/abs/2507.01599", "authors": ["Zhaoyan Sun", "Jiayi Wang", "Xinyang Zhao", "Jiachi Wang", "Guoliang Li"], "title": "Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Traditional Data+AI systems utilize data-driven techniques to optimize\nperformance, but they rely heavily on human experts to orchestrate system\npipelines, enabling them to adapt to changes in data, queries, tasks, and\nenvironments. For instance, while there are numerous data science tools\navailable, developing a pipeline planning system to coordinate these tools\nremains challenging. This difficulty arises because existing Data+AI systems\nhave limited capabilities in semantic understanding, reasoning, and planning.\nFortunately, we have witnessed the success of large language models (LLMs) in\nenhancing semantic understanding, reasoning, and planning abilities. It is\ncrucial to incorporate LLM techniques to revolutionize data systems for\norchestrating Data+AI applications effectively.\n  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive\narchitecture designed to orchestrate Data+AI ecosystems, which focuses on\ntackling data-related tasks by integrating knowledge comprehension, reasoning,\nand planning capabilities. We delve into the challenges involved in designing\ndata agents, such as understanding data/queries/environments/tools,\norchestrating pipelines/workflows, optimizing and executing pipelines, and\nfostering pipeline self-reflection. Furthermore, we present examples of data\nagent systems, including a data science agent, data analytics agents (such as\nunstructured data analytics agent, semantic structured data analytics agent,\ndata lake analytics agent, and multi-modal data analytics agent), and a\ndatabase administrator (DBA) agent. We also outline several open challenges\nassociated with designing data agent systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u2018Data Agent\u2019\u6982\u5ff5\uff0c\u65e8\u5728\u901a\u8fc7\u6574\u5408LLM\u6280\u672f\u63d0\u5347Data+AI\u7cfb\u7edf\u7684\u8bed\u4e49\u7406\u89e3\u3001\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\uff0c\u4ee5\u81ea\u52a8\u5316\u6570\u636e\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edfData+AI\u7cfb\u7edf\u4f9d\u8d56\u4eba\u5de5\u4e13\u5bb6\u534f\u8c03\u6d41\u7a0b\uff0c\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u548c\u89c4\u5212\u80fd\u529b\uff0c\u800cLLM\u7684\u6210\u529f\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u63d0\u51fa\u2018Data Agent\u2019\u67b6\u6784\uff0c\u6574\u5408\u77e5\u8bc6\u7406\u89e3\u3001\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\uff0c\u5177\u4f53\u5305\u62ec\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u3001\u6570\u636e\u5206\u6790\u4ee3\u7406\uff08\u5982\u975e\u7ed3\u6784\u5316\u6570\u636e\u4ee3\u7406\u3001\u8bed\u4e49\u7ed3\u6784\u5316\u6570\u636e\u4ee3\u7406\u7b49\uff09\u548cDBA\u4ee3\u7406\u3002", "result": "\u8bba\u6587\u63a2\u8ba8\u4e86\u8bbe\u8ba1\u6570\u636e\u4ee3\u7406\u7684\u6311\u6218\uff0c\u5e76\u5c55\u793a\u4e86\u591a\u79cd\u4ee3\u7406\u7cfb\u7edf\u7684\u5177\u4f53\u793a\u4f8b\u3002", "conclusion": "\u8bbe\u8ba1\u6570\u636e\u4ee3\u7406\u7cfb\u7edf\u4ecd\u9700\u89e3\u51b3\u591a\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4f46LLM\u6280\u672f\u7684\u6574\u5408\u4e3aData+AI\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.01031", "pdf": "https://arxiv.org/pdf/2507.01031", "abs": "https://arxiv.org/abs/2507.01031", "authors": ["Fanchen Bu", "Kijung Shin"], "title": "PyTorch-based Geometric Learning with Non-CUDA Processing Units: Experiences from Intel Gaudi-v2 HPUs", "categories": ["cs.LG", "cs.SE"], "comment": "Conference paper: Accepted in Korea Computer Congress (KCC) 2025. The\n  library is available at https://github.com/bokveizen/gaudi-geometric-learning", "summary": "Geometric learning has emerged as a powerful paradigm for modeling\nnon-Euclidean data, especially graph-structured ones, with applications\nspanning social networks, molecular structures, knowledge graphs, and\nrecommender systems. While Nvidia's CUDA-enabled graphics processing units\n(GPUs) largely dominate the hardware landscape, emerging accelerators such as\nIntel's Gaudi Habana Processing Units (HPUs) offer competitive performance and\nenergy efficiency. However, the usage of such non-CUDA processing units\nrequires significant engineering effort and novel software adaptations. In this\nwork, we present our experiences porting PyTorch-based geometric learning\nframeworks to Gaudi-v2 HPUs. We introduce a collection of core utilities that\nrestore essential operations (e.g., scatter, sparse indexing, k-nearest\nneighbors) on Gaudi-v2 HPUs, and we consolidate sixteen guided tutorials and\neleven real-world examples with diagnostic analyses of encountered failures and\ndetailed workarounds. We collect all our experiences into a publicly accessible\nGitHub repository. Our contributions lower the barrier for researchers to\nexperiment with geometric-learning algorithms and models on non-CUDA hardware,\nproviding a foundation for further optimization and cross-platform portability.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u5c06\u57fa\u4e8ePyTorch\u7684\u51e0\u4f55\u5b66\u4e60\u6846\u67b6\u79fb\u690d\u5230\u975eCUDA\u786c\u4ef6\uff08\u5982Gaudi-v2 HPU\uff09\u7684\u7ecf\u9a8c\uff0c\u63d0\u4f9b\u4e86\u6838\u5fc3\u5de5\u5177\u3001\u6559\u7a0b\u548c\u6848\u4f8b\uff0c\u964d\u4f4e\u4e86\u7814\u7a76\u95e8\u69db\u3002", "motivation": "\u975eCUDA\u786c\u4ef6\uff08\u5982Gaudi-v2 HPU\uff09\u5728\u6027\u80fd\u4e0e\u80fd\u6548\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4f46\u7f3a\u4e4f\u9002\u914d\u8f6f\u4ef6\uff0c\u9700\u5de5\u7a0b\u52aa\u529b\u548c\u8f6f\u4ef6\u521b\u65b0\u3002", "method": "\u5f00\u53d1\u6838\u5fc3\u5de5\u5177\u6062\u590d\u5173\u952e\u64cd\u4f5c\uff08\u5982scatter\u3001\u7a00\u758f\u7d22\u5f15\u7b49\uff09\uff0c\u63d0\u4f9b\u6559\u7a0b\u548c\u5b9e\u4f8b\uff0c\u603b\u7ed3\u5931\u8d25\u6848\u4f8b\u4e0e\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u6210\u529f\u79fb\u690d\u6846\u67b6\uff0c\u5f00\u6e90GitHub\u8d44\u6e90\u5e93\uff0c\u4fc3\u8fdb\u975eCUDA\u786c\u4ef6\u4e0a\u7684\u51e0\u4f55\u5b66\u4e60\u7814\u7a76\u3002", "conclusion": "\u7814\u7a76\u964d\u4f4e\u4e86\u975eCUDA\u786c\u4ef6\u4f7f\u7528\u95e8\u69db\uff0c\u4e3a\u4f18\u5316\u4e0e\u8de8\u5e73\u53f0\u79fb\u690d\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.01305", "pdf": "https://arxiv.org/pdf/2507.01305", "abs": "https://arxiv.org/abs/2507.01305", "authors": ["Worameth Chinchuthakun", "Pakkapon Phongthawee", "Amit Raj", "Varun Jampani", "Pramook Khungurn", "Supasorn Suwajanakorn"], "title": "DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting", "categories": ["cs.CV", "cs.GR", "cs.LG", "I.3.3; I.4.8"], "comment": "arXiv admin note: substantial text overlap with arXiv:2312.09168", "summary": "We introduce a simple yet effective technique for estimating lighting from a\nsingle low-dynamic-range (LDR) image by reframing the task as a chrome ball\ninpainting problem. This approach leverages a pre-trained diffusion model,\nStable Diffusion XL, to overcome the generalization failures of existing\nmethods that rely on limited HDR panorama datasets. While conceptually simple,\nthe task remains challenging because diffusion models often insert incorrect or\ninconsistent content and cannot readily generate chrome balls in HDR format.\nOur analysis reveals that the inpainting process is highly sensitive to the\ninitial noise in the diffusion process, occasionally resulting in unrealistic\noutputs. To address this, we first introduce DiffusionLight, which uses\niterative inpainting to compute a median chrome ball from multiple outputs to\nserve as a stable, low-frequency lighting prior that guides the generation of a\nhigh-quality final result. To generate high-dynamic-range (HDR) light probes,\nan Exposure LoRA is fine-tuned to create LDR images at multiple exposure\nvalues, which are then merged. While effective, DiffusionLight is\ntime-intensive, requiring approximately 30 minutes per estimation. To reduce\nthis overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to\nabout 30 seconds with minimal quality loss. This 60x speedup is achieved by\ntraining a Turbo LoRA to directly predict the averaged chrome balls from the\niterative process. Inference is further streamlined into a single denoising\npass using a LoRA swapping technique. Experimental results that show our method\nproduces convincing light estimates across diverse settings and demonstrates\nsuperior generalization to in-the-wild scenarios. Our code is available at\nhttps://diffusionlight.github.io/turbo", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5c06\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u94ec\u7403\u4fee\u590d\u95ee\u9898\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578bStable Diffusion XL\u6765\u4f30\u8ba1\u4f4e\u52a8\u6001\u8303\u56f4\u56fe\u50cf\u5149\u7167\u7684\u6280\u672f\u3002\u901a\u8fc7\u8fed\u4ee3\u4fee\u590d\u8ba1\u7b97\u4e2d\u503c\u94ec\u7403\u4f5c\u4e3a\u4f4e\u9891\u5149\u7167\u5148\u9a8c\uff0c\u5e76\u5f15\u5165Exposure LoRA\u751f\u6210HDR\u5149\u7167\u63a2\u9488\u3002DiffusionLight-Turbo\u8fdb\u4e00\u6b65\u5c06\u8fd0\u884c\u65f6\u4ece30\u5206\u949f\u51cf\u5c11\u523030\u79d2\uff0c\u5b9e\u73b0\u4e8660\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6709\u9650\u7684HDR\u5168\u666f\u6570\u636e\u96c6\uff0c\u5b58\u5728\u6cdb\u5316\u5931\u8d25\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u5149\u7167\u4f30\u8ba1\u6280\u672f\u3002", "method": "\u63d0\u51faDiffusionLight\uff0c\u5229\u7528\u8fed\u4ee3\u4fee\u590d\u8ba1\u7b97\u4e2d\u503c\u94ec\u7403\u4f5c\u4e3a\u4f4e\u9891\u5149\u7167\u5148\u9a8c\uff0c\u5e76\u5f15\u5165Exposure LoRA\u751f\u6210HDR\u5149\u7167\u63a2\u9488\u3002\u8fdb\u4e00\u6b65\u5f00\u53d1DiffusionLight-Turbo\uff0c\u901a\u8fc7\u8bad\u7ec3Turbo LoRA\u76f4\u63a5\u9884\u6d4b\u8fed\u4ee3\u8fc7\u7a0b\u7ed3\u679c\uff0c\u5b9e\u73b0\u52a0\u901f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u751f\u6210\u9ad8\u8d28\u91cf\u5149\u7167\u4f30\u8ba1\uff0c\u5e76\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "DiffusionLight\u53ca\u5176\u52a0\u901f\u7248DiffusionLight-Turbo\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u5149\u7167\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901f\u5ea6\u548c\u6027\u80fd\u3002"}}
{"id": "2507.01652", "pdf": "https://arxiv.org/pdf/2507.01652", "abs": "https://arxiv.org/abs/2507.01652", "authors": ["Yuxin Mao", "Zhen Qin", "Jinxing Zhou", "Hui Deng", "Xuyang Shen", "Bin Fan", "Jing Zhang", "Yiran Zhong", "Yuchao Dai"], "title": "Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Autoregressive (AR) models have garnered significant attention in image\ngeneration for their ability to effectively capture both local and global\nstructures within visual data. However, prevalent AR models predominantly rely\non the transformer architectures, which are beset by quadratic computational\ncomplexity concerning input sequence length and substantial memory overhead due\nto the necessity of maintaining key-value caches. Although linear attention\nmechanisms have successfully reduced this burden in language models, our\ninitial experiments reveal that they significantly degrade image generation\nquality because of their inability to capture critical long-range dependencies\nin visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a\nnovel attention mechanism that explicitly preserves genuine 2D spatial\nrelationships within the flattened image sequences by computing\nposition-dependent decay factors based on true 2D spatial location rather than\n1D sequence positions. Based on this mechanism, we present LASADGen, an\nautoregressive image generator that enables selective attention to relevant\nspatial contexts with linear complexity. Experiments on ImageNet show LASADGen\nachieves state-of-the-art image generation performance and computational\nefficiency, bridging the gap between linear attention's efficiency and spatial\nunderstanding needed for high-quality generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86LASADGen\uff0c\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u6ce8\u610f\u529b\u548c\u7a7a\u95f4\u611f\u77e5\u8870\u51cf\u7684AR\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7ebf\u6027\u6ce8\u610f\u529b\u5728\u56fe\u50cf\u751f\u6210\u4e2d\u65e0\u6cd5\u6355\u6349\u957f\u7a0b\u4f9d\u8d56\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684AR\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u4e2d\u4f9d\u8d56Transformer\u67b6\u6784\uff0c\u4f46\u9762\u4e34\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5185\u5b58\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u7ebf\u6027\u6ce8\u610f\u529b\u867d\u80fd\u51cf\u8f7b\u8d1f\u62c5\u4f46\u4f1a\u964d\u4f4e\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51faLASAD\u673a\u5236\uff0c\u901a\u8fc7\u57fa\u4e8e\u771f\u5b9e2D\u7a7a\u95f4\u4f4d\u7f6e\u7684\u8870\u51cf\u56e0\u5b50\u4fdd\u7559\u7a7a\u95f4\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408LASADGen\u5b9e\u73b0\u9ad8\u6548\u751f\u6210\u3002", "result": "\u5728ImageNet\u4e0a\uff0cLASADGen\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\u751f\u6210\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u8fbe\u5230\u4e86SOTA\u6027\u80fd\u3002", "conclusion": "LASADGen\u6210\u529f\u5e73\u8861\u4e86\u7ebf\u6027\u6ce8\u610f\u529b\u7684\u6548\u7387\u4e0e\u9ad8\u8d28\u91cf\u56fe\u50cf\u751f\u6210\u7684\u7a7a\u95f4\u7406\u89e3\u9700\u6c42\u3002"}}
{"id": "2507.01360", "pdf": "https://arxiv.org/pdf/2507.01360", "abs": "https://arxiv.org/abs/2507.01360", "authors": ["Yijie Li", "Weichong Ling", "Taiting Lu", "Yi-Chao Chen", "Vaishnavi Ranganathan", "Lili Qiu", "Jingxian Wang"], "title": "MmBack: Clock-free Multi-Sensor Backscatter with Synchronous Acquisition and Multiplexing", "categories": ["cs.NI", "eess.SP"], "comment": "16 pages, 14 figures", "summary": "Backscatter tags provide a low-power solution for sensor applications, yet\nmany real-world scenarios require multiple sensors-often of different types-for\ncomplex sensing tasks. However, existing designs support only a single sensor\nper tag, increasing spatial overhead. State-of-the-art approaches to\nmultiplexing multiple sensor streams on a single tag rely on onboard clocks or\nmultiple modulation chains, which add cost, enlarge form factor, and remain\nprone to timing drift-disrupting synchronization across sensors.\n  We present mmBack, a low-power, clock-free backscatter tag that enables\nsynchronous multi-sensor data acquisition and multiplexing over a single\nmodulation chain. mmBack synchronizes sensor inputs in parallel using a shared\nreference signal extracted from ambient RF excitation, eliminating the need for\nan onboard timing source. To efficiently multiplex sensor data, mmBack designs\na voltage-division scheme to multiplex multiple sensor inputs as backscatter\nfrequency shifts through a single oscillator and RF switch. At the receiver,\nmmBack develops a frequency tracking algorithm and a finite-state machine for\naccurate demultiplexing. mmBack's ASIC design consumes 25.56uW, while its\nprototype supports 5 concurrent sensor streams with bandwidths of up to 5kHz\nand 3 concurrent sensor streams with bandwidth of up to 18kHz. Evaluation shows\nthat mmBack achieves an average SNR surpassing 15dB in signal reconstruction.", "AI": {"tldr": "mmBack\u662f\u4e00\u79cd\u4f4e\u529f\u8017\u3001\u65e0\u65f6\u949f\u53cd\u5411\u6563\u5c04\u6807\u7b7e\uff0c\u652f\u6301\u591a\u4f20\u611f\u5668\u540c\u6b65\u6570\u636e\u91c7\u96c6\u548c\u590d\u7528\uff0c\u901a\u8fc7\u5355\u4e00\u8c03\u5236\u94fe\u5b9e\u73b0\u9ad8\u6548\u591a\u4f20\u611f\u5668\u8f93\u5165\u3002", "motivation": "\u73b0\u6709\u8bbe\u8ba1\u4ec5\u652f\u6301\u6bcf\u4e2a\u6807\u7b7e\u5355\u4f20\u611f\u5668\uff0c\u800c\u591a\u4f20\u611f\u5668\u573a\u666f\u9700\u8981\u540c\u6b65\u548c\u590d\u7528\u529f\u80fd\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u65f6\u949f\u6216\u591a\u8c03\u5236\u94fe\uff0c\u589e\u52a0\u4e86\u6210\u672c\u548c\u590d\u6742\u6027\u3002", "method": "mmBack\u5229\u7528\u73af\u5883RF\u6fc0\u52b1\u63d0\u53d6\u5171\u4eab\u53c2\u8003\u4fe1\u53f7\u540c\u6b65\u4f20\u611f\u5668\u8f93\u5165\uff0c\u5e76\u901a\u8fc7\u7535\u538b\u5206\u914d\u65b9\u6848\u590d\u7528\u4f20\u611f\u5668\u6570\u636e\u4e3a\u9891\u7387\u504f\u79fb\u3002\u63a5\u6536\u7aef\u4f7f\u7528\u9891\u7387\u8ddf\u8e2a\u7b97\u6cd5\u548c\u6709\u9650\u72b6\u6001\u673a\u89e3\u590d\u7528\u3002", "result": "mmBack\u539f\u578b\u652f\u63015\u4e2a5kHz\u5e26\u5bbd\u62163\u4e2a18kHz\u5e26\u5bbd\u7684\u5e76\u53d1\u4f20\u611f\u5668\u6d41\uff0cASIC\u529f\u8017\u4e3a25.56\u03bcW\uff0c\u4fe1\u53f7\u91cd\u6784\u5e73\u5747SNR\u8d85\u8fc715dB\u3002", "conclusion": "mmBack\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u529f\u8017\u7684\u591a\u4f20\u611f\u5668\u540c\u6b65\u548c\u590d\u7528\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bbe\u8ba1\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.01166", "pdf": "https://arxiv.org/pdf/2507.01166", "abs": "https://arxiv.org/abs/2507.01166", "authors": ["Sifatul Anindho", "Videep Venkatesha", "Nathaniel Blanchard"], "title": "A Methodological Framework for Capturing Cognitive-Affective States in Collaborative Learning", "categories": ["cs.HC"], "comment": "Accepted to the Interactive Workshop: Multimodal, Multiparty Learning\n  Analytics (MMLA) at the conference Educational Data Mining (EDM) 2025", "summary": "Identification of affective and attentional states of individuals within\ngroups is difficult to obtain without disrupting the natural flow of\ncollaboration. Recent work from our group used a retrospect cued recall\nparadigm where participants spoke about their cognitive-affective states while\nthey viewed videos of their groups. We then collected additional participants\nwhere their reports were constrained to a subset of pre-identified\ncognitive-affective states. In this latter case, participants either self\nreported or reported in response to probes. Here, we present an initial\nanalysis of the frequency and temporal distribution of participant reports, and\nhow the distributions of labels changed across the two collections. Our\napproach has implications for the educational data mining community in tracking\ncognitive-affective states in collaborative learning more effectively and in\ndeveloping improved adaptive learning systems that can detect and respond to\ncognitive-affective states.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5728\u5c0f\u7ec4\u534f\u4f5c\u4e2d\u8bc6\u522b\u4e2a\u4f53\u7684\u60c5\u611f\u548c\u6ce8\u610f\u529b\u72b6\u6001\uff0c\u901a\u8fc7\u56de\u987e\u6027\u63d0\u793a\u56de\u5fc6\u8303\u5f0f\uff0c\u5206\u6790\u4e86\u53c2\u4e0e\u8005\u62a5\u544a\u7684\u9891\u7387\u548c\u65f6\u95f4\u5206\u5e03\uff0c\u4ee5\u53ca\u4e0d\u540c\u6536\u96c6\u65b9\u5f0f\u4e0b\u6807\u7b7e\u5206\u5e03\u7684\u53d8\u5316\u3002", "motivation": "\u7814\u7a76\u4e2d\u8bc6\u522b\u5c0f\u7ec4\u534f\u4f5c\u4e2d\u4e2a\u4f53\u7684\u60c5\u611f\u548c\u6ce8\u610f\u529b\u72b6\u6001\u901a\u5e38\u96be\u4ee5\u5728\u4e0d\u5e72\u6270\u81ea\u7136\u534f\u4f5c\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8ddf\u8e2a\u534f\u4f5c\u5b66\u4e60\u4e2d\u7684\u8ba4\u77e5\u60c5\u611f\u72b6\u6001\uff0c\u5e76\u4e3a\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u652f\u6301\u3002", "method": "\u7814\u7a76\u91c7\u7528\u56de\u987e\u6027\u63d0\u793a\u56de\u5fc6\u8303\u5f0f\uff0c\u53c2\u4e0e\u8005\u901a\u8fc7\u89c2\u770b\u5c0f\u7ec4\u89c6\u9891\u63cf\u8ff0\u5176\u8ba4\u77e5\u60c5\u611f\u72b6\u6001\u3002\u968f\u540e\uff0c\u5bf9\u989d\u5916\u53c2\u4e0e\u8005\u8fdb\u884c\u7ea6\u675f\u6027\u62a5\u544a\uff0c\u5206\u4e3a\u81ea\u6211\u62a5\u544a\u548c\u54cd\u5e94\u63d0\u793a\u62a5\u544a\u4e24\u79cd\u65b9\u5f0f\u3002", "result": "\u7814\u7a76\u5206\u6790\u4e86\u53c2\u4e0e\u8005\u62a5\u544a\u7684\u9891\u7387\u548c\u65f6\u95f4\u5206\u5e03\uff0c\u53d1\u73b0\u4e0d\u540c\u6536\u96c6\u65b9\u5f0f\uff08\u81ea\u7531\u62a5\u544a\u4e0e\u7ea6\u675f\u6027\u62a5\u544a\uff09\u4e0b\u6807\u7b7e\u5206\u5e03\u5b58\u5728\u53d8\u5316\u3002\u521d\u6b65\u5206\u6790\u8868\u660e\uff0c\u7ea6\u675f\u6027\u62a5\u544a\u4e0e\u81ea\u7531\u62a5\u544a\u5728\u72b6\u6001\u8bc6\u522b\u4e0a\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5bf9\u6559\u80b2\u6570\u636e\u6316\u6398\u793e\u533a\u6709\u91cd\u8981\u610f\u4e49\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8ddf\u8e2a\u534f\u4f5c\u5b66\u4e60\u4e2d\u7684\u8ba4\u77e5\u60c5\u611f\u72b6\u6001\uff0c\u5e76\u6709\u52a9\u4e8e\u5f00\u53d1\u80fd\u591f\u68c0\u6d4b\u548c\u54cd\u5e94\u8fd9\u4e9b\u72b6\u6001\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u3002"}}
{"id": "2507.01462", "pdf": "https://arxiv.org/pdf/2507.01462", "abs": "https://arxiv.org/abs/2507.01462", "authors": ["Eneko Osaba", "Estibaliz Garrote", "Pablo Miranda-Rodriguez", "Alessia Ciacco", "Itziar Cabanes", "Aitziber Mancisidor"], "title": "Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0", "categories": ["cs.RO", "cs.AI", "cs.ET"], "comment": "2 pages, 1 figure, paper accepted for presentation at the IEEE\n  International Conference on Quantum Computing and Engineering (QCE)", "summary": "This work explores the application of hybrid quantum-classical algorithms to\noptimize robotic inspection trajectories derived from Computer-Aided Design\n(CAD) models in industrial settings. By modeling the task as a 3D variant of\nthe Traveling Salesman Problem, incorporating incomplete graphs and open-route\nconstraints, this study evaluates the performance of two D-Wave-based solvers\nagainst classical methods such as GUROBI and Google OR-Tools. Results across\nfive real-world cases demonstrate competitive solution quality with\nsignificantly reduced computation times, highlighting the potential of quantum\napproaches in automation under Industry 4.0.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7b97\u6cd5\u5728\u4f18\u5316\u5de5\u4e1a\u73af\u5883\u4e2d\u57fa\u4e8eCAD\u6a21\u578b\u7684\u673a\u5668\u4eba\u68c0\u6d4b\u8f68\u8ff9\u4e2d\u7684\u5e94\u7528\uff0c\u7ed3\u679c\u663e\u793a\u91cf\u5b50\u65b9\u6cd5\u5728\u8ba1\u7b97\u65f6\u95f4\u548c\u89e3\u8d28\u91cf\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u4f18\u5316\u5de5\u4e1a\u81ea\u52a8\u5316\u4e2d\u7684\u673a\u5668\u4eba\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u4ee5\u6ee1\u8db3\u5de5\u4e1a4.0\u5bf9\u9ad8\u6548\u548c\u667a\u80fd\u5316\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5c06\u4efb\u52a1\u5efa\u6a21\u4e3a3D\u65c5\u884c\u5546\u95ee\u9898\uff0c\u7ed3\u5408\u4e0d\u5b8c\u5168\u56fe\u548c\u5f00\u653e\u8def\u5f84\u7ea6\u675f\uff0c\u6bd4\u8f83\u4e86D-Wave\u91cf\u5b50\u6c42\u89e3\u5668\u548c\u7ecf\u5178\u65b9\u6cd5\uff08\u5982GUROBI\u548cGoogle OR-Tools\uff09\u7684\u6027\u80fd\u3002", "result": "\u5728\u4e94\u4e2a\u5b9e\u9645\u6848\u4f8b\u4e2d\uff0c\u91cf\u5b50\u65b9\u6cd5\u5728\u8ba1\u7b97\u65f6\u95f4\u4e0a\u663e\u8457\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\uff0c\u540c\u65f6\u89e3\u8d28\u91cf\u76f8\u5f53\u3002", "conclusion": "\u91cf\u5b50\u65b9\u6cd5\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u9886\u57df\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5feb\u901f\u6c42\u89e3\u590d\u6742\u4f18\u5316\u95ee\u9898\u7684\u573a\u666f\u4e2d\u3002"}}
{"id": "2507.01676", "pdf": "https://arxiv.org/pdf/2507.01676", "abs": "https://arxiv.org/abs/2507.01676", "authors": ["Giuseppe Ruggeri", "Renzo Andri", "Daniele Jahier Pagliari", "Lukas Cavigelli"], "title": "Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.IR", "C.4; D.1.3; H.3.3; H.3.4"], "comment": "5 pages, 4 figures, conference: IEEE ICCD24", "summary": "Deep Recommender Models (DLRMs) inference is a fundamental AI workload\naccounting for more than 79% of the total AI workload in Meta's data centers.\nDLRMs' performance bottleneck is found in the embedding layers, which perform\nmany random memory accesses to retrieve small embedding vectors from tables of\nvarious sizes. We propose the design of tailored data flows to speedup\nembedding look-ups. Namely, we propose four strategies to look up an embedding\ntable effectively on one core, and a framework to automatically map the tables\nasymmetrically to the multiple cores of a SoC. We assess the effectiveness of\nour method using the Huawei Ascend AI accelerators, comparing it with the\ndefault Ascend compiler, and we perform high-level comparisons with Nvidia\nA100. Results show a speed-up varying from 1.5x up to 6.5x for real workload\ndistributions, and more than 20x for extremely unbalanced distributions.\nFurthermore, the method proves to be much more independent of the query\ndistribution than the baseline.", "AI": {"tldr": "\u9488\u5bf9\u6df1\u5ea6\u63a8\u8350\u6a21\u578b\uff08DLRM\uff09\u63a8\u7406\u4e2d\u7684\u5d4c\u5165\u5c42\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u56db\u79cd\u5355\u6838\u9ad8\u6548\u67e5\u627e\u7b56\u7565\u53ca\u591a\u6838\u975e\u5bf9\u79f0\u6620\u5c04\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "DLRM\u63a8\u7406\u5360Meta\u6570\u636e\u4e2dAI\u5de5\u4f5c\u8d1f\u8f7d\u768479%\uff0c\u5176\u6027\u80fd\u74f6\u9888\u5728\u4e8e\u5d4c\u5165\u5c42\u7684\u5c0f\u5411\u91cf\u968f\u673a\u5185\u5b58\u8bbf\u95ee\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u5355\u6838\u67e5\u627e\u7b56\u7565\u548c\u591a\u6838\u975e\u5bf9\u79f0\u6620\u5c04\u6846\u67b6\uff0c\u4f18\u5316\u5d4c\u5165\u8868\u67e5\u627e\u3002", "result": "\u5728\u534e\u4e3aAscend\u52a0\u901f\u5668\u4e0a\u5b9e\u6d4b\uff0c\u6027\u80fd\u63d0\u53471.5x\u81f36.5x\uff08\u6781\u7aef\u4e0d\u5e73\u8861\u5206\u5e03\u53ef\u8fbe20x\uff09\uff0c\u4e14\u5bf9\u67e5\u8be2\u5206\u5e03\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5d4c\u5165\u5c42\u6027\u80fd\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347DLRM\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2507.01298", "pdf": "https://arxiv.org/pdf/2507.01298", "abs": "https://arxiv.org/abs/2507.01298", "authors": ["Debasish Pattanayak", "Ajay D. Kshemkalyani", "Manish Kumar", "Anisur Rahaman Molla", "Gokarna Sharma"], "title": "Optimal Dispersion Under Asynchrony", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "comment": "35 pages, 5 figures, 2 tables, and 6 pseudocodes", "summary": "We study the dispersion problem in anonymous port-labeled graphs: $k \\leq n$\nmobile agents, each with a unique ID and initially located arbitrarily on the\nnodes of an $n$-node graph with maximum degree $\\Delta$, must autonomously\nrelocate so that no node hosts more than one agent. Dispersion serves as a\nfundamental task in distributed computing of mobile agents, and its complexity\nstems from key challenges in local coordination under anonymity and limited\nmemory.\n  The goal is to minimize both the time to achieve dispersion and the memory\nrequired per agent. It is known that any algorithm requires $\\Omega(k)$ time in\nthe worst case, and $\\Omega(\\log k)$ bits of memory per agent. A recent result\n[SPAA'25] gives an optimal $O(k)$-time algorithm in the synchronous setting and\nan $O(k \\log k)$-time algorithm in the asynchronous setting, both using\n$O(\\log(k+\\Delta))$ bits.\n  In this paper, we close the complexity gap in the asynchronous setting by\npresenting the first dispersion algorithm that runs in optimal $O(k)$ time\nusing $O(\\log(k+\\Delta))$ bits of memory per agent. Our solution is based on a\nnovel technique we develop in this paper that constructs a port-one tree in\nanonymous graphs, which may be of independent interest.", "AI": {"tldr": "\u7814\u7a76\u4e86\u533f\u540d\u7aef\u53e3\u6807\u8bb0\u56fe\u4e2d\u7684\u5206\u6563\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u5f02\u6b65\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u6700\u4f18\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u5206\u6563\u7b97\u6cd5\u3002", "motivation": "\u5206\u6563\u95ee\u9898\u662f\u79fb\u52a8\u4ee3\u7406\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u57fa\u7840\u4efb\u52a1\uff0c\u533f\u540d\u6027\u548c\u6709\u9650\u5185\u5b58\u5e26\u6765\u534f\u8c03\u6311\u6218\u3002\u76ee\u6807\u662f\u4f18\u5316\u5206\u6563\u65f6\u95f4\u548c\u5185\u5b58\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u5728\u533f\u540d\u56fe\u4e2d\u6784\u5efa\u7aef\u53e3\u5355\u6811\u7684\u65b0\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u6700\u4f18\u7684\u5f02\u6b65\u5206\u6563\u7b97\u6cd5\u3002", "result": "\u5728\u5f02\u6b65\u73af\u5883\u4e2d\uff0c\u7b97\u6cd5\u4ee5$O(k)$\u65f6\u95f4\u8fd0\u884c\uff0c\u6bcf\u4e2a\u4ee3\u7406\u4f7f\u7528$O(\\log(k+\\Delta))$\u4f4d\u5185\u5b58\uff0c\u586b\u8865\u4e86\u590d\u6742\u6027\u7a7a\u767d\u3002", "conclusion": "\u6280\u672f\u65b0\u9896\uff0c\u53ef\u80fd\u5177\u6709\u72ec\u7acb\u4ef7\u503c\uff0c\u89e3\u51b3\u4e86\u5f02\u6b65\u8bbe\u7f6e\u4e0b\u5206\u6563\u95ee\u9898\u7684\u590d\u6742\u5ea6\u95ee\u9898\u3002"}}
{"id": "2507.01755", "pdf": "https://arxiv.org/pdf/2507.01755", "abs": "https://arxiv.org/abs/2507.01755", "authors": ["Roberto Garc\u00eda", "Renzo Angles", "Vicente Rojas", "Sebasti\u00e1n Ferrada"], "title": "PathDB: A system for evaluating regular path queries", "categories": ["cs.DB"], "comment": null, "summary": "PathDB is a Java-based graph database designed for in-memory data loading and\nquerying. By utilizing Regular Path Queries (RPQ) and a closed path algebra,\nPathDB processes paths through its three main components: the parser, the\nlogical plan, and the physical plan. This modular design allows for targeted\noptimizations and modifications without impacting overall functionality.\nBenchmark experiments illustrate PathDB's execution times and flexibility in\nhandling dynamic and complex path queries, compared to baseline methods like\nDepth-First Search (DFS) and Breadth-First Search (BFS) guided by an automaton,\nhighlighting its optimizations that contribute to its performance.", "AI": {"tldr": "PathDB\u662f\u4e00\u4e2a\u57fa\u4e8eJava\u7684\u5185\u5b58\u56fe\u6570\u636e\u5e93\uff0c\u901a\u8fc7\u6b63\u5219\u8def\u5f84\u67e5\u8be2\u548c\u5c01\u95ed\u8def\u5f84\u4ee3\u6570\u4f18\u5316\u8def\u5f84\u5904\u7406\uff0c\u6027\u80fd\u4f18\u4e8eDFS\u548cBFS\u65b9\u6cd5\u3002", "motivation": "\u8bbe\u8ba1PathDB\u662f\u4e3a\u4e86\u9ad8\u6548\u5904\u7406\u52a8\u6001\u548c\u590d\u6742\u7684\u8def\u5f84\u67e5\u8be2\uff0c\u540c\u65f6\u63d0\u4f9b\u6a21\u5757\u5316\u4f18\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u6b63\u5219\u8def\u5f84\u67e5\u8be2\uff08RPQ\uff09\u548c\u5c01\u95ed\u8def\u5f84\u4ee3\u6570\uff0c\u901a\u8fc7\u89e3\u6790\u5668\u3001\u903b\u8f91\u8ba1\u5212\u548c\u7269\u7406\u8ba1\u5212\u4e09\u4e2a\u7ec4\u4ef6\u5904\u7406\u8def\u5f84\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePathDB\u5728\u6267\u884c\u65f6\u95f4\u548c\u7075\u6d3b\u6027\u4e0a\u4f18\u4e8eDFS\u548cBFS\u7b49\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "PathDB\u7684\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u4f18\u5316\u7b56\u7565\u4f7f\u5176\u5728\u590d\u6742\u8def\u5f84\u67e5\u8be2\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.01069", "pdf": "https://arxiv.org/pdf/2507.01069", "abs": "https://arxiv.org/abs/2507.01069", "authors": ["Nishant A. Parikh"], "title": "Agentic AI in Product Management: A Co-Evolutionary Model", "categories": ["cs.CE", "cs.SE"], "comment": "41 pages, 2 figures", "summary": "This study explores agentic AI's transformative role in product management,\nproposing a conceptual co-evolutionary framework to guide its integration\nacross the product lifecycle. Agentic AI, characterized by autonomy,\ngoal-driven behavior, and multi-agent collaboration, redefines product managers\n(PMs) as orchestrators of socio-technical ecosystems. Using systems theory,\nco-evolutionary theory, and human-AI interaction theory, the framework maps\nagentic AI capabilities in discovery, scoping, business case development,\ndevelopment, testing, and launch. An integrative review of 70+ sources,\nincluding case studies from leading tech firms, highlights PMs' evolving roles\nin AI orchestration, supervision, and strategic alignment. Findings emphasize\nmutual adaptation between PMs and AI, requiring skills in AI literacy,\ngovernance, and systems thinking. Addressing gaps in traditional frameworks,\nthis study provides a foundation for future research and practical\nimplementation to ensure responsible, effective agentic AI integration in\nsoftware organizations.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u540c\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5bfc\u4ee3\u7406AI\u5728\u4ea7\u54c1\u751f\u547d\u5468\u671f\u4e2d\u7684\u96c6\u6210\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u4ea7\u54c1\u7ecf\u7406\u7684\u89d2\u8272\u4e3a\u6280\u672f\u751f\u6001\u7cfb\u7edf\u7684\u534f\u8c03\u8005\u3002", "motivation": "\u63a2\u8ba8\u4ee3\u7406AI\u5728\u4ea7\u54c1\u7ba1\u7406\u4e2d\u7684\u53d8\u9769\u4f5c\u7528\uff0c\u586b\u8865\u4f20\u7edf\u6846\u67b6\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u7ed3\u5408\u7cfb\u7edf\u7406\u8bba\u3001\u534f\u540c\u8fdb\u5316\u7406\u8bba\u548c\u4eba\u673a\u4ea4\u4e92\u7406\u8bba\uff0c\u5bf970\u591a\u4e2a\u6765\u6e90\u8fdb\u884c\u7efc\u5408\u56de\u987e\u3002", "result": "\u5f3a\u8c03\u4e86\u4ea7\u54c1\u7ecf\u7406\u4e0e\u4ee3\u7406AI\u7684\u76f8\u4e92\u9002\u5e94\uff0c\u9700\u8981AI\u7d20\u517b\u3001\u6cbb\u7406\u548c\u7cfb\u7edf\u601d\u7ef4\u7b49\u65b0\u6280\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8f6f\u4ef6\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u8d1f\u8d23\u4efb\u4e14\u6709\u6548\u7684\u4ee3\u7406AI\u96c6\u6210\u6846\u67b6\uff0c\u652f\u6301\u672a\u6765\u7814\u7a76\u548c\u5b9e\u8df5\u3002"}}
{"id": "2507.01631", "pdf": "https://arxiv.org/pdf/2507.01631", "abs": "https://arxiv.org/abs/2507.01631", "authors": ["Camille Billouard", "Dawa Derksen", "Alexandre Constantin", "Bruno Vallet"], "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D\n  Vision Across Altitudes). Version before camera ready. Our code will be made\n  public after the conference", "summary": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "AI": {"tldr": "Snake-NeRF\u662f\u4e00\u79cd\u6269\u5c55\u5230\u5927\u573a\u666f\u7684NeRF\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5757\u8bad\u7ec3\u548c\u91cd\u53e0\u88c1\u526a\u56fe\u50cf\u89e3\u51b3\u4e86\u5185\u5b58\u95ee\u9898\uff0c\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u4e14\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709NeRF\u65b9\u6cd5\u56e0\u5185\u5b58\u9650\u5236\u96be\u4ee5\u5904\u7406\u5927\u573a\u666f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5355\u8bbe\u5907\u9ad8\u6548\u8fd0\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5206\u5757\u65e0\u91cd\u53e0\u76843D\u74e6\u7247\u7b56\u7565\u548c\u91cd\u53e0\u88c1\u526a\u56fe\u50cf\u7684\u65b9\u6cd5\uff0c\u7ed3\u54082\u00d72 3D\u74e6\u7247\u8fdb\u5c55\u7b56\u7565\u548c\u5206\u6bb5\u91c7\u6837\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5355GPU\u4e0a\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u5904\u7406\u5927\u573a\u666f\u536b\u661f\u56fe\u50cf\u4e14\u4e0d\u727a\u7272\u8d28\u91cf\u3002", "conclusion": "Snake-NeRF\u6709\u6548\u89e3\u51b3\u4e86\u5927\u573a\u666fNeRF\u7684\u6269\u5c55\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u3002"}}
{"id": "2507.01776", "pdf": "https://arxiv.org/pdf/2507.01776", "abs": "https://arxiv.org/abs/2507.01776", "authors": ["Yuxuan Yang"], "title": "Human-Machine Collaboration-Guided Space Design: Combination of Machine Learning Models and Humanistic Design Concepts", "categories": ["cs.HC", "cs.MM"], "comment": null, "summary": "The integration of machine learning (ML) into spatial design holds immense\npotential for optimizing space utilization, enhancing functionality, and\nstreamlining design processes. ML can automate tasks, predict performance\noutcomes, and tailor spaces to user preferences. However, the emotional,\ncultural, and aesthetic dimensions of design remain crucial for creating spaces\nthat truly resonate with users-elements that ML alone cannot address. The key\nchallenge lies in harmonizing data-driven efficiency with the nuanced,\nsubjective aspects of design. This paper proposes a human-machine collaboration\nframework to bridge this gap. An effective framework should recognize that\nwhile ML enhances design efficiency through automation and prediction, it must\nbe paired with human creativity to ensure spaces are emotionally engaging and\nculturally relevant. Human designers contribute intuition, empathy, and\ncultural insight, guiding ML-generated solutions to align with users' emotional\nand cultural needs. Additionally, we explore how various ML models can be\nintegrated with human-centered design principles. These models can automate\ndesign generation and optimization, while human designers refine the outputs to\nensure emotional resonance and aesthetic appeal. Through case studies in office\nand residential design, we illustrate how this framework fosters both\ncreativity and cultural relevance. By merging ML with human creativity, spatial\ndesign can achieve a balance of efficiency and emotional impact, resulting in\nenvironments that are both functional and deeply human.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u5c06\u673a\u5668\u5b66\u4e60\u7684\u6548\u7387\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u7684\u521b\u9020\u529b\u7ed3\u5408\uff0c\u4ee5\u4f18\u5316\u7a7a\u95f4\u8bbe\u8ba1\u5e76\u786e\u4fdd\u60c5\u611f\u4e0e\u6587\u5316\u5171\u9e23\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u4f18\u5316\u7a7a\u95f4\u8bbe\u8ba1\u7684\u6548\u7387\uff0c\u540c\u65f6\u89e3\u51b3\u5176\u65e0\u6cd5\u6ee1\u8db3\u60c5\u611f\u3001\u6587\u5316\u548c\u5ba1\u7f8e\u9700\u6c42\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u7ed3\u5408ML\u7684\u81ea\u52a8\u5316\u3001\u9884\u6d4b\u80fd\u529b\u548c\u4eba\u7c7b\u8bbe\u8ba1\u5e08\u7684\u521b\u9020\u529b\u3001\u76f4\u89c9\u4e0e\u6587\u5316\u6d1e\u5bdf\u3002", "result": "\u901a\u8fc7\u529e\u516c\u548c\u4f4f\u5b85\u8bbe\u8ba1\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u63d0\u5347\u8bbe\u8ba1\u7684\u521b\u9020\u529b\u548c\u6587\u5316\u76f8\u5173\u6027\u3002", "conclusion": "\u878d\u5408ML\u4e0e\u4eba\u7c7b\u521b\u9020\u529b\uff0c\u80fd\u5728\u7a7a\u95f4\u8bbe\u8ba1\u4e2d\u5b9e\u73b0\u6548\u7387\u4e0e\u60c5\u611f\u5f71\u54cd\u7684\u5e73\u8861\uff0c\u521b\u9020\u51fa\u529f\u80fd\u6027\u4e0e\u4eba\u6027\u5316\u517c\u5177\u7684\u73af\u5883\u3002"}}
{"id": "2507.01773", "pdf": "https://arxiv.org/pdf/2507.01773", "abs": "https://arxiv.org/abs/2507.01773", "authors": ["Bo Yang", "Ruihuai Liang", "Weixin Li", "Han Wang", "Xuelin Cao", "Zhiwen Yu", "Samson Lasaulce", "M\u00e9rouane Debbah", "Mohamed-Slim Alouini", "H. Vincent Poor", "Chau Yuen"], "title": "Frontiers of Generative AI for Network Optimization: Theories, Limits, and Visions", "categories": ["cs.NI"], "comment": null, "summary": "While interest in the application of generative AI (GenAI) in network\noptimization has surged in recent years, its rapid progress has often\novershadowed critical limitations intrinsic to generative models that remain\ninsufficiently examined in existing literature. This survey provides a\ncomprehensive review and critical analysis of GenAI in network optimization. We\nfocus on the two dominant paradigms of GenAI including generative diffusion\nmodels (GDMs) and large pre-trained models (LPTMs), and organize our discussion\naround a categorization we introduce, dividing network optimization problems\ninto two primary formulations: one-shot optimization and Markov decision\nprocess (MDP). We first trace key works, including foundational contributions\nfrom the AI community, and categorize current efforts in network optimization.\nWe also review frontier applications of GDMs and LPTMs in other networking\ntasks, providing additional context. Furthermore, we present theoretical\ngeneralization bounds for GDMs in both one-shot and MDP settings, offering\ninsights into the fundamental factors affecting model performance. Most\nimportantly, we reflect on the overestimated perception of GenAI's general\ncapabilities and caution against the all-in-one illusion it may convey. We\nhighlight critical limitations, including difficulties in constraint\nsatisfying, limited concept understanding, and the inherent probabilistic\nnature of outputs. We also propose key future directions, such as bridging the\ngap between generation and optimization. Although they are increasingly\nintegrated in implementations, they differ fundamentally in both objectives and\nunderlying mechanisms, necessitating a deeper understanding of their\ntheoretical connections. Ultimately, this survey aims to provide a structured\noverview and a deeper insight into the strengths, limitations, and potential of\nGenAI in network optimization.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u751f\u6210\u5f0fAI\u5728\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u5176\u5c40\u9650\u6027\u548c\u672a\u6765\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u751f\u6210\u6269\u6563\u6a21\u578b\u548c\u5927\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4f5c\u7528\u53ca\u5176\u7406\u8bba\u8fb9\u754c\u3002", "motivation": "\u8fd1\u5e74\u6765\u751f\u6210\u5f0fAI\u5728\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u6fc0\u589e\uff0c\u4f46\u5176\u5feb\u901f\u8fdb\u5c55\u63a9\u76d6\u4e86\u751f\u6210\u6a21\u578b\u7684\u5185\u5728\u5c40\u9650\u6027\u3002\u672c\u6587\u65e8\u5728\u5168\u9762\u56de\u987e\u548c\u6279\u5224\u6027\u5206\u6790\u8fd9\u4e9b\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u56f4\u7ed5\u751f\u6210\u6269\u6563\u6a21\u578b\u548c\u5927\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5c06\u7f51\u7edc\u4f18\u5316\u95ee\u9898\u5206\u4e3a\u4e00\u6b21\u6027\u4f18\u5316\u548c\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e24\u7c7b\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u6cdb\u5316\u8fb9\u754c\u3002", "result": "\u63ed\u793a\u751f\u6210\u5f0fAI\u7684\u5c40\u9650\u6027\uff0c\u5982\u7ea6\u675f\u6ee1\u8db3\u56f0\u96be\u3001\u6982\u5ff5\u7406\u89e3\u6709\u9650\u53ca\u8f93\u51fa\u6982\u7387\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u751f\u6210\u4e0e\u4f18\u5316\u7684\u6865\u6881\u3002", "conclusion": "\u8bba\u6587\u7ed3\u6784\u5316\u6982\u8ff0\u4e86\u751f\u6210\u5f0fAI\u5728\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u4f18\u52bf\u3001\u5c40\u9650\u6027\u548c\u6f5c\u529b\uff0c\u547c\u5401\u5bf9\u5176\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u66f4\u6df1\u5165\u7684\u7406\u89e3\u3002"}}
{"id": "2507.01209", "pdf": "https://arxiv.org/pdf/2507.01209", "abs": "https://arxiv.org/abs/2507.01209", "authors": ["Paul C. Parsons", "Arran Ridley"], "title": "Judgment as Coordination: A Joint Systems View of Visualization Design Practice", "categories": ["cs.HC"], "comment": "IEEE VIS 2025 (conditional acceptance)", "summary": "Professional visualization design has become an increasingly important area\nof inquiry, yet much of the field's discourse remains anchored in\nresearcher-centered contexts. Studies of design practice often focus on\nindividual designers' decisions and reflections, offering limited insight into\nthe collaborative and systemic dimensions of professional work. In this paper,\nwe propose a systems-level reframing of design judgment grounded in the\ncoordination and adaptation that sustain progress amid uncertainty, constraint,\nand misalignment. Drawing on sustained engagement across multiple empirical\nstudies--including ethnographic observation of design teams and qualitative\nstudies of individual practitioners--we identify recurring episodes in which\ncoherence was preserved not by selecting an optimal option, but by repairing\nalignment, adjusting plans, and reframing goals. We interpret these dynamics\nthrough the lens of Joint Cognitive Systems, which provide tools for analyzing\nhow judgment emerges as a distributed capacity within sociotechnical activity.\nThis perspective surfaces often-invisible work in visualization design and\noffers researchers a new conceptual vocabulary for studying how design activity\nis sustained in practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u7684\u8bbe\u8ba1\u5224\u65ad\u6846\u67b6\uff0c\u5173\u6ce8\u4e13\u4e1a\u53ef\u89c6\u5316\u8bbe\u8ba1\u4e2d\u7684\u534f\u4f5c\u548c\u7cfb\u7edf\u6027\u7ef4\u5ea6\uff0c\u5f3a\u8c03\u901a\u8fc7\u4fee\u590d\u5bf9\u9f50\u3001\u8c03\u6574\u8ba1\u5212\u548c\u91cd\u6784\u76ee\u6807\u6765\u7ef4\u6301\u8bbe\u8ba1\u8fde\u8d2f\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8\u4e13\u4e1a\u53ef\u89c6\u5316\u8bbe\u8ba1\u4e2d\u534f\u4f5c\u4e0e\u7cfb\u7edf\u6027\u7ef4\u5ea6\u7684\u4e0d\u8db3\uff0c\u5f53\u524d\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u4e2a\u4f53\u8bbe\u8ba1\u5e08\u7684\u51b3\u7b56\uff0c\u5ffd\u7565\u4e86\u56e2\u961f\u5408\u4f5c\u4e2d\u7684\u5b9e\u9645\u5de5\u4f5c\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u591a\u4e2a\u5b9e\u8bc1\u7814\u7a76\uff0c\u5982\u8bbe\u8ba1\u56e2\u961f\u7684\u6c11\u65cf\u5fd7\u89c2\u5bdf\u548c\u4e2a\u4f53\u4ece\u4e1a\u8005\u7684\u5b9a\u6027\u7814\u7a76\uff0c\u4ee5\u53ca\u8054\u5408\u8ba4\u77e5\u7cfb\u7edf\u7406\u8bba\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bbe\u8ba1\u8fde\u8d2f\u6027\u5e76\u975e\u901a\u8fc7\u9009\u62e9\u6700\u4f18\u65b9\u6848\u7ef4\u6301\uff0c\u800c\u662f\u901a\u8fc7\u4fee\u590d\u5bf9\u9f50\u3001\u8c03\u6574\u8ba1\u5212\u548c\u91cd\u6784\u76ee\u6807\u6765\u5b9e\u73b0\uff0c\u63ed\u793a\u4e86\u8bbe\u8ba1\u4e2d\u9690\u85cf\u7684\u5de5\u4f5c\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u8fd9\u4e00\u7cfb\u7edf\u7ea7\u89c6\u89d2\u4e3a\u53ef\u89c6\u5316\u8bbe\u8ba1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u6982\u5ff5\u5de5\u5177\uff0c\u5e2e\u52a9\u7406\u89e3\u8bbe\u8ba1\u6d3b\u52a8\u5728\u5b9e\u9645\u4e2d\u7684\u6301\u7eed\u8fd0\u4f5c\u3002"}}
{"id": "2507.01808", "pdf": "https://arxiv.org/pdf/2507.01808", "abs": "https://arxiv.org/abs/2507.01808", "authors": ["Xiaoyu Ji", "Jessica Shorland", "Joshua Shank", "Pascal Delpe-Brice", "Latanya Sweeney", "Jan Allebach", "Ali Shakouri"], "title": "Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.ET", "68T01, 68T05, 68T45, 94A60"], "comment": "20 pages, 11 figures, 30 references", "summary": "Small- and medium-sized manufacturers need innovative data tools but, because\nof competition and privacy concerns, often do not want to share their\nproprietary data with researchers who might be interested in helping. This\npaper introduces a privacy-preserving platform by which manufacturers may\nsafely share their data with researchers through secure methods, so that those\nresearchers then create innovative tools to solve the manufacturers' real-world\nproblems, and then provide tools that execute solutions back onto the platform\nfor others to use with privacy and confidentiality guarantees. We illustrate\nthis problem through a particular use case which addresses an important problem\nin the large-scale manufacturing of food crystals, which is that quality\ncontrol relies on image analysis tools. Previous to our research, food crystals\nin the images were manually counted, which required substantial and\ntime-consuming human efforts, but we have developed and deployed a crystal\nanalysis tool which makes this process both more rapid and accurate. The tool\nenables automatic characterization of the crystal size distribution and numbers\nfrom microscope images while the natural imperfections from the sample\npreparation are automatically removed; a machine learning model to count high\nresolution translucent crystals and agglomeration of crystals was also\ndeveloped to aid in these efforts. The resulting algorithm was then packaged\nfor real-world use on the factory floor via a web-based app secured through the\noriginating privacy-preserving platform, allowing manufacturers to use it while\nkeeping their proprietary data secure. After demonstrating this full process,\nfuture directions are also explored.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u5e73\u53f0\uff0c\u5e2e\u52a9\u4e2d\u5c0f\u578b\u5236\u9020\u5546\u5b89\u5168\u5171\u4eab\u6570\u636e\u4ee5\u5f00\u53d1\u521b\u65b0\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u98df\u54c1\u6676\u4f53\u8d28\u91cf\u63a7\u5236\u7684\u5b9e\u4f8b\u5c55\u793a\u4e86\u8be5\u5e73\u53f0\u7684\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u5236\u9020\u5546\u56e0\u7ade\u4e89\u548c\u9690\u79c1\u95ee\u9898\u4e0d\u613f\u5171\u4eab\u6570\u636e\uff0c\u800c\u96be\u4ee5\u83b7\u53d6\u521b\u65b0\u5de5\u5177\u7684\u77db\u76fe\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u5e73\u53f0\uff0c\u5236\u9020\u5546\u901a\u8fc7\u5b89\u5168\u65b9\u6cd5\u5171\u4eab\u6570\u636e\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u5de5\u5177\u540e\u8fd4\u56de\u5230\u5e73\u53f0\u4f9b\u5176\u4ed6\u4eba\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u8bc1\u9690\u79c1\u548c\u673a\u5bc6\u6027\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6676\u4f53\u5206\u6790\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u98df\u54c1\u6676\u4f53\u56fe\u50cf\u81ea\u52a8\u5206\u6790\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u5e73\u53f0\u90e8\u7f72\u4f7f\u7528\u3002", "conclusion": "\u9690\u79c1\u4fdd\u62a4\u5e73\u53f0\u6210\u529f\u89e3\u51b3\u4e86\u6570\u636e\u5171\u4eab\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u77db\u76fe\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u6269\u5c55\u5e94\u7528\u3002"}}
{"id": "2507.01438", "pdf": "https://arxiv.org/pdf/2507.01438", "abs": "https://arxiv.org/abs/2507.01438", "authors": ["Zheyu Shen", "Yexiao He", "Ziyao Wang", "Yuning Zhang", "Guoheng Sun", "Wanghao Ye", "Ang Li"], "title": "EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have gained significant attention due to their\nversatility across a wide array of applications. Fine-tuning LLMs with\nparameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these\nmodels to efficiently adapt to downstream tasks without extensive retraining.\nDeploying fine-tuned LLMs on multi-tenant edge devices offers substantial\nbenefits, such as reduced latency, enhanced privacy, and personalized\nresponses. However, serving LLMs efficiently on resource-constrained edge\ndevices presents critical challenges, including the complexity of adapter\nselection for different tasks and memory overhead from frequent adapter\nswapping. Moreover, given the multiple requests in multi-tenant settings,\nprocessing requests sequentially results in underutilization of computational\nresources and increased latency. This paper introduces EdgeLoRA, an efficient\nsystem for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA\nincorporates three key innovations: (1) an adaptive adapter selection mechanism\nto streamline the adapter configuration process; (2) heterogeneous memory\nmanagement, leveraging intelligent adapter caching and pooling to mitigate\nmemory operation overhead; and (3) batch LoRA inference, enabling efficient\nbatch processing to significantly reduce computational latency. Comprehensive\nevaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly\noutperforms the status quo (i.e., llama.cpp) in terms of both latency and\nthroughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times\nboost in throughput. Even more impressively, it can serve several orders of\nmagnitude more adapters simultaneously. These results highlight EdgeLoRA's\npotential to transform edge deployment of LLMs in multi-tenant scenarios,\noffering a scalable and efficient solution for resource-constrained\nenvironments.", "AI": {"tldr": "EdgeLoRA\u662f\u4e00\u4e2a\u9ad8\u6548\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u591a\u79df\u6237\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72LLMs\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9002\u914d\u5668\u9009\u62e9\u3001\u5f02\u6784\u5185\u5b58\u7ba1\u7406\u548c\u6279\u91cfLoRA\u63a8\u7406\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u591a\u79df\u6237\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9ad8\u6548\u90e8\u7f72LLMs\u7684\u6311\u6218\uff0c\u5982\u9002\u914d\u5668\u9009\u62e9\u548c\u5185\u5b58\u5f00\u9500\u95ee\u9898\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u9002\u914d\u5668\u9009\u62e9\u3001\u5f02\u6784\u5185\u5b58\u7ba1\u7406\u548c\u6279\u91cfLoRA\u63a8\u7406\u6280\u672f\u3002", "result": "EdgeLoRA\u5728\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff08\u5982llama.cpp\uff09\uff0c\u541e\u5410\u91cf\u63d0\u53474\u500d\uff0c\u540c\u65f6\u652f\u6301\u66f4\u591a\u9002\u914d\u5668\u3002", "conclusion": "EdgeLoRA\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684LLMs\u8fb9\u7f18\u90e8\u7f72\u65b9\u6848\u3002"}}
{"id": "2507.01053", "pdf": "https://arxiv.org/pdf/2507.01053", "abs": "https://arxiv.org/abs/2507.01053", "authors": ["Rafi Al Attrach", "Pedro Moreira", "Rajna Fani", "Renato Umeton", "Leo Anthony Celi"], "title": "Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis", "categories": ["cs.IR", "cs.AI", "cs.DB", "68T50, 68P15", "H.2.3; I.2.7; J.3"], "comment": "10 pages, 4 figures", "summary": "As ever-larger clinical datasets become available, they have the potential to\nunlock unprecedented opportunities for medical research. Foremost among them is\nMedical Information Mart for Intensive Care (MIMIC-IV), the world's largest\nopen-source EHR database. However, the inherent complexity of these datasets,\nparticularly the need for sophisticated querying skills and the need to\nunderstand the underlying clinical settings, often presents a significant\nbarrier to their effective use. M3 lowers the technical barrier to\nunderstanding and querying MIMIC-IV data. With a single command it retrieves\nMIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the\nhosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers\nconverse with the database in plain English. Ask a clinical question in natural\nlanguage; M3 uses a language model to translate it into SQL, executes the query\nagainst the MIMIC-IV dataset, and returns structured results alongside the\nunderlying query for verifiability and reproducibility. Demonstrations show\nthat minutes of dialogue with M3 yield the kind of nuanced cohort analyses that\nonce demanded hours of handcrafted SQL and relied on understanding the\ncomplexities of clinical workflows. By simplifying access, M3 invites the\nbroader research community to mine clinical critical-care data and accelerates\nthe translation of raw records into actionable insight.", "AI": {"tldr": "M3\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u964d\u4f4e\u4f7f\u7528MIMIC-IV\u6570\u636e\u5e93\u7684\u6280\u672f\u95e8\u69db\uff0c\u52a0\u901f\u4e34\u5e8a\u6570\u636e\u5206\u6790\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u4e34\u5e8a\u6570\u636e\u96c6\uff08\u5982MIMIC-IV\uff09\u56e0\u590d\u6742\u6027\u5e26\u6765\u7684\u4f7f\u7528\u969c\u788d\uff0c\u4f7f\u5176\u66f4\u6613\u88ab\u5e7f\u6cdb\u7814\u7a76\u793e\u533a\u5229\u7528\u3002", "method": "M3\u5229\u7528\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u6362\u4e3aSQL\u67e5\u8be2\uff0c\u5e76\u7ed3\u5408\u672c\u5730SQLite\u6216BigQuery\u6267\u884c\u67e5\u8be2\uff0c\u8fd4\u56de\u7ed3\u6784\u5316\u548c\u53ef\u9a8c\u8bc1\u7684\u7ed3\u679c\u3002", "result": "\u901a\u8fc7M3\uff0c\u7814\u7a76\u4eba\u5458\u80fd\u4ee5\u81ea\u7136\u8bed\u8a00\u5feb\u901f\u5b8c\u6210\u590d\u6742\u5206\u6790\uff0c\u663e\u8457\u51cf\u5c11\u4f20\u7edf\u624b\u5de5SQL\u67e5\u8be2\u7684\u65f6\u95f4\u548c\u7406\u89e3\u4e34\u5e8a\u6d41\u7a0b\u7684\u9700\u6c42\u3002", "conclusion": "M3\u7b80\u5316\u4e86\u4e34\u5e8a\u6570\u636e\u7684\u8bbf\u95ee\uff0c\u4fc3\u8fdb\u4e86\u4ece\u539f\u59cb\u8bb0\u5f55\u5230\u53ef\u64cd\u4f5c\u89c1\u89e3\u7684\u8f6c\u5316\uff0c\u63a8\u52a8\u4e86\u533b\u5b66\u7814\u7a76\u7684\u8fdb\u6b65\u3002"}}
{"id": "2507.01457", "pdf": "https://arxiv.org/pdf/2507.01457", "abs": "https://arxiv.org/abs/2507.01457", "authors": ["Federico Nicolas Peccia", "Frederik Haxel", "Oliver Bringmann"], "title": "Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": "9 pages, 10 figures, 2 algorithms", "summary": "RISC-V provides a flexible and scalable platform for applications ranging\nfrom embedded devices to high-performance computing clusters. Particularly, its\nRISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI\nworkloads. But writing software that efficiently utilizes the vector units of\nRISC-V CPUs without expert knowledge requires the programmer to rely on the\nautovectorization features of compilers or hand-crafted libraries like\nmuRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing\nthe integration with the RISC-V RVV extension, thus heavily limiting the\nefficient deployment of complex AI workloads. In this paper, we present a\nworkflow based on the TVM compiler to efficiently map AI workloads onto RISC-V\nvector units. Instead of relying on hand-crafted libraries, we integrated the\nRVV extension into TVM's MetaSchedule framework, a probabilistic program\nframework for tensor operation tuning. We implemented different RISC-V SoCs on\nan FPGA and tuned a wide range of AI workloads on them. We found that our\nproposal shows a mean improvement of 46% in execution latency when compared\nagainst the autovectorization feature of GCC, and 29% against muRISCV-NN.\nMoreover, the binary resulting from our proposal has a smaller code memory\nfootprint, making it more suitable for embedded devices. Finally, we also\nevaluated our solution on a commercially available RISC-V SoC implementing the\nRVV 1.0 Vector Extension and found our solution is able to find mappings that\nare 35% faster on average than the ones proposed by LLVM. We open-sourced our\nproposal for the community to expand it to target other RISC-V extensions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTVM\u7f16\u8bd1\u5668\u7684\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u9ad8\u6548\u5730\u5c06AI\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u5230RISC-V\u5411\u91cf\u5355\u5143\uff0c\u901a\u8fc7\u96c6\u6210RVV\u6269\u5c55\u548cMetaSchedule\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "RISC-V\u7684\u5411\u91cf\u6269\u5c55\uff08RVV\uff09\u4e3aAI\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u52a0\u901f\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u6548\u7684\u7f16\u7a0b\u5de5\u5177\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u5c06RVV\u6269\u5c55\u96c6\u6210\u5230TVM\u7684MetaSchedule\u6846\u67b6\u4e2d\uff0c\u5e76\u91c7\u7528\u6982\u7387\u7f16\u7a0b\u65b9\u6cd5\u5bf9\u5f20\u91cf\u64cd\u4f5c\u8fdb\u884c\u8c03\u4f18\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u8f83\u4e8eGCC\u7684\u81ea\u52a8\u5411\u91cf\u5316\u548cmuRISCV-NN\u5e93\uff0c\u8be5\u65b9\u6848\u5206\u522b\u63d0\u5347\u4e8646%\u548c29%\u7684\u6267\u884c\u901f\u5ea6\uff0c\u4e14\u4ee3\u7801\u5360\u7528\u66f4\u5c11\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86AI\u5de5\u4f5c\u8d1f\u8f7d\u5728RISC-V\u4e0a\u7684\u6267\u884c\u6548\u7387\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u8bbe\u5907\uff0c\u5e76\u5f00\u6e90\u4ee5\u4fbf\u793e\u533a\u8fdb\u4e00\u6b65\u6269\u5c55\u3002"}}
{"id": "2507.01800", "pdf": "https://arxiv.org/pdf/2507.01800", "abs": "https://arxiv.org/abs/2507.01800", "authors": ["Shengli Zhou", "Jianuo Zhu", "Qilin Huang", "Fangjing Wang", "Yanfu Zhang", "Feng Zheng"], "title": "HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision", "categories": ["cs.CV", "cs.MM"], "comment": "ICANN 2025", "summary": "3D Visual Question-Answering (3D VQA) is pivotal for models to perceive the\nphysical world and perform spatial reasoning. Answer-centric supervision is a\ncommonly used training method for 3D VQA models. Many models that utilize this\nstrategy have achieved promising results in 3D VQA tasks. However, the\nanswer-centric approach only supervises the final output of models and allows\nmodels to develop reasoning pathways freely. The absence of supervision on the\nreasoning pathway enables the potential for developing superficial shortcuts\nthrough common patterns in question-answer pairs. Moreover, although\nslow-thinking methods advance large language models, they suffer from\nunderthinking. To address these issues, we propose \\textbf{HCNQA}, a 3D VQA\nmodel leveraging a hierarchical concentration narrowing supervision method. By\nmimicking the human process of gradually focusing from a broad area to specific\nobjects while searching for answers, our method guides the model to perform\nthree phases of concentration narrowing through hierarchical supervision. By\nsupervising key checkpoints on a general reasoning pathway, our method can\nensure the development of a rational and effective reasoning pathway. Extensive\nexperimental results demonstrate that our method can effectively ensure that\nthe model develops a rational reasoning pathway and performs better. The code\nis available at https://github.com/JianuoZhu/HCNQA.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHCNQA\u76843D VQA\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u6ce8\u610f\u529b\u96c6\u4e2d\u76d1\u7763\u65b9\u6cd5\uff0c\u9010\u6b65\u5f15\u5bfc\u6a21\u578b\u4ece\u5e7f\u6cdb\u533a\u57df\u805a\u7126\u5230\u7279\u5b9a\u5bf9\u8c61\uff0c\u786e\u4fdd\u63a8\u7406\u8def\u5f84\u7684\u5408\u7406\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u76843D VQA\u6a21\u578b\u901a\u5e38\u91c7\u7528\u7b54\u6848\u4e2d\u5fc3\u76d1\u7763\u65b9\u6cd5\uff0c\u4ec5\u5173\u6ce8\u6700\u7ec8\u8f93\u51fa\u800c\u5ffd\u7565\u63a8\u7406\u8def\u5f84\u7684\u76d1\u7763\uff0c\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4f9d\u8d56\u8868\u9762\u6377\u5f84\u3002\u6b64\u5916\uff0c\u6162\u601d\u8003\u65b9\u6cd5\u5b58\u5728\u6b20\u601d\u8003\u95ee\u9898\u3002", "method": "\u63d0\u51faHCNQA\u6a21\u578b\uff0c\u91c7\u7528\u5206\u5c42\u6ce8\u610f\u529b\u96c6\u4e2d\u76d1\u7763\u65b9\u6cd5\uff0c\u5206\u4e09\u4e2a\u9636\u6bb5\u9010\u6b65\u805a\u7126\u5177\u4f53\u5bf9\u8c61\uff0c\u76d1\u7763\u5173\u952e\u68c0\u67e5\u70b9\u4ee5\u786e\u4fdd\u63a8\u7406\u8def\u5f84\u7684\u5408\u7406\u6027\u548c\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u786e\u4fdd\u6a21\u578b\u53d1\u5c55\u51fa\u5408\u7406\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u53d6\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "HCNQA\u901a\u8fc7\u5206\u5c42\u76d1\u7763\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u67093D VQA\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.01571", "pdf": "https://arxiv.org/pdf/2507.01571", "abs": "https://arxiv.org/abs/2507.01571", "authors": ["Koen T. W. Teuwen", "Sam Baggen", "Emmanuele Zambon", "Luca Allodi"], "title": "On the Effect of Ruleset Tuning and Data Imbalance on Explainable Network Security Alert Classifications: a Case-Study on DeepCASE", "categories": ["cs.CR", "cs.LG", "cs.NI"], "comment": null, "summary": "Automation in Security Operations Centers (SOCs) plays a prominent role in\nalert classification and incident escalation. However, automated methods must\nbe robust in the presence of imbalanced input data, which can negatively affect\nperformance. Additionally, automated methods should make explainable decisions.\nIn this work, we evaluate the effect of label imbalance on the classification\nof network intrusion alerts. As our use-case we employ DeepCASE, the\nstate-of-the-art method for automated alert classification. We show that label\nimbalance impacts both classification performance and correctness of the\nclassification explanations offered by DeepCASE. We conclude tuning the\ndetection rules used in SOCs can significantly reduce imbalance and may benefit\nthe performance and explainability offered by alert post-processing methods\nsuch as DeepCASE. Therefore, our findings suggest that traditional methods to\nimprove the quality of input data can benefit automation.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u6807\u7b7e\u4e0d\u5e73\u8861\u4f1a\u5f71\u54cd\u81ea\u52a8\u5316\u5b89\u5168\u8fd0\u8425\u4e2d\u5fc3\uff08SOC\uff09\u7684\u5206\u7c7b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u8c03\u6574\u68c0\u6d4b\u89c4\u5219\u53ef\u6539\u5584\u8fd9\u4e00\u73b0\u8c61\u3002", "motivation": "\u81ea\u52a8\u5316SOC\u65b9\u6cd5\u5728\u9762\u5bf9\u4e0d\u5e73\u8861\u6570\u636e\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u9700\u5177\u5907\u53ef\u89e3\u91ca\u6027\uff0c\u56e0\u6b64\u7814\u7a76\u6807\u7b7e\u4e0d\u5e73\u8861\u5bf9\u7f51\u7edc\u5165\u4fb5\u8b66\u62a5\u5206\u7c7b\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u6700\u65b0\u65b9\u6cd5DeepCASE\uff0c\u8bc4\u4f30\u6807\u7b7e\u4e0d\u5e73\u8861\u5bf9\u5206\u7c7b\u6027\u80fd\u548c\u89e3\u91ca\u6b63\u786e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u6807\u7b7e\u4e0d\u5e73\u8861\u5bf9DeepCASE\u7684\u5206\u7c7b\u6027\u80fd\u548c\u89e3\u91ca\u6b63\u786e\u6027\u5747\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u8c03\u6574\u68c0\u6d4b\u89c4\u5219\u53ef\u7f13\u89e3\u4e0d\u5e73\u8861\u3002", "conclusion": "\u6539\u8fdb\u8f93\u5165\u6570\u636e\u8d28\u91cf\u7684\u4f20\u7edf\u65b9\u6cd5\u53ef\u63d0\u5347\u81ea\u52a8\u5316\u5de5\u5177\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.01274", "pdf": "https://arxiv.org/pdf/2507.01274", "abs": "https://arxiv.org/abs/2507.01274", "authors": ["Vishakha Lall", "Yisi Liu"], "title": "AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted and Presented at 11th International Maritime Science\n  Conference", "summary": "Traditional simulator-based training for maritime professionals is critical\nfor ensuring safety at sea but often depends on subjective trainer assessments\nof technical skills, behavioral focus, communication, and body language, posing\nchallenges such as subjectivity, difficulty in measuring key features, and\ncognitive limitations. Addressing these issues, this study develops an\nAI-driven framework to enhance maritime training by objectively assessing\ntrainee performance through visual focus tracking, speech recognition, and\nstress detection, improving readiness for high-risk scenarios. The system\nintegrates AI techniques, including visual focus determination using eye\ntracking, pupil dilation analysis, and computer vision; communication analysis\nthrough a maritime-specific speech-to-text model and natural language\nprocessing; communication correctness using large language models; and mental\nstress detection via vocal pitch. Models were evaluated on data from simulated\nmaritime scenarios with seafarers exposed to controlled high-stress events. The\nAI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for\nmaritime speech recognition, and ~90% for stress detection, surpassing existing\nbenchmarks. The system provides insights into visual attention, adherence to\ncommunication checklists, and stress levels under demanding conditions. This\nstudy demonstrates how AI can transform maritime training by delivering\nobjective performance analytics, enabling personalized feedback, and improving\npreparedness for real-world operational challenges.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2aAI\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u7126\u70b9\u8ffd\u8e2a\u3001\u8bed\u97f3\u8bc6\u522b\u548c\u538b\u529b\u68c0\u6d4b\u7b49\u6280\u672f\uff0c\u5ba2\u89c2\u8bc4\u4f30\u6d77\u4e8b\u57f9\u8bad\u4e2d\u7684\u53d7\u8bad\u8005\u8868\u73b0\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9ad8\u538b\u529b\u60c5\u666f\u4e0b\u7684\u51c6\u5907\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6d77\u4e8b\u6a21\u62df\u5668\u57f9\u8bad\u4f9d\u8d56\u4e3b\u89c2\u8bc4\u4f30\uff0c\u5b58\u5728\u4e3b\u89c2\u6027\u3001\u5173\u952e\u7279\u5f81\u96be\u4ee5\u6d4b\u91cf\u548c\u8ba4\u77e5\u5c40\u9650\u7b49\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7AI\u6280\u672f\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528AI\u6280\u672f\uff0c\u5305\u62ec\u89c6\u89c9\u7126\u70b9\u8ffd\u8e2a\uff08\u773c\u52a8\u3001\u77b3\u5b54\u653e\u5927\u5206\u6790\uff09\u3001\u8bed\u97f3\u8bc6\u522b\uff08\u6d77\u4e8b\u4e13\u7528\u8bed\u97f3\u8f6c\u6587\u672c\u6a21\u578b\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09\u3001\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u901a\u8baf\u51c6\u786e\u6027\uff0c\u4ee5\u53ca\u58f0\u97f3\u97f3\u9ad8\u68c0\u6d4b\u538b\u529b\u3002", "result": "AI\u7b97\u6cd5\u5728\u6a21\u62df\u6d77\u4e8b\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u89c6\u89c9\u68c0\u6d4b\u51c6\u786e\u7387\u7ea692%\uff0c\u8bed\u97f3\u8bc6\u522b\u7ea691%\uff0c\u538b\u529b\u68c0\u6d4b\u7ea690%\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cAI\u53ef\u4e3a\u6d77\u4e8b\u57f9\u8bad\u63d0\u4f9b\u5ba2\u89c2\u8868\u73b0\u5206\u6790\uff0c\u652f\u6301\u4e2a\u6027\u5316\u53cd\u9988\uff0c\u63d0\u5347\u5e94\u5bf9\u5b9e\u9645\u64cd\u4f5c\u6311\u6218\u7684\u51c6\u5907\u80fd\u529b\u3002"}}
{"id": "2507.01615", "pdf": "https://arxiv.org/pdf/2507.01615", "abs": "https://arxiv.org/abs/2507.01615", "authors": ["Alper Alimoglu", "Kamil Erdayandi", "Mustafa A. Mustafa", "\u00dcmit Cali"], "title": "EDGChain-E: A Decentralized Git-Based Framework for Versioning Encrypted Energy Data", "categories": ["cs.DC"], "comment": null, "summary": "This paper proposes a new decentralized framework, named EDGChain-E\n(Encrypted-Data-Git Chain for Energy), designed to manage version-controlled,\nencrypted energy data using blockchain and the InterPlanetary File System. The\nframework incorporates a Decentralized Autonomous Organization (DAO) to\norchestrate collaborative data governance across the lifecycle of energy\nresearch and operations, such as smart grid monitoring, demand forecasting, and\npeer-to-peer energy trading. In EDGChain-E, initial commits capture the full\nencrypted datasets-such as smart meter readings or grid telemetry-while\nsubsequent updates are tracked as encrypted Git patches, ensuring integrity,\ntraceability, and privacy. This versioning mechanism supports secure\ncollaboration across multiple stakeholders (e.g., utilities, researchers,\nregulators) without compromising sensitive or regulated information. We\nhighlight the framework's capability to maintain FAIR-compliant (Findable,\nAccessible, Interoperable, Reusable) provenance of encrypted data. By embedding\nhash-based content identifiers in Merkle trees, the system enables transparent,\nauditable, and immutable tracking of data changes, thereby supporting\nreproducibility and trust in decentralized energy applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEDGChain-E\u7684\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u5229\u7528\u533a\u5757\u94fe\u548c\u661f\u9645\u6587\u4ef6\u7cfb\u7edf\u7ba1\u7406\u7248\u672c\u63a7\u5236\u548c\u52a0\u5bc6\u7684\u80fd\u6e90\u6570\u636e\uff0c\u652f\u6301\u591a\u65b9\u5b89\u5168\u534f\u4f5c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u80fd\u6e90\u6570\u636e\u7ba1\u7406\u4e2d\u7684\u9690\u79c1\u3001\u5b8c\u6574\u6027\u548c\u591a\u65b9\u534f\u4f5c\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u533a\u5757\u94fe\u548cGit\u7684\u7248\u672c\u63a7\u5236\u673a\u5236\u3002", "method": "\u91c7\u7528\u533a\u5757\u94fe\u548c\u661f\u9645\u6587\u4ef6\u7cfb\u7edf\u5b58\u50a8\u52a0\u5bc6\u6570\u636e\uff0c\u901a\u8fc7DAO\u5b9e\u73b0\u534f\u540c\u6cbb\u7406\uff0c\u5e76\u4f7f\u7528Git\u8ddf\u8e2a\u6570\u636e\u66f4\u65b0\u4ee5\u786e\u4fdd\u9690\u79c1\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "result": "\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u80fd\u6e90\u6570\u636e\u7684\u5b89\u5168\u534f\u4f5c\uff0c\u652f\u6301FAIR\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u9ed8\u514b\u5c14\u6811\u786e\u4fdd\u6570\u636e\u53d8\u66f4\u7684\u900f\u660e\u6027\u548c\u4e0d\u53ef\u7be1\u6539\u6027\u3002", "conclusion": "EDGChain-E\u4e3a\u53bb\u4e2d\u5fc3\u5316\u80fd\u6e90\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u4fdd\u8bc1\u6570\u636e\u5b8c\u6574\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01267", "pdf": "https://arxiv.org/pdf/2507.01267", "abs": "https://arxiv.org/abs/2507.01267", "authors": ["Michelle Si", "Jian Pei"], "title": "Counterfactual Explanation of Shapley Value in Data Coalitions", "categories": ["cs.GT", "cs.DB"], "comment": null, "summary": "The Shapley value is widely used for data valuation in data markets. However,\nexplaining the Shapley value of an owner in a data coalition is an unexplored\nand challenging task. To tackle this, we formulate the problem of finding the\ncounterfactual explanation of Shapley value in data coalitions. Essentially,\ngiven two data owners $A$ and $B$ such that $A$ has a higher Shapley value than\n$B$, a counterfactual explanation is a smallest subset of data entries in $A$\nsuch that transferring the subset from $A$ to $B$ makes the Shapley value of\n$A$ less than that of $B$. We show that counterfactual explanations always\nexist, but finding an exact counterfactual explanation is NP-hard. Using Monte\nCarlo estimation to approximate counterfactual explanations directly according\nto the definition is still very costly, since we have to estimate the Shapley\nvalues of owners $A$ and $B$ after each possible subset shift. We develop a\nseries of heuristic techniques to speed up computation by estimating\ndifferential Shapley values, computing the power of singular data entries, and\nshifting subsets greedily, culminating in the SV-Exp algorithm. Our\nexperimental results on real datasets clearly demonstrate the efficiency of our\nmethod and the effectiveness of counterfactuals in interpreting the Shapley\nvalue of an owner.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u4e3a\u6570\u636e\u5e02\u573a\u4e2d\u6570\u636e\u6240\u6709\u8005\u7684Shapley\u503c\u63d0\u4f9b\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5SV-Exp\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89e3\u91ca\u6570\u636e\u8054\u76df\u4e2d\u6240\u6709\u8005\u7684Shapley\u503c\uff0c\u4e9f\u9700\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53cd\u4e8b\u5b9e\u89e3\u91ca\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u5b58\u5728\u4f46\u8ba1\u7b97\u590d\u6742\uff0c\u6700\u7ec8\u5f00\u53d1\u4e86SV-Exp\u7b97\u6cd5\uff0c\u5229\u7528\u542f\u53d1\u5f0f\u6280\u672f\u52a0\u901f\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6548\u7387\u53ca\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u6709\u6548\u6027\u3002", "conclusion": "SV-Exp\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86Shapley\u503c\u89e3\u91ca\u7684\u96be\u9898\u3002"}}
{"id": "2507.01436", "pdf": "https://arxiv.org/pdf/2507.01436", "abs": "https://arxiv.org/abs/2507.01436", "authors": ["Luke S. Snyder", "Chenglong Wang", "Steven Drucker"], "title": "Challenges & Opportunities with LLM-Assisted Visualization Retargeting", "categories": ["cs.HC"], "comment": "5 pages, 3 figures, 1 table", "summary": "Despite the ubiquity of visualization examples published on the web,\nretargeting existing custom chart implementations to new datasets remains\ndifficult, time-intensive, and tedious. The adaptation process assumes author\nfamiliarity with both the implementation of the example as well as how the new\ndataset might need to be transformed to fit into the example code. With recent\nadvances in Large Language Models (LLMs), automatic adaptation of code can be\nachieved from high-level user prompts, reducing the barrier for visualization\nretargeting. To better understand how LLMs can assist retargeting and its\npotential limitations, we characterize and evaluate the performance of LLM\nassistance across multiple datasets and charts of varying complexity,\ncategorizing failures according to type and severity. In our evaluation, we\ncompare two approaches: (1) directly instructing the LLM model to fully\ngenerate and adapt code by treating code as text inputs and (2) a more\nconstrained program synthesis pipeline where the LLM guides the code\nconstruction process by providing structural information (e.g., visual\nencodings) based on properties of the example code and data. We find that both\napproaches struggle when new data has not been appropriately transformed, and\ndiscuss important design recommendations for future retargeting systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7b80\u5316\u53ef\u89c6\u5316\u56fe\u8868\u4ee3\u7801\u7684\u91cd\u65b0\u5b9a\u5411\u8fc7\u7a0b\uff0c\u8bc4\u4f30\u4e86\u4e24\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\u5e76\u5206\u6790\u4e86\u5176\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u89c6\u5316\u56fe\u8868\u4ee3\u7801\u96be\u4ee5\u91cd\u65b0\u5b9a\u5411\u5230\u65b0\u6570\u636e\u96c6\uff0c\u8fc7\u7a0b\u8017\u65f6\u4e14\u590d\u6742\uff0c\u56e0\u6b64\u63a2\u7d22LLMs\u5982\u4f55\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u6bd4\u8f83\u4e24\u79cd\u65b9\u6cd5\uff1a\u76f4\u63a5\u751f\u6210\u4ee3\u7801\u7684\u6587\u672c\u8f93\u5165\u6cd5\u548c\u57fa\u4e8e\u7a0b\u5e8f\u5408\u6210\u7684\u7ed3\u6784\u5316\u5f15\u5bfc\u6cd5\uff0c\u6d4b\u8bd5\u5176\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u548c\u56fe\u8868\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u5728\u6570\u636e\u5904\u7406\u4e0d\u5f53\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u63ed\u793a\u4e86\u5931\u8d25\u7684\u7c7b\u578b\u548c\u4e25\u91cd\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u91cd\u5b9a\u5411\u7cfb\u7edf\u8bbe\u8ba1\u7684\u5173\u952e\u5efa\u8bae\uff0c\u4ee5\u4f18\u5316LLMs\u5728\u53ef\u89c6\u5316\u4ee3\u7801\u9002\u914d\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.01520", "pdf": "https://arxiv.org/pdf/2507.01520", "abs": "https://arxiv.org/abs/2507.01520", "authors": ["Yiran Zheng", "Yue Quan", "Su Yan", "Xinting Lv", "Yuguanmin Cao", "Minjie Fu", "Mingji Jin"], "title": "A bibliometric analysis on the current situation and hot trends of the impact of microplastics on soil based on CiteSpace", "categories": ["cs.DL", "cs.DB"], "comment": null, "summary": "This paper aims to comprehensively grasp the research status and development\ntrends of soil microplastics (MPs). It collects studies from the Web of Science\nCore Collection covering the period from 2013 to 2024. Employing CiteSpace and\nVOSviewer, the paper conducts in - depth analyses of literature regarding the\nenvironmental impacts of microplastics. These analyses involve keyword co -\noccurrence, clustering, burst term identification, as well as co - occurrence\nanalysis of authors and institutions. Microplastics can accumulate in soil,\ntransfer through food chains, and ultimately affect human health, making the\nresearch on them essential for effective pollution control. Focusing on the\ninternational research on the impacts of microplastics on soil and ecosystems,\nthe study reveals a steadily increasing trend in the number of publications\neach year, reaching a peak of 956 articles in 2024. A small number of highly\nproductive authors contribute significantly to the overall research output. The\nkeyword clustering analysis results in ten major clusters, including topics\nsuch as plastic pollution and microbial communities. The research on soil\nmicroplastics has evolved through three distinct stages: the preliminary\nexploration phase from 2013 to 2016, the expansion phase from 2017 to 2020, and\nthe integration phase from 2021 to 2024. For future research, multi - level\nassessments of the impacts of microplastics on soil ecosystems and organisms\nshould be emphasized, in order to fully uncover the associated hazards and\ndevelop practical solutions.", "AI": {"tldr": "\u7efc\u8ff0\u4e862013-2024\u5e74\u571f\u58e4\u5fae\u5851\u6599\uff08MPs\uff09\u7684\u7814\u7a76\u73b0\u72b6\u4e0e\u53d1\u5c55\u8d8b\u52bf\uff0c\u901a\u8fc7\u6587\u732e\u8ba1\u91cf\u5de5\u5177\u5206\u6790\u5173\u952e\u8bcd\u3001\u4f5c\u8005\u548c\u673a\u6784\u7b49\uff0c\u63ed\u793a\u4e86\u7814\u7a76\u70ed\u70b9\u4e0e\u6f14\u53d8\u9636\u6bb5\uff0c\u5e76\u5f3a\u8c03\u672a\u6765\u9700\u5173\u6ce8\u5fae\u5851\u6599\u5bf9\u571f\u58e4\u751f\u6001\u7684\u591a\u5c42\u6b21\u5f71\u54cd\u3002", "motivation": "\u5fae\u5851\u6599\u5728\u571f\u58e4\u4e2d\u79ef\u7d2f\u5e76\u901a\u8fc7\u98df\u7269\u94fe\u5f71\u54cd\u4eba\u7c7b\u5065\u5eb7\uff0c\u9700\u7cfb\u7edf\u6027\u7814\u7a76\u4ee5\u6307\u5bfc\u6c61\u67d3\u63a7\u5236\u3002", "method": "\u57fa\u4e8eWeb of Science\u6587\u732e\uff0c\u4f7f\u7528CiteSpace\u548cVOSviewer\u8fdb\u884c\u5173\u952e\u8bcd\u5171\u73b0\u3001\u805a\u7c7b\u3001\u4f5c\u8005\u4e0e\u673a\u6784\u5206\u6790\u3002", "result": "\u7814\u7a76\u6570\u91cf\u9010\u5e74\u589e\u957f\uff0c2024\u5e74\u8fbe\u5cf0\u503c\uff08956\u7bc7\uff09\uff1b\u5173\u952e\u8bcd\u805a\u7c7b\u663e\u793a\u5341\u5927\u4e3b\u9898\uff08\u5982\u5851\u6599\u6c61\u67d3\u3001\u5fae\u751f\u7269\u7fa4\u843d\uff09\uff1b\u7814\u7a76\u5206\u4e3a\u4e09\u9636\u6bb5\uff08\u63a2\u7d22\u3001\u6269\u5c55\u3001\u6574\u5408\uff09\u3002", "conclusion": "\u672a\u6765\u9700\u6df1\u5165\u7814\u7a76\u5fae\u5851\u6599\u5bf9\u571f\u58e4\u751f\u6001\u7684\u5c42\u7ea7\u5316\u5f71\u54cd\uff0c\u4ee5\u63ed\u793a\u5371\u5bb3\u5e76\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01471", "pdf": "https://arxiv.org/pdf/2507.01471", "abs": "https://arxiv.org/abs/2507.01471", "authors": ["Pengkun Liu", "Jackson Greene", "Jiali Huang", "Pingbo Tang", "Yu Hou"], "title": "Analysis of Drone-Assisted Building Inspection Training in VR vs 2D Monitor Display: an EEG Study", "categories": ["cs.HC"], "comment": null, "summary": "Researchers have been using simulation-based methods for drone-assisted\ninspection training. Multiple brain regions are associated with information\nprocesses and decision-making, and the connectivity of these regions may\nfurther influence inspectors' performance. However, researchers do not\nunderstand the pathways of the information flows when drone pilots process the\nmaintenance and manipulation of information, which may affect the efficiency of\ntacit knowledge transfer. This study aims to reveal the causal connection\nbetween participants' brain regions using an electroencephalogram and dynamic\ncausal modeling when processing drone-assisted building energy audit tasks\nusing different display modalities. The results showed similar single-direction\nconnectivity patterns for the different simulation groups. The results also\nshowed similar patterns between brain regions related to visual inspection\nperformance before and after training. These findings highlight the nature of\nbrain asymmetries and may be utilized in measuring cognitive states and\ndesigning adaptive automation in the knowledge transfer of drone-based\ninspection.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u8111\u7535\u56fe\u548c\u52a8\u6001\u56e0\u679c\u5efa\u6a21\u63ed\u793a\u65e0\u4eba\u673a\u8f85\u52a9\u5efa\u7b51\u80fd\u6e90\u5ba1\u8ba1\u4efb\u52a1\u4e2d\u4e0d\u540c\u663e\u793a\u6a21\u6001\u4e0b\u5927\u8111\u533a\u57df\u95f4\u7684\u56e0\u679c\u8054\u7cfb\uff0c\u7ed3\u679c\u663e\u793a\u76f8\u4f3c\u7684\u5355\u5411\u8fde\u63a5\u6a21\u5f0f\u548c\u8bad\u7ec3\u524d\u540e\u7684\u89c6\u89c9\u68c0\u67e5\u8868\u73b0\u76f8\u5173\u5927\u8111\u533a\u57df\u6a21\u5f0f\u3002", "motivation": "\u63a2\u8ba8\u65e0\u4eba\u673a\u98de\u884c\u5458\u5728\u4fe1\u606f\u5904\u7406\u548c\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u5927\u8111\u533a\u57df\u95f4\u7684\u4fe1\u606f\u6d41\u8def\u5f84\uff0c\u4ee5\u63d0\u9ad8\u9690\u6027\u77e5\u8bc6\u4f20\u9012\u7684\u6548\u7387\u3002", "method": "\u4f7f\u7528\u8111\u7535\u56fe\u548c\u52a8\u6001\u56e0\u679c\u5efa\u6a21\u5206\u6790\u53c2\u4e0e\u8005\u5904\u7406\u65e0\u4eba\u673a\u8f85\u52a9\u5efa\u7b51\u80fd\u6e90\u5ba1\u8ba1\u4efb\u52a1\u65f6\u7684\u5927\u8111\u533a\u57df\u8fde\u63a5\u3002", "result": "\u4e0d\u540c\u6a21\u62df\u7ec4\u663e\u793a\u51fa\u76f8\u4f3c\u7684\u5355\u5411\u8fde\u63a5\u6a21\u5f0f\uff0c\u4e14\u8bad\u7ec3\u524d\u540e\u4e0e\u89c6\u89c9\u68c0\u67e5\u8868\u73b0\u76f8\u5173\u7684\u5927\u8111\u533a\u57df\u6a21\u5f0f\u76f8\u4f3c\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u7684\u5927\u8111\u4e0d\u5bf9\u79f0\u6027\u53ef\u7528\u4e8e\u6d4b\u91cf\u8ba4\u77e5\u72b6\u6001\u548c\u8bbe\u8ba1\u65e0\u4eba\u673a\u68c0\u67e5\u4e2d\u77e5\u8bc6\u4f20\u9012\u7684\u81ea\u9002\u5e94\u81ea\u52a8\u5316\u3002"}}
{"id": "2507.01880", "pdf": "https://arxiv.org/pdf/2507.01880", "abs": "https://arxiv.org/abs/2507.01880", "authors": ["Stefano Schuppli", "Fawzi Mohamed", "Henrique Mendon\u00e7a", "Nina Mujkanovic", "Elia Palme", "Dino Conciatore", "Lukas Drescher", "Miguel Gila", "Pim Witlox", "Joost VandeVondele", "Maxime Martinasso", "Thomas C. Schulthess", "Torsten Hoefler"], "title": "Evolving HPC services to enable ML workloads on HPE Cray EX", "categories": ["cs.DC", "cs.LG"], "comment": "Presented at the Cray User Group 2025 (CUG'25)", "summary": "The Alps Research Infrastructure leverages GH200 technology at scale,\nfeaturing 10,752 GPUs. Accessing Alps provides a significant computational\nadvantage for researchers in Artificial Intelligence (AI) and Machine Learning\n(ML). While Alps serves a broad range of scientific communities, traditional\nHPC services alone are not sufficient to meet the dynamic needs of the ML\ncommunity. This paper presents an initial investigation into extending HPC\nservice capabilities to better support ML workloads. We identify key challenges\nand gaps we have observed since the early-access phase (2023) of Alps by the\nSwiss AI community and propose several technological enhancements. These\ninclude a user environment designed to facilitate the adoption of HPC for ML\nworkloads, balancing performance with flexibility; a utility for rapid\nperformance screening of ML applications during development; observability\ncapabilities and data products for inspecting ongoing large-scale ML workloads;\na utility to simplify the vetting of allocated nodes for compute readiness; a\nservice plane infrastructure to deploy various types of workloads, including\nsupport and inference services; and a storage infrastructure tailored to the\nspecific needs of ML workloads. These enhancements aim to facilitate the\nexecution of ML workloads on HPC systems, increase system usability and\nresilience, and better align with the needs of the ML community. We also\ndiscuss our current approach to security aspects. This paper concludes by\nplacing these proposals in the broader context of changes in the communities\nserved by HPC infrastructure like ours.", "AI": {"tldr": "\u963f\u5c14\u5351\u65af\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u5229\u7528GH200\u6280\u672f\uff0c\u63d0\u4f9b\u5927\u89c4\u6a21\u8ba1\u7b97\u80fd\u529b\u4ee5\u6ee1\u8db3AI\u548cML\u793e\u533a\u7684\u9700\u6c42\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u6269\u5c55HPC\u670d\u52a1\u4ee5\u652f\u6301ML\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u6280\u672f\u6539\u8fdb\uff0c\u5982\u7528\u6237\u73af\u5883\u4f18\u5316\u3001\u6027\u80fd\u7b5b\u9009\u5de5\u5177\u548c\u5b58\u50a8\u57fa\u7840\u8bbe\u65bd\u5b9a\u5236\u7b49\u3002", "motivation": "\u4f20\u7edfHPC\u670d\u52a1\u96be\u4ee5\u6ee1\u8db3ML\u793e\u533a\u7684\u52a8\u6001\u9700\u6c42\uff0c\u963f\u5c14\u5351\u65af\u57fa\u7840\u8bbe\u65bd\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u63d0\u4f9b\u66f4\u9002\u5408ML\u5de5\u4f5c\u8d1f\u8f7d\u7684\u652f\u6301\u3002", "method": "\u901a\u8fc7\u65e9\u671f\u8bbf\u95ee\u9636\u6bb5\u7684\u89c2\u5bdf\uff0c\u63d0\u51fa\u4e86\u5305\u62ec\u7528\u6237\u73af\u5883\u8bbe\u8ba1\u3001\u6027\u80fd\u7b5b\u67e5\u5de5\u5177\u3001\u53ef\u89c2\u6d4b\u6027\u670d\u52a1\u3001\u8282\u70b9\u9a8c\u8bc1\u5de5\u5177\u548c\u670d\u52a1\u5e73\u9762\u57fa\u7840\u8bbe\u65bd\u5728\u5185\u7684\u6280\u672f\u6539\u8fdb\u3002", "result": "\u63d0\u51fa\u7684\u6539\u8fdb\u6709\u52a9\u4e8eML\u5de5\u4f5c\u8d1f\u8f7d\u5728HPC\u7cfb\u7edf\u4e0a\u7684\u6267\u884c\uff0c\u63d0\u5347\u7cfb\u7edf\u53ef\u7528\u6027\u548c\u5f39\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u5efa\u8bae\u4e0d\u4ec5\u6ee1\u8db3\u4e86ML\u793e\u533a\u7684\u9700\u6c42\uff0c\u4e5f\u4e3aHPC\u57fa\u7840\u8bbe\u65bd\u7684\u66f4\u5e7f\u6cdb\u53d8\u9769\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2507.01616", "pdf": "https://arxiv.org/pdf/2507.01616", "abs": "https://arxiv.org/abs/2507.01616", "authors": ["Chengkun He", "Xiangmin Zhou", "Chen Wang", "Longbing Cao", "Jie Shao", "Xiaodong Li", "Guang Xu", "Carrie Jinqiu Hu", "Zahir Tari"], "title": "Enhanced Influence-aware Group Recommendation for Online Media Propagation", "categories": ["cs.IR", "cs.AI", "cs.DB"], "comment": null, "summary": "Group recommendation over social media streams has attracted significant\nattention due to its wide applications in domains such as e-commerce,\nentertainment, and online news broadcasting. By leveraging social connections\nand group behaviours, group recommendation (GR) aims to provide more accurate\nand engaging content to a set of users rather than individuals. Recently,\ninfluence-aware GR has emerged as a promising direction, as it considers the\nimpact of social influence on group decision-making. In earlier work, we\nproposed Influence-aware Group Recommendation (IGR) to solve this task.\nHowever, this task remains challenging due to three key factors: the large and\never-growing scale of social graphs, the inherently dynamic nature of influence\npropagation within user groups, and the high computational overhead of\nreal-time group-item matching.\n  To tackle these issues, we propose an Enhanced Influence-aware Group\nRecommendation (EIGR) framework. First, we introduce a Graph Extraction-based\nSampling (GES) strategy to minimise redundancy across multiple temporal social\ngraphs and effectively capture the evolving dynamics of both groups and items.\nSecond, we design a novel DYnamic Independent Cascade (DYIC) model to predict\nhow influence propagates over time across social items and user groups.\nFinally, we develop a two-level hash-based User Group Index (UG-Index) to\nefficiently organise user groups and enable real-time recommendation\ngeneration. Extensive experiments on real-world datasets demonstrate that our\nproposed framework, EIGR, consistently outperforms state-of-the-art baselines\nin both effectiveness and efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u589e\u5f3a\u578b\u5f71\u54cd\u529b\u611f\u77e5\u7fa4\u7ec4\u63a8\u8350\u6846\u67b6\uff08EIGR\uff09\uff0c\u901a\u8fc7\u56fe\u63d0\u53d6\u91c7\u6837\u7b56\u7565\u3001\u52a8\u6001\u72ec\u7acb\u7ea7\u8054\u6a21\u578b\u548c\u4e24\u7ea7\u54c8\u5e0c\u7528\u6237\u7ec4\u7d22\u5f15\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u793e\u4ea4\u56fe\u89c4\u6a21\u5927\u3001\u5f71\u54cd\u4f20\u64ad\u52a8\u6001\u6027\u548c\u5b9e\u65f6\u5339\u914d\u8ba1\u7b97\u5f00\u9500\u7b49\u6311\u6218\u3002", "motivation": "\u7fa4\u7ec4\u63a8\u8350\u5728\u793e\u4ea4\u5a92\u4f53\u6d41\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u793e\u4ea4\u56fe\u89c4\u6a21\u5927\u3001\u5f71\u54cd\u4f20\u64ad\u52a8\u6001\u6027\u53ca\u5b9e\u65f6\u5339\u914d\u5f00\u9500\u7b49\u9ad8\u6311\u6218\u3002", "method": "\u63d0\u51faEIGR\u6846\u67b6\uff0c\u5305\u62ecGES\u7b56\u7565\u51cf\u5c11\u5197\u4f59\u3001DYIC\u6a21\u578b\u9884\u6d4b\u5f71\u54cd\u4f20\u64ad\u52a8\u6001\u3001UG-\u7d22\u5f15\u5b9e\u73b0\u5b9e\u65f6\u63a8\u8350\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEIGR\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "EIGR\u901a\u8fc7\u52a8\u6001\u5efa\u6a21\u548c\u9ad8\u6548\u7d22\u5f15\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7fa4\u7ec4\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u5b9e\u65f6\u6027\u3002"}}
{"id": "2507.01548", "pdf": "https://arxiv.org/pdf/2507.01548", "abs": "https://arxiv.org/abs/2507.01548", "authors": ["Wen Zhan", "Ziqun Hua", "Peiyue Lin", "Yunfei Chen"], "title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "A version of this manuscript has been submitted to the [IASDR 2025\n  Conference](https://iasdr2025.org/) and is currently under review", "summary": "This paper explores how older adults, particularly aging migrants in urban\nChina, can engage AI-assisted co-creation to express personal narratives that\nare often fragmented, underrepresented, or difficult to verbalize. Through a\npilot workshop combining oral storytelling and the symbolic reconstruction of\nHanzi, participants shared memories of migration and recreated new character\nforms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM),\ntogether with physical materials. Supported by human facilitation and a soft AI\npresence, participants transformed lived experience into visual and tactile\nexpressions without requiring digital literacy. This approach offers new\nperspectives on human-AI collaboration and aging by repositioning AI not as a\ncontent producer but as a supportive mechanism, and by supporting narrative\nagency within sociotechnical systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u8001\u5e74\u4eba\uff08\u5c24\u5176\u662f\u57ce\u5e02\u4e2d\u56fd\u79fb\u6c11\uff09\u5982\u4f55\u901a\u8fc7AI\u8f85\u52a9\u5171\u521b\u8868\u8fbe\u5e38\u88ab\u5ffd\u89c6\u6216\u96be\u4ee5\u8a00\u8bf4\u7684\u4e2a\u4eba\u53d9\u4e8b\u3002", "motivation": "\u65e8\u5728\u5e2e\u52a9\u8001\u5e74\u79fb\u6c11\u901a\u8fc7\u975e\u6570\u5b57\u5316\u7684\u65b9\u5f0f\u8868\u8fbe\u788e\u7247\u5316\u6216\u88ab\u4f4e\u4f30\u7684\u53d9\u4e8b\uff0c\u540c\u65f6\u63a2\u7d22AI\u5728\u652f\u6301\u53d9\u4e8b\u521b\u4f5c\u4e2d\u7684\u65b0\u89d2\u8272\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u53e3\u5934\u8bb2\u8ff0\u548c\u6c49\u5b57\u8c61\u5f81\u91cd\u6784\u7684\u8bd5\u70b9\u5de5\u4f5c\u574a\uff0c\u53c2\u4e0e\u8005\u5229\u7528LLM\u7684\u7bc6\u4f53\u5b57\u5f62\u5efa\u8bae\u548c\u5b9e\u7269\u6750\u6599\u91cd\u65b0\u521b\u4f5c\u5b57\u7b26\u3002", "result": "\u53c2\u4e0e\u8005\u5c06\u751f\u6d3b\u7ecf\u9a8c\u8f6c\u5316\u4e3a\u89c6\u89c9\u548c\u89e6\u89c9\u8868\u8fbe\uff0c\u65e0\u9700\u6570\u5b57\u7d20\u517b\uff0c\u5c55\u793a\u4e86AI\u4f5c\u4e3a\u652f\u6301\u673a\u5236\u800c\u975e\u5185\u5bb9\u751f\u4ea7\u8005\u7684\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u4e0e\u4eba\u7c7b\u534f\u4f5c\u53ca\u8001\u9f84\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5f3a\u8c03AI\u5728\u652f\u6301\u53d9\u4e8b\u4e3b\u4f53\u6027\u548c\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.01067", "pdf": "https://arxiv.org/pdf/2507.01067", "abs": "https://arxiv.org/abs/2507.01067", "authors": ["Keun Soo Yim"], "title": "Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SY", "eess.SY"], "comment": null, "summary": "Time series forecasting models have diverse real world applications (e.g.,\nfrom electricity metrics to software workload). Latest foundational models\ntrained for time series forecasting show strengths (e.g., for long sequences\nand in zero-shot settings). However, foundational model was not yet used for\nforecasting rare, spiky events, i.e., a challenging target because those are a\ncorner case of extreme events. In this paper, we optimize a state-of-the-art\nfoundational model to forecast sporadic or spiky production outages of\nhigh-performance machine learning services powering billions of client devices.\nWe evaluate the forecasting errors of the foundational model compared with\nclassical stochastic forecasting models (e.g., moving average and\nautoregressive). The analysis helps us understand how each of the evaluated\nmodels performs for the sporadic or spiky events. For example, it identifies\nthe key patterns in the target data that are well tracked by the foundational\nmodel vs. each of the stochastic models. We use the models with optimal\nparameters to estimate a year-long outage statistics of a particular root cause\nwith less than 6% value errors.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528\u6700\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u9884\u6d4b\u7f55\u89c1\u3001\u5c16\u9510\u7684\u4e8b\u4ef6\uff08\u5982\u673a\u5668\u5b66\u4e60\u670d\u52a1\u7684\u751f\u4ea7\u4e2d\u65ad\uff09\uff0c\u5e76\u5bf9\u6bd4\u4e86\u8be5\u6a21\u578b\u4e0e\u7ecf\u5178\u968f\u673a\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5c1a\u672a\u7528\u4e8e\u9884\u6d4b\u7f55\u89c1\u7684\u5c16\u9510\u4e8b\u4ef6\u3002\u672c\u6587\u65e8\u5728\u4f18\u5316\u57fa\u7840\u6a21\u578b\uff0c\u4ee5\u9884\u6d4b\u9ad8\u6027\u80fd\u673a\u5668\u5b66\u4e60\u670d\u52a1\u7684\u5076\u53d1\u6027\u4e2d\u65ad\u3002", "method": "\u4f18\u5316\u4e86\u4e00\u4e2a\u5148\u8fdb\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u4e0e\u7ecf\u5178\u968f\u673a\u9884\u6d4b\u6a21\u578b\uff08\u5982\u79fb\u52a8\u5e73\u5747\u548c\u81ea\u56de\u5f52\u6a21\u578b\uff09\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5206\u6790\u5b83\u4eec\u7684\u9884\u6d4b\u8bef\u5dee\u548c\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u57fa\u7840\u6a21\u578b\u80fd\u8f83\u597d\u5730\u6355\u6349\u76ee\u6807\u6570\u636e\u7684\u5173\u952e\u6a21\u5f0f\uff0c\u5e76\u4e0e\u6700\u4f18\u53c2\u6570\u7684\u6a21\u578b\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4e00\u5e74\u957f\u4e2d\u65ad\u7edf\u8ba1\u7684\u4f4e\u8bef\u5dee\uff08<6%\uff09\u9884\u6d4b\u3002", "conclusion": "\u4f18\u5316\u540e\u7684\u57fa\u7840\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u7f55\u89c1\u5c16\u9510\u4e8b\u4ef6\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u968f\u673a\u9884\u6d4b\u6a21\u578b\u3002"}}
{"id": "2507.01690", "pdf": "https://arxiv.org/pdf/2507.01690", "abs": "https://arxiv.org/abs/2507.01690", "authors": ["Beatriz Severes", "Ana O. Henriques", "Rory Clark", "Paulo Bala", "Anna Carter", "Rua Mae Williams", "Geraldine Fitzpatrick"], "title": "Designing for Community Care: Reimagining Support for Equity & Well-being in Academia", "categories": ["cs.HC"], "comment": null, "summary": "Academic well-being is deeply influenced by peer-support networks, yet they\nremain informal, inequitable, and unsustainable, often relying on personal\nconnections and social capital rather than structured, inclusive systems.\nAdditionally, institutional well-being responses frequently focus on student\npopulations, neglecting the emotional labour of faculty and staff, reinforcing\nan exclusionary academic culture. Drawing on HCI methodologies, participatory\ndesign, and care ethics, this workshop will provide a space for rethinking how\nacademic communities can support inclusive networks. Through pre-workshop\nengagement, co-design activities, and reflection, participants will examine\nsystemic gaps in networks and explore ways to embed care, equity, and\nsustainability into academic peer-support frameworks -- from informal,\nexclusionary models to structured, inclusive care-based ecosystems. At the end\nof the workshop, participants will co-develop design strategies for integrating\ncare and resilience in academic ecosystems, resources for designing equitable\nsupport systems, and a peer network invested and committed to fostering a\nsupportive academic community.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7HCI\u65b9\u6cd5\u548c\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u91cd\u6784\u5b66\u672f\u5708\u4e2d\u7684\u540c\u4f34\u652f\u6301\u7f51\u7edc\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5305\u5bb9\u3001\u53ef\u6301\u7eed\u7684\u7cfb\u7edf\u3002", "motivation": "\u5b66\u672f\u5e78\u798f\u611f\u53d7\u5230\u540c\u4f34\u652f\u6301\u7f51\u7edc\u7684\u6df1\u523b\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u7f51\u7edc\u4f9d\u8d56\u975e\u6b63\u5f0f\u7684\u4e2a\u4eba\u5173\u7cfb\uff0c\u5b58\u5728\u4e0d\u516c\u5e73\u548c\u4e0d\u53ef\u6301\u7eed\u7684\u95ee\u9898\u3002\u6b64\u5916\uff0c\u673a\u6784\u5bf9\u5e78\u798f\u7684\u5173\u6ce8\u591a\u96c6\u4e2d\u4e8e\u5b66\u751f\uff0c\u5ffd\u89c6\u4e86\u6559\u804c\u5de5\u7684\u60c5\u611f\u52b3\u52a8\uff0c\u52a0\u5267\u4e86\u5b66\u672f\u6587\u5316\u7684\u6392\u65a5\u6027\u3002", "method": "\u91c7\u7528HCI\u65b9\u6cd5\u3001\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u548c\u5173\u6000\u4f26\u7406\u5b66\uff0c\u901a\u8fc7\u9884\u7814\u8ba8\u4f1a\u4e92\u52a8\u3001\u5171\u540c\u8bbe\u8ba1\u548c\u53cd\u601d\u6d3b\u52a8\uff0c\u63a2\u7d22\u5982\u4f55\u5c06\u5173\u6000\u3001\u516c\u5e73\u548c\u53ef\u6301\u7eed\u6027\u5d4c\u5165\u5b66\u672f\u540c\u4f34\u652f\u6301\u6846\u67b6\u3002", "result": "\u7814\u8ba8\u4f1a\u7ed3\u675f\u65f6\uff0c\u53c2\u4e0e\u8005\u5c06\u5171\u540c\u5f00\u53d1\u6574\u5408\u5173\u6000\u4e0e\u97e7\u6027\u7684\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u8bbe\u8ba1\u7b56\u7565\u3001\u516c\u5e73\u652f\u6301\u7cfb\u7edf\u7684\u8d44\u6e90\uff0c\u5e76\u5efa\u7acb\u4e00\u4e2a\u81f4\u529b\u4e8e\u652f\u6301\u5b66\u672f\u793e\u533a\u7684\u540c\u4f34\u7f51\u7edc\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u3001\u5305\u5bb9\u6027\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u53ef\u4ee5\u91cd\u6784\u5b66\u672f\u540c\u4f34\u652f\u6301\u7f51\u7edc\uff0c\u4f7f\u5176\u66f4\u516c\u5e73\u3001\u53ef\u6301\u7eed\uff0c\u5e76\u6db5\u76d6\u6240\u6709\u5b66\u672f\u6210\u5458\u7684\u60c5\u611f\u9700\u6c42\u3002"}}
{"id": "2507.01075", "pdf": "https://arxiv.org/pdf/2507.01075", "abs": "https://arxiv.org/abs/2507.01075", "authors": ["Gabriele Padovani", "Valentine Anantharaj", "Sandro Fiore"], "title": "Provenance Tracking in Large-Scale Machine Learning Systems", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "As the demand for large scale AI models continues to grow, the optimization\nof their training to balance computational efficiency, execution time, accuracy\nand energy consumption represents a critical multidimensional challenge.\nAchieving this balance requires not only innovative algorithmic techniques and\nhardware architectures but also comprehensive tools for monitoring, analyzing,\nand understanding the underlying processes involved in model training and\ndeployment. Provenance data information about the origins, context, and\ntransformations of data and processes has become a key component in this\npursuit. By leveraging provenance, researchers and engineers can gain insights\ninto resource usage patterns, identify inefficiencies, and ensure\nreproducibility and accountability in AI development workflows. For this\nreason, the question of how distributed resources can be optimally utilized to\nscale large AI models in an energy efficient manner is a fundamental one. To\nsupport this effort, we introduce the yProv4ML library, a tool designed to\ncollect provenance data in JSON format, compliant with the W3C PROV and ProvML\nstandards. yProv4ML focuses on flexibility and extensibility, and enables users\nto integrate additional data collection tools via plugins. The library is fully\nintegrated with the yProv framework, allowing for higher level pairing in tasks\nrun also through workflow management systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fayProv4ML\u5e93\uff0c\u7528\u4e8e\u6536\u96c6\u7b26\u5408W3C PROV\u548cProvML\u6807\u51c6\u7684JSON\u683c\u5f0f\u6eaf\u6e90\u6570\u636e\uff0c\u4ee5\u4f18\u5316\u5927\u89c4\u6a21AI\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u3001\u6267\u884c\u65f6\u95f4\u3001\u51c6\u786e\u6027\u548c\u80fd\u8017\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21AI\u6a21\u578b\u9700\u6c42\u7684\u589e\u957f\uff0c\u5982\u4f55\u5728\u8ba1\u7b97\u6548\u7387\u3001\u6267\u884c\u65f6\u95f4\u3001\u51c6\u786e\u6027\u548c\u80fd\u8017\u4e4b\u95f4\u5b9e\u73b0\u5e73\u8861\u6210\u4e3a\u5173\u952e\u6311\u6218\uff0c\u6eaf\u6e90\u6570\u636e\u4e3a\u6b64\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002", "method": "\u5f00\u53d1\u4e86\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684yProv4ML\u5e93\uff0c\u652f\u6301\u901a\u8fc7\u63d2\u4ef6\u96c6\u6210\u5176\u4ed6\u6570\u636e\u6536\u96c6\u5de5\u5177\uff0c\u5e76\u4e0eyProv\u6846\u67b6\u5b8c\u5168\u96c6\u6210\u3002", "result": "yProv4ML\u5e93\u80fd\u591f\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u5206\u6790\u8d44\u6e90\u4f7f\u7528\u6a21\u5f0f\u3001\u53d1\u73b0\u4f4e\u6548\u95ee\u9898\uff0c\u5e76\u786e\u4fddAI\u5f00\u53d1\u5de5\u4f5c\u6d41\u7684\u53ef\u91cd\u590d\u6027\u548c\u95ee\u8d23\u6027\u3002", "conclusion": "\u901a\u8fc7yProv4ML\u5e93\u7684\u5f15\u5165\uff0c\u53ef\u4ee5\u66f4\u9ad8\u6548\u5730\u5229\u7528\u5206\u5e03\u5f0f\u8d44\u6e90\uff0c\u4ee5\u80fd\u6e90\u53cb\u597d\u7684\u65b9\u5f0f\u6269\u5c55\u5927\u89c4\u6a21AI\u6a21\u578b\u3002"}}
{"id": "2507.01719", "pdf": "https://arxiv.org/pdf/2507.01719", "abs": "https://arxiv.org/abs/2507.01719", "authors": ["Dorian Peters", "Fernanda Espinoza", "Marco da Re", "Guido Ivetta", "Luciana Benotti", "Rafael A. Calvo"], "title": "Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "There is justifiable interest in leveraging conversational AI (CAI) for\nhealth across the majority world, but to be effective, CAI must respond\nappropriately within culturally and linguistically diverse contexts. Therefore,\nwe need ways to address the fact that current LLMs exclude many lived\nexperiences globally. Various advances are underway which focus on top-down\napproaches and increasing training data. In this paper, we aim to complement\nthese with a bottom-up locally-grounded approach based on qualitative data\ncollected during participatory workshops in Latin America. Our goal is to\nconstruct a rich and human-centred understanding of: a) potential areas of\ncultural misalignment in digital health; b) regional perspectives on chatbots\nfor health and c)strategies for creating culturally-appropriate CAI; with a\nfocus on the understudied Latin American context. Our findings show that\nacademic boundaries on notions of culture lose meaning at the ground level and\ntechnologies will need to engage with a broader framework; one that\nencapsulates the way economics, politics, geography and local logistics are\nentangled in cultural experience. To this end, we introduce a framework for\n'Pluriversal Conversational AI for Health' which allows for the possibility\nthat more relationality and tolerance, rather than just more data, may be\ncalled for.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u4e0b\u800c\u4e0a\u7684\u672c\u5730\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u62c9\u4e01\u7f8e\u6d32\u7684\u53c2\u4e0e\u8005\u5de5\u4f5c\u574a\u6536\u96c6\u5b9a\u6027\u6570\u636e\uff0c\u7814\u7a76\u6587\u5316\u5bf9\u9f50\u95ee\u9898\u3001\u5bf9\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u7684\u533a\u57df\u89c2\u70b9\u4ee5\u53ca\u521b\u5efa\u6587\u5316\u9002\u5b9c\u7684\u5bf9\u8bddAI\u7b56\u7565\uff0c\u6700\u7ec8\u63d0\u51fa\u4e86\u201c\u591a\u5143\u5bf9\u8bddAI\u5065\u5eb7\u201d\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5ffd\u89c6\u4e86\u8bb8\u591a\u5168\u7403\u6027\u7684\u751f\u6d3b\u7ecf\u9a8c\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u57fa\u4e8e\u672c\u5730\u6587\u5316\u7684\u65b9\u6cd5\u6765\u6539\u5584\u5065\u5eb7\u9886\u57df\u7684\u5bf9\u8bddAI\uff08CAI\uff09\u3002", "method": "\u901a\u8fc7\u62c9\u4e01\u7f8e\u6d32\u7684\u53c2\u4e0e\u6027\u5de5\u4f5c\u574a\u6536\u96c6\u5b9a\u6027\u6570\u636e\uff0c\u5206\u6790\u6570\u5b57\u5065\u5eb7\u4e2d\u7684\u6587\u5316\u5dee\u5f02\u3001\u533a\u57df\u5bf9\u804a\u5929\u673a\u5668\u4eba\u7684\u770b\u6cd5\u53ca\u6587\u5316\u9002\u5b9c\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6587\u5316\u5728\u57fa\u5c42\u5931\u53bb\u4e86\u5b66\u672f\u5b9a\u4e49\u7684\u8fb9\u754c\uff0c\u9700\u8981\u66f4\u5e7f\u6cdb\u7684\u6846\u67b6\uff08\u5305\u62ec\u7ecf\u6d4e\u3001\u653f\u6cbb\u3001\u5730\u7406\u548c\u672c\u5730\u7269\u6d41\uff09\u3002\u63d0\u51fa\u4e86\u201c\u591a\u5143\u5bf9\u8bddAI\u5065\u5eb7\u201d\u6846\u67b6\u3002", "conclusion": "\u5bf9\u8bddAI\u7684\u53d1\u5c55\u9700\u8981\u66f4\u6ce8\u91cd\u5173\u7cfb\u6027\u548c\u5305\u5bb9\u6027\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6570\u636e\u91cf\u7684\u589e\u52a0\u3002"}}
{"id": "2507.01078", "pdf": "https://arxiv.org/pdf/2507.01078", "abs": "https://arxiv.org/abs/2507.01078", "authors": ["Gabriele Padovani", "Valentine Anantharaj", "Sandro Fiore"], "title": "yProv4ML: Effortless Provenance Tracking for Machine Learning Systems", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "The rapid growth of interest in large language models (LLMs) reflects their\npotential for flexibility and generalization, and attracted the attention of a\ndiverse range of researchers. However, the advent of these techniques has also\nbrought to light the lack of transparency and rigor with which development is\npursued. In particular, the inability to determine the number of epochs and\nother hyperparameters in advance presents challenges in identifying the best\nmodel. To address this challenge, machine learning frameworks such as MLFlow\ncan automate the collection of this type of information. However, these tools\ncapture data using proprietary formats and pose little attention to lineage.\nThis paper proposes yProv4ML, a framework to capture provenance information\ngenerated during machine learning processes in PROV-JSON format, with minimal\ncode modifications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86yProv4ML\u6846\u67b6\uff0c\u7528\u4e8e\u4ee5PROV-JSON\u683c\u5f0f\u6355\u83b7\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u6570\u636e\u6765\u6e90\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u5728\u900f\u660e\u5ea6\u548c\u6570\u636e\u6eaf\u6e90\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\u7f3a\u4e4f\u900f\u660e\u6027\u548c\u4e25\u8c28\u6027\uff0c\u5c24\u5176\u662f\u8d85\u53c2\u6570\u8bbe\u7f6e\u548c\u6570\u636e\u6765\u6e90\u95ee\u9898\uff0c\u4fc3\u4f7f\u4e86yProv4ML\u6846\u67b6\u7684\u5f00\u53d1\u3002", "method": "\u901a\u8fc7yProv4ML\u6846\u67b6\uff0c\u4ee5PROV-JSON\u683c\u5f0f\u6355\u83b7\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u6570\u636e\u6765\u6e90\u4fe1\u606f\uff0c\u4e14\u53ea\u9700\u6700\u5c0f\u5316\u4ee3\u7801\u4fee\u6539\u3002", "result": "yProv4ML\u5b9e\u73b0\u4e86\u5bf9\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u7684\u6570\u636e\u6765\u6e90\u4fe1\u606f\u7684\u9ad8\u6548\u6355\u83b7\uff0c\u63d0\u5347\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "conclusion": "yProv4ML\u4e3a\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u7684\u900f\u660e\u6027\u548c\u6570\u636e\u6eaf\u6e90\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.01090", "pdf": "https://arxiv.org/pdf/2507.01090", "abs": "https://arxiv.org/abs/2507.01090", "authors": ["Riccardo Mengoni", "Walter Nadalin", "Mathys Rennela", "Jimmy Rotureau", "Tom Darras", "Julien Laurat", "Eleni Diamanti", "Ioannis Lavdas"], "title": "Efficient Gate Reordering for Distributed Quantum Compiling in Data Centers", "categories": ["quant-ph", "cs.DC"], "comment": null, "summary": "Just as classical computing relies on distributed systems, the quantum\ncomputing era requires new kinds of infrastructure and software tools. Quantum\nnetworks will become the backbone of hybrid, quantum-augmented data centers, in\nwhich quantum algorithms are distributed over a local network of quantum\nprocessing units (QPUs) interconnected via shared entanglement. In this\ncontext, it is crucial to develop methods and software that minimize the number\nof inter-QPU communications. Here we describe key features of the quantum\ncompiler araQne, which is designed to minimize distribution cost, measured by\nthe number of entangled pairs required to distribute a monolithic quantum\ncircuit using gate teleportation protocols. We establish the crucial role\nplayed by circuit reordering strategies, which strongly reduce the distribution\ncost compared to a baseline approach.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u6240\u9700\u7684\u91cf\u5b50\u7f51\u7edc\u548c\u8f6f\u4ef6\u5de5\u5177\uff0c\u4ecb\u7ecd\u4e86\u7f16\u8bd1\u5668araQne\u5982\u4f55\u901a\u8fc7\u7535\u8def\u91cd\u6392\u7b56\u7565\u51cf\u5c11\u91cf\u5b50\u5904\u7406\u5668\u95f4\u7684\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u9700\u8981\u5206\u5e03\u5f0f\u7cfb\u7edf\u652f\u6301\uff0c\u91cf\u5b50\u7f51\u7edc\u5c06\u6210\u4e3a\u6df7\u5408\u91cf\u5b50\u6570\u636e\u4e2d\u5fc3\u7684\u6838\u5fc3\uff0c\u7814\u7a76\u5982\u4f55\u51cf\u5c11\u91cf\u5b50\u5904\u7406\u5668\u95f4\u7684\u901a\u4fe1\u6210\u672c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f00\u53d1\u91cf\u5b50\u7f16\u8bd1\u5668araQne\uff0c\u5229\u7528\u95e8\u9690\u5f62\u4f20\u6001\u534f\u8bae\u548c\u7535\u8def\u91cd\u6392\u7b56\u7565\u6765\u6700\u5c0f\u5316\u5206\u5e03\u6210\u672c\uff08\u7ea0\u7f20\u5bf9\u6570\uff09\u3002", "result": "\u7535\u8def\u91cd\u6392\u7b56\u7565\u663e\u8457\u964d\u4f4e\u4e86\u5206\u5e03\u6210\u672c\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "araQne\u7f16\u8bd1\u5668\u901a\u8fc7\u4f18\u5316\u7535\u8def\u91cd\u6392\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u7f51\u7edc\u7684\u5206\u5e03\u5f0f\u5b9e\u73b0\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2507.01862", "pdf": "https://arxiv.org/pdf/2507.01862", "abs": "https://arxiv.org/abs/2507.01862", "authors": ["Sanjay Krishna Anbalagan", "Xinrui Nie", "Umesh Mohan", "Vijay Kumar Kanamarlapudi", "Anughna Kommalapati", "Xiaodan Zhao"], "title": "Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents", "categories": ["cs.HC", "cs.AI", "H.5.2; I.2.7"], "comment": "8 pages, 1 figure, pre-print of poster accepted for HCI International\n  2025 (HCII 2025), CCIS vol 2529", "summary": "Domain specific chatbot applications often involve multi step interactions,\nsuch as refining search filters, selecting multiple items, or performing\ncomparisons. Traditional graphical user interfaces (GUIs) handle these\nworkflows by providing explicit \"Submit\" (commit data) and \"Reset\" (discard\ndata) actions, allowing back-end systems to track user intent unambiguously. In\ncontrast, conversational agents rely on subtle language cues, which can lead to\nconfusion and incomplete context management. This paper proposes modeling these\nGUI inspired metaphors acknowledgment (submit like) and context switching\n(reset-like) as explicit tasks within large language model (LLM) prompts. By\ncapturing user acknowledgment, reset actions, and chain of thought (CoT)\nreasoning as structured session data, we preserve clarity, reduce user\nconfusion, and align domain-specific chatbot interactions with back-end logic.\nWe demonstrate our approach in hotel booking and customer management scenarios,\nhighlighting improvements in multi-turn task coherence, user satisfaction, and\nefficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5728LLM\u63d0\u793a\u4e2d\u660e\u786e\u5efa\u6a21GUI\u542f\u53d1\u5f0f\u4efb\u52a1\uff08\u5982\u786e\u8ba4\u548c\u4e0a\u4e0b\u6587\u5207\u6362\uff09\uff0c\u4ee5\u6539\u5584\u9886\u57df\u7279\u5b9a\u804a\u5929\u673a\u5668\u4eba\u7684\u591a\u8f6e\u4ea4\u4e92\u6e05\u6670\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edfGUI\u901a\u8fc7\u660e\u786e\u7684\u201c\u63d0\u4ea4\u201d\u548c\u201c\u91cd\u7f6e\u201d\u64cd\u4f5c\u7ba1\u7406\u7528\u6237\u610f\u56fe\uff0c\u800c\u804a\u5929\u673a\u5668\u4eba\u4f9d\u8d56\u8bed\u8a00\u7ebf\u7d22\u6613\u5bfc\u81f4\u4e0a\u4e0b\u6587\u6df7\u4e71\u3002", "method": "\u5c06GUI\u542f\u53d1\u5f0f\u4efb\u52a1\u5efa\u6a21\u4e3aLLM\u63d0\u793a\u4e2d\u7684\u660e\u786e\u4efb\u52a1\uff0c\u5e76\u6355\u6349\u7528\u6237\u786e\u8ba4\u3001\u91cd\u7f6e\u548c\u601d\u7ef4\u94fe\u4f5c\u4e3a\u7ed3\u6784\u5316\u4f1a\u8bdd\u6570\u636e\u3002", "result": "\u5728\u9152\u5e97\u9884\u8ba2\u548c\u5ba2\u6237\u7ba1\u7406\u573a\u666f\u4e2d\uff0c\u591a\u8f6e\u4efb\u52a1\u8fde\u8d2f\u6027\u3001\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u6548\u7387\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u4f1a\u8bdd\u6570\u636e\uff0c\u53ef\u4ee5\u63d0\u5347\u804a\u5929\u673a\u5668\u4eba\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u4ea4\u4e92\u6e05\u6670\u5ea6\u548c\u6548\u7387\u3002"}}
{"id": "2507.01285", "pdf": "https://arxiv.org/pdf/2507.01285", "abs": "https://arxiv.org/abs/2507.01285", "authors": ["Aymen Rayane Khouas", "Mohamed Reda Bouadjenek", "Hakim Hacid", "Sunil Aryal"], "title": "Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated Recommendation", "categories": ["cs.LG", "cs.DC", "cs.IR"], "comment": "17 pages, 5 figures", "summary": "Graph federated recommendation systems offer a privacy-preserving alternative\nto traditional centralized recommendation architectures, which often raise\nconcerns about data security. While federated learning enables personalized\nrecommendations without exposing raw user data, existing aggregation methods\noverlook the unique properties of user embeddings in this setting. Indeed,\ntraditional aggregation methods fail to account for their complexity and the\ncritical role of user similarity in recommendation effectiveness. Moreover,\nevolving user interactions require adaptive aggregation while preserving the\ninfluence of high-relevance anchor users (the primary users before expansion in\ngraph-based frameworks). To address these limitations, we introduce\nDist-FedAvg, a novel distance-based aggregation method designed to enhance\npersonalization and aggregation efficiency in graph federated learning. Our\nmethod assigns higher aggregation weights to users with similar embeddings,\nwhile ensuring that anchor users retain significant influence in local updates.\nEmpirical evaluations on multiple datasets demonstrate that Dist-FedAvg\nconsistently outperforms baseline aggregation techniques, improving\nrecommendation accuracy while maintaining seamless integration into existing\nfederated learning frameworks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ddd\u79bb\u7684\u805a\u5408\u65b9\u6cd5Dist-FedAvg\uff0c\u7528\u4e8e\u56fe\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u4e2a\u6027\u5316\u63a8\u8350\u548c\u805a\u5408\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u7528\u6237\u5d4c\u5165\u7684\u590d\u6742\u6027\u548c\u7528\u6237\u76f8\u4f3c\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e14\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u7528\u6237\u4ea4\u4e92\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u805a\u5408\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u8d4b\u4e88\u76f8\u4f3c\u7528\u6237\u5d4c\u5165\u66f4\u9ad8\u7684\u805a\u5408\u6743\u91cd\uff0c\u5e76\u4fdd\u6301\u951a\u70b9\u7528\u6237\u7684\u5f71\u54cd\u529b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u540d\u4e3aDist-FedAvg\u7684\u805a\u5408\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDist-FedAvg\u5728\u63a8\u8350\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u3002", "conclusion": "Dist-FedAvg\u662f\u4e00\u79cd\u6709\u6548\u7684\u805a\u5408\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u56fe\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u540c\u65f6\u517c\u987e\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2507.01944", "pdf": "https://arxiv.org/pdf/2507.01944", "abs": "https://arxiv.org/abs/2507.01944", "authors": ["Ehud Sharlin", "Yuichi Itoh", "Benjamin Watson", "Yoshifumi Kitamura", "Steve Sutphen", "Lili Liu", "Fumio Kishino"], "title": "Spatial tangible user interfaces for cognitive assessment and training", "categories": ["cs.HC"], "comment": null, "summary": "This paper discusses Tangible User Interfaces (TUIs) and their potential\nimpact on cognitive assessment and cognitive training. We believe that TUIs,\nand particularly a subset that we dub spatial TUIs, can extend human computer\ninteraction beyond some of its current limitations. Spatial TUIs exploit human\ninnate spatial and tactile ability in an intuitive and direct manner, affording\ninteraction paradigms that are practically impossible using current interface\ntechnology. As proof-of-concept we examine implementations in the field of\ncognitive assessment and training. In this paper we use Cognitive Cubes, a\nnovel TUI we developed, as an applied test bed for our beliefs, presenting\npromising experimental results for cognitive assessment of spatial ability, and\npossibly for training purposes.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u53ef\u89e6\u7528\u6237\u754c\u9762\uff08TUIs\uff09\u53ca\u5176\u5728\u8ba4\u77e5\u8bc4\u4f30\u548c\u8bad\u7ec3\u4e2d\u7684\u6f5c\u5728\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u7a7a\u95f4TUIs\u7684\u5b50\u96c6\uff0c\u80fd\u591f\u7a81\u7834\u73b0\u6709\u4ea4\u4e92\u6280\u672f\u7684\u9650\u5236\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u901a\u8fc7\u7a7a\u95f4TUIs\u5229\u7528\u4eba\u7c7b\u56fa\u6709\u7684\u7a7a\u95f4\u548c\u89e6\u89c9\u80fd\u529b\uff0c\u6269\u5c55\u4eba\u673a\u4ea4\u4e92\u7684\u53ef\u80fd\u6027\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u578bTUI\uff08Cognitive Cubes\uff09\uff0c\u5e76\u4ee5\u6b64\u4f5c\u4e3a\u5b9e\u9a8c\u5e73\u53f0\uff0c\u9a8c\u8bc1\u5176\u7528\u4e8e\u7a7a\u95f4\u80fd\u529b\u8ba4\u77e5\u8bc4\u4f30\u548c\u8bad\u7ec3\u7684\u53ef\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86Cognitive Cubes\u5728\u7a7a\u95f4\u80fd\u529b\u8ba4\u77e5\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u53ef\u80fd\u9002\u7528\u4e8e\u8bad\u7ec3\u76ee\u7684\u3002", "conclusion": "\u7ed3\u8bba\u8ba4\u4e3a\u7a7a\u95f4TUIs\u4e3a\u8ba4\u77e5\u8bc4\u4f30\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u4ea4\u4e92\u8303\u5f0f\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.01453", "pdf": "https://arxiv.org/pdf/2507.01453", "abs": "https://arxiv.org/abs/2507.01453", "authors": ["Michelle Yeo", "Haoqian Zhang"], "title": "Rational Censorship Attack: Breaking Blockchain with a Blackboard", "categories": ["cs.GT", "cs.CR", "cs.DC"], "comment": null, "summary": "Censorship resilience is a fundamental assumption underlying the security of\nblockchain protocols. Additionally, the analysis of blockchain security from an\neconomic and game theoretic perspective has been growing in popularity in\nrecent years. In this work, we present a surprising rational censorship attack\non blockchain censorship resilience when we adopt the analysis of blockchain\nsecurity from a game theoretic lens and assume all users are rational. In our\nattack, a colluding group with sufficient voting power censors the remainder\nnodes such that the group alone can gain all the rewards from maintaining the\nblockchain. We show that if nodes are rational, coordinating this attack just\nrequires a public read and write blackboard and we formally model the attack\nusing a game theoretic framework. Furthermore, we note that to ensure the\nsuccess of the attack, nodes need to know the total true voting power held by\nthe colluding group. We prove that the strategy to join the rational censorship\nattack and also for nodes to honestly declare their power is a subgame perfect\nequilibrium in the corresponding extensive form game induced by our attack.\nFinally, we discuss the implications of the attack on blockchain users and\nprotocol designers as well as some potential countermeasures.", "AI": {"tldr": "\u533a\u5757\u94fe\u7684\u5ba1\u67e5\u97e7\u6027\u662f\u534f\u8bae\u5b89\u5168\u7684\u57fa\u7840\u5047\u8bbe\u3002\u672c\u6587\u4ece\u535a\u5f08\u8bba\u89c6\u89d2\u5206\u6790\u533a\u5757\u94fe\u5b89\u5168\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u7406\u6027\u5ba1\u67e5\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u5f53\u6240\u6709\u7528\u6237\u7406\u6027\u65f6\uff0c\u5c11\u6570\u7fa4\u4f53\u53ef\u4ee5\u901a\u8fc7\u5408\u8c0b\u5ba1\u67e5\u5176\u4ed6\u8282\u70b9\u72ec\u5360\u5956\u52b1\u3002", "motivation": "\u7814\u7a76\u533a\u5757\u94fe\u5b89\u5168\u6027\u65f6\uff0c\u5ba1\u67e5\u97e7\u6027\u5e38\u88ab\u89c6\u4e3a\u57fa\u7840\u5047\u8bbe\u3002\u8fd1\u5e74\u6765\uff0c\u535a\u5f08\u8bba\u548c\u7ecf\u6d4e\u89d2\u5ea6\u7684\u5206\u6790\u65e5\u76ca\u6d41\u884c\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u5f53\u7528\u6237\u7406\u6027\u65f6\uff0c\u533a\u5757\u94fe\u5ba1\u67e5\u97e7\u6027\u7684\u6f5c\u5728\u8106\u5f31\u6027\u3002", "method": "\u901a\u8fc7\u535a\u5f08\u8bba\u6846\u67b6\u5efa\u6a21\uff0c\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u7406\u6027\u5ba1\u67e5\u653b\u51fb\uff0c\u5047\u8bbe\u5408\u8c0b\u7fa4\u4f53\u62e5\u6709\u8db3\u591f\u6295\u7968\u6743\uff0c\u53ef\u4ee5\u5ba1\u67e5\u5176\u4ed6\u8282\u70b9\u4ee5\u72ec\u5360\u5956\u52b1\u3002\u653b\u51fb\u4ec5\u9700\u516c\u5171\u8bfb\u5199\u9ed1\u677f\uff0c\u5e76\u8981\u6c42\u8282\u70b9\u77e5\u9053\u5408\u8c0b\u7fa4\u4f53\u7684\u771f\u5b9e\u6295\u7968\u6743\u3002", "result": "\u8bc1\u660e\u4e86\u52a0\u5165\u7406\u6027\u5ba1\u67e5\u653b\u51fb\u53ca\u8bda\u5b9e\u5730\u58f0\u660e\u6295\u7968\u6743\u662f\u5b50\u535a\u5f08\u5b8c\u7f8e\u5747\u8861\u3002\u653b\u51fb\u7684\u6210\u529f\u4f9d\u8d56\u4e8e\u5408\u8c0b\u7fa4\u4f53\u6295\u7968\u6743\u7684\u516c\u5f00\u6027\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u7406\u6027\u7528\u6237\u73af\u5883\u4e0b\u533a\u5757\u94fe\u5ba1\u67e5\u97e7\u6027\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u5e76\u4e3a\u7528\u6237\u548c\u534f\u8bae\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u5bf9\u6297\u63aa\u65bd\u7684\u601d\u8def\u3002"}}
{"id": "2507.01770", "pdf": "https://arxiv.org/pdf/2507.01770", "abs": "https://arxiv.org/abs/2507.01770", "authors": ["Guanglu Zhang", "Qihang Shan", "Jonathan Cagan"], "title": "GPU-based complete search for nonlinear minimization subject to bounds", "categories": ["math.NA", "cs.AI", "cs.DC", "cs.MS", "cs.NA", "math.OC", "65G20, 65G30, 65G40, 90C06, 90C26, 90C30", "G.1.6; G.4"], "comment": "36 pages, 3 figures", "summary": "This paper introduces a GPU-based complete search method to enclose the\nglobal minimum of a nonlinear function subject to simple bounds on the\nvariables. Using interval analysis, coupled with the computational power and\narchitecture of GPU, the method iteratively rules out the regions in the search\ndomain where the global minimum cannot exist and leaves a finite set of regions\nwhere the global minimum must exist. For effectiveness, because of the rigor of\ninterval analysis, the method is guaranteed to enclose the global minimum of\nthe nonlinear function even in the presence of rounding errors. For efficiency,\nthe method employs a novel GPU-based single program, single data parallel\nprogramming style to circumvent major GPU performance bottlenecks, and a\nvariable cycling technique is also integrated into the method to reduce\ncomputational cost when minimizing large-scale nonlinear functions. The method\nis validated by minimizing 10 multimodal benchmark test functions with scalable\ndimensions, including the well-known Ackley function, Griewank function, Levy\nfunction, and Rastrigin function. These benchmark test functions represent\ngrand challenges of global optimization, and enclosing the guaranteed global\nminimum of these benchmark test functions with more than 80 dimensions has not\nbeen reported in the literature. Our method completely searches the feasible\ndomain and successfully encloses the guaranteed global minimum of these 10\nbenchmark test functions with up to 10,000 dimensions using only one GPU in a\nreasonable computation time, far exceeding the reported results in the\nliterature due to the unique method design and implementation based on GPU\narchitecture.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPU\u7684\u5168\u5c40\u641c\u7d22\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u53d8\u91cf\u6709\u754c\u7684\u60c5\u51b5\u4e0b\u5bfb\u627e\u975e\u7ebf\u6027\u51fd\u6570\u7684\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u5229\u7528\u533a\u95f4\u5206\u6790\u548c\u9ad8\u6027\u80fdGPU\u67b6\u6784\uff0c\u786e\u4fdd\u7ed3\u679c\u5168\u5c40\u6700\u4f18\u4e14\u9ad8\u6548\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u5ea6\u975e\u7ebf\u6027\u51fd\u6570\u7684\u5168\u5c40\u4f18\u5316\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u740680\u7ef4\u4ee5\u4e0a\u51fd\u6570\u65f6\uff0c\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u4e14\u4e25\u8c28\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u533a\u95f4\u5206\u6790\u548cGPU\u5e76\u884c\u8ba1\u7b97\uff0c\u901a\u8fc7\u8fed\u4ee3\u6392\u9664\u4e0d\u53ef\u80fd\u5305\u542b\u5168\u5c40\u6700\u5c0f\u503c\u7684\u533a\u57df\uff0c\u5e76\u91c7\u7528\u5355\u7a0b\u5e8f\u591a\u6570\u636e\uff08SPMD\uff09\u7f16\u7a0b\u98ce\u683c\u548c\u53d8\u91cf\u5faa\u73af\u6280\u672f\u63d0\u5347\u6548\u7387\u3002", "result": "\u6210\u529f\u5728\u5355GPU\u4e0a\u9ad8\u6548\u641c\u7d22\u5e76\u786e\u5b9a\u4e8610\u4e2a\u591a\u6a21\u6001\u6d4b\u8bd5\u51fd\u6570\uff08\u5305\u62ecAckley\u3001Griewank\u7b49\uff09\u5728\u9ad8\u8fbe10,000\u7ef4\u7684\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u8fdc\u8d85\u6587\u732e\u62a5\u9053\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7GPU\u67b6\u6784\u548c\u72ec\u7279\u7684\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u7ef4\u5ea6\u5168\u5c40\u4f18\u5316\u7684\u6548\u7387\u548c\u53ef\u884c\u6027\uff0c\u586b\u8865\u4e86\u6587\u732e\u4e2d\u7684\u7a7a\u767d\u3002"}}
{"id": "2507.01061", "pdf": "https://arxiv.org/pdf/2507.01061", "abs": "https://arxiv.org/abs/2507.01061", "authors": ["Jingjing Qu", "Kejia Hu", "Jun Zhu", "Wenhao Li", "Teng Wang", "Zhiyun Chen", "Yulei Ye", "Chaochao Lu", "Aimin Zhou", "Xiangfeng Wang", "James Evan"], "title": "Epitome: Pioneering an Experimental Platform for AI-Social Science Integration", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "18 pages, 5figures", "summary": "The integration of Large Language Models (LLMs) into social science\nexperiments represents a transformative approach to understanding human-AI\ninteractions and their societal impacts. We introduce Epitome, the world's\nfirst open experimental platform dedicated to the deep integration of\nartificial intelligence and social science. Rooted in theoretical foundations\nfrom management, communication studies, sociology, psychology, and ethics,\nEpitome focuses on the interactive impacts of AI on individuals, organizations,\nand society during its real-world deployment. It constructs a theoretical\nsupport system through cross-disciplinary experiments. The platform offers a\none-stop comprehensive experimental solution spanning \"foundation\nmodels-complex application development-user feedback\" through seven core\nmodules, while embedding the classical \"control-comparison-comparative causal\nlogic\" of social science experiments into multilevel human-computer interaction\nenvironments, including dialogues, group chats, and multi-agent virtual\nscenarios. With its canvas-style, user-friendly interface, Epitome enables\nresearchers to easily design and run complex experimental scenarios,\nfacilitating systematic investigations into the social impacts of AI and\nexploration of integrated solutions.To demonstrate its capabilities, we\nreplicated three seminal social science experiments involving LLMs, showcasing\nEpitome's potential to streamline complex experimental designs and produce\nrobust results, suitable for publishing in the top selective journals. Our\nfindings highlight the platform's utility in enhancing the efficiency and\nquality of human-AI interactions, providing valuable insights into the societal\nimplications of AI technologies. Epitome thus offers a powerful tool for\nadvancing interdisciplinary research at the intersection of AI and social\nscience, with potential applications in policy-making, ...", "AI": {"tldr": "Epitome\u662f\u4e00\u4e2a\u5f00\u653e\u5f0f\u5b9e\u9a8c\u5e73\u53f0\uff0c\u4e13\u6ce8\u4e8eAI\u4e0e\u793e\u4f1a\u79d1\u5b66\u6df1\u5ea6\u878d\u5408\u7684\u5e73\u53f0\uff0c\u65e8\u5728\u901a\u8fc7\u591a\u5b66\u79d1\u5b9e\u9a8c\u7814\u7a76AI\u5728\u793e\u4f1a\u4e2d\u7684\u4e92\u52a8\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u4eba\u7c7b\u4e0eAI\u7684\u4e92\u52a8\u53ca\u5176\u793e\u4f1a\u5f71\u54cd\uff0c\u63a8\u52a8\u8de8\u5b66\u79d1\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u4e03\u4e2a\u6838\u5fc3\u6a21\u5757\u63d0\u4f9b\u4e00\u7ad9\u5f0f\u5b9e\u9a8c\u89e3\u51b3\u65b9\u6848\uff0c\u5d4c\u5165\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u7684\u7ecf\u5178\u903b\u8f91\u3002", "result": "\u5c55\u793a\u4e86Epitome\u5728\u7b80\u5316\u590d\u6742\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u4ea7\u751f\u7a33\u5065\u7ed3\u679c\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "Epitome\u4e3aAI\u4e0e\u793e\u4f1a\u79d1\u5b66\u7684\u8de8\u5b66\u79d1\u7814\u7a76\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2507.01902", "pdf": "https://arxiv.org/pdf/2507.01902", "abs": "https://arxiv.org/abs/2507.01902", "authors": ["Grier M. Jones", "Hans-Arno Jacobsen"], "title": "Analyzing Common Electronic Structure Theory Algorithms for Distributed Quantum Computing", "categories": ["quant-ph", "cs.DC", "physics.chem-ph"], "comment": null, "summary": "To move towards the utility era of quantum computing, many corporations have\nposed distributed quantum computing (DQC) as a framework for scaling the\ncurrent generation of devices for practical applications. One of these\napplications is quantum chemistry, also known as electronic structure theory,\nwhich has been poised as a \"killer application\" of quantum computing, To this\nend, we analyze five electronic structure methods, found in common packages\nsuch as Tequila and ffsim, which can be easily interfaced with the Qiskit\nCircuit Cutting addon. Herein, we provide insights into cutting these\nalgorithms using local operations (LO) to determine their aptitude for\ndistribution. The key findings of our work are that many of these algorithms\ncannot be efficiently parallelized using LO, and new methods must be developed\nto apply electronic structure theory within a DQC framework.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\uff08DQC\uff09\u5728\u91cf\u5b50\u5316\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u4e94\u79cd\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\uff0c\u53d1\u73b0\u591a\u6570\u65e0\u6cd5\u901a\u8fc7\u5c40\u90e8\u64cd\u4f5c\uff08LO\uff09\u9ad8\u6548\u5e76\u884c\u5316\uff0c\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u63a8\u8fdb\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u7814\u7a76\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\uff08DQC\uff09\u5728\u91cf\u5b50\u5316\u5b66\u4e2d\u7684\u6f5c\u529b\uff0c\u56e0\u4e3a\u91cf\u5b50\u5316\u5b66\u88ab\u89c6\u4e3a\u91cf\u5b50\u8ba1\u7b97\u7684\u201c\u6740\u624b\u7ea7\u5e94\u7528\u201d\u3002", "method": "\u5206\u6790\u4e86\u4e94\u79cd\u5e38\u89c1\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\uff08\u5982Tequila\u548cffsim\u4e2d\u7684\u65b9\u6cd5\uff09\uff0c\u5e76\u5229\u7528Qiskit Circuit Cutting\u63d2\u4ef6\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u5728LO\u4e0b\u7684\u5e76\u884c\u5316\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u591a\u6570\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\u65e0\u6cd5\u901a\u8fc7LO\u9ad8\u6548\u5e76\u884c\u5316\uff0c\u9650\u5236\u4e86\u5176\u5728DQC\u6846\u67b6\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u624d\u80fd\u5c06\u7535\u5b50\u7ed3\u6784\u7406\u8bba\u6709\u6548\u5e94\u7528\u4e8e\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u6846\u67b6\u4e2d\u3002"}}
{"id": "2507.01111", "pdf": "https://arxiv.org/pdf/2507.01111", "abs": "https://arxiv.org/abs/2507.01111", "authors": ["Haosen Xing", "Haoran Ma", "Sijin Zhang", "Hartmut Geyer"], "title": "Environment-Aware and Human-Cooperative Swing Control for Lower-Limb Prostheses in Diverse Obstacle Scenarios", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Current control strategies for powered lower limb prostheses often lack\nawareness of the environment and the user's intended interactions with it. This\nlimitation becomes particularly apparent in complex terrains. Obstacle\nnegotiation, a critical scenario exemplifying such challenges, requires both\nreal-time perception of obstacle geometry and responsiveness to user intention\nabout when and where to step over or onto, to dynamically adjust swing\ntrajectories. We propose a novel control strategy that fuses environmental\nawareness and human cooperativeness: an on-board depth camera detects obstacles\nahead of swing phase, prompting an elevated early-swing trajectory to ensure\nclearance, while late-swing control defers to natural biomechanical cues from\nthe user. This approach enables intuitive stepping strategies without requiring\nunnatural movement patterns. Experiments with three non-amputee participants\ndemonstrated 100 percent success across more than 150 step-overs and 30\nstep-ons with randomly placed obstacles of varying heights (4-16 cm) and\ndistances (15-70 cm). By effectively addressing obstacle navigation -- a\ngateway challenge for complex terrain mobility -- our system demonstrates\nadaptability to both environmental constraints and user intentions, with\npromising applications across diverse locomotion scenarios.", "AI": {"tldr": "\u5f53\u524d\u52a8\u529b\u4e0b\u80a2\u5047\u80a2\u7684\u63a7\u5236\u7b56\u7565\u7f3a\u4e4f\u5bf9\u73af\u5883\u548c\u4f7f\u7528\u8005\u610f\u56fe\u7684\u611f\u77e5\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u5730\u5f62\u4e2d\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u73af\u5883\u611f\u77e5\u548c\u7528\u6237\u534f\u4f5c\u7684\u65b0\u63a7\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u6df1\u5ea6\u6444\u50cf\u5934\u68c0\u6d4b\u969c\u788d\u7269\u5e76\u52a8\u6001\u8c03\u6574\u6b65\u6001\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u52a8\u529b\u4e0b\u80a2\u5047\u80a2\u5728\u590d\u6742\u5730\u5f62\u4e2d\u7684\u8868\u73b0\u53d7\u9650\uff0c\u5c24\u5176\u662f\u969c\u788d\u7269\u5bfc\u822a\u65f6\uff0c\u73b0\u6709\u7b56\u7565\u65e0\u6cd5\u5b9e\u65f6\u611f\u77e5\u969c\u788d\u7269\u548c\u7528\u6237\u610f\u56fe\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u673a\u8f7d\u6df1\u5ea6\u6444\u50cf\u5934\u5728\u6446\u52a8\u9636\u6bb5\u524d\u68c0\u6d4b\u969c\u788d\u7269\uff0c\u901a\u8fc7\u63d0\u524d\u8c03\u6574\u6446\u52a8\u8f68\u8ff9\u786e\u4fdd\u8de8\u8fc7\u969c\u788d\u7269\uff0c\u5e76\u5728\u540e\u671f\u6446\u52a8\u9636\u6bb5\u4f9d\u8d56\u7528\u6237\u7684\u751f\u7269\u529b\u5b66\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7cfb\u7edf\u5728\u4e09\u540d\u975e\u622a\u80a2\u8005\u53c2\u4e0e\u7684\u6d4b\u8bd5\u4e2d\uff0c\u6210\u529f\u5904\u7406\u4e86\u8d85\u8fc7150\u6b21\u8de8\u8d8a\u548c30\u6b21\u8e0f\u4e0a\u4e0d\u540c\u9ad8\u5ea6\uff084-16\u5398\u7c73\uff09\u548c\u8ddd\u79bb\uff0815-70\u5398\u7c73\uff09\u7684\u969c\u788d\u7269\uff0c\u6210\u529f\u7387\u8fbe100%\u3002", "conclusion": "\u8be5\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u969c\u788d\u7269\u5bfc\u822a\u8fd9\u4e00\u590d\u6742\u5730\u5f62\u79fb\u52a8\u7684\u5173\u952e\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5176\u9002\u5e94\u73af\u5883\u7ea6\u675f\u548c\u7528\u6237\u610f\u56fe\u7684\u80fd\u529b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.01168", "pdf": "https://arxiv.org/pdf/2507.01168", "abs": "https://arxiv.org/abs/2507.01168", "authors": ["Yeonbin Son", "Matthew L. Bolton"], "title": "Towards a Signal Detection Based Measure for Assessing Information Quality of Explainable Recommender Systems", "categories": ["cs.IR", "cs.HC"], "comment": "Accepted to IEEE CAI 2025", "summary": "There is growing interest in explainable recommender systems that provide\nrecommendations along with explanations for the reasoning behind them. When\nevaluating recommender systems, most studies focus on overall recommendation\nperformance. Only a few assess the quality of the explanations. Explanation\nquality is often evaluated through user studies that subjectively gather users'\nopinions on representative explanatory factors that shape end-users'\nperspective towards the results, not about the explanation contents itself. We\naim to fill this gap by developing an objective metric to evaluate Veracity:\nthe information quality of explanations. Specifically, we decompose Veracity\ninto two dimensions: Fidelity and Attunement. Fidelity refers to whether the\nexplanation includes accurate information about the recommended item.\nAttunement evaluates whether the explanation reflects the target user's\npreferences. By applying signal detection theory, we first determine decision\noutcomes for each dimension and then combine them to calculate a sensitivity,\nwhich serves as the final Veracity value. To assess the effectiveness of the\nproposed metric, we set up four cases with varying levels of information\nquality to validate whether our metric can accurately capture differences in\nquality. The results provided meaningful insights into the effectiveness of our\nproposed metric.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ba2\u89c2\u6307\u6807Veracity\uff0c\u7528\u4e8e\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u4e2d\u89e3\u91ca\u7684\u771f\u5b9e\u6027\uff0c\u5305\u62ecFidelity\u548cAttunement\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u7684\u8bc4\u4f30\u591a\u5173\u6ce8\u63a8\u8350\u6027\u80fd\uff0c\u800c\u89e3\u91ca\u8d28\u91cf\u7684\u8bc4\u4f30\u591a\u4f9d\u8d56\u4e3b\u89c2\u7528\u6237\u7814\u7a76\uff0c\u7f3a\u4e4f\u5ba2\u89c2\u6307\u6807\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5c06Veracity\u5206\u89e3\u4e3aFidelity\uff08\u89e3\u91ca\u4fe1\u606f\u51c6\u786e\u6027\uff09\u548cAttunement\uff08\u89e3\u91ca\u4e0e\u7528\u6237\u504f\u597d\u5339\u914d\u5ea6\uff09\uff0c\u5e76\u5229\u7528\u4fe1\u53f7\u68c0\u6d4b\u7406\u8bba\u8ba1\u7b97\u654f\u611f\u5ea6\u4f5c\u4e3a\u6700\u7ec8\u503c\u3002", "result": "\u901a\u8fc7\u8bbe\u7f6e\u56db\u79cd\u4e0d\u540c\u4fe1\u606f\u8d28\u91cf\u7684\u6848\u4f8b\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6307\u6807\u80fd\u51c6\u786e\u6355\u6349\u89e3\u91ca\u8d28\u91cf\u7684\u5dee\u5f02\u3002", "conclusion": "\u63d0\u51fa\u7684Veracity\u6307\u6807\u80fd\u6709\u6548\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u4e2d\u89e3\u91ca\u7684\u4fe1\u606f\u8d28\u91cf\uff0c\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u65b9\u5411\u3002"}}
{"id": "2507.01196", "pdf": "https://arxiv.org/pdf/2507.01196", "abs": "https://arxiv.org/abs/2507.01196", "authors": ["Na Lee", "Konstantinos Barmpas", "Yannis Panagakis", "Dimitrios Adamos", "Nikolaos Laskaris", "Stefanos Zafeiriou"], "title": "Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": null, "summary": "Foundation Models have demonstrated significant success across various\ndomains in Artificial Intelligence (AI), yet their capabilities for brainwave\nmodeling remain unclear. In this paper, we comprehensively evaluate current\nLarge Brainwave Foundation Models (LBMs) through systematic fine-tuning\nexperiments across multiple Brain-Computer Interface (BCI) benchmark tasks,\nincluding memory tasks and sleep stage classification. Our extensive analysis\nshows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%)\nover traditional deep architectures while requiring significantly more\nparameters (millions vs thousands), raising important questions about their\nefficiency and applicability in BCI contexts. Moreover, through detailed\nablation studies and Low-Rank Adaptation (LoRA), we significantly reduce\ntrainable parameters without performance degradation, while demonstrating that\narchitectural and training inefficiencies limit LBMs' current capabilities. Our\nexperiments span both full model fine-tuning and parameter-efficient adaptation\ntechniques, providing insights into optimal training strategies for BCI\napplications. We pioneer the application of LoRA to LBMs, revealing that\nperformance benefits generally emerge when adapting multiple neural network\ncomponents simultaneously. These findings highlight the critical need for\ndomain-specific development strategies to advance LBMs, suggesting that current\narchitectures may require redesign to fully leverage the potential of\nfoundation models in brainwave analysis.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u8bc4\u4f30\u4e86\u5927\u578b\u8111\u6ce2\u57fa\u7840\u6a21\u578b\uff08LBMs\uff09\u5728\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u76f8\u6bd4\u4f20\u7edf\u6df1\u5ea6\u67b6\u6784\u4ec5\u7565\u5fae\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u53c2\u6570\u91cf\u663e\u8457\u589e\u52a0\uff0c\u5e76\u901a\u8fc7LoRA\u6280\u672f\u663e\u8457\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "motivation": "\u63a2\u7a76\u57fa\u7840\u6a21\u578b\u5728\u8111\u6ce2\u5efa\u6a21\u4e2d\u7684\u6f5c\u529b\uff0c\u8bc4\u4f30\u5176\u5728BCI\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u9002\u7528\u6027\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5fae\u8c03\u5b9e\u9a8c\uff0c\u5305\u62ec\u5b8c\u6574\u6a21\u578b\u5fae\u8c03\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u6280\u672f\uff08\u5982LoRA\uff09\uff0c\u5e76\u8fdb\u884c\u8be6\u7ec6\u7684\u6d88\u878d\u7814\u7a76\u3002", "result": "LBMs\u4ec5\u5e26\u67650.9%-1.2%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u53c2\u6570\u91cf\u8fdc\u9ad8\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff1bLoRA\u80fd\u51cf\u5c11\u53c2\u6570\u800c\u65e0\u6027\u80fd\u635f\u5931\u3002", "conclusion": "LBMs\u9700\u91cd\u65b0\u8bbe\u8ba1\u4ee5\u5145\u5206\u53d1\u6325\u6f5c\u529b\uff0c\u57df\u7279\u5b9a\u5f00\u53d1\u7b56\u7565\u5bf9\u63a8\u8fdb\u8111\u6ce2\u5206\u6790\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.01206", "pdf": "https://arxiv.org/pdf/2507.01206", "abs": "https://arxiv.org/abs/2507.01206", "authors": ["Kathy Zhuang", "Zixun Huang", "Yukun Song", "Rui Li", "Yinuo Zhou", "Allen Y. Yang"], "title": "2024 NASA SUITS Report: LLM-Driven Immersive Augmented Reality User Interface for Robotics and Space Exploration", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "As modern computing advances, new interaction paradigms have emerged,\nparticularly in Augmented Reality (AR), which overlays virtual interfaces onto\nphysical objects. This evolution poses challenges in machine perception,\nespecially for tasks like 3D object pose estimation in complex, dynamic\nenvironments. Our project addresses critical issues in human-robot interaction\nwithin mobile AR, focusing on non-intrusive, spatially aware interfaces. We\npresent URSA, an LLM-driven immersive AR system developed for NASA's 2023-2024\nSUITS challenge, targeting future spaceflight needs such as the Artemis\nmissions. URSA integrates three core technologies: a head-mounted AR device\n(e.g., HoloLens) for intuitive visual feedback, voice control powered by large\nlanguage models for hands-free interaction, and robot tracking algorithms that\nenable accurate 3D localization in dynamic settings. To enhance precision, we\nleverage digital twin localization technologies, using datasets like\nDTTD-Mobile and specialized hardware such as the ZED2 camera for real-world\ntracking under noise and occlusion. Our system enables real-time robot control\nand monitoring via an AR interface, even in the absence of ground-truth\nsensors--vital for hazardous or remote operations. Key contributions include:\n(1) a non-intrusive AR interface with LLM-based voice input; (2) a ZED2-based\ndataset tailored for non-rigid robotic bodies; (3) a Local Mission Control\nConsole (LMCC) for mission visualization; (4) a transformer-based 6DoF pose\nestimator (DTTDNet) optimized for depth fusion and real-time tracking; and (5)\nend-to-end integration for astronaut mission support. This work advances\ndigital twin applications in robotics, offering scalable solutions for both\naerospace and industrial domains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faURSA\u7cfb\u7edf\uff0c\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u76843D\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u548c\u4eba\u7c7b-\u673a\u5668\u4eba\u4ea4\u4e92\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u672a\u6765\u592a\u7a7a\u4efb\u52a1\u5982Artemis\u3002", "motivation": "\u968f\u7740AR\u6280\u672f\u7684\u53d1\u5c55\uff0c\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u673a\u5668\u611f\u77e5\u548c3D\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u9762\u4e34\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u975e\u4fb5\u5165\u5f0f\u3001\u7a7a\u95f4\u611f\u77e5\u7684AR\u7cfb\u7edf\uff0c\u4ee5\u6ee1\u8db3NASA\u672a\u6765\u592a\u7a7a\u4efb\u52a1\u7684\u9700\u6c42\u3002", "method": "URSA\u7cfb\u7edf\u6574\u5408\u4e86\u5934\u6234\u5f0fAR\u8bbe\u5907\uff08\u5982HoloLens\uff09\u3001\u57fa\u4e8eLLM\u7684\u8bed\u97f3\u63a7\u5236\u548c\u673a\u5668\u4eba\u8ddf\u8e2a\u7b97\u6cd5\uff0c\u5e76\u5229\u7528\u6570\u5b57\u5b6a\u751f\u5b9a\u4f4d\u6280\u672f\u548cDTTD-Mobile\u6570\u636e\u96c6\u63d0\u5347\u7cbe\u5ea6\u3002\u7cfb\u7edf\u8fd8\u5305\u62ecDTTDNet\uff08\u57fa\u4e8eTransformer\u76846DoF\u59ff\u6001\u4f30\u8ba1\u5668\uff09\u548cLMCC\uff08\u4efb\u52a1\u53ef\u89c6\u5316\u63a7\u5236\u53f0\uff09\u3002", "result": "URSA\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5b9e\u65f6\u673a\u5668\u4eba\u63a7\u5236\u548c\u76d1\u63a7\uff0c\u9002\u7528\u4e8e\u566a\u58f0\u548c\u906e\u6321\u73af\u5883\uff0c\u4e14\u65e0\u9700\u5730\u9762\u771f\u5b9e\u4f20\u611f\u5668\u3002\u4e3b\u8981\u8d21\u732e\u5305\u62ec\u975e\u4fb5\u5165\u5f0fAR\u63a5\u53e3\u3001ZED2\u6570\u636e\u96c6\u3001LMCC\u3001DTTDNet\u548c\u7aef\u5230\u7aef\u96c6\u6210\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a8\u52a8\u4e86\u6570\u5b57\u5b6a\u751f\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u5e94\u7528\uff0c\u4e3a\u822a\u7a7a\u822a\u5929\u548c\u5de5\u4e1a\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01282", "pdf": "https://arxiv.org/pdf/2507.01282", "abs": "https://arxiv.org/abs/2507.01282", "authors": ["Matthew JY Kang", "Wenli Yang", "Monica R Roberts", "Byeong Ho Kang", "Charles B Malpas"], "title": "Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "The recent boom of large language models (LLMs) has re-ignited the hope that\nartificial intelligence (AI) systems could aid medical diagnosis. Yet despite\ndazzling benchmark scores, LLM assistants have yet to deliver measurable\nimprovements at the bedside. This scoping review aims to highlight the areas\nwhere AI is limited to make practical contributions in the clinical setting,\nspecifically in dementia diagnosis and care.\n  Standalone machine-learning models excel at pattern recognition but seldom\nprovide actionable, interpretable guidance, eroding clinician trust. Adjacent\nuse of LLMs by physicians did not result in better diagnostic accuracy or\nspeed. Key limitations trace to the data-driven paradigm: black-box outputs\nwhich lack transparency, vulnerability to hallucinations, and weak causal\nreasoning. Hybrid approaches that combine statistical learning with expert\nrule-based knowledge, and involve clinicians throughout the process help bring\nback interpretability. They also fit better with existing clinical workflows,\nas seen in examples like PEIRS and ATHENA-CDS.\n  Future decision-support should prioritise explanatory coherence by linking\npredictions to clinically meaningful causes. This can be done through\nneuro-symbolic or hybrid AI that combines the language ability of LLMs with\nhuman causal expertise. AI researchers have addressed this direction, with\nexplainable AI and neuro-symbolic AI being the next logical steps in further\nadvancement in AI. However, they are still based on data-driven knowledge\nintegration instead of human-in-the-loop approaches. Future research should\nmeasure success not only by accuracy but by improvements in clinician\nunderstanding, workflow fit, and patient outcomes. A better understanding of\nwhat helps improve human-computer interactions is greatly needed for AI systems\nto become part of clinical practice.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u4ecd\u9762\u4e34\u8bf8\u591a\u9650\u5236\uff0c\u5c24\u5176\u662f\u5728\u75f4\u5446\u75c7\u8bca\u65ad\u548c\u62a4\u7406\u4e2d\u3002\u6df7\u5408\u65b9\u6cd5\u7ed3\u5408\u7edf\u8ba1\u5b66\u4e60\u548c\u4e13\u5bb6\u77e5\u8bc6\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u5e76\u5951\u5408\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u63a2\u7d22AI\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u5b9e\u9645\u8d21\u732e\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u75f4\u5446\u75c7\u8bca\u65ad\u4e2d\uff0c\u4ee5\u6539\u8fdbAI\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u548c\u53ef\u63a5\u53d7\u6027\u3002", "method": "\u91c7\u7528\u8303\u56f4\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790AI\u5728\u4e34\u5e8a\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u6df7\u5408\u65b9\u6cd5\uff08\u5982PEIRS\u548cATHENA-CDS\uff09\u7684\u6709\u6548\u6027\u3002", "result": "AI\u7684\u5c40\u9650\u6027\u5305\u62ec\u9ed1\u76d2\u8f93\u51fa\u3001\u5e7b\u89c9\u95ee\u9898\u548c\u5f31\u56e0\u679c\u63a8\u7406\u3002\u6df7\u5408\u65b9\u6cd5\u80fd\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u7684\u5951\u5408\u5ea6\u3002", "conclusion": "\u672a\u6765AI\u51b3\u7b56\u652f\u6301\u5e94\u6ce8\u91cd\u89e3\u91ca\u6027\u548c\u4e34\u5e8a\u610f\u4e49\uff0c\u7ed3\u5408\u795e\u7ecf\u7b26\u53f7AI\u548c\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5e76\u4ee5\u6539\u5584\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u548c\u60a3\u8005\u7ed3\u679c\u4e3a\u6210\u529f\u6807\u51c6\u3002"}}
{"id": "2507.01431", "pdf": "https://arxiv.org/pdf/2507.01431", "abs": "https://arxiv.org/abs/2507.01431", "authors": ["Yoonseok Yang", "Minjune Kim", "Marlon Rondinelli", "Keren Shao"], "title": "Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": "7 pages, 5 figues, 1 table", "summary": "Grading handwritten, open-ended responses remains a major bottleneck in large\nuniversity STEM courses. We introduce Pensieve (https://www.pensieve.co), an\nAI-assisted grading platform that leverages large language models (LLMs) to\ntranscribe and evaluate student work, providing instructors with rubric-aligned\nscores, transcriptions, and confidence ratings. Unlike prior tools that focus\nnarrowly on specific tasks like transcription or rubric generation, Pensieve\nsupports the entire grading pipeline-from scanned student submissions to final\nfeedback-within a human-in-the-loop interface.\n  Pensieve has been deployed in real-world courses at over 20 institutions and\nhas graded more than 300,000 student responses. We present system details and\nempirical results across four core STEM disciplines: Computer Science,\nMathematics, Physics, and Chemistry. Our findings show that Pensieve reduces\ngrading time by an average of 65%, while maintaining a 95.4% agreement rate\nwith instructor-assigned grades for high-confidence predictions.", "AI": {"tldr": "Pensieve\u662f\u4e00\u4e2aAI\u8f85\u52a9\u8bc4\u5206\u5e73\u53f0\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u5f55\u548c\u8bc4\u4f30\u5b66\u751f\u4f5c\u4e1a\uff0c\u663e\u8457\u51cf\u5c11\u8bc4\u5206\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8bc4\u5206\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21STEM\u8bfe\u7a0b\u4e2d\u624b\u5199\u5f00\u653e\u5f0f\u4f5c\u4e1a\u8bc4\u5206\u7684\u74f6\u9888\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u4eba\u5728\u73af\u8def\u754c\u9762\uff0c\u5b9e\u73b0\u4ece\u5b66\u751f\u63d0\u4ea4\u5230\u6700\u7ec8\u53cd\u9988\u7684\u5b8c\u6574\u8bc4\u5206\u6d41\u7a0b\u3002", "result": "\u572820\u591a\u4e2a\u673a\u6784\u7684\u5b9e\u9645\u8bfe\u7a0b\u4e2d\u90e8\u7f72\uff0c\u8bc4\u520630\u4e07\u4efd\u4f5c\u4e1a\uff0c\u8bc4\u5206\u65f6\u95f4\u51cf\u5c1165%\uff0c\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u4e0e\u6559\u5e08\u8bc4\u5206\u4e00\u81f4\u7387\u8fbe95.4%\u3002", "conclusion": "Pensieve\u5728\u63d0\u5347\u8bc4\u5206\u6548\u7387\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u8bc4\u5206\u8d28\u91cf\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u5b9e\u9645\u6559\u80b2\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
