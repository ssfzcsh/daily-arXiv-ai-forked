{"id": "2508.15135", "pdf": "https://arxiv.org/pdf/2508.15135", "abs": "https://arxiv.org/abs/2508.15135", "authors": ["Sumudu Liyanage", "Sherlock A. Licorish", "Markus Wagner", "Stephen G. MacDonell"], "title": "On the need to perform comprehensive evaluations of automated program repair benchmarks: Sorald case study", "categories": ["cs.SE"], "comment": null, "summary": "In supporting the development of high-quality software, especially necessary\nin the era of LLMs, automated program repair (APR) tools aim to improve code\nquality by automatically addressing violations detected by static analysis\nprofilers. Previous research tends to evaluate APR tools only for their ability\nto clear violations, neglecting their potential introduction of new (sometimes\nsevere) violations, changes to code functionality and degrading of code\nstructure. There is thus a need for research to develop and assess\ncomprehensive evaluation frameworks for APR tools. This study addresses this\nresearch gap, and evaluates Sorald (a state-of-the-art APR tool) as a proof of\nconcept. Sorald's effectiveness was evaluated in repairing 3,529 SonarQube\nviolations across 30 rules within 2,393 Java code snippets extracted from Stack\nOverflow. Outcomes show that while Sorald fixes specific rule violations, it\nintroduced 2,120 new faults (32 bugs, 2088 code smells), reduced code\nfunctional correctness--as evidenced by a 24% unit test failure rate--and\ndegraded code structure, demonstrating the utility of our framework. Findings\nemphasize the need for evaluation methodologies that capture the full spectrum\nof APR tool effects, including side effects, to ensure their safe and effective\nadoption.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u5de5\u5177\u8bc4\u4f30\u6846\u67b6\uff0c\u91cd\u70b9\u5206\u6790\u4e86Sorald\u5de5\u5177\u7684\u4fee\u590d\u6548\u679c\u53ca\u5176\u53ef\u80fd\u5f15\u5165\u7684\u65b0\u95ee\u9898\u3002", "motivation": "\u5728LLM\u65f6\u4ee3\uff0cAPR\u5de5\u5177\u88ab\u5e7f\u6cdb\u7528\u4e8e\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u5176\u6e05\u9664\u8fdd\u89c4\u7684\u80fd\u529b\uff0c\u5ffd\u7565\u4e86\u5176\u6f5c\u5728\u7684\u526f\u4f5c\u7528\u3002", "method": "\u7814\u7a76\u4f7f\u7528Sorald\u5de5\u5177\u4fee\u590d\u4e86\u6765\u81eaStack Overflow\u76842,393\u4e2aJava\u4ee3\u7801\u7247\u6bb5\u4e2d\u76843,529\u4e2aSonarQube\u8fdd\u89c4\uff0c\u5e76\u8bc4\u4f30\u5176\u4fee\u590d\u6548\u679c\u3002", "result": "Sorald\u867d\u7136\u4fee\u590d\u4e86\u7279\u5b9a\u8fdd\u89c4\uff0c\u4f46\u5f15\u5165\u4e862,120\u4e2a\u65b0\u95ee\u9898\uff0832\u4e2abug\u30012,088\u4e2a\u4ee3\u7801\u5f02\u5473\uff09\uff0c\u529f\u80fd\u6b63\u786e\u6027\u4e0b\u964d24%\uff0c\u4e14\u4ee3\u7801\u7ed3\u6784\u9000\u5316\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u9700\u8981\u5168\u9762\u7684APR\u5de5\u5177\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fdd\u5176\u5b89\u5168\u6709\u6548\u4f7f\u7528\u3002"}}
{"id": "2508.15411", "pdf": "https://arxiv.org/pdf/2508.15411", "abs": "https://arxiv.org/abs/2508.15411", "authors": ["Frederik Vandeputte"], "title": "Foundational Design Principles and Patterns for Building Robust and Adaptive GenAI-Native Systems", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.MA"], "comment": null, "summary": "Generative AI (GenAI) has emerged as a transformative technology,\ndemonstrating remarkable capabilities across diverse application domains.\nHowever, GenAI faces several major challenges in developing reliable and\nefficient GenAI-empowered systems due to its unpredictability and inefficiency.\nThis paper advocates for a paradigm shift: future GenAI-native systems should\nintegrate GenAI's cognitive capabilities with traditional software engineering\nprinciples to create robust, adaptive, and efficient systems.\n  We introduce foundational GenAI-native design principles centered around five\nkey pillars -- reliability, excellence, evolvability, self-reliance, and\nassurance -- and propose architectural patterns such as GenAI-native cells,\norganic substrates, and programmable routers to guide the creation of resilient\nand self-evolving systems. Additionally, we outline the key ingredients of a\nGenAI-native software stack and discuss the impact of these systems from\ntechnical, user adoption, economic, and legal perspectives, underscoring the\nneed for further validation and experimentation. Our work aims to inspire\nfuture research and encourage relevant communities to implement and refine this\nconceptual framework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u751f\u6210\u5f0fAI\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u7ed3\u5408\uff0c\u6784\u5efa\u53ef\u9760\u3001\u81ea\u9002\u5e94\u3001\u9ad8\u6548\u7684GenAI\u539f\u751f\u7cfb\u7edf\uff0c\u5e76\u8bbe\u8ba1\u4e94\u5927\u539f\u5219\u53ca\u67b6\u6784\u6a21\u5f0f\u3002", "motivation": "\u751f\u6210\u5f0fAI\u867d\u5f3a\u5927\uff0c\u4f46\u5176\u4e0d\u53ef\u9884\u6d4b\u6027\u548c\u4f4e\u6548\u6027\u9650\u5236\u4e86\u53ef\u9760\u6027\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u9700\u7ed3\u5408\u4f20\u7edf\u5de5\u7a0b\u539f\u5219\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e94\u5927\u8bbe\u8ba1\u539f\u5219\uff08\u53ef\u9760\u6027\u3001\u5353\u8d8a\u6027\u3001\u53ef\u8fdb\u5316\u6027\u3001\u81ea\u4f9d\u8d56\u6027\u3001\u4fdd\u969c\u6027\uff09\u53ca\u67b6\u6784\u6a21\u5f0f\uff08\u5982GenAI\u539f\u751f\u5355\u5143\uff09\u3002", "result": "\u6784\u5efa\u4e86GenAI\u539f\u751f\u8f6f\u4ef6\u6808\u6846\u67b6\uff0c\u5e76\u4ece\u6280\u672f\u3001\u7528\u6237\u3001\u7ecf\u6d4e\u3001\u6cd5\u5f8b\u591a\u89d2\u5ea6\u5206\u6790\u5176\u5f71\u54cd\u3002", "conclusion": "\u547c\u5401\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e0e\u5b9e\u8df5\uff0c\u63a8\u52a8GenAI\u539f\u751f\u7cfb\u7edf\u7684\u7814\u7a76\u4e0e\u5b9e\u73b0\u3002"}}
{"id": "2508.15423", "pdf": "https://arxiv.org/pdf/2508.15423", "abs": "https://arxiv.org/abs/2508.15423", "authors": ["Ruiqi Wang", "Zezhou Yang", "Cuiyun Gao", "Xin Xia", "Qing Liao"], "title": "An Empirical Study of Knowledge Distillation for Code Understanding Tasks", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by ICSE 2026 (Cycle 1)", "summary": "Pre-trained language models (PLMs) have emerged as powerful tools for code\nunderstanding. However, deploying these PLMs in large-scale applications faces\npractical challenges due to their computational intensity and inference\nlatency. Knowledge distillation (KD), a promising model compression and\nacceleration technique, addresses these limitations by transferring knowledge\nfrom large teacher models to compact student models, enabling efficient\ninference while preserving most of the teacher models' capabilities. While this\ntechnique has shown remarkable success in natural language processing and\ncomputer vision domains, its potential for code understanding tasks remains\nlargely underexplored.\n  In this paper, we systematically investigate the effectiveness and usage of\nKD in code understanding tasks. Our study encompasses two popular types of KD\nmethods, i.e., logit-based and feature-based KD methods, experimenting across\neight student models and two teacher PLMs from different domains on three\ndownstream tasks. The experimental results indicate that KD consistently offers\nnotable performance boosts across student models with different sizes compared\nwith standard fine-tuning. Notably, code-specific PLM demonstrates better\neffectiveness as the teacher model. Among all KD methods, the latest\nfeature-based KD methods exhibit superior performance, enabling student models\nto retain up to 98% teacher performance with merely 5% parameters. Regarding\nstudent architecture, our experiments reveal that similarity with teacher\narchitecture does not necessarily lead to better performance. We further\ndiscuss the efficiency and behaviors in the KD process and inference, summarize\nthe implications of findings, and identify promising future directions.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u548c\u5e94\u7528\uff0c\u53d1\u73b0\u7279\u5f81\u57faKD\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u5b66\u751f\u6a21\u578b\u53c2\u6570\u4ec5\u4e3a5%\u65f6\u53ef\u4fdd\u7559\u6559\u5e08\u6a21\u578b98%\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLMs\uff09\u5728\u4ee3\u7801\u7406\u89e3\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8ba1\u7b97\u5bc6\u96c6\u6027\u548c\u63a8\u7406\u5ef6\u8fdf\u9650\u5236\u4e86\u5927\u89c4\u6a21\u5e94\u7528\u90e8\u7f72\u3002\u77e5\u8bc6\u84b8\u998f\u4f5c\u4e3a\u4e00\u79cd\u6a21\u578b\u538b\u7f29\u548c\u52a0\u901f\u6280\u672f\uff0c\u6709\u671b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5176\u5728\u4ee3\u7801\u7406\u89e3\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e24\u79cdKD\u65b9\u6cd5\uff08\u57fa\u4e8elogit\u548c\u7279\u5f81\uff09\uff0c\u5728\u516b\u4e2a\u5b66\u751f\u6a21\u578b\u548c\u4e24\u4e2a\u6559\u5e08PLM\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8986\u76d6\u4e09\u4e2a\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "KD\u80fd\u663e\u8457\u63d0\u5347\u4e0d\u540c\u89c4\u6a21\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7279\u5f81\u57faKD\u65b9\u6cd5\u5c24\u5176\u7a81\u51fa\uff1b\u4ee3\u7801\u4e13\u7528PLM\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\u6548\u679c\u66f4\u4f73\uff1b\u5b66\u751f\u6a21\u578b\u4e0e\u6559\u5e08\u6a21\u578b\u67b6\u6784\u76f8\u4f3c\u6027\u5e76\u975e\u6027\u80fd\u51b3\u5b9a\u56e0\u7d20\u3002", "conclusion": "KD\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u7279\u5f81\u57fa\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6548\u7387\u548c\u884c\u4e3a\u7684\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2508.15495", "pdf": "https://arxiv.org/pdf/2508.15495", "abs": "https://arxiv.org/abs/2508.15495", "authors": ["Dongjun Yu", "Xiao Yan", "Zhenrui Li", "Jipeng Xiao", "Haochuan He", "Yongda Yu", "Hao Zhang", "Guoping Rong", "Xiaobo Huang"], "title": "SynthCoder: A Synthetical Strategy to Tune LLMs for Code Completion", "categories": ["cs.SE"], "comment": null, "summary": "Code completion is a prominent application of Large Language Models (LLMs) in\nsoftware engineering. Due to the near real-time response requirements of this\ntask, base models with small to medium-sized parameters are typically employed,\nsupplemented by various optimization and post-training techniques. However,\nthese optimization methods often have trade-offs, leading to a seesaw effect\nwhere performance improvements on certain datasets or metrics are accompanied\nby degradations on others -- sometimes even falling below the baseline model's\nperformance. This paper proposes SynthCoder, a model that integrates leading\nindustry practices to achieve state-of-the-art performance on the\nFill-in-the-Middle (FIM) code completion task. In specific, we first construct\na diverse dataset by combining Abstract Syntax Tree (AST) node extraction with\nheuristics that simulate developer behavior. Then we enrich our training corpus\nwith cross-file contextual information using the BM25 algorithm and call\ngraphs, enhancing the model's ability to perform code completion in both\nfile-level and repository-level scenarios. As the last step, we employ a\ntwo-stage training process using the Seed-Coder-8B-Base as the base model.\nFirst, we fine-tune the model using Curriculum Learning technology. Following\nthis, we perform alignment using Direct Preference Optimization (DPO) with\npreference pairs generated through Rejection Sampling. Experimental results\ndemonstrate that our final model excels on mainstream repository-level code\ncompletion benchmarks, including aiXcoder, ExecRepoBench, CrossCodeEval, and\nCoLT. Furthermore, our carefully curated training set effectively mitigates the\nmodel's tendency to just repeat existing code, a common issue existing in\nvarious code completion models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSynthCoder\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408AST\u8282\u70b9\u63d0\u53d6\u3001BM25\u7b97\u6cd5\u548c\u8c03\u7528\u56fe\u7b49\u6280\u672f\uff0c\u4f18\u5316\u4e86\u4ee3\u7801\u586b\u5145\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u6210\u7ee9\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7801\u8865\u5168\u6a21\u578b\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5e38\u51fa\u73b0\u6027\u80fd\u6ce2\u52a8\uff0c\u67d0\u4e9b\u6570\u636e\u96c6\u6216\u6307\u6807\u7684\u63d0\u5347\u4ee5\u5176\u4ed6\u65b9\u9762\u7684\u4e0b\u964d\u4e3a\u4ee3\u4ef7\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7efc\u5408\u884c\u4e1a\u6700\u4f73\u5b9e\u8df5\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u6027\u80fd\u7a33\u5b9a\u7684\u6a21\u578b\u3002", "method": "\u6784\u5efa\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\uff0c\u7ed3\u5408AST\u8282\u70b9\u63d0\u53d6\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u6a21\u62df\u5f00\u53d1\u8005\u884c\u4e3a\uff1b\u5229\u7528BM25\u7b97\u6cd5\u548c\u8c03\u7528\u56fe\u589e\u5f3a\u8de8\u6587\u4ef6\u4e0a\u4e0b\u6587\u4fe1\u606f\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08\u8bfe\u7a0b\u5b66\u4e60\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff09\u3002", "result": "SynthCoder\u5728aiXcoder\u3001ExecRepoBench\u7b49\u4e3b\u6d41\u4ee3\u7801\u8865\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u6709\u6548\u7f13\u89e3\u4e86\u6a21\u578b\u91cd\u590d\u73b0\u6709\u4ee3\u7801\u7684\u95ee\u9898\u3002", "conclusion": "SynthCoder\u901a\u8fc7\u7efc\u5408\u4f18\u5316\u6280\u672f\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\uff0c\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5e38\u89c1\u95ee\u9898\u3002"}}
{"id": "2508.14930", "pdf": "https://arxiv.org/pdf/2508.14930", "abs": "https://arxiv.org/abs/2508.14930", "authors": ["Hanwen Zhao", "John Akers", "Baback Elmieh", "Ira Kemelmacher-Shlizerman"], "title": "Hybrelighter: Combining Deep Anisotropic Diffusion and Scene Reconstruction for On-device Real-time Relighting in Mixed Reality", "categories": ["cs.GR"], "comment": null, "summary": "Mixed Reality scene relighting, where virtual changes to lighting conditions\nrealistically interact with physical objects, producing authentic illumination\nand shadows, can be used in a variety of applications. One such application in\nreal estate could be visualizing a room at different times of day and placing\nvirtual light fixtures. Existing deep learning-based relighting techniques\ntypically exceed the real-time performance capabilities of current MR devices.\nOn the other hand, scene understanding methods, such as on-device scene\nreconstruction, often yield inaccurate results due to scanning limitations, in\nturn affecting relighting quality. Finally, simpler 2D image filter-based\napproaches cannot represent complex geometry and shadows. We introduce a novel\nmethod to integrate image segmentation, with lighting propagation via\nanisotropic diffusion on top of basic scene understanding, and the\ncomputational simplicity of filter-based techniques. Our approach corrects\non-device scanning inaccuracies, delivering visually appealing and accurate\nrelighting effects in real-time on edge devices, achieving speeds as high as\n100 fps. We show a direct comparison between our method and the industry\nstandard, and present a practical demonstration of our method in the\naforementioned real estate example.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u73b0\u5b9e\u573a\u666f\u91cd\u65b0\u7167\u660e\u65b9\u6cd5\uff0c\u7ed3\u5408\u56fe\u50cf\u5206\u5272\u3001\u5404\u5411\u5f02\u6027\u6269\u6563\u548c\u8ba1\u7b97\u7b80\u5355\u7684\u6ee4\u6ce2\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5b9e\u65f6\u8fd0\u884c\uff0c\u573a\u666f\u91cd\u5efa\u65b9\u6cd5\u56e0\u626b\u63cf\u9650\u5236\u5bfc\u81f4\u7ed3\u679c\u4e0d\u51c6\u786e\uff0c2D\u56fe\u50cf\u6ee4\u6ce2\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u590d\u6742\u51e0\u4f55\u548c\u9634\u5f71\u3002", "method": "\u96c6\u6210\u56fe\u50cf\u5206\u5272\u3001\u57fa\u4e8e\u5404\u5411\u5f02\u6027\u6269\u6563\u7684\u5149\u7167\u4f20\u64ad\u548c\u57fa\u7840\u573a\u666f\u7406\u89e3\uff0c\u7ed3\u5408\u6ee4\u6ce2\u6280\u672f\u7684\u8ba1\u7b97\u7b80\u5355\u6027\u3002", "result": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0100 fps\u7684\u5b9e\u65f6\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6821\u6b63\u626b\u63cf\u8bef\u5dee\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u91cd\u7167\u660e\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u884c\u4e1a\u6807\u51c6\uff0c\u9002\u7528\u4e8e\u5982\u623f\u5730\u4ea7\u53ef\u89c6\u5316\u7b49\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.15357", "pdf": "https://arxiv.org/pdf/2508.15357", "abs": "https://arxiv.org/abs/2508.15357", "authors": ["Haji Gul", "Abul Ghani Naim", "Ajaz Ahmad Bhat"], "title": "KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph Completion Models", "categories": ["cs.CL", "cs.PF"], "comment": null, "summary": "Knowledge Graphs (KGs) enable applications in various domains such as\nsemantic search, recommendation systems, and natural language processing. KGs\nare often incomplete, missing entities and relations, an issue addressed by\nKnowledge Graph Completion (KGC) methods that predict missing elements.\nDifferent evaluation metrics, such as Mean Reciprocal Rank (MRR), Mean Rank\n(MR), and Hit@k, are commonly used to assess the performance of such KGC\nmodels. A major challenge in evaluating KGC models, however, lies in comparing\ntheir performance across multiple datasets and metrics. A model may outperform\nothers on one dataset but underperform on another, making it difficult to\ndetermine overall superiority. Moreover, even within a single dataset,\ndifferent metrics such as MRR and Hit@1 can yield conflicting rankings, where\none model excels in MRR while another performs better in Hit@1, further\ncomplicating model selection for downstream tasks. These inconsistencies hinder\nholistic comparisons and highlight the need for a unified meta-metric that\nintegrates performance across all metrics and datasets to enable a more\nreliable and interpretable evaluation framework. To address this need, we\npropose KG Evaluation based on Distance from Average Solution (EDAS), a robust\nand interpretable meta-metric that synthesizes model performance across\nmultiple datasets and diverse evaluation criteria into a single normalized\nscore ($M_i \\in [0,1]$). Unlike traditional metrics that focus on isolated\naspects of performance, EDAS offers a global perspective that supports more\ninformed model selection and promotes fairness in cross-dataset evaluation.\nExperimental results on benchmark datasets such as FB15k-237 and WN18RR\ndemonstrate that EDAS effectively integrates multi-metric, multi-dataset\nperformance into a unified ranking, offering a consistent, robust, and\ngeneralizable framework for evaluating KGC models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5143\u5ea6\u91cfEDAS\uff0c\u7528\u4e8e\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff08KGC\uff09\u6a21\u578b\u4e2d\u591a\u6570\u636e\u96c6\u548c\u591a\u8bc4\u4ef7\u6307\u6807\u4e0b\u7684\u8bc4\u4f30\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684KGC\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u6307\u6807\u4e0b\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u5bfc\u81f4\u6a21\u578b\u9009\u62e9\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8ddd\u79bb\u5e73\u5747\u89e3\u7684\u8bc4\u4f30\u65b9\u6cd5\uff08EDAS\uff09\uff0c\u5c06\u591a\u6570\u636e\u96c6\u548c\u591a\u6307\u6807\u7684\u6027\u80fd\u7efc\u5408\u4e3a\u4e00\u4e2a\u6807\u51c6\u5316\u5206\u6570\u3002", "result": "\u5728FB15k-237\u548cWN18RR\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cEDAS\u6210\u529f\u6574\u5408\u4e86\u591a\u6307\u6807\u3001\u591a\u6570\u636e\u96c6\u7684\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6392\u540d\u3002", "conclusion": "EDAS\u63d0\u4f9b\u4e86\u4e00\u79cd\u5168\u5c40\u3001\u4e00\u81f4\u4e14\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u66f4\u516c\u5e73\u548c\u53ef\u9760\u5730\u6bd4\u8f83KGC\u6a21\u578b\u3002"}}
{"id": "2508.15109", "pdf": "https://arxiv.org/pdf/2508.15109", "abs": "https://arxiv.org/abs/2508.15109", "authors": ["Ziteng Wang", "Ruijie Fang", "Linus Zheng", "Dixin Tang", "Isil Dillig"], "title": "Homomorphism Calculus for User-Defined Aggregations", "categories": ["cs.PL", "D.3.0; F.3.1"], "comment": null, "summary": "Data processing frameworks like Apache Spark and Flink provide built-in\nsupport for user-defined aggregation functions (UDAFs), enabling the\nintegration of domain-specific logic. However, for these frameworks to support\n\\emph{efficient} UDAF execution, the function needs to satisfy a\n\\emph{homomorphism property}, which ensures that partial results from\nindependent computations can be merged correctly. Motivated by this problem,\nthis paper introduces a novel \\emph{homomorphism calculus} that can both verify\nand refute whether a UDAF is a dataframe homomorphism. If so, our calculus also\nenables the construction of a corresponding merge operator which can be used\nfor incremental computation and parallel execution. We have implemented an\nalgorithm based on our proposed calculus and evaluate it on real-world UDAFs,\ndemonstrating that our approach significantly outperforms two leading\nsynthesizers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u540c\u6001\u6f14\u7b97\uff0c\u7528\u4e8e\u9a8c\u8bc1\u548c\u5426\u5b9aUDAF\u662f\u5426\u4e3a\u540c\u6001\uff0c\u5e76\u6784\u5efa\u76f8\u5e94\u7684\u5408\u5e76\u7b97\u5b50\u4ee5\u652f\u6301\u9ad8\u6548\u8ba1\u7b97\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u5408\u6210\u5668\u3002", "motivation": "\u4e3a\u652f\u6301\u9ad8\u6548\u7684UDAF\u6267\u884c\uff0c\u9700\u8981\u6ee1\u8db3\u540c\u6001\u6027\u8d28\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u81ea\u52a8\u5316\u9a8c\u8bc1\u548c\u6784\u5efa\u5408\u5e76\u7b97\u5b50\u7684\u5de5\u5177\u3002", "method": "\u5f15\u5165\u540c\u6001\u6f14\u7b97\uff0c\u9a8c\u8bc1UDAF\u7684\u540c\u6001\u6027\u5e76\u6784\u5efa\u5408\u5e76\u7b97\u5b50\u3002", "result": "\u5b9e\u73b0\u7b97\u6cd5\u5e76\u5728\u771f\u5b9eUDAF\u4e0a\u9a8c\u8bc1\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u5408\u6210\u5668\u3002", "conclusion": "\u8be5\u6f14\u7b97\u65b9\u6cd5\u80fd\u6709\u6548\u652f\u6301UDAF\u7684\u9ad8\u6548\u6267\u884c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.15220", "pdf": "https://arxiv.org/pdf/2508.15220", "abs": "https://arxiv.org/abs/2508.15220", "authors": ["Aniruddha Joshi", "Supratik Chakraborty", "S Akshay", "Shetal Shah", "Hazem Torfah", "Sanjit Seshia"], "title": "Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "This work has been accepted at ATVA'25", "summary": "Creating meaningful interpretations for black-box machine learning models\ninvolves balancing two often conflicting objectives: accuracy and\nexplainability. Exploring the trade-off between these objectives is essential\nfor developing trustworthy interpretations. While many techniques for\nmulti-objective interpretation synthesis have been developed, they typically\nlack formal guarantees on the Pareto-optimality of the results. Methods that do\nprovide such guarantees, on the other hand, often face severe scalability\nlimitations when exploring the Pareto-optimal space. To address this, we\ndevelop a framework based on local optimality guarantees that enables more\nscalable synthesis of interpretations. Specifically, we consider the problem of\nsynthesizing a set of Pareto-optimal interpretations with local optimality\nguarantees, within the immediate neighborhood of each solution. Our approach\nbegins with a multi-objective learning or search technique, such as\nMulti-Objective Monte Carlo Tree Search, to generate a best-effort set of\nPareto-optimal candidates with respect to accuracy and explainability. We then\nverify local optimality for each candidate as a Boolean satisfiability problem,\nwhich we solve using a SAT solver. We demonstrate the efficacy of our approach\non a set of benchmarks, comparing it against previous methods for exploring the\nPareto-optimal front of interpretations. In particular, we show that our\napproach yields interpretations that closely match those synthesized by methods\noffering global guarantees.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u6700\u4f18\u6027\u4fdd\u8bc1\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5e73\u8861\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728Pareto\u6700\u4f18\u7a7a\u95f4\u63a2\u7d22\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u5728\u89e3\u91ca\u9ed1\u76d2\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\uff0c\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5e38\u5b58\u5728\u51b2\u7a81\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9Pareto\u6700\u4f18\u6027\u7684\u6b63\u5f0f\u4fdd\u8bc1\u6216\u9762\u4e34\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002", "method": "\u7ed3\u5408\u591a\u76ee\u6807\u5b66\u4e60\u6216\u641c\u7d22\u6280\u672f\uff08\u5982\u591a\u76ee\u6807\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff09\u751f\u6210\u5019\u9009\u89e3\uff0c\u5e76\u901a\u8fc7SAT\u6c42\u89e3\u5668\u9a8c\u8bc1\u5176\u5c40\u90e8\u6700\u4f18\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u89e3\u91ca\u4e0e\u63d0\u4f9b\u5168\u5c40\u4fdd\u8bc1\u7684\u65b9\u6cd5\u7ed3\u679c\u76f8\u8fd1\uff0c\u540c\u65f6\u66f4\u5177\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u6548\u5408\u6210Pareto\u6700\u4f18\u89e3\u91ca\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u517c\u5177\u5c40\u90e8\u6700\u4f18\u6027\u4fdd\u8bc1\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.14941", "pdf": "https://arxiv.org/pdf/2508.14941", "abs": "https://arxiv.org/abs/2508.14941", "authors": ["Yi-Chun Chen"], "title": "Robust Symbolic Reasoning for Visual Narratives via Hierarchical and Semantically Normalized Knowledge Graphs", "categories": ["cs.MM", "cs.CL"], "comment": "12 pages, 4 figures, 2 tables. Extends our earlier framework on\n  hierarchical narrative graphs with a semantic normalization module", "summary": "Understanding visual narratives such as comics requires structured\nrepresentations that capture events, characters, and their relations across\nmultiple levels of story organization. However, symbolic narrative graphs often\nsuffer from inconsistency and redundancy, where similar actions or events are\nlabeled differently across annotations or contexts. Such variance limits the\neffectiveness of reasoning and generalization.\n  This paper introduces a semantic normalization framework for hierarchical\nnarrative knowledge graphs. Building on cognitively grounded models of\nnarrative comprehension, we propose methods that consolidate semantically\nrelated actions and events using lexical similarity and embedding-based\nclustering. The normalization process reduces annotation noise, aligns symbolic\ncategories across narrative levels, and preserves interpretability.\n  We demonstrate the framework on annotated manga stories from the Manga109\ndataset, applying normalization to panel-, event-, and story-level graphs.\nPreliminary evaluations across narrative reasoning tasks, such as action\nretrieval, character grounding, and event summarization, show that semantic\nnormalization improves coherence and robustness, while maintaining symbolic\ntransparency. These findings suggest that normalization is a key step toward\nscalable, cognitively inspired graph models for multimodal narrative\nunderstanding.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u89c4\u8303\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u51cf\u5c11\u53d9\u4e8b\u77e5\u8bc6\u56fe\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u5197\u4f59\uff0c\u901a\u8fc7\u8bcd\u6c47\u76f8\u4f3c\u6027\u548c\u5d4c\u5165\u805a\u7c7b\u65b9\u6cd5\u6539\u5584\u591a\u6a21\u6001\u53d9\u4e8b\u7406\u89e3\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u7b26\u53f7\u5316\u7684\u53d9\u4e8b\u56fe\u5728\u5904\u7406\u89c6\u89c9\u53d9\u4e8b\uff08\u5982\u6f2b\u753b\uff09\u65f6\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u548c\u5197\u4f59\u95ee\u9898\uff0c\u9650\u5236\u4e86\u63a8\u7406\u548c\u6cdb\u5316\u7684\u6548\u679c\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u89c4\u8303\u5316\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u8ba4\u77e5\u6a21\u578b\u7684\u53d9\u4e8b\u7406\u89e3\u65b9\u6cd5\uff0c\u91c7\u7528\u8bcd\u6c47\u76f8\u4f3c\u6027\u548c\u5d4c\u5165\u805a\u7c7b\u6280\u672f\uff0c\u5bf9\u5c42\u6b21\u5316\u7684\u53d9\u4e8b\u77e5\u8bc6\u56fe\u8fdb\u884c\u8bed\u4e49\u89c4\u8303\u5316\uff0c\u51cf\u5c11\u6ce8\u91ca\u566a\u97f3\u5e76\u4fdd\u6301\u7b26\u53f7\u900f\u660e\u6027\u3002", "result": "\u5728Manga109\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u8bc4\u4f30\u8868\u660e\uff0c\u8bed\u4e49\u89c4\u8303\u5316\u63d0\u9ad8\u4e86\u53d9\u4e8b\u63a8\u7406\u4efb\u52a1\uff08\u5982\u52a8\u4f5c\u68c0\u7d22\u3001\u89d2\u8272\u5b9a\u4f4d\u548c\u4e8b\u4ef6\u6458\u8981\uff09\u7684\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8bed\u4e49\u89c4\u8303\u5316\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u8ba4\u77e5\u542f\u53d1\u7684\u591a\u6a21\u6001\u53d9\u4e8b\u7406\u89e3\u6a21\u578b\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2508.15058", "pdf": "https://arxiv.org/pdf/2508.15058", "abs": "https://arxiv.org/abs/2508.15058", "authors": ["Kaiqiang Lin", "Mohamed-Slim Alouini"], "title": "Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer", "categories": ["cs.NI", "eess.SP"], "comment": "8 pages, 4 figures, 2 tables, submitted to IEEE WCM", "summary": "Wireless underground sensor networks (WUSNs), which enable real-time sensing\nand monitoring of underground resources by underground devices (UDs), hold\ngreat promise for delivering substantial social and economic benefits across\nvarious verticals. However, due to the harsh subterranean environment, scarce\nnetwork resources, and restricted communication coverage, WUSNs face\nsignificant challenges in supporting sustainable massive machine-type\ncommunications (mMTC), particularly in remote, disaster-stricken, and\nhard-to-reach areas. To complement this, we conceptualize in this study a novel\nspace-air-ground-underground integrated network (SAGUIN) architecture that\nseamlessly incorporates satellite systems, aerial platforms, terrestrial\nnetworks, and underground communications. On this basis, we integrate LoRaWAN\nand wireless energy transfer (WET) technologies into SAGUIN to enable\nsustainable subterranean mMTC. We begin by reviewing the relevant technical\nbackground and presenting the architecture and implementation challenges of\nSAGUIN. Then, we employ simulations to model a remote underground pipeline\nmonitoring scenario to evaluate the feasibility and performance of SAGUIN based\non LoRaWAN and WET technologies, focusing on the effects of parameters such as\nunderground conditions, time allocation, LoRaWAN spread factor (SF)\nconfigurations, reporting periods, and harvested energy levels. Our results\nevidence that the proposed SAGUIN system, when combined with the derived time\nallocation strategy and an appropriate SF, can effectively extend the\noperational lifetime of UDs, thereby facilitating sustainable subterranean\nmMTC. Finally, we pinpoint key challenges and future research directions for\nSAGUIN.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u578b\u7a7a\u95f4-\u7a7a\u4e2d-\u5730\u9762-\u5730\u4e0b\u96c6\u6210\u7f51\u7edc\uff08SAGUIN\uff09\uff0c\u7ed3\u5408LoRaWAN\u548c\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6280\u672f\uff0c\u652f\u6301\u5730\u4e0b\u5927\u89c4\u6a21\u673a\u5668\u901a\u4fe1\uff08mMTC\uff09\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u5730\u4e0b\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\uff08WUSNs\uff09\u5728\u6076\u52a3\u73af\u5883\u4e0b\u652f\u6301mMTC\u9762\u4e34\u6311\u6218\uff0cSAGUIN\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u901a\u4fe1\u65b9\u5f0f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408LoRaWAN\u548c\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6280\u672f\uff0c\u6784\u5efaSAGUIN\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u6a21\u62df\u8fdc\u7a0b\u5730\u4e0b\u7ba1\u9053\u76d1\u63a7\u573a\u666f\u8bc4\u4f30\u6027\u80fd\u3002", "result": "SAGUIN\u7ed3\u5408\u9002\u5f53\u7684\u65f6\u95f4\u5206\u914d\u7b56\u7565\u548cLoRaWAN\u53c2\u6570\u914d\u7f6e\uff0c\u53ef\u6709\u6548\u5ef6\u957f\u8bbe\u5907\u5bff\u547d\uff0c\u652f\u6301\u53ef\u6301\u7eedmMTC\u3002", "conclusion": "SAGUIN\u4e3a\u5730\u4e0bmMTC\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2508.15043", "pdf": "https://arxiv.org/pdf/2508.15043", "abs": "https://arxiv.org/abs/2508.15043", "authors": ["Haoyang Yang", "Elliott H. Faa", "Weijian Liu", "Shunan Guo", "Duen Horng Chau", "Yalong Yang"], "title": "LitForager: Exploring Multimodal Literature Foraging Strategies in Immersive Sensemaking", "categories": ["cs.HC"], "comment": "11 pages, 10 figures, Accepted to IEEE ISMAR 2025 (TVCG)", "summary": "Exploring and comprehending relevant academic literature is a vital yet\nchallenging task for researchers, especially given the rapid expansion in\nresearch publications. This task fundamentally involves sensemaking -\ninterpreting complex, scattered information sources to build understanding.\nWhile emerging immersive analytics tools have shown cognitive benefits like\nenhanced spatial memory and reduced mental load, they predominantly focus on\ninformation synthesis (e.g., organizing known documents). In contrast, the\nequally important information foraging phase - discovering and gathering\nrelevant literature - remains underexplored within immersive environments,\nhindering a complete sensemaking workflow. To bridge this gap, we introduce\nLitForager, an interactive literature exploration tool designed to facilitate\ninformation foraging of research literature within an immersive sensemaking\nworkflow using network-based visualizations and multimodal interactions.\nDeveloped with WebXR and informed by a formative study with researchers,\nLitForager supports exploration guidance, spatial organization, and seamless\ntransition through a 3D literature network. An observational user study with 15\nresearchers demonstrated LitForager's effectiveness in supporting fluid\nforaging strategies and spatial sensemaking through its multimodal interface.", "AI": {"tldr": "LitForager\u662f\u4e00\u6b3e\u9762\u5411\u6c89\u6d78\u5f0f\u6587\u732e\u63a2\u7d22\u7684\u5de5\u5177\uff0c\u65e8\u5728\u901a\u8fc73D\u7f51\u7edc\u53ef\u89c6\u5316\u5e2e\u52a9\u7814\u7a76\u8005\u9ad8\u6548\u53d1\u73b0\u548c\u7ec4\u7ec7\u6587\u732e\u3002", "motivation": "\u7814\u7a76\u8005\u9762\u4e34\u6587\u732e\u5feb\u901f\u589e\u957f\u7684\u6311\u6218\uff0c\u73b0\u6709\u5de5\u5177\u591a\u5173\u6ce8\u4fe1\u606f\u6574\u5408\u800c\u975e\u6587\u732e\u53d1\u73b0\uff0c\u9650\u5236\u4e86\u5b8c\u6574\u7684\u7406\u89e3\u6d41\u7a0b\u3002", "method": "\u5f00\u53d1LitForager\u5de5\u5177\uff0c\u57fa\u4e8eWebXR\u6280\u672f\uff0c\u901a\u8fc73D\u7f51\u7edc\u548c\u591a\u6a21\u5f0f\u4ea4\u4e92\u652f\u6301\u6587\u732e\u63a2\u7d22\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cLitForager\u80fd\u6709\u6548\u652f\u6301\u7075\u6d3b\u7684\u6587\u732e\u53d1\u73b0\u7b56\u7565\u548c\u7a7a\u95f4\u7406\u89e3\u3002", "conclusion": "LitForager\u586b\u8865\u4e86\u6c89\u6d78\u5f0f\u73af\u5883\u4e2d\u6587\u732e\u53d1\u73b0\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u63d0\u5347\u4e86\u7814\u7a76\u8005\u7684\u6587\u732e\u63a2\u7d22\u6548\u7387\u3002"}}
{"id": "2508.15391", "pdf": "https://arxiv.org/pdf/2508.15391", "abs": "https://arxiv.org/abs/2508.15391", "authors": ["Benjamin Kraner", "Luca Pennella", "Nicol\u00f2 Vallarano", "Claudio J. Tessone"], "title": "Money in Motion: Micro-Velocity and Usage of Ethereums Liquid Staking Tokens", "categories": ["cs.ET"], "comment": null, "summary": "We introduce a micro-velocity framework for analysing the on-chain\ncirculation of Lidos liquid-staking tokens, stETH, and its wrapped ERC-20 form,\nwstETH. By reconstructing full transfer and share-based accounting histories,\nwe compute address-level velocities and decompose them into behavioural\ncomponents. Despite their growing importance, the micro-level monetary dynamics\nof LSTs remain largely unexplored. Our data reveal persistently high velocity\nfor both tokens, reflecting intensive reuse within DeFi. Yet activity is highly\nconcentrated: a small cohort of large addresses, likely institutional accounts,\nare responsible for most turnover, while the rest of the users remain largely\npassive. We also observe a gradual transition in user behavior, characterized\nby a shift toward wstETH, the non-rebasing variant of stETH. This shift appears\nto align with DeFi composability trends, as wstETH is more frequently deployed\nacross protocols such as AAVE, Spark, Balancer, and SkyMoney.\n  To make the study fully reproducible, we release (i) an open-source pipeline\nthat indexes event logs and historical contract state, and (ii) two public\ndatasets containing every Transfer and TransferShares record for stETH and\nwstETH through 2024-11-08. This is the first large-scale empirical\ncharacterisation of liquid-staking token circulation. Our approach offers a\nscalable template for monitoring staking asset flows and provides new,\nopen-access resources to the research community.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5fae\u901f\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790Lido\u6d41\u52a8\u6027\u8d28\u62bc\u4ee3\u5e01stETH\u53ca\u5176ERC-20\u5305\u88c5\u5f62\u5f0fwstETH\u7684\u94fe\u4e0a\u6d41\u901a\u60c5\u51b5\u3002\u901a\u8fc7\u91cd\u5efa\u5b8c\u6574\u7684\u8f6c\u8d26\u548c\u4efd\u989d\u5386\u53f2\uff0c\u8ba1\u7b97\u5730\u5740\u7ea7\u522b\u7684\u901f\u5ea6\u5e76\u5206\u89e3\u4e3a\u884c\u4e3a\u6a21\u5f0f\u3002", "motivation": "\u5c3d\u7ba1\u6d41\u52a8\u6027\u8d28\u62bc\u4ee3\u5e01\uff08LSTs\uff09\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u5176\u5fae\u89c2\u5c42\u9762\u7684\u8d27\u5e01\u52a8\u6001\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684\u6570\u636e\u7d22\u5f15\u7ba1\u9053\uff0c\u5206\u6790\u4e8b\u4ef6\u65e5\u5fd7\u548c\u5386\u53f2\u5408\u7ea6\u72b6\u6001\uff0c\u5e76\u53d1\u5e03\u4e86\u4e24\u7ec4\u516c\u5f00\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u622a\u81f32024\u5e7411\u67088\u65e5\u7684stETH\u548cwstETH\u7684\u6240\u6709\u8f6c\u8d26\u8bb0\u5f55\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e24\u79cd\u4ee3\u5e01\u7684\u6d41\u901a\u901f\u5ea6\u6301\u7eed\u8f83\u9ad8\uff0c\u4f46\u6d3b\u52a8\u9ad8\u5ea6\u96c6\u4e2d\uff0c\u4e3b\u8981\u7531\u5c11\u6570\u5927\u578b\u5730\u5740\uff08\u53ef\u80fd\u662f\u673a\u6784\u8d26\u6237\uff09\u4e3b\u5bfc\u3002\u6b64\u5916\uff0c\u7528\u6237\u884c\u4e3a\u9010\u6e10\u8f6c\u5411\u66f4\u4fbf\u4e8eDeFi\u7ec4\u5408\u7684wstETH\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5927\u89c4\u6a21\u5b9e\u8bc1\u63cf\u8ff0\u6d41\u52a8\u6027\u8d28\u62bc\u4ee3\u5e01\u7684\u6d41\u901a\u60c5\u51b5\uff0c\u4e3a\u76d1\u63a7\u8d28\u62bc\u8d44\u4ea7\u6d41\u52a8\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6a21\u677f\uff0c\u5e76\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u65b0\u7684\u5f00\u653e\u8d44\u6e90\u3002"}}
{"id": "2508.14899", "pdf": "https://arxiv.org/pdf/2508.14899", "abs": "https://arxiv.org/abs/2508.14899", "authors": ["Adeel Ahmad", "Ahmad Tameem Kamal", "Nouman Amir", "Bilal Zafar", "Saad Bin Nasir"], "title": "Accelerating GenAI Workloads by Enabling RISC-V Microkernel Support in IREE", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "This project enables RISC-V microkernel support in IREE, an MLIR-based\nmachine learning compiler and runtime. The approach begins by enabling the\nlowering of MLIR linalg dialect contraction ops to linalg.mmt4d op for the\nRISC-V64 target within the IREE pass pipeline, followed by the development of\noptimized microkernels for RISC-V. The performance gains are compared with\nupstream IREE and Llama.cpp for the Llama-3.2-1B-Instruct model.", "AI": {"tldr": "\u8be5\u9879\u76ee\u5728IREE\u4e2d\u5b9e\u73b0\u4e86RISC-V\u5fae\u5185\u6838\u652f\u6301\uff0c\u4f18\u5316\u4e86MLIR linalg dialect\u64cd\u4f5c\uff0c\u5e76\u5f00\u53d1\u4e86\u9488\u5bf9RISC-V\u7684\u5fae\u5185\u6838\uff0c\u6027\u80fd\u4e0e\u4e0a\u6e38IREE\u548cLlama.cpp\u5bf9\u6bd4\u3002", "motivation": "\u4e3a\u4e86\u5728RISC-V\u67b6\u6784\u4e0a\u63d0\u5347\u673a\u5668\u5b66\u4e60\u7684\u7f16\u8bd1\u548c\u8fd0\u884c\u6548\u7387\u3002", "method": "\u901a\u8fc7MLIR linalg dialect\u64cd\u4f5c\u4f18\u5316\u548c\u5f00\u53d1RISC-V\u5fae\u5185\u6838\u3002", "result": "\u6027\u80fd\u4e0eLlama-3.2-1B-Instruct\u6a21\u578b\u7684\u4e0a\u6e38IREE\u548cLlama.cpp\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002", "conclusion": "\u9879\u76ee\u6210\u529f\u5b9e\u73b0\u4e86RISC-V\u5fae\u5185\u6838\u652f\u6301\uff0c\u5e76\u5c55\u793a\u4e86\u6027\u80fd\u63d0\u5347\u6f5c\u529b\u3002"}}
{"id": "2508.15070", "pdf": "https://arxiv.org/pdf/2508.15070", "abs": "https://arxiv.org/abs/2508.15070", "authors": ["Daichi Amagata"], "title": "Random Sampling over Spatial Range Joins", "categories": ["cs.DB"], "comment": "Accepted version of our ICDE2025 paper", "summary": "Spatial range joins have many applications, including geographic information\nsystems, location-based social networking services, neuroscience, and\nvisualization. However, joins incur not only expensive computational costs but\nalso too large result sets. A practical and reasonable approach to alleviating\nthese issues is to return random samples of the join results. Although this is\npromising and sufficient for many applications involving spatial range joins,\nefficiently computing random samples is not trivial. This is because we must\nobtain random join samples without running spatial range joins. We address this\nchallenging problem for the first time and aim at designing a time- and\nspace-efficient algorithm. First, we design two baseline algorithms that employ\nexisting techniques for random sampling and show that they are not efficient.\nThen, we propose a new data structure that can deal with our problem in\n$\\tilde{O}(n + m + t)$ expected time and $O(n+m)$ space, where $n$ and $m$ are\nthe sizes of two point sets and $t$ is the required number of samples. We\nconduct extensive experiments using four real spatial datasets, and the results\ndemonstrate that our algorithm is significantly faster than the baselines in\nmost tests.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7a7a\u95f4\u8303\u56f4\u8fde\u63a5\u968f\u673a\u91c7\u6837\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8fde\u63a5\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u7ed3\u679c\u96c6\u8fc7\u5927\u7684\u95ee\u9898\u3002", "motivation": "\u7a7a\u95f4\u8303\u56f4\u8fde\u63a5\u5728\u8bb8\u591a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u7ed3\u679c\u96c6\u5927\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u968f\u673a\u91c7\u6837\u8fde\u63a5\u7ed3\u679c\u3002", "method": "\u9996\u5148\u8bbe\u8ba1\u4e86\u4e24\u79cd\u57fa\u4e8e\u73b0\u6709\u968f\u673a\u91c7\u6837\u6280\u672f\u7684\u57fa\u7ebf\u7b97\u6cd5\uff0c\u53d1\u73b0\u5176\u6548\u7387\u4e0d\u8db3\uff1b\u968f\u540e\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u7ed3\u6784\uff0c\u80fd\u591f\u5728\u9884\u671f\u65f6\u95f4\u548c\u7a7a\u95f4\u5185\u5b8c\u6210\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u65b0\u7b97\u6cd5\u5728\u591a\u6570\u6d4b\u8bd5\u4e2d\u663e\u8457\u5feb\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u6548\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u9700\u8981\u5927\u89c4\u6a21\u7a7a\u95f4\u8303\u56f4\u8fde\u63a5\u968f\u673a\u91c7\u6837\u7684\u573a\u666f\u3002"}}
{"id": "2508.15105", "pdf": "https://arxiv.org/pdf/2508.15105", "abs": "https://arxiv.org/abs/2508.15105", "authors": ["Yunzhao Yang", "Runhui Wang", "Xuanqing Liu", "Adit Krishnan", "Yefan Tao", "Yuqian Deng", "Kuangyou Yao", "Peiyuan Sun", "Henrik Johnson", "Aditi sinha", "Davor Golac", "Gerald Friedland", "Usman Shakeel", "Daryl Cooke", "Joe Sullivan", "Chris Kong"], "title": "Declarative Data Pipeline for Large Scale ML Services", "categories": ["cs.DC"], "comment": null, "summary": "Modern distributed data processing systems face significant challenges in\nbalancing system performance with code maintainability and developer\nproductivity, particularly when integrating machine learning capabilities at\nscale. In large collaborative environments, these challenges are amplified by\nhigh communication overhead between teams and the complexity of coordinating\ndevelopment across multiple groups. This paper presents a novel \"Declarative\nData Pipeline\" architecture that addresses these challenges while processing\nbillions of records with high accuracy and efficiency. Our architecture\nintroduces a modular framework that seamlessly integrates machine learning\ncapabilities within Apache Spark by combining logical computation units that we\nrefer as Pipes, departing from traditional microservice-based approaches. By\nestablishing clear component boundaries and standardized interfaces, we achieve\nboth modularity and system optimization without sacrificing maintainability.\nThe enterprise case study demonstrate substantial improvements in multiple\ndimensions: development efficiency improved by 50%,\ncollaboration/troubleshooting efforts compressed from weeks to days,\nperformance improved by 500x in scalability and by 10x in throughput. The\nacademic experiment also proves at least 5.7x faster in throughput with 99% CPU\nutilization than non-framework implementations. This paper details the\narchitectural decisions, implementation strategies, and performance\noptimizations that enable these improvements, providing insights for building\nscalable, maintainable data processing systems that effectively balance system\nperformance with development velocity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684'\u58f0\u660e\u5f0f\u6570\u636e\u7ba1\u9053'\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u6807\u51c6\u5316\u63a5\u53e3\uff0c\u5728Apache Spark\u4e2d\u9ad8\u6548\u96c6\u6210\u673a\u5668\u5b66\u4e60\u529f\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u5206\u5e03\u5f0f\u6570\u636e\u5904\u7406\u7cfb\u7edf\u5728\u5e73\u8861\u7cfb\u7edf\u6027\u80fd\u4e0e\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u53ca\u5f00\u53d1\u6548\u7387\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u534f\u4f5c\u73af\u5883\u4e2d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u8ba1\u7b97\u5355\u5143\uff08Pipes\uff09\u4ee3\u66ff\u4f20\u7edf\u7684\u5fae\u670d\u52a1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u673a\u5668\u5b66\u4e60\u4e0eApache Spark\u7684\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u4f01\u4e1a\u6848\u4f8b\u663e\u793a\u5f00\u53d1\u6548\u7387\u63d0\u534750%\uff0c\u534f\u4f5c/\u6545\u969c\u6392\u9664\u65f6\u95f4\u4ece\u5468\u7f29\u77ed\u5230\u5929\uff0c\u6027\u80fd\u63d0\u5347500\u500d\uff08\u53ef\u6269\u5c55\u6027\uff09\u548c10\u500d\uff08\u541e\u5410\u91cf\uff09\u3002\u5b66\u672f\u5b9e\u9a8c\u8bc1\u660e\u541e\u5410\u91cf\u81f3\u5c11\u5feb5.7\u500d\u4e14CPU\u5229\u7528\u7387\u8fbe99%\u3002", "conclusion": "\u901a\u8fc7\u67b6\u6784\u51b3\u7b56\u548c\u6027\u80fd\u4f18\u5316\uff0c\u672c\u6587\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u4e14\u6613\u7ef4\u62a4\u7684\u6570\u636e\u5904\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u5f00\u53d1\u6548\u7387\u3002"}}
{"id": "2508.15496", "pdf": "https://arxiv.org/pdf/2508.15496", "abs": "https://arxiv.org/abs/2508.15496", "authors": ["Elena Masserini", "Diego Clerissi", "Daniela Micucci", "Jo\u00e3o R. Campos", "Leonardo Mariani"], "title": "Towards the Assessment of Task-based Chatbots: From the TOFU-R Snapshot to the BRASATO Curated Dataset", "categories": ["cs.SE"], "comment": "10 pages, 10 figure, Accepted at IEEE International Symposium on\n  Software Reliability Engineering (ISSRE) 2025", "summary": "Task-based chatbots are increasingly being used to deliver real services, yet\nassessing their reliability, security, and robustness remains underexplored,\nalso due to the lack of large-scale, high-quality datasets. The emerging\nautomated quality assessment techniques targeting chatbots often rely on\nlimited pools of subjects, such as custom-made toy examples, or outdated, no\nlonger available, or scarcely popular agents, complicating the evaluation of\nsuch techniques. In this paper, we present two datasets and the tool support\nnecessary to create and maintain these datasets. The first dataset is RASA\nTASK-BASED CHATBOTS FROM GITHUB (TOFU-R), which is a snapshot of the Rasa\nchatbots available on GitHub, representing the state of the practice in\nopen-source chatbot development with Rasa. The second dataset is BOT RASA\nCOLLECTION (BRASATO), a curated selection of the most relevant chatbots for\ndialogue complexity, functional complexity, and utility, whose goal is to ease\nreproducibility and facilitate research on chatbot reliability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\uff08TOFU-R\u548cBRASATO\uff09\u53ca\u76f8\u5173\u5de5\u5177\uff0c\u7528\u4e8e\u8bc4\u4f30\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u7684\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u804a\u5929\u673a\u5668\u4eba\u8d28\u91cf\u8bc4\u4f30\u6280\u672f\u56e0\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u800c\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u6536\u96c6\u5e76\u6574\u7406GitHub\u4e0a\u7684Rasa\u804a\u5929\u673a\u5668\u4eba\uff08TOFU-R\uff09\uff0c\u5e76\u4ece\u4e2d\u7b5b\u9009\u51fa\u5bf9\u8bdd\u590d\u6742\u5ea6\u3001\u529f\u80fd\u590d\u6742\u5ea6\u548c\u5b9e\u7528\u6027\u7a81\u51fa\u7684\u673a\u5668\u4eba\uff08BRASATO\uff09\u3002", "result": "\u63d0\u4f9b\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\u53ca\u5de5\u5177\u652f\u6301\uff0c\u52a9\u529b\u804a\u5929\u673a\u5668\u4eba\u53ef\u9760\u6027\u7814\u7a76\u3002", "conclusion": "TOFU-R\u548cBRASATO\u6570\u636e\u96c6\u586b\u8865\u4e86\u7814\u7a76\u7a7a\u767d\uff0c\u4fc3\u8fdb\u4e86\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u7684\u8bc4\u4f30\u4e0e\u6539\u8fdb\u3002"}}
{"id": "2508.14933", "pdf": "https://arxiv.org/pdf/2508.14933", "abs": "https://arxiv.org/abs/2508.14933", "authors": ["Lucas S. Kupssinsk\u00fc", "Marco N. Bochernitsan", "Jordan Kopper", "Ot\u00e1vio Parraga", "Rodrigo C. Barros"], "title": "Inference Time Debiasing Concepts in Diffusion Models", "categories": ["cs.GR", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose DeCoDi, a debiasing procedure for text-to-image diffusion-based\nmodels that changes the inference procedure, does not significantly change\nimage quality, has negligible compute overhead, and can be applied in any\ndiffusion-based image generation model. DeCoDi changes the diffusion process to\navoid latent dimension regions of biased concepts. While most deep learning\ndebiasing methods require complex or compute-intensive interventions, our\nmethod is designed to change only the inference procedure. Therefore, it is\nmore accessible to a wide range of practitioners. We show the effectiveness of\nthe method by debiasing for gender, ethnicity, and age for the concepts of\nnurse, firefighter, and CEO. Two distinct human evaluators manually inspect\n1,200 generated images. Their evaluation results provide evidence that our\nmethod is effective in mitigating biases based on gender, ethnicity, and age.\nWe also show that an automatic bias evaluation performed by the GPT4o is not\nsignificantly statistically distinct from a human evaluation. Our evaluation\nshows promising results, with reliable levels of agreement between evaluators\nand more coverage of protected attributes. Our method has the potential to\nsignificantly improve the diversity of images it generates by diffusion-based\ntext-to-image generative models.", "AI": {"tldr": "DeCoDi\u662f\u4e00\u79cd\u9488\u5bf9\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u53bb\u504f\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u63a8\u65ad\u8fc7\u7a0b\u51cf\u5c11\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\uff0c\u8ba1\u7b97\u5f00\u9500\u4f4e\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u6269\u6563\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u53bb\u504f\u65b9\u6cd5\u901a\u5e38\u590d\u6742\u4e14\u8ba1\u7b97\u5bc6\u96c6\uff0cDeCoDi\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66f4\u6613\u7528\u4e14\u9ad8\u6548\u7684\u53bb\u504f\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u76f4\u63a5\u4fee\u6539\u6269\u6563\u8fc7\u7a0b\u7684\u63a8\u65ad\u6b65\u9aa4\uff0c\u907f\u514d\u6f5c\u5728\u7ef4\u5ea6\u4e2d\u504f\u89c1\u6982\u5ff5\u7684\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDeCoDi\u5728\u6027\u522b\u3001\u79cd\u65cf\u548c\u5e74\u9f84\u504f\u89c1\u53bb\u9664\u65b9\u9762\u6709\u6548\uff0c\u4eba\u5de5\u8bc4\u4f30\u548cGPT4o\u81ea\u52a8\u8bc4\u4f30\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "DeCoDi\u80fd\u663e\u8457\u63d0\u5347\u6269\u6563\u6a21\u578b\u751f\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\uff0c\u6f5c\u5728\u5e94\u7528\u5e7f\u6cdb\u3002"}}
{"id": "2508.15478", "pdf": "https://arxiv.org/pdf/2508.15478", "abs": "https://arxiv.org/abs/2508.15478", "authors": ["Nghiem Thanh Pham", "Tung Kieu", "Duc-Manh Nguyen", "Son Ha Xuan", "Nghia Duong-Trung", "Danh Le-Phuoc"], "title": "SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impacts -- Extended Version", "categories": ["cs.CL", "cs.CY", "cs.PF"], "comment": "24 pages. An extended version of \"SLM-Bench: A Comprehensive\n  Benchmark of Small Language Models on Environmental Impacts\" accepted at\n  EMNLP 2025", "summary": "Small Language Models (SLMs) offer computational efficiency and\naccessibility, yet a systematic evaluation of their performance and\nenvironmental impact remains lacking. We introduce SLM-Bench, the first\nbenchmark specifically designed to assess SLMs across multiple dimensions,\nincluding accuracy, computational efficiency, and sustainability metrics.\nSLM-Bench evaluates 15 SLMs on 9 NLP tasks using 23 datasets spanning 14\ndomains. The evaluation is conducted on 4 hardware configurations, providing a\nrigorous comparison of their effectiveness. Unlike prior benchmarks, SLM-Bench\nquantifies 11 metrics across correctness, computation, and consumption,\nenabling a holistic assessment of efficiency trade-offs. Our evaluation\nconsiders controlled hardware conditions, ensuring fair comparisons across\nmodels. We develop an open-source benchmarking pipeline with standardized\nevaluation protocols to facilitate reproducibility and further research. Our\nfindings highlight the diverse trade-offs among SLMs, where some models excel\nin accuracy while others achieve superior energy efficiency. SLM-Bench sets a\nnew standard for SLM evaluation, bridging the gap between resource efficiency\nand real-world applicability.", "AI": {"tldr": "SLM-Bench\u662f\u9996\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u7b49\u591a\u7ef4\u5ea6\uff0c\u586b\u8865\u4e86\u7cfb\u7edf\u6027\u8bc4\u4f30SLM\u7684\u7a7a\u767d\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u6027\u80fd\u548c\u73af\u5883\u5f71\u54cd\u7cfb\u7edf\u6027\u8bc4\u4f30\u7684\u5de5\u5177\uff0cSLM-Bench\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "SLM-Bench\u5bf915\u4e2aSLM\u57289\u4e2aNLP\u4efb\u52a1\u4e0a\u4f7f\u752823\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6db5\u76d614\u4e2a\u9886\u57df\uff0c\u5e76\u57284\u79cd\u786c\u4ef6\u914d\u7f6e\u4e0b\u8bc4\u4f3011\u4e2a\u6307\u6807\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540cSLM\u5728\u51c6\u786e\u6027\u548c\u80fd\u6e90\u6548\u7387\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u90e8\u5206\u6a21\u578b\u5728\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u53e6\u4e00\u4e9b\u5219\u80fd\u6e90\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "SLM-Bench\u4e3aSLM\u8bc4\u4f30\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u4fc3\u8fdb\u4e86\u8d44\u6e90\u6548\u7387\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5e73\u8861\u3002"}}
{"id": "2508.15137", "pdf": "https://arxiv.org/pdf/2508.15137", "abs": "https://arxiv.org/abs/2508.15137", "authors": ["Ruijie Fang", "Zachary Kincaid", "Thomas Reps"], "title": "Software Model Checking via Summary-Guided Search (Extended Version)", "categories": ["cs.PL", "cs.SE"], "comment": "Preliminary manuscript of extended version of paper that will appear\n  in OOPSLA 2025. 36 pages", "summary": "In this work, we describe a new software model-checking algorithm called GPS.\nGPS treats the task of model checking a program as a directed search of the\nprogram states, guided by a compositional, summary-based static analysis. The\nsummaries produced by static analysis are used both to prune away infeasible\npaths and to drive test generation to reach new, unexplored program states. GPS\ncan find both proofs of safety and counter-examples to safety (i.e., inputs\nthat trigger bugs), and features a novel two-layered search strategy that\nrenders it particularly efficient at finding bugs in programs featuring long,\ninput-dependent error paths. To make GPS refutationally complete (in the sense\nthat it will find an error if one exists, if it is allotted enough time), we\nintroduce an instrumentation technique and show that it helps GPS achieve\nrefutation-completeness without sacrificing overall performance. We benchmarked\nGPS on a suite of benchmarks including both programs from the Software\nVerification Competition (SV-COMP) and from prior literature, and found that\nour implementation of GPS outperforms state-of-the-art software model checkers\n(including the top performers in SV-COMP ReachSafety-Loops category), both in\nterms of the number of benchmarks solved and in terms of running time.", "AI": {"tldr": "GPS\u662f\u4e00\u79cd\u65b0\u7684\u8f6f\u4ef6\u6a21\u578b\u68c0\u67e5\u7b97\u6cd5\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u7684\u7ec4\u5408\u6027\u6458\u8981\u5f15\u5bfc\u7a0b\u5e8f\u72b6\u6001\u7684\u6709\u5411\u641c\u7d22\uff0c\u9ad8\u6548\u68c0\u6d4b\u7a0b\u5e8f\u5b89\u5168\u6027\u548c\u9519\u8bef\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u6a21\u578b\u68c0\u67e5\u5668\u5728\u68c0\u6d4b\u957f\u4e14\u8f93\u5165\u76f8\u5173\u7684\u9519\u8bef\u8def\u5f84\u65f6\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "GPS\u7ed3\u5408\u9759\u6001\u5206\u6790\u7684\u6458\u8981\u4fe1\u606f\u8fdb\u884c\u8def\u5f84\u4fee\u526a\u548c\u6d4b\u8bd5\u751f\u6210\uff0c\u91c7\u7528\u5206\u5c42\u641c\u7d22\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5de5\u5177\u5316\u6280\u672f\u5b9e\u73b0\u5b8c\u5168\u6027\u3002", "result": "GPS\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u6a21\u578b\u68c0\u67e5\u5668\uff0c\u5305\u62ecSV-COMP\u4e2d\u7684\u9886\u5148\u5de5\u5177\u3002", "conclusion": "GPS\u901a\u8fc7\u5176\u65b0\u9896\u7684\u641c\u7d22\u7b56\u7565\u548c\u5de5\u5177\u5316\u6280\u672f\uff0c\u5728\u9ad8\u6548\u6027\u548c\u5b8c\u5907\u6027\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2508.15402", "pdf": "https://arxiv.org/pdf/2508.15402", "abs": "https://arxiv.org/abs/2508.15402", "authors": ["Antonio Casares"], "title": "Transition-based vs stated-based acceptance for automata over infinite words", "categories": ["cs.FL", "cs.LO", "68Q45", "F.4.3"], "comment": null, "summary": "Automata over infinite objects are a well-established model with applications\nin logic and formal verification. Traditionally, acceptance in such automata is\ndefined based on the set of states visited infinitely often during a run.\nHowever, there is a growing trend towards defining acceptance based on\ntransitions rather than states.\n  In this survey, we analyse the reasons for this shift and advocate using\ntransition-based acceptance in the context of automata over infinite words. We\npresent a collection of problems where the choice of formalism has a major\nimpact and discuss the causes of these differences.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8c03\u67e5\u4e86\u5728\u65e0\u9650\u5b57\u81ea\u52a8\u673a\u4e2d\u5c06\u63a5\u53d7\u6761\u4ef6\u4ece\u57fa\u4e8e\u72b6\u6001\u8f6c\u5411\u57fa\u4e8e\u8f6c\u79fb\u7684\u8d8b\u52bf\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u79cd\u9009\u62e9\u5bf9\u95ee\u9898\u89e3\u51b3\u7684\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u4e0a\uff0c\u65e0\u9650\u5bf9\u8c61\u81ea\u52a8\u673a\u7684\u63a5\u53d7\u6761\u4ef6\u57fa\u4e8e\u72b6\u6001\uff0c\u4f46\u8fd1\u5e74\u6765\u6709\u8f6c\u5411\u57fa\u4e8e\u8f6c\u79fb\u7684\u8d8b\u52bf\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u8fd9\u79cd\u8f6c\u53d8\u7684\u539f\u56e0\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u548c\u5206\u6790\uff0c\u6bd4\u8f83\u57fa\u4e8e\u72b6\u6001\u548c\u57fa\u4e8e\u8f6c\u79fb\u7684\u63a5\u53d7\u6761\u4ef6\u5728\u65e0\u9650\u5b57\u81ea\u52a8\u673a\u4e2d\u7684\u5e94\u7528\u548c\u6548\u679c\u3002", "result": "\u57fa\u4e8e\u8f6c\u79fb\u7684\u63a5\u53d7\u6761\u4ef6\u5728\u67d0\u4e9b\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u9009\u62e9\u63a5\u53d7\u6761\u4ef6\u7684\u5f62\u5f0f\u5bf9\u81ea\u52a8\u673a\u7684\u8868\u73b0\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u5728\u65e0\u9650\u5b57\u81ea\u52a8\u673a\u4e2d\uff0c\u57fa\u4e8e\u8f6c\u79fb\u7684\u63a5\u53d7\u6761\u4ef6\u66f4\u5177\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u503c\u5f97\u63a8\u5e7f\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.14956", "pdf": "https://arxiv.org/pdf/2508.14956", "abs": "https://arxiv.org/abs/2508.14956", "authors": ["Nan-Hong Kuo", "Hojjat Baghban"], "title": "Holo-Artisan: A Personalized Multi-User Holographic Experience for Virtual Museums on the Edge Intelligence", "categories": ["cs.MM", "cs.NI", "cs.SY", "eess.IV", "eess.SY"], "comment": null, "summary": "We present Holo-Artisan, a novel system architecture enabling immersive\nmulti-user experiences in virtual museums through true holographic displays and\npersonalized edge intelligence. In our design, local edge computing nodes\nprocess real-time user data -- including pose, facial expression, and voice --\nfor multiple visitors concurrently. Generative AI models then drive digital\nartworks (e.g., a volumetric Mona Lisa) to respond uniquely to each viewer. For\ninstance, the Mona Lisa can return a smile to one visitor while engaging in a\nspoken Q\\&A with another, all in real time. A cloud-assisted collaboration\nplatform composes these interactions in a shared scene using a universal scene\ndescription, and employs ray tracing to render high-fidelity, personalized\nviews with a direct pipeline to glasses-free holographic displays. To preserve\nuser privacy and continuously improve personalization, we integrate federated\nlearning (FL) -- edge devices locally fine-tune AI models and share only model\nupdates for aggregation. This edge-centric approach minimizes latency and\nbandwidth usage, ensuring a synchronized shared experience with individual\ncustomization. Through Holo-Artisan, static museum exhibits are transformed\ninto dynamic, living artworks that engage each visitor in a personal dialogue,\nheralding a new paradigm of cultural heritage interaction.", "AI": {"tldr": "Holo-Artisan\u662f\u4e00\u4e2a\u901a\u8fc7\u5168\u606f\u663e\u793a\u548c\u4e2a\u6027\u5316\u8fb9\u7f18\u667a\u80fd\u5b9e\u73b0\u865a\u62df\u535a\u7269\u9986\u591a\u7528\u6237\u6c89\u6d78\u5f0f\u4f53\u9a8c\u7684\u7cfb\u7edf\u67b6\u6784\u3002", "motivation": "\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u5c06\u9759\u6001\u535a\u7269\u9986\u5c55\u54c1\u8f6c\u5316\u4e3a\u52a8\u6001\u3001\u4e92\u52a8\u6027\u5f3a\u7684\u827a\u672f\u4f5c\u54c1\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u6587\u5316\u9057\u4ea7\u4e92\u52a8\u65b9\u5f0f\u3002", "method": "\u4f7f\u7528\u672c\u5730\u8fb9\u7f18\u8ba1\u7b97\u8282\u70b9\u5904\u7406\u5b9e\u65f6\u7528\u6237\u6570\u636e\uff0c\u7ed3\u5408\u751f\u6210\u5f0fAI\u548c\u8054\u90a6\u5b66\u4e60\uff0c\u901a\u8fc7\u4e91\u534f\u4f5c\u5e73\u53f0\u548c\u5149\u7ebf\u8ffd\u8e2a\u6280\u672f\u5b9e\u73b0\u4e2a\u6027\u5316\u5168\u606f\u5c55\u793a\u3002", "result": "\u5b9e\u73b0\u4e86\u591a\u7528\u6237\u540c\u6b65\u5171\u4eab\u7684\u4e2a\u6027\u5316\u4ea4\u4e92\u4f53\u9a8c\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u5e26\u5bbd\u4f7f\u7528\u3002", "conclusion": "Holo-Artisan\u4e3a\u6587\u5316\u9057\u4ea7\u4e92\u52a8\u5f00\u542f\u4e86\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u6280\u672f\u5b9e\u73b0\u4e86\u827a\u672f\u54c1\u7684\u52a8\u6001\u5316\u548c\u4e2a\u6027\u5316\u4e92\u52a8\u3002"}}
{"id": "2508.15087", "pdf": "https://arxiv.org/pdf/2508.15087", "abs": "https://arxiv.org/abs/2508.15087", "authors": ["Jashanjot Singh Sidhu", "Jorge Ignacio Sandoval", "Abdelhak Bentaleb", "Sandra Cespedes"], "title": "From 5G RAN Queue Dynamics to Playback: A Performance Analysis for QUIC Video Streaming", "categories": ["cs.NI"], "comment": null, "summary": "The rapid adoption of QUIC as a transport protocol has transformed content\ndelivery by reducing latency, enhancing congestion control (CC), and enabling\nmore efficient multiplexing. With the advent of 5G networks, which support\nultra-low latency and high bandwidth, streaming high-resolution video at 4K and\nbeyond has become increasingly viable. However, optimizing Quality of\nExperience (QoE) in mobile networks remains challenging due to the complex\ninteractions among Adaptive Bit Rate (ABR) schemes at the application layer, CC\nalgorithms at the transport layer, and Radio Link Control (RLC) queuing at the\nlink layer in the 5G network. While prior studies have largely examined these\ncomponents in isolation, this work presents a comprehensive analysis of the\nimpact of modern active queue management (AQM) strategies, such as RED and L4S,\non video streaming over diverse QUIC implementations--focusing particularly on\ntheir interaction with the RLC buffer in 5G environments and the interplay\nbetween CC algorithms and ABR schemes. Our findings demonstrate that the\neffectiveness of AQM strategies in improving video streaming QoE is\nintrinsically linked to their dynamic interaction with QUIC implementations, CC\nalgorithms and ABR schemes-highlighting that isolated optimizations are\ninsufficient. This intricate interdependence necessitates holistic, cross-layer\nadaptive mechanisms capable of real-time coordination between network,\ntransport and application layers, which are crucial for fully leveraging the\ncapabilities of 5G networks to deliver robust, adaptive, and high-quality video\nstreaming.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86QUIC\u534f\u8bae\u4e0e5G\u7f51\u7edc\u73af\u5883\u4e0b\u89c6\u9891\u6d41QoE\u7684\u4f18\u5316\u6311\u6218\uff0c\u5f3a\u8c03\u8de8\u5c42\u534f\u8c03\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740QUIC\u534f\u8bae\u7684\u5e7f\u6cdb\u5e94\u7528\u548c5G\u7f51\u7edc\u7684\u5230\u6765\uff0c\u89c6\u9891\u6d41\u7684QoE\u4f18\u5316\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662fABR\u3001CC\u548cRLC\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86\u73b0\u4ee3AQM\u7b56\u7565\uff08\u5982RED\u548cL4S\uff09\u5bf9\u89c6\u9891\u6d41\u7684\u5f71\u54cd\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u4e0eQUIC\u5b9e\u73b0\u3001CC\u7b97\u6cd5\u548cABR\u65b9\u6848\u7684\u52a8\u6001\u4ea4\u4e92\u3002", "result": "\u7814\u7a76\u53d1\u73b0AQM\u7b56\u7565\u7684\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u4e0eQUIC\u3001CC\u548cABR\u7684\u534f\u540c\u4f5c\u7528\uff0c\u5b64\u7acb\u4f18\u5316\u4e0d\u8db3\u4ee5\u63d0\u5347QoE\u3002", "conclusion": "\u4e3a\u5145\u5206\u5229\u75285G\u6f5c\u529b\uff0c\u9700\u8981\u8de8\u5c42\u81ea\u9002\u5e94\u673a\u5236\uff0c\u5b9e\u73b0\u7f51\u7edc\u3001\u4f20\u8f93\u548c\u5e94\u7528\u5c42\u7684\u5b9e\u65f6\u534f\u8c03\u3002"}}
{"id": "2508.15045", "pdf": "https://arxiv.org/pdf/2508.15045", "abs": "https://arxiv.org/abs/2508.15045", "authors": ["Guillermo Vera-Amaro", "Jos\u00e9 Rafael Rojano-C\u00e1ceres"], "title": "Understanding Accessibility Needs of Blind Authors on CMS-Based Websites", "categories": ["cs.HC", "H.5.2; H.5.4"], "comment": "15 pages, 5 figures, presented in Ibero-American Conference on\n  Human-Computer Interaction 2025", "summary": "This paper addresses the limited attention given to blind users as content\ncreators in Content Management Systems (CMS), a gap that remains under-explored\nin web accessibility research. For blind authors, effective interaction with\nCMS platforms requires more than technical compliance; it demands interfaces\ndesigned with semantic clarity, predictable navigation, and meaningful feedback\nfor screen reader users. This study investigates the accessibility barriers\nblind users face when performing key tasks, such as page creation, menu\nediting, and image publishing, using CMS platforms. A two-fold evaluation was\nconducted using automated tools and manual usability testing with three blind\nand one sighted participant, complemented by expert analysis based on the\nBarrier Walkthrough method. Results showed that block-based interfaces were\nparticularly challenging, often marked as accessible by automated tools but\nresulting in critical usability issues during manual evaluation. The use of a\ntext-based editor, the integration of AI-generated image descriptions, and\ntraining aligned with screen reader workflows, significantly improved usability\nand autonomy. These findings underscore the limitations of automated\nassessments and highlight the importance of user-centered design practices.\nEnhancing CMS accessibility requires consistent navigation structures, reduced\nreliance on visual interaction patterns, and the integration of AI tools that\nsupport blind content authors throughout the content creation process.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u76f2\u4eba\u7528\u6237\u5728\u5185\u5bb9\u7ba1\u7406\u7cfb\u7edf\uff08CMS\uff09\u4e2d\u4f5c\u4e3a\u5185\u5bb9\u521b\u4f5c\u8005\u9762\u4e34\u7684\u969c\u788d\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u4ee5\u63d0\u5347\u5176\u4f7f\u7528\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524dCMS\u5bf9\u76f2\u4eba\u5185\u5bb9\u521b\u4f5c\u8005\u7684\u652f\u6301\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u754c\u9762\u8bbe\u8ba1\u548c\u53cd\u9988\u673a\u5236\u4e0a\uff0c\u7f3a\u4e4f\u6df1\u5165\u7814\u7a76\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u5316\u5de5\u5177\u548c\u624b\u52a8\u53ef\u7528\u6027\u6d4b\u8bd5\uff08\u5305\u62ec\u76f2\u4eba\u548c\u89c6\u529b\u6b63\u5e38\u53c2\u4e0e\u8005\uff09\uff0c\u5e76\u91c7\u7528\u4e13\u5bb6\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u5757\u72b6\u7f16\u8f91\u5668\u5b58\u5728\u4e25\u91cd\u53ef\u7528\u6027\u95ee\u9898\uff0c\u800c\u6587\u672c\u7f16\u8f91\u5668\u3001AI\u751f\u6210\u56fe\u50cf\u63cf\u8ff0\u548c\u9488\u5bf9\u6027\u57f9\u8bad\u663e\u8457\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "\u81ea\u52a8\u5316\u8bc4\u4f30\u5c40\u9650\u6027\u5927\uff0c\u9700\u901a\u8fc7\u7528\u6237\u4e2d\u5fc3\u8bbe\u8ba1\u3001\u7b80\u5316\u5bfc\u822a\u548c\u6574\u5408AI\u5de5\u5177\u6765\u63d0\u5347CMS\u65e0\u969c\u788d\u6027\u3002"}}
{"id": "2508.15542", "pdf": "https://arxiv.org/pdf/2508.15542", "abs": "https://arxiv.org/abs/2508.15542", "authors": ["Mingyang Yu", "Haorui Yang", "Donglin Wang", "Desheng Kong", "Ji Du", "Yulong Fu", "Wei Wang", "Jing Xu"], "title": "Distributed Shared Layered Storage Quantum Simulator: A novel quantum simulation system for efficient scaling and cost optimization", "categories": ["cs.ET", "quant-ph"], "comment": null, "summary": "Quantum simulators are essential tools for developing and testing quantum\nalgorithms. However, the high-frequency traversal characteristic of quantum\nsimulators represents an unprecedented demand in the history of IT, and\nexisting distributed technologies is unable to meet this requirement, resulting\nin a single-node bottleneck of quantum simulator. To overcome this limitation,\nthis paper introduces a novel Distributed Shared Layered Storage Quantum\nSimulator (DSLSQS). By leveraging an innovative distributed architecture in\nwhich multiple computational nodes share data storage directly, together with\nDe-TCP/IP networking technology, DSLSQS effectively eliminates East-West data\nflow in distributed systems. This approach mitigates the bottleneck of\ndistributed quantum simulation clusters and enhances the scalability. Moreover,\nthe system employs layered storage technology, which reduces usage of expensive\nhigh-performance memory and substantially lowers simulation costs. Furthermore,\nthis paper systematically analyzes the performance and cost constraints of\ndistributed quantum simulator cluster, identifying distributed networking as\nthe primary performance bottleneck and highlighting that minimizing storage\ncosts is crucial to reducing the total cost. Finally, experimental evaluations\nwith a 27-qubit simulation confirm the successful implementation of layered\nstorage within the quantum simulator. DSLSQS significantly enhances simulation\nefficiency, yielding a performance improvement of over 350% compared to\nexisting distributed technologies. These results underscore the superior\nperformance and scalability of the proposed architecture in managing complex\nquantum computing tasks. This paper provides crucial insights for the practical\ndeployment of quantum computing and presents an effective framework for the\ndevelopment of distributed quantum simulation clusters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u5206\u5e03\u5f0f\u5171\u4eab\u5206\u5c42\u5b58\u50a8\u91cf\u5b50\u6a21\u62df\u5668\uff08DSLSQS\uff09\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5206\u5e03\u5f0f\u67b6\u6784\u548c\u53bbTCP/IP\u7f51\u7edc\u6280\u672f\uff0c\u89e3\u51b3\u91cf\u5b50\u6a21\u62df\u5668\u7684\u9ad8\u9891\u904d\u5386\u9700\u6c42\uff0c\u63d0\u5347\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u6280\u672f\u65e0\u6cd5\u6ee1\u8db3\u91cf\u5b50\u6a21\u62df\u5668\u7684\u9ad8\u9891\u904d\u5386\u9700\u6c42\uff0c\u5bfc\u81f4\u5355\u8282\u70b9\u74f6\u9888\u3002\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5206\u5e03\u5f0f\u67b6\u6784\u6765\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u5171\u4eab\u6570\u636e\u5b58\u50a8\u67b6\u6784\u548c\u53bbTCP/IP\u7f51\u7edc\u6280\u672f\uff0c\u7ed3\u5408\u5206\u5c42\u5b58\u50a8\u6280\u672f\uff0c\u51cf\u5c11\u9ad8\u6027\u80fd\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cDSLSQS\u572827\u91cf\u5b50\u6bd4\u7279\u6a21\u62df\u4e2d\u6027\u80fd\u63d0\u5347\u8d85\u8fc7350%\uff0c\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u6210\u672c\u3002", "conclusion": "DSLSQS\u4e3a\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u5e76\u4e3a\u5206\u5e03\u5f0f\u91cf\u5b50\u6a21\u62df\u96c6\u7fa4\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2508.14907", "pdf": "https://arxiv.org/pdf/2508.14907", "abs": "https://arxiv.org/abs/2508.14907", "authors": ["Lukas Krupp", "Ian O'Connor", "Luca Benini", "Christoph Studer", "Joachim Rodrigues", "Norbert Wehn"], "title": "Improving Chip Design Enablement for Universities in Europe -- A Position Paper", "categories": ["cs.AR"], "comment": "Published in the proceedings of the 2025 Design, Automation & Test in\n  Europe Conference (DATE)", "summary": "The semiconductor industry is pivotal to Europe's economy, especially within\nthe industrial and automotive sectors. However, Europe faces a significant\nshortfall in chip design capabilities, marked by a severe skilled labor\nshortage and lagging contributions in the design value chain segment. This\npaper explores the role of European universities and academic initiatives in\nenhancing chip design education and research to address these deficits. We\nprovide a comprehensive overview of current European chip design initiatives,\nanalyze major challenges in recruitment, productivity, technology access, and\ndesign enablement, and identify strategic opportunities to strengthen chip\ndesign capabilities within academic institutions. Our analysis leads to a\nseries of recommendations that highlight the need for coordinated efforts and\nstrategic investments to overcome these challenges.", "AI": {"tldr": "\u6b27\u6d32\u9762\u4e34\u82af\u7247\u8bbe\u8ba1\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u5b66\u548c\u5b66\u672f\u673a\u6784\u5982\u4f55\u901a\u8fc7\u6559\u80b2\u548c\u7814\u7a76\u6765\u63d0\u5347\u8fd9\u4e00\u80fd\u529b\u3002", "motivation": "\u6b27\u6d32\u534a\u5bfc\u4f53\u884c\u4e1a\u7ecf\u6d4e\u91cd\u8981\uff0c\u4f46\u82af\u7247\u8bbe\u8ba1\u80fd\u529b\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u4eba\u624d\u77ed\u7f3a\u548c\u6280\u672f\u843d\u540e\u3002", "method": "\u7efc\u8ff0\u6b27\u6d32\u73b0\u6709\u82af\u7247\u8bbe\u8ba1\u9879\u76ee\uff0c\u5206\u6790\u62db\u8058\u3001\u751f\u4ea7\u529b\u3001\u6280\u672f\u83b7\u53d6\u548c\u8bbe\u8ba1\u652f\u6301\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u6218\u7565\u673a\u4f1a\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u5efa\u8bae\uff0c\u5f3a\u8c03\u534f\u8c03\u52aa\u529b\u548c\u6218\u7565\u6295\u8d44\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u9700\u901a\u8fc7\u5b66\u672f\u673a\u6784\u7684\u534f\u4f5c\u548c\u6295\u8d44\u6765\u63d0\u5347\u6b27\u6d32\u7684\u82af\u7247\u8bbe\u8ba1\u80fd\u529b\u3002"}}
{"id": "2508.15238", "pdf": "https://arxiv.org/pdf/2508.15238", "abs": "https://arxiv.org/abs/2508.15238", "authors": ["Yinyu Liu", "Kaiqiang Yu", "Shengxin Liu", "Cheng Long", "Zhaoquan Gu"], "title": "Temporal $k$-Core Query, Revisited", "categories": ["cs.DB"], "comment": null, "summary": "Querying cohesive subgraphs in temporal graphs is essential for understanding\nthe dynamic structure of real-world networks, such as evolving communities in\nsocial platforms, shifting hyperlink structures on the Web, and transient\ncommunication patterns in call networks. Recently, research has focused on the\ntemporal $k$-core query, which aims to identify all $k$-cores across all\npossible time sub-intervals within a given query interval. The state-of-the-art\nalgorithm OTCD mitigates redundant computations over overlapping sub-intervals\nby exploiting inclusion relationships among $k$-cores in different time\nintervals. Nevertheless, OTCD remains limited in scalability due to the\ncombinatorial growth in interval enumeration and repeated processing. In this\npaper, we revisit the temporal $k$-core query problem and introduce a novel\nalgorithm CoreT, which dynamically records the earliest timestamp at which each\nvertex or edge enters a $k$-core. This strategy enables substantial pruning of\nredundant computations. As a result, CoreT requires only a single pass over the\nquery interval and achieves improved time complexity, which is linear in both\nthe number of temporal edges within the query interval and the duration of the\ninterval, making it highly scalable for long-term temporal analysis.\nExperimental results on large real-world datasets show that CoreT achieves up\nto four orders of magnitude speedup compared to the existing state-of-the-art\nOTCD, demonstrating its effectiveness and scalability for temporal $k$-core\nanalysis.", "AI": {"tldr": "CoreT\u7b97\u6cd5\u901a\u8fc7\u52a8\u6001\u8bb0\u5f55\u9876\u70b9\u6216\u8fb9\u8fdb\u5165k\u6838\u7684\u6700\u65e9\u65f6\u95f4\u6233\uff0c\u663e\u8457\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff0c\u5b9e\u73b0\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u9ad8\u6548\u7684\u65f6\u95f4\u6838\u67e5\u8be2\u3002", "motivation": "\u7406\u89e3\u52a8\u6001\u7f51\u7edc\uff08\u5982\u793e\u4ea4\u5e73\u53f0\u3001\u7f51\u9875\u94fe\u63a5\u3001\u901a\u4fe1\u7f51\u7edc\uff09\u7684\u7ed3\u6784\u9700\u8981\u9ad8\u6548\u7684\u65f6\u5e8fk\u6838\u67e5\u8be2\u65b9\u6cd5\uff0c\u73b0\u6709\u7b97\u6cd5OTCD\u56e0\u5197\u4f59\u8ba1\u7b97\u548c\u7ec4\u5408\u589e\u957f\u53d7\u9650\u3002", "method": "CoreT\u7b97\u6cd5\u52a8\u6001\u8bb0\u5f55\u6bcf\u4e2a\u9876\u70b9\u6216\u8fb9\u8fdb\u5165k\u6838\u7684\u6700\u65e9\u65f6\u95f4\u6233\uff0c\u5b9e\u73b0\u5355\u6b21\u904d\u5386\u67e5\u8be2\u533a\u95f4\u5e76\u4f18\u5316\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoreT\u6bd4OTCD\u5feb\u56db\u4e2a\u6570\u91cf\u7ea7\uff0c\u9002\u7528\u4e8e\u957f\u671f\u65f6\u5e8f\u5206\u6790\u3002", "conclusion": "CoreT\u5728\u65f6\u5e8fk\u6838\u67e5\u8be2\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.15351", "pdf": "https://arxiv.org/pdf/2508.15351", "abs": "https://arxiv.org/abs/2508.15351", "authors": ["Cynthia Marcelino", "Leonard Guelmino", "Thomas Pusztai", "Stefan Nastic"], "title": "Databelt: A Continuous Data Path for Serverless Workflows in the 3D Compute Continuum", "categories": ["cs.DC"], "comment": null, "summary": "Typically, serverless functions rely on remote storage services for managing\nstate, which can result in increased latency and network communication\noverhead. In a dynamic environment such as the 3D (Edge-Cloud-Space) Compute\nContinuum, serverless functions face additional challenges due to frequent\nchanges in network topology. As satellites move in and out of the range of\nground stations, functions must make multiple hops to access cloud services,\nleading to high-latency state access and unnecessary data transfers. In this\npaper, we present Databelt, a state management framework for serverless\nworkflows designed for the dynamic environment of the 3D Compute Continuum.\nDatabelt introduces an SLO-aware state propagation mechanism that enables the\nfunction state to move continuously in orbit. Databelt proactively offloads\nfunction states to the most suitable node, such that when functions execute,\nthe data is already present on the execution node or nearby, thus minimizing\nstate access latency and reducing the number of network hops. Additionally,\nDatabelt introduces a function state fusion mechanism that abstracts state\nmanagement for functions sharing the same serverless runtime. When functions\nare fused, Databelt seamlessly retrieves their state as a group, reducing\nredundant network and storage operations and improving overall workflow\nefficiency. Our experimental results show that Databelt reduces workflow\nexecution time by up to 66% and increases throughput by 50% compared to the\nbaselines. Furthermore, our results show that Databelt function state fusion\nreduces storage operations latency by up to 20%, by reducing repetitive storage\nrequests for functions within the same runtime, ensuring efficient execution of\nserverless workflows in highly dynamic network environments such as the 3D\nContinuum.", "AI": {"tldr": "Databelt\u662f\u4e00\u4e2a\u9488\u5bf93D\u8ba1\u7b97\u8fde\u7eed\u4f53\u52a8\u6001\u73af\u5883\u8bbe\u8ba1\u7684\u65e0\u670d\u52a1\u5668\u5de5\u4f5c\u6d41\u72b6\u6001\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7SLO\u611f\u77e5\u7684\u72b6\u6001\u4f20\u64ad\u548c\u51fd\u6570\u72b6\u6001\u878d\u5408\u673a\u5236\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u65e0\u670d\u52a1\u5668\u51fd\u6570\u5728\u52a8\u6001\u7f51\u7edc\u73af\u5883\uff08\u59823D\u8ba1\u7b97\u8fde\u7eed\u4f53\uff09\u4e2d\u56e0\u9891\u7e41\u7f51\u7edc\u62d3\u6251\u53d8\u5316\u5bfc\u81f4\u7684\u9ad8\u5ef6\u8fdf\u548c\u4e0d\u5fc5\u8981\u6570\u636e\u4f20\u8f93\u95ee\u9898\u3002", "method": "1. SLO\u611f\u77e5\u72b6\u6001\u4f20\u64ad\u673a\u5236\uff0c\u4e3b\u52a8\u5378\u8f7d\u51fd\u6570\u72b6\u6001\u5230\u6700\u5408\u9002\u7684\u8282\u70b9\uff1b2. \u51fd\u6570\u72b6\u6001\u878d\u5408\u673a\u5236\uff0c\u5c06\u5171\u4eab\u540c\u4e00\u8fd0\u884c\u65f6\u7684\u51fd\u6570\u72b6\u6001\u62bd\u8c61\u4e3a\u7ec4\u7ba1\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDatabelt\u5c06\u5de5\u4f5c\u6d41\u6267\u884c\u65f6\u95f4\u51cf\u5c1166%\uff0c\u541e\u5410\u91cf\u63d0\u534750%\uff0c\u5b58\u50a8\u64cd\u4f5c\u5ef6\u8fdf\u964d\u4f4e20%\u3002", "conclusion": "Databelt\u901a\u8fc7\u52a8\u6001\u72b6\u6001\u7ba1\u7406\u548c\u878d\u5408\u673a\u5236\uff0c\u663e\u8457\u4f18\u5316\u4e86\u65e0\u670d\u52a1\u5668\u5de5\u4f5c\u6d41\u5728\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.15503", "pdf": "https://arxiv.org/pdf/2508.15503", "abs": "https://arxiv.org/abs/2508.15503", "authors": ["Sebastian Baltes", "Florian Angermeir", "Chetan Arora", "Marvin Mu\u00f1oz Bar\u00f3n", "Chunyang Chen", "Lukas B\u00f6hme", "Fabio Calefato", "Neil Ernst", "Davide Falessi", "Brian Fitzgerald", "Davide Fucci", "Marcos Kalinowski", "Stefano Lambiase", "Daniel Russo", "Mircea Lungu", "Lutz Prechelt", "Paul Ralph", "Christoph Treude", "Stefan Wagner"], "title": "Evaluation Guidelines for Empirical Studies in Software Engineering involving LLMs", "categories": ["cs.SE"], "comment": "Draft of evaluation guidelines for empirical studies in software\n  engineering involving LLMs (see also llm-guidelines.org)", "summary": "Large language models (LLMs) are increasingly being integrated into software\nengineering (SE) research and practice, yet their non-determinism, opaque\ntraining data, and evolving architectures complicate the reproduction and\nreplication of empirical studies. We present a community effort to scope this\nspace, introducing a taxonomy of LLM-based study types together with eight\nguidelines for designing and reporting empirical studies involving LLMs. The\nguidelines present essential (must) criteria as well as desired (should)\ncriteria and target transparency throughout the research process. Our\nrecommendations, contextualized by our study types, are: (1) to declare LLM\nusage and role; (2) to report model versions, configurations, and fine-tuning;\n(3) to document tool architectures; (4) to disclose prompts and interaction\nlogs; (5) to use human validation; (6) to employ an open LLM as a baseline; (7)\nto report suitable baselines, benchmarks, and metrics; and (8) to openly\narticulate limitations and mitigations. Our goal is to enable reproducibility\nand replicability despite LLM-specific barriers to open science. We maintain\nthe study types and guidelines online as a living resource for the community to\nuse and shape (llm-guidelines.org).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\u548c\u516b\u6761\u6307\u5357\uff0c\u4ee5\u63d0\u9ad8\u6d89\u53ca\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b9e\u8bc1\u7814\u7a76\u7684\u900f\u660e\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u7531\u4e8eLLM\u7684\u975e\u786e\u5b9a\u6027\u3001\u4e0d\u900f\u660e\u7684\u8bad\u7ec3\u6570\u636e\u548c\u4e0d\u65ad\u6f14\u53d8\u7684\u67b6\u6784\uff0c\u9700\u8981\u89e3\u51b3\u5176\u5728\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u590d\u73b0\u548c\u590d\u5236\u7684\u6311\u6218\u3002", "method": "\u5f15\u5165LLM\u7814\u7a76\u7c7b\u578b\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u51fa\u516b\u6761\u8bbe\u8ba1\u6307\u5357\uff0c\u6db5\u76d6\u900f\u660e\u5ea6\u3001\u6a21\u578b\u914d\u7f6e\u3001\u9a8c\u8bc1\u7b49\u65b9\u9762\u3002", "result": "\u5236\u5b9a\u4e86\u4e00\u5957\u652f\u6301\u7814\u7a76\u900f\u660e\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u7684\u5177\u4f53\u6307\u5357\uff0c\u5e76\u5728\u7ebf\u63d0\u4f9b\u4f5c\u4e3a\u6301\u7eed\u66f4\u65b0\u7684\u8d44\u6e90\u3002", "conclusion": "\u901a\u8fc7\u660e\u786e\u6307\u5357\u548c\u5206\u7c7b\u6cd5\uff0c\u5e2e\u52a9\u793e\u533a\u514b\u670dLLM\u7814\u7a76\u7684\u590d\u73b0\u969c\u788d\uff0c\u63a8\u52a8\u5f00\u653e\u79d1\u5b66\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.14931", "pdf": "https://arxiv.org/pdf/2508.14931", "abs": "https://arxiv.org/abs/2508.14931", "authors": ["Zahra TehraniNasab", "Amar Kumar", "Tal Arbel"], "title": "Pixels Under Pressure: Exploring Fine-Tuning Paradigms for Foundation Models in High-Resolution Medical Imaging", "categories": ["eess.IV", "cs.GR"], "comment": null, "summary": "Advancements in diffusion-based foundation models have improved text-to-image\ngeneration, yet most efforts have been limited to low-resolution settings. As\nhigh-resolution image synthesis becomes increasingly essential for various\napplications, particularly in medical imaging domains, fine-tuning emerges as a\ncrucial mechanism for adapting these powerful pre-trained models to\ntask-specific requirements and data distributions. In this work, we present a\nsystematic study, examining the impact of various fine-tuning techniques on\nimage generation quality when scaling to high resolution 512x512 pixels. We\nbenchmark a diverse set of fine-tuning methods, including full fine-tuning\nstrategies and parameter-efficient fine-tuning (PEFT). We dissect how different\nfine-tuning methods influence key quality metrics, including Fr\\'echet\nInception Distance (FID), Vendi score, and prompt-image alignment. We also\nevaluate the utility of generated images in a downstream classification task\nunder data-scarce conditions, demonstrating that specific fine-tuning\nstrategies improve both generation fidelity and downstream performance when\nsynthetic images are used for classifier training and evaluation on real\nimages. Our code is accessible through the project website -\nhttps://tehraninasab.github.io/PixelUPressure/.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u9ad8\u5206\u8fa8\u7387\uff08512x512\u50cf\u7d20\uff09\u56fe\u50cf\u751f\u6210\u4e2d\uff0c\u4e0d\u540c\u5fae\u8c03\u6280\u672f\u5bf9\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u533b\u5b66\u5f71\u50cf\u7b49\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u57fa\u7840\u6a21\u578b\u5728\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u591a\u9650\u4e8e\u4f4e\u5206\u8fa8\u7387\u3002\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u5728\u533b\u5b66\u5f71\u50cf\u7b49\u9886\u57df\u9700\u6c42\u589e\u52a0\uff0c\u9700\u901a\u8fc7\u5fae\u8c03\u9002\u5e94\u4efb\u52a1\u9700\u6c42\u548c\u6570\u636e\u5206\u5e03\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u5fae\u8c03\u65b9\u6cd5\uff08\u5305\u62ec\u5168\u5fae\u8c03\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff09\uff0c\u5206\u6790\u5176\u5bf9FID\u3001Vendi\u5206\u6570\u548c\u63d0\u793a-\u56fe\u50cf\u5bf9\u9f50\u7b49\u6307\u6807\u7684\u5f71\u54cd\uff0c\u5e76\u6d4b\u8bd5\u751f\u6210\u56fe\u50cf\u5728\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u7684\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u6548\u7528\u3002", "result": "\u67d0\u4e9b\u5fae\u8c03\u7b56\u7565\u63d0\u9ad8\u4e86\u751f\u6210\u56fe\u50cf\u7684\u4fdd\u771f\u5ea6\uff0c\u5e76\u6539\u5584\u4e86\u5728\u5408\u6210\u56fe\u50cf\u7528\u4e8e\u5206\u7c7b\u5668\u8bad\u7ec3\u548c\u771f\u5b9e\u56fe\u50cf\u8bc4\u4f30\u65f6\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "\u5fae\u8c03\u6280\u672f\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u7279\u5b9a\u7684\u5fae\u8c03\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u751f\u6210\u8d28\u91cf\u548c\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2508.15601", "pdf": "https://arxiv.org/pdf/2508.15601", "abs": "https://arxiv.org/abs/2508.15601", "authors": ["Li Zhang", "Youhe Jiang", "Guoliang He", "Xin Chen", "Han Lv", "Qian Yao", "Fangcheng Fu", "Kai Chen"], "title": "Efficient Mixed-Precision Large Language Model Inference with TurboMind", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "Mixed-precision inference techniques reduce the memory and computational\ndemands of Large Language Models (LLMs) by applying hybrid precision formats to\nmodel weights, activations, and KV caches. This work introduces mixed-precision\nLLM inference techniques that encompass (i) systematic memory and compute\noptimization across hierarchical storage and tensor core architectures, and\n(ii) comprehensive end-to-end mixed-precision optimization across diverse\nprecision formats and hardware configurations. Our approach features two novel\nmixed-precision pipelines designed for optimal hardware utilization: a General\nMatrix Multiply (GEMM) pipeline that optimizes matrix operations through\noffline weight packing and online acceleration, and an attention pipeline that\nenables efficient attention computation with arbitrary Query, Key, and Value\nprecision combinations. The key implementation of the pipelines includes (i)\nhardware-aware weight packing for automatic format optimization, (ii) adaptive\nhead alignment for efficient attention computation, (iii) instruction-level\nparallelism for memory hierarchy exploitation, and (iv) KV memory loading\npipeline for enhanced inference efficiency. We conduct comprehensive\nevaluations across 16 popular LLMs and 4 representative GPU architectures.\nResults demonstrate that our approach achieves up to 61% lower serving latency\n(30% on average) and up to 156% higher throughput (58% on average) in\nmixed-precision workloads compared to existing mixed-precision frameworks,\nestablishing consistent performance improvements across all tested\nconfigurations and hardware types. This work is integrated into TurboMind, a\nhigh-performance inference engine of the LMDeploy project, which is\nopen-sourced and publicly available at https://github.com/InternLM/lmdeploy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u7cbe\u5ea6LLM\u63a8\u7406\u6280\u672f\uff0c\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u7814\u7a76\u6df7\u5408\u7cbe\u5ea6\u63a8\u7406\u6280\u672f\uff0c\u4f18\u5316\u786c\u4ef6\u5229\u7528\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u65b0\u7ba1\u9053\uff1aGEMM\u7ba1\u9053\u548c\u6ce8\u610f\u529b\u7ba1\u9053\uff0c\u652f\u6301\u79bb\u7ebf\u6743\u91cd\u6253\u5305\u4e0e\u5728\u7ebf\u52a0\u901f\uff0c\u4ee5\u53ca\u4efb\u610f\u7cbe\u5ea6\u7ec4\u5408\u7684\u9ad8\u6548\u6ce8\u610f\u529b\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u572816\u79cdLLM\u548c4\u79cdGPU\u67b6\u6784\u4e0a\uff0c\u5e73\u5747\u964d\u4f4e30%\u5ef6\u8fdf\uff0c\u63d0\u534758%\u541e\u5410\u91cf\u3002", "conclusion": "\u8be5\u6280\u672f\u5df2\u96c6\u6210\u5230\u5f00\u6e90\u9879\u76eeTurboMind\u4e2d\uff0c\u4e3a\u6df7\u5408\u7cbe\u5ea6\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15157", "pdf": "https://arxiv.org/pdf/2508.15157", "abs": "https://arxiv.org/abs/2508.15157", "authors": ["David M Kahn", "Jan Hoffmann", "Runming Li"], "title": "Big-Stop Semantics: A Simple Way to Get the Benefits of Small-Step Semantics in a Big-Step Judgment", "categories": ["cs.PL"], "comment": "26 pages, 27 figures", "summary": "As evident in the programming language literature, many practitioners favor\nspecifying dynamic program behavior using big-step over small-step semantics.\nUnlike small-step semantics, which must dwell on every intermediate program\nstate, big-step semantics conveniently jump directly to the ever-important\nresult of the computation. Big-step semantics also typically involve fewer\ninference rules than their small-step counterparts. However, in exchange for\nergonomics, big-step semantics give up power: Small-step semantics describes\nprogram behaviors that are outside the grasp of big-step semantics, notably\ndivergence. This work presents a little-known extension of big-step semantics\nwith inductive definitions that captures diverging computations without\nintroducing error states. This big-stop semantics is illustrated for typed,\nuntyped, and effectful variants of PCF, as well as a while-loop-based\nimperative language. Big-stop semantics extends the standard big-step inference\nrules with a few additional rules to define an evaluation judgment that is\nequivalent to the reflexive-transitive closure of small-step transitions. This\nsimple extension contrasts with other solutions in the literature which\nsacrifice ergonomics by introducing many additional inference rules, global\nstate, and/or less-commonly-understood reasoning principles like coinduction.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9c9c\u4e3a\u4eba\u77e5\u7684\u5927\u6b65\u8bed\u4e49\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f52\u7eb3\u5b9a\u4e49\u6355\u83b7\u53d1\u6563\u8ba1\u7b97\uff0c\u65e0\u9700\u5f15\u5165\u9519\u8bef\u72b6\u6001\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u53d8\u4f53\u3002", "motivation": "\u5927\u6b65\u8bed\u4e49\u5728\u7f16\u7a0b\u8bed\u8a00\u4e2d\u56e0\u5176\u7b80\u6d01\u6027\u548c\u76f4\u63a5\u6027\u53d7\u5230\u9752\u7750\uff0c\u4f46\u65e0\u6cd5\u63cf\u8ff0\u53d1\u6563\u8ba1\u7b97\uff1b\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7b80\u5355\u6269\u5c55\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u79f0\u4e3a'big-stop'\u8bed\u4e49\u7684\u6269\u5c55\uff0c\u901a\u8fc7\u5c11\u91cf\u989d\u5916\u89c4\u5219\u5b9a\u4e49\u7b49\u4ef7\u4e8e\u5c0f\u6b65\u8bed\u4e49\u4f20\u9012\u95ed\u5305\u7684\u8bc4\u4f30\u5224\u65ad\uff0c\u907f\u514d\u590d\u6742\u7684\u9644\u52a0\u89c4\u5219\u6216\u5168\u5c40\u72b6\u6001\u3002", "result": "\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u7c7b\u578b\u5316\u3001\u975e\u7c7b\u578b\u5316\u548c\u5e26\u6548\u5e94\u7684PCF\u4ee5\u53ca\u57fa\u4e8ewhile\u5faa\u73af\u7684\u547d\u4ee4\u5f0f\u8bed\u8a00\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "big-stop\u8bed\u4e49\u5728\u4fdd\u6301\u5927\u6b65\u8bed\u4e49\u7b80\u6d01\u6027\u7684\u540c\u65f6\uff0c\u6709\u6548\u6355\u83b7\u4e86\u53d1\u6563\u8ba1\u7b97\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u7b80\u5355\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.15454", "pdf": "https://arxiv.org/pdf/2508.15454", "abs": "https://arxiv.org/abs/2508.15454", "authors": ["Saar Tzour-Shaday", "Dana Drachsler Cohen"], "title": "Mini-Batch Robustness Verification of Deep Neural Networks", "categories": ["cs.LG", "cs.LO", "cs.PL"], "comment": "30 pages, 12 figures, conference OOPSLA 2025", "summary": "Neural network image classifiers are ubiquitous in many safety-critical\napplications. However, they are susceptible to adversarial attacks. To\nunderstand their robustness to attacks, many local robustness verifiers have\nbeen proposed to analyze $\\epsilon$-balls of inputs. Yet, existing verifiers\nintroduce a long analysis time or lose too much precision, making them less\neffective for a large set of inputs. In this work, we propose a new approach to\nlocal robustness: group local robustness verification. The key idea is to\nleverage the similarity of the network computations of certain $\\epsilon$-balls\nto reduce the overall analysis time. We propose BaVerLy, a sound and complete\nverifier that boosts the local robustness verification of a set of\n$\\epsilon$-balls by dynamically constructing and verifying mini-batches.\nBaVerLy adaptively identifies successful mini-batch sizes, accordingly\nconstructs mini-batches of $\\epsilon$-balls that have similar network\ncomputations, and verifies them jointly. If a mini-batch is verified, all\n$\\epsilon$-balls are proven robust. Otherwise, one $\\epsilon$-ball is suspected\nas not being robust, guiding the refinement. In the latter case, BaVerLy\nleverages the analysis results to expedite the analysis of that $\\epsilon$-ball\nas well as the other $\\epsilon$-balls in the batch. We evaluate BaVerLy on\nfully connected and convolutional networks for MNIST and CIFAR-10. Results show\nthat BaVerLy scales the common one by one verification by 2.3x on average and\nup to 4.1x, in which case it reduces the total analysis time from 24 hours to 6\nhours.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c40\u90e8\u9c81\u68d2\u6027\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u548c\u9a8c\u8bc1mini-batch\u6765\u63d0\u9ad8\u9a8c\u8bc1\u6548\u7387\uff0c\u5e73\u5747\u63d0\u901f2.3\u500d\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u56fe\u50cf\u5206\u7c7b\u5668\u6613\u53d7\u5bf9\u6297\u653b\u51fb\uff0c\u73b0\u6709\u9a8c\u8bc1\u5668\u5206\u6790\u65f6\u95f4\u957f\u6216\u7cbe\u5ea6\u4e0d\u8db3\u3002", "method": "\u63d0\u51faBaVerLy\u9a8c\u8bc1\u5668\uff0c\u5229\u7528\u7f51\u7edc\u8ba1\u7b97\u7684\u76f8\u4f3c\u6027\u52a8\u6001\u6784\u5efamini-batch\u8fdb\u884c\u8054\u5408\u9a8c\u8bc1\u3002", "result": "\u5728MNIST\u548cCIFAR-10\u4e0a\u6d4b\u8bd5\uff0c\u5e73\u5747\u63d0\u901f2.3\u500d\uff0c\u6700\u9ad84.1\u500d\u3002", "conclusion": "BaVerLy\u663e\u8457\u63d0\u5347\u4e86\u5c40\u90e8\u9c81\u68d2\u6027\u9a8c\u8bc1\u7684\u6548\u7387\u3002"}}
{"id": "2508.14996", "pdf": "https://arxiv.org/pdf/2508.14996", "abs": "https://arxiv.org/abs/2508.14996", "authors": ["Andrew C. Freeman", "Luke Reinkensmeyer"], "title": "\\textit{adder-viz}: Real-Time Visualization Software for Transcoding Event Video", "categories": ["cs.MM", "cs.CV", "cs.HC", "eess.IV"], "comment": "Accepted to the Open-Source Track at ACM Multimedia 2025", "summary": "Recent years have brought about a surge in neuromorphic ``event'' video\nresearch, primarily targeting computer vision applications. Event video eschews\nvideo frames in favor of asynchronous, per-pixel intensity samples. While much\nwork has focused on a handful of representations for specific event cameras,\nthese representations have shown limitations in flexibility, speed, and\ncompressibility. We previously proposed the unified AD{\\Delta}ER representation\nto address these concerns. This paper introduces numerous improvements to the\n\\textit{adder-viz} software for visualizing real-time event transcode processes\nand applications in-the-loop. The MIT-licensed software is available from a\ncentralized repository at\n\\href{https://github.com/ac-freeman/adder-codec-rs}{https://github.com/ac-freeman/adder-codec-rs}.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u5bf9AD\u0394ER\u8868\u793a\u6cd5\u7684\u6539\u8fdb\uff0c\u5e76\u63a8\u51fa\u4e86adder-viz\u8f6f\u4ef6\uff0c\u7528\u4e8e\u5b9e\u65f6\u4e8b\u4ef6\u8f6c\u7801\u8fc7\u7a0b\u7684\u53ef\u89c6\u5316\u3002", "motivation": "\u4f20\u7edf\u7684\u4e8b\u4ef6\u89c6\u9891\u8868\u793a\u6cd5\u5728\u7075\u6d3b\u6027\u3001\u901f\u5ea6\u548c\u538b\u7f29\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0cAD\u0394ER\u8868\u793a\u6cd5\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u6539\u8fdb\u7684AD\u0394ER\u8868\u793a\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u5f00\u6e90\u8f6f\u4ef6adder-viz\uff0c\u652f\u6301\u5b9e\u65f6\u4e8b\u4ef6\u8f6c\u7801\u8fc7\u7a0b\u7684\u53ef\u89c6\u5316\u3002", "result": "\u63d0\u4f9b\u4e86MIT\u8bb8\u53ef\u7684adder-viz\u8f6f\u4ef6\uff0c\u89e3\u51b3\u4e86\u4e8b\u4ef6\u89c6\u9891\u8868\u793a\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u516c\u5f00\u5728GitHub\u4e0a\u3002", "conclusion": "AD\u0394ER\u8868\u793a\u6cd5\u53ca\u5176\u76f8\u5173\u5de5\u5177\u4e3a\u4e8b\u4ef6\u89c6\u9891\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15268", "pdf": "https://arxiv.org/pdf/2508.15268", "abs": "https://arxiv.org/abs/2508.15268", "authors": ["Gaosheng Zhao", "Dong In Kim"], "title": "Toward Autonomous Digital Populations for Communication-Sensing-Computation Ecosystem", "categories": ["cs.NI"], "comment": null, "summary": "Future communication networks are expected to achieve deep integration of\ncommunication, sensing, and computation, forming a tightly coupled and\nautonomously operating infrastructure system. However, current reliance on\ncentralized control, static design, and human intervention continues to\nconstrain the multidimensional evolution of network functions and applications,\nlimiting adaptability and resilience in large-scale, layered, and complex\nenvironments. To address these challenges, this paper proposes a\nnature-inspired architectural framework that leverages digital twin technology\nto organize connected devices at the edge into functional digital populations,\nwhile enabling the emergence of an evolvable digital ecosystem through\nmulti-population integration at the cloud. We believe that this framework,\nwhich combines engineering methodologies with sociotechnical insights, lays the\ntheoretical foundation for building next-generation communication networks with\ndynamic coordination, distributed decision-making, continuous adaptation, and\nevolutionary capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u7136\u542f\u53d1\u7684\u67b6\u6784\u6846\u67b6\uff0c\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u7ec4\u7ec7\u8fb9\u7f18\u8bbe\u5907\u4e3a\u529f\u80fd\u6570\u5b57\u7fa4\u4f53\uff0c\u5e76\u901a\u8fc7\u591a\u7fa4\u4f53\u4e91\u96c6\u6210\u6784\u5efa\u53ef\u6f14\u5316\u7684\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u7f51\u7edc\u4f9d\u8d56\u96c6\u4e2d\u63a7\u5236\u3001\u9759\u6001\u8bbe\u8ba1\u548c\u4eba\u5de5\u5e72\u9884\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u3001\u5206\u5c42\u548c\u590d\u6742\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u5f39\u6027\u3002", "method": "\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\u6280\u672f\uff0c\u7ec4\u7ec7\u8fb9\u7f18\u8bbe\u5907\u4e3a\u529f\u80fd\u6570\u5b57\u7fa4\u4f53\uff0c\u5e76\u5728\u4e91\u7aef\u5b9e\u73b0\u591a\u7fa4\u4f53\u96c6\u6210\u3002", "result": "\u63d0\u51fa\u4e00\u79cd\u52a8\u6001\u534f\u8c03\u3001\u5206\u5e03\u5f0f\u51b3\u7b56\u3001\u6301\u7eed\u9002\u5e94\u548c\u5177\u5907\u8fdb\u5316\u80fd\u529b\u7684\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6784\u5efa\u5177\u5907\u52a8\u6001\u6f14\u5316\u548c\u9002\u5e94\u80fd\u529b\u7684\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.15146", "pdf": "https://arxiv.org/pdf/2508.15146", "abs": "https://arxiv.org/abs/2508.15146", "authors": ["Longfei Chen", "Shenghan Gao", "Shiwei Wang", "Ken Lin", "Yun Wang", "Quan Li"], "title": "QueryGenie: Making LLM-Based Database Querying Transparent and Controllable", "categories": ["cs.HC"], "comment": "Accepted by The 38th Annual ACM Symposium on User Interface Software\n  and Technology (UIST Adjunct '25), September 28-October 1, 2025, Busan,\n  Republic of Korea", "summary": "Conversational user interfaces powered by large language models (LLMs) have\nsignificantly lowered the technical barriers to database querying. However,\nexisting tools still encounter several challenges, such as misinterpretation of\nuser intent, generation of hallucinated content, and the absence of effective\nmechanisms for human feedback-all of which undermine their reliability and\npractical utility. To address these issues and promote a more transparent and\ncontrollable querying experience, we proposed QueryGenie, an interactive system\nthat enables users to monitor, understand, and guide the LLM-driven query\ngeneration process. Through incremental reasoning, real-time validation, and\nresponsive interaction mechanisms, users can iteratively refine query logic and\nensure alignment with their intent.", "AI": {"tldr": "QueryGenie\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3LLM\u9a71\u52a8\u7684\u6570\u636e\u5e93\u67e5\u8be2\u4e2d\u7684\u7528\u6237\u610f\u56fe\u8bef\u89e3\u3001\u5e7b\u89c9\u5185\u5bb9\u751f\u6210\u548c\u7f3a\u4e4f\u53cd\u9988\u673a\u5236\u7b49\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u65f6\u9a8c\u8bc1\u548c\u4ea4\u4e92\u5f0f\u63a7\u5236\u63d0\u5347\u67e5\u8be2\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5728\u6570\u636e\u5e93\u67e5\u8be2\u4e2d\u5b58\u5728\u7528\u6237\u610f\u56fe\u8bef\u89e3\u3001\u5e7b\u89c9\u5185\u5bb9\u751f\u6210\u548c\u7f3a\u4e4f\u53cd\u9988\u673a\u5236\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u5f00\u53d1\u4e86QueryGenie\u7cfb\u7edf\uff0c\u91c7\u7528\u589e\u91cf\u63a8\u7406\u3001\u5b9e\u65f6\u9a8c\u8bc1\u548c\u54cd\u5e94\u5f0f\u4ea4\u4e92\u673a\u5236\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u8fed\u4ee3\u4f18\u5316\u67e5\u8be2\u903b\u8f91\u5e76\u786e\u4fdd\u4e0e\u610f\u56fe\u4e00\u81f4\u3002", "result": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u63a7\u5236\u548c\u5b9e\u65f6\u9a8c\u8bc1\uff0c\u63d0\u5347\u4e86\u67e5\u8be2\u7684\u900f\u660e\u5ea6\u548c\u53ef\u63a7\u6027\u3002", "conclusion": "QueryGenie\u6709\u6548\u5730\u89e3\u51b3\u4e86LLM\u9a71\u52a8\u7684\u6570\u636e\u5e93\u67e5\u8be2\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u7528\u6237\u4f53\u9a8c\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.15545", "pdf": "https://arxiv.org/pdf/2508.15545", "abs": "https://arxiv.org/abs/2508.15545", "authors": ["Mingyang Yu", "Haorui Yang", "Donglin Wang", "Desheng Kong", "Ji Du", "Yulong Fu", "Jing Xu"], "title": "QVecOpt: An Efficient Storage and Computing Opti-mization Framework for Large-scale Quantum State Simulation", "categories": ["cs.ET"], "comment": null, "summary": "In response to the challenges in large-scale quantum state simulation on\nclassical computing platforms, including memory limits, frequent disk I/O, and\nhigh computational complexity, this study builds upon a previously proposed\nhierarchical storage-based quantum simulation system and introduces an\noptimization framework, the Quantum Vector Optimization Framework (QVecOpt).\nQVecOpt integrates four strategies: amplitude pairing, cache optimization,\nblock storage optimization, and parallel optimization. These collectively\nenhance state vector storage and computational scheduling. The amplitude\npairing mechanism locates relevant amplitude pairs via bitwise XOR, reducing\ntraversal complexity of single-qubit gates from $O(2^n)$ to $O(1)$. Cache\noptimization pre-allocates buffers and loads only required data, cutting disk\nI/O. Block storage optimization partitions the state vector for on-demand\nloading and local updates, reducing redundant access. Parallel optimization\ndistributes the state vector across nodes for collaborative computation,\nachieving near-linear speedup. Complexity analysis shows that, compared with\nhierarchical storage simulation, the method reduces state vector traversals for\nsingle-qubit gates from $2^n$ to 1, removing the main bottleneck. It also\nlowers computational and I/O complexity from $O(2^n)$ to $O(2^n/C)$ and\n$O(2^n/B)$. In simulations of 16-29 qubits, efficiency improves nearly tenfold,\nbreaking the memory bottleneck of existing tools and enabling high-bit quantum\ncircuit simulations beyond traditional methods. This work provides an\nefficient, scalable solution for classical simulation of large-scale quantum\ncomputation with significant academic and practical value.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u91cf\u5b50\u77e2\u91cf\u4f18\u5316\u6846\u67b6(QVecOpt)\uff0c\u901a\u8fc7\u56db\u79cd\u7b56\u7565\u4f18\u5316\u7ecf\u5178\u8ba1\u7b97\u5e73\u53f0\u4e0a\u7684\u5927\u89c4\u6a21\u91cf\u5b50\u6001\u6a21\u62df\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548cI/O\u590d\u6742\u5ea6\uff0c\u63d0\u5347\u4e86\u6a21\u62df\u6548\u7387\u3002", "motivation": "\u9488\u5bf9\u7ecf\u5178\u8ba1\u7b97\u5e73\u53f0\u4e0a\u5927\u89c4\u6a21\u91cf\u5b50\u6001\u6a21\u62df\u9762\u4e34\u7684\u5185\u5b58\u9650\u5236\u3001\u9891\u7e41\u78c1\u76d8I/O\u548c\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u7b49\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u4f18\u5316\u6846\u67b6\u3002", "method": "\u7ed3\u5408\u632f\u5e45\u914d\u5bf9\u3001\u7f13\u5b58\u4f18\u5316\u3001\u5757\u5b58\u50a8\u4f18\u5316\u548c\u5e76\u884c\u4f18\u5316\u56db\u79cd\u7b56\u7565\uff0c\u4f18\u5316\u72b6\u6001\u77e2\u91cf\u7684\u5b58\u50a8\u548c\u8ba1\u7b97\u8c03\u5ea6\u3002", "result": "\u76f8\u6bd4\u5206\u5c42\u5b58\u50a8\u6a21\u62df\uff0c\u8be5\u65b9\u6cd5\u5c06\u5355\u91cf\u5b50\u95e8\u7684\u72b6\u6001\u77e2\u91cf\u904d\u5386\u4ece2^n\u6b21\u964d\u81f31\u6b21\uff0c\u8ba1\u7b97\u548cI/O\u590d\u6742\u5ea6\u4eceO(2^n)\u964d\u81f3O(2^n/C)\u548cO(2^n/B)\uff0c16-29\u91cf\u5b50\u4f4d\u7684\u6a21\u62df\u6548\u7387\u63d0\u5347\u8fd1\u5341\u500d\u3002", "conclusion": "QVecOpt\u4e3a\u5927\u89c4\u6a21\u91cf\u5b50\u8ba1\u7b97\u7684\u7ecf\u5178\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u5b66\u672f\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.14917", "pdf": "https://arxiv.org/pdf/2508.14917", "abs": "https://arxiv.org/abs/2508.14917", "authors": ["Weichien Liao"], "title": "Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis", "categories": ["cs.AR", "cs.CV", "cs.DC", "eess.IV", "eess.SP", "physics.ins-det"], "comment": "FPGA-based denoising pipeline for PRISM-scale imaging. Real-time\n  frame subtraction and averaging via burst-mode AXI4 and DRAM buffering.\n  Benchmarked against CPU/GPU workflows; scalable across multi-bank FPGA setups", "summary": "High-throughput imaging workflows, such as Parallel Rapid Imaging with\nSpectroscopic Mapping (PRISM), generate data at rates that exceed conventional\nreal-time processing capabilities. We present a scalable FPGA-based\npreprocessing pipeline for real-time denoising, implemented via High-Level\nSynthesis (HLS) and optimized for DRAM-backed buffering. Our architecture\nperforms frame subtraction and averaging directly on streamed image data,\nminimizing latency through burst-mode AXI4 interfaces. The resulting kernel\noperates below the inter-frame interval, enabling inline denoising and reducing\ndataset size for downstream CPU/GPU analysis. Validated under PRISM-scale\nacquisition, this modular FPGA framework offers a practical solution for\nlatency-sensitive imaging workflows in spectroscopy and microscopy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u53ef\u6269\u5c55\u9884\u5904\u7406\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u5b9e\u65f6\u53bb\u566a\uff0c\u9002\u7528\u4e8e\u9ad8\u541e\u5410\u91cf\u6210\u50cf\u5de5\u4f5c\u6d41\u3002", "motivation": "\u9ad8\u541e\u5410\u91cf\u6210\u50cf\u5de5\u4f5c\u6d41\uff08\u5982PRISM\uff09\u751f\u6210\u7684\u6570\u636e\u901f\u7387\u8d85\u51fa\u4f20\u7edf\u5b9e\u65f6\u5904\u7406\u80fd\u529b\uff0c\u9700\u8981\u4f4e\u5ef6\u8fdf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u9ad8\u7ea7\u7efc\u5408\uff08HLS\uff09\u5b9e\u73b0\u7684FPGA\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7DRAM\u7f13\u51b2\u4f18\u5316\uff0c\u76f4\u63a5\u5bf9\u6d41\u5f0f\u56fe\u50cf\u6570\u636e\u8fdb\u884c\u5e27\u51cf\u6cd5\u548c\u5e73\u5747\u64cd\u4f5c\uff0c\u6700\u5c0f\u5316\u5ef6\u8fdf\u3002", "result": "\u8be5\u5185\u6838\u64cd\u4f5c\u65f6\u95f4\u4f4e\u4e8e\u5e27\u95f4\u9694\uff0c\u652f\u6301\u5b9e\u65f6\u53bb\u566a\u5e76\u51cf\u5c11\u4e0b\u6e38CPU/GPU\u5206\u6790\u7684\u6570\u636e\u96c6\u5927\u5c0f\uff0c\u5df2\u9a8c\u8bc1\u9002\u7528\u4e8ePRISM\u89c4\u6a21\u91c7\u96c6\u3002", "conclusion": "\u8fd9\u79cd\u6a21\u5757\u5316FPGA\u6846\u67b6\u4e3a\u5149\u8c31\u5b66\u548c\u663e\u5fae\u955c\u4e2d\u7684\u5ef6\u8fdf\u654f\u611f\u6210\u50cf\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15276", "pdf": "https://arxiv.org/pdf/2508.15276", "abs": "https://arxiv.org/abs/2508.15276", "authors": ["Zhongjun Ding", "Yin Lin", "Tianjing Zeng"], "title": "AmbiSQL: Interactive Ambiguity Detection and Resolution for Text-to-SQL", "categories": ["cs.DB", "cs.CL"], "comment": null, "summary": "Text-to-SQL systems translate natural language questions into SQL queries,\nproviding substantial value for non-expert users. While large language models\n(LLMs) show promising results for this task, they remain error-prone. Query\nambiguity has been recognized as a major obstacle for LLM-based Text-to-SQL\nsystems, leading to misinterpretation of user intent and inaccurate SQL\ngeneration. We demonstrate AmbiSQL, an interactive system that automatically\ndetects query ambiguities and guides users through intuitive multiple-choice\nquestions to clarify their intent. Our approach introduces a fine-grained\nambiguity taxonomy for identifying ambiguities that affect database element\nmapping and LLM reasoning, then incorporates user feedback to rewrite ambiguous\nquestions. Evaluation on an ambiguous query dataset shows that AmbiSQL achieves\n87.2% precision in ambiguity detection and improves SQL exact match accuracy by\n50% when integrated with Text-to-SQL systems. Our demonstration showcases the\nsignificant performance gains and highlights the system's practical usability.\nCode repo and demonstration are available at:\nhttps://github.com/JustinzjDing/AmbiSQL.", "AI": {"tldr": "AmbiSQL \u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u89e3\u51b3 Text-to-SQL \u4e2d\u7684\u67e5\u8be2\u6b67\u4e49\uff0c\u901a\u8fc7\u7528\u6237\u53cd\u9988\u63d0\u9ad8 SQL \u751f\u6210\u51c6\u786e\u6027\u3002", "motivation": "LLM \u5728 Text-to-SQL \u4efb\u52a1\u4e2d\u5b58\u5728\u8bef\u89e3\u7528\u6237\u610f\u56fe\u7684\u95ee\u9898\uff0c\u67e5\u8be2\u6b67\u4e49\u662f\u4e3b\u8981\u969c\u788d\u3002AmbiSQL \u65e8\u5728\u901a\u8fc7\u4ea4\u4e92\u5f0f\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ec6\u7c92\u5ea6\u6b67\u4e49\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u591a\u9009\u95ee\u9898\u5f15\u5bfc\u7528\u6237\u6f84\u6e05\u610f\u56fe\uff0c\u5e76\u5229\u7528\u53cd\u9988\u91cd\u5199\u6b67\u4e49\u95ee\u9898\u3002", "result": "\u5728\u6b67\u4e49\u68c0\u6d4b\u4e0a\u8fbe\u5230 87.2% \u7684\u7cbe\u786e\u5ea6\uff0cSQL \u751f\u6210\u51c6\u786e\u7387\u63d0\u5347 50%\u3002", "conclusion": "AmbiSQL \u663e\u8457\u63d0\u5347\u4e86 Text-to-SQL \u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.15484", "pdf": "https://arxiv.org/pdf/2508.15484", "abs": "https://arxiv.org/abs/2508.15484", "authors": ["Caterina Feletti", "Paola Flocchini", "Debasish Pattanayak", "Giuseppe Prencipe", "Nicola Santoro"], "title": "Universal Dancing by Luminous Robots under Sequential Schedulers", "categories": ["cs.DC"], "comment": null, "summary": "The Dancing problem requires a swarm of $n$ autonomous mobile robots to form\na sequence of patterns, aka perform a choreography. Existing work has proven\nthat some crucial restrictions on choreographies and initial configurations\n(e.g., on repetitions of patterns, periodicity, symmetries,\ncontractions/expansions) must hold so that the Dancing problem can be solved\nunder certain robot models. Here, we prove that these necessary constraints can\nbe dropped by considering the LUMI model (i.e., where robots are endowed with a\nlight whose color can be chosen from a constant-size palette) under the quite\nunexplored sequential scheduler. We formalize the class of Universal Dancing\nproblems which require a swarm of $n$ robots starting from any initial\nconfiguration to perform a (periodic or finite) sequence of arbitrary patterns,\nonly provided that each pattern consists of $n$ vertices (including\nmultiplicities). However, we prove that, to be solvable under LUMI, the length\nof the feasible choreographies is bounded by the compositions of $n$ into the\nnumber of colors available to the robots. We provide an algorithm solving the\nUniversal Dancing problem by exploiting the peculiar capability of sequential\nrobots to implement a distributed counter mechanism. Even assuming non-rigid\nmovements, our algorithm ensures spatial homogeneity of the performed\nchoreography.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728LUMI\u6a21\u578b\u548c\u987a\u5e8f\u8c03\u5ea6\u5668\u4e0b\u89e3\u51b3\u901a\u7528\u821e\u8e48\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u653e\u5bbd\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u5bf9\u6a21\u5f0f\u548c\u521d\u59cb\u914d\u7f6e\u7684\u9650\u5236\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u73b0\u6709\u821e\u8e48\u95ee\u9898\u4e2d\u5bf9\u6a21\u5f0f\u548c\u521d\u59cb\u914d\u7f6e\u7684\u4e25\u683c\u9650\u5236\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86LUMI\u6a21\u578b\u548c\u987a\u5e8f\u8c03\u5ea6\u5668\uff0c\u5229\u7528\u673a\u5668\u4eba\u643a\u5e26\u7684\u5149\u4fe1\u53f7\uff08\u989c\u8272\uff09\u548c\u5206\u5e03\u5f0f\u8ba1\u6570\u673a\u5236\u6765\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u89e3\u51b3\u901a\u7528\u821e\u8e48\u95ee\u9898\uff0c\u4e14\u5728\u975e\u521a\u6027\u8fd0\u52a8\u4e0b\u4fdd\u6301\u7a7a\u95f4\u540c\u8d28\u6027\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0cLUMI\u6a21\u578b\u548c\u987a\u5e8f\u8c03\u5ea6\u5668\u80fd\u591f\u653e\u5bbd\u73b0\u6709\u821e\u8e48\u95ee\u9898\u7684\u9650\u5236\u6761\u4ef6\uff0c\u4e3a\u901a\u7528\u821e\u8e48\u95ee\u9898\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15512", "pdf": "https://arxiv.org/pdf/2508.15512", "abs": "https://arxiv.org/abs/2508.15512", "authors": ["Markus Borg", "Martin Larsson", "Philip Breid", "Nadim Hagatulah"], "title": "QUPER-MAn: Benchmark-Guided Target Setting for Maintainability Requirements", "categories": ["cs.SE"], "comment": "Accepted at the 1st International Workshop on Responsible Software\n  Engineering", "summary": "Maintainable source code is essential for sustainable development in any\nsoftware organization. Unfortunately, many studies show that maintainability\noften receives less attention than its importance warrants. We argue that\nrequirements engineering can address this gap the problem by fostering\ndiscussions and setting appropriate targets in a responsible manner. In this\npreliminary work, we conducted an exploratory study of industry practices\nrelated to requirements engineering for maintainability. Our findings confirm\nprevious studies: maintainability remains a second-class quality concern.\nExplicit requirements often make sweeping references to coding conventions.\nTools providing maintainability proxies are common but typically only used in\nimplicit requirements related to engineering practices. To address this, we\npropose QUPER-MAn, a maintainability adaption of the QUPER model, which was\noriginally developed to help organizations set targets for performance\nrequirements. Developed using a design science approach, QUPER-MAn, integrates\nmaintainability benchmarks and supports target setting. We posit that it can\nshift maintainability from an overlooked development consequence to an actively\nmanaged goal driven by informed and responsible engineering decisions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faQUPER-MAn\u6a21\u578b\uff0c\u5c06\u53ef\u7ef4\u62a4\u6027\u4ece\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u7ba1\u7406\u7684\u76ee\u6807\uff0c\u901a\u8fc7\u9700\u6c42\u5de5\u7a0b\u89e3\u51b3\u53ef\u7ef4\u62a4\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u53ef\u7ef4\u62a4\u6027\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u9700\u6c42\u5de5\u7a0b\u63d0\u5347\u5176\u91cd\u8981\u6027\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86QUPER-MAn\u6a21\u578b\uff0c\u6574\u5408\u53ef\u7ef4\u62a4\u6027\u57fa\u51c6\u5e76\u652f\u6301\u76ee\u6807\u8bbe\u5b9a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53ef\u7ef4\u62a4\u6027\u4ecd\u662f\u6b21\u8981\u5173\u6ce8\u70b9\uff0c\u5de5\u5177\u4f7f\u7528\u4e5f\u4ec5\u9690\u542b\u6d89\u53ca\uff1bQUPER-MAn\u6709\u671b\u6539\u53d8\u8fd9\u4e00\u73b0\u72b6\u3002", "conclusion": "QUPER-MAn\u6a21\u578b\u80fd\u901a\u8fc7\u9700\u6c42\u5de5\u7a0b\u4e3b\u52a8\u7ba1\u7406\u53ef\u7ef4\u62a4\u6027\uff0c\u63a8\u52a8\u5176\u5728\u5f00\u53d1\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.15047", "pdf": "https://arxiv.org/pdf/2508.15047", "abs": "https://arxiv.org/abs/2508.15047", "authors": ["Yibo Liu", "Liam Shatzel", "Brandon Haworth", "Teseo Schneider"], "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions", "categories": ["cs.AI", "cs.GR"], "comment": null, "summary": "Animating and simulating crowds using an agent-based approach is a\nwell-established area where every agent in the crowd is individually controlled\nsuch that global human-like behaviour emerges. We observe that human navigation\nand movement in crowds are often influenced by complex social and environmental\ninteractions, driven mainly by language and dialogue. However, most existing\nwork does not consider these dimensions and leads to animations where\nagent-agent and agent-environment interactions are largely limited to steering\nand fixed higher-level goal extrapolation.\n  We propose a novel method that exploits large language models (LLMs) to\ncontrol agents' movement. Our method has two main components: a dialogue system\nand language-driven navigation. We periodically query agent-centric LLMs\nconditioned on character personalities, roles, desires, and relationships to\ncontrol the generation of inter-agent dialogue when necessitated by the spatial\nand social relationships with neighbouring agents. We then use the conversation\nand each agent's personality, emotional state, vision, and physical state to\ncontrol the navigation and steering of each agent. Our model thus enables\nagents to make motion decisions based on both their perceptual inputs and the\nongoing dialogue.\n  We validate our method in two complex scenarios that exemplify the interplay\nbetween social interactions, steering, and crowding. In these scenarios, we\nobserve that grouping and ungrouping of agents automatically occur.\nAdditionally, our experiments show that our method serves as an\ninformation-passing mechanism within the crowd. As a result, our framework\nproduces more realistic crowd simulations, with emergent group behaviours\narising naturally from any environmental setting.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a7\u5236\u4eba\u7fa4\u52a8\u753b\u4e2d\u4ee3\u7406\u8fd0\u52a8\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u5bfc\u822a\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u57fa\u4e8e\u793e\u4ea4\u4e92\u52a8\u548c\u611f\u77e5\u8f93\u5165\u505a\u51fa\u66f4\u81ea\u7136\u7684\u8fd0\u52a8\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u7fa4\u6a21\u62df\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u793e\u4ea4\u548c\u73af\u5883\u4e92\u52a8\u7684\u8bed\u8a00\u7ef4\u5ea6\u8003\u8651\uff0c\u5bfc\u81f4\u4ee3\u7406\u95f4\u4e92\u52a8\u5c40\u9650\u4e8e\u7b80\u5355\u7684\u907f\u969c\u548c\u76ee\u6807\u5bfc\u5411\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u5bfc\u822a\uff0c\u5229\u7528\u4ee3\u7406\u7684\u4e2a\u6027\u3001\u60c5\u611f\u72b6\u6001\u3001\u89c6\u89c9\u548c\u7269\u7406\u72b6\u6001\u63a7\u5236\u8fd0\u52a8\u548c\u5bf9\u8bdd\u751f\u6210\u3002", "result": "\u5728\u590d\u6742\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u89c2\u5bdf\u5230\u4ee3\u7406\u81ea\u52a8\u5206\u7ec4\u548c\u89e3\u7ec4\uff0c\u4e14\u6846\u67b6\u4ea7\u751f\u4e86\u66f4\u771f\u5b9e\u7684\u4eba\u7fa4\u6a21\u62df\u548c\u81ea\u7136\u6d8c\u73b0\u7684\u7fa4\u4f53\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408LLM\uff0c\u6846\u67b6\u80fd\u591f\u4ea7\u751f\u66f4\u81ea\u7136\u548c\u771f\u5b9e\u7684\u4eba\u7fa4\u6a21\u62df\uff0c\u793e\u4ea4\u4e92\u52a8\u548c\u7fa4\u4f53\u884c\u4e3a\u53ef\u4ee5\u4ece\u73af\u5883\u8bbe\u7f6e\u4e2d\u81ea\u7136\u6d8c\u73b0\u3002"}}
{"id": "2508.15166", "pdf": "https://arxiv.org/pdf/2508.15166", "abs": "https://arxiv.org/abs/2508.15166", "authors": ["Jingbo Wang", "Shashin Halalingaiah", "Weiyi Chen", "Chao Wang", "Isil Dillig"], "title": "Probabilistic Inference for Datalog with Correlated Inputs", "categories": ["cs.PL"], "comment": "Accepted for publication at OOPSLA 2025 (R2)", "summary": "Probabilistic extensions of logic programming languages, such as ProbLog,\nintegrate logical reasoning with probabilistic inference to evaluate\nprobabilities of output relations; however, prior work does not account for\npotential statistical correlations among input facts. This paper introduces\nPraline, a new extension to Datalog designed for precise probabilistic\ninference in the presence of (partially known) input correlations. We formulate\nthe inference task as a constrained optimization problem, where the solution\nyields sound and precise probability bounds for output facts. However, due to\nthe complexity of the resulting optimization problem, this approach alone often\ndoes not scale to large programs. To address scalability, we propose a more\nefficient $\\delta$-exact inference algorithm that leverages constraint solving,\nstatic analysis, and iterative refinement. Our empirical evaluation on\nchallenging real-world benchmarks, including side-channel analysis,\ndemonstrates that our method not only scales effectively but also delivers\ntight probability bounds.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPraline\uff0c\u4e00\u79cd\u6269\u5c55\u7684Datalog\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u8f93\u5165\u76f8\u5173\u6027\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u548c\u9ad8\u6548\u7b97\u6cd5\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u7cbe\u786e\u6982\u7387\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\u6982\u7387\u6269\u5c55\uff08\u5982ProbLog\uff09\u672a\u8003\u8651\u8f93\u5165\u4e8b\u5b9e\u95f4\u7684\u7edf\u8ba1\u76f8\u5173\u6027\uff0c\u9650\u5236\u4e86\u63a8\u7406\u7684\u51c6\u786e\u6027\u3002", "method": "\u5c06\u63a8\u7406\u4efb\u52a1\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u03b4-\u51c6\u786e\u63a8\u7406\u7b97\u6cd5\uff0c\u7ed3\u5408\u7ea6\u675f\u6c42\u89e3\u3001\u9759\u6001\u5206\u6790\u548c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982\u4fa7\u4fe1\u9053\u5206\u6790\uff09\u4e2d\u4e0d\u4ec5\u53ef\u6269\u5c55\uff0c\u8fd8\u80fd\u63d0\u4f9b\u7d27\u81f4\u7684\u6982\u7387\u754c\u9650\u3002", "conclusion": "Praline\u89e3\u51b3\u4e86\u8f93\u5165\u76f8\u5173\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u9ad8\u6548\u7b97\u6cd5\u5b9e\u73b0\u4e86\u7cbe\u786e\u4e14\u53ef\u6269\u5c55\u7684\u6982\u7387\u63a8\u7406\u3002"}}
{"id": "2508.15398", "pdf": "https://arxiv.org/pdf/2508.15398", "abs": "https://arxiv.org/abs/2508.15398", "authors": ["Takahiro Matsumoto", "Masafumi Suzuki", "Mariko Yamaguchi", "Masakatsu Aoki", "Shunsuke Konagai", "Kazuhiko Murasaki"], "title": "A Low-Latency 3D Live Remote Visualization System for Tourist Sites Integrating Dynamic and Pre-captured Static Point Clouds", "categories": ["cs.MM", "I.3.7"], "comment": "3 pages, 4 figures, submitted to IEEE ISMAR 2025 Posters", "summary": "Various real-time methods for capturing and transmitting dynamic 3D spaces\nhave been proposed, including those based on RGB-D cameras and volumetric\ncapture. However, applying existing methods to outdoor tourist sites remains\ndifficult because maintenance and aesthetic constraints limit sensor placement,\nand daylight variability complicates processing. We propose a system that\ncombines multiple LiDARs and cameras for live dynamic point cloud capture, and\nintegrates them with pre-captured static point clouds for wide-area 3D\nvisualization. The system sustains 30 fps across wide-area scenes while keeping\nlatency below 100 ms. To mitigate lighting inconsistencies, static point-cloud\ncolors are automatically adjusted to current lighting. The effectiveness of our\nsystem is demonstrated through real-world deployment in a tourist site.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LiDAR\u548c\u6444\u50cf\u5934\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b9e\u65f6\u52a8\u6001\u70b9\u4e91\u6355\u83b7\uff0c\u5e76\u901a\u8fc7\u9884\u6355\u83b7\u9759\u6001\u70b9\u4e91\u6574\u5408\u5b9e\u73b0\u5e7f\u57df3D\u53ef\u89c6\u5316\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6237\u5916\u666f\u70b9\u5e94\u7528\u53d7\u9650\uff0c\u56e0\u4f20\u611f\u5668\u5e03\u5c40\u548c\u65e5\u5149\u53d8\u5316\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u591aLiDAR\u548c\u6444\u50cf\u5934\uff0c\u52a8\u6001\u8c03\u6574\u9759\u6001\u70b9\u4e91\u989c\u8272\u4ee5\u9002\u5e94\u5149\u7167\u53d8\u5316\u3002", "result": "\u7cfb\u7edf\u5728\u5e7f\u57df\u573a\u666f\u4e2d\u4fdd\u630130 fps\uff0c\u5ef6\u8fdf\u4f4e\u4e8e100 ms\uff0c\u5e76\u5728\u5b9e\u9645\u666f\u70b9\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u6237\u5916\u666f\u70b93D\u5b9e\u65f6\u6355\u83b7\u7684\u6311\u6218\u3002"}}
{"id": "2508.15307", "pdf": "https://arxiv.org/pdf/2508.15307", "abs": "https://arxiv.org/abs/2508.15307", "authors": ["Xiangtong Wang", "Wei Li", "Menglong Yang", "Songchen Han"], "title": "Unlocking the Performance Potential of Mega-Constellation Networks: An Exploration of Structure-Building Paradigms", "categories": ["cs.NI"], "comment": null, "summary": "The network structure design plays a vital role in the mega-constellation\nnetwork (MSN) to coordinate massive network nodes to ensure the effectiveness\nand reliability of operations and services for future space wireless\ncommunications networks.\n  One of the critical issues in MCN is how to design an optimal network control\nstructure by configuring the most stable inter-satellite link (ISL) to achieve\nhigh available MCN within a limited average transmission delays.\n  To address this problem, this paper introduces a novel MCN structure design\nparadigm: Structure = Motif + Lattice (SML), which decouples MCN design into\nlocal motifs design and global lattices design. Specifically, we formulate the\nHigh-Availability and Low-Latency Mega-Constellation Design (HALLMD) problem,\naimed at maximizing ISL availability while minimizing the transmission latency.\nTo solve HALLMD, we propose SMLOP, a heuristic algorithm that efficiently finds\noptimal network structures in polynomial time. Experimental validation on four\npublic state-of-the-art constellations demonstrates significant improvements,\nincluding enhanced capacity by $5\\sim 18\\%$, increased throughput by $1\\sim\n12\\%$, reduced path stretch by $12\\sim 23\\%$, and Round-Trip Time (RTT) by\n$8\\sim 77\\%$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSML\u7684\u65b0\u578b\u5de8\u661f\u5ea7\u7f51\u7edc\u7ed3\u6784\u8bbe\u8ba1\u8303\u5f0f\uff0c\u901a\u8fc7\u89e3\u8026\u5c40\u90e8\u56fe\u6848\u548c\u5168\u5c40\u683c\u5b50\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u9ad8\u53ef\u7528\u6027\u548c\u4f4e\u5ef6\u8fdf\u7684\u7f51\u7edc\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u8bbe\u8ba1\u6700\u4f18\u7f51\u7edc\u63a7\u5236\u7ed3\u6784\u4ee5\u914d\u7f6e\u6700\u7a33\u5b9a\u7684\u661f\u95f4\u94fe\u8def\uff08ISL\uff09\uff0c\u5728\u6709\u9650\u5e73\u5747\u4f20\u8f93\u5ef6\u8fdf\u5185\u5b9e\u73b0\u9ad8\u53ef\u7528\u7684\u5de8\u661f\u5ea7\u7f51\u7edc\uff08MCN\uff09\u3002", "method": "\u63d0\u51faSML\u8303\u5f0f\uff0c\u5c06MCN\u8bbe\u8ba1\u89e3\u8026\u4e3a\u5c40\u90e8\u56fe\u6848\u8bbe\u8ba1\u548c\u5168\u5c40\u683c\u5b50\u8bbe\u8ba1\uff0c\u5e76\u5f00\u53d1\u4e86\u542f\u53d1\u5f0f\u7b97\u6cd5SMLOP\u6765\u9ad8\u6548\u6c42\u89e3\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0cSMLOP\u7b97\u6cd5\u5728\u56db\u79cd\u5148\u8fdb\u661f\u5ea7\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u80fd\u529b\uff085%~18%\uff09\u3001\u541e\u5410\u91cf\uff081%~12%\uff09\uff0c\u5e76\u51cf\u5c11\u4e86\u8def\u5f84\u62c9\u4f38\uff0812%~23%\uff09\u548c\u5f80\u8fd4\u65f6\u95f4\uff088%~77%\uff09\u3002", "conclusion": "SML\u8303\u5f0f\u53caSMLOP\u7b97\u6cd5\u4e3a\u5de8\u661f\u5ea7\u7f51\u7edc\u7684\u9ad8\u6548\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15148", "pdf": "https://arxiv.org/pdf/2508.15148", "abs": "https://arxiv.org/abs/2508.15148", "authors": ["Yuansong Xu", "Shuhao Zhang", "Yijie Fan", "Shaohan Shi", "Zhenhui Peng", "Quan Li"], "title": "ReviseMate: Exploring Contextual Support for Digesting STEM Paper Reviews", "categories": ["cs.HC"], "comment": "Appear in Proc. ACM Hum.-Comput. Interact., Vol. 9, No. 7, Article\n  CSCW321. Publication date: November 2025", "summary": "Effectively assimilating and integrating reviewer feedback is crucial for\nresearchers seeking to refine their papers and handle potential rebuttal phases\nin academic venues. However, traditional review digestion processes present\nchallenges such as time consumption, reading fatigue, and the requisite for\ncomprehensive analytical skills. Prior research on review analysis often\nprovides theoretical guidance with limited targeted support. Additionally,\ngeneral text comprehension tools overlook the intricate nature of\ncomprehensively understanding reviews and lack contextual assistance. To bridge\nthis gap, we formulated research questions to explore the authors' concerns and\nmethods for enhancing comprehension during the review digestion phase. Through\ninterviews and the creation of storyboards, we developed ReviseMate, an\ninteractive system designed to address the identified challenges. A controlled\nuser study (N=31) demonstrated the superiority of ReviseMate over baseline\nmethods, with positive feedback regarding user interaction. Subsequent field\ndeployment (N=6) further validated the effectiveness of ReviseMate in\nreal-world review digestion scenarios. These findings underscore the potential\nof interactive tools to significantly enhance the assimilation and integration\nof reviewer feedback during the manuscript review process.", "AI": {"tldr": "ReviseMate\u662f\u4e00\u79cd\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u65e8\u5728\u5e2e\u52a9\u7814\u7a76\u8005\u66f4\u9ad8\u6548\u5730\u6d88\u5316\u548c\u6574\u5408\u5ba1\u7a3f\u4eba\u53cd\u9988\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4f20\u7edf\u5ba1\u7a3f\u53cd\u9988\u6d88\u5316\u8fc7\u7a0b\u8017\u65f6\u957f\u3001\u6613\u75b2\u52b3\u4e14\u9700\u9ad8\u5206\u6790\u80fd\u529b\uff0c\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u9488\u5bf9\u6027\u652f\u6301\uff0c\u9700\u8981\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8bbf\u8c08\u548c\u6545\u4e8b\u677f\u8bbe\u8ba1\u5f00\u53d1ReviseMate\u7cfb\u7edf\uff0c\u5e76\u8fdb\u884c\u63a7\u5236\u7528\u6237\u7814\u7a76\uff08N=31\uff09\u548c\u5b9e\u5730\u90e8\u7f72\uff08N=6\uff09\u9a8c\u8bc1\u3002", "result": "ReviseMate\u5728\u7528\u6237\u7814\u7a76\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u5730\u90e8\u7f72\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u5176\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4ea4\u4e92\u5f0f\u5de5\u5177\uff08\u5982ReviseMate\uff09\u80fd\u663e\u8457\u63d0\u5347\u5ba1\u7a3f\u53cd\u9988\u7684\u6d88\u5316\u4e0e\u6574\u5408\u6548\u679c\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.15620", "pdf": "https://arxiv.org/pdf/2508.15620", "abs": "https://arxiv.org/abs/2508.15620", "authors": ["Valeriy A. Slipko", "Alon Ascoli", "Fernando Corinto", "Yuriy V. Pershin"], "title": "Low-Power Control of Resistance Switching Transitions in First-Order Memristors", "categories": ["cs.ET", "cond-mat.mes-hall"], "comment": null, "summary": "In many cases, the behavior of physical memristive devices can be relatively\nwell captured by using a single internal state variable. This study\ninvestigates the low-power control of first-order memristive devices to derive\nthe most energy-efficient protocols for programming their resistances. A unique\nyet general approach to optimizing the switching transitions in devices of this\nkind is introduced. For pedagogical purposes, without loss of generality, the\nproposed control paradigm is applied to a couple of differential algebraic\nequation sets for voltage-controlled devices, specifically Kvatinsky's Voltage\nThrEshold Adaptive Memristor mathematical description and Miranda's and Sune's\ndynamic balance model. It is demonstrated that, depending upon intrinsic\nphysical properties of the device, captured in the model formulas and parameter\nsetting, and upon constraints on programming time and voltages, the optimal\nprotocol for either of the two switching scenarios may require the application\nof a single square voltage pulse of height set to a certain level within the\nadmissible range across a fraction or entire given programming time interval,\nor of some more involved voltage stimulus of unique polarity, including\nanalogue continuous waveforms that can be approximated by trains of square\nvoltage pulses of different heights, over the entire programming time interval.\nThe practical implications of these research findings are significant, as the\ndevelopment of energy-efficient protocols to program memristive devices,\nresolving the so-called voltage-time dilemma in the device physics community,\nis a subject under intensive and extensive studies across the academic\ncommunity and industry.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u4e00\u9636\u5fc6\u963b\u5668\u4ef6\u5f00\u5173\u8f6c\u6362\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u65e8\u5728\u5f00\u53d1\u6700\u8282\u80fd\u7684\u7535\u963b\u7f16\u7a0b\u534f\u8bae\u3002\u901a\u8fc7\u9488\u5bf9\u4e24\u79cd\u7535\u538b\u63a7\u5236\u5668\u4ef6\u6a21\u578b\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u6839\u636e\u8bbe\u5907\u7279\u6027\u548c\u7ea6\u675f\u6761\u4ef6\u9009\u62e9\u6700\u4f18\u7535\u538b\u8109\u51b2\u7684\u7b56\u7565\u3002", "motivation": "\u5fc6\u963b\u5668\u4ef6\u7684\u4f4e\u529f\u8017\u63a7\u5236\u5728\u5b66\u672f\u548c\u5de5\u4e1a\u754c\u5907\u53d7\u5173\u6ce8\uff0c\u89e3\u51b3\u6240\u8c13\u7684\u201c\u7535\u538b-\u65f6\u95f4\u56f0\u5883\u201d\u662f\u7814\u7a76\u91cd\u70b9\u3002", "method": "\u91c7\u7528\u901a\u7528\u4f18\u5316\u65b9\u6cd5\uff0c\u9488\u5bf9\u4e24\u79cd\u7535\u538b\u63a7\u5236\u5fc6\u963b\u5668\u6a21\u578b\uff08Kvatinsky\u548cMiranda-Sune\u6a21\u578b\uff09\u5e94\u7528\u4e0d\u540c\u7535\u538b\u8109\u51b2\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6839\u636e\u8bbe\u5907\u7279\u6027\u548c\u7ea6\u675f\uff0c\u6700\u4f18\u7f16\u7a0b\u534f\u8bae\u53ef\u80fd\u662f\u5355\u4e00\u56fa\u5b9a\u7535\u538b\u8109\u51b2\u6216\u590d\u6742\u8fde\u7eed\u6ce2\u5f62\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5fc6\u963b\u5668\u4ef6\u8282\u80fd\u7f16\u7a0b\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u89e3\u51b3\u4e86\u201c\u7535\u538b-\u65f6\u95f4\u56f0\u5883\u201d\u3002"}}
{"id": "2508.15685", "pdf": "https://arxiv.org/pdf/2508.15685", "abs": "https://arxiv.org/abs/2508.15685", "authors": ["Kang Eun Jeon", "Sangheum Yeon", "Jinhee Kim", "Hyeonsu Bang", "Johnny Rhe", "Jong Hwan Ko"], "title": "Row-Column Hybrid Grouping for Fault-Resilient Multi-Bit Weight Representation on IMC Arrays", "categories": ["cs.AR", "cs.AI"], "comment": "Accepted to appear at ICCAD'25 (Munich, Germany)", "summary": "This paper addresses two critical challenges in analog In-Memory Computing\n(IMC) systems that limit their scalability and deployability: the computational\nunreliability caused by stuck-at faults (SAFs) and the high compilation\noverhead of existing fault-mitigation algorithms, namely Fault-Free (FF). To\novercome these limitations, we first propose a novel multi-bit weight\nrepresentation technique, termed row-column hybrid grouping, which generalizes\nconventional column grouping by introducing redundancy across both rows and\ncolumns. This structural redundancy enhances fault tolerance and can be\neffectively combined with existing fault-mitigation solutions. Second, we\ndesign a compiler pipeline that reformulates the fault-aware weight\ndecomposition problem as an Integer Linear Programming (ILP) task, enabling\nfast and scalable compilation through off-the-shelf solvers. Further\nacceleration is achieved through theoretical insights that identify fault\npatterns amenable to trivial solutions, significantly reducing computation.\nExperimental results on convolutional networks and small language models\ndemonstrate the effectiveness of our approach, achieving up to 8%p improvement\nin accuracy, 150x faster compilation, and 2x energy efficiency gain compared to\nexisting baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u591a\u6bd4\u7279\u6743\u91cd\u8868\u793a\u6280\u672f\u548c\u7f16\u8bd1\u5668\u6d41\u6c34\u7ebf\uff0c\u89e3\u51b3\u4e86\u6a21\u62df\u5185\u5b58\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u8ba1\u7b97\u4e0d\u53ef\u9760\u6027\u548c\u9ad8\u7f16\u8bd1\u5f00\u9500\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6a21\u62df\u5185\u5b58\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u56e0 stuck-at faults \u548c\u73b0\u6709\u6545\u969c\u7f13\u89e3\u7b97\u6cd5\u7684\u9ad8\u7f16\u8bd1\u5f00\u9500\u800c\u9650\u5236\u5176\u6269\u5c55\u548c\u90e8\u7f72\u7684\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u884c-\u5217\u6df7\u5408\u5206\u7ec4\u7684\u591a\u6bd4\u7279\u6743\u91cd\u8868\u793a\u6280\u672f\uff1b2. \u8bbe\u8ba1\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u7684\u7f16\u8bd1\u5668\u6d41\u6c34\u7ebf\u3002", "result": "\u5728\u5377\u79ef\u7f51\u7edc\u548c\u5c0f\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u4e868%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3001150\u500d\u7684\u7f16\u8bd1\u901f\u5ea6\u63d0\u5347\u548c2\u500d\u7684\u80fd\u6548\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5197\u4f59\u548c\u5feb\u901f\u7f16\u8bd1\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.15285", "pdf": "https://arxiv.org/pdf/2508.15285", "abs": "https://arxiv.org/abs/2508.15285", "authors": ["Chunyu Zhao", "Hongzhi Wang", "Kaixin Zhang", "Hongliang Li", "Yihan Zhang", "Jiawei Zhang", "Kunkai Gu", "Yuan Tian", "Xiangdong Huang", "Jingyi Xu"], "title": "Efficient Cloud-Edge-Device Query Execution Based on Collaborative Scan Operator", "categories": ["cs.DB", "C.2.4; H.2.4; D.2.11"], "comment": "12 pages, 23 figures. Submitted to IEEE Transactions on ICDE", "summary": "In cloud-edge-device (CED) collaborative query (CQ) processing, by leveraging\nCED collaboration, the advantages of both cloud computing and edge resources\ncan be fully integrated. However, it is difficult to implement collaborative\noperators that can flexibly switch between the cloud and the edge during query\nexecution. Thus, in this paper, we aim to improve the query performance when\nthe edge resources reach a bottleneck. To achieve seamless switching of query\nexecution between the cloud and edge, we propose a CQ processing method by\nestablishing a CED collaborative framework based on the collaborative scan\noperator, so that query execution can be transferred to the cloud at any time\nwhen the edge resources are saturated. Extensive experiments show that, under\nsufficient network download bandwidth, the CED collaborative scan operator can\neffectively alleviate the performance degradation of scan operators caused by\nhigh I/O load and CPU wait time at the edge. It also achieves balanced resource\nscheduling between the cloud and edge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e91\u8fb9\u7aef\u534f\u4f5c\u6846\u67b6\u7684\u67e5\u8be2\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u534f\u4f5c\u626b\u63cf\u7b97\u5b50\u5b9e\u73b0\u67e5\u8be2\u6267\u884c\u5728\u4e91\u7aef\u548c\u8fb9\u7f18\u4e4b\u95f4\u7684\u65e0\u7f1d\u5207\u6362\uff0c\u89e3\u51b3\u8fb9\u7f18\u8d44\u6e90\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u5728\u4e91\u8fb9\u7aef\u534f\u4f5c\u67e5\u8be2\u5904\u7406\u4e2d\uff0c\u5145\u5206\u5229\u7528\u4e91\u8ba1\u7b97\u7684\u7075\u6d3b\u6027\u548c\u8fb9\u7f18\u8d44\u6e90\u4f18\u52bf\uff0c\u4f46\u5728\u67e5\u8be2\u6267\u884c\u8fc7\u7a0b\u4e2d\u96be\u4ee5\u7075\u6d3b\u5207\u6362\u534f\u4f5c\u7b97\u5b50\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u534f\u4f5c\u626b\u63cf\u7b97\u5b50\u7684\u4e91\u8fb9\u7aef\u534f\u4f5c\u6846\u67b6\uff0c\u5b9e\u73b0\u5728\u8fb9\u7f18\u8d44\u6e90\u9971\u548c\u65f6\u968f\u65f6\u5c06\u67e5\u8be2\u6267\u884c\u8f6c\u79fb\u5230\u4e91\u7aef\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u8fb9\u7f18\u9ad8I/O\u8d1f\u8f7d\u548cCPU\u7b49\u5f85\u65f6\u95f4\u5bfc\u81f4\u7684\u626b\u63cf\u7b97\u5b50\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u5b9e\u73b0\u4e91\u8fb9\u8d44\u6e90\u5747\u8861\u8c03\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u4f5c\u626b\u63cf\u7b97\u5b50\u65b9\u6cd5\u63d0\u5347\u4e86\u67e5\u8be2\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u4e91\u8fb9\u7aef\u8d44\u6e90\u7684\u9ad8\u6548\u534f\u4f5c\u3002"}}
{"id": "2508.15562", "pdf": "https://arxiv.org/pdf/2508.15562", "abs": "https://arxiv.org/abs/2508.15562", "authors": ["Pierre Fraigniaud", "Minh Hang Nguyen", "Ami Paz", "Ulrich Schmid", "Hugo Rincon Galeana"], "title": "Lower Bounds for $k$-Set Agreement in Fault-Prone Networks", "categories": ["cs.DC"], "comment": "To be presented in DISC 2025", "summary": "We develop a new lower bound for k-set agreement in synchronous\nmessage-passing systems connected by an arbitrary directed communication\nnetwork, where up to t processes may crash. Our result thus generalizes the\nt/k+1 lower bound for complete networks in the t-resilient model by Chaudhuri,\nHerlihy, Lynch, and Tuttle [JACM'00]. Moreover, it generalizes two lower bounds\nfor oblivious algorithms in synchronous systems connected by an arbitrary\nundirected communication network known to the processes, namely, the domination\nnumber-based lower bound by Castaneda, Fraigniaud, Paz, Rajsbaum, Roy, and\nTravers [TCS'21] for failure-free processes, and the radius-based lower bound\nin the t-resilient model by Fraigniaud, Nguyen, and Paz [STACS'24].\n  Our topological proof non-trivially generalizes and extends the\nconnectivity-based approach for the complete network, as presented in the book\nby Herlihy, Kozlov, and Rajsbaum (2013). It is based on a sequence of shellable\ncarrier maps that, starting from a shellable input complex, determine the\nevolution of the protocol complex: During the first t/k rounds, carrier maps\nthat crash exactly k processes per round are used, ensuring high connectivity\nof their images. A Sperner's lemma style argument is used to prove that k-set\nagreement is still impossible by that round. From round t/k+1 up to our lower\nbound, we employ a novel carrier map that maintains high connectivity. Our\nproof also provides a strikingly simple lower bound for k-set agreement in\nsynchronous systems with an arbitrary communication network with initial\ncrashes. We express the resulting additional agreement overhead via an\nappropriately defined radius of the communication graphs. Finally, we prove\nthat the usual input pseudosphere complex for k-set agreement can be replaced\nby an exponentially smaller input complex based on Kuhn triangulations, which\nwe prove to be also shellable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u540c\u6b65\u6d88\u606f\u4f20\u9012\u7cfb\u7edf\u4e2dk-set\u534f\u8bae\u7684\u65b0\u4e0b\u754c\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u6709\u5411\u901a\u4fe1\u7f51\u7edc\uff0c\u5e76\u7ed3\u5408\u62d3\u6251\u65b9\u6cd5\u6269\u5c55\u4e86\u73b0\u6709\u7406\u8bba\u3002", "motivation": "\u65e8\u5728\u5c06\u5df2\u6709\u7684k-set\u534f\u8bae\u4e0b\u754c\u7406\u8bba\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u5305\u62ec\u6709\u5411\u901a\u4fe1\u7f51\u7edc\u548c\u4e0d\u540c\u6545\u969c\u6a21\u578b\u3002", "method": "\u91c7\u7528\u62d3\u6251\u8bc1\u660e\u65b9\u6cd5\uff0c\u901a\u8fc7Shellable carrier maps\u548cSperner\u5f15\u7406\u5206\u6790\u534f\u8bae\u590d\u6742\u6027\uff0c\u5e76\u7ed3\u5408\u65b0\u7684carrier map\u7ef4\u6301\u9ad8\u8fde\u901a\u6027\u3002", "result": "\u8bba\u6587\u4e0d\u4ec5\u6269\u5c55\u4e86\u73b0\u6709\u4e0b\u754c\uff0c\u8fd8\u63d0\u51fa\u4e86\u57fa\u4e8e\u901a\u4fe1\u56fe\u534a\u5f84\u7684\u9644\u52a0\u534f\u8bae\u5f00\u9500\uff0c\u5e76\u8bc1\u660e\u53ef\u4ee5\u4f7f\u7528\u66f4\u5c0f\u7684\u8f93\u5165\u590d\u5f62\u3002", "conclusion": "\u7814\u7a76\u4e3ak-set\u534f\u8bae\u5728\u66f4\u5e7f\u6cdb\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u7b80\u5316\u4e86\u90e8\u5206\u590d\u6742\u6027\u5206\u6790\u3002"}}
{"id": "2508.15536", "pdf": "https://arxiv.org/pdf/2508.15536", "abs": "https://arxiv.org/abs/2508.15536", "authors": ["Yi Zhang", "He Jiang", "Xiaochen Li", "Shikai Guo", "Peiyu Zou", "Zun Wang"], "title": "A Novel Mutation Based Method for Detecting FPGA Logic Synthesis Tool Bugs", "categories": ["cs.SE"], "comment": null, "summary": "FPGA (Field-Programmable Gate Array) logic synthesis tools are key components\nin the EDA (Electronic Design Automation) toolchain. They convert hardware\ndesigns written in description languages such as Verilog into gate-level\nrepresentations for FPGAs. However, defects in these tools may lead to\nunexpected behaviors and pose security risks. Therefore, it is crucial to\nharden these tools through testing. Although several methods have been proposed\nto automatically test FPGA logic synthesis tools, the challenge remains of\ninsufficient semantic and logical complexity in test programs. In this paper,\nwe propose VERMEI, a new method for testing FPGA logic synthesis tools. VERMEI\nconsists of three modules: preprocessing, equivalent mutation, and bug\nidentification. The preprocessing module identifies zombie logic (inactive code\nwith no impact on the circuit output) in seed programs through simulation and\ncoverage analysis. The equivalent mutation module generates equivalent variants\nof seed programs by pruning or inserting logic fragments in zombie areas. It\nuses Bayesian sampling to extract logic fragments from historical Verilog\ndesigns, making the generated variants have complex control flows and\nstructures. The bug identification module, based on differential testing,\ncompares the synthesized outputs of seed and variant programs to identify bugs.\nExperiments on Yosys, Vivado, and Quartus demonstrate that VERMEI outperforms\nthe state-of-the-art methods. Within five months, VERMEI reported 15 bugs to\nvendors, 9 of which were confirmed as new.", "AI": {"tldr": "VERMEI\u662f\u4e00\u79cd\u65b0\u7684FPGA\u903b\u8f91\u7efc\u5408\u5de5\u5177\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u5904\u7406\u3001\u7b49\u4ef7\u53d8\u5f02\u548c\u9519\u8bef\u8bc6\u522b\u4e09\u4e2a\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u679c\uff0c\u53d1\u73b0\u4e86\u591a\u4e2a\u65b0bug\u3002", "motivation": "FPGA\u903b\u8f91\u7efc\u5408\u5de5\u5177\u4e2d\u7684\u7f3a\u9677\u53ef\u80fd\u5bfc\u81f4\u610f\u5916\u884c\u4e3a\u548c\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u6d4b\u8bd5\u65b9\u6cd5\u5728\u6d4b\u8bd5\u7a0b\u5e8f\u7684\u8bed\u4e49\u548c\u903b\u8f91\u590d\u6742\u6027\u4e0a\u4e0d\u8db3\u3002", "method": "VERMEI\u5305\u542b\u9884\u5904\u7406\u3001\u7b49\u4ef7\u53d8\u5f02\u548c\u9519\u8bef\u8bc6\u522b\u4e09\u4e2a\u6a21\u5757\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u8986\u76d6\u5206\u6790\u8bc6\u522b\u50f5\u5c38\u903b\u8f91\uff0c\u5229\u7528\u8d1d\u53f6\u65af\u91c7\u6837\u751f\u6210\u590d\u6742\u53d8\u4f53\uff0c\u5e76\u901a\u8fc7\u5dee\u5206\u6d4b\u8bd5\u8bc6\u522b\u9519\u8bef\u3002", "result": "\u5728Yosys\u3001Vivado\u548cQuartus\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVERMEI\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e94\u4e2a\u6708\u5185\u62a5\u544a\u4e8615\u4e2abug\uff0c\u5176\u4e2d9\u4e2a\u4e3a\u65b0bug\u3002", "conclusion": "VERMEI\u662f\u4e00\u79cd\u6709\u6548\u7684FPGA\u903b\u8f91\u7efc\u5408\u5de5\u5177\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u9519\u8bef\u53d1\u73b0\u80fd\u529b\u3002"}}
{"id": "2508.15372", "pdf": "https://arxiv.org/pdf/2508.15372", "abs": "https://arxiv.org/abs/2508.15372", "authors": ["Xinshuang Liu", "Runfa Blark Li", "Keito Suzuki", "Truong Nguyen"], "title": "Image-Conditioned 3D Gaussian Splat Quantization", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has attracted considerable attention for\nenabling high-quality real-time rendering. Although 3DGS compression methods\nhave been proposed for deployment on storage-constrained devices, two\nlimitations hinder archival use: (1) they compress medium-scale scenes only to\nthe megabyte range, which remains impractical for large-scale scenes or\nextensive scene collections; and (2) they lack mechanisms to accommodate scene\nchanges after long-term archival. To address these limitations, we propose an\nImage-Conditioned Gaussian Splat Quantizer (ICGS-Quantizer) that substantially\nenhances compression efficiency and provides adaptability to scene changes\nafter archiving. ICGS-Quantizer improves quantization efficiency by jointly\nexploiting inter-Gaussian and inter-attribute correlations and by using shared\ncodebooks across all training scenes, which are then fixed and applied to\npreviously unseen test scenes, eliminating the overhead of per-scene codebooks.\nThis approach effectively reduces the storage requirements for 3DGS to the\nkilobyte range while preserving visual fidelity. To enable adaptability to\npost-archival scene changes, ICGS-Quantizer conditions scene decoding on images\ncaptured at decoding time. The encoding, quantization, and decoding processes\nare trained jointly, ensuring that the codes, which are quantized\nrepresentations of the scene, are effective for conditional decoding. We\nevaluate ICGS-Quantizer on 3D scene compression and 3D scene updating.\nExperimental results show that ICGS-Quantizer consistently outperforms\nstate-of-the-art methods in compression efficiency and adaptability to scene\nchanges. Our code, model, and data will be publicly available on GitHub.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u50cf\u6761\u4ef6\u5316\u7684\u9ad8\u65af\u6e85\u5c04\u91cf\u5316\u5668\uff08ICGS-Quantizer\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u7684\u538b\u7f29\u6548\u7387\uff0c\u5e76\u652f\u6301\u5b58\u6863\u540e\u7684\u573a\u666f\u53d8\u5316\u9002\u5e94\u3002", "motivation": "\u73b0\u67093DGS\u538b\u7f29\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u573a\u666f\u6216\u957f\u671f\u5b58\u6863\u540e\u7684\u573a\u666f\u53d8\u5316\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u8054\u5408\u5229\u7528\u9ad8\u65af\u95f4\u548c\u5c5e\u6027\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4ee5\u53ca\u8de8\u573a\u666f\u5171\u4eab\u7801\u672c\uff0cICGS-Quantizer\u63d0\u5347\u4e86\u91cf\u5316\u6548\u7387\uff1b\u540c\u65f6\u901a\u8fc7\u56fe\u50cf\u6761\u4ef6\u5316\u7684\u89e3\u7801\u673a\u5236\u9002\u5e94\u573a\u666f\u53d8\u5316\u3002", "result": "ICGS-Quantizer\u5c063DGS\u7684\u5b58\u50a8\u9700\u6c42\u964d\u4f4e\u81f3\u5343\u5b57\u8282\u7ea7\u522b\uff0c\u5e76\u5728\u538b\u7f29\u6548\u7387\u548c\u573a\u666f\u53d8\u5316\u9002\u5e94\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ICGS-Quantizer\u4e3a3DGS\u7684\u9ad8\u6548\u538b\u7f29\u548c\u957f\u671f\u5b58\u6863\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.15264", "pdf": "https://arxiv.org/pdf/2508.15264", "abs": "https://arxiv.org/abs/2508.15264", "authors": ["Patrick Redmond", "Jonathan Castello", "Jos\u00e9 Manuel Calder\u00f3n Trilla", "Lindsey Kuper"], "title": "Exploring the Theory and Practice of Concurrency in the Entity-Component-System Pattern", "categories": ["cs.PL"], "comment": "This is an extended version (with appendices) of the OOPSLA 2025\n  paper", "summary": "The Entity-Component-System (ECS) software design pattern, long used in game\ndevelopment, encourages a clean separation of identity (entities), data\nproperties (components), and computational behaviors (systems). Programs\nwritten using the ECS pattern are naturally concurrent, and the pattern offers\nmodularity, flexibility, and performance benefits that have led to a\nproliferation of ECS frameworks. Nevertheless, the ECS pattern is little-known\nand not well understood outside of a few domains. Existing explanations of the\nECS pattern tend to be mired in the concrete details of particular ECS\nframeworks, or they explain the pattern in terms of imperfect metaphors or in\nterms of what it is not. We seek a rigorous understanding of the ECS pattern\nvia the design of a formal model, Core ECS, that abstracts away the details of\nspecific implementations to reveal the essence of software using the ECS\npattern. We identify a class of Core ECS programs that behave deterministically\nregardless of scheduling, enabling use of the ECS pattern as a\ndeterministic-by-construction concurrent programming model. With Core ECS as a\npoint of comparison, we then survey several real-world ECS frameworks and find\nthat they all leave opportunities for deterministic concurrency unexploited.\nOur findings point out a space for new ECS implementation techniques that\nbetter leverage such opportunities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCore ECS\u7684\u6b63\u5f0f\u6a21\u578b\uff0c\u65e8\u5728\u62bd\u8c61ECS\u6a21\u5f0f\u7684\u672c\u8d28\uff0c\u5e76\u786e\u5b9a\u4e86\u4e00\u7c7b\u8c03\u5ea6\u65e0\u5173\u7684\u786e\u5b9a\u6027\u7a0b\u5e8f\uff0c\u4e3aECS\u6846\u67b6\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "ECS\u6a21\u5f0f\u5728\u6e38\u620f\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u6982\u5ff5\u5728\u9886\u57df\u5916\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\u3002\u73b0\u6709\u89e3\u91ca\u591a\u5c40\u9650\u4e8e\u5177\u4f53\u6846\u67b6\u6216\u6a21\u7cca\u9690\u55bb\uff0c\u7f3a\u4e4f\u4e25\u8c28\u7684\u62bd\u8c61\u6a21\u578b\u3002", "method": "\u8bbe\u8ba1Core ECS\u6a21\u578b\uff0c\u62bd\u8c61ECS\u6a21\u5f0f\u7684\u672c\u8d28\uff0c\u8bc6\u522b\u8c03\u5ea6\u65e0\u5173\u7684\u786e\u5b9a\u6027\u7a0b\u5e8f\u7c7b\uff0c\u5e76\u5bf9\u6bd4\u5206\u6790\u73b0\u6709ECS\u6846\u67b6\u3002", "result": "Core ECS\u63ed\u793a\u4e86ECS\u6a21\u5f0f\u7684\u672c\u8d28\uff0c\u53d1\u73b0\u73b0\u6709\u6846\u67b6\u672a\u5145\u5206\u5229\u7528\u786e\u5b9a\u6027\u5e76\u53d1\u7684\u673a\u4f1a\u3002", "conclusion": "\u7814\u7a76\u4e3aECS\u6846\u67b6\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u6307\u51fa\u4e86\u5b9e\u73b0\u786e\u5b9a\u6027\u5e76\u53d1\u7684\u6280\u672f\u7a7a\u95f4\u3002"}}
{"id": "2508.15595", "pdf": "https://arxiv.org/pdf/2508.15595", "abs": "https://arxiv.org/abs/2508.15595", "authors": ["Abhishek Dandekar", "Prashiddha D. Thapa", "Ashrafur Rahman", "Julius Schulz-Zander"], "title": "Interface on demand: Towards AI native Control interfaces for 6G", "categories": ["cs.NI"], "comment": null, "summary": "Traditional standardized network interfaces face significant limitations,\nincluding vendor-specific incompatibilities, rigid design assumptions, and lack\nof adaptability for new functionalities. We propose a multi-agent framework\nleveraging large language models (LLMs) to generate control interfaces on\ndemand between network functions (NFs). This includes a matching agent, which\naligns required control functionalities with NF capabilities, and a\ncode-generation agent, which generates the necessary API server for interface\nrealization. We validate our approach using simulated multi-vendor gNB and WLAN\nAP environments. The performance evaluations highlight the trade-offs between\ncost and latency across LLMs for interface generation tasks. Our work sets the\nfoundation for AI-native dynamic control interface generation, paving the way\nfor enhanced interoperability and adaptability in future mobile networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u751f\u6210\u7f51\u7edc\u529f\u80fd\u95f4\u7684\u63a7\u5236\u63a5\u53e3\uff0c\u63d0\u5347\u4e86\u4e92\u64cd\u4f5c\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u6807\u51c6\u5316\u7f51\u7edc\u63a5\u53e3\u5b58\u5728\u4f9b\u5e94\u5546\u7279\u5b9a\u4e0d\u517c\u5bb9\u3001\u8bbe\u8ba1\u5047\u8bbe\u50f5\u5316\u548c\u7f3a\u4e4f\u65b0\u529f\u80fd\u9002\u5e94\u6027\u95ee\u9898\uff0c\u4e9f\u9700\u52a8\u6001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5339\u914d\u4ee3\u7406\u548c\u4ee3\u7801\u751f\u6210\u4ee3\u7406\uff0c\u7ed3\u5408LLM\u6280\u672f\uff0c\u901a\u8fc7\u6a21\u62df\u591a\u4f9b\u5e94\u5546\u73af\u5883\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\u3002", "result": "\u6027\u80fd\u8bc4\u4f30\u5c55\u793a\u4e86\u5728\u6210\u672c\u548c\u5ef6\u8fdf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u8bc1\u660e\u4e86AI\u539f\u751f\u52a8\u6001\u63a5\u53e3\u751f\u6210\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u7684\u4e92\u64cd\u4f5c\u6027\u548c\u9002\u5e94\u6027\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.15152", "pdf": "https://arxiv.org/pdf/2508.15152", "abs": "https://arxiv.org/abs/2508.15152", "authors": ["Matthew Brehmer", "Ginger Gloystein", "Bailiang Zhou", "Abby Gray", "Sruthi Pillai", "Ben Medina", "Vidya Setlur"], "title": "Evaluating an Immersive Analytics Application at an Enterprise Business Intelligence Customer Conference", "categories": ["cs.HC"], "comment": "To appear at the Human Factors in Immersive Analytics (HFIA) Workshop\n  at IEEE VIS 2025", "summary": "We reflect on an evaluation of an immersive analytics application (Tableau\nfor visionOS) conducted at a large enterprise business intelligence (BI)\nconference. Conducting a study in such a context offered an opportunistic\nsetting to gather diverse feedback. However, this setting also highlighted the\nchallenge of evaluating usability while also assessing potential utility, as\nfeedback straddled between the novelty of the experience and the practicality\nof the application in participants' analytical workflows. This formative\nevaluation with 22 participants allowed us to gather insights with respect to\nthe usability of Tableau for visionOS, along with broader perspectives on the\npotential for head-mounted displays (HMDs) to promote new ways to engage with\nBI data. Our experience suggests a need for new evaluation considerations that\nintegrate qualitative and quantitative measures and account for unique\ninteraction patterns with 3D representations and interfaces accessible via an\nHMD. Overall, we contribute an enterprise perspective on evaluation\nmethodologies for immersive analytics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5bf9Tableau for visionOS\u5728\u5927\u578b\u4f01\u4e1aBI\u4f1a\u8bae\u4e0a\u7684\u8bc4\u4f30\uff0c\u63a2\u8ba8\u4e86\u6c89\u6d78\u5f0f\u5206\u6790\u5e94\u7528\u7684\u53ef\u7528\u6027\u548c\u5b9e\u7528\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u9700\u6c42\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u4f01\u4e1a\u73af\u5883\u4e2d\u6c89\u6d78\u5f0f\u5206\u6790\u5e94\u7528\uff08\u5982Tableau for visionOS\uff09\u7684\u53ef\u7528\u6027\u548c\u6f5c\u5728\u6548\u7528\uff0c\u5c24\u5176\u662f\u5728\u65b0\u4ea4\u4e92\u65b9\u5f0f\uff08\u5982\u5934\u6234\u663e\u793a\u5668\uff09\u4e0b\u5982\u4f55\u8bc4\u4f30\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5f62\u6210\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf922\u540d\u53c2\u4e0e\u8005\u7684\u53cd\u9988\u8fdb\u884c\u5206\u6790\uff0c\u7ed3\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u6570\u636e\uff0c\u63a2\u8ba8\u4e86\u8be5\u6280\u672f\u5728BI\u5de5\u4f5c\u6d41\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8bc4\u4f30\u6c89\u6d78\u5f0f\u5206\u6790\u9700\u517c\u987e\u4f53\u9a8c\u7684\u65b0\u9896\u6027\u548c\u5b9e\u9645\u6548\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u6574\u5408\u5b9a\u6027\u4e0e\u5b9a\u91cf\u65b9\u6cd5\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u8bba\u6587\u4e3a\u4f01\u4e1a\u7ea7\u6c89\u6d78\u5f0f\u5206\u6790\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u5728HMD\u4ea4\u4e92\u4e2d\u8bc4\u4f303D\u754c\u9762\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.15733", "pdf": "https://arxiv.org/pdf/2508.15733", "abs": "https://arxiv.org/abs/2508.15733", "authors": ["Hayato Ishida", "Amal Elsokary", "Maria Aslam", "Catherine White", "Michael J. de C. Henshaw", "Siyuan Ji"], "title": "Exploration of Evolving Quantum Key Distribution Network Architecture Using Model-Based Systems Engineering", "categories": ["cs.ET", "cs.SE", "quant-ph"], "comment": "Accepted by the IEEE International Symposium on Systems Engineering,\n  Oct 28-30, 2025", "summary": "Realisation of significant advances in capabilities of sensors, computing,\ntiming, and communication enabled by quantum technologies is dependent on\nengineering highly complex systems that integrate quantum devices into existing\nclassical infrastructure. A systems engineering approach is considered to\naddress the growing need for quantum-secure telecommunications that overcome\nthe threat to encryption caused by maturing quantum computation. This work\nexplores a range of existing and future quantum communication networks,\nspecifically quantum key distribution network proposals, to model and\ndemonstrate the evolution of quantum key distribution network architectures.\nLeveraging Orthogonal Variability Modelling and Systems Modelling Language as\ncandidate modelling languages, the study creates traceable artefacts to promote\nmodular architectures that are reusable for future studies. We propose a\nvariability-driven framework for managing fast-evolving network architectures\nwith respect to increasing stakeholder expectations. The result contributes to\nthe systematic development of viable quantum key distribution networks and\nsupports the investigation of similar integration challenges relevant to the\nbroader context of quantum systems engineering.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u91cf\u5b50\u901a\u4fe1\u7f51\u7edc\uff0c\u7279\u522b\u662f\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7f51\u7edc\u67b6\u6784\u7684\u6f14\u8fdb\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u53ef\u53d8\u6027\u5efa\u6a21\u7684\u6846\u67b6\uff0c\u4ee5\u7ba1\u7406\u5feb\u901f\u53d1\u5c55\u7684\u7f51\u7edc\u67b6\u6784\u5e76\u6ee1\u8db3\u5229\u76ca\u76f8\u5173\u8005\u7684\u671f\u671b\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u91cf\u5b50\u8bbe\u5907\u9700\u8981\u96c6\u6210\u5230\u7ecf\u5178\u57fa\u7840\u8bbe\u65bd\u4e2d\u3002\u91cf\u5b50\u8ba1\u7b97\u7684\u6210\u719f\u5bf9\u52a0\u5bc6\u6280\u672f\u6784\u6210\u5a01\u80c1\uff0c\u56e0\u6b64\u9700\u8981\u91cf\u5b50\u5b89\u5168\u901a\u4fe1\u3002", "method": "\u5229\u7528\u6b63\u4ea4\u53ef\u53d8\u6027\u5efa\u6a21\u548c\u7cfb\u7edf\u5efa\u6a21\u8bed\u8a00\uff0c\u7814\u7a76\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7f51\u7edc\u67b6\u6784\u7684\u6f14\u8fdb\uff0c\u5e76\u5f00\u53d1\u53ef\u8ffd\u8e2a\u7684\u6a21\u5757\u5316\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u53d8\u6027\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u652f\u6301\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7f51\u7edc\u7684\u7cfb\u7edf\u5316\u5f00\u53d1\uff0c\u5e76\u6709\u52a9\u4e8e\u89e3\u51b3\u91cf\u5b50\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u7c7b\u4f3c\u96c6\u6210\u6311\u6218\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7f51\u7edc\u7684\u53ef\u884c\u6027\u548c\u7cfb\u7edf\u6027\u5f00\u53d1\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u5e76\u4e3a\u91cf\u5b50\u7cfb\u7edf\u5de5\u7a0b\u7684\u96c6\u6210\u95ee\u9898\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15008", "pdf": "https://arxiv.org/pdf/2508.15008", "abs": "https://arxiv.org/abs/2508.15008", "authors": ["Hamza A. Abushahla", "Dara Varam", "Ariel J. N. Panopio", "Mohamed I. AlHajri"], "title": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "39 pages, 16 figures, 8 Tables, submitted to the Proceedings of the\n  IEEE", "summary": "The deployment of Quantized Neural Networks (QNNs) on resource-constrained\ndevices, such as microcontrollers, has introduced significant challenges in\nbalancing model performance, computational complexity and memory constraints.\nTiny Machine Learning (TinyML) addresses these issues by integrating\nadvancements across machine learning algorithms, hardware acceleration, and\nsoftware optimization to efficiently run deep neural networks on embedded\nsystems. This survey presents a hardware-centric introduction to quantization,\nsystematically reviewing essential quantization techniques employed to\naccelerate deep learning models for embedded applications. In particular,\nfurther emphasis is put on critical trade-offs among model performance and\nhardware capabilities. The survey further evaluates existing software\nframeworks and hardware platforms designed specifically for supporting QNN\nexecution on microcontrollers. Moreover, we provide an analysis of the current\nchallenges and an outline of promising future directions in the rapidly\nevolving domain of QNN deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\uff08QNN\uff09\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\uff08\u5982\u5fae\u63a7\u5236\u5668\uff09\u4e0a\u7684\u90e8\u7f72\u6311\u6218\uff0c\u63a2\u8ba8\u4e86TinyML\u5982\u4f55\u901a\u8fc7\u7b97\u6cd5\u3001\u786c\u4ef6\u548c\u8f6f\u4ef6\u4f18\u5316\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u5206\u6790\u4e86\u73b0\u6709\u6846\u67b6\u3001\u5e73\u53f0\u4ee5\u53ca\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u90e8\u7f72\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u65f6\u9762\u4e34\u6027\u80fd\u3001\u8ba1\u7b97\u590d\u6742\u6027\u548c\u5185\u5b58\u9650\u5236\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u91cf\u5316\u6280\u672f\uff0c\u5206\u6790\u6a21\u578b\u6027\u80fd\u4e0e\u786c\u4ef6\u80fd\u529b\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u8bc4\u4f30\u73b0\u6709\u8f6f\u4ef6\u6846\u67b6\u548c\u786c\u4ef6\u5e73\u53f0\u3002", "result": "\u603b\u7ed3\u4e86\u5f53\u524dQNN\u90e8\u7f72\u7684\u5173\u952e\u6280\u672f\u548c\u5de5\u5177\uff0c\u5e76\u6307\u51fa\u4e86\u76f8\u5173\u6311\u6218\u3002", "conclusion": "QNN\u90e8\u7f72\u9886\u57df\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u4f46\u672a\u6765\u7814\u7a76\u65b9\u5411\u5145\u6ee1\u5e0c\u671b\u3002"}}
{"id": "2508.15290", "pdf": "https://arxiv.org/pdf/2508.15290", "abs": "https://arxiv.org/abs/2508.15290", "authors": ["Peiqi Yin", "Xiao Yan", "Qihui Zhou", "Hui Li", "Xiaolu Li", "Lin Zhang", "Meiling Wang", "Xin Yao", "James Cheng"], "title": "Gorgeous: Revisiting the Data Layout for Disk-Resident High-Dimensional Vector Search", "categories": ["cs.DB"], "comment": "12 pages, 19 figures", "summary": "Similarity-based vector search underpins many important applications, but a\nkey challenge is processing massive vector datasets (e.g., in TBs). To reduce\ncosts, some systems utilize SSDs as the primary data storage. They employ a\nproximity graph, which connects similar vectors to form a graph and is the\nstate-of-the-art index for vector search. However, these systems are hindered\nby sub-optimal data layouts that fail to effectively utilize valuable memory\nspace to reduce disk access and suffer from poor locality for accessing\ndisk-resident data. Through extensive profiling and analysis, we found that the\nstructure of the proximity graph index is accessed more frequently than the\nvectors themselves, yet existing systems do not distinguish between the two. To\naddress this problem, we design the Gorgeous system with the principle of\nprioritizing graph structure over vectors. Specifically, Gorgeous features a\nmemory cache that keeps the adjacency lists of graph nodes to improve cache\nhits and a disk block format that explicitly stores neighbors' adjacency lists\nalong with a vector to enhance data locality. Experimental results show that\nGorgeous consistently outperforms two state-of-the-art disk-based systems for\nvector search, boosting average query throughput by over 60% and reducing query\nlatency by over 35%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u5411\u91cf\u641c\u7d22\u7684\u7cfb\u7edfGorgeous\uff0c\u901a\u8fc7\u4f18\u5148\u5904\u7406\u56fe\u7ed3\u6784\u800c\u975e\u5411\u91cf\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u5904\u7406\u5927\u89c4\u6a21\u5411\u91cf\u6570\u636e\u96c6\u65f6\uff0c\u672a\u80fd\u6709\u6548\u5229\u7528\u5185\u5b58\u7a7a\u95f4\u548c\u78c1\u76d8\u8bbf\u95ee\u5c40\u90e8\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\u3002", "method": "\u8bbe\u8ba1Gorgeous\u7cfb\u7edf\uff0c\u91c7\u7528\u5185\u5b58\u7f13\u5b58\u56fe\u7ed3\u6784\u7684\u90bb\u63a5\u8868\u548c\u4f18\u5316\u7684\u78c1\u76d8\u5757\u683c\u5f0f\uff0c\u63d0\u5347\u6570\u636e\u5c40\u90e8\u6027\u3002", "result": "Gorgeous\u6bd4\u73b0\u6709\u7cfb\u7edf\u5e73\u5747\u67e5\u8be2\u541e\u5410\u91cf\u63d0\u534760%\u4ee5\u4e0a\uff0c\u5ef6\u8fdf\u964d\u4f4e35%\u4ee5\u4e0a\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5148\u5904\u7406\u56fe\u7ed3\u6784\uff0cGorgeous\u663e\u8457\u4f18\u5316\u4e86\u5927\u89c4\u6a21\u5411\u91cf\u641c\u7d22\u7684\u6027\u80fd\u3002"}}
{"id": "2508.15570", "pdf": "https://arxiv.org/pdf/2508.15570", "abs": "https://arxiv.org/abs/2508.15570", "authors": ["Marion Wiese", "Kamila Serwa", "Anastasia Besier", "Ariane S. Marion-Jetten", "Eva Bittner"], "title": "Establishing Technical Debt Management -- A Five-Step Workshop Approach and an Action Research Study", "categories": ["cs.SE"], "comment": "Accepted for publication by the Journal of Systems and Software --\n  Special Issue on Managing Technical Debt in Software-Intensive Products and\n  Services", "summary": "Context. Technical debt (TD) items are constructs in a software system\nproviding short-term benefits but hindering future changes. TD management (TDM)\nis frequently researched but rarely adopted in practice. Goal. This study aimed\nto establish a TDM process in an IT company based on a predefined workshop\nconcept. We analyzed which research approaches practitioners adopted for each\nTD activity and the TDM's long-term effect on TD awareness. Method. We used\naction research (five action cycles in 16 months) with an IT team that creates\nIT solutions for signal processing. To examine TD awareness, we (1) analyzed\nquestionnaires completed during each workshop, (2) observed team meetings, (3)\nadopted a method from psychology for measuring awareness in decision-making\nsituations called TD-SAGAT, and (4) evaluated the backlog data. Results.\nPractitioners preferred TD repayment and prioritization based on the system's\nevolution and cost calculations, i.e., repayment of so-called low-hanging\nfruits. Reminders in the backlog items, such as checkboxes or text templates,\nled to a sustainable rise in TD awareness. Conclusions. We showed that a\nworkshop-based approach is feasible and leads to sustainable process changes.\nNew ideas for TDM applicable to other IT teams emerged, e.g., using a\nre-submission date, using a Talked about TD checkbox, and using visualizations\nfor TD prioritization.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u901a\u8fc7\u5de5\u4f5c\u574a\u5f62\u5f0f\u5728IT\u516c\u53f8\u4e2d\u5efa\u7acb\u6280\u672f\u503a\u52a1\uff08TD\uff09\u7ba1\u7406\u6d41\u7a0b\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5bf9TD\u610f\u8bc6\u7684\u957f\u671f\u5f71\u54cd\u3002", "motivation": "\u6280\u672f\u503a\u52a1\u7ba1\u7406\uff08TDM\uff09\u5728\u7814\u7a76\u4e2d\u5e38\u89c1\u4f46\u5b9e\u9645\u5e94\u7528\u8f83\u5c11\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5de5\u4f5c\u574a\u5f62\u5f0f\u5c06TDM\u5f15\u5165\u5b9e\u8df5\u3002", "method": "\u91c7\u7528\u884c\u52a8\u7814\u7a76\u65b9\u6cd5\uff0816\u4e2a\u6708\u51855\u4e2a\u884c\u52a8\u5468\u671f\uff09\uff0c\u7ed3\u5408\u95ee\u5377\u3001\u56e2\u961f\u4f1a\u8bae\u89c2\u5bdf\u3001\u5fc3\u7406\u5b66\u65b9\u6cd5\uff08TD-SAGAT\uff09\u548c\u5f85\u529e\u4e8b\u9879\u6570\u636e\u5206\u6790\u3002", "result": "\u5b9e\u8df5\u8005\u503e\u5411\u4e8e\u57fa\u4e8e\u7cfb\u7edf\u6f14\u5316\u548c\u6210\u672c\u8ba1\u7b97\u4f18\u5148\u507f\u8fd8\u4f4e\u5782\u679c\u5b9e\uff08low-hanging fruits\uff09\uff0c\u5f85\u529e\u4e8b\u9879\u4e2d\u7684\u63d0\u9192\uff08\u5982\u590d\u9009\u6846\u6216\u6587\u672c\u6a21\u677f\uff09\u53ef\u6301\u7eed\u63d0\u5347TD\u610f\u8bc6\u3002", "conclusion": "\u5de5\u4f5c\u574a\u65b9\u6cd5\u53ef\u884c\u4e14\u80fd\u5e26\u6765\u53ef\u6301\u7eed\u7684\u6d41\u7a0b\u6539\u8fdb\uff0c\u5e76\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u5176\u4ed6IT\u56e2\u961f\u7684\u65b0TDM\u65b9\u6cd5\uff0c\u5982\u91cd\u65b0\u63d0\u4ea4\u65e5\u671f\u3001'\u8ba8\u8bba\u8fc7TD'\u590d\u9009\u6846\u548c\u53ef\u89c6\u5316\u4f18\u5148\u6392\u5e8f\u3002"}}
{"id": "2508.15755", "pdf": "https://arxiv.org/pdf/2508.15755", "abs": "https://arxiv.org/abs/2508.15755", "authors": ["Jie Xu", "Eric Heiden", "Iretiayo Akinola", "Dieter Fox", "Miles Macklin", "Yashraj Narang"], "title": "Neural Robot Dynamics", "categories": ["cs.RO", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "Accurate and efficient simulation of modern robots remains challenging due to\ntheir high degrees of freedom and intricate mechanisms. Neural simulators have\nemerged as a promising alternative to traditional analytical simulators,\ncapable of efficiently predicting complex dynamics and adapting to real-world\ndata; however, existing neural simulators typically require\napplication-specific training and fail to generalize to novel tasks and/or\nenvironments, primarily due to inadequate representations of the global state.\nIn this work, we address the problem of learning generalizable neural\nsimulators for robots that are structured as articulated rigid bodies. We\npropose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models\nfor predicting future states for articulated rigid bodies under contact\nconstraints. NeRD uniquely replaces the low-level dynamics and contact solvers\nin an analytical simulator and employs a robot-centric and spatially-invariant\nsimulation state representation. We integrate the learned NeRD models as an\ninterchangeable backend solver within a state-of-the-art robotics simulator. We\nconduct extensive experiments to show that the NeRD simulators are stable and\naccurate over a thousand simulation steps; generalize across tasks and\nenvironment configurations; enable policy learning exclusively in a neural\nengine; and, unlike most classical simulators, can be fine-tuned from\nreal-world data to bridge the gap between simulation and reality.", "AI": {"tldr": "\u795e\u7ecf\u673a\u5668\u4eba\u52a8\u529b\u5b66\uff08NeRD\uff09\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u9884\u6d4b\u673a\u5668\u4eba\u7684\u672a\u6765\u72b6\u6001\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u795e\u7ecf\u6a21\u62df\u5668\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u4eba\u7684\u9ad8\u81ea\u7531\u5ea6\u548c\u590d\u6742\u673a\u5236\u4f7f\u5f97\u6a21\u62df\u53d8\u5f97\u56f0\u96be\uff0c\u73b0\u6709\u795e\u7ecf\u6a21\u62df\u5668\u901a\u5e38\u9700\u8981\u7279\u5b9a\u8bad\u7ec3\u4e14\u96be\u4ee5\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u6216\u73af\u5883\u3002", "method": "NeRD\u901a\u8fc7\u673a\u5668\u4eba\u4e2d\u5fc3\u548c\u7a7a\u95f4\u4e0d\u53d8\u7684\u6a21\u62df\u72b6\u6001\u8868\u793a\uff0c\u66ff\u4ee3\u4e86\u4f20\u7edf\u6a21\u62df\u5668\u4e2d\u7684\u4f4e\u5c42\u52a8\u529b\u5b66\u548c\u63a5\u89e6\u6c42\u89e3\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cNeRD\u6a21\u62df\u5668\u7a33\u5b9a\u4e14\u51c6\u786e\uff0c\u80fd\u591f\u6cdb\u5316\u5230\u4e0d\u540c\u4efb\u52a1\u548c\u73af\u5883\u914d\u7f6e\uff0c\u5e76\u53ef\u4ee5\u901a\u8fc7\u73b0\u5b9e\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u3002", "conclusion": "NeRD\u4e3a\u673a\u5668\u4eba\u52a8\u529b\u5b66\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u7f29\u5c0f\u6a21\u62df\u4e0e\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.15333", "pdf": "https://arxiv.org/pdf/2508.15333", "abs": "https://arxiv.org/abs/2508.15333", "authors": ["Francesco Dagnino", "Paola Giannini", "Violet Ka I Pun", "Ulises Torrella"], "title": "Fair Termination for Resource-Aware Active Objects", "categories": ["cs.PL", "F.3.3"], "comment": "18 pages, 12 pages of appendix, 12 figures, APLAS 2025", "summary": "Active object systems are a model of distributed computation that has been\nadopted for modelling distributed systems and business process workflows. This\nfield of modelling is, in essence, concurrent and resource-aware, motivating\nthe development of resource-aware formalisations on the active object model.\nThe contributions of this work are the development of a core calculus for\nresource-aware active objects together with a type system ensuring that\nwell-typed programs are fairly terminating, i.e., they can always eventually\nterminate. To achieve this, we combine techniques from graded semantics and\ntype systems, which are quite well understood for sequential programs, with\nthose for fair termination, which have been developed for synchronous~sessions.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u8d44\u6e90\u611f\u77e5\u7684\u4e3b\u52a8\u5bf9\u8c61\u6838\u5fc3\u6f14\u7b97\uff0c\u7ed3\u5408\u7c7b\u578b\u7cfb\u7edf\u786e\u4fdd\u7a0b\u5e8f\u516c\u5e73\u7ec8\u6b62\u3002", "motivation": "\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u548c\u4e1a\u52a1\u6d41\u7a0b\u5efa\u6a21\u63d0\u4f9b\u8d44\u6e90\u611f\u77e5\u7684\u5e76\u53d1\u6a21\u578b\u3002", "method": "\u7ed3\u5408\u5206\u7ea7\u8bed\u4e49\u548c\u7c7b\u578b\u7cfb\u7edf\u6280\u672f\uff0c\u6269\u5c55\u5230\u540c\u6b65\u4f1a\u8bdd\u7684\u516c\u5e73\u7ec8\u6b62\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u80fd\u786e\u4fdd\u516c\u5e73\u7ec8\u6b62\u7684\u8d44\u6e90\u611f\u77e5\u4e3b\u52a8\u5bf9\u8c61\u6f14\u7b97\u3002", "conclusion": "\u8be5\u6f14\u7b97\u4e3a\u8d44\u6e90\u611f\u77e5\u5e76\u53d1\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u786e\u4fdd\u7a0b\u5e8f\u7684\u516c\u5e73\u7ec8\u6b62\u6027\u3002"}}
{"id": "2508.15227", "pdf": "https://arxiv.org/pdf/2508.15227", "abs": "https://arxiv.org/abs/2508.15227", "authors": ["Wen-Fan Wang", "Ting-Ying Lee", "Chien-Ting Lu", "Che-Wei Hsu", "Nil Ponsa Campany", "Yu Chen", "Mike Y. Chen", "Bing-Yu Chen"], "title": "GenTune: Toward Traceable Prompts to Improve Controllability of Image Refinement in Environment Design", "categories": ["cs.HC", "cs.AI", "H.5.2"], "comment": "Accepted ACM Symposium on User Interface Software and Technology\n  (UIST '25)", "summary": "Environment designers in the entertainment industry create imaginative 2D and\n3D scenes for games, films, and television, requiring both fine-grained control\nof specific details and consistent global coherence. Designers have\nincreasingly integrated generative AI into their workflows, often relying on\nlarge language models (LLMs) to expand user prompts for text-to-image\ngeneration, then iteratively refining those prompts and applying inpainting.\nHowever, our formative study with 10 designers surfaced two key challenges: (1)\nthe lengthy LLM-generated prompts make it difficult to understand and isolate\nthe keywords that must be revised for specific visual elements; and (2) while\ninpainting supports localized edits, it can struggle with global consistency\nand correctness. Based on these insights, we present GenTune, an approach that\nenhances human--AI collaboration by clarifying how AI-generated prompts map to\nimage content. Our GenTune system lets designers select any element in a\ngenerated image, trace it back to the corresponding prompt labels, and revise\nthose labels to guide precise yet globally consistent image refinement. In a\nsummative study with 20 designers, GenTune significantly improved prompt--image\ncomprehension, refinement quality, and efficiency, and overall satisfaction\n(all $p < .01$) compared to current practice. A follow-up field study with two\nstudios further demonstrated its effectiveness in real-world settings.", "AI": {"tldr": "GenTune\u662f\u4e00\u4e2a\u6539\u8fdb\u8bbe\u8ba1\u5e08\u4e0e\u751f\u6210\u5f0fAI\u534f\u4f5c\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u6e05\u6670\u5730\u6620\u5c04AI\u751f\u6210\u7684\u63d0\u793a\u4e0e\u56fe\u50cf\u5185\u5bb9\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u5b9e\u8df5\u4e2d\u63d0\u793a\u7406\u89e3\u96be\u548c\u5168\u5c40\u4e00\u81f4\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u8bbe\u8ba1\u5e08\u5728\u4f7f\u7528\u751f\u6210\u5f0fAI\u65f6\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1aLLM\u751f\u6210\u7684\u5197\u957f\u63d0\u793a\u96be\u4ee5\u7406\u89e3\u4e0e\u4fee\u6539\uff0c\u4ee5\u53cainpainting\u5728\u5c40\u90e8\u7f16\u8f91\u65f6\u53ef\u80fd\u5f71\u54cd\u5168\u5c40\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51faGenTune\u7cfb\u7edf\uff0c\u5141\u8bb8\u8bbe\u8ba1\u5e08\u9009\u62e9\u56fe\u50cf\u5143\u7d20\u5e76\u56de\u6eaf\u5230\u5bf9\u5e94\u63d0\u793a\u6807\u7b7e\uff0c\u4ece\u800c\u7cbe\u51c6\u4fee\u6539\u5e76\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\u3002", "result": "GenTune\u663e\u8457\u63d0\u5347\u4e86\u63d0\u793a\u4e0e\u56fe\u50cf\u7684\u7406\u89e3\u3001\u7f16\u8f91\u8d28\u91cf\u548c\u6548\u7387\uff0c\u8bbe\u8ba1\u5e08\u6ee1\u610f\u5ea6\u663e\u8457\u63d0\u9ad8\uff08p < .01\uff09\u3002\u5b9e\u5730\u7814\u7a76\u4e5f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "GenTune\u901a\u8fc7\u6539\u8fdb\u4eba\u673a\u534f\u4f5c\u673a\u5236\uff0c\u4e3a\u8bbe\u8ba1\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u4e14\u4e00\u81f4\u7684\u751f\u6210\u5f0fAI\u5de5\u5177\u3002"}}
{"id": "2508.14906", "pdf": "https://arxiv.org/pdf/2508.14906", "abs": "https://arxiv.org/abs/2508.14906", "authors": ["Amir Kermanshahani", "Ebrahim Ardeshir-Larijani", "Rakesh Saini", "Saif Al-Kuwari"], "title": "Collaborative Filtering using Variational Quantum Hopfield Associative Memory", "categories": ["cs.IR", "cs.AI", "cs.ET", "cs.LG"], "comment": null, "summary": "Quantum computing, with its ability to do exponentially faster computation\ncompared to classical systems, has found novel applications in various fields\nsuch as machine learning and recommendation systems. Quantum Machine Learning\n(QML), which integrates quantum computing with machine learning techniques,\npresents powerful new tools for data processing and pattern recognition. This\npaper proposes a hybrid recommendation system that combines Quantum Hopfield\nAssociative Memory (QHAM) with deep neural networks to improve the extraction\nand classification on the MovieLens 1M dataset. User archetypes are clustered\ninto multiple unique groups using the K-Means algorithm and converted into\npolar patterns through the encoder's activation function. These polar patterns\nare then integrated into the variational QHAM-based hybrid recommendation\nmodel. The system was trained using the MSE loss over 35 epochs in an ideal\nenvironment, achieving an ROC value of 0.9795, an accuracy of 0.8841, and an\nF-1 Score of 0.8786. Trained with the same number of epochs in a noisy\nenvironment using a custom Qiskit AER noise model incorporating bit-flip and\nreadout errors with the same probabilities as in real quantum hardware, it\nachieves an ROC of 0.9177, an accuracy of 0.8013, and an F-1 Score equal to\n0.7866, demonstrating consistent performance.\n  Additionally, we were able to optimize the qubit overhead present in previous\nQHAM architectures by efficiently updating only one random targeted qubit. This\nresearch presents a novel framework that combines variational quantum computing\nwith deep learning, capable of dealing with real-world datasets with comparable\nperformance compared to purely classical counterparts. Additionally, the model\ncan perform similarly well in noisy configurations, showcasing a steady\nperformance and proposing a promising direction for future usage in\nrecommendation systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50Hopfield\u8054\u60f3\u8bb0\u5fc6\uff08QHAM\uff09\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\uff0c\u7528\u4e8e\u63d0\u5347\u5728MovieLens 1M\u6570\u636e\u96c6\u4e0a\u7684\u63d0\u53d6\u4e0e\u5206\u7c7b\u6027\u80fd\u3002\u901a\u8fc7\u805a\u7c7b\u7528\u6237\u539f\u578b\u5e76\u8f6c\u6362\u4e3a\u6781\u6027\u6a21\u5f0f\uff0c\u6a21\u578b\u5728\u7406\u60f3\u548c\u566a\u58f0\u73af\u5883\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u9700\u89e3\u51b3\u566a\u58f0\u73af\u5883\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002", "method": "\u4f7f\u7528K-Means\u805a\u7c7b\u7528\u6237\u539f\u578b\u5e76\u8f6c\u6362\u4e3a\u6781\u6027\u6a21\u5f0f\uff0c\u7ed3\u5408\u53d8\u5206QHAM\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5728\u7406\u60f3\u73af\u5883\u4e2d\uff0cROC\u503c\u4e3a0.9795\uff0c\u51c6\u786e\u7387\u4e3a0.8841\uff1b\u566a\u58f0\u73af\u5883\u4e2dROC\u4e3a0.9177\uff0c\u51c6\u786e\u7387\u4e3a0.8013\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u7ed3\u5408\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u566a\u58f0\u73af\u5883\u4e0b\u8868\u73b0\u7a33\u5b9a\u3002"}}
{"id": "2508.15468", "pdf": "https://arxiv.org/pdf/2508.15468", "abs": "https://arxiv.org/abs/2508.15468", "authors": ["Zhiqiang Que", "Chang Sun", "Sudarshan Paramesvaran", "Emyr Clement", "Katerina Karakoulaki", "Christopher Brown", "Lauri Laatu", "Arianna Cox", "Alexander Tapper", "Wayne Luk", "Maria Spiropulu"], "title": "JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs", "categories": ["hep-ex", "cs.AR", "cs.LG"], "comment": "10 pages, 9 figures", "summary": "Graph Neural Networks (GNNs), particularly Interaction Networks (INs), have\nshown exceptional performance for jet tagging at the CERN High-Luminosity Large\nHadron Collider (HL-LHC). However, their computational complexity and irregular\nmemory access patterns pose significant challenges for deployment on FPGAs in\nhardware trigger systems, where strict latency and resource constraints apply.\nIn this work, we propose JEDI-linear, a novel GNN architecture with linear\ncomputational complexity that eliminates explicit pairwise interactions by\nleveraging shared transformations and global aggregation. To further enhance\nhardware efficiency, we introduce fine-grained quantization-aware training with\nper-parameter bitwidth optimization and employ multiplier-free\nmultiply-accumulate operations via distributed arithmetic. Evaluation results\nshow that our FPGA-based JEDI-linear achieves 3.7 to 11.5 times lower latency,\nup to 150 times lower initiation interval, and up to 6.2 times lower LUT usage\ncompared to state-of-the-art designs while also delivering higher model\naccuracy and eliminating the need for DSP blocks entirely. In contrast,\nstate-of-the-art solutions consume over 8,700 DSPs. This is the first\ninteraction-based GNN to achieve less than 60~ns latency and currently meets\nthe requirements for use in the HL-LHC CMS Level-1 trigger system. This work\nadvances the next-generation trigger systems by enabling accurate, scalable,\nand resource-efficient GNN inference in real-time environments. Our\nopen-sourced templates will further support reproducibility and broader\nadoption across scientific applications.", "AI": {"tldr": "JEDI-linear\u662f\u4e00\u79cd\u65b0\u578bGNN\u67b6\u6784\uff0c\u901a\u8fc7\u5171\u4eab\u53d8\u6362\u548c\u5168\u5c40\u805a\u5408\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4f18\u5316\u4e86FPGA\u90e8\u7f72\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u8d44\u6e90\u4f7f\u7528\u3002", "motivation": "\u89e3\u51b3GNN\u5728FPGA\u786c\u4ef6\u89e6\u53d1\u5668\u7cfb\u7edf\u4e2d\u90e8\u7f72\u65f6\u7684\u9ad8\u8ba1\u7b97\u590d\u6742\u6027\u548c\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u590d\u6742\u5ea6\u7684GNN\u67b6\u6784\uff0c\u7ed3\u5408\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u548c\u5206\u5e03\u5f0f\u7b97\u672f\uff0c\u4f18\u5316\u786c\u4ef6\u6548\u7387\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u8bbe\u8ba1\uff0cJEDI-linear\u5b9e\u73b0\u4e86\u66f4\u4f4e\u5ef6\u8fdf\uff083.7-11.5\u500d\uff09\u3001\u66f4\u4f4e\u7684LUT\u4f7f\u7528\uff086.2\u500d\uff09\u53ca\u66f4\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "JEDI-linear\u6ee1\u8db3\u4e86HL-LHC CMS Level-1\u89e6\u53d1\u7cfb\u7edf\u7684\u5b9e\u65f6\u8981\u6c42\uff0c\u63a8\u52a8\u4e86\u9ad8\u6548GNN\u63a8\u7406\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.15694", "pdf": "https://arxiv.org/pdf/2508.15694", "abs": "https://arxiv.org/abs/2508.15694", "authors": ["Yijie Zhou", "Shengyuan Lin", "Shufeng Gong", "Song Yu", "Shuhao Fan", "Yanfeng Zhang", "Ge Yu"], "title": "GoVector: An I/O-Efficient Caching Strategy for High-Dimensional Vector Nearest Neighbor Search", "categories": ["cs.DB"], "comment": "12 pages, 12 figures, this paper is the English version of our\n  Chinese paper accepted for publication in Journal of Software, Vol. 37, No.\n  3, 2026", "summary": "Graph-based high-dimensional vector indices have become a mainstream solution\nfor large-scale approximate nearest neighbor search (ANNS). However, their\nsubstantial memory footprint often requires storage on secondary devices, where\nfrequent on-demand loading of graph and vector data leads to I/O becoming the\ndominant bottleneck, accounting for over 90\\% of query latency. Existing static\ncaching strategies mitigate this issue only in the initial navigation phase by\npreloading entry points and multi-hop neighbors, but they fail in the second\nphase where query-dependent nodes must be dynamically accessed to achieve high\nrecall. We propose GoVector, an I/O-efficient caching strategy tailored for\ndisk-based graph indices. GoVector combines (1) a static cache that stores\nentry points and frequently accessed neighbors, and (2) a dynamic cache that\nadaptively captures nodes with high spatial locality during the second search\nphase. To further align storage layout with similarity-driven search patterns,\nGoVector reorders nodes on disk so that similar vectors are colocated on the\nsame or adjacent pages, thereby improving locality and reducing I/O overhead.\nExtensive experiments on multiple public datasets show that GoVector achieves\nsubstantial performance improvements. At 90% recall, it reduces I/O operations\nby 46% on average, increases query throughput by 1.73x, and lowers query\nlatency by 42% compared to state-of-the-art disk-based graph indexing systems.", "AI": {"tldr": "GoVector\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u57fa\u4e8e\u56fe\u7684ANNS\u7d22\u5f15\u7684I/O\u9ad8\u6548\u7f13\u5b58\u7b56\u7565\uff0c\u901a\u8fc7\u9759\u6001\u548c\u52a8\u6001\u7f13\u5b58\u7ed3\u5408\u53ca\u5b58\u50a8\u5e03\u5c40\u4f18\u5316\uff0c\u663e\u8457\u51cf\u5c11I/O\u64cd\u4f5c\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u9759\u6001\u7f13\u5b58\u7b56\u7565\u5728ANNS\u641c\u7d22\u7684\u7b2c\u4e8c\u9636\u6bb5\u6548\u679c\u4e0d\u4f73\uff0c\u5bfc\u81f4I/O\u6210\u4e3a\u74f6\u9888\uff0c\u5f71\u54cd\u67e5\u8be2\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u3002", "method": "\u7ed3\u5408\u9759\u6001\u7f13\u5b58\uff08\u9884\u52a0\u8f7d\u9ad8\u9891\u8bbf\u95ee\u8282\u70b9\uff09\u548c\u52a8\u6001\u7f13\u5b58\uff08\u81ea\u9002\u5e94\u6355\u83b7\u7a7a\u95f4\u5c40\u90e8\u6027\u9ad8\u7684\u8282\u70b9\uff09\uff0c\u5e76\u4f18\u5316\u5b58\u50a8\u5e03\u5c40\u4ee5\u4f7f\u76f8\u4f3c\u5411\u91cf\u5728\u78c1\u76d8\u4e0a\u76f8\u90bb\u3002", "result": "\u572890%\u53ec\u56de\u7387\u4e0b\uff0c\u5e73\u5747\u51cf\u5c1146%\u7684I/O\u64cd\u4f5c\uff0c\u67e5\u8be2\u541e\u5410\u91cf\u63d0\u53471.73\u500d\uff0c\u5ef6\u8fdf\u964d\u4f4e42%\u3002", "conclusion": "GoVector\u4e3a\u57fa\u4e8e\u78c1\u76d8\u7684\u56fe\u7d22\u5f15\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7f13\u5b58\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86ANNS\u7684\u6027\u80fd\u3002"}}
{"id": "2508.15647", "pdf": "https://arxiv.org/pdf/2508.15647", "abs": "https://arxiv.org/abs/2508.15647", "authors": ["Haoran Zhang", "Zihao Zhang", "Shuai Mu", "Sebastian Angel", "Vincent Liu"], "title": "CausalMesh: A Formally Verified Causal Cache for Stateful Serverless Computing", "categories": ["cs.DC"], "comment": "Extended version from PVLDB Volume 17, Issue 13, 2024. This version\n  includes full proofs and formal verification in Dafny and fixes some small\n  bugs", "summary": "Stateful serverless workflows consist of multiple serverless functions that\naccess state on a remote database. Developers sometimes add a cache layer\nbetween the serverless runtime and the database to improve I/O latency.\nHowever, in a serverless environment, functions in the same workflow may be\nscheduled to different nodes with different caches, which can cause\nnon-intuitive anomalies. This paper presents CausalMesh, a novel approach to\ncausally consistent caching in environments where a computation may migrate\nfrom one machine to another, such as in serverless computing. CausalMesh is the\nfirst cache system that supports coordination-free and abort-free read/write\noperations and read transactions when clients roam among multiple servers.\nCausalMesh also supports read-write transactional causal consistency in the\npresence of client roaming, but at the cost of abort-freedom.\n  We have formally verified CausalMesh's protocol in Dafny, and our\nexperimental evaluation shows that CausalMesh has lower latency and higher\nthroughput than existing proposals", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCausalMesh\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u670d\u52a1\u5668\u65e0\u72b6\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u56e0\u679c\u4e00\u81f4\u6027\u7684\u7f13\u5b58\uff0c\u652f\u6301\u65e0\u534f\u8c03\u548c\u65e0\u4e2d\u6b62\u7684\u8bfb\u5199\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u5728\u591a\u8282\u70b9\u670d\u52a1\u5668\u65e0\u72b6\u6001\u73af\u5883\u4e2d\uff0c\u7531\u4e8e\u7f13\u5b58\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u5f02\u5e38\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86CausalMesh\u7f13\u5b58\u7cfb\u7edf\uff0c\u652f\u6301\u56e0\u679c\u4e00\u81f4\u6027\u7684\u8bfb\u5199\u64cd\u4f5c\u548c\u4e8b\u52a1\u5904\u7406\uff0c\u9002\u7528\u4e8e\u5ba2\u6237\u7aef\u5728\u591a\u670d\u52a1\u5668\u95f4\u8fc1\u79fb\u7684\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCausalMesh\u5728\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u4e14\u5176\u534f\u8bae\u5df2\u901a\u8fc7Dafny\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "conclusion": "CausalMesh\u4e3a\u670d\u52a1\u5668\u65e0\u72b6\u6001\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u7f13\u5b58\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15584", "pdf": "https://arxiv.org/pdf/2508.15584", "abs": "https://arxiv.org/abs/2508.15584", "authors": ["Maria Teresa Rossi", "Leonardo Mariani", "Oliviero Riganelli"], "title": "From PREVENTion to REACTion: Enhancing Failure Resolution in Naval Systems", "categories": ["cs.SE"], "comment": null, "summary": "Complex and large industrial systems often misbehave, for instance, due to\nwear, misuse, or faults. To cope with these incidents, it is important to\ntimely detect their occurrences, localize the sources of the problems, and\nimplement the appropriate countermeasures. This paper reports our experience\nwith a state-of-the-art failure prediction method, PREVENT, and its extension\nwith a troubleshooting module, REACT, applied to naval systems developed by\nFincantieri. Our results show how to integrate anomaly detection with\ntroubleshooting procedures. We conclude by discussing a lesson learned, which\nmay help deploy and extend these analyses to other industrial products.", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u5982\u4f55\u901a\u8fc7PREVENT\u548cREACT\u65b9\u6cd5\u9884\u6d4b\u548c\u89e3\u51b3\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u95ee\u9898\u3002", "motivation": "\u9762\u5bf9\u590d\u6742\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u95ee\u9898\uff0c\u9700\u8981\u53ca\u65f6\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u5b9e\u65bd\u5e94\u5bf9\u63aa\u65bd\u3002", "method": "\u91c7\u7528PREVENT\u6545\u969c\u9884\u6d4b\u65b9\u6cd5\u548c\u6269\u5c55\u7684REACT\u6545\u969c\u6392\u9664\u6a21\u5757\u3002", "result": "\u6210\u529f\u5c06\u5f02\u5e38\u68c0\u6d4b\u4e0e\u6545\u969c\u6392\u9664\u7a0b\u5e8f\u96c6\u6210\u3002", "conclusion": "\u8fd9\u4e00\u65b9\u6cd5\u6709\u52a9\u4e8e\u5728\u5176\u4ed6\u5de5\u4e1a\u4ea7\u54c1\u4e2d\u63a8\u5e7f\u548c\u5e94\u7528\u3002"}}
{"id": "2508.15773", "pdf": "https://arxiv.org/pdf/2508.15773", "abs": "https://arxiv.org/abs/2508.15773", "authors": ["Gaurav Parmar", "Or Patashnik", "Daniil Ostashev", "Kuan-Chieh Wang", "Kfir Aberman", "Srinivasa Narasimhan", "Jun-Yan Zhu"], "title": "Scaling Group Inference for Diverse and High-Quality Generation", "categories": ["cs.CV", "cs.GR", "cs.LG"], "comment": "Project website: https://www.cs.cmu.edu/~group-inference, GitHub:\n  https://github.com/GaParmar/group-inference", "summary": "Generative models typically sample outputs independently, and recent\ninference-time guidance and scaling algorithms focus on improving the quality\nof individual samples. However, in real-world applications, users are often\npresented with a set of multiple images (e.g., 4-8) for each prompt, where\nindependent sampling tends to lead to redundant results, limiting user choices\nand hindering idea exploration. In this work, we introduce a scalable group\ninference method that improves both the diversity and quality of a group of\nsamples. We formulate group inference as a quadratic integer assignment\nproblem: candidate outputs are modeled as graph nodes, and a subset is selected\nto optimize sample quality (unary term) while maximizing group diversity\n(binary term). To substantially improve runtime efficiency, we progressively\nprune the candidate set using intermediate predictions, allowing our method to\nscale up to large candidate sets. Extensive experiments show that our method\nsignificantly improves group diversity and quality compared to independent\nsampling baselines and recent inference algorithms. Our framework generalizes\nacross a wide range of tasks, including text-to-image, image-to-image, image\nprompting, and video generation, enabling generative models to treat multiple\noutputs as cohesive groups rather than independent samples.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u7fa4\u4f53\u63a8\u7406\u65b9\u6cd5\uff0c\u63d0\u5347\u751f\u6210\u6837\u672c\u7684\u591a\u6837\u6027\u4e0e\u8d28\u91cf\uff0c\u89e3\u51b3\u72ec\u7acb\u91c7\u6837\u5bfc\u81f4\u7684\u5197\u4f59\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u7528\u6237\u901a\u5e38\u4f1a\u6536\u5230\u591a\u5f20\u56fe\u50cf\uff08\u59824-8\u5f20\uff09\uff0c\u72ec\u7acb\u91c7\u6837\u5bfc\u81f4\u7ed3\u679c\u5197\u4f59\uff0c\u9650\u5236\u4e86\u7528\u6237\u9009\u62e9\u548c\u521b\u610f\u63a2\u7d22\u3002", "method": "\u5c06\u7fa4\u4f53\u63a8\u7406\u5efa\u6a21\u4e3a\u4e8c\u6b21\u6574\u6570\u5206\u914d\u95ee\u9898\uff0c\u5019\u9009\u8f93\u51fa\u4f5c\u4e3a\u56fe\u8282\u70b9\uff0c\u4f18\u5316\u6837\u672c\u8d28\u91cf\u540c\u65f6\u6700\u5927\u5316\u7fa4\u4f53\u591a\u6837\u6027\uff0c\u5e76\u901a\u8fc7\u6e10\u8fdb\u526a\u679d\u63d0\u5347\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u7fa4\u4f53\u591a\u6837\u6027\u548c\u8d28\u91cf\uff0c\u9002\u7528\u4e8e\u6587\u672c\u5230\u56fe\u50cf\u3001\u56fe\u50cf\u5230\u56fe\u50cf\u3001\u56fe\u50cf\u63d0\u793a\u548c\u89c6\u9891\u751f\u6210\u7b49\u591a\u79cd\u4efb\u52a1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u751f\u6210\u6a21\u578b\u80fd\u5c06\u591a\u4e2a\u8f93\u51fa\u89c6\u4e3a\u7d27\u5bc6\u7fa4\u4f53\u800c\u975e\u72ec\u7acb\u6837\u672c\uff0c\u63d0\u5347\u5b9e\u7528\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.15576", "pdf": "https://arxiv.org/pdf/2508.15576", "abs": "https://arxiv.org/abs/2508.15576", "authors": ["Andreas L\u00f6\u00f6w", "Seung Hoon Park", "Daniele Nantes-Sobrinho", "Sacha-\u00c9lie Ayoun", "Opale Sj\u00f6stedt", "Philippa Gardner"], "title": "Compositional Symbolic Execution for the Next 700 Memory Models (Extended Version)", "categories": ["cs.PL"], "comment": null, "summary": "Multiple successful compositional symbolic execution (CSE) tools and\nplatforms exploit separation logic (SL) for compositional verification and/or\nincorrectness separation logic (ISL) for compositional bug-finding, including\nVeriFast, Viper, Gillian, CN, and Infer-Pulse. Previous work on the Gillian\nplatform, the only CSE platform that is parametric on the memory model, meaning\nthat it can be instantiated to different memory models, suggests that the\nability to use custom memory models allows for more flexibility in supporting\nanalysis of a wide range of programming languages, for implementing custom\nautomation, and for improving performance. However, the literature lacks a\nsatisfactory formal foundation for memory-model-parametric CSE platforms.\n  In this paper, inspired by Gillian, we provide a new formal foundation for\nmemory-model-parametric CSE platforms. Our foundation advances the state of the\nart in four ways. First, we mechanise our foundation (in the interactive\ntheorem prover Rocq). Second, we validate our foundation by instantiating it to\na broad range of memory models, including models for C and CHERI. Third,\nwhereas previous memory-model-parametric work has only covered SL analyses, we\ncover both SL and ISL analyses. Fourth, our foundation is based on standard\ndefinitions of SL and ISL (including definitions of function specification\nvalidity, to ensure sound interoperation with other tools and platforms also\nbased on standard definitions).", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u5185\u5b58\u6a21\u578b\u53c2\u6570\u5316\u7ec4\u5408\u7b26\u53f7\u6267\u884c\uff08CSE\uff09\u5e73\u53f0\u63d0\u4f9b\u4e86\u65b0\u7684\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u6280\u672f\uff0c\u652f\u6301\u591a\u79cd\u5185\u5b58\u6a21\u578b\uff0c\u6db5\u76d6\u5206\u79bb\u903b\u8f91\uff08SL\uff09\u548c\u4e0d\u6b63\u786e\u6027\u5206\u79bb\u903b\u8f91\uff08ISL\uff09\uff0c\u5e76\u57fa\u4e8e\u6807\u51c6\u5b9a\u4e49\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5185\u5b58\u6a21\u578b\u53c2\u6570\u5316CSE\u5e73\u53f0\u7684\u6ee1\u610f\u5f62\u5f0f\u5316\u57fa\u7840\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u5347\u7075\u6d3b\u6027\u5e76\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u8bed\u8a00\u5206\u6790\u3002", "method": "\u7814\u7a76\u8005\u5728Rocq\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5f62\u5f0f\u5316\u4e86\u65b0\u57fa\u7840\uff0c\u5e76\u5c06\u5176\u5b9e\u4f8b\u5316\u5230\u591a\u79cd\u5185\u5b58\u6a21\u578b\uff08\u5982C\u548cCHERI\uff09\uff0c\u540c\u65f6\u6db5\u76d6\u4e86SL\u548cISL\u5206\u6790\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u5185\u5b58\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u6269\u5c55\u4e86SL\u548cISL\u5206\u6790\u7684\u8303\u56f4\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5185\u5b58\u6a21\u578b\u53c2\u6570\u5316CSE\u5e73\u53f0\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4fc3\u8fdb\u4e86\u5de5\u5177\u4e92\u64cd\u4f5c\u6027\u548c\u5206\u6790\u7684\u7075\u6d3b\u6027\u3002"}}
{"id": "2508.15249", "pdf": "https://arxiv.org/pdf/2508.15249", "abs": "https://arxiv.org/abs/2508.15249", "authors": ["Alaul Islam", "Fairouz Grioui", "Raimund Dachselt", "Petra Isenberg"], "title": "Visualization on Smart Wristbands: Results from an In-situ Design Workshop with Four Scenarios", "categories": ["cs.HC"], "comment": "12 pages, 8 figures", "summary": "We present the results of an in-situ ideation workshop for designing data\nvisualizations on smart wristbands that can show data around the entire wrist\nof a wearer. Wristbands pose interesting challenges because the visibility of\ndifferent areas of the band depends on the wearer's arm posture. We focused on\nfour usage scenarios that lead to different postures: office work, leisurely\nwalks, cycling, and driving. As the technology for smart wristbands is not yet\ncommercially available, we conducted a paper-based ideation exercise that\nshowed how spatial layout and visualization design on smart wristbands may need\nto vary depending on the types of data items of interest and arm postures.\nParticipants expressed a strong preference for responsive visualization designs\nthat could adapt to the movement of wearers' arms. Supplemental material from\nthe study is available here: https://osf.io/4hrca/.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5de5\u4f5c\u574a\u63a2\u8ba8\u4e86\u667a\u80fd\u624b\u73af\u5728\u4e0d\u540c\u81c2\u59ff\u4e0b\u7684\u6570\u636e\u53ef\u89c6\u5316\u8bbe\u8ba1\uff0c\u53d1\u73b0\u7528\u6237\u504f\u597d\u81ea\u9002\u5e94\u81c2\u59ff\u7684\u53ef\u89c6\u5316\u65b9\u6848\u3002", "motivation": "\u667a\u80fd\u624b\u73af\u7684\u53ef\u89c6\u5316\u8bbe\u8ba1\u56e0\u81c2\u59ff\u4e0d\u540c\u800c\u9762\u4e34\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7eb8\u5f20\u7684\u6784\u601d\u7ec3\u4e60\uff0c\u5206\u6790\u4e0d\u540c\u4f7f\u7528\u573a\u666f\uff08\u5982\u529e\u516c\u3001\u6563\u6b65\uff09\u4e0b\u7684\u8bbe\u8ba1\u9700\u6c42\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7528\u6237\u66f4\u503e\u5411\u4e8e\u80fd\u81ea\u9002\u5e94\u81c2\u59ff\u7684\u53ef\u89c6\u5316\u8bbe\u8ba1\u3002", "conclusion": "\u667a\u80fd\u624b\u73af\u53ef\u89c6\u5316\u8bbe\u8ba1\u9700\u8003\u8651\u81c2\u59ff\u53d8\u5316\uff0c\u81ea\u9002\u5e94\u8bbe\u8ba1\u662f\u672a\u6765\u7684\u65b9\u5411\u3002"}}
{"id": "2508.14955", "pdf": "https://arxiv.org/pdf/2508.14955", "abs": "https://arxiv.org/abs/2508.14955", "authors": ["Samuel Yen-Chi Chen", "Prayag Tiwari"], "title": "Quantum Long Short-term Memory with Differentiable Architecture Search", "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.NE", "quant-ph"], "comment": "Accepted by the IEEE International Conference on Quantum Artificial\n  Intelligence (QAI) 2025", "summary": "Recent advances in quantum computing and machine learning have given rise to\nquantum machine learning (QML), with growing interest in learning from\nsequential data. Quantum recurrent models like QLSTM are promising for\ntime-series prediction, NLP, and reinforcement learning. However, designing\neffective variational quantum circuits (VQCs) remains challenging and often\ntask-specific. To address this, we propose DiffQAS-QLSTM, an end-to-end\ndifferentiable framework that optimizes both VQC parameters and architecture\nselection during training. Our results show that DiffQAS-QLSTM consistently\noutperforms handcrafted baselines, achieving lower loss across diverse test\nsettings. This approach opens the door to scalable and adaptive quantum\nsequence learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiffQAS-QLSTM\u7684\u53ef\u5fae\u5206\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u91cf\u5b50\u5faa\u73af\u6a21\u578b\u7684\u53d8\u5206\u91cf\u5b50\u7535\u8def\u53c2\u6570\u548c\u67b6\u6784\u9009\u62e9\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u624b\u52a8\u8bbe\u8ba1\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u53d8\u5206\u91cf\u5b50\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u4efb\u52a1\u7279\u5b9a\u6027\u548c\u6311\u6218\u6027\u95ee\u9898\uff0c\u63d0\u5347\u91cf\u5b50\u5e8f\u5217\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u5f00\u53d1\u4e86DiffQAS-QLSTM\uff0c\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u540c\u65f6\u4f18\u5316VQC\u53c2\u6570\u548c\u67b6\u6784\u9009\u62e9\u3002", "result": "DiffQAS-QLSTM\u5728\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u624b\u52a8\u8bbe\u8ba1\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u635f\u5931\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u7684\u91cf\u5b50\u5e8f\u5217\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2508.15436", "pdf": "https://arxiv.org/pdf/2508.15436", "abs": "https://arxiv.org/abs/2508.15436", "authors": ["Yutaro Oguri", "Mai Nishimura", "Yusuke Matsui"], "title": "On the Effectiveness of Graph Reordering for Accelerating Approximate Nearest Neighbor Search on GPU", "categories": ["cs.IR", "cs.CV", "cs.DB", "cs.DC", "cs.DS"], "comment": null, "summary": "We present the first systematic investigation of graph reordering effects for\ngraph-based Approximate Nearest Neighbor Search (ANNS) on a GPU. While\ngraph-based ANNS has become the dominant paradigm for modern AI applications,\nrecent approaches focus on algorithmic innovations while neglecting memory\nlayout considerations that significantly affect execution time. Our unified\nevaluation framework enables comprehensive evaluation of diverse reordering\nstrategies across different graph indices through a graph adapter that converts\narbitrary graph topologies into a common representation and a GPU-optimized\ngraph traversal engine. We conduct a comprehensive analysis across diverse\ndatasets and state-of-the-art graph indices, introducing analysis metrics that\nquantify the relationship between structural properties and memory layout\neffectiveness. Our GPU-targeted reordering achieves up to 15$\\%$ QPS\nimprovements while preserving search accuracy, demonstrating that memory layout\noptimization operates orthogonally to existing algorithmic innovations. We will\nrelease all code upon publication to facilitate reproducibility and foster\nfurther research.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86GPU\u4e0a\u57fa\u4e8e\u56fe\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff08ANNS\uff09\u7684\u56fe\u91cd\u6392\u5e8f\u6548\u679c\uff0c\u901a\u8fc7\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u548cGPU\u4f18\u5316\u7684\u56fe\u904d\u5386\u5f15\u64ce\uff0c\u5c55\u793a\u4e86\u5185\u5b58\u5e03\u5c40\u4f18\u5316\u5bf9\u6027\u80fd\u7684\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u56fe\u7684ANNS\u5df2\u6210\u4e3a\u73b0\u4ee3AI\u5e94\u7528\u7684\u4e3b\u5bfc\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u7b97\u6cd5\u521b\u65b0\uff0c\u5ffd\u7565\u4e86\u663e\u8457\u5f71\u54cd\u6267\u884c\u65f6\u95f4\u7684\u5185\u5b58\u5e03\u5c40\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u56fe\u9002\u914d\u5668\u548cGPU\u4f18\u5316\u7684\u56fe\u904d\u5386\u5f15\u64ce\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u4e0d\u540c\u56fe\u7d22\u5f15\u7684\u591a\u6837\u5316\u91cd\u6392\u5e8f\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9488\u5bf9GPU\u7684\u91cd\u6392\u5e8f\u7b56\u7565\u53ef\u5728\u4fdd\u6301\u641c\u7d22\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5c06QPS\u63d0\u5347\u9ad8\u8fbe15%\u3002", "conclusion": "\u5185\u5b58\u5e03\u5c40\u4f18\u5316\u4e0e\u73b0\u6709\u7b97\u6cd5\u521b\u65b0\u6b63\u4ea4\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u6240\u6709\u4ee3\u7801\u5c06\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.15750", "pdf": "https://arxiv.org/pdf/2508.15750", "abs": "https://arxiv.org/abs/2508.15750", "authors": ["Celeste Barnaby", "Qiaochu Chen", "Ramya Ramalingam", "Osbert Bastani", "Isil Dillig"], "title": "Active Learning for Neurosymbolic Program Synthesis", "categories": ["cs.PL"], "comment": null, "summary": "The goal of active learning for program synthesis is to synthesize the\ndesired program by asking targeted questions that minimize user interaction.\nWhile prior work has explored active learning in the purely symbolic setting,\nsuch techniques are inadequate for the increasingly popular paradigm of\nneurosymbolic program synthesis, where the synthesized program incorporates\nneural components. When applied to the neurosymbolic setting, such techniques\ncan -- and, in practice, do -- return an unintended program due to\nmispredictions of neural components. This paper proposes a new active learning\ntechnique that can handle the unique challenges posed by neural network\nmispredictions. Our approach is based upon a new evaluation strategy called\nconstrained conformal evaluation (CCE), which accounts for neural\nmispredictions while taking into account user-provided feedback. Our proposed\nmethod iteratively makes CCE more precise until all remaining programs are\nguaranteed to be observationally equivalent. We have implemented this method in\na tool called SmartLabel and experimentally evaluated it on three neurosymbolic\ndomains. Our results demonstrate that SmartLabel identifies the ground truth\nprogram for 98% of the benchmarks, requiring under 5 rounds of user interaction\non average. In contrast, prior techniques for active learning are only able to\nconverge to the ground truth program for at most 65% of the benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e3b\u52a8\u5b66\u4e60\u6280\u672f\uff0c\u7528\u4e8e\u5904\u7406\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u5408\u6210\u4e2d\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u9519\u8bef\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7SmartLabel\u5de5\u5177\u5728\u4e09\u4e2a\u9886\u57df\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u5408\u6210\u4e2d\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u9519\u8bef\u5bfc\u81f4\u7684\u4e3b\u52a8\u5b66\u4e60\u6280\u672f\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u53d7\u9650\u7b26\u5408\u8bc4\u4f30(CCE)\u7684\u65b0\u7b56\u7565\uff0c\u7ed3\u5408\u7528\u6237\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\uff0c\u786e\u4fdd\u6700\u7ec8\u7a0b\u5e8f\u7684\u7b49\u4ef7\u6027\u3002", "result": "SmartLabel\u572898%\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6210\u529f\u8bc6\u522b\u771f\u5b9e\u7a0b\u5e8f\uff0c\u5e73\u5747\u4ea4\u4e92\u6b21\u6570\u4f4e\u4e8e5\u6b21\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u5408\u6210\u4e2d\u7684\u4e3b\u52a8\u5b66\u4e60\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.15258", "pdf": "https://arxiv.org/pdf/2508.15258", "abs": "https://arxiv.org/abs/2508.15258", "authors": ["Dooyoung Kim", "Woontack Woo"], "title": "Spatio-Temporal Mixed and Augmented Reality Experience Description for Interactive Playback", "categories": ["cs.HC"], "comment": "4 pages, 2 figures, Accepted in the IEEE ISMAR 2025 XRStand Workshop", "summary": "We propose the Spatio-Temporal Mixed and Augmented Reality Experience\nDescription (MAR-ED), a novel framework to standardize the representation of\npast events for interactive and adaptive playback in a user's present physical\nspace. While current spatial media technologies have primarily focused on\ncapturing or replaying content as static assets, often disconnected from the\nviewer's environment or offering limited interactivity, the means to describe\nan experience's underlying semantic and interactive structure remains\nunderexplored. We propose a descriptive framework called MAR-ED based on three\ncore primitives: 1) Event Primitives for semantic scene graph representation,\n2) Keyframe Primitives for efficient and meaningful data access, and 3)\nPlayback Primitives for user-driven adaptive interactive playback of recorded\nMAR experience. The proposed flowchart of the three-stage process of the\nproposed MAR-ED framework transforms a recorded experience into a unique\nadaptive MAR experience during playback, where its spatio-temporal structure\ndynamically conforms to a new environment and its narrative can be altered by\nlive user input. Drawing on this framework, personal digital memories and\nrecorded events can evolve beyond passive 2D/3D videos into immersive,\nspatially-integrated group experiences, opening new paradigms for training,\ncultural heritage, and interactive storytelling without requiring complex,\nper-user adaptive rendering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMAR-ED\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u6807\u51c6\u5316\u63cf\u8ff0\u8fc7\u53bb\u4e8b\u4ef6\u7684\u65f6\u7a7a\u6df7\u5408\u548c\u589e\u5f3a\u73b0\u5b9e\u4f53\u9a8c\uff0c\u4ee5\u652f\u6301\u7528\u6237\u5728\u5f53\u524d\u7269\u7406\u7a7a\u95f4\u4e2d\u7684\u4ea4\u4e92\u5f0f\u81ea\u9002\u5e94\u56de\u653e\u3002", "motivation": "\u5f53\u524d\u7a7a\u95f4\u5a92\u4f53\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u5185\u5bb9\u7684\u6355\u6349\u6216\u56de\u653e\uff0c\u7f3a\u4e4f\u4e0e\u73af\u5883\u4e92\u52a8\u6216\u8bed\u4e49\u7ed3\u6784\u7684\u63cf\u8ff0\uff0cMAR-ED\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u57fa\u4e8e\u4e09\u4e2a\u6838\u5fc3\u539f\u8bed\uff1a\u4e8b\u4ef6\u539f\u8bed\uff08\u8bed\u4e49\u573a\u666f\u56fe\u8868\u793a\uff09\u3001\u5173\u952e\u5e27\u539f\u8bed\uff08\u9ad8\u6548\u6570\u636e\u8bbf\u95ee\uff09\u548c\u56de\u653e\u539f\u8bed\uff08\u7528\u6237\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u4e92\u52a8\u56de\u653e\uff09\uff0c\u5b9e\u73b0\u8bb0\u5f55\u4f53\u9a8c\u5230\u81ea\u9002\u5e94MAR\u4f53\u9a8c\u7684\u8f6c\u6362\u3002", "result": "MAR-ED\u6846\u67b6\u80fd\u591f\u52a8\u6001\u9002\u5e94\u65b0\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u8f93\u5165\u8c03\u6574\u53d9\u4e8b\uff0c\u5c06\u6570\u5b57\u8bb0\u5fc6\u548c\u8bb0\u5f55\u4e8b\u4ef6\u5347\u7ea7\u4e3a\u6c89\u6d78\u5f0f\u7684\u96c6\u4f53\u4f53\u9a8c\u3002", "conclusion": "MAR-ED\u4e3a\u57f9\u8bad\u3001\u6587\u5316\u9057\u4ea7\u548c\u4ea4\u4e92\u5f0f\u53d9\u4e8b\u7b49\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u65e0\u9700\u590d\u6742\u7684\u81ea\u9002\u5e94\u6e32\u67d3\u3002"}}
{"id": "2508.15110", "pdf": "https://arxiv.org/pdf/2508.15110", "abs": "https://arxiv.org/abs/2508.15110", "authors": ["Graham Hill", "JingYuan Gong", "Thulani Babeli", "Moseli Mots'oehli", "James Gachomo Wanjiku"], "title": "LLMs and Agentic AI in Insurance Decision-Making: Opportunities and Challenges For Africa", "categories": ["cs.CE", "cs.CL", "cs.ET", "stat.AP"], "comment": null, "summary": "In this work, we highlight the transformative potential of Artificial\nIntelligence (AI), particularly Large Language Models (LLMs) and agentic AI, in\nthe insurance sector. We consider and emphasize the unique opportunities,\nchallenges, and potential pathways in insurance amid rapid performance\nimprovements, increased open-source access, decreasing deployment costs, and\nthe complexity of LLM or agentic AI frameworks. To bring it closer to home, we\nidentify critical gaps in the African insurance market and highlight key local\nefforts, players, and partnership opportunities. Finally, we call upon\nactuaries, insurers, regulators, and tech leaders to a collaborative effort\naimed at creating inclusive, sustainable, and equitable AI strategies and\nsolutions: by and for Africans.", "AI": {"tldr": "\u63a2\u8ba8AI\uff08\u5c24\u5176\u662fLLMs\u548c\u667a\u80fd\u4ee3\u7406AI\uff09\u5728\u4fdd\u9669\u4e1a\u7684\u53d8\u9769\u6f5c\u529b\uff0c\u5206\u6790\u673a\u9047\u4e0e\u6311\u6218\uff0c\u5e76\u9488\u5bf9\u975e\u6d32\u5e02\u573a\u63d0\u51fa\u5408\u4f5c\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76AI\u5728\u4fdd\u9669\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u975e\u6d32\u5e02\u573a\u7684\u72ec\u7279\u9700\u6c42\u548c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5206\u6790AI\u6280\u672f\u7684\u53d1\u5c55\u8d8b\u52bf\u548c\u73b0\u72b6\uff0c\u7ed3\u5408\u975e\u6d32\u4fdd\u9669\u5e02\u573a\u7684\u5177\u4f53\u95ee\u9898\u3002", "result": "\u63d0\u51faAI\u6280\u672f\u53ef\u4e3a\u975e\u6d32\u4fdd\u9669\u4e1a\u5e26\u6765\u53d8\u9769\uff0c\u5e76\u547c\u5401\u591a\u65b9\u5408\u4f5c\u5f00\u53d1\u672c\u5730\u5316\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u547c\u5401\u884c\u4e1a\u591a\u65b9\u534f\u4f5c\uff0c\u4e3a\u975e\u6d32\u4fdd\u9669\u5e02\u573a\u5f00\u53d1\u53ef\u6301\u7eed\u3001\u5305\u5bb9\u7684AI\u7b56\u7565\u3002"}}
{"id": "2508.15010", "pdf": "https://arxiv.org/pdf/2508.15010", "abs": "https://arxiv.org/abs/2508.15010", "authors": ["Sami Alabed", "Dominik Grewe", "Norman Alexander Rink", "Timur Sitdikov", "Agnieszka Swietlik", "Dimitrios Vytiniotis", "Daniel Belov"], "title": "TOAST: Fast and scalable auto-partitioning based on principled static analysis", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Partitioning large machine learning models across distributed accelerator\nsystems is a complex process, requiring a series of interdependent decisions\nthat are further complicated by internal sharding ambiguities. Consequently,\nexisting auto-partitioners often suffer from out-of-memory errors or are\nprohibitively slow when exploring the exponentially large space of possible\npartitionings. To mitigate this, they artificially restrict the search space,\nbut this approach frequently yields infeasible solutions that violate device\nmemory constraints or lead to sub-optimal performance.\n  We propose a system that combines a novel static compiler analysis with a\nMonte Carlo Tree Search. Our analysis constructs an efficient decision space by\nidentifying (i) tensor dimensions requiring identical sharding, and (ii)\npartitioning \"conflicts\" that require resolution.\n  Our system significantly outperforms state-of-the-art industrial methods\nacross diverse hardware platforms and model architectures, discovering\npreviously unknown, superior solutions, and the process is fully automated even\nfor complex and large models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9759\u6001\u7f16\u8bd1\u5668\u5206\u6790\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u9ad8\u6548\u5206\u533a\u5927\u578b\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4f18\u4e8e\u73b0\u6709\u5de5\u4e1a\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5206\u533a\u5668\u5728\u63a2\u7d22\u6307\u6570\u7ea7\u5927\u7684\u5206\u533a\u7a7a\u95f4\u65f6\uff0c\u5e38\u56e0\u5185\u5b58\u4e0d\u8db3\u6216\u901f\u5ea6\u8fc7\u6162\u800c\u53d7\u9650\uff0c\u4e14\u4eba\u4e3a\u9650\u5236\u641c\u7d22\u7a7a\u95f4\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u884c\u6216\u6b21\u4f18\u7684\u89e3\u3002", "method": "\u7ed3\u5408\u9759\u6001\u7f16\u8bd1\u5668\u5206\u6790\u6784\u5efa\u9ad8\u6548\u51b3\u7b56\u7a7a\u95f4\uff0c\u8bc6\u522b\u9700\u8981\u76f8\u540c\u5206\u533a\u7684\u5f20\u91cf\u7ef4\u5ea6\u548c\u5206\u533a\u51b2\u7a81\uff0c\u5e76\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u5206\u533a\u7b56\u7565\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u591a\u6837\u786c\u4ef6\u5e73\u53f0\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u663e\u8457\u4f18\u4e8e\u5de5\u4e1a\u754c\u6700\u65b0\u65b9\u6cd5\uff0c\u53d1\u73b0\u65b0\u7684\u4f18\u8d28\u89e3\uff0c\u4e14\u8fc7\u7a0b\u5168\u81ea\u52a8\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u4e3a\u5927\u578b\u6a21\u578b\u5206\u533a\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.15386", "pdf": "https://arxiv.org/pdf/2508.15386", "abs": "https://arxiv.org/abs/2508.15386", "authors": ["Sabine Houy", "Bruno Kreyssig", "Timothee Riom", "Alexandre Bartel", "Patrick McDaniel"], "title": "A Practical Guideline and Taxonomy to LLVM's Control Flow Integrity", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Memory corruption vulnerabilities remain one of the most severe threats to\nsoftware security. They often allow attackers to achieve arbitrary code\nexecution by redirecting a vulnerable program's control flow. While Control\nFlow Integrity (CFI) has gained traction to mitigate this exploitation path,\ndevelopers are not provided with any direction on how to apply CFI to\nreal-world software. In this work, we establish a taxonomy mapping LLVM's\nforward-edge CFI variants to memory corruption vulnerability classes, offering\nactionable guidance for developers seeking to deploy CFI incrementally in\nexisting codebases. Based on the Top 10 Known Exploited Vulnerabilities (KEV)\nlist, we identify four high-impact vulnerability categories and select one\nrepresentative CVE for each. We evaluate LLVM's CFI against each CVE and\nexplain why CFI blocks exploitation in two cases while failing in the other\ntwo, illustrating its potential and current limitations. Our findings support\ninformed deployment decisions and provide a foundation for improving the\npractical use of CFI in production systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86LLVM\u7684\u524d\u5411\u8fb9\u7f18CFI\u53d8\u4f53\u5bf9\u5185\u5b58\u635f\u574f\u6f0f\u6d1e\u7684\u9632\u5fa1\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6f0f\u6d1e\u6848\u4f8b\u8bc4\u4f30\u5176\u6709\u6548\u6027\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002", "motivation": "\u5185\u5b58\u635f\u574f\u6f0f\u6d1e\u662f\u8f6f\u4ef6\u5b89\u5168\u7684\u91cd\u8981\u5a01\u80c1\uff0c\u4f46\u73b0\u6709\u7684CFI\u6280\u672f\u7f3a\u4e4f\u5177\u4f53\u90e8\u7f72\u6307\u5bfc\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u57fa\u4e8eTop 10 KEV\u5217\u8868\uff0c\u9009\u53d6\u56db\u7c7b\u4ee3\u8868\u6027\u6f0f\u6d1e\uff0c\u8bc4\u4f30LLVM\u7684CFI\u53d8\u4f53\u5bf9\u6bcf\u7c7b\u6f0f\u6d1e\u7684\u9632\u5fa1\u6548\u679c\u3002", "result": "CFI\u5728\u4e24\u7c7b\u6f0f\u6d1e\u4e2d\u6210\u529f\u963b\u6b62\u653b\u51fb\uff0c\u4f46\u5728\u53e6\u5916\u4e24\u7c7b\u4e2d\u5931\u6548\uff0c\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86CFI\u7684\u5b9e\u7528\u90e8\u7f72\u5efa\u8bae\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u6539\u8fdbCFI\u7684\u5b9e\u9645\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.15716", "pdf": "https://arxiv.org/pdf/2508.15716", "abs": "https://arxiv.org/abs/2508.15716", "authors": ["Hongqi Li", "Yitong Chen", "Yujuan Wang", "Weihang Ni", "Haodong Zhang"], "title": "Foundation Models for Cross-Domain EEG Analysis Application: A Survey", "categories": ["cs.HC", "cs.AI"], "comment": "Submitted to IEEE Journals", "summary": "Electroencephalography (EEG) analysis stands at the forefront of neuroscience\nand artificial intelligence research, where foundation models are reshaping the\ntraditional EEG analysis paradigm by leveraging their powerful representational\ncapacity and cross-modal generalization. However, the rapid proliferation of\nthese techniques has led to a fragmented research landscape, characterized by\ndiverse model roles, inconsistent architectures, and a lack of systematic\ncategorization. To bridge this gap, this study presents the first comprehensive\nmodality-oriented taxonomy for foundation models in EEG analysis,\nsystematically organizing research advances based on output modalities of the\nnative EEG decoding, EEG-text, EEG-vision, EEG-audio, and broader multimodal\nframeworks. We rigorously analyze each category's research ideas, theoretical\nfoundations, and architectural innovations, while highlighting open challenges\nsuch as model interpretability, cross-domain generalization, and real-world\napplicability in EEG-based systems. By unifying this dispersed field, our work\nnot only provides a reference framework for future methodology development but\naccelerates the translation of EEG foundation models into scalable,\ninterpretable, and online actionable solutions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u6001\u7684\u5206\u7c7b\u7cfb\u7edf\uff0c\u7528\u4e8eEEG\u5206\u6790\u4e2d\u7684\u57fa\u7840\u6a21\u578b\uff0c\u6db5\u76d6EEG\u89e3\u7801\u3001EEG\u6587\u672c\u3001EEG\u89c6\u89c9\u3001EEG\u97f3\u9891\u53ca\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4e86\u5f00\u653e\u6311\u6218\u5982\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u5f53\u524dEEG\u5206\u6790\u4e2d\u57fa\u7840\u6a21\u578b\u7684\u7814\u7a76\u5206\u6563\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5206\u7c7b\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u4ee5\u4fc3\u8fdb\u65b9\u6cd5\u5f00\u53d1\u548c\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f93\u51fa\u6a21\u6001\u7684\u5206\u7c7b\u6cd5\uff0c\u7cfb\u7edf\u6574\u7406\u4e86EEG\u57fa\u7840\u6a21\u578b\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5e76\u5206\u6790\u4e86\u5404\u7c7b\u522b\u7684\u8bbe\u8ba1\u601d\u60f3\u548c\u7406\u8bba\u4f9d\u636e\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2a\u5168\u9762\u7684EEG\u57fa\u7840\u6a21\u578b\u5206\u7c7b\u4f53\u7cfb\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5206\u7c7b\uff0c\u8be5\u7814\u7a76\u4fc3\u8fdb\u4e86EEG\u57fa\u7840\u6a21\u578b\u5411\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u5b9e\u9645\u5e94\u7528\u7684\u8f6c\u5316\u3002"}}
{"id": "2508.15451", "pdf": "https://arxiv.org/pdf/2508.15451", "abs": "https://arxiv.org/abs/2508.15451", "authors": ["H. I. Nurdin", "C. A. Nijhuis"], "title": "A Solvable Molecular Switch Model for Stable Temporal Information Processing", "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "comment": "21 pages, 6 figures, submitted for publication. Comments are welcome", "summary": "This paper studies an input-driven one-state differential equation model\ninitially developed for an experimentally demonstrated dynamic molecular switch\nthat switches like synapses in the brain do. The linear-in-the-state and\nnonlinear-in-the-input model is exactly solvable, and it is shown that it also\npossesses mathematical properties of convergence and fading memory that enable\nstable processing of time-varying inputs by nonlinear dynamical systems. Thus,\nthe model exhibits the co-existence of biologically-inspired behavior and\ndesirable mathematical properties for stable learning on sequential data. The\nresults give theoretical support for the use of the dynamic molecular switches\nas computational units in deep cascaded/layered feedforward and recurrent\narchitectures as well as other more general structures for neuromorphic\ncomputing. They could also inspire more general exactly solvable models that\ncan be fitted to emulate arbitrary physical devices which can mimic\nbrain-inspired behaviour and perform stable computation on input signals.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u8f93\u5165\u9a71\u52a8\u7684\u5355\u72b6\u6001\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6700\u521d\u4e3a\u52a8\u6001\u5206\u5b50\u5f00\u5173\u8bbe\u8ba1\uff0c\u5177\u6709\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7279\u6027\uff0c\u80fd\u591f\u7a33\u5b9a\u5904\u7406\u65f6\u53d8\u8f93\u5165\uff0c\u5e76\u652f\u6301\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u52a8\u6001\u5206\u5b50\u5f00\u5173\u7684\u6570\u5b66\u6a21\u578b\uff0c\u9a8c\u8bc1\u5176\u5728\u7a33\u5b9a\u5b66\u4e60\u548c\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7ed3\u5408\u7684\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\uff0c\u5206\u6790\u5176\u6536\u655b\u6027\u548c\u8bb0\u5fc6\u7279\u6027\u3002", "result": "\u6a21\u578b\u5c55\u793a\u4e86\u751f\u7269\u5b66\u542f\u53d1\u7684\u884c\u4e3a\u4e0e\u6570\u5b66\u7a33\u5b9a\u6027\u7684\u5171\u5b58\uff0c\u9002\u7528\u4e8e\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u52a8\u6001\u5206\u5b50\u5f00\u5173\u5728\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u53ef\u80fd\u542f\u53d1\u66f4\u591a\u53ef\u6c42\u89e3\u7684\u6a21\u578b\u3002"}}
{"id": "2508.15158", "pdf": "https://arxiv.org/pdf/2508.15158", "abs": "https://arxiv.org/abs/2508.15158", "authors": ["Md. Nurul Absur", "Abhinav Kumar", "Swastik Brahma", "Saptarshi Debroy"], "title": "Reliable Multi-view 3D Reconstruction for `Just-in-time' Edge Environments", "categories": ["cs.CV", "cs.DC"], "comment": "11 Pages, 7 Figures", "summary": "Multi-view 3D reconstruction applications are revolutionizing critical use\ncases that require rapid situational-awareness, such as emergency response,\ntactical scenarios, and public safety. In many cases, their near-real-time\nlatency requirements and ad-hoc needs for compute resources necessitate\nadoption of `Just-in-time' edge environments where the system is set up on the\nfly to support the applications during the mission lifetime. However,\nreliability issues can arise from the inherent dynamism and operational\nadversities of such edge environments, resulting in spatiotemporally correlated\ndisruptions that impact the camera operations, which can lead to sustained\ndegradation of reconstruction quality. In this paper, we propose a novel\nportfolio theory inspired edge resource management strategy for reliable\nmulti-view 3D reconstruction against possible system disruptions. Our proposed\nmethodology can guarantee reconstruction quality satisfaction even when the\ncameras are prone to spatiotemporally correlated disruptions. The portfolio\ntheoretic optimization problem is solved using a genetic algorithm that\nconverges quickly for realistic system settings. Using publicly available and\ncustomized 3D datasets, we demonstrate the proposed camera selection strategy's\nbenefits in guaranteeing reliable 3D reconstruction against traditional\nbaseline strategies, under spatiotemporal disruptions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6295\u8d44\u7ec4\u5408\u7406\u8bba\u7684\u8fb9\u7f18\u8d44\u6e90\u7ba1\u7406\u7b56\u7565\uff0c\u7528\u4e8e\u5728\u591a\u89c6\u56fe3D\u91cd\u5efa\u4e2d\u5e94\u5bf9\u53ef\u80fd\u7684\u7cfb\u7edf\u4e2d\u65ad\uff0c\u4fdd\u8bc1\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001\u8fb9\u7f18\u73af\u5883\u4e2d\u56e0\u76f8\u673a\u64cd\u4f5c\u4e2d\u65ad\u5bfc\u81f4\u7684\u591a\u89c6\u56fe3D\u91cd\u5efa\u8d28\u91cf\u6301\u7eed\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6295\u8d44\u7ec4\u5408\u7406\u8bba\u542f\u53d1\u7684\u8d44\u6e90\u7ba1\u7406\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u5feb\u901f\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u76f8\u673a\u9009\u62e9\u7b56\u7565\u5728\u65f6\u7a7a\u76f8\u5173\u4e2d\u65ad\u4e0b\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u53ef\u9760\u4fdd\u8bc13D\u91cd\u5efa\u8d28\u91cf\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u89c6\u56fe3D\u91cd\u5efa\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u8fb9\u7f18\u73af\u5883\u3002"}}
{"id": "2508.15555", "pdf": "https://arxiv.org/pdf/2508.15555", "abs": "https://arxiv.org/abs/2508.15555", "authors": ["Ruiyu Zhang", "Lin Nie", "Xin Zhao"], "title": "HEAS: Hierarchical Evolutionary Agent Simulation Framework for Cross-Scale Modeling and Multi-Objective Search", "categories": ["cs.MA", "cs.CE", "cs.LG", "cs.NE", "cs.SE"], "comment": "9 pages, 1 figure", "summary": "Hierarchical Evolutionary Agent Simulation (HEAS) is a Python framework that\nunifies layered agent-based modeling with evolutionary optimization and\ntournament evaluation in a single, reproducible workflow. HEAS represents\nmodels as hierarchies of lightweight processes (\"streams\") scheduled in\ndeterministic layers that read and write a shared context, making cross-scale\ncouplings explicit and auditable. A compact API and CLI-simulate, optimize,\nevaluate-expose single- and multi-objective evolution, PyTorch policy\nintegration via parameter flattening/unflattening, and general tournament\ntooling with user-defined scoring and voting rules. The framework standardizes\nevaluation through uniform per-step and episode metrics, persists seeds,\nlogbooks, and hall-of-fame archives, and provides plotting helpers for traces,\nPareto fronts, and comparative outcomes, reducing glue code and improving\ncomparability across studies. HEAS emphasizes separation of mechanism from\norchestration, allowing exogenous drivers, endogenous agents, and aggregators\nto be composed and swapped without refactoring, while the same model can be\nused for forward simulation, optimization, or systematic comparison. We\nillustrate usage with two compact examples-an ecological system and an\nenterprise decision-making setting. HEAS offers a practical foundation for\ncross-disciplinary, multi-level inquiry, yielding reliable, reproducible\nresults.", "AI": {"tldr": "HEAS\u662f\u4e00\u4e2aPython\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5206\u5c42\u4ee3\u7406\u5efa\u6a21\u3001\u8fdb\u5316\u4f18\u5316\u548c\u6bd4\u8d5b\u8bc4\u4f30\uff0c\u63d0\u4f9b\u7edf\u4e00\u4e14\u53ef\u91cd\u590d\u7684\u5de5\u4f5c\u6d41\u3002", "motivation": "\u89e3\u51b3\u8de8\u5c3a\u5ea6\u5efa\u6a21\u4e2d\u7684\u8026\u5408\u95ee\u9898\uff0c\u63d0\u9ad8\u53ef\u5ba1\u8ba1\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u91c7\u7528\u5206\u5c42\u8f7b\u91cf\u7ea7\u8fdb\u7a0b\uff08\"streams\"\uff09\u548c\u5171\u4eab\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u5355\u76ee\u6807/\u591a\u76ee\u6807\u8fdb\u5316\u3001PyTorch\u7b56\u7565\u96c6\u6210\u53ca\u7528\u6237\u5b9a\u4e49\u7684\u6bd4\u8d5b\u89c4\u5219\u3002", "result": "\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u6307\u6807\u3001\u5b58\u6863\u529f\u80fd\u548c\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u51cf\u5c11\u4ee3\u7801\u91cd\u590d\u5e76\u63d0\u9ad8\u7814\u7a76\u95f4\u7684\u53ef\u6bd4\u6027\u3002", "conclusion": "HEAS\u4e3a\u8de8\u5b66\u79d1\u3001\u591a\u5c42\u7ea7\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u751f\u6210\u53ef\u9760\u4e14\u53ef\u91cd\u590d\u7684\u7ed3\u679c\u3002"}}
{"id": "2508.15727", "pdf": "https://arxiv.org/pdf/2508.15727", "abs": "https://arxiv.org/abs/2508.15727", "authors": ["Hannah Selder", "Florian Fischer", "Per Ola Kristensson", "Arthur Fleig"], "title": "Demystifying Reward Design in Reinforcement Learning for Upper Extremity Interaction: Practical Guidelines for Biomechanical Simulations in HCI", "categories": ["cs.HC", "H.5.2; F.m"], "comment": "17 pages, 14 figures, 1 table, ACM UIST 2025", "summary": "Designing effective reward functions is critical for reinforcement\nlearning-based biomechanical simulations, yet HCI researchers and practitioners\noften waste (computation) time with unintuitive trial-and-error tuning. This\npaper demystifies reward function design by systematically analyzing the impact\nof effort minimization, task completion bonuses, and target proximity\nincentives on typical HCI tasks such as pointing, tracking, and choice\nreaction. We show that proximity incentives are essential for guiding movement,\nwhile completion bonuses ensure task success. Effort terms, though optional,\nhelp refine motion regularity when appropriately scaled. We perform an\nextensive analysis of how sensitive task success and completion time depend on\nthe weights of these three reward components. From these results we derive\npractical guidelines to create plausible biomechanical simulations without the\nneed for reinforcement learning expertise, which we then validate on remote\ncontrol and keyboard typing tasks. This paper advances simulation-based\ninteraction design and evaluation in HCI by improving the efficiency and\napplicability of biomechanical user modeling for real-world interface\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u5bf9HCI\u4efb\u52a1\uff08\u5982\u6307\u5411\u3001\u8ddf\u8e2a\u548c\u9009\u62e9\u53cd\u5e94\uff09\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4f18\u5316\u751f\u7269\u529b\u5b66\u6a21\u62df\u7684\u5b9e\u7528\u6307\u5357\u3002", "motivation": "\u4e3a\u4e86\u51cf\u5c11HCI\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u5728\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u65f6\u7684\u65f6\u95f4\u548c\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u7cfb\u7edf\u65b9\u6cd5\u4f18\u5316\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u3002", "method": "\u7cfb\u7edf\u5730\u5206\u6790\u4e86\u52aa\u529b\u6700\u5c0f\u5316\u3001\u4efb\u52a1\u5b8c\u6210\u5956\u52b1\u548c\u76ee\u6807\u63a5\u8fd1\u6fc0\u52b1\u5bf9HCI\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u5956\u52b1\u7ec4\u4ef6\u7684\u6743\u91cd\u5bf9\u4efb\u52a1\u6210\u529f\u548c\u5b8c\u6210\u65f6\u95f4\u7684\u654f\u611f\u6027\u3002", "result": "\u53d1\u73b0\u63a5\u8fd1\u6fc0\u52b1\u5bf9\u5f15\u5bfc\u8fd0\u52a8\u81f3\u5173\u91cd\u8981\uff0c\u4efb\u52a1\u5b8c\u6210\u5956\u52b1\u786e\u4fdd\u4efb\u52a1\u6210\u529f\uff0c\u800c\u9002\u5f53\u7f29\u653e\u7684\u52aa\u529b\u9879\u6709\u52a9\u4e8e\u63d0\u5347\u52a8\u4f5c\u89c4\u5f8b\u6027\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u4f18\u5316\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\uff0c\u63d0\u5347\u4e86\u751f\u7269\u529b\u5b66\u7528\u6237\u6a21\u578b\u5728\u771f\u5b9e\u754c\u9762\u5f00\u53d1\u4e2d\u7684\u6548\u7387\u548c\u9002\u7528\u6027\uff0c\u63a8\u52a8\u4e86\u57fa\u4e8e\u6a21\u62df\u7684HCI\u8bbe\u8ba1\u548c\u8bc4\u4f30\u3002"}}
{"id": "2508.15267", "pdf": "https://arxiv.org/pdf/2508.15267", "abs": "https://arxiv.org/abs/2508.15267", "authors": ["Ruilin Zhou", "Jinglei Cheng", "Yuhang Gan", "Junyu Liu", "Chen Qian"], "title": "Optimizing Compilation for Distributed Quantum Computing via Clustering and Annealing", "categories": ["quant-ph", "cs.DC"], "comment": null, "summary": "Efficiently mapping quantum programs onto Distributed quantum computing (DQC)\nare challenging, particularly when considering the heterogeneous quantum\nprocessing units (QPUs) with different structures. In this paper, we present a\ncomprehensive compilation framework that addresses these challenges with three\nkey insights: exploiting structural patterns within quantum circuits, using\nclustering for initial qubit placement, and adjusting qubit mapping with\nannealing algorithms. Experimental results demonstrate the effectiveness of our\nmethods and the capability to handle complex heterogeneous distributed quantum\nsystems. Our evaluation shows that our method reduces the objective value at\nmost 88.40\\% compared to the baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\uff08DQC\uff09\u7684\u7f16\u8bd1\u6846\u67b6\uff0c\u901a\u8fc7\u7535\u8def\u7ed3\u6784\u5206\u6790\u3001\u805a\u7c7b\u548c\u9000\u706b\u7b97\u6cd5\u4f18\u5316\u91cf\u5b50\u7a0b\u5e8f\u6620\u5c04\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u3002", "motivation": "\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u7cfb\u7edf\u4e2d\uff0c\u7531\u4e8e\u91cf\u5b50\u5904\u7406\u5355\u5143\uff08QPUs\uff09\u7684\u5f02\u6784\u6027\uff0c\u9ad8\u6548\u6620\u5c04\u91cf\u5b50\u7a0b\u5e8f\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7f16\u8bd1\u6846\u67b6\uff0c\u5229\u7528\u7535\u8def\u7ed3\u6784\u6a21\u5f0f\u5206\u6790\u3001\u521d\u59cb\u91cf\u5b50\u6bd4\u7279\u653e\u7f6e\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u4ee5\u53ca\u9000\u706b\u7b97\u6cd5\u8c03\u6574\u91cf\u5b50\u6bd4\u7279\u6620\u5c04\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5904\u7406\u590d\u6742\u7684\u5f02\u6784\u5206\u5e03\u5f0f\u91cf\u5b50\u7cfb\u7edf\uff0c\u76ee\u6807\u503c\u6700\u591a\u964d\u4f4e\u4e8688.40%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f02\u6784\u5206\u5e03\u5f0f\u91cf\u5b50\u7cfb\u7edf\u7684\u7a0b\u5e8f\u6620\u5c04\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15752", "pdf": "https://arxiv.org/pdf/2508.15752", "abs": "https://arxiv.org/abs/2508.15752", "authors": ["Jon E. Froehlich", "Jared Hwang", "Zeyu Wang", "John S. O'Meara", "Xia Su", "William Huang", "Yang Zhang", "Alex Fiannaca", "Philip Nelson", "Shaun Kane"], "title": "\"Does the cafe entrance look accessible? Where is the door?\" Towards Geospatial AI Agents for Visual Inquiries", "categories": ["cs.HC", "cs.AI", "cs.CV", "H.5; I.2"], "comment": "Accepted to the ICCV'25 Workshop \"Vision Foundation Models and\n  Generative AI for Accessibility: Challenges and Opportunities\"", "summary": "Interactive digital maps have revolutionized how people travel and learn\nabout the world; however, they rely on pre-existing structured data in GIS\ndatabases (e.g., road networks, POI indices), limiting their ability to address\ngeo-visual questions related to what the world looks like. We introduce our\nvision for Geo-Visual Agents--multimodal AI agents capable of understanding and\nresponding to nuanced visual-spatial inquiries about the world by analyzing\nlarge-scale repositories of geospatial images, including streetscapes (e.g.,\nGoogle Street View), place-based photos (e.g., TripAdvisor, Yelp), and aerial\nimagery (e.g., satellite photos) combined with traditional GIS data sources. We\ndefine our vision, describe sensing and interaction approaches, provide three\nexemplars, and enumerate key challenges and opportunities for future work.", "AI": {"tldr": "\u63d0\u51faGeo-Visual Agents\u7684\u613f\u666f\uff0c\u901a\u8fc7\u591a\u6a21\u6001AI\u5206\u6790\u5730\u7406\u7a7a\u95f4\u56fe\u50cf\u548cGIS\u6570\u636e\uff0c\u89e3\u51b3\u89c6\u89c9-\u7a7a\u95f4\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6570\u5b57\u5730\u56fe\u4f9d\u8d56GIS\u7ed3\u6784\u5316\u6570\u636e\uff0c\u65e0\u6cd5\u6709\u6548\u56de\u7b54\u89c6\u89c9\u5316\u7684\u5730\u7406\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u8857\u9053\u666f\u89c2\u3001\u5730\u70b9\u7167\u7247\u3001\u822a\u62cd\u56fe\u50cf\u7b49\u591a\u6e90\u5730\u7406\u7a7a\u95f4\u6570\u636e\uff0c\u6784\u5efa\u591a\u6a21\u6001AI\u4ee3\u7406\u3002", "result": "\u63d0\u51fa\u4e86Geo-Visual Agents\u7684\u613f\u666f\uff0c\u5c55\u793a\u4e86\u4e09\u79cd\u793a\u4f8b\uff0c\u5e76\u63a2\u8ba8\u4e86\u6311\u6218\u548c\u672a\u6765\u673a\u4f1a\u3002", "conclusion": "Geo-Visual Agents\u4e3a\u5730\u7406\u89c6\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.14920", "pdf": "https://arxiv.org/pdf/2508.14920", "abs": "https://arxiv.org/abs/2508.14920", "authors": ["Ilya Fedorov", "Dmitry Korobchenko"], "title": "Human Feedback Driven Dynamic Speech Emotion Recognition", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "comment": null, "summary": "This work proposes to explore a new area of dynamic speech emotion\nrecognition. Unlike traditional methods, we assume that each audio track is\nassociated with a sequence of emotions active at different moments in time. The\nstudy particularly focuses on the animation of emotional 3D avatars. We propose\na multi-stage method that includes the training of a classical speech emotion\nrecognition model, synthetic generation of emotional sequences, and further\nmodel improvement based on human feedback. Additionally, we introduce a novel\napproach to modeling emotional mixtures based on the Dirichlet distribution.\nThe models are evaluated based on ground-truth emotions extracted from a\ndataset of 3D facial animations. We compare our models against the sliding\nwindow approach. Our experimental results show the effectiveness of\nDirichlet-based approach in modeling emotional mixtures. Incorporating human\nfeedback further improves the model quality while providing a simplified\nannotation procedure.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\uff0c\u5173\u6ce83D\u865a\u62df\u89d2\u8272\u7684\u60c5\u611f\u52a8\u753b\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u8bad\u7ec3\u548cDirichlet\u5206\u5e03\u5efa\u6a21\u60c5\u611f\u6df7\u5408\uff0c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22\u52a8\u6001\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7684\u65b0\u9886\u57df\uff0c\u7279\u522b\u5173\u6ce83D\u865a\u62df\u89d2\u8272\u7684\u60c5\u611f\u52a8\u753b\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u60c5\u611f\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6311\u6218\u3002", "method": "1. \u8bad\u7ec3\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u6a21\u578b\uff1b2. \u5408\u6210\u60c5\u611f\u5e8f\u5217\uff1b3. \u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u4f18\u5316\u6a21\u578b\uff1b4. \u63d0\u51fa\u57fa\u4e8eDirichlet\u5206\u5e03\u7684\u60c5\u611f\u6df7\u5408\u5efa\u6a21\u65b9\u6cd5\u3002", "result": "Dirichlet\u5206\u5e03\u65b9\u6cd5\u5728\u60c5\u611f\u6df7\u5408\u5efa\u6a21\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7ed3\u5408\u4eba\u7c7b\u53cd\u9988\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u8d28\u91cf\u5e76\u7b80\u5316\u4e86\u6807\u6ce8\u6d41\u7a0b\u3002", "conclusion": "\u63d0\u51fa\u7684\u52a8\u6001\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\u57283D\u865a\u62df\u89d2\u8272\u52a8\u753b\u4e2d\u6709\u6548\uff0cDirichlet\u5206\u5e03\u548c\u4eba\u7c7b\u53cd\u9988\u7684\u7ed3\u5408\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2508.15703", "pdf": "https://arxiv.org/pdf/2508.15703", "abs": "https://arxiv.org/abs/2508.15703", "authors": ["Al Amjad Tawfiq Isstaif", "Evangelia Kalyvianaki", "Richard Mortier"], "title": "Mitigating context switching in densely packed Linux clusters with Latency-Aware Group Scheduling", "categories": ["cs.OS", "cs.DC"], "comment": null, "summary": "Cluster orchestrators such as Kubernetes depend on accurate estimates of node\ncapacity and job requirements. Inaccuracies in either lead to poor placement\ndecisions and degraded cluster performance. In this paper, we show that in\ndensely packed workloads, such as serverless applications, CPU context\nswitching overheads can become so significant that a node's performance is\nseverely degraded, even when the orchestrator placement is theoretically sound.\nIn practice this issue is typically mitigated by over-provisioning the cluster,\nleading to wasted resources.\n  We show that these context switching overhead arise from both an increase in\nthe average cost of an individual context switch and a higher rate of context\nswitching, which together amplify overhead multiplicatively when managing large\nnumbers of concurrent cgroups, Linux's group scheduling mechanism for managing\nmulti-threaded colocated workloads. We propose and evaluate modifications to\nthe standard Linux kernel scheduler that mitigate these effects, achieving the\nsame effective performance with a 28% smaller cluster size. The key insight\nbehind our approach is to prioritise task completion over low-level per-task\nfairness, enabling the scheduler to drain contended CPU run queues more rapidly\nand thereby reduce time spent on context switching.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5bc6\u96c6\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0cCPU\u4e0a\u4e0b\u6587\u5207\u6362\u5f00\u9500\u4f1a\u663e\u8457\u964d\u4f4e\u96c6\u7fa4\u6027\u80fd\uff0c\u5373\u4f7f\u8c03\u5ea6\u7406\u8bba\u4e0a\u5408\u7406\u3002\u901a\u8fc7\u4fee\u6539Linux\u5185\u6838\u8c03\u5ea6\u5668\uff0c\u51cf\u5c11\u4e0a\u4e0b\u6587\u5207\u6362\u5f00\u9500\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5c06\u96c6\u7fa4\u5927\u5c0f\u7f29\u5c0f28%\u3002", "motivation": "Kubernetes\u7b49\u96c6\u7fa4\u8c03\u5ea6\u5668\u4f9d\u8d56\u8282\u70b9\u5bb9\u91cf\u548c\u4efb\u52a1\u9700\u6c42\u7684\u51c6\u786e\u4f30\u8ba1\uff0c\u4e0d\u51c6\u786e\u6027\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u901a\u5e38\u901a\u8fc7\u8fc7\u5ea6\u914d\u7f6e\u8d44\u6e90\u6765\u7f13\u89e3\u95ee\u9898\uff0c\u4f46\u4f1a\u9020\u6210\u6d6a\u8d39\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u5bf9\u6807\u51c6Linux\u5185\u6838\u8c03\u5ea6\u5668\u7684\u4fee\u6539\uff0c\u4ee5\u51cf\u5c11\u4e0a\u4e0b\u6587\u5207\u6362\u7684\u5f00\u9500\u3002\u5173\u952e\u601d\u8def\u662f\u4f18\u5148\u5b8c\u6210\u4efb\u52a1\u800c\u975e\u4f4e\u7ea7\u522b\u7684\u4efb\u52a1\u516c\u5e73\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6539\u8fdb\u540e\u7684\u8c03\u5ea6\u5668\u80fd\u591f\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5c06\u96c6\u7fa4\u89c4\u6a21\u7f29\u5c0f28%\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u8c03\u5ea6\u5668\u4ee5\u51cf\u5c11\u4e0a\u4e0b\u6587\u5207\u6362\u5f00\u9500\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u96c6\u7fa4\u6027\u80fd\u5e76\u51cf\u5c11\u8d44\u6e90\u6d6a\u8d39\u3002"}}
{"id": "2508.15680", "pdf": "https://arxiv.org/pdf/2508.15680", "abs": "https://arxiv.org/abs/2508.15680", "authors": ["Mark Cote", "Susana Aires"], "title": "Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle", "categories": ["cs.AI", "cs.HC", "I.2.6; I.2.11; K.4.1; K.6.0"], "comment": "15 pages, 3 figures, Presented at IAIL 2025 - Imagining the AI\n  Landscape after the AI Act, 4th International Workshop on Imagining the AI\n  Landscape After the AI Act, The fourth International Conference on Hybrid\n  Human-Artificial Intelligence", "summary": "This paper argues that a techno-philosophical reading of the EU AI Act\nprovides insight into the long-term dynamics of data in AI systems,\nspecifically, how the lifecycle from ingestion to deployment generates\nrecursive value chains that challenge existing frameworks for Responsible AI.\nWe introduce a conceptual tool to frame the AI pipeline, spanning data,\ntraining regimes, architectures, feature stores, and transfer learning. Using\ncross-disciplinary methods, we develop a technically grounded and\nphilosophically coherent analysis of regulatory blind spots. Our central claim\nis that what remains absent from policymaking is an account of the dynamic of\nbecoming that underpins both the technical operation and economic logic of AI.\nTo address this, we advance a formal reading of AI inspired by Simondonian\nphilosophy of technology, reworking his concept of individuation to model the\nAI lifecycle, including the pre-individual milieu, individuation, and\nindividuated AI. To translate these ideas, we introduce futurity: the\nself-reinforcing lifecycle of AI, where more data enhances performance, deepens\npersonalisation, and expands application domains. Futurity highlights the\nrecursively generative, non-rivalrous nature of data, underpinned by\ninfrastructures like feature stores that enable feedback, adaptation, and\ntemporal recursion. Our intervention foregrounds escalating power asymmetries,\nparticularly the tech oligarchy whose infrastructures of capture, training, and\ndeployment concentrate value and decision-making. We argue that effective\nregulation must address these infrastructural and temporal dynamics, and\npropose measures including lifecycle audits, temporal traceability, feedback\naccountability, recursion transparency, and a right to contest recursive reuse.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6280\u672f\u54f2\u5b66\u89c6\u89d2\u5206\u6790\u6b27\u76dfAI\u6cd5\u6848\uff0c\u63a2\u8ba8AI\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u957f\u671f\u52a8\u6001\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u5ff5\u5de5\u5177\u6765\u7406\u89e3AI\u751f\u547d\u5468\u671f\u4e2d\u7684\u52a8\u6001\u751f\u6210\u8fc7\u7a0b\u53ca\u5176\u76d1\u7ba1\u76f2\u70b9\u3002", "motivation": "\u63ed\u793aAI\u6570\u636e\u751f\u547d\u5468\u671f\u4e2d\u9012\u5f52\u4ef7\u503c\u94fe\u5bf9\u73b0\u6709\u8d1f\u8d23\u4efbAI\u6846\u67b6\u7684\u6311\u6218\uff0c\u5e76\u6307\u51fa\u653f\u7b56\u5236\u5b9a\u4e2d\u7f3a\u4e4f\u5bf9AI\u6280\u672f\u548c\u7ecf\u6d4e\u903b\u8f91\u52a8\u6001\u6027\u7684\u5173\u6ce8\u3002", "method": "\u91c7\u7528\u8de8\u5b66\u79d1\u65b9\u6cd5\uff0c\u7ed3\u5408Simondonian\u6280\u672f\u54f2\u5b66\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e2a\u4f53\u5316\u6982\u5ff5\uff0c\u63d0\u51faAI\u751f\u547d\u5468\u671f\u7684\u5f62\u5f0f\u5316\u89e3\u8bfb\uff0c\u5e76\u5f15\u5165\u201c\u672a\u6765\u6027\u201d\u6982\u5ff5\u3002", "result": "\u8bc6\u522b\u4e86AI\u751f\u547d\u5468\u671f\u4e2d\u57fa\u7840\u8bbe\u65bd\u548c\u65f6\u95f4\u52a8\u6001\u5bf9\u6743\u529b\u4e0d\u5bf9\u79f0\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u76d1\u7ba1\u63aa\u65bd\u5982\u751f\u547d\u5468\u671f\u5ba1\u8ba1\u3001\u65f6\u95f4\u53ef\u8ffd\u6eaf\u6027\u7b49\u3002", "conclusion": "\u6709\u6548\u76d1\u7ba1\u9700\u5173\u6ce8AI\u57fa\u7840\u8bbe\u65bd\u548c\u65f6\u95f4\u52a8\u6001\uff0c\u63d0\u51fa\u5177\u4f53\u63aa\u65bd\u4ee5\u5e94\u5bf9\u6280\u672f\u5be1\u5934\u5784\u65ad\u548c\u4ef7\u503c\u96c6\u4e2d\u7684\u95ee\u9898\u3002"}}
