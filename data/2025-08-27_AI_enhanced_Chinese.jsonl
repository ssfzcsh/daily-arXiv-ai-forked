{"id": "2508.18370", "pdf": "https://arxiv.org/pdf/2508.18370", "abs": "https://arxiv.org/abs/2508.18370", "authors": ["Terry Yue Zhuo", "Dingmin Wang", "Hantian Ding", "Varun Kumar", "Zijian Wang"], "title": "Training Language Model Agents to Find Vulnerabilities with CTF-Dojo", "categories": ["cs.SE", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional capabilities when\ntrained within executable runtime environments, notably excelling at software\nengineering tasks through verified feedback loops. Yet, scalable and\ngeneralizable execution-grounded environments remain scarce, limiting progress\nin training more capable ML agents. We introduce CTF-Dojo, the first\nlarge-scale executable runtime tailored for training LLMs with verifiable\nfeedback, featuring 658 fully functional Capture-The-Flag (CTF)-style\nchallenges containerized in Docker with guaranteed reproducibility. To enable\nrapid scaling without manual intervention, we develop CTF-Forge, an automated\npipeline that transforms publicly available artifacts into ready-to-use\nexecution environments in minutes, eliminating weeks of expert configuration\ntraditionally required. We trained LLM-based agents on just 486 high-quality,\nexecution-verified trajectories from CTF-Dojo, achieving up to 11.6% absolute\ngains over strong baselines across three competitive benchmarks: InterCode-CTF,\nNYU CTF Bench, and Cybench. Our best-performing 32B model reaches 31.9% Pass@1,\nestablishing a new open-weight state-of-the-art that rivals frontier models\nlike DeepSeek-V3-0324 and Gemini-2.5-Flash. By framing CTF-style tasks as a\nbenchmark for executable-agent learning, CTF-Dojo demonstrates that\nexecution-grounded training signals are not only effective but pivotal in\nadvancing high-performance ML agents without dependence on costly proprietary\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u7684CTF-Dojo\u662f\u4e00\u4e2a\u53ef\u6267\u884c\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u7528\u4e8e\u8bad\u7ec3LLM\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u53ef\u9a8c\u8bc1\u53cd\u9988\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u53ef\u6269\u5c55\u4e14\u901a\u7528\u7684\u6267\u884c\u73af\u5883\u7a00\u7f3a\uff0c\u9650\u5236\u4e86\u8bad\u7ec3\u66f4\u5f3a\u5927ML\u4ee3\u7406\u7684\u8fdb\u5c55\u3002", "method": "\u4f7f\u7528CTF-Dojo\uff08658\u4e2aCTF\u6311\u6218\u7684Docker\u5bb9\u5668\u73af\u5883\uff09\u548c\u81ea\u52a8\u5316\u7684CTF-Forge\u7ba1\u9053\uff0c\u5feb\u901f\u6784\u5efa\u8bad\u7ec3\u73af\u5883\u3002", "result": "\u4ec5\u7528486\u4e2a\u9ad8\u8d28\u91cf\u8f68\u8ff9\u8bad\u7ec3LLM\u4ee3\u7406\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u9ad8\u8fbe11.6%\u7684\u63d0\u5347\uff0c32B\u6a21\u578b\u8fbe\u523031.9% Pass@1\u3002", "conclusion": "CTF-Dojo\u5c55\u793a\u4e86\u57fa\u4e8e\u6267\u884c\u7684\u8bad\u7ec3\u4fe1\u53f7\u5728\u63d0\u5347ML\u4ee3\u7406\u6027\u80fd\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u65e0\u9700\u4f9d\u8d56\u6602\u8d35\u7684\u4e13\u6709\u7cfb\u7edf\u3002"}}
{"id": "2508.18431", "pdf": "https://arxiv.org/pdf/2508.18431", "abs": "https://arxiv.org/abs/2508.18431", "authors": ["K\u00e9rian Fiter", "Louis Malassign\u00e9-Onfroy", "Bentley Oakes"], "title": "DTInsight: A Tool for Explicit, Interactive, and Continuous Digital Twin Reporting", "categories": ["cs.SE", "cs.ET", "cs.HC", "cs.SY", "eess.SY"], "comment": null, "summary": "With Digital Twin (DT) construction and evolution occurring over time,\nstakeholders require tools to understand the current characteristics and\nconceptual architecture of the system at any time. We introduce DTInsight, a\nsystematic and automated tool and methodology for producing continuous\nreporting for DTs. DTInsight offers three key features: (a) an interactive\nconceptual architecture visualization of DTs; (b) generation of summaries of DT\ncharacteristics based on ontological data; and (c) integration of these outputs\ninto a reporting page within a continuous integration and continuous deployment\n(CI/CD) pipeline. Given a modeled description of the DT aligning to our DT\nDescription Framework (DTDF), DTInsight enables up-to-date and detailed reports\nfor enhanced stakeholder understanding.", "AI": {"tldr": "DTInsight\u662f\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u5177\u548c\u65b9\u6cd5\u8bba\uff0c\u7528\u4e8e\u4e3a\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u751f\u6210\u6301\u7eed\u62a5\u544a\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u3001\u7279\u6027\u6458\u8981\u548c\u96c6\u6210\u529f\u80fd\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5b6a\u751f\u7684\u6784\u5efa\u548c\u6f14\u5316\uff0c\u9700\u8981\u4e00\u4e2a\u5de5\u5177\u6765\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u5b9e\u65f6\u7406\u89e3\u7cfb\u7edf\u7684\u7279\u6027\u548c\u67b6\u6784\u3002", "method": "DTInsight\u901a\u8fc7DT\u63cf\u8ff0\u6846\u67b6\uff08DTDF\uff09\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u67b6\u6784\u53ef\u89c6\u5316\u3001\u672c\u4f53\u6570\u636e\u6458\u8981\u751f\u6210\uff0c\u5e76\u5c06\u8fd9\u4e9b\u529f\u80fd\u96c6\u6210\u5230CI/CD\u7ba1\u9053\u4e2d\u3002", "result": "DTInsight\u80fd\u591f\u751f\u6210\u6700\u65b0\u4e14\u8be6\u7ec6\u7684\u62a5\u544a\uff0c\u63d0\u5347\u5229\u76ca\u76f8\u5173\u8005\u7684\u7406\u89e3\u3002", "conclusion": "DTInsight\u4e3a\u6570\u5b57\u5b6a\u751f\u7684\u6301\u7eed\u62a5\u544a\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18452", "pdf": "https://arxiv.org/pdf/2508.18452", "abs": "https://arxiv.org/abs/2508.18452", "authors": ["Pierre-Emmanuel Goffi", "Rapha\u00ebl Tremblay", "Bentley Oakes"], "title": "Engineering a Digital Twin for the Monitoring and Control of Beer Fermentation Sampling", "categories": ["cs.SE", "cs.SY", "eess.SY"], "comment": "Accepted for EDTconf 2025", "summary": "Successfully engineering interactive industrial DTs is a complex task,\nespecially when implementing services beyond passive monitoring. We present\nhere an experience report on engineering a safety-critical digital twin (DT)\nfor beer fermentation monitoring, which provides continual sampling and reduces\nmanual sampling time by 91%. We document our systematic methodology and\npractical solutions for implementing bidirectional DTs in industrial\nenvironments. This includes our three-phase engineering approach that\ntransforms a passive monitoring system into an interactive Type 2 DT with\nreal-time control capabilities for pressurized systems operating at seven bar.\nWe contribute details of multi-layered safety protocols, hardware-software\nintegration strategies across Arduino controllers and Unity visualization, and\nreal-time synchronization solutions. We document specific engineering\nchallenges and solutions spanning interdisciplinary integration, demonstrating\nhow our use of the constellation reporting framework facilitates cross-domain\ncollaboration. Key findings include the critical importance of safety-first\ndesign, simulation-driven development, and progressive implementation\nstrategies. Our work thus provides actionable guidance for practitioners\ndeveloping DTs requiring bidirectional control in safety-critical applications.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5f00\u53d1\u53cc\u5411\u63a7\u5236\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5305\u62ec\u4e09\u9636\u6bb5\u5de5\u7a0b\u65b9\u6cd5\u3001\u591a\u5c42\u5b89\u5168\u534f\u8bae\u53ca\u8f6f\u786c\u4ef6\u96c6\u6210\u7b56\u7565\uff0c\u6210\u529f\u5c06\u53d1\u9175\u76d1\u63a7\u624b\u52a8\u91c7\u6837\u65f6\u95f4\u51cf\u5c1191%\u3002", "motivation": "\u5de5\u7a0b\u5316\u4ea4\u4e92\u5f0f\u5de5\u4e1aDT\u662f\u4e00\u9879\u590d\u6742\u4efb\u52a1\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u73b0\u8d85\u8d8a\u88ab\u52a8\u76d1\u63a7\u7684\u670d\u52a1\u65f6\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u548c\u5b9e\u8df5\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5b9e\u73b0\u5de5\u4e1a\u73af\u5883\u4e2d\u53cc\u5411DT\u7684\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5c06\u88ab\u52a8\u76d1\u63a7\u7cfb\u7edf\u5347\u7ea7\u4e3a\u4ea4\u4e92\u5f0fType 2 DT\uff0c\u5b9e\u73b07 bar\u538b\u529b\u7cfb\u7edf\u7684\u5b9e\u65f6\u63a7\u5236\u3002\u6db5\u76d6\u591a\u5c42\u5b89\u5168\u534f\u8bae\u3001Arduino\u63a7\u5236\u5668\u4e0eUnity\u53ef\u89c6\u5316\u7684\u8f6f\u786c\u4ef6\u96c6\u6210\u7b56\u7565\u53ca\u5b9e\u65f6\u540c\u6b65\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u9a71\u52a8\u5f00\u53d1\u548c\u6e10\u8fdb\u5f0f\u5b9e\u65bd\u7b56\u7565\uff0c\u6210\u529f\u5c06\u5564\u9152\u53d1\u9175\u76d1\u63a7\u7684\u624b\u52a8\u91c7\u6837\u65f6\u95f4\u51cf\u5c1191%\uff0c\u5e76\u9a8c\u8bc1\u4e86\u53cc\u5411\u63a7\u5236DT\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f00\u53d1\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u53cc\u5411\u63a7\u5236DT\u7684\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u5b89\u5168\u4f18\u5148\u8bbe\u8ba1\u3001\u8de8\u9886\u57df\u534f\u4f5c\u548c\u6e10\u8fdb\u5f0f\u5b9e\u65bd\u7b56\u7565\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.18547", "pdf": "https://arxiv.org/pdf/2508.18547", "abs": "https://arxiv.org/abs/2508.18547", "authors": ["Youssef Abdelsalam", "Norman Peitek", "Anna-Maria Maurer", "Mariya Toneva", "Sven Apel"], "title": "How do Humans and LLMs Process Confusing Code?", "categories": ["cs.SE"], "comment": null, "summary": "Already today, humans and programming assistants based on large language\nmodels (LLMs) collaborate in everyday programming tasks. Clearly, a\nmisalignment between how LLMs and programmers comprehend code can lead to\nmisunderstandings, inefficiencies, low code quality, and bugs.\n  A key question in this space is whether humans and LLMs are confused by the\nsame kind of code. This would not only guide our choices of integrating LLMs in\nsoftware engineering workflows, but also inform about possible improvements of\nLLMs.\n  To this end, we conducted an empirical study comparing an LLM to human\nprogrammers comprehending clean and confusing code. We operationalized\ncomprehension for the LLM by using LLM perplexity, and for human programmers\nusing neurophysiological responses (in particular, EEG-based fixation-related\npotentials).\n  We found that LLM perplexity spikes correlate both in terms of location and\namplitude with human neurophysiological responses that indicate confusion. This\nresult suggests that LLMs and humans are similarly confused about the code.\nBased on these findings, we devised a data-driven, LLM-based approach to\nidentify regions of confusion in code that elicit confusion in human\nprogrammers.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u4eba\u7c7b\u7a0b\u5e8f\u5458\u5728\u7406\u89e3\u4ee3\u7801\u65f6\u7684\u56f0\u60d1\u70b9\u76f8\u4f3c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6765\u8bc6\u522b\u4ee3\u7801\u4e2d\u7684\u56f0\u60d1\u533a\u57df\u3002", "motivation": "\u63a2\u7d22\u4eba\u7c7b\u548cLLMs\u5728\u7406\u89e3\u4ee3\u7801\u65f6\u7684\u56f0\u60d1\u662f\u5426\u4e00\u81f4\uff0c\u4ee5\u4f18\u5316LLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u4f5c\u6d41\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83LLM\u7684\u56f0\u60d1\u5ea6\uff08perplexity\uff09\u548c\u4eba\u7c7b\u7a0b\u5e8f\u5458\u7684\u795e\u7ecf\u751f\u7406\u53cd\u5e94\uff08\u5982EEG\uff09\uff0c\u5206\u6790\u4e24\u8005\u5728\u7406\u89e3\u5e72\u51c0\u548c\u56f0\u60d1\u4ee3\u7801\u65f6\u7684\u8868\u73b0\u3002", "result": "LLM\u7684\u56f0\u60d1\u5ea6\u5cf0\u503c\u4e0e\u4eba\u7c7b\u795e\u7ecf\u751f\u7406\u53cd\u5e94\u7684\u56f0\u60d1\u4fe1\u53f7\u5728\u4f4d\u7f6e\u548c\u5e45\u5ea6\u4e0a\u76f8\u5173\uff0c\u8868\u660e\u4e24\u8005\u56f0\u60d1\u70b9\u76f8\u4f3c\u3002", "conclusion": "\u57fa\u4e8e\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5229\u7528LLM\u8bc6\u522b\u4ee3\u7801\u4e2d\u53ef\u80fd\u5f15\u53d1\u4eba\u7c7b\u56f0\u60d1\u7684\u533a\u57df\u3002"}}
{"id": "2508.18673", "pdf": "https://arxiv.org/pdf/2508.18673", "abs": "https://arxiv.org/abs/2508.18673", "authors": ["Xinglong Yang", "Quan Feng", "Zhongying Pan", "Xiang Chen", "Yu Tian", "Wentong Li", "Shuofei Qiao", "Yuxia Geng", "Xingyu Zhao", "Sheng-Jun Huang"], "title": "Tailored Teaching with Balanced Difficulty: Elevating Reasoning in Multimodal Chain-of-Thought via Prompt Curriculum", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": null, "summary": "The effectiveness of Multimodal Chain-of-Thought (MCoT) prompting is often\nlimited by the use of randomly or manually selected examples. These examples\nfail to account for both model-specific knowledge distributions and the\nintrinsic complexity of the tasks, resulting in suboptimal and unstable model\nperformance. To address this, we propose a novel framework inspired by the\npedagogical principle of \"tailored teaching with balanced difficulty\". We\nreframe prompt selection as a prompt curriculum design problem: constructing a\nwell ordered set of training examples that align with the model's current\ncapabilities. Our approach integrates two complementary signals: (1)\nmodel-perceived difficulty, quantified through prediction disagreement in an\nactive learning setup, capturing what the model itself finds challenging; and\n(2) intrinsic sample complexity, which measures the inherent difficulty of each\nquestion-image pair independently of any model. By jointly analyzing these\nsignals, we develop a difficulty-balanced sampling strategy that ensures the\nselected prompt examples are diverse across both dimensions. Extensive\nexperiments conducted on five challenging benchmarks and multiple popular\nMultimodal Large Language Models (MLLMs) demonstrate that our method yields\nsubstantial and consistent improvements and greatly reduces performance\ndiscrepancies caused by random sampling, providing a principled and robust\napproach for enhancing multimodal reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u6a21\u578b\u611f\u77e5\u96be\u5ea6\u548c\u6837\u672c\u5185\u5728\u590d\u6742\u6027\u6765\u4f18\u5316\u591a\u6a21\u6001\u601d\u7ef4\u94fe\uff08MCoT\uff09\u63d0\u793a\u7684\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u968f\u673a\u6216\u4eba\u5de5\u9009\u62e9\u63d0\u793a\u793a\u4f8b\u65f6\u7684\u4e0d\u8db3\uff0c\u8fd9\u4e9b\u793a\u4f8b\u672a\u80fd\u8003\u8651\u6a21\u578b\u7279\u5b9a\u77e5\u8bc6\u5206\u5e03\u548c\u4efb\u52a1\u5185\u5728\u590d\u6742\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u96be\u5ea6\u5e73\u8861\u91c7\u6837\u7b56\u7565\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u611f\u77e5\u96be\u5ea6\u548c\u5185\u5728\u6837\u672c\u590d\u6742\u6027\uff0c\u8bbe\u8ba1\u6709\u5e8f\u7684\u63d0\u793a\u8bfe\u7a0b\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u4e2a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u51cf\u5c11\u4e86\u968f\u673a\u91c7\u6837\u5e26\u6765\u7684\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u589e\u5f3a\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u548c\u7a33\u5065\u7684\u9014\u5f84\u3002"}}
{"id": "2508.19110", "pdf": "https://arxiv.org/pdf/2508.19110", "abs": "https://arxiv.org/abs/2508.19110", "authors": ["Carla Piazza", "Riccardo Romanello", "Sabina Rossi"], "title": "Exact Persistent Stochastic Non-Interference", "categories": ["cs.PF"], "comment": null, "summary": "Persistent Stochastic Non-Interference (PSNI) was introduced to capture a\nquantitative security property in stochastic process algebras, ensuring that a\nhigh-level process does not influence the observable behaviour of a low-level\ncomponent, as formalised via lumpable bisimulation. In this work, we revisit\nPSNI from a performance-oriented perspective and propose a new characterisation\nbased on a refined behavioural relation. We introduce \\emph{weak-exact\nequivalence}, which extends exact equivalence with a relaxed treatment of\ninternal (\\(\\tau\\)) actions, enabling precise control over quantitative\nobservables while accommodating unobservable transitions. Based on this, we\ndefine \\emph{Exact PSNI} (EPSNI), a variant of PSNI characterised via\nweak-exact equivalence. We show that EPSNI admits the same bisimulation-based\nand unwinding-style characterisations as PSNI, and enjoys analogous\ncompositionality properties. These results confirm weak-exact equivalence as a\nrobust foundation for reasoning about non-interference in stochastic systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Exact PSNI\uff08EPSNI\uff09\uff0c\u57fa\u4e8e\u5f31\u7cbe\u786e\u7b49\u4ef7\u7684\u65b0\u5b89\u5168\u7279\u6027\uff0c\u7528\u4e8e\u5206\u6790\u968f\u673a\u7cfb\u7edf\u4e2d\u7684\u975e\u5e72\u6270\u6027\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6PSNI\uff0c\u4ece\u6027\u80fd\u89d2\u5ea6\u63d0\u51fa\u66f4\u7cbe\u786e\u7684\u884c\u4e3a\u5173\u7cfb\uff0c\u4ee5\u63a7\u5236\u91cf\u5316\u53ef\u89c2\u5bdf\u6027\u3002", "method": "\u5f15\u5165\u5f31\u7cbe\u786e\u7b49\u4ef7\uff08weak-exact equivalence\uff09\uff0c\u6269\u5c55\u7cbe\u786e\u7b49\u4ef7\u5e76\u653e\u677e\u5185\u90e8\u52a8\u4f5c\u5904\u7406\uff0c\u5b9a\u4e49EPSNI\u3002", "result": "EPSNI\u4fdd\u6301\u4e0ePSNI\u76f8\u540c\u7684\u7279\u6027\uff08\u5982\u53cc\u6a21\u62df\u548c\u5c55\u5f00\u5f62\u5f0f\uff09\uff0c\u5e76\u5177\u6709\u7c7b\u4f3c\u7684\u7ec4\u5408\u6027\u3002", "conclusion": "\u5f31\u7cbe\u786e\u7b49\u4ef7\u4e3a\u968f\u673a\u7cfb\u7edf\u975e\u5e72\u6270\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2508.19206", "pdf": "https://arxiv.org/pdf/2508.19206", "abs": "https://arxiv.org/abs/2508.19206", "authors": ["Hera Brown", "Jakub Konieczny"], "title": "Decidability of Extensions of Presburger Arithmetic by Hardy Field Functions", "categories": ["cs.LO", "math.LO", "math.NT", "11U05, 03B10, 03B25, 11J54"], "comment": "17 pages", "summary": "We study the extension of Presburger arithmetic by the class of\nsub-polynomial Hardy field functions, and show the majority of these extensions\nto be undecidable. More precisely, we show that the theory\n$\\mathrm{Th}(\\mathbb{Z}; <, +, \\lfloor f \\rceil)$, where $f$ is a Hardy field\nfunction and $\\lfloor \\cdot \\rceil$ the nearest integer operator, is\nundecidable when $f$ grows polynomially faster than $x$. Further, we show that\nwhen $f$ grows sub-linearly quickly, but still as fast as some polynomial, the\ntheory $\\mathrm{Th}(\\mathbb{Z}; <, +, \\lfloor f \\rceil)$ is undecidable.", "AI": {"tldr": "\u7814\u7a76\u4e86Presburger\u7b97\u672f\u901a\u8fc7\u4e9a\u591a\u9879\u5f0fHardy\u573a\u51fd\u6570\u7684\u6269\u5c55\uff0c\u53d1\u73b0\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u8fd9\u4e9b\u6269\u5c55\u662f\u4e0d\u53ef\u5224\u5b9a\u7684\u3002", "motivation": "\u63a2\u7d22Hardy\u573a\u51fd\u6570\u5728Presburger\u7b97\u672f\u4e2d\u7684\u6269\u5c55\u662f\u5426\u53ef\u5224\u5b9a\uff0c\u7279\u522b\u662f\u5f53\u51fd\u6570\u7684\u589e\u957f\u901f\u7387\u4ecb\u4e8e\u591a\u9879\u5f0f\u548c\u7ebf\u6027\u4e4b\u95f4\u65f6\u3002", "method": "\u901a\u8fc7\u5206\u6790$\r\n\\mathrm{Th}(\\mathbb{Z}; <, +, \\lfloor f \\rceil)$\u7406\u8bba\u7684\u53ef\u5224\u5b9a\u6027\uff0c\u5176\u4e2d$f$\u662fHardy\u573a\u51fd\u6570\uff0c$\r\n\\lfloor \\cdot \\rceil$\u662f\u6700\u8fd1\u6574\u6570\u7b97\u5b50\u3002", "result": "\u5f53$f$\u7684\u589e\u957f\u901f\u7387\u6bd4\u7ebf\u6027\u5feb\uff08\u591a\u9879\u5f0f\u7ea7\u522b\uff09\u6216\u4ecb\u4e8e\u591a\u9879\u5f0f\u4e0e\u7ebf\u6027\u4e4b\u95f4\uff08\u4e9a\u7ebf\u6027\uff09\u65f6\uff0c\u7406\u8bba\u4e0d\u53ef\u5224\u5b9a\u3002", "conclusion": "Hardy\u573a\u51fd\u6570\u5728\u7279\u5b9a\u589e\u957f\u901f\u7387\u4e0b\u7684\u6269\u5c55\u4f1a\u5bfc\u81f4Presburger\u7b97\u672f\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\u3002"}}
{"id": "2508.18525", "pdf": "https://arxiv.org/pdf/2508.18525", "abs": "https://arxiv.org/abs/2508.18525", "authors": ["Eleni Tselepi", "Spyridon Thermos", "Gerasimos Potamianos"], "title": "Controllable Single-shot Animation Blending with Temporal Conditioning", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to the AI for Visual Arts Workshop at ICCV 2025", "summary": "Training a generative model on a single human skeletal motion sequence\nwithout being bound to a specific kinematic tree has drawn significant\nattention from the animation community. Unlike text-to-motion generation,\nsingle-shot models allow animators to controllably generate variations of\nexisting motion patterns without requiring additional data or extensive\nretraining. However, existing single-shot methods do not explicitly offer a\ncontrollable framework for blending two or more motions within a single\ngenerative pass. In this paper, we present the first single-shot motion\nblending framework that enables seamless blending by temporally conditioning\nthe generation process. Our method introduces a skeleton-aware normalization\nmechanism to guide the transition between motions, allowing smooth, data-driven\ncontrol over when and how motions blend. We perform extensive quantitative and\nqualitative evaluations across various animation styles and different kinematic\nskeletons, demonstrating that our approach produces plausible, smooth, and\ncontrollable motion blends in a unified and efficient manner.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u6b21\u8fd0\u52a8\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u5728\u5355\u4e00\u751f\u6210\u8fc7\u7a0b\u4e2d\u65e0\u7f1d\u6df7\u5408\u4e24\u79cd\u6216\u66f4\u591a\u8fd0\u52a8\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u663e\u5f0f\u63a7\u5236\u8fd0\u52a8\u6df7\u5408\u7684\u95ee\u9898\u3002", "motivation": "\u52a8\u753b\u793e\u533a\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u5355\u4e00\u8fd0\u52a8\u5e8f\u5217\u4e0a\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5e76\u80fd\u53ef\u63a7\u5730\u751f\u6210\u8fd0\u52a8\u53d8\u4f53\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\u6216\u5927\u91cf\u91cd\u65b0\u8bad\u7ec3\u3002\u540c\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5728\u5355\u4e00\u751f\u6210\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u63a7\u5236\u8fd0\u52a8\u6df7\u5408\u7684\u80fd\u529b\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9aa8\u67b6\u611f\u77e5\u7684\u5f52\u4e00\u5316\u673a\u5236\uff0c\u901a\u8fc7\u65f6\u95f4\u6761\u4ef6\u5316\u7684\u751f\u6210\u8fc7\u7a0b\u6765\u5f15\u5bfc\u8fd0\u52a8\u4e4b\u95f4\u7684\u8fc7\u6e21\uff0c\u5b9e\u73b0\u5e73\u6ed1\u3001\u6570\u636e\u9a71\u52a8\u7684\u6df7\u5408\u63a7\u5236\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u52a8\u753b\u98ce\u683c\u548c\u4e0d\u540c\u9aa8\u67b6\u7ed3\u6784\u7684\u5e7f\u6cdb\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5\u7edf\u4e00\u4e14\u9ad8\u6548\u7684\u65b9\u5f0f\u751f\u6210\u5408\u7406\u3001\u5e73\u6ed1\u4e14\u53ef\u63a7\u7684\u8fd0\u52a8\u6df7\u5408\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u662f\u9996\u4e2a\u5b9e\u73b0\u5355\u6b21\u8fd0\u52a8\u6df7\u5408\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u52a8\u753b\u521b\u4f5c\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2508.18283", "pdf": "https://arxiv.org/pdf/2508.18283", "abs": "https://arxiv.org/abs/2508.18283", "authors": ["Vivek Kumar", "Himanshu Sahu", "Hari Prabhat Gupta", "Biplav Srivastava"], "title": "Technology-assisted Personalized Yoga for Better Health -- Challenges and Outlook", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "10 Pages, 11 figures, 2 tables", "summary": "Yoga is a discipline of physical postures, breathing techniques, and\nmeditative practices rooted in ancient Indian traditions, now embraced\nworldwide for promoting overall well-being and inner balance. The practices are\na large set of items, our term for executable actions like physical poses or\nbreath exercises, to offer for a person's well-being. However, to get benefits\nof Yoga tailored to a person's unique needs, a person needs to (a) discover\ntheir subset from the large and seemingly complex set with inter-dependencies,\n(b) continue to follow them with interest adjusted to their changing abilities\nand near-term objectives, and (c) as appropriate, adapt to alternative items\nbased on changing environment and the person's health conditions. In this\nvision paper, we describe the challenges for the Yoga personalization problem.\nNext, we sketch a preliminary approach and use the experience to provide an\noutlook on solving the challenging problem using existing and novel techniques\nfrom a multidisciplinary computing perspective. To the best of our knowledge,\nthis is the first paper that comprehensively examines decision support issues\naround Yoga personalization, from pose sensing to recommendation of corrections\nfor a complete regimen, and illustrates with a case study of Surya Namaskar --\na set of 12 choreographed poses.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u745c\u4f3d\u4e2a\u6027\u5316\u95ee\u9898\u53ca\u5176\u591a\u5b66\u79d1\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u7684\u521d\u6b65\u65b9\u6cd5\u3002", "motivation": "\u745c\u4f3d\u4f5c\u4e3a\u4e00\u79cd\u5168\u7403\u6d41\u884c\u7684\u8eab\u5fc3\u953b\u70bc\u65b9\u5f0f\uff0c\u5176\u590d\u6742\u6027\u4f7f\u5f97\u4e2a\u6027\u5316\u63a8\u8350\u6210\u4e3a\u6311\u6218\uff0c\u9700\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u3001\u5174\u8da3\u548c\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u521d\u6b65\u7684\u591a\u5b66\u79d1\u8ba1\u7b97\u89c6\u89d2\u65b9\u6cd5\uff0c\u7ed3\u5408\u6848\u4f8b\u7814\u7a76\u8bf4\u660e\u745c\u4f3d\u59ff\u52bf\u4f20\u611f\u548c\u7ea0\u6b63\u63a8\u8350\u3002", "result": "\u9996\u6b21\u5168\u9762\u7814\u7a76\u4e86\u745c\u4f3d\u4e2a\u6027\u5316\u51b3\u7b56\u652f\u6301\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u745c\u4f3d\u4e2a\u6027\u5316\u662f\u4e00\u4e2a\u590d\u6742\u4f46\u53ef\u884c\u7684\u95ee\u9898\uff0c\u9700\u7ed3\u5408\u591a\u5b66\u79d1\u6280\u672f\u89e3\u51b3\uff0c\u672a\u6765\u6709\u671b\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2508.18516", "pdf": "https://arxiv.org/pdf/2508.18516", "abs": "https://arxiv.org/abs/2508.18516", "authors": ["Kubra Duran", "Lal Verda Cakir", "Sana Ullah Jan", "Kerem Gursu", "Berk Canberk"], "title": "Digital Twin-Guided Energy Management over Real-Time Pub/Sub Protocol in 6G Smart Cities", "categories": ["cs.NI"], "comment": null, "summary": "Although the emergence of 6G IoT networks has accelerated the deployment of\nenhanced smart city services, the resource limitations of IoT devices remain as\na significant problem. Given this limitation, meeting the low-latency service\nrequirement of 6G networks becomes even more challenging. However, existing 6G\nIoT management strategies lack real-time operation and mostly rely on discrete\nactions, which are insufficient to optimise energy consumption. To address\nthese, in this study, we propose a Digital Twin (DT)-guided energy management\nframework to jointly handle the low latency and energy efficiency challenges in\n6G IoT networks. In this framework, we provide the twin models through a\ndistributed overlay network and handle the dynamic updates between the data\nlayer and the upper layers of the DT over the Real-Time Publish Subscribe\n(RTPS) protocol. We also design a Reinforcement Learning (RL) engine with a\nnovel formulated reward function to provide optimal data update times for each\nof the IoT devices. The RL engine receives a diverse set of environment states\nfrom the What-if engine and runs Deep Deterministic Policy Gradient (DDPG) to\noutput continuous actions to the IoT devices. Based on our simulation results,\nwe observe that the proposed framework achieves a 37% improvement in 95th\npercentile latency and a 30% reduction in energy consumption compared to the\nexisting literature.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u7684\u80fd\u6e90\u7ba1\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b36G\u7269\u8054\u7f51\u4e2d\u7684\u4f4e\u5ef6\u8fdf\u548c\u80fd\u6e90\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8bbe\u5907\u6570\u636e\u66f4\u65b0\u65f6\u95f4\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "6G\u7269\u8054\u7f51\u7684\u8d44\u6e90\u9650\u5236\u4e0e\u4f4e\u5ef6\u8fdf\u9700\u6c42\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u4ee5\u53ca\u73b0\u6709\u7ba1\u7406\u7b56\u7565\u7f3a\u4e4f\u5b9e\u65f6\u6027\u548c\u8fde\u7eed\u6027\uff0c\u4fc3\u4f7f\u7814\u7a76\u56e2\u961f\u5f00\u53d1\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u8986\u76d6\u7f51\u7edc\u63d0\u4f9b\u5b6a\u751f\u6a21\u578b\uff0c\u5229\u7528RTPS\u534f\u8bae\u5904\u7406\u52a8\u6001\u66f4\u65b0\uff1b\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5f15\u64ce\uff0c\u7ed3\u5408DDPG\u7b97\u6cd5\u4f18\u5316\u8bbe\u5907\u6570\u636e\u66f4\u65b0\u65f6\u95f4\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u572895%\u767e\u5206\u4f4d\u5ef6\u8fdf\u4e0a\u63d0\u5347\u4e8637%\uff0c\u80fd\u8017\u964d\u4f4e\u4e8630%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e866G\u7269\u8054\u7f51\u7684\u4f4e\u5ef6\u8fdf\u548c\u80fd\u6e90\u6548\u7387\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u8df5\u4e2d\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.18924", "pdf": "https://arxiv.org/pdf/2508.18924", "abs": "https://arxiv.org/abs/2508.18924", "authors": ["Wei Xuan", "Zhongrui Wang", "Lang Feng", "Ning Lin", "Zihao Xuan", "Rongliang Fu", "Tsung-Yi Ho", "Yuzhong Jiao", "Luhong Liang"], "title": "SeDA: Secure and Efficient DNN Accelerators with Hardware/Software Synergy", "categories": ["cs.AR"], "comment": "Accepted by Design Automation Conference (DAC), 2025", "summary": "Ensuring the confidentiality and integrity of DNN accelerators is paramount\nacross various scenarios spanning autonomous driving, healthcare, and finance.\nHowever, current security approaches typically require extensive hardware\nresources, and incur significant off-chip memory access overheads. This paper\nintroduces SeDA, which utilizes 1) a bandwidth-aware encryption mechanism to\nimprove hardware resource efficiency, 2) optimal block granularity through\nintra-layer and inter-layer tiling patterns, and 3) a multi-level integrity\nverification mechanism that minimizes, or even eliminates, memory access\noverheads. Experimental results show that SeDA decreases performance overhead\nby over 12% for both server and edge neural processing units (NPUs), while\nensuring robust scalability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSeDA\uff0c\u901a\u8fc7\u5e26\u5bbd\u611f\u77e5\u52a0\u5bc6\u3001\u4f18\u5316\u5757\u7c92\u5ea6\u548c\u591a\u7ea7\u5b8c\u6574\u6027\u9a8c\u8bc1\uff0c\u663e\u8457\u51cf\u5c11DNN\u52a0\u901f\u5668\u7684\u6027\u80fd\u548c\u5185\u5b58\u8bbf\u95ee\u5f00\u9500\u3002", "motivation": "\u786e\u4fddDNN\u52a0\u901f\u5668\u7684\u673a\u5bc6\u6027\u548c\u5b8c\u6574\u6027\u5728\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u548c\u91d1\u878d\u7b49\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5b89\u5168\u65b9\u6848\u8d44\u6e90\u6d88\u8017\u5927\u4e14\u5185\u5b58\u8bbf\u95ee\u5f00\u9500\u9ad8\u3002", "method": "SeDA\u91c7\u7528\u5e26\u5bbd\u611f\u77e5\u52a0\u5bc6\u3001\u4f18\u5316\u5757\u7c92\u5ea6\uff08\u901a\u8fc7\u5c42\u5185\u548c\u5c42\u95f4\u5206\u5757\u6a21\u5f0f\uff09\u548c\u591a\u7ea7\u5b8c\u6574\u6027\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cSeDA\u5c06\u670d\u52a1\u5668\u548c\u8fb9\u7f18NPU\u7684\u6027\u80fd\u5f00\u9500\u964d\u4f4e\u8d85\u8fc712%\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "SeDA\u5728\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u548c\u5185\u5b58\u8bbf\u95ee\u5f00\u9500\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2508.18296", "pdf": "https://arxiv.org/pdf/2508.18296", "abs": "https://arxiv.org/abs/2508.18296", "authors": ["Edgar Rangel", "Fabio Martinez"], "title": "Federative ischemic stroke segmentation as alternative to overcome domain-shift multi-institution challenges", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "11 pages, 4 figures, 3 tables, source code available", "summary": "Stroke is the second leading cause of death and the third leading cause of\ndisability worldwide. Clinical guidelines establish diffusion resonance imaging\n(DWI, ADC) as the standard for localizing, characterizing, and measuring\ninfarct volume, enabling treatment support and prognosis. Nonetheless, such\nlesion analysis is highly variable due to different patient demographics,\nscanner vendors, and expert annotations. Computational support approaches have\nbeen key to helping with the localization and segmentation of lesions. However,\nthese strategies are dedicated solutions that learn patterns from only one\ninstitution, lacking the variability to generalize geometrical lesions shape\nmodels. Even worse, many clinical centers lack sufficient labeled samples to\nadjust these dedicated solutions. This work developed a collaborative framework\nfor segmenting ischemic stroke lesions in DWI sequences by sharing knowledge\nfrom deep center-independent representations. From 14 emulated healthcare\ncenters with 2031 studies, the FedAvg model achieved a general DSC of $0.71 \\pm\n0.24$, AVD of $5.29 \\pm 22.74$, ALD of $2.16 \\pm 3.60$ and LF1 of $0.70 \\pm\n0.26$ over all centers, outperforming both the centralized and other federated\nrules. Interestingly, the model demonstrated strong generalization properties,\nshowing uniform performance across different lesion categories and reliable\nperformance in out-of-distribution centers (with DSC of $0.64 \\pm 0.29$ and AVD\nof $4.44 \\pm 8.74$ without any additional training).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u6df1\u5ea6\u4e2d\u5fc3\u65e0\u5173\u8868\u5f81\u77e5\u8bc6\u6765\u5206\u5272DWI\u5e8f\u5217\u4e2d\u7684\u7f3a\u8840\u6027\u5352\u4e2d\u75c5\u53d8\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u5352\u4e2d\u75c5\u53d8\u5206\u6790\u56e0\u60a3\u8005\u3001\u626b\u63cf\u8bbe\u5907\u548c\u4e13\u5bb6\u6807\u6ce8\u7684\u5dee\u5f02\u800c\u9ad8\u5ea6\u53ef\u53d8\uff0c\u73b0\u6709\u8ba1\u7b97\u7b56\u7565\u5c40\u9650\u4e8e\u5355\u4e00\u673a\u6784\u6570\u636e\uff0c\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u90a6\u5e73\u5747\uff08FedAvg\uff09\u6a21\u578b\u4ece14\u4e2a\u533b\u7597\u4e2d\u5fc3\u76842031\u9879\u7814\u7a76\u4e2d\u5171\u4eab\u77e5\u8bc6\u3002", "result": "FedAvg\u6a21\u578b\u5728\u6240\u6709\u4e2d\u5fc3\u4e0a\u7684DSC\u4e3a0.71\u00b10.24\uff0c\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u5176\u4ed6\u8054\u90a6\u89c4\u5219\uff0c\u4e14\u5728\u5916\u90e8\u5206\u5e03\u4e2d\u5fc3\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u534f\u4f5c\u6846\u67b6\u89e3\u51b3\u4e86\u6570\u636e\u4e0d\u8db3\u548c\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u5352\u4e2d\u75c5\u53d8\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.18331", "pdf": "https://arxiv.org/pdf/2508.18331", "abs": "https://arxiv.org/abs/2508.18331", "authors": ["Eduardo Vyhmeister", "Bastien Pietropaoli", "Alejando Martinez Molina", "Montserrat Gonzalez-Ferreiro", "Gabriel Gonzalez-Castane", "Jordi Arjona Aroca", "Andrea Visentin"], "title": "Metrics, KPIs, and Taxonomy for Data Valuation and Monetisation -- A Systematic Literature Review", "categories": ["cs.DB", "A.1"], "comment": "Additional Key Words and Phrases: Data monetisation, Data valuation,\n  Metrics, Key Performance Indicators, KPIs, Systematic Literature Review", "summary": "Data valuation and data monetisation are complex subjects but essential to\nmost organisations today. Unfortunately, they still lack standard procedures\nand frameworks for organisations to follow. In this survey, we introduce the\nreader to the concepts by providing the definitions and the background required\nto better understand data, monetisation strategies, and finally metrics and\nKPIs used in these strategies. We have conducted a systematic literature review\non metrics and KPIs used in data valuation and monetisation, in every aspect of\nan organisation's business, and by a variety of stakeholders. We provide an\nexpansive list of such metrics and KPIs with 162 references. We then categorise\nall the metrics and KPIs found into a large taxonomy, following the Balanced\nScorecard (BSC) approach with further subclustering to cover every aspect of an\norganisation's business. This taxonomy will help every level of data management\nunderstand the complex landscape of the domain. We also discuss the difficulty\nin creating a standard framework for data valuation and data monetisation and\nthe major challenges the domain is currently facing.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u6570\u636e\u5206\u7c7b\uff0c\u63a2\u8ba8\u4e86\u6570\u636e\u4f30\u503c\u548c\u8d27\u5e01\u5316\u7684\u5173\u952e\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5e73\u8861\u8ba1\u5206\u5361\u7684\u5206\u7c7b\u6cd5\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u7406\u89e3\u8be5\u9886\u57df\u7684\u590d\u6742\u6027\u3002", "motivation": "\u6570\u636e\u4f30\u503c\u548c\u8d27\u5e01\u5316\u5728\u73b0\u4ee3\u7ec4\u7ec7\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u6846\u67b6\u548c\u7a0b\u5e8f\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u7cfb\u7edf\u68b3\u7406\u6587\u732e\u548c\u6307\u6807\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u66f4\u597d\u5730\u7406\u89e3\u548c\u5e94\u7528\u76f8\u5173\u6982\u5ff5\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u6536\u96c6\u5e76\u5206\u6790\u4e86162\u7bc7\u6587\u732e\u4e2d\u7684\u6307\u6807\u548cKPI\u3002\u91c7\u7528\u5e73\u8861\u8ba1\u5206\u5361\u65b9\u6cd5\u5bf9\u8fd9\u4e9b\u6307\u6807\u8fdb\u884c\u5206\u7c7b\u548c\u5b50\u805a\u7c7b\uff0c\u4ee5\u8986\u76d6\u7ec4\u7ec7\u7684\u6240\u6709\u4e1a\u52a1\u5c42\u9762\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6307\u6807\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u6570\u636e\u4f30\u503c\u548c\u8d27\u5e01\u5316\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u4e3a\u7ec4\u7ec7\u7684\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u6846\u67b6\u3002", "conclusion": "\u5c3d\u7ba1\u63d0\u51fa\u4e86\u5206\u7c7b\u6cd5\uff0c\u4f46\u6570\u636e\u4f30\u503c\u548c\u8d27\u5e01\u5316\u4ecd\u9762\u4e34\u6807\u51c6\u5316\u6846\u67b6\u7684\u6311\u6218\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002"}}
{"id": "2508.18489", "pdf": "https://arxiv.org/pdf/2508.18489", "abs": "https://arxiv.org/abs/2508.18489", "authors": ["Haochen Pan", "Ryan Chard", "Reid Mello", "Christopher Grams", "Tanjin He", "Alexander Brace", "Owen Price Skelly", "Will Engler", "Hayden Holbrook", "Song Young Oh", "Maxime Gonthier", "Michael Papka", "Ben Blaiszik", "Kyle Chard", "Ian Foster"], "title": "Experiences with Model Context Protocol Servers for Science and High Performance Computing", "categories": ["cs.DC"], "comment": "11 pages, including a 4-page appendix", "summary": "Large language model (LLM)-powered agents are increasingly used to plan and\nexecute scientific workflows, yet most research cyberinfrastructure (CI)\nexposes heterogeneous APIs and implements security models that present barriers\nfor use by agents. We report on our experience using the Model Context Protocol\n(MCP) as a unifying interface that makes research capabilities discoverable,\ninvokable, and composable. Our approach is pragmatic: we implement thin MCP\nservers over mature services, including Globus Transfer, Compute, and Search;\nstatus APIs exposed by computing facilities; Octopus event fabric; and\ndomain-specific tools such as Garden and Galaxy. We use case studies in\ncomputational chemistry, bioinformatics, quantum chemistry, and filesystem\nmonitoring to illustrate how this MCP-oriented architecture can be used in\npractice. We distill lessons learned and outline open challenges in evaluation\nand trust for agent-led science.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u4f7f\u7528MCP\u534f\u8bae\u4f5c\u4e3a\u7edf\u4e00\u63a5\u53e3\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u80fd\u591f\u66f4\u6709\u6548\u5730\u53d1\u73b0\u3001\u8c03\u7528\u548c\u7ec4\u5408\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u7684\u5f02\u6784API\u3002\u901a\u8fc7\u591a\u9886\u57df\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86MCP\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5e76\u603b\u7ed3\u4e86\u7ecf\u9a8c\u6559\u8bad\u548c\u672a\u6765\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\uff08CI\uff09\u7684\u5f02\u6784API\u548c\u5b89\u5168\u6a21\u578b\u9650\u5236\u4e86LLM\u4ee3\u7406\u7684\u90e8\u7f72\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7MCP\u534f\u8bae\u4e3a\u4ee3\u7406\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u63a5\u53e3\uff0c\u4ee5\u7b80\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u91c7\u7528MCP\u534f\u8bae\u4f5c\u4e3a\u4e2d\u95f4\u5c42\uff0c\u5c06\u5176\u5b9e\u73b0\u4e3a\u73b0\u6709\u6210\u719f\u670d\u52a1\u7684\u8584\u670d\u52a1\u5668\uff08\u5982Globus\u3001Octopus\u7b49\uff09\uff0c\u5e76\u901a\u8fc7\u591a\u4e2a\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002", "result": "\u5b9e\u8df5\u8bc1\u660e\uff0cMCP\u80fd\u591f\u6709\u6548\u5730\u7edf\u4e00\u5f02\u6784API\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u53d1\u73b0\u3001\u8c03\u7528\u548c\u7ec4\u5408\u7814\u7a76\u80fd\u529b\u3002\u6848\u4f8b\u7814\u7a76\u6db5\u76d6\u4e86\u8ba1\u7b97\u5316\u5b66\u3001\u751f\u7269\u4fe1\u606f\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u3002", "conclusion": "MCP\u67b6\u6784\u5728\u4ee3\u7406\u4e3b\u5bfc\u7684\u79d1\u5b66\u7814\u7a76\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u8bc4\u4f30\u548c\u4fe1\u4efb\u7b49\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2508.18587", "pdf": "https://arxiv.org/pdf/2508.18587", "abs": "https://arxiv.org/abs/2508.18587", "authors": ["Bar\u0131\u015f Bayaz\u0131t", "Yao Li", "Xujie Si"], "title": "A Case Study on the Effectiveness of LLMs in Verification with Proof Assistants", "categories": ["cs.PL", "cs.AI"], "comment": "Accepted by LMPL 2025", "summary": "Large language models (LLMs) can potentially help with verification using\nproof assistants by automating proofs. However, it is unclear how effective\nLLMs are in this task. In this paper, we perform a case study based on two\nmature Rocq projects: the hs-to-coq tool and Verdi. We evaluate the\neffectiveness of LLMs in generating proofs by both quantitative and qualitative\nanalysis. Our study finds that: (1) external dependencies and context in the\nsame source file can significantly help proof generation; (2) LLMs perform\ngreat on small proofs but can also generate large proofs; (3) LLMs perform\ndifferently on different verification projects; and (4) LLMs can generate\nconcise and smart proofs, apply classical techniques to new definitions, but\ncan also make odd mistakes.", "AI": {"tldr": "LLMs\u5728\u8bc1\u660e\u52a9\u624b\u4e2d\u7684\u5e94\u7528\u6548\u679c\u7814\u7a76\uff0c\u53d1\u73b0\u5176\u5728\u5c0f\u8bc1\u660e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u53d7\u5916\u90e8\u4f9d\u8d56\u548c\u9879\u76ee\u5dee\u5f02\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8LLMs\u5728\u81ea\u52a8\u5316\u8bc1\u660e\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u6210\u719f\u9879\u76eehs-to-coq\u548cVerdi\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\uff0c\u8bc4\u4f30LLMs\u5728\u751f\u6210\u8bc1\u660e\u65f6\u7684\u8868\u73b0\uff0c\u5305\u62ec\u4f9d\u8d56\u3001\u9879\u76ee\u5dee\u5f02\u548c\u9519\u8bef\u7c7b\u578b\u3002", "result": "LLMs\u5728\u5c0f\u8bc1\u660e\u4e2d\u8868\u73b0\u4f18\u79c0\uff0c\u80fd\u751f\u6210\u7b80\u6d01\u8bc1\u660e\uff0c\u4f46\u53d7\u5916\u90e8\u4f9d\u8d56\u548c\u9879\u76ee\u7c7b\u578b\u5f71\u54cd\uff0c\u4e14\u53ef\u80fd\u72af\u5947\u602a\u9519\u8bef\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u5316\u8bc1\u660e\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u6ce8\u610f\u9879\u76ee\u5dee\u5f02\u548c\u4f9d\u8d56\u6027\u95ee\u9898\u3002"}}
{"id": "2508.18636", "pdf": "https://arxiv.org/pdf/2508.18636", "abs": "https://arxiv.org/abs/2508.18636", "authors": ["Yan Wang", "Xinyi Hou", "Yanjie Zhao", "Weiguo Lin", "Haoyu Wang", "Junjun Si"], "title": "LaQual: A Novel Framework for Automated Evaluation of LLM App Quality", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "LLM app stores are quickly emerging as platforms that gather a wide range of\nintelligent applications based on LLMs, giving users many choices for content\ncreation, coding support, education, and more. However, the current methods for\nranking and recommending apps in these stores mostly rely on static metrics\nlike user activity and favorites, which makes it hard for users to efficiently\nfind high-quality apps. To address these challenges, we propose LaQual, an\nautomated framework for evaluating the quality of LLM apps. LaQual consists of\nthree main stages: first, it labels and classifies LLM apps in a hierarchical\nway to accurately match them to different scenarios; second, it uses static\nindicators, such as time-weighted user engagement and functional capability\nmetrics, to filter out low-quality apps; and third, it conducts a dynamic,\nscenario-adaptive evaluation, where the LLM itself generates scenario-specific\nevaluation metrics, scoring rules, and tasks for a thorough quality assessment.\nExperiments on a popular LLM app store show that LaQual is effective. Its\nautomated scores are highly consistent with human judgments (with Spearman's\nrho of 0.62 and p=0.006 in legal consulting, and rho of 0.60 and p=0.009 in\ntravel planning). By effectively screening, LaQual can reduce the pool of\ncandidate LLM apps by 66.7% to 81.3%. User studies further confirm that LaQual\nsignificantly outperforms baseline systems in decision confidence, comparison\nefficiency (with average scores of 5.45 compared to 3.30), and the perceived\nvalue of its evaluation reports (4.75 versus 2.25). Overall, these results\ndemonstrate that LaQual offers a scalable, objective, and user-centered\nsolution for finding and recommending high-quality LLM apps in real-world use\ncases.", "AI": {"tldr": "LaQual\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5e94\u7528\u7684\u8d28\u91cf\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u7c7b\u3001\u9759\u6001\u7b5b\u9009\u548c\u52a8\u6001\u8bc4\u4f30\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "motivation": "\u5f53\u524dLLM\u5e94\u7528\u5546\u5e97\u7684\u6392\u540d\u548c\u63a8\u8350\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u6307\u6807\uff0c\u7528\u6237\u96be\u4ee5\u9ad8\u6548\u627e\u5230\u9ad8\u8d28\u91cf\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "LaQual\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a\u5206\u5c42\u5206\u7c7bLLM\u5e94\u7528\u3001\u9759\u6001\u6307\u6807\u7b5b\u9009\u4f4e\u8d28\u91cf\u5e94\u7528\u3001\u52a8\u6001\u751f\u6210\u573a\u666f\u9002\u914d\u7684\u8bc4\u4f30\u6307\u6807\u548c\u4efb\u52a1\u8fdb\u884c\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLaQual\u7684\u81ea\u52a8\u8bc4\u5206\u4e0e\u4eba\u5de5\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff08Spearman's rho 0.62-0.60\uff09\uff0c\u80fd\u51cf\u5c11\u5019\u9009\u5e94\u752866.7%-81.3%\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u5176\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\u3002", "conclusion": "LaQual\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u5ba2\u89c2\u4e14\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5e94\u7528\u7684\u63a8\u8350\u8d28\u91cf\u3002"}}
{"id": "2508.18734", "pdf": "https://arxiv.org/pdf/2508.18734", "abs": "https://arxiv.org/abs/2508.18734", "authors": ["DongHoon Lim", "YoungChae Kim", "Dong-Hyun Kim", "Da-Hee Yang", "Joon-Hyuk Chang"], "title": "Improving Noise Robust Audio-Visual Speech Recognition via Router-Gated Cross-Modal Feature Fusion", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.AS", "eess.SP"], "comment": "Accepted to IEEE ASRU 2025", "summary": "Robust audio-visual speech recognition (AVSR) in noisy environments remains\nchallenging, as existing systems struggle to estimate audio reliability and\ndynamically adjust modality reliance. We propose router-gated cross-modal\nfeature fusion, a novel AVSR framework that adaptively reweights audio and\nvisual features based on token-level acoustic corruption scores. Using an\naudio-visual feature fusion-based router, our method down-weights unreliable\naudio tokens and reinforces visual cues through gated cross-attention in each\ndecoder layer. This enables the model to pivot toward the visual modality when\naudio quality deteriorates. Experiments on LRS3 demonstrate that our approach\nachieves an 16.51-42.67% relative reduction in word error rate compared to\nAV-HuBERT. Ablation studies confirm that both the router and gating mechanism\ncontribute to improved robustness under real-world acoustic noise.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u8c03\u6574\u97f3\u9891\u548c\u89c6\u89c9\u7279\u5f81\u6743\u91cd\u7684AVSR\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u566a\u58f0\u73af\u5883\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u5728\u566a\u58f0\u73af\u5883\u4e2d\u96be\u4ee5\u4f30\u8ba1\u97f3\u9891\u53ef\u9760\u6027\u5e76\u52a8\u6001\u8c03\u6574\u6a21\u6001\u4f9d\u8d56\u6027\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8def\u7531\u5668\u7684\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ee4\u724c\u7ea7\u58f0\u5b66\u635f\u574f\u8bc4\u5206\u52a8\u6001\u8c03\u6574\u97f3\u9891\u548c\u89c6\u89c9\u7279\u5f81\u6743\u91cd\uff0c\u5e76\u5728\u89e3\u7801\u5c42\u4e2d\u901a\u8fc7\u95e8\u63a7\u4ea4\u53c9\u6ce8\u610f\u529b\u5f3a\u5316\u89c6\u89c9\u7ebf\u7d22\u3002", "result": "\u5728LRS3\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u8f83\u4e8eAV-HuBERT\uff0c\u6a21\u578b\u5b9e\u73b0\u4e8616.51-42.67%\u7684\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e\u3002", "conclusion": "\u63d0\u51fa\u7684\u8def\u7531\u5668\u548c\u95e8\u63a7\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u771f\u5b9e\u566a\u58f0\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.19073", "pdf": "https://arxiv.org/pdf/2508.19073", "abs": "https://arxiv.org/abs/2508.19073", "authors": ["Ehsan Yousefzadeh-Asl-Miandoab", "Reza Karimzadeh", "Bulat Ibragimov", "Florina M. Ciorba", "P\u0131nar T\u00f6z\u00fcn"], "title": "CARMA: Collocation-Aware Resource Manager with GPU Memory Estimator", "categories": ["cs.DC", "cs.LG", "cs.PF"], "comment": null, "summary": "Studies conducted on enterprise-scale infrastructure have shown that GPUs --\nthe core computational resource for deep learning (DL) training -- are often\nsignificantly underutilized. DL task collocation on GPUs is an opportunity to\naddress this challenge. However, it may result in (1) out-of-memory crashes for\nthe subsequently arriving task and (2) slowdowns for all tasks sharing the GPU\ndue to resource interference. The former challenge poses a threat to\nrobustness, while the latter affects the quality of service and energy\nefficiency.\n  We propose CARMA, a server-scale task-level collocation-aware resource\nmanagement system that handles both collocation challenges. CARMA encompasses\nGPUMemNet, a novel ML-based GPU memory estimator framework for DL training\ntasks, to minimize out-of-memory errors and introduces collocation policies\nthat cap GPU utilization to minimize interference. Furthermore, CARMA\nintroduces a recovery method to ensure robust restart of tasks that crash. Our\nevaluation on traces modeled after real-world DL training task traces shows\nthat CARMA increases the GPU utilization over time by 39.3\\%, decreases the\nend-to-end execution time by $\\sim$26.7\\%, and reduces the GPU energy use by\n$\\sim$14.2\\%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCARMA\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316GPU\u8d44\u6e90\u5206\u914d\u548c\u4efb\u52a1\u8c03\u5ea6\uff0c\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u5728GPU\u4e0a\u7684\u5185\u5b58\u4e0d\u8db3\u548c\u6027\u80fd\u5e72\u6270\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347GPU\u5229\u7528\u7387\u548c\u80fd\u6548\u3002", "motivation": "\u4f01\u4e1a\u7ea7\u57fa\u7840\u8bbe\u65bd\u4e2dGPU\u5229\u7528\u7387\u666e\u904d\u8f83\u4f4e\uff0c\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u5728GPU\u4e0a\u7684\u5171\u5b58\u53ef\u80fd\u5bfc\u81f4\u5185\u5b58\u4e0d\u8db3\u548c\u6027\u80fd\u5e72\u6270\u95ee\u9898\uff0c\u5f71\u54cd\u7cfb\u7edf\u7a33\u5065\u6027\u548c\u80fd\u6548\u3002", "method": "\u63d0\u51fa\u4e86CARMA\u7cfb\u7edf\uff0c\u5305\u62ecGPU\u5185\u5b58\u4f30\u8ba1\u6846\u67b6GPUMemNet\u548c\u8d44\u6e90\u7ba1\u7406\u7b56\u7565\uff0c\u4ee5\u6700\u5c0f\u5316\u5185\u5b58\u9519\u8bef\u548c\u6027\u80fd\u5e72\u6270\uff0c\u5e76\u63d0\u4f9b\u4efb\u52a1\u6062\u590d\u673a\u5236\u3002", "result": "CARMA\u5c06GPU\u5229\u7528\u7387\u63d0\u5347\u4e8639.3%\uff0c\u4efb\u52a1\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u4e86\u7ea626.7%\uff0cGPU\u80fd\u8017\u964d\u4f4e\u4e86\u7ea614.2%\u3002", "conclusion": "CARMA\u901a\u8fc7\u667a\u80fd\u8d44\u6e90\u7ba1\u7406\u663e\u8457\u4f18\u5316\u4e86GPU\u7684\u5229\u7528\u6548\u7387\u548c\u80fd\u6548\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u5171\u5b58\u7684\u6311\u6218\u3002"}}
{"id": "2508.18526", "pdf": "https://arxiv.org/pdf/2508.18526", "abs": "https://arxiv.org/abs/2508.18526", "authors": ["Anastasis Kratsios", "Dennis Zvigelsky", "Bradd Hart"], "title": "Quantifying The Limits of AI Reasoning: Systematic Neural Network Representations of Algorithms", "categories": ["cs.LG", "cs.CC", "cs.LO", "cs.NA", "cs.NE", "math.NA", "68T07, 68Q17, 68Q05, 68W40, 68N99"], "comment": "18 pages main body, 45 pages total + references", "summary": "A main open question in contemporary AI research is quantifying the forms of\nreasoning neural networks can perform when perfectly trained. This paper\nanswers this by interpreting reasoning tasks as circuit emulation, where the\ngates define the type of reasoning; e.g. Boolean gates for predicate logic,\ntropical circuits for dynamic programming, arithmetic and analytic gates for\nsymbolic mathematical representation, and hybrids thereof for deeper reasoning;\ne.g. higher-order logic.\n  We present a systematic meta-algorithm that converts essentially any circuit\ninto a feedforward neural network (NN) with ReLU activations by iteratively\nreplacing each gate with a canonical ReLU MLP emulator. We show that, on any\ndigital computer, our construction emulates the circuit exactly--no\napproximation, no rounding, modular overflow included--demonstrating that no\nreasoning task lies beyond the reach of neural networks. The number of neurons\nin the resulting network (parametric complexity) scales with the circuit's\ncomplexity, and the network's computational graph (structure) mirrors that of\nthe emulated circuit. This formalizes the folklore that NNs networks trade\nalgorithmic run-time (circuit runtime) for space complexity (number of\nneurons).\n  We derive a range of applications of our main result, from emulating\nshortest-path algorithms on graphs with cubic--size NNs, to simulating stopped\nTuring machines with roughly quadratically--large NNs, and even the emulation\nof randomized Boolean circuits. Lastly, we demonstrate that our result is\nstrictly more powerful than a classical universal approximation theorem: any\nuniversal function approximator can be encoded as a circuit and directly\nemulated by a NN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5143\u7b97\u6cd5\uff0c\u5c06\u4efb\u4f55\u7535\u8def\u8f6c\u6362\u4e3a\u5177\u6709ReLU\u6fc0\u6d3b\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u8bc1\u660e\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u7cbe\u786e\u6a21\u62df\u5404\u79cd\u63a8\u7406\u4efb\u52a1\uff0c\u4e14\u5176\u89c4\u6a21\u548c\u7ed3\u6784\u76f4\u63a5\u53cd\u6620\u7535\u8def\u590d\u6742\u6027\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u5728\u5b8c\u7f8e\u8bad\u7ec3\u6761\u4ef6\u4e0b\u80fd\u6267\u884c\u4f55\u79cd\u5f62\u5f0f\u63a8\u7406\u7684\u6838\u5fc3\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06\u63a8\u7406\u4efb\u52a1\u89e3\u91ca\u4e3a\u7535\u8def\u4eff\u771f\uff0c\u4f7f\u7528ReLU\u591a\u5c42\u611f\u77e5\u5668\u9010\u6b65\u66ff\u6362\u7535\u8def\u95e8\uff0c\u6784\u5efa\u7cbe\u786e\u6a21\u62df\u7684\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u8bc1\u660e\u795e\u7ecf\u7f51\u7edc\u80fd\u7cbe\u786e\u6a21\u62df\u4efb\u4f55\u7535\u8def\uff08\u5982\u5e03\u5c14\u903b\u8f91\u3001\u52a8\u6001\u89c4\u5212\u7b49\uff09\uff0c\u4e14\u89c4\u6a21\u548c\u7ed3\u6784\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u76f4\u63a5\u76f8\u5173\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u7684\u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u53ef\u8f6c\u5316\u4e3a\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u5176\u80fd\u529b\u8d85\u8d8a\u7ecf\u5178\u7684\u901a\u7528\u8fd1\u4f3c\u5b9a\u7406\u3002"}}
{"id": "2508.18540", "pdf": "https://arxiv.org/pdf/2508.18540", "abs": "https://arxiv.org/abs/2508.18540", "authors": ["Jonghyun Kim", "Cheng Sun", "Michael Stengel", "Matthew Chan", "Andrew Russell", "Jaehyun Jung", "Wil Braithwaite", "Shalini De Mello", "David Luebke"], "title": "Real-time 3D Visualization of Radiance Fields on Light Field Displays", "categories": ["cs.GR", "eess.IV"], "comment": "10 pages, 14 figures. J. Kim, C. Sun, and M. Stengel contributed\n  equally", "summary": "Radiance fields have revolutionized photo-realistic 3D scene visualization by\nenabling high-fidelity reconstruction of complex environments, making them an\nideal match for light field displays. However, integrating these technologies\npresents significant computational challenges, as light field displays require\nmultiple high-resolution renderings from slightly shifted viewpoints, while\nradiance fields rely on computationally intensive volume rendering. In this\npaper, we propose a unified and efficient framework for real-time radiance\nfield rendering on light field displays. Our method supports a wide range of\nradiance field representations, including NeRFs, 3D Gaussian Splatting, and\nSparse Voxels, within a shared architecture based on a single-pass plane\nsweeping strategy and caching of shared, non-directional components. The\nframework generalizes across different scene formats without retraining, and\navoids redundant computation across views. We further demonstrate a real-time\ninteractive application on a Looking Glass display, achieving 200+ FPS at 512p\nacross 45 views, enabling seamless, immersive 3D interaction. On standard\nbenchmarks, our method achieves up to 22x speedup compared to independently\nrendering each view, while preserving image quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5149\u573a\u663e\u793a\u5668\u4e0a\u5b9e\u65f6\u6e32\u67d3\u8f90\u5c04\u573a\uff0c\u652f\u6301\u591a\u79cd\u8f90\u5c04\u573a\u8868\u793a\uff0c\u5e76\u5728\u591a\u79cd\u573a\u666f\u4e2d\u5b9e\u73b0\u9ad8\u5e27\u7387\u3002", "motivation": "\u7ed3\u5408\u5149\u573a\u663e\u793a\u5668\u548c\u8f90\u5c04\u573a\u6280\u672f\u9762\u4e34\u8ba1\u7b97\u91cf\u5927\u3001\u5b9e\u65f6\u6027\u5dee\u7684\u6311\u6218\uff0c\u7814\u7a76\u76ee\u6807\u662f\u5b9e\u73b0\u9ad8\u6548\u5b9e\u65f6\u7684\u6e32\u67d3\u3002", "method": "\u91c7\u7528\u5355\u904d\u5e73\u9762\u626b\u63cf\u7b56\u7565\u548c\u5171\u4eab\u975e\u65b9\u5411\u6027\u7ec4\u4ef6\u7684\u7f13\u5b58\u6280\u672f\uff0c\u652f\u6301NeRFs\u30013D\u9ad8\u65af\u6e85\u5c04\u7b49\u591a\u79cd\u8868\u793a\uff0c\u907f\u514d\u89c6\u56fe\u95f4\u5197\u4f59\u8ba1\u7b97\u3002", "result": "\u5728Looking Glass\u663e\u793a\u5668\u4e0a\u5b9e\u73b0200+ FPS\uff08512p\uff0c45\u89c6\u56fe\uff09\uff0c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u901f\u5ea6\u63d0\u534722\u500d\u4e14\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u591a\u79cd\u8f90\u5c04\u573a\u8868\u793a\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u5b9e\u65f6\u6e32\u67d3\uff0c\u4e3a\u6c89\u6d78\u5f0f3D\u4ea4\u4e92\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.18317", "pdf": "https://arxiv.org/pdf/2508.18317", "abs": "https://arxiv.org/abs/2508.18317", "authors": ["Meir Nizri", "Amos Azaria", "Chirag Gupta", "Noam Hazon"], "title": "Does Calibration Affect Human Actions?", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Calibration has been proposed as a way to enhance the reliability and\nadoption of machine learning classifiers. We study a particular aspect of this\nproposal: how does calibrating a classification model affect the decisions made\nby non-expert humans consuming the model's predictions? We perform a\nHuman-Computer-Interaction (HCI) experiment to ascertain the effect of\ncalibration on (i) trust in the model, and (ii) the correlation between\ndecisions and predictions. We also propose further corrections to the reported\ncalibrated scores based on Kahneman and Tversky's prospect theory from\nbehavioral economics, and study the effect of these corrections on trust and\ndecision-making. We find that calibration is not sufficient on its own; the\nprospect theory correction is crucial for increasing the correlation between\nhuman decisions and the model's predictions. While this increased correlation\nsuggests higher trust in the model, responses to ``Do you trust the model\nmore?\" are unaffected by the method used.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6821\u51c6\u5206\u7c7b\u6a21\u578b\u5bf9\u975e\u4e13\u5bb6\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6821\u51c6\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u4fe1\u4efb\uff0c\u800c\u7ed3\u5408\u524d\u666f\u7406\u8bba\u4fee\u6b63\u80fd\u63d0\u9ad8\u51b3\u7b56\u4e0e\u9884\u6d4b\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u63a2\u8ba8\u6821\u51c6\u5982\u4f55\u5f71\u54cd\u975e\u4e13\u5bb6\u5bf9\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u7684\u4fe1\u4efb\u548c\u51b3\u7b56\u76f8\u5173\u6027\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7HCI\u5b9e\u9a8c\u8bc4\u4f30\u6821\u51c6\u5bf9\u4fe1\u4efb\u548c\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u524d\u666f\u7406\u8bba\u7684\u4fee\u6b63\u65b9\u6cd5\u3002", "result": "\u6821\u51c6\u672c\u8eab\u4e0d\u8db3\uff0c\u524d\u666f\u7406\u8bba\u4fee\u6b63\u663e\u8457\u63d0\u9ad8\u4e86\u51b3\u7b56\u4e0e\u9884\u6d4b\u7684\u76f8\u5173\u6027\uff0c\u4f46\u5bf9\u76f4\u63a5\u4fe1\u4efb\u95ee\u9898\u7684\u56de\u7b54\u65e0\u5f71\u54cd\u3002", "conclusion": "\u6821\u51c6\u9700\u7ed3\u5408\u884c\u4e3a\u7ecf\u6d4e\u5b66\u7406\u8bba\uff08\u5982\u524d\u666f\u7406\u8bba\uff09\u624d\u80fd\u771f\u6b63\u63d0\u5347\u6a21\u578b\u7684\u51b3\u7b56\u76f8\u5173\u6027\uff0c\u800c\u76f4\u63a5\u4fe1\u4efb\u95ee\u9898\u53ef\u80fd\u9700\u8981\u5176\u4ed6\u5e72\u9884\u3002"}}
{"id": "2508.18702", "pdf": "https://arxiv.org/pdf/2508.18702", "abs": "https://arxiv.org/abs/2508.18702", "authors": ["Ziye Jia", "Jia He", "Lijun He", "Min Sheng", "Junyu Liu", "Qihui Wu", "Zhu Han"], "title": "Dynamic Trajectory Optimization and Power Control for Hierarchical UAV Swarms in 6G Aerial Access Network", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Unmanned aerial vehicles (UAVs) can serve as aerial base stations (BSs) to\nextend the ubiquitous connectivity for ground users (GUs) in the\nsixth-generation (6G) era. However, it is challenging to cooperatively deploy\nmultiple UAV swarms in large-scale remote areas. Hence, in this paper, we\npropose a hierarchical UAV swarms structure for 6G aerial access networks,\nwhere the head UAVs serve as aerial BSs, and tail UAVs (T-UAVs) are responsible\nfor relay. In detail, we jointly optimize the dynamic deployment and trajectory\nof UAV swarms, which is formulated as a multi-objective optimization problem\n(MOP) to concurrently minimize the energy consumption of UAV swarms and GUs, as\nwell as the delay of GUs. However, the proposed MOP is a mixed integer\nnonlinear programming and NP-hard to solve. Therefore, we develop a K-means and\nVoronoi diagram based area division method, and construct Fermat points to\nestablish connections between GUs and T-UAVs. Then, an improved non-dominated\nsorting whale optimization algorithm is proposed to seek Pareto optimal\nsolutions for the transformed MOP. Finally, extensive simulations are conducted\nto verify the performance of proposed algorithms by comparing with baseline\nmechanisms, resulting in a 50% complexity reduction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e6G\u7a7a\u4e2d\u63a5\u5165\u7f51\u7edc\u7684\u5206\u5c42\u65e0\u4eba\u673a\u7fa4\u7ed3\u6784\uff0c\u901a\u8fc7\u4f18\u5316\u90e8\u7f72\u548c\u8f68\u8ff9\u4ee5\u51cf\u5c11\u80fd\u8017\u548c\u5ef6\u8fdf\uff0c\u5e76\u4f7f\u7528\u6539\u8fdb\u7684\u7b97\u6cd5\u5b9e\u73b050%\u7684\u590d\u6742\u6027\u964d\u4f4e\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5927\u89c4\u6a21\u504f\u8fdc\u533a\u57df\u534f\u540c\u90e8\u7f72\u591a\u65e0\u4eba\u673a\u7fa4\u7684\u6311\u6218\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u5206\u5c42\u65e0\u4eba\u673a\u7fa4\u7ed3\u6784\uff0c\u4ee5\u6269\u5c556G\u65f6\u4ee3\u5730\u9762\u7528\u6237\u7684\u8fde\u63a5\u6027\u3002", "method": "\u91c7\u7528\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u7fa4\u7684\u52a8\u6001\u90e8\u7f72\u548c\u8f68\u8ff9\uff0c\u4f7f\u7528K-means\u548cVoronoi\u56fe\u8fdb\u884c\u533a\u57df\u5212\u5206\uff0c\u5e76\u5229\u7528\u6539\u8fdb\u7684\u975e\u652f\u914d\u6392\u5e8f\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\u6c42\u89e3\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u4e0e\u57fa\u51c6\u673a\u5236\u6bd4\u8f83\u65f6\uff0c\u5b9e\u73b0\u4e8650%\u7684\u590d\u6742\u6027\u964d\u4f4e\u3002", "conclusion": "\u5206\u5c42\u65e0\u4eba\u673a\u7fa4\u7ed3\u6784\u548c\u4f18\u5316\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e866G\u7a7a\u4e2d\u63a5\u5165\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u504f\u8fdc\u533a\u57df\u7684\u8fde\u63a5\u6269\u5c55\u3002"}}
{"id": "2508.18961", "pdf": "https://arxiv.org/pdf/2508.18961", "abs": "https://arxiv.org/abs/2508.18961", "authors": ["Qianpeng Li", "Yu Song", "Xin Liu", "Wenna Song", "Boshi Zhao", "Zhichao Wang", "Aoxin Chen", "Tielin Zhang", "Liang Chen"], "title": "TaiBai: A fully programmable brain-inspired processor with topology-aware efficiency", "categories": ["cs.AR"], "comment": null, "summary": "Brain-inspired computing has emerged as a promising paradigm to overcome the\nenergy-efficiency limitations of conventional intelligent systems by emulating\nthe brain's partitioned architecture and event-driven sparse computation.\nHowever, existing brain-inspired chips often suffer from rigid network topology\nconstraints and limited neuronal programmability, hindering their adaptability.\nTo address these challenges, we present TaiBai, an event-driven, programmable\nmany-core brain-inspired processor that leverages temporal and spatial spike\nsparsity to minimize bandwidth and computational overhead. TaiBai chip contains\nthree key features: First, a brain-inspired hierarchical topology encoding\nscheme is designed to flexibly support arbitrary network architectures while\nslashing storage overhead for large-scale networks; Second, a multi-granularity\ninstruction set enables programmability of brain-like spiking neuron or\nsynapses with various dynamics and on-chip learning rules; Third, a co-designed\ncompiler stack optimizes task mapping and resource allocation. After evaluating\nacross various tasks, such as speech recognition, ECG classification, and\ncross-day brain-computer interface decoding, we found spiking neural networks\nembedded on the TaiBai chip could achieve more than 200 times higher energy\nefficiency than a standard NVIDIA RTX 3090 GPU at a comparable accuracy. These\nresults demonstrated its high potentiation as a scalable, programmable, and\nultra-efficient solution for both multi-scale brain simulation and\nbrain-inspired computation.", "AI": {"tldr": "TaiBai\u662f\u4e00\u79cd\u4e8b\u4ef6\u9a71\u52a8\u7684\u53ef\u7f16\u7a0b\u591a\u6838\u8111\u542f\u53d1\u5904\u7406\u5668\uff0c\u901a\u8fc7\u5229\u7528\u65f6\u7a7a\u5cf0\u503c\u7a00\u758f\u6027\u4f18\u5316\u5e26\u5bbd\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u5177\u6709\u7075\u6d3b\u7684\u62d3\u6251\u7f16\u7801\u3001\u591a\u7c92\u5ea6\u6307\u4ee4\u96c6\u548c\u4f18\u5316\u7684\u7f16\u8bd1\u5668\u5806\u6808\uff0c\u80fd\u6548\u6bd4\u4f20\u7edfGPU\u9ad8200\u500d\u4ee5\u4e0a\u3002", "motivation": "\u4f20\u7edf\u8111\u542f\u53d1\u82af\u7247\u56e0\u7f51\u7edc\u62d3\u6251\u521a\u6027\u9650\u5236\u548c\u795e\u7ecf\u5143\u53ef\u7f16\u7a0b\u6027\u4e0d\u8db3\uff0c\u963b\u788d\u4e86\u5176\u9002\u5e94\u6027\u3002TaiBai\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u548c\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5c42\u6b21\u5316\u62d3\u6251\u7f16\u7801\u65b9\u6848\u4ee5\u652f\u6301\u4efb\u610f\u7f51\u7edc\u67b6\u6784\uff0c\u5f00\u53d1\u4e86\u591a\u7c92\u5ea6\u6307\u4ee4\u96c6\u5b9e\u73b0\u795e\u7ecf\u5143\u548c\u7a81\u89e6\u7684\u53ef\u7f16\u7a0b\u6027\uff0c\u5e76\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u7684\u7f16\u8bd1\u5668\u5806\u6808\u4f18\u5316\u4efb\u52a1\u6620\u5c04\u548c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5728\u591a\u79cd\u4efb\u52a1\u6d4b\u8bd5\u4e2d\uff0cTaiBai\u82af\u7247\u4e0a\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u80fd\u6548\u6bd4NVIDIA RTX 3090 GPU\u9ad8200\u500d\u4ee5\u4e0a\uff0c\u4e14\u7cbe\u5ea6\u76f8\u5f53\u3002", "conclusion": "TaiBai\u5c55\u793a\u4e86\u5176\u5728\u591a\u5c3a\u5ea6\u8111\u6a21\u62df\u548c\u8111\u542f\u53d1\u8ba1\u7b97\u4e2d\u7684\u9ad8\u5ea6\u6f5c\u80fd\uff0c\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u7f16\u7a0b\u4e14\u8d85\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18494", "pdf": "https://arxiv.org/pdf/2508.18494", "abs": "https://arxiv.org/abs/2508.18494", "authors": ["Yanqi Chen", "Xiao Yan", "Alexandra Meliou", "Eric Lo"], "title": "DiskJoin: Large-scale Vector Similarity Join with SSD", "categories": ["cs.DB"], "comment": "Accepted at SIGMOD 2026", "summary": "Similarity join--a widely used operation in data science--finds all pairs of\nitems that have distance smaller than a threshold. Prior work has explored\ndistributed computation methods to scale similarity join to large data volumes\nbut these methods require a cluster deployment, and efficiency suffers from\nexpensive inter-machine communication. On the other hand, disk-based solutions\nare more cost-effective by using a single machine and storing the large dataset\non high-performance external storage, such as NVMe SSDs, but in these methods\nthe disk I/O time is a serious bottleneck. In this paper, we propose DiskJoin,\nthe first disk-based similarity join algorithm that can process billion-scale\nvector datasets efficiently on a single machine. DiskJoin improves disk I/O by\ntailoring the data access patterns to avoid repetitive accesses and read\namplification. It also uses main memory as a dynamic cache and carefully\nmanages cache eviction to improve cache hit rate and reduce disk retrieval\ntime. For further acceleration, we adopt a probabilistic pruning technique that\ncan effectively prune a large number of vector pairs from computation. Our\nevaluation on real-world, large-scale datasets shows that DiskJoin\nsignificantly outperforms alternatives, achieving speedups from 50x to 1000x.", "AI": {"tldr": "DiskJoin\u662f\u4e00\u79cd\u57fa\u4e8e\u78c1\u76d8\u7684\u9ad8\u6548\u76f8\u4f3c\u6027\u8fde\u63a5\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u5355\u673a\u5904\u7406\u5341\u4ebf\u7ea7\u5411\u91cf\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4f18\u5316\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\u548c\u52a8\u6001\u7f13\u5b58\u7ba1\u7406\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\u548c\u4f20\u7edf\u78c1\u76d8\u89e3\u51b3\u65b9\u6848\u7684I/O\u74f6\u9888\uff0c\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u7684\u5355\u673a\u5904\u7406\u65b9\u6848\u3002", "method": "\u4f18\u5316\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\u4ee5\u907f\u514d\u91cd\u590d\u8bfb\u53d6\u548c\u8bfb\u653e\u5927\uff0c\u5229\u7528\u4e3b\u5b58\u4f5c\u4e3a\u52a8\u6001\u7f13\u5b58\uff0c\u5e76\u7ed3\u5408\u6982\u7387\u6027\u526a\u679d\u6280\u672f\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "result": "\u5728\u771f\u5b9e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0cDiskJoin\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb50\u81f31000\u500d\u3002", "conclusion": "DiskJoin\u4e3a\u5927\u89c4\u6a21\u76f8\u4f3c\u6027\u8fde\u63a5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5355\u673a\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u901f\u5ea6\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2508.18556", "pdf": "https://arxiv.org/pdf/2508.18556", "abs": "https://arxiv.org/abs/2508.18556", "authors": ["Abhijeet Saraha", "Yuanbo Li", "Chris Porter", "Santosh Pande"], "title": "Managing Multi Instance GPUs for High Throughput and Energy Savings", "categories": ["cs.DC"], "comment": null, "summary": "Modern GPUs such as the Ampere series (A30, A100) as well as the Hopper\nseries (H100, H200) offer performance as well as security isolation features.\nThey also support a good amount of concurrency, but taking advantage of it can\nbe quite challenging due to the complex constraints on partitioning the chip.\n  In this work, we develop partitioning and scheduling schemes for a variety of\nworkloads, ranging from scientific to modern ML workloads, including LLMs. We\ndevelop several schemes involving dynamic memory estimation, partition fusion\nand partition fission. We also support process restart to recover from\nout-of-memory errors for workloads and early restart as an optimization. This\napproach yields up to 6.20x throughput and 5.93x energy improvements for\ngeneral workloads; and we see 1.59x and 1.12x improvement to throughput and\nenergy, respectively, for ML workloads on an A100 GPU. We leverage this\ntechnique on LLM workloads and show good improvements, including up to 1.43x\nthroughput improvement and 1.11x energy savings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u73b0\u4ee3GPU\uff08\u5982Ampere\u548cHopper\u7cfb\u5217\uff09\u7684\u5206\u533a\u4e0e\u8c03\u5ea6\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u7528\u53ca\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u5229\u7528\u73b0\u4ee3GPU\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\u9694\u79bb\u7279\u6027\uff0c\u89e3\u51b3\u7531\u4e8e\u590d\u6742\u5206\u533a\u7ea6\u675f\u5bfc\u81f4\u7684\u5e76\u53d1\u5229\u7528\u96be\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u52a8\u6001\u5185\u5b58\u4f30\u8ba1\u3001\u5206\u533a\u878d\u5408\u4e0e\u5206\u88c2\u7b49\u65b9\u6848\uff0c\u5e76\u652f\u6301\u8fdb\u7a0b\u91cd\u542f\u4ee5\u4f18\u5316\u5185\u5b58\u9519\u8bef\u6062\u590d\u3002", "result": "\u5728A100 GPU\u4e0a\u5b9e\u73b0\u4e86\u901a\u7528\u5de5\u4f5c\u8d1f\u8f7d\u6700\u9ad86.20\u500d\u541e\u5410\u548c5.93\u500d\u80fd\u6548\u63d0\u5347\uff0c\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u6700\u9ad81.59\u500d\u541e\u5410\u548c1.12\u500d\u80fd\u6548\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u65b9\u6848\u80fd\u663e\u8457\u63d0\u5347GPU\u5728\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u6027\u80fd\u548c\u80fd\u6548\u8868\u73b0\u3002"}}
{"id": "2508.19074", "pdf": "https://arxiv.org/pdf/2508.19074", "abs": "https://arxiv.org/abs/2508.19074", "authors": ["ZhenDong Chen", "ZhanShang Nie", "ShiXing Wan", "JunYi Li", "YongTian Cheng", "Shuai Zhao"], "title": "An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees", "categories": ["cs.RO", "cs.AI", "cs.PL"], "comment": null, "summary": "The Large Language Models (LLM) are increasingly being deployed in robotics\nto generate robot control programs for specific user tasks, enabling embodied\nintelligence. Existing methods primarily focus on LLM training and prompt\ndesign that utilize LLMs to generate executable programs directly from user\ntasks in natural language. However, due to the inconsistency of the LLMs and\nthe high complexity of the tasks, such best-effort approaches often lead to\ntremendous programming errors in the generated code, which significantly\nundermines the effectiveness especially when the light-weight LLMs are applied.\nThis paper introduces a natural-robotic language translation framework that (i)\nprovides correctness verification for generated control programs and (ii)\nenhances the performance of LLMs in program generation via feedback-based\nfine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is\nproposed to abstract away from the intricate details of the control programs,\nbridging the natural language tasks with the underlying robot skills. Then, the\nRSL compiler and debugger are constructed to verify RSL programs generated by\nthe LLM and provide error feedback to the LLM for refining the outputs until\nbeing verified by the compiler. This provides correctness guarantees for the\nLLM-generated programs before being offloaded to the robots for execution,\nsignificantly enhancing the effectiveness of LLM-powered robotic applications.\nExperiments demonstrate NRTrans outperforms the existing method under a range\nof LLMs and tasks, and achieves a high success rate for light-weight LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u7136\u8bed\u8a00\u4e0e\u673a\u5668\u4eba\u8bed\u8a00\u7684\u7ffb\u8bd1\u6846\u67b6\uff08NRTrans\uff09\uff0c\u901a\u8fc7\u9a8c\u8bc1\u548c\u53cd\u9988\u673a\u5236\u63d0\u9ad8\u8f7b\u91cf\u7ea7LLM\u751f\u6210\u673a\u5668\u4eba\u63a7\u5236\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u76f4\u63a5\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u751f\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u4f46\u7531\u4e8eLLM\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u4efb\u52a1\u7684\u9ad8\u590d\u6742\u6027\uff0c\u751f\u6210\u7684\u7a0b\u5e8f\u9519\u8bef\u7387\u9ad8\uff0c\u5c24\u5176\u662f\u5728\u8f7b\u91cf\u7ea7LLM\u4e2d\u8868\u73b0\u66f4\u5dee\u3002", "method": "\u63d0\u51fa\u4e86Robot Skill Language\uff08RSL\uff09\u4f5c\u4e3a\u62bd\u8c61\u5c42\uff0c\u8fde\u63a5\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u548c\u673a\u5668\u4eba\u6280\u80fd\uff1b\u8bbe\u8ba1\u4e86RSL\u7f16\u8bd1\u5668\u548c\u8c03\u8bd5\u5668\uff0c\u9a8c\u8bc1LLM\u751f\u6210\u7684\u7a0b\u5e8f\u5e76\u63d0\u4f9b\u9519\u8bef\u53cd\u9988\u4ee5\u4f18\u5316\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8868\u660eNRTrans\u5728\u591a\u79cdLLM\u548c\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8f7b\u91cf\u7ea7LLM\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u9a8c\u8bc1\u548c\u53cd\u9988\u673a\u5236\uff0c\u4e3aLLM\u751f\u6210\u7684\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5e94\u7528\u7684\u6548\u80fd\u3002"}}
{"id": "2508.18675", "pdf": "https://arxiv.org/pdf/2508.18675", "abs": "https://arxiv.org/abs/2508.18675", "authors": ["Xu Lu", "Weisong Sun", "Yiran Zhang", "Ming Hu", "Cong Tian", "Zhi Jin", "Yang Liu"], "title": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision", "categories": ["cs.SE"], "comment": null, "summary": "Automated code generation has long been considered the holy grail of software\nengineering. The emergence of Large Language Models (LLMs) has catalyzed a\nrevolutionary breakthrough in this area. However, existing methods that only\nrely on LLMs remain inadequate in the quality of generated code, offering no\nguarantees of satisfying practical requirements. They lack a systematic\nstrategy for requirements development and modeling. Recently, LLM-based agents\ntypically possess powerful abilities and play an essential role in facilitating\nthe alignment of LLM outputs with user requirements. In this paper, we envision\nthe first multi-agent framework for reliable code generation based on\n\\textsc{re}quirements \\textsc{de}velopment and \\textsc{fo}rmalization, named\n\\textsc{ReDeFo}. This framework incorporates three agents, highlighting their\naugmentation with knowledge and techniques of formal methods, into the\nrequirements-to-code generation pipeline to strengthen quality assurance. The\ncore of \\textsc{ReDeFo} is the use of formal specifications to bridge the gap\nbetween potentially ambiguous natural language requirements and precise\nexecutable code. \\textsc{ReDeFo} enables rigorous reasoning about correctness,\nuncovering hidden bugs, and enforcing critical properties throughout the\ndevelopment process. In general, our framework aims to take a promising step\ntoward realizing the long-standing vision of reliable, auto-generated software.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReDeFo\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u9700\u6c42\u5f00\u53d1\u548c\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u63d0\u5347\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5f25\u8865\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u5728\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\u548c\u8d28\u91cf\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u9700\u6c42\u5f00\u53d1\u7b56\u7565\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u4ee3\u7406\u7684\u591a\u4ee3\u7406\u6846\u67b6ReDeFo\uff0c\u878d\u5408\u5f62\u5f0f\u5316\u65b9\u6cd5\u7684\u77e5\u8bc6\u4e0e\u6280\u672f\uff0c\u7528\u4e8e\u9700\u6c42\u5230\u4ee3\u7801\u7684\u751f\u6210\u6d41\u7a0b\u3002", "result": "\u901a\u8fc7\u5f62\u5f0f\u5316\u89c4\u8303\u6865\u63a5\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e0e\u7cbe\u786e\u4ee3\u7801\uff0c\u589e\u5f3a\u4e86\u8d28\u91cf\u4fdd\u8bc1\uff0c\u652f\u6301\u6b63\u786e\u6027\u63a8\u7406\u548c\u7f3a\u9677\u53d1\u73b0\u3002", "conclusion": "ReDeFo\u4e3a\u5b9e\u73b0\u53ef\u9760\u81ea\u52a8\u751f\u6210\u8f6f\u4ef6\u7684\u76ee\u6807\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.18781", "pdf": "https://arxiv.org/pdf/2508.18781", "abs": "https://arxiv.org/abs/2508.18781", "authors": ["Lisai Zhang", "Baohan Xu", "Siqian Yang", "Mingyu Yin", "Jing Liu", "Chao Xu", "Siqi Wang", "Yidi Wu", "Yuxin Hong", "Zihao Zhang", "Yanzhang Liang", "Yudong Jiang"], "title": "AniME: Adaptive Multi-Agent Planning for Long Animation Generation", "categories": ["cs.AI", "cs.MM"], "comment": "2 pages, Technical Report", "summary": "We present AniME, a director-oriented multi-agent system for automated\nlong-form anime production, covering the full workflow from a story to the\nfinal video. The director agent keeps a global memory for the whole workflow,\nand coordinates several downstream specialized agents. By integrating\ncustomized Model Context Protocol (MCP) with downstream model instruction, the\nspecialized agent adaptively selects control conditions for diverse sub-tasks.\nAniME produces cinematic animation with consistent characters and synchronized\naudio visual elements, offering a scalable solution for AI-driven anime\ncreation.", "AI": {"tldr": "AniME\u662f\u4e00\u4e2a\u5bfc\u6f14\u5bfc\u5411\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u957f\u7bc7\u52a8\u753b\u5236\u4f5c\uff0c\u6db5\u76d6\u4ece\u6545\u4e8b\u5230\u6700\u7ec8\u89c6\u9891\u7684\u5168\u6d41\u7a0b\u3002", "motivation": "\u89e3\u51b3\u957f\u7bc7\u52a8\u753b\u5236\u4f5c\u7684\u81ea\u52a8\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u81f4\u6027\u548c\u540c\u6b65\u6027\u5f3a\u7684AI\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5bfc\u6f14\u4ee3\u7406\u7ef4\u62a4\u5168\u5c40\u8bb0\u5fc6\uff0c\u534f\u8c03\u4e0b\u6e38\u4e13\u4e1a\u4ee3\u7406\uff0c\u7ed3\u5408MCP\u534f\u8bae\u81ea\u9002\u5e94\u9009\u62e9\u5b50\u4efb\u52a1\u63a7\u5236\u6761\u4ef6\u3002", "result": "\u751f\u6210\u5177\u6709\u4e00\u81f4\u6027\u548c\u540c\u6b65\u6027\u7684\u7535\u5f71\u7ea7\u52a8\u753b\uff0c\u9002\u7528\u4e8e\u89c4\u6a21\u5316AI\u52a8\u753b\u521b\u4f5c\u3002", "conclusion": "AniME\u4e3aAI\u9a71\u52a8\u7684\u52a8\u753b\u5236\u4f5c\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18597", "pdf": "https://arxiv.org/pdf/2508.18597", "abs": "https://arxiv.org/abs/2508.18597", "authors": ["Xiaohao Sun", "Divyam Goel", "Angle X. Chang"], "title": "SemLayoutDiff: Semantic Layout Generation with Diffusion Model for Indoor Scene Synthesis", "categories": ["cs.GR", "cs.CV"], "comment": "Project page: https://3dlg-hcvc.github.io/SemLayoutDiff/", "summary": "We present SemLayoutDiff, a unified model for synthesizing diverse 3D indoor\nscenes across multiple room types. The model introduces a scene layout\nrepresentation combining a top-down semantic map and attributes for each\nobject. Unlike prior approaches, which cannot condition on architectural\nconstraints, SemLayoutDiff employs a categorical diffusion model capable of\nconditioning scene synthesis explicitly on room masks. It first generates a\ncoherent semantic map, followed by a cross-attention-based network to predict\nfurniture placements that respect the synthesized layout. Our method also\naccounts for architectural elements such as doors and windows, ensuring that\ngenerated furniture arrangements remain practical and unobstructed. Experiments\non the 3D-FRONT dataset show that SemLayoutDiff produces spatially coherent,\nrealistic, and varied scenes, outperforming previous methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86SemLayoutDiff\uff0c\u4e00\u79cd\u7edf\u4e00\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u591a\u6837\u5316\u76843D\u5ba4\u5185\u573a\u666f\u5e03\u5c40\uff0c\u7ed3\u5408\u8bed\u4e49\u5730\u56fe\u4e0e\u7269\u4f53\u5c5e\u6027\uff0c\u5e76\u901a\u8fc7\u6269\u6563\u6a21\u578b\u548c\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u7a7a\u95f4\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u57fa\u4e8e\u5efa\u7b51\u7ea6\u675f\u751f\u6210\u573a\u666f\u7684\u95ee\u9898\uff0c\u5f3a\u8c03\u7a7a\u95f4\u4e00\u81f4\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u7ed3\u5408\u8bed\u4e49\u5730\u56fe\u4e0e\u6269\u6563\u6a21\u578b\uff0c\u5206\u6b65\u751f\u6210\u8bed\u4e49\u5e03\u5c40\u548c\u5bb6\u5177\u5e03\u7f6e\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u4fdd\u6301\u5bb6\u5177\u4e0e\u5e03\u5c40\u7684\u534f\u8c03\u3002", "result": "\u57283D-FRONT\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u751f\u6210\u573a\u666f\u66f4\u4e00\u81f4\u3001\u771f\u5b9e\u4e14\u591a\u6837\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SemLayoutDiff\u901a\u8fc7\u663e\u5f0f\u5efa\u7b51\u7ea6\u675f\u548c\u5206\u5c42\u751f\u6210\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u573a\u666f\u5408\u6210\u7684\u8d28\u91cf\u4e0e\u591a\u6837\u6027\u3002"}}
{"id": "2508.18481", "pdf": "https://arxiv.org/pdf/2508.18481", "abs": "https://arxiv.org/abs/2508.18481", "authors": ["Yue Yang", "Xue Xie", "Xinkai Wang", "Hui Zhang", "Chiming Yu", "Xiaoxian Xiong", "Lifeng Zhu", "Yuanyi Zheng", "Jue Cen", "Bruce Daniel", "Fred Baik"], "title": "Impact of Target and Tool Visualization on Depth Perception and Usability in Optical See-Through AR", "categories": ["cs.HC", "cs.CV", "cs.GR"], "comment": null, "summary": "Optical see-through augmented reality (OST-AR) systems like Microsoft\nHoloLens 2 hold promise for arm's distance guidance (e.g., surgery), but depth\nperception of the hologram and occlusion of real instruments remain\nchallenging. We present an evaluation of how visualizing the target object with\ndifferent transparencies and visualizing a tracked tool (virtual proxy vs. real\ntool vs. no tool tracking) affects depth perception and system usability. Ten\nparticipants performed two experiments on HoloLens 2. In Experiment 1, we\ncompared high-transparency vs. low-transparency target rendering in a depth\nmatching task at arm's length. In Experiment 2, participants performed a\nsimulated surgical pinpoint task on a frontal bone target under six\nvisualization conditions ($2 \\times 3$: two target transparencies and three\ntool visualization modes: virtual tool hologram, real tool, or no tool\ntracking). We collected data on depth matching error, target localization\nerror, system usability, task workload, and qualitative feedback. Results show\nthat a more opaque target yields significantly lower depth estimation error\nthan a highly transparent target at arm's distance. Moreover, showing the real\ntool (occluding the virtual target) led to the highest accuracy and usability\nwith the lowest workload, while not tracking the tool yielded the worst\nperformance and user ratings. However, making the target highly transparent,\nwhile allowing the real tool to remain visible, slightly impaired depth cues\nand did not improve usability. Our findings underscore that correct occlusion\ncues, rendering virtual content opaque and occluding it with real tools in real\ntime, are critical for depth perception and precision in OST-AR. Designers of\narm-distance AR systems should prioritize robust tool tracking and occlusion\nhandling; if unavailable, cautiously use transparency to balance depth\nperception and tool visibility.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e0d\u540c\u900f\u660e\u5ea6\u548c\u5de5\u5177\u8ffd\u8e2a\u65b9\u5f0f\u5bf9\u5149\u900f\u89c6\u589e\u5f3a\u73b0\u5b9e\uff08OST-AR\uff09\u7cfb\u7edf\u4e2d\u6df1\u5ea6\u611f\u77e5\u548c\u7cfb\u7edf\u53ef\u7528\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u900f\u660e\u7684\u76ee\u6807\u548c\u5b9e\u65f6\u5de5\u5177\u8ffd\u8e2a\u80fd\u663e\u8457\u63d0\u9ad8\u7cbe\u5ea6\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u89e3\u51b3\u5149\u900f\u89c6\u589e\u5f3a\u73b0\u5b9e\u7cfb\u7edf\u4e2d\u6df1\u5ea6\u611f\u77e5\u548c\u5b9e\u9645\u5de5\u5177\u906e\u6321\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u5728\u624b\u672f\u7b49\u8fd1\u8ddd\u79bb\u4efb\u52a1\u4e2d\u7684\u6307\u5bfc\u548c\u7cbe\u5ea6\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\uff0c\u5206\u522b\u6bd4\u8f83\u4e0d\u540c\u900f\u660e\u5ea6\u7684\u76ee\u6807\u6e32\u67d3\u548c\u4e09\u79cd\u5de5\u5177\u8ffd\u8e2a\u65b9\u5f0f\uff08\u865a\u62df\u5de5\u5177\u3001\u5b9e\u9645\u5de5\u5177\u3001\u65e0\u8ffd\u8e2a\uff09\u5bf9\u6df1\u5ea6\u5339\u914d\u548c\u6a21\u62df\u624b\u672f\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "result": "\u4e0d\u900f\u660e\u7684\u76ee\u6807\u663e\u8457\u964d\u4f4e\u6df1\u5ea6\u4f30\u8ba1\u8bef\u5dee\uff0c\u5b9e\u65f6\u5de5\u5177\u8ffd\u8e2a\u7684\u906e\u6321\u6548\u679c\u6700\u4f73\uff0c\u800c\u900f\u660e\u76ee\u6807\u663e\u793a\u867d\u5141\u8bb8\u5de5\u5177\u53ef\u89c1\uff0c\u5374\u8f7b\u5fae\u635f\u5bb3\u6df1\u5ea6\u611f\u77e5\u4e14\u672a\u6539\u5584\u53ef\u7528\u6027\u3002", "conclusion": "\u5728OST-AR\u7cfb\u7edf\u4e2d\uff0c\u6b63\u786e\u7684\u906e\u6321\u7ebf\u7d22\u3001\u4e0d\u900f\u660e\u7684\u865a\u62df\u5185\u5bb9\u53ca\u5b9e\u65f6\u5de5\u5177\u906e\u6321\u662f\u6df1\u5ea6\u611f\u77e5\u548c\u7cbe\u5ea6\u7684\u5173\u952e\uff0c\u8bbe\u8ba1\u5e94\u4f18\u5148\u8003\u8651\u5de5\u5177\u8ffd\u8e2a\u548c\u906e\u6321\u5904\u7406\u3002"}}
{"id": "2508.18725", "pdf": "https://arxiv.org/pdf/2508.18725", "abs": "https://arxiv.org/abs/2508.18725", "authors": ["Ruichen Zhang", "Guangyuan Liu", "Yinqiu Liu", "Changyuan Zhao", "Jiacheng Wang", "Yunting Xu", "Dusit Niyato", "Jiawen Kang", "Yonghui Li", "Shiwen Mao", "Sumei Sun", "Xuemin Shen", "Dong In Kim"], "title": "Toward Edge General Intelligence with Agentic AI and Agentification: Concepts, Technologies, and Future Directions", "categories": ["cs.NI", "cs.IT", "math.IT"], "comment": null, "summary": "The rapid expansion of sixth-generation (6G) wireless networks and the\nInternet of Things (IoT) has catalyzed the evolution from centralized cloud\nintelligence towards decentralized edge general intelligence. However,\ntraditional edge intelligence methods, characterized by static models and\nlimited cognitive autonomy, fail to address the dynamic, heterogeneous, and\nresource-constrained scenarios inherent to emerging edge networks. Agentic\nartificial intelligence (Agentic AI) emerges as a transformative solution,\nenabling edge systems to autonomously perceive multimodal environments, reason\ncontextually, and adapt proactively through continuous\nperception-reasoning-action loops. In this context, the agentification of edge\nintelligence serves as a key paradigm shift, where distributed entities evolve\ninto autonomous agents capable of collaboration and continual adaptation. This\npaper presents a comprehensive survey dedicated to Agentic AI and\nagentification frameworks tailored explicitly for edge general intelligence.\nFirst, we systematically introduce foundational concepts and clarify\ndistinctions from traditional edge intelligence paradigms. Second, we analyze\nimportant enabling technologies, including compact model compression,\nenergy-aware computing strategies, robust connectivity frameworks, and advanced\nknowledge representation and reasoning mechanisms. Third, we provide\nrepresentative case studies demonstrating Agentic AI's capabilities in\nlow-altitude economy networks, intent-driven networking, vehicular networks,\nand human-centric service provisioning, supported by numerical evaluations.\nFurthermore, we identify current research challenges, review emerging\nopen-source platforms, and highlight promising future research directions to\nguide robust, scalable, and trustworthy Agentic AI deployments for\nnext-generation edge environments.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\uff08Agentic AI\uff09\u5728\u8fb9\u7f18\u901a\u7528\u667a\u80fd\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u5176\u4e0e\u4f20\u7edf\u8fb9\u7f18\u667a\u80fd\u7684\u533a\u522b\u3001\u5173\u952e\u6280\u672f\u3001\u6848\u4f8b\u7814\u7a76\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u77406G\u548cIoT\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4f20\u7edf\u8fb9\u7f18\u667a\u80fd\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9\u52a8\u6001\u3001\u5f02\u6784\u548c\u8d44\u6e90\u53d7\u9650\u7684\u573a\u666f\uff0c\u4ee3\u7406AI\u63d0\u4f9b\u4e86\u53d8\u9769\u6027\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u9996\u5148\u4ecb\u7ecd\u57fa\u7840\u6982\u5ff5\u548c\u4e0e\u4f20\u7edf\u8fb9\u7f18\u667a\u80fd\u7684\u533a\u522b\uff0c\u968f\u540e\u5206\u6790\u5173\u952e\u6280\u672f\uff08\u5982\u6a21\u578b\u538b\u7f29\u3001\u80fd\u6548\u8ba1\u7b97\u7b49\uff09\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5e94\u7528\u6548\u679c\u3002", "result": "\u4ee3\u7406AI\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u7f51\u7edc\u3001\u8f66\u8f86\u7f51\u7edc\u7b49\u9886\u57df\u5c55\u793a\u4e86\u5f3a\u5927\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u4ee3\u7406AI\u662f\u8fb9\u7f18\u667a\u80fd\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u7814\u7a76\u6311\u6218\u4ee5\u5b9e\u73b0\u89c4\u6a21\u5316\u3001\u53ef\u4fe1\u8d56\u7684\u90e8\u7f72\u3002"}}
{"id": "2508.19090", "pdf": "https://arxiv.org/pdf/2508.19090", "abs": "https://arxiv.org/abs/2508.19090", "authors": ["Rohan Juneja", "Pranav Dangi", "Thilini Kaushalya Bandara", "Zhaoying Li", "Dhananjaya Wijerathne", "Li-Shiuan Peh", "Tulika Mitra"], "title": "Building an Open CGRA Ecosystem for Agile Innovation", "categories": ["cs.AR"], "comment": null, "summary": "Modern computing workloads, particularly in AI and edge applications, demand\nhardware-software co-design to meet aggressive performance and energy targets.\nSuch co-design benefits from open and agile platforms that replace closed,\nvertically integrated development with modular, community-driven ecosystems.\nCoarse-Grained Reconfigurable Architectures (CGRAs), with their unique balance\nof flexibility and efficiency are particularly well-suited for this paradigm.\nWhen built on open-source hardware generators and software toolchains, CGRAs\nprovide a compelling foundation for architectural exploration, cross-layer\noptimization, and real-world deployment. In this paper, we will present an open\nCGRA ecosystem that we have developed to support agile innovation across the\nstack. Our contributions include HyCUBE, a CGRA with a reconfigurable\nsingle-cycle multi-hop interconnect for efficient data movement; PACE, which\nembeds a power-efficient HyCUBE within a RISC-V SoC targeting edge computing;\nand Morpher, a fully open-source, architecture-adaptive CGRA design framework\nthat supports design space exploration, compilation, simulation, and\nvalidation. By embracing openness at every layer, we aim to lower barriers to\ninnovation, enable reproducible research, and demonstrate how CGRAs can anchor\nthe next wave of agile hardware development. We will conclude with a call for a\nunified abstraction layer for CGRAs and spatial accelerators, one that\ndecouples hardware specialization from software development. Such a\nrepresentation would unlock architectural portability, compiler innovation, and\na scalable, open foundation for spatial computing.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684CGRA\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u62ecHyCUBE\u3001PACE\u548cMorpher\uff0c\u65e8\u5728\u964d\u4f4e\u521b\u65b0\u95e8\u69db\u5e76\u63a8\u52a8\u7a7a\u95f4\u8ba1\u7b97\u7684\u53d1\u5c55\u3002", "motivation": "\u73b0\u4ee3AI\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u9700\u8981\u5f00\u653e\u7684\u654f\u6377\u5e73\u53f0\uff0cCGRA\u56e0\u5176\u7075\u6d3b\u6027\u548c\u9ad8\u6548\u6027\u975e\u5e38\u9002\u5408\u8fd9\u4e00\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86HyCUBE\uff08\u5177\u6709\u53ef\u91cd\u6784\u5355\u5468\u671f\u591a\u8df3\u4e92\u8fde\u7684CGRA\uff09\u3001PACE\uff08\u96c6\u6210\u5728RISC-V SoC\u4e2d\u7684\u4f4e\u529f\u8017CGRA\uff09\u548cMorpher\uff08\u5f00\u6e90CGRA\u8bbe\u8ba1\u6846\u67b6\uff09\u3002", "result": "\u901a\u8fc7\u8fd9\u4e9b\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u67b6\u6784\u63a2\u7d22\u3001\u8de8\u5c42\u4f18\u5316\u548c\u5b9e\u9645\u90e8\u7f72\uff0c\u63a8\u52a8\u4e86\u654f\u6377\u786c\u4ef6\u5f00\u53d1\u7684\u521b\u65b0\u3002", "conclusion": "\u547c\u5401\u5236\u5b9a\u7edf\u4e00\u7684CGRA\u62bd\u8c61\u5c42\uff0c\u4ee5\u89e3\u8026\u786c\u4ef6\u7279\u5316\u4e0e\u8f6f\u4ef6\u5f00\u53d1\uff0c\u4fc3\u8fdb\u7a7a\u95f4\u8ba1\u7b97\u7684\u5f00\u653e\u4e0e\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.19160", "pdf": "https://arxiv.org/pdf/2508.19160", "abs": "https://arxiv.org/abs/2508.19160", "authors": ["Dmitry Filippov", "Peter Yang", "Prakash Murali"], "title": "Architecting Distributed Quantum Computers: Design Insights from Resource Estimation", "categories": ["quant-ph", "cs.AR", "cs.DC", "cs.ET"], "comment": null, "summary": "To enable practically useful quantum computing, we require hundreds to\nthousands of logical qubits (collections of physical qubits with error\ncorrection). Current monolithic device architectures have scaling limits beyond\nfew tens of logical qubits. To scale up, we require architectures that\norchestrate several monolithic devices into a distributed quantum computing\nsystem. Currently, resource estimation, which is crucial for determining\nhardware needs and bottlenecks, focuses exclusively on monolithic systems. Our\nwork fills this gap and answers key architectural design questions about\ndistributed systems, including the impact of distribution on application\nresource needs, the organization of qubits across nodes and the requirements of\nentanglement distillation (quantum network). To answer these questions, we\ndevelop a novel resource estimation framework that models the key components of\nthe distributed execution stack. We analyse the performance of practical\nquantum algorithms on various hardware configurations, spanning different qubit\nspeeds, entanglement generation rates and distillation protocols. We show that\ndistributed architectures have practically feasible resource requirements; for\na node size of 45K qubits, distributed systems need on average 1.4X higher\nnumber of physical qubits and 4X higher execution time compared to monolithic\narchitectures, but with more favourable hardware implementation prospects. Our\ninsights on entanglement generation rates, node sizes and architecture have the\npotential to inform system designs in the coming years.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u7684\u8d44\u6e90\u4f30\u7b97\u6846\u67b6\uff0c\u5206\u6790\u4e86\u5176\u6027\u80fd\u4e0e\u8d44\u6e90\u9700\u6c42\uff0c\u5e76\u4e0e\u5355\u7247\u67b6\u6784\u8fdb\u884c\u6bd4\u8f83\u3002", "motivation": "\u73b0\u6709\u5355\u7247\u91cf\u5b50\u8ba1\u7b97\u8bbe\u5907\u5728\u89c4\u6a21\u4e0a\u53d7\u9650\uff0c\u5206\u5e03\u5f0f\u67b6\u6784\u6709\u671b\u7a81\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u4f46\u7f3a\u4e4f\u76f8\u5173\u8d44\u6e90\u4f30\u7b97\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u8d44\u6e90\u4f30\u7b97\u6846\u67b6\uff0c\u6a21\u62df\u5206\u5e03\u5f0f\u6267\u884c\u6808\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u5206\u6790\u4e0d\u540c\u786c\u4ef6\u914d\u7f6e\u4e0b\u7684\u91cf\u5b50\u7b97\u6cd5\u6027\u80fd\u3002", "result": "\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u8d44\u6e90\u9700\u6c42\uff08\u7269\u7406\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u548c\u6267\u884c\u65f6\u95f4\uff09\u6bd4\u5355\u7247\u67b6\u6784\u9ad8\uff0c\u4f46\u786c\u4ef6\u5b9e\u73b0\u524d\u666f\u66f4\u597d\u3002", "conclusion": "\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u8d44\u6e90\u4f30\u7b97\u7684\u53ef\u884c\u6027\u548c\u8bbe\u8ba1\u89c1\u89e3\u4e3a\u672a\u6765\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2508.18576", "pdf": "https://arxiv.org/pdf/2508.18576", "abs": "https://arxiv.org/abs/2508.18576", "authors": ["Farzad Habibi", "Juncheng Fang", "Tania Lorido-Botran", "Faisal Nawab"], "title": "Brook-2PL: Tolerating High Contention Workloads with A Deadlock-Free Two-Phase Locking Protocol", "categories": ["cs.DB"], "comment": null, "summary": "The problem of hotspots remains a critical challenge in high-contention\nworkloads for concurrency control (CC) protocols. Traditional concurrency\ncontrol approaches encounter significant difficulties under high contention,\nresulting in excessive transaction aborts and deadlocks. In this paper, we\npropose Brook-2PL, a novel two-phase locking (2PL) protocol that (1) introduces\nSLW-Graph for deadlock-free transaction execution, and (2) proposes partial\ntransaction chopping for early lock release. Previous methods suffer from\ntransaction aborts that lead to wasted work and can further burden the system\ndue to their cascading effects. Brook-2PL addresses this limitation by\nstatically analyzing a new graph-based dependency structure called SLW-Graph,\nenabling deadlock-free two-phase locking through predetermined lock\nacquisition. Brook-2PL also reduces contention by enabling early lock release\nusing partial transaction chopping and static transaction analysis. We overcome\nthe inherent limitations of traditional transaction chopping by providing a\nmore flexible chopping method. Evaluation using both our synthetic online game\nstore workload and the TPC-C benchmark shows that Brook-2PL significantly\noutperforms state-of-the-art CC protocols. Brook-2PL achieves an average\nspeed-up of 2.86x while reducing tail latency (p95) by 48% in the TPC-C\nbenchmark.", "AI": {"tldr": "Brook-2PL\u662f\u4e00\u79cd\u65b0\u578b\u4e24\u9636\u6bb5\u9501\u534f\u8bae\uff0c\u901a\u8fc7SLW-Graph\u548c\u90e8\u5206\u4e8b\u52a1\u5206\u5272\u89e3\u51b3\u9ad8\u4e89\u7528\u4e0b\u7684\u70ed\u70b9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5e76\u53d1\u63a7\u5236\u534f\u8bae\u5728\u9ad8\u4e89\u7528\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u5927\u91cf\u4e8b\u52a1\u4e2d\u6b62\u548c\u6b7b\u9501\uff0cBrook-2PL\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165SLW-Graph\u5b9e\u73b0\u65e0\u6b7b\u9501\u4e8b\u52a1\u6267\u884c\uff0c\u5e76\u901a\u8fc7\u90e8\u5206\u4e8b\u52a1\u5206\u5272\u5b9e\u73b0\u65e9\u671f\u9501\u91ca\u653e\u3002", "result": "\u5728TPC-C\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBrook-2PL\u5e73\u5747\u63d0\u901f2.86\u500d\uff0c\u5c3e\u90e8\u5ef6\u8fdf\u964d\u4f4e48%\u3002", "conclusion": "Brook-2PL\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u4e89\u7528\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u534f\u8bae\u3002"}}
{"id": "2508.18572", "pdf": "https://arxiv.org/pdf/2508.18572", "abs": "https://arxiv.org/abs/2508.18572", "authors": ["Zhiqiang Xie", "Ziyi Xu", "Mark Zhao", "Yuwei An", "Vikram Sharma Mailthody", "Scott Mahlke", "Michael Garland", "Christos Kozyrakis"], "title": "Strata: Hierarchical Context Caching for Long Context Language Model Serving", "categories": ["cs.DC"], "comment": "13 pages, 14 figures, under peer review", "summary": "Large Language Models (LLMs) with expanding context windows face significant\nperformance hurdles. While caching key-value (KV) states is critical for\navoiding redundant computation, the storage footprint of long-context caches\nquickly exceeds GPU memory capacity, forcing production systems to adopt\nhierarchical caching across memory hierarchies. However, transferring large\ncached contexts back to the GPU introduces severe performance bottlenecks:\nfragmented I/O from paged layouts prevents full bandwidth utilization, and\nexisting schedulers fail to account for cache-loading delays, leaving systems\nloading-bound rather than compute-bound. We present Strata, a hierarchical\ncontext caching framework designed for efficient long context LLM serving.\nStrata introduces GPU-assisted I/O to combat KV cache fragmentation, decoupling\nGPU and CPU memory layouts and employs cache-aware request scheduling to\nbalance compute with I/O latency and overlapping unavoidable stalls with\ncomplementary tasks. Built on SGLang and deployed in production, Strata\nachieves up to 5x lower Time-To-First-Token (TTFT) compared to vLLM + LMCache\nand 3.75x speedup over NVIDIA TensorRT-LLM on long-context benchmarks, without\ndegrading short-context performance.", "AI": {"tldr": "Strata\u6846\u67b6\u901a\u8fc7GPU\u8f85\u52a9I/O\u548c\u7f13\u5b58\u611f\u77e5\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u670d\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u54cd\u5e94\u901f\u5ea6\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587LLM\u7684\u6027\u80fd\u74f6\u9888\u5728\u4e8eKV\u7f13\u5b58\u5b58\u50a8\u548c\u52a0\u8f7d\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7cfb\u7edf\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5e26\u5bbd\u4e14\u8c03\u5ea6\u6548\u7387\u4f4e\u3002", "method": "\u63d0\u51faStrata\u6846\u67b6\uff0c\u91c7\u7528GPU\u8f85\u52a9I/O\u89e3\u51b3\u7f13\u5b58\u788e\u7247\u5316\uff0c\u5e76\u901a\u8fc7\u7f13\u5b58\u611f\u77e5\u8c03\u5ea6\u5e73\u8861\u8ba1\u7b97\u4e0eI/O\u5ef6\u8fdf\u3002", "result": "Strata\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u6bd4vLLM + LMCache\u66f4\u4f4e\u7684TTFT\uff085\u500d\uff09\u548c\u6bd4NVIDIA TensorRT-LLM\u66f4\u5feb\u7684\u901f\u5ea6\uff083.75\u500d\uff09\u3002", "conclusion": "Strata\u4ee5\u9ad8\u6548\u7684\u65b9\u5f0f\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u670d\u52a1\u7684\u6027\u80fd\u95ee\u9898\uff0c\u4e14\u4e0d\u5f71\u54cd\u77ed\u4e0a\u4e0b\u6587\u6027\u80fd\u3002"}}
{"id": "2508.18721", "pdf": "https://arxiv.org/pdf/2508.18721", "abs": "https://arxiv.org/abs/2508.18721", "authors": ["Yunrui Pei", "Hongshu Wang", "Wenjie Zhang", "Yun Lin", "Weiyu Kong", "Jin song Dong"], "title": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "categories": ["cs.SE"], "comment": null, "summary": "Dynamic data dependency, answering \"why a variable has this value?\", is\ncritical for debugging. Given a program step `s` reading a variable `v`,\nfinding the dynamic definition of `v` is challenging. Traditional methods\nrequire either (1) exhaustive instrumentation of all possible definitions of\n`v` in one run or (2) replicating the run to re-examine reads/writes - both\ncostly. If `v` is defined in a library, instrumentation becomes expensive; for\nnon-deterministic programs, replication is infeasible.\n  We propose RecovSlicing, which computes dynamic data dependency in a single\nrun with partial instrumentation. We leverage LLMs to infer program behavior\nfrom a partially recorded trace and code context. Given a trace and a slicing\ncriterion (step `s` and variable `v`), RecovSlicing estimates the runtime\ndefinition of `v` by recovering the missing execution.It also supports implicit\nvariables, such as those in `list.get(i)`. Technically, RecovSlicing tackles:\n(1) recovering runtime values and structures, and (2) aligning recovered\nvariables with recorded memory to analyze definitions.\n  We evaluate RecovSlicing on 8,300 data dependencies across three slicing\nbenchmarks, comparing it with Slicer4J, ND-Slicer, LLM Slicer, and re-execution\nSlicer. RecovSlicing achieves accuracy of 80.3%, 91.1%, and 98.3%,\noutperforming the best baseline (39.0%, 82.0%, 59.9%), and also leads in recall\n(91.1%, 91.1%, 98.3% vs. 53.4%, 79.1%, 87.1%). Integrated into a regression bug\nlocalizer, it enables finding 16% more regressions.", "AI": {"tldr": "RecovSlicing\u662f\u4e00\u79cd\u52a8\u6001\u6570\u636e\u4f9d\u8d56\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u6b21\u8fd0\u884c\u548c\u90e8\u5206\u63d2\u6869\u89e3\u51b3\u53d8\u91cf\u5b9a\u4e49\u8ffd\u8e2a\u95ee\u9898\uff0c\u5229\u7528LLM\u63a8\u65ad\u7a0b\u5e8f\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5168\u9762\u63d2\u6869\u6216\u91cd\u590d\u8fd0\u884c\uff0c\u6210\u672c\u9ad8\u4e14\u5bf9\u975e\u786e\u5b9a\u6027\u7a0b\u5e8f\u4e0d\u53ef\u884c\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "RecovSlicing\u7ed3\u5408\u90e8\u5206\u8bb0\u5f55\u7684\u6267\u884c\u8f68\u8ff9\u548c\u4ee3\u7801\u4e0a\u4e0b\u6587\uff0c\u4f7f\u7528LLM\u63a8\u65ad\u7f3a\u5931\u6267\u884c\uff0c\u652f\u6301\u663e\u5f0f\u548c\u9690\u5f0f\u53d8\u91cf\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRecovSlicing\u7684\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5e2e\u52a9\u5b9a\u4f4d\u66f4\u591a\u56de\u5f52\u9519\u8bef\u3002", "conclusion": "RecovSlicing\u4e3a\u52a8\u6001\u6570\u636e\u4f9d\u8d56\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7a0b\u5e8f\u8c03\u8bd5\u3002"}}
{"id": "2508.18944", "pdf": "https://arxiv.org/pdf/2508.18944", "abs": "https://arxiv.org/abs/2508.18944", "authors": ["Shashikant Verma", "Shanmuganathan Raman"], "title": "PanoHair: Detailed Hair Strand Synthesis on Volumetric Heads", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Achieving realistic hair strand synthesis is essential for creating lifelike\ndigital humans, but producing high-fidelity hair strand geometry remains a\nsignificant challenge. Existing methods require a complex setup for data\nacquisition, involving multi-view images captured in constrained studio\nenvironments. Additionally, these methods have longer hair volume estimation\nand strand synthesis times, which hinder efficiency. We introduce PanoHair, a\nmodel that estimates head geometry as signed distance fields using knowledge\ndistillation from a pre-trained generative teacher model for head synthesis.\nOur approach enables the prediction of semantic segmentation masks and 3D\norientations specifically for the hair region of the estimated geometry. Our\nmethod is generative and can generate diverse hairstyles with latent space\nmanipulations. For real images, our approach involves an inversion process to\ninfer latent codes and produces visually appealing hair strands, offering a\nstreamlined alternative to complex multi-view data acquisition setups. Given\nthe latent code, PanoHair generates a clean manifold mesh for the hair region\nin under 5 seconds, along with semantic and orientation maps, marking a\nsignificant improvement over existing methods, as demonstrated in our\nexperiments.", "AI": {"tldr": "PanoHair\u662f\u4e00\u79cd\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u6559\u5e08\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u5feb\u901f\u751f\u6210\u9ad8\u4fdd\u771f\u5934\u53d1\u51e0\u4f55\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u5934\u53d1\u5408\u6210\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u590d\u6742\u7684\u6570\u636e\u91c7\u96c6\u8bbe\u7f6e\u4e14\u6548\u7387\u4f4e\u4e0b\uff0cPanoHair\u65e8\u5728\u7b80\u5316\u6d41\u7a0b\u5e76\u63d0\u9ad8\u5934\u53d1\u5408\u6210\u7684\u901f\u5ea6\u548c\u591a\u6837\u6027\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u84b8\u998f\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4f30\u8ba1\u5934\u90e8\u51e0\u4f55\uff0c\u5e76\u9884\u6d4b\u5934\u53d1\u533a\u57df\u7684\u8bed\u4e49\u5206\u5272\u548c3D\u65b9\u5411\uff0c\u652f\u6301\u6f5c\u5728\u7a7a\u95f4\u64cd\u4f5c\u751f\u6210\u591a\u6837\u5316\u53d1\u578b\u3002", "result": "PanoHair\u80fd\u57285\u79d2\u5185\u751f\u6210\u5e72\u51c0\u7684\u5934\u53d1\u7f51\u683c\u53ca\u8bed\u4e49\u548c\u65b9\u5411\u56fe\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "PanoHair\u4e3a\u5934\u53d1\u5408\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.18499", "pdf": "https://arxiv.org/pdf/2508.18499", "abs": "https://arxiv.org/abs/2508.18499", "authors": ["Arlen Fan", "Fan Lei", "Steven R. Corman", "Ross Maciejewski"], "title": "Skeptik: A Hybrid Framework for Combating Potential Misinformation in Journalism", "categories": ["cs.HC"], "comment": "Arlen Fan and Fan Lei contributed equally to this research. Accepted\n  by ACM Transactions on Interactive Intelligent Systems (TiiS)", "summary": "The proliferation of misinformation in journalism, often stemming from flawed\nreasoning and logical fallacies, poses significant challenges to public\nunderstanding and trust in news media. Traditional fact-checking methods, while\nvaluable, are insufficient for detecting the subtle logical inconsistencies\nthat can mislead readers within seemingly factual content. To address this gap,\nwe introduce Skeptik, a hybrid framework that integrates Large Language Models\n(LLMs) with heuristic approaches to analyze and annotate potential logical\nfallacies and reasoning errors in online news articles. Operating as a web\nbrowser extension, Skeptik automatically highlights sentences that may contain\nlogical fallacies, provides detailed explanations, and offers multi-layered\ninterventions to help readers critically assess the information presented. The\nsystem is designed to be extensible, accommodating a wide range of fallacy\ntypes and adapting to evolving misinformation tactics. Through comprehensive\ncase studies, quantitative analyses, usability experiments, and expert\nevaluations, we demonstrate the effectiveness of Skeptik in enhancing readers'\ncritical examination of news content and promoting media literacy. Our\ncontributions include the development of an expandable classification system\nfor logical fallacies, the innovative integration of LLMs for real-time\nanalysis and annotation, and the creation of an interactive user interface that\nfosters user engagement and close reading. By emphasizing the logical integrity\nof textual content rather than relying solely on factual accuracy, Skeptik\noffers a comprehensive solution to combat potential misinformation in\njournalism. Ultimately, our framework aims to improve critical reading and\nprotect the public from deceptive information online and enhance the overall\ncredibility of news media.", "AI": {"tldr": "Skeptik\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u65b0\u95fb\u6587\u7ae0\u4e2d\u7684\u903b\u8f91\u8c2c\u8bef\uff0c\u5e2e\u52a9\u8bfb\u8005\u6279\u5224\u6027\u8bc4\u4f30\u5185\u5bb9\u3002", "motivation": "\u4f20\u7edf\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u65b0\u95fb\u4e2d\u7684\u903b\u8f91\u95ee\u9898\uff0cSkeptik\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u9ad8\u8bfb\u8005\u7684\u6279\u5224\u6027\u601d\u7ef4\u548c\u5bf9\u5a92\u4f53\u7684\u4fe1\u4efb\u3002", "method": "Skeptik\u4f5c\u4e3a\u6d4f\u89c8\u5668\u6269\u5c55\uff0c\u81ea\u52a8\u6807\u6ce8\u903b\u8f91\u8c2c\u8bef\u53e5\u5b50\uff0c\u63d0\u4f9b\u89e3\u91ca\u548c\u591a\u5c42\u6b21\u5e72\u9884\u3002\u7cfb\u7edf\u53ef\u6269\u5c55\uff0c\u9002\u5e94\u65b0\u7684\u8c2c\u8bef\u7c7b\u578b\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u3001\u5b9a\u91cf\u5206\u6790\u548c\u4e13\u5bb6\u8bc4\u4f30\uff0c\u8bc1\u660eSkeptik\u80fd\u6709\u6548\u63d0\u5347\u8bfb\u8005\u5bf9\u65b0\u95fb\u7684\u6279\u5224\u6027\u5206\u6790\u80fd\u529b\u3002", "conclusion": "Skeptik\u901a\u8fc7\u5173\u6ce8\u903b\u8f91\u5b8c\u6574\u6027\u800c\u975e\u4ec5\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4e3a\u6253\u51fb\u65b0\u95fb\u4e2d\u7684\u8bef\u5bfc\u4fe1\u606f\u63d0\u4f9b\u4e86\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18803", "pdf": "https://arxiv.org/pdf/2508.18803", "abs": "https://arxiv.org/abs/2508.18803", "authors": ["Jiaqi Wu", "Jing Liu", "Yang Liu", "Lixu Wang", "Zehua Wang", "Wei Chen", "Zijian Tian", "Richard Yu", "Victor C. M. Leung"], "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "The proliferation of Internet of things (IoT) devices in smart cities,\ntransportation, healthcare, and industrial applications, coupled with the\nexplosive growth of AI-driven services, has increased demands for efficient\ndistributed computing architectures and networks, driving cloud-edge-terminal\ncollaborative intelligence (CETCI) as a fundamental paradigm within the\nartificial intelligence of things (AIoT) community. With advancements in deep\nlearning, large language models (LLMs), and edge computing, CETCI has made\nsignificant progress with emerging AIoT applications, moving beyond isolated\nlayer optimization to deployable collaborative intelligence systems for AIoT\n(CISAIOT), a practical research focus in AI, distributed computing, and\ncommunications. This survey describes foundational architectures, enabling\ntechnologies, and scenarios of CETCI paradigms, offering a tutorial-style\nreview for CISAIOT beginners. We systematically analyze architectural\ncomponents spanning cloud, edge, and terminal layers, examining core\ntechnologies including network virtualization, container orchestration, and\nsoftware-defined networking, while presenting categorizations of collaboration\nparadigms that cover task offloading, resource allocation, and optimization\nacross heterogeneous infrastructures. Furthermore, we explain intelligent\ncollaboration learning frameworks by reviewing advances in federated learning,\ndistributed deep learning, edge-cloud model evolution, and reinforcement\nlearning-based methods. Finally, we discuss challenges (e.g., scalability,\nheterogeneity, interoperability) and future trends (e.g., 6G+, agents, quantum\ncomputing, digital twin), highlighting how integration of distributed computing\nand communication can address open issues and guide development of robust,\nefficient, and secure collaborative AIoT systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u662f\u4e00\u7bc7\u5173\u4e8e\u4e91\u8fb9\u7aef\u534f\u540c\u667a\u80fd\uff08CETCI\uff09\u5728AIoT\u4e2d\u5e94\u7528\u7684\u7efc\u8ff0\uff0c\u4ecb\u7ecd\u4e86\u5176\u57fa\u7840\u67b6\u6784\u3001\u5173\u952e\u6280\u672f\u53ca\u5e94\u7528\u573a\u666f\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u6311\u6218\u548c\u8d8b\u52bf\u3002", "motivation": "\u968f\u7740IoT\u8bbe\u5907\u548cAI\u670d\u52a1\u7684\u5feb\u901f\u589e\u957f\uff0c\u9ad8\u6548\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u7f51\u7edc\u67b6\u6784\u9700\u6c42\u589e\u52a0\uff0c\u63a8\u52a8\u4e86CETCI\u5728AIoT\u4e2d\u7684\u53d1\u5c55\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u4e91\u3001\u8fb9\u3001\u7aef\u4e09\u5c42\u67b6\u6784\uff0c\u63a2\u8ba8\u7f51\u7edc\u865a\u62df\u5316\u3001\u5bb9\u5668\u7f16\u6392\u7b49\u6280\u672f\uff0c\u5e76\u5206\u7c7b\u534f\u4f5c\u8303\u5f0f\u5982\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u7efc\u8ff0\u4e86CETCI\u7684\u67b6\u6784\u3001\u6280\u672f\u548c\u534f\u4f5c\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u667a\u80fd\u534f\u4f5c\u5b66\u4e60\u6846\u67b6\u53ca\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684\u672a\u6765\u65b9\u5411\u3002", "conclusion": "CETCI\u4e3aAIoT\u63d0\u4f9b\u4e86\u9ad8\u6548\u534f\u4f5c\u65b9\u6848\uff0c\u4f46\u9700\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u3001\u5f02\u6784\u6027\u7b49\u6311\u6218\uff0c\u672a\u6765\u53ef\u7ed3\u54086G+\u3001\u91cf\u5b50\u8ba1\u7b97\u7b49\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2508.18616", "pdf": "https://arxiv.org/pdf/2508.18616", "abs": "https://arxiv.org/abs/2508.18616", "authors": ["Yalong Zhang", "Rong-Hua Li", "Qi Zhang", "Guoren Wang"], "title": "Optimal $(\u03b1,\u03b2)$-Dense Subgraph Search in Bipartite Graphs", "categories": ["cs.DB"], "comment": null, "summary": "Dense subgraph search in bipartite graphs is a fundamental problem in graph\nanalysis, with wide-ranging applications in fraud detection, recommendation\nsystems, and social network analysis. The recently proposed $(\\alpha,\n\\beta)$-dense subgraph model has demonstrated superior capability in capturing\nthe intrinsic density structure of bipartite graphs compared to existing\nalternatives. However, despite its modeling advantages, the $(\\alpha,\n\\beta)$-dense subgraph model lacks efficient support for query processing and\ndynamic updates, limiting its practical utility in large-scale applications. To\naddress these limitations, we propose BD-Index, a novel index that answers\n$(\\alpha, \\beta)$-dense subgraph queries in optimal time while using only\nlinear space $O(|E|)$, making it well-suited for real-world applications\nrequiring both fast query processing and low memory consumption. We further\ndevelop two complementary maintenance strategies for dynamic bipartite graphs\nto support efficient updates to the BD-Index. The space-efficient strategy\nupdates the index in time complexity of $O(p \\cdot |E|^{1.5})$ per edge\ninsertion or deletion, while maintaining a low space cost of $O(|E|)$ (the same\nas the index itself), where $p$ is typically a small constant in real-world\ngraphs. In contrast, the time-efficient strategy significantly reduces the\nupdate time to $O(p \\cdot |E|)$ per edge update by maintaining auxiliary\norientation structures, at the cost of increased memory usage up to $O(p \\cdot\n|E|)$. These two strategies provide flexible trade-offs between maintenance\nefficiency and memory usage, enabling BD-Index to adapt to diverse application\nrequirements. Extensive experiments on 10 large-scale real-world datasets\ndemonstrate high efficiency and scalability of our proposed solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e8c\u5206\u56fe\u4e2d\u5bc6\u96c6\u5b50\u56fe\u641c\u7d22\u7684\u9ad8\u6548\u7d22\u5f15BD-Index\uff0c\u652f\u6301\u6700\u4f18\u67e5\u8be2\u65f6\u95f4\u548c\u7ebf\u6027\u7a7a\u95f4\u5360\u7528\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u79cd\u52a8\u6001\u7ef4\u62a4\u7b56\u7565\u4ee5\u5e73\u8861\u66f4\u65b0\u6548\u7387\u4e0e\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u5f53\u524d(\u03b1,\u03b2)-\u5bc6\u96c6\u5b50\u56fe\u6a21\u578b\u867d\u80fd\u6709\u6548\u6355\u6349\u4e8c\u5206\u56fe\u7684\u5bc6\u5ea6\u7ed3\u6784\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u6548\u7684\u67e5\u8be2\u5904\u7406\u548c\u52a8\u6001\u66f4\u65b0\u652f\u6301\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86BD-Index\uff0c\u4e00\u79cd\u652f\u6301\u6700\u4f18\u67e5\u8be2\u65f6\u95f4\u7684\u7ebf\u6027\u7a7a\u95f4\u7d22\u5f15\uff0c\u5e76\u5f00\u53d1\u4e86\u4e24\u79cd\u52a8\u6001\u7ef4\u62a4\u7b56\u7565\uff1a\u7a7a\u95f4\u9ad8\u6548\u7b56\u7565\uff08\u8f83\u4f4e\u66f4\u65b0\u590d\u6742\u5ea6\u4f46\u4fdd\u6301\u4f4e\u7a7a\u95f4\u6210\u672c\uff09\u548c\u65f6\u95f4\u9ad8\u6548\u7b56\u7565\uff08\u663e\u8457\u51cf\u5c11\u66f4\u65b0\u65f6\u95f4\u4f46\u589e\u52a0\u5185\u5b58\u4f7f\u7528\uff09\u3002", "result": "\u572810\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cBD-Index\u53ca\u5176\u7ef4\u62a4\u7b56\u7565\u5177\u6709\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "BD-Index\u53ca\u5176\u52a8\u6001\u7ef4\u62a4\u7b56\u7565\u80fd\u591f\u7075\u6d3b\u9002\u5e94\u4e0d\u540c\u5e94\u7528\u9700\u6c42\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.18667", "pdf": "https://arxiv.org/pdf/2508.18667", "abs": "https://arxiv.org/abs/2508.18667", "authors": ["Jiakun Yan", "Marc Snir", "Yanfei Guo"], "title": "Examining MPI and its Extensions for Asynchronous Multithreaded Communication", "categories": ["cs.DC"], "comment": "This preprint has not undergone peer review. The Version of Record of\n  this contribution (with improvements after peer review) will be published in\n  EuroMPI25", "summary": "The increasing complexity of HPC architectures and the growing adoption of\nirregular scientific algorithms demand efficient support for asynchronous,\nmultithreaded communication. This need is especially pronounced with\nAsynchronous Many-Task (AMT) systems. This communication pattern was not a\nconsideration during the design of the original MPI specification. The MPI\ncommunity has recently introduced several extensions to address these evolving\nrequirements. This work evaluates two such extensions, the Virtual\nCommunication Interface (VCI) and the Continuation extensions, in the context\nof an established AMT runtime HPX. We begin by using an MPI-level\nmicrobenchmark, modeled from HPX's low-level communication mechanism, to\nmeasure the peak performance potential of these extensions. We then integrate\nthem into HPX to evaluate their effectiveness in real-world scenarios. Our\nresults show that while these extensions can enhance performance compared to\nstandard MPI, areas for improvement remain. The current continuation proposal\nlimits the maximum multithreaded message rate achievable in the multi-VCI\nsetting. Furthermore, the recommended one-VCI-per-thread mode proves\nineffective in real-world systems due to the attentiveness problem. These\nfindings underscore the importance of improving intra-VCI threading efficiency\nto achieve scalable multithreaded communication and fully realize the benefits\nof recent MPI extensions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86MPI\u7684\u4e24\u4e2a\u6269\u5c55\uff08VCI\u548cContinuation\uff09\u5728AMT\u7cfb\u7edfHPX\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5b83\u4eec\u867d\u6709\u6539\u8fdb\u4f46\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u968f\u7740\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u7684\u590d\u6742\u5316\u548c\u4e0d\u89c4\u5219\u79d1\u5b66\u7b97\u6cd5\u7684\u666e\u53ca\uff0c\u5f02\u6b65\u591a\u7ebf\u7a0b\u901a\u4fe1\u9700\u6c42\u589e\u52a0\uff0cMPI\u7684\u539f\u59cb\u8bbe\u8ba1\u672a\u8003\u8651\u6b64\u9700\u6c42\uff0c\u9700\u8bc4\u4f30\u5176\u65b0\u6269\u5c55\u7684\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u5fae\u57fa\u51c6\u6d4b\u8bd5\u548cHPX\u96c6\u6210\uff0c\u8bc4\u4f30VCI\u548cContinuation\u6269\u5c55\u7684\u5cf0\u503c\u6027\u80fd\u548c\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "result": "\u65b0\u6269\u5c55\u76f8\u6bd4\u6807\u51c6MPI\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46Continuation\u9650\u5236\u4e86\u591aVCI\u7684\u591a\u7ebf\u7a0b\u6d88\u606f\u901f\u7387\uff0c\u5355VCI\u6a21\u5f0f\u56e0\u6ce8\u610f\u529b\u95ee\u9898\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "\u9700\u63d0\u9ad8VCI\u5185\u7ebf\u7a0b\u6548\u7387\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u591a\u7ebf\u7a0b\u901a\u4fe1\uff0c\u5145\u5206\u53d1\u6325MPI\u6269\u5c55\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.18771", "pdf": "https://arxiv.org/pdf/2508.18771", "abs": "https://arxiv.org/abs/2508.18771", "authors": ["Kexin Sun", "Hongyu Kuang", "Sebastian Baltes", "Xin Zhou", "He Zhang", "Xiaoxing Ma", "Guoping Rong", "Dong Shao", "Christoph Treude"], "title": "Does AI Code Review Lead to Code Changes? A Case Study of GitHub Actions", "categories": ["cs.SE"], "comment": null, "summary": "AI-based code review tools automatically review and comment on pull requests\nto improve code quality. Despite their growing presence, little is known about\ntheir actual impact. We present a large-scale empirical study of 16 popular\nAI-based code review actions for GitHub workflows, analyzing more than 22,000\nreview comments in 178 repositories. We investigate (1) how these tools are\nadopted and configured, (2) whether their comments lead to code changes, and\n(3) which factors influence their effectiveness. We develop a two-stage\nLLM-assisted framework to determine whether review comments are addressed, and\nuse interpretable machine learning to identify influencing factors. Our\nfindings show that, while adoption is growing, effectiveness varies widely.\nComments that are concise, contain code snippets, and are manually triggered,\nparticularly those from hunk-level review tools, are more likely to result in\ncode changes. These results highlight the importance of careful tool design and\nsuggest directions for improving AI-based code review systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e8616\u79cd\u6d41\u884c\u7684\u57fa\u4e8eAI\u7684\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u5728GitHub\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u8d85\u8fc722,000\u6761\u8bc4\u8bba\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5de5\u5177\u7684\u6709\u6548\u6027\u56e0\u8bbe\u8ba1\u800c\u5f02\uff0c\u7b80\u77ed\u3001\u542b\u4ee3\u7801\u7247\u6bb5\u4e14\u624b\u52a8\u89e6\u53d1\u7684\u8bc4\u8bba\u66f4\u5bb9\u6613\u5bfc\u81f4\u4ee3\u7801\u53d8\u66f4\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e86\u89e3\u57fa\u4e8eAI\u7684\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\u7684\u6548\u679c\u548c\u5f71\u54cd\u56e0\u7d20\uff0c\u586b\u8865\u5f53\u524d\u5bf9\u8be5\u9886\u57df\u4e86\u89e3\u4e0d\u8db3\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684LLM\u8f85\u52a9\u6846\u67b6\u6765\u5206\u6790\u8bc4\u8bba\u662f\u5426\u88ab\u91c7\u7eb3\uff0c\u5e76\u4f7f\u7528\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u8bc6\u522b\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5de5\u5177\u7684\u91c7\u7528\u7387\u5728\u589e\u957f\uff0c\u4f46\u6709\u6548\u6027\u5dee\u5f02\u8f83\u5927\uff1b\u7b80\u77ed\u3001\u542b\u4ee3\u7801\u7247\u6bb5\u4e14\u624b\u52a8\u89e6\u53d1\u7684\u8bc4\u8bba\u66f4\u5bb9\u6613\u5bfc\u81f4\u4ee3\u7801\u53d8\u66f4\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u5de5\u5177\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u57fa\u4e8eAI\u7684\u4ee3\u7801\u5ba1\u67e5\u7cfb\u7edf\u7684\u65b9\u5411\u3002"}}
{"id": "2508.19140", "pdf": "https://arxiv.org/pdf/2508.19140", "abs": "https://arxiv.org/abs/2508.19140", "authors": ["Florian Hahlbohm", "Linus Franke", "Leon Overk\u00e4mping", "Paula Wespe", "Susana Castillo", "Martin Eisemann", "Marcus Magnor"], "title": "A Bag of Tricks for Efficient Implicit Neural Point Clouds", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Project page: https://fhahlbohm.github.io/inpc_v2/", "summary": "Implicit Neural Point Cloud (INPC) is a recent hybrid representation that\ncombines the expressiveness of neural fields with the efficiency of point-based\nrendering, achieving state-of-the-art image quality in novel view synthesis.\nHowever, as with other high-quality approaches that query neural networks\nduring rendering, the practical usability of INPC is limited by comparatively\nslow rendering. In this work, we present a collection of optimizations that\nsignificantly improve both the training and inference performance of INPC\nwithout sacrificing visual fidelity. The most significant modifications are an\nimproved rasterizer implementation, more effective sampling techniques, and the\nincorporation of pre-training for the convolutional neural network used for\nhole-filling. Furthermore, we demonstrate that points can be modeled as small\nGaussians during inference to further improve quality in extrapolated, e.g.,\nclose-up views of the scene. We design our implementations to be broadly\napplicable beyond INPC and systematically evaluate each modification in a\nseries of experiments. Our optimized INPC pipeline achieves up to 25% faster\ntraining, 2x faster rendering, and 20% reduced VRAM usage paired with slight\nimage quality improvements.", "AI": {"tldr": "INPC\u662f\u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u573a\u548c\u70b9\u4e91\u6e32\u67d3\u7684\u9ad8\u6548\u8868\u793a\u65b9\u6cd5\uff0c\u4f46\u5728\u6e32\u67d3\u901f\u5ea6\u4e0a\u53d7\u9650\u3002\u672c\u7814\u7a76\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u89c6\u89c9\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1INPC\u5728\u56fe\u50cf\u8d28\u91cf\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u8f83\u6162\u7684\u6e32\u67d3\u901f\u5ea6\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u6539\u8fdb\u5149\u6805\u5316\u5b9e\u73b0\u3001\u9ad8\u6548\u91c7\u6837\u6280\u672f\u3001\u9884\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5c06\u70b9\u5efa\u6a21\u4e3a\u9ad8\u65af\u5206\u5e03\u3002", "result": "\u4f18\u5316\u540e\u7684INPC\u5b9e\u73b0\u4e86\u8bad\u7ec3\u901f\u5ea6\u63d0\u534725%\uff0c\u6e32\u67d3\u901f\u5ea6\u7ffb\u500d\uff0c\u663e\u5b58\u4f7f\u7528\u51cf\u5c1120%\uff0c\u4e14\u56fe\u50cf\u8d28\u91cf\u7565\u6709\u63d0\u5347\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86INPC\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5176\u9ad8\u8d28\u91cf\u6e32\u67d3\u80fd\u529b\u3002"}}
{"id": "2508.18545", "pdf": "https://arxiv.org/pdf/2508.18545", "abs": "https://arxiv.org/abs/2508.18545", "authors": ["Tasmia Shahriar", "Mia Ameen", "Aditi Mallavarapu", "Shiyan Jiang", "Noboru Matsuda"], "title": "Beyond prior knowledge: The predictive role of knowledge-building in Tutor Learning", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "When adopting the role of a teacher in learning-by-teaching environments,\nstudents often struggle to engage in knowledge-building activities, such as\nproviding explanations and addressing misconceptions. Instead, they frequently\ndefault to knowledge-telling behaviors, where they simply dictate what they\nalready know or what to do without deeper reflection, thereby limiting\nlearning. Teachable agents, particularly those capable of posing persistent\nfollow-up questions, have been shown to encourage students (tutors) to shift\nfrom knowledge-telling to knowledge-building and enhance tutor learning. Tutor\nlearning encompasses two interrelated types of knowledge: conceptual and\nprocedural knowledge. Research has established a bidirectional relationship\nbetween these knowledge types, where improvements in one reinforce the other.\nThis study investigates the role of knowledge-building in mediating the\nbidirectional relationship between procedural and conceptual learning. Our\nfindings revealed a stable bidirectional relationship between procedural and\nconceptual knowledge, with higher post-test scores observed among students who\nengaged in knowledge-building, regardless of their procedural and conceptual\npre-test performance. This suggests that knowledge-building serves as a crucial\nmechanism bridging the gap between students with low prior knowledge and higher\nconceptual and procedural learning gain.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5b66\u751f\u5728\u6559\u5b66\u4e2d\u901a\u8fc7\u77e5\u8bc6\u6784\u5efa\u6d3b\u52a8\uff08\u5982\u89e3\u91ca\u548c\u7ea0\u9519\uff09\u80fd\u66f4\u6709\u6548\u5730\u63d0\u5347\u6982\u5ff5\u6027\u548c\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff0c\u77e5\u8bc6\u6784\u5efa\u5728\u4e24\u8005\u4e4b\u95f4\u8d77\u5173\u952e\u4e2d\u4ecb\u4f5c\u7528\u3002", "motivation": "\u5b66\u751f\u5728\u6559\u5b66\u73af\u5883\u4e2d\u5f80\u5f80\u503e\u5411\u4e8e\u77e5\u8bc6\u8bb2\u8ff0\u800c\u975e\u77e5\u8bc6\u6784\u5efa\uff0c\u9650\u5236\u4e86\u5b66\u4e60\u6548\u679c\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u77e5\u8bc6\u6784\u5efa\u5982\u4f55\u4fc3\u8fdb\u6982\u5ff5\u6027\u4e0e\u7a0b\u5e8f\u6027\u77e5\u8bc6\u7684\u53cc\u5411\u63d0\u5347\u3002", "method": "\u901a\u8fc7\u53ef\u6559\u4ee3\u7406\uff08\u80fd\u63d0\u51fa\u6301\u7eed\u8ddf\u8fdb\u95ee\u9898\u7684\u865a\u62df\u5b66\u751f\uff09\u5f15\u5bfc\u5b66\u751f\u8fdb\u884c\u77e5\u8bc6\u6784\u5efa\u6d3b\u52a8\uff0c\u5206\u6790\u5176\u5bf9\u6982\u5ff5\u6027\u548c\u7a0b\u5e8f\u6027\u77e5\u8bc6\u7684\u5f71\u54cd\u3002", "result": "\u77e5\u8bc6\u6784\u5efa\u80fd\u7a33\u5b9a\u4e2d\u4ecb\u6982\u5ff5\u6027\u4e0e\u7a0b\u5e8f\u6027\u77e5\u8bc6\u7684\u53cc\u5411\u5173\u7cfb\uff0c\u4e14\u53c2\u4e0e\u77e5\u8bc6\u6784\u5efa\u7684\u5b66\u751f\u5728\u540e\u6d4b\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u77e5\u8bc6\u6784\u5efa\u662f\u8fde\u63a5\u4f4e\u5148\u9a8c\u77e5\u8bc6\u4e0e\u9ad8\u5b66\u4e60\u6536\u76ca\u7684\u5173\u952e\u673a\u5236\uff0c\u6559\u5b66\u8bbe\u8ba1\u4e2d\u5e94\u6ce8\u91cd\u6fc0\u53d1\u5b66\u751f\u7684\u77e5\u8bc6\u6784\u5efa\u884c\u4e3a\u3002"}}
{"id": "2508.18855", "pdf": "https://arxiv.org/pdf/2508.18855", "abs": "https://arxiv.org/abs/2508.18855", "authors": ["Lisa Maile", "Kai-Steffen Hielscher", "Reinhard German"], "title": "Network Calculus Results for TSN: An Introduction", "categories": ["cs.NI"], "comment": null, "summary": "Time-Sensitive Networking (TSN) is a set of standards that enables the\nindustry to provide real-time guarantees for time-critical communications with\nEthernet hardware. TSN supports various queuing and scheduling mechanisms and\nallows the integration of multiple traffic types in a single network. Network\nCalculus (NC) can be used to calculate upper bounds for latencies and buffer\nsizes within these networks, for example, for safety or real-time traffic. We\nexplain the relevance of NC for TSN-based computer communications and potential\nareas of application. Different NC analysis approaches have been published to\nexamine different parts of TSN and this paper provides a survey of these\npublications and presents their main results, dependencies, and differences. We\npresent a consistent presentation of the most important results and suggest an\nimprovement to model the output of sending end-devices. To ease access to the\ncurrent research status, we introduce a common notation to show how all results\ndepend on each other and also identify common assumptions. Thus, we offer a\ncomprehensive overview of NC for industrial networks and identify possible\nareas for future work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u65f6\u95f4\u654f\u611f\u7f51\u7edc\uff08TSN\uff09\u4e2d\u7f51\u7edc\u6f14\u7b97\uff08NC\uff09\u7684\u5e94\u7528\uff0c\u6574\u7406\u5e76\u7edf\u4e00\u4e86\u4e0d\u540c\u5206\u6790\u65b9\u6cd5\u7684\u4e3b\u8981\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u6a21\u578b\u4ee5\u63cf\u8ff0\u53d1\u9001\u7aef\u8bbe\u5907\u7684\u8f93\u51fa\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "TSN\u4e3a\u5de5\u4e1a\u7f51\u7edc\u63d0\u4f9b\u4e86\u5b9e\u65f6\u901a\u4fe1\u4fdd\u969c\uff0c\u800cNC\u53ef\u7528\u4e8e\u8ba1\u7b97\u7f51\u7edc\u4e2d\u7684\u5ef6\u8fdf\u548c\u7f13\u51b2\u533a\u4e0a\u9650\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684NC\u5206\u6790\u65b9\u6cd5\u5206\u6563\u4e14\u7f3a\u4e4f\u7edf\u4e00\u6027\uff0c\u56e0\u6b64\u8bba\u6587\u65e8\u5728\u6574\u5408\u8fd9\u4e9b\u65b9\u6cd5\u5e76\u63d0\u4f9b\u4e00\u81f4\u7684\u7814\u7a76\u6846\u67b6\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff0c\u6574\u7406\u5e76\u5bf9\u6bd4\u4e86\u4e0d\u540c\u7684NC\u5206\u6790\u65b9\u6cd5\u548c\u7ed3\u679c\uff0c\u5f15\u5165\u4e86\u4e00\u81f4\u7684\u7b26\u53f7\u7cfb\u7edf\u4ee5\u5c55\u793a\u7ed3\u679c\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u53d1\u9001\u7aef\u8bbe\u5907\u8f93\u51fa\u6a21\u578b\u3002", "result": "\u7814\u7a76\u7edf\u4e00\u4e86NC\u5728TSN\u4e2d\u7684\u5e94\u7528\uff0c\u660e\u786e\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u5f02\u540c\u548c\u5047\u8bbe\u6761\u4ef6\uff0c\u4e3a\u5de5\u4e1a\u7f51\u7edc\u7684\u5206\u6790\u63d0\u4f9b\u4e86\u5168\u9762\u53c2\u8003\uff0c\u5e76\u6307\u51fa\u4e86\u6a21\u578b\u6539\u8fdb\u7684\u6f5c\u529b\u3002", "conclusion": "\u8bba\u6587\u4e3aTSN\u4e2d\u7684NC\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u7efc\u8ff0\u548c\u7edf\u4e00\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u672a\u6765\u7814\u7a76\u7684\u53ef\u80fd\u65b9\u5411\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2508.18617", "pdf": "https://arxiv.org/pdf/2508.18617", "abs": "https://arxiv.org/abs/2508.18617", "authors": ["Ziqi Wang", "Jingzhe Zhang", "Wei Hu"], "title": "WoW: A Window-to-Window Incremental Index for Range-Filtering Approximate Nearest Neighbor Search", "categories": ["cs.DB"], "comment": "Accepted in the ACM SIGMOD/PODS International Conference on\n  Management of Data (SIGMOD 2026)", "summary": "Given a hybrid dataset where every data object consists of a vector and an\nattribute value, for each query with a target vector and a range filter,\nrange-filtering approximate nearest neighbor search (RFANNS) aims to retrieve\nthe most similar vectors from the dataset and the corresponding attribute\nvalues fall in the query range. It is a fundamental function in vector database\nmanagement systems and intelligent systems with embedding abilities. Dedicated\nindices for RFANNS accelerate query speed with an acceptable accuracy loss on\nnearest neighbors. However, they are still facing the challenges to be\nconstructed incrementally and generalized to achieve superior query performance\nfor arbitrary range filters. In this paper, we introduce a window graph-based\nRFANNS index. For incremental construction, we propose an insertion algorithm\nto add new vector-attribute pairs into hierarchical window graphs with varying\nwindow size. To handle arbitrary range filters, we optimize relevant window\nsearch for attribute filter checks and vector distance computations by range\nselectivity. Extensive experiments on real-world datasets show that for index\nconstruction, the indexing time is on par with the most building-efficient\nindex, and 4.9x faster than the most query-efficient index with 0.4-0.5x\nsmaller size; For RFANNS query, it is 4x faster than the most efficient\nincremental index, and matches the performance of the best statically-built\nindex.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a97\u53e3\u56fe\u7684RFANNS\u7d22\u5f15\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u589e\u91cf\u6784\u5efa\u548c\u4efb\u610f\u8303\u56f4\u8fc7\u6ee4\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6784\u5efa\u65f6\u95f4\u548c\u67e5\u8be2\u6548\u7387\u5747\u4f18\u4e8e\u73b0\u6709\u7d22\u5f15\u3002", "motivation": "RFANNS\u5728\u5411\u91cf\u6570\u636e\u5e93\u548c\u667a\u80fd\u7cfb\u7edf\u4e2d\u662f\u57fa\u7840\u529f\u80fd\uff0c\u4f46\u73b0\u6709\u7d22\u5f15\u96be\u4ee5\u589e\u91cf\u6784\u5efa\u4e14\u65e0\u6cd5\u5e94\u5bf9\u4efb\u610f\u8303\u56f4\u8fc7\u6ee4\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u7a97\u53e3\u56fe\u7d22\u5f15\uff0c\u589e\u91cf\u6784\u5efa\u7b97\u6cd5\u7528\u4e8e\u52a8\u6001\u6dfb\u52a0\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u8303\u56f4\u9009\u62e9\u6027\u4f18\u5316\u7a97\u53e3\u641c\u7d22\u4ee5\u5904\u7406\u4efb\u610f\u8303\u56f4\u8fc7\u6ee4\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6784\u5efa\u65f6\u95f4\u4e0e\u6700\u5feb\u901f\u7d22\u5f15\u76f8\u5f53\uff0c\u67e5\u8be2\u6548\u7387\u6bd4\u6700\u4f18\u52a8\u6001\u7d22\u5f15\u5feb4\u500d\uff0c\u4e14\u63a5\u8fd1\u9759\u6001\u7d22\u5f15\u6027\u80fd\u3002", "conclusion": "\u7a97\u53e3\u56fe\u7d22\u5f15\u5728\u6784\u5efa\u548c\u67e5\u8be2\u6548\u7387\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u589e\u91cf\u6570\u636e\u548c\u9ad8\u6027\u80fd\u9700\u6c42\u3002"}}
{"id": "2508.18850", "pdf": "https://arxiv.org/pdf/2508.18850", "abs": "https://arxiv.org/abs/2508.18850", "authors": ["Xinhao Luo", "Zihan Liu", "Yangjie Zhou", "Shihan Fang", "Ziyu Huang", "Yu Feng", "Chen Zhang", "Shixuan Sun", "Zhenzhe Zheng", "Jingwen Leng", "Minyi Guo"], "title": "ClusterFusion: Expanding Operator Fusion Scope for LLM Inference via Cluster-Level Collective Primitive", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Large language model (LLM) decoding suffers from high latency due to\nfragmented execution across operators and heavy reliance on off-chip memory for\ndata exchange and reduction. This execution model limits opportunities for\nfusion and incurs significant memory traffic and kernel launch overhead. While\nmodern architectures such as NVIDIA Hopper provide distributed shared memory\nand low-latency intra-cluster interconnects, they expose only low-level data\nmovement instructions, lacking structured abstractions for collective on-chip\ncommunication. To bridge this software-hardware gap, we introduce two\ncluster-level communication primitives, ClusterReduce and ClusterGather, which\nabstract common communication patterns and enable structured, high-speed data\nexchange and reduction between thread blocks within a cluster, allowing\nintermediate results to be on-chip without involving off-chip memory. Building\non these abstractions, we design ClusterFusion, an execution framework that\nschedules communication and computation jointly to expand operator fusion scope\nby composing decoding stages such as QKV Projection, Attention, and Output\nProjection into a single fused kernels. Evaluations on H100 GPUs show that\nClusterFusion outperforms state-of-the-art inference frameworks by 1.61x on\naverage in end-to-end latency across different models and configurations. The\nsource code is available at https://github.com/xinhao-luo/ClusterFusion.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aClusterFusion\u7684\u6267\u884c\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u7fa4\u7ea7\u901a\u4fe1\u539f\u8bed\uff08ClusterReduce\u548cClusterGather\uff09\u4f18\u5316LLM\u89e3\u7801\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u4e861.61\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7531\u4e8e\u64cd\u4f5c\u788e\u7247\u5316\u548c\u5bf9\u7247\u5916\u5185\u5b58\u4f9d\u8d56\u5bfc\u81f4\u7684\u9ad8\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86ClusterReduce\u548cClusterGather\u4e24\u4e2a\u96c6\u7fa4\u7ea7\u901a\u4fe1\u539f\u8bed\uff0c\u8bbe\u8ba1ClusterFusion\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8c03\u5ea6\u901a\u4fe1\u548c\u8ba1\u7b97\uff0c\u6269\u5c55\u7b97\u5b50\u878d\u5408\u8303\u56f4\u3002", "result": "\u5728H100 GPU\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cClusterFusion\u5e73\u5747\u7aef\u5230\u7aef\u5ef6\u8fdf\u6bd4\u73b0\u6709\u6846\u67b6\u63d0\u53471.61\u500d\u3002", "conclusion": "ClusterFusion\u901a\u8fc7\u9ad8\u6548\u7684\u6570\u636e\u4ea4\u6362\u548c\u7b97\u5b50\u878d\u5408\uff0c\u663e\u8457\u964d\u4f4e\u4e86LLM\u89e3\u7801\u7684\u5ef6\u8fdf\u3002"}}
{"id": "2508.18816", "pdf": "https://arxiv.org/pdf/2508.18816", "abs": "https://arxiv.org/abs/2508.18816", "authors": ["Sabato Nocera", "Davide Fucci", "Giuseppe Scanniello"], "title": "Dealing with SonarQube Cloud: Initial Results from a Mining Software Repository Study", "categories": ["cs.SE"], "comment": "Accepted for ESEM25 NIER track", "summary": "Background: Static Code Analysis (SCA) tools are widely adopted to enforce\ncode quality standards. However, little is known about how open-source projects\nuse and customize these tools. Aims: This paper investigates how GitHub\nprojects use and customize a popular SCA tool, namely SonarQube Cloud. Method:\nWe conducted a mining study of GitHub projects that are linked through GitHub\nActions to SonarQube Cloud projects. Results: Among 321 GitHub projects using\nSonarQube Cloud, 81% of them are correctly connected to SonarQube Cloud\nprojects, while others exhibit misconfigurations or restricted access. Among\n265 accessible SonarQube Cloud projects, 75% use the organization's default\nquality gate, i.e., a set of conditions that deployed source code must meet to\npass automated checks. While 55% of the projects use the built-in quality gate\nprovided by SonarQube Cloud, 45% of them customize their quality gate with\ndifferent conditions. Overall, the most common quality conditions align with\nSonarQube Cloud's \"Clean as You Code\" principle and enforce security,\nmaintainability, reliability, coverage, and a few duplicates on newly added or\nmodified source code. Conclusions: Many projects rely on predefined\nconfigurations, yet a significant portion customize their configurations to\nmeet specific quality goals. Building on our initial results, we envision a\nfuture research agenda linking quality gate configurations to actual software\noutcomes (e.g., improvement of software security). This would enable\nevidence-based recommendations for configuring SCA tools like SonarQube Cloud\nin various contexts.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86GitHub\u9879\u76ee\u5982\u4f55\u4f7f\u7528\u548c\u5b9a\u5236SonarQube Cloud\u8fd9\u4e00\u9759\u6001\u4ee3\u7801\u5206\u6790\u5de5\u5177\uff0c\u53d1\u73b0\u591a\u6570\u9879\u76ee\u4f7f\u7528\u9ed8\u8ba4\u914d\u7f6e\uff0c\u4f46\u4e5f\u6709\u663e\u8457\u90e8\u5206\u8fdb\u884c\u81ea\u5b9a\u4e49\u4ee5\u8fbe\u6210\u7279\u5b9a\u8d28\u91cf\u76ee\u6807\u3002", "motivation": "\u7814\u7a76\u5f00\u6e90\u9879\u76ee\u5982\u4f55\u4f7f\u7528\u548c\u5b9a\u5236SCA\u5de5\u5177\uff0c\u4ee5\u4e86\u89e3\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u548c\u914d\u7f6e\u6548\u679c\u3002", "method": "\u901a\u8fc7\u6316\u6398GitHub\u9879\u76ee\u4e0eSonarQube Cloud\u7684\u94fe\u63a5\u6570\u636e\uff0c\u5206\u6790\u914d\u7f6e\u548c\u4f7f\u7528\u60c5\u51b5\u3002", "result": "81%\u7684\u9879\u76ee\u6b63\u786e\u8fde\u63a5\u5230SonarQube Cloud\uff0c75%\u4f7f\u7528\u9ed8\u8ba4\u8d28\u91cf\u95e8\uff0c45%\u81ea\u5b9a\u4e49\u8d28\u91cf\u95e8\u3002\u5e38\u89c1\u6761\u4ef6\u7b26\u5408\u201cClean as You Code\u201d\u539f\u5219\u3002", "conclusion": "\u9879\u76ee\u591a\u4f9d\u8d56\u9884\u5b9a\u4e49\u914d\u7f6e\uff0c\u4f46\u81ea\u5b9a\u4e49\u914d\u7f6e\u4e5f\u5f88\u666e\u904d\u3002\u672a\u6765\u7814\u7a76\u53ef\u63a2\u7d22\u914d\u7f6e\u4e0e\u5b9e\u9645\u8f6f\u4ef6\u6548\u679c\u7684\u5173\u7cfb\uff0c\u4ee5\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684SCA\u5de5\u5177\u914d\u7f6e\u5efa\u8bae\u3002"}}
{"id": "2508.18580", "pdf": "https://arxiv.org/pdf/2508.18580", "abs": "https://arxiv.org/abs/2508.18580", "authors": ["Haitham Abdelsalam", "Chanelle Montpetit", "Arash Harirpoush", "Maryse Fortin", "Yiming Xiao"], "title": "Gamification of Immersive Cervical Rehabilitation Exercises in VR: An Exploratory Study on Chin Tuck and Range of Motion Exercises", "categories": ["cs.HC"], "comment": "8 pages, 7 figures, Accepted in the IEEE ISMAR 2025 XRehab Workshop", "summary": "Chronic neck pain is a prevalent condition that affects millions of\nindividuals worldwide, causing significant individual suffering and\nsocioeconomic burdens. Although exercise rehabilitation is a staple in\nrelieving pain and improving muscle function for the condition, traditional\none-on-one rehabilitation sessions are costly and suffer from poor adherence\nand accessibility for the patients. Thanks to the increasing accessibility and\nrecent advancements in sensing and display technology, virtual reality (VR)\noffers the potential to tackle the challenges in traditional exercise\nrehabilitation, particularly through gamification. However, still in its\ninfancy, VR-based neck exercise rehabilitation lacks exploration in effective\ngamification strategies and existing prototypes. To address the knowledge gap,\nwe conduct an exploratory study on the gamification strategies for VR-based\ncervical rehabilitation exercises by using chin tuck and neck range of motion\nexercises as examples. Specifically, with different game themes, we investigate\na survival and level progression strategy for muscle strengthening (chin tuck)\nexercise for the first time, and the suitability of ambient reward for a neck\nrange of motion exercise. Through a preliminary user study, we assess the\nproposed novel VR neck rehabilitation games and they demonstrate excellent\nusability, engagement, and perceived health value.", "AI": {"tldr": "VR\u7ed3\u5408\u6e38\u620f\u5316\u7b56\u7565\u7528\u4e8e\u6162\u6027\u9888\u90e8\u75bc\u75db\u5eb7\u590d\u7684\u7814\u7a76\uff0c\u63a2\u7d22\u4e86\u65b0\u9896\u7684\u5eb7\u590d\u6e38\u620f\uff0c\u521d\u6b65\u7814\u7a76\u8868\u660e\u5176\u5177\u6709\u826f\u597d\u7684\u53ef\u7528\u6027\u3001\u53c2\u4e0e\u611f\u548c\u5065\u5eb7\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u7684\u4e00\u5bf9\u4e00\u5eb7\u590d\u6cbb\u7597\u6210\u672c\u9ad8\u3001\u4f9d\u4ece\u6027\u5dee\u4e14\u53ef\u53ca\u6027\u4e0d\u8db3\uff0cVR\u6280\u672f\u7ed3\u5408\u6e38\u620f\u5316\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u8bbe\u8ba1\u4e24\u79cdVR\u6e38\u620f\uff08\u751f\u5b58\u4e0e\u7b49\u7ea7\u8fdb\u6b65\u7b56\u7565\u7528\u4e8e\u808c\u8089\u5f3a\u5316\u7ec3\u4e60\uff0c\u73af\u5883\u5956\u52b1\u7528\u4e8e\u9888\u90e8\u6d3b\u52a8\u8303\u56f4\u7ec3\u4e60\uff09\uff0c\u5e76\u8fdb\u884c\u4e86\u521d\u6b65\u7528\u6237\u7814\u7a76\u3002", "result": "\u521d\u6b65\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u63d0\u51fa\u7684VR\u9888\u90e8\u5eb7\u590d\u6e38\u620f\u5728\u53ef\u7528\u6027\u3001\u53c2\u4e0e\u611f\u548c\u5065\u5eb7\u4ef7\u503c\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "VR\u6e38\u620f\u5316\u7b56\u7565\u4e3a\u6162\u6027\u9888\u90e8\u75bc\u75db\u5eb7\u590d\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u4f46\u5176\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5b8c\u5584\u3002"}}
{"id": "2508.18863", "pdf": "https://arxiv.org/pdf/2508.18863", "abs": "https://arxiv.org/abs/2508.18863", "authors": ["Pietro Talli", "Anup Mishra", "Federico Chiariotti", "Israel Leyva-Mayorga", "Andrea Zanella", "Petar Popovski"], "title": "Saving Energy with Relaxed Latency Constraints: A Study on Data Compression and Communication", "categories": ["cs.NI"], "comment": null, "summary": "With the advent of edge computing, data generated by end devices can be\npre-processed before transmission, possibly saving transmission time and\nenergy. On the other hand, data processing itself incurs latency and energy\nconsumption, depending on the complexity of the computing operations and the\nspeed of the processor. The energy-latency-reliability profile resulting from\nthe concatenation of pre-processing operations (specifically, data compression)\nand data transmission is particularly relevant in wireless communication\nservices, whose requirements may change dramatically with the application\ndomain. In this paper, we study this multi-dimensional optimization problem,\nintroducing a simple model to investigate the tradeoff among end-to-end\nlatency, reliability, and energy consumption when considering compression and\ncommunication operations in a constrained wireless device. We then study the\nPareto fronts of the energy-latency trade-off, considering data compression\nratio and device processing speed as key design variables. Our results show\nthat the energy costs grows exponentially with the reduction of the end-to-end\nlatency, so that considerable energy saving can be obtained by slightly\nrelaxing the latency requirements of applications. These findings challenge\nconventional rigid communication latency targets, advocating instead for\napplication-specific end-to-end latency budgets that account for computational\nand transmission overhead.", "AI": {"tldr": "\u7814\u7a76\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u9884\u5904\u7406\uff08\u5982\u6570\u636e\u538b\u7f29\uff09\u548c\u4f20\u8f93\u4e4b\u95f4\u7684\u591a\u7ef4\u4f18\u5316\u95ee\u9898\uff0c\u5206\u6790\u80fd\u91cf\u3001\u5ef6\u8fdf\u548c\u53ef\u9760\u6027\u7684\u6743\u8861\u3002", "motivation": "\u968f\u7740\u8fb9\u7f18\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u9884\u5904\u7406\u7684\u80fd\u91cf\u548c\u5ef6\u8fdf\u4e0e\u4f20\u8f93\u7684\u9700\u6c42\u4e4b\u95f4\u7684\u5e73\u8861\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7b80\u5355\u6a21\u578b\uff0c\u8003\u5bdf\u538b\u7f29\u548c\u901a\u4fe1\u64cd\u4f5c\u7684\u6743\u8861\uff0c\u7814\u7a76Pareto\u524d\u6cbf\u3002", "result": "\u7ed3\u679c\u663e\u793a\u80fd\u91cf\u6210\u672c\u968f\u5ef6\u8fdf\u51cf\u5c11\u5448\u6307\u6570\u589e\u957f\uff0c\u653e\u677e\u5ef6\u8fdf\u8981\u6c42\u53ef\u663e\u8457\u8282\u80fd\u3002", "conclusion": "\u6311\u6218\u4f20\u7edf\u7684\u56fa\u5b9a\u5ef6\u8fdf\u76ee\u6807\uff0c\u5efa\u8bae\u91c7\u7528\u57fa\u4e8e\u5e94\u7528\u7684\u5177\u4f53\u5ef6\u8fdf\u9884\u7b97\u3002"}}
{"id": "2508.18736", "pdf": "https://arxiv.org/pdf/2508.18736", "abs": "https://arxiv.org/abs/2508.18736", "authors": ["Jungwoo Kim", "Minsang Kim", "Jaeheon Lee", "Chanwoo Moon", "Heejin Kim", "Taeho Hwang", "Woosuk Chung", "Yeseong Kim", "Sungjin Lee"], "title": "Rethinking Caching for LLM Serving Systems: Beyond Traditional Heuristics", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Serving Large Language Models (LLMs) at scale requires meeting strict Service\nLevel Objectives (SLOs) under severe computational and memory constraints.\nNevertheless, traditional caching strategies fall short: exact-matching and\nprefix caches neglect query semantics, while state-of-the-art semantic caches\nremain confined to traditional intuitions, offering little conceptual\ndeparture. Building on this, we present SISO, a semantic caching system that\nredefines efficiency for LLM serving. SISO introduces centroid-based caching to\nmaximize coverage with minimal memory, locality-aware replacement to preserve\nhigh-value entries, and dynamic thresholding to balance accuracy and latency\nunder varying workloads. Across diverse datasets, SISO delivers up to\n1.71$\\times$ higher hit ratios and consistently stronger SLO attainment\ncompared to state-of-the-art systems.", "AI": {"tldr": "SISO\u662f\u4e00\u79cd\u4e13\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u670d\u52a1\u8bbe\u8ba1\u7684\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7f13\u5b58\u7b56\u7565\u65e0\u6cd5\u6ee1\u8db3LLM\u670d\u52a1\u7684\u9ad8\u6548\u9700\u6c42\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u5e94\u5bf9\u8ba1\u7b97\u548c\u5185\u5b58\u9650\u5236\u3002", "method": "SISO\u91c7\u7528\u57fa\u4e8e\u805a\u7c7b\u7684\u7f13\u5b58\uff08centroid-based caching\uff09\u3001\u5c40\u90e8\u611f\u77e5\u66ff\u6362\uff08locality-aware replacement\uff09\u548c\u52a8\u6001\u9608\u503c\uff08dynamic thresholding\uff09\u6765\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e2d\uff0cSISO\u7684\u547d\u4e2d\u7387\u63d0\u5347\u4e861.71\u500d\uff0c\u670d\u52a1\u7b49\u7ea7\u76ee\u6807\uff08SLO\uff09\u8fbe\u6210\u7387\u66f4\u9ad8\u3002", "conclusion": "SISO\u901a\u8fc7\u521b\u65b0\u7684\u8bed\u4e49\u7f13\u5b58\u7b56\u7565\uff0c\u4e3aLLM\u670d\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18950", "pdf": "https://arxiv.org/pdf/2508.18950", "abs": "https://arxiv.org/abs/2508.18950", "authors": ["Thomas Jakobsche", "Fredrik Roberts\u00e9n", "Jessica R. Jones", "Utz-Uwe Haus", "Florina M. Ciorba"], "title": "SIREN: Software Identification and Recognition in HPC Systems", "categories": ["cs.DC"], "comment": null, "summary": "HPC systems use monitoring and operational data analytics to ensure\nefficiency, performance, and orderly operations. Application-specific insights\nare crucial for analyzing the increasing complexity and diversity of HPC\nworkloads, particularly through the identification of unknown software and\nrecognition of repeated executions, which facilitate system optimization and\nsecurity improvements. However, traditional identification methods using job or\nfile names are unreliable for arbitrary user-provided names (a.out). Fuzzy\nhashing of executables detects similarities despite changes in executable\nversion or compilation approach while preserving privacy and file integrity,\novercoming these limitations. We introduce SIREN, a process-level data\ncollection framework for software identification and recognition. SIREN\nimproves observability in HPC by enabling analysis of process metadata,\nenvironment information, and executable fuzzy hashes. Findings from a first\nopt-in deployment campaign on LUMI show SIREN's ability to provide insights\ninto software usage, recognition of repeated executions of known applications,\nand similarity-based identification of unknown applications.", "AI": {"tldr": "SIREN\u662f\u4e00\u4e2a\u7528\u4e8eHPC\u7cfb\u7edf\u8f6f\u4ef6\u8bc6\u522b\u548c\u91cd\u590d\u6267\u884c\u8bc6\u522b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u7cca\u54c8\u5e0c\u7b49\u6280\u672f\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "HPC\u7cfb\u7edf\u9700\u8981\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u8f6f\u4ef6\u548c\u91cd\u590d\u6267\u884c\uff0c\u4f20\u7edf\u65b9\u6cd5\u56e0\u4f9d\u8d56\u6587\u4ef6\u540d\u800c\u4e0d\u53ef\u9760\u3002", "method": "\u91c7\u7528\u6a21\u7cca\u54c8\u5e0c\u6280\u672f\u5206\u6790\u8fdb\u7a0b\u5143\u6570\u636e\u3001\u73af\u5883\u4fe1\u606f\u548c\u53ef\u6267\u884c\u6587\u4ef6\u54c8\u5e0c\uff0c\u5f00\u53d1SIREN\u6846\u67b6\u3002", "result": "\u5728LUMI\u4e0a\u7684\u521d\u6b65\u90e8\u7f72\u8868\u660e\uff0cSIREN\u80fd\u6709\u6548\u8bc6\u522b\u8f6f\u4ef6\u4f7f\u7528\u60c5\u51b5\u548c\u672a\u77e5\u5e94\u7528\u7684\u76f8\u4f3c\u6027\u3002", "conclusion": "SIREN\u63d0\u9ad8\u4e86HPC\u7cfb\u7edf\u7684\u53ef\u89c2\u6d4b\u6027\uff0c\u4e3a\u7cfb\u7edf\u4f18\u5316\u548c\u5b89\u5168\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.18955", "pdf": "https://arxiv.org/pdf/2508.18955", "abs": "https://arxiv.org/abs/2508.18955", "authors": ["Yunbo Ni", "Shaohua Li"], "title": "Interleaving Large Language Models for Compiler Testing", "categories": ["cs.SE"], "comment": null, "summary": "Testing compilers with AI models, especially large language models (LLMs),\nhas shown great promise. However, current approaches struggle with two key\nproblems: The generated programs for testing compilers are often too simple,\nand extensive testing with the LLMs is computationally expensive. In this\npaper, we propose a novel compiler testing framework that decouples the testing\nprocess into two distinct phases: an offline phase and an online phase. In the\noffline phase, we use LLMs to generate a collection of small but feature-rich\ncode pieces. In the online phase, we reuse these code pieces by strategically\ncombining them to build high-quality and valid test programs, which are then\nused to test compilers.\n  We implement this idea in a tool, LegoFuzz, for testing C compilers. The\nresults are striking: we found 66 bugs in GCC and LLVM, the most widely used C\ncompilers. Almost half of the bugs are miscompilation bugs, which are serious\nand hard-to-find bugs that none of the existing LLM-based tools could find. We\nbelieve this efficient design opens up new possibilities for using AI models in\nsoftware testing beyond just C compilers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f16\u8bd1\u5668\u6d4b\u8bd5\u6846\u67b6LegoFuzz\uff0c\u901a\u8fc7\u79bb\u7ebf\u751f\u6210\u548c\u5728\u7ebf\u7ec4\u5408\u4ee3\u7801\u7247\u6bb5\u6765\u9ad8\u6548\u6d4b\u8bd5C\u7f16\u8bd1\u5668\uff0c\u53d1\u73b0\u4e86GCC\u548cLLVM\u4e2d\u768466\u4e2a\u4e25\u91cd\u9519\u8bef\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709AI\u6a21\u578b\u6d4b\u8bd5\u7f16\u8bd1\u5668\u65b9\u6cd5\u4e2d\u5b58\u5728\u751f\u6210\u7684\u7a0b\u5e8f\u8fc7\u4e8e\u7b80\u5355\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u5206\u79bb\u7ebf\u9636\u6bb5\uff08\u7528LLM\u751f\u6210\u5c0f\u800c\u529f\u80fd\u4e30\u5bcc\u7684\u4ee3\u7801\u7247\u6bb5\uff09\u548c\u5728\u7ebf\u9636\u6bb5\uff08\u7ec4\u5408\u8fd9\u4e9b\u7247\u6bb5\u6784\u5efa\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7a0b\u5e8f\uff09\u7684\u4e24\u9636\u6bb5\u6d4b\u8bd5\u6846\u67b6\u3002", "result": "\u5728GCC\u548cLLVM\u4e2d\u53d1\u73b0\u4e8666\u4e2a\u9519\u8bef\uff0c\u8fd1\u534a\u6570\u662f\u73b0\u6709LLM\u5de5\u5177\u65e0\u6cd5\u53d1\u73b0\u7684\u4e25\u91cd\u9519\u8bef\uff08miscompilation bugs\uff09\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u9ad8\u6548\uff0c\u4e3aAI\u6a21\u578b\u5728\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4e0d\u4ec5\u9650\u4e8eC\u7f16\u8bd1\u5668\u3002"}}
{"id": "2508.19204", "pdf": "https://arxiv.org/pdf/2508.19204", "abs": "https://arxiv.org/abs/2508.19204", "authors": ["Julian Ost", "Andrea Ramazzina", "Amogh Joshi", "Maximilian B\u00f6mer", "Mario Bijelic", "Felix Heide"], "title": "LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "Project webpage: https://light.princeton.edu/LSD-3D", "summary": "Large-scale scene data is essential for training and testing in robot\nlearning. Neural reconstruction methods have promised the capability of\nreconstructing large physically-grounded outdoor scenes from captured sensor\ndata. However, these methods have baked-in static environments and only allow\nfor limited scene control -- they are functionally constrained in scene and\ntrajectory diversity by the captures from which they are reconstructed. In\ncontrast, generating driving data with recent image or video diffusion models\noffers control, however, at the cost of geometry grounding and causality. In\nthis work, we aim to bridge this gap and present a method that directly\ngenerates large-scale 3D driving scenes with accurate geometry, allowing for\ncausal novel view synthesis with object permanence and explicit 3D geometry\nestimation. The proposed method combines the generation of a proxy geometry and\nenvironment representation with score distillation from learned 2D image\npriors. We find that this approach allows for high controllability, enabling\nthe prompt-guided geometry and high-fidelity texture and structure that can be\nconditioned on map layouts -- producing realistic and geometrically consistent\n3D generations of complex driving scenes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ee3\u7406\u51e0\u4f55\u751f\u6210\u548c2D\u56fe\u50cf\u5148\u9a8c\u7684\u65b9\u6cd5\uff0c\u76f4\u63a5\u751f\u6210\u5177\u6709\u7cbe\u786e\u51e0\u4f55\u7684\u5927\u89c4\u6a213D\u9a7e\u9a76\u573a\u666f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u4e2d\u9759\u6001\u73af\u5883\u9650\u5236\u6216\u7f3a\u4e4f\u51e0\u4f55\u57fa\u7840\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u573a\u666f\u6570\u636e\u5bf9\u673a\u5668\u4eba\u5b66\u4e60\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u795e\u7ecf\u91cd\u5efa\u65b9\u6cd5\u53d7\u9650\u4e8e\u9759\u6001\u73af\u5883\u4e14\u53ef\u63a7\u6027\u4f4e\uff0c\u800c\u56fe\u50cf\u6216\u89c6\u9891\u6269\u6563\u6a21\u578b\u7f3a\u4e4f\u51e0\u4f55\u57fa\u7840\u548c\u56e0\u679c\u5173\u7cfb\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7ed3\u5408\u4ee3\u7406\u51e0\u4f55\u751f\u6210\u4e0e\u73af\u5883\u8868\u793a\uff0c\u5229\u7528\u5b66\u4e60\u5230\u76842D\u56fe\u50cf\u5148\u9a8c\u8fdb\u884c\u5206\u6570\u63d0\u53d6\uff0c\u5b9e\u73b0\u9ad8\u53ef\u63a7\u6027\u7684\u5927\u89c4\u6a213D\u573a\u666f\u751f\u6210\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u51e0\u4f55\u7cbe\u786e\u3001\u53ef\u63a7\u6027\u5f3a\u7684\u5927\u89c4\u6a213D\u9a7e\u9a76\u573a\u666f\uff0c\u652f\u6301\u56e0\u679c\u65b0\u89c6\u89d2\u5408\u6210\u548c3D\u51e0\u4f55\u4f30\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u53ef\u63a7\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u80fd\u591f\u751f\u6210\u903c\u771f\u4e14\u51e0\u4f55\u4e00\u81f4\u7684\u590d\u6742\u9a7e\u9a76\u573a\u666f\u3002"}}
{"id": "2508.18591", "pdf": "https://arxiv.org/pdf/2508.18591", "abs": "https://arxiv.org/abs/2508.18591", "authors": ["Kinga Skiers", "Yun Suen Pai", "Marina Nakagawa", "Kouta Minamizawa", "Giulia Barbareschi"], "title": "Portable Silent Room: Exploring VR Design for Anxiety and Emotion Regulation for Neurodivergent Women and Non-Binary Individuals", "categories": ["cs.HC"], "comment": null, "summary": "Neurodivergent individuals, particularly those with Autism and Attention\nDeficit Hyperactivity Disorder (ADHD), frequently experience anxiety, panic\nattacks, meltdowns, and emotional dysregulation due to societal pressures and\ninadequate accommodations. These challenges are especially pronounced for\nneurodivergent women and non-binary individuals navigating intersecting\nbarriers of neurological differences and gender expectations. This research\ninvestigates virtual reality (VR) as a portable safe space for emotional\nregulation, addressing challenges of sensory overload and motion sickness while\nenhancing relaxation capabilities. Our mixed-methods approach included an\nonline survey (N=223) and an ideation workshop (N=32), which provided key\ndesign elements for creating effective calming VR environments. Based on these\nfindings, we developed and iteratively tested VR prototypes with neurodivergent\nwomen and non-binary participants (N=12), leading to a final version offering\nenhanced adaptability to individual sensory needs. This final prototype\nunderwent a comprehensive evaluation with 25 neurodivergent participants to\nassess its effectiveness as a regulatory tool. This research contributes to the\ndevelopment of inclusive, adaptive VR environments that function as\npersonalized \"portable silent rooms\" offering neurodivergent individuals\non-demand access to sensory regulation regardless of physical location.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u4f5c\u4e3a\u795e\u7ecf\u591a\u6837\u6027\u4e2a\u4f53\u7684\u4fbf\u643a\u5f0f\u5b89\u5168\u7a7a\u95f4\uff0c\u5e2e\u52a9\u60c5\u7eea\u8c03\u8282\uff0c\u5c24\u5176\u9488\u5bf9\u81ea\u95ed\u75c7\u548cADHD\u5973\u6027\u53ca\u975e\u4e8c\u5143\u6027\u522b\u8005\u3002", "motivation": "\u795e\u7ecf\u591a\u6837\u6027\u4e2a\u4f53\u5e38\u56e0\u793e\u4f1a\u538b\u529b\u548c\u7f3a\u4e4f\u9002\u5f53\u652f\u6301\u800c\u7ecf\u5386\u7126\u8651\u548c\u60c5\u7eea\u5931\u8c03\uff0c\u5973\u6027\u53ca\u975e\u4e8c\u5143\u6027\u522b\u8005\u9762\u4e34\u66f4\u591a\u969c\u788d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u5728\u7ebf\u8c03\u67e5\uff08N=223\uff09\u548c\u8bbe\u8ba1\u7814\u8ba8\u4f1a\uff08N=32\uff09\uff0c\u5f00\u53d1\u5e76\u6d4b\u8bd5VR\u539f\u578b\uff08N=12\uff09\uff0c\u6700\u7ec8\u8bc4\u4f30\uff08N=25\uff09\u3002", "result": "\u5f00\u53d1\u7684VR\u539f\u578b\u9002\u5e94\u4e2a\u4f53\u611f\u5b98\u9700\u6c42\uff0c\u53ef\u4f5c\u4e3a\u4e2a\u6027\u5316\u4fbf\u643a\u5f0f\u5b89\u9759\u7a7a\u95f4\uff0c\u63d0\u4f9b\u968f\u65f6\u968f\u5730\u611f\u5b98\u8c03\u8282\u3002", "conclusion": "VR\u73af\u5883\u4e3a\u795e\u7ecf\u591a\u6837\u6027\u4e2a\u4f53\u63d0\u4f9b\u5305\u5bb9\u6027\u548c\u9002\u5e94\u6027\u652f\u6301\uff0c\u63d0\u5347\u60c5\u7eea\u8c03\u8282\u80fd\u529b\u3002"}}
{"id": "2508.18883", "pdf": "https://arxiv.org/pdf/2508.18883", "abs": "https://arxiv.org/abs/2508.18883", "authors": ["Lisa Maile", "Kai-Steffen Hielscher", "Reinhard German"], "title": "Combining Static and Dynamic Traffic with Delay Guarantees in Time-Sensitive Networking", "categories": ["cs.NI"], "comment": "Code published as DYRECTsn (https://github.com/Kathess/DYRECTsn): an\n  open-source TSN framework for dynamic traffic with latency guarantees. It\n  applies Network Calculus to compute worst case delays and supports online\n  admission control, ensuring predictable real-time performance. Optimizes\n  delay budgets in the network", "summary": "To support reliable and low-latency communication, Time-Sensitive Networking\nintroduced protocols and interfaces for resource allocation in Ethernet.\nHowever, the implementation of these allocation algorithms has not yet been\ncovered by the standards. Our work focuses on deadline-guaranteeing resource\nallocation for networks with static and dynamic traffic. To achieve this, we\ncombine offline network optimization heuristics with online admission control\nand, thus, allow for new flow registrations while the network is running. We\ndemonstrate our solution on Credit-Based Shaper networks by using the delay\nanalysis framework Network Calculus. We compare our approach with an intuitive\nand a brute-force algorithm, where we can achieve significant improvements,\nboth, in terms of quality and runtime. Thereby, our results show that we can\nguarantee maximum end-to-end delays and also increase the flexibility of the\nnetwork while requiring only minimal user input.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65f6\u95f4\u654f\u611f\u7f51\u7edc\u4e2d\u652f\u6301\u9759\u6001\u548c\u52a8\u6001\u6d41\u91cf\u7684\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\uff0c\u7ed3\u5408\u79bb\u7ebf\u548c\u5728\u7ebf\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u7f51\u7edc\u5ef6\u8fdf\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u654f\u611f\u7f51\u7edc\u4e2d\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\u7684\u6807\u51c6\u5316\u7a7a\u767d\uff0c\u786e\u4fdd\u4f4e\u5ef6\u8fdf\u548c\u53ef\u9760\u6027\u3002", "method": "\u7ed3\u5408\u79bb\u7ebf\u7f51\u7edc\u4f18\u5316\u542f\u53d1\u5f0f\u548c\u5728\u7ebf\u51c6\u5165\u63a7\u5236\uff0c\u4f7f\u7528Network Calculus\u6846\u67b6\u9a8c\u8bc1Credit-Based Shaper\u7f51\u7edc\u3002", "result": "\u4e0e\u76f4\u89c9\u548c\u66b4\u529b\u7b97\u6cd5\u76f8\u6bd4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8d28\u91cf\u548c\u8fd0\u884c\u65f6\u6027\u80fd\uff0c\u4fdd\u8bc1\u6700\u5927\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "conclusion": "\u8be5\u65b9\u6848\u901a\u8fc7\u6700\u5c0f\u7528\u6237\u8f93\u5165\uff0c\u63d0\u5347\u4e86\u7f51\u7edc\u7075\u6d3b\u6027\u5e76\u786e\u4fdd\u5ef6\u8fdf\u4fdd\u969c\u3002"}}
{"id": "2508.18758", "pdf": "https://arxiv.org/pdf/2508.18758", "abs": "https://arxiv.org/abs/2508.18758", "authors": ["Yipeng Zhang", "Chen Wang", "Yuzhe Zhang", "Jacky Jiang"], "title": "Text to Query Plans for Question Answering on Large Tables", "categories": ["cs.DB", "cs.AI", "cs.CL"], "comment": null, "summary": "Efficient querying and analysis of large tabular datasets remain significant\nchallenges, especially for users without expertise in programming languages\nlike SQL. Text-to-SQL approaches have shown promising performance on benchmark\ndata; however, they inherit SQL's drawbacks, including inefficiency with large\ndatasets and limited support for complex data analyses beyond basic querying.\nWe propose a novel framework that transforms natural language queries into\nquery plans. Our solution is implemented outside traditional databases,\nallowing us to support classical SQL commands while avoiding SQL's inherent\nlimitations. Additionally, we enable complex analytical functions, such as\nprincipal component analysis and anomaly detection, providing greater\nflexibility and extensibility than traditional SQL capabilities. We leverage\nLLMs to iteratively interpret queries and construct operation sequences,\naddressing computational complexity by incrementally building solutions. By\nexecuting operations directly on the data, we overcome context length\nlimitations without requiring the entire dataset to be processed by the model.\nWe validate our framework through experiments on both standard databases and\nlarge scientific tables, demonstrating its effectiveness in handling extensive\ndatasets and performing sophisticated data analyses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u67e5\u8be2\u8ba1\u5212\u7684\u65b0\u6846\u67b6\uff0c\u7ed5\u8fc7SQL\u7684\u5c40\u9650\u6027\u5e76\u652f\u6301\u590d\u6742\u5206\u6790\u529f\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8868\u683c\u6570\u636e\u96c6\u67e5\u8be2\u548c\u5206\u6790\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u4e3a\u975e\u7f16\u7a0b\u7528\u6237\u63d0\u4f9b\u66f4\u9ad8\u6548\u548c\u7075\u6d3b\u7684\u5de5\u5177\u3002", "method": "\u5229\u7528LLM\u9010\u6b65\u89e3\u91ca\u67e5\u8be2\u5e76\u6784\u5efa\u64cd\u4f5c\u5e8f\u5217\uff0c\u76f4\u63a5\u5728\u6570\u636e\u4e0a\u6267\u884c\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u6807\u51c6\u6570\u636e\u5e93\u548c\u5927\u578b\u79d1\u5b66\u8868\u683c\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u514b\u670d\u4e86SQL\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u4e86\u66f4\u7075\u6d3b\u548c\u9ad8\u6548\u7684\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2508.18969", "pdf": "https://arxiv.org/pdf/2508.18969", "abs": "https://arxiv.org/abs/2508.18969", "authors": ["Zhuoqiang Guo", "Runze Mao", "Lijun Liu", "Guangming Tan", "Weile Jia", "Zhi X. Chen"], "title": "Deep Learning-Enabled Supercritical Flame Simulation at Detailed Chemistry and Real-Fluid Accuracy Towards Trillion-Cell Scale", "categories": ["cs.DC"], "comment": "12 pages, 14 figures, conference: SC25", "summary": "For decades, supercritical flame simulations incorporating detailed chemistry\nand real-fluid transport have been limited to millions of cells, constraining\nthe resolved spatial and temporal scales of the physical system. We optimize\nthe supercritical flame simulation software DeepFlame -- which incorporates\ndeep neural networks while retaining the real-fluid mechanical and chemical\naccuracy -- from three perspectives: parallel computing, computational\nefficiency, and I/O performance. Our highly optimized DeepFlame achieves\nsupercritical liquid oxygen/methane (LOX/\\ce{CH4}) turbulent combustion\nsimulation of up to 618 and 154 billion cells with unprecedented\ntime-to-solution, attaining 439/1186 and 187/316 PFlop/s (32.3\\%/21.8\\% and\n37.4\\%/31.8\\% of the peak) in FP32/mixed-FP16 precision on Sunway (98,304\nnodes) and Fugaku (73,728 nodes) supercomputers, respectively. This\ncomputational capability surpasses existing capacities by three orders of\nmagnitude, enabling the first practical simulation of rocket engine combustion\nwith >100 LOX/\\ce{CH4} injectors. This breakthrough establishes high-fidelity\nsupercritical flame modeling as a critical design tool for next-generation\nrocket propulsion and ultra-high energy density systems.", "AI": {"tldr": "\u901a\u8fc7\u4f18\u5316DeepFlame\u8f6f\u4ef6\uff0c\u5b9e\u73b0\u4e86\u8d85\u4e34\u754c\u706b\u7130\u6a21\u62df\u7684\u5927\u89c4\u6a21\u8ba1\u7b97\uff0c\u8fbe\u5230\u524d\u6240\u672a\u6709\u7684\u6027\u80fd\uff0c\u4e3a\u706b\u7bad\u53d1\u52a8\u673a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u5de5\u5177\u3002", "motivation": "\u8d85\u4e34\u754c\u706b\u7130\u6a21\u62df\u56e0\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\uff0c\u957f\u671f\u5c40\u9650\u4e8e\u767e\u4e07\u7ea7\u7f51\u683c\u3002\u4f18\u5316\u8f6f\u4ef6\u4ee5\u7a81\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u652f\u6301\u706b\u7bad\u53d1\u52a8\u673a\u7b49\u590d\u6742\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3002", "method": "\u4ece\u5e76\u884c\u8ba1\u7b97\u3001\u8ba1\u7b97\u6548\u7387\u548cI/O\u6027\u80fd\u4e09\u4e2a\u65b9\u9762\u4f18\u5316DeepFlame\u8f6f\u4ef6\uff0c\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4fdd\u6301\u771f\u5b9e\u6d41\u4f53\u529b\u5b66\u548c\u5316\u5b66\u7cbe\u5ea6\u3002", "result": "\u5728Sunway\u548cFugaku\u8d85\u7b97\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe6180\u4ebf\u548c1540\u4ebf\u7f51\u683c\u7684\u6a21\u62df\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u706b\u7bad\u53d1\u52a8\u673a\u71c3\u70e7\u6a21\u62df\u63d0\u4f9b\u53ef\u80fd\u3002", "conclusion": "\u4f18\u5316\u7684DeepFlame\u5c06\u9ad8\u7cbe\u5ea6\u8d85\u4e34\u754c\u706b\u7130\u6a21\u62df\u63d0\u5347\u4e3a\u65b0\u8bbe\u8ba1\u5de5\u5177\uff0c\u652f\u6301\u4e0b\u4e00\u4ee3\u706b\u7bad\u63a8\u8fdb\u7cfb\u7edf\u5f00\u53d1\u3002"}}
{"id": "2508.18993", "pdf": "https://arxiv.org/pdf/2508.18993", "abs": "https://arxiv.org/abs/2508.18993", "authors": ["Ziyi Ni", "Huacan Wang", "Shuo Zhang", "Shuo Lu", "Ziyang He", "Wang You", "Zhenheng Tang", "Yuntao Du", "Bill Sun", "Hongzhang Liu", "Sen Hu", "Ronghao Chen", "Bo Li", "Xin Li", "Chen Hu", "Binxing Jiao", "Daxin Jiang", "Pin Lyu"], "title": "GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging", "categories": ["cs.SE", "cs.AI"], "comment": "Highly practical, Well-motivated, Actionable", "summary": "Beyond scratch coding, exploiting large-scale code repositories (e.g.,\nGitHub) for practical tasks is vital in real-world software development, yet\ncurrent benchmarks rarely evaluate code agents in such authentic,\nworkflow-driven scenarios. To bridge this gap, we introduce GitTaskBench, a\nbenchmark designed to systematically assess this capability via 54 realistic\ntasks across 7 modalities and 7 domains. Each task pairs a relevant repository\nwith an automated, human-curated evaluation harness specifying practical\nsuccess criteria. Beyond measuring execution and task success, we also propose\nthe alpha-value metric to quantify the economic benefit of agent performance,\nwhich integrates task success rates, token cost, and average developer\nsalaries. Experiments across three state-of-the-art agent frameworks with\nmultiple advanced LLMs show that leveraging code repositories for complex task\nsolving remains challenging: even the best-performing system, OpenHands+Claude\n3.7, solves only 48.15% of tasks. Error analysis attributes over half of\nfailures to seemingly mundane yet critical steps like environment setup and\ndependency resolution, highlighting the need for more robust workflow\nmanagement and increased timeout preparedness. By releasing GitTaskBench, we\naim to drive progress and attention toward repository-aware code reasoning,\nexecution, and deployment -- moving agents closer to solving complex,\nend-to-end real-world tasks. The benchmark and code are open-sourced at\nhttps://github.com/QuantaAlpha/GitTaskBench.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86GitTaskBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u5728\u771f\u5b9e\u3001\u5de5\u4f5c\u6d41\u9a71\u52a8\u7684\u4ee3\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u7cfb\u7edf\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65f6\u4ecd\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f88\u5c11\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u5728\u771f\u5b9e\u7684\u5de5\u4f5c\u6d41\u9a71\u52a8\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u800c\u8fd9\u662f\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u91cd\u8981\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5f15\u516554\u4e2a\u8de87\u79cd\u6a21\u6001\u548c\u9886\u57df\u7684\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u914d\u6709\u81ea\u52a8\u5316\u7684\u4eba\u4e3a\u8bc4\u4f30\u5de5\u5177\uff0c\u8861\u91cf\u6267\u884c\u548c\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5e76\u63d0\u51faalpha-value\u6307\u6807\u91cf\u5316\u7ecf\u6d4e\u6536\u76ca\u3002", "result": "\u6700\u4f73\u7cfb\u7edf\u4ec5\u5b8c\u621048.15%\u7684\u4efb\u52a1\uff0c\u8d85\u8fc7\u4e00\u534a\u7684\u5931\u8d25\u6e90\u4e8e\u73af\u5883\u8bbe\u7f6e\u548c\u4f9d\u8d56\u89e3\u51b3\u7b49\u57fa\u7840\u6b65\u9aa4\u3002", "conclusion": "GitTaskBench\u65e8\u5728\u63a8\u52a8\u5bf9\u4ee3\u7801\u5e93\u611f\u77e5\u80fd\u529b\u7684\u5173\u6ce8\uff0c\u63a8\u52a8\u4ee3\u7406\u89e3\u51b3\u590d\u6742\u7aef\u5230\u7aef\u73b0\u5b9e\u4efb\u52a1\u7684\u80fd\u529b\u53d1\u5c55\u3002"}}
{"id": "2508.18640", "pdf": "https://arxiv.org/pdf/2508.18640", "abs": "https://arxiv.org/abs/2508.18640", "authors": ["Aniket Nuthalapati", "Nicholas Hinds", "Brian Y. Lim", "Qianwen Wang"], "title": "Enhancing XAI Interpretation through a Reverse Mapping from Insights to Visualizations", "categories": ["cs.HC"], "comment": "5 pages, 5 figures, accepted by IEEE VIS 2025", "summary": "As AI systems become increasingly integrated into high-stakes domains,\nenabling users to accurately interpret model behavior is critical. While AI\nexplanations can be provided, users often struggle to reason effectively with\nthese explanations, limiting their ability to validate or learn from AI\ndecisions. To address this gap, we introduce Reverse Mapping, a novel approach\nthat enhances visual explanations by incorporating user-derived insights back\ninto the explanation workflow. Our system extracts structured insights from\nfree-form user interpretations using a large language model and maps them back\nonto visual explanations through interactive annotations and coordinated\nmulti-view visualizations. Inspired by the verification loop in the\nvisualization knowledge generation model, this design aims to foster more\ndeliberate, reflective interaction with AI explanations. We demonstrate our\napproach in a prototype system with two use cases and qualitative user\nfeedback.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReverse Mapping\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7528\u6237\u5bf9AI\u89e3\u91ca\u7684\u53cd\u9988\u6574\u5408\u5230\u53ef\u89c6\u5316\u89e3\u91ca\u4e2d\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u548c\u9a8c\u8bc1AI\u51b3\u7b56\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7528\u6237\u9700\u8981\u66f4\u6709\u6548\u5730\u7406\u89e3\u548c\u9a8c\u8bc1AI\u89e3\u91ca\uff0c\u4f46\u73b0\u6709\u7684\u89e3\u91ca\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u3002", "method": "\u63d0\u51faReverse Mapping\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7528\u6237\u53cd\u9988\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u89c1\u89e3\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0f\u6ce8\u91ca\u548c\u591a\u89c6\u56fe\u53ef\u89c6\u5316\u5c06\u5176\u6620\u5c04\u56de\u89c6\u89c9\u89e3\u91ca\u4e2d\u3002", "result": "\u901a\u8fc7\u539f\u578b\u7cfb\u7edf\u548c\u7528\u6237\u5b9a\u6027\u53cd\u9988\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u7528\u6237\u4e0eAI\u89e3\u91ca\u4ea4\u4e92\u4e2d\u7684\u53cd\u601d\u6027\u548c\u6709\u6548\u6027\u7684\u6f5c\u529b\u3002", "conclusion": "Reverse Mapping\u4e3a\u589e\u5f3a\u7528\u6237\u5bf9AI\u89e3\u91ca\u7684\u7406\u89e3\u548c\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9014\u5f84\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.18902", "pdf": "https://arxiv.org/pdf/2508.18902", "abs": "https://arxiv.org/abs/2508.18902", "authors": ["Daniel Lindenschmitt", "Paul Seehofer", "Marius Schmitz", "Jan Mertes", "Roland Bless", "Martina Zitterbart", "Jan C. Aurich", "Hans D. Schotten"], "title": "Adaptive 6G Networks-in-Network Management for Industrial Applications", "categories": ["cs.NI"], "comment": "2 figures", "summary": "This paper presents the application of Dynamic Spectrum Management (DSM) for\nfuture 6G industrial networks, establishing an efficient controller for the\nNetworks-in-Network (NiN) concept. The proposed architecture integrates nomadic\nas well as static sub-networks (SNs with diverse Quality of Service (QoS)\nrequirements within the coverage area of an overlayer network, managed by a\ncentralized spectrum manager (SM). Control plane connectivity between the SNs\nand the DSM is ensured by the self-organizing KIRA routing protocol. The\ndemonstrated system enables scalable, zero-touch connectivity and supports\nnomadic SNs through seamless discovery and reconfiguration. SNs are implemented\nfor modular Industrial Internet of Things (IIoT) scenarios, as well as for\nmission-critical control loops and for logistics or nomadic behavior. The DSM\nframework dynamically adapts spectrum allocation to meet real-time demands\nwhile ensuring reliable operation. The demonstration highlights the potential\nof DSM and NiNs to support flexible, dense, and heterogeneous wireless\ndeployments in reconfigurable manufacturing environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u9891\u8c31\u7ba1\u7406\uff08DSM\uff09\u65b9\u6848\uff0c\u7528\u4e8e6G\u5de5\u4e1a\u7f51\u7edc\u4e2d\u7684\u7f51\u7edc\u5d4c\u5957\uff08NiN\uff09\u6982\u5ff5\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u9891\u8c31\u7ba1\u7406\u5668\u5b9e\u73b0\u9ad8\u6548\u9891\u8c31\u5206\u914d\uff0c\u4e3a\u5de5\u4e1a\u7269\u8054\u7f51\u63d0\u4f9b\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u8fde\u63a5\u3002", "motivation": "\u4e3a\u89e3\u51b3\u672a\u67656G\u5de5\u4e1a\u7f51\u7edc\u4e2d\u5f02\u6784\u5b50\u7f51\u7edc\uff08SNs\uff09\u7684\u52a8\u6001\u9891\u8c31\u9700\u6c42\u548c\u5b9e\u65f6\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u4fdd\u969c\u95ee\u9898\uff0c\u63d0\u51faDSM\u6846\u67b6\u3002", "method": "\u91c7\u7528\u96c6\u4e2d\u5f0f\u9891\u8c31\u7ba1\u7406\u5668\uff08SM\uff09\u548c\u81ea\u7ec4\u7ec7KIRA\u8def\u7531\u534f\u8bae\uff0c\u652f\u6301\u9759\u6001\u548c\u79fb\u52a8\u5b50\u7f51\u7edc\u7684\u52a8\u6001\u9891\u8c31\u5206\u914d\u4e0e\u65e0\u7f1d\u91cd\u65b0\u914d\u7f6e\u3002", "result": "\u7cfb\u7edf\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u7684\u96f6\u63a5\u89e6\u8fde\u63a5\u80fd\u529b\uff0c\u652f\u6301\u6a21\u5757\u5316\u5de5\u4e1a\u7269\u8054\u7f51\u573a\u666f\u548c\u5173\u952e\u4efb\u52a1\u63a7\u5236\u3002", "conclusion": "DSM\u548cNiNs\u6846\u67b6\u5728\u53ef\u91cd\u6784\u5236\u9020\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u7075\u6d3b\u3001\u5bc6\u96c6\u548c\u5f02\u6784\u65e0\u7ebf\u90e8\u7f72\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.18830", "pdf": "https://arxiv.org/pdf/2508.18830", "abs": "https://arxiv.org/abs/2508.18830", "authors": ["Shahrzad Khayatbashi", "Majid Rafiei", "Jiayuan Chen", "Timotheus Kampik", "Gregor Berg", "Amin Jalali"], "title": "Enriching Object-Centric Event Data with Process Scopes: A Framework for Aggregation and Analysis", "categories": ["cs.DB"], "comment": null, "summary": "Object-Centric Process Mining enables the analysis of complex operational\nbehavior by capturing interactions among multiple business objects (e.g.,\norders, items, deliveries). These interactions are recorded using\nObject-Centric Event Data (OCED) formats, such as the Object-Centric Event Log\n(OCEL). However, existing formats lack explicit definitions of process scopes,\nwhich restricts analysis to individual processes and limits insights to a low\nlevel of granularity. In practice, OCED often spans multiple interrelated\nprocesses, as shared objects connect events across organizational functions.\nThis structure reflects how value is created along the organizational value\nchain, but introduces challenges for interpretation when process boundaries are\nnot clearly defined. Moreover, process definitions are typically subjective and\ncontext-dependent; they vary across organizations, roles, and analytical goals,\nand cannot always be discovered automatically. To address these challenges, we\npropose a method for embedding analyst-defined process scopes into OCEL. This\nenables the structured representation of multiple coexisting processes,\nsupports the aggregation of event data across scopes, and facilitates analysis\nat varying levels of abstraction. We demonstrate the applicability of our\napproach using a publicly available OCEL log and provide supporting tools for\nscope definition and analysis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c06\u5206\u6790\u5e08\u5b9a\u4e49\u7684\u8fc7\u7a0b\u8303\u56f4\u5d4c\u5165\u5230\u9762\u5411\u5bf9\u8c61\u7684\u4e8b\u4ef6\u65e5\u5fd7\uff08OCEL\uff09\u4e2d\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u683c\u5f0f\u7f3a\u4e4f\u660e\u786e\u8fc7\u7a0b\u8303\u56f4\u5b9a\u4e49\u7684\u95ee\u9898\uff0c\u652f\u6301\u591a\u8fc7\u7a0b\u5171\u5b58\u548c\u4e0d\u540c\u62bd\u8c61\u7ea7\u522b\u7684\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u9762\u5411\u5bf9\u8c61\u4e8b\u4ef6\u6570\u636e\uff08OCED\uff09\u683c\u5f0f\u7f3a\u4e4f\u660e\u786e\u7684\u8fc7\u7a0b\u8303\u56f4\u5b9a\u4e49\uff0c\u9650\u5236\u4e86\u5206\u6790\u5c42\u6b21\u548c\u6d1e\u5bdf\u529b\u3002\u5b9e\u8df5\u4e2d\uff0cOCED\u5e38\u6d89\u53ca\u591a\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u8fc7\u7a0b\uff0c\u4f46\u56e0\u8fc7\u7a0b\u8fb9\u754c\u4e0d\u660e\u786e\u800c\u96be\u4ee5\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c06\u5206\u6790\u5e08\u5b9a\u4e49\u7684\u8fc7\u7a0b\u8303\u56f4\u5d4c\u5165OCEL\uff0c\u652f\u6301\u591a\u8fc7\u7a0b\u7684\u7ed3\u6784\u5316\u8868\u793a\u548c\u8de8\u8303\u56f4\u7684\u805a\u5408\u5206\u6790\u3002", "result": "\u901a\u8fc7\u516c\u5f00\u53ef\u7528\u7684OCEL\u65e5\u5fd7\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9002\u7528\u6027\uff0c\u5e76\u63d0\u4f9b\u5de5\u5177\u652f\u6301\u8303\u56f4\u5b9a\u4e49\u548c\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u8fc7\u7a0b\u8fb9\u754c\u4e0d\u660e\u786e\u7684\u95ee\u9898\uff0c\u652f\u6301\u66f4\u7075\u6d3b\u548c\u591a\u5c42\u6b21\u7684\u5206\u6790\uff0c\u63d0\u5347\u4e86\u9762\u5411\u5bf9\u8c61\u8fc7\u7a0b\u6316\u6398\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.19056", "pdf": "https://arxiv.org/pdf/2508.19056", "abs": "https://arxiv.org/abs/2508.19056", "authors": ["S. Panda", "D. Munjal", "D. P. Mohapatra"], "title": "A Slice-Based Change Impact Analysis for Regression Test Case Prioritization of Object-Oriented Programs", "categories": ["cs.SE"], "comment": null, "summary": "Test case prioritization focuses on finding a suitable order of execution of\nthe test cases in a test suite to meet some performance goals like detecting\nfaults early. It is likely that some test cases execute the program parts that\nare more prone to errors and will detect more errors if executed early during\nthe testing process. Finding an optimal order of execution for the selected\nregression test cases saves time and cost of retesting. This paper presents a\nstatic approach to prioritizing the test cases by computing the affected\ncomponent coupling (ACC) of the affected parts of object-oriented programs. We\nconstruct a graph named affected slice graph (ASG) to represent these affected\nprogram parts.We determine the fault-proneness of the nodes of ASG by computing\ntheir respective ACC values. We assign higher priority to those test cases that\ncover the nodes with higher ACC values. Our analysis with mutation faults shows\nthat the test cases executing the fault-prone program parts have a higher\nchance to reveal faults earlier than other test cases in the test suite. The\nresult obtained from seven case studies justifies that our approach is feasible\nand gives acceptable performance in comparison to some existing techniques.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u9759\u6001\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u9762\u5411\u5bf9\u8c61\u7a0b\u5e8f\u4e2d\u53d7\u5f71\u54cd\u90e8\u5206\u7684\u8026\u5408\u5ea6\uff08ACC\uff09\u6765\u4f18\u5148\u6267\u884c\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63d0\u9ad8\u65e9\u671f\u9519\u8bef\u68c0\u6d4b\u6548\u7387\u3002", "motivation": "\u6d4b\u8bd5\u7528\u4f8b\u4f18\u5148\u6267\u884c\u7684\u76ee\u6807\u662f\u4f18\u5316\u6d4b\u8bd5\u987a\u5e8f\u4ee5\u65e9\u671f\u68c0\u6d4b\u9519\u8bef\uff0c\u8282\u7701\u91cd\u65b0\u6d4b\u8bd5\u7684\u65f6\u95f4\u548c\u6210\u672c\u3002", "method": "\u6784\u5efa\u53d7\u5f71\u54cd\u5207\u7247\u56fe\uff08ASG\uff09\u8868\u793a\u53d7\u5f71\u54cd\u7684\u7a0b\u5e8f\u90e8\u5206\uff0c\u901a\u8fc7\u8ba1\u7b97\u8282\u70b9\u7684ACC\u503c\u786e\u5b9a\u5176\u9519\u8bef\u503e\u5411\u6027\uff0c\u4f18\u5148\u6267\u884c\u8986\u76d6\u9ad8ACC\u503c\u8282\u70b9\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u65e9\u671f\u9519\u8bef\u68c0\u6d4b\u7387\uff0c\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\u5177\u6709\u53ef\u884c\u6027\u3002", "conclusion": "\u57fa\u4e8eACC\u7684\u9759\u6001\u4f18\u5148\u6267\u884c\u65b9\u6cd5\u5728\u6d4b\u8bd5\u7528\u4f8b\u4f18\u5316\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2508.18670", "pdf": "https://arxiv.org/pdf/2508.18670", "abs": "https://arxiv.org/abs/2508.18670", "authors": ["Vidya Setlur", "Samuel Ridet"], "title": "R\u00c9CITKIT: A Spatial Toolkit for Designing and Evaluating Human-Centered Immersive Data Narratives", "categories": ["cs.HC"], "comment": "5 pages, 3 figures", "summary": "Spatial computing presents new opportunities for immersive data storytelling,\nyet there is limited guidance on how to build such experiences or adapt\ntraditional narrative visualizations to this medium. We introduce a toolkit,\nR\\'ECITKIT for supporting spatial data narratives in head-mounted display (HMD)\nenvironments. The toolkit allows developers to create interactive dashboards,\ntag data attributes as spatial assets to 3D models and immersive scenes,\ngenerate text and audio narratives, enabling dynamic filtering, and\nhierarchical drill-down data discoverability. To demonstrate the utility of the\ntoolkit, we developed Charles Minard's historical flow map of Napoleon's 1812\ncampaign in Russia as an immersive experience on Apple Vision Pro. We conducted\na preliminary evaluation with 21 participants that comprised two groups:\ndevelopers, who evaluated the toolkit by authoring spatial stories and\nconsumers, who provided feedback on the Minard app's narrative clarity,\ninteraction design, and engagement. Feedback highlighted how spatial\ninteractions and guided narration enhanced insight formation, with participants\nemphasizing the benefits of physical manipulation (e.g., gaze, pinch,\nnavigation) for understanding temporal and geographic data. Participants also\nidentified opportunities for future enhancement, including improved interaction\naffordance visibility, customizable storytelling logic, and integration of\ncontextual assets to support user orientation. These findings contribute to the\nbroader discourse on toolkit-driven approaches to immersive data storytelling\nacross domains such as education, decision support, and exploratory analytics.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86R\u00c9CITKIT\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5728\u5934\u6234\u5f0f\u663e\u793a\u5668\uff08HMD\uff09\u73af\u5883\u4e2d\u6784\u5efa\u7a7a\u95f4\u6570\u636e\u53d9\u4e8b\uff0c\u5e76\u901a\u8fc7\u5f00\u53d1\u62ff\u7834\u4ed11812\u5e74\u6218\u5f79\u7684\u6c89\u6d78\u5f0f\u5730\u56fe\u6f14\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002\u521d\u6b65\u7528\u6237\u8bc4\u4f30\u8868\u660e\uff0c\u7a7a\u95f4\u4ea4\u4e92\u548c\u5f15\u5bfc\u53d9\u4e8b\u6709\u52a9\u4e8e\u589e\u5f3a\u6570\u636e\u6d1e\u5bdf\u529b\u3002", "motivation": "\u7a7a\u95f4\u8ba1\u7b97\u4e3a\u6c89\u6d78\u5f0f\u6570\u636e\u53d9\u4e8b\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u76f8\u5173\u5de5\u5177\u548c\u6307\u5bfc\u3002", "method": "\u5f00\u53d1\u4e86R\u00c9CITKIT\u5de5\u5177\u5305\uff0c\u652f\u6301\u521b\u5efa\u4ea4\u4e92\u5f0f\u4eea\u8868\u76d8\u3001\u7a7a\u95f4\u8d44\u4ea7\u6807\u8bb0\u3001\u52a8\u6001\u8fc7\u6ee4\u548c\u6570\u636e\u63a2\u7d22\u3002\u901a\u8fc7\u5f00\u53d1\u62ff\u7834\u4ed1\u6218\u5f79\u7684\u6c89\u6d78\u5f0f\u5e94\u7528\u8fdb\u884c\u4e86\u6f14\u793a\u548c\u521d\u6b65\u7528\u6237\u8bc4\u4f30\u3002", "result": "\u7528\u6237\u53cd\u9988\u663e\u793a\uff0c\u7a7a\u95f4\u4ea4\u4e92\u548c\u7269\u7406\u64cd\u4f5c\uff08\u5982\u51dd\u89c6\u3001\u634f\u5408\uff09\u5bf9\u7406\u89e3\u65f6\u7a7a\u6570\u636e\u7279\u522b\u6709\u6548\u3002\u540c\u65f6\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\uff0c\u5982\u63d0\u5347\u4ea4\u4e92\u53ef\u89c1\u6027\u548c\u81ea\u5b9a\u4e49\u53d9\u4e8b\u903b\u8f91\u3002", "conclusion": "\u8be5\u5de5\u5177\u5305\u4e3a\u6c89\u6d78\u5f0f\u6570\u636e\u53d9\u4e8b\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u652f\u6301\uff0c\u672a\u6765\u53ef\u6269\u5c55\u81f3\u6559\u80b2\u3001\u51b3\u7b56\u652f\u6301\u7b49\u9886\u57df\u3002"}}
{"id": "2508.19067", "pdf": "https://arxiv.org/pdf/2508.19067", "abs": "https://arxiv.org/abs/2508.19067", "authors": ["Aiden Valentine", "George Parisis"], "title": "LeoTCP: Low-Latency and High-Throughput Data Transport for LEO Satellite Networks", "categories": ["cs.NI"], "comment": "10 pages, 10 figures", "summary": "Low-Earth Orbit (LEO) satellite networks consist of thousands of satellites\norbiting the Earth, enabling low-latency and high-throughput communications\nacross the globe. Such networks present unprecedented challenges due to their\ndynamic nature, which state-of-the-art data transport protocols do not address.\nThese challenges include: (1) non-congestive latency variation and loss, caused\nby continuous satellite movement and fluctuating link quality due to weather\neffects; (2) transient hotspots leading to buffer build-up, latency inflation,\nand potential packet loss; and (3) frequent handovers, which may result in\ntemporary connectivity loss and re-routing through paths with unknown\ncongestion and delay characteristics. In this paper, we introduce LeoTCP, a\nnovel data transport protocol designed specifically to address these\nchallenges. LeoTCP leverages in-network telemetry (INT) to gather congestion\ninformation on a per-hop basis. Using this information, LeoTCP (1) minimises\nboth buffer occupancy and latency for end users, (2) maximises application\nthroughput and network utilisation, and (3) swiftly reacts to network hotspots.\nWe compare LeoTCP to state-of-the-art data transport protocols using a LEO\nsatellite simulation model and targeted micro-benchmarks, both based on\nOMNeT++/INET. The simulation model captures RTT dynamics in a simulated LEO\nsatellite constellation, while the micro-benchmarks isolate key LEO-specific\ncharacteristics, including non-congestive latency variation and loss, path\nchanges, and congestion hotspots. Our results demonstrate that LeoTCP\nsignificantly increases goodput compared to existing state-of-the-art\napproaches, while simultaneously minimising latency.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86LeoTCP\uff0c\u4e00\u79cd\u4e13\u4e3a\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u536b\u661f\u7f51\u7edc\u8bbe\u8ba1\u7684\u65b0\u578b\u6570\u636e\u4f20\u8f93\u534f\u8bae\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u7f51\u7edc\u4e2d\u7684\u5ef6\u8fdf\u53d8\u5316\u3001\u70ed\u70b9\u548c\u9891\u7e41\u5207\u6362\u7b49\u6311\u6218\u3002", "motivation": "LEO\u536b\u661f\u7f51\u7edc\u7531\u4e8e\u5176\u52a8\u6001\u7279\u6027\uff08\u5982\u536b\u661f\u79fb\u52a8\u3001\u94fe\u8def\u8d28\u91cf\u6ce2\u52a8\u548c\u9891\u7e41\u5207\u6362\uff09\u5e26\u6765\u4e86\u72ec\u7279\u7684\u6311\u6218\uff0c\u73b0\u6709\u534f\u8bae\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u3002", "method": "LeoTCP\u5229\u7528\u7f51\u7edc\u5185\u9065\u6d4b\u6280\u672f\uff08INT\uff09\u9010\u8df3\u6536\u96c6\u62e5\u585e\u4fe1\u606f\uff0c\u4ee5\u6700\u5c0f\u5316\u7f13\u51b2\u5360\u7528\u548c\u5ef6\u8fdf\uff0c\u6700\u5927\u5316\u541e\u5410\u91cf\u548c\u7f51\u7edc\u5229\u7528\u7387\uff0c\u5e76\u5feb\u901f\u5e94\u5bf9\u7f51\u7edc\u70ed\u70b9\u3002", "result": "\u901a\u8fc7\u4e0e\u73b0\u6709\u534f\u8bae\u7684\u6bd4\u8f83\uff0cLeoTCP\u5728\u4eff\u771f\u548c\u5fae\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "conclusion": "LeoTCP\u662f\u89e3\u51b3LEO\u536b\u661f\u7f51\u7edc\u52a8\u6001\u7279\u6027\u5f15\u8d77\u7684\u6311\u6218\u7684\u6709\u6548\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.19055", "pdf": "https://arxiv.org/pdf/2508.19055", "abs": "https://arxiv.org/abs/2508.19055", "authors": ["Giancarlo Gatti", "Rihan Hai"], "title": "Private Quantum Database", "categories": ["quant-ph", "cs.DB"], "comment": null, "summary": "Quantum databases open an exciting new frontier in data management by\noffering privacy guarantees that classical systems cannot match. Traditional\nengines tackle user privacy, which hides the records being queried, or data\nprivacy, which prevents a user from learning more than she has queried. We\npropose a quantum database that protects both by leveraging quantum mechanics:\nwhen the user measures her chosen basis, the superposition collapses and the\nunqueried rows become physically inaccessible. We encode relational tables as a\nsequence of Quantum Random Access Codes (QRACs) over mutually unbiased bases\n(MUBs), transmit a bounded number of quantum states, and let a single,\ndestructive measurement reconstruct only the selected tuple. This allows us to\npreserve data privacy and user privacy at once without trusted hardware or\nheavyweight cryptography. Moreover, we envision a novel hybrid\nquantum-classical architecture ready for early deployment, which ensures\ncompatibility with the limitations of today's Noisy Intermediate-Scale Quantum\ndevices.", "AI": {"tldr": "\u91cf\u5b50\u6570\u636e\u5e93\u901a\u8fc7\u91cf\u5b50\u529b\u5b66\u4fdd\u62a4\u6570\u636e\u548c\u7528\u6237\u9690\u79c1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408QRACs\u548cMUBs\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u4f9d\u8d56\u53ef\u4fe1\u786c\u4ef6\u6216\u590d\u6742\u52a0\u5bc6\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u5e93\u7cfb\u7edf\u53ea\u80fd\u5355\u72ec\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u6216\u7528\u6237\u9690\u79c1\uff0c\u91cf\u5b50\u6570\u636e\u5e93\u65e8\u5728\u540c\u65f6\u5b9e\u73b0\u8fd9\u4e24\u8005\u3002", "method": "\u5c06\u5173\u7cfb\u8868\u7f16\u7801\u4e3a\u57fa\u4e8eMUBs\u7684QRACs\u5e8f\u5217\uff0c\u901a\u8fc7\u6709\u9650\u91cf\u5b50\u6001\u4f20\u8f93\u548c\u5355\u6b21\u7834\u574f\u6027\u6d4b\u91cf\u5b9e\u73b0\u6570\u636e\u91cd\u6784\u3002", "result": "\u5b9e\u73b0\u4e86\u6570\u636e\u9690\u79c1\u548c\u7528\u6237\u9690\u79c1\u7684\u53cc\u91cd\u4fdd\u62a4\uff0c\u4e14\u517c\u5bb9\u5f53\u524dNISQ\u8bbe\u5907\u7684\u9650\u5236\u3002", "conclusion": "\u91cf\u5b50\u6570\u636e\u5e93\u4e3a\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u524d\u6cbf\u6280\u672f\uff0c\u540c\u65f6\u9002\u5408\u65e9\u671f\u90e8\u7f72\u7684\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u67b6\u6784\u3002"}}
{"id": "2508.19078", "pdf": "https://arxiv.org/pdf/2508.19078", "abs": "https://arxiv.org/abs/2508.19078", "authors": ["Fahao Chen", "Jie Wan", "Peng Li", "Zhou Su", "Dongxiao Yu"], "title": "Federated Fine-Tuning of Sparsely-Activated Large Language Models on Resource-Constrained Devices", "categories": ["cs.DC"], "comment": "Accepted by EuroSys'26. The camera-ready version will be uploaded\n  later", "summary": "Federated fine-tuning of Mixture-of-Experts (MoE)-based large language models\n(LLMs) is challenging due to their massive computational requirements and the\nresource constraints of participants. Existing working attempts to fill this\ngap through model quantization, computation offloading, or expert pruning.\nHowever, they cannot achieve desired performance due to impractical system\nassumptions and a lack of consideration for MoE-specific characteristics. In\nthis paper, we propose FLUX, a system designed to enable federated fine-tuning\nof MoE-based LLMs across participants with constrained computing resources\n(e.g., consumer-grade GPUs), aiming to minimize time-to-accuracy. FLUX\nintroduces three key innovations: (1) quantization-based local profiling to\nestimate expert activation with minimal overhead, (2) adaptive layer-aware\nexpert merging to reduce resource consumption while preserving accuracy, and\n(3) dynamic expert role assignment using an exploration-exploitation strategy\nto balance tuning and non-tuning experts. Extensive experiments on LLaMA-MoE\nand DeepSeek-MoE with multiple benchmark datasets demonstrate that FLUX\nsignificantly outperforms existing methods, achieving up to 4.75X speedup in\ntime-to-accuracy.", "AI": {"tldr": "FLUX\u7cfb\u7edf\u901a\u8fc7\u91cf\u5316\u5206\u6790\u3001\u81ea\u9002\u5e94\u5408\u5e76\u548c\u52a8\u6001\u89d2\u8272\u5206\u914d\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u8054\u90a6\u5fae\u8c03Mixture-of-Experts\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u8054\u90a6\u5fae\u8c03MoE\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6311\u6218\uff0c\u5f25\u8865\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u91cf\u5316\u5206\u6790\u3001\u81ea\u9002\u5e94\u5408\u5e76\u548c\u52a8\u6001\u89d2\u8272\u5206\u914d\u4e09\u79cd\u521b\u65b0\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cFLUX\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u901f\u8fbe4.75\u500d\u3002", "conclusion": "FLUX\u4e3a\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u8054\u90a6\u5fae\u8c03\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18298", "pdf": "https://arxiv.org/pdf/2508.18298", "abs": "https://arxiv.org/abs/2508.18298", "authors": ["Gohar Irfan Chaudhry", "Esha Choukse", "Haoran Qiu", "\u00cd\u00f1igo Goiri", "Rodrigo Fonseca", "Adam Belay", "Ricardo Bianchini"], "title": "Murakkab: Resource-Efficient Agentic Workflow Orchestration in Cloud Platforms", "categories": ["cs.MA", "cs.AI", "cs.SE"], "comment": null, "summary": "Agentic workflows commonly coordinate multiple models and tools with complex\ncontrol logic. They are quickly becoming the dominant paradigm for AI\napplications. However, serving them remains inefficient with today's\nframeworks. The key problem is that they expose workflows as opaque sequences\nof model and tool calls that tightly couple agent logic with model and hardware\nchoices. Often, these workflow components are fragmented across different\nentities, preventing systems from reasoning about trade-offs across accuracy,\nlatency, energy, and cost. This leads to resource waste and degraded\nservice-level objectives (SLOs).\n  We present Murakkab, a resource-efficient serving system for agentic\nworkflows. Murakkab introduces a declarative abstraction that decouples\nworkflow specification from execution configuration. A profile-guided optimizer\nand adaptive runtime jointly manage the full stack: orchestrating workflow\ncomponents, mapping them to models and hardware, and dynamically reconfiguring\nexecution to satisfy user-defined SLOs. By exposing the internal structure of\nagentic workflows, Murakkab enables cross-layer optimization that existing\nframeworks and cloud schedulers cannot achieve.\n  Our evaluation on diverse workflows shows that \\sysname{} reduces GPU usage\nby up to 2.8$\\times$, energy consumption by 3.7$\\times$, and cost by\n4.3$\\times$ while maintaining SLOs.", "AI": {"tldr": "Murakkab\u7cfb\u7edf\u901a\u8fc7\u58f0\u660e\u5f0f\u62bd\u8c61\u548c\u8de8\u5c42\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u8d44\u6e90\u6548\u7387\uff0c\u51cf\u5c11\u4e86GPU\u4f7f\u7528\u3001\u80fd\u6e90\u6d88\u8017\u548c\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u8d44\u6e90\u5229\u7528\u6548\u7387\u4f4e\uff0c\u903b\u8f91\u4e0e\u6a21\u578b\u3001\u786c\u4ef6\u9009\u62e9\u7d27\u8026\u5408\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u548c\u670d\u52a1\u76ee\u6807\u53d7\u635f\u3002", "method": "\u63d0\u51faMurakkab\u7cfb\u7edf\uff0c\u91c7\u7528\u58f0\u660e\u5f0f\u62bd\u8c61\u5206\u79bb\u5de5\u4f5c\u6d41\u89c4\u683c\u4e0e\u6267\u884c\u914d\u7f6e\uff0c\u7ed3\u5408\u4f18\u5316\u5668\u548c\u8fd0\u884c\u65f6\u52a8\u6001\u8c03\u6574\u6267\u884c\u3002", "result": "\u6d4b\u8bd5\u663e\u793a\uff0cMurakkab\u51cf\u5c11GPU\u4f7f\u75282.8\u500d\uff0c\u80fd\u80173.7\u500d\uff0c\u6210\u672c4.3\u500d\uff0c\u540c\u65f6\u6ee1\u8db3SLO\u3002", "conclusion": "Murakkab\u901a\u8fc7\u8de8\u5c42\u4f18\u5316\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7406\u5de5\u4f5c\u6d41\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u3002"}}
{"id": "2508.18782", "pdf": "https://arxiv.org/pdf/2508.18782", "abs": "https://arxiv.org/abs/2508.18782", "authors": ["Hiroto Sakimura", "Takayuki Nagaya", "Tomoki Nishi", "Tetsuo Kurahashi", "Katsunori Kohda", "Nobuhiko Muramoto"], "title": "Long-Term Variability in Physiological-Arousal Relationships for Robust Emotion Estimation", "categories": ["cs.HC", "cs.AI"], "comment": "9 pages, 5 figures, accepted at 13th International Conference on\n  Affective Computing and Intelligent Interaction (ACII 2025)", "summary": "Estimating emotional states from physiological signals is a central topic in\naffective computing and psychophysiology. While many emotion estimation systems\nimplicitly assume a stable relationship between physiological features and\nsubjective affect, this assumption has rarely been tested over long timeframes.\nThis study investigates whether such relationships remain consistent across\nseveral months within individuals. We developed a custom measurement system and\nconstructed a longitudinal dataset by collecting physiological signals --\nincluding blood volume pulse, electrodermal activity (EDA), skin temperature,\nand acceleration--along with self-reported emotional states from 24\nparticipants over two three-month periods. Data were collected in naturalistic\nworking environments, allowing analysis of the relationship between\nphysiological features and subjective arousal in everyday contexts. We examined\nhow physiological-arousal relationships evolve over time by using Explainable\nBoosting Machines (EBMs) to ensure model interpretability. A model trained on\n1st-period data showed a 5\\% decrease in accuracy when tested on 2nd-period\ndata, indicating long-term variability in physiological-arousal associations.\nEBM-based comparisons further revealed that while heart rate remained a\nrelatively stable predictor, minimum EDA exhibited substantial individual-level\nfluctuations between periods. While the number of participants is limited,\nthese findings highlight the need to account for temporal variability in\nphysiological-arousal relationships and suggest that emotion estimation models\nshould be periodically updated -- e.g., every five months -- based on observed\nshift trends to maintain robust performance over time.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u751f\u7406\u4fe1\u53f7\u4e0e\u60c5\u7eea\u72b6\u6001\u7684\u5173\u7cfb\u5b58\u5728\u957f\u671f\u53d8\u5f02\u6027\uff0c\u9700\u5b9a\u671f\u66f4\u65b0\u60c5\u7eea\u4f30\u8ba1\u6a21\u578b\u4ee5\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u9a8c\u8bc1\u751f\u7406\u7279\u5f81\u4e0e\u4e3b\u89c2\u60c5\u7eea\u4e4b\u95f4\u7684\u7a33\u5b9a\u5173\u7cfb\u662f\u5426\u80fd\u5728\u6570\u6708\u5185\u4fdd\u6301\u4e00\u81f4\uff0c\u4ee5\u63d0\u5347\u60c5\u7eea\u4f30\u8ba1\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "method": "\u5229\u7528\u5b9a\u5236\u6d4b\u91cf\u7cfb\u7edf\u6536\u96c624\u540d\u53c2\u4e0e\u8005\u81ea\u7136\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u751f\u7406\u4fe1\u53f7\uff08\u5982\u5fc3\u7387\u3001EDA\u7b49\uff09\u53ca\u81ea\u6211\u62a5\u544a\u60c5\u7eea\uff0c\u4f7f\u7528EBMs\u5206\u6790\u5176\u53d8\u5316\u3002", "result": "\u6a21\u578b\u5728\u7b2c\u4e8c\u671f\u6570\u636e\u4e0a\u7684\u51c6\u786e\u6027\u4e0b\u964d5%\uff0c\u663e\u793a\u751f\u7406-\u5524\u9192\u5173\u7cfb\u7684\u957f\u671f\u53d8\u5f02\u6027\uff1b\u5fc3\u7387\u7a33\u5b9a\uff0c\u4f46EDA\u5b58\u5728\u4e2a\u4f53\u6ce2\u52a8\u3002", "conclusion": "\u751f\u7406-\u5524\u9192\u5173\u7cfb\u5177\u65f6\u95f4\u53d8\u5f02\u6027\uff0c\u9700\u5b9a\u671f\uff08\u5982\u6bcf\u4e94\u4e2a\u6708\uff09\u66f4\u65b0\u60c5\u7eea\u4f30\u8ba1\u6a21\u578b\u4ee5\u5e94\u5bf9\u53d8\u5316\u3002"}}
{"id": "2508.19130", "pdf": "https://arxiv.org/pdf/2508.19130", "abs": "https://arxiv.org/abs/2508.19130", "authors": ["Laura Finarelli", "Maoquan Ni", "Michela Meo", "Falko Dressler", "Gianluca Rizzo"], "title": "Sharing is Caring: Analysis of Hybrid Network Sharing Strategies for Energy Efficient Multi-Operator Cellular Systems", "categories": ["cs.NI"], "comment": null, "summary": "This paper introduces a novel analytical framework for evaluating\nenergy-efficient, QoS-aware network-sharing strategies in cellular networks.\nLeveraging stochastic geometry, our framework enables the systematic assessment\nof network performance across a range of sharing paradigms, including both\nconventional single-operator scenarios and advanced hybrid strategies that\nenable full integration and cooperation among multiple mobile network\noperators. Our framework incorporates diverse user densities, rate\nrequirements, and energy consumption models to ensure comprehensive analysis.\nApplying our results to real-world datasets from French mobile network\noperators, we demonstrate that hybrid network sharing can yield substantial\nenergy savings, up to $35\\%$, while maintaining quality of service.\nFurthermore, our results allow us to characterizing how the benefits of network\nsharing vary as a function of the geographical and functional characteristics\nof the deployment area. These findings highlight the potential of collaborative\nsharing strategies to enhance operational efficiency and sustainability in\nnext-generation cellular networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8702\u7a9d\u7f51\u7edc\u4e2d\u80fd\u6548\u4e14QoS\u611f\u77e5\u7684\u7f51\u7edc\u5171\u4eab\u7b56\u7565\u7684\u65b0\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u968f\u673a\u51e0\u4f55\u5b66\u548c\u591a\u8fd0\u8425\u5546\u534f\u4f5c\uff0c\u5c55\u793a\u4e86\u9ad8\u8fbe35%\u7684\u8282\u80fd\u6f5c\u529b\u3002", "motivation": "\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u7f51\u7edc\u5171\u4eab\u7b56\u7565\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u591a\u8fd0\u8425\u5546\u534f\u4f5c\u7684\u80cc\u666f\u4e0b\uff0c\u4ee5\u63d0\u5347\u80fd\u6548\u548c\u670d\u52a1\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u968f\u673a\u51e0\u4f55\u5b66\u6846\u67b6\uff0c\u7ed3\u5408\u7528\u6237\u5bc6\u5ea6\u3001\u901f\u7387\u9700\u6c42\u548c\u80fd\u8017\u6a21\u578b\uff0c\u5206\u6790\u5355\u8fd0\u8425\u5546\u548c\u591a\u8fd0\u8425\u5546\u6df7\u5408\u5171\u4eab\u7b56\u7565\u3002", "result": "\u5e94\u7528\u4e8e\u6cd5\u56fd\u79fb\u52a8\u8fd0\u8425\u5546\u6570\u636e\u96c6\u65f6\uff0c\u6df7\u5408\u5171\u4eab\u7b56\u7565\u53ef\u5b9e\u73b0\u9ad8\u8fbe35%\u7684\u8282\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u670d\u52a1\u8d28\u91cf\uff0c\u4e14\u6548\u76ca\u53d7\u90e8\u7f72\u533a\u57df\u7279\u6027\u5f71\u54cd\u3002", "conclusion": "\u534f\u4f5c\u5171\u4eab\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u4e0b\u4e00\u4ee3\u8702\u7a9d\u7f51\u7edc\u7684\u8fd0\u8425\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2508.19138", "pdf": "https://arxiv.org/pdf/2508.19138", "abs": "https://arxiv.org/abs/2508.19138", "authors": ["Nicolas Vetsch", "Alexander Maeder", "Vincent Maillou", "Anders Winka", "Jiang Cao", "Grzegorz Kwasniewski", "Leonard Deuschle", "Torsten Hoefler", "Alexandros Nikolaos Ziogas", "Mathieu Luisier"], "title": "Ab-initio Quantum Transport with the GW Approximation, 42,240 Atoms, and Sustained Exascale Performance", "categories": ["cs.DC", "cond-mat.mes-hall", "cs.CE"], "comment": null, "summary": "Designing nanoscale electronic devices such as the currently manufactured\nnanoribbon field-effect transistors (NRFETs) requires advanced modeling tools\ncapturing all relevant quantum mechanical effects. State-of-the-art approaches\ncombine the non-equilibrium Green's function (NEGF) formalism and density\nfunctional theory (DFT). However, as device dimensions do not exceed a few\nnanometers anymore, electrons are confined in ultra-small volumes, giving rise\nto strong electron-electron interactions. To account for these critical\neffects, DFT+NEGF solvers should be extended with the GW approximation, which\nmassively increases their computational intensity. Here, we present the first\nimplementation of the NEGF+GW scheme capable of handling NRFET geometries with\ndimensions comparable to experiments. This package, called QuaTrEx, makes use\nof a novel spatial domain decomposition scheme, can treat devices made of up to\n84,480 atoms, scales very well on the Alps and Frontier supercomputers (>80%\nweak scaling efficiency), and sustains an exascale FP64 performance on 42,240\natoms (1.15 Eflop/s).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuaTrEx\u7684NEGF+GW\u5b9e\u73b0\u65b9\u6848\uff0c\u7528\u4e8e\u5904\u7406\u7eb3\u7c73\u5c3a\u5ea6\u7535\u5b50\u5668\u4ef6\u4e2d\u7684\u5f3a\u7535\u5b50-\u7535\u5b50\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5927\u89c4\u6a21\u8ba1\u7b97\u4e2d\u7684\u9ad8\u6548\u6027\u80fd\u3002", "motivation": "\u7eb3\u7c73\u5c3a\u5ea6\u7535\u5b50\u5668\u4ef6\uff08\u5982NRFETs\uff09\u7684\u5efa\u6a21\u9700\u8981\u6355\u6349\u91cf\u5b50\u529b\u5b66\u6548\u5e94\uff0c\u5c24\u5176\u662f\u5f3a\u7535\u5b50-\u7535\u5b50\u76f8\u4e92\u4f5c\u7528\u3002\u73b0\u6709DFT+NEGF\u65b9\u6cd5\u9700\u6269\u5c55GW\u8fd1\u4f3c\u3002", "method": "\u63d0\u51fa\u4e86NEGF+GW\u65b9\u6848\u7684\u9996\u6b21\u5b9e\u73b0\uff0c\u4f7f\u7528\u65b0\u7684\u7a7a\u95f4\u57df\u5206\u89e3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u5b9e\u9a8c\u89c4\u6a21\uff0884,480\u539f\u5b50\uff09\u7684\u5668\u4ef6\u3002", "result": "QuaTrEx\u5728\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u8868\u73b0\u4f18\u5f02\uff08>80%\u5f31\u6269\u5c55\u6548\u7387\uff09\uff0c1.15 Eflop/s\u7684exascale\u6027\u80fd\u3002", "conclusion": "QuaTrEx\u4e3a\u7eb3\u7c73\u5668\u4ef6\u5efa\u6a21\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\uff0c\u80fd\u591f\u5904\u7406\u5b9e\u9a8c\u89c4\u6a21\u7684\u5f3a\u76f8\u4e92\u4f5c\u7528\u95ee\u9898\u3002"}}
{"id": "2508.18439", "pdf": "https://arxiv.org/pdf/2508.18439", "abs": "https://arxiv.org/abs/2508.18439", "authors": ["Anders M\u00f8lmen H\u00f8st", "Pierre Lison", "Leon Moonen"], "title": "A Systematic Approach to Predict the Impact of Cybersecurity Vulnerabilities Using LLMs", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.SE"], "comment": null, "summary": "Vulnerability databases, such as the National Vulnerability Database (NVD),\noffer detailed descriptions of Common Vulnerabilities and Exposures (CVEs), but\noften lack information on their real-world impact, such as the tactics,\ntechniques, and procedures (TTPs) that adversaries may use to exploit the\nvulnerability. However, manually linking CVEs to their corresponding TTPs is a\nchallenging and time-consuming task, and the high volume of new vulnerabilities\npublished annually makes automated support desirable.\n  This paper introduces TRIAGE, a two-pronged automated approach that uses\nLarge Language Models (LLMs) to map CVEs to relevant techniques from the ATT&CK\nknowledge base. We first prompt an LLM with instructions based on MITRE's CVE\nMapping Methodology to predict an initial list of techniques. This list is then\ncombined with the results from a second LLM-based module that uses in-context\nlearning to map a CVE to relevant techniques. This hybrid approach\nstrategically combines rule-based reasoning with data-driven inference. Our\nevaluation reveals that in-context learning outperforms the individual mapping\nmethods, and the hybrid approach improves recall of exploitation techniques. We\nalso find that GPT-4o-mini performs better than Llama3.3-70B on this task.\nOverall, our results show that LLMs can be used to automatically predict the\nimpact of cybersecurity vulnerabilities and TRIAGE makes the process of mapping\nCVEs to ATT&CK more efficient.\n  Keywords: vulnerability impact, CVE, ATT&CK techniques, large language\nmodels, automated mapping.", "AI": {"tldr": "TRIAGE\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5c06CVE\u6620\u5c04\u5230ATT&CK\u6280\u672f\uff0c\u7ed3\u5408\u89c4\u5219\u63a8\u7406\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u6570\u636e\u5e93\u7f3a\u4e4f\u6f0f\u6d1e\u5b9e\u9645\u5f71\u54cd\u4fe1\u606f\uff0c\u4eba\u5de5\u6620\u5c04\u8017\u65f6\u4e14\u6548\u7387\u4f4e\uff0c\u9700\u81ea\u52a8\u5316\u652f\u6301\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684LLM\u6a21\u5757\uff0c\u9884\u6d4bCVE\u76f8\u5173\u653b\u51fb\u6280\u672f\u3002", "result": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u8868\u73b0\u4f18\u4e8e\u5355\u4e00\u65b9\u6cd5\uff0c\u6df7\u5408\u65b9\u6cd5\u63d0\u5347\u6280\u672f\u53ec\u56de\u7387\uff0cGPT-4o-mini\u4f18\u4e8eLlama3.3-70B\u3002", "conclusion": "LLM\u53ef\u81ea\u52a8\u5316\u9884\u6d4b\u6f0f\u6d1e\u5f71\u54cd\uff0cTRIAGE\u63d0\u5347CVE\u5230ATT&CK\u6620\u5c04\u6548\u7387\u3002"}}
{"id": "2508.18784", "pdf": "https://arxiv.org/pdf/2508.18784", "abs": "https://arxiv.org/abs/2508.18784", "authors": ["Maximilian Frank", "Simon Lund"], "title": "Insights into User Interface Innovations from a Design Thinking Workshop at deRSE25", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Large Language Models have become widely adopted tools due to their versatile\ncapabilities, yet their user interfaces remain limited, often following rigid,\nlinear interaction paradigms. In this paper, we present insights from a design\nthinking workshop held at the deRSE25 conference aiming at collaboratively\ndeveloping innovative user interface concepts for LLMs. During the workshop,\nparticipants identified common use cases, evaluated the strengths and\nshortcomings of current LLM interfaces, and created visualizations of new\ninteraction concepts emphasizing flexible context management, dynamic\nconversation branching, and enhanced mechanisms for user control. We describe\nhow these participant-generated ideas advanced our own whiteboard-based UI\napproach. The ongoing development of this interface is guided by the\nhuman-centered design process - an iterative, user-focused methodology that\nemphasizes continuous refinement through user feedback. Broader implications\nfor future LLM interface development are discussed, advocating for increased\nattention to UI innovation grounded in user-centered design principles.", "AI": {"tldr": "\u8bba\u6587\u603b\u7ed3\u4e86\u901a\u8fc7\u8bbe\u8ba1\u601d\u7ef4\u5de5\u4f5c\u574a\u5f00\u53d1\u7684\u521b\u65b0LLM\u7528\u6237\u754c\u9762\u6982\u5ff5\uff0c\u5f3a\u8c03\u7528\u6237\u4e2d\u5fc3\u8bbe\u8ba1\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709LLM\u754c\u9762\u8fc7\u4e8e\u7ebf\u6027\u5316\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7528\u6237\u53cd\u9988\u5f00\u53d1\u66f4\u7075\u6d3b\u7684\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u601d\u7ef4\u5de5\u4f5c\u574a\u6536\u96c6\u53c2\u4e0e\u8005\u610f\u89c1\uff0c\u63d0\u51fa\u65b0\u754c\u9762\u6982\u5ff5\uff0c\u5e76\u91c7\u7528\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u65b9\u6cd5\u8fed\u4ee3\u5f00\u53d1\u3002", "result": "\u63d0\u51fa\u4e86\u652f\u6301\u7075\u6d3b\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u52a8\u6001\u5bf9\u8bdd\u5206\u652f\u548c\u589e\u5f3a\u7528\u6237\u63a7\u5236\u7684\u754c\u9762\u6982\u5ff5\u3002", "conclusion": "\u672a\u6765LLM\u754c\u9762\u5f00\u53d1\u5e94\u66f4\u6ce8\u91cd\u7528\u6237\u4e2d\u5fc3\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2508.19141", "pdf": "https://arxiv.org/pdf/2508.19141", "abs": "https://arxiv.org/abs/2508.19141", "authors": ["Federico Chiariotti", "Andrea Zanella"], "title": "A Theory of Goal-Oriented Medium Access: Protocol Design and Distributed Bandit Learning", "categories": ["cs.NI", "math.OC", "94A05, 68M12", "C.2.1; G.3; H.1.1"], "comment": "Submitted to IEEE INFOCOM 2026", "summary": "The Goal-oriented Communication (GoC) paradigm breaks the separation between\ncommunication and the content of the data, tailoring communication decisions to\nthe specific needs of the receiver and targeting application performance. While\nrecent studies show impressive encoding performance in point-to-point\nscenarios, the multi-node distributed scenario is still almost unexplored.\nMoreover, the few studies to investigate this consider a centralized\ncollision-free approach, where a central scheduler decides the transmission\norder of the nodes. In this work, we address the Goal-oriented Multiple Access\n(GoMA) problem, in which multiple intelligent agents must coordinate to share a\nwireless channel and avoid mutual interference. We propose a theoretical\nframework for the analysis and optimization of distributed GoMA, serving as a\nfirst step towards its complete characterization. We prove that the problem is\nnon-convex and may admit multiple Nash Equilibrium (NE) solutions. We provide a\ncharacterization of each node's best response to others' strategies and propose\nan optimization approach that provably reaches one such NE, outperforming\ncentralized approaches by up to 100% while also reducing energy consumption. We\nalso design a distributed learning algorithm that operates with limited\nfeedback and no prior knowledge.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u8282\u70b9\u5206\u5e03\u5f0f\u573a\u666f\u4e0b\u7684\u76ee\u6807\u5bfc\u5411\u591a\u5740\u63a5\u5165\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u6846\u67b6\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u95ee\u9898\u7684\u975e\u51f8\u6027\u548c\u5b58\u5728\u591a\u4e2a\u7eb3\u4ec0\u5747\u8861\u89e3\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0f\u5b66\u4e60\u7b97\u6cd5\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u591a\u8282\u70b9\u5206\u5e03\u5f0f\u573a\u666f\u4e0b\u7684\u76ee\u6807\u5bfc\u5411\u901a\u4fe1\u95ee\u9898\uff0c\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u4e2d\u96c6\u4e2d\u5f0f\u8c03\u5ea6\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u63d0\u5347\u901a\u4fe1\u6548\u7387\u548c\u80fd\u91cf\u5229\u7528\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u548c\u4f18\u5316\u5206\u5e03\u5f0f\u76ee\u6807\u5bfc\u5411\u591a\u5740\u63a5\u5165\u95ee\u9898\uff1b\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u5b66\u4e60\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u6709\u9650\u53cd\u9988\u548c\u65e0\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u8fd0\u884c\u3002", "result": "\u8bc1\u660e\u4e86\u95ee\u9898\u7684\u975e\u51f8\u6027\u548c\u591a\u7eb3\u4ec0\u5747\u8861\u89e3\u7684\u5b58\u5728\uff1b\u63d0\u51fa\u7684\u4f18\u5316\u65b9\u6cd5\u6bd4\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe100%\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u80fd\u8017\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u76ee\u6807\u5bfc\u5411\u591a\u5740\u63a5\u5165\u95ee\u9898\u7684\u5206\u5e03\u5f0f\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u7b97\u6cd5\u5b9e\u8df5\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.18376", "pdf": "https://arxiv.org/pdf/2508.18376", "abs": "https://arxiv.org/abs/2508.18376", "authors": ["Weilin Cai", "Le Qin", "Shwai He", "Junwei Cui", "Ang Li", "Jiayi Huang"], "title": "DualSparse-MoE: Coordinating Tensor/Neuron-Level Sparsity with Expert Partition and Reconstruction", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Mixture of Experts (MoE) has become a mainstream architecture for building\nLarge Language Models (LLMs) by reducing per-token computation while enabling\nmodel scaling. It can be viewed as partitioning a large Feed-Forward Network\n(FFN) at the tensor level into fine-grained sub-FFNs, or experts, and\nactivating only a sparse subset for each input. While this sparsity improves\nefficiency, MoE still faces substantial challenges due to their massive\ncomputational scale and unpredictable activation patterns.\n  To enable efficient MoE deployment, we identify dual sparsity at the tensor\nand neuron levels in pre-trained MoE modules as a key factor for both accuracy\nand efficiency. Unlike prior work that increases tensor-level sparsity through\nfiner-grained expert design during pre-training, we introduce post-training\nexpert partitioning to induce such sparsity without retraining. This preserves\nthe mathematical consistency of model transformations and enhances both\nefficiency and accuracy in subsequent fine-tuning and inference. Building upon\nthis, we propose DualSparse-MoE, an inference system that integrates dynamic\ntensor-level computation dropping with static neuron-level reconstruction to\ndeliver significant efficiency gains with minimal accuracy loss.\n  Experimental results show that enforcing an approximate 25% drop rate with\nour approach reduces average accuracy by only 0.08%-0.28% across three\nprevailing MoE models, while nearly all degrees of computation dropping\nconsistently yield proportional computational speedups. Furthermore,\nincorporating load-imbalance awareness into expert parallelism achieves a 1.41x\nMoE module speedup with just 0.5% average accuracy degradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDualSparse-MoE\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u52a8\u6001\u5f20\u91cf\u7ea7\u8ba1\u7b97\u4e22\u5f03\u548c\u9759\u6001\u795e\u7ecf\u5143\u7ea7\u91cd\u5efa\uff0c\u663e\u8457\u63d0\u9ad8\u4e86MoE\u6a21\u578b\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "MoE\u67b6\u6784\u867d\u7136\u901a\u8fc7\u7a00\u758f\u6fc0\u6d3b\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u4ecd\u9762\u4e34\u5927\u89c4\u6a21\u8ba1\u7b97\u548c\u4e0d\u53ef\u9884\u6d4b\u6fc0\u6d3b\u6a21\u5f0f\u7684\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u53cc\u7a00\u758f\u6027\uff08\u5f20\u91cf\u548c\u795e\u7ecf\u5143\u7ea7\u522b\uff09\u4f18\u5316MoE\u90e8\u7f72\u3002", "method": "\u5f15\u5165\u8bad\u7ec3\u540e\u4e13\u5bb6\u5212\u5206\u6280\u672f\uff0c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u8bf1\u5bfc\u7a00\u758f\u6027\u3002\u7ed3\u5408\u52a8\u6001\u5f20\u91cf\u7ea7\u8ba1\u7b97\u4e22\u5f03\u548c\u9759\u6001\u795e\u7ecf\u5143\u7ea7\u91cd\u5efa\uff0c\u6784\u5efaDualSparse-MoE\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e22\u5f0325%\u7684\u8ba1\u7b97\u4ec5\u5bfc\u81f40.08%-0.28%\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u800c\u8ba1\u7b97\u901f\u5ea6\u6210\u6bd4\u4f8b\u63d0\u5347\u3002\u8d1f\u8f7d\u5747\u8861\u4f18\u5316\u8fdb\u4e00\u6b65\u5b9e\u73b01.41\u500d\u7684\u6a21\u5757\u52a0\u901f\u3002", "conclusion": "DualSparse-MoE\u5728\u4fdd\u8bc1\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347MoE\u6a21\u578b\u7684\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21LLMs\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2508.18485", "pdf": "https://arxiv.org/pdf/2508.18485", "abs": "https://arxiv.org/abs/2508.18485", "authors": ["Peter T. Breuer"], "title": "An 8- and 12-bit block AES cipher", "categories": ["cs.CR", "cs.DS", "cs.SE", "E.3; F.2.1"], "comment": "This \"research note\" of mine from 2013 has been requested so often\n  from me over the years, along with requests for a way to cite it properly,\n  that I think it's appropriate to put it out on the web in a citeable archive.\n  Arxiv, step up", "summary": "Because it is so unusual, or hard to find, or expository, a truly tiny 8- or\n12-bit block AES (Rijndael) cipher is documented here, along with Java source\ncode.", "AI": {"tldr": "\u672c\u6587\u8bb0\u5f55\u4e86\u4e00\u79cd\u7f55\u89c1\u76848\u4f4d\u621612\u4f4d\u5757AES\uff08Rijndael\uff09\u5bc6\u7801\uff0c\u5e76\u63d0\u4f9b\u4e86Java\u6e90\u4ee3\u7801\u3002", "motivation": "\u7531\u4e8e\u8fd9\u79cd\u5fae\u5c0f\u5757\u7684AES\u5bc6\u7801\u975e\u5e38\u7f55\u89c1\u4e14\u96be\u4ee5\u627e\u5230\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6587\u6863\u548c\u4ee3\u7801\u7684\u65b9\u5f0f\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u5b9e\u73b0\u5e76\u8be6\u7ec6\u63cf\u8ff0\u4e86\u4e00\u79cd8\u4f4d\u621612\u4f4d\u5757\u7684AES\uff08Rijndael\uff09\u5bc6\u7801\uff0c\u5e76\u63d0\u4f9b\u4e86Java\u6e90\u4ee3\u7801\u4f5c\u4e3a\u53c2\u8003\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u5e76\u5c55\u793a\u4e86\u4e00\u79cd\u975e\u6807\u51c6\u7684\u5fae\u5c0f\u5757AES\u5bc6\u7801\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u8d44\u6e90\u3002", "conclusion": "\u672c\u6587\u4e3a\u7814\u7a76\u975e\u6807\u51c6\u5757\u5927\u5c0f\u7684AES\u5bc6\u7801\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6599\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u4e86\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2508.18875", "pdf": "https://arxiv.org/pdf/2508.18875", "abs": "https://arxiv.org/abs/2508.18875", "authors": ["Laurie Gale", "Sue Sentance"], "title": "PRIMMDebug: A Debugging Teaching Aid For Secondary Students", "categories": ["cs.HC"], "comment": "12 pages, 8 figures", "summary": "Debugging is often a challenging and infuriating experience for secondary\nschool students learning their first text-based programming language. Many\nstudents resort to ineffective debugging strategies, making success with\nsolving errors unlikely and emotional distress common. Developing tools that\nencourage students to adopt a more systematic and reflective approach to\ndebugging is therefore an important, but lacking, area of research. This paper\npresents PRIMMDebug, a debugging teaching aid for secondary school students\nlearning text-based programming. The aid consists of an online tool that takes\nstudents through the steps of a systematic debugging process based on PRIMM, a\nframework for teaching programming. The tool promotes a reflective approach to\ndebugging by heavily encouraging students to articulate their thoughts\nthroughout the PRIMMDebug process while simultaneously limiting their ability\nto run and edit code. To evaluate the tool, a set of students from four\nsecondary schools were taught with PRIMMDebug over several lessons. Survey\nresults and log data analysis show that students were generally reluctant to\nengage with the systematicity and reflection that the tool encourages. Given\nthat related work on systematic debugging has reported similar challenges, we\nend by considering how these approaches could be refined to help more students\nbenefit from them.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86PRIMMDebug\uff0c\u4e00\u79cd\u5e2e\u52a9\u4e2d\u5b66\u751f\u5b66\u4e60\u6587\u672c\u7f16\u7a0b\u7684\u8c03\u8bd5\u8f85\u52a9\u5de5\u5177\uff0c\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u5316\u548c\u53cd\u601d\u6027\u65b9\u6cd5\u6539\u5584\u8c03\u8bd5\u6548\u679c\uff0c\u4f46\u5b66\u751f\u5bf9\u6b64\u65b9\u6cd5\u7684\u63a5\u53d7\u5ea6\u8f83\u4f4e\u3002", "motivation": "\u4e2d\u5b66\u751f\u5728\u5b66\u4e60\u6587\u672c\u7f16\u7a0b\u65f6\u5e38\u56e0\u8c03\u8bd5\u56f0\u96be\u800c\u4ea7\u751f\u60c5\u611f\u56f0\u6270\uff0c\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u7cfb\u7edf\u6027\uff0c\u4fc3\u4f7f\u5f00\u53d1PRIMMDebug\u4ee5\u63d0\u5347\u8c03\u8bd5\u6548\u7387\u3002", "method": "PRIMMDebug\u662f\u4e00\u4e2a\u57fa\u4e8ePRIMM\u6846\u67b6\u7684\u5728\u7ebf\u5de5\u5177\uff0c\u901a\u8fc7\u9650\u5236\u4ee3\u7801\u7f16\u8f91\u548c\u8fd0\u884c\uff0c\u9f13\u52b1\u5b66\u751f\u7cfb\u7edf\u6027\u3001\u53cd\u601d\u6027\u5730\u8c03\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5b66\u751f\u5bf9\u5de5\u5177\u5021\u5bfc\u7684\u7cfb\u7edf\u6027\u548c\u53cd\u601d\u6027\u65b9\u6cd5\u63a5\u53d7\u5ea6\u4e0d\u9ad8\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u5b9e\u7528\u6027\u3002", "conclusion": "PRIMMDebug\u867d\u63d0\u51fa\u6709\u6548\u6846\u67b6\uff0c\u4f46\u9700\u8c03\u6574\u4ee5\u9002\u5e94\u5b66\u751f\u9700\u6c42\uff0c\u4ee5\u6269\u5927\u5176\u5e94\u7528\u6548\u679c\u3002"}}
{"id": "2508.18328", "pdf": "https://arxiv.org/pdf/2508.18328", "abs": "https://arxiv.org/abs/2508.18328", "authors": ["Masudul Hasan Masud Bhuiyan", "Matteo Varvello", "Yasir Zaki", "Cristian-Alexandru Staicu"], "title": "Not All Visitors are Bilingual: A Measurement Study of the Multilingual Web from an Accessibility Perspective", "categories": ["cs.CL", "cs.CY", "cs.NI"], "comment": "6 pages, 6 figures", "summary": "English is the predominant language on the web, powering nearly half of the\nworld's top ten million websites. Support for multilingual content is\nnevertheless growing, with many websites increasingly combining English with\nregional or native languages in both visible content and hidden metadata. This\nmultilingualism introduces significant barriers for users with visual\nimpairments, as assistive technologies like screen readers frequently lack\nrobust support for non-Latin scripts and misrender or mispronounce non-English\ntext, compounding accessibility challenges across diverse linguistic contexts.\nYet, large-scale studies of this issue have been limited by the lack of\ncomprehensive datasets on multilingual web content. To address this gap, we\nintroduce LangCrUX, the first large-scale dataset of 120,000 popular websites\nacross 12 languages that primarily use non-Latin scripts. Leveraging this\ndataset, we conduct a systematic analysis of multilingual web accessibility and\nuncover widespread neglect of accessibility hints. We find that these hints\noften fail to reflect the language diversity of visible content, reducing the\neffectiveness of screen readers and limiting web accessibility. We finally\npropose Kizuki, a language-aware automated accessibility testing extension to\naccount for the limited utility of language-inconsistent accessibility hints.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86LangCrUX\u6570\u636e\u96c6\uff0c\u5206\u6790\u4e86\u591a\u8bed\u8a00\u7f51\u9875\u65e0\u969c\u788d\u95ee\u9898\uff0c\u5e76\u63d0\u51faKizuki\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u591a\u8bed\u8a00\u7f51\u9875\u5bf9\u89c6\u89c9\u969c\u788d\u7528\u6237\u9020\u6210\u6311\u6218\uff0c\u4f46\u7f3a\u4e4f\u5927\u89c4\u6a21\u7814\u7a76\u6570\u636e\u3002", "method": "\u4f7f\u7528LangCrUX\u6570\u636e\u96c6\uff0812\u79cd\u8bed\u8a00\u768412\u4e07\u4e2a\u7f51\u7ad9\uff09\uff0c\u7cfb\u7edf\u5206\u6790\u65e0\u969c\u788d\u63d0\u793a\u7684\u8bed\u8a00\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u53d1\u73b0\u65e0\u969c\u788d\u63d0\u793a\u672a\u53cd\u6620\u5185\u5bb9\u8bed\u8a00\u591a\u6837\u6027\uff0c\u964d\u4f4e\u4e86\u5c4f\u5e55\u9605\u8bfb\u5668\u6548\u679c\u3002", "conclusion": "\u63d0\u51faKizuki\u6269\u5c55\u4ee5\u6539\u5584\u591a\u8bed\u8a00\u7f51\u9875\u65e0\u969c\u788d\u6d4b\u8bd5\u3002"}}
{"id": "2508.18588", "pdf": "https://arxiv.org/pdf/2508.18588", "abs": "https://arxiv.org/abs/2508.18588", "authors": ["Jingkai He", "Tianjian Li", "Erhu Feng", "Dong Du", "Qian Liu", "Tao Liu", "Yubin Xia", "Haibo Chen"], "title": "History Rhymes: Accelerating LLM Reinforcement Learning with RhymeRL", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "With the rapid advancement of large language models (LLMs), reinforcement\nlearning (RL) has emerged as a pivotal methodology for enhancing the reasoning\ncapabilities of LLMs. Unlike traditional pre-training approaches, RL\nencompasses multiple stages: rollout, reward, and training, which necessitates\ncollaboration among various worker types. However, current RL systems continue\nto grapple with substantial GPU underutilization, due to two primary factors:\n(1) The rollout stage dominates the overall RL process due to test-time\nscaling; (2) Imbalances in rollout lengths (within the same batch) result in\nGPU bubbles. While prior solutions like asynchronous execution and truncation\noffer partial relief, they may compromise training accuracy for efficiency.\n  Our key insight stems from a previously overlooked observation: rollout\nresponses exhibit remarkable similarity across adjacent training epochs. Based\non the insight, we introduce RhymeRL, an LLM RL system designed to accelerate\nRL training with two key innovations. First, to enhance rollout generation, we\npresent HistoSpec, a speculative decoding inference engine that utilizes the\nsimilarity of historical rollout token sequences to obtain accurate drafts.\nSecond, to tackle rollout bubbles, we introduce HistoPipe, a two-tier\nscheduling strategy that leverages the similarity of historical rollout\ndistributions to balance workload among rollout workers. We have evaluated\nRhymeRL within a real production environment, demonstrating scalability from\ndozens to thousands of GPUs. Experimental results demonstrate that RhymeRL\nachieves a 2.6x performance improvement over existing methods, without\ncompromising accuracy or modifying the RL paradigm.", "AI": {"tldr": "RhymeRL\u901a\u8fc7\u5229\u7528\u5386\u53f2\u751f\u6210\u7684\u76f8\u4f3c\u6027\u4f18\u5316RL\u8bad\u7ec3\uff0c\u63d0\u51fa\u4e86\u4e24\u9879\u521b\u65b0\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86GPU\u5229\u7528\u7387\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u5f53\u524dRL\u7cfb\u7edf\u5728LLM\u8bad\u7ec3\u4e2d\u5b58\u5728GPU\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u751f\u6210\u9636\u6bb5\u5360\u4e3b\u5bfc\u548c\u6279\u6b21\u957f\u5ea6\u4e0d\u5747\u5bfc\u81f4\u7684\u7a7a\u95f2\u3002\u9700\u8981\u4e00\u79cd\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86RhymeRL\u7cfb\u7edf\uff0c\u5305\u542bHistoSpec\uff08\u57fa\u4e8e\u5386\u53f2\u751f\u6210\u76f8\u4f3c\u6027\u7684\u63a8\u6d4b\u89e3\u7801\u5f15\u64ce\uff09\u548cHistoPipe\uff08\u5229\u7528\u5386\u53f2\u5206\u5e03\u76f8\u4f3c\u6027\u7684\u8c03\u5ea6\u7b56\u7565\uff09\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eRhymeRL\u5728\u771f\u5b9e\u751f\u4ea7\u73af\u5883\u4e2d\u53ef\u6269\u5c55\u81f3\u6570\u5343GPU\uff0c\u6027\u80fd\u63d0\u53472.6\u500d\uff0c\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "conclusion": "RhymeRL\u901a\u8fc7\u9ad8\u6548\u5229\u7528\u5386\u53f2\u6570\u636e\u7684\u76f8\u4f3c\u6027\uff0c\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u7684GPU\u5229\u7528\u7387\u95ee\u9898\uff0c\u4e3aLLM\u63a8\u7406\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2508.19219", "pdf": "https://arxiv.org/pdf/2508.19219", "abs": "https://arxiv.org/abs/2508.19219", "authors": ["Faezeh Dehghan Tarzjani", "Mostafa Salehi"], "title": "An Efficient Lightweight Blockchain for Decentralized IoT", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "The Internet of Things (IoT) is applied in various fields, and the number of\nphysical devices connected to the IoT is increasingly growing. There are\nsignificant challenges to the IoT's growth and development, mainly due to the\ncentralized nature and large-scale IoT networks. The emphasis on the\ndecentralization of IoT's architecture can overcome challenges to IoT's\ncapabilities. A promising decentralized platform for IoT is blockchain. Owing\nto IoT devices' limited resources, traditional consensus algorithms such as PoW\nand PoS in the blockchain are computationally expensive. Therefore, the PoA\nconsensus algorithm is proposed in the blockchain consensus network for IoT.\nThe PoA selects the validator as Turn-based selection (TBS) that needs\noptimization and faces system reliability, energy consumption, latency, and low\nscalability. We propose an efficient, lightweight blockchain for decentralizing\nIoT architecture by using virtualization and clustering to increase\nproductivity and scalability to address these issues. We also introduce a novel\nPoA based on the Weight-Based-Selection (WBS) method for validators to validate\ntransactions and add them to the blockchain. By simulation, we evaluated the\nperformance of our proposed WBS method as opposed to TBS. The results show\nreduced energy consumption, and response time, and increased throughput.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u7269\u8054\u7f51\uff08IoT\uff09\u7f51\u7edc\u4e2d\u7684\u6311\u6218\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7PoA\u5171\u8bc6\u7b97\u6cd5\uff08WBS\u65b9\u6cd5\uff09\u4ee5\u4f18\u5316\u80fd\u8017\u548c\u6027\u80fd\u3002", "motivation": "\u7269\u8054\u7f51\u7684\u96c6\u4e2d\u5f0f\u67b6\u6784\u548c\u5927\u89c4\u6a21\u7f51\u7edc\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u53bb\u4e2d\u5fc3\u5316\u89e3\u51b3\u65b9\u6848\u3002\u4f20\u7edf\u533a\u5757\u94fe\u5171\u8bc6\u7b97\u6cd5\uff08\u5982PoW\u3001PoS\uff09\u5bf9\u8d44\u6e90\u6709\u9650\u7684IoT\u8bbe\u5907\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6743\u91cd\u7684PoA\u5171\u8bc6\u7b97\u6cd5\uff08WBS\uff09\uff0c\u7ed3\u5408\u865a\u62df\u5316\u548c\u96c6\u7fa4\u6280\u672f\uff0c\u63d0\u5347\u751f\u4ea7\u529b\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u6bd4\u8f83\uff0cWBS\u65b9\u6cd5\u6bd4\u4f20\u7edfTBS\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u548c\u54cd\u5e94\u65f6\u95f4\uff0c\u5e76\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u3002", "conclusion": "\u5229\u7528WBS\u65b9\u6cd5\u7684\u8f7b\u91cf\u7ea7\u533a\u5757\u94fe\u67b6\u6784\u80fd\u6709\u6548\u89e3\u51b3IoT\u4e2d\u7684\u53bb\u4e2d\u5fc3\u5316\u9700\u6c42\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.18918", "pdf": "https://arxiv.org/pdf/2508.18918", "abs": "https://arxiv.org/abs/2508.18918", "authors": ["Youngwon Choi", "Donghyuk Jung", "Hwayeon Kim"], "title": "DESAMO: A Device for Elder-Friendly Smart Homes Powered by Embedded LLM with Audio Modality", "categories": ["cs.HC", "cs.SD", "eess.AS"], "comment": "2 pages, 2 figures. Accepted for presentation as a UIST 2025 Poster", "summary": "We present DESAMO, an on-device smart home system for elder-friendly use\npowered by Audio LLM, that supports natural and private interactions. While\nconventional voice assistants rely on ASR-based pipelines or ASR-LLM cascades,\noften struggling with the unclear speech common among elderly users and unable\nto handle non-speech audio, DESAMO leverages an Audio LLM to process raw audio\ninput directly, enabling a robust understanding of user intent and critical\nevents, such as falls or calls for help.", "AI": {"tldr": "DESAMO\u662f\u4e00\u4e2a\u57fa\u4e8e\u97f3\u9891LLM\u7684\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\uff0c\u4e13\u4e3a\u8001\u5e74\u4eba\u8bbe\u8ba1\uff0c\u652f\u6301\u81ea\u7136\u4e14\u79c1\u5bc6\u7684\u4ea4\u4e92\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8bed\u97f3\u52a9\u624b\u5728\u5904\u7406\u8001\u5e74\u4eba\u4e0d\u6e05\u6670\u8bed\u97f3\u53ca\u975e\u8bed\u97f3\u97f3\u9891\u65f6\u7684\u4e0d\u8db3\u3002", "method": "\u5229\u7528\u97f3\u9891LLM\u76f4\u63a5\u5904\u7406\u539f\u59cb\u97f3\u9891\u8f93\u5165\uff0c\u65e0\u9700\u4f9d\u8d56ASR\u6216ASR-LLM\u7ea7\u8054\u3002", "result": "\u80fd\u66f4\u9c81\u68d2\u5730\u7406\u89e3\u7528\u6237\u610f\u56fe\u53ca\u5173\u952e\u4e8b\u4ef6\uff08\u5982\u6454\u5012\u6216\u547c\u6551\uff09\u3002", "conclusion": "DESAMO\u4e3a\u8001\u5e74\u4eba\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u667a\u80fd\u5bb6\u5c45\u4ea4\u4e92\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19009", "pdf": "https://arxiv.org/pdf/2508.19009", "abs": "https://arxiv.org/abs/2508.19009", "authors": ["Md Anwar Hossen", "Fatema Siddika", "Wensheng Zhang", "Anuj Sharma", "Ali Jannesari"], "title": "FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": "12 pages, 6 figures", "summary": "Heterogeneous Federated Learning (HFL) has gained attention for its ability\nto accommodate diverse models and heterogeneous data across clients.\nPrototype-based HFL methods emerge as a promising solution to address\nstatistical heterogeneity and privacy challenges, paving the way for new\nadvancements in HFL research. This method focuses on sharing only\nclass-representative prototypes among heterogeneous clients. However, these\nprototypes are often aggregated on the server using weighted averaging, leading\nto sub-optimal global knowledge; these cause the shrinking of aggregated\nprototypes, which negatively affects the model performance in scenarios when\nmodels are heterogeneous and data distributions are extremely non-IID. We\npropose FedProtoKD in a Heterogeneous Federated Learning setting, using an\nenhanced dual-knowledge distillation mechanism to improve the system\nperformance with clients' logits and prototype feature representation. We aim\nto resolve the prototype margin-shrinking problem using a contrastive\nlearning-based trainable server prototype by leveraging a class-wise adaptive\nprototype margin. Furthermore, we assess the importance of public samples using\nthe closeness of the sample's prototype to its class representative prototypes,\nwhich enhances learning performance. FedProtoKD achieved average improvements\nof 1.13% up to 34.13% accuracy across various settings and significantly\noutperforms existing state-of-the-art HFL methods.", "AI": {"tldr": "FedProtoKD \u662f\u4e00\u79cd\u57fa\u4e8e\u53cc\u77e5\u8bc6\u84b8\u998f\u673a\u5236\u7684\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u53ef\u8bad\u7ec3\u7684\u670d\u52a1\u5668\u539f\u578b\u89e3\u51b3\u4e86\u539f\u578b\u7f29\u5c0f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u539f\u578b\u805a\u5408\u65f6\u4f7f\u7528\u52a0\u6743\u5e73\u5747\uff0c\u5bfc\u81f4\u539f\u578b\u7f29\u5c0f\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u5f02\u6784\u6a21\u578b\u548c\u6781\u7aef\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51fa FedProtoKD\uff0c\u5229\u7528\u53cc\u77e5\u8bc6\u84b8\u998f\u673a\u5236\uff08\u5ba2\u6237\u7aef logits \u548c\u539f\u578b\u7279\u5f81\u8868\u793a\uff09\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u53ef\u8bad\u7ec3\u7684\u670d\u52a1\u5668\u539f\u578b\uff0c\u6539\u8fdb\u539f\u578b\u805a\u5408\u6548\u679c\u3002", "result": "\u5728\u591a\u79cd\u8bbe\u5b9a\u4e0b\uff0cFedProtoKD \u7684\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u4e86 1.13% \u5230 34.13%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "FedProtoKD \u901a\u8fc7\u6539\u8fdb\u539f\u578b\u805a\u5408\u548c\u77e5\u8bc6\u84b8\u998f\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2508.18919", "pdf": "https://arxiv.org/pdf/2508.18919", "abs": "https://arxiv.org/abs/2508.18919", "authors": ["Edyta Bogucka", "Marios Constantinides", "Sanja \u0160\u0107epanovi\u0107", "Daniele Quercia"], "title": "Impact Assessment Card: Communicating Risks and Benefits of AI Uses", "categories": ["cs.HC", "K.4.1, K.4.2, H.5.3, D.2.9", "K.4.1; K.4.2; H.5.3; D.2.9"], "comment": "42 pages, 14 figures", "summary": "Communicating the risks and benefits of AI is important for regulation and\npublic understanding. Yet current methods such as technical reports often\nexclude people without technical expertise. Drawing on HCI research, we\ndeveloped an Impact Assessment Card to present this information more clearly.\nWe held three focus groups with a total of 12 participants who helped identify\ndesign requirements and create early versions of the card. We then tested a\nrefined version in an online study with 235 participants, including AI\ndevelopers, compliance experts, and members of the public selected to reflect\nthe U.S. population by age, sex, and race. Participants used either the card or\na full impact assessment report to write an email supporting or opposing a\nproposed AI system. The card led to faster task completion and higher-quality\nemails across all groups. We discuss how design choices can improve\naccessibility and support AI governance. Examples of cards are available at:\nhttps://social-dynamics.net/ai-risks/impact-card/.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3a\u2018\u5f71\u54cd\u8bc4\u4f30\u5361\u2019\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u66f4\u6e05\u6670\u5730\u5411\u516c\u4f17\u4f20\u8fbeAI\u7684\u98ce\u9669\u548c\u6536\u76ca\uff0c\u6bd4\u4f20\u7edf\u6280\u672f\u62a5\u544a\u66f4\u9ad8\u6548\u548c\u6613\u7406\u89e3\u3002", "motivation": "\u5f53\u524d\u7684\u6280\u672f\u62a5\u544a\u5f80\u5f80\u6392\u65a5\u975e\u6280\u672f\u80cc\u666f\u7684\u516c\u4f17\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6613\u7406\u89e3\u7684\u6c9f\u901a\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u4e0e12\u540d\u53c2\u4e0e\u8005\u7684\u7126\u70b9\u5c0f\u7ec4\u4f1a\u8bae\u8bbe\u8ba1\u4e86\u521d\u7248\u5361\u7247\uff0c\u968f\u540e\u5728235\u540d\u591a\u6837\u5316\u53c2\u4e0e\u8005\u7684\u5728\u7ebf\u7814\u7a76\u4e2d\u6d4b\u8bd5\u4e86\u4f18\u5316\u7248\u3002", "result": "\u4f7f\u7528\u5361\u7247\u6bd4\u4f20\u7edf\u62a5\u544a\u66f4\u5feb\u5b8c\u6210\u4efb\u52a1\uff0c\u4e14\u751f\u6210\u7684\u90ae\u4ef6\u8d28\u91cf\u66f4\u4f18\u3002", "conclusion": "\u8bbe\u8ba1\u9009\u62e9\u53ef\u4ee5\u63d0\u5347\u4fe1\u606f\u7684\u53ef\u7406\u89e3\u6027\uff0c\u652f\u6301AI\u6cbb\u7406\u3002"}}
{"id": "2508.19121", "pdf": "https://arxiv.org/pdf/2508.19121", "abs": "https://arxiv.org/abs/2508.19121", "authors": ["Xiaolin He", "Zirui Li", "Xinwei Wang", "Riender Happee", "Meng Wang"], "title": "Reading minds on the road: decoding perceived risk in automated vehicles through 140K+ ratings", "categories": ["cs.HC"], "comment": null, "summary": "Perceived risk in automated vehicles (AVs) can create the very danger that\nautomation is meant to prevent: a frightened rider may hesitate when seconds\nmatter, misjudge hazards, or disengage. However, measuring how perceived risk\nevolves in real time during driving remains challenging, leaving a gap in\ndecoding such hidden psychological states. Here, we present a novel method to\ntime-continuously measure and decode perceived risk. We conducted a controlled\nexperiment where 2,164 participants viewed high-fidelity videos of common\nhighway driving scenes and provided 141,628 discrete safety ratings. Through\ncontinuous-signal reconstruction of the discrete ratings, we obtained 236 hours\nof time-continuous perceived risk data - the largest perceived risk dataset to\ndate. Leveraging this dataset, we trained deep neural networks that predict\nmoment-by-moment perceived risk from vehicle kinematics with a mean relative\nerror below $3\\%$. Explainable AI analysis uncovers which factors determine\nperceived risk in real time. Our findings demonstrate a new paradigm for\nquantifying dynamic passenger experience and psychological constructs in real\ntime. These findings can guide the design of AVs and other machines that\noperate in close proximity to people, adjusting behaviour before trust erodes,\nand help realise automation's benefits in transport, healthcare, and service\nrobotics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u6d4b\u91cf\u548c\u89e3\u7801\u81ea\u52a8\u5316\u8f66\u8f86(AVs)\u4e2d\u611f\u77e5\u98ce\u9669\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u6784\u79bb\u6563\u5b89\u5168\u8bc4\u5206\u83b7\u5f97\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u611f\u77e5\u98ce\u9669\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u5b9e\u65f6\u611f\u77e5\u98ce\u9669\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e2d\u7684\u611f\u77e5\u98ce\u9669\u53ef\u80fd\u5bfc\u81f4\u5371\u9669\u884c\u4e3a\uff0c\u4f46\u76ee\u524d\u5b9e\u65f6\u6d4b\u91cf\u8fd9\u79cd\u5fc3\u7406\u72b6\u6001\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u901a\u8fc7\u9ad8\u4fdd\u771f\u89c6\u9891\u5b9e\u9a8c\u6536\u96c6\u53c2\u4e0e\u8005\u7684\u79bb\u6563\u5b89\u5168\u8bc4\u5206\uff0c\u91cd\u6784\u4e3a\u8fde\u7eed\u4fe1\u53f7\uff0c\u5e76\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4ece\u8f66\u8f86\u8fd0\u52a8\u5b66\u9884\u6d4b\u611f\u77e5\u98ce\u9669\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86236\u5c0f\u65f6\u7684\u8fde\u7eed\u611f\u77e5\u98ce\u9669\u6570\u636e\u96c6\uff0c\u9884\u6d4b\u6a21\u578b\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e3%\u3002\u53ef\u89e3\u91ca\u6027\u5206\u6790\u63ed\u793a\u4e86\u5b9e\u65f6\u611f\u77e5\u98ce\u9669\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u65f6\u91cf\u5316\u4e58\u5ba2\u5fc3\u7406\u72b6\u6001\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u81ea\u52a8\u9a7e\u9a76\u548c\u5176\u4ed6\u673a\u5668\u7684\u8bbe\u8ba1\uff0c\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u6280\u672f\u7684\u6f5c\u5728\u4f18\u52bf\u3002"}}
{"id": "2508.19230", "pdf": "https://arxiv.org/pdf/2508.19230", "abs": "https://arxiv.org/abs/2508.19230", "authors": ["Kaushall Senthil Nathan", "Jieun Lee", "Derrick M. Wang", "Geneva M. Smith", "Eugene Kukshinov", "Daniel Harley", "Lennart E. Nacke"], "title": "Beyond Competitive Gaming: How Casual Players Evaluate and Respond to Teammate Performance", "categories": ["cs.HC"], "comment": "7 pages, 1 figure, CHI Play 2025 Conference", "summary": "Teammate performance evaluation fundamentally shapes intervention design in\nvideo games. However, our current understanding stems primarily from\ncompetitive E-Sports contexts where individual performance directly impacts\noutcomes. This research addresses whether performance evaluation mechanisms and\nbehavioural responses identified in competitive games generalize to casual\ncooperative games. We investigated how casual players evaluate teammate\ncompetence and respond behaviourally in a controlled between-subjects\nexperiment (N=23). We manipulated confederate performance in Overcooked 2,\ncombining observations, NASA TLX self-reports, and interviews. We present two\nkey findings. (1) Observations revealed frustration behaviours completely\nabsent in self-report data. Thus, these instruments assess fundamentally\ndistinct constructs. (2) Participants consistently evaluated teammate\nperformance through relative comparison rather than absolute metrics. This\ncontradicts task-performance operationalizations dominant in competitive gaming\nresearch. Hence, performance evaluation frameworks from competitive contexts\ncannot be directly applied to casual cooperative games. We provide empirical\nevidence that performance evaluation in casual games requires a comparative\noperationalization.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u4f11\u95f2\u5408\u4f5c\u6e38\u620f\u4e2d\u73a9\u5bb6\u5982\u4f55\u8bc4\u4f30\u961f\u53cb\u8868\u73b0\uff0c\u53d1\u73b0\u4e0e\u7ade\u4e89\u6027\u6e38\u620f\u4e0d\u540c\uff0c\u4f11\u95f2\u73a9\u5bb6\u66f4\u503e\u5411\u4e8e\u76f8\u5bf9\u6bd4\u8f83\u800c\u975e\u7edd\u5bf9\u6307\u6807\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u9a8c\u8bc1\u7ade\u4e89\u6027\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u8bc4\u4f30\u673a\u5236\u548c\u884c\u4e3a\u53cd\u5e94\u662f\u5426\u9002\u7528\u4e8e\u4f11\u95f2\u5408\u4f5c\u6e38\u620f\u3002", "method": "\u901a\u8fc7\u64cd\u63a7\u300aOvercooked 2\u300b\u4e2d\u961f\u53cb\u8868\u73b0\uff0c\u7ed3\u5408\u89c2\u5bdf\u3001NASA TLX\u81ea\u8bc4\u548c\u8bbf\u8c08\uff0c\u8fdb\u884c\u53d7\u8bd5\u8005\u95f4\u5b9e\u9a8c\uff08N=23\uff09\u3002", "result": "\u7814\u7a76\u663e\u793a\uff1a(1)\u89c2\u5bdf\u6570\u636e\u63ed\u793a\u4e86\u81ea\u8bc4\u4e2d\u672a\u4f53\u73b0\u7684\u632b\u8d25\u884c\u4e3a\uff1b(2)\u73a9\u5bb6\u901a\u8fc7\u76f8\u5bf9\u6bd4\u8f83\u800c\u975e\u7edd\u5bf9\u6307\u6807\u8bc4\u4f30\u961f\u53cb\u8868\u73b0\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\u7ade\u4e89\u6027\u6e38\u620f\u7684\u8868\u73b0\u8bc4\u4f30\u6846\u67b6\u4e0d\u9002\u7528\u4e8e\u4f11\u95f2\u5408\u4f5c\u6e38\u620f\uff0c\u4f11\u95f2\u6e38\u620f\u9700\u8981\u57fa\u4e8e\u6bd4\u8f83\u7684\u64cd\u4f5c\u5316\u65b9\u6cd5\u3002"}}
{"id": "2508.18288", "pdf": "https://arxiv.org/pdf/2508.18288", "abs": "https://arxiv.org/abs/2508.18288", "authors": ["Jay L. Cunningham", "Adinawa Adjagbodjou", "Jeffrey Basoah", "Jainaba Jawara", "Kowe Kadoma", "Aaleyah Lewis"], "title": "Toward Responsible ASR for African American English Speakers: A Scoping Review of Bias and Equity in Speech Technology", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": "10 pages, 9 Pages (References and Appendices). The archival version\n  has been accepted to AAAI (AIES 2025) without the extended Appendices. This\n  extended version includes Appendices", "summary": "This scoping literature review examines how fairness, bias, and equity are\nconceptualized and operationalized in Automatic Speech Recognition (ASR) and\nadjacent speech and language technologies (SLT) for African American English\n(AAE) speakers and other linguistically diverse communities. Drawing from 44\npeer-reviewed publications across Human-Computer Interaction (HCI), Machine\nLearning/Natural Language Processing (ML/NLP), and Sociolinguistics, we\nidentify four major areas of inquiry: (1) how researchers understand\nASR-related harms; (2) inclusive data practices spanning collection, curation,\nannotation, and model training; (3) methodological and theoretical approaches\nto linguistic inclusion; and (4) emerging practices and design recommendations\nfor more equitable systems. While technical fairness interventions are growing,\nour review highlights a critical gap in governance-centered approaches that\nforeground community agency, linguistic justice, and participatory\naccountability. We propose a governance-centered ASR lifecycle as an emergent\ninterdisciplinary framework for responsible ASR development and offer\nimplications for researchers, practitioners, and policymakers seeking to\naddress language marginalization in speech AI systems.", "AI": {"tldr": "\u8be5\u8303\u56f4\u7efc\u8ff0\u63a2\u8ba8\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u53ca\u76f8\u5173\u6280\u672f\u4e2d\u516c\u5e73\u6027\u3001\u504f\u89c1\u548c\u516c\u6b63\u6027\u5bf9\u975e\u88d4\u7f8e\u56fd\u82f1\u8bed\uff08AAE\uff09\u4f7f\u7528\u8005\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u6cbb\u7406\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3ASR\u6280\u672f\u5bf9\u8bed\u8a00\u591a\u6837\u6027\u7684\u5ffd\u89c6\u53ca\u5bf9AAE\u7b49\u8bed\u8a00\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u901a\u8fc744\u7bc7\u8de8\u5b66\u79d1\u6587\u732e\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u56db\u4e2a\u4e3b\u8981\u7814\u7a76\u65b9\u5411\u3002", "result": "\u53d1\u73b0\u6280\u672f\u516c\u5e73\u5e72\u9884\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u6cbb\u7406\u4e3a\u4e2d\u5fc3\u7684ASR\u5f00\u53d1\u751f\u547d\u5468\u671f\u6846\u67b6\u3002", "conclusion": "\u9700\u66f4\u591a\u793e\u533a\u53c2\u4e0e\u548c\u8bed\u8a00\u5b66\u516c\u6b63\u7684\u6cbb\u7406\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u516c\u5e73\u7684ASR\u7cfb\u7edf\u3002"}}
{"id": "2508.18301", "pdf": "https://arxiv.org/pdf/2508.18301", "abs": "https://arxiv.org/abs/2508.18301", "authors": ["Md Sabbir Ahmed", "Nova Ahmed"], "title": "A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach", "categories": ["cs.LG", "cs.CY", "cs.HC"], "comment": null, "summary": "Background: Existing robust, pervasive device-based systems developed in\nrecent years to detect depression require data collected over a long period and\nmay not be effective in cases where early detection is crucial.\n  Objective: Our main objective was to develop a minimalistic system to\nidentify depression using data retrieved in the fastest possible time.\n  Methods: We developed a fast tool that retrieves the past 7 days' app usage\ndata in 1 second (mean 0.31, SD 1.10 seconds). A total of 100 students from\nBangladesh participated in our study, and our tool collected their app usage\ndata. To identify depressed and nondepressed students, we developed a diverse\nset of ML models. We selected important features using the stable approach,\nalong with 3 main types of feature selection (FS) approaches.\n  Results: Leveraging only the app usage data retrieved in 1 second, our light\ngradient boosting machine model used the important features selected by the\nstable FS approach and correctly identified 82.4% (n=42) of depressed students\n(precision=75%, F1-score=78.5%). Moreover, after comprehensive exploration, we\npresented a parsimonious stacking model where around 5 features selected by the\nall-relevant FS approach Boruta were used in each iteration of validation and\nshowed a maximum precision of 77.4% (balanced accuracy=77.9%). A SHAP analysis\nof our best models presented behavioral markers that were related to\ndepression.\n  Conclusions: Due to our system's fast and minimalistic nature, it may make a\nworthwhile contribution to identifying depression in underdeveloped and\ndeveloping regions. In addition, our detailed discussion about the implication\nof our findings can facilitate the development of less resource-intensive\nsystems to better understand students who are depressed.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5feb\u901f\u68c0\u6d4b\u6291\u90c1\u7684\u7cfb\u7edf\uff0c\u5229\u75287\u5929\u7684\u5e94\u7528\u4f7f\u7528\u6570\u636e\uff0c\u57281\u79d2\u5185\u5b8c\u6210\u5206\u6790\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe82.4%\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u9700\u8981\u957f\u65f6\u95f4\u6570\u636e\u6536\u96c6\uff0c\u65e0\u6cd5\u6ee1\u8db3\u65e9\u671f\u6291\u90c1\u68c0\u6d4b\u7684\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u5feb\u901f\u5de5\u5177\u6536\u96c67\u5929\u5e94\u7528\u4f7f\u7528\u6570\u636e\uff0c\u4f7f\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002", "result": "\u57fa\u4e8e1\u79d2\u5185\u83b7\u53d6\u7684\u6570\u636e\uff0c\u6a21\u578b\u8bc6\u522b\u6291\u90c1\u5b66\u751f\u7684\u51c6\u786e\u7387\u8fbe82.4%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u7684\u5feb\u901f\u548c\u7b80\u7ea6\u7279\u6027\u4f7f\u5176\u9002\u7528\u4e8e\u6b20\u53d1\u8fbe\u5730\u533a\uff0c\u5e76\u4e3a\u5f00\u53d1\u4f4e\u8d44\u6e90\u7cfb\u7edf\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2508.18406", "pdf": "https://arxiv.org/pdf/2508.18406", "abs": "https://arxiv.org/abs/2508.18406", "authors": ["Ryan Hare", "Ying Tang"], "title": "Toward Generalized Autonomous Agents: A Neuro-Symbolic AI Framework for Integrating Social and Technical Support in Education", "categories": ["cs.MA", "cs.AI", "cs.HC"], "comment": "Preprint. This work has been submitted to the IEEE for possible\n  publication. In review for IEEE's Systems, Man, and Cybernetics Magazine. 8\n  pages, 3 figures. arxiv abstract has been shortened as the magazine format\n  uses a long-form abstract", "summary": "One of the enduring challenges in education is how to empower students to\ntake ownership of their learning by setting meaningful goals, tracking their\nprogress, and adapting their strategies when faced with setbacks. Research has\nshown that this form of leaner-centered learning is best cultivated through\nstructured, supportive environments that promote guided practice, scaffolded\ninquiry, and collaborative dialogue. In response, educational efforts have\nincreasingly embraced artificial-intelligence (AI)-powered digital learning\nenvironments, ranging from educational apps and virtual labs to serious games.\nRecent advances in large language models (LLMs) and neuro-symbolic systems,\nmeanwhile, offer a transformative opportunity to reimagine how support is\ndelivered in digital learning environments. LLMs are enabling socially\ninteractive learning experiences and scalable, cross-domain learning support\nthat can adapt instructional strategies across varied subjects and contexts. In\nparallel, neuro-symbolic AI provides new avenues for designing these agents\nthat are not only adaptive but also scalable across domains. Based on these\nremarks, this paper presents a multi-agent, neuro-symbolic framework designed\nto resolve the aforementioned challenges. The framework assigns distinct\npedagogical roles to specialized agents: an RL-based 'tutor' agent provides\nauthoritative, non-verbal scaffolding, while a proactive, LLM-powered 'peer'\nagent facilitates the social dimensions of learning. While prior work has\nexplored such agents in isolation, our framework's novelty lies in unifying\nthem through a central educational ontology. Through case studies in both\ncollege-level and middle school settings, we demonstrate the framework's\nadaptability across domains. We conclude by outlining key insights and future\ndirections for advancing AI-driven learning environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4ee3\u7406\u3001\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u2018\u5bfc\u5e08\u2019\u4ee3\u7406\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u2018\u540c\u4f34\u2019\u4ee3\u7406\uff0c\u4ee5\u89e3\u51b3\u5b66\u751f\u81ea\u4e3b\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u8de8\u9886\u57df\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u6559\u80b2\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u662f\u5982\u4f55\u8ba9\u5b66\u751f\u81ea\u4e3b\u8bbe\u5b9a\u76ee\u6807\u3001\u8ddf\u8e2a\u8fdb\u5ea6\u5e76\u8c03\u6574\u7b56\u7565\u3002\u4eba\u5de5\u667a\u80fd\uff08\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\u548c\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff09\u7684\u8fdb\u6b65\u4e3a\u6570\u5b57\u5316\u5b66\u4e60\u73af\u5883\u63d0\u4f9b\u4e86\u65b0\u7684\u652f\u6301\u65b9\u5f0f\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u4ee3\u7406\u3001\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5305\u542b\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u2018\u5bfc\u5e08\u2019\u4ee3\u7406\u548c\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u2018\u540c\u4f34\u2019\u4ee3\u7406\uff0c\u901a\u8fc7\u4e2d\u5fc3\u6559\u80b2\u672c\u4f53\u7edf\u4e00\u5b83\u4eec\u7684\u89d2\u8272\u3002", "result": "\u6846\u67b6\u5728\u5927\u5b66\u751f\u548c\u4e2d\u5b66\u751f\u73af\u5883\u4e2d\u6210\u529f\u5c55\u793a\u4e86\u8de8\u9886\u57df\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u5e76\u5c55\u671b\u4e86\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u5b66\u4e60\u73af\u5883\u7684\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2508.18492", "pdf": "https://arxiv.org/pdf/2508.18492", "abs": "https://arxiv.org/abs/2508.18492", "authors": ["Aparajita Marathe", "Anne Marie Piper"], "title": "The Accessibility Paradox: How Blind and Low Vision Employees Experience and Negotiate Accessibility in the Technology Industry", "categories": ["cs.CY", "cs.HC"], "comment": "Article to be published in CSCW 2025 November edition", "summary": "Many technology companies aim to improve access and inclusion not only by\nmaking their products accessible but also by bringing people with disabilities\ninto the tech workforce. We know less about how accessibility is experienced\nand negotiated by disabled workers within these organizations. Through\ninterviews with 20 BLV workers across various tech companies, we uncover a\npersistent misalignment between organizational attempts at accessibility and\nthe current realities of these employees. We introduce the concept of the\naccessibility paradox, which we define as the inherent tension between the\nproductivity- and profit-driven nature of tech companies and their desire to\nhire and retain disabled workers. Focusing on the experiences of BLV workers,\nwe show how the accessibility paradox manifests in their everyday workplace\ninteractions, including digital infrastructure, accommodations processes and\npolicies, ability assumptions, and competing priorities. We offer\nrecommendations for future research and practice to understand and improve\nworkplace accessibility and inclusion.", "AI": {"tldr": "\u79d1\u6280\u516c\u53f8\u8bd5\u56fe\u901a\u8fc7\u4ea7\u54c1\u53ef\u8bbf\u95ee\u6027\u548c\u96c7\u4f63\u6b8b\u75be\u5458\u5de5\u6539\u5584\u5305\u5bb9\u6027\uff0c\u4f46\u7814\u7a76\u4e2d\u53d1\u73b0\u7ec4\u7ec7\u52aa\u529b\u4e0e\u5b9e\u9645\u4f53\u9a8c\u5b58\u5728\u77db\u76fe\uff0c\u79f0\u4e3a\u2018\u53ef\u8bbf\u95ee\u6027\u6096\u8bba\u2019\u3002", "motivation": "\u63a2\u8ba8\u79d1\u6280\u516c\u53f8\u4e2d\u6b8b\u75be\u5458\u5de5\uff08\u5c24\u5176\u662f\u89c6\u89c9\u969c\u788d\u8005\uff09\u7684\u53ef\u8bbf\u95ee\u6027\u4f53\u9a8c\u4e0e\u7ec4\u7ec7\u52aa\u529b\u4e4b\u95f4\u7684\u4e0d\u5bf9\u7b49\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u5bf920\u540d\u89c6\u89c9\u969c\u788d\u5458\u5de5\u7684\u8bbf\u8c08\uff0c\u5206\u6790\u4ed6\u4eec\u5728\u804c\u573a\u4e2d\u7684\u65e5\u5e38\u4f53\u9a8c\u3002", "result": "\u63ed\u793a\u4e86\u53ef\u8bbf\u95ee\u6027\u6096\u8bba\uff0c\u5373\u516c\u53f8\u8ffd\u6c42\u751f\u4ea7\u529b\u4e0e\u5229\u6da6\u7684\u76ee\u6807\u4e0e\u96c7\u4f63\u6b8b\u75be\u5458\u5de5\u7684\u77db\u76fe\uff0c\u8868\u73b0\u5728\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u3001\u653f\u7b56\u3001\u80fd\u529b\u5047\u8bbe\u7b49\u65b9\u9762\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u548c\u5b9e\u8df5\u4e2d\u6539\u5584\u804c\u573a\u53ef\u8bbf\u95ee\u6027\u4e0e\u5305\u5bb9\u6027\u7684\u5efa\u8bae\u3002"}}
{"id": "2508.19163", "pdf": "https://arxiv.org/pdf/2508.19163", "abs": "https://arxiv.org/abs/2508.19163", "authors": ["Ernest Lim", "Yajie Vera He", "Jared Joselowitz", "Kate Preston", "Mohita Chowdhury", "Louis Williams", "Aisling Higham", "Katrina Mason", "Mariane Melo", "Tom Lawton", "Yan Jia", "Ibrahim Habli"], "title": "MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation", "categories": ["cs.AI", "cs.HC", "cs.MA", "68T50, 68T42, 92C50, 68Q60", "I.2.0; J.3"], "comment": "36 pages, 16 figures", "summary": "Despite the growing use of large language models (LLMs) in clinical dialogue\nsystems, existing evaluations focus on task completion or fluency, offering\nlittle insight into the behavioral and risk management requirements essential\nfor safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion\nfRamework for safe Interactions and conteXtual clinical conversational\nevaluation), a structured, extensible framework for safety-oriented evaluation\nof clinical dialogue agents.\n  MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical\nscenarios, expected system behaviors and failure modes derived through\nstructured safety engineering methods; (2) BehvJudge, an LLM-based evaluator\nfor detecting safety-relevant dialogue failures, validated against expert\nclinician annotations; and (3) PatBot, a simulated patient agent capable of\nproducing diverse, scenario-conditioned responses, evaluated for realism and\nbehavioral fidelity with human factors expertise, and a patient-preference\nstudy.\n  Across three experiments, we show that MATRIX enables systematic, scalable\nsafety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard\ndetection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded\nassessment of 240 dialogues. We also conducted one of the first realism\nanalyses of LLM-based patient simulation, showing that PatBot reliably\nsimulates realistic patient behavior in quantitative and qualitative\nevaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking\nfive LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios\nand 10 clinical domains.\n  MATRIX is the first framework to unify structured safety engineering with\nscalable, validated conversational AI evaluation, enabling regulator-aligned\nsafety auditing. We release all evaluation tools, prompts, structured\nscenarios, and datasets.", "AI": {"tldr": "MATRIX \u662f\u4e00\u4e2a\u9762\u5411\u5b89\u5168\u8bc4\u4f30\u7684\u4e34\u5e8a\u5bf9\u8bdd\u7cfb\u7edf\u6846\u67b6\uff0c\u6574\u5408\u4e86\u5b89\u5168\u5de5\u7a0b\u65b9\u6cd5\u548c\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u591a\u5173\u6ce8\u4efb\u52a1\u5b8c\u6210\u5ea6\u6216\u6d41\u7545\u6027\uff0c\u7f3a\u4e4f\u5bf9\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u884c\u4e3a\u7684\u6df1\u5165\u5206\u6790\u3002", "method": "MATRIX \u7ed3\u5408\u4e86\u5b89\u5168\u573a\u666f\u5206\u7c7b\u3001\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u5668\uff08BehvJudge\uff09\u548c\u6a21\u62df\u60a3\u8005\u4ee3\u7406\uff08PatBot\uff09\u3002", "result": "\u5b9e\u9a8c\u663e\u793aMATRIX\u5728\u5371\u9669\u68c0\u6d4b\u548c\u60a3\u8005\u6a21\u62df\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u4eba\u5de5\u8bc4\u4f30\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u591a\u4e2aLLM\u4ee3\u7406\u7684\u8bc4\u4f30\u3002", "conclusion": "MATRIX \u9996\u6b21\u5c06\u5b89\u5168\u5de5\u7a0b\u4e0e\u53ef\u6269\u5c55\u7684\u5bf9\u8bddAI\u8bc4\u4f30\u7ed3\u5408\uff0c\u4e3a\u5b89\u5168\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5de5\u5177\u3002"}}
{"id": "2508.19227", "pdf": "https://arxiv.org/pdf/2508.19227", "abs": "https://arxiv.org/abs/2508.19227", "authors": ["Jiaqi Chen", "Yanzhe Zhang", "Yutong Zhang", "Yijia Shao", "Diyi Yang"], "title": "Generative Interfaces for Language Models", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Preprint", "summary": "Large language models (LLMs) are increasingly seen as assistants, copilots,\nand consultants, capable of supporting a wide range of tasks through natural\nconversation. However, most systems remain constrained by a linear\nrequest-response format that often makes interactions inefficient in\nmulti-turn, information-dense, and exploratory tasks. To address these\nlimitations, we propose Generative Interfaces for Language Models, a paradigm\nin which LLMs respond to user queries by proactively generating user interfaces\n(UIs) that enable more adaptive and interactive engagement. Our framework\nleverages structured interface-specific representations and iterative\nrefinements to translate user queries into task-specific UIs. For systematic\nevaluation, we introduce a multidimensional assessment framework that compares\ngenerative interfaces with traditional chat-based ones across diverse tasks,\ninteraction patterns, and query types, capturing functional, interactive, and\nemotional aspects of user experience. Results show that generative interfaces\nconsistently outperform conversational ones, with humans preferring them in\nover 70% of cases. These findings clarify when and why users favor generative\ninterfaces, paving the way for future advancements in human-AI interaction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u754c\u9762\uff08Generative Interfaces for Language Models\uff09\uff0c\u901a\u8fc7\u4e3b\u52a8\u751f\u6210\u7528\u6237\u754c\u9762\u6765\u63d0\u5347\u4ea4\u4e92\u6548\u7387\uff0c\u4f18\u4e8e\u4f20\u7edf\u804a\u5929\u754c\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u7684\u7ebf\u6027\u8bf7\u6c42-\u54cd\u5e94\u683c\u5f0f\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u5229\u7528\u7ed3\u6784\u5316\u754c\u9762\u8868\u793a\u548c\u8fed\u4ee3\u4f18\u5316\uff0c\u5c06\u7528\u6237\u67e5\u8be2\u8f6c\u5316\u4e3a\u4efb\u52a1\u7279\u5b9a\u754c\u9762\u3002", "result": "\u751f\u6210\u5f0f\u754c\u9762\u572870%\u4ee5\u4e0a\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u4f20\u7edf\u804a\u5929\u754c\u9762\uff0c\u7528\u6237\u66f4\u504f\u597d\u6b64\u7c7b\u4ea4\u4e92\u65b9\u5f0f\u3002", "conclusion": "\u751f\u6210\u5f0f\u754c\u9762\u4e3a\u4eba\u7c7b\u4e0eAI\u4ea4\u4e92\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
