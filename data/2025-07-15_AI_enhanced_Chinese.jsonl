{"id": "2507.08943", "pdf": "https://arxiv.org/pdf/2507.08943", "abs": "https://arxiv.org/abs/2507.08943", "authors": ["Pedro Lopes", "Paola Accioly", "Paulo Borba", "Vitor Menezes"], "title": "Choosing the Right Git Workflow: A Comparative Analysis of Trunk-based vs. Branch-based Approaches", "categories": ["cs.SE", "D.2.7"], "comment": "11 pages with 3 figures", "summary": "Git has become one of the most widely used version control systems today.\nAmong its distinguishing features, its ability to easily and quickly create\nbranches stands out, allowing teams to customize their workflows. In this\ncontext, various formats of collaborative development workflows using Git have\nemerged and gained popularity among software engineers. We can categorize such\nworkflows into two main types: branch-based workflows and trunk-based\nworkflows. Branch-based workflows typically define a set of remote branches\nwith well-defined objectives, such as feature branches, a branch for feature\nintegration, and a main branch. The goal is to migrate changes from the most\nisolated branch to the main one shared by all as the code matures. In this\ncategory, GitFlow stands out as the most popular example. In contrast,\ntrunk-based workflows have a single remote branch where developers integrate\ntheir changes directly. In this range of options, choosing a workflow that\nmaximizes team productivity while promoting software quality becomes a\nnon-trivial task. Despite discussions on forums, social networks, and blogs,\nfew scientific articles have explored this topic. In this work, we provide\nevidence on how Brazilian developers work with Git workflows and what factors\nfavor or hinder the use of each model. To this end, we conducted\nsemi-structured interviews and a survey with software developers. Our results\nindicate that trunk-based development favors fast-paced projects with\nexperienced and smaller teams, while branch-based development suits less\nexperienced and larger teams better, despite posing management challenges.", "AI": {"tldr": "\u7efc\u8ff0Git\u5de5\u4f5c\u6d41\uff08\u5206\u652f\u4e0e\u4e3b\u5e72\u6a21\u5f0f\uff09\u5728\u5df4\u897f\u5f00\u53d1\u8005\u4e2d\u7684\u5e94\u7528\u53ca\u9002\u7528\u573a\u666f\u3002", "motivation": "\u63a2\u7d22Git\u5de5\u4f5c\u6d41\uff08\u5206\u652f\u4e0e\u4e3b\u5e72\u6a21\u5f0f\uff09\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u53ca\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u548c\u8c03\u67e5\u95ee\u5377\u6536\u96c6\u6570\u636e\u3002", "result": "\u4e3b\u5e72\u6a21\u5f0f\u9002\u5408\u5feb\u901f\u5f00\u53d1\u3001\u5c0f\u89c4\u6a21\u4e14\u7ecf\u9a8c\u4e30\u5bcc\u7684\u56e2\u961f\uff1b\u5206\u652f\u6a21\u5f0f\u9002\u5408\u5927\u89c4\u6a21\u4e14\u7ecf\u9a8c\u4e0d\u8db3\u7684\u56e2\u961f\u3002", "conclusion": "\u56e2\u961f\u89c4\u6a21\u4e0e\u7ecf\u9a8c\u662f\u9009\u62e9Git\u5de5\u4f5c\u6d41\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2507.08992", "pdf": "https://arxiv.org/pdf/2507.08992", "abs": "https://arxiv.org/abs/2507.08992", "authors": ["Abdelhalim Dahou", "Ansgar Scherp", "Sebastian Kurten", "Brigitte Mathiak", "Madhu Chauhan"], "title": "Semantic Source Code Segmentation using Small and Large Language Models", "categories": ["cs.SE", "cs.CL", "cs.PL"], "comment": "18 pages, 4 figures", "summary": "Source code segmentation, dividing code into functionally coherent segments,\nis crucial for knowledge retrieval and maintenance in software development.\nWhile enabling efficient navigation and comprehension of large codebases,\nmanual and syntactic analysis approaches have become impractical as\nrepositories grow, especially for low-resource languages like R and their\nresearch domains (e.g., social sciences, psychology).This paper introduces an\nautomated, domain-specific approach for research R code segmentation using\nLarge and Small Language Models (LLMs/SLMs). It presents two novel approaches\nand a human-annotated dataset, StatCodeSeg. We explore two distinct approaches:\nline-by-line analysis with context and range-based segment determination. We\nexperiment with LLMs and fine-tuned SLMs. To support the generalizability of\nour approaches, we also include experiments on Python code from the computer\nscience domain.Our results show that context-based line-by-line analysis is\nsuperior over range-based segmentation.Using smaller language models like\nCodeBERT and an encoder-only version of CodeT5+ are better than their LLM\ncounterparts. Most notably, these two best-performing models did not see R code\nduring pre-training versus the LLMs but were only fine-tuned on 4,130 lines of\nmanually annotated code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u3001\u9886\u57df\u7279\u5b9a\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u7814\u7a76R\u4ee3\u7801\u7684\u5206\u5272\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4e24\u79cd\u65b0\u65b9\u6cd5\u548c\u4e00\u4e2a\u4eba\u5de5\u6807\u6ce8\u7684\u6570\u636e\u96c6StatCodeSeg\u3002\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u9010\u884c\u5206\u6790\u4f18\u4e8e\u57fa\u4e8e\u8303\u56f4\u7684\u5212\u5206\uff0c\u4e14\u8f83\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5e93\u7684\u589e\u957f\uff0c\u5c24\u5176\u662f\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u5982R\u53ca\u5176\u7814\u7a76\u9886\u57df\uff08\u5982\u793e\u4f1a\u79d1\u5b66\u3001\u5fc3\u7406\u5b66\uff09\uff0c\u624b\u52a8\u548c\u57fa\u4e8e\u8bed\u6cd5\u5206\u6790\u7684\u65b9\u6cd5\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u5b9e\u73b0\u9ad8\u6548\u7684\u4ee3\u7801\u5206\u5272\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u9010\u884c\u5206\u6790\u548c\u57fa\u4e8e\u8303\u56f4\u7684\u6bb5\u5212\u5206\uff0c\u5e76\u4f7f\u7528\u5927\u578b\u548c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs/SLMs\uff09\u8fdb\u884c\u5b9e\u9a8c\u3002\u8fd8\u5f15\u5165\u4e86\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6StatCodeSeg\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u9010\u884c\u5206\u6790\u4f18\u4e8e\u57fa\u4e8e\u8303\u56f4\u7684\u5212\u5206\u3002\u5728\u6a21\u578b\u8868\u73b0\u4e0a\uff0c\u8f83\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\uff08\u5982CodeBERT\u548c\u7f16\u7801\u5668\u7248\u672c\u7684CodeT5+\uff09\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5c3d\u7ba1\u5b83\u4eec\u672a\u5728\u9884\u8bad\u7ec3\u4e2d\u4f7f\u7528R\u4ee3\u7801\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u5206\u5272\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5373\u4f7f\u9884\u8bad\u7ec3\u6570\u636e\u4e0d\u5305\u542b\u76ee\u6807\u8bed\u8a00\uff08R\u4ee3\u7801\uff09\uff0c\u4ec5\u901a\u8fc7\u5bf9\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u7684\u5fae\u8c03\u4e5f\u80fd\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2507.09023", "pdf": "https://arxiv.org/pdf/2507.09023", "abs": "https://arxiv.org/abs/2507.09023", "authors": ["Yao Fehlis", "Charles Crain", "Aidan Jensen", "Michael Watson", "James Juhasz", "Paul Mandel", "Betty Liu", "Shawn Mahon", "Daren Wilson", "Nick Lynch-Jonely", "Ben Leedom", "David Fuller"], "title": "Accelerating Drug Discovery Through Agentic AI: A Multi-Agent Approach to Laboratory Automation in the DMTA Cycle", "categories": ["cs.SE", "cs.AI", "cs.MA"], "comment": null, "summary": "The pharmaceutical industry faces unprecedented challenges in drug discovery,\nwith traditional approaches struggling to meet modern therapeutic development\ndemands. This paper introduces a novel AI framework, Tippy, that transforms\nlaboratory automation through specialized AI agents operating within the\nDesign-Make-Test-Analyze (DMTA) cycle. Our multi-agent system employs five\nspecialized agents - Supervisor, Molecule, Lab, Analysis, and Report, with\nSafety Guardrail oversight - each designed to excel in specific phases of the\ndrug discovery pipeline. Tippy represents the first production-ready\nimplementation of specialized AI agents for automating the DMTA cycle,\nproviding a concrete example of how AI can transform laboratory workflows. By\nleveraging autonomous AI agents that reason, plan, and collaborate, we\ndemonstrate how Tippy accelerates DMTA cycles while maintaining scientific\nrigor essential for pharmaceutical research. The system shows significant\nimprovements in workflow efficiency, decision-making speed, and\ncross-disciplinary coordination, offering a new paradigm for AI-assisted drug\ndiscovery.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aTippy\u7684\u65b0\u578bAI\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684AI\u4ee3\u7406\u5728\u836f\u7269\u53d1\u73b0\u7684DMTA\u5468\u671f\u4e2d\u5b9e\u73b0\u81ea\u52a8\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u5de5\u4f5c\u6548\u7387\u548c\u51b3\u7b56\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u836f\u7269\u53d1\u73b0\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u73b0\u4ee3\u6cbb\u7597\u5f00\u53d1\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684AI\u6280\u672f\u6765\u6539\u8fdb\u5b9e\u9a8c\u5ba4\u81ea\u52a8\u5316\u548c\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "Tippy\u91c7\u7528\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5305\u62ec\u4e94\u79cd\u4e13\u95e8\u4ee3\u7406\uff08Supervisor\u3001Molecule\u3001Lab\u3001Analysis\u3001Report\uff09\u548cSafety Guardrail\u76d1\u7763\uff0c\u5404\u81ea\u8d1f\u8d23\u836f\u7269\u53d1\u73b0\u7ba1\u9053\u7684\u4e0d\u540c\u9636\u6bb5\u3002", "result": "Tippy\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\u3001\u51b3\u7b56\u901f\u5ea6\u548c\u8de8\u5b66\u79d1\u534f\u4f5c\uff0c\u4e3aAI\u8f85\u52a9\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002", "conclusion": "Tippy\u662f\u9996\u4e2a\u53ef\u7528\u4e8e\u751f\u4ea7\u7684\u4e13\u95e8AI\u4ee3\u7406\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86AI\u5982\u4f55\u901a\u8fc7\u81ea\u4e3b\u4ee3\u7406\u52a0\u901fDMTA\u5468\u671f\uff0c\u540c\u65f6\u4fdd\u6301\u79d1\u5b66\u4e25\u8c28\u6027\u3002"}}
{"id": "2507.09039", "pdf": "https://arxiv.org/pdf/2507.09039", "abs": "https://arxiv.org/abs/2507.09039", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "title": "Towards Extracting Software Requirements from App Reviews using Seq2seq Framework", "categories": ["cs.SE"], "comment": null, "summary": "Mobile app reviews are a large-scale data source for software improvements. A\nkey task in this context is effectively extracting requirements from app\nreviews to analyze the users' needs and support the software's evolution.\nRecent studies show that existing methods fail at this task since app reviews\nusually contain informal language, grammatical and spelling errors, and a large\namount of irrelevant information that might not have direct practical value for\ndevelopers. To address this, we propose a novel reformulation of requirements\nextraction as a Named Entity Recognition (NER) task based on the\nsequence-to-sequence (Seq2seq) generation approach. With this aim, we propose a\nSeq2seq framework, incorporating a BiLSTM encoder and an LSTM decoder, enhanced\nwith a self-attention mechanism, GloVe embeddings, and a CRF model. We\nevaluated our framework on two datasets: a manually annotated set of 1,000\nreviews (Dataset 1) and a crowdsourced set of 23,816 reviews (Dataset 2). The\nquantitative evaluation of our framework showed that it outperformed existing\nstate-of-the-art methods with an F1 score of 0.96 on Dataset 2, and achieved\ncomparable performance on Dataset 1 with an F1 score of 0.47.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e8f\u5217\u5230\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u4efb\u52a1\uff0c\u7528\u4e8e\u4ece\u79fb\u52a8\u5e94\u7528\u8bc4\u8bba\u4e2d\u63d0\u53d6\u9700\u6c42\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u56e0\u8bc4\u8bba\u4e2d\u5b58\u5728\u975e\u6b63\u5f0f\u8bed\u8a00\u3001\u8bed\u6cd5\u9519\u8bef\u548c\u65e0\u5173\u4fe1\u606f\u800c\u5931\u6548\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u79fb\u52a8\u5e94\u7528\u8bc4\u8bba\u65f6\uff0c\u7531\u4e8e\u8bc4\u8bba\u4e2d\u7684\u975e\u6b63\u5f0f\u8bed\u8a00\u3001\u8bed\u6cd5\u9519\u8bef\u548c\u5927\u91cf\u65e0\u5173\u4fe1\u606f\uff0c\u96be\u4ee5\u6709\u6548\u63d0\u53d6\u7528\u6237\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408BiLSTM\u7f16\u7801\u5668\u3001LSTM\u89e3\u7801\u5668\u3001\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3001GloVe\u5d4c\u5165\u548cCRF\u6a21\u578b\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6846\u67b6\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6846\u67b6\u5728\u5305\u542b23,816\u6761\u8bc4\u8bba\u7684\u6570\u636e\u96c62\u4e0a\u7684F1\u5206\u6570\u4e3a0.96\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u5728\u5305\u542b1,000\u6761\u8bc4\u8bba\u7684\u6570\u636e\u96c61\u4e0a\u7684F1\u5206\u6570\u4e3a0.47\uff0c\u8868\u73b0\u63a5\u8fd1\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4ece\u79fb\u52a8\u5e94\u7528\u8bc4\u8bba\u4e2d\u63d0\u53d6\u9700\u6c42\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.08836", "pdf": "https://arxiv.org/pdf/2507.08836", "abs": "https://arxiv.org/abs/2507.08836", "authors": ["Damien Fovet", "Shashank Chamoli", "Sarah Oury", "Srishti Singhal"], "title": "Accuracy and Consumption analysis from a compressed model by CompactifAI from Multiverse Computing", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "This study evaluates the performance of a compression method, called\nCompactifAI, developed by Multiverse Computing, applied to the large language\nmodel Llama 3.1 8B\\cite{llama}. The evaluation focused on model efficiency (in\nterms of energy consumption) and accuracy using respectively the frameworks\nCodecarbon\\cite{codecarbon} and Ragas\\cite{ragas}. A comparison was performed\nbetween the model compressed with\nCompactifAI\\cite{compactifai}\\cite{compactifai2} and its full-size version. Our\nfindings reveal that the compressed model using CompactifAI not only\nsignificantly reduced the computational resources but also maintained the model\naccuracy, making the model more efficient, scalable and cost-effective.", "AI": {"tldr": "CompactifAI\u538b\u7f29\u65b9\u6cd5\u5e94\u7528\u4e8eLlama 3.1 8B\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5e76\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u8bc4\u4f30CompactifAI\u538b\u7f29\u65b9\u6cd5\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6548\u7387\uff08\u80fd\u8017\uff09\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528Codecarbon\u548cRagas\u6846\u67b6\u5bf9\u6bd4\u538b\u7f29\u6a21\u578b\u4e0e\u5b8c\u6574\u6a21\u578b\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "result": "\u538b\u7f29\u6a21\u578b\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "CompactifAI\u4f7f\u6a21\u578b\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u3002"}}
{"id": "2507.09539", "pdf": "https://arxiv.org/pdf/2507.09539", "abs": "https://arxiv.org/abs/2507.09539", "authors": ["Anna Bolotina", "Christoph M. Kirsch", "Stefanie Muroya Lei", "Matthias Pleschinger"], "title": "Bounded Model Checking of RISC-V Machine Code with Context-Free-Language Ordered Binary Decision Diagrams", "categories": ["cs.PL"], "comment": null, "summary": "Symbolic execution is a powerful technique for analyzing the behavior of\nsoftware yet scalability remains a challenge due to state explosion in control\nand data flow. Existing tools typically aim at managing control flow\ninternally, often at the expense of completeness, while offloading reasoning\nover data flow to SMT solvers. Moreover, reasoning typically happens on source\ncode or intermediate representation level to leverage structural information,\nmaking machine code generation part of the trust base. We are interested in\nchanging the equation in two non-trivial ways: pushing reasoning down to\nmachine code level, and then offloading reasoning entirely into SMT solvers and\nother, possibly more efficient solver technology. In more abstract terms, we\nare asking if bit-precise reasoning technology can be made scalable on\nsoftware, and not just hardware. For this purpose, we developed two tools\ncalled rotor and bitme for model generation and bounded model checking,\nrespectively. We chose RISC-V restricted to integer arithmetic as modeling\ntarget for rotor since RISC-V integer semantics is essentially equivalent to\nestablished SMT semantics over bitvectors and arrays of bitvectors. While\nstate-of-the-art SMT solvers struggle in our experiments, we have evidence that\nthere is potential for improvement. To show the potential, we have slightly\ngeneralized and then implemented in bitme two types of binary decision diagrams\n(BDDs): algebraic decision diagrams (ADDs) and context-free-language ordered\nbinary decision diagrams (CFLOBDDs). Bitme uses BDDs to propagate program input\nthrough models, essentially generalizing constant propagation to domain\npropagation. SMT solvers only get involved when model input cannot be\npropagated, significanly speeding up SMT solving. We then study the impact on\nstate explosion of CFLOBDDs, which are potentially more scalable than ADDs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u5c06\u7b26\u53f7\u6267\u884c\u63a8\u7406\u5b8c\u5168\u4e0b\u653e\u81f3\u673a\u5668\u7801\u5c42\u9762\u5e76\u5229\u7528SMT\u6c42\u89e3\u5668\u548c\u5176\u4ed6\u9ad8\u6548\u6c42\u89e3\u6280\u672f\uff0c\u6765\u89e3\u51b3\u8f6f\u4ef6\u5206\u6790\u4e2d\u7684\u72b6\u6001\u7206\u70b8\u95ee\u9898\u3002\u4f5c\u8005\u5f00\u53d1\u4e86\u5de5\u5177rotor\u548cbitme\uff0c\u5206\u522b\u7528\u4e8e\u6a21\u578b\u751f\u6210\u548c\u6709\u754c\u6a21\u578b\u68c0\u67e5\uff0c\u5e76\u5c55\u793a\u4e86\u6539\u8fdb\u6f5c\u529b\u3002", "motivation": "\u7b26\u53f7\u6267\u884c\u5728\u8f6f\u4ef6\u884c\u4e3a\u5206\u6790\u4e2d\u5f3a\u5927\u4f46\u9762\u4e34\u72b6\u6001\u7206\u70b8\u7684\u6311\u6218\uff0c\u5c24\u5176\u5728\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\u7ba1\u7406\u4e0a\u3002\u73b0\u6709\u5de5\u5177\u901a\u5e38\u5728\u727a\u7272\u5b8c\u6574\u6027\u7684\u524d\u63d0\u4e0b\u7ba1\u7406\u63a7\u5236\u6d41\uff0c\u800c\u5c06\u6570\u636e\u6d41\u5206\u6790\u4ea4\u7ed9SMT\u6c42\u89e3\u5668\u3002\u4f5c\u8005\u5e0c\u671b\u6539\u53d8\u73b0\u72b6\uff0c\u5c06\u63a8\u7406\u4e0b\u653e\u5230\u673a\u5668\u7801\u5c42\u9762\u5e76\u5229\u7528\u66f4\u9ad8\u6548\u7684\u6c42\u89e3\u6280\u672f\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e24\u4e2a\u5de5\u5177\uff1arotor\u7528\u4e8e\u6a21\u578b\u751f\u6210\uff0cbitme\u7528\u4e8e\u6709\u754c\u6a21\u578b\u68c0\u67e5\u3002rotor\u4e13\u6ce8\u4e8eRISC-V\u6574\u6570\u8bed\u4e49\uff0c\u800cbitme\u5f15\u5165\u4e86\u4e24\u79cd\u4e8c\u8fdb\u5236\u51b3\u7b56\u56fe\uff08ADDs\u548cCFLOBDDs\uff09\u6765\u4f18\u5316\u8f93\u5165\u4f20\u64ad\uff0c\u51cf\u5c11SMT\u6c42\u89e3\u5668\u7684\u8d1f\u62c5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5c3d\u7ba1\u5f53\u524dSMT\u6c42\u89e3\u5668\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7bitme\u5de5\u5177\u5229\u7528BDDs\uff08\u5c24\u5176\u662fCFLOBDDs\uff09\u53ef\u4ee5\u663e\u8457\u52a0\u5feb\u6c42\u89e3\u901f\u5ea6\u5e76\u7f13\u89e3\u72b6\u6001\u7206\u70b8\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u6539\u8fdb\u6f5c\u529b\u3002", "conclusion": "\u8bba\u6587\u8868\u660e\uff0c\u901a\u8fc7\u5c06\u7b26\u53f7\u6267\u884c\u63a8\u7406\u5b8c\u5168\u4e0b\u653e\u81f3\u673a\u5668\u7801\u5c42\u9762\u5e76\u91c7\u7528\u9ad8\u6548\u6c42\u89e3\u6280\u672f\uff0c\u53ef\u4ee5\u63d0\u5347\u8f6f\u4ef6\u5206\u6790\u7684\u89c4\u6a21\u548c\u6548\u7387\uff0c\u5c24\u5176\u662f\u4f7f\u7528CFLOBDDs\u8fdb\u4e00\u6b65\u4f18\u5316\u72b6\u6001\u7ba1\u7406\u3002"}}
{"id": "2507.09094", "pdf": "https://arxiv.org/pdf/2507.09094", "abs": "https://arxiv.org/abs/2507.09094", "authors": ["Xiaoren Xu", "Hao Xu", "Dongyu Wei", "Walid Saad", "Mehdi Bennis", "Mingzhe Chen"], "title": "Transformer based Collaborative Reinforcement Learning for Fluid Antenna System (FAS)-enabled 3D UAV Positioning", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "In this paper, a novel Three dimensional (3D) positioning framework of fluid\nantenna system (FAS)-enabled unmanned aerial vehicles (UAVs) is developed. In\nthe proposed framework, a set of controlled UAVs cooperatively estimate the\nreal-time 3D position of a target UAV. Here, the active UAV transmits a\nmeasurement signal to the passive UAVs via the reflection from the target UAV.\nEach passive UAV estimates the distance of the active-target-passive UAV link\nand selects an antenna port to share the distance information with the base\nstation (BS) that calculates the real-time position of the target UAV. As the\ntarget UAV is moving due to its task operation, the controlled UAVs must\noptimize their trajectories and select optimal antenna port, aiming to estimate\nthe real-time position of the target UAV. We formulate this problem as an\noptimization problem to minimize the target UAV positioning error via\noptimizing the trajectories of all controlled UAVs and antenna port selection\nof passive UAVs. Here, an attention-based recurrent multi-agent reinforcement\nlearning (AR-MARL) scheme is proposed, which enables each controlled UAV to use\nthe local Q function to determine its trajectory and antenna port while\noptimizing the target UAV positioning performance without knowing the\ntrajectories and antenna port selections of other controlled UAVs. Different\nfrom current MARL methods, the proposed method uses a recurrent neural network\n(RNN) that incorporates historical state-action pairs of each controlled UAV,\nand an attention mechanism to analyze the importance of these historical\nstate-action pairs, thus improving the global Q function approximation accuracy\nand the target UAV positioning accuracy. Simulation results show that the\nproposed AR-MARL scheme can reduce the average positioning error by up to 17.5%\nand 58.5% compared to the VD-MARL scheme and the proposed method without FAS.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u578b\u76843D\u5b9a\u4f4d\u6846\u67b6\uff0c\u901a\u8fc7\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\uff08FAS\uff09\u548c\u65e0\u4eba\u673a\uff08UAV\uff09\u534f\u4f5c\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08AR-MARL\uff09\u4f18\u5316\u76ee\u6807\u65e0\u4eba\u673a\u7684\u5b9e\u65f6\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u4efb\u52a1\u6267\u884c\u4e2d\u9700\u8981\u5b9e\u65f6\u5b9a\u4f4d\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e0b\u7cbe\u5ea6\u4e0d\u8db3\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408FAS\u548c\u4f18\u5316\u7b97\u6cd5\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u5b9a\u4f4d\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u53d7\u63a7\u65e0\u4eba\u673a\u7684\u8f68\u8ff9\u548c\u5929\u7ebf\u7aef\u53e3\u9009\u62e9\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u7684\u5faa\u73af\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08AR-MARL\uff09\u6765\u4f30\u8ba1\u76ee\u6807\u65e0\u4eba\u673a\u7684\u5b9e\u65f6\u4f4d\u7f6e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cAR-MARL\u65b9\u6848\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff08VD-MARL\uff09\u548c\u65e0FAS\u7684\u65b9\u6cd5\u5206\u522b\u51cf\u5c11\u4e8617.5%\u548c58.5%\u7684\u5e73\u5747\u5b9a\u4f4d\u8bef\u5dee\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u76ee\u6807\u65e0\u4eba\u673a\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u8bc1\u660e\u4e86FAS\u548cAR-MARL\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.09647", "pdf": "https://arxiv.org/pdf/2507.09647", "abs": "https://arxiv.org/abs/2507.09647", "authors": ["Peican Zhu", "Yubo Jing", "Le Cheng", "Keke Tang", "Yangming Guo"], "title": "KEN: Knowledge Augmentation and Emotion Guidance Network for Multimodal Fake News Detection", "categories": ["cs.MM", "cs.AI"], "comment": "Accepted by ACM MM 2025", "summary": "In recent years, the rampant spread of misinformation on social media has\nmade accurate detection of multimodal fake news a critical research focus.\nHowever, previous research has not adequately understood the semantics of\nimages, and models struggle to discern news authenticity with limited textual\ninformation. Meanwhile, treating all emotional types of news uniformly without\ntailored approaches further leads to performance degradation. Therefore, we\npropose a novel Knowledge Augmentation and Emotion Guidance Network (KEN). On\nthe one hand, we effectively leverage LVLM's powerful semantic understanding\nand extensive world knowledge. For images, the generated captions provide a\ncomprehensive understanding of image content and scenes, while for text, the\nretrieved evidence helps break the information silos caused by the closed and\nlimited text and context. On the other hand, we consider inter-class\ndifferences between different emotional types of news through balanced\nlearning, achieving fine-grained modeling of the relationship between emotional\ntypes and authenticity. Extensive experiments on two real-world datasets\ndemonstrate the superiority of our KEN.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aKEN\u7684\u65b0\u7f51\u7edc\uff0c\u901a\u8fc7\u77e5\u8bc6\u589e\u5f3a\u548c\u60c5\u611f\u5f15\u5bfc\uff0c\u7ed3\u5408LVLM\u7684\u8bed\u4e49\u7406\u89e3\u548c\u4e16\u754c\u77e5\u8bc6\uff0c\u4f18\u5316\u591a\u6a21\u6001\u5047\u65b0\u95fb\u68c0\u6d4b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u865a\u5047\u4fe1\u606f\u6cdb\u6ee5\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u672a\u80fd\u5145\u5206\u7406\u89e3\u56fe\u50cf\u8bed\u4e49\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u60c5\u611f\u7c7b\u578b\u7684\u9488\u5bf9\u6027\u5904\u7406\uff0c\u5bfc\u81f4\u68c0\u6d4b\u6027\u80fd\u4e0d\u8db3\u3002", "method": "\u5229\u7528LVLM\u7684\u8bed\u4e49\u7406\u89e3\u548c\u4e16\u754c\u77e5\u8bc6\uff0c\u751f\u6210\u56fe\u50cf\u63cf\u8ff0\u5e76\u68c0\u7d22\u6587\u672c\u8bc1\u636e\uff1b\u901a\u8fc7\u5e73\u8861\u5b66\u4e60\u8003\u8651\u4e0d\u540c\u60c5\u611f\u7c7b\u578b\u7684\u7c7b\u95f4\u5dee\u5f02\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5efa\u6a21\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86KEN\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "KEN\u901a\u8fc7\u7ed3\u5408\u77e5\u8bc6\u589e\u5f3a\u548c\u60c5\u611f\u5f15\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5047\u65b0\u95fb\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09140", "pdf": "https://arxiv.org/pdf/2507.09140", "abs": "https://arxiv.org/abs/2507.09140", "authors": ["Chuang Chen", "Xiaoxuan Xie", "Yongming Zhang", "Tianyu Zhang", "Haoran Xie"], "title": "Interactive Drawing Guidance for Anime Illustrations with Diffusion Model", "categories": ["cs.GR"], "comment": "9 pages, 7 figures. In proceedings of NICOGRAPH International 2025", "summary": "Creating high-quality anime illustrations presents notable challenges,\nparticularly for beginners, due to the intricate styles and fine details\ninherent in anime art. We present an interactive drawing guidance system\nspecifically designed for anime illustrations to address this issue. It offers\nreal-time guidance to help users refine their work and streamline the creative\nprocess. Our system is built upon the StreamDiffusion pipeline to deliver\nreal-time drawing assistance. We fine-tune Stable Diffusion with LoRA to\nsynthesize anime style RGB images from user-provided hand-drawn sketches and\nprompts. Leveraging the Informative Drawings model, we transform these RGB\nimages into rough sketches, which are further refined into structured guidance\nsketches using a custom-designed optimizer. The proposed system offers precise,\nreal-time guidance aligned with the creative intent of the user, significantly\nenhancing both the efficiency and accuracy of the drawing process. To assess\nthe effectiveness of our approach, we conducted a user study, gathering\nempirical feedback on both system performance and interface usability.", "AI": {"tldr": "\u4e3a\u5e2e\u52a9\u521d\u5b66\u8005\u89e3\u51b3\u52a8\u6f2b\u63d2\u753b\u7ed8\u5236\u4e2d\u7684\u9ad8\u96be\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u65f6\u4ea4\u4e92\u5f0f\u7ed8\u56fe\u6307\u5bfc\u7cfb\u7edf\uff0c\u57fa\u4e8eStreamDiffusion\u548cStable Diffusion\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u521b\u4f5c\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u52a8\u6f2b\u63d2\u753b\u7684\u590d\u6742\u98ce\u683c\u548c\u7cbe\u7ec6\u7ec6\u8282\u5bf9\u521d\u5b66\u8005\u6784\u6210\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u63d0\u4f9b\u5b9e\u65f6\u6307\u5bfc\u7684\u7cfb\u7edf\u6765\u7b80\u5316\u521b\u4f5c\u8fc7\u7a0b\u3002", "method": "\u7ed3\u5408StreamDiffusion\u7ba1\u9053\uff0c\u4f7f\u7528LoRA\u5fae\u8c03Stable Diffusion\u751f\u6210\u52a8\u6f2b\u98ce\u683cRGB\u56fe\u50cf\uff0c\u5e76\u901a\u8fc7Informative Drawings\u6a21\u578b\u548c\u81ea\u5b9a\u4e49\u4f18\u5316\u5668\u751f\u6210\u7ed3\u6784\u5316\u6307\u5bfc\u8349\u56fe\u3002", "result": "\u7cfb\u7edf\u80fd\u63d0\u4f9b\u7cbe\u786e\u7684\u5b9e\u65f6\u7ed8\u56fe\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u7ed8\u5236\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u6027\u80fd\u548c\u53ef\u7528\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6f2b\u63d2\u753b\u7ed8\u5236\u4e2d\u7684\u9ad8\u96be\u5ea6\u95ee\u9898\uff0c\u4e3a\u521d\u5b66\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u521b\u4f5c\u5de5\u5177\u3002"}}
{"id": "2507.08990", "pdf": "https://arxiv.org/pdf/2507.08990", "abs": "https://arxiv.org/abs/2507.08990", "authors": ["Arka Ghosh", "Aliaume Lopez"], "title": "Computability of Equivariant Gr\u00f6bner bases", "categories": ["cs.LO", "math.AC"], "comment": null, "summary": "Let $\\mathbb{K}$ be a field, $\\mathcal{X}$ be an infinite set (of\nindeterminates), and $\\mathcal{G}$ be a group acting on $\\mathcal{X}$. An ideal\nin the polynomial ring $\\mathbb{K}[\\mathcal{X}]$ is called equivariant if it is\ninvariant under the action of $\\mathcal{G}$. We show Gr\\\"obner bases for\nequivariant ideals are computable are hence the equivariant ideal membership is\ndecidable when $\\mathcal{G}$ and $\\mathcal{X}$ satisfies the Hilbert's basis\nproperty, that is, when every equivariant ideal in $\\mathbb{K}[\\mathcal{X}]$ is\nfinitely generated. Moreover, we give a sufficient condition for the\nundecidability of the equivariant ideal membership problem. This condition is\nsatisfied by the most common examples not satisfying the Hilbert's basis\nproperty.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u65e0\u9650\u96c6\u4e0a\u7684\u591a\u9879\u5f0f\u73af\u4e2d\u7684\u7b49\u4ef7\u7406\u60f3\uff0c\u8bc1\u660e\u4e86\u5728\u6ee1\u8db3Hilbert\u57fa\u6027\u8d28\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u8ba1\u7b97Gr\u00f6bner\u57fa\u5e76\u5224\u5b9a\u7406\u60f3\u6210\u5458\u8d44\u683c\uff0c\u540c\u65f6\u7ed9\u51fa\u4e86\u6210\u5458\u8d44\u683c\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\u7684\u5145\u5206\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u65e0\u9650\u96c6\u4e0a\u7684\u591a\u9879\u5f0f\u73af\u4e2d\u7684\u7b49\u4ef7\u7406\u60f3\u53ca\u5176\u8ba1\u7b97\u6027\u8d28\uff0c\u5c24\u5176\u662f\u5728\u7fa4\u4f5c\u7528\u4e0b\u7684\u7406\u60f3\u6210\u5458\u95ee\u9898\u7684\u53ef\u5224\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u7fa4\u4f5c\u7528\u548cHilbert\u57fa\u6027\u8d28\uff0c\u7814\u7a76Gr\u00f6bner\u57fa\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u7406\u60f3\u6210\u5458\u95ee\u9898\u7684\u53ef\u5224\u5b9a\u6027\u6761\u4ef6\u3002", "result": "\u5728\u6ee1\u8db3Hilbert\u57fa\u6027\u8d28\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u8ba1\u7b97Gr\u00f6bner\u57fa\u5e76\u5224\u5b9a\u7406\u60f3\u6210\u5458\u8d44\u683c\uff1b\u540c\u65f6\u7ed9\u51fa\u4e86\u6210\u5458\u8d44\u683c\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\u7684\u6761\u4ef6\u3002", "conclusion": "\u8bba\u6587\u4e3a\u65e0\u9650\u96c6\u4e0a\u7684\u7b49\u4ef7\u7406\u60f3\u7684\u53ef\u8ba1\u7b97\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u53ef\u5224\u5b9a\u6027\u7684\u6761\u4ef6\uff0c\u6269\u5c55\u4e86\u5bf9\u7406\u60f3\u6210\u5458\u95ee\u9898\u7684\u7406\u89e3\u3002"}}
{"id": "2507.09067", "pdf": "https://arxiv.org/pdf/2507.09067", "abs": "https://arxiv.org/abs/2507.09067", "authors": ["Serhan W. Bahar"], "title": "Quantum-Resilient Privacy Ledger (QRPL): A Sovereign Digital Currency for the Post-Quantum Era", "categories": ["cs.ET", "cs.CR"], "comment": null, "summary": "The emergence of quantum computing presents profound challenges to existing\ncryptographic infrastructures, whilst the development of central bank digital\ncurrencies (CBDCs) has raised concerns regarding privacy preservation and\nexcessive centralisation in digital payment systems. This paper proposes the\nQuantum-Resilient Privacy Ledger (QRPL) as an innovative token-based digital\ncurrency architecture that incorporates National Institute of Standards and\nTechnology (NIST)-standardised post-quantum cryptography (PQC) with hash-based\nzero-knowledge proofs to ensure user sovereignty, scalability, and transaction\nconfidentiality. Key contributions include adaptations of ephemeral proof\nchains for unlinkable transactions, a privacy-weighted Proof-of-Stake (PoS)\nconsensus to promote equitable participation, and a novel zero-knowledge\nproof-based mechanism for privacy-preserving selective disclosure. QRPL aims to\naddress critical shortcomings in prevailing CBDC designs, including risks of\npervasive surveillance, with a 10-20 second block time to balance security and\nthroughput in future monetary systems. While conceptual, empirical prototypes\nare planned. Future work includes prototype development to validate these\nmodels empirically.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQRPL\u7684\u91cf\u5b50\u6297\u9690\u79c1\u8d26\u672c\u67b6\u6784\uff0c\u7ed3\u5408NIST\u6807\u51c6\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u65e8\u5728\u89e3\u51b3CBDC\u8bbe\u8ba1\u4e2d\u7684\u9690\u79c1\u548c\u4e2d\u5fc3\u5316\u95ee\u9898\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u5d1b\u8d77\u5bf9\u73b0\u6709\u52a0\u5bc6\u57fa\u7840\u8bbe\u65bd\u6784\u6210\u5a01\u80c1\uff0c\u540c\u65f6CBDC\u7684\u53d1\u5c55\u5f15\u53d1\u4e86\u5bf9\u9690\u79c1\u548c\u4e2d\u5fc3\u5316\u7684\u62c5\u5fe7\u3002", "method": "\u63d0\u51fa\u4e86\u7ed3\u5408\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684QRPL\u67b6\u6784\uff0c\u5305\u62ec\u77ed\u6682\u8bc1\u660e\u94fe\u3001\u9690\u79c1\u52a0\u6743\u7684PoS\u5171\u8bc6\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u9009\u62e9\u6027\u62ab\u9732\u673a\u5236\u3002", "result": "QRPL\u65e8\u5728\u89e3\u51b3CBDC\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u7f3a\u9677\uff0c\u5982\u666e\u904d\u76d1\u63a7\u98ce\u9669\uff0c\u5e76\u5b9e\u73b010-20\u79d2\u7684\u533a\u5757\u65f6\u95f4\u4ee5\u5e73\u8861\u5b89\u5168\u6027\u548c\u541e\u5410\u91cf\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86QRPL\u7684\u6982\u5ff5\uff0c\u5e76\u8ba1\u5212\u5f00\u53d1\u539f\u578b\u4ee5\u5b9e\u8bc1\u9a8c\u8bc1\u5176\u6a21\u578b\u3002"}}
{"id": "2507.08954", "pdf": "https://arxiv.org/pdf/2507.08954", "abs": "https://arxiv.org/abs/2507.08954", "authors": ["Alexander Fuerst", "Siddharth Anil", "Vishakha Dixit", "Purushottam", "Kulkarni", "Prateek Sharma"], "title": "MQFQ-Sticky: Fair Queueing For Serverless GPU Functions", "categories": ["cs.DC", "cs.SY", "eess.SY"], "comment": null, "summary": "Hardware accelerators like GPUs are now ubiquitous in data centers, but are\nnot fully supported by common cloud abstractions such as Functions as a Service\n(FaaS). Many popular and emerging FaaS applications such as machine learning\nand scientific computing can benefit from GPU acceleration. However, FaaS\nframeworks (such as OpenWhisk) are not capable of providing this acceleration\nbecause of the impedance mismatch between GPUs and the FaaS programming model,\nwhich requires virtualization and sandboxing of each function. The challenges\nare amplified due to the highly dynamic and heterogeneous FaaS workloads. This\npaper presents the design and implementation of a FaaS system for providing GPU\nacceleration in a black-box manner (without modifying function code). Running\nsmall functions in containerized sandboxes is challenging due to limited GPU\nconcurrency and high cold-start overheads, resulting in heavy queueing of\nfunction invocations. We show how principles from I/O scheduling, such as fair\nqueuing and anticipatory scheduling, can be translated to function scheduling\non GPUs. We develop MQFQ-Sticky, an integrated fair queueing and GPU memory\nmanagement approach, which balances the tradeoffs between locality, fairness,\nand latency. Empirical evaluation on a range of workloads shows that it reduces\nfunction latency by 2x to 20x compared to existing GPU and CPU queueing\npolicies.", "AI": {"tldr": "FaaS\u6846\u67b6\u7f3a\u4e4f\u5bf9GPU\u52a0\u901f\u7684\u5929\u7136\u652f\u6301\uff0c\u5bfc\u81f4ML\u548c\u79d1\u5b66\u8ba1\u7b97\u7b49\u5e94\u7528\u65e0\u6cd5\u5145\u5206\u5229\u7528GPU\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u9700\u4fee\u6539\u51fd\u6570\u4ee3\u7801\u7684GPU\u52a0\u901fFaaS\u7cfb\u7edf\uff0c\u901a\u8fc7\u8c03\u5ea6\u7b56\u7565\uff08\u5982\u516c\u5e73\u961f\u5217\u548c\u9884\u8c03\u5ea6\uff09\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u73b0\u6709FaaS\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u652f\u6301GPU\u52a0\u901f\uff0c\u963b\u788d\u4e86\u673a\u5668\u5b66\u4e60\u548c\u79d1\u5b66\u8ba1\u7b97\u7b49\u5e94\u7528\u7684\u6027\u80fd\u63d0\u5347\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u9ed1\u76d2\u5f0fGPU\u52a0\u901fFaaS\u7cfb\u7edf\uff0c\u5229\u7528I/O\u8c03\u5ea6\u539f\u5219\uff08\u5982\u516c\u5e73\u961f\u5217\u548c\u9884\u8c03\u5ea6\uff09\u4f18\u5316\u51fd\u6570\u8c03\u5ea6\u3002\u63d0\u51fa\u4e86MQFQ-Sticky\u65b9\u6cd5\uff0c\u5e73\u8861\u5c40\u90e8\u6027\u3001\u516c\u5e73\u6027\u548c\u5ef6\u8fdf\u3002", "result": "\u5728\u591a\u79cd\u8d1f\u8f7d\u4e0b\uff0cMQFQ-Sticky\u5c06\u51fd\u6570\u5ef6\u8fdf\u964d\u4f4e\u4e862\u500d\u523020\u500d\uff0c\u4f18\u4e8e\u73b0\u6709\u7684GPU\u548cCPU\u961f\u5217\u7b56\u7565\u3002", "conclusion": "\u63d0\u51fa\u7684\u8c03\u5ea6\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86FaaS\u7cfb\u7edf\u4e2dGPU\u52a0\u901f\u7684\u6548\u7387\uff0c\u4e3a\u52a8\u6001\u5f02\u6784\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08923", "pdf": "https://arxiv.org/pdf/2507.08923", "abs": "https://arxiv.org/abs/2507.08923", "authors": ["Rub\u00e9n Rodr\u00edguez \u00c1lvarez", "Denisa-Andreea Constantinescu", "Miguel Pe\u00f3n-Quir\u00f3s", "David Atienza"], "title": "CEO-DC: An Actionable Framework to Close the Carbon Gap in HPC Data Centers", "categories": ["cs.AR", "cs.CY", "cs.PF", "B.8.2; C.0; C.1.4; C.4; C.5.5; J.4; K.1; K.4.1; K.6.4"], "comment": "15 pages, 11 figures, 2 tables", "summary": "The rapid expansion of data centers (DCs) to support large-scale AI and\nscientific workloads is driving unsustainable growth in energy consumption and\ngreenhouse gas emissions. While successive generations of hardware platforms\nhave improved performance and energy efficiency, the question remains whether\nnew, more efficient platforms can realistically offset the rising emissions\nassociated with increasing demand. Prior studies often overlook the complex\ntrade-offs in such transitions by failing to account for both the economic\nincentives and the projected compute demand growth over the operational\nlifetime of the devices. In response, we present CEO-DC, an integrated model\nand decision-making methodology for Carbon and Economy Optimization in Data\nCenters. CEO-DC models the competing forces of cost, carbon, and compute demand\nto guide optimal platform procurement and replacement strategies. We propose\nmetrics to steer procurement, platform design, and policy decisions toward\nsustainable DC technologies. Given current platform trends, our AI case study\nusing CEO-DC shows that upgrading legacy devices on a 4-year cycle reduces\ntotal emissions. However, these upgrades fail to scale with DC demand growth\ntrends without increasing total emissions in over 44% of cases, and require\neconomic incentives for adoption in over 72%. Furthermore, current carbon\nprices are insufficient to motivate upgrades in 9 out of the 14 countries with\nthe highest number of DCs globally. We also find that optimizing platforms for\nenergy efficiency at the expense of latency can increase the carbon price\nrequired to justify their adoption. In summary, CEO-DC provides actionable\ninsights for DC architects, platform designers, and policymakers by timing\nlegacy platform upgrades, constraining DC growth to sustainable levels,\noptimizing platform performance-to-cost ratios, and increasing incentives.", "AI": {"tldr": "CEO-DC\u6a21\u578b\u7814\u7a76\u6570\u636e\u4e2d\u5fc3\u78b3\u6392\u653e\u4e0e\u7ecf\u6d4e\u4f18\u5316\u7684\u51b3\u7b56\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u8bbe\u5907\u5347\u7ea7\u53ef\u51cf\u6392\u4f46\u7ecf\u6d4e\u6fc0\u52b1\u4e0d\u8db3\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u7684\u5feb\u901f\u6269\u5f20\u5bfc\u81f4\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u6fc0\u589e\uff0c\u786c\u4ef6\u6548\u7387\u63d0\u5347\u662f\u5426\u80fd\u62b5\u6d88\u9700\u6c42\u589e\u957f\u4ecd\u5b58\u7591\u3002", "method": "\u63d0\u51faCEO-DC\u6a21\u578b\uff0c\u6574\u5408\u6210\u672c\u3001\u78b3\u6392\u653e\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u4f18\u5316\u91c7\u8d2d\u4e0e\u8bbe\u5907\u5347\u7ea7\u7b56\u7565\u3002", "result": "4\u5e74\u5468\u671f\u5347\u7ea7\u8bbe\u5907\u53ef\u51cf\u6392\u4f46\u9700\u7ecf\u6d4e\u6fc0\u52b1\uff0c\u4e14\u78b3\u4ef7\u683c\u4e0d\u8db3\uff1b\u80fd\u6548\u4f18\u5316\u53ef\u80fd\u589e\u52a0\u91c7\u7528\u95e8\u69db\u3002", "conclusion": "CEO-DC\u4e3a\u8bbe\u5907\u5347\u7ea7\u3001\u653f\u7b56\u6fc0\u52b1\u548c\u53ef\u6301\u7eed\u589e\u957f\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2507.09003", "pdf": "https://arxiv.org/pdf/2507.09003", "abs": "https://arxiv.org/abs/2507.09003", "authors": ["Prasoon Patidar", "Alex Crown", "Kevin Hsieh", "Yifei Xu", "Tusher Chakraborty", "Ranveer Chandra", "Yuvraj Agarwal"], "title": "Orchestration for Domain-specific Edge-Cloud Language Models", "categories": ["cs.DB"], "comment": null, "summary": "The remarkable performance of Large Language Models (LLMs) has inspired many\napplications, which often necessitate edge-cloud collaboration due to\nconnectivity, privacy, and cost considerations. Traditional methods primarily\nfocus on selecting the best LLM model for optimizing performance, while\nneglecting the critical interplay between the components of the LLM serving\npipeline (context retrieval, query preprocessing, etc.) or the changing latency\nand cost constraints. We introduce ECO-LLM (Edge-Cloud Orchestrator for LLMs),\na novel system that reframes this problem as a joint optimization challenge and\nsolves it by systematically exploring component configurations and dynamically\nselecting optimal strategies at the query level. ECO-LLM consists of two\ncomponents: (1) the ECO-LLM Emulator, which efficiently explores the vast\nconfiguration space utilizing query clustering and pareto-optimal path\nselection, gathering domain-specific performance metrics without exhaustive\nevaluation; and (2) the ECO-LLM Runtime, which leverages these metrics to\ndynamically select optimal resolution strategies for user queries while meeting\nuser-defined Service Level Objectives (SLOs). We evaluate ECO-LLM on a smart\nhome and a smart car assistant scenarios. With an exhaustive exploration of all\npossible configurations for seen queries, ECO-LLM outperforms cloud-based\nmodels like GPT-4o in terms of accuracy (90% vs. 74% on average) while reducing\ncosts by 90% and latency by 55%, demonstrating the value of its joint\noptimization at the query level. In practical deployment for previously unseen\nqueries, ECO-LLM selects configurations that reduce costs by 62% or improve\nresponse times by 62% on average compared to state-of-the-art model routing\napproaches, while maintaining higher accuracy and consistently adhering to\nspecified latency and cost constraints.", "AI": {"tldr": "ECO-LLM\u662f\u4e00\u79cd\u65b0\u578b\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316LLM\u670d\u52a1\u6d41\u7a0b\u7684\u7ec4\u4ef6\u914d\u7f6e\u548c\u52a8\u6001\u7b56\u7565\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4ec5\u5173\u6ce8\u9009\u62e9\u6700\u4f73LLM\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u7ec4\u4ef6\u95f4\u7684\u534f\u540c\u4f5c\u7528\u548c\u52a8\u6001\u7ea6\u675f\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0e\u6210\u672c\u4e0d\u5e73\u8861\u3002", "method": "ECO-LLM\u901a\u8fc7\u4eff\u771f\u5668\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u63a2\u7d22\u914d\u7f6e\u7a7a\u95f4\u5e76\u52a8\u6001\u9009\u62e9\u6700\u4f18\u7b56\u7565\u3002", "result": "ECO-LLM\u5728\u667a\u80fd\u5bb6\u5c45\u548c\u8f66\u8f7d\u573a\u666f\u4e2d\uff0c\u7cbe\u5ea6\u63d0\u534716%\uff0c\u6210\u672c\u964d\u4f4e90%\uff0c\u5ef6\u8fdf\u51cf\u5c1155%\u3002", "conclusion": "\u8054\u5408\u4f18\u5316\u548c\u52a8\u6001\u7b56\u7565\u9009\u62e9\u80fd\u9ad8\u6548\u6ee1\u8db3SLOs\uff0c\u4e3a\u8fb9\u7f18-\u4e91\u534f\u4f5c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.08804", "pdf": "https://arxiv.org/pdf/2507.08804", "abs": "https://arxiv.org/abs/2507.08804", "authors": ["Delia Deliu"], "title": "Cognitive Dissonance Artificial Intelligence (CD-AI): The Mind at War with Itself. Harnessing Discomfort to Sharpen Critical Thinking", "categories": ["cs.HC", "cs.CY"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING", "summary": "AI-augmented systems are traditionally designed to streamline human\ndecision-making by minimizing cognitive load, clarifying arguments, and\noptimizing efficiency. However, in a world where algorithmic certainty risks\nbecoming an Orwellian tool of epistemic control, true intellectual growth\ndemands not passive acceptance but active struggle. Drawing on the dystopian\nvisions of George Orwell and Philip K. Dick - where reality is unstable,\nperception malleable, and truth contested - this paper introduces Cognitive\nDissonance AI (CD-AI): a novel framework that deliberately sustains uncertainty\nrather than resolving it. CD-AI does not offer closure, but compels users to\nnavigate contradictions, challenge biases, and wrestle with competing truths.\nBy delaying resolution and promoting dialectical engagement, CD-AI enhances\nreflective reasoning, epistemic humility, critical thinking, and adaptability\nin complex decision-making. This paper examines the theoretical foundations of\nthe approach, presents an implementation model, explores its application in\ndomains such as ethics, law, politics, and science, and addresses key ethical\nconcerns - including decision paralysis, erosion of user autonomy, cognitive\nmanipulation, and bias in AI reasoning. In reimagining AI as an engine of doubt\nrather than a deliverer of certainty, CD-AI challenges dominant paradigms of\nAI-augmented reasoning and offers a new vision - one in which AI sharpens the\nmind not by resolving conflict, but by sustaining it. Rather than reinforcing\nHuxleyan complacency or pacifying the user into intellectual conformity, CD-AI\nechoes Nietzsche's vision of the Uebermensch - urging users to transcend\npassive cognition through active epistemic struggle.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCognitive Dissonance AI\uff08CD-AI\uff09\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u7ef4\u6301\u4e0d\u786e\u5b9a\u6027\u800c\u975e\u6d88\u9664\u5b83\u6765\u4fc3\u8fdb\u4e3b\u52a8\u8ba4\u77e5\u6597\u4e89\uff0c\u589e\u5f3a\u53cd\u601d\u6027\u63a8\u7406\u548c\u6279\u5224\u6027\u601d\u7ef4\u3002", "motivation": "\u4f20\u7edfAI\u7cfb\u7edf\u901a\u8fc7\u6700\u5c0f\u5316\u8ba4\u77e5\u8d1f\u8377\u548c\u4f18\u5316\u6548\u7387\u6765\u7b80\u5316\u51b3\u7b56\uff0c\u4f46\u7b97\u6cd5\u786e\u5b9a\u6027\u53ef\u80fd\u5bfc\u81f4\u77e5\u8bc6\u63a7\u5236\u7684\u5371\u9669\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u79cdAI\u6846\u67b6\uff0c\u901a\u8fc7\u7ef4\u6301\u8ba4\u77e5\u77db\u76fe\u6765\u4fc3\u8fdb\u771f\u6b63\u7684\u667a\u529b\u6210\u957f\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86CD-AI\u6846\u67b6\uff0c\u901a\u8fc7\u5ef6\u8fdf\u51b3\u7b56\u89e3\u51b3\u3001\u9f13\u52b1\u8fa9\u8bc1\u4e92\u52a8\u548c\u7ef4\u6301\u8ba4\u77e5\u77db\u76fe\u6765\u5b9e\u73b0\u3002\u7406\u8bba\u63a2\u8ba8\u3001\u6a21\u578b\u5b9e\u73b0\u4ee5\u53ca\u5728\u4f26\u7406\u3001\u6cd5\u5f8b\u3001\u653f\u6cbb\u548c\u79d1\u5b66\u7b49\u9886\u57df\u7684\u5e94\u7528\u88ab\u8be6\u7ec6\u5206\u6790\u3002", "result": "CD-AI\u80fd\u589e\u5f3a\u53cd\u601d\u6027\u63a8\u7406\u3001\u8ba4\u77e5\u8c26\u900a\u3001\u6279\u5224\u6027\u601d\u7ef4\u548c\u590d\u6742\u51b3\u7b56\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u4f46\u53ef\u80fd\u5f15\u53d1\u51b3\u7b56\u762b\u75ea\u3001\u7528\u6237\u81ea\u4e3b\u6027\u4fb5\u8680\u7b49\u4f26\u7406\u95ee\u9898\u3002", "conclusion": "CD-AI\u6311\u6218\u4e86\u4f20\u7edfAI\u589e\u5f3a\u63a8\u7406\u7684\u8303\u5f0f\uff0c\u63d0\u5021\u901a\u8fc7\u7ef4\u6301\u8ba4\u77e5\u51b2\u7a81\u800c\u975e\u89e3\u51b3\u51b2\u7a81\u6765\u63d0\u5347\u601d\u7ef4\u80fd\u529b\uff0c\u547c\u5e94\u4e86\u5c3c\u91c7\u7684\u201c\u8d85\u4eba\u201d\u54f2\u5b66\u3002"}}
{"id": "2507.09049", "pdf": "https://arxiv.org/pdf/2507.09049", "abs": "https://arxiv.org/abs/2507.09049", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "title": "CMER: A Context-Aware Approach for Mining Ethical Concern-related App Reviews", "categories": ["cs.SE"], "comment": null, "summary": "With the increasing proliferation of mobile applications in our daily lives,\nthe concerns surrounding ethics have surged significantly. Users communicate\ntheir feedback in app reviews, frequently emphasizing ethical concerns, such as\nprivacy and security. Incorporating these reviews has proved to be useful for\nmany areas of software engineering (e.g., requirement engineering, testing,\netc.). However, app reviews related to ethical concerns generally use\ndomain-specific language and are typically overshadowed by more generic\ncategories of user feedback, such as app reliability and usability. Thus,\nmaking automated extraction a challenging and time-consuming effort.\n  This study proposes CMER (A \\underline{C}ontext-Aware Approach for\n\\underline{M}ining \\underline{E}thical Concern-related App\n\\underline{R}eviews), a novel approach that combines Natural Language Inference\n(NLI) and a decoder-only (LLaMA-like) Large Language Model (LLM) to extract\nethical concern-related app reviews at scale. In CMER, NLI provides\ndomain-specific context awareness by using domain-specific hypotheses, and the\nLlama-like LLM eliminates the need for labeled data in the classification task.\nWe evaluated the validity of CMER by mining privacy and security-related\nreviews (PSRs) from the dataset of more than 382K app reviews of mobile\ninvestment apps. First, we evaluated four NLI models and compared the results\nof domain-specific hypotheses with generic hypotheses. Next, we evaluated three\nLLMs for the classification task. Finally, we combined the best NLI and LLM\nmodels (CMER) and extracted 2,178 additional PSRs overlooked by the previous\nstudy using a keyword-based approach, thus demonstrating the effectiveness of\nCMER. These reviews can be further refined into actionable requirement\nartifacts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCMER\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u548c\u7c7b\u4f3cLLaMA\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u63d0\u53d6\u5e94\u7528\u8bc4\u8bba\u4e2d\u6d89\u53ca\u4f26\u7406\u5173\u5207\u7684\u5185\u5bb9\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u65e5\u76ca\u666e\u53ca\uff0c\u4f26\u7406\u5173\u5207\uff08\u5982\u9690\u79c1\u548c\u5b89\u5168\uff09\u6210\u4e3a\u7528\u6237\u53cd\u9988\u7684\u91cd\u8981\u5185\u5bb9\uff0c\u4f46\u8fd9\u4e9b\u53cd\u9988\u901a\u5e38\u4f7f\u7528\u7279\u5b9a\u9886\u57df\u8bed\u8a00\u4e14\u88ab\u5176\u4ed6\u901a\u7528\u53cd\u9988\u7c7b\u522b\u63a9\u76d6\uff0c\u96be\u4ee5\u81ea\u52a8\u63d0\u53d6\u3002", "method": "CMER\u65b9\u6cd5\u7ed3\u5408NLI\u548cLLM\uff0cNLI\u63d0\u4f9b\u9886\u57df\u7279\u5b9a\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\uff0cLLM\u65e0\u9700\u6807\u8bb0\u6570\u636e\u5373\u53ef\u5206\u7c7b\u3002\u7814\u7a76\u4ece\u4e00\u4e2a\u8d85\u8fc7382K\u8bc4\u8bba\u7684\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u9690\u79c1\u548c\u5b89\u5168\u76f8\u5173\u8bc4\u8bba\uff08PSRs\uff09\u3002", "result": "CMER\u6210\u529f\u63d0\u53d6\u4e862178\u6761\u6b64\u524d\u5173\u952e\u5b57\u65b9\u6cd5\u5ffd\u7565\u7684PSRs\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002\u8fd9\u4e9b\u8bc4\u8bba\u53ef\u8fdb\u4e00\u6b65\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u9700\u6c42\u89c4\u8303\u3002", "conclusion": "CMER\u901a\u8fc7\u7ed3\u5408NLI\u548cLLM\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f26\u7406\u5173\u5207\u8bc4\u8bba\u63d0\u53d6\u7684\u6311\u6218\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.09883", "pdf": "https://arxiv.org/pdf/2507.09883", "abs": "https://arxiv.org/abs/2507.09883", "authors": ["Swarn Priya", "Fr\u00e9d\u00e9ric Besson", "Connor Sughrue", "Tim Steenvoorden", "Jamie Fulford", "Freek Verbeek", "Binoy Ravindran"], "title": "BeePL: Correct-by-compilation kernel extensions", "categories": ["cs.PL"], "comment": "45 pages, 18 figures", "summary": "eBPF is a technology that allows developers to safely extend kernel\nfunctionality without modifying kernel source code or developing loadable\nkernel modules. Since the kernel governs critical system operations and\nenforces isolation boundaries between user space and privileged data, any\nmechanism that modifies its behavior must meet the highest standards of safety\nand correctness. To this end, the eBPF toolchain includes a verifier, which\nstatically checks safety properties such as memory access validity, bounded\nloops, and type correctness before loading the program into the kernel.\nHowever, the existing verifier is both overly conservative in some\ncases-rejecting valid programs-and unsound in others, permitting unsafe\nbehavior that violates the intended semantics of the kernel interface.\n  To address these challenges, we introduce BeePL, a domain-specific language\nfor eBPF with a formally verified type system. The BeePL type system, along\nwith the language design, statically enforces key safety properties such as\ntype-correct memory access, safe pointer usage, absence of unbounded loops, and\nstructured control flow. These guarantees are backed by formal type soundness\nproofs, ensuring that well-typed programs satisfy the safety invariants\nrequired by the eBPF execution environment. BeePL also proves that well-typed\nsource programs meet critical eBPF-specific properties related to memory\nsafety, termination, and control flow, enabling high-level reasoning prior to\ncompilation. For properties not fully enforceable statically-such as dynamic\nbounds and undefined behavior-BeePL inserts semantics-preserving runtime checks\nduring compilation. We develop a verified compilation strategy that extends\nCompCert to generate BPF bytecode from BeePL programs, establishing a\nprincipled foundation for an end-to-end verifiable toolchain for safe kernel\nextensions.", "AI": {"tldr": "BeePL \u662f\u4e00\u79cd\u9488\u5bf9 eBPF \u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7c7b\u578b\u7cfb\u7edf\u89e3\u51b3\u73b0\u6709 eBPF \u9a8c\u8bc1\u5668\u7684\u4e0d\u8db3\uff0c\u786e\u4fdd\u7a0b\u5e8f\u7684\u5185\u5b58\u5b89\u5168\u3001\u7ec8\u6b62\u6027\u548c\u63a7\u5236\u6d41\u5b89\u5168\u3002", "motivation": "\u73b0\u6709 eBPF \u9a8c\u8bc1\u5668\u5728\u5904\u7406\u7a0b\u5e8f\u65f6\u8fc7\u4e8e\u4fdd\u5b88\u6216\u5b58\u5728\u6f0f\u6d1e\uff0c\u5bfc\u81f4\u67d0\u4e9b\u6709\u6548\u7a0b\u5e8f\u88ab\u62d2\u7edd\u6216\u5141\u8bb8\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "method": "\u5f15\u5165 BeePL\uff0c\u5176\u7c7b\u578b\u7cfb\u7edf\u53ef\u9759\u6001\u4fdd\u8bc1\u5185\u5b58\u8bbf\u95ee\u3001\u6307\u9488\u4f7f\u7528\u3001\u5faa\u73af\u548c\u63a7\u5236\u6d41\u7684\u5b89\u5168\u6027\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u8bc1\u660e\u652f\u6301\u8fd9\u4e9b\u4fdd\u8bc1\u3002\u5bf9\u4e8e\u52a8\u6001\u95ee\u9898\uff0cBeePL \u901a\u8fc7\u8fd0\u884c\u65f6\u68c0\u67e5\u8865\u5145\u3002", "result": "BeePL \u63d0\u4f9b\u4e86\u4ece\u9ad8\u7ea7\u8bed\u8a00\u5230 BPF \u5b57\u8282\u7801\u7684\u53ef\u9a8c\u8bc1\u7f16\u8bd1\u7b56\u7565\uff0c\u786e\u4fdd\u5185\u6838\u6269\u5c55\u7684\u5b89\u5168\u6027\u3002", "conclusion": "BeePL \u4e3a\u5b89\u5168\u5185\u6838\u6269\u5c55\u63d0\u4f9b\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u53ef\u9a8c\u8bc1\u7684\u5de5\u5177\u94fe\uff0c\u89e3\u51b3\u4e86\u73b0\u6709 eBPF \u9a8c\u8bc1\u5668\u7684\u7f3a\u9677\u3002"}}
{"id": "2507.09124", "pdf": "https://arxiv.org/pdf/2507.09124", "abs": "https://arxiv.org/abs/2507.09124", "authors": ["Syed Danial Ali Shah", "Maryam Hafeez", "Abdelaziz Salama", "Syed Ali Raza Zaidi"], "title": "Proactive AI-and-RAN Workload Orchestration in O-RAN Architectures for 6G Networks", "categories": ["cs.NI"], "comment": null, "summary": "The vision of AI-RAN convergence, as advocated by the AI-RAN Alliance, aims\nto unlock a unified 6G platform capable of seamlessly supporting AI and RAN\nworkloads over shared infrastructure. However, the architectural framework and\nintelligent resource orchestration strategies necessary to realize this vision\nremain largely unexplored. In this paper, we propose a Converged AI-and-ORAN\nArchitectural (CAORA) framework based on O-RAN specifications, enabling the\ndynamic coexistence of real-time RAN and computationally intensive AI\nworkloads. We design custom xApps within the Near-Real-Time RAN Intelligent\nController (NRT-RIC) to monitor RAN KPIs and expose radio analytics to an\nEnd-to-End (E2E) orchestrator via the recently introduced Y1 interface. The\norchestrator incorporates workload forecasting and anomaly detection modules,\naugmenting a Soft Actor-Critic (SAC) reinforcement learning agent that\nproactively manages resource allocation, including Multi-Instance GPU (MIG)\npartitioning. Using real-world 5G traffic traces from Barcelona, our\ntrace-driven simulations demonstrate that CAORA achieves near 99\\% fulfillment\nof RAN demands, supports dynamic AI workloads, and maximizes infrastructure\nutilization even under highly dynamic conditions. Our results reveal that\npredictive orchestration significantly improves system adaptability, resource\nefficiency, and service continuity, offering a viable blueprint for future\nAI-and-RAN converged 6G systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eO-RAN\u89c4\u8303\u7684AI\u4e0eRAN\u878d\u5408\u67b6\u6784\uff08CAORA\uff09\uff0c\u901a\u8fc7\u52a8\u6001\u8d44\u6e90\u5206\u914d\u548c\u667a\u80fd\u8c03\u5ea6\uff0c\u6210\u529f\u5b9e\u73b0\u4e865G\u7f51\u7edc\u73af\u5883\u4e0bAI\u4e0eRAN\u5de5\u4f5c\u8d1f\u8f7d\u7684\u9ad8\u6548\u5171\u5b58\u3002", "motivation": "\u89e3\u51b3AI-RAN\u878d\u5408\u57286G\u5e73\u53f0\u4e2d\u7684\u67b6\u6784\u548c\u8d44\u6e90\u8c03\u5ea6\u95ee\u9898\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u57fa\u7840\u8bbe\u65bd\u5171\u4eab\u3002", "method": "\u8bbe\u8ba1CAORA\u6846\u67b6\uff0c\u5229\u7528NRT-RIC\u4e2d\u7684xApps\u76d1\u63a7RAN\u6027\u80fd\u6307\u6807\uff0c\u901a\u8fc7Y1\u63a5\u53e3\u4e0eE2E\u7f16\u6392\u5668\u4ea4\u4e92\uff0c\u7ed3\u5408SAC\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5728\u5df4\u585e\u7f57\u90a3\u76845G\u6d41\u91cf\u6570\u636e\u6a21\u62df\u4e2d\uff0cCAORA\u5b9e\u73b0\u4e8699%\u7684RAN\u9700\u6c42\u6ee1\u8db3\u7387\uff0c\u5e76\u652f\u6301\u52a8\u6001AI\u5de5\u4f5c\u8d1f\u8f7d\u3002", "conclusion": "CAORA\u6846\u67b6\u4e3aAI\u4e0eRAN\u878d\u5408\u76846G\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u84dd\u672c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u9002\u5e94\u6027\u548c\u8d44\u6e90\u6548\u7387\u3002"}}
{"id": "2507.09945", "pdf": "https://arxiv.org/pdf/2507.09945", "abs": "https://arxiv.org/abs/2507.09945", "authors": ["Huilai Li", "Yonghao Dang", "Ying Xing", "Yiming Wang", "Jianqin Yin"], "title": "ESG-Net: Event-Aware Semantic Guided Network for Dense Audio-Visual Event Localization", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "Dense audio-visual event localization (DAVE) aims to identify event\ncategories and locate the temporal boundaries in untrimmed videos. Most studies\nonly employ event-related semantic constraints on the final outputs, lacking\ncross-modal semantic bridging in intermediate layers. This causes modality\nsemantic gap for further fusion, making it difficult to distinguish between\nevent-related content and irrelevant background content. Moreover, they rarely\nconsider the correlations between events, which limits the model to infer\nconcurrent events among complex scenarios. In this paper, we incorporate\nmulti-stage semantic guidance and multi-event relationship modeling, which\nrespectively enable hierarchical semantic understanding of audio-visual events\nand adaptive extraction of event dependencies, thereby better focusing on\nevent-related information. Specifically, our eventaware semantic guided network\n(ESG-Net) includes a early semantics interaction (ESI) module and a mixture of\ndependency experts (MoDE) module. ESI applys multi-stage semantic guidance to\nexplicitly constrain the model in learning semantic information through\nmulti-modal early fusion and several classification loss functions, ensuring\nhierarchical understanding of event-related content. MoDE promotes the\nextraction of multi-event dependencies through multiple serial mixture of\nexperts with adaptive weight allocation. Extensive experiments demonstrate that\nour method significantly surpasses the state-of-the-art methods, while greatly\nreducing parameters and computational load. Our code will be released on\nhttps://github.com/uchiha99999/ESG-Net.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aESG-Net\u7684\u5bc6\u96c6\u89c6\u542c\u4e8b\u4ef6\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bed\u4e49\u5f15\u5bfc\u548c\u591a\u4e8b\u4ef6\u5173\u7cfb\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u6a21\u6001\u8bed\u4e49\u9e3f\u6c9f\u548c\u5e76\u53d1\u4e8b\u4ef6\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u4e2d\u95f4\u5c42\u7684\u8de8\u6a21\u6001\u8bed\u4e49\u878d\u5408\uff0c\u4e14\u672a\u8003\u8651\u4e8b\u4ef6\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u96be\u4ee5\u533a\u5206\u4e8b\u4ef6\u76f8\u5173\u5185\u5bb9\u548c\u80cc\u666f\u5185\u5bb9\u3002", "method": "\u63d0\u51faESG-Net\uff0c\u5305\u542bESI\u6a21\u5757\uff08\u591a\u9636\u6bb5\u8bed\u4e49\u5f15\u5bfc\uff09\u548cMoDE\u6a21\u5757\uff08\u81ea\u9002\u5e94\u4e8b\u4ef6\u4f9d\u8d56\u6027\u63d0\u53d6\uff09\uff0c\u5206\u522b\u5b9e\u73b0\u5206\u5c42\u8bed\u4e49\u7406\u89e3\u4e0e\u4e8b\u4ef6\u4f9d\u8d56\u5efa\u6a21\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\u8d1f\u62c5\u3002", "conclusion": "ESG-Net\u901a\u8fc7\u591a\u9636\u6bb5\u8bed\u4e49\u5f15\u5bfc\u548c\u4e8b\u4ef6\u4f9d\u8d56\u5efa\u6a21\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5bc6\u96c6\u89c6\u542c\u4e8b\u4ef6\u5b9a\u4f4d\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2507.09146", "pdf": "https://arxiv.org/pdf/2507.09146", "abs": "https://arxiv.org/abs/2507.09146", "authors": ["Ryuichi Miyauchi", "Hengyuan Chang", "Tsukasa Fukusato", "Kazunori Miyata", "Haoran Xie"], "title": "Physics-Aware Fluid Field Generation from User Sketches Using Helmholtz-Hodge Decomposition", "categories": ["cs.GR"], "comment": "8 pages, 12 figures. In proceedings of NICOGRAPH International 2025", "summary": "Fluid simulation techniques are widely used in various fields such as film\nproduction, but controlling complex fluid behaviors remains challenging. While\nrecent generative models enable intuitive generation of vector fields from user\nsketches, they struggle to maintain physical properties such as\nincompressibility. To address these issues, this paper proposes a method for\ninteractively designing 2D vector fields. Conventional generative models can\nintuitively generate vector fields from user sketches, but remain difficult to\nconsider physical properties. Therefore, we add a simple editing process after\ngenerating the vector field. In the first stage, we use a latent diffusion\nmodel~(LDM) to automatically generate initial 2D vector fields from user\nsketches. In the second stage, we apply the Helmholtz-Hodge decomposition to\nlocally extract physical properties such as incompressibility from the results\ngenerated by LDM and recompose them according to user intentions. Through\nmultiple experiments, we demonstrate the effectiveness of our proposed method.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u4ea4\u4e92\u5f0f\u8bbe\u8ba1\u4e8c\u7ef4\u77e2\u91cf\u573a\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6f5c\u5728\u6269\u6563\u6a21\u578b\u548c\u8d6b\u5c14\u59c6\u970d\u5179-\u970d\u5fb7\u5206\u89e3\uff0c\u4f18\u5316\u4e86\u7528\u6237\u8349\u56fe\u751f\u6210\u7684\u77e2\u91cf\u573a\uff0c\u540c\u65f6\u4fdd\u6301\u7269\u7406\u7279\u6027\u3002", "motivation": "\u590d\u6742\u6d41\u4f53\u884c\u4e3a\u7684\u63a7\u5236\u4ecd\u5177\u6311\u6218\u6027\uff0c\u73b0\u6709\u751f\u6210\u6a21\u578b\u96be\u4ee5\u517c\u987e\u7269\u7406\u7279\u6027\uff08\u5982\u4e0d\u53ef\u538b\u7f29\u6027\uff09\u3002", "method": "\u5206\u4e24\u9636\u6bb5\uff1a1) \u4f7f\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4ece\u7528\u6237\u8349\u56fe\u751f\u6210\u521d\u59cb\u77e2\u91cf\u573a\uff1b2) \u901a\u8fc7\u8d6b\u5c14\u59c6\u970d\u5179-\u970d\u5fb7\u5206\u89e3\u5c40\u90e8\u63d0\u53d6\u5e76\u91cd\u7ec4\u7269\u7406\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u751f\u6210\u7684\u77e2\u91cf\u573a\u65e2\u7b26\u5408\u7528\u6237\u610f\u56fe\uff0c\u53c8\u4fdd\u6301\u4e86\u7269\u7406\u7279\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u76f4\u89c2\u4e14\u7269\u7406\u51c6\u786e\u7684\u77e2\u91cf\u573a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09194", "pdf": "https://arxiv.org/pdf/2507.09194", "abs": "https://arxiv.org/abs/2507.09194", "authors": ["Mohimenul Kabir", "Kuldeep S Meel"], "title": "A Simple and Effective ASP-Based Tool for Enumerating Minimal Hitting Sets", "categories": ["cs.LO"], "comment": "To appear in Technical Communications (TC) of ICLP 2025", "summary": "The hitting set problem is a fundamental problem in computer science and\nmathematics. Given a family of sets over a universe of elements, a minimal\nhitting set is a subset-minimal collection of elements that intersects each set\nin the family. Enumerating all minimal hitting sets is crucial in various\nreal-world applications.\n  In this paper, we address the full enumeration of all minimal hitting sets\nfor a given family of sets. We formulate the problem using Answer Set\nProgramming (ASP) and leverage existing ASP solvers for efficient enumeration.\nWe propose an ASP-based tool, MinHit-ASP, and our empirical evaluation shows\nthat it effectively enumerates minimal hitting sets across benchmarks from\ndiverse problem domains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u5de5\u5177MinHit-ASP\uff0c\u7528\u4e8e\u9ad8\u6548\u679a\u4e3e\u7ed9\u5b9a\u96c6\u65cf\u7684\u6240\u6709\u6700\u5c0f\u51fb\u4e2d\u96c6\u3002", "motivation": "\u6700\u5c0f\u51fb\u4e2d\u96c6\u7684\u679a\u4e3e\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u6570\u5b66\u4e2d\u6709\u91cd\u8981\u5e94\u7528\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5de5\u5177\u652f\u6301\u3002", "method": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u5efa\u6a21\u95ee\u9898\uff0c\u5e76\u5229\u7528\u73b0\u6709ASP\u6c42\u89e3\u5668\u5b9e\u73b0\u9ad8\u6548\u679a\u4e3e\uff0c\u5f00\u53d1\u5de5\u5177MinHit-ASP\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMinHit-ASP\u80fd\u591f\u5728\u591a\u79cd\u95ee\u9898\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9ad8\u6548\u679a\u4e3e\u6700\u5c0f\u51fb\u4e2d\u96c6\u3002", "conclusion": "MinHit-ASP\u662f\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u6700\u5c0f\u51fb\u4e2d\u96c6\u679a\u4e3e\u5de5\u5177\u3002"}}
{"id": "2507.10463", "pdf": "https://arxiv.org/pdf/2507.10463", "abs": "https://arxiv.org/abs/2507.10463", "authors": ["Maxwell Aifer", "Zach Belateche", "Suraj Bramhavar", "Kerem Y. Camsari", "Patrick J. Coles", "Gavin Crooks", "Douglas J. Durian", "Andrea J. Liu", "Anastasia Marchenkova", "Antonio J. Martinez", "Peter L. McMahon", "Faris Sbahi", "Benjamin Weiner", "Logan G. Wright"], "title": "Solving the compute crisis with physics-based ASICs", "categories": ["cs.ET", "cs.AR"], "comment": "16 pages, 5 figures", "summary": "Escalating artificial intelligence (AI) demands expose a critical \"compute\ncrisis\" characterized by unsustainable energy consumption, prohibitive training\ncosts, and the approaching limits of conventional CMOS scaling. Physics-based\nApplication-Specific Integrated Circuits (ASICs) present a transformative\nparadigm by directly harnessing intrinsic physical dynamics for computation\nrather than expending resources to enforce idealized digital abstractions. By\nrelaxing the constraints needed for traditional ASICs, like enforced\nstatelessness, unidirectionality, determinism, and synchronization, these\ndevices aim to operate as exact realizations of physical processes, offering\nsubstantial gains in energy efficiency and computational throughput. This\napproach enables novel co-design strategies, aligning algorithmic requirements\nwith the inherent computational primitives of physical systems. Physics-based\nASICs could accelerate critical AI applications like diffusion models,\nsampling, optimization, and neural network inference as well as traditional\ncomputational workloads like scientific simulation of materials and molecules.\nUltimately, this vision points towards a future of heterogeneous,\nhighly-specialized computing platforms capable of overcoming current scaling\nbottlenecks and unlocking new frontiers in computational power and efficiency.", "AI": {"tldr": "\u7269\u7406ASIC\u901a\u8fc7\u5229\u7528\u7269\u7406\u52a8\u529b\u5b66\u76f4\u63a5\u8ba1\u7b97\uff0c\u7a81\u7834\u4f20\u7edfCMOS\u9650\u5236\uff0c\u63d0\u5347\u80fd\u6e90\u6548\u7387\u548c\u8ba1\u7b97\u541e\u5410\u91cf\uff0c\u9002\u7528\u4e8eAI\u53ca\u79d1\u5b66\u6a21\u62df\u3002", "motivation": "\u4f20\u7edfAI\u8ba1\u7b97\u9762\u4e34\u80fd\u6e90\u6d88\u8017\u9ad8\u3001\u8bad\u7ec3\u6210\u672c\u5927\u53caCMOS\u6269\u5c55\u74f6\u9888\uff0c\u9700\u65b0\u578b\u8ba1\u7b97\u8303\u5f0f\u3002", "method": "\u653e\u677e\u4f20\u7edfASIC\u7ea6\u675f\uff08\u5982\u65e0\u72b6\u6001\u3001\u5355\u5411\u6027\u7b49\uff09\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u7269\u7406\u52a8\u529b\u5b66\u7684\u4e13\u7528\u7535\u8def\u3002", "result": "\u7269\u7406ASIC\u5728\u80fd\u6e90\u6548\u7387\u548c\u8ba1\u7b97\u541e\u5410\u91cf\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u6269\u6563\u6a21\u578b\u3001\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u7b49\u3002", "conclusion": "\u7269\u7406ASIC\u6709\u671b\u7a81\u7834\u5f53\u524d\u8ba1\u7b97\u74f6\u9888\uff0c\u5f00\u542f\u9ad8\u6548\u5f02\u6784\u8ba1\u7b97\u65b0\u65f6\u4ee3\u3002"}}
{"id": "2507.09546", "pdf": "https://arxiv.org/pdf/2507.09546", "abs": "https://arxiv.org/abs/2507.09546", "authors": ["Xiangwang Hou", "Jingjing Wang", "Jun Du", "Chunxiao Jiang", "Yong Ren", "Dusit Niyato"], "title": "Lightweight Federated Learning over Wireless Edge Networks", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "With the exponential growth of smart devices connected to wireless networks,\ndata production is increasing rapidly, requiring machine learning (ML)\ntechniques to unlock its value. However, the centralized ML paradigm raises\nconcerns over communication overhead and privacy. Federated learning (FL)\noffers an alternative at the network edge, but practical deployment in wireless\nnetworks remains challenging. This paper proposes a lightweight FL (LTFL)\nframework integrating wireless transmission power control, model pruning, and\ngradient quantization. We derive a closed-form expression of the FL convergence\ngap, considering transmission error, model pruning error, and gradient\nquantization error. Based on these insights, we formulate an optimization\nproblem to minimize the convergence gap while meeting delay and energy\nconstraints. To solve the non-convex problem efficiently, we derive closed-form\nsolutions for the optimal model pruning ratio and gradient quantization level,\nand employ Bayesian optimization for transmission power control. Extensive\nexperiments on real-world datasets show that LTFL outperforms state-of-the-art\nschemes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u8054\u90a6\u5b66\u4e60\uff08LTFL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u65e0\u7ebf\u4f20\u8f93\u529f\u7387\u63a7\u5236\u3001\u6a21\u578b\u526a\u679d\u548c\u68af\u5ea6\u91cf\u5316\uff0c\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u90e8\u7f72\u6311\u6218\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u8bbe\u5907\u8fde\u63a5\u65e0\u7ebf\u7f51\u7edc\u7684\u589e\u957f\uff0c\u6570\u636e\u91cf\u6025\u5267\u589e\u52a0\uff0c\u4f46\u96c6\u4e2d\u5f0f\u673a\u5668\u5b66\u4e60\u5b58\u5728\u901a\u4fe1\u5f00\u9500\u548c\u9690\u79c1\u95ee\u9898\u3002\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6210\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u90e8\u7f72\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u8bba\u6587\u63d0\u51faLTFL\u6846\u67b6\uff0c\u7ed3\u5408\u4f20\u8f93\u529f\u7387\u63a7\u5236\u3001\u6a21\u578b\u526a\u679d\u548c\u68af\u5ea6\u91cf\u5316\uff0c\u63a8\u5bfc\u4e86FL\u6536\u655b\u95f4\u9699\u7684\u95ed\u5f0f\u8868\u8fbe\uff0c\u5e76\u8bbe\u8ba1\u4f18\u5316\u95ee\u9898\u4ee5\u6700\u5c0f\u5316\u6536\u655b\u95f4\u9699\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLTFL\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u6210\u529f\u964d\u4f4e\u4e86\u6536\u655b\u95f4\u9699\u5e76\u6ee1\u8db3\u5ef6\u8fdf\u548c\u80fd\u91cf\u7ea6\u675f\u3002", "conclusion": "LTFL\u4e3a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09010", "pdf": "https://arxiv.org/pdf/2507.09010", "abs": "https://arxiv.org/abs/2507.09010", "authors": ["Chun-Ting Chen", "HanGyeol Mun", "Jian Meng", "Mohamed S. Abdelfattah", "Jae-sun Seo"], "title": "Hybrid Systolic Array Accelerator with Optimized Dataflow for Edge Large Language Model Inference", "categories": ["cs.AR", "cs.AI"], "comment": "Accepted as a conference paper at the 2025 IEEE/ACM International\n  Symposium on Low Power Electronics and Design (ISLPED)", "summary": "Edge inference for large language models (LLM) offers secure, low-latency,\nand cost-effective inference solutions. We emphasize that an edge accelerator\nshould achieve high area efficiency and minimize external memory access (EMA)\nduring the memory-bound decode stage, while maintaining high energy efficiency\nduring the compute intensive prefill stage. This paper proposes an edge LLM\ninference accelerator featuring a hybrid systolic array (HSA) architecture that\noptimizes inference efficiency in both stages. To further reduce EMA, we adopt\nMXINT4 weight quantization and propose an optimized dataflow tailored for HSA,\nensuring negligible dequantization overhead and achieving 100% hardware\nutilization with minimal accuracy loss under edge DRAM bandwidth constraints.\nFor non-linear operations, we incorporate optimized root mean square\nnormalization (RMSNorm) and rotary position embedding (RoPE) units, reducing\ntheir latency, area, and memory access overhead while enabling end-to-end\ninference on our accelerator. Our solution achieves 247/117 (token/s/mm2) while\nrunning a 1.3B LLM on long-input/long-output scenarios, providing >2.45x/13.5x\nimprovement over existing approaches, while maintaining superior energy\nefficiency in token generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u8109\u52a8\u9635\u5217\uff08HSA\uff09\u7684\u8fb9\u7f18LLM\u63a8\u7406\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u4f18\u5316\u6570\u636e\u6d41\u548c\u91cf\u5316\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u548c\u786c\u4ef6\u5229\u7528\u7387\u3002", "motivation": "\u8fb9\u7f18LLM\u63a8\u7406\u9700\u8981\u9ad8\u9762\u79ef\u6548\u7387\u3001\u4f4e\u5916\u90e8\u5b58\u50a8\u5668\u8bbf\u95ee\uff08EMA\uff09\u548c\u9ad8\u80fd\u6548\uff0c\u4ee5\u652f\u6301\u4f4e\u5ef6\u8fdf\u548c\u4f4e\u6210\u672c\u3002", "method": "\u91c7\u7528\u6df7\u5408\u8109\u52a8\u9635\u5217\u67b6\u6784\uff0c\u7ed3\u5408MXINT4\u6743\u91cd\u91cf\u5316\u548c\u4f18\u5316\u6570\u636e\u6d41\uff0c\u51cf\u5c11EMA\uff1b\u8bbe\u8ba1\u4e13\u7528\u786c\u4ef6\u5355\u5143\uff08\u5982RMSNorm\u548cRoPE\uff09\u4ee5\u964d\u4f4e\u975e\u7ebf\u6027\u64cd\u4f5c\u7684\u5f00\u9500\u3002", "result": "\u57281.3B LLM\u7684\u957f\u8f93\u5165/\u957f\u8f93\u51fa\u573a\u666f\u4e2d\uff0c\u8fbe\u5230247/117\uff08token/s/mm2\uff09\uff0c\u6027\u80fd\u63d0\u53472.45\u500d/13.5\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u80fd\u6548\u3002", "conclusion": "\u8be5\u52a0\u901f\u5668\u5728\u8fb9\u7f18\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u5ef6\u8fdf\u7684LLM\u63a8\u7406\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09138", "pdf": "https://arxiv.org/pdf/2507.09138", "abs": "https://arxiv.org/abs/2507.09138", "authors": ["Zhengding Hu", "Vibha Murthy", "Zaifeng Pan", "Wanlu Li", "Xiaoyi Fang", "Yufei Ding", "Yuke Wang"], "title": "HedraRAG: Coordinating LLM Generation and Database Retrieval in Heterogeneous RAG Serving", "categories": ["cs.DB", "cs.LG"], "comment": "Accepted by SOSP 2025", "summary": "This paper addresses emerging system-level challenges in heterogeneous\nretrieval-augmented generation (RAG) serving, where complex multi-stage\nworkflows and diverse request patterns complicate efficient execution. We\npresent HedraRAG, a runtime system built on a graph-based abstraction that\nexposes optimization opportunities across stage-level parallelism,\nintra-request similarity, and inter-request skewness. These opportunities are\nrealized through dynamic graph transformations, such as node splitting,\nreordering, edge addition, and dependency rewiring, applied to wavefronts of\nsubgraphs spanning concurrent requests. The resulting execution plans are\nmapped onto hybrid CPU-GPU pipelines to improve resource utilization and reduce\nlatency. Evaluations across a wide range of RAG workflows demonstrate speedups\nexceeding 1.5x and reaching up to 5x over existing frameworks, showcasing the\neffectiveness of coordinated generation and retrieval in serving environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faHedraRAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u56fe\u62bd\u8c61\u4f18\u5316\u5f02\u6784\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u670d\u52a1\u4e2d\u7684\u591a\u9636\u6bb5\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u9ad8\u6548\u5e76\u884c\u4e0e\u8d44\u6e90\u5229\u7528\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784RAG\u670d\u52a1\u4e2d\u591a\u9636\u6bb5\u5de5\u4f5c\u6d41\u548c\u591a\u6837\u5316\u8bf7\u6c42\u6a21\u5f0f\u5e26\u6765\u7684\u7cfb\u7edf\u7ea7\u6311\u6218\uff0c\u4f18\u5316\u6267\u884c\u6548\u7387\u3002", "method": "\u57fa\u4e8e\u56fe\u62bd\u8c61\u7684HedraRAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u56fe\u53d8\u6362\uff08\u5982\u8282\u70b9\u5206\u88c2\u3001\u91cd\u6392\u5e8f\u3001\u8fb9\u6dfb\u52a0\u7b49\uff09\u6539\u8fdb\u6267\u884c\u8ba1\u5212\uff0c\u5e76\u5728CPU-GPU\u6df7\u5408\u7ba1\u9053\u4e2d\u6620\u5c04\u5b9e\u65bd\u3002", "result": "\u5728\u591a\u79cdRAG\u5de5\u4f5c\u6d41\u4e2d\u5b9e\u73b01.5\u500d\u81f35\u500d\u7684\u52a0\u901f\uff0c\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "conclusion": "HedraRAG\u901a\u8fc7\u534f\u8c03\u751f\u6210\u4e0e\u68c0\u7d22\uff0c\u5728\u670d\u52a1\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2507.08805", "pdf": "https://arxiv.org/pdf/2507.08805", "abs": "https://arxiv.org/abs/2507.08805", "authors": ["Mike Kentros", "Manos Kamarianakis", "Michael Cole", "Vitaliy Popov", "Antonis Protopsaltis", "George Papagiannakis"], "title": "Non-linear, Team-based VR Training for Cardiac Arrest Care with enhanced CRM Toolkit", "categories": ["cs.HC", "cs.CY", "cs.GR"], "comment": "4 pages, 3 figures, 1 table", "summary": "This paper introduces iREACT, a novel VR simulation addressing key\nlimitations in traditional cardiac arrest (CA) training. Conventional methods\nstruggle to replicate the dynamic nature of real CA events, hindering Crew\nResource Management (CRM) skill development. iREACT provides a non-linear,\ncollaborative environment where teams respond to changing patient states,\nmirroring real CA complexities. By capturing multi-modal data (user actions,\ncognitive load, visual gaze) and offering real-time and post-session feedback,\niREACT enhances CRM assessment beyond traditional methods. A formative\nevaluation with medical experts underscores its usability and educational\nvalue, with potential applications in other high-stakes training scenarios to\nimprove teamwork, communication, and decision-making.", "AI": {"tldr": "iREACT\u662f\u4e00\u79cd\u65b0\u578bVR\u6a21\u62df\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5fc3\u810f\u9aa4\u505c(CA)\u57f9\u8bad\u4e2d\u7684\u5173\u952e\u9650\u5236\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u534f\u4f5c\u73af\u5883\u6a21\u62df\u771f\u5b9eCA\u4e8b\u4ef6\uff0c\u63d0\u5347\u56e2\u961f\u534f\u4f5c\u6280\u80fd\u3002", "motivation": "\u4f20\u7edfCA\u57f9\u8bad\u65b9\u6cd5\u96be\u4ee5\u590d\u73b0\u771f\u5b9e\u4e8b\u4ef6\u7684\u52a8\u6001\u6027\u548c\u590d\u6742\u6027\uff0c\u963b\u788d\u56e2\u961f\u8d44\u6e90\u7ba1\u7406(CRM)\u6280\u80fd\u7684\u53d1\u5c55\u3002", "method": "iREACT\u63d0\u4f9b\u975e\u7ebf\u6027\u534f\u4f5c\u73af\u5883\uff0c\u6355\u6349\u591a\u6a21\u6001\u6570\u636e\uff08\u7528\u6237\u884c\u4e3a\u3001\u8ba4\u77e5\u8d1f\u8377\u3001\u89c6\u89c9\u6ce8\u89c6\uff09\uff0c\u5e76\u63d0\u4f9b\u5b9e\u65f6\u548c\u4e8b\u540e\u53cd\u9988\u3002", "result": "\u533b\u5b66\u4e13\u5bb6\u7684\u5f62\u6210\u6027\u8bc4\u4f30\u8868\u660eiREACT\u5177\u6709\u53ef\u7528\u6027\u548c\u6559\u80b2\u4ef7\u503c\uff0c\u9002\u7528\u4e8e\u5176\u4ed6\u9ad8\u98ce\u9669\u57f9\u8bad\u573a\u666f\u3002", "conclusion": "iREACT\u901a\u8fc7\u6a21\u62df\u771f\u5b9eCA\u4e8b\u4ef6\u548c\u63d0\u4f9b\u591a\u6a21\u6001\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u4e86CRM\u6280\u80fd\u57f9\u8bad\u6548\u679c\u3002"}}
{"id": "2507.09051", "pdf": "https://arxiv.org/pdf/2507.09051", "abs": "https://arxiv.org/abs/2507.09051", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "title": "SAGE: A Context-Aware Approach for Mining Privacy Requirements Relevant Reviews from Mental Health Apps", "categories": ["cs.SE"], "comment": null, "summary": "Mental health (MH) apps often require sensitive user data to customize\nservices for mental wellness needs. However, such data collection practices in\nsome MH apps raise significant privacy concerns for users. These concerns are\noften mentioned in app reviews, but other feedback categories, such as\nreliability and usability, tend to take precedence. This poses a significant\nchallenge in automatically identifying privacy requirements-relevant reviews\n(privacy reviews) that can be utilized to extract privacy requirements and\naddress users' privacy concerns. Thus, this study introduces SAGE, a\ncontext-aware approach to automatically mining privacy reviews from MH apps\nusing Natural Language Inference (NLI) with MH domain-specific privacy\nhypotheses (provides domain-specific context awareness) and a GPT model\n(eliminates the need for fine-tuning). The quantitative evaluation of SAGE on a\ndataset of 204K app reviews achieved an F1 score of 0.85 without any\nfine-tuning, outperforming the fine-tuned baseline classifiers BERT and T5.\nFurthermore, SAGE extracted 748 privacy reviews previously overlooked by\nkeyword-based methods, demonstrating its effectiveness through qualitative\nevaluation. These reviews can later be refined into actionable privacy\nrequirement artifacts.", "AI": {"tldr": "SAGE\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u548cGPT\u6a21\u578b\u7684\u667a\u80fd\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u4ece\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u8bc4\u8bba\u4e2d\u6316\u6398\u9690\u79c1\u76f8\u5173\u7684\u53cd\u9988\uff0c\u65e0\u9700\u5fae\u8c03\u4e14\u6548\u679c\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\u3002", "motivation": "\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u6536\u96c6\u654f\u611f\u6570\u636e\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\uff0c\u4f46\u76f8\u5173\u53cd\u9988\u5e38\u88ab\u5176\u4ed6\u7c7b\u522b\uff08\u5982\u53ef\u9760\u6027\u3001\u6613\u7528\u6027\uff09\u63a9\u76d6\uff0c\u96be\u4ee5\u81ea\u52a8\u63d0\u53d6\u9690\u79c1\u9700\u6c42\u3002", "method": "\u63d0\u51faSAGE\u65b9\u6cd5\uff0c\u7ed3\u5408NLI\u548cGPT\u6a21\u578b\uff0c\u5229\u7528\u9886\u57df\u7279\u5b9a\u7684\u9690\u79c1\u5047\u8bbe\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u9ad8\u6548\u8bc6\u522b\u9690\u79c1\u8bc4\u8bba\u3002", "result": "SAGE\u572820.4\u4e07\u6761\u8bc4\u8bba\u4e2dF1\u5206\u6570\u8fbe0.85\uff0c\u4f18\u4e8eBERT\u548cT5\uff0c\u5e76\u53d1\u73b0748\u6761\u5173\u952e\u8bcd\u65b9\u6cd5\u9057\u6f0f\u7684\u9690\u79c1\u8bc4\u8bba\u3002", "conclusion": "SAGE\u80fd\u6709\u6548\u6316\u6398\u9690\u79c1\u9700\u6c42\uff0c\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u9700\u6c42\u6587\u6863\uff0c\u63d0\u5347\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2507.09790", "pdf": "https://arxiv.org/pdf/2507.09790", "abs": "https://arxiv.org/abs/2507.09790", "authors": ["Helge Spieker", "Th\u00e9o Matricon", "Nassim Belmecheri", "J\u00f8rn Eirik Betten", "Gauthier Le Bartz Lyan", "Heraldo Borges", "Quentin Mazouni", "Dennis Gross", "Arnaud Gotlieb", "Mathieu Acher"], "title": "Prompting for Performance: Exploring LLMs for Configuring Software", "categories": ["cs.SE", "cs.AI", "cs.PF"], "comment": null, "summary": "Software systems usually provide numerous configuration options that can\naffect performance metrics such as execution time, memory usage, binary size,\nor bitrate. On the one hand, making informed decisions is challenging and\nrequires domain expertise in options and their combinations. On the other hand,\nmachine learning techniques can search vast configuration spaces, but with a\nhigh computational cost, since concrete executions of numerous configurations\nare required. In this exploratory study, we investigate whether large language\nmodels (LLMs) can assist in performance-oriented software configuration through\nprompts. We evaluate several LLMs on tasks including identifying relevant\noptions, ranking configurations, and recommending performant configurations\nacross various configurable systems, such as compilers, video encoders, and SAT\nsolvers. Our preliminary results reveal both positive abilities and notable\nlimitations: depending on the task and systems, LLMs can well align with expert\nknowledge, whereas hallucinations or superficial reasoning can emerge in other\ncases. These findings represent a first step toward systematic evaluations and\nthe design of LLM-based solutions to assist with software configuration.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u80fd\u901a\u8fc7\u63d0\u793a\u8f85\u52a9\u6027\u80fd\u5bfc\u5411\u7684\u8f6f\u4ef6\u914d\u7f6e\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5176\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u914d\u7f6e\u9009\u9879\u4f17\u591a\u4e14\u5f71\u54cd\u6027\u80fd\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u7814\u7a76LLMs\u5728\u6b64\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u8bc4\u4f30\u591a\u79cdLLMs\u5728\u8bc6\u522b\u76f8\u5173\u9009\u9879\u3001\u6392\u5e8f\u914d\u7f6e\u548c\u63a8\u8350\u9ad8\u6027\u80fd\u914d\u7f6e\u7b49\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6d89\u53ca\u7f16\u8bd1\u5668\u3001\u89c6\u9891\u7f16\u7801\u5668\u7b49\u7cfb\u7edf\u3002", "result": "LLMs\u5728\u90e8\u5206\u4efb\u52a1\u4e2d\u80fd\u4e0e\u4e13\u5bb6\u77e5\u8bc6\u4e00\u81f4\uff0c\u4f46\u4e5f\u53ef\u80fd\u51fa\u73b0\u5e7b\u89c9\u6216\u6d45\u5c42\u63a8\u7406\u7684\u95ee\u9898\u3002", "conclusion": "\u8fd9\u662f\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u8bbe\u8ba1\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u914d\u7f6e\u8f85\u52a9\u89e3\u51b3\u65b9\u6848\u7684\u9996\u6b65\u63a2\u7d22\u3002"}}
{"id": "2507.10301", "pdf": "https://arxiv.org/pdf/2507.10301", "abs": "https://arxiv.org/abs/2507.10301", "authors": ["Wenhao Tang", "Sam Lindley"], "title": "Rows and Capabilities as Modal Effects", "categories": ["cs.PL"], "comment": null, "summary": "Effect handlers allow programmers to model and compose computational effects\nmodularly. Effect systems statically guarantee that all effects are handled.\nSeveral recent practical effect systems are based on either row polymorphism or\ncapabilities. However, there remains a gap in understanding the precise\nrelationship between effect systems with such disparate foundations. The main\ndifficulty is that in both row-based and capability-based systems, effect\ntracking is typically entangled with other features such as functions.\n  We propose a uniform framework for encoding, analysing, and comparing effect\nsystems. Our framework exploits and generalises modal effect types, a recent\nnovel effect system which decouples effect tracking from functions via\nmodalities. Modalities offer fine-grained control over when and how effects are\ntracked, enabling us to express different strategies for effect tracking. We\ngive encodings as macro translations from existing row-based and\ncapability-based effect systems into our framework and show that these\nencodings preserve types and semantics. Our encodings reveal the essence of\neffect tracking mechanisms in different effect systems, enable a direct\nanalysis on their differences, and provide valuable insights on language\ndesign.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u7f16\u7801\u3001\u5206\u6790\u548c\u6bd4\u8f83\u57fa\u4e8e\u884c\u591a\u6001\u548c\u80fd\u529b\u7684\u4e0d\u540c\u6548\u679c\u7cfb\u7edf\uff0c\u63ed\u793a\u4e86\u6548\u679c\u8ddf\u8e2a\u673a\u5236\u7684\u672c\u8d28\u3002", "motivation": "\u4e3a\u4e86\u586b\u8865\u5f53\u524d\u5bf9\u884c\u591a\u6001\u548c\u80fd\u529b\u57fa\u7840\u6548\u679c\u7cfb\u7edf\u4e4b\u95f4\u5173\u7cfb\u7406\u89e3\u7684\u7a7a\u767d\uff0c\u89e3\u51b3\u6548\u679c\u8ddf\u8e2a\u4e0e\u5176\u4ed6\u7279\u6027\uff08\u5982\u51fd\u6570\uff09\u7ea0\u7f20\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u5e76\u63a8\u5e7f\u6a21\u6001\u6548\u679c\u7c7b\u578b\uff0c\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u5b8f\u7ffb\u8bd1\u5c06\u73b0\u6709\u884c\u548c\u80fd\u529b\u57fa\u7840\u6548\u679c\u7cfb\u7edf\u7f16\u7801\u5230\u6846\u67b6\u4e2d\u3002", "result": "\u7f16\u7801\u4fdd\u7559\u4e86\u7c7b\u578b\u548c\u8bed\u4e49\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6548\u679c\u7cfb\u7edf\u7684\u672c\u8d28\u5dee\u5f02\uff0c\u4e3a\u8bed\u8a00\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6548\u679c\u7cfb\u7edf\u7684\u5206\u6790\u548c\u6bd4\u8f83\u63d0\u4f9b\u4e86\u7edf\u4e00\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u548c\u8bbe\u8ba1\u6548\u679c\u5904\u7406\u8bed\u8a00\u3002"}}
{"id": "2507.09153", "pdf": "https://arxiv.org/pdf/2507.09153", "abs": "https://arxiv.org/abs/2507.09153", "authors": ["Bilal Karaman", "Ilhan Ba\u015ft\u00fcrk", "Ferdi Kara", "Engin Zeydan", "Esra Aycan Beyaz\u0131t", "Sezai Ta\u015fk\u0131n", "Emil Bj\u00f6rnson", "Halim Yanikomeroglu"], "title": "On-Demand HAPS-Assisted Communication System for Public Safety in Emergency and Disaster Response", "categories": ["cs.NI"], "comment": "Accepted for publication in IEEE COMMAG", "summary": "Natural disasters often disrupt communication networks and severely hamper\nemergency response and disaster management. Existing solutions, such as\nportable communication units and cloud-based network architectures, have\nimproved disaster resilience but fall short if both the Radio Access Network\n(RAN) and backhaul infrastructure become inoperable. To address these\nchallenges, we propose a demand-driven communication system supported by High\nAltitude Platform Stations (HAPS) to restore communication in an affected area\nand enable effective disaster relief. The proposed emergency response network\nis a promising solution as it provides a rapidly deployable, resilient\ncommunications infrastructure. The proposed HAPS-based communication can play a\ncrucial role not only in ensuring connectivity for mobile users but also in\nrestoring backhaul connections when terrestrial networks fail. As a bridge\nbetween the disaster management center and the affected areas, it can\nfacilitate the exchange of information in real time, collect data from the\naffected regions, and relay crucial updates to emergency responders. Enhancing\nsituational awareness, coordination between relief agencies, and ensuring\nefficient resource allocation can significantly strengthen disaster response\ncapabilities. In this paper, simulations show that HAPS with hybrid optical/THz\nlinks boosts backhaul capacity and resilience, even in harsh conditions.\nHAPS-enabled RAN in S- and Ka-bands ensures reliable communication for first\nresponders and disaster-affected populations. This paper also explores the\nintegration of HAPS into emergency communication frameworks and standards, as\nit has the potential to improve network resilience and support effective\ndisaster management.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u7a7a\u5e73\u53f0\u7ad9\uff08HAPS\uff09\u7684\u9700\u6c42\u9a71\u52a8\u901a\u4fe1\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u81ea\u7136\u707e\u5bb3\u4e2d\u5feb\u901f\u6062\u590d\u901a\u4fe1\uff0c\u63d0\u5347\u5e94\u6025\u54cd\u5e94\u80fd\u529b\u3002", "motivation": "\u81ea\u7136\u707e\u5bb3\u5e38\u5bfc\u81f4\u901a\u4fe1\u7f51\u7edc\u4e2d\u65ad\uff0c\u5f71\u54cd\u5e94\u6025\u54cd\u5e94\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5728\u65e0\u7ebf\u7535\u63a5\u5165\u7f51\u7edc\uff08RAN\uff09\u548c\u56de\u7a0b\u57fa\u7840\u8bbe\u65bd\u540c\u65f6\u5931\u6548\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u4e9f\u9700\u66f4\u53ef\u9760\u7684\u901a\u4fe1\u6062\u590d\u624b\u6bb5\u3002", "method": "\u4f7f\u7528HAPS\u652f\u6301\u7684\u6df7\u5408\u5149/\u592a\u8d6b\u5179\u94fe\u8def\u63d0\u5347\u56de\u7a0b\u5bb9\u91cf\u548c\u97e7\u6027\uff0c\u5e76\u5728S\u548cKa\u6ce2\u6bb5\u90e8\u7f72HAPS\u652f\u6301\u7684RAN\uff0c\u786e\u4fdd\u901a\u4fe1\u53ef\u9760\u6027\u3002", "result": "\u6a21\u62df\u663e\u793a\uff0cHAPS\u65b9\u6848\u5728\u6076\u52a3\u6761\u4ef6\u4e0b\u4ecd\u80fd\u9ad8\u6548\u6062\u590d\u901a\u4fe1\uff0c\u589e\u5f3a\u707e\u5bb3\u7ba1\u7406\u4e2d\u7684\u5b9e\u65f6\u4fe1\u606f\u4ea4\u6362\u548c\u8d44\u6e90\u5206\u914d\u3002", "conclusion": "HAPS\u901a\u4fe1\u7cfb\u7edf\u662f\u4e00\u79cd\u5feb\u901f\u90e8\u7f72\u3001\u9ad8\u97e7\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u663e\u8457\u63d0\u5347\u707e\u5bb3\u5e94\u5bf9\u80fd\u529b\uff0c\u503c\u5f97\u7eb3\u5165\u5e94\u6025\u901a\u4fe1\u6846\u67b6\u548c\u6807\u51c6\u3002"}}
{"id": "2507.10066", "pdf": "https://arxiv.org/pdf/2507.10066", "abs": "https://arxiv.org/abs/2507.10066", "authors": ["Abhijeet Narang", "Parul Gupta", "Liuyijia Su", "Abhinav Dhall"], "title": "LayLens: Improving Deepfake Understanding through Simplified Explanations", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "This demonstration paper presents $\\mathbf{LayLens}$, a tool aimed to make\ndeepfake understanding easier for users of all educational backgrounds. While\nprior works often rely on outputs containing technical jargon, LayLens bridges\nthe gap between model reasoning and human understanding through a three-stage\npipeline: (1) explainable deepfake detection using a state-of-the-art forgery\nlocalization model, (2) natural language simplification of technical\nexplanations using a vision-language model, and (3) visual reconstruction of a\nplausible original image via guided image editing. The interface presents both\ntechnical and layperson-friendly explanations in addition to a side-by-side\ncomparison of the uploaded and reconstructed images. A user study with 15\nparticipants shows that simplified explanations significantly improve clarity\nand reduce cognitive load, with most users expressing increased confidence in\nidentifying deepfakes. LayLens offers a step toward transparent, trustworthy,\nand user-centric deepfake forensics.", "AI": {"tldr": "LayLens\u662f\u4e00\u4e2a\u5de5\u5177\uff0c\u65e8\u5728\u5e2e\u52a9\u4e0d\u540c\u6559\u80b2\u80cc\u666f\u7684\u7528\u6237\u66f4\u5bb9\u6613\u7406\u89e3\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u3002\u5b83\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u7b80\u5316\u6280\u672f\u89e3\u91ca\uff0c\u63d0\u9ad8\u7528\u6237\u5bf9\u6df1\u5ea6\u4f2a\u9020\u7684\u7406\u89e3\u548c\u8bc6\u522b\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5de5\u5177\u591a\u4f7f\u7528\u6280\u672f\u6027\u672f\u8bed\uff0c\u5bfc\u81f4\u666e\u901a\u7528\u6237\u96be\u4ee5\u7406\u89e3\u3002LayLens\u65e8\u5728\u901a\u8fc7\u7b80\u5316\u89e3\u91ca\u548c\u53ef\u89c6\u5316\u6bd4\u8f83\uff0c\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\uff0c\u63d0\u5347\u7528\u6237\u5bf9\u6df1\u5ea6\u4f2a\u9020\u7684\u8bc6\u522b\u4fe1\u5fc3\u3002", "method": "LayLens\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a(1)\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c(2)\u81ea\u7136\u8bed\u8a00\u7b80\u5316\u6280\u672f\u89e3\u91ca\uff0c(3)\u901a\u8fc7\u56fe\u50cf\u7f16\u8f91\u91cd\u5efa\u539f\u59cb\u56fe\u50cf\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5316\u89e3\u91ca\u663e\u8457\u63d0\u9ad8\u4e86\u6e05\u6670\u5ea6\uff0c\u964d\u4f4e\u4e86\u8ba4\u77e5\u8d1f\u8377\uff0c\u591a\u6570\u7528\u6237\u8868\u793a\u5bf9\u8bc6\u522b\u6df1\u5ea6\u4f2a\u9020\u66f4\u6709\u4fe1\u5fc3\u3002", "conclusion": "LayLens\u4e3a\u900f\u660e\u3001\u53ef\u4fe1\u8d56\u4e14\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u6df1\u5ea6\u4f2a\u9020\u53d6\u8bc1\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2507.09441", "pdf": "https://arxiv.org/pdf/2507.09441", "abs": "https://arxiv.org/abs/2507.09441", "authors": ["Ankit Sanjyal"], "title": "RectifiedHR: High-Resolution Diffusion via Energy Profiling and Adaptive Guidance Scheduling", "categories": ["cs.GR", "cs.CV"], "comment": "8 Pages, 10 Figures, Pre-Print Version, Code Available at:\n  https://github.com/ANKITSANJYAL/RectifiedHR", "summary": "High-resolution image synthesis with diffusion models often suffers from\nenergy instabilities and guidance artifacts that degrade visual quality. We\nanalyze the latent energy landscape during sampling and propose adaptive\nclassifier-free guidance (CFG) schedules that maintain stable energy\ntrajectories. Our approach introduces energy-aware scheduling strategies that\nmodulate guidance strength over time, achieving superior stability scores\n(0.9998) and consistency metrics (0.9873) compared to fixed-guidance\napproaches. We demonstrate that DPM++ 2M with linear-decreasing CFG scheduling\nyields optimal performance, providing sharper, more faithful images while\nreducing artifacts. Our energy profiling framework serves as a powerful\ndiagnostic tool for understanding and improving diffusion model behavior.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\uff08CFG\uff09\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u5728\u80fd\u91cf\u5206\u5e03\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u4e2d\u7684\u80fd\u91cf\u4e0d\u7a33\u5b9a\u548c\u5f15\u5bfc\u4f2a\u5f71\u95ee\u9898\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u4e2d\uff0c\u6269\u6563\u6a21\u578b\u5e38\u56e0\u80fd\u91cf\u4e0d\u7a33\u5b9a\u548c\u5f15\u5bfc\u4f2a\u5f71\u5bfc\u81f4\u89c6\u89c9\u8d28\u91cf\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7a33\u5b9a\u80fd\u91cf\u8f68\u8ff9\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u80fd\u91cf\u611f\u77e5\u8c03\u5ea6\u7b56\u7565\uff0c\u52a8\u6001\u8c03\u6574\u5f15\u5bfc\u5f3a\u5ea6\uff0c\u4f7f\u7528DPM++ 2M\u6a21\u578b\u7ed3\u5408\u7ebf\u6027\u9012\u51cf\u7684CFG\u8c03\u5ea6\u3002", "result": "\u65b9\u6cd5\u5728\u7a33\u5b9a\u6027\uff080.9998\uff09\u548c\u4e00\u81f4\u6027\uff080.9873\uff09\u6307\u6807\u4e0a\u4f18\u4e8e\u56fa\u5b9a\u5f15\u5bfc\u65b9\u6cd5\uff0c\u751f\u6210\u4e86\u66f4\u9510\u5229\u3001\u66f4\u771f\u5b9e\u7684\u56fe\u50cf\u5e76\u51cf\u5c11\u4e86\u4f2a\u5f71\u3002", "conclusion": "\u80fd\u91cf\u5206\u6790\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u6269\u6563\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u81ea\u9002\u5e94CFG\u8c03\u5ea6\u5728\u56fe\u50cf\u5408\u6210\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2507.09326", "pdf": "https://arxiv.org/pdf/2507.09326", "abs": "https://arxiv.org/abs/2507.09326", "authors": ["Kanta Takahata", "Jonas Sch\u00f6pf", "Naoki Nishida", "Takahito Aoto"], "title": "Recovering Commutation of Logically Constrained Rewriting and Equivalence Transformations (Full Version)", "categories": ["cs.LO"], "comment": "Accepted at the 27th International Symposium on Principles and\n  Practice of Declarative Programming (PPDP) 2025", "summary": "Logically constrained term rewriting is a relatively new rewriting formalism\nthat naturally supports built-in data structures, such as integers and bit\nvectors. In the analysis of logically constrained term rewrite systems\n(LCTRSs), rewriting constrained terms plays a crucial role. However, this\ncombines rewrite rule applications and equivalence transformations in a closely\nintertwined way. This intertwining makes it difficult to establish useful\ntheoretical properties for this kind of rewriting and causes problems in\nimplementations -- namely, that impractically large search spaces are often\nrequired. To address this issue, we propose in this paper a novel notion of\nmost general constrained rewriting, which operates on existentially constrained\nterms, a concept recently introduced by the authors. We define a class of\nleft-linear, left-value-free LCTRSs that are general enough to simulate all\nleft-linear LCTRSs and exhibit the desired key property: most general\nconstrained rewriting commutes with equivalence. This property ensures that\nequivalence transformations can be deferred until after the application of\nrewrite rules, which helps mitigate the issue of large search spaces in\nimplementations. In addition to that, we show that the original rewriting\nformalism on constrained terms can be embedded into our new rewriting formalism\non existentially constrained terms. Thus, our results are expected to have\nsignificant implications for achieving correct and efficient implementations in\ntools operating on LCTRSs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u201c\u6700\u4e00\u822c\u7ea6\u675f\u91cd\u5199\u201d\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u903b\u8f91\u7ea6\u675f\u9879\u91cd\u5199\u7cfb\u7edf\u4e2d\u7684\u641c\u7d22\u7a7a\u95f4\u8fc7\u5927\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u5173\u952e\u6027\u8d28\u3002", "motivation": "\u903b\u8f91\u7ea6\u675f\u9879\u91cd\u5199\u7cfb\u7edf\uff08LCTRSs\uff09\u5728\u91cd\u5199\u7ea6\u675f\u9879\u65f6\uff0c\u91cd\u5199\u89c4\u5219\u5e94\u7528\u548c\u7b49\u4ef7\u53d8\u6362\u7d27\u5bc6\u7ed3\u5408\uff0c\u5bfc\u81f4\u7406\u8bba\u6027\u8d28\u96be\u4ee5\u5efa\u7acb\u4e14\u5b9e\u73b0\u4e2d\u641c\u7d22\u7a7a\u95f4\u8fc7\u5927\u3002", "method": "\u5f15\u5165\u201c\u6700\u4e00\u822c\u7ea6\u675f\u91cd\u5199\u201d\u6982\u5ff5\uff0c\u57fa\u4e8e\u5de6\u7ebf\u6027\u3001\u5de6\u503c\u65e0\u5173\u7684LCTRSs\uff0c\u8bc1\u660e\u5176\u5173\u952e\u6027\u8d28\uff08\u91cd\u5199\u4e0e\u7b49\u4ef7\u53d8\u6362\u53ef\u4ea4\u6362\uff09\u3002", "result": "\u65b0\u65b9\u6cd5\u80fd\u591f\u5c06\u7b49\u4ef7\u53d8\u6362\u63a8\u8fdf\u5230\u91cd\u5199\u89c4\u5219\u5e94\u7528\u540e\uff0c\u6709\u6548\u51cf\u5c11\u5b9e\u73b0\u4e2d\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u4e0e\u539f\u91cd\u5199\u5f62\u5f0f\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aLCTRSs\u5de5\u5177\u7684\u6b63\u786e\u9ad8\u6548\u5b9e\u73b0\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2507.08880", "pdf": "https://arxiv.org/pdf/2507.08880", "abs": "https://arxiv.org/abs/2507.08880", "authors": ["Qifeng Tang", "Yain-Whar Si"], "title": "Central Bank Digital Currencies: A Survey", "categories": ["econ.GN", "cs.CE", "cs.CY", "cs.ET", "q-fin.EC", "68M14", "A.1; C.5"], "comment": "49 pages, 6 figures", "summary": "With the advancement of digital payment technologies, central banks worldwide\nhave increasingly begun to explore the implementation of Central Bank Digital\nCurrencies (CBDCs). This paper presents a comprehensive review of the latest\ndevelopments in CBDC system design and implementation. By analyzing 135\nresearch papers published between 2018 and 2025, the study provides an in-depth\nexamination of CBDC design taxonomy and ecosystem frameworks. Grounded in the\nCBDC Design Pyramid, the paper refines and expands key architectural elements\nby thoroughly investigating innovations in ledger technologies, the selection\nof consensus mechanisms, and challenges associated with offline payments and\ndigital wallet integration. Furthermore, it conceptualizes a CBDC ecosystem. A\ndetailed comparative analysis of 26 existing CBDC systems is conducted across\nfour dimensions: system architecture, ledger technology, access model, and\napplication domain. The findings reveal that the most common configuration\nconsists of a two-tier architecture, distributed ledger technology (DLT), and a\ntoken-based access model. However, no dominant trend has emerged regarding\napplication domains. Notably, recent research shows a growing focus on\nleveraging CBDCs for cross-border payments to resolve inefficiencies and\nstructural delays in current systems. Finally, the paper offers several\nforward-looking recommendations for future research.", "AI": {"tldr": "\u5bf9\u592e\u884c\u6570\u5b57\u8d27\u5e01\uff08CBDC\uff09\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u5b9e\u65bd\u7684\u5168\u9762\u7efc\u8ff0\uff0c\u57fa\u4e8e135\u7bc7\u7814\u7a76\u8bba\u6587\uff0c\u5206\u6790\u4e86CBDC\u5206\u7c7b\u4e0e\u751f\u6001\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f8326\u4e2a\u73b0\u6709\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u652f\u4ed8\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u5168\u7403\u592e\u884c\u5f00\u59cb\u63a2\u7d22CBDC\u7684\u5b9e\u65bd\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u652f\u4ed8\u7cfb\u7edf\u7684\u4f4e\u6548\u548c\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u67902018\u81f32025\u5e74\u7684135\u7bc7\u8bba\u6587\uff0c\u7814\u7a76CBDC\u8bbe\u8ba1\u5206\u7c7b\u4e0e\u751f\u6001\u6846\u67b6\uff0c\u91c7\u7528CBDC\u8bbe\u8ba1\u91d1\u5b57\u5854\u7ec6\u5316\u5173\u952e\u6280\u672f\u5143\u7d20\uff0c\u5e76\u6bd4\u8f8326\u4e2aCBDC\u7cfb\u7edf\u7684\u56db\u4e2a\u7ef4\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6700\u5e38\u89c1\u7684\u914d\u7f6e\u662f\u53cc\u5c42\u67b6\u6784\u3001\u5206\u5e03\u5f0f\u8d26\u672c\u6280\u672f\uff08DLT\uff09\u548c\u57fa\u4e8e\u4ee4\u724c\u7684\u8bbf\u95ee\u6a21\u578b\uff0c\u4f46\u5728\u5e94\u7528\u9886\u57df\u5c1a\u65e0\u4e3b\u6d41\u8d8b\u52bf\u3002", "conclusion": "\u8bba\u6587\u5efa\u8bae\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8CBDC\u5728\u8de8\u5883\u652f\u4ed8\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u524d\u77bb\u6027\u5efa\u8bae\u3002"}}
{"id": "2507.09926", "pdf": "https://arxiv.org/pdf/2507.09926", "abs": "https://arxiv.org/abs/2507.09926", "authors": ["Zixuan Song", "Zhishu Shen", "Xiaoyu Zheng", "Qiushi Zheng", "Zheng Lei", "Jiong Jin"], "title": "Intelligent Task Management via Dynamic Multi-region Division in LEO Satellite Networks", "categories": ["cs.DC"], "comment": null, "summary": "As a key complement to terrestrial networks and a fundamental component of\nfuture 6G systems, Low Earth Orbit (LEO) satellite networks are expected to\nprovide high-quality communication services when integrated with ground-based\ninfrastructure, thereby attracting significant research interest. However, the\nlimited satellite onboard resources and the uneven distribution of\ncomputational workloads often result in congestion along inter-satellite links\n(ISLs) that degrades task processing efficiency. Effectively managing the\ndynamic and large-scale topology of LEO networks to ensure balanced task\ndistribution remains a critical challenge. To this end, we propose a dynamic\nmulti-region division framework for intelligent task management in LEO\nsatellite networks. This framework optimizes both intra- and inter-region\nrouting to minimize task delay while balancing the utilization of computational\nand communication resources. Based on this framework, we propose a dynamic\nmulti-region division algorithm based on the Genetic Algorithm (GA), which\nadaptively adjusts the size of each region based on the workload status of\nindividual satellites. Additionally, we incorporate an adaptive routing\nalgorithm and a task splitting and offloading scheme based on Multi-Agent Deep\nDeterministic Policy Gradient (MA-DDPG) to effectively accommodate the arriving\ntasks. Simulation results demonstrate that our proposed framework outperforms\ncomparative methods in terms of the task delay, energy consumption per task,\nand task completion rate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u591a\u533a\u57df\u5212\u5206\u6846\u67b6\uff0c\u7528\u4e8eLEO\u536b\u661f\u7f51\u7edc\u4e2d\u7684\u667a\u80fd\u4efb\u52a1\u7ba1\u7406\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u4f18\u5316\u4efb\u52a1\u5ef6\u8fdf\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "LEO\u536b\u661f\u7f51\u7edc\u662f\u672a\u67656G\u7cfb\u7edf\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u5176\u8d44\u6e90\u6709\u9650\u4e14\u4efb\u52a1\u5206\u5e03\u4e0d\u5747\uff0c\u5bfc\u81f4\u94fe\u8def\u62e5\u5835\u548c\u4efb\u52a1\u5904\u7406\u6548\u7387\u4e0b\u964d\uff0c\u4e9f\u9700\u667a\u80fd\u7ba1\u7406\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u52a8\u6001\u591a\u533a\u57df\u5212\u5206\u6846\u67b6\u548cMA-DDPG\u7684\u4efb\u52a1\u5206\u914d\u4e0e\u5378\u8f7d\u65b9\u6848\uff0c\u4f18\u5316\u8def\u7531\u4e0e\u8d44\u6e90\u5e73\u8861\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4efb\u52a1\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u5b8c\u6210\u7387\u4e0a\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u52a8\u6001\u591a\u533a\u57df\u5212\u5206\u548c\u667a\u80fd\u4efb\u52a1\u7ba1\u7406\u65b9\u6848\u6709\u6548\u63d0\u5347\u4e86LEO\u7f51\u7edc\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09201", "pdf": "https://arxiv.org/pdf/2507.09201", "abs": "https://arxiv.org/abs/2507.09201", "authors": ["Weihong Xu", "Haein Choi", "Po-kai Hsu", "Shimeng Yu", "Tajana Rosing"], "title": "SLIM: A Heterogeneous Accelerator for Edge Inference of Sparse Large Language Model via Adaptive Thresholding", "categories": ["cs.AR", "cs.DC"], "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional proficiency in\nunderstanding and generating human language, but efficient inference on\nresource-constrained embedded devices remains challenging due to large model\nsizes and memory-intensive operations in feedforward network (FFN) and\nmulti-head attention (MHA) layers. While existing accelerators offload LLM\ninference to expensive heterogeneous computing systems, they fail to exploit\nthe significant sparsity inherent in LLM operations, leaving hardware resources\nunderutilized. We propose SLIM, an algorithm-hardware co-design optimized for\nsparse LLM serving on edge devices. SLIM exploits LLM sparsity through an\nadaptive thresholding algorithm that enables runtime-configurable sparsity with\nnegligible accuracy loss, fetching only activated neurons to dramatically\nreduce data movement. Our heterogeneous hardware architecture strategically\ncombines near-storage processing (NSP) and processing-in-memory (PIM): FFN\nweights are stored in high-density 3D NAND and computed using NSP units, while\nmemory-intensive MHA operations are processed in PIM modules. This design\nsignificantly reduces memory footprint, data movement, and energy consumption.\nOur comprehensive evaluation demonstrates SLIM's effectiveness, achieving\n13-18x throughput improvements over SSD-GPU systems and 9-10x better energy\nefficiency over DRAM-GPU systems while maintaining low latency, making\ncost-effective LLM deployment viable for edge computing environments.", "AI": {"tldr": "SLIM\u662f\u4e00\u79cd\u9762\u5411\u8fb9\u7f18\u8bbe\u5907\u7684\u7a00\u758f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u4f18\u5316\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9608\u503c\u7b97\u6cd5\u548c\u5f02\u6784\u786c\u4ef6\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u52a0\u901f\u5668\u672a\u80fd\u5145\u5206\u5229\u7528LLM\u64cd\u4f5c\u4e2d\u7684\u663e\u8457\u7a00\u758f\u6027\uff0c\u5bfc\u81f4\u786c\u4ef6\u8d44\u6e90\u5229\u7528\u4e0d\u8db3\uff0c\u800cSLIM\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u65e8\u5728\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u548c\u80fd\u8017\u3002", "method": "SLIM\u91c7\u7528\u81ea\u9002\u5e94\u9608\u503c\u7b97\u6cd5\u5b9e\u73b0\u8fd0\u884c\u65f6\u53ef\u914d\u7f6e\u7684\u7a00\u758f\u6027\uff0c\u7ed3\u5408\u4e86\u8fd1\u5b58\u50a8\u5904\u7406\uff08NSP\uff09\u548c\u5185\u5b58\u5185\u5904\u7406\uff08PIM\uff09\u7684\u5f02\u6784\u786c\u4ef6\u67b6\u6784\u3002", "result": "SLIM\u6bd4SSD-GPU\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u534713-18\u500d\uff0c\u6bd4DRAM-GPU\u7cfb\u7edf\u80fd\u6548\u63d0\u53479-10\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "SLIM\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684LLM\u90e8\u7f72\u65b9\u6848\uff0c\u663e\u8457\u4f18\u5316\u4e86\u8d44\u6e90\u5229\u7528\u548c\u80fd\u6548\u3002"}}
{"id": "2507.09448", "pdf": "https://arxiv.org/pdf/2507.09448", "abs": "https://arxiv.org/abs/2507.09448", "authors": ["Pramod Chunduri", "Yao Lu", "Joy Arulraj"], "title": "TRACER: Efficient Object Re-Identification in Networked Cameras through Adaptive Query Processing", "categories": ["cs.DB", "cs.CV"], "comment": null, "summary": "Efficiently re-identifying and tracking objects across a network of cameras\nis crucial for applications like traffic surveillance. Spatula is the\nstate-of-the-art video database management system (VDBMS) for processing Re-ID\nqueries. However, it suffers from two limitations. Its spatio-temporal\nfiltering scheme has limited accuracy on large camera networks due to localized\ncamera history. It is not suitable for critical video analytics applications\nthat require high recall due to a lack of support for adaptive query\nprocessing.\n  In this paper, we present Tracer, a novel VDBMS for efficiently processing\nRe-ID queries using an adaptive query processing framework. Tracer selects the\noptimal camera to process at each time step by training a recurrent network to\nmodel long-term historical correlations. To accelerate queries under a high\nrecall constraint, Tracer incorporates a probabilistic adaptive search model\nthat processes camera feeds in incremental search windows and dynamically\nupdates the sampling probabilities using an exploration-exploitation strategy.\nTo address the paucity of benchmarks for the Re-ID task due to privacy\nconcerns, we present a novel synthetic benchmark for generating multi-camera\nRe-ID datasets based on real-world traffic distribution. Our evaluation shows\nthat Tracer outperforms the state-of-the-art cross-camera analytics system by\n3.9x on average across diverse datasets.", "AI": {"tldr": "Tracer\u662f\u4e00\u4e2a\u65b0\u7684\u89c6\u9891\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08VDBMS\uff09\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u67e5\u8be2\u5904\u7406\u6846\u67b6\u9ad8\u6548\u5904\u7406\u5bf9\u8c61\u91cd\u8bc6\u522b\uff08Re-ID\uff09\u67e5\u8be2\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edfSpatula\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edfSpatula\u5728\u5927\u578b\u6444\u50cf\u5934\u7f51\u7edc\u4e2d\u56e0\u5c40\u90e8\u5386\u53f2\u6570\u636e\u5bfc\u81f4\u65f6\u7a7a\u8fc7\u6ee4\u51c6\u786e\u7387\u6709\u9650\uff0c\u4e14\u65e0\u6cd5\u652f\u6301\u9ad8\u53ec\u56de\u7387\u7684\u81ea\u9002\u5e94\u67e5\u8be2\u5904\u7406\u3002", "method": "Tracer\u5229\u7528\u5faa\u73af\u7f51\u7edc\u5efa\u6a21\u957f\u671f\u5386\u53f2\u5173\u8054\uff0c\u52a8\u6001\u9009\u62e9\u6700\u4f18\u6444\u50cf\u5934\uff0c\u5e76\u91c7\u7528\u6982\u7387\u81ea\u9002\u5e94\u641c\u7d22\u6a21\u578b\u52a0\u901f\u67e5\u8be2\u3002", "result": "Tracer\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u5e73\u5747\u6bd4\u73b0\u6709\u7cfb\u7edf\u63d0\u5347\u4e863.9\u500d\u3002", "conclusion": "Tracer\u901a\u8fc7\u81ea\u9002\u5e94\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86Re-ID\u4efb\u52a1\u7684\u6548\u7387\u548c\u53ec\u56de\u7387\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u5927\u89c4\u6a21\u76d1\u63a7\u573a\u666f\u3002"}}
{"id": "2507.08914", "pdf": "https://arxiv.org/pdf/2507.08914", "abs": "https://arxiv.org/abs/2507.08914", "authors": ["Munachimso B. Oguine", "Ozioma C. Oguine", "Karla Badillo-Urquiola", "Oluwasogo Adekunle Okunade"], "title": "'Teens Need to Be Educated on the Danger': Digital Access, Online Risks, and Safety Practices Among Nigerian Adolescents", "categories": ["cs.HC", "cs.CY"], "comment": "14 pages, 4 figures. Accepted to AfriCHI 2025", "summary": "Adolescents increasingly rely on online technologies to explore their\nidentities, form social connections, and access information and entertainment.\nHowever, their growing digital engagement exposes them to significant online\nrisks, particularly in underrepresented contexts like West Africa. This study\ninvestigates the online experiences of 409 secondary school adolescents in\nNigeria's Federal Capital Territory (FCT), focusing on their access to\ntechnology, exposure to risks, coping strategies, key stakeholders influencing\ntheir online interactions, and recommendations for improving online safety.\nUsing self-administered surveys, we found that while most adolescents reported\nmoderate access to online technology and connectivity, those who encountered\nrisks frequently reported exposure to inappropriate content and online scams.\nBlocking and reporting tools were the most commonly used strategies, though\nsome adolescents responded with inaction due to limited resources or awareness.\nParents emerged as the primary support network, though monitoring practices and\ncommunication varied widely. Guided by Protection Motivation Theory (PMT), our\nanalysis interprets adolescents' online safety behaviors as shaped by both\ntheir threat perceptions and their confidence in available coping strategies. A\nthematic analysis of their recommendations highlights the need for greater\nawareness and education, parental mediation, enhanced safety tools, stricter\nage restrictions, improved content moderation, government accountability, and\nresilience-building initiatives. Our findings underscore the importance of\nculturally and contextually relevant interventions to empower adolescents in\nnavigating the digital world, with implications for parents, educators,\ndesigners, and policymakers.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5c3c\u65e5\u5229\u4e9a\u9752\u5c11\u5e74\u5728\u6570\u5b57\u4e16\u754c\u4e2d\u7684\u5728\u7ebf\u4f53\u9a8c\uff0c\u91cd\u70b9\u5173\u6ce8\u6280\u672f\u8bbf\u95ee\u3001\u98ce\u9669\u66b4\u9732\u3001\u5e94\u5bf9\u7b56\u7565\u53ca\u5efa\u8bae\u3002", "motivation": "\u9752\u5c11\u5e74\u4f9d\u8d56\u6570\u5b57\u6280\u672f\u4f46\u9762\u4e34\u98ce\u9669\uff0c\u5c24\u5176\u662f\u5728\u897f\u975e\u7b49\u88ab\u5ffd\u89c6\u7684\u5730\u533a\uff0c\u9700\u4e86\u89e3\u5176\u5728\u7ebf\u884c\u4e3a\u53ca\u5b89\u5168\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5bf9409\u540d\u5c3c\u65e5\u5229\u4e9a\u4e2d\u5b66\u751f\u8fdb\u884c\u81ea\u586b\u5f0f\u8c03\u67e5\uff0c\u5206\u6790\u5176\u6280\u672f\u8bbf\u95ee\u3001\u98ce\u9669\u66b4\u9732\u548c\u5e94\u5bf9\u7b56\u7565\u3002", "result": "\u591a\u6570\u9752\u5c11\u5e74\u6709\u4e2d\u7b49\u6280\u672f\u8bbf\u95ee\uff0c\u4f46\u5e38\u906d\u9047\u4e0d\u5f53\u5185\u5bb9\u548c\u8bc8\u9a97\uff1b\u5bb6\u957f\u662f\u4e3b\u8981\u652f\u6301\uff0c\u4f46\u8d44\u6e90\u4e0e\u610f\u8bc6\u4e0d\u8db3\u5f71\u54cd\u4e86\u5e94\u5bf9\u3002", "conclusion": "\u9700\u9488\u5bf9\u6587\u5316\u548c\u60c5\u5883\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\uff0c\u63d0\u5347\u9752\u5c11\u5e74\u6570\u5b57\u7d20\u517b\uff0c\u547c\u5401\u591a\u65b9\u5408\u4f5c\u4ee5\u63d0\u9ad8\u5728\u7ebf\u5b89\u5168\u3002"}}
{"id": "2507.09063", "pdf": "https://arxiv.org/pdf/2507.09063", "abs": "https://arxiv.org/abs/2507.09063", "authors": ["Avi Arora", "Jinu Jang", "Roshanak Zilouchian Moghaddam"], "title": "SetupBench: Assessing Software Engineering Agents' Ability to Bootstrap Development Environments", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern Large Language Model (LLM) agents promise end to end assistance with\nreal-world software tasks, yet existing benchmarks evaluate LLM agents almost\nexclusively in pre-baked environments where every dependency is pre-installed.\nTo fill this gap, we introduce SetupBench, a 93 instance benchmark that\nisolates the environment-bootstrap skill: starting from a bare Linux sandbox,\nan agent must install packages, resolve dependency conflicts, initialize\ndatabases, and configure background services. Our tasks span seven language\necosystems, five database engines, and multi-service orchestration scenarios,\neach accompanies by a natural language problem statement and a deterministic\nsuccess command. Through evaluation of OpenHands, a state-of-the-art coding\nagent, we find low success rates across task categories, with particular\nchallenges in repository setup (38.9-57.4%) and local database configuration\n(20.0-53.3%). Our analysis reveals systematic failure modes including\nincomplete development tooling installation, hallucinated task constraints, and\nnon-persistent environment modifications that break agent-human collaboration\nworkflows. We identify substantial inefficiencies in agent exploration\nstrategies, with 38-89% of actions being unnecessary compared to optimal human\nbehavior. These findings highlight gaps in current agents' practical\nenvironment-bootstrap capabilities. By targeting this critical yet\nunder-evaluated capability, SetupBench provides a rigorous yard-stick for the\nnext generation of software developer agents aiming to solve end to end\nreal-wold tasks.", "AI": {"tldr": "SetupBench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u4ee3\u7406\u73af\u5883\u5f15\u5bfc\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d6\u591a\u79cd\u8bed\u8a00\u548c\u6570\u636e\u5e93\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684LLM\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5728\u9884\u914d\u7f6e\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u73af\u5883\u5f15\u5bfc\u9700\u6c42\u3002", "method": "\u4f7f\u752893\u4e2a\u5b9e\u4f8b\u7684SetupBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4ee3\u7406\u5728\u88f8Linux\u6c99\u76d2\u4e2d\u7684\u73af\u5883\u5f15\u5bfc\u80fd\u529b\u3002", "result": "OpenHands\u4ee3\u7406\u5728\u5404\u7c7b\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u8f83\u4f4e\uff0c\u5c24\u5176\u5728\u4ed3\u5e93\u8bbe\u7f6e\u548c\u6570\u636e\u5e93\u914d\u7f6e\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "SetupBench\u63d0\u4f9b\u4e86\u8bc4\u4f30\u4e0b\u4e00\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4ee3\u7406\u73af\u5883\u5f15\u5bfc\u80fd\u529b\u7684\u4e25\u683c\u6807\u51c6\u3002"}}
{"id": "2507.10367", "pdf": "https://arxiv.org/pdf/2507.10367", "abs": "https://arxiv.org/abs/2507.10367", "authors": ["Jingwei Xu", "Junbin Kang", "Mingkai Dong", "Mingyu Liu", "Lu Zhang", "Shaohong Guo", "Ziyan Qiu", "Mingzhen You", "Ziyi Tian", "Anqi Yu", "Tianhong Ding", "Xinwei Hu", "Haibo Chen"], "title": "FalconFS: Distributed File System for Large-Scale Deep Learning Pipeline", "categories": ["cs.DC", "cs.PF"], "comment": "Accepted by NSDI'26", "summary": "Client-side metadata caching has long been considered an effective method for\naccelerating metadata operations in distributed file systems (DFSs). However,\nwe have found that client-side state (e.g., caching) is not only ineffective\nbut also consumes valuable memory resources in the deep learning pipelines. We\nthus propose FalconFS, a DFS optimized for deep learning pipelines with the\nstateless-client architecture. Specifically, instead of performing client-side\npath resolution and caching, FalconFS efficiently resolves paths on the server\nside using hybrid metadata indexing and lazy namespace replication. FalconFS\nalso boosts server concurrency with concurrent request merging and provides\neasy deployment with VFS shortcut. Evaluations against CephFS and Lustre show\nthat FalconFS achieves up to 5.72$\\times$ throughput for small file read/write\nand up to 12.81$\\times$ throughput for deep learning model training. FalconFS\nhas been running in Huawei autonomous driving system's production environment\nwith 10,000 NPUs for one year.", "AI": {"tldr": "\u4f20\u7edf\u5ba2\u6237\u7aef\u5143\u6570\u636e\u7f13\u5b58\u5728\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf\u4e2d\u6548\u679c\u4e0d\u4f73\u4e14\u6d88\u8017\u8d44\u6e90\uff0cFalconFS\u91c7\u7528\u65e0\u72b6\u6001\u5ba2\u6237\u7aef\u67b6\u6784\u4f18\u5316\u6df1\u5ea6\u5b66\u4e60\u6d41\u7a0b\u3002", "motivation": "\u89e3\u51b3\u5ba2\u6237\u7aef\u5143\u6570\u636e\u7f13\u5b58\u65e0\u6548\u548c\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\u3002", "method": "\u91c7\u7528\u670d\u52a1\u5668\u7aef\u8def\u5f84\u89e3\u6790\u4e0e\u6df7\u5408\u5143\u6570\u636e\u7d22\u5f15\u3001\u60f0\u6027\u547d\u540d\u7a7a\u95f4\u590d\u5236\uff0c\u63d0\u5347\u5e76\u53d1\u6027\u548c\u90e8\u7f72\u4fbf\u6377\u6027\u3002", "result": "\u5728\u5c0f\u6587\u4ef6\u8bfb\u5199\u548c\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\uff0c\u541e\u5410\u91cf\u63d0\u53475.72\u500d\u548c12.81\u500d\u3002", "conclusion": "FalconFS\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.10482", "pdf": "https://arxiv.org/pdf/2507.10482", "abs": "https://arxiv.org/abs/2507.10482", "authors": ["Simon Guilloud", "Viktor Kun\u010dak"], "title": "Orthologic Type Systems", "categories": ["cs.PL", "cs.LO"], "comment": null, "summary": "We propose to use orthologic as the basis for designing type systems\nsupporting intersection, union, and negation types in the presence of subtyping\nassumptions. We show how to extend orthologic to support monotonic and\nantimonotonic functions, supporting the use of type constructors in such type\nsystems. We present a proof system for orthologic with function symbols,\nshowing that it admits partial cut elimination. Using these insights, we\npresent an $\\mathcal O(n^2(1+m))$ algorithm for deciding the subtyping relation\nunder $m$ assumptions. We also show $O(n^2)$ polynomial-time normalization\nalgorithm, allowing simplification of types to their minimal canonical form.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6b63\u4ea4\u903b\u8f91\u8bbe\u8ba1\u7c7b\u578b\u7cfb\u7edf\uff0c\u652f\u6301\u5b50\u7c7b\u578b\u5047\u8bbe\u4e0b\u7684\u4ea4\u3001\u5e76\u548c\u5426\u5b9a\u7c7b\u578b\uff0c\u6269\u5c55\u4e86\u6b63\u4ea4\u903b\u8f91\u4ee5\u652f\u6301\u5355\u8c03\u548c\u975e\u5355\u8c03\u51fd\u6570\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u5b50\u7c7b\u578b\u5173\u7cfb\u5224\u5b9a\u7b97\u6cd5\u548c\u591a\u9879\u5f0f\u65f6\u95f4\u89c4\u8303\u5316\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5b50\u7c7b\u578b\u5047\u8bbe\u4e0b\u8bbe\u8ba1\u652f\u6301\u4ea4\u3001\u5e76\u548c\u5426\u5b9a\u7c7b\u578b\u7684\u7c7b\u578b\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u57fa\u4e8e\u6b63\u4ea4\u903b\u8f91\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u6269\u5c55\u6b63\u4ea4\u903b\u8f91\u4ee5\u652f\u6301\u5355\u8c03\u548c\u975e\u5355\u8c03\u51fd\u6570\uff0c\u63d0\u51fa\u4e00\u4e2a\u5e26\u51fd\u6570\u7b26\u53f7\u7684\u8bc1\u660e\u7cfb\u7edf\uff0c\u5e76\u8bc1\u660e\u5176\u5141\u8bb8\u90e8\u5206\u5272\u6d88\u9664\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u5b50\u7c7b\u578b\u5173\u7cfb\u5224\u5b9a\u7b97\u6cd5\u548c\u89c4\u8303\u5316\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$\textit{O}(n^2(1+m))$\u7684\u5b50\u7c7b\u578b\u5173\u7cfb\u5224\u5b9a\u7b97\u6cd5\uff0c\u4ee5\u53ca\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4$\textit{O}(n^2)$\u7684\u89c4\u8303\u5316\u7b97\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6b63\u4ea4\u903b\u8f91\u7684\u6269\u5c55\u548c\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5b50\u7c7b\u578b\u5047\u8bbe\u4e0b\u590d\u6742\u7c7b\u578b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\u95ee\u9898\uff0c\u4e3a\u7c7b\u578b\u7cfb\u7edf\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2507.09270", "pdf": "https://arxiv.org/pdf/2507.09270", "abs": "https://arxiv.org/abs/2507.09270", "authors": ["Songhan Zhao", "Yusi Long", "Lanhua Li", "Bo Gu", "Shimin Gong", "Zehui Xiong"], "title": "Joint Traffic Reshaping and Channel Reconfiguration in RIS-assisted Semantic NOMA Communications", "categories": ["cs.NI"], "comment": null, "summary": "In this paper, we consider a semantic-aware reconfigurable intelligent\nsurface (RIS)-assisted wireless network, where multiple semantic users (SUs)\nsimultaneously transmit semantic information to an access point (AP) by using\nthe non-orthogonal multiple access (NOMA) method. The SUs can reshape their\ntraffic demands by modifying the semantic extraction factor, while the RIS can\nreconfigure the channel conditions via the passive beamforming. This provides\nthe AP with greater flexibility to decode the superimposed signals from the\nSUs. We aim to minimize the system's overall energy consumption, while ensuring\nthat each SU's traffic demand is satisfied. Hence, we formulate a joint\noptimization problem of the SUs' decoding order and semantic control, as well\nas the RIS's passive beamforming strategy. This problem is intractable due to\nthe complicated coupling in constraints. To solve this, we decompose the\noriginal problem into two subproblems and solve them by using a series of\napproximate methods. Numerical results show that the joint traffic reshaping\nand channel reconfiguration scheme significantly improves the energy saving\nperformance of the NOMA transmissions compared to the benchmark methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u611f\u77e5\u7684\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u8f85\u52a9\u65e0\u7ebf\u7f51\u7edc\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8bed\u4e49\u7528\u6237\uff08SUs\uff09\u7684\u89e3\u7801\u987a\u5e8f\u3001\u8bed\u4e49\u63a7\u5236\u548cRIS\u7684\u88ab\u52a8\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u7cfb\u7edf\u7684\u6574\u4f53\u80fd\u8017\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u5728\u6ee1\u8db3\u6bcf\u4e2aSU\u7684\u6d41\u91cf\u9700\u6c42\u7684\u540c\u65f6\uff0c\u6700\u5c0f\u5316\u7cfb\u7edf\u7684\u6574\u4f53\u80fd\u8017\uff0c\u901a\u8fc7\u8bed\u4e49\u6d41\u91cf\u91cd\u5851\u548c\u4fe1\u9053\u91cd\u6784\u63d0\u4f9b\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u3002", "method": "\u91c7\u7528\u975e\u6b63\u4ea4\u591a\u5740\u63a5\u5165\uff08NOMA\uff09\u65b9\u6cd5\uff0c\u5c06\u539f\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u95ee\u9898\uff0c\u5e76\u5229\u7528\u8fd1\u4f3c\u65b9\u6cd5\u6c42\u89e3\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6848\u5728\u80fd\u8017\u8282\u7ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8bed\u4e49\u63a7\u5236\u548cRIS\u88ab\u52a8\u6ce2\u675f\u6210\u5f62\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347NOMA\u4f20\u8f93\u7684\u80fd\u6548\u3002"}}
{"id": "2507.10109", "pdf": "https://arxiv.org/pdf/2507.10109", "abs": "https://arxiv.org/abs/2507.10109", "authors": ["Wenjie Tian", "Xinfa Zhu", "Haohe Liu", "Zhixian Zhao", "Zihao Chen", "Chaofan Ding", "Xinhan Di", "Junjie Zheng", "Lei Xie"], "title": "DualDub: Video-to-Soundtrack Generation via Joint Speech and Background Audio Synthesis", "categories": ["cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "While recent video-to-audio (V2A) models can generate realistic background\naudio from visual input, they largely overlook speech, an essential part of\nmany video soundtracks. This paper proposes a new task, video-to-soundtrack\n(V2ST) generation, which aims to jointly produce synchronized background audio\nand speech within a unified framework. To tackle V2ST, we introduce DualDub, a\nunified framework built on a multimodal language model that integrates a\nmultimodal encoder, a cross-modal aligner, and dual decoding heads for\nsimultaneous background audio and speech generation. Specifically, our proposed\ncross-modal aligner employs causal and non-causal attention mechanisms to\nimprove synchronization and acoustic harmony. Besides, to handle data scarcity,\nwe design a curriculum learning strategy that progressively builds the\nmultimodal capability. Finally, we introduce DualBench, the first benchmark for\nV2ST evaluation with a carefully curated test set and comprehensive metrics.\nExperimental results demonstrate that DualDub achieves state-of-the-art\nperformance, generating high-quality and well-synchronized soundtracks with\nboth speech and background audio.", "AI": {"tldr": "DualDub\u6846\u67b6\u63d0\u51fa\u89c6\u9891\u5230\u914d\u4e50\uff08V2ST\uff09\u4efb\u52a1\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u8054\u5408\u751f\u6210\u8bed\u97f3\u548c\u80cc\u666f\u97f3\u9891\uff0c\u91c7\u7528\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u5230\u97f3\u9891\uff08V2A\uff09\u6a21\u578b\u5ffd\u89c6\u8bed\u97f3\u90e8\u5206\uff0c\u800c\u8bed\u97f3\u662f\u89c6\u9891\u914d\u4e50\u7684\u5173\u952e\u7ec4\u6210\uff0c\u56e0\u6b64\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "DualDub\u6574\u5408\u591a\u6a21\u6001\u7f16\u7801\u5668\u3001\u8de8\u6a21\u6001\u5bf9\u9f50\u5668\u53ca\u53cc\u89e3\u7801\u5934\uff0c\u91c7\u7528\u56e0\u679c\u4e0e\u975e\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u63d0\u5347\u540c\u6b65\u6027\uff0c\u5e76\u8bbe\u8ba1\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u5e94\u5bf9\u6570\u636e\u7a00\u7f3a\u3002", "result": "DualDub\u5728\u9996\u4e2aV2ST\u57fa\u51c6DualBench\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u4e14\u540c\u6b65\u7684\u8bed\u97f3\u4e0e\u80cc\u666f\u97f3\u9891\u914d\u4e50\u3002", "conclusion": "DualDub\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u548c\u5148\u8fdb\u5bf9\u9f50\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u89c6\u9891\u914d\u4e50\u7684\u5168\u9762\u751f\u6210\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2507.09704", "pdf": "https://arxiv.org/pdf/2507.09704", "abs": "https://arxiv.org/abs/2507.09704", "authors": ["Xiaotang Zhang", "Ziyi Chang", "Qianhui Men", "Hubert Shum"], "title": "Real-time and Controllable Reactive Motion Synthesis via Intention Guidance", "categories": ["cs.GR"], "comment": null, "summary": "We propose a real-time method for reactive motion synthesis based on the\nknown trajectory of input character, predicting instant reactions using only\nhistorical, user-controlled motions. Our method handles the uncertainty of\nfuture movements by introducing an intention predictor, which forecasts key\njoint intentions to make pose prediction more deterministic from the historical\ninteraction. The intention is later encoded into the latent space of its\nreactive motion, matched with a codebook which represents mappings between\ninput and output. It samples a categorical distribution for pose generation and\nstrengthens model robustness through adversarial training. Unlike previous\noffline approaches, the system can recursively generate intentions and reactive\nmotions using feedback from earlier steps, enabling real-time, long-term\nrealistic interactive synthesis. Both quantitative and qualitative experiments\nshow our approach outperforms other matching-based motion synthesis approaches,\ndelivering superior stability and generalizability. In our method, user can\nalso actively influence the outcome by controlling the moving directions,\ncreating a personalized interaction path that deviates from predefined\ntrajectories.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f93\u5165\u89d2\u8272\u8f68\u8ff9\u7684\u5b9e\u65f6\u53cd\u5e94\u52a8\u4f5c\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u610f\u56fe\u9884\u6d4b\u5668\u5904\u7406\u672a\u6765\u8fd0\u52a8\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5229\u7528\u5bf9\u6297\u8bad\u7ec3\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u79bb\u7ebf\u5904\u7406\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u3001\u957f\u671f\u7684\u4ea4\u4e92\u5f0f\u52a8\u4f5c\u5408\u6210\uff0c\u4e14\u7f3a\u4e4f\u7528\u6237\u4e3b\u52a8\u5e72\u9884\u7684\u7075\u6d3b\u6027\u3002", "method": "\u5f15\u5165\u610f\u56fe\u9884\u6d4b\u5668\u9884\u6d4b\u5173\u8282\u610f\u56fe\uff0c\u5c06\u5176\u7f16\u7801\u5230\u6f5c\u5728\u7a7a\u95f4\u5e76\u4e0e\u4ee3\u7801\u5e93\u5339\u914d\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u751f\u6210\u52a8\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8e\u5339\u914d\u7684\u52a8\u4f5c\u5408\u6210\u65b9\u6cd5\uff0c\u5e76\u80fd\u5b9e\u73b0\u7528\u6237\u4e3b\u52a8\u5e72\u9884\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5b9e\u65f6\u3001\u957f\u671f\u7684\u4ea4\u4e92\u5f0f\u52a8\u4f5c\u5408\u6210\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u52a8\u4f5c\u7684\u81ea\u7136\u6027\u548c\u4e2a\u6027\u5316\u7a0b\u5ea6\u3002"}}
{"id": "2507.09390", "pdf": "https://arxiv.org/pdf/2507.09390", "abs": "https://arxiv.org/abs/2507.09390", "authors": ["Etienne Payet"], "title": "Non-Termination of Logic Programs Using Patterns", "categories": ["cs.LO"], "comment": "25 pages, presented at the 41st International Conference on Logic\n  Programming, ICLP 2025", "summary": "In this paper, we consider an approach introduced in term rewriting for the\nautomatic detection of non-looping non-termination from patterns of rules. We\nadapt it to logic programming by defining a new unfolding technique that\nproduces patterns describing possibly infinite sets of finite rewrite\nsequences. We present an experimental evaluation of our contributions that we\nimplemented in our tool NTI.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4ece\u89c4\u5219\u6a21\u5f0f\u4e2d\u81ea\u52a8\u68c0\u6d4b\u975e\u5faa\u73af\u975e\u7ec8\u6b62\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u903b\u8f91\u7f16\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c55\u5f00\u6280\u672f\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u903b\u8f91\u7f16\u7a0b\u4e2d\u975e\u7ec8\u6b62\u6027\u7684\u81ea\u52a8\u68c0\u6d4b\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u672f\u8bed\u91cd\u5199\u4e2d\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e86\u65b0\u7684\u5c55\u5f00\u6280\u672f\uff0c\u751f\u6210\u63cf\u8ff0\u53ef\u80fd\u65e0\u9650\u6709\u9650\u91cd\u5199\u5e8f\u5217\u96c6\u7684\u6a21\u5f0f\u3002", "result": "\u5728\u5de5\u5177NTI\u4e2d\u5b9e\u73b0\u5e76\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u672f\u8bed\u91cd\u5199\u4e2d\u7684\u6280\u672f\u9002\u914d\u5230\u903b\u8f91\u7f16\u7a0b\uff0c\u4e3a\u68c0\u6d4b\u975e\u7ec8\u6b62\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.08908", "pdf": "https://arxiv.org/pdf/2507.08908", "abs": "https://arxiv.org/abs/2507.08908", "authors": ["M. Z. Naser"], "title": "The Engineer's Dilemma: A Review of Establishing a Legal Framework for Integrating Machine Learning in Construction by Navigating Precedents and Industry Expectations", "categories": ["cs.CY", "cs.ET", "cs.LG"], "comment": null, "summary": "Despite the widespread interest in machine learning (ML), the engineering\nindustry has not yet fully adopted ML-based methods, which has left engineers\nand stakeholders uncertain about the legal and regulatory frameworks that\ngovern their decisions. This gap remains unaddressed as an engineer's\ndecision-making process, typically governed by professional ethics and\npractical guidelines, now intersects with complex algorithmic outputs. To\nbridge this gap, this paper explores how engineers can navigate legal\nprinciples and legislative justifications that support and/or contest the\ndeployment of ML technologies. Drawing on recent precedents and experiences\ngained from other fields, this paper argues that analogical reasoning can\nprovide a basis for embedding ML within existing engineering codes while\nmaintaining professional accountability and meeting safety requirements. In\nexploring these issues, the discussion focuses on established liability\ndoctrines, such as negligence and product liability, and highlights how courts\nhave evaluated the use of predictive models. We further analyze how legislative\nbodies and standard-setting organizations can furnish explicit guidance\nequivalent to prior endorsements of emergent technologies. This exploration\nstresses the vitality of understanding the interplay between technical\njustifications and legal precedents for shaping an informed stance on ML's\nlegitimacy in engineering practice. Finally, our analysis catalyzes a legal\nframework for integrating ML through which stakeholders can critically assess\nthe responsibilities, liabilities, and benefits inherent in ML-driven\nengineering solutions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5de5\u7a0b\u5e08\u5982\u4f55\u5728\u6cd5\u5f8b\u6846\u67b6\u5185\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5efa\u8bae\u901a\u8fc7\u7c7b\u6bd4\u63a8\u7406\u5c06\u5176\u5d4c\u5165\u73b0\u6709\u5de5\u7a0b\u51c6\u5219\uff0c\u540c\u65f6\u4fdd\u6301\u4e13\u4e1a\u8d23\u4efb\u548c\u5b89\u5168\u8981\u6c42\u3002", "motivation": "\u5de5\u7a0b\u884c\u4e1a\u5c1a\u672a\u5b8c\u5168\u91c7\u7528\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5bfc\u81f4\u5de5\u7a0b\u5e08\u548c\u5229\u76ca\u76f8\u5173\u8005\u5bf9\u6cd5\u5f8b\u548c\u76d1\u7ba1\u6846\u67b6\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6cd5\u5f8b\u8d23\u4efb\u5b66\u8bf4\u548c\u6cd5\u5ead\u5224\u4f8b\uff0c\u63d0\u4f9b\u5c06\u673a\u5668\u5b66\u4e60\u6574\u5408\u5230\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u7684\u6cd5\u5f8b\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e00\u4e2a\u6cd5\u5f8b\u6846\u67b6\uff0c\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u7684\u8d23\u4efb\u3001\u4e49\u52a1\u548c\u76ca\u5904\u3002", "conclusion": "\u9700\u8981\u7406\u89e3\u6280\u672f\u8bba\u8bc1\u4e0e\u6cd5\u5f8b\u5148\u4f8b\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u5f62\u6210\u5bf9\u673a\u5668\u5b66\u4e60\u5728\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u5408\u6cd5\u6027\u7684\u660e\u667a\u7acb\u573a\u3002"}}
{"id": "2507.10026", "pdf": "https://arxiv.org/pdf/2507.10026", "abs": "https://arxiv.org/abs/2507.10026", "authors": ["Zhifei Xu", "Zhiqing Tang", "Jiong Lou", "Zhi Yao", "Xuan Xie", "Tian Wang", "Yinglong Wang", "Weijia Jia"], "title": "EAT: QoS-Aware Edge-Collaborative AIGC Task Scheduling via Attention-Guided Diffusion Reinforcement Learning", "categories": ["cs.DC"], "comment": null, "summary": "The growth of Artificial Intelligence (AI) and large language models has\nenabled the use of Generative AI (GenAI) in cloud data centers for diverse\nAI-Generated Content (AIGC) tasks. Models like Stable Diffusion introduce\nunavoidable delays and substantial resource overhead, which are unsuitable for\nusers at the network edge with high QoS demands. Deploying AIGC services on\nedge servers reduces transmission times but often leads to underutilized\nresources and fails to optimally balance inference latency and quality. To\naddress these issues, this paper introduces a QoS-aware\n\\underline{E}dge-collaborative \\underline{A}IGC \\underline{T}ask scheduling\n(EAT) algorithm. Specifically: 1) We segment AIGC tasks and schedule patches to\nvarious edge servers, formulating it as a gang scheduling problem that balances\ninference latency and quality while considering server heterogeneity, such as\ndiffering model distributions and cold start issues. 2) We propose a\nreinforcement learning-based EAT algorithm that uses an attention layer to\nextract load and task queue information from edge servers and employs a\ndiffusion-based policy network for scheduling, efficiently enabling model\nreuse. 3) We develop an AIGC task scheduling system that uses our EAT algorithm\nto divide tasks and distribute them across multiple edge servers for\nprocessing. Experimental results based on our system and large-scale\nsimulations show that our EAT algorithm can reduce inference latency by up to\n56\\% compared to baselines. We release our open-source code at\nhttps://github.com/zzf1955/EAT.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fb9\u7f18\u534f\u4f5c\u7684AIGC\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5EAT\uff0c\u901a\u8fc7\u5206\u6bb5\u4efb\u52a1\u548c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4f18\u5316\u8fb9\u7f18\u670d\u52a1\u5668\u7684\u8d44\u6e90\u5229\u7528\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0fAI\u5728\u4e91\u6570\u636e\u4e2d\u5fc3\u4f7f\u7528\u65f6\u5b58\u5728\u5ef6\u8fdf\u9ad8\u548c\u8d44\u6e90\u6d88\u8017\u5927\u7684\u95ee\u9898\uff0c\u800c\u8fb9\u7f18\u670d\u52a1\u5668\u7684\u90e8\u7f72\u867d\u7136\u51cf\u5c11\u4f20\u8f93\u65f6\u95f4\uff0c\u4f46\u8d44\u6e90\u5229\u7528\u4e0d\u8db3\u4e14\u96be\u4ee5\u5e73\u8861\u5ef6\u8fdf\u548c\u8d28\u91cf\u3002", "method": "1) \u5c06AIGC\u4efb\u52a1\u5206\u6bb5\u5e76\u8c03\u5ea6\u5230\u591a\u53f0\u8fb9\u7f18\u670d\u52a1\u5668\uff0c\u5efa\u6a21\u4e3a\u7fa4\u8c03\u5ea6\u95ee\u9898\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684EAT\u7b97\u6cd5\uff0c\u5229\u7528\u6ce8\u610f\u529b\u5c42\u63d0\u53d6\u670d\u52a1\u5668\u4fe1\u606f\u5e76\u91c7\u7528\u6269\u6563\u7b56\u7565\u7f51\u7edc\u8fdb\u884c\u8c03\u5ea6\uff1b3) \u5f00\u53d1\u4efb\u52a1\u8c03\u5ea6\u7cfb\u7edf\u5b9e\u73b0\u591a\u670d\u52a1\u5668\u534f\u540c\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEAT\u7b97\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u53ef\u5c06\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u591a\u8fbe56%\u3002", "conclusion": "EAT\u7b97\u6cd5\u6709\u6548\u4f18\u5316\u4e86\u8fb9\u7f18\u670d\u52a1\u5668\u7684\u8d44\u6e90\u5229\u7528\u7387\u548c\u4efb\u52a1\u8c03\u5ea6\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86AIGC\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09660", "pdf": "https://arxiv.org/pdf/2507.09660", "abs": "https://arxiv.org/abs/2507.09660", "authors": ["Shuvra S. Bhattacharyya", "Marilyn Wolf"], "title": "Tools and Methodologies for System-Level Design", "categories": ["cs.AR"], "comment": "This is a preprint of a chapter to appear in the forthcoming volume\n  Handbook on Electronic Design Automation (third edition), published by Taylor\n  & Francis. The final version may differ", "summary": "System-level design, once the province of board designers, has now become a\ncentral concern for chip designers. Because chip design is a less forgiving\ndesign medium -- design cycles are longer and mistakes are harder to correct --\nsystem-on-chip designers need a more extensive tool suite than may be used by\nboard designers and a variety of tools and methodologies have been developed\nfor system-level design of systems-on-chips (SoCs). System-level design is less\namenable to synthesis than are logic or physical design. As a result,\nsystem-level tools concentrate on modeling, simulation, design space\nexploration, and design verification. The goal of modeling is to correctly\ncapture the system's operational semantics, which helps with both\nimplementation and verification. The study of models of computation provides a\nframework for the description of digital systems. Not only do we need to\nunderstand a particular style of computation, such as dataflow, but we also\nneed to understand how different models of computation can reliably communicate\nwith each other. Design space exploration tools, such as hardware/software\nco-design, develop candidate designs to understand trade-offs. Simulation can\nbe used not only to verify functional correctness but also to supply\nperformance and power/energy information for design analysis. This chapter\nemploys two applications -- video and neural networks -- as examples. Both are\nleading-edge applications that illustrate many important aspects of\nsystem-level design.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u4e86\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u5728\u82af\u7247\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u4ecb\u7ecd\u4e86\u76f8\u5173\u5de5\u5177\u548c\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u89c6\u9891\u548c\u795e\u7ecf\u7f51\u7edc\u4e24\u4e2a\u5e94\u7528\u793a\u4f8b\u5c55\u793a\u4e86\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u7684\u5173\u952e\u65b9\u9762\u3002", "motivation": "\u968f\u7740\u82af\u7247\u8bbe\u8ba1\u6210\u4e3a\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u7684\u6838\u5fc3\uff0c\u8bbe\u8ba1\u5e08\u9700\u8981\u66f4\u5168\u9762\u7684\u5de5\u5177\u5957\u4ef6\u6765\u5e94\u5bf9\u8bbe\u8ba1\u5468\u671f\u957f\u548c\u9519\u8bef\u96be\u4ee5\u4fee\u6b63\u7684\u6311\u6218\u3002", "method": "\u8bba\u6587\u91c7\u7528\u5efa\u6a21\u3001\u4eff\u771f\u3001\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u548c\u9a8c\u8bc1\u7b49\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u8ba1\u7b97\u6a21\u578b\u4ee5\u63cf\u8ff0\u6570\u5b57\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7\u89c6\u9891\u548c\u795e\u7ecf\u7f51\u7edc\u4e24\u4e2a\u5e94\u7528\u793a\u4f8b\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u5de5\u5177\u5728\u529f\u80fd\u9a8c\u8bc1\u548c\u6027\u80fd\u5206\u6790\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u5de5\u5177\u5728\u82af\u7247\u8bbe\u8ba1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u590d\u6742\u7684\u8ba1\u7b97\u6a21\u578b\u548c\u8bbe\u8ba1\u9a8c\u8bc1\u3002"}}
{"id": "2507.09592", "pdf": "https://arxiv.org/pdf/2507.09592", "abs": "https://arxiv.org/abs/2507.09592", "authors": ["Isaac Shi", "Zeyuan Li", "Fan Liu", "Wenli Wang", "Lewei He", "Yang Yang", "Tianyu Shi"], "title": "THOR: Transformer Heuristics for On-Demand Retrieval", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "We introduce the THOR (Transformer Heuristics for On-Demand Retrieval)\nModule, designed and implemented by eSapiens, a secure, scalable engine that\ntransforms natural-language questions into verified, read-only SQL analytics\nfor enterprise databases. The Text-to-SQL module follows a decoupled\norchestration/execution architecture: a Supervisor Agent routes queries, Schema\nRetrieval dynamically injects table and column metadata, and a SQL Generation\nAgent emits single-statement SELECT queries protected by a read-only guardrail.\nAn integrated Self-Correction & Rating loop captures empty results, execution\nerrors, or low-quality outputs and triggers up to five LLM-driven regeneration\nattempts. Finally, a Result Interpretation Agent produces concise,\nhuman-readable insights and hands raw rows to the Insight & Intelligence engine\nfor visualization or forecasting.\n  Smoke tests across finance, sales, and operations scenarios demonstrate\nreliable ad-hoc querying and automated periodic reporting. By embedding schema\nawareness, fault-tolerant execution, and compliance guardrails, the THOR Module\nempowers non-technical users to access live data with zero-SQL simplicity and\nenterprise-grade safety.", "AI": {"tldr": "THOR\u6a21\u5757\u662f\u4e00\u4e2a\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u6362\u4e3a\u5b89\u5168\u7684\u3001\u53ea\u8bfbSQL\u67e5\u8be2\u7684\u5f15\u64ce\uff0c\u9002\u7528\u4e8e\u4f01\u4e1a\u6570\u636e\u5e93\uff0c\u5177\u6709\u81ea\u6211\u4fee\u6b63\u548c\u7ed3\u679c\u89e3\u91ca\u529f\u80fd\u3002", "motivation": "\u4e3a\u975e\u6280\u672f\u7528\u6237\u63d0\u4f9b\u7b80\u5355\u5b89\u5168\u7684\u6570\u636e\u5e93\u8bbf\u95ee\u65b9\u5f0f\uff0c\u907f\u514dSQL\u590d\u6742\u6027\u3002", "method": "\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u5305\u62ec\u67e5\u8be2\u8def\u7531\u3001\u52a8\u6001\u6a21\u5f0f\u68c0\u7d22\u3001SQL\u751f\u6210\u3001\u81ea\u6211\u4fee\u6b63\u4e0e\u8bc4\u5206\u5faa\u73af\u4ee5\u53ca\u7ed3\u679c\u89e3\u91ca\u3002", "result": "\u5728\u8d22\u52a1\u3001\u9500\u552e\u548c\u8fd0\u8425\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u53ef\u9760\u7684\u5373\u5e2d\u67e5\u8be2\u548c\u81ea\u52a8\u62a5\u544a\u529f\u80fd\u3002", "conclusion": "THOR\u6a21\u5757\u901a\u8fc7\u6a21\u5f0f\u611f\u77e5\u548c\u5bb9\u9519\u6267\u884c\uff0c\u4e3a\u975e\u6280\u672f\u7528\u6237\u63d0\u4f9b\u4e86\u5b89\u5168\u4fbf\u6377\u7684\u6570\u636e\u8bbf\u95ee\u65b9\u6848\u3002"}}
{"id": "2507.08973", "pdf": "https://arxiv.org/pdf/2507.08973", "abs": "https://arxiv.org/abs/2507.08973", "authors": ["Jose Gonzalez-Belmonte", "Jaerock Kwon"], "title": "Analytical Study on the Visibility of Potential Positions for External Human-Machine Interfaces", "categories": ["cs.HC"], "comment": "28 pages, 5 tables, 10 figures", "summary": "As we move towards a future of autonomous vehicles, questions regarding their\nmethod of communication have arisen. One of the common questions concerns the\nplacement of the signaling used to communicate with pedestrians and road users,\nbut little work has been published fully dedicated to exploring this. This\npaper uses a simulation made in the Unity game engine to record the visibility\nof fifteen different vehicles, specifically regarding the visibility of frontal\nelements by a pedestrian on the sidewalk. Variables include the vehicle\nposition, number of vehicles on the road, and minimum and maximum distance of\nthe recorded points. It was concluded that the areas of the vehicle most often\nseen by pedestrians on the sidewalk attempting to cross the road were the\nfrontal frontal fenders and the headlights, with the frontal wheels, frontal\ndoors, bumper, and side mirrors are less visible alternatives. These findings\nare valuable in the future design of signaling for autonomous vehicles, in\norder to ensure pedestrians are able to see them on approaching vehicles. The\nsoftware used provides a platform for similar works in the future to be\nconducted.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7Unity\u6a21\u62df\u5b9e\u9a8c\u5206\u6790\u4e8615\u79cd\u8f66\u8f86\u524d\u90e8\u5143\u7d20\u7684\u53ef\u89c1\u6027\uff0c\u53d1\u73b0\u524d\u7ffc\u5b50\u677f\u548c\u524d\u5927\u706f\u6700\u6613\u88ab\u884c\u4eba\u770b\u5230\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4fe1\u53f7\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002", "motivation": "\u7814\u7a76\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0e\u884c\u4eba\u901a\u4fe1\u7684\u4fe1\u53f7\u663e\u793a\u4f4d\u7f6e\u95ee\u9898\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f7f\u7528Unity\u6e38\u620f\u5f15\u64ce\u6a21\u62df\u5b9e\u9a8c\uff0c\u8bb0\u5f5515\u79cd\u8f66\u8f86\u524d\u90e8\u5143\u7d20\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u53ef\u89c1\u6027\uff0c\u53d8\u91cf\u5305\u62ec\u8f66\u8f86\u4f4d\u7f6e\u3001\u9053\u8def\u8f66\u8f86\u6570\u91cf\u53ca\u8bb0\u5f55\u70b9\u7684\u8ddd\u79bb\u8303\u56f4\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u884c\u4eba\u6700\u5e38\u770b\u5230\u7684\u662f\u524d\u7ffc\u5b50\u677f\u548c\u524d\u5927\u706f\uff0c\u800c\u524d\u8f6e\u3001\u524d\u95e8\u3001\u4fdd\u9669\u6760\u548c\u540e\u89c6\u955c\u7684\u53ef\u89c1\u6027\u8f83\u4f4e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4fe1\u53f7\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4f9d\u636e\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6a21\u62df\u5e73\u53f0\u3002"}}
{"id": "2507.09108", "pdf": "https://arxiv.org/pdf/2507.09108", "abs": "https://arxiv.org/abs/2507.09108", "authors": ["Aaditya Bhatia", "Gustavo A. Oliva", "Gopi Krishnan Rajbahadur", "Haoxiang Zhang", "Yihao Chen", "Zhilong Chen", "Arthur Leung", "Dayi Lin", "Boyuan Chen", "Ahmed E. Hassan"], "title": "SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "High-quality labeled datasets are crucial for training and evaluating\nfoundation models in software engineering, but creating them is often\nprohibitively expensive and labor-intensive. We introduce SPICE, a scalable,\nautomated pipeline for labeling SWE-bench-style datasets with annotations for\nissue clarity, test coverage, and effort estimation. SPICE combines\ncontext-aware code navigation, rationale-driven prompting, and multi-pass\nconsensus to produce labels that closely approximate expert annotations.\nSPICE's design was informed by our own experience and frustration in labeling\nmore than 800 instances from SWE-Gym. SPICE achieves strong agreement with\nhuman-labeled SWE-bench Verified data while reducing the cost of labeling 1,000\ninstances from around $100,000 (manual annotation) to just $5.10. These results\ndemonstrate SPICE's potential to enable cost-effective, large-scale dataset\ncreation for SE-focused FMs. To support the community, we release both SPICE\ntool and SPICE Bench, a new dataset of 6,802 SPICE-labeled instances curated\nfrom 291 open-source projects in SWE-Gym (over 13x larger than SWE-bench\nVerified).", "AI": {"tldr": "SPICE\u662f\u4e00\u79cd\u81ea\u52a8\u5316\u6807\u6ce8\u7ba1\u9053\uff0c\u7528\u4e8e\u9ad8\u6548\u4f4e\u6210\u672c\u5730\u751f\u6210\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6807\u6ce8\u6210\u672c\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u6807\u6ce8\u6570\u636e\u96c6\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u7840\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u8017\u65f6\u3002SPICE\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "SPICE\u7ed3\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u4ee3\u7801\u5bfc\u822a\u3001\u7406\u8bba\u9a71\u52a8\u7684\u63d0\u793a\u548c\u591a\u8f6e\u5171\u8bc6\u673a\u5236\uff0c\u751f\u6210\u63a5\u8fd1\u4e13\u5bb6\u6807\u6ce8\u7684\u6807\u7b7e\u3002", "result": "SPICE\u5728\u6807\u6ce81,000\u6761\u6570\u636e\u65f6\uff0c\u6210\u672c\u4ece\u624b\u52a8\u6807\u6ce8\u768410\u4e07\u7f8e\u5143\u964d\u81f35.10\u7f8e\u5143\uff0c\u4e14\u4e0e\u4eba\u5de5\u6807\u6ce8\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "SPICE\u80fd\u591f\u4f4e\u6210\u672c\u3001\u5927\u89c4\u6a21\u5730\u751f\u6210\u8f6f\u4ef6\u5de5\u7a0b\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u5de5\u5177\u548c\u6570\u636e\u96c6\uff08SPICE Bench\uff09\u3002"}}
{"id": "2507.09341", "pdf": "https://arxiv.org/pdf/2507.09341", "abs": "https://arxiv.org/abs/2507.09341", "authors": ["Mahsa Paknejad", "Parisa Fard Moshiri", "Murat Simsek", "Burak Kantarci", "Hussein T. Mouftah"], "title": "Meeting Deadlines in Motion: Deep RL for Real-Time Task Offloading in Vehicular Edge Networks", "categories": ["cs.NI"], "comment": "8 pages, 7 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025", "summary": "Vehicular Mobile Edge Computing (VEC) drives the future by enabling\nlow-latency, high-efficiency data processing at the very edge of vehicular\nnetworks. This drives innovation in key areas such as autonomous driving,\nintelligent transportation systems, and real-time analytics. Despite its\npotential, VEC faces significant challenges, particularly in adhering to strict\ntask offloading deadlines, as vehicles remain within the coverage area of\nRoadside Units (RSUs) for only brief periods. To tackle this challenge, this\npaper evaluates the performance boundaries of task processing by initially\nestablishing a theoretical limit using Particle Swarm Optimization (PSO) in a\nstatic environment. To address more dynamic and practical scenarios, PSO, Deep\nQ-Network (DQN), and Proximal Policy Optimization (PPO) models are implemented\nin an online setting. The objective is to minimize dropped tasks and reduce\nend-to-end (E2E) latency, covering both communication and computation delays.\nExperimental results demonstrate that the DQN model considerably surpasses the\ndynamic PSO approach, achieving a 99.2% reduction in execution time.\nFurthermore, It leads to a reduction in dropped tasks by 2.5% relative to\ndynamic PSO and achieves 18.6\\% lower E2E latency, highlighting the\neffectiveness of Deep Reinforcement Learning (DRL) in enabling scalable and\nefficient task management for VEC systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8f66\u8f7d\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08VEC\uff09\u7684\u4efb\u52a1\u5378\u8f7d\u95ee\u9898\uff0c\u63d0\u51fa\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u5f3a\u5316\u65b9\u6cd5\uff08\u5982DQN\u548cPPO\uff09\u4f18\u5316\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u4efb\u52a1\u4e22\u5f03\u7387\u3002", "motivation": "VEC\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u56e0\u5176\u77ed\u6682\u8986\u76d6\u8303\u56f4\u548c\u4e25\u683c\u4efb\u52a1\u5378\u8f7d\u65f6\u9650\u9762\u4e34\u6311\u6218\uff0c\u9700\u4f18\u5316\u4efb\u52a1\u7ba1\u7406\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u7814\u7a76\u4e2d\u5148\u5728\u9759\u6001\u73af\u5883\u4e2d\u7528PSO\u5efa\u7acb\u7406\u8bba\u6781\u9650\uff0c\u540e\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6d4b\u8bd5PSO\u3001DQN\u548cPPO\u6a21\u578b\uff0c\u4ee5\u6700\u5c0f\u5316\u4efb\u52a1\u4e22\u5f03\u548c\u5ef6\u8fdf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDQN\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f18\u4e8ePSO\uff0c\u6267\u884c\u65f6\u95f4\u51cf\u5c1199.2%\uff0c\u4efb\u52a1\u4e22\u5f03\u7387\u964d\u4f4e2.5%\uff0cE2E\u5ef6\u8fdf\u964d\u4f4e18.6%\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u5f3a\u5316\u65b9\u6cd5\uff08\u5982DQN\uff09\u5728VEC\u7cfb\u7edf\u4e2d\u53ef\u663e\u8457\u63d0\u5347\u4efb\u52a1\u7ba1\u7406\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.09068", "pdf": "https://arxiv.org/pdf/2507.09068", "abs": "https://arxiv.org/abs/2507.09068", "authors": ["Dell Zhang", "Xiangyu Chen", "Jixiang Luo", "Mengxi Jia", "Changzhi Sun", "Ruilong Ren", "Jingren Liu", "Hao Sun", "Xuelong Li"], "title": "Infinite Video Understanding", "categories": ["cs.CV", "cs.AI", "cs.IR", "cs.LG", "cs.MM"], "comment": null, "summary": "The rapid advancements in Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) have ushered in remarkable progress in video understanding.\nHowever, a fundamental challenge persists: effectively processing and\ncomprehending video content that extends beyond minutes or hours. While recent\nefforts like Video-XL-2 have demonstrated novel architectural solutions for\nextreme efficiency, and advancements in positional encoding such as HoPE and\nVideoRoPE++ aim to improve spatio-temporal understanding over extensive\ncontexts, current state-of-the-art models still encounter significant\ncomputational and memory constraints when faced with the sheer volume of visual\ntokens from lengthy sequences. Furthermore, maintaining temporal coherence,\ntracking complex events, and preserving fine-grained details over extended\nperiods remain formidable hurdles, despite progress in agentic reasoning\nsystems like Deep Video Discovery. This position paper posits that a logical,\nalbeit ambitious, next frontier for multimedia research is Infinite Video\nUnderstanding -- the capability for models to continuously process, understand,\nand reason about video data of arbitrary, potentially never-ending duration. We\nargue that framing Infinite Video Understanding as a blue-sky research\nobjective provides a vital north star for the multimedia, and the wider AI,\nresearch communities, driving innovation in areas such as streaming\narchitectures, persistent memory mechanisms, hierarchical and adaptive\nrepresentations, event-centric reasoning, and novel evaluation paradigms.\nDrawing inspiration from recent work on long/ultra-long video understanding and\nseveral closely related fields, we outline the core challenges and key research\ndirections towards achieving this transformative capability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u2018\u65e0\u9650\u89c6\u9891\u7406\u89e3\u2019\u4f5c\u4e3a\u591a\u5a92\u4f53\u7814\u7a76\u7684\u4e0b\u4e00\u524d\u6cbf\u76ee\u6807\uff0c\u65e8\u5728\u89e3\u51b3\u957f\u65f6\u95f4\u89c6\u9891\u5904\u7406\u4e2d\u7684\u8ba1\u7b97\u3001\u5185\u5b58\u548c\u4e00\u81f4\u6027\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u6269\u5c55\u5728\u89c6\u9891\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u4ecd\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8d85\u957f\u89c6\u9891\u5185\u5bb9\uff0c\u9700\u8981\u7a81\u7834\u6027\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5b9a\u4f4d\u2018\u65e0\u9650\u89c6\u9891\u7406\u89e3\u2019\u4e3a\u76ee\u6807\uff0c\u63d0\u51fa\u9700\u5728\u6d41\u5f0f\u67b6\u6784\u3001\u6301\u4e45\u8bb0\u5fc6\u673a\u5236\u3001\u5206\u5c42\u8868\u793a\u7b49\u9886\u57df\u521b\u65b0\u3002", "result": "\u8bba\u6587\u5e76\u672a\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u6838\u5fc3\u6311\u6218\u548c\u65b9\u5411\u3002", "conclusion": "\u2018\u65e0\u9650\u89c6\u9891\u7406\u89e3\u2019\u662f\u4e00\u4e2a\u96c4\u5fc3\u52c3\u52c3\u4f46\u5173\u952e\u7684\u7814\u7a76\u76ee\u6807\uff0c\u5c06\u63a8\u52a8\u591a\u5a92\u4f53\u548cAI\u9886\u57df\u7684\u521b\u65b0\u3002"}}
{"id": "2507.09792", "pdf": "https://arxiv.org/pdf/2507.09792", "abs": "https://arxiv.org/abs/2507.09792", "authors": ["Prashant Govindarajan", "Davide Baldelli", "Jay Pathak", "Quentin Fournier", "Sarath Chandar"], "title": "CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": null, "summary": "Computer-aided design (CAD) is the digital construction of 2D and 3D objects,\nand is central to a wide range of engineering and manufacturing applications\nlike automobile and aviation. Despite its importance, CAD modeling remains\nlargely a time-intensive, manual task. Recent works have attempted to automate\nthis process with small transformer-based models and handcrafted CAD sequence\nrepresentations. However, there has been little effort to leverage the\npotential of large language models (LLMs) for sequential CAD design. In this\nwork, we introduce a new large-scale dataset of more than 170k CAD models\nannotated with high-quality, human-like descriptions generated with our\npipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs\nto generate CAD sequences represented in a JSON-based format from natural\nlanguage descriptions, demonstrating the viability and effectiveness of this\napproach for text-conditioned CAD generation. Because simple metrics often fail\nto reflect the quality of generated objects, we introduce geometric and\ntopological metrics based on sphericity, mean curvature, and Euler\ncharacteristic to provide richer structural insights. Our experiments and\nablation studies on both synthetic and human-annotated data demonstrate that\nCADmium is able to automate CAD design, drastically speeding up the design of\nnew objects. The dataset, code, and fine-tuned models are available online.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u5316CAD\u8bbe\u8ba1\uff0c\u901a\u8fc7\u751f\u6210\u9ad8\u8d28\u91cf\u63cf\u8ff0\u548cJSON\u683c\u5f0f\u7684CAD\u5e8f\u5217\uff0c\u663e\u8457\u63d0\u5347\u8bbe\u8ba1\u6548\u7387\u3002", "motivation": "CAD\u8bbe\u8ba1\u76ee\u524d\u4ecd\u4f9d\u8d56\u624b\u52a8\u64cd\u4f5c\uff0c\u8017\u65f6\u4e14\u4f4e\u6548\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528LLMs\u7684\u6f5c\u529b\u3002", "method": "\u57fa\u4e8eGPT-4.1\u751f\u6210\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u4ee3\u7801LLMs\u4ee5\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210JSON\u683c\u5f0f\u7684CAD\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u51e0\u4f55\u548c\u62d3\u6251\u6307\u6807\u8bc4\u4f30\u8d28\u91cf\u3002", "result": "CADmium\u80fd\u591f\u663e\u8457\u52a0\u901f\u65b0\u5bf9\u8c61\u7684CAD\u8bbe\u8ba1\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u5316CAD\u8bbe\u8ba1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u65b0\u6570\u636e\u96c6\u548c\u6307\u6807\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2507.09427", "pdf": "https://arxiv.org/pdf/2507.09427", "abs": "https://arxiv.org/abs/2507.09427", "authors": ["Sonia Marin", "Paaras Padhiar"], "title": "Justification Logic for Intuitionistic Modal Logic (Extended Technical Report)", "categories": ["cs.LO", "math.LO"], "comment": null, "summary": "Justification logics are an explication of modal logic; boxes are replaced\nwith proof terms formally through realisation theorems. This can be achieved\nsyntactically using a cut-free proof system e.g. using sequent, hypersequent or\nnested sequent calculi. In constructive modal logic, boxes and diamonds are\ndecoupled and not De Morgan dual. Kuznets, Marin and Stra{\\ss}burger provide a\njustification counterpart to constructive modal logic CK and some extensions by\nmaking diamonds explicit by introducing new terms called satisfiers. We\ncontinue the line of work to provide a justification counterpart to Fischer\nServi's intuitionistic modal logic IK and its extensions with the t and 4\naxioms. We: extend the syntax of proof terms to accommodate the additional\naxioms of intuitionistic modal logic; provide an axiomatisation of these\njustification logics; provide a syntactic realisation procedure using a\ncut-free nested sequent system for intuitionistic modal logic introduced by\nStra{\\ss}burger.", "AI": {"tldr": "\u672c\u6587\u4e3a\u76f4\u89c9\u4e3b\u4e49\u6a21\u6001\u903b\u8f91IK\u53ca\u5176\u6269\u5c55\u63d0\u4f9b\u4e86\u6b63\u5f53\u6027\u903b\u8f91\u7684\u5bf9\u5e94\uff0c\u6269\u5c55\u4e86\u8bc1\u660e\u9879\u8bed\u6cd5\u5e76\u5f15\u5165\u4e86\u65e0\u5272\u5d4c\u5957\u5e8f\u5217\u7cfb\u7edf\u3002", "motivation": "\u63a2\u7d22\u76f4\u89c9\u4e3b\u4e49\u6a21\u6001\u903b\u8f91IK\u53ca\u5176\u6269\u5c55\u7684\u6b63\u5f53\u6027\u903b\u8f91\u5bf9\u5e94\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u6269\u5c55\u8bc1\u660e\u9879\u8bed\u6cd5\u4ee5\u9002\u5e94\u76f4\u89c9\u4e3b\u4e49\u6a21\u6001\u903b\u8f91\u7684\u516c\u7406\uff0c\u63d0\u51fa\u6b63\u5f53\u6027\u903b\u8f91\u7684\u516c\u7406\u5316\uff0c\u5e76\u5229\u7528Stra\u00dfburger\u7684\u65e0\u5272\u5d4c\u5957\u5e8f\u5217\u7cfb\u7edf\u8fdb\u884c\u5b9e\u73b0\u3002", "result": "\u6210\u529f\u4e3aIK\u53ca\u5176\u6269\u5c55\u63d0\u4f9b\u4e86\u6b63\u5f53\u6027\u903b\u8f91\u7684\u516c\u7406\u5316\u548c\u5b9e\u73b0\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u6b63\u5f53\u6027\u903b\u8f91\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u76f4\u89c9\u4e3b\u4e49\u6a21\u6001\u903b\u8f91\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u73b0\u5de5\u5177\u3002"}}
{"id": "2507.09495", "pdf": "https://arxiv.org/pdf/2507.09495", "abs": "https://arxiv.org/abs/2507.09495", "authors": ["Hang Wang", "Junshan Zhang"], "title": "GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective", "categories": ["cs.AI", "cs.ET", "cs.HC", "cs.RO", "cs.SY", "eess.SY"], "comment": "Position paper", "summary": "Multi-agent reinforcement learning faces fundamental challenges that\nconventional approaches have failed to overcome: exponentially growing joint\naction spaces, non-stationary environments where simultaneous learning creates\nmoving targets, and partial observability that constrains coordination. Current\nmethods remain reactive, employing stimulus-response mechanisms that fail when\nfacing novel scenarios. We argue for a transformative paradigm shift from\nreactive to proactive multi-agent intelligence through generative AI-based\nreinforcement learning. This position advocates reconceptualizing agents not as\nisolated policy optimizers, but as sophisticated generative models capable of\nsynthesizing complex multi-agent dynamics and making anticipatory decisions\nbased on predictive understanding of future interactions. Rather than\nresponding to immediate observations, generative-RL agents can model\nenvironment evolution, predict other agents' behaviors, generate coordinated\naction sequences, and engage in strategic reasoning accounting for long-term\ndynamics. This approach leverages pattern recognition and generation\ncapabilities of generative AI to enable proactive decision-making, seamless\ncoordination through enhanced communication, and dynamic adaptation to evolving\nscenarios. We envision this paradigm shift will unlock unprecedented\npossibilities for distributed intelligence, moving beyond individual\noptimization toward emergent collective behaviors representing genuine\ncollaborative intelligence. The implications extend across autonomous systems,\nrobotics, and human-AI collaboration, promising solutions to coordination\nchallenges intractable under traditional reactive frameworks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u751f\u6210\u5f0fAI\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u4ece\u88ab\u52a8\u53cd\u5e94\u8f6c\u5411\u4e3b\u52a8\u9884\u6d4b\u51b3\u7b56\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u7206\u70b8\u3001\u73af\u5883\u975e\u5e73\u7a33\u6027\u548c\u90e8\u5206\u89c2\u6d4b\u6027\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u88ab\u52a8\u53cd\u5e94\uff0c\u65e0\u6cd5\u5e94\u5bf9\u65b0\u573a\u666f\u3002", "method": "\u63d0\u51fa\u5c06\u667a\u80fd\u4f53\u91cd\u6784\u4e3a\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u9884\u6d4b\u73af\u5883\u6f14\u53d8\u548c\u5176\u4ed6\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u751f\u6210\u534f\u8c03\u52a8\u4f5c\u5e8f\u5217\uff0c\u5e76\u57fa\u4e8e\u957f\u671f\u52a8\u6001\u8fdb\u884c\u6218\u7565\u63a8\u7406\u3002", "result": "\u751f\u6210\u5f0f\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u53ef\u5b9e\u73b0\u4e3b\u52a8\u51b3\u7b56\u3001\u65e0\u7f1d\u534f\u8c03\u548c\u52a8\u6001\u9002\u5e94\uff0c\u5c55\u73b0\u51fa\u96c6\u4f53\u534f\u4f5c\u667a\u80fd\u7684\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u6709\u671b\u5728\u81ea\u4e3b\u7cfb\u7edf\u3001\u673a\u5668\u4eba\u548c\u4eba\u673a\u534f\u4f5c\u7b49\u9886\u57df\u89e3\u51b3\u4f20\u7edf\u6846\u67b6\u96be\u4ee5\u5904\u7406\u7684\u534f\u8c03\u95ee\u9898\u3002"}}
{"id": "2507.10069", "pdf": "https://arxiv.org/pdf/2507.10069", "abs": "https://arxiv.org/abs/2507.10069", "authors": ["Zedong Liu", "Shenggan Cheng", "Guangming Tan", "Yang You", "Dingwen Tao"], "title": "ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Multimodal large language models (MLLMs) extend LLMs to handle images,\nvideos, and audio by incorporating feature extractors and projection modules.\nHowever, these additional components -- combined with complex inference\npipelines and heterogeneous workloads -- introduce significant inference\noverhead. Therefore, efficiently serving MLLMs remains a major challenge.\nCurrent tightly coupled serving architectures struggle to distinguish between\nmixed request types or adapt parallelism strategies to different inference\nstages, leading to increased time-to-first-token (TTFT) latency and poor\nresource utilization. To address this, we propose Elastic Multimodal\nParallelism (EMP), a new serving paradigm that elastically adapts to resource\nheterogeneity across request types and inference stages. Building upon EMP, we\ndevelop ElasticMM, an MLLM serving system that (1) separates requests into\nindependent modality groups with dynamic resource allocation via a\nmodality-aware load balancer; (2) decouples inference stages and enables\nparallelism adjustment and adaptive scaling via elastic partition scheduling;\nand (3) improves inference efficiency through unified multimodal prefix caching\nand non-blocking encoding. Experiments on diverse real-world datasets show that\nElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by\nup to 4.2x and achieving 3.2-4.5x higher throughput while meeting service-level\nobjectives (SLOs).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aElastic Multimodal Parallelism (EMP)\u7684\u65b0\u670d\u52a1\u8303\u5f0f\uff0c\u4ee5\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\u5728\u63a8\u7406\u65f6\u7684\u6548\u7387\u95ee\u9898\u3002\u901a\u8fc7ElasticMM\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u8d44\u6e90\u5206\u914d\u3001\u5e76\u884c\u8c03\u6574\u548c\u7f13\u5b58\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u3002", "motivation": "\u7531\u4e8eMLLM\u5728\u63a8\u7406\u65f6\u9700\u8981\u5904\u7406\u590d\u6742\u7684\u591a\u6a21\u6001\u6570\u636e\u548c\u5f02\u6784\u8d1f\u8f7d\uff0c\u4f20\u7edf\u7684\u670d\u52a1\u67b6\u6784\u96be\u4ee5\u9ad8\u6548\u5e94\u5bf9\uff0c\u5bfc\u81f4\u5ef6\u8fdf\u9ad8\u548c\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3002", "method": "\u63d0\u51faEMP\u8303\u5f0f\uff0c\u5f00\u53d1\u4e86ElasticMM\u7cfb\u7edf\uff0c\u5305\u62ec\u6a21\u6001\u611f\u77e5\u8d1f\u8f7d\u5747\u8861\u3001\u5f39\u6027\u5206\u533a\u8c03\u5ea6\u548c\u7edf\u4e00\u591a\u6a21\u6001\u524d\u7f00\u7f13\u5b58\u7b49\u5173\u952e\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cElasticMM\u6bd4\u73b0\u6709\u7cfb\u7edf\u964d\u4f4e\u4e864.2\u500d\u7684TTFT\u5ef6\u8fdf\uff0c\u63d0\u5347\u4e863.2-4.5\u500d\u7684\u541e\u5410\u91cf\uff0c\u540c\u65f6\u6ee1\u8db3\u670d\u52a1\u7ea7\u522b\u76ee\u6807\u3002", "conclusion": "EMP\u548cElasticMM\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u670d\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2507.09730", "pdf": "https://arxiv.org/pdf/2507.09730", "abs": "https://arxiv.org/abs/2507.09730", "authors": ["Jiechen Huang", "Wenjian Yu"], "title": "Efficient FRW Transitions via Stochastic Finite Differences for Handling Non-Stratified Dielectrics", "categories": ["cs.AR", "cs.NA", "math.NA"], "comment": "5 pages, 6 figures", "summary": "The accuracy of floating-random-walk (FRW) based capacitance extraction\nstands only when the recursive FRW transitions are sampled unbiasedly according\nto surrounding dielectrics. Advanced technology profiles, featuring complicated\nnon-stratified dielectrics, challenge the accuracy of existing FRW transition\nschemes that approximate dielectrics with stratified or eight-octant patterns.\nIn this work, we propose an algorithm named MicroWalk, enabling accurate FRW\ntransitions for arbitrary dielectrics while keeping high efficiency. It is\nprovably unbiased and equivalent to using transition probabilities solved by\nfinite difference method, but at orders of magnitude lower cost (802$\\times$\nfaster). An enhanced 3-D capacitance solver is developed with a hybrid strategy\nfor complicated dielectrics, combining MicroWalk with the special treatment for\nthe first transition cube and the analytical algorithm for stratified cubes.\nExperiments on real-world structures show that our solver achieves a\nsignificant accuracy advantage over existing FRW solvers, while preserving high\nefficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMicroWalk\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u590d\u6742\u7684\u975e\u5206\u5c42\u4ecb\u8d28\u4e2d\u5b9e\u73b0\u51c6\u786e\u4e14\u9ad8\u6548\u7684\u7535\u5bb9\u91cf\u63d0\u53d6\u3002", "motivation": "\u73b0\u6709\u968f\u673a\u6e38\u8d70\uff08FRW\uff09\u65b9\u6cd5\u5728\u590d\u6742\u4ecb\u8d28\u4e2d\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faMicroWalk\u7b97\u6cd5\uff0c\u7ed3\u5408\u6709\u9650\u5dee\u5206\u6cd5\u548c\u9ad8\u6548\u7387\u7684\u8fc7\u6e21\u7b56\u7565\uff0c\u5904\u7406\u4efb\u610f\u4ecb\u8d28\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u4f18\u52bf\uff08802\u500d\u63d0\u901f\uff09\u3002", "conclusion": "MicroWalk\u4e3a\u590d\u6742\u4ecb\u8d28\u4e2d\u7684\u7535\u5bb9\u91cf\u63d0\u53d6\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u7cbe\u5ea6\u4e14\u9ad8\u6548\u7684\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09642", "pdf": "https://arxiv.org/pdf/2507.09642", "abs": "https://arxiv.org/abs/2507.09642", "authors": ["Yina Lv", "Qiao Li", "Quanqing Xu", "Congming Gao", "Chuanhui Yang", "Xiaoli Wang", "Chun Jason Xue"], "title": "Rethinking LSM-tree based Key-Value Stores: A Survey", "categories": ["cs.DB"], "comment": null, "summary": "LSM-tree is a widely adopted data structure in modern key-value store systems\nthat optimizes write performance in write-heavy applications by using append\nwrites to achieve sequential writes. However, the unpredictability of LSM-tree\ncompaction introduces significant challenges, including performance variability\nduring peak workloads and in resource-constrained environments, write\namplification caused by data rewriting during compactions, read amplification\nfrom multi-level queries, trade-off between read and write performance, as well\nas efficient space utilization to mitigate space amplification. Prior studies\non LSM-tree optimizations have addressed the above challenges; however, in\nrecent years, research on LSM-tree optimization has continued to propose. The\ngoal of this survey is to review LSM-tree optimization, focusing on\nrepresentative works in the past five years. This survey first studies existing\nsolutions on how to mitigate the performance impact of LSM-tree flush and\ncompaction and how to improve basic key-value operations. In addition,\ndistributed key-value stores serve multi-tenants, ranging from tens of\nthousands to millions of users with diverse requirements. We then analyze the\nnew challenges and opportunities in these modern architectures and across\nvarious application scenarios. Unlike the existing survey papers, this survey\nprovides a detailed discussion of the state-of-the-art work on LSM-tree\noptimizations and gives future research directions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86LSM-tree\u5728\u952e\u503c\u5b58\u50a8\u7cfb\u7edf\u4e2d\u7684\u4f18\u5316\u5de5\u4f5c\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u8fc7\u53bb\u4e94\u5e74\u7684\u4ee3\u8868\u6027\u7814\u7a76\uff0c\u65e8\u5728\u89e3\u51b3LSM-tree\u5728\u6027\u80fd\u53d8\u5f02\u6027\u3001\u8bfb\u5199\u653e\u5927\u7b49\u95ee\u9898\u4e0a\u7684\u6311\u6218\uff0c\u5e76\u63a2\u8ba8\u5206\u5e03\u5f0f\u573a\u666f\u4e0b\u7684\u65b0\u673a\u9047\u3002", "motivation": "LSM-tree\u5728\u5199\u5bc6\u96c6\u578b\u5e94\u7528\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u4e0d\u53ef\u9884\u6d4b\u7684\u538b\u7f29\u64cd\u4f5c\u5bfc\u81f4\u6027\u80fd\u53d8\u5f02\u6027\u3001\u8bfb\u5199\u653e\u5927\u7b49\u95ee\u9898\u3002\u5c3d\u7ba1\u5df2\u6709\u4f18\u5316\u7814\u7a76\uff0c\u4f46\u8fd1\u5e74\u6765\u4ecd\u4e0d\u65ad\u6709\u65b0\u7814\u7a76\u6d8c\u73b0\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u5bf9\u6700\u65b0\u7684\u4f18\u5316\u5de5\u4f5c\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\u3002", "method": "\u901a\u8fc7\u7efc\u8ff0\u8fc7\u53bb\u4e94\u5e74\u4e2d\u5177\u6709\u4ee3\u8868\u6027\u7684LSM-tree\u4f18\u5316\u7814\u7a76\u5de5\u4f5c\uff0c\u5206\u6790\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5982\u4f55\u51cf\u8f7bflush\u548c\u538b\u7f29\u7684\u6027\u80fd\u5f71\u54cd\uff0c\u5e76\u63d0\u5347\u57fa\u7840\u952e\u503c\u64cd\u4f5c\u6548\u7387\u3002\u540c\u65f6\uff0c\u63a2\u8ba8\u5206\u5e03\u5f0f\u591a\u79df\u6237\u67b6\u6784\u4e0b\u7684\u65b0\u6311\u6218\u4e0e\u673a\u9047\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86LSM-tree\u4f18\u5316\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u63d0\u4f9b\u4e86\u5bf9\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u8be6\u7ec6\u5206\u6790\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u8fd9\u7bc7\u7efc\u8ff0\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u7684\u7a7a\u767d\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86LSM-tree\u4f18\u5316\u7684\u524d\u6cbf\u5de5\u4f5c\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u7684\u7814\u7a76\u8d8b\u52bf\u3002"}}
{"id": "2507.09100", "pdf": "https://arxiv.org/pdf/2507.09100", "abs": "https://arxiv.org/abs/2507.09100", "authors": ["Mohammad Abolnejadian", "Shakiba Amirshahi", "Matthew Brehmer", "Anamaria Crisan"], "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.0"], "comment": "7 pages and 4 figures. Proceedings of the 7th ACM Conference on\n  Conversational User Interfaces (CUI '25)", "summary": "In decision-making conversations, experts must navigate complex choices and\nmake on-the-spot decisions while engaged in conversation. Although extensive\nhistorical data often exists, the real-time nature of these scenarios makes it\ninfeasible for decision-makers to review and leverage relevant information.\nThis raises an interesting question: What if experts could utilize relevant\npast data in real-time decision-making through insights derived from past data?\nTo explore this, we implemented a conversational user interface, taking\ndoctor-patient interactions as an example use case. Our system continuously\nlistens to the conversation, identifies patient problems and doctor-suggested\nsolutions, and retrieves related data from an embedded dataset, generating\nconcise insights using a pipeline built around a retrieval-based Large Language\nModel (LLM) agent. We evaluated the prototype by embedding Health Canada\ndatasets into a vector database and conducting simulated studies using sample\ndoctor-patient dialogues, showing effectiveness but also challenges, setting\ndirections for the next steps of our work.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u5728\u5b9e\u65f6\u51b3\u7b56\u5bf9\u8bdd\u4e2d\u5229\u7528\u5386\u53f2\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5b9e\u65f6\u5bf9\u8bdd\u754c\u9762\uff0c\u5e2e\u52a9\u4e13\u5bb6\uff08\u5982\u533b\u751f\uff09\u5728\u5bf9\u8bdd\u4e2d\u83b7\u53d6\u76f8\u5173\u6570\u636e\u652f\u6301\u3002", "motivation": "\u4e13\u5bb6\u5728\u5b9e\u65f6\u51b3\u7b56\u5bf9\u8bdd\u4e2d\u96be\u4ee5\u5229\u7528\u5386\u53f2\u6570\u636e\uff0c\u5bfc\u81f4\u51b3\u7b56\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u6b64\u7814\u7a76\u5e0c\u671b\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u5b9e\u65f6\u76d1\u542c\u5bf9\u8bdd\u3001\u8bc6\u522b\u95ee\u9898\u5e76\u63d0\u4f9b\u76f8\u5173\u6570\u636e\u652f\u6301\uff0c\u5229\u7528\u5d4c\u5165\u6570\u636e\u96c6\u548c\u5411\u91cf\u6570\u636e\u5e93\u68c0\u7d22\u4fe1\u606f\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u6709\u6548\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u6311\u6218\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86\u5728\u5b9e\u65f6\u51b3\u7b56\u4e2d\u5229\u7528\u5386\u53f2\u6570\u636e\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u5e94\u5bf9\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2507.09135", "pdf": "https://arxiv.org/pdf/2507.09135", "abs": "https://arxiv.org/abs/2507.09135", "authors": ["Yalong Du", "Chaozheng Wang", "Huaijin Wang"], "title": "Position Paper: Programming Language Techniques for Bridging LLM Code Generation Semantic Gaps", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models have demonstrated remarkable capabilities in automated\ncode generation, yet their statistical nature and black-box characteristics\ncreate significant semantic gaps manifested through syntax errors, semantic\nhallucinations, and reliability concerns. This position paper argues that\nprincipled integration of Programming Language (PL) techniques is essential for\nbridging these gaps. Through structured program representations, formal\ncorrectness guarantees, and robust verification mechanisms, PL techniques can\nelevate LLM-generated code from statistical pattern matching to truly reliable\nand trustworthy levels. This integration is crucial for developing systems that\ngenerate code that is not only functionally correct but also interpretable,\nverifiable, and ultimately trustworthy.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5c06\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\uff08PL\uff09\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\uff0c\u4ee5\u89e3\u51b3LLM\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u8bed\u4e49\u7f3a\u9677\uff0c\u63d0\u5347\u4ee3\u7801\u7684\u53ef\u9760\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u7edf\u8ba1\u7279\u6027\u548c\u9ed1\u7bb1\u6027\u8d28\u5bfc\u81f4\u8bed\u4e49\u7f3a\u9677\uff0c\u5982\u8bed\u6cd5\u9519\u8bef\u3001\u8bed\u4e49\u5e7b\u89c9\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u7a0b\u5e8f\u8868\u793a\u3001\u5f62\u5f0f\u5316\u6b63\u786e\u6027\u4fdd\u8bc1\u548c\u9c81\u68d2\u7684\u9a8c\u8bc1\u673a\u5236\uff0cPL\u6280\u672f\u53ef\u4ee5\u586b\u8865LLM\u751f\u6210\u4ee3\u7801\u7684\u8bed\u4e49\u7f3a\u9677\u3002", "result": "PL\u6280\u672f\u80fd\u591f\u5c06LLM\u751f\u6210\u7684\u4ee3\u7801\u4ece\u5355\u7eaf\u7684\u7edf\u8ba1\u6a21\u5f0f\u5339\u914d\u63d0\u5347\u5230\u53ef\u9760\u548c\u53ef\u4fe1\u7684\u6c34\u5e73\u3002", "conclusion": "LLM\u4e0ePL\u6280\u672f\u7684\u7ed3\u5408\u5bf9\u4e8e\u751f\u6210\u529f\u80fd\u6b63\u786e\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u9a8c\u8bc1\u4e14\u53ef\u4fe1\u7684\u4ee3\u7801\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.10099", "pdf": "https://arxiv.org/pdf/2507.10099", "abs": "https://arxiv.org/abs/2507.10099", "authors": ["Jay Lee", "Gyuhyeok Oh", "Joongwon Ahn", "Xiaokang Qiu"], "title": "ReDemon UI: Reactive Synthesis by Demonstration for Web UI", "categories": ["cs.HC", "cs.PL"], "comment": "Submitted to UIST 2025 Posters", "summary": "ReDemon UI synthesizes React applications from user demonstrations, enabling\ndesigners and non-expert programmers to create UIs that integrate with standard\nUI prototyping workflows. Users provide a static mockup sketch with event\nhandler holes and demonstrate desired runtime behaviors by interacting with the\nrendered mockup and editing the sketch. ReDemon UI identifies reactive data and\nsynthesizes a React program with correct state update logic. We utilize\nenumerative synthesis for simple UIs and LLMs for more complex UIs.", "AI": {"tldr": "ReDemon UI \u901a\u8fc7\u7528\u6237\u6f14\u793a\u5408\u6210 React \u5e94\u7528\uff0c\u652f\u6301\u8bbe\u8ba1\u5e08\u548c\u975e\u4e13\u4e1a\u7a0b\u5e8f\u5458\u521b\u5efa\u7b26\u5408\u6807\u51c6 UI \u539f\u578b\u5de5\u4f5c\u6d41\u7a0b\u7684\u754c\u9762\u3002", "motivation": "\u65e8\u5728\u7b80\u5316 UI \u5f00\u53d1\u6d41\u7a0b\uff0c\u4f7f\u975e\u4e13\u5bb6\u4e5f\u80fd\u53c2\u4e0e React \u5e94\u7528\u7684\u521b\u5efa\u3002", "method": "\u7528\u6237\u63d0\u4f9b\u9759\u6001\u8349\u56fe\u5e76\u6f14\u793a\u4ea4\u4e92\u884c\u4e3a\uff1b\u7cfb\u7edf\u7ed3\u5408\u679a\u4e3e\u5408\u6210\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210 React \u7a0b\u5e8f\u3002", "result": "\u5b9e\u73b0\u4e86\u81ea\u52a8\u8bc6\u522b\u53cd\u5e94\u6570\u636e\u548c\u6b63\u786e\u72b6\u6001\u66f4\u65b0\u903b\u8f91\u7684 React \u7a0b\u5e8f\u5408\u6210\u3002", "conclusion": "ReDemon UI \u4e3a\u975e\u4e13\u4e1a\u5f00\u53d1\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684 UI \u5f00\u53d1\u5de5\u5177\u3002"}}
{"id": "2507.09346", "pdf": "https://arxiv.org/pdf/2507.09346", "abs": "https://arxiv.org/abs/2507.09346", "authors": ["Arild Yonkeu", "Mohammadreza Amini", "Burak Kantarci"], "title": "Fast and Adaptive Task Management in MEC: A Deep Learning Approach Using Pointer Networks", "categories": ["cs.NI"], "comment": "8 pages, 8 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025", "summary": "Task offloading and scheduling in Mobile Edge Computing (MEC) are vital for\nmeeting the low-latency demands of modern IoT and dynamic task scheduling\nscenarios. MEC reduces the processing burden on resource-constrained devices by\nenabling task execution at nearby edge servers. However, efficient task\nscheduling remains a challenge in dynamic, time-sensitive environments.\nConventional methods -- such as heuristic algorithms and mixed-integer\nprogramming -- suffer from high computational overhead, limiting their\nreal-time applicability. Existing deep learning (DL) approaches offer faster\ninference but often lack scalability and adaptability to dynamic workloads. To\naddress these issues, we propose a Pointer Network-based architecture for task\nscheduling in dynamic edge computing scenarios. Our model is trained on a\ngenerated synthetic dataset using genetic algorithms to determine the optimal\ntask ordering. Experimental results show that our model achieves lower drop\nratios and waiting times than baseline methods, and a soft sequence accuracy of\nup to 89.2%. Our model consistently achieves inference times under 2 seconds\nacross all evaluated task counts, whereas the integer and binary programming\napproaches require approximately up to 18 seconds and 90 seconds, respectively.\nIt also shows strong generalization across varying scenarios, and adaptability\nto real-time changes, offering a scalable and efficient solution for edge-based\ntask management.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6307\u9488\u7f51\u7edc\u7684\u52a8\u6001\u8fb9\u7f18\u8ba1\u7b97\u4efb\u52a1\u8c03\u5ea6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u548c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5b9e\u65f6\u6027\u548c\u9002\u5e94\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u4e2d\u4efb\u52a1\u5378\u8f7d\u4e0e\u8c03\u5ea6\u7684\u4f4e\u5ef6\u8fdf\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u9ad8\u8ba1\u7b97\u5f00\u9500\u6216\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u6027\u3002", "method": "\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3\u6307\u9488\u7f51\u7edc\u6a21\u578b\uff0c\u4f18\u5316\u4efb\u52a1\u8c03\u5ea6\u987a\u5e8f\u3002", "result": "\u6a21\u578b\u5728\u4e22\u5f03\u7387\u548c\u7b49\u5f85\u65f6\u95f4\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e8f\u5217\u51c6\u786e\u7387\u8fbe89.2%\uff0c\u63a8\u7406\u65f6\u95f4\u4f4e\u4e8e2\u79d2\uff0c\u8fdc\u5feb\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u65b9\u6848\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u8fb9\u7f18\u4efb\u52a1\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09256", "pdf": "https://arxiv.org/pdf/2507.09256", "abs": "https://arxiv.org/abs/2507.09256", "authors": ["Junyu Chen", "Yihua Gao", "Mingyuan Ge", "Mingyong Li"], "title": "Ambiguity-Aware and High-Order Relation Learning for Multi-Grained Image-Text Matching", "categories": ["cs.CV", "cs.IR", "cs.MM"], "comment": "Accepted by the Knowledge-Based Systems(KBS), 2025", "summary": "Image-text matching is crucial for bridging the semantic gap between computer\nvision and natural language processing. However, existing methods still face\nchallenges in handling high-order associations and semantic ambiguities among\nsimilar instances. These ambiguities arise from subtle differences between soft\npositive samples (semantically similar but incorrectly labeled) and soft\nnegative samples (locally matched but globally inconsistent), creating matching\nuncertainties. Furthermore, current methods fail to fully utilize the\nneighborhood relationships among semantically similar instances within training\nbatches, limiting the model's ability to learn high-order shared knowledge.\nThis paper proposes the Ambiguity-Aware and High-order Relation learning\nframework (AAHR) to address these issues. AAHR constructs a unified\nrepresentation space through dynamic clustering prototype contrastive learning,\neffectively mitigating the soft positive sample problem. The framework\nintroduces global and local feature extraction mechanisms and an adaptive\naggregation network, significantly enhancing full-grained semantic\nunderstanding capabilities. Additionally, AAHR employs intra-modal and\ninter-modal correlation matrices to investigate neighborhood relationships\namong sample instances thoroughly. It incorporates GNN to enhance semantic\ninteractions between instances. Furthermore, AAHR integrates momentum\ncontrastive learning to expand the negative sample set. These combined\nstrategies significantly improve the model's ability to discriminate between\nfeatures. Experimental results demonstrate that AAHR outperforms existing\nstate-of-the-art methods on Flickr30K, MSCOCO, and ECCV Caption datasets,\nconsiderably improving the accuracy and efficiency of image-text matching. The\ncode and model checkpoints for this research are available at\nhttps://github.com/Image-Text-Matching/AAHR .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AAHR\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u805a\u7c7b\u539f\u578b\u5bf9\u6bd4\u5b66\u4e60\u548c\u7279\u5f81\u63d0\u53d6\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u50cf-\u6587\u672c\u5339\u914d\u4e2d\u7684\u8bed\u4e49\u6a21\u7cca\u6027\u548c\u9ad8\u9636\u5173\u8054\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u76f8\u4f3c\u5b9e\u4f8b\u7684\u9ad8\u9636\u5173\u8054\u548c\u8bed\u4e49\u6a21\u7cca\u6027\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u8f6f\u6b63\u6837\u672c\u548c\u8f6f\u8d1f\u6837\u672c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u53ca\u672a\u80fd\u5145\u5206\u5229\u7528\u90bb\u5c45\u5173\u7cfb\u3002", "method": "AAHR\u91c7\u7528\u52a8\u6001\u805a\u7c7b\u539f\u578b\u5bf9\u6bd4\u5b66\u4e60\u6784\u5efa\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\uff0c\u7ed3\u5408\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\u673a\u5236\u3001\u81ea\u9002\u5e94\u805a\u5408\u7f51\u7edc\u53caGNN\uff0c\u589e\u5f3a\u8bed\u4e49\u4ea4\u4e92\u3002", "result": "AAHR\u5728Flickr30K\u3001MSCOCO\u548cECCV Caption\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5339\u914d\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "AAHR\u901a\u8fc7\u7efc\u5408\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u50cf-\u6587\u672c\u5339\u914d\u4e2d\u7684\u8bed\u4e49\u6a21\u7cca\u6027\u548c\u9ad8\u9636\u5173\u8054\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.10542", "pdf": "https://arxiv.org/pdf/2507.10542", "abs": "https://arxiv.org/abs/2507.10542", "authors": ["Shivangi Aneja", "Sebastian Weiss", "Irene Baeza", "Prashanth Chandran", "Gaspard Zoss", "Matthias Nie\u00dfner", "Derek Bradley"], "title": "ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "(SIGGRAPH 2025) Paper Video: https://youtu.be/VyWkgsGdbkk Project\n  Page: https://shivangi-aneja.github.io/projects/scaffoldavatar/", "summary": "Generating high-fidelity real-time animated sequences of photorealistic 3D\nhead avatars is important for many graphics applications, including immersive\ntelepresence and movies. This is a challenging problem particularly when\nrendering digital avatar close-ups for showing character's facial microfeatures\nand expressions. To capture the expressive, detailed nature of human heads,\nincluding skin furrowing and finer-scale facial movements, we propose to couple\nlocally-defined facial expressions with 3D Gaussian splatting to enable\ncreating ultra-high fidelity, expressive and photorealistic 3D head avatars. In\ncontrast to previous works that operate on a global expression space, we\ncondition our avatar's dynamics on patch-based local expression features and\nsynthesize 3D Gaussians at a patch level. In particular, we leverage a\npatch-based geometric 3D face model to extract patch expressions and learn how\nto translate these into local dynamic skin appearance and motion by coupling\nthe patches with anchor points of Scaffold-GS, a recent hierarchical scene\nrepresentation. These anchors are then used to synthesize 3D Gaussians\non-the-fly, conditioned by patch-expressions and viewing direction. We employ\ncolor-based densification and progressive training to obtain high-quality\nresults and faster convergence for high resolution 3K training images. By\nleveraging patch-level expressions, ScaffoldAvatar consistently achieves\nstate-of-the-art performance with visually natural motion, while encompassing\ndiverse facial expressions and styles in real time.", "AI": {"tldr": "\u57fa\u4e8e\u5c40\u90e8\u8868\u60c5\u7279\u5f81\u548c3D\u9ad8\u65af\u6e85\u5c04\u6280\u672f\uff0c\u63d0\u51fa\u4e00\u79cd\u751f\u6210\u9ad8\u4fdd\u771f3D\u5934\u90e8\u52a8\u753b\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5b9e\u65f6\u591a\u6837\u8868\u60c5\u6e32\u67d3\u3002", "motivation": "\u4e3a\u5b9e\u73b0\u6c89\u6d78\u5f0f\u8fdc\u7a0b\u5448\u73b0\u548c\u7535\u5f71\u4e2d\u9ad8\u4fdd\u771f3D\u5934\u90e8\u52a8\u753b\u7684\u5b9e\u65f6\u751f\u6210\uff0c\u9700\u89e3\u51b3\u9762\u90e8\u5fae\u89c2\u7279\u5f81\u548c\u8868\u60c5\u7684\u7ec6\u8282\u6e32\u67d3\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c40\u90e8\u8868\u60c5\u7279\u5f81\u4e0e3D\u9ad8\u65af\u6e85\u5c04\u6280\u672f\u7ed3\u5408\uff0c\u5229\u7528\u5206\u5757\u51e0\u4f55\u6a21\u578b\u63d0\u53d6\u8868\u60c5\u7279\u5f81\uff0c\u5e76\u52a8\u6001\u5408\u62103D\u9ad8\u65af\u70b9\u3002", "result": "ScaffoldAvatar\u5728\u591a\u6837\u8868\u60c5\u548c\u98ce\u683c\u4e2d\u5b9e\u73b0\u81ea\u7136\u52a8\u6001\u6e32\u67d3\uff0c\u8fbe\u5230\u4e1a\u754c\u9886\u5148\u6c34\u5e73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c40\u90e8\u8868\u60c5\u548c\u9ad8\u65af\u6e85\u5c04\u7684\u6709\u6548\u7ed3\u5408\uff0c\u4e3a\u9ad8\u4fdd\u771f3D\u5934\u90e8\u52a8\u753b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09708", "pdf": "https://arxiv.org/pdf/2507.09708", "abs": "https://arxiv.org/abs/2507.09708", "authors": ["Apekshya Bhattarai", "Dinisha Uprety", "Pooja Pathak", "Safal Narshing Shrestha", "Salina Narkarmi", "Sanjog Sigdel"], "title": "A Study Of Sudoku Solving Algorithms: Backtracking and Heuristic", "categories": ["cs.LO"], "comment": "14 pages", "summary": "This paper presents a comparative analysis of Sudoku-solving strategies,\nfocusing on recursive backtracking and a heuristic-based constraint propagation\nmethod. Using a dataset of 500 puzzles across five difficulty levels (Beginner\nto Expert), we evaluated performance based on average solving time. The\nheuristic approach consistently outperformed backtracking, achieving speedup\nratios ranging from 1.27x in Beginner puzzles to 2.91x in Expert puzzles. These\nfindings underscore the effectiveness of heuristic strategies, particularly in\ntackling complex puzzles across varying difficulty levels.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u9012\u5f52\u56de\u6eaf\u548c\u542f\u53d1\u5f0f\u7ea6\u675f\u4f20\u64ad\u65b9\u6cd5\u5728\u6570\u72ec\u6c42\u89e3\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u901f\u5ea6\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u56de\u6eaf\u6cd5\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u4e0d\u540c\u6570\u72ec\u6c42\u89e3\u7b56\u7565\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u9012\u5f52\u56de\u6eaf\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u4e0d\u540c\u96be\u5ea6\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u5305\u542b500\u4e2a\u6570\u72ec\u8c1c\u9898\u7684\u6570\u636e\u96c6\uff0c\u5206\u4e3a\u4e94\u4e2a\u96be\u5ea6\u7ea7\u522b\uff0c\u901a\u8fc7\u5e73\u5747\u6c42\u89e3\u65f6\u95f4\u8bc4\u4f30\u4e24\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u6240\u6709\u96be\u5ea6\u7ea7\u522b\u5747\u8868\u73b0\u66f4\u4f18\uff0c\u901f\u5ea6\u63d0\u5347\u4ece\u5165\u95e8\u7ea7\u76841.27\u500d\u5230\u4e13\u5bb6\u7ea7\u76842.91\u500d\u3002", "conclusion": "\u542f\u53d1\u5f0f\u7b56\u7565\u5728\u590d\u6742\u6570\u72ec\u6c42\u89e3\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u96be\u5ea6\u8c1c\u9898\u4e2d\u8868\u73b0\u66f4\u9ad8\u6548\u3002"}}
{"id": "2507.09682", "pdf": "https://arxiv.org/pdf/2507.09682", "abs": "https://arxiv.org/abs/2507.09682", "authors": ["Laura Baird", "Armin Moin"], "title": "OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization", "categories": ["cs.SE", "cs.AI", "cs.ET"], "comment": "IEEE International Conference on Quantum Computing and Engineering\n  (QCE) 2025 - Extended Abstract", "summary": "We propose a novel approach, OrQstrator, which is a modular framework for\nconducting quantum circuit optimization in the Noisy Intermediate-Scale Quantum\n(NISQ) era. Our framework is powered by Deep Reinforcement Learning (DRL). Our\norchestration engine intelligently selects among three complementary circuit\noptimizers: A DRL-based circuit rewriter trained to reduce depth and gate count\nvia learned rewrite sequences; a domain-specific optimizer that performs\nefficient local gate resynthesis and numeric optimization; a parameterized\ncircuit instantiator that improves compilation by optimizing template circuits\nduring gate set translation. These modules are coordinated by a central\norchestration engine that learns coordination policies based on circuit\nstructure, hardware constraints, and backend-aware performance features such as\ngate count, depth, and expected fidelity. The system outputs an optimized\ncircuit for hardware-aware transpilation and execution, leveraging techniques\nfrom an existing state-of-the-art approach, called the NISQ Analyzer, to adapt\nto backend constraints.", "AI": {"tldr": "OrQstrator\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5728NISQ\u65f6\u4ee3\u4f18\u5316\u91cf\u5b50\u7535\u8def\uff0c\u901a\u8fc7\u667a\u80fd\u9009\u62e9\u4e09\u79cd\u4e92\u8865\u7684\u4f18\u5316\u5668\u6765\u51cf\u5c11\u6df1\u5ea6\u548c\u95e8\u6570\u3002", "motivation": "\u89e3\u51b3NISQ\u65f6\u4ee3\u91cf\u5b50\u7535\u8def\u4f18\u5316\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u786c\u4ef6\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u3001\u57df\u7279\u5b9a\u4f18\u5316\u5668\u548c\u53c2\u6570\u5316\u7535\u8def\u5b9e\u4f8b\u5316\u5668\uff0c\u901a\u8fc7\u4e2d\u592e\u534f\u8c03\u5f15\u64ce\u9009\u62e9\u4f18\u5316\u7b56\u7565\u3002", "result": "\u751f\u6210\u4f18\u5316\u540e\u7684\u7535\u8def\uff0c\u9002\u914d\u540e\u7aef\u786c\u4ef6\u7ea6\u675f\u3002", "conclusion": "OrQstrator\u6846\u67b6\u5728\u786c\u4ef6\u611f\u77e5\u7684\u91cf\u5b50\u7535\u8def\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7ed3\u5408\u591a\u79cd\u4f18\u5316\u6280\u672f\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.10139", "pdf": "https://arxiv.org/pdf/2507.10139", "abs": "https://arxiv.org/abs/2507.10139", "authors": ["Filipe Miguel Gon\u00e7alves de Almeida", "CJ Carey", "Hendrik Fichtenberger", "Jonathan Halcrow", "Silvio Lattanzi", "Andr\u00e9 Linhares", "Tao Meng", "Ashkan Norouzi-Fard", "Nikos Parotsidis", "Bryan Perozzi", "David Simcha"], "title": "Large-Scale Graph Building in Dynamic Environments: Low Latency and High Quality", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Learning and constructing large-scale graphs has attracted attention in\nrecent decades, resulting in a rich literature that introduced various systems,\ntools, and algorithms. Grale is one of such tools that is designed for offline\nenvironments and is deployed in more than 50 different industrial settings at\nGoogle. Grale is widely applicable because of its ability to efficiently learn\nand construct a graph on datasets with multiple types of features. However, it\nis often the case that applications require the underlying data to evolve\ncontinuously and rapidly and the updated graph needs to be available with low\nlatency. Such setting make the use of Grale prohibitive. While there are\nApproximate Nearest Neighbor (ANN) systems that handle dynamic updates with low\nlatency, they are mostly limited to similarities over a single embedding.\n  In this work, we introduce a system that inherits the advantages and the\nquality of Grale, and maintains a graph construction in a dynamic setting with\ntens of milliseconds of latency per request. We call the system Dynamic Grale\nUsing ScaNN (Dynamic GUS). Our system has a wide range of applications with\nover 10 deployments at Google. One of the applications is in Android Security\nand Privacy, where Dynamic Grale Using ScaNN enables capturing harmful\napplications 4 times faster, before they can reach users.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Dynamic Grale Using ScaNN\uff08Dynamic GUS\uff09\u7cfb\u7edf\uff0c\u7ed3\u5408Grale\u7684\u4f18\u70b9\u548cScaNN\u7684\u52a8\u6001\u5904\u7406\u80fd\u529b\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u7684\u56fe\u6784\u5efa\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5de5\u4e1a\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5982Grale\u867d\u5728\u79bb\u7ebf\u73af\u5883\u4e0b\u9ad8\u6548\uff0c\u4f46\u65e0\u6cd5\u5e94\u5bf9\u6570\u636e\u5feb\u901f\u52a8\u6001\u66f4\u65b0\u7684\u9700\u6c42\uff1b\u800c\u52a8\u6001ANN\u7cfb\u7edf\u4ec5\u9650\u4e8e\u5355\u4e00\u5d4c\u5165\u76f8\u4f3c\u6027\u3002\u56e0\u6b64\u9700\u8981\u7ed3\u5408Grale\u7684\u9ad8\u8d28\u91cf\u548c\u52a8\u6001\u5904\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faDynamic GUS\u7cfb\u7edf\uff0c\u7ee7\u627fGrale\u7684\u7b97\u6cd5\u4f18\u52bf\uff0c\u5e76\u5229\u7528ScaNN\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u52a8\u6001\u66f4\u65b0\u3002", "result": "\u7cfb\u7edf\u5728Google\u5185\u90e8\u6210\u529f\u90e8\u7f72\uff0c\u5176\u4e2d\u5728Android\u5b89\u5168\u4e0e\u9690\u79c1\u5e94\u7528\u4e2d\uff0c\u6709\u5bb3\u5e94\u7528\u7684\u6355\u83b7\u901f\u5ea6\u63d0\u5347\u4e864\u500d\u3002", "conclusion": "Dynamic GUS\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u56fe\u6784\u5efa\u7684\u9700\u6c42\uff0c\u517c\u5177\u9ad8\u8d28\u91cf\u548c\u4f4e\u5ef6\u8fdf\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.09774", "pdf": "https://arxiv.org/pdf/2507.09774", "abs": "https://arxiv.org/abs/2507.09774", "authors": ["MD Zobaer Hossain Bhuiyan", "Abir Bin Faruque", "Mahtab Newaz", "Mohammad Abdul Qayum"], "title": "Low-Cost Fuel Dispenser Prototype Using STM32 and an H-bridge motor driver", "categories": ["cs.AR"], "comment": null, "summary": "This paper presents the design and development of a low-cost fuel dispensing\nsystem prototype based on the STM32 microcontroller and L298N motor driver. The\nsystem aims to provide an affordable and scalable solution for fuel delivery in\nremote or small-scale environments where conventional, high-cost systems are\nnot feasible. The core control unit is built using an STM32 microcontroller,\nwhich manages user input through a 4x4 matrix keypad and displays operational\ndata on a 16x4 LCD screen via I2C communication. A 12V DC pump motor is used to\nsimulate the fuel dispensing mechanism, precisely controlled via the dual\nH-bridge L298N motor driver. The system is powered by a 11.1V battery and is\ndesigned for ease of deployment and portability. The keypad allows users to\ninput the desired fuel amount, while the system ensures accurate motor runtime\ncorresponding to the volume to be dispensed. This project demonstrates how\nembedded systems can be leveraged to build cost-effective, user-friendly, and\nenergy-efficient solutions. The proposed design can be further enhanced with\nflow sensors, GSM connectivity, RFID cards, and payment integration for\nreal-world applications in fuel stations or agricultural use.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8eSTM32\u5fae\u63a7\u5236\u5668\u548cL298N\u7535\u673a\u9a71\u52a8\u5668\u7684\u4f4e\u6210\u672c\u71c3\u6599\u5206\u914d\u7cfb\u7edf\u539f\u578b\uff0c\u9002\u7528\u4e8e\u504f\u8fdc\u6216\u5c0f\u89c4\u6a21\u73af\u5883\u3002", "motivation": "\u5728\u4f20\u7edf\u9ad8\u6210\u672c\u7cfb\u7edf\u4e0d\u53ef\u884c\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u71c3\u6599\u8f93\u9001\u63d0\u4f9b\u7ecf\u6d4e\u5b9e\u60e0\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528STM32\u5fae\u63a7\u5236\u5668\u7ba1\u7406\u7528\u6237\u8f93\u5165\u548c\u663e\u793a\u6570\u636e\uff0c\u901a\u8fc7L298N\u7535\u673a\u9a71\u52a8\u63a7\u523612V DC\u6cf5\u7535\u673a\uff0c\u6a21\u62df\u71c3\u6599\u5206\u914d\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u7cbe\u786e\u63a7\u5236\u71c3\u6599\u5206\u914d\u91cf\uff0c\u5c55\u793a\u4e86\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5728\u6784\u5efa\u7ecf\u6d4e\u9ad8\u6548\u3001\u7528\u6237\u53cb\u597d\u548c\u8282\u80fd\u89e3\u51b3\u65b9\u6848\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u53ef\u8fdb\u4e00\u6b65\u6269\u5c55\uff0c\u5982\u6dfb\u52a0\u6d41\u91cf\u4f20\u611f\u5668\u3001GSM\u8fde\u63a5\u548c\u652f\u4ed8\u96c6\u6210\uff0c\u9002\u7528\u4e8e\u52a0\u6cb9\u7ad9\u6216\u519c\u4e1a\u5e94\u7528\u3002"}}
{"id": "2507.10017", "pdf": "https://arxiv.org/pdf/2507.10017", "abs": "https://arxiv.org/abs/2507.10017", "authors": ["Zhiyang Tang", "Yanping Wu", "Xiangjun Zai", "Chen Chen", "Xiaoyang Wang", "Ying Zhang"], "title": "Efficient Temporal Simple Path Graph Generation", "categories": ["cs.DB"], "comment": null, "summary": "Interactions between two entities often occur at specific timestamps, which\ncan be modeled as a temporal graph. Exploring the relationships between\nvertices based on temporal paths is one of the fundamental tasks. In this\npaper, we conduct the first research to propose and investigate the problem of\ngenerating the temporal simple path graph (tspG), which is the subgraph\nconsisting of all temporal simple paths from the source vertex to the target\nvertex within the given time interval. Directly enumerating all temporal simple\npaths and constructing the tspG is computationally expensive. To accelerate the\nprocessing, we propose an efficient method named Verification in Upper-bound\nGraph. It first incorporates the temporal path constraint and simple path\nconstraint to exclude unpromising edges from the original graph, which obtains\na tight upper-bound graph as a high-quality approximation of the tspG in\npolynomial time. Then, an Escape Edges Verification algorithm is further\napplied in the upper-bound graph to construct the exact tspG without\nexhaustively enumerating all temporal simple paths between given vertices.\nFinally, comprehensive experiments on 10 real-world graphs are conducted to\ndemonstrate the efficiency and effectiveness of the proposed techniques.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u7ed9\u5b9a\u65f6\u95f4\u95f4\u9694\u5185\u4ece\u6e90\u9876\u70b9\u5230\u76ee\u6807\u9876\u70b9\u7684\u6240\u6709\u65f6\u5e8f\u7b80\u5355\u8def\u5f84\u6784\u6210\u5b50\u56fe\uff08tspG\uff09\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\u907f\u514d\u76f4\u63a5\u679a\u4e3e\u8def\u5f84\u3002", "motivation": "\u65f6\u5e8f\u56fe\u4e2d\u57fa\u4e8e\u65f6\u5e8f\u8def\u5f84\u7684\u9876\u70b9\u5173\u7cfb\u63a2\u7d22\u662f\u57fa\u7840\u4efb\u52a1\uff0c\u800c\u76f4\u63a5\u679a\u4e3e\u8def\u5f84\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e9f\u9700\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Verification in Upper-bound Graph\u65b9\u6cd5\uff0c\u5148\u901a\u8fc7\u7ea6\u675f\u6761\u4ef6\u6392\u9664\u65e0\u5173\u8fb9\u5f97\u5230\u4e0a\u754c\u56fe\uff0c\u518d\u7528Escape Edges Verification\u7b97\u6cd5\u7cbe\u786e\u6784\u5efatspG\u3002", "result": "\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u56fe\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u89e3\u51b3\u4e86tspG\u6784\u5efa\u95ee\u9898\uff0c\u907f\u514d\u4e86\u8def\u5f84\u679a\u4e3e\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2507.09190", "pdf": "https://arxiv.org/pdf/2507.09190", "abs": "https://arxiv.org/abs/2507.09190", "authors": ["Andreas Pramendorfer", "Rainhard Dieter Findling"], "title": "User-to-PC Authentication Through Confirmation on Mobile Devices: On Usability and Performance", "categories": ["cs.HC", "cs.CR"], "comment": "Submitted to MoMM 2025", "summary": "Protecting personal computers (PCs) from unauthorized access typically relies\non password authentication, which is know to suffer from cognitive burden and\nweak credentials. As many users nowadays carry mobile devices with advanced\nsecurity features throughout their day, there is an opportunity to leverage\nthese devices to improve authentication to PCs. In this paper we utilize a\ntoken-based passwordless approach where users authenticate to their PC by\nconfirming the authentication request on their smartphones or smartwatches.\nUpon a request to login to the PC, or to evaluate privileges, the PC issues an\nauthentication request that users receive on their mobile devices, where users\ncan confirm or deny the request. We evaluate button tap and biometric\nfingerprint verification as confirmation variants, and compare their\nauthentication duration, success rate, and usability to traditional\npassword-based authentication in a user study with 30 participants and a total\nof 1,200 authentication attempts. Smartwatch-based authentication outperformed\npassword-based authentication and smartphone-based variants in authentication\nduration, while showing comparable success rates. Participants rated\nsmartwatch-based authentication highest in usability, followed by\npassword-based authentication and smartphone-based authentication.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee4\u724c\u7684\u65e0\u5bc6\u7801\u8ba4\u8bc1\u65b9\u6cd5\uff0c\u5229\u7528\u667a\u80fd\u624b\u673a\u6216\u667a\u80fd\u624b\u8868\u8fdb\u884cPC\u8ba4\u8bc1\uff0c\u4e0e\u4f20\u7edf\u5bc6\u7801\u8ba4\u8bc1\u76f8\u6bd4\uff0c\u667a\u80fd\u624b\u8868\u8ba4\u8bc1\u5728\u901f\u5ea6\u548c\u53ef\u7528\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u4f20\u7edf\u5bc6\u7801\u8ba4\u8bc1\u5b58\u5728\u8ba4\u77e5\u8d1f\u62c5\u548c\u5f31\u51ed\u8bc1\u95ee\u9898\uff0c\u800c\u73b0\u4ee3\u79fb\u52a8\u8bbe\u5907\u5177\u6709\u9ad8\u7ea7\u5b89\u5168\u529f\u80fd\uff0c\u53ef\u7528\u4e8e\u6539\u8fdbPC\u8ba4\u8bc1\u3002", "method": "\u91c7\u7528\u4ee4\u724c\u65e0\u5bc6\u7801\u8ba4\u8bc1\uff0c\u7528\u6237\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u786e\u8ba4\u8ba4\u8bc1\u8bf7\u6c42\uff0c\u652f\u6301\u6309\u94ae\u70b9\u51fb\u548c\u6307\u7eb9\u9a8c\u8bc1\uff0c\u5e76\u4e0e\u4f20\u7edf\u5bc6\u7801\u8ba4\u8bc1\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u667a\u80fd\u624b\u8868\u8ba4\u8bc1\u901f\u5ea6\u6700\u5feb\uff0c\u6210\u529f\u7387\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\uff0c\u4e14\u7528\u6237\u8bc4\u4ef7\u6700\u9ad8\u3002", "conclusion": "\u667a\u80fd\u624b\u8868\u8ba4\u8bc1\u662f\u4e00\u79cd\u5feb\u901f\u3001\u9ad8\u6548\u4e14\u7528\u6237\u53cb\u597d\u7684PC\u8ba4\u8bc1\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.09186", "pdf": "https://arxiv.org/pdf/2507.09186", "abs": "https://arxiv.org/abs/2507.09186", "authors": ["Minhaj Uddin Ahmad", "Akid Abrar", "Sagar Dasgupta", "Mizanur Rahman"], "title": "OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advanced Transportation Research", "categories": ["cs.SE"], "comment": null, "summary": "We introduce OpenCAMS (Open-Source Connected and Automated Mobility\nCo-Simulation Platform), an open-source, synchronized, and extensible\nco-simulation framework that tightly couples three best-in-class simulation\ntools: (i) SUMO, (ii) CARLA, and (iii) OMNeT++. OpenCAMS is designed to support\nadvanced research in transportation safety, mobility, and cybersecurity by\ncombining the strengths of each simulation domain. Specifically, SUMO provides\nlarge-scale, microscopic traffic modeling; CARLA offers high-fidelity 3D\nperception, vehicle dynamics, and control simulation; and OMNeT++ enables\nmodular, event-driven network communication, such as cellular\nvehicle-to-everything (C-V2X). OpenCAMS employs a time-synchronized,\nbidirectional coupling architecture that ensures coherent simulation\nprogression across traffic, perception, and communication domains while\npreserving modularity and reproducibility. For example, CARLA can simulate and\nrender a subset of vehicles that require detailed sensor emulation and control\nlogic; SUMO orchestrates network-wide traffic flow, vehicle routing, and\ntraffic signal management; and OMNeT++ dynamically maps communication nodes to\nboth mobile entities (e.g., vehicles) and static entities (e.g., roadside\nunits) to enable C-V2X communication. While these three simulators form the\nfoundational core of OpenCAMS, the platform is designed to be expandable and\nfuture-proof, allowing additional simulators to be integrated on top of this\ncore without requiring fundamental changes to the system architecture. The\nOpenCAMS platform is fully open-source and publicly available through its\nGitHub repository https://github.com/minhaj6/carla-sumo-omnetpp-cosim,\nproviding the research community with an accessible, flexible, and\ncollaborative environment for advancing next-generation intelligent\ntransportation systems.", "AI": {"tldr": "OpenCAMS\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u540c\u6b65\u7684\u3001\u53ef\u6269\u5c55\u7684\u534f\u540c\u4eff\u771f\u6846\u67b6\uff0c\u6574\u5408\u4e86SUMO\u3001CARLA\u548cOMNeT++\u4e09\u79cd\u4eff\u771f\u5de5\u5177\uff0c\u7528\u4e8e\u4ea4\u901a\u3001\u611f\u77e5\u548c\u901a\u4fe1\u9886\u57df\u7684\u7814\u7a76\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u4ea4\u901a\u5b89\u5168\u6027\u3001\u79fb\u52a8\u6027\u548c\u7f51\u7edc\u5b89\u5168\u7684\u9ad8\u7ea7\u7814\u7a76\uff0c\u7ed3\u5408\u4e0d\u540c\u4eff\u771f\u5de5\u5177\u7684\u4f18\u52bf\u3002", "method": "\u91c7\u7528\u65f6\u95f4\u540c\u6b65\u7684\u53cc\u5411\u8026\u5408\u67b6\u6784\uff0c\u7ed3\u5408SUMO\u3001CARLA\u548cOMNeT++\u7684\u529f\u80fd\uff0c\u5b9e\u73b0\u4ea4\u901a\u6d41\u3001\u9ad8\u4fdd\u771f\u611f\u77e5\u548c\u901a\u4fe1\u6a21\u62df\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u652f\u6301\u4e0b\u4e00\u4ee3\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u7814\u7a76\u3002", "conclusion": "OpenCAMS\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u534f\u4f5c\u7684\u73af\u5883\uff0c\u4fc3\u8fdb\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.10324", "pdf": "https://arxiv.org/pdf/2507.10324", "abs": "https://arxiv.org/abs/2507.10324", "authors": ["Amit K. Chopra", "Samuel H. Christie V", "Munindar P. Singh"], "title": "Toolsuite for Implementing Multiagent Systems Based on Communication Protocols", "categories": ["cs.MA", "cs.AI", "cs.PL", "cs.SE", "I.2.11; I.2.4; I.2.5"], "comment": null, "summary": "Interaction-Oriented Programming (IOP) is an approach to building a\nmultiagent system by modeling the interactions between its roles via a flexible\ninteraction protocol and implementing agents to realize the interactions of the\nroles they play in the protocol.\n  In recent years, we have developed an extensive suite of software that\nenables multiagent system developers to apply IOP. These include tools for\nefficiently verifying protocols for properties such as liveness and safety and\nmiddleware that simplifies the implementation of agents. This paper presents\nsome of that software suite.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4ea4\u4e92\u5bfc\u5411\u7f16\u7a0b\uff08IOP\uff09\u53ca\u5176\u5728\u5f00\u53d1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5c55\u793a\u4e86\u76f8\u5173\u8f6f\u4ef6\u5de5\u5177\u548c\u4e2d\u95f4\u4ef6\u3002", "motivation": "\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u53d1\u8005\u63d0\u4f9b\u9ad8\u6548\u7684\u4ea4\u4e92\u534f\u8bae\u9a8c\u8bc1\u548c\u667a\u80fd\u4f53\u5b9e\u73b0\u5de5\u5177\u3002", "method": "\u4f7f\u7528IOP\u65b9\u6cd5\uff0c\u901a\u8fc7\u7075\u6d3b\u4ea4\u4e92\u534f\u8bae\u5efa\u6a21\u89d2\u8272\u95f4\u4e92\u52a8\uff0c\u5e76\u5f00\u53d1\u76f8\u5173\u8f6f\u4ef6\u5de5\u5177\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u5957\u5305\u542b\u534f\u8bae\u9a8c\u8bc1\u5de5\u5177\u548c\u7b80\u5316\u667a\u80fd\u4f53\u5b9e\u73b0\u7684\u4e2d\u95f4\u4ef6\u7684\u8f6f\u4ef6\u5957\u4ef6\u3002", "conclusion": "IOP\u53ca\u76f8\u5173\u5de5\u5177\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u652f\u6301\u3002"}}
{"id": "2507.09352", "pdf": "https://arxiv.org/pdf/2507.09352", "abs": "https://arxiv.org/abs/2507.09352", "authors": ["Ghazal Asemian", "Mohammadreza Amini", "Burak Kantarci"], "title": "Reliable Task Offloading in MEC through Transmission Diversity and Jamming-Aware Scheduling", "categories": ["cs.NI", "eess.SP"], "comment": "5 pages, 2 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025", "summary": "Mobile Edge Computing (MEC) enables low-latency applications by bringing\ncomputation closer to the user, but dynamic task arrivals and communication\nthreats like jamming complicate reliable task offloading and resource\nallocation. In this paper, we formulate a dynamic MEC framework considering the\ntransmission diversity that jointly addresses task scheduling and resource\nblock (RB) assignment in the presence of jamming. First, we define and evaluate\nkey network metrics-including dropped task ratio and bandwidth\nutilization-while maintaining service continuity by accounting for the existing\ncommitments of the edge server to previously offloaded tasks. Then, we propose\na jamming-aware offloading and RB allocation framework that leverages\ntransmission diversity and optimal scheduling across distributed gNBs. The\nproposed solution is compared to a similar scenario without transmission\ndiversity and two baseline strategies of first-come-first-served (FCFS) and\nshortest task first (STF). The proposed algorithm effectively mitigates the\nimpact of jamming while enhancing resource utilization and minimizing task drop\nrates, making it highly suitable for mission-critical MEC applications. At\nsignal-to-jamming-and-noise ratio (SJNR) of 4 dB, the proposed method achieves\na $0.26$ task drop rate, outperforming the scenario without transmission\ndiversity with a task drop rate of 0.50 and STF and FCFS strategies with 0.52\nand 0.63 task drop rates, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u652f\u6301\u4f20\u8f93\u591a\u6837\u6027\u7684\u52a8\u6001MEC\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4efb\u52a1\u8c03\u5ea6\u548c\u8d44\u6e90\u5206\u914d\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "\u52a8\u6001\u4efb\u52a1\u5230\u8fbe\u548c\u901a\u4fe1\u5a01\u80c1\uff08\u5982\u5e72\u6270\uff09\u4f7fMEC\u4e2d\u7684\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u590d\u6742\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e72\u6270\u611f\u77e5\u7684\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5757\u5206\u914d\u6846\u67b6\uff0c\u7ed3\u5408\u4f20\u8f93\u591a\u6837\u6027\u548c\u5206\u5e03\u5f0fgNBs\u7684\u6700\u4f18\u8c03\u5ea6\u3002", "result": "\u57284 dB\u7684SJNR\u4e0b\uff0c\u4efb\u52a1\u4e22\u5f03\u7387\u4e3a0.26\uff0c\u4f18\u4e8e\u65e0\u4f20\u8f93\u591a\u6837\u6027\u76840.50\u4ee5\u53caSTF\u548cFCFS\u76840.52\u548c0.63\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u663e\u8457\u51cf\u5c11\u5e72\u6270\u5f71\u54cd\uff0c\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u548c\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u9002\u7528\u4e8e\u4efb\u52a1\u5173\u952e\u578bMEC\u5e94\u7528\u3002"}}
{"id": "2507.09376", "pdf": "https://arxiv.org/pdf/2507.09376", "abs": "https://arxiv.org/abs/2507.09376", "authors": ["Bilkent Samsurya"], "title": "Acoustic Wave Modeling Using 2D FDTD: Applications in Unreal Engine For Dynamic Sound Rendering", "categories": ["cs.SD", "cs.HC", "cs.MM", "eess.AS", "H.5.5"], "comment": "Accepted to the 50th International Computer Music Conference (ICMC),\n  2025", "summary": "Accurate sound propagation simulation is essential for delivering immersive\nexperiences in virtual applications, yet industry methods for acoustic modeling\noften do not account for the full breadth of acoustic wave phenomena. This\npaper proposes a novel two-dimensional (2D) finite-difference time-domain\n(FDTD) framework that simulates sound propagation as a wave-based model in\nUnreal Engine, with an emphasis on capturing lower frequency wave phenomena,\nembedding occlusion, diffraction, reflection and interference in generated\nimpulse responses. The process begins by discretizing the scene geometry into a\n2D grid via a top-down projection from which obstacle masks and boundary\nconditions are derived. A Python-based FDTD solver injects a sine sweep at a\nsource position, and virtual quadraphonic microphone arrays record pressure\nfield responses at pre-defined listener positions. De-convolution of the\npressure responses yields multi-channel impulse responses that retain spatial\ndirectionality which are then integrated into Unreal Engine's audio pipeline\nfor dynamic playback. Benchmark tests confirm agreement with analytical\nexpectations, and the paper outlines hybrid extensions aimed at commercial\nviability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u76842D FDTD\u6846\u67b6\uff0c\u7528\u4e8e\u5728Unreal Engine\u4e2d\u6a21\u62df\u4f4e\u9891\u58f0\u6ce2\u73b0\u8c61\uff0c\u5305\u62ec\u906e\u6321\u3001\u884d\u5c04\u3001\u53cd\u5c04\u548c\u5e72\u6270\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u5de5\u4e1a\u4e2d\u7684\u58f0\u5b66\u5efa\u6a21\u65b9\u6cd5\u672a\u80fd\u5b8c\u5168\u6db5\u76d6\u58f0\u6ce2\u73b0\u8c61\uff0c\u5f71\u54cd\u4e86\u865a\u62df\u5e94\u7528\u4e2d\u7684\u6c89\u6d78\u4f53\u9a8c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u5168\u9762\u6a21\u62df\u58f0\u6ce2\u4f20\u64ad\u7684\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u91c7\u75282D FDTD\u6846\u67b6\uff0c\u901a\u8fc7\u573a\u666f\u51e0\u4f55\u7684\u79bb\u6563\u5316\u751f\u6210\u969c\u788d\u7269\u63a9\u7801\u548c\u8fb9\u754c\u6761\u4ef6\uff0c\u4f7f\u7528\u57fa\u4e8ePython\u7684FDTD\u6c42\u89e3\u5668\u6ce8\u5165\u6b63\u5f26\u626b\u9891\u4fe1\u53f7\uff0c\u5e76\u901a\u8fc7\u56db\u58f0\u9053\u9ea6\u514b\u98ce\u9635\u5217\u8bb0\u5f55\u538b\u529b\u573a\u54cd\u5e94\u3002", "result": "\u538b\u529b\u573a\u54cd\u5e94\u7ecf\u8fc7\u53bb\u5377\u79ef\u540e\u751f\u6210\u591a\u901a\u9053\u8109\u51b2\u54cd\u5e94\uff0c\u4fdd\u7559\u4e86\u7a7a\u95f4\u65b9\u5411\u6027\uff0c\u5e76\u5728Unreal Engine\u4e2d\u5b9e\u73b0\u4e86\u52a8\u6001\u64ad\u653e\u3002\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u4e0e\u7406\u8bba\u9884\u671f\u4e00\u81f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6a21\u62df\u4e86\u4f4e\u9891\u58f0\u6ce2\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u9762\u5411\u5546\u4e1a\u53ef\u884c\u6027\u7684\u6df7\u5408\u6269\u5c55\u65b9\u6848\u3002"}}
{"id": "2507.10133", "pdf": "https://arxiv.org/pdf/2507.10133", "abs": "https://arxiv.org/abs/2507.10133", "authors": ["Nicholas Leisegang", "Thomas Meyer", "Ivan Varzinczak"], "title": "Extending Defeasibility for Propositional Standpoint Logics", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "In this paper, we introduce a new defeasible version of propositional\nstandpoint logic by integrating Kraus et al.'s defeasible conditionals, Britz\nand Varzinczak's notions of defeasible necessity and distinct possibility,\nalong with Leisegang et al.'s approach to defeasibility into the standpoint\nlogics of G\\'omez \\'Alvarez and Rudolph. The resulting logical framework allows\nfor the expression of defeasibility on the level of implications, standpoint\nmodal operators, and standpoint-sharpening statements. We provide a\npreferential semantics for this extended language and propose a tableaux\ncalculus, which is shown to be sound and complete with respect to preferential\nentailment. We also establish the computational complexity of the tableaux\nprocedure to be in PSpace.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u5e9f\u6b62\u547d\u9898\u7acb\u573a\u903b\u8f91\uff0c\u7ed3\u5408\u4e86\u591a\u79cd\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u8bed\u4e49\u548c\u63a8\u7406\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u6027\u3002", "motivation": "\u7ed3\u5408\u591a\u79cd\u53ef\u5e9f\u6b62\u903b\u8f91\u7406\u8bba\uff0c\u6269\u5c55\u7acb\u573a\u903b\u8f91\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u53ef\u5e9f\u6b62\u6027\u7684\u591a\u5c42\u6b21\u95ee\u9898\u3002", "method": "\u6574\u5408Kraus\u7b49\u4eba\u7684\u53ef\u5e9f\u6b62\u6761\u4ef6\u3001Britz\u548cVarzinczak\u7684\u53ef\u5e9f\u6b62\u5fc5\u8981\u6027\u53ca\u72ec\u7279\u53ef\u80fd\u6027\u6982\u5ff5\uff0c\u4ee5\u53caLeisegang\u7b49\u4eba\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u65b0\u7684\u903b\u8f91\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4f18\u5148\u8bed\u4e49\u548c\u8868\u63a8\u6f14\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u8868\u63a8\u6f14\u7b97\u6cd5\u5728\u4f18\u5148\u8574\u542b\u4e0b\u7684\u53ef\u9760\u6027\u548c\u5b8c\u5907\u6027\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u6027\u4e3aPSpace\u3002", "conclusion": "\u65b0\u6846\u67b6\u6210\u529f\u6269\u5c55\u4e86\u7acb\u573a\u903b\u8f91\u7684\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u591a\u5c42\u53ef\u5e9f\u6b62\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10421", "pdf": "https://arxiv.org/pdf/2507.10421", "abs": "https://arxiv.org/abs/2507.10421", "authors": ["Meriem Zerkouk", "Miloud Mihoubi", "Belkacem Chikhaoui"], "title": "SentiDrop: A Multi Modal Machine Learning model for Predicting Dropout in Distance Learning", "categories": ["cs.AI", "cs.ET", "cs.IR", "cs.LG"], "comment": "International Conference on Education and New Learning Technologies\n  (2025)", "summary": "School dropout is a serious problem in distance learning, where early\ndetection is crucial for effective intervention and student perseverance.\nPredicting student dropout using available educational data is a widely\nresearched topic in learning analytics. Our partner's distance learning\nplatform highlights the importance of integrating diverse data sources,\nincluding socio-demographic data, behavioral data, and sentiment analysis, to\naccurately predict dropout risks. In this paper, we introduce a novel model\nthat combines sentiment analysis of student comments using the Bidirectional\nEncoder Representations from Transformers (BERT) model with socio-demographic\nand behavioral data analyzed through Extreme Gradient Boosting (XGBoost). We\nfine-tuned BERT on student comments to capture nuanced sentiments, which were\nthen merged with key features selected using feature importance techniques in\nXGBoost. Our model was tested on unseen data from the next academic year,\nachieving an accuracy of 84\\%, compared to 82\\% for the baseline model.\nAdditionally, the model demonstrated superior performance in other metrics,\nsuch as precision and F1-score. The proposed method could be a vital tool in\ndeveloping personalized strategies to reduce dropout rates and encourage\nstudent perseverance", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408BERT\u60c5\u611f\u5206\u6790\u548cXGBoost\u7684\u65b0\u578b\u6a21\u578b\uff0c\u51c6\u786e\u9884\u6d4b\u8fdc\u7a0b\u5b66\u4e60\u4e2d\u5b66\u751f\u8f8d\u5b66\u98ce\u9669\uff0c\u51c6\u786e\u7387\u8fbe84%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u8fdc\u7a0b\u5b66\u4e60\u4e2d\u5b66\u751f\u8f8d\u5b66\u95ee\u9898\u4e25\u91cd\uff0c\u9700\u65e9\u671f\u5e72\u9884\uff0c\u6574\u5408\u591a\u6837\u5316\u6570\u636e\u6e90\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528BERT\u5206\u6790\u5b66\u751f\u8bc4\u8bba\u60c5\u611f\uff0c\u7ed3\u5408XGBoost\u5904\u7406\u793e\u4f1a\u4eba\u53e3\u548c\u884c\u4e3a\u6570\u636e\uff0c\u7279\u5f81\u9009\u62e9\u540e\u5408\u5e76\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u672a\u89c1\u6570\u636e\u4e0a\u51c6\u786e\u7387\u8fbe84%\uff0c\u4e14\u5728\u5176\u4ed6\u6307\u6807\uff08\u5982\u7cbe\u786e\u7387\u548cF1\u5206\u6570\uff09\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4e3a\u4e2a\u6027\u5316\u5e72\u9884\u7b56\u7565\u63d0\u4f9b\u652f\u6301\uff0c\u6709\u6548\u964d\u4f4e\u8f8d\u5b66\u7387\u5e76\u63d0\u5347\u5b66\u751f\u575a\u6301\u6027\u3002"}}
{"id": "2507.10150", "pdf": "https://arxiv.org/pdf/2507.10150", "abs": "https://arxiv.org/abs/2507.10150", "authors": ["Ruihao Gong", "Shihao Bai", "Siyu Wu", "Yunqian Fan", "Zaijun Wang", "Xiuhong Li", "Hailong Yang", "Xianglong Liu"], "title": "Past-Future Scheduler for LLM Serving under SLA Guarantees", "categories": ["cs.DC"], "comment": "Accepted to ASPLOS 2025", "summary": "The exploration and application of Large Language Models (LLMs) is thriving.\nTo reduce deployment costs, continuous batching has become an essential feature\nin current service frameworks. The effectiveness of continuous batching relies\non an accurate estimate of the memory requirements of requests. However, due to\nthe diversity in request output lengths, existing frameworks tend to adopt\naggressive or conservative schedulers, which often result in significant\noverestimation or underestimation of memory consumption. Consequently, they\nsuffer from harmful request evictions or prolonged queuing times, failing to\nachieve satisfactory throughput under strict Service Level Agreement (SLA)\nguarantees (a.k.a. goodput), across various LLM application scenarios with\ndiffering input-output length distributions. To address this issue, we propose\na novel Past-Future scheduler that precisely estimates the peak memory\nresources required by the running batch via considering the historical\ndistribution of request output lengths and calculating memory occupancy at each\nfuture time point. It adapts to applications with all types of input-output\nlength distributions, balancing the trade-off between request queuing and\nharmful evictions, thereby consistently achieving better goodput. Furthermore,\nto validate the effectiveness of the proposed scheduler, we developed a\nhigh-performance LLM serving framework, LightLLM, that implements the\nPast-Future scheduler. Compared to existing aggressive or conservative\nschedulers, LightLLM demonstrates superior goodput, achieving up to 2-3$\\times$\nhigher goodput than other schedulers under heavy loads. LightLLM is open source\nto boost the research in such direction (https://github.com/ModelTC/lightllm).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPast-Future\u8c03\u5ea6\u5668\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cbe\u786e\u4f30\u8ba1\u5185\u5b58\u9700\u6c42\u6765\u63d0\u5347LLM\u670d\u52a1\u6846\u67b6\u7684\u6548\u7387\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6027\u80fd\u6846\u67b6LightLLM\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709LLM\u670d\u52a1\u6846\u67b6\u56e0\u8bf7\u6c42\u8f93\u51fa\u957f\u5ea6\u7684\u591a\u6837\u6027\uff0c\u5e38\u56e0\u6fc0\u8fdb\u6216\u4fdd\u5b88\u7684\u8c03\u5ea6\u7b56\u7565\u5bfc\u81f4\u5185\u5b58\u4f30\u8ba1\u4e0d\u51c6\u786e\uff0c\u4ece\u800c\u5f71\u54cd\u541e\u5410\u91cf\u548c\u670d\u52a1\u8d28\u91cf\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u7684\u8c03\u5ea6\u5668\u8bbe\u8ba1\u3002", "method": "\u63d0\u51faPast-Future\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u5386\u53f2\u8bf7\u6c42\u8f93\u51fa\u957f\u5ea6\u5206\u5e03\u548c\u672a\u6765\u65f6\u95f4\u70b9\u7684\u5185\u5b58\u5360\u7528\u8ba1\u7b97\uff0c\u7cbe\u786e\u4f30\u8ba1\u5185\u5b58\u9700\u6c42\uff0c\u5e73\u8861\u8bf7\u6c42\u6392\u961f\u4e0e\u6709\u5bb3\u9a71\u9010\u7684\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLightLLM\u6846\u67b6\u5728\u91cd\u8d1f\u8f7d\u4e0b\u6bd4\u5176\u4ed6\u8c03\u5ea6\u5668\u9ad8\u51fa2-3\u500d\u7684\u597d\u541e\u5410\u91cf\uff0c\u9a8c\u8bc1\u4e86Past-Future\u8c03\u5ea6\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "Past-Future\u8c03\u5ea6\u5668\u80fd\u9002\u5e94\u591a\u79cd\u5e94\u7528\u573a\u666f\uff0c\u663e\u8457\u63d0\u5347\u597d\u541e\u5410\u91cf\uff0c\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2507.09780", "pdf": "https://arxiv.org/pdf/2507.09780", "abs": "https://arxiv.org/abs/2507.09780", "authors": ["Feilong Qiaoyuan", "Jihe Wang", "Zhiyu Sun", "Linying Wu", "Yuanhua Xiao", "Danghui Wang"], "title": "BitParticle: Partializing Sparse Dual-Factors to Build Quasi-Synchronizing MAC Arrays for Energy-efficient DNNs", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 13 figures, 3 Tables", "summary": "Bit-level sparsity in quantized deep neural networks (DNNs) offers\nsignificant potential for optimizing Multiply-Accumulate (MAC) operations.\nHowever, two key challenges still limit its practical exploitation. First,\nconventional bit-serial approaches cannot simultaneously leverage the sparsity\nof both factors, leading to a complete waste of one factor' s sparsity. Methods\ndesigned to exploit dual-factor sparsity are still in the early stages of\nexploration, facing the challenge of partial product explosion. Second, the\nfluctuation of bit-level sparsity leads to variable cycle counts for MAC\noperations. Existing synchronous scheduling schemes that are suitable for\ndual-factor sparsity exhibit poor flexibility and still result in significant\nunderutilization of MAC units. To address the first challenge, this study\nproposes a MAC unit that leverages dual-factor sparsity through the emerging\nparticlization-based approach. The proposed design addresses the issue of\npartial product explosion through simple control logic, resulting in a more\narea- and energy-efficient MAC unit. In addition, by discarding less\nsignificant intermediate results, the design allows for further hardware\nsimplification at the cost of minor accuracy loss. To address the second\nchallenge, a quasi-synchronous scheme is introduced that adds cycle-level\nelasticity to the MAC array, reducing pipeline stalls and thereby improving MAC\nunit utilization. Evaluation results show that the exact version of the\nproposed MAC array architecture achieves a 29.2% improvement in area efficiency\ncompared to the state-of-the-art bit-sparsity-driven architecture, while\nmaintaining comparable energy efficiency. The approximate variant further\nimproves energy efficiency by 7.5%, compared to the exact version. Index-Terms:\nDNN acceleration, Bit-level sparsity, MAC unit", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MAC\u5355\u5143\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5229\u7528\u91cf\u5316DNN\u4e2d\u7684\u53cc\u56e0\u5b50\u7a00\u758f\u6027\uff0c\u89e3\u51b3\u4e86\u90e8\u5206\u4e58\u79ef\u7206\u70b8\u548cMAC\u5355\u5143\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u9762\u79ef\u548c\u80fd\u6548\u3002", "motivation": "\u91cf\u5316DNN\u4e2d\u7684\u6bd4\u7279\u7ea7\u7a00\u758f\u6027\u4e3a\u4f18\u5316MAC\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5229\u7528\u53cc\u56e0\u5b50\u7684\u7a00\u758f\u6027\uff0c\u4e14\u540c\u6b65\u8c03\u5ea6\u65b9\u6848\u7684\u7075\u6d3b\u6027\u4e0d\u8db3\uff0c\u5bfc\u81f4MAC\u5355\u5143\u5229\u7528\u7387\u4f4e\u4e0b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8epartialization\u7684MAC\u5355\u5143\uff0c\u901a\u8fc7\u7b80\u5355\u63a7\u5236\u903b\u8f91\u89e3\u51b3\u90e8\u5206\u4e58\u79ef\u7206\u70b8\u95ee\u9898\uff1b\u5f15\u5165\u51c6\u540c\u6b65\u8c03\u5ea6\u65b9\u6848\uff0c\u589e\u52a0MAC\u9635\u5217\u7684\u5468\u671f\u7ea7\u5f39\u6027\uff0c\u51cf\u5c11\u6d41\u6c34\u7ebf\u505c\u987f\u3002", "result": "\u7cbe\u786e\u7248MAC\u5355\u5143\u9762\u79ef\u6548\u7387\u63d0\u534729.2%\uff0c\u8fd1\u4f3c\u7248\u5728\u7cbe\u786e\u7248\u57fa\u7840\u4e0a\u80fd\u6548\u63d0\u9ad87.5%\u3002", "conclusion": "\u65b0\u8bbe\u8ba1\u663e\u8457\u4f18\u5316\u4e86MAC\u5355\u5143\u7684\u6027\u80fd\uff0c\u540c\u65f6\u652f\u6301\u8fdb\u4e00\u6b65\u786c\u4ef6\u7b80\u5316\uff0c\u9002\u7528\u4e8eDNN\u52a0\u901f\u3002"}}
{"id": "2507.10070", "pdf": "https://arxiv.org/pdf/2507.10070", "abs": "https://arxiv.org/abs/2507.10070", "authors": ["Yang Xiao", "Mo Sun", "Ziyu Song", "Bing Tian", "Jie Zhang", "Jie Sun", "Zeke Wang"], "title": "Breaking the Storage-Compute Bottleneck in Billion-Scale ANNS: A GPU-Driven Asynchronous I/O Framework", "categories": ["cs.DB"], "comment": null, "summary": "With the advancement of information retrieval, recommendation systems, and\nRetrieval-Augmented Generation (RAG), Approximate Nearest Neighbor Search\n(ANNS) gains widespread applications due to its higher performance and\naccuracy. While several disk-based ANNS systems have emerged to handle\nexponentially growing vector datasets, they suffer from suboptimal performance\ndue to two inherent limitations: 1) failing to overlap SSD accesses with\ndistance computation processes and 2) extended I/O latency caused by suboptimal\nI/O Stack. To address these challenges, we present FlashANNS, a GPU-accelerated\nout-of-core graph-based ANNS system through I/O-compute overlapping. Our core\ninsight lies in the synchronized orchestration of I/O and computation through\nthree key innovations: 1) Dependency-Relaxed asynchronous pipeline: FlashANNS\ndecouples I/O-computation dependencies to fully overlap between GPU distance\ncalculations and SSD data transfers. 2) Warp-Level concurrent SSD access:\nFlashANNS implements a lock-free I/O stack with warp-level concurrency control,\nto reduce the latency-induced time overhead. 3) Computation-I/O balanced graph\ndegree Selection: FlashANNS selects graph degrees via lightweight\ncompute-to-I/O ratio sampling, ensuring optimal balance between computational\nload and storage access latency across different I/O bandwidth configurations.\nWe implement FlashANNS and compare it with state-of-the-art out-of-core ANNS\nsystems (SPANN, DiskANN) and a GPU-accelerated out-of-core ANNS system\n(FusionANNS). Experimental results demonstrate that at $\\geq$95\\% recall@10\naccuracy, our method achieves 2.3-5.9$\\times$ higher throughput compared to\nexisting SOTA methods with a single SSD, and further attains 2.7-12.2$\\times$\nthroughput improvement in multi-SSD configurations.", "AI": {"tldr": "FlashANNS\u662f\u4e00\u4e2a\u57fa\u4e8eGPU\u52a0\u901f\u7684\u56fe\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7I/O\u8ba1\u7b97\u91cd\u53e0\u4f18\u5316\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u78c1\u76d8\u7684ANNS\u7cfb\u7edf\u56e0\u65e0\u6cd5\u6709\u6548\u91cd\u53e0SSD\u8bbf\u95ee\u4e0e\u8ddd\u79bb\u8ba1\u7b97\u4ee5\u53caI/O\u6808\u6027\u80fd\u4e0d\u8db3\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "FlashANNS\u63d0\u51fa\u4e09\u9879\u521b\u65b0\uff1a\u4f9d\u8d56\u677e\u89e3\u7684\u5f02\u6b65\u7ba1\u9053\u3001Warp\u7ea7\u5e76\u53d1SSD\u8bbf\u95ee\u3001\u8ba1\u7b97-I/O\u5e73\u8861\u7684\u56fe\u5ea6\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u663e\u793aFlashANNS\u5728\u5355SSD\u548c\u591aSSD\u914d\u7f6e\u4e0b\u5206\u522b\u5b9e\u73b02.3-5.9\u500d\u548c2.7-12.2\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "FlashANNS\u901a\u8fc7\u4f18\u5316I/O\u8ba1\u7b97\u91cd\u53e0\uff0c\u663e\u8457\u63d0\u5347\u4e86ANNS\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.09262", "pdf": "https://arxiv.org/pdf/2507.09262", "abs": "https://arxiv.org/abs/2507.09262", "authors": ["Soobin Yim", "Sangbong Yoo", "Chanyoung Yoon", "Chanyoung Jung", "Chansoo Kim", "Yun Jang", "Ghulam Jilani Quadri"], "title": "Discrepancies in Mental Workload Estimation: Self-Reported versus EEG-Based Measures in Data Visualization Evaluation", "categories": ["cs.HC"], "comment": null, "summary": "Accurate assessment of mental workload (MW) is crucial for understanding\ncognitive processes during visualization tasks. While EEG-based measures are\nemerging as promising alternatives to conventional assessment techniques, such\nas selfreport measures, studies examining consistency across these different\nmethodologies are limited. In a preliminary study, we observed indications of\npotential discrepancies between EEGbased and self-reported MW measures.\nMotivated by these preliminary observations, our study further explores the\ndiscrepancies between EEG-based and self-reported MW assessment methods through\nan experiment involving visualization tasks. In the experiment, we employ two\nbenchmark tasks: the Visualization Literacy Assessment Test (VLAT) and a\nSpatial Visualization (SV) task. EEG signals are recorded from participants\nusing a 32-channel system at a sampling rate of 128 Hz during the visualization\ntasks. For each participant, MW is estimated using an EEG-based model built on\na Graph Attention Network (GAT) architecture, and these estimates are compared\nwith conventional MW measures to examine potential discrepancies. Our findings\nreveal notable discrepancies between task difficulty and EEG-based MW\nestimates, as well as between EEG-based and self-reported MW measures across\nvarying task difficulty levels. Additionally, the observed patterns suggest the\npresence of unconscious cognitive effort that may not be captured by selfreport\nalone.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8111\u7535\u56fe\uff08EEG\uff09\u548c\u81ea\u6211\u62a5\u544a\u4e2d\u8bc4\u4f30\u5fc3\u7406\u8d1f\u8377\uff08MW\uff09\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0\u4e24\u79cd\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u521d\u6b65\u7814\u7a76\u8868\u660eEEG\u548c\u81ea\u6211\u62a5\u544a\u5728MW\u8bc4\u4f30\u4e0a\u53ef\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u4e3a\u6b64\u8fdb\u4e00\u6b65\u63a2\u7d22\u5176\u4e00\u81f4\u6027\u3002", "method": "\u901a\u8fc7\u53ef\u89c6\u5316\u4efb\u52a1\u5b9e\u9a8c\uff0c\u4f7f\u7528VLAT\u548cSV\u4efb\u52a1\uff0c\u752832\u901a\u9053EEG\u8bb0\u5f55\u4fe1\u53f7\uff0c\u5e76\u57fa\u4e8eGAT\u6a21\u578b\u4f30\u8ba1MW\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "\u53d1\u73b0\u4efb\u52a1\u96be\u5ea6\u4e0eEEG\u4f30\u8ba1\u7684MW\u4e0d\u4e00\u81f4\uff0c\u4e14EEG\u4e0e\u81ea\u6211\u62a5\u544a\u4e4b\u95f4\u4e5f\u5b58\u5728\u5dee\u5f02\uff0c\u8868\u660e\u53ef\u80fd\u5b58\u5728\u672a\u88ab\u81ea\u6211\u62a5\u544a\u6355\u6349\u7684\u65e0\u610f\u8bc6\u8ba4\u77e5\u52aa\u529b\u3002", "conclusion": "EEG\u548c\u81ea\u6211\u62a5\u544a\u5728MW\u8bc4\u4f30\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u6697\u793a\u65e0\u610f\u8bc6\u8ba4\u77e5\u52aa\u529b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.09199", "pdf": "https://arxiv.org/pdf/2507.09199", "abs": "https://arxiv.org/abs/2507.09199", "authors": ["Huihui Huang", "Ratnadira Widyasari", "Ting Zhang", "Ivana Clairine Irsan", "Jieke Shi", "Han Wei Ang", "Frank Liauw", "Eng Lieh Ouh", "Lwin Khin Shar", "Hong Jin Kang", "David Lo"], "title": "Back to the Basics: Rethinking Issue-Commit Linking with LLM-Assisted Retrieval", "categories": ["cs.SE"], "comment": null, "summary": "Issue-commit linking, which connects issues with commits that fix them, is\ncrucial for software maintenance. Existing approaches have shown promise in\nautomatically recovering these links. Evaluations of these techniques assess\ntheir ability to identify genuine links from plausible but false links.\nHowever, these evaluations overlook the fact that, in reality, when a\nrepository has more commits, the presence of more plausible yet unrelated\ncommits may interfere with the tool in differentiating the correct fix commits.\nTo address this, we propose the Realistic Distribution Setting (RDS) and use it\nto construct a more realistic evaluation dataset that includes 20 open-source\nprojects. By evaluating tools on this dataset, we observe that the performance\nof the state-of-the-art deep learning-based approach drops by more than half,\nwhile the traditional Information Retrieval method, VSM, outperforms it.\n  Inspired by these observations, we propose EasyLink, which utilizes a vector\ndatabase as a modern Information Retrieval technique. To address the\nlong-standing problem of the semantic gap between issues and commits, EasyLink\nleverages a large language model to rerank the commits retrieved from the\ndatabase. Under our evaluation, EasyLink achieves an average Precision@1 of\n75.91%, improving over the state-of-the-art by over four times. Additionally,\nthis paper provides practical guidelines for advancing research in issue-commit\nlink recovery.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u8bbe\u7f6e\uff08RDS\uff09\u548c\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u95ee\u9898-\u63d0\u4ea4\u94fe\u63a5\u6062\u590d\u5de5\u5177\u7684\u6027\u80fd\uff0c\u5e76\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u5927\u5e45\u4e0b\u964d\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u5de5\u5177EasyLink\uff0c\u7ed3\u5408\u5411\u91cf\u6570\u636e\u5e93\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u95ee\u9898-\u63d0\u4ea4\u94fe\u63a5\u6062\u590d\u65b9\u6cd5\u5728\u8bc4\u4f30\u4e2d\u5ffd\u7565\u4e86\u5b9e\u9645\u573a\u666f\u4e2d\u66f4\u591a\u4e0d\u76f8\u5173\u63d0\u4ea4\u5bf9\u5de5\u5177\u7684\u5e72\u6270\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u8bbe\u7f6e\u548c\u6539\u8fdb\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faRealistic Distribution Setting (RDS)\u6784\u5efa\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u6570\u636e\u96c6\uff1b\u63d0\u51faEasyLink\uff0c\u7ed3\u5408\u5411\u91cf\u6570\u636e\u5e93\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u94fe\u63a5\u6062\u590d\u3002", "result": "\u5728RDS\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u8d85\u8fc7\u4e00\u534a\uff0c\u800cVSM\u8868\u73b0\u66f4\u4f18\uff1bEasyLink\u5728Precision@1\u4e0a\u8fbe\u523075.91%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u56db\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5de5\u5177EasyLink\uff0c\u4e3a\u95ee\u9898-\u63d0\u4ea4\u94fe\u63a5\u6062\u590d\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.09462", "pdf": "https://arxiv.org/pdf/2507.09462", "abs": "https://arxiv.org/abs/2507.09462", "authors": ["Haoye Chai", "Yuan Yuan", "Yong Li"], "title": "MobiWorld: World Models for Mobile Wireless Network", "categories": ["cs.NI"], "comment": "7 pages, 6 figures", "summary": "Accurate modeling and simulation of mobile networks are essential for\nenabling intelligent and cost-effective network optimization. In this paper, we\npropose MobiWorld, a generative world model designed to support high-fidelity\nand flexible environment simulation for mobile network planning and\noptimization. Unlike traditional predictive models constrained by limited\ngeneralization capabilities, MobiWorld exhibits strong universality by\nintegrating heterogeneous data sources, including sensors, mobile devices, and\nbase stations, as well as multimodal data types such as sequences and images.\nIt is capable of generating both network element-level observations (e.g.,\ntraffic load, user distribution) and system-level performance indicators (e.g.,\nthroughput, energy consumption) to support a wide range of planning and\noptimization tasks. Built upon advanced diffusion models, MobiWorld offers\npowerful controllable generation capabilities by modeling the joint\ndistribution between mobile network data and diverse conditional factors\nincluding spatio temporal contexts, user behaviors, and optimization policies.\nThis enables accurate simulation of dynamic network states under varying policy\nconfigurations, providing optimization agents with precise environmental\nfeedback and facilitating effective decision-making without relying on costly\nreal-network interactions. We demonstrate the effectiveness of MobiWorld in a\ncollaborative energy-saving scenario, where an agent uses observations and\nrewards generated by MobiWorld to optimize base station sleep and user\noffloading policies. Experimental results show that MobiWorld exhibits strong\ncontrollable generation performance and outperforms traditional methods in\nenergy optimization.", "AI": {"tldr": "MobiWorld\u662f\u4e00\u79cd\u751f\u6210\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u5f02\u6784\u6570\u636e\u6e90\u548c\u591a\u6a21\u6001\u6570\u636e\u7c7b\u578b\uff0c\u652f\u6301\u79fb\u52a8\u7f51\u7edc\u89c4\u5212\u548c\u4f18\u5316\u7684\u9ad8\u4fdd\u771f\u73af\u5883\u6a21\u62df\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u53ef\u63a7\u751f\u6210\u80fd\u529b\uff0c\u5e76\u5728\u80fd\u6e90\u4f18\u5316\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u79fb\u52a8\u7f51\u7edc\u7684\u51c6\u786e\u5efa\u6a21\u548c\u4eff\u771f\u5bf9\u4e8e\u5b9e\u73b0\u667a\u80fd\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u7f51\u7edc\u4f18\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\u56e0\u6cdb\u5316\u80fd\u529b\u6709\u9650\u800c\u53d7\u5230\u7ea6\u675f\u3002", "method": "MobiWorld\u57fa\u4e8e\u5148\u8fdb\u7684\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u5efa\u6a21\u79fb\u52a8\u7f51\u7edc\u6570\u636e\u4e0e\u65f6\u7a7a\u4e0a\u4e0b\u6587\u3001\u7528\u6237\u884c\u4e3a\u548c\u4f18\u5316\u7b56\u7565\u7b49\u6761\u4ef6\u56e0\u7d20\u7684\u8054\u5408\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u53ef\u63a7\u751f\u6210\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMobiWorld\u5728\u53ef\u63a7\u751f\u6210\u6027\u80fd\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5728\u534f\u4f5c\u8282\u80fd\u573a\u666f\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "MobiWorld\u4e3a\u79fb\u52a8\u7f51\u7edc\u89c4\u5212\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u4fdd\u771f\u3001\u7075\u6d3b\u7684\u73af\u5883\u6a21\u62df\u5de5\u5177\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u6602\u8d35\u771f\u5b9e\u7f51\u7edc\u4ea4\u4e92\u7684\u60c5\u51b5\u4e0b\u652f\u6301\u6709\u6548\u7684\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2507.09403", "pdf": "https://arxiv.org/pdf/2507.09403", "abs": "https://arxiv.org/abs/2507.09403", "authors": ["Amit Jaspal", "Feng Zhang", "Wei Chang", "Sumit Kumar", "Yubo Wang", "Roni Mittleman", "Qifan Wang", "Weize Mao"], "title": "Balancing Semantic Relevance and Engagement in Related Video Recommendations", "categories": ["cs.IR", "cs.MM"], "comment": null, "summary": "Related video recommendations commonly use collaborative filtering (CF)\ndriven by co-engagement signals, often resulting in recommendations lacking\nsemantic coherence and exhibiting strong popularity bias. This paper introduces\na novel multi-objective retrieval framework, enhancing standard two-tower\nmodels to explicitly balance semantic relevance and user engagement. Our\napproach uniquely combines: (a) multi-task learning (MTL) to jointly optimize\nco-engagement and semantic relevance, explicitly prioritizing topical\ncoherence; (b) fusion of multimodal content features (textual and visual\nembeddings) for richer semantic understanding; and (c) off-policy correction\n(OPC) via inverse propensity weighting to effectively mitigate popularity bias.\nEvaluation on industrial-scale data and a two-week live A/B test reveals our\nframework's efficacy. We observed significant improvements in semantic\nrelevance (from 51% to 63% topic match rate), a reduction in popular item\ndistribution (-13.8% popular video recommendations), and a +0.04% improvement\nin our topline user engagement metric. Our method successfully achieves better\nsemantic coherence, balanced engagement, and practical scalability for\nreal-world deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u591a\u76ee\u6807\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\uff0c\u6709\u6548\u5e73\u8861\u8bed\u4e49\u76f8\u5173\u6027\u4e0e\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u540c\u65f6\u51cf\u5c11\u6d41\u884c\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u7684\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u7cfb\u7edf\u56e0\u4f9d\u8d56\u5171\u53c2\u4e0e\u4fe1\u53f7\uff0c\u5e38\u5bfc\u81f4\u63a8\u8350\u7ed3\u679c\u7f3a\u4e4f\u8bed\u4e49\u8fde\u8d2f\u6027\u4e14\u5b58\u5728\u660e\u663e\u7684\u6d41\u884c\u504f\u89c1\u3002", "method": "\u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u8054\u5408\u4f18\u5316\u5171\u53c2\u4e0e\u4e0e\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u878d\u5408\u591a\u6a21\u6001\u5185\u5bb9\u7279\u5f81\uff0c\u5e76\u5229\u7528\u53cd\u503e\u5411\u52a0\u6743\u51cf\u5c11\u6d41\u884c\u504f\u89c1\u3002", "result": "\u5728\u5de5\u4e1a\u89c4\u6a21\u6570\u636e\u548cA/B\u6d4b\u8bd5\u4e2d\uff0c\u8bed\u4e49\u76f8\u5173\u6027\u63d0\u5347\u81f363%\uff0c\u6d41\u884c\u89c6\u9891\u63a8\u8350\u51cf\u5c1113.8%\uff0c\u7528\u6237\u53c2\u4e0e\u5ea6\u63d0\u9ad80.04%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u8bed\u4e49\u8fde\u8d2f\u6027\u3001\u53c2\u4e0e\u5ea6\u5e73\u8861\u53ca\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2507.08884", "pdf": "https://arxiv.org/pdf/2507.08884", "abs": "https://arxiv.org/abs/2507.08884", "authors": ["Jordan Riley Benson", "David Crist", "Phil Lafleur", "Benjamin Watson"], "title": "Agent-based visualization of streaming text", "categories": ["cs.MA", "cs.GR"], "comment": null, "summary": "We present a visualization infrastructure that maps data elements to agents,\nwhich have behaviors parameterized by those elements. Dynamic visualizations\nemerge as the agents change position, alter appearance and respond to one\nother. Agents move to minimize the difference between displayed agent-to-agent\ndistances, and an input matrix of ideal distances. Our current application is\nvisualization of streaming text. Each agent represents a significant word,\nvisualizing it by displaying the word itself, centered in a circle sized by the\nfrequency of word occurrence. We derive the ideal distance matrix from word\ncooccurrence, mapping higher co-occurrence to lower distance. To depict\nco-occurrence in its textual context, the ratio of intersection to circle area\napproximates the ratio of word co-occurrence to frequency. A networked backend\nprocess gathers articles from news feeds, blogs, Digg or Twitter, exploiting\nonline search APIs to focus on user-chosen topics. Resulting visuals reveal the\nprimary topics in text streams as clusters, with agent-based layout moving\nwithout instability as data streams change dynamically.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6570\u636e\u5143\u7d20\u6620\u5c04\u5230\u4ee3\u7406\u7684\u53ef\u89c6\u5316\u57fa\u7840\u8bbe\u65bd\uff0c\u4ee3\u7406\u7684\u884c\u4e3a\u7531\u6570\u636e\u5143\u7d20\u53c2\u6570\u5316\uff0c\u52a8\u6001\u53ef\u89c6\u5316\u901a\u8fc7\u4ee3\u7406\u7684\u4f4d\u7f6e\u53d8\u5316\u3001\u5916\u89c2\u8c03\u6574\u548c\u76f8\u4e92\u54cd\u5e94\u5b9e\u73b0\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u4ee3\u7406\u884c\u4e3a\u5b9e\u73b0\u52a8\u6001\u53ef\u89c6\u5316\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6d41\u5f0f\u6587\u672c\u6570\u636e\uff0c\u5e2e\u52a9\u7528\u6237\u76f4\u89c2\u7406\u89e3\u6587\u672c\u6d41\u4e2d\u7684\u4e3b\u8981\u4e3b\u9898\u53ca\u5176\u5173\u7cfb\u3002", "method": "\u4f7f\u7528\u4ee3\u7406\u4ee3\u8868\u91cd\u8981\u8bcd\u6c47\uff0c\u901a\u8fc7\u5706\u5f62\u5927\u5c0f\u8868\u793a\u8bcd\u9891\uff0c\u4ee3\u7406\u95f4\u8ddd\u79bb\u57fa\u4e8e\u8bcd\u5171\u73b0\u77e9\u9635\u4f18\u5316\uff0c\u540e\u7aef\u5904\u7406\u4ece\u65b0\u95fb\u3001\u535a\u5ba2\u7b49\u6765\u6e90\u6293\u53d6\u6570\u636e\u5e76\u751f\u6210\u53ef\u89c6\u5316\u3002", "result": "\u53ef\u89c6\u5316\u7ed3\u679c\u663e\u793a\u6587\u672c\u6d41\u4e2d\u7684\u4e3b\u8981\u4e3b\u9898\u4e3a\u805a\u7c7b\uff0c\u4ee3\u7406\u5e03\u5c40\u80fd\u591f\u52a8\u6001\u9002\u5e94\u6570\u636e\u6d41\u53d8\u5316\u4e14\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u4e86\u6d41\u5f0f\u6587\u672c\u7684\u52a8\u6001\u53ef\u89c6\u5316\uff0c\u80fd\u591f\u6e05\u6670\u5c55\u793a\u4e3b\u9898\u805a\u7c7b\u548c\u8bcd\u6c47\u5173\u7cfb\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2507.10181", "pdf": "https://arxiv.org/pdf/2507.10181", "abs": "https://arxiv.org/abs/2507.10181", "authors": ["Kalmer Apinis", "Danel Ahman"], "title": "A simple formalization of alpha-equivalence", "categories": ["cs.LO"], "comment": "to be submitted to LMCS", "summary": "While teaching untyped $\\lambda$-calculus to undergraduate students, we were\nwondering why $\\alpha$-equivalence is not directly inductively defined. In this\npaper, we demonstrate that this is indeed feasible. Specifically, we provide a\ngrounded, inductive definition for $\\alpha$-equivalence and show that it\nconforms to the specification provided in the literature. The work presented in\nthis paper is fully formalized in the Rocq Prover.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u76f4\u63a5\u5f52\u7eb3\u5b9a\u4e49\u03b1-\u7b49\u4ef7\u6027\u5728\u03bb\u6f14\u7b97\u6559\u5b66\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u9645\u53ef\u7528\u7684\u5b9a\u4e49\uff0c\u901a\u8fc7Rocq Prover\u5b9e\u73b0\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "motivation": "\u5728\u6559\u5b66\u65e0\u7c7b\u578b\u03bb\u6f14\u7b97\u65f6\uff0c\u4f5c\u8005\u5bf9\u03b1-\u7b49\u4ef7\u6027\u672a\u80fd\u76f4\u63a5\u5f52\u7eb3\u5b9a\u4e49\u611f\u5230\u56f0\u60d1\uff0c\u56e0\u6b64\u8bd5\u56fe\u63a2\u7d22\u5176\u53ef\u884c\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f52\u7eb3\u7684\u03b1-\u7b49\u4ef7\u6027\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7Rocq Prover\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u79cd\u5f52\u7eb3\u5b9a\u4e49\u4e0e\u6587\u732e\u4e2d\u7684\u89c4\u8303\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u5176\u6b63\u786e\u6027\u3002", "conclusion": "\u8bba\u6587\u8bc1\u660e\u03b1-\u7b49\u4ef7\u6027\u53ef\u4ee5\u76f4\u63a5\u5f52\u7eb3\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u5de5\u5177\u5b9e\u73b0\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.10259", "pdf": "https://arxiv.org/pdf/2507.10259", "abs": "https://arxiv.org/abs/2507.10259", "authors": ["Chengze Du", "Zhiwei Yu", "Heng Xu", "Haojie Wang", "Bo liu", "Jialong Li"], "title": "Cross-Timeslot Optimization for Distributed GPU Inference Using Reinforcement Learning", "categories": ["cs.DC", "cs.NI"], "comment": "17 pages, 12 figures", "summary": "The rapid growth of large language model (LLM) services imposes increasing\ndemands on distributed GPU inference infrastructure. Most existing scheduling\nsystems rely on the current system state to make decisions, without considering\nhow task demand and resource availability evolve over time. This lack of\ntemporal awareness leads to inefficient GPU utilization, high task migration\noverhead, and poor system responsiveness under dynamic workloads. In this work,\nwe identify the fundamental limitations of these instantaneous-state-only\nscheduling approaches and propose Temporal Optimal Resource scheduling via\nTwo-layer Architecture (TORTA). TORTA introduces a spatiotemporal scheduling\nframework that captures both long-term workload patterns and short-term\nexecution constraints. It adopts a two-layer design: a macro-level scheduler\nleverages reinforcement learning and optimal transport to coordinate\ninter-region task distribution, while a micro-level allocator refines\ntask-to-server assignments within each region to reduce latency and switching\ncosts. Experimental results across multiple network topologies show that TORTA\nreduces average inference response time by up to 15\\%, improves load balance by\napproximately 4-5\\%, and cuts total operational cost by 10-20\\% compared to\nstate-of-the-art baseline methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aTORTA\u7684\u4e24\u5c42\u65f6\u7a7a\u8c03\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u5206\u5e03\u5f0fGPU\u63a8\u7406\u57fa\u7840\u8bbe\u65bd\u7684\u8d44\u6e90\u8c03\u5ea6\uff0c\u901a\u8fc7\u7ed3\u5408\u957f\u671f\u5de5\u4f5c\u8d1f\u8f7d\u6a21\u5f0f\u548c\u77ed\u671f\u6267\u884c\u7ea6\u675f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u8c03\u5ea6\u7cfb\u7edf\u4ec5\u57fa\u4e8e\u5f53\u524d\u7cfb\u7edf\u72b6\u6001\u505a\u51fa\u51b3\u7b56\uff0c\u5ffd\u89c6\u4e86\u4efb\u52a1\u9700\u6c42\u548c\u8d44\u6e90\u53ef\u7528\u6027\u7684\u65f6\u95f4\u6f14\u53d8\uff0c\u5bfc\u81f4GPU\u5229\u7528\u7387\u4f4e\u3001\u4efb\u52a1\u8fc1\u79fb\u5f00\u9500\u9ad8\u4ee5\u53ca\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7cfb\u7edf\u54cd\u5e94\u6027\u5dee\u3002", "method": "TORTA\u91c7\u7528\u4e24\u5c42\u8bbe\u8ba1\uff0c\u5b8f\u89c2\u8c03\u5ea6\u5668\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u6700\u4f18\u4f20\u8f93\u534f\u8c03\u533a\u57df\u95f4\u4efb\u52a1\u5206\u914d\uff0c\u5fae\u89c2\u5206\u914d\u5668\u4f18\u5316\u533a\u57df\u5185\u4efb\u52a1\u5230\u670d\u52a1\u5668\u7684\u5206\u914d\u4ee5\u51cf\u5c11\u5ef6\u8fdf\u548c\u5207\u6362\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTORTA\u5728\u591a\u79cd\u7f51\u7edc\u62d3\u6251\u4e0b\u5c06\u5e73\u5747\u63a8\u7406\u54cd\u5e94\u65f6\u95f4\u51cf\u5c1115%\uff0c\u8d1f\u8f7d\u5747\u8861\u63d0\u53474-5%\uff0c\u603b\u8fd0\u8425\u6210\u672c\u964d\u4f4e10-20%\u3002", "conclusion": "TORTA\u901a\u8fc7\u65f6\u7a7a\u611f\u77e5\u8c03\u5ea6\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0fGPU\u63a8\u7406\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e3a\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u8d44\u6e90\u8c03\u5ea6\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10178", "pdf": "https://arxiv.org/pdf/2507.10178", "abs": "https://arxiv.org/abs/2507.10178", "authors": ["Wonung Kim", "Yubin Lee", "Yoonsung Kim", "Jinwoo Hwang", "Seongryong Oh", "Jiyong Jung", "Aziz Huseynov", "Woong Gyu Park", "Chang Hyun Park", "Divya Mahajan", "Jongse Park"], "title": "Pimba: A Processing-in-Memory Acceleration for Post-Transformer Large Language Model Serving", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Transformers are the driving force behind today's Large Language Models\n(LLMs), serving as the foundation for their performance and versatility. Yet,\ntheir compute and memory costs grow with sequence length, posing scalability\nchallenges for long-context inferencing. In response, the algorithm community\nis exploring alternative architectures, such as state space models (SSMs),\nlinear attention, and recurrent neural networks (RNNs), which we refer to as\npost-transformers. This shift presents a key challenge: building a serving\nsystem that efficiently supports both transformer and post-transformer LLMs\nwithin a unified framework. To address this challenge, we analyze the\nperformance characteristics of transformer and post-transformer LLMs. Despite\ntheir algorithmic differences, both are fundamentally limited by memory\nbandwidth under batched inference due to attention in transformers and state\nupdates in post-transformers. Further analyses suggest two additional insights:\n(1) state update operations, unlike attention, incur high hardware cost, making\nper-bank PIM acceleration inefficient, and (2) different low-precision\narithmetic methods offer varying accuracy-area tradeoffs, while we identify\nMicrosoft's MX as the Pareto-optimal choice. Building on these insights, we\ndesign Pimba as an array of State-update Processing Units (SPUs), each shared\nbetween two banks to enable interleaved access to PIM. Each SPU includes a\nState-update Processing Engine (SPE) that comprises element-wise multipliers\nand adders using MX-based quantized arithmetic, enabling efficient execution of\nstate update and attention operations. Our evaluation shows that, compared to\nLLM-optimized GPU and GPU+PIM systems, Pimba achieves up to 3.2x and 2.1x\nhigher token generation throughput, respectively.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86Transformer\u548cpost-transformer LLMs\u7684\u6027\u80fd\u7279\u70b9\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6846\u67b6Pimba\uff0c\u901a\u8fc7SPUs\u9ad8\u6548\u652f\u6301\u4e24\u8005\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u541e\u5410\u91cf\u3002", "motivation": "\u7531\u4e8eTransformer\u7684\u7b97\u529b\u548c\u5185\u5b58\u6210\u672c\u968f\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\u800c\u589e\u957f\uff0c\u5f71\u54cd\u4e86\u957f\u6587\u672c\u63a8\u7406\u7684\u53ef\u6269\u5c55\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u9ad8\u6548\u652f\u6301Transformer\u548cpost-transformer LLMs\u7684\u6846\u67b6\u3002", "method": "\u5206\u6790\u4e86Transformer\u548cpost-transformer LLMs\u7684\u6027\u80fd\u74f6\u9888\uff0c\u8bbe\u8ba1\u4e86Pimba\u7cfb\u7edf\uff0c\u5305\u542b\u5171\u4eab\u7684State-update Processing Units (SPUs)\uff0c\u4f7f\u7528MX\u91cf\u5316\u7b97\u6cd5\u9ad8\u6548\u6267\u884c\u72b6\u6001\u66f4\u65b0\u548c\u6ce8\u610f\u529b\u64cd\u4f5c\u3002", "result": "\u4e0e\u4f18\u5316\u7684GPU\u548cGPU+PIM\u7cfb\u7edf\u76f8\u6bd4\uff0cPimba\u7684token\u751f\u6210\u541e\u5410\u91cf\u5206\u522b\u63d0\u9ad8\u4e863.2\u500d\u548c2.1\u500d\u3002", "conclusion": "Pimba\u6210\u529f\u89e3\u51b3\u4e86Transformer\u548cpost-transformer LLMs\u7684\u7edf\u4e00\u9ad8\u6548\u670d\u52a1\u95ee\u9898\uff0c\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3002"}}
{"id": "2507.10337", "pdf": "https://arxiv.org/pdf/2507.10337", "abs": "https://arxiv.org/abs/2507.10337", "authors": ["Benzhao Tang", "Shiyu Yang", "Zhitao Shen", "Wenjie Zhang", "Xuemin Lin", "Zhihong Tian"], "title": "LogLite: Lightweight Plug-and-Play Streaming Log Compression", "categories": ["cs.DB"], "comment": "accepted by VLDB 2025", "summary": "Log data is a vital resource for capturing system events and states. With the\nincreasing complexity and widespread adoption ofmodern software systems and IoT\ndevices, the daily volume of log generation has surged to tens of petabytes,\nleading to significant collection and storage costs. To address this challenge,\nlossless log compression has emerged as an effective solution, enabling\nsubstantial resource savings without compromising log information. In this\npaper, we first conduct a characterization study on extensive public log\ndatasets and identify four key observations. Building on these insights, we\npropose LogLite, a lightweight, plug-and-play, streaming lossless compression\nalgorithm designed to handle both TEXT and JSON logs throughout their life\ncycle. LogLite requires no predefined rules or pre-training and is inherently\nadaptable to evolving log structures. Our evaluation shows that, compared to\nstate-of-the-art baselines, LogLite achieves Pareto optimality in most\nscenarios, delivering an average improvement of up to 67.8% in compression\nratio and up to 2.7 $\\times$ in compression speed.", "AI": {"tldr": "LogLite\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u5373\u63d2\u5373\u7528\u7684\u65e0\u635f\u65e5\u5fd7\u538b\u7f29\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u538b\u7f29\u6548\u7387\u548c\u901f\u5ea6\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u548cIoT\u8bbe\u5907\u7684\u666e\u53ca\uff0c\u65e5\u5fd7\u6570\u636e\u91cf\u6fc0\u589e\uff0c\u5bfc\u81f4\u5b58\u50a8\u548c\u6536\u96c6\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u9ad8\u6548\u7684\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u516c\u5f00\u65e5\u5fd7\u6570\u636e\u96c6\u7684\u7279\u5f81\u5206\u6790\uff0c\u63d0\u51fa\u65e0\u9884\u5b9a\u4e49\u89c4\u5219\u6216\u9884\u8bad\u7ec3\u7684LogLite\u7b97\u6cd5\uff0c\u9002\u7528\u4e8eTEXT\u548cJSON\u65e5\u5fd7\u3002", "result": "LogLite\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u5b9e\u73b0Pareto\u6700\u4f18\uff0c\u538b\u7f29\u6bd4\u63d0\u534767.8%\uff0c\u538b\u7f29\u901f\u5ea6\u63d0\u53472.7\u500d\u3002", "conclusion": "LogLite\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u65e5\u5fd7\u538b\u7f29\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u65e5\u5fd7\u7ed3\u6784\u3002"}}
{"id": "2507.09489", "pdf": "https://arxiv.org/pdf/2507.09489", "abs": "https://arxiv.org/abs/2507.09489", "authors": ["Zikun Deng", "Yuanbang Liu", "Mingrui Zhu", "Da Xiang", "Haiyue Yu", "Zicheng Su", "Qinglong Lu", "Tobias Schreck", "Yi Cai"], "title": "TraSculptor: Visual Analytics for Enhanced Decision-Making in Road Traffic Planning", "categories": ["cs.HC"], "comment": "IEEE Transactions on Visualization and Computer Graphics", "summary": "The design of urban road networks significantly influences traffic\nconditions, underscoring the importance of informed traffic planning. Traffic\nplanning experts rely on specialized platforms to simulate traffic systems,\nassessing the efficacy of the road network across various states of\nmodifications. Nevertheless, a prevailing issue persists: many existing traffic\nplanning platforms exhibit inefficiencies in flexibly interacting with the road\nnetwork's structure and attributes and intuitively comparing multiple states\nduring the iterative planning process. This paper introduces TraSculptor, an\ninteractive planning decision-making system. To develop TraSculptor, we\nidentify and address two challenges: interactive modification of road networks\nand intuitive comparison of multiple network states. For the first challenge,\nwe establish flexible interactions to enable experts to easily and directly\nmodify the road network on the map. For the second challenge, we design a\ncomparison view with a history tree of multiple states and a road-state matrix\nto facilitate intuitive comparison of road network states. To evaluate\nTraSculptor, we provided a usage scenario where the Braess's paradox was\nshowcased, invited experts to perform a case study on the Sioux Falls network,\nand collected expert feedback through interviews.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86TraSculptor\u7cfb\u7edf\uff0c\u89e3\u51b3\u4ea4\u901a\u89c4\u5212\u4e2d\u7f51\u7edc\u4fee\u6539\u548c\u72b6\u6001\u6bd4\u8f83\u7684\u4ea4\u4e92\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4ea4\u901a\u89c4\u5212\u5e73\u53f0\u5728\u4ea4\u4e92\u6027\u548c\u591a\u72b6\u6001\u6bd4\u8f83\u65b9\u9762\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u8bbe\u8ba1\u7075\u6d3b\u7684\u4ea4\u4e92\u4fee\u6539\u529f\u80fd\u548c\u591a\u72b6\u6001\u5386\u53f2\u6811\u6bd4\u8f83\u89c6\u56fe\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u548c\u4e13\u5bb6\u53cd\u9988\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "conclusion": "TraSculptor\u63d0\u5347\u4e86\u4ea4\u901a\u89c4\u5212\u4e2d\u7684\u4ea4\u4e92\u6027\u548c\u6bd4\u8f83\u6548\u7387\u3002"}}
{"id": "2507.09220", "pdf": "https://arxiv.org/pdf/2507.09220", "abs": "https://arxiv.org/abs/2507.09220", "authors": ["Syed Tauhid Ullah Shah", "Mohammad Hussein", "Ann Barcomb", "Mohammad Moshirpour"], "title": "Explainability as a Compliance Requirement: What Regulated Industries Need from AI Tools for Design Artifact Generation", "categories": ["cs.SE"], "comment": null, "summary": "Artificial Intelligence (AI) tools for automating design artifact generation\nare increasingly used in Requirements Engineering (RE) to transform textual\nrequirements into structured diagrams and models. While these AI tools,\nparticularly those based on Natural Language Processing (NLP), promise to\nimprove efficiency, their adoption remains limited in regulated industries\nwhere transparency and traceability are essential. In this paper, we\ninvestigate the explainability gap in AI-driven design artifact generation\nthrough semi-structured interviews with ten practitioners from safety-critical\nindustries. We examine how current AI-based tools are integrated into workflows\nand the challenges arising from their lack of explainability. We also explore\nmitigation strategies, their impact on project outcomes, and features needed to\nimprove usability. Our findings reveal that non-explainable AI outputs\nnecessitate extensive manual validation, reduce stakeholder trust, struggle to\nhandle domain-specific terminology, disrupt team collaboration, and introduce\nregulatory compliance risks, often negating the anticipated efficiency\nbenefits. To address these issues, we identify key improvements, including\nsource tracing, providing clear justifications for tool-generated decisions,\nsupporting domain-specific adaptation, and enabling compliance validation. This\nstudy outlines a practical roadmap for improving the transparency, reliability,\nand applicability of AI tools in requirements engineering workflows,\nparticularly in regulated and safety-critical environments where explainability\nis crucial for adoption and certification.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86AI\u5de5\u5177\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u81ea\u52a8\u751f\u6210\u8bbe\u8ba1\u5de5\u4ef6\u65f6\u7684\u53ef\u89e3\u91ca\u6027\u5dee\u8ddd\uff0c\u53d1\u73b0\u975e\u900f\u660eAI\u8f93\u51fa\u5bfc\u81f4\u624b\u52a8\u9a8c\u8bc1\u589e\u52a0\u3001\u4fe1\u4efb\u964d\u4f4e\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u63aa\u65bd\u3002", "motivation": "\u7814\u7a76AI\u5de5\u5177\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u4e2d\u5e94\u7528\u7684\u900f\u660e\u5ea6\u95ee\u9898\uff0c\u56e0\u5176\u5728\u53d7\u76d1\u7ba1\u884c\u4e1a\u4e2d\u7684\u4f4e\u91c7\u7528\u7387\u3002", "method": "\u901a\u8fc7\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u4e0e\u5341\u4f4d\u4ece\u4e1a\u8005\u63a2\u8ba8AI\u5de5\u5177\u7684\u96c6\u6210\u548c\u53ef\u89e3\u91ca\u6027\u6311\u6218\u3002", "result": "\u53d1\u73b0\u975e\u900f\u660eAI\u8f93\u51fa\u5e26\u6765\u9a8c\u8bc1\u3001\u4fe1\u4efb\u3001\u5408\u89c4\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u5982\u6e90\u5934\u8ffd\u8e2a\u548c\u9886\u57df\u9002\u5e94\u3002", "conclusion": "\u4e3a\u63d0\u5347AI\u5de5\u5177\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u7ebf\u56fe\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u53d7\u76d1\u7ba1\u73af\u5883\u3002"}}
{"id": "2507.09613", "pdf": "https://arxiv.org/pdf/2507.09613", "abs": "https://arxiv.org/abs/2507.09613", "authors": ["Giovanni Geraci", "Francesca Meneghello", "Francesc Wilhelmi", "David Lopez-Perez", "I\u00f1aki Val", "Lorenzo Galati Giordano", "Carlos Cordeiro", "Monisha Ghosh", "Edward Knightly", "Boris Bellalta"], "title": "Wi-Fi: Twenty-Five Years and Counting", "categories": ["cs.NI", "cs.IT", "eess.SP", "math.IT"], "comment": "39 pages, 28 figures, 3 tables", "summary": "Today, Wi-Fi is over 25 years old. Yet, despite sharing the same branding\nname, today's Wi-Fi boasts entirely new capabilities that were not even on the\nroadmap 25 years ago. This article aims to provide a holistic and comprehensive\ntechnical and historical tutorial on Wi-Fi, beginning with IEEE 802.11b (Wi-Fi\n1) and looking forward to IEEE 802.11bn (Wi-Fi 8). This is the first tutorial\narticle to span these eight generations. Rather than a generation-by-generation\nexposition, we describe the key mechanisms that have advanced Wi-Fi. We begin\nby discussing spectrum allocation and coexistence, and detailing the IEEE\n802.11 standardization cycle. Second, we provide an overview of the physical\nlayer and describe key elements that have enabled data rates to increase by\nover 1,000x. Third, we describe how Wi-Fi Medium Access Control has been\nenhanced from the original Distributed Coordination Function to now include\ncapabilities spanning from frame aggregation to wideband spectrum access.\nFourth, we describe how Wi-Fi 5 first broke the one-user-at-a-time paradigm and\nintroduced multi-user access. Fifth, given the increasing use of mobile,\nbattery-powered devices, we describe Wi-Fi's energy-saving mechanisms over the\ngenerations. Sixth, we discuss how Wi-Fi was enhanced to seamlessly aggregate\nspectrum across 2.4 GHz, 5 GHz, and 6 GHz bands to improve throughput,\nreliability, and latency. Finally, we describe how Wi-Fi enables nearby Access\nPoints to coordinate in order to improve performance and efficiency. In the\nAppendix, we further discuss Wi-Fi developments beyond 802.11bn, including\nintegrated mmWave operations, sensing, security and privacy extensions, and the\nadoption of AI/ML.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86Wi-Fi\u4ece1\u4ee3\u52308\u4ee3\u7684\u5168\u65b9\u4f4d\u6280\u672f\u5386\u53f2\u6559\u7a0b\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u9891\u8c31\u5206\u914d\u3001\u7269\u7406\u5c42\u5347\u7ea7\u3001\u591a\u7528\u6237\u8bbf\u95ee\u7b49\u5173\u952e\u673a\u5236\u7684\u6f14\u8fdb\u3002", "motivation": "Wi-Fi\u6280\u672f\u5728\u8fc7\u53bb25\u5e74\u7ecf\u5386\u4e86\u5de8\u5927\u53d8\u9769\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u4eceWi-Fi 1\u5230Wi-Fi 8\u7684\u5168\u9762\u6280\u672f\u6559\u7a0b\u7a7a\u767d\u3002", "method": "\u6587\u7ae0\u901a\u8fc7\u5206\u6a21\u5757\u8ba8\u8bba\u9891\u8c31\u5206\u914d\u3001\u7269\u7406\u5c42\u6280\u672f\u3001\u591a\u7528\u6237\u8bbf\u95ee\u7b49\u6838\u5fc3\u673a\u5236\uff0c\u800c\u975e\u9010\u4ee3\u53d9\u8ff0\uff0c\u5168\u9762\u5206\u6790Wi-Fi\u7684\u6f14\u8fdb\u3002", "result": "Wi-Fi\u7684\u6570\u636e\u901f\u7387\u63d0\u5347\u8d851000\u500d\uff0c\u652f\u6301\u591a\u7528\u6237\u8bbf\u95ee\u3001\u8282\u80fd\u4f18\u5316\u7b49\uff0c\u672a\u6765\u8fd8\u5c06\u96c6\u6210\u6beb\u7c73\u6ce2\u548cAI\u6280\u672f\u3002", "conclusion": "Wi-Fi\u7684\u6301\u7eed\u521b\u65b0\u4f7f\u5176\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u529f\u80fd\u4e0a\u5927\u5e45\u63d0\u5347\uff0c\u672a\u6765\u6280\u672f\u6269\u5c55\u5c06\u8fdb\u4e00\u6b65\u589e\u5f3a\u5176\u80fd\u529b\u3002"}}
{"id": "2507.10403", "pdf": "https://arxiv.org/pdf/2507.10403", "abs": "https://arxiv.org/abs/2507.10403", "authors": ["Daniele Rege Cambrin", "Lorenzo Vaiani", "Giuseppe Gallipoli", "Luca Cagliero", "Paolo Garza"], "title": "Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.MM"], "comment": null, "summary": "Retrieving relevant imagery from vast satellite archives is crucial for\napplications like disaster response and long-term climate monitoring. However,\nmost text-to-image retrieval systems are limited to RGB data, failing to\nexploit the unique physical information captured by other sensors, such as the\nall-weather structural sensitivity of Synthetic Aperture Radar (SAR) or the\nspectral signatures in optical multispectral data. To bridge this gap, we\nintroduce CrisisLandMark, a new large-scale corpus of over 647,000 Sentinel-1\nSAR and Sentinel-2 multispectral images paired with structured textual\nannotations for land cover, land use, and crisis events harmonized from\nauthoritative land cover systems (CORINE and Dynamic World) and crisis-specific\nsources. We then present CLOSP (Contrastive Language Optical SAR Pretraining),\na novel framework that uses text as a bridge to align unpaired optical and SAR\nimages into a unified embedding space. Our experiments show that CLOSP achieves\na new state-of-the-art, improving retrieval nDGC by 54% over existing models.\nAdditionally, we find that the unified training strategy overcomes the inherent\ndifficulty of interpreting SAR imagery by transferring rich semantic knowledge\nfrom the optical domain with indirect interaction. Furthermore, GeoCLOSP, which\nintegrates geographic coordinates into our framework, creates a powerful\ntrade-off between generality and specificity: while the CLOSP excels at general\nsemantic tasks, the GeoCLOSP becomes a specialized expert for retrieving\nlocation-dependent crisis events and rare geographic features. This work\nhighlights that the integration of diverse sensor data and geographic context\nis essential for unlocking the full potential of remote sensing archives.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CrisisLandMark\u6570\u636e\u96c6\u548cCLOSP\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u4f20\u611f\u5668\u6570\u636e\uff08SAR\u548c\u591a\u5149\u8c31\uff09\u4e0e\u6587\u672c\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6587\u672c-\u56fe\u50cf\u68c0\u7d22\u7cfb\u7edf\u4e3b\u8981\u9650\u4e8eRGB\u6570\u636e\uff0c\u672a\u80fd\u5229\u7528SAR\u548c\u591a\u5149\u8c31\u6570\u636e\u7684\u72ec\u7279\u7269\u7406\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5176\u5728\u707e\u5bb3\u54cd\u5e94\u548c\u6c14\u5019\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165CrisisLandMark\u6570\u636e\u96c6\uff0864.7\u4e07\u5f20SAR\u548c\u591a\u5149\u8c31\u56fe\u50cf\u4e0e\u7ed3\u6784\u5316\u6587\u672c\u914d\u5bf9\uff09\uff0c\u5e76\u63d0\u51faCLOSP\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5c06\u5149\u5b66\u548cSAR\u56fe\u50cf\u5bf9\u9f50\u5230\u7edf\u4e00\u7684\u5d4c\u5165\u7a7a\u95f4\u3002\u8fd8\u63d0\u51fa\u4e86GeoCLOSP\uff0c\u6574\u5408\u5730\u7406\u5750\u6807\u4ee5\u63d0\u5347\u5b9a\u4f4d\u4f9d\u8d56\u4efb\u52a1\u7684\u6027\u80fd\u3002", "result": "CLOSP\u5728\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684nDGC\u6307\u6807\u4e0a\u6bd4\u73b0\u6709\u6a21\u578b\u63d0\u534754%\uff0c\u5e76\u901a\u8fc7\u7edf\u4e00\u8bad\u7ec3\u7b56\u7565\u514b\u670dSAR\u56fe\u50cf\u89e3\u91ca\u7684\u56f0\u96be\u3002GeoCLOSP\u5728\u5b9a\u4f4d\u4f9d\u8d56\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u591a\u4f20\u611f\u5668\u6570\u636e\u548c\u5730\u7406\u4e0a\u4e0b\u6587\u7684\u6574\u5408\u5bf9\u5145\u5206\u53d1\u6325\u9065\u611f\u6863\u6848\u6f5c\u529b\u81f3\u5173\u91cd\u8981\u3002CLOSP\u548cGeoCLOSP\u4e3a\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.10466", "pdf": "https://arxiv.org/pdf/2507.10466", "abs": "https://arxiv.org/abs/2507.10466", "authors": ["Kathlee Barsse", "Romain P\u00e9choux", "Simon Perdrix"], "title": "A Quantum Programming Language for Coherent Control", "categories": ["cs.LO"], "comment": null, "summary": "We introduce a programming language that allows for the coherent control of\narbitrary quantum operations. The problem of defining coherent control beyond\nthe unitary case, using, for example, a quantum conditional in the presence of\nrecursion or iteration has long been known to be a major difficulty. We resolve\nthis problem by defining an operational semantics based on appropriate Kraus\ndecompositions and a denotational semantics based on vacuum-extensions. We show\nthat the language is universal for vacuum-extensions and that the two semantics\nare adequate. Moreover, we define a notion of observational equivalence: two\nprograms are equivalent if their probability of termination is the same in any\ncontext. The denotational semantics is shown to be fully abstract for\nobservational equivalence.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7f16\u7a0b\u8bed\u8a00\u4ee5\u4e00\u81f4\u63a7\u5236\u4efb\u610f\u91cf\u5b50\u64cd\u4f5c\uff0c\u89e3\u51b3\u9012\u5f52\u6216\u8fed\u4ee3\u4e2d\u91cf\u5b50\u6761\u4ef6\u63a7\u5236\u7684\u96be\u9898\uff0c\u901a\u8fc7Kraus\u5206\u89e3\u548c\u771f\u7a7a\u6269\u5c55\u8bed\u4e49\u5b9e\u73b0\u901a\u7528\u6027\uff0c\u5e76\u9a8c\u8bc1\u5176\u5145\u5206\u6027\u4e0e\u5b8c\u5168\u62bd\u8c61\u6027\u3002", "motivation": "\u89e3\u51b3\u91cf\u5b50\u64cd\u4f5c\u4e2d\u7684\u4e00\u81f4\u63a7\u5236\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u9012\u5f52\u6216\u8fed\u4ee3\u6761\u4ef6\u4e0b\u91cf\u5b50\u6761\u4ef6\u63a7\u5236\u7684\u6311\u6218\u3002", "method": "\u5b9a\u4e49\u57fa\u4e8eKraus\u5206\u89e3\u7684\u64cd\u4f5c\u8bed\u4e49\u548c\u57fa\u4e8e\u771f\u7a7a\u6269\u5c55\u7684\u6307\u79f0\u8bed\u4e49\uff0c\u9a8c\u8bc1\u8bed\u8a00\u7684\u901a\u7528\u6027\u548c\u8bed\u4e49\u7684\u5145\u5206\u6027\u3002", "result": "\u8bc1\u660e\u8bed\u8a00\u5bf9\u771f\u7a7a\u6269\u5c55\u5177\u6709\u901a\u7528\u6027\uff0c\u64cd\u4f5c\u4e0e\u6307\u79f0\u8bed\u4e49\u5145\u5206\u4e14\u6307\u79f0\u8bed\u4e49\u5bf9\u89c2\u5bdf\u7b49\u4ef7\u5b8c\u5168\u62bd\u8c61\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u91cf\u5b50\u63a7\u5236\u95ee\u9898\u7684\u65b0\u8bed\u8a00\uff0c\u9a8c\u8bc1\u4e86\u5176\u8bed\u4e49\u7684\u5145\u5206\u6027\u548c\u5b8c\u5168\u62bd\u8c61\u6027\uff0c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.09776", "pdf": "https://arxiv.org/pdf/2507.09776", "abs": "https://arxiv.org/abs/2507.09776", "authors": ["Mihir Kavishwar", "Naresh Shanbhag"], "title": "Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing", "categories": ["eess.SP", "cs.AR"], "comment": "Code available at: https://github.com/mihirvk2/CSNR-optimal-ADC", "summary": "Analog in-memory computing (AIMC) is an energy-efficient alternative to\ndigital architectures for accelerating machine learning and signal processing\nworkloads. However, its energy efficiency is limited by the high energy cost of\nthe column analog-to-digital converters (ADCs). Reducing the ADC precision is\nan effective approach to lowering its energy cost. However, doing so also\nreduces the AIMC's computational accuracy thereby making it critical to\nidentify the minimum precision required to meet a target accuracy. Prior works\noverestimate the ADC precision requirements by modeling quantization error as\ninput-independent noise, maximizing the signal-to-quantization-noise ratio\n(SQNR), and ignoring the discrete nature of ideal pre-ADC signal. We address\nthese limitations by developing analytical expressions for estimating the\ncompute signal-to-noise ratio (CSNR), a true metric of accuracy for AIMCs, and\npropose CACTUS, an algorithm to obtain CSNR-optimal ADC parameters. Using a\ncircuit-aware behavioral model of an SRAM-based AIMC in a 28nm CMOS process, we\nshow that for a 256-dimensional binary dot product, CACTUS reduces the ADC\nprecision requirements by 3b while achieving 6dB higher CSNR over prior\nmethods. We also delineate operating conditions under which our proposed\nCSNR-optimal ADCs outperform conventional SQNR-optimal ADCs.", "AI": {"tldr": "AIMC\u7684\u8282\u80fd\u6f5c\u529b\u53d7\u9650\u4e8e\u9ad8\u80fd\u8017\u7684ADC\uff0c\u964d\u4f4eADC\u7cbe\u5ea6\u867d\u80fd\u8282\u80fd\u4f46\u4f1a\u5f71\u54cd\u8ba1\u7b97\u7cbe\u5ea6\u3002\u672c\u6587\u63d0\u51faCSNR\u548cCACTUS\u7b97\u6cd5\uff0c\u4f18\u5316ADC\u53c2\u6570\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u7cbe\u5ea6\u548c\u66f4\u4f4e\u80fd\u8017\u3002", "motivation": "\u89e3\u51b3AIMC\u4e2d\u56e0ADC\u9ad8\u7cbe\u5ea6\u8981\u6c42\u5bfc\u81f4\u7684\u80fd\u8017\u95ee\u9898\uff0c\u540c\u65f6\u786e\u4fdd\u8ba1\u7b97\u7cbe\u5ea6\u3002", "method": "\u5f00\u53d1CSNR\u5206\u6790\u6a21\u578b\u5e76\u63d0\u51faCACTUS\u7b97\u6cd5\uff0c\u4f18\u5316ADC\u53c2\u6570\u3002", "result": "\u572828nm CMOS\u5de5\u827a\u4e0b\uff0cCACTUS\u53ef\u5c06ADC\u7cbe\u5ea6\u964d\u4f4e3\u4f4d\uff0c\u540c\u65f6\u63d0\u9ad8CSNR 6dB\u3002", "conclusion": "CSNR-optimal ADC\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u4f20\u7edfSQNR-optimal ADC\uff0c\u663e\u8457\u63d0\u5347AIMC\u7684\u80fd\u6548\u6bd4\u3002"}}
{"id": "2507.10391", "pdf": "https://arxiv.org/pdf/2507.10391", "abs": "https://arxiv.org/abs/2507.10391", "authors": ["Mihail Stoian", "Johannes Th\u00fcrauf", "Andreas Zimmerer", "Alexander van Renen", "Andreas Kipf"], "title": "Instance-Optimized String Fingerprints", "categories": ["cs.DB"], "comment": "Sixth International Workshop on Applied AI for Database Systems and\n  Applications (AIDB 2025)", "summary": "Recent research found that cloud data warehouses are text-heavy. However,\ntheir capabilities for efficiently processing string columns remain limited,\nrelying primarily on techniques like dictionary encoding and prefix-based\npartition pruning. In recent work, we introduced string fingerprints - a\nlightweight secondary index structure designed to approximate LIKE predicates,\nalbeit with false positives. This approach is particularly compelling for\ncolumnar query engines, where fingerprints can help reduce both compute and I/O\noverhead. We show that string fingerprints can be optimized for specific\nworkloads using mixed-integer optimization, and that they can generalize to\nunseen table predicates. On an IMDb column evaluated in DuckDB v1.3, this\nyields table-scan speedups of up to 1.36$\\times$.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5b57\u7b26\u4e32\u6307\u7eb9\u201d\u7684\u8f7b\u91cf\u7ea7\u4e8c\u7ea7\u7d22\u5f15\u7ed3\u6784\uff0c\u7528\u4e8e\u8fd1\u4f3c\u5904\u7406LIKE\u8c13\u8bcd\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u548cI/O\u5f00\u9500\uff0c\u5e76\u5728DuckDB\u4e2d\u5b9e\u73b0\u4e861.36\u500d\u7684\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u4e91\u6570\u636e\u4ed3\u5e93\u4e2d\u5b57\u7b26\u4e32\u5217\u7684\u5904\u7406\u6548\u7387\u8f83\u4f4e\uff0c\u73b0\u6709\u6280\u672f\uff08\u5982\u5b57\u5178\u7f16\u7801\u548c\u524d\u7f00\u5206\u533a\u4fee\u526a\uff09\u80fd\u529b\u6709\u9650\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u5b57\u7b26\u4e32\u5217\u7684\u5904\u7406\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u5b57\u7b26\u4e32\u6307\u7eb9\u4f5c\u4e3a\u4e8c\u7ea7\u7d22\u5f15\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408\u6df7\u5408\u6574\u6570\u4f18\u5316\u6280\u672f\uff0c\u9488\u5bf9\u7279\u5b9a\u8d1f\u8f7d\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728DuckDB v1.3\u4e2d\uff0cIMDb\u5217\u7684\u626b\u63cf\u901f\u5ea6\u63d0\u5347\u4e861.36\u500d\u3002", "conclusion": "\u5b57\u7b26\u4e32\u6307\u7eb9\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f18\u5316\u5b57\u7b26\u4e32\u5904\u7406\u7684\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5217\u5f0f\u67e5\u8be2\u5f15\u64ce\u3002"}}
{"id": "2507.09549", "pdf": "https://arxiv.org/pdf/2507.09549", "abs": "https://arxiv.org/abs/2507.09549", "authors": ["Hrittika Bhowmick", "Shilpaa Anand"], "title": "The Spectacle of Fidelity: Blind Resistance and the Wizardry of Prototyping", "categories": ["cs.HC", "H.5.2; K.4.2; D.2.2"], "comment": "3 pages. Submitted for Access InContext Workshop at CHI'25, April 26,\n  2025, Yokohama, Japan", "summary": "Prototyping is widely regarded in Human-Computer Interaction as an iterative\nprocess through which ideas are tested and refined, often via visual mockups,\nscreen flows, and coded simulations. This position paper critiques the\nvisual-centric norms embedded in prototyping culture by drawing from the lived\nexperiences of blind scholars and insights from cultural disability studies. It\ndiscusses how dominant methods of prototyping rely on an unexamined fidelity to\nsight, privileging what can be rendered visibly coherent while marginalizing\nother modes of knowing and making. By repositioning prototyping as a situated,\nembodied, and relational practice, this paper challenges HCI to rethink what\nkinds of design participation are legitimized and which are excluded when\nprototyping is reduced to screen-based simulations.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u4e86\u4eba\u673a\u4ea4\u4e92\u4e2d\u89c6\u89c9\u4e2d\u5fc3\u539f\u578b\u8bbe\u8ba1\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5021\u4ece\u76f2\u4eba\u5b66\u8005\u7684\u7ecf\u9a8c\u51fa\u53d1\u91cd\u65b0\u5b9a\u4e49\u539f\u578b\u8bbe\u8ba1\u3002", "motivation": "\u63a2\u8ba8\u73b0\u6709\u539f\u578b\u8bbe\u8ba1\u6587\u5316\u4e2d\u5bf9\u89c6\u89c9\u7684\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u4ee5\u53ca\u8fd9\u79cd\u4f9d\u8d56\u5982\u4f55\u6392\u9664\u4e86\u975e\u89c6\u89c9\u6a21\u5f0f\u7684\u8bbe\u8ba1\u53c2\u4e0e\u3002", "method": "\u7ed3\u5408\u76f2\u4eba\u5b66\u8005\u7684\u751f\u6d3b\u7ecf\u9a8c\u548c\u6587\u5316\u6b8b\u75be\u7814\u7a76\u7684\u89c1\u89e3\uff0c\u5206\u6790\u89c6\u89c9\u4e2d\u5fc3\u539f\u578b\u8bbe\u8ba1\u7684\u5c40\u9650\u6027\u3002", "result": "\u63d0\u51fa\u539f\u578b\u8bbe\u8ba1\u5e94\u4f5c\u4e3a\u4e00\u79cd\u60c5\u5883\u5316\u3001\u5177\u8eab\u5316\u548c\u5173\u7cfb\u6027\u7684\u5b9e\u8df5\uff0c\u4ee5\u5305\u5bb9\u66f4\u591a\u5143\u7684\u8bbe\u8ba1\u53c2\u4e0e\u65b9\u5f0f\u3002", "conclusion": "\u547c\u5401\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u91cd\u65b0\u5ba1\u89c6\u539f\u578b\u8bbe\u8ba1\u7684\u5b9a\u4e49\uff0c\u4ee5\u66f4\u5305\u5bb9\u7684\u6001\u5ea6\u5bf9\u5f85\u4e0d\u540c\u611f\u77e5\u6a21\u5f0f\u7684\u8bbe\u8ba1\u53c2\u4e0e\u3002"}}
{"id": "2507.09315", "pdf": "https://arxiv.org/pdf/2507.09315", "abs": "https://arxiv.org/abs/2507.09315", "authors": ["Yongqian Sun", "Weihua Kuang", "Chao Shen", "Xidao Wen", "Tinghua Zheng", "Heng Liu", "Shenglin Zhang", "Bo Wu", "Dan Pei"], "title": "Enhancing Interpretability in Software Change Management with Chain-of-Thought Reasoning", "categories": ["cs.SE", "cs.AI"], "comment": "22 pages, 19 figures", "summary": "In modern online services, frequent software changes introduce significant\nrisks. To tackle this challenge, we propose SCELM (Software Change Evaluation\nand Lifecycle Management), an end-to-end automated framework for software\nchange management. SCELM aims to manage software changes efficiently and\nprecisely, significantly reducing service failures and economic losses.", "AI": {"tldr": "\u63d0\u51faSCELM\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u7ba1\u7406\u8f6f\u4ef6\u53d8\u66f4\uff0c\u964d\u4f4e\u670d\u52a1\u5931\u8d25\u548c\u7ecf\u6d4e\u635f\u5931\u3002", "motivation": "\u73b0\u4ee3\u5728\u7ebf\u670d\u52a1\u4e2d\u9891\u7e41\u7684\u8f6f\u4ef6\u53d8\u66f4\u5e26\u6765\u4e86\u663e\u8457\u98ce\u9669\u3002", "method": "\u63d0\u51faSCELM\uff08\u8f6f\u4ef6\u53d8\u66f4\u8bc4\u4f30\u4e0e\u751f\u547d\u5468\u671f\u7ba1\u7406\uff09\u6846\u67b6\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u7ba1\u7406\u3002", "result": "SCELM\u80fd\u9ad8\u6548\u3001\u7cbe\u51c6\u5730\u7ba1\u7406\u8f6f\u4ef6\u53d8\u66f4\uff0c\u663e\u8457\u51cf\u5c11\u670d\u52a1\u5931\u8d25\u548c\u7ecf\u6d4e\u635f\u5931\u3002", "conclusion": "SCELM\u662f\u89e3\u51b3\u8f6f\u4ef6\u53d8\u66f4\u98ce\u9669\u7684\u6709\u6548\u81ea\u52a8\u5316\u6846\u67b6\u3002"}}
{"id": "2507.09798", "pdf": "https://arxiv.org/pdf/2507.09798", "abs": "https://arxiv.org/abs/2507.09798", "authors": ["Aashish Gottipati", "Lili Qiu"], "title": "Towards Robust RTC in Sparse LEO Constellations", "categories": ["cs.NI"], "comment": "8 pages, 5 figures", "summary": "Google's congestion control (GCC) has become a cornerstone for real-time\nvideo and audio communication, yet its performance remains fragile in emerging\nLow Earth Orbit (LEO) networks. Sparse direct-to-device constellations offer\nlonger duration links and reduced handover frequency compared to dense\ndeployments, presenting a unique opportunity for high-quality real-time\ncommunication (RTC) in environments with limited terrestrial network\ninfrastructure. In this paper, we study the behavior of videoconferencing\nsystems in sparse LEO constellations. We observe that video quality degrades\ndue to inherent delays and network instability introduced by the high altitude\nand rapid movement of LEO satellites, with these effects exacerbated by\nWebRTC's conventional ``one-size-fits-all'' sender-side pacing queue\nmanagement. To boost RTC performance, we introduce a data-driven queue\nmanagement mechanism that adapts the maximum pacing queue capacity based on\npredicted handover activity. Specifically, our approach employs shorter queue\nlimits during stable, no-handover phases to prioritize low latency\ncommunication, and preemptively increases pacing queue capacity when entering\nperiods of increased handover activity to absorb disruptions. Our method yields\nup to $3$x improvements in video bitrate and reduces freeze rate by $62\\%$\ncompared to default WebRTC.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u7a00\u758fLEO\u661f\u5ea7\u4e2d\u89c6\u9891\u4f1a\u8bae\u7cfb\u7edf\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u961f\u5217\u7ba1\u7406\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u9891\u6bd4\u7279\u7387\u5e76\u964d\u4f4e\u4e86\u51bb\u7ed3\u7387\u3002", "motivation": "Google\u7684\u62e5\u585e\u63a7\u5236\u5728LEO\u7f51\u7edc\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u7a00\u758fLEO\u661f\u5ea7\u4e3a\u5b9e\u65f6\u901a\u4fe1\u63d0\u4f9b\u4e86\u72ec\u7279\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u6280\u672f\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u4f18\u52bf\u3002", "method": "\u5f15\u5165\u6570\u636e\u9a71\u52a8\u7684\u961f\u5217\u7ba1\u7406\u673a\u5236\uff0c\u6839\u636e\u9884\u6d4b\u7684\u624b\u5207\u6362\u6d3b\u52a8\u52a8\u6001\u8c03\u6574\u53d1\u9001\u7aef\u961f\u5217\u5bb9\u91cf\u3002", "result": "\u76f8\u6bd4\u9ed8\u8ba4WebRTC\uff0c\u89c6\u9891\u6bd4\u7279\u7387\u63d0\u53473\u500d\uff0c\u51bb\u7ed3\u7387\u964d\u4f4e62%\u3002", "conclusion": "\u8be5\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u7a00\u758fLEO\u7f51\u7edc\u4e2d\u7684\u5b9e\u65f6\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2507.10461", "pdf": "https://arxiv.org/pdf/2507.10461", "abs": "https://arxiv.org/abs/2507.10461", "authors": ["Tao Tang", "Chengxu Yang"], "title": "RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "eess.IV"], "comment": "To appear in the proceedings of the 6th International Conference on\n  Artificial Intelligence and Electromechanical Automation (AIEA 2025). 5\n  pages, 6 figures", "summary": "Pansharpening refers to the process of integrating a high resolution\npanchromatic (PAN) image with a lower resolution multispectral (MS) image to\ngenerate a fused product, which is pivotal in remote sensing. Despite the\neffectiveness of CNNs in addressing this challenge, they are inherently\nconstrained by the uniform application of convolutional kernels across all\nspatial positions, overlooking local content variations. To overcome this\nissue, we introduce RAPNet, a new architecture that leverages content-adaptive\nconvolution. At its core, RAPNet employs the Receptive-field Adaptive\nPansharpening Convolution (RAPConv), designed to produce spatially adaptive\nkernels responsive to local feature context, thereby enhancing the precision of\nspatial detail extraction. Additionally, the network integrates the\nPansharpening Dynamic Feature Fusion (PAN-DFF) module, which incorporates an\nattention mechanism to achieve an optimal balance between spatial detail\nenhancement and spectral fidelity. Comprehensive evaluations on publicly\navailable datasets confirm that RAPNet delivers superior performance compared\nto existing approaches, as demonstrated by both quantitative metrics and\nqualitative assessments. Ablation analyses further substantiate the\neffectiveness of the proposed adaptive components.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAPNet\u7684\u65b0\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u5185\u5bb9\u81ea\u9002\u5e94\u5377\u79ef\uff08RAPConv\uff09\u548c\u52a8\u6001\u7279\u5f81\u878d\u5408\u6a21\u5757\uff08PAN-DFF\uff09\u6539\u8fdb\u4e86\u9065\u611f\u56fe\u50cf\u878d\u5408\u7684\u7cbe\u5ea6\u548c\u6548\u679c\u3002", "motivation": "\u5c3d\u7ba1CNN\u5728\u9065\u611f\u56fe\u50cf\u878d\u5408\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u5747\u5300\u5377\u79ef\u6838\u7684\u5e94\u7528\u5ffd\u7565\u4e86\u5c40\u90e8\u5185\u5bb9\u53d8\u5316\uff0c\u5bfc\u81f4\u7cbe\u5ea6\u53d7\u9650\u3002", "method": "RAPNet\u91c7\u7528RAPConv\u751f\u6210\u7a7a\u95f4\u81ea\u9002\u5e94\u6838\uff0c\u5e76\u7ed3\u5408PAN-DFF\u6a21\u5757\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u4f18\u5316\u7a7a\u95f4\u7ec6\u8282\u4e0e\u5149\u8c31\u4fdd\u771f\u5ea6\u7684\u5e73\u8861\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0cRAPNet\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u81ea\u9002\u5e94\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u3002", "conclusion": "RAPNet\u901a\u8fc7\u81ea\u9002\u5e94\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u9065\u611f\u56fe\u50cf\u878d\u5408\u7684\u6027\u80fd\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09373", "pdf": "https://arxiv.org/pdf/2507.09373", "abs": "https://arxiv.org/abs/2507.09373", "authors": ["Rida Ait El Manssour", "Mahsa Naraghi", "Mahsa Shirmohammadi", "James Worrell"], "title": "Algebraic Closure of Matrix Sets Recognized by 1-VASS", "categories": ["cs.FL", "cs.LO", "math.AG"], "comment": null, "summary": "It is known how to compute the Zariski closure of a finitely generated monoid\nof matrices and, more generally, of a set of matrices specified by a regular\nlanguage. This result was recently used to give a procedure to compute all\npolynomial invariants of a given affine program. Decidability of the more\ngeneral problem of computing all polynomial invariants of affine programs with\nrecursive procedure calls remains open. Mathematically speaking, the core\nchallenge is to compute the Zariski closure of a set of matrices defined by a\ncontext-free language. In this paper, we approach the problem from two sides:\nTowards decidability, we give a procedure to compute the Zariski closure of\nsets of matrices given by one-counter languages (that is, languages accepted by\none-dimensional vector addition systems with states and zero tests), a proper\nsubclass of context-free languages. On the other side, we show that the problem\nbecomes undecidable for indexed languages, a natural extension of context-free\nlanguages corresponding to nested pushdown automata. One of our main technical\ntools is a novel adaptation of Simon's factorization forests to infinite\nmonoids of matrices.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u8ba1\u7b97\u7531\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u5b9a\u4e49\u7684\u77e9\u9635\u96c6\u7684Zariski\u95ed\u5305\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u4e00\u7c7b\u5b50\u8bed\u8a00\u7684\u53ef\u5224\u5b9a\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u66f4\u5e7f\u6cdb\u7684\u8bed\u8a00\u7c7b\u522b\u4e2d\u95ee\u9898\u662f\u4e0d\u53ef\u5224\u5b9a\u7684\u3002", "motivation": "\u7814\u7a76\u7684\u6838\u5fc3\u95ee\u9898\u662f\u8ba1\u7b97\u7531\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u5b9a\u4e49\u7684\u77e9\u9635\u96c6\u7684Zariski\u95ed\u5305\uff0c\u8fd9\u5728\u8ba1\u7b97\u4eff\u5c04\u7a0b\u5e8f\u7684\u9012\u5f52\u8c03\u7528\u591a\u9879\u5f0f\u4e0d\u53d8\u91cf\u65f6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u8bba\u6587\u4ece\u53ef\u5224\u5b9a\u6027\u548c\u4e0d\u53ef\u5224\u5b9a\u6027\u4e24\u65b9\u9762\u5165\u624b\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9\u4e00\u7c7b\u5b50\u8bed\u8a00\uff08\u5355\u8ba1\u6570\u5668\u8bed\u8a00\uff09\u7684Zariski\u95ed\u5305\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u66f4\u5e7f\u6cdb\u7684\u7d22\u5f15\u8bed\u8a00\u7c7b\u522b\u4e2d\u95ee\u9898\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\u3002", "result": "\u7814\u7a76\u8005\u6210\u529f\u5730\u5b9e\u73b0\u4e86\u5355\u8ba1\u6570\u5668\u8bed\u8a00\u7c7b\u522b\u4e2d\u77e9\u9635\u96c6Zariski\u95ed\u5305\u7684\u8ba1\u7b97\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u5728\u7d22\u5f15\u8bed\u8a00\u7c7b\u522b\u4e2d\u8be5\u95ee\u9898\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u5f15\u5165Simon\u7684\u56e0\u5b50\u5206\u89e3\u68ee\u6797\u6280\u672f\uff0c\u4e3a\u77e9\u9635\u65e0\u9650\u5e7a\u534a\u7fa4\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u8fdb\u4e00\u6b65\u63a8\u52a8\u4e86\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.10392", "pdf": "https://arxiv.org/pdf/2507.10392", "abs": "https://arxiv.org/abs/2507.10392", "authors": ["Runsheng Benson Guo", "Utkarsh Anand", "Khuzaima Daudjee", "Rathijit Sen"], "title": "Zorse: Optimizing LLM Training Efficiency on Heterogeneous GPU Clusters", "categories": ["cs.DC"], "comment": null, "summary": "Large language models (LLMs) require vast amounts of GPU compute to train,\nbut limited availability and high costs of GPUs make homogeneous clusters\nimpractical for many organizations. Instead, assembling heterogeneous clusters\nby pooling together GPUs of different generations allows them to achieve higher\naggregate compute and make use of all available GPUs. However, training on\nheterogeneous clusters presents several challenges, including load balancing\nacross GPUs, optimizing memory usage to accommodate varying memory capacities,\nand ensuring communication-efficient training over diverse network\ninterconnects potentially spanning multiple datacenters. In this paper, we make\nthe case that efficient training on heterogeneous clusters requires (1) the\nintegration of pipeline parallelism and data parallelism in a manner that is\nboth communication- and memory-efficient, and (2) a more adaptable\nconfiguration of pipeline and data parallelism, which includes the capability\nto flexibly partition GPUs into asymmetric pipeline parallel stages and to\nincorporate heterogeneous GPUs within the same data parallelism group. We\npropose Zorse, the first system to unify all these capabilities while\nincorporating a planner that automatically configures training strategies for a\ngiven workload. Our evaluation shows that Zorse significantly outperforms\nstate-of-the-art systems in heterogeneous training scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aZorse\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u5f02\u6784GPU\u96c6\u7fa4\u4e0a\u9ad8\u6548\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u6d41\u6c34\u7ebf\u5e76\u884c\u548c\u6570\u636e\u5e76\u884c\uff0c\u5e76\u52a8\u6001\u8c03\u6574\u914d\u7f6e\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u7531\u4e8eGPU\u7684\u6709\u9650\u4f9b\u5e94\u548c\u9ad8\u6210\u672c\uff0c\u8bb8\u591a\u7ec4\u7ec7\u65e0\u6cd5\u4f7f\u7528\u540c\u6784\u96c6\u7fa4\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u3002\u901a\u8fc7\u5229\u7528\u5f02\u6784GPU\u96c6\u7fa4\u53ef\u4ee5\u63d0\u5347\u7b97\u529b\uff0c\u4f46\u9762\u4e34\u8d1f\u8f7d\u5747\u8861\u3001\u5185\u5b58\u4f18\u5316\u548c\u901a\u4fe1\u6548\u7387\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faZorse\u7cfb\u7edf\uff0c\u7ed3\u5408\u6d41\u6c34\u7ebf\u5e76\u884c\u548c\u6570\u636e\u5e76\u884c\uff0c\u652f\u6301\u5f02\u6784GPU\u7684\u52a8\u6001\u914d\u7f6e\uff0c\u5e76\u5f15\u5165\u81ea\u52a8\u89c4\u5212\u5668\u4f18\u5316\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660eZorse\u5728\u5f02\u6784\u8bad\u7ec3\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "conclusion": "Zorse\u4e3a\u5f02\u6784GPU\u96c6\u7fa4\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2507.09948", "pdf": "https://arxiv.org/pdf/2507.09948", "abs": "https://arxiv.org/abs/2507.09948", "authors": ["Zijian Ding", "Tung Nguyen", "Weikai Li", "Aditya Grover", "Yizhou Sun", "Jason Cong"], "title": "Iceberg: Enhancing HLS Modeling with Synthetic Data", "categories": ["cs.LG", "cs.AR"], "comment": "9 pages. accepted to ICLAD'25", "summary": "Deep learning-based prediction models for High-Level Synthesis (HLS) of\nhardware designs often struggle to generalize. In this paper, we study how to\nclose the generalizability gap of these models through pretraining on synthetic\ndata and introduce Iceberg, a synthetic data augmentation approach that expands\nboth large language model (LLM)-generated programs and weak labels of unseen\ndesign configurations. Our weak label generation method is integrated with an\nin-context model architecture, enabling meta-learning from actual and proximate\nlabels. Iceberg improves the geometric mean modeling accuracy by $86.4\\%$ when\nadapt to six real-world applications with few-shot examples and achieves a\n$2.47\\times$ and a $1.12\\times$ better offline DSE performance when adapting to\ntwo different test datasets. Our open-sourced code is here:\n\\href{https://github.com/UCLA-VAST/iceberg}{https://github.com/UCLA-VAST/iceberg}", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIceberg\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u548c\u5f31\u6807\u7b7e\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u5c42\u6b21\u7efc\u5408\uff08HLS\uff09\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709HLS\u9884\u6d4b\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u5408\u6210\u6570\u636e\u9884\u8bad\u7ec3\u548c\u5f31\u6807\u7b7e\u751f\u6210\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u6a21\u578b\u67b6\u6784\u8fdb\u884c\u5143\u5b66\u4e60\u3002", "result": "\u5728\u5c11\u6837\u672c\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u7cbe\u5ea6\u63d0\u534786.4%\uff0c\u79bb\u7ebfDSE\u6027\u80fd\u63d0\u9ad82.47\u500d\u548c1.12\u500d\u3002", "conclusion": "Iceberg\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728HLS\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.10019", "pdf": "https://arxiv.org/pdf/2507.10019", "abs": "https://arxiv.org/abs/2507.10019", "authors": ["Pranav Joshi"], "title": "Sampling-Based Estimation of Jaccard Containment and Similarity", "categories": ["stat.CO", "cs.DB", "stat.ML"], "comment": null, "summary": "This paper addresses the problem of estimating the containment and similarity\nbetween two sets using only random samples from each set, without relying on\nsketches or full data access. The study introduces a binomial model for\npredicting the overlap between samples, demonstrating that it is both accurate\nand practical when sample sizes are small compared to the original sets. The\npaper compares this model to previous approaches and shows that it provides\nbetter estimates under the considered conditions. It also analyzes the\nstatistical properties of the estimator, including error bounds and sample size\nrequirements needed to achieve a desired level of accuracy and confidence. The\nframework is extended to estimate set similarity, and the paper provides\nguidance for applying these methods in large scale data systems where only\npartial or sampled data is available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u9879\u5206\u5e03\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u901a\u8fc7\u968f\u673a\u6837\u672c\u4f30\u8ba1\u4e24\u4e2a\u96c6\u5408\u7684\u5305\u542b\u6027\u548c\u76f8\u4f3c\u6027\uff0c\u65e0\u9700\u5b8c\u6574\u6570\u636e\u6216\u8349\u56fe\u3002\u6a21\u578b\u5728\u5c0f\u6837\u672c\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002", "motivation": "\u89e3\u51b3\u5728\u4ec5\u80fd\u83b7\u53d6\u968f\u673a\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u51c6\u786e\u4f30\u8ba1\u4e24\u4e2a\u96c6\u5408\u7684\u5305\u542b\u6027\u548c\u76f8\u4f3c\u6027\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e8c\u9879\u5206\u5e03\u6a21\u578b\u9884\u6d4b\u6837\u672c\u95f4\u7684\u91cd\u53e0\uff0c\u5206\u6790\u5176\u7edf\u8ba1\u7279\u6027\uff0c\u5305\u62ec\u8bef\u5dee\u754c\u9650\u548c\u6837\u672c\u91cf\u9700\u6c42\uff0c\u5e76\u6269\u5c55\u81f3\u96c6\u5408\u76f8\u4f3c\u6027\u4f30\u8ba1\u3002", "result": "\u6a21\u578b\u5728\u5c0f\u6837\u672c\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u5e76\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8e\u968f\u673a\u6837\u672c\u7684\u96c6\u5408\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u9760\u7684\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u3002"}}
{"id": "2507.09664", "pdf": "https://arxiv.org/pdf/2507.09664", "abs": "https://arxiv.org/abs/2507.09664", "authors": ["Zoe Kaputa", "Anika Rajaram", "Vryan Almanon Feliciano", "Zhuoyue Lyu", "Maneesh Agrawala", "Hari Subramonyam"], "title": "SimStep: Chain-of-Abstractions for Incremental Specification and Debugging of AI-Generated Interactive Simulations", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Programming-by-prompting with generative AI offers a new paradigm for\nend-user programming, shifting the focus from syntactic fluency to semantic\nintent. This shift holds particular promise for non-programmers such as\neducators, who can describe instructional goals in natural language to generate\ninteractive learning content. Yet in bypassing direct code authoring, many of\nprogramming's core affordances - such as traceability, stepwise refinement, and\nbehavioral testing - are lost. We propose the Chain-of-Abstractions (CoA)\nframework as a way to recover these affordances while preserving the expressive\nflexibility of natural language. CoA decomposes the synthesis process into a\nsequence of cognitively meaningful, task-aligned representations that function\nas checkpoints for specification, inspection, and refinement. We instantiate\nthis approach in SimStep, an authoring environment for teachers that scaffolds\nsimulation creation through four intermediate abstractions: Concept Graph,\nScenario Graph, Learning Goal Graph, and UI Interaction Graph. To address\nambiguities and misalignments, SimStep includes an inverse correction process\nthat surfaces in-filled model assumptions and enables targeted revision without\nrequiring users to manipulate code. Evaluations with educators show that CoA\nenables greater authoring control and interpretability in\nprogramming-by-prompting workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChain-of-Abstractions\uff08CoA\uff09\u7684\u6846\u67b6\uff0c\u65e8\u5728\u6062\u590d\u7f16\u7a0b\u4e2d\u7684\u6838\u5fc3\u529f\u80fd\uff08\u5982\u53ef\u8ffd\u6eaf\u6027\u3001\u9010\u6b65\u4f18\u5316\u548c\u884c\u4e3a\u6d4b\u8bd5\uff09\uff0c\u540c\u65f6\u4fdd\u7559\u81ea\u7136\u8bed\u8a00\u7684\u8868\u8fbe\u7075\u6d3b\u6027\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u7f16\u7a0b\u4e3a\u7ec8\u7aef\u7528\u6237\u7f16\u7a0b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5c24\u5176\u662f\u4e3a\u975e\u7a0b\u5e8f\u5458\uff08\u5982\u6559\u80b2\u5de5\u4f5c\u8005\uff09\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u65b9\u5f0f\u7ed5\u8fc7\u4e86\u76f4\u63a5\u7f16\u5199\u4ee3\u7801\uff0c\u5bfc\u81f4\u7f16\u7a0b\u7684\u6838\u5fc3\u529f\u80fd\u4e27\u5931\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86CoA\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u751f\u6210\u8fc7\u7a0b\u4e3a\u4e00\u7cfb\u5217\u4efb\u52a1\u5bf9\u9f50\u7684\u62bd\u8c61\u8868\u793a\u3002\u5e76\u5728SimStep\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u8fd9\u4e00\u65b9\u6cd5\uff0c\u652f\u6301\u6559\u5e08\u901a\u8fc7\u56db\u4e2a\u4e2d\u95f4\u62bd\u8c61\uff08\u5982\u6982\u5ff5\u56fe\u3001\u573a\u666f\u56fe\u7b49\uff09\u521b\u5efa\u6559\u5b66\u6a21\u62df\u3002", "result": "SimStep\u5305\u542b\u9006\u5411\u4fee\u6b63\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5904\u7406\u6b67\u4e49\u548c\u504f\u5dee\u3002\u5b9e\u9a8c\u663e\u793a\uff0cCoA\u63d0\u9ad8\u4e86\u7f16\u7a0b\u6d41\u7a0b\u7684\u53ef\u63a7\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "CoA\u5728\u7f16\u7a0b\u63d0\u793a\u6d41\u7a0b\u4e2d\u589e\u5f3a\u4e86\u4f5c\u8005\u7684\u63a7\u5236\u529b\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6559\u80b2\u5de5\u4f5c\u8005\u3002"}}
{"id": "2507.09414", "pdf": "https://arxiv.org/pdf/2507.09414", "abs": "https://arxiv.org/abs/2507.09414", "authors": ["Khizra Sohail", "Atif Aftab Ahmed Jilani", "Nigar Azhar Butt"], "title": "Enhancing NeuroEvolution-Based Game Testing: A Branch Coverage Approach for Scratch Programs", "categories": ["cs.SE"], "comment": null, "summary": "Automated test generation for game-like programs presents unique challenges\ndue to their non-deterministic behavior and complex control structures. The\nNEATEST framework has been used for automated testing in Scratch games,\nemploying neuroevolution-based test generation optimized for statement\ncoverage. However, statement coverage alone is often insufficient for fault\ndetection, as it does not guarantee execution of all logical branches. This\npaper introduces a branch coverage-based fitness function to enhance test\neffectiveness in automated game testing. We extend NEATEST by integrating a\nbranch fitness function that prioritizes control-dependent branches, guiding\nthe neuroevolution process to maximize branch exploration. To evaluate the\neffectiveness of this approach, empirical experiments were conducted on 25\nScratch games, comparing Neatest with Statement Coverage (NSC) against Neatest\nwith Branch Coverage (NBC). A mutation analysis was also performed to assess\nthe fault detection capabilities of both techniques. The results demonstrate\nthat NBC achieves higher branch coverage than NSC in 13 out of 25 games,\nparticularly in programs with complex conditional structures. Moreover, NBC\nachieves a lower false positive rate in mutation testing, making it a more\nreliable approach for identifying faulty behavior in game programs. These\nfindings confirm that branch coverage-based test generation improves test\ncoverage and fault detection in Scratch programs.", "AI": {"tldr": "NEATEST\u6846\u67b6\u539f\u672c\u91c7\u7528\u57fa\u4e8e\u8bed\u53e5\u8986\u76d6\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff0c\u4f46\u5b58\u5728\u4e0d\u8db3\u3002\u672c\u6587\u63d0\u51fa\u5206\u652f\u8986\u76d6\u7684\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u679c\u548c\u6545\u969c\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u6e38\u620f\u7a0b\u5e8f\u7684\u975e\u786e\u5b9a\u6027\u548c\u590d\u6742\u63a7\u5236\u7ed3\u6784\u4f7f\u5f97\u4f20\u7edf\u8bed\u53e5\u8986\u76d6\u6d4b\u8bd5\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u6269\u5c55NEATEST\uff0c\u96c6\u6210\u5206\u652f\u8986\u76d6\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u4f18\u5148\u5904\u7406\u63a7\u5236\u4f9d\u8d56\u7684\u5206\u652f\uff0c\u4ee5\u589e\u5f3a\u5206\u652f\u63a2\u7d22\u3002", "result": "\u572825\u4e2aScratch\u6e38\u620f\u4e2d\uff0c\u5206\u652f\u8986\u76d6\u7248\u672c\uff08NBC\uff09\u572813\u4e2a\u6e38\u620f\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u590d\u6742\u6761\u4ef6\u7ed3\u6784\u7684\u7a0b\u5e8f\u4e2d\u6548\u679c\u663e\u8457\uff0c\u4e14\u8bef\u62a5\u7387\u66f4\u4f4e\u3002", "conclusion": "\u5206\u652f\u8986\u76d6\u4e3a\u57fa\u7840\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347Scratch\u7a0b\u5e8f\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6545\u969c\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2507.09852", "pdf": "https://arxiv.org/pdf/2507.09852", "abs": "https://arxiv.org/abs/2507.09852", "authors": ["Zihao Zhou", "Zipeng Dai", "Linyi Huang", "Cui Yang", "Youjun Xiang", "Jie Tang", "Kai-kit Wong"], "title": "UavNetSim-v1: A Python-based Simulation Platform for UAV Communication Networks", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "In unmanned aerial vehicle (UAV) networks, communication protocols and\nalgorithms are essential for cooperation and collaboration between UAVs.\nSimulation provides a cost-effective solution for prototyping, debugging, and\nanalyzing protocols and algorithms, avoiding the prohibitive expenses of field\nexperiments. In this paper, we present ``UavNetSim-v1'', an open-source\nPython-based simulation platform designed for rapid development, testing, and\nevaluating the protocols and algorithms in UAV networks. ``UavNetSim-v1''\nprovides most of the functionalities developers may need, including\nrouting/medium access control (MAC) protocols, topology control algorithms and\nmobility/energy models, while maintaining ease of use. Furthermore, the\nplatform supports comprehensive performance evaluation and features an\ninteractive visualization interface for in-depth algorithm analysis. In short,\n``UavNetSim-v1'' lends itself to both rapid prototyping and educational\npurposes, and can serve as a lightweight yet powerful alternative to mature\nnetwork simulators for UAV communication research.", "AI": {"tldr": "UavNetSim-v1\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u5f00\u6e90\u4eff\u771f\u5e73\u53f0\uff0c\u7528\u4e8e\u5feb\u901f\u5f00\u53d1\u548c\u8bc4\u4f30\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\u7684\u534f\u8bae\u548c\u7b97\u6cd5\u3002", "motivation": "\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\u7684\u901a\u4fe1\u534f\u8bae\u548c\u7b97\u6cd5\u9700\u8981\u9ad8\u6548\u5f00\u53d1\u5de5\u5177\uff0c\u4eff\u771f\u53ef\u4ee5\u8282\u7701\u9ad8\u6602\u7684\u5b9e\u5730\u5b9e\u9a8c\u6210\u672c\u3002", "method": "\u5f00\u53d1\u4e86UavNetSim-v1\u5e73\u53f0\uff0c\u652f\u6301\u8def\u7531/MAC\u534f\u8bae\u3001\u62d3\u6251\u63a7\u5236\u7b97\u6cd5\u3001\u79fb\u52a8\u6027/\u80fd\u91cf\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u754c\u9762\u3002", "result": "\u5e73\u53f0\u529f\u80fd\u5168\u9762\uff0c\u9002\u7528\u4e8e\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u6559\u80b2\u76ee\u7684\uff0c\u53ef\u4f5c\u4e3a\u6210\u719f\u7684\u7f51\u7edc\u4eff\u771f\u5de5\u5177\u7684\u8f7b\u91cf\u66ff\u4ee3\u3002", "conclusion": "UavNetSim-v1\u4e3a\u65e0\u4eba\u673a\u901a\u4fe1\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u6613\u7528\u7684\u4eff\u771f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10469", "pdf": "https://arxiv.org/pdf/2507.10469", "abs": "https://arxiv.org/abs/2507.10469", "authors": ["Mikko Korkiakoski", "Saeid Sheikhi", "Jesper Nyman", "Jussi Saariniemi", "Kalle Tapio", "Panos Kostakos"], "title": "An Empirical Evaluation of AI-Powered Non-Player Characters' Perceived Realism and Performance in Virtual Reality Environments", "categories": ["cs.HC", "cs.AI", "cs.MM"], "comment": null, "summary": "Advancements in artificial intelligence (AI) have significantly enhanced the\nrealism and interactivity of non-player characters (NPCs) in virtual reality\n(VR), creating more engaging and believable user experiences. This paper\nevaluates AI-driven NPCs within a VR interrogation simulator, focusing on their\nperceived realism, usability, and system performance. The simulator features\ntwo AI-powered NPCs, a suspect, and a partner, using GPT-4 Turbo to engage\nparticipants in a scenario to determine the suspect's guilt or innocence. A\nuser study with 18 participants assessed the system using the System Usability\nScale (SUS), Game Experience Questionnaire (GEQ), and a Virtual Agent\nBelievability Questionnaire, alongside latency measurements for speech-to-text\n(STT), text-to-speech (TTS), OpenAI GPT-4 Turbo, and overall (cycle) latency.\nResults showed an average cycle latency of 7 seconds, influenced by the\nincreasing conversational context. Believability scored 6.67 out of 10, with\nhigh ratings in behavior, social relationships, and intelligence but moderate\nscores in emotion and personality. The system achieved a SUS score of 79.44,\nindicating good usability. These findings demonstrate the potential of large\nlanguage models to improve NPC realism and interaction in VR while highlighting\nchallenges in reducing system latency and enhancing emotional depth. This\nresearch contributes to the development of more sophisticated AI-driven NPCs,\nrevealing the need for performance optimization to achieve increasingly\nimmersive virtual experiences.", "AI": {"tldr": "\u7814\u7a76\u4e86AI\u9a71\u52a8\u7684NPC\u5728VR\u5ba1\u8baf\u6a21\u62df\u5668\u4e2d\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u4e86\u5176\u771f\u5b9e\u6027\u3001\u53ef\u7528\u6027\u548c\u7cfb\u7edf\u6027\u80fd\uff0c\u7ed3\u679c\u663e\u793aGPT-4 Turbo\u63d0\u5347\u4e86NPC\u7684\u771f\u5b9e\u6027\uff0c\u4f46\u5b58\u5728\u5ef6\u8fdf\u548c\u60c5\u611f\u6df1\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7AI\u63d0\u5347VR\u4e2dNPC\u7684\u771f\u5b9e\u6027\u548c\u4ea4\u4e92\u4f53\u9a8c\uff0c\u5e76\u8bc4\u4f30\u5176\u5b9e\u9645\u6548\u679c\u3002", "method": "\u4f7f\u7528GPT-4 Turbo\u5f00\u53d1VR\u5ba1\u8baf\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc4\u4f30NPC\u7684\u771f\u5b9e\u6027\u3001\u53ef\u7528\u6027\u548c\u7cfb\u7edf\u6027\u80fd\uff0c\u6d4b\u91cf\u5ef6\u8fdf\u7b49\u6307\u6807\u3002", "result": "\u5e73\u5747\u5ef6\u8fdf7\u79d2\uff0c\u771f\u5b9e\u611f\u8bc4\u5206\u4e3a6.67/10\uff0c\u7cfb\u7edf\u53ef\u7528\u6027\u5206\u6570\u4e3a79.44\uff0c\u8868\u660eAI\u63d0\u5347\u4e86NPC\u7684\u771f\u5b9e\u6027\uff0c\u4f46\u5ef6\u8fdf\u548c\u60c5\u611f\u8868\u73b0\u4ecd\u9700\u6539\u8fdb\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u663e\u8457\u63d0\u5347VR\u4e2dNPC\u7684\u771f\u5b9e\u6027\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\u548c\u60c5\u611f\u8868\u73b0\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6c89\u6d78\u611f\u3002"}}
{"id": "2507.09751", "pdf": "https://arxiv.org/pdf/2507.09751", "abs": "https://arxiv.org/abs/2507.09751", "authors": ["Bradley P. Allen", "Prateek Chhikara", "Thomas Macaulay Ferguson", "Filip Ilievski", "Paul Groth"], "title": "Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations", "categories": ["cs.AI", "cs.CL", "cs.LO"], "comment": "29 pages, 9 tables, 3 figures. Accepted to the 19th Conference on\n  Neurosymbolic Learning and Reasoning (NeSy 2025)", "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but they exhibit problems with\nlogical consistency in the output they generate. How can we harness LLMs'\nbroad-coverage parametric knowledge in formal reasoning despite their\ninconsistency? We present a method for directly integrating an LLM into the\ninterpretation function of the formal semantics for a paraconsistent logic. We\nprovide experimental evidence for the feasibility of the method by evaluating\nthe function using datasets created from several short-form factuality\nbenchmarks. Unlike prior work, our method offers a theoretical framework for\nneuro-symbolic reasoning that leverages an LLM's knowledge while preserving the\nunderlying logic's soundness and completeness properties.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u5f62\u5f0f\u8bed\u4e49\u5b66\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u5176\u903b\u8f91\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "LLMs\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u903b\u8f91\u4e00\u81f4\u6027\u4e0d\u8db3\uff0c\u9700\u63a2\u7d22\u5982\u4f55\u5229\u7528\u5176\u77e5\u8bc6\u8fdb\u884c\u5f62\u5f0f\u63a8\u7406\u3002", "method": "\u5c06LLM\u76f4\u63a5\u6574\u5408\u5230\u5f62\u5f0f\u8bed\u4e49\u7684\u89e3\u91ca\u51fd\u6570\u4e2d\uff0c\u57fa\u4e8e\u8d85\u534f\u8c03\u903b\u8f91\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\uff0c\u4e14\u4fdd\u6301\u4e86\u903b\u8f91\u7684\u5b8c\u5907\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u540c\u65f6\u5229\u7528LLM\u77e5\u8bc6\u4e14\u4e0d\u635f\u5bb3\u903b\u8f91\u5c5e\u6027\u3002"}}
{"id": "2507.10413", "pdf": "https://arxiv.org/pdf/2507.10413", "abs": "https://arxiv.org/abs/2507.10413", "authors": ["Gabriel Rocha"], "title": "Consensus, Inconsistency, Emergence: what's paraconsistency got to do with it?", "categories": ["cs.DC", "cs.CC", "cs.IT", "cs.LO", "math.IT"], "comment": "10 pages", "summary": "The consensus problem, briefly stated, consists of having processes in an\nasynchronous distributed system agree on a value. It is widely known that the\nconsensus problem does not have a deterministic solution that ensures both\ntermination and consistency, if there is at least one faulty process in the\nsystem. This result, known as the FLP impossibility theorem, led to several\ngeneralizations and developments in theoretical distributed computing. This\npaper argues that the FLP impossibility theorem holds even under a generalized\ndefinition of computation through oracles. Furthermore, using a theoretical\nmachinery from complex systems, this paper also posits that inconsistency may\nbe an emergent feature of consensus over distributed systems by examining how a\nsystem transitions phases. Under the same complex systems framework, this paper\nexamines paraconsistent logics, arguing that while inconsistency is not an\nemergent feature for these logics, triviality may be. Lastly, some attention is\ngiven to the possibility of developing consensus algorithms capable of\nparaconsistent reasoning.", "AI": {"tldr": "FLP\u4e0d\u53ef\u884c\u5b9a\u7406\u5728\u5e7f\u4e49\u8ba1\u7b97\u5b9a\u4e49\u4e0b\u4ecd\u7136\u6210\u7acb\uff0c\u4e0d\u4e00\u81f4\u6027\u53ef\u80fd\u662f\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\u7279\u6027\uff0c\u800c\u6b21\u534f\u8c03\u903b\u8f91\u4e2d\u5e73\u51e1\u6027\u53ef\u80fd\u662f\u6d8c\u73b0\u7279\u6027\u3002", "motivation": "\u63a2\u7d22FLP\u4e0d\u53ef\u884c\u5b9a\u7406\u7684\u5e7f\u4e49\u9002\u7528\u6027\uff0c\u4ee5\u53ca\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u4e0d\u4e00\u81f4\u6027\u548c\u6b21\u534f\u8c03\u903b\u8f91\u4e2d\u7279\u6027\u7684\u6d8c\u73b0\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5e7f\u4e49\u8ba1\u7b97\u5b9a\u4e49\u548c\u590d\u6742\u7cfb\u7edf\u7406\u8bba\u5206\u6790FLP\u5b9a\u7406\uff0c\u5e76\u7814\u7a76\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u76f8\u53d8\u548c\u6b21\u534f\u8c03\u903b\u8f91\u3002", "result": "FLP\u5b9a\u7406\u5728\u5e7f\u4e49\u8ba1\u7b97\u4e0b\u4ecd\u6210\u7acb\uff0c\u4e0d\u4e00\u81f4\u6027\u53ef\u80fd\u662f\u6d8c\u73b0\u7279\u6027\uff1b\u6b21\u534f\u8c03\u903b\u8f91\u4e2d\u5e73\u51e1\u6027\u53ef\u80fd\u662f\u6d8c\u73b0\u7279\u6027\u3002", "conclusion": "\u8bba\u6587\u6269\u5c55\u4e86FLP\u5b9a\u7406\u7684\u7406\u89e3\uff0c\u63d0\u51fa\u4e86\u4e0d\u4e00\u81f4\u6027\u548c\u6b21\u534f\u8c03\u903b\u8f91\u4e2d\u5e73\u51e1\u6027\u7684\u6d8c\u73b0\u53ef\u80fd\u6027\uff0c\u5e76\u63a2\u7d22\u4e86\u53ef\u80fd\u7684\u5171\u8bc6\u7b97\u6cd5\u3002"}}
{"id": "2507.09965", "pdf": "https://arxiv.org/pdf/2507.09965", "abs": "https://arxiv.org/abs/2507.09965", "authors": ["Weiyu Chen", "Chengjie Liu", "Wenhao Huang", "Jinyang Lyu", "Mingqian Yang", "Yuan Du", "Li Du", "Jun Yang"], "title": "AnalogTester: A Large Language Model-Based Framework for Automatic Testbench Generation in Analog Circuit Design", "categories": ["cs.MA", "cs.AR"], "comment": "accepted by ISEDA 2025", "summary": "Recent advancements have demonstrated the significant potential of large\nlanguage models (LLMs) in analog circuit design. Nevertheless, testbench\nconstruction for analog circuits remains manual, creating a critical bottleneck\nin achieving fully automated design processes. Particularly when replicating\ncircuit designs from academic papers, manual Testbench construction demands\ntime-intensive implementation and frequent adjustments, which fails to address\nthe dynamic diversity and flexibility requirements for automation. AnalogTester\ntackles automated analog design challenges through an LLM-powered pipeline: a)\ndomain-knowledge integration, b) paper information extraction, c) simulation\nscheme synthesis, and d) testbench code generation with Tsinghua Electronic\nDesign (TED). AnalogTester has demonstrated automated Testbench generation\ncapabilities for three fundamental analog circuit types: operational amplifiers\n(op-amps), bandgap references (BGRs), and low-dropout regulators (LDOs), while\nmaintaining a scalable framework for adaptation to broader circuit topologies.\nFurthermore, AnalogTester can generate circuit knowledge data and TED code\ncorpus, establishing fundamental training datasets for LLM specialization in\nanalog circuit design automation.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684AnalogTester\u901a\u8fc7\u96c6\u6210\u9886\u57df\u77e5\u8bc6\u3001\u63d0\u53d6\u8bba\u6587\u4fe1\u606f\u3001\u5408\u6210\u4eff\u771f\u65b9\u6848\u5e76\u751f\u6210\u6d4b\u8bd5\u53f0\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u4e2d\u624b\u52a8\u6d4b\u8bd5\u53f0\u6784\u5efa\u7684\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u4e2d\u624b\u52a8\u6d4b\u8bd5\u53f0\u6784\u5efa\u6548\u7387\u4f4e\u4e0b\uff0c\u65e0\u6cd5\u6ee1\u8db3\u81ea\u52a8\u5316\u9700\u6c42\uff0cAnalogTester\u65e8\u5728\u901a\u8fc7LLM\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528LLM\u9a71\u52a8\u7684\u56db\u5927\u6b65\u9aa4\uff1a\u9886\u57df\u77e5\u8bc6\u96c6\u6210\u3001\u8bba\u6587\u4fe1\u606f\u63d0\u53d6\u3001\u4eff\u771f\u65b9\u6848\u5408\u6210\u3001\u6d4b\u8bd5\u53f0\u4ee3\u7801\u751f\u6210\u3002", "result": "\u6210\u529f\u81ea\u52a8\u5316\u751f\u6210\u4e09\u79cd\u57fa\u672c\u6a21\u62df\u7535\u8def\uff08\u8fd0\u653e\u3001\u5e26\u9699\u57fa\u51c6\u3001\u4f4e\u538b\u5dee\u7a33\u538b\u5668\uff09\u7684\u6d4b\u8bd5\u53f0\uff0c\u5e76\u6784\u5efa\u4e86LLM\u4e13\u4e1a\u5316\u7684\u57fa\u7840\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "conclusion": "AnalogTester\u4e3a\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u5e76\u63a8\u52a8\u4e86LLM\u5728\u8be5\u9886\u57df\u7684\u4e13\u4e1a\u5316\u5e94\u7528\u3002"}}
{"id": "2507.10281", "pdf": "https://arxiv.org/pdf/2507.10281", "abs": "https://arxiv.org/abs/2507.10281", "authors": ["Jiaming Tian", "Liyao Li", "Wentao Ye", "Haobo Wang", "Lingxin Wang", "Lihua Yu", "Zujie Ren", "Gang Chen", "Junbo Zhao"], "title": "Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence", "categories": ["cs.AI", "cs.DB"], "comment": null, "summary": "Tables are fundamental in domains such as finance, healthcare, and public\nadministration, yet real-world table tasks often involve noise, structural\nheterogeneity, and semantic complexity--issues underexplored in existing\nresearch that primarily targets clean academic datasets. This survey focuses on\nLLM-based Table Agents, which aim to automate table-centric workflows by\nintegrating preprocessing, reasoning, and domain adaptation. We define five\ncore competencies--C1: Table Structure Understanding, C2: Table and Query\nSemantic Understanding, C3: Table Retrieval and Compression, C4: Executable\nReasoning with Traceability, and C5: Cross-Domain Generalization--to analyze\nand compare current approaches. In addition, a detailed examination of the\nText-to-SQL Agent reveals a performance gap between academic benchmarks and\nreal-world scenarios, especially for open-source models. Finally, we provide\nactionable insights to improve the robustness, generalization, and efficiency\nof LLM-based Table Agents in practical settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u8868\u683c\u4efb\u52a1\u7684\u590d\u6742\u6027\uff0c\u5e76\u901a\u8fc7\u5b9a\u4e49\u4e94\u5927\u6838\u5fc3\u80fd\u529b\uff0c\u7814\u7a76\u4e86\u57fa\u4e8eLLM\u7684\u8868\u683c\u4ee3\u7406\uff0c\u63d0\u51fa\u4e86\u63d0\u5347\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u7684\u89c1\u89e3\u3002", "motivation": "\u73b0\u5b9e\u8868\u683c\u4efb\u52a1\u4e2d\u7684\u566a\u58f0\u3001\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u8bed\u4e49\u590d\u6742\u6027\u5728\u73b0\u6709\u7814\u7a76\u4e2d\u88ab\u5ffd\u89c6\uff0c\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5b9a\u4e49\u4e86\u4e94\u5927\u6838\u5fc3\u80fd\u529b\uff08C1-C5\uff09\uff0c\u5e76\u5bf9\u6bd4\u5206\u6790\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u5173\u6ce8Text-to-SQL\u4ee3\u7406\u3002", "result": "\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5728\u5b66\u672f\u57fa\u51c6\u4e0e\u5b9e\u9645\u573a\u666f\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u63d0\u4f9b\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "\u901a\u8fc7\u7814\u7a76\u548c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u63d0\u5347LLM\u8868\u683c\u4ee3\u7406\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u6548\u7387\u7684\u65b9\u6848\u3002"}}
{"id": "2507.09917", "pdf": "https://arxiv.org/pdf/2507.09917", "abs": "https://arxiv.org/abs/2507.09917", "authors": ["Zikun Deng", "Jiabao Huang", "Chenxi Ruan", "Jialing Li", "Shaowu Gao", "Yi Cai"], "title": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series", "categories": ["cs.HC"], "comment": null, "summary": "Spatial time series visualization offers scientific research pathways and\nanalytical decision-making tools across various spatiotemporal domains. Despite\nmany advanced methodologies, the seamless integration of temporal and spatial\ninformation remains a challenge. The space-time cube (STC) stands out as a\npromising approach for the synergistic presentation of spatial and temporal\ninformation, with successful applications across various spatiotemporal\ndatasets. However, the STC is plagued by well-known issues such as visual\nocclusion and depth ambiguity, which are further exacerbated when dealing with\nlarge-scale spatial time series data. In this study, we introduce a novel\ntechnical framework termed VolumeSTCube, designed for continuous spatiotemporal\nphenomena. It first leverages the concept of the STC to transform discretely\ndistributed spatial time series data into continuously volumetric data.\nSubsequently, volume rendering and surface rendering techniques are employed to\nvisualize the transformed volumetric data. Volume rendering is utilized to\nmitigate visual occlusion, while surface rendering provides pattern details by\nenhanced lighting information. Lastly, we design interactions to facilitate the\nexploration and analysis from temporal, spatial, and spatiotemporal\nperspectives. VolumeSTCube is evaluated through a computational experiment, a\nreal-world case study with one expert, and a controlled user study with twelve\nnon-experts, compared against a baseline from prior work, showing its\nsuperiority and effectiveness in largescale spatial time series analysis.", "AI": {"tldr": "VolumeSTCube\u662f\u4e00\u79cd\u65b0\u7684\u65f6\u7a7a\u6570\u636e\u53ef\u89c6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4f53\u79ef\u6e32\u67d3\u548c\u8868\u9762\u6e32\u67d3\u6280\u672f\u89e3\u51b3\u4e86\u7a7a\u95f4\u65f6\u95f4\u7acb\u65b9\u4f53\uff08STC\uff09\u7684\u89c6\u89c9\u906e\u6321\u548c\u6df1\u5ea6\u6a21\u7cca\u95ee\u9898\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "motivation": "\u89e3\u51b3STC\u5728\u53ef\u89c6\u5316\u65f6\u7a7a\u6570\u636e\u65f6\u5b58\u5728\u7684\u89c6\u89c9\u906e\u6321\u548c\u6df1\u5ea6\u6a21\u7cca\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u4e2d\u7684\u6311\u6218\u3002", "method": "\u5229\u7528STC\u5c06\u79bb\u6563\u7684\u65f6\u7a7a\u6570\u636e\u8f6c\u6362\u4e3a\u8fde\u7eed\u7684\u4f53\u79ef\u6570\u636e\uff0c\u5e76\u8fd0\u7528\u4f53\u79ef\u6e32\u67d3\u548c\u8868\u9762\u6e32\u67d3\u6280\u672f\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u540c\u65f6\u8bbe\u8ba1\u4ea4\u4e92\u529f\u80fd\u4ee5\u652f\u6301\u591a\u89d2\u5ea6\u5206\u6790\u3002", "result": "\u901a\u8fc7\u8ba1\u7b97\u5b9e\u9a8c\u3001\u4e13\u5bb6\u6848\u4f8b\u7814\u7a76\u548c\u975e\u4e13\u5bb6\u7528\u6237\u7814\u7a76\u53d1\u73b0\uff0cVolumeSTCube\u5728\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u5206\u6790\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "VolumeSTCube\u6709\u6548\u89e3\u51b3\u4e86STC\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u65f6\u7a7a\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2507.09481", "pdf": "https://arxiv.org/pdf/2507.09481", "abs": "https://arxiv.org/abs/2507.09481", "authors": ["Yuheng Huang", "Da Song", "Zhenlan Ji", "Shuai Wang", "Lei Ma"], "title": "Evaluating LLMs on Sequential API Call Through Automated Test Generation", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "By integrating tools from external APIs, Large Language Models (LLMs) have\nexpanded their promising capabilities in a diverse spectrum of complex\nreal-world tasks. However, testing, evaluation, and analysis of LLM tool use\nremain in their early stages. Most existing benchmarks rely on manually\ncollected test cases, many of which cannot be automatically checked for\nsemantic correctness and instead depend on static methods such as string\nmatching. Additionally, these benchmarks often overlook the complex\ninteractions that occur between sequential API calls, which are common in\nreal-world applications. To fill the gap, in this paper, we introduce StateGen,\nan automated framework designed to generate diverse coding tasks involving\nsequential API interactions. StateGen combines state-machine-based API\nconstraint solving and validation, energy-based sampling, and control-flow\ninjection to generate executable programs. These programs are then translated\ninto human-like natural language task descriptions through a collaboration of\ntwo LLM agents. Utilizing StateGen, we construct StateEval, a benchmark\nencompassing 120 verified test cases spanning across three representative\nscenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental\nresults confirm that StateGen can effectively generate challenging and\nrealistic API-oriented tasks, highlighting areas for improvement in current\nLLMs incorporating APIs.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86StateGen\uff0c\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u6d89\u53ca\u8fde\u7eedAPI\u4ea4\u4e92\u7684\u591a\u6837\u5316\u7f16\u7a0b\u4efb\u52a1\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b120\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u7684StateEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u7684API\u6574\u5408\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLMs\u7684\u5de5\u5177\u4f7f\u7528\u6d4b\u8bd5\u548c\u8bc4\u4f30\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u624b\u52a8\u6536\u96c6\u7684\u6d4b\u8bd5\u6848\u4f8b\uff0c\u4e14\u65e0\u6cd5\u81ea\u52a8\u68c0\u67e5\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u540c\u65f6\u5ffd\u89c6\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u5e38\u89c1\u7684\u8fde\u7eedAPI\u4ea4\u4e92\u3002", "method": "StateGen\u7ed3\u5408\u4e86\u57fa\u4e8e\u72b6\u6001\u673a\u7684API\u7ea6\u675f\u89e3\u51b3\u3001\u80fd\u91cf\u91c7\u6837\u3001\u63a7\u5236\u6d41\u6ce8\u5165\u7b49\u6280\u672f\u751f\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2aLLM\u4ee3\u7406\u5c06\u5176\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eStateGen\u80fd\u6709\u6548\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u548c\u771f\u5b9e\u6027\u7684API\u5bfc\u5411\u4efb\u52a1\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728API\u6574\u5408\u65b9\u9762\u7684\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "StateGen\u548cStateEval\u4e3a\u89e3\u51b3LLMs\u5de5\u5177\u4f7f\u7528\u7684\u6d4b\u8bd5\u548c\u8bc4\u4f30\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u6539\u8fdb\u7684\u65b9\u5411\u3002"}}
{"id": "2507.09942", "pdf": "https://arxiv.org/pdf/2507.09942", "abs": "https://arxiv.org/abs/2507.09942", "authors": ["Jiaming Cheng", "Duong Tung Nguyen"], "title": "Green-LLM: Optimal Workload Allocation for Environmentally-Aware Distributed Inference", "categories": ["cs.NI", "cs.DC", "cs.SY", "eess.SY", "math.OC"], "comment": "5 pages, 11 figures", "summary": "This letter investigates the optimal allocation of large language model (LLM)\ninference workloads across heterogeneous edge data centers (DCs) over time.\nEach DC features on-site renewable generation and faces dynamic electricity\nprices and spatiotemporal variability in renewable availability. The central\nquestion is: how can inference workloads be optimally distributed to the DCs to\nminimize energy consumption, carbon emissions, and water usage while enhancing\nuser experience? This letter proposes a novel optimization model for LLM\nservice providers to reduce operational costs and environmental impacts.\nNumerical results validate the efficacy of the proposed approach.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u5728\u5f02\u6784\u8fb9\u7f18\u6570\u636e\u4e2d\u5fc3\u4f18\u5316\u5206\u914dLLM\u63a8\u7406\u4efb\u52a1\uff0c\u4ee5\u964d\u4f4e\u80fd\u8017\u3001\u78b3\u6392\u653e\u53ca\u6c34\u8d44\u6e90\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u89e3\u51b3LLM\u63a8\u7406\u4efb\u52a1\u5728\u52a8\u6001\u7535\u4ef7\u548c\u53ef\u518d\u751f\u80fd\u6e90\u53ef\u7528\u6027\u7684\u65f6\u7a7a\u53d8\u5316\u4e0b\u7684\u4f18\u5316\u5206\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u6a21\u578b\uff0c\u8003\u8651\u4e86\u8fd0\u8425\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u7684\u6700\u5c0f\u5316\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u4f18\u5316\u6a21\u578b\u80fd\u5e2e\u52a9LLM\u670d\u52a1\u63d0\u4f9b\u5546\u51cf\u5c11\u8fd0\u8425\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u3002"}}
{"id": "2507.10510", "pdf": "https://arxiv.org/pdf/2507.10510", "abs": "https://arxiv.org/abs/2507.10510", "authors": ["Jiangkai Wu", "Zhiyuan Ren", "Liming Liu", "Xinggong Zhang"], "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI", "categories": ["cs.NI", "cs.AI", "cs.HC", "cs.MM"], "comment": null, "summary": "AI Video Chat emerges as a new paradigm for Real-time Communication (RTC),\nwhere one peer is not a human, but a Multimodal Large Language Model (MLLM).\nThis makes interaction between humans and AI more intuitive, as if chatting\nface-to-face with a real person. However, this poses significant challenges to\nlatency, because the MLLM inference takes up most of the response time, leaving\nvery little time for video streaming. Due to network uncertainty and\ninstability, transmission latency becomes a critical bottleneck preventing AI\nfrom being like a real person. To address this, we propose Artic, an\nAI-oriented Real-time Communication framework, exploring the network\nrequirement shift from \"humans watching video\" to \"AI understanding video\". To\nreduce bitrate dramatically while maintaining MLLM accuracy, we propose\nContext-Aware Video Streaming that recognizes the importance of each video\nregion for chat and allocates bitrate almost exclusively to chat-important\nregions. To avoid packet retransmission, we propose Loss-Resilient Adaptive\nFrame Rate that leverages previous frames to substitute for lost/delayed frames\nwhile avoiding bitrate waste. To evaluate the impact of video streaming quality\non MLLM accuracy, we build the first benchmark, named Degraded Video\nUnderstanding Benchmark (DeViBench). Finally, we discuss some open questions\nand ongoing solutions for AI Video Chat.", "AI": {"tldr": "\u63d0\u51faArtic\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u89c6\u9891\u6d41\u548c\u81ea\u9002\u5e94\u5e27\u7387\u964d\u4f4e\u5ef6\u8fdf\uff0c\u63d0\u9ad8AI\u89c6\u9891\u804a\u5929\u4f53\u9a8c\u3002", "motivation": "\u89e3\u51b3AI\u89c6\u9891\u804a\u5929\u4e2dMLLM\u63a8\u7406\u548c\u7f51\u7edc\u5ef6\u8fdf\u5bfc\u81f4\u7684\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f7fAI\u4ea4\u4e92\u66f4\u63a5\u8fd1\u771f\u4eba\u3002", "method": "\u63d0\u51faContext-Aware Video Streaming\u548cLoss-Resilient Adaptive Frame Rate\u6280\u672f\uff0c\u4f18\u5316\u89c6\u9891\u6d41\u5904\u7406\u3002", "result": "\u6784\u5efaDeViBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u89c6\u9891\u6d41\u8d28\u91cf\u5bf9MLLM\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "Artic\u6846\u67b6\u6709\u6548\u964d\u4f4e\u5ef6\u8fdf\uff0c\u4e3aAI\u89c6\u9891\u804a\u5929\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.10338", "pdf": "https://arxiv.org/pdf/2507.10338", "abs": "https://arxiv.org/abs/2507.10338", "authors": ["Enyuan Tian", "Yiwei Ci", "Qiusong Yang", "Yufeng Li", "Zhichao Lyu"], "title": "AssertCoder: LLM-Based Assertion Generation via Multimodal Specification Extraction", "categories": ["cs.SE", "cs.AR", "cs.LO"], "comment": "7 pages, 3 figures", "summary": "Assertion-Based Verification (ABV) is critical for ensuring functional\ncorrectness in modern hardware systems. However, manually writing high-quality\nSVAs remains labor-intensive and error-prone. To bridge this gap, we propose\nAssertCoder, a novel unified framework that automatically generates\nhigh-quality SVAs directly from multimodal hardware design specifications.\nAssertCoder employs a modality-sensitive preprocessing to parse heterogeneous\nspecification formats (text, tables, diagrams, and formulas), followed by a set\nof dedicated semantic analyzers that extract structured representations aligned\nwith signal-level semantics. These representations are utilized to drive\nassertion synthesis via multi-step chain-of-thought (CoT) prompting. The\nframework incorporates a mutation-based evaluation approach to assess assertion\nquality via model checking and further refine the generated assertions.\nExperimental evaluation across three real-world Register-Transfer Level (RTL)\ndesigns demonstrates AssertCoder's superior performance, achieving an average\nincrease of 8.4% in functional correctness and 5.8% in mutation detection\ncompared to existing state-of-the-art approaches.", "AI": {"tldr": "AssertCoder \u662f\u4e00\u79cd\u81ea\u52a8\u4ece\u591a\u6a21\u6001\u786c\u4ef6\u8bbe\u8ba1\u89c4\u8303\u751f\u6210\u9ad8\u8d28\u91cf SVAs \u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u6001\u654f\u611f\u9884\u5904\u7406\u548c\u8bed\u4e49\u5206\u6790\u5668\u63d0\u53d6\u7ed3\u6784\u5316\u8868\u793a\uff0c\u518d\u901a\u8fc7\u591a\u6b65\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u5b8c\u6210\u65ad\u8a00\u5408\u6210\uff0c\u6700\u7ec8\u901a\u8fc7\u53d8\u5f02\u8bc4\u4f30\u4f18\u5316\u65ad\u8a00\u8d28\u91cf\u3002", "motivation": "\u624b\u52a8\u7f16\u5199\u9ad8\u8d28\u91cf\u7684 SVAs \u65e2\u8d39\u65f6\u53c8\u5bb9\u6613\u51fa\u9519\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u5de5\u5177\u6765\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "AssertCoder \u7ed3\u5408\u6a21\u6001\u654f\u611f\u9884\u5904\u7406\u3001\u8bed\u4e49\u5206\u6790\u5668\u548c\u591a\u6b65\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\uff0c\u5b9e\u73b0\u4ece\u591a\u6a21\u6001\u89c4\u8303\u5230\u65ad\u8a00\u7684\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAssertCoder \u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u53d8\u5f02\u68c0\u6d4b\u65b9\u9762\u5206\u522b\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e86 8.4% \u548c 5.8%\u3002", "conclusion": "AssertCoder \u4e3a\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u65ad\u8a00\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10430", "pdf": "https://arxiv.org/pdf/2507.10430", "abs": "https://arxiv.org/abs/2507.10430", "authors": ["Ji Liu", "Beichen Ma", "Yang Zhou", "Jingbo Zhou", "Ruoming Jin", "Dejing Dou", "Huaiyu Dai", "Haixun Wang", "Patrick Valduriez"], "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "29 pages, to appear in ACM Transactions on Knowledge Discovery from\n  Data (TKDD)", "summary": "Federated Learning (FL) is a promising distributed machine learning approach\nthat enables collaborative training of a global model using multiple edge\ndevices. The data distributed among the edge devices is highly heterogeneous.\nThus, FL faces the challenge of data distribution and heterogeneity, where\nnon-Independent and Identically Distributed (non-IID) data across edge devices\nmay yield in significant accuracy drop. Furthermore, the limited computation\nand communication capabilities of edge devices increase the likelihood of\nstragglers, thus leading to slow model convergence. In this paper, we propose\nthe FedDHAD FL framework, which comes with two novel methods: Dynamic\nHeterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH\ndynamically adjusts the weights of each local model within the model\naggregation process based on the non-IID degree of heterogeneous data to deal\nwith the statistical data heterogeneity. FedAD performs neuron-adaptive\noperations in response to heterogeneous devices to improve accuracy while\nachieving superb efficiency. The combination of these two methods makes FedDHAD\nsignificantly outperform state-of-the-art solutions in terms of accuracy (up to\n6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to\n15.0% smaller).", "AI": {"tldr": "FedDHAD\u662f\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5f02\u6784\u6a21\u578b\u805a\u5408\u548c\u81ea\u9002\u5e94Dropout\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u6784\u548c\u8fb9\u7f18\u8bbe\u5907\u6027\u80fd\u9650\u5236\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5206\u5e03\u4e0d\u5747\uff08\u975eIID\uff09\u548c\u8bbe\u5907\u6027\u80fd\u9650\u5236\u5bfc\u81f4\u7684\u6a21\u578b\u6536\u655b\u6162\u548c\u51c6\u786e\u6027\u4e0b\u964d\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u63d0\u51faFedDH\uff08\u52a8\u6001\u5f02\u6784\u6a21\u578b\u805a\u5408\uff09\u548cFedAD\uff08\u81ea\u9002\u5e94Dropout\uff09\u4e24\u79cd\u65b9\u6cd5\uff0c\u5206\u522b\u5904\u7406\u6570\u636e\u5f02\u6784\u548c\u8bbe\u5907\u6027\u80fd\u95ee\u9898\u3002", "result": "\u5728\u51c6\u786e\u6027\uff08\u6700\u9ad8\u63d0\u53476.7%\uff09\u3001\u6548\u7387\uff08\u6700\u9ad8\u5feb2.02\u500d\uff09\u548c\u8ba1\u7b97\u6210\u672c\uff08\u6700\u9ad8\u964d\u4f4e15.0%\uff09\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "FedDHAD\u6846\u67b6\u901a\u8fc7\u7ed3\u5408FedDH\u548cFedAD\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.09959", "pdf": "https://arxiv.org/pdf/2507.09959", "abs": "https://arxiv.org/abs/2507.09959", "authors": ["Shuchang Xu", "Xiaofu Jin", "Wenshuo Zhang", "Huamin Qu", "Yukang Yan"], "title": "Branch Explorer: Leveraging Branching Narratives to Support Interactive 360\u00b0 Video Viewing for Blind and Low Vision Users", "categories": ["cs.HC"], "comment": null, "summary": "360{\\deg} videos enable users to freely choose their viewing paths, but blind\nand low vision (BLV) users are often excluded from this interactive experience.\nTo bridge this gap, we present Branch Explorer, a system that transforms\n360{\\deg} videos into branching narratives -- stories that dynamically unfold\nbased on viewer choices -- to support interactive viewing for BLV audiences.\nOur formative study identified three key considerations for accessible\nbranching narratives: providing diverse branch options, ensuring coherent story\nprogression, and enabling immersive navigation among branches. To address these\nneeds, Branch Explorer employs a multi-modal machine learning pipeline to\ngenerate diverse narrative paths, allowing users to flexibly make choices at\ndetected branching points and seamlessly engage with each storyline through\nimmersive audio guidance. Evaluation with 12 BLV viewers showed that Branch\nExplorer significantly enhanced user agency and engagement in 360{\\deg} video\nviewing. Users also developed personalized strategies for exploring 360{\\deg}\ncontent. We further highlight implications for supporting accessible\nexploration of videos and virtual environments.", "AI": {"tldr": "Branch Explorer\u7cfb\u7edf\u901a\u8fc7\u5c06360\u5ea6\u89c6\u9891\u8f6c\u5316\u4e3a\u5206\u652f\u53d9\u4e8b\uff0c\u652f\u6301\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u4e92\u52a8\u89c2\u770b\uff0c\u63d0\u5347\u5176\u53c2\u4e0e\u611f\u3002", "motivation": "360\u5ea6\u89c6\u9891\u901a\u5e38\u65e0\u6cd5\u4e3a\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u63d0\u4f9b\u4e92\u52a8\u4f53\u9a8c\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u591a\u6a21\u6001\u673a\u5668\u5b66\u4e60\u751f\u6210\u591a\u6837\u53d9\u4e8b\u8def\u5f84\uff0c\u7528\u6237\u53ef\u901a\u8fc7\u97f3\u9891\u5bfc\u89c8\u81ea\u7531\u9009\u62e9\u5206\u652f\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c12\u540d\u7528\u6237\u4f53\u9a8c\u663e\u8457\u63d0\u5347\uff0c\u5e76\u53d1\u5c55\u51fa\u4e2a\u6027\u5316\u63a2\u7d22\u7b56\u7565\u3002", "conclusion": "Branch Explorer\u4e3a\u89c6\u9891\u548c\u865a\u62df\u73af\u5883\u65e0\u969c\u788d\u63a2\u7d22\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.09490", "pdf": "https://arxiv.org/pdf/2507.09490", "abs": "https://arxiv.org/abs/2507.09490", "authors": ["Yan Zhao", "Chiwei Tang"], "title": "Towards LLM-Based Automatic Playtest", "categories": ["cs.SE"], "comment": null, "summary": "Playtesting is the process in which people play a video game for testing. It\nis critical for the quality assurance of gaming software. Manual playtesting is\ntime-consuming and expensive. However, automating this process is challenging,\nas playtesting typically requires domain knowledge and problem-solving skills\nthat most conventional testing tools lack. Recent advancements in artificial\nintelligence (AI) have opened up new possibilities for applying Large Language\nModels (LLMs) to playtesting. However, significant challenges remain: current\nLLMs cannot visually perceive game environments, and most existing research\nfocuses on text-based games or games with robust APIs. Many non-text games lack\nAPIs to provide textual descriptions of game states, making it almost\nimpossible to naively apply LLMs for playtesting. This paper introduces Lap,\nour novel approach to LLM-based Automatic Playtesting, which uses ChatGPT to\ntest match-3 games, a category of games where players match three or more\nidentical tiles in a row or column to earn points. Lap encompasses three key\nphases: processing of game environments, prompting-based action generation, and\naction execution. Given a match-3 game, Lap takes a snapshot of the game board\nand converts it to a numeric matrix. It then prompts the ChatGPT-O1-mini API to\nsuggest moves based on that matrix and tentatively applies the suggested moves\nto earn points and trigger changes in the game board. It repeats the\nabove-mentioned three steps iteratively until timeout. For evaluation, we\nconducted a case study using Lap on an open-source match-3 game, CasseBonbons,\nand empirically compared it with three existing tools. Our results are\npromising: Lap outperformed existing tools by achieving higher code coverage\nand triggering more program crashes. This research sheds light on the future of\nautomatic testing and LLM applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u6e38\u620f\u6d4b\u8bd5\u65b9\u6cd5Lap\uff0c\u7528\u4e8e\u6d4b\u8bd5\u4e09\u6d88\u6e38\u620f\u3002Lap\u901a\u8fc7\u5904\u7406\u6e38\u620f\u73af\u5883\u3001\u57fa\u4e8e\u63d0\u793a\u751f\u6210\u52a8\u4f5c\u548c\u6267\u884c\u52a8\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u7387\u3002", "motivation": "\u624b\u52a8\u6e38\u620f\u6d4b\u8bd5\u8017\u65f6\u4e14\u6602\u8d35\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u5de5\u5177\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002AI\u7684\u8fdb\u5c55\u4e3aLLM\u5728\u6e38\u620f\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89c6\u89c9\u611f\u77e5\u6e38\u620f\u73af\u5883\uff0c\u4e14\u591a\u5c40\u9650\u4e8e\u6587\u672c\u6e38\u620f\u6216\u5177\u5907API\u7684\u6e38\u620f\u3002Lap\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "Lap\u5c06\u6e38\u620f\u677f\u8f6c\u6362\u4e3a\u6570\u503c\u77e9\u9635\uff0c\u5229\u7528ChatGPT-O1-mini API\u751f\u6210\u5efa\u8bae\u52a8\u4f5c\uff0c\u5e76\u6267\u884c\u52a8\u4f5c\u4ee5\u89e6\u53d1\u6e38\u620f\u53d8\u5316\uff0c\u8fed\u4ee3\u8fdb\u884c\u76f4\u81f3\u8d85\u65f6\u3002", "result": "\u5728\u5f00\u6e90\u4e09\u6d88\u6e38\u620fCasseBonbons\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLap\u5728\u4ee3\u7801\u8986\u76d6\u7387\u548c\u89e6\u53d1\u7a0b\u5e8f\u5d29\u6e83\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "conclusion": "Lap\u5c55\u793a\u4e86LLM\u5728\u81ea\u52a8\u6e38\u620f\u6d4b\u8bd5\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u81ea\u52a8\u6d4b\u8bd5\u548cLLM\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.10210", "pdf": "https://arxiv.org/pdf/2507.10210", "abs": "https://arxiv.org/abs/2507.10210", "authors": ["Thijs Havinga", "Xianjun Jiao", "Wei Liu", "Baiheng Chen", "Robbe Gaeremynck", "Ingrid Moerman"], "title": "Fine-Grained Coordinated OFDMA With Fiber Backhaul Enabled by openwifi and White Rabbit", "categories": ["cs.NI"], "comment": "6 pages, 7 figures. Submitted to GLOBECOM 2025", "summary": "Proper coordination is needed to guarantee the performance of wireless\nnetworks in dense deployments. Contention-based systems suffer badly in terms\nof latency when multiple devices compete for the same resources. Coordinated\nOrthogonal Frequency Division Multiple Access (Co-OFDMA) is proposed for Wi-Fi\n8 to remedy this, as it enables multiple Access Points (APs) to share spectrum\nmore efficiently. However, fine-grained resource allocation, namely within\n20MHz bandwidth, is argued to be impractical due to the over-the-air scheduling\noverhead and complexity in terms of physical layer signaling. A wired backhaul\nmitigates the need for over-the-air scheduling and synchronization, and it\nallows for coordination even if APs are not in each others' range. Furthermore,\nit forms the basis for more advanced multi-AP coordination schemes like\ncoordinated beamforming and joint transmission. In this work we demonstrate the\nrealization of Wi-Fi 6 compliant fine-grained Co-OFDMA using a fiber backhaul,\nenabled by the open-source platforms openwifi and White Rabbit. We show that\nthe performance in terms of carrier frequency offset pre-compensation and time\nsynchronization between two APs exceeds related wireless standard requirements.\nFurthermore, the quality of the received constellation of the Co-OFDMA frame as\nreported by a wireless connectivity tester is better than individual frames\nsent by the APs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6709\u7ebf\u80cc\u677f\u7684\u7ec6\u7c92\u5ea6Co-OFDMA\u6280\u672f\uff0c\u89e3\u51b3\u4e86Wi-Fi 8\u5728\u591aAP\u5bc6\u96c6\u90e8\u7f72\u4e2d\u7684\u8d44\u6e90\u7ade\u4e89\u548c\u8c03\u5ea6\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u4f18\u8d8a\u6027\u3002", "motivation": "\u5bc6\u96c6\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0c\u7ade\u4e89\u6027\u7cfb\u7edf\u5728\u591a\u8bbe\u5907\u7ade\u4e89\u8d44\u6e90\u65f6\u5ef6\u8fdf\u95ee\u9898\u4e25\u91cd\uff0cCo-OFDMA\u88ab\u63d0\u51fa\u7528\u4e8e\u66f4\u9ad8\u6548\u7684\u9891\u8c31\u5171\u4eab\uff0c\u4f46\u7ec6\u7c92\u5ea6\u8d44\u6e90\u5206\u914d\u5b58\u5728\u5b9e\u9645\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u5149\u7ea4\u80cc\u677f\u5b9e\u73b0Wi-Fi 6\u517c\u5bb9\u7684\u7ec6\u7c92\u5ea6Co-OFDMA\uff0c\u5229\u7528\u5f00\u6e90\u5e73\u53f0openwifi\u548cWhite Rabbit\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u89e3\u51b3\u4e86\u7a7a\u4e2d\u8c03\u5ea6\u548c\u540c\u6b65\u7684\u590d\u6742\u6027\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4e24\u4e2aAP\u4e4b\u95f4\u7684\u8f7d\u6ce2\u9891\u7387\u504f\u79fb\u9884\u8865\u507f\u548c\u65f6\u95f4\u540c\u6b65\u6027\u80fd\u4f18\u4e8e\u76f8\u5173\u65e0\u7ebf\u6807\u51c6\u8981\u6c42\uff0cCo-OFDMA\u5e27\u7684\u63a5\u6536\u8d28\u91cf\u4f18\u4e8eAP\u5355\u72ec\u53d1\u9001\u7684\u5e27\u3002", "conclusion": "\u57fa\u4e8e\u6709\u7ebf\u80cc\u677f\u7684Co-OFDMA\u6280\u672f\u5728\u591aAP\u534f\u8c03\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u9ad8\u7ea7\u591aAP\u534f\u8c03\u65b9\u6848\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.08846", "pdf": "https://arxiv.org/pdf/2507.08846", "abs": "https://arxiv.org/abs/2507.08846", "authors": ["Serdar Metin"], "title": "Precomputed Dominant Resource Fairness", "categories": ["cs.GT", "cs.DC", "cs.DS"], "comment": "9 pages", "summary": "Although resource allocation is a well studied problem in computer science,\nuntil the prevalence of distributed systems, such as computing clouds and data\ncentres, the question had been addressed predominantly for single resource type\nscenarios. At the beginning of the last decade, with the introuction of\nDominant Resource Fairness, the studies of the resource allocation problem has\nfinally extended to the multiple resource type scenarios. Dominant Resource\nFairness is a solution, addressing the problem of fair allocation of multiple\nresource types, among users with heterogeneous demands. Based on Max-min\nFairness, which is a well established algorithm in the literature for\nallocating resources in the single resource type scenarios, Dominant Resource\nFairness generalises the scheme to the multiple resource case. It has a number\nof desirable properties that makes it preferable over alternatives, such as\nSharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness,\nand as such, it is widely adopted in distributed systems. In the present study,\nwe revisit the original study, and analyse the structure of the algorithm in\ncloser view, to come up with an alternative algorithm, which approximates the\nDominant Resource Fairness allocation in fewer steps. We name the new algorithm\nPrecomputed Dominant Resource Fairness, after its main working principle.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u9884\u8ba1\u7b97\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u201d\u7684\u65b0\u7b97\u6cd5\uff0c\u65e8\u5728\u4ee5\u66f4\u5c11\u6b65\u9aa4\u8fd1\u4f3c\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u5206\u914d\u3002", "motivation": "\u968f\u7740\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u591a\u8d44\u6e90\u7c7b\u578b\u573a\u666f\u4e0b\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\u53d8\u5f97\u91cd\u8981\u3002\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u867d\u7136\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5176\u7b97\u6cd5\u7ed3\u6784\u4ecd\u6709\u4f18\u5316\u7a7a\u95f4\u3002", "method": "\u57fa\u4e8e\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\uff08Max-min\u516c\u5e73\u6027\u7684\u591a\u8d44\u6e90\u6269\u5c55\uff09\uff0c\u5206\u6790\u5176\u7b97\u6cd5\u7ed3\u6784\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7b97\u6cd5\u2014\u2014\u9884\u8ba1\u7b97\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u3002", "result": "\u65b0\u7b97\u6cd5\u80fd\u591f\u5728\u66f4\u5c11\u6b65\u9aa4\u5185\u8fd1\u4f3c\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u7684\u5206\u914d\u7ed3\u679c\u3002", "conclusion": "\u9884\u8ba1\u7b97\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u66ff\u4ee3\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u8d44\u6e90\u7c7b\u578b\u573a\u666f\u4e0b\u7684\u8d44\u6e90\u5206\u914d\u3002"}}
{"id": "2507.10024", "pdf": "https://arxiv.org/pdf/2507.10024", "abs": "https://arxiv.org/abs/2507.10024", "authors": ["Shaolun Ruan", "Rui Sheng", "Xiaolin Wen", "Jiachen Wang", "Tianyi Zhang", "Yong Wang", "Tim Dwyer", "Jiannan Li"], "title": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles", "categories": ["cs.HC"], "comment": null, "summary": "Design studies aim to create visualization solutions for real-world problems\nof different application domains. Recently, the emergence of large language\nmodels (LLMs) has introduced new opportunities to enhance the design study\nprocess, providing capabilities such as creative problem-solving, data\nhandling, and insightful analysis. However, despite their growing popularity,\nthere remains a lack of systematic understanding of how LLMs can effectively\nassist researchers in visualization-specific design studies. In this paper, we\nconducted a multi-stage qualitative study to fill this gap, involving 30 design\nstudy researchers from diverse backgrounds and expertise levels. Through\nin-depth interviews and carefully-designed questionnaires, we investigated\nstrategies for utilizing LLMs, the challenges encountered, and the practices\nused to overcome them. We further compiled and summarized the roles that LLMs\ncan play across different stages of the design study process. Our findings\nhighlight practical implications to inform visualization practitioners, and\nprovide a framework for leveraging LLMs to enhance the design study process in\nvisualization research.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u6709\u6548\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u589e\u5f3a\u53ef\u89c6\u5316\u8bbe\u8ba1\u7814\u7a76\u7684\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u591a\u9636\u6bb5\u5b9a\u6027\u7814\u7a76\u603b\u7ed3\u4e86LLM\u5728\u8bbe\u8ba1\u7814\u7a76\u4e2d\u7684\u89d2\u8272\u3001\u6311\u6218\u548c\u5e94\u5bf9\u7b56\u7565\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u53ef\u89c6\u5316\u8bbe\u8ba1\u7814\u7a76\u4e2d\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5173\u4e8e\u5982\u4f55\u7cfb\u7edf\u5229\u7528LLM\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u591a\u9636\u6bb5\u5b9a\u6027\u7814\u7a76\uff0c\u91c7\u8bbf\u4e8630\u540d\u4e0d\u540c\u80cc\u666f\u7684\u8bbe\u8ba1\u7814\u7a76\u4eba\u5458\uff0c\u7ed3\u5408\u6df1\u5ea6\u8bbf\u8c08\u548c\u95ee\u5377\u8c03\u67e5\uff0c\u63a2\u8ba8\u4e86LLM\u7684\u4f7f\u7528\u7b56\u7565\u3001\u6311\u6218\u53ca\u5e94\u5bf9\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u5728\u8bbe\u8ba1\u7814\u7a76\u7684\u4e0d\u540c\u9636\u6bb5\u53ef\u4ee5\u626e\u6f14\u591a\u79cd\u89d2\u8272\uff0c\u5e76\u4e3a\u53ef\u89c6\u5316\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u53ef\u89c6\u5316\u7814\u7a76\u4e2d\u5982\u4f55\u5229\u7528LLM\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u6846\u67b6\u548c\u5b9e\u8df5\u5efa\u8bae\u3002"}}
{"id": "2507.09529", "pdf": "https://arxiv.org/pdf/2507.09529", "abs": "https://arxiv.org/abs/2507.09529", "authors": ["Yunqian Wang", "Xiaohong Li", "Yao Zhang", "Yuekang Li", "Zhiping Zhou", "Ruitao Feng"], "title": "It Only Gets Worse: Revisiting DL-Based Vulnerability Detectors from a Practical Perspective", "categories": ["cs.SE"], "comment": null, "summary": "With the growing threat of software vulnerabilities, deep learning (DL)-based\ndetectors have gained popularity for vulnerability detection. However, doubts\nremain regarding their consistency within declared CWE ranges, real-world\neffectiveness, and applicability across scenarios. These issues may lead to\nunreliable detection, high false positives/negatives, and poor adaptability to\nemerging vulnerabilities. A comprehensive analysis is needed to uncover\ncritical factors affecting detection and guide improvements in model design and\ndeployment. In this paper, we present VulTegra, a novel evaluation framework\nthat conducts a multidimensional comparison of scratch-trained and\npre-trained-based DL models for vulnerability detection. VulTegra reveals that\nstate-of-the-art (SOTA) detectors still suffer from low consistency, limited\nreal-world capabilities, and scalability challenges. Contrary to common belief,\npre-trained models are not consistently better than scratch-trained models but\nexhibit distinct strengths in specific contexts.Importantly, our study exposes\nthe limitations of relying solely on CWE-based classification and identifies\nkey factors that significantly affect model performance. Experimental results\nshow that adjusting just one such factor consistently improves recall across\nall seven evaluated detectors, with six also achieving better F1 scores. Our\nfindings provide deeper insights into model behavior and emphasize the need to\nconsider both vulnerability types and inherent code features for effective\ndetection.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86VulTegra\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u548c\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u6f0f\u6d1e\u5a01\u80c1\u7684\u589e\u52a0\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6f0f\u6d1e\u68c0\u6d4b\u5668\u65e5\u76ca\u6d41\u884c\uff0c\u4f46\u5176\u4e00\u81f4\u6027\u3001\u5b9e\u9645\u6548\u679c\u548c\u9002\u7528\u6027\u4ecd\u5b58\u5728\u95ee\u9898\u3002", "method": "\u63d0\u51faVulTegra\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ef4\u6bd4\u8f83\u4ece\u96f6\u8bad\u7ec3\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u73b0\u6709\u68c0\u6d4b\u5668\u5728\u4e00\u81f4\u6027\u3001\u5b9e\u9645\u80fd\u529b\u548c\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u8c03\u6574\u5173\u952e\u56e0\u7d20\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u9700\u7ed3\u5408\u6f0f\u6d1e\u7c7b\u578b\u548c\u4ee3\u7801\u7279\u5f81\u4ee5\u6539\u8fdb\u68c0\u6d4b\u6548\u679c\uff0c\u5e76\u4e3a\u6a21\u578b\u8bbe\u8ba1\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2507.08868", "pdf": "https://arxiv.org/pdf/2507.08868", "abs": "https://arxiv.org/abs/2507.08868", "authors": ["Benedikt Pittl", "Werner Mach", "Erich Schikuta"], "title": "A Survey on Bilateral Multi-Round Cloud-SLA Negotiation Strategies", "categories": ["cs.GT", "cs.DC", "91B26", "J.1; J.4"], "comment": "Preprint", "summary": "Today, static cloud markets where consumers purchase services directly from\nproviders are dominating. Thus, consumers neither negotiate the price nor the\ncharacteristics of the service. In recent years, providers have adopted more\ndynamic trading mechanisms, as e.g. Amazon's EC2 platform shows: In addition to\nthe reservation marketspace and the on-demand marketspace, Amazon offers a spot\nmarketspace where consumers can bid for virtual machines. This spot marketspace\nwas extended with spot blocks, and recently Amazon reworked the bidding\noptions. In addition, other cloud providers, such as Virtustream, adopt dynamic\ntrading mechanisms. The scientific community envisions autonomous multi-round\nnegotiations for realizing future cloud marketspaces. Consequently, consumers\nand providers exchange offers and counteroffers to reach an agreement. This\nhelps providers increase the utilization of their datacenters, while consumers\ncan purchase highly customized cloud services.\n  In the paper at hand, we present a survey on multi-round bilateral\nnegotiation strategies for trading cloud resources. Thus, we analyzed\npeer-reviewed articles in order to identify trends, gaps, similarities, and the\nscope of such negotiation strategies. In addition, we surveyed the formalism\nthat the scientific community uses to describe such strategies. Based on these\nfindings, we derived recommendations for creating and documenting bilateral\nmulti-round negotiation strategies to foster their implementation in the\nindustry.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4e91\u8d44\u6e90\u4ea4\u6613\u4e2d\u7684\u591a\u8f6e\u53cc\u8fb9\u8c08\u5224\u7b56\u7565\uff0c\u5206\u6790\u4e86\u8d8b\u52bf\u3001\u5dee\u8ddd\u548c\u76f8\u4f3c\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5173\u5efa\u8bae\u3002", "motivation": "\u63a2\u8ba8\u4e91\u5e02\u573a\u4e2d\u52a8\u6001\u4ea4\u6613\u673a\u5236\u7684\u6f5c\u529b\uff0c\u5982\u591a\u8f6e\u8c08\u5224\u5982\u4f55\u63d0\u5347\u6570\u636e\u4e2d\u5fc3\u5229\u7528\u7387\u548c\u5b9a\u5236\u5316\u670d\u52a1\u3002", "method": "\u901a\u8fc7\u5206\u6790\u540c\u884c\u8bc4\u5ba1\u6587\u7ae0\uff0c\u8bc6\u522b\u8c08\u5224\u7b56\u7565\u7684\u8d8b\u52bf\u3001\u5dee\u8ddd\u548c\u8303\u56f4\uff0c\u5e76\u8c03\u67e5\u63cf\u8ff0\u8fd9\u4e9b\u7b56\u7565\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u521b\u5efa\u548c\u8bb0\u5f55\u53cc\u8fb9\u591a\u8f6e\u8c08\u5224\u7b56\u7565\u7684\u5efa\u8bae\uff0c\u4ee5\u4fc3\u8fdb\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u591a\u8f6e\u53cc\u8fb9\u8c08\u5224\u7b56\u7565\u4e3a\u4e91\u5e02\u573a\u63d0\u4f9b\u4e86\u4f18\u5316\u6f5c\u529b\uff0c\u672a\u6765\u9700\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u9a8c\u8bc1\u5176\u6548\u679c\u3002"}}
{"id": "2507.10043", "pdf": "https://arxiv.org/pdf/2507.10043", "abs": "https://arxiv.org/abs/2507.10043", "authors": ["Suemin Jeon", "JunYoung Choi", "Haejin Jeong", "Won-Ki Jeong"], "title": "XROps: A Visual Workflow Management System for Dynamic Immersive Analytics", "categories": ["cs.HC"], "comment": null, "summary": "Immersive analytics is gaining attention across multiple domains due to its\ncapability to facilitate intuitive data analysis in expansive environments\nthrough user interaction with data. However, creating immersive analytics\nsystems for specific tasks is challenging due to the need for programming\nexpertise and significant development effort. Despite the introduction of\nvarious immersive visualization authoring toolkits, domain experts still face\nhurdles in adopting immersive analytics into their workflow, particularly when\nfaced with dynamically changing tasks and data in real time. To lower such\ntechnical barriers, we introduce XROps, a web-based authoring system that\nallows users to create immersive analytics applications through interactive\nvisual programming, without the need for low-level scripting or coding. XROps\nenables dynamic immersive analytics authoring by allowing users to modify each\nstep of the data visualization process with immediate feedback, enabling them\nto build visualizations on-the-fly and adapt to changing environments. It also\nsupports the integration and visualization of real-time sensor data from XR\ndevices, a key feature of immersive analytics, facilitating the creation of\nvarious analysis scenarios. We evaluated the usability of XROps through a user\nstudy and demonstrate its efficacy and usefulness in several example scenarios.\nWe have released a web platform (https://vience.io/xrops) to demonstrate\nvarious examples to supplement our findings.", "AI": {"tldr": "XROps\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f51\u7edc\u7684\u53ef\u89c6\u5316\u7f16\u7a0b\u7cfb\u7edf\uff0c\u65e8\u5728\u964d\u4f4e\u521b\u5efa\u6c89\u6d78\u5f0f\u5206\u6790\u5e94\u7528\u7684\u6280\u672f\u95e8\u69db\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u96c6\u6210\u548c\u52a8\u6001\u8c03\u6574\u3002", "motivation": "\u73b0\u6709\u6c89\u6d78\u5f0f\u5206\u6790\u5de5\u5177\u9700\u8981\u7f16\u7a0b\u6280\u80fd\uff0c\u4e14\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u4efb\u52a1\u548c\u6570\u636e\u53d8\u5316\uff0c\u9650\u5236\u4e86\u9886\u57df\u4e13\u5bb6\u7684\u4f7f\u7528\u3002", "method": "\u5f00\u53d1\u4e86XROps\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u7f16\u7a0b\u5b9e\u73b0\u6c89\u6d78\u5f0f\u5206\u6790\u7684\u52a8\u6001\u521b\u4f5c\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u96c6\u6210\u548c\u5373\u65f6\u53cd\u9988\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660eXROps\u6613\u7528\u4e14\u6709\u6548\uff0c\u80fd\u591f\u652f\u6301\u591a\u79cd\u5206\u6790\u573a\u666f\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5c55\u793a\u5e73\u53f0\u3002", "conclusion": "XROps\u4e3a\u9886\u57df\u4e13\u5bb6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u7f16\u7a0b\u7684\u5de5\u5177\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6c89\u6d78\u5f0f\u5206\u6790\u7cfb\u7edf\u7684\u5f00\u53d1\u95e8\u69db\u3002"}}
{"id": "2507.09583", "pdf": "https://arxiv.org/pdf/2507.09583", "abs": "https://arxiv.org/abs/2507.09583", "authors": ["Taniv Ashraf"], "title": "A Serverless Architecture for Real-Time Stock Analysis using Large Language Models: An Iterative Development and Debugging Case Study", "categories": ["cs.SE", "cs.AI", "I.2.7; J.1"], "comment": "6 pages. The live application can be viewed at\n  https://codepen.io/tanivashraf/pen/GgpgxBY and the source code is available\n  at https://github.com/TanivAshraf/ai-stock-analyzer", "summary": "The advent of powerful, accessible Large Language Models (LLMs) like Google's\nGemini presents new opportunities for democratizing financial data analysis.\nThis paper documents the design, implementation, and iterative debugging of a\nnovel, serverless system for real-time stock analysis. The system leverages the\nGemini API for qualitative assessment, automates data ingestion and processing\nvia GitHub Actions, and presents the findings through a decoupled, static\nfrontend. We detail the architectural evolution of the system, from initial\nconcepts to a robust, event-driven pipeline, highlighting the practical\nchallenges encountered during deployment. A significant portion of this paper\nis dedicated to a case study on the debugging process, covering common software\nerrors, platform-specific permission issues, and rare, environment-level\nplatform bugs. The final architecture operates at a near-zero cost,\ndemonstrating a viable model for individuals to build sophisticated AI-powered\nfinancial tools. The operational application is publicly accessible, and the\ncomplete source code is available for review. We conclude by discussing the\nrole of LLMs in financial analysis, the importance of robust debugging\nmethodologies, and the emerging paradigm of human-AI collaboration in software\ndevelopment.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Google\u7684Gemini\uff09\u7684\u5b9e\u65f6\u80a1\u7968\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u670d\u52a1\u5668\u67b6\u6784\u5b9e\u73b0\u4f4e\u6210\u672c\u8fd0\u884c\uff0c\u5e76\u5206\u4eab\u4e86\u8c03\u8bd5\u7ecf\u9a8c\u3002", "motivation": "\u5229\u7528\u5f3a\u5927\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Gemini\uff09 democratize \u91d1\u878d\u6570\u636e\u5206\u6790\uff0c\u4e3a\u4e2a\u4eba\u63d0\u4f9b\u9ad8\u7ea7AI\u5de5\u5177\u3002", "method": "\u7cfb\u7edf\u91c7\u7528Gemini API\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u901a\u8fc7GitHub Actions\u81ea\u52a8\u5316\u6570\u636e\u5904\u7406\uff0c\u5e76\u4f7f\u7528\u9759\u6001\u524d\u7aef\u5c55\u793a\u7ed3\u679c\u3002\u8be6\u7ec6\u8bb0\u5f55\u4e86\u4ece\u6982\u5ff5\u5230\u4e8b\u4ef6\u9a71\u52a8\u7ba1\u9053\u7684\u67b6\u6784\u6f14\u5316\u3002", "result": "\u6700\u7ec8\u67b6\u6784\u51e0\u4e4e\u96f6\u6210\u672c\u8fd0\u884c\uff0c\u9002\u7528\u4e8e\u4e2a\u4eba\u6784\u5efa\u590d\u6742\u7684AI\u91d1\u878d\u5de5\u5177\uff0c\u7cfb\u7edf\u516c\u5f00\u53ef\u7528\uff0c\u6e90\u4ee3\u7801\u5f00\u653e\u3002", "conclusion": "\u8ba8\u8bba\u4e86LLM\u5728\u91d1\u878d\u5206\u6790\u4e2d\u7684\u4f5c\u7528\u3001\u8c03\u8bd5\u65b9\u6cd5\u8bba\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u65b0\u5174\u8303\u5f0f\u3002"}}
{"id": "2507.09288", "pdf": "https://arxiv.org/pdf/2507.09288", "abs": "https://arxiv.org/abs/2507.09288", "authors": ["Javier Blanco-Romero", "Pedro Otero Garc\u00eda", "Daniel Sobral-Blanco", "Florina Almenares Mendoza", "Ana Fern\u00e1ndez Vilas", "Manuel Fern\u00e1ndez-Veiga"], "title": "Hybrid Quantum Security for IPsec", "categories": ["cs.CR", "cs.NI"], "comment": "23 pages, 6 figures, quantum key distribution, post-quantum\n  cryptography, IPsec security protocols", "summary": "Quantum Key Distribution (QKD) offers information-theoretic security against\nquantum computing threats, but integrating QKD into existing security protocols\nremains an unsolved challenge due to fundamental mismatches between\npre-distributed quantum keys and computational key exchange paradigms. This\npaper presents the first systematic comparison of sequential versus parallel\nhybrid QKD-PQC key establishment strategies for IPsec, revealing fundamental\nprotocol design principles that extend beyond specific implementations. We\nintroduce two novel approaches for incorporating QKD into Internet Key Exchange\nversion 2 (IKEv2) with support for both ETSI GS QKD 004 stateful and ETSI GS\nQKD 014 stateless API specifications: (1) a pure QKD approach that replaces\ncomputational key derivation with identifier-based quantum key coordination,\nand (2) a unified QKD-KEM abstraction that enables parallel composition of\nquantum and post-quantum cryptographic methods within existing protocol\nframeworks. Our key insight is that parallel hybrid approaches eliminate the\nmultiplicative latency penalties inherent in sequential methods mandated by RFC\n9370, achieving significant performance improvements under realistic network\nconditions. Performance evaluation using a Docker-based testing framework with\nIDQuantique QKD hardware demonstrates that the parallel hybrid approach\nsignificantly outperforms sequential methods under network latency conditions,\nwhile pure QKD achieves minimal bandwidth overhead through identifier-based key\ncoordination. Our implementations provide practical quantum-enhanced IPsec\nsolutions suitable for critical infrastructure deployments requiring\ndefense-in-depth security.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5e8f\u5217\u5316\u4e0e\u5e76\u884c\u6df7\u5408QKD-PQC\u5bc6\u94a5\u5efa\u7acb\u7b56\u7565\uff0c\u63d0\u51fa\u4e24\u79cd\u5c06QKD\u96c6\u6210\u5230IKEv2\u7684\u65b0\u65b9\u6cd5\uff0c\u8bc1\u660e\u5e76\u884c\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5e8f\u5217\u65b9\u6cd5\u3002", "motivation": "\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u867d\u63d0\u4f9b\u7406\u8bba\u4e0a\u5b89\u5168\u7684\u5bc6\u94a5\uff0c\u4f46\u5c06\u5176\u878d\u5165\u73b0\u6709\u5b89\u5168\u534f\u8bae\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a\u7eafQKD\u548c\u7edf\u4e00QKD-KEM\u62bd\u8c61\uff0c\u652f\u6301\u5e76\u884c\u7ec4\u5408\u91cf\u5b50\u4e0e\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u65b9\u6cd5\u3002", "result": "\u5e76\u884c\u6df7\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff1b\u7eafQKD\u901a\u8fc7\u6807\u8bc6\u5bc6\u94a5\u534f\u8c03\u51cf\u5c11\u5e26\u5bbd\u5f00\u9500\u3002", "conclusion": "\u63d0\u4f9b\u7684\u5b9e\u73b0\u9002\u7528\u4e8e\u9700\u8981\u6df1\u5ea6\u9632\u5fa1\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u90e8\u7f72\uff0c\u5c55\u73b0\u4e86\u91cf\u5b50\u589e\u5f3aIPsec\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.09019", "pdf": "https://arxiv.org/pdf/2507.09019", "abs": "https://arxiv.org/abs/2507.09019", "authors": ["Amey Agrawal", "Nitin Kedia", "Anmol Agarwal", "Jayashree Mohan", "Nipun Kwatra", "Souvik Kundu", "Ramachandran Ramjee", "Alexey Tumanov"], "title": "On Evaluating Performance of LLM Inference Serving Systems", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "The rapid evolution of Large Language Model (LLM) inference systems has\nyielded significant efficiency improvements. However, our systematic analysis\nreveals that current evaluation methodologies frequently exhibit fundamental\nflaws, often manifesting as common evaluation anti-patterns that obscure true\nperformance characteristics and impede scientific progress. Through a\ncomprehensive examination of recent systems, we identify recurring\nanti-patterns across three key dimensions: Baseline Fairness, Evaluation Setup,\nand Metric Design. These anti-patterns are uniquely problematic for LLM\ninference due to its dual-phase nature combining distinct prefill and decode\noperations, its handling of highly heterogeneous workloads, and its strict\ntemporal requirements for interactive use. We demonstrate how common\nanti-patterns -- such as inadequate baseline comparisons that conflate\nengineering effort with algorithmic novelty, workload selections that fail to\nrepresent production scenarios, and metric normalizations that hide substantial\nperformance variability like generation stalls-lead to misleading conclusions.\nTo address these challenges, we provide a comprehensive checklist derived from\nour analysis, establishing a framework for recognizing and avoiding these\nanti-patterns in favor of robust LLM inference evaluation. To demonstrate the\npractical application of our framework, we present a case study analyzing\nspeculative decoding, a technique whose bursty, non-uniform token generation is\neasily misinterpreted when evaluated using approaches characteristic of these\nanti-patterns. Our work establishes a rigorous foundation for evaluation\nmethodology, enabling meaningful comparisons, ensuring reproducible results,\nand ultimately accelerating genuine progress in LLM inference systems by moving\nbeyond common anti-patterns to align evaluation with real-world requirements.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u5e38\u89c1\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86\u8bc6\u522b\u548c\u907f\u514d\u8fd9\u4e9b\u95ee\u9898\u7684\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u7cfb\u7edf\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u5bfc\u81f4\u6027\u80fd\u7279\u5f81\u88ab\u63a9\u76d6\uff0c\u963b\u788d\u79d1\u5b66\u8fdb\u6b65\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff08\u57fa\u7ebf\u516c\u5e73\u6027\u3001\u8bc4\u4f30\u8bbe\u7f6e\u548c\u6307\u6807\u8bbe\u8ba1\uff09\u4e2d\u7684\u5e38\u89c1\u53cd\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u68c0\u67e5\u6e05\u5355\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5e38\u89c1\u53cd\u6a21\u5f0f\uff08\u5982\u57fa\u7ebf\u6bd4\u8f83\u4e0d\u5f53\u3001\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u4e0d\u5177\u4ee3\u8868\u6027\u7b49\uff09\u4f1a\u5bfc\u81f4\u8bef\u5bfc\u6027\u7ed3\u8bba\u3002", "conclusion": "\u8bba\u6587\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e25\u8c28\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u65e8\u5728\u4fc3\u8fdbLLM\u63a8\u7406\u7cfb\u7edf\u7684\u771f\u5b9e\u8fdb\u6b65\u3002"}}
{"id": "2507.10044", "pdf": "https://arxiv.org/pdf/2507.10044", "abs": "https://arxiv.org/abs/2507.10044", "authors": ["Shaohan Shi", "Yuheng Shao", "Haoran Jiang", "Yunjie Yao", "Zhijun Zhang", "Xu Ding", "Quan Li"], "title": "MEDebiaser: A Human-AI Feedback System for Mitigating Bias in Multi-label Medical Image Classification", "categories": ["cs.HC"], "comment": null, "summary": "Medical images often contain multiple labels with imbalanced distributions\nand co-occurrence, leading to bias in multi-label medical image classification.\nClose collaboration between medical professionals and machine learning\npractitioners has significantly advanced medical image analysis. However,\ntraditional collaboration modes struggle to facilitate effective feedback\nbetween physicians and AI models, as integrating medical expertise into the\ntraining process via engineers can be time-consuming and labor-intensive. To\nbridge this gap, we introduce MEDebiaser, an interactive system enabling\nphysicians to directly refine AI models using local explanations. By combining\nprediction with attention loss functions and employing a customized ranking\nstrategy to alleviate scalability, MEDebiaser allows physicians to mitigate\nbiases without technical expertise, reducing reliance on engineers, and thus\nenhancing more direct human-AI feedback. Our mechanism and user studies\ndemonstrate that it effectively reduces biases, improves usability, and\nenhances collaboration efficiency, providing a practical solution for\nintegrating medical expertise into AI-driven healthcare.", "AI": {"tldr": "MEDebiaser\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u5141\u8bb8\u533b\u751f\u901a\u8fc7\u672c\u5730\u89e3\u91ca\u76f4\u63a5\u4f18\u5316AI\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u51cf\u5c11\u5bf9\u5de5\u7a0b\u5e08\u7684\u4f9d\u8d56\uff0c\u63d0\u5347\u4eba\u673a\u534f\u4f5c\u6548\u7387\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u6807\u7b7e\u5206\u5e03\u4e0d\u5747\u8861\u4e14\u5b58\u5728\u5171\u73b0\u95ee\u9898\uff0c\u5bfc\u81f4\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u7684\u504f\u89c1\uff0c\u4f20\u7edf\u5408\u4f5c\u6a21\u5f0f\u96be\u4ee5\u5b9e\u73b0\u533b\u751f\u4e0eAI\u6a21\u578b\u7684\u6709\u6548\u53cd\u9988\u3002", "method": "MEDebiaser\u7ed3\u5408\u9884\u6d4b\u4e0e\u6ce8\u610f\u529b\u635f\u5931\u51fd\u6570\uff0c\u91c7\u7528\u5b9a\u5236\u6392\u540d\u7b56\u7565\uff0c\u4f7f\u533b\u751f\u65e0\u9700\u6280\u672f\u80cc\u666f\u5373\u53ef\u76f4\u63a5\u8c03\u6574\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cMEDebiaser\u80fd\u6709\u6548\u51cf\u5c11\u504f\u89c1\uff0c\u63d0\u5347\u53ef\u7528\u6027\u548c\u534f\u4f5c\u6548\u7387\u3002", "conclusion": "MEDebiaser\u4e3a\u5c06\u533b\u5b66\u4e13\u4e1a\u77e5\u8bc6\u878d\u5165AI\u533b\u7597\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09594", "pdf": "https://arxiv.org/pdf/2507.09594", "abs": "https://arxiv.org/abs/2507.09594", "authors": ["Aydin Homay"], "title": "How to Define Design in Industrial Control and Automation Software", "categories": ["cs.SE"], "comment": null, "summary": "Design is a fundamental aspect of engineering, enabling the creation of\nproducts, systems, and organizations to meet societal and/or business needs.\nHowever, the absence of a scientific foundation in design often results in\nsubjective decision-making, reducing both efficiency and innovation. This\nchallenge is particularly evident in the software industry and, by extension,\nin the domain of industrial control and automation systems (iCAS).\n  In this study, first we review the existing design definitions within the\nsoftware industry, challenge prevailing misconceptions about design, review\ndesign definition in the field of design theory and address key questions such\nas: When does design begin? How can design be defined scientifically? What\nconstitutes good design? and the difference between design and design language\nby relying on advancements in the field of design theory. We also evaluate the\ndistinction between ad-hoc and systematic design approaches, and present\narguments on how to balance complementary operational concerns while resolving\nconflicting evolutionary concerns.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u8bbe\u8ba1\u5728\u5de5\u7a0b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u6307\u51fa\u7f3a\u4e4f\u79d1\u5b66\u57fa\u7840\u4f1a\u5bfc\u81f4\u4e3b\u89c2\u51b3\u7b56\uff0c\u5f71\u54cd\u6548\u7387\u548c\u521b\u65b0\u3002\u901a\u8fc7\u56de\u987e\u8f6f\u4ef6\u884c\u4e1a\u7684\u8bbe\u8ba1\u5b9a\u4e49\uff0c\u6311\u6218\u8bef\u89e3\uff0c\u5e76\u57fa\u4e8e\u8bbe\u8ba1\u7406\u8bba\u63d0\u51fa\u79d1\u5b66\u5b9a\u4e49\u548c\u597d\u8bbe\u8ba1\u7684\u6807\u51c6\u3002", "motivation": "\u8bbe\u8ba1\u5728\u5de5\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u79d1\u5b66\u57fa\u7840\uff0c\u5bfc\u81f4\u4e3b\u89c2\u51b3\u7b56\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u8f6f\u4ef6\u548c\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u4e2d\u3002", "method": "\u56de\u987e\u8f6f\u4ef6\u884c\u4e1a\u7684\u8bbe\u8ba1\u5b9a\u4e49\uff0c\u6311\u6218\u8bef\u89e3\uff0c\u7ed3\u5408\u8bbe\u8ba1\u7406\u8bba\u63d0\u51fa\u79d1\u5b66\u5b9a\u4e49\u548c\u597d\u8bbe\u8ba1\u6807\u51c6\uff0c\u5e76\u533a\u5206\u4e34\u65f6\u548c\u7cfb\u7edf\u5316\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u8bbe\u8ba1\u7406\u8bba\uff0c\u660e\u786e\u4e86\u8bbe\u8ba1\u7684\u79d1\u5b66\u5b9a\u4e49\u3001\u597d\u8bbe\u8ba1\u7684\u6807\u51c6\uff0c\u4ee5\u53ca\u5982\u4f55\u5e73\u8861\u64cd\u4f5c\u4e0e\u8fdb\u5316\u7684\u9700\u6c42\u3002", "conclusion": "\u8bba\u6587\u4e3a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u79d1\u5b66\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\u548c\u521b\u65b0\u6027\uff0c\u5c24\u5176\u5728\u8f6f\u4ef6\u548c\u5de5\u4e1a\u63a7\u5236\u9886\u57df\u3002"}}
{"id": "2507.09301", "pdf": "https://arxiv.org/pdf/2507.09301", "abs": "https://arxiv.org/abs/2507.09301", "authors": ["Julio Gento Suela", "Javier Blanco-Romero", "Florina Almenares Mendoza", "Daniel D\u00edaz-S\u00e1nchez"], "title": "Implementing and Evaluating Post-Quantum DNSSEC in CoreDNS", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "The emergence of quantum computers poses a significant threat to current\nsecure service, application and/or protocol implementations that rely on RSA\nand ECDSA algorithms, for instance DNSSEC, because public-key cryptography\nbased on number factorization or discrete logarithm is vulnerable to quantum\nattacks. This paper presents the integration of post-quantum cryptographic\n(PQC) algorithms into CoreDNS to enable quantum-resistant DNSSEC functionality.\nWe have developed a plugin that extends CoreDNS with support for five PQC\nsignature algorithm families: ML-DSA, FALCON, SPHINCS+, MAYO, and SNOVA. Our\nimplementation maintains compatibility with existing DNS resolution flows while\nproviding on-the-fly signing using quantum-resistant signatures. A benchmark\nhas been performed and performance evaluation results reveal significant\ntrade-offs between security and efficiency. The results indicate that while PQC\nalgorithms introduce operational overhead, several candidates offer viable\ncompromises for transitioning DNSSEC to quantum-resistant cryptography.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u540e\u91cf\u5b50\u5bc6\u7801\uff08PQC\uff09\u7b97\u6cd5\u96c6\u6210\u5230CoreDNS\u4e2d\uff0c\u4ee5\u5b9e\u73b0\u91cf\u5b50\u5b89\u5168\u7684DNSSEC\u529f\u80fd\uff0c\u652f\u6301\u4e94\u79cdPQC\u7b7e\u540d\u7b97\u6cd5\uff0c\u5e76\u8bc4\u4f30\u5176\u6027\u80fd\u4e0e\u5b89\u5168\u6027\u6743\u8861\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u51fa\u73b0\u5a01\u80c1\u5230\u4f9d\u8d56RSA\u548cECDSA\u7b49\u7b97\u6cd5\u7684\u5b89\u5168\u670d\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u90e8\u7f72\u91cf\u5b50\u5b89\u5168\u7684\u5bc6\u7801\u5b66\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u63d2\u4ef6\uff0c\u5728CoreDNS\u4e2d\u96c6\u6210\u4e86\u4e94\u79cdPQC\u7b7e\u540d\u7b97\u6cd5\u5bb6\u65cf\uff08ML-DSA\u3001FALCON\u3001SPHINCS+\u3001MAYO\u548cSNOVA\uff09\uff0c\u5e76\u4fdd\u6301\u4e0e\u73b0\u6709DNS\u89e3\u6790\u6d41\u7a0b\u7684\u517c\u5bb9\u6027\u3002", "result": "\u6027\u80fd\u8bc4\u4f30\u663e\u793aPQC\u7b97\u6cd5\u5728\u5b89\u5168\u6027\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6743\u8861\uff0c\u90e8\u5206\u7b97\u6cd5\u9002\u5408\u8fc7\u6e21\u5230\u91cf\u5b50\u5b89\u5168\u7684DNSSEC\u3002", "conclusion": "\u5c3d\u7ba1PQC\u7b97\u6cd5\u589e\u52a0\u4e86\u64cd\u4f5c\u5f00\u9500\uff0c\u4f46\u90e8\u5206\u5019\u9009\u7b97\u6cd5\u4e3aDNSSEC\u5411\u91cf\u5b50\u5b89\u5168\u5bc6\u7801\u5b66\u7684\u8fc7\u6e21\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.09596", "pdf": "https://arxiv.org/pdf/2507.09596", "abs": "https://arxiv.org/abs/2507.09596", "authors": ["Aydin Homay"], "title": "The Mythical Good Software", "categories": ["cs.SE"], "comment": null, "summary": "Good software has high cohesion and low coupling is clumsy, obscure, and in\nsome certain cases could be actually a harmful state of being. It is clumsy\nbecause there is no perfect correlation between higher cohesiveness and optimum\ndesign, and it is obscure because it conveys the message that coupling and\ncohesion are two distinct design principles, while there are in principle the\nsame design approaches, and only the time and space differ between them, and it\ncould also be a harmful state of being because we should not always aim for\nhigher cohesiveness without considering its cost.\n  In the course of this study, we aim to elucidate for the readers the meaning\nand underlying philosophy of the aforementioned paragraph.", "AI": {"tldr": "\u8f6f\u4ef6\u8bbe\u8ba1\u4e2d\u9ad8\u5185\u805a\u4f4e\u8026\u5408\u5e76\u975e\u603b\u662f\u6700\u4f18\uff0c\u53ef\u80fd\u7b28\u62d9\u3001\u6a21\u7cca\u751a\u81f3\u6709\u5bb3\u3002", "motivation": "\u9610\u660e\u9ad8\u5185\u805a\u4f4e\u8026\u5408\u7684\u5b9e\u9645\u610f\u4e49\u53ca\u5176\u6f5c\u5728\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5176\u7b28\u62d9\u6027\u3001\u6a21\u7cca\u6027\u548c\u6f5c\u5728\u5371\u5bb3\u6027\u6765\u8bf4\u660e\u3002", "result": "\u6307\u51fa\u9ad8\u5185\u805a\u4f4e\u8026\u5408\u5e76\u975e\u7edd\u5bf9\u539f\u5219\uff0c\u9700\u6743\u8861\u6210\u672c\u3002", "conclusion": "\u8bbe\u8ba1\u65f6\u5e94\u7efc\u5408\u8003\u91cf\uff0c\u800c\u975e\u76f2\u76ee\u8ffd\u6c42\u9ad8\u5185\u805a\u4f4e\u8026\u5408\u3002"}}
{"id": "2507.09627", "pdf": "https://arxiv.org/pdf/2507.09627", "abs": "https://arxiv.org/abs/2507.09627", "authors": ["Muhammad Kamran Saeed", "Ashfaq Khokhar", "Shakil Ahmed"], "title": "Lightweight Deep Learning-Based Channel Estimation for RIS-Aided Extremely Large-Scale MIMO Systems on Resource-Limited Edge Devices", "categories": ["cs.IT", "cs.CV", "cs.LG", "cs.NI", "math.IT"], "comment": null, "summary": "Next-generation wireless technologies such as 6G aim to meet demanding\nrequirements such as ultra-high data rates, low latency, and enhanced\nconnectivity. Extremely Large-Scale MIMO (XL-MIMO) and Reconfigurable\nIntelligent Surface (RIS) are key enablers, with XL-MIMO boosting spectral and\nenergy efficiency through numerous antennas, and RIS offering dynamic control\nover the wireless environment via passive reflective elements. However,\nrealizing their full potential depends on accurate Channel State Information\n(CSI). Recent advances in deep learning have facilitated efficient cascaded\nchannel estimation. However, the scalability and practical deployment of\nexisting estimation models in XL-MIMO systems remain limited. The growing\nnumber of antennas and RIS elements introduces a significant barrier to\nreal-time and efficient channel estimation, drastically increasing data volume,\nescalating computational complexity, requiring advanced hardware, and resulting\nin substantial energy consumption. To address these challenges, we propose a\nlightweight deep learning framework for efficient cascaded channel estimation\nin XL-MIMO systems, designed to minimize computational complexity and make it\nsuitable for deployment on resource-constrained edge devices. Using spatial\ncorrelations in the channel, we introduce a patch-based training mechanism that\nreduces the dimensionality of input to patch-level representations while\npreserving essential information, allowing scalable training for large-scale\nsystems. Simulation results under diverse conditions demonstrate that our\nframework significantly improves estimation accuracy and reduces computational\ncomplexity, regardless of the increasing number of antennas and RIS elements in\nXL-MIMO systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8eXL-MIMO\u7cfb\u7edf\u4e2d\u7684\u9ad8\u6548\u7ea7\u8054\u4fe1\u9053\u4f30\u8ba1\uff0c\u65e8\u5728\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "motivation": "6G\u7b49\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u6280\u672f\u9700\u6ee1\u8db3\u8d85\u9ad8\u6570\u636e\u901f\u7387\u3001\u4f4e\u5ef6\u8fdf\u548c\u589e\u5f3a\u8fde\u63a5\u6027\uff0cXL-MIMO\u548cRIS\u662f\u5173\u952e\u63a8\u52a8\u6280\u672f\uff0c\u4f46\u5176\u6f5c\u529b\u4f9d\u8d56\u4e8e\u51c6\u786e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u3002\u73b0\u6709\u4f30\u8ba1\u6a21\u578b\u5728\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u90e8\u7f72\u4e0a\u5b58\u5728\u5c40\u9650\u3002", "method": "\u5229\u7528\u4fe1\u9053\u4e2d\u7684\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5757\u7684\u8bad\u7ec3\u673a\u5236\uff0c\u5c06\u8f93\u5165\u964d\u7ef4\u4e3a\u5206\u5757\u7ea7\u8868\u793a\uff0c\u540c\u65f6\u4fdd\u7559\u5173\u952e\u4fe1\u606f\uff0c\u9002\u5408\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u8bad\u7ec3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e0d\u53d7XL-MIMO\u7cfb\u7edf\u4e2d\u5929\u7ebf\u548cRIS\u5143\u4ef6\u6570\u91cf\u589e\u52a0\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u8f7b\u91cf\u7ea7\u6846\u67b6\u4e3aXL-MIMO\u7cfb\u7edf\u4e2d\u7684\u9ad8\u6548\u4fe1\u9053\u4f30\u8ba1\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002"}}
{"id": "2507.09453", "pdf": "https://arxiv.org/pdf/2507.09453", "abs": "https://arxiv.org/abs/2507.09453", "authors": ["Micha\u0142 J\u00f3\u017awik", "Johan Pouwelse"], "title": "SmartphoneDemocracy: Privacy-Preserving E-Voting on Decentralized Infrastructure using Novel European Identity", "categories": ["cs.CR", "cs.DC"], "comment": "18 pages, 4 figures", "summary": "The digitization of democratic processes promises greater accessibility but\npresents challenges in terms of security, privacy, and verifiability. Existing\nelectronic voting systems often rely on centralized architectures, creating\nsingle points of failure and forcing too much trust in authorities, which\ncontradicts democratic principles. This research addresses the challenge of\ncreating a secure, private e-voting system with minimized trust dependencies\ndesigned for the most versatile personal device: the smartphone. We introduce\nSmartphoneDemocracy, a novel e-voting protocol that combines three key\ntechnologies: the emerging European Digital Identity (EUDI) Wallet for\nSybil-resistant identity verification, Zero-Knowledge Proofs for\nprivacy-preserving validation, and a peer-to-peer blockchain (TrustChain) for a\nresilient, serverless public bulletin board. Our protocol enables voters to\nregister and cast ballots anonymously and verifiably directly from their\nsmartphones. We provide a detailed protocol design, a security analysis against\na defined threat model, and a performance evaluation demonstrating that the\ncomputational and network overhead is feasible for medium- to large-scale\nelections. By developing and prototyping this system, we demonstrate a viable\npath to empower citizens with a trustworthy, accessible, and user-controlled\ndigital voting experience.", "AI": {"tldr": "\u8bba\u6587\u6458\u8981\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aSmartphoneDemocracy\u7684\u65b0\u578b\u7535\u5b50\u6295\u7968\u534f\u8bae\uff0c\u7ed3\u5408\u4e86\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u94b1\u5305\u3001\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u70b9\u5bf9\u70b9\u533a\u5757\u94fe\u6280\u672f\uff0c\u65e8\u5728\u63d0\u4f9b\u5b89\u5168\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u53ef\u9a8c\u8bc1\u7684\u667a\u80fd\u624b\u673a\u6295\u7968\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u4f9d\u8d56\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u5b58\u5728\u5355\u70b9\u6545\u969c\u548c\u8fc7\u5ea6\u4fe1\u4efb\u95ee\u9898\uff0c\u8fdd\u80cc\u6c11\u4e3b\u539f\u5219\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5b89\u5168\u7684\u53bb\u4e2d\u5fc3\u5316\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u94b1\u5305\uff08EUDI Wallet\uff09\u9632\u6b62\u8eab\u4efd\u4f2a\u9020\uff0c\u96f6\u77e5\u8bc6\u8bc1\u660e\u4fdd\u62a4\u9690\u79c1\uff0cTrustChain\u533a\u5757\u94fe\u4f5c\u4e3a\u65e0\u670d\u52a1\u5668\u7684\u516c\u5171\u516c\u544a\u677f\u3002", "result": "\u534f\u8bae\u8bbe\u8ba1\u8be6\u5b9e\uff0c\u5b89\u5168\u5206\u6790\u5b8c\u5584\uff0c\u6027\u80fd\u8bc4\u4f30\u663e\u793a\u8ba1\u7b97\u548c\u7f51\u7edc\u5f00\u9500\u9002\u7528\u4e8e\u4e2d\u5927\u89c4\u6a21\u9009\u4e3e\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u516c\u6c11\u63d0\u4f9b\u4e86\u53ef\u4fe1\u3001\u6613\u7528\u4e14\u7528\u6237\u53ef\u63a7\u7684\u6570\u5b57\u5316\u6295\u7968\u4f53\u9a8c\u3002"}}
{"id": "2507.10102", "pdf": "https://arxiv.org/pdf/2507.10102", "abs": "https://arxiv.org/abs/2507.10102", "authors": ["Jeongone Seo", "Kyung-zoon Hong", "Sol Baik"], "title": "When Familiarity Remains: Procedural Memory, Symbolic Anchors, and Digital Engagement in Dementia Care", "categories": ["cs.HC"], "comment": "23 page, 2 tables, 1 figure", "summary": "INTRODUCTION: Older adults with early-stage dementia often retain procedural\nmemory, enabling continued use of familiar technologies. Additionally, symbolic\nanchors such as photos or personalized content may serve as memory cues to\nreinforce digital engagement. This study explores how these mechanisms support\ntechnology use in dementia care within the South Korean context.\n  METHODS: We conducted in-depth interviews with 11 professional caregivers of\ncommunity-dwelling older adults with cognitive decline. Grounded theory methods\nguided the analysis, using iterative coding and constant comparison to identify\nemergent themes.\n  RESULTS: Caregivers reported that familiar digital routines (e.g., taking\nphotos) persisted through procedural memory. Symbolic anchors such as family\nphotos or recognizable icons enhanced interaction and emotional engagement.\nHowever, unfamiliar or anthropomorphic technologies often triggered fear or\nsymbolic resistance.\n  DISCUSSION: Findings highlight the dual role of procedural memory and\nsymbolic anchors in sustaining digital engagement. Designing culturally\nresponsive and cognitively accessible technologies may enhance autonomy and\nwell-being in dementia care.\n  Keywords: procedural memory, symbolic anchors, dementia care, digital\nengagement, older adults, cultural adaptation, caregiving technologies", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u548c\u8c61\u5f81\u6027\u951a\u70b9\u5982\u4f55\u652f\u6301\u97e9\u56fd\u8001\u5e74\u75f4\u5446\u75c7\u60a3\u8005\u7684\u6280\u672f\u4f7f\u7528\uff0c\u901a\u8fc7\u8bbf\u8c08\u53d1\u73b0\u719f\u6089\u7684\u6570\u5b57\u4e60\u60ef\u548c\u8c61\u5f81\u6027\u5185\u5bb9\u80fd\u589e\u5f3a\u4e92\u52a8\uff0c\u800c\u4e0d\u719f\u6089\u7684\u6280\u672f\u53ef\u80fd\u5f15\u53d1\u6050\u60e7\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u548c\u8c61\u5f81\u6027\u951a\u70b9\u5728\u8001\u5e74\u75f4\u5446\u75c7\u62a4\u7406\u4e2d\u5982\u4f55\u652f\u6301\u6280\u672f\u4f7f\u7528\uff0c\u5c24\u5176\u662f\u5728\u97e9\u56fd\u6587\u5316\u80cc\u666f\u4e0b\u3002", "method": "\u901a\u8fc7\u6df1\u5ea6\u8bbf\u8c0811\u4f4d\u793e\u533a\u5c45\u4f4f\u7684\u8ba4\u77e5\u8870\u9000\u8001\u5e74\u4eba\u7684\u4e13\u4e1a\u62a4\u7406\u4eba\u5458\uff0c\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\u5206\u6790\u6570\u636e\u3002", "result": "\u719f\u6089\u7684\u6570\u5b57\u4e60\u60ef\uff08\u5982\u62cd\u7167\uff09\u901a\u8fc7\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u6301\u7eed\u5b58\u5728\uff0c\u8c61\u5f81\u6027\u951a\u70b9\uff08\u5982\u5bb6\u5ead\u7167\u7247\uff09\u589e\u5f3a\u4e92\u52a8\uff1b\u4e0d\u719f\u6089\u7684\u6280\u672f\u53ef\u80fd\u5f15\u53d1\u6050\u60e7\u6216\u6297\u62d2\u3002", "conclusion": "\u8bbe\u8ba1\u7b26\u5408\u6587\u5316\u548c\u8ba4\u77e5\u9700\u6c42\u7684\u6280\u672f\u53ef\u63d0\u5347\u8001\u5e74\u75f4\u5446\u75c7\u60a3\u8005\u7684\u81ea\u4e3b\u6027\u548c\u5e78\u798f\u611f\uff0c\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u548c\u8c61\u5f81\u6027\u951a\u70b9\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.09599", "pdf": "https://arxiv.org/pdf/2507.09599", "abs": "https://arxiv.org/abs/2507.09599", "authors": ["Aydin Homay"], "title": "Complexity and Coupling: A Functional Domain Approach", "categories": ["cs.SE"], "comment": null, "summary": "This paper provides a precise and scientific definition of complexity and\ncoupling, grounded in the functional domain, particularly within industrial\ncontrol and automation systems (iCAS). We highlight the widespread ambiguity in\ndefining complexity and coupling, emphasizing that many existing definitions\nrooted in physical attributes lead to confusion and inconsistencies.\nFurthermore, we re-exhibit why coupled design inherently increases complexity\nand how potentially this complexity could be reduced. Drawing on examples from\nvarious disciplines, such as software engineering, industrial automation, and\nmechanical design, we demonstrate that complexity does not necessarily\ncorrelate with system size or the number of components, and coupling, unlike\ncommon belief in software engineering, actually does not occur in the physical\ndomain but in the functional domain. We conclude that effective design\nnecessitates addressing coupling and complexity within the functional domain.", "AI": {"tldr": "\u672c\u6587\u5bf9\u590d\u6742\u6027\u548c\u8026\u5408\u8fdb\u884c\u4e86\u7cbe\u786e\u79d1\u5b66\u5b9a\u4e49\uff0c\u5f3a\u8c03\u5176\u5728\u529f\u80fd\u57df\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u800c\u975e\u7269\u7406\u5c5e\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u5b66\u79d1\u4f8b\u5b50\u8bc1\u660e\u590d\u6742\u6027\u4e0d\u4f9d\u8d56\u7cfb\u7edf\u89c4\u6a21\uff0c\u8026\u5408\u4e5f\u53d1\u751f\u5728\u529f\u80fd\u57df\u3002\u6700\u7ec8\u6307\u51fa\u6709\u6548\u8bbe\u8ba1\u9700\u5728\u529f\u80fd\u57df\u4e2d\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u5bf9\u590d\u6742\u6027\u548c\u8026\u5408\u7684\u5b9a\u4e49\u6a21\u7cca\u4e14\u57fa\u4e8e\u7269\u7406\u5c5e\u6027\uff0c\u5bfc\u81f4\u6df7\u6dc6\u548c\u4e0d\u4e00\u81f4\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u57fa\u4e8e\u529f\u80fd\u57df\u7684\u79d1\u5b66\u5b9a\u4e49\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5de5\u4e1a\u63a7\u5236\u4e0e\u81ea\u52a8\u5316\u7cfb\u7edf(iCAS)\u53ca\u5176\u4ed6\u9886\u57df\uff08\u5982\u8f6f\u4ef6\u5de5\u7a0b\u3001\u673a\u68b0\u8bbe\u8ba1\uff09\u7684\u4f8b\u5b50\uff0c\u91cd\u65b0\u5b9a\u4e49\u590d\u6742\u6027\u548c\u8026\u5408\uff0c\u5e76\u63a2\u8ba8\u5176\u5173\u7cfb\u3002", "result": "\u590d\u6742\u6027\u4e0d\u4f9d\u8d56\u4e8e\u7cfb\u7edf\u89c4\u6a21\u6216\u7ec4\u4ef6\u6570\u91cf\uff0c\u8026\u5408\u53d1\u751f\u5728\u529f\u80fd\u57df\u800c\u975e\u7269\u7406\u57df\u3002", "conclusion": "\u6709\u6548\u8bbe\u8ba1\u5fc5\u987b\u5728\u529f\u80fd\u57df\u4e2d\u89e3\u51b3\u8026\u5408\u4e0e\u590d\u6742\u6027\u95ee\u9898\u3002"}}
{"id": "2507.09719", "pdf": "https://arxiv.org/pdf/2507.09719", "abs": "https://arxiv.org/abs/2507.09719", "authors": ["Jiaheng Xiong", "Qiaolun Zhang", "Yoann Pi\u00e9tri", "Raja Yehia", "Raouf Boutaba", "Francesco Musumeci", "Massimo Tornatore"], "title": "Power Consumption Analysis of QKD Networks under Different Protocols and Detector Configurations", "categories": ["quant-ph", "cs.NI"], "comment": null, "summary": "We analyze the power consumption of quantum key distribution (QKD) networks\nunder various protocol and detector configurations. Using realistic network\ntopologies, we evaluate discrete-variable vs continuous-variable QKD and\noptimize device placement, quantifying power trade-offs of SNSPD vs APD\ndetectors and the benefits of optical bypass.", "AI": {"tldr": "\u5206\u6790\u4e86\u4e0d\u540c\u534f\u8bae\u548c\u63a2\u6d4b\u5668\u914d\u7f6e\u4e0b\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7f51\u7edc\u7684\u529f\u8017\uff0c\u8bc4\u4f30\u79bb\u6563\u53d8\u91cf\u548c\u8fde\u7eed\u53d8\u91cfQKD\uff0c\u5e76\u4f18\u5316\u8bbe\u5907\u5e03\u5c40\u3002", "motivation": "\u63a2\u8ba8\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7f51\u7edc\u7684\u80fd\u8017\u95ee\u9898\uff0c\u4ee5\u4f18\u5316\u5176\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u73b0\u5b9e\u7f51\u7edc\u62d3\u6251\uff0c\u6bd4\u8f83\u79bb\u6563\u53d8\u91cf\u548c\u8fde\u7eed\u53d8\u91cfQKD\uff0c\u8bc4\u4f30SNSPD\u548cAPD\u63a2\u6d4b\u5668\u7684\u529f\u8017\u5dee\u5f02\u53ca\u5149\u5b66\u65c1\u8def\u7684\u4f18\u52bf\u3002", "result": "\u91cf\u5316\u4e86\u4e0d\u540c\u914d\u7f6e\u4e0b\u7684\u529f\u8017\u6298\u8877\uff0c\u5e76\u5c55\u793a\u4e86\u5149\u5b66\u65c1\u8def\u7684\u6548\u76ca\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4f18\u5316QKD\u7f51\u7edc\u7684\u80fd\u6e90\u6548\u7387\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.09579", "pdf": "https://arxiv.org/pdf/2507.09579", "abs": "https://arxiv.org/abs/2507.09579", "authors": ["Marc Bara"], "title": "PromptChain: A Decentralized Web3 Architecture for Managing AI Prompts as Digital Assets", "categories": ["cs.CR", "cs.DC", "68M14, 94A60", "H.3.4; K.6.5; H.3.5"], "comment": "14 pages, 6 figures", "summary": "We present PromptChain, a decentralized Web3 architecture that establishes AI\nprompts as first-class digital assets with verifiable ownership, version\ncontrol, and monetization capabilities. Current centralized platforms lack\nmechanisms for proper attribution, quality assurance, or fair compensation for\nprompt creators. PromptChain addresses these limitations through a novel\nintegration of IPFS for immutable storage, smart contracts for governance, and\ntoken incentives for community curation. Our design includes: (1) a\ncomprehensive metadata schema for cross-model compatibility, (2) a\nstake-weighted validation mechanism to align incentives, and (3) a token\neconomy that rewards contributors proportionally to their impact. The proposed\narchitecture demonstrates how decentralized systems could potentially match\ncentralized alternatives in efficiency while providing superior ownership\nguarantees and censorship resistance through blockchain-anchored provenance\ntracking. By decoupling prompts from specific AI models or outputs, this work\nestablishes the foundation for an open ecosystem of human-AI collaboration in\nthe Web3 era, representing the first systematic treatment of prompts as\nstandalone digital assets with dedicated decentralized infrastructure.", "AI": {"tldr": "PromptChain\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684Web3\u67b6\u6784\uff0c\u5c06AI\u63d0\u793a\u4f5c\u4e3a\u6570\u5b57\u8d44\u4ea7\uff0c\u5177\u6709\u53ef\u9a8c\u8bc1\u7684\u6240\u6709\u6743\u3001\u7248\u672c\u63a7\u5236\u548c\u53d8\u73b0\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u4e2d\u5fc3\u5316\u5e73\u53f0\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u4e2d\u5fc3\u5316\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u63d0\u793a\u521b\u4f5c\u8005\u7684\u5408\u7406\u5f52\u5c5e\u3001\u8d28\u91cf\u4fdd\u8bc1\u548c\u516c\u5e73\u8865\u507f\u673a\u5236\uff0cPromptChain\u65e8\u5728\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u6280\u672f\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5229\u7528IPFS\u8fdb\u884c\u4e0d\u53ef\u53d8\u5b58\u50a8\u3001\u667a\u80fd\u5408\u7ea6\u5b9e\u73b0\u6cbb\u7406\u3001\u4ee3\u5e01\u6fc0\u52b1\u673a\u5236\u8fdb\u884c\u793e\u533a\u7ba1\u7406\uff0c\u5305\u62ec\u8de8\u6a21\u578b\u517c\u5bb9\u7684\u5143\u6570\u636e\u6a21\u5f0f\u3001\u6743\u76ca\u52a0\u6743\u9a8c\u8bc1\u673a\u5236\u548c\u8d21\u732e\u8005\u6309\u6bd4\u4f8b\u5956\u52b1\u7684\u4ee3\u5e01\u7ecf\u6d4e\u3002", "result": "PromptChain\u8bc1\u660e\u4e86\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u5728\u6548\u7387\u4e0a\u53ef\u5ab2\u7f8e\u4e2d\u5fc3\u5316\u7cfb\u7edf\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u6240\u6709\u6743\u4fdd\u969c\u548c\u6297\u5ba1\u67e5\u80fd\u529b\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e3aWeb3\u65f6\u4ee3\u7684\u4eba\u673a\u534f\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5c06\u63d0\u793a\u89c6\u4e3a\u72ec\u7acb\u6570\u5b57\u8d44\u4ea7\u5e76\u63d0\u4f9b\u4e86\u4e13\u7528\u7684\u53bb\u4e2d\u5fc3\u5316\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2507.10240", "pdf": "https://arxiv.org/pdf/2507.10240", "abs": "https://arxiv.org/abs/2507.10240", "authors": ["Angelos Chatzimparmpas"], "title": "Visual Analytics for Explainable and Trustworthy Artificial Intelligence", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Our society increasingly depends on intelligent systems to solve complex\nproblems, ranging from recommender systems suggesting the next movie to watch\nto AI models assisting in medical diagnoses for hospitalized patients. With the\niterative improvement of diagnostic accuracy and efficiency, AI holds\nsignificant potential to mitigate medical misdiagnoses by preventing numerous\ndeaths and reducing an economic burden of approximately 450 EUR billion\nannually. However, a key obstacle to AI adoption lies in the lack of\ntransparency: many automated systems function as \"black boxes,\" providing\npredictions without revealing the underlying processes. This opacity can hinder\nexperts' ability to trust and rely on AI systems. Visual analytics (VA)\nprovides a compelling solution by combining AI models with interactive\nvisualizations. These specialized charts and graphs empower users to\nincorporate their domain expertise to refine and improve the models, bridging\nthe gap between AI and human understanding. In this work, we define,\ncategorize, and explore how VA solutions can foster trust across the stages of\na typical AI pipeline. We propose a design space for innovative visualizations\nand present an overview of our previously developed VA dashboards, which\nsupport critical tasks within the various pipeline stages, including data\nprocessing, feature engineering, hyperparameter tuning, understanding,\ndebugging, refining, and comparing models.", "AI": {"tldr": "AI\u7cfb\u7edf\u5728\u533b\u7597\u7b49\u9886\u57df\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u963b\u788d\u4e86\u5176\u91c7\u7528\u3002\u89c6\u89c9\u5206\u6790\uff08VA\uff09\u901a\u8fc7\u7ed3\u5408AI\u6a21\u578b\u4e0e\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u5e76\u6539\u8fdb\u6a21\u578b\uff0c\u589e\u5f3a\u4fe1\u4efb\u3002", "motivation": "AI\u7cfb\u7edf\u5982\u2018\u9ed1\u76d2\u2019\uff0c\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u5f71\u54cd\u4e13\u5bb6\u5bf9\u5176\u7684\u4fe1\u4efb\u548c\u4f7f\u7528\u3002", "method": "\u5229\u7528\u89c6\u89c9\u5206\u6790\uff08VA\uff09\u5c06AI\u6a21\u578b\u4e0e\u4ea4\u4e92\u53ef\u89c6\u5316\u7ed3\u5408\uff0c\u5b9a\u4e49\u5e76\u63a2\u7d22VA\u5982\u4f55\u63d0\u5347AI\u6d41\u7a0b\u5404\u9636\u6bb5\u7684\u4fe1\u4efb\u3002", "result": "\u63d0\u51fa\u53ef\u89c6\u5316\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u5f00\u53d1\u7528\u4e8eAI\u6d41\u7a0b\u5404\u5173\u952e\u4efb\u52a1\u7684VA\u4eea\u8868\u677f\u3002", "conclusion": "VA\u662f\u89e3\u51b3AI\u900f\u660e\u5ea6\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u589e\u5f3a\u7528\u6237\u5bf9AI\u6a21\u578b\u7684\u4fe1\u4efb\u548c\u7406\u89e3\u3002"}}
{"id": "2507.09637", "pdf": "https://arxiv.org/pdf/2507.09637", "abs": "https://arxiv.org/abs/2507.09637", "authors": ["Lo Gullstrand Heander", "Emma S\u00f6derberg", "Christofer Rydenf\u00e4lt"], "title": "Code Review as Decision-Making -- Building a Cognitive Model from the Questions Asked During Code Review", "categories": ["cs.SE", "cs.HC", "D.2.0; D.2.3; K.4.3"], "comment": "39 pages, 14 figures Submitted to Empirical Software Engineering,\n  Springer Nature", "summary": "Code review is a well-established and valued practice in the software\nengineering community contributing to both code quality and interpersonal\nbenefits. However, there are challenges in both tools and processes that give\nrise to misalignments and frustrations. Recent research seeks to address this\nby automating code review entirely, but we believe that this risks losing the\nmajority of the interpersonal benefits such as knowledge transfer and shared\nownership.\n  We believe that by better understanding the cognitive processes involved in\ncode review, it would be possible to improve tool support, with out without AI,\nand make code review both more efficient, more enjoyable, while increasing or\nmaintaining all of its benefits. In this paper, we conduct an ethnographic\nthink-aloud study involving 10 participants and 34 code reviews. We build a\ncognitive model of code review bottom up through thematic, statistical,\ntemporal, and sequential analysis of the transcribed material. Through the\ndata, the similarities between the cognitive process in code review and\ndecision-making processes, especially recognition-primed decision-making,\nbecome apparent.\n  The result is the Code Review as Decision-Making (CRDM) model that shows how\nthe developers move through two phases during the code review; first an\norientation phase to establish context and rationale and then an analytical\nphase to understand, assess, and plan the rest of the review. Throughout the\nprocess several decisions must be taken, on writing comments, finding more\ninformation, voting, running the code locally, verifying continuous integration\nresults, etc.\n  Analysis software and process-coded data publicly available at:\nhttps://doi.org/10.5281/zenodo.15758266", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCRDM\u7684\u6a21\u578b\uff0c\u5c06\u5176\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff0c\u65e8\u5728\u63d0\u5347\u5de5\u5177\u652f\u6301\uff0c\u540c\u65f6\u4fdd\u7559\u4eba\u9645\u4e92\u52a8\u7684\u76ca\u5904\u3002", "motivation": "\u76ee\u524d\u4ee3\u7801\u5ba1\u67e5\u7684\u81ea\u52a8\u5316\u5de5\u5177\u6709\u53ef\u80fd\u4e27\u5931\u77e5\u8bc6\u4f20\u9012\u548c\u5171\u4eab\u6240\u6709\u6743\u7b49\u4eba\u9645\u76ca\u5904\uff0c\u7814\u7a76\u5e0c\u671b\u901a\u8fc7\u7406\u89e3\u8ba4\u77e5\u8fc7\u7a0b\u6765\u4f18\u5316\u5de5\u5177\u652f\u6301\u3002", "method": "\u901a\u8fc7\u6c11\u65cf\u5fd7\u7684\"\u8bf4\u51fa\u601d\u8003\"\u7814\u7a76\uff0c\u5bf910\u540d\u53c2\u4e0e\u8005\u768434\u6b21\u4ee3\u7801\u5ba1\u67e5\u8fdb\u884c\u5206\u6790\uff0c\u6784\u5efa\u4e86\u8ba4\u77e5\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86CRDM\u6a21\u578b\uff0c\u63cf\u8ff0\u4e86\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u4ece\u2018\u5b9a\u4f4d\u2019\u5230\u2018\u5206\u6790\u2019\u7684\u4e24\u9636\u6bb5\u8ba4\u77e5\u8fc7\u7a0b\u3002", "conclusion": "\u901a\u8fc7\u7406\u89e3\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u66f4\u597d\u7684\u5de5\u5177\u4ee5\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u7684\u6548\u7387\u548c\u4f53\u9a8c\uff0c\u540c\u65f6\u4fdd\u7559\u5176\u4eba\u9645\u76ca\u5904\u3002"}}
{"id": "2507.09859", "pdf": "https://arxiv.org/pdf/2507.09859", "abs": "https://arxiv.org/abs/2507.09859", "authors": ["Guntur Dharma Putra", "Bagus Rakadyanto Oktavianto Putra"], "title": "Endorsement-Driven Blockchain SSI Framework for Dynamic IoT Ecosystems", "categories": ["cs.CR", "cs.NI"], "comment": "5 pages, 4 figures. Accepted to IEEE ICBC 2025 as a short paper", "summary": "Self-Sovereign Identity (SSI) offers significant potential for managing\nidentities in the Internet of Things (IoT), enabling decentralized\nauthentication and credential management without reliance on centralized\nentities. However, existing SSI frameworks often limit credential issuance and\nrevocation to trusted entities, such as IoT manufacturers, which restricts\nflexibility in dynamic IoT ecosystems. In this paper, we propose a\nblockchain-based SSI framework that allows any individual with a verifiable\ntrust linkage to act as a credential issuer, ensuring decentralized and\nscalable identity management. Our framework incorporates a layered\narchitecture, where trust is dynamically established through endorsement-based\ncalculations and maintained via a hierarchical chain-of-trust mechanism.\nBlockchain serves as the Verifiable Data Registry, ensuring transparency and\nimmutability of identity operations, while smart contracts automate critical\nprocesses such as credential issuance, verification, and revocation. A\nproof-of-concept implementation demonstrates that the proposed framework is\nfeasible and incurs minimal overheads compared to the baseline, making it\nwell-suited for dynamic and resource-constrained IoT environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u81ea\u4e3b\u6743\u8eab\u4efd\u6846\u67b6\uff0c\u652f\u6301\u4efb\u4f55\u6709\u53ef\u4fe1\u94fe\u7684\u4e2a\u4eba\u4f5c\u4e3a\u51ed\u8bc1\u9881\u53d1\u8005\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u7269\u8054\u7f51\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u6743\u8eab\u4efd\u6846\u67b6\u901a\u5e38\u9650\u5236\u51ed\u8bc1\u9881\u53d1\u548c\u64a4\u9500\u7ed9\u53ef\u4fe1\u5b9e\u4f53\uff0c\u9650\u5236\u52a8\u6001\u7269\u8054\u7f51\u751f\u6001\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u3002", "method": "\u91c7\u7528\u533a\u5757\u94fe\u4f5c\u4e3a\u53ef\u9a8c\u8bc1\u6570\u636e\u6ce8\u518c\u8868\uff0c\u7ed3\u5408\u5206\u5c42\u67b6\u6784\u548c\u667a\u80fd\u5408\u7ea6\u81ea\u52a8\u5316\u5173\u952e\u6d41\u7a0b\u3002", "result": "\u6982\u5ff5\u9a8c\u8bc1\u663e\u793a\u8be5\u6846\u67b6\u53ef\u884c\u4e14\u6027\u80fd\u5f00\u9500\u4f4e\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u73af\u5883\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u53bb\u4e2d\u5fc3\u5316\u4e14\u53ef\u6269\u5c55\u7684\u8eab\u4efd\u7ba1\u7406\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u7269\u8054\u7f51\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2507.10427", "pdf": "https://arxiv.org/pdf/2507.10427", "abs": "https://arxiv.org/abs/2507.10427", "authors": ["Jing Li", "Felix Schijve", "Sheng Li", "Yuye Yang", "Jun Hu", "Emilia Barakova"], "title": "Towards Emotion Co-regulation with LLM-powered Socially Assistive Robots: Integrating LLM Prompts and Robotic Behaviors to Support Parent-Neurodivergent Child Dyads", "categories": ["cs.HC", "cs.RO"], "comment": "Submission for the IROS 2025 conference", "summary": "Socially Assistive Robotics (SAR) has shown promise in supporting emotion\nregulation for neurodivergent children. Recently, there has been increasing\ninterest in leveraging advanced technologies to assist parents in co-regulating\nemotions with their children. However, limited research has explored the\nintegration of large language models (LLMs) with SAR to facilitate emotion\nco-regulation between parents and children with neurodevelopmental disorders.\nTo address this gap, we developed an LLM-powered social robot by deploying a\nspeech communication module on the MiRo-E robotic platform. This supervised\nautonomous system integrates LLM prompts and robotic behaviors to deliver\ntailored interventions for both parents and neurodivergent children. Pilot\ntests were conducted with two parent-child dyads, followed by a qualitative\nanalysis. The findings reveal MiRo-E's positive impacts on interaction dynamics\nand its potential to facilitate emotion regulation, along with identified\ndesign and technical challenges. Based on these insights, we provide design\nimplications to advance the future development of LLM-powered SAR for mental\nhealth applications.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u793e\u4ea4\u8f85\u52a9\u673a\u5668\u4eba\uff08SAR\uff09\u7ed3\u5408\uff0c\u5e2e\u52a9\u795e\u7ecf\u53d1\u80b2\u969c\u788d\u513f\u7ae5\u53ca\u5176\u5bb6\u957f\u5171\u540c\u8c03\u8282\u60c5\u7eea\uff0c\u5e76\u5c55\u793a\u4e86\u521d\u6b65\u5b9e\u9a8c\u7684\u79ef\u6781\u6548\u679c\u548c\u8bbe\u8ba1\u6311\u6218\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u5173\u4e8e\u5982\u4f55\u5c06LLM\u4e0eSAR\u7ed3\u5408\u4ee5\u652f\u6301\u795e\u7ecf\u53d1\u80b2\u969c\u788d\u513f\u7ae5\u53ca\u5176\u5bb6\u957f\u5171\u540c\u8c03\u8282\u60c5\u7eea\u7684\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5728MiRo-E\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u90e8\u7f72\u8bed\u97f3\u901a\u4fe1\u6a21\u5757\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u793e\u4ea4\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u4eb2\u5b50\u5bf9\u7684\u8bd5\u70b9\u6d4b\u8bd5\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\uff0cMiRo-E\u5bf9\u4e92\u52a8\u52a8\u6001\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u5e76\u53ef\u80fd\u4fc3\u8fdb\u60c5\u7eea\u8c03\u8282\uff0c\u4f46\u4e5f\u53d1\u73b0\u4e86\u8bbe\u8ba1\u548c\u6280\u672f\u4e0a\u7684\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u5f00\u53d1LLM\u9a71\u52a8\u7684SAR\u5728\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u542f\u793a\u3002"}}
{"id": "2507.09665", "pdf": "https://arxiv.org/pdf/2507.09665", "abs": "https://arxiv.org/abs/2507.09665", "authors": ["Saima Afrin", "Bowen Xu", "Antonio Mastropaolo"], "title": "Is Quantization a Deal-breaker? Empirical Insights from Large Code Models", "categories": ["cs.SE"], "comment": null, "summary": "The growing scale of large language models (LLMs) not only demands extensive\ncomputational resources but also raises environmental concerns due to their\nincreasing carbon footprint. Model quantization emerges as an effective\napproach that can reduce the resource demands of LLMs by decreasing parameter\nprecision without substantially affecting performance (e.g., 16 bit to 4 bit).\nWhile recent studies have established quantization as a promising approach for\noptimizing large code models (LCMs), a specialized subset of LLMs tailored for\nautomated software engineering, their findings offer only limited insights into\nits practical implications. Specifically, current investigations focus only on\nthe functional correctness of the code generated by quantized models,\nneglecting how quantization impacts critical aspects of code quality such as\nreliability, maintainability, and security. To bridge this gap, our study\ninvestigates the effects of quantization on the qualitative aspects of\nautomatically generated code. We apply Activation-aware Weight Quantization\n(AWQ) to two widely used code models, CodeLlama and DeepSeekCoder, to generate\nJava and Python code. Using state-of-the-art static analysis tools, we evaluate\nsoftware quality metrics and static features including cyclomatic complexity,\ncognitive complexity, and lines of code. Our findings reveal that quantization\nis a robust technique that not only preserves functional correctness, but also\nretains key qualitative code attributes sought after by developers, such as\nmaintainability and structural simplicity.", "AI": {"tldr": "\u91cf\u5316\u6280\u672f\u80fd\u6709\u6548\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d44\u6e90\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u8d28\u91cf\u5c5e\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u5bf9\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u5f71\u54cd\u7684\u7814\u7a76\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u5e94\u7528AWQ\u91cf\u5316\u6280\u672f\u5bf9CodeLlama\u548cDeepSeekCoder\u6a21\u578b\u8fdb\u884c\u91cf\u5316\uff0c\u751f\u6210Java\u548cPython\u4ee3\u7801\uff0c\u5e76\u4f7f\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\u8bc4\u4f30\u4ee3\u7801\u8d28\u91cf\u3002", "result": "\u91cf\u5316\u4e0d\u4ec5\u4fdd\u6301\u529f\u80fd\u6b63\u786e\u6027\uff0c\u8fd8\u4fdd\u7559\u4e86\u4ee3\u7801\u7684\u53ef\u7ef4\u62a4\u6027\u548c\u7ed3\u6784\u7b80\u6d01\u6027\u7b49\u5173\u952e\u8d28\u91cf\u5c5e\u6027\u3002", "conclusion": "\u91cf\u5316\u662f\u4e00\u79cd\u7a33\u5065\u7684\u6280\u672f\uff0c\u9002\u7528\u4e8e\u4f18\u5316\u5927\u4ee3\u7801\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u8d28\u91cf\u3002"}}
{"id": "2507.10160", "pdf": "https://arxiv.org/pdf/2507.10160", "abs": "https://arxiv.org/abs/2507.10160", "authors": ["Manuel R\u00f6der", "Christoph Raab", "Frank-Michael Schleif"], "title": "Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": "Extension of http://dx.doi.org/10.5220/0012351900003654", "summary": "Federated Learning has emerged as a leading paradigm for decentralized,\nprivacy-preserving learning, particularly relevant in the era of interconnected\nedge devices equipped with sensors. However, the practical implementation of\nFederated Learning faces three primary challenges: the need for human\ninvolvement in costly data labelling processes for target adaptation, covariate\nshift in client device data collection due to environmental factors affecting\nsensors, leading to discrepancies between source and target samples, and the\nimpracticality of continuous or regular model updates in resource-constrained\nenvironments due to limited data transmission capabilities and technical\nconstraints on channel availability and energy efficiency. To tackle these\nissues, we expand upon an efficient and scalable Federated Learning framework\ntailored for real-world client adaptation in industrial settings. This\nframework leverages a pre-trained source model comprising a deep backbone, an\nadaptation module, and a classifier running on a powerful server. By freezing\nthe backbone and classifier during client adaptation on resource-constrained\ndevices, we allow the domain adaptive linear layer to handle target domain\nadaptation, thus minimizing overall computational overhead. Furthermore, this\nsetup, designated as FedAcross+, is extended to encompass the processing of\nstreaming data, thereby rendering the solution suitable for non-stationary\nenvironments. Extensive experimental results demonstrate the effectiveness of\nFedAcross+ in achieving competitive adaptation on low-end client devices with\nlimited target samples, successfully addressing the challenge of domain shift.\nMoreover, our framework accommodates sporadic model updates within\nresource-constrained environments, ensuring practical and seamless deployment.", "AI": {"tldr": "\u8054\u90a6\u5b66\u4e60\u5728\u9690\u79c1\u4fdd\u62a4\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9762\u4e34\u6807\u7b7e\u6210\u672c\u9ad8\u3001\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\u548c\u6a21\u578b\u66f4\u65b0\u53d7\u9650\u7b49\u95ee\u9898\u3002\u63d0\u51fa\u7684FedAcross+\u6846\u67b6\u901a\u8fc7\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u81ea\u9002\u5e94\u5c42\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e9b\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u9ad8\u6807\u7b7e\u6210\u672c\u3001\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\u548c\u8d44\u6e90\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5305\u62ec\u6df1\u5ea6\u4e3b\u5e72\u3001\u81ea\u9002\u5e94\u6a21\u5757\u548c\u5206\u7c7b\u5668\uff09\uff0c\u5728\u5ba2\u6237\u7aef\u8bbe\u5907\u4e0a\u51bb\u7ed3\u4e3b\u5e72\u548c\u5206\u7c7b\u5668\uff0c\u4ec5\u901a\u8fc7\u81ea\u9002\u5e94\u5c42\u8fdb\u884c\u76ee\u6807\u57df\u9002\u5e94\u3002", "result": "FedAcross+\u5728\u4f4e\u7aef\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u9002\u5e94\u6548\u679c\uff0c\u5e76\u80fd\u5904\u7406\u6d41\u6570\u636e\u548c\u975e\u5e73\u7a33\u73af\u5883\u3002", "conclusion": "FedAcross+\u662f\u4e00\u4e2a\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u9645\u5de5\u4e1a\u573a\u666f\u3002"}}
{"id": "2507.10267", "pdf": "https://arxiv.org/pdf/2507.10267", "abs": "https://arxiv.org/abs/2507.10267", "authors": ["Novruz Amirov", "Baran Isik", "Bilal Ihsan Tuncer", "Serif Bahtiyar"], "title": "DNS Tunneling: Threat Landscape and Improved Detection Solutions", "categories": ["cs.CR", "cs.LG", "cs.NI"], "comment": null, "summary": "Detecting Domain Name System (DNS) tunneling is a significant challenge in\nsecurity due to its capacity to hide harmful actions within DNS traffic that\nappears to be normal and legitimate. Traditional detection methods are based on\nrule-based approaches or signature matching methods that are often insufficient\nto accurately identify such covert communication channels. This research is\nabout effectively detecting DNS tunneling. We propose a novel approach to\ndetect DNS tunneling with machine learning algorithms. We combine machine\nlearning algorithms to analyze the traffic by using features extracted from DNS\ntraffic. Analyses results show that the proposed approach is a good candidate\nto detect DNS tunneling accurately.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4bDNS\u96a7\u9053\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u89c4\u5219\u548c\u7b7e\u540d\u5339\u914d\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u7684DNS\u96a7\u9053\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u89c4\u5219\u6216\u7b7e\u540d\u5339\u914d\uff09\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u8bc6\u522b\u9690\u853d\u901a\u4fe1\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6DNS\u6d41\u91cf\u7279\u5f81\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4bDNS\u96a7\u9053\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4bDNS\u96a7\u9053\u65b9\u9762\u5177\u6709\u826f\u597d\u6f5c\u529b\u3002"}}
{"id": "2507.10325", "pdf": "https://arxiv.org/pdf/2507.10325", "abs": "https://arxiv.org/abs/2507.10325", "authors": ["Herlock", "Rahimi", "Dionysis Kalogerias"], "title": "Convergence of Agnostic Federated Averaging", "categories": ["cs.LG", "cs.DC", "eess.SP"], "comment": "5 pages, 2 figurres, CAMSAP conference", "summary": "Federated learning (FL) enables decentralized model training without\ncentralizing raw data. However, practical FL deployments often face a key\nrealistic challenge: Clients participate intermittently in server aggregation\nand with unknown, possibly biased participation probabilities. Most existing\nconvergence results either assume full-device participation, or rely on\nknowledge of (in fact uniform) client availability distributions -- assumptions\nthat rarely hold in practice. In this work, we characterize the optimization\nproblem that consistently adheres to the stochastic dynamics of the well-known\n\\emph{agnostic Federated Averaging (FedAvg)} algorithm under random (and\nvariably-sized) client availability, and rigorously establish its convergence\nfor convex, possibly nonsmooth losses, achieving a standard rate of order\n$\\mathcal{O}(1/\\sqrt{T})$, where $T$ denotes the aggregation horizon. Our\nanalysis provides the first convergence guarantees for agnostic FedAvg under\ngeneral, non-uniform, stochastic client participation, without knowledge of the\nparticipation distribution. We also empirically demonstrate that agnostic\nFedAvg in fact outperforms common (and suboptimal) weighted aggregation FedAvg\nvariants, even with server-side knowledge of participation weights.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u968f\u673a\u53c2\u4e0e\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u5e94\u968f\u673a\u5ba2\u6237\u53c2\u4e0e\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u53c2\u4e0e\u968f\u673a\u6027\u5bfc\u81f4\u7684\u4f18\u5316\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5168\u8bbe\u5907\u53c2\u4e0e\u6216\u5df2\u77e5\u5206\u5e03\uff0c\u4f46\u5728\u5b9e\u9645\u4e2d\u96be\u4ee5\u6210\u7acb\u3002", "method": "\u901a\u8fc7\u5206\u6790\u968f\u673a\u5ba2\u6237\u53c2\u4e0e\u7684\u52a8\u6001\uff0c\u63d0\u51fa\u4e86\u9002\u5e94\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u7684\u8054\u90a6\u5e73\u5747\uff08FedAvg\uff09\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u5728\u51f8\u4e14\u53ef\u80fd\u975e\u5e73\u6ed1\u635f\u5931\u4e0b\uff0c\u7b97\u6cd5\u7684\u6536\u655b\u901f\u5ea6\u4e3a$$\\mathcal{O}(1/$sqrt{T})\uff0c\u5e76\u5b9e\u8bc1\u8868\u660e\u5176\u4f18\u4e8e\u5df2\u77e5\u6743\u91cd\u7684\u52a0\u6743\u805a\u5408\u53d8\u4f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u968f\u673a\u5ba2\u6237\u53c2\u4e0e\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u969c\uff0c\u4e14\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2507.10479", "pdf": "https://arxiv.org/pdf/2507.10479", "abs": "https://arxiv.org/abs/2507.10479", "authors": ["Max R\u00e4dler", "Mark Colley", "Enrico Rukzio"], "title": "VIP-Sim: A User-Centered Approach to Vision Impairment Simulation for Accessible Design", "categories": ["cs.HC"], "comment": "Conditionally accepted at UIST'25", "summary": "People with vision impairments (VIPs) often rely on their remaining vision\nwhen interacting with user interfaces. Simulating visual impairments is an\neffective tool for designers, fostering awareness of the challenges faced by\nVIPs. While previous research has introduced various vision impairment\nsimulators, none have yet been developed with the direct involvement of VIPs or\nthoroughly evaluated from their perspective. To address this gap, we developed\nVIP-Sim. This symptom-based vision simulator was created through a\nparticipatory design process tailored explicitly for this purpose, involving\nN=7 VIPs. 21 symptoms, like field loss or light sensitivity, can be overlaid on\ndesktop design tools. Most participants felt VIP-Sim could replicate their\nsymptoms. VIP-Sim was received positively, but concerns about exclusion in\ndesign and comprehensiveness of the simulation remain, mainly whether it\nrepresents the experiences of other VIPs.", "AI": {"tldr": "VIP-Sim\u662f\u4e00\u6b3e\u57fa\u4e8e\u75c7\u72b6\u7684\u89c6\u89c9\u969c\u788d\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u4e0e7\u540d\u89c6\u89c9\u969c\u788d\u8005\uff08VIPs\uff09\u5408\u4f5c\u5f00\u53d1\uff0c\u65e8\u5728\u5e2e\u52a9\u8bbe\u8ba1\u5e08\u66f4\u597d\u5730\u7406\u89e3\u89c6\u89c9\u969c\u788d\u8005\u7684\u9700\u6c42\u3002\u5c3d\u7ba1\u591a\u6570\u53c2\u4e0e\u8005\u8ba4\u4e3aVIP-Sim\u80fd\u6709\u6548\u6a21\u62df\u4ed6\u4eec\u7684\u75c7\u72b6\uff0c\u4f46\u4ecd\u5b58\u5728\u5bf9\u8bbe\u8ba1\u4e2d\u7684\u5305\u5bb9\u6027\u548c\u6a21\u62df\u5168\u9762\u6027\u7684\u62c5\u5fe7\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u969c\u788d\u6a21\u62df\u5668\u7f3a\u4e4f\u89c6\u89c9\u969c\u788d\u8005\u7684\u76f4\u63a5\u53c2\u4e0e\u548c\u8bc4\u4f30\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u6b3e\u66f4\u8d34\u8fd1\u771f\u5b9e\u4f53\u9a8c\u7684\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u8fc7\u7a0b\u5f00\u53d1VIP-Sim\uff0c\u6db5\u76d621\u79cd\u89c6\u89c9\u75c7\u72b6\uff08\u5982\u89c6\u91ce\u7f3a\u5931\u6216\u5149\u654f\u611f\uff09\uff0c\u53ef\u96c6\u6210\u5230\u684c\u9762\u8bbe\u8ba1\u5de5\u5177\u4e2d\u3002", "result": "\u591a\u6570\u53c2\u4e0e\u8005\u8ba4\u4e3aVIP-Sim\u80fd\u6709\u6548\u6a21\u62df\u5176\u75c7\u72b6\uff0c\u5de5\u5177\u53d7\u5230\u79ef\u6781\u8bc4\u4ef7\uff0c\u4f46\u4ecd\u5b58\u5728\u5bf9\u5305\u5bb9\u6027\u548c\u5168\u9762\u6027\u7684\u8d28\u7591\u3002", "conclusion": "VIP-Sim\u5728\u6a21\u62df\u89c6\u89c9\u969c\u788d\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u6269\u5c55\u4ee5\u66f4\u5168\u9762\u5730\u4ee3\u8868\u5404\u7c7b\u89c6\u89c9\u969c\u788d\u8005\u7684\u4f53\u9a8c\u3002"}}
{"id": "2408.10887", "pdf": "https://arxiv.org/pdf/2408.10887", "abs": "https://arxiv.org/abs/2408.10887", "authors": ["Cesar Alan Contreras", "Alireza Rastegarpanah", "Rustam Stolkin", "Manolis Chiou"], "title": "A Mini-Review on Mobile Manipulators with Variable Autonomy", "categories": ["cs.RO", "cs.HC"], "comment": "Presented at Variable Autonomy for Human-Robot Teaming (VAT) at IEEE\n  RO-MAN 2024 Workshop", "summary": "This paper presents a mini-review of the current state of research in mobile\nmanipulators with variable levels of autonomy, emphasizing their associated\nchallenges and application environments. The need for mobile manipulators in\ndifferent environments is evident due to the unique challenges and risks each\npresents. Many systems deployed in these environments are not fully autonomous,\nrequiring human-robot teaming to ensure safe and reliable operations under\nuncertainties. Through this analysis, we identify gaps and challenges in the\nliterature on Variable Autonomy, including cognitive workload and communication\ndelays, and propose future directions, including whole-body Variable Autonomy\nfor mobile manipulators, virtual reality frameworks, and large language models\nto reduce operators' complexity and cognitive load in some challenging and\nuncertain scenarios.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u79fb\u52a8\u673a\u68b0\u81c2\u7684\u53ef\u53d8\u81ea\u4e3b\u6027\u7814\u7a76\u73b0\u72b6\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u76f8\u5173\u6311\u6218\u548c\u5e94\u7528\u73af\u5883\u3002\u5206\u6790\u4e86\u4eba\u673a\u534f\u4f5c\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u79fb\u52a8\u673a\u68b0\u81c2\u5728\u4e0d\u540c\u73af\u5883\u4e2d\u7684\u9700\u6c42\u53ca\u5176\u9762\u4e34\u7684\u72ec\u7279\u6311\u6218\u548c\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u6587\u732e\u5206\u6790\uff0c\u603b\u7ed3\u4e86\u53ef\u53d8\u81ea\u4e3b\u6027\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u5e76\u6307\u51fa\u8ba4\u77e5\u8d1f\u8377\u548c\u901a\u4fe1\u5ef6\u8fdf\u7b49\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u672a\u6765\u53d1\u5c55\u65b9\u5411\uff0c\u5305\u62ec\u5168\u8eab\u53ef\u53d8\u81ea\u4e3b\u6027\u3001\u865a\u62df\u73b0\u5b9e\u6846\u67b6\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u51cf\u5c11\u64cd\u4f5c\u5458\u590d\u6742\u5ea6\u548c\u8ba4\u77e5\u8d1f\u8377\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u786e\u5b9a\u73af\u5883\u548c\u6311\u6218\u3002"}}
{"id": "2507.09820", "pdf": "https://arxiv.org/pdf/2507.09820", "abs": "https://arxiv.org/abs/2507.09820", "authors": ["Jia Yi Goh", "Shaun Khoo", "Nyx Iskandar", "Gabriel Chua", "Leanne Tan", "Jessica Foo"], "title": "Measuring What Matters: A Framework for Evaluating Safety Risks in Real-World LLM Applications", "categories": ["cs.SE", "cs.CY"], "comment": null, "summary": "Most safety testing efforts for large language models (LLMs) today focus on\nevaluating foundation models. However, there is a growing need to evaluate\nsafety at the application level, as components such as system prompts,\nretrieval pipelines, and guardrails introduce additional factors that\nsignificantly influence the overall safety of LLM applications. In this paper,\nwe introduce a practical framework for evaluating application-level safety in\nLLM systems, validated through real-world deployment across multiple use cases\nwithin our organization. The framework consists of two parts: (1) principles\nfor developing customized safety risk taxonomies, and (2) practices for\nevaluating safety risks in LLM applications. We illustrate how the proposed\nframework was applied in our internal pilot, providing a reference point for\norganizations seeking to scale their safety testing efforts. This work aims to\nbridge the gap between theoretical concepts in AI safety and the operational\nrealities of safeguarding LLM applications in practice, offering actionable\nguidance for safe and scalable deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e94\u7528\u7ea7\u5b89\u5168\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u5305\u542b\u5b9a\u5236\u5316\u5b89\u5168\u98ce\u9669\u5206\u7c7b\u539f\u5219\u548c\u8bc4\u4f30\u5b9e\u8df5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u5b89\u5168\u6d4b\u8bd5\u591a\u96c6\u4e2d\u4e8e\u57fa\u7840\u6a21\u578b\uff0c\u4f46\u5e94\u7528\u7ea7\u7ec4\u4ef6\uff08\u5982\u7cfb\u7edf\u63d0\u793a\u3001\u68c0\u7d22\u7ba1\u9053\u548c\u9632\u62a4\u63aa\u65bd\uff09\u5bf9LLM\u5e94\u7528\u7684\u6574\u4f53\u5b89\u5168\u6027\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4e9f\u9700\u8bc4\u4f30\u3002", "method": "\u6846\u67b6\u5305\u62ec\u4e24\u90e8\u5206\uff1a\u5f00\u53d1\u5b9a\u5236\u5316\u5b89\u5168\u98ce\u9669\u5206\u7c7b\u7684\u539f\u5219\uff0c\u4ee5\u53ca\u8bc4\u4f30LLM\u5e94\u7528\u5b89\u5168\u98ce\u9669\u7684\u5b9e\u8df5\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u7ec4\u7ec7\u5185\u591a\u4e2a\u5b9e\u9645\u7528\u4f8b\u7684\u90e8\u7f72\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u89c4\u6a21\u5316\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u5f25\u5408AI\u5b89\u5168\u7406\u8bba\u4e0e\u5b9e\u9645LLM\u5e94\u7528\u4fdd\u62a4\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5b89\u5168\u90e8\u7f72\u6307\u5357\u3002"}}
{"id": "2507.08978", "pdf": "https://arxiv.org/pdf/2507.08978", "abs": "https://arxiv.org/abs/2507.08978", "authors": ["Katherine Limes", "Nathan Malkin", "Kelsey R. Fulton"], "title": "Characterizing Security and Privacy Teaching Standards for Schools in the United States", "categories": ["cs.CR", "cs.HC"], "comment": null, "summary": "Increasingly, students begin learning aspects of security and privacy during\ntheir primary and secondary education (grades K-12 in the United States).\nIndividual U.S. states and some national organizations publish teaching\nstandards -- guidance that outlines expectations for what students should learn\n-- which often form the basis for course curricula. However, research has not\nyet examined what is covered by these standards and whether the topics align\nwith what the broader security and privacy community thinks students should\nknow. To shed light on these questions, we started by collecting computer\nscience teaching standards from all U.S. states and eight national\norganizations. After manually examining a total of 11,954 standards, we labeled\n3,778 of them as being related to security and privacy, further classifying\nthese into 103 topics. Topics ranged from technical subjects like encryption,\nnetwork security, and embedded systems to social subjects such as laws, ethics,\nand appropriate online behavior. Subsequently, we interviewed 11 security and\nprivacy professionals to examine how the teaching standards align with their\nexpectations. We found that, while the specific topics they mentioned mostly\noverlapped with those of existing standards, professionals placed a greater\nemphasis on threat modeling and security mindset.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u7f8e\u56fdK-12\u6559\u80b2\u4e2d\u5b89\u5168\u548c\u9690\u79c1\u8bfe\u7a0b\u6807\u51c6\u7684\u8986\u76d6\u8303\u56f4\uff0c\u53d1\u73b0\u73b0\u6709\u6807\u51c6\u4e0e\u4e13\u4e1a\u4eba\u58eb\u7684\u671f\u671b\u57fa\u672c\u4e00\u81f4\uff0c\u4f46\u4e13\u4e1a\u4eba\u58eb\u66f4\u5f3a\u8c03\u5a01\u80c1\u5efa\u6a21\u548c\u5b89\u5168\u601d\u7ef4\u3002", "motivation": "\u63a2\u8ba8K-12\u6559\u80b2\u4e2d\u5b89\u5168\u548c\u9690\u79c1\u8bfe\u7a0b\u6807\u51c6\u7684\u8986\u76d6\u60c5\u51b5\uff0c\u4ee5\u53ca\u4e0e\u4e13\u4e1a\u4eba\u58eb\u671f\u671b\u7684\u5339\u914d\u7a0b\u5ea6\u3002", "method": "\u6536\u96c6\u5e76\u4eba\u5de5\u5206\u6790\u7f8e\u56fd\u5404\u5dde\u53ca\u56fd\u5bb6\u7ec4\u7ec7\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u6807\u51c6\uff0c\u5206\u7c7b\u540e\u4e0e11\u4f4d\u4e13\u4e1a\u4eba\u58eb\u7684\u8bbf\u8c08\u7ed3\u679c\u5bf9\u6bd4\u3002", "result": "\u6807\u51c6\u548c\u4e13\u4e1a\u4eba\u58eb\u7684\u671f\u671b\u5728\u4e3b\u9898\u4e0a\u5927\u90e8\u5206\u91cd\u53e0\uff0c\u4f46\u540e\u8005\u66f4\u91cd\u89c6\u5a01\u80c1\u5efa\u6a21\u548c\u5b89\u5168\u601d\u7ef4\u3002", "conclusion": "\u73b0\u6709\u6559\u80b2\u6807\u51c6\u9700\u8fdb\u4e00\u6b65\u5f3a\u5316\u5a01\u80c1\u5efa\u6a21\u548c\u5b89\u5168\u601d\u7ef4\u7684\u57f9\u517b\u3002"}}
{"id": "2507.09866", "pdf": "https://arxiv.org/pdf/2507.09866", "abs": "https://arxiv.org/abs/2507.09866", "authors": ["Wei Zhang", "Jian Yang", "Jiaxi Yang", "Ya Wang", "Zhoujun Li", "Zeyu Cui", "Binyuan Hui", "Junyang Lin"], "title": "Turning the Tide: Repository-based Code Reflection", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code large language models (LLMs) enhance programming by understanding and\ngenerating code across languages, offering intelligent feedback, bug detection,\nand code updates through reflection, improving development efficiency and\naccessibility. While benchmarks (e.g. HumanEval/LiveCodeBench) evaluate code\ngeneration and real-world relevance, previous works ignore the scenario of\nmodifying code in repositories. Considering challenges remaining in improving\nreflection capabilities and avoiding data contamination in dynamic benchmarks,\nwe introduce LiveRepoReflection, a challenging benchmark for evaluating code\nunderstanding and generation in multi-file repository contexts, featuring 1,888\nrigorously filtered test cases across $6$ programming languages to ensure\ndiversity, correctness, and high difficulty. Further, we create\nRepoReflection-Instruct, a large-scale, quality-filtered instruction-tuning\ndataset derived from diverse sources, used to train RepoReflectionCoder through\na two-turn dialogue process involving code generation and error-driven repair.\nThe leaderboard evaluates over 40 LLMs to reflect the model performance of\nrepository-based code reflection.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86LiveRepoReflection\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u6587\u4ef6\u4ed3\u5e93\u573a\u666f\u4e0b\u4ee3\u7801\u7406\u89e3\u548c\u751f\u6210\u7684\u6311\u6218\u6027\u57fa\u51c6\uff0c\u4ee5\u53caRepoReflection-Instruct\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3RepoReflectionCoder\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u548c\u7406\u89e3\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4ed3\u5e93\u4ee3\u7801\u4fee\u6539\u573a\u666f\u7684\u8bc4\u4f30\uff0c\u4e14\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u53cd\u601d\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faLiveRepoReflection\u57fa\u51c6\uff0c\u5305\u542b1,888\u4e2a\u6d4b\u8bd5\u6848\u4f8b\uff0c\u8986\u76d66\u79cd\u7f16\u7a0b\u8bed\u8a00\uff1b\u6784\u5efaRepoReflection-Instruct\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e24\u8f6e\u5bf9\u8bdd\u8bad\u7ec3RepoReflectionCoder\u6a21\u578b\u3002", "result": "\u751f\u6210\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u57fa\u51c6\u548c\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e8640\u591a\u4e2aLLM\u5728\u4ed3\u5e93\u4ee3\u7801\u53cd\u601d\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "LiveRepoReflection\u586b\u8865\u4e86\u4ed3\u5e93\u4ee3\u7801\u4fee\u6539\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u6587\u4ef6\u73af\u5883\u4e2d\u7684\u4ee3\u7801\u53cd\u601d\u80fd\u529b\u3002"}}
{"id": "2507.09089", "pdf": "https://arxiv.org/pdf/2507.09089", "abs": "https://arxiv.org/abs/2507.09089", "authors": ["Joel Becker", "Nate Rush", "Elizabeth Barnes", "David Rein"], "title": "Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity", "categories": ["cs.AI", "cs.HC", "cs.SE", "I.2"], "comment": "50 pages, 8 tables, 22 figures", "summary": "Despite widespread adoption, the impact of AI tools on software development\nin the wild remains understudied. We conduct a randomized controlled trial\n(RCT) to understand how AI tools at the February-June 2025 frontier affect the\nproductivity of experienced open-source developers. 16 developers with moderate\nAI experience complete 246 tasks in mature projects on which they have an\naverage of 5 years of prior experience. Each task is randomly assigned to allow\nor disallow usage of early 2025 AI tools. When AI tools are allowed, developers\nprimarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet.\nBefore starting tasks, developers forecast that allowing AI will reduce\ncompletion time by 24%. After completing the study, developers estimate that\nallowing AI reduced completion time by 20%. Surprisingly, we find that allowing\nAI actually increases completion time by 19%--AI tooling slowed developers\ndown. This slowdown also contradicts predictions from experts in economics (39%\nshorter) and ML (38% shorter). To understand this result, we collect and\nevaluate evidence for 20 properties of our setting that a priori could\ncontribute to the observed slowdown effect--for example, the size and quality\nstandards of projects, or prior developer experience with AI tooling. Although\nthe influence of experimental artifacts cannot be entirely ruled out, the\nrobustness of the slowdown effect across our analyses suggests it is unlikely\nto primarily be a function of our experimental design.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u53d1\u73b0\uff0c\u4f7f\u75282025\u5e74\u524d\u6cbfAI\u5de5\u5177\uff08\u5982Cursor Pro\u548cClaude 3.5/3.7 Sonnet\uff09\u53cd\u800c\u4f7f\u5f00\u53d1\u8005\u5b8c\u6210\u4efb\u52a1\u65f6\u95f4\u589e\u52a019%\uff0c\u4e0e\u5f00\u53d1\u8005\u548c\u4e13\u5bb6\u7684\u9884\u671f\u76f8\u53cd\u3002", "motivation": "\u63a2\u8ba8AI\u5de5\u5177\u5bf9\u5f00\u6e90\u5f00\u53d1\u8005\u7684\u5b9e\u9645\u751f\u4ea7\u529b\u5f71\u54cd\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7a7a\u767d\u3002", "method": "16\u540d\u6709AI\u7ecf\u9a8c\u7684\u5f00\u53d1\u8005\u968f\u673a\u5b8c\u6210246\u4e2a\u4efb\u52a1\uff0c\u90e8\u5206\u4efb\u52a1\u5141\u8bb8\u4f7f\u7528AI\u5de5\u5177\uff0c\u6bd4\u8f83\u5b8c\u6210\u65f6\u95f4\u5dee\u5f02\u3002", "result": "AI\u5de5\u5177\u4f7f\u7528\u4f7f\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u589e\u52a019%\uff0c\u4e0e\u5f00\u53d1\u8005\u9884\u671f\u51cf\u5c1120%\u548c\u7ecf\u6d4e/ML\u4e13\u5bb6\u9884\u6d4b\u51cf\u5c1138-39%\u76f8\u53cd\u3002", "conclusion": "AI\u5de5\u5177\u53ef\u80fd\u5728\u67d0\u4e9b\u60c5\u5883\u4e0b\u51cf\u7f13\u5f00\u53d1\u901f\u5ea6\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5f71\u54cd\u56e0\u7d20\u3002"}}
{"id": "2507.09892", "pdf": "https://arxiv.org/pdf/2507.09892", "abs": "https://arxiv.org/abs/2507.09892", "authors": ["Zimu Chen", "Di Wang"], "title": "PathFuzzing: Worst Case Analysis by Fuzzing Symbolic-Execution Paths", "categories": ["cs.SE", "D.2.5"], "comment": "10 pages, 1 figure", "summary": "Estimating worst-case resource consumption is a critical task in software\ndevelopment. The worst-case analysis (WCA) problem is an optimization-based\nabstraction of this task. Fuzzing and symbolic execution are widely used\ntechniques for addressing the WCA problem. However, improving code coverage in\nfuzzing or managing path explosion in symbolic execution within the context of\nWCA poses significant challenges. In this paper, we propose PathFuzzing, aiming\nto combine the strengths of both techniques to design a WCA method. The key\nidea is to transform a program into a symbolic one that takes an execution path\n(encoded as a binary string) and interprets the bits as branch decisions.\nPathFuzzing then applies evolutionary fuzzing techniques to the transformed\nprogram to search for binary strings that represent satisfiable path conditions\nand lead to high resource consumption. We evaluate the performance of\nPathFuzzing experimentally on a benchmark suite that consists of prior work's\nbenchmarks and some added by us. Results show that PathFuzzing generally\noutperforms a fuzzing and a symbolic-execution baseline.", "AI": {"tldr": "PathFuzzing \u662f\u4e00\u79cd\u7ed3\u5408\u6a21\u7cca\u6d4b\u8bd5\u4e0e\u7b26\u53f7\u6267\u884c\u4f18\u70b9\u7684\u6700\u574f\u60c5\u51b5\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a0b\u5e8f\u8f6c\u6362\u548c\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u8d44\u6e90\u6d88\u8017\u7684\u4f30\u8ba1\u3002", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\u548c\u7b26\u53f7\u6267\u884c\u5728\u6700\u574f\u60c5\u51b5\u5206\u6790\uff08WCA\uff09\u4e2d\u5b58\u5728\u4ee3\u7801\u8986\u76d6\u7387\u4f4e\u548c\u8def\u5f84\u7206\u70b8\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "PathFuzzing \u5c06\u7a0b\u5e8f\u8f6c\u6362\u4e3a\u7b26\u53f7\u7a0b\u5e8f\uff0c\u5229\u7528\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u7f16\u7801\u6267\u884c\u8def\u5f84\uff0c\u5e76\u901a\u8fc7\u8fdb\u5316\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\u641c\u7d22\u9ad8\u8d44\u6e90\u6d88\u8017\u7684\u53ef\u6ee1\u8db3\u8def\u5f84\u6761\u4ef6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPathFuzzing \u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u548c\u7b26\u53f7\u6267\u884c\u65b9\u6cd5\u3002", "conclusion": "PathFuzzing \u6210\u529f\u7ed3\u5408\u4e86\u6a21\u7cca\u6d4b\u8bd5\u548c\u7b26\u53f7\u6267\u884c\u7684\u4f18\u52bf\uff0c\u4e3a\u6700\u574f\u60c5\u51b5\u8d44\u6e90\u6d88\u8017\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09111", "pdf": "https://arxiv.org/pdf/2507.09111", "abs": "https://arxiv.org/abs/2507.09111", "authors": ["Di Wen", "Kunyu Peng", "Kailun Yang", "Yufan Chen", "Ruiping Liu", "Junwei Zheng", "Alina Roitberg", "Rainer Stiefelhagen"], "title": "RoHOI: Robustness Benchmark for Human-Object Interaction Detection", "categories": ["cs.CV", "cs.HC", "cs.RO", "eess.IV"], "comment": "Benchmarks, datasets, and code will be made publicly available at\n  https://github.com/Kratos-Wen/RoHOI", "summary": "Human-Object Interaction (HOI) detection is crucial for robot-human\nassistance, enabling context-aware support. However, models trained on clean\ndatasets degrade in real-world conditions due to unforeseen corruptions,\nleading to inaccurate prediction. To address this, we introduce the first\nrobustness benchmark for HOI detection, evaluating model resilience under\ndiverse challenges. Despite advances, current models struggle with\nenvironmental variability, occlusion, and noise. Our benchmark, RoHOI, includes\n20 corruption types based on HICO-DET and V-COCO datasets and a new\nrobustness-focused metric. We systematically analyze existing models in the\nrelated field, revealing significant performance drops under corruptions. To\nimprove robustness, we propose a Semantic-Aware Masking-based Progressive\nLearning (SAMPL) strategy to guide the model to be optimized based on holistic\nand partial cues, dynamically adjusting the model's optimization to enhance\nrobust feature learning. Extensive experiments show our approach outperforms\nstate-of-the-art methods, setting a new standard for robust HOI detection.\nBenchmarks, datasets, and code will be made publicly available at\nhttps://github.com/Kratos-Wen/RoHOI.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u7528\u4e8e\u4eba-\u7269\u4ea4\u4e92\uff08HOI\uff09\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u57fa\u51c6RoHOI\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u591a\u6837\u5316\u6311\u6218\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u8bed\u4e49\u611f\u77e5\u63a9\u853d\u6e10\u8fdb\u5b66\u4e60\uff08SAMPL\uff09\u7b56\u7565\u4ee5\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709HOI\u68c0\u6d4b\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u9000\u5316\u95ee\u9898\u4e25\u91cd\uff0c\u4e9f\u9700\u4e00\u4e2a\u80fd\u8bc4\u4f30\u548c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u9c81\u68d2\u6027\u57fa\u51c6RoHOI\uff0c\u5305\u542b20\u79cd\u8150\u8d25\u7c7b\u578b\uff0c\u5e76\u63d0\u51faSAMPL\u7b56\u7565\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4f18\u5316\u589e\u5f3a\u9c81\u68d2\u7279\u5f81\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSAMPL\u7b56\u7565\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u786e\u7acb\u4e86\u65b0\u6807\u51c6\uff0c\u4e14\u57fa\u51c6\u548c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "conclusion": "RoHOI\u57fa\u51c6\u548cSAMPL\u7b56\u7565\u4e3aHOI\u68c0\u6d4b\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2507.09907", "pdf": "https://arxiv.org/pdf/2507.09907", "abs": "https://arxiv.org/abs/2507.09907", "authors": ["Thomas Hansper", "Kevin Phong Pham", "Michael Neumann"], "title": "Modelling Interrelations Between Agile Practices: The Agile Map", "categories": ["cs.SE"], "comment": null, "summary": "Agile methods are defined through guidelines comprising various practices\nintended to enable agile ways of working. These guidelines further comprise a\nspecific set of agile practices aiming to enable teams for an agile way of\nworking. However, due to its wide-spread use in practice we know that agile\npractices are adopted and tailored intensively, which lead to a high variety of\nagile practices in terms of their level of detail. Problem: A high variety of\nagile practices can be challenging as we do not know how different agile\npractices are interrelated with each other. To be more precise, tailoring and\nadopting agile practices may lead to the challenge, that the combinatorial use\nof several agile practices can only be successful to a limited extent, as\npractices support or even require each other for a effective use in practice.\nObjective: Our study aims to provide an enabler for this problem. We want to\nidentify interrelations between agile practices and describe them in a\nsystematic manner. Contribution: The core contribution of this paper is the\nAgile Map, a theoretical model describing relations between agile practices\nfollowing a systematic approach aiming to provide an overview of coherences\nbetween agile practices. The model aims to support practitioners in selecting\nand combining agile practices in a meaningful way.", "AI": {"tldr": "\u6458\u8981\u8ba8\u8bba\u4e86\u654f\u6377\u5b9e\u8df5\u4e2d\u5b9e\u8df5\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6a21\u578b\uff08Agile Map\uff09\u6765\u7cfb\u7edf\u5316\u63cf\u8ff0\u8fd9\u4e9b\u5173\u7cfb\uff0c\u4ee5\u5e2e\u52a9\u5b9e\u8df5\u8005\u66f4\u6709\u6548\u5730\u9009\u62e9\u548c\u7ec4\u5408\u654f\u6377\u5b9e\u8df5\u3002", "motivation": "\u654f\u6377\u5b9e\u8df5\u5728\u5e7f\u6cdb\u5e94\u7528\u4e2d\u88ab\u5b9a\u5236\u548c\u91c7\u7528\uff0c\u5bfc\u81f4\u5b9e\u8df5\u4e4b\u95f4\u5b58\u5728\u9ad8\u5ea6\u591a\u6837\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u76f8\u4e92\u5173\u7cfb\u7684\u7cfb\u7edf\u7406\u89e3\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5b9e\u8df5\u4e2d\u7ec4\u5408\u4f7f\u7528\u654f\u6377\u5b9e\u8df5\u65f6\u6548\u679c\u53d7\u9650\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u7406\u8bba\u6a21\u578b\uff08Agile Map\uff09\u6765\u63cf\u8ff0\u654f\u6377\u5b9e\u8df5\u4e4b\u95f4\u7684\u76f8\u4e92\u8054\u7cfb\u3002", "result": "\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662fAgile Map\uff0c\u5b83\u4e3a\u654f\u6377\u5b9e\u8df5\u4e4b\u95f4\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u6a21\u578b\uff0c\u5e2e\u52a9\u5b9e\u8df5\u8005\u66f4\u6709\u610f\u4e49\u5730\u9009\u62e9\u548c\u7ec4\u5408\u5b9e\u8df5\u3002", "conclusion": "Agile Map\u4e3a\u7406\u89e3\u548c\u5e94\u7528\u654f\u6377\u5b9e\u8df5\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u5de5\u5177\uff0c\u65e8\u5728\u652f\u6301\u5b9e\u8df5\u8005\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u66f4\u6709\u6548\u5730\u4f7f\u7528\u654f\u6377\u65b9\u6cd5\u3002"}}
{"id": "2507.09911", "pdf": "https://arxiv.org/pdf/2507.09911", "abs": "https://arxiv.org/abs/2507.09911", "authors": ["Marvin Auf der Landwehr", "Julia Topp", "Michael Neumann"], "title": "When Less is More: A systematic review of four-day workweek conceptualizations and their effects on organizational performance", "categories": ["cs.SE"], "comment": null, "summary": "Context: Agile IT organizations, which are characterized by self-organization\nand collaborative social interactions, require motivating, efficient and\nflexible work environments to maximize value creation. Compressed work\nschedules such as the four-day workweek have evolved into multiple facets over\nthe last decades and are associated with various benefits for organizations and\ntheir employees. Objective: Our objective in this study is to deepen our\ncomprehension of the impact of compressed work schedules on the operational\nefficacy of IT enterprises, while concurrently developing a comprehensive\nframework delineating the intricacies of compressed work schedules.Method: We\nconducted a systematic review of available conceptualizations related to\nfour-day workweek schedules and elaborate on their organizational and social\neffects. To cover scientific and practice-oriented literature, our review\ncombined a systematic literature review and a web content analysis. Results:\nBased on the generated insights, we derive a meta-framework that matches\nconceptualizations and effects, finally guiding the adoption of compressed work\nschedules based on individual managerial prerequisites and circumstances.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u538b\u7f29\u5de5\u4f5c\u5236\uff08\u5982\u56db\u5929\u5de5\u4f5c\u5468\uff09\u5bf9IT\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\u4ee5\u6307\u5bfc\u5176\u5b9e\u65bd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u7406\u89e3\u538b\u7f29\u5de5\u4f5c\u5236\u5bf9IT\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u5f00\u53d1\u4e00\u4e2a\u6846\u67b6\u6765\u6307\u5bfc\u5176\u5e94\u7528\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u548c\u7f51\u7edc\u5185\u5bb9\u5206\u6790\uff0c\u7ed3\u5408\u79d1\u5b66\u548c\u5b9e\u8df5\u5bfc\u5411\u7684\u6587\u732e\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5143\u6846\u67b6\uff0c\u5c06\u538b\u7f29\u5de5\u4f5c\u5236\u7684\u6982\u5ff5\u5316\u548c\u6548\u679c\u5339\u914d\uff0c\u4ee5\u6307\u5bfc\u4f01\u4e1a\u5728\u4e0d\u540c\u7ba1\u7406\u524d\u63d0\u548c\u60c5\u5883\u4e0b\u7684\u91c7\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aIT\u4f01\u4e1a\u5b9e\u65bd\u538b\u7f29\u5de5\u4f5c\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u548c\u5b9e\u8df5\u6307\u5357\u3002"}}
{"id": "2507.09482", "pdf": "https://arxiv.org/pdf/2507.09482", "abs": "https://arxiv.org/abs/2507.09482", "authors": ["Changli Wang", "Rui Wu", "Fang Yin"], "title": "ViSP: A PPO-Driven Framework for Sarcasm Generation with Contrastive Learning", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Human emotions are complex, with sarcasm being a subtle and distinctive form.\nDespite progress in sarcasm research, sarcasm generation remains underexplored,\nprimarily due to the overreliance on textual modalities and the neglect of\nvisual cues, as well as the mismatch between image content and sarcastic intent\nin existing datasets. In this paper, we introduce M2SaG, a multimodal sarcasm\ngeneration dataset with 4,970 samples, each containing an image, a sarcastic\ntext, and a sarcasm target. To benchmark M2SaG, we propose ViSP, a generation\nframework that integrates Proximal Policy Optimization (PPO) and contrastive\nlearning. PPO utilizes reward scores from DIP to steer the generation of\nsarcastic texts, while contrastive learning encourages the model to favor\noutputs with higher reward scores. These strategies improve overall generation\nquality and produce texts with more pronounced sarcastic intent. We evaluate\nViSP across five metric sets and find it surpasses all baselines, including\nlarge language models, underscoring their limitations in sarcasm generation.\nFurthermore, we analyze the distributions of Sarcasm Scores and Factual\nIncongruity for both M2SaG and the texts generated by ViSP. The generated texts\nexhibit higher mean Sarcasm Scores (0.898 vs. 0.770) and Factual Incongruity\n(0.768 vs. 0.739), demonstrating that ViSP produces higher-quality sarcastic\ncontent than the original dataset. % The dataset and code will be publicly\navailable. Our dataset and code will be released at\n\\textit{https://github.com/wclapply/ViSP}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u8bbd\u523a\u751f\u6210\u6570\u636e\u96c6M2SaG\u548c\u751f\u6210\u6846\u67b6ViSP\uff0c\u7ed3\u5408PPO\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u751f\u6210\u66f4\u5177\u8bbd\u523a\u6027\u7684\u6587\u672c\u3002", "motivation": "\u73b0\u6709\u8bbd\u523a\u7814\u7a76\u591a\u4f9d\u8d56\u6587\u672c\u6a21\u6001\uff0c\u5ffd\u7565\u4e86\u89c6\u89c9\u7ebf\u7d22\uff0c\u4e14\u6570\u636e\u96c6\u56fe\u50cf\u5185\u5bb9\u4e0e\u8bbd\u523a\u610f\u56fe\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u8bbd\u523a\u751f\u6210\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51faViSP\u6846\u67b6\uff0c\u6574\u5408PPO\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5229\u7528DIP\u7684\u5956\u52b1\u5206\u6570\u5f15\u5bfc\u751f\u6210\u8bbd\u523a\u6587\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cViSP\u5728\u4e94\u5927\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u751f\u6210\u6587\u672c\u7684\u8bbd\u523a\u8bc4\u5206\uff080.898\uff09\u548c\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u6027\uff080.768\uff09\u9ad8\u4e8e\u539f\u6570\u636e\u96c6\uff080.770\u548c0.739\uff09\u3002", "conclusion": "ViSP\u6846\u67b6\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u8bbd\u523a\u6587\u672c\uff0c\u586b\u8865\u4e86\u591a\u6a21\u6001\u8bbd\u523a\u751f\u6210\u7684\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2507.10054", "pdf": "https://arxiv.org/pdf/2507.10054", "abs": "https://arxiv.org/abs/2507.10054", "authors": ["Emir Bosnak", "Sahand Moslemi", "Mayasah Lami", "Anil Koyuncu"], "title": "Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks", "categories": ["cs.SE"], "comment": "Accepted to ICSME 2025", "summary": "Large Language Models (LLMs) are increasingly used as code assistants, yet\ntheir behavior when explicitly asked to generate insecure code remains poorly\nunderstood. While prior research has focused on unintended vulnerabilities or\nadversarial prompting techniques, this study examines a more direct threat\nscenario: open-source LLMs generating vulnerable code when prompted either\ndirectly or indirectly. We propose a dual experimental design: (1) Dynamic\nPrompting, which systematically varies vulnerability type, user persona, and\ndirectness across structured templates; and (2) Reverse Prompting, which\nderives prompts from real vulnerable code samples to assess vulnerability\nreproduction accuracy. We evaluate three open-source 7B-parameter models\n(Qwen2, Mistral, and Gemma) using ESBMC static analysis to assess both the\npresence of vulnerabilities and the correctness of the generated vulnerability\ntype. Results show all models frequently produce vulnerable outputs, with Qwen2\nachieving highest correctness rates. User persona significantly affects\nsuccess, where student personas achieved higher vulnerability rates than\nprofessional roles, while direct prompts were marginally more effective.\nVulnerability reproduction followed an inverted-U pattern with cyclomatic\ncomplexity, peaking at moderate ranges. Our findings expose limitations of\nsafety mechanisms in open-source models, particularly for seemingly benign\neducational requests.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u88ab\u76f4\u63a5\u6216\u95f4\u63a5\u63d0\u793a\u65f6\u5bb9\u6613\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\uff0c\u4e14\u7528\u6237\u89d2\u8272\u548c\u63d0\u793a\u65b9\u5f0f\u663e\u8457\u5f71\u54cd\u6f0f\u6d1e\u751f\u6210\u7387\u3002", "motivation": "\u7406\u89e3LLMs\u5728\u660e\u786e\u8981\u6c42\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\u65f6\u7684\u884c\u4e3a\uff0c\u8bc4\u4f30\u5f00\u6e90\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u52a8\u6001\u63d0\u793a\u548c\u53cd\u5411\u63d0\u793a\u4e24\u79cd\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u5de5\u5177\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u6f0f\u6d1e\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u5747\u9891\u7e41\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\uff0cQwen2\u51c6\u786e\u6027\u6700\u9ad8\uff1b\u7528\u6237\u89d2\u8272\uff08\u5b66\u751f\uff09\u548c\u76f4\u63a5\u63d0\u793a\u5bf9\u6f0f\u6d1e\u751f\u6210\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "\u5f00\u6e90\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\u5b58\u5728\u4e0d\u8db3\uff0c\u6559\u80b2\u7c7b\u8bf7\u6c42\u5c24\u5176\u5bb9\u6613\u88ab\u6ee5\u7528\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2507.10062", "pdf": "https://arxiv.org/pdf/2507.10062", "abs": "https://arxiv.org/abs/2507.10062", "authors": ["Erg\u00fcn Batuhan Kaynak", "Mayasah Lami", "Sahand Moslemi", "Anil Koyuncu"], "title": "LLMShot: Reducing snapshot testing maintenance via LLMs", "categories": ["cs.SE"], "comment": "Accepted to ICSME 2025", "summary": "Snapshot testing has emerged as a critical technique for UI validation in\nmodern software development, yet it suffers from substantial maintenance\noverhead due to frequent UI changes causing test failures that require manual\ninspection to distinguish between genuine regressions and intentional design\nchanges. This manual triage process becomes increasingly burdensome as\napplications evolve, creating a need for automated analysis solutions. This\npaper introduces LLMShot, a novel framework that leverages vision-based Large\nLanguage Models to automatically analyze snapshot test failures through\nhierarchical classification of UI changes. To evaluate LLMShot's effectiveness,\nwe developed a comprehensive dataset using a feature-rich iOS application with\nconfigurable feature flags, creating realistic scenarios that produce authentic\nsnapshot differences representative of real development workflows. Our\nevaluation using Gemma3 models demonstrates strong classification performance,\nwith the 12B variant achieving over 84% recall in identifying failure root\ncauses while the 4B model offers practical deployment advantages with\nacceptable performance for continuous integration environments. However, our\nexploration of selective ignore mechanisms revealed significant limitations in\ncurrent prompting-based approaches for controllable visual reasoning. LLMShot\nrepresents the first automated approach to semantic snapshot test analysis,\noffering developers structured insights that can substantially reduce manual\ntriage effort and advance toward more intelligent UI testing paradigms.", "AI": {"tldr": "LLMShot\u5229\u7528\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5206\u6790UI\u5feb\u7167\u6d4b\u8bd5\u5931\u8d25\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u7c7b\u51cf\u5c11\u4eba\u5de5\u68c0\u67e5\u8d1f\u62c5\uff0c12B\u6a21\u578b\u53ec\u56de\u7387\u8d8584%\uff0c\u4f46\u63d0\u793a\u673a\u5236\u4ecd\u6709\u5c40\u9650\u3002", "motivation": "UI\u5feb\u7167\u6d4b\u8bd5\u56e0\u9891\u7e41\u53d8\u66f4\u5bfc\u81f4\u5927\u91cf\u624b\u52a8\u68c0\u67e5\u9700\u6c42\uff0c\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\u3002", "method": "\u63d0\u51faLLMShot\u6846\u67b6\uff0c\u5229\u7528\u5206\u5c42\u5206\u7c7b\u7684\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u6d4b\u8bd5\u5931\u8d25\uff0c\u5e76\u6784\u5efaiOS\u5e94\u7528\u6570\u636e\u96c6\u9a8c\u8bc1\u3002", "result": "12B\u6a21\u578b\u53ec\u56de\u7387\u8fbe84%\uff0c4B\u6a21\u578b\u9002\u5408\u6301\u7eed\u96c6\u6210\uff0c\u4f46\u63d0\u793a\u673a\u5236\u53ef\u63a7\u6027\u4e0d\u8db3\u3002", "conclusion": "LLMShot\u9996\u6b21\u5b9e\u73b0\u8bed\u4e49\u5feb\u7167\u6d4b\u8bd5\u81ea\u52a8\u5206\u6790\uff0c\u4e3a\u667a\u80fdUI\u6d4b\u8bd5\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.10103", "pdf": "https://arxiv.org/pdf/2507.10103", "abs": "https://arxiv.org/abs/2507.10103", "authors": ["Hanyang Guo", "Xiaoheng Xie", "Hong-Ning Dai", "Peng Di", "Yu Zhang", "Bishenghui Tao", "Zibin Zheng"], "title": "Accelerating Automatic Program Repair with Dual Retrieval-Augmented Fine-Tuning and Patch Generation on Large Language Models", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Automated Program Repair (APR) is essential for ensuring software reliability\nand quality while enhancing efficiency and reducing developers' workload.\nAlthough rule-based and learning-based APR methods have demonstrated their\neffectiveness, their performance was constrained by the defect type of repair,\nthe quality of training data, and the size of model parameters. Recently, Large\nLanguage Models (LLMs) combined with Retrieval-Augmented-Generation (RAG) have\nbeen increasingly adopted in APR tasks. However, current code LLMs and RAG\ndesigns neither fully address code repair tasks nor consider code-specific\nfeatures. To overcome these limitations, we propose SelRepair, a novel APR\napproach with integration of a fine-tuned LLM with a newly-designed dual RAG\nmodule. This approach uses a bug-fix pair dataset for fine-tuning and\nincorporates semantic and syntactic/structural similarity information through\nan RAG selection gate. This design ensures relevant information is retrieved\nefficiently, thereby reducing token length and inference time. Evaluations on\nJava datasets show SelRepair outperforms other APR methods, achieving 26.29%\nand 17.64% in terms of exact match (EM) on different datasets while reducing\ninference time by at least 6.42% with controlled input lengths.", "AI": {"tldr": "SelRepair\u662f\u4e00\u79cd\u7ed3\u5408\u5fae\u8c03LLM\u548c\u53ccRAG\u6a21\u5757\u7684\u65b0\u578bAPR\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u548c\u8bed\u6cd5/\u7ed3\u6784\u76f8\u4f3c\u6027\u4f18\u5316\u4fee\u590d\u6548\u7387\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684APR\u65b9\u6cd5\u53d7\u9650\u4e8e\u7f3a\u9677\u7c7b\u578b\u3001\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u548c\u6a21\u578b\u53c2\u6570\u89c4\u6a21\uff0c\u4e14\u4ee3\u7801LLMs\u548cRAG\u8bbe\u8ba1\u672a\u5145\u5206\u5173\u6ce8\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u6216\u4ee3\u7801\u7279\u5f81\u3002", "method": "\u63d0\u51faSelRepair\uff0c\u6574\u5408\u5fae\u8c03LLM\u4e0e\u53ccRAG\u6a21\u5757\uff0c\u5229\u7528bug-fix\u5bf9\u6570\u636e\u96c6\u548c\u76f8\u4f3c\u6027\u4fe1\u606f\u68c0\u7d22\u4f18\u5316\u6548\u7387\u3002", "result": "\u5728Java\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0cEM\u8fbe\u523026.29%\u548c17.64%\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u5c11\u81f3\u5c116.42%\u3002", "conclusion": "SelRepair\u901a\u8fc7\u4f18\u5316\u4fe1\u606f\u68c0\u7d22\u548c\u6a21\u578b\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4e86APR\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2507.09788", "pdf": "https://arxiv.org/pdf/2507.09788", "abs": "https://arxiv.org/abs/2507.09788", "authors": ["Paulo Salem", "Robert Sim", "Christopher Olsen", "Prerit Saxena", "Rafael Barcelos", "Yi Ding"], "title": "TinyTroupe: An LLM-powered Multiagent Persona Simulation Toolkit", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.HC", "I.2.11; I.6.5; I.6.7"], "comment": "9 pages. Preprint to be submitted to peer-review", "summary": "Recent advances in Large Language Models (LLM) have led to a new class of\nautonomous agents, renewing and expanding interest in the area. LLM-powered\nMultiagent Systems (MAS) have thus emerged, both for assistive and simulation\npurposes, yet tools for realistic human behavior simulation -- with its\ndistinctive challenges and opportunities -- remain underdeveloped. Existing MAS\nlibraries and tools lack fine-grained persona specifications, population\nsampling facilities, experimentation support, and integrated validation, among\nother key capabilities, limiting their utility for behavioral studies, social\nsimulation, and related applications. To address these deficiencies, in this\nwork we introduce TinyTroupe, a simulation toolkit enabling detailed persona\ndefinitions (e.g., nationality, age, occupation, personality, beliefs,\nbehaviors) and programmatic control via numerous LLM-driven mechanisms. This\nallows for the concise formulation of behavioral problems of practical\ninterest, either at the individual or group level, and provides effective means\nfor their solution. TinyTroupe's components are presented using representative\nworking examples, such as brainstorming and market research sessions, thereby\nsimultaneously clarifying their purpose and demonstrating their usefulness.\nQuantitative and qualitative evaluations of selected aspects are also provided,\nhighlighting possibilities, limitations, and trade-offs. The approach, though\nrealized as a specific Python implementation, is meant as a novel conceptual\ncontribution, which can be partially or fully incorporated in other contexts.\nThe library is available as open source at\nhttps://github.com/microsoft/tinytroupe.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86TinyTroupe\uff0c\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u4eff\u771f\u5de5\u5177\u5305\uff0c\u652f\u6301\u8be6\u7ec6\u89d2\u8272\u5b9a\u4e49\u548c\u7a0b\u5e8f\u5316\u63a7\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u5728\u884c\u4e3a\u7814\u7a76\u548c\u793e\u4ea4\u4eff\u771f\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5de5\u5177\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u89d2\u8272\u5b9a\u4e49\u548c\u5b9e\u9a8c\u652f\u6301\uff0c\u963b\u788d\u4e86\u884c\u4e3a\u7814\u7a76\u548c\u793e\u4ea4\u4eff\u771f\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86TinyTroupe\u5de5\u5177\u5305\uff0c\u63d0\u4f9b\u8be6\u7ec6\u89d2\u8272\u5b9a\u4e49\u548cLLM\u9a71\u52a8\u673a\u5236\uff0c\u652f\u6301\u4e2a\u4f53\u6216\u7fa4\u4f53\u884c\u4e3a\u95ee\u9898\u7684\u89e3\u51b3\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u4e86\u5de5\u5177\u7684\u6709\u7528\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u5176\u53ef\u80fd\u6027\u548c\u9650\u5236\u3002", "conclusion": "TinyTroupe\u662f\u4e00\u4e2a\u521b\u65b0\u578b\u6982\u5ff5\u8d21\u732e\uff0c\u53ef\u90e8\u5206\u6216\u5b8c\u5168\u7528\u4e8e\u5176\u4ed6\u573a\u666f\uff0c\u76ee\u524d\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.10182", "pdf": "https://arxiv.org/pdf/2507.10182", "abs": "https://arxiv.org/abs/2507.10182", "authors": ["Gehao Zhang", "Zhenting Wang", "Juan Zhai"], "title": "Breaking the Myth: Can Small Models Infer Postconditions Too?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Formal specifications are essential for ensuring software correctness, yet\nmanually writing them is tedious and error-prone. Large Language Models (LLMs)\nhave shown promise in generating such specifications from natural language\nintents, but the giant model size and high computational demands raise a\nfundamental question: Do we really need large models for this task? In this\npaper, we show that a small, fine-tuned language model can achieve high-quality\npostcondition generation with much lower computational costs. We construct a\nspecialized dataset of prompts, reasoning logs, and postconditions, then\nsupervise the fine-tuning of a $7$B-parameter code model. Our approach tackles\nreal-world repository dependencies and preserves pre-state information,\nallowing for expressive and accurate specifications. We evaluate the model on a\nbenchmark of real-world Java bugs (Defects4J) and compare against both\nproprietary giants (e.g., GPT-4o) and open-source large models. Empirical\nresults demonstrate that our compact model matches or outperforms significantly\nlarger counterparts in syntax correctness, semantic correctness, and\nbug-distinguishing capability. These findings highlight that targeted\nfine-tuning on a modest dataset can enable small models to achieve results\nformerly seen only in massive, resource-heavy LLMs, offering a practical and\nefficient path for the real-world adoption of automated specification\ngeneration.", "AI": {"tldr": "\u5c0f\u578b\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u540e\u7f6e\u6761\u4ef6\u65f6\u6027\u80fd\u5ab2\u7f8e\u5927\u578b\u6a21\u578b\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u3002", "motivation": "\u9a8c\u8bc1\u662f\u5426\u771f\u6b63\u9700\u8981\u5927\u578b\u6a21\u578b\u6765\u751f\u6210\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u63a2\u7d22\u9ad8\u6548\u5b9e\u7528\u7684\u81ea\u52a8\u5316\u89c4\u8303\u751f\u6210\u65b9\u6848\u3002", "method": "\u6784\u5efa\u5305\u542b\u63d0\u793a\u3001\u63a8\u7406\u65e5\u5fd7\u548c\u540e\u7f6e\u6761\u4ef6\u7684\u4e13\u7528\u6570\u636e\u96c6\uff0c\u5e76\u5bf97B\u53c2\u6570\u4ee3\u7801\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728\u771f\u5b9eJava\u7f3a\u9677\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5c0f\u578b\u6a21\u578b\u5728\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u8bed\u4e49\u6b63\u786e\u6027\u548c\u533a\u5206\u7f3a\u9677\u80fd\u529b\u4e0a\u5ab2\u7f8e\u6216\u8d85\u8d8a\u5927\u578b\u6a21\u578b\u3002", "conclusion": "\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u5fae\u8c03\u53ef\u4ee5\u4f7f\u5c0f\u578b\u6a21\u578b\u8fbe\u5230\u5927\u578b\u6a21\u578b\u7684\u6548\u679c\uff0c\u4e3a\u81ea\u52a8\u5316\u89c4\u8303\u751f\u6210\u7684\u73b0\u5b9e\u5e94\u7528\u63d0\u4f9b\u9ad8\u6548\u8def\u5f84\u3002"}}
{"id": "2507.10131", "pdf": "https://arxiv.org/pdf/2507.10131", "abs": "https://arxiv.org/abs/2507.10131", "authors": ["Cesar Alan Contreras", "Manolis Chiou", "Alireza Rastegarpanah", "Michal Szulik", "Rustam Stolkin"], "title": "Probabilistic Human Intent Prediction for Mobile Manipulation: An Evaluation with Human-Inspired Constraints", "categories": ["cs.RO", "cs.CV", "cs.HC"], "comment": "Submitted to Journal of Intelligent & Robotic Systems (Under Review)", "summary": "Accurate inference of human intent enables human-robot collaboration without\nconstraining human control or causing conflicts between humans and robots. We\npresent GUIDER (Global User Intent Dual-phase Estimation for Robots), a\nprobabilistic framework that enables a robot to estimate the intent of human\noperators. GUIDER maintains two coupled belief layers, one tracking navigation\ngoals and the other manipulation goals. In the Navigation phase, a Synergy Map\nblends controller velocity with an occupancy grid to rank interaction areas.\nUpon arrival at a goal, an autonomous multi-view scan builds a local 3D cloud.\nThe Manipulation phase combines U2Net saliency, FastSAM instance saliency, and\nthree geometric grasp-feasibility tests, with an end-effector kinematics-aware\nupdate rule that evolves object probabilities in real-time. GUIDER can\nrecognize areas and objects of intent without predefined goals. We evaluated\nGUIDER on 25 trials (five participants x five task variants) in Isaac Sim, and\ncompared it with two baselines, one for navigation and one for manipulation.\nAcross the 25 trials, GUIDER achieved a median stability of 93-100% during\nnavigation, compared with 60-100% for the BOIR baseline, with an improvement of\n39.5% in a redirection scenario (T5). During manipulation, stability reached\n94-100% (versus 69-100% for Trajectron), with a 31.4% difference in a\nredirection task (T3). In geometry-constrained trials (manipulation), GUIDER\nrecognized the object intent three times earlier than Trajectron (median\nremaining time to confident prediction 23.6 s vs 7.8 s). These results validate\nour dual-phase framework and show improvements in intent inference in both\nphases of mobile manipulation tasks.", "AI": {"tldr": "GUIDER \u662f\u4e00\u79cd\u53cc\u76f8\u4f4d\u6982\u7387\u6846\u67b6\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u63a8\u65ad\u4eba\u7c7b\u64cd\u4f5c\u5458\u7684\u610f\u56fe\uff0c\u5728\u5bfc\u822a\u548c\u64cd\u7eb5\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u4eba\u7c7b\u610f\u56fe\u51c6\u786e\u63a8\u65ad\uff0c\u907f\u514d\u51b2\u7a81\u3002", "method": "GUIDER \u6846\u67b6\u5305\u542b\u5bfc\u822a\u548c\u64cd\u7eb5\u4e24\u4e2a\u8026\u5408\u7684\u4fe1\u5ff5\u5c42\uff0c\u5206\u522b\u5229\u7528 Synergy Map \u548c\u591a\u6a21\u6001\u6570\u636e\u5904\u7406\u6280\u672f\uff08\u5982 U2Net\u3001FastSAM \u548c\u51e0\u4f55\u6293\u53d6\u53ef\u884c\u6027\u6d4b\u8bd5\uff09\u5b9e\u65f6\u66f4\u65b0\u610f\u56fe\u3002", "result": "\u5b9e\u9a8c\u4e2d\uff0cGUIDER \u5728\u5bfc\u822a\u548c\u64cd\u7eb5\u9636\u6bb5\u7684\u7a33\u5b9a\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff08BOIR \u548c Trajectron\uff09\u3002", "conclusion": "GUIDER \u6709\u6548\u63d0\u5347\u4e86\u79fb\u52a8\u64cd\u7eb5\u4efb\u52a1\u4e2d\u610f\u56fe\u63a8\u65ad\u7684\u51c6\u786e\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u53cc\u76f8\u4f4d\u6846\u67b6\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2507.10228", "pdf": "https://arxiv.org/pdf/2507.10228", "abs": "https://arxiv.org/abs/2507.10228", "authors": ["Hugo Villamizar", "Daniel Mendez", "Marcos Kalinowski"], "title": "Towards a Framework for Operationalizing the Specification of Trustworthy AI Requirements", "categories": ["cs.SE"], "comment": "This paper has been accepted for presentation at the 2025 IEEE 33rd\n  International Requirements Engineering Conference Workshops (REW-RETRAI 2025)", "summary": "Growing concerns around the trustworthiness of AI-enabled systems highlight\nthe role of requirements engineering (RE) in addressing emergent,\ncontext-dependent properties that are difficult to specify without structured\napproaches. In this short vision paper, we propose the integration of two\ncomplementary approaches: AMDiRE, an artefact-based approach for RE, and\nPerSpecML, a perspective-based method designed to support the elicitation,\nanalysis, and specification of machine learning (ML)-enabled systems. AMDiRE\nprovides a structured, artefact-centric, process-agnostic methodology and\ntemplates that promote consistency and traceability in the results; however, it\nis primarily oriented toward deterministic systems. PerSpecML, in turn,\nintroduces multi-perspective guidance to uncover concerns arising from the\ndata-driven and non-deterministic behavior of ML-enabled systems. We envision a\npathway to operationalize trustworthiness-related requirements, bridging\nstakeholder-driven concerns and structured artefact models. We conclude by\noutlining key research directions and open challenges to be discussed with the\nRE community.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u6574\u5408AMDiRE\u548cPerSpecML\u4e24\u79cd\u65b9\u6cd5\uff0c\u4ee5\u89c4\u8303AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u8d56\u6027\u9700\u6c42\uff0c\u586b\u8865\u786e\u5b9a\u6027\u7cfb\u7edf\u4e0e\u975e\u786e\u5b9a\u6027\u7cfb\u7edf\u4e4b\u95f4\u7684\u9700\u6c42\u5de5\u7a0b\u7a7a\u767d\u3002", "motivation": "\u89e3\u51b3AI\u7cfb\u7edf\u56e0\u6570\u636e\u9a71\u52a8\u548c\u975e\u786e\u5b9a\u6027\u884c\u4e3a\u5bfc\u81f4\u7684\u4fe1\u4efb\u95ee\u9898\uff0c\u9700\u8981\u7ed3\u6784\u5316\u7684\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408AMDiRE\uff08\u57fa\u4e8e\u5de5\u4ef6\u7684\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\uff09\u548cPerSpecML\uff08\u652f\u6301ML\u7cfb\u7edf\u9700\u6c42\u7684\u591a\u89c6\u89d2\u65b9\u6cd5\uff09\u3002", "result": "\u63d0\u51fa\u4e00\u6761\u5b9e\u73b0\u53ef\u4fe1\u8d56\u6027\u9700\u6c42\u7684\u8def\u5f84\uff0c\u8fde\u63a5\u5229\u76ca\u76f8\u5173\u8005\u5173\u6ce8\u70b9\u548c\u7ed3\u6784\u5316\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7814\u7a76\u65b9\u5411\u4e0e\u5f00\u653e\u6311\u6218\uff0c\u547c\u5401\u9700\u6c42\u5de5\u7a0b\u793e\u533a\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2507.10135", "pdf": "https://arxiv.org/pdf/2507.10135", "abs": "https://arxiv.org/abs/2507.10135", "authors": ["Santiago de Leon-Martinez", "Robert Moro", "Branislav Kveton", "Maria Bielikova"], "title": "Riding the Carousel: The First Extensive Eye Tracking Analysis of Browsing Behavior in Carousel Recommenders", "categories": ["cs.IR", "cs.HC"], "comment": null, "summary": "Carousels have become the de-facto interface in online services. However,\nthere is a lack of research in carousels, particularly examining how\nrecommender systems may be designed differently than the traditional\nsingle-list interfaces. One of the key elements for understanding how to design\na system for a particular interface is understanding how users browse. For\ncarousels, users may browse in a number of different ways due to the added\ncomplexity of multiple topic defined-lists and swiping to see more items.\n  Eye tracking is the key to understanding user behavior by providing valuable,\ndirect information on how users see and navigate. In this work, we provide the\nfirst extensive analysis of the eye tracking behavior in carousel recommenders\nunder the free-browsing setting. To understand how users browse, we examine the\nfollowing research questions : 1) where do users start browsing, 2) how do\nusers transition from item to item within the same carousel and across\ncarousels, and 3) how does genre preference impact transitions?\n  This work addresses a gap in the field and provides the first extensive\nempirical results of eye tracked browsing behavior in carousels for improving\nrecommenders. Taking into account the insights learned from the above\nquestions, our final contribution is to provide suggestions to help carousel\nrecommender system designers optimize their systems for user browsing behavior.\nThe most important suggestion being to reorder the ranked item positions to\naccount for browsing after swiping.These contributions aim not only to help\nimprove current systems, but also to encourage and allow the design of new user\nmodels, systems, and metrics that are better suited to the complexity of\ncarousel interfaces.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8f6e\u64ad\u754c\u9762\u4e2d\u7528\u6237\u7684\u6d4f\u89c8\u884c\u4e3a\uff0c\u901a\u8fc7\u773c\u52a8\u8ffd\u8e2a\u5206\u6790\u63d0\u51fa\u4e86\u6539\u8fdb\u63a8\u8350\u7cfb\u7edf\u7684\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76\u8f6e\u64ad\u754c\u9762\u4e2d\u7528\u6237\u6d4f\u89c8\u884c\u4e3a\uff0c\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u6539\u8fdb\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u4f7f\u7528\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u5206\u6790\u7528\u6237\u5728\u81ea\u7531\u6d4f\u89c8\u4e2d\u7684\u884c\u4e3a\uff0c\u91cd\u70b9\u5173\u6ce8\u6d4f\u89c8\u8d77\u59cb\u70b9\u3001\u9879\u76ee\u95f4\u8f6c\u6362\u4ee5\u53ca\u7c7b\u578b\u504f\u597d\u7684\u5f71\u54cd\u3002", "result": "\u63d0\u51fa\u91cd\u65b0\u6392\u5217\u63a8\u8350\u9879\u76ee\u4ee5\u9002\u5e94\u7528\u6237\u6d4f\u89c8\u884c\u4e3a\u7684\u5efa\u8bae\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6ed1\u52a8\u540e\u7684\u6d4f\u89c8\u884c\u4e3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8f6e\u64ad\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u5e76\u9f13\u52b1\u5f00\u53d1\u66f4\u9002\u5e94\u590d\u6742\u754c\u9762\u7684\u7528\u6237\u6a21\u578b\u548c\u7cfb\u7edf\u3002"}}
{"id": "2507.10235", "pdf": "https://arxiv.org/pdf/2507.10235", "abs": "https://arxiv.org/abs/2507.10235", "authors": ["Zhixiang Chen", "Zhuangbin Chen", "Xingjie Cai", "Wei Li", "Zibin Zheng"], "title": "An Empirical Study of Interaction Bugs in ROS-based Software", "categories": ["cs.SE"], "comment": null, "summary": "Modern robotic systems integrate multiple independent software and hardware\ncomponents, each responsible for distinct functionalities such as perception,\ndecision-making, and execution. These components interact extensively to\naccomplish complex end-to-end tasks. As a result, the overall system\nreliability depends not only on the correctness of individual components, but\nalso on the correctness of their interactions. Failures often manifest at the\nboundaries between components, yet interaction-related reliability issues in\nrobotics--referred to here as interaction bugs (iBugs)--remain underexplored.\n  This work presents an empirical study of iBugs within robotic systems built\nusing the Robot Operating System (ROS), a widely adopted open-source robotics\nframework. A total of 121 iBugs were analyzed across ten actively maintained\nand representative ROS projects. The identified iBugs are categorized into\nthree major types: intra-system iBugs, hardware iBugs, and environmental iBugs,\ncovering a broad range of interaction scenarios in robotics. The analysis\nincludes an examination of root causes, fixing strategies, and the impact of\nthese bugs. Several findingsa are derived that shed light on the nature of\niBugs and suggest directions for improving their prevention and detection.\nThese insights aim to inform the design of more robust and safer robotic\nsystems.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u4ea4\u4e92\u95ee\u9898\uff08iBugs\uff09\uff0c\u63d0\u51fa\u4e86\u4e09\u7c7biBugs\u53ca\u5176\u89e3\u51b3\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u5355\u4e2a\u7ec4\u4ef6\u7684\u6b63\u786e\u6027\uff0c\u8fd8\u4f9d\u8d56\u4e8e\u7ec4\u4ef6\u95f4\u4ea4\u4e92\u7684\u6b63\u786e\u6027\uff0c\u4f46\u4ea4\u4e92\u76f8\u5173\u7684\u53ef\u9760\u6027\u95ee\u9898\uff08iBugs\uff09\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u4f7f\u7528ROS\u6846\u67b6\u5206\u6790\u4e8610\u4e2a\u4ee3\u8868\u6027\u9879\u76ee\u4e2d\u7684121\u4e2aiBugs\uff0c\u5c06\u5176\u5206\u4e3a\u4e09\u7c7b\uff1a\u7cfb\u7edf\u5185iBugs\u3001\u786c\u4ef6iBugs\u548c\u73af\u5883iBugs\uff0c\u5e76\u7814\u7a76\u4e86\u539f\u56e0\u548c\u4fee\u590d\u7b56\u7565\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86iBugs\u7684\u7279\u70b9\u53ca\u5176\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u6539\u8fdb\u9884\u9632\u548c\u68c0\u6d4b\u7684\u65b9\u5411\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u63d0\u9ad8\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2507.10208", "pdf": "https://arxiv.org/pdf/2507.10208", "abs": "https://arxiv.org/abs/2507.10208", "authors": ["Hamzah Ziadeh", "Hendrik Knoche"], "title": "Survey for Categorising Explainable AI Studies Using Data Analysis Task Frameworks", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Research into explainable artificial intelligence (XAI) for data analysis\ntasks suffer from a large number of contradictions and lack of concrete design\nrecommendations stemming from gaps in understanding the tasks that require AI\nassistance. In this paper, we drew on multiple fields such as visual analytics,\ncognition, and dashboard design to propose a method for categorising and\ncomparing XAI studies under three dimensions: what, why, and who. We identified\nthe main problems as: inadequate descriptions of tasks, context-free studies,\nand insufficient testing with target users. We propose that studies should\nspecifically report on their users' domain, AI, and data analysis expertise to\nillustrate the generalisability of their findings. We also propose study\nguidelines for designing and reporting XAI tasks to improve the XAI community's\nability to parse the rapidly growing field. We hope that our contribution can\nhelp researchers and designers better identify which studies are most relevant\nto their work, what gaps exist in the research, and how to handle contradictory\nresults regarding XAI design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u7c7b\u548c\u6bd4\u8f83\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7814\u7a76\u7684\u4e09\u7ef4\u6846\u67b6\uff08\u4ec0\u4e48\u3001\u4e3a\u4ec0\u4e48\u3001\u8c01\uff09\uff0c\u4ee5\u89e3\u51b3\u5f53\u524d\u7814\u7a76\u4e2d\u4efb\u52a1\u63cf\u8ff0\u4e0d\u8db3\u3001\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u548c\u7528\u6237\u6d4b\u8bd5\u4e0d\u5168\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdbXAI\u7814\u7a76\u8bbe\u8ba1\u548c\u62a5\u544a\u7684\u5efa\u8bae\u3002", "motivation": "\u7531\u4e8e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u5728\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e2d\u5b58\u5728\u5927\u91cf\u77db\u76fe\u548c\u7f3a\u4e4f\u5177\u4f53\u8bbe\u8ba1\u5efa\u8bae\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u591a\u9886\u57df\uff08\u5982\u53ef\u89c6\u5316\u5206\u6790\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u4eea\u8868\u76d8\u8bbe\u8ba1\uff09\u7684\u89c6\u89d2\uff0c\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u7814\u7a76\u5206\u7c7b\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdbXAI\u7814\u7a76\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u201c\u4ec0\u4e48\u3001\u4e3a\u4ec0\u4e48\u3001\u8c01\u201d\u4e09\u4e2a\u7ef4\u5ea6\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u7c7b\u548c\u6bd4\u8f83XAI\u7814\u7a76\uff0c\u5e76\u5f3a\u8c03\u4e86\u7814\u7a76\u4e2d\u5e94\u660e\u786e\u62a5\u544a\u7528\u6237\u7684\u9886\u57df\u77e5\u8bc6\u3001AI\u4e13\u4e1a\u77e5\u8bc6\u548c\u6570\u636e\u5206\u6790\u6280\u80fd\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u8bbe\u8ba1\u548c\u62a5\u544aXAI\u4efb\u52a1\u7684\u7814\u7a76\u6307\u5357\u3002", "result": "\u7814\u7a76\u53d1\u73b0XAI\u7814\u7a76\u4e2d\u7684\u4e3b\u8981\u95ee\u9898\u5305\u62ec\u4efb\u52a1\u63cf\u8ff0\u4e0d\u8db3\u3001\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u7814\u7a76\u548c\u7528\u6237\u6d4b\u8bd5\u4e0d\u5168\u3002\u63d0\u51fa\u7684\u6846\u67b6\u548c\u6307\u5357\u6709\u52a9\u4e8e\u6539\u8fdb\u7814\u7a76\u7684\u8bbe\u8ba1\u548c\u62a5\u544a\u7684\u6807\u51c6\u5316\u3002", "conclusion": "\u8be5\u8bba\u6587\u7684\u8d21\u732e\u5728\u4e8e\u4e3aXAI\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u5206\u7c7b\u548c\u6bd4\u8f83\u6846\u67b6\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u8bbe\u8ba1\u8005\u66f4\u6709\u6548\u5730\u8bc6\u522b\u76f8\u5173\u7814\u7a76\u3001\u53d1\u73b0\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u89e3\u51b3\u77db\u76fe\u7684\u8bbe\u8ba1\u7ed3\u679c\uff0c\u4ece\u800c\u63a8\u52a8XAI\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.10244", "pdf": "https://arxiv.org/pdf/2507.10244", "abs": "https://arxiv.org/abs/2507.10244", "authors": ["Adam \u0160t\u011bp\u00e1nek", "David Ku\u0165\u00e1k", "Barbora Kozl\u00edkov\u00e1", "Jan By\u0161ka"], "title": "Helveg: Diagrams for Software Documentation", "categories": ["cs.SE", "D.2.2; D.2.11"], "comment": "13 pages, 5 figures, accepted by TVCG", "summary": "Software developers often have to gain an understanding of a codebase. Be it\nprogrammers getting onboarded onto a team project or, for example, developers\nstriving to grasp an external open-source library. In either case, they\nfrequently turn to the project's documentation. However, documentation in its\ntraditional textual form is ill-suited for this kind of high-level exploratory\nanalysis, since it is immutable from the readers' perspective and thus forces\nthem to follow a predefined path. We have designed an approach bringing aspects\nof software architecture visualization to API reference documentation. It\nutilizes a highly interactive node-link diagram with expressive node glyphs and\nflexible filtering capabilities, providing a high-level overview of the\ncodebase as well as details on demand. To test our design, we have implemented\na prototype named Helveg, capable of automatically generating diagrams of C\\#\ncodebases. User testing of Helveg confirmed its potential, but it also revealed\nproblems with the readability, intuitiveness, and user experience of our tool.\nTherefore, in this paper, which is an extended version of our VISSOFT paper\nwith DOI 10.1109/VISSOFT64034.2024.00012, we address many of these problems\nthrough major changes to the glyph design, means of interaction, and user\ninterface of the tool. To assess the improvements, this new version of Helveg\nwas evaluated again with the same group of participants as the previous\nversion.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aHelveg\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u8282\u70b9\u94fe\u63a5\u56fe\u6539\u8fdbAPI\u6587\u6863\u7684\u63a2\u7d22\u6027\u5206\u6790\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u6863\u4e0d\u6613\u5bfc\u822a\u7684\u95ee\u9898\u3002\u7528\u6237\u6d4b\u8bd5\u540e\u5bf9\u5de5\u5177\u7684\u56fe\u5f62\u8bbe\u8ba1\u548c\u7528\u6237\u4f53\u9a8c\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "motivation": "\u4f20\u7edfAPI\u6587\u6863\u5f62\u5f0f\u56fa\u5b9a\uff0c\u4e0d\u9002\u5408\u4ee3\u7801\u5e93\u7684\u9ad8\u5c42\u6b21\u63a2\u7d22\u5206\u6790\uff0c\u5f00\u53d1\u8005\u9700\u8981\u66f4\u7075\u6d3b\u7684\u63a2\u7d22\u5de5\u5177\u3002", "method": "\u8bbe\u8ba1\u4e86\u4ea4\u4e92\u5f0f\u8282\u70b9\u94fe\u63a5\u56fe\uff0c\u652f\u6301\u8282\u70b9\u7b26\u53f7\u548c\u7075\u6d3b\u8fc7\u6ee4\u529f\u80fd\uff0c\u5e76\u5f00\u53d1\u4e86C#\u4ee3\u7801\u5e93\u81ea\u52a8\u751f\u6210\u56fe\u8868\u7684\u539f\u578b\u5de5\u5177Helveg\u3002", "result": "\u7528\u6237\u6d4b\u8bd5\u8bc1\u5b9e\u4e86\u5de5\u5177\u6f5c\u529b\uff0c\u4f46\u4e5f\u53d1\u73b0\u4e86\u53ef\u8bfb\u6027\u3001\u76f4\u89c2\u6027\u548c\u7528\u6237\u4f53\u9a8c\u95ee\u9898\u3002\u65b0\u7248Helveg\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u6539\u8fdb\u540e\u7684Helveg\u5728\u7528\u6237\u6d4b\u8bd5\u4e2d\u8868\u73b0\u66f4\u4f73\uff0c\u9a8c\u8bc1\u4e86\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5bf9\u4ee3\u7801\u5e93\u63a2\u7d22\u7684\u4ef7\u503c\u3002"}}
{"id": "2507.10500", "pdf": "https://arxiv.org/pdf/2507.10500", "abs": "https://arxiv.org/abs/2507.10500", "authors": ["Kyungtae Han", "Yitao Chen", "Rohit Gupta", "Onur Altintas"], "title": "Scene-Aware Conversational ADAS with Generative AI for Real-Time Driver Assistance", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "While autonomous driving technologies continue to advance, current Advanced\nDriver Assistance Systems (ADAS) remain limited in their ability to interpret\nscene context or engage with drivers through natural language. These systems\ntypically rely on predefined logic and lack support for dialogue-based\ninteraction, making them inflexible in dynamic environments or when adapting to\ndriver intent. This paper presents Scene-Aware Conversational ADAS (SC-ADAS), a\nmodular framework that integrates Generative AI components including large\nlanguage models, vision-to-text interpretation, and structured function calling\nto enable real-time, interpretable, and adaptive driver assistance. SC-ADAS\nsupports multi-turn dialogue grounded in visual and sensor context, allowing\nnatural language recommendations and driver-confirmed ADAS control. Implemented\nin the CARLA simulator with cloud-based Generative AI, the system executes\nconfirmed user intents as structured ADAS commands without requiring model\nfine-tuning. We evaluate SC-ADAS across scene-aware, conversational, and\nrevisited multi-turn interactions, highlighting trade-offs such as increased\nlatency from vision-based context retrieval and token growth from accumulated\ndialogue history. These results demonstrate the feasibility of combining\nconversational reasoning, scene perception, and modular ADAS control to support\nthe next generation of intelligent driver assistance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSC-ADAS\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u5f0fAI\u6280\u672f\u5b9e\u73b0\u573a\u666f\u611f\u77e5\u548c\u5bf9\u8bdd\u5f0fADAS\uff0c\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5176\u53ef\u884c\u6027\uff0c\u4f46\u4e5f\u5b58\u5728\u5ef6\u8fdf\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709ADAS\u7cfb\u7edf\u7f3a\u4e4f\u573a\u666f\u7406\u89e3\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faSC-ADAS\u6846\u67b6\uff0c\u6574\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u89c6\u89c9\u5230\u6587\u672c\u89e3\u6790\u7b49\u529f\u80fd\uff0c\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u548c\u573a\u666f\u611f\u77e5\u3002", "result": "\u7cfb\u7edf\u5728CARLA\u6a21\u62df\u5668\u4e2d\u9a8c\u8bc1\u53ef\u884c\uff0c\u4f46\u5b58\u5728\u89c6\u89c9\u4e0a\u4e0b\u6587\u68c0\u7d22\u5ef6\u8fdf\u7b49\u5c40\u9650\u6027\u3002", "conclusion": "SC-ADAS\u5c55\u793a\u4e86\u751f\u6210\u5f0fAI\u5728\u667a\u80fd\u9a7e\u9a76\u8f85\u52a9\u4e2d\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2507.10305", "pdf": "https://arxiv.org/pdf/2507.10305", "abs": "https://arxiv.org/abs/2507.10305", "authors": ["Linus Ververs", "Trang Linh Lam", "Janina Berger", "Lutz Prechelt"], "title": "A Grounded Theory on the Teacher and Student Roles in Pair Programming", "categories": ["cs.SE"], "comment": null, "summary": "Context: Pair programming is an established (agile) practice and is practiced\nthroughout the industry. Objective: Understand under what circumstances\nknowledge transfer can harm a pair programming session. Method: Grounded Theory\nMethodology based on 17 recorded pair programming sessions with 18 developers\nfrom 5 German software companies accompanied, by 6 interviews with different\ndevelopers from 4 other German companies. Results: We define the student and\nteacher roles to help developers deal with a one-sided knowledge gap. We\ndescribe pitfalls to avoid and develop a grounded theory centered around the\nPower Gap in pair programming. Conclusions: Knowledge transfer can be harmful\nwhen developers don't pay attention to their partners needs and desires. If\ndevelopers don't pay attention to the Power Gap and keep it in check, Defensive\nBehavior may arise that leads to a vicious cycle impacting the knowledge\ntransfer, the Togetherness and the code quality in a negative way.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\uff0c\u77e5\u8bc6\u8f6c\u79fb\u53ef\u80fd\u56e0\u5f00\u53d1\u8005\u5ffd\u89c6\u5bf9\u65b9\u7684\u2018\u6743\u529b\u5dee\u8ddd\u2019\u800c\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u5bfc\u81f4\u9632\u5fa1\u884c\u4e3a\u548c\u6076\u6027\u5faa\u73af\u3002", "motivation": "\u63a2\u8ba8\u5728\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u54ea\u4e9b\u60c5\u51b5\u4e0b\u77e5\u8bc6\u8f6c\u79fb\u4f1a\u5e26\u6765\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u5206\u679017\u6b21\u7ed3\u5bf9\u7f16\u7a0b\u4f1a\u8bdd\u8bb0\u5f55\u548c6\u6b21\u5f00\u53d1\u8005\u8bbf\u8c08\u3002", "result": "\u5b9a\u4e49\u4e86\u5b66\u751f\u548c\u6559\u5e08\u89d2\u8272\uff0c\u5e76\u56f4\u7ed5\u2018\u6743\u529b\u5dee\u8ddd\u2019\u63d0\u51fa\u7406\u8bba\uff0c\u6307\u51fa\u5176\u53ef\u80fd\u5bfc\u81f4\u9632\u5fa1\u884c\u4e3a\u548c\u8d1f\u9762\u5faa\u73af\u3002", "conclusion": "\u5ffd\u89c6\u2018\u6743\u529b\u5dee\u8ddd\u2019\u4f1a\u5bfc\u81f4\u9632\u5fa1\u884c\u4e3a\uff0c\u8fdb\u800c\u5bf9\u77e5\u8bc6\u8f6c\u79fb\u3001\u5408\u4f5c\u548c\u4ee3\u7801\u8d28\u91cf\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2507.10321", "pdf": "https://arxiv.org/pdf/2507.10321", "abs": "https://arxiv.org/abs/2507.10321", "authors": ["Viktor Sinitsyn", "Nils Schlautmann", "Florian Schwaiger", "Florian Holzapfel"], "title": "Streamlined Airborne Software Development for Large UAVs: From Unified Data Collection to Automated Code Generation", "categories": ["cs.SE", "cs.SY", "eess.SY"], "comment": null, "summary": "The aerospace industry has experienced significant transformations over the\nlast decade, driven by technological advancements and innovative solutions in\ngoods and personal transportation. This evolution has spurred the emergence of\nnumerous start-ups that now face challenges traditionally encountered by\nestablished aerospace companies. Among these challenges is the efficient\nprocessing of digital intra-device communication interfaces for onboard\nequipment - a critical component for ensuring seamless system integration and\nfunctionality. Addressing this challenge requires solutions that emphasize\nclear and consistent interface descriptions, automation of processes, and\nreduced labor-intensive efforts.\n  This paper presents a novel process and toolchain designed to streamline the\ndevelopment of digital interfaces and onboard software, which our team has\nsuccessfully applied in several completed projects. The proposed approach\nfocuses on automation and flexibility while maintaining compliance with design\nassurance requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4f18\u5316\u822a\u7a7a\u822a\u5929\u8bbe\u5907\u6570\u5b57\u63a5\u53e3\u5f00\u53d1\u7684\u81ea\u52a8\u5316\u5de5\u5177\u94fe\uff0c\u4ee5\u89e3\u51b3\u65b0\u521b\u516c\u53f8\u9762\u4e34\u7684\u4f20\u7edf\u6311\u6218\u3002", "motivation": "\u822a\u7a7a\u822a\u5929\u884c\u4e1a\u7684\u6570\u5b57\u5316\u8f6c\u578b\u548c\u65b0\u5174\u516c\u53f8\u7684\u5d1b\u8d77\u9700\u8981\u9ad8\u6548\u4e14\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u63a5\u53e3\u5f00\u53d1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d41\u7a0b\u548c\u5de5\u5177\u94fe\uff0c\u5f3a\u8c03\u81ea\u52a8\u5316\u3001\u7075\u6d3b\u6027\u5e76\u7b26\u5408\u8bbe\u8ba1\u4fdd\u969c\u8981\u6c42\u3002", "result": "\u8be5\u5de5\u5177\u94fe\u5df2\u5728\u591a\u4e2a\u9879\u76ee\u4e2d\u6210\u529f\u5e94\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u63a5\u53e3\u5f00\u53d1\u7684\u6548\u7387\uff0c\u540c\u65f6\u786e\u4fdd\u7cfb\u7edf\u6574\u5408\u7684\u987a\u7545\u6027\u3002"}}
{"id": "2507.10422", "pdf": "https://arxiv.org/pdf/2507.10422", "abs": "https://arxiv.org/abs/2507.10422", "authors": ["Tao Xiao", "Youmei Fan", "Fabio Calefato", "Christoph Treude", "Raula Gaikovina Kula", "Hideaki Hata", "Sebastian Baltes"], "title": "Self-Admitted GenAI Usage in Open-Source Software", "categories": ["cs.SE"], "comment": "17 pages, 8 tables, 1 figures, currently under review", "summary": "The widespread adoption of generative AI (GenAI) tools such as GitHub Copilot\nand ChatGPT is transforming software development. Since generated source code\nis virtually impossible to distinguish from manually written code, their\nreal-world usage and impact on open-source software development remain poorly\nunderstood. In this paper, we introduce the concept of self-admitted GenAI\nusage, that is, developers explicitly referring to the use of GenAI tools for\ncontent creation in software artifacts. Using this concept as a lens to study\nhow GenAI tools are integrated into open-source software projects, we analyze a\ncurated sample of more than 250,000 GitHub repositories, identifying 1,292 such\nself-admissions across 156 repositories in commit messages, code comments, and\nproject documentation. Using a mixed methods approach, we derive a taxonomy of\n32 tasks, 10 content types, and 11 purposes associated with GenAI usage based\non 284 qualitatively coded mentions. We then analyze 13 documents with policies\nand usage guidelines for GenAI tools and conduct a developer survey to uncover\nthe ethical, legal, and practical concerns behind them. Our findings reveal\nthat developers actively manage how GenAI is used in their projects,\nhighlighting the need for project-level transparency, attribution, and quality\ncontrol practices in the new era of AI-assisted software development. Finally,\nwe examine the longitudinal impact of GenAI adoption on code churn in 151\nrepositories with self-admitted GenAI usage and find no general increase,\ncontradicting popular narratives on the impact of GenAI on software\ndevelopment.", "AI": {"tldr": "\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\uff08\u5982GitHub Copilot\u548cChatGPT\uff09\u5728\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u7684\u4f7f\u7528\uff0c\u63d0\u51fa\u4e86\u201c\u81ea\u6211\u627f\u8ba4\u7684AI\u4f7f\u7528\u201d\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u4e86\u5176\u4efb\u52a1\u3001\u5185\u5bb9\u548c\u76ee\u7684\uff0c\u4ee5\u53ca\u5f00\u53d1\u8005\u7684\u4f26\u7406\u548c\u6cd5\u5f8b\u62c5\u5fe7\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u5f00\u6e90\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u4f7f\u7528\u548c\u5f71\u54cd\uff0c\u4ee5\u586b\u8865\u56e0\u96be\u4ee5\u533a\u5206AI\u751f\u6210\u4ee3\u7801\u548c\u624b\u52a8\u7f16\u5199\u4ee3\u7801\u800c\u5bfc\u81f4\u7684\u7406\u89e3\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u679025\u4e07\u591a\u4e2aGitHub\u4ee3\u7801\u5e93\u4e2d\u76841,292\u4e2a\u81ea\u6211\u627f\u8ba4\u7684AI\u4f7f\u7528\u6848\u4f8b\uff0c\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff08\u5b9a\u6027\u7f16\u7801\u548c\u5f00\u53d1\u8005\u8c03\u67e5\uff09\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86AI\u91c7\u7528\u5bf9\u4ee3\u7801\u53d8\u66f4\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5f00\u53d1\u8005\u79ef\u6781\u7ba1\u7406AI\u5de5\u5177\u7684\u4f7f\u7528\uff0c\u5f3a\u8c03\u900f\u660e\u5ea6\u548c\u8d28\u91cf\u63a7\u5236\uff1bAI\u91c7\u7528\u672a\u5bfc\u81f4\u4ee3\u7801\u53d8\u66f4\u7387\u7684\u666e\u904d\u589e\u52a0\u3002", "conclusion": "\u63ed\u793a\u4e86AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u9700\u5173\u6ce8\u900f\u660e\u5ea6\u548c\u8d28\u91cf\u63a7\u5236\u7684\u5b9e\u8df5\u9700\u6c42\uff0c\u5e76\u6311\u6218\u4e86\u5173\u4e8eAI\u5bf9\u5f00\u53d1\u6548\u7387\u5f71\u54cd\u7684\u6d41\u884c\u89c2\u70b9\u3002"}}
{"id": "2507.08848", "pdf": "https://arxiv.org/pdf/2507.08848", "abs": "https://arxiv.org/abs/2507.08848", "authors": ["Calum Corrie Imrie", "Ioannis Stefanakos", "Sepeedeh Shahbeigi", "Richard Hawkins", "Simon Burton"], "title": "Assuring the Safety of Reinforcement Learning Components: AMLAS-RL", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SE"], "comment": null, "summary": "The rapid advancement of machine learning (ML) has led to its increasing\nintegration into cyber-physical systems (CPS) across diverse domains. While CPS\noffer powerful capabilities, incorporating ML components introduces significant\nsafety and assurance challenges. Among ML techniques, reinforcement learning\n(RL) is particularly suited for CPS due to its capacity to handle complex,\ndynamic environments where explicit models of interaction between system and\nenvironment are unavailable or difficult to construct. However, in\nsafety-critical applications, this learning process must not only be effective\nbut demonstrably safe. Safe-RL methods aim to address this by incorporating\nsafety constraints during learning, yet they fall short in providing systematic\nassurance across the RL lifecycle. The AMLAS methodology offers structured\nguidance for assuring the safety of supervised learning components, but it does\nnot directly apply to the unique challenges posed by RL. In this paper, we\nadapt AMLAS to provide a framework for generating assurance arguments for an\nRL-enabled system through an iterative process; AMLAS-RL. We demonstrate\nAMLAS-RL using a running example of a wheeled vehicle tasked with reaching a\ntarget goal without collision.", "AI": {"tldr": "\u5c06AMLAS\u65b9\u6cd5\u6269\u5c55\u81f3RL\u9886\u57df\uff0c\u63d0\u51faAMLAS-RL\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u4e3aRL\u7cfb\u7edf\u751f\u6210\u5b89\u5168\u4fdd\u969c\u8bba\u8bc1\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728CPS\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46RL\u7684\u5b89\u5168\u6027\u4e0e\u7cfb\u7edf\u6027\u4fdd\u969c\u4e0d\u8db3\uff0c\u9700\u4e13\u95e8\u65b9\u6cd5\u786e\u4fdd\u5176\u5b89\u5168\u3002", "method": "\u6269\u5c55AMLAS\u65b9\u6cd5\uff0c\u63d0\u51faAMLAS-RL\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u4e3aRL\u7cfb\u7edf\u751f\u6210\u5b89\u5168\u4fdd\u969c\u8bba\u8bc1\uff0c\u5e76\u4ee5\u8f6e\u5f0f\u8f66\u8f86\u907f\u969c\u4e3a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u5c06AMLAS-RL\u5e94\u7528\u4e8e\u8f6e\u5f0f\u8f66\u8f86\u907f\u969c\u6848\u4f8b\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\u3002", "conclusion": "AMLAS-RL\u4e3aRL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u5b89\u5168\u4fdd\u969c\u6846\u67b6\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5728RL\u9886\u57df\u7684\u7a7a\u767d\u3002"}}
{"id": "2507.09036", "pdf": "https://arxiv.org/pdf/2507.09036", "abs": "https://arxiv.org/abs/2507.09036", "authors": ["Florian Kofler", "Marcel Rosier", "Mehdi Astaraki", "Hendrik M\u00f6ller", "Ilhem Isra Mekki", "Josef A. Buchner", "Anton Schmick", "Arianna Pfiffer", "Eva Oswald", "Lucas Zimmer", "Ezequiel de la Rosa", "Sarthak Pati", "Julian Canisius", "Arianna Piffer", "Ujjwal Baid", "Mahyar Valizadeh", "Akis Linardos", "Jan C. Peeken", "Surprosanna Shit", "Felix Steinbauer", "Daniel Rueckert", "Rolf Heckemann", "Spyridon Bakas", "Jan Kirschke", "Constantin von See", "Ivan Ezhov", "Marie Piraud", "Benedikt Wiestler", "Bjoern Menze"], "title": "BrainLesion Suite: A Flexible and User-Friendly Framework for Modular Brain Lesion Image Analysis", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SE"], "comment": "16p, 3f", "summary": "BrainLesion Suite is a versatile toolkit for building modular brain lesion\nimage analysis pipelines in Python. Following Pythonic principles, BrainLesion\nSuite is designed to provide a 'brainless' development experience, minimizing\ncognitive effort and streamlining the creation of complex workflows for\nclinical and scientific practice. At its core is an adaptable preprocessing\nmodule that performs co-registration, atlas registration, and optional\nskull-stripping and defacing on arbitrary multi-modal input images. BrainLesion\nSuite leverages algorithms from the BraTS challenge to synthesize missing\nmodalities, inpaint lesions, and generate pathology-specific tumor\nsegmentations. BrainLesion Suite also enables quantifying segmentation model\nperformance, with tools such as panoptica to compute lesion-wise metrics.\nAlthough BrainLesion Suite was originally developed for image analysis\npipelines of brain lesions such as glioma, metastasis, and multiple sclerosis,\nit can be adapted for other biomedical image analysis applications. The\nindividual BrainLesion Suite packages and tutorials are accessible on GitHub.", "AI": {"tldr": "BrainLesion Suite \u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u6a21\u5757\u5316\u8111\u90e8\u75c5\u53d8\u56fe\u50cf\u5206\u6790\u6d41\u7a0b\u7684 Python \u5de5\u5177\u5305\uff0c\u7b80\u5316\u5f00\u53d1\u6d41\u7a0b\u5e76\u63d0\u4f9b\u7075\u6d3b\u7684\u9884\u5904\u7406\u529f\u80fd\u3002", "motivation": "\u65e8\u5728\u4e3a\u4e34\u5e8a\u548c\u79d1\u7814\u5b9e\u8df5\u63d0\u4f9b\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u51cf\u5c11\u8ba4\u77e5\u8d1f\u62c5\uff0c\u7b80\u5316\u590d\u6742\u5de5\u4f5c\u6d41\u7684\u521b\u5efa\u3002", "method": "\u57fa\u4e8e Python\uff0c\u63d0\u4f9b\u9884\u5904\u7406\u6a21\u5757\uff08\u5305\u62ec\u914d\u51c6\u3001\u56fe\u8c31\u6ce8\u518c\u7b49\uff09\u3001\u652f\u6301\u6a21\u6001\u5408\u6210\u3001\u75c5\u7076\u4fee\u590d\u548c\u5206\u5272\u6027\u80fd\u8bc4\u4f30\u5de5\u5177\u3002", "result": "\u9002\u7528\u4e8e\u8111\u90e8\u75c5\u53d8\uff08\u5982\u80f6\u8d28\u7624\u3001\u8f6c\u79fb\u7624\u548c\u591a\u53d1\u6027\u786c\u5316\u75c7\uff09\u5206\u6790\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u751f\u7269\u533b\u5b66\u56fe\u50cf\u5e94\u7528\u3002", "conclusion": "BrainLesion Suite \u662f\u4e00\u4e2a\u529f\u80fd\u5f3a\u5927\u4e14\u6613\u4e8e\u6269\u5c55\u7684\u5de5\u5177\u5305\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u533b\u7597\u56fe\u50cf\u5206\u6790\u9700\u6c42\u3002"}}
{"id": "2507.10535", "pdf": "https://arxiv.org/pdf/2507.10535", "abs": "https://arxiv.org/abs/2507.10535", "authors": ["Hongchao Jiang", "Yiming Chen", "Yushi Cao", "Hung-yi Lee", "Robby T. Tan"], "title": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "Dataset is available at\n  https://huggingface.co/datasets/mattymchen/codejudgebench", "summary": "Large Language Models (LLMs) have significantly advanced the state-of-the-art\nin various coding tasks. Beyond directly answering user queries, LLMs can also\nserve as judges, assessing and comparing the quality of responses generated by\nother models. Such an evaluation capability is crucial both for benchmarking\ndifferent LLMs and for improving response quality through response ranking.\nHowever, despite the growing adoption of the LLM-as-a-Judge paradigm, its\neffectiveness in coding scenarios remains underexplored due to the absence of\ndedicated benchmarks. To address this gap, we introduce CodeJudgeBench, a\nbenchmark explicitly designed to evaluate the performance of LLM-as-a-Judge\nmodels across three critical coding tasks: code generation, code repair, and\nunit test generation. Through comprehensive benchmarking of 26 LLM-as-a-Judge\nmodels, we find that recent thinking models significantly outperform\nnon-thinking models on our carefully designed code judging tasks. Notably, even\nrelatively small thinking models, such as Qwen3-8B, can outperform specially\ntrained LLM-as-a-Judge models up to 70B in size. Nevertheless, all models still\nexhibit significant randomness in their judgment of coding tasks. For pairwise\njudging tasks, simply changing the order in which responses are presented can\nsubstantially impact accuracy. In addition, when judging code and unit tests\nwritten by different LLMs, LLM-as-a-Judge models also show variance in\nperformance. This sensitivity raises concerns about the reliability and\nconsistency of LLM-as-a-Judge in coding scenarios. Lastly, we study optimal\nprompting strategies for LLM-as-a-Judge. We find that using pair-wise\ncomparison outperforms scalar point-wise judging. Furthermore, retaining\ncomments and reasoning in the full, unprocessed LLM response leads to improved\njudge performance.", "AI": {"tldr": "CodeJudgeBench\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30LLM\u4f5c\u4e3a\u8bc4\u59d4\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u3001\u4fee\u590d\u548c\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u7684\u57fa\u51c6\uff0c\u7814\u7a76\u53d1\u73b0\u601d\u8003\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5b58\u5728\u663e\u8457\u968f\u673a\u6027\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u8bc4\u4f30LLM\u4f5c\u4e3a\u8bc4\u59d4\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u6548\u679c\u7684\u57fa\u51c6\uff0c\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u662f\u672c\u6587\u7684\u4e3b\u8981\u52a8\u673a\u3002", "method": "\u901a\u8fc7CodeJudgeBench\u57fa\u51c6\u6d4b\u8bd526\u4e2aLLM\u8bc4\u59d4\u6a21\u578b\uff0c\u5206\u6790\u5176\u5728\u4e09\u7c7b\u7f16\u7801\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u7814\u7a76\u63d0\u793a\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u601d\u8003\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u975e\u601d\u8003\u6a21\u578b\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5b58\u5728\u968f\u673a\u6027\uff1b\u914d\u5bf9\u6bd4\u8f83\u63d0\u793a\u7b56\u7565\u4f18\u4e8e\u70b9\u5f0f\u8bc4\u5206\uff0c\u4fdd\u7559\u5b8c\u6574\u89e3\u91ca\u63d0\u5347\u8bc4\u59d4\u8868\u73b0\u3002", "conclusion": "LLM\u4f5c\u4e3a\u8bc4\u59d4\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u89e3\u51b3\u968f\u673a\u6027\u548c\u654f\u611f\u6027\u95ee\u9898\u4ee5\u63d0\u5347\u53ef\u9760\u6027\u3002"}}
