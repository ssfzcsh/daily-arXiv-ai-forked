{"id": "2506.07771", "pdf": "https://arxiv.org/pdf/2506.07771", "abs": "https://arxiv.org/abs/2506.07771", "authors": ["Yulei Wang", "Yalin Liu", "Yaru Fu", "Zhiguo Ding"], "title": "Pinching-Antenna Systems For Indoor Immersive Communications: A 3D-Modeling Based Performance Analysis", "categories": ["cs.PF"], "comment": null, "summary": "The emerging pinching antenna (PA) technology has high flexibility to\nreconfigure wireless channels and combat line-of-sight blockage, thus holding\ntransformative potential for indoor immersive applications in 6G. This paper\ninvestigates Pinching-antenna systems (PASS) for indoor immersive\ncommunications. Our contributions are threefold: (1) we construct a 3D model to\ncharacterize the distribution of users, waveguides, and PAs in the PASS; (2) we\ndevelop a general theoretical model on downlink performance of PASS by\ncapturing PA-user relationships and system parameters' impacts; and (3) we\nconduct comprehensive numerical results of the theoretical model and provide\nimplementation guidelines for PASS deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u7528\u4e8e\u5ba4\u5185\u6c89\u6d78\u5f0f\u901a\u4fe1\u7684Pinching-antenna\u7cfb\u7edf\uff08PASS\uff09\uff0c\u63d0\u51fa\u4e863D\u6a21\u578b\u3001\u7406\u8bba\u6a21\u578b\u548c\u90e8\u7f72\u6307\u5357\u3002", "motivation": "\u63a2\u7d22Pinching\u5929\u7ebf\u6280\u672f\uff08PA\uff09\u57286G\u5ba4\u5185\u6c89\u6d78\u5f0f\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u89e3\u51b3\u89c6\u7ebf\u906e\u6321\u95ee\u9898\u3002", "method": "1. \u6784\u5efa3D\u6a21\u578b\u63cf\u8ff0\u7528\u6237\u3001\u6ce2\u5bfc\u548cPA\u7684\u5206\u5e03\uff1b2. \u5efa\u7acb\u7406\u8bba\u6a21\u578b\u5206\u6790\u4e0b\u884c\u94fe\u8def\u6027\u80fd\uff1b3. \u63d0\u4f9b\u6570\u503c\u7ed3\u679c\u548c\u90e8\u7f72\u6307\u5357\u3002", "result": "\u7406\u8bba\u6a21\u578b\u5f97\u5230\u9a8c\u8bc1\uff0c\u5e76\u63d0\u4f9b\u4e86PASS\u7cfb\u7edf\u7684\u90e8\u7f72\u5efa\u8bae\u3002", "conclusion": "PASS\u7cfb\u7edf\u57286G\u5ba4\u5185\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u7075\u6d3b\u914d\u7f6e\u65e0\u7ebf\u4fe1\u9053\u5e76\u89e3\u51b3\u89c6\u7ebf\u906e\u6321\u95ee\u9898\u3002"}}
{"id": "2506.06450", "pdf": "https://arxiv.org/pdf/2506.06450", "abs": "https://arxiv.org/abs/2506.06450", "authors": ["Antonio Jes\u00fas Banegas-Luna", "Baldomero Imbern\u00f3n Tudela", "Carlos Mart\u00ednez-Cort\u00e9s", "Jos\u00e9 Mar\u00eda Cecilia", "Horacio P\u00e9rez-S\u00e1nchez"], "title": "Performance Impact of Containerized METADOCK 2 on Heterogeneous Platforms", "categories": ["cs.DC", "cs.PF"], "comment": "20 pages, 5 figures, 2 tables", "summary": "Virtual screening (VS) is a computationally intensive process crucial for\ndrug discovery, often requiring significant resources to analyze large chemical\nlibraries and predict ligand-protein interactions. This study evaluates the\nperformance impact of containerization on METADOCK 2, a high-throughput docking\nsoftware when deployed on heterogeneous high-performance computing (HPC)\nplatforms. By testing three containerization technologies - Docker,\nSingularity, and Apptainer - across varying CPU and GPU configurations, the\nexperiments reveal that containerization introduces negligible performance\noverhead, with deviations below 1%. Moreover, METADOCK 2 demonstrated the\ncapability to efficiently process large molecular complexes, surpassing the\nlimitations of commercial tools such as AutoDock Vina. The results underscore\nthe advantages of container-based deployment for ensuring portability,\nreproducibility, and scalability in scientific computing. This study concludes\nthat containerized METADOCK 2 is a robust and efficient solution for VS tasks\non heterogeneous HPC platforms.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5bb9\u5668\u5316\u5bf9\u865a\u62df\u7b5b\u9009\u8f6f\u4ef6METADOCK 2\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u5e73\u53f0\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793a\u6027\u80fd\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff08\u4f4e\u4e8e1%\uff09\uff0c\u4e14\u80fd\u9ad8\u6548\u5904\u7406\u5927\u5206\u5b50\u590d\u5408\u7269\u3002", "motivation": "\u63a2\u8ba8\u5bb9\u5668\u5316\u6280\u672f\u5728\u9ad8\u901a\u91cf\u865a\u62df\u7b5b\u9009\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4ee5\u63d0\u9ad8\u79d1\u5b66\u8ba1\u7b97\u7684\u53ef\u79fb\u690d\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u6269\u5c55\u6027\u3002", "method": "\u6d4b\u8bd5\u4e09\u79cd\u5bb9\u5668\u5316\u6280\u672f\uff08Docker\u3001Singularity\u3001Apptainer\uff09\u5728\u4e0d\u540cCPU\u548cGPU\u914d\u7f6e\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u5bb9\u5668\u5316\u6027\u80fd\u5f00\u9500\u6781\u5c0f\uff0cMETADOCK 2\u8868\u73b0\u4f18\u4e8e\u5546\u4e1a\u5de5\u5177AutoDock Vina\uff0c\u80fd\u9ad8\u6548\u5904\u7406\u5927\u5206\u5b50\u590d\u5408\u7269\u3002", "conclusion": "\u5bb9\u5668\u5316\u7684METADOCK 2\u662f\u5f02\u6784\u9ad8\u6027\u80fd\u8ba1\u7b97\u5e73\u53f0\u4e0a\u865a\u62df\u7b5b\u9009\u4efb\u52a1\u7684\u5f3a\u5927\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06472", "pdf": "https://arxiv.org/pdf/2506.06472", "abs": "https://arxiv.org/abs/2506.06472", "authors": ["Ziqi Yuan", "Haoyang Zhang", "Yirui Eric Zhou", "Apoorve Mohan", "I-Hsin Chung", "Seetharami Seelam", "Jian Huang"], "title": "Cost-Efficient LLM Training with Lifetime-Aware Tensor Offloading via GPUDirect Storage", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "We present the design and implementation of a new lifetime-aware tensor\noffloading framework for GPU memory expansion using low-cost PCIe-based\nsolid-state drives (SSDs). Our framework, TERAIO, is developed explicitly for\nlarge language model (LLM) training with multiple GPUs and multiple SSDs. Its\ndesign is driven by our observation that the active tensors take only a small\nfraction (1.7% on average) of allocated GPU memory in each LLM training\niteration, the inactive tensors are usually large and will not be used for a\nlong period of time, creating ample opportunities for offloading/prefetching\ntensors to/from slow SSDs without stalling the GPU training process. TERAIO\naccurately estimates the lifetime (active period of time in GPU memory) of each\ntensor with the profiling of the first few iterations in the training process.\nWith the tensor lifetime analysis, TERAIO will generate an optimized tensor\noffloading/prefetching plan and integrate it into the compiled LLM program via\nPyTorch. TERAIO has a runtime tensor migration engine to execute the\noffloading/prefetching plan via GPUDirect storage, which allows direct tensor\nmigration between GPUs and SSDs for alleviating the CPU bottleneck and\nmaximizing the SSD bandwidth utilization. In comparison with state-of-the-art\nstudies such as ZeRO-Offload and ZeRO-Infinity, we show that TERAIO improves\nthe training performance of various LLMs by 1.47x on average, and achieves\n80.7% of the ideal performance assuming unlimited GPU memory.", "AI": {"tldr": "TERAIO\u662f\u4e00\u79cd\u57fa\u4e8eSSD\u7684GPU\u5185\u5b58\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5f20\u91cf\u751f\u547d\u5468\u671f\u4f18\u5316\u5378\u8f7d/\u9884\u53d6\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u5927\u90e8\u5206GPU\u5185\u5b58\u88ab\u672a\u6d3b\u8dc3\u4f7f\u7528\u7684\u5f20\u91cf\u5360\u7528\uff0c\u800c\u6d3b\u8dc3\u5f20\u91cf\u5360\u6bd4\u5f88\u5c0f\uff0c\u8fd9\u4e3a\u5378\u8f7d/\u9884\u53d6\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "TERAIO\u901a\u8fc7\u524d\u51e0\u6b21\u8fed\u4ee3\u5206\u6790\u5f20\u91cf\u751f\u547d\u5468\u671f\u5e76\u751f\u6210\u5378\u8f7d/\u9884\u53d6\u8ba1\u5212\uff0c\u5229\u7528GPUDirect\u5b58\u50a8\u76f4\u63a5\u5728GPU\u548cSSD\u95f4\u8fc1\u79fb\u5f20\u91cf\u3002", "result": "TERAIO\u5e73\u5747\u63d0\u5347\u8bad\u7ec3\u6027\u80fd1.47\u500d\uff0c\u8fbe\u5230\u7406\u60f3\u6027\u80fd\uff08\u65e0\u9650GPU\u5185\u5b58\u5047\u8bbe\uff09\u768480.7%\u3002", "conclusion": "TERAIO\u6709\u6548\u5229\u7528SSD\u6269\u5c55GPU\u5185\u5b58\uff0c\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2506.06773", "pdf": "https://arxiv.org/pdf/2506.06773", "abs": "https://arxiv.org/abs/2506.06773", "authors": ["Emet Behrendt", "Shing Wai Pun", "Prashant J. Nair"], "title": "Taming Wild Branches: Overcoming Hard-to-Predict Branches using the Bullseye Predictor", "categories": ["cs.AR", "cs.LG", "cs.PF", "C.1.2; B.2.1; C.4; C.0"], "comment": "Paper accepted and presented at the 6th Championship Branch\n  Prediction (CBP) workshop, co-held with ISCA 2025, on June 21, 2025, Tokyo,\n  Japan", "summary": "Branch prediction is key to the performance of out-of-order processors. While\nthe CBP-2016 winner TAGE-SC-L combines geometric-history tables, a statistical\ncorrector, and a loop predictor, over half of its remaining mispredictions stem\nfrom a small set of hard-to-predict (H2P) branches. These branches occur under\ndiverse global histories, causing repeated thrashing in TAGE and eviction\nbefore usefulness counters can mature. Prior work shows that simply enlarging\nthe tables offers only marginal improvement.\n  We augment a 159 KB TAGE-SC-L predictor with a 28 KB H2P-targeted subsystem\ncalled the Bullseye predictor. It identifies problematic PCs using a\nset-associative H2P Identification Table (HIT) and steers them to one of two\nbranch-specific perceptrons, one indexed by hashed local history and the other\nby folded global history. A short trial phase tracks head-to-head accuracy in\nan H2P cache. A branch becomes perceptron-resident only if the perceptron's\nsustained accuracy and output magnitude exceed dynamic thresholds, after which\nTAGE updates for that PC are suppressed to reduce pollution. The HIT, cache,\nand perceptron operate fully in parallel with TAGE-SC-L, providing higher\nfidelity on the H2P tail. This achieves an average MPKI of 3.4045 and CycWpPKI\nof 145.09.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBullseye\u7684\u9884\u6d4b\u5b50\u7cfb\u7edf\uff0c\u7528\u4e8e\u6539\u8fdbTAGE-SC-L\u5206\u652f\u9884\u6d4b\u5668\u5728\u5904\u7406\u96be\u4ee5\u9884\u6d4b\uff08H2P\uff09\u5206\u652f\u65f6\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u52a8\u6001\u9608\u503c\u548c\u5e76\u884c\u64cd\u4f5c\u51cf\u5c11\u9884\u6d4b\u9519\u8bef\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "TAGE-SC-L\u9884\u6d4b\u5668\u5728\u5904\u7406H2P\u5206\u652f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u7b80\u5355\u7684\u8868\u6269\u5927\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a28 KB\u7684Bullseye\u5b50\u7cfb\u7edf\uff0c\u901a\u8fc7H2P\u8bc6\u522b\u8868\uff08HIT\uff09\u548c\u4e24\u4e2a\u5206\u652f\u7279\u5b9a\u611f\u77e5\u5668\u6765\u52a8\u6001\u8bc6\u522b\u548c\u5904\u7406H2P\u5206\u652f\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9TAGE\u8868\u7684\u6c61\u67d3\u3002", "result": "Bullseye\u4e0eTAGE-SC-L\u5e76\u884c\u8fd0\u884c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9884\u6d4b\u9519\u8bef\u7387\uff08MPKI\u4e3a3.4045\uff0cCycWpPKI\u4e3a145.09\uff09\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u5236\u7684H2P\u5206\u652f\u5904\u7406\u673a\u5236\uff0cBullseye\u6709\u6548\u63d0\u5347\u4e86\u5206\u652f\u9884\u6d4b\u5668\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u590d\u6742\u5206\u652f\u65f6\u3002"}}
{"id": "2506.06870", "pdf": "https://arxiv.org/pdf/2506.06870", "abs": "https://arxiv.org/abs/2506.06870", "authors": ["Bugra Kilictas", "Faruk Alpay"], "title": "Recursive Semantic Anchoring in ISO 639:2023: A Structural Extension to ISO/TC 37 Frameworks", "categories": ["cs.LO", "cs.AI", "03B70, 18M05, 68T50", "F.4.1; I.2.7"], "comment": "21 pages, no figures. Includes formal proofs, RDF/Turtle ontology\n  schema, {\\phi}-index disambiguation cases, and evaluation of\n  transformer-based AI models under semantic drift", "summary": "ISO 639:2023 unifies the ISO language-code family and introduces contextual\nmetadata, but it lacks a machine-native mechanism for handling dialectal drift\nand creole mixtures. We propose a formalisation of recursive semantic\nanchoring, attaching to every language entity $\\chi$ a family of fixed-point\noperators $\\phi_{n,m}$ that model bounded semantic drift via the relation\n$\\phi_{n,m}(\\chi) = \\chi \\oplus \\Delta(\\chi)$, where $\\Delta(\\chi)$ is a drift\nvector in a latent semantic manifold. The base anchor $\\phi_{0,0}$ recovers the\ncanonical ISO 639:2023 identity, whereas $\\phi_{99,9}$ marks the maximal drift\nstate that triggers a deterministic fallback. Using category theory, we treat\nthe operators $\\phi_{n,m}$ as morphisms and drift vectors as arrows in a\ncategory $\\mathrm{DriftLang}$. A functor $\\Phi: \\mathrm{DriftLang} \\to\n\\mathrm{AnchorLang}$ maps every drifted object to its unique anchor and proves\nconvergence. We provide an RDF/Turtle schema (\\texttt{BaseLanguage},\n\\texttt{DriftedLanguage}, \\texttt{ResolvedAnchor}) and worked examples -- e.g.,\n$\\phi_{8,4}$ (Standard Mandarin) versus $\\phi_{8,7}$ (a colloquial variant),\nand $\\phi_{1,7}$ for Nigerian Pidgin anchored to English. Experiments with\ntransformer models show higher accuracy in language identification and\ntranslation on noisy or code-switched input when the $\\phi$-indices are used to\nguide fallback routing. The framework is compatible with ISO/TC 37 and provides\nan AI-tractable, drift-aware semantic layer for future standards.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9012\u5f52\u8bed\u4e49\u951a\u5b9a\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fa\u5b9a\u70b9\u7b97\u5b50\u5efa\u6a21\u8bed\u8a00\u53d8\u4f53\u7684\u8bed\u4e49\u6f02\u79fb\uff0c\u4e3aISO 639:2023\u63d0\u4f9b\u4e86\u4e00\u79cd\u673a\u5668\u53cb\u597d\u7684\u5904\u7406\u673a\u5236\u3002", "motivation": "ISO 639:2023\u7f3a\u4e4f\u5904\u7406\u65b9\u8a00\u6f02\u79fb\u548c\u514b\u91cc\u5965\u5c14\u8bed\u6df7\u5408\u7684\u673a\u5236\uff0c\u5e0c\u671b\u901a\u8fc7\u6570\u5b66\u6a21\u578b\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u56fa\u5b9a\u70b9\u7b97\u5b50\u548c\u8bed\u4e49\u6f02\u79fb\u5411\u91cf\u5efa\u6a21\u8bed\u8a00\u53d8\u4f53\u7684\u8bed\u4e49\u53d8\u5316\uff0c\u5e76\u901a\u8fc7\u8303\u7574\u8bba\u548cRDF/Turtle\u6a21\u5f0f\u5b9e\u73b0\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u8bed\u4e49\u951a\u5b9a\u7684\u65b9\u6cd5\u5728\u8bed\u8a00\u8bc6\u522b\u548c\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u5c24\u5176\u662f\u5728\u566a\u58f0\u6216\u4ee3\u7801\u5207\u6362\u8f93\u5165\u65f6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u8bed\u8a00\u6807\u51c6\u7684\u8bed\u4e49\u5c42\u63d0\u4f9b\u4e86AI\u53ef\u5904\u7406\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5bb9ISO/TC 37\u3002"}}
{"id": "2506.06478", "pdf": "https://arxiv.org/pdf/2506.06478", "abs": "https://arxiv.org/abs/2506.06478", "authors": ["Sowmiya Dhandapani"], "title": "Enhancing Software Supply Chain Security Through STRIDE-Based Threat Modelling of CI/CD Pipelines", "categories": ["cs.SE"], "comment": null, "summary": "With the increasing adoption of Continuous Integration and Continuous\nDeployment pipelines, securing software supply chains has become a critical\nchallenge for modern DevOps teams. This study addresses these challenges by\napplying a structured threat modeling approach to identify and mitigate risks\nthroughout the CI/CD lifecycle. By modeling a representative pipeline\narchitecture incorporating tools such as GitHub, Jenkins, Docker, and\nKubernetes and applying the STRIDE framework, we systematically analyze\nvulnerabilities at each stage, from source code management to deployment.\nThreats are documented and mapped to comprehensive security controls drawn from\nstandards like NIST SP 800-218, OWASP Top 10 CI/CD risks, and the SLSA\nframework. Controls are further evaluated against SLSA maturity levels to\nassess improvements in trust and provenance. To operationalize these findings,\nthe study outlines a practical security toolchain integration strategy grounded\nin Security as Code and Shift Left-Shield Right principles, enabling automated,\nenforceable security across the pipeline. This approach provides a pragmatic\nroadmap for enhancing CI/CD pipeline security against evolving software supply\nchain threats.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5a01\u80c1\u5efa\u6a21\u65b9\u6cd5\u8bc6\u522b\u548c\u7f13\u89e3CI/CD\u751f\u547d\u5468\u671f\u4e2d\u7684\u98ce\u9669\uff0c\u8bc4\u4f30\u5b89\u5168\u63a7\u5236\u5e76\u63d0\u51fa\u5de5\u5177\u94fe\u96c6\u6210\u7b56\u7565\u3002", "motivation": "\u968f\u7740CI/CD\u7ba1\u9053\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4fdd\u969c\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u6210\u4e3aDevOps\u56e2\u961f\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u4f7f\u7528STRIDE\u6846\u67b6\u5efa\u6a21\u5178\u578bCI/CD\u7ba1\u9053\uff0c\u7ed3\u5408NIST\u3001OWASP\u3001SLSA\u6807\u51c6\u5206\u6790\u6f0f\u6d1e\u5e76\u5236\u5b9a\u5b89\u5168\u63a7\u5236\u63aa\u65bd\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8eSecurity as Code\u548cShift Left-Shield Right\u539f\u5219\u7684\u81ea\u52a8\u5316\u5b89\u5168\u5de5\u5177\u94fe\u96c6\u6210\u7b56\u7565\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63d0\u5347CI/CD\u7ba1\u9053\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u7ebf\u56fe\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5a01\u80c1\u3002"}}
{"id": "2506.06447", "pdf": "https://arxiv.org/pdf/2506.06447", "abs": "https://arxiv.org/abs/2506.06447", "authors": ["Jacob Erickson"], "title": "Fake Friends and Sponsored Ads: The Risks of Advertising in Conversational Search", "categories": ["cs.HC", "cs.CY"], "comment": "Accepted for publication at ACM CUI 2025", "summary": "Digital commerce thrives on advertising, with many of the largest technology\ncompanies relying on it as a significant source of revenue. However, in the\ncontext of information-seeking behavior, such as search, advertising may\ndegrade the user experience by lowering search quality, misusing user data for\ninappropriate personalization, potentially misleading individuals, or even\nleading them toward harm. These challenges remain significant as conversational\nsearch technologies, such as ChatGPT, become widespread. This paper critically\nexamines the future of advertising in conversational search, utilizing several\nspeculative examples to illustrate the potential risks posed to users who seek\nguidance on sensitive topics. Additionally, it provides an overview of the\nforms that advertising might take in this space and introduces the \"fake friend\ndilemma,\" the idea that a conversational agent may exploit unaligned user trust\nto achieve other objectives. This study presents a provocative discussion on\nthe future of online advertising in the space of conversational search and ends\nwith a call to action.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5bf9\u8bdd\u641c\u7d22\u4e2d\u7684\u5e7f\u544a\u95ee\u9898\uff0c\u6307\u51fa\u5176\u5bf9\u7528\u6237\u4f53\u9a8c\u7684\u6f5c\u5728\u5371\u5bb3\uff0c\u5e76\u63d0\u51fa\u4e86\u201c\u5047\u670b\u53cb\u56f0\u5883\u201d\u7684\u6982\u5ff5\uff0c\u547c\u5401\u91c7\u53d6\u884c\u52a8\u4ee5\u907f\u514d\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u5bf9\u8bdd\u641c\u7d22\u6280\u672f\uff08\u5982ChatGPT\uff09\u7684\u666e\u53ca\uff0c\u5e7f\u544a\u53ef\u80fd\u5bf9\u7528\u6237\u7684\u4fe1\u606f\u5bfb\u6c42\u884c\u4e3a\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u5305\u62ec\u964d\u4f4e\u641c\u7d22\u8d28\u91cf\u3001\u6ee5\u7528\u7528\u6237\u6570\u636e\u6216\u8bef\u5bfc\u7528\u6237\uff0c\u5c24\u5176\u662f\u654f\u611f\u8bdd\u9898\u7684\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u63a8\u6d4b\u6027\u6848\u4f8b\u6279\u5224\u6027\u5730\u5206\u6790\u5e7f\u544a\u5728\u5bf9\u8bdd\u641c\u7d22\u4e2d\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u5e7f\u544a\u53ef\u80fd\u7684\u5f62\u5f0f\u548c\u201c\u5047\u670b\u53cb\u56f0\u5883\u201d\u7684\u6982\u5ff5\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5e7f\u544a\u5728\u5bf9\u8bdd\u641c\u7d22\u4e2d\u53ef\u80fd\u5bf9\u7528\u6237\u9020\u6210\u7684\u5371\u5bb3\uff0c\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u7528\u6237\u4fe1\u4efb\u5b9e\u73b0\u5176\u4ed6\u76ee\u6807\u7684\u673a\u5236\u3002", "conclusion": "\u8bba\u6587\u547c\u5401\u5173\u6ce8\u5bf9\u8bdd\u641c\u7d22\u4e2d\u5e7f\u544a\u7684\u6f5c\u5728\u98ce\u9669\u5e76\u63d0\u51fa\u884c\u52a8\u5efa\u8bae\uff0c\u4ee5\u907f\u514d\u672a\u6765\u53ef\u80fd\u51fa\u73b0\u7684\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2506.06469", "pdf": "https://arxiv.org/pdf/2506.06469", "abs": "https://arxiv.org/abs/2506.06469", "authors": ["Anil Madhavapeddy", "Sam Reynolds", "Alec P. Christie", "David A. Coomes", "Michael W. Dales", "Patrick Ferris", "Ryan Gibb", "Hamed Haddadi", "Sadiq Jaffer", "Josh Millar", "Cyrus Omar", "William J. Sutherland", "Jon Crowcroft"], "title": "Steps towards an Ecology for the Internet", "categories": ["cs.NI", "cs.ET"], "comment": "To appear in the sixth decennial Aarhus conference: Computing X\n  Crisis, Aug 2025", "summary": "The Internet has grown from a humble set of protocols for end-to-end\nconnectivity into a critical global system with no builtin \"immune system\". In\nthe next decade the Internet will likely grow to a trillion nodes and need\nprotection from threats ranging from floods of fake generative data to\nAI-driven malware. Unfortunately, growing centralisation has lead to the\nbreakdown of mutualism across the network, with surveillance capitalism now the\ndominant business model. We take lessons from from biological systems towards\nevolving a more resilient Internet that can integrate adaptation mechanisms\ninto its fabric. We also contribute ideas for how the Internet might\nincorporate digital immune systems, including how software stacks might mutate\nto encourage more architectural diversity. We strongly advocate for the\nInternet to \"re-decentralise\" towards incentivising more mutualistic forms of\ncommunication.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e92\u8054\u7f51\u672a\u6765\u7684\u5b89\u5168\u6311\u6218\uff0c\u501f\u9274\u751f\u7269\u7cfb\u7edf\u63d0\u51fa\u6784\u5efa\u66f4\u5177\u5f39\u6027\u7684\u4e92\u8054\u7f51\uff0c\u5e76\u5021\u5bfc\u53bb\u4e2d\u5fc3\u5316\u4ee5\u4fc3\u8fdb\u4e92\u5229\u901a\u4fe1\u3002", "motivation": "\u4e92\u8054\u7f51\u7f3a\u4e4f\u5185\u7f6e\u7684\u514d\u75ab\u7cfb\u7edf\uff0c\u672a\u6765\u53ef\u80fd\u9762\u4e34\u4e07\u4ebf\u8282\u70b9\u548cAI\u9a71\u52a8\u7684\u5a01\u80c1\uff0c\u5f53\u524d\u8fc7\u5ea6\u4e2d\u5fc3\u5316\u5bfc\u81f4\u4e92\u60e0\u5173\u7cfb\u5d29\u6e83\u3002", "method": "\u4ece\u751f\u7269\u7cfb\u7edf\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u63d0\u51fa\u5c06\u9002\u5e94\u6027\u673a\u5236\u878d\u5165\u4e92\u8054\u7f51\u67b6\u6784\uff0c\u8bbe\u8ba1\u6570\u5b57\u514d\u75ab\u7cfb\u7edf\u5e76\u63d0\u5021\u8f6f\u4ef6\u6808\u591a\u6837\u5316\u3002", "result": "\u63d0\u51fa\u4e86\u4e92\u8054\u7f51\u53bb\u4e2d\u5fc3\u5316\u7684\u5efa\u8bae\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u6570\u5b57\u514d\u75ab\u7cfb\u7edf\u589e\u5f3a\u5176\u5f39\u6027\u3002", "conclusion": "\u4e92\u8054\u7f51\u9700\u8981\u91cd\u65b0\u53bb\u4e2d\u5fc3\u5316\uff0c\u5e76\u901a\u8fc7\u751f\u7269\u542f\u53d1\u7684\u65b9\u6cd5\u63d0\u5347\u5176\u9002\u5e94\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2506.06495", "pdf": "https://arxiv.org/pdf/2506.06495", "abs": "https://arxiv.org/abs/2506.06495", "authors": ["Hiromi Ishii", "Taro Shimizu", "Toshiki Teramura"], "title": "Optimizing Optimizations: Case Study on Detecting Specific Types of Mathematical Optimization Constraints with E-Graphs in JijModeling", "categories": ["cs.PL", "cs.MS", "math.OC"], "comment": "To be presented at EGRAPHS '25\n  https://pldi25.sigplan.org/home/egraphs-2025", "summary": "In solving mathematical optimization problems efficiently, it is crucial to\nmake use of information about specific types of constraints, such as the\none-hot or Special-Ordered Set (SOS) constraints. In many cases, exploiting\nsuch information gives asymptotically better execution time. JijModeling, an\nindustrial-strength mathematical optimization modeller, achieves this by\nseparating the symbolic representation of an optimization problem from the\ninput data. In this paper, we will report a real-world case study on a\nconstraint detection mechanism modulo the algebraic congruence using e-graphs,\nand describe heuristic criteria for designing rewriting systems. We give\nbenchmarking result that shows the performance impact of the constraint\ndetection mechanism.\n  We also introduce egg_recursive, a utility library for writing egg-terms as\nrecursive abstract syntax trees, reducing the burden of writing and maintaining\ncomplex terms in S-expressions.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u7279\u5b9a\u7ea6\u675f\u4fe1\u606f\uff08\u5982one-hot\u6216SOS\u7ea6\u675f\uff09\u6765\u63d0\u9ad8\u6570\u5b66\u4f18\u5316\u95ee\u9898\u7684\u6548\u7387\uff0c\u5e76\u901a\u8fc7JijModeling\u5b9e\u73b0\u7b26\u53f7\u8868\u793a\u4e0e\u8f93\u5165\u6570\u636e\u7684\u5206\u79bb\u3002\u6587\u4e2d\u63d0\u51fa\u4e86\u57fa\u4e8ee-graph\u7684\u7ea6\u675f\u68c0\u6d4b\u673a\u5236\u548c\u542f\u53d1\u5f0f\u91cd\u5199\u7cfb\u7edf\u6807\u51c6\uff0c\u5e76\u5c55\u793a\u4e86\u6027\u80fd\u6d4b\u8bd5\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86egg_recursive\u5de5\u5177\u5e93\uff0c\u7528\u4e8e\u7b80\u5316\u590d\u6742S\u8868\u8fbe\u5f0f\u7684\u7f16\u5199\u548c\u7ef4\u62a4\u3002", "motivation": "\u5229\u7528\u7279\u5b9a\u7ea6\u675f\u4fe1\u606f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6570\u5b66\u4f18\u5316\u95ee\u9898\u7684\u6267\u884c\u6548\u7387\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u7b26\u53f7\u8868\u793a\u548c\u6570\u636e\u5904\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7JijModeling\u5206\u79bb\u7b26\u53f7\u8868\u793a\u4e0e\u8f93\u5165\u6570\u636e\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8ee-graph\u7684\u7ea6\u675f\u68c0\u6d4b\u673a\u5236\u548c\u542f\u53d1\u5f0f\u91cd\u5199\u7cfb\u7edf\u6807\u51c6\u3002", "result": "\u6027\u80fd\u6d4b\u8bd5\u8868\u660e\u7ea6\u675f\u68c0\u6d4b\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u4f18\u5316\u95ee\u9898\u7684\u6267\u884c\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u7ea6\u675f\u68c0\u6d4b\u548c\u7b26\u53f7\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u4f18\u5316\u95ee\u9898\u7684\u89e3\u51b3\u6548\u7387\uff0c\u5e76\u4e3a\u590d\u6742S\u8868\u8fbe\u5f0f\u7684\u7ba1\u7406\u63d0\u4f9b\u4e86\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2506.06541", "pdf": "https://arxiv.org/pdf/2506.06541", "abs": "https://arxiv.org/abs/2506.06541", "authors": ["Eugenie Lai", "Gerardo Vitagliano", "Ziyu Zhang", "Sivaprasad Sudhir", "Om Chabra", "Anna Zeng", "Anton A. Zabreyko", "Chenning Li", "Ferdi Kossmann", "Jialin Ding", "Jun Chen", "Markos Markakis", "Matthew Russo", "Weiyang Wang", "Ziniu Wu", "Michael J. Cafarella", "Lei Cao", "Samuel Madden", "Tim Kraska"], "title": "KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes", "categories": ["cs.DB", "cs.AI", "cs.MA"], "comment": null, "summary": "Constructing real-world data-to-insight pipelines often involves data\nextraction from data lakes, data integration across heterogeneous data sources,\nand diverse operations from data cleaning to analysis. The design and\nimplementation of data science pipelines require domain knowledge, technical\nexpertise, and even project-specific insights. AI systems have shown remarkable\nreasoning, coding, and understanding capabilities. However, it remains unclear\nto what extent these capabilities translate into successful design and\nexecution of such complex pipelines. We introduce KRAMABENCH: a benchmark\ncomposed of 104 manually-curated real-world data science pipelines spanning\n1700 data files from 24 data sources in 6 different domains. We show that these\npipelines test the end-to-end capabilities of AI systems on data processing,\nrequiring data discovery, wrangling and cleaning, efficient processing,\nstatistical reasoning, and orchestrating data processing steps given a\nhigh-level task. Our evaluation tests 5 general models and 3 code generation\nmodels using our reference framework, DS-GURU, which instructs the AI model to\ndecompose a question into a sequence of subtasks, reason through each step, and\nsynthesize Python code that implements the proposed design. Our results on\nKRAMABENCH show that, although the models are sufficiently capable of solving\nwell-specified data science code generation tasks, when extensive data\nprocessing and domain knowledge are required to construct real-world data\nscience pipelines, existing out-of-box models fall short. Progress on\nKramaBench represents crucial steps towards developing autonomous data science\nagents for real-world applications. Our code, reference framework, and data are\navailable at https://github.com/mitdbg/KramaBench.", "AI": {"tldr": "KRAMABENCH\u662f\u4e00\u4e2a\u5305\u542b104\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u79d1\u5b66\u7ba1\u9053\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u6570\u636e\u5904\u7406\u65b9\u9762\u7684\u7aef\u5230\u7aef\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u7ba1\u9053\u8bbe\u8ba1\u4e0a\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u7814\u7a76\u63a2\u7d22AI\u7cfb\u7edf\u662f\u5426\u80fd\u591f\u6210\u529f\u8bbe\u8ba1\u548c\u6267\u884c\u590d\u6742\u7684\u6570\u636e\u79d1\u5b66\u7ba1\u9053\uff0c\u586b\u8865\u73b0\u6709\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u624b\u52a8\u6574\u7406\u7684104\u4e2a\u771f\u5b9e\u6570\u636e\u79d1\u5b66\u7ba1\u9053\u6d4b\u8bd55\u4e2a\u901a\u7528\u6a21\u578b\u548c3\u4e2a\u4ee3\u7801\u751f\u6210\u6a21\u578b\uff0c\u4f7f\u7528DS-GURU\u6846\u67b6\u6307\u5bfcAI\u6a21\u578b\u5206\u89e3\u4efb\u52a1\u5e76\u751f\u6210\u4ee3\u7801\u3002", "result": "\u73b0\u6709\u6a21\u578b\u5728\u660e\u786e\u7684\u6570\u636e\u79d1\u5b66\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u5927\u91cf\u6570\u636e\u5904\u7406\u548c\u9886\u57df\u77e5\u8bc6\u7684\u590d\u6742\u7ba1\u9053\u8bbe\u8ba1\u4e2d\u8868\u73b0\u4e0d\u8db3\u3002", "conclusion": "KRAMABENCH\u4e3a\u5f00\u53d1\u81ea\u4e3b\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u8fc8\u51fa\u4e86\u5173\u952e\u4e00\u6b65\uff0c\u4f46\u4ecd\u9700\u6539\u8fdbAI\u6a21\u578b\u5728\u590d\u6742\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2506.06381", "pdf": "https://arxiv.org/pdf/2506.06381", "abs": "https://arxiv.org/abs/2506.06381", "authors": ["Trisanth Srinivasan", "Santosh Patapati", "Himani Musku", "Idhant Gode", "Aditya Arora", "Samvit Bhattacharya", "Abubakr Nazriev", "Sanika Hirave", "Zaryab Kanjiani", "Srinjoy Ghose", "Srinidhi Shetty"], "title": "CPS-Guard: Framework for Dependability Assurance of AI- and LLM-Based Cyber-Physical Systems", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.HC", "cs.MA", "C.3; C.4; D.2.4; D.4.6; I.2.7"], "comment": null, "summary": "Cyber-Physical Systems (CPS) increasingly depend on advanced AI techniques to\noperate in critical applications. However, traditional verification and\nvalidation methods often struggle to handle the unpredictable and dynamic\nnature of AI components. In this paper, we introduce CPS-Guard, a novel\nframework that employs multi-role orchestration to automate the iterative\nassurance process for AI-powered CPS. By assigning specialized roles (e.g.,\nsafety monitoring, security assessment, fault injection, and recovery planning)\nto dedicated agents within a simulated environment, CPS-Guard continuously\nevaluates and refines AI behavior against a range of dependability\nrequirements. We demonstrate the framework through a case study involving an\nautonomous vehicle navigating an intersection with an AI-based planner. Our\nresults show that CPS-Guard effectively detects vulnerabilities, manages\nperformance impacts, and supports adaptive recovery strategies, thereby\noffering a structured and extensible solution for rigorous V&V in safety- and\nsecurity-critical systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86CPS-Guard\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89d2\u8272\u7f16\u6392\u81ea\u52a8\u5316AI\u9a71\u52a8\u7684CPS\u7684\u9a8c\u8bc1\u4e0e\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9AI\u7ec4\u4ef6\u7684\u52a8\u6001\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u591a\u89d2\u8272\u7f16\u6392\uff0c\u5728\u6a21\u62df\u73af\u5883\u4e2d\u901a\u8fc7\u4e13\u7528\u4ee3\u7406\uff08\u5982\u5b89\u5168\u76d1\u63a7\u3001\u5b89\u5168\u8bc4\u4f30\u3001\u6545\u969c\u6ce8\u5165\u7b49\uff09\u6301\u7eed\u8bc4\u4f30\u548c\u6539\u8fdbAI\u884c\u4e3a\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660eCPS-Guard\u80fd\u6709\u6548\u68c0\u6d4b\u6f0f\u6d1e\u3001\u7ba1\u7406\u6027\u80fd\u5f71\u54cd\u5e76\u652f\u6301\u81ea\u9002\u5e94\u6062\u590d\u7b56\u7565\u3002", "conclusion": "CPS-Guard\u4e3a\u5b89\u5168\u548c\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u7ed3\u6784\u5316\u9a8c\u8bc1\u4e0e\u9a8c\u8bc1\u65b9\u6848\u3002"}}
{"id": "2506.06448", "pdf": "https://arxiv.org/pdf/2506.06448", "abs": "https://arxiv.org/abs/2506.06448", "authors": ["Vaastav Anand", "Matheus Stolet", "Jonathan Mace", "Antoine Kaufmann"], "title": "Generating representative macrobenchmark microservice systems from distributed traces with Palette", "categories": ["cs.DC"], "comment": null, "summary": "Microservices are the dominant design for developing cloud systems\n  today. Advancements for microservice need to be evaluated in representative\nsystems, e.g. with matching scale, topology, and execution patterns.\n  Unfortunately in practice, researchers and practitioners alike often do not\nhave access to representative systems. Thus they have to resort to sub-optimal\nnon-representative alternatives, e.g. small and oversimplified synthetic\nbenchmark systems or simulated system models instead.\n  To solve this issue, we propose the use of distributed trace datasets,\navailable from large internet companies,\n  to generate representative microservice systems.\n  To do so, we introduce a novel abstraction of a system topology which uses\nGraphical Causal Models (GCMs)\n  to model the underlying system by incorporating the branching probabilities,\nexecution order of outgoing\n  calls to every dependency, and execution times.\n  We then incorporate this topology in Palette, a system that generates\n  representative flexible macrobenchmarks microservice systems from distributed\ntraces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5206\u5e03\u5f0f\u8ddf\u8e2a\u6570\u636e\u96c6\u751f\u6210\u4ee3\u8868\u6027\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u7814\u7a76\u4e2d\u7f3a\u4e4f\u4ee3\u8868\u6027\u7cfb\u7edf\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u7814\u7a76\u548c\u5b9e\u8df5\u4e2d\u7f3a\u4e4f\u5177\u6709\u4ee3\u8868\u6027\u7684\u5fae\u670d\u52a1\u7cfb\u7edf\uff08\u5982\u89c4\u6a21\u3001\u62d3\u6251\u548c\u6267\u884c\u6a21\u5f0f\u5339\u914d\u7684\u7cfb\u7edf\uff09\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u5e03\u5f0f\u8ddf\u8e2a\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u6765\u751f\u6210\u4ee3\u8868\u6027\u7cfb\u7edf\uff0c\u4ee5\u4fc3\u8fdb\u5fae\u670d\u52a1\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "\u4f7f\u7528\u56fe\u5f62\u56e0\u679c\u6a21\u578b\uff08GCMs\uff09\u62bd\u8c61\u7cfb\u7edf\u62d3\u6251\uff0c\u5305\u62ec\u5206\u652f\u6982\u7387\u3001\u8c03\u7528\u6267\u884c\u987a\u5e8f\u548c\u6267\u884c\u65f6\u95f4\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230Palette\u7cfb\u7edf\u4e2d\uff0c\u4ece\u5206\u5e03\u5f0f\u8ddf\u8e2a\u751f\u6210\u7075\u6d3b\u7684\u5b8f\u89c2\u57fa\u51c6\u5fae\u670d\u52a1\u7cfb\u7edf\u3002", "result": "Palette\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u5177\u6709\u4ee3\u8868\u6027\u7684\u5fae\u670d\u52a1\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u7814\u7a76\u4e2d\u7f3a\u4e4f\u771f\u5b9e\u7cfb\u7edf\u7684\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u5206\u5e03\u5f0f\u8ddf\u8e2a\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u4e00\u79cd\u751f\u6210\u4ee3\u8868\u6027\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.06693", "pdf": "https://arxiv.org/pdf/2506.06693", "abs": "https://arxiv.org/abs/2506.06693", "authors": ["Priyanshu Yadav"], "title": "Design and Implementation of a RISC-V SoC with Custom DSP Accelerators for Edge Computing", "categories": ["cs.AR", "cs.AI", "eess.SP", "C.1.3, B.5.2, I.5.1 C.1.3, B.5.2, I.5.1 C.1.3, B.5.2, I.5.1"], "comment": "12 Pages, 1 figure", "summary": "This paper presents a comprehensive analysis of the RISC-V instruction set\narchitecture, focusing on its modular design, implementation challenges, and\nperformance characteristics. We examine the RV32I base instruction set with\nextensions for multiplication (M) and atomic operations (A). Through\ncycle-accurate simulation of a pipelined implementation, we evaluate\nperformance metrics including CPI (cycles per instruction) and power\nefficiency. Our results demonstrate RISC-V's advantages in embedded systems and\nits scalability for custom accelerators. Comparative analysis shows a 17%\nreduction in power consumption compared to ARM Cortex-M0 implementations in\nsimilar process nodes. The open-standard nature of RISC-V provides significant\nflexibility for domain-specific optimizations.", "AI": {"tldr": "\u8bba\u6587\u5bf9RISC-V\u6307\u4ee4\u96c6\u67b6\u6784\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u3001\u5b9e\u73b0\u6311\u6218\u548c\u6027\u80fd\u7279\u5f81\u3002\u901a\u8fc7RV32I\u57fa\u7840\u6307\u4ee4\u96c6\u53ca\u5176\u6269\u5c55\uff08\u4e58\u6cd5\u548c\u539f\u5b50\u64cd\u4f5c\uff09\u7684\u5468\u671f\u7cbe\u786e\u6a21\u62df\uff0c\u8bc4\u4f30\u4e86CPI\u548c\u80fd\u6548\u3002\u7ed3\u679c\u8868\u660e\uff0cRISC-V\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u4e14\u9002\u5408\u81ea\u5b9a\u4e49\u52a0\u901f\u5668\u3002\u4e0eARM Cortex-M0\u76f8\u6bd4\uff0c\u529f\u8017\u964d\u4f4e\u4e8617%\u3002", "motivation": "\u7814\u7a76RISC-V\u6307\u4ee4\u96c6\u67b6\u6784\u7684\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u6027\u80fd\u7279\u5f81\uff0c\u4ee5\u9a8c\u8bc1\u5176\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u81ea\u5b9a\u4e49\u52a0\u901f\u5668\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528RV32I\u57fa\u7840\u6307\u4ee4\u96c6\u53ca\u5176\u6269\u5c55\uff08\u4e58\u6cd5\u548c\u539f\u5b50\u64cd\u4f5c\uff09\uff0c\u901a\u8fc7\u5468\u671f\u7cbe\u786e\u7684\u6d41\u6c34\u7ebf\u6a21\u62df\uff0c\u8bc4\u4f30CPI\u548c\u80fd\u6548\u3002", "result": "RISC-V\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u529f\u8017\u6bd4ARM Cortex-M0\u964d\u4f4e\u4e8617%\uff0c\u4e14\u5177\u6709\u9ad8\u5ea6\u7684\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "RISC-V\u4f5c\u4e3a\u5f00\u653e\u6807\u51c6\uff0c\u5177\u6709\u663e\u8457\u7684\u7075\u6d3b\u6027\u548c\u6027\u80fd\u4f18\u52bf\uff0c\u5c24\u5176\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u5b9a\u5236\u5316\u5e94\u7528\u4e2d\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.06817", "pdf": "https://arxiv.org/pdf/2506.06817", "abs": "https://arxiv.org/abs/2506.06817", "authors": ["Haoran Wu", "Ce Guo", "Wayne Luk", "Robert Mullins"], "title": "ASPO: Constraint-Aware Bayesian Optimization for FPGA-based Soft Processors", "categories": ["cs.AR", "cs.LG", "cs.NE", "cs.PF"], "comment": "Accepted to International Conference on Field-Programmable Logic and\n  Applications (FPL) 2025", "summary": "Bayesian Optimization (BO) has shown promise in tuning processor design\nparameters. However, standard BO does not support constraints involving\ncategorical parameters such as types of branch predictors and division\ncircuits. In addition, optimization time of BO grows with processor complexity,\nwhich becomes increasingly significant especially for FPGA-based soft\nprocessors. This paper introduces ASPO, an approach that leverages disjunctive\nform to enable BO to handle constraints involving categorical parameters.\nUnlike existing methods that directly apply standard BO, the proposed ASPO\nmethod, for the first time, customizes the mathematical mechanism of BO to\naddress challenges faced by soft-processor designs on FPGAs. Specifically, ASPO\nsupports categorical parameters using a novel customized BO covariance kernel.\nIt also accelerates the design evaluation procedure by penalizing the BO\nacquisition function with potential evaluation time and by reusing FPGA\nsynthesis checkpoints from previously evaluated configurations. ASPO targets\nthree soft processors: RocketChip, BOOM, and EL2 VeeR. The approach is\nevaluated based on seven RISC-V benchmarks. Results show that ASPO can reduce\nexecution time for the ``multiply'' benchmark on the BOOM processor by up to\n35\\% compared to the default configuration. Furthermore, it reduces design time\nfor the BOOM processor by up to 74\\% compared to Boomerang, a state-of-the-art\nhardware-oriented BO approach.", "AI": {"tldr": "ASPO\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6807\u51c6BO\u5728\u5904\u7406\u5206\u7c7b\u53c2\u6570\u7ea6\u675f\u548c\u4f18\u5316\u65f6\u95f4\u589e\u957f\u95ee\u9898\uff0c\u7279\u522b\u9488\u5bf9FPGA\u8f6f\u5904\u7406\u5668\u8bbe\u8ba1\u3002", "motivation": "\u6807\u51c6\u8d1d\u53f6\u65af\u4f18\u5316\uff08BO\uff09\u65e0\u6cd5\u5904\u7406\u5206\u7c7b\u53c2\u6570\u7ea6\u675f\uff0c\u4e14\u4f18\u5316\u65f6\u95f4\u968f\u5904\u7406\u5668\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u5c24\u5176\u662f\u5728FPGA\u8f6f\u5904\u7406\u5668\u8bbe\u8ba1\u4e2d\u66f4\u4e3a\u663e\u8457\u3002", "method": "ASPO\u901a\u8fc7\u5b9a\u5236BO\u7684\u6570\u5b66\u673a\u5236\uff0c\u4f7f\u7528\u65b0\u578b\u534f\u65b9\u5dee\u6838\u652f\u6301\u5206\u7c7b\u53c2\u6570\uff0c\u5e76\u901a\u8fc7\u60e9\u7f5a\u91c7\u96c6\u51fd\u6570\u548c\u590d\u7528FPGA\u5408\u6210\u68c0\u67e5\u70b9\u52a0\u901f\u8bbe\u8ba1\u8bc4\u4f30\u3002", "result": "ASPO\u5728BOOM\u5904\u7406\u5668\u4e0a\u4e3a\u4e58\u6cd5\u57fa\u51c6\u6d4b\u8bd5\u51cf\u5c11\u4e8635%\u7684\u6267\u884c\u65f6\u95f4\uff0c\u5e76\u5c06\u8bbe\u8ba1\u65f6\u95f4\u51cf\u5c11\u4e8674%\uff0c\u4f18\u4e8e\u73b0\u6709\u786c\u4ef6\u5bfc\u5411BO\u65b9\u6cd5\u3002", "conclusion": "ASPO\u4e3aFPGA\u8f6f\u5904\u7406\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u8bbe\u8ba1\u65f6\u95f4\u3002"}}
{"id": "2506.07635", "pdf": "https://arxiv.org/pdf/2506.07635", "abs": "https://arxiv.org/abs/2506.07635", "authors": ["Siwei Hu", "Victor Lopata", "Sadegh Soudjani", "Paolo Zuliani"], "title": "Verification of Quantum Circuits through Barrier Certificates using a Scenario Approach", "categories": ["cs.LO", "quant-ph"], "comment": null, "summary": "In recent years, various techniques have been explored for the verification\nof quantum circuits, including the use of barrier certificates, mathematical\ntools capable of demonstrating the correctness of such systems. These\ncertificates ensure that, starting from initial states and applying the\nsystem's dynamics, the system will never reach undesired states. In this paper,\nwe propose a methodology for synthesizing such certificates for quantum\ncircuits using a scenario-based approach, for both finite and infinite time\nhorizons. In addition, our approach can handle uncertainty in the initial\nstates and in the system's dynamics. We present several case studies on quantum\ncircuits, comparing the performance of different types of barrier certificate\nand analyzing which one is most suitable for each case.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5408\u6210\u91cf\u5b50\u7535\u8def\u7684\u5c4f\u969c\u8bc1\u4e66\uff0c\u4ee5\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\uff0c\u9002\u7528\u4e8e\u6709\u9650\u548c\u65e0\u9650\u65f6\u95f4\u8303\u56f4\uff0c\u5e76\u80fd\u5904\u7406\u521d\u59cb\u72b6\u6001\u548c\u7cfb\u7edf\u52a8\u6001\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u91cf\u5b50\u7535\u8def\u7684\u9a8c\u8bc1\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u5c4f\u969c\u8bc1\u4e66\u4f5c\u4e3a\u4e00\u79cd\u6570\u5b66\u5de5\u5177\u53ef\u4ee5\u786e\u4fdd\u7cfb\u7edf\u4ece\u521d\u59cb\u72b6\u6001\u51fa\u53d1\u4e14\u5e94\u7528\u7cfb\u7edf\u52a8\u6001\u540e\u4e0d\u4f1a\u8fdb\u5165\u4e0d\u671f\u671b\u7684\u72b6\u6001\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\u5408\u6210\u5c4f\u969c\u8bc1\u4e66\uff0c\u5e76\u8003\u8651\u521d\u59cb\u72b6\u6001\u548c\u7cfb\u7edf\u52a8\u6001\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u91cf\u5b50\u7535\u8def\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u7c7b\u578b\u5c4f\u969c\u8bc1\u4e66\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u5404\u81ea\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u9a8c\u8bc1\u91cf\u5b50\u7535\u8def\u7684\u6b63\u786e\u6027\uff0c\u5e76\u4e3a\u9009\u62e9\u5408\u9002\u7684\u5c4f\u969c\u8bc1\u4e66\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2506.06508", "pdf": "https://arxiv.org/pdf/2506.06508", "abs": "https://arxiv.org/abs/2506.06508", "authors": ["Adriano Torres", "Sebastian Baltes", "Christoph Treude", "Markus Wagner"], "title": "Information-Theoretic Detection of Unusual Source Code Changes", "categories": ["cs.SE"], "comment": "48 pages, 17 figures, 7 tables, accepted for publication in the\n  Empirical Software Engineering journal", "summary": "The code base of software projects evolves essentially through inserting and\nremoving information to and from the source code. We can measure this evolution\nvia the elements of information - tokens, words, nodes - of the respective\nrepresentation of the code. In this work, we approach the measurement of the\ninformation content of the source code of open-source projects from an\ninformation-theoretic standpoint. Our focus is on the entropy of two\nfundamental representations of code: tokens and abstract syntax tree nodes,\nfrom which we derive definitions of textual and structural entropy. We proceed\nwith an empirical assessment where we evaluate the evolution patterns of the\nentropy of 95 actively maintained open source projects. We calculate the\nstatistical relationships between our derived entropy metrics and classic\nmethods of measuring code complexity and learn that entropy may capture\ndifferent dimensions of complexity than classic metrics. Finally, we conduct\nentropy-based anomaly detection of unusual changes to demonstrate that our\napproach may effectively recognise unusual source code change events with over\n60% precision, and lay the groundwork for improvements to information-theoretic\nmeasurement of source code evolution, thus paving the way for a new approach to\nstatically gauging program complexity throughout its development.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u7684\u89c6\u89d2\uff0c\u6d4b\u91cf\u5f00\u6e90\u9879\u76ee\u4e2d\u6e90\u4ee3\u7801\u7684\u4fe1\u606f\u5185\u5bb9\uff0c\u5b9a\u4e49\u4e86\u6587\u672c\u548c\u7ed3\u6784\u71b5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u4e0e\u7ecf\u5178\u4ee3\u7801\u590d\u6742\u5ea6\u6307\u6807\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u71b5\u80fd\u6355\u6349\u4e0d\u540c\u7684\u590d\u6742\u5ea6\u7ef4\u5ea6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u6d4b\u91cf\u6e90\u4ee3\u7801\u7684\u6f14\u5316\uff0c\u4ee5\u71b5\u4f5c\u4e3a\u8861\u91cf\u6307\u6807\uff0c\u63a2\u7d22\u5176\u4e0e\u4ee3\u7801\u590d\u6742\u5ea6\u7684\u5173\u7cfb\uff0c\u5e76\u9a8c\u8bc1\u71b5\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u8bba\u6587\u5b9a\u4e49\u4e86\u57fa\u4e8etoken\u548c\u62bd\u8c61\u8bed\u6cd5\u6811\u8282\u70b9\u7684\u6587\u672c\u548c\u7ed3\u6784\u71b5\uff0c\u901a\u8fc7\u5206\u679095\u4e2a\u5f00\u6e90\u9879\u76ee\u7684\u6f14\u5316\u6a21\u5f0f\uff0c\u8bc4\u4f30\u71b5\u4e0e\u4f20\u7edf\u590d\u6742\u5ea6\u6307\u6807\u7684\u5173\u7cfb\uff0c\u5e76\u8fdb\u884c\u71b5\u57fa\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u71b5\u80fd\u6355\u6349\u4e0e\u7ecf\u5178\u590d\u6742\u5ea6\u6307\u6807\u4e0d\u540c\u7684\u7ef4\u5ea6\uff0c\u71b5\u57fa\u5f02\u5e38\u68c0\u6d4b\u7684\u7cbe\u5ea6\u8d85\u8fc760%\u3002", "conclusion": "\u8bba\u6587\u4e3a\u4fe1\u606f\u8bba\u65b9\u6cd5\u5728\u4ee3\u7801\u6f14\u5316\u6d4b\u91cf\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f00\u521b\u4e86\u4e00\u79cd\u9759\u6001\u8861\u91cf\u7a0b\u5e8f\u590d\u6742\u5ea6\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2506.06473", "pdf": "https://arxiv.org/pdf/2506.06473", "abs": "https://arxiv.org/abs/2506.06473", "authors": ["Imran Fahad", "Danny Scott", "Azizul Zahid", "Matthew Bringle", "Srinayana Patil", "Ella Bevins", "Carmen Palileo", "Sai Swaminathan"], "title": "RadioGami: Batteryless, Long-Range Wireless Paper Sensors Using Tunnel Diodes", "categories": ["cs.HC", "J.0"], "comment": "The paper is published in the Proceedings of the ACM on Interactive,\n  Mobile, Wearable and Ubiquitous Technologies (IMWUT) and will be presented at\n  UbiComp 2025", "summary": "Paper-based interactive RF devices have opened new possibilities for wireless\nsensing, yet they are typically constrained by short operational ranges. This\npaper introduces RadioGami, a method for creating long-range, batteryless RF\nsensing surfaces on paper using low-cost, DIY materials like copper tape,\npaper, and off-the-shelf electronics paired with an affordable radio receiver\n(approx. $20). We explore the design space enabled by RadioGami, including\nsensing paper deformations like bending, tearing, and origami patterns (Miura,\nKresling) at ranges up to 45.73 meters. RadioGami employs a novel ultra-low\npower (35uW) switching circuit with a tunnel diode for wireless functionality.\nThese surfaces can sustainably operate by harvesting energy using tiny\nphotodiodes. We demonstrate applications that monitor object status, track user\ninteractions (rotation, sliding), and detect environmental changes. We\ncharacterize performance, sensitivity, range, and power consumption with\ndeployment studies. RadioGami advances sustainable, tangible, and batteryless\ninterfaces for embodied interaction.", "AI": {"tldr": "RadioGami\u662f\u4e00\u79cd\u4f4e\u6210\u672c\u3001DIY\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7eb8\u57fa\u6750\u6599\u5b9e\u73b0\u957f\u8ddd\u79bb\u3001\u65e0\u7535\u6c60\u7684\u5c04\u9891\u4f20\u611f\u8868\u9762\uff0c\u53ef\u611f\u77e5\u7eb8\u5f20\u53d8\u5f62\u548c\u73af\u5883\u53d8\u5316\u3002", "motivation": "\u4f20\u7edf\u7eb8\u57faRF\u8bbe\u5907\u53d7\u9650\u4e8e\u77ed\u8ddd\u79bb\u64cd\u4f5c\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6301\u7eed\u3001\u53ef\u4ea4\u4e92\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u94dc\u5e26\u3001\u7eb8\u5f20\u548c\u73b0\u6210\u7535\u5b50\u5668\u4ef6\uff0c\u7ed3\u5408\u8d85\u4f4e\u529f\u8017\u5f00\u5173\u7535\u8def\u548c\u96a7\u9053\u4e8c\u6781\u7ba1\uff0c\u5b9e\u73b0\u8fdc\u8ddd\u79bb\u65e0\u7ebf\u4f20\u611f\u3002", "result": "\u80fd\u591f\u572845.73\u7c73\u8303\u56f4\u5185\u611f\u77e5\u7eb8\u5f20\u53d8\u5f62\uff08\u5982\u5f2f\u66f2\u3001\u6495\u88c2\u3001\u6298\u7eb8\uff09\uff0c\u5e76\u53ef\u6301\u7eed\u8fd0\u884c\u3002", "conclusion": "RadioGami\u4e3a\u53ef\u6301\u7eed\u3001\u65e0\u7535\u6c60\u7684\u4ea4\u4e92\u754c\u9762\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.06688", "pdf": "https://arxiv.org/pdf/2506.06688", "abs": "https://arxiv.org/abs/2506.06688", "authors": ["Heerok Banerjee"], "title": "A Comparative Analyses Of Network Formation In Low-power Lossy Networks: ContikiMAC vs Orchestra-enabled TSCH", "categories": ["cs.NI"], "comment": null, "summary": "Medium Access Control (MAC) layer protocols are the underlying paradigms\nwhich dictate the transmission & reception of data in any network. Particularly\nfor Low-powered Lossy Networks (LLNs), the design and selection of appropiate\nMAC-layer protocols is crucial inorder to satisfy several networking objectives\nsuch as joining time, network lifetime, energy consumption, end-to-end-delay,\netc. In this report, we have presented a comparative analysis between\nContiki-MAC and Orchestra-enabled TSCH protocol which provides insights towards\nthe network joining & convergence time as well as an estimate of the energy\nconsumption required of build such LLNs. Our results indicates that Contiki-MAC\noutperforms Orchestra-enabled TSCH by a factor of 13 times in network\nformation.", "AI": {"tldr": "\u5bf9Contiki-MAC\u548cOrchestra-enabled TSCH\u534f\u8bae\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0cContiki-MAC\u5728\u7f51\u7edc\u5f62\u6210\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u540e\u800513\u500d\u3002", "motivation": "\u9488\u5bf9\u4f4e\u529f\u8017\u6709\u635f\u7f51\u7edc\uff08LLNs\uff09\uff0c\u9009\u62e9\u5408\u9002\u7684MAC\u5c42\u534f\u8bae\u5bf9\u6ee1\u8db3\u7f51\u7edc\u76ee\u6807\uff08\u5982\u52a0\u5165\u65f6\u95f4\u3001\u7f51\u7edc\u5bff\u547d\u3001\u80fd\u8017\u7b49\uff09\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83Contiki-MAC\u548cOrchestra-enabled TSCH\u534f\u8bae\u7684\u7f51\u7edc\u52a0\u5165\u3001\u6536\u655b\u65f6\u95f4\u53ca\u80fd\u8017\u3002", "result": "Contiki-MAC\u5728\u7f51\u7edc\u5f62\u6210\u65b9\u9762\u7684\u6027\u80fd\u4f18\u4e8eOrchestra-enabled TSCH 13\u500d\u3002", "conclusion": "Contiki-MAC\u66f4\u9002\u5408\u7528\u4e8e\u4f4e\u529f\u8017\u6709\u635f\u7f51\u7edc\u7684\u6784\u5efa\u3002"}}
{"id": "2506.06544", "pdf": "https://arxiv.org/pdf/2506.06544", "abs": "https://arxiv.org/abs/2506.06544", "authors": ["Sophia Drossopoulou", "Julian Mackay", "Susan Eisenbach", "James Noble"], "title": "Reasoning about External Calls", "categories": ["cs.PL"], "comment": "86 pages, 25 main paper, and 58 pages of appendices, many diagrams\n  and figures", "summary": "In today's complex software, internal trusted code is tightly intertwined\nwith external untrusted code. To reason about internal code, programmers must\nreason about the potential effects of calls to external code, even though that\ncode is not trusted and may not even be available. The effects of external\ncalls can be limited, if internal code is programmed defensively, limiting\npotential effects by limiting access to the capabilities necessary to cause\nthose effects.\n  This paper addresses the specification and verification of internal code that\nrelies on encapsulation and object capabilities to limit the effects of\nexternal calls. We propose new assertions for access to capabilities, new\nspecifications for limiting effects, and a Hoare logic to verify that a module\nsatisfies its specification, even while making external calls. We illustrate\nthe approach though a running example with mechanised proofs, and prove\nsoundness of the Hoare logic.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89c4\u8303\u5316\u548c\u9a8c\u8bc1\u5185\u90e8\u4ee3\u7801\uff0c\u901a\u8fc7\u5c01\u88c5\u548c\u80fd\u529b\u9650\u5236\u6765\u63a7\u5236\u5916\u90e8\u8c03\u7528\u7684\u5f71\u54cd\u3002", "motivation": "\u5728\u590d\u6742\u8f6f\u4ef6\u4e2d\uff0c\u5185\u90e8\u53ef\u4fe1\u4ee3\u7801\u4e0e\u5916\u90e8\u4e0d\u53ef\u4fe1\u4ee3\u7801\u7d27\u5bc6\u4ea4\u7ec7\uff0c\u9700\u9650\u5236\u5916\u90e8\u8c03\u7528\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u65b0\u7684\u80fd\u529b\u8bbf\u95ee\u65ad\u8a00\u3001\u6548\u679c\u9650\u5236\u89c4\u8303\u53caHoare\u903b\u8f91\uff0c\u9a8c\u8bc1\u6a21\u5757\u6ee1\u8db3\u89c4\u8303\u3002", "result": "\u901a\u8fc7\u8fd0\u884c\u793a\u4f8b\u548c\u673a\u68b0\u5316\u8bc1\u660e\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc1\u660e\u4e86Hoare\u903b\u8f91\u7684\u5408\u7406\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u786e\u4fdd\u4e86\u5185\u90e8\u4ee3\u7801\u7684\u53ef\u9760\u6027\uff0c\u5373\u4f7f\u5728\u5916\u90e8\u8c03\u7528\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2506.07675", "pdf": "https://arxiv.org/pdf/2506.07675", "abs": "https://arxiv.org/abs/2506.07675", "authors": ["Yuyang Song", "Hanxu Yan", "Jiale Lao", "Yibo Wang", "Yufei Li", "Yuanchun Zhou", "Jianguo Wang", "Mingjie Tang"], "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "categories": ["cs.DB"], "comment": null, "summary": "Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle.", "AI": {"tldr": "QUITE\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u6846\u67b6\u548c\u5b9e\u65f6\u6570\u636e\u5e93\u53cd\u9988\uff0c\u5c06SQL\u67e5\u8be2\u91cd\u5199\u4e3a\u6027\u80fd\u66f4\u597d\u7684\u7b49\u6548\u5f62\u5f0f\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684SQL\u67e5\u8be2\u91cd\u5199\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5904\u7406\u65b0\u67e5\u8be2\u6a21\u5f0f\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u5229\u7528LLM\u7684\u8bed\u4e49\u548c\u63a8\u7406\u80fd\u529b\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u67e5\u8be2\u91cd\u5199\u3002", "method": "\u63d0\u51faQUITE\u7cfb\u7edf\uff0c\u91c7\u7528\u8bad\u7ec3\u65e0\u5173\u7684\u591a\u4ee3\u7406\u6846\u67b6\u548c\u6709\u9650\u72b6\u6001\u673a\uff0c\u7ed3\u5408\u5b9e\u65f6\u53cd\u9988\u548c\u63d0\u793a\u6ce8\u5165\u6280\u672f\uff0c\u4f18\u5316\u67e5\u8be2\u91cd\u5199\u8fc7\u7a0b\u3002", "result": "QUITE\u5c06\u67e5\u8be2\u6267\u884c\u65f6\u95f4\u51cf\u5c1135.8%\uff0c\u751f\u621024.1%\u66f4\u591a\u91cd\u5199\uff0c\u8986\u76d6\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7684\u67e5\u8be2\u6848\u4f8b\u3002", "conclusion": "QUITE\u901a\u8fc7LLM\u548c\u53cd\u9988\u673a\u5236\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u8986\u76d6\u9762\u66f4\u5e7f\u7684SQL\u67e5\u8be2\u91cd\u5199\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.06459", "pdf": "https://arxiv.org/pdf/2506.06459", "abs": "https://arxiv.org/abs/2506.06459", "authors": ["Ruitao Chen", "Mozhang Guo", "Jinge Li"], "title": "Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control", "categories": ["cs.LG", "cs.ET", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Automated driving (AD) has substantially improved vehicle safety and driving\ncomfort, but their impact on passenger well-being, particularly infant sleep,\nis not sufficiently studied. Sudden acceleration, abrupt braking, and sharp\nmaneuvers can disrupt infant sleep, compromising both passenger comfort and\nparental convenience. To solve this problem, this paper explores the\nintegration of reinforcement learning (RL) within AD to personalize driving\nbehavior and optimally balance occupant comfort and travel efficiency. In\nparticular, we propose an intelligent cruise control framework that adapts to\nvarying driving conditions to enhance infant sleep quality by effectively\nsynergizing wearable sensing and vehicle data. Long short-term memory (LSTM)\nand transformer-based neural networks are integrated with RL to model the\nrelationship between driving behavior and infant sleep quality under diverse\ntraffic and road conditions. Based on the sleep quality indicators from the\nwearable sensors, driving action data from vehicle controllers, and map data\nfrom map applications, the model dynamically computes the optimal driving\naggressiveness level, which is subsequently translated into specific AD control\nstrategies, e.g., the magnitude and frequency of acceleration, lane change, and\novertaking. Simulation results demonstrate that the proposed solution\nsignificantly improves infant sleep quality compared to baseline methods, while\npreserving desirable travel efficiency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u81ea\u52a8\u9a7e\u9a76\u884c\u4e3a\uff0c\u63d0\u5347\u5a74\u513f\u7761\u7720\u8d28\u91cf\uff0c\u540c\u65f6\u517c\u987e\u51fa\u884c\u6548\u7387\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u867d\u63d0\u5347\u4e86\u5b89\u5168\u6027\u548c\u8212\u9002\u6027\uff0c\u4f46\u5176\u5bf9\u5a74\u513f\u7761\u7720\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u7a81\u52a0\u51cf\u901f\u548c\u6025\u8f6c\u5f2f\u53ef\u80fd\u6270\u4e71\u5a74\u513f\u7761\u7720\uff0c\u5f71\u54cd\u4e58\u5ba2\u8212\u9002\u5ea6\u548c\u5bb6\u957f\u4fbf\u5229\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u667a\u80fd\u5de1\u822a\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0e\u8f66\u8f86\u6570\u636e\uff0c\u5229\u7528LSTM\u548cTransformer\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u9a7e\u9a76\u884c\u4e3a\u4e0e\u5a74\u513f\u7761\u7720\u8d28\u91cf\u7684\u5173\u7cfb\u3002\u8be5\u65b9\u6cd5\u6839\u636e\u4f20\u611f\u5668\u3001\u8f66\u8f86\u63a7\u5236\u5668\u548c\u5730\u56fe\u6570\u636e\u52a8\u6001\u4f18\u5316\u9a7e\u9a76\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6848\u663e\u8457\u63d0\u5347\u4e86\u5a74\u513f\u7761\u7720\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u51fa\u884c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4e0e\u591a\u6e90\u6570\u636e\u878d\u5408\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u4f18\u5316\u4e86\u81ea\u52a8\u9a7e\u9a76\u884c\u4e3a\uff0c\u4e3a\u63d0\u5347\u5a74\u513f\u7761\u7720\u8d28\u91cf\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.06769", "pdf": "https://arxiv.org/pdf/2506.06769", "abs": "https://arxiv.org/abs/2506.06769", "authors": ["Miryeong Kwon", "Donghyun Gouk", "Eunjee Na", "Jiseon Kim", "Junhee Kim", "Hyein Woo", "Eojin Ryu", "Hyunkyu Choi", "Jinwoo Baek", "Hanyeoreum Bae", "Mahmut Kandemir", "Myoungsoo Jung"], "title": "Containerized In-Storage Processing and Computing-Enabled SSD Disaggregation", "categories": ["cs.AR"], "comment": null, "summary": "ISP minimizes data transfer for analytics but faces challenges in adaptation\nand disaggregation. We propose DockerSSD, an ISP model leveraging OS-level\nvirtualization and lightweight firmware to enable containerized data processing\ndirectly on SSDs. Key features include Ethernet over NVMe for network-based ISP\nmanagement and Virtual Firmware for secure, efficient container execution.\nDockerSSD supports disaggregated storage pools, reducing host overhead and\nenhancing large-scale services like LLM inference. It achieves up to 2.0x\nbetter performance for I/O-intensive workloads, and 7.9x improvement in\ndistributed LLM inference.", "AI": {"tldr": "DockerSSD\u662f\u4e00\u79cd\u5229\u7528OS\u7ea7\u865a\u62df\u5316\u548c\u8f7b\u91cf\u7ea7\u56fa\u4ef6\u7684ISP\u6a21\u578b\uff0c\u76f4\u63a5\u5728SSD\u4e0a\u5b9e\u73b0\u5bb9\u5668\u5316\u6570\u636e\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u5206\u5e03\u5f0fLLM\u63a8\u7406\u6548\u7387\u3002", "motivation": "ISP\u9700\u89e3\u51b3\u6570\u636e\u5206\u6790\u548c\u89e3\u8026\u5b58\u50a8\u7684\u6311\u6218\uff0cDockerSSD\u901a\u8fc7\u521b\u65b0\u8bbe\u8ba1\u4f18\u5316\u6570\u636e\u7ba1\u7406\u548c\u5904\u7406\u6548\u7387\u3002", "method": "\u7ed3\u5408OS\u7ea7\u865a\u62df\u5316\u3001\u8f7b\u91cf\u7ea7\u56fa\u4ef6\uff0c\u652f\u6301\u57fa\u4e8e\u7f51\u7edc\u7684ISP\u7ba1\u7406\u53ca\u5b89\u5168\u7684\u5bb9\u5668\u8fd0\u884c\u3002", "result": "I/O\u5bc6\u96c6\u578b\u4efb\u52a1\u6027\u80fd\u63d0\u53472.0\u500d\uff0c\u5206\u5e03\u5f0fLLM\u63a8\u7406\u6548\u7387\u63d0\u53477.9\u500d\u3002", "conclusion": "DockerSSD\u4e3a\u5927\u89c4\u6a21\u670d\u52a1\u63d0\u4f9b\u9ad8\u6548\u3001\u4f4e\u5f00\u9500\u7684\u89e3\u8026\u5b58\u50a8\u65b9\u6848\uff0c\u6027\u80fd\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2506.06691", "pdf": "https://arxiv.org/pdf/2506.06691", "abs": "https://arxiv.org/abs/2506.06691", "authors": ["Kaushik Talathi", "Aparna Santra Biswas"], "title": "An Efficient Digital Watermarking Technique for Small Scale devices", "categories": ["cs.MM", "cs.CR"], "comment": "28 pages, 11 figures, 4 tables", "summary": "In the age of IoT and mobile platforms, ensuring that content stay authentic\nwhilst avoiding overburdening limited hardware is a key problem. This study\nintroduces hybrid Fast Wavelet Transform & Additive Quantization index\nModulation (FWT-AQIM) scheme, a lightweight watermarking approach that secures\ndigital pictures on low-power, memory-constrained small scale devices to\nachieve a balanced trade-off among robustness, imperceptibility, and\ncomputational efficiency. The method embeds watermark in the luminance\ncomponent of YCbCr color space using low-frequency FWT sub-bands, minimizing\nperceptual distortion, using additive QIM for simplicity. Both the extraction\nand embedding processes run in less than 40 ms and require minimum RAM when\ntested on a Raspberry Pi 5. Quality assessments on standard and high-resolution\nimages yield PSNR greater than equal to 34 dB and SSIM greater than equal to\n0.97, while robustness verification includes various geometric and\nsignal-processing attacks demonstrating near-zero bit error rates and NCC\ngreater than equal to 0.998. Using a mosaic-based watermark, redundancy added\nenhancing robustness without reducing throughput, which peaks at 11 MP/s. These\nfindings show that FWT-AQIM provides an efficient, scalable solution for\nreal-time, secure watermarking in bandwidth- and power-constrained contexts,\nopening the way for dependable content protection in developing IoT and\nmultimedia applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6c34\u5370\u65b9\u6848FWT-AQIM\uff0c\u9002\u7528\u4e8e\u4f4e\u529f\u8017\u8bbe\u5907\uff0c\u5728\u9c81\u68d2\u6027\u3001\u4e0d\u53ef\u611f\u77e5\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002", "motivation": "\u5728IoT\u548c\u79fb\u52a8\u5e73\u53f0\u65f6\u4ee3\uff0c\u5982\u4f55\u5728\u6709\u9650\u786c\u4ef6\u8d44\u6e90\u4e0b\u786e\u4fdd\u5185\u5bb9\u771f\u5b9e\u6027\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df7\u5408\u5feb\u901f\u5c0f\u6ce2\u53d8\u6362\u548c\u52a0\u6027\u91cf\u5316\u7d22\u5f15\u8c03\u5236\uff08FWT-AQIM\uff09\u65b9\u6cd5\uff0c\u5728YCbCr\u8272\u5f69\u7a7a\u95f4\u7684\u4eae\u5ea6\u5206\u91cf\u4e2d\u5d4c\u5165\u6c34\u5370\u3002", "result": "\u5728Raspberry Pi 5\u4e0a\u6d4b\u8bd5\uff0c\u5d4c\u5165\u548c\u63d0\u53d6\u8fc7\u7a0b\u8017\u65f6\u5c0f\u4e8e40\u6beb\u79d2\uff0cPSNR\u226534 dB\uff0cSSIM\u22650.97\uff0c\u5bf9\u653b\u51fb\u7684\u9c81\u68d2\u6027\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "FWT-AQIM\u4e3a\u5e26\u5bbd\u548c\u529f\u8017\u53d7\u9650\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u5b89\u5168\u6c34\u5370\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07500", "pdf": "https://arxiv.org/pdf/2506.07500", "abs": "https://arxiv.org/abs/2506.07500", "authors": ["Shakir Yousefi", "Andreas Plesner", "Till Aczel", "Roger Wattenhofer"], "title": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "Modern neural networks demonstrate state-of-the-art performance on numerous\nexisting benchmarks; however, their high computational requirements and energy\nconsumption prompt researchers to seek more efficient solutions for real-world\ndeployment. Logic gate networks (LGNs) learns a large network of logic gates\nfor efficient image classification. However, learning a network that can solve\na simple problem like CIFAR-10 can take days to weeks to train. Even then,\nalmost half of the network remains unused, causing a discretization gap. This\ndiscretization gap hinders real-world deployment of LGNs, as the performance\ndrop between training and inference negatively impacts accuracy. We inject\nGumbel noise with a straight-through estimator during training to significantly\nspeed up training, improve neuron utilization, and decrease the discretization\ngap. We theoretically show that this results from implicit Hessian\nregularization, which improves the convergence properties of LGNs. We train\nnetworks $4.5 \\times$ faster in wall-clock time, reduce the discretization gap\nby $98\\%$, and reduce the number of unused gates by $100\\%$.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6ce8\u5165Gumbel\u566a\u58f0\u548c\u76f4\u901a\u4f30\u8ba1\u5668\u6765\u52a0\u901f\u903b\u8f91\u95e8\u7f51\u7edc\uff08LGNs\uff09\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u901f\u5ea6\u3001\u795e\u7ecf\u5143\u5229\u7528\u7387\u548c\u51cf\u5c11\u4e86\u79bb\u6563\u5316\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1\u903b\u8f91\u95e8\u7f51\u7edc\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\uff0c\u4f46\u5176\u8bad\u7ec3\u65f6\u95f4\u957f\u3001\u795e\u7ecf\u5143\u5229\u7528\u7387\u4f4e\u548c\u79bb\u6563\u5316\u5dee\u8ddd\u5927\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6ce8\u5165Gumbel\u566a\u58f0\u5e76\u4f7f\u7528\u76f4\u901a\u4f30\u8ba1\u5668\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e\u8fd9\u9690\u542b\u4e86Hessian\u6b63\u5219\u5316\uff0c\u6539\u5584\u4e86\u6536\u655b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u53474.5\u500d\uff0c\u79bb\u6563\u5316\u5dee\u8ddd\u51cf\u5c1198%\uff0c\u672a\u4f7f\u7528\u95e8\u6570\u91cf\u51cf\u5c11100%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LGNs\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u5176\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.07802", "pdf": "https://arxiv.org/pdf/2506.07802", "abs": "https://arxiv.org/abs/2506.07802", "authors": ["Nicolaj \u00d8. Jensen", "Kim G. Larsen", "Didier Lime", "Ji\u0159\u00ed Srba"], "title": "On-The-Fly Symbolic Algorithm for Timed ATL with Abstractions", "categories": ["cs.LO"], "comment": "Full version of paper published in CONCUR 2025", "summary": "Verification of real-time systems with multiple components controlled by\nmultiple parties is a challenging task due to its computational complexity. We\npresent an on-the-fly algorithm for verifying timed alternating-time temporal\nlogic (TATL), a branching-time logic with quantifiers over outcomes that\nresults from coalitions of players in such systems. We combine existing work on\ngames and timed CTL verification in the abstract dependency graph (ADG)\nframework, which allows for easy creation of on-the-fly algorithms that only\nexplore the state space as needed. In addition, we generalize the conventional\ninclusion check to the ADG framework which enables dynamic reductions of the\ndependency graph. Using the insights from the generalization, we present a\nnovel abstraction that eliminates the need for inclusion checking altogether in\nour domain. We implement our algorithms in Uppaal and our experiments show that\nwhile inclusion checking considerably enhances performance, our abstraction\nprovides even more significant improvements, almost two orders of magnitude\nfaster than the naive method. In addition, we outperform Uppaal Tiga, which can\nverify only a strict subset of TATL. After implementing our new abstraction in\nUppaal Tiga, we also improve its performance by almost an order of magnitude.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u65f6\u9a8c\u8bc1TATL\u903b\u8f91\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u4f9d\u8d56\u56fe\u548c\u65b0\u578b\u62bd\u8c61\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u5173\u5de5\u5177\u3002", "motivation": "\u591a\u7ec4\u4ef6\u591a\u53c2\u4e0e\u65b9\u7684\u5b9e\u65f6\u7cfb\u7edf\u9a8c\u8bc1\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u9ad8\u6548\u7b97\u6cd5\u3002", "method": "\u7ed3\u5408\u6e38\u620f\u7406\u8bba\u548c\u65f6\u95f4CTL\u9a8c\u8bc1\uff0c\u5728ADG\u6846\u67b6\u4e2d\u5b9e\u73b0\u52a8\u6001\u7b97\u6cd5\uff0c\u5e76\u63d0\u51fa\u65b0\u62bd\u8c61\u65b9\u6cd5\u907f\u514d\u5305\u542b\u68c0\u67e5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u65b0\u65b9\u6cd5\u6bd4\u539f\u59cb\u65b9\u6cd5\u5feb\u8fd1\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u5e76\u4f18\u4e8eUppaal Tiga\u3002", "conclusion": "\u63d0\u51fa\u7684\u62bd\u8c61\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u6548\u7387\uff0c\u9002\u7528\u8303\u56f4\u66f4\u5e7f\u3002"}}
{"id": "2506.06509", "pdf": "https://arxiv.org/pdf/2506.06509", "abs": "https://arxiv.org/abs/2506.06509", "authors": ["Jakub Jagielski", "Markus Abel"], "title": "Private GPTs for LLM-driven testing in software development and machine learning", "categories": ["cs.SE", "cs.AI", "I.2.1"], "comment": "5 pages, 10 figures", "summary": "In this contribution, we examine the capability of private GPTs to\nautomatically generate executable test code based on requirements. More\nspecifically, we use acceptance criteria as input, formulated as part of epics,\nor stories, which are typically used in modern development processes. This\ngives product owners, or business intelligence, respectively, a way to directly\nproduce testable criteria through the use of LLMs. We explore the quality of\nthe so-produced tests in two ways: i) directly by letting the LLM generate code\nfrom requirements, ii) through an intermediate step using Gherkin syntax. As a\nresult, it turns out that the two-step procedure yields better results -where\nwe define better in terms of human readability and best coding practices, i.e.\nlines of code and use of additional libraries typically used in testing.\nConcretely, we evaluate prompt effectiveness across two scenarios: a simple\n\"Hello World\" program and a digit classification model, showing that structured\nprompts lead to higher-quality test outputs.", "AI": {"tldr": "\u7814\u7a76\u4e86\u79c1\u6709GPT\u57fa\u4e8e\u9700\u6c42\u81ea\u52a8\u751f\u6210\u53ef\u6267\u884c\u6d4b\u8bd5\u4ee3\u7801\u7684\u80fd\u529b\u3002\u53d1\u73b0\u4e24\u6b65\u6cd5\uff08\u5148\u8f6c\u6362\u4e3aGherkin\u8bed\u6cd5\uff09\u6548\u679c\u66f4\u597d\uff0c\u5c24\u5176\u5728\u4ee3\u7801\u53ef\u8bfb\u6027\u548c\u6700\u4f73\u5b9e\u8df5\u65b9\u9762\u3002", "motivation": "\u63a2\u7d22\u79c1\u6709GPT\u5982\u4f55\u901a\u8fc7\u9700\u6c42\u76f4\u63a5\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\uff0c\u4e3a\u4ea7\u54c1\u6240\u6709\u8005\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u7684\u6d4b\u8bd5\u6807\u51c6\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u63a5\u53d7\u6807\u51c6\u4f5c\u4e3a\u8f93\u5165\uff0c\u5bf9\u6bd4\u4e24\u79cd\u65b9\u6cd5\uff1a\u76f4\u63a5\u751f\u6210\u4ee3\u7801\u4e0e\u901a\u8fc7Gherkin\u8bed\u6cd5\u95f4\u63a5\u751f\u6210\u3002", "result": "\u4e24\u6b65\u6cd5\u5728\u4ee3\u7801\u53ef\u8bfb\u6027\u548c\u6700\u4f73\u5b9e\u8df5\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u7ed3\u6784\u5316\u63d0\u793a\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u6d4b\u8bd5\u8f93\u51fa\u3002", "conclusion": "\u901a\u8fc7\u4e2d\u95f4\u6b65\u9aa4\uff08\u5982Gherkin\u8bed\u6cd5\uff09\u53ef\u4ee5\u663e\u8457\u63d0\u5347GPT\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\u7684\u8d28\u91cf\u3002"}}
{"id": "2506.06774", "pdf": "https://arxiv.org/pdf/2506.06774", "abs": "https://arxiv.org/abs/2506.06774", "authors": ["Luca-Maxim Meinhardt", "Simon Demharter", "Michael Rietzler", "Mark Colley", "Thomas E\u00dfmeyer", "Enrico Rukzio"], "title": "Mind Games! Exploring the Impact of Dark Patterns in Mixed Reality Scenarios", "categories": ["cs.HC"], "comment": null, "summary": "Mixed Reality (MR) integrates virtual objects with the real world, offering\npotential but raising concerns about misuse through dark patterns. This study\nexplored the effects of four dark patterns, adapted from prior research, and\napplied to MR across three targets: places, products, and people. In a\ntwo-factorial within-subject study with 74 participants, we analyzed 13 videos\nsimulating MR experiences during a city walk. Results show that all dark\npatterns significantly reduced user comfort, increased reactance, and decreased\nthe intention to use MR glasses, with the most disruptive effects linked to\npersonal or monetary manipulation. Additionally, the dark patterns of Emotional\nand Sensory Manipulation and Hiding Information produced similar impacts on the\nuser in MR, suggesting a re-evaluation of current classifications to go beyond\ndeceptive design techniques. Our findings highlight the importance of\ndeveloping ethical design guidelines and tools to detect and prevent dark\npatterns as immersive technologies continue to evolve.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6df7\u5408\u73b0\u5b9e\uff08MR\uff09\u4e2d\u7684\u56db\u79cd\u9ed1\u6697\u6a21\u5f0f\u5bf9\u7528\u6237\u4f53\u9a8c\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u6a21\u5f0f\u663e\u8457\u964d\u4f4e\u7528\u6237\u8212\u9002\u5ea6\u3001\u589e\u52a0\u6297\u62d2\u5fc3\u7406\uff0c\u5e76\u51cf\u5c11\u4f7f\u7528MR\u773c\u955c\u7684\u610f\u613f\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u9ed1\u6697\u6a21\u5f0f\u5728MR\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5bf9\u7528\u6237\u7684\u5f71\u54cd\uff0c\u4ee5\u63a8\u52a8\u4f26\u7406\u8bbe\u8ba1\u6307\u5357\u548c\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc774\u540d\u53c2\u4e0e\u8005\u7684\u53cc\u56e0\u7d20\u53d7\u8bd5\u5185\u7814\u7a76\uff0c\u5206\u6790\u4e8613\u4e2a\u6a21\u62dfMR\u57ce\u5e02\u6f2b\u6b65\u4f53\u9a8c\u7684\u89c6\u9891\u3002", "result": "\u6240\u6709\u9ed1\u6697\u6a21\u5f0f\u5747\u663e\u8457\u964d\u4f4e\u7528\u6237\u8212\u9002\u5ea6\u3001\u589e\u52a0\u6297\u62d2\u5fc3\u7406\uff0c\u4e2a\u4eba\u6216\u91d1\u94b1\u64cd\u7eb5\u6548\u679c\u6700\u663e\u8457\u3002\u60c5\u611f\u4e0e\u611f\u5b98\u64cd\u7eb5\u53ca\u9690\u85cf\u4fe1\u606f\u5728MR\u4e2d\u7684\u5f71\u54cd\u76f8\u4f3c\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5236\u5b9a\u4f26\u7406\u8bbe\u8ba1\u6307\u5357\u548c\u5de5\u5177\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u9884\u9632\u9ed1\u6697\u6a21\u5f0f\u5728\u6c89\u6d78\u5f0f\u6280\u672f\u4e2d\u7684\u6ee5\u7528\u3002"}}
{"id": "2506.06916", "pdf": "https://arxiv.org/pdf/2506.06916", "abs": "https://arxiv.org/abs/2506.06916", "authors": ["Stavros Dimou", "Guevara Noubir"], "title": "ARGOS: Anomaly Recognition and Guarding through O-RAN Sensing", "categories": ["cs.NI", "cs.CR"], "comment": null, "summary": "Rogue Base Station (RBS) attacks, particularly those exploiting downgrade\nvulnerabilities, remain a persistent threat as 5G Standalone (SA) deployments\nare still limited and User Equipment (UE) manufacturers continue to support\nlegacy network connectivity. This work introduces ARGOS, a comprehensive O-RAN\ncompliant Intrusion Detection System (IDS) deployed within the Near Real-Time\nRIC, designed to detect RBS downgrade attacks in real time, an area previously\nunexplored within the O-RAN context. The system enhances the 3GPP KPM Service\nModel to enable richer, UE-level telemetry and features a custom xApp that\napplies unsupervised Machine Learning models for anomaly detection.\nDistinctively, the updated KPM Service Model operates on cross-layer features\nextracted from Modem Layer 1 (ML1) logs and Measurement Reports collected\ndirectly from Commercial Off-The-Shelf (COTS) UEs. To evaluate system\nperformance under realistic conditions, a dedicated testbed is implemented\nusing Open5GS, srsRAN, and FlexRIC, and validated against an extensive\nreal-world measurement dataset. Among the evaluated models, the Variational\nAutoencoder (VAE) achieves the best balance of detection performance and\nefficiency, reaching 99.5% Accuracy with only 0.6% False Positives and minimal\nsystem overhead.", "AI": {"tldr": "ARGOS\u662f\u4e00\u79cd\u5728O-RAN\u73af\u5883\u4e2d\u5b9e\u65f6\u68c0\u6d4bRogue Base Station\u964d\u7ea7\u653b\u51fb\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5229\u7528\u6539\u8fdb\u76843GPP KPM\u670d\u52a1\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff0c\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "5G\u72ec\u7acb\u90e8\u7f72\u6709\u9650\u4e14\u8bbe\u5907\u5236\u9020\u5546\u4ecd\u652f\u6301\u4f20\u7edf\u7f51\u7edc\u8fde\u63a5\uff0cRogue Base Station\u653b\u51fb\u6301\u7eed\u5a01\u80c1\u7f51\u7edc\u5b89\u5168\u3002", "method": "ARGOS\u7cfb\u7edf\u90e8\u7f72\u4e8eNear Real-Time RIC\uff0c\u91c7\u7528\u6539\u8fdb\u7684KPM\u670d\u52a1\u6a21\u578b\u548c\u57fa\u4e8e\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u5f02\u5e38\u68c0\u6d4bxApp\uff0c\u5229\u7528\u8de8\u5c42\u7279\u5f81\u548c\u5546\u7528\u8bbe\u5907\u6570\u636e\u3002", "result": "\u5728\u771f\u5b9e\u6d4b\u8bd5\u73af\u5883\u4e2d\uff0c\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe99.5%\uff0c\u8bef\u62a5\u7387\u4ec50.6%\u3002", "conclusion": "ARGOS\u80fd\u6709\u6548\u68c0\u6d4bRBS\u964d\u7ea7\u653b\u51fb\uff0c\u4e3aO-RAN\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07834", "pdf": "https://arxiv.org/pdf/2506.07834", "abs": "https://arxiv.org/abs/2506.07834", "authors": ["Doehyun Baek", "Daniel Lehmann", "Ben L. Titzer", "Sukyoung Ryu", "Michael Pradel"], "title": "Execution-Aware Program Reduction for WebAssembly via Record and Replay", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "WebAssembly (Wasm) programs may trigger bugs in their engine implementations.\nTo aid debugging, program reduction techniques try to produce a smaller variant\nof the input program that still triggers the bug. However, existing\nexecution-unaware program reduction techniques struggle with large and complex\nWasm programs, because they rely on static information and apply syntactic\ntransformations, while ignoring the valuable information offered by the input\nprogram's execution behavior.\n  We present RR-Reduce and Hybrid-Reduce, novel execution-aware program\nreduction techniques that leverage execution behaviors via record and replay.\nRR-Reduce identifies a bug-triggering function as the target function, isolates\nthat function from the rest of the program, and generates a reduced program\nthat replays only the interactions between the target function and the rest of\nthe program. Hybrid-Reduce combines a complementary execution-unaware reduction\ntechnique with RR-Reduce to further reduce program size.\n  We evaluate RR-Reduce and Hybrid-Reduce on 28 Wasm programs that trigger a\ndiverse set of bugs in three engines. On average, RR-Reduce reduces the\nprograms to 1.20 percent of their original size in 14.5 minutes, which\noutperforms the state of the art by 33.15 times in terms of reduction time.\nHybrid-Reduce reduces the programs to 0.13 percent of their original size in\n3.5 hours, which outperforms the state of the art by 3.42 times in terms of\nreduced program size and 2.26 times in terms of reduction time. We envision\nRR-Reduce as the go-to tool for rapid, on-demand debugging in minutes, and\nHybrid-Reduce for scenarios where developers require the smallest possible\nprograms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u6267\u884c\u611f\u77e5\u7684\u7a0b\u5e8f\u7f29\u51cf\u6280\u672f\uff08RR-Reduce\u548cHybrid-Reduce\uff09\uff0c\u901a\u8fc7\u8bb0\u5f55\u548c\u91cd\u653e\u6267\u884c\u884c\u4e3a\u6765\u89e3\u51b3\u73b0\u6709\u9759\u6001\u6280\u672f\u5904\u7406\u5927\u578b\u590d\u6742WebAssembly\u7a0b\u5e8f\u65f6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u4f9d\u8d56\u9759\u6001\u4fe1\u606f\u4e14\u5ffd\u7565\u6267\u884c\u884c\u4e3a\uff0c\u96be\u4ee5\u6709\u6548\u7f29\u51cf\u5927\u578b\u590d\u6742WebAssembly\u7a0b\u5e8f\u3002", "method": "RR-Reduce\u901a\u8fc7\u8bc6\u522b\u548c\u9694\u79bb\u89e6\u53d1\u9519\u8bef\u7684\u51fd\u6570\u751f\u6210\u7f29\u51cf\u7a0b\u5e8f\uff1bHybrid-Reduce\u7ed3\u5408\u6267\u884c\u611f\u77e5\u548c\u65e0\u611f\u77e5\u6280\u672f\u8fdb\u4e00\u6b65\u7f29\u51cf\u7a0b\u5e8f\u3002", "result": "RR-Reduce\u5e73\u5747\u5c06\u7a0b\u5e8f\u7f29\u51cf\u81f3\u539f\u5927\u5c0f\u76841.20%\uff0c\u7528\u65f614.5\u5206\u949f\uff1bHybrid-Reduce\u7f29\u51cf\u81f30.13%\uff0c\u7528\u65f63.5\u5c0f\u65f6\uff0c\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "RR-Reduce\u9002\u5408\u5feb\u901f\u8c03\u8bd5\uff0cHybrid-Reduce\u9002\u5408\u9700\u8981\u6700\u5c0f\u5316\u7a0b\u5e8f\u7684\u573a\u666f\u3002"}}
{"id": "2506.06396", "pdf": "https://arxiv.org/pdf/2506.06396", "abs": "https://arxiv.org/abs/2506.06396", "authors": ["Christopher D. Molek", "Roberto Fronteddu", "K. Brent Venable", "Niranjan Suri"], "title": "Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": null, "summary": "The expansion of the Internet of Things (IoT) in the battlefield, Internet of\nBattlefield Things (IoBT), gives rise to new opportunities for enhancing\nsituational awareness. To increase the potential of IoBT for situational\nawareness in critical decision making, the data from these devices must be\nprocessed into consumer-ready information objects, and made available to\nconsumers on demand. To address this challenge we propose a workflow that makes\nuse of natural language processing (NLP) to query a database technology and\nreturn a response in natural language. Our solution utilizes Large Language\nModels (LLMs) that are sized for edge devices to perform NLP as well as\ngraphical databases which are well suited for dynamic connected networks which\nare pervasive in the IoBT. Our architecture employs LLMs for both mapping\nquestions in natural language to Cypher database queries as well as to\nsummarize the database output back to the user in natural language. We evaluate\nseveral medium sized LLMs for both of these tasks on a database representing\npublicly available data from the US Army's Multipurpose Sensing Area (MSA) at\nthe Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion\nparameters) outperforms the other models across all the considered metrics.\nMost importantly, we note that, unlike current methods, our two step approach\nallows the relaxation of the Exact Match (EM) requirement of the produced\nCypher queries with ground truth code and, in this way, it achieves a 19.4%\nincrease in accuracy. Our workflow lays the ground work for deploying LLMs on\nedge devices to enable natural language interactions with databases containing\ninformation objects for critical decision making.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5de5\u4f5c\u6d41\uff0c\u4ee5\u63d0\u5347\u6218\u573a\u7269\u8054\u7f51\uff08IoBT\uff09\u4e2d\u60c5\u5883\u611f\u77e5\u7684\u6570\u636e\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u901a\u8fc7IoBT\u63d0\u5347\u6218\u573a\u60c5\u5883\u611f\u77e5\u80fd\u529b\uff0c\u9700\u8981\u5c06\u8bbe\u5907\u6570\u636e\u8f6c\u6362\u4e3a\u7528\u6237\u53cb\u597d\u7684\u4fe1\u606f\u5bf9\u8c61\uff0c\u5e76\u5b9e\u73b0\u6309\u9700\u8bbf\u95ee\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5de5\u4f5c\u6d41\uff0c\u5229\u7528\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u7684LLMs\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u6620\u5c04\u4e3aCypher\u6570\u636e\u5e93\u67e5\u8be2\uff0c\u5e76\u5c06\u6570\u636e\u5e93\u7ed3\u679c\u4ee5\u81ea\u7136\u8bed\u8a00\u5f62\u5f0f\u8fd4\u56de\u3002", "result": "\u5728\u57fa\u4e8e\u516c\u5f00\u7f8e\u519b\u6570\u636e\u7684\u6d4b\u8bd5\u4e2d\uff0cLlama 3.1\uff0880\u4ebf\u53c2\u6570\uff09\u8868\u73b0\u6700\u4f73\uff0c\u4e14\u4e24\u9636\u6bb5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u67e5\u8be2\u51c6\u786e\u6027\uff0819.4%\uff09\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u4e3a\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72LLMs\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u652f\u6301\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u8bbf\u95ee\u5173\u952e\u51b3\u7b56\u4fe1\u606f\u3002"}}
{"id": "2506.06743", "pdf": "https://arxiv.org/pdf/2506.06743", "abs": "https://arxiv.org/abs/2506.06743", "authors": ["Allie Tran", "Werner Bailer", "Duc-Tien Dang-Nguyen", "Graham Healy", "Steve Hodges", "Bj\u00f6rn \u00de\u00f3r J\u00f3nsson", "Luca Rossetto", "Klaus Schoeffmann", "Minh-Triet Tran", "Lucia Vadicamo", "Cathal Gurrin"], "title": "The State-of-the-Art in Lifelog Retrieval: A Review of Progress at the ACM Lifelog Search Challenge Workshop 2022-24", "categories": ["cs.MM", "cs.IR"], "comment": null, "summary": "The ACM Lifelog Search Challenge (LSC) is a venue that welcomes and compares\nsystems that support the exploration of lifelog data, and in particular the\nretrieval of specific information, through an interactive competition format.\nThis paper reviews the recent advances in interactive lifelog retrieval as\ndemonstrated at the ACM LSC from 2022 to 2024. Through a detailed comparative\nanalysis, we highlight key improvements across three main retrieval tasks:\nknown-item search, question answering, and ad-hoc search. Our analysis\nidentifies trends such as the widespread adoption of embedding-based retrieval\nmethods (e.g., CLIP, BLIP), increased integration of large language models\n(LLMs) for conversational retrieval, and continued innovation in multimodal and\ncollaborative search interfaces. We further discuss how specific retrieval\ntechniques and user interface (UI) designs have impacted system performance,\nemphasizing the importance of balancing retrieval complexity with usability.\nOur findings indicate that embedding-driven approaches combined with LLMs show\npromise for lifelog retrieval systems. Likewise, improving UI design can\nenhance usability and efficiency. Additionally, we recommend reconsidering\nmulti-instance system evaluations within the expert track to better manage\nvariability in user familiarity and configuration effectiveness.", "AI": {"tldr": "\u8bba\u6587\u56de\u987e\u4e862022\u5e74\u81f32024\u5e74ACM LSC\u7ade\u8d5b\u4e2d\u4e92\u52a8\u5f0f\u751f\u547d\u65e5\u5fd7\u68c0\u7d22\u7684\u8fdb\u5c55\uff0c\u5206\u6790\u6bd4\u8f83\u4e86\u4e09\u79cd\u68c0\u7d22\u4efb\u52a1\u7684\u6539\u8fdb\u8d8b\u52bf\uff0c\u7a81\u51fa\u5d4c\u5165\u68c0\u7d22\u65b9\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\uff0c\u5e76\u63a2\u8ba8\u4e86\u7528\u6237\u754c\u9762\u8bbe\u8ba1\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u901a\u8fc7\u5206\u6790ACM LSC\u7ade\u8d5b\u4e2d\u7684\u7cfb\u7edf\u8868\u73b0\uff0c\u603b\u7ed3\u4e92\u52a8\u5f0f\u751f\u547d\u65e5\u5fd7\u68c0\u7d22\u7684\u6700\u65b0\u8fdb\u5c55\u548c\u8d8b\u52bf\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u901a\u8fc7\u5bf92022-2024\u5e74ACM LSC\u7ade\u8d5b\u7684\u7cfb\u7edf\u8fdb\u884c\u8be6\u7ec6\u6bd4\u8f83\u5206\u6790\uff0c\u5f52\u7eb3\u51fa\u5d4c\u5165\u68c0\u7d22\u65b9\u6cd5\uff08\u5982CLIP\u3001BLIP\uff09\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f1a\u8bdd\u68c0\u7d22\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u548c\u534f\u4f5c\u641c\u7d22\u754c\u9762\u7684\u521b\u65b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5d4c\u5165\u9a71\u52a8\u65b9\u6cd5\u4e0eLLMs\u7ed3\u5408\u5728\u751f\u547d\u65e5\u5fd7\u68c0\u7d22\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u540c\u65f6\u6539\u8fdbUI\u8bbe\u8ba1\u80fd\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u672a\u6765\u5e94\u6ce8\u91cd\u5e73\u8861\u68c0\u7d22\u590d\u6742\u6027\u4e0e\u53ef\u7528\u6027\uff0c\u5e76\u5efa\u8bae\u5728\u4e13\u5bb6\u7cfb\u7edf\u4e2d\u6539\u8fdb\u591a\u5b9e\u4f8b\u7cfb\u7edf\u8bc4\u4f30\u4ee5\u9002\u5e94\u4e0d\u540c\u7528\u6237\u719f\u6089\u7a0b\u5ea6\u548c\u914d\u7f6e\u6548\u679c\u3002"}}
{"id": "2506.06440", "pdf": "https://arxiv.org/pdf/2506.06440", "abs": "https://arxiv.org/abs/2506.06440", "authors": ["Chuhao Chen", "Zhiyang Dou", "Chen Wang", "Yiming Huang", "Anjun Chen", "Qiao Feng", "Jiatao Gu", "Lingjie Liu"], "title": "Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Faithfully reconstructing textured shapes and physical properties from videos\npresents an intriguing yet challenging problem. Significant efforts have been\ndedicated to advancing such a system identification problem in this area.\nPrevious methods often rely on heavy optimization pipelines with a\ndifferentiable simulator and renderer to estimate physical parameters. However,\nthese approaches frequently necessitate extensive hyperparameter tuning for\neach scene and involve a costly optimization process, which limits both their\npracticality and generalizability. In this work, we propose a novel framework,\nVid2Sim, a generalizable video-based approach for recovering geometry and\nphysical properties through a mesh-free reduced simulation based on Linear\nBlend Skinning (LBS), offering high computational efficiency and versatile\nrepresentation capability. Specifically, Vid2Sim first reconstructs the\nobserved configuration of the physical system from video using a feed-forward\nneural network trained to capture physical world knowledge. A lightweight\noptimization pipeline then refines the estimated appearance, geometry, and\nphysical properties to closely align with video observations within just a few\nminutes. Additionally, after the reconstruction, Vid2Sim enables high-quality,\nmesh-free simulation with high efficiency. Extensive experiments demonstrate\nthat our method achieves superior accuracy and efficiency in reconstructing\ngeometry and physical properties from video data.", "AI": {"tldr": "Vid2Sim\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u9891\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u901a\u8fc7\u65e0\u7f51\u683c\u7b80\u5316\u6a21\u62df\u9ad8\u6548\u91cd\u5efa\u51e0\u4f55\u548c\u7269\u7406\u5c5e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u4f18\u5316\u6d41\u7a0b\u548c\u5927\u91cf\u8d85\u53c2\u6570\u8c03\u6574\uff0c\u9650\u5236\u4e86\u5b9e\u7528\u6027\u548c\u6cdb\u5316\u6027\u3002", "method": "Vid2Sim\u7ed3\u5408\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u7269\u7406\u4e16\u754c\u77e5\u8bc6\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4f18\u5316\u6d41\u7a0b\u8fdb\u884c\u5feb\u901f\u7cbe\u786e\u91cd\u5efa\u3002", "result": "\u5b9e\u9a8c\u663e\u793aVid2Sim\u5728\u91cd\u5efa\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Vid2Sim\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u7684\u89c6\u9891\u5230\u51e0\u4f55\u548c\u7269\u7406\u5c5e\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06716", "pdf": "https://arxiv.org/pdf/2506.06716", "abs": "https://arxiv.org/abs/2506.06716", "authors": ["Max Bannach", "Erik D. Demaine", "Timothy Gomez", "Markus Hecher"], "title": "#P is Sandwiched by One and Two #2DNF Calls: Is Subtraction Stronger Than We Thought?", "categories": ["cs.CC", "cs.DM", "cs.DS", "cs.LO", "math.CO", "68Q17, 68Q15, 68Q25, 68Q27, 03B05, 03D10, 03D15, 05C85, 05C62,\n  05-08, 94C15", "G.2.1; G.2.2; F.4.1; F.1.3; F.1.1"], "comment": null, "summary": "The canonical class in the realm of counting complexity is #P. It is well\nknown that the problem of counting the models of a propositional formula in\ndisjunctive normal form (#DNF) is complete for #P under Turing reductions. On\nthe other hand, #DNF $\\in$ spanL and spanL $\\not\\subseteq$ #P unless NL = NP.\nHence, the class of functions logspace-reducible to #DNF is a strict subset of\n#P under plausible complexity-theoretic assumptions. By contrast, we show that\ntwo calls to a (restricted) #2DNF oracle suffice to capture gapP, namely, that\nthe logspace many-one closure of the subtraction between the results of two\n#2DNF calls is gapP. Because #P $\\not\\subseteq$ gapP, #P is strictly contained\nbetween one and two #2DNF oracle calls.\n  Surprisingly, the propositional formulas needed in both calls are linear-time\ncomputable, and the reduction preserves interesting structural as well as\nsymmetry properties, leading to algorithmic applications. We show that a single\nsubtraction suffices to compensate for the absence of negation while still\ncapturing gapP, i.e., our results carry over to the monotone fragments of #2SAT\nand #2DNF. Since our reduction is linear-time, it preserves sparsity and, as a\nconsequence we obtain a sparsification lemma for both #2SAT and #2DNF. This has\nonly been known for kSAT with k $\\geq$ 3 and respective counting versions. We\nfurther show that both #2DNF calls can be combined into a single call if we\nallow a little postprocessing (computable by AC0- or TC0-circuits).\nConsequently, we derive refined versions of Toda's Theorem: PH $\\subseteq$\n[#MON2SAT]$^{log}_{TC0}$ = [#MON2DNF]$^{log}_{TC0}$ and PH $\\subseteq$\n[#IMPL2SAT]$^{log}_{AC0}$. Our route to these results is via structure-aware\nreductions that preserve parameters like treewidth up to an additive overhead.\nThe absence of multiplicative overhead indeed yields parameterized SETH-tight\nlower bounds.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u4e2d\u7684 #DNF \u95ee\u9898\u548c #2DNF \u95ee\u9898\u7684\u590d\u6742\u6027\u5173\u7cfb\uff0c\u63ed\u793a\u4e86 gapP \u53ef\u4ee5\u901a\u8fc7\u4e24\u4e2a #2DNF \u67e5\u8be2\u6355\u83b7\uff0c\u4e14\u8bc1\u660e\u4e86\u5728\u5355\u8c03\u7247\u6bb5\u4e2d\u4e5f\u80fd\u5b9e\u73b0\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u7ebf\u6027\u65f6\u95f4\u51cf\u6cd5\u7684\u5e94\u7528\uff0c\u5e76\u6539\u8fdb\u4e86 Toda \u5b9a\u7406\u7684\u7ed3\u679c\u3002", "motivation": "\u63a2\u8ba8 #DNF \u548c #2DNF \u95ee\u9898\u5728\u8ba1\u7b97\u590d\u6742\u6027\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728 logspace \u5f52\u7ea6\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u89e3\u51b3\u5355\u8c03\u7247\u6bb5\u4e2d\u7684\u76f8\u5173\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u7684\u5f52\u7ea6\u65b9\u6cd5\u548c\u6280\u672f\uff0c\u5206\u6790 #2DNF \u67e5\u8be2\u7684\u590d\u6742\u6027\uff0c\u5e76\u4f7f\u7528\u7ebf\u6027\u65f6\u95f4\u51cf\u6cd5\u6355\u83b7 gapP\u3002", "result": "\u8bc1\u660e\u4e24\u4e2a\u53d7\u9650\u7684 #2DNF \u67e5\u8be2\u8db3\u4ee5\u6355\u83b7 gapP\uff0c\u4e14\u7ed3\u679c\u9002\u7528\u4e8e\u5355\u8c03\u7247\u6bb5\uff1b\u540c\u65f6\u6539\u8fdb\u4e86 Toda \u5b9a\u7406\uff0c\u5c55\u793a\u4e86\u53c2\u6570\u5316\u7684 SETH \u7d27\u4e0b\u754c\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86 #2DNF \u67e5\u8be2\u7684\u4e30\u5bcc\u6027\u53ca\u5176\u5728\u590d\u6742\u6027\u7406\u8bba\u548c\u7b97\u6cd5\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u7ed3\u6784\u4fdd\u7559\u548c\u53c2\u6570\u5316\u590d\u6742\u6027\u4e2d\u7684\u610f\u4e49\u3002"}}
{"id": "2506.06764", "pdf": "https://arxiv.org/pdf/2506.06764", "abs": "https://arxiv.org/abs/2506.06764", "authors": ["Wendk\u00fbuni C. Ou\u00e9draogo", "Yinghua Li", "Xueqi Dang", "Xin Zhou", "Anil Koyuncu", "Jacques Klein", "David Lo", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Mind the Gap: A Readability-Aware Metric for Test Code Complexity", "categories": ["cs.SE"], "comment": null, "summary": "Automatically generated unit tests-from search-based tools like EvoSuite or\nLLMs-vary significantly in structure and readability. Yet most evaluations rely\non metrics like Cyclomatic Complexity and Cognitive Complexity, designed for\nfunctional code rather than test code. Recent studies have shown that\nSonarSource's Cognitive Complexity metric assigns near-zero scores to\nLLM-generated tests, yet its behavior on EvoSuite-generated tests and its\napplicability to test-specific code structures remain unexplored. We introduce\nCCTR, a Test-Aware Cognitive Complexity metric tailored for unit tests. CCTR\nintegrates structural and semantic features like assertion density, annotation\nroles, and test composition patterns-dimensions ignored by traditional\ncomplexity models but critical for understanding test code. We evaluate 15,750\ntest suites generated by EvoSuite, GPT-4o, and Mistral Large-1024 across 350\nclasses from Defects4J and SF110. Results show CCTR effectively discriminates\nbetween structured and fragmented test suites, producing interpretable scores\nthat better reflect developer-perceived effort. By bridging structural analysis\nand test readability, CCTR provides a foundation for more reliable evaluation\nand improvement of generated tests. We publicly release all data, prompts, and\nevaluation scripts to support replication.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86CCTR\uff0c\u4e00\u79cd\u9488\u5bf9\u5355\u5143\u6d4b\u8bd5\u7684\u8ba4\u77e5\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u7ed3\u5408\u4e86\u7ed3\u6784\u7279\u5f81\u548c\u8bed\u4e49\u7279\u5f81\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u6d4b\u8bd5\u4ee3\u7801\u7684\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u590d\u6742\u6027\u5ea6\u91cf\u5982Cyclomatic Complexity\u548cCognitive Complexity\u4e0d\u9002\u7528\u4e8e\u6d4b\u8bd5\u4ee3\u7801\uff0c\u7279\u522b\u662fLLM\u751f\u6210\u7684\u6d4b\u8bd5\u4ee3\u7801\u3002", "method": "\u63d0\u51faCCTR\u5ea6\u91cf\uff0c\u6574\u5408\u65ad\u8a00\u5bc6\u5ea6\u3001\u6ce8\u91ca\u89d2\u8272\u548c\u6d4b\u8bd5\u7ec4\u5408\u6a21\u5f0f\u7b49\u7279\u5f81\uff0c\u8bc4\u4f30EvoSuite\u3001GPT-4o\u548cMistral Large-1024\u751f\u6210\u7684\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "CCTR\u80fd\u6709\u6548\u533a\u5206\u7ed3\u6784\u5316\u548c\u788e\u7247\u5316\u7684\u6d4b\u8bd5\u5957\u4ef6\uff0c\u751f\u6210\u66f4\u7b26\u5408\u5f00\u53d1\u8005\u611f\u77e5\u7684\u590d\u6742\u6027\u8bc4\u5206\u3002", "conclusion": "CCTR\u4e3a\u6d4b\u8bd5\u4ee3\u7801\u7684\u53ef\u9760\u8bc4\u4f30\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.06825", "pdf": "https://arxiv.org/pdf/2506.06825", "abs": "https://arxiv.org/abs/2506.06825", "authors": ["Shijing He", "Yaxiong Lei", "Zihan Zhang", "Yuzhou Sun", "Shujun Li", "Chi Zhang", "Juan Ye"], "title": "Identity Deepfake Threats to Biometric Authentication Systems: Public and Expert Perspectives", "categories": ["cs.HC", "cs.CR", "68T10, 68T45, 68M25", "I.4.9; I.5.4; K.4.1; K.6.5"], "comment": null, "summary": "Generative AI (Gen-AI) deepfakes pose a rapidly evolving threat to biometric\nauthentication, yet a significant gap exists between expert understanding of\nthese risks and public perception. This disconnection creates critical\nvulnerabilities in systems trusted by millions. To bridge this gap, we\nconducted a comprehensive mixed-method study, surveying 408 professionals\nacross key sectors and conducting in-depth interviews with 37 participants (25\nexperts, 12 general public [non-experts]). Our findings reveal a paradox: while\nthe public increasingly relies on biometrics for convenience, experts express\ngrave concerns about the spoofing of static modalities like face and voice\nrecognition. We found significant demographic and sector-specific divides in\nawareness and trust, with finance professionals, for example, showing\nheightened skepticism. To systematically analyze these threats, we introduce a\nnovel Deepfake Kill Chain model, adapted from Hutchins et al.'s cybersecurity\nframeworks to map the specific attack vectors used by malicious actors against\nbiometric systems. Based on this model and our empirical findings, we propose a\ntri-layer mitigation framework that prioritizes dynamic biometric signals\n(e.g., eye movements), robust privacy-preserving data governance, and targeted\neducational initiatives. This work provides the first empirically grounded\nroadmap for defending against AI-generated identity threats by aligning\ntechnical safeguards with human-centered insights.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u751f\u6210\u5f0fAI\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u5bf9\u751f\u7269\u7279\u5f81\u8ba4\u8bc1\u7684\u5a01\u80c1\uff0c\u63ed\u793a\u4e86\u516c\u4f17\u4e0e\u4e13\u5bb6\u4e4b\u95f4\u7684\u8ba4\u77e5\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5b9e\u8bc1\u7684\u4e09\u5c42\u7f13\u89e3\u6846\u67b6\u3002", "motivation": "\u751f\u7269\u7279\u5f81\u8ba4\u8bc1\u7cfb\u7edf\u9762\u4e34\u751f\u6210\u5f0fAI\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u5feb\u901f\u6f14\u53d8\u5a01\u80c1\uff0c\u800c\u516c\u4f17\u4e0e\u4e13\u5bb6\u5728\u6b64\u98ce\u9669\u4e0a\u7684\u8ba4\u77e5\u5dee\u8ddd\u5bfc\u81f4\u4e86\u7cfb\u7edf\u7684\u5173\u952e\u6f0f\u6d1e\u3002", "method": "\u7814\u7a76\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u5bf9408\u540d\u4e13\u4e1a\u4eba\u58eb\u7684\u8c03\u67e5\u548c37\u540d\u53c2\u4e0e\u8005\u7684\u6df1\u5ea6\u8bbf\u8c08\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\u94fe\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u516c\u4f17\u4f9d\u8d56\u4e8e\u751f\u7269\u7279\u5f81\u8ba4\u8bc1\u7684\u4fbf\u5229\u6027\uff0c\u800c\u4e13\u5bb6\u5219\u5bf9\u9759\u6001\u6a21\u6001\u5982\u9762\u90e8\u548c\u8bed\u97f3\u8bc6\u522b\u7684\u4f2a\u9020\u8868\u793a\u4e25\u91cd\u62c5\u5fe7\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u5c42\u7f13\u89e3\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7ed3\u5408\u6280\u672f\u4fdd\u969c\u548c\u4ee5\u4eba\u4e3a\u672c\u7684\u89c1\u89e3\uff0c\u4e3a\u9632\u5fa1AI\u751f\u6210\u7684\u8eab\u4efd\u5a01\u80c1\u63d0\u4f9b\u4e86\u9996\u4e2a\u57fa\u4e8e\u5b9e\u8bc1\u7684\u8def\u7ebf\u56fe\u3002"}}
{"id": "2506.07715", "pdf": "https://arxiv.org/pdf/2506.07715", "abs": "https://arxiv.org/abs/2506.07715", "authors": ["Yian Zhu", "Ziye Jia", "Lei Zhang", "Yao Wu", "Qiuming Zhu", "Qihui Wu"], "title": "Delay Optimization in Remote ID-Based UAV Communication via BLE and Wi-Fi Switching", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "The remote identification (Remote ID) broadcast capability allows unmanned\naerial vehicles (UAVs) to exchange messages, which is a pivotal technology for\ninter-UAV communications. Although this capability enhances the operational\nvisibility, low delay in Remote ID-based communications is critical for\nensuring the efficiency and timeliness of multi-UAV operations in dynamic\nenvironments. To address this challenge, we first establish delay models for\nRemote ID communications by considering packet reception and collisions across\nboth BLE 4 and Wi-Fi protocols. Building upon these models, we formulate an\noptimization problem to minimize the long-term communication delay through\nadaptive protocol selection. Since the delay performance varies with the UAV\ndensity, we propose an adaptive BLE/Wi-Fi switching algorithm based on the\nmulti-agent deep Q-network approach. Experimental results demonstrate that in\ndynamic-density scenarios, our strategy achieves 32.1% and 37.7% lower latency\ncompared to static BLE 4 and Wi-Fi modes respectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94BLE/Wi-Fi\u5207\u6362\u7b97\u6cd5\u7684\u8fdc\u7a0b\u8bc6\u522b\uff08Remote ID\uff09\u901a\u4fe1\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u964d\u4f4e\u52a8\u6001\u73af\u5883\u4e0b\u591a\u65e0\u4eba\u673a\u64cd\u4f5c\u7684\u5ef6\u8fdf\u3002", "motivation": "\u8fdc\u7a0b\u8bc6\u522b\uff08Remote ID\uff09\u5e7f\u64ad\u80fd\u529b\u662f\u65e0\u4eba\u673a\u95f4\u901a\u4fe1\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5728\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u4f4e\u5ef6\u8fdf\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5efa\u7acbBLE 4\u548cWi-Fi\u534f\u8bae\u7684\u5ef6\u8fdf\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df1\u5ea6Q\u7f51\u7edc\u7684\u81ea\u9002\u5e94BLE/Wi-Fi\u5207\u6362\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u52a8\u6001\u5bc6\u5ea6\u573a\u666f\u4e2d\uff0c\u8be5\u7b56\u7565\u6bd4\u9759\u6001BLE 4\u548cWi-Fi\u6a21\u5f0f\u5206\u522b\u964d\u4f4e\u4e8632.1%\u548c37.7%\u7684\u5ef6\u8fdf\u3002", "conclusion": "\u81ea\u9002\u5e94\u534f\u8bae\u9009\u62e9\u663e\u8457\u63d0\u5347\u4e86\u591a\u65e0\u4eba\u673a\u64cd\u4f5c\u7684\u6548\u7387\u548c\u5b9e\u65f6\u6027\u3002"}}
{"id": "2506.06835", "pdf": "https://arxiv.org/pdf/2506.06835", "abs": "https://arxiv.org/abs/2506.06835", "authors": ["Wang Fang", "Chris Heunen", "Robin Kaarsgaard"], "title": "Hadamard-$\u03a0$: Equational Quantum Programming", "categories": ["quant-ph", "cs.PL"], "comment": "116 pages", "summary": "Quantum computing offers advantages over classical computation, yet the\nprecise features that set the two apart remain unclear. In the standard quantum\ncircuit model, adding a 1-qubit basis-changing gate -- commonly chosen to be\nthe Hadamard gate -- to a universal set of classical reversible gates yields\ncomputationally universal quantum computation. However, the computational\nbehaviours enabled by this addition are not fully characterised. We give such a\ncharacterisation by introducing a small quantum programming language extending\nthe universal classical reversible programming language $\\Pi$ with a single\nprimitive corresponding to the Hadamard gate. The language comes equipped with\na sound and complete categorical semantics that is specified by a purely\nequational theory, enabling reasoning about the equivalence of quantum programs\nin a way that can be automated. Completeness is shown by means of a novel\nfinite presentation, and corresponding synthesis algorithm, for the groups of\northogonal matrices with entries in the ring $\\mathbb{Z}[\\tfrac{1}{\\sqrt{2}}]$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c0f\u578b\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\uff0c\u901a\u8fc7\u6269\u5c55\u7ecf\u5178\u53ef\u9006\u7f16\u7a0b\u8bed\u8a00\u03a0\uff0c\u5f15\u5165Hadamard\u95e8\u539f\u8bed\uff0c\u4ee5\u5b9e\u73b0\u8ba1\u7b97\u901a\u7528\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b8c\u5907\u7684\u8303\u7574\u8bed\u4e49\u548c\u7b49\u4ef7\u6027\u81ea\u52a8\u5316\u63a8\u7406\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u91cf\u5b50\u8ba1\u7b97\u5728\u6807\u51c6\u91cf\u5b50\u7535\u8def\u6a21\u578b\u4e2d\u901a\u8fc7\u6dfb\u52a0Hadamard\u95e8\u5b9e\u73b0\u901a\u7528\u8ba1\u7b97\uff0c\u4f46\u5176\u5177\u4f53\u8ba1\u7b97\u884c\u4e3a\u5c1a\u672a\u5b8c\u5168\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5c0f\u578b\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\uff0c\u6269\u5c55\u7ecf\u5178\u53ef\u9006\u8bed\u8a00\u03a0\uff0c\u4ec5\u6dfb\u52a0Hadamard\u95e8\u539f\u8bed\u3002\u901a\u8fc7\u8303\u7574\u8bed\u4e49\u548c\u7eaf\u7b49\u5f0f\u7406\u8bba\uff0c\u5b9e\u73b0\u7a0b\u5e8f\u7684\u7b49\u4ef7\u6027\u81ea\u52a8\u5316\u63a8\u7406\u3002", "result": "\u5c55\u793a\u4e86\u6b63\u4ea4\u77e9\u9635\u7fa4\u5728\u73af\u2124[1/\u221a2]\u4e0a\u7684\u6709\u9650\u8868\u793a\u548c\u5408\u6210\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u8bed\u4e49\u7684\u5b8c\u5907\u6027\u3002", "conclusion": "\u901a\u8fc7\u6269\u5c55\u7ecf\u5178\u7f16\u7a0b\u8bed\u8a00\u5e76\u5f15\u5165Hadamard\u95e8\uff0c\u5b9e\u73b0\u4e86\u91cf\u5b50\u7a0b\u5e8f\u7684\u5b8c\u5907\u8bed\u4e49\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2506.07552", "pdf": "https://arxiv.org/pdf/2506.07552", "abs": "https://arxiv.org/abs/2506.07552", "authors": ["Valter Uotila", "Jiaheng Lu"], "title": "Quantum Information-Theoretical Size Bounds for Conjunctive Queries with Functional Dependencies", "categories": ["quant-ph", "cs.DB"], "comment": "13 pages, 3 figures", "summary": "Deriving formulations for computing and estimating tight worst-case size\nincreases for conjunctive queries with various constraints has been at the core\nof theoretical database research. If the problem has no constraints or only one\nconstraint, such as functional dependencies or degree constraints, tight\nworst-case size bounds have been proven, and they are even practically\ncomputable. If the problem has more than one constraint, computing tight bounds\ncan be difficult in practice and may even require an infinite number of linear\ninequalities in its optimization formulation. While these challenges have been\naddressed with varying methods, no prior research has employed quantum\ninformation theory to address this problem. In this work, we establish a\nconnection between earlier work on estimating size bounds for conjunctive\nqueries with classical information theory and the field of quantum information\ntheory. We propose replacing the classical Shannon entropy formulation with the\nquantum R\\'enyi entropy. Whereas classical Shannon entropy requires infinitely\nmany inequalities to characterize the optimization space, R\\'enyi entropy\nrequires only one type of inequality, which is non-negativity. Although this is\na promising modification, optimization with respect to the quantum states\ninstead of classical distributions creates a new set of challenges that prevent\nus from finding a practically computable, tight worst-case size bound. In this\nline, we propose a quantum version to derive worst-case size bounds. The\nprevious tight classical worst-case size bound can be viewed as a special limit\nof this quantum bound. We also provide a comprehensive background on prior\nresearch and discuss the future possibilities of quantum information theory in\ntheoretical database research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u91cf\u5b50R\u00e9nyi\u71b5\u66ff\u4ee3\u7ecf\u5178\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u9999\u519c\u71b5\uff0c\u4ee5\u7b80\u5316\u591a\u7ea6\u675f\u6761\u4ef6\u4e0b\u8054\u5408\u67e5\u8be2\u7684\u6700\u574f\u60c5\u51b5\u5927\u5c0f\u754c\u9650\u7684\u8ba1\u7b97\uff0c\u5c3d\u7ba1\u5b9e\u8df5\u4e2d\u4ecd\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u591a\u7ea6\u675f\u6761\u4ef6\u4e0b\u8054\u5408\u67e5\u8be2\u7684\u6700\u574f\u60c5\u51b5\u5927\u5c0f\u754c\u9650\u8ba1\u7b97\u7684\u590d\u6742\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5f53\u7ea6\u675f\u6761\u4ef6\u8d85\u8fc7\u4e00\u4e2a\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u65e0\u9650\u591a\u7684\u7ebf\u6027\u4e0d\u7b49\u5f0f\uff0c\u8ba1\u7b97\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u91cf\u5b50R\u00e9nyi\u71b5\u66ff\u4ee3\u7ecf\u5178\u9999\u519c\u71b5\uff0c\u901a\u8fc7\u4ec5\u9700\u975e\u8d1f\u6027\u4e0d\u7b49\u5f0f\u7684\u4f18\u5316\u7a7a\u95f4\u7b80\u5316\u95ee\u9898\uff0c\u5e76\u5efa\u7acb\u91cf\u5b50\u7248\u672c\u7684\u6700\u574f\u60c5\u51b5\u5927\u5c0f\u754c\u9650\u6a21\u578b\u3002", "result": "\u5c3d\u7ba1\u91cf\u5b50\u65b9\u6cd5\u7b80\u5316\u4e86\u4f18\u5316\u7a7a\u95f4\u7684\u63cf\u8ff0\uff0c\u4f46\u7531\u4e8e\u91cf\u5b50\u6001\u7684\u4f18\u5316\u590d\u6742\u6027\uff0c\u672a\u80fd\u5b9e\u73b0\u5b9e\u9645\u53ef\u8ba1\u7b97\u7684\u7d27\u5bc6\u6700\u574f\u60c5\u51b5\u5927\u5c0f\u754c\u9650\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u5728\u6570\u636e\u5e93\u7406\u8bba\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5c06\u7ecf\u5178\u754c\u9650\u89c6\u4e3a\u91cf\u5b50\u754c\u9650\u7684\u7279\u4f8b\u3002"}}
{"id": "2506.06580", "pdf": "https://arxiv.org/pdf/2506.06580", "abs": "https://arxiv.org/abs/2506.06580", "authors": ["Xiaoran Liu", "Istvan David"], "title": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "categories": ["cs.AI", "cs.ET", "cs.SE", "cs.SY", "eess.SY"], "comment": null, "summary": "Insufficient data volume and quality are particularly pressing challenges in\nthe adoption of modern subsymbolic AI. To alleviate these challenges, AI\nsimulation uses virtual training environments in which AI agents can be safely\nand efficiently developed with simulated, synthetic data. Digital twins open\nnew avenues in AI simulation, as these high-fidelity virtual replicas of\nphysical systems are equipped with state-of-the-art simulators and the ability\nto further interact with the physical system for additional data collection. In\nthis article, we report on our systematic survey of digital twin-enabled AI\nsimulation. By analyzing 22 primary studies, we identify technological trends\nand derive a reference framework to situate digital twins and AI components.\nBased on our findings, we derive a reference framework and provide\narchitectural guidelines by mapping it onto the ISO 23247 reference\narchitecture for digital twins. Finally, we identify challenges and research\nopportunities for prospective researchers.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6570\u5b57\u5b6a\u751f\u5982\u4f55\u52a9\u529b\u73b0\u4ee3\u975e\u7b26\u53f7AI\u7684\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u7cfb\u7edf\u8c03\u67e5\u63d0\u51fa\u6280\u672f\u8d8b\u52bf\u548c\u53c2\u8003\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u975e\u7b26\u53f7AI\u5728\u6570\u636e\u91cf\u548c\u8d28\u91cf\u4e0a\u7684\u4e0d\u8db3\uff0c\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u9ad8\u4fdd\u771f\u6a21\u62df\u73af\u5883\uff0c\u4f18\u5316AI\u8bad\u7ec3\u3002", "method": "\u7cfb\u7edf\u8c03\u67e5\u4e8622\u9879\u4e3b\u8981\u7814\u7a76\uff0c\u5206\u6790\u6280\u672f\u8d8b\u52bf\u5e76\u8bbe\u8ba1\u53c2\u8003\u6846\u67b6\uff0c\u7ed3\u5408ISO 23247\u6807\u51c6\u3002", "result": "\u63d0\u51fa\u4e86\u6570\u5b57\u5b6a\u751f\u4e0eAI\u7ec4\u4ef6\u7ed3\u5408\u7684\u53c2\u8003\u6846\u67b6\u548c\u67b6\u6784\u6307\u5357\uff0c\u5e76\u6307\u51fa\u7814\u7a76\u6311\u6218\u3002", "conclusion": "\u6570\u5b57\u5b6a\u751f\u662fAI\u6a21\u62df\u7684\u6709\u6548\u5de5\u5177\uff0c\u672a\u6765\u7814\u7a76\u9700\u8fdb\u4e00\u6b65\u89e3\u51b3\u6280\u672f\u6311\u6218\u3002"}}
{"id": "2506.07159", "pdf": "https://arxiv.org/pdf/2506.07159", "abs": "https://arxiv.org/abs/2506.07159", "authors": ["Mrinmay Sen", "Chalavadi Krishna Mohan"], "title": "pFedSOP : Accelerating Training Of Personalized Federated Learning Using Second-Order Optimization", "categories": ["cs.DC", "cs.LG", "68Q25, 68T05, 90C06, 90C25, 90C30", "I.2.6; G.1.6; C.2.4"], "comment": null, "summary": "Personalized Federated Learning (PFL) enables clients to collaboratively\ntrain personalized models tailored to their individual objectives, addressing\nthe challenge of model generalization in traditional Federated Learning (FL)\ndue to high data heterogeneity. However, existing PFL methods often require\nincreased communication rounds to achieve the desired performance, primarily\ndue to slow training caused by the use of first-order optimization, which has\nlinear convergence. Additionally, many of these methods increase local\ncomputation because of the additional data fed into the model during the search\nfor personalized local models. One promising solution to this slow training is\nsecond-order optimization, known for its quadratic convergence. However,\nemploying it in PFL is challenging due to the Hessian matrix and its inverse.\nIn this paper, we propose pFedSOP, which efficiently utilizes second-order\noptimization in PFL to accelerate the training of personalized models and\nenhance performance with fewer communication rounds. Our approach first\ncomputes a personalized local gradient update using the Gompertz function-based\nnormalized angle between local and global gradient updates, incorporating\nclient-specific global information. We then use a regularized Fisher\nInformation Matrix (FIM), computed from this personalized gradient update, as\nan approximation of the Hessian to update the personalized models. This\nFIM-based second-order optimization speeds up training with fewer communication\nrounds by tackling the challenges with exact Hessian and avoids additional data\nbeing fed into the model during the search for personalized local models.\nExtensive experiments on heterogeneously partitioned image classification\ndatasets with partial client participation demonstrate that pFedSOP outperforms\nstate-of-the-art FL and PFL algorithms.", "AI": {"tldr": "pFedSOP\u662f\u4e00\u79cd\u5229\u7528\u4e8c\u9636\u4f18\u5316\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u901a\u4fe1\u8f6e\u6b21\u548c\u672c\u5730\u8ba1\u7b97\u52a0\u901f\u8bad\u7ec3\uff0c\u5e76\u5728\u5f02\u6784\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u56e0\u4e00\u9636\u4f18\u5316\u5bfc\u81f4\u7684\u8bad\u7ec3\u901f\u5ea6\u6162\u548c\u901a\u4fe1\u8f6e\u6b21\u591a\u7684\u95ee\u9898\uff0c\u5229\u7528\u4e8c\u9636\u4f18\u5316\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u4f7f\u7528Gompertz\u51fd\u6570\u8ba1\u7b97\u4e2a\u6027\u5316\u68af\u5ea6\u66f4\u65b0\uff0c\u5e76\u5229\u7528\u6b63\u5219\u5316Fisher\u4fe1\u606f\u77e9\u9635\u8fd1\u4f3cHessian\u77e9\u9635\u8fdb\u884c\u6a21\u578b\u66f4\u65b0\u3002", "result": "\u5728\u5f02\u6784\u5206\u5e03\u7684\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\uff0cpFedSOP\u5728\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709FL\u548cPFL\u7b97\u6cd5\u3002", "conclusion": "pFedSOP\u901a\u8fc7\u6709\u6548\u5229\u7528\u4e8c\u9636\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86PFL\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.06938", "pdf": "https://arxiv.org/pdf/2506.06938", "abs": "https://arxiv.org/abs/2506.06938", "authors": ["Bastian J\u00e4ckl", "Vojt\u011bch Kloda", "Daniel A. Keim", "Jakub Loko\u010d"], "title": "Experimental Evaluation of Static Image Sub-Region-Based Search Models Using CLIP", "categories": ["cs.MM", "cs.CV", "68U10", "H.3.3; I.4.10; H.2.8"], "comment": "14 pages, 4 figures, 2 tables", "summary": "Advances in multimodal text-image models have enabled effective text-based\nquerying in extensive image collections. While these models show convincing\nperformance for everyday life scenes, querying in highly homogeneous,\nspecialized domains remains challenging. The primary problem is that users can\noften provide only vague textual descriptions as they lack expert knowledge to\ndiscriminate between homogenous entities. This work investigates whether adding\nlocation-based prompts to complement these vague text queries can enhance\nretrieval performance. Specifically, we collected a dataset of 741 human\nannotations, each containing short and long textual descriptions and bounding\nboxes indicating regions of interest in challenging underwater scenes. Using\nthese annotations, we evaluate the performance of CLIP when queried on various\nstatic sub-regions of images compared to the full image. Our results show that\nboth a simple 3-by-3 partitioning and a 5-grid overlap significantly improve\nretrieval effectiveness and remain robust to perturbations of the annotation\nbox.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u9ad8\u5ea6\u540c\u8d28\u5316\u7684\u9886\u57df\uff08\u5982\u6c34\u4e0b\u573a\u666f\uff09\u4e2d\uff0c\u901a\u8fc7\u6dfb\u52a0\u57fa\u4e8e\u4f4d\u7f6e\u7684\u63d0\u793a\u6765\u589e\u5f3a\u6587\u672c\u67e5\u8be2\u7684\u56fe\u50cf\u68c0\u7d22\u6548\u679c\uff0c\u7ed3\u679c\u663e\u793a\u7b80\u5355\u5206\u533a\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4e13\u4e1a\u9886\u57df\u4e2d\uff0c\u7528\u6237\u56e0\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\u53ea\u80fd\u63d0\u4f9b\u6a21\u7cca\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u5bfc\u81f4\u591a\u6a21\u6001\u6a21\u578b\u5728\u9ad8\u5ea6\u540c\u8d28\u5316\u573a\u666f\u4e2d\u68c0\u7d22\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u6536\u96c6\u4e86741\u4e2a\u4eba\u5de5\u6807\u6ce8\uff08\u5305\u542b\u6587\u672c\u63cf\u8ff0\u548c\u611f\u5174\u8da3\u533a\u57df\u6846\uff09\uff0c\u8bc4\u4f30CLIP\u6a21\u578b\u5728\u4e0d\u540c\u9759\u6001\u5b50\u533a\u57df\u4e0e\u5b8c\u6574\u56fe\u50cf\u4e0a\u7684\u68c0\u7d22\u8868\u73b0\u3002", "result": "3\u00d73\u5206\u533a\u548c5\u7f51\u683c\u91cd\u53e0\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6548\u679c\uff0c\u5e76\u5bf9\u6807\u6ce8\u6846\u6270\u52a8\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u57fa\u4e8e\u4f4d\u7f6e\u7684\u63d0\u793a\u662f\u63d0\u5347\u9ad8\u5ea6\u540c\u8d28\u5316\u9886\u57df\u56fe\u50cf\u68c0\u7d22\u7684\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2506.06462", "pdf": "https://arxiv.org/pdf/2506.06462", "abs": "https://arxiv.org/abs/2506.06462", "authors": ["Nicol\u00e1s Violante", "Andreas Meuleman", "Alban Gauthier", "Fr\u00e9do Durand", "Thibault Groueix", "George Drettakis"], "title": "Splat and Replace: 3D Reconstruction with Repetitive Elements", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH Conference Papers 2025. Project site:\n  https://repo-sam.inria.fr/nerphys/splat-and-replace/", "summary": "We leverage repetitive elements in 3D scenes to improve novel view synthesis.\nNeural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have greatly\nimproved novel view synthesis but renderings of unseen and occluded parts\nremain low-quality if the training views are not exhaustive enough. Our key\nobservation is that our environment is often full of repetitive elements. We\npropose to leverage those repetitions to improve the reconstruction of\nlow-quality parts of the scene due to poor coverage and occlusions. We propose\na method that segments each repeated instance in a 3DGS reconstruction,\nregisters them together, and allows information to be shared among instances.\nOur method improves the geometry while also accounting for appearance\nvariations across instances. We demonstrate our method on a variety of\nsynthetic and real scenes with typical repetitive elements, leading to a\nsubstantial improvement in the quality of novel view synthesis.", "AI": {"tldr": "\u5229\u75283D\u573a\u666f\u4e2d\u7684\u91cd\u590d\u5143\u7d20\u63d0\u5347\u65b0\u89c6\u89d2\u5408\u6210\u8d28\u91cf\u3002", "motivation": "\u5f53\u524dNeRF\u548c3DGS\u6280\u672f\u867d\u63d0\u5347\u4e86\u65b0\u89c6\u89d2\u5408\u6210\u6548\u679c\uff0c\u4f46\u5bf9\u672a\u8986\u76d6\u6216\u906e\u6321\u533a\u57df\u7684\u6e32\u67d3\u8d28\u91cf\u4ecd\u4e0d\u8db3\u3002\u73af\u5883\u4e2d\u5e38\u6709\u91cd\u590d\u5143\u7d20\uff0c\u53ef\u7528\u4e8e\u6539\u5584\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u52723DGS\u91cd\u5efa\u4e2d\u7684\u91cd\u590d\u5b9e\u4f8b\u3001\u5bf9\u9f50\u5e76\u5171\u4eab\u4fe1\u606f\uff0c\u540c\u65f6\u8003\u8651\u5b9e\u4f8b\u95f4\u7684\u5916\u89c2\u53d8\u5316\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65b0\u89c6\u89d2\u5408\u6210\u7684\u8d28\u91cf\u3002", "conclusion": "\u5229\u7528\u91cd\u590d\u5143\u7d20\u80fd\u6709\u6548\u6539\u8fdb3D\u573a\u666f\u91cd\u5efa\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5728\u8986\u76d6\u4e0d\u8db3\u6216\u5b58\u5728\u906e\u6321\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2506.06968", "pdf": "https://arxiv.org/pdf/2506.06968", "abs": "https://arxiv.org/abs/2506.06968", "authors": ["Pavel Kovalev", "Carlo Angiuli"], "title": "A dependently-typed calculus of event telicity and culminativity", "categories": ["cs.CL", "cs.LO"], "comment": "52 pages, Agda formalization available at\n  https://doi.org/10.5281/zenodo.15602617", "summary": "We present a dependently-typed cross-linguistic framework for analyzing the\ntelicity and culminativity of events, accompanied by examples of using our\nframework to model English sentences. Our framework consists of two parts. In\nthe nominal domain, we model the boundedness of noun phrases and its\nrelationship to subtyping, delimited quantities, and adjectival modification.\nIn the verbal domain we define a dependent event calculus, modeling telic\nevents as those whose undergoer is bounded, culminating events as telic events\nthat achieve their inherent endpoint, and consider adverbial modification. In\nboth domains we pay particular attention to associated entailments. Our\nframework is defined as an extension of intensional Martin-L\\\"of dependent type\ntheory, and the rules and examples in this paper have been formalized in the\nAgda proof assistant.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f9d\u8d56\u7c7b\u578b\u7684\u8de8\u8bed\u8a00\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u4e8b\u4ef6\u7684\u7ec8\u7ed3\u6027\u548c\u5b8c\u6210\u6027\uff0c\u5e76\u5728\u82f1\u8bed\u53e5\u5b50\u5efa\u6a21\u4e2d\u5e94\u7528\u3002\u8be5\u6846\u67b6\u5206\u540d\u4e49\u548c\u52a8\u8bcd\u4e24\u90e8\u5206\u5efa\u6a21\uff0c\u5e76\u901a\u8fc7Agda\u5f62\u5f0f\u5316\u3002", "motivation": "\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684\u65b9\u6cd5\u6765\u5206\u6790\u4e8b\u4ef6\u7684\u7ec8\u7ed3\u6027\u548c\u5b8c\u6210\u6027\uff0c\u89e3\u51b3\u8bed\u8a00\u4e2d\u7684\u754c\u9650\u548c\u5b50\u7c7b\u578b\u95ee\u9898\u3002", "method": "\u6269\u5c55Martin-L\u00f6f\u4f9d\u8d56\u7c7b\u578b\u7406\u8bba\uff0c\u540d\u4e49\u90e8\u5206\u5efa\u6a21\u540d\u8bcd\u77ed\u8bed\u7684\u754c\u9650\u6027\uff0c\u52a8\u8bcd\u90e8\u5206\u5b9a\u4e49\u4f9d\u8d56\u4e8b\u4ef6\u6f14\u7b97\u3002", "result": "\u6210\u529f\u5f62\u5f0f\u5316\u4e86\u6846\u67b6\uff0c\u5e76\u901a\u8fc7Agda\u5b9e\u73b0\u4e86\u89c4\u5219\u548c\u793a\u4f8b\u3002", "conclusion": "\u6846\u67b6\u80fd\u6709\u6548\u5206\u6790\u4e8b\u4ef6\u7ec8\u7ed3\u6027\u548c\u5b8c\u6210\u6027\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5176\u4e25\u8c28\u6027\u3002"}}
{"id": "2506.06767", "pdf": "https://arxiv.org/pdf/2506.06767", "abs": "https://arxiv.org/abs/2506.06767", "authors": ["Wendk\u00fbuni C. Ou\u00e9draogo", "Yinghua Li", "Xueqi Dang", "Xin Zhou", "Anil Koyuncu", "Jacques Klein", "David Lo", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Beyond Surface Similarity: Evaluating LLM-Based Test Refactorings with Structural and Semantic Awareness", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly employed to automatically\nrefactor unit tests, aiming to enhance readability, naming, and structural\nclarity while preserving functional behavior. However, evaluating such\nrefactorings remains challenging: traditional metrics like CodeBLEU are overly\nsensitive to renaming and structural edits, whereas embedding-based\nsimilarities capture semantics but ignore readability and modularity. We\nintroduce CTSES, a composite metric that integrates CodeBLEU, METEOR, and\nROUGE-L to balance behavior preservation, lexical quality, and structural\nalignment. CTSES is evaluated on over 5,000 test suites automatically\nrefactored by GPT-4o and Mistral-Large-2407, using Chain-of-Thought prompting,\nacross two established Java benchmarks: Defects4J and SF110. Our results show\nthat CTSES yields more faithful and interpretable assessments, better aligned\nwith developer expectations and human intuition than existing metrics.", "AI": {"tldr": "CTSES\u662f\u4e00\u79cd\u65b0\u7684\u590d\u5408\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u81ea\u52a8\u91cd\u6784\u5355\u5143\u6d4b\u8bd5\u7684\u6548\u679c\uff0c\u7ed3\u5408\u4e86CodeBLEU\u3001METEOR\u548cROUGE-L\uff0c\u6bd4\u73b0\u6709\u6307\u6807\u66f4\u80fd\u53cd\u6620\u5f00\u53d1\u8005\u671f\u671b\u548c\u4eba\u7c7b\u76f4\u89c9\u3002", "motivation": "\u8bc4\u4f30LLMs\u81ea\u52a8\u91cd\u6784\u5355\u5143\u6d4b\u8bd5\u7684\u6548\u679c\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u4f20\u7edf\u6307\u6807\u5bf9\u91cd\u547d\u540d\u548c\u7ed3\u6784\u7f16\u8f91\u8fc7\u4e8e\u654f\u611f\uff0c\u800c\u57fa\u4e8e\u5d4c\u5165\u7684\u76f8\u4f3c\u6027\u6307\u6807\u5219\u5ffd\u7565\u4e86\u53ef\u8bfb\u6027\u548c\u6a21\u5757\u5316\u3002", "method": "\u63d0\u51faCTSES\u590d\u5408\u6307\u6807\uff0c\u7ed3\u5408CodeBLEU\u3001METEOR\u548cROUGE-L\uff0c\u4ee5\u5e73\u8861\u884c\u4e3a\u4fdd\u7559\u3001\u8bcd\u6c47\u8d28\u91cf\u548c\u7ed3\u6784\u5bf9\u9f50\uff0c\u5e76\u5728\u4e24\u4e2aJava\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86GPT-4o\u548cMistral-Large-2407\u7684\u91cd\u6784\u6548\u679c\u3002", "result": "CTSES\u57285,000\u591a\u4e2a\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5b83\u6bd4\u5176\u4ed6\u6307\u6807\u66f4\u80fd\u63d0\u4f9b\u5fe0\u5b9e\u548c\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\uff0c\u66f4\u7b26\u5408\u5f00\u53d1\u8005\u671f\u671b\u548c\u4eba\u7c7b\u76f4\u89c9\u3002", "conclusion": "CTSES\u662f\u4e00\u79cd\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u9002\u7528\u4e8eLLMs\u81ea\u52a8\u91cd\u6784\u5355\u5143\u6d4b\u8bd5\u7684\u6548\u679c\u8bc4\u4f30\u3002"}}
{"id": "2506.06829", "pdf": "https://arxiv.org/pdf/2506.06829", "abs": "https://arxiv.org/abs/2506.06829", "authors": ["Hritom Das", "Imran Fahad", "SNB Tushar", "Sk Hasibul Alam", "Graham Buchanan", "Danny Scott", "Garrett S. Rose", "Sai Swaminathan"], "title": "In-Sensor Motion Recognition with Memristive System and Light Sensing Surfaces", "categories": ["cs.HC"], "comment": "The paper was published in the 2024 IEEE Computer Society Annual\n  Symposium on VLSI (ISVLSI)", "summary": "In this paper, we introduce a novel device architecture that merges\nmemristive devices with light-sensing surfaces, for energy-efficient motion\nrecognition at the edge. Our light-sensing surface captures motion data through\nin-sensor computation. This data is then processed using a memristive system\nequipped with a HfO2-based synaptic device, coupled with a winner-take-all\n(WTA) circuit, tailored for low-power motion classification tasks. We validate\nour end-to-end system using four distinct human hand gestures - left-to-right,\nright-to-left, bottom-to-top, and top-to-bottom movements - to assess energy\nefficiency and classification robustness. Our experiments show that the system\nrequires an average of only 4.17 nJ for taking our processed analog signal and\nmapping weights onto our memristive system and 0.952 nJ for testing per\nmovement class, achieving 97.22% accuracy even under 5% noise interference. A\nkey advantage of our proposed architecture is its low energy requirement,\nenabling the integration of energy-harvesting solutions such as solar power for\nsustainable autonomous operation. Additionally, our approach enhances data\nprivacy by processing data locally, reducing the need for external data\ntransmission and storage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u8bbe\u5907\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u5408\u5fc6\u963b\u5668\u4ef6\u4e0e\u5149\u654f\u8868\u9762\uff0c\u5b9e\u73b0\u4e86\u8fb9\u7f18\u7aef\u7684\u8282\u80fd\u8fd0\u52a8\u8bc6\u522b\u3002\u5149\u654f\u8868\u9762\u901a\u8fc7\u4f20\u611f\u5668\u5185\u8ba1\u7b97\u6355\u83b7\u8fd0\u52a8\u6570\u636e\uff0c\u5fc6\u963b\u7cfb\u7edf\u5229\u7528HfO2\u57fa\u7a81\u89e6\u5668\u4ef6\u548c\u80dc\u8005\u5168\u5f97\uff08WTA\uff09\u7535\u8def\u8fdb\u884c\u4f4e\u529f\u8017\u8fd0\u52a8\u5206\u7c7b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7cfb\u7edf\u5e73\u5747\u80fd\u8017\u6781\u4f4e\uff0c\u5e76\u5177\u5907\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u8282\u80fd\u7684\u8fb9\u7f18\u7aef\u8fd0\u52a8\u8bc6\u522b\u7cfb\u7edf\uff0c\u7ed3\u5408\u5fc6\u963b\u5668\u4ef6\u4e0e\u5149\u654f\u8868\u9762\uff0c\u4ee5\u5b9e\u73b0\u4f4e\u80fd\u8017\u548c\u9ad8\u9690\u79c1\u4fdd\u62a4\uff0c\u9002\u5408\u53ef\u6301\u7eed\u81ea\u4e3b\u8fd0\u884c\u7684\u5e94\u7528\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5149\u654f\u8868\u9762\u548c\u5fc6\u963b\u7cfb\u7edf\u7684\u67b6\u6784\uff0c\u96c6\u6210\u4e86HfO2\u57fa\u7a81\u89e6\u5668\u4ef6\u548cWTA\u7535\u8def\uff0c\u901a\u8fc7\u56db\u7c7b\u624b\u52bf\u5b9e\u9a8c\u9a8c\u8bc1\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u7cfb\u7edf\u5e73\u5747\u80fd\u8017\u4e3a4.17 nJ\uff08\u9884\u5904\u7406\uff09\u548c0.952 nJ\uff08\u6d4b\u8bd5\uff09\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523097.22%\uff0c\u4e14\u5bf95%\u566a\u58f0\u5e72\u6270\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u67b6\u6784\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\uff0c\u9002\u5408\u7ed3\u5408\u80fd\u91cf\u6536\u96c6\u6280\u672f\uff08\u5982\u592a\u9633\u80fd\uff09\u5b9e\u73b0\u53ef\u6301\u7eed\u8fd0\u884c\uff0c\u540c\u65f6\u901a\u8fc7\u672c\u5730\u6570\u636e\u5904\u7406\u589e\u5f3a\u4e86\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2506.07880", "pdf": "https://arxiv.org/pdf/2506.07880", "abs": "https://arxiv.org/abs/2506.07880", "authors": ["Salar Nouri", "Mojdeh Karbalaee Motalleb", "Vahid Shah-Mansouri"], "title": "Diffusion-RL for Scalable Resource Allocation for 6G Networks", "categories": ["cs.NI", "eess.SP"], "comment": "9 pages, 8 figures", "summary": "This paper presents a novel approach to resource allocation in Open Radio\nAccess Networks (O-RAN), leveraging a Generative AI technique with network\nslicing to address the diverse demands of 5G and 6G service types such as\nEnhanced Mobile Broadband (eMBB), Ultra-Reliable Low-Latency Communications\n(URLLC), and Massive Machine-Type Communications (mMTC). Additionally, we\nprovide a comprehensive analysis and comparison of machine learning (ML)\ntechniques for resource allocation within O-RAN, evaluating their effectiveness\nin optimizing network performance. We introduce a diffusion-based reinforcement\nlearning (Diffusion-RL) algorithm designed to optimize the allocation of\nphysical resource blocks (PRBs) and power consumption, thereby maximizing\nweighted throughput and minimizing the delay for user equipment (UE). The\nDiffusion-RL model incorporates controlled noise and perturbations to explore\noptimal resource distribution while meeting each service type's Quality of\nService (QoS) requirements. We evaluate the performance of our proposed method\nagainst several benchmarks, including an exhaustive search algorithm, deep\nQ-networks (DQN), and the Semi-Supervised Variational Autoencoder (SS-VAE).\nComprehensive metrics, such as throughput and latency, are presented for each\nservice type. Experimental results demonstrate that the Diffusion-based RL\napproach outperforms existing methods in efficiency, scalability, and\nrobustness, offering a promising solution for resource allocation in dynamic\nand heterogeneous O-RAN environments with significant implications for future\n6G networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0fAI\u548c\u7f51\u7edc\u5207\u7247\u7684\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\uff0c\u7528\u4e8eO-RAN\u4e2d\u76845G\u548c6G\u670d\u52a1\u9700\u6c42\uff0c\u5f15\u5165Diffusion-RL\u7b97\u6cd5\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3O-RAN\u4e2d5G\u548c6G\u591a\u6837\u5316\u670d\u52a1\u7c7b\u578b\uff08\u5982eMBB\u3001URLLC\u3001mMTC\uff09\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51faDiffusion-RL\u7b97\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u566a\u58f0\u548c\u6270\u52a8\u4f18\u5316PRB\u548c\u529f\u8017\u5206\u914d\u3002", "result": "Diffusion-RL\u5728\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5982DQN\u3001SS-VAE\uff09\uff0c\u5c55\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Diffusion-RL\u4e3a\u52a8\u6001\u5f02\u6784O-RAN\u73af\u5883\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u5bf96G\u7f51\u7edc\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2506.06590", "pdf": "https://arxiv.org/pdf/2506.06590", "abs": "https://arxiv.org/abs/2506.06590", "authors": ["Kim Calabrese", "David Doty", "Mina Latifi"], "title": "Robust predicate and function computation in continuous chemical reaction networks", "categories": ["cs.CC", "cs.DC", "cs.ET"], "comment": null, "summary": "We initiate the study of rate-constant-independent computation of Boolean\npredicates and numerical functions in the continuous model of chemical reaction\nnetworks (CRNs), which model the amount of a chemical species as a nonnegative,\nreal-valued *concentration*. Real-valued numerical functions have previously\nbeen studied, finding that exactly the continuous, piecewise rational linear\nfunctions $f: \\mathbb{R}_{> 0}^k \\to \\mathbb{R}_{> 0}$ can be computed\n*stably*, a.k.a., *rate-independently*, meaning that the CRN gets the answer\ncorrect no matter the rate at which reactions occur.\n  We show that, contrary to functions, continuous CRNs are severely limited in\nthe Boolean predicates they can stably decide, reporting an answer based only\non which inputs are 0 or positive.\n  This limitation motivates a slightly relaxed notion of rate-independent\ncomputation in CRNs that we call *robust computation*. The standard mass-action\nrate model is used, in which each reaction is assigned a rate equal to the\nproduct of its reactant concentrations and its rate constant. The computation\nis correct in this model if it converges to the correct output for any positive\nchoice of rate constants. This adversary is weaker than the stable computation\nadversary, the latter being able to run reactions at non-mass-action rates.\n  We show that CRNs can robustly decide every finite Boolean combination of\n*threshold predicates*: those predicates defined by taking a rational weighted\nsum of the inputs $\\mathbf{x} \\in \\mathbb{R}^k_{\\ge 0}$ and comparing to a\nconstant, answering the question ``Is $\\sum_{i=1}^k w_i \\cdot \\mathbf{x}(i) >\nh$?'', for rational weights $w_i$ and real threshold $h$. Turning to function\ncomputation, we show that CRNs can robustly compute any piecewise affine\nfunction with rational coefficients, where threshold predicates determine which\naffine piece to evaluate for a given input.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\uff08CRNs\uff09\u4e2d\u901f\u7387\u5e38\u6570\u65e0\u5173\u7684\u5e03\u5c14\u8c13\u8bcd\u548c\u6570\u503c\u51fd\u6570\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u53d1\u73b0\u5e03\u5c14\u8c13\u8bcd\u7684\u8ba1\u7b97\u53d7\u9650\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u5bbd\u677e\u7684\u201c\u7a33\u5065\u8ba1\u7b97\u201d\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u53ef\u4ee5\u89e3\u51b3\u9608\u503c\u8c13\u8bcd\u548c\u5206\u6bb5\u4eff\u5c04\u51fd\u6570\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22CRNs\u5728\u901f\u7387\u5e38\u6570\u72ec\u7acb\u60c5\u51b5\u4e0b\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u7279\u522b\u662f\u5e03\u5c14\u8c13\u8bcd\u548c\u6570\u503c\u51fd\u6570\u7684\u8ba1\u7b97\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u7a33\u5065\u8ba1\u7b97\u65b9\u6cd5\u4ee5\u6269\u5c55\u5176\u9002\u7528\u8303\u56f4\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u8d28\u91cf\u4f5c\u7528\u901f\u7387\u6a21\u578b\uff0c\u5b9a\u4e49\u7a33\u5065\u8ba1\u7b97\u7684\u6761\u4ef6\uff0c\u5373\u5bf9\u4e8e\u4efb\u4f55\u6b63\u901f\u7387\u5e38\u6570\u7684\u9009\u62e9\uff0c\u8ba1\u7b97\u90fd\u80fd\u6536\u655b\u5230\u6b63\u786e\u8f93\u51fa\u3002\u7814\u7a76\u4e86CRNs\u5728\u7a33\u5065\u8ba1\u7b97\u4e0b\u7684\u9608\ufffd\ufffd\u8c13\u8bcd\u548c\u5206\u6bb5\u4eff\u5c04\u51fd\u6570\u7684\u8ba1\u7b97\u80fd\u529b\u3002", "result": "CRNs\u53ef\u4ee5\u7a33\u5065\u5730\u51b3\u5b9a\u6240\u6709\u6709\u9650\u5e03\u5c14\u7ec4\u5408\u7684\u9608\u503c\u8c13\u8bcd\uff0c\u5e76\u8ba1\u7b97\u4efb\u4f55\u6709\u7406\u7cfb\u6570\u7684\u5206\u6bb5\u4eff\u5c04\u51fd\u6570\u3002", "conclusion": "\u7a33\u5065\u8ba1\u7b97\u65b9\u6cd5\u6269\u5c55\u4e86CRNs\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u66f4\u590d\u6742\u7684\u5e03\u5c14\u8c13\u8bcd\u548c\u6570\u503c\u51fd\u6570\u95ee\u9898\uff0c\u5c3d\u7ba1\u5728\u4e25\u683c\u7684\u901f\u7387\u72ec\u7acb\u6761\u4ef6\u4e0b\u5176\u8868\u73b0\u53d7\u9650\u3002"}}
{"id": "2506.07379", "pdf": "https://arxiv.org/pdf/2506.07379", "abs": "https://arxiv.org/abs/2506.07379", "authors": ["Bruno Moreira Coimbra", "Marco Mambelli"], "title": "Addressing tokens dynamic generation, propagation, storage and renewal to secure the GlideinWMS pilot based jobs and system", "categories": ["cs.DC", "H.3.4; D.2.7"], "comment": "8 pages, 3 figures, for associated code, see\n  https://github.com/glideinWMS/glideinwms, to be published in proceedings of\n  27th International Conference on Computing in High Energy and Nuclear Physics\n  (CHEP 2024). 21-25 October 2024. Krakow,; Poland. (C24-10-21.8)", "summary": "GlideinWMS has been one of the first middleware in the WLCG community to\ntransition from X.509 to support also tokens. The first step was to get from\nthe prototype in 2019 to using tokens in production in 2022. This paper will\npresent the challenges introduced by the wider adoption of tokens and the\nevolution plans for securing the pilot infrastructure of GlideinWMS and\nsupporting the new requirements. In the last couple of years, the GlideinWMS\nteam supported the migration of experiments and resources to tokens. Inadequate\nsupport in the current infrastructure, more stringent requirements, and the\nhigher spatial and temporal granularity forced GlideinWMS to revisit once more\nhow credentials are generated, used, and propagated. The new credential modules\nhave been designed to be used in multiple systems (GlideinWMS, HEPCloud) and\nuse a model where credentials have type, purpose, and different flows.\nCredentials are dynamically generated in order to customize the duration and\nlimit the scope to the targeted resource. This allows to enforce the least\nprivilege principle. Finally, we also considered adding credential storage,\nrenewal, and invalidation mechanisms within the GlideinWMS infrastructure to\nbetter serve the experiments' needs.", "AI": {"tldr": "GlideinWMS\u4eceX.509\u8f6c\u5411\u652f\u6301\u4ee4\u724c\u7684\u751f\u4ea7\u5e94\u7528\uff0c\u9047\u5230\u6311\u6218\u5e76\u8ba1\u5212\u4f18\u5316\u57fa\u7840\u8bbe\u65bd\u4ee5\u6ee1\u8db3\u65b0\u9700\u6c42\u3002", "motivation": "GlideinWMS\u56e2\u961f\u9700\u8981\u652f\u6301\u4ee4\u724c\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5e76\u89e3\u51b3\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u4e0d\u8db3\u548c\u66f4\u4e25\u683c\u7684\u8981\u6c42\u3002", "method": "\u8bbe\u8ba1\u4e86\u65b0\u7684\u51ed\u8bc1\u6a21\u5757\uff0c\u652f\u6301\u52a8\u6001\u751f\u6210\u3001\u7c7b\u578b\u5316\u7ba1\u7406\u548c\u6700\u5c0f\u6743\u9650\u539f\u5219\uff0c\u5e76\u8ba1\u5212\u52a0\u5165\u5b58\u50a8\u3001\u66f4\u65b0\u548c\u5931\u6548\u673a\u5236\u3002", "result": "\u5b9e\u73b0\u4e86\u51ed\u8bc1\u5728\u591a\u7cfb\u7edf\u4e2d\u7684\u901a\u7528\u6027\uff0c\u652f\u6301\u52a8\u6001\u8303\u56f4\u548c\u65f6\u95f4\u7684\u5b9a\u5236\u3002", "conclusion": "GlideinWMS\u901a\u8fc7\u6539\u8fdb\u51ed\u8bc1\u7ba1\u7406\uff0c\u66f4\u597d\u5730\u6ee1\u8db3\u4e86\u5b9e\u9a8c\u9700\u6c42\u5e76\u589e\u5f3a\u4e86\u5b89\u5168\u6027\u3002"}}
{"id": "2506.07046", "pdf": "https://arxiv.org/pdf/2506.07046", "abs": "https://arxiv.org/abs/2506.07046", "authors": ["Anushka Jha", "Tanushree Dewangan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "QForce-RL: Quantized FPGA-Optimized Reinforcement Learning Compute Engine", "categories": ["cs.AR", "cs.CV", "cs.RO", "eess.IV"], "comment": null, "summary": "Reinforcement Learning (RL) has outperformed other counterparts in sequential\ndecision-making and dynamic environment control. However, FPGA deployment is\nsignificantly resource-expensive, as associated with large number of\ncomputations in training agents with high-quality images and possess new\nchallenges. In this work, we propose QForce-RL takes benefits of quantization\nto enhance throughput and reduce energy footprint with light-weight RL\narchitecture, without significant performance degradation. QForce-RL takes\nadvantages from E2HRL to reduce overall RL actions to learn desired policy and\nQuaRL for quantization based SIMD for hardware acceleration. We have also\nprovided detailed analysis for different RL environments, with emphasis on\nmodel size, parameters, and accelerated compute ops. The architecture is\nscalable for resource-constrained devices and provide parametrized efficient\ndeployment with flexibility in latency, throughput, power, and energy\nefficiency. The proposed QForce-RL provides performance enhancement up to 2.3x\nand better FPS - 2.6x compared to SoTA works.", "AI": {"tldr": "QForce-RL\u662f\u4e00\u79cd\u5229\u7528\u91cf\u5316\u548c\u8f7b\u91cf\u7ea7\u67b6\u6784\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86FPGA\u90e8\u7f72\u7684\u541e\u5410\u91cf\u548c\u80fd\u6e90\u6548\u7387\u3002", "motivation": "FPGA\u90e8\u7f72\u5f3a\u5316\u5b66\u4e60\u8d44\u6e90\u6d88\u8017\u5927\uff0cQForce-RL\u65e8\u5728\u901a\u8fc7\u91cf\u5316\u548c\u8f7b\u91cf\u7ea7\u67b6\u6784\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408E2HRL\u51cf\u5c11\u52a8\u4f5c\u7a7a\u95f4\u548cQuaRL\u7684\u91cf\u5316SIMD\u52a0\u901f\u786c\u4ef6\uff0c\u4f18\u5316\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u64cd\u4f5c\u3002", "result": "\u6027\u80fd\u63d0\u53472.3\u500d\uff0c\u5e27\u7387\u63d0\u53472.6\u500d\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u3002", "conclusion": "QForce-RL\u5728\u8d44\u6e90\u6548\u7387\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.07076", "pdf": "https://arxiv.org/pdf/2506.07076", "abs": "https://arxiv.org/abs/2506.07076", "authors": ["Xinyi Wu", "Haohong Wang", "Aggelos K. Katsaggelos"], "title": "Harmony-Aware Music-driven Motion Synthesis with Perceptual Constraint on UGC Datasets", "categories": ["cs.MM"], "comment": null, "summary": "With the popularity of video-based user-generated content (UGC) on social\nmedia, harmony, as dictated by human perceptual principles, is critical in\nassessing the rhythmic consistency of audio-visual UGCs for better user\nengagement. In this work, we propose a novel harmony-aware GAN framework,\nfollowing a specifically designed harmony evaluation strategy to enhance\nrhythmic synchronization in the automatic music-to-motion synthesis using a UGC\ndance dataset. This harmony strategy utilizes refined cross-modal beat\ndetection to capture closely correlated audio and visual rhythms in an\naudio-visual pair. To mimic human attention mechanism, we introduce\nsaliency-based beat weighting and interval-driven beat alignment, which ensures\naccurate harmony score estimation consistent with human perception. Building on\nthis strategy, our model, employing efficient encoder-decoder and depth-lifting\ndesigns, is adversarially trained based on categorized musical meter segments\nto generate realistic and rhythmic 3D human motions. We further incorporate our\nharmony evaluation strategy as a weakly supervised perceptual constraint to\nflexibly guide the synchronized audio-visual rhythms during the generation\nprocess. Experimental results show that our proposed model significantly\noutperforms other leading music-to-motion methods in rhythmic harmony, both\nquantitatively and qualitatively, even with limited UGC training data. Live\nsamples 15 can be watched at: https://youtu.be/tWwz7yq4aUs", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGAN\u7684\u548c\u8c10\u611f\u77e5\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u97f3\u4e50\u5230\u52a8\u4f5c\u5408\u6210\u7684\u8282\u594f\u540c\u6b65\u6027\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u8282\u62cd\u68c0\u6d4b\u548c\u4eba\u7c7b\u611f\u77e5\u7b56\u7565\u5b9e\u73b0\u66f4\u81ea\u7136\u76843D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u3002", "motivation": "\u968f\u7740\u89c6\u9891\u7528\u6237\u751f\u6210\u5185\u5bb9\uff08UGC\uff09\u7684\u6d41\u884c\uff0c\u57fa\u4e8e\u4eba\u7c7b\u611f\u77e5\u539f\u5219\u7684\u548c\u8c10\u6027\u5bf9\u63d0\u5347\u97f3\u9891-\u89c6\u89c9\u5185\u5bb9\u7684\u8282\u594f\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4ece\u800c\u63d0\u9ad8\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u548c\u8c10\u8bc4\u4f30\u7b56\u7565\uff0c\u5305\u62ec\u8de8\u6a21\u6001\u8282\u62cd\u68c0\u6d4b\u3001\u57fa\u4e8e\u663e\u8457\u6027\u7684\u8282\u62cd\u52a0\u6743\u548c\u95f4\u9694\u9a71\u52a8\u7684\u8282\u62cd\u5bf9\u9f50\uff1b\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u548c\u6df1\u5ea6\u63d0\u5347\u8bbe\u8ba1\u7684GAN\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5f31\u76d1\u7763\u611f\u77e5\u7ea6\u675f\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8282\u594f\u548c\u8c10\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u97f3\u4e50\u5230\u52a8\u4f5c\u5408\u6210\u65b9\u6cd5\uff0c\u5373\u4f7f\u8bad\u7ec3\u6570\u636e\u6709\u9650\uff0c\u4e5f\u80fd\u751f\u6210\u66f4\u771f\u5b9e\u76843D\u4eba\u4f53\u8fd0\u52a8\u3002", "conclusion": "\u63d0\u51fa\u7684\u548c\u8c10\u611f\u77e5\u6846\u67b6\u548c\u8bc4\u4f30\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u97f3\u4e50\u5230\u52a8\u4f5c\u5408\u6210\u7684\u8282\u594f\u540c\u6b65\u6027\uff0c\u7b26\u5408\u4eba\u7c7b\u611f\u77e5\u539f\u5219\u3002"}}
{"id": "2506.06483", "pdf": "https://arxiv.org/pdf/2506.06483", "abs": "https://arxiv.org/abs/2506.06483", "authors": ["Yao Ni", "Song Wen", "Piotr Koniusz", "Anoop Cherian"], "title": "Noise Consistency Regularization for Improved Subject-Driven Image Synthesis", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Fine-tuning Stable Diffusion enables subject-driven image synthesis by\nadapting the model to generate images containing specific subjects. However,\nexisting fine-tuning methods suffer from two key issues: underfitting, where\nthe model fails to reliably capture subject identity, and overfitting, where it\nmemorizes the subject image and reduces background diversity. To address these\nchallenges, we propose two auxiliary consistency losses for diffusion\nfine-tuning. First, a prior consistency regularization loss ensures that the\npredicted diffusion noise for prior (non-subject) images remains consistent\nwith that of the pretrained model, improving fidelity. Second, a subject\nconsistency regularization loss enhances the fine-tuned model's robustness to\nmultiplicative noise modulated latent code, helping to preserve subject\nidentity while improving diversity. Our experimental results demonstrate that\nincorporating these losses into fine-tuning not only preserves subject identity\nbut also enhances image diversity, outperforming DreamBooth in terms of CLIP\nscores, background variation, and overall visual quality.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u8f85\u52a9\u4e00\u81f4\u6027\u635f\u5931\uff08\u5148\u9a8c\u4e00\u81f4\u6027\u6b63\u5219\u5316\u548c\u4e3b\u9898\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff09\u6765\u6539\u8fdbStable Diffusion\u7684\u5fae\u8c03\uff0c\u89e3\u51b3\u8eab\u4efd\u6355\u6349\u4e0d\u8db3\u548c\u80cc\u666f\u591a\u6837\u6027\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002", "motivation": "\u73b0\u6709\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u8eab\u4efd\u6355\u6349\u4e0d\u53ef\u9760\uff08\u6b20\u62df\u5408\uff09\u548c\u80cc\u666f\u591a\u6837\u6027\u51cf\u5c11\uff08\u8fc7\u62df\u5408\uff09\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u751f\u6210\u7684\u56fe\u50cf\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u4e00\u81f4\u6027\u635f\u5931\uff1a\u5148\u9a8c\u4e00\u81f4\u6027\u6b63\u5219\u5316\u4fdd\u6301\u975e\u4e3b\u9898\u56fe\u50cf\u7684\u566a\u58f0\u9884\u6d4b\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u4e00\u81f4\uff0c\u4e3b\u9898\u4e00\u81f4\u6027\u6b63\u5219\u5316\u589e\u5f3a\u6a21\u578b\u5bf9\u566a\u58f0\u8c03\u5236\u7684\u6f5c\u5728\u4ee3\u7801\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728CLIP\u5206\u6570\u3001\u80cc\u666f\u591a\u6837\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u4e0a\u4f18\u4e8eDreamBooth\uff0c\u66f4\u597d\u5730\u4fdd\u7559\u4e86\u4e3b\u9898\u8eab\u4efd\u5e76\u63d0\u5347\u4e86\u591a\u6837\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e00\u81f4\u6027\u635f\u5931\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6b20\u62df\u5408\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u5347\u4e86Stable Diffusion\u6a21\u578b\u5728\u4e3b\u9898\u9a71\u52a8\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2506.07131", "pdf": "https://arxiv.org/pdf/2506.07131", "abs": "https://arxiv.org/abs/2506.07131", "authors": ["Ruy J. G. B. de Queiroz"], "title": "Meaning as Use, Application, Employment, Purpose, Usefulness", "categories": ["math.HO", "cs.LO", "03, 00, 03F03, 03Fxx, 03B38", "F.4.1; F.3.2"], "comment": null, "summary": "Arising from the whole body of Wittgenstein's writings is a picture of a (not\nnecessarily straight, linear, but admittedly tireless) journey to come to terms\nwith the mechanics of language as an instrument to conceive `reality' and to\ncommunicate an acquired conception of the `world'. The journey passes through\nmathematics, psychology, color perception, certainty, aesthetic, but, looking\nat it from a sort of birdview, it seems reasonable to say that these are all\nused as `test beds' for his reflections and `experimentations' towards an all\nencompassing perspective of such a fundamental gateway to human reasoning and\nlife-revealing as language. Whatever labelling of Wittgenstein as a mystic, a\nlogicist, a conventionalist, a skeptic, an anti-metaphysics, an anti-realist, a\nverificationist, a pragmatist, and many others, does not seem to do justice to\nhis absolute obsession with being a persistent `deep diver' into the nature of\nlanguage. Working with an open and searchable account of the Nachlass has\nallowed us to identify important aspects of the philosopher's possible common\nline of thinking, in spite of changes of directions, some of them acknowledged\nby Wittgenstein himself. One of those aspects is the association of meaning\nwith use, application, purpose, usefulness of symbols in language, which\nhappens to show itself from the very beginning through to the very late\nwritings. The German terms Gebrauch, Anwendung, \\emph{Verwendung}, Zweck in\nrelation to meaning, sense of signs, words, sentences, appear in several texts\nsince the WW1 Notebooks (1914--1916) up until very late manuscripts from\n1950--51.", "AI": {"tldr": "Wittgenstein\u5bf9\u8bed\u8a00\u7684\u672c\u8d28\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76\uff0c\u5c06\u5176\u89c6\u4e3a\u7406\u89e3\u73b0\u5b9e\u548c\u4e16\u754c\u7684\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u3001\u5fc3\u7406\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u6d4b\u8bd5\u5176\u7406\u8bba\uff0c\u6700\u7ec8\u5f3a\u8c03\u8bed\u8a00\u7684\u610f\u4e49\u4e0e\u4f7f\u7528\u3001\u76ee\u7684\u5bc6\u5207\u76f8\u5173\u3002", "motivation": "\u63a2\u8ba8Wittgenstein\u5982\u4f55\u901a\u8fc7\u5bf9\u8bed\u8a00\u7684\u591a\u89d2\u5ea6\u7814\u7a76\uff0c\u63ed\u793a\u5176\u4f5c\u4e3a\u4eba\u7c7b\u63a8\u7406\u548c\u751f\u6d3b\u63ed\u793a\u7684\u6839\u672c\u9014\u5f84\u3002", "method": "\u901a\u8fc7\u5f00\u653e\u548c\u53ef\u641c\u7d22\u7684Nachlass\u8d44\u6599\u5e93\uff0c\u5206\u6790Wittgenstein\u7684\u6587\u672c\uff0c\u8ffd\u8e2a\u5176\u5bf9\u8bed\u8a00\u610f\u4e49\u4e0e\u4f7f\u7528\u7684\u53cd\u590d\u63a2\u8ba8\u3002", "result": "\u53d1\u73b0Wittgenstein\u4ece\u65e9\u671f\u5230\u665a\u671f\u7684\u8457\u4f5c\u4e2d\u59cb\u7ec8\u5f3a\u8c03\u8bed\u8a00\u610f\u4e49\u4e0e\u4f7f\u7528\u3001\u76ee\u7684\u7684\u5173\u7cfb\uff0c\u8fd9\u4e00\u6838\u5fc3\u601d\u60f3\u8d2f\u7a7f\u5176\u7814\u7a76\u3002", "conclusion": "Wittgenstein\u7684\u7814\u7a76\u5c55\u793a\u4e86\u8bed\u8a00\u4f5c\u4e3a\u610f\u4e49\u8f7d\u4f53\u7684\u6838\u5fc3\u5730\u4f4d\uff0c\u5176\u601d\u60f3\u8d85\u8d8a\u4e86\u5355\u4e00\u6807\u7b7e\uff0c\u4f53\u73b0\u4e86\u5bf9\u8bed\u8a00\u672c\u8d28\u7684\u6301\u7eed\u63a2\u7d22\u3002"}}
{"id": "2506.06946", "pdf": "https://arxiv.org/pdf/2506.06946", "abs": "https://arxiv.org/abs/2506.06946", "authors": ["Daniel Lawand", "Lucas Quaresma", "Roberto Bolgheroni", "Alfredo Goldman", "Renato Cordeiro Ferreira"], "title": "Is Your Training Pipeline Production-Ready? A Case Study in the Healthcare Domain", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.7; I.2.7; I.5.4"], "comment": "9 pages, 3 figures (2 diagrams, 1 code listing), submitted to the\n  workshop SADIS 2025", "summary": "Deploying a Machine Learning (ML) training pipeline into production requires\nrobust software engineering practices. This differs significantly from\nexperimental workflows. This experience report investigates this challenge in\nSPIRA, a project whose goal is to create an ML-Enabled System (MLES) to\npre-diagnose insufficiency respiratory via speech analysis. The first version\nof SPIRA's training pipeline lacked critical software quality attributes. This\npaper presents an overview of the MLES, then compares three versions of the\narchitecture of the Continuous Training subsystem, which evolved from a Big\nBall of Mud, to a Modular Monolith, towards Microservices. By adopting\ndifferent design principles and patterns to enhance its maintainability,\nrobustness, and extensibility. In this way, the paper seeks to offer insights\nfor both ML Engineers tasked to productionize ML training pipelines and Data\nScientists seeking to adopt MLOps practices.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5c06\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u7ba1\u9053\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\u7684\u6311\u6218\uff0c\u901a\u8fc7SPIRA\u9879\u76ee\u7684\u6848\u4f8b\u5c55\u793a\u4e86\u4ece\u521d\u59cb\u6df7\u4e71\u67b6\u6784\u5230\u6a21\u5757\u5316\u5355\u4f53\u67b6\u6784\uff0c\u518d\u5230\u5fae\u670d\u52a1\u67b6\u6784\u7684\u6f14\u53d8\u8fc7\u7a0b\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u7ba1\u9053\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7f3a\u4e4f\u5173\u952e\u8f6f\u4ef6\u8d28\u91cf\u5c5e\u6027\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u3001\u5065\u58ee\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83SPIRA\u9879\u76ee\u4e2d\u4e09\u4e2a\u7248\u672c\u7684\u8fde\u7eed\u8bad\u7ec3\u5b50\u7cfb\u7edf\u67b6\u6784\uff08\u4ece\u6df7\u4e71\u67b6\u6784\u5230\u6a21\u5757\u5316\u5355\u4f53\u67b6\u6784\uff0c\u518d\u5230\u5fae\u670d\u52a1\u67b6\u6784\uff09\uff0c\u91c7\u7528\u4e0d\u540c\u7684\u8bbe\u8ba1\u539f\u5219\u548c\u6a21\u5f0f\u3002", "result": "\u4f18\u5316\u540e\u7684\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u3001\u5065\u58ee\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u548c\u6570\u636e\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e86\u751f\u4ea7\u5316\u5b9e\u8df5\u7684\u53c2\u8003\u3002", "conclusion": "\u901a\u8fc7\u67b6\u6784\u6f14\u5316\uff0c\u8bc1\u660e\u4e86\u8bbe\u8ba1\u539f\u5219\u548c\u6a21\u5f0f\u5728\u63d0\u5347ML\u8bad\u7ec3\u7ba1\u9053\u751f\u4ea7\u73af\u5883\u6027\u80fd\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u76f8\u5173\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u7ecf\u9a8c\u3002"}}
{"id": "2506.06874", "pdf": "https://arxiv.org/pdf/2506.06874", "abs": "https://arxiv.org/abs/2506.06874", "authors": ["Ala Yankouskaya", "Areej B. Babiker", "Syeda W. F. Rizvi", "Sameha Alshakhsi", "Magnus Liebherr", "Raian Ali"], "title": "LLM-D12: A Dual-Dimensional Scale of Instrumental and Relational Dependencies on Large Language Models", "categories": ["cs.HC", "cs.AI", "Human-Centered Computing -- > Human computer interaction (HCI) -->\n  HCI design and evaluation methods"], "comment": null, "summary": "There is growing interest in understanding how people interact with large\nlanguage models (LLMs) and whether such models elicit dependency or even\naddictive behaviour. Validated tools to assess the extent to which individuals\nmay become dependent on LLMs are scarce and primarily build on classic\nbehavioral addiction symptoms, adapted to the context of LLM use. We view this\nas a conceptual limitation, as the LLM-human relationship is more nuanced and\nwarrants a fresh and distinct perspective. To address this gap, we developed\nand validated a new 12-item questionnaire to measure LLM dependency, referred\nto as LLM-D12. The scale was based on the authors' prior theoretical work, with\nitems developed accordingly and responses collected from 526 participants in\nthe UK. Exploratory and confirmatory factor analyses, performed on separate\nhalves of the total sample using a split-sample approach, supported a\ntwo-factor structure: Instrumental Dependency (six items) and Relationship\nDependency (six items). Instrumental Dependency reflects the extent to which\nindividuals rely on LLMs to support or collaborate in decision-making and\ncognitive tasks. Relationship Dependency captures the tendency to perceive LLMs\nas socially meaningful, sentient, or companion-like entities. The two-factor\nstructure demonstrated excellent internal consistency and clear discriminant\nvalidity. External validation confirmed both the conceptual foundation and the\ndistinction between the two subscales. The psychometric properties and\nstructure of our LLM-D12 scale were interpreted in light of the emerging view\nthat dependency on LLMs does not necessarily indicate dysfunction but may still\nreflect reliance levels that could become problematic in certain contexts.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u768412\u9879\u95ee\u5377LLM-D12\uff0c\u7528\u4e8e\u6d4b\u91cf\u4eba\u4eec\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4f9d\u8d56\u6027\uff0c\u5305\u62ec\u5de5\u5177\u6027\u4f9d\u8d56\u548c\u5173\u7cfb\u6027\u4f9d\u8d56\u4e24\u4e2a\u7ef4\u5ea6\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u8bc4\u4f30\u4eba\u4eec\u5bf9LLM\u4f9d\u8d56\u6027\u7684\u5de5\u5177\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u884c\u4e3a\u6210\u763e\u75c7\u72b6\uff0c\u800cLLM\u4e0e\u4eba\u7c7b\u7684\u5173\u7cfb\u66f4\u4e3a\u590d\u6742\uff0c\u9700\u8981\u65b0\u89c6\u89d2\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5de5\u4f5c\u5f00\u53d1\u4e8612\u9879\u7684LLM-D12\u95ee\u5377\uff0c\u6536\u96c6\u4e86526\u540d\u82f1\u56fd\u53c2\u4e0e\u8005\u7684\u6570\u636e\uff0c\u4f7f\u7528\u5206\u6837\u672c\u65b9\u6cd5\u8fdb\u884c\u4e86\u63a2\u7d22\u6027\u548c\u9a8c\u8bc1\u6027\u56e0\u5b50\u5206\u6790\u3002", "result": "\u95ee\u5377\u652f\u6301\u53cc\u56e0\u5b50\u7ed3\u6784\uff1a\u5de5\u5177\u6027\u4f9d\u8d56\u548c\u5173\u7cfb\u6027\u4f9d\u8d56\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u5185\u90e8\u4e00\u81f4\u6027\u548c\u533a\u5206\u6548\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u5176\u6982\u5ff5\u57fa\u7840\u3002", "conclusion": "LLM-D12\u95ee\u5377\u4e3a\u8bc4\u4f30LLM\u4f9d\u8d56\u6027\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u8868\u660e\u4f9d\u8d56\u4e0d\u4e00\u5b9a\u662f\u529f\u80fd\u5931\u8c03\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u5883\u4e0b\u53ef\u80fd\u6210\u4e3a\u95ee\u9898\u3002"}}
{"id": "2506.06474", "pdf": "https://arxiv.org/pdf/2506.06474", "abs": "https://arxiv.org/abs/2506.06474", "authors": ["Everett Richards", "Bipul Thapa", "Lena Mashayekhy"], "title": "Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.MA", "cs.NI", "I.4.8; I.2.10; I.2.11; I.2.9; C.2.4"], "comment": "This paper has been accepted to IEEE EDGE 2025. The final version\n  will be published in IEEE Xplore later this year", "summary": "Accurate and reliable object detection is critical for ensuring the safety\nand efficiency of Connected Autonomous Vehicles (CAVs). Traditional on-board\nperception systems have limited accuracy due to occlusions and blind spots,\nwhile cloud-based solutions introduce significant latency, making them\nunsuitable for real-time processing demands required for autonomous driving in\ndynamic environments. To address these challenges, we introduce an innovative\nframework, Edge-Enabled Collaborative Object Detection (ECOD) for CAVs, that\nleverages edge computing and multi-CAV collaboration for real-time,\nmulti-perspective object detection. Our ECOD framework integrates two key\nalgorithms: Perceptive Aggregation and Collaborative Estimation (PACE) and\nVariable Object Tally and Evaluation (VOTE). PACE aggregates detection data\nfrom multiple CAVs on an edge server to enhance perception in scenarios where\nindividual CAVs have limited visibility. VOTE utilizes a consensus-based voting\nmechanism to improve the accuracy of object classification by integrating data\nfrom multiple CAVs. Both algorithms are designed at the edge to operate in\nreal-time, ensuring low-latency and reliable decision-making for CAVs. We\ndevelop a hardware-based controlled testbed consisting of camera-equipped\nrobotic CAVs and an edge server to evaluate the efficacy of our framework. Our\nexperimental results demonstrate the significant benefits of ECOD in terms of\nimproved object classification accuracy, outperforming traditional\nsingle-perspective onboard approaches by up to 75%, while ensuring low-latency,\nedge-driven real-time processing. This research highlights the potential of\nedge computing to enhance collaborative perception for latency-sensitive\nautonomous systems.", "AI": {"tldr": "ECOD\u6846\u67b6\u5229\u7528\u8fb9\u7f18\u8ba1\u7b97\u548c\u591aCAV\u534f\u4f5c\uff0c\u901a\u8fc7PACE\u548cVOTE\u7b97\u6cd5\u63d0\u5347\u5b9e\u65f6\u591a\u89c6\u89d2\u7269\u4f53\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0cECOD\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u6bd4\u4f20\u7edf\u5355\u89c6\u89d2\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe75%\u3002", "motivation": "\u4f20\u7edf\u8f66\u8f7d\u611f\u77e5\u7cfb\u7edf\u56e0\u906e\u6321\u548c\u76f2\u533a\u51c6\u786e\u6027\u53d7\u9650\uff0c\u800c\u4e91\u7aef\u89e3\u51b3\u65b9\u6848\u5ef6\u8fdf\u9ad8\uff0c\u65e0\u6cd5\u6ee1\u8db3\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u52a8\u9a7e\u9a76\u7684\u5b9e\u65f6\u9700\u6c42\u3002", "method": "ECOD\u6846\u67b6\u6574\u5408PACE\u548cVOTE\u7b97\u6cd5\uff0c\u524d\u8005\u805a\u5408\u591aCAV\u6570\u636e\u4ee5\u589e\u5f3a\u611f\u77e5\uff0c\u540e\u8005\u901a\u8fc7\u5171\u8bc6\u6295\u7968\u673a\u5236\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cECOD\u5728\u7269\u4f53\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u534775%\uff0c\u540c\u65f6\u786e\u4fdd\u4f4e\u5ef6\u8fdf\u5b9e\u65f6\u5904\u7406\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u8fb9\u7f18\u8ba1\u7b97\u53ef\u663e\u8457\u589e\u5f3a\u5bf9\u5ef6\u8fdf\u654f\u611f\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u534f\u4f5c\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2506.07135", "pdf": "https://arxiv.org/pdf/2506.07135", "abs": "https://arxiv.org/abs/2506.07135", "authors": ["Jos\u00e9 Manuel Su\u00e1rez", "Lu\u00eds Mariano Bibb\u00f3", "Joaqu\u00edn Bogado", "Alejandro Fernandez"], "title": "Taxonomy of migration scenarios for Qiskit refactoring using LLMs", "categories": ["cs.SE", "cs.AI", "cs.ET"], "comment": "Accepted for publication in ASQC JAIIO 54\n  (https://54jaiio.sadio.org.ar/simposios/)", "summary": "As quantum computing advances, quantum programming libraries' heterogeneity\nand steady evolution create new challenges for software developers. Frequent\nupdates in software libraries break working code that needs to be refactored,\nthus adding complexity to an already complex landscape. These refactoring\nchallenges are, in many cases, fundamentally different from those known in\nclassical software engineering due to the nature of quantum computing software.\nThis study addresses these challenges by developing a taxonomy of quantum\ncircuit's refactoring problems, providing a structured framework to analyze and\ncompare different refactoring approaches. Large Language Models (LLMs) have\nproven valuable tools for classic software development, yet their value in\nquantum software engineering remains unexplored. This study uses LLMs to\ncategorize refactoring needs in migration scenarios between different Qiskit\nversions. Qiskit documentation and release notes were scrutinized to create an\ninitial taxonomy of refactoring required for migrating between Qiskit releases.\nTwo taxonomies were produced: one by expert developers and one by an LLM. These\ntaxonomies were compared, analyzing differences and similarities, and were\nintegrated into a unified taxonomy that reflects the findings of both methods.\nBy systematically categorizing refactoring challenges in Qiskit, the unified\ntaxonomy is a foundation for future research on AI-assisted migration while\nenabling a more rigorous evaluation of automated refactoring techniques.\nAdditionally, this work contributes to quantum software engineering (QSE) by\nenhancing software development workflows, improving language compatibility, and\npromoting best practices in quantum programming.", "AI": {"tldr": "\u7814\u7a76\u4e86\u91cf\u5b50\u7f16\u7a0b\u4e2d\u8f6f\u4ef6\u5e93\u9891\u7e41\u66f4\u65b0\u5e26\u6765\u7684\u4ee3\u7801\u91cd\u6784\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u91cf\u5b50\u7535\u8def\u91cd\u6784\u95ee\u9898\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u5206\u7c7bQiskit\u7248\u672c\u8fc1\u79fb\u4e2d\u7684\u91cd\u6784\u9700\u6c42\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u8f6f\u4ef6\u7684\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u8f6f\u4ef6\u5e93\u9891\u7e41\u66f4\u65b0\uff0c\u4ee3\u7801\u9700\u8981\u91cd\u6784\uff0c\u800c\u8fd9\u4e9b\u95ee\u9898\u4e0e\u7ecf\u5178\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u91cd\u6784\u95ee\u9898\u6709\u672c\u8d28\u4e0d\u540c\uff0c\u4e9f\u9700\u7cfb\u7edf\u5316\u7814\u7a76\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790Qiskit\u6587\u6863\u548c\u53d1\u5e03\u8bf4\u660e\u5efa\u7acb\u521d\u59cb\u91cd\u6784\u5206\u7c7b\u6cd5\uff0c\u5e76\u5206\u522b\u7531\u4e13\u5bb6\u548cLLM\u751f\u6210\u4e24\u79cd\u5206\u7c7b\u6cd5\uff0c\u6700\u7ec8\u6574\u5408\u4e3a\u7edf\u4e00\u7684\u5206\u7c7b\u6cd5\u3002", "result": "\u751f\u6210\u4e86\u4e24\u79cd\u5206\u7c7b\u6cd5\u5e76\u6574\u5408\u6210\u7edf\u4e00\u7684\u5206\u7c7b\u6cd5\uff0c\u4e3aAI\u8f85\u52a9\u8fc1\u79fb\u548c\u81ea\u52a8\u5316\u91cd\u6784\u6280\u672f\u7684\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u5de5\u5177\uff0c\u4f18\u5316\u4e86\u5f00\u53d1\u6d41\u7a0b\uff0c\u63d0\u5347\u4e86\u8bed\u8a00\u517c\u5bb9\u6027\uff0c\u5e76\u4fc3\u8fdb\u4e86\u91cf\u5b50\u7f16\u7a0b\u7684\u6700\u4f73\u5b9e\u8df5\u3002"}}
{"id": "2506.07574", "pdf": "https://arxiv.org/pdf/2506.07574", "abs": "https://arxiv.org/abs/2506.07574", "authors": ["Alkida Balliu", "Corinna Coupette", "Antonio Cruciani", "Francesco d'Amore", "Massimo Equi", "Henrik Lievonen", "Augusto Modanese", "Dennis Olivetti", "Jukka Suomela"], "title": "New Limits on Distributed Quantum Advantage: Dequantizing Linear Programs", "categories": ["cs.DC", "cs.CC"], "comment": null, "summary": "In this work, we give two results that put new limits on distributed quantum\nadvantage in the context of the LOCAL model of distributed computing. First, we\nshow that there is no distributed quantum advantage for any linear program. Put\notherwise, if there is a quantum-LOCAL algorithm $\\mathcal{A}$ that finds an\n$\\alpha$-approximation of some linear optimization problem $\\Pi$ in $T$\ncommunication rounds, we can construct a classical, deterministic LOCAL\nalgorithm $\\mathcal{A}'$ that finds an $\\alpha$-approximation of $\\Pi$ in $T$\nrounds. As a corollary, all classical lower bounds for linear programs,\nincluding the KMW bound, hold verbatim in quantum-LOCAL. Second, using the\nabove result, we show that there exists a locally checkable labeling problem\n(LCL) for which quantum-LOCAL is strictly weaker than the classical\ndeterministic SLOCAL model. Our results extend from quantum-LOCAL also to\nfinitely dependent and non-signaling distributions, and one of the corollaries\nof our work is that the non-signaling model and the SLOCAL model are\nincomparable in the context of LCL problems: By prior work, there exists an LCL\nproblem for which SLOCAL is strictly weaker than the non-signaling model, and\nour work provides a separation in the opposite direction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u5728\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u4e2d\uff0c\u91cf\u5b50\u65b9\u6cd5\u5e76\u4e0d\u6bd4\u7ecf\u5178\u65b9\u6cd5\u66f4\u6709\u4f18\u52bf\uff0c\u5c24\u5176\u5728\u5c40\u90e8\u6a21\u578b\u4e2d\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0\u67d0\u4e9b\u672c\u5730\u53ef\u68c0\u67e5\u6807\u8bb0\u95ee\u9898\uff08LCL\uff09\u4e2d\uff0c\u91cf\u5b50\u5c40\u90e8\u6a21\u578b\u7684\u8868\u73b0\u751a\u81f3\u5f31\u4e8e\u7ecf\u5178\u786e\u5b9a\u6027SLOCAL\u6a21\u578b\u3002", "motivation": "\u63a2\u8ba8\u5728LOCAL\u6a21\u578b\u4e2d\uff0c\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u662f\u5426\u6bd4\u7ecf\u5178\u8ba1\u7b97\u66f4\u5177\u4f18\u52bf\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u6784\u9020\u6027\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u91cf\u5b50LOCAL\u7b97\u6cd5\u5728\u89e3\u51b3\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5bf9\u6bd4\u4e86\u91cf\u5b50LOCAL\u3001SLOCAL\u548c\u975e\u4fe1\u53f7\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u91cf\u5b50LOCAL\u5728\u89e3\u51b3\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u65f6\u6ca1\u6709\u4f18\u52bf\uff0c\u4e14\u5728\u7279\u5b9aLCL\u95ee\u9898\u4e2d\u8868\u73b0\u4e0d\u5982SLOCAL\u6a21\u578b\u3002", "conclusion": "\u91cf\u5b50LOCAL\u6a21\u578b\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u4f18\u52bf\u6709\u9650\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e0d\u5982\u7ecf\u5178\u6a21\u578b\u3002"}}
{"id": "2506.07126", "pdf": "https://arxiv.org/pdf/2506.07126", "abs": "https://arxiv.org/abs/2506.07126", "authors": ["Weihan Lu", "Hong Cai Chen"], "title": "MAGNet: A Multi-Scale Attention-Guided Graph Fusion Network for DRC Violation Detection", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 12 figures, 2 tables", "summary": "Design rule checking (DRC) is of great significance for cost reduction and\ndesign efficiency improvement in integrated circuit (IC) designs.\nMachine-learning-based DRC has become an important approach in computer-aided\ndesign (CAD). In this paper, we propose MAGNet, a hybrid deep learning model\nthat integrates an improved U-Net with a graph neural network for DRC violation\nprediction. The U-Net backbone is enhanced with a Dynamic Attention Module\n(DAM) and a Multi-Scale Convolution Module (MSCM) to strengthen its capability\nin extracting fine-grained and multi-scale spatial features. In parallel, we\nconstruct a pixel-aligned graph structure based on chip layout tiles, and apply\na specialized GNN to model the topological relationships among pins. During\ngraph construction, a graph-to-grid mapping is generated to align GNN features\nwith the layout image. In addition, a label amplification strategy is adopted\nduring training to enhance the model's sensitivity to sparse violation\npatterns. Overall, MAGNet effectively combines spatial, semantic, and\nstructural information, achieving improved prediction accuracy and reduced\nfalse positive rates in DRC hotspot detection. Subsequently, through\nincremental training, we achieve a more sensitive discrimination ability for\nhotspots. The results demonstrate that, in comparison with ibUnet, RouteNet,\nand J-Net, MAGnet significantly outperforms these models, achieving substantial\nimprovements in overall performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86MAGNet\uff0c\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u6539\u8fdb\u7684U-Net\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8eDRC\u8fdd\u89c4\u9884\u6d4b\uff0c\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u76ee\u7684\u662f\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u63d0\u5347\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u8bbe\u8ba1\u89c4\u5219\u68c0\u67e5\uff08DRC\uff09\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u4ece\u800c\u964d\u4f4e\u6210\u672c\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684U-Net\uff08\u52a8\u6001\u6ce8\u610f\u529b\u6a21\u5757\u548c\u591a\u5c3a\u5ea6\u5377\u79ef\u6a21\u5757\uff09\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u62d3\u6251\u5173\u7cfb\uff0c\u5e76\u91c7\u7528\u6807\u7b7e\u653e\u5927\u7b56\u7565\u589e\u5f3a\u7a00\u758f\u8fdd\u89c4\u6a21\u5f0f\u7684\u654f\u611f\u6027\u3002", "result": "MAGNet\u5728DRC\u70ed\u70b9\u68c0\u6d4b\u4e2d\u663e\u8457\u4f18\u4e8e\u5bf9\u6bd4\u6a21\u578b\uff08ibUnet\u3001RouteNet\u548cJ-Net\uff09\uff0c\u51c6\u786e\u7387\u63d0\u5347\u4e14\u8bef\u62a5\u7387\u964d\u4f4e\u3002", "conclusion": "MAGNet\u6210\u529f\u7ed3\u5408\u7a7a\u95f4\u3001\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\uff0c\u4e3aDRC\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.06407", "pdf": "https://arxiv.org/pdf/2506.06407", "abs": "https://arxiv.org/abs/2506.06407", "authors": ["Zhi Wen Soi", "Chaoyi Zhu", "Fouad Abiad", "Aditya Shankar", "Jeroen M. Galjaard", "Huijuan Wang", "Lydia Y. Chen"], "title": "TimeWak: Temporal Chained-Hashing Watermark for Time Series Data", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MM"], "comment": null, "summary": "Synthetic time series generated by diffusion models enable sharing\nprivacy-sensitive datasets, such as patients' functional MRI records. Key\ncriteria for synthetic data include high data utility and traceability to\nverify the data source. Recent watermarking methods embed in homogeneous latent\nspaces, but state-of-the-art time series generators operate in real space,\nmaking latent-based watermarking incompatible. This creates the challenge of\nwatermarking directly in real space while handling feature heterogeneity and\ntemporal dependencies. We propose TimeWak, the first watermarking algorithm for\nmultivariate time series diffusion models. To handle temporal dependence and\nspatial heterogeneity, TimeWak embeds a temporal chained-hashing watermark\ndirectly within the real temporal-feature space. The other unique feature is\nthe $\\epsilon$-exact inversion, which addresses the non-uniform reconstruction\nerror distribution across features from inverting the diffusion process to\ndetect watermarks. We derive the error bound of inverting multivariate time\nseries and further maintain high watermark detectability. We extensively\nevaluate TimeWak on its impact on synthetic data quality, watermark\ndetectability, and robustness under various post-editing attacks, against 5\ndatasets and baselines of different temporal lengths. Our results show that\nTimeWak achieves improvements of 61.96% in context-FID score, and 8.44% in\ncorrelational scores against the state-of-the-art baseline, while remaining\nconsistently detectable.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6269\u6563\u6a21\u578b\u7684\u6c34\u5370\u7b97\u6cd5TimeWak\uff0c\u901a\u8fc7\u5728\u771f\u5b9e\u65f6\u7a7a\u5d4c\u5165\u65f6\u5e8f\u94fe\u5f0f\u54c8\u5e0c\u6c34\u5370\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e0e\u6c34\u5370\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u5e76\u5728\u6570\u636e\u8d28\u91cf\u548c\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u4f9d\u8d56\u540c\u8d28\u6f5c\u5728\u7a7a\u95f4\u5d4c\u5165\uff0c\u4f46\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u5668\u5728\u771f\u5b9e\u7a7a\u95f4\u64cd\u4f5c\uff0c\u5bfc\u81f4\u6f5c\u5728\u6c34\u5370\u65b9\u6cd5\u4e0d\u517c\u5bb9\u3002\u9700\u8981\u76f4\u63a5\u5728\u771f\u5b9e\u65f6\u7a7a\u89e3\u51b3\u7279\u5f81\u5f02\u8d28\u6027\u548c\u65f6\u5e8f\u4f9d\u8d56\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faTimeWak\u7b97\u6cd5\uff0c\u76f4\u63a5\u5728\u771f\u5b9e\u65f6\u7a7a\u5d4c\u5165\u65f6\u5e8f\u94fe\u5f0f\u54c8\u5e0c\u6c34\u5370\uff0c\u5e76\u5f15\u5165\u03b5-\u7cbe\u786e\u53cd\u8f6c\u6280\u672f\u5904\u7406\u6269\u6563\u8fc7\u7a0b\u9006\u53d8\u7684\u975e\u5747\u5300\u91cd\u6784\u8bef\u5dee\u3002", "result": "\u57285\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cTimeWak\u5728context-FID\u8bc4\u5206\u4e0a\u63d0\u534761.96%\uff0c\u76f8\u5173\u6027\u8bc4\u5206\u63d0\u53478.44%\uff0c\u4e14\u6c34\u5370\u59cb\u7ec8\u4fdd\u6301\u9ad8\u53ef\u68c0\u6d4b\u6027\u3002", "conclusion": "TimeWak\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u6269\u6563\u6a21\u578b\u7684\u6c34\u5370\u5d4c\u5165\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5408\u6210\u6570\u636e\u8d28\u91cf\u548c\u6297\u653b\u51fb\u80fd\u529b\u3002"}}
{"id": "2506.06494", "pdf": "https://arxiv.org/pdf/2506.06494", "abs": "https://arxiv.org/abs/2506.06494", "authors": ["Lei Lan", "Zixuan Lu", "Chun Yuan", "Weiwei Xu", "Hao Su", "Huamin Wang", "Chenfanfu Jiang", "Yin Yang"], "title": "JGS2: Near Second-order Converging Jacobi/Gauss-Seidel for GPU Elastodynamics", "categories": ["cs.GR"], "comment": null, "summary": "In parallel simulation, convergence and parallelism are often seen as\ninherently conflicting objectives. Improved parallelism typically entails\nlighter local computation and weaker coupling, which unavoidably slow the\nglobal convergence. This paper presents a novel GPU algorithm that achieves\nconvergence rates comparable to fullspace Newton's method while maintaining\ngood parallelizability just like the Jacobi method. Our approach is built on a\nkey insight into the phenomenon of overshoot. Overshoot occurs when a local\nsolver aggressively minimizes its local energy without accounting for the\nglobal context, resulting in a local update that undermines global convergence.\nTo address this, we derive a theoretically second-order optimal solution to\nmitigate overshoot. Furthermore, we adapt this solution into a pre-computable\nform. Leveraging Cubature sampling, our runtime cost is only marginally higher\nthan the Jacobi method, yet our algorithm converges nearly quadratically as\nNewton's method. We also introduce a novel full-coordinate formulation for more\nefficient pre-computation. Our method integrates seamlessly with the\nincremental potential contact method and achieves second-order convergence for\nboth stiff and soft materials. Experimental results demonstrate that our\napproach delivers high-quality simulations and outperforms state-of-the-art GPU\nmethods with 50 to 100 times better convergence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bGPU\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u4e0e\u96c5\u53ef\u6bd4\u65b9\u6cd5\u7c7b\u4f3c\u7684\u5e76\u884c\u6027\u7684\u540c\u65f6\uff0c\u6536\u655b\u901f\u5ea6\u63a5\u8fd1\u725b\u987f\u6cd5\u3002\u65b9\u6cd5\u901a\u8fc7\u89e3\u51b3\u201c\u8fc7\u51b2\u201d\u73b0\u8c61\u5b9e\u73b0\uff0c\u7ed3\u5408Cubature\u91c7\u6837\u548c\u5168\u5750\u6807\u516c\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6536\u655b\u6027\u80fd\u3002", "motivation": "\u5e76\u884c\u6a21\u62df\u4e2d\uff0c\u6536\u655b\u6027\u548c\u5e76\u884c\u6027\u5e38\u88ab\u89c6\u4e3a\u51b2\u7a81\u76ee\u6807\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u7b97\u6cd5\uff0c\u5b9e\u73b0\u9ad8\u5e76\u884c\u6027\u548c\u5feb\u901f\u6536\u655b\u7684\u53cc\u8d62\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u4e8c\u9636\u6700\u4f18\u89e3\u6291\u5236\u8fc7\u51b2\u73b0\u8c61\uff0c\u7ed3\u5408Cubature\u91c7\u6837\u548c\u5168\u5750\u6807\u516c\u5f0f\u9884\u8ba1\u7b97\uff0c\u63d0\u5347\u7b97\u6cd5\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7b97\u6cd5\u6536\u655b\u901f\u5ea6\u6bd4\u5f53\u524d\u6700\u4f18GPU\u65b9\u6cd5\u5feb50\u5230100\u500d\uff0c\u9002\u7528\u4e8e\u521a\u6027\u548c\u67d4\u6027\u6750\u6599\u7684\u9ad8\u8d28\u91cf\u6a21\u62df\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u6536\u655b\u4e0e\u5e76\u884c\u6027\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u5e76\u884c\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07268", "pdf": "https://arxiv.org/pdf/2506.07268", "abs": "https://arxiv.org/abs/2506.07268", "authors": ["L. Sunil Chandran", "Rishikesh Gajjala", "Kuldeep S. Meel"], "title": "CNFs and DNFs with Exactly $k$ Solutions", "categories": ["cs.DM", "cs.DS", "cs.LO", "math.CO", "math.LO"], "comment": "To appear in SAT 2025", "summary": "Model counting is a fundamental problem that consists of determining the\nnumber of satisfying assignments for a given Boolean formula. The weighted\nvariant, which computes the weighted sum of satisfying assignments, has\nextensive applications in probabilistic reasoning, network reliability,\nstatistical physics, and formal verification. A common approach for solving\nweighted model counting is to reduce it to unweighted model counting, which\nraises an important question: {\\em What is the minimum number of terms (or\nclauses) required to construct a DNF (or CNF) formula with exactly $k$\nsatisfying assignments?}\n  In this paper, we establish both upper and lower bounds on this question. We\nprove that for any natural number $k$, one can construct a monotone DNF formula\nwith exactly $k$ satisfying assignments using at most $O(\\sqrt{\\log k}\\log\\log\nk)$ terms. This construction represents the first $o(\\log k)$ upper bound for\nthis problem. We complement this result by showing that there exist infinitely\nmany values of $k$ for which any DNF or CNF representation requires at least\n$\\Omega(\\log\\log k)$ terms or clauses. These results have significant\nimplications for the efficiency of model counting algorithms based on formula\ntransformations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u95ee\u9898\uff0c\u63a2\u8ba8\u4e86\u6784\u5efa\u5177\u6709\u6070\u597dk\u4e2a\u6ee1\u8db3\u8d4b\u503c\u7684DNF\u6216CNF\u516c\u5f0f\u6240\u9700\u7684\u6700\u5c0f\u9879\u6570\u6216\u5b50\u53e5\u6570\u3002\u63d0\u51fa\u4e86\u9996\u4e2ao(log k)\u4e0a\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u67d0\u4e9bk\u503c\u9700\u8981\u03a9(log log k)\u9879\u6216\u5b50\u53e5\u7684\u4e0b\u754c\u3002", "motivation": "\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u5728\u6982\u7387\u63a8\u7406\u3001\u7f51\u7edc\u53ef\u9760\u6027\u7b49\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u7814\u7a76\u6700\u5c0f\u9879\u6570\u95ee\u9898\u6709\u52a9\u4e8e\u63d0\u9ad8\u57fa\u4e8e\u516c\u5f0f\u8f6c\u6362\u7684\u6a21\u578b\u8ba1\u6570\u7b97\u6cd5\u7684\u6548\u7387\u3002", "method": "\u901a\u8fc7\u6784\u9020\u5355\u8c03DNF\u516c\u5f0f\uff0c\u8bc1\u660e\u4e86\u4e0a\u754cO(\u221a(log k) log log k)\uff1b\u540c\u65f6\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u786e\u5b9a\u4e86\u67d0\u4e9bk\u503c\u7684\u4e0b\u754c\u03a9(log log k)\u3002", "result": "\u9996\u6b21\u63d0\u51fao(log k)\u7684\u4e0a\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u4e0b\u754c\u7684\u5b58\u5728\uff0c\u8868\u660e\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u9700\u8981\u81f3\u5c11\u03a9(log log k)\u9879\u6216\u5b50\u53e5\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5bf9\u6a21\u578b\u8ba1\u6570\u7b97\u6cd5\u7684\u6548\u7387\u6539\u8fdb\u6709\u91cd\u8981\u610f\u4e49\uff0c\u63ed\u793a\u4e86\u516c\u5f0f\u8f6c\u6362\u4e2d\u7684\u590d\u6742\u5ea6\u9650\u5236\u3002"}}
{"id": "2506.07041", "pdf": "https://arxiv.org/pdf/2506.07041", "abs": "https://arxiv.org/abs/2506.07041", "authors": ["Leijie Wang", "Weizi Wu", "Lirong Que", "Nirvan Tyagi", "Amy X. Zhang"], "title": "From Inquisitorial to Adversarial: Using Legal Theory to Redesign Online Reporting Systems", "categories": ["cs.HC"], "comment": "Under review", "summary": "User reporting systems are central to addressing interpersonal conflicts and\nprotecting users from harm in online spaces, particularly those with heightened\nprivacy expectations. However, users often express frustration at their lack of\ninsight and input into the reporting process. Drawing on offline legal\nliterature, we trace these frustrations to the inquisitorial nature of today's\nonline reporting systems, where moderators lead evidence gathering and case\ndevelopment. In contrast, adversarial models can grant users greater control\nand thus are better for procedural justice and privacy protection, despite\ntheir increased risks of system abuse. This motivates us to explore the\npotential of incorporating adversarial practices into online reporting systems.\nThrough literature review, formative interviews, and threat modeling, we find a\nrich design space for empowering users to collect and present their evidence\nwhile mitigating potential abuse in the reporting process. In particular, we\npropose designs that minimize the amount of information shared for reporting\npurposes, as well as supporting evidence authentication. Finally, we discuss\nhow our findings can inform new cryptographic tools and new efforts to apply\ncomparative legal frameworks to online moderation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u7ebf\u7528\u6237\u4e3e\u62a5\u7cfb\u7edf\u7684\u6539\u8fdb\uff0c\u63d0\u51fa\u4e86\u5bf9\u6297\u6027\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u4ee5\u63d0\u5347\u7528\u6237\u63a7\u5236\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u5f53\u524d\u5728\u7ebf\u4e3e\u62a5\u7cfb\u7edf\u91c7\u7528\u8baf\u95ee\u5236\uff0c\u7528\u6237\u7f3a\u4e4f\u53c2\u4e0e\u611f\u3002\u5bf9\u6297\u6027\u6a21\u578b\u53ef\u80fd\u66f4\u597d\u5730\u5b9e\u73b0\u7a0b\u5e8f\u6b63\u4e49\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u3001\u8bbf\u8c08\u548c\u5a01\u80c1\u5efa\u6a21\uff0c\u63a2\u7d22\u5bf9\u6297\u6027\u5b9e\u8df5\u5728\u4e3e\u62a5\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8bbe\u8ba1\u51cf\u5c11\u4fe1\u606f\u5171\u4eab\u7684\u65b9\u6848\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5bf9\u6297\u6027\u6a21\u578b\u53ef\u8d4b\u4e88\u7528\u6237\u66f4\u591a\u63a7\u5236\u6743\uff0c\u4f46\u9700\u5e73\u8861\u6ee5\u7528\u98ce\u9669\u3002\u8bbe\u8ba1\u4e86\u652f\u6301\u8bc1\u636e\u8ba4\u8bc1\u7684\u6700\u5c0f\u5316\u4fe1\u606f\u5171\u4eab\u65b9\u6848\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u7ebf\u4e3e\u62a5\u7cfb\u7edf\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c24\u5176\u662f\u7ed3\u5408\u6cd5\u5f8b\u6846\u67b6\u548c\u5bc6\u7801\u5b66\u5de5\u5177\u7684\u5e94\u7528\u3002"}}
{"id": "2506.06532", "pdf": "https://arxiv.org/pdf/2506.06532", "abs": "https://arxiv.org/abs/2506.06532", "authors": ["Zijiang Yan", "Hao Zhou", "Jianhua Pei", "Hina Tabassum"], "title": "Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks", "categories": ["cs.LG", "cs.AI", "cs.NI", "cs.RO", "cs.SY", "eess.SY"], "comment": "Accepted in ICML 2025 Workshop on Machine Learning for Wireless\n  Communication and Networks (ML4Wireless)", "summary": "Unmanned aerial vehicles (UAVs) have been widely adopted in various\nreal-world applications. However, the control and optimization of multi-UAV\nsystems remain a significant challenge, particularly in dynamic and constrained\nenvironments. This work explores the joint motion and communication control of\nmultiple UAVs operating within integrated terrestrial and non-terrestrial\nnetworks that include high-altitude platform stations (HAPS). Specifically, we\nconsider an aerial highway scenario in which UAVs must accelerate, decelerate,\nand change lanes to avoid collisions and maintain overall traffic flow.\nDifferent from existing studies, we propose a novel hierarchical and\ncollaborative method based on large language models (LLMs). In our approach, an\nLLM deployed on the HAPS performs UAV access control, while another LLM onboard\neach UAV handles motion planning and control. This LLM-based framework\nleverages the rich knowledge embedded in pre-trained models to enable both\nhigh-level strategic planning and low-level tactical decisions. This\nknowledge-driven paradigm holds great potential for the development of\nnext-generation 3D aerial highway systems. Experimental results demonstrate\nthat our proposed collaborative LLM-based method achieves higher system\nrewards, lower operational costs, and significantly reduced UAV collision rates\ncompared to baseline approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5206\u5c42\u534f\u4f5c\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u65e0\u4eba\u673a\u5728\u52a8\u6001\u7ea6\u675f\u73af\u5883\u4e2d\u7684\u8fd0\u52a8\u548c\u901a\u4fe1\u63a7\u5236\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u5728\u52a8\u6001\u548c\u53d7\u9650\u73af\u5883\u4e2d\u7684\u63a7\u5236\u4e0e\u4f18\u5316\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u96c6\u6210\u5730\u9762\u548c\u975e\u5730\u9762\u7f51\u7edc\uff08\u5982\u9ad8\u7a7a\u5e73\u53f0\u7ad9\uff09\u7684\u573a\u666f\u4e2d\u3002", "method": "\u91c7\u7528\u5206\u5c42\u534f\u4f5c\u7684LLM\u6846\u67b6\uff0cHAPS\u4e0a\u7684LLM\u8d1f\u8d23\u65e0\u4eba\u673a\u63a5\u5165\u63a7\u5236\uff0c\u6bcf\u67b6\u65e0\u4eba\u673a\u4e0a\u7684LLM\u5904\u7406\u8fd0\u52a8\u89c4\u5212\u4e0e\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cfb\u7edf\u5956\u52b1\u3001\u66f4\u4f4e\u7684\u8fd0\u8425\u6210\u672c\u548c\u663e\u8457\u51cf\u5c11\u7684\u65e0\u4eba\u673a\u78b0\u649e\u7387\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u77e5\u8bc6\u7684\u8303\u5f0f\u4e3a\u4e0b\u4e00\u4ee3\u4e09\u7ef4\u7a7a\u4e2d\u9ad8\u901f\u516c\u8def\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2506.07436", "pdf": "https://arxiv.org/pdf/2506.07436", "abs": "https://arxiv.org/abs/2506.07436", "authors": ["Nishi Chaudhary", "S M Jamil Uddin", "Sathvik Sharath Chandra", "Anto Ovid", "Alex Albert"], "title": "Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition", "categories": ["cs.CV", "cs.AI", "cs.ET"], "comment": null, "summary": "The recent emergence of multimodal large language models (LLMs) has\nintroduced new opportunities for improving visual hazard recognition on\nconstruction sites. Unlike traditional computer vision models that rely on\ndomain-specific training and extensive datasets, modern LLMs can interpret and\ndescribe complex visual scenes using simple natural language prompts. However,\ndespite growing interest in their applications, there has been limited\ninvestigation into how different LLMs perform in safety-critical visual tasks\nwithin the construction domain. To address this gap, this study conducts a\ncomparative evaluation of five state-of-the-art LLMs: Claude-3 Opus, GPT-4.5,\nGPT-4o, GPT-o3, and Gemini 2.0 Pro, to assess their ability to identify\npotential hazards from real-world construction images. Each model was tested\nunder three prompting strategies: zero-shot, few-shot, and chain-of-thought\n(CoT). Zero-shot prompting involved minimal instruction, few-shot incorporated\nbasic safety context and a hazard source mnemonic, and CoT provided\nstep-by-step reasoning examples to scaffold model thinking. Quantitative\nanalysis was performed using precision, recall, and F1-score metrics across all\nconditions. Results reveal that prompting strategy significantly influenced\nperformance, with CoT prompting consistently producing higher accuracy across\nmodels. Additionally, LLM performance varied under different conditions, with\nGPT-4.5 and GPT-o3 outperforming others in most settings. The findings also\ndemonstrate the critical role of prompt design in enhancing the accuracy and\nconsistency of multimodal LLMs for construction safety applications. This study\noffers actionable insights into the integration of prompt engineering and LLMs\nfor practical hazard recognition, contributing to the development of more\nreliable AI-assisted safety systems.", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5efa\u7b51\u5de5\u5730\u89c6\u89c9\u5371\u9669\u8bc6\u522b\u4e2d\u7684\u5e94\u7528\u7814\u7a76\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e94\u79cd\u5148\u8fdb\u6a21\u578b\u5728\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63d0\u793a\u80fd\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u5f3a\u8c03\u63d0\u793a\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u586b\u8865\u591a\u6a21\u6001LLM\u5728\u5efa\u7b51\u5b89\u5168\u9886\u57df\u5e94\u7528\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63a2\u8ba8\u4e0d\u540c\u6a21\u578b\u5728\u89c6\u89c9\u5371\u9669\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\u53ca\u5176\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5bf9\u4e94\u79cd\u6a21\u578b\uff08Claude-3 Opus\u3001GPT-4.5\u3001GPT-4o\u3001GPT-o3\u3001Gemini 2.0 Pro\uff09\u8fdb\u884c\u4e86\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff08\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u94fe\u5f0f\u601d\u7ef4\uff09\u7684\u6bd4\u8f83\u8bc4\u4f30\uff0c\u4f7f\u7528\u7cbe\u51c6\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u8fdb\u884c\u91cf\u5316\u5206\u6790\u3002", "result": "CoT\u63d0\u793a\u7b56\u7565\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u662fGPT-4.5\u548cGPT-o3\u8868\u73b0\u6700\u4f18\uff1b\u63d0\u793a\u8bbe\u8ba1\u5bf9\u591a\u6a21\u6001LLM\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5efa\u7b51\u5b89\u5168\u9886\u57df\u7684AI\u8f85\u52a9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u63d0\u793a\u5de5\u7a0b\u5efa\u8bae\uff0c\u4fc3\u8fdb\u4e86\u66f4\u53ef\u9760\u7684\u6a21\u578b\u5e94\u7528\u3002"}}
{"id": "2506.07838", "pdf": "https://arxiv.org/pdf/2506.07838", "abs": "https://arxiv.org/abs/2506.07838", "authors": ["Fr\u00e9d\u00e9ric Sutera", "Tain\u00e3 Coleman", "\u0130lkay Altinta\u015f", "Rosa M. Badia", "Bartosz Balis", "Kyle Chard", "Iacopo Colonnelli", "Ewa Deelman", "Paolo Di Tommaso", "Thomas Fahringer", "Carole Goble", "Shantenu Jha", "Daniel S. Katz", "Johannes K\u00f6ster", "Ulf Leser", "Kshitij Mehta", "Hilary Oliver", "J. -Luc Peterson", "Giovanni Pizzi", "Lo\u00efc Pottier", "Ra\u00fcl Sirvent", "Eric Suchyta", "Douglas Thain", "Sean R. Wilkinson", "Justin M. Wozniak", "Rafael Ferreira da Silva"], "title": "A Terminology for Scientific Workflow Systems", "categories": ["cs.DC"], "comment": null, "summary": "The term scientific workflow has evolved over the last two decades to\nencompass a broad range of compositions of interdependent compute tasks and\ndata movements. It has also become an umbrella term for processing in modern\nscientific applications. Today, many scientific applications can be considered\nas workflows made of multiple dependent steps, and hundreds of workflow\nmanagement systems (WMSs) have been developed to manage and run these\nworkflows. However, no turnkey solution has emerged to address the diversity of\nscientific processes and the infrastructure on which they are implemented.\nInstead, new research problems requiring the execution of scientific workflows\nwith some novel feature often lead to the development of an entirely new WMS. A\ndirect consequence is that many existing WMSs share some salient features,\noffer similar functionalities, and can manage the same categories of workflows\nbut also have some distinct capabilities. This situation makes researchers who\ndevelop workflows face the complex question of selecting a WMS. This selection\ncan be driven by technical considerations, to find the system that is the most\nappropriate for their application and for the resources available to them, or\nother factors such as reputation, adoption, strong community support, or\nlong-term sustainability. To address this problem, a group of WMS developers\nand practitioners joined their efforts to produce a community-based terminology\nof WMSs. This paper summarizes their findings and introduces this new\nterminology to characterize WMSs. This terminology is composed of fives axes:\nworkflow characteristics, composition, orchestration, data management, and\nmetadata capture. Each axis comprises several concepts that capture the\nprominent features of WMSs. Based on this terminology, this paper also presents\na classification of 23 existing WMSs according to the proposed axes and terms.", "AI": {"tldr": "\u8bba\u6587\u603b\u7ed3\u4e86\u79d1\u5b66\u5de5\u4f5c\u6d41\u7ba1\u7406\u7cfb\u7edf\uff08WMSs\uff09\u7684\u5206\u7c7b\u548c\u672f\u8bed\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e94\u4e2a\u8f74\u7684\u65b0\u672f\u8bed\u6765\u63cf\u8ff0WMS\u7684\u7279\u5f81\u3002", "motivation": "\u7531\u4e8e\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u591a\u6837\u6027\u548c\u590d\u6742\u6027\uff0c\u73b0\u6709WMSs\u529f\u80fd\u91cd\u53e0\u4f46\u53c8\u5404\u5177\u7279\u8272\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u9009\u62e9\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u7684\u672f\u8bed\u548c\u5206\u7c7b\u65b9\u6cd5\u6765\u5e2e\u52a9\u9009\u62e9\u3002", "method": "\u4f5c\u8005\u4e0eWMS\u5f00\u53d1\u8005\u53ca\u5b9e\u8df5\u8005\u5408\u4f5c\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u4e94\u4e2a\u8f74\uff08\u5de5\u4f5c\u6d41\u7279\u5f81\u3001\u7ec4\u6210\u3001\u7f16\u6392\u3001\u6570\u636e\u7ba1\u7406\u548c\u5143\u6570\u636e\u6355\u83b7\uff09\u7684\u793e\u533a\u672f\u8bed\u3002", "result": "\u57fa\u4e8e\u65b0\u672f\u8bed\uff0c\u5bf923\u4e2a\u73b0\u6709WMSs\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5c55\u793a\u4e86\u5b83\u4eec\u7684\u5171\u6027\u548c\u7279\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u6807\u51c6\u5316\u7684\u672f\u8bed\u548c\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u66f4\u6709\u6548\u5730\u9009\u62e9\u548c\u8bc4\u4f30WMSs\u3002"}}
{"id": "2506.07239", "pdf": "https://arxiv.org/pdf/2506.07239", "abs": "https://arxiv.org/abs/2506.07239", "authors": ["Raghu Vamshi Hemadri", "Jitendra Bhandari", "Johann Knechtel", "Badri P Gopalan", "Ramesh Narayanaswamy", "Ramesh Karri", "Siddharth Garg"], "title": "VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Modern chip design is complex, and there is a crucial need for early-stage\nprediction of key design-quality metrics like timing and routing congestion\ndirectly from Verilog code (a commonly used programming language for hardware\ndesign). It is especially important yet complex to predict individual lines of\ncode that cause timing violations or downstream routing congestion. Prior works\nhave tried approaches like converting Verilog into an intermediate graph\nrepresentation and using LLM embeddings alongside other features to predict\nmodule-level quality, but did not consider line-level quality prediction. We\npropose VeriLoC, the first method that predicts design quality directly from\nVerilog at both the line- and module-level. To this end, VeriLoC leverages\nrecent Verilog code-generation LLMs to extract local line-level and\nmodule-level embeddings, and train downstream classifiers/regressors on\nconcatenations of these embeddings. VeriLoC achieves high F1-scores of\n0.86-0.95 for line-level congestion and timing prediction, and reduces the mean\naverage percentage error from 14% - 18% for SOTA methods down to only 4%. We\nbelieve that VeriLoC embeddings and insights from our work will also be of\nvalue for other predictive and optimization tasks for complex hardware design.", "AI": {"tldr": "VeriLoC\u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u9996\u6b21\u76f4\u63a5\u4eceVerilog\u4ee3\u7801\u9884\u6d4b\u7ebf\u8def\u7ea7\u548c\u6a21\u5757\u7ea7\u7684\u8bbe\u8ba1\u8d28\u91cf\uff0c\u5229\u7528LLM\u5d4c\u5165\u63d0\u53d6\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u4ee3\u82af\u7247\u8bbe\u8ba1\u590d\u6742\uff0c\u9700\u8981\u65e9\u671f\u9884\u6d4b\u5173\u952e\u8bbe\u8ba1\u8d28\u91cf\u6307\u6807\uff08\u5982\u65f6\u5e8f\u548c\u5e03\u7ebf\u62e5\u585e\uff09\uff0c\u5c24\u5176\u662f\u4eceVerilog\u4ee3\u7801\u4e2d\u76f4\u63a5\u9884\u6d4b\u5bfc\u81f4\u95ee\u9898\u7684\u5177\u4f53\u4ee3\u7801\u884c\u3002", "method": "VeriLoC\u5229\u7528Verilog\u4ee3\u7801\u751f\u6210LLM\u63d0\u53d6\u7ebf\u8def\u7ea7\u548c\u6a21\u5757\u7ea7\u5d4c\u5165\uff0c\u5e76\u8bad\u7ec3\u4e0b\u6e38\u5206\u7c7b\u5668/\u56de\u5f52\u5668\u3002", "result": "VeriLoC\u5728\u7ebf\u8def\u7ea7\u62e5\u585e\u548c\u65f6\u5e8f\u9884\u6d4b\u4e2dF1\u5206\u6570\u8fbe0.86-0.95\uff0c\u5c06\u5e73\u5747\u767e\u5206\u6bd4\u8bef\u5dee\u4ece14%-18%\u964d\u81f34%\u3002", "conclusion": "VeriLoC\u4e3a\u590d\u6742\u786c\u4ef6\u8bbe\u8ba1\u7684\u9884\u6d4b\u548c\u4f18\u5316\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5d4c\u5165\u548c\u89c1\u89e3\u3002"}}
{"id": "2506.07050", "pdf": "https://arxiv.org/pdf/2506.07050", "abs": "https://arxiv.org/abs/2506.07050", "authors": ["Zheng Wang", "Kai Ying", "Bin Xu", "Chunjiao Wang", "Cong Bai"], "title": "From Swath to Full-Disc: Advancing Precipitation Retrieval with Multimodal Knowledge Expansion", "categories": ["cs.CV", "cs.IR", "cs.MM"], "comment": null, "summary": "Accurate near-real-time precipitation retrieval has been enhanced by\nsatellite-based technologies. However, infrared-based algorithms have low\naccuracy due to weak relations with surface precipitation, whereas passive\nmicrowave and radar-based methods are more accurate but limited in range. This\nchallenge motivates the Precipitation Retrieval Expansion (PRE) task, which\naims to enable accurate, infrared-based full-disc precipitation retrievals\nbeyond the scanning swath. We introduce Multimodal Knowledge Expansion, a\ntwo-stage pipeline with the proposed PRE-Net model. In the Swath-Distilling\nstage, PRE-Net transfers knowledge from a multimodal data integration model to\nan infrared-based model within the scanning swath via Coordinated Masking and\nWavelet Enhancement (CoMWE). In the Full-Disc Adaptation stage, Self-MaskTune\nrefines predictions across the full disc by balancing multimodal and full-disc\ninfrared knowledge. Experiments on the introduced PRE benchmark demonstrate\nthat PRE-Net significantly advanced precipitation retrieval performance,\noutperforming leading products like PERSIANN-CCS, PDIR, and IMERG. The code\nwill be available at https://github.com/Zjut-MultimediaPlus/PRE-Net.", "AI": {"tldr": "PRE-Net\u901a\u8fc7\u591a\u6a21\u6001\u77e5\u8bc6\u6269\u5c55\u63d0\u5347\u4e86\u7ea2\u5916\u964d\u6c34\u53cd\u6f14\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u7ea2\u5916\u964d\u6c34\u53cd\u6f14\u6280\u672f\u7cbe\u5ea6\u4f4e\uff0c\u800c\u5fae\u6ce2\u548c\u96f7\u8fbe\u6280\u672f\u8303\u56f4\u6709\u9650\uff0c\u56e0\u6b64\u63d0\u51faPRE\u4efb\u52a1\u4ee5\u6269\u5c55\u7ea2\u5916\u6280\u672f\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u7a0b\uff08Swath-Distilling\u548cFull-Disc Adaptation\uff09\uff0c\u7ed3\u5408CoMWE\u548cSelf-MaskTune\u6280\u672f\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "PRE-Net\u5728PRE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8aPERSIANN-CCS\u7b49\u4e3b\u6d41\u4ea7\u54c1\u3002", "conclusion": "PRE-Net\u4e3a\u5168\u76d8\u964d\u6c34\u53cd\u6f14\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5f00\u6e90\u4ee3\u7801\u4ee5\u63a8\u52a8\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2506.07020", "pdf": "https://arxiv.org/pdf/2506.07020", "abs": "https://arxiv.org/abs/2506.07020", "authors": ["Qiujie Dong", "Jiepeng Wang", "Rui Xu", "Cheng Lin", "Yuan Liu", "Shiqing Xin", "Zichun Zhong", "Xin Li", "Changhe Tu", "Taku Komura", "Leif Kobbelt", "Scott Schaefer", "Wenping Wang"], "title": "CrossGen: Learning and Generating Cross Fields for Quad Meshing", "categories": ["cs.GR"], "comment": "Project page: https://anonymousproject-homepage.github.io/", "summary": "Cross fields play a critical role in various geometry processing tasks,\nespecially for quad mesh generation. Existing methods for cross field\ngeneration often struggle to balance computational efficiency with generation\nquality, using slow per-shape optimization. We introduce CrossGen, a novel\nframework that supports both feed-forward prediction and latent generative\nmodeling of cross fields for quad meshing by unifying geometry and cross field\nrepresentations within a joint latent space. Our method enables extremely fast\ncomputation of high-quality cross fields of general input shapes, typically\nwithin one second without per-shape optimization. Our method assumes a\npoint-sampled surface, or called a point-cloud surface, as input, so we can\naccommodate various different surface representations by a straightforward\npoint sampling process. Using an auto-encoder network architecture, we encode\ninput point-cloud surfaces into a sparse voxel grid with fine-grained latent\nspaces, which are decoded into both SDF-based surface geometry and cross\nfields. We also contribute a dataset of models with both high-quality signed\ndistance fields (SDFs) representations and their corresponding cross fields,\nand use it to train our network. Once trained, the network is capable of\ncomputing a cross field of an input surface in a feed-forward manner, ensuring\nhigh geometric fidelity, noise resilience, and rapid inference. Furthermore,\nleveraging the same unified latent representation, we incorporate a diffusion\nmodel for computing cross fields of new shapes generated from partial input,\nsuch as sketches. To demonstrate its practical applications, we validate\nCrossGen on the quad mesh generation task for a large variety of surface\nshapes. Experimental results...", "AI": {"tldr": "CrossGen\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u6f5c\u5728\u7a7a\u95f4\u7edf\u4e00\u51e0\u4f55\u548c\u4ea4\u53c9\u573a\u8868\u793a\uff0c\u5b9e\u73b0\u4e86\u56db\u8fb9\u7f51\u683c\u751f\u6210\u4e2d\u4ea4\u53c9\u573a\u7684\u5feb\u901f\u9884\u6d4b\u548c\u6f5c\u5728\u751f\u6210\u5efa\u6a21\u3002", "motivation": "\u73b0\u6709\u7684\u4ea4\u53c9\u573a\u751f\u6210\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u4e0a\u96be\u4ee5\u5e73\u8861\uff0c\u901a\u5e38\u9700\u8981\u7f13\u6162\u7684\u9010\u5f62\u72b6\u4f18\u5316\u3002", "method": "\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u7f51\u7edc\u67b6\u6784\uff0c\u5c06\u8f93\u5165\u70b9\u4e91\u8868\u9762\u7f16\u7801\u4e3a\u7a00\u758f\u4f53\u7d20\u7f51\u683c\uff0c\u89e3\u7801\u4e3a\u57fa\u4e8eSDF\u7684\u51e0\u4f55\u548c\u4ea4\u53c9\u573a\uff0c\u5e76\u7ed3\u5408\u6269\u6563\u6a21\u578b\u5904\u7406\u90e8\u5206\u8f93\u5165\u751f\u6210\u65b0\u5f62\u72b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCrossGen\u80fd\u5728\u4e0d\u5230\u4e00\u79d2\u7684\u65f6\u95f4\u5185\u5feb\u901f\u8ba1\u7b97\u9ad8\u8d28\u91cf\u4ea4\u53c9\u573a\uff0c\u5177\u6709\u9ad8\u51e0\u4f55\u4fdd\u771f\u5ea6\u3001\u566a\u58f0\u9c81\u68d2\u6027\u548c\u5feb\u901f\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "CrossGen\u4e3a\u56db\u8fb9\u7f51\u683c\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u4ea4\u53c9\u573a\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u8868\u9762\u5f62\u72b6\u3002"}}
{"id": "2506.07477", "pdf": "https://arxiv.org/pdf/2506.07477", "abs": "https://arxiv.org/abs/2506.07477", "authors": ["Thomas Zhu", "Joshua Clune", "Jeremy Avigad", "Albert Qiaochu Jiang", "Sean Welleck"], "title": "Premise Selection for a Lean Hammer", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "LeanHammer is available at https://github.com/JOSHCLUNE/LeanHammer", "summary": "Neural methods are transforming automated reasoning for proof assistants, yet\nintegrating these advances into practical verification workflows remains\nchallenging. Hammers are tools that interface with external automatic theorem\nprovers to automate tedious reasoning steps. They have dramatically improved\nproductivity in proof assistants, but the Lean proof assistant still does not\nhave a hammer despite its growing popularity. We present LeanHammer, the first\nend-to-end domain-general hammer for Lean, built on a novel neural premise\nselection system for a hammer in dependent type theory. Unlike existing Lean\npremise selectors, our approach dynamically adapts to user-specific contexts\nand combines with symbolic proof search and reconstruction to create a\npractical hammer. With comprehensive evaluations, we show that our premise\nselector enables LeanHammer to solve 21\\% more goals relative to existing\npremise selectors, and generalize well to diverse domains. Our work bridges the\ngap between neural retrieval and symbolic reasoning, making formal verification\nmore accessible to researchers and practitioners.", "AI": {"tldr": "LeanHammer\u662f\u4e00\u4e2a\u57fa\u4e8e\u795e\u7ecf\u524d\u63d0\u9009\u62e9\u7cfb\u7edf\u7684\u9886\u57df\u901a\u7528\u5de5\u5177\uff0c\u9996\u6b21\u4e3aLean\u8bc1\u660e\u52a9\u624b\u63d0\u4f9b\u4e86\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u63a8\u7406\u652f\u6301\u3002\u5b83\u901a\u8fc7\u52a8\u6001\u9002\u5e94\u7528\u6237\u4e0a\u4e0b\u6587\u5e76\u7ed3\u5408\u7b26\u53f7Proof\u641c\u7d22\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u76ee\u6807\u89e3\u51b3\u7387\u3002", "motivation": "\u5c3d\u7ba1\u795e\u7ecf\u65b9\u6cd5\u5728\u81ea\u52a8\u63a8\u7406\u4e2d\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5c06\u5176\u5e94\u7528\u5230\u5b9e\u9645\u8bc1\u660e\u52a9\u624b\u4e2d\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002Lean\u662f\u53d7\u6b22\u8fce\u7684\u8bc1\u660e\u52a9\u624b\uff0c\u4f46\u7f3a\u4e4f\u81ea\u52a8\u5316\u5de5\u5177Hammers\u3002\u56e0\u6b64\uff0c\u5f00\u53d1LeanHammer\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faLeanHammer\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u795e\u7ecf\u524d\u63d0\u9009\u62e9\u7cfb\u7edf\u4e0e\u7b26\u53f7Proof\u641c\u7d22\u548c\u91cd\u5efa\uff0c\u52a8\u6001\u9002\u5e94\u7528\u6237\u4e0a\u4e0b\u6587\u3002", "result": "\u4e0e\u73b0\u6709\u524d\u63d0\u9009\u62e9\u5668\u76f8\u6bd4\uff0cLeanHammer\u80fd\u89e3\u51b321%\u66f4\u591a\u7684\u76ee\u6807\uff0c\u5e76\u80fd\u5728\u591a\u6837\u5316\u9886\u57df\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "LeanHammer\u6210\u529f\u5c06\u795e\u7ecf\u68c0\u7d22\u4e0e\u7b26\u53f7\u63a8\u7406\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u53ef\u53ca\u6027\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\u3002"}}
{"id": "2506.07385", "pdf": "https://arxiv.org/pdf/2506.07385", "abs": "https://arxiv.org/abs/2506.07385", "authors": ["Ruofan Liu", "Xiwen Teoh", "Yun Lin", "Guanjie Chen", "Ruofei Ren", "Denys Poshyvanyk", "Jin Song Dong"], "title": "GUIPilot: A Consistency-based Mobile GUI Testing Approach for Detecting Application-specific Bugs", "categories": ["cs.SE"], "comment": null, "summary": "In this work, we propose GUIPilot, an approach for detecting inconsistencies\nbetween the mobile design and their implementations. The mobile design usually\nconsists of design mock-ups that specify (1) the expected screen appearances\n(e.g., widget layouts, colors, and shapes) and (2) the expected screen\nbehaviors, regarding how one screen can transition into another (e.g., labeled\nwidgets with textual description). Given a design mock-up and the\nimplementation of its application, GUIPilot reports both their screen\ninconsistencies as well as process inconsistencies. On the one hand, GUIPilot\ndetects the screen inconsistencies by abstracting every screen into a widget\ncontainer where each widget is represented by its position, width, height, and\ntype. By defining the partial order of widgets and the costs of replacing,\ninserting, and deleting widgets in a screen, we convert the screen-matching\nproblem into an optimizable widget alignment problem. On the other hand, we\ntranslate the specified GUI transition into stepwise actions on the mobile\nscreen (e.g., click, long-press, input text on some widgets). To this end, we\npropose a visual prompt for the vision-language model to infer widget-specific\nactions on the screen. By this means, we can validate the presence or absence\nof expected transitions in the implementation. Our extensive experiments on 80\nmobile applications and 160 design mock-ups show that (1) GUIPilot can achieve\n94.5% precision and 99.6% recall in detecting screen inconsistencies,\noutperforming the state-of-the-art approach, such as GVT, by 66.2% and 56.6%\nrespectively, and (2) GUIPilot reports zero errors in detecting process\ninconsistencies. Furthermore, our industrial case study on applying GUIPilot on\na trading mobile application shows that GUIPilot has detected nine application\nbugs, and all the bugs were confirmed by the original application experts.", "AI": {"tldr": "GUIPilot\u662f\u4e00\u79cd\u68c0\u6d4b\u79fb\u52a8\u8bbe\u8ba1\u4e0e\u5176\u5b9e\u73b0\u4e4b\u95f4\u4e0d\u4e00\u81f4\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c4f\u5e55\u548c\u884c\u4e3a\u5206\u6790\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u79fb\u52a8\u8bbe\u8ba1\u901a\u5e38\u5305\u542b\u8bbe\u8ba1\u6a21\u62df\u56fe\uff0c\u4f46\u5b9e\u9645\u5b9e\u73b0\u4e2d\u53ef\u80fd\u51fa\u73b0\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u5de5\u5177\u8fdb\u884c\u81ea\u52a8\u5316\u68c0\u6d4b\u3002", "method": "GUIPilot\u5c06\u5c4f\u5e55\u62bd\u8c61\u4e3a\u63a7\u4ef6\u5bb9\u5668\uff0c\u901a\u8fc7\u4f18\u5316\u63a7\u4ef6\u5bf9\u9f50\u95ee\u9898\u68c0\u6d4b\u5c4f\u5e55\u4e0d\u4e00\u81f4\u6027\uff1b\u901a\u8fc7\u89c6\u89c9\u63d0\u793a\u6a21\u578b\u63a8\u65ad\u884c\u4e3a\u52a8\u4f5c\u9a8c\u8bc1\u8fc7\u6e21\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cGUIPilot\u5728\u5c4f\u5e55\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u4e2d\u7684\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u5206\u522b\u4e3a94.5%\u548c99.6%\uff0c\u8fc7\u7a0b\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u96f6\u8bef\u5dee\u3002", "conclusion": "GUIPilot\u9ad8\u6548\u4e14\u51c6\u786e\uff0c\u5de5\u4e1a\u6848\u4f8b\u4e2d\u68c0\u6d4b\u5230\u591a\u4e2a\u5e94\u7528\u7f3a\u9677\uff0c\u8bc1\u5b9e\u5176\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2506.07193", "pdf": "https://arxiv.org/pdf/2506.07193", "abs": "https://arxiv.org/abs/2506.07193", "authors": ["Tobias King", "Michael Knierim", "Philipp Lepold", "Christopher Clarke", "Hans Gellersen", "Michael Beigl", "Tobias R\u00f6ddiger"], "title": "earEOG via Periauricular Electrodes to Facilitate Eye Tracking in a Natural Headphone Form Factor", "categories": ["cs.HC"], "comment": "12 pages", "summary": "Eye tracking technology is frequently utilized to diagnose eye and\nneurological disorders, assess sleep and fatigue, study human visual\nperception, and enable novel gaze-based interaction methods. However,\ntraditional eye tracking methodologies are constrained by bespoke hardware that\nis often cumbersome to wear, complex to apply, and demands substantial\ncomputational resources. To overcome these limitations, we investigated\nElectrooculography (EOG) eye tracking using 14 electrodes positioned around the\nears, integrated into a custom-built headphone form factor device. In a\ncontrolled experiment, 16 participants tracked stimuli designed to induce\nsmooth pursuits and saccades. Data analysis identified optimal electrode pairs\nfor vertical and horizontal eye movement tracking, benchmarked against\ngold-standard EOG and camera-based methods. The electrode montage nearest the\neyes yielded the best horizontal results. Horizontal smooth pursuits via earEOG\nshowed high correlation with gold-standard measures ($r_{\\mathrm{EOG}} = 0.81,\np = 0.01$; $r_{\\mathrm{CAM}} = 0.56, p = 0.02$), while vertical pursuits were\nweakly correlated ($r_{\\mathrm{EOG}} = 0.28, p = 0.04$; $r_{\\mathrm{CAM}} =\n0.35, p = 0.05$). Voltage deflections when performing saccades showed strong\ncorrelation in the horizontal direction ($r_{\\mathrm{left}} = 0.99, p = 0.0$;\n$r_{\\mathrm{right}} = 0.99, p = 0.0$) but low correlation in the vertical\ndirection ($r_{\\mathrm{up}} = 0.6, p = 0.23$; $r_{\\mathrm{down}} = 0.19, p =\n0.73$). Overall, horizontal earEOG demonstrated strong performance, indicating\nits potential effectiveness, while vertical earEOG results were poor,\nsuggesting limited feasibility in our current setup.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u8033\u673a\u7684\u773c\u52a8\u8ffd\u8e2a\u65b9\u6cd5\uff08earEOG\uff09\uff0c\u5229\u7528\u7535\u6781\u6d4b\u91cf\u773c\u52a8\uff0c\u5b9e\u9a8c\u663e\u793a\u6c34\u5e73\u65b9\u5411\u6548\u679c\u826f\u597d\uff0c\u4f46\u5782\u76f4\u65b9\u5411\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u4f20\u7edf\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u4f9d\u8d56\u7b28\u91cd\u786c\u4ef6\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u5e0c\u671b\u901a\u8fc7\u8033\u673a\u96c6\u6210\u7684\u7535\u773c\u52a8\u56fe\uff08EOG\uff09\u6280\u672f\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4f7f\u752814\u4e2a\u7535\u6781\u5206\u5e03\u5728\u8033\u673a\u4e0a\u7684\u8bbe\u5907\uff0c\u6d4b\u91cf16\u540d\u53c2\u4e0e\u8005\u7684\u773c\u52a8\u6570\u636e\uff0c\u5206\u6790\u4e0e\u6807\u51c6\u65b9\u6cd5\u7684\u5173\u8054\u6027\u3002", "result": "\u6c34\u5e73\u65b9\u5411\u773c\u52a8\uff08\u5e73\u6ed1\u8ffd\u8e2a\u548c\u626b\u89c6\uff09\u4e0e\u6807\u51c6\u65b9\u6cd5\u9ad8\u5ea6\u76f8\u5173\uff0c\u5782\u76f4\u65b9\u5411\u76f8\u5173\u6027\u8f83\u5f31\u3002", "conclusion": "\u8033EOG\u5728\u6c34\u5e73\u65b9\u5411\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5782\u76f4\u65b9\u5411\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2506.06943", "pdf": "https://arxiv.org/pdf/2506.06943", "abs": "https://arxiv.org/abs/2506.06943", "authors": ["Forough Shirin Abkenar"], "title": "WiFi Pathologies Detection using LLMs", "categories": ["eess.SP", "cs.NI"], "comment": null, "summary": "In this paper, we fine-tune encoder-only and decoder-only large language\nmodels (LLMs) to detect pathologies in IEEE 802.11 networks, commonly known as\nWiFi. Our approach involves manually crafting prompts followed by fine-tuning.\nEvaluations show that the sequential model achieves high detection accuracy\nusing labeled data, while the causal model performs equally well for unlabeled\ndata.", "AI": {"tldr": "\u901a\u8fc7\u5fae\u8c03\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u68c0\u6d4bWiFi\u7f51\u7edc\u4e2d\u7684\u5f02\u5e38\u60c5\u51b5\u3002", "motivation": "\u7814\u7a76\u76ee\u6807\u662f\u5229\u7528LLMs\u6765\u68c0\u6d4bIEEE 802.11\uff08WiFi\uff09\u7f51\u7edc\u7684\u75c5\u7406\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u7f51\u7edc\u8bca\u65ad\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u624b\u52a8\u8bbe\u8ba1\u63d0\u793a\u8bed\u5e76\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u91c7\u7528\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u548c\u56e0\u679c\u6a21\u578b\u4e24\u79cd\u67b6\u6784\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5e8f\u5217\u6a21\u578b\u5728\u6807\u6ce8\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u56e0\u679c\u6a21\u578b\u5728\u672a\u6807\u6ce8\u6570\u636e\u4e0a\u540c\u6837\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5fae\u8c03\u540e\u7684LLMs\u80fd\u591f\u6709\u6548\u68c0\u6d4bWiFi\u7f51\u7edc\u4e2d\u7684\u5f02\u5e38\u60c5\u51b5\uff0c\u4e24\u79cd\u6a21\u578b\u5404\u5177\u4f18\u52bf\u3002"}}
{"id": "2506.07714", "pdf": "https://arxiv.org/pdf/2506.07714", "abs": "https://arxiv.org/abs/2506.07714", "authors": ["Francesco Marchiori", "Denis Donadel", "Alessandro Brighente", "Mauro Conti"], "title": "Profiling Electric Vehicles via Early Charging Voltage Patterns", "categories": ["cs.CR", "cs.ET", "cs.LG"], "comment": "Accepted to be presented at the AI&CPSS Workshop in conjunction with\n  ARES 2025", "summary": "Electric Vehicles (EVs) are rapidly gaining adoption as a sustainable\nalternative to fuel-powered vehicles, making secure charging infrastructure\nessential. Despite traditional authentication protocols, recent results showed\nthat attackers may steal energy through tailored relay attacks. One\ncountermeasure is leveraging the EV's fingerprint on the current exchanged\nduring charging. However, existing methods focus on the final charging stage,\nallowing malicious actors to consume substantial energy before being detected\nand repudiated. This underscores the need for earlier and more effective\nauthentication methods to prevent unauthorized charging. Meanwhile, profiling\nraises privacy concerns, as uniquely identifying EVs through charging patterns\ncould enable user tracking.\n  In this paper, we propose a framework for uniquely identifying EVs using\nphysical measurements from the early charging stages. We hypothesize that\nvoltage behavior early in the process exhibits similar characteristics to\ncurrent behavior in later stages. By extracting features from early voltage\nmeasurements, we demonstrate the feasibility of EV profiling. Our approach\nimproves existing methods by enabling faster and more reliable vehicle\nidentification. We test our solution on a dataset of 7408 usable charges from\n49 EVs, achieving up to 0.86 accuracy. Feature importance analysis shows that\nnear-optimal performance is possible with just 10 key features, improving\nefficiency alongside our lightweight models. This research lays the foundation\nfor a novel authentication factor while exposing potential privacy risks from\nunauthorized access to charging data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e9\u671f\u5145\u7535\u9636\u6bb5\u7535\u538b\u884c\u4e3a\u7684\u7535\u52a8\u6c7d\u8f66\u8ba4\u8bc1\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u7684\u901f\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u5145\u7535\u6570\u636e\u53ef\u80fd\u5e26\u6765\u7684\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5b89\u5168\u6027\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u8ba4\u8bc1\u65b9\u6cd5\u96c6\u4e2d\u5728\u5145\u7535\u540e\u671f\uff0c\u65e0\u6cd5\u53ca\u65f6\u963b\u6b62\u80fd\u6e90\u76d7\u7a83\u884c\u4e3a\uff0c\u540c\u65f6\u5145\u7535\u6a21\u5f0f\u5206\u6790\u53ef\u80fd\u5f15\u53d1\u9690\u79c1\u95ee\u9898\u3002", "method": "\u5229\u7528\u65e9\u671f\u5145\u7535\u9636\u6bb5\u7684\u7535\u538b\u6d4b\u91cf\u6570\u636e\u63d0\u53d6\u7279\u5f81\uff0c\u9a8c\u8bc1\u7535\u52a8\u6c7d\u8f66\u6307\u7eb9\u8bc6\u522b\u7684\u53ef\u884c\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u96c6\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\u3002", "result": "\u57287408\u6b21\u5145\u7535\u6570\u636e\u4e2d\uff0c\u6a21\u578b\u51c6\u786e\u7387\u8fbe0.86\uff0c\u4ec5\u970010\u4e2a\u5173\u952e\u7279\u5f81\u5373\u53ef\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7535\u52a8\u6c7d\u8f66\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u4f46\u5f3a\u8c03\u4e86\u5145\u7535\u6570\u636e\u53ef\u80fd\u88ab\u6ee5\u7528\u7684\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2506.06579", "pdf": "https://arxiv.org/pdf/2506.06579", "abs": "https://arxiv.org/abs/2506.06579", "authors": ["Adarsh Prasad Behera", "Jaya Prakash Champati", "Roberto Morabito", "Sasu Tarkoma", "James Gross"], "title": "Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": null, "summary": "Recent progress in Language Models (LMs) has dramatically advanced the field\nof natural language processing (NLP), excelling at tasks like text generation,\nsummarization, and question answering. However, their inference remains\ncomputationally expensive and energy intensive, especially in settings with\nlimited hardware, power, or bandwidth. This makes it difficult to deploy LMs in\nmobile, edge, or cost sensitive environments. To address these challenges,\nrecent approaches have introduced multi LLM intelligent model selection\nstrategies that dynamically allocate computational resources based on query\ncomplexity -- using lightweight models for simpler queries and escalating to\nlarger models only when necessary. This survey explores two complementary\nstrategies for efficient LLM inference: (i) routing, which selects the most\nsuitable model based on the query, and (ii) cascading or hierarchical inference\n(HI), which escalates queries through a sequence of models until a confident\nresponse is found. Both approaches aim to reduce computation by using\nlightweight models for simpler tasks while offloading only when needed. We\nprovide a comparative analysis of these techniques across key performance\nmetrics, discuss benchmarking efforts, and outline open challenges. Finally, we\noutline future research directions to enable faster response times, adaptive\nmodel selection based on task complexity, and scalable deployment across\nheterogeneous environments, making LLM based systems more efficient and\naccessible for real world applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u8f7b\u91cf\u7ea7\u6216\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ee5\u964d\u4f4e\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u8ba1\u7b97\u8d44\u6e90\u548c\u80fd\u8017\u65b9\u9762\u7684\u9ad8\u989d\u9700\u6c42\u9650\u5236\u4e86\u5176\u5728\u79fb\u52a8\u3001\u8fb9\u7f18\u7b49\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u8bba\u6587\u7814\u7a76\u4e86\u4e24\u79cd\u7b56\u7565\uff1a\u8def\u7531\uff08\u6839\u636e\u67e5\u8be2\u9009\u62e9\u5408\u9002\u6a21\u578b\uff09\u548c\u7ea7\u8054\u63a8\u7406\uff08\u9010\u6b65\u63d0\u5347\u6a21\u578b\u590d\u6742\u5ea6\u76f4\u81f3\u83b7\u5f97\u6ee1\u610f\u7ed3\u679c\uff09\u3002", "result": "\u8fd9\u4e9b\u7b56\u7565\u80fd\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5305\u62ec\u66f4\u5feb\u54cd\u5e94\u65f6\u95f4\u3001\u57fa\u4e8e\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u81ea\u9002\u5e94\u6a21\u578b\u9009\u62e9\uff0c\u4ee5\u53ca\u8de8\u5f02\u6784\u73af\u5883\u7684\u53ef\u6269\u5c55\u90e8\u7f72\u3002"}}
{"id": "2506.07367", "pdf": "https://arxiv.org/pdf/2506.07367", "abs": "https://arxiv.org/abs/2506.07367", "authors": ["Zeyu Guo"], "title": "A Survey on LUT-based Deep Neural Networks Implemented in FPGAs", "categories": ["cs.AR"], "comment": null, "summary": "Low-latency, energy-efficient deep neural networks (DNNs) inference are\ncritical for edge applications, where traditional cloud-based deployment\nsuffers from high latency and security risks. Field-Programmable Gate Arrays\n(FPGAs) offer a compelling solution, balancing reconfigurability, power\nefficiency, and real-time performance. However, conventional FPGA-based DNNs\nrely heavily on digital signal processing (DSP) blocks for multiply-accumulate\n(MAC) operations, limiting scalability.\n  LUT-based DNNs address this challenge by fully leveraging FPGA lookup tables\n(LUTs) for computation, improving resource utilization and reducing inference\nlatency. This survey provides a comprehensive review of LUT-based DNN\narchitectures, including their evolution, design methodologies, and performance\ntrade-offs, while outlining promising directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8eLUT\u7684DNN\u67b6\u6784\uff0c\u89e3\u51b3\u4e86FPGA\u4e2dDSP\u5757\u9650\u5236\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u8d44\u6e90\u5229\u7528\u7387\u548c\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u9700\u6c42\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u6548\u7684DNN\u63a8\u7406\uff0c\u4f20\u7edfFPGA\u4f9d\u8d56DSP\u5757\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002\u57fa\u4e8eLUT\u7684DNN\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "method": "\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8eLUT\u7684DNN\u67b6\u6784\uff0c\u5305\u62ec\u5176\u6f14\u53d8\u3001\u8bbe\u8ba1\u65b9\u6cd5\u548c\u6027\u80fd\u6743\u8861\u3002", "result": "\u57fa\u4e8eLUT\u7684DNN\u63d0\u9ad8\u4e86FPGA\u8d44\u6e90\u5229\u7528\u7387\uff0c\u51cf\u5c11\u4e86\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "\u57fa\u4e8eLUT\u7684DNN\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u672a\u6765\u7814\u7a76\u5c06\u8fdb\u4e00\u6b65\u4f18\u5316\u5176\u6027\u80fd\u3002"}}
{"id": "2506.07138", "pdf": "https://arxiv.org/pdf/2506.07138", "abs": "https://arxiv.org/abs/2506.07138", "authors": ["Hao Tang", "Chengchao Shen"], "title": "Learning Compact Vision Tokens for Efficient Large Multimodal Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": "The source code and trained weights are available at\n  https://github.com/visresearch/LLaVA-STF", "summary": "Large multimodal models (LMMs) suffer significant computational challenges\ndue to the high cost of Large Language Models (LLMs) and the quadratic\ncomplexity of processing long vision token sequences. In this paper, we explore\nthe spatial redundancy among vision tokens and shorten the length of vision\ntoken sequences for inference acceleration. Specifically, we propose a Spatial\nToken Fusion (STF) method to learn compact vision tokens for short vision token\nsequence, where spatial-adjacent tokens are fused into one. Meanwhile,\nweight-frozen vision encoder can not well adapt to the demand of extensive\ndownstream vision-language tasks. To this end, we further introduce a\nMulti-Block Token Fusion (MBTF) module to supplement multi-granularity features\nfor the reduced token sequence. Overall, we combine STF and MBTF module to\nbalance token reduction and information preservation, thereby improving\ninference efficiency without sacrificing multimodal reasoning capabilities.\nExperimental results demonstrate that our method based on LLaVA-1.5 achieves\ncomparable or even superior performance to the baseline on 8 popular\nvision-language benchmarks with only $25\\%$ vision tokens of baseline. The\nsource code and trained weights are available at\nhttps://github.com/visresearch/LLaVA-STF.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSTF\u548cMBTF\u7684\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u89c6\u89c9\u6807\u8bb0\u5e8f\u5217\u7684\u957f\u5ea6\u5e76\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u56e0\u89c6\u89c9\u6807\u8bb0\u5e8f\u5217\u957f\u800c\u5e26\u6765\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7Spatial Token Fusion (STF)\u5b66\u4e60\u7d27\u51d1\u89c6\u89c9\u6807\u8bb0\uff0c\u5e76\u901a\u8fc7Multi-Block Token Fusion (MBTF)\u8865\u5145\u591a\u7c92\u5ea6\u7279\u5f81\u3002", "result": "\u57288\u4e2a\u89c6\u89c9\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u4f7f\u7528\u57fa\u7ebf25%\u7684\u89c6\u89c9\u6807\u8bb0\uff0c\u6027\u80fd\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "\u7ec4\u5408STF\u548cMBTF\u6a21\u5757\uff0c\u80fd\u6709\u6548\u5e73\u8861\u6807\u8bb0\u51cf\u5c11\u548c\u4fe1\u606f\u4fdd\u7559\uff0c\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u4e14\u4e0d\u727a\u7272\u6027\u80fd\u3002"}}
{"id": "2506.07069", "pdf": "https://arxiv.org/pdf/2506.07069", "abs": "https://arxiv.org/abs/2506.07069", "authors": ["Zhican Wang", "Guanghui He", "Dantong Liu", "Lingjun Gao", "Shell Xu Hu", "Chen Zhang", "Zhuoran Song", "Nicholas Lane", "Wayne Luk", "Hongxiang Fan"], "title": "Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization", "categories": ["cs.GR", "cs.AR", "cs.CV", "cs.LG"], "comment": "Preprint. Under review", "summary": "3D Gaussian Splatting (3DGS) has recently gained significant attention for\nhigh-quality and efficient view synthesis, making it widely adopted in fields\nsuch as AR/VR, robotics, and autonomous driving. Despite its impressive\nalgorithmic performance, real-time rendering on resource-constrained devices\nremains a major challenge due to tight power and area budgets. This paper\npresents an architecture-algorithm co-design to address these inefficiencies.\nFirst, we reveal substantial redundancy caused by repeated computation of\ncommon terms/expressions during the conventional rasterization. To resolve\nthis, we propose axis-oriented rasterization, which pre-computes and reuses\nshared terms along both the X and Y axes through a dedicated hardware design,\neffectively reducing multiply-and-add (MAC) operations by up to 63%. Second, by\nidentifying the resource and performance inefficiency of the sorting process,\nwe introduce a novel neural sorting approach that predicts order-independent\nblending weights using an efficient neural network, eliminating the need for\ncostly hardware sorters. A dedicated training framework is also proposed to\nimprove its algorithmic stability. Third, to uniformly support rasterization\nand neural network inference, we design an efficient reconfigurable processing\narray that maximizes hardware utilization and throughput. Furthermore, we\nintroduce a $\\pi$-trajectory tile schedule, inspired by Morton encoding and\nHilbert curve, to optimize Gaussian reuse and reduce memory access overhead.\nComprehensive experiments demonstrate that the proposed design preserves\nrendering quality while achieving a speedup of $23.4\\sim27.8\\times$ and energy\nsavings of $28.8\\sim51.4\\times$ compared to edge GPUs for real-world scenes. We\nplan to open-source our design to foster further development in this field.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u67b6\u6784-\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f74\u5bfc\u5411\u5149\u6805\u5316\u3001\u795e\u7ecf\u6392\u5e8f\u548c\u53ef\u91cd\u6784\u5904\u7406\u9635\u5217\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u9ad8\u65af\u6e32\u67d3\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba13D\u9ad8\u65af\u6e32\u67d3\u5728\u89c6\u89c9\u5408\u6210\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u6e32\u67d3\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8f74\u5bfc\u5411\u5149\u6805\u5316\u51cf\u5c11\u8ba1\u7b97\u5197\u4f59\uff0c\u5f15\u5165\u795e\u7ecf\u6392\u5e8f\u66ff\u4ee3\u786c\u4ef6\u6392\u5e8f\u5668\uff0c\u5e76\u901a\u8fc7\u53ef\u91cd\u6784\u5904\u7406\u9635\u5217\u7edf\u4e00\u652f\u6301\u5149\u6805\u5316\u548c\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u8bbe\u8ba1\u5728\u4fdd\u6301\u6e32\u67d3\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u6027\u80fd\u63d0\u534723.4~27.8\u500d\uff0c\u80fd\u8017\u964d\u4f4e28.8~51.4\u500d\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e863D\u9ad8\u65af\u6e32\u67d3\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u6548\u7387\u95ee\u9898\uff0c\u5e76\u8ba1\u5212\u5f00\u6e90\u4ee5\u63a8\u52a8\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.07419", "pdf": "https://arxiv.org/pdf/2506.07419", "abs": "https://arxiv.org/abs/2506.07419", "authors": ["An Guo", "Xinyu Gao", "Chunrong Fang", "Haoxiang Tian", "Weisong Sun", "Yanzhou Mu", "Shuncheng Tang", "Lei Ma", "Zhenyu Chen"], "title": "Generate Realistic Test Scenes for V2X Communication Systems", "categories": ["cs.SE"], "comment": null, "summary": "Accurately perceiving complex driving environments is essential for ensuring\nthe safe operation of autonomous vehicles. With the tremendous progress in deep\nlearning and communication technologies, cooperative perception with\nVehicle-to-Everything (V2X) technologies has emerged as a solution to overcome\nthe limitations of single-agent perception systems in perceiving distant\nobjects and occlusions. Despite the considerable advancements, V2X cooperative\nperception systems require thorough testing and continuous enhancement of\nsystem performance. Given that V2X driving scenes entail intricate\ncommunications with multiple vehicles across various geographic locations,\ncreating V2X test scenes for these systems poses a significant challenge.\nMoreover, current testing methodologies rely on manual data collection and\nlabeling, which are both time-consuming and costly.\n  In this paper, we design and implement V2XGen, an automated testing\ngeneration tool for V2X cooperative perception systems. V2XGen utilizes a\nhigh-fidelity approach to generate realistic cooperative object instances and\nstrategically place them within the background data in crucial positions.\nFurthermore, V2XGen adopts a fitness-guided V2X scene generation strategy for\nthe transformed scene generation process and improves testing efficiency. We\nconduct experiments on V2XGen using multiple cooperative perception systems\nwith different fusion schemes to assess its performance on various tasks. The\nexperimental results demonstrate that V2XGen is capable of generating realistic\ntest scenes and effectively detecting erroneous behaviors in different\nV2X-oriented driving conditions. Furthermore, the results validate that\nretraining systems under test with the generated scenes can enhance average\ndetection precision while reducing occlusion and long-range perception errors.", "AI": {"tldr": "V2XGen\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u5de5\u5177\uff0c\u7528\u4e8e\u63d0\u5347V2X\u534f\u540c\u611f\u77e5\u7cfb\u7edf\u7684\u6d4b\u8bd5\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u5355\u667a\u80fd\u4f53\u611f\u77e5\u7cfb\u7edf\u5728\u8fdc\u8ddd\u79bb\u548c\u906e\u6321\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0cV2X\u534f\u540c\u611f\u77e5\u7cfb\u7edf\u9700\u8981\u9ad8\u6548\u6d4b\u8bd5\u5de5\u5177\u6765\u9a8c\u8bc1\u548c\u4f18\u5316\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u9ad8\u4fdd\u771f\u65b9\u6cd5\u751f\u6210\u771f\u5b9e\u534f\u540c\u5bf9\u8c61\u5b9e\u4f8b\uff0c\u5e76\u901a\u8fc7\u9002\u5e94\u6027\u5f15\u5bfc\u7684V2X\u573a\u666f\u751f\u6210\u7b56\u7565\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cV2XGen\u80fd\u751f\u6210\u771f\u5b9e\u6d4b\u8bd5\u573a\u666f\uff0c\u6709\u6548\u68c0\u6d4b\u9519\u8bef\u884c\u4e3a\uff0c\u5e76\u63d0\u5347\u7cfb\u7edf\u68c0\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "V2XGen\u4e3aV2X\u534f\u540c\u611f\u77e5\u7cfb\u7edf\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2506.07211", "pdf": "https://arxiv.org/pdf/2506.07211", "abs": "https://arxiv.org/abs/2506.07211", "authors": ["Gionnieve Lim", "Bryan Chen Zhengyu Tan", "Kellie Yu Hui Sim", "Weiyan Shi", "Ming Hui Chew", "Ming Shan Hee", "Roy Ka-Wei Lee", "Simon T. Perrault", "Kenny Tsu Wei Choo"], "title": "Sword and Shield: Uses and Strategies of LLMs in Navigating Disinformation", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The emergence of Large Language Models (LLMs) presents a dual challenge in\nthe fight against disinformation. These powerful tools, capable of generating\nhuman-like text at scale, can be weaponised to produce sophisticated and\npersuasive disinformation, yet they also hold promise for enhancing detection\nand mitigation strategies. This paper investigates the complex dynamics between\nLLMs and disinformation through a communication game that simulates online\nforums, inspired by the game Werewolf, with 25 participants. We analyse how\nDisinformers, Moderators, and Users leverage LLMs to advance their goals,\nrevealing both the potential for misuse and combating disinformation. Our\nfindings highlight the varying uses of LLMs depending on the participants'\nroles and strategies, underscoring the importance of understanding their\neffectiveness in this context. We conclude by discussing implications for\nfuture LLM development and online platform design, advocating for a balanced\napproach that empowers users and fosters trust while mitigating the risks of\nLLM-assisted disinformation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u4e2d\u7684\u53cc\u91cd\u4f5c\u7528\uff0c\u901a\u8fc7\u6a21\u62df\u5728\u7ebf\u8bba\u575b\u7684\u6e38\u620f\u5b9e\u9a8c\u5206\u6790\u5176\u6f5c\u5728\u5371\u5bb3\u4e0e\u79ef\u6781\u7528\u9014\uff0c\u5e76\u63d0\u51fa\u5747\u8861\u53d1\u5c55\u7684\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76LLM\u5728\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u4e2d\u7684\u53cc\u91cd\u4f5c\u7528\uff0c\u65e2\u53ef\u80fd\u88ab\u6ee5\u7528\u751f\u6210\u865a\u5047\u4fe1\u606f\uff0c\u4e5f\u53ef\u7528\u4e8e\u68c0\u6d4b\u548c\u5e94\u5bf9\u865a\u5047\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u53d7\u72fc\u4eba\u6740\u542f\u53d1\u7684\u901a\u8baf\u6e38\u620f\uff0c\u6a21\u62df\u5728\u7ebf\u8bba\u575b\uff0c\u5206\u679025\u540d\u53c2\u4e0e\u8005\u5728\u4e0d\u540c\u89d2\u8272\uff08\u6563\u64ad\u8005\u3001\u76d1\u7ba1\u8005\u3001\u7528\u6237\uff09\u4e2d\u5229\u7528LLM\u7684\u7b56\u7565\u3002", "result": "\u53d1\u73b0LLM\u7684\u4f7f\u7528\u56e0\u89d2\u8272\u548c\u7b56\u7565\u800c\u5f02\uff0c\u63ed\u793a\u4e86\u5176\u6f5c\u5728\u7684\u6ee5\u7528\u548c\u5bf9\u6297\u865a\u5047\u4fe1\u606f\u7684\u53cc\u91cd\u6548\u679c\u3002", "conclusion": "\u5efa\u8bae\u672a\u6765LLM\u5f00\u53d1\u548c\u5e73\u53f0\u8bbe\u8ba1\u9700\u5e73\u8861\uff0c\u65e2\u80fd\u63d0\u5347\u7528\u6237\u80fd\u529b\u3001\u589e\u5f3a\u4fe1\u4efb\uff0c\u53c8\u80fd\u964d\u4f4e\u865a\u5047\u4fe1\u606f\u98ce\u9669\u3002"}}
{"id": "2506.07355", "pdf": "https://arxiv.org/pdf/2506.07355", "abs": "https://arxiv.org/abs/2506.07355", "authors": ["Yuya Okada", "Takayuki Nishio"], "title": "SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "6 pages, submitted to IEEE Globecom 2025 (under review)", "summary": "We propose SALT (Split-Adaptive Lightweight Tuning), a lightweight model\nadaptation framework for Split Computing under closed constraints, where the\nhead and tail networks are proprietary and inaccessible to users. In such\nclosed environments, conventional adaptation methods are infeasible since they\nrequire access to model parameters or architectures. SALT addresses this\nchallenge by introducing a compact, trainable adapter on the client side to\nrefine latent features from the head network, enabling user-specific adaptation\nwithout modifying the original models or increasing communication overhead. We\nevaluate SALT on user-specific classification tasks with CIFAR-10 and\nCIFAR-100, demonstrating improved accuracy with lower training latency compared\nto fine-tuning methods. Furthermore, SALT facilitates model adaptation for\nrobust inference over lossy networks, a common challenge in edge-cloud\nenvironments. With minimal deployment overhead, SALT offers a practical\nsolution for personalized inference in edge AI systems under strict system\nconstraints.", "AI": {"tldr": "SALT \u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6a21\u578b\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5c01\u95ed\u7ea6\u675f\u4e0b\u8fdb\u884c Split Computing\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u9002\u914d\u5668\u4f18\u5316\u7279\u5f81\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u63a8\u7406\uff0c\u63d0\u5347\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u8bad\u7ec3\u5ef6\u8fdf\u3002", "motivation": "\u5728 Split Computing \u7684\u5c01\u95ed\u73af\u5883\u4e2d\uff0c\u7528\u6237\u65e0\u6cd5\u8bbf\u95ee\u5934\u5c3e\u7f51\u7edc\u7684\u53c2\u6570\u6216\u67b6\u6784\uff0c\u4f20\u7edf\u9002\u5e94\u65b9\u6cd5\u4e0d\u53ef\u884c\u3002SALT \u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "SALT \u5728\u5ba2\u6237\u7aef\u5f15\u5165\u4e00\u4e2a\u7d27\u51d1\u3001\u53ef\u8bad\u7ec3\u7684\u9002\u914d\u5668\uff0c\u4f18\u5316\u5934\u7f51\u7edc\u7684\u6f5c\u5728\u7279\u5f81\uff0c\u65e0\u9700\u4fee\u6539\u539f\u59cb\u6a21\u578b\u6216\u589e\u52a0\u901a\u4fe1\u5f00\u9500\u3002", "result": "\u5728 CIFAR-10 \u548c CIFAR-100 \u4efb\u52a1\u4e2d\uff0cSALT \u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u8bad\u7ec3\u5ef6\u8fdf\u66f4\u4f4e\uff0c\u5e76\u80fd\u9002\u5e94\u6709\u635f\u7f51\u7edc\u7684\u7a33\u5065\u63a8\u7406\u3002", "conclusion": "SALT \u4e3a\u8fb9\u7f18 AI \u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u4e25\u683c\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e2a\u6027\u5316\u63a8\u7406\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u90e8\u7f72\u5f00\u9500\u6781\u5c0f\u3002"}}
{"id": "2506.07743", "pdf": "https://arxiv.org/pdf/2506.07743", "abs": "https://arxiv.org/abs/2506.07743", "authors": ["G. Intoccia", "U. Chirico", "G. Pepe", "S. Cuomo"], "title": "Quantum-Enhanced Spectral Solution of the Poisson Equation", "categories": ["math.NA", "cs.ET", "cs.NA"], "comment": null, "summary": "We present a hybrid numerical-quantum method for solving the Poisson equation\nunder homogeneous Dirichlet boundary conditions, leveraging the Quantum Fourier\nTransform (QFT) to enhance computational efficiency and reduce time and space\ncomplexity. This approach bypasses the integration-heavy calculations of\nclassical methods, which have to deal with high computational costs for large\nnumber of points. The proposed method estimates the coefficients of the series\nexpansion of the solution directly within the quantum framework. Numerical\nexperiments validate its effectiveness and reveal significant improvements in\nterms of time and space complexity and solution accuracy, demonstrating the\ncapability of quantum-assisted techniques to contribute in solving partial\ndifferential equations (PDEs). Despite the inherent challenges of quantum\nimplementation, the present work serves as a starting point for future\nresearches aimed at refining and expanding quantum numerical methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6570\u503c-\u91cf\u5b50\u65b9\u6cd5\uff0c\u5229\u7528\u91cf\u5b50\u5085\u91cc\u53f6\u53d8\u6362\uff08QFT\uff09\u63d0\u5347\u6cca\u677e\u65b9\u7a0b\u6c42\u89e3\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u964d\u4f4e\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u7ecf\u5178\u65b9\u6cd5\u5728\u5904\u7406\u5927\u91cf\u70b9\u65f6\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u63a2\u7d22\u91cf\u5b50\u8f85\u52a9\u6280\u672f\u5728\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u6c42\u89e3\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u91cf\u5b50\u6846\u67b6\u76f4\u63a5\u4f30\u8ba1\u89e3\u7684\u7ea7\u6570\u5c55\u5f00\u7cfb\u6570\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u7684\u79ef\u5206\u8ba1\u7b97\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u65f6\u95f4\u3001\u7a7a\u95f4\u590d\u6742\u6027\u548c\u89e3\u7cbe\u5ea6\u4e0a\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u5c3d\u7ba1\u91cf\u5b50\u5b9e\u73b0\u5b58\u5728\u6311\u6218\uff0c\u4f46\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u4f18\u5316\u548c\u6269\u5c55\u91cf\u5b50\u6570\u503c\u65b9\u6cd5\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.07665", "pdf": "https://arxiv.org/pdf/2506.07665", "abs": "https://arxiv.org/abs/2506.07665", "authors": ["Roberto Giorgi"], "title": "FREESS: An Educational Simulator of a RISC-V-Inspired Superscalar Processor Based on Tomasulo's Algorithm", "categories": ["cs.AR", "C.1.2; C.1.3; K.3.2"], "comment": "WCAE'25 - Workshop on Computer Architecture Education, June 21--25,\n  2025, Tokyo, Japan", "summary": "FREESS is a free, interactive simulator that illustrates instruction-level\nparallelism in a RISC-V-inspired superscalar processor. Based on an extended\nversion of Tomasulo's algorithm, FREESS is intended as a hands-on educational\ntool for Advanced Computer Architecture courses. It enables students to explore\ndynamic, out-of-order instruction execution, emphasizing how instructions are\nissued as soon as their operands become available.\n  The simulator models key microarchitectural components, including the\nInstruction Window (IW), Reorder Buffer (ROB), Register Map (RM), Free Pool\n(FP), and Load/Store Queues. FREESS allows users to dynamically configure\nruntime parameters, such as the superscalar issue width, functional unit types\nand latencies, and the sizes of architectural buffers and queues.\n  To simplify learning, the simulator uses a minimal instruction set inspired\nby RISC-V (ADD, ADDI, BEQ, BNE, LW, MUL, SW), which is sufficient to\ndemonstrate key pipeline stages: fetch, register renaming, out-of-order\ndispatch, execution, completion, commit, speculative branching, and memory\naccess. FREESS includes three step-by-step, illustrated examples that visually\ndemonstrate how multiple instructions can be issued and executed in parallel\nwithin a single cycle. Being open source, FREESS encourages students and\neducators to experiment freely by writing and analyzing their own\ninstruction-level programs and superscalar architectures.", "AI": {"tldr": "FREESS\u662f\u4e00\u4e2a\u514d\u8d39\u7684\u4ea4\u4e92\u5f0f\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u6559\u5b66RISC-V\u542f\u53d1\u7684\u8d85\u6807\u91cf\u5904\u7406\u5668\u4e2d\u7684\u6307\u4ee4\u7ea7\u5e76\u884c\u6027\u3002", "motivation": "\u4e3a\u9ad8\u7ea7\u8ba1\u7b97\u673a\u67b6\u6784\u8bfe\u7a0b\u63d0\u4f9b\u4e00\u4e2a\u5b9e\u8df5\u6027\u5f3a\u7684\u6559\u5b66\u5de5\u5177\uff0c\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u52a8\u6001\u4e71\u5e8f\u6307\u4ee4\u6267\u884c\u3002", "method": "\u57fa\u4e8e\u6269\u5c55\u7684Tomasulo\u7b97\u6cd5\uff0c\u6a21\u62df\u5fae\u67b6\u6784\u7ec4\u4ef6\uff0c\u652f\u6301\u52a8\u6001\u914d\u7f6e\u8fd0\u884c\u65f6\u53c2\u6570\uff0c\u4f7f\u7528\u7cbe\u7b80\u7684RISC-V\u6307\u4ee4\u96c6\u3002", "result": "\u901a\u8fc7\u4e00\u6b65\u6b65\u7684\u793a\u4f8b\uff0c\u53ef\u89c6\u5316\u5c55\u793a\u6307\u4ee4\u5728\u5355\u5468\u671f\u5185\u7684\u5e76\u884c\u6267\u884c\uff0c\u63d0\u4f9b\u5f00\u6e90\u5e73\u53f0\u4f9b\u5b9e\u9a8c\u3002", "conclusion": "FREESS\u662f\u4e00\u4e2a\u6709\u6548\u7684\u6559\u80b2\u5de5\u5177\uff0c\u9002\u5408\u5b66\u751f\u548c\u6559\u5e08\u901a\u8fc7\u5b9e\u9a8c\u5b66\u4e60\u8d85\u6807\u91cf\u67b6\u6784\u548c\u6307\u4ee4\u7ea7\u5e76\u884c\u6027\u3002"}}
{"id": "2506.07634", "pdf": "https://arxiv.org/pdf/2506.07634", "abs": "https://arxiv.org/abs/2506.07634", "authors": ["Chenyu Yang", "Shuai Wang", "Hangting Chen", "Wei Tan", "Jianwei Yu", "Haizhou Li"], "title": "SongBloom: Coherent Song Generation via Interleaved Autoregressive Sketching and Diffusion Refinement", "categories": ["eess.AS", "cs.MM"], "comment": "Submitted to NeurIPS2025", "summary": "Generating music with coherent structure, harmonious instrumental and vocal\nelements remains a significant challenge in song generation. Existing language\nmodels and diffusion-based methods often struggle to balance global coherence\nwith local fidelity, resulting in outputs that lack musicality or suffer from\nincoherent progression and mismatched lyrics. This paper introduces\n$\\textbf{SongBloom}$, a novel framework for full-length song generation that\nleverages an interleaved paradigm of autoregressive sketching and\ndiffusion-based refinement. SongBloom employs an autoregressive diffusion model\nthat combines the high fidelity of diffusion models with the scalability of\nlanguage models. Specifically, it gradually extends a musical sketch from short\nto long and refines the details from coarse to fine-grained. The interleaved\ngeneration paradigm effectively integrates prior semantic and acoustic context\nto guide the generation process. Experimental results demonstrate that\nSongBloom outperforms existing methods across both subjective and objective\nmetrics and achieves performance comparable to the state-of-the-art commercial\nmusic generation platforms. Audio samples are available on our demo page:\nhttps://cypress-yang.github.io/SongBloom\\_demo.", "AI": {"tldr": "SongBlo\u2026", "motivation": "Generating music with coherent structure and harmonious elements remains challenging, as current methods struggle with balancing global coherence and local fidelity.", "method": "SongBloom uses an autoregressive diffusion model for full-length song generation, combining diffusion models' high fidelity with language models' scalability through interleaved sketching and refinement.", "result": "SongBloom outperforms existing methods in subjective and objective metrics, achieving performance close to commercial platforms.", "conclusion": "SongBloom presents a promising framework for high-quality, coherent song generation."}}
{"id": "2506.07209", "pdf": "https://arxiv.org/pdf/2506.07209", "abs": "https://arxiv.org/abs/2506.07209", "authors": ["Lei Li", "Angela Dai"], "title": "HOI-PAGE: Zero-Shot Human-Object Interaction Generation with Part Affordance Guidance", "categories": ["cs.GR", "cs.CV"], "comment": "Project page: https://hoipage.github.io/ Video:\n  https://youtu.be/b1pJU9lKQTE", "summary": "We present HOI-PAGE, a new approach to synthesizing 4D human-object\ninteractions (HOIs) from text prompts in a zero-shot fashion, driven by\npart-level affordance reasoning. In contrast to prior works that focus on\nglobal, whole body-object motion for 4D HOI synthesis, we observe that\ngenerating realistic and diverse HOIs requires a finer-grained understanding --\nat the level of how human body parts engage with object parts. We thus\nintroduce Part Affordance Graphs (PAGs), a structured HOI representation\ndistilled from large language models (LLMs) that encodes fine-grained part\ninformation along with contact relations. We then use these PAGs to guide a\nthree-stage synthesis: first, decomposing input 3D objects into geometric\nparts; then, generating reference HOI videos from text prompts, from which we\nextract part-based motion constraints; finally, optimizing for 4D HOI motion\nsequences that not only mimic the reference dynamics but also satisfy\npart-level contact constraints. Extensive experiments show that our approach is\nflexible and capable of generating complex multi-object or multi-person\ninteraction sequences, with significantly improved realism and text alignment\nfor zero-shot 4D HOI generation.", "AI": {"tldr": "HOI-PAGE\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u6837\u672c\u65b9\u6cd5\uff0c\u901a\u8fc7\u90e8\u5206\u7ea7\u9002\u5e94\u6027\u63a8\u7406\u4ece\u6587\u672c\u63d0\u793a\u5408\u62104D\u4eba-\u7269\u4ea4\u4e92\uff08HOI\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u771f\u5b9e\u6027\u548c\u6587\u672c\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5173\u6ce8\u5168\u5c40\u4eba\u4f53-\u7269\u4f53\u8fd0\u52a8\uff0c\u800c\u5ffd\u7565\u90e8\u5206\u7ea7\u4ea4\u4e92\u7ec6\u8282\u3002\u4e3a\u4e86\u751f\u6210\u66f4\u771f\u5b9e\u548c\u591a\u6837\u5316\u7684HOI\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u7406\u89e3\u3002", "method": "\u5f15\u5165\u90e8\u5206\u9002\u5e94\u6027\u56fe\uff08PAGs\uff09\u8868\u5f81HOI\uff0c\u5e76\u7ed3\u5408\u4e09\u9636\u6bb5\u5408\u6210\u65b9\u6cd5\uff1a\u5206\u89e3\u5bf9\u8c61\u3001\u751f\u6210\u53c2\u8003\u89c6\u9891\u3001\u4f18\u53164D\u8fd0\u52a8\u5e8f\u5217\u4ee5\u6ee1\u8db3\u90e8\u5206\u7ea7\u63a5\u89e6\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u7075\u6d3b\u751f\u6210\u590d\u6742\u7684\u591a\u4eba\u6216\u591a\u7269\u4ea4\u4e92\u5e8f\u5217\uff0c\u5728\u96f6\u6837\u672c4D HOI\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u7684\u771f\u5b9e\u6027\u548c\u6587\u672c\u5bf9\u9f50\u3002", "conclusion": "HOI-PAGE\u901a\u8fc7\u90e8\u5206\u7ea7\u63a8\u7406\u548c\u7ed3\u6784\u5316\u8868\u5f81\uff0c\u4e3a4D HOI\u5408\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07486", "pdf": "https://arxiv.org/pdf/2506.07486", "abs": "https://arxiv.org/abs/2506.07486", "authors": ["Yuxiang Zhang", "Pengyu Xue", "Zhen Yang", "Xiaoxue Ren", "Xiang Li", "Linhao Wu", "Jiancheng Zhao", "Xingda Yu"], "title": "A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions", "categories": ["cs.SE"], "comment": null, "summary": "Automated test-generation research overwhelmingly assumes the correctness of\nfocal methods, yet practitioners routinely face non-regression scenarios where\nthe focal method may be defective. A baseline evaluation of EvoSuite and two\nleading Large Language Model (LLM)-based generators, namely ChatTester and\nChatUniTest, on defective focal methods reveals that despite achieving up to\n83% of branch coverage, none of the generated tests expose defects.\n  To resolve this problem, we first construct two new benchmarks, namely\nDefects4J-Desc and QuixBugs-Desc, for experiments. In particular, each focal\nmethod is equipped with an extra Natural Language Description (NLD) for code\nfunctionality understanding.\n  Subsequently, we propose DISTINCT, a Description-guided, branch-consistency\nanalysis framework that transforms LLMs into fault-aware test generators.\nDISTINCT carries three iterative components: (1) a Generator that derives\ninitial tests based on the NLDs and the focal method, (2) a Validator that\niteratively fixes uncompilable tests using compiler diagnostics, and (3) an\nAnalyzer that iteratively aligns test behavior with NLD semantics via\nbranch-level analysis.\n  Extensive experiments confirm the effectiveness of our approach. Compared to\nstate-of-the-art methods, DISTINCT achieves an average improvement of 14.64% in\nCompilation Success Rate (CSR) and 6.66% in Passing Rate (PR) across both\nbenchmarks. It notably enhances Defect Detection Rate (DDR) on both benchmarks,\nwith a particularly significant gain of 149.26% observed on Defects4J-Desc. In\nterms of code coverage, DISTINCT improves Statement Coverage (SC) by an average\nof 3.77% and Branch Coverage (BC) by 5.36%. These results set a new baseline\nfor non-regressive test generation and highlight how description-driven\nreasoning enables LLMs to move beyond coverage chasing toward effective defect\ndetection.", "AI": {"tldr": "DISTINCT\u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u652f\u4e00\u81f4\u6027\u5206\u6790\u63d0\u5347LLM\u5728\u7f3a\u9677\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u751f\u6210\u5de5\u5177\u5047\u8bbe\u88ab\u6d4b\u8bd5\u65b9\u6cd5\u6b63\u786e\uff0c\u800c\u5b9e\u9645\u573a\u666f\u4e2d\u65b9\u6cd5\u53ef\u80fd\u6709\u7f3a\u9677\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u9ad8\u7f3a\u9677\u68c0\u6d4b\u7387\u3002", "method": "DISTINCT\u5305\u542b\u751f\u6210\u5668\u3001\u9a8c\u8bc1\u5668\u548c\u5206\u6790\u5668\u4e09\u4e2a\u8fed\u4ee3\u7ec4\u4ef6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u548c\u5206\u652f\u5206\u6790\u751f\u6210\u5e76\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "DISTINCT\u663e\u8457\u63d0\u5347\u7f16\u8bd1\u6210\u529f\u7387\u3001\u901a\u8fc7\u7387\u548c\u7f3a\u9677\u68c0\u6d4b\u7387\uff0c\u5e76\u5728\u4ee3\u7801\u8986\u76d6\u7387\u548c\u5206\u652f\u8986\u76d6\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DISTINCT\u4e3a\u975e\u56de\u5f52\u6d4b\u8bd5\u751f\u6210\u8bbe\u5b9a\u4e86\u65b0\u57fa\u51c6\uff0c\u5c55\u793a\u4e86\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u9a71\u52a8\u7684LLM\u5728\u7f3a\u9677\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.07278", "pdf": "https://arxiv.org/pdf/2506.07278", "abs": "https://arxiv.org/abs/2506.07278", "authors": ["Victor B. Santos", "Cau\u00e3 O. Jord\u00e3o", "Leonardo J. O. Ibiapina", "Gabriel M. Silva", "Mirella E. B. Santana", "Matheus A. Garrido", "Lucas R. C. Farias"], "title": "IDEIA: A Generative AI-Based System for Real-Time Editorial Ideation in Digital Journalism", "categories": ["cs.HC"], "comment": "9 pages, 5 figures", "summary": "This paper presents IDEIA (Intelligent Engine for Editorial Ideation and\nAssistance), a generative AI-powered system designed to optimize the\njournalistic ideation process by combining real-time trend analysis with\nautomated content suggestion. Developed in collaboration with the Sistema\nJornal do Commercio de Comunica\\c{c}\\~ao (SJCC), the largest media conglomerate\nin Brazil's North and Northeast regions, IDEIA integrates the Google Trends API\nfor data-driven topic monitoring and the Google Gemini API for the generation\nof context-aware headlines and summaries. The system adopts a modular\narchitecture based on Node.js, React, and PostgreSQL, supported by Docker\ncontainerization and a CI/CD pipeline using GitHub Actions and Vercel.\nEmpirical results demonstrate a significant reduction in the time and cognitive\neffort required for editorial planning, with reported gains of up to 70\\% in\nthe content ideation stage. This work contributes to the field of computational\njournalism by showcasing how intelligent automation can enhance productivity\nwhile maintaining editorial quality. It also discusses the technical and\nethical implications of incorporating generative models into newsroom\nworkflows, highlighting scalability and future applicability across sectors\nbeyond journalism.", "AI": {"tldr": "IDEIA\u662f\u4e00\u4e2a\u751f\u6210\u5f0fAI\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9e\u65f6\u8d8b\u52bf\u5206\u6790\u548c\u5185\u5bb9\u5efa\u8bae\u4f18\u5316\u65b0\u95fb\u7f16\u8f91\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65b0\u95fb\u7f16\u8f91\u8fc7\u7a0b\u4e2d\u65f6\u95f4\u548c\u8ba4\u77e5\u8d1f\u62c5\u9ad8\u7684\u95ee\u9898\uff0cIDEIA\u65e8\u5728\u901a\u8fc7AI\u667a\u80fd\u8f85\u52a9\u63d0\u5347\u5185\u5bb9\u7b56\u5212\u6548\u7387\u3002", "method": "IDEIA\u6574\u5408\u4e86Google Trends\u548cGemini API\uff0c\u91c7\u7528Node.js\u3001React\u548cPostgreSQL\u7684\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5e76\u5229\u7528Docker\u548cCI/CD\u8fdb\u884c\u90e8\u7f72\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7f16\u8f91\u7b56\u5212\u9636\u6bb5\u7684\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe70%\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u3002", "conclusion": "IDEIA\u5c55\u793a\u4e86\u667a\u80fd\u81ea\u52a8\u5316\u5728\u65b0\u95fb\u4e1a\u4e2d\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u751f\u6210\u6a21\u578b\u5728\u65b0\u95fb\u5de5\u4f5c\u6d41\u4e2d\u7684\u6280\u672f\u53ca\u4f26\u7406\u95ee\u9898\u3002"}}
{"id": "2506.07836", "pdf": "https://arxiv.org/pdf/2506.07836", "abs": "https://arxiv.org/abs/2506.07836", "authors": ["Silvia Lucia Sanna", "Diego Soi", "Davide Maiorca", "Giorgio Giacinto"], "title": "Are Trees Really Green? A Detection Approach of IoT Malware Attacks", "categories": ["cs.CR", "cs.AI", "cs.NI"], "comment": null, "summary": "Nowadays, the Internet of Things (IoT) is widely employed, and its usage is\ngrowing exponentially because it facilitates remote monitoring, predictive\nmaintenance, and data-driven decision making, especially in the healthcare and\nindustrial sectors. However, IoT devices remain vulnerable due to their\nresource constraints and difficulty in applying security patches. Consequently,\nvarious cybersecurity attacks are reported daily, such as Denial of Service,\nparticularly in IoT-driven solutions. Most attack detection methodologies are\nbased on Machine Learning (ML) techniques, which can detect attack patterns.\nHowever, the focus is more on identification rather than considering the impact\nof ML algorithms on computational resources. This paper proposes a green\nmethodology to identify IoT malware networking attacks based on flow\nprivacy-preserving statistical features. In particular, the hyperparameters of\nthree tree-based models -- Decision Trees, Random Forest and Extra-Trees -- are\noptimized based on energy consumption and test-time performance in terms of\nMatthew's Correlation Coefficient. Our results show that models maintain high\nperformance and detection accuracy while consistently reducing power usage in\nterms of watt-hours (Wh). This suggests that on-premise ML-based Intrusion\nDetection Systems are suitable for IoT and other resource-constrained devices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8282\u80fd\u7684\u6811\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522bIoT\u6076\u610f\u7f51\u7edc\u653b\u51fb\uff0c\u517c\u987e\u9ad8\u6027\u80fd\u4e0e\u4f4e\u80fd\u8017\u3002", "motivation": "IoT\u8bbe\u5907\u7531\u4e8e\u8d44\u6e90\u53d7\u9650\u548c\u96be\u4ee5\u5e94\u7528\u5b89\u5168\u8865\u4e01\uff0c\u6613\u53d7\u7f51\u7edc\u653b\u51fb\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u591a\u5173\u6ce8\u653b\u51fb\u8bc6\u522b\uff0c\u5ffd\u7565\u4e86\u7b97\u6cd5\u5bf9\u8ba1\u7b97\u8d44\u6e90\u7684\u5f71\u54cd\u3002", "method": "\u4f18\u5316\u4e09\u79cd\u6811\u6a21\u578b\uff08\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u3001Extra-Trees\uff09\u7684\u8d85\u53c2\u6570\uff0c\u57fa\u4e8e\u80fd\u8017\u548c\u6d4b\u8bd5\u6027\u80fd\uff08\u9a6c\u4fee\u65af\u76f8\u5173\u7cfb\u6570\uff09\u3002", "result": "\u6a21\u578b\u5728\u964d\u4f4e\u80fd\u8017\uff08\u74e6\u65f6\uff09\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u548c\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u57fa\u4e8e\u672c\u5730\u7684ML\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u9002\u5408IoT\u7b49\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u3002"}}
{"id": "2506.07810", "pdf": "https://arxiv.org/pdf/2506.07810", "abs": "https://arxiv.org/abs/2506.07810", "authors": ["Emiliano Tolotti", "Enrico Blanzieri", "Davide Pastorello"], "title": "A weighted quantum ensemble of homogeneous quantum classifiers", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "21 pages, 4 figures", "summary": "Ensemble methods in machine learning aim to improve prediction accuracy by\ncombining multiple models. This is achieved by ensuring diversity among\npredictors to capture different data aspects. Homogeneous ensembles use\nidentical models, achieving diversity through different data subsets, and\nweighted-average ensembles assign higher influence to more accurate models\nthrough a weight learning procedure. We propose a method to achieve a weighted\nhomogeneous quantum ensemble using quantum classifiers with indexing registers\nfor data encoding. This approach leverages instance-based quantum classifiers,\nenabling feature and training point subsampling through superposition and\ncontrolled unitaries, and allowing for a quantum-parallel execution of diverse\ninternal classifiers with different data compositions in superposition. The\nmethod integrates a learning process involving circuit execution and classical\nweight optimization, for a trained ensemble execution with weights encoded in\nthe circuit at test-time. Empirical evaluation demonstrate the effectiveness of\nthe proposed method, offering insights into its performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a0\u6743\u540c\u8d28\u91cf\u5b50\u96c6\u6210\u65b9\u6cd5\uff0c\u5229\u7528\u91cf\u5b50\u5206\u7c7b\u5668\u548c\u7d22\u5f15\u5bc4\u5b58\u5668\u5b9e\u73b0\u6570\u636e\u7f16\u7801\uff0c\u901a\u8fc7\u91cf\u5b50\u5e76\u884c\u6267\u884c\u591a\u6837\u5316\u5185\u90e8\u5206\u7c7b\u5668\uff0c\u5e76\u5728\u6d4b\u8bd5\u65f6\u7535\u8def\u4e2d\u7f16\u7801\u6743\u91cd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u901a\u8fc7\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u7684\u5e76\u884c\u6027\u548c\u96c6\u6210\u5b66\u4e60\u7684\u591a\u6837\u6027\uff0c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u91cf\u5b50\u5206\u7c7b\u5668\u548c\u7d22\u5f15\u5bc4\u5b58\u5668\u8fdb\u884c\u6570\u636e\u7f16\u7801\uff0c\u901a\u8fc7\u53e0\u52a0\u548c\u63a7\u5236\u95e8\u5b9e\u73b0\u6570\u636e\u5b50\u91c7\u6837\uff0c\u91cf\u5b50\u5e76\u884c\u6267\u884c\u591a\u6837\u5316\u5206\u7c7b\u5668\uff0c\u5e76\u4f18\u5316\u6743\u91cd\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u52a0\u6743\u540c\u8d28\u91cf\u5b50\u96c6\u6210\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u9ad8\u6548\u4e14\u591a\u6837\u5316\u7684\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u96c6\u6210\u5b66\u4e60\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2506.07581", "pdf": "https://arxiv.org/pdf/2506.07581", "abs": "https://arxiv.org/abs/2506.07581", "authors": ["Tan Chen", "Jintao Yan", "Yuxuan Sun", "Sheng Zhou", "Zhisheng Niu"], "title": "FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Federated learning (FL) is a promising paradigm for multiple devices to\ncooperatively train a model. When applied in wireless networks, two issues\nconsistently affect the performance of FL, i.e., data heterogeneity of devices\nand limited bandwidth. Many papers have investigated device scheduling\nstrategies considering the two issues. However, most of them recognize data\nheterogeneity as a property of individual devices. In this paper, we prove that\nthe convergence speed of FL is affected by the sum of device-level and\nsample-level collective gradient divergence (CGD). The device-level CGD refers\nto the gradient divergence of the scheduled device group, instead of the sum of\nthe individual device divergence. The sample-level CGD is statistically upper\nbounded by sampling variance, which is inversely proportional to the total\nnumber of samples scheduled for local update. To derive a tractable form of the\ndevice-level CGD, we further consider a classification problem and transform it\ninto the weighted earth moving distance (WEMD) between the group distribution\nand the global distribution. Then we propose FedCGD algorithm to minimize the\nsum of multi-level CGDs by balancing WEMD and sampling variance, within\npolynomial time. Simulation shows that the proposed strategy increases\nclassification accuracy on the CIFAR-10 dataset by up to 4.2\\% while scheduling\n41.8\\% fewer devices, and flexibly switches between reducing WEMD and reducing\nsampling variance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u591a\u7ea7\u68af\u5ea6\u53d1\u6563\uff08CGD\uff09\u6982\u5ff5\uff0c\u8bc1\u660e\u5176\u5f71\u54cdFL\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u63d0\u51faFedCGD\u7b97\u6cd5\u4f18\u5316\u8c03\u5ea6\u7b56\u7565\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u8054\u90a6\u5b66\u4e60\u7684\u6570\u636e\u5f02\u6784\u6027\u548c\u5e26\u5bbd\u9650\u5236\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u672a\u5145\u5206\u5173\u6ce8\u8bbe\u5907\u7ea7\u548c\u6837\u672c\u7ea7\u68af\u5ea6\u53d1\u6563\u7684\u96c6\u4f53\u6548\u5e94\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8bbe\u5907\u7ea7\u548c\u6837\u672c\u7ea7CGD\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u5206\u7c7b\u95ee\u9898\u7684\u52a0\u6743\u5730\u7403\u79fb\u52a8\u8ddd\u79bb\uff08WEMD\uff09\uff0c\u5e76\u63d0\u51faFedCGD\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFedCGD\u5728\u51cf\u5c11\u8c03\u5ea6\u8bbe\u5907\u6570\u91cf\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86CIFAR-10\u6570\u636e\u96c6\u5206\u7c7b\u51c6\u786e\u73874.2%\u3002", "conclusion": "\u591a\u7ea7CGD\u4f18\u5316\u80fd\u6709\u6548\u63d0\u5347FL\u6027\u80fd\uff0cFedCGD\u7b97\u6cd5\u5728\u5b9e\u9645\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.07945", "pdf": "https://arxiv.org/pdf/2506.07945", "abs": "https://arxiv.org/abs/2506.07945", "authors": ["Arnav Sheth", "Ivaxi Sheth", "Mario Fritz"], "title": "ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols", "categories": ["cs.AR", "cs.AI", "cs.CL"], "comment": "Accepted at MLSysArch@ISCA 2025", "summary": "Recent advances in Large Language Models (LLMs) have shown promising\ncapabilities in generating code for general-purpose programming languages. In\ncontrast, their applicability for hardware description languages, particularly\nfor generating synthesizable and functionally correct designs, remains\nsignificantly underexplored. HDLs such as SystemVerilog are logic-oriented and\ndemand strict adherence to timing semantics, concurrency, and synthesizability\nconstraints. Moreover, HDL-based design flows encompass a broad set of tasks\nbeyond structural code generation, including testbench development,\nassertion-based verification, timing closure, and protocol-level integration\nfor on-chip communication. The objective of our paper is to analyze the\ncapabilities of state-of-the-art LLMs in generating SystemVerilog\nimplementations of standard communication protocols, a core component of\nembedded and System-on-Chip (SoC) architectures. This paper introduces the\nfirst benchmark suite targeting four widely used protocols: SPI, I2C, UART, and\nAXI. We define code generation tasks that capture varying levels of design\nabstraction and prompt specificity. The generated designs are assessed for\nsyntactic correctness, synthesizability, and functional fidelity via waveform\nsimulation and test benches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u751f\u6210\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\uff08HDL\uff09\u5982SystemVerilog\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u6807\u51c6\u901a\u4fe1\u534f\u8bae\u7684\u5b9e\u73b0\u3002", "motivation": "\u76ee\u524dLLMs\u5728\u901a\u7528\u7f16\u7a0b\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728HDL\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u751f\u6210\u53ef\u7efc\u5408\u4e14\u529f\u80fd\u6b63\u786e\u7684\u8bbe\u8ba1\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9SPI\u3001I2C\u3001UART\u548cAXI\u56db\u79cd\u5e7f\u6cdb\u4f7f\u7528\u534f\u8bae\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e0d\u540c\u8bbe\u8ba1\u62bd\u8c61\u6c34\u5e73\u548c\u63d0\u793a\u5177\u4f53\u6027\u7684\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u3002", "result": "\u751f\u6210\u7684\u4ee3\u7801\u901a\u8fc7\u6ce2\u5f62\u4eff\u771f\u548c\u6d4b\u8bd5\u53f0\u8bc4\u4f30\u4e86\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u53ef\u7efc\u5408\u6027\u548c\u529f\u80fd\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86LLMs\u5728HDL\u9886\u57df\u5e94\u7528\u7684\u7a7a\u767d\uff0c\u4e3a\u751f\u6210\u53ef\u7efc\u5408\u548c\u529f\u80fd\u6b63\u786e\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u5206\u6790\u3002"}}
{"id": "2506.07863", "pdf": "https://arxiv.org/pdf/2506.07863", "abs": "https://arxiv.org/abs/2506.07863", "authors": ["Lev Novitskiy", "Viacheslav Vasilev", "Maria Kovaleva", "Vladimir Arkhipkin", "Denis Dimitrov"], "title": "VIVAT: Virtuous Improving VAE Training through Artifact Mitigation", "categories": ["cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "Variational Autoencoders (VAEs) remain a cornerstone of generative computer\nvision, yet their training is often plagued by artifacts that degrade\nreconstruction and generation quality. This paper introduces VIVAT, a\nsystematic approach to mitigating common artifacts in KL-VAE training without\nrequiring radical architectural changes. We present a detailed taxonomy of five\nprevalent artifacts - color shift, grid patterns, blur, corner and droplet\nartifacts - and analyze their root causes. Through straightforward\nmodifications, including adjustments to loss weights, padding strategies, and\nthe integration of Spatially Conditional Normalization, we demonstrate\nsignificant improvements in VAE performance. Our method achieves\nstate-of-the-art results in image reconstruction metrics (PSNR and SSIM) across\nmultiple benchmarks and enhances text-to-image generation quality, as evidenced\nby superior CLIP scores. By preserving the simplicity of the KL-VAE framework\nwhile addressing its practical challenges, VIVAT offers actionable insights for\nresearchers and practitioners aiming to optimize VAE training.", "AI": {"tldr": "VIVAT\u901a\u8fc7\u7b80\u5355\u8c03\u6574\uff08\u5982\u635f\u5931\u6743\u91cd\u3001\u586b\u5145\u7b56\u7565\u548c\u7a7a\u95f4\u6761\u4ef6\u5f52\u4e00\u5316\uff09\u6709\u6548\u89e3\u51b3KL-VAE\u8bad\u7ec3\u4e2d\u7684\u5e38\u89c1\u4f2a\u5f71\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u56fe\u50cf\u91cd\u5efa\u548c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "VAE\u8bad\u7ec3\u4e2d\u5e38\u89c1\u7684\u4f2a\u5f71\u95ee\u9898\uff08\u5982\u989c\u8272\u504f\u79fb\u3001\u7f51\u683c\u6a21\u5f0f\u7b49\uff09\u5f71\u54cd\u4e86\u91cd\u5efa\u548c\u751f\u6210\u8d28\u91cf\uff0cVIVAT\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u6027\u6539\u8fdb\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u800c\u4e0d\u6539\u53d8\u57fa\u7840\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u4e94\u79cd\u5e38\u89c1\u4f2a\u5f71\u7684\u5206\u7c7b\u548c\u6839\u6e90\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u8c03\u6574\u635f\u5931\u6743\u91cd\u3001\u4f18\u5316\u586b\u5145\u7b56\u7565\u53ca\u5f15\u5165\u7a7a\u95f4\u6761\u4ef6\u5f52\u4e00\u5316\u7b49\u7b80\u5355\u4fee\u6539\u8fdb\u884c\u6539\u8fdb\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPSNR\u548cSSIM\u6307\u6807\u8fbe\u5230\u6700\u4f18\uff0c\u4e14\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684CLIP\u5206\u6570\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "VIVAT\u5728\u4fdd\u6301KL-VAE\u6846\u67b6\u7b80\u6d01\u6027\u7684\u540c\u65f6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8bad\u7ec3\u4e2d\u7684\u5b9e\u9645\u95ee\u9898\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2506.07558", "pdf": "https://arxiv.org/pdf/2506.07558", "abs": "https://arxiv.org/abs/2506.07558", "authors": ["Fabian Lander", "Diaaeldin Taha"], "title": "Immersive Visualization of Flat Surfaces Using Ray Marching", "categories": ["cs.GR", "math.DG", "math.DS", "math.GT", "68U05, 51M20", "I.3.7; I.3.5"], "comment": "Presented at Bridges Math and Art Conference, Eindhoven 2025. Online\n  demo and code available at\n  https://fabianlander.github.io/apps/raymarchingflatsurfacesapp/ and\n  https://github.com/FabianLander/RayMarchingFlatSurfaces", "summary": "We present an effective method for visualizing flat surfaces using ray\nmarching. Our approach provides an intuitive way to explore translation\nsurfaces, mirror rooms, unfolded polyhedra, and translation prisms while\nmaintaining computational efficiency. We demonstrate the utility of the method\nthrough various examples and provide implementation insights for programmers.\nFinally, we discuss the use of our visualizations in outreach. We make our\nsimulations and code available online.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5149\u7ebf\u884c\u8fdb\u7684\u9ad8\u6548\u5e73\u5766\u8868\u9762\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u7ffb\u8bd1\u8868\u9762\u3001\u955c\u9762\u623f\u95f4\u3001\u5c55\u5f00\u591a\u9762\u4f53\u548c\u7ffb\u8bd1\u68f1\u955c\uff0c\u5e76\u63d0\u4f9b\u5b9e\u73b0\u7ec6\u8282\u548c\u793a\u4f8b\u3002", "motivation": "\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u76f4\u89c2\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u63a2\u7d22\u4e0d\u540c\u7c7b\u578b\u7684\u5e73\u5766\u8868\u9762\uff0c\u5e76\u4e3a\u7a0b\u5e8f\u5458\u63d0\u4f9b\u5b9e\u73b0\u53c2\u8003\u3002", "method": "\u91c7\u7528\u5149\u7ebf\u884c\u8fdb\u6280\u672f\u8fdb\u884c\u5e73\u5766\u8868\u9762\u7684\u53ef\u89c6\u5316\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u51e0\u4f55\u7ed3\u6784\uff0c\u5305\u62ec\u7ffb\u8bd1\u8868\u9762\u548c\u5c55\u5f00\u591a\u9762\u4f53\u7b49\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u793a\u4f8b\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u63d0\u4f9b\u4e86\u5728\u7ebf\u53ef\u7528\u7684\u4ee3\u7801\u548c\u6a21\u62df\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u5b66\u672f\u548c\u7814\u7a76\u9886\u57df\uff0c\u8fd8\u53ef\u7528\u4e8e\u79d1\u666e\u63a8\u5e7f\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.07503", "pdf": "https://arxiv.org/pdf/2506.07503", "abs": "https://arxiv.org/abs/2506.07503", "authors": ["Honglin Shu", "Michael Fu", "Junji Yu", "Dong Wang", "Chakkrit Tantithamthavorn", "Junjie Chen", "Yasutaka Kamei"], "title": "Large Language Models for Multilingual Vulnerability Detection: How Far Are We?", "categories": ["cs.SE"], "comment": "33 pages, 9 figures", "summary": "Various deep learning-based approaches utilizing pre-trained language models\n(PLMs) have been proposed for automated vulnerability detection. With recent\nadvancements in large language models (LLMs), several studies have begun\nexploring their application to vulnerability detection tasks. However, existing\nstudies primarily focus on specific programming languages (e.g., C/C++) and\nfunction-level detection, leaving the strengths and weaknesses of PLMs and LLMs\nin multilingual and multi-granularity scenarios largely unexplored. To bridge\nthis gap, we conduct a comprehensive fine-grained empirical study evaluating\nthe effectiveness of state-of-the-art PLMs and LLMs for multilingual\nvulnerability detection. Using over 30,000 real-world vulnerability-fixing\npatches across seven programming languages, we systematically assess model\nperformance at both the function-level and line-level. Our key findings\nindicate that GPT-4o, enhanced through instruction tuning and few-shot\nprompting, significantly outperforms all other evaluated models, including\nCodeT5P. Furthermore, the LLM-based approach demonstrates superior capability\nin detecting unique multilingual vulnerabilities, particularly excelling in\nidentifying the most dangerous and high-severity vulnerabilities. These results\nunderscore the promising potential of adopting LLMs for multilingual\nvulnerability detection at function-level and line-level, revealing their\ncomplementary strengths and substantial improvements over PLM approaches. This\nfirst empirical evaluation of PLMs and LLMs for multilingual vulnerability\ndetection highlights LLMs' value in addressing real-world software security\nchallenges.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u4e86\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLMs\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u8bed\u8a00\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0GPT-4o\u5728\u591a\u8bed\u8a00\u548c\u7ec6\u7c92\u5ea6\u573a\u666f\u4e2d\u8868\u73b0\u6700\u4f18\u3002", "motivation": "\u5c3d\u7ba1PLMs\u548cLLMs\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u6709\u6240\u5e94\u7528\uff0c\u4f46\u5176\u5728\u591a\u8bed\u8a00\u548c\u591a\u7c92\u5ea6\u573a\u666f\u4e2d\u7684\u8868\u73b0\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u5229\u752830,000\u591a\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u4fee\u590d\u8865\u4e01\uff0c\u5bf9\u4e03\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u51fd\u6570\u7ea7\u548c\u884c\u7ea7\u6f0f\u6d1e\u68c0\u6d4b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "GPT-4o\u5728\u6307\u4ee4\u8c03\u4f18\u548c\u5c11\u6837\u672c\u63d0\u793a\u4e0b\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4e14\u5728\u68c0\u6d4b\u9ad8\u5371\u6f0f\u6d1e\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "LLMs\u5728\u591a\u8bed\u8a00\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u548c\u4f18\u52bf\uff0c\u4e3a\u5b9e\u9645\u8f6f\u4ef6\u5b89\u5168\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07281", "pdf": "https://arxiv.org/pdf/2506.07281", "abs": "https://arxiv.org/abs/2506.07281", "authors": ["Leah Hope Ajmani", "Nuredin Ali Abdelkadir", "Stevie Chancellor"], "title": "Secondary Stakeholders in AI: Fighting for, Brokering, and Navigating Agency", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "As AI technologies become more human-facing, there have been numerous calls\nto adapt participatory approaches to AI development -- spurring the idea of\nparticipatory AI. However, these calls often focus only on primary\nstakeholders, such as end-users, and not secondary stakeholders. This paper\nseeks to translate the ideals of participatory AI to a broader population of\nsecondary AI stakeholders through semi-structured interviews. We theorize that\nmeaningful participation involves three participatory ideals: (1) informedness,\n(2) consent, and (3) agency. We also explore how secondary stakeholders realize\nthese ideals by traversing a complicated problem space. Like walking up the\nrungs of a ladder, these ideals build on one another. We introduce three\nstakeholder archetypes: the reluctant data contributor, the unsupported\nactivist, and the well-intentioned practitioner, who must navigate systemic\nbarriers to achieving agentic AI relationships. We envision an AI future where\nsecondary stakeholders are able to meaningfully participate with the AI systems\nthey influence and are influenced by.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u5c06\u53c2\u4e0e\u5f0fAI\u7406\u5ff5\u6269\u5c55\u81f3\u6b21\u8981\u5229\u76ca\u76f8\u5173\u8005\uff0c\u901a\u8fc7\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u63d0\u51fa\u4e09\u4e2a\u53c2\u4e0e\u7406\u60f3\uff1a\u77e5\u60c5\u3001\u540c\u610f\u548c\u80fd\u52a8\u6027\u3002", "motivation": "\u5f53\u524d\u53c2\u4e0e\u5f0fAI\u4e3b\u8981\u5173\u6ce8\u4e3b\u8981\u5229\u76ca\u76f8\u5173\u8005\uff08\u5982\u7ec8\u7aef\u7528\u6237\uff09\uff0c\u5ffd\u89c6\u4e86\u6b21\u8981\u5229\u76ca\u76f8\u5173\u8005\uff0c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u7406\u8bba\u5316\u6b21\u8981\u5229\u76ca\u76f8\u5173\u8005\u7684\u53c2\u4e0e\u7406\u60f3\uff0c\u5e76\u63d0\u51fa\u4e09\u79cd\u5229\u76ca\u76f8\u5173\u8005\u539f\u578b\u3002", "result": "\u63d0\u51fa\u6b21\u8981\u5229\u76ca\u76f8\u5173\u8005\u5b9e\u73b0\u53c2\u4e0e\u7406\u60f3\u7684\u8def\u5f84\uff0c\u5f3a\u8c03\u77e5\u60c5\u3001\u540c\u610f\u548c\u80fd\u52a8\u6027\u7684\u9012\u8fdb\u5173\u7cfb\u3002", "conclusion": "\u7814\u7a76\u547c\u5401\u672a\u6765AI\u53d1\u5c55\u4e2d\uff0c\u6b21\u8981\u5229\u76ca\u76f8\u5173\u8005\u80fd\u6709\u6548\u53c2\u4e0e\u5e76\u5f71\u54cdAI\u7cfb\u7edf\u3002"}}
{"id": "2506.07605", "pdf": "https://arxiv.org/pdf/2506.07605", "abs": "https://arxiv.org/abs/2506.07605", "authors": ["Marco Di Gennaro", "Giovanni De Lucia", "Stefano Longari", "Stefano Zanero", "Michele Carminati"], "title": "TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "Proceedings on Privacy Enhancing Technologies (To appear) 2025(4)", "summary": "Federated Learning has emerged as a privacy-oriented alternative to\ncentralized Machine Learning, enabling collaborative model training without\ndirect data sharing. While extensively studied for neural networks, the\nsecurity and privacy implications of tree-based models remain underexplored.\nThis work introduces TimberStrike, an optimization-based dataset reconstruction\nattack targeting horizontally federated tree-based models. Our attack, carried\nout by a single client, exploits the discrete nature of decision trees by using\nsplit values and decision paths to infer sensitive training data from other\nclients. We evaluate TimberStrike on State-of-the-Art federated gradient\nboosting implementations across multiple frameworks, including Flower, NVFlare,\nand FedTree, demonstrating their vulnerability to privacy breaches. On a\npublicly available stroke prediction dataset, TimberStrike consistently\nreconstructs between 73.05% and 95.63% of the target dataset across all\nimplementations. We further analyze Differential Privacy, showing that while it\npartially mitigates the attack, it also significantly degrades model\nperformance. Our findings highlight the need for privacy-preserving mechanisms\nspecifically designed for tree-based Federated Learning systems, and we provide\npreliminary insights into their design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86TimberStrike\u653b\u51fb\uff0c\u4e00\u79cd\u9488\u5bf9\u57fa\u4e8e\u6811\u7684\u8054\u90a6\u5b66\u4e60\u7684\u4f18\u5316\u6570\u636e\u96c6\u91cd\u6784\u653b\u51fb\uff0c\u8bc1\u660e\u4e86\u73b0\u6709\u7cfb\u7edf\u7684\u9690\u79c1\u6f0f\u6d1e\uff0c\u5e76\u8ba8\u8bba\u4e86\u5dee\u5206\u9690\u79c1\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8e\u6811\u7684\u8054\u90a6\u5b66\u4e60\u6a21\u578b\u5728\u5b89\u5168\u548c\u9690\u79c1\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5355\u4e2a\u5ba2\u6237\u7aef\u5229\u7528\u51b3\u7b56\u6811\u7684\u5206\u88c2\u503c\u548c\u8def\u5f84\u4fe1\u606f\uff0c\u91cd\u6784\u5176\u4ed6\u5ba2\u6237\u7aef\u7684\u654f\u611f\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u5728\u591a\u4e2a\u6846\u67b6\u4e2d\u9a8c\u8bc1\u653b\u51fb\u6548\u679c\u3002", "result": "\u5728\u6240\u6709\u6d4b\u8bd5\u6846\u67b6\u4e2d\uff0cTimberStrike\u80fd\u91cd\u678473.05%\u81f395.63%\u7684\u76ee\u6807\u6570\u636e\u96c6\uff0c\u5dee\u5206\u9690\u79c1\u867d\u80fd\u90e8\u5206\u7f13\u89e3\u653b\u51fb\u4f46\u663e\u8457\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u9700\u4e3a\u57fa\u4e8e\u6811\u7684\u8054\u90a6\u5b66\u4e60\u8bbe\u8ba1\u4e13\u95e8\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u8bba\u6587\u4e3a\u6b64\u63d0\u4f9b\u4e86\u521d\u6b65\u8bbe\u8ba1\u601d\u8def\u3002"}}
{"id": "2506.07957", "pdf": "https://arxiv.org/pdf/2506.07957", "abs": "https://arxiv.org/abs/2506.07957", "authors": ["Mat\u00edas Mazzanti", "Esteban Mocskos", "Augusto Vega", "Pradip Bose"], "title": "Understanding the Error Sensitivity of Privacy-Aware Computing", "categories": ["cs.AR", "cs.CR"], "comment": null, "summary": "Homomorphic Encryption (HE) enables secure computation on encrypted data\nwithout decryption, allowing a great opportunity for privacy-preserving\ncomputation. In particular, domains such as healthcare, finance, and\ngovernment, where data privacy and security are of utmost importance, can\nbenefit from HE by enabling third-party computation and services on sensitive\ndata. In other words, HE constitutes the \"Holy Grail\" of cryptography: data\nremains encrypted all the time, being protected while in use.\n  HE's security guarantees rely on noise added to data to make relatively\nsimple problems computationally intractable. This error-centric intrinsic HE\nmechanism generates new challenges related to the fault tolerance and\nrobustness of HE itself: hardware- and software-induced errors during HE\noperation can easily evade traditional error detection and correction\nmechanisms, resulting in silent data corruption (SDC).\n  In this work, we motivate a thorough discussion regarding the sensitivity of\nHE applications to bit faults and provide a detailed error characterization\nstudy of CKKS (Cheon-Kim-Kim-Song). This is one of the most popular HE schemes\ndue to its fixed-point arithmetic support for AI and machine learning\napplications. We also delve into the impact of the residue number system (RNS)\nand the number theoretic transform (NTT), two widely adopted HE optimization\ntechniques, on CKKS' error sensitivity. To the best of our knowledge, this is\nthe first work that looks into the robustness and error sensitivity of\nhomomorphic encryption and, as such, it can pave the way for critical future\nwork in this area.", "AI": {"tldr": "\u8be5\u6587\u63a2\u8ba8\u4e86\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u5728\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u91cd\u70b9\u5173\u6ce8CKKS\u65b9\u6848\u5bf9\u786c\u4ef6\u548c\u8f6f\u4ef6\u9519\u8bef\u7684\u654f\u611f\u6027\uff0c\u5e76\u7814\u7a76\u4e86\u4f18\u5316\u6280\u672f\u5bf9\u9519\u8bef\u654f\u611f\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u662f\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5bb9\u6613\u53d7\u5230\u786c\u4ef6\u548c\u8f6f\u4ef6\u9519\u8bef\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u6570\u636e\u635f\u574f\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76HE\uff08\u7279\u522b\u662fCKKS\u65b9\u6848\uff09\u7684\u9519\u8bef\u654f\u611f\u6027\uff0c\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8be6\u7ec6\u7814\u7a76CKKS\u65b9\u6848\uff0c\u5206\u6790\u4e86\u5176\u5728\u786c\u4ef6\u548c\u8f6f\u4ef6\u9519\u8bef\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u8ba8\u4e86\u6b8b\u6570\u7cfb\u7edf\uff08RNS\uff09\u548c\u6570\u8bba\u53d8\u6362\uff08NTT\uff09\u5bf9\u9519\u8bef\u654f\u611f\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cCKKS\u65b9\u6848\u5bf9\u4f4d\u9519\u8bef\u7279\u522b\u654f\u611f\uff0c\u4e14\u4f18\u5316\u6280\u672f\uff08\u5982RNS\u548cNTT\uff09\u53ef\u80fd\u8fdb\u4e00\u6b65\u52a0\u5267\u8fd9\u4e00\u95ee\u9898\u3002\u8fd9\u4e3a\u672a\u6765\u63d0\u9ad8HE\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86HE\u7684\u9519\u8bef\u654f\u611f\u6027\uff0c\u63ed\u793a\u4e86\u6f5c\u5728\u7684\u6570\u636e\u635f\u574f\u98ce\u9669\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdbHE\u7684\u7a33\u5065\u6027\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.07657", "pdf": "https://arxiv.org/pdf/2506.07657", "abs": "https://arxiv.org/abs/2506.07657", "authors": ["Zeyu Xiao", "Zhenyi Wu", "Mingyang Sun", "Qipeng Yan", "Yufan Guo", "Zhuoer Liang", "Lihua Zhang"], "title": "PIG: Physically-based Multi-Material Interaction with 3D Gaussians", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D Gaussian Splatting has achieved remarkable success in reconstructing both\nstatic and dynamic 3D scenes. However, in a scene represented by 3D Gaussian\nprimitives, interactions between objects suffer from inaccurate 3D\nsegmentation, imprecise deformation among different materials, and severe\nrendering artifacts. To address these challenges, we introduce PIG:\nPhysically-Based Multi-Material Interaction with 3D Gaussians, a novel approach\nthat combines 3D object segmentation with the simulation of interacting objects\nin high precision. Firstly, our method facilitates fast and accurate mapping\nfrom 2D pixels to 3D Gaussians, enabling precise 3D object-level segmentation.\nSecondly, we assign unique physical properties to correspondingly segmented\nobjects within the scene for multi-material coupled interactions. Finally, we\nhave successfully embedded constraint scales into deformation gradients,\nspecifically clamping the scaling and rotation properties of the Gaussian\nprimitives to eliminate artifacts and achieve geometric fidelity and visual\nconsistency. Experimental results demonstrate that our method not only\noutperforms the state-of-the-art (SOTA) in terms of visual quality, but also\nopens up new directions and pipelines for the field of physically realistic\nscene generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPIG\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u54083D\u5bf9\u8c61\u5206\u5272\u4e0e\u9ad8\u7cbe\u5ea6\u7269\u4f53\u4ea4\u4e92\u6a21\u62df\uff0c\u89e3\u51b3\u4e863D\u9ad8\u65af\u573a\u666f\u4e2d\u7684\u5206\u5272\u4e0d\u51c6\u3001\u53d8\u5f62\u4e0d\u7cbe\u786e\u548c\u6e32\u67d3\u4f2a\u5f71\u95ee\u9898\u3002", "motivation": "\u5f53\u524d3D\u9ad8\u65af\u573a\u666f\u4e2d\u7269\u4f53\u4ea4\u4e92\u5b58\u5728\u5206\u5272\u4e0d\u51c6\u3001\u53d8\u5f62\u4e0d\u7cbe\u786e\u548c\u6e32\u67d3\u4f2a\u5f71\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u591a\u6750\u6599\u4ea4\u4e92\u548c\u7269\u7406\u6a21\u62df\u3002", "method": "\u901a\u8fc7\u4ece2D\u50cf\u7d20\u52303D\u9ad8\u65af\u7684\u5feb\u901f\u51c6\u786e\u6620\u5c04\u5b9e\u73b0\u5206\u5272\uff0c\u4e3a\u5206\u5272\u5bf9\u8c61\u5206\u914d\u7269\u7406\u5c5e\u6027\uff0c\u5e76\u5728\u53d8\u5f62\u68af\u5ea6\u4e2d\u5d4c\u5165\u7ea6\u675f\u5c3a\u5ea6\uff0c\u6d88\u9664\u4f2a\u5f71\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u8d28\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u4e3a\u7269\u7406\u771f\u5b9e\u573a\u666f\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u548c\u6d41\u7a0b\u3002", "conclusion": "PIG\u65b9\u6cd5\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u7269\u7406\u771f\u5b9e\u611f\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4e3a3D\u573a\u666f\u751f\u6210\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.07524", "pdf": "https://arxiv.org/pdf/2506.07524", "abs": "https://arxiv.org/abs/2506.07524", "authors": ["Shiwei Feng", "Xiangzhe Xu", "Xuan Chen", "Kaiyuan Zhang", "Syed Yusuf Ahmed", "Zian Su", "Mingwei Zheng", "Xiangyu Zhang"], "title": "IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents", "categories": ["cs.SE", "cs.AI", "cs.CY"], "comment": null, "summary": "LLM agents are increasingly deployed to automate real-world tasks by invoking\nAPIs through natural language instructions. While powerful, they often suffer\nfrom misinterpretation of user intent, leading to the agent's actions that\ndiverge from the user's intended goal, especially as external toolkits evolve.\nTraditional software testing assumes structured inputs and thus falls short in\nhandling the ambiguity of natural language. We introduce IntenTest, an\nAPI-centric stress testing framework that systematically uncovers intent\nintegrity violations in LLM agents. Unlike prior work focused on fixed\nbenchmarks or adversarial inputs, IntenTest generates realistic tasks based on\ntoolkits' documentation and applies targeted mutations to expose subtle agent\nerrors while preserving user intent. To guide testing, we propose semantic\npartitioning, which organizes natural language tasks into meaningful categories\nbased on toolkit API parameters and their equivalence classes. Within each\npartition, seed tasks are mutated and ranked by a lightweight predictor that\nestimates the likelihood of triggering agent errors. To enhance efficiency,\nIntenTest maintains a datatype-aware strategy memory that retrieves and adapts\neffective mutation patterns from past cases. Experiments on 80 toolkit APIs\ndemonstrate that IntenTest effectively uncovers intent integrity violations,\nsignificantly outperforming baselines in both error-exposing rate and query\nefficiency. Moreover, IntenTest generalizes well to stronger target models\nusing smaller LLMs for test generation, and adapts to evolving APIs across\ndomains.", "AI": {"tldr": "IntenTest\u662f\u4e00\u4e2a\u9488\u5bf9LLM\u4ee3\u7406\u7684API\u538b\u529b\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u751f\u6210\u548c\u53d8\u5f02\u4efb\u52a1\uff0c\u63ed\u793a\u610f\u56fe\u5b8c\u6574\u6027\u8fdd\u89c4\u95ee\u9898\u3002", "motivation": "\u90e8\u7f72LLM\u4ee3\u7406\u65f6\uff0c\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u6a21\u7cca\u6027\u53ef\u80fd\u5bfc\u81f4\u4ee3\u7406\u884c\u4e3a\u504f\u79bb\u7528\u6237\u610f\u56fe\uff0c\u5c24\u5176\u662f\u968f\u7740\u5916\u90e8\u5de5\u5177\u96c6\u7684\u6f14\u53d8\uff0c\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u8fd9\u79cd\u6a21\u7cca\u6027\u3002", "method": "IntenTest\u901a\u8fc7\u5de5\u5177\u6587\u6863\u751f\u6210\u771f\u5b9e\u4efb\u52a1\uff0c\u5e94\u7528\u5b9a\u5411\u53d8\u5f02\uff0c\u5e76\u5229\u7528\u8bed\u4e49\u5206\u533a\u548c\u8f7b\u91cf\u7ea7\u9884\u6d4b\u5668\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u3002", "result": "\u572880\u4e2a\u5de5\u5177API\u7684\u5b9e\u9a8c\u4e2d\uff0cIntenTest\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u66b4\u9732\u9519\u8bef\uff0c\u5e76\u5bf9\u66f4\u5f3a\u7684\u76ee\u6807\u6a21\u578b\u8868\u73b0\u826f\u597d\u3002", "conclusion": "IntenTest\u4e3a\u89e3\u51b3LLM\u4ee3\u7406\u610f\u56fe\u5b8c\u6574\u6027\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u6f14\u53d8\u7684API\u73af\u5883\u3002"}}
{"id": "2506.07389", "pdf": "https://arxiv.org/pdf/2506.07389", "abs": "https://arxiv.org/abs/2506.07389", "authors": ["Guanming Qiao", "Partha Protim Paul"], "title": "Human Side of Smart Contract Fuzzing: An Empirical Study", "categories": ["cs.HC", "cs.SE"], "comment": null, "summary": "Smart contract (SC) fuzzing is a critical technique for detecting\nvulnerabilities in blockchain applications. However, its adoption remains\nchallenging for practitioners due to fundamental differences between SCs and\ntraditional software systems. In this study, we investigate the challenges\npractitioners face when adopting SC fuzzing tools by conducting an inductive\ncontent analysis of 381 GitHub issues from two widely used SC fuzzers: Echidna\nand Foundry. Furthermore, we conducted a user study to examine how these\nchallenges affect different practitioner groups, SC developers, and traditional\nsoftware security professionals, and identify strategies practitioners use to\novercome them. We systematically categorize these challenges into a taxonomy\nbased on their nature and occurrence within the SC fuzzing workflow. Our\nfindings reveal domain-specific ease-of-use and usefulness challenges,\nincluding technical issues with blockchain emulation, and human issues with a\nlack of accessible documentation and process automation. Our results provide\nactionable insights for tool developers and researchers, guiding future\nimprovements in SC fuzzer tool design.", "AI": {"tldr": "\u5206\u6790\u667a\u80fd\u5408\u7ea6\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u5728\u5b9e\u8df5\u4e2d\u9762\u4e34\u7684\u6311\u6218\uff0c\u901a\u8fc7GitHub\u95ee\u9898\u548c\u7528\u6237\u7814\u7a76\u5206\u7c7b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\uff08SC\uff09\u6a21\u7cca\u6d4b\u8bd5\u662f\u68c0\u6d4b\u533a\u5757\u94fe\u5e94\u7528\u4e2d\u6f0f\u6d1e\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5176\u91c7\u7528\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3aSC\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u7cfb\u7edf\u5b58\u5728\u6839\u672c\u6027\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u5206\u6790Echidna\u548cFoundry\u4e24\u4e2aSC\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u7684381\u4e2aGitHub\u95ee\u9898\uff0c\u5e76\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff0c\u5206\u7c7b\u6311\u6218\u5e76\u8bc6\u522b\u89e3\u51b3\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u9886\u57df\u7279\u5b9a\u7684\u6613\u7528\u6027\u548c\u5b9e\u7528\u6027\u6311\u6218\uff0c\u5305\u62ec\u533a\u5757\u94fe\u6a21\u62df\u7684\u6280\u672f\u95ee\u9898\u548c\u6587\u6863\u4e0d\u8db3\u53ca\u81ea\u52a8\u5316\u7f3a\u5931\u7684\u4eba\u4e3a\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5de5\u5177\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6539\u8fdb\u65b9\u5411\uff0c\u6307\u5bfc\u672a\u6765SC\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u7684\u8bbe\u8ba1\u4f18\u5316\u3002"}}
{"id": "2506.07724", "pdf": "https://arxiv.org/pdf/2506.07724", "abs": "https://arxiv.org/abs/2506.07724", "authors": ["Longyun Chen", "Jingcheng Liu", "Penghui Yao"], "title": "Optimal quantum sampling on distributed databases", "categories": ["quant-ph", "cs.DC"], "comment": null, "summary": "Quantum sampling, a fundamental subroutine in numerous quantum algorithms,\ninvolves encoding a given probability distribution in the amplitudes of a pure\nstate. Given the hefty cost of large-scale quantum storage, we initiate the\nstudy of quantum sampling in a distributed setting. Specifically, we assume\nthat the data is distributed among multiple machines, and each machine solely\nmaintains a basic oracle that counts the multiplicity of individual elements.\nGiven a quantum sampling task, which is to sample from the joint database, a\ncoordinator can make oracle queries to all machines. We focus on the oblivious\ncommunication model, where communications between the coordinator and the\nmachines are predetermined. We present both sequential and parallel algorithms:\nthe sequential algorithm queries the machines sequentially, while the parallel\nalgorithm allows the coordinator to query all machines simultaneously.\nFurthermore, we prove that both algorithms are optimal in their respective\nsettings.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u91cf\u5b50\u91c7\u6837\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u987a\u5e8f\u548c\u5e76\u884c\u4e24\u79cd\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6700\u4f18\u6027\u3002", "motivation": "\u7531\u4e8e\u5927\u89c4\u6a21\u91cf\u5b50\u5b58\u50a8\u7684\u9ad8\u6210\u672c\uff0c\u7814\u7a76\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u7684\u91cf\u5b50\u91c7\u6837\u95ee\u9898\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5728\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e2d\uff0c\u6570\u636e\u5206\u5e03\u5728\u591a\u53f0\u673a\u5668\u4e0a\uff0c\u6bcf\u53f0\u673a\u5668\u7ef4\u62a4\u4e00\u4e2a\u57fa\u672c\u7684oracle\uff1b\u63d0\u51fa\u4e86\u987a\u5e8f\u548c\u5e76\u884c\u4e24\u79cd\u7b97\u6cd5\uff0c\u5206\u522b\u901a\u8fc7\u987a\u5e8f\u6216\u540c\u65f6\u67e5\u8be2\u673a\u5668\u6765\u5b9e\u73b0\u91c7\u6837\u3002", "result": "\u63d0\u51fa\u7684\u987a\u5e8f\u548c\u5e76\u884c\u7b97\u6cd5\u5728\u5404\u81ea\u8bbe\u7f6e\u4e0b\u5747\u88ab\u8bc1\u660e\u4e3a\u6700\u4f18\u3002", "conclusion": "\u5206\u5e03\u5f0f\u91cf\u5b50\u91c7\u6837\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u987a\u5e8f\u548c\u5e76\u884c\u7b97\u6cd5\u9ad8\u6548\u89e3\u51b3\uff0c\u4e14\u7b97\u6cd5\u5728\u5404\u81ea\u573a\u666f\u4e0b\u662f\u6700\u4f18\u7684\u3002"}}
{"id": "2506.06505", "pdf": "https://arxiv.org/pdf/2506.06505", "abs": "https://arxiv.org/abs/2506.06505", "authors": ["Keisuke Sugiura", "Hiroki Matsutani"], "title": "InstantFT: An FPGA-Based Runtime Subsecond Fine-tuning of CNN Models", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Training deep neural networks (DNNs) requires significantly more computation\nand memory than inference, making runtime adaptation of DNNs challenging on\nresource-limited IoT platforms. We propose InstantFT, an FPGA-based method for\nultra-fast CNN fine-tuning on IoT devices, by optimizing the forward and\nbackward computations in parameter-efficient fine-tuning (PEFT). Experiments on\ndatasets with concept drift demonstrate that InstantFT fine-tunes a pre-trained\nCNN 17.4x faster than existing Low-Rank Adaptation (LoRA)-based approaches,\nwhile achieving comparable accuracy. Our FPGA-based InstantFT reduces the\nfine-tuning time to just 0.36s and improves energy-efficiency by 16.3x,\nenabling on-the-fly adaptation of CNNs to non-stationary data distributions.", "AI": {"tldr": "InstantFT\u662f\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u8d85\u5febCNN\u5fae\u8c03\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u80fd\u6e90\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8d44\u6e90\u6709\u9650\u7684\u7269\u8054\u7f51\u5e73\u53f0\u4e0a\u8fd0\u884c\u65f6\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u4e2d\u7684\u524d\u5411\u548c\u53cd\u5411\u8ba1\u7b97\uff0c\u63d0\u51faInstantFT\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cInstantFT\u6bd4\u73b0\u6709\u7684\u57fa\u4e8eLoRA\u7684\u65b9\u6cd5\u5feb17.4\u500d\uff0c\u80fd\u8017\u964d\u4f4e16.3\u500d\uff0c\u4e14\u51c6\u786e\u7387\u76f8\u5f53\u3002", "conclusion": "InstantFT\u80fd\u591f\u5feb\u901f\u9002\u5e94\u975e\u5e73\u7a33\u6570\u636e\u5206\u5e03\uff0c\u9002\u7528\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5b9e\u65f6\u9700\u6c42\u3002"}}
{"id": "2506.07897", "pdf": "https://arxiv.org/pdf/2506.07897", "abs": "https://arxiv.org/abs/2506.07897", "authors": ["Shuja Khalid", "Mohamed Ibrahim", "Yang Liu"], "title": "GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "We present a novel approach for enhancing the resolution and geometric\nfidelity of 3D Gaussian Splatting (3DGS) beyond native training resolution.\nCurrent 3DGS methods are fundamentally limited by their input resolution,\nproducing reconstructions that cannot extrapolate finer details than are\npresent in the training views. Our work breaks this limitation through a\nlightweight generative model that predicts and refines additional 3D Gaussians\nwhere needed most. The key innovation is our Hessian-assisted sampling\nstrategy, which intelligently identifies regions that are likely to benefit\nfrom densification, ensuring computational efficiency. Unlike computationally\nintensive GANs or diffusion approaches, our method operates in real-time\n(0.015s per inference on a single consumer-grade GPU), making it practical for\ninteractive applications. Comprehensive experiments demonstrate significant\nimprovements in both geometric accuracy and rendering quality compared to\nstate-of-the-art methods, establishing a new paradigm for resolution-free 3D\nscene enhancement.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u751f\u6210\u6a21\u578b\u548cHessian\u8f85\u52a9\u91c7\u6837\u7b56\u7565\uff0c\u63d0\u53473D\u9ad8\u65af\u6cfc\u6e85\u7684\u5206\u8fa8\u7387\u548c\u51e0\u4f55\u4fdd\u771f\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u67093DGS\u65b9\u6cd5\u53d7\u9650\u4e8e\u8f93\u5165\u5206\u8fa8\u7387\uff0c\u65e0\u6cd5\u751f\u6210\u6bd4\u8bad\u7ec3\u89c6\u56fe\u66f4\u7cbe\u7ec6\u7684\u7ec6\u8282\uff0c\u56e0\u6b64\u9700\u8981\u7a81\u7834\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u751f\u6210\u6a21\u578b\u9884\u6d4b\u548c\u7ec6\u5316\u989d\u5916\u76843D\u9ad8\u65af\u70b9\uff0c\u5e76\u7ed3\u5408Hessian\u8f85\u52a9\u91c7\u6837\u7b56\u7565\u667a\u80fd\u8bc6\u522b\u9700\u8981\u5bc6\u96c6\u5316\u7684\u533a\u57df\u3002", "result": "\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\uff08\u5355\u6d88\u8d39\u7ea7GPU\u4e0a\u6bcf\u63a8\u74060.015\u79d2\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51e0\u4f55\u7cbe\u5ea6\u548c\u6e32\u67d3\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5206\u8fa8\u7387\u9650\u5236\u76843D\u573a\u666f\u589e\u5f3a\u65b0\u8303\u5f0f\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u4ea4\u4e92\u5e94\u7528\u3002"}}
{"id": "2506.07594", "pdf": "https://arxiv.org/pdf/2506.07594", "abs": "https://arxiv.org/abs/2506.07594", "authors": ["E. G. Santana Jr", "Jander Pereira Santos Junior", "Erlon P. Almeida", "Iftekhar Ahmed", "Paulo Anselmo da Mota Silveira Neto", "Eduardo Santana de Almeida"], "title": "Evaluating LLMs Effectiveness in Detecting and Correcting Test Smells: An Empirical Study", "categories": ["cs.SE"], "comment": null, "summary": "Test smells indicate poor development practices in test code, reducing\nmaintainability and reliability. While developers often struggle to prevent or\nrefactor these issues, existing tools focus primarily on detection rather than\nautomated refactoring. Large Language Models (LLMs) have shown strong potential\nin code understanding and transformation, but their ability to both identify\nand refactor test smells remains underexplored. We evaluated GPT-4-Turbo, LLaMA\n3 70B, and Gemini-1.5 Pro on Python and Java test suites, using PyNose and\nTsDetect for initial smell detection, followed by LLM-driven refactoring.\nGemini achieved the highest detection accuracy (74.35\\% Python, 80.32\\% Java),\nwhile LLaMA was lowest. All models could refactor smells, but effectiveness\nvaried, sometimes introducing new smells. Gemini also improved test coverage,\nunlike GPT-4 and LLaMA, which often reduced it. These results highlight LLMs'\npotential for automated test smell refactoring, with Gemini as the strongest\nperformer, though challenges remain across languages and smell types.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8bc6\u522b\u548c\u91cd\u6784\u6d4b\u8bd5\u4ee3\u7801\u4e2d\u7684\u574f\u5473\u9053\uff08test smells\uff09\u65b9\u9762\u7684\u80fd\u529b\uff0c\u8bc4\u4f30\u4e86GPT-4-Turbo\u3001LLaMA 3 70B\u548cGemini-1.5 Pro\u7684\u8868\u73b0\uff0c\u53d1\u73b0Gemini\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u6d4b\u8bd5\u4ee3\u7801\u4e2d\u7684\u574f\u5473\u9053\u964d\u4f4e\u4e86\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u4e3b\u8981\u96c6\u4e2d\u4e8e\u68c0\u6d4b\u800c\u975e\u81ea\u52a8\u91cd\u6784\u3002LLM\u5728\u4ee3\u7801\u7406\u89e3\u548c\u8f6c\u6362\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u6d4b\u8bd5\u574f\u5473\u9053\u5904\u7406\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528PyNose\u548cTsDetect\u68c0\u6d4bPython\u548cJava\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u7684\u574f\u5473\u9053\uff0c\u968f\u540e\u5229\u7528GPT-4-Turbo\u3001LLaMA 3 70B\u548cGemini-1.5 Pro\u8fdb\u884c\u91cd\u6784\u3002", "result": "Gemini\u5728\u68c0\u6d4b\u548c\u91cd\u6784\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u6700\u9ad8\uff08Python 74.35%\uff0cJava 80.32%\uff09\uff0c\u5e76\u80fd\u63d0\u9ad8\u6d4b\u8bd5\u8986\u76d6\u7387\uff1b\u800cGPT-4\u548cLLaMA\u5219\u53ef\u80fd\u964d\u4f4e\u8986\u76d6\u7387\u6216\u5f15\u5165\u65b0\u574f\u5473\u9053\u3002", "conclusion": "LLM\u5728\u81ea\u52a8\u5316\u6d4b\u8bd5\u574f\u5473\u9053\u91cd\u6784\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662fGemini\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u4e0d\u540c\u8bed\u8a00\u548c\u574f\u5473\u9053\u7c7b\u578b\u7684\u5904\u7406\u4ecd\u5b58\u5728\u6311\u6218\u3002"}}
{"id": "2506.07393", "pdf": "https://arxiv.org/pdf/2506.07393", "abs": "https://arxiv.org/abs/2506.07393", "authors": ["Anna Yokokubo", "Takeo Hamada", "Tatsuya Ishizuka", "Hiroaki Mori", "Noboru Koshizuka"], "title": "Happiness Finder: Exploring the Role of AI in Enhancing Well-Being During Four-Leaf Clover Searches", "categories": ["cs.HC"], "comment": null, "summary": "A four-leaf clover (FLC) symbolizes luck and happiness worldwide, but it is\nhard to distinguish it from the common three-leaf clover. While AI technology\ncan assist in searching for FLC, it may not replicate the traditional search's\nsense of achievement. This study explores searcher feelings when AI aids the\nFLC search. In this study, we developed a system called ``Happiness Finder''\nthat uses object detection algorithms on smartphones or tablets to support the\nsearch. We exhibited HappinessFinder at an international workshop, allowing\nparticipants to experience four-leaf clover searching using potted artificial\nclovers and the HappinessFinder app. This paper reports the findings from this\ndemonstration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528AI\u8f85\u52a9\u5bfb\u627e\u56db\u53f6\u8349\u7684\u4f53\u9a8c\uff0c\u5f00\u53d1\u4e86\u540d\u4e3a'HappinessFinder'\u7684App\uff0c\u5e76\u5728\u5de5\u4f5c\u574a\u4e2d\u5c55\u793a\u4e86\u5176\u6548\u679c\u3002", "motivation": "\u56db\u53f6\u8349\u8c61\u5f81\u5e78\u8fd0\uff0c\u4f46\u4f20\u7edf\u641c\u7d22\u7684\u6210\u5c31\u611f\u53ef\u80fd\u88abAI\u66ff\u4ee3\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u8f85\u52a9\u641c\u7d22\u65f6\u7684\u7528\u6237\u611f\u53d7\u3002", "method": "\u5f00\u53d1'HappinessFinder'\u7cfb\u7edf\uff0c\u5229\u7528\u667a\u80fd\u624b\u673a\u7684\u7269\u4f53\u68c0\u6d4b\u7b97\u6cd5\u8f85\u52a9\u641c\u7d22\uff0c\u5e76\u5728\u5de5\u4f5c\u574a\u4e2d\u901a\u8fc7\u4eba\u5de5\u76c6\u683d\u5c55\u793a\u6548\u679c\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86AI\u8f85\u52a9\u56db\u53f6\u8349\u641c\u7d22\u7684\u5b9e\u9645\u5e94\u7528\u548c\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "AI\u8f85\u52a9\u5de5\u5177\u867d\u80fd\u63d0\u5347\u6548\u7387\uff0c\u4f46\u9700\u5e73\u8861\u6280\u672f\u4fbf\u5229\u4e0e\u4f20\u7edf\u4f53\u9a8c\u7684\u6210\u5c31\u611f\u3002"}}
{"id": "2506.06787", "pdf": "https://arxiv.org/pdf/2506.06787", "abs": "https://arxiv.org/abs/2506.06787", "authors": ["Qiyun Zhao"], "title": "FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "As integrated circuit scale grows and design complexity rises, effective\ncircuit representation helps support logic synthesis, formal verification, and\nother automated processes in electronic design automation. And-Inverter Graphs\n(AIGs), as a compact and canonical structure, are widely adopted for\nrepresenting Boolean logic in these workflows. However, the increasing\ncomplexity and integration density of modern circuits introduce structural\nheterogeneity and global logic information loss in AIGs, posing significant\nchallenges to accurate circuit modeling. To address these issues, we propose\nFuncGNN, which integrates hybrid feature aggregation to extract\nmulti-granularity topological patterns, thereby mitigating structural\nheterogeneity and enhancing logic circuit representations. FuncGNN further\nintroduces gate-aware normalization that adapts to circuit-specific gate\ndistributions, improving robustness to structural heterogeneity. Finally,\nFuncGNN employs multi-layer integration to merge intermediate features across\nlayers, effectively synthesizing local and global semantic information for\ncomprehensive logic representations. Experimental results on two logic-level\nanalysis tasks (i.e., signal probability prediction and truth-table distance\nprediction) demonstrate that FuncGNN outperforms existing state-of-the-art\nmethods, achieving improvements of 2.06% and 18.71%, respectively, while\nreducing training time by approximately 50.6% and GPU memory usage by about\n32.8%.", "AI": {"tldr": "FuncGNN\u901a\u8fc7\u6df7\u5408\u7279\u5f81\u805a\u5408\u3001\u95e8\u611f\u77e5\u5f52\u4e00\u5316\u548c\u591a\u5c42\u96c6\u6210\u6280\u672f\uff0c\u89e3\u51b3\u7535\u8def\u8bbe\u8ba1\u4e2dAIG\u7684\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u5168\u5c40\u903b\u8f91\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u903b\u8f91\u7535\u8def\u8868\u793a\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u7535\u8def\u590d\u6742\u5ea6\u548c\u96c6\u6210\u5bc6\u5ea6\u589e\u52a0\uff0c\u5bfc\u81f4AIG\u5728\u8868\u793a\u5e03\u5c14\u903b\u8f91\u65f6\u51fa\u73b0\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u5168\u5c40\u903b\u8f91\u4fe1\u606f\u4e22\u5931\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u7535\u8def\u8868\u793a\u65b9\u6cd5\u3002", "method": "FuncGNN\u91c7\u7528\u6df7\u5408\u7279\u5f81\u63d0\u53d6\u591a\u7c92\u5ea6\u62d3\u6251\u6a21\u5f0f\uff0c\u95e8\u611f\u77e5\u5f52\u4e00\u5316\u9002\u5e94\u7279\u5b9a\u95e8\u5206\u5e03\uff0c\u591a\u5c42\u96c6\u6210\u878d\u5408\u5c40\u90e8\u548c\u5168\u5c40\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u5728\u4fe1\u53f7\u6982\u7387\u9884\u6d4b\u548c\u771f\u503c\u8868\u8ddd\u79bb\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cFuncGNN\u6027\u80fd\u63d0\u53472.06%\u548c18.71%\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1150.6%\uff0cGPU\u5185\u5b58\u4f7f\u7528\u964d\u4f4e32.8%\u3002", "conclusion": "FuncGNN\u5728\u89e3\u51b3\u7535\u8def\u8868\u793a\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u662f\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u9886\u57df\u7684\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2506.07917", "pdf": "https://arxiv.org/pdf/2506.07917", "abs": "https://arxiv.org/abs/2506.07917", "authors": ["Allen Tu", "Haiyang Ying", "Alex Hanson", "Yonghan Lee", "Tom Goldstein", "Matthias Zwicker"], "title": "Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes", "categories": ["cs.GR", "cs.CV"], "comment": "Project Page: https://speede3dgs.github.io/", "summary": "Recent extensions of 3D Gaussian Splatting (3DGS) to dynamic scenes achieve\nhigh-quality novel view synthesis by using neural networks to predict the\ntime-varying deformation of each Gaussian. However, performing per-Gaussian\nneural inference at every frame poses a significant bottleneck, limiting\nrendering speed and increasing memory and compute requirements. In this paper,\nwe present Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS), a general\npipeline for accelerating the rendering speed of dynamic 3DGS and 4DGS\nrepresentations by reducing neural inference through two complementary\ntechniques. First, we propose a temporal sensitivity pruning score that\nidentifies and removes Gaussians with low contribution to the dynamic scene\nreconstruction. We also introduce an annealing smooth pruning mechanism that\nimproves pruning robustness in real-world scenes with imprecise camera poses.\nSecond, we propose GroupFlow, a motion analysis technique that clusters\nGaussians by trajectory similarity and predicts a single rigid transformation\nper group instead of separate deformations for each Gaussian. Together, our\ntechniques accelerate rendering by $10.37\\times$, reduce model size by\n$7.71\\times$, and shorten training time by $2.71\\times$ on the NeRF-DS dataset.\nSpeeDe3DGS also improves rendering speed by $4.20\\times$ and $58.23\\times$ on\nthe D-NeRF and HyperNeRF vrig datasets. Our methods are modular and can be\nintegrated into any deformable 3DGS or 4DGS framework.", "AI": {"tldr": "SpeeDe3DGS\u901a\u8fc7\u4e24\u79cd\u4e92\u8865\u6280\u672f\uff08\u65f6\u95f4\u654f\u611f\u5ea6\u526a\u679d\u548cGroupFlow\u8fd0\u52a8\u5206\u6790\uff09\u52a0\u901f\u52a8\u60013D\u9ad8\u65af\u6e85\u5c04\u6e32\u67d3\uff0c\u63d0\u5347\u901f\u5ea610.37\u500d\uff0c\u6a21\u578b\u7f29\u5c0f7.71\u500d\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c112.71\u500d\u3002", "motivation": "\u52a8\u6001\u573a\u666f\u76843D\u9ad8\u65af\u6e85\u5c04\u6e32\u67d3\u56e0\u9010\u9ad8\u65af\u795e\u7ecf\u63a8\u7406\u5bfc\u81f4\u6e32\u67d3\u901f\u5ea6\u6162\u3001\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u9700\u8981\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u65f6\u95f4\u654f\u611f\u5ea6\u526a\u679d\u548cGroupFlow\u8fd0\u52a8\u5206\u6790\u6280\u672f\uff0c\u5206\u522b\u51cf\u5c11\u9ad8\u65af\u6570\u91cf\u548c\u9884\u6d4b\u5355\u4e00\u521a\u6027\u53d8\u6362\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u6e32\u67d3\u901f\u5ea6\u3001\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\u5e76\u7f29\u77ed\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "SpeeDe3DGS\u6a21\u5757\u5316\u8bbe\u8ba1\u53ef\u96c6\u6210\u5230\u4efb\u4f55\u52a8\u60013DGS\u6846\u67b6\u4e2d\uff0c\u9ad8\u6548\u89e3\u51b3\u6e32\u67d3\u74f6\u9888\u3002"}}
{"id": "2506.07683", "pdf": "https://arxiv.org/pdf/2506.07683", "abs": "https://arxiv.org/abs/2506.07683", "authors": ["Alexander Bakhtin", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Leveraging Network Methods for Hub-like Microservice Detection", "categories": ["cs.SE", "cs.DM"], "comment": null, "summary": "Context: Microservice Architecture is a popular architectural paradigm that\nfacilitates flexibility by decomposing applications into small, independently\ndeployable services. Catalogs of architectural anti-patterns have been proposed\nto highlight the negative aspects of flawed microservice design. In particular,\nthe Hub-like anti-pattern lacks an unambiguous definition and detection method.\nAim: In this work, we aim to find a robust detection approach for the Hub-like\nmicroservice anti-pattern that outputs a reasonable number of Hub-like\ncandidates with high precision. Method: We leveraged a dataset of 25\nmicroservice networks and several network hub detection techniques to identify\nthe Hub-like anti-pattern, namely scale-free property, centrality metrics and\nclustering coefficient, minimum description length principle, and the approach\nbehind the Arcan tool. Results and Conclusion: Our findings revealed that the\nstudied architectural networks are not scale-free, that most considered hub\ndetection approaches do not agree on the detected hubs, and that the method by\nKirkley leveraging the Erdos-Renyi encoding is the most accurate one in terms\nof the number of detected hubs and the detection precision. Investigating\nfurther the applicability of these methods to detecting Hub-like components in\nmicroservice-based and other systems opens up new research directions.\nMoreover, our results provide an evaluation of the approach utilized by the\nwidely used Arcan tool and highlight the potential to update the tool to use\nthe normalized degree centrality of a component in the network, or for the\napproach based on ER encoding to be adopted instead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u68c0\u6d4b\u5fae\u670d\u52a1\u67b6\u6784\u4e2dHub-like\u53cd\u6a21\u5f0f\u7684\u7a33\u5065\u65b9\u6cd5\uff0c\u5e76\u6bd4\u8f83\u4e86\u591a\u79cd\u7f51\u7edc\u4e2d\u5fc3\u68c0\u6d4b\u6280\u672f\u7684\u6548\u679c\u3002", "motivation": "\u7531\u4e8eHub-like\u53cd\u6a21\u5f0f\u7f3a\u4e4f\u660e\u786e\u7684\u5b9a\u4e49\u548c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7814\u7a76\u65e8\u5728\u627e\u5230\u4e00\u79cd\u9ad8\u7cbe\u5ea6\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5229\u752825\u4e2a\u5fae\u670d\u52a1\u7f51\u7edc\u6570\u636e\u96c6\uff0c\u91c7\u7528\u591a\u79cd\u7f51\u7edc\u4e2d\u5fc3\u68c0\u6d4b\u6280\u672f\uff08\u5982\u65e0\u6807\u5ea6\u5c5e\u6027\u3001\u4e2d\u5fc3\u6027\u5ea6\u91cf\u7b49\uff09\u8fdb\u884c\u8bc6\u522b\u3002", "result": "\u53d1\u73b0\u7814\u7a76\u7684\u7f51\u7edc\u4e0d\u5177\u5907\u65e0\u6807\u5ea6\u7279\u6027\uff0c\u591a\u6570\u65b9\u6cd5\u5728\u68c0\u6d4b\u4e2d\u5fc3\u70b9\u65f6\u4e0d\u4e00\u81f4\uff0cKirkley\u7684ER\u7f16\u7801\u65b9\u6cd5\u6700\u51c6\u786e\u3002", "conclusion": "\u7814\u7a76\u4e3aArcan\u5de5\u5177\u63d0\u4f9b\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.07707", "pdf": "https://arxiv.org/pdf/2506.07707", "abs": "https://arxiv.org/abs/2506.07707", "authors": ["Maryam Teimouri", "Filip Ginter", "Tomi \"bgt\" Suovuo"], "title": "Interaction Analysis by Humans and AI: A Comparative Perspective", "categories": ["cs.HC"], "comment": null, "summary": "This paper explores how Mixed Reality (MR) and 2D video conferencing\ninfluence children's communication during a gesture-based guessing game.\nFinnish-speaking participants engaged in a short collaborative task using two\ndifferent setups: Microsoft HoloLens MR and Zoom. Audio-video recordings were\ntranscribed and analyzed using Large Language Models (LLMs), enabling iterative\ncorrection, translation, and annotation. Despite limitations in annotations'\naccuracy and agreement, automated approaches significantly reduced processing\ntime and allowed non-Finnish-speaking researchers to participate in data\nanalysis. Evaluations highlight both the efficiency and constraints of\nLLM-based analyses for capturing children's interactions across these\nplatforms. Initial findings indicate that MR fosters richer interaction,\nevidenced by higher emotional expression during annotation, and heightened\nengagement, while Zoom offers simplicity and accessibility. This study\nunderscores the potential of MR to enhance collaborative learning experiences\nfor children in distributed settings.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8MR\u548cZoom\u5bf9\u513f\u7ae5\u624b\u52bf\u731c\u8c1c\u6e38\u620f\u4e2d\u6c9f\u901a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0MR\u4fc3\u8fdb\u66f4\u4e30\u5bcc\u7684\u4e92\u52a8\uff0c\u800cZoom\u66f4\u7b80\u4fbf\u3002", "motivation": "\u63a2\u7d22MR\u548c2D\u89c6\u9891\u4f1a\u8bae\u6280\u672f\u5728\u513f\u7ae5\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u6c9f\u901a\u6548\u679c\u5dee\u5f02\uff0c\u4ee5\u4f18\u5316\u5206\u5e03\u5f0f\u5b66\u4e60\u4f53\u9a8c\u3002", "method": "\u4f7f\u7528Microsoft HoloLens MR\u548cZoom\u8fdb\u884c\u5b9e\u9a8c\uff0c\u901a\u8fc7LLM\u5206\u6790\u97f3\u9891\u89c6\u9891\u8bb0\u5f55\u3002", "result": "MR\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u60c5\u611f\u8868\u8fbe\u548c\u53c2\u4e0e\u5ea6\uff0c\u800cZoom\u66f4\u7b80\u5355\u6613\u7528\u3002", "conclusion": "MR\u6709\u6f5c\u529b\u63d0\u5347\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u513f\u7ae5\u7684\u534f\u4f5c\u5b66\u4e60\u4f53\u9a8c\uff0c\u4f46\u9700\u8981\u7ed3\u5408\u6280\u672f\u7684\u7b80\u4fbf\u6027\u3002"}}
{"id": "2506.07932", "pdf": "https://arxiv.org/pdf/2506.07932", "abs": "https://arxiv.org/abs/2506.07932", "authors": ["Rishit Dagli", "Yushi Guan", "Sankeerth Durvasula", "Mohammadreza Mofayezi", "Nandita Vijaykumar"], "title": "Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "We propose Squeeze3D, a novel framework that leverages implicit prior\nknowledge learnt by existing pre-trained 3D generative models to compress 3D\ndata at extremely high compression ratios. Our approach bridges the latent\nspaces between a pre-trained encoder and a pre-trained generation model through\ntrainable mapping networks. Any 3D model represented as a mesh, point cloud, or\na radiance field is first encoded by the pre-trained encoder and then\ntransformed (i.e. compressed) into a highly compact latent code. This latent\ncode can effectively be used as an extremely compressed representation of the\nmesh or point cloud. A mapping network transforms the compressed latent code\ninto the latent space of a powerful generative model, which is then conditioned\nto recreate the original 3D model (i.e. decompression). Squeeze3D is trained\nentirely on generated synthetic data and does not require any 3D datasets. The\nSqueeze3D architecture can be flexibly used with existing pre-trained 3D\nencoders and existing generative models. It can flexibly support different\nformats, including meshes, point clouds, and radiance fields. Our experiments\ndemonstrate that Squeeze3D achieves compression ratios of up to 2187x for\ntextured meshes, 55x for point clouds, and 619x for radiance fields while\nmaintaining visual quality comparable to many existing methods. Squeeze3D only\nincurs a small compression and decompression latency since it does not involve\ntraining object-specific networks to compress an object.", "AI": {"tldr": "Squeeze3D\u5229\u7528\u9884\u8bad\u7ec3\u76843D\u751f\u6210\u6a21\u578b\u7684\u9690\u5f0f\u5148\u9a8c\u77e5\u8bc6\uff0c\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u6620\u5c04\u7f51\u7edc\u5b9e\u73b03D\u6570\u636e\u7684\u9ad8\u538b\u7f29\u6bd4\u3002", "motivation": "\u7ed3\u5408\u73b0\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5b9e\u73b0\u9ad8\u65483D\u6570\u636e\u538b\u7f29\u3002", "method": "\u901a\u8fc7\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u538b\u7f293D\u6570\u636e\uff0c\u518d\u901a\u8fc7\u6620\u5c04\u7f51\u7edc\u4e0e\u751f\u6210\u6a21\u578b\u7ed3\u5408\uff0c\u5b9e\u73b0\u538b\u7f29\u4e0e\u89e3\u538b\u7f29\u3002", "result": "\u5b9e\u73b0\u9ad8\u538b\u7f29\u6bd4\uff08\u6700\u9ad82187\u500d\uff09\uff0c\u4e14\u89c6\u89c9\u8d28\u91cf\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "Squeeze3D\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u6570\u636e\u8bad\u7ec3\u7684\u9ad8\u65483D\u538b\u7f29\u65b9\u6848\u3002"}}
{"id": "2506.07690", "pdf": "https://arxiv.org/pdf/2506.07690", "abs": "https://arxiv.org/abs/2506.07690", "authors": ["Alexander Bakhtin", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Centrality Change Proneness: an Early Indicator of Microservice Architectural Degradation", "categories": ["cs.SE", "cs.DM", "cs.NA", "math.NA"], "comment": null, "summary": "Over the past decade, the wide adoption of Microservice Architecture has\nrequired the identification of various patterns and anti-patterns to prevent\nMicroservice Architectural Degradation. Frequently, the systems are modelled as\na network of connected services. Recently, the study of temporal networks has\nemerged as a way to describe and analyze evolving networks. Previous research\nhas explored how software metrics such as size, complexity, and quality are\nrelated to microservice centrality in the architectural network. This study\ninvestigates whether temporal centrality metrics can provide insight into the\nearly detection of architectural degradation by correlating or affecting\nsoftware metrics. We reconstructed the architecture of 7 releases of an OSS\nmicroservice project with 42 services. For every service in every release, we\ncomputed the software and centrality metrics. From one of the latter, we\nderived a new metric, Centrality Change Proneness. We then explored the\ncorrelation between the metrics. We identified 7 size and 5 complexity metrics\nthat have a consistent correlation with centrality, while Centrality Change\nProneness did not affect the software metrics, thus providing yet another\nperspective and an early indicator of microservice architectural degradation.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65f6\u95f4\u4e2d\u5fc3\u6027\u6307\u6807\u662f\u5426\u6709\u52a9\u4e8e\u65e9\u671f\u68c0\u6d4b\u5fae\u670d\u52a1\u67b6\u6784\u9000\u5316\uff0c\u53d1\u73b07\u4e2a\u89c4\u6a21\u548c5\u4e2a\u590d\u6742\u6027\u6307\u6807\u4e0e\u4e2d\u5fc3\u6027\u76f8\u5173\uff0c\u65b0\u6307\u6807Centrality Change Proneness\u53ef\u4f5c\u4e3a\u65e9\u671f\u6307\u793a\u5668\u3002", "motivation": "\u63a2\u8ba8\u65f6\u95f4\u4e2d\u5fc3\u6027\u6307\u6807\u4e0e\u8f6f\u4ef6\u6307\u6807\u7684\u5173\u7cfb\uff0c\u4ee5\u65e9\u671f\u68c0\u6d4b\u5fae\u670d\u52a1\u67b6\u6784\u9000\u5316\u3002", "method": "\u5bf97\u4e2a\u7248\u672c\u7684OSS\u5fae\u670d\u52a1\u9879\u76ee\u8fdb\u884c\u67b6\u6784\u91cd\u5efa\uff0c\u8ba1\u7b97\u8f6f\u4ef6\u548c\u4e2d\u5fc3\u6027\u6307\u6807\uff0c\u5206\u6790\u76f8\u5173\u6027\u3002", "result": "7\u4e2a\u89c4\u6a21\u548c5\u4e2a\u590d\u6742\u6027\u6307\u6807\u4e0e\u4e2d\u5fc3\u6027\u76f8\u5173\uff0cCentrality Change Proneness\u4e0d\u5f71\u54cd\u8f6f\u4ef6\u6307\u6807\u3002", "conclusion": "\u65f6\u95f4\u4e2d\u5fc3\u6027\u6307\u6807\u4e3a\u5fae\u670d\u52a1\u67b6\u6784\u9000\u5316\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u548c\u65e9\u671f\u68c0\u6d4b\u5de5\u5177\u3002"}}
{"id": "2506.07777", "pdf": "https://arxiv.org/pdf/2506.07777", "abs": "https://arxiv.org/abs/2506.07777", "authors": ["Brandon Lyman", "Yichi Zhang", "Celia Pearce", "Miso Kim", "Casper Harteveld", "Leanne Chukoskie", "Bob De Schutter"], "title": "Supporting Aging Well through Accessible Digital Games: The Supplemental Role of AI in Game Design for Older Adults", "categories": ["cs.HC"], "comment": "21 pages, 1 figure", "summary": "As the population continues to age, and gaming continues to grow as a hobby\nfor older people, heterogeneity among older adult gamers is increasing. We\nargue that traditional game-based accessibility features, such as simplified\ninput schemes, redundant information channels, and increased legibility of\ndigital user interfaces, are increasingly limited in the face of this\nheterogeneity. This is because such features affect all older adult players\nsimultaneously and therefore are designed generically. We introduce artificial\nintelligence, although it has its own limitations and ethical concerns, as a\nmethod of creating player-based accessibility features, given the adaptive\nnature of the emerging technology. These accessibility features may help to\naddress unique assemblage of accessibility needs an individual may accumulate\nthrough age. We adopt insights from gerontology, HCI, and disability studies\ninto the digital game design discourse for older adults, and we contribute\ninsight that can guide the integration of player-based accessibility features\nto supplement game-based counterparts. The accessibility of digital games for\nheterogenous older adult audience is paramount, as the medium offers short-term\nsocial, emotional, psychological, cognitive, and physical that support the\nlong-term goal of aging well.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u4eba\u5de5\u667a\u80fd\u4e3a\u8001\u5e74\u6e38\u620f\u73a9\u5bb6\u8bbe\u8ba1\u4e2a\u6027\u5316\u8f85\u52a9\u529f\u80fd\uff0c\u4ee5\u5e94\u5bf9\u5176\u65e5\u76ca\u591a\u6837\u5316\u7684\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u8001\u5e74\u6e38\u620f\u73a9\u5bb6\u7fa4\u4f53\u7684\u591a\u6837\u5316\uff0c\u4f20\u7edf\u6e38\u620f\u8f85\u52a9\u529f\u80fd\uff08\u5982\u7b80\u5316\u8f93\u5165\u3001\u5197\u4f59\u4fe1\u606f\u7b49\uff09\u5df2\u65e0\u6cd5\u6ee1\u8db3\u4e2a\u4f53\u9700\u6c42\uff0c\u4e9f\u9700\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u7ed3\u5408\u8001\u5e74\u5b66\u3001\u4eba\u673a\u4ea4\u4e92\u548c\u6b8b\u75be\u7814\u7a76\u7684\u89c6\u89d2\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u73a9\u5bb6\u4e2a\u4f53\u7684\u9002\u5e94\u6027\u8f85\u52a9\u529f\u80fd\u3002", "result": "\u63d0\u51fa\u4e86\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u4e2a\u6027\u5316\u8f85\u52a9\u529f\u80fd\u6846\u67b6\uff0c\u4e3a\u8001\u5e74\u73a9\u5bb6\u63d0\u4f9b\u66f4\u7cbe\u51c6\u7684\u652f\u6301\u3002", "conclusion": "\u4e2a\u6027\u5316\u8f85\u52a9\u529f\u80fd\u5bf9\u63d0\u5347\u8001\u5e74\u73a9\u5bb6\u7684\u6e38\u620f\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u5176\u8eab\u5fc3\u5065\u5eb7\u548c\u793e\u4ea4\u8054\u7cfb\u3002"}}
{"id": "2506.07139", "pdf": "https://arxiv.org/pdf/2506.07139", "abs": "https://arxiv.org/abs/2506.07139", "authors": ["Arev Hambardzumyan", "Rafayel Ghasabyan", "Vahagn Tamazyan"], "title": "FPGA-Based Material Testing Machine Controller", "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.AR", "cs.SY"], "comment": null, "summary": "In the realm of contemporary materials testing, the demand for scalability,\nadaptability, parallelism, and speed has surged due to the proliferation of\ndiverse materials and testing standards. Traditional controller-based systems\noften fall short in meeting these requirements, resulting in adaptability and\nprocessing speed limitations. Conversely, FPGA-based controllers present a\nmultifaceted, high-performance solution. Key advantages of FPGA-based\ncontrollers in materials testing encompass reconfiguration capabilities for\ncost-effective adaptation to evolving materials and standards. FPGAs also\nenable the integration of parallel control and data acquisition circuits, vital\nfor multichannel test equipment demanding simultaneous, independent operation\nof multiple control channels.", "AI": {"tldr": "FPGA\u63a7\u5236\u5668\u5728\u6750\u6599\u6d4b\u8bd5\u4e2d\u89e3\u51b3\u4e86\u4f20\u7edf\u63a7\u5236\u5668\u7684\u9002\u5e94\u6027\u548c\u901f\u5ea6\u9650\u5236\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u63a7\u5236\u5668\u5728\u6750\u6599\u6d4b\u8bd5\u4e2d\u56e0\u591a\u6837\u6027\u6750\u6599\u53ca\u6d4b\u8bd5\u6807\u51c6\u5e26\u6765\u7684\u9002\u5e94\u6027\u548c\u5904\u7406\u901f\u5ea6\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u91c7\u7528FPGA\u6280\u672f\uff0c\u5b9e\u73b0\u53ef\u91cd\u6784\u63a7\u5236\u548c\u5e76\u884c\u6570\u636e\u91c7\u96c6\u7535\u8def\u96c6\u6210\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u9002\u5e94\u6027\u5f3a\u3001\u5904\u7406\u901f\u5ea6\u5feb\u7684\u591a\u901a\u9053\u6d4b\u8bd5\u8bbe\u5907\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "FPGA\u63a7\u5236\u5668\u4e3a\u6750\u6599\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.07781", "pdf": "https://arxiv.org/pdf/2506.07781", "abs": "https://arxiv.org/abs/2506.07781", "authors": ["Mart Karta\u0161ev", "David D\u00f6rner", "\u00d6zer \u00d6zkahraman", "Petter \u00d6gren", "Ivan Stenius", "John Folkesson"], "title": "SMaRCSim: Maritime Robotics Simulation Modules", "categories": ["cs.RO", "cs.GR"], "comment": null, "summary": "Developing new functionality for underwater robots and testing them in the\nreal world is time-consuming and resource-intensive. Simulation environments\nallow for rapid testing before field deployment. However, existing tools lack\ncertain functionality for use cases in our project: i) developing\nlearning-based methods for underwater vehicles; ii) creating teams of\nautonomous underwater, surface, and aerial vehicles; iii) integrating the\nsimulation with mission planning for field experiments. A holistic solution to\nthese problems presents great potential for bringing novel functionality into\nthe underwater domain. In this paper we present SMaRCSim, a set of simulation\npackages that we have developed to help us address these issues.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aSMaRCSim\u7684\u4eff\u771f\u5de5\u5177\u5305\uff0c\u65e8\u5728\u89e3\u51b3\u6c34\u4e0b\u673a\u5668\u4eba\u5f00\u53d1\u4e2d\u7684\u6d4b\u8bd5\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u4eff\u771f\u5de5\u5177\u7f3a\u4e4f\u5bf9\u5b66\u4e60\u578b\u65b9\u6cd5\u3001\u591a\u7c7b\u578b\u81ea\u4e3b\u8f7d\u5177\u56e2\u961f\u534f\u4f5c\u4ee5\u53ca\u4e0e\u4efb\u52a1\u89c4\u5212\u96c6\u6210\u7684\u652f\u6301\u3002", "method": "\u5f00\u53d1\u4e86SMaRCSim\u4eff\u771f\u5de5\u5177\u5305\uff0c\u63d0\u4f9b\u4e0a\u8ff0\u529f\u80fd\u3002", "result": "SMaRCSim\u4e3a\u6c34\u4e0b\u673a\u5668\u4eba\u5f00\u53d1\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u4eff\u771f\u652f\u6301\u3002", "conclusion": "SMaRCSim\u5c55\u793a\u4e86\u5c06\u65b0\u529f\u80fd\u5f15\u5165\u6c34\u4e0b\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.07695", "pdf": "https://arxiv.org/pdf/2506.07695", "abs": "https://arxiv.org/abs/2506.07695", "authors": ["Parsa Miraghaei", "Sergio Moreschini", "Antti Kolehmainen", "David H\u00e4stbacka"], "title": "Towards a Small Language Model Lifecycle Framework", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Background: The growing demand for efficient and deployable language models\nhas led to increased interest in Small Language Models (SLMs). However,\nexisting research remains fragmented, lacking a unified lifecycle perspective.\n  Objective: This study aims to define a comprehensive lifecycle framework for\nSLMs by synthesizing insights from academic literature and practitioner\nsources.\n  Method: We conducted a comprehensive survey of 36 works, analyzing and\ncategorizing lifecycle-relevant techniques.\n  Results: We propose a modular lifecycle model structured into main, optional,\nand cross-cutting components. The model captures key interconnections across\nstages, supporting method reuse, co-adaptation, and lifecycle-awareness.\n  Conclusion: Our framework provides a coherent foundation for developing and\nmaintaining SLMs, bridging theory and practice, and guiding future research and\ntool development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684SLMs\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u6574\u5408\u4e86\u5b66\u672f\u548c\u5b9e\u8df5\u4e2d\u7684\u89c1\u89e3\uff0c\u652f\u6301\u65b9\u6cd5\u91cd\u7528\u548c\u751f\u547d\u5468\u671f\u610f\u8bc6\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u586b\u8865\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLMs)\u7814\u7a76\u4e2d\u7f3a\u4e4f\u7edf\u4e00\u751f\u547d\u5468\u671f\u89c6\u89d2\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7efc\u5408\u5206\u679036\u9879\u7814\u7a76\uff0c\u5f52\u7c7b\u548c\u5206\u6790\u751f\u547d\u5468\u671f\u76f8\u5173\u6280\u672f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u5305\u542b\u4e3b\u8981\u3001\u53ef\u9009\u548c\u8de8\u9886\u57df\u7ec4\u4ef6\uff0c\u652f\u6301\u65b9\u6cd5\u91cd\u7528\u548c\u751f\u547d\u5468\u671f\u610f\u8bc6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aSLMs\u7684\u5f00\u53d1\u548c\u7ef4\u62a4\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u57fa\u7840\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u7814\u7a76\u548c\u5de5\u5177\u5f00\u53d1\u3002"}}
{"id": "2506.07830", "pdf": "https://arxiv.org/pdf/2506.07830", "abs": "https://arxiv.org/abs/2506.07830", "authors": ["Yichi Zhang", "Brandon Lyman", "Celia Pearce", "Miso Kim", "Casper Harteveld", "Leanne Chukoskie", "Bob De Schutter"], "title": "Integrating Artificial Intelligence as Assistive Technology for Older Adult Gamers: A Pilot Study", "categories": ["cs.HC"], "comment": "9 pages, 1 figure", "summary": "With respect to digital games, older adults are a demographic that is often\nunderserved due to an industry-wide focus on younger audiences' preferences and\nskill sets. Meanwhile, as artificial intelligence (AI) continues to expand into\neveryday technologies, its assistive capabilities have been recognized,\nsuggesting its potential in improving the gaming experience for older gamers.\nTo study this potential, we iteratively developed a pilot survey aimed at\nunderstanding older adult gamers' current gameplay preference, challenges they\nare facing, and their perspectives of AI usage in gaming. This article\ncontributes an overview of our iterative survey-design workflow, and pilot\nresults from 39 participants. During each iteration, we analyzed the survey's\nefficacy and adjusted the content, language, and format to better capture\nmeaningful data, and was able to create a refined survey for a larger, more\nrepresentative future parent study. At the same time, preliminary findings\nsuggest that for older adult gamers, usability issues in gaming remain key\nobstacles, while this demographic's perceptions of AI are shaped by both its\npractical benefits and concerns about autonomy and complexity. These findings\nalso offer early insights for the design of age-inclusive, AI-supported gaming\nexperiences.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u5982\u4f55\u6539\u5584\u8001\u5e74\u73a9\u5bb6\u7684\u6e38\u620f\u4f53\u9a8c\uff0c\u901a\u8fc7\u8fed\u4ee3\u5f00\u53d1\u8c03\u67e5\u95ee\u5377\uff0c\u4e86\u89e3\u4ed6\u4eec\u7684\u6e38\u620f\u504f\u597d\u3001\u6311\u6218\u53ca\u5bf9AI\u7684\u770b\u6cd5\uff0c\u521d\u6b65\u53d1\u73b0\u53ef\u7528\u6027\u95ee\u9898\u548cAI\u7684\u53cc\u9762\u6027\u662f\u5173\u952e\u3002", "motivation": "\u7814\u7a76\u8001\u5e74\u73a9\u5bb6\u5728\u6570\u5b57\u6e38\u620f\u4e2d\u7684\u9700\u6c42\uff0c\u63a2\u7d22AI\u5982\u4f55\u8f85\u52a9\u6539\u8fdb\u4ed6\u4eec\u7684\u6e38\u620f\u4f53\u9a8c\u3002", "method": "\u8fed\u4ee3\u8bbe\u8ba1\u5e76\u4f18\u5316\u8c03\u67e5\u95ee\u5377\uff0c\u6536\u96c639\u540d\u8001\u5e74\u73a9\u5bb6\u7684\u6570\u636e\u548c\u53cd\u9988\u3002", "result": "\u53d1\u73b0\u6e38\u620f\u53ef\u7528\u6027\u95ee\u9898\u548cAI\u7684\u5b9e\u9645\u76ca\u5904\u4e0e\u81ea\u4e3b\u6743\u62c5\u5fe7\u662f\u4e3b\u8981\u969c\u788d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u65b9\u5411\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5e74\u9f84\u5305\u5bb9\u6027AI\u6e38\u620f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u521d\u6b65\u89c1\u89e3\uff0c\u5e76\u4f18\u5316\u4e86\u8c03\u67e5\u5de5\u5177\u7528\u4e8e\u66f4\u5927\u89c4\u6a21\u7814\u7a76\u3002"}}
{"id": "2506.07263", "pdf": "https://arxiv.org/pdf/2506.07263", "abs": "https://arxiv.org/abs/2506.07263", "authors": ["Yuhui Zhu", "Alessandro Biondi"], "title": "Exploiting Inaccurate Branch History in Side-Channel Attacks", "categories": ["cs.CR", "cs.AR"], "comment": "20 pages, 8 figures, to be published in proceedings of the 34th\n  USENIX Security Symposium (2025)", "summary": "Modern out-of-order CPUs heavily rely on speculative execution for\nperformance optimization, with branch prediction serving as a cornerstone to\nminimize stalls and maximize efficiency. Whenever shared branch prediction\nresources lack proper isolation and sanitization methods, they may originate\nsecurity vulnerabilities that expose sensitive data across different software\ncontexts.\n  This paper examines the fundamental components of modern Branch Prediction\nUnits (BPUs) and investigates how resource sharing and contention affect two\nwidely implemented but underdocumented features: Bias-Free Branch Prediction\nand Branch History Speculation. Our analysis demonstrates that these BPU\nfeatures, while designed to enhance speculative execution efficiency through\nmore accurate branch histories, can also introduce significant security risks.\nWe show that these features can inadvertently modify the Branch History Buffer\n(BHB) update behavior and create new primitives that trigger malicious\nmis-speculations.\n  This discovery exposes previously unknown cross-privilege attack surfaces for\nBranch History Injection (BHI). Based on these findings, we present three novel\nattack primitives: two Spectre attacks, namely Spectre-BSE and Spectre-BHS, and\na cross-privilege control flow side-channel attack called BiasScope. Our\nresearch identifies corresponding patterns of vulnerable control flows and\ndemonstrates exploitation on multiple processors. Finally, Chimera is\npresented: an attack demonstrator based on eBPF for a variant of Spectre-BHS\nthat is capable of leaking kernel memory contents at 24,628 bit/s.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u73b0\u4ee3\u5206\u652f\u9884\u6d4b\u5355\u5143\uff08BPU\uff09\u7684\u8d44\u6e90\u5171\u4eab\u548c\u7ade\u4e89\u5982\u4f55\u5f71\u54cd\u5176\u7279\u6027\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u7279\u6027\u53ef\u80fd\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u653b\u51fb\u6a21\u578b\u3002", "motivation": "\u63a2\u8ba8\u5206\u652f\u9884\u6d4b\u8d44\u6e90\u7f3a\u4e4f\u9694\u79bb\u5bfc\u81f4\u7684\u6f5c\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7BPU\u7279\u6027\uff08\u5982Bias-Free Branch Prediction\u548cBranch History Speculation\uff09\u5f15\u53d1\u65b0\u7684\u653b\u51fb\u9762\u3002", "method": "\u5206\u6790BPU\u7684\u57fa\u672c\u7ec4\u4ef6\uff0c\u7814\u7a76\u8d44\u6e90\u5171\u4eab\u548c\u7ade\u4e89\u5bf9\u5176\u7279\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e9b\u7279\u6027\u5982\u4f55\u4fee\u6539\u5206\u652f\u5386\u53f2\u7f13\u51b2\u533a\uff08BHB\uff09\u7684\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u4e86\u65b0\u7684\u8de8\u6743\u9650\u653b\u51fb\u9762\uff08BHI\uff09\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u653b\u51fb\u6a21\u578b\uff08Spectre-BSE\u3001Spectre-BHS\u548cBiasScope\uff09\uff0c\u5e76\u5728\u591a\u6b3e\u5904\u7406\u5668\u4e0a\u9a8c\u8bc1\u4e86\u6f0f\u6d1e\u5229\u7528\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cBPU\u7279\u6027\u867d\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46\u4e5f\u5e26\u6765\u5b89\u5168\u98ce\u9669\uff0c\u4f5c\u8005\u5f00\u53d1\u7684Chimera\u653b\u51fb\u6f14\u793a\u5668\u9a8c\u8bc1\u4e86Spectre-BHS\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.07942", "pdf": "https://arxiv.org/pdf/2506.07942", "abs": "https://arxiv.org/abs/2506.07942", "authors": ["Yang Liu", "Armstrong Foundjem", "Foutse Khomh", "Heng Li"], "title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have become vital tools in software development\ntasks such as code generation, completion, and analysis. As their integration\ninto workflows deepens, ensuring robustness against vulnerabilities especially\nthose triggered by diverse or adversarial inputs becomes increasingly\nimportant. Such vulnerabilities may lead to incorrect or insecure code\ngeneration when models encounter perturbed task descriptions, code, or\ncomments. Prior research often overlooks the role of natural language in\nguiding code tasks. This study investigates how adversarial perturbations in\nnatural language inputs including prompts, comments, and descriptions affect\nLLMs for Code (LLM4Code). It examines the effects of perturbations at the\ncharacter, word, and sentence levels to identify the most impactful\nvulnerabilities. We analyzed multiple projects (e.g., ReCode, OpenAttack) and\ndatasets (e.g., HumanEval, MBPP), establishing a taxonomy of adversarial\nattacks. The first dimension classifies the input type code, prompts, or\ncomments while the second dimension focuses on granularity: character, word, or\nsentence-level changes. We adopted a mixed-methods approach, combining\nquantitative performance metrics with qualitative vulnerability analysis.\nLLM4Code models show varying robustness across perturbation types.\nSentence-level attacks were least effective, suggesting models are resilient to\nbroader contextual changes. In contrast, word-level perturbations posed serious\nchallenges, exposing semantic vulnerabilities. Character-level effects varied,\nshowing model sensitivity to subtle syntactic deviations.Our study offers a\nstructured framework for testing LLM4Code robustness and emphasizes the\ncritical role of natural language in adversarial evaluation. Improving model\nresilience to semantic-level disruptions is essential for secure and reliable\ncode-generation systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5bf9\u6297\u6027\u6270\u52a8\u5bf9\u4ee3\u7801\u751f\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM4Code\uff09\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u5b57\u7b26\u3001\u8bcd\u548c\u53e5\u5b50\u7ea7\u522b\u7684\u6270\u52a8\u6548\u679c\uff0c\u53d1\u73b0\u8bcd\u7ea7\u522b\u6270\u52a8\u6700\u5177\u5a01\u80c1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u5bf9\u5bf9\u6297\u6027\u8f93\u5165\u7684\u9c81\u68d2\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u586b\u8865\u4e86\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u5bf9\u4ee3\u7801\u4efb\u52a1\u5f71\u54cd\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u5b9a\u91cf\u6027\u80fd\u6307\u6807\u548c\u5b9a\u6027\u6f0f\u6d1e\u5206\u6790\uff0c\u6d4b\u8bd5\u4e86\u5b57\u7b26\u3001\u8bcd\u548c\u53e5\u5b50\u7ea7\u522b\u7684\u5bf9\u6297\u6027\u6270\u52a8\u5bf9LLM4Code\u7684\u5f71\u54cd\u3002", "result": "\u8bcd\u7ea7\u522b\u6270\u52a8\u6700\u6613\u66b4\u9732\u6a21\u578b\u6f0f\u6d1e\uff0c\u800c\u53e5\u5b50\u7ea7\u522b\u6270\u52a8\u5bf9\u6a21\u578b\u5f71\u54cd\u8f83\u5c0f\uff0c\u5b57\u7b26\u7ea7\u522b\u6270\u52a8\u6548\u679c\u56e0\u6a21\u578b\u800c\u5f02\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6d4b\u8bd5LLM4Code\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u5e76\u5f3a\u8c03\u63d0\u9ad8\u6a21\u578b\u5bf9\u8bed\u4e49\u7ea7\u6270\u52a8\u7684\u62b5\u6297\u529b\u662f\u5173\u952e\u3002"}}
{"id": "2506.07930", "pdf": "https://arxiv.org/pdf/2506.07930", "abs": "https://arxiv.org/abs/2506.07930", "authors": ["Kieran J. Smith", "Tristan C. Endsley", "Torin K. Clark"], "title": "Predicting Situation Awareness from Physiological Signals", "categories": ["cs.HC"], "comment": "15 pages, 6 figures, submitted to IEEE Transactions on Human-Machine\n  Systems", "summary": "Situation awareness (SA)--comprising the ability to 1) perceive critical\nelements in the environment, 2) comprehend their meanings, and 3) project their\nfuture states--is critical for human operator performance. Due to the\ndisruptive nature of gold-standard SA measures, researchers have sought\nphysiological indicators to provide real-time information about SA. We extend\nprior work by using a multimodal suite of neurophysiological,\npsychophysiological, and behavioral signals, predicting all three levels of SA\nalong a continuum, and predicting a comprehensive measure of SA in a complex\nmulti-tasking simulation. We present a lab study in which 31 participants\ncontrolled an aircraft simulator task battery while wearing physiological\nsensors and responding to SA 'freeze-probe' assessments. We demonstrate the\nvalidity of task and assessment for measuring SA. Multimodal physiological\nmodels predict SA with greater predictive performance ($Q^2$ for levels 1-3 and\ntotal, respectively: 0.14, 0.00, 0.26, and 0.36) than models built with\nshuffled labels, demonstrating that multimodal physiological signals provide\nuseful information in predicting all SA levels. Level 3 SA (projection) was\nbest predicted, and level 2 SA comprehension) was the most challenging to\npredict. Ablation analysis and single sensor models found EEG and eye-tracking\nsignals to be particularly useful to predictions of level 3 and total SA. A\nreduced sensor fusion model showed that predictive performance can be\nmaintained with a subset of sensors. This first rigorous cross-validation\nassessment of predictive performance demonstrates the utility of multimodal\nphysiological signals for inferring complex, holistic, objective measures of SA\nat all levels, non-disruptively, and along a continuum.", "AI": {"tldr": "\u901a\u8fc7\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u9884\u6d4b\u60c5\u5883\u610f\u8bc6\uff08SA\uff09\u7684\u4e09\u4e2a\u5c42\u6b21\uff0c\u5c55\u793a\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u60c5\u5883\u610f\u8bc6\u6d4b\u91cf\u65b9\u6cd5\u5177\u6709\u7834\u574f\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u5b9e\u65f6\u3001\u975e\u5e72\u6270\u6027\u7684\u751f\u7406\u6307\u6807\u6765\u9884\u6d4bSA\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u795e\u7ecf\u751f\u7406\u3001\u5fc3\u7406\u751f\u7406\u548c\u884c\u4e3a\u4fe1\u53f7\uff0c\u7ed3\u5408\u98de\u673a\u6a21\u62df\u4efb\u52a1\u548c\u51bb\u7ed3\u63a2\u6d4b\u8bc4\u4f30\uff0c\u9884\u6d4bSA\u7684\u8fde\u7eed\u6027\u548c\u5168\u9762\u6027\u3002", "result": "\u591a\u6a21\u6001\u751f\u7406\u6a21\u578b\u80fd\u6709\u6548\u9884\u6d4bSA\uff0c\u7279\u522b\u662f\u7b2c\u4e09\u5c42\u6b21\uff08\u9884\u6d4b\uff09\uff0c\u800c\u7b2c\u4e8c\u5c42\u6b21\uff08\u7406\u89e3\uff09\u6700\u96be\u9884\u6d4b\u3002EEG\u548c\u773c\u52a8\u4fe1\u53f7\u5bf9\u9884\u6d4b\u8d21\u732e\u663e\u8457\u3002", "conclusion": "\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u5728\u975e\u5e72\u6270\u6027\u9884\u6d4bSA\u65b9\u9762\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u80fd\u63d0\u4f9b\u5168\u9762\u7684\u3001\u5ba2\u89c2\u7684\u6d4b\u91cf\u3002"}}
{"id": "2506.07366", "pdf": "https://arxiv.org/pdf/2506.07366", "abs": "https://arxiv.org/abs/2506.07366", "authors": ["Haiyue Ma", "Zhixu Du", "Yiran Chen"], "title": "MoE-GPS: Guidlines for Prediction Strategy for Dynamic Expert Duplication in MoE Load Balancing", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "In multi-GPU Mixture-of-Experts (MoE) network, experts are distributed across\ndifferent GPUs, which creates load imbalance as each expert processes different\nnumber of tokens. Recent works improve MoE inference load balance by\ndynamically duplicating popular experts to more GPUs to process excessive\ntokens, which requires predicting the distribution before routing. In this\npaper, we discuss the tradeoff of prediction strategies, accuracies, overhead,\nand end-to-end system performance. We propose MoE-GPS, a framework that guides\nthe selection of the optimal predictor design under various system\nconfigurations, by quantifying the performance impact to system-level model\nruntime. Specifically, we advocate for Distribution-Only Prediction, a\nprediction strategy that only predicts overall token distribution which\nsignificantly reduces overhead compared to the traditional Token-to-Expert\nPrediction. On Mixtral 8x7B MMLU dataset, MoE-GPS suggests Distribution-Only\nPrediction which improves end-to-end inference performance by more than 23%\ncompared with Token-to-Expert Prediction.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u591aGPU MoE\u7f51\u7edc\u4e2d\u7684\u8d1f\u8f7d\u5747\u8861\u95ee\u9898\uff0c\u63d0\u51faMoE-GPS\u6846\u67b6\u4f18\u5316\u9884\u6d4b\u5668\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591aGPU MoE\u7f51\u7edc\u4e2d\u56e0\u4e13\u5bb6\u5206\u5e03\u4e0d\u5747\u5bfc\u81f4\u7684\u8d1f\u8f7d\u5931\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faMoE-GPS\u6846\u67b6\uff0c\u91cf\u5316\u9884\u6d4b\u7b56\u7565\uff08\u5982Distribution-Only Prediction\uff09\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5728Mixtral 8x7B MMLU\u6570\u636e\u96c6\u4e0a\uff0cDistribution-Only Prediction\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u534723%\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "MoE-GPS\u901a\u8fc7\u4f18\u5316\u9884\u6d4b\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u914d\u7f6e\u3002"}}
{"id": "2506.07955", "pdf": "https://arxiv.org/pdf/2506.07955", "abs": "https://arxiv.org/abs/2506.07955", "authors": ["Zewei", "Tian", "Alex Liu", "Lief Esbenshade", "Shawon Sarkar", "Zachary Zhang", "Kevin He", "Min Sun"], "title": "Implementation Considerations for Automated AI Grading of Student Work", "categories": ["cs.HC"], "comment": null, "summary": "This study explores the classroom implementation of an AI-powered grading\nplatform in K-12 settings through a co-design pilot with 19 teachers. We\ncombine platform usage logs, surveys, and qualitative interviews to examine how\nteachers use AI-generated rubrics and grading feedback. Findings reveal that\nwhile teachers valued the AI's rapid narrative feedback for formative purposes,\nthey distrusted automated scoring and emphasized the need for human oversight.\nStudents welcomed fast, revision-oriented feedback but remained skeptical of\nAI-only grading. We discuss implications for the design of trustworthy,\nteacher-centered AI assessment tools that enhance feedback while preserving\npedagogical agency.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86AI\u8bc4\u5206\u5e73\u53f0\u5728K-12\u8bfe\u5802\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u6559\u5e08\u8ba4\u53ef\u80fd\u5feb\u901f\u53cd\u9988\u4f46\u8d28\u7591\u81ea\u52a8\u8bc4\u5206\uff0c\u5b66\u751f\u559c\u6b22\u5feb\u901f\u53cd\u9988\u4f46\u6000\u7591AI\u8bc4\u5206\u53ef\u9760\u6027\u3002", "motivation": "\u63a2\u7d22AI\u8bc4\u5206\u5e73\u53f0\u5728\u6559\u80b2\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\u53ca\u5176\u5bf9\u6559\u5e08\u4e0e\u5b66\u751f\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5e73\u53f0\u65e5\u5fd7\u3001\u95ee\u5377\u8c03\u67e5\u548c\u5b9a\u6027\u8bbf\u8c08\uff0c\u7ed3\u540819\u540d\u6559\u5e08\u7684\u534f\u540c\u8bbe\u8ba1\u5b9e\u9a8c\u3002", "result": "\u6559\u5e08\u91cd\u89c6AI\u7684\u5feb\u901f\u53cd\u9988\u4f46\u8d28\u7591\u5176\u8bc4\u5206\u51c6\u786e\u6027\uff0c\u5b66\u751f\u559c\u6b22\u5feb\u901f\u53cd\u9988\u4f46\u5bf9AI\u8bc4\u5206\u6301\u6000\u7591\u6001\u5ea6\u3002", "conclusion": "\u8bbe\u8ba1\u53ef\u4fe1\u8d56\u4e14\u4ee5\u6559\u5e08\u4e3a\u4e2d\u5fc3\u7684AI\u8bc4\u4f30\u5de5\u5177\uff0c\u9700\u589e\u5f3a\u53cd\u9988\u6548\u679c\u5e76\u4fdd\u7559\u6559\u5e08\u7684\u6559\u5b66\u4e3b\u5bfc\u6743\u3002"}}
{"id": "2506.06821", "pdf": "https://arxiv.org/pdf/2506.06821", "abs": "https://arxiv.org/abs/2506.06821", "authors": ["Yuhan Cao", "Zian Chen", "Kun Quan", "Ziliang Zhang", "Yu Wang", "Xiaoning Dong", "Yeqi Feng", "Guanzhong He", "Jingcheng Huang", "Jianhao Li", "Yixuan Tan", "Jiafu Tang", "Yilin Tang", "Junlei Wu", "Qianyu Xiao", "Can Zheng", "Shouchen Zhou", "Yuxiang Zhu", "Yiming Huang", "Tian Xie", "Tianxing He"], "title": "Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "37 pages, 22 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode generation, capable of tackling complex tasks during inference. However,\nthe extent to which LLMs can be utilized for code checking or debugging through\ntest case generation remains largely unexplored. We investigate this problem\nfrom the perspective of competition-level programming (CP) programs and propose\nTCGBench, a Benchmark for (LLM generation of) Test Case Generators. This\nbenchmark comprises two tasks, aimed at studying the capabilities of LLMs in\n(1) generating valid test case generators for a given CP problem, and further\n(2) generating targeted test case generators that expose bugs in human-written\ncode. Experimental results indicate that while state-of-the-art LLMs can\ngenerate valid test case generators in most cases, most LLMs struggle to\ngenerate targeted test cases that reveal flaws in human code effectively.\nEspecially, even advanced reasoning models (e.g., o3-mini) fall significantly\nshort of human performance in the task of generating targeted generators.\nFurthermore, we construct a high-quality, manually curated dataset of\ninstructions for generating targeted generators. Analysis demonstrates that the\nperformance of LLMs can be enhanced with the aid of this dataset, by both\nprompting and fine-tuning.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u68c0\u67e5\u6216\u8c03\u8bd5\u4e2d\u901a\u8fc7\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u4e86TCGBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0LLM\u5728\u751f\u6210\u6709\u6548\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5668\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u751f\u6210\u9488\u5bf9\u6027\u6d4b\u8bd5\u7528\u4f8b\u66b4\u9732\u4ee3\u7801\u7f3a\u9677\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u4ee3\u7801\u68c0\u67e5\u548c\u8c03\u8bd5\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u901a\u8fc7\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u6765\u53d1\u73b0\u7ade\u4e89\u7f16\u7a0b\u4e2d\u7684\u4ee3\u7801\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u4e86TCGBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e24\u4e2a\u4efb\u52a1\uff1a1\uff09\u4e3a\u7ed9\u5b9a\u7ade\u4e89\u7f16\u7a0b\u95ee\u9898\u751f\u6210\u6709\u6548\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5668\uff1b2\uff09\u751f\u6210\u9488\u5bf9\u6027\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5668\u4ee5\u66b4\u9732\u4eba\u7c7b\u4ee3\u7801\u4e2d\u7684\u7f3a\u9677\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLM\u5728\u751f\u6210\u6709\u6548\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5668\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u751f\u6210\u9488\u5bf9\u6027\u6d4b\u8bd5\u7528\u4f8b\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4e0e\u4eba\u7c7b\u8868\u73b0\u5dee\u8ddd\u663e\u8457\u3002\u901a\u8fc7\u9ad8\u8d28\u91cf\u624b\u52a8\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u63d0\u9ad8LLM\u7684\u8868\u73b0\u3002", "conclusion": "LLM\u5728\u4ee3\u7801\u8c03\u8bd5\u4e2d\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u5c24\u5176\u662f\u5728\u751f\u6210\u9488\u5bf9\u6027\u6d4b\u8bd5\u7528\u4f8b\u65b9\u9762\u3002"}}
{"id": "2506.07997", "pdf": "https://arxiv.org/pdf/2506.07997", "abs": "https://arxiv.org/abs/2506.07997", "authors": ["Fan Yang", "Yuan Tian", "Jiansong Zhang"], "title": "Supporting Construction Worker Well-Being with a Multi-Agent Conversational AI System", "categories": ["cs.HC"], "comment": null, "summary": "The construction industry is characterized by both high physical and\npsychological risks, yet supports of mental health remain limited. While\nadvancements in artificial intelligence (AI), particularly large language\nmodels (LLMs), offer promising solutions, their potential in construction\nremains largely underexplored. To bridge this gap, we developed a\nconversational multi-agent system that addresses industry-specific challenges\nthrough an AI-driven approach integrated with domain knowledge. In parallel, it\nfulfills construction workers' basic psychological needs by enabling\ninteractions with multiple agents, each has a distinct persona. This approach\nensures that workers receive both practical problem-solving support and social\nengagement, ultimately contributing to their overall well-being. We evaluate\nits usability and effectiveness through a within-subjects user study with 12\nparticipants. The results show that our system significantly outperforms the\nsingle-agent baseline, achieving improvements of 18% in usability, 40% in\nself-determination, 60% in social presence, and 60% in trust. These findings\nhighlight the promise of LLM-driven AI systems in providing domain-specific\nsupport for construction workers.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u591aAgent\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u901a\u8fc7AI\u9a71\u52a8\u7684\u65b9\u6cd5\u89e3\u51b3\u5efa\u7b51\u884c\u4e1a\u4e2d\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u4eba\u7684\u5fc3\u7406\u9700\u6c42\u548c\u793e\u4ea4\u4e92\u52a8\u3002", "motivation": "\u5efa\u7b51\u884c\u4e1a\u5fc3\u7406\u98ce\u9669\u9ad8\u4f46\u652f\u6301\u4e0d\u8db3\uff0cAI\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\u6f5c\u529b\u672a\u88ab\u5145\u5206\u6316\u6398\uff0c\u4e9f\u9700\u884c\u4e1a\u4e13\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u7684\u591aAgent\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u6bcf\u4e2aAgent\u5177\u6709\u72ec\u7279\u89d2\u8272\uff0c\u63d0\u4f9b\u95ee\u9898\u548c\u793e\u4ea4\u652f\u6301\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u7cfb\u7edf\u5728\u53ef\u7528\u6027\u3001\u81ea\u6211\u51b3\u5b9a\u3001\u793e\u4ea4\u5b58\u5728\u548c\u4fe1\u4efb\u65b9\u9762\u5206\u522b\u63d0\u5347\u4e8618%\u300140%\u300160%\u548c60%\uff0c\u4f18\u4e8e\u5355Agent\u57fa\u7ebf\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cLLM\u9a71\u52a8\u7684AI\u7cfb\u7edf\u5728\u5efa\u7b51\u884c\u4e1a\u4e2d\u5177\u6709\u63d0\u4f9b\u9886\u57df\u4e13\u7528\u652f\u6301\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2506.06286", "pdf": "https://arxiv.org/pdf/2506.06286", "abs": "https://arxiv.org/abs/2506.06286", "authors": ["Kevin Baum"], "title": "Disentangling AI Alignment: A Structured Taxonomy Beyond Safety and Ethics", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "accepted for the LNCS post proceedings of the AISoLA 2024 conference", "summary": "Recent advances in AI research make it increasingly plausible that artificial\nagents with consequential real-world impact will soon operate beyond tightly\ncontrolled environments. Ensuring that these agents are not only safe but that\nthey adhere to broader normative expectations is thus an urgent\ninterdisciplinary challenge. Multiple fields -- notably AI Safety, AI\nAlignment, and Machine Ethics -- claim to contribute to this task. However, the\nconceptual boundaries and interrelations among these domains remain vague,\nleaving researchers without clear guidance in positioning their work.\n  To address this meta-challenge, we develop a structured conceptual framework\nfor understanding AI alignment. Rather than focusing solely on alignment goals,\nwe introduce a taxonomy distinguishing the alignment aim (safety, ethicality,\nlegality, etc.), scope (outcome vs. execution), and constituency (individual\nvs. collective). This structural approach reveals multiple legitimate alignment\nconfigurations, providing a foundation for practical and philosophical\nintegration across domains, and clarifying what it might mean for an agent to\nbe aligned all-things-considered.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u6982\u5ff5\u6846\u67b6\uff0c\u4ee5\u533a\u5206AI\u5bf9\u9f50\u7684\u76ee\u6807\u3001\u8303\u56f4\u548c\u9009\u6c11\uff0c\u4e3a\u89e3\u51b3AI\u5b89\u5168\u4e0e\u4f26\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5f53\u524dAI\u7814\u7a76\u5feb\u901f\u53d1\u5c55\uff0c\u4f46AI\u5b89\u5168\u3001\u5bf9\u9f50\u548c\u4f26\u7406\u5b66\u7b49\u9886\u57df\u7684\u6982\u5ff5\u8fb9\u754c\u6a21\u7cca\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u7814\u7a76\u65b9\u5411\u3002", "method": "\u5f15\u5165\u5206\u7c7b\u6cd5\uff0c\u533a\u5206\u5bf9\u9f50\u7684\u76ee\u6807\uff08\u5b89\u5168\u3001\u4f26\u7406\u3001\u5408\u6cd5\u6027\u7b49\uff09\u3001\u8303\u56f4\uff08\u7ed3\u679c\u4e0e\u6267\u884c\uff09\u548c\u9009\u6c11\uff08\u4e2a\u4f53\u4e0e\u96c6\u4f53\uff09\u3002", "result": "\u6846\u67b6\u63ed\u793a\u4e86\u591a\u79cd\u5408\u7406\u7684\u5bf9\u9f50\u914d\u7f6e\uff0c\u4e3a\u8de8\u9886\u57df\u7684\u5b9e\u8df5\u548c\u54f2\u5b66\u6574\u5408\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u4ee3\u7406\u7684\u5168\u9762\u5bf9\u9f50\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u6709\u52a9\u4e8e\u6f84\u6e05\u7814\u7a76\u65b9\u5411\u548c\u76ee\u6807\u3002"}}
{"id": "2506.07390", "pdf": "https://arxiv.org/pdf/2506.07390", "abs": "https://arxiv.org/abs/2506.07390", "authors": ["Xin-Cheng Wen", "Yijun Yang", "Cuiyun Gao", "Yang Xiao", "Deheng Ye"], "title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "categories": ["cs.AI", "cs.SE"], "comment": "Accepted by ACL 2025 Findings", "summary": "Large language models (LLMs) demonstrate considerable proficiency in numerous\ncoding-related tasks; however, their capabilities in detecting software\nvulnerabilities remain limited. This limitation primarily stems from two\nfactors: (1) the absence of reasoning data related to vulnerabilities, which\nhinders the models' ability to capture underlying vulnerability patterns; and\n(2) their focus on learning semantic representations rather than the reason\nbehind them, thus failing to recognize semantically similar vulnerability\nsamples. Furthermore, the development of LLMs specialized in vulnerability\ndetection is challenging, particularly in environments characterized by the\nscarcity of high-quality datasets. In this paper, we propose a novel framework\nReVD that excels at mining vulnerability patterns through reasoning data\nsynthesizing and vulnerability-specific preference optimization. Specifically,\nwe construct forward and backward reasoning processes for vulnerability and\ncorresponding fixed code, ensuring the synthesis of high-quality reasoning\ndata. Moreover, we design the triplet supervised fine-tuning followed by\ncurriculum online preference optimization for enabling ReVD to better\nunderstand vulnerability patterns. The extensive experiments conducted on\nPrimeVul and SVEN datasets demonstrate that ReVD sets new state-of-the-art for\nLLM-based software vulnerability detection, e.g., 12.24\\%-22.77\\% improvement\nin the accuracy. The source code and data are available at\nhttps://github.com/Xin-Cheng-Wen/PO4Vul.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faReVD\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u63a8\u7406\u6570\u636e\u548c\u4f18\u5316\u6f0f\u6d1e\u504f\u597d\uff0c\u663e\u8457\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u4e3b\u8981\u7f3a\u4e4f\u4e0e\u6f0f\u6d1e\u76f8\u5173\u7684\u63a8\u7406\u6570\u636e\u548c\u5bf9\u8bed\u4e49\u80cc\u540e\u539f\u56e0\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u6784\u5efa\u6f0f\u6d1e\u53ca\u5176\u4fee\u590d\u4ee3\u7801\u7684\u524d\u540e\u5411\u63a8\u7406\u8fc7\u7a0b\uff0c\u8bbe\u8ba1\u4e09\u91cd\u76d1\u7763\u5fae\u8c03\u548c\u8bfe\u7a0b\u5728\u7ebf\u504f\u597d\u4f18\u5316\u3002", "result": "\u5728PrimeVul\u548cSVEN\u6570\u636e\u96c6\u4e0a\uff0cReVD\u5c06\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u9ad812.24%-22.77%\u3002", "conclusion": "ReVD\u901a\u8fc7\u63a8\u7406\u6570\u636e\u5408\u6210\u548c\u504f\u597d\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\uff0c\u6210\u4e3a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2506.06306", "pdf": "https://arxiv.org/pdf/2506.06306", "abs": "https://arxiv.org/abs/2506.06306", "authors": ["Ali Abedi", "Charlene H. Chu", "Shehroz S. Khan"], "title": "Benchmarking Early Agitation Prediction in Community-Dwelling People with Dementia Using Multimodal Sensors and Machine Learning", "categories": ["eess.SP", "cs.CV", "cs.HC", "cs.LG"], "comment": "16 pages, 4 figures, 2 tables", "summary": "Agitation is one of the most common responsive behaviors in people living\nwith dementia, particularly among those residing in community settings without\ncontinuous clinical supervision. Timely prediction of agitation can enable\nearly intervention, reduce caregiver burden, and improve the quality of life\nfor both patients and caregivers. This study aimed to develop and benchmark\nmachine learning approaches for the early prediction of agitation in\ncommunity-dwelling older adults with dementia using multimodal sensor data. A\nnew set of agitation-related contextual features derived from activity data was\nintroduced and employed for agitation prediction. A wide range of machine\nlearning and deep learning models was evaluated across multiple problem\nformulations, including binary classification for single-timestamp tabular\nsensor data and multi-timestamp sequential sensor data, as well as anomaly\ndetection for single-timestamp tabular sensor data. The study utilized the\nTechnology Integrated Health Management (TIHM) dataset, the largest publicly\navailable dataset for remote monitoring of people living with dementia,\ncomprising 2,803 days of in-home activity, physiology, and sleep data. The most\neffective setting involved binary classification of sensor data using the\ncurrent 6-hour timestamp to predict agitation at the subsequent timestamp.\nIncorporating additional information, such as time of day and agitation\nhistory, further improved model performance, with the highest AUC-ROC of 0.9720\nand AUC-PR of 0.4320 achieved by the light gradient boosting machine. This work\npresents the first comprehensive benchmarking of state-of-the-art techniques\nfor agitation prediction in community-based dementia care using\nprivacy-preserving sensor data. The approach enables accurate, explainable, and\nefficient agitation prediction, supporting proactive dementia care and aging in\nplace.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u901a\u8fc7\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\u65e9\u671f\u9884\u6d4b\u793e\u533a\u5c45\u4f4f\u8001\u5e74\u75f4\u5446\u60a3\u8005\u7684\u6fc0\u52a8\u884c\u4e3a\uff0c\u5f15\u5165\u65b0\u7684\u7279\u5f81\u96c6\uff0c\u5e76\u5229\u7528\u516c\u5f00\u6570\u636e\u8fdb\u884c\u4e86\u591a\u6a21\u578b\u6bd4\u8f83\u3002", "motivation": "\u75f4\u5446\u60a3\u8005\u7684\u6fc0\u52a8\u884c\u4e3a\u5e38\u89c1\u4e14\u5f71\u54cd\u751f\u6d3b\u8d28\u91cf\uff0c\u65e9\u671f\u9884\u6d4b\u53ef\u51cf\u8f7b\u62a4\u7406\u8d1f\u62c5\u5e76\u6539\u5584\u60a3\u8005\u548c\u62a4\u7406\u8005\u7684\u751f\u6d3b\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u4e8c\u8fdb\u5236\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u5229\u7528TIHM\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6700\u4f73\u6a21\u578b\u57286\u5c0f\u65f6\u65f6\u95f4\u6233\u7684\u4e8c\u8fdb\u5236\u5206\u7c7b\u4e2d\u8868\u73b0\u6700\u4f18\uff08AUC-ROC: 0.9720\uff09\uff0c\u52a0\u5165\u65f6\u95f4\u548c\u5386\u53f2\u4fe1\u606f\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u793e\u533a\u75f4\u5446\u62a4\u7406\u63d0\u4f9b\u4e86\u9690\u79c1\u4fdd\u62a4\u3001\u9ad8\u6548\u7684\u6fc0\u52a8\u9884\u6d4b\u65b9\u6cd5\uff0c\u652f\u6301\u4e3b\u52a8\u62a4\u7406\u548c\u5c31\u5730\u517b\u8001\u3002"}}
{"id": "2506.07871", "pdf": "https://arxiv.org/pdf/2506.07871", "abs": "https://arxiv.org/abs/2506.07871", "authors": ["Sigma Jahan", "Mohammad Masudur Rahman"], "title": "Can Hessian-Based Insights Support Fault Diagnosis in Attention-based Models?", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "As attention-based deep learning models scale in size and complexity,\ndiagnosing their faults becomes increasingly challenging. In this work, we\nconduct an empirical study to evaluate the potential of Hessian-based analysis\nfor diagnosing faults in attention-based models. Specifically, we use\nHessian-derived insights to identify fragile regions (via curvature analysis)\nand parameter interdependencies (via parameter interaction analysis) within\nattention mechanisms. Through experiments on three diverse models (HAN, 3D-CNN,\nDistilBERT), we show that Hessian-based metrics can localize instability and\npinpoint fault sources more effectively than gradients alone. Our empirical\nfindings suggest that these metrics could significantly improve fault diagnosis\nin complex neural architectures, potentially improving software debugging\npractices.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eHessian\u77e9\u9635\u7684\u5206\u6790\u65b9\u6cd5\u5728\u6ce8\u610f\u529b\u673a\u5236\u6a21\u578b\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u53d1\u73b0\u5176\u6bd4\u68af\u5ea6\u5206\u6790\u66f4\u6709\u6548\u3002", "motivation": "\u968f\u7740\u6ce8\u610f\u529b\u6a21\u578b\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u6545\u969c\u8bca\u65ad\u53d8\u5f97\u66f4\u5177\u6311\u6218\u6027\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22Hessian\u77e9\u9635\u5206\u6790\u5728\u6b64\u9886\u57df\u7684\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7Hessian\u77e9\u9635\u7684\u66f2\u7387\u5206\u6790\u548c\u53c2\u6570\u4ea4\u4e92\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u8106\u5f31\u533a\u57df\u548c\u53c2\u6570\u4f9d\u8d56\u6027\uff0c\u5e76\u5728HAN\u30013D-CNN\u548cDistilBERT\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHessian\u6307\u6807\u6bd4\u68af\u5ea6\u66f4\u80fd\u51c6\u786e\u5b9a\u4f4d\u4e0d\u7a33\u5b9a\u6027\u548c\u6545\u969c\u6e90\u3002", "conclusion": "Hessian\u77e9\u9635\u6307\u6807\u80fd\u663e\u8457\u63d0\u5347\u590d\u6742\u795e\u7ecf\u67b6\u6784\u7684\u6545\u969c\u8bca\u65ad\u80fd\u529b\uff0c\u6709\u671b\u6539\u8fdb\u8f6f\u4ef6\u8c03\u8bd5\u5b9e\u8df5\u3002"}}
{"id": "2506.06524", "pdf": "https://arxiv.org/pdf/2506.06524", "abs": "https://arxiv.org/abs/2506.06524", "authors": ["Sam Earle", "Ahmed Khalifa", "Muhammad Umair Nasir", "Zehua Jiang", "Graham Todd", "Andrzej Banburski-Fahey", "Julian Togelius"], "title": "ScriptDoctor: Automatic Generation of PuzzleScript Games via Large Language Models and Tree Search", "categories": ["cs.AI", "cs.HC"], "comment": "5 pages, 3 figures, 3 tables, submitted to IEEE Conference on Games\n  as a Short Paper", "summary": "There is much interest in using large pre-trained models in Automatic Game\nDesign (AGD), whether via the generation of code, assets, or more abstract\nconceptualization of design ideas. But so far this interest largely stems from\nthe ad hoc use of such generative models under persistent human supervision.\nMuch work remains to show how these tools can be integrated into\nlonger-time-horizon AGD pipelines, in which systems interface with game engines\nto test generated content autonomously. To this end, we introduce ScriptDoctor,\na Large Language Model (LLM)-driven system for automatically generating and\ntesting games in PuzzleScript, an expressive but highly constrained description\nlanguage for turn-based puzzle games over 2D gridworlds. ScriptDoctor generates\nand tests game design ideas in an iterative loop, where human-authored examples\nare used to ground the system's output, compilation errors from the\nPuzzleScript engine are used to elicit functional code, and search-based agents\nplay-test generated games. ScriptDoctor serves as a concrete example of the\npotential of automated, open-ended LLM-based workflows in generating novel game\ncontent.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u6e38\u620f\u8bbe\u8ba1\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aScriptDoctor\u7684\u7cfb\u7edf\uff0c\u5b83\u80fd\u591f\u901a\u8fc7\u8fed\u4ee3\u5faa\u73af\u751f\u6210\u548c\u6d4b\u8bd5\u6e38\u620f\u8bbe\u8ba1\u3002", "motivation": "\u76ee\u524d\uff0c\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u81ea\u52a8\u6e38\u620f\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4eba\u5de5\u76d1\u7763\uff0c\u7f3a\u4e4f\u957f\u671f\u81ea\u4e3b\u751f\u6210\u548c\u6d4b\u8bd5\u7684\u7ba1\u9053\u3002", "method": "ScriptDoctor\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728PuzzleScript\u4e2d\u751f\u6210\u548c\u6d4b\u8bd5\u6e38\u620f\uff0c\u7ed3\u5408\u4eba\u7c7b\u793a\u4f8b\u3001\u5f15\u64ce\u9519\u8bef\u53cd\u9988\u548c\u57fa\u4e8e\u641c\u7d22\u7684\u4ee3\u7406\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "ScriptDemonstrate\u4e86LLM\u9a71\u52a8\u7684\u5de5\u4f5c\u6d41\u5728\u751f\u6210\u65b0\u9896\u6e38\u620f\u5185\u5bb9\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "ScriptDoctor\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u4f53\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u793a\u4f8b\uff0c\u5c55\u793a\u4e86LLM\u5728\u5f00\u653e\u6e38\u620f\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.06576", "pdf": "https://arxiv.org/pdf/2506.06576", "abs": "https://arxiv.org/abs/2506.06576", "authors": ["Yijia Shao", "Humishka Zope", "Yucheng Jiang", "Jiaxin Pei", "David Nguyen", "Erik Brynjolfsson", "Diyi Yang"], "title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": "Preprint", "summary": "The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the\nlabor market, raising concerns about job displacement, diminished human agency,\nand overreliance on automation. Yet, we lack a systematic understanding of the\nevolving landscape. In this paper, we address this gap by introducing a novel\nauditing framework to assess which occupational tasks workers want AI agents to\nautomate or augment, and how those desires align with the current technological\ncapabilities. Our framework features an audio-enhanced mini-interview to\ncapture nuanced worker desires and introduces the Human Agency Scale (HAS) as a\nshared language to quantify the preferred level of human involvement. Using\nthis framework, we construct the WORKBank database, building on the U.S.\nDepartment of Labor's O*NET database, to capture preferences from 1,500 domain\nworkers and capability assessments from AI experts across over 844 tasks\nspanning 104 occupations. Jointly considering the desire and technological\ncapability divides tasks in WORKBank into four zones: Automation \"Green Light\"\nZone, Automation \"Red Light\" Zone, R&D Opportunity Zone, Low Priority Zone.\nThis highlights critical mismatches and opportunities for AI agent development.\nMoving beyond a simple automate-or-not dichotomy, our results reveal diverse\nHAS profiles across occupations, reflecting heterogeneous expectations for\nhuman involvement. Moreover, our study offers early signals of how AI agent\nintegration may reshape the core human competencies, shifting from\ninformation-focused skills to interpersonal ones. These findings underscore the\nimportance of aligning AI agent development with human desires and preparing\nworkers for evolving workplace dynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u5ba1\u8ba1\u6846\u67b6\u6765\u8bc4\u4f30\u5de5\u4eba\u5e0c\u671bAI\u81ea\u52a8\u5316\u6216\u589e\u5f3a\u7684\u804c\u4e1a\u4efb\u52a1\uff0c\u5e76\u6bd4\u8f83\u4e86\u8fd9\u4e9b\u613f\u671b\u4e0e\u5f53\u524d\u6280\u672f\u80fd\u529b\u7684\u5339\u914d\u60c5\u51b5\uff0c\u6700\u7ec8\u6784\u5efa\u4e86WORKBank\u6570\u636e\u5e93\u4ee5\u63ed\u793a\u4efb\u52a1\u7684\u4e0d\u540c\u4f18\u5148\u7ea7\u548c\u5f00\u53d1\u673a\u4f1a\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5176\u5bf9\u52b3\u52a8\u5e02\u573a\u7684\u5f71\u54cd\u65e5\u76ca\u663e\u8457\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5de5\u4eba\u9700\u6c42\u4e0e\u6280\u672f\u80fd\u529b\u5339\u914d\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u5f15\u5165\u97f3\u9891\u589e\u5f3a\u7684\u5c0f\u578b\u8bbf\u8c08\u548cHuman Agency Scale (HAS)\u6765\u91cf\u5316\u5de5\u4eba\u5bf9\u4efb\u52a1\u81ea\u52a8\u5316\u7684\u504f\u597d\uff0c\u5e76\u6784\u5efaWORKBank\u6570\u636e\u5e93\uff0c\u7ed3\u5408\u5de5\u4eba\u504f\u597d\u548cAI\u4e13\u5bb6\u8bc4\u4f30\uff0c\u5c06\u4efb\u52a1\u5206\u4e3a\u56db\u4e2a\u533a\u57df\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4efb\u52a1\u53ef\u4ee5\u5212\u5206\u4e3a\u56db\u4e2a\u4f18\u5148\u7ea7\u533a\u57df\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u804c\u4e1a\u5bf9\u4eba\u5de5\u53c2\u4e0e\u7684\u591a\u6837\u5316\u9700\u6c42\uff0c\u5e76\u6307\u51faAI\u96c6\u6210\u53ef\u80fd\u5c06\u4eba\u7c7b\u6838\u5fc3\u80fd\u529b\u4ece\u4fe1\u606f\u6280\u80fd\u8f6c\u5411\u4eba\u9645\u6280\u80fd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03AI\u5f00\u53d1\u5e94\u4e0e\u4eba\u7c7b\u9700\u6c42\u5bf9\u9f50\uff0c\u5e76\u4e3a\u5de5\u4eba\u9002\u5e94\u672a\u6765\u7684\u5de5\u4f5c\u52a8\u6001\u505a\u597d\u51c6\u5907\u3002"}}
{"id": "2506.06591", "pdf": "https://arxiv.org/pdf/2506.06591", "abs": "https://arxiv.org/abs/2506.06591", "authors": ["Shijing He", "Yaxiong Lei", "Xiao Zhan", "Chi Zhang", "Juan Ye", "Ruba Abu-Salma", "Jose Such"], "title": "Privacy Perspectives and Practices of Chinese Smart Home Product Teams", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Previous research has explored the privacy needs and concerns of device\nowners, primary users, and different bystander groups with regard to smart home\ndevices like security cameras, smart speakers, and hubs, but little is known\nabout the privacy views and practices of smart home product teams, particularly\nthose in non-Western contexts. This paper presents findings from 27\nsemi-structured interviews with Chinese smart home product team members,\nincluding product/project managers, software/hardware engineers, user\nexperience (UX) designers, legal/privacy experts, and marketers/operation\nspecialists. We examine their privacy perspectives, practices, and risk\nmitigation strategies. Our results show that participants emphasized compliance\nwith Chinese data privacy laws, which typically prioritized national security\nover individual privacy rights. China-specific cultural, social, and legal\nfactors also influenced participants' ethical considerations and attitudes\ntoward balancing user privacy and security with convenience. Drawing on our\nfindings, we propose a set of recommendations for smart home product teams,\nalong with socio-technical and legal interventions to address smart home\nprivacy issues-especially those belonging to at-risk groups-in Chinese\nmulti-user smart homes.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc727\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u7814\u7a76\u4e86\u4e2d\u56fd\u667a\u80fd\u5bb6\u5c45\u4ea7\u54c1\u56e2\u961f\u7684\u9690\u79c1\u89c2\u70b9\u4e0e\u5b9e\u8df5\uff0c\u53d1\u73b0\u5176\u66f4\u6ce8\u91cd\u56fd\u5bb6\u5b89\u5168\u7684\u5408\u89c4\u6027\uff0c\u5e76\u53d7\u4e2d\u56fd\u6587\u5316\u3001\u793e\u4f1a\u548c\u6cd5\u5f8b\u56e0\u7d20\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u975e\u897f\u65b9\u80cc\u666f\u4e0b\u667a\u80fd\u5bb6\u5c45\u4ea7\u54c1\u56e2\u961f\u7684\u9690\u79c1\u89c2\u70b9\u4e0e\u5b9e\u8df5\u3002", "method": "\u91c7\u752827\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u6db5\u76d6\u4e0d\u540c\u804c\u80fd\u7684\u56e2\u961f\u6210\u5458\u3002", "result": "\u4e2d\u56fd\u56e2\u961f\u66f4\u6ce8\u91cd\u56fd\u5bb6\u5b89\u5168\u5408\u89c4\u6027\uff0c\u6587\u5316\u548c\u793e\u4f1a\u56e0\u7d20\u5f71\u54cd\u5176\u9690\u79c1\u4e0e\u4fbf\u5229\u7684\u5e73\u8861\u3002", "conclusion": "\u63d0\u51fa\u9488\u5bf9\u4e2d\u56fd\u667a\u80fd\u5bb6\u5c45\u9690\u79c1\u95ee\u9898\u7684\u5efa\u8bae\u548c\u793e\u4f1a\u6280\u672f\u6cd5\u5f8b\u5e72\u9884\u63aa\u65bd\u3002"}}
{"id": "2506.06813", "pdf": "https://arxiv.org/pdf/2506.06813", "abs": "https://arxiv.org/abs/2506.06813", "authors": ["Dipto Das", "Syed Ishtiaque Ahmed", "Shion Guha"], "title": "BTPD: A Multilingual Hand-curated Dataset of Bengali Transnational Political Discourse Across Online Communities", "categories": ["cs.CL", "cs.CY", "cs.HC"], "comment": null, "summary": "Understanding political discourse in online spaces is crucial for analyzing\npublic opinion and ideological polarization. While social computing and\ncomputational linguistics have explored such discussions in English, such\nresearch efforts are significantly limited in major yet under-resourced\nlanguages like Bengali due to the unavailability of datasets. In this paper, we\npresent a multilingual dataset of Bengali transnational political discourse\n(BTPD) collected from three online platforms, each representing distinct\ncommunity structures and interaction dynamics. Besides describing how we\nhand-curated the dataset through community-informed keyword-based retrieval,\nthis paper also provides a general overview of its topics and multilingual\ncontent.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u591a\u8bed\u8a00\u7684\u5b5f\u52a0\u62c9\u8de8\u56fd\u653f\u6cbb\u8bdd\u8bed\u6570\u636e\u96c6\uff08BTPD\uff09\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u6570\u636e\u7a7a\u767d\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u4e3b\u9898\u548c\u5185\u5bb9\u6982\u51b5\u3002", "motivation": "\u7814\u7a76\u5728\u7ebf\u653f\u6cbb\u8bdd\u8bed\u5bf9\u5206\u6790\u516c\u4f17\u610f\u89c1\u548c\u610f\u8bc6\u5f62\u6001\u6781\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u7b49\u8d44\u6e90\u4e0d\u8db3\u8bed\u8a00\u7684\u7814\u7a76\u56e0\u7f3a\u4e4f\u6570\u636e\u96c6\u800c\u53d7\u9650\u3002", "method": "\u901a\u8fc7\u793e\u533a\u9a71\u52a8\u7684\u5173\u952e\u8bcd\u68c0\u7d22\u65b9\u6cd5\uff0c\u4ece\u4e09\u4e2a\u5728\u7ebf\u5e73\u53f0\u624b\u5de5\u6536\u96c6\u6570\u636e\uff0c\u6784\u5efa\u6570\u636e\u96c6\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u591a\u8bed\u8a00\u7684\u5b5f\u52a0\u62c9\u8de8\u56fd\u653f\u6cbb\u8bdd\u8bed\u6570\u636e\u96c6\uff0c\u5e76\u5bf9\u5176\u4e3b\u9898\u548c\u5185\u5bb9\u8fdb\u884c\u4e86\u6982\u8ff0\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u7814\u7a76\u5b5f\u52a0\u62c9\u8bed\u653f\u6cbb\u8bdd\u8bed\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2506.06816", "pdf": "https://arxiv.org/pdf/2506.06816", "abs": "https://arxiv.org/abs/2506.06816", "authors": ["Dipto Das", "Shion Guha", "Bryan Semaan"], "title": "How do datasets, developers, and models affect biases in a low-resourced language?", "categories": ["cs.CL", "cs.CY", "cs.HC"], "comment": null, "summary": "Sociotechnical systems, such as language technologies, frequently exhibit\nidentity-based biases. These biases exacerbate the experiences of historically\nmarginalized communities and remain understudied in low-resource contexts.\nWhile models and datasets specific to a language or with multilingual support\nare commonly recommended to address these biases, this paper empirically tests\nthe effectiveness of such approaches in the context of gender, religion, and\nnationality-based identities in Bengali, a widely spoken but low-resourced\nlanguage. We conducted an algorithmic audit of sentiment analysis models built\non mBERT and BanglaBERT, which were fine-tuned using all Bengali sentiment\nanalysis (BSA) datasets from Google Dataset Search. Our analyses showed that\nBSA models exhibit biases across different identity categories despite having\nsimilar semantic content and structure. We also examined the inconsistencies\nand uncertainties arising from combining pre-trained models and datasets\ncreated by individuals from diverse demographic backgrounds. We connected these\nfindings to the broader discussions on epistemic injustice, AI alignment, and\nmethodological decisions in algorithmic audits.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5b5f\u52a0\u62c9\u8bed\uff09\u4e2d\u8bed\u8a00\u6280\u672f\u7684\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u8eab\u4efd\u504f\u89c1\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7b97\u6cd5\u5ba1\u8ba1\u9a8c\u8bc1\u6a21\u578b\u504f\u89c1\u7684\u5b58\u5728\u3002", "motivation": "\u8bed\u8a00\u6280\u672f\u4e2d\u7684\u8eab\u4efd\u504f\u89c1\u95ee\u9898\u5bf9\u5386\u53f2\u8fb9\u7f18\u5316\u793e\u533a\u5f71\u54cd\u663e\u8457\uff0c\u4f46\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e0b\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5bf9\u57fa\u4e8emBERT\u548cBanglaBERT\u7684\u60c5\u611f\u5206\u6790\u6a21\u578b\u8fdb\u884c\u7b97\u6cd5\u5ba1\u8ba1\uff0c\u6d4b\u8bd5\u5176\u5728\u6027\u522b\u3001\u5b97\u6559\u548c\u56fd\u7c4d\u8eab\u4efd\u4e0a\u7684\u504f\u89c1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u8bed\u4e49\u5185\u5bb9\u548c\u7ed3\u6784\u76f8\u4f3c\uff0c\u4f46\u6a21\u578b\u5728\u4e0d\u540c\u8eab\u4efd\u7c7b\u522b\u4e0a\u8868\u73b0\u51fa\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u51f8\u663e\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u4e0e\u6570\u636e\u96c6\u7ed3\u5408\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u5173\u8054\u4e86\u8ba4\u77e5\u4e0d\u516c\u548cAI\u5bf9\u9f50\u7684\u8ba8\u8bba\u3002"}}
{"id": "2506.06991", "pdf": "https://arxiv.org/pdf/2506.06991", "abs": "https://arxiv.org/abs/2506.06991", "authors": ["Yichi Zhang", "Jinlong Pang", "Zhaowei Zhu", "Yang Liu"], "title": "Evaluating LLM-corrupted Crowdsourcing Data Without Ground Truth", "categories": ["cs.AI", "cs.GT", "cs.HC"], "comment": "33 pages, 9 figures", "summary": "The recent success of generative AI highlights the crucial role of\nhigh-quality human feedback in building trustworthy AI systems. However, the\nincreasing use of large language models (LLMs) by crowdsourcing workers poses a\nsignificant challenge: datasets intended to reflect human input may be\ncompromised by LLM-generated responses. Existing LLM detection approaches often\nrely on high-dimension training data such as text, making them unsuitable for\nannotation tasks like multiple-choice labeling. In this work, we investigate\nthe potential of peer prediction -- a mechanism that evaluates the information\nwithin workers' responses without using ground truth -- to mitigate\nLLM-assisted cheating in crowdsourcing with a focus on annotation tasks. Our\napproach quantifies the correlations between worker answers while conditioning\non (a subset of) LLM-generated labels available to the requester. Building on\nprior research, we propose a training-free scoring mechanism with theoretical\nguarantees under a crowdsourcing model that accounts for LLM collusion. We\nestablish conditions under which our method is effective and empirically\ndemonstrate its robustness in detecting low-effort cheating on real-world\ncrowdsourcing datasets.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528\u540c\u884c\u9884\u6d4b\u673a\u5236\u68c0\u6d4b\u548c\u51cf\u5c11\u4f17\u5305\u4efb\u52a1\u4e2dLLM\u8f85\u52a9\u4f5c\u5f0a\u884c\u4e3a\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6807\u6ce8\u4efb\u52a1\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f17\u5305\u5de5\u4f5c\u8005\u53ef\u80fd\u4f9d\u8d56LLM\u751f\u6210\u7b54\u6848\uff0c\u5bfc\u81f4\u6570\u636e\u96c6\u8d28\u91cf\u4e0b\u964d\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5bf9\u6b64\u4e0d\u591f\u9002\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u540c\u884c\u9884\u6d4b\u7684\u65e0\u8bad\u7ec3\u8bc4\u5206\u673a\u5236\uff0c\u901a\u8fc7\u91cf\u5316\u5de5\u4eba\u56de\u7b54\u95f4\u7684\u76f8\u5173\u6027\uff08\u4ee5LLM\u751f\u6210\u7684\u6807\u7b7e\u4e3a\u6761\u4ef6\uff09\uff0c\u65e0\u9700\u4f9d\u8d56\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\u68c0\u6d4b\u4f5c\u5f0a\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u4f4e\u8d28\u91cf\u4f5c\u5f0a\u884c\u4e3a\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u4f17\u5305\u6570\u636e\u96c6\u3002", "conclusion": "\u540c\u884c\u9884\u6d4b\u673a\u5236\u80fd\u6709\u6548\u5e94\u5bf9LLM\u8f85\u52a9\u4f5c\u5f0a\uff0c\u4e3a\u4f17\u5305\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u8d28\u91cf\u4fdd\u969c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.07073", "pdf": "https://arxiv.org/pdf/2506.07073", "abs": "https://arxiv.org/abs/2506.07073", "authors": ["Emmanuel Deruty", "Maarten Grachten"], "title": "Insights on Harmonic Tones from a Generative Music Experiment", "categories": ["cs.SD", "cs.HC", "eess.AS", "68T01", "J.5"], "comment": "15th International Workshop on Machine Learning and Music, September\n  9, 2024, Vilnius, Lithuania", "summary": "The ultimate purpose of generative music AI is music production. The\nstudio-lab, a social form within the art-science branch of\ncross-disciplinarity, is a way to advance music production with AI music\nmodels. During a studio-lab experiment involving researchers, music producers,\nand an AI model for music generating bass-like audio, it was observed that the\nproducers used the model's output to convey two or more pitches with a single\nharmonic complex tone, which in turn revealed that the model had learned to\ngenerate structured and coherent simultaneous melodic lines using monophonic\nsequences of harmonic complex tones. These findings prompt a reconsideration of\nthe long-standing debate on whether humans can perceive harmonics as distinct\npitches and highlight how generative AI can not only enhance musical creativity\nbut also contribute to a deeper understanding of music.", "AI": {"tldr": "\u751f\u6210\u97f3\u4e50AI\u901a\u8fc7\u827a\u672f\u4e0e\u79d1\u5b66\u7684\u8de8\u5b66\u79d1\u5408\u4f5c\u2014\u2014\u5de5\u4f5c\u5ba4\u5b9e\u9a8c\u5ba4\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u80fd\u591f\u751f\u6210\u7ed3\u6784\u5316\u548c\u8fde\u8d2f\u7684\u591a\u91cd\u65cb\u5f8b\u7ebf\uff0c\u4fc3\u8fdb\u97f3\u4e50\u521b\u9020\u529b\u548c\u97f3\u4e50\u8ba4\u77e5\u7684\u7814\u7a76\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u97f3\u4e50AI\u5728\u97f3\u4e50\u5236\u4f5c\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5bf9\u97f3\u4e50\u7406\u8bba\u548c\u4eba\u7c7b\u542c\u89c9\u611f\u77e5\u7684\u6f5c\u5728\u8d21\u732e\u3002", "method": "\u901a\u8fc7\u5de5\u4f5c\u5ba4\u5b9e\u9a8c\u5ba4\u7684\u5b9e\u9a8c\uff0c\u7814\u7a76\u8005\u3001\u97f3\u4e50\u5236\u4f5c\u4eba\u548cAI\u6a21\u578b\u5408\u4f5c\uff0c\u89c2\u5bdf\u6a21\u578b\u751f\u6210\u4f4e\u97f3\u97f3\u9891\u7684\u80fd\u529b\u53ca\u5176\u5bf9\u97f3\u4e50\u5236\u4f5c\u7684\u5f71\u54cd\u3002", "result": "AI\u6a21\u578b\u5b66\u4f1a\u4e86\u751f\u6210\u7ed3\u6784\u5316\u7684\u591a\u91cd\u65cb\u5f8b\u7ebf\uff0c\u97f3\u4e50\u5236\u4f5c\u4eba\u5229\u7528\u8fd9\u4e9b\u8f93\u51fa\u6765\u63a2\u7d22\u8c10\u6ce2\u4f5c\u4e3a\u72ec\u7acb\u97f3\u9ad8\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u751f\u6210\u97f3\u4e50AI\u4e0d\u4ec5\u80fd\u63d0\u5347\u97f3\u4e50\u521b\u4f5c\uff0c\u8fd8\u4e3a\u4eba\u7c7b\u611f\u77e5\u591a\u97f3\u9ad8\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u89c6\u89d2\u3002"}}
{"id": "2506.07275", "pdf": "https://arxiv.org/pdf/2506.07275", "abs": "https://arxiv.org/abs/2506.07275", "authors": ["Haochen Song", "Dominik Hofer", "Rania Islambouli", "Laura Hawkins", "Ananya Bhattacharjee", "Meredith Franklin", "Joseph Jay Williams"], "title": "Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models", "categories": ["cs.LG", "cs.HC", "stat.AP"], "comment": null, "summary": "Machine learning approaches, such as contextual multi-armed bandit (cMAB)\nalgorithms, offer a promising strategy to reduce sedentary behavior by\ndelivering personalized interventions to encourage physical activity. However,\ncMAB algorithms typically require large participant samples to learn\neffectively and may overlook key psychological factors that are not explicitly\nencoded in the model. In this study, we propose a hybrid approach that combines\ncMAB for selecting intervention types with large language models (LLMs) to\npersonalize message content. We evaluate four intervention types: behavioral\nself-monitoring, gain-framed, loss-framed, and social comparison, each\ndelivered as a motivational message aimed at increasing motivation for physical\nactivity and daily step count. Message content is further personalized using\ndynamic contextual factors including daily fluctuations in self-efficacy,\nsocial influence, and regulatory focus. Over a seven-day trial, participants\nreceive daily messages assigned by one of four models: cMAB alone, LLM alone,\ncombined cMAB with LLM personalization (cMABxLLM), or equal randomization\n(RCT). Outcomes include daily step count and message acceptance, assessed via\necological momentary assessments (EMAs). We apply a causal inference framework\nto evaluate the effects of each model. Our findings offer new insights into the\ncomplementary roles of LLM-based personalization and cMAB adaptation in\npromoting physical activity through personalized behavioral messaging.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed3\u5408\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\uff08cMAB\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u5e72\u9884\u4ee5\u51cf\u5c11\u4e45\u5750\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709cMAB\u7b97\u6cd5\u9700\u8981\u5927\u91cf\u6837\u672c\u4e14\u53ef\u80fd\u5ffd\u7565\u5fc3\u7406\u56e0\u7d20\uff0c\u5e0c\u671b\u901a\u8fc7\u7ed3\u5408LLM\u63d0\u5347\u5e72\u9884\u6548\u679c\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u56db\u79cd\u6a21\u578b\uff1a\u5355\u72eccMAB\u3001\u5355\u72ecLLM\u3001cMABxLLM\u7ec4\u5408\u548c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff08RCT\uff09\uff0c\u8bc4\u4f30\u5176\u5bf9\u6b65\u6570\u548c\u6d88\u606f\u63a5\u53d7\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u6846\u67b6\u5206\u6790\u4e86\u6bcf\u79cd\u6a21\u578b\u7684\u6548\u679c\u3002", "conclusion": "LLM\u4e2a\u6027\u5316\u548ccMAB\u9002\u5e94\u5728\u4fc3\u8fdb\u4f53\u80b2\u6d3b\u52a8\u65b9\u9762\u5177\u6709\u4e92\u8865\u4f5c\u7528\u3002"}}
{"id": "2506.07667", "pdf": "https://arxiv.org/pdf/2506.07667", "abs": "https://arxiv.org/abs/2506.07667", "authors": ["Prarabdh Shukla", "Wei Yin Chong", "Yash Patel", "Brennan Schaffner", "Danish Pruthi", "Arjun Bhagoji"], "title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch", "categories": ["cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "To meet the demands of content moderation, online platforms have resorted to\nautomated systems. Newer forms of real-time engagement($\\textit{e.g.}$, users\ncommenting on live streams) on platforms like Twitch exert additional pressures\non the latency expected of such moderation systems. Despite their prevalence,\nrelatively little is known about the effectiveness of these systems. In this\npaper, we conduct an audit of Twitch's automated moderation tool\n($\\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful\ncontent. For our audit, we create streaming accounts to act as siloed test\nbeds, and interface with the live chat using Twitch's APIs to send over\n$107,000$ comments collated from $4$ datasets. We measure $\\texttt{AutoMod}$'s\naccuracy in flagging blatantly hateful content containing misogyny, racism,\nableism and homophobia. Our experiments reveal that a large fraction of hateful\nmessages, up to $94\\%$ on some datasets, $\\textit{bypass moderation}$.\nContextual addition of slurs to these messages results in $100\\%$ removal,\nrevealing $\\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We\nalso find that contrary to Twitch's community guidelines, $\\texttt{AutoMod}$\nblocks up to $89.5\\%$ of benign examples that use sensitive words in\npedagogical or empowering contexts. Overall, our audit points to large gaps in\n$\\texttt{AutoMod}$'s capabilities and underscores the importance for such\nsystems to understand context effectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5ba1\u8ba1Twitch\u7684\u81ea\u52a8\u5ba1\u6838\u5de5\u5177AutoMod\uff0c\u53d1\u73b0\u5176\u5728\u68c0\u6d4b\u4ec7\u6068\u5185\u5bb9\u65f6\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\uff0c94%\u7684\u4ec7\u6068\u5185\u5bb9\u672a\u88ab\u6807\u8bb0\uff0c\u540c\u65f6\u5bf9\u654f\u611f\u8bcd\u7684\u975e\u4ec7\u6068\u4f7f\u7528\u8fc7\u5ea6\u5ba1\u67e5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u8bc4\u4f30\u5b9e\u65f6\u4e92\u52a8\u5e73\u53f0\uff08\u5982Twitch\uff09\u7684\u81ea\u52a8\u5ba1\u6838\u7cfb\u7edf\u5728\u68c0\u6d4b\u4ec7\u6068\u5185\u5bb9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u521b\u5efa\u6d4b\u8bd5\u8d26\u6237\u3001\u901a\u8fc7Twitch API\u53d1\u9001107,000\u6761\u8bc4\u8bba\uff0c\u5e76\u6d4b\u91cfAutoMod\u5bf9\u4ec7\u6068\u5185\u5bb9\u7684\u6807\u8bb0\u51c6\u786e\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793aAutoMod\u6f0f\u68c0\u7387\u9ad8\u8fbe94%\uff0c\u4e14\u5bf9\u654f\u611f\u8bcd\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u8db3\uff0c\u8bef\u5220\u4e8689.5%\u7684\u826f\u6027\u5185\u5bb9\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51faAutoMod\u5b58\u5728\u91cd\u5927\u7f3a\u9677\uff0c\u5f3a\u8c03\u4e86\u81ea\u52a8\u5316\u5ba1\u6838\u7cfb\u7edf\u9700\u66f4\u597d\u5730\u7406\u89e3\u4e0a\u4e0b\u6587\u3002"}}
