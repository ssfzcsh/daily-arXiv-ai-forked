{"id": "2507.05269", "pdf": "https://arxiv.org/pdf/2507.05269", "abs": "https://arxiv.org/abs/2507.05269", "authors": ["Danning Xie", "Mingwei Zheng", "Xuwei Liu", "Jiannan Wang", "Chengpeng Wang", "Lin Tan", "Xiangyu Zhang"], "title": "CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been widely adopted across diverse software\nengineering domains, such as code generation, program repair, and vulnerability\ndetection. These applications require understanding beyond surface-level code\npatterns: value propagation, control flow, and interdependence between program\nelements. However, existing benchmarks primarily evaluate end-to-end outcomes,\nsuch as whether code is correctly repaired or generated, leaving the models\nability for program semantic reasoning underexplored. This work presents CoRe,\na high-quality, human-verified benchmark designed to evaluate LLMs on\nfundamental static analysis tasks. CoRe includes 12,553 task instances spanning\ndata dependency, control dependency, and information flow across programs\nwritten in C/C++, Java, and Python. To ensure semantic diversity and reasoning\ncomplexity, we propose a semantics-aware diverse sampling strategy that selects\ntargets and task instances based on structural coverage and dependency depth.\nWe evaluate 10 mainstream LLMs and show that, while they perform well at\nidentifying dependencies, models still struggle with tasks that require deeper\nsemantic understanding and multi-step reasoning. We further conduct qualitative\nanalyses to uncover key challenges, such as complex control structures and\nbackward dependency patterns, offering insights into improving LLMs code\nreasoning capabilities.", "AI": {"tldr": "CoRe\u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u3001\u4eba\u5de5\u9a8c\u8bc1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9759\u6001\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5176\u5728\u6df1\u5c42\u8bed\u4e49\u63a8\u7406\u548c\u591a\u6b65\u63a8\u7406\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u7aef\u5230\u7aef\u7ed3\u679c\uff08\u5982\u4ee3\u7801\u4fee\u590d\u6216\u751f\u6210\uff09\uff0c\u4f46\u672a\u5145\u5206\u63a2\u7d22LLM\u5bf9\u7a0b\u5e8f\u8bed\u4e49\u63a8\u7406\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faCoRe\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec12,553\u4e2a\u4efb\u52a1\u5b9e\u4f8b\uff0c\u8986\u76d6C/C++\u3001Java\u548cPython\uff0c\u91c7\u7528\u8bed\u4e49\u611f\u77e5\u7684\u591a\u6837\u6027\u91c7\u6837\u7b56\u7565\u3002", "result": "\u8bc4\u4f3010\u4e2a\u4e3b\u6d41LLM\u53d1\u73b0\uff0c\u5b83\u4eec\u5728\u8bc6\u522b\u4f9d\u8d56\u5173\u7cfb\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6df1\u5c42\u8bed\u4e49\u7406\u89e3\u548c\u591a\u6b65\u63a8\u7406\u4e0a\u4ecd\u6709\u56f0\u96be\u3002", "conclusion": "\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u590d\u6742\u63a7\u5236\u7ed3\u6784\u548c\u53cd\u5411\u4f9d\u8d56\u6a21\u5f0f\u662f\u4e3b\u8981\u6311\u6218\uff0c\u4e3a\u63d0\u5347LLM\u7684\u4ee3\u7801\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2507.05270", "pdf": "https://arxiv.org/pdf/2507.05270", "abs": "https://arxiv.org/abs/2507.05270", "authors": ["Boyuan Li", "Chengwei Liu", "Lingling Fan", "Sen Chen", "Zhenlin Zhang", "Zheli Liu"], "title": "Open Source, Hidden Costs: A Systematic Literature Review on OSS License Management", "categories": ["cs.SE"], "comment": null, "summary": "Integrating third-party software components is a common practice in modern\nsoftware development, offering significant advantages in terms of efficiency\nand innovation. However, this practice is fraught with risks related to\nsoftware licensing. A lack of understanding may lead to disputes, which can\npose serious legal and operational challenges. To these ends, both academia and\nindustry have conducted various investigations and proposed solutions and tools\nto deal with these challenges. However, significant limitations still remain.\nMoreover, the rapid evolution of open-source software (OSS) licenses, as well\nas the rapidly incorporated generative software engineering techniques, such as\nlarge language models for code (CodeLLMs), are placing greater demands on the\nsystematic management of software license risks. To unveil the severe\nchallenges and explore possible future directions, we conduct the first\nsystematic literature review (SLR) on 80 carefully selected OSS license-related\npapers, classifying existing research into three key categories, i.e., license\nidentification, license risk assessment, and license risk mitigation. Based on\nthese, we discuss challenges in existing solutions, conclude the opportunities\nto shed light on future research directions and offer practical recommendations\nfor practitioners. We hope this thorough review will help bridge the gaps\nbetween academia and industry and accelerate the ecosystem-wide governance of\nlegitimate software risks within the software engineering community.", "AI": {"tldr": "\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u96c6\u6210\u7b2c\u4e09\u65b9\u8f6f\u4ef6\u7ec4\u4ef6\u662f\u5e38\u89c1\u505a\u6cd5\uff0c\u867d\u7136\u9ad8\u6548\u4e14\u521b\u65b0\uff0c\u4f46\u4e5f\u4f34\u968f\u8f6f\u4ef6\u8bb8\u53ef\u98ce\u9669\u3002\u672c\u6587\u901a\u8fc780\u7bc7\u76f8\u5173\u6587\u732e\u7684\u7cfb\u7edf\u7efc\u8ff0\uff0c\u7814\u7a76\u8bb8\u53ef\u8bc6\u522b\u3001\u98ce\u9669\u8bc4\u4f30\u4e0e\u7f13\u89e3\uff0c\u63a2\u8ba8\u672a\u6765\u7814\u7a76\u65b9\u5411\u4e0e\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u63ed\u793a\u5f00\u6e90\u8f6f\u4ef6\uff08OSS\uff09\u8bb8\u53ef\u98ce\u9669\u7684\u4e25\u5cfb\u6311\u6218\uff0c\u63a2\u7d22\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u5b66\u672f\u754c\u548c\u4ea7\u4e1a\u754c\u63d0\u4f9b\u7cfb\u7edf\u5316\u7ba1\u7406\u8f6f\u4ef6\u8bb8\u53ef\u98ce\u9669\u7684\u5efa\u8bae\u3002", "method": "\u5bf980\u7bc7\u7cbe\u9009\u7684OSS\u8bb8\u53ef\u76f8\u5173\u6587\u732e\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\uff08SLR\uff09\uff0c\u5c06\u7814\u7a76\u5206\u4e3a\u8bb8\u53ef\u8bc6\u522b\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u98ce\u9669\u7f13\u89e3\u4e09\u7c7b\u3002", "result": "\u603b\u7ed3\u4e86\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u5b9e\u8df5\u5efa\u8bae\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u7f29\u5c0f\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u7684\u5dee\u8ddd\uff0c\u52a0\u901f\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u5bf9\u5408\u6cd5\u8f6f\u4ef6\u98ce\u9669\u7684\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u3002"}}
{"id": "2507.05272", "pdf": "https://arxiv.org/pdf/2507.05272", "abs": "https://arxiv.org/abs/2507.05272", "authors": ["Daragh King", "Vasileios Koutavas", "Laura Kovacs"], "title": "FuzzFeed: An Automatic Approach to Weakest Precondition Generation using LLMs and Fuzzing", "categories": ["cs.SE", "cs.AI", "cs.LO"], "comment": null, "summary": "The weakest precondition (WP) of a program describes the largest set of\ninitial states from which all terminating executions of the program satisfy a\ngiven postcondition. The generation of WPs is an important task with practical\napplications in areas ranging from verification to run-time error checking.\n  This paper proposes the combination of Large Language Models (LLMs) and fuzz\ntesting for generating WPs. In pursuit of this goal, we introduce Fuzzing\nGuidance (FG); FG acts as a means of directing LLMs towards correct WPs using\nprogram execution feedback. FG utilises fuzz testing for approximately checking\nthe validity and weakness of candidate WPs, this information is then fed back\nto the LLM as a means of context refinement.\n  We demonstrate the effectiveness of our approach on a comprehensive benchmark\nset of deterministic array programs in Java. Our experiments indicate that LLMs\nare capable of producing viable candidate WPs, and that this ability can be\npractically enhanced through FG.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u6a21\u7cca\u6d4b\u8bd5\u751f\u6210\u6700\u5f31\u524d\u7f6e\u6761\u4ef6\uff08WP\uff09\uff0c\u5e76\u901a\u8fc7\u6a21\u7cca\u6307\u5bfc\uff08FG\uff09\u5229\u7528\u7a0b\u5e8f\u6267\u884c\u53cd\u9988\u4f18\u5316LLM\u751f\u6210\u7684WP\u3002", "motivation": "\u6700\u5f31\u524d\u7f6e\u6761\u4ef6\u7684\u751f\u6210\u5728\u9a8c\u8bc1\u548c\u8fd0\u884c\u65f6\u9519\u8bef\u68c0\u67e5\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u5b58\u5728\u6548\u7387\u6216\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6a21\u7cca\u6d4b\u8bd5\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u7cca\u6307\u5bfc\uff08FG\uff09\u5229\u7528\u7a0b\u5e8f\u6267\u884c\u53cd\u9988\u4f18\u5316LLM\u751f\u6210\u7684\u5019\u9009WP\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u786e\u5b9a\u6027\u6570\u7ec4\u7a0b\u5e8f\u4e0a\uff0cLLM\u80fd\u591f\u751f\u6210\u53ef\u884c\u7684\u5019\u9009WP\uff0c\u800cFG\u53ef\u663e\u8457\u63d0\u5347\u8fd9\u4e00\u80fd\u529b\u3002", "conclusion": "LLMs\u7ed3\u5408FG\u7684\u65b9\u6cd5\u5728\u751f\u6210\u6700\u5f31\u524d\u7f6e\u6761\u4ef6\u65b9\u9762\u8868\u73b0\u51fa\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.05279", "pdf": "https://arxiv.org/pdf/2507.05279", "abs": "https://arxiv.org/abs/2507.05279", "authors": ["Virgile Boraud", "Yannis Bendi-Ouis", "Paul Bernard", "Xavier Hinaut"], "title": "ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.NE"], "comment": null, "summary": "We introduce a tool designed to improve the capabilities of Large Language\nModels (LLMs) in assisting with code development using the ReservoirPy library,\nas well as in answering complex questions in the field of Reservoir Computing.\nBy incorporating external knowledge through Retrieval-Augmented Generation\n(RAG) and knowledge graphs, our approach aims to reduce hallucinations and\nincrease the factual accuracy of generated responses. The system provides an\ninteractive experience similar to ChatGPT, tailored specifically for\nReservoirPy, enabling users to write, debug, and understand Python code while\naccessing reliable domain-specific insights. In our evaluation, while\nproprietary models such as ChatGPT-4o and NotebookLM performed slightly better\non general knowledge questions, our model outperformed them on coding tasks and\nshowed a significant improvement over its base model, Codestral-22B.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u6b3e\u5de5\u5177\uff0c\u65e8\u5728\u901a\u8fc7RAG\u548c\u77e5\u8bc6\u56fe\u8c31\u63d0\u5347LLM\u5728\u4ee3\u7801\u5f00\u53d1\u548c\u50a8\u5c42\u8ba1\u7b97\u9886\u57df\u95ee\u7b54\u7684\u80fd\u529b\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u7279\u5b9a\u9886\u57df\uff08\u5982ReservoirPy\uff09\u4ee3\u7801\u5f00\u53d1\u548c\u95ee\u7b54\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u5176\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u7ed3\u5408RAG\u548c\u77e5\u8bc6\u56fe\u8c31\uff0c\u8bbe\u8ba1\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u4e13\u6ce8\u4e8eReservoirPy\u7684\u4ee3\u7801\u7f16\u5199\u3001\u8c03\u8bd5\u548c\u9886\u57df\u77e5\u8bc6\u95ee\u7b54\u3002", "result": "\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u4f18\u4e8eChatGPT-4o\u548cNotebookLM\uff0c\u4e14\u5728\u57fa\u7840\u6a21\u578bCodestral-22B\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u5177\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u5347\u901a\u7528\u6027\u3002"}}
{"id": "2507.05304", "pdf": "https://arxiv.org/pdf/2507.05304", "abs": "https://arxiv.org/abs/2507.05304", "authors": ["Saqib Nazir", "Olivier L\u00e9zoray", "S\u00e9bastien Bougleux"], "title": "Self-Attention Based Multi-Scale Graph Auto-Encoder Network of 3D Meshes", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": null, "summary": "3D meshes are fundamental data representations for capturing complex\ngeometric shapes in computer vision and graphics applications. While\nConvolutional Neural Networks (CNNs) have excelled in structured data like\nimages, extending them to irregular 3D meshes is challenging due to the\nnon-Euclidean nature of the data. Graph Convolutional Networks (GCNs) offer a\nsolution by applying convolutions to graph-structured data, but many existing\nmethods rely on isotropic filters or spectral decomposition, limiting their\nability to capture both local and global mesh features. In this paper, we\nintroduce 3D Geometric Mesh Network (3DGeoMeshNet), a novel GCN-based framework\nthat uses anisotropic convolution layers to effectively learn both global and\nlocal features directly in the spatial domain. Unlike previous approaches that\nconvert meshes into intermediate representations like voxel grids or point\nclouds, our method preserves the original polygonal mesh format throughout the\nreconstruction process, enabling more accurate shape reconstruction. Our\narchitecture features a multi-scale encoder-decoder structure, where separate\nglobal and local pathways capture both large-scale geometric structures and\nfine-grained local details. Extensive experiments on the COMA dataset\ncontaining human faces demonstrate the efficiency of 3DGeoMeshNet in terms of\nreconstruction accuracy.", "AI": {"tldr": "3DGeoMeshNet\u662f\u4e00\u79cd\u57fa\u4e8eGCN\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5404\u5411\u5f02\u6027\u5377\u79ef\u5c42\u5728\u7a7a\u95f4\u57df\u4e2d\u5b66\u4e60\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\uff0c\u76f4\u63a5\u5728\u539f\u59cb\u591a\u8fb9\u5f62\u7f51\u683c\u683c\u5f0f\u4e0a\u8fdb\u884c\u64cd\u4f5c\uff0c\u63d0\u9ad8\u4e86\u91cd\u5efa\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684GCN\u65b9\u6cd5\u5728\u5904\u74063D\u7f51\u683c\u65f6\u4f9d\u8d56\u5404\u5411\u540c\u6027\u6ee4\u6ce2\u5668\u6216\u9891\u8c31\u5206\u89e3\uff0c\u65e0\u6cd5\u540c\u65f6\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\uff0c\u4e14\u901a\u5e38\u9700\u8f6c\u6362\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u5bfc\u81f4\u91cd\u5efa\u4e0d\u51c6\u786e\u30023DGeoMeshNet\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "3DGeoMeshNet\u91c7\u7528\u57fa\u4e8eGCN\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u5404\u5411\u5f02\u6027\u5377\u79ef\u5c42\u548c\u591a\u5c3a\u5ea6\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u76f4\u63a5\u5728\u539f\u59cb\u7f51\u683c\u4e0a\u64cd\u4f5c\uff0c\u901a\u8fc7\u5168\u5c40\u548c\u5c40\u90e8\u8def\u5f84\u6355\u6349\u7279\u5f81\u3002", "result": "\u5728COMA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c3DGeoMeshNet\u5728\u91cd\u5efa\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u9ad8\u6548\u3002", "conclusion": "3DGeoMeshNet\u901a\u8fc7\u76f4\u63a5\u5728\u7a7a\u95f4\u57df\u64cd\u4f5c\u539f\u59cb\u7f51\u683c\uff0c\u7ed3\u5408\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u76843D\u5f62\u72b6\u91cd\u5efa\u3002"}}
{"id": "2507.05597", "pdf": "https://arxiv.org/pdf/2507.05597", "abs": "https://arxiv.org/abs/2507.05597", "authors": ["Yiming Zhao", "Xuanqi Meng", "Xinyu Tong", "Xiulong Liu", "Xin Xie", "Wenyu Qu"], "title": "Baton: Compensate for Missing Wi-Fi Features for Practical Device-free Tracking", "categories": ["cs.NI", "eess.SP"], "comment": "17 pages, 20 figures. Accepted and published in IEEE Transactions on\n  Mobile Computing on April 10, 2025. This is the accepted version. Final\n  published version: https://ieeexplore.ieee.org/document/10962318", "summary": "Wi-Fi contact-free sensing systems have attracted widespread attention due to\ntheir ubiquity and convenience. The integrated sensing and communication (ISAC)\ntechnology utilizes off-the-shelf Wi-Fi communication signals for sensing,\nwhich further promotes the deployment of intelligent sensing applications.\nHowever, current Wi-Fi sensing systems often require prolonged and unnecessary\ncommunication between transceivers, and brief communication interruptions will\nlead to significant performance degradation. This paper proposes Baton, the\nfirst system capable of accurately tracking targets even under severe Wi-Fi\nfeature deficiencies. To be specific, we explore the relevance of the Wi-Fi\nfeature matrix from both horizontal and vertical dimensions. The horizontal\ndimension reveals feature correlation across different Wi-Fi links, while the\nvertical dimension reveals feature correlation among different time slots.\nBased on the above principle, we propose the Simultaneous Tracking And\nPredicting (STAP) algorithm, which enables the seamless transfer of Wi-Fi\nfeatures over time and across different links, akin to passing a baton. We\nimplement the system on commercial devices, and the experimental results show\nthat our system outperforms existing solutions with a median tracking error of\n0.46m, even when the communication duty cycle is as low as 20.00%. Compared\nwith the state-of-the-art, our system reduces the tracking error by 79.19% in\nscenarios with severe Wi-Fi feature deficiencies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBaton\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u5728Wi-Fi\u7279\u5f81\u4e25\u91cd\u7f3a\u5931\u7684\u60c5\u51b5\u4e0b\u7cbe\u786e\u8ddf\u8e2a\u76ee\u6807\uff0c\u901a\u8fc7\u6c34\u5e73\u548c\u5782\u76f4\u7ef4\u5ea6\u7684\u76f8\u5173\u6027\u5206\u6790\u4ee5\u53caSTAP\u7b97\u6cd5\u5b9e\u73b0\u7279\u5f81\u65e0\u7f1d\u4f20\u9012\u3002", "motivation": "\u5f53\u524dWi-Fi\u4f20\u611f\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u6301\u7eed\u901a\u4fe1\uff0c\u77ed\u6682\u4e2d\u65ad\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u5728\u7279\u5f81\u7f3a\u5931\u65f6\u4ecd\u80fd\u51c6\u786e\u8ddf\u8e2a\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63a2\u7d22Wi-Fi\u7279\u5f81\u77e9\u9635\u5728\u6c34\u5e73\u548c\u5782\u76f4\u7ef4\u5ea6\u7684\u76f8\u5173\u6027\uff0c\u63d0\u51faSTAP\u7b97\u6cd5\uff0c\u5b9e\u73b0\u7279\u5f81\u5728\u65f6\u95f4\u548c\u4e0d\u540c\u94fe\u8def\u95f4\u7684\u65e0\u7f1d\u4f20\u9012\u3002", "result": "\u5728\u5546\u7528\u8bbe\u5907\u4e0a\u5b9e\u73b0\uff0c\u4e2d\u4f4d\u8ddf\u8e2a\u8bef\u5dee\u4e3a0.46m\uff0c\u901a\u4fe1\u5360\u7a7a\u6bd4\u4ec5\u4e3a20.00%\uff0c\u6bd4\u73b0\u6709\u6280\u672f\u51cf\u5c1179.19%\u7684\u8ddf\u8e2a\u8bef\u5dee\u3002", "conclusion": "Baton\u7cfb\u7edf\u5728Wi-Fi\u7279\u5f81\u4e25\u91cd\u7f3a\u5931\u65f6\u4ecd\u80fd\u9ad8\u6548\u8ddf\u8e2a\u76ee\u6807\uff0c\u8868\u73b0\u51fa\u663e\u8457\u4f18\u8d8a\u6027\u3002"}}
{"id": "2507.05621", "pdf": "https://arxiv.org/pdf/2507.05621", "abs": "https://arxiv.org/abs/2507.05621", "authors": ["Suoxiang Zhang", "Xiaxi Li", "Hongrui Chang", "Zhuoyan Hou", "Guoxin Wu", "Ronghua Ji"], "title": "AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Domain-specific image generation aims to produce high-quality visual content\nfor specialized fields while ensuring semantic accuracy and detail fidelity.\nHowever, existing methods exhibit two critical limitations: First, current\napproaches address prompt engineering and model adaptation separately,\noverlooking the inherent dependence between semantic understanding and visual\nrepresentation in specialized domains. Second, these techniques inadequately\nincorporate domain-specific semantic constraints during content synthesis,\nresulting in generation outcomes that exhibit hallucinations and semantic\ndeviations. To tackle these issues, we propose AdaptaGen, a hierarchical\nsemantic optimization framework that integrates matrix-based prompt\noptimization with multi-perspective understanding, capturing comprehensive\nsemantic relationships from both global and local perspectives. To mitigate\nhallucinations in specialized domains, we design a cross-modal adaptation\nmechanism, which, when combined with intelligent content synthesis, enables\npreserving core thematic elements while incorporating diverse details across\nimages. Additionally, we introduce a two-phase caption semantic transformation\nduring the generation phase. This approach maintains semantic coherence while\nenhancing visual diversity, ensuring the generated images adhere to\ndomain-specific constraints. Experimental results confirm our approach's\neffectiveness, with our framework achieving superior performance across 40\ncategories from diverse datasets using only 16 images per category,\ndemonstrating significant improvements in image quality, diversity, and\nsemantic consistency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdaptaGen\u7684\u5206\u5c42\u8bed\u4e49\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u9886\u57df\u7279\u5b9a\u56fe\u50cf\u751f\u6210\u4e2d\u8bed\u4e49\u51c6\u786e\u6027\u548c\u7ec6\u8282\u4fdd\u771f\u5ea6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u63d0\u793a\u5de5\u7a0b\u548c\u6a21\u578b\u9002\u5e94\u65f6\u5ffd\u89c6\u4e86\u8bed\u4e49\u7406\u89e3\u4e0e\u89c6\u89c9\u8868\u793a\u7684\u5185\u5728\u4f9d\u8d56\uff0c\u4e14\u5728\u5185\u5bb9\u5408\u6210\u4e2d\u672a\u80fd\u5145\u5206\u878d\u5165\u9886\u57df\u7279\u5b9a\u8bed\u4e49\u7ea6\u675f\uff0c\u5bfc\u81f4\u751f\u6210\u7ed3\u679c\u51fa\u73b0\u5e7b\u89c9\u548c\u8bed\u4e49\u504f\u5dee\u3002", "method": "AdaptaGen\u7ed3\u5408\u77e9\u9635\u5316\u63d0\u793a\u4f18\u5316\u4e0e\u591a\u89c6\u89d2\u7406\u89e3\uff0c\u8bbe\u8ba1\u8de8\u6a21\u6001\u9002\u5e94\u673a\u5236\u548c\u4e24\u9636\u6bb5\u6807\u9898\u8bed\u4e49\u8f6c\u6362\uff0c\u4ee5\u589e\u5f3a\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u89c6\u89c9\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cAdaptaGen\u5728\u4f7f\u7528\u6bcf\u7c7b\u522b\u4ec516\u5f20\u56fe\u50cf\u7684\u60c5\u51b5\u4e0b\uff0c\u572840\u4e2a\u5206\u7c7b\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u56fe\u50cf\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "AdaptaGen\u901a\u8fc7\u96c6\u6210\u8bed\u4e49\u4f18\u5316\u548c\u8de8\u6a21\u6001\u9002\u5e94\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9886\u57df\u7279\u5b9a\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.05446", "pdf": "https://arxiv.org/pdf/2507.05446", "abs": "https://arxiv.org/abs/2507.05446", "authors": ["Ben Boudaoud", "Josef Spjut", "Joohwan Kim", "Arjun Madhusudan", "Benjamin Watson"], "title": "Esports and expertise: what competitive gaming can teach us about mastery", "categories": ["cs.HC"], "comment": null, "summary": "Historically, much research and development in human computer interaction has\nfocused on atomic and generalizable tasks, where task completion time indicates\nproductivity. However, the emergence of competitive games and esports reminds\nus of an alternative perspective on human performance in HCI: mastery of\nhigher-level, holistic practices. Just as a world-renowned artist is rarely\nevaluated for their individual brush strokes, so skilled competitive gamers\nrarely succeed solely by completing individual mouse movements or keystrokes as\nquickly as possible. Instead, they optimize more task-specific skills, adeptly\nperforming challenges deep in the learning curve for their game of choice.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u4e86\u4eba\u673a\u4ea4\u4e92\u7814\u7a76\u4e2d\u4ece\u539f\u5b50\u5316\u4efb\u52a1\u5230\u66f4\u9ad8\u5c42\u6b21\u7efc\u5408\u6280\u80fd\u7684\u8f6c\u53d8\uff0c\u63d0\u51fa\u5728\u7535\u7ade\u7b49\u9886\u57df\u7684\u8868\u73b0\u66f4\u4f9d\u8d56\u4e8e\u5bf9\u7279\u5b9a\u4efb\u52a1\u6280\u80fd\u7684\u638c\u63e1\u3002", "motivation": "\u4f20\u7edf\u4eba\u673a\u4ea4\u4e92\u7814\u7a76\u5173\u6ce8\u539f\u5b50\u5316\u548c\u901a\u7528\u4efb\u52a1\uff0c\u4f46\u7535\u7ade\u7684\u5174\u8d77\u8868\u660e\u4eba\u7c7b\u8868\u73b0\u66f4\u4f9d\u8d56\u4e8e\u9ad8\u5c42\u6b21\u3001\u7efc\u5408\u6280\u80fd\u7684\u638c\u63e1\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u4f20\u7edf\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u4e0e\u7535\u7ade\u4e2d\u6280\u80fd\u8868\u73b0\uff0c\u5206\u6790\u4eba\u7c7b\u5728\u9ad8\u5c42\u6b21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6307\u51fa\u5728\u7535\u7ade\u7b49\u9886\u57df\uff0c\u6210\u529f\u4f9d\u8d56\u4e8e\u5bf9\u7279\u5b9a\u4efb\u52a1\u6280\u80fd\u7684\u4f18\u5316\uff0c\u800c\u975e\u5355\u7eaf\u7684\u5feb\u901f\u5b8c\u6210\u539f\u5b50\u5316\u4efb\u52a1\u3002", "conclusion": "\u4eba\u673a\u4ea4\u4e92\u7814\u7a76\u9700\u4ece\u539f\u5b50\u5316\u4efb\u52a1\u6269\u5c55\u5230\u66f4\u9ad8\u5c42\u6b21\u7684\u7efc\u5408\u6280\u80fd\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u7406\u89e3\u4eba\u7c7b\u8868\u73b0\u3002"}}
{"id": "2506.19866", "pdf": "https://arxiv.org/pdf/2506.19866", "abs": "https://arxiv.org/abs/2506.19866", "authors": ["Joyce Reimer", "Pranta Saha", "Chris Chen", "Neeraj Dhar", "Brook Byrns", "Steven Rayan", "Gordon Broderick"], "title": "GPU-accelerated Modeling of Biological Regulatory Networks", "categories": ["q-bio.MN", "cs.PF", "math.OC", "q-bio.QM"], "comment": "10 pages, 5 figures, 2 tables; submitted to 16th ACM Conference on\n  Bioinformatics, Computational Biology, and Health Informatics (ACM BCB 2025)\n  as submission no. 6", "summary": "The complex regulatory dynamics of a biological network can be succinctly\ncaptured using discrete logic models. Given even sparse time-course data from\nthe system of interest, previous work has shown that global optimization\nschemes are suitable for proposing logic models that explain the data and make\npredictions about how the system will behave under varying conditions.\nConsidering the large scale of the parameter search spaces associated with\nthese regulatory systems, performance optimizations on the level of both\nhardware and software are necessary for making this a practical tool for in\nsilico pharmaceutical research. We show here how the implementation of these\nglobal optimization algorithms in a GPU-computing environment can accelerate\nthe solution of these parameter search problems considerably. We carry out\nparameter searches on two model biological regulatory systems that represent\nalmost an order of magnitude scale-up in complexity, and we find the gains in\nefficiency from GPU to be a 33%-43% improvement compared to multi-thread CPU\nimplementations and a 33%-1866% increase compared to CPU in serial. These\nimprovements make global optimization of logic model identification a far more\nattractive and feasible method for in silico hypothesis generation and design\nof experiments.", "AI": {"tldr": "\u4f7f\u7528GPU\u52a0\u901f\u5168\u5c40\u4f18\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u751f\u7269\u7f51\u7edc\u79bb\u6563\u903b\u8f91\u6a21\u578b\u53c2\u6570\u641c\u7d22\u7684\u6548\u7387\u3002", "motivation": "\u751f\u7269\u7f51\u7edc\u7684\u590d\u6742\u8c03\u63a7\u52a8\u6001\u9700\u8981\u901a\u8fc7\u79bb\u6563\u903b\u8f91\u6a21\u578b\u9ad8\u6548\u6355\u6349\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u4f4e\uff0c\u9650\u5236\u4e86\u5176\u5728\u836f\u7269\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5728GPU\u8ba1\u7b97\u73af\u5883\u4e2d\u5b9e\u73b0\u5168\u5c40\u4f18\u5316\u7b97\u6cd5\uff0c\u9488\u5bf9\u4e24\u4e2a\u590d\u6742\u5ea6\u4e0d\u540c\u7684\u751f\u7269\u8c03\u63a7\u7cfb\u7edf\u8fdb\u884c\u53c2\u6570\u641c\u7d22\u3002", "result": "GPU\u5b9e\u73b0\u7684\u6548\u7387\u6bd4\u591a\u7ebf\u7a0bCPU\u63d0\u9ad833%-43%\uff0c\u6bd4\u4e32\u884cCPU\u63d0\u9ad833%-1866%\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u8bc6\u522b\u7684\u53ef\u884c\u6027\u3002", "conclusion": "GPU\u52a0\u901f\u4f7f\u5168\u5c40\u4f18\u5316\u65b9\u6cd5\u66f4\u5b9e\u7528\uff0c\u4e3a\u8ba1\u7b97\u673a\u836f\u7269\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u5047\u8bbe\u751f\u6210\u5de5\u5177\u3002"}}
{"id": "2507.05886", "pdf": "https://arxiv.org/pdf/2507.05886", "abs": "https://arxiv.org/abs/2507.05886", "authors": ["Aaron Bembenek"], "title": "Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better", "categories": ["cs.AI", "cs.PL"], "comment": "6 pages, 4 figures", "summary": "There is growing excitement about building software verifiers, synthesizers,\nand other Automated Reasoning (AR) tools by combining traditional symbolic\nalgorithms and Large Language Models (LLMs). Unfortunately, the current\npractice for constructing such neurosymbolic AR systems is an ad hoc\nprogramming model that does not have the strong guarantees of traditional\nsymbolic algorithms, nor a deep enough synchronization of neural networks and\nsymbolic reasoning to unlock the full potential of LLM-powered reasoning. I\npropose Neurosymbolic Transition Systems as a principled computational model\nthat can underlie infrastructure for building neurosymbolic AR tools. In this\nmodel, symbolic state is paired with intuition, and state transitions operate\nover symbols and intuition in parallel. I argue why this new paradigm can scale\nlogical reasoning beyond current capabilities while retaining the strong\nguarantees of symbolic algorithms, and I sketch out how the computational model\nI propose can be reified in a logic programming language.", "AI": {"tldr": "\u63d0\u51fa\u4e86Neurosymbolic Transition Systems\u4f5c\u4e3a\u4e00\u79cd\u539f\u5219\u6027\u8ba1\u7b97\u6a21\u578b\uff0c\u7528\u4e8e\u6784\u5efa\u795e\u7ecf\u7b26\u53f7\u81ea\u52a8\u63a8\u7406\u5de5\u5177\uff0c\u7ed3\u5408\u7b26\u53f7\u72b6\u6001\u4e0e\u76f4\u89c9\uff0c\u5e76\u884c\u64cd\u4f5c\u7b26\u53f7\u4e0e\u76f4\u89c9\uff0c\u4ee5\u6269\u5c55\u903b\u8f91\u63a8\u7406\u80fd\u529b\u5e76\u4fdd\u7559\u7b26\u53f7\u7b97\u6cd5\u7684\u5f3a\u4fdd\u8bc1\u3002", "motivation": "\u5f53\u524d\u6784\u5efa\u795e\u7ecf\u7b26\u53f7\u81ea\u52a8\u63a8\u7406\u7cfb\u7edf\u7684\u5b9e\u8df5\u7f3a\u4e4f\u4f20\u7edf\u7b26\u53f7\u7b97\u6cd5\u7684\u5f3a\u4fdd\u8bc1\uff0c\u4e14\u672a\u80fd\u5145\u5206\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7b26\u53f7\u63a8\u7406\uff0c\u9650\u5236\u4e86LLM\u63a8\u7406\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faNeurosymbolic Transition Systems\u4f5c\u4e3a\u8ba1\u7b97\u6a21\u578b\uff0c\u7ed3\u5408\u7b26\u53f7\u72b6\u6001\u4e0e\u76f4\u89c9\uff0c\u5e76\u884c\u64cd\u4f5c\u7b26\u53f7\u4e0e\u76f4\u89c9\uff0c\u5e76\u901a\u8fc7\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\u5b9e\u73b0\u3002", "result": "\u8be5\u6a21\u578b\u80fd\u6269\u5c55\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u7b26\u53f7\u7b97\u6cd5\u7684\u5f3a\u4fdd\u8bc1\uff0c\u4e3a\u6784\u5efa\u795e\u7ecf\u7b26\u53f7\u81ea\u52a8\u63a8\u7406\u5de5\u5177\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "Neurosymbolic Transition Systems\u4e3a\u795e\u7ecf\u7b26\u53f7\u81ea\u52a8\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u6709\u671b\u89e3\u51b3\u5f53\u524d\u5b9e\u8df5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.05327", "pdf": "https://arxiv.org/pdf/2507.05327", "abs": "https://arxiv.org/abs/2507.05327", "authors": ["Antoine Chambert-Loir", "Mar\u00eda In\u00e9s de Frutos-Fern\u00e1ndez"], "title": "A Formalization of Divided Powers in Lean", "categories": ["cs.LO", "math.AC", "14F30 (Primary) 13J05 (Secondary)"], "comment": "16th International Conference on Interactive Theorem Proving (ITP\n  '25), 2025, Reykjavik, Iceland", "summary": "Given an ideal $I$ in a commutative ring $A$, a divided power structure on\n$I$ is a collection of maps $\\{\\gamma_n \\colon I \\to A\\}_{n \\in \\mathbb{N}}$,\nsubject to axioms that imply that it behaves like the family $\\{x \\mapsto\n\\frac{x^n}{n!}\\}_{n \\in \\mathbb{N}}$, but which can be defined even when\ndivision by factorials is not possible in $A$. Divided power structures have\nimportant applications in diverse areas of mathematics, including algebraic\ntopology, number theory and algebraic geometry.\n  In this article we describe a formalization in Lean 4 of the basic theory of\ndivided power structures, including divided power morphisms and sub-divided\npower ideals, and we provide several fundamental constructions, in particular\nquotients and sums. This constitutes the first formalization of this theory in\nany theorem prover.\n  As a prerequisite of general interest, we expand the formalized theory of\nmultivariate power series rings, endowing them with a topology and defining\nevaluation and substitution of power series.", "AI": {"tldr": "\u672c\u6587\u5728 Lean 4 \u4e2d\u5bf9\u5e42\u9664\u7ed3\u6784\u7684\u7406\u8bba\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\uff0c\u5305\u62ec\u5e42\u9664\u540c\u6001\u548c\u5b50\u5e42\u9664\u7406\u60f3\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6784\u9020\uff08\u5982\u5546\u548c\u548c\uff09\uff0c\u8fd9\u662f\u9996\u6b21\u5728\u4efb\u4f55\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5bf9\u8be5\u7406\u8bba\u7684\u5f62\u5f0f\u5316\u3002", "motivation": "\u5e42\u9664\u7ed3\u6784\u5728\u4ee3\u6570\u62d3\u6251\u3001\u6570\u8bba\u548c\u4ee3\u6570\u51e0\u4f55\u7b49\u591a\u4e2a\u6570\u5b66\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u5176\u5f62\u5f0f\u5316\u7406\u8bba\u5c1a\u672a\u5728\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5b9e\u73b0\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u591a\u53d8\u91cf\u5e42\u7ea7\u6570\u73af\u7684\u5f62\u5f0f\u5316\u7406\u8bba\uff08\u5305\u62ec\u62d3\u6251\u7ed3\u6784\u548c\u5e42\u7ea7\u6570\u7684\u6c42\u503c\u4e0e\u66ff\u6362\uff09\uff0c\u4f5c\u8005\u5728 Lean 4 \u4e2d\u5b9e\u73b0\u4e86\u5e42\u9664\u7ed3\u6784\u7684\u57fa\u672c\u7406\u8bba\u3002", "result": "\u6210\u529f\u5f62\u5f0f\u5316\u4e86\u5e42\u9664\u7ed3\u6784\u7684\u57fa\u672c\u7406\u8bba\uff0c\u5305\u62ec\u5e42\u9664\u540c\u6001\u3001\u5b50\u5e42\u9664\u7406\u60f3\uff0c\u4ee5\u53ca\u5546\u548c\u548c\u7b49\u5173\u952e\u6784\u9020\u3002", "conclusion": "\u672c\u6587\u7684\u5de5\u4f5c\u4e3a\u5e42\u9664\u7ed3\u6784\u7684\u7406\u8bba\u63d0\u4f9b\u4e86\u9996\u4e2a\u5f62\u5f0f\u5316\u5b9e\u73b0\uff0c\u4e3a\u76f8\u5173\u6570\u5b66\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.05403", "pdf": "https://arxiv.org/pdf/2507.05403", "abs": "https://arxiv.org/abs/2507.05403", "authors": ["Shuning Zhang", "Yongjoo Park"], "title": "PBE Meets LLM: When Few Examples Aren't Few-Shot Enough", "categories": ["cs.DB"], "comment": "7 pages, 5 figures, accepted by VLDB QDB'25 workshop", "summary": "Large language models (LLMs) can generate code from natural language\ndescriptions. Their performance is typically evaluated using programming\nbenchmarks that simulate real-world tasks. These benchmarks provide\nspecifications in the form of docstrings, function signatures, or bug reports.\nThe model then generates a program, which is tested against predefined test\ncases. In contrast, Programming by Example (PBE) uses input-output examples as\nthe specification. Traditional PBE systems rely on search-based methods over\nrestricted transformation spaces. They are usually designed for narrow domains\nand fixed input formats. It remains unclear how well LLMs perform on PBE tasks.\n  In this work, we evaluate LLMs on PBE tasks involving tabular data\ntransformations. We prompt models to generate functions that convert an input\ntable to an output table. We test the generated functions on unseen inputs to\nmeasure accuracy. Our study includes multiple LLMs and evaluates different\nprompting strategies, such as one-shot vs. multi-try. We also compare\nperformance with and without PBE-specific knowledge. Finally, we propose a\nhybrid method that calls a traditional PBE solver first, and then falls back to\nLLMs if necessary. Our results show that LLMs support more diverse input\nformats and achieve higher accuracy than conventional methods. However, they\nstruggle with tasks that contain ambiguity. The hybrid approach improves\noverall success by combining the strengths of both approaches.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u57fa\u4e8e\u793a\u4f8b\u7684\u7f16\u7a0b\uff08PBE\uff09\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5904\u7406\u8868\u683c\u6570\u636e\u8f6c\u6362\u4efb\u52a1\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edfPBE\u7cfb\u7edf\u5728\u72ed\u7a84\u9886\u57df\u548c\u56fa\u5b9a\u8f93\u5165\u683c\u5f0f\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4e0d\u6e05\u695aLLMs\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u751f\u6210\u51fd\u6570\u5c06\u8f93\u5165\u8868\u8f6c\u6362\u4e3a\u8f93\u51fa\u8868\uff0c\u6d4b\u8bd5\u591a\u79cdLLMs\u548c\u63d0\u793a\u7b56\u7565\uff08\u5982\u5355\u6b21\u4e0e\u591a\u6b21\u5c1d\u8bd5\uff09\uff0c\u5e76\u6bd4\u8f83\u6709\u65e0PBE\u77e5\u8bc6\u7684\u6548\u679c\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u5148\u8c03\u7528\u4f20\u7edfPBE\u6c42\u89e3\u5668\uff0c\u5fc5\u8981\u65f6\u518d\u4f7f\u7528LLMs\u3002", "result": "LLMs\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u8f93\u5165\u683c\u5f0f\u4e14\u51c6\u786e\u6027\u66f4\u9ad8\uff0c\u4f46\u5904\u7406\u6a21\u7cca\u4efb\u52a1\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u6df7\u5408\u65b9\u6cd5\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\uff0c\u63d0\u9ad8\u4e86\u6574\u4f53\u6210\u529f\u7387\u3002", "conclusion": "LLMs\u5728PBE\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u6df7\u5408\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05308", "pdf": "https://arxiv.org/pdf/2507.05308", "abs": "https://arxiv.org/abs/2507.05308", "authors": ["Zehuan Chen", "Xiangwei Lai"], "title": "High Order Collaboration-Oriented Federated Graph Neural Network for Accurate QoS Prediction", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Predicting Quality of Service (QoS) data crucial for cloud service selection,\nwhere user privacy is a critical concern. Federated Graph Neural Networks\n(FGNNs) can perform QoS data prediction as well as maintaining user privacy.\nHowever, existing FGNN-based QoS predictors commonly implement on-device\ntraining on scattered explicit user-service graphs, thereby failing to utilize\nthe implicit user-user interactions. To address this issue, this study proposes\na high order collaboration-oriented federated graph neural network (HC-FGNN) to\nobtain accurate QoS prediction with privacy preservation. Concretely, it\nmagnifies the explicit user-service graphs following the principle of attention\nmechanism to obtain the high order collaboration, which reflects the implicit\nuser-user interactions. Moreover, it utilizes a lightweight-based message\naggregation way to improve the computational efficiency. The extensive\nexperiments on two QoS datasets from real application indicate that the\nproposed HC-FGNN possesses the advantages of high prediction accurate and\nprivacy protection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u9636\u534f\u4f5c\u7684\u8054\u90a6\u56fe\u795e\u7ecf\u7f51\u7edc\uff08HC-FGNN\uff09\uff0c\u7528\u4e8e\u9690\u79c1\u4fdd\u62a4\u7684QoS\u9884\u6d4b\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u653e\u5927\u7528\u6237-\u670d\u52a1\u56fe\u4ee5\u6355\u6349\u9690\u5f0f\u7528\u6237\u4ea4\u4e92\uff0c\u5e76\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eFGNN\u7684QoS\u9884\u6d4b\u65b9\u6cd5\u672a\u80fd\u5229\u7528\u9690\u5f0f\u7528\u6237-\u7528\u6237\u4ea4\u4e92\uff0c\u4e14\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u53c8\u80fd\u4fdd\u62a4\u9690\u79c1\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHC-FGNN\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u6269\u5c55\u663e\u5f0f\u7528\u6237-\u670d\u52a1\u56fe\u4ee5\u6355\u6349\u9ad8\u9636\u534f\u4f5c\uff08\u9690\u5f0f\u7528\u6237\u4ea4\u4e92\uff09\uff0c\u5e76\u91c7\u7528\u8f7b\u91cf\u7ea7\u6d88\u606f\u805a\u5408\u65b9\u6cd5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9eQoS\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHC-FGNN\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "HC-FGNN\u901a\u8fc7\u6355\u6349\u9690\u5f0f\u7528\u6237\u4ea4\u4e92\u5e76\u4f18\u5316\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684QoS\u9884\u6d4b\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u4e3a\u4e91\u670d\u52a1\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.05523", "pdf": "https://arxiv.org/pdf/2507.05523", "abs": "https://arxiv.org/abs/2507.05523", "authors": ["Furqan Zahoor", "Ibrahim A. Albulushi", "Saleh Bunaiyan", "Anupam Chattopadhyay", "Hesham ElSawy", "Feras Al-Dirini"], "title": "Adaptive Variation-Resilient Random Number Generator for Embedded Encryption", "categories": ["cs.ET", "cond-mat.dis-nn", "cs.CR"], "comment": null, "summary": "With a growing interest in securing user data within the internet-of-things\n(IoT), embedded encryption has become of paramount importance, requiring\nlight-weight high-quality Random Number Generators (RNGs). Emerging stochastic\ndevice technologies produce random numbers from stochastic physical processes\nat high quality, however, their generated random number streams are adversely\naffected by process and supply voltage variations, which can lead to bias in\nthe generated streams. In this work, we present an adaptive variation-resilient\nRNG capable of extracting unbiased encryption-grade random number streams from\nphysically driven entropy sources, for embedded cryptography applications. As a\nproof of concept, we employ a stochastic magnetic tunnel junction (sMTJ) device\nas an entropy source. The impact of variations in the sMTJ is mitigated by\nemploying an adaptive digitizer with an adaptive voltage reference that\ndynamically tracks any stochastic signal drift or deviation, leading to\nunbiased random bit stream generation. The generated unbiased bit streams, due\nto their higher entropy, then only need to undergo simplified post-processing.\nStatistical randomness tests based on the National Institute of Standards and\nTechnology (NIST) test suite are conducted on bit streams obtained using\nsimulations and FPGA entropy source emulation experiments, validating\nencryption-grade randomness at a significantly reduced hardware cost, and\nacross a wide range of process-induced device variations and supply voltage\nfluctuations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u5e94\u6027\u5f3a\u3001\u80fd\u62b5\u6297\u53d8\u5f02\u7684\u968f\u673a\u6570\u751f\u6210\u5668\uff08RNG\uff09\uff0c\u7528\u4e8e\u5d4c\u5165\u5f0f\u52a0\u5bc6\u5e94\u7528\uff0c\u901a\u8fc7\u52a8\u6001\u8ddf\u8e2a\u7269\u7406\u71b5\u6e90\u7684\u4fe1\u53f7\u6f02\u79fb\u6216\u504f\u5dee\uff0c\u751f\u6210\u65e0\u504f\u7684\u968f\u673a\u6570\u6d41\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\uff08IoT\uff09\u4e2d\u5bf9\u7528\u6237\u6570\u636e\u5b89\u5168\u7684\u9700\u6c42\u589e\u957f\uff0c\u5d4c\u5165\u5f0f\u52a0\u5bc6\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8f7b\u91cf\u7ea7\u9ad8\u8d28\u91cf\u7684RNG\u3002\u73b0\u6709\u7684\u968f\u673a\u6570\u751f\u6210\u6280\u672f\u5728\u9ad8\u53d8\u5f02\u73af\u5883\u4e0b\u5bb9\u6613\u4ea7\u751f\u504f\u5dee\u3002", "method": "\u4f7f\u7528\u81ea\u9002\u5e94\u6570\u5b57\u5316\u5668\u548c\u81ea\u9002\u5e94\u7535\u538b\u53c2\u8003\u6765\u52a8\u6001\u8ddf\u8e2a\u968f\u673a\u4fe1\u53f7\u7684\u53d8\u5316\uff0c\u4ece\u800c\u751f\u6210\u65e0\u504f\u7684\u968f\u673a\u6570\u6d41\u3002\u7814\u7a76\u4e2d\u91c7\u7528\u968f\u673a\u78c1\u6027\u96a7\u9053\u7ed3\uff08sMTJ\uff09\u4f5c\u4e3a\u71b5\u6e90\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548cFPGA\u5b9e\u9a8c\uff0c\u751f\u6210\u7684\u968f\u673a\u6570\u6d41\u901a\u8fc7\u4e86NIST\u7edf\u8ba1\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u52a0\u5bc6\u7ea7\u968f\u673a\u6570\u751f\u6210\uff0c\u4e14\u786c\u4ef6\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u7269\u7406\u71b5\u6e90\u5728\u53d8\u5f02\u73af\u5883\u4e0b\u7684\u504f\u5dee\u95ee\u9898\uff0c\u4e3a\u5d4c\u5165\u5f0f\u52a0\u5bc6\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u968f\u673a\u6570\u751f\u6210\u65b9\u6848\u3002"}}
{"id": "2507.05556", "pdf": "https://arxiv.org/pdf/2507.05556", "abs": "https://arxiv.org/abs/2507.05556", "authors": ["Jumin Kim", "Seungmin Baek", "Minbok Wi", "Hwayong Nam", "Michael Jaemin Kim", "Sukhan Lee", "Kyomin Sohn", "Jung Ho Ahn"], "title": "Per-Row Activation Counting on Real Hardware: Demystifying Performance Overheads", "categories": ["cs.AR", "cs.CR"], "comment": "4 pages, 4 figures, to appear at IEEE Computer Architecture Letters", "summary": "Per-Row Activation Counting (PRAC), a DRAM read disturbance mitigation\nmethod, modifies key DRAM timing parameters, reportedly causing significant\nperformance overheads in simulator-based studies. However, given known\ndiscrepancies between simulators and real hardware, real-machine experiments\nare vital for accurate PRAC performance estimation. We present the first\nreal-machine performance analysis of PRAC. After verifying timing modifications\non the latest CPUs using microbenchmarks, our analysis shows that PRAC's\naverage and maximum overheads are just 1.06% and 3.28% for the SPEC CPU2017\nworkloads -- up to 9.15x lower than simulator-based reports. Further, we show\nthat the close page policy minimizes this overhead by effectively hiding the\nelongated DRAM row precharge operations due to PRAC from the critical path.", "AI": {"tldr": "PRAC\u662f\u4e00\u79cdDRAM\u8bfb\u5e72\u6270\u7f13\u89e3\u65b9\u6cd5\uff0c\u5b9e\u9645\u6027\u80fd\u5f00\u9500\u663e\u8457\u4f4e\u4e8e\u6a21\u62df\u5668\u4f30\u7b97\uff0c\u7814\u7a76\u8868\u660e\u91c7\u7528\u5173\u95ed\u9875\u7b56\u7565\u53ef\u8fdb\u4e00\u6b65\u964d\u4f4e\u5f00\u9500\u3002", "motivation": "\u7531\u4e8e\u6a21\u62df\u5668\u4e0e\u771f\u5b9e\u786c\u4ef6\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u901a\u8fc7\u771f\u5b9e\u673a\u5668\u5b9e\u9a8c\u51c6\u786e\u8bc4\u4f30PRAC\u7684\u6027\u80fd\u5f00\u9500\u3002", "method": "\u5728\u6700\u65b0CPU\u4e0a\u9a8c\u8bc1\u65f6\u5e8f\u4fee\u6539\uff0c\u5e76\u4f7f\u7528\u5fae\u57fa\u51c6\u6d4b\u8bd5\u548cSPEC CPU2017\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u5206\u6790\u3002", "result": "PRAC\u7684\u5e73\u5747\u548c\u6700\u5927\u6027\u80fd\u5f00\u9500\u4ec5\u4e3a1.06%\u548c3.28%\uff0c\u6bd4\u6a21\u62df\u5668\u62a5\u544a\u4f4e9.15\u500d\uff0c\u4e14\u5173\u95ed\u9875\u7b56\u7565\u6709\u6548\u9690\u85cf\u4e86\u989d\u5916\u5f00\u9500\u3002", "conclusion": "\u5b9e\u9645\u673a\u5668\u6d4b\u8bd5\u663e\u793aPRAC\u7684\u5f00\u9500\u8fdc\u4f4e\u4e8e\u9884\u671f\uff0c\u5173\u95ed\u9875\u7b56\u7565\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.05281", "pdf": "https://arxiv.org/pdf/2507.05281", "abs": "https://arxiv.org/abs/2507.05281", "authors": ["Lingyue Fu", "Hao Guan", "Bolun Zhang", "Haowei Yuan", "Yaoming Zhu", "Jun Xu", "Zongyu Wang", "Lin Qiu", "Xunliang Cai", "Xuezhi Cao", "Weiwen Liu", "Weinan Zhang", "Yong Yu"], "title": "CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) demonstrate increasingly sophisticated code\nprocessing capabilities, evaluating their performance on engineering-level code\nremains challenging. Existing repository-level benchmarks primarily focus on\nsingle scenarios, such as code generation or bug fixing, without adequately\ncapturing the diversity and complexity of real-world software or project\nengineering workflows. Furthermore, these benchmarks suffer from limited\ncontrollability in question positioning and reliability issues in their\ngenerated test cases. To address these limitations, we present CorePipe, a\nfully automated pipeline that converts repositories into comprehensive test\ncases, and introduce CoreCodeBench, a configurable multi-scenario\nrepository-level benchmark. To simulate real engineering scenarios, CorePipe\ngenerates three types of atomic questions (Development, BugFix, and Test-Driven\nDevelopment) specifically targeting core code segments. These atomic questions\nare further combined into three types of composite questions, with difficulty\nlevels flexibly adjusted through hyperparameter tuning. CoreCodeBench provides\na comprehensive and extensive repository-level benchmark to investigate the\napplicability of LLMs in real-world engineering projects. Experiments with 16\nLLMs across diverse scenarios reveal varying capabilities and offer\nmulti-dimensional insights into LLM performance in engineering contexts. The\ncode for CorePipe is available at\nhttps://github.com/AGI-Eval-Official/CoreCodeBench, and the data for\nCoreCodeBench can be accessed at\nhttps://huggingface.co/collections/tubehhh/corecodebench-68256d2faabf4b1610a08caa.", "AI": {"tldr": "CoreCodeBench\u662f\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u591a\u573a\u666f\u4ed3\u5e93\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u591a\u6837\u6027\u548c\u590d\u6742\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7CorePipe\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6a21\u62df\u771f\u5b9e\u5de5\u7a0b\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u573a\u666f\uff08\u5982\u4ee3\u7801\u751f\u6210\u6216\u9519\u8bef\u4fee\u590d\uff09\uff0c\u672a\u80fd\u5145\u5206\u4f53\u73b0\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u7684\u591a\u6837\u6027\u548c\u590d\u6742\u6027\uff0c\u4e14\u5b58\u5728\u53ef\u63a7\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faCorePipe\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u5c06\u4ed3\u5e93\u8f6c\u5316\u4e3a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u5f00\u53d1CoreCodeBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u4e09\u79cd\u539f\u5b50\u95ee\u9898\uff08\u5f00\u53d1\u3001\u9519\u8bef\u4fee\u590d\u3001\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\uff09\u53ca\u5176\u7ec4\u5408\uff0c\u7075\u6d3b\u8c03\u6574\u96be\u5ea6\u3002", "result": "\u572816\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u4e3a\u5de5\u7a0b\u5e94\u7528\u63d0\u4f9b\u4e86\u591a\u7ef4\u5ea6\u7684\u6027\u80fd\u6d1e\u5bdf\u3002", "conclusion": "CoreCodeBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u5de5\u7a0b\u9879\u76ee\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2507.06109", "pdf": "https://arxiv.org/pdf/2507.06109", "abs": "https://arxiv.org/abs/2507.06109", "authors": ["Seungoh Han", "Jaehoon Jang", "Hyunsu Kim", "Jaeheung Surh", "Junhyung Kwak", "Hyowon Ha", "Kyungdon Joo"], "title": "LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for Panorama-Style Mobile Captures", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Preprint", "summary": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled real-time novel\nview synthesis (NVS) with impressive quality in indoor scenes. However,\nachieving high-fidelity rendering requires meticulously captured images\ncovering the entire scene, limiting accessibility for general users. We aim to\ndevelop a practical 3DGS-based NVS framework using simple panorama-style motion\nwith a handheld camera (e.g., mobile device). While convenient, this\nrotation-dominant motion and narrow baseline make accurate camera pose and 3D\npoint estimation challenging, especially in textureless indoor scenes. To\naddress these challenges, we propose LighthouseGS, a novel framework inspired\nby the lighthouse-like sweeping motion of panoramic views. LighthouseGS\nleverages rough geometric priors, such as mobile device camera poses and\nmonocular depth estimation, and utilizes the planar structures often found in\nindoor environments. We present a new initialization method called plane\nscaffold assembly to generate consistent 3D points on these structures,\nfollowed by a stable pruning strategy to enhance geometry and optimization\nstability. Additionally, we introduce geometric and photometric corrections to\nresolve inconsistencies from motion drift and auto-exposure in mobile devices.\nTested on collected real and synthetic indoor scenes, LighthouseGS delivers\nphotorealistic rendering, surpassing state-of-the-art methods and demonstrating\nthe potential for panoramic view synthesis and object placement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e3D\u9ad8\u65af\u7403\u9762\u6295\u5f71\uff083DGS\uff09\u7684\u65b0\u578b\u89c6\u56fe\u5408\u6210\u6846\u67b6LighthouseGS\uff0c\u9002\u7528\u4e8e\u624b\u6301\u8bbe\u5907\u62cd\u6444\u7684\u5ba4\u5185\u5168\u666f\u56fe\u50cf\uff0c\u89e3\u51b3\u4e86\u7a84\u57fa\u7ebf\u548c\u7eb9\u7406\u7f3a\u5931\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u67093DGS\u65b9\u6cd5\u9700\u8981\u7cbe\u7ec6\u62cd\u6444\u7684\u5b8c\u6574\u573a\u666f\u56fe\u50cf\uff0c\u9650\u5236\u4e86\u666e\u901a\u7528\u6237\u7684\u4f7f\u7528\uff1b\u5e0c\u671b\u901a\u8fc7\u7b80\u5355\u7684\u5168\u666f\u5f0f\u624b\u6301\u8bbe\u5907\u62cd\u6444\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u89c6\u56fe\u5408\u6210\u3002", "method": "\u5229\u7528\u7c97\u7565\u7684\u51e0\u4f55\u5148\u9a8c\uff08\u8bbe\u5907\u4f4d\u59ff\u548c\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\uff09\u548c\u5ba4\u5185\u5e73\u9762\u7ed3\u6784\uff0c\u63d0\u51fa\u5e73\u9762\u652f\u67b6\u7ec4\u88c5\u521d\u59cb\u5316\u65b9\u6cd5\u548c\u7a33\u5b9a\u526a\u679d\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u51e0\u4f55\u4e0e\u5149\u5ea6\u6821\u6b63\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u7684\u5ba4\u5185\u573a\u666f\u4e2d\u6d4b\u8bd5\uff0cLighthouseGS\u5b9e\u73b0\u4e86\u903c\u771f\u7684\u6e32\u67d3\u6548\u679c\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LighthouseGS\u4e3a\u5168\u666f\u89c6\u56fe\u5408\u6210\u548c\u7269\u4f53\u653e\u7f6e\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05731", "pdf": "https://arxiv.org/pdf/2507.05731", "abs": "https://arxiv.org/abs/2507.05731", "authors": ["Yuxin Zhang", "Jiahao Yang", "Zhe Chen", "Wenjun Zhu", "Jin Zhao", "Yue Gao"], "title": "A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": "11 pages, 12 figures", "summary": "Recently, large vision-language models (LVLMs) unleash powerful analysis\ncapabilities for low Earth orbit (LEO) satellite Earth observation images in\nthe data center. However, fast satellite motion, brief satellite-ground station\n(GS) contact windows, and large size of the images pose a data download\nchallenge. To enable near real-time Earth observation applications (e.g.,\ndisaster and extreme weather monitoring), we should explore how to deploy LVLM\nin LEO satellite networks, and design SpaceVerse, an efficient satellite-ground\nsynergistic LVLM inference system. To this end, firstly, we deploy compact\nLVLMs on satellites for lightweight tasks, whereas regular LVLMs operate on GSs\nto handle computationally intensive tasks. Then, we propose a computing and\ncommunication co-design framework comprised of a progressive confidence network\nand an attention-based multi-scale preprocessing, used to identify on-satellite\ninferring data, and reduce data redundancy before satellite-GS transmission,\nseparately. We implement and evaluate SpaceVerse on real-world LEO satellite\nconstellations and datasets, achieving a 31.2% average gain in accuracy and a\n51.2% reduction in latency compared to state-of-the-art baselines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SpaceVerse\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u536b\u661f\u548c\u5730\u9762\u7ad9\u534f\u540c\u90e8\u7f72\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\uff0c\u4ee5\u89e3\u51b3\u536b\u661f\u56fe\u50cf\u4e0b\u8f7d\u548c\u5b9e\u65f6\u5206\u6790\u7684\u6311\u6218\u3002", "motivation": "\u536b\u661f\u5feb\u901f\u8fd0\u52a8\u3001\u77ed\u6682\u7684\u536b\u661f-\u5730\u9762\u7ad9\u63a5\u89e6\u7a97\u53e3\u548c\u5927\u56fe\u50cf\u5c3a\u5bf8\u5bfc\u81f4\u6570\u636e\u4e0b\u8f7d\u56f0\u96be\uff0c\u9700\u8981\u652f\u6301\u8fd1\u5b9e\u65f6\u5730\u7403\u89c2\u6d4b\u5e94\u7528\uff08\u5982\u707e\u5bb3\u76d1\u6d4b\uff09\u3002", "method": "\u5728\u536b\u661f\u4e0a\u90e8\u7f72\u8f7b\u91cf\u7ea7LVLM\u5904\u7406\u7b80\u5355\u4efb\u52a1\uff0c\u5730\u9762\u7ad9\u5904\u7406\u590d\u6742\u4efb\u52a1\uff1b\u63d0\u51fa\u8ba1\u7b97\u4e0e\u901a\u4fe1\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u5305\u62ec\u6e10\u8fdb\u7f6e\u4fe1\u7f51\u7edc\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u591a\u5c3a\u5ea6\u9884\u5904\u7406\u3002", "result": "\u5728\u771f\u5b9eLEO\u536b\u661f\u661f\u5ea7\u548c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\uff0c\u5e73\u5747\u7cbe\u5ea6\u63d0\u534731.2%\uff0c\u5ef6\u8fdf\u964d\u4f4e51.2%\u3002", "conclusion": "SpaceVerse\u7cfb\u7edf\u901a\u8fc7\u534f\u540c\u90e8\u7f72\u548c\u4f18\u5316\u8bbe\u8ba1\uff0c\u6709\u6548\u63d0\u5347\u4e86\u536b\u661f\u56fe\u50cf\u5206\u6790\u7684\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.05715", "pdf": "https://arxiv.org/pdf/2507.05715", "abs": "https://arxiv.org/abs/2507.05715", "authors": ["Guohao Li", "Li Jing", "Jia Wu", "Xuefei Li", "Kai Zhu", "Yue He"], "title": "From ID-based to ID-free: Rethinking ID Effectiveness in Multimodal Collaborative Filtering Recommendation", "categories": ["cs.IR", "cs.MM"], "comment": "ACM MM'25 (Experimental supplementary version)", "summary": "Most existing multimodal collaborative filtering recommendation (MCFRec)\nmethods rely heavily on ID features and multimodal content to enhance\nrecommendation performance. However, this paper reveals that ID features are\neffective but have limited benefits in multimodal collaborative filtering\nrecommendation. Therefore, this paper systematically deconstruct the pros and\ncons of ID features: (i) they provide initial embedding but lack semantic\nrichness, (ii) they provide a unique identifier for each user and item but\nhinder generalization to untrained data, and (iii) they assist in aligning and\nfusing multimodal features but may lead to representation shift. Based on these\ninsights, this paper proposes IDFREE, an ID-free multimodal collaborative\nFiltering REcommEndation baseline. IDFREE replaces ID features with multimodal\nfeatures and positional encodings to generate semantically meaningful ID-free\nembeddings. For ID-free multimodal collaborative filtering, it further proposes\nan adaptive similarity graph module to construct dynamic user-user and\nitem-item graphs based on multimodal features. Then, an augmented user-item\ngraph encoder is proposed to construct more effective user and item encoding.\nFinally, IDFREE achieves inter-multimodal alignment based on the contrastive\nlearning and uses Softmax loss as recommendation loss. Basic experiments on\nthree public datasets demonstrate that IDFREE outperforms existing ID-based\nMCFRec methods, achieving an average performance gain of 72.24% across standard\nmetrics (Recall@5, 10, 20, 50 and NDCG@5, 10, 20, 50). Exploratory and extended\nexperiments further validate our findings on the limitations of ID features in\nMCFRec. The code is released at https://github.com/G-H-Li/IDFREE.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86IDFREE\uff0c\u4e00\u79cd\u65e0ID\u7684\u591a\u6a21\u6001\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u57fa\u7ebf\uff0c\u53d6\u4ee3ID\u7279\u5f81\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u76f8\u4f3c\u56fe\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709MCFRec\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56ID\u7279\u5f81\uff0c\u4f46\u5176\u5728\u591a\u6a21\u6001\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u4e2d\u6548\u679c\u6709\u9650\uff0c\u8bba\u6587\u63ed\u793a\u4e86ID\u7279\u5f81\u7684\u4f18\u7f3a\u70b9\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u7279\u5f81\u548c\u4f4d\u7f6e\u7f16\u7801\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u5d4c\u5165\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u76f8\u4f3c\u56fe\u6a21\u5757\u548c\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u884c\u5bf9\u9f50\u4e0e\u63a8\u8350\u3002", "result": "\u5b9e\u9a8c\u8868\u660eIDFREE\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eID\u7684\u65b9\u6cd5\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u534772.24%\u3002", "conclusion": "ID\u7279\u5f81\u5728\u591a\u6a21\u6001\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u4e2d\u6709\u5c40\u9650\u6027\uff0cIDFREE\u4e3a\u5176\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.05447", "pdf": "https://arxiv.org/pdf/2507.05447", "abs": "https://arxiv.org/abs/2507.05447", "authors": ["Aiur Nanzatov", "Lourdes Pe\u00f1a-Castillo", "Oscar Meruvia-Pastor"], "title": "NRXR-ID: Two-Factor Authentication (2FA) in VR Using Near-Range Extended Reality and Smartphones", "categories": ["cs.HC", "cs.CV", "cs.GR"], "comment": null, "summary": "Two-factor authentication (2FA) has become widely adopted as an efficient and\nsecure way to validate someone's identity online. Two-factor authentication is\ndifficult in virtual reality (VR) because users are usually wearing a\nhead-mounted display (HMD) which does not allow them to see their real-world\nsurroundings. We present NRXR-ID, a technique to implement two-factor\nauthentication while using extended reality systems and smartphones. The\nproposed method allows users to complete an authentication challenge using\ntheir smartphones without removing their HMD. We performed a user study where\nwe explored four types of challenges for users, including a novel\ncheckers-style challenge. Users responded to these challenges under three\ndifferent configurations, including a technique that uses the smartphone to\nsupport gaze-based selection without the use of VR controllers. A 4X3\nwithin-subjects design allowed us to study all the variations proposed. We\ncollected performance metrics and performed user experience questionnaires to\ncollect subjective impressions from 30 participants. Results suggest that the\ncheckers-style visual matching challenge was the most appropriate option,\nfollowed by entering a digital PIN challenge submitted via the smartphone and\nanswered within the VR environment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNRXR-ID\u7684\u6280\u672f\uff0c\u7528\u4e8e\u5728\u865a\u62df\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u53cc\u56e0\u7d20\u8ba4\u8bc1\uff0c\u901a\u8fc7\u667a\u80fd\u624b\u673a\u5b8c\u6210\u8ba4\u8bc1\u6311\u6218\uff0c\u65e0\u9700\u6458\u4e0b\u5934\u6234\u5f0f\u663e\u793a\u5668\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u56fd\u9645\u8df3\u68cb\u5f0f\u89c6\u89c9\u5339\u914d\u6311\u6218\u662f\u6700\u4f73\u9009\u62e9\u3002", "motivation": "\u89e3\u51b3\u865a\u62df\u73b0\u5b9e\u4e2d\u53cc\u56e0\u7d20\u8ba4\u8bc1\u7684\u56f0\u96be\uff0c\u56e0\u4e3a\u7528\u6237\u4f69\u6234\u5934\u6234\u5f0f\u663e\u793a\u5668\u65f6\u65e0\u6cd5\u770b\u5230\u73b0\u5b9e\u73af\u5883\u3002", "method": "\u63d0\u51faNRXR-ID\u6280\u672f\uff0c\u5229\u7528\u667a\u80fd\u624b\u673a\u5b8c\u6210\u8ba4\u8bc1\u6311\u6218\uff0c\u5305\u62ec\u56fd\u9645\u8df3\u68cb\u5f0f\u6311\u6218\u7b49\u56db\u79cd\u7c7b\u578b\uff0c\u5e76\u5728\u4e09\u79cd\u4e0d\u540c\u914d\u7f6e\u4e0b\u6d4b\u8bd5\u3002\u91c7\u75284X3\u88ab\u8bd5\u5185\u8bbe\u8ba1\u3002", "result": "\u56fd\u9645\u8df3\u68cb\u5f0f\u89c6\u89c9\u5339\u914d\u6311\u6218\u8868\u73b0\u6700\u4f73\uff0c\u5176\u6b21\u662f\u667a\u80fd\u624b\u673a\u8f93\u5165PIN\u7801\u7684\u65b9\u5f0f\u3002", "conclusion": "NRXR-ID\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86VR\u73af\u5883\u4e2d\u7684\u53cc\u56e0\u7d20\u8ba4\u8bc1\u95ee\u9898\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.05813", "pdf": "https://arxiv.org/pdf/2507.05813", "abs": "https://arxiv.org/abs/2507.05813", "authors": ["Ferhat Bayar", "Onur Salan", "Erdogan Aydin", "Haci Ilhan"], "title": "Adaptive Communication Through Exploiting RIS, SSK, and CIM for Improved Reliability and Efficiency", "categories": ["cs.IT", "cs.ET", "cs.MS", "cs.PF", "cs.SY", "eess.SY", "math.IT"], "comment": null, "summary": "In this paper, we present a novel communication system model that integrates\nreconfigurable intelligent surfaces (RIS), spatial shift keying (SSK), and code\nindex modulation (CIM) based on Hadamard coding called RIS based transmit\nSSK-CIM (RIS-CIM-TSSK). By leveraging RIS, the system adapts rapidly to dynamic\nenvironments, enhancing error rates and overall reliability. SSK facilitates\nthe transmission of additional passive information while eliminating the need\nfor multiple radio frequency (RF) chains, thereby reducing complexity. CIM\nenhances passive information transmission through frequency domain spreading,\nwhich may increase signal obfuscation. This proposed scheme not only improves\nenergy efficiency but also offers a robust solution for reliable communication\nin modern wireless networks, paving the way for smarter and more adaptable\nimplementations. We consider a suboptimal, low-complexity detector for the\nproposed scheme and also address the blind case for phase adjustment of the\nRIS. Finally, we present the simulation results for the proposed system model\nacross various configurations, including different numbers of receive and\ntransmit antennas, varying reflecting elements of the RIS, and different code\nlengths.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u901a\u4fe1\u7cfb\u7edf\u6a21\u578bRIS-CIM-TSSK\uff0c\u7ed3\u5408\u4e86\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u3001\u7a7a\u95f4\u79fb\u4f4d\u952e\u63a7\uff08SSK\uff09\u548c\u57fa\u4e8eHadamard\u7f16\u7801\u7684\u7801\u7d22\u5f15\u8c03\u5236\uff08CIM\uff09\uff0c\u4ee5\u63d0\u9ad8\u52a8\u6001\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u4ee3\u65e0\u7ebf\u7f51\u7edc\u9700\u8981\u66f4\u667a\u80fd\u548c\u81ea\u9002\u5e94\u7684\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u80fd\u6548\u3002\u901a\u8fc7\u6574\u5408RIS\u3001SSK\u548cCIM\uff0c\u7cfb\u7edf\u80fd\u591f\u5feb\u901f\u9002\u5e94\u52a8\u6001\u73af\u5883\u5e76\u51cf\u5c11\u590d\u6742\u6027\u3002", "method": "\u5f00\u53d1\u4e86RIS-CIM-TSSK\u6a21\u578b\uff0c\u5229\u7528RIS\u5feb\u901f\u9002\u5e94\u73af\u5883\uff0cSSK\u51cf\u5c11\u5c04\u9891\u94fe\u590d\u6742\u6027\uff0cCIM\u589e\u5f3a\u88ab\u52a8\u4fe1\u606f\u4f20\u8f93\u3002\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u68c0\u6d4b\u5668\u548c\u76f2\u76f8\u4f4d\u8c03\u6574\u65b9\u6848\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u4e0d\u540c\u914d\u7f6e\u4e0b\uff08\u5982\u5929\u7ebf\u6570\u91cf\u548cRIS\u53cd\u5c04\u5143\u4ef6\u53d8\u5316\uff09\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u80fd\u6548\u548c\u53ef\u9760\u6027\u65b9\u9762\u3002", "conclusion": "RIS-CIM-TSSK\u4e3a\u73b0\u4ee3\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u667a\u80fd\u5316\u548c\u9002\u5e94\u6027\u5f3a\u7684\u7279\u70b9\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6269\u5c55\u3002"}}
{"id": "2507.05542", "pdf": "https://arxiv.org/pdf/2507.05542", "abs": "https://arxiv.org/abs/2507.05542", "authors": ["Mingchang Ge", "Liping Wang", "Xuemin Lin", "Yuang Zhang", "Kunming Wang"], "title": "GTRSS: Graph-based Top-$k$ Representative Similar Subtrajectory Query", "categories": ["cs.DB"], "comment": null, "summary": "Trajectory mining has attracted significant attention. This paper addresses\nthe Top-k Representative Similar Subtrajectory Query (TRSSQ) problem, which\naims to find the k most representative subtrajectories similar to a query.\nExisting methods rely on costly filtering-validation frameworks, resulting in\nslow response times. Addressing this, we propose GTRSS, a novel Graph-based\nTop-k Representative Similar Subtrajectory Query framework. During the offline\nphase, GTRSS builds a dual-layer graph index that clusters trajectories\ncontaining similar representative subtrajectories. In the online phase, it\nefficiently retrieves results by navigating the graph toward query-relevant\nclusters, bypassing full-dataset scanning and heavy computation. To support\nthis, we introduce the Data Trajectory Similarity Metric (DTSM) to measure the\nmost similar subtrajectory pair. We further combine R-tree and grid filtering\nwith DTSM pruning rules to speed up index building. To the best of our\nknowledge, GTRSS is the first graph-based solution for top-k subtrajectory\nsearch. Experiments on real datasets demonstrate that GTRSS significantly\nenhances both efficiency and accuracy, achieving a retrieval accuracy of over\n90 percent and up to two orders of magnitude speedup in query performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u65b0\u6846\u67b6GTRSS\uff0c\u7528\u4e8e\u9ad8\u6548\u89e3\u51b3Top-k\u4ee3\u8868\u6027\u76f8\u4f3c\u5b50\u8f68\u8ff9\u67e5\u8be2\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u6210\u672c\u7684\u8fc7\u6ee4-\u9a8c\u8bc1\u6846\u67b6\uff0c\u5bfc\u81f4\u54cd\u5e94\u65f6\u95f4\u6162\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "GTRSS\u91c7\u7528\u53cc\u5c42\u56fe\u7d22\u5f15\u79bb\u7ebf\u805a\u7c7b\u76f8\u4f3c\u5b50\u8f68\u8ff9\uff0c\u5728\u7ebf\u9636\u6bb5\u901a\u8fc7\u5bfc\u822a\u56fe\u5feb\u901f\u68c0\u7d22\u7ed3\u679c\uff0c\u7ed3\u5408R\u6811\u548c\u7f51\u683c\u8fc7\u6ee4\u4ee5\u53caDTSM\u5ea6\u91cf\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793aGTRSS\u68c0\u7d22\u51c6\u786e\u7387\u8d85\u8fc790%\uff0c\u67e5\u8be2\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "GTRSS\u662f\u9996\u4e2a\u57fa\u4e8e\u56fe\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b50\u8f68\u8ff9\u641c\u7d22\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.05653", "pdf": "https://arxiv.org/pdf/2507.05653", "abs": "https://arxiv.org/abs/2507.05653", "authors": ["Guilin Zhang", "Srinivas Vippagunta", "Raghavendra Nandagopal", "Suchitra Raman", "Jeff Xu", "Marcus Pfeiffer", "Shree Chatterjee", "Ziqi Tan", "Wulan Guo", "Hailong Jiang"], "title": "Archetype-Aware Predictive Autoscaling with Uncertainty Quantification for Serverless Workloads on Kubernetes", "categories": ["cs.DC"], "comment": "6 pages, 4 figures, 1 table. First three authors contributed equally.\n  Correspondence to Hailong Jiang", "summary": "High-performance extreme computing (HPEC) platforms increasingly adopt\nserverless paradigms, yet face challenges in efficiently managing highly\ndynamic workloads while maintaining service-level objectives (SLOs). We propose\n**AAPA**, an archetype-aware predictive autoscaling system that leverages weak\nsupervision to automatically classify 300\\,000\\,+ workload windows into four\narchetypes (PERIODIC, SPIKE, RAMP, STATIONARY\\_NOISY) with 99.8\\% accuracy.\nEvaluation on publicly available Azure Functions traces shows that AAPA reduces\nSLO violations by up to 50\\%, improves response time by 40\\%, albeit with a\n2--8\\,$\\times$ increase in resource cost under spike-heavy loads.", "AI": {"tldr": "AAPA\u5229\u7528\u5f31\u76d1\u7763\u6280\u672f\u9ad8\u6548\u5206\u7c7b\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u51cf\u5c11SLO\u8fdd\u89c450%\uff0c\u63d0\u5347\u54cd\u5e94\u65f6\u95f440%\uff0c\u4f46\u8d44\u6e90\u6210\u672c\u589e\u52a02-8\u500d\u3002", "motivation": "HPEC\u5e73\u53f0\u9700\u8981\u9ad8\u6548\u7ba1\u7406\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4ee5\u6ee1\u8db3SLO\uff0c\u4f46\u76ee\u524d\u65b9\u6cd5\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51faAAPA\u7cfb\u7edf\uff0c\u91c7\u7528\u5f31\u76d1\u7763\u6280\u672f\u5c06\u5de5\u4f5c\u8d1f\u8f7d\u5206\u7c7b\u4e3a\u56db\u79cd\u6a21\u5f0f\uff0c\u51c6\u786e\u738799.8%\u3002", "result": "\u5728Azure Functions\u6d4b\u8bd5\u4e2d\uff0cAAPA\u51cf\u5c11SLO\u8fdd\u89c450%\uff0c\u54cd\u5e94\u65f6\u95f4\u63d0\u534740%\uff0c\u4f46\u8d44\u6e90\u6210\u672c\u589e\u52a02-8\u500d\u3002", "conclusion": "AAPA\u5728\u52a8\u6001\u8d1f\u8f7d\u7ba1\u7406\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9700\u6743\u8861\u6027\u80fd\u63d0\u5347\u4e0e\u8d44\u6e90\u6210\u672c\u3002"}}
{"id": "2507.06063", "pdf": "https://arxiv.org/pdf/2507.06063", "abs": "https://arxiv.org/abs/2507.06063", "authors": ["Yuhei Yamada"], "title": "Practical design and performance of physical reservoir computing using hysteresis", "categories": ["cs.ET", "cs.NE"], "comment": null, "summary": "Physical reservoir computing is an innovative idea for using physical\nphenomena as computational resources. Recent research has revealed that\ninformation processing techniques can improve the performance, but for\npractical applications, it is equally important to study the level of\nperformance with a simple design that is easy to construct experimentally. We\nfocus on a reservoir composed of independent hysteretic systems as a model\nsuitable for the practical implementation of physical reservoir computing. In\nthis paper, we discuss the appropriate design of this reservoir, its\nperformance, and its limitations. This research will serve as a practical\nguideline for constructing hysteresis-based reservoirs.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u78c1\u6ede\u7cfb\u7edf\u7684\u7269\u7406\u50a8\u5b58\u8ba1\u7b97\u6a21\u578b\u7684\u8bbe\u8ba1\u3001\u6027\u80fd\u53ca\u9650\u5236\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7b80\u5355\u6613\u5efa\u7684\u5b9e\u7528\u6307\u5357\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7b80\u5355\u8bbe\u8ba1\u7684\u4fe1\u606f\u5904\u7406\u6280\u672f\u63d0\u5347\u7269\u7406\u50a8\u5b58\u8ba1\u7b97\u7684\u6027\u80fd\uff0c\u4ee5\u63a8\u52a8\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u7531\u72ec\u7acb\u78c1\u6ede\u7cfb\u7edf\u7ec4\u6210\u7684\u50a8\u5b58\u6a21\u578b\uff0c\u8ba8\u8bba\u5176\u8bbe\u8ba1\u3001\u6027\u80fd\u548c\u9650\u5236\u3002", "result": "\u4e3a\u57fa\u4e8e\u78c1\u6ede\u7cfb\u7edf\u7684\u50a8\u5b58\u6a21\u578b\u6784\u5efa\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u78c1\u6ede\u7cfb\u7edf\u5728\u7269\u7406\u50a8\u5b58\u8ba1\u7b97\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.05681", "pdf": "https://arxiv.org/pdf/2507.05681", "abs": "https://arxiv.org/abs/2507.05681", "authors": ["Muhammad Hadir Khan", "Matthew Guthaus"], "title": "GATMesh: Clock Mesh Timing Analysis using Graph Neural Networks", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": null, "summary": "Clock meshes are essential in high-performance VLSI systems for minimizing\nskew and handling PVT variations, but analyzing them is difficult due to\nreconvergent paths, multi-source driving, and input mesh buffer skew. SPICE\nsimulations are accurate but slow; yet simplified models miss key effects like\nslew and input skew. We propose GATMesh, a Graph Neural Network (GNN)-based\nframework that models the clock mesh as a graph with augmented structural and\nphysical features. Trained on SPICE data, GATMesh achieves high accuracy with\naverage delay error of 5.27ps on unseen benchmarks, while achieving speed-ups\nof 47146x over multi-threaded SPICE simulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eGNN\u7684GATMesh\u6846\u67b6\uff0c\u9ad8\u6548\u51c6\u786e\u5730\u5206\u6790\u65f6\u949f\u7f51\u7edc\uff0c\u5ef6\u8fdf\u8bef\u5dee\u4ec55.27ps\uff0c\u901f\u5ea6\u6bd4SPICE\u5feb47146\u500d\u3002", "motivation": "\u65f6\u949f\u7f51\u7edc\u5728\u9ad8\u6027\u80fdVLSI\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5206\u6790\u65b9\u6cd5\u6216\u6162\u6216\u4e0d\u51c6\u786e\u3002", "method": "\u91c7\u7528GNN\u5efa\u6a21\u65f6\u949f\u7f51\u7edc\uff0c\u7ed3\u5408\u7ed3\u6784\u548c\u7269\u7406\u7279\u5f81\uff0c\u5229\u7528SPICE\u6570\u636e\u8bad\u7ec3\u3002", "result": "GATMesh\u5ef6\u8fdf\u5e73\u5747\u8bef\u5dee\u4e3a5.27ps\uff0c\u901f\u5ea6\u6bd4SPICE\u5feb47146\u500d\u3002", "conclusion": "GATMesh\u662f\u4e00\u79cd\u9ad8\u6548\u51c6\u786e\u7684\u65f6\u949f\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2507.05289", "pdf": "https://arxiv.org/pdf/2507.05289", "abs": "https://arxiv.org/abs/2507.05289", "authors": ["Igor Regis da Silva Simoes", "Elaine Venson"], "title": "Measuring how changes in code readability attributes affect code quality evaluation by Large Language Models", "categories": ["cs.SE"], "comment": null, "summary": "Code readability is one of the main aspects of code quality, influenced by\nvarious properties like identifier names, comments, code structure, and\nadherence to standards. However, measuring this attribute poses challenges in\nboth industry and academia. While static analysis tools assess attributes such\nas code smells and comment percentage, code reviews introduce an element of\nsubjectivity. This paper explores using Large Language Models (LLMs) to\nevaluate code quality attributes related to its readability in a standardized,\nreproducible, and consistent manner. We conducted a quasi-experiment study to\nmeasure the effects of code changes on Large Language Model (LLM)s\ninterpretation regarding its readability quality attribute. Nine LLMs were\ntested, undergoing three interventions: removing comments, replacing identifier\nnames with obscure names, and refactoring to remove code smells. Each\nintervention involved 10 batch analyses per LLM, collecting data on response\nvariability. We compared the results with a known reference model and tool. The\nresults showed that all LLMs were sensitive to the interventions, with\nagreement with the reference classifier being high for the original and\nrefactored code scenarios. The LLMs demonstrated a strong semantic sensitivity\nthat the reference model did not fully capture. A thematic analysis of the LLMs\nreasoning confirmed their evaluations directly reflected the nature of each\nintervention. The models also exhibited response variability, with 9.37% to\n14.58% of executions showing a standard deviation greater than zero, indicating\nresponse oscillation, though this did not always compromise the statistical\nsignificance of the results. LLMs demonstrated potential for evaluating\nsemantic quality aspects, such as coherence between identifier names, comments,\nand documentation with code purpose.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6807\u51c6\u5316\u8bc4\u4f30\u4ee3\u7801\u53ef\u8bfb\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5bf9\u4ee3\u7801\u66f4\u6539\u7684\u654f\u611f\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u4ee3\u7801\u53ef\u8bfb\u6027\u8bc4\u4f30\u4e2d\u7684\u4e3b\u89c2\u6027\u548c\u6807\u51c6\u5316\u96be\u9898\u3002", "method": "\u91c7\u7528\u51c6\u5b9e\u9a8c\u7814\u7a76\uff0c\u6d4b\u8bd59\u79cdLLMs\u5bf9\u4e09\u79cd\u5e72\u9884\u63aa\u65bd\uff08\u5220\u9664\u6ce8\u91ca\u3001\u6df7\u6dc6\u6807\u8bc6\u7b26\u3001\u91cd\u6784\u4ee3\u7801\uff09\u7684\u54cd\u5e94\u3002", "result": "LLMs\u5bf9\u6240\u6709\u5e72\u9884\u63aa\u65bd\u654f\u611f\uff0c\u4e0e\u539f\u5206\u7c7b\u5668\u5728\u539f\u59cb\u548c\u91cd\u6784\u4ee3\u7801\u573a\u666f\u4e2d\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u5c55\u73b0\u51fa\u8bed\u4e49\u654f\u611f\u6027\u3002", "conclusion": "LLMs\u5728\u8bc4\u4f30\u4ee3\u7801\u8bed\u4e49\u8d28\u91cf\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u6807\u8bc6\u7b26\u540d\u79f0\u3001\u6ce8\u91ca\u4e0e\u4ee3\u7801\u76ee\u7684\u7684\u8fde\u8d2f\u6027\u4e0a\u3002"}}
{"id": "2507.05829", "pdf": "https://arxiv.org/pdf/2507.05829", "abs": "https://arxiv.org/abs/2507.05829", "authors": ["Zekai Sun", "Xiuxian Guan", "Zheng Lin", "Zihan Fang", "Xiangming Cai", "Zhe Chen", "Fangming Liu", "Heming Cui", "Jie Xiong", "Wei Ni", "Chau Yuen"], "title": "Intra-DP: A High Performance Collaborative Inference System for Mobile Edge Computing", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": "14 pages, 19 figures", "summary": "Deploying deep neural networks (DNNs) on resource-constrained mobile devices\npresents significant challenges, particularly in achieving real-time\nperformance while simultaneously coping with limited computational resources\nand battery life. While Mobile Edge Computing (MEC) offers collaborative\ninference with GPU servers as a promising solution, existing approaches\nprimarily rely on layer-wise model partitioning and undergo significant\ntransmission bottlenecks caused by the sequential execution of DNN operations.\nTo address this challenge, we present Intra-DP, a high-performance\ncollaborative inference system optimized for DNN inference on MEC. Intra DP\nemploys a novel parallel computing technique based on local operators (i.e.,\noperators whose minimum unit input is not the entire input tensor, such as the\nconvolution kernel). By decomposing their computations (operations) into\nseveral independent sub-operations and overlapping the computation and\ntransmission of different sub-operations through parallel execution, Intra-DP\nmitigates transmission bottlenecks in MEC, achieving fast and energy-efficient\ninference. The evaluation demonstrates that Intra-DP reduces per-inference\nlatency by up to 50% and energy consumption by up to 75% compared to\nstate-of-the-art baselines, without sacrificing accuracy.", "AI": {"tldr": "Intra-DP\u662f\u4e00\u79cd\u9488\u5bf9\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u4f18\u5316\u7684\u9ad8\u6027\u80fd\u534f\u4f5c\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5e76\u884c\u8ba1\u7b97\u6280\u672f\u51cf\u5c11\u4f20\u8f93\u74f6\u9888\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u8bbe\u5907\u4e0a\u90e8\u7f72\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u9762\u4e34\u5b9e\u65f6\u6027\u80fd\u548c\u8d44\u6e90\u9650\u5236\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4f20\u8f93\u74f6\u9888\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u672c\u5730\u64cd\u4f5c\u7b26\u7684\u5e76\u884c\u8ba1\u7b97\u6280\u672f\uff0c\u5c06\u8ba1\u7b97\u5206\u89e3\u4e3a\u72ec\u7acb\u5b50\u64cd\u4f5c\uff0c\u5e76\u884c\u6267\u884c\u4ee5\u51cf\u5c11\u4f20\u8f93\u74f6\u9888\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cIntra-DP\u5c06\u6bcf\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e50%\uff0c\u80fd\u8017\u964d\u4f4e75%\uff0c\u4e14\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002", "conclusion": "Intra-DP\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u4f20\u8f93\u74f6\u9888\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u8282\u80fd\u7684DNN\u63a8\u7406\u3002"}}
{"id": "2507.05859", "pdf": "https://arxiv.org/pdf/2507.05859", "abs": "https://arxiv.org/abs/2507.05859", "authors": ["Wenkang Zhang", "Yan Zhao", "Qiang Wang", "Li Song", "Zhengxue Cheng"], "title": "D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos", "categories": ["cs.CV", "cs.MM"], "comment": "12 pages, 9 figures, 8 tables", "summary": "Free-viewpoint video (FVV) enables immersive 3D experiences, but efficient\ncompression of dynamic 3D representations remains a major challenge. Recent\nadvances in 3D Gaussian Splatting (3DGS) and its dynamic extensions have\nenabled high-fidelity scene modeling. However, existing methods often couple\nscene reconstruction with optimization-dependent coding, which limits\ngeneralizability. This paper presents Feedforward Compression of Dynamic\nGaussian Splatting (D-FCGS), a novel feedforward framework for compressing\ntemporally correlated Gaussian point cloud sequences. Our approach introduces a\nGroup-of-Frames (GoF) structure with I-P frame coding, where inter-frame\nmotions are extracted via sparse control points. The resulting motion tensors\nare compressed in a feedforward manner using a dual prior-aware entropy model\nthat combines hyperprior and spatial-temporal priors for accurate rate\nestimation. For reconstruction, we perform control-point-guided motion\ncompensation and employ a refinement network to enhance view-consistent\nfidelity. Trained on multi-view video-derived Gaussian frames, D-FCGS\ngeneralizes across scenes without per-scene optimization. Experiments show that\nit matches the rate-distortion performance of optimization-based methods,\nachieving over 40 times compression in under 2 seconds while preserving visual\nquality across viewpoints. This work advances feedforward compression for\ndynamic 3DGS, paving the way for scalable FVV transmission and storage in\nimmersive applications.", "AI": {"tldr": "D-FCGS\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u524d\u9988\u6846\u67b6\uff0c\u7528\u4e8e\u538b\u7f29\u52a8\u6001\u9ad8\u65af\u70b9\u4e91\u5e8f\u5217\uff0c\u901a\u8fc7I-P\u5e27\u7f16\u7801\u548c\u63a7\u5236\u70b9\u63d0\u53d6\u8fd0\u52a8\uff0c\u7ed3\u5408\u8d85\u5148\u9a8c\u548c\u65f6\u7a7a\u5148\u9a8c\uff0c\u5b9e\u73b0\u9ad8\u6548\u538b\u7f29\u548c\u9ad8\u8d28\u91cf\u91cd\u5efa\u3002", "motivation": "\u52a8\u60013D\u9ad8\u65af\u70b9\u4e91\u5e8f\u5217\u7684\u9ad8\u6548\u538b\u7f29\u662f\u81ea\u7531\u89c6\u70b9\u89c6\u9891\uff08FVV\uff09\u7684\u6838\u5fc3\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4f18\u5316\u7f16\u7801\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528Group-of-Frames\u7ed3\u6784\uff0c\u4f7f\u7528I-P\u5e27\u7f16\u7801\u548c\u7a00\u758f\u63a7\u5236\u70b9\u63d0\u53d6\u8fd0\u52a8\u5f20\u91cf\uff0c\u7ed3\u5408\u53cc\u5148\u9a8c\u71b5\u6a21\u578b\u548c\u8fd0\u52a8\u8865\u507f\u4f18\u5316\u91cd\u5efa\u3002", "result": "\u5b9e\u9a8c\u8868\u660eD-FCGS\u57282\u79d2\u5185\u5b9e\u73b040\u500d\u538b\u7f29\uff0c\u4fdd\u6301\u89c6\u89c9\u8d28\u91cf\uff0c\u6027\u80fd\u4e0e\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "D-FCGS\u4e3a\u52a8\u60013D\u9ad8\u65af\u70b9\u4e91\u7684\u524d\u9988\u538b\u7f29\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u63a8\u52a8FVV\u7684\u53ef\u6269\u5c55\u4f20\u8f93\u548c\u5b58\u50a8\u3002"}}
{"id": "2507.05461", "pdf": "https://arxiv.org/pdf/2507.05461", "abs": "https://arxiv.org/abs/2507.05461", "authors": ["Akshat Choube", "Ha Le", "Jiachen Li", "Kaixin Ji", "Vedant Das Swain", "Varun Mishra"], "title": "GLOSS: Group of LLMs for Open-Ended Sensemaking of Passive Sensing Data for Health and Wellbeing", "categories": ["cs.HC"], "comment": null, "summary": "The ubiquitous presence of smartphones and wearables has enabled researchers\nto build prediction and detection models for various health and behavior\noutcomes using passive sensing data from these devices. Achieving a high-level,\nholistic understanding of an individual's behavior and context, however,\nremains a significant challenge. Due to the nature of passive sensing data,\nsensemaking -- the process of interpreting and extracting insights -- requires\nboth domain knowledge and technical expertise, creating barriers for different\nstakeholders. Existing systems designed to support sensemaking are either not\nopen-ended or cannot perform complex data triangulation. In this paper, we\npresent a novel sensemaking system, Group of LLMs for Open-ended Sensemaking\n(GLOSS), capable of open-ended sensemaking and performing complex multimodal\ntriangulation to derive insights. We demonstrate that GLOSS significantly\noutperforms the commonly used Retrieval-Augmented Generation (RAG) technique,\nachieving 87.93% accuracy and 66.19% consistency, compared to RAG's 29.31%\naccuracy and 52.85% consistency. Furthermore, we showcase the promise of GLOSS\nthrough four use cases inspired by prior and ongoing work in the UbiComp and\nHCI communities. Finally, we discuss the potential of GLOSS, its broader\nimplications, and the limitations of our work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGLOSS\u7684\u65b0\u578b\u611f\u77e5\u7cfb\u7edf\uff0c\u80fd\u591f\u8fdb\u884c\u5f00\u653e\u5f0f\u611f\u77e5\u548c\u590d\u6742\u591a\u6a21\u6001\u4e09\u89d2\u6d4b\u91cf\u4ee5\u63d0\u53d6\u6d1e\u5bdf\uff0c\u663e\u8457\u4f18\u4e8e\u5e38\u89c1\u7684RAG\u6280\u672f\u3002", "motivation": "\u667a\u80fd\u624b\u673a\u548c\u7a7f\u6234\u8bbe\u5907\u7684\u666e\u53ca\u4e3a\u5065\u5eb7\u548c\u884c\u4e3a\u9884\u6d4b\u63d0\u4f9b\u4e86\u88ab\u52a8\u4f20\u611f\u6570\u636e\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u5f00\u653e\u5f0f\u611f\u77e5\u548c\u590d\u6742\u6570\u636e\u4e09\u89d2\u6d4b\u91cf\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86GLOSS\u7cfb\u7edf\uff0c\u652f\u6301\u5f00\u653e\u5f0f\u611f\u77e5\u548c\u591a\u6a21\u6001\u4e09\u89d2\u6d4b\u91cf\uff0c\u5e76\u4e0eRAG\u6280\u672f\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "GLOSS\u5728\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u4e0a\u663e\u8457\u4f18\u4e8eRAG\uff0887.93% vs 29.31%\u51c6\u786e\u6027\uff1b66.19% vs 52.85%\u4e00\u81f4\u6027\uff09\u3002", "conclusion": "GLOSS\u5c55\u793a\u4e86\u5728UbiComp\u548cHCI\u9886\u57df\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u5176\u5c40\u9650\u6027\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2507.05275", "pdf": "https://arxiv.org/pdf/2507.05275", "abs": "https://arxiv.org/abs/2507.05275", "authors": ["Weibing Zheng", "Laurah Turner", "Jess Kropczynski", "Murat Ozer", "Seth Overla", "Shane Halse"], "title": "A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LO", "cs.MA", "D.2.4; K.3.1; C.3; I.2.6"], "comment": "6 pages, 3 figures, 1 table. 2025 IFSA World Congress NAFIPS Annual\n  Meeting", "summary": "Assisting medical students with clinical reasoning (CR) during clinical\nscenario training remains a persistent challenge in medical education. This\npaper presents the design and architecture of the Fuzzy Supervisor Agent (FSA),\na novel component for the Multi-Agent Educational Clinical Scenario Simulation\n(MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to\ncontinuously interpret student interactions with specialized clinical agents\n(e.g., patient, physical exam, diagnostic, intervention) using pre-defined\nfuzzy rule bases for professionalism, medical relevance, ethical behavior, and\ncontextual distraction. By analyzing student decision-making processes in\nreal-time, the FSA is designed to deliver adaptive, context-aware feedback and\nprovides assistance precisely when students encounter difficulties. This work\nfocuses on the technical framework and rationale of the FSA, highlighting its\npotential to provide scalable, flexible, and human-like supervision in\nsimulation-based medical education. Future work will include empirical\nevaluation and integration into broader educational settings. More detailed\ndesign and implementation is~\\href{https://github.com/2sigmaEdTech/MAS/}{open\nsourced here}.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u7cca\u76d1\u7763\u4ee3\u7406\uff08FSA\uff09\u8bbe\u8ba1\uff0c\u7528\u4e8e\u533b\u5b66\u6559\u80b2\u4e2d\u7684\u4e34\u5e8a\u60c5\u666f\u6a21\u62df\u5e73\u53f0\uff08MAECSS\uff09\uff0c\u901a\u8fc7\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u5b9e\u65f6\u5206\u6790\u5b66\u751f\u51b3\u7b56\uff0c\u63d0\u4f9b\u9002\u5e94\u6027\u53cd\u9988\u3002", "motivation": "\u89e3\u51b3\u533b\u5b66\u6559\u80b2\u4e2d\u4e34\u5e8a\u63a8\u7406\u8bad\u7ec3\u7684\u76d1\u7763\u96be\u9898\uff0c\u63d0\u4f9b\u53ca\u65f6\u3001\u7cbe\u51c6\u7684\u8f85\u52a9\u3002", "method": "\u57fa\u4e8e\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\uff08FIS\uff09\uff0c\u901a\u8fc7\u9884\u5b9a\u4e49\u7684\u6a21\u7cca\u89c4\u5219\u5206\u6790\u5b66\u751f\u4e0e\u4e34\u5e8a\u4ee3\u7406\u7684\u4e92\u52a8\uff0c\u5b9e\u65f6\u751f\u6210\u53cd\u9988\u3002", "result": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u7075\u6d3b\u4e14\u6a21\u62df\u4eba\u7c7b\u76d1\u7763\u7684FSA\u6846\u67b6\uff0c\u672a\u6765\u5c06\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "conclusion": "FSA\u6709\u671b\u5728\u6a21\u62df\u533b\u5b66\u6559\u80b2\u4e2d\u63d0\u4f9b\u9ad8\u6548\u7684\u76d1\u7763\uff0c\u4e0b\u4e00\u6b65\u662f\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u548c\u5927\u89c4\u6a21\u96c6\u6210\u3002"}}
{"id": "2507.05573", "pdf": "https://arxiv.org/pdf/2507.05573", "abs": "https://arxiv.org/abs/2507.05573", "authors": ["Shivani Tripathi", "Pushpanjali Nema", "Aditya Halder", "Shi Qiao", "Alekh Jindal"], "title": "Prompt Migration: Stabilizing GenAI Applications with Evolving Large Language Models", "categories": ["cs.DB", "cs.AI", "cs.SE"], "comment": null, "summary": "Generative AI is transforming business applications by enabling natural\nlanguage interfaces and intelligent automation. However, the underlying large\nlanguage models (LLMs) are evolving rapidly and so prompting them consistently\nis a challenge. This leads to inconsistent and unpredictable application\nbehavior, undermining the reliability that businesses require for\nmission-critical workflows. In this paper, we introduce the concept of prompt\nmigration as a systematic approach to stabilizing GenAI applications amid\nchanging LLMs. Using the Tursio enterprise search application as a case study,\nwe analyze the impact of successive GPT model upgrades, detail our migration\nframework including prompt redesign and a migration testbed, and demonstrate\nhow these techniques restore application consistency. Our results show that\nstructured prompt migration can fully recover the application reliability that\nwas lost due to model drift. We conclude with practical lessons learned,\nemphasizing the need for prompt lifecycle management and robust testing to\nensure dependable GenAI-powered business applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u2014\u2014\u63d0\u793a\u8fc1\u79fb\u2014\u2014\u4ee5\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5feb\u901f\u5347\u7ea7\u5bfc\u81f4\u7684\u751f\u6210\u5f0fAI\u5e94\u7528\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "motivation": "\u4f01\u4e1a\u9700\u8981\u53ef\u9760\u7684\u751f\u6210\u5f0fAI\u5e94\u7528\uff0c\u4f46LLM\u7684\u5feb\u901f\u53d8\u5316\u5bfc\u81f4\u5e94\u7528\u884c\u4e3a\u4e0d\u4e00\u81f4\uff0c\u5f71\u54cd\u5173\u952e\u4e1a\u52a1\u5de5\u4f5c\u6d41\u7684\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u63d0\u793a\u8fc1\u79fb\u6846\u67b6\uff0c\u5305\u62ec\u63d0\u793a\u91cd\u65b0\u8bbe\u8ba1\u548c\u8fc1\u79fb\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4ee5\u6848\u4f8b\u5206\u6790\uff08Tursio\u4f01\u4e1a\u641c\u7d22\u5e94\u7528\uff09\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u8fc1\u79fb\uff0c\u53ef\u4ee5\u5b8c\u5168\u6062\u590d\u56e0\u6a21\u578b\u6f02\u79fb\u800c\u4e22\u5931\u7684\u5e94\u7528\u53ef\u9760\u6027\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u63d0\u793a\u751f\u547d\u5468\u671f\u7ba1\u7406\u548c\u9c81\u68d2\u6d4b\u8bd5\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u786e\u4fdd\u751f\u6210\u5f0fAI\u4e1a\u52a1\u5e94\u7528\u7684\u7a33\u5b9a\u6027\u3002"}}
{"id": "2507.05704", "pdf": "https://arxiv.org/pdf/2507.05704", "abs": "https://arxiv.org/abs/2507.05704", "authors": ["Qianpiao Ma", "Junlong Zhou", "Xiangpeng Hou", "Jianchun Liu", "Hongli Xu", "Jianeng Miao", "Qingmin Jia"], "title": "Air-FedGA: A Grouping Asynchronous Federated Learning Mechanism Exploiting Over-the-air Computation", "categories": ["cs.DC"], "comment": "This paper has been accepted by IEEE International Parallel &\n  Distributed Processing Symposium (IPDPS), 2025", "summary": "Federated learning (FL) is a new paradigm to train AI models over distributed\nedge devices (i.e., workers) using their local data, while confronting various\nchallenges including communication resource constraints, edge heterogeneity and\ndata Non-IID. Over-the-air computation (AirComp) is a promising technique to\nachieve efficient utilization of communication resource for model aggregation\nby leveraging the superposition property of a wireless multiple access channel\n(MAC). However, AirComp requires strict synchronization among edge devices,\nwhich is hard to achieve in heterogeneous scenarios. In this paper, we propose\nan AirComp-based grouping asynchronous federated learning mechanism\n(Air-FedGA), which combines the advantages of AirComp and asynchronous FL to\naddress the communication and heterogeneity challenges. Specifically, Air-FedGA\norganizes workers into groups and performs over-the-air aggregation within each\ngroup, while groups asynchronously communicate with the parameter server to\nupdate the global model. In this way, Air-FedGA accelerates the FL model\ntraining by over-the-air aggregation, while relaxing the synchronization\nrequirement of this aggregation technology. We theoretically prove the\nconvergence of Air-FedGA. We formulate a training time minimization problem for\nAir-FedGA and propose the power control and worker grouping algorithm to solve\nit, which jointly optimizes the power scaling factors at edge devices, the\ndenoising factors at the parameter server, as well as the worker grouping\nstrategy. We conduct experiments on classical models and datasets, and the\nresults demonstrate that our proposed mechanism and algorithm can speed up FL\nmodel training by 29.9%-71.6% compared with the state-of-the-art solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a7a\u4e2d\u8ba1\u7b97\u7684\u5206\u7ec4\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u673a\u5236\uff08Air-FedGA\uff09\uff0c\u89e3\u51b3\u4e86\u901a\u4fe1\u8d44\u6e90\u9650\u5236\u548c\u8bbe\u5907\u5f02\u6784\u6027\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5206\u5e03\u5f0f\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8bad\u7ec3\u6a21\u578b\u65f6\u9762\u4e34\u901a\u4fe1\u8d44\u6e90\u9650\u5236\u3001\u8bbe\u5907\u5f02\u6784\u6027\u548c\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7b49\u95ee\u9898\uff0c\u7a7a\u4e2d\u8ba1\u7b97\u867d\u7136\u80fd\u9ad8\u6548\u5229\u7528\u901a\u4fe1\u8d44\u6e90\uff0c\u4f46\u5bf9\u540c\u6b65\u8981\u6c42\u4e25\u683c\u3002", "method": "\u63d0\u51faAir-FedGA\u673a\u5236\uff0c\u5c06\u8bbe\u5907\u5206\u7ec4\u8fdb\u884c\u7a7a\u4e2d\u8ba1\u7b97\u805a\u5408\uff0c\u7ec4\u95f4\u5f02\u6b65\u66f4\u65b0\u5168\u5c40\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u529f\u7387\u63a7\u5236\u548c\u5206\u7ec4\u7b97\u6cd5\u4f18\u5316\u8bad\u7ec3\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAir-FedGA\u80fd\u6bd4\u73b0\u6709\u65b9\u6848\u52a0\u901f\u8bad\u7ec329.9%-71.6%\uff0c\u5e76\u7406\u8bba\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002", "conclusion": "Air-FedGA\u7ed3\u5408\u4e86\u7a7a\u4e2d\u8ba1\u7b97\u548c\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u901a\u4fe1\u548c\u5f02\u6784\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2507.06156", "pdf": "https://arxiv.org/pdf/2507.06156", "abs": "https://arxiv.org/abs/2507.06156", "authors": ["Poupak Azad", "Jiahua Xu", "Yebo Feng", "Preston Strowbridge", "Cuneyt Akcora"], "title": "Hedge Funds on a Swamp: Analyzing Patterns, Vulnerabilities, and Defense Measures in Blockchain Bridges [Experiment, Analysis \\& Benchmark]", "categories": ["cs.ET", "cs.CR"], "comment": null, "summary": "Blockchain bridges have become essential infrastructure for enabling\ninteroperability across different blockchain networks, with more than $24B\nmonthly bridge transaction volume. However, their growing adoption has been\naccompanied by a disproportionate rise in security breaches, making them the\nsingle largest source of financial loss in Web3. For cross-chain ecosystems to\nbe robust and sustainable, it is essential to understand and address these\nvulnerabilities. In this study, we present a comprehensive systematization of\nblockchain bridge design and security. We define three bridge security priors,\nformalize the architectural structure of 13 prominent bridges, and identify 23\nattack vectors grounded in real-world blockchain exploits. Using this\nfoundation, we evaluate 43 representative attack scenarios and introduce a\nlayered threat model that captures security failures across source chain,\noff-chain, and destination chain components.\n  Our analysis at the static code and transaction network levels reveals\nrecurring design flaws, particularly in access control, validator trust\nassumptions, and verification logic, and identifies key patterns in adversarial\nbehavior based on transaction-level traces. To support future development, we\npropose a decision framework for bridge architecture design, along with defense\nmechanisms such as layered validation and circuit breakers. This work provides\na data-driven foundation for evaluating bridge security and lays the groundwork\nfor standardizing resilient cross-chain infrastructure.", "AI": {"tldr": "\u533a\u5757\u94fe\u6865\u6881\u662f\u5b9e\u73b0\u4e0d\u540c\u533a\u5757\u94fe\u7f51\u7edc\u4e92\u64cd\u4f5c\u6027\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u5176\u5b89\u5168\u6027\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u6210\u4e3aWeb3\u4e2d\u6700\u5927\u7684\u7ecf\u6d4e\u635f\u5931\u6765\u6e90\u3002\u672c\u6587\u7cfb\u7edf\u5316\u7814\u7a76\u4e86\u6865\u6881\u7684\u8bbe\u8ba1\u4e0e\u5b89\u5168\uff0c\u63d0\u51fa\u4e86\u5b89\u5168\u4f18\u5148\u7ea7\u3001\u653b\u51fb\u5411\u91cf\u5206\u6790\u53ca\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u968f\u7740\u533a\u5757\u94fe\u6865\u6881\u7684\u5e7f\u6cdb\u4f7f\u7528\uff08\u6708\u4ea4\u6613\u91cf\u8d85\u8fc7240\u4ebf\u7f8e\u5143\uff09\uff0c\u5176\u5b89\u5168\u6f0f\u6d1e\u5bfc\u81f4\u7684\u635f\u5931\u4e0d\u65ad\u589e\u52a0\u3002\u4e3a\u4e86\u6784\u5efa\u7a33\u5065\u7684\u8de8\u94fe\u751f\u6001\uff0c\u4e9f\u9700\u7cfb\u7edf\u5316\u7814\u7a76\u6865\u6881\u7684\u5b89\u5168\u95ee\u9898\u3002", "method": "\u7814\u7a76\u5b9a\u4e49\u4e86\u4e09\u4e2a\u6865\u6881\u5b89\u5168\u4f18\u5148\u7ea7\uff0c\u5f62\u5f0f\u5316\u4e8613\u4e2a\u6865\u6881\u7684\u67b6\u6784\u7ed3\u6784\uff0c\u8bc6\u522b\u4e8623\u4e2a\u57fa\u4e8e\u73b0\u5b9e\u653b\u51fb\u7684\u653b\u51fb\u5411\u91cf\uff0c\u5e76\u5206\u6790\u4e8643\u4e2a\u5178\u578b\u653b\u51fb\u573a\u666f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bbe\u8ba1\u4e2d\u7684\u5e38\u89c1\u7f3a\u9677\uff08\u5982\u8bbf\u95ee\u63a7\u5236\u3001\u9a8c\u8bc1\u903b\u8f91\u95ee\u9898\uff09\uff0c\u63d0\u51fa\u4e86\u5206\u5c42\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u9759\u6001\u4ee3\u7801\u548c\u4ea4\u6613\u7f51\u7edc\u5206\u6790\u63ed\u793a\u4e86\u653b\u51fb\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u4e86\u6865\u6881\u67b6\u6784\u8bbe\u8ba1\u7684\u51b3\u7b56\u6846\u67b6\u548c\u9632\u5fa1\u673a\u5236\uff08\u5982\u5206\u5c42\u9a8c\u8bc1\u548c\u7194\u65ad\u673a\u5236\uff09\uff0c\u4e3a\u6807\u51c6\u5316\u8de8\u94fe\u57fa\u7840\u8bbe\u65bd\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.06069", "pdf": "https://arxiv.org/pdf/2507.06069", "abs": "https://arxiv.org/abs/2507.06069", "authors": ["Atiyeh Gheibi-Fetrat", "Amirsaeed Ahmadi-Tonekaboni", "Farzam Koohi-Ronaghi", "Pariya Hajipour", "Sana Babayan-Vanestan", "Fatemeh Fotouhi", "Elahe Mortazavian-Farsani", "Pouria Khajehpour-Dezfouli", "Sepideh Safari", "Shaahin Hessabi", "Hamid Sarbazi-Azad"], "title": "RTGPU: Real-Time Computing with Graphics Processing Units", "categories": ["cs.AR"], "comment": "This document provides a concise summary of the book RTGPU, submitted\n  to Synthesis Lectures on Computer Architecture. Due to copyright\n  restrictions, the full content is not reproduced here; readers are referred\n  to the complete book for more comprehensive details", "summary": "In this work, we survey the role of GPUs in real-time systems. Originally\ndesigned for parallel graphics workloads, GPUs are now widely used in\ntime-critical applications such as machine learning, autonomous vehicles, and\nrobotics due to their high computational throughput. Their parallel\narchitecture is well-suited for accelerating complex tasks under strict timing\nconstraints. However, their integration into real-time systems presents several\nchallenges, including non-preemptive execution, execution time variability, and\nresource contention; factors that can lead to unpredictable delays and deadline\nviolations. We examine existing solutions that address these challenges,\nincluding scheduling algorithms, resource management techniques, and\nsynchronization methods, and highlight open research directions to improve GPU\npredictability and performance in real-time environments.", "AI": {"tldr": "GPU\u5728\u5b9e\u65f6\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\u53ca\u6311\u6218", "motivation": "\u7814\u7a76GPU\u5728\u5b9e\u65f6\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u53ca\u5176\u5e26\u6765\u7684\u6311\u6218", "method": "\u7efc\u8ff0\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u8c03\u5ea6\u7b97\u6cd5\u3001\u8d44\u6e90\u7ba1\u7406\u6280\u672f\u548c\u540c\u6b65\u65b9\u6cd5", "result": "\u603b\u7ed3\u4e86GPU\u5728\u5b9e\u65f6\u7cfb\u7edf\u4e2d\u7684\u8868\u73b0\u53ca\u5176\u95ee\u9898", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u6539\u8fdbGPU\u53ef\u9884\u6d4b\u6027\u548c\u6027\u80fd\u7684\u7814\u7a76\u65b9\u5411"}}
{"id": "2507.05294", "pdf": "https://arxiv.org/pdf/2507.05294", "abs": "https://arxiv.org/abs/2507.05294", "authors": ["William Law"], "title": "zkSDK: Streamlining zero-knowledge proof development through automated trace-driven ZK-backend selection", "categories": ["cs.SE"], "comment": "undergrad thesis", "summary": "The rapid advancement of creating Zero-Knowledge (ZK) programs has led to the\ndevelopment of numerous tools designed to support developers. Popular options\ninclude being able to write in general-purpose programming languages like Rust\nfrom Risc Zero. Other languages exist like Circom, Lib-snark, and Cairo.\nHowever, developers entering the ZK space are faced with many different ZK\nbackends to choose from, leading to a steep learning curve and a fragmented\ndeveloper experience across different platforms. As a result, many developers\ntend to select a single ZK backend and remain tied to it. This thesis\nintroduces zkSDK, a modular framework that streamlines ZK application\ndevelopment by abstracting the backend complexities. At the core of zkSDK is\nPresto, a custom Python-like programming language that enables the profiling\nand analysis of a program to assess its computational workload intensity.\nCombined with user-defined criteria, zkSDK employs a dynamic selection\nalgorithm to automatically choose the optimal ZK-proving backend. Through an\nin-depth analysis and evaluation of real-world workloads, we demonstrate that\nzkSDK effectively selects the best-suited backend from a set of supported ZK\nbackends, delivering a seamless and user-friendly development experience.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3azkSDK\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u65e8\u5728\u7b80\u5316\u96f6\u77e5\u8bc6\uff08ZK\uff09\u5e94\u7528\u5f00\u53d1\uff0c\u901a\u8fc7\u62bd\u8c61\u540e\u7aef\u590d\u6742\u6027\u5e76\u63d0\u4f9b\u52a8\u6001\u9009\u62e9\u7b97\u6cd5\u81ea\u52a8\u9009\u62e9\u6700\u4f18ZK\u8bc1\u660e\u540e\u7aef\u3002", "motivation": "\u7531\u4e8e\u96f6\u77e5\u8bc6\u7a0b\u5e8f\u5f00\u53d1\u7684\u5feb\u901f\u8fdb\u6b65\uff0c\u5f00\u53d1\u8005\u9762\u4e34\u591a\u79cdZK\u540e\u7aef\u9009\u62e9\uff0c\u5bfc\u81f4\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u4e14\u4f53\u9a8c\u788e\u7247\u5316\u3002zkSDK\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86zkSDK\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u662fPresto\u8bed\u8a00\uff0c\u7528\u4e8e\u5206\u6790\u7a0b\u5e8f\u7684\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\u5f3a\u5ea6\uff0c\u5e76\u7ed3\u5408\u7528\u6237\u5b9a\u4e49\u7684\u52a8\u6001\u9009\u62e9\u7b97\u6cd5\u81ea\u52a8\u9009\u62e9\u6700\u4f18ZK\u540e\u7aef\u3002", "result": "\u901a\u8fc7\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u6790\u4e0e\u8bc4\u4f30\uff0czkSDK\u80fd\u591f\u6709\u6548\u9009\u62e9\u6700\u9002\u5408\u7684\u540e\u7aef\uff0c\u63d0\u4f9b\u65e0\u7f1d\u4e14\u7528\u6237\u53cb\u597d\u7684\u5f00\u53d1\u4f53\u9a8c\u3002", "conclusion": "zkSDK\u6210\u529f\u89e3\u51b3\u4e86ZK\u5f00\u53d1\u4e2d\u7684\u540e\u7aef\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2507.05572", "pdf": "https://arxiv.org/pdf/2507.05572", "abs": "https://arxiv.org/abs/2507.05572", "authors": ["Andrey Titov", "Tina N. H. Nantenaina", "Marta Kersten-Oertel", "Simon Drouin"], "title": "AnatomyCarve: A VR occlusion management technique for medical images based on segment-aware clipping", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "Visualizing 3D medical images is challenging due to self-occlusion, where\nanatomical structures of interest can be obscured by surrounding tissues.\nExisting methods, such as slicing and interactive clipping, are limited in\ntheir ability to fully represent internal anatomy in context. In contrast,\nhand-drawn medical illustrations in anatomy books manage occlusion effectively\nby selectively removing portions based on tissue type, revealing 3D structures\nwhile preserving context. This paper introduces AnatomyCarve, a novel technique\ndeveloped for a VR environment that creates high-quality illustrations similar\nto those in anatomy books, while remaining fast and interactive. AnatomyCarve\nallows users to clip selected segments from 3D medical volumes, preserving\nspatial relations and contextual information. This approach enhances\nvisualization by combining advanced rendering techniques with natural user\ninteractions in VR. Usability of AnatomyCarve was assessed through a study with\nnon-experts, while surgical planning effectiveness was evaluated with\npracticing neurosurgeons and residents. The results show that AnatomyCarve\nenables customized anatomical visualizations, with high user satisfaction,\nsuggesting its potential for educational and clinical applications.", "AI": {"tldr": "AnatomyCarve\u662f\u4e00\u79cdVR\u6280\u672f\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5207\u9664\u7ec4\u7ec7\u6765\u53ef\u89c6\u53163D\u533b\u5b66\u56fe\u50cf\uff0c\u7c7b\u4f3c\u89e3\u5256\u6559\u79d1\u4e66\u4e2d\u7684\u624b\u7ed8\u63d2\u56fe\uff0c\u63d0\u9ad8\u4e86\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u81ea\u906e\u6321\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b8c\u6574\u5c55\u793a3D\u533b\u5b66\u56fe\u50cf\u7684\u5185\u90e8\u89e3\u5256\u7ed3\u6784\uff0c\u800c\u624b\u7ed8\u533b\u5b66\u63d2\u56fe\u5374\u80fd\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86AnatomyCarve\u6280\u672f\uff0c\u5728VR\u73af\u5883\u4e2d\u9009\u62e9\u6027\u5207\u96643D\u533b\u5b66\u4f53\u6570\u636e\u4e2d\u7684\u90e8\u5206\u7ec4\u7ec7\uff0c\u4fdd\u7559\u7a7a\u95f4\u5173\u7cfb\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u7814\u7a76\u8868\u660eAnatomyCarve\u63d0\u4f9b\u5b9a\u5236\u5316\u89e3\u5256\u53ef\u89c6\u5316\uff0c\u975e\u4e13\u5bb6\u548c\u795e\u7ecf\u5916\u79d1\u533b\u751f\u5bf9\u5176\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u4e34\u5e8a\u6548\u679c\u8bc4\u4ef7\u8f83\u9ad8\u3002", "conclusion": "AnatomyCarve\u5177\u6709\u6559\u80b2\u548c\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\uff0c\u5176\u7ed3\u5408\u9ad8\u7ea7\u6e32\u67d3\u6280\u672f\u548cVR\u4ea4\u4e92\u7684\u65b9\u6709\u6548\u63d0\u5347\u4e86\u533b\u5b66\u56fe\u50cf\u7684\u53ef\u89c6\u5316\u6548\u679c\u3002"}}
{"id": "2507.05876", "pdf": "https://arxiv.org/pdf/2507.05876", "abs": "https://arxiv.org/abs/2507.05876", "authors": ["Nehal Baganal Krishna", "Anam Tahir", "Firas Khamis", "Mina Tahmasbi Arashloo", "Michael Zink", "Amr Rizk"], "title": "OLAF: Programmable Data Plane Acceleration for Asynchronous Distributed Reinforcement Learning", "categories": ["cs.NI", "cs.AR"], "comment": "17 pages, 11 figures", "summary": "Asynchronous Distributed Reinforcement Learning (DRL) can suffer from\ndegraded convergence when model updates become stale, often the result of\nnetwork congestion and packet loss during large-scale training. This work\nintroduces a network data-plane acceleration architecture that mitigates such\nstaleness by enabling inline processing of DRL model updates as they traverse\nthe accelerator engine. To this end, we design and prototype a novel queueing\nmechanism that opportunistically combines compatible updates sharing a network\nelement, reducing redundant traffic and preserving update utility.\nComplementing this we provide a lightweight transmission control mechanism at\nthe worker nodes that is guided by feedback from the in-network accelerator. To\nassess model utility at line rate, we introduce the Age-of-Model (AoM) metric\nas a proxy for staleness and verify global fairness and responsiveness\nproperties using a formal verification method. Our evaluations demonstrate that\nthis architecture significantly reduces update staleness and congestion,\nultimately improving the convergence rate in asynchronous DRL workloads.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7f51\u7edc\u6570\u636e\u5e73\u9762\u52a0\u901f\u67b6\u6784\uff0c\u901a\u8fc7\u5728\u7ebf\u5904\u7406DRL\u6a21\u578b\u66f4\u65b0\uff0c\u51cf\u5c11\u66f4\u65b0\u5ef6\u8fdf\u548c\u7f51\u7edc\u62e5\u585e\uff0c\u4ece\u800c\u63d0\u9ad8\u5f02\u6b65DRL\u8bad\u7ec3\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5f02\u6b65\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u5728\u6a21\u578b\u66f4\u65b0\u5ef6\u8fdf\u65f6\u4f1a\u51fa\u73b0\u6536\u655b\u6027\u80fd\u4e0b\u964d\uff0c\u901a\u5e38\u662f\u7531\u4e8e\u5927\u89c4\u6a21\u8bad\u7ec3\u4e2d\u7684\u7f51\u7edc\u62e5\u585e\u548c\u6570\u636e\u5305\u4e22\u5931\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6392\u961f\u673a\u5236\uff0c\u5408\u5e76\u517c\u5bb9\u7684\u66f4\u65b0\u4ee5\u51cf\u5c11\u5197\u4f59\u6d41\u91cf\uff0c\u5e76\u5728\u5de5\u4f5c\u8282\u70b9\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u4f20\u8f93\u63a7\u5236\u673a\u5236\uff0c\u901a\u8fc7\u7f51\u7edc\u52a0\u901f\u5668\u53cd\u9988\u8fdb\u884c\u6307\u5bfc\u3002\u5f15\u5165Age-of-Model\uff08AoM\uff09\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u6548\u7528\u3002", "result": "\u8be5\u67b6\u6784\u663e\u8457\u51cf\u5c11\u4e86\u66f4\u65b0\u5ef6\u8fdf\u548c\u62e5\u585e\uff0c\u6539\u5584\u4e86\u5f02\u6b65DRL\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u6570\u636e\u5e73\u9762\u52a0\u901f\u67b6\u6784\u548cAoM\u6307\u6807\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6b65DRL\u4e2d\u7684\u66f4\u65b0\u5ef6\u8fdf\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6536\u655b\u6027\u80fd\u3002"}}
{"id": "2507.05939", "pdf": "https://arxiv.org/pdf/2507.05939", "abs": "https://arxiv.org/abs/2507.05939", "authors": ["Bing Wang", "Ximing Li", "Mengzhe Ye", "Changchun Li", "Bo Fu", "Jianfeng Qu", "Lin Yuanbo Wu"], "title": "Remember Past, Anticipate Future: Learning Continual Multimodal Misinformation Detectors", "categories": ["cs.CL", "cs.MM"], "comment": "Accepted by ACM MM 2025. 10 pages, 6 figures. Code:\n  https://github.com/wangbing1416/DAEDCMD", "summary": "Nowadays, misinformation articles, especially multimodal ones, are widely\nspread on social media platforms and cause serious negative effects. To control\ntheir propagation, Multimodal Misinformation Detection (MMD) becomes an active\ntopic in the community to automatically identify misinformation. Previous MMD\nmethods focus on supervising detectors by collecting offline data. However, in\nreal-world scenarios, new events always continually emerge, making MMD models\ntrained on offline data consistently outdated and ineffective. To address this\nissue, training MMD models under online data streams is an alternative,\ninducing an emerging task named continual MMD. Unfortunately, it is hindered by\ntwo major challenges. First, training on new data consistently decreases the\ndetection performance on past data, named past knowledge forgetting. Second,\nthe social environment constantly evolves over time, affecting the\ngeneralization on future data. To alleviate these challenges, we propose to\nremember past knowledge by isolating interference between event-specific\nparameters with a Dirichlet process-based mixture-of-expert structure, and\nanticipate future environmental distributions by learning a continuous-time\ndynamics model. Accordingly, we induce a new continual MMD method DAEDCMD.\nExtensive experiments demonstrate that DAEDCMD can consistently and\nsignificantly outperform the compared methods, including six MMD baselines and\nthree continual learning methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6301\u7eed\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u65b9\u6cd5DAEDCMD\uff0c\u901a\u8fc7\u9694\u79bb\u4e8b\u4ef6\u7279\u5b9a\u53c2\u6570\u548c\u9884\u6d4b\u672a\u6765\u73af\u5883\u5206\u5e03\u6765\u5e94\u5bf9\u8fc7\u53bb\u77e5\u8bc6\u9057\u5fd8\u548c\u672a\u6765\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u5e7f\u6cdb\u4f20\u64ad\uff0c\u4f20\u7edf\u79bb\u7ebf\u8bad\u7ec3\u7684\u68c0\u6d4b\u6a21\u578b\u65e0\u6cd5\u9002\u5e94\u65b0\u4e8b\u4ef6\u7684\u4e0d\u65ad\u6d8c\u73b0\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u6301\u7eedMMD\u4efb\u52a1\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eDirichlet\u8fc7\u7a0b\u7684\u6df7\u5408\u4e13\u5bb6\u7ed3\u6784\u9694\u79bb\u4e8b\u4ef6\u7279\u5b9a\u53c2\u6570\u4ee5\u51cf\u5c11\u5e72\u6270\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u6a21\u578b\u9884\u6d4b\u672a\u6765\u73af\u5883\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDAEDCMD\u663e\u8457\u4f18\u4e8e\u516d\u79cdMMD\u57fa\u51c6\u65b9\u6cd5\u548c\u4e09\u79cd\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "DAEDCMD\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eedMMD\u4e2d\u7684\u77e5\u8bc6\u9057\u5fd8\u548c\u672a\u6765\u6cdb\u5316\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.05532", "pdf": "https://arxiv.org/pdf/2507.05532", "abs": "https://arxiv.org/abs/2507.05532", "authors": ["Lala Shakti Swarup Ray", "Bo Zhou", "Paul Lukowicz"], "title": "W2W: A Simulated Exploration of IMU Placement Across the Human Body for Designing Smarter Wearable", "categories": ["cs.HC"], "comment": null, "summary": "Inertial measurement units (IMUs) are central to wearable systems for\nactivity recognition and pose estimation, but sensor placement remains largely\nguided by heuristics and convention. In this work, we introduce Where to Wear\n(W2W), a simulation-based framework for systematic exploration of IMU placement\nutility across the body. Using labeled motion capture data, W2W generates\nrealistic synthetic IMU signals at 512 anatomically distributed surface\npatches, enabling high-resolution, task-specific evaluation of sensor\nperformance. We validate reliability of W2W by comparing spatial performance\nrankings from synthetic data with real IMU recordings in two multimodal\ndatasets, confirming strong agreement in activity-wise trends. Further analysis\nreveals consistent spatial trends across activity types and uncovers overlooked\nhigh-utility regions that are rarely used in commercial systems. These findings\nchallenge long-standing placement norms and highlight opportunities for more\nefficient, task-adaptive sensor configurations. Overall, our results\ndemonstrate that simulation with W2W can serve as a powerful design tool for\noptimizing sensor placement, enabling scalable, data-driven strategies that are\nimpractical to obtain through physical experimentation alone.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86W2W\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u65b9\u6cd5\u7cfb\u7edf\u8bc4\u4f30IMU\u5728\u8eab\u4f53\u4e0d\u540c\u4f4d\u7f6e\u7684\u5b9e\u7528\u6027\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u4f20\u611f\u5668\u653e\u7f6e\u65b9\u5f0f\u3002", "motivation": "\u5f53\u524dIMU\u5728\u7a7f\u6234\u7cfb\u7edf\u4e2d\u7684\u653e\u7f6e\u591a\u4f9d\u8d56\u7ecf\u9a8c\u548c\u60ef\u4f8b\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u5e0c\u671b\u63d0\u51fa\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u8fd0\u52a8\u6355\u6349\u6570\u636e\u751f\u6210512\u4e2a\u4eba\u4f53\u8868\u9762\u533a\u57df\u7684\u5408\u6210IMU\u4fe1\u53f7\uff0c\u8bc4\u4f30\u4f20\u611f\u5668\u5728\u4e0d\u540c\u4f4d\u7f6e\u7684\u6027\u80fd\u3002", "result": "W2W\u6a21\u62df\u7ed3\u679c\u4e0e\u5b9e\u9645IMU\u6570\u636e\u4e00\u81f4\uff0c\u53d1\u73b0\u4e86\u4e00\u4e9b\u88ab\u5ffd\u89c6\u7684\u9ad8\u6548\u533a\u57df\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u653e\u7f6e\u89c4\u8303\u3002", "conclusion": "W2W\u4e3a\u4f20\u611f\u5668\u653e\u7f6e\u4f18\u5316\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u4eff\u771f\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.05428", "pdf": "https://arxiv.org/pdf/2507.05428", "abs": "https://arxiv.org/abs/2507.05428", "authors": ["Tein van der Lugt"], "title": "An order-theoretic circuit syntax and characterisation of the concept lattice", "categories": ["quant-ph", "cs.LO", "math.CO"], "comment": "15+2 pages, comments very welcome", "summary": "We take an order-theoretic approach to circuit (string diagram) syntax,\ntreating a circuit as a partial order with additional input-output structure.\nWe define morphisms between circuits and prove a factorisation theorem showing\nthat these can, in the finite case, be regarded as formalising a notion of\nsyntactical circuit rewrites, with quotient maps in particular corresponding to\ngate composition. We then consider the connectivity of a circuit, expressed as\na binary relation between its inputs and outputs, and characterise the concept\nlattice from formal concept analysis as the unique smallest circuit that admits\nmorphisms from all other circuits with the same connectivity. This has\nsignificance for quantum causality, particularly to the study of causal\ndecompositions of unitary transformations. We close by constructing the circuit\ncharacterised by the dual statement.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5e8f\u7406\u8bba\u65b9\u6cd5\u7814\u7a76\u7535\u8def\u8bed\u6cd5\uff0c\u5c06\u7535\u8def\u89c6\u4e3a\u5e26\u6709\u8f93\u5165\u8f93\u51fa\u7ed3\u6784\u7684\u504f\u5e8f\u96c6\uff0c\u5b9a\u4e49\u4e86\u7535\u8def\u95f4\u7684\u6001\u5c04\u5e76\u8bc1\u660e\u4e86\u5206\u89e3\u5b9a\u7406\u3002\u8fd8\u63a2\u8ba8\u4e86\u7535\u8def\u7684\u8fde\u901a\u6027\u53ca\u5176\u5728\u91cf\u5b50\u56e0\u679c\u6027\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u7535\u8def\u7684\u8bed\u6cd5\u7ed3\u6784\u548c\u91cd\u5199\u89c4\u5219\uff0c\u4e3a\u91cf\u5b50\u56e0\u679c\u6027\u7814\u7a76\u63d0\u4f9b\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002", "method": "\u5229\u7528\u504f\u5e8f\u96c6\u548c\u6001\u5c04\u5b9a\u4e49\u7535\u8def\u8bed\u6cd5\uff0c\u8bc1\u660e\u5206\u89e3\u5b9a\u7406\uff0c\u5e76\u63a2\u8ba8\u8fde\u901a\u6027\u4e0e\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\u7684\u8054\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u6709\u9650\u60c5\u51b5\u4e0b\uff0c\u6001\u5c04\u53ef\u4ee5\u5f62\u5f0f\u5316\u4e3a\u7535\u8def\u91cd\u5199\u89c4\u5219\uff0c\u5e76\u627e\u5230\u5177\u6709\u76f8\u540c\u8fde\u901a\u6027\u7684\u6700\u5c0f\u7535\u8def\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u91cf\u5b50\u56e0\u679c\u6027\u4e2d\u7684\u56e0\u679c\u5206\u89e3\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u6784\u9020\u4e86\u5bf9\u5076\u7535\u8def\u4ee5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u7406\u8bba\u3002"}}
{"id": "2507.05869", "pdf": "https://arxiv.org/pdf/2507.05869", "abs": "https://arxiv.org/abs/2507.05869", "authors": ["Tim C. Rese", "David Bermbach"], "title": "Towards an Application-Centric Benchmark Suite for Spatiotemporal Database Systems", "categories": ["cs.DB"], "comment": null, "summary": "Spatiotemporal data play a key role for mobility-based applications and are\ntheir produced volume is growing continuously, among others, due to the\nincreased availability of IoT devices.\n  When working with spatiotemporal data, developers rely on spatiotemporal\ndatabase systems such as PostGIS or MobilityDB.\n  For better understanding their quality of service behavior and then choosing\nthe best system, benchmarking is the go-to approach.\n  Unfortunately, existing work in this field studies only small isolated\naspects and a comprehensive application-centric benchmark suite is still\nmissing.\n  In this paper, we argue that an application-centric benchmark suite for\nspatiotemporal database systems is urgently needed.\n  We identify requirements for such a benchmark suite, discuss domain-specific\nchallenges, and sketch-out the architecture of a modular benchmarking suite.", "AI": {"tldr": "\u672c\u6587\u5f3a\u8c03\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u9762\u5411\u5e94\u7528\u7684\u65f6\u7a7a\u6570\u636e\u5e93\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u4ee5\u6ee1\u8db3\u5bf9\u7cfb\u7edf\u670d\u52a1\u8d28\u91cf\u7684\u7406\u89e3\u548c\u9009\u62e9\u3002", "motivation": "\u7531\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u7684\u666e\u53ca\uff0c\u65f6\u7a7a\u6570\u636e\u91cf\u6301\u7eed\u589e\u957f\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u5173\u6ce8\u5c0f\u8303\u56f4\u5b64\u7acb\u95ee\u9898\uff0c\u7f3a\u5c11\u5168\u9762\u7684\u5e94\u7528\u5bfc\u5411\u6d4b\u8bd5\u5957\u4ef6\u3002", "method": "\u63d0\u51fa\u6784\u5efa\u6a21\u5757\u5316\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u7684\u9700\u6c42\uff0c\u8ba8\u8bba\u9886\u57df\u6311\u6218\uff0c\u5e76\u8bbe\u8ba1\u5176\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u5e94\u7528\u7684\u65f6\u7a7a\u6570\u636e\u5e93\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u7684\u67b6\u6784\u6846\u67b6\u3002", "conclusion": "\u4e3a\u65f6\u7a7a\u6570\u636e\u5e93\u7cfb\u7edf\u5f00\u53d1\u4e00\u4e2a\u7efc\u5408\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u662f\u8feb\u5207\u9700\u8981\u7684\u3002"}}
{"id": "2507.06011", "pdf": "https://arxiv.org/pdf/2507.06011", "abs": "https://arxiv.org/abs/2507.06011", "authors": ["Daghash K. Alqahtani", "Maria A. Rodriguez", "Muhammad Aamir Cheema", "Hamid Rezatofighi", "Adel N. Toosi"], "title": "ECORE: Energy-Conscious Optimized Routing for Deep Learning Models at the Edge", "categories": ["cs.DC", "cs.CV"], "comment": null, "summary": "Edge computing enables data processing closer to the source, significantly\nreducing latency an essential requirement for real-time vision-based analytics\nsuch as object detection in surveillance and smart city environments. However,\nthese tasks place substantial demands on resource constrained edge devices,\nmaking the joint optimization of energy consumption and detection accuracy\ncritical. To address this challenge, we propose ECORE, a framework that\nintegrates multiple dynamic routing strategies including estimation based\ntechniques and a greedy selection algorithm to direct image processing requests\nto the most suitable edge device-model pair. ECORE dynamically balances energy\nefficiency and detection performance based on object characteristics. We\nevaluate our approach through extensive experiments on real-world datasets,\ncomparing the proposed routers against widely used baseline techniques. The\nevaluation leverages established object detection models (YOLO, SSD,\nEfficientDet) and diverse edge platforms, including Jetson Orin Nano, Raspberry\nPi 4 and 5, and TPU accelerators. Results demonstrate that our proposed\ncontext-aware routing strategies can reduce energy consumption and latency by\n45% and 49%, respectively, while incurring only a 2% loss in detection accuracy\ncompared to accuracy-centric methods.", "AI": {"tldr": "ECORE\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8def\u7531\u7b56\u7565\u4f18\u5316\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u3002", "motivation": "\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\uff0c\u5b9e\u65f6\u89c6\u89c9\u5206\u6790\uff08\u5982\u76ee\u6807\u68c0\u6d4b\uff09\u5bf9\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u63d0\u51fa\u4e86\u9ad8\u8981\u6c42\uff0c\u9700\u8981\u540c\u65f6\u4f18\u5316\u80fd\u8017\u548c\u68c0\u6d4b\u7cbe\u5ea6\u3002", "method": "ECORE\u6846\u67b6\u7ed3\u5408\u591a\u79cd\u52a8\u6001\u8def\u7531\u7b56\u7565\uff08\u4f30\u8ba1\u6280\u672f\u548c\u8d2a\u5fc3\u9009\u62e9\u7b97\u6cd5\uff09\uff0c\u5c06\u56fe\u50cf\u5904\u7406\u8bf7\u6c42\u5206\u914d\u5230\u6700\u5408\u9002\u7684\u8fb9\u7f18\u8bbe\u5907-\u6a21\u578b\u7ec4\u5408\uff0c\u52a8\u6001\u5e73\u8861\u80fd\u6548\u548c\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cECORE\u80fd\u5c06\u80fd\u8017\u548c\u5ef6\u8fdf\u5206\u522b\u964d\u4f4e45%\u548c49%\uff0c\u68c0\u6d4b\u7cbe\u5ea6\u4ec5\u635f\u59312%\u3002", "conclusion": "ECORE\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\uff0c\u5e73\u8861\u4e86\u80fd\u6548\u548c\u7cbe\u5ea6\u3002"}}
{"id": "2507.05536", "pdf": "https://arxiv.org/pdf/2507.05536", "abs": "https://arxiv.org/abs/2507.05536", "authors": ["Moseli Mots'oehli", "Feimei Chen", "Hok Wai Chan", "Itumeleng Tlali", "Thulani Babeli", "Kyungim Baek", "Huaijin Chen"], "title": "Simulating Refractive Distortions and Weather-Induced Artifacts for Resource-Constrained Autonomous Perception", "categories": ["cs.CV", "cs.ET", "cs.LG"], "comment": "This paper has been submitted to the ICCV 2025 Workshop on Computer\n  Vision for Developing Countries (CV4DC) for review", "summary": "The scarcity of autonomous vehicle datasets from developing regions,\nparticularly across Africa's diverse urban, rural, and unpaved roads, remains a\nkey obstacle to robust perception in low-resource settings. We present a\nprocedural augmentation pipeline that enhances low-cost monocular dashcam\nfootage with realistic refractive distortions and weather-induced artifacts\ntailored to challenging African driving scenarios. Our refractive module\nsimulates optical effects from low-quality lenses and air turbulence, including\nlens distortion, Perlin noise, Thin-Plate Spline (TPS), and divergence-free\n(incompressible) warps. The weather module adds homogeneous fog, heterogeneous\nfog, and lens flare. To establish a benchmark, we provide baseline performance\nusing three image restoration models. To support perception research in\nunderrepresented African contexts, without costly data collection, labeling, or\nsimulation, we release our distortion toolkit, augmented dataset splits, and\nbenchmark results.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u589e\u5f3a\u4f4e\u6210\u672c\u5355\u76ee\u884c\u8f66\u8bb0\u5f55\u4eea\u89c6\u9891\u6570\u636e\u7684\u7ba1\u9053\uff0c\u4ee5\u6a21\u62df\u975e\u6d32\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u5149\u5b66\u548c\u5929\u6c14\u6548\u5e94\uff0c\u5e76\u63d0\u4f9b\u4e86\u57fa\u51c6\u6027\u80fd\u6d4b\u8bd5\u548c\u5de5\u5177\u5305\u3002", "motivation": "\u89e3\u51b3\u53d1\u5c55\u4e2d\u56fd\u5bb6\uff08\u5c24\u5176\u662f\u975e\u6d32\uff09\u7f3a\u4e4f\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u5728\u8d44\u6e90\u532e\u4e4f\u73af\u5883\u4e0b\u7684\u611f\u77e5\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e86\u6298\u5c04\u6a21\u5757\u548c\u5929\u6c14\u6a21\u5757\uff0c\u6a21\u62df\u4f4e\u8d28\u91cf\u955c\u5934\u7684\u5149\u5b66\u6548\u5e94\u548c\u5929\u6c14\u76f8\u5173\u566a\u58f0\uff0c\u5e76\u901a\u8fc7\u4e09\u79cd\u56fe\u50cf\u4fee\u590d\u6a21\u578b\u5efa\u7acb\u4e86\u57fa\u51c6\u6027\u80fd\u3002", "result": "\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u6570\u636e\u96c6\u3001\u5de5\u5177\u5305\u548c\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff0c\u652f\u6301\u5728\u975e\u6d32\u7b49\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u7684\u7814\u7a76\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f4e\u6210\u672c\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u907f\u514d\u4e86\u6602\u8d35\u7684\u6570\u636e\u91c7\u96c6\u548c\u6a21\u62df\u6210\u672c\u3002"}}
{"id": "2507.06127", "pdf": "https://arxiv.org/pdf/2507.06127", "abs": "https://arxiv.org/abs/2507.06127", "authors": ["Dongsheng Zuo", "Jiadong Zhu", "Yang Luo", "Yuzhe Ma"], "title": "PrefixAgent: An LLM-Powered Design Framework for Efficient Prefix Adder Optimization", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Prefix adders are fundamental arithmetic circuits, but their design space\ngrows exponentially with bit-width, posing significant optimization challenges.\nPrevious works face limitations in performance, generalization, and\nscalability. To address these challenges, we propose PrefixAgent, a large\nlanguage model (LLM)-powered framework that enables efficient prefix adder\noptimization. Specifically, PrefixAgent reformulates the problem into subtasks\nincluding backbone synthesis and structure refinement, which effectively\nreduces the search space. More importantly, this new design perspective enables\nus to efficiently collect enormous high-quality data and reasoning traces with\nE-graph, which further results in an effective fine-tuning of LLM. Experimental\nresults show that PrefixAgent synthesizes prefix adders with consistently\nsmaller areas compared to baseline methods, while maintaining scalability and\ngeneralization in commercial EDA flows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6PrefixAgent\uff0c\u901a\u8fc7\u5206\u89e3\u4efb\u52a1\u548c\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u524d\u7f00\u52a0\u6cd5\u5668\u7684\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u524d\u7f00\u52a0\u6cd5\u5668\u8bbe\u8ba1\u7a7a\u95f4\u968f\u4f4d\u6570\u6307\u6570\u589e\u957f\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u3001\u6cdb\u5316\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u9700\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5c06\u4f18\u5316\u4efb\u52a1\u5206\u89e3\u4e3a\u9aa8\u67b6\u5408\u6210\u4e0e\u7ed3\u6784\u7ec6\u5316\uff0c\u5229\u7528E-graph\u6536\u96c6\u6570\u636e\u5e76\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "PrefixAgent\u751f\u6210\u7684\u524d\u7f00\u52a0\u6cd5\u5668\u9762\u79ef\u66f4\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u5546\u4e1aEDA\u5de5\u5177\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "PrefixAgent\u4e3a\u524d\u7f00\u52a0\u6cd5\u5668\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u3001\u53ef\u6269\u5c55\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2507.05307", "pdf": "https://arxiv.org/pdf/2507.05307", "abs": "https://arxiv.org/abs/2507.05307", "authors": ["Xuanqi Gao", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Chao Shen"], "title": "ASSURE: Metamorphic Testing for AI-powered Browser Extensions", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The integration of Large Language Models (LLMs) into browser extensions has\nrevolutionized web browsing, enabling sophisticated functionalities like\ncontent summarization, intelligent translation, and context-aware writing\nassistance. However, these AI-powered extensions introduce unprecedented\nchallenges in testing and reliability assurance. Traditional browser extension\ntesting approaches fail to address the non-deterministic behavior,\ncontext-sensitivity, and complex web environment integration inherent to\nLLM-powered extensions. Similarly, existing LLM testing methodologies operate\nin isolation from browser-specific contexts, creating a critical gap in\neffective evaluation frameworks. To bridge this gap, we present ASSURE, a\nmodular automated testing framework specifically designed for AI-powered\nbrowser extensions. ASSURE comprises three principal components: (1) a modular\ntest case generation engine that supports plugin-based extension of testing\nscenarios, (2) an automated execution framework that orchestrates the complex\ninteractions between web content, extension processing, and AI model behavior,\nand (3) a configurable validation pipeline that systematically evaluates\nbehavioral consistency and security invariants rather than relying on exact\noutput matching. Our evaluation across six widely-used AI browser extensions\ndemonstrates ASSURE's effectiveness, identifying 531 distinct issues spanning\nsecurity vulnerabilities, metamorphic relation violations, and content\nalignment problems. ASSURE achieves 6.4x improved testing throughput compared\nto manual approaches, detecting critical security vulnerabilities within 12.4\nminutes on average. This efficiency makes ASSURE practical for integration into\ndevelopment pipelines, offering a comprehensive solution to the unique\nchallenges of testing AI-powered browser extensions.", "AI": {"tldr": "ASSURE\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3aAI\u6d4f\u89c8\u5668\u6269\u5c55\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u548cLLM\u6d4b\u8bd5\u65b9\u6cd5\u5728\u975e\u786e\u5b9a\u6027\u884c\u4e3a\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u548c\u590d\u6742\u7f51\u9875\u96c6\u6210\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "AI\u6d4f\u89c8\u5668\u6269\u5c55\u7684\u6d4b\u8bd5\u548c\u53ef\u9760\u6027\u4fdd\u969c\u9762\u4e34\u524d\u6240\u672a\u6709\u7684\u6311\u6218\uff0c\u4f20\u7edf\u7684\u6d4b\u8bd5\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9\u5176\u975e\u786e\u5b9a\u6027\u548c\u590d\u6742\u6027\u3002", "method": "ASSURE\u6846\u67b6\u5305\u542b\u6a21\u5757\u5316\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5f15\u64ce\u3001\u81ea\u52a8\u5316\u6267\u884c\u6846\u67b6\u548c\u53ef\u914d\u7f6e\u7684\u9a8c\u8bc1\u7ba1\u9053\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u884c\u4e3a\u4e00\u81f4\u6027\u548c\u5b89\u5168\u6027\u3002", "result": "\u5728\u516d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684AI\u6d4f\u89c8\u5668\u6269\u5c55\u4e2d\uff0cASSURE\u8bc6\u522b\u51fa531\u4e2a\u95ee\u9898\uff0c\u6d4b\u8bd5\u541e\u5410\u91cf\u6bd4\u624b\u52a8\u65b9\u6cd5\u63d0\u5347\u4e866.4\u500d\u3002", "conclusion": "ASSURE\u4e3a\u6d4b\u8bd5AI\u6d4f\u89c8\u5668\u6269\u5c55\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u96c6\u6210\u5230\u5f00\u53d1\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2507.05906", "pdf": "https://arxiv.org/pdf/2507.05906", "abs": "https://arxiv.org/abs/2507.05906", "authors": ["Chenhao Li", "Marco Hutter", "Andreas Krause"], "title": "Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why", "categories": ["cs.LG", "cs.AI", "cs.GR", "cs.RO"], "comment": null, "summary": "This survey provides a comparative analysis of feature-based and GAN-based\napproaches to learning from demonstrations, with a focus on the structure of\nreward functions and their implications for policy learning. Feature-based\nmethods offer dense, interpretable rewards that excel at high-fidelity motion\nimitation, yet often require sophisticated representations of references and\nstruggle with generalization in unstructured settings. GAN-based methods, in\ncontrast, use implicit, distributional supervision that enables scalability and\nadaptation flexibility, but are prone to training instability and coarse reward\nsignals. Recent advancements in both paradigms converge on the importance of\nstructured motion representations, which enable smoother transitions,\ncontrollable synthesis, and improved task integration. We argue that the\ndichotomy between feature-based and GAN-based methods is increasingly nuanced:\nrather than one paradigm dominating the other, the choice should be guided by\ntask-specific priorities such as fidelity, diversity, interpretability, and\nadaptability. This work outlines the algorithmic trade-offs and design\nconsiderations that underlie method selection, offering a framework for\nprincipled decision-making in learning from demonstrations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6bd4\u8f83\u4e86\u7279\u5f81\u57fa\u548cGAN\u57fa\u7684\u5b66\u4e60\u6f14\u793a\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u5956\u52b1\u51fd\u6570\u7ed3\u6784\u5bf9\u7b56\u7565\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u4e24\u8005\u5404\u6709\u4f18\u52a3\uff0c\u9009\u62e9\u5e94\u57fa\u4e8e\u4efb\u52a1\u9700\u6c42\u3002", "motivation": "\u7814\u7a76\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u5728\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u65f6\u7684\u8868\u73b0\uff0c\u4ee5\u6307\u5bfc\u5b9e\u9645\u5e94\u7528\u4e2d\u65b9\u6cd5\u7684\u9009\u62e9\u3002", "method": "\u5bf9\u6bd4\u7279\u5f81\u57fa\u548cGAN\u57fa\u65b9\u6cd5\u7684\u5956\u52b1\u51fd\u6570\u7ed3\u6784\u53ca\u5176\u5bf9\u7b56\u7565\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5206\u6790\u5176\u4f18\u7f3a\u70b9\u3002", "result": "\u7279\u5f81\u57fa\u65b9\u6cd5\u9002\u5408\u9ad8\u4fdd\u771f\u8fd0\u52a8\u6a21\u4eff\uff0c\u800cGAN\u57fa\u65b9\u6cd5\u66f4\u5177\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\uff0c\u4f46\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002\u4e24\u8005\u5747\u9700\u7ed3\u6784\u5316\u8fd0\u52a8\u8868\u793a\u3002", "conclusion": "\u65b9\u6cd5\u9009\u62e9\u5e94\u57fa\u4e8e\u4efb\u52a1\u9700\u6c42\uff0c\u5982\u4fdd\u771f\u5ea6\u3001\u591a\u6837\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\uff0c\u800c\u975e\u5355\u7eaf\u8ffd\u6c42\u67d0\u4e00\u8303\u5f0f\u3002"}}
{"id": "2507.06001", "pdf": "https://arxiv.org/pdf/2507.06001", "abs": "https://arxiv.org/abs/2507.06001", "authors": ["Carlo Segat", "Sandro Rodriguez Garzo", "Axel K\u00fcpper"], "title": "Programmable Governance for Group-Controlled Decentralized Identifiers", "categories": ["cs.NI"], "comment": null, "summary": "Self-Sovereign Identity (SSI) is a paradigm for digital identity management\nthat offers unique privacy advantages. A key technology in SSI is Decentralized\nIdentifiers (DIDs) and their associated metadata, DID Documents (DDOs). DDOs\ncontain crucial verification material such as the public keys of the entity\nidentified by the DID (i.e., the DID subject) and are often anchored on a\ndistributed ledger to ensure security and availability. Long-lived DIDs need to\nsupport updates (e.g., key rotation). Ideally, only the DID subject should\nauthorize DDO updates. However, in practice, update capabilities may be shared\nor delegated. While the DID specification acknowledges such scenarios, it does\nnot define how updates should be authorized when multiple entities jointly\ncontrol a DID (i.e., group control). This article examines the implementation\nof an on-chain, trustless mechanism enabling DID controllers under group\ncontrol to program their governance rules. The main research question is the\nfollowing: Can a technical mechanism be developed to orchestrate on-chain group\ncontrol of a DDO in a ledger-agnostic and adaptable manner?", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\uff08SSI\uff09\u4e2d\u5b9e\u73b0\u591a\u65b9\u5171\u540c\u63a7\u5236\u7684 DID \u66f4\u65b0\u673a\u5236\uff0c\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u4fe1\u4efb\u3001\u53ef\u7f16\u7a0b\u4e14\u4e0d\u4f9d\u8d56\u7279\u5b9a\u5206\u5e03\u5f0f\u8d26\u672c\u7684\u6280\u672f\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684 DID \u89c4\u8303\u867d\u7136\u627f\u8ba4\u591a\u65b9\u5171\u540c\u63a7\u5236\u7684\u573a\u666f\uff0c\u4f46\u672a\u660e\u786e\u5b9a\u4e49\u5982\u4f55\u6388\u6743\u66f4\u65b0\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u591a\u65b9\u534f\u4f5c\u65f6\u3002\u7f3a\u4e4f\u7edf\u4e00\u4e14\u7075\u6d3b\u7684\u6280\u672f\u673a\u5236\u9650\u5236\u4e86 DID \u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u94fe\u4e0a\u7684\u3001\u65e0\u9700\u4fe1\u4efb\u7684\u673a\u5236\uff0c\u5141\u8bb8 DID \u7684\u63a7\u5236\u8005\u5728\u591a\u65b9\u534f\u4f5c\u4e0b\u7f16\u7a0b\u5236\u5b9a\u6cbb\u7406\u89c4\u5219\u3002\u91cd\u70b9\u5728\u4e8e\u786e\u4fdd\u8be5\u673a\u5236\u4e0d\u4f9d\u8d56\u7279\u5b9a\u8d26\u672c\uff0c\u4e14\u5177\u6709\u9002\u5e94\u6027\u3002", "result": "\u7814\u7a76\u8bc1\u660e\uff0c\u53ef\u4ee5\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u5b9e\u73b0\u591a\u65b9\u5171\u540c\u63a7\u5236\u7684 DDO \u66f4\u65b0\uff0c\u4e14\u8be5\u673a\u5236\u80fd\u5728\u4e0d\u540c\u5206\u5e03\u5f0f\u8d26\u672c\u4e0a\u901a\u7528\u3002", "conclusion": "\u8be5\u673a\u5236\u4e3a\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u6cbb\u7406\u65b9\u6848\uff0c\u652f\u6301\u590d\u6742\u7684\u591a\u65b9\u534f\u4f5c\u573a\u666f\uff0c\u586b\u8865\u4e86\u73b0\u6709\u89c4\u8303\u7684\u7a7a\u767d\u3002"}}
{"id": "2507.06071", "pdf": "https://arxiv.org/pdf/2507.06071", "abs": "https://arxiv.org/abs/2507.06071", "authors": ["Chang Liu", "Ye Pan", "Chenyang Ding", "Susanto Rahardja", "Xiaokang Yang"], "title": "MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding", "categories": ["cs.CV", "cs.MM"], "comment": "11 pages, 8 figures", "summary": "Audio-driven emotional 3D facial animation aims to generate synchronized lip\nmovements and vivid facial expressions. However, most existing approaches focus\non static and predefined emotion labels, limiting their diversity and\nnaturalness. To address these challenges, we propose MEDTalk, a novel framework\nfor fine-grained and dynamic emotional talking head generation. Our approach\nfirst disentangles content and emotion embedding spaces from motion sequences\nusing a carefully designed cross-reconstruction process, enabling independent\ncontrol over lip movements and facial expressions. Beyond conventional\naudio-driven lip synchronization, we integrate audio and speech text,\npredicting frame-wise intensity variations and dynamically adjusting static\nemotion features to generate realistic emotional expressions. Furthermore, to\nenhance control and personalization, we incorporate multimodal inputs-including\ntext descriptions and reference expression images-to guide the generation of\nuser-specified facial expressions. With MetaHuman as the priority, our\ngenerated results can be conveniently integrated into the industrial production\npipeline.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MEDTalk\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u548c\u7ec6\u7c92\u5ea6\u7684\u60c5\u611f\u63a7\u5236\u751f\u6210\u903c\u771f\u76843D\u9762\u90e8\u52a8\u753b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u60c5\u611f\u6807\u7b7e\u9759\u6001\u548c\u9884\u5b9a\u4e49\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u9759\u6001\u548c\u9884\u5b9a\u4e49\u7684\u60c5\u611f\u6807\u7b7e\uff0c\u9650\u5236\u4e86\u52a8\u753b\u7684\u591a\u6837\u6027\u548c\u81ea\u7136\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u60c5\u611f\u7279\u5f81\uff0c\u751f\u6210\u66f4\u81ea\u7136\u548c\u591a\u6837\u5316\u7684\u9762\u90e8\u8868\u60c5\u3002", "method": "MEDTalk\u901a\u8fc7\u4ea4\u53c9\u91cd\u5efa\u8fc7\u7a0b\u5206\u89e3\u5185\u5bb9\u548c\u60c5\u611f\u5d4c\u5165\u7a7a\u95f4\uff0c\u72ec\u7acb\u63a7\u5236\u5507\u90e8\u8fd0\u52a8\u548c\u9762\u90e8\u8868\u60c5\u3002\u7ed3\u5408\u97f3\u9891\u548c\u8bed\u97f3\u6587\u672c\u9884\u6d4b\u5f3a\u5ea6\u53d8\u5316\uff0c\u52a8\u6001\u8c03\u6574\u9759\u6001\u60c5\u611f\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u591a\u6a21\u6001\u8f93\u5165\uff08\u6587\u672c\u63cf\u8ff0\u548c\u53c2\u8003\u8868\u60c5\u56fe\u50cf\uff09\u589e\u5f3a\u63a7\u5236\u3002", "result": "\u751f\u6210\u7684\u52a8\u753b\u53ef\u4ee5\u4e0e\u5de5\u4e1a\u751f\u4ea7\u7ebf\uff08\u5982MetaHuman\uff09\u65e0\u7f1d\u96c6\u6210\uff0c\u63d0\u9ad8\u4e86\u5b9e\u7528\u6027\u548c\u903c\u771f\u5ea6\u3002", "conclusion": "MEDTalk\u6846\u67b6\u5728\u52a8\u6001\u60c5\u611f\u63a7\u5236\u548c\u591a\u6a21\u6001\u8f93\u5165\u7684\u652f\u6301\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u9762\u90e8\u52a8\u753b\u7684\u591a\u6837\u6027\u548c\u81ea\u7136\u6027\uff0c\u9002\u5408\u5de5\u4e1a\u5e94\u7528\u3002"}}
{"id": "2507.05537", "pdf": "https://arxiv.org/pdf/2507.05537", "abs": "https://arxiv.org/abs/2507.05537", "authors": ["Tim Gorichanaz"], "title": "Information Needs and Practices Supported by ChatGPT", "categories": ["cs.HC", "cs.IR"], "comment": "To be presented at the 2025 ASIS&T virtual satellite meeting,\n  December 2025", "summary": "This study considers ChatGPT as an information source, investigating the\ninformation needs that people come to ChatGPT with and the information\npractices that ChatGPT supports, through a qualitative content analysis of 205\nuser vignettes. The findings show that ChatGPT is used in a range of life\ndomains (home/family, work, leisure, etc.) and for a range of human needs\n(writing/editing, learning, simple programming tasks, etc.), constituting the\ninformation needs that people use ChatGPT to address. Related to these\ninformation needs, the findings show six categories of information practices\nthat ChatGPT supports: Writing, Deciding, Identifying, Ideating, Talking, and\nCritiquing. This work suggests that, in the AI age, information need should be\nconceptualized not just as a matter of \"getting questions answered\" or even\n\"making sense,\" but as skillfully coping in the world, a notion that includes\nboth understanding and action. This study leads to numerous opportunities for\nfuture work at the junction of generative AI and information needs, seeking,\nuse and experience.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5b9a\u6027\u5185\u5bb9\u5206\u6790205\u4e2a\u7528\u6237\u6848\u4f8b\uff0c\u63a2\u8ba8ChatGPT\u4f5c\u4e3a\u4fe1\u606f\u6e90\u7684\u4f7f\u7528\u573a\u666f\u548c\u4fe1\u606f\u5b9e\u8df5\uff0c\u53d1\u73b0\u5176\u652f\u6301\u591a\u79cd\u751f\u6d3b\u9886\u57df\u548c\u9700\u6c42\uff0c\u5e76\u63d0\u51fa\u4e86\u516d\u7c7b\u4fe1\u606f\u5b9e\u8df5\u3002", "motivation": "\u63a2\u8ba8ChatGPT\u5982\u4f55\u6ee1\u8db3\u7528\u6237\u7684\u4fe1\u606f\u9700\u6c42\uff0c\u5e76\u91cd\u65b0\u5b9a\u4e49AI\u65f6\u4ee3\u7684\u4fe1\u606f\u9700\u6c42\u6982\u5ff5\u3002", "method": "\u901a\u8fc7\u5b9a\u6027\u5185\u5bb9\u5206\u6790205\u4e2a\u7528\u6237\u6848\u4f8b\u3002", "result": "ChatGPT\u5e94\u7528\u4e8e\u591a\u4e2a\u751f\u6d3b\u9886\u57df\uff08\u5bb6\u5ead\u3001\u5de5\u4f5c\u3001\u4f11\u95f2\u7b49\uff09\u548c\u9700\u6c42\uff08\u5199\u4f5c\u3001\u5b66\u4e60\u3001\u7f16\u7a0b\u7b49\uff09\uff0c\u5e76\u652f\u6301\u516d\u7c7b\u4fe1\u606f\u5b9e\u8df5\uff1a\u5199\u4f5c\u3001\u51b3\u7b56\u3001\u8bc6\u522b\u3001\u6784\u601d\u3001\u5bf9\u8bdd\u548c\u6279\u8bc4\u3002", "conclusion": "AI\u65f6\u4ee3\u7684\u4fe1\u606f\u9700\u6c42\u5e94\u4ece\u201c\u56de\u7b54\u95ee\u9898\u201d\u6269\u5c55\u5230\u201c\u5728\u4e16\u754c\u4e2d\u719f\u7ec3\u5e94\u5bf9\u201d\uff0c\u4e3a\u751f\u6210\u5f0fAI\u4e0e\u4fe1\u606f\u9700\u6c42\u7814\u7a76\u5f00\u8f9f\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.05438", "pdf": "https://arxiv.org/pdf/2507.05438", "abs": "https://arxiv.org/abs/2507.05438", "authors": ["Josefine B. Graebener", "Inigo Incer", "Richard M. Murray"], "title": "A Compositional Approach to Diagnosing Faults in Cyber-Physical Systems", "categories": ["eess.SY", "cs.LO", "cs.SY"], "comment": null, "summary": "Identifying the cause of a system-level failure in a cyber-physical system\n(CPS) can be like tracing a needle in a haystack. This paper approaches the\nproblem by assuming that the CPS has been designed compositionally and that\neach component in the system is associated with an assume-guarantee contract.\nWe exploit recent advances in contract-based design that show how to compute\nthe contract for the entire system using the component-level contracts. When\npresented with a system-level failure, our approach is able to efficiently\nidentify the components that are responsible for the system-level failure\ntogether with the specific predicates in those components' specifications that\nare involved in the fault. We implemented this approach using Pacti and\ndemonstrate it through illustrative examples inspired by an autonomous vehicle\nin the DARPA urban challenge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5951\u7ea6\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8bc6\u522b\u5bfc\u81f4\u7cfb\u7edf\u7ea7\u6545\u969c\u7684\u7ec4\u4ef6\u53ca\u5176\u89c4\u8303\u4e2d\u7684\u7279\u5b9a\u8c13\u8bcd\u3002", "motivation": "\u5728\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\uff08CPS\uff09\u4e2d\uff0c\u7cfb\u7edf\u7ea7\u6545\u969c\u7684\u6839\u6e90\u5f80\u5f80\u96be\u4ee5\u8ffd\u8e2a\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u5229\u7528\u7ec4\u5408\u8bbe\u8ba1\u548c\u7ec4\u4ef6\u7ea7\u5951\u7ea6\u6765\u7b80\u5316\u6545\u969c\u8bca\u65ad\u8fc7\u7a0b\u3002", "method": "\u5047\u8bbeCPS\u91c7\u7528\u7ec4\u5408\u8bbe\u8ba1\uff0c\u6bcf\u4e2a\u7ec4\u4ef6\u9644\u6709\u5047\u8bbe-\u4fdd\u8bc1\u5951\u7ea6\u3002\u901a\u8fc7\u8ba1\u7b97\u7cfb\u7edf\u7ea7\u5951\u7ea6\uff0c\u7ed3\u5408\u7ec4\u4ef6\u7ea7\u5951\u7ea6\uff0c\u5feb\u901f\u5b9a\u4f4d\u6545\u969c\u7ec4\u4ef6\u53ca\u5176\u89c4\u8303\u4e2d\u7684\u76f8\u5173\u8c13\u8bcd\u3002", "result": "\u4f7f\u7528Pacti\u5de5\u5177\u5b9e\u73b0\u8be5\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7DARPA\u57ce\u5e02\u6311\u6218\u4e2d\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u6848\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u5b9a\u4f4d\u7cfb\u7edf\u7ea7\u6545\u969c\u7684\u6839\u6e90\uff0c\u4e3aCPS\u7684\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.06005", "pdf": "https://arxiv.org/pdf/2507.06005", "abs": "https://arxiv.org/abs/2507.06005", "authors": ["Diana Baumann", "Tim C. Rese", "David Bermbach"], "title": "Towards Serverless Processing of Spatiotemporal Big Data Queries", "categories": ["cs.DB", "cs.DC"], "comment": null, "summary": "Spatiotemporal data are being produced in continuously growing volumes by a\nvariety of data sources and a variety of application fields rely on rapid\nanalysis of such data. Existing systems such as PostGIS or MobilityDB usually\nbuild on relational database systems, thus, inheriting their scale-out\ncharacteristics. As a consequence, big spatiotemporal data scenarios still have\nlimited support even though many query types can easily be parallelized. In\nthis paper, we propose our vision of a native serverless data processing\napproach for spatiotemporal data: We break down queries into small subqueries\nwhich then leverage the near-instant scaling of Function-as-a-Service platforms\nto execute them in parallel. With this, we partially solve the scalability\nneeds of big spatiotemporal data processing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7684\u65f6\u7a7a\u6570\u636e\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u6267\u884c\u5b50\u67e5\u8be2\u6765\u89e3\u51b3\u5927\u6570\u636e\u573a\u666f\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5173\u7cfb\u6570\u636e\u5e93\u7684\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u5904\u7406\u4e2d\u6269\u5c55\u6027\u6709\u9650\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u5c0f\u4efb\u52a1\uff0c\u5229\u7528FaaS\u5e73\u53f0\u7684\u5373\u65f6\u6269\u5c55\u80fd\u529b\u5e76\u884c\u6267\u884c\u3002", "result": "\u90e8\u5206\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u5904\u7406\u7684\u6269\u5c55\u6027\u9700\u6c42\u3002", "conclusion": "\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u4e3a\u65f6\u7a7a\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.06031", "pdf": "https://arxiv.org/pdf/2507.06031", "abs": "https://arxiv.org/abs/2507.06031", "authors": ["Juncheng Jia", "Ji Liu", "Chao Huo", "Yihui Shen", "Yang Zhou", "Huaiyu Dai", "Dejing Dou"], "title": "Efficient Federated Learning with Timely Update Dissemination", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "38 pages, to appear in Knowledge and Information Systems (KAIS)", "summary": "Federated Learning (FL) has emerged as a compelling methodology for the\nmanagement of distributed data, marked by significant advancements in recent\nyears. In this paper, we propose an efficient FL approach that capitalizes on\nadditional downlink bandwidth resources to ensure timely update dissemination.\nInitially, we implement this strategy within an asynchronous framework,\nintroducing the Asynchronous Staleness-aware Model Update (FedASMU), which\nintegrates both server-side and device-side methodologies. On the server side,\nwe present an asynchronous FL system model that employs a dynamic model\naggregation technique, which harmonizes local model updates with the global\nmodel to enhance both accuracy and efficiency. Concurrently, on the device\nside, we propose an adaptive model adjustment mechanism that integrates the\nlatest global model with local models during training to further elevate\naccuracy. Subsequently, we extend this approach to a synchronous context,\nreferred to as FedSSMU. Theoretical analyses substantiate the convergence of\nour proposed methodologies. Extensive experiments, encompassing six models and\nfive public datasets, demonstrate that FedASMU and FedSSMU significantly\nsurpass baseline methods in terms of both accuracy (up to 145.87%) and\nefficiency (up to 97.59%).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u989d\u5916\u7684\u4e0b\u884c\u5e26\u5bbd\u8d44\u6e90\uff0c\u8bbe\u8ba1\u4e86\u5f02\u6b65\uff08FedASMU\uff09\u548c\u540c\u6b65\uff08FedSSMU\uff09\u4e24\u79cd\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5904\u7406\u5206\u5e03\u5f0f\u6570\u636e\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u66f4\u65b0\u4f20\u64ad\u7684\u53ca\u65f6\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5229\u7528\u989d\u5916\u4e0b\u884c\u5e26\u5bbd\u8d44\u6e90\uff0c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5f02\u6b65\uff08FedASMU\uff09\u548c\u540c\u6b65\uff08FedSSMU\uff09\u4e24\u79cd\u7b56\u7565\u3002\u5f02\u6b65\u7b56\u7565\u7ed3\u5408\u52a8\u6001\u6a21\u578b\u805a\u5408\u548c\u81ea\u9002\u5e94\u6a21\u578b\u8c03\u6574\uff1b\u540c\u6b65\u7b56\u7565\u5219\u5ef6\u4f38\u4e86\u5f02\u6b65\u65b9\u6cd5\u7684\u6838\u5fc3\u601d\u60f3\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0cFedASMU\u548cFedSSMU\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6700\u9ad8\u63d0\u5347145.87%\u7684\u51c6\u786e\u6027\u548c97.59%\u7684\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u901a\u8fc7\u5f02\u6b65\u548c\u540c\u6b65\u7b56\u7565\u4f18\u5316\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u66f4\u65b0\u4f20\u64ad\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.05531", "pdf": "https://arxiv.org/pdf/2507.05531", "abs": "https://arxiv.org/abs/2507.05531", "authors": ["Sanaz Kazemi Abharian", "Sai Manoj Pudukotai Dinakarrao"], "title": "Bit-Flip Fault Attack: Crushing Graph Neural Networks via Gradual Bit Search", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as a powerful machine learning\nmethod for graph-structured data. A plethora of hardware accelerators has been\nintroduced to meet the performance demands of GNNs in real-world applications.\nHowever, security challenges of hardware-based attacks have been generally\noverlooked. In this paper, we investigate the vulnerability of GNN models to\nhardware-based fault attack, wherein an attacker attempts to misclassify output\nby modifying trained weight parameters through fault injection in a memory\ndevice. Thus, we propose Gradual Bit-Flip Fault Attack (GBFA), a layer-aware\nbit-flip fault attack, selecting a vulnerable bit in each selected weight\ngradually to compromise the GNN's performance by flipping a minimal number of\nbits. To achieve this, GBFA operates in two steps. First, a Markov model is\ncreated to predict the execution sequence of layers based on features extracted\nfrom memory access patterns, enabling the launch of the attack within a\nspecific layer. Subsequently, GBFA identifies vulnerable bits within the\nselected weights using gradient ranking through an in-layer search. We evaluate\nthe effectiveness of the proposed GBFA attack on various GNN models for node\nclassification tasks using the Cora and PubMed datasets. Our findings show that\nGBFA significantly degrades prediction accuracy, and the variation in its\nimpact across different layers highlights the importance of adopting a\nlayer-aware attack strategy in GNNs. For example, GBFA degrades GraphSAGE's\nprediction accuracy by 17% on the Cora dataset with only a single bit flip in\nthe last layer.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u786c\u4ef6\u6545\u969c\u653b\u51fb\u65b9\u6cd5\uff08GBFA\uff09\uff0c\u901a\u8fc7\u9010\u5c42\u7ffb\u8f6c\u6743\u91cd\u7684\u5c11\u91cf\u6bd4\u7279\uff0c\u663e\u8457\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7814\u7a76GNNs\u5728\u786c\u4ef6\u5b89\u5168\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u5c24\u5176\u662f\u901a\u8fc7\u6545\u969c\u6ce8\u5165\u653b\u51fb\u4fee\u6539\u6743\u91cd\u53c2\u6570\u5bfc\u81f4\u8bef\u5206\u7c7b\u7684\u95ee\u9898\u3002", "method": "GBFA\u5206\u4e24\u6b65\u8fdb\u884c\uff1a1\uff09\u7528\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u9884\u6d4b\u5c42\u6267\u884c\u987a\u5e8f\uff1b2\uff09\u901a\u8fc7\u68af\u5ea6\u6392\u540d\u9009\u62e9\u8106\u5f31\u6bd4\u7279\u5e76\u7ffb\u8f6c\u3002", "result": "\u5728Cora\u548cPubMed\u6570\u636e\u96c6\u4e0a\uff0cGBFA\u663e\u8457\u964d\u4f4e\u4e86GNN\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u4f8b\u5982GraphSAGE\u5728\u6700\u540e\u4e00\u5c42\u4ec5\u7ffb\u8f6c\u4e00\u4e2a\u6bd4\u7279\u65f6\u51c6\u786e\u7387\u4e0b\u964d17%\u3002", "conclusion": "GBFA\u63ed\u793a\u4e86GNNs\u5bf9\u9010\u5c42\u653b\u51fb\u7b56\u7565\u7684\u8106\u5f31\u6027\uff0c\u5f3a\u8c03\u4e86\u786c\u4ef6\u5b89\u5168\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.05316", "pdf": "https://arxiv.org/pdf/2507.05316", "abs": "https://arxiv.org/abs/2507.05316", "authors": ["Koren Lazar", "Matan Vetzler", "Kiran Kate", "Jason Tsay", "David Boaz Himanshu Gupta", "Avraham Shinnar", "Rohith D Vallam", "David Amid Esther Goldbraich", "Guy Uziel", "Jim Laredo", "Ateret Anaby Tavor"], "title": "OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "AI agents and business automation tools interacting with external web\nservices require standardized, machine-readable information about their APIs in\nthe form of API specifications. However, the information about APIs available\nonline is often presented as unstructured, free-form HTML documentation,\nrequiring external users to spend significant time manually converting it into\na structured format. To address this, we introduce OASBuilder, a novel\nframework that transforms long and diverse API documentation pages into\nconsistent, machine-readable API specifications. This is achieved through a\ncarefully crafted pipeline that integrates large language models and rule-based\nalgorithms which are guided by domain knowledge of the structure of\ndocumentation webpages. Our experiments demonstrate that OASBuilder generalizes\nwell across hundreds of APIs, and produces valid OpenAPI specifications that\nencapsulate most of the information from the original documentation. OASBuilder\nhas been successfully implemented in an enterprise environment, saving\nthousands of hours of manual effort and making hundreds of complex enterprise\nAPIs accessible as tools for LLMs.", "AI": {"tldr": "OASBuilder\u662f\u4e00\u4e2a\u5c06API\u6587\u6863\u4ece\u975e\u7ed3\u6784\u5316HTML\u8f6c\u6362\u4e3a\u673a\u5668\u53ef\u8bfb\u7684OpenAPI\u89c4\u8303\u7684\u65b0\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3API\u6587\u6863\u975e\u7ed3\u6784\u5316\u95ee\u9898\uff0c\u51cf\u5c11\u624b\u52a8\u8f6c\u6362\u7684\u65f6\u95f4\u6210\u672c\u3002", "method": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6d41\u7a0b\u5904\u7406\u6587\u6863\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eOASBuilder\u80fd\u6709\u6548\u5904\u7406\u6570\u767e\u79cdAPI\uff0c\u751f\u6210\u5305\u542b\u5927\u90e8\u5206\u539f\u6587\u6863\u4fe1\u606f\u7684\u6709\u6548OpenAPI\u89c4\u8303\u3002", "conclusion": "OASBuilder\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u6210\u529f\u843d\u5730\uff0c\u8282\u7701\u4e86\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u65f6\u95f4\uff0c\u5e76\u4e3aLLM\u63d0\u4f9b\u4e86\u53ef\u7528\u7684API\u5de5\u5177\u3002"}}
{"id": "2507.05519", "pdf": "https://arxiv.org/pdf/2507.05519", "abs": "https://arxiv.org/abs/2507.05519", "authors": ["Gopal Gupta", "Abhiramon Rajasekharan", "Alexis R. Tudor", "Elmer Salazar", "Joaqu\u00edn Arias"], "title": "Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We consider the problem of implementing deontic modal logic. We show how\n(deontic) modal operators can be expressed elegantly using default negation\n(negation-as-failure) and strong negation present in answer set programming\n(ASP). We propose using global constraints of ASP to represent obligations and\nimpermissibilities of deontic modal logic. We show that our proposed\nrepresentation results in the various paradoxes of deontic modal logic being\nelegantly resolved.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u56de\u7b54\u96c6\u7f16\u7a0b\uff08ASP\uff09\u4e2d\u7684\u9ed8\u8ba4\u5426\u5b9a\u548c\u5f3a\u5426\u5b9a\u6765\u4f18\u96c5\u5b9e\u73b0\u9053\u4e49\u6a21\u6001\u903b\u8f91\u7684\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u9053\u4e49\u6a21\u6001\u903b\u8f91\u7684\u5b9e\u73b0\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u5176\u6096\u8bba\u3002", "method": "\u4f7f\u7528ASP\u7684\u5168\u5c40\u7ea6\u675f\u6765\u8868\u793a\u9053\u4e49\u6a21\u6001\u903b\u8f91\u7684\u4e49\u52a1\u548c\u7981\u6b62\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4f18\u96c5\u5730\u89e3\u51b3\u4e86\u9053\u4e49\u6a21\u6001\u903b\u8f91\u7684\u591a\u79cd\u6096\u8bba\u3002", "conclusion": "ASP\u4e2d\u7684\u5426\u5b9a\u673a\u5236\u4e3a\u9053\u4e49\u6a21\u6001\u903b\u8f91\u7684\u5b9e\u73b0\u548c\u6096\u8bba\u89e3\u51b3\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2507.06171", "pdf": "https://arxiv.org/pdf/2507.06171", "abs": "https://arxiv.org/abs/2507.06171", "authors": ["Whanhee Cho", "Anna Fariha"], "title": "Data-Semantics-Aware Recommendation of Diverse Pivot Tables", "categories": ["cs.DB"], "comment": null, "summary": "Data summarization is essential to discover insights from large datasets. In\na spreadsheets, pivot tables offer a convenient way to summarize tabular data\nby computing aggregates over some attributes, grouped by others. However,\nidentifying attribute combinations that will result in useful pivot tables\nremains a challenge, especially for high-dimensional datasets. We formalize the\nproblem of automatically recommending insightful and interpretable pivot\ntables, eliminating the tedious manual process. A crucial aspect of\nrecommending a set of pivot tables is to diversify them. Traditional works\ninadequately address the table-diversification problem, which leads us to\nconsider the problem of pivot table diversification.\n  We present SAGE, a data-semantics-aware system for recommending k-budgeted\ndiverse pivot tables, overcoming the shortcomings of prior work for top-k\nrecommendations that cause redundancy. SAGE ensures that each pivot table is\ninsightful, interpretable, and adaptive to the user's actions and preferences,\nwhile also guaranteeing that the set of pivot tables are different from each\nother, offering a diverse recommendation. We make two key technical\ncontributions: (1) a data-semantics-aware model to measure the utility of a\nsingle pivot table and the diversity of a set of pivot tables, and (2) a\nscalable greedy algorithm that can efficiently select a set of diverse pivot\ntables of high utility, by leveraging data semantics to significantly reduce\nthe combinatorial search space. Our extensive experiments on three real-world\ndatasets show that SAGE outperforms alternative approaches, and efficiently\nscales to accommodate high-dimensional datasets. Additionally, we present\nseveral case studies to highlight SAGE's qualitative effectiveness over\ncommercial software and Large Language Models (LLMs).", "AI": {"tldr": "SAGE\u662f\u4e00\u4e2a\u6570\u636e\u8bed\u4e49\u611f\u77e5\u7cfb\u7edf\uff0c\u7528\u4e8e\u63a8\u8350\u591a\u6837\u5316\u7684\u6570\u636e\u900f\u89c6\u8868\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u5728\u5927\u6570\u636e\u96c6\u4e2d\uff0c\u624b\u52a8\u8bc6\u522b\u6709\u7528\u7684\u6570\u636e\u900f\u89c6\u8868\u7ec4\u5408\u8d39\u65f6\u8d39\u529b\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "SAGE\u91c7\u7528\u6570\u636e\u8bed\u4e49\u611f\u77e5\u6a21\u578b\u8861\u91cf\u5355\u4e2a\u900f\u89c6\u8868\u6548\u7528\u548c\u96c6\u5408\u591a\u6837\u6027\uff0c\u5e76\u7ed3\u5408\u8d2a\u5fc3\u7b97\u6cd5\u9ad8\u6548\u7b5b\u9009\u9ad8\u5b9e\u7528\u6027\u4e14\u591a\u6837\u5316\u7684\u900f\u89c6\u8868\u7ec4\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSAGE\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5e76\u80fd\u9ad8\u6548\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u3002", "conclusion": "SAGE\u901a\u8fc7\u6570\u636e\u8bed\u4e49\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u900f\u89c6\u8868\u63a8\u8350\u7684\u591a\u6837\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u548cLLMs\u3002"}}
{"id": "2507.06107", "pdf": "https://arxiv.org/pdf/2507.06107", "abs": "https://arxiv.org/abs/2507.06107", "authors": ["Junaid Ahmed Khan", "Andrea Bartolini"], "title": "A Unified Ontology for Scalable Knowledge Graph-Driven Operational Data Analytics in High-Performance Computing Systems", "categories": ["cs.DC", "cs.DB"], "comment": "12 pages", "summary": "Modern high-performance computing (HPC) systems generate massive volumes of\nheterogeneous telemetry data from millions of sensors monitoring compute,\nmemory, power, cooling, and storage subsystems. As HPC infrastructures scale to\nsupport increasingly complex workloads-including generative AI-the need for\nefficient, reliable, and interoperable telemetry analysis becomes critical.\nOperational Data Analytics (ODA) has emerged to address these demands; however,\nthe reliance on schema-less storage solutions limits data accessibility and\nsemantic integration. Ontologies and knowledge graphs (KG) provide an effective\nway to enable efficient and expressive data querying by capturing domain\nsemantics, but they face challenges such as significant storage overhead and\nthe limited applicability of existing ontologies, which are often tailored to\nspecific HPC systems only. In this paper, we present the first unified ontology\nfor ODA in HPC systems, designed to enable semantic interoperability across\nheterogeneous data centers. Our ontology models telemetry data from the two\nlargest publicly available ODA datasets-M100 (Cineca, Italy) and F-DATA\n(Fugaku, Japan)-within a single data model. The ontology is validated through\n36 competency questions reflecting real-world stakeholder requirements, and we\nintroduce modeling optimizations that reduce knowledge graph (KG) storage\noverhead by up to 38.84% compared to a previous approach, with an additional\n26.82% reduction depending on the desired deployment configuration. This work\npaves the way for scalable ODA KGs and supports not only analysis within\nindividual systems, but also cross-system analysis across heterogeneous HPC\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u7edf\u4e00\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u7cfb\u7edf\u64cd\u4f5c\u6570\u636e\u5206 \u6790\uff08ODA\uff09\u672c\u4f53\uff0c\u652f\u6301\u5f02\u6784\u6570\u636e\u4e2d\u5fc3\u95f4\u7684\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0c\u5e76\u4f18\u5316\u5efa\u6a21\u4ee5\u663e\u8457\u51cf\u5c11\u77e5\u8bc6\u56fe\u8c31\u5b58\u50a8\u5f00\u9500\u3002", "motivation": "\u968f\u7740HPC\u7cfb\u7edf\u6269\u5c55\u5230\u652f\u6301\u751f\u6210\u5f0fAI\u7b49\u590d\u6742\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5bf9\u9ad8\u6548\u3001\u53ef\u9760\u4e14\u53ef\u4e92\u64cd\u4f5c\u7684\u9065\u6d4b\u6570\u636e\u5206\u6790\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\u3002\u73b0\u6709\u65b9\u6cd5\u56e0\u4f9d\u8d56\u65e0\u6a21\u5f0f\u5b58\u50a8\u65b9\u6848\u800c\u9650\u5236\u4e86\u6570\u636e\u53ef\u8bbf\u95ee\u6027\u548c\u8bed\u4e49\u96c6\u6210\u3002", "method": "\u8bbe\u8ba1\u7edf\u4e00\u7684\u672c\u4f53\uff0c\u7ed3\u5408M100\u548cF-DATA\u4e24\u5927\u516c\u5f00ODA\u6570\u636e\u96c6\uff0c\u901a\u8fc736\u4e2a\u80fd\u529b\u95ee\u9898\u9a8c\u8bc1\uff0c\u5e76\u5f15\u5165\u5efa\u6a21\u4f18\u5316\u4ee5\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\u3002", "result": "\u4e0e\u4e4b\u524d\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b58\u50a8\u5f00\u9500\u51cf\u5c1138.84%\uff0c\u6839\u636e\u90e8\u7f72\u914d\u7f6e\u8fd8\u53ef\u989d\u5916\u51cf\u5c1126.82%\u3002\u652f\u6301\u8de8\u5f02\u6784HPC\u7cfb\u7edf\u7684\u5206\u6790\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684ODA\u77e5\u8bc6\u56fe\u8c31\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u652f\u6301\u5f02\u6784HPC\u7cfb\u7edf\u7684\u8de8\u7cfb\u7edf\u5206\u6790\u3002"}}
{"id": "2507.05576", "pdf": "https://arxiv.org/pdf/2507.05576", "abs": "https://arxiv.org/abs/2507.05576", "authors": ["Mehdi Elahi", "Mohamed R. Elshamy", "Abdel-Hameed Badawy", "Ahmad Patooghy"], "title": "iThermTroj: Exploiting Intermittent Thermal Trojans in Multi-Processor System-on-Chips", "categories": ["cs.CR", "cs.AR"], "comment": null, "summary": "Thermal Trojan attacks present a pressing concern for the security and\nreliability of System-on-Chips (SoCs), especially in mobile applications. The\nsituation becomes more complicated when such attacks are more evasive and\noperate sporadically to stay hidden from detection mechanisms. In this paper,\nwe introduce Intermittent Thermal Trojans (iThermTroj) that exploit the chips'\nthermal information in a random time-triggered manner. According to our\nexperiments, iThermTroj attack can easily bypass available threshold-based\nthermal Trojan detection solutions. We investigate SoC vulnerabilities to\nvariations of iThermTroj through an in-depth analysis of Trojan activation and\nduration scenarios. We also propose a set of tiny Machine Learning classifiers\nfor run-time anomaly detection to protect SoCs against such intermittent\nthermal Trojan attacks. Compared to existing methods, our approach improves the\nattack detection rate by 29.4\\%, 17.2\\%, and 14.3\\% in scenarios where\niThermTroj manipulates up to 80\\%, 60\\%, and 40\\% of SoC's thermal data,\nrespectively. Additionally, our method increases the full protection resolution\nto 0.8 degrees Celsius, meaning that any temperature manipulations exceeding\n$\\pm 0.8$ degrees will be detected with 100\\% accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aiThermTroj\u7684\u95f4\u6b47\u6027\u70ed\u6728\u9a6c\u653b\u51fb\uff0c\u5e76\u5f00\u53d1\u4e86\u5fae\u578b\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7387\u548c\u4fdd\u62a4\u5206\u8fa8\u7387\u3002", "motivation": "\u70ed\u6728\u9a6c\u653b\u51fb\u5bf9SoC\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u68c0\u6d4b\u673a\u5236\u6613\u88ab\u89c4\u907f\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6728\u9a6c\u6fc0\u6d3b\u548c\u6301\u7eed\u65f6\u95f4\u573a\u666f\uff0c\u63d0\u51fa\u5fae\u578b\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u8fdb\u884c\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u4e0d\u540c\u653b\u51fb\u5f3a\u5ea6\u4e0b\u663e\u8457\u63d0\u9ad8\u68c0\u6d4b\u7387\uff0c\u5e76\u5c06\u4fdd\u62a4\u5206\u8fa8\u7387\u63d0\u5347\u81f30.8\u6444\u6c0f\u5ea6\u3002", "conclusion": "\u5fae\u578b\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u80fd\u6709\u6548\u9632\u5fa1\u95f4\u6b47\u6027\u70ed\u6728\u9a6c\u653b\u51fb\uff0c\u663e\u8457\u63d0\u5347SoC\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2507.05325", "pdf": "https://arxiv.org/pdf/2507.05325", "abs": "https://arxiv.org/abs/2507.05325", "authors": ["Lidiany Cerqueira", "Jo\u00e3o Pedro Bastos", "Danilo Neves", "Glauco Carneiro", "Rodrigo Sp\u00ednola", "S\u00e1vio Freire", "Jos\u00e9 Amancio Macedo Santos", "Manoel Mendon\u00e7a"], "title": "Exploring Empathy in Software Engineering: Insights from a Grey Literature Analysis of Practitioners' Perspectives", "categories": ["cs.SE"], "comment": "This is the author's version of the paper accepted for publication in\n  ACM Transactions on Software Engineering and Methodology. The final version\n  will be available via the ACM Digital Library. The HTML preview may not\n  render some formatting correctly. Please refer to the PDF version for\n  accurate presentation", "summary": "Context. Empathy, a key social skill, is essential for communication and\ncollaboration in SE but remains an under-researched topic. Aims. This study\ninvestigates empathy in SE from practitioners' perspectives, aiming to\ncharacterize its meaning, identify barriers, discuss practices to overcome\nthem, and explore its effects. Method. A qualitative content analysis was\nconducted on 55 web articles from DEV and Medium, two communities widely used\nby practitioners. To strengthen our findings, we conducted a follow-up survey\nwith empathy experts. Results. The study proposes a definition of empathy in\nSE, identifies barriers such as toxic culture and excessive technical focus,\npractices to foster empathy in teams, and outcomes, including improved\ncollaboration, communication, and reduced anxiety, frustration, and stress.\nThese findings are synthesized into a conceptual framework. Conclusion. Survey\nresults indicate the framework is clear, valuable, and raises empathy\nawareness, with suggestions for improvements and integration into training.\nThis study paves the way for improving team dynamics by addressing barriers and\noffering strategies to cultivate empathy. Future work will explore empathy's\nbroader implications in SE practice.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u540c\u7406\u5fc3\u7684\u610f\u4e49\u3001\u963b\u788d\u53ca\u63d0\u5347\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u6982\u5ff5\u6846\u67b6\u5e76\u9a8c\u8bc1\u5176\u4ef7\u503c\u3002", "motivation": "\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u81f3\u5173\u91cd\u8981\u4f46\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u4ece\u5b9e\u8df5\u8005\u89d2\u5ea6\u6df1\u5165\u63a2\u8ba8\u3002", "method": "\u901a\u8fc7\u5185\u5bb9\u5206\u679055\u7bc7\u7f51\u7edc\u6587\u7ae0\u53ca\u4e13\u5bb6\u8c03\u67e5\uff0c\u63d0\u51fa\u540c\u7406\u5fc3\u5b9a\u4e49\u3001\u963b\u788d\u53ca\u63d0\u5347\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u540c\u7406\u5fc3\u6982\u5ff5\u6846\u67b6\uff0c\u9a8c\u8bc1\u5176\u6e05\u6670\u6027\u548c\u4ef7\u503c\uff0c\u4e3a\u56e2\u961f\u52a8\u6001\u6539\u8fdb\u63d0\u4f9b\u4f9d\u636e\u3002", "conclusion": "\u7814\u7a76\u4e3a\u57f9\u517b\u540c\u7406\u5fc3\u63d0\u4f9b\u7b56\u7565\uff0c\u672a\u6765\u5c06\u63a2\u7d22\u5176\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2507.05600", "pdf": "https://arxiv.org/pdf/2507.05600", "abs": "https://arxiv.org/abs/2507.05600", "authors": ["Tom Moher", "Louis Gomez", "Janet Kim", "Claudia Hindo", "Benjamin Watson", "Stephen Fransen", "Tim McEneany"], "title": "StoryGrid: A Tangible Interface for Student Expression", "categories": ["cs.HC"], "comment": null, "summary": "StorySpace is a classroom-based design and presentation system for\ninteractive multimedia posters. Employing the technology base first used in\nEden's PITAboard [2002], StorySpace allows groups of learners to manipulate\nprojected multimedia objects on a horizontal board using a small collection of\nshared physical tokens. In this paper, we present the ongoing design history of\nStorySpace in the context of its introduction within an urban high school\nliterature class. Interface modifications based on student and teacher feedback\nled on changes in token semantics and media importing methods. We describe how\nStorySpace features enriched students' interpretations of literature, with\nparticular emphasis in two areas: (1) attention to audience, and (2) reflection\nof multiple perspectives.", "AI": {"tldr": "StorySpace\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bfe\u5802\u7684\u8bbe\u8ba1\u548c\u5c55\u793a\u7cfb\u7edf\uff0c\u7528\u4e8e\u4e92\u52a8\u591a\u5a92\u4f53\u6d77\u62a5\u3002\u5b83\u901a\u8fc7\u7269\u7406\u4ee4\u724c\u64cd\u4f5c\u591a\u5a92\u4f53\u5bf9\u8c61\uff0c\u5e76\u5728\u9ad8\u4e2d\u6587\u5b66\u8bfe\u7a0b\u4e2d\u5e94\u7528\uff0c\u6839\u636e\u5e08\u751f\u53cd\u9988\u6539\u8fdb\u754c\u9762\uff0c\u4e30\u5bcc\u4e86\u5b66\u751f\u5bf9\u6587\u5b66\u7684\u89e3\u8bfb\u3002", "motivation": "\u8bbe\u8ba1\u548c\u6539\u8fdbStorySpace\u7cfb\u7edf\uff0c\u7528\u4e8e\u6559\u5b66\u73af\u5883\u4e2d\u4e92\u52a8\u591a\u5a92\u4f53\u6d77\u62a5\u7684\u5236\u4f5c\u548c\u5c55\u793a\uff0c\u4ee5\u63d0\u5347\u5b66\u751f\u5bf9\u6587\u5b66\u7684\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4ee4\u724c\u64cd\u4f5c\u6295\u5f71\u7684\u591a\u5a92\u4f53\u5bf9\u8c61\uff0c\u7ed3\u5408\u5e08\u751f\u53cd\u9988\u4e0d\u65ad\u6539\u8fdb\u754c\u9762\u8bbe\u8ba1\uff0c\u5982\u4ee4\u724c\u8bed\u4e49\u548c\u5a92\u4f53\u5bfc\u5165\u65b9\u6cd5\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u5e94\u7528\u4e8e\u9ad8\u4e2d\u6587\u5b66\u8bfe\u5802\uff0c\u5b66\u751f\u5728\u6587\u5b66\u89e3\u8bfb\u4e2d\u66f4\u6ce8\u91cd\u53d7\u4f17\u548c\u591a\u5143\u89c6\u89d2\u3002", "conclusion": "StorySpace\u901a\u8fc7\u4e92\u52a8\u8bbe\u8ba1\u6709\u6548\u63d0\u5347\u4e86\u5b66\u751f\u5bf9\u6587\u5b66\u7684\u53c2\u4e0e\u548c\u7406\u89e3\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.05794", "pdf": "https://arxiv.org/pdf/2507.05794", "abs": "https://arxiv.org/abs/2507.05794", "authors": ["Avi Shaked", "Nan Messe"], "title": "Automated Reasoning for Vulnerability Management by Design", "categories": ["cs.CR", "cs.AI", "cs.LO", "cs.SY", "eess.SY"], "comment": null, "summary": "For securing systems, it is essential to manage their vulnerability posture\nand design appropriate security controls. Vulnerability management allows to\nproactively address vulnerabilities by incorporating pertinent security\ncontrols into systems designs. Current vulnerability management approaches do\nnot support systematic reasoning about the vulnerability postures of systems\ndesigns. To effectively manage vulnerabilities and design security controls, we\npropose a formally grounded automated reasoning mechanism. We integrate the\nmechanism into an open-source security design tool and demonstrate its\napplication through an illustrative example driven by real-world challenges.\nThe automated reasoning mechanism allows system designers to identify\nvulnerabilities that are applicable to a specific system design, explicitly\nspecify vulnerability mitigation options, declare selected controls, and thus\nsystematically manage vulnerability postures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f62\u5f0f\u5316\u57fa\u7840\u7684\u81ea\u52a8\u5316\u63a8\u7406\u673a\u5236\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u6f0f\u6d1e\u7ba1\u7406\u548c\u5b89\u5168\u63a7\u5236\u8bbe\u8ba1\u3002", "motivation": "\u5f53\u524d\u6f0f\u6d1e\u7ba1\u7406\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u8bbe\u8ba1\u6f0f\u6d1e\u72b6\u6001\u7684\u7cfb\u7edf\u5316\u63a8\u7406\uff0c\u9650\u5236\u4e86\u6f0f\u6d1e\u7684\u6709\u6548\u7ba1\u7406\u3002", "method": "\u96c6\u6210\u4e00\u79cd\u81ea\u52a8\u5316\u63a8\u7406\u673a\u5236\u5230\u5f00\u6e90\u5b89\u5168\u8bbe\u8ba1\u5de5\u5177\u4e2d\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u5176\u5e94\u7528\u3002", "result": "\u8be5\u673a\u5236\u5e2e\u52a9\u8bbe\u8ba1\u5e08\u8bc6\u522b\u7279\u5b9a\u8bbe\u8ba1\u7684\u9002\u7528\u6f0f\u6d1e\uff0c\u660e\u786e\u6f0f\u6d1e\u7f13\u89e3\u9009\u9879\uff0c\u5e76\u7cfb\u7edf\u5316\u7ba1\u7406\u6f0f\u6d1e\u72b6\u6001\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u81ea\u52a8\u5316\u63a8\u7406\u673a\u5236\uff0c\u53ef\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6f0f\u6d1e\u7ba1\u7406\u7684\u6548\u7387\u548c\u7cbe\u51c6\u5ea6\u3002"}}
{"id": "2507.06192", "pdf": "https://arxiv.org/pdf/2507.06192", "abs": "https://arxiv.org/abs/2507.06192", "authors": ["Jiale Lao", "Immanuel Trummer"], "title": "SQLBarber: A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Database research and development often require a large number of SQL queries\nfor benchmarking purposes. However, acquiring real-world SQL queries is\nchallenging due to privacy concerns, and existing SQL generation methods are\nlimited in customization and in satisfying realistic constraints. To address\nthis issue, we present SQLBarber, a system based on Large Language Models\n(LLMs) to generate customized and realistic SQL workloads. SQLBarber (i)\neliminates the need for users to manually craft SQL templates in advance, while\nproviding the flexibility to accept natural language specifications to\nconstrain SQL templates, (ii) scales efficiently to generate large volumes of\nqueries matching any user-defined cost distribution (e.g., cardinality and\nexecution plan cost), and (iii) uses execution statistics from Amazon Redshift\nand Snowflake to derive SQL template specifications and query cost\ndistributions that reflect real-world query characteristics. SQLBarber\nintroduces (i) a declarative interface for users to effortlessly generate\ncustomized SQL templates, (ii) an LLM-powered pipeline augmented with a\nself-correction module that profiles, refines, and prunes SQL templates based\non query costs, and (iii) a Bayesian Optimizer to efficiently explore different\npredicate values and identify a set of queries that satisfy the target cost\ndistribution. We construct and open-source ten benchmarks of varying difficulty\nlevels and target query cost distributions based on real-world statistics from\nSnowflake and Amazon Redshift. Extensive experiments on these benchmarks show\nthat SQLBarber is the only system that can generate customized SQL templates.\nIt reduces query generation time by one to three orders of magnitude, and\nsignificantly improves alignment with the target cost distribution, compared\nwith existing methods.", "AI": {"tldr": "SQLBarber\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u5b9a\u5236\u5316\u4e14\u73b0\u5b9e\u7684SQL\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u89e3\u51b3\u4e86\u73b0\u6709SQL\u751f\u6210\u65b9\u6cd5\u7684\u5c40\u9650\u3002", "motivation": "\u7814\u7a76\u81f4\u529b\u4e8e\u89e3\u51b3\u6570\u636e\u5e93\u5f00\u53d1\u548c\u6d4b\u8bd5\u4e2d\u83b7\u53d6\u771f\u5b9eSQL\u67e5\u8be2\u7684\u56f0\u96be\uff0c\u540c\u65f6\u6ee1\u8db3\u5b9a\u5236\u5316\u548c\u73b0\u5b9e\u7ea6\u675f\u7684\u9700\u6c42\u3002", "method": "SQLBarber\u5229\u7528\u81ea\u7136\u8bed\u8a00\u7ea6\u675f\u751f\u6210SQL\u6a21\u677f\uff0c\u5e76\u901a\u8fc7\u81ea\u6821\u6b63\u6a21\u5757\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u5668\u9ad8\u6548\u751f\u6210\u7b26\u5408\u76ee\u6807\u6210\u672c\u5206\u5e03\u7684\u67e5\u8be2\u3002", "result": "\u7cfb\u7edf\u663e\u8457\u51cf\u5c11\u4e86\u67e5\u8be2\u751f\u6210\u65f6\u95f4\u5e76\u63d0\u9ad8\u4e86\u4e0e\u76ee\u6807\u6210\u672c\u5206\u5e03\u7684\u5bf9\u9f50\u5ea6\u3002", "conclusion": "SQLBarber\u662f\u552f\u4e00\u80fd\u751f\u6210\u5b9a\u5236\u5316SQL\u6a21\u677f\u7684\u7cfb\u7edf\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.05809", "pdf": "https://arxiv.org/pdf/2507.05809", "abs": "https://arxiv.org/abs/2507.05809", "authors": ["Craig Wright"], "title": "A Formal Refutation of the Blockchain Trilemma", "categories": ["cs.CC", "cs.CR", "cs.DC", "cs.DS", "03B70, 68M10, 91A80", "F.4.1; D.4.6; C.2.2"], "comment": "12 pages", "summary": "The so-called blockchain trilemma asserts the impossibility of simultaneously\nachieving scalability, security, and decentralisation within a single\nblockchain protocol. In this paper, we formally refute that proposition.\nEmploying predicate logic, formal automata theory, computational complexity\nanalysis, and graph-theoretic measures of relay topology--specifically Baran's\nmodel of network path redundancy--we demonstrate that the trilemma constitutes\na category error, conflates distinct analytical domains, and relies upon\nunproven causal assumptions. We further expose its reliance on composition\nfallacies drawn from flawed system implementations. A constructive\ncounterexample is presented: a blockchain protocol exhibiting unbounded\ntransaction throughput, cryptographic security under adversarial load, and\nmultipath decentralised propagation. This example is not hypothetical but\ngrounded in protocol design enabled by compact block relay, SPV verification,\nand IPv6 multicast. The trilemma is revealed not as a law of protocol\narchitecture, but as a heuristic fallacy sustained by imprecision and design\ndefeatism.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5f62\u5f0f\u903b\u8f91\u548c\u8ba1\u7b97\u590d\u6742\u6027\u5206\u6790\uff0c\u9a73\u65a5\u4e86\u533a\u5757\u94fe\u4e09\u96be\u95ee\u9898\u7684\u89c2\u70b9\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u65e0\u9650\u4ea4\u6613\u541e\u5410\u91cf\u7684\u533a\u5757\u94fe\u534f\u8bae\u3002", "motivation": "\u4f20\u7edf\u7684\u533a\u5757\u94fe\u4e09\u96be\u95ee\u9898\u8ba4\u4e3a\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3001\u5b89\u5168\u6027\u548c\u53bb\u4e2d\u5fc3\u5316\uff0c\u672c\u6587\u65e8\u5728\u8bc1\u660e\u8fd9\u4e00\u89c2\u70b9\u662f\u9519\u8bef\u7684\u3002", "method": "\u4f7f\u7528\u8c13\u8bcd\u903b\u8f91\u3001\u5f62\u5f0f\u81ea\u52a8\u673a\u7406\u8bba\u3001\u8ba1\u7b97\u590d\u6742\u6027\u5206\u6790\u548c\u56fe\u8bba\u7684\u8def\u5f84\u5197\u4f59\u6a21\u578b\uff08Baran\u6a21\u578b\uff09\uff0c\u5206\u6790\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5b9e\u9645\u7684\u533a\u5757\u94fe\u534f\u8bae\u3002", "result": "\u5c55\u793a\u4e86\u4e00\u79cd\u65e2\u5177\u6709\u65e0\u9650\u4ea4\u6613\u541e\u5410\u91cf\u3001\u5bc6\u7801\u5b66\u5b89\u5168\uff0c\u53c8\u80fd\u5b9e\u73b0\u591a\u8def\u5f84\u53bb\u4e2d\u5fc3\u5316\u4f20\u64ad\u7684\u533a\u5757\u94fe\u534f\u8bae\uff0c\u8bc1\u660e\u4e86\u4e09\u96be\u95ee\u9898\u662f\u9519\u8bef\u7684\u3002", "conclusion": "\u533a\u5757\u94fe\u4e09\u96be\u95ee\u9898\u5e76\u975e\u534f\u8bae\u67b6\u6784\u7684\u5b9a\u5f8b\uff0c\u800c\u662f\u56e0\u8bbe\u8ba1\u4e0d\u7cbe\u786e\u548c\u7f3a\u9677\u9020\u6210\u7684\u8bef\u5bfc\u6027\u89c2\u70b9\u3002"}}
{"id": "2507.05504", "pdf": "https://arxiv.org/pdf/2507.05504", "abs": "https://arxiv.org/abs/2507.05504", "authors": ["Alex Kleijwegt", "Sinem Getir Yaman", "Radu Calinescu"], "title": "Tool for Supporting Debugging and Understanding of Normative Requirements Using LLMs", "categories": ["cs.SE"], "comment": null, "summary": "Normative requirements specify social, legal, ethical, empathetic, and\ncultural (SLEEC) norms that must be observed by a system. To support the\nidentification of SLEEC requirements, numerous standards and regulations have\nbeen developed. These requirements are typically defined by stakeholders in the\nnon-technical system with diverse expertise (e.g., ethicists, lawyers, social\nscientists). Hence, ensuring their consistency and managing the requirement\nelicitation process are complex and error-prone tasks. Recent research has\naddressed this challenge using domain-specific languages to specify normative\nrequirements as rules, whose consistency can then be analyzed with formal\nmethods. Nevertheless, these approaches often present the results from formal\nverification tools in a way that is inaccessible to non-technical users. This\nhinders understanding and makes the iterative process of eliciting and\nvalidating these requirements inefficient in terms of both time and effort. To\naddress this problem, we introduce SLEEC-LLM, a tool that uses large language\nmodels (LLMs) to provide natural-language interpretations for model-checking\ncounterexamples corresponding to SLEEC rule inconsistencies. SLEEC-LLM improves\nthe efficiency and explainability of normative requirements elicitation and\nconsistency analysis. To demonstrate its effectiveness, we summarise its use in\ntwo real-world case studies involving non-technical stakeholders.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5de5\u5177SLEEC-LLM\uff0c\u7528\u4e8e\u5c06SLEEC\u89c4\u5219\u4e0d\u4e00\u81f4\u6027\u5206\u6790\u7684\u6a21\u578b\u68c0\u67e5\u7ed3\u679c\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u4ee5\u63d0\u9ad8\u975e\u6280\u672f\u7528\u6237\u7684\u7406\u89e3\u548c\u9700\u6c42\u5206\u6790\u6548\u7387\u3002", "motivation": "\u89c4\u8303\u9700\u6c42\uff08SLEEC\uff09\u7684\u590d\u6742\u6027\u53ca\u5176\u4e00\u81f4\u6027\u7ba1\u7406\u5bf9\u4e8e\u975e\u6280\u672f\u7528\u6237\u6765\u8bf4\u96be\u4ee5\u7406\u89e3\uff0c\u5bfc\u81f4\u9700\u6c42\u9a8c\u8bc1\u8fc7\u7a0b\u4f4e\u6548\u3002", "method": "\u5f00\u53d1\u4e86SLEEC-LLM\u5de5\u5177\uff0c\u5229\u7528LLM\u5c06\u6a21\u578b\u68c0\u67e5\u7684\u53cd\u4f8b\u7ed3\u679c\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "SLEEC-LLM\u63d0\u9ad8\u4e86\u89c4\u8303\u9700\u6c42\u7684\u83b7\u53d6\u548c\u4e00\u81f4\u6027\u5206\u6790\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5177\u4f53\u4f53\u73b0\u5728\u4e24\u4e2a\u5b9e\u9645\u6848\u4f8b\u4e2d\u3002", "conclusion": "SLEEC-LLM\u6709\u6548\u89e3\u51b3\u4e86\u975e\u6280\u672f\u7528\u6237\u7406\u89e3\u6a21\u578b\u68c0\u67e5\u7ed3\u679c\u7684\u96be\u9898\uff0c\u63d0\u5347\u4e86\u89c4\u8303\u9700\u6c42\u5206\u6790\u7684\u6548\u7387\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2507.05605", "pdf": "https://arxiv.org/pdf/2507.05605", "abs": "https://arxiv.org/abs/2507.05605", "authors": ["Oleg Aleksandrovich Golev", "Michelle Huang", "Chanketya Nop", "Kritin Vongthongsri", "Andr\u00e9s Monroy-Hern\u00e1ndez", "Parastoo Abtahi"], "title": "Hapster: Using Apple Watch Haptics to Enable Live Low-Friction Student Feedback in the Physical Classroom", "categories": ["cs.HC"], "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems, pp. 1-7. 2024", "summary": "The benefits of student response systems (SRSs) for in-person lectures are\nwell-researched. However, all current SRSs only rely on a visual interface to\nrelay information to the instructor. We describe the design and evaluation of\nHapster, a prototype system that uses an Apple Watch to deliver live,\naggregated student feedback to the instructor via both visual and vibro-tactile\nmodalities. We evaluated this system with 6 instructors and 155 students at a\nU.S. university. Participants reported that the system was effective at\ndelivering live student feedback and facilitating better engagement from both\nthe instructor and the students. However, instructors also noted several\nchallenges with differentiating and perceiving the haptic sequences while\nlecturing. We conclude by discussing the tradeoff between system flexibility\nand abuse potential while identifying opportunities for further research\nregarding accessibility, content moderation, and additional interaction\nmodalities. Our results suggest that haptics can be used as an effective live\nfeedback mechanism for instructors in the physical classroom.", "AI": {"tldr": "Hapster\u662f\u4e00\u79cd\u901a\u8fc7\u89c6\u89c9\u548c\u89e6\u89c9\u6a21\u6001\u4f20\u9012\u5b66\u751f\u53cd\u9988\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u7814\u7a76\u8868\u660e\u5176\u80fd\u63d0\u5347\u8bfe\u5802\u53c2\u4e0e\u5ea6\uff0c\u4f46\u4e5f\u5b58\u5728\u89e6\u89c9\u611f\u77e5\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u63a2\u7d22\u5b66\u751f\u53cd\u9988\u7cfb\u7edf\uff08SRSs\uff09\u4e2d\u89e6\u89c9\u6a21\u6001\u7684\u6f5c\u529b\uff0c\u4ee5\u589e\u5f3a\u8bfe\u5802\u6559\u5b66\u6548\u679c\u3002", "method": "\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e86Hapster\uff0c\u4e00\u79cd\u57fa\u4e8eApple Watch\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9\u548c\u89e6\u89c9\u6a21\u6001\u4f20\u9012\u5b66\u751f\u53cd\u9988\uff0c6\u540d\u6559\u5e08\u548c155\u540d\u5b66\u751f\u53c2\u4e0e\u3002", "result": "\u7cfb\u7edf\u6709\u6548\u4fc3\u8fdb\u4e86\u8bfe\u5802\u53c2\u4e0e\uff0c\u4f46\u6559\u5e08\u5bf9\u89e6\u89c9\u5e8f\u5217\u7684\u611f\u77e5\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u89e6\u89c9\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u5b9e\u65f6\u53cd\u9988\u673a\u5236\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u7075\u6d3b\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u4ea4\u4e92\u6a21\u6001\u3002"}}
{"id": "2507.05865", "pdf": "https://arxiv.org/pdf/2507.05865", "abs": "https://arxiv.org/abs/2507.05865", "authors": ["Ter\u00e9zia Slanin\u00e1kov\u00e1", "Jaroslav Olha", "David Proch\u00e1zka", "Matej Antol", "Vlastislav Dohnal"], "title": "On the Costs and Benefits of Learned Indexing for Dynamic High-Dimensional Data: Extended Version", "categories": ["cs.IR", "cs.DB"], "comment": null, "summary": "One of the main challenges within the growing research area of learned\nindexing is the lack of adaptability to dynamically expanding datasets. This\npaper explores the dynamization of a static learned index for complex data\nthrough operations such as node splitting and broadening, enabling efficient\nadaptation to new data. Furthermore, we evaluate the trade-offs between static\nand dynamic approaches by introducing an amortized cost model to assess query\nperformance in tandem with the build costs of the index structure, enabling\nexperimental determination of when a dynamic learned index outperforms its\nstatic counterpart. We apply the dynamization method to a static learned index\nand demonstrate that its superior scaling quickly surpasses the static\nimplementation in terms of overall costs as the database grows. This is an\nextended version of the paper presented at DAWAK 2025.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u52a8\u6001\u5316\u9759\u6001\u5b66\u4e60\u7d22\u5f15\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8282\u70b9\u5206\u5272\u548c\u6269\u5c55\u5b9e\u73b0\u9ad8\u6548\u9002\u5e94\u52a8\u6001\u6269\u5c55\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u52a8\u6001\u7d22\u5f15\u5728\u6570\u636e\u5e93\u589e\u957f\u65f6\u4f18\u4e8e\u9759\u6001\u7d22\u5f15\u3002", "motivation": "\u5b66\u4e60\u7d22\u5f15\u7814\u7a76\u9886\u57df\u7684\u4e3b\u8981\u6311\u6218\u4e4b\u4e00\u662f\u7f3a\u4e4f\u5bf9\u52a8\u6001\u6269\u5c55\u6570\u636e\u96c6\u7684\u9002\u5e94\u6027\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u5982\u4f55\u52a8\u6001\u5316\u9759\u6001\u5b66\u4e60\u7d22\u5f15\u4ee5\u9002\u5e94\u65b0\u6570\u636e\u3002", "method": "\u91c7\u7528\u8282\u70b9\u5206\u5272\u548c\u6269\u5c55\u7b49\u64cd\u4f5c\u52a8\u6001\u5316\u9759\u6001\u5b66\u4e60\u7d22\u5f15\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u644a\u9500\u6210\u672c\u6a21\u578b\u8bc4\u4f30\u67e5\u8be2\u6027\u80fd\u4e0e\u7d22\u5f15\u6784\u5efa\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a8\u6001\u5b66\u4e60\u7d22\u5f15\u5728\u6570\u636e\u5e93\u589e\u957f\u65f6\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6269\u5c55\u6027\uff0c\u603b\u4f53\u6210\u672c\u8fc5\u901f\u4f18\u4e8e\u9759\u6001\u5b9e\u73b0\u3002", "conclusion": "\u52a8\u6001\u5316\u5b66\u4e60\u7d22\u5f15\u65b9\u6cd5\u5728\u52a8\u6001\u6269\u5c55\u6570\u636e\u96c6\u573a\u666f\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9700\u8981\u9891\u7e41\u66f4\u65b0\u7684\u6570\u636e\u5e93\u3002"}}
{"id": "2507.05565", "pdf": "https://arxiv.org/pdf/2507.05565", "abs": "https://arxiv.org/abs/2507.05565", "authors": ["Sangwon Hyun", "Shaukat Ali", "M. Ali Babar"], "title": "Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models", "categories": ["cs.SE", "cs.AI", "cs.NE"], "comment": null, "summary": "Assessing the trustworthiness of Large Language Models (LLMs), such as\nrobustness, has garnered significant attention. Recently, metamorphic testing\nthat defines Metamorphic Relations (MRs) has been widely applied to evaluate\nthe robustness of LLM executions. However, the MR-based robustness testing\nstill requires a scalable number of MRs, thereby necessitating the optimization\nof selecting MRs. Most extant LLM testing studies are limited to automatically\ngenerating test cases (i.e., MRs) to enhance failure detection. Additionally,\nmost studies only considered a limited test space of single perturbation MRs in\ntheir evaluation of LLMs. In contrast, our paper proposes a search-based\napproach for optimizing the MR groups to maximize failure detection and\nminimize the LLM execution cost. Moreover, our approach covers the\ncombinatorial perturbations in MRs, facilitating the expansion of test space in\nthe robustness assessment. We have developed a search process and implemented\nfour search algorithms: Single-GA, NSGA-II, SPEA2, and MOEA/D with novel\nencoding to solve the MR selection problem in the LLM robustness testing. We\nconducted comparative experiments on the four search algorithms along with a\nrandom search, using two major LLMs with primary Text-to-Text tasks. Our\nstatistical and empirical investigation revealed two key findings: (1) the\nMOEA/D algorithm performed the best in optimizing the MR space for LLM\nrobustness testing, and (2) we identified silver bullet MRs for the LLM\nrobustness testing, which demonstrated dominant capabilities in confusing LLMs\nacross different Text-to-Text tasks. In LLM robustness assessment, our research\nsheds light on the fundamental problem for optimized testing and provides\ninsights into search-based solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\u4f18\u5316MR\u7ec4\uff0c\u4ee5\u6700\u5927\u5316\u6545\u969c\u68c0\u6d4b\u5e76\u6700\u5c0f\u5316LLM\u6267\u884c\u6210\u672c\uff0c\u5e76\u8986\u76d6\u4e86\u7ec4\u5408\u6270\u52a8\u3002MOEA/D\u7b97\u6cd5\u5728\u4f18\u5316MR\u7a7a\u95f4\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u53d1\u73b0\u4e86\u5bf9LLM\u7a33\u5065\u6027\u6d4b\u8bd5\u5177\u6709\u4f18\u52bf\u7684MR\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7a33\u5065\u6027\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u7684MR\u6d4b\u8bd5\u9700\u8981\u4f18\u5316\u9009\u62e9\u548c\u6269\u5c55\u6d4b\u8bd5\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u641c\u7d22\u65b9\u6cd5\u4f18\u5316MR\u7ec4\uff0c\u5b9e\u65bd\u4e86\u56db\u79cd\u641c\u7d22\u7b97\u6cd5\uff08Single-GA\u3001NSGA-II\u3001SPEA2\u548cMOEA/D\uff09\uff0c\u5e76\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "MOEA/D\u7b97\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e9b\u5bf9LLM\u7a33\u5065\u6027\u6d4b\u8bd5\u7279\u522b\u6709\u6548\u7684MR\u3002", "conclusion": "\u7814\u7a76\u4e3aLLM\u7a33\u5065\u6027\u6d4b\u8bd5\u7684\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u641c\u7d22\u65b9\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.05616", "pdf": "https://arxiv.org/pdf/2507.05616", "abs": "https://arxiv.org/abs/2507.05616", "authors": ["Liam Franco Esparraguera", "Kristoffer Selberg", "Brian Lou", "Jenny Sun", "Beza Desta", "Andr\u00e9s Monroy-Hern\u00e1ndez", "Parastoo Abtahi"], "title": "Breaking the Plane: Exploring Real-Time Visualization of 3D Surfaces in Augmented Reality with Handwritten Input", "categories": ["cs.HC"], "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems, pp. 1-9. 2024", "summary": "We introduce Breaking the Plane, an augmented reality (AR) application built\nfor AR headsets that enables users to visualize 3D mathematical functions using\nhandwritten input. Researchers have demonstrated overlaying 3D visualizations\nof mathematical concepts through AR enhances learning motivation and\ncomprehension, and equation parsing makes the authoring of teaching materials\nmore time-efficient for instructors. Previous works have developed AR systems\nthat separately employ equation parsing and 3D mathematical visualizations, but\nwork has yet to be done to combine those features by enabling real-time\ninteractions and dynamic visualizations that help users learn in situ. We\nexplore this by developing an AR system featuring handwritten equation parsing,\ngraph manipulation, and a 3D function plotter. We found that our system\nsignificantly surpassed other systems in engagement, achieved comparable ease\nof use to a popular visualization tool, was considered the most effective in\naiding problem-solving, and was highly preferred by participants for future\nuse.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u540d\u4e3a\u201cBreaking the Plane\u201d\u7684AR\u5e94\u7528\uff0c\u901a\u8fc7\u624b\u5199\u8f93\u5165\u5b9e\u73b03D\u6570\u5b66\u51fd\u6570\u7684\u53ef\u89c6\u5316\uff0c\u7ed3\u5408\u5b9e\u65f6\u4ea4\u4e92\u548c\u52a8\u6001\u53ef\u89c6\u5316\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u5c55\u793a\u4e86AR\u5728\u6570\u5b66\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u4f46\u5c1a\u672a\u6709\u7cfb\u7edf\u80fd\u5c06\u624b\u5199\u65b9\u7a0b\u89e3\u6790\u4e0e3D\u53ef\u89c6\u5316\u7ed3\u5408\uff0c\u63d0\u4f9b\u5b9e\u65f6\u4ea4\u4e92\u5b66\u4e60\u4f53\u9a8c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u624b\u5199\u65b9\u7a0b\u89e3\u6790\u3001\u56fe\u5f62\u64cd\u4f5c\u548c3D\u51fd\u6570\u7ed8\u56fe\u5668\u7684AR\u7cfb\u7edf\u3002", "result": "\u7cfb\u7edf\u5728\u53c2\u4e0e\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7cfb\u7edf\uff0c\u6613\u7528\u6027\u4e0e\u6d41\u884c\u53ef\u89c6\u5316\u5de5\u5177\u76f8\u5f53\uff0c\u4e14\u88ab\u8ba4\u4e3a\u662f\u6700\u6709\u6548\u7684\u95ee\u9898\u89e3\u51b3\u8f85\u52a9\u5de5\u5177\uff0c\u7528\u6237\u672a\u6765\u4f7f\u7528\u610f\u613f\u5f3a\u70c8\u3002", "conclusion": "\u7ed3\u5408\u624b\u5199\u8f93\u5165\u548c\u52a8\u60013D\u53ef\u89c6\u5316\u7684AR\u7cfb\u7edf\u80fd\u6709\u6548\u63d0\u5347\u6570\u5b66\u5b66\u4e60\u7684\u6548\u679c\u548c\u53c2\u4e0e\u5ea6\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.06008", "pdf": "https://arxiv.org/pdf/2507.06008", "abs": "https://arxiv.org/abs/2507.06008", "authors": ["Jungeun Lim", "Stephan A. Fahrenkrog-Petersen", "Xixi Lu", "Jan Mendling", "Minseok Song"], "title": "The Impact of Event Data Partitioning on Privacy-aware Process Discovery", "categories": ["cs.CR", "cs.AI", "cs.DB"], "comment": null, "summary": "Information systems support the execution of business processes. The event\nlogs of these executions generally contain sensitive information about\ncustomers, patients, and employees. The corresponding privacy challenges can be\naddressed by anonymizing the event logs while still retaining utility for\nprocess discovery. However, trading off utility and privacy is difficult: the\nhigher the complexity of event log, the higher the loss of utility by\nanonymization. In this work, we propose a pipeline that combines anonymization\nand event data partitioning, where event abstraction is utilized for\npartitioning. By leveraging event abstraction, event logs can be segmented into\nmultiple parts, allowing each sub-log to be anonymized separately. This\npipeline preserves privacy while mitigating the loss of utility. To validate\nour approach, we study the impact of event partitioning on two anonymization\ntechniques using three real-world event logs and two process discovery\ntechniques. Our results demonstrate that event partitioning can bring\nimprovements in process discovery utility for directly-follows-based\nanonymization techniques.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u533f\u540d\u5316\u548c\u4e8b\u4ef6\u6570\u636e\u5206\u533a\u7684\u6d41\u7a0b\uff0c\u901a\u8fc7\u4e8b\u4ef6\u62bd\u8c61\u5206\u5272\u4e8b\u4ef6\u65e5\u5fd7\u4ee5\u51cf\u5c11\u533f\u540d\u5316\u5e26\u6765\u7684\u6548\u7528\u635f\u5931\u3002", "motivation": "\u89e3\u51b3\u4e8b\u4ef6\u65e5\u5fd7\u533f\u540d\u5316\u4e2d\u9690\u79c1\u4fdd\u62a4\u4e0e\u6548\u7528\u4fdd\u7559\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u533f\u540d\u5316\u548c\u4e8b\u4ef6\u6570\u636e\u5206\u533a\u7684\u6d41\u7a0b\uff0c\u5229\u7528\u4e8b\u4ef6\u62bd\u8c61\u5bf9\u65e5\u5fd7\u8fdb\u884c\u5206\u5272\uff0c\u5206\u522b\u533f\u540d\u5316\u5404\u90e8\u5206\u3002", "result": "\u4e8b\u4ef6\u5206\u533a\u80fd\u591f\u63d0\u5347\u57fa\u4e8e\u76f4\u63a5\u8ddf\u968f\u5173\u7cfb\u7684\u533f\u540d\u5316\u6280\u672f\u5728\u8fc7\u7a0b\u53d1\u73b0\u4e2d\u7684\u6548\u7528\u3002", "conclusion": "\u4e8b\u4ef6\u5206\u533a\u65b9\u6cd5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u65e5\u5fd7\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.06062", "pdf": "https://arxiv.org/pdf/2507.06062", "abs": "https://arxiv.org/abs/2507.06062", "authors": ["Julia Pelzer", "Corn\u00e9 Verburg", "Alexander Heinlein", "Miriam Schulte"], "title": "Few-Shot Learning by Explicit Physics Integration: An Application to Groundwater Heat Transport", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Machine learning methods often struggle with real-world applications in\nscience and engineering due to limited or low-quality training data. In this\nwork, the example of groundwater flow with heat transport is considered; this\ncorresponds to an advection-diffusion process under heterogeneous flow\nconditions, that is, spatially distributed material parameters and heat\nsources. Classical numerical simulations are costly and challenging due to high\nspatio-temporal resolution requirements and large domains. While often\ncomputationally more efficient, purely data-driven surrogate models face\ndifficulties, particularly in predicting the advection process, which is highly\nsensitive to input variations and involves long-range spatial interactions.\nTherefore, in this work, a Local-Global Convolutional Neural Network (LGCNN)\napproach is introduced. It combines a lightweight numerical surrogate for the\ntransport process (global) with convolutional neural networks for the\ngroundwater velocity and heat diffusion processes (local). With the LGCNN, a\ncity-wide subsurface temperature field is modeled, involving a heterogeneous\ngroundwater flow field and one hundred groundwater heat pump injection points\nforming interacting heat plumes over long distances. The model is first\nsystematically analyzed based on random subsurface input fields. Then, the\nmodel is trained on a handful of cut-outs from a real-world subsurface map of\nthe Munich region in Germany, and it scales to larger cut-outs without\nretraining. All datasets, our code, and trained models are published for\nreproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c40\u90e8\u4e0e\u5168\u5c40\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08LGCNN\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5730\u4e0b\u6c34\u6d41\u52a8\u4e0e\u70ed\u4f20\u8f93\u95ee\u9898\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6570\u503c\u6a21\u62df\u7684\u9ad8\u6210\u672c\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5b9e\u9645\u79d1\u5b66\u4e0e\u5de5\u7a0b\u5e94\u7528\u4e2d\u5e38\u56e0\u8bad\u7ec3\u6570\u636e\u6709\u9650\u6216\u8d28\u91cf\u4f4e\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u662f\u5728\u9884\u6d4b\u5730\u4e0b\u6c34\u6d41\u52a8\u8fd9\u79cd\u5bf9\u8f93\u5165\u53d8\u5316\u9ad8\u5ea6\u654f\u611f\u4e14\u6d89\u53ca\u957f\u8ddd\u79bb\u7a7a\u95f4\u4ea4\u4e92\u7684\u8fc7\u7a0b\u4e2d\u3002", "method": "\u5f15\u5165\u4e86Local-Global Convolutional Neural Network\uff08LGCNN\uff09\uff0c\u7ed3\u5408\u4e86\u8f7b\u91cf\u7ea7\u6570\u503c\u6a21\u62df\u66ff\u4ee3\u6a21\u578b\uff08\u5168\u5c40\uff09\u4e0e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08\u5c40\u90e8\uff09\uff0c\u5206\u522b\u5904\u7406\u5730\u4e0b\u6c34\u901f\u5ea6\u548c\u70ed\u6269\u6563\u8fc7\u7a0b\u3002", "result": "LGCNN\u6210\u529f\u6a21\u62df\u4e86\u57ce\u5e02\u8303\u56f4\u5185\u7684\u5730\u4e0b\u6e29\u5ea6\u573a\uff0c\u5305\u62ec\u5f02\u8d28\u5730\u4e0b\u6c34\u6d41\u52a8\u573a\u548c\u591a\u4e2a\u5730\u4e0b\u6c34\u70ed\u6cf5\u6ce8\u5165\u70b9\u5f62\u6210\u7684\u957f\u8ddd\u79bb\u70ed\u7fbd\u6d41\u3002\u6a21\u578b\u5728\u5c0f\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u4e0a\u8bad\u7ec3\u540e\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6269\u5c55\u5230\u66f4\u5927\u8303\u56f4\u3002", "conclusion": "LGCNN\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u5730\u4e0b\u6c34\u6d41\u52a8\u4e0e\u70ed\u4f20\u8f93\u95ee\u9898\uff0c\u540c\u65f6\u652f\u6301\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u7684\u518d\u73b0\u6027\u3002"}}
{"id": "2507.05932", "pdf": "https://arxiv.org/pdf/2507.05932", "abs": "https://arxiv.org/abs/2507.05932", "authors": ["You Lu", "Dingji Wang", "Kaifeng Huang", "Bihuan Chen", "Xin Peng"], "title": "TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems", "categories": ["cs.SE", "cs.CV"], "comment": null, "summary": "Autonomous vehicle technology has been developed in the last decades with\nrecent advances in sensing and computing technology. There is an urgent need to\nensure the reliability and robustness of autonomous driving systems (ADSs).\nDespite the recent achievements in testing various ADS modules, little\nattention has been paid on the automated testing of traffic light detection\nmodels in ADSs. A common practice is to manually collect and label traffic\nlight data. However, it is labor-intensive, and even impossible to collect\ndiverse data under different driving environments.\n  To address these problems, we propose and implement TigAug to automatically\naugment labeled traffic light images for testing traffic light detection models\nin ADSs. We construct two families of metamorphic relations and three families\nof transformations based on a systematic understanding of weather environments,\ncamera properties, and traffic light properties. We use augmented images to\ndetect erroneous behaviors of traffic light detection models by\ntransformation-specific metamorphic relations, and to improve the performance\nof traffic light detection models by retraining. Large-scale experiments with\nfour state-of-the-art traffic light detection models and two traffic light\ndatasets have demonstrated that i) TigAug is effective in testing traffic light\ndetection models, ii) TigAug is efficient in synthesizing traffic light images,\nand iii) TigAug generates traffic light images with acceptable naturalness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTigAug\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u589e\u5f3a\u4ea4\u901a\u706f\u56fe\u50cf\u6570\u636e\uff0c\u4ee5\u6d4b\u8bd5\u548c\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u7684\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u6d4b\u8bd5\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u6570\u636e\u6536\u96c6\uff0c\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u8986\u76d6\u591a\u6837\u9a7e\u9a76\u73af\u5883\u3002", "method": "\u6784\u5efa\u4e24\u7c7b\u53d8\u5f62\u5173\u7cfb\u548c\u4e09\u7c7b\u56fe\u50cf\u53d8\u6362\uff0c\u57fa\u4e8e\u5929\u6c14\u3001\u76f8\u673a\u53ca\u4ea4\u901a\u706f\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9eTigAug\u80fd\u6709\u6548\u6d4b\u8bd5\u6a21\u578b\u3001\u9ad8\u6548\u751f\u6210\u56fe\u50cf\uff0c\u4e14\u56fe\u50cf\u81ea\u7136\u5ea6\u53ef\u63a5\u53d7\u3002", "conclusion": "TigAug\u4e3a\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u4e0e\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.05820", "pdf": "https://arxiv.org/pdf/2507.05820", "abs": "https://arxiv.org/abs/2507.05820", "authors": ["Syemin Park", "Soobin Park", "Youn-kyung Lim"], "title": "Constella: Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents", "categories": ["cs.HC", "cs.AI", "cs.MA"], "comment": "50 pages", "summary": "Creating a cast of characters by attending to their relational dynamics is a\ncritical aspect of most long-form storywriting. However, our formative study\n(N=14) reveals that writers struggle to envision new characters that could\ninfluence existing ones, to balance similarities and differences among\ncharacters, and to intricately flesh out their relationships. Based on these\nobservations, we designed Constella, an LLM-based multi-agent tool that\nsupports storywriters' interconnected character creation process. Constella\nsuggests related characters (FRIENDS DISCOVERY feature), reveals the inner\nmindscapes of several characters simultaneously (JOURNALS feature), and\nmanifests relationships through inter-character responses (COMMENTS feature).\nOur 7-8 day deployment study with storywriters (N=11) shows that Constella\nenabled the creation of expansive communities composed of related characters,\nfacilitated the comparison of characters' thoughts and emotions, and deepened\nwriters' understanding of character relationships. We conclude by discussing\nhow multi-agent interactions can help distribute writers' attention and effort\nacross the character cast.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Constella\uff0c\u4e00\u6b3e\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u5de5\u5177\uff0c\u65e8\u5728\u5e2e\u52a9\u4f5c\u5bb6\u89e3\u51b3\u521b\u4f5c\u89d2\u8272\u5173\u7cfb\u65f6\u7684\u6311\u6218\u3002\u901a\u8fc7\u529f\u80fd\u5982FRIENDS DISCOVERY\u3001JOURNALS\u548cCOMMENTS\uff0c\u5b83\u652f\u6301\u4f5c\u5bb6\u6784\u5efa\u6269\u5c55\u7684\u89d2\u8272\u793e\u533a\u5e76\u6df1\u5165\u7406\u89e3\u89d2\u8272\u5173\u7cfb\u3002", "motivation": "\u4f5c\u5bb6\u5728\u957f\u7bc7\u6545\u4e8b\u521b\u4f5c\u4e2d\u5e38\u96be\u4ee5\u8bbe\u60f3\u65b0\u89d2\u8272\u3001\u5e73\u8861\u89d2\u8272\u95f4\u7684\u76f8\u4f3c\u4e0e\u5dee\u5f02\uff0c\u5e76\u6df1\u5165\u523b\u753b\u89d2\u8272\u5173\u7cfb\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86Constella\u5de5\u5177\uff0c\u5229\u7528LLM\u63d0\u4f9b\u89d2\u8272\u5efa\u8bae\uff08FRIENDS DISCOVERY\uff09\u3001\u5c55\u793a\u591a\u4e2a\u89d2\u8272\u7684\u5185\u5fc3\u4e16\u754c\uff08JOURNALS\uff09\uff0c\u4ee5\u53ca\u901a\u8fc7\u89d2\u8272\u95f4\u4e92\u52a8\uff08COMMENTS\uff09\u8868\u73b0\u5173\u7cfb\u3002", "result": "\u90e8\u7f72\u7814\u7a76\u8868\u660e\uff0cConstella\u5e2e\u52a9\u4f5c\u5bb6\u6784\u5efa\u4e86\u6269\u5c55\u7684\u89d2\u8272\u793e\u533a\uff0c\u6bd4\u8f83\u89d2\u8272\u601d\u60f3\u4e0e\u60c5\u611f\uff0c\u5e76\u52a0\u6df1\u4e86\u5bf9\u5173\u7cfb\u7684\u7406\u89e3\u3002", "conclusion": "\u591a\u4ee3\u7406\u4e92\u52a8\u6709\u52a9\u4e8e\u4f5c\u5bb6\u5728\u89d2\u8272\u7fa4\u4f53\u4e2d\u5206\u914d\u6ce8\u610f\u529b\u4e0e\u7cbe\u529b\u3002"}}
{"id": "2507.05981", "pdf": "https://arxiv.org/pdf/2507.05981", "abs": "https://arxiv.org/abs/2507.05981", "authors": ["Marc Oriol", "Quim Motger", "Jordi Marco", "Xavier Franch"], "title": "Multi-Agent Debate Strategies to Enhance Requirements Engineering with Large Language Models", "categories": ["cs.SE"], "comment": null, "summary": "Context: Large Language Model (LLM) agents are becoming widely used for\nvarious Requirements Engineering (RE) tasks. Research on improving their\naccuracy mainly focuses on prompt engineering, model fine-tuning, and retrieval\naugmented generation. However, these methods often treat models as isolated\nblack boxes - relying on single-pass outputs without iterative refinement or\ncollaboration, limiting robustness and adaptability. Objective: We propose\nthat, just as human debates enhance accuracy and reduce bias in RE tasks by\nincorporating diverse perspectives, different LLM agents debating and\ncollaborating may achieve similar improvements. Our goal is to investigate\nwhether Multi-Agent Debate (MAD) strategies can enhance RE performance. Method:\nWe conducted a systematic study of existing MAD strategies across various\ndomains to identify their key characteristics. To assess their applicability in\nRE, we implemented and tested a preliminary MAD-based framework for RE\nclassification. Results: Our study identified and categorized several MAD\nstrategies, leading to a taxonomy outlining their core attributes. Our\npreliminary evaluation demonstrated the feasibility of applying MAD to RE\nclassification. Conclusions: MAD presents a promising approach for improving\nLLM accuracy in RE tasks. This study provides a foundational understanding of\nMAD strategies, offering insights for future research and refinements in RE\napplications.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\uff08MAD\uff09\u7b56\u7565\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u4e86\u521d\u6b65MAD\u6846\u67b6\u5e76\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u5fae\u8c03\uff09\u5c06LLM\u89c6\u4e3a\u5b64\u7acb\u9ed1\u7bb1\uff0c\u7f3a\u4e4f\u8fed\u4ee3\u4f18\u5316\u548c\u534f\u4f5c\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002\u53d7\u4eba\u7c7b\u8fa9\u8bba\u542f\u53d1\uff0c\u5e0c\u671b\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u63d0\u5347RE\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u73b0\u6709MAD\u7b56\u7565\uff0c\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u5e76\u6784\u5efa\u521d\u6b65MAD\u6846\u67b6\u7528\u4e8eRE\u5206\u7c7b\u4efb\u52a1\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86MAD\u7b56\u7565\u7684\u6838\u5fc3\u7279\u5f81\uff0c\u521d\u6b65\u8bc4\u4f30\u8868\u660e\u5176\u5728RE\u5206\u7c7b\u4efb\u52a1\u4e2d\u53ef\u884c\u3002", "conclusion": "MAD\u4e3a\u63d0\u5347LLM\u5728RE\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.05962", "pdf": "https://arxiv.org/pdf/2507.05962", "abs": "https://arxiv.org/abs/2507.05962", "authors": ["Jiapeng Yao", "Lantian Zhang", "Jiping Huang"], "title": "Evaluation of Large Language Model-Driven AutoML in Data and Model Management from Human-Centered Perspective", "categories": ["cs.HC"], "comment": null, "summary": "As organizations increasingly seek to leverage machine learning (ML)\ncapabilities, the technical complexity of implementing ML solutions creates\nsignificant barriers to adoption and impacts operational efficiency. This\nresearch examines how Large Language Models (LLMs) can transform the\naccessibility of ML technologies within organizations through a human-centered\nAutomated Machine Learning (AutoML) approach. Through a comprehensive user\nstudy involving 15 professionals across various roles and technical\nbackgrounds, we evaluate the organizational impact of an LLM-based AutoML\nframework compared to traditional implementation methods. Our research offers\nfour significant contributions to both management practice and technical\ninnovation: First, we present pioneering evidence that LLM-based interfaces can\ndramatically improve ML implementation success rates, with 93.34% of users\nachieved superior performance in the LLM condition, with 46.67% showing higher\naccuracy (10-25% improvement over baseline) and 46.67% demonstrating\nsignificantly higher accuracy (>25% improvement over baseline), while 6.67%\nmaintained comparable performance levels; and 60% reporting substantially\nreduced development time. Second, we demonstrate how natural language\ninterfaces can effectively bridge the technical skills gap in organizations,\ncutting implementation time by 50% while improving accuracy across all\nexpertise levels. Third, we provide valuable insights for organizations\ndesigning human-AI collaborative systems, showing that our approach reduced\nerror resolution time by 73% and significantly accelerated employee learning\ncurves. Finally, we establish empirical support for natural language as an\neffective interface for complex technical systems, offering organizations a\npath to democratize ML capabilities without compromising quality or\nperformance.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684AutoML\u6846\u67b6\u5982\u4f55\u63d0\u5347\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6280\u672f\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u5b9e\u65bd\u6548\u7387\uff0c\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u6210\u529f\u7387\u3001\u7cbe\u5ea6\u548c\u5f00\u53d1\u65f6\u95f4\u4e0a\u7684\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u7ec4\u7ec7\u5728\u5e94\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u65f6\u9762\u4e34\u6280\u672f\u590d\u6742\u6027\u5e26\u6765\u7684\u9ad8\u95e8\u69db\u548c\u4f4e\u6548\u7387\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5982\u4f55\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u964d\u4f4e\u6280\u672f\u95e8\u69db\u3002", "method": "\u901a\u8fc7\u5bf915\u540d\u4e0d\u540c\u80cc\u666f\u7684\u4e13\u4e1a\u4eba\u58eb\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff0c\u6bd4\u8f83\u4e86LLM-based AutoML\u4e0e\u4f20\u7edf\u65b9\u6cd5\u7684\u5b9e\u65bd\u6548\u679c\u3002", "result": "LLM-based AutoML\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u65bd\u6210\u529f\u7387\uff0893.34%\u7528\u6237\u8868\u73b0\u66f4\u4f18\uff09\u3001\u7cbe\u5ea6\uff0846.67%\u63d0\u534710-25%\uff0c46.67%\u63d0\u5347>25%\uff09\u548c\u5f00\u53d1\u6548\u7387\uff0860%\u7528\u6237\u5f00\u53d1\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\uff09\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684LLM\u63a5\u53e3\u80fd\u6709\u6548\u964d\u4f4e\u6280\u672f\u95e8\u69db\uff0c\u4fc3\u8fdbML\u80fd\u529b\u7684\u6c11\u4e3b\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u548c\u9ad8\u6027\u80fd\u3002"}}
{"id": "2507.05995", "pdf": "https://arxiv.org/pdf/2507.05995", "abs": "https://arxiv.org/abs/2507.05995", "authors": ["Pengzhou Chen", "Tao Chen"], "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning", "categories": ["cs.SE", "68Nxx", "D.2.0; D.2.8"], "comment": "This paper has been accepted by ICSE26", "summary": "The high configurability of modern software systems has made configuration\ntuning a crucial step for assuring system performance, e.g., latency or\nthroughput. However, given the expensive measurements, large configuration\nspace, and rugged configuration landscape, existing tuners suffer\nineffectiveness due to the difficult balance of budget utilization between\nexploring uncertain regions (for escaping from local optima) and exploiting\nguidance of known good configurations (for fast convergence). The root cause is\nthat we lack knowledge of where the promising regions lay, which also causes\nchallenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by\ncausally purified rules. PromiseTune is unique in the sense that we learn\nrules, which reflect certain regions in the configuration landscape, and purify\nthem with causal inference. The remaining rules serve as approximated\nreflections of the promising regions, bounding the tuning to emphasize these\nplaces in the landscape. This, as we demonstrate, can effectively mitigate the\nimpact of the exploration and exploitation trade-off. Those purified regions\ncan then be paired with the measured configurations to provide spatial\nexplainability at the landscape level. Comparing with 11 state-of-the-art\ntuners on 12 systems and varying budgets, we show that PromiseTune performs\nsignificantly better than the others with $42\\%$ superior rank to the overall\nsecond best while providing richer information to explain the hidden system\ncharacteristics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPromiseTune\u65b9\u6cd5\uff0c\u901a\u8fc7\u56e0\u679c\u7eaf\u5316\u7684\u89c4\u5219\u6307\u5bfc\u914d\u7f6e\u8c03\u4f18\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8c03\u4f18\u5668\u5728\u63a2\u7d22\u548c\u5229\u7528\u95f4\u7684\u5e73\u8861\u96be\u9898\uff0c\u5e76\u63d0\u5347\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u7684\u9ad8\u53ef\u914d\u7f6e\u6027\u4f7f\u5f97\u914d\u7f6e\u8c03\u4f18\u6210\u4e3a\u786e\u4fdd\u6027\u80fd\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u96be\u4ee5\u5e73\u8861\u800c\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faPromiseTune\uff0c\u901a\u8fc7\u56e0\u679c\u7eaf\u5316\u5b66\u4e60\u914d\u7f6e\u89c4\u5219\uff0c\u754c\u5b9a\u6709\u524d\u666f\u7684\u533a\u57df\uff0c\u6307\u5bfc\u8c03\u4f18\u8fc7\u7a0b\u3002", "result": "\u572812\u4e2a\u7cfb\u7edf\u548c\u4e0d\u540c\u9884\u7b97\u4e0b\u4e0e11\u79cd\u5148\u8fdb\u8c03\u4f18\u5668\u5bf9\u6bd4\uff0cPromiseTune\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u6392\u540d\u63d0\u534742%\uff0c\u5e76\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u7cfb\u7edf\u7279\u6027\u89e3\u91ca\u4fe1\u606f\u3002", "conclusion": "PromiseTune\u901a\u8fc7\u56e0\u679c\u7eaf\u5316\u89c4\u5219\u6709\u6548\u89e3\u51b3\u4e86\u914d\u7f6e\u8c03\u4f18\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u96be\u9898\uff0c\u5e76\u63d0\u5347\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.06000", "pdf": "https://arxiv.org/pdf/2507.06000", "abs": "https://arxiv.org/abs/2507.06000", "authors": ["Shuning Zhang", "Hui Wang", "Xin Yi"], "title": "Exploring Collaboration Patterns and Strategies in Human-AI Co-creation through the Lens of Agency: A Scoping Review of the Top-tier HCI Literature", "categories": ["cs.HC"], "comment": null, "summary": "As Artificial Intelligence (AI) increasingly becomes an active collaborator\nin co-creation, understanding the distribution and dynamic of agency is\nparamount. The Human-Computer Interaction (HCI) perspective is crucial for this\nanalysis, as it uniquely reveals the interaction dynamics and specific control\nmechanisms that dictate how agency manifests in practice. Despite this\nimportance, a systematic synthesis mapping agency configurations and control\nmechanisms within the HCI/CSCW literature is lacking. Addressing this gap, we\nreviewed 134 papers from top-tier HCI/CSCW venues (e.g., CHI, UIST, CSCW) over\nthe past 20 years. This review yields four primary contributions: (1) an\nintegrated theoretical framework structuring agency patterns, control\nmechanisms, and interaction contexts, (2) a comprehensive operational catalog\nof control mechanisms detailing how agency is implemented; (3) an actionable\ncross-context map linking agency configurations to diverse co-creative\npractices; and (4) grounded implications and guidance for future CSCW research\nand the design of co-creative systems, addressing aspects like trust and\nethics.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86HCI/CSCW\u9886\u57df134\u7bc7\u9876\u4f1a\u8bba\u6587\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u5173\u4e8eAI\u534f\u4f5c\u4e2d\u673a\u6784\u5206\u914d\u4e0e\u63a7\u5236\u673a\u5236\u7684\u7406\u8bba\u6846\u67b6\u3001\u64cd\u4f5c\u76ee\u5f55\u548c\u8de8\u60c5\u5883\u6620\u5c04\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u968f\u7740AI\u5728\u5171\u540c\u521b\u4f5c\u4e2d\u7684\u89d2\u8272\u65e5\u76ca\u91cd\u8981\uff0c\u7406\u89e3\u5176\u673a\u6784\u5206\u914d\u4e0e\u52a8\u6001\u63a7\u5236\u673a\u5236\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u7efc\u8ff0\u3002", "method": "\u56de\u987e\u4e86\u8fc7\u53bb20\u5e74134\u7bc7\u6765\u81eaCHI\u3001UIST\u3001CSCW\u7b49\u9876\u4f1a\u7684HCI/CSCW\u8bba\u6587\u3002", "result": "\u63d0\u51fa\u4e86\u56db\u9879\u4e3b\u8981\u8d21\u732e\uff1a\u7406\u8bba\u6846\u67b6\u3001\u63a7\u5236\u673a\u5236\u76ee\u5f55\u3001\u8de8\u60c5\u5883\u6620\u5c04\u53ca\u672a\u6765\u7814\u7a76\u6307\u5bfc\u3002", "conclusion": "\u586b\u8865\u4e86HCI/CSCW\u9886\u57df\u5bf9AI\u534f\u4f5c\u4e2d\u673a\u6784\u4e0e\u63a7\u5236\u673a\u5236\u7cfb\u7edf\u6027\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u5408\u4f5c\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2507.06014", "pdf": "https://arxiv.org/pdf/2507.06014", "abs": "https://arxiv.org/abs/2507.06014", "authors": ["Tim Puhlf\u00fcr\u00df", "Julia Butzke", "Walid Maalej"], "title": "Model Cards Revisited: Bridging the Gap Between Theory and Practice for Ethical AI Requirements", "categories": ["cs.SE"], "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Model cards are the primary documentation framework for developers of\nartificial intelligence (AI) models to communicate critical information to\ntheir users. Those users are often developers themselves looking for relevant\ndocumentation to ensure that their AI systems comply with the ethical\nrequirements of existing laws, guidelines, and standards. Recent studies\nindicate inadequate model documentation practices, suggesting a gap between AI\nrequirements and current practices in model documentation. To understand this\ngap and provide actionable guidance to bridge it, we conducted a thematic\nanalysis of 26 guidelines on ethics and AI, three AI documentation frameworks,\nthree quantitative studies of model cards, and ten actual model cards. We\nidentified a total of 43 ethical requirements relevant to model documentation\nand organized them into a taxonomy featuring four themes and twelve sub-themes\nrepresenting ethical principles. Our findings indicate that model developers\npredominantly emphasize model capabilities and reliability in the documentation\nwhile overlooking other ethical aspects, such as explainability, user autonomy,\nand fairness. This underscores the need for enhanced support in documenting\nethical AI considerations. Our taxonomy serves as a foundation for a revised\nmodel card framework that holistically addresses ethical AI requirements.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86AI\u6a21\u578b\u6587\u6863\u7684\u4f26\u7406\u8981\u6c42\u4e0e\u5b9e\u8df5\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e86\u5305\u542b43\u9879\u4f26\u7406\u8981\u6c42\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u547c\u5401\u6539\u8fdb\u6587\u6863\u6846\u67b6\u4ee5\u5168\u9762\u8986\u76d6\u4f26\u7406\u8003\u91cf\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u6587\u6863\u5b9e\u8df5\u4e2d\u5b58\u5728\u4f26\u7406\u8981\u6c42\u4e0e\u5b9e\u9645\u5185\u5bb9\u7684\u4e0d\u5339\u914d\uff0c\u5f00\u53d1\u8005\u5e38\u5ffd\u7565\u5982\u53ef\u89e3\u91ca\u6027\u3001\u7528\u6237\u81ea\u4e3b\u6743\u548c\u516c\u5e73\u6027\u7b49\u4f26\u7406\u65b9\u9762\u3002", "method": "\u901a\u8fc7\u5bf926\u4e2a\u4f26\u7406\u4e0eAI\u6307\u5357\u30013\u4e2a\u6587\u6863\u6846\u67b6\u30013\u9879\u6a21\u578b\u5361\u91cf\u5316\u7814\u7a76\u548c10\u4e2a\u5b9e\u9645\u6a21\u578b\u5361\u7684\u4e3b\u9898\u5206\u6790\uff0c\u7814\u7a76\u8005\u8bc6\u522b\u5e76\u5206\u7c7b\u4e8643\u9879\u4f26\u7406\u8981\u6c42\u3002", "result": "\u53d1\u73b0\u5f00\u53d1\u8005\u66f4\u5173\u6ce8\u6a21\u578b\u80fd\u529b\u4e0e\u53ef\u9760\u6027\uff0c\u800c\u5ffd\u89c6\u5176\u4ed6\u4f26\u7406\u8981\u6c42\u3002\u63d0\u51fa\u4e86\u5305\u542b4\u4e2a\u4e3b\u9898\u548c12\u4e2a\u5b50\u4e3b\u9898\u7684\u5206\u7c7b\u6cd5\u3002", "conclusion": "\u9700\u8981\u6539\u8fdb\u73b0\u6709\u6587\u6863\u6846\u67b6\u4ee5\u5168\u9762\u6ee1\u8db3\u4f26\u7406\u8981\u6c42\uff0c\u5206\u7c7b\u6cd5\u4e3a\u4fee\u8ba2\u6a21\u578b\u5361\u6846\u67b6\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.06141", "pdf": "https://arxiv.org/pdf/2507.06141", "abs": "https://arxiv.org/abs/2507.06141", "authors": ["Pat Pataranutaporn", "Nattavudh Powdthavee", "Chayapatr Archiwaranguprok", "Pattie Maes"], "title": "Large Language Models Predict Human Well-being -- But Not Equally Everywhere", "categories": ["cs.HC"], "comment": null, "summary": "Subjective well-being is a key metric in economic, medical, and policy\ndecision-making. As artificial intelligence provides scalable tools for\nmodelling human outcomes, it is crucial to evaluate whether large language\nmodels (LLMs) can accurately predict well-being across diverse global\npopulations. We evaluate four leading LLMs using data from 64,000 individuals\nin 64 countries. While LLMs capture broad correlates such as income and health,\ntheir predictive accuracy decreases in countries underrepresented in the\ntraining data, highlighting systematic biases rooted in global digital and\neconomic inequality. A pre-registered experiment demonstrates that LLMs rely on\nsurface-level linguistic similarity rather than conceptual understanding,\nleading to systematic misestimations in unfamiliar or resource-limited\nsettings. Injecting findings from underrepresented contexts substantially\nenhances performance, but a significant gap remains. These results highlight\nboth the promise and limitations of LLMs in predicting global well-being,\nunderscoring the importance of robust validation prior to their implementation\nacross these areas.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u9884\u6d4b\u5168\u7403\u5e78\u798f\u611f\uff0c\u4f46\u53d7\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\u504f\u5dee\uff0c\u8868\u73b0\u4e0d\u5747\u8861\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u5168\u7403\u4eba\u7fa4\u4e2d\u9884\u6d4b\u4e3b\u89c2\u5e78\u798f\u611f\u7684\u80fd\u529b\uff0c\u4ee5\u9a8c\u8bc1\u5176\u9002\u7528\u4e8e\u7ecf\u6d4e\u3001\u533b\u7597\u548c\u653f\u7b56\u51b3\u7b56\u3002", "method": "\u4f7f\u7528\u6765\u81ea64\u4e2a\u56fd\u5bb664,000\u4eba\u7684\u6570\u636e\u6d4b\u8bd5\u56db\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u9884\u6ce8\u518c\u5b9e\u9a8c\u3002", "result": "LLMs\u5728\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u7684\u56fd\u5bb6\u8868\u73b0\u8f83\u5dee\uff0c\u4f9d\u8d56\u8bed\u8a00\u76f8\u4f3c\u6027\u800c\u975e\u6982\u5ff5\u7406\u89e3\uff1b\u6539\u8fdb\u6570\u636e\u540e\u4ecd\u6709\u5dee\u8ddd\u3002", "conclusion": "LLMs\u5728\u9884\u6d4b\u5168\u7403\u5e78\u798f\u611f\u65b9\u9762\u6709\u6f5c\u529b\u4f46\u5b58\u5c40\u9650\u6027\uff0c\u9700\u5145\u5206\u9a8c\u8bc1\u540e\u5e94\u7528\u3002"}}
{"id": "2507.05305", "pdf": "https://arxiv.org/pdf/2507.05305", "abs": "https://arxiv.org/abs/2507.05305", "authors": ["Lorenzo Lee Solano", "Charles Koutcheme", "Juho Leinonen", "Alexandra Vassar", "Jake Renzella"], "title": "Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.SE"], "comment": "7 pages, 3 tables, 1 figure", "summary": "Frontier Large language models (LLMs) like ChatGPT and Gemini can decipher\ncryptic compiler errors for novice programmers, but their computational scale,\ncost, and tendency to over-assist make them problematic for widespread\npedagogical adoption. This work demonstrates that smaller, specialised language\nmodels, enhanced via Supervised Fine-Tuning (SFT), present a more viable\nalternative for educational tools. We utilise a new dataset of 40,000 C\ncompiler error explanations, derived from real introductory programming (CS1/2)\nstudent-generated programming errors, which we used to fine-tune three\nopen-source models: Qwen3-4B, Llama-3.1-8B, and Qwen3-32B. We performed a dual\nevaluation, combining expert human reviews with a large-scale automated\nanalysis of 8,000 responses using a validated LLM-as-judge ensemble. Our\nresults show that SFT significantly boosts the pedagogical quality of smaller\nmodels, achieving performance comparable to much larger models. We analyse the\ntrade-offs between model size and quality, confirming that fine-tuning compact,\nefficient models on high-quality, domain-specific data is a potent strategy for\ncreating specialised models to drive educational tools. We provide a replicable\nmethodology to foster broader access to generative AI capabilities in\neducational contexts.", "AI": {"tldr": "\u5c0f\u578b\u4e13\u7528\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5728\u6559\u80b2\u5de5\u5177\u4e2d\u8868\u73b0\u4f18\u4e8e\u5927\u578b\u901a\u7528\u6a21\u578b\uff0c\u66f4\u9002\u5408\u6559\u5b66\u573a\u666f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\u548cGemini\uff09\u867d\u7136\u80fd\u89e3\u6790\u7f16\u8bd1\u5668\u9519\u8bef\uff0c\u4f46\u5176\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5bb9\u6613\u8fc7\u5ea6\u8f85\u52a9\uff0c\u4e0d\u9002\u5408\u5e7f\u6cdb\u6559\u5b66\u5e94\u7528\u3002", "method": "\u4f7f\u752840,000\u6761C\u7f16\u8bd1\u5668\u9519\u8bef\u6570\u636e\u96c6\u5bf9Qwen3-4B\u3001Llama-3.1-8B\u548cQwen3-32B\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u9a8c\u8bc1\u6548\u679c\u3002", "result": "SFT\u663e\u8457\u63d0\u5347\u5c0f\u578b\u6a21\u578b\u7684\u6559\u5b66\u8d28\u91cf\uff0c\u6027\u80fd\u63a5\u8fd1\u5927\u578b\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u4e13\u7528\u6570\u636e\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u9ad8\u8d28\u91cf\u9886\u57df\u6570\u636e\u5fae\u8c03\u5c0f\u578b\u6a21\u578b\u662f\u6559\u80b2\u5de5\u5177\u5f00\u53d1\u7684\u53ef\u884c\u7b56\u7565\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2507.06202", "pdf": "https://arxiv.org/pdf/2507.06202", "abs": "https://arxiv.org/abs/2507.06202", "authors": ["Charlotte Kiesel", "Dipayan Mukherjee", "Mark Hasegawa-Johnson", "Karrie Karahalios"], "title": "V(is)owel: An Interactive Vowel Chart to Understand What Makes Visual Pronunciation Effective in Second Language Learning", "categories": ["cs.HC", "K.3.1"], "comment": null, "summary": "Visual feedback speeds up learners' improvement of pronunciation in a second\nlanguage. The visual combined with audio allows speakers to see sounds and\ndifferences in pronunciation that they are unable to hear. Prior studies have\ntested different visual methods for improving pronunciation, however, we do not\nhave conclusive understanding of what aspects of the visualizations contributed\nto improvements. Based on previous work, we created V(is)owel, an interactive\nvowel chart. Vowel charts provide actionable feedback by directly mapping\nphysical tongue movement onto a chart. We compared V(is)owel with an\nauditory-only method to explore how learners parse visual and auditory feedback\nto understand how and why visual feedback is effective for pronunciation\nimprovement. The findings suggest that designers should include explicit\nanatomical feedback that directly maps onto physical movement for phonetically\nuntrained learners. Furthermore, visual feedback has the potential to motivate\nmore practice since all eight of the participants cited using the visuals as a\ngoal with V(is)owel versus relying on their own judgment with audio alone.\nTheir statements are backed up by all participants practicing words with\nV(is)owel more than with audio-only. Our results indicate that V(is)owel is\neffective at providing actionable feedback, demonstrating the potential of\nvisual feedback methods in second language learning.", "AI": {"tldr": "\u89c6\u89c9\u53cd\u9988\uff08\u5982V(is)owel\uff09\u901a\u8fc7\u76f4\u89c2\u5c55\u793a\u53d1\u97f3\u5dee\u5f02\uff0c\u5e2e\u52a9\u4e8c\u8bed\u5b66\u4e60\u8005\u66f4\u5feb\u6539\u5584\u53d1\u97f3\uff0c\u4e14\u80fd\u6fc0\u53d1\u66f4\u591a\u7ec3\u4e60\u52a8\u673a\u3002", "motivation": "\u6b64\u524d\u7814\u7a76\u672a\u660e\u786e\u89c6\u89c9\u53cd\u9988\u4e2d\u54ea\u4e9b\u65b9\u9762\u5bf9\u53d1\u97f3\u6539\u5584\u6709\u6548\uff0c\u56e0\u6b64\u8bbe\u8ba1V(is)owel\u4ee5\u63a2\u7d22\u89c6\u89c9\u53cd\u9988\u7684\u4f5c\u7528\u673a\u5236\u3002", "method": "\u5f00\u53d1\u4ea4\u4e92\u5f0f\u5143\u97f3\u56fe\u8868V(is)owel\uff0c\u4e0e\u7eaf\u542c\u89c9\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u5206\u6790\u5b66\u4e60\u8005\u5728\u89c6\u89c9\u4e0e\u542c\u89c9\u53cd\u9988\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "V(is)owel\u901a\u8fc7\u76f4\u63a5\u6620\u5c04\u751f\u7406\u52a8\u4f5c\u63d0\u4f9b\u6709\u6548\u53cd\u9988\uff0c\u4e14\u5b66\u4e60\u8005\u66f4\u503e\u5411\u4e8e\u4f7f\u7528\u89c6\u89c9\u5de5\u5177\u8fdb\u884c\u7ec3\u4e60\u3002", "conclusion": "\u8bbe\u8ba1\u53d1\u97f3\u5b66\u4e60\u5de5\u5177\u65f6\uff0c\u5e94\u52a0\u5165\u76f4\u89c2\u7684\u751f\u7406\u52a8\u4f5c\u53cd\u9988\uff0c\u89c6\u89c9\u53cd\u9988\u5728\u4e8c\u8bed\u5b66\u4e60\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002"}}
{"id": "2505.10426", "pdf": "https://arxiv.org/pdf/2505.10426", "abs": "https://arxiv.org/abs/2505.10426", "authors": ["Maurice Chiodo", "Dennis M\u00fcller", "Paul Siewert", "Jean-Luc Wetherall", "Zoya Yasmine", "John Burden"], "title": "Formalising Human-in-the-Loop: Computational Reductions, Failure Modes, and Legal-Moral Responsibility", "categories": ["cs.CY", "cs.AI", "cs.HC", "math.HO", "F.1; H.1.2; I.2.0; K.4.1"], "comment": "12 pages. Keywords: Human-in-the-loop, Artificial Intelligence,\n  Oracle Machines, Liability, AI Safety, AI Regulations, Turing Reduction", "summary": "The legal compliance and safety of different Human-in-the-loop (HITL) setups\nfor AI can vary greatly. This manuscript aims to identify new ways of choosing\nbetween such setups, and shows that there is an unavoidable trade-off between\nthe attribution of legal responsibility and the technical explainability of AI.\nWe begin by using the notion of oracle machines from computability theory to\nformalise different HITL setups, distinguishing between trivial human\nmonitoring, single endpoint human action, and highly involved interaction\nbetween the human(s) and the AI. These correspond to total functions, many-one\nreductions, and Turing reductions respectively. A taxonomy categorising HITL\nfailure modes is then presented, highlighting the limitations on what any HITL\nsetup can actually achieve. Our approach then identifies oversights from UK and\nEU legal frameworks, which focus on certain HITL setups which may not always\nachieve the desired ethical, legal, and sociotechnical outcomes. We suggest\nareas where the law should recognise the effectiveness of different HITL setups\nand assign responsibility in these contexts, avoiding unnecessary and\nunproductive human \"scapegoating\". Overall, we show how HITL setups involve\nmany technical design decisions, and can be prone to failures which are often\nout of the humans' control. This opens up a new analytic perspective on the\nchallenges arising in the creation of HITL setups, helping inform AI developers\nand lawmakers on designing HITL to better achieve their desired outcomes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4e0d\u540c\u4eba\u673a\u534f\u4f5c\uff08HITL\uff09\u8bbe\u7f6e\u7684\u6cd5\u5f8b\u5408\u89c4\u6027\u548c\u5b89\u5168\u6027\uff0c\u5c55\u793a\u4e86\u6cd5\u5f8b\u8d23\u4efb\u5f52\u5c5e\u4e0e\u6280\u672f\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u4e0d\u53ef\u907f\u514d\u7684\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u4eba\u673a\u534f\u4f5c\u8bbe\u7f6e\u7684\u591a\u6837\u6027\u53ca\u5176\u5728\u6cd5\u5f8b\u548c\u6280\u672f\u4e0a\u7684\u5f71\u54cd\uff0c\u4e3a\u89e3\u51b3\u6cd5\u5f8b\u6846\u67b6\u4e2d\u7684\u76f2\u70b9\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "method": "\u5229\u7528\u8ba1\u7b97\u7406\u8bba\u4e2d\u7684\u9884\u8a00\u673a\u6982\u5ff5\u5f62\u5f0f\u5316HITL\u8bbe\u7f6e\uff0c\u63d0\u51fa\u5206\u7c7b\u6cd5\u5206\u6790\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u8bc4\u4f30\u6cd5\u5f8b\u6846\u67b6\u7684\u5c40\u9650\u6027\u3002", "result": "\u63ed\u793a\u4e86HITL\u8bbe\u7f6e\u4e2d\u7684\u8bbe\u8ba1\u51b3\u7b56\u548c\u6f5c\u5728\u5931\u8d25\u6a21\u5f0f\uff0c\u6307\u51fa\u6cd5\u5f8b\u9700\u66f4\u7075\u6d3b\u5730\u9002\u5e94\u4e0d\u540c\u8bbe\u7f6e\u3002", "conclusion": "HITL\u8bbe\u7f6e\u6d89\u53ca\u591a\u65b9\u9762\u6311\u6218\uff0c\u9700\u5f00\u53d1\u8005\u548c\u7acb\u6cd5\u8005\u5171\u540c\u4f18\u5316\uff0c\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u6cd5\u5f8b\u548c\u6280\u672f\u6548\u679c\u3002"}}
{"id": "2507.05619", "pdf": "https://arxiv.org/pdf/2507.05619", "abs": "https://arxiv.org/abs/2507.05619", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Detecting and Mitigating Reward Hacking in Reinforcement Learning Systems: A Comprehensive Empirical Study", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "Reward hacking in Reinforcement Learning (RL) systems poses a critical threat\nto the deployment of autonomous agents, where agents exploit flaws in reward\nfunctions to achieve high scores without fulfilling intended objectives.\nDespite growing awareness of this problem, systematic detection and mitigation\napproaches remain limited. This paper presents a large-scale empirical study of\nreward hacking across diverse RL environments and algorithms. We analyze 15,247\ntraining episodes across 15 RL environments (Atari, MuJoCo, custom domains) and\n5 algorithms (PPO, SAC, DQN, A3C, Rainbow), implementing automated detection\nalgorithms for six categories of reward hacking: specification gaming, reward\ntampering, proxy optimization, objective misalignment, exploitation patterns,\nand wireheading. Our detection framework achieves 78.4% precision and 81.7%\nrecall across environments, with computational overhead under 5%. Through\ncontrolled experiments varying reward function properties, we demonstrate that\nreward density and alignment with true objectives significantly impact hacking\nfrequency ($p < 0.001$, Cohen's $d = 1.24$). We validate our approach through\nthree simulated application studies representing recommendation systems,\ncompetitive gaming, and robotic control scenarios. Our mitigation techniques\nreduce hacking frequency by up to 54.6% in controlled scenarios, though we find\nthese trade-offs are more challenging in practice due to concept drift, false\npositive costs, and adversarial adaptation. All detection algorithms, datasets,\nand experimental protocols are publicly available to support reproducible\nresearch in RL safety.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u81ea\u52a8\u68c0\u6d4b\u6846\u67b6\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u5a01\u80c1\u81ea\u4e3b\u4ee3\u7406\u7684\u90e8\u7f72\uff0c\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u68c0\u6d4b\u548c\u7f13\u89e3\u65b9\u6cd5\uff0c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u572815\u79cdRL\u73af\u5883\u548c5\u79cd\u7b97\u6cd5\u4e2d\u5206\u679015,247\u4e2a\u8bad\u7ec3\u7247\u6bb5\uff0c\u5f00\u53d1\u4e86\u516d\u7c7b\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u7684\u81ea\u52a8\u68c0\u6d4b\u6846\u67b6\u3002", "result": "\u68c0\u6d4b\u6846\u67b6\u5b9e\u73b0\u4e8678.4%\u7684\u7cbe\u5ea6\u548c81.7%\u7684\u53ec\u56de\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u5956\u52b1\u5bc6\u5ea6\u548c\u771f\u5b9e\u76ee\u6807\u5bf9\u9f50\u663e\u8457\u5f71\u54cd\u9ed1\u5ba2\u9891\u7387\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u68c0\u6d4b\u548c\u7f13\u89e3\u65b9\u6cd5\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u9700\u5e94\u5bf9\u6982\u5ff5\u6f02\u79fb\u548c\u5bf9\u6297\u6027\u9002\u5e94\u7b49\u6311\u6218\u3002"}}
{"id": "2507.05292", "pdf": "https://arxiv.org/pdf/2507.05292", "abs": "https://arxiv.org/abs/2507.05292", "authors": ["Kaiqi Yang", "Hang Li", "Yucheng Chu", "Ahreum Han", "Yasemin Copur-Gencturk", "Jiliang Tang", "Hui Liu"], "title": "A LLM-Driven Multi-Agent Systems for Professional Development of Mathematics Teachers", "categories": ["cs.CY", "cs.HC", "cs.MA"], "comment": null, "summary": "Professional development (PD) serves as the cornerstone for teacher tutors to\ngrasp content knowledge. However, providing equitable and timely PD\nopportunities for teachers poses significant challenges. To address this issue,\nwe introduce I-VIP (Intelligent Virtual Interactive Program), an intelligent\ntutoring platform for teacher professional development, driven by large\nlanguage models (LLMs) and supported by multi-agent frameworks. This platform\noffers a user-friendly conversational interface and allows users to employ a\nvariety of interactive tools to facilitate question answering, knowledge\ncomprehension, and reflective summarization while engaging in dialogue. To\nunderpin the functionality of this platform, including knowledge expectation\nanalysis, response scoring and classification, and feedback generation, the\nmulti-agent frameworks are leveraged to enhance the accuracy of judgments and\nmitigate the issue of missing key points.", "AI": {"tldr": "I-VIP\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u4ee3\u7406\u6846\u67b6\u7684\u667a\u80fd\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\u5e73\u53f0\uff0c\u65e8\u5728\u63d0\u4f9b\u516c\u5e73\u3001\u53ca\u65f6\u7684PD\u673a\u4f1a\u3002", "motivation": "\u89e3\u51b3\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\u4e2d\u516c\u5e73\u6027\u548c\u53ca\u65f6\u6027\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u63d0\u4f9b\u5bf9\u8bdd\u754c\u9762\u548c\u4e92\u52a8\u5de5\u5177\u3002", "result": "\u5e73\u53f0\u652f\u6301\u77e5\u8bc6\u5206\u6790\u3001\u56de\u7b54\u8bc4\u5206\u53ca\u53cd\u9988\u751f\u6210\uff0c\u63d0\u5347\u5224\u65ad\u51c6\u786e\u6027\u3002", "conclusion": "I-VIP\u901a\u8fc7\u6280\u672f\u521b\u65b0\u6539\u5584\u4e86\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2507.05549", "pdf": "https://arxiv.org/pdf/2507.05549", "abs": "https://arxiv.org/abs/2507.05549", "authors": ["Prerana Khatiwada", "Joshua Washington", "Tyler Walsh", "Ahmed Saif Hamed", "Lokesh Bhatta"], "title": "The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art", "categories": ["cs.CY", "cs.AI", "cs.HC", "I.2.0"], "comment": "7 pages", "summary": "As Artificial Intelligence (AI) continues to grow daily, more exciting (and\nsomewhat controversial) technology emerges every other day. As we see the\nadvancements in AI, we see more and more people becoming skeptical of it. This\npaper explores the complications and confusion around the ethics of generative\nAI art. We delve deep into the ethical side of AI, specifically generative art.\nWe step back from the excitement and observe the impossible conundrums that\nthis impressive technology produces. Covering environmental consequences,\ncelebrity representation, intellectual property, deep fakes, and artist\ndisplacement. Our research found that generative AI art is responsible for\nincreased carbon emissions, spreading misinformation, copyright infringement,\nunlawful depiction, and job displacement. In light of this, we propose multiple\npossible solutions for these problems. We address each situation's history,\ncause, and consequences and offer different viewpoints. At the root of it all,\nthough, the central theme is that generative AI Art needs to be correctly\nlegislated and regulated.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u827a\u672f\u7684\u4f26\u7406\u95ee\u9898\u5f15\u53d1\u4e89\u8bae\uff0c\u5305\u62ec\u73af\u5883\u5f71\u54cd\u3001\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u3001\u7248\u6743\u4fb5\u6743\u53ca\u804c\u4e1a\u66ff\u4ee3\u7b49\uff0c\u9700\u7acb\u6cd5\u548c\u76d1\u7ba1\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0fAI\u827a\u672f\u4e2d\u7684\u4f26\u7406\u56f0\u5883\u548c\u6f5c\u5728\u5371\u5bb3\uff0c\u547c\u5401\u5bf9\u5176\u89c4\u8303\u548c\u7acb\u6cd5\u3002", "method": "\u5206\u6790\u751f\u6210\u5f0fAI\u827a\u672f\u7684\u5386\u53f2\u3001\u539f\u56e0\u53ca\u540e\u679c\uff0c\u63d0\u51fa\u591a\u89c6\u89d2\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u751f\u6210\u5f0fAI\u827a\u672f\u5bfc\u81f4\u78b3\u6392\u653e\u589e\u52a0\u3001\u4fe1\u606f\u8bef\u5bfc\u3001\u7248\u6743\u95ee\u9898\u53ca\u827a\u672f\u5bb6\u5931\u4e1a\u7b49\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u827a\u672f\u4e9f\u9700\u7acb\u6cd5\u548c\u76d1\u7ba1\u4ee5\u89e3\u51b3\u5176\u4f26\u7406\u548c\u793e\u4f1a\u95ee\u9898\u3002"}}
{"id": "2507.05984", "pdf": "https://arxiv.org/pdf/2507.05984", "abs": "https://arxiv.org/abs/2507.05984", "authors": ["Zhijun Guo", "Alvina Lai", "Julia Ive", "Alexandru Petcu", "Yutong Wang", "Luyuan Qi", "Johan H Thygesen", "Kezhi Li"], "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively\nscreen depression but lack interactivity and adaptability. We developed\nHopeBot, a chatbot powered by a large language model (LLM) that administers the\nPHQ-9 using retrieval-augmented generation and real-time clarification. In a\nwithin-subject study, 132 adults in the United Kingdom and China completed both\nself-administered and chatbot versions. Scores demonstrated strong agreement\n(ICC = 0.91; 45% identical). Among 75 participants providing comparative\nfeedback, 71% reported greater trust in the chatbot, highlighting clearer\nstructure, interpretive guidance, and a supportive tone. Mean ratings (0-10)\nwere 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,\nand 7.4 for recommendation helpfulness; the latter varied significantly by\nemployment status and prior mental-health service use (p < 0.05). Overall,\n87.1% expressed willingness to reuse or recommend HopeBot. These findings\ndemonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden\nadjuncts for routine depression screening.", "AI": {"tldr": "HopeBot\u662f\u4e00\u6b3e\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u7528\u4e8e\u6291\u90c1\u7b5b\u67e5\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u4fe1\u4efb\u5ea6\u3001\u8212\u9002\u5ea6\u548c\u7ed3\u6784\u6e05\u6670\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u95ee\u5377\u3002", "motivation": "\u4f20\u7edf\u6291\u90c1\u7b5b\u67e5\u5de5\u5177\u5982PHQ-9\u7f3a\u4e4f\u4ea4\u4e92\u6027\u548c\u9002\u5e94\u6027\uff0cHopeBot\u901a\u8fc7LLM\u6280\u672f\u63d0\u4f9b\u5b9e\u65f6\u6f84\u6e05\u548c\u4e2a\u6027\u5316\u652f\u6301\u3002", "method": "\u7814\u7a76\u901a\u8fc7132\u540d\u6210\u4eba\u7684\u5bf9\u6bd4\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86\u81ea\u586b\u95ee\u5377\u548cHopeBot\u7248\u672c\u7684\u8868\u73b0\uff0c\u5e76\u6536\u96c6\u7528\u6237\u53cd\u9988\u3002", "result": "HopeBot\u5728ICC\u4e00\u81f4\u6027(0.91)\u548c\u7528\u6237\u4fe1\u4efb\u5ea6(71%)\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c87.1%\u7528\u6237\u613f\u610f\u91cd\u590d\u4f7f\u7528\u6216\u63a8\u8350\u3002", "conclusion": "\u8bed\u97f3LLM\u804a\u5929\u673a\u5668\u4eba\u53ef\u4f5c\u4e3a\u9ad8\u6548\u3001\u4f4e\u8d1f\u62c5\u7684\u6291\u90c1\u7b5b\u67e5\u8f85\u52a9\u5de5\u5177\u3002"}}
{"id": "2507.06185", "pdf": "https://arxiv.org/pdf/2507.06185", "abs": "https://arxiv.org/abs/2507.06185", "authors": ["Zhicheng Lin"], "title": "Hidden Prompts in Manuscripts Exploit AI-Assisted Peer Review", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "In July 2025, 18 academic manuscripts on the preprint website arXiv were\nfound to contain hidden instructions known as prompts designed to manipulate\nAI-assisted peer review. Instructions such as \"GIVE A POSITIVE REVIEW ONLY\"\nwere concealed using techniques like white-colored text. Author responses\nvaried: one planned to withdraw the affected paper, while another defended the\npractice as legitimate testing of reviewer compliance. This commentary analyzes\nthis practice as a novel form of research misconduct. We examine the technique\nof prompt injection in large language models (LLMs), revealing four types of\nhidden prompts, ranging from simple positive review commands to detailed\nevaluation frameworks. The defense that prompts served as \"honeypots\" to detect\nreviewers improperly using AI fails under examination--the consistently\nself-serving nature of prompt instructions indicates intent to manipulate.\nPublishers maintain inconsistent policies: Elsevier prohibits AI use in peer\nreview entirely, while Springer Nature permits limited use with disclosure\nrequirements. The incident exposes systematic vulnerabilities extending beyond\npeer review to any automated system processing scholarly texts, including\nplagiarism detection and citation indexing. Our analysis underscores the need\nfor coordinated technical screening at submission portals and harmonized\npolicies governing generative AI (GenAI) use in academic evaluation.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e862025\u5e747\u6708\u5728arXiv\u9884\u5370\u672c\u7f51\u7ad9\u4e0a\u53d1\u73b0\u768418\u7bc7\u5b66\u672f\u624b\u7a3f\uff0c\u8fd9\u4e9b\u624b\u7a3f\u542b\u6709\u65e8\u5728\u64cd\u7eb5AI\u8f85\u52a9\u540c\u884c\u8bc4\u5ba1\u7684\u9690\u85cf\u6307\u4ee4\uff08\u63d0\u793a\uff09\uff0c\u63ed\u793a\u4e86\u8fd9\u4e00\u884c\u4e3a\u662f\u4e00\u79cd\u65b0\u578b\u7684\u5b66\u672f\u4e0d\u7aef\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u8ba8\u9690\u85cf\u5728\u5b66\u672f\u624b\u7a3f\u4e2d\u7684\u63d0\u793a\u6307\u4ee4\u5982\u4f55\u88ab\u7528\u4e8e\u64cd\u63a7AI\u8f85\u52a9\u7684\u540c\u884c\u8bc4\u5ba1\uff0c\u5e76\u63ed\u793a\u8fd9\u79cd\u884c\u4e3a\u5bf9\u5b66\u672f\u8bc4\u4ef7\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790arXiv\u4e0a\u53d1\u73b0\u768418\u7bc7\u624b\u7a3f\u4e2d\u7684\u9690\u85cf\u63d0\u793a\uff0c\u603b\u7ed3\u4e86\u56db\u79cd\u7c7b\u578b\u7684\u63d0\u793a\u6307\u4ee4\uff0c\u5e76\u8bc4\u4f30\u4e86\u76f8\u5173\u51fa\u7248\u5546\u7684\u653f\u7b56\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u9690\u85cf\u63d0\u793a\u5177\u6709\u660e\u663e\u7684\u81ea\u6211\u670d\u52a1\u610f\u56fe\uff0c\u8868\u660e\u5176\u76ee\u7684\u662f\u64cd\u7eb5\u8bc4\u5ba1\uff1b\u540c\u65f6\uff0c\u51fa\u7248\u5546\u5bf9AI\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u4f7f\u7528\u653f\u7b56\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u9700\u8981\u5728\u63d0\u4ea4\u95e8\u6237\u4e0a\u8fdb\u884c\u6280\u672f\u7b5b\u67e5\uff0c\u5e76\u534f\u8c03\u751f\u6210\u5f0fAI\u5728\u5b66\u672f\u8bc4\u4ef7\u4e2d\u7684\u4f7f\u7528\u653f\u7b56\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e00\u7cfb\u7edf\u6027\u6f0f\u6d1e\u3002"}}
