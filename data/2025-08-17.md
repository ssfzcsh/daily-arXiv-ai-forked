<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 6]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.HC](#cs.HC) [Total: 17]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.AR](#cs.AR) [Total: 3]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.CV](#cs.CV) [Total: 4]
- [math.FA](#math.FA) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CL](#cs.CL) [Total: 3]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [quant-ph](#quant-ph) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [FormalGrad: Integrating Formal Methods with Gradient-Based LLM Refinement](https://arxiv.org/abs/2508.10059)
*Yueke Zhang,Yifan Zhang,Kevin Leach,Yu Huang*

Main category: cs.SE

TL;DR: FormalGrad通过将形式化方法集成到基于LLM的迭代代码生成循环中，解决了LLM生成代码在正确性、鲁棒性和效率上的不足，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成的代码在严格约束领域中缺乏正确性、鲁棒性和效率保证的问题。

Method: 引入FormalGrad框架，将代码视为可微分变量，通过形式化约束和结构化反馈生成文本伪梯度，指导模型迭代优化解决方案。

Result: 在HumanEval、HumanEval+和LiveCodeBench基准测试中表现优异，绝对性能提升达27%，相对提升41%。

Conclusion: FormalGrad能够生成形式化证明的、鲁棒且高效的代码，为高风险应用中的可靠AI辅助软件开发铺平了道路。

Abstract: While Large Language Models (LLMs) have demonstrated remarkable capabilities
in code generation, they often produce solutions that lack guarantees of
correctness, robustness, and efficiency. The limitation is acute in domains
requiring strict constraints. FormalGrad introduces a principled framework that
integrates formal methods directly into an iterative LLM-based generation loop.
It uniquely treats code as a differentiable variable, converting structured
feedback and formal constraints into a textual pseudo-gradient. This gradient
guides the model to iteratively refine solutions, ensuring they are not only
functional but also robust and formally justified. We evaluate FormalGrad on
the HumanEval, HumanEval+, and LiveCodeBench benchmarks. Our implementation
outperforms strong baselines, achieving an absolute improvement of up to 27% on
HumanEval and a 41% relative improvement on the challenging LiveCodeBench V6.
FormalGrad generates formally justified code that is robust and efficient,
paving the way for reliable AI-assisted software development in high-stakes
applications.

</details>


### [2] [SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion](https://arxiv.org/abs/2508.10068)
*Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen*

Main category: cs.SE

TL;DR: Saracoder是一种基于层次特征优化的检索框架，通过深度学习语义关系、去重、结构相似性评估和多样性重排序，解决了代码补全中的语义误导和冗余问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统代码补全中因文本相似性导致的语义误导、冗余和同质化，以及外部符号歧义的问题。

Method: 引入Hierarchical Feature Optimization模块深度学习语义关系、去重、图结构相似性评估和重排序，并采用External-Aware Identifier Disambiguator模块解析跨文件符号歧义。

Result: 在CrossCodeEval和RepoEval-Updated基准测试中显著优于现有方法，支持多语言和多模型。

Conclusion: 系统优化检索结果可为构建更准确、稳健的代码补全系统提供新范式。

Abstract: Retrieval-augmented generation (RAG) for repository-level code completion
commonly relies on superficial text similarity, leading to results plagued by
semantic misguidance, redundancy, and homogeneity, while also failing to
resolve external symbol ambiguity. To address these challenges, we introduce
Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core
Hierarchical Feature Optimization module systematically refines candidates by
distilling deep semantic relationships, pruning exact duplicates, assessing
structural similarity with a novel graph-based metric that weighs edits by
their topological importance, and reranking results to maximize both relevance
and diversity. Furthermore, an External-Aware Identifier Disambiguator module
accurately resolves cross-file symbol ambiguity via dependency analysis.
Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated
benchmarks demonstrate that Saracoder significantly outperforms existing
baselines across multiple programming languages and models. Our work proves
that systematically refining retrieval results across multiple dimensions
provides a new paradigm for building more accurate and robust repository-level
code completion systems.

</details>


### [3] [Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History](https://arxiv.org/abs/2508.10074)
*Ruofan Lu,Yintong Huo,Meng Zhang,Yichen Li,Michael R. Lyu*

Main category: cs.SE

TL;DR: 论文提出了Next Edit Prediction任务，旨在通过开发者的交互历史预测下一个编辑动作的位置和内容，以改善AI代码助手的用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有的代码完成和聊天式编辑方式无法主动预测开发者的连续编辑意图，导致用户体验不佳，因此需要新的方法。

Method: 作者构建了一个高质量的监督微调数据集和评估基准，并对一系列模型进行了监督微调。

Result: 通过全面的评估，作者发现了一些新的结论，为未来的交互模式奠定了基础。

Conclusion: 这项研究为一种新的交互模式奠定了基础，可以主动预测开发者的动作，而不仅仅是响应明确的指令。

Abstract: The rapid advancement of large language models (LLMs) has led to the
widespread adoption of AI-powered coding assistants integrated into a
development environment. On one hand, low-latency code completion offers
completion suggestions but is fundamentally constrained to the cursor's current
position. On the other hand, chat-based editing can perform complex
modifications, yet forces developers to stop their work, describe the intent in
natural language, which causes a context-switch away from the code. This
creates a suboptimal user experience, as neither paradigm proactively predicts
the developer's next edit in a sequence of related edits. To bridge this gap
and provide the seamless code edit suggestion, we introduce the task of Next
Edit Prediction, a novel task designed to infer developer intent from recent
interaction history to predict both the location and content of the subsequent
edit. Specifically, we curate a high-quality supervised fine-tuning dataset and
an evaluation benchmark for the Next Edit Prediction task. Then, we conduct
supervised fine-tuning on a series of models and performed a comprehensive
evaluation of both the fine-tuned models and other baseline models, yielding
several novel findings. This work lays the foundation for a new interaction
paradigm that proactively collaborate with developers by anticipating their
following action, rather than merely reacting to explicit instructions.

</details>


### [4] [On the synchronization between Hugging Face pre-trained language models and their upstream GitHub repository](https://arxiv.org/abs/2508.10157)
*Ajibode Adekunle,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 预训练语言模型（PTLM）在自然语言处理（NLP）中取得进展，但跨平台开发（如GitHub和Hugging Face）的协调问题导致版本不一致和同步困难，研究发现八种同步模式并揭示了结构性问题。


<details>
  <summary>Details</summary>
Motivation: 研究PTLM在GitHub和Hugging Face上的跨平台开发协调问题，以解决版本不一致、同步困难及由此带来的用户风险。

Method: 通过混合方法研究325个PTLM家族（904个Hugging Face变体），分析提交活动的协调方式及同步模式。

Result: 发现八种同步模式，部分同步模式（如分散同步和稀疏同步）揭示跨平台发布实践中的结构性脱节，导致改进或修复未能跨平台复制。

Conclusion: 识别这些同步模式对改进PTLM发布流程的监督和可追溯性至关重要。

Abstract: Pretrained language models (PTLMs) have advanced natural language processing
(NLP), enabling progress in tasks like text generation and translation. Like
software package management, PTLMs are trained using code and environment
scripts in upstream repositories (e.g., GitHub, GH) and distributed as variants
via downstream platforms like Hugging Face (HF). Coordinating development
between GH and HF poses challenges such as misaligned release timelines,
inconsistent versioning, and limited reuse of PTLM variants. We conducted a
mixed-method study of 325 PTLM families (904 HF variants) to examine how commit
activities are coordinated. Our analysis reveals that GH contributors typically
make changes related to specifying the version of the model, improving code
quality, performance optimization, and dependency management within the
training scripts, while HF contributors make changes related to improving model
descriptions, data set handling, and setup required for model inference.
Furthermore, to understand the synchronization aspects of commit activities
between GH and HF, we examined three dimensions of these activities -- lag
(delay), type of synchronization, and intensity -- which together yielded eight
distinct synchronization patterns. The prevalence of partially synchronized
patterns, such as Disperse synchronization and Sparse synchronization, reveals
structural disconnects in current cross-platform release practices. These
patterns often result in isolated changes -- where improvements or fixes made
on one platform are never replicated on the other -- and in some cases,
indicate an abandonment of one repository in favor of the other. Such
fragmentation risks exposing end users to incomplete, outdated, or behaviorally
inconsistent models. Hence, recognizing these synchronization patterns is
critical for improving oversight and traceability in PTLM release workflows.

</details>


### [5] [Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution](https://arxiv.org/abs/2508.10517)
*Likai Ye,Mengliang Li,Dehai Zhao,Jiamou Sun,Xiaoxue Ren*

Main category: cs.SE

TL;DR: 论文研究了Solidity版本演化中的编译错误问题，并评估了大型语言模型（LLMs）在解决这些错误中的表现，提出了一个结合专家知识和LLM的新框架SMCFIXER。


<details>
  <summary>Details</summary>
Motivation: Solidity的频繁版本更新带来了编译错误、代码迁移和维护的挑战，需研究如何有效解决这些问题以提高智能合约的可靠性。

Method: 通过实证研究分析Solidity版本演化中的错误问题，系统评估LLMs的修复能力，并提出结合专家知识检索和LLM的框架SMCFIXER。

Result: 研究发现81.68%的合约在不同版本中遇到编译错误，LLMs在语义级问题上效果有限，但SMCFIXER显著提升了修复准确率，达到96.97%。

Conclusion: SMCFIXER通过结合专家知识和LLM机制，有效解决了Solidity版本迁移中的编译错误问题，为智能合约的可靠性提供了新方法。

Abstract: Solidity, the dominant smart contract language for Ethereum, has rapidly
evolved with frequent version updates to enhance security, functionality, and
developer experience. However, these continual changes introduce significant
challenges, particularly in compilation errors, code migration, and
maintenance. Therefore, we conduct an empirical study to investigate the
challenges in the Solidity version evolution and reveal that 81.68% of examined
contracts encounter errors when compiled across different versions, with 86.92%
of compilation errors.
  To mitigate these challenges, we conducted a systematic evaluation of large
language models (LLMs) for resolving Solidity compilation errors during version
migrations. Our empirical analysis across both open-source (LLaMA3, DeepSeek)
and closed-source (GPT-4o, GPT-3.5-turbo) LLMs reveals that although these
models exhibit error repair capabilities, their effectiveness diminishes
significantly for semantic-level issues and shows strong dependency on prompt
engineering strategies. This underscores the critical need for domain-specific
adaptation in developing reliable LLM-based repair systems for smart contracts.
  Building upon these insights, we introduce SMCFIXER, a novel framework that
systematically integrates expert knowledge retrieval with LLM-based repair
mechanisms for Solidity compilation error resolution. The architecture
comprises three core phases: (1) context-aware code slicing that extracts
relevant error information; (2) expert knowledge retrieval from official
documentation; and (3) iterative patch generation for Solidity migration.
Experimental validation across Solidity version migrations demonstrates our
approach's statistically significant 24.24% improvement over baseline GPT-4o on
real-world datasets, achieving near-perfect 96.97% accuracy.

</details>


### [6] [EVOSCAT: Exploring Software Change Dynamics in Large-Scale Historical Datasets](https://arxiv.org/abs/2508.10852)
*Souhaila Serbout,Diana Carolina Muñoz Hurtado,Hassan Atwi,Edoardo Riggio,Cesare Pautasso*

Main category: cs.SE

TL;DR: EvoScat是一个工具，通过交互式密度散点图，帮助研究者可视化大规模历史数据集，支持软件项目的演进分析。


<details>
  <summary>Details</summary>
Motivation: 长期软件项目包含大量历史变更，传统方法难以高效分析大规模数据集。

Method: 使用交互式密度散点图，支持时间轴配置、排序和颜色映射，以可视化百万级事件。

Result: EvoScat展示了在多个场景（如变更速度比较、克隆检测）中的有效性和灵活性。

Conclusion: 该工具为研究者提供了高效分析和比较软件演进数据的新方法。

Abstract: Long lived software projects encompass a large number of artifacts, which
undergo many revisions throughout their history. Empirical software engineering
researchers studying software evolution gather and collect datasets with
millions of events, representing changes introduced to specific artifacts. In
this paper, we propose EvoScat, a tool that attempts addressing temporal
scalability through the usage of interactive density scatterplot to provide a
global overview of large historical datasets mined from open source
repositories in a single visualization. EvoScat intents to provide researchers
with a mean to produce scalable visualizations that can help them explore and
characterize evolution datasets, as well as comparing the histories of
individual artifacts, both in terms of 1) observing how rapidly different
artifacts age over multiple-year-long time spans 2) how often metrics
associated with each artifacts tend towards an improvement or worsening. The
paper shows how the tool can be tailored to specific analysis needs (pace of
change comparison, clone detection, freshness assessment) thanks to its support
for flexible configuration of history scaling and alignment along the time
axis, artifacts sorting and interactive color mapping, enabling the analysis of
millions of events obtained by mining the histories of tens of thousands of
software artifacts. We include in this paper a gallery showcasing datasets
gathering specific artifacts (OpenAPI descriptions, GitHub workflow
definitions) across multiple repositories, as well as diving into the history
of specific popular open source projects.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Generating Compilers for Qubit Mapping and Routing](https://arxiv.org/abs/2508.10781)
*Abtin Molavi,Amanda Xu,Ethan Cecchetti,Swamit Tannu,Aws Albarghouthi*

Main category: cs.PL

TL;DR: 本文提出了一种自动生成适用于任意量子架构的量子比特映射和路由（QMR）编译器的方法，通过Marol语言简化了QMR问题的定义，并展示了其解决方案的竞争力。


<details>
  <summary>Details</summary>
Motivation: 量子计算机的潜力依赖于编译器的优化，而QMR是关键步骤。但由于量子架构的多样性和快速演变，手工编写编译器复杂且耗时。

Method: 作者识别了QMR问题的共同核心结构（设备状态机），并基于此开发了一门领域特定语言Marol，用于定义QMR问题，并通过参数化求解器解决。

Result: 通过案例研究证明，自动生成的编译器在运行时间和解决方案质量上与手工编写的专业编译器相当。

Conclusion: 该方法简化了未来量子编译器的开发，适应不断涌现的新量子架构。

Abstract: Quantum computers promise to solve important problems faster than classical
computers, potentially unlocking breakthroughs in materials science, chemistry,
and beyond. Optimizing compilers are key to realizing this potential, as they
minimize expensive resource usage and limit error rates. A critical compilation
step is qubit mapping and routing (QMR), which finds mappings from circuit
qubits to qubits on a target device and plans instruction execution while
satisfying the device's connectivity constraints. The challenge is that the
landscape of quantum architectures is incredibly diverse and fast-evolving.
Given this diversity, hundreds of papers have addressed the QMR problem for
different qubit hardware, connectivity constraints, and quantum error
correction schemes.
  We present an approach for automatically generating qubit mapping and routing
compilers for arbitrary quantum architectures. Though each QMR problem is
different, we identify a common core structure-device state machine-that we use
to formulate an abstract QMR problem. Our formulation naturally leads to a
domain-specific language, Marol, for specifying QMR problems-for example, the
well-studied NISQ mapping and routing problem requires only 12 lines of Marol.
We demonstrate that QMR problems, defined in Marol, can be solved with a
powerful parametric solver that can be instantiated for any Marol program. We
evaluate our approach through case studies of important QMR problems from prior
and recent work, covering noisy and fault-tolerant quantum architectures on all
major hardware platforms. Our thorough evaluation shows that generated
compilers are competitive with handwritten, specialized compilers in terms of
runtime and solution quality. We envision that our approach will simplify
development of future quantum compilers as new quantum architectures continue
to emerge.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [8] [Meta-Metrics and Best Practices for System-Level Inference Performance Benchmarking](https://arxiv.org/abs/2508.10251)
*Shweta Salaria,Zhuoran Liu,Nelson Mimura Gonzalez*

Main category: cs.PF

TL;DR: 论文介绍了FMwork方法，用于高效评估基础模型的推理性能，通过元指标、参数选择和成本性能分析，显著提高了实验效率。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型的推理性能面临实验配置复杂且资源消耗大的问题，因此需要一种高效的方法来优化测试流程。

Method: FMwork框架包括元指标、参数选择和战略成本性能评估，通过优化实验设计和减少不必要测试，提高效率。

Result: 实验显示，FMwork能实现最高24倍的效率提升，并在保持高准确率的同时减少资源消耗。

Conclusion: FMwork为评估基础模型性能提供了一种高效且准确的方法，显著优化了实验流程和资源利用。

Abstract: Benchmarking inference performance (speed) of Foundation Models such as Large
Language Models (LLM) involves navigating a vast experimental landscape to
understand the complex interactions between hardware and software components.
However, evaluating every possible test configuration is impractical,
unfeasible and unnecessary. To address this challenge, we introduce FMwork, a
comprehensive and methodical approach to creating a controlled testing
environment that accurately reflects and characterizes performance. FMwork
comprises a set of benchmkaring best practices with three key components: 1)
meta-metrics, 2) parameter selection, and 3) strategic cost-performance
evaluation. Meta-metrics account for time and resources spent on benchmarking
and the relative accuracy of the results compared to a larger body of
measurements, representing the complete experimental space. FMwork
operationalizes the meta-metrics and provides efficient strategies for
parameter selection and cost-performance analysis. Using the framework, we show
up to 24x improvement (speedup and/or resource savings) running sweeps of
experiments compared to the ground truth. Even already considering a subset of
experiments as reference point (using the power of two for batch sizes),
reducing experimental output size from 1024 to 128 tokens yields another 2.7x
gain while keeping 96.6% accuracy for an evaluation using Llama 3.1 8B model.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [9] [Rethinking Reliability Using Network Coding: a Practical 5G Evaluation](https://arxiv.org/abs/2508.10247)
*Laura Landon,Vipindev Adat Vasudevan,Junmo Sung,Muriel Médard*

Main category: cs.NI

TL;DR: 在5G测试平台的IP层中集成实时网络编码系统，替代传统基于重传的可靠性机制（如ARQ/HARQ），通过RLNC实现前向纠错，验证其在吞吐量、抖动和资源使用上的优势。


<details>
  <summary>Details</summary>
Motivation: 探索网络编码在无线系统中替代传统重传机制的潜力，以提高资源利用效率和可靠性。

Method: 采用基于netfilter的数据包拦截框架，在gNB与UE之间的实时流量中注入RLNC的块编码方案，分析其对吞吐量、抖动和资源使用的影响。

Result: 实验表明，RLNC在适度至高丢包率下能以更少的传输次数完全恢复丢包，并保持高吞吐量。

Conclusion: 网络编码未来可有效替代基于重传的可靠性机制，有望提升无线系统的资源利用率。

Abstract: This work presents the design and implementation of a real-time network
coding system integrated into the IP layer of a 5G testbed, offering an
alternative to conventional retransmission-based reliability mechanisms such as
ARQ and HARQ. Using a netfilter-based packet interception framework, we inject
forward erasure correction using Random Linear Network Coding (RLNC) into live
traffic between a gNB and UE over a 3GPP RF link. We evaluate a block coding
scheme, analyzing its impact on throughput, jitter, and resource usage. Results
show that with appropriate code rate selection, RLNC can fully recover from
packet losses using fewer transmissions than ARQ/HARQ and maintain a high
throughput, particularly under moderate-to-high packet loss rates. These
findings demonstrate that network coding can effectively replace
retransmission-based reliability in future wireless systems, with the potential
for more efficient resource utilization.

</details>


### [10] [Design of a Timer Queue Supporting Dynamic Update Operations](https://arxiv.org/abs/2508.10283)
*Zekun Wang,Binghao Yue,Weitao Pan,Jiangyi Shi,Yue Hao*

Main category: cs.NI

TL;DR: 提出了一种基于脉动阵列和移位寄存器的混合架构硬件优先级队列，用于高效管理计时器队列，支持五种操作，并在FPGA上实现高性能和低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大规模计时器在网络处理中广泛使用，但传统实现存在计时精度低和计算开销高的问题。

Method: 设计了一种混合架构硬件优先级队列，结合脉动阵列和移位寄存器的优势，支持五种操作，并通过集中式布尔逻辑编码高效生成控制信号。

Result: 实验结果显示，该设计在FPGA上运行频率超过400 MHz，资源消耗比现有最优实现减少了2.2-2.8倍。

Conclusion: 该设计首次实现了队列内优先级更新，并在性能和资源效率上显著优于现有方案。

Abstract: Large-scale timers are ubiquitous in network processing, including flow table
entry expiration control in software defined network (SDN) switches, MAC
address aging in Ethernet bridges, and retransmission timeout management in
TCP/IP protocols. Conventional implementations suffer from critical
limitations: low timing accuracy due to large-scale timer traversal and high
computational overhead for new timer insertion. This paper presents a
hybrid-architecture hardware priority queue based on systolic arrays and shift
registers for efficient timer queue management. The design uniquely supports
five operations: enqueue, dequeue, delete, update, and peek.To the best of our
knowledge, it is the first hardware priority queue enabling in-queue priority
updates. By leveraging centralized Boolean logic encoding within systolic
blocks, the design efficiently generates set/shift control signals while the
novel push-first operation ensures FIFO ordering for same-priority timers
without additional metadata. Experimental results demonstrate that the design
operates at over 400 MHz on FPGAs, achieving a 2.2-2.8x reduction in resource
consumption compared to state-of-the-art implementations.

</details>


### [11] [Near-realtime Earth Observation Via Starlink LEO Satellite Constellation](https://arxiv.org/abs/2508.10338)
*Bo Wu,Pengfei Zhou*

Main category: cs.NI

TL;DR: 该论文提出了一种名为“Starlink Space User”（SSU）的新系统，利用Starlink卫星基础设施为地球观测卫星提供高效数据中继服务，显著减少了数据积压问题。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星的数据下载因地面站数量有限和通信窗口短暂而面临挑战，而Starlink等新兴LEO星座提供了持续连接的可能性，为解决这一问题提供了新思路。

Method: 论文设计了SSU系统，将地球观测卫星视为Starlink的“太空用户”，开发了链路和PoP选择算法以及系统调度优化算法，并结合实际Starlink性能数据进行了仿真评估。

Result: 结果表明，SSU系统能够显著降低每颗卫星的中位数数据积压量。

Conclusion: Starlink辅助设计方案为地球观测卫星的数据中继提供了一种高效且可行的解决方案。

Abstract: Earth observation (EO) satellites in Low Earth Orbit (LEO) are collecting
vast amounts of data, which are invaluable for applications such as monitoring
forest fires. However, data downloading from EO satellites faces significant
challenges due to the limited number of ground stations and the brief
communication windows with them. Conversely, emerging LEO constellations like
Starlink have enabled continuous connectivity and revolutionized access for
ordinary users globally, who can connect via a simple satellite dish. In this
paper, we study the feasibility of supporting EO satellites with Starlink
satellite infrastructure and introduce a novel data delivery system, designated
as "Starlink Space User" (SSU), for relaying data from observation satellites.
SSU treats EO satellites as space users of Starlink, facilitating efficient
data transfer to Earth. At the core of SSU is a novel class of algorithms
designed for link and PoP selection, as well as system scheduling optimization,
that operate effectively atop Starlink's proprietary infrastructure. We assess
the performance of SSU using trace-driven simulations alongside real-world
Starlink performance measurements. Our results demonstrate that the proposed
Starlink-aided design can significantly reduce the median backlog (data not
delivered) per satellite.

</details>


### [12] [Probabilistic Latency Analysis of the Data Distribution Service in ROS 2](https://arxiv.org/abs/2508.10413)
*Sanghoon Lee,Hyung-Seok Park,Jiyeong Chae,Kyung-Joon Park*

Main category: cs.NI

TL;DR: 本文针对ROS 2 DDS在无线网络中的可靠传输问题，提出了一种概率延迟分析（PLA）方法，通过离散状态建模和系统性分析，为优化无线工业机器人的性能提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: ROS 2 DDS在无线网络中由于心跳周期、IP分片和重传间隔的紧密耦合，导致端到端延迟行为不明确，缺乏调优参数的实践指导。

Method: 提出PLA方法，通过离散状态建模和系统性分析中间件及传输层事件，计算未确认消息的稳态概率分布和重传延迟。

Result: 在270种场景中验证PLA，结果显示分析预测与实验结果高度一致。

Conclusion: PLA为无线工业机器人中可靠性、延迟和性能的系统优化提供了理论基础。

Abstract: Robot Operating System 2 (ROS 2) is now the de facto standard for robotic
communication, pairing UDP transport with the Data Distribution Service (DDS)
publish-subscribe middleware. DDS achieves reliability through periodic
heartbeats that solicit acknowledgments for missing samples and trigger
selective retransmissions. In lossy wireless networks, the tight coupling among
heartbeat period, IP fragmentation, and retransmission interval obscures end to
end latency behavior and leaves practitioners with little guidance on how to
tune these parameters. To address these challenges, we propose a probabilistic
latency analysis (PLA) that analytically models the reliable transmission
process of ROS 2 DDS communication using a discrete state approach. By
systematically analyzing both middleware level and transport level events, PLA
computes the steady state probability distribution of unacknowledged messages
and the retransmission latency. We validate our PLA across 270 scenarios,
exploring variations in packet delivery ratios, message sizes, and both
publishing and retransmission intervals, demonstrating a close alignment
between analytical predictions and experimental results. Our findings establish
a theoretical basis to systematically optimize reliability, latency, and
performance in wireless industrial robotics.

</details>


### [13] [Federated Learning Over LoRa Networks: Simulator Design and Performance Evaluation](https://arxiv.org/abs/2508.10574)
*Anshika Singh,Siddhartha S. Borkotoky*

Main category: cs.NI

TL;DR: 该论文开发了一个基于Python的模拟器，用于评估集中式联邦学习（FL）在LoRa网络中的性能，并详细分析了干扰和传输参数对FL的影响，强调了前向帧擦除校正（FEC）的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究联邦学习在LoRa低功耗广域网中的独特挑战，包括带宽限制、干扰和严格的占空比约束。

Method: 开发Python模拟器，整合Flower和LoRaSim框架，模拟FL更新传输的链路级模型，支持多种优化技术如稀疏化、量化、压缩、FEC和占空比控制。

Result: FEC在保证FL收敛和设备通信时间中起关键作用，模拟结果揭示了传输参数和干扰对FL性能的具体影响。

Conclusion: 为LoRa网络中联邦学习的通信协议设计提供了重要见解，强调了FEC的重要性。

Abstract: Federated learning (FL) over long-range (LoRa) low-power wide area networks
faces unique challenges due to limited bandwidth, interference, and strict
duty-cycle constraints. We develop a Python-based simulator that integrates and
extends the Flower and LoRaSim frameworks to evaluate centralized FL over LoRa
networks. The simulator employs a detailed link-level model for FL update
transfer over LoRa channels, capturing LoRa's receiver sensitivity,
interference characteristics, block-fading effects, and constraints on the
maximum transmission unit. It supports update sparsification, quantization,
compression, forward frame-erasure correction (FEC), and duty cycling.
Numerical results illustrate the impact of transmission parameters (spreading
factor, FEC rate) and interference on FL performance. Demonstrating the
critical role of FEC in enabling FL over LoRa networks, we perform an in-depth
evaluation of the impact of FEC on FL convergence and device airtime, providing
insights for communication protocol design for FL over LoRa networks.

</details>


### [14] [Balancing the Energy Consumption and Latency of Over-the-Air Firmware Updates in LoRaWAN](https://arxiv.org/abs/2508.10588)
*Siddhartha S. Borkotoky*

Main category: cs.NI

TL;DR: 论文提出了一种灵活的方法，用于在LoRaWAN中实现固件更新（FUOTA）时在能耗和延迟之间可调节的权衡，适应不同更新需求。


<details>
  <summary>Details</summary>
Motivation: LoRaWAN终端设备能量受限且受限于传输占空比，因此控制固件更新的能耗和延迟是关键挑战。

Method: 采用LoRa扩频因子顺序传输更新帧，通过调整最小扩频因子和每个扩频因子的传输次数，实现能耗与延迟的可调节权衡。

Result: 该方法能够根据更新需求灵活选择低延迟高能耗或高延迟低能耗模式，适应安全和常规更新需求。

Conclusion: 提出的方案为LoRaWAN中的FUOTA提供了一种有效的能量与延迟权衡策略，适用于不同场景。

Abstract: Over-the-air firmware updates are crucial for mitigating security threats and
maintaining up-to-date device functionality in Long Range Wide Area Networks
(LoRaWANs). LoRaWAN end devices are usually energy-constrained, and LoRaWAN
transmissions are subject to duty-cycle restrictions. Consequently, controlling
the energy expenditure and update-delivery latency of FUOTA are key challenges.
We propose a flexible scheme that achieves a tunable trade-off between the
energy consumption and delivery delay. The scheme employs the LoRa spreading
factors sequentially to transmit update-carrying frames, sending a fixed number
of frames with a given spreading factor before moving to the next. By adjusting
the smallest spreading factor to be used and the number of transmissions per
spreading factor, a suitable energy-delay trade-off can be achieved. Thus,
time-sensitive updates, such as security patches, may be sent with a
low-delay-high-energy setting, whereas a more energy-efficient but higher-delay
setting may be used for non-critical updates.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [15] [Ensembling Synchronisation-based and Face-Voice Association Paradigms for Robust Active Speaker Detection in Egocentric Recordings](https://arxiv.org/abs/2508.10580)
*Jason Clarke,Yoshihiko Gotoh,Stefan Goetze*

Main category: cs.MM

TL;DR: 提出了一种简单的加权平均集成方法，结合同步依赖和同步无关模型，提升了第一人称视角下的主动说话人检测性能。


<details>
  <summary>Details</summary>
Motivation: 第一人称视角记录中，频繁的遮挡、运动模糊和音频干扰降低了嘴唇运动与语音同步的可辨别性，传统方法在此场景下表现不佳。

Method: 通过加权平均集成同步依赖和同步无关模型，并优化了预处理流程。

Result: 在Ego4D-AVD验证集上，mAP分别达到70.2%和66.7%。

Conclusion: 集成方法在复杂场景下表现出互补优势，验证了各组件的有效性。

Abstract: Audiovisual active speaker detection (ASD) in egocentric recordings is
challenged by frequent occlusions, motion blur, and audio interference, which
undermine the discernability of temporal synchrony between lip movement and
speech. Traditional synchronisation-based systems perform well under clean
conditions but degrade sharply in first-person recordings. Conversely,
face-voice association (FVA)-based methods forgo synchronisation modelling in
favour of cross-modal biometric matching, exhibiting robustness to transient
visual corruption but suffering when overlapping speech or front-end
segmentation errors occur. In this paper, a simple yet effective ensemble
approach is proposed to fuse synchronisation-dependent and
synchronisation-agnostic model outputs via weighted averaging, thereby
harnessing complementary cues without introducing complex fusion architectures.
A refined preprocessing pipeline for the FVA-based component is also introduced
to optimise ensemble integration. Experiments on the Ego4D-AVD validation set
demonstrate that the ensemble attains 70.2% and 66.7% mean Average Precision
(mAP) with TalkNet and Light-ASD backbones, respectively. A qualitative
analysis stratified by face image quality and utterance masking prevalence
further substantiates the complementary strengths of each component.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [16] [Repairing General Game Descriptions (extended version)](https://arxiv.org/abs/2508.10438)
*Yifan He,Munyque Mittelmann,Aniello Murano,Abdallah Saffidine,Michael Thielscher*

Main category: cs.LO

TL;DR: 论文提出了一种基于最小修复的自动化方法，用于修正不符合逻辑要求的Game Description Language (GDL)描述。


<details>
  <summary>Details</summary>
Motivation: GDL描述的编写对非专家来说具有挑战性，且现有的自动化定理证明无法自动修复错误，需要手动完成。论文旨在解决这一问题。

Method: 定义了GDL描述的最小修复问题，提供了相关计算问题的复杂度分析，并提出了基于Answer Set Programming的编码方法。

Result: 该方法能够自动修复不符合逻辑要求的游戏描述。

Conclusion: 提出的方法为GDL描述的自动化修复提供了有效解决方案。

Abstract: The Game Description Language (GDL) is a widely used formalism for specifying
the rules of general games. Writing correct GDL descriptions can be
challenging, especially for non-experts. Automated theorem proving has been
proposed to assist game design by verifying if a GDL description satisfies
desirable logical properties. However, when a description is proved to be
faulty, the repair task itself can only be done manually. Motivated by the work
on repairing unsolvable planning domain descriptions, we define a more general
problem of finding minimal repairs for GDL descriptions that violate formal
requirements, and we provide complexity results for various computational
problems related to minimal repair. Moreover, we present an Answer Set
Programming-based encoding for solving the minimal repair problem and
demonstrate its application for automatically repairing ill-defined game
descriptions.

</details>


### [17] [Modal definability in Euclidean modal logics](https://arxiv.org/abs/2508.10813)
*Philippe Balbiani,Tinko Tinchev*

Main category: cs.LO

TL;DR: 本文研究欧几里得模态逻辑所确定的框架类中的模态可定义性问题的可计算性，并刻画了导致该问题不可判定的欧几里得模态逻辑类别。


<details>
  <summary>Details</summary>
Motivation: 探讨欧几里得模态逻辑在框架类中的模态可定义性问题的可计算性，旨在识别哪些逻辑会导致该问题不可判定。

Method: 通过分析欧几里得模态逻辑所确定的框架类，研究其模态可定义性问题的可计算性。

Result: 成功刻画了导致模态可定义性问题不可判定的欧几里得模态逻辑类别。

Conclusion: 本文为欧几里得模态逻辑中的可计算性问题提供了理论支持，揭示了某些逻辑在此问题上的不可判定性。

Abstract: This paper is about the computability of the modal definability problem in
classes of frames determined by Euclidean modal logics. We characterize those
Euclidean modal logics such that the classes of frames they determine give rise
to an undecidable modal definability problem.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [18] [Pre-trained Transformer-models using chronic invasive electrophysiology for symptom decoding without patient-individual training](https://arxiv.org/abs/2508.10160)
*Timon Merk,Saeed Salehi,Richard M. Koehler,Qiming Cui,Maria Olaru,Amelia Hahn,Nicole R. Provenza,Simon Little,Reza Abbasi-Asl,Phil A. Starr,Wolf-Julian Neumann*

Main category: cs.HC

TL;DR: 该研究提出了一种基于预训练大模型的方法，用于解码病理和生理状态，支持个体化闭环神经调控治疗，无需患者特异性训练。


<details>
  <summary>Details</summary>
Motivation: 基于大模型的通用状态估计潜力，开发无需患者个体训练的神经解码方法，以实现更广泛的应用。

Method: 使用慢性纵向深部脑刺激记录数据训练基础模型，优化预训练损失函数以校正频率偏差，并展示30分钟扩展上下文窗口。

Result: 在下游任务中，成功解码帕金森病症状，采用留一受试者交叉验证，无需患者个体训练。

Conclusion: 该方法证明了预训练大模型在神经解码中的潜力，为个体化神经调控治疗提供了新思路。

Abstract: Neural decoding of pathological and physiological states can enable
patient-individualized closed-loop neuromodulation therapy. Recent advances in
pre-trained large-scale foundation models offer the potential for generalized
state estimation without patient-individual training. Here we present a
foundation model trained on chronic longitudinal deep brain stimulation
recordings spanning over 24 days. Adhering to long time-scale symptom
fluctuations, we highlight the extended context window of 30 minutes. We
present an optimized pre-training loss function for neural electrophysiological
data that corrects for the frequency bias of common masked auto-encoder loss
functions due to the 1-over-f power law. We show in a downstream task the
decoding of Parkinson's disease symptoms with leave-one-subject-out
cross-validation without patient-individual training.

</details>


### [19] [Training Spatial Ability in Virtual Reality](https://arxiv.org/abs/2508.10195)
*Yiannos Demetriou,Manasvi Parikh,Sara Eskandari,Westley Weimer,Madeline Endres*

Main category: cs.HC

TL;DR: 研究表明，虚拟现实（VR）可以有效教授空间推理技能，与传统的纸笔课程效果相当，但效率更高。


<details>
  <summary>Details</summary>
Motivation: 由于空间推理能力对STEM学科至关重要，而少数群体常在此能力上表现不足，VR被提议为一种可能的高效教学工具，但目前缺乏结构化VR课程的研究。

Method: 研究将现有纸笔课程的三部分模块改编为VR课程，结合教学脚手架和实时反馈，对24名本科生进行了为期三周的评估。

Result: VR课程显著提升了学生的空间能力，与传统课程效果无显著差异，但学习时间更短。VR的使用还减少了晕动症的发生率。

Conclusion: VR可以高效教授空间推理技能，且学生体验良好，为空间能力培训提供了新的可能性。

Abstract: Background: Spatial reasoning has been identified as a critical skill for
success in STEM. Unfortunately, under-represented groups often have lower
incoming spatial ability. Courses that improve spatial skills exist but are not
widely used. Virtual reality (VR) has been suggested as a possible tool for
teaching spatial reasoning since students are more accurate and complete
spatial tasks more quickly in three dimensions. However, no prior work has
developed or evaluated a fully-structured VR spatial skills course. Objectives:
We seek to assess the effectiveness of teaching spatial reasoning in VR, both
in isolation as a structured training curriculum and also in comparison to
traditional methods. Methods: We adapted three modules of an existing
pencil-and-paper course to VR, leveraging educational scaffolding and real-time
feedback in the design. We evaluated our three-week course in a study with
$n=24$ undergraduate introductory STEM students, capturing both quantitative
spatial ability gains (using pre- and post test scores on validated
assessments) and qualitative insights (from a post-study questionnaire). We
also compared our VR course to an offering of a baseline non-VR course (using
data collected in a previous study). Results and Conclusions: Students who took
our VR course had significant spatial ability gains. Critically, we find no
significant difference in outcomes between our VR course (3 meetings of 120
minutes each) and a baseline pencil and paper course (10 meetings of 90 minutes
each), suggesting that spatial reasoning can be very efficiently taught in VR.
We observed cybersickness at lower rates than are generally reported and most
students reported enjoying learning in VR.

</details>


### [20] [Personalized Real-time Jargon Support for Online Meetings](https://arxiv.org/abs/2508.10239)
*Yifan Song,Wing Yee Au,Hon Yung Wong,Brian P. Bailey,Tal August*

Main category: cs.HC

TL;DR: 该论文研究了跨学科交流中的术语障碍，开发了名为ParseJargon的个性化术语识别与解释系统，实验证明其显著提升理解与参与度。


<details>
  <summary>Details</summary>
Motivation: 跨学科交流常因领域专用术语而受阻，研究旨在解决这一问题。

Method: 通过日记研究和实验设计ParseJargon系统，并进行对照实验和实地研究验证效果。

Result: 个性化术语支持显著提升理解、参与度和工作欣赏，通用支持则适得其反。

Conclusion: 研究为设计个性化术语工具提供了见解，适用于跨学科和教育领域。

Abstract: Effective interdisciplinary communication is frequently hindered by
domain-specific jargon. To explore the jargon barriers in-depth, we conducted a
formative diary study with 16 professionals, revealing critical limitations in
current jargon-management strategies during workplace meetings. Based on these
insights, we designed ParseJargon, an interactive LLM-powered system providing
real-time personalized jargon identification and explanations tailored to
users' individual backgrounds. A controlled experiment comparing ParseJargon
against baseline (no support) and general-purpose (non-personalized) conditions
demonstrated that personalized jargon support significantly enhanced
participants' comprehension, engagement, and appreciation of colleagues' work,
whereas general-purpose support negatively affected engagement. A follow-up
field study validated ParseJargon's usability and practical value in real-time
meetings, highlighting both opportunities and limitations for real-world
deployment. Our findings contribute insights into designing personalized jargon
support tools, with implications for broader interdisciplinary and educational
applications.

</details>


### [21] [Facilitating Longitudinal Interaction Studies of AI Systems](https://arxiv.org/abs/2508.10252)
*Tao Long,Sitong Wang,Émilie Fabre,Tony Wang,Anup Sathya,Jason Wu,Savvas Petridis,Dingzeyu Li,Tuhin Chakrabarty,Yue Jiang,Jingyi Li,Tiffany Tseng,Ken Nakagaki,Qian Yang,Nikolas Martelaro,Jeffrey V. Nickerson,Lydia B. Chilton*

Main category: cs.HC

TL;DR: 研究者提出长期研究的重要性，以解决用户与AI互动中的动态变化问题，工作坊旨在提供实用策略。


<details>
  <summary>Details</summary>
Motivation: 由于用户与AI的互动会随时间变化，单次评估不足以捕捉动态问题，需要长期研究。

Method: 工作坊包括主题演讲、小组讨论和互动小组活动，旨在设计协议和工具原型。

Result: 目标是建立长期系统研究的社区，并推广其作为设计和评估工具的常用方法。

Conclusion: 长期研究是解决用户与AI互动动态变化的关键，工作坊为研究者提供了实现这一目标的策略。

Abstract: UIST researchers develop tools to address user challenges. However, user
interactions with AI evolve over time through learning, adaptation, and
repurposing, making one time evaluations insufficient. Capturing these dynamics
requires longer-term studies, but challenges in deployment, evaluation design,
and data collection have made such longitudinal research difficult to
implement. Our workshop aims to tackle these challenges and prepare researchers
with practical strategies for longitudinal studies. The workshop includes a
keynote, panel discussions, and interactive breakout groups for discussion and
hands-on protocol design and tool prototyping sessions. We seek to foster a
community around longitudinal system research and promote it as a more embraced
method for designing, building, and evaluating UIST tools.

</details>


### [22] [Artificial Emotion: A Survey of Theories and Debates on Realising Emotion in Artificial Intelligence](https://arxiv.org/abs/2508.10286)
*Yupei Li,Qiyang Sun,Michelle Schlicher,Yee Wen Lim,Björn W. Schuller*

Main category: cs.HC

TL;DR: 讨论了情感计算（AC）如何让AI系统识别和响应人类情绪，并探讨了AI是否需要发展内部情感状态（Artificial Emotion，AE）以实现更高级的智能（AGI）。


<details>
  <summary>Details</summary>
Motivation: 现有AI在情绪识别和合成方面已有进展，但内部情感状态的开发仍不明确，这可能为AI带来类似人类的‘内在情绪’优势。

Method: 回顾了AE在机器学习中的表现，分析了情感调制的架构，并总结了建模和集成AE到未来AI的机制。

Result: 初步研究表明AI可能表现出AE行为，但缺少清晰框架。AE可能为AI带来好处，但也存在伦理和安全风险。

Conclusion: AE在未来可能对AI有益，但需谨慎对待其伦理和安全问题。

Abstract: Affective Computing (AC) has enabled Artificial Intelligence (AI) systems to
recognise, interpret, and respond to human emotions - a capability also known
as Artificial Emotional Intelligence (AEI). It is increasingly seen as an
important component of Artificial General Intelligence (AGI). We discuss
whether in order to peruse this goal, AI benefits from moving beyond emotion
recognition and synthesis to develop internal emotion-like states, which we
term as Artificial Emotion (AE). This shift potentially allows AI to benefit
from the paradigm of `inner emotions' in ways we - as humans - do. Although
recent research shows early signs that AI systems may exhibit AE-like
behaviours, a clear framework for how emotions can be realised in AI remains
underexplored. In this paper, we discuss potential advantages of AE in AI,
review current manifestations of AE in machine learning systems, examine
emotion-modulated architectures, and summarise mechanisms for modelling and
integrating AE into future AI. We also explore the ethical implications and
safety risks associated with `emotional' AGI, while concluding with our opinion
on how AE could be beneficial in the future.

</details>


### [23] [Beyond Self-Regulated Learning Processes: Unveiling Hidden Tactics in Generative AI-Assisted Writing](https://arxiv.org/abs/2508.10310)
*Kaixun Yang,Yizhou Fan,Luzhen Tang,Mladen Raković,Xinyu Li,Dragan Gašević,Guanliang Chen*

Main category: cs.HC

TL;DR: 论文探讨了在生成式AI辅助学习中如何通过分层系统概念化自我调节学习（SRL），并利用隐马尔可夫模型（HMMs）分析学习行为，发现不同SRL策略的学习者表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI（GenAI）在教育中的整合，自我调节学习（SRL）的重要性日益凸显。为了支持学习者在这种新环境中学习，需要深入理解SRL与GenAI互动中的动态过程。

Method: 采用分层系统概念化SRL，将其分为可观察的学习模式和隐藏的战术行为，进而利用隐马尔可夫模型（HMMs）分析高等教育学生在GenAI辅助写作中的数字痕迹数据。

Result: 研究发现学习者可分为三个具有不同SRL策略的群体，且这些群体在任务表现上存在显著差异。这表明SRL策略的选择在GenAI辅助学习中至关重要。

Conclusion: 研究不仅提供了一种新的SRL建模方法，还为设计自适应性学习技术提供了理论基础，以更有效地支持GenAI增强的教育环境中的学习者。

Abstract: The integration of Generative AI (GenAI) into education is reshaping how
students learn, making self-regulated learning (SRL) - the ability to plan,
monitor, and adapt one's learning - more important than ever. To support
learners in these new contexts, it is essential to understand how SRL unfolds
during interaction with GenAI tools. Learning analytics offers powerful
techniques for analyzing digital trace data to infer SRL behaviors. However,
existing approaches often assume SRL processes are linear, segmented, and
non-overlapping-assumptions that overlook the dynamic, recursive, and
non-linear nature of real-world learning. We address this by conceptualizing
SRL as a layered system: observable learning patterns reflect hidden tactics
(short, purposeful action states), which combine into broader SRL strategies.
Using Hidden Markov Models (HMMs), we analyzed trace data from higher education
students engaged in GenAI-assisted academic writing. We identified three
distinct groups of learners, each characterized by different SRL strategies.
These groups showed significant differences in performance, indicating that
students' use of different SRL strategies in GenAI-assisted writing led to
varying task outcomes. Our findings advance the methodological toolkit for
modeling SRL and inform the design of adaptive learning technologies that more
effectively support learners in GenAI-enhanced educational environments.

</details>


### [24] [Mental Effort Estimation in Motion Exploration and Concept Generation Design Tasks using Inter-Band Relative Power Difference of EEG](https://arxiv.org/abs/2508.10353)
*G. Kalyan Ramana,Sumit Yempalle,Prasad S. Onkar*

Main category: cs.HC

TL;DR: 本文研究了设计师在概念设计中的认知过程，尤其是涉及运动探索任务时，通过EEG测量心理努力，并提出了新指标inter-BRPD。


<details>
  <summary>Details</summary>
Motivation: 理解设计师在探索关节产品概念时的认知现象，以支持概念设计工具的开发。

Method: 通过EEG记录32名参与者的数据，使用新指标inter-BRPD量化心理努力。

Result: inter-BRPD仅需一半传统参数即可有效捕捉心理努力，统计验证其可靠性。

Conclusion: 研究为概念设计的支持和评估提供了新可能性。

Abstract: Conceptual design is a cognitively complex task, especially in the
engineering design of products having relative motion between components.
Designers prefer sketching as a medium for conceptual design and use gestures
and annotations to represent such relative motion. Literature suggests that
static representations of motion in sketches may not achieve the intended
functionality when realised, because it primarily depends on the designers'
mental capabilities for motion simulation. Thus, it is important to understand
the cognitive phenomena when designers are exploring concepts of articulated
products. The current work is an attempt to understand design neurocognition by
categorising the tasks and measuring the mental effort involved in these tasks
using EEG. The analysis is intended to validate design intervention tools to
support the conceptual design involving motion exploration. A novel EEG-based
metric, inter-Band Relative Power Difference (inter-BRPD), is introduced to
quantify mental effort. A design experiment is conducted with 32 participants,
where they have to perform one control task and 2 focus tasks corresponding to
the motion exploration task (MET) and the concept generation task (CGT),
respectively. EEG data is recorded during the 3 tasks, cleaned, processed and
analysed using the MNE library in Python. It is observed from the results that
inter-BRPD captures the essence of mental effort with half the number of
conventionally used parameters. The reliability and efficacy of the inter-BRPD
metric are also statistically validated against literature-based cognitive
metrics. With these new insights, the study opens up possibilities for creating
support for conceptual design and its evaluation.

</details>


### [25] ["Here Comes the Makeup Tutorial You Asked For!": Exploring Communication Strategies and Viewer Engagement in Beauty Videos on Rednote](https://arxiv.org/abs/2508.10364)
*Xueer Lin,Chenyu Li,Yuhan Lyu,Zhicong Lu,Zhenhui Peng*

Main category: cs.HC

TL;DR: 研究分析了美妆视频的传播策略及其对观众参与度的影响，通过编码352个视频和评论分类，揭示了例如呼吁行动能增加讨论的规律。


<details>
  <summary>Details</summary>
Motivation: 探讨美妆视频创作者使用的传播策略如何影响观众参与，以促进美妆知识的传播。

Method: 编码352个Rednote平台的美妆视频，分类评论并回归分析策略对观众参与的影响。

Result: 发现特定策略如结尾呼吁行动能引发更多关于产品效果的讨论。

Conclusion: 为美妆视频创作和知识传播提供了实际启示。

Abstract: More and more people, especially females, create and view beauty videos
covering topics like makeup tutorials and vlogs on social media platforms.
Understanding the communication strategies that creators use in these videos
and how they affect viewers' engagement can help spread beauty knowledge. By
coding 352 beauty videos in Rednote, this study presents a comprehensive
taxonomy of communication strategies used by the creators, such as using home
as the video background and displaying makeup effects when starting the
narrative at the beginning. We further label and computationally classify six
categories of comments that reveal viewers' engagement with beauty videos. The
regression analyses reveal the effects of beauty video communication strategies
on viewers' engagement; for example, calling viewers to take action at the end
tends to attract more comments that debate the product's efficacy. We discuss
insights into fostering the creation of beauty videos and the communication of
beauty knowledge.

</details>


### [26] [MCP2OSC: Parametric Control by Natural Language](https://arxiv.org/abs/2508.10414)
*Yuan-Yi Fan*

Main category: cs.HC

TL;DR: 研究提出了一种新型MCP服务器和提示设计标准，通过自然语言提示实现精确控制，结合LLM处理OSC消息，增强人机协作。


<details>
  <summary>Details</summary>
Motivation: 解决文本提示在高精度任务中的不足以及旋钮控制的复杂性，探索自然语言在OSC控制中的应用。

Method: 提出MCP服务器和提示设计标准，结合Claude模型和MCP2OSC服务器，通过自然语言生成和处理OSC消息。

Result: 成功实现OSC消息的生成、解释、搜索、可视化、验证和调试，展示了LLM在多媒体设备控制中的潜力。

Conclusion: MCP2OSC通过LLM和自然语言接口，为多媒体设备控制提供了一种创新的通用机制。

Abstract: Text prompts enable intuitive content creation but may fall short in
achieving high precision for intricate tasks; knob or slider controls offer
precise adjustments at the cost of increased complexity. To address the gap
between knobs and prompts, a new MCP (Model Context Protocol) server and a
unique set of prompt design criteria are presented to enable exploring
parametric OSC (OpenSoundControl) control by natural language prompts.
Demonstrated by 14 practical QA examples with best practices and the
generalized prompt templates, this study finds Claude integrated with the
MCP2OSC server effective in generating OSC messages by natural language,
interpreting, searching, and visualizing OSC messages, validating and debugging
OSC messages, and managing OSC address patterns. MCP2OSC enhances human-machine
collaboration by leveraging LLM (Large Language Model) to handle intricate OSC
development tasks, and by empowering human creativity with an intuitive
language interface featuring flexible precision controls: a prompt-based OSC
tool. This study provides a novel perspective on the creative MCP application
at the network protocol level by utilizing LLM's strength in directly
processing and generating human-readable OSC messages. The results suggest its
potential for a LLM-based universal control mechanism for multimedia devices.

</details>


### [27] [Stress Detection from Multimodal Wearable Sensor Data](https://arxiv.org/abs/2508.10468)
*Paul Schreiber,Beyza Cinar,Lennart Mackert,Maria Maleshkova*

Main category: cs.HC

TL;DR: 该论文提出了一个多模态的情感计算数据集，用于开发和评估自动化压力识别系统，同时提供了一个标准化框架和分类基准。


<details>
  <summary>Details</summary>
Motivation: 目前关于压力和情感计算的数据集和标准化协议有限，因此需要开发一个多模态数据集来支持相关研究。

Method: 通过标准化框架收集穿戴设备的生理和运动信号，并在实验室环境中对不同压力状态进行分类和标注。

Result: 提出的数据集在二分类和多分类任务中分别达到了89%和82%的准确率。

Conclusion: 论文贡献了一个公开可用的多模态压力数据集，并展示了其在压力识别中的有效性。

Abstract: Human-Computer Interaction (HCI) is a multi-modal, interdisciplinary field
focused on designing, studying, and improving the interactions between people
and computer systems. This involves the design of systems that can recognize,
interpret, and respond to human emotions or stress. Developing systems to
monitor and react to stressful events can help prevent severe health
implications caused by long-term stress exposure. Currently, the publicly
available datasets and standardized protocols for data collection in this
domain are limited. Therefore, we introduce a multi-modal dataset intended for
wearable affective computing research, specifically the development of
automated stress recognition systems. We systematically review the publicly
available datasets recorded in controlled laboratory settings. Based on a
proposed framework for the standardization of stress experiments and data
collection, we collect physiological and motion signals from wearable devices
(e.g., electrodermal activity, photoplethysmography, three-axis accelerometer).
During the experimental protocol, we differentiate between the following four
affective/activity states: neutral, physical, cognitive stress, and
socio-evaluative stress. These different phases are meticulously labeled,
allowing for detailed analysis and reconstruction of each experiment. Meta-data
such as body positions, locations, and rest phases are included as further
annotations. In addition, we collect psychological self-assessments after each
stressor to evaluate subjects' affective states. The contributions of this
paper are twofold: 1) a novel multi-modal, publicly available dataset for
automated stress recognition, and 2) a benchmark for stress detection with 89\%
in a binary classification (baseline vs. stress) and 82\% in a multi-class
classification (baseline vs. stress vs. physical exercise).

</details>


### [28] [Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling](https://arxiv.org/abs/2508.10561)
*Andrea Gargano,Jasin Machkour,Mimma Nardelli,Enzo Pasquale Scilingo,Michael Muma*

Main category: cs.HC

TL;DR: 该研究通过严格的生理特征选择方法，发现仅有两种皮肤电特征与唤醒水平显著相关，强调了可重复性评估在情感计算中的重要性。


<details>
  <summary>Details</summary>
Motivation: 情感计算中主观情绪体验与客观生理标记的可靠关联是一个关键挑战，研究旨在解决这一问题。

Method: 使用T-Rex方法对164个心血管和皮肤电信号特征进行选择，控制假发现率。

Result: 仅两种皮肤电特征与唤醒水平显著相关，确认率达100%。

Conclusion: 研究为需要高可靠性的应用（如心理健康识别和人机交互）提供了有前景的方法。

Abstract: In Affective Computing, a key challenge lies in reliably linking subjective
emotional experiences with objective physiological markers. This preliminary
study addresses the issue of reproducibility by identifying physiological
features from cardiovascular and electrodermal signals that are associated with
continuous self-reports of arousal levels. Using the Continuously Annotated
Signal of Emotion dataset, we analyzed 164 features extracted from cardiac and
electrodermal signals of 30 participants exposed to short emotion-evoking
videos. Feature selection was performed using the Terminating-Random
Experiments (T-Rex) method, which performs variable selection systematically
controlling a user-defined target False Discovery Rate. Remarkably, among all
candidate features, only two electrodermal-derived features exhibited
reproducible and statistically significant associations with arousal, achieving
a 100\% confirmation rate. These results highlight the necessity of rigorous
reproducibility assessments in physiological features selection, an aspect
often overlooked in Affective Computing. Our approach is particularly promising
for applications in safety-critical environments requiring trustworthy and
reliable white box models, such as mental disorder recognition and human-robot
interaction systems.

</details>


### [29] [Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions](https://arxiv.org/abs/2508.10586)
*Birgit Nierula,Mustafa Tevfik Lafci,Anna Melnik,Mert Akgül,Farelle Toumaleu Siewe,Sebastian Bosse*

Main category: cs.HC

TL;DR: 研究虚拟现实中的个人空间侵犯，探讨了面部表情和交互阶段对生理反应的影响，发现不同生理指标捕捉了不同的社交行为特征。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实中个人空间侵犯的生理反应研究不足，尤其是面部表情和交互阶段的影响，需进一步探索。

Method: 采用2x2因子设计，记录皮肤电反应（SCR）、心率变异性（HRV）和不适评分，分析个人空间侵犯和面部表情的影响。

Result: 站立阶段的SCR反应更强，愤怒表情降低HRV并增加不适感，但未增强SCR反应。

Conclusion: 不同生理指标反映不同的社交行为特征，为虚拟环境中社交行为的多模态评估提供了依据。

Abstract: Proxemics, the study of spatial behavior, is fundamental to social
interaction and increasingly relevant for virtual reality (VR) applications.
While previous research has established that users respond to personal space
violations in VR similarly as in real-world settings, phase-specific
physiological responses and the modulating effects of facial expressions remain
understudied. We investigated physiological and subjective responses to
personal space violations by virtual avatars, to understand how threatening
facial expressions and interaction phases (approach vs. standing) influence
these responses. Sixteen participants experienced a 2x2 factorial design
manipulating Personal Space (intrusion vs. respect) and Facial Expression
(neutral vs. angry) while we recorded skin conductance response (SCR), heart
rate variability (HRV), and discomfort ratings. Personal space boundaries were
individually calibrated using a stop-distance procedure. Results show that SCR
responses are significantly higher during the standing phase compared to the
approach phase when personal space was violated, indicating that prolonged
proximity within personal space boundaries is more physiologically arousing
than the approach itself. Angry facial expressions significantly reduced HRV,
reflecting decreased parasympathetic activity, and increased discomfort
ratings, but did not amplify SCR responses. These findings demonstrate that
different physiological modalities capture distinct aspects of proxemic
responses: SCR primarily reflects spatial boundary violations, while HRV
responds to facial threat cues. Our results provide insights for developing
comprehensive multi-modal assessments of social behavior in virtual
environments and inform the design of more realistic avatar interactions.

</details>


### [30] [DEV: A Driver-Environment-Vehicle Closed-Loop Framework for Risk-Aware Adaptive Automation of Driving](https://arxiv.org/abs/2508.10618)
*Anaïs Halin,Christel Devue,Marc Van Droogenbroeck*

Main category: cs.HC

TL;DR: 文章提出了DEV框架，用于动态风险感知的驾驶自动化，通过实时调整自动化级别以提高安全性和驾驶体验。


<details>
  <summary>Details</summary>
Motivation: 随着车辆自动化的普及，驾驶员分心、情境意识降低以及模式混淆等新风险凸显，需要一种能够动态评估和调整风险的方法。

Method: 提出DEV框架，通过驾驶员、环境和车辆的动态交互，实时评估风险并调整自动化级别。

Result: DEV框架能够支持更平滑的过渡和更有效的驾驶员与自动化系统的协作，并通过指标量化驱动风险。

Conclusion: DEV框架为多学科研究提供了一个综合视角，指导开发动态、风险感知的驾驶自动化系统。

Abstract: The increasing integration of automation in vehicles aims to enhance both
safety and comfort, but it also introduces new risks, including driver
disengagement, reduced situation awareness, and mode confusion. In this work,
we propose the DEV framework, a closed-loop framework for risk-aware adaptive
driving automation that captures the dynamic interplay between the driver, the
environment, and the vehicle. The framework promotes to continuously adjusting
the operational level of automation based on a risk management strategy. The
real-time risk assessment supports smoother transitions and effective
cooperation between the driver and the automation system. Furthermore, we
introduce a nomenclature of indexes corresponding to each core component,
namely driver involvement, environment complexity, and vehicle engagement, and
discuss how their interaction influences driving risk. The DEV framework offers
a comprehensive perspective to align multidisciplinary research efforts and
guide the development of dynamic, risk-aware driving automation systems.

</details>


### [31] [Are Electrodermal Activity-Based Indicators of Driver Cognitive Distraction Robust to Varying Traffic Conditions and Adaptive Cruise Control Use?](https://arxiv.org/abs/2508.10620)
*Anaïs Halin,Marc Van Droogenbroeck,Christel Devue*

Main category: cs.HC

TL;DR: 研究通过模拟驾驶实验，探讨皮肤电活动（EDA）如何反映驾驶员在不同交通条件和自适应巡航控制（ACC）使用下的认知分心。


<details>
  <summary>Details</summary>
Motivation: 旨在理解EDA指标如何表征驾驶员认知分心及其受驾驶环境和自动化使用的影响。

Method: 六种驾驶场景中，结合认知分心（有无心算任务）和驾驶环境复杂度（不同交通条件），记录三种EDA指标。

Result: EDA指标显著受认知分心和ACC使用影响，环境复杂度仅影响SCL和SCR幅度，不影响SCR频率。

Conclusion: EDA指标可有效反映驾驶员心理负荷的多种变化源，包括分心、环境和自动化使用。

Abstract: In this simulator study, we investigate whether and how electrodermal
activity (EDA) reflects driver cognitive distraction under varying traffic
conditions and adaptive cruise control (ACC) use. Participants drove in six
scenarios, combining two levels of cognitive distraction (presence/absence of a
mental calculation task) and three levels of driving environment complexity
(different traffic conditions). Throughout the experiment, they were free to
activate or deactivate ACC (ACC use, two levels). We analyzed three EDA-based
indicators of cognitive distraction: SCL (mean skin conductance level), SCR
amplitude (mean amplitude of skin conductance responses), and SCR rate (rate of
skin conductance responses). Results indicate that all three indicators were
significantly influenced by cognitive distraction and ACC use, while
environment complexity influenced SCL and SCR amplitude, but not SCR rate.
These findings suggest that EDA-based indicators reflect variations in drivers'
mental workload due not only to cognitive distraction, but also to driving
environment and automation use.

</details>


### [32] [Gaze-Based Indicators of Driver Cognitive Distraction: Effects of Different Traffic Conditions and Adaptive Cruise Control Use](https://arxiv.org/abs/2508.10624)
*Anaïs Halin,Adrien Deliège,Christel Devue,Marc Van Droogenbroeck*

Main category: cs.HC

TL;DR: 研究表明，垂直注视分散度随交通复杂度增加，而自适应巡航控制（ACC）使注视集中于道路中心；认知分心减少道路中心注视并增加垂直分散度。


<details>
  <summary>Details</summary>
Motivation: 探讨不同交通条件和ACC使用下，注视参数如何反映驾驶员认知分心。

Method: 通过驾驶模拟器实验，结合认知分心（有无心算）和驾驶环境复杂度（三个水平），记录两名注视指标（道路中心注视百分比和注视分散度）。

Result: 交通复杂度增加垂直注视分散度，ACC使注视集中；认知分心减少道路中心注视，增加垂直分散度，心算期间注视集中暂时增加。

Conclusion: 注视参数能有效区分认知分心，心算期间注视行为存在动态变化。

Abstract: In this simulator study, we investigate how gaze parameters reflect driver
cognitive distraction under varying traffic conditions and adaptive cruise
control (ACC) use. Participants completed six driving scenarios that combined
two levels of cognitive distraction (with/without mental calculations) and
three levels of driving environment complexity. Throughout the experiment,
participants were free to activate or deactivate an ACC. We analyzed two
gaze-based indicators of driver cognitive distraction: the percent road center,
and the gaze dispersions (horizontal and vertical). Our results show that
vertical gaze dispersion increases with traffic complexity, while ACC use leads
to gaze concentration toward the road center. Cognitive distraction reduces
road center gaze and increases vertical dispersion. Complementary analyses
revealed that these observations actually arise mainly between mental
calculations, while periods of mental calculations are characterized by a
temporary increase in gaze concentration.

</details>


### [33] [Visualization of Electronic Health Record Sequences at Scale](https://arxiv.org/abs/2508.10700)
*Ambre Assor,Mickael Sereno,Jean-Daniel Fekete*

Main category: cs.HC

TL;DR: ParcoursVis是一种渐进式视觉分析工具，用于大规模探索电子健康记录序列，通过逐步计算和更新可视化结果，支持交互式分析数千万患者的记录。


<details>
  <summary>Details</summary>
Motivation: 现有工具在处理大规模数据时因计算延迟而无法保持交互性，限制了探索罕见医疗条件或意外患者路径的能力。

Method: 采用渐进式算法，快速生成近似的初始聚合结果（冰柱树可视化），并迭代优化，直至完成全部计算。

Result: ParcoursVis能够处理数千万患者、每个患者数千事件的记录，比类似系统多处理3到5个数量级的数据。

Conclusion: 工具的成功为大规模数据分析提供了新思路，并支持医疗实践中的改进，同时开源原型促进了进一步研究。

Abstract: We present ParcoursVis, a Progressive Visual Analytics tool designed to
explore electronic health record sequences of patients at scale. Existing tools
process and aggregate the whole dataset upfront before showing the
visualization, taking a time proportional to the data size. Therefore, to
remain interactive, existing tools are limited to data sizes that can be
processed in under a few seconds to meet the latency constraints of human
attention. To overcome this limitation and scale to larger sizes, ParcoursVis
relies on a progressive algorithm that quickly shows an approximate initial
result of the aggregation, visualized as an Icicle tree, and improves it
iteratively, updating the visualization until the whole computation is done.
With its architecture, ParcoursVis remains interactive while visualizing the
sequences of tens of millions of patients, each described with thousands of
events; three to five orders of magnitude more than similar systems. Managing
large datasets allows for exploring rare medical conditions or unexpected
patient pathways, contributing to improving treatments. We describe the
algorithms we use and our evaluation concerning their scalability, convergence,
and stability. We also report on a set of guidelines to support visualization
designers in developing scalable progressive systems. ParcoursVis already
allows practitioners to perform analyses on two large real medical datasets.
Our prototype is open-source.

</details>


### [34] ["I Want My Chart to Be Just for Me": Community-Engaged Design to Support Outpatient Healthcare for Resettled Communities](https://arxiv.org/abs/2508.10757)
*Zhanming Chen,Juan F. Maestre,May Hang,Alisha Ghaju,Ji Youn Shin*

Main category: cs.HC

TL;DR: 本文探讨了重新定居人群在医疗保健中的挑战，提出基于社区资产的解决方案，通过参与式设计工作坊识别社区优势。


<details>
  <summary>Details</summary>
Motivation: 重新定居人群在获取医疗服务时面临文化、语言和社会经济障碍，现有技术方案常忽视社区自身优势。

Method: 研究者与30名苗族社区成员进行了两次参与式设计工作坊。

Result: 识别出社区拥有的四种资产，如代际健康支持和基于故事的沟通方式。

Conclusion: 参与式设计能促进基于资产的方法，为技术设计提供利用患者优势支持健康管理的启示。

Abstract: Individuals resettled in a new environment often face challenges in accessing
adequate healthcare services, particularly within the complex processes of
outpatient clinic care. Cultural differences, language barriers, and low
socioeconomic status contribute to these difficulties. While previous studies
have identified barriers and proposed technology-mediated solutions for
resettled populations, many focus on addressing deficits rather than building
on the strengths these communities already possess, which limits the
sustainability and relevance of these solutions in everyday life. We conducted
two community-based participatory design workshops with 30 Hmong community
members in a large metropolitan area in the US. Through this process, we
identified four types of assets the community has gradually developed,
including intergenerational support for health management and
storytelling-based communication practices that facilitate relatable and
culturally grounded interactions. We show how participatory design workshops
can foster asset-based approaches, and discuss design implications for
technologies that leverage patients' existing strengths to support their health
management during outpatient visits.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [35] [B-repLer: Semantic B-rep Latent Editor using Large Language Models](https://arxiv.org/abs/2508.10201)
*Yilin Liu,Niladri Shekhar Dutt,Changjian Li,Niloy J. Mitra*

Main category: cs.GR

TL;DR: 论文探讨了如何将多模态大语言模型（mLLMs）应用于高层次的边界表示（B-rep）CAD对象编辑，提出了一种名为B-repLer的微调模型，能够理解文本提示并对B-reps进行语义编辑。


<details>
  <summary>Details</summary>
Motivation: 尽管mLLMs在多种任务中表现出色，但在3D分析和编辑任务中表现有限。B-reps作为工程对象的行业标准，缺乏公开的标注数据和工具支持，限制了其应用。

Method: 设计了一种新颖的多模态架构B-repLer，能够处理B-rep模型，并利用现有CAD工具自动生成推理数据集，无需外部标注。

Result: B-repLer能够基于文本提示对B-reps进行复杂语义编辑，生成有效输出，实现了以往无法完成的任务。

Conclusion: 研究表明，mLLMs可以通过特定架构和数据集生成方法适应B-rep编辑任务，为CAD领域提供了新的可能性。

Abstract: Multimodal large language models (mLLMs), trained in a mixed modal setting as
a universal model, have been shown to compete with or even outperform many
specialized algorithms for imaging and graphics tasks. As demonstrated across
many applications, mLLMs' ability to jointly process image and text data makes
them suitable for zero-shot applications or efficient fine-tuning towards
specialized tasks. However, they have had limited success in 3D analysis and
editing tasks. This is due to both the lack of suitable (annotated) 3D data as
well as the idiosyncrasies of 3D representations. In this paper, we investigate
whether mLLMs can be adapted to support high-level editing of Boundary
Representation (B-rep) CAD objects. B-reps remain the industry-standard for
precisely encoding engineering objects, but are challenging as the
representation is fragile (i.e. can easily lead to invalid CAD objects) and no
publicly available data source exists with semantically-annotated B-reps or CAD
construction history. We present B-repLer as a finetuned mLLM that can
understand text prompts and make semantic edits on given B-Reps to produce
valid outputs. We enable this via a novel multimodal architecture, specifically
designed to handle B-rep models, and demonstrate how existing CAD tools, in
conjunction with mLLMs, can be used to automatically generate the required
reasoning dataset, without relying on external annotations. We extensively
evaluate B-repLer and demonstrate several text-based B-rep edits of various
complexity, which were not previously possible.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [36] [Hard Shell, Reliable Core: Improving Resilience in Replicated Systems with Selective Hybridization](https://arxiv.org/abs/2508.10141)
*Laura Lawniczak,Tobias Distler*

Main category: cs.DC

TL;DR: ShellFT框架通过微复制技术提升了共识系统中混合容错模型的灵活性，减少了多样化成本。


<details>
  <summary>Details</summary>
Motivation: 现有混合容错方法在灵活性和成本上存在不足。

Method: 利用微复制技术，允许选择性增强拜占庭容错的部分。

Result: 相比传统方法，多样化成本降低70%以上。

Conclusion: ShellFT为定制混合容错方案提供了高效灵活的方法。

Abstract: Hybrid fault models are known to be an effective means for enhancing the
robustness of consensus-based replicated systems. However, existing
hybridization approaches suffer from limited flexibility with regard to the
composition of crash-tolerant and Byzantine fault-tolerant system parts and/or
are associated with a significant diversification overhead. In this paper we
address these issues with ShellFT, a framework that leverages the concept of
micro replication to allow system designers to freely choose the parts of the
replication logic that need to be resilient against Byzantine faults. As a key
benefit, such a selective hybridization makes it possible to develop hybrid
solutions that are tailored to the specific characteristics and requirements of
individual use cases. To illustrate this flexibility, we present three custom
ShellFT protocols and analyze the complexity of their implementations. Our
evaluation shows that compared with traditional hybridization approaches,
ShellFT is able to decrease diversification costs by more than 70%.

</details>


### [37] [Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices](https://arxiv.org/abs/2508.10202)
*Sreeram Venkat,Kasia Swirydowicz,Noah Wolfe,Omar Ghattas*

Main category: cs.DC

TL;DR: 论文提出了一种基于Hipify的性能可移植框架，并将其应用于FFTMatvec，使其能在AMD GPU上高效运行。同时，提出了动态混合精度框架，通过Pareto前沿分析优化计算配置。


<details>
  <summary>Details</summary>
Motivation: 领导级计算设施的硬件多样性以及GPU在低精度计算中的性能提升，促使科学HPC工作流程采用混合精度算法和性能可移植性模型。

Method: 使用Hipify实现性能可移植框架，并将其应用于FFTMatvec；开发动态混合精度框架，通过Pareto前沿分析确定最佳精度配置。

Result: FFTMatvec在AMD GPU上表现出色，性能优化通过rocBLAS库直接集成；动态混合精度框架可根据误差容忍度优化配置；在OLCF Frontier超级计算机的2,048个GPU上实现扩展。

Conclusion: 该工作展示了性能可移植性和混合精度算法在高性能计算中的潜力，为科学HPC工作流程提供了实用解决方案。

Abstract: The hardware diversity displayed in leadership-class computing facilities,
alongside the immense performance boosts exhibited by today's GPUs when
computing in lower precision, provide a strong incentive for scientific HPC
workflows to adopt mixed-precision algorithms and performance portability
models. We present an on-the-fly framework using Hipify for performance
portability and apply it to FFTMatvec-an HPC application that computes
matrix-vector products with block-triangular Toeplitz matrices. Our approach
enables FFTMatvec, initially a CUDA-only application, to run seamlessly on AMD
GPUs with excellent observed performance. Performance optimizations for AMD
GPUs are integrated directly into the open-source rocBLAS library, keeping the
application code unchanged. We then present a dynamic mixed-precision framework
for FFTMatvec; a Pareto front analysis determines the optimal mixed-precision
configuration for a desired error tolerance. Results are shown for AMD Instinct
MI250X, MI300X, and the newly launched MI355X GPUs. The performance-portable,
mixed-precision FFTMatvec is scaled to 2,048 GPUs on the OLCF Frontier
supercomputer.

</details>


### [38] [GPZ: GPU-Accelerated Lossy Compressor for Particle Data](https://arxiv.org/abs/2508.10305)
*Ruoyu Li,Yafan Huang,Longtao Zhang,Zhuoxun Yang,Sheng Di,Jiajun Huang,Jinyang Liu,Jiannan Tian,Xin Liang,Guanpeng Li,Hanqi Guo,Franck Cappello,Kai Zhao*

Main category: cs.DC

TL;DR: GPZ是一种针对大规模粒子数据的高性能、误差有界的无损压缩器，专为现代GPU设计，通过四阶段并行流水线和优化技术，显著提升压缩效率和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 传统压缩技术难以处理不规则粒子分布和GPU架构限制，导致吞吐量低和压缩比不佳，因此需要针对GPU优化的新型压缩器。

Method: 提出GPZ，采用四阶段并行流水线，结合计算、内存访问和GPU占用优化技术，以适应大规模并行硬件。

Result: 在三种GPU架构和六个真实科学数据集上的评估显示，GPZ比五种先进GPU压缩器吞吐量提高8倍，同时压缩比和数据质量更优。

Conclusion: GPZ在性能和压缩效率上显著优于现有技术，适用于多种GPU架构和科学领域。

Abstract: Particle-based simulations and point-cloud applications generate massive,
irregular datasets that challenge storage, I/O, and real-time analytics.
Traditional compression techniques struggle with irregular particle
distributions and GPU architectural constraints, often resulting in limited
throughput and suboptimal compression ratios. In this paper, we present GPZ, a
high-performance, error-bounded lossy compressor designed specifically for
large-scale particle data on modern GPUs. GPZ employs a novel four-stage
parallel pipeline that synergistically balances high compression efficiency
with the architectural demands of massively parallel hardware. We introduce a
suite of targeted optimizations for computation, memory access, and GPU
occupancy that enables GPZ to achieve near-hardware-limit throughput. We
conduct an extensive evaluation on three distinct GPU architectures
(workstation, data center, and edge) using six large-scale, real-world
scientific datasets from five distinct domains. The results demonstrate that
GPZ consistently and significantly outperforms five state-of-the-art GPU
compressors, delivering up to 8x higher end-to-end throughput while
simultaneously achieving superior compression ratios and data quality.

</details>


### [39] [Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models](https://arxiv.org/abs/2508.10349)
*Tianjun Yuan,Jiaxiang Geng,Pengchao Han,Xianhao Chen,Bing Luo*

Main category: cs.DC

TL;DR: 提出了一种灵活的个性化联邦学习范式（FlexP-SFL），通过分割学习和对齐策略解决客户端数据不足和异构问题，提升了模型性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决有限客户端数据和异构数据分布对协同学习的阻碍，实现个性化目标的同时进行协作学习。

Method: 基于分割学习，客户端根据资源限制部分本地训练模型，剩余部分卸载到服务器，并采用对齐策略优化全局数据性能。

Result: 实验结果表明，FlexP-SFL在个性化微调效率和最终准确性上优于基线模型。

Conclusion: FlexP-SFL在资源受限的客户端环境中有效提升了个性化联邦学习的性能。

Abstract: Fine-tuning foundation models is critical for superior performance on
personalized downstream tasks, compared to using pre-trained models.
Collaborative learning can leverage local clients' datasets for fine-tuning,
but limited client data and heterogeneous data distributions hinder effective
collaboration. To address the challenge, we propose a flexible personalized
federated learning paradigm that enables clients to engage in collaborative
learning while maintaining personalized objectives. Given the limited and
heterogeneous computational resources available on clients, we introduce
\textbf{flexible personalized split federated learning (FlexP-SFL)}. Based on
split learning, FlexP-SFL allows each client to train a portion of the model
locally while offloading the rest to a server, according to resource
constraints. Additionally, we propose an alignment strategy to improve
personalized model performance on global data. Experimental results show that
FlexP-SFL outperforms baseline models in personalized fine-tuning efficiency
and final accuracy.

</details>


### [40] [Dalek: An Unconventional and Energy-Aware Heterogeneous Cluster](https://arxiv.org/abs/2508.10481)
*Adrien Cassagne,Noé Amiot,Manuel Bouyer*

Main category: cs.DC

TL;DR: Dalek是一个实验性计算集群，用于评估异构消费级硬件在软件设计、原型开发和算法开发中的性能。它采用低成本硬件，并提供高精度能源监控。


<details>
  <summary>Details</summary>
Motivation: 评估消费级硬件在计算任务中的性能，提供低成本且多功能的计算平台。

Method: 集群采用异构硬件（如mini-PC、笔记本电脑和游戏台式机的CPU和GPU），并开发了高精度能源监控平台。

Result: 通过合成基准测试验证了集群性能，能源监控平台能实现毫瓦级分辨率的高精度采样。

Conclusion: Dalek为计算机科学中的能源意识研究提供了高效且经济的研究平台。

Abstract: Dalek is an experimental compute cluster designed to evaluate the performance
of heterogeneous, consumer-grade hardware for software design, prototyping, and
algorithm development. In contrast to traditional computing centers that rely
on costly, server-class components, Dalek integrates CPUs and GPUs typically
found in mini-PCs, laptops, and gaming desktops, providing a cost-effective yet
versatile platform. This document details the cluster's architecture and
software stack, and presents results from synthetic benchmarks. Furthermore, it
introduces a custom energy monitoring platform capable of delivering 1000
averaged samples per second with milliwatt-level resolution. This
high-precision monitoring capability enables a wide range of energy-aware
research experiments in applied Computer Science.

</details>


### [41] [Introducing CQ: A C-like API for Quantum Accelerated HPC](https://arxiv.org/abs/2508.10854)
*Oliver Thomson Brown,Mateusz Meller,James Richings*

Main category: cs.DC

TL;DR: 本文提出了一种名为CQ的量子加速HPC的C-like API规范，以及其参考实现CQ-SimBE，旨在将量子计算逐步集成到传统HPC代码中。


<details>
  <summary>Details</summary>
Motivation: 支持从C和Fortran等语言运行时卸载量子计算，为严格和强类型编译语言提供描述和卸载量子计算的方法，并赋予程序员对经典数据移动的精细控制。

Method: 设计了CQ规范及其参考实现CQ-SimBE，基于statevector模拟器QuEST，采用C99编写。

Result: CQ-SimBE展示了CQ的用途和实用性，并为支持模拟量子计算等新功能提供了实验空间。

Conclusion: CQ规范和CQ-SimBE均为开源，可在公共仓库中获取，为量子计算与传统HPC的集成提供了实用工具。

Abstract: In this paper we present CQ, a specification for a C-like API for quantum
accelerated HPC, as well as CQ-SimBE, a reference implementation of CQ written
in C99, and built on top of the statevector simulator QuEST. CQ focuses on
enabling the incremental integration of quantum computing into classical HPC
codes by supporting runtime offloading from languages such as C and Fortran. It
provides a way of describing and offloading quantum computations which is
compatible with strictly and strongly typed compiled languages, and gives the
programmer fine-grained control over classical data movement. The CQ Simulated
Backend (CQ-SimBE) provides both a way to demonstrate the usage and utility of
CQ, and a space to experiment with new features such as support for analogue
quantum computing. Both the CQ specification and CQ-SimBE are open-source, and
available in public repositories.

</details>


### [42] [Minimmit: Fast Finality with Even Faster Blocks](https://arxiv.org/abs/2508.10862)
*Brendan Kobayashi Chou,Andrew Lewis-Pye,Patrick O'Grady*

Main category: cs.DC

TL;DR: Minimmit是一种新的状态机复制协议，通过快速切换视图降低延迟。


<details>
  <summary>Details</summary>
Motivation: 扩展Alpenglow等协议的'2轮最终性'方法以进一步减少延迟。

Method: 引入快速切换视图的机制，提供一致性及活跃性证明。

Result: 初步提供了协议的设计、证明和伪代码，后续将补充优化和实验结果。

Conclusion: Minimmit展示了降低SMR延迟的潜力，未来将进一步完善。

Abstract: Minimmit is a new protocol for State-Machine-Replication (SMR) that extends
the '2-round finality' approach of protocols such as Alpenglow to further
reduce latency, by allowing for faster progression through 'views'. This
preliminary draft provides motivation and pseudocode, together with proofs of
consistency and liveness. An updated draft with a proof of optimistic
responsiveness, suggested optimizations, and experiments, is to follow.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [43] [Privacy-Preserving Approximate Nearest Neighbor Search on High-Dimensional Data](https://arxiv.org/abs/2508.10373)
*Yingfan Liu,Yandi Zhang,Jiadong Xie,Hui Li,Jeffrey Xu Yu,Jiangtao Cui*

Main category: cs.DB

TL;DR: 论文提出了一种新型的隐私保护k-ANNS解决方案，通过在单一云服务器上实现高效的隐私保护最近邻搜索，避免了用户与云之间的通信开销。


<details>
  <summary>Details</summary>
Motivation: 在云计算和AI时代，数据所有者将数据外包给云服务器以提供k-近邻搜索服务，但现有隐私保护方案无法同时满足隐私、效率、准确性和最小化用户参与的需求。

Method: 引入一种名为距离比较加密的新加密方法，设计隐私保护索引结合先进k-ANNS方法和近似距离计算，采用过滤-精炼搜索策略。

Result: 实验表明，该方法比现有方案快3个数量级，且不影响准确性。

Conclusion: 该方案在隐私保护、效率和准确性之间取得了良好平衡，优于现有方法。

Abstract: In the era of cloud computing and AI, data owners outsource ubiquitous
vectors to the cloud, which furnish approximate $k$-nearest neighbors
($k$-ANNS) services to users. To protect data privacy against the untrusted
server, privacy-preserving $k$-ANNS (PP-ANNS) on vectors has been a fundamental
and urgent problem. However, existing PP-ANNS solutions fall short of meeting
the requirements of data privacy, efficiency, accuracy, and minimal user
involvement concurrently. To tackle this challenge, we introduce a novel
solution that primarily executes PP-ANNS on a single cloud server to avoid the
heavy communication overhead between the cloud and the user. To ensure data
privacy, we introduce a novel encryption method named distance comparison
encryption, facilitating secure, efficient, and exact distance comparisons. To
optimize the trade-off between data privacy and search performance, we design a
privacy-preserving index that combines the state-of-the-art $k$-ANNS method
with an approximate distance computation method. Then, we devise a search
method using a filter-and-refine strategy based on the index. Moreover, we
provide the security analysis of our solution and conduct extensive experiments
to demonstrate its superiority over existing solutions. Based on our
experimental results, our method accelerates PP-ANNS by up to 3 orders of
magnitude compared to state-of-the-art methods, while not compromising the
accuracy.

</details>


### [44] [Cross-Organizational Analysis of Parliamentary Processes: A Case Study](https://arxiv.org/abs/2508.10381)
*Paul-Julius Hillmann,Stephan A. Fahrenkrog-Petersen,Jan Mendling*

Main category: cs.DB

TL;DR: 该论文首次将流程挖掘应用于议会流程，分析了三个德国州议会的立法流程，并提出了跨组织比较的新方法。


<details>
  <summary>Details</summary>
Motivation: 由于企业通常不愿共享数据，跨组织流程比较研究较少。本文利用法律要求公开数据的德国州议会作为研究对象，探索流程挖掘在跨组织比较中的应用。

Method: 通过分析三个德国州议会的立法流程数据，结合流程挖掘技术进行比较研究，并与政治科学家和联邦议会的专家进行知识交流。

Result: 揭示了不同州议会流程的差异和最佳实践，为流程优化提供了新见解。

Conclusion: 本文为政治科学与流程挖掘的跨学科研究开辟了新方向，展示了公开数据的潜力。

Abstract: Process Mining has been widely adopted by businesses and has been shown to
help organizations analyze and optimize their processes. However, so far,
little attention has gone into the cross-organizational comparison of
processes, since many companies are hesitant to share their data. In this
paper, we explore the processes of German state parliaments that are often
legally required to share their data and run the same type of processes for
different geographical regions. This paper is the first attempt to apply
process mining to parliamentary processes and, therefore, contributes toward a
novel interdisciplinary research area that combines political science and
process mining. In our case study, we analyze legislative processes of three
German state parliaments and generate insights into their differences and best
practices. We provide a discussion of the relevance of our results that are
based on knowledge exchange with a political scientist and a domain expert from
the German federal parliament.

</details>


### [45] [Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching](https://arxiv.org/abs/2508.10460)
*Wei Tian,Jieming Shi,Man Lung Yiu*

Main category: cs.DB

TL;DR: 论文提出了TRMMA和MMA两种方法，分别用于低采样率轨迹的恢复和地图匹配，旨在提高稀疏轨迹数据的质量。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的轨迹数据通常稀疏且与路网不对齐，许多应用需要高质量数据以获得最佳性能。

Method: MMA首先通过分类任务将GPS点映射到路网的候选段，TRMMA基于MMA的结果推断缺失点并生成高采样轨迹。

Result: TRMMA和MMA在四个大型真实数据集上的实验表明，其性能显著优于现有方法。

Conclusion: TRMMA和MMA能高效且显著地提升稀疏轨迹数据的质量，适用于轨迹恢复和地图匹配任务。

Abstract: Real-world trajectories are often sparse with low-sampling rates (i.e., long
intervals between consecutive GPS points) and misaligned with road networks,
yet many applications demand high-quality data for optimal performance. To
improve data quality with sparse trajectories as input, we systematically study
two related research problems: trajectory recovery on road network, which aims
to infer missing points to recover high-sampling trajectories, and map
matching, which aims to map GPS points to road segments to determine underlying
routes. In this paper, we present efficient methods TRMMA and MMA for accurate
trajectory recovery and map matching, respectively, where MMA serves as the
first step of TRMMA. In MMA, we carefully formulate a classification task to
map a GPS point from sparse trajectories to a road segment over a small
candidate segment set, rather than the entire road network. We develop
techniques in MMA to generate effective embeddings that capture the patterns of
GPS data, directional information, and road segments, to accurately align
sparse trajectories to routes. For trajectory recovery, TRMMA focuses on the
segments in the route returned by MMA to infer missing points with position
ratios on road segments, producing high-sampling trajectories efficiently by
avoiding evaluation of all road segments. Specifically, in TRMMA, we design a
dual-transformer encoding process to cohesively capture latent patterns in
trajectories and routes, and an effective decoding technique to sequentially
predict the position ratios and road segments of missing points. We conduct
extensive experiments to compare TRMMA and MMA with numerous existing methods
for trajectory recovery and map matching, respectively, on 4 large real-world
datasets. TRMMA and MMA consistently achieve the best result quality, often by
a significant margin.

</details>


### [46] [Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria](https://arxiv.org/abs/2508.10504)
*Zhliang Xiang,Meghyn Bienvenu,Gianluca Cima,Víctor Gutiérrez-Basulto,Yazmín Ibáñez-García*

Main category: cs.DB

TL;DR: ASPEN+扩展了ASPEN系统，增加了局部合并和新优化标准的功能，以提升集体实体解析的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的ASPEN系统仅支持全局合并，但在实际应用中局部合并更合适，例如不同实例的同名可能需要匹配不同实体。

Method: ASPEN+引入了局部合并和新的优化标准（如最小化规则违反或最大化支持合并的规则数量），并进行了形式化和计算分析。

Result: 在真实数据集上的实验表明，局部合并和新优化标准显著提高了准确性和运行效率。

Conclusion: ASPEN+通过支持局部合并和引入新优化标准，有效提升了集体实体解析的性能。

Abstract: In this paper, we present ASPEN+, which extends an existing ASP-based system,
ASPEN,for collective entity resolution with two important functionalities:
support for local merges and new optimality criteria for preferred solutions.
Indeed, ASPEN only supports so-called global merges of entity-referring
constants (e.g. author ids), in which all occurrences of matched constants are
treated as equivalent and merged accordingly. However, it has been argued that
when resolving data values, local merges are often more appropriate, as e.g.
some instances of 'J. Lee' may refer to 'Joy Lee', while others should be
matched with 'Jake Lee'. In addition to allowing such local merges, ASPEN+
offers new optimality criteria for selecting solutions, such as minimizing rule
violations or maximising the number of rules supporting a merge. Our main
contributions are thus (1) the formalisation and computational analysis of
various notions of optimal solution, and (2) an extensive experimental
evaluation on real-world datasets, demonstrating the effect of local merges and
the new optimality criteria on both accuracy and runtime.

</details>


### [47] [Emerging Skycube](https://arxiv.org/abs/2508.10516)
*Mickaël Martin Nevot*

Main category: cs.DB

TL;DR: 论文提出了一种结合多准则决策分析和趋势逆转发现的方法，通过引入Emerging Skycube概念，有效提取全局最优数据，并优化计算和存储效率。


<details>
  <summary>Details</summary>
Motivation: 现有数据库管理系统缺乏集成解决方案来处理多准则决策分析中的复杂数据需求，特别是在需要多属性的情况下。

Method: 提出Emerging Skycube概念，结合Skycube和新兴数据立方体，并通过两种连续的减少方法来节省计算时间和存储空间。

Result: 实现了在减少计算量和存储需求的同时，仍能提取出非支配数据，并观察其演化趋势。

Conclusion: Emerging Skycube为多准则决策分析提供了一种高效的解决方案，具有实际应用潜力。

Abstract: Combining multi-criteria decision analysis and trend reversal discovery make
it possible to extract globally optimal, or non-dominated, data in relation to
several criteria, and then to observe their evolution according to a
decision-making property. Thus, we introduce Emerging Skycube, a concept
associating Skycube and emerging datacube. As far as we know, no
DBMS-integrated solution exists to compute an emerging Skycube, and hence
taking advantage of ROLAP analysis tools. An emerging datacube has only one
measure: we propose to use several to comply to multi-criteria decision
analysis constraints which requires multiple attributes. A datacube is
expensive to compute. An emerging datacube is about twice as expensive. On the
other hand, an emerging Skycube is cheaper as the trend reversal is computed
after two Skycube calculations, which considerably reduces the relation volume
in comparison with the initial one. It is possible to save even more computing
time and storage space. To this end, we propose two successive reductions.
First, a Skycube lossless partial materialisation using Skylines concepts
lattice, based on the agree concepts lattice and partitions lattice. Then,
either the closed emerging Skycube for an information-loss reduction, or the
closed emerging L-Skycube for a smaller but lossless reduction.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [48] [DiffAxE: Diffusion-driven Hardware Accelerator Generation and Design Space Exploration](https://arxiv.org/abs/2508.10303)
*Arkapravo Ghosh,Abhishek Moitra,Abhiroop Bhattacharjee,Ruokai Yin,Priyadarshini Panda*

Main category: cs.AR

TL;DR: 论文提出了一种基于生成的硬件设计空间探索方法，通过建模为1-D图像生成，大幅提升了在大规模、非凸设计空间中的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 随着AI工作负载（如DNN和LLM）的复杂性和规模增长，传统的设计空间探索方法在效率和准确性上难以应对O(10^17)规模的复杂空间。

Method: 采用生成模型将硬件设计建模为1-D图像合成，以目标性能为条件，高效学习非可微、非双射的硬件-性能映射关系。

Result: 在O(10^17)设计空间中，生成误差比贝叶斯优化低0.86%，速度提升17000倍；结构化DSE中，能耗延迟积（EDP）降低9.8%，性能提升6%，搜索速度最高提升1312倍。

Conclusion: 该方法显著优于现有优化方法，尤其是在大规模复杂设计空间中，为AI硬件加速器设计提供了高效且精确的解决方案。

Abstract: Design space exploration (DSE) is critical for developing optimized hardware
architectures, especially for AI workloads such as deep neural networks (DNNs)
and large language models (LLMs), which require specialized acceleration. As
model complexity grows, accelerator design spaces have expanded to O(10^17),
becoming highly irregular, non-convex, and exhibiting many-to-one mappings from
design configurations to performance metrics. This complexity renders direct
inverse derivation infeasible and necessitates heuristic or sampling-based
optimization. Conventional methods - including Bayesian optimization, gradient
descent, reinforcement learning, and genetic algorithms - depend on iterative
sampling, resulting in long runtimes and sensitivity to initialization. Deep
learning-based approaches have reframed DSE as classification using
recommendation models, but remain limited to small-scale (O(10^3)), less
complex design spaces. To overcome these constraints, we propose a generative
approach that models hardware design as 1-D image synthesis conditioned on
target performance, enabling efficient learning of non-differentiable,
non-bijective hardware-performance mappings. Our framework achieves 0.86% lower
generation error than Bayesian optimization with a 17000x speedup, and
outperforms GANDSE with 30% lower error at only 1.83x slower search. We further
extend the method to a structured DSE setting, attaining 9.8% lower
energy-delay product (EDP) and 6% higher performance, with up to 145.6x and
1312x faster search compared to existing optimization methods on O(10^17)
design spaces. For LLM inference, our method achieves 3.37x and 7.75x lower EDP
on a 32nm ASIC and Xilinx Ultrascale+ VPU13 FPGA, respectively, compared to the
state-of-the-art DOSA framework.

</details>


### [49] [AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design](https://arxiv.org/abs/2508.10409)
*Zihao Chen,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Xinyi Yang,Mingjie Zhou,Zhuoyao Du,Xu Yan,Zhouyang Wu,Zhenyu Xu,Jiangli Huang,Li Shang,Xuan Zeng,Fan Yang*

Main category: cs.AR

TL;DR: AnalogSeeker是一个开源的基础语言模型，旨在整合模拟电路设计的领域知识并提供设计辅助。通过领域知识蒸馏和定制训练方法，模型在知识评估基准上表现优异，并在实际设计中有效。


<details>
  <summary>Details</summary>
Motivation: 解决模拟电路设计领域数据稀缺和知识复杂性的问题，提供开源工具以支持研究和设计。

Method: 采用领域知识框架收集语料，通过多代理框架蒸馏知识为问答对，并使用定制化监督微调算法训练模型。

Result: 在AMSBench-TQA基准上达到85.04%准确率，比原始模型提升15.67%，并在实际设计中表现良好。

Conclusion: AnalogSeeker通过数据策略和训练方法改进，成为模拟电路设计领域的有效工具，并开源供研究使用。

Abstract: In this paper, we propose AnalogSeeker, an effort toward an open-source
foundation language model for analog circuit design, with the aim of
integrating domain knowledge and giving design assistance. To overcome the
scarcity of data in this field, we employ a corpus collection strategy based on
the domain knowledge framework of analog circuits. High-quality, accessible
textbooks across relevant subfields are systematically curated and cleaned into
a textual domain corpus. To address the complexity of knowledge of analog
circuits, we introduce a granular domain knowledge distillation method. Raw,
unlabeled domain corpus is decomposed into typical, granular learning nodes,
where a multi-agent framework distills implicit knowledge embedded in
unstructured text into question-answer data pairs with detailed reasoning
processes, yielding a fine-grained, learnable dataset for fine-tuning. To
address the unexplored challenges in training analog circuit foundation models,
we explore and share our training methods through both theoretical analysis and
experimental validation. We finally establish a fine-tuning-centric training
paradigm, customizing and implementing a neighborhood self-constrained
supervised fine-tuning algorithm. This approach enhances training outcomes by
constraining the perturbation magnitude between the model's output
distributions before and after training. In practice, we train the
Qwen2.5-32B-Instruct model to obtain AnalogSeeker, which achieves 85.04%
accuracy on AMSBench-TQA, the analog circuit knowledge evaluation benchmark,
with a 15.67% point improvement over the original model and is competitive with
mainstream commercial models. Furthermore, AnalogSeeker also shows
effectiveness in the downstream operational amplifier design task. AnalogSeeker
is open-sourced at https://huggingface.co/analogllm/analogseeker for research
use.

</details>


### [50] [THERMOS: Thermally-Aware Multi-Objective Scheduling of AI Workloads on Heterogeneous Multi-Chiplet PIM Architectures](https://arxiv.org/abs/2508.10691)
*Alish Kanani,Lukas Pfromm,Harsh Sharma,Janardhan Rao Doppa,Partha Pratim Pande,Umit Y. Ogras*

Main category: cs.AR

TL;DR: THERMOS是一个针对异构多芯片PIM架构的AI工作负载调度框架，通过多目标强化学习实现性能、能耗和热管理的优化。


<details>
  <summary>Details</summary>
Motivation: 异构芯片PIM架构虽然有潜力提升AI推理的性能和能效，但动态负载特性和功耗限制使其调度复杂，需要智能解决方案。

Method: 开发THERMOS框架，采用多目标强化学习（MORL）策略，动态优化执行时间、能耗及热管理目标。

Result: 评估显示，THERMOS比基线算法快89%、节能57%，且运行时和能耗开销极低。

Conclusion: THERMOS为异构PIM架构的高效AI负载调度提供了实用且高效的解决方案。

Abstract: Chiplet-based integration enables large-scale systems that combine diverse
technologies, enabling higher yield, lower costs, and scalability, making them
well-suited to AI workloads. Processing-in-Memory (PIM) has emerged as a
promising solution for AI inference, leveraging technologies such as ReRAM,
SRAM, and FeFET, each offering unique advantages and trade-offs. A
heterogeneous chiplet-based PIM architecture can harness the complementary
strengths of these technologies to enable higher performance and energy
efficiency. However, scheduling AI workloads across such a heterogeneous system
is challenging due to competing performance objectives, dynamic workload
characteristics, and power and thermal constraints. To address this need, we
propose THERMOS, a thermally-aware, multi-objective scheduling framework for AI
workloads on heterogeneous multi-chiplet PIM architectures. THERMOS trains a
single multi-objective reinforcement learning (MORL) policy that is capable of
achieving Pareto-optimal execution time, energy, or a balanced objective at
runtime, depending on the target preferences. Comprehensive evaluations show
that THERMOS achieves up to 89% faster average execution time and 57% lower
average energy consumption than baseline AI workload scheduling algorithms with
only 0.14% runtime and 0.022% energy overhead.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [51] [DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality](https://arxiv.org/abs/2508.10605)
*Xinyi Wang,Angeliki Katsenou,David Bull*

Main category: eess.IV

TL;DR: 提出了一种基于时空碎片化的NR-VQA模型，利用帧间差异分析质量敏感区域，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 用户生成视频内容（UGC）的快速增长推动了无参考（NR）视频质量评估（VQA）研究的需求，该方法在社交媒体和流媒体应用中至关重要。

Method: 通过多层次的帧间差异分析（帧、块、碎片帧），整合全局和局部信息，提取2D和3D特征。

Result: 在五个UGC数据集上表现优异（DIVA-VQA-L:0.898，DIVA-VQA-B:0.886），运行复杂度低。

Conclusion: 提出的方法在性能与效率上均优于现有NR-VQA模型，代码与模型已开源。

Abstract: The rapid growth of user-generated (video) content (UGC) has driven increased
demand for research on no-reference (NR) perceptual video quality assessment
(VQA). NR-VQA is a key component for large-scale video quality monitoring in
social media and streaming applications where a pristine reference is not
available. This paper proposes a novel NR-VQA model based on spatio-temporal
fragmentation driven by inter-frame variations. By leveraging these inter-frame
differences, the model progressively analyses quality-sensitive regions at
multiple levels: frames, patches, and fragmented frames. It integrates frames,
fragmented residuals, and fragmented frames aligned with residuals to
effectively capture global and local information. The model extracts both 2D
and 3D features in order to characterize these spatio-temporal variations.
Experiments conducted on five UGC datasets and against state-of-the-art models
ranked our proposed method among the top 2 in terms of average rank correlation
(DIVA-VQA-L: 0.898 and DIVA-VQA-B: 0.886). The improved performance is offered
at a low runtime complexity, with DIVA-VQA-B ranked top and DIVA-VQA-L third on
average compared to the fastest existing NR-VQA method. Code and models are
publicly available at: https://github.com/xinyiW915/DIVA-VQA.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [52] [Why Cannot Large Language Models Ever Make True Correct Reasoning?](https://arxiv.org/abs/2508.10265)
*Jingde Cheng*

Main category: cs.AI

TL;DR: 该论文认为大语言模型（LLMs）的“理解能力”和“推理能力”是误解，指出其工作原理存在本质限制，无法实现真正的推理能力。


<details>
  <summary>Details</summary>
Motivation: 作者旨在澄清LLMs的所谓“理解”和“推理”能力只是人们的错觉，并揭示其本质的工作原理限制。

Method: 通过分析LLMs的基本工作原理，指出其无法实现真正的推理。

Result: 论证了LLMs在本质上缺乏真正的理解与推理能力。

Conclusion: LLMs因其工作原理的限制，无法具备真正的推理能力。

Abstract: Recently, with the application progress of AIGC tools based on large language
models (LLMs), led by ChatGPT, many AI experts and more non-professionals are
trumpeting the "understanding ability" and "reasoning ability" of the LLMs. The
present author considers that the so-called "understanding ability" and
"reasoning ability" of LLMs are just illusions of those people who with vague
concepts. In fact, the LLMs can never have the true understanding ability and
true reasoning ability. This paper intents to explain that, because the
essential limitations of their working principle, the LLMs can never have the
ability of true correct reasoning.

</details>


### [53] [Agentic Design Review System](https://arxiv.org/abs/2508.10745)
*Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种基于多代理协作的Agentic设计评审系统，结合图匹配和提示扩展方法，有效评估图形设计并生成实用反馈。


<details>
  <summary>Details</summary>
Motivation: 现有图形设计评估需要综合多个专家评审的反馈，但缺乏系统化的方法。

Method: 提出AgenticDRS，通过协作代理和元代理分析设计，采用图匹配和提示扩展方法使代理更具设计意识。

Result: 实验评估证明AgenticDRS优于现有基线，能有效评估设计并提供实用反馈。

Conclusion: 本研究为图形设计评估提供了实用但尚未充分探索的研究方向。

Abstract: Evaluating graphic designs involves assessing it from multiple facets like
alignment, composition, aesthetics and color choices. Evaluating designs in a
holistic way involves aggregating feedback from individual expert reviewers.
Towards this, we propose an Agentic Design Review System (AgenticDRS), where
multiple agents collaboratively analyze a design, orchestrated by a meta-agent.
A novel in-context exemplar selection approach based on graph matching and a
unique prompt expansion method plays central role towards making each agent
design aware. Towards evaluating this framework, we propose DRS-BENCH
benchmark. Thorough experimental evaluation against state-of-the-art baselines
adapted to the problem setup, backed-up with critical ablation experiments
brings out the efficacy of Agentic-DRS in evaluating graphic designs and
generating actionable feedback. We hope that this work will attract attention
to this pragmatic, yet under-explored research direction.

</details>


### [54] [Modeling Human Responses to Multimodal AI Content](https://arxiv.org/abs/2508.10769)
*Zhiqi Shen,Shaojing Fan,Danni Xu,Terence Sim,Mohan Kankanhalli*

Main category: cs.AI

TL;DR: 论文通过MhAIM数据集和T-Lens系统，研究了人类对AI生成内容的反应，提出了新指标和工具，以应对AI驱动错误信息的风险。


<details>
  <summary>Details</summary>
Motivation: 研究AI生成内容对人类认知和行为的影响，尤其是在交易或股票市场等领域，预测用户反应比验证事实准确性更重要。

Method: 引入包含154,552条在线帖子（111,153条为AI生成）的MhAIM数据集，提出信任度、影响力和开放性三个新指标，开发了基于LLM的T-Lens系统，其核心是HR-MCP协议。

Result: 人类在同时看到文本和视觉内容时更易识别AI生成内容，尤其是两者不一致时。T-Lens系统能更好地预测和适应用户反应。

Conclusion: 研究为提升LLM的人类意识能力提供了实用工具和实证见解，有助于减轻AI驱动错误信息的风险。

Abstract: As AI-generated content becomes widespread, so does the risk of
misinformation. While prior research has primarily focused on identifying
whether content is authentic, much less is known about how such content
influences human perception and behavior. In domains like trading or the stock
market, predicting how people react (e.g., whether a news post will go viral),
can be more critical than verifying its factual accuracy. To address this, we
take a human-centered approach and introduce the MhAIM Dataset, which contains
154,552 online posts (111,153 of them AI-generated), enabling large-scale
analysis of how people respond to AI-generated content. Our human study reveals
that people are better at identifying AI content when posts include both text
and visuals, particularly when inconsistencies exist between the two. We
propose three new metrics: trustworthiness, impact, and openness, to quantify
how users judge and engage with online content. We present T-Lens, an LLM-based
agent system designed to answer user queries by incorporating predicted human
responses to multimodal information. At its core is HR-MCP (Human Response
Model Context Protocol), built on the standardized Model Context Protocol
(MCP), enabling seamless integration with any LLM. This integration allows
T-Lens to better align with human reactions, enhancing both interpretability
and interaction capabilities. Our work provides empirical insights and
practical tools to equip LLMs with human-awareness capabilities. By
highlighting the complex interplay among AI, human cognition, and information
reception, our findings suggest actionable strategies for mitigating the risks
of AI-driven misinformation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [55] [Enabling Generic Robot Skill Implementation Using Object Oriented Programming](https://arxiv.org/abs/2508.10497)
*Abdullah Farrukh,Achim Wagner,Martin Ruskowski*

Main category: cs.RO

TL;DR: 本文提出了一种简化现代机器人系统接口的软件框架，旨在降低部署机器人系统的复杂性，特别针对中小企业和研究人员。


<details>
  <summary>Details</summary>
Motivation: 中小企业和研究人员在缺乏机器人专业知识的情况下，难以实现和维护机器人系统。依赖外部集成商可能导致供应商锁定和外部依赖问题。

Method: 通过抽象层统一不同制造商和型号的机器人接口，使用Python实现原型，应用于包含Yaskawa Motoman GP4的拣选单元。

Result: 提出的框架有效减少了部署机器人系统的复杂性，为中小企业和研究人员提供了便利。

Conclusion: 该软件框架简化了机器人系统的接口和部署过程，有助于降低对专业知识和外部依赖的需求。

Abstract: Developing robotic algorithms and integrating a robotic subsystem into a
larger system can be a difficult task. Particularly in small and medium-sized
enterprises (SMEs) where robotics expertise is lacking, implementing,
maintaining and developing robotic systems can be a challenge. As a result,
many companies rely on external expertise through system integrators, which, in
some cases, can lead to vendor lock-in and external dependency. In the academic
research on intelligent manufacturing systems, robots play a critical role in
the design of robust autonomous systems. Similar challenges are faced by
researchers who want to use robotic systems as a component in a larger smart
system, without having to deal with the complexity and vastness of the robot
interfaces in detail. In this paper, we propose a software framework that
reduces the effort required to deploy a working robotic system. The focus is
solely on providing a concept for simplifying the different interfaces of a
modern robot system and using an abstraction layer for different manufacturers
and models. The Python programming language is used to implement a prototype of
the concept. The target system is a bin-picking cell containing a Yaskawa
Motoman GP4.

</details>


### [56] [Why Report Failed Interactions With Robots?! Towards Vignette-based Interaction Quality](https://arxiv.org/abs/2508.10603)
*Agnes Axelsson,Merle Reimann,Ronald Cumbal,Hannah Pelikan,Divesh Lala*

Main category: cs.RO

TL;DR: 该论文提出使用民族志小故事（vignettes）来揭示人机交互（HRI）中的失败案例，尤其是研究中常被忽略的失败情况，并提倡将其作为现有交互评估方法的补充。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLMs）提升了人机交互质量，但与人人交互相比仍存在不足。由于失败的性质和严重性依赖上下文，难以普遍化。

Method: 作者提出使用民族志小故事（vignettes）来记录失败案例，并以个人经历为基础编写小故事，强调其多学科视角的优势。

Result: 小故事能清晰展示失败、促进机器人能力的透明度，并记录研究中未提及的意外行为。

Conclusion: 建议在HRI研究中广泛使用小故事，以补充现有评估方法。

Abstract: Although the quality of human-robot interactions has improved with the advent
of LLMs, there are still various factors that cause systems to be sub-optimal
when compared to human-human interactions. The nature and criticality of
failures are often dependent on the context of the interaction and so cannot be
generalized across the wide range of scenarios and experiments which have been
implemented in HRI research. In this work we propose the use of a technique
overlooked in the field of HRI, ethnographic vignettes, to clearly highlight
these failures, particularly those that are rarely documented. We describe the
methodology behind the process of writing vignettes and create our own based on
our personal experiences with failures in HRI systems. We emphasize the
strength of vignettes as the ability to communicate failures from a
multi-disciplinary perspective, promote transparency about the capabilities of
robots, and document unexpected behaviours which would otherwise be omitted
from research reports. We encourage the use of vignettes to augment existing
interaction evaluation methods.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [57] [Puppeteer: Rig and Animate Your 3D Models](https://arxiv.org/abs/2508.10898)
*Chaoyue Song,Xiu Li,Fan Yang,Zhongcong Xu,Jiacheng Wei,Fayao Liu,Jiashi Feng,Guosheng Lin,Jianfeng Zhang*

Main category: cs.CV

TL;DR: 摘要介绍了Puppeteer框架，一种用于自动化绑定和动画3D模型的方法，通过预测骨骼结构、皮肤权重和优化动画流程，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现代交互应用需要动态3D内容，但静态3D模型的动画转化仍依赖专家干预，成为内容创作的瓶颈。

Method: Puppeteer通过自回归变压器预测骨骼结构，结合注意力架构推断皮肤权重，并利用基于优化的动画流程生成高质量动画。

Result: 实验表明，该方法在骨骼预测和皮肤权重质量上显著优于现有技术，且能处理多样化的3D内容。

Conclusion: Puppeteer为自动化3D动画生成提供了高效且高质量的解决方案。

Abstract: Modern interactive applications increasingly demand dynamic 3D content, yet
the transformation of static 3D models into animated assets constitutes a
significant bottleneck in content creation pipelines. While recent advances in
generative AI have revolutionized static 3D model creation, rigging and
animation continue to depend heavily on expert intervention. We present
Puppeteer, a comprehensive framework that addresses both automatic rigging and
animation for diverse 3D objects. Our system first predicts plausible skeletal
structures via an auto-regressive transformer that introduces a joint-based
tokenization strategy for compact representation and a hierarchical ordering
methodology with stochastic perturbation that enhances bidirectional learning
capabilities. It then infers skinning weights via an attention-based
architecture incorporating topology-aware joint attention that explicitly
encodes inter-joint relationships based on skeletal graph distances. Finally,
we complement these rigging advances with a differentiable optimization-based
animation pipeline that generates stable, high-fidelity animations while being
computationally more efficient than existing approaches. Extensive evaluations
across multiple benchmarks demonstrate that our method significantly
outperforms state-of-the-art techniques in both skeletal prediction accuracy
and skinning quality. The system robustly processes diverse 3D content, ranging
from professionally designed game assets to AI-generated shapes, producing
temporally coherent animations that eliminate the jittering issues common in
existing methods.

</details>


### [58] [Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model](https://arxiv.org/abs/2508.10156)
*Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann*

Main category: cs.CV

TL;DR: 研究探讨了将真实图像与合成图像结合使用是否能提升西瓜病害分类模型的性能，结果表明混合使用效果最佳。


<details>
  <summary>Details</summary>
Motivation: 评估生成式人工智能（GenAI）模型生成的合成图像在西瓜病害分类中的有效性，以减少对资源密集型实地数据收集的依赖。

Method: 采用EfficientNetV2-L模型，结合增强微调和迁移学习技术，训练五组不同比例的真实与合成图像数据集（H0-H4）。

Result: 混合使用少量真实图像与大量合成图像（H3-H4）显著提升了模型的F1分数（从0.65到1.00），优于仅使用真实或合成图像。

Conclusion: 单独使用合成图像不足以替代真实图像，混合使用两者可最大化作物病害分类模型的性能。

Abstract: The current advancements in generative artificial intelligence (GenAI) models
have paved the way for new possibilities for generating high-resolution
synthetic images, thereby offering a promising alternative to traditional image
acquisition for training computer vision models in agriculture. In the context
of crop disease diagnosis, GenAI models are being used to create synthetic
images of various diseases, potentially facilitating model creation and
reducing the dependency on resource-intensive in-field data collection.
However, limited research has been conducted on evaluating the effectiveness of
integrating real with synthetic images to improve disease classification
performance. Therefore, this study aims to investigate whether combining a
limited number of real images with synthetic images can enhance the prediction
accuracy of an EfficientNetV2-L model for classifying watermelon
\textit{(Citrullus lanatus)} diseases. The training dataset was divided into
five treatments: H0 (only real images), H1 (only synthetic images), H2 (1:1
real-to-synthetic), H3 (1:10 real-to-synthetic), and H4 (H3 + random images to
improve variability and model generalization). All treatments were trained
using a custom EfficientNetV2-L architecture with enhanced fine-tuning and
transfer learning techniques. Models trained on H2, H3, and H4 treatments
demonstrated high precision, recall, and F1-score metrics. Additionally, the
weighted F1-score increased from 0.65 (on H0) to 1.00 (on H3-H4) signifying
that the addition of a small number of real images with a considerable volume
of synthetic images improved model performance and generalizability. Overall,
this validates the findings that synthetic images alone cannot adequately
substitute for real images; instead, both must be used in a hybrid manner to
maximize model performance for crop disease classification.

</details>


### [59] [SynSpill: Improved Industrial Spill Detection With Synthetic Data](https://arxiv.org/abs/2508.10171)
*Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas*

Main category: cs.CV

TL;DR: 论文提出了一种利用高质量合成数据生成管道的方法，来解决大规模视觉语言模型（VLMs）在工业泄漏检测等小众、安全关键领域性能下降的问题。通过参数高效微调（PEFT），合成数据显著提升了YOLO和DETR等目标检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 工业泄漏检测等领域的稀缺性和数据敏感性导致传统微调方法不可行，需要找到一种高效且可扩展的解决方案。

Method: 引入了一个基于合成数据生成的框架，并通过PEFT微调VLMs和对象检测器。

Result: 合成数据（SynSpill数据集）显著提升了VLMs和检测器的性能，尤其是在未见过的泄漏场景中。

Conclusion: 高保真合成数据可以有效弥合安全关键应用中的领域差距，结合轻量级适配，为工业环境中视觉系统的部署提供了经济高效的解决方案。

Abstract: Large-scale Vision-Language Models (VLMs) have transformed general-purpose
visual recognition through strong zero-shot capabilities. However, their
performance degrades significantly in niche, safety-critical domains such as
industrial spill detection, where hazardous events are rare, sensitive, and
difficult to annotate. This scarcity -- driven by privacy concerns, data
sensitivity, and the infrequency of real incidents -- renders conventional
fine-tuning of detectors infeasible for most industrial settings.
  We address this challenge by introducing a scalable framework centered on a
high-quality synthetic data generation pipeline. We demonstrate that this
synthetic corpus enables effective Parameter-Efficient Fine-Tuning (PEFT) of
VLMs and substantially boosts the performance of state-of-the-art object
detectors such as YOLO and DETR. Notably, in the absence of synthetic data
(SynSpill dataset), VLMs still generalize better to unseen spill scenarios than
these detectors. When SynSpill is used, both VLMs and detectors achieve marked
improvements, with their performance becoming comparable.
  Our results underscore that high-fidelity synthetic data is a powerful means
to bridge the domain gap in safety-critical applications. The combination of
synthetic generation and lightweight adaptation offers a cost-effective,
scalable pathway for deploying vision systems in industrial environments where
real data is scarce/impractical to obtain.
  Project Page: https://synspill.vercel.app

</details>


### [60] [Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones](https://arxiv.org/abs/2508.10268)
*Yujie Zhao,Jiabei Zeng,Shiguang Shan*

Main category: cs.CV

TL;DR: 本文提出了一种动态校准策略，通过用户在移动设备时注视校准点，引入头部姿态变化，从而提升基于外观的凝视点（PoG）估计的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有凝视点估计方法因个体差异和头部姿态变化导致泛化能力不足，需通过校准提升准确性。

Method: 构建MobilePoG基准数据集，分析校准点和头部姿态多样性对估计准确性的影响，提出动态校准策略。

Result: 实验表明，校准时引入头部姿态变化能显著提升估计器对姿态变化的鲁棒性。

Conclusion: 动态校准策略在保证用户友好性的同时，显著提升了凝视点估计器的性能。

Abstract: Although appearance-based point-of-gaze (PoG) estimation has improved, the
estimators still struggle to generalize across individuals due to personal
differences. Therefore, person-specific calibration is required for accurate
PoG estimation. However, calibrated PoG estimators are often sensitive to head
pose variations. To address this, we investigate the key factors influencing
calibrated estimators and explore pose-robust calibration strategies.
Specifically, we first construct a benchmark, MobilePoG, which includes facial
images from 32 individuals focusing on designated points under either fixed or
continuously changing head poses. Using this benchmark, we systematically
analyze how the diversity of calibration points and head poses influences
estimation accuracy. Our experiments show that introducing a wider range of
head poses during calibration improves the estimator's ability to handle pose
variation. Building on this insight, we propose a dynamic calibration strategy
in which users fixate on calibration points while moving their phones. This
strategy naturally introduces head pose variation during a user-friendly and
efficient calibration process, ultimately producing a better calibrated PoG
estimator that is less sensitive to head pose variations than those using
conventional calibration strategies. Codes and datasets are available at our
project page.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [61] [The phi-Process: Operator-Algebraic Embeddings of Possibilities, Transfinite Stabilization, and a Quantitative Application to Sensory Depletion](https://arxiv.org/abs/2508.10650)
*Bugra Kilictas,Faruk Alpay*

Main category: math.FA

TL;DR: 本文提出了一种处理可能性嵌入的transfinite Phi过程，证明了其确定性、稳定性和组合性，并给出了应用示例和反例。


<details>
  <summary>Details</summary>
Motivation: 研究如何在结构化状态空间（如完全格、Banach和Hilbert空间、正交模格）中形式化处理可能性嵌入的算子，并探讨其动态行为和定量应用。

Method: 通过形式化transfinite Phi过程，证明其确定性引理、序数稳定定理和Riesz投影乘积定理，并研究其组合性和闭合性。

Result: 建立了确定性全局动态、序数稳定性和组合性定律，并成功应用于感官耗竭的定量模型。

Conclusion: 过程在不同条件下表现稳定且可组合，证明了其在数学建模和实际应用中的潜力。

Abstract: We formalize a transfinite Phi process that treats all possibility embeddings
as operators on structured state spaces including complete lattices, Banach and
Hilbert spaces, and orthomodular lattices. We prove a determinization lemma
showing that lifting to sets or distributions yields a deterministic global
dynamic, an ordinal stabilization theorem sending operator transforms to the
fixed subspace by stage omega under normal spectral contraction, and a product
of Riesz projections theorem for commuting layers. We establish a
compositionality law for lifted maps, show closure of Phi packings, and present
a quantitative application to sensory depletion that models tissue removal as a
projection and derives strict decreases in the attainable fixed point under
minimal monotonicity and positivity assumptions. We also state measurable
conditions for probabilistic lifts, give explicit non normal and non commuting
counterexamples, and provide finite dimensional and stochastic witnesses
together with per theorem scope tables and a small reproducible code appendix.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [62] [zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature](https://arxiv.org/abs/2508.09995)
*Rui Zhou,Haohui Ma,Tianle Xin,Lixin Zou,Qiuyue Hu,Hongxi Cheng,Mingzhi Lin,Jingjing Guo,Sheng Wang,Guoqing Zhang,Yanjie Wei,Liangzhen Zheng*

Main category: q-bio.BM

TL;DR: zERExtractor是一个自动化平台，用于从文献中提取酶催化反应和活性数据，整合了多种AI模型和人类专家修正，显著提升了数据提取的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于酶动力学文献的快速增长超过了数据库的整理能力，阻碍了AI驱动的建模和知识发现，因此开发了zERExtractor来解决这一问题。

Method: 采用模块化架构，结合深度学习和LLM等先进模型，支持OCR、语义实体识别等功能，并通过主动学习和专家验证优化系统。

Result: 在表识别、分子图像解析和关系提取等方面表现优异，准确率分别达到89.9%、99.1%和94.2%。

Conclusion: zERExtractor填补了酶动力学数据空白，为未来的AI建模和生化知识发现奠定了基础。

Abstract: The rapid expansion of enzyme kinetics literature has outpaced the curation
capabilities of major biochemical databases, creating a substantial barrier to
AI-driven modeling and knowledge discovery. We present zERExtractor, an
automated and extensible platform for comprehensive extraction of
enzyme-catalyzed reaction and activity data from scientific literature.
zERExtractor features a unified, modular architecture that supports
plug-and-play integration of state-of-the-art models, including large language
models (LLMs), as interchangeable components, enabling continuous system
evolution alongside advances in AI. Our pipeline combines domain-adapted deep
learning, advanced OCR, semantic entity recognition, and prompt-driven LLM
modules, together with human expert corrections, to extract kinetic parameters
(e.g., kcat, Km), enzyme sequences, substrate SMILES, experimental conditions,
and molecular diagrams from heterogeneous document formats. Through active
learning strategies integrating AI-assisted annotation, expert validation, and
iterative refinement, the system adapts rapidly to new data sources. We also
release a large benchmark dataset comprising over 1,000 annotated tables and
5,000 biological fields from 270 P450-related enzymology publications.
Benchmarking demonstrates that zERExtractor consistently outperforms existing
baselines in table recognition (Acc 89.9%), molecular image interpretation (up
to 99.1%), and relation extraction (accuracy 94.2%). zERExtractor bridges the
longstanding data gap in enzyme kinetics with a flexible, plugin-ready
framework and high-fidelity extraction, laying the groundwork for future
AI-powered enzyme modeling and biochemical knowledge discovery.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [63] [A Unified Evaluation Framework for Multi-Annotator Tendency Learning](https://arxiv.org/abs/2508.10393)
*Liyun Zhang,Jingcheng Ke,Shenli Fan,Xuanmeng Sha,Zheng Lian*

Main category: cs.LG

TL;DR: 论文提出了首个评估框架，用于衡量个体倾向学习方法（ITL）是否真正捕捉了标注者的标注行为模式，并提供了两个新指标：DIC和BAE。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估ITL方法是否真正捕捉标注者个体倾向并提供有意义的行为解释的框架。

Method: 提出了统一的评估框架，包括两个新指标：DIC用于量化模型捕捉标注者倾向的能力，BAE用于评估模型解释与标注者行为的对齐程度。

Result: 通过大量实验验证了所提评估框架的有效性。

Conclusion: 该框架填补了ITL方法评估的空白，并为解释性分析提供了新工具。

Abstract: Recent works have emerged in multi-annotator learning that shift focus from
Consensus-oriented Learning (CoL), which aggregates multiple annotations into a
single ground-truth prediction, to Individual Tendency Learning (ITL), which
models annotator-specific labeling behavior patterns (i.e., tendency) to
provide explanation analysis for understanding annotator decisions. However, no
evaluation framework currently exists to assess whether ITL methods truly
capture individual tendencies and provide meaningful behavioral explanations.
To address this gap, we propose the first unified evaluation framework with two
novel metrics: (1) Difference of Inter-annotator Consistency (DIC) quantifies
how well models capture annotator tendencies by comparing predicted
inter-annotator similarity structures with ground-truth; (2) Behavior Alignment
Explainability (BAE) evaluates how well model explanations reflect annotator
behavior and decision relevance by aligning explainability-derived with
ground-truth labeling similarity structures via Multidimensional Scaling (MDS).
Extensive experiments validate the effectiveness of our proposed evaluation
framework.

</details>


### [64] [Constrained Decoding of Diffusion LLMs with Context-Free Grammars](https://arxiv.org/abs/2508.10111)
*Niels Mündler,Jasper Dekoninck,Martin Vechev*

Main category: cs.LG

TL;DR: 提出了第一个针对扩散语言模型的受限解码方法，确保生成内容符合形式语言（如C++或JSON）的语法约束。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型（LLM）的概率性输出可能不符合形式语言的语法约束，现有方法不适用于扩散模型，因此需要一种新的受限解码方法。

Method: 将受限解码问题转化为可加性填充问题，进一步简化为判断目标语言与正则语言交集是否为空的任务，并提出高效算法解决。

Result: 实验表明，该方法在C++代码填充和JSON数据提取等任务中，几乎完全保证了语法正确性，同时保持了功能性。

Conclusion: 该方法为扩散模型的受限解码提供了实用且高效的解决方案。

Abstract: Large language models (LLMs) have shown promising performance across diverse
domains. Many practical applications of LLMs, such as code completion and
structured data extraction, require adherence to syntactic constraints
specified by a formal language. Yet, due to their probabilistic nature, LLM
output is not guaranteed to adhere to such formal languages. Prior work has
proposed constrained decoding as a means to restrict LLM generation to
particular formal languages. However, existing works are not applicable to the
emerging paradigm of diffusion LLMs, when used in practical scenarios such as
the generation of formally correct C++ or JSON output. In this paper we address
this challenge and present the first constrained decoding method for diffusion
models, one that can handle formal languages captured by context-free grammars.
We begin by reducing constrained decoding to the more general additive
infilling problem, which asks whether a partial output can be completed to a
valid word in the target language. This problem also naturally subsumes the
previously unaddressed multi-region infilling constrained decoding. We then
reduce this problem to the task of deciding whether the intersection of the
target language and a regular language is empty and present an efficient
algorithm to solve it for context-free languages. Empirical results on various
applications, such as C++ code infilling and structured data extraction in
JSON, demonstrate that our method achieves near-perfect syntactic correctness
while consistently preserving or improving functional correctness. Importantly,
our efficiency optimizations ensure that the computational overhead remains
practical.

</details>


### [65] [A Hierarchical IDS for Zero-Day Attack Detection in Internet of Medical Things Networks](https://arxiv.org/abs/2508.10346)
*Md Ashraf Uddin,Nam H. Chu,Reza Rafeh*

Main category: cs.LG

TL;DR: 提出了一种多层级IoMT入侵检测系统框架，能够检测零日攻击并区分已知和未知威胁，实验显示高准确率和F1分数。


<details>
  <summary>Details</summary>
Motivation: IoMT设备资源受限，传统集中式IDS不适合，可能导致延迟或隐私风险，需要一种高效且可靠的检测系统。

Method: 采用多层框架，第一层使用元学习或OCC粗略过滤流量，后续层识别攻击类型和新颖性。

Result: 在CICIoMT2024数据集上实现99.77%准确率和97.8% F1分数，第一层能高效检测零日攻击。

Conclusion: 该框架在IoMT环境中表现出色，具有强适用性和高安全性。

Abstract: The Internet of Medical Things (IoMT) is driving a healthcare revolution but
remains vulnerable to cyberattacks such as denial of service, ransomware, data
hijacking, and spoofing. These networks comprise resource constrained,
heterogeneous devices (e.g., wearable sensors, smart pills, implantables),
making traditional centralized Intrusion Detection Systems (IDSs) unsuitable
due to response delays, privacy risks, and added vulnerabilities. Centralized
IDSs require all sensors to transmit data to a central server, causing delays
or network disruptions in dense environments. Running IDSs locally on IoMT
devices is often infeasible due to limited computation, and even lightweight
IDS components remain at risk if updated models are delayed leaving them
exposed to zero-day attacks that threaten patient health and data security. We
propose a multi level IoMT IDS framework capable of detecting zero day attacks
and distinguishing between known and unknown threats. The first layer (near
Edge) filters traffic at a coarse level (attack or not) using meta-learning or
One Class Classification (OCC) with the usfAD algorithm. Subsequent layers (far
Edge, Cloud) identify attack type and novelty. Experiments on the CICIoMT2024
dataset show 99.77 percentage accuracy and 97.8 percentage F1-score. The first
layer detects zero-day attacks with high accuracy without needing new datasets,
ensuring strong applicability in IoMT environments. Additionally, the
meta-learning approach achieves high.

</details>


### [66] [Semantic Communication with Distribution Learning through Sequential Observations](https://arxiv.org/abs/2508.10350)
*Samer Lahoud,Kinda Khawam*

Main category: cs.LG

TL;DR: 该论文研究了语义通信中的分布学习问题，揭示了在未知先验情况下学习源统计量的基本条件，分析了学习速率与性能之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统语义通信优化单个意义的传输，但本文旨在解决接收端通过序列观察推断潜在意义分布的问题，特别是在先验未知的情况下。

Method: 通过证明可学习性需要有效传输矩阵的满秩条件，并量化估计误差对语义失真的影响，论文提出了理论框架。

Result: 实验验证了系统条件对学习速率和性能的关键影响，揭示了一种根本性权衡：优化即时语义性能的编码方案往往牺牲长期可学习性。

Conclusion: 该研究首次严格描述了语义通信中的统计学习，并提供了平衡即时性能与适应能力的系统设计原则。

Abstract: Semantic communication aims to convey meaning rather than bit-perfect
reproduction, representing a paradigm shift from traditional communication.
This paper investigates distribution learning in semantic communication where
receivers must infer the underlying meaning distribution through sequential
observations. While semantic communication traditionally optimizes individual
meaning transmission, we establish fundamental conditions for learning source
statistics when priors are unknown. We prove that learnability requires full
rank of the effective transmission matrix, characterize the convergence rate of
distribution estimation, and quantify how estimation errors translate to
semantic distortion. Our analysis reveals a fundamental trade-off: encoding
schemes optimized for immediate semantic performance often sacrifice long-term
learnability. Experiments on CIFAR-10 validate our theoretical framework,
demonstrating that system conditioning critically impacts both learning rate
and achievable performance. These results provide the first rigorous
characterization of statistical learning in semantic communication and offer
design principles for systems that balance immediate performance with
adaptation capability.

</details>


### [67] [EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation](https://arxiv.org/abs/2508.10474)
*Lisa Haxel,Jaivardhan Kapoor,Ulf Ziemann,Jakob H. Macke*

Main category: cs.LG

TL;DR: EDAPT通过持续模型适应消除了BCI校准需求，提高了准确性，减少了部署障碍。


<details>
  <summary>Details</summary>
Motivation: 脑机接口（BCI）因神经信号漂移和用户差异导致精度下降，需要频繁校准，影响实际应用。

Method: EDAPT先训练多用户数据的基线解码器，后通过监督微调持续个性化模型。

Result: EDAPT在三个BCI任务中表现优于静态方法，运行高效，200毫秒内更新模型。

Conclusion: EDAPT为无校准BCI提供了实用路径，减少部署障碍。

Abstract: Brain-computer interfaces (BCIs) suffer from accuracy degradation as neural
signals drift over time and vary across users, requiring frequent recalibration
that limits practical deployment. We introduce EDAPT, a task- and
model-agnostic framework that eliminates calibration through continual model
adaptation. EDAPT first trains a baseline decoder using data from multiple
users, then continually personalizes this model via supervised finetuning as
the neural patterns evolve during use. We tested EDAPT across nine datasets
covering three BCI tasks, and found that it consistently improved accuracy over
conventional, static methods. These improvements primarily stem from combining
population-level pretraining and online continual finetuning, with unsupervised
domain adaptation providing further gains on some datasets. EDAPT runs
efficiently, updating models within 200 milliseconds on consumer-grade
hardware. Finally, decoding accuracy scales with total data budget rather than
its allocation between subjects and trials. EDAPT provides a practical pathway
toward calibration-free BCIs, reducing a major barrier to BCI deployment.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [68] [Molecule Mixture Detection and Alphabet Design for Non-linear, Cross-reactive Receiver Arrays in MC](https://arxiv.org/abs/2508.10856)
*Bastian Heinlein,Kaikai Zhu,Sümeyye Carkit-Yilmaz,Sebastian Lotter,Helene M. Loos,Andrea Buettner,Yansha Deng,Robert Schober,Vahid Jamali*

Main category: eess.SP

TL;DR: 论文提出了一种适用于非线性、交叉敏感接收器的分子混合物通信检测器和字母表设计算法，通过实验验证其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有商用传感器的非线性和交叉敏感行为与理想假设不符，需要开发更实际的检测器和字母表设计方法。

Method: 提出一种基于近似最大似然检测的检测器，并结合接收器特性的字母表设计算法。

Result: 仿真实验表明，检测器性能接近数据驱动方法且无需大量训练样本；字母表设计算法优于不考虑接收器特性的方法。

Conclusion: 提出的方法为可靠的气体分子通信提供了潜在解决方案，并适用于其他化学传感器。

Abstract: Air-based molecular communication (MC) has the potential to be one of the
first MC systems to be deployed in real-world applications, enabled by existing
sensor technologies such as metal-oxide semi-conductor (MOS) sensors. However,
commercially available sensors usually exhibit non-linear and cross-reactive
behavior, contrary to the idealizing assumptions about linear and perfectly
molecule type-specific sensing often made in the MC literature. To address this
gap, we propose a detector for molecule mixture communication with a general
non-linear, cross-reactive receiver (RX) array that performs approximate
maximum likelihood detection on the sensor outputs. Additionally, we introduce
an algorithm for the design of mixture alphabets that accounts for the RX
characteristics. We evaluate our detector and alphabet design algorithm through
simulations that are based on measurements reported for two commercial MOS
sensors. Our simulations demonstrate that the proposed detector achieves
similar symbol error rates as data-driven methods without requiring large
numbers of training samples and that the alphabet design algorithm outperforms
methods that do not account for the RX characteristics. Since the proposed
detector and alphabet design algorithm are also applicable to other chemical
sensors, they pave the way for reliable air-based MC.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [69] [A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx](https://arxiv.org/abs/2508.10017)
*Rodrigo Tertulino*

Main category: cs.CR

TL;DR: 该论文提出了一种联邦学习框架，结合差分隐私和SMOTETomek技术，解决了医疗数据中的隐私和类别不平衡问题，并在心血管风险预测中取得了高实用性和隐私保护的平衡。


<details>
  <summary>Details</summary>
Motivation: 医疗数据具有隐私性和类别不平衡的特点，标准联邦学习方法无法有效处理，尤其是隐私保护和临床实用性之间的权衡问题亟待解决。

Method: 采用SMOTETomek技术处理类别不平衡，并通过优化的FedProx算法应对非独立同分布数据，同时结合差分隐私保护隐私。

Result: 优化的FedProx优于标准FedAvg，实现了隐私预算（epsilon）与召回率之间的非线性权衡，找到最优平衡点（epsilon 9.0，召回率>77%）。

Conclusion: 研究为处理实际医疗数据提供了一种有效、安全且精确的方法，为隐私保护与临床实用的权衡提供了实用方案。

Abstract: Federated Learning (FL) presents a groundbreaking approach for collaborative
health research, allowing model training on decentralized data while
safeguarding patient privacy. FL offers formal security guarantees when
combined with Differential Privacy (DP). The integration of these technologies,
however, introduces a significant trade-off between privacy and clinical
utility, a challenge further complicated by the severe class imbalance often
present in medical datasets. The research presented herein addresses these
interconnected issues through a systematic, multi-stage analysis. An FL
framework was implemented for cardiovascular risk prediction, where initial
experiments showed that standard methods struggled with imbalanced data,
resulting in a recall of zero. To overcome such a limitation, we first
integrated the hybrid Synthetic Minority Over-sampling Technique with Tomek
Links (SMOTETomek) at the client level, successfully developing a clinically
useful model. Subsequently, the framework was optimized for non-IID data using
a tuned FedProx algorithm. Our final results reveal a clear, non-linear
trade-off between the privacy budget (epsilon) and model recall, with the
optimized FedProx consistently out-performing standard FedAvg. An optimal
operational region was identified on the privacy-utility frontier, where strong
privacy guarantees (with epsilon 9.0) can be achieved while maintaining high
clinical utility (recall greater than 77%). Ultimately, our study provides a
practical methodological blueprint for creating effective, secure, and accurate
diagnostic tools that can be applied to real-world, heterogeneous healthcare
data.

</details>


### [70] [An Architecture for Distributed Digital Identities in the Physical World](https://arxiv.org/abs/2508.10185)
*René Mayrhofer,Michael Roland,Tobias Höller,Philipp Hofer,Mario Lins*

Main category: cs.CR

TL;DR: 该论文提出了一种分布式数字身份架构，用于物理世界中的交易，如开门、公共交通或跨境，解决了集中式身份管理的隐私和可用性问题。


<details>
  <summary>Details</summary>
Motivation: 集中式身份管理存在单点故障和隐私风险，需要一种去中心化的解决方案来支持安全的物理世界交易。

Method: 设计了一个结合传感器、身份机构、属性验证器和新型个人身份代理（PIA）的分布式架构，并通过协议实现完全去中心化交易。

Result: 通过形式化验证证明协议满足安全属性，概念验证实现展示了架构和协议的可行性。

Conclusion: 分布式数字身份架构在延迟可接受的场景中具有实际应用潜力。

Abstract: Digital identities are increasingly important for mediating not only digital
but also physical service transactions. Managing such identities through
centralized providers can cause both availability and privacy concerns: single
points of failure and control are ideal targets for global attacks on
technical, organizational, or legal fronts. We design, analyze, and build a
distributed digital identity architecture for physical world transactions in
common scenarios like unlocking doors, public transport, or crossing country
borders. This architecture combines (biometric and other) sensors, (established
and upcoming) identity authorities, attribute verifiers, and a new core
component we call the \emph{Personal Identity Agent (PIA)} that represents
individuals with their identity attributes in the digital domain. All
transactions are conducted in a completely decentralized manner, and the
components for which we currently assume central coordination are optional and
only used for assisting with service discovery and latency reduction. We
present a first protocol between these parties and formally verify that it
achieves relevant security properties based on a realistic threat model
including strong global adversaries. A proof-of-concept implementation
demonstrates practical feasibility of both architecture and initial protocol
for applications that can tolerate end-to-end latencies in the range of a few
seconds.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [71] [Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices](https://arxiv.org/abs/2508.10071)
*Jay L. Cunningham,Kevin Zhongyang Shao,Rock Yuren Pang,Nathaniel Mengist*

Main category: cs.CY

TL;DR: 论文研究了NLP从业者对数据公平性的认知及其面临的挑战，提出了结合技术与政策的治理建议。


<details>
  <summary>Details</summary>
Motivation: 探讨NLP从业者在数据公平性问题上的实际体验和挑战，填补研究空白。

Method: 基于2024年的问卷和焦点小组研究，分析美国NLP从业者的观点。

Result: 研究发现商业目标与公平承诺之间存在矛盾，呼吁更具参与性和问责性的数据流程。

Conclusion: 改进NLP公平性需要结构性治理改革，支持从业者能动性和社区同意。

Abstract: While research has focused on surfacing and auditing algorithmic bias to
ensure equitable AI development, less is known about how NLP practitioners -
those directly involved in dataset development, annotation, and deployment -
perceive and navigate issues of NLP data equity. This study is among the first
to center practitioners' perspectives, linking their experiences to a
multi-scalar AI governance framework and advancing participatory
recommendations that bridge technical, policy, and community domains. Drawing
on a 2024 questionnaire and focus group, we examine how U.S.-based NLP data
practitioners conceptualize fairness, contend with organizational and systemic
constraints, and engage emerging governance efforts such as the U.S. AI Bill of
Rights. Findings reveal persistent tensions between commercial objectives and
equity commitments, alongside calls for more participatory and accountable data
workflows. We critically engage debates on data diversity and diversity
washing, arguing that improving NLP equity requires structural governance
reforms that support practitioner agency and community consent.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [72] [Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry](https://arxiv.org/abs/2508.09991)
*Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji*

Main category: cs.CL

TL;DR: 本文总结了在加拿大不列颠哥伦比亚癌症登记处实施自然语言处理（NLP）模型的经验教训，强调基于业务目标定义问题、采用迭代开发方法，以及促进跨学科合作的重要性。


<details>
  <summary>Details</summary>
Motivation: 通过NLP技术从临床文档中自动化提取数据，以提高医疗保健管理的效率和患者护理质量。

Method: 采用迭代开发方法，结合跨学科协作，包括领域专家、最终用户和机器学习专家的共同设计。模型选择注重实用性和数据质量。

Result: 提供了成功实施AI/NLP解决方案的关键考量，包括问题定义、模型选择、数据质量管理和错误缓解策略。

Conclusion: 这些经验教训不仅适用于癌症登记处，也可为其他医疗保健组织在实施AI/NLP解决方案时提供指导。

Abstract: Automating data extraction from clinical documents offers significant
potential to improve efficiency in healthcare settings, yet deploying Natural
Language Processing (NLP) solutions presents practical challenges. Drawing upon
our experience implementing various NLP models for information extraction and
classification tasks at the British Columbia Cancer Registry (BCCR), this paper
shares key lessons learned throughout the project lifecycle. We emphasize the
critical importance of defining problems based on clear business objectives
rather than solely technical accuracy, adopting an iterative approach to
development, and fostering deep interdisciplinary collaboration and co-design
involving domain experts, end-users, and ML specialists from inception. Further
insights highlight the need for pragmatic model selection (including hybrid
approaches and simpler methods where appropriate), rigorous attention to data
quality (representativeness, drift, annotation), robust error mitigation
strategies involving human-in-the-loop validation and ongoing audits, and
building organizational AI literacy. These practical considerations,
generalizable beyond cancer registries, provide guidance for healthcare
organizations seeking to successfully implement AI/NLP solutions to enhance
data management processes and ultimately improve patient care and public health
outcomes.

</details>


### [73] [User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents](https://arxiv.org/abs/2508.10004)
*Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo*

Main category: cs.CL

TL;DR: 研究表明，注意力权重在生物医学文档分类中虽能提升模型性能，但其作为解释工具的实用性有限，且可视化方式对用户感知有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探讨注意力机制是否能为生物医学文献分类提供有效的解释支持，以及不同可视化方式对用户理解的影响。

Method: 通过用户研究，评估注意力权重在文档分类中的作用，并比较不同可视化格式的效果。

Result: XLNet模型分类准确，但注意力权重解释效果不佳；用户偏好直观的可视化方式（如文字亮度或背景色）。

Conclusion: 注意力权重的解释效果受可视化方式影响，未来需优化展示形式以提高实用性。

Abstract: The attention mechanism is a core component of the Transformer architecture.
Beyond improving performance, attention has been proposed as a mechanism for
explainability via attention weights, which are associated with input features
(e.g., tokens in a document). In this context, larger attention weights may
imply more relevant features for the model's prediction. In evidence-based
medicine, such explanations could support physicians' understanding and
interaction with AI systems used to categorize biomedical literature. However,
there is still no consensus on whether attention weights provide helpful
explanations. Moreover, little research has explored how visualizing attention
affects its usefulness as an explanation aid. To bridge this gap, we conducted
a user study to evaluate whether attention-based explanations support users in
biomedical document classification and whether there is a preferred way to
visualize them. The study involved medical experts from various disciplines who
classified articles based on study design (e.g., systematic reviews, broad
synthesis, randomized and non-randomized trials). Our findings show that the
Transformer model (XLNet) classified documents accurately; however, the
attention weights were not perceived as particularly helpful for explaining the
predictions. However, this perception varied significantly depending on how
attention was visualized. Contrary to Munzner's principle of visual
effectiveness, which favors precise encodings like bar length, users preferred
more intuitive formats, such as text brightness or background color. While our
results do not confirm the overall utility of attention weights for
explanation, they suggest that their perceived helpfulness is influenced by how
they are visually presented.

</details>


### [74] [PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs](https://arxiv.org/abs/2508.10028)
*Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani*

Main category: cs.CL

TL;DR: PREF是一个无需个性化参考的评估框架，通过三步流程（覆盖、偏好、评分）联合评估文本生成质量和用户对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法往往忽略用户个性化需求，PREF旨在填补这一空白。

Method: 采用三步流程：覆盖阶段生成通用准则，偏好阶段根据用户资料调整，评分阶段用LLM打分。

Result: 在PrefEval基准测试中，PREF表现优于基线，准确性更高且更符合人类判断。

Conclusion: PREF为个性化语言生成系统的可靠评估和开发奠定了基础。

Abstract: Personalised text generation is essential for user-centric information
systems, yet most evaluation methods overlook the individuality of users. We
introduce \textbf{PREF}, a \textbf{P}ersonalised \textbf{R}eference-free
\textbf{E}valuation \textbf{F}ramework that jointly measures general output
quality and user-specific alignment without requiring gold personalised
references. PREF operates in a three-step pipeline: (1) a coverage stage uses a
large language model (LLM) to generate a comprehensive, query-specific
guideline covering universal criteria such as factuality, coherence, and
completeness; (2) a preference stage re-ranks and selectively augments these
factors using the target user's profile, stated or inferred preferences, and
context, producing a personalised evaluation rubric; and (3) a scoring stage
applies an LLM judge to rate candidate answers against this rubric, ensuring
baseline adequacy while capturing subjective priorities. This separation of
coverage from preference improves robustness, transparency, and reusability,
and allows smaller models to approximate the personalised quality of larger
ones. Experiments on the PrefEval benchmark, including implicit
preference-following tasks, show that PREF achieves higher accuracy, better
calibration, and closer alignment with human judgments than strong baselines.
By enabling scalable, interpretable, and user-aligned evaluation, PREF lays the
groundwork for more reliable assessment and development of personalised
language generation systems.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [75] [An Intelligent Infrastructure as a Foundation for Modern Science](https://arxiv.org/abs/2508.10051)
*Satrajit S. Ghosh*

Main category: q-bio.NC

TL;DR: 论文提出通过动态AI生态系统改进传统科学基础设施，尤其是神经科学领域，以加速科学发现。


<details>
  <summary>Details</summary>
Motivation: 传统科学基础设施存在数据孤岛、缺乏互操作性和不可持续等问题，AI技术为变革提供了机遇。

Method: 以神经科学为例，提出动态AI生态系统，整合数据、集体利益和数字存储库原则，并制定操作指南。

Result: 呼吁全球协调、解决资金不足问题，促进人机协作，实现高效、可复制的科学研究。

Conclusion: 智能基础设施将加速科学发现并带来社会效益，为其他领域树立典范。

Abstract: Infrastructure shapes societies and scientific discovery. Traditional
scientific infrastructure, often static and fragmented, leads to issues like
data silos, lack of interoperability and reproducibility, and unsustainable
short-lived solutions. Our current technical inability and social reticence to
connect and coordinate scientific research and engineering leads to
inefficiencies and impedes progress. With AI technologies changing how we
interact with the world around us, there is an opportunity to transform
scientific processes. Neuroscience's exponential growth of multimodal and
multiscale data, and urgent clinical relevance demand an infrastructure itself
learns, coordinates, and improves. Using neuroscience as a stress test, this
perspective argues for a paradigm shift: infrastructure must evolve into a
dynamic, AI-aligned ecosystem to accelerate science. Building on several
existing principles for data, collective benefit, and digital repositories, I
recommend operational guidelines for implementing them to create this dynamic
ecosystem, aiming to foster a decentralized, self-learning, and self-correcting
system where humans and AI can collaborate seamlessly. Addressing the chronic
underfunding of scientific infrastructure, acknowledging diverse contributions
beyond publications, and coordinating global efforts are critical steps for
this transformation. By prioritizing an intelligent infrastructure as a central
scientific instrument for knowledge generation, we can overcome current
limitations, accelerate discovery, ensure reproducibility and ethical
practices, and ultimately translate neuroscientific understanding into tangible
societal benefits, setting a blueprint for other scientific domains.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [76] [Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech](https://arxiv.org/abs/2508.10332)
*Abhijit Sinha,Harishankar Kumar,Mohit Joshi,Hemant Kumar Kathania,Shrikanth Narayanan,Sudarsana Reddy Kadiri*

Main category: eess.AS

TL;DR: 论文分析了SSL模型（特别是Wav2Vec2变体）在儿童语音年龄和性别分类中的表现，发现早期层更适合捕捉说话者特征，并通过PCA进一步提升分类效果。


<details>
  <summary>Details</summary>
Motivation: 由于儿童语音在音高、发音等方面的高变异性，现有SSL模型对其年龄和性别分类能力的研究不足，因此需要深入分析层间特征。

Method: 使用PFSTAR和CMU Kids数据集，对四种Wav2Vec2变体进行分层分析，并结合PCA降低冗余。

Result: Wav2Vec2-large-lv60在CMU Kids上分别达到97.14%（年龄）和98.20%（性别），在PFSTAR上表现也显著。PCA有效提升了分类效果。

Conclusion: 研究揭示了SSL模型中说话者特征的层次分布，为儿童语音接口提供了更精准的优化方向。

Abstract: Children's speech presents challenges for age and gender classification due
to high variability in pitch, articulation, and developmental traits. While
self-supervised learning (SSL) models perform well on adult speech tasks, their
ability to encode speaker traits in children remains underexplored. This paper
presents a detailed layer-wise analysis of four Wav2Vec2 variants using the
PFSTAR and CMU Kids datasets. Results show that early layers (1-7) capture
speaker-specific cues more effectively than deeper layers, which increasingly
focus on linguistic information. Applying PCA further improves classification,
reducing redundancy and highlighting the most informative components. The
Wav2Vec2-large-lv60 model achieves 97.14% (age) and 98.20% (gender) on CMU
Kids; base-100h and large-lv60 models reach 86.05% and 95.00% on PFSTAR. These
results reveal how speaker traits are structured across SSL model depth and
support more targeted, adaptive strategies for child-aware speech interfaces.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [77] [Approximating Entanglement Based on Abstract Interpretation](https://arxiv.org/abs/2508.10056)
*Aske Nord Raahauge,Martin Bom Marchioro,Rasmus Ross Nylandsted*

Main category: quant-ph

TL;DR: 论文提出了一种静态分析方法，用于近似估计量子比特的纠缠情况，避免了精确分析的指数级慢速问题。


<details>
  <summary>Details</summary>
Motivation: 量子比特的纠缠是量子系统的关键特性，准确识别纠缠状态对于量子电路优化和算法验证至关重要。

Method: 通过扩展已有的抽象解释方法，提出了一种静态分析方法，用于近似估计量子比特的纠缠情况。

Result: 该方法被证明是可靠的，并在Standard ML中实现了具有线性时间复杂度的可扩展实现。

Conclusion: 该静态分析方法为量子程序的纠缠分析提供了高效的近似解决方案。

Abstract: Entanglement is a fundamental property of quantum systems, essential for
non-trivial quantum programs. Identifying when qubits become entangled is
critical for circuit optimization, and for arguing for the correctness of
quantum algorithms. This paper presents a static analysis method for
approximating entanglement by extending an already existing abstract
interpretation, thus avoiding the exponential slowdown of an exact analysis.
The approach is shown to be sound and an implementation is provided in Standard
ML with linear-time scalability.

</details>


### [78] [Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse](https://arxiv.org/abs/2508.10590)
*Viswak R Balaji,Samuel Punch*

Main category: quant-ph

TL;DR: 该论文通过量子计算模拟研究了质量相关退相干模型，验证了Penrose引力诱导坍塌假设的量子不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索量子叠加态的引力诱导坍塌现象，为量子力学基本原理提供实验参考。

Method: 利用Qiskit AerSimulator实现质量相关退相噪声模型，应用于GHZ态、分支质量纠缠和Grover搜索等实验。

Result: 模型生成独特的坍塌特征，可作为未来硬件实验中检测引力诱导效应的基准参考。

Conclusion: 研究为利用量子计算机测试量子力学基本问题提供了可重复协议和参考框架。

Abstract: We present a quantum computing simulation study of mass-dependent decoherence
models inspired by Penrose's gravity-induced collapse hypothesis. According to
objective reduction (OR) theory, quantum superpositions become unstable when
the gravitational self-energy difference between branches exceeds a certain
threshold, leading to a collapse time $\tau \approx \hbar / E_G$. In this work,
we implement a mass-dependent dephasing noise channel, $p(m) = 1 - e^{-k
m^{\alpha}}$, within the Qiskit AerSimulator, where $m$ is a proxy for the
effective mass of a superposition, mapped to circuit parameters such as the
number of entangled qubits or branch size. We apply this model to three
canonical quantum computing experiments: GHZ state parity measurements,
branch-mass entanglement tests, and Grover's search to generate distinctive
collapse signatures that differ qualitatively from constant-rate dephasing. The
resulting patterns serve as a baseline reference: if future hardware
experiments exhibit the same scaling trends under ideal isolation, this could
indicate a contribution from mass-dependent collapse processes. Conversely,
deviation toward constant-noise behaviour would suggest the absence of such
gravitationally induced effects. Our results provide a reproducible protocol
and reference for using quantum computers as potential testbeds for probing
fundamental questions in quantum mechanics.

</details>


### [79] [Routing and Wavelength Assignment with Minimal Attack Radius for QKD Networks](https://arxiv.org/abs/2508.10613)
*Mengyao Li,Qiaolun Zhang,Zongshuai Yang,Stefano Bregni,Alberto Gatto,Raouf Boutaba,Massimo Tornatore*

Main category: quant-ph

TL;DR: 该论文提出了一个名为maxNAR的新指标来量化物理层攻击的最坏影响，并研究了RWA-MAR问题。通过ILP模型和启发式算法，结合QKPs缓存机制，优化了安全性和资源利用率。实验证明其方法在安全性和可扩展性上优于基线。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发(QKD)虽然具有安全性，但容易因物理层攻击（如高功率干扰）中断密钥交换。为解决这一问题，研究需要量化攻击影响并优化网络架构。

Method: 引入maxNAR指标评估攻击影响，提出RWA-MAR问题并用ILP建模。设计了结合QKPs的启发式算法，优化了OB和TR架构的动态控制。

Result: 仿真结果显示，所提方法在安全性和可扩展性上显著优于基线方法。

Conclusion: 通过maxNAR和RWA-MAR框架，该研究有效提升了QKD网络对物理层攻击的抵抗能力，并通过动态架构选择增强了适应性。

Abstract: Quantum Key Distribution (QKD) can distribute keys with guaranteed security
but remains susceptible to key exchange interruption due to physical-layer
threats, such as high-power jamming attacks. To address this challenge, we
first introduce a novel metric, namely Maximum Number of Affected Requests
(maxNAR), to quantify the worst-case impact of a single physical-layer attack,
and then we investigate a new problem of Routing and Wavelength Assignment with
Minimal Attack Radius (RWA-MAR). We formulate the problem using an Integer
Linear Programming (ILP) model and propose a scalable heuristic to efficiently
minimize maxNAR. Our approach incorporates key caching through Quantum Key
Pools (QKPs) to enhance resilience and optimize resource utilization. Moreover,
we model the impact of different QKD network architectures, employing Optical
Bypass (OB) for optical switching of quantum channels and Trusted Relay (TR)
for secure key forwarding. Moreover, a tunable parameter is designed in the
heuristic to guide the preference for OB or TR, offering enhanced adaptability
and dynamic control in diverse network scenarios. Simulation results confirm
that our method significantly outperforms the baseline in terms of security and
scalability.

</details>
