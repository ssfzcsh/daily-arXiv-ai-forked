{"id": "2508.00031", "pdf": "https://arxiv.org/pdf/2508.00031", "abs": "https://arxiv.org/abs/2508.00031", "authors": ["Junde Wu"], "title": "Git Context Controller: Manage the Context of LLM-based Agents like Git", "categories": ["cs.SE"], "comment": "in updating", "summary": "Large language model (LLM) based agents have shown impressive capabilities by\ninterleaving internal reasoning with external tool use. However, as these\nagents are deployed in long-horizon workflows, such as coding for a big,\nlong-term project, context management becomes a critical bottleneck. We\nintroduce Git-Context-Controller (GCC), a structured context management\nframework inspired by software version control systems. GCC elevates context as\nversioned memory hierarchy like Git. It structures agent memory as a persistent\nfile system with explicit operations: COMMIT, BRANCH, MERGE, and CONTEXT,\nenabling milestone-based checkpointing, exploration of alternative plans, and\nstructured reflection. Our approach empowers agents to manage long-term goals,\nisolate architectural experiments, and recover or hand off memory across\nsessions and agents. Empirically, agents equipped with GCC achieve\nstate-of-the-art performance on the SWE-Bench-Lite benchmark, resolving 48.00\nof software bugs, outperforming 26 competitive systems. In a self-replication\ncase study, a GCC-augmented agent builds a new CLI agent from scratch,\nachieving 40.7 task resolution, compared to only 11.7 without GCC. The code is\nreleased at: https://github.com/theworldofagents/GCC", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aGit-Context-Controller (GCC)\u7684\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u7ba1\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u88ab\u90e8\u7f72\u5728\u957f\u671f\u4efb\u52a1\u4e2d\uff0c\u4e0a\u4e0b\u6587\u7ba1\u7406\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "GCC\u6846\u67b6\u901a\u8fc7\u7c7b\u4f3cGit\u7684\u7248\u672c\u63a7\u5236\u673a\u5236\uff0c\u5c06\u4ee3\u7406\u5185\u5b58\u7ed3\u6784\u5316\u4e3a\u6301\u4e45\u6587\u4ef6\u7cfb\u7edf\uff0c\u652f\u6301COMMIT\u3001BRANCH\u3001MERGE\u7b49\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u914d\u5907GCC\u7684\u4ee3\u7406\u5728SWE-Bench-Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u89e3\u51b3\u4e8648.00%\u7684\u8f6f\u4ef6\u9519\u8bef\uff0c\u5e76\u5728\u81ea\u590d\u5236\u6848\u4f8b\u4e2d\u663e\u8457\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u7387\u3002", "conclusion": "GCC\u6846\u67b6\u6709\u6548\u652f\u6301\u4ee3\u7406\u7ba1\u7406\u957f\u671f\u76ee\u6807\u3001\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u5728\u8de8\u4f1a\u8bdd\u548c\u8de8\u4ee3\u7406\u573a\u666f\u4e2d\u5b9e\u73b0\u5185\u5b58\u6062\u590d\u6216\u4f20\u9012\u3002"}}
{"id": "2508.00033", "pdf": "https://arxiv.org/pdf/2508.00033", "abs": "https://arxiv.org/abs/2508.00033", "authors": ["Nuno Fachada", "Daniel Fernandes", "Carlos M. Fernandes", "Bruno D. Ferreira-Saraiva", "Jo\u00e3o P. Matos-Carvalho"], "title": "GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries", "categories": ["cs.SE", "cs.AI", "cs.CL", "68T50", "I.2.2; I.2.7; D.2.3"], "comment": null, "summary": "Large Language Models (LLMs) have advanced rapidly as tools for automating\ncode generation in scientific research, yet their ability to interpret and use\nunfamiliar Python APIs for complex computational experiments remains poorly\ncharacterized. This study systematically benchmarks a selection of\nstate-of-the-art LLMs in generating functional Python code for two increasingly\nchallenging scenarios: conversational data analysis with the \\textit{ParShift}\nlibrary, and synthetic data generation and clustering using \\textit{pyclugen}\nand \\textit{scikit-learn}. Both experiments use structured, zero-shot prompts\nspecifying detailed requirements but omitting in-context examples. Model\noutputs are evaluated quantitatively for functional correctness and prompt\ncompliance over multiple runs, and qualitatively by analyzing the errors\nproduced when code execution fails. Results show that only a small subset of\nmodels consistently generate correct, executable code, with GPT-4.1 standing\nout as the only model to always succeed in both tasks. In addition to\nbenchmarking LLM performance, this approach helps identify shortcomings in\nthird-party libraries, such as unclear documentation or obscure implementation\nbugs. Overall, these findings highlight current limitations of LLMs for\nend-to-end scientific automation and emphasize the need for careful prompt\ndesign, comprehensive library documentation, and continued advances in language\nmodel capabilities.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c\u53d1\u73b0GPT-4.1\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86LLM\u548c\u7b2c\u4e09\u65b9\u5e93\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u751f\u6210Python\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u4e0d\u719f\u6089\u7684API\u65f6\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u96f6\u793a\u4f8b\u63d0\u793a\uff0c\u6d4b\u8bd5LLM\u5728\u6570\u636e\u5206\u6790\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u529f\u80fd\u548c\u63d0\u793a\u7b26\u5408\u6027\u8bc4\u4f30\u3002", "result": "\u4ec5\u6709\u5c11\u6570\u6a21\u578b\u80fd\u751f\u6210\u6b63\u786e\u4ee3\u7801\uff0cGPT-4.1\u8868\u73b0\u6700\u4e3a\u7a33\u5b9a\uff1b\u540c\u65f6\u4e5f\u53d1\u73b0\u4e86\u7b2c\u4e09\u65b9\u5e93\u6587\u6863\u548c\u5b9e\u73b0\u7684\u4e0d\u8db3\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u79d1\u5b66\u81ea\u52a8\u5316\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\u63d0\u793a\u8bbe\u8ba1\u3001\u6587\u6863\u548c\u6a21\u578b\u80fd\u529b\u3002"}}
{"id": "2508.00045", "pdf": "https://arxiv.org/pdf/2508.00045", "abs": "https://arxiv.org/abs/2508.00045", "authors": ["Samah Kansab"], "title": "Machine Learning Pipeline for Software Engineering: A Systematic Literature Review", "categories": ["cs.SE"], "comment": null, "summary": "The rapid advancement of software development practices has introduced\nchallenges in ensuring quality and efficiency across the software engineering\n(SE) lifecycle. As SE systems grow in complexity, traditional approaches often\nfail to scale, resulting in longer debugging times, inefficient defect\ndetection, and resource-heavy development cycles. Machine Learning (ML) has\nemerged as a key solution, enabling automation in tasks such as defect\nprediction, code review, and release quality estimation. However, the\neffectiveness of ML in SE depends on the robustness of its pipeline, including\ndata collection, preprocessing, feature engineering, algorithm selection,\nvalidation, and evaluation.\n  This systematic literature review (SLR) examines state-of-the-art ML\npipelines designed for SE, consolidating best practices, challenges, and gaps.\nOur findings show that robust preprocessing, such as SMOTE for data balancing\nand SZZ-based algorithms for feature selection, improves model reliability.\nEnsemble methods like Random Forest and Gradient Boosting dominate performance\nacross tasks, while simpler models such as Naive Bayes remain valuable for\nefficiency and interpretability. Evaluation metrics including AUC, F1-score,\nand precision are most common, with new metrics like Best Arithmetic Mean (BAM)\nemerging in niche applications. Validation techniques such as bootstrapping are\nwidely used to ensure model stability and generalizability.\n  This SLR highlights the importance of well-designed ML pipelines for\naddressing SE challenges and provides actionable insights for researchers and\npractitioners seeking to optimize software quality and efficiency. By\nidentifying gaps and trends, this study sets a foundation for advancing ML\nadoption and fostering innovation in increasingly complex development\nenvironments.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5173\u4e8e\u673a\u5668\u5b66\u4e60\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e94\u7528\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u5f53\u524dML\u7ba1\u9053\u7684\u4f18\u7f3a\u70b9\u53ca\u6700\u4f73\u5b9e\u8df5\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u8f6f\u4ef6\u8d28\u91cf\u4e0e\u6548\u7387\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u7531\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u8c03\u8bd5\u65f6\u95f4\u957f\u3001\u7f3a\u9677\u68c0\u6d4b\u6548\u7387\u4f4e\u7b49\u95ee\u9898\uff0c\u673a\u5668\u5b66\u4e60\u6210\u4e3a\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002\u4f46ML\u7684\u6548\u679c\u4f9d\u8d56\u4e8e\u5176\u7ba1\u9053\u7684\u9c81\u68d2\u6027\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u5206\u6790\u4e86ML\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6700\u65b0\u7ba1\u9053\uff0c\u6574\u7406\u4e86\u9884\u5904\u7406\u3001\u7279\u5f81\u9009\u62e9\u3001\u7b97\u6cd5\u9009\u62e9\u3001\u9a8c\u8bc1\u548c\u8bc4\u4f30\u7b49\u65b9\u9762\u7684\u6700\u4f73\u5b9e\u8df5\u4e0e\u6311\u6218\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u9c81\u68d2\u7684\u9884\u5904\u7406\uff08\u5982SMOTE\uff09\u548c\u7279\u5f81\u9009\u62e9\uff08\u5982SZZ\uff09\u80fd\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\u3002\u96c6\u6210\u65b9\u6cd5\uff08\u5982\u968f\u673a\u68ee\u6797\u3001\u68af\u5ea6\u63d0\u5347\uff09\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u7b80\u5355\u6a21\u578b\uff08\u5982\u6734\u7d20\u8d1d\u53f6\u65af\uff09\u9002\u5408\u9ad8\u6548\u548c\u53ef\u89e3\u91ca\u6027\u573a\u666f\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u8bbe\u8ba1\u826f\u597d\u7684ML\u7ba1\u9053\u5bf9\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u6311\u6218\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u4f18\u5316\u8f6f\u4ef6\u8d28\u91cf\u4e0e\u6548\u7387\u7684\u884c\u52a8\u6307\u5357\u3002\u901a\u8fc7\u8bc6\u522b\u5dee\u8ddd\u4e0e\u8d8b\u52bf\uff0c\u4e3a\u590d\u6742\u5f00\u53d1\u73af\u5883\u4e2dML\u7684\u8fdb\u4e00\u6b65\u5e94\u7528\u548c\u521b\u65b0\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.00083", "pdf": "https://arxiv.org/pdf/2508.00083", "abs": "https://arxiv.org/abs/2508.00083", "authors": ["Yihong Dong", "Xue Jiang", "Jiaru Qian", "Tian Wang", "Kechi Zhang", "Zhi Jin", "Ge Li"], "title": "A Survey on Code Generation with LLM-based Agents", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": "Work in progress", "summary": "Code generation agents powered by large language models (LLMs) are\nrevolutionizing the software development paradigm. Distinct from previous code\ngeneration techniques, code generation agents are characterized by three core\nfeatures. 1) Autonomy: the ability to independently manage the entire workflow,\nfrom task decomposition to coding and debugging. 2) Expanded task scope:\ncapabilities that extend beyond generating code snippets to encompass the full\nsoftware development lifecycle (SDLC). 3) Enhancement of engineering\npracticality: a shift in research emphasis from algorithmic innovation toward\npractical engineering challenges, such as system reliability, process\nmanagement, and tool integration. This domain has recently witnessed rapid\ndevelopment and an explosion in research, demonstrating significant application\npotential. This paper presents a systematic survey of the field of LLM-based\ncode generation agents. We trace the technology's developmental trajectory from\nits inception and systematically categorize its core techniques, including both\nsingle-agent and multi-agent architectures. Furthermore, this survey details\nthe applications of LLM-based agents across the full SDLC, summarizes\nmainstream evaluation benchmarks and metrics, and catalogs representative\ntools. Finally, by analyzing the primary challenges, we identify and propose\nseveral foundational, long-term research directions for the future work of the\nfield.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u6280\u672f\uff0c\u5206\u6790\u4e86\u5176\u81ea\u4e3b\u6027\u3001\u4efb\u52a1\u6269\u5c55\u6027\u548c\u5de5\u7a0b\u5b9e\u7528\u6027\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7814\u7a76LLM\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u7684\u6838\u5fc3\u7279\u6027\u53ca\u5176\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u7cfb\u7edf\u8c03\u67e5\u4e86\u8be5\u9886\u57df\u7684\u6280\u672f\u53d1\u5c55\u3001\u6838\u5fc3\u67b6\u6784\uff08\u5355\u4ee3\u7406\u4e0e\u591a\u4ee3\u7406\uff09\u3001\u5e94\u7528\u573a\u666f\u3001\u8bc4\u6d4b\u57fa\u51c6\u548c\u5de5\u5177\u3002", "result": "\u603b\u7ed3\u4e86LLM\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u7684\u73b0\u72b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u672a\u6765\u7814\u7a76\u7684\u957f\u671f\u65b9\u5411\u3002", "conclusion": "\u8be5\u9886\u57df\u5e94\u7528\u6f5c\u529b\u5de8\u5927\uff0c\u9700\u8fdb\u4e00\u6b65\u89e3\u51b3\u5de5\u7a0b\u6311\u6218\u4ee5\u63a8\u52a8\u53d1\u5c55\u3002"}}
{"id": "2508.00398", "pdf": "https://arxiv.org/pdf/2508.00398", "abs": "https://arxiv.org/abs/2508.00398", "authors": ["Sunjae Yoon", "Gwanhyeong Koo", "Younghwan Lee", "Ji Woo Hong", "Chang D. Yoo"], "title": "Occlusion-robust Stylization for Drawing-based 3D Animation", "categories": ["cs.GR", "cs.CV"], "comment": "11 pages, 13 figures, ICCV 2025", "summary": "3D animation aims to generate a 3D animated video from an input image and a\ntarget 3D motion sequence. Recent advances in image-to-3D models enable the\ncreation of animations directly from user-hand drawings. Distinguished from\nconventional 3D animation, drawing-based 3D animation is crucial to preserve\nartist's unique style properties, such as rough contours and distinct stroke\npatterns. However, recent methods still exhibit quality deterioration in style\nproperties, especially under occlusions caused by overlapping body parts,\nleading to contour flickering and stroke blurring. This occurs due to a\n`stylization pose gap' between training and inference in stylization networks\ndesigned to preserve drawing styles in drawing-based 3D animation systems. The\nstylization pose gap denotes that input target poses used to train the\nstylization network are always in occlusion-free poses, while target poses\nencountered in an inference include diverse occlusions under dynamic motions.\nTo this end, we propose Occlusion-robust Stylization Framework (OSF) for\ndrawing-based 3D animation. We found that while employing object's edge can be\neffective input prior for guiding stylization, it becomes notably inaccurate\nwhen occlusions occur at inference. Thus, our proposed OSF provides\nocclusion-robust edge guidance for stylization network using optical flow,\nensuring a consistent stylization even under occlusions. Furthermore, OSF\noperates in a single run instead of the previous two-stage method, achieving\n2.4x faster inference and 2.1x less memory.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Occlusion-robust Stylization Framework (OSF)\uff0c\u7528\u4e8e\u89e3\u51b3\u57fa\u4e8e\u624b\u7ed8\u76843D\u52a8\u753b\u4e2d\u56e0\u906e\u6321\u5bfc\u81f4\u98ce\u683c\u9000\u5316\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5149\u5b66\u6d41\u63d0\u4f9b\u906e\u6321\u9c81\u68d2\u7684\u8fb9\u7f18\u5f15\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u98ce\u683c\u4e00\u81f4\u6027\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u57fa\u4e8e\u624b\u7ed8\u76843D\u52a8\u753b\u4e2d\uff0c\u56e0\u906e\u6321\u5bfc\u81f4\u98ce\u683c\u5c5e\u6027\u9000\u5316\uff08\u5982\u8f6e\u5ed3\u95ea\u70c1\u548c\u7b14\u89e6\u6a21\u7cca\uff09\uff0c\u5c24\u5176\u662f\u5728\u52a8\u6001\u8fd0\u52a8\u4e2d\u3002\u8fd9\u662f\u7531\u4e8e\u8bad\u7ec3\u4e0e\u63a8\u7406\u65f6\u7684\u59ff\u52bf\u5dee\u8ddd\uff08stylization pose gap\uff09\u95ee\u9898\u6240\u81f4\u3002", "method": "\u63d0\u51faOSF\u6846\u67b6\uff0c\u5229\u7528\u5149\u5b66\u6d41\u63d0\u4f9b\u906e\u6321\u9c81\u68d2\u7684\u8fb9\u7f18\u5f15\u5bfc\uff0c\u786e\u4fdd\u5373\u4f7f\u5728\u906e\u6321\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u4e00\u81f4\u7684\u98ce\u683c\u5316\u3002OSF\u5355\u9636\u6bb5\u8fd0\u884c\uff0c\u6bd4\u4e24\u9636\u6bb5\u65b9\u6cd5\u66f4\u5feb\u4e14\u66f4\u8282\u7701\u5185\u5b58\u3002", "result": "OSF\u663e\u8457\u63d0\u5347\u4e86\u98ce\u683c\u4e00\u81f4\u6027\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53472.4\u500d\uff0c\u5185\u5b58\u5360\u7528\u51cf\u5c112.1\u500d\u3002", "conclusion": "OSF\u4e3a\u57fa\u4e8e\u624b\u7ed8\u76843D\u52a8\u753b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u98ce\u683c\u9000\u5316\u95ee\u9898\uff0c\u540c\u65f6\u4f18\u5316\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2508.00003", "pdf": "https://arxiv.org/pdf/2508.00003", "abs": "https://arxiv.org/abs/2508.00003", "authors": ["Kang Rong Roy Ang"], "title": "Building Bigraphs of the real world", "categories": ["cs.LO"], "comment": "Submitted in partial fulfilment of the requirements for Part II of\n  the Computer Science Tripos at the University of Cambridge", "summary": "This report proposes a formal specification for organising all buildings,\nstreets and administrative areas in the world into a hierarchical\nspace-partitioning tree using data from OpenStreetMap. This hierarchical\nstructure is encoded into a bigraph, serving as a digital twin of the world and\ncapturing complete street connectivity. It presents a tool implemented in OCaml\n(source code at https://github.com/royangkr/bigraph-of-the-world ) that\nconstructs bigraphs for regions from any part of the world. In addition, it\ncontributes algorithmic improvements to open-source bigraph-building tools that\nenable them to efficiently construct and transform extremely large bigraphs,\nachieving up to a 97x speedup among other gains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528OpenStreetMap\u6570\u636e\u5c06\u5168\u7403\u5efa\u7b51\u3001\u8857\u9053\u548c\u884c\u653f\u533a\u7ec4\u7ec7\u6210\u5c42\u6b21\u7a7a\u95f4\u5206\u533a\u6811\u7684\u89c4\u8303\uff0c\u5e76\u5c06\u5176\u7f16\u7801\u4e3a\u53cd\u6620\u8857\u9053\u8fde\u63a5\u6027\u7684\u6570\u5b57\u5b6a\u751f\u5927\u56fe\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u6548\u5de5\u5177\u3002", "motivation": "\u901a\u8fc7\u5c42\u6b21\u5316\u7ed3\u6784\u548c\u5927\u56fe\u6280\u672f\uff0c\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u5b8c\u6574\u8868\u793a\u5168\u7403\u8857\u9053\u8fde\u63a5\u6027\u7684\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u3002", "method": "\u5229\u7528OpenStreetMap\u6570\u636e\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eOCaml\u7684\u5de5\u5177\uff0c\u6784\u5efa\u5168\u7403\u533a\u57df\u7684\u5927\u56fe\uff0c\u5e76\u5bf9\u5f00\u6e90\u5de5\u5177\u8fdb\u884c\u7b97\u6cd5\u6539\u8fdb\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u8d85\u5927\u56fe\u7684\u5feb\u901f\u6784\u5efa\u548c\u8f6c\u6362\uff0c\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe97\u500d\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5168\u7403\u7a7a\u95f4\u6570\u636e\u7684\u5c42\u6b21\u5316\u5efa\u6a21\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2508.00441", "pdf": "https://arxiv.org/pdf/2508.00441", "abs": "https://arxiv.org/abs/2508.00441", "authors": ["Daichi Mukunoki"], "title": "DGEMM without FP64 Arithmetic -- using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme", "categories": ["cs.PF", "cs.AR", "cs.MS"], "comment": null, "summary": "Since AI computations require low-precision matrix multiplications,\nprocessors with enhanced performance for these operations are increasing along\nwith the growing demand for AI computations. However, it is difficult to use\nthese operations directly for scientific computations. The Ozaki scheme, an\naccurate matrix multiplication method proposed by Ozaki et al. in 2012, enables\nFP64 matrix multiplication (DGEMM) using low-precision floating-point\noperations such as FP16. The method was subsequently extended to utilize\ninteger arithmetic. The use of integer operations reduces computational cost\ncompared to the floating-point based approach. It has also demonstrated higher\nperformance than hardware FP64 operations on GPUs with fast INT8 Tensor Cores\nfor AI workloads. However, the latest hardware tends to enhance low-precision\nfloating-point operation performance such as FP8 instead of INT8. This study\nrevisits the utilization of low-precision floating-point operations in the\nOzaki scheme, considering the latest AI hardware. Specifically, we consider the\nuse of FP6 and FP8 Tensor Cores. Moreover, for processors that support very\nslow FP64 operations or do not support them at all, we consider the use of the\nFP64 emulation based on integer arithmetic. We also examine a new blocking\nstrategy. We demonstrate the effectiveness of these methods by evaluating the\nperformance of DGEMM using FP8 Tensor Cores and FP64 emulation on a Blackwell\narchitecture GPU.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u63a2\u8ba8\u4e86Ozaki\u65b9\u6848\u5728\u6700\u65b0AI\u786c\u4ef6\u4e2d\u4f7f\u7528\u4f4e\u7cbe\u5ea6\u6d6e\u70b9\u8fd0\u7b97\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u5173\u6ce8FP6\u548cFP8\u5f20\u91cf\u6838\u5fc3\uff0c\u4ee5\u53ca\u57fa\u4e8e\u6574\u6570\u8fd0\u7b97\u7684FP64\u6a21\u62df\u3002", "motivation": "\u968f\u7740AI\u8ba1\u7b97\u9700\u6c42\u589e\u957f\uff0c\u4f4e\u7cbe\u5ea6\u77e9\u9635\u4e58\u6cd5\u52a0\u901f\u786c\u4ef6\u666e\u53ca\uff0c\u4f46\u96be\u4ee5\u76f4\u63a5\u7528\u4e8e\u79d1\u5b66\u8ba1\u7b97\u3002Ozaki\u65b9\u6848\u867d\u80fd\u7528\u4f4e\u7cbe\u5ea6\u8fd0\u7b97\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u77e9\u9635\u4e58\u6cd5\uff0c\u4f46\u6700\u65b0\u786c\u4ef6\u66f4\u504f\u5411\u4f4e\u7cbe\u5ea6\u6d6e\u70b9\u800c\u975e\u6574\u6570\u8fd0\u7b97\u3002", "method": "\u7814\u7a76\u4e86FP6\u548cFP8\u5f20\u91cf\u6838\u5fc3\u7684\u5e94\u7528\uff0c\u4ee5\u53caFP64\u6a21\u62df\u548c\u65b0\u7684\u5206\u5757\u7b56\u7565\u3002", "result": "\u5728\u9ed1\u8393\u67b6\u6784GPU\u4e0a\u9a8c\u8bc1\u4e86\u4f7f\u7528FP8\u5f20\u91cf\u6838\u5fc3\u548cFP64\u6a21\u62df\u8fdb\u884cDGEMM\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408\u4f4e\u7cbe\u5ea6\u6d6e\u70b9\u8fd0\u7b97\u548cFP64\u6a21\u62df\u7684Ozaki\u65b9\u6848\u5728\u65b0\u786c\u4ef6\u4e0a\u4ecd\u5177\u6f5c\u529b\u3002"}}
{"id": "2508.00579", "pdf": "https://arxiv.org/pdf/2508.00579", "abs": "https://arxiv.org/abs/2508.00579", "authors": ["Ziyu Gong", "Yihua Huang", "Chengcheng Mai"], "title": "MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval", "categories": ["cs.MM", "cs.IR"], "comment": null, "summary": "The multi-modal long-context document question-answering task aims to locate\nand integrate multi-modal evidences (such as texts, tables, charts, images, and\nlayouts) distributed across multiple pages, for question understanding and\nanswer generation. The existing methods can be categorized into Large\nVision-Language Model (LVLM)-based and Retrieval-Augmented Generation\n(RAG)-based methods. However, the former were susceptible to hallucinations,\nwhile the latter struggled for inter-modal disconnection and cross-page\nfragmentation. To address these challenges, a novel multi-modal RAG model,\nnamed MMRAG-DocQA, was proposed, leveraging both textual and visual information\nacross long-range pages to facilitate accurate question answering. A\nhierarchical indexing method with the integration of flattened in-page chunks\nand topological cross-page chunks was designed to jointly establish in-page\nmulti-modal associations and long-distance cross-page dependencies. By means of\njoint similarity evaluation and large language model (LLM)-based re-ranking, a\nmulti-granularity semantic retrieval method, including the page-level parent\npage retrieval and document-level summary retrieval, was proposed to foster\nmulti-modal evidence connection and long-distance evidence integration and\nreasoning. Experimental results performed on public datasets, MMLongBench-Doc\nand LongDocURL, demonstrated the superiority of our MMRAG-DocQA method in\nunderstanding and answering modality-rich and multi-page documents.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u591a\u6a21\u6001RAG\u6a21\u578bMMRAG-DocQA\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u957f\u4e0a\u4e0b\u6587\u6587\u6863\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u591a\u6a21\u6001\u95f4\u65ad\u6027\uff0c\u901a\u8fc7\u5206\u5c42\u7d22\u5f15\u548c\u591a\u7c92\u5ea6\u8bed\u4e49\u68c0\u7d22\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLVLM\u548cRAG\u7684\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u53ca\u591a\u6a21\u6001\u95f4\u4e0d\u8fde\u8d2f\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u6574\u5408\u8de8\u9875\u591a\u6a21\u6001\u4fe1\u606f\u4ee5\u5b9e\u73b0\u51c6\u786e\u95ee\u7b54\u3002", "method": "\u63d0\u51faMMRAG-DocQA\u6a21\u578b\uff0c\u91c7\u7528\u5206\u5c42\u7d22\u5f15\u7ed3\u5408\u9875\u9762\u5185\u548c\u8de8\u9875\u62d3\u6251\u5757\uff0c\u591a\u7c92\u5ea6\u8bed\u4e49\u68c0\u7d22\u53caLLM\u91cd\u6392\u5e8f\u4ee5\u4f18\u5316\u8bc1\u636e\u8fde\u63a5\u548c\u63a8\u7406\u3002", "result": "\u5728MMLongBench-Doc\u548cLongDocURL\u6570\u636e\u96c6\u4e0a\uff0cMMRAG-DocQA\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u5904\u7406\u591a\u9875\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u3002", "conclusion": "MMRAG-DocQA\u901a\u8fc7\u5206\u5c42\u7d22\u5f15\u548c\u591a\u7c92\u5ea6\u68c0\u7d22\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u957f\u6587\u6863\u95ee\u7b54\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5c55\u793a\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2508.00604", "pdf": "https://arxiv.org/pdf/2508.00604", "abs": "https://arxiv.org/abs/2508.00604", "authors": ["Rajpreet Singh", "Vidhi Kothari"], "title": "Composable OS Kernel Architectures for Autonomous Intelligence", "categories": ["cs.OS", "cs.AI"], "comment": "8 pages", "summary": "As intelligent systems permeate edge devices, cloud infrastructure, and\nembedded real-time environments, this research proposes a new OS kernel\narchitecture for intelligent systems, transforming kernels from static resource\nmanagers to adaptive, AI-integrated platforms. Key contributions include: (1)\ntreating Loadable Kernel Modules (LKMs) as AI-oriented computation units for\nfast sensory and cognitive processing in kernel space; (2) expanding the Linux\nkernel into an AI-native environment with built-in deep learning inference,\nfloating-point acceleration, and real-time adaptive scheduling for efficient ML\nworkloads; and (3) introducing a Neurosymbolic kernel design leveraging\nCategory Theory and Homotopy Type Theory to unify symbolic reasoning and\ndifferentiable logic within OS internals. Together, these approaches enable\noperating systems to proactively anticipate and adapt to the cognitive needs of\nautonomous intelligent applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u667a\u80fd\u7cfb\u7edf\u64cd\u4f5c\u7cfb\u7edf\u5185\u6838\u67b6\u6784\uff0c\u5c06\u5185\u6838\u4ece\u9759\u6001\u8d44\u6e90\u7ba1\u7406\u5668\u8f6c\u53d8\u4e3a\u81ea\u9002\u5e94\u3001\u96c6\u6210AI\u7684\u5e73\u53f0\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u7cfb\u7edf\u5728\u8fb9\u7f18\u8bbe\u5907\u3001\u4e91\u57fa\u7840\u8bbe\u65bd\u548c\u5d4c\u5165\u5f0f\u5b9e\u65f6\u73af\u5883\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5185\u6838\u67b6\u6784\u6765\u652f\u6301\u8fd9\u4e9b\u7cfb\u7edf\u7684\u9700\u6c42\u3002", "method": "(1) \u5c06\u53ef\u52a0\u8f7d\u5185\u6838\u6a21\u5757\uff08LKM\uff09\u89c6\u4e3a\u9762\u5411AI\u7684\u8ba1\u7b97\u5355\u5143\uff1b(2) \u5c06Linux\u5185\u6838\u6269\u5c55\u4e3a\u652f\u6301\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\u3001\u6d6e\u70b9\u52a0\u901f\u548c\u5b9e\u65f6\u81ea\u9002\u5e94\u8c03\u5ea6\u7684AI\u539f\u751f\u73af\u5883\uff1b(3) \u5f15\u5165\u57fa\u4e8e\u8303\u7574\u8bba\u548c\u540c\u4f26\u7c7b\u578b\u7406\u8bba\u7684\u795e\u7ecf\u7b26\u53f7\u5185\u6838\u8bbe\u8ba1\u3002", "result": "\u64cd\u4f5c\u7cfb\u7edf\u80fd\u591f\u4e3b\u52a8\u9884\u6d4b\u5e76\u9002\u5e94\u81ea\u4e3b\u667a\u80fd\u5e94\u7528\u7684\u8ba4\u77e5\u9700\u6c42\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u5185\u6838\u67b6\u6784\uff0c\u63d0\u5347\u4e86\u5176\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.00295", "pdf": "https://arxiv.org/pdf/2508.00295", "abs": "https://arxiv.org/abs/2508.00295", "authors": ["Md Mazharul Islam", "Diego Ferrer", "Shamiul Alam", "Juan P. Mendez", "Denis Mamaluy", "Wei Pan", "Ahmedullah Aziz"], "title": "Reimagining Voltage-Controlled Cryogenic Boolean Logic Paradigm with Quantum-Enhanced Josephson Junction FETs", "categories": ["cs.ET", "cs.AR", "physics.app-ph"], "comment": null, "summary": "The growing demand for ultra low power computing and the emergence of quantum\ntechnologies have intensified interest in cryogenic electronics, particularly\nsuperconducting devices.Despite their promise, current controlled\nsuperconducting components face fundamental challenges in cascadability,\nlimiting their effectiveness in complex logic architectures.To overcome this,\nrecent efforts have focused on developing gate tunable superconducting devices,\nsuch as Josephson Junction Field Effect Transistors (JJFETs).However, achieving\nrobust control and sufficient supercurrent gain, both critical for\ntransistor-like performance in logic circuits remains a key challenge.A recent\nadvancement in JJFET design, based on InAs and GaSb heterostructures,\ndemonstrates enhanced gain and favorable device characteristics suitable for\ncircuit integration.Building on this innovation, we propose and analyze\nfundamental voltage controlled logic topologies using the quantum enhanced\nJJFET. We develop a Verilog A based circuit compatible compact model of the\nquantum enhanced JJFET which accurately captures the experimentally observed\ndevice characteristics.To ensure cascadability, our logic circuits incorporate\nthe multilayered Heater Nanocryotron (nTron), a superconducting nanowire-based\nthermal switch.Through simulation based analysis, we demonstrate the successful\nimplementation of fundamental logic gates, including NOT, NAND, and NOR.\nFurthermore, we design a 3 input majority gate, which plays a pivotal role in\nquantum and reversible computing due to its universality.Finally, to\ndemonstrate the cascadability of our proposed logic topology, we demonstrate\nthe operation of a 2 input XOR gate based on our designed JJFET based NOT,\nNAND, and NOR gate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u91cf\u5b50\u589e\u5f3aJJFET\u7684\u8d85\u5bfc\u903b\u8f91\u7535\u8def\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8d85\u5bfc\u5668\u4ef6\u5728\u7ea7\u8054\u6027\u548c\u589e\u76ca\u65b9\u9762\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u57fa\u672c\u903b\u8f91\u95e8\u548c\u7ea7\u8054\u7535\u8def\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u8d85\u4f4e\u6e29\u7535\u5b50\u5668\u4ef6\u5728\u4f4e\u529f\u8017\u8ba1\u7b97\u548c\u91cf\u5b50\u6280\u672f\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u8d85\u5bfc\u5668\u4ef6\u5728\u7ea7\u8054\u6027\u548c\u589e\u76ca\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u903b\u8f91\u67b6\u6784\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u91cf\u5b50\u589e\u5f3aJJFET\uff08\u57fa\u4e8eInAs\u548cGaSb\u5f02\u8d28\u7ed3\u6784\uff09\u8bbe\u8ba1\u7535\u538b\u63a7\u5236\u903b\u8f91\u7535\u8def\uff0c\u5e76\u7ed3\u5408\u591a\u5c42\u52a0\u70ed\u7eb3\u7c73\u8d85\u5bfc\u70ed\u5f00\u5173\uff08nTron\uff09\u786e\u4fdd\u7ea7\u8054\u6027\u3002\u901a\u8fc7Verilog A\u6a21\u578b\u6a21\u62df\u5668\u4ef6\u7279\u6027\u3002", "result": "\u4eff\u771f\u5c55\u793a\u4e86NOT\u3001NAND\u548cNOR\u7b49\u57fa\u672c\u903b\u8f91\u95e8\u4ee5\u53ca3\u8f93\u5165\u591a\u6570\u95e8\u7684\u6210\u529f\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc72\u8f93\u5165XOR\u95e8\u9a8c\u8bc1\u4e86\u7ea7\u8054\u6027\u3002", "conclusion": "\u91cf\u5b50\u589e\u5f3aJJFET\u53canTron\u7684\u7ed3\u5408\u4e3a\u8d85\u5bfc\u903b\u8f91\u7535\u8def\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63a8\u52a8\u8d85\u4f4e\u6e29\u7535\u5b50\u5668\u4ef6\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.00005", "pdf": "https://arxiv.org/pdf/2508.00005", "abs": "https://arxiv.org/abs/2508.00005", "authors": ["Tilman Hinnerichs", "Bart Swinkels", "Jaap de Jong", "Reuben Gardos Reid", "Tudor Magirescu", "Neil Yorke-Smith", "Sebastijan Dumancic"], "title": "Modelling Program Spaces in Program Synthesis with Constraints", "categories": ["cs.PL", "cs.AI"], "comment": null, "summary": "A core challenge in program synthesis is taming the large space of possible\nprograms. Since program synthesis is essentially a combinatorial search, the\ncommunity has sought to leverage powerful combinatorial constraint solvers.\nHere, constraints are used to express the program semantics, but not as a\npotentially potent tool to remove unwanted programs. Recent inductive logic\nprogramming approaches introduce constraints on the program's syntax to be\nsynthesized. These syntactic constraints allow for checking and propagating a\nconstraint without executing the program, and thus for arbitrary operators. In\nthis work, we leverage syntactic constraints to model program spaces, defining\nnot just solutions that are feasible, but also ones that are likely useful. To\ndemonstrate this idea, we introduce BART, a solver that efficiently propagates\nand solves these constraints. We evaluate BART on program space enumeration\ntasks, finding that the constraints eliminate up to 99 percent of the program\nspace, and that modeling program spaces significantly reduces enumeration time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8bed\u6cd5\u7ea6\u675f\u4f18\u5316\u7a0b\u5e8f\u5408\u6210\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7BART\u6c42\u89e3\u5668\u9ad8\u6548\u6d88\u9664\u4e0d\u5fc5\u8981\u7a0b\u5e8f\uff0c\u663e\u8457\u63d0\u5347\u679a\u4e3e\u6548\u7387\u3002", "motivation": "\u7a0b\u5e8f\u5408\u6210\u7684\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u5e9e\u5927\u7684\u7a0b\u5e8f\u7a7a\u95f4\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7ec4\u5408\u7ea6\u675f\u6c42\u89e3\u5668\u8868\u8fbe\u7a0b\u5e8f\u8bed\u4e49\uff0c\u4f46\u672a\u5145\u5206\u5229\u7528\u7ea6\u675f\u79fb\u9664\u65e0\u7528\u7a0b\u5e8f\u3002", "method": "\u5f15\u5165\u8bed\u6cd5\u7ea6\u675f\u5bf9\u7a0b\u5e8f\u7a7a\u95f4\u5efa\u6a21\uff0c\u5f00\u53d1BART\u6c42\u89e3\u5668\u9ad8\u6548\u4f20\u64ad\u548c\u89e3\u51b3\u8fd9\u4e9b\u7ea6\u675f\u3002", "result": "\u7ea6\u675f\u53ef\u6d88\u9664\u9ad8\u8fbe99%\u7684\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u663e\u8457\u51cf\u5c11\u679a\u4e3e\u65f6\u95f4\u3002", "conclusion": "\u8bed\u6cd5\u7ea6\u675f\u662f\u4e00\u79cd\u9ad8\u6548\u5de5\u5177\uff0c\u80fd\u6709\u6548\u7f29\u5c0f\u7a0b\u5e8f\u5408\u6210\u7a7a\u95f4\u5e76\u63d0\u5347\u679a\u4e3e\u6548\u7387\u3002"}}
{"id": "2508.00007", "pdf": "https://arxiv.org/pdf/2508.00007", "abs": "https://arxiv.org/abs/2508.00007", "authors": ["Gaowei Chang", "Eidan Lin", "Chengxuan Yuan", "Rizhao Cai", "Binbin Chen", "Xuan Xie", "Yin Zhang"], "title": "Agent Network Protocol Technical White Paper", "categories": ["cs.NI", "cs.AI"], "comment": "This white paper is a reformatted version of the open-source\n  community edition previously released by the ANP Open Source Technology\n  Community(https://github.com/agent-network-protocol)", "summary": "With the development of large models and autonomous decision-making AI,\nagents are rapidly becoming the new entities of the internet, following mobile\napps. However, existing internet infrastructure is primarily designed for human\ninteraction, creating data silos, unfriendly interfaces, and high collaboration\ncosts among agents, making it difficult to support the needs for large-scale\nagent interconnection and collaboration. The internet is undergoing a profound\ntransformation, showing four core trends: agents replacing traditional\nsoftware, universal agent interconnection, native protocol-based connections,\nand autonomous agent organization and collaboration. To align with these\ntrends, Agent Network Protocol (ANP) proposes a new generation of communication\nprotocols for the Agentic Web. ANP adheres to AI-native design, maintains\ncompatibility with existing internet protocols, adopts a modular composable\narchitecture, follows minimalist yet extensible principles, and enables rapid\ndeployment based on existing infrastructure. Through a three-layer protocol\nsystem--identity and encrypted communication layer, meta-protocol negotiation\nlayer, and application protocol layer--ANP. systematically solves the problems\nof agent identity authentication, dynamic negotiation, and capability discovery\ninteroperability.", "AI": {"tldr": "ANP\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Agent\u901a\u4fe1\u534f\u8bae\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a21Agent\u4e92\u8054\u4e0e\u534f\u4f5c\u4e2d\u7684\u8eab\u4efd\u9a8c\u8bc1\u3001\u52a8\u6001\u534f\u5546\u548c\u80fd\u529b\u53d1\u73b0\u7b49\u95ee\u9898\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u7684\u666e\u53ca\uff0c\u73b0\u6709\u4e92\u8054\u7f51\u57fa\u7840\u8bbe\u65bd\u96be\u4ee5\u6ee1\u8db3\u5927\u89c4\u6a21\u4ee3\u7406\u4e92\u8054\u4e0e\u534f\u4f5c\u7684\u9700\u6c42\uff0c\u9700\u8981\u8bbe\u8ba1\u65b0\u7684\u901a\u4fe1\u534f\u8bae\u3002", "method": "ANP\u91c7\u7528AI\u539f\u751f\u7684\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5206\u4e3a\u8eab\u4efd\u4e0e\u52a0\u5bc6\u901a\u4fe1\u5c42\u3001\u5143\u534f\u8bae\u534f\u5546\u5c42\u548c\u5e94\u7528\u534f\u8bae\u5c42\u3002", "result": "ANP\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u4e86\u4ee3\u7406\u8eab\u4efd\u8ba4\u8bc1\u3001\u52a8\u6001\u534f\u5546\u548c\u80fd\u529b\u53d1\u73b0\u4e92\u64cd\u4f5c\u6027\u7b49\u95ee\u9898\u3002", "conclusion": "ANP\u662f\u9002\u5e94\u672a\u6765Agent\u4e92\u8054\u7f51\u8d8b\u52bf\u7684\u65b0\u4e00\u4ee3\u901a\u4fe1\u534f\u8bae\u3002"}}
{"id": "2508.00002", "pdf": "https://arxiv.org/pdf/2508.00002", "abs": "https://arxiv.org/abs/2508.00002", "authors": ["Kaustav Bhattacharjee", "Jun Yuan", "Aritra Dasgupta"], "title": "ReVise: A Human-AI Interface for Incremental Algorithmic Recourse", "categories": ["cs.HC"], "comment": "Conditionally accepted for the IEEE VIS 2025 Short Papers track", "summary": "The recent adoption of artificial intelligence in socio-technical systems\nraises concerns about the black-box nature of the resulting decisions in fields\nsuch as hiring, finance, admissions, etc. If data subjects -- such as job\napplicants, loan applicants, and students -- receive an unfavorable outcome,\nthey may be interested in algorithmic recourse, which involves updating certain\nfeatures to yield a more favorable result when re-evaluated by algorithmic\ndecision-making. Unfortunately, when individuals do not fully understand the\nincremental steps needed to change their circumstances, they risk following\nmisguided paths that can lead to significant, long-term adverse consequences.\nExisting recourse approaches focus exclusively on the final recourse goal but\nneglect the possible incremental steps to reach the goal with real-life\nconstraints, user preferences, and model artifacts. To address this gap, we\nformulate a visual analytic workflow for incremental recourse planning in\ncollaboration with AI/ML experts and contribute an interactive visualization\ninterface that helps data subjects efficiently navigate the recourse\nalternatives and make an informed decision. We present a usage scenario and\nsubjective feedback from observational studies with twelve graduate students\nusing a real-world dataset, which demonstrates that our approach can be\ninstrumental for data subjects in choosing a suitable recourse path.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u5e2e\u52a9\u6570\u636e\u4e3b\u4f53\u5728\u7b97\u6cd5\u51b3\u7b56\u4e2d\u89c4\u5212\u6e10\u8fdb\u7684\u8865\u6551\u8def\u5f84\uff0c\u4ee5\u907f\u514d\u8bef\u5bfc\u6027\u884c\u52a8\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u9ed1\u7bb1\u7279\u6027\u5f15\u53d1\u4e86\u62c5\u5fe7\u3002\u6570\u636e\u4e3b\u4f53\uff08\u5982\u6c42\u804c\u8005\u3001\u8d37\u6b3e\u7533\u8bf7\u8005\uff09\u5728\u4e0d\u5b8c\u5168\u7406\u89e3\u5982\u4f55\u6539\u53d8\u81ea\u8eab\u72b6\u51b5\u65f6\uff0c\u53ef\u80fd\u91c7\u53d6\u9519\u8bef\u884c\u52a8\uff0c\u5bfc\u81f4\u957f\u671f\u4e0d\u826f\u540e\u679c\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u5173\u6ce8\u6700\u7ec8\u8865\u6551\u76ee\u6807\uff0c\u5ffd\u89c6\u4e86\u9010\u6b65\u5b9e\u73b0\u7684\u53ef\u884c\u6027\u548c\u7528\u6237\u504f\u597d\u3002", "method": "\u4f5c\u8005\u4e0eAI/ML\u4e13\u5bb6\u5408\u4f5c\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u754c\u9762\uff0c\u5e2e\u52a9\u6570\u636e\u4e3b\u4f53\u9ad8\u6548\u63a2\u7d22\u8865\u6551\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u96c6\u7684\u4f7f\u7528\u573a\u666f\u548c12\u540d\u7814\u7a76\u751f\u7684\u4e3b\u89c2\u53cd\u9988\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u4ea4\u4e92\u5f0f\u5de5\u5177\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u6570\u636e\u4e3b\u4f53\u9009\u62e9\u5408\u9002\u7684\u6e10\u8fdb\u8865\u6551\u8def\u5f84\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.00475", "pdf": "https://arxiv.org/pdf/2508.00475", "abs": "https://arxiv.org/abs/2508.00475", "authors": ["Yunhao Ma", "Yanyu Lin", "Mingjing Li", "Puli Quan", "Chenlin Zhou", "Wenyue Zhang", "Zhiwei Zhong", "Wanyi Jia", "Xueke Zhu", "Qingyan Meng", "Huihui Zhou", "Fengwei An"], "title": "E2ATST: A Temporal-Spatial Optimized Energy-Efficient Architecture for Training Spiking Transformer", "categories": ["cs.AR", "cs.NE"], "comment": null, "summary": "(1) Pengcheng Laboratory, (2) Southern University of Science and Technology,\n(3) Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences,\n(4) University of Chinese Academy of Sciences", "AI": {"tldr": "\u7814\u7a76\u6765\u81ea\u6df1\u5733\u7684\u9ad8\u6821\u548c\u7814\u7a76\u673a\u6784\u5408\u4f5c\u5b8c\u6210\u3002", "motivation": "\u63a2\u8ba8\u6df1\u5733\u5730\u533a\u9ad8\u6821\u548c\u7814\u7a76\u673a\u6784\u4e4b\u95f4\u7684\u5408\u4f5c\u6a21\u5f0f\u548c\u6210\u679c\u3002", "method": "\u5206\u6790\u591a\u4e2a\u673a\u6784\u7684\u8054\u5408\u7814\u7a76\u60c5\u51b5\u3002", "result": "\u5c55\u793a\u4e86\u6df1\u5733\u5730\u533a\u5b66\u672f\u5408\u4f5c\u7684\u6f5c\u529b\u4e0e\u6210\u6548\u3002", "conclusion": "\u6df1\u5733\u7684\u7814\u7a76\u673a\u6784\u548c\u9ad8\u6821\u901a\u8fc7\u5408\u4f5c\u63d0\u5347\u4e86\u7814\u7a76\u6c34\u5e73\u548c\u5f71\u54cd\u529b\u3002"}}
{"id": "2508.00217", "pdf": "https://arxiv.org/pdf/2508.00217", "abs": "https://arxiv.org/abs/2508.00217", "authors": ["Xiaofeng Wu", "Alan Ritter", "Wei Xu"], "title": "Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges", "categories": ["cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables have gained significant attention in large language models (LLMs) and\nmultimodal large language models (MLLMs) due to their complex and flexible\nstructure. Unlike linear text inputs, tables are two-dimensional, encompassing\nformats that range from well-structured database tables to complex,\nmulti-layered spreadsheets, each with different purposes. This diversity in\nformat and purpose has led to the development of specialized methods and tasks,\ninstead of universal approaches, making navigation of table understanding tasks\nchallenging. To address these challenges, this paper introduces key concepts\nthrough a taxonomy of tabular input representations and an introduction of\ntable understanding tasks. We highlight several critical gaps in the field that\nindicate the need for further research: (1) the predominance of\nretrieval-focused tasks that require minimal reasoning beyond mathematical and\nlogical operations; (2) significant challenges faced by models when processing\ncomplex table structures, large-scale tables, length context, or multi-table\nscenarios; and (3) the limited generalization of models across different\ntabular representations and formats.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8868\u683c\u5904\u7406\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u6cd5\u548c\u4efb\u52a1\u6846\u67b6\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u7814\u7a76\u4e2d\u7684\u5173\u952e\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u8868\u683c\u7ed3\u6784\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u4e13\u95e8\u5316\u800c\u975e\u901a\u7528\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u5206\u7c7b\u548c\u4efb\u52a1\u6846\u67b6\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u6cd5\u63cf\u8ff0\u8868\u683c\u8f93\u5165\u8868\u793a\u5f62\u5f0f\uff0c\u5e76\u4ecb\u7ecd\u8868\u683c\u7406\u89e3\u4efb\u52a1\uff0c\u68b3\u7406\u5f53\u524d\u7814\u7a76\u7684\u4e0d\u8db3\u3002", "result": "\u6307\u51fa\u4e86\u4e09\u4e2a\u5173\u952e\u7814\u7a76\u7a7a\u767d\uff1a\u4efb\u52a1\u504f\u91cd\u4e8e\u68c0\u7d22\u800c\u975e\u63a8\u7406\uff1b\u5904\u7406\u590d\u6742\u8868\u683c\u7ed3\u6784\u548c\u5927\u89c4\u6a21\u8868\u683c\u65f6\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff1b\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u8bba\u6587\u547c\u5401\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u89e3\u51b3\u8868\u683c\u5904\u7406\u9886\u57df\u7684\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u63a8\u7406\u80fd\u529b\u3001\u590d\u6742\u7ed3\u6784\u5904\u7406\u548c\u591a\u8868\u683c\u573a\u666f\u7684\u5efa\u6a21\u3002"}}
{"id": "2508.00341", "pdf": "https://arxiv.org/pdf/2508.00341", "abs": "https://arxiv.org/abs/2508.00341", "authors": ["Shengheng Liu", "Ningning Fu", "Zhonghao Zhang", "Yongming Huang", "Tony Q. S. Quek"], "title": "Integrated user scheduling and beam steering in over-the-air federated learning for mobile IoT", "categories": ["cs.DC"], "comment": "To appear in ACM TOIT. 24 pages, 8 figures", "summary": "The rising popularity of Internet of things (IoT) has spurred technological\nadvancements in mobile internet and interconnected systems. While offering\nflexible connectivity and intelligent applications across various domains, IoT\nservice providers must gather vast amounts of sensitive data from users, which\nnonetheless concomitantly raises concerns about privacy breaches. Federated\nlearning (FL) has emerged as a promising decentralized training paradigm to\ntackle this challenge. This work focuses on enhancing the aggregation\nefficiency of distributed local models by introducing over-the-air computation\ninto the FL framework. Due to radio resource scarcity in large-scale networks,\nonly a subset of users can participate in each training round. This highlights\nthe need for effective user scheduling and model transmission strategies to\noptimize communication efficiency and inference accuracy. To address this, we\npropose an integrated approach to user scheduling and receive beam steering,\nsubject to constraints on the number of selected users and transmit power.\nLeveraging the difference-of-convex technique, we decompose the primal\nnon-convex optimization problem into two sub-problems, yielding an iterative\nsolution. While effective, the computational load of the iterative method\nhampers its practical implementation. To overcome this, we further propose a\nlow-complexity user scheduling policy based on characteristic analysis of the\nwireless channel to directly determine the user subset without iteration.\nExtensive experiments validate the superiority of the proposed method in terms\nof aggregation error and learning performance over existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7a7a\u4e2d\u8ba1\u7b97\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u7528\u6237\u8c03\u5ea6\u548c\u63a5\u6536\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u6a21\u578b\u805a\u5408\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u7269\u8054\u7f51\uff08IoT\uff09\u7684\u666e\u53ca\u5bfc\u81f4\u5927\u91cf\u654f\u611f\u6570\u636e\u7684\u6536\u96c6\uff0c\u9690\u79c1\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4f5c\u4e3a\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u9700\u8981\u89e3\u51b3\u65e0\u7ebf\u8d44\u6e90\u7a00\u7f3a\u5bfc\u81f4\u7684\u7528\u6237\u53c2\u4e0e\u9650\u5236\u95ee\u9898\u3002", "method": "\u5f15\u5165\u7a7a\u4e2d\u8ba1\u7b97\u5230FL\u6846\u67b6\uff0c\u901a\u8fc7\u5dee\u5206\u51f8\u6280\u672f\u5206\u89e3\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4f4e\u590d\u6742\u5ea6\u7528\u6237\u8c03\u5ea6\u7b56\u7565\u4ee5\u76f4\u63a5\u786e\u5b9a\u7528\u6237\u5b50\u96c6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u805a\u5408\u8bef\u5dee\u548c\u5b66\u4e60\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u8c03\u5ea6\u548c\u4f20\u8f93\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21FL\u7f51\u7edc\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2508.00128", "pdf": "https://arxiv.org/pdf/2508.00128", "abs": "https://arxiv.org/abs/2508.00128", "authors": ["Md Nazmul Haque", "Hua Yang", "Zhou Yang", "Bowen Xu"], "title": "How Quantization Impacts Privacy Risk on LLMs for Code?", "categories": ["cs.SE"], "comment": null, "summary": "Large language models for code (LLMs4Code) rely heavily on massive training\ndata, including sensitive data, such as cloud service credentials of the\nprojects and personal identifiable information of the developers, raising\nserious privacy concerns. Membership inference (MI) has recently emerged as an\neffective tool for assessing privacy risk by identifying whether specific data\nbelong to a model's training set. In parallel, model compression techniques,\nespecially quantization, have gained traction for reducing computational costs\nand enabling the deployment of large models. However, while quantized models\nstill retain knowledge learned from the original training data, it remains\nunclear whether quantization affects their ability to retain and expose privacy\ninformation. Answering this question is of great importance to understanding\nprivacy risks in real-world deployments. In this work, we conduct the first\nempirical study on how quantization influences task performance and privacy\nrisk simultaneously in LLMs4Code. To do this, we implement widely used\nquantization techniques (static and dynamic) to three representative model\nfamilies, namely Pythia, CodeGen, and GPTNeo. Our results demonstrate that\nquantization has a significant impact on reducing the privacy risk relative to\nthe original model. We also uncover a positive correlation between task\nperformance and privacy risk, indicating an underlying tradeoff. Moreover, we\nreveal the possibility that quantizing larger models could yield better balance\nthan using full-precision small models. Finally, we demonstrate that these\nfindings generalize across different architectures, model sizes and MI methods,\noffering practical guidance for safeguarding privacy when deploying compressed\nLLMs4Code.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u91cf\u5316\u6280\u672f\u5bf9\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs4Code\uff09\u7684\u4efb\u52a1\u6027\u80fd\u548c\u9690\u79c1\u98ce\u9669\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u91cf\u5316\u80fd\u663e\u8457\u964d\u4f4e\u9690\u79c1\u98ce\u9669\uff0c\u5e76\u4e0e\u4efb\u52a1\u6027\u80fd\u5b58\u5728\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u7531\u4e8eLLMs4Code\u5728\u8bad\u7ec3\u4e2d\u53ef\u80fd\u5305\u542b\u654f\u611f\u6570\u636e\uff08\u5982\u4e91\u670d\u52a1\u51ed\u8bc1\u548c\u4e2a\u4eba\u4fe1\u606f\uff09\uff0c\u9690\u79c1\u98ce\u9669\u5907\u53d7\u5173\u6ce8\u3002\u91cf\u5316\u6280\u672f\u5e7f\u6cdb\u7528\u4e8e\u964d\u4f4e\u6a21\u578b\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u5176\u5bf9\u9690\u79c1\u4fdd\u62a4\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7814\u7a76\u91c7\u7528\u9759\u6001\u548c\u52a8\u6001\u91cf\u5316\u6280\u672f\uff0c\u5e94\u7528\u4e8ePythia\u3001CodeGen\u548cGPTNeo\u4e09\u79cd\u4ee3\u8868\u6027\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u6210\u5458\u63a8\u65ad\uff08MI\uff09\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\u3002", "result": "\u91cf\u5316\u663e\u8457\u964d\u4f4e\u4e86\u9690\u79c1\u98ce\u9669\uff0c\u4e14\u4efb\u52a1\u6027\u80fd\u4e0e\u9690\u79c1\u98ce\u9669\u5448\u6b63\u76f8\u5173\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u91cf\u5316\u540e\u7684\u8f83\u5927\u6a21\u578b\u53ef\u80fd\u5728\u4efb\u52a1\u6027\u80fd\u548c\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u3002", "conclusion": "\u91cf\u5316\u662f\u964d\u4f4eLLMs4Code\u9690\u79c1\u98ce\u9669\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2508.00424", "pdf": "https://arxiv.org/pdf/2508.00424", "abs": "https://arxiv.org/abs/2508.00424", "authors": ["Kresimir Matkovic", "Rainer Splechtna", "Denis Gracanin", "Helwig Hauser"], "title": "CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data", "categories": ["cs.GR"], "comment": "Will be published in TVCG and presented at IEEE VIS", "summary": "The interactive visual analysis of set-typed data, i.e., data with attributes\nthat are of type set, is a rewarding area of research and applications.\nValuable prior work has contributed solutions that enable the study of such\ndata with individual set-typed dimensions. In this paper, we present CrossSet,\na novel method for the joint study of two set-typed dimensions and their\ninterplay. Based on a task analysis, we describe a new, multi-scale approach to\nthe interactive visual exploration and analysis of such data. Two set-typed\ndata dimensions are jointly visualized using a hierarchical matrix layout,\nenabling the analysis of the interactions between two set-typed attributes at\nseveral levels, in addition to the analysis of individual such dimensions.\nCrossSet is anchored at a compact, large-scale overview that is complemented by\ndrill-down opportunities to study the relations between and within the\nset-typed dimensions, enabling an interactive visual multi-scale exploration\nand analysis of bivariate set-typed data. Such an interactive approach makes it\npossible to study single set-typed dimensions in detail, to gain an overview of\nthe interaction and association between two such dimensions, to refine one of\nthe dimensions to gain additional details at several levels, and to drill down\nto the specific interactions of individual set-elements from the set-typed\ndimensions. To demonstrate the effectiveness and efficiency of CrossSet, we\nhave evaluated the new method in the context of several application scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCrossSet\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5206\u6790\u53cc\u53d8\u91cf\u96c6\u5408\u7c7b\u578b\u6570\u636e\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u65b9\u6cd5\u8054\u5408\u7814\u7a76\u4e24\u4e2a\u96c6\u5408\u7c7b\u578b\u7684\u7ef4\u5ea6\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u4e2a\u96c6\u5408\u7c7b\u578b\u7ef4\u5ea6\u7684\u5206\u6790\uff0c\u800c\u7f3a\u4e4f\u5bf9\u4e24\u4e2a\u96c6\u5408\u7c7b\u578b\u7ef4\u5ea6\u53ca\u5176\u4ea4\u4e92\u4f5c\u7528\u7684\u8054\u5408\u7814\u7a76\u3002", "method": "\u57fa\u4e8e\u4efb\u52a1\u5206\u6790\uff0c\u91c7\u7528\u5206\u5c42\u77e9\u9635\u5e03\u5c40\u5b9e\u73b0\u53cc\u7ef4\u5ea6\u96c6\u5408\u7c7b\u578b\u6570\u636e\u7684\u591a\u5c3a\u5ea6\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u652f\u6301\u4ece\u5168\u5c40\u6982\u89c8\u5230\u7ec6\u8282\u5206\u6790\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u5e94\u7528\u573a\u666f\u9a8c\u8bc1\u4e86CrossSet\u7684\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002", "conclusion": "CrossSet\u4e3a\u53cc\u53d8\u91cf\u96c6\u5408\u7c7b\u578b\u6570\u636e\u7684\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u9ad8\u6548\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.00004", "pdf": "https://arxiv.org/pdf/2508.00004", "abs": "https://arxiv.org/abs/2508.00004", "authors": ["Dazhu Li", "Sujata Ghosh", "Fenrong Liu"], "title": "Reasoning under uncertainty in the game of Cops and Robbers", "categories": ["cs.LO", "math.LO"], "comment": null, "summary": "The game of Cops and Robbers is an important model for studying computational\nqueries in pursuit-evasion environments, among others. As recent logical\nexplorations have shown, its structure exhibits appealing analogies with modal\nlogic. In this paper, we enrich the game with a setting in which players may\nhave imperfect information. We propose a new formal framework, Epistemic Logic\nof Cops and Robbers (ELCR), to make the core notions of the game precise, for\ninstance, players' positions, observational power and inference. Applying ELCR\nto analyze the game, we obtain an automated way to track interactions between\nplayers and characterize their information updates during the game. The update\nmechanism is defined by a novel dynamic operator, and we compare it with some\nrelevant paradigms from the game and logic perspectives. We study various\nproperties of ELCR including axiomatization and decidability. To our knowledge,\nthis is the first attempt to explore these games from a formal point of view\nwhere (partial) information available to players is taken into account.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u6846\u67b6ELCR\uff0c\u7528\u4e8e\u5206\u6790Cops and Robbers\u6e38\u620f\u4e2d\u73a9\u5bb6\u7684\u4e0d\u5b8c\u5168\u4fe1\u606f\uff0c\u5e76\u7814\u7a76\u5176\u903b\u8f91\u6027\u8d28\u548c\u66f4\u65b0\u673a\u5236\u3002", "motivation": "\u7814\u7a76Cops and Robbers\u6e38\u620f\u4e2d\u73a9\u5bb6\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u5f71\u54cd\uff0c\u586b\u8865\u5f62\u5f0f\u5316\u5206\u6790\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51faEpistemic Logic of Cops and Robbers (ELCR)\u6846\u67b6\uff0c\u7eb3\u5165\u73a9\u5bb6\u4f4d\u7f6e\u3001\u89c2\u5bdf\u80fd\u529b\u548c\u63a8\u7406\u7b49\u6838\u5fc3\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u64cd\u4f5c\u7b26\u5b9a\u4e49\u4fe1\u606f\u66f4\u65b0\u673a\u5236\u3002", "result": "\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u8ffd\u8e2a\u73a9\u5bb6\u4e92\u52a8\u548c\u4fe1\u606f\u66f4\u65b0\uff0c\u7814\u7a76\u4e86ELCR\u7684\u591a\u79cd\u6027\u8d28\uff08\u5982\u516c\u7406\u5316\u548c\u53ef\u5224\u5b9a\u6027\uff09\uff0c\u5e76\u4e0e\u76f8\u5173\u903b\u8f91\u548c\u6e38\u620f\u8303\u5f0f\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "ELCR\u6846\u67b6\u9996\u6b21\u4ece\u5f62\u5f0f\u5316\u89d2\u5ea6\u63a2\u8ba8\u4e86Cops and Robbers\u6e38\u620f\u4e2d\u7684\u4e0d\u5b8c\u5168\u4fe1\u606f\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.00305", "pdf": "https://arxiv.org/pdf/2508.00305", "abs": "https://arxiv.org/abs/2508.00305", "authors": ["Ammar Ahmed", "Sheng Di", "Franck Cappello", "Zirui Liu", "Jingoo Han", "Ali Anwar"], "title": "Systematic Evaluation of Optimization Techniques for Long-Context Language Models", "categories": ["cs.CL", "cs.LG", "cs.PF"], "comment": null, "summary": "Large language models (LLMs) excel across diverse natural language processing\ntasks but face resource demands and limited context windows. Although\ntechniques like pruning, quantization, and token dropping can mitigate these\nissues, their efficacy in long-context scenarios and system evaluation remains\nunderexplored. This paper systematically benchmarks these optimizations,\ncharacterizing memory usage, latency, and throughput, and studies how these\nmethods impact the quality of text generation. We first analyze individual\noptimization methods for two LLM architectures supporting long context and then\nsystematically evaluate combinations of these techniques to assess how this\ndeeper analysis impacts performance metrics. We subsequently study the\nscalability of individual optimization methods on a larger variant with 70\nbillion-parameter model. Our novel insights reveal that naive combination\ninference optimization algorithms can adversely affect larger models due to\ncompounded approximation errors, as compared to their smaller counterparts.\nExperiments show that relying solely on F1 obscures these effects by hiding\nprecision-recall trade-offs in question answering tasks. By integrating\nsystem-level profiling with task-specific insights, this study helps LLM\npractitioners and researchers explore and balance efficiency, accuracy, and\nscalability across tasks and hardware configurations.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4f18\u5316\u6280\u672f\uff08\u5982\u526a\u679d\u3001\u91cf\u5316\u548c\u6807\u8bb0\u4e22\u5f03\uff09\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u7684\u6548\u679c\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u53ca\u5176\u5728\u66f4\u5927\u6a21\u578b\u4e0a\u7684\u6269\u5c55\u6027\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u591a\u79cdNLP\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9ad8\u8d44\u6e90\u9700\u6c42\u548c\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u4e24\u79cd\u652f\u6301\u957f\u4e0a\u4e0b\u6587\u7684LLM\u67b6\u6784\u7684\u4f18\u5316\u65b9\u6cd5\uff08\u5355\u72ec\u53ca\u7ec4\u5408\u4f7f\u7528\uff09\uff0c\u5e76\u6269\u5c55\u8bc4\u4f30\u5230700\u4ebf\u53c2\u6570\u7684\u66f4\u5927\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f18\u5316\u65b9\u6cd5\u7684\u7b80\u5355\u7ec4\u5408\u4f1a\u56e0\u7d2f\u79ef\u8fd1\u4f3c\u8bef\u5dee\u800c\u5bf9\u8f83\u5927\u6a21\u578b\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u4e14\u4ec5\u4f9d\u8d56F1\u5206\u6570\u4f1a\u63a9\u76d6\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u7cbe\u5ea6-\u53ec\u56de\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aLLM\u5b9e\u8df5\u8005\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u5e73\u8861\u6548\u7387\u3001\u51c6\u786e\u6027\u548c\u6269\u5c55\u6027\u7684\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.23585", "pdf": "https://arxiv.org/pdf/2507.23585", "abs": "https://arxiv.org/abs/2507.23585", "authors": ["Sophia Liu", "Shm Garanganao Almeda"], "title": "Agency Among Agents: Designing with Hypertextual Friction in the Algorithmic Web", "categories": ["cs.HC", "cs.AI", "cs.MM", "cs.SI"], "comment": "To appear in: Adjunct Proceedings of the 36th ACM Conference on\n  Hypertext and Social Media, Chicago, IL, USA, September 15-18, 2025", "summary": "Today's algorithm-driven interfaces, from recommendation feeds to GenAI\ntools, often prioritize engagement and efficiency at the expense of user\nagency. As systems take on more decision-making, users have less control over\nwhat they see and how meaning or relationships between content are constructed.\nThis paper introduces \"Hypertextual Friction,\" a conceptual design stance that\nrepositions classical hypertext principles--friction, traceability, and\nstructure--as actionable values for reclaiming agency in algorithmically\nmediated environments. Through a comparative analysis of real-world\ninterfaces--Wikipedia vs. Instagram Explore, and Are.na vs. GenAI image\ntools--we examine how different systems structure user experience, navigation,\nand authorship. We show that hypertext systems emphasize provenance,\nassociative thinking, and user-driven meaning-making, while algorithmic systems\ntend to obscure process and flatten participation. We contribute: (1) a\ncomparative analysis of how interface structures shape agency in user-driven\nversus agent-driven systems, and (2) a conceptual stance that offers\nhypertextual values as design commitments for reclaiming agency in an\nincreasingly algorithmic web.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u2018\u8d85\u6587\u672c\u6469\u64e6\u2019\u6982\u5ff5\uff0c\u65e8\u5728\u901a\u8fc7\u91cd\u65b0\u5e94\u7528\u8d85\u6587\u672c\u539f\u5219\uff08\u6469\u64e6\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u7ed3\u6784\uff09\u6765\u6062\u590d\u7b97\u6cd5\u9a71\u52a8\u754c\u9762\u4e2d\u88ab\u524a\u5f31\u7684\u7528\u6237\u63a7\u5236\u6743\u3002", "motivation": "\u5f53\u524d\u7b97\u6cd5\u9a71\u52a8\u7684\u754c\u9762\uff08\u5982\u63a8\u8350\u7cfb\u7edf\u548c\u751f\u6210\u5f0fAI\u5de5\u5177\uff09\u4ee5\u727a\u7272\u7528\u6237\u63a7\u5236\u6743\u4e3a\u4ee3\u4ef7\u4f18\u5148\u8003\u8651\u53c2\u4e0e\u5ea6\u548c\u6548\u7387\uff0c\u5bfc\u81f4\u7528\u6237\u5bf9\u5185\u5bb9\u7684\u53ef\u89c1\u6027\u548c\u610f\u4e49\u6784\u5efa\u5931\u53bb\u63a7\u5236\u3002", "method": "\u901a\u8fc7\u5bf9Wikipedia\u4e0eInstagram Explore\u4ee5\u53caAre.na\u4e0e\u751f\u6210\u5f0fAI\u56fe\u50cf\u5de5\u5177\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u7814\u7a76\u4e0d\u540c\u7cfb\u7edf\u5982\u4f55\u6784\u5efa\u7528\u6237\u4f53\u9a8c\u3001\u5bfc\u822a\u548c\u521b\u4f5c\u3002", "result": "\u8d85\u6587\u672c\u7cfb\u7edf\u5f3a\u8c03\u6765\u6e90\u3001\u5173\u8054\u601d\u7ef4\u548c\u7528\u6237\u9a71\u52a8\u7684\u610f\u4e49\u6784\u5efa\uff0c\u800c\u7b97\u6cd5\u7cfb\u7edf\u5219\u6a21\u7cca\u8fc7\u7a0b\u5e76\u524a\u5f31\u53c2\u4e0e\u611f\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u2018\u8d85\u6587\u672c\u6469\u64e6\u2019\u4f5c\u4e3a\u8bbe\u8ba1\u7acb\u573a\uff0c\u4e3a\u5728\u7b97\u6cd5\u4e3b\u5bfc\u7684\u7f51\u7edc\u73af\u5883\u4e2d\u6062\u590d\u7528\u6237\u63a7\u5236\u6743\u63d0\u4f9b\u4e86\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00013", "pdf": "https://arxiv.org/pdf/2508.00013", "abs": "https://arxiv.org/abs/2508.00013", "authors": ["Zurabi Kobaladze", "Anna Arnania", "Tamar Sanikidze"], "title": "From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms", "categories": ["cs.PL", "I.2.6; F.1.1"], "comment": "78 pages. Undergraduate thesis project submitted in partial\n  fulfillment of the requirements for the Bachelor's degree in Computer Science\n  at Kutaisi International University", "summary": "Program synthesis--the automated generation of executable code from\nhigh-level specifications--has been a central goal of computer science for over\nfifty years. This thesis provides a comparative literature review of the main\nparadigms that have shaped the field, tracing its evolution from formal logic\nbased methods to recent advances using large scale neural models. We examine\nfive key approaches: logic based (deductive) synthesis, inductive (example\nbased) synthesis, sketch/schema based synthesis, large language model based\nsynthesis, and neuro-symbolic hybrids. For each, we analyze foundational\nprinciples, notable systems, and practical applications, highlighting trade\noffs between correctness guarantees, specification requirements, search\ncomplexity, and expressive power. By reviewing developments from formally\nverified synthesis tools such as KIDS and Coq to data driven models generating\nprobabilistic code from natural language like Codex, we present a comprehensive\nnarrative of progress and ongoing challenges. This work emphasizes the\ntransition from symbolic to hybrid neuro-symbolic methods and outlines future\ndirections for reliable and scalable program synthesis.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86\u7a0b\u5e8f\u5408\u6210\u7684\u4e94\u79cd\u4e3b\u8981\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u8fdb\u5c55\u4e0e\u6311\u6218\uff0c\u5f3a\u8c03\u4e86\u4ece\u7b26\u53f7\u65b9\u6cd5\u5230\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u7684\u8f6c\u53d8\u3002", "motivation": "\u63a2\u7a76\u7a0b\u5e8f\u5408\u6210\u9886\u57df\u7684\u53d1\u5c55\u5386\u7a0b\u548c\u4e3b\u8981\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e0d\u540c\u8303\u5f0f\u7684\u4f18\u7f3a\u70b9\u3002", "method": "\u5bf9\u4e94\u79cd\u4e3b\u8981\u65b9\u6cd5\uff08\u57fa\u4e8e\u903b\u8f91\u3001\u5f52\u7eb3\u3001\u8349\u56fe/\u6a21\u5f0f\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\uff09\u8fdb\u884c\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u5176\u539f\u7406\u3001\u7cfb\u7edf\u548c\u5e94\u7528\u3002", "result": "\u603b\u7ed3\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u6743\u8861\uff08\u5982\u6b63\u786e\u6027\u4fdd\u8bc1\u548c\u641c\u7d22\u590d\u6742\u6027\uff09\uff0c\u5e76\u5c55\u793a\u4e86\u4ece\u7b26\u53f7\u5230\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u7684\u6f14\u53d8\u3002", "conclusion": "\u672a\u6765\u53d1\u5c55\u65b9\u5411\u662f\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u7a0b\u5e8f\u5408\u6210\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u3002"}}
{"id": "2508.00009", "pdf": "https://arxiv.org/pdf/2508.00009", "abs": "https://arxiv.org/abs/2508.00009", "authors": ["Sourav Mondal", "Elaine Wong"], "title": "Enabling Immersive XR Collaborations over FTTR Networks (Invited)", "categories": ["cs.NI", "cs.AI"], "comment": "This invited paper was presented in Optica Advanced Photonic Congress\n  2025", "summary": "Fiber-To-The-Room is a potential solution to achieve in-premise extended\nreality collaborations. This paper explores predictive bandwidth allocation and\nseamless handover schemes over FTTR, showing high-quality immersive experience\nfor in-premise collaborations can be achieved. \\c{opyright} 2025 The Author(s).", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86FTTR\uff08\u5149\u7ea4\u5230\u623f\u95f4\uff09\u4e0b\u7684\u9884\u6d4b\u5e26\u5bbd\u5206\u914d\u548c\u65e0\u7f1d\u5207\u6362\u65b9\u6848\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u6c89\u6d78\u5f0f\u534f\u4f5c\u4f53\u9a8c\u3002", "motivation": "\u7814\u7a76FTTR\u4f5c\u4e3a\u5b9e\u73b0\u5ba4\u5185\u6269\u5c55\u73b0\u5b9e\u534f\u4f5c\u7684\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u63d0\u5347\u534f\u4f5c\u4f53\u9a8c\u3002", "method": "\u63d0\u51fa\u4e86\u9884\u6d4b\u5e26\u5bbd\u5206\u914d\u548c\u65e0\u7f1d\u5207\u6362\u65b9\u6848\u3002", "result": "\u901a\u8fc7FTTR\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u6c89\u6d78\u5f0f\u534f\u4f5c\u4f53\u9a8c\u3002", "conclusion": "FTTR\u7ed3\u5408\u9884\u6d4b\u5e26\u5bbd\u5206\u914d\u548c\u65e0\u7f1d\u5207\u6362\u65b9\u6848\uff0c\u662f\u63d0\u5347\u5ba4\u5185\u534f\u4f5c\u4f53\u9a8c\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.00103", "pdf": "https://arxiv.org/pdf/2508.00103", "abs": "https://arxiv.org/abs/2508.00103", "authors": ["Guilherme Guerino", "Luiz Rodrigues", "Luana Bianchiniand Mariana Alves", "Marcelo Marinho", "Thomaz Veloso", "Valmir Macario", "Diego Dermeval", "Thales Vieira", "Ig Bittencourt", "Seiji Isotani"], "title": "A Mixed User-Centered Approach to Enable Augmented Intelligence in Intelligent Tutoring Systems: The Case of MathAIde app", "categories": ["cs.HC", "cs.AI", "68T01", "H.5.0; I.2.0"], "comment": "Article accepted in the International Journal of Human-Computer\n  Interaction", "summary": "Integrating Artificial Intelligence in Education (AIED) aims to enhance\nlearning experiences through technologies like Intelligent Tutoring Systems\n(ITS), offering personalized learning, increased engagement, and improved\nretention rates. However, AIED faces three main challenges: the critical role\nof teachers in the design process, the limitations and reliability of AI tools,\nand the accessibility of technological resources. Augmented Intelligence (AuI)\naddresses these challenges by enhancing human capabilities rather than\nreplacing them, allowing systems to suggest solutions. In contrast, humans\nprovide final assessments, thus improving AI over time. In this sense, this\nstudy focuses on designing, developing, and evaluating MathAIde, an ITS that\ncorrects mathematics exercises using computer vision and AI and provides\nfeedback based on photos of student work. The methodology included\nbrainstorming sessions with potential users, high-fidelity prototyping, A/B\ntesting, and a case study involving real-world classroom environments for\nteachers and students. Our research identified several design possibilities for\nimplementing AuI in ITSs, emphasizing a balance between user needs and\ntechnological feasibility. Prioritization and validation through prototyping\nand testing highlighted the importance of efficiency metrics, ultimately\nleading to a solution that offers pre-defined remediation alternatives for\nteachers. Real-world deployment demonstrated the usefulness of the proposed\nsolution. Our research contributes to the literature by providing a usable,\nteacher-centered design approach that involves teachers in all design phases.\nAs a practical implication, we highlight that the user-centered design approach\nincreases the usefulness and adoption potential of AIED systems, especially in\nresource-limited environments.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faMathAIde\u7cfb\u7edf\uff0c\u7ed3\u5408\u8ba1\u7b97\u673a\u89c6\u89c9\u548cAI\u7ea0\u6b63\u6570\u5b66\u7ec3\u4e60\uff0c\u5e76\u901a\u8fc7\u53cd\u9988\u63d0\u5347\u5b66\u4e60\u6548\u679c\uff0c\u5f3a\u8c03\u6559\u5e08\u5728\u8bbe\u8ba1\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\u3002", "motivation": "\u89e3\u51b3AI\u6559\u80b2\u4e2d\u6559\u5e08\u53c2\u4e0e\u4e0d\u8db3\u3001AI\u5de5\u5177\u9650\u5236\u53ca\u8d44\u6e90\u53ef\u53ca\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u667a\u80fd\uff08AuI\uff09\u63d0\u5347\u7cfb\u7edf\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u5934\u8111\u98ce\u66b4\u3001\u9ad8\u4fdd\u771f\u539f\u578b\u3001A/B\u6d4b\u8bd5\u53ca\u771f\u5b9e\u8bfe\u5802\u6848\u4f8b\u7814\u7a76\uff0c\u8bbe\u8ba1\u5e76\u8bc4\u4f30MathAIde\u7cfb\u7edf\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u6559\u5e08\u4e3a\u4e2d\u5fc3\u7684AuI\u5b9e\u73b0\u65b9\u6848\uff0c\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u548c\u9ad8\u91c7\u7eb3\u6f5c\u529b\u3002", "conclusion": "\u7528\u6237\u4e2d\u5fc3\u8bbe\u8ba1\u63d0\u5347AIED\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u548c\u91c7\u7eb3\u7387\uff0c\u5c24\u5176\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u3002"}}
{"id": "2508.00017", "pdf": "https://arxiv.org/pdf/2508.00017", "abs": "https://arxiv.org/abs/2508.00017", "authors": ["Nikolai Sergeev"], "title": "Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation", "categories": ["cs.LO", "cs.AI", "cs.AR"], "comment": "19 pages, 5 figures. Code and interactive HTML proof graphs\n  permanently archived on Zenodo (DOI: 10.5281/zenodo.16408441)", "summary": "We present Generative Logic (GL), a deterministic architecture that begins\nfrom user-supplied axiomatic definitions -- written in a minimalist\nMathematical Programming Language (MPL) -- and systematically explores their\ndeductive neighborhood. Definitions are compiled into a distributed grid of\nsimple Logic Blocks (LBs) that exchange messages; any time several expressions\nunify under an inference rule, a new fact is emitted with full provenance to\nits sources, yielding replayable, auditable proof graphs.\n  A prototype software implementation instantiates the workflow on first-order\nPeano arithmetic. Starting only from the Peano axioms, GL enumerates candidate\nimplications, applies normalization and type filters, and automatically\nreconstructs machine-checkable proofs of foundational arithmetic laws including\nassociativity and commutativity of addition, associativity and commutativity of\nmultiplication, and distributivity. Generated proofs export to navigable HTML\nso that every inference step can be inspected independently.\n  We outline a hardware-software co-design path toward massively parallel\nrealizations and describe prospective integration with probabilistic models\n(e.g., Large Language Models (LLMs)) for autoformalization and conjecture\nseeding. The Python and MPL code to reproduce the Peano experiments, along with\nthe full HTML proof graphs, are available in the project's GitHub repository at\nhttps://github.com/Generative-Logic/GL/tree/35a111ea9ba53afe051703d6050be0c3923e9724\nand are permanently archived at https://doi.org/10.5281/zenodo.16408441. We\ninvite community feedback and collaboration.", "AI": {"tldr": "\u751f\u6210\u903b\u8f91\uff08GL\uff09\u662f\u4e00\u79cd\u57fa\u4e8e\u7528\u6237\u63d0\u4f9b\u7684\u516c\u7406\u5316\u5b9a\u4e49\u7684\u786e\u5b9a\u6027\u67b6\u6784\uff0c\u901a\u8fc7\u903b\u8f91\u5757\uff08LBs\uff09\u7cfb\u7edf\u63a2\u7d22\u5176\u6f14\u7ece\u90bb\u57df\uff0c\u81ea\u52a8\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u3002", "motivation": "\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u53ef\u5ba1\u8ba1\u3001\u53ef\u91cd\u73b0\u7684\u8bc1\u660e\u7cfb\u7edf\uff0c\u81ea\u52a8\u751f\u6210\u548c\u9a8c\u8bc1\u6570\u5b66\u5b9a\u7406\uff0c\u652f\u6301\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u3002", "method": "\u5c06\u516c\u7406\u5316\u5b9a\u4e49\u7f16\u8bd1\u4e3a\u903b\u8f91\u5757\u7f51\u683c\uff0c\u901a\u8fc7\u6d88\u606f\u4ea4\u6362\u548c\u7edf\u4e00\u63a8\u7406\u89c4\u5219\u751f\u6210\u65b0\u4e8b\u5b9e\uff0c\u5b9e\u73b0\u673a\u5668\u53ef\u68c0\u67e5\u7684\u8bc1\u660e\u3002", "result": "\u6210\u529f\u4ece\u76ae\u4e9a\u8bfa\u516c\u7406\u81ea\u52a8\u751f\u6210\u4e86\u52a0\u6cd5\u3001\u4e58\u6cd5\u7b49\u57fa\u7840\u7b97\u672f\u5b9a\u5f8b\u7684\u53ef\u9a8c\u8bc1\u8bc1\u660e\uff0c\u5e76\u5bfc\u51fa\u4e3a\u53ef\u4ea4\u4e92\u7684HTML\u683c\u5f0f\u3002", "conclusion": "GL\u5c55\u793a\u4e86\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u7684\u6f5c\u529b\uff0c\u4e3a\u4e0e\u6982\u7387\u6a21\u578b\uff08\u5982LLMs\uff09\u7684\u96c6\u6210\u548c\u786c\u4ef6\u52a0\u901f\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.00426", "pdf": "https://arxiv.org/pdf/2508.00426", "abs": "https://arxiv.org/abs/2508.00426", "authors": ["Rohan Gandhi", "Ankur Mallick", "Ken Sueda", "Rui Liang"], "title": "Tetris: Efficient Intra-Datacenter Calls Packing for Large Conferencing Services", "categories": ["cs.DC"], "comment": null, "summary": "Conference services like Zoom, Microsoft Teams, and Google Meet facilitate\nmillions of daily calls, yet ensuring high performance at low costs remains a\nsignificant challenge. This paper revisits the problem of packing calls across\nMedia Processor (MP) servers that host the calls within individual datacenters\n(DCs). We show that the algorithm used in Teams -- a large scale conferencing\nservice as well as other state-of-art algorithms are prone to placing calls\nresulting in some of the MPs becoming hot (high CPU utilization) that leads to\ndegraded performance and/or elevated hosting costs. The problem arises from\ndisregarding the variability in CPU usage among calls, influenced by\ndifferences in participant numbers and media types (audio/video), compounded by\nbursty call arrivals. To tackle this, we propose Tetris, a multi-step framework\nwhich (a) optimizes initial call assignments by leveraging historical data and\n(b) periodically migrates calls from hot MPs using linear optimization, aiming\nto minimize hot MP usage. Evaluation based on a 24-hour trace of over 10\nmillion calls in one DC shows that Tetris reduces participant numbers on hot\nMPs by at least 2.5X.", "AI": {"tldr": "Tetris\u6846\u67b6\u901a\u8fc7\u5229\u7528\u5386\u53f2\u6570\u636e\u548c\u5b9a\u671f\u8fc1\u79fb\u4f18\u5316\u547c\u53eb\u5206\u914d\uff0c\u663e\u8457\u964d\u4f4e\u70ed\u70b9MP\u7684\u8d1f\u8f7d\u3002", "motivation": "\u5f53\u524d\u7b97\u6cd5\u5728\u9ad8\u8d1f\u8f7d\u65f6\u6613\u5bfc\u81f4MP\u670d\u52a1\u5668\u70ed\u70b9\u95ee\u9898\uff0c\u5f71\u54cd\u6027\u80fd\u548c\u6210\u672c\u3002", "method": "\u63d0\u51faTetris\u6846\u67b6\uff0c\u5206\u4e24\u6b65\u4f18\u5316\u547c\u53eb\u5206\u914d\uff1a\u57fa\u4e8e\u5386\u53f2\u6570\u636e\u7684\u521d\u59cb\u5206\u914d\u548c\u5b9a\u671f\u8fc1\u79fb\u3002", "result": "\u572824\u5c0f\u65f6\u8d85\u8fc71000\u4e07\u6b21\u547c\u53eb\u7684\u6d4b\u8bd5\u4e2d\uff0cTetris\u5c06\u70ed\u70b9MP\u4e0a\u7684\u53c2\u4e0e\u8005\u6570\u51cf\u5c11\u81f3\u5c112.5\u500d\u3002", "conclusion": "Tetris\u6709\u6548\u89e3\u51b3\u4e86MP\u670d\u52a1\u5668\u70ed\u70b9\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2508.00198", "pdf": "https://arxiv.org/pdf/2508.00198", "abs": "https://arxiv.org/abs/2508.00198", "authors": ["Cleyton Magalhaes", "Italo Santos", "Brody Stuart-Verner", "Ronnie de Souza Santos"], "title": "Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems", "categories": ["cs.SE"], "comment": null, "summary": "Background: Software systems powered by large language models are becoming a\nroutine part of everyday technologies, supporting applications across a wide\nrange of domains. In software engineering, many studies have focused on how\nLLMs support tasks such as code generation, debugging, and documentation.\nHowever, there has been limited focus on how full systems that integrate LLMs\nare tested during development. Aims: This study explores how LLM-powered\nsystems are tested in the context of real-world application development.\nMethod: We conducted an exploratory case study using 99 individual reports\nwritten by students who built and deployed LLM-powered applications as part of\na university course. Each report was independently analyzed using thematic\nanalysis, supported by a structured coding process. Results: Testing strategies\ncombined manual and automated methods to evaluate both system logic and model\nbehavior. Common practices included exploratory testing, unit testing, and\nprompt iteration. Reported challenges included integration failures,\nunpredictable outputs, prompt sensitivity, hallucinations, and uncertainty\nabout correctness. Conclusions: Testing LLM-powered systems required\nadaptations to traditional verification methods, blending source-level\nreasoning with behavior-aware evaluations. These findings provide evidence on\nthe practical context of testing generative components in software systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u7cfb\u7edf\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u63d0\u51fa\u9700\u8981\u7ed3\u5408\u624b\u52a8\u4e0e\u81ea\u52a8\u5316\u7b56\u7565\uff0c\u5e76\u9002\u5e94\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u7684\u8c03\u6574\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u591a\u5173\u6ce8LLM\u5728\u4ee3\u7801\u751f\u6210\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u800c\u7f3a\u4e4f\u5bf9LLM\u7cfb\u7edf\u5f00\u53d1\u4e2d\u6d4b\u8bd5\u65b9\u6cd5\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u901a\u8fc799\u4efd\u5b66\u751f\u62a5\u544a\uff0c\u91c7\u7528\u4e3b\u9898\u5206\u6790\u548c\u7ed3\u6784\u5316\u7f16\u7801\u8fdb\u884c\u63a2\u7d22\u6027\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u6d4b\u8bd5\u7b56\u7565\u7ed3\u5408\u624b\u52a8\u4e0e\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u6db5\u76d6\u7cfb\u7edf\u903b\u8f91\u548c\u6a21\u578b\u884c\u4e3a\uff0c\u5e38\u89c1\u6311\u6218\u5305\u62ec\u8f93\u51fa\u4e0d\u7a33\u5b9a\u548c\u63d0\u793a\u654f\u611f\u6027\u3002", "conclusion": "\u6d4b\u8bd5LLM\u7cfb\u7edf\u9700\u878d\u5408\u6e90\u7801\u63a8\u7406\u548c\u884c\u4e3a\u8bc4\u4f30\uff0c\u4e3a\u751f\u6210\u5f0f\u7ec4\u4ef6\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5b9e\u8df5\u4f9d\u636e\u3002"}}
{"id": "2508.00428", "pdf": "https://arxiv.org/pdf/2508.00428", "abs": "https://arxiv.org/abs/2508.00428", "authors": ["Nan Xiang", "Tianyi Liang", "Haiwen Huang", "Shiqi Jiang", "Hao Huang", "Yifei Huang", "Liangyu Chen", "Changbo Wang", "Chenhui Li"], "title": "Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation", "categories": ["cs.GR", "cs.HC"], "comment": "IEEE VIS VAST 2025 ACM 2012 CCS - Human-centered computing,\n  Visualization, Visualization design and evaluation methods", "summary": "Text-to-3D (T23D) generation has transformed digital content creation, yet\nremains bottlenecked by blind trial-and-error prompting processes that yield\nunpredictable results. While visual prompt engineering has advanced in\ntext-to-image domains, its application to 3D generation presents unique\nchallenges requiring multi-view consistency evaluation and spatial\nunderstanding. We present Sel3DCraft, a visual prompt engineering system for\nT23D that transforms unstructured exploration into a guided visual process. Our\napproach introduces three key innovations: a dual-branch structure combining\nretrieval and generation for diverse candidate exploration; a multi-view hybrid\nscoring approach that leverages MLLMs with innovative high-level metrics to\nassess 3D models with human-expert consistency; and a prompt-driven visual\nanalytics suite that enables intuitive defect identification and refinement.\nExtensive testing and user studies demonstrate that Sel3DCraft surpasses other\nT23D systems in supporting creativity for designers.", "AI": {"tldr": "Sel3DCraft\u662f\u4e00\u4e2a\u7528\u4e8e\u6587\u672c\u52303D\u751f\u6210\u7684\u89c6\u89c9\u63d0\u793a\u5de5\u7a0b\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u7ed3\u6784\u3001\u591a\u89c6\u56fe\u6df7\u5408\u8bc4\u5206\u548c\u89c6\u89c9\u5206\u6790\u5957\u4ef6\u89e3\u51b3\u4e86\u4f20\u7edf\u76f2\u8bd5\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u7684\u6587\u672c\u52303D\u751f\u6210\u6280\u672f\u4f9d\u8d56\u4e8e\u76f2\u76ee\u7684\u8bd5\u9519\u63d0\u793a\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9884\u6d4b\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u76f4\u89c2\u7684\u5f15\u5bfc\u65b9\u6cd5\u3002", "method": "Sel3DCraft\u91c7\u7528\u53cc\u5206\u652f\u7ed3\u6784\uff08\u68c0\u7d22\u4e0e\u751f\u6210\u7ed3\u5408\uff09\u3001\u591a\u89c6\u56fe\u6df7\u5408\u8bc4\u5206\u4ee5\u53ca\u89c6\u89c9\u5206\u6790\u5de5\u5177\uff0c\u4ee5\u63d0\u53473D\u6a21\u578b\u7684\u8bc4\u4f30\u548c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cSel3DCraft\u5728\u652f\u6301\u8bbe\u8ba1\u5e08\u521b\u9020\u529b\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u6587\u672c\u52303D\u751f\u6210\u7cfb\u7edf\u3002", "conclusion": "Sel3DCraft\u901a\u8fc7\u89c6\u89c9\u63d0\u793a\u5de5\u7a0b\u6539\u8fdb\u4e86\u6587\u672c\u52303D\u751f\u6210\u7684\u6548\u7387\u548c\u53ef\u63a7\u6027\uff0c\u4e3a\u8bbe\u8ba1\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2508.00014", "pdf": "https://arxiv.org/pdf/2508.00014", "abs": "https://arxiv.org/abs/2508.00014", "authors": ["Isa Vialard"], "title": "Deciding the Value of Two-Clock Almost Non-Zeno Weighted Timed Games", "categories": ["cs.LO"], "comment": null, "summary": "The Value Problem for weighted timed games (wtgs) consists in determining,\ngiven a two-player weighted timed game with a reachability objective and a\nrational threshold, whether or not the value of the game exceeds the threshold.\nWhen restrained to wtgs with non-negative weight, this problem is known to be\nundecidable for weighted timed games with three or more clocks, and decidable\nfor one-clock wtgs. The Value Problem for two-clock non-negative wtgs, which\nremained stubbornly open for a decade, was recently shown to be undecidable. In\nthis article, we show that the Value Problem is decidable when considering\ntwo-clock almost non-Zeno wtgs.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5e26\u6709\u4e24\u65f6\u949f\u4e14\u51e0\u4e4e\u975eZeno\u7684\u52a0\u6743\u5b9a\u65f6\u6e38\u620f\u7684\u4ef7\u503c\u95ee\u9898\uff0c\u8868\u660e\u5176\u5177\u6709\u53ef\u5224\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76\u52a0\u6743\u5b9a\u65f6\u6e38\u620f\uff08wtgs\uff09\u7684\u4ef7\u503c\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4e24\u65f6\u949f\u4e14\u51e0\u4e4e\u975eZeno\u7684\u6e38\u620f\uff0c\u586b\u8865\u4e86\u8fd9\u4e00\u9886\u57df\u957f\u671f\u5b58\u5728\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u548c\u7b97\u6cd5\u5206\u6790\uff0c\u7814\u7a76\u4e24\u65f6\u949f\u4e14\u51e0\u4e4e\u975eZeno\u7684wtgs\u7684\u6027\u8d28\uff0c\u5e76\u8bc1\u660e\u5176\u4ef7\u503c\u95ee\u9898\u7684\u53ef\u5224\u5b9a\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u4e24\u65f6\u949f\u4e14\u51e0\u4e4e\u975eZeno\u7684wtgs\u4e2d\uff0c\u4ef7\u503c\u95ee\u9898\u662f\u53ef\u5224\u5b9a\u7684\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u52a0\u6743\u5b9a\u65f6\u6e38\u620f\u9886\u57df\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u5bf9\u8fd9\u7c7b\u6e38\u620f\u53ef\u5224\u5b9a\u6027\u7684\u7406\u89e3\u3002"}}
{"id": "2508.00629", "pdf": "https://arxiv.org/pdf/2508.00629", "abs": "https://arxiv.org/abs/2508.00629", "authors": ["Francisco Crespo", "Javier Villegas", "Carlos Baena", "Eduardo Baena", "Sergio Fortes", "Raquel Barco"], "title": "Energy-Aware CPU Orchestration in O-RAN: A dApp-Driven Lightweight Approach", "categories": ["cs.NI", "cs.OS", "cs.PF"], "comment": null, "summary": "The transition toward softwarized Radio Access Networks (RANs), driven by the\nOpen RAN (O-RAN) paradigm, enables flexible, vendor-neutral deployments through\ndisaggregation and virtualization of base station functions. However, this\nshift introduces new challenges in managing CPU resources efficiently under\nstrict real-time constraints. In particular, the interplay between\nlatency-sensitive RAN workloads and general-purpose Operating System (OS)\nschedulers often leads to sub-optimal performance and unnecessary energy\nconsumption. This work proposes a lightweight, programmable distributed\napplication (dApp) deployed at the Distributed Unit (DU) level to dynamically\norchestrate CPU usage. The dApp operates in closed loop with the OS, leveraging\nthread-level telemetry like context switches, Instructions Per Cycle (IPC), and\ncache metrics, to adapt CPU thread affinity, core isolation, and frequency\nscaling in real time. Unlike existing solutions, it requires no access to\nproprietary RAN software, hardware-specific features, or kernel modifications.\nFully compliant with the O-RAN architecture and agnostic to the underlying RAN\nstack, the proposed solution introduces negligible overhead while improving\nenergy efficiency and CPU utilization. Experimental results using a\ncommercial-grade srsRAN deployment demonstrate consistent power savings without\ncompromising real-time processing performance, highlighting the potential of\nlow-latency dApps for fine-grained resource control in next-generation networks", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u7f16\u7a0b\u7684\u5206\u5e03\u5f0f\u5e94\u7528\uff08dApp\uff09\uff0c\u7528\u4e8e\u5728\u8f6f\u5316\u7684\u65e0\u7ebf\u7535\u63a5\u5165\u7f51\u7edc\uff08RAN\uff09\u4e2d\u52a8\u6001\u7ba1\u7406CPU\u8d44\u6e90\uff0c\u63d0\u9ad8\u80fd\u6548\u548c\u5229\u7528\u7387\u3002", "motivation": "\u968f\u7740Open RAN\uff08O-RAN\uff09\u7684\u53d1\u5c55\uff0cRAN\u7684\u8f6f\u4ef6\u5316\u5e26\u6765\u7684\u7075\u6d3b\u6027\u548c\u591a\u4f9b\u5e94\u5546\u90e8\u7f72\u9762\u4e34\u7740\u5728\u4e25\u683c\u5b9e\u65f6\u7ea6\u675f\u4e0b\u9ad8\u6548\u7ba1\u7406CPU\u8d44\u6e90\u7684\u65b0\u6311\u6218\u3002\u4f20\u7edf\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u4e0e\u5ef6\u8fdf\u654f\u611f\u7684RAN\u5de5\u4f5c\u8d1f\u8f7d\u4ea4\u4e92\u65f6\uff0c\u5f80\u5f80\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u80fd\u8017\u589e\u52a0\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u90e8\u7f72\u5728\u5206\u5e03\u5f0f\u5355\u5143\uff08DU\uff09\u5c42\u7ea7\u7684dApp\uff0c\u901a\u8fc7\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u95ed\u73af\u534f\u4f5c\uff0c\u5229\u7528\u7ebf\u7a0b\u7ea7\u9065\u6d4b\u6570\u636e\uff08\u5982\u4e0a\u4e0b\u6587\u5207\u6362\u3001\u6bcf\u5468\u671f\u6307\u4ee4\u6570IPC\u548c\u7f13\u5b58\u6307\u6807\uff09\uff0c\u5b9e\u65f6\u8c03\u6574CPU\u7ebf\u7a0b\u4eb2\u548c\u6027\u3001\u6838\u5fc3\u9694\u79bb\u548c\u9891\u7387\u7f29\u653e\u3002\u8be5\u89e3\u51b3\u65b9\u6848\u65e0\u9700\u8bbf\u95ee\u4e13\u6709RAN\u8f6f\u4ef6\u3001\u786c\u4ef6\u7279\u5b9a\u529f\u80fd\u6216\u5185\u6838\u4fee\u6539\u3002", "result": "\u5728\u5546\u7528\u7ea7srsRAN\u90e8\u7f72\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u5728\u4fdd\u8bc1\u5b9e\u65f6\u5904\u7406\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u8282\u7701\u80fd\u8017\uff0c\u540c\u65f6\u63d0\u5347CPU\u5229\u7528\u7387\uff0c\u4e14\u7cfb\u7edf\u5f00\u9500\u6781\u4f4e\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u4f4e\u5ef6\u8fdfdApp\u5728\u4e0b\u4e00\u4ee3\u7f51\u7edc\u4e2d\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u8d44\u6e90\u63a7\u5236\u7684\u6f5c\u529b\uff0c\u4e3aO-RAN\u67b6\u6784\u4e2d\u7684\u80fd\u6548\u548c\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9014\u5f84\u3002"}}
{"id": "2508.00260", "pdf": "https://arxiv.org/pdf/2508.00260", "abs": "https://arxiv.org/abs/2508.00260", "authors": ["Hyundong Jin", "Hyung Jin Chang", "Eunwoo Kim"], "title": "Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted to ICCV 2025", "summary": "Continual learning enables pre-trained generative vision-language models\n(VLMs) to incorporate knowledge from new tasks without retraining data from\nprevious ones. Recent methods update a visual projector to translate visual\ninformation for new tasks, connecting pre-trained vision encoders with large\nlanguage models. However, such adjustments may cause the models to prioritize\nvisual inputs over language instructions, particularly learning tasks with\nrepetitive types of textual instructions. To address the neglect of language\ninstructions, we propose a novel framework that grounds the translation of\nvisual information on instructions for language models. We introduce a mixture\nof visual projectors, each serving as a specialized visual-to-language\ntranslation expert based on the given instruction context to adapt to new\ntasks. To avoid using experts for irrelevant instruction contexts, we propose\nan expert recommendation strategy that reuses experts for tasks similar to\nthose previously learned. Additionally, we introduce expert pruning to\nalleviate interference from the use of experts that cumulatively activated in\nprevious tasks. Extensive experiments on diverse vision-language tasks\ndemonstrate that our method outperforms existing continual learning approaches\nby generating instruction-following responses.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u8bed\u8a00\u6307\u4ee4\u7684\u89c6\u89c9\u6295\u5f71\u5668\u6df7\u5408\u548c\u4e13\u5bb6\u63a8\u8350\u7b56\u7565\uff0c\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5ffd\u89c6\u8bed\u8a00\u6307\u4ee4\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5728\u66f4\u65b0\u89c6\u89c9\u6295\u5f71\u5668\u65f6\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5ffd\u89c6\u8bed\u8a00\u6307\u4ee4\uff0c\u5c24\u5176\u662f\u5bf9\u91cd\u590d\u7c7b\u578b\u7684\u6587\u672c\u6307\u4ee4\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u89c6\u89c9\u6295\u5f71\u5668\uff0c\u6bcf\u4e2a\u6295\u5f71\u5668\u4f5c\u4e3a\u57fa\u4e8e\u6307\u4ee4\u4e0a\u4e0b\u6587\u7684\u4e13\u4e1a\u89c6\u89c9-\u8bed\u8a00\u7ffb\u8bd1\u4e13\u5bb6\uff1b\u5f15\u5165\u4e13\u5bb6\u63a8\u8350\u7b56\u7565\u548c\u4e13\u5bb6\u526a\u679d\u6280\u672f\u4ee5\u907f\u514d\u5e72\u6270\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u751f\u6210\u66f4\u7b26\u5408\u6307\u4ee4\u7684\u54cd\u5e94\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e2d\u8bed\u8a00\u6307\u4ee4\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2508.00016", "pdf": "https://arxiv.org/pdf/2508.00016", "abs": "https://arxiv.org/abs/2508.00016", "authors": ["Matt Kaufmann", "Yahya Sohail", "Warren A. Hunt Jr"], "title": "Extended Abstract: Mutable Objects with Several Implementations", "categories": ["cs.PL", "cs.LO"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "This extended abstract outlines an ACL2 feature, attach-stobj, that first\nappeared in ACL2 Version 8.6 (October, 2024). This feature supports different\nexecutable operations for a given abstract stobj, without requiring\nrecertification of the book that introduces that stobj or theorems about it.\nThe paper provides background as well as a user-level overview and some\nimplementation notes.", "AI": {"tldr": "\u6458\u8981\u4ecb\u7ecd\u4e86ACL2\u7684\u65b0\u529f\u80fdattach-stobj\uff0c\u5141\u8bb8\u5728\u4e0d\u91cd\u65b0\u8ba4\u8bc1\u7684\u60c5\u51b5\u4e0b\u4e3a\u62bd\u8c61stobj\u63d0\u4f9b\u4e0d\u540c\u7684\u53ef\u6267\u884c\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u62bd\u8c61stobj\u7684\u7075\u6d3b\u6027\u95ee\u9898\uff0c\u907f\u514d\u9891\u7e41\u7684\u91cd\u65b0\u8ba4\u8bc1\u3002", "method": "\u901a\u8fc7attach-stobj\u529f\u80fd\u5b9e\u73b0\u4e0d\u540c\u7684\u53ef\u6267\u884c\u64cd\u4f5c\uff0c\u5e76\u63d0\u4f9b\u80cc\u666f\u3001\u7528\u6237\u6982\u8ff0\u548c\u5b9e\u73b0\u8bf4\u660e\u3002", "result": "\u589e\u5f3a\u4e86ACL2\u7684\u529f\u80fd\u7075\u6d3b\u6027\uff0c\u51cf\u5c11\u4e86\u8ba4\u8bc1\u8d1f\u62c5\u3002", "conclusion": "attach-stobj\u4e3aACL2\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5f00\u53d1\u4f53\u9a8c\u3002"}}
{"id": "2508.00010", "pdf": "https://arxiv.org/pdf/2508.00010", "abs": "https://arxiv.org/abs/2508.00010", "authors": ["Ruibo Wang", "Baha Eddine Youcef Belmekki", "Howard H. Yang", "Mohamed Slim Alouini"], "title": "Non-Terrestrial Network Models Using Stochastic Geometry: Planar or Spherical?", "categories": ["cs.NI"], "comment": null, "summary": "With the explosive deployment of non-terrestrial networks (NTNs), the\ncomputational complexity of network performance analysis is rapidly escalating.\nAs one of the most suitable mathematical tools for analyzing large-scale\nnetwork topologies, stochastic geometry (SG) enables the representation of\nnetwork performance metrics as functions of network parameters, thus offering\nlow-complexity performance analysis solutions. However, choosing between planar\nand spherical models remains challenging. Planar models neglect Earth's\ncurvature, causing deviations in high-altitude NTN analysis, yet are still\noften used for simplicity. This paper introduces relative error to quantify the\ngap between planar and spherical models, helping determine when planar modeling\nis sufficient. To calculate the relative error, we first propose a point\nprocess (PP) generation algorithm that simultaneously generates a pair of\nhomogeneous and asymptotically similar planar and spherical PPs. We then\nintroduce several typical similarity metrics, including topology-related and\nnetwork-level metrics, and further develop a relative error estimation\nalgorithm based on these metrics. In addition, we derive an analytical\nexpression for the optimal planar altitude, which reduces computational\ncomplexity and provides theoretical support for planar approximation. Finally,\nnumerical results investigate how deployment altitude and region affect NTN\nmodeling, with case studies on HAP and LEO satellite constellations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5728\u975e\u5730\u9762\u7f51\u7edc\uff08NTN\uff09\u6027\u80fd\u5206\u6790\u4e2d\uff0c\u5e73\u9762\u4e0e\u7403\u5f62\u6a21\u578b\u7684\u76f8\u5bf9\u8bef\u5dee\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u76f8\u4f3c\u5e73\u9762\u548c\u7403\u5f62\u70b9\u8fc7\u7a0b\u7684\u7b97\u6cd5\u4ee5\u53ca\u76f8\u5bf9\u8bef\u5dee\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u786e\u5b9a\u5e73\u9762\u6a21\u578b\u7684\u9002\u7528\u6027\u3002", "motivation": "\u968f\u7740\u975e\u5730\u9762\u7f51\u7edc\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7f51\u7edc\u6027\u80fd\u5206\u6790\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u6025\u5267\u589e\u52a0\u3002\u5e73\u9762\u6a21\u578b\u56e0\u7b80\u5316\u8ba1\u7b97\u800c\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u5ffd\u7565\u5730\u7403\u66f2\u7387\u4f1a\u5bfc\u81f4\u9ad8\u6d77\u62d4NTN\u5206\u6790\u504f\u5dee\uff0c\u56e0\u6b64\u9700\u8981\u91cf\u5316\u5e73\u9762\u4e0e\u7403\u5f62\u6a21\u578b\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u751f\u6210\u5e73\u9762\u548c\u7403\u5f62\u70b9\u8fc7\u7a0b\u7684\u7b97\u6cd5\uff0c\u5e76\u57fa\u4e8e\u62d3\u6251\u548c\u7f51\u7edc\u7ea7\u6307\u6807\u5b9a\u4e49\u4e86\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u8fdb\u800c\u5f00\u53d1\u4e86\u76f8\u5bf9\u8bef\u5dee\u4f30\u8ba1\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u63a8\u5bfc\u4e86\u6700\u4f18\u5e73\u9762\u9ad8\u5ea6\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u90e8\u7f72\u9ad8\u5ea6\u548c\u533a\u57df\u5bf9NTN\u5efa\u6a21\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7HAP\u548cLEO\u536b\u661f\u661f\u5ea7\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u4e3a\u5e73\u9762\u6a21\u578b\u5728\u9ad8\u6d77\u62d4NTN\u5206\u6790\u4e2d\u7684\u9002\u7528\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2508.00107", "pdf": "https://arxiv.org/pdf/2508.00107", "abs": "https://arxiv.org/abs/2508.00107", "authors": ["Jan Simson"], "title": "Decoupling Data and Tooling in Interactive Visualization", "categories": ["cs.HC"], "comment": "Poster at IEEE VIS 2025", "summary": "Interactive data visualization is a major part of modern exploratory data\nanalysis, with web-based technologies enabling a rich ecosystem of both\nspecialized and general tools. However, current visualization tools often lack\nsupport for transformation or wrangling of data and are forced to re-implement\ntheir own solutions to load and ingest data. This redundancy creates\nsubstantial development overhead for tool creators, steeper learning curves for\nusers who must master different data handling interfaces across tools and a\ndegraded user experience as data handling is usually seen as an after-thought.\n  We propose a modular approach that separates data wrangling and loading\ncapabilities from visualization components. This architecture allows\nvisualization tools to concentrate on their core strengths while providing the\nopportunity to develop a unified, powerful interface for data handling. An\nadditional benefit of this approach is that it allows for multiple tools to\nexist and be used side by side. We demonstrate the feasibility of this approach\nby building an early prototype using web technologies to encapsulate\nvisualization tools and manage data flow between them.\n  We discuss future research directions, including downstream integrations with\nother tooling, such as IDEs, literate programming notebooks and applications,\nas well as incorporation of new technologies for efficient data\ntransformations. We seek input from the community to better understand the\nrequirements towards this approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u6574\u7406\u4e0e\u52a0\u8f7d\u529f\u80fd\u4e0e\u53ef\u89c6\u5316\u7ec4\u4ef6\u5206\u79bb\uff0c\u4ee5\u51cf\u5c11\u5f00\u53d1\u5197\u4f59\u5e76\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524d\u53ef\u89c6\u5316\u5de5\u5177\u7f3a\u4e4f\u5bf9\u6570\u636e\u6574\u7406\u7684\u652f\u6301\uff0c\u5bfc\u81f4\u5f00\u53d1\u6210\u672c\u9ad8\u3001\u7528\u6237\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\uff0c\u7528\u6237\u4f53\u9a8c\u8f83\u5dee\u3002", "method": "\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u5206\u79bb\u6570\u636e\u5904\u7406\u4e0e\u53ef\u89c6\u5316\u529f\u80fd\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7f51\u7edc\u6280\u672f\u7684\u539f\u578b\u3002", "result": "\u5c55\u793a\u4e86\u6a21\u5757\u5316\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5141\u8bb8\u591a\u79cd\u5de5\u5177\u5e76\u884c\u4f7f\u7528\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u4e0e\u5176\u4ed6\u5de5\u5177\u96c6\u6210\u548c\u91c7\u7528\u65b0\u6280\u672f\u4f18\u5316\u6570\u636e\u8f6c\u6362\uff0c\u5e0c\u671b\u83b7\u5f97\u793e\u533a\u53cd\u9988\u3002"}}
{"id": "2508.00622", "pdf": "https://arxiv.org/pdf/2508.00622", "abs": "https://arxiv.org/abs/2508.00622", "authors": ["Kapel Dev", "Yash Madhwal", "Sofia Shevelo", "Pavel Osinenko", "Yury Yanovich"], "title": "SwarnRaft: Leveraging Consensus for Robust Drone Swarm Coordination in GNSS-Degraded Environments", "categories": ["cs.DC"], "comment": null, "summary": "Unmanned aerial vehicle (UAV) swarms are increasingly used in critical\napplications such as aerial mapping, environmental monitoring, and autonomous\ndelivery. However, the reliability of these systems is highly dependent on\nuninterrupted access to the Global Navigation Satellite Systems (GNSS) signals,\nwhich can be disrupted in real-world scenarios due to interference,\nenvironmental conditions, or adversarial attacks, causing disorientation,\ncollision risks, and mission failure. This paper proposes SwarnRaft, a\nblockchain-inspired positioning and consensus framework for maintaining\ncoordination and data integrity in UAV swarms operating under GNSS-denied\nconditions. SwarnRaft leverages the Raft consensus algorithm to enable\ndistributed drones (nodes) to agree on state updates such as location and\nheading, even in the absence of GNSS signals for one or more nodes. In our\nprototype, each node uses GNSS and local sensing, and communicates over WiFi in\na simulated swarm. Upon signal loss, consensus is used to reconstruct or verify\nthe position of the failed node based on its last known state and trajectory.\nOur system demonstrates robustness in maintaining swarm coherence and fault\ntolerance through a lightweight, scalable communication model. This work offers\na practical and secure foundation for decentralized drone operation in\nunpredictable environments.", "AI": {"tldr": "SwarnRaft\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5b9a\u4f4d\u4e0e\u5171\u8bc6\u6846\u67b6\uff0c\u7528\u4e8e\u5728GNSS\u4fe1\u53f7\u7f3a\u5931\u65f6\u7ef4\u6301\u65e0\u4eba\u673a\u7fa4\u7684\u534f\u4f5c\u4e0e\u6570\u636e\u5b8c\u6574\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u7fa4\u5728\u5173\u952e\u5e94\u7528\u4e2d\u4f9d\u8d56GNSS\u4fe1\u53f7\uff0c\u4f46\u4fe1\u53f7\u53ef\u80fd\u56e0\u5e72\u6270\u6216\u653b\u51fb\u4e2d\u65ad\uff0c\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\u3002", "method": "\u5229\u7528Raft\u5171\u8bc6\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u8282\u70b9\uff08\u65e0\u4eba\u673a\uff09\u8fbe\u6210\u72b6\u6001\u66f4\u65b0\u5171\u8bc6\uff0c\u5373\u4f7f\u90e8\u5206\u8282\u70b9\u65e0\u6cd5\u63a5\u6536GNSS\u4fe1\u53f7\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u901a\u8fc7\u8f7b\u91cf\u7ea7\u901a\u4fe1\u6a21\u578b\u5c55\u793a\u4e86\u5728\u4fe1\u53f7\u7f3a\u5931\u65f6\u7684\u9c81\u68d2\u6027\u548c\u5bb9\u9519\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4e0d\u53ef\u9884\u6d4b\u73af\u5883\u4e2d\u7684\u5206\u6563\u5f0f\u65e0\u4eba\u673a\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u5b89\u5168\u7684\u57fa\u7840\u3002"}}
{"id": "2508.00244", "pdf": "https://arxiv.org/pdf/2508.00244", "abs": "https://arxiv.org/abs/2508.00244", "authors": ["Briza Mel Dias de Sousa", "Renato Cordeiro Ferreira", "Alfredo Goldman"], "title": "Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems", "categories": ["cs.SE", "cs.PL", "D.3.2; D.2.11; D.2.13"], "comment": "11 pages, 16 figures (1 table, 3 diagrams, 5 graphics, 7 listings),\n  submitted to CTICQS capstone project competition at SBQS 2025", "summary": "After decades of dominance by object-oriented programming (OOP), functional\nprogramming (FP) is gaining increasing attention in the software industry. This\nstudy compares the impact of OOP and FP on the architectural characteristics of\nsoftware systems. For that, it examines the design and implementation of a\nDigital Wallet system, developed in Kotlin (representing OOP) and Scala\n(representing FP). The comparison is made through both qualitative and\nquantitative analyses to explore how each paradigm influences the system's\narchitectural characteristics. The self-ethnographic qualitative analysis\nprovides a side-by-side comparison of both implementations, revealing the\nperspective of those writing such code. The survey-based quantitative analysis\ngathers feedback from developers with diverse backgrounds, showing their\nimpressions of those reading this code. Hopefully, these results may be useful\nfor developers or organizations seeking to make more informed decisions about\nwhich paradigm is best suited for their next project.", "AI": {"tldr": "\u6bd4\u8f83\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff08OOP\uff09\u548c\u51fd\u6570\u5f0f\u7f16\u7a0b\uff08FP\uff09\u5bf9\u8f6f\u4ef6\u7cfb\u7edf\u67b6\u6784\u7279\u6027\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5b9a\u6027\u5b9a\u91cf\u5206\u6790\u4e24\u79cd\u8bed\u8a00\u5b9e\u73b0\u6570\u5b57\u94b1\u5305\u7cfb\u7edf\u7684\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u51fd\u6570\u5f0f\u7f16\u7a0b\u5728\u5de5\u4e1a\u754c\u7684\u5173\u6ce8\u5ea6\u4e0a\u5347\uff0c\u7814\u7a76\u65e8\u5728\u6bd4\u8f83OOP\u548cFP\u5bf9\u7cfb\u7edf\u67b6\u6784\u7684\u5f71\u54cd\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u9009\u62e9\u66f4\u9002\u5408\u7684\u8303\u5f0f\u3002", "method": "\u4f7f\u7528Kotlin\uff08OOP\u4ee3\u8868\uff09\u548cScala\uff08FP\u4ee3\u8868\uff09\u5b9e\u73b0\u6570\u5b57\u94b1\u5305\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9a\u6027\uff08\u81ea\u6211\u6c11\u65cf\u5fd7\uff09\u548c\u5b9a\u91cf\uff08\u5f00\u53d1\u8005\u8c03\u67e5\uff09\u65b9\u6cd5\u5206\u6790\u4e24\u79cd\u8303\u5f0f\u7684\u5dee\u5f02\u3002", "result": "\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u63ed\u793a\u4e86\u4e24\u79cd\u7f16\u7a0b\u8303\u5f0f\u5728\u7cfb\u7edf\u67b6\u6784\u7279\u6027\u4e0a\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u5f00\u53d1\u8005\u7684\u7f16\u5199\u548c\u9605\u8bfb\u4f53\u9a8c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u5728\u9009\u62e9\u7f16\u7a0b\u8303\u5f0f\u65f6\u63d0\u4f9b\u4e86\u53c2\u8003\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u66f4\u660e\u667a\u7684\u51b3\u7b56\u3002"}}
{"id": "2508.00782", "pdf": "https://arxiv.org/pdf/2508.00782", "abs": "https://arxiv.org/abs/2508.00782", "authors": ["Kien T. Pham", "Yingqing He", "Yazhou Xing", "Qifeng Chen", "Long Chen"], "title": "SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS"], "comment": "The 33rd ACM Multimedia Conference (MM '25)", "summary": "Audio-driven video generation aims to synthesize realistic videos that align\nwith input audio recordings, akin to the human ability to visualize scenes from\nauditory input. However, existing approaches predominantly focus on exploring\nsemantic information, such as the classes of sounding sources present in the\naudio, limiting their ability to generate videos with accurate content and\nspatial composition. In contrast, we humans can not only naturally identify the\nsemantic categories of sounding sources but also determine their deeply encoded\nspatial attributes, including locations and movement directions. This useful\ninformation can be elucidated by considering specific spatial indicators\nderived from the inherent physical properties of sound, such as loudness or\nfrequency. As prior methods largely ignore this factor, we present SpA2V, the\nfirst framework explicitly exploits these spatial auditory cues from audios to\ngenerate videos with high semantic and spatial correspondence. SpA2V decomposes\nthe generation process into two stages: 1) Audio-guided Video Planning: We\nmeticulously adapt a state-of-the-art MLLM for a novel task of harnessing\nspatial and semantic cues from input audio to construct Video Scene Layouts\n(VSLs). This serves as an intermediate representation to bridge the gap between\nthe audio and video modalities. 2) Layout-grounded Video Generation: We develop\nan efficient and effective approach to seamlessly integrate VSLs as conditional\nguidance into pre-trained diffusion models, enabling VSL-grounded video\ngeneration in a training-free manner. Extensive experiments demonstrate that\nSpA2V excels in generating realistic videos with semantic and spatial alignment\nto the input audios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpA2V\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u542c\u89c9\u7ebf\u7d22\u4ece\u97f3\u9891\u751f\u6210\u8bed\u4e49\u548c\u7a7a\u95f4\u5bf9\u9f50\u7684\u89c6\u9891\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u97f3\u9891\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u5ffd\u7565\u4e86\u58f0\u97f3\u7684\u7a7a\u95f4\u5c5e\u6027\uff08\u5982\u4f4d\u7f6e\u548c\u65b9\u5411\uff09\uff0c\u800cSpA2V\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "SpA2V\u5206\u4e3a\u4e24\u9636\u6bb5\uff1a1\uff09\u97f3\u9891\u5f15\u5bfc\u7684\u89c6\u9891\u89c4\u5212\uff0c\u5229\u7528MLLM\u63d0\u53d6\u7a7a\u95f4\u548c\u8bed\u4e49\u7ebf\u7d22\u6784\u5efa\u89c6\u9891\u573a\u666f\u5e03\u5c40\uff08VSL\uff09\uff1b2\uff09\u57fa\u4e8e\u5e03\u5c40\u7684\u89c6\u9891\u751f\u6210\uff0c\u5c06VSL\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSpA2V\u80fd\u751f\u6210\u4e0e\u8f93\u5165\u97f3\u9891\u8bed\u4e49\u548c\u7a7a\u95f4\u5bf9\u9f50\u7684\u9ad8\u8d28\u91cf\u89c6\u9891\u3002", "conclusion": "SpA2V\u901a\u8fc7\u5229\u7528\u7a7a\u95f4\u542c\u89c9\u7ebf\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u9891\u751f\u6210\u7684\u7a7a\u95f4\u548c\u8bed\u4e49\u51c6\u786e\u6027\u3002"}}
{"id": "2508.00015", "pdf": "https://arxiv.org/pdf/2508.00015", "abs": "https://arxiv.org/abs/2508.00015", "authors": ["Matt Kaufmann", "J Strother Moore"], "title": "Extended Abstract: Partial-encapsulate and Its Support for Floating-point Operations in ACL2", "categories": ["cs.LO", "cs.MS"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We illustrate the power of partial-encapsulate, showing how it is used in the\nimplementation of floating-point operations in ACL2.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86 partial-encapsulate \u7684\u5f3a\u5927\u529f\u80fd\uff0c\u5e76\u901a\u8fc7 ACL2 \u4e2d\u6d6e\u70b9\u8fd0\u7b97\u7684\u5b9e\u73b0\u6765\u8bf4\u660e\u5176\u5e94\u7528\u3002", "motivation": "\u901a\u8fc7 partial-encapsulate \u6765\u5c55\u793a\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728 ACL2 \u4e2d\u5b9e\u73b0\u6d6e\u70b9\u8fd0\u7b97\u65f6\u7684\u9ad8\u6548\u6027\u3002", "method": "\u4f7f\u7528 partial-encapsulate \u529f\u80fd\uff0c\u7ed3\u5408 ACL2 \u5b9e\u73b0\u6d6e\u70b9\u8fd0\u7b97\u7684\u5177\u4f53\u64cd\u4f5c\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86 partial-encapsulate \u5728 ACL2 \u4e2d\u5b9e\u73b0\u6d6e\u70b9\u8fd0\u7b97\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "partial-encapsulate \u662f\u4e00\u79cd\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5728 ACL2 \u7b49\u7cfb\u7edf\u4e2d\u9ad8\u6548\u5b9e\u73b0\u590d\u6742\u7684\u6d6e\u70b9\u8fd0\u7b97\u3002"}}
{"id": "2508.00816", "pdf": "https://arxiv.org/pdf/2508.00816", "abs": "https://arxiv.org/abs/2508.00816", "authors": ["Youssef Ait El Mahjoub", "Jean-Michel Fourneau", "Salma Alouah"], "title": "Efficient Solving of Large Single Input Superstate Decomposable Markovian Decision Process", "categories": ["math.OC", "cs.LG", "cs.PF"], "comment": "Preprint article submitted to ValueTools2025", "summary": "Solving Markov Decision Processes (MDPs) remains a central challenge in\nsequential decision-making, especially when dealing with large state spaces and\nlong-term optimization criteria. A key step in Bellman dynamic programming\nalgorithms is the policy evaluation, which becomes computationally demanding in\ninfinite-horizon settings such as average-reward or discounted-reward\nformulations. In the context of Markov chains, aggregation and disaggregation\ntechniques have for a long time been used to reduce complexity by exploiting\nstructural decompositions. In this work, we extend these principles to a\nstructured class of MDPs. We define the Single-Input Superstate Decomposable\nMarkov Decision Process (SISDMDP), which combines Chiu's single-input\ndecomposition with Robertazzi's single-cycle recurrence property. When a policy\ninduces this structure, the resulting transition graph can be decomposed into\ninteracting components with centralized recurrence. We develop an exact and\nefficient policy evaluation method based on this structure. This yields a\nscalable solution applicable to both average and discounted reward MDPs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u8f93\u5165\u8d85\u72b6\u6001\u53ef\u5206\u89e3MDP\uff08SISDMDP\uff09\u7684\u9ad8\u6548\u7b56\u7565\u8bc4\u4f30\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4\u548c\u957f\u671f\u4f18\u5316\u7684MDP\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4\u548c\u957f\u671f\u4f18\u5316MDP\u95ee\u9898\u65f6\uff0c\u4f20\u7edf\u7b56\u7565\u8bc4\u4f30\u65b9\u6cd5\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u5c24\u5176\u5728\u65e0\u9650\u65f6\u57df\u8bbe\u7f6e\u4e0b\u3002", "method": "\u7ed3\u5408Chiu\u7684\u5355\u8f93\u5165\u5206\u89e3\u548cRobertazzi\u7684\u5355\u5468\u671f\u9012\u5f52\u5c5e\u6027\uff0c\u5b9a\u4e49\u4e86SISDMDP\uff0c\u5e76\u5229\u7528\u5176\u7ed3\u6784\u5f00\u53d1\u4e86\u7cbe\u786e\u4e14\u9ad8\u6548\u7684\u7b56\u7565\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u5e73\u5747\u548c\u6298\u6263\u5956\u52b1MDP\u7684\u89c4\u6a21\u5316\u6c42\u89e3\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5206\u89e3\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684MDP\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u590d\u6742\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u8ba1\u7b97\u5de5\u5177\u3002"}}
{"id": "2508.00632", "pdf": "https://arxiv.org/pdf/2508.00632", "abs": "https://arxiv.org/abs/2508.00632", "authors": ["Alexia Jolicoeur-Martineau"], "title": "Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings", "categories": ["cs.AI", "cs.MA", "cs.MM"], "comment": null, "summary": "While AI excels at generating text, audio, images, and videos, creating\ninteractive audio-visual content such as video games remains challenging.\nCurrent LLMs can generate JavaScript games and animations, but lack automated\nevaluation metrics and struggle with complex content that normally requires\nteams of humans working for many months (multi-shot, multi-agents) using assets\nmade by artists. To tackle these issues, we built a new metric and a\nmulti-agent system.\n  We propose AVR-Eval, a relative metric for multimedia content quality using\nAudio-Visual Recordings (AVRs). An omni-modal model (processing text, video,\nand audio) compares the AVRs of two contents, with a text model reviewing\nevaluations to determine superiority. We show that AVR-Eval properly identifies\ngood from broken or mismatched content.\n  We built AVR-Agent, a multi-agent system generating JavaScript code from a\nbank of multimedia assets (audio, images, 3D models). The coding agent selects\nrelevant assets, generates multiple initial codes, uses AVR-Eval to identify\nthe best version, and iteratively improves it through omni-modal agent feedback\nfrom the AVR.\n  We run experiments on games and animations with AVR-Eval (win rate of content\nA against B). We find that content generated by AVR-Agent has a significantly\nhigher win rate against content made through one-shot generation. However,\nmodels struggle to leverage custom assets and AVR feedback effectively, showing\nno higher win rate. This reveals a critical gap: while humans benefit from\nhigh-quality assets and audio-visual feedback, current coding models do not\nseem to utilize these resources as effectively, highlighting fundamental\ndifferences between human and machine content creation approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAVR-Eval\u8bc4\u4ef7\u6807\u51c6\u548cAVR-Agent\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u751f\u6210\u4ea4\u4e92\u5f0f\u591a\u5a92\u4f53\u5185\u5bb9\uff0c\u4f46\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5229\u7528\u9ad8\u8d28\u91cf\u8d44\u4ea7\u548c\u53cd\u9988\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u590d\u6742\u4ea4\u4e92\u5f0f\u5185\u5bb9\uff08\u5982\u89c6\u9891\u6e38\u620f\uff09\u65f6\u81ea\u52a8\u5316\u8bc4\u4f30\u548c\u8d28\u91cf\u63d0\u5347\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faAVR-Eval\u4f5c\u4e3a\u591a\u5a92\u4f53\u5185\u5bb9\u8d28\u91cf\u76f8\u5bf9\u8bc4\u4ef7\u6807\u51c6\uff0c\u5e76\u5f00\u53d1AVR-Agent\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u751f\u6210JavaScript\u4ee3\u7801\u3002", "result": "AVR-Agent\u751f\u6210\u7684\u5185\u5bb9\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u4e00\u6b21\u6027\u751f\u6210\u7684\u5185\u5bb9\uff0c\u4f46\u6a21\u578b\u672a\u80fd\u6709\u6548\u5229\u7528\u81ea\u5b9a\u4e49\u8d44\u4ea7\u548c\u53cd\u9988\u3002", "conclusion": "\u63ed\u793a\u4e86\u4eba\u7c7b\u4e0e\u673a\u5668\u5728\u5185\u5bb9\u521b\u4f5c\u65b9\u6cd5\u4e0a\u7684\u6839\u672c\u5dee\u5f02\uff0c\u5f53\u524d\u6a21\u578b\u5728\u5229\u7528\u9ad8\u8d28\u91cf\u8d44\u4ea7\u548c\u53cd\u9988\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2508.00422", "pdf": "https://arxiv.org/pdf/2508.00422", "abs": "https://arxiv.org/abs/2508.00422", "authors": ["Varun Bharti", "Shashwat Jha", "Dhruv Kumar", "Pankaj Jalote"], "title": "Automated Type Annotation in Python Using Large Language Models", "categories": ["cs.PL", "cs.LG"], "comment": "Under Review", "summary": "Type annotations in Python enhance maintainability and error detection.\nHowever, generating these annotations manually is error prone and requires\nextra effort. Traditional automation approaches like static analysis, machine\nlearning, and deep learning struggle with limited type vocabularies, behavioral\nover approximation, and reliance on large labeled datasets. In this work, we\nexplore the use of LLMs for generating type annotations in Python. We develop a\ngenerate check repair pipeline: the LLM proposes annotations guided by a\nConcrete Syntax Tree representation, a static type checker (Mypy) verifies\nthem, and any errors are fed back for iterative refinement. We evaluate four\nLLM variants: GPT 4oMini, GPT 4.1mini (general-purpose), and O3Mini, O4Mini\n(reasoning optimized), on 6000 code snippets from the ManyTypes4Py benchmark.\nWe first measure the proportion of code snippets annotated by LLMs for which\nMyPy reported no errors (i.e., consistent results): GPT 4oMini achieved\nconsistency on 65.9% of cases (34.1% inconsistent), while GPT 4.1mini, O3Mini,\nand O4Mini each reached approximately 88.6% consistency (around 11.4%\nfailures). To measure annotation quality, we then compute exact-match and\nbase-type match accuracies over all 6000 snippets: GPT 4.1mini and O3Mini\nperform the best, achieving up to 70.5% exact match and 79.1% base type\naccuracy, requiring under one repair iteration on average. Our results\ndemonstrate that general-purpose and reasoning optimized LLMs, without any task\nspecific fine tuning or additional training can be effective in generating\nconsistent type annotations.They perform competitively with traditional deep\nlearning techniques which require large labeled dataset for training. While our\nwork focuses on Python, the pipeline can be extended to other optionally typed\nimperative languages like Ruby", "AI": {"tldr": "LLMs\u7528\u4e8e\u81ea\u52a8\u751f\u6210Python\u7c7b\u578b\u6ce8\u91ca\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u4e0e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u7ade\u4e89\u3002", "motivation": "\u624b\u52a8\u751f\u6210Python\u7c7b\u578b\u6ce8\u91ca\u8d39\u65f6\u4e14\u6613\u9519\uff0c\u4f20\u7edf\u81ea\u52a8\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u3002", "method": "\u4f7f\u7528LLM\u751f\u6210\u6ce8\u91ca\uff0c\u7ed3\u5408\u8bed\u6cd5\u6811\u548c\u7c7b\u578b\u68c0\u67e5\u5668\u8fdb\u884c\u8fed\u4ee3\u4fee\u590d\u3002", "result": "GPT4.1mini\u548cO3Mini\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u5206\u522b\u8fbe70.5%\u548c79.1%\u3002", "conclusion": "LLMs\u5728\u751f\u6210\u7c7b\u578b\u6ce8\u91ca\u4e2d\u6709\u6548\u4e14\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u8bed\u8a00\u3002"}}
{"id": "2508.00011", "pdf": "https://arxiv.org/pdf/2508.00011", "abs": "https://arxiv.org/abs/2508.00011", "authors": ["Ahmet Melih Ince", "Ayse Elif Canbilen", "Halim Yanikomeroglu"], "title": "AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks", "categories": ["cs.NI", "cs.AI", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures, to appear in IEEE conference proceedings", "summary": "Sixth-generation (6G) networks are designed to meet the hyper-reliable and\nlow-latency communication (HRLLC) requirements of safety-critical applications\nsuch as autonomous driving. Integrating non-terrestrial networks (NTN) into the\n6G infrastructure brings redundancy to the network, ensuring continuity of\ncommunications even under extreme conditions. In particular, high-altitude\nplatform stations (HAPS) stand out for their wide coverage and low latency\nadvantages, supporting communication reliability and enhancing information\nfreshness, especially in rural areas and regions with infrastructure\nconstraints. In this paper, we present reinforcement learning-based approaches\nusing deep deterministic policy gradient (DDPG) to dynamically optimize the\nage-of-information (AoI) in HAPS-enabled vehicle-to-everything (V2X) networks.\nThe proposed method improves information freshness and overall network\nreliability by enabling independent learning without centralized coordination.\nThe findings reveal the potential of HAPS-supported solutions, combined with\nDDPG-based learning, for efficient AoI-aware resource allocation in\nplatoon-based autonomous vehicle systems.", "AI": {"tldr": "\u8bba\u6587\u6458\u8981\u6982\u8ff0\u4e866G\u7f51\u7edc\u5982\u4f55\u7ed3\u5408\u975e\u5730\u9762\u7f51\u7edc\uff08NTN\uff09\u548c\u9ad8\u7a7a\u5e73\u53f0\u7ad9\uff08HAPS\uff09\uff0c\u901a\u8fc7\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316V2X\u7f51\u7edc\u4e2d\u7684\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff08AoI\uff09\uff0c\u63d0\u5347\u7f51\u7edc\u53ef\u9760\u6027\u548c\u4fe1\u606f\u65f6\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db36G\u7f51\u7edc\u5bf9\u8d85\u9ad8\u53ef\u9760\u6027\u548c\u4f4e\u5ef6\u8fdf\u901a\u4fe1\uff08HRLLC\uff09\u7684\u9700\u6c42\uff0c\u5c24\u5176\u662f\u5728\u81ea\u52a8\u9a7e\u9a76\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u63a2\u7d22\u65b0\u6280\u672f\u4ee5\u589e\u5f3a\u7f51\u7edc\u7684\u5197\u4f59\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u52a8\u6001\u4f18\u5316HAPS\u652f\u6301\u7684V2X\u7f51\u7edc\u4e2d\u7684\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff08AoI\uff09\uff0c\u5b9e\u73b0\u53bb\u4e2d\u5fc3\u5316\u7684\u8d44\u6e90\u5206\u914d\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u7ed3\u5408HAPS\u548c\u57fa\u4e8eDDPG\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u4fe1\u606f\u65b0\u9c9c\u5ea6\u548c\u7f51\u7edc\u603b\u4f53\u53ef\u9760\u6027\uff0c\u5c24\u5176\u662f\u5728\u8f66\u961f\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u3002", "conclusion": "HAPS\u652f\u6301\u7684\u89e3\u51b3\u65b9\u6848\u4e0eDDPG\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u4e3a6G\u7f51\u7edc\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53bb\u4e2d\u5fc3\u5316\u7684\u65b9\u6cd5\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u901a\u4fe1\u9700\u6c42\u63d0\u4f9b\u4e86\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00140", "pdf": "https://arxiv.org/pdf/2508.00140", "abs": "https://arxiv.org/abs/2508.00140", "authors": ["Zhanna Kaufman", "Madeline Endres", "Cindy Xiong Bearfield", "Yuriy Brun"], "title": "Your Model Is Unfair, Are You Even Aware? Inverse Relationship Between Comprehension and Trust in Explainability Visualizations of Biased ML Models", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Systems relying on ML have become ubiquitous, but so has biased behavior\nwithin them. Research shows that bias significantly affects stakeholders' trust\nin systems and how they use them. Further, stakeholders of different\nbackgrounds view and trust the same systems differently. Thus, how ML models'\nbehavior is explained plays a key role in comprehension and trust. We survey\nexplainability visualizations, creating a taxonomy of design characteristics.\nWe conduct user studies to evaluate five state-of-the-art visualization tools\n(LIME, SHAP, CP, Anchors, and ELI5) for model explainability, measuring how\ntaxonomy characteristics affect comprehension, bias perception, and trust for\nnon-expert ML users. Surprisingly, we find an inverse relationship between\ncomprehension and trust: the better users understand the models, the less they\ntrust them. We investigate the cause and find that this relationship is\nstrongly mediated by bias perception: more comprehensible visualizations\nincrease people's perception of bias, and increased bias perception reduces\ntrust. We confirm this relationship is causal: Manipulating explainability\nvisualizations to control comprehension, bias perception, and trust, we show\nthat visualization design can significantly (p < 0.001) increase comprehension,\nincrease perceived bias, and reduce trust. Conversely, reducing perceived model\nbias, either by improving model fairness or by adjusting visualization design,\nsignificantly increases trust even when comprehension remains high. Our work\nadvances understanding of how comprehension affects trust and systematically\ninvestigates visualization's role in facilitating responsible ML applications.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86ML\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u53ef\u89c6\u5316\u5bf9\u7528\u6237\u7406\u89e3\u548c\u4fe1\u4efb\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7406\u89e3\u4e0e\u4fe1\u4efb\u5448\u8d1f\u76f8\u5173\uff0c\u56e0\u4e3a\u66f4\u6613\u7406\u89e3\u7684\u89c6\u89c9\u5316\u4f1a\u589e\u52a0\u5bf9\u504f\u89c1\u7684\u611f\u77e5\uff0c\u4ece\u800c\u964d\u4f4e\u4fe1\u4efb\u3002", "motivation": "ML\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u884c\u4e3a\u666e\u904d\u5b58\u5728\uff0c\u5f71\u54cd\u5229\u76ca\u76f8\u5173\u8005\u7684\u4fe1\u4efb\u548c\u4f7f\u7528\u65b9\u5f0f\uff0c\u4e0d\u540c\u80cc\u666f\u7684\u7528\u6237\u5bf9\u540c\u4e00\u7cfb\u7edf\u7684\u770b\u6cd5\u548c\u4fe1\u4efb\u5ea6\u4e0d\u540c\u3002\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u53ef\u89e3\u91ca\u6027\u53ef\u89c6\u5316\u5982\u4f55\u5f71\u54cd\u7406\u89e3\u548c\u4fe1\u4efb\u3002", "method": "\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u4e94\u79cd\u6700\u5148\u8fdb\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff08LIME\u3001SHAP\u3001CP\u3001Anchors\u548cELI5\uff09\uff0c\u6d4b\u91cf\u8bbe\u8ba1\u7279\u5f81\u5bf9\u975e\u4e13\u5bb6\u7528\u6237\u7684\u7406\u89e3\u3001\u504f\u89c1\u611f\u77e5\u548c\u4fe1\u4efb\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7406\u89e3\u4e0e\u4fe1\u4efb\u5448\u8d1f\u76f8\u5173\uff0c\u66f4\u6613\u7406\u89e3\u7684\u89c6\u89c9\u5316\u4f1a\u589e\u52a0\u504f\u89c1\u611f\u77e5\uff0c\u4ece\u800c\u964d\u4f4e\u4fe1\u4efb\u3002\u901a\u8fc7\u8bbe\u8ba1\u5e72\u9884\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u7406\u89e3\u3001\u589e\u52a0\u504f\u89c1\u611f\u77e5\u5e76\u964d\u4f4e\u4fe1\u4efb\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u7406\u89e3\u4e0e\u4fe1\u4efb\u7684\u5173\u7cfb\uff0c\u5f3a\u8c03\u53ef\u89c6\u5316\u8bbe\u8ba1\u5728\u4fc3\u8fdb\u8d1f\u8d23\u4efbML\u5e94\u7528\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2508.00041", "pdf": "https://arxiv.org/pdf/2508.00041", "abs": "https://arxiv.org/abs/2508.00041", "authors": ["Yebo Wu", "Jingguang Li", "Zhijiang Guo", "Li Li"], "title": "Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Federated fine-tuning enables Large Language Models (LLMs) to adapt to\ndownstream tasks while preserving data privacy, but its resource-intensive\nnature limits deployment on edge devices. In this paper, we introduce\nDevelopmental Federated Tuning (DevFT), a resource-efficient approach inspired\nby cognitive development that progressively builds a powerful LLM from a\ncompact foundation. DevFT decomposes the fine-tuning process into developmental\nstages, each optimizing submodels with increasing parameter capacity. Knowledge\nfrom earlier stages transfers to subsequent submodels, providing optimized\ninitialization parameters that prevent convergence to local minima and\naccelerate training. This paradigm mirrors human learning, gradually\nconstructing comprehensive knowledge structure while refining existing skills.\nTo efficiently build stage-specific submodels, DevFT introduces\ndeconfliction-guided layer grouping and differential-based layer fusion to\ndistill essential information and construct representative layers. Evaluations\nacross multiple benchmarks demonstrate that DevFT significantly outperforms\nstate-of-the-art methods, achieving up to 4.59$\\times$ faster convergence,\n10.67$\\times$ reduction in communication overhead, and 9.07% average\nperformance improvement, while maintaining compatibility with existing\napproaches.", "AI": {"tldr": "DevFT\u662f\u4e00\u79cd\u53d7\u8ba4\u77e5\u53d1\u5c55\u542f\u53d1\u7684\u8d44\u6e90\u9ad8\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u7684\u5fae\u8c03\u8fc7\u7a0b\uff0c\u9010\u6b65\u6784\u5efa\u5f3a\u5927\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u6027\u80fd\u5e76\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8054\u90a6\u5fae\u8c03\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8d44\u6e90\u6d88\u8017\u5927\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u9690\u79c1\uff0c\u63d0\u51fa\u4e86DevFT\u65b9\u6cd5\u3002", "method": "DevFT\u5c06\u5fae\u8c03\u8fc7\u7a0b\u5206\u89e3\u4e3a\u591a\u4e2a\u53d1\u5c55\u9636\u6bb5\uff0c\u6bcf\u4e2a\u9636\u6bb5\u4f18\u5316\u5177\u6709\u9012\u589e\u53c2\u6570\u5bb9\u91cf\u7684\u5b50\u6a21\u578b\u3002\u901a\u8fc7\u77e5\u8bc6\u8fc1\u79fb\u548c\u4f18\u5316\u7684\u521d\u59cb\u5316\u53c2\u6570\uff0c\u52a0\u901f\u8bad\u7ec3\u5e76\u907f\u514d\u5c40\u90e8\u6700\u5c0f\u503c\u3002", "result": "DevFT\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u4f4e\u7684\u901a\u4fe1\u5f00\u9500\u548c\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "conclusion": "DevFT\u4e0d\u4ec5\u8d44\u6e90\u9ad8\u6548\uff0c\u8fd8\u80fd\u4e0e\u73b0\u6709\u65b9\u6cd5\u517c\u5bb9\uff0c\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u8054\u90a6\u5fae\u8c03\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00253", "pdf": "https://arxiv.org/pdf/2508.00253", "abs": "https://arxiv.org/abs/2508.00253", "authors": ["Moumita Asad", "Rafed Muhammad Yasir", "Armin Geramirad", "Sam Malek"], "title": "Leveraging Large Language Model for Information Retrieval-based Bug Localization", "categories": ["cs.SE"], "comment": null, "summary": "Information Retrieval-based Bug Localization aims to identify buggy source\nfiles for a given bug report. While existing approaches -- ranging from vector\nspace models to deep learning models -- have shown potential in this domain,\ntheir effectiveness is often limited by the vocabulary mismatch between bug\nreports and source code. To address this issue, we propose a novel Large\nLanguage Model (LLM) based bug localization approach, called GenLoc. Given a\nbug report, GenLoc leverages an LLM equipped with code-exploration functions to\niteratively analyze the code base and identify potential buggy files. To gather\nbetter context, GenLoc may optionally retrieve semantically relevant files\nusing vector embeddings. GenLoc has been evaluated on over 9,000 real-world bug\nreports from six large-scale Java projects. Experimental results show that\nGenLoc outperforms five state-of-the-art bug localization techniques across\nmultiple metrics, achieving an average improvement of more than 60\\% in\nAccuracy@1.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5GenLoc\uff0c\u901a\u8fc7\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u548c\u5411\u91cf\u5d4c\u5165\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7f3a\u9677\u62a5\u544a\u4e0e\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5\u56e0\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\u6548\u679c\u6709\u9650\uff0cGenLoc\u65e8\u5728\u901a\u8fc7LLM\u548c\u4ee3\u7801\u63a2\u7d22\u6280\u672f\u63d0\u5347\u5b9a\u4f4d\u51c6\u786e\u7387\u3002", "method": "GenLoc\u7ed3\u5408LLM\u7684\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u548c\u5411\u91cf\u5d4c\u5165\u6280\u672f\uff0c\u8fed\u4ee3\u5206\u6790\u4ee3\u7801\u5e93\u4ee5\u5b9a\u4f4d\u6f5c\u5728\u7f3a\u9677\u6587\u4ef6\u3002", "result": "\u57286\u4e2a\u5927\u578bJava\u9879\u76ee\u76849000\u591a\u4e2a\u5b9e\u9645\u7f3a\u9677\u62a5\u544a\u4e2d\uff0cGenLoc\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u4e94\u79cd\u5148\u8fdb\u6280\u672f\uff0cAccuracy@1\u5e73\u5747\u63d0\u5347\u8d85\u8fc760%\u3002", "conclusion": "GenLoc\u901a\u8fc7LLM\u548c\u4e0a\u4e0b\u6587\u589e\u5f3a\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u7f3a\u9677\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.00733", "pdf": "https://arxiv.org/pdf/2508.00733", "abs": "https://arxiv.org/abs/2508.00733", "authors": ["Le Wang", "Jun Wang", "Feng Deng", "Chen Zhang", "Kun Gai", "Di Zhang"], "title": "AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "comment": "12 pages, 2 figures", "summary": "We present AudioGen-Omni - a unified approach based on multimodal diffusion\ntransformers (MMDit), capable of generating high-fidelity audio, speech, and\nsongs coherently synchronized with the input video. AudioGen-Omni introduces a\nnovel joint training paradigm that seamlessly integrates large-scale\nvideo-text-audio corpora, enabling a model capable of generating semantically\nrich, acoustically diverse audio conditioned on multimodal inputs and adaptable\nto a wide range of audio generation tasks. AudioGen-Omni employs a unified\nlyrics-transcription encoder that encodes graphemes and phonemes from both sung\nand spoken inputs into dense frame-level representations. Dense frame-level\nrepresentations are fused using an AdaLN-based joint attention mechanism\nenhanced with phase-aligned anisotropic positional infusion (PAAPI), wherein\nRoPE is selectively applied to temporally structured modalities to ensure\nprecise and robust cross-modal alignment. By unfreezing all modalities and\nmasking missing inputs, AudioGen-Omni mitigates the semantic constraints of\ntext-frozen paradigms, enabling effective cross-modal conditioning. This joint\ntraining approach enhances audio quality, semantic alignment, and lip-sync\naccuracy, while also achieving state-of-the-art results on\nText-to-Audio/Speech/Song tasks. With an inference time of 1.91 seconds for 8\nseconds of audio, it offers substantial improvements in both efficiency and\ngenerality.", "AI": {"tldr": "AudioGen-Omni \u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u6269\u6563\u53d8\u6362\u5668\uff08MMDit\uff09\u7684\u7edf\u4e00\u65b9\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u8f93\u5165\u89c6\u9891\u751f\u6210\u9ad8\u8d28\u91cf\u97f3\u9891\u3001\u8bed\u97f3\u548c\u6b4c\u66f2\uff0c\u5e76\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u5b9e\u73b0\u591a\u4efb\u52a1\u9002\u5e94\u3002", "motivation": "\u4e3a\u514b\u670d\u4f20\u7edf\u6587\u672c\u56fa\u5b9a\u8303\u5f0f\u7684\u8bed\u4e49\u9650\u5236\uff0c\u63d0\u5347\u8de8\u6a21\u6001\u6761\u4ef6\u751f\u6210\u7684\u6548\u679c\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u80fd\u591f\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u7684\u7edf\u4e00\u6a21\u578b\u3002", "method": "\u91c7\u7528\u8054\u5408\u8bad\u7ec3\u8303\u5f0f\uff0c\u6574\u5408\u89c6\u9891-\u6587\u672c-\u97f3\u9891\u6570\u636e\uff0c\u901a\u8fc7\u6b4c\u8bcd-\u8f6c\u5f55\u7f16\u7801\u5668\u548cPAAPI\u589e\u5f3a\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u7cbe\u51c6\u8de8\u6a21\u6001\u5bf9\u9f50\u3002", "result": "\u5728\u97f3\u9891\u8d28\u91cf\u3001\u8bed\u4e49\u5bf9\u9f50\u548c\u5507\u540c\u6b65\u51c6\u786e\u5ea6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5728\u591a\u9879\u97f3\u9891\u751f\u6210\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u63a8\u7406\u65f6\u95f4\u5927\u5e45\u7f29\u77ed\u3002", "conclusion": "AudioGen-Omni \u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u548c\u9ad8\u6548\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u97f3\u9891\u751f\u6210\u7684\u6027\u80fd\u4e0e\u6548\u7387\u3002"}}
{"id": "2508.00482", "pdf": "https://arxiv.org/pdf/2508.00482", "abs": "https://arxiv.org/abs/2508.00482", "authors": ["Erdem Yildirim", "Albert Schimpf", "Stefan Wehr", "Annette Bieniusa"], "title": "Semantic Subtyping for Maps in Erlang", "categories": ["cs.PL"], "comment": null, "summary": "In this paper we will construct a set-theoretic model of types featuring type\nvariables, base types, set-theoretic types and map types. Syntax of map types\nspans all the map types available in Erlang. The model of types is used to\ndefine a semantic subtyping relation based on set containment. The novelty of\nthis work is the definition of subtyping over parameteric map types.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7c7b\u578b\u53d8\u91cf\u3001\u57fa\u672c\u7c7b\u578b\u3001\u96c6\u5408\u7c7b\u578b\u548c\u6620\u5c04\u7c7b\u578b\u7684\u96c6\u5408\u8bba\u6a21\u578b\uff0c\u5b9a\u4e49\u4e86\u57fa\u4e8e\u96c6\u5408\u5305\u542b\u7684\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u91cd\u70b9\u662f\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u5b9a\u4e49\u3002", "motivation": "\u4e3aErlang\u4e2d\u7684\u6620\u5c04\u7c7b\u578b\u63d0\u4f9b\u4e00\u4e2a\u96c6\u5408\u8bba\u6a21\u578b\uff0c\u5e76\u5b9a\u4e49\u5176\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u7279\u522b\u662f\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u7c7b\u578b\uff08\u5982\u7c7b\u578b\u53d8\u91cf\u3001\u57fa\u672c\u7c7b\u578b\u7b49\uff09\u7684\u96c6\u5408\u8bba\u6a21\u578b\uff0c\u5b9a\u4e49\u57fa\u4e8e\u96c6\u5408\u5305\u542b\u7684\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u4e86\u4e00\u4e2a\u9002\u7528\u4e8eErlang\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u5c24\u5176\u662f\u89e3\u51b3\u4e86\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u95ee\u9898\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aErlang\u7684\u7c7b\u578b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u7279\u522b\u662f\u6269\u5c55\u4e86\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u5b9a\u4e49\u80fd\u529b\u3002"}}
{"id": "2508.00020", "pdf": "https://arxiv.org/pdf/2508.00020", "abs": "https://arxiv.org/abs/2508.00020", "authors": ["Ferdaous Tarhouni", "Ruibo Wang", "Mohamed-Slim Alouini"], "title": "Performance Analysis of SAGIN from the Relay Perspective: A Spherical Stochastic Geometry Approach", "categories": ["cs.NI"], "comment": null, "summary": "In recent years, the satellite-aerial-ground integrated network (SAGIN) has\nbecome essential in meeting the increasing demands for global wireless\ncommunications. In SAGIN, high-altitude platforms (HAPs) can serve as\ncommunication hubs and act as relays to enhance communication performance. In\nthis paper, we evaluate network performance and analyze the role of HAPs in\nSAGIN from the relay perspective. Based on this unique perspective, we\nintroduce three metrics to evaluate the performance, named the average access\ndata rate, the average backhaul data rate, and the backhaul rate exceedance\nprobability (BREP). Considering the need for dynamic topology and interference\nanalysis, we choose spherical stochastic geometry (SSG) as a tool and derive\nanalytical expressions for the above metrics to achieve low-complexity\nperformance evaluation. Specifically, we provide a closed-form expression for\nthe end-to-end performance metric BREP. Given that there is no existing\nliterature in the SSG field studying networks from a relay perspective, we\nspecifically investigate the impact of satellite network topology on\nperformance in our numerical results to further highlight the advantages of the\nSSG framework. Additionally, we analyze the minimum HAP transmission power\nrequired to maintain both short-term and long-term data rate demands.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u536b\u661f-\u7a7a\u4e2d-\u5730\u9762\u4e00\u4f53\u5316\u7f51\u7edc\uff08SAGIN\uff09\u4e2d\u9ad8\u7a7a\u5e73\u53f0\uff08HAPs\uff09\u4f5c\u4e3a\u4e2d\u7ee7\u7684\u6027\u80fd\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u6027\u80fd\u6307\u6807\uff0c\u5e76\u4f7f\u7528\u7403\u5f62\u968f\u673a\u51e0\u4f55\uff08SSG\uff09\u5de5\u5177\u8fdb\u884c\u5206\u6790\u3002\u540c\u65f6\u8fd8\u7814\u7a76\u4e86\u536b\u661f\u7f51\u7edc\u62d3\u6251\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u4ee5\u53caHAPs\u7684\u6700\u5c0f\u4f20\u8f93\u529f\u7387\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u5168\u7403\u65e0\u7ebf\u901a\u4fe1\u9700\u6c42\u7684\u589e\u957f\uff0cSAGIN\u7684\u91cd\u8981\u6027\u65e5\u76ca\u51f8\u663e\u3002HAPs\u4f5c\u4e3a\u4e2d\u7ee7\u8282\u70b9\u53ef\u4ee5\u63d0\u5347\u901a\u4fe1\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u8fd9\u4e00\u72ec\u7279\u89c6\u89d2\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u7403\u5f62\u968f\u673a\u51e0\u4f55\uff08SSG\uff09\u5de5\u5177\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u6027\u80fd\u6307\u6807\uff1a\u5e73\u5747\u63a5\u5165\u6570\u636e\u901f\u7387\u3001\u5e73\u5747\u56de\u7a0b\u6570\u636e\u901f\u7387\u548c\u56de\u7a0b\u901f\u7387\u8d85\u51fa\u6982\u7387\uff08BREP\uff09\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86BREP\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7ed3\u679c\u5c55\u793a\u4e86\u536b\u661f\u7f51\u7edc\u62d3\u6251\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u4ee5\u53caHAPs\u7684\u6700\u5c0f\u4f20\u8f93\u529f\u7387\u9700\u6c42\u3002", "conclusion": "\u901a\u8fc7SSG\u6846\u67b6\uff0c\u8bba\u6587\u4e3aSAGIN\u4e2dHAPs\u7684\u4e2d\u7ee7\u6027\u80fd\u63d0\u4f9b\u4e86\u4f4e\u590d\u6742\u5ea6\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86SSG\u5728\u6b64\u7c7b\u7814\u7a76\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2508.00160", "pdf": "https://arxiv.org/pdf/2508.00160", "abs": "https://arxiv.org/abs/2508.00160", "authors": ["Ziqing Xu", "Nick Bryan-Kinns"], "title": "DeformTune: A Deformable XAI Music Prototype for Non-Musicians", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS"], "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts\n  2025) arXiv:2406.14485", "summary": "Many existing AI music generation tools rely on text prompts, complex\ninterfaces, or instrument-like controls, which may require musical or technical\nknowledge that non-musicians do not possess. This paper introduces DeformTune,\na prototype system that combines a tactile deformable interface with the\nMeasureVAE model to explore more intuitive, embodied, and explainable AI\ninteraction. We conducted a preliminary study with 11 adult participants\nwithout formal musical training to investigate their experience with\nAI-assisted music creation. Thematic analysis of their feedback revealed\nrecurring challenge--including unclear control mappings, limited expressive\nrange, and the need for guidance throughout use. We discuss several design\nopportunities for enhancing explainability of AI, including multimodal feedback\nand progressive interaction support. These findings contribute early insights\ntoward making AI music systems more explainable and empowering for novice\nusers.", "AI": {"tldr": "DeformTune \u662f\u4e00\u4e2a\u7ed3\u5408\u89e6\u89c9\u53d8\u5f62\u754c\u9762\u4e0e MeasureVAE \u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u65e8\u5728\u4e3a\u65e0\u97f3\u4e50\u80cc\u666f\u7684\u7528\u6237\u63d0\u4f9b\u66f4\u76f4\u89c2\u7684 AI \u97f3\u4e50\u751f\u6210\u4f53\u9a8c\u3002\u521d\u6b65\u7814\u7a76\u63ed\u793a\u4e86\u7528\u6237\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u63d0\u5347 AI \u53ef\u89e3\u91ca\u6027\u7684\u8bbe\u8ba1\u673a\u4f1a\u3002", "motivation": "\u73b0\u6709 AI \u97f3\u4e50\u751f\u6210\u5de5\u5177\u4f9d\u8d56\u6587\u672c\u63d0\u793a\u6216\u590d\u6742\u754c\u9762\uff0c\u9650\u5236\u4e86\u975e\u97f3\u4e50\u80cc\u666f\u7528\u6237\u7684\u4f7f\u7528\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u66f4\u76f4\u89c2\u3001\u6613\u7528\u7684\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u5f00\u53d1 DeformTune \u539f\u578b\u7cfb\u7edf\uff0c\u7ed3\u5408\u89e6\u89c9\u53d8\u5f62\u754c\u9762\u4e0e MeasureVAE \u6a21\u578b\uff0c\u5e76\u901a\u8fc7 11 \u540d\u975e\u4e13\u4e1a\u97f3\u4e50\u7528\u6237\u7684\u521d\u6b65\u7814\u7a76\u6536\u96c6\u53cd\u9988\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7528\u6237\u9762\u4e34\u63a7\u5236\u6620\u5c04\u4e0d\u660e\u786e\u3001\u8868\u8fbe\u8303\u56f4\u6709\u9650\u7b49\u95ee\u9898\uff0c\u4f46\u63d0\u51fa\u4e86\u901a\u8fc7\u591a\u6a21\u6001\u53cd\u9988\u548c\u6e10\u8fdb\u5f0f\u4ea4\u4e92\u652f\u6301\u63d0\u5347 AI \u53ef\u89e3\u91ca\u6027\u7684\u673a\u4f1a\u3002", "conclusion": "DeformTune \u4e3a AI \u97f3\u4e50\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7528\u6237\u53cb\u597d\u6027\u63d0\u4f9b\u4e86\u65e9\u671f\u7814\u7a76\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u8bbe\u8ba1\u66f4\u6613\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2508.00234", "pdf": "https://arxiv.org/pdf/2508.00234", "abs": "https://arxiv.org/abs/2508.00234", "authors": ["Jin Yang", "Qiong Wu", "Zhiying Feng", "Zhi Zhou", "Deke Guo", "Xu Chen"], "title": "Quality-of-Service Aware LLM Routing for Edge Computing with Multiple Experts", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.MA"], "comment": "Accepted by IEEE Transactions on Mobile Computing", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities,\nleading to a significant increase in user demand for LLM services. However,\ncloud-based LLM services often suffer from high latency, unstable\nresponsiveness, and privacy concerns. Therefore, multiple LLMs are usually\ndeployed at the network edge to boost real-time responsiveness and protect data\nprivacy, particularly for many emerging smart mobile and IoT applications.\nGiven the varying response quality and latency of LLM services, a critical\nissue is how to route user requests from mobile and IoT devices to an\nappropriate LLM service (i.e., edge LLM expert) to ensure acceptable\nquality-of-service (QoS). Existing routing algorithms fail to simultaneously\naddress the heterogeneity of LLM services, the interference among requests, and\nthe dynamic workloads necessary for maintaining long-term stable QoS. To meet\nthese challenges, in this paper we propose a novel deep reinforcement learning\n(DRL)-based QoS-aware LLM routing framework for sustained high-quality LLM\nservices. Due to the dynamic nature of the global state, we propose a dynamic\nstate abstraction technique to compactly represent global state features with a\nheterogeneous graph attention network (HAN). Additionally, we introduce an\naction impact estimator and a tailored reward function to guide the DRL agent\nin maximizing QoS and preventing latency violations. Extensive experiments on\nboth Poisson and real-world workloads demonstrate that our proposed algorithm\nsignificantly improves average QoS and computing resource efficiency compared\nto existing baselines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684QoS\u611f\u77e5LLM\u8def\u7531\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u8fb9\u7f18LLM\u670d\u52a1\u7684\u5b9e\u65f6\u54cd\u5e94\u548c\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u4e91LLM\u670d\u52a1\u5b58\u5728\u9ad8\u5ef6\u8fdf\u3001\u4e0d\u7a33\u5b9a\u54cd\u5e94\u548c\u9690\u79c1\u95ee\u9898\uff0c\u90e8\u7f72\u8fb9\u7f18LLM\u662f\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9700\u4f18\u5316\u8bf7\u6c42\u8def\u7531\u4ee5\u4fdd\u969cQoS\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u7ed3\u5408\u52a8\u6001\u72b6\u6001\u62bd\u8c61\u6280\u672f\u548c\u5f02\u6784\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08HAN\uff09\uff0c\u4ee5\u53ca\u52a8\u4f5c\u5f71\u54cd\u4f30\u8ba1\u5668\u548c\u5b9a\u5236\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\uff0c\u6240\u63d0\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u5e73\u5747QoS\u548c\u8ba1\u7b97\u8d44\u6e90\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3LLM\u670d\u52a1\u5f02\u6784\u6027\u3001\u8bf7\u6c42\u5e72\u6270\u548c\u52a8\u6001\u8d1f\u8f7d\u95ee\u9898\uff0c\u786e\u4fdd\u957f\u671f\u7a33\u5b9aQoS\u3002"}}
{"id": "2508.00255", "pdf": "https://arxiv.org/pdf/2508.00255", "abs": "https://arxiv.org/abs/2508.00255", "authors": ["Boqi Chen", "Ou Wei", "Bingzhou Zheng", "Gunter Mussbacher"], "title": "Accurate and Consistent Graph Model Generation from Text with Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at ACM / IEEE 28th International Conference on Model Driven\n  Engineering Languages and Systems (MODELS 2025)", "summary": "Graph model generation from natural language description is an important task\nwith many applications in software engineering. With the rise of large language\nmodels (LLMs), there is a growing interest in using LLMs for graph model\ngeneration. Nevertheless, LLM-based graph model generation typically produces\npartially correct models that suffer from three main issues: (1) syntax\nviolations: the generated model may not adhere to the syntax defined by its\nmetamodel, (2) constraint inconsistencies: the structure of the model might not\nconform to some domain-specific constraints, and (3) inaccuracy: due to the\ninherent uncertainty in LLMs, the models can include inaccurate, hallucinated\nelements. While the first issue is often addressed through techniques such as\nconstraint decoding or filtering, the latter two remain largely unaddressed.\nMotivated by recent self-consistency approaches in LLMs, we propose a novel\nabstraction-concretization framework that enhances the consistency and quality\nof generated graph models by considering multiple outputs from an LLM. Our\napproach first constructs a probabilistic partial model that aggregates all\ncandidate outputs and then refines this partial model into the most appropriate\nconcrete model that satisfies all constraints. We evaluate our framework on\nseveral popular open-source and closed-source LLMs using diverse datasets for\nmodel generation tasks. The results demonstrate that our approach significantly\nimproves both the consistency and quality of the generated graph models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61-\u5177\u4f53\u5316\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u5408LLM\u7684\u591a\u4e2a\u8f93\u51fa\u6765\u63d0\u5347\u56fe\u6a21\u578b\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u89e3\u51b3\u4e86\u8bed\u6cd5\u9519\u8bef\u548c\u7ea6\u675f\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LLM\u751f\u6210\u7684\u56fe\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u8bed\u6cd5\u8fdd\u89c4\u3001\u7ea6\u675f\u4e0d\u4e00\u81f4\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u4e09\u5927\u95ee\u9898\u3002", "method": "\u91c7\u7528\u62bd\u8c61-\u5177\u4f53\u5316\u6846\u67b6\uff0c\u9996\u5148\u751f\u6210\u6982\u7387\u6027\u90e8\u5206\u6a21\u578b\u805a\u5408\u5019\u9009\u8f93\u51fa\uff0c\u518d\u7cbe\u70bc\u4e3a\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\u7684\u5177\u4f53\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u56fe\u6a21\u578b\u7684\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u751f\u6210\u56fe\u6a21\u578b\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u8fd9\u4e00\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00021", "pdf": "https://arxiv.org/pdf/2508.00021", "abs": "https://arxiv.org/abs/2508.00021", "authors": ["Thomas A. Henzinger", "Konstantin Kueffner", "Vasu Singh", "I Sun"], "title": "Alignment Monitoring", "categories": ["cs.LO"], "comment": null, "summary": "Formal verification provides assurances that a probabilistic system satisfies\nits specification--conditioned on the system model being aligned with reality.\nWe propose alignment monitoring to watch that this assumption is justified. We\nconsider a probabilistic model well aligned if it accurately predicts the\nbehaviour of an uncertain system in advance. An alignment score measures this\nby quantifying the similarity between the model's predicted and the system's\n(unknown) actual distributions. An alignment monitor observes the system at\nruntime; at each point in time it uses the current state and the model to\npredict the next state. After the next state is observed, the monitor updates\nthe verdict, which is a high-probability interval estimate for the true\nalignment score. We utilize tools from sequential forecasting to construct our\nalignment monitors. Besides a monitor for measuring the expected alignment\nscore, we introduce a differential alignment monitor, designed for comparing\ntwo models, and a weighted alignment monitor, which permits task-specific\nalignment monitoring. We evaluate our monitors experimentally on the PRISM\nbenchmark suite. They are fast, memory-efficient, and detect misalignment\nearly.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5bf9\u9f50\u76d1\u63a7\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u6982\u7387\u6a21\u578b\u4e0e\u5b9e\u9645\u7cfb\u7edf\u7684\u9884\u6d4b\u5bf9\u9f50\u60c5\u51b5\uff0c\u5e76\u63d0\u4f9b\u4e86\u591a\u7c7b\u76d1\u63a7\u5668\u4ee5\u8bc4\u4f30\u6a21\u578b\u5bf9\u9f50\u6027\u3002", "motivation": "\u786e\u4fdd\u6982\u7387\u6a21\u578b\u4e0e\u73b0\u5b9e\u7684\u7cfb\u7edf\u884c\u4e3a\u5bf9\u9f50\u662f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u524d\u63d0\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u52a8\u6001\u76d1\u6d4b\u673a\u5236\u3002", "method": "\u5229\u7528\u987a\u5e8f\u9884\u6d4b\u5de5\u5177\u6784\u5efa\u5bf9\u9f50\u76d1\u63a7\u5668\uff0c\u5305\u62ec\u57fa\u7840\u5bf9\u9f50\u76d1\u63a7\u5668\u3001\u5dee\u5206\u5bf9\u9f50\u76d1\u63a7\u5668\u548c\u52a0\u6743\u5bf9\u9f50\u76d1\u63a7\u5668\u3002", "result": "\u5b9e\u9a8c\u5728PRISM\u57fa\u51c6\u5957\u4ef6\u4e0a\u9a8c\u8bc1\uff0c\u76d1\u63a7\u5668\u5feb\u901f\u3001\u5185\u5b58\u9ad8\u6548\u4e14\u80fd\u65e9\u671f\u68c0\u6d4b\u4e0d\u5bf9\u9f50\u3002", "conclusion": "\u5bf9\u9f50\u76d1\u63a7\u5668\u4e3a\u6a21\u578b\u4e0e\u73b0\u5b9e\u7684\u52a8\u6001\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2508.00748", "pdf": "https://arxiv.org/pdf/2508.00748", "abs": "https://arxiv.org/abs/2508.00748", "authors": ["Laura Pedrouzo-Rodriguez", "Pedro Delgado-DeRobles", "Luis F. Gomez", "Ruben Tolosana", "Ruben Vera-Rodriguez", "Aythami Morales", "Julian Fierrez"], "title": "Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.MM"], "comment": "Accepted at the IEEE International Joint Conference on Biometrics\n  (IJCB 2025)", "summary": "Photorealistic talking-head avatars are becoming increasingly common in\nvirtual meetings, gaming, and social platforms. These avatars allow for more\nimmersive communication, but they also introduce serious security risks. One\nemerging threat is impersonation: an attacker can steal a user's\navatar-preserving their appearance and voice-making it nearly impossible to\ndetect its fraudulent usage by sight or sound alone. In this paper, we explore\nthe challenge of biometric verification in such avatar-mediated scenarios. Our\nmain question is whether an individual's facial motion patterns can serve as\nreliable behavioral biometrics to verify their identity when the avatar's\nvisual appearance is a facsimile of its owner. To answer this question, we\nintroduce a new dataset of realistic avatar videos created using a\nstate-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and\nimpostor avatar videos. We also propose a lightweight, explainable\nspatio-temporal Graph Convolutional Network architecture with temporal\nattention pooling, that uses only facial landmarks to model dynamic facial\ngestures. Experimental results demonstrate that facial motion cues enable\nmeaningful identity verification with AUC values approaching 80%. The proposed\nbenchmark and biometric system are available for the research community in\norder to bring attention to the urgent need for more advanced behavioral\nbiometric defenses in avatar-based communication systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u865a\u62df\u5316\u8eab\u4e2d\u4f7f\u7528\u9762\u90e8\u8fd0\u52a8\u6a21\u5f0f\u4f5c\u4e3a\u884c\u4e3a\u751f\u7269\u7279\u5f81\u8fdb\u884c\u8eab\u4efd\u9a8c\u8bc1\u7684\u53ef\u80fd\u6027\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6570\u636e\u96c6\u548c\u8f7b\u91cf\u7ea7\u7f51\u7edc\u67b6\u6784\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u903c\u771f\u865a\u62df\u5316\u8eab\u7684\u666e\u53ca\uff0c\u5176\u5e26\u6765\u7684\u8eab\u4efd\u5192\u7528\u98ce\u9669\u65e5\u76ca\u4e25\u91cd\u3002\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u9762\u90e8\u8fd0\u52a8\u6a21\u5f0f\u80fd\u5426\u4f5c\u4e3a\u53ef\u9760\u7684\u884c\u4e3a\u751f\u7269\u7279\u5f81\u6765\u68c0\u6d4b\u5192\u7528\u884c\u4e3a\u3002", "method": "\u901a\u8fc7GAGAvatar\u751f\u6210\u4e86\u771f\u5b9e\u4e0e\u5192\u7528\u7684\u865a\u62df\u5316\u8eab\u89c6\u9891\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u65f6\u7a7a\u56fe\u5377\u79ef\u7f51\u7edc\u67b6\u6784\uff0c\u5229\u7528\u9762\u90e8\u5173\u952e\u70b9\u5efa\u6a21\u52a8\u6001\u8868\u60c5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9762\u90e8\u8fd0\u52a8\u7279\u5f81\u53ef\u5b9e\u73b0\u6709\u6548\u7684\u8eab\u4efd\u9a8c\u8bc1\uff0cAUC\u503c\u63a5\u8fd180%\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u865a\u62df\u5316\u8eab\u901a\u4fe1\u7cfb\u7edf\u4e2d\u52a0\u5f3a\u884c\u4e3a\u751f\u7269\u7279\u5f81\u9632\u5fa1\u7684\u7d27\u8feb\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5173\u6570\u636e\u96c6\u548c\u7cfb\u7edf\u4f9b\u793e\u533a\u7814\u7a76\u3002"}}
{"id": "2508.00534", "pdf": "https://arxiv.org/pdf/2508.00534", "abs": "https://arxiv.org/abs/2508.00534", "authors": ["Mikel Vandeloise"], "title": "Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations", "categories": ["cs.PL", "cs.CL", "D.3.2; F.3.2; D.3.1"], "comment": "Preprint submitted to the Journal of Object Technology on July 29,\n  2025. Data available upon request until peer-review is completed", "summary": "The rise of multi-paradigm languages challenges traditional classification\nmethods, leading to practical software engineering issues like interoperability\ndefects. This systematic literature review (SLR) maps the formal foundations of\nprogramming paradigms. Our objective is twofold: (1) to assess the state of the\nart of classification formalisms and their limitations, and (2) to identify the\nconceptual primitives and mathematical frameworks for a more powerful,\nreconstructive approach.\n  Based on a synthesis of 74 primary studies, we find that existing taxonomies\nlack conceptual granularity, a unified formal basis, and struggle with hybrid\nlanguages. In response, our analysis reveals a strong convergence toward a\ncompositional reconstruction of paradigms. This approach identifies a minimal\nset of orthogonal, atomic primitives and leverages mathematical frameworks,\npredominantly Type theory, Category theory and Unifying Theories of Programming\n(UTP), to formally guarantee their compositional properties.\n  We conclude that the literature reflects a significant intellectual shift\naway from classification towards these promising formal, reconstructive\nframeworks. This review provides a map of this evolution and proposes a\nresearch agenda for their unification.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u7efc\u8ff0\u4e86\u591a\u8303\u5f0f\u7f16\u7a0b\u8bed\u8a00\u7684\u5206\u7c7b\u95ee\u9898\uff0c\u6307\u51fa\u73b0\u6709\u5206\u7c7b\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u7ec4\u5408\u91cd\u6784\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u591a\u8303\u5f0f\u8bed\u8a00\u7684\u5174\u8d77\u4f7f\u5f97\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff0c\u5bfc\u81f4\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u4e92\u64cd\u4f5c\u6027\u7f3a\u9677\u7b49\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5bf974\u9879\u4e3b\u8981\u7814\u7a76\u7684\u7efc\u5408\uff0c\u5206\u6790\u73b0\u6709\u5206\u7c7b\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u7ec4\u5408\u91cd\u6784\u7684\u539f\u5b50\u57fa\u5143\u548c\u6570\u5b66\u6846\u67b6\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u5206\u7c7b\u6cd5\u7f3a\u4e4f\u6982\u5ff5\u7ec6\u7c92\u5ea6\u548c\u7edf\u4e00\u7684\u5f62\u5f0f\u57fa\u7840\uff0c\u800c\u7ec4\u5408\u91cd\u6784\u65b9\u6cd5\uff08\u57fa\u4e8e\u7c7b\u578b\u8bba\u3001\u8303\u7574\u8bba\u548c\u7edf\u4e00\u7f16\u7a0b\u7406\u8bba\uff09\u66f4\u5177\u524d\u666f\u3002", "conclusion": "\u7814\u7a76\u6307\u51fa\u6587\u732e\u4e2d\u51fa\u73b0\u4e86\u4ece\u5206\u7c7b\u5411\u5f62\u5f0f\u91cd\u6784\u6846\u67b6\u7684\u663e\u8457\u8f6c\u53d8\uff0c\u5e76\u63d0\u51fa\u7edf\u4e00\u7814\u7a76\u7684\u8bae\u7a0b\u3002"}}
{"id": "2508.00028", "pdf": "https://arxiv.org/pdf/2508.00028", "abs": "https://arxiv.org/abs/2508.00028", "authors": ["Abir Ray"], "title": "Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models", "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.NA", "math.NA"], "comment": "12 pages", "summary": "Spectrum resources are often underutilized across time and space, motivating\ndynamic spectrum access strategies that allow secondary users to exploit unused\nfrequencies. A key challenge is predicting when and where spectrum will be\navailable (i.e., unused by primary licensed users) in order to enable proactive\nand interference-free access. This paper proposes a scalable framework for\nspectrum availability prediction that combines a two-state Markov chain model\nof primary user activity with high-fidelity propagation models from the ITU-R\n(specifically Recommendations P.528 and P.2108). The Markov chain captures\ntemporal occupancy patterns, while the propagation models incorporate path loss\nand clutter effects to determine if primary signals exceed interference\nthresholds at secondary user locations. By integrating these components, the\nproposed method can predict spectrum opportunities both in time and space with\nimproved accuracy. We develop the system model and algorithm for the approach,\nanalyze its scalability and computational efficiency, and discuss assumptions,\nlimitations, and potential applications. The framework is flexible and can be\nadapted to various frequency bands and scenarios. The results and analysis show\nthat the proposed approach can effectively identify available spectrum with low\ncomputational cost, making it suitable for real-time spectrum management in\ncognitive radio networks and other dynamic spectrum sharing systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9a6c\u5c14\u53ef\u592b\u94fe\u6a21\u578b\u548cITU-R\u4f20\u64ad\u6a21\u578b\u7684\u53ef\u6269\u5c55\u9891\u8c31\u53ef\u7528\u6027\u9884\u6d4b\u6846\u67b6\uff0c\u4ee5\u52a8\u6001\u8bc6\u522b\u9891\u8c31\u673a\u4f1a\u3002", "motivation": "\u9891\u8c31\u8d44\u6e90\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u4e0a\u5e38\u88ab\u4f4e\u6548\u5229\u7528\uff0c\u9700\u52a8\u6001\u9891\u8c31\u63a5\u5165\u7b56\u7565\u4ee5\u5141\u8bb8\u6b21\u7ea7\u7528\u6237\u4f7f\u7528\u7a7a\u95f2\u9891\u7387\u3002", "method": "\u7ed3\u5408\u4e24\u72b6\u6001\u9a6c\u5c14\u53ef\u592b\u94fe\u6a21\u578b\uff08\u6355\u6349\u65f6\u95f4\u5360\u7528\u6a21\u5f0f\uff09\u548cITU-R\u4f20\u64ad\u6a21\u578b\uff08\u8def\u5f84\u635f\u8017\u548c\u6742\u6ce2\u6548\u5e94\uff09\uff0c\u9884\u6d4b\u9891\u8c31\u53ef\u7528\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u9884\u6d4b\u65f6\u7a7a\u9891\u8c31\u673a\u4f1a\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u9891\u8c31\u7ba1\u7406\u3002", "conclusion": "\u6846\u67b6\u7075\u6d3b\uff0c\u53ef\u9002\u914d\u4e0d\u540c\u9891\u6bb5\u548c\u573a\u666f\uff0c\u4e3a\u8ba4\u77e5\u65e0\u7ebf\u7535\u7f51\u7edc\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00178", "pdf": "https://arxiv.org/pdf/2508.00178", "abs": "https://arxiv.org/abs/2508.00178", "authors": ["Brian Houck", "Travis Lowdermilk", "Cody Beyer", "Steven Clarke", "Ben Hanrahan"], "title": "The SPACE of AI: Real-World Lessons on AI's Impact on Developers", "categories": ["cs.HC", "cs.AI", "cs.SE"], "comment": null, "summary": "As artificial intelligence (AI) tools become increasingly embedded in\nsoftware development workflows, questions persist about their true impact on\ndeveloper productivity and experience. This paper presents findings from a\nmixed-methods study examining how developers perceive AI's influence across the\ndimensions of the SPACE framework: Satisfaction, Performance, Activity,\nCollaboration and Efficiency. Drawing on survey responses from over 500\ndevelopers and qualitative insights from interviews and observational studies,\nwe find that AI is broadly adopted and widely seen as enhancing productivity,\nparticularly for routine tasks. However, the benefits vary, depending on task\ncomplexity, individual usage patterns, and team-level adoption. Developers\nreport increased efficiency and satisfaction, with less evidence of impact on\ncollaboration. Organizational support and peer learning play key roles in\nmaximizing AI's value. These findings suggest that AI is augmenting developers\nrather than replacing them, and that effective integration depends as much on\nteam culture and support structures as on the tools themselves. We conclude\nwith practical recommendations for teams, organizations and researchers seeking\nto harness AI's potential in software engineering.", "AI": {"tldr": "AI\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u88ab\u5e7f\u6cdb\u91c7\u7eb3\uff0c\u4e3b\u8981\u63d0\u5347\u4f8b\u884c\u4efb\u52a1\u7684\u6548\u7387\uff0c\u4f46\u5bf9\u534f\u4f5c\u5f71\u54cd\u6709\u9650\u3002\u56e2\u961f\u6587\u5316\u548c\u652f\u6301\u7ed3\u6784\u662f\u5173\u952e\u3002", "motivation": "\u63a2\u8ba8AI\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u548c\u4f53\u9a8c\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7814\u7a76\u65b9\u6cd5\uff0c\u5305\u62ec500\u591a\u4efd\u5f00\u53d1\u8005\u8c03\u67e5\u548c\u5b9a\u6027\u8bbf\u8c08\u4e0e\u89c2\u5bdf\u3002", "result": "AI\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u6ee1\u610f\u5ea6\uff0c\u4f46\u5bf9\u534f\u4f5c\u5f71\u54cd\u8f83\u5c0f\uff1b\u7ec4\u7ec7\u652f\u6301\u5bf9\u6700\u5927\u5316AI\u4ef7\u503c\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "AI\u662f\u5f00\u53d1\u8005\u7684\u8865\u5145\uff0c\u6709\u6548\u96c6\u6210\u9700\u56e2\u961f\u6587\u5316\u548c\u7ed3\u6784\u652f\u6301\u3002"}}
{"id": "2508.00596", "pdf": "https://arxiv.org/pdf/2508.00596", "abs": "https://arxiv.org/abs/2508.00596", "authors": ["Xiang Zhang", "Zhou Li", "Shuangyang Li", "Kai Wan", "Derrick Wing Kwan Ng", "Giuseppe Caire"], "title": "Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience", "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.LG", "math.IT"], "comment": "Submitted to IEEE for potential journal publication", "summary": "In decentralized federated learning (FL), multiple clients collaboratively\nlearn a shared machine learning (ML) model by leveraging their privately held\ndatasets distributed across the network, through interactive exchange of the\nintermediate model updates. To ensure data security, cryptographic techniques\nare commonly employed to protect model updates during aggregation. Despite\ngrowing interest in secure aggregation, existing works predominantly focus on\nprotocol design and computational guarantees, with limited understanding of the\nfundamental information-theoretic limits of such systems. Moreover, optimal\nbounds on communication and key usage remain unknown in decentralized settings,\nwhere no central aggregator is available. Motivated by these gaps, we study the\nproblem of decentralized secure aggregation (DSA) from an information-theoretic\nperspective. Specifically, we consider a network of $K$ fully-connected users,\neach holding a private input -- an abstraction of local training data -- who\naim to securely compute the sum of all inputs. The security constraint requires\nthat no user learns anything beyond the input sum, even when colluding with up\nto $T$ other users. We characterize the optimal rate region, which specifies\nthe minimum achievable communication and secret key rates for DSA. In\nparticular, we show that to securely compute one symbol of the desired input\nsum, each user must (i) transmit at least one symbol to others, (ii) hold at\nleast one symbol of secret key, and (iii) all users must collectively hold no\nfewer than $K - 1$ independent key symbols. Our results establish the\nfundamental performance limits of DSA, providing insights for the design of\nprovably secure and communication-efficient protocols in distributed learning\nsystems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u805a\u5408\u95ee\u9898\uff0c\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u63a2\u7d22\u4e86\u6700\u5c0f\u901a\u4fe1\u548c\u5bc6\u94a5\u4f7f\u7528\u7387\uff0c\u5e76\u5efa\u7acb\u4e86\u6027\u80fd\u6781\u9650\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u534f\u8bae\u8bbe\u8ba1\u548c\u8ba1\u7b97\u4fdd\u8bc1\uff0c\u4f46\u5bf9\u4fe1\u606f\u8bba\u6781\u9650\u548c\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e0b\u7684\u901a\u4fe1\u4e0e\u5bc6\u94a5\u4f7f\u7528\u6700\u4f18\u754c\u9650\u4e86\u89e3\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5206\u6790$K$\u4e2a\u5168\u8fde\u63a5\u7528\u6237\u7684\u5b89\u5168\u805a\u5408\u95ee\u9898\uff0c\u8981\u6c42\u6bcf\u4e2a\u7528\u6237\u4e0d\u6cc4\u9732\u9664\u8f93\u5165\u548c\u4e4b\u5916\u7684\u4efb\u4f55\u4fe1\u606f\uff0c\u5e76\u63a8\u5bfc\u4e86\u6700\u4f18\u901f\u7387\u533a\u57df\u3002", "result": "\u6bcf\u7528\u6237\u9700\u4f20\u8f93\u81f3\u5c11\u4e00\u4e2a\u7b26\u53f7\u3001\u6301\u6709\u81f3\u5c11\u4e00\u4e2a\u5bc6\u94a5\u7b26\u53f7\uff0c\u4e14\u6240\u6709\u7528\u6237\u603b\u5bc6\u94a5\u91cf\u4e0d\u5c11\u4e8e$K - 1$\u4e2a\u72ec\u7acb\u7b26\u53f7\u3002", "conclusion": "\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u5b89\u5168\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u534f\u8bae\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2508.00408", "pdf": "https://arxiv.org/pdf/2508.00408", "abs": "https://arxiv.org/abs/2508.00408", "authors": ["Dong Huang", "Jie M. Zhang", "Mark Harman", "Qianru Zhang", "Mingzhe Du", "See-Kiong Ng"], "title": "Benchmarking LLMs for Unit Test Generation from Real-World Functions", "categories": ["cs.SE", "cs.CL"], "comment": "Under Review", "summary": "Recently, large language models (LLMs) have shown great promise in automating\nunit test generation, significantly reducing the manual effort required by\ndevelopers. To effectively evaluate the capabilities of LLMs in this domain, it\nis crucial to have a well-designed benchmark that accurately reflects\nreal-world scenarios and mitigates common pitfalls. Existing LLM test\ngeneration benchmarks are limited by two critical drawbacks: data contamination\nand structurally simple function code. As a result, we often cannot rely on the\nvalidity of scientific conclusions drawn from empirical studies using these\nlimited benchmarks. The empirical evidence presented may be biased due to\ncontamination and may fail to generalize beyond toy programs due to structural\nsimplicity.\n  To address these problems, we introduce ULT (UnLeakedTestbench), a new\nbenchmark specifically designed for function-level unit test generation from\nreal-world Python functions. ULT is constructed through a multi-stage curation\nprocess that ensures high cyclomatic complexity and mitigates test case\ncontamination. With 3,909 carefully selected function-level tasks, ULT provides\na more realistic and challenging evaluation of LLMs' test generation\ncapabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT\nwith leaked tests designed to enable a controlled analysis of memorization\nversus reasoning in test generation. Our evaluation results demonstrate that\nULT is significantly more challenging. For example, test cases generated by\nLLMs only achieve 41.32\\%, 45.10\\%, 30.22\\%, and 40.21\\% for accuracy,\nstatement coverage, branch coverage, and mutation score on average for all\nLLMs, respectively. These results are substantially lower than the\ncorresponding metrics on TestEval (91.79\\%, 92.18\\%, 82.04\\%, and 49.69\\%) and\nPLT (47.07\\%, 55.13\\%, 40.07\\%, and 50.80\\%).", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86ULT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u6570\u636e\u6c61\u67d3\u548c\u7ed3\u6784\u7b80\u5355\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6d4b\u8bd5\u751f\u6210\u57fa\u51c6\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u7ed3\u6784\u7b80\u5355\u6027\u4e24\u5927\u95ee\u9898\uff0c\u53ef\u80fd\u5bfc\u81f4\u7814\u7a76\u7ed3\u8bba\u7684\u504f\u5dee\u548c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u771f\u5b9e\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u65b0\u57fa\u51c6\u3002", "method": "ULT\u901a\u8fc7\u591a\u9636\u6bb5\u7b5b\u9009\u6784\u5efa\uff0c\u5305\u542b3,909\u4e2a\u9ad8\u590d\u6742\u5ea6\u7684Python\u51fd\u6570\u4efb\u52a1\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86PLT\u57fa\u51c6\u7528\u4e8e\u5206\u6790\u8bb0\u5fc6\u4e0e\u63a8\u7406\u7684\u5dee\u5f02\u3002", "result": "ULT\u7684\u6d4b\u8bd5\u7ed3\u679c\u663e\u8457\u4f4e\u4e8e\u5176\u4ed6\u57fa\u51c6\uff08\u5982TestEval\u548cPLT\uff09\uff0c\u8868\u660e\u5176\u66f4\u5177\u6311\u6218\u6027\u3002\u4f8b\u5982\uff0cLLMs\u5728\u51c6\u786e\u7387\u3001\u8bed\u53e5\u8986\u76d6\u7387\u3001\u5206\u652f\u8986\u76d6\u7387\u548c\u53d8\u5f02\u8bc4\u5206\u4e0a\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "ULT\u4e3a\u8bc4\u4f30LLMs\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u6807\u51c6\uff0c\u540c\u65f6PLT\u8f85\u52a9\u5206\u6790\u4e86\u6a21\u578b\u7684\u8bb0\u5fc6\u6548\u5e94\u3002"}}
{"id": "2508.00151", "pdf": "https://arxiv.org/pdf/2508.00151", "abs": "https://arxiv.org/abs/2508.00151", "authors": ["Faruk Alpay", "Hamdi Al Alakkad"], "title": "Ordinal Folding Index: A Computable Metric for Self-Referential Semantics", "categories": ["cs.LO", "cs.GT", "03B70, 91A44, 91A05, 68Q10", "F.1.1; F.4.1; F.3.1; I.2.3"], "comment": "13 pages, 2 figures. Introduces the Ordinal Folding Index, a\n  computable ordinal depth metric for self referential statements that unifies\n  fixed point logic with infinite game theory", "summary": "The Ordinal Folding Index (OFI) is a new, fully computable yard-stick that\nmeasures how many rounds of self-reference a statement, protocol or position\nmust unfold before its truth or outcome stabilises. By turning this abstract\n'fold-back' depth into a single ordinal number, OFI forges a direct link\nbetween areas that are usually studied in isolation: the closure stages of\nfixed-point logics, the time-to-win values of infinite parity games, and the\nordinal progressions that calibrate the strength of formal theories. We prove\nthat OFI refines all classical game-theoretic and logical metrics while\nremaining algorithmically enumerable, supply a polynomial-time approximation\nscheme on finite arenas, and show how the index coincides exactly with the\nlength of the shortest winning strategy in the associated evaluation game.\nAlongside the theory we outline five open problems from the completeness of the\ncomputable-ordinal spectrum to the possibility of 'compressing' deep\nself-reference that chart a research programme at the intersection of\ncomputer-aided logic, algorithmic game theory and ordinal analysis. OFI thus\ninvites game theorists and logicians alike to view infinite play, transfinite\ninduction and reflective reasoning through a single, intuitive lens, opening\ncommon ground for techniques.", "AI": {"tldr": "OFI\u662f\u4e00\u79cd\u65b0\u7684\u3001\u5b8c\u5168\u53ef\u8ba1\u7b97\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u8861\u91cf\u8bed\u53e5\u3001\u534f\u8bae\u6216\u89c2\u70b9\u9700\u8981\u7ecf\u8fc7\u591a\u5c11\u8f6e\u81ea\u5f15\u7528\u624d\u80fd\u7a33\u5b9a\u5176\u771f\u5b9e\u6027\u6216\u7ed3\u679c\u3002", "motivation": "OFI\u65e8\u5728\u5efa\u7acb\u56fa\u5b9a\u70b9\u903b\u8f91\u3001\u65e0\u9650\u5947\u5076\u6e38\u620f\u548c\u5f62\u5f0f\u7406\u8bba\u5f3a\u5ea6\u4e4b\u95f4\u7684\u76f4\u63a5\u8054\u7cfb\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u89c6\u89d2\u3002", "method": "\u901a\u8fc7\u5c06\u81ea\u5f15\u7528\u6df1\u5ea6\u8f6c\u5316\u4e3a\u5355\u4e00\u5e8f\u6570\uff0cOFI\u7ed3\u5408\u4e86\u6e38\u620f\u7406\u8bba\u548c\u903b\u8f91\u5ea6\u91cf\uff0c\u5e76\u8bc1\u660e\u5176\u53ef\u7b97\u6cd5\u679a\u4e3e\u3002", "result": "OFI\u6539\u8fdb\u4e86\u6240\u6709\u7ecf\u5178\u6e38\u620f\u7406\u8bba\u548c\u903b\u8f91\u5ea6\u91cf\uff0c\u540c\u65f6\u5728\u6709\u9650\u7ade\u6280\u573a\u4e0a\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\u3002", "conclusion": "OFI\u4e3a\u6e38\u620f\u7406\u8bba\u5bb6\u548c\u903b\u8f91\u5b66\u5bb6\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5de5\u5177\uff0c\u4e3a\u8de8\u9886\u57df\u6280\u672f\u5f00\u8f9f\u4e86\u5171\u540c\u7814\u7a76\u57fa\u7840\u3002"}}
{"id": "2508.00042", "pdf": "https://arxiv.org/pdf/2508.00042", "abs": "https://arxiv.org/abs/2508.00042", "authors": ["Athanasios Tziouvaras", "Carolina Fortuna", "George Floros", "Kostas Kolomvatsos", "Panagiotis Sarigiannidis", "Marko Grobelnik", "Bla\u017e Bertalani\u010d"], "title": "Towards Reliable AI in 6G: Detecting Concept Drift in Wireless Network", "categories": ["cs.NI", "cs.LG"], "comment": "10 pages, 12 figures", "summary": "AI-native 6G networks promise unprecedented automation and performance by\nembedding machine-learning models throughout the radio access and core segments\nof the network. However, the non-stationary nature of wireless environments due\nto infrastructure changes, user mobility, and emerging traffic patterns,\ninduces concept drifts that can quickly degrade these model accuracies.\nExisting methods in general are very domain specific, or struggle with certain\ntype of concept drift. In this paper, we introduce two unsupervised,\nmodel-agnostic, batch concept drift detectors. Both methods compute an\nexpected-utility score to decide when concept drift occurred and if model\nretraining is warranted, without requiring ground-truth labels after\ndeployment. We validate our framework on two real-world wireless use cases in\noutdoor fingerprinting for localization and for link-anomaly detection, and\ndemonstrate that both methods are outperforming classical detectors such as\nADWIN, DDM, CUSUM by 20-40 percentage points. Additionally, they achieve an\nF1-score of 0.94 and 1.00 in correctly triggering retraining alarm, thus\nreducing the false alarm rate by up to 20 percentage points compared to the\nbest classical detectors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u65e0\u76d1\u7763\u3001\u6a21\u578b\u65e0\u5173\u7684\u6279\u91cf\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf96G\u7f51\u7edc\u4e2dAI\u6a21\u578b\u56e0\u65e0\u7ebf\u73af\u5883\u52a8\u6001\u53d8\u5316\u5bfc\u81f4\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\uff0c\u7814\u7a76\u901a\u7528\u4e14\u9ad8\u6548\u7684\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e24\u79cd\u57fa\u4e8e\u671f\u671b\u6548\u7528\u8bc4\u5206\u7684\u65e0\u76d1\u7763\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u5668\uff0c\u65e0\u9700\u90e8\u7f72\u540e\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\u89e6\u53d1\u6a21\u578b\u518d\u8bad\u7ec3\u3002", "result": "\u65b9\u6cd5\u5728\u771f\u5b9e\u65e0\u7ebf\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cF1\u5206\u6570\u8fbe0.94-1.00\uff0c\u5047\u8b66\u62a5\u7387\u964d\u4f4e20%\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e866G\u7f51\u7edc\u4e2dAI\u6a21\u578b\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2508.00211", "pdf": "https://arxiv.org/pdf/2508.00211", "abs": "https://arxiv.org/abs/2508.00211", "authors": ["Esen K. T\u00fct\u00fcnc\u00fc", "Mar Gonzalez-Franco", "Eric J. Gonzalez"], "title": "HandOver: Enabling Precise Selection & Manipulation of 3D Objects with Mouse and Hand Tracking", "categories": ["cs.HC"], "comment": "11 pages, 10 figures", "summary": "We present HandOver, an extended reality (XR) interaction technique designed\nto unify the precision of traditional mouse input for object selection with the\nexpressiveness of hand-tracking for object manipulation. With HandOver, the\nmouse is used to drive a depth-aware 3D cursor enabling precise and restful\ntargeting -by hovering their hand over the mouse, the user can then seamlessly\ntransition into direct 3D manipulation of the target object. In a formal user\nstudy, we compare HandOver against two raybased techniques: traditional\nraycasting (Ray) and a hybrid method (Ray+Hand) in a 3D docking task. Results\nshow HandOver yields lower task errors across all distances, and moreover\nimproves interaction ergonomics as highlighted by a RULA posture analysis and\nself-reported measures (NASA-TLX). These findings illustrate the benefits of\nblending traditional precise input devices with the expressive gestural inputs\nafforded by hand-tracking in XR, leading to improved user comfort and task\nperformance. This blended paradigm yields a unified workflow allowing users to\nleverage the best of each input modality as they interact in immersive\nenvironments.", "AI": {"tldr": "HandOver\u7ed3\u5408\u9f20\u6807\u7cbe\u786e\u9009\u62e9\u548c\u624b\u52bf\u8ffd\u8e2a\u76843D\u64cd\u4f5c\uff0c\u63d0\u9ad8XR\u4ea4\u4e92\u7684\u7cbe\u5ea6\u548c\u8868\u73b0\u529b\u3002\u7528\u6237\u7814\u7a76\u663e\u793a\u5176\u4f18\u4e8e\u4f20\u7edf\u5149\u7ebf\u6295\u5c04\u65b9\u6cd5\uff0c\u964d\u4f4e\u4efb\u52a1\u8bef\u5dee\u5e76\u63d0\u5347\u64cd\u4f5c\u8212\u9002\u6027\u3002", "motivation": "\u4f20\u7edfXR\u4ea4\u4e92\u4e2d\uff0c\u5149\u7ebf\u6295\u5c04\u6280\u672f\u96be\u4ee5\u517c\u987e\u5bf9\u8c61\u9009\u62e9\u7684\u7cbe\u5ea6\u548c\u624b\u52bf\u64cd\u4f5c\u7684\u7075\u6d3b\u6027\u3002HandOver\u65e8\u5728\u7ed3\u5408\u9f20\u6807\u7684\u7cbe\u786e\u6027\u548c\u624b\u52bf\u7684\u8868\u73b0\u529b\uff0c\u63d0\u4f9b\u66f4\u4f18\u7684\u4ea4\u4e92\u65b9\u6848\u3002", "method": "HandOver\u5229\u7528\u9f20\u6807\u9a71\u52a8\u6df1\u5ea6\u611f\u77e53D\u5149\u6807\u8fdb\u884c\u7cbe\u786e\u9009\u62e9\uff0c\u7528\u6237\u901a\u8fc7\u624b\u52bf\u60ac\u505c\u8fc7\u6e21\u5230\u76f4\u63a53D\u64cd\u4f5c\u76ee\u6807\u5bf9\u8c61\u3002\u5728\u7814\u7a76\u4e2d\uff0c\u4e0e\u4e24\u79cd\u5149\u7ebf\u6295\u5c04\u6280\u672f\uff08\u4f20\u7edfRay\u548c\u6df7\u5408Ray+Hand\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "HandOver\u5728\u6240\u6709\u8ddd\u79bb\u7684\u4efb\u52a1\u8bef\u5dee\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u901a\u8fc7RULA\u59ff\u52bf\u5206\u6790\u548cNASA-TLX\u81ea\u8bc4\u6307\u6807\u663e\u8457\u63d0\u5347\u4ea4\u4e92\u8212\u9002\u6027\u3002", "conclusion": "HandOver\u5c55\u793a\u4e86\u4e00\u79cd\u7ed3\u5408\u4f20\u7edf\u8f93\u5165\u8bbe\u5907\u548c\u624b\u52bf\u8ffd\u8e2a\u7684XR\u4ea4\u4e92\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u7528\u6237\u8212\u9002\u5ea6\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u6c89\u6d78\u5f0f\u73af\u5883\u63d0\u4f9b\u7edf\u4e00\u7684\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2508.00636", "pdf": "https://arxiv.org/pdf/2508.00636", "abs": "https://arxiv.org/abs/2508.00636", "authors": ["Haocheng Jiang", "Hua Shen", "Jixin Zhang", "Willy Susilo", "Mingwu Zhang"], "title": "FedGuard: A Diverse-Byzantine-Robust Mechanism for Federated Learning with Major Malicious Clients", "categories": ["cs.CR", "cs.DC"], "comment": null, "summary": "Federated learning is a distributed training framework vulnerable to\nByzantine attacks, particularly when over 50% of clients are malicious or when\ndatasets are highly non-independent and identically distributed (non-IID).\nAdditionally, most existing defense mechanisms are designed for specific attack\ntypes (e.g., gradient similarity-based schemes can only defend against outlier\nmodel poisoning), limiting their effectiveness. In response, we propose\nFedGuard, a novel federated learning mechanism. FedGuard cleverly addresses the\naforementioned issues by leveraging the high sensitivity of membership\ninference to model bias. By requiring clients to include an additional\nmini-batch of server-specified data in their training, FedGuard can identify\nand exclude poisoned models, as their confidence in the mini-batch will drop\nsignificantly. Our comprehensive evaluation unequivocally shows that, under\nthree highly non-IID datasets, with 90% of clients being Byzantine and seven\ndifferent types of Byzantine attacks occurring in each round, FedGuard\nsignificantly outperforms existing robust federated learning schemes in\nmitigating various types of Byzantine attacks.", "AI": {"tldr": "FedGuard\u662f\u4e00\u79cd\u65b0\u578b\u8054\u90a6\u5b66\u4e60\u673a\u5236\uff0c\u901a\u8fc7\u5229\u7528\u6210\u5458\u63a8\u65ad\u5bf9\u6a21\u578b\u504f\u5dee\u7684\u9ad8\u654f\u611f\u6027\uff0c\u6709\u6548\u8bc6\u522b\u5e76\u6392\u9664\u4e2d\u6bd2\u6a21\u578b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6848\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6613\u53d7\u62dc\u5360\u5ead\u653b\u51fb\uff0c\u5c24\u5176\u662f\u5f53\u5927\u591a\u6570\u5ba2\u6237\u7aef\u4e3a\u6076\u610f\u6216\u6570\u636e\u9ad8\u5ea6\u975e\u72ec\u7acb\u540c\u5206\u5e03\u65f6\u3002\u73b0\u6709\u9632\u5fa1\u673a\u5236\u4ec5\u9488\u5bf9\u7279\u5b9a\u653b\u51fb\u7c7b\u578b\uff0c\u6548\u679c\u6709\u9650\u3002", "method": "FedGuard\u8981\u6c42\u5ba2\u6237\u7aef\u5728\u8bad\u7ec3\u4e2d\u5305\u542b\u670d\u52a1\u5668\u6307\u5b9a\u7684\u989d\u5916\u5c0f\u6279\u91cf\u6570\u636e\uff0c\u5229\u7528\u4e2d\u6bd2\u6a21\u578b\u5728\u8fd9\u6279\u6570\u636e\u4e0a\u7f6e\u4fe1\u5ea6\u663e\u8457\u4e0b\u964d\u7684\u7279\u6027\u8fdb\u884c\u8bc6\u522b\u3002", "result": "\u5728\u4e09\u79cd\u9ad8\u5ea6\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u96c6\u300190%\u5ba2\u6237\u7aef\u4e3a\u62dc\u5360\u5ead\u4e14\u6bcf\u8f6e\u4e03\u79cd\u653b\u51fb\u60c5\u51b5\u4e0b\uff0cFedGuard\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "FedGuard\u901a\u8fc7\u521b\u65b0\u6027\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u62dc\u5360\u5ead\u653b\u51fb\u95ee\u9898\uff0c\u5177\u5907\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2508.00462", "pdf": "https://arxiv.org/pdf/2508.00462", "abs": "https://arxiv.org/abs/2508.00462", "authors": ["Linus Ververs", "Lutz Prechelt"], "title": "Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory", "categories": ["cs.SE"], "comment": null, "summary": "Context: Pair Programming as a work mode is used (occasionally or frequently)\nthroughout professional software development. Objective: Understand what\npower-related phenomena occur in pair programming as it is used in industry;\ngive advice to practitioners on how to do better pair programming. Method:\nAnalyze 22 industrial pair programming sessions using Grounded Theory\nMethodology. Formulate a Grounded Theory on power-related behaviors. Run a\nsurvey with 292 participants about that theory. Use it to demonstrate that the\nphenomena are common. Results: Our theory describes the phenomenon of Power\nGap: a perceived difference in participation opportunities. The theory shows\nthe behaviors that create a Power Gap or result from it. Power Gaps tend to\ndamage knowledge transfer, code quality, and process effi ciency. The survey\nresults show that all concepts from our theory are frequent in practice. They\nalso provide more grounding for concepts that are observable only indirectly.\nConclusions: It is a valuable component of pair programming skill to be able to\navoid Power Gaps. Specifically, pair partners need to avoid Hierarchical\nBehavior (which tends to create or increase a Power Gap) and should perform\nenough Equalizing Behavior (which prevents or reduces a Power Gap).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u7684\u6743\u529b\u5dee\u8ddd\u73b0\u8c61\u53ca\u5176\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u5584\u5efa\u8bae\u3002", "motivation": "\u63a2\u7a76\u5de5\u4e1a\u4e2d\u7ed3\u5bf9\u7f16\u7a0b\u7684\u6743\u529b\u76f8\u5173\u73b0\u8c61\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u5206\u679022\u4e2a\u5de5\u4e1a\u7ed3\u5bf9\u7f16\u7a0b\u4f1a\u8bdd\uff0c\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u8c03\u67e5292\u540d\u53c2\u4e0e\u8005\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u63d0\u51fa\u6743\u529b\u5dee\u8ddd\u7406\u8bba\uff0c\u6307\u51fa\u5176\u5bf9\u77e5\u8bc6\u4f20\u9012\u3001\u4ee3\u7801\u8d28\u91cf\u548c\u6548\u7387\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u8c03\u67e5\u8bc1\u5b9e\u7406\u8bba\u5e38\u89c1\u3002", "conclusion": "\u907f\u514d\u6743\u529b\u5dee\u8ddd\u662f\u7ed3\u5bf9\u7f16\u7a0b\u7684\u91cd\u8981\u6280\u80fd\uff0c\u9700\u51cf\u5c11\u5c42\u7ea7\u884c\u4e3a\uff0c\u589e\u52a0\u5e73\u7b49\u884c\u4e3a\u3002"}}
{"id": "2508.00419", "pdf": "https://arxiv.org/pdf/2508.00419", "abs": "https://arxiv.org/abs/2508.00419", "authors": ["Varun Bharti", "Shashwat Jha", "Dhruv Kumar", "Pankaj Jalote"], "title": "Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers", "categories": ["cs.LO", "cs.LG", "cs.PL"], "comment": "Under Review", "summary": "Loop invariants are essential for proving the correctness of programs with\nloops. Developing loop invariants is challenging, and fully automatic synthesis\ncannot be guaranteed for arbitrary programs. Some approaches have been proposed\nto synthesize loop invariants using symbolic techniques and more recently using\nneural approaches. These approaches are able to correctly synthesize loop\ninvariants only for subsets of standard benchmarks. In this work, we\ninvestigate whether modern, reasoning-optimized large language models can do\nbetter. We integrate OpenAI's O1, O1-mini, and O3-mini into a tightly coupled\ngenerate-and-check pipeline with the Z3 SMT solver, using solver\ncounterexamples to iteratively guide invariant refinement. We use Code2Inv\nbenchmark, which provides C programs along with their formal preconditions and\npostconditions. On this benchmark of 133 tasks, our framework achieves 100%\ncoverage (133 out of 133), outperforming the previous best of 107 out of 133,\nwhile requiring only 1-2 model proposals per instance and 14-55 seconds of\nwall-clock time. These results demonstrate that LLMs possess latent logical\nreasoning capabilities which can help automate loop invariant synthesis. While\nour experiments target C-specific programs, this approach should be\ngeneralizable to other imperative languages.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982OpenAI\u7684O1\u7cfb\u5217\uff09\u4e0eZ3\u6c42\u89e3\u5668\u7ed3\u5408\uff0c\u81ea\u52a8\u5316\u751f\u6210\u5faa\u73af\u4e0d\u53d8\u5f0f\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5faa\u73af\u4e0d\u53d8\u5f0f\u7684\u81ea\u52a8\u751f\u6210\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u8986\u76d6\u6240\u6709\u7a0b\u5e8f\u3002\u672c\u6587\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5728\u8fd9\u4e00\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "method": "\u5c06OpenAI\u7684O1\u7cfb\u5217\u6a21\u578b\u4e0eZ3\u6c42\u89e3\u5668\u7d27\u5bc6\u8026\u5408\uff0c\u901a\u8fc7\u751f\u6210-\u68c0\u67e5\u6d41\u7a0b\u8fed\u4ee3\u4f18\u5316\u5faa\u73af\u4e0d\u53d8\u5f0f\u3002\u4f7f\u7528Code2Inv\u57fa\u51c6\u6d4b\u8bd5133\u4e2a\u4efb\u52a1\u3002", "result": "\u6846\u67b6\u8986\u76d6\u6240\u6709133\u4e2a\u4efb\u52a1\uff08100%\uff09\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684\u6700\u4f73107\u4e2a\u4efb\u52a1\u3002\u6bcf\u6b21\u5b9e\u4f8b\u4ec5\u97001-2\u6b21\u6a21\u578b\u63d0\u8bae\uff0c\u8017\u65f614-55\u79d2\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u6f5c\u5728\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u53ef\u7528\u4e8e\u81ea\u52a8\u5316\u5faa\u73af\u4e0d\u53d8\u5f0f\u751f\u6210\uff0c\u4e14\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u547d\u4ee4\u5f0f\u8bed\u8a00\u3002"}}
{"id": "2508.00228", "pdf": "https://arxiv.org/pdf/2508.00228", "abs": "https://arxiv.org/abs/2508.00228", "authors": ["Aashay Arora", "Diego Davila", "Frank W\u00fcrthwein", "John Graham", "Dima Mishin", "Justas Balcas", "Tom Lehman", "Xi Yang", "Chin Guok", "Harvey Newman"], "title": "Benchmarking XRootD-HTTPS on 400Gbps Links with Variable Latencies", "categories": ["cs.NI"], "comment": "Submitted to CHEP 24", "summary": "In anticipation of the High Luminosity-LHC era, there is a critical need to\noversee software readiness for upcoming growth in network traffic for\nproduction and user data analysis access. This paper looks into software and\nhardware required improvements in US-CMS Tier-2 sites to be able to sustain and\nmeet the projected 400 Gbps bandwidth demands while tackling the challenge\nposed by varying latencies between sites. Specifically, our study focuses on\nidentifying the performance of XRootD HTTP third-party copies across multiple\n400 Gbps links and exploring different host and transfer configurations. Our\napproach involves systematic testing with variations in the number of origins\nper cluster and CPU allocations for each origin. By replicating real network\nconditions and creating network \"loops\" that traverse multiple switches across\nthe wide area network, we are able to replicate authentic network conditions", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u9ad8\u4eae\u5ea6LHC\u65f6\u4ee3\u4e0b\uff0cUS-CMS Tier-2\u7ad9\u70b9\u5982\u4f55\u63d0\u5347\u8f6f\u786c\u4ef6\u4ee5\u5e94\u5bf9400 Gbps\u5e26\u5bbd\u9700\u6c42\uff0c\u91cd\u70b9\u6d4b\u8bd5\u4e86XRootD HTTP\u7b2c\u4e09\u65b9\u62f7\u8d1d\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u5e94\u5bf9\u672a\u6765\u7f51\u7edc\u6d41\u91cf\u7684\u589e\u957f\uff0c\u786e\u4fdd\u751f\u4ea7\u4e0e\u7528\u6237\u6570\u636e\u5206\u6790\u8bbf\u95ee\u7684\u8f6f\u4ef6\u51c6\u5907\u5c31\u7eea\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u6a21\u62df\u771f\u5b9e\u7f51\u7edc\u6761\u4ef6\uff0c\u63a2\u7d22\u4e0d\u540c\u4e3b\u673a\u548c\u4f20\u8f93\u914d\u7f6e\u5bf9XRootD HTTP\u7b2c\u4e09\u65b9\u62f7\u8d1d\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u6210\u529f\u590d\u73b0\u4e86\u771f\u5b9e\u7f51\u7edc\u6761\u4ef6\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u53f0\u6765\u6e90\u4e3b\u673a\u548cCPU\u5206\u914d\u7684\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u4e3a\u672a\u6765\u7f51\u7edc\u5347\u7ea7\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u652f\u6301\u9ad8\u5e26\u5bbd\u9700\u6c42\u7684\u5b9e\u73b0\u3002"}}
{"id": "2508.00233", "pdf": "https://arxiv.org/pdf/2508.00233", "abs": "https://arxiv.org/abs/2508.00233", "authors": ["Douglas Markant", "Subham Sah", "Alireza Karduni", "Milad Rogha", "My Thai", "Wenwen Dou"], "title": "Correcting Misperceptions at a Glance: Using Data Visualizations to Reduce Political Sectarianism", "categories": ["cs.HC"], "comment": "11 pages, 5 figures. IEEE VIS 2025", "summary": "Political sectarianism is fueled in part by misperceptions of political\nopponents: People commonly overestimate the support for extreme policies among\nmembers of the other party. Research suggests that correcting partisan\nmisperceptions by informing people about the actual views of outparty members\nmay reduce one's own expressed support for political extremism, including\npartisan violence and anti-democratic actions. The present study investigated\nhow correction effects depend on different representations of outparty views\ncommunicated through data visualizations. We conducted an experiment with U.S.\nbased participants from Prolific (N=239 Democrats, N=244 Republicans).\nParticipants made predictions about support for political violence and\nundemocratic practices among members of their political outparty. They were\nthen presented with data from an earlier survey on the actual views of outparty\nmembers. Some participants viewed only the average response (Mean-Only\ncondition), while other groups were shown visual representations of the range\nof views from 75% of the outparty (Mean+Interval condition) or the full\ndistribution of responses (Mean+Points condition). Compared to a control group\nthat was not informed about outparty views, we observed the strongest\ncorrection effects among participants in the Mean-only and Mean+Points\ncondition, while correction effects were weaker in the Mean+Interval condition.\nIn addition, participants who observed the full distribution of out-party views\n(Mean+Points condition) were most accurate at later recalling the degree of\nsupport among the outparty. Our findings suggest that data visualizations can\nbe an important tool for correcting pervasive distortions in beliefs about\nother groups. However, the way in which variability in outparty views is\nvisualized can significantly shape how people interpret and respond to\ncorrective information.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u653f\u6cbb\u6d3e\u522b\u7684\u6781\u7aef\u4e3b\u4e49\u90e8\u5206\u6e90\u4e8e\u5bf9\u653f\u6cbb\u5bf9\u624b\u7684\u9519\u8bef\u8ba4\u77e5\uff0c\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\u8ba4\u77e5\u80fd\u51cf\u5c11\u6781\u7aef\u4e3b\u4e49\u652f\u6301\u3002\u6570\u636e\u53ef\u89c6\u5316\u7684\u65b9\u5f0f\u5f71\u54cd\u7ea0\u6b63\u6548\u679c\u3002", "motivation": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u6570\u636e\u53ef\u89c6\u5316\u7ea0\u6b63\u5bf9\u653f\u6cbb\u5bf9\u624b\u7684\u8bef\u89e3\uff0c\u4ee5\u51cf\u5c11\u6781\u7aef\u4e3b\u4e49\u652f\u6301\u3002", "method": "\u5b9e\u9a8c\u8bbe\u8ba1\u6bd4\u8f83\u4e0d\u540c\u6570\u636e\u53ef\u89c6\u5316\u65b9\u5f0f\uff08\u4ec5\u5e73\u5747\u503c\u3001\u5e73\u5747\u503c\u52a0\u533a\u95f4\u3001\u5e73\u5747\u503c\u52a0\u70b9\uff09\u5bf9\u7ea0\u6b63\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u4ec5\u663e\u793a\u5e73\u5747\u503c\u548c\u663e\u793a\u5168\u5206\u5e03\u7684\u7ea0\u6b63\u6548\u679c\u6700\u5f3a\uff0c\u800c\u663e\u793a\u533a\u95f4\u7684\u6548\u679c\u8f83\u5f31\u3002\u663e\u793a\u5168\u5206\u5e03\u8fd8\u63d0\u9ad8\u4e86\u8bb0\u5fc6\u51c6\u786e\u6027\u3002", "conclusion": "\u6570\u636e\u53ef\u89c6\u5316\u662f\u7ea0\u6b63\u7fa4\u4f53\u8bef\u89e3\u7684\u6709\u6548\u5de5\u5177\uff0c\u4f46\u5176\u5448\u73b0\u65b9\u5f0f\u663e\u8457\u5f71\u54cd\u6548\u679c\u3002"}}
{"id": "2508.00806", "pdf": "https://arxiv.org/pdf/2508.00806", "abs": "https://arxiv.org/abs/2508.00806", "authors": ["Ping Chen", "Zhuohong Deng", "Ping Li", "Shuibing He", "Hongzi Zhu", "Yi Zheng", "Zhefeng Wang", "Baoxing Huai", "Minyi Guo"], "title": "Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management", "categories": ["cs.LG", "cs.DC"], "comment": "8 pages", "summary": "Training large language models often employs recomputation to alleviate\nmemory pressure, which can introduce up to 30% overhead in real-world\nscenarios. In this paper, we propose Adacc, a novel memory management framework\nthat combines adaptive compression and activation checkpointing to reduce the\nGPU memory footprint. It comprises three modules: (1) We design layer-specific\ncompression algorithms that account for outliers in LLM tensors, instead of\ndirectly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We\npropose an optimal scheduling policy that employs MILP to determine the best\nmemory optimization for each tensor. (3) To accommodate changes in training\ntensors, we introduce an adaptive policy evolution mechanism that adjusts the\npolicy during training to enhance throughput. Experimental results show that\nAdacc can accelerate the LLM training by 1.01x to 1.37x compared to\nstate-of-the-art frameworks, while maintaining comparable model accuracy to the\nBaseline.", "AI": {"tldr": "Adacc\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u5185\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u538b\u7f29\u548c\u6fc0\u6d3b\u68c0\u67e5\u70b9\u6280\u672f\uff0c\u51cf\u5c11GPU\u5185\u5b58\u5360\u7528\uff0c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\uff0c\u91cd\u65b0\u8ba1\u7b97\u4f1a\u5e26\u6765\u9ad8\u8fbe30%\u7684\u5f00\u9500\uff0cAdacc\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u7ba1\u7406\u51cf\u5c11\u8fd9\u79cd\u5f00\u9500\u3002", "method": "\u5305\u62ec\u4e09\u5c42\u8bbe\u8ba1\uff1a\u9488\u5bf9\u5f02\u5e38\u7684\u5c42\u7279\u5b9a\u538b\u7f29\u7b97\u6cd5\u3001\u57fa\u4e8eMILP\u7684\u6700\u4f18\u8c03\u5ea6\u7b56\u7565\u548c\u81ea\u9002\u5e94\u7b56\u7565\u6f14\u5316\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u663e\u793aAdacc\u80fd\u52a0\u901f\u8bad\u7ec31.01x\u81f31.37x\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7ebf\u76f8\u5f53\u7684\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "Adacc\u6709\u6548\u89e3\u51b3\u4e86\u5185\u5b58\u5f00\u9500\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2508.00508", "pdf": "https://arxiv.org/pdf/2508.00508", "abs": "https://arxiv.org/abs/2508.00508", "authors": ["Panagiotis Diamantakis", "Thanassis Avgerinos", "Yannis Smaragdakis"], "title": "Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Over the past two decades, two different types of static analyses have\nemerged as dominant paradigms both in academia and industry: value-flow\nanalysis (e.g., data-flow analysis or points-to analysis) and symbolic analysis\n(e.g., symbolic execution). Despite their individual successes in numerous\napplication fields, the two approaches have remained largely separate; an\nartifact of the simple reality that there is no broadly adopted unifying\nplatform for effortless and efficient integration of symbolic techniques with\nhigh-performance data-flow reasoning.\n  To bridge this gap, we introduce Desyan: a platform for writing program\nanalyses with seamless integration of value-flow and symbolic reasoning. Desyan\nexpands a production-ready Datalog fixpoint engine (Souffl\\'e) with\nfull-fledged SMT solving invoking industry-leading SMT engines. Desyan provides\nconstructs for automatically (and efficiently!) handling typical patterns that\ncome up in program analysis. At the same time, the integration is agnostic with\nrespect to the solving technology, and supports Datalog-native symbolic\nreasoning, via a bottom-up algebraic reasoning module.\n  The result is an engine that allows blending different kinds of reasoning, as\nneeded for the underlying analysis. For value-flow analysis, the engine is the\nbest-in-class Datalog evaluator (often by a factor of over 20x in execution\ntime); for applications that require full SMT (e.g., a concolic execution\nengine or other symbolic evaluator that needs to solve arbitrarily complex\nconditions), the engine is leveraging the leading SMT solvers; for lightweight\nsymbolic evaluation (e.g., solving simple conditionals in the context of a\npath-sensitive analysis), the engine can use Datalog-native symbolic reasoning,\nachieving large speedups (often of over 2x) compared to eagerly appealing to an\nSMT solver.", "AI": {"tldr": "Desyan\u662f\u4e00\u4e2a\u6574\u5408\u503c\u6d41\u5206\u6790\u548c\u7b26\u53f7\u63a8\u7406\u7684\u7a0b\u5e8f\u5206\u6790\u5e73\u53f0\uff0c\u57fa\u4e8eSouffl\u00e9 Datalog\u5f15\u64ce\uff0c\u652f\u6301\u9ad8\u6548SMT\u6c42\u89e3\u548c\u672c\u5730\u7b26\u53f7\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u503c\u6d41\u5206\u6790\u548c\u7b26\u53f7\u5206\u6790\u7f3a\u4e4f\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u5bfc\u81f4\u4e24\u79cd\u6280\u672f\u96be\u4ee5\u9ad8\u6548\u96c6\u6210\uff0c\u9650\u5236\u4e86\u7a0b\u5e8f\u5206\u6790\u7684\u6f5c\u529b\u548c\u6548\u7387\u3002", "method": "Desyan\u6269\u5c55\u4e86Souffl\u00e9 Datalog\u5f15\u64ce\uff0c\u96c6\u6210SMT\u6c42\u89e3\u5668\uff0c\u5e76\u63d0\u4f9b\u81ea\u52a8\u5904\u7406\u5178\u578b\u6a21\u5f0f\u7684\u652f\u6301\uff0c\u540c\u65f6\u652f\u6301Datalog\u672c\u5730\u7b26\u53f7\u63a8\u7406\u3002", "result": "Desyan\u5728\u503c\u6d41\u5206\u6790\u4e2d\u6027\u80fd\u9886\u5148\uff08\u63d0\u534720\u500d\u4ee5\u4e0a\uff09\uff0c\u5728\u9700\u8981\u590d\u6742SMT\u6c42\u89e3\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u8f7b\u91cf\u7ea7\u7b26\u53f7\u63a8\u7406\u901f\u5ea6\u63d0\u53472\u500d\u4ee5\u4e0a\u3002", "conclusion": "Desyan\u6210\u529f\u586b\u8865\u4e86\u503c\u6d41\u5206\u6790\u548c\u7b26\u53f7\u5206\u6790\u7684\u9e3f\u6c9f\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u96c6\u6210\u5e73\u53f0\u3002"}}
{"id": "2508.00575", "pdf": "https://arxiv.org/pdf/2508.00575", "abs": "https://arxiv.org/abs/2508.00575", "authors": ["Camille Bourgaux", "Anton Gnatenko", "Micha\u00ebl Thomazo"], "title": "Analysing Temporal Reasoning in Description Logics Using Formal Grammars", "categories": ["cs.LO", "cs.AI"], "comment": "This is an extended version of a paper appearing at the 28th European\n  Conference on Artificial Intelligence (ECAI 2025). 20 pages", "summary": "We establish a correspondence between (fragments of)\n$\\mathcal{TEL}^\\bigcirc$, a temporal extension of the $\\mathcal{EL}$\ndescription logic with the LTL operator $\\bigcirc^k$, and some specific kinds\nof formal grammars, in particular, conjunctive grammars (context-free grammars\nequipped with the operation of intersection). This connection implies that\n$\\mathcal{TEL}^\\bigcirc$ does not possess the property of ultimate periodicity\nof models, and further leads to undecidability of query answering in\n$\\mathcal{TEL}^\\bigcirc$, closing a question left open since the introduction\nof $\\mathcal{TEL}^\\bigcirc$. Moreover, it also allows to establish decidability\nof query answering for some new interesting fragments of\n$\\mathcal{TEL}^\\bigcirc$, and to reuse for this purpose existing tools and\nalgorithms for conjunctive grammars.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u7279\u5b9a\u5f62\u5f0f\u6587\u6cd5\u4e0e\u65f6\u6001\u63cf\u8ff0\u903b\u8f91 $\\mathcal{TEL}^\\bigcirc$ \u7247\u6bb5\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u5176\u6a21\u578b\u975e\u5468\u671f\u6027\u53ca\u67e5\u8be2\u56de\u7b54\u4e0d\u53ef\u5224\u5b9a\u6027\uff0c\u540c\u65f6\u53d1\u73b0\u4e86\u67d0\u4e9b\u7247\u6bb5\u7684\u53ef\u5224\u5b9a\u6027\u3002", "motivation": "\u63a2\u7d22 $\\mathcal{TEL}^\\bigcirc$ \u4e0e\u5f62\u5f0f\u6587\u6cd5\uff08\u5982\u8fde\u63a5\u6587\u6cd5\uff09\u7684\u8054\u7cfb\uff0c\u89e3\u51b3\u5176\u6a21\u578b\u5468\u671f\u6027\u548c\u67e5\u8be2\u56de\u7b54\u53ef\u5224\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06 $\\mathcal{TEL}^\\bigcirc$ \u7247\u6bb5\u4e0e\u8fde\u63a5\u6587\u6cd5\u5efa\u7acb\u5bf9\u5e94\u5173\u7cfb\uff0c\u5206\u6790\u5176\u6027\u8d28\u3002", "result": "\u8bc1\u660e $\\mathcal{TEL}^\\bigcirc$ \u4e0d\u5177\u6709\u6a21\u578b\u5468\u671f\u6027\uff0c\u67e5\u8be2\u56de\u7b54\u4e0d\u53ef\u5224\u5b9a\uff0c\u4f46\u53d1\u73b0\u4e86\u67d0\u4e9b\u7247\u6bb5\u7684\u53ef\u5224\u5b9a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86 $\\mathcal{TEL}^\\bigcirc$ \u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u5e76\u4e3a\u5176\u4ed6\u7247\u6bb5\u7684\u53ef\u5224\u5b9a\u6027\u63d0\u4f9b\u4e86\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2508.00239", "pdf": "https://arxiv.org/pdf/2508.00239", "abs": "https://arxiv.org/abs/2508.00239", "authors": ["Jacqueline Elise Bruen", "Myounghoon Jeon"], "title": "What's Behind the Magic? Audiences Seek Artistic Value in Generative AI's Contributions to a Live Dance Performance", "categories": ["cs.HC", "cs.AI"], "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts\n  2025) arXiv:2406.14485", "summary": "With the development of generative artificial intelligence (GenAI) tools to\ncreate art, stakeholders cannot come to an agreement on the value of these\nworks. In this study we uncovered the mixed opinions surrounding art made by\nAI. We developed two versions of a dance performance augmented by technology\neither with or without GenAI. For each version we informed audiences of the\nperformance's development either before or after a survey on their perceptions\nof the performance. There were thirty-nine participants (13 males, 26 female)\ndivided between the four performances. Results demonstrated that individuals\nwere more inclined to attribute artistic merit to works made by GenAI when they\nwere unaware of its use. We present this case study as a call to address the\nimportance of utilizing the social context and the users' interpretations of\nGenAI in shaping a technical explanation, leading to a greater discussion that\ncan bridge gaps in understanding.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u89c2\u4f17\u5bf9AI\u751f\u6210\u827a\u672f\u4f5c\u54c1\u7684\u8bc4\u4ef7\u5dee\u5f02\uff0c\u5c24\u5176\u662f\u5bf9\u821e\u8e48\u8868\u6f14\u7684\u8bc4\u4ef7\uff0c\u7ed3\u679c\u663e\u793a\u89c2\u4f17\u5728\u4e0d\u4e86\u89e3AI\u53c2\u4e0e\u65f6\u66f4\u5bb9\u6613\u8ba4\u53ef\u5176\u827a\u672f\u4ef7\u503c\u3002", "motivation": "\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u751f\u6210\u827a\u672f\u7684\u4ef7\u503c\u4e89\u8bae\uff0c\u5c24\u5176\u662f\u89c2\u4f17\u5bf9\u4e0d\u540c\u6280\u672f\u53c2\u4e0e\u7684\u8868\u6f14\u7684\u611f\u77e5\u5dee\u5f02\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u4e2a\u7248\u672c\u7684\u821e\u8e48\u8868\u6f14\uff08\u542b\u6216\u4e0d\u542bGenAI\uff09\uff0c\u5bf9\u89c2\u4f17\u8fdb\u884c\u524d\u540e\u95ee\u5377\u8c03\u67e5\uff0c\u517139\u540d\u53c2\u4e0e\u8005\u3002", "result": "\u89c2\u4f17\u5728\u4e0d\u4e86\u89e3AI\u53c2\u4e0e\u65f6\u66f4\u503e\u5411\u4e8e\u8ba4\u53ef\u5176\u827a\u672f\u4ef7\u503c\u3002", "conclusion": "\u5f3a\u8c03\u793e\u4f1a\u80cc\u666f\u548c\u7528\u6237\u89e3\u91ca\u7684\u91cd\u8981\u6027\uff0c\u547c\u5401\u66f4\u5e7f\u6cdb\u7684\u8ba8\u8bba\u4ee5\u5f25\u5408\u7406\u89e3\u5dee\u8ddd\u3002"}}
{"id": "2508.00546", "pdf": "https://arxiv.org/pdf/2508.00546", "abs": "https://arxiv.org/abs/2508.00546", "authors": ["Wenchao Gu", "Zongyi Lyu", "Yanlin Wang", "Hongyu Zhang", "Cuiyun Gao", "Michael R. Lyu"], "title": "SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code retrieval aims to provide users with desired code snippets based on\nusers' natural language queries. With the development of deep learning\ntechnologies, adopting pre-trained models for this task has become mainstream.\nConsidering the retrieval efficiency, most of the previous approaches adopt a\ndual-encoder for this task, which encodes the description and code snippet into\nrepresentation vectors, respectively. However, the model structure of the\ndual-encoder tends to limit the model's performance, since it lacks the\ninteraction between the code snippet and description at the bottom layer of the\nmodel during training. To improve the model's effectiveness while preserving\nits efficiency, we propose a framework, which adopts Self-AdaPtive Model\nDistillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts\nthe dual-encoder to narrow the search space and then adopts the cross-encoder\nto improve accuracy. To improve the efficiency of SPENCER, we propose a novel\nmodel distillation technique, which can greatly reduce the inference time of\nthe dual-encoder while maintaining the overall performance. We also propose a\nteaching assistant selection strategy for our model distillation, which can\nadaptively select the suitable teaching assistant models for different\npre-trained models during the model distillation to ensure the model\nperformance. Extensive experiments demonstrate that the combination of\ndual-encoder and cross-encoder improves overall performance compared to solely\ndual-encoder-based models for code retrieval. Besides, our model distillation\ntechnique retains over 98% of the overall performance while reducing the\ninference time of the dual-encoder by 70%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPENCER\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u63d0\u5347\u4ee3\u7801\u68c0\u7d22\u6027\u80fd\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u6a21\u578b\u84b8\u998f\u6280\u672f\u4f18\u5316\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u53cc\u7f16\u7801\u5668\u7f3a\u4e4f\u5e95\u5c42\u6a21\u578b\u8bad\u7ec3\u65f6\u4ee3\u7801\u4e0e\u63cf\u8ff0\u7684\u4ea4\u4e92\uff0c\u9650\u5236\u4e86\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u9ad8\u6548\u679c\u53c8\u4fdd\u6301\u6548\u7387\u7684\u65b9\u6cd5\u3002", "method": "SPENCER\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u518d\u4f7f\u7528\u4ea4\u53c9\u7f16\u7801\u5668\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u6a21\u578b\u84b8\u998f\u6280\u672f\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u6a21\u578b\u84b8\u998f\u6280\u672f\u51cf\u5c1170%\u63a8\u7406\u65f6\u95f4\u7684\u540c\u65f6\u4fdd\u6301\u4e8698%\u7684\u6027\u80fd\u3002", "conclusion": "SPENCER\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u53cc\u7f16\u7801\u5668\u65b9\u6cd5\uff0c\u4e3a\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00613", "pdf": "https://arxiv.org/pdf/2508.00613", "abs": "https://arxiv.org/abs/2508.00613", "authors": ["Benedikt Maderbacher", "Roderick Bloem"], "title": "Parameterized Infinite-State Reactive Synthesis", "categories": ["cs.LO"], "comment": null, "summary": "We propose a method to synthesize a parameterized infinite-state systems that\ncan be instantiated for different parameter values. The specification is given\nin a parameterized temporal logic that allows for data variables as well as\nparameter variables that encode properties of the environment. Our synthesis\nmethod runs in a counterexample-guided loop consisting of four main steps:\nFirst, we use existing techniques to synthesize concrete systems for some small\nparameter instantiations. Second, we generalize the concrete systems into a\nparameterized program. Third, we create a proof candidate consisting of an\ninvariant and a ranking function. Fourth, we check the proof candidate for\nconsistency with the program. If the proof succeeds, the parameterized program\nis valid. Otherwise, we identify a parameter value for which the proof fails\nand add a new concrete instance to step one. To generalize programs and create\nproof candidates, we use a combination of anti-unification and syntax-guided\nsynthesis to express syntactic differences between programs as functions of the\nparameters. We evaluate our approach on examples from the literature that have\nbeen extended with parameters as well as new problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u6210\u53c2\u6570\u5316\u65e0\u9650\u72b6\u6001\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u53ef\u9488\u5bf9\u4e0d\u540c\u53c2\u6570\u503c\u5b9e\u4f8b\u5316\u3002\u65b9\u6cd5\u901a\u8fc7\u53cd\u4f8b\u5f15\u5bfc\u5faa\u73af\uff0c\u5305\u62ec\u5408\u6210\u5177\u4f53\u7cfb\u7edf\u3001\u901a\u7528\u5316\u7a0b\u5e8f\u3001\u751f\u6210\u8bc1\u660e\u5019\u9009\u548c\u9a8c\u8bc1\u8bc1\u660e\u56db\u4e2a\u6b65\u9aa4\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u53c2\u6570\u5316\u7cfb\u7edf\u7684\u5408\u6210\uff0c\u7279\u522b\u662f\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u73af\u5883\u53c2\u6570\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u53cd\u4f8b\u5f15\u5bfc\u7684\u5faa\u73af\u65b9\u6cd5\uff0c\u7ed3\u5408\u53cd\u901a\u7528\u5316\u548c\u8bed\u6cd5\u5f15\u5bfc\u7684\u5408\u6210\u6280\u672f\uff0c\u5c06\u7a0b\u5e8f\u4e2d\u7684\u8bed\u6cd5\u5dee\u5f02\u8868\u8fbe\u4e3a\u53c2\u6570\u7684\u51fd\u6570\u3002", "result": "\u5728\u6587\u732e\u4e2d\u7684\u793a\u4f8b\u548c\u65b0\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5408\u6210\u53c2\u6570\u5316\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u6280\u672f\u786e\u4fdd\u5176\u6b63\u786e\u6027\u3002"}}
{"id": "2508.00772", "pdf": "https://arxiv.org/pdf/2508.00772", "abs": "https://arxiv.org/abs/2508.00772", "authors": ["Md Imranur Rahman Akib", "Fathima Binthe Muhammed", "Umit Saha", "Md Fazlul Karim Patwary", "Mehrin Anannya", "Md Alomgeer Hussein", "Md Biplob Hosen"], "title": "From Code to Career: Assessing Competitive Programmers for Industry Placement", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "In today's fast-paced tech industry, there is a growing need for tools that\nevaluate a programmer's job readiness based on their coding performance. This\nstudy focuses on predicting the potential of Codeforces users to secure various\nlevels of software engineering jobs. The primary objective is to analyze how a\nuser's competitive programming activity correlates with their chances of\nobtaining positions, ranging from entry-level roles to jobs at major tech\ncompanies. We collect user data using the Codeforces API, process key\nperformance metrics, and build a prediction model using a Random Forest\nclassifier. The model categorizes users into four levels of employability,\nranging from those needing further development to those ready for top-tier tech\njobs. The system is implemented using Flask and deployed on Render for\nreal-time predictions. Our evaluation demonstrates that the approach\neffectively distinguishes between different skill levels based on coding\nproficiency and participation. This work lays a foundation for the use of\nmachine learning in career assessment and could be extended to predict job\nreadiness in broader technical fields.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCodeforces\u7528\u6237\u7f16\u7a0b\u8868\u73b0\u9884\u6d4b\u5176\u5c31\u4e1a\u80fd\u529b\u7684\u6a21\u578b\uff0c\u91c7\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u5c06\u7528\u6237\u5206\u4e3a\u56db\u4e2a\u5c31\u4e1a\u80fd\u529b\u7b49\u7ea7\uff0c\u5e76\u901a\u8fc7Flask\u90e8\u7f72\u5b9e\u73b0\u5b9e\u65f6\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u79d1\u6280\u884c\u4e1a\u9700\u8981\u8bc4\u4f30\u7a0b\u5e8f\u5458\u5c31\u4e1a\u80fd\u529b\u7684\u5de5\u5177\uff0c\u7814\u7a76\u65e8\u5728\u5206\u6790\u7ade\u4e89\u7f16\u7a0b\u6d3b\u52a8\u4e0e\u6c42\u804c\u6210\u529f\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002", "method": "\u4f7f\u7528Codeforces API\u6536\u96c6\u7528\u6237\u6570\u636e\uff0c\u5904\u7406\u5173\u952e\u6027\u80fd\u6307\u6807\uff0c\u6784\u5efa\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u6a21\u578b\uff0c\u5e76\u901a\u8fc7Flask\u90e8\u7f72\u3002", "result": "\u6a21\u578b\u80fd\u6709\u6548\u533a\u5206\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\uff0c\u9884\u6d4b\u7528\u6237\u5c31\u4e1a\u80fd\u529b\uff0c\u4e3a\u804c\u4e1a\u8bc4\u4f30\u63d0\u4f9b\u673a\u5668\u5b66\u4e60\u57fa\u7840\u3002", "conclusion": "\u7814\u7a76\u4e3a\u673a\u5668\u5b66\u4e60\u5728\u6280\u672f\u804c\u4e1a\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u9886\u57df\u3002"}}
{"id": "2508.00256", "pdf": "https://arxiv.org/pdf/2508.00256", "abs": "https://arxiv.org/abs/2508.00256", "authors": ["Chuang Zhang", "Geng Sun", "Jiacheng Wang", "Yijing Lin", "Weijie Yuan", "Sinem Coleri", "Dusit Niyato", "Tony Q. S. Quek"], "title": "Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study", "categories": ["cs.NI", "cs.AI"], "comment": "This paper has been submitted to IEEE Communications Magazine for\n  consideration", "summary": "Low-altitude wireless networks (LAWNs) have the potential to revolutionize\ncommunications by supporting a range of applications, including urban parcel\ndelivery, aerial inspections and air taxis. However, compared with traditional\nwireless networks, LAWNs face unique security challenges due to low-altitude\noperations, frequent mobility and reliance on unlicensed spectrum, making it\nmore vulnerable to some malicious attacks. In this paper, we investigate some\nlarge artificial intelligence model (LAM)-enabled solutions for secure\ncommunications in LAWNs. Specifically, we first explore the amplified security\nrisks and important limitations of traditional AI methods in LAWNs. Then, we\nintroduce the basic concepts of LAMs and delve into the role of LAMs in\naddressing these challenges. To demonstrate the practical benefits of LAMs for\nsecure communications in LAWNs, we propose a novel LAM-based optimization\nframework that leverages large language models (LLMs) to generate enhanced\nstate features on top of handcrafted representations, and to design intrinsic\nrewards accordingly, thereby improving reinforcement learning performance for\nsecure communication tasks. Through a typical case study, simulation results\nvalidate the effectiveness of the proposed framework. Finally, we outline\nfuture directions for integrating LAMs into secure LAWN applications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\uff08LAWNs\uff09\u7684\u5b89\u5168\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u578b\u4eba\u5de5\u667a\u80fd\u6a21\u578b\uff08LAM\uff09\u7684\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5b89\u5168\u901a\u4fe1\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u4f4e\u7a7a\u64cd\u4f5c\u3001\u9891\u7e41\u79fb\u52a8\u548c\u4f9d\u8d56\u672a\u6388\u6743\u9891\u6bb5\u7684\u7279\u6027\uff0cLAWNs\u9762\u4e34\u72ec\u7279\u7684\u5b89\u5168\u6311\u6218\uff0c\u4f20\u7edfAI\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u7814\u7a76LAMs\u7684\u89e3\u51b3\u65b9\u6848\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLAM\u7684\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u589e\u5f3a\u72b6\u6001\u7279\u5f81\u5e76\u8bbe\u8ba1\u5185\u5728\u5956\u52b1\uff0c\u4ee5\u6539\u8fdb\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u901a\u4fe1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u4eff\u771f\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u6846\u67b6\u5728LAWNs\u5b89\u5168\u901a\u4fe1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "LAMs\u5728LAWNs\u5b89\u5168\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u5176\u96c6\u6210\u65b9\u5411\u3002"}}
{"id": "2508.00252", "pdf": "https://arxiv.org/pdf/2508.00252", "abs": "https://arxiv.org/abs/2508.00252", "authors": ["Wataru Kawabe", "Hiroto Fukuda", "Akihisa Shitara", "Yuri Nakao", "Yusuke Sugano"], "title": "TofuML: A Spatio-Physical Interactive Machine Learning Device for Interactive Exploration of Machine Learning for Novices", "categories": ["cs.HC"], "comment": "31 pages", "summary": "We introduce TofuML, an interactive system designed to make machine learning\n(ML) concepts more accessible and engaging for non-expert users. Unlike\nconventional GUI-based systems, TofuML employs a physical and spatial interface\nconsisting of a small device and a paper mat, allowing users to train and\nevaluate sound classification models through intuitive, toy-like interactions.\nThrough two user studies -- a comparative study against a GUI-based version and\na public event deployment -- we investigated how TofuML impacts users'\nengagement in the ML model creation process, their ability to provide\nappropriate training data, and their conception of potential applications. Our\nresults indicated that TofuML enhanced user engagement compared to a GUI while\nlowering barriers for non-experts to engage with ML. Users demonstrated\ncreativity in conceiving diverse ML applications, revealing opportunities to\noptimize between conceptual understanding and user engagement. These findings\ncontribute to developing interactive ML systems/frameworks designed for a wide\nrange of users.", "AI": {"tldr": "TofuML \u662f\u4e00\u4e2a\u4e92\u52a8\u7cfb\u7edf\uff0c\u901a\u8fc7\u7269\u7406\u7a7a\u95f4\u754c\u9762\u4f7f\u975e\u4e13\u5bb6\u7528\u6237\u66f4\u5bb9\u6613\u63a5\u89e6\u548c\u7406\u89e3\u673a\u5668\u5b66\u4e60\u6982\u5ff5\uff0c\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u975e\u4e13\u5bb6\u7528\u6237\u66f4\u5bb9\u6613\u7406\u89e3\u548c\u53c2\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bbe\u8ba1\u4e0e\u8bc4\u4f30\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u7269\u7406\u8bbe\u5907\u4e0e\u7eb8\u8d28\u754c\u9762\uff0c\u8ba9\u7528\u6237\u901a\u8fc7\u76f4\u89c9\u64cd\u4f5c\u8bad\u7ec3\u58f0\u97f3\u5206\u7c7b\u6a21\u578b\uff0c\u5e76\u4e0e\u4f20\u7edf GUI \u7cfb\u7edf\u5bf9\u6bd4\u3002", "result": "TofuML \u6bd4 GUI \u66f4\u80fd\u5438\u5f15\u7528\u6237\uff0c\u964d\u4f4e\u975e\u4e13\u5bb6\u53c2\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u95e8\u69db\uff0c\u5e76\u6fc0\u53d1\u7528\u6237\u521b\u65b0\u7684\u5e94\u7528\u60f3\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u9762\u5411\u5e7f\u6cdb\u7528\u6237\u7684\u4e92\u52a8\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u53c2\u8003\u3002"}}
{"id": "2508.00593", "pdf": "https://arxiv.org/pdf/2508.00593", "abs": "https://arxiv.org/abs/2508.00593", "authors": ["Shuyao Jiang", "Jiazhen Gu", "Wujie Zheng", "Yangfan Zhou", "Michael R. Lyu"], "title": "Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System", "categories": ["cs.SE"], "comment": "Accepted by the 19th ACM/IEEE International Symposium on Empirical\n  Software Engineering and Measurement (ESEM 2025)", "summary": "Background: It has long been suggested that user feedback, typically written\nin natural language by end-users, can help issue detection. However, for\nlarge-scale online service systems that receive a tremendous amount of\nfeedback, it remains a challenging task to identify severe issues from user\nfeedback. Aims: To develop a better feedback-based issue detection approach, it\nis crucial first to gain a comprehensive understanding of the characteristics\nof user feedback in real production systems. Method: In this paper, we conduct\nan empirical study on 50,378,766 user feedback items from six real-world\nservices in a one-billion-user online service system. We first study what users\nprovide in their feedback. We then examine whether certain features of feedback\nitems can be good indicators of severe issues. Finally, we investigate whether\nadopting machine learning techniques to analyze user feedback is reasonable.\nResults: Our results show that a large proportion of user feedback provides\nirrelevant information about system issues. As a result, it is crucial to\nfilter out issue-irrelevant information when processing user feedback.\nMoreover, we find severe issues that cannot be easily detected based solely on\nuser feedback characteristics. Finally, we find that the distributions of the\nfeedback topics in different time intervals are similar. This confirms that\ndesigning machine learning-based approaches is a viable direction for better\nanalyzing user feedback. Conclusions: We consider that our findings can serve\nas an empirical foundation for feedback-based issue detection in large-scale\nservice systems, which sheds light on the design and implementation of\npractical issue detection approaches.", "AI": {"tldr": "\u7814\u7a76\u7528\u6237\u53cd\u9988\u5728\u5927\u578b\u670d\u52a1\u7cfb\u7edf\u4e2d\u7528\u4e8e\u95ee\u9898\u68c0\u6d4b\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u9700\u8fc7\u6ee4\u65e0\u5173\u4fe1\u606f\u4e14\u673a\u5668\u5b66\u4e60\u662f\u53ef\u884c\u65b9\u5411\u3002", "motivation": "\u4e86\u89e3\u7528\u6237\u53cd\u9988\u7279\u6027\u4ee5\u6539\u8fdb\u95ee\u9898\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5bf9\u8d85\u8fc75000\u4e07\u6761\u7528\u6237\u53cd\u9988\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u53cd\u9988\u5185\u5bb9\u548c\u7279\u5f81\u3002", "result": "\u5927\u90e8\u5206\u53cd\u9988\u4e0e\u95ee\u9898\u65e0\u5173\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u662f\u5408\u7406\u7684\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u548c\u5b9e\u73b0\u5b9e\u7528\u7684\u53cd\u9988\u95ee\u9898\u68c0\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.00653", "pdf": "https://arxiv.org/pdf/2508.00653", "abs": "https://arxiv.org/abs/2508.00653", "authors": ["Luc\u00eda G\u00f3mez \u00c1lvarez", "Sebastian Rudolph"], "title": "Putting Perspective into OWL [sic]: Complexity-Neutral Standpoint Reasoning for Ontology Languages via Monodic S5 over Counting Two-Variable First-Order Logic (Extended Version with Appendix)", "categories": ["cs.LO"], "comment": null, "summary": "Standpoint extensions of knowledge representation formalisms have been\nrecently introduced as a means to incorporate multi-perspective modelling and\nreasoning through modal operators that attribute pieces of knowledge to\nspecific entities or agents. In these extensions, the integration between\nconceptual modelling and perspective annotations can vary in strength, with\nmonodic standpoint extensions offering a well-balanced approach. They allow for\nadvanced modelling features, such as the expression of rigid concepts, while\nmaintaining desirable reasoning complexity.\n  We consider the extension of C2--the counting two-variable fragment of\nfirst-order logic--by monodic standpoints. At the heart of our work is a\npolynomial-time translation of formulas in this extended formalism into\nstandard, standpoint-free C2, a result that relies on intricate model-theoretic\narguments. Thanks to this translation, the satisfiability problem remains at\nthe same complexity level: NExpTime-complete, as in plain C2. Since our\nformalism subsumes monodic S5 over C2, this result also marks a substantial\nadvancement in the study of first-order modal logics.\n  From a practical standpoint, this means that highly expressive description\nlogics such as SHOIQBs and SROIQBs--which underpin the widely adopted OWL 1 and\nOWL 2 ontology languages standardised by the W3C--can be extended with monodic\nstandpoints without increasing the standard reasoning complexity.\n  We further prove that NExpTime-hardness arises even in significantly less\nexpressive description logics, as long as they include both nominals and\nmonodic standpoints. Moreover, we show that if the monodicity restriction is\nrelaxed even slightly in the presence of inverse roles, functionality, and\nnominals, the satisfiability problem becomes undecidable.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86C2\u903b\u8f91\u7684\u5355\u8c03\u7acb\u573a\u6269\u5c55\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u65f6\u95f4\u7ffb\u8bd1\u5c06\u6269\u5c55\u540e\u7684\u5f62\u5f0f\u8f6c\u5316\u4e3a\u6807\u51c6C2\u903b\u8f91\uff0c\u4fdd\u6301\u4e86NExpTime\u5b8c\u5168\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u63cf\u8ff0\u903b\u8f91\u7684\u6269\u5c55\u9650\u5236\u3002", "motivation": "\u591a\u89c6\u89d2\u5efa\u6a21\u548c\u63a8\u7406\u5728\u77e5\u8bc6\u8868\u793a\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u5982\u4f55\u5728\u4fdd\u6301\u9ad8\u6548\u63a8\u7406\u7684\u540c\u65f6\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u901a\u8fc7\u591a\u9879\u5f0f\u65f6\u95f4\u7ffb\u8bd1\u5c06\u5355\u8c03\u7acb\u573a\u6269\u5c55\u7684C2\u903b\u8f91\u516c\u5f0f\u8f6c\u5316\u4e3a\u6807\u51c6C2\u903b\u8f91\uff0c\u5e76\u5229\u7528\u6a21\u578b\u8bba\u8bba\u8bc1\u5c55\u793a\u5176\u53ef\u884c\u6027\u3002", "result": "\u6269\u5c55\u540e\u7684\u903b\u8f91\u4fdd\u6301\u4e86NExpTime\u5b8c\u5168\u6027\uff0c\u4e14\u5728\u63cf\u8ff0\u903b\u8f91\u4e2d\u6269\u5c55\u5355\u8c03\u7acb\u573a\u4e0d\u4f1a\u589e\u52a0\u63a8\u7406\u590d\u6742\u5ea6\u3002", "conclusion": "\u5355\u8c03\u7acb\u573a\u5728\u4fdd\u6301\u9ad8\u6548\u63a8\u7406\u7684\u540c\u65f6\u4e3a\u77e5\u8bc6\u8868\u793a\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\uff0c\u4f46\u9650\u5236\u5176\u6269\u5c55\u6761\u4ef6\u4ee5\u907f\u514d\u4e0d\u53ef\u5224\u5b9a\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.00261", "pdf": "https://arxiv.org/pdf/2508.00261", "abs": "https://arxiv.org/abs/2508.00261", "authors": ["Saichao Liu", "Geng Sun", "Chuang Zhang", "Xuejie Liu", "Jiacheng Wang", "Changyuan Zhao", "Dusit Niyato"], "title": "Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning", "categories": ["cs.NI", "eess.SP"], "comment": "This paper has been accepted by IEEE GLOBECOM 2025", "summary": "Mobile edge computing (MEC) is a promising technique to improve the\ncomputational capacity of smart devices (SDs) in Internet of Things (IoT).\nHowever, the performance of MEC is restricted due to its fixed location and\nlimited service scope. Hence, we investigate an unmanned aerial vehicle\n(UAV)-assisted MEC system, where multiple UAVs are dispatched and each UAV can\nsimultaneously provide computing service for multiple SDs. To improve the\nperformance of system, we formulated a UAV-based trajectory control and\nresource allocation multi-objective optimization problem (TCRAMOP) to\nsimultaneously maximize the offloading number of UAVs and minimize total\noffloading delay and total energy consumption of UAVs by optimizing the flight\npaths of UAVs as well as the computing resource allocated to served SDs. Then,\nconsider that the solution of TCRAMOP requires continuous decision-making and\nthe system is dynamic, we propose an enhanced deep reinforcement learning (DRL)\nalgorithm, namely, distributed proximal policy optimization with imitation\nlearning (DPPOIL). This algorithm incorporates the generative adversarial\nimitation learning technique to improve the policy performance. Simulation\nresults demonstrate the effectiveness of our proposed DPPOIL and prove that the\nlearned strategy of DPPOIL is better compared with other baseline methods.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65e0\u4eba\u673a\u8f85\u52a9\u7684\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u65e0\u4eba\u673a\u98de\u884c\u8def\u5f84\u548c\u8d44\u6e90\u5206\u914d\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002\u63d0\u51fa\u4e86\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u7684\u589e\u5f3a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5DPPOIL\uff0c\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7531\u4e8e\u4f4d\u7f6e\u56fa\u5b9a\u548c\u670d\u52a1\u8303\u56f4\u6709\u9650\uff0c\u6027\u80fd\u53d7\u9650\u3002\u65e0\u4eba\u673a\u8f85\u52a9\u7684MEC\u7cfb\u7edf\u6709\u671b\u63d0\u5347\u667a\u80fd\u8bbe\u5907\u7684\u8ba1\u7b97\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898TCRAMOP\uff0c\u4f18\u5316\u65e0\u4eba\u673a\u98de\u884c\u8def\u5f84\u548c\u8d44\u6e90\u5206\u914d\uff1b\u8bbe\u8ba1DPPOIL\u7b97\u6cd5\uff0c\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u63d0\u5347\u7b56\u7565\u6027\u80fd\u3002", "result": "\u4eff\u771f\u663e\u793aDPPOIL\u7b97\u6cd5\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u65e0\u4eba\u673a\u8f85\u52a9MEC\u7cfb\u7edf\u53caDPPOIL\u7b97\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u670d\u52a1\u6027\u80fd\u3002"}}
{"id": "2508.00300", "pdf": "https://arxiv.org/pdf/2508.00300", "abs": "https://arxiv.org/abs/2508.00300", "authors": ["Shruthi Chari", "Oshani Seneviratne", "Prithwish Chakraborty", "Pablo Meyer", "Deborah L. McGuinness"], "title": "MetaExplainer: A Framework to Generate Multi-Type User-Centered Explanations for AI Systems", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Explanations are crucial for building trustworthy AI systems, but a gap often\nexists between the explanations provided by models and those needed by users.\nTo address this gap, we introduce MetaExplainer, a neuro-symbolic framework\ndesigned to generate user-centered explanations. Our approach employs a\nthree-stage process: first, we decompose user questions into machine-readable\nformats using state-of-the-art large language models (LLM); second, we delegate\nthe task of generating system recommendations to model explainer methods; and\nfinally, we synthesize natural language explanations that summarize the\nexplainer outputs. Throughout this process, we utilize an Explanation Ontology\nto guide the language models and explainer methods. By leveraging LLMs and a\nstructured approach to explanation generation, MetaExplainer aims to enhance\nthe interpretability and trustworthiness of AI systems across various\napplications, providing users with tailored, question-driven explanations that\nbetter meet their needs. Comprehensive evaluations of MetaExplainer demonstrate\na step towards evaluating and utilizing current state-of-the-art explanation\nframeworks. Our results show high performance across all stages, with a 59.06%\nF1-score in question reframing, 70% faithfulness in model explanations, and 67%\ncontext-utilization in natural language synthesis. User studies corroborate\nthese findings, highlighting the creativity and comprehensiveness of generated\nexplanations. Tested on the Diabetes (PIMA Indian) tabular dataset,\nMetaExplainer supports diverse explanation types, including Contrastive,\nCounterfactual, Rationale, Case-Based, and Data explanations. The framework's\nversatility and traceability from using ontology to guide LLMs suggest broad\napplicability beyond the tested scenarios, positioning MetaExplainer as a\npromising tool for enhancing AI explainability across various domains.", "AI": {"tldr": "MetaExplainer\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u6b65\u6d41\u7a0b\u751f\u6210\u7528\u6237\u4e2d\u5fc3\u7684AI\u89e3\u91ca\uff0c\u663e\u8457\u63d0\u5347\u89e3\u91ca\u7684\u4e2a\u6027\u5316\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u63d0\u4f9b\u7684\u89e3\u91ca\u4e0e\u7528\u6237\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u8d34\u8fd1\u7528\u6237\u7684\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u5206\u89e3\u7528\u6237\u95ee\u9898\u3001\u751f\u6210\u6a21\u578b\u63a8\u8350\u3001\u5408\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u5e76\u7ed3\u5408\u89e3\u91ca\u672c\u4f53\u6307\u5bfcLLMs\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u9ad8\u7ee9\u6548\uff08F1-score 59.06%\uff09\uff0c\u7528\u6237\u7814\u7a76\u8bc1\u5b9e\u89e3\u91ca\u7684\u521b\u9020\u6027\u548c\u5168\u9762\u6027\u3002", "conclusion": "MetaExplainer\u5728\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u5907\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.00630", "pdf": "https://arxiv.org/pdf/2508.00630", "abs": "https://arxiv.org/abs/2508.00630", "authors": ["Khaled Ahmed", "Jialing Song", "Boqi Chen", "Ou Wei", "Bingzhou Zheng"], "title": "MCeT: Behavioral Model Correctness Evaluation using Large Language Models", "categories": ["cs.SE"], "comment": "MODELS 2025", "summary": "Behavioral model diagrams, e.g., sequence diagrams, are an essential form of\ndocumentation that are typically designed by system engineers from requirements\ndocumentation, either fully manually or assisted by design tools. With the\ngrowing use of Large Language Models (LLM) as AI modeling assistants, more\nautomation will be involved in generating diagrams. This necessitates the\nadvancement of automatic model correctness evaluation tools. Such a tool can be\nused to evaluate both manually and AI automatically generated models; to\nprovide feedback to system engineers, and enable AI assistants to self-evaluate\nand self-enhance their generated models.\n  In this paper, we propose MCeT, the first fully automated tool to evaluate\nthe correctness of a behavioral model, sequence diagrams in particular, against\nits corresponding requirements text and produce a list of issues that the model\nhas. We utilize LLMs for the correctness evaluation tasks as they have shown\noutstanding natural language understanding ability. However, we show that\ndirectly asking an LLM to compare a diagram to requirements finds less than 35%\nof issues that experienced engineers can find. We propose to supplement the\ndirect check with a fine-grained, multi-perspective approach; we split the\ndiagram into atomic, non-divisible interactions, and split the requirements\ntext into atomic, self-contained items. We compare the diagram with atomic\nrequirements and each diagram-atom with the requirements. We also propose a\nself-consistency checking approach that combines perspectives to mitigate LLM\nhallucinated issues. Our combined approach improves upon the precision of the\ndirect approach from 0.58 to 0.81 in a dataset of real requirements. Moreover,\nthe approach finds 90% more issues that the experienced engineers found than\nthe direct approach, and reports an average of 6 new issues per diagram.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMCeT\u5de5\u5177\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u7ec6\u7c92\u5ea6\u65b9\u6cd5\u7ed3\u5408LLM\uff0c\u81ea\u52a8\u8bc4\u4f30\u884c\u4e3a\u6a21\u578b\uff08\u5982\u987a\u5e8f\u56fe\uff09\u7684\u6b63\u786e\u6027\uff0c\u76f8\u6bd4\u76f4\u63a5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u95ee\u9898\u53d1\u73b0\u7387\u548c\u7cbe\u5ea6\u3002", "motivation": "\u968f\u7740LLM\u5728\u6a21\u578b\u751f\u6210\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u5f00\u53d1\u81ea\u52a8\u8bc4\u4f30\u5de5\u5177\u4ee5\u63d0\u5347\u6a21\u578b\u6b63\u786e\u6027\uff0c\u5e76\u4e3a\u5de5\u7a0b\u5e08\u548cAI\u52a9\u624b\u63d0\u4f9b\u53cd\u9988\u3002", "method": "MCeT\u5c06\u56fe\u8868\u5206\u89e3\u4e3a\u539f\u5b50\u4ea4\u4e92\uff0c\u9700\u6c42\u6587\u672c\u5206\u89e3\u4e3a\u539f\u5b50\u9879\uff0c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\uff0c\u5e76\u7ed3\u5408\u81ea\u4e00\u81f4\u6027\u68c0\u67e5\u51cf\u5c11LLM\u5e7b\u89c9\u95ee\u9898\u3002", "result": "\u65b9\u6cd5\u5728\u771f\u5b9e\u9700\u6c42\u6570\u636e\u96c6\u4e0a\uff0c\u5c06\u7cbe\u5ea6\u4ece0.58\u63d0\u5347\u81f30.81\uff0c\u95ee\u9898\u53d1\u73b0\u7387\u63d0\u9ad890%\uff0c\u6bcf\u5f20\u56fe\u8868\u5e73\u5747\u591a\u53d1\u73b06\u4e2a\u65b0\u95ee\u9898\u3002", "conclusion": "\u591a\u89c6\u89d2\u7ec6\u7c92\u5ea6\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u76f4\u63a5LLM\u8bc4\u4f30\uff0c\u4e3a\u884c\u4e3a\u6a21\u578b\u6b63\u786e\u6027\u68c0\u67e5\u63d0\u4f9b\u4e86\u9ad8\u6548\u81ea\u52a8\u5316\u5de5\u5177\u3002"}}
{"id": "2508.00403", "pdf": "https://arxiv.org/pdf/2508.00403", "abs": "https://arxiv.org/abs/2508.00403", "authors": ["Rongsheng Zhang", "Ruichen Zhang", "Yang Lu", "Wei Chen", "Bo Ai", "Dusit Niyato"], "title": "Mamba for Wireless Communications and Networking: Principles and Opportunities", "categories": ["cs.NI"], "comment": null, "summary": "Mamba has emerged as a powerful model for efficiently addressing tasks\ninvolving temporal and spatial data. Regarding the escalating heterogeneity and\ndynamics in wireless networks, Mamba holds the potential to revolutionize\nwireless communication and networking designs by balancing the trade-off\nbetween computational efficiency and effectiveness. This article presents a\ncomprehensive overview of Mamba' applications in wireless systems.\nSpecifically, we first analyze the potentials of Mamba for wireless signal\nprocessing tasks from the perspectives of long-range dependency modeling and\nspatial feature extraction. Then we propose two application frameworks for\nMamba in wireless communications, i.e., replacement of traditional algorithms,\nand enabler of novel paradigms. Guided by the two frameworks, we conduct case\nstudies on intelligent resource allocation and joint source and channel\ndecoding to demonstrate Mamba's improvements in both feature enhancement and\ncomputational efficiency. Finally, we highlight critical challenges and outline\npotential research directions for Mamba in wireless communications and\nnetworking.", "AI": {"tldr": "Mamba\u6a21\u578b\u5728\u65f6\u7a7a\u6570\u636e\u5904\u7406\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u9ad8\u6548\u6027\uff0c\u6709\u671b\u901a\u8fc7\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u4e0e\u6548\u679c\uff0c\u9769\u65b0\u65e0\u7ebf\u901a\u4fe1\u548c\u7f51\u7edc\u8bbe\u8ba1\u3002\u6587\u7ae0\u7efc\u8ff0\u4e86Mamba\u5728\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u5e94\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5728\u7279\u5f81\u589e\u5f3a\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u6539\u8fdb\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u65e0\u7ebf\u7f51\u7edc\u7684\u5f02\u6784\u6027\u548c\u52a8\u6001\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u4e9f\u9700\u9ad8\u6548\u7684\u6a21\u578b\u6765\u4f18\u5316\u901a\u4fe1\u548c\u7f51\u7edc\u8bbe\u8ba1\u3002Mamba\u6a21\u578b\u56e0\u5176\u5728\u65f6\u7a7a\u6570\u636e\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u6027\uff0c\u88ab\u9009\u4e3a\u6f5c\u5728\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6587\u7ae0\u9996\u5148\u4ece\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\u548c\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u7684\u89d2\u5ea6\u5206\u6790Mamba\u5728\u65e0\u7ebf\u4fe1\u53f7\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u968f\u540e\u63d0\u51fa\u4e24\u79cd\u5e94\u7528\u6846\u67b6\uff08\u66ff\u4ee3\u4f20\u7edf\u7b97\u6cd5\u548c\u5b9e\u73b0\u65b0\u8303\u5f0f\uff09\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cMamba\u5728\u667a\u80fd\u8d44\u6e90\u5206\u914d\u548c\u8054\u5408\u6e90\u4e0e\u4fe1\u9053\u89e3\u7801\u7b49\u4efb\u52a1\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7279\u5f81\u589e\u5f3a\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "Mamba\u5728\u65e0\u7ebf\u901a\u4fe1\u548c\u7f51\u7edc\u8bbe\u8ba1\u4e2d\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u4e00\u4e9b\u5173\u952e\u6311\u6218\uff0c\u672a\u6765\u7814\u7a76\u53ef\u56f4\u7ed5\u8fd9\u4e9b\u6311\u6218\u5c55\u5f00\u3002"}}
{"id": "2508.00321", "pdf": "https://arxiv.org/pdf/2508.00321", "abs": "https://arxiv.org/abs/2508.00321", "authors": ["Shuning Zhang", "Ying Ma", "Xin Yi", "Hewu Li"], "title": "Evaluating the Efficacy of Large Language Models for Generating Fine-Grained Visual Privacy Policies in Homes", "categories": ["cs.HC"], "comment": null, "summary": "The proliferation of visual sensors in smart home environments, particularly\nthrough wearable devices like smart glasses, introduces profound privacy\nchallenges. Existing privacy controls are often static and coarse-grained,\nfailing to accommodate the dynamic and socially nuanced nature of home\nenvironments. This paper investigates the viability of using Large Language\nModels (LLMs) as the core of a dynamic and adaptive privacy policy engine. We\npropose a conceptual framework where visual data is classified using a\nmulti-dimensional schema that considers data sensitivity, spatial context, and\nsocial presence. An LLM then reasons over this contextual information to\nenforce fine-grained privacy rules, such as selective object obfuscation, in\nreal-time. Through a comparative evaluation of state-of-the-art Vision Language\nModels (including GPT-4o and the Qwen-VL series) in simulated home settings ,\nour findings show the feasibility of this approach. The LLM-based engine\nachieved a top machine-evaluated appropriateness score of 3.99 out of 5, and\nthe policies generated by the models received a top human-evaluated score of\n4.00 out of 5.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5728\u667a\u80fd\u5bb6\u5c45\u73af\u5883\u4e2d\u5229\u7528LLM\u5b9e\u73b0\u52a8\u6001\u9690\u79c1\u63a7\u5236\u7684\u53ef\u884c\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ef4\u5ea6\u5206\u7c7b\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u667a\u80fd\u5bb6\u5c45\u4e2d\u89c6\u89c9\u4f20\u611f\u5668\u7684\u666e\u53ca\u5e26\u6765\u4e86\u9690\u79c1\u6311\u6218\uff0c\u73b0\u6709\u9690\u79c1\u63a7\u5236\u65b9\u6cd5\u9759\u6001\u4e14\u7c97\u7cd9\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u548c\u793e\u4ea4\u590d\u6742\u7684\u73af\u5883\u3002", "method": "\u63d0\u51fa\u591a\u7ef4\u5ea6\u5206\u7c7b\u6846\u67b6\uff08\u6570\u636e\u654f\u611f\u6027\u3001\u7a7a\u95f4\u4e0a\u4e0b\u6587\u3001\u793e\u4ea4\u5b58\u5728\uff09\uff0c\u5229\u7528LLM\u5b9e\u65f6\u63a8\u7406\u5e76\u6267\u884c\u7ec6\u7c92\u5ea6\u9690\u79c1\u89c4\u5219\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u53ef\u884c\uff0cLLM\u5f15\u64ce\u7684\u673a\u5668\u8bc4\u4f30\u5f97\u5206\u4e3a3.99/5\uff0c\u4eba\u7c7b\u8bc4\u4f30\u5f97\u5206\u4e3a4.00/5\u3002", "conclusion": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u52a8\u6001\u9690\u79c1\u653f\u7b56\u5f15\u64ce\u6838\u5fc3\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u793e\u4f1a\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2508.00700", "pdf": "https://arxiv.org/pdf/2508.00700", "abs": "https://arxiv.org/abs/2508.00700", "authors": ["Alfred Santa Molison", "Marcia Moraes", "Glaucia Melo", "Fabio Santos", "Wesley K. G. Assuncao"], "title": "Is LLM-Generated Code More Maintainable \\& Reliable than Human-Written Code?", "categories": ["cs.SE"], "comment": "Accepted ESEM2025", "summary": "Background: The rise of Large Language Models (LLMs) in software development\nhas opened new possibilities for code generation. Despite the widespread use of\nthis technology, it remains unclear how well LLMs generate code solutions in\nterms of software quality and how they compare to human-written code. Aims:\nThis study compares the internal quality attributes of LLM-generated and\nhuman-written code. Method: Our empirical study integrates datasets of coding\ntasks, three LLM configurations (zero-shot, few-shot, and fine-tuning), and\nSonarQube to assess software quality. The dataset comprises Python code\nsolutions across three difficulty levels: introductory, interview, and\ncompetition. We analyzed key code quality metrics, including maintainability\nand reliability, and the estimated effort required to resolve code issues.\nResults: Our analysis shows that LLM-generated code has fewer bugs and requires\nless effort to fix them overall. Interestingly, fine-tuned models reduced the\nprevalence of high-severity issues, such as blocker and critical bugs, and\nshifted them to lower-severity categories, but decreased the model's\nperformance. In competition-level problems, the LLM solutions sometimes\nintroduce structural issues that are not present in human-written code.\nConclusion: Our findings provide valuable insights into the quality of\nLLM-generated code; however, the introduction of critical issues in more\ncomplex scenarios highlights the need for a systematic evaluation and\nvalidation of LLM solutions. Our work deepens the understanding of the\nstrengths and limitations of LLMs for code generation.", "AI": {"tldr": "\u6bd4\u8f83\u4e86LLM\u751f\u6210\u4ee3\u7801\u4e0e\u4eba\u7c7b\u7f16\u5199\u4ee3\u7801\u7684\u8d28\u91cf\uff0c\u53d1\u73b0LLM\u4ee3\u7801\u6574\u4f53\u7f3a\u9677\u66f4\u5c11\uff0c\u4f46\u9700\u6ce8\u610f\u590d\u6742\u573a\u666f\u4e0b\u7684\u4e25\u91cd\u95ee\u9898\u3002", "motivation": "\u7814\u7a76LLM\u751f\u6210\u4ee3\u7801\u4e0e\u4eba\u7c7b\u7f16\u5199\u4ee3\u7801\u5728\u8f6f\u4ef6\u8d28\u91cf\u4e0a\u7684\u5dee\u5f02\uff0c\u4ee5\u8bc4\u4f30LLM\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u7ed3\u5408\u7f16\u7801\u4efb\u52a1\u6570\u636e\u96c6\u3001\u4e09\u79cdLLM\u914d\u7f6e\uff08\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u5fae\u8c03\uff09\u53caSonarQube\u5de5\u5177\u5206\u6790Python\u4ee3\u7801\u8d28\u91cf\u6307\u6807\u3002", "result": "LLM\u4ee3\u7801\u7f3a\u9677\u8f83\u5c11\u4e14\u4fee\u590d\u6210\u672c\u4f4e\uff0c\u4f46\u5fae\u8c03\u540e\u6a21\u578b\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\uff0c\u4e14\u590d\u6742\u4efb\u52a1\u4e2d\u6613\u51fa\u73b0\u7ed3\u6784\u6027\u7f3a\u9677\u3002", "conclusion": "LLM\u751f\u6210\u4ee3\u7801\u6709\u4f18\u52bf\u4f46\u4e5f\u5b58\u5728\u95ee\u9898\uff0c\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u4ee5\u63d0\u9ad8\u590d\u6742\u573a\u666f\u4e0b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2508.00106", "pdf": "https://arxiv.org/pdf/2508.00106", "abs": "https://arxiv.org/abs/2508.00106", "authors": ["Ernest Bonnah", "Luan Viet Nguyen", "Khaza Anuarul Hoque"], "title": "Hyperproperty-Constrained Secure Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SY", "eess.SY"], "comment": "Accepted in IEEE/ACM MEMOCODE 2025", "summary": "Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a\ndomain-specific formal specification language known for its effectiveness in\ncompactly representing security, opacity, and concurrency properties for\nrobotics applications. This paper focuses on HyperTWTL-constrained secure\nreinforcement learning (SecRL). Although temporal logic-constrained safe\nreinforcement learning (SRL) is an evolving research problem with several\nexisting literature, there is a significant research gap in exploring\nsecurity-aware reinforcement learning (RL) using hyperproperties. Given the\ndynamics of an agent as a Markov Decision Process (MDP) and opacity/security\nconstraints formalized as HyperTWTL, we propose an approach for learning\nsecurity-aware optimal policies using dynamic Boltzmann softmax RL while\nsatisfying the HyperTWTL constraints. The effectiveness and scalability of our\nproposed approach are demonstrated using a pick-up and delivery robotic mission\ncase study. We also compare our results with two other baseline RL algorithms,\nshowing that our proposed method outperforms them.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHyperTWTL\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08SecRL\uff09\uff0c\u7528\u4e8e\u5728\u6ee1\u8db3HyperTWTL\u7ea6\u675f\u7684\u6761\u4ef6\u4e0b\u5b66\u4e60\u5b89\u5168\u611f\u77e5\u7684\u6700\u4f18\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u6269\u5c55\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u8bb8\u591a\u5173\u4e8e\u65f6\u5e8f\u903b\u8f91\u7ea6\u675f\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff08SRL\uff09\u7684\u7814\u7a76\uff0c\u4f46\u5728\u5229\u7528\u8d85\u5c5e\u6027\u63a2\u7d22\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u9762\u5b58\u5728\u663e\u8457\u7684\u7814\u7a76\u7a7a\u767d\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u52a8\u6001Boltzmann softmax\u5f3a\u5316\u5b66\u4e60\u548cHyperTWTL\u7ea6\u675f\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u6846\u67b6\u4e0b\u5b66\u4e60\u5b89\u5168\u611f\u77e5\u7684\u6700\u4f18\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u62fe\u53d6\u548c\u4ea4\u4ed8\u673a\u5668\u4eba\u4efb\u52a1\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6269\u5c55\u6027\uff0c\u5e76\u4e0e\u5176\u4ed6\u4e24\u79cd\u57fa\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u76f8\u6bd4\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u672c\u6587\u7684\u65b9\u6cd5\u4e3a\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u8d85\u5c5e\u6027\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.00583", "pdf": "https://arxiv.org/pdf/2508.00583", "abs": "https://arxiv.org/abs/2508.00583", "authors": ["Yunting Xu", "Jiacheng Wang", "Ruichen Zhang", "Dusit Niyato", "Deepu Rajan", "Liang Yu", "Haibo Zhou", "Abbas Jamalipour", "Xianbin Wang"], "title": "Enhancing Wireless Networks for IoT with Large Vision Models: Foundations and Applications", "categories": ["cs.NI"], "comment": "7 pages, 6 figures", "summary": "Large vision models (LVMs) have emerged as a foundational paradigm in visual\nintelligence, achieving state-of-the-art performance across diverse visual\ntasks. Recent advances in LVMs have facilitated their integration into Internet\nof Things (IoT) scenarios, offering superior generalization and adaptability\nfor vision-assisted network optimization. In this paper, we first investigate\nthe functionalities and core architectures of LVMs, highlighting their\ncapabilities across classification, segmentation, generation, and multimodal\nvisual processing. We then explore a variety of LVM applications in wireless\ncommunications, covering representative tasks across the physical layer,\nnetwork layer, and application layer. Furthermore, given the substantial model\nsize of LVMs and the challenges of model retraining in wireless domains, we\npropose a progressive fine-tuning framework that incrementally adapts\npretrained LVMs for joint optimization of multiple IoT tasks. A case study in\nlow-altitude economy networks (LAENets) demonstrates the effectiveness of the\nproposed framework over conventional CNNs in joint beamforming and positioning\ntasks for Internet of drones, underscoring a promising direction for\nintegrating LVMs into intelligent wireless systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u89c6\u89c9\u6a21\u578b\uff08LVMs\uff09\u5728\u89c6\u89c9\u667a\u80fd\u548c\u7269\u8054\u7f51\uff08IoT\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6e10\u8fdb\u5f0f\u5fae\u8c03\u6846\u67b6\u4ee5\u4f18\u5316\u591a\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u7814\u7a76LVMs\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5353\u8d8a\u8868\u73b0\u53ca\u5176\u5728\u65e0\u7ebf\u901a\u4fe1\u9886\u57df\u7684\u6f5c\u5728\u5e94\u7528\uff0c\u89e3\u51b3LVMs\u6a21\u578b\u5927\u548c\u91cd\u8bad\u7ec3\u96be\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6e10\u8fdb\u5f0f\u5fae\u8c03\u6846\u67b6\uff0c\u9010\u6b65\u8c03\u6574\u9884\u8bad\u7ec3\u7684LVMs\u4ee5\u9002\u5e94\u65e0\u7ebf\u9886\u57df\u7684\u591a\u4efb\u52a1\u8054\u5408\u4f18\u5316\u3002", "result": "\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u7f51\u7edc\uff08LAENets\uff09\u4e2d\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u8054\u5408\u6ce2\u675f\u6210\u5f62\u548c\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edfCNN\u3002", "conclusion": "LVMs\u4e3a\u667a\u80fd\u65e0\u7ebf\u7cfb\u7edf\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u5c24\u5176\u662f\u5728\u591a\u4efb\u52a1\u4f18\u5316\u7684IoT\u573a\u666f\u4e2d\u3002"}}
{"id": "2508.00328", "pdf": "https://arxiv.org/pdf/2508.00328", "abs": "https://arxiv.org/abs/2508.00328", "authors": ["Shuning Zhang", "Ying Ma", "Yongquan `Owen' Hu", "Ting Dang", "Hong Jia", "Xin Yi", "Hewu Li"], "title": "From Patient Burdens to User Agency: Designing for Real-Time Protection Support in Online Health Consultations", "categories": ["cs.HC"], "comment": null, "summary": "Online medical consultation platforms, while convenient, are undermined by\nsignificant privacy risks that erode user trust. We first conducted in-depth\nsemi-structured interviews with 12 users to understand their perceptions of\nsecurity and privacy landscapes on online medical consultation platforms, as\nwell as their practices, challenges and expectation. Our analysis reveals a\ncritical disconnect between users' desires for anonymity and control, and\nplatform realities that offload the responsibility of ``privacy labor''. To\nbridge this gap, we present SafeShare, an interaction technique that leverages\nlocalized LLM to redact consultations in real-time. SafeShare balances utility\nand privacy through selectively anonymize private information. A technical\nevaluation of SafeShare's core PII detection module on 3 dataset demonstrates\nhigh efficacy, achieving 89.64\\% accuracy with Qwen3-4B on IMCS21 dataset.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u7ebf\u533b\u7597\u54a8\u8be2\u5e73\u53f0\u7684\u9690\u79c1\u98ce\u9669\uff0c\u63d0\u51fa\u4e86SafeShare\u6280\u672f\u4ee5\u5e73\u8861\u9690\u79c1\u4e0e\u5b9e\u7528\u6027\uff0c\u901a\u8fc7\u672c\u5730\u5316LLM\u5b9e\u65f6\u533f\u540d\u5316\u4fe1\u606f\u3002", "motivation": "\u7528\u6237\u5bf9\u533f\u540d\u6027\u548c\u63a7\u5236\u6743\u7684\u9700\u6c42\u4e0e\u5e73\u53f0\u73b0\u5b9e\u7684\u9690\u79c1\u4fdd\u62a4\u63aa\u65bd\u5b58\u5728\u8131\u8282\uff0c\u4e9f\u9700\u89e3\u51b3\u4ee5\u91cd\u5efa\u4fe1\u4efb\u3002", "method": "\u901a\u8fc7\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u4e86\u89e3\u7528\u6237\u9700\u6c42\u548c\u6311\u6218\uff0c\u5f00\u53d1\u4e86SafeShare\u6280\u672f\uff0c\u91c7\u7528\u672c\u5730\u5316LLM\u5b9e\u65f6\u533f\u540d\u5316\u54a8\u8be2\u5185\u5bb9\u3002", "result": "SafeShare\u7684PII\u68c0\u6d4b\u6a21\u5757\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0cIMCS21\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe89.64%\u3002", "conclusion": "SafeShare\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u6709\u6548\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u4fe1\u606f\u5b9e\u7528\u6027\uff0c\u4e3a\u5728\u7ebf\u533b\u7597\u5e73\u53f0\u7684\u9690\u79c1\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00738", "pdf": "https://arxiv.org/pdf/2508.00738", "abs": "https://arxiv.org/abs/2508.00738", "authors": ["Bernhard Rumpe", "Max Stachon", "Sebastian St\u00fcber", "Valdes Voufo"], "title": "Tool-Assisted Conformance Checking to Reference Process Models", "categories": ["cs.SE", "cs.FL", "68N30", "D.2.4"], "comment": null, "summary": "Reference models convey best practices and standards. The reference\nframeworks necessitate conformance checks to ensure adherence to established\nguidelines and principles, which is crucial for maintaining quality and\nconsistency in various processes. This paper explores automated conformance\nchecks for concrete process models against reference models using causal\ndependency analysis of tasks and events. Existing notions of conformance\nchecking for process models focus on verifying process execution traces and\nlack the expressiveness and automation needed for semantic model comparison,\nleaving this question unresolved. We integrate our approach into a broader\nsemantic framework for defining reference model conformance. We outline an\nalgorithm for reference process model conformance checking, evaluate it through\na case study, and discuss its strengths and limitations. Our research provides\na tool-assisted solution enhancing accuracy and flexibility in process model\nconformance verification.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u4efb\u52a1\u548c\u4e8b\u4ef6\u7684\u56e0\u679c\u4f9d\u8d56\u5206\u6790\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u4ee5\u9a8c\u8bc1\u5177\u4f53\u6d41\u7a0b\u6a21\u578b\u662f\u5426\u53c2\u8003\u4e86\u53c2\u8003\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u8bed\u4e49\u6a21\u578b\u6bd4\u8f83\u7684\u8868\u8fbe\u80fd\u529b\u548c\u81ea\u52a8\u5316\u652f\u6301\uff0c\u5bfc\u81f4\u8fd9\u4e00\u95ee\u9898\u672a\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u57fa\u4e8e\u56e0\u679c\u4f9d\u8d56\u5206\u6790\uff0c\u5e76\u96c6\u6210\u5230\u4e00\u4e2a\u66f4\u5e7f\u6cdb\u7684\u8bed\u4e49\u6846\u67b6\u4e2d\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u8be5\u7b97\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u65b9\u9762\u7684\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u5de5\u5177\u8f85\u52a9\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u6d41\u7a0b\u6a21\u578b\u4e00\u81f4\u6027\u9a8c\u8bc1\u7684\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2508.00633", "pdf": "https://arxiv.org/pdf/2508.00633", "abs": "https://arxiv.org/abs/2508.00633", "authors": ["Chad Nester", "Niels Voorneveld"], "title": "Dynamics and Coherence for the Free Cornering with Protocol Choice", "categories": ["math.CT", "cs.LO"], "comment": "24 pages, in peer review", "summary": "We present a term rewriting system that models the dynamic aspects of the\nfree cornering with protocol choice of a monoidal category, which has been\nproposed as a categorical model of process interaction. This term rewriting\nsystem is confluent and terminating in an appropriate sense. We use this\nmachinery to prove a coherence theorem for the free cornering with protocol\nchoice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u672f\u8bed\u91cd\u5199\u7cfb\u7edf\uff0c\u7528\u4e8e\u6a21\u62df\u5177\u6709\u534f\u8bae\u9009\u62e9\u7684\u81ea\u7531\u89d2\u52a8\u7684\u52a8\u6001\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u8be5\u7cfb\u7edf\u8bc1\u660e\u4e86\u81ea\u7531\u89d2\u52a8\u4e0e\u534f\u8bae\u9009\u62e9\u7684\u76f8\u5e72\u6027\u5b9a\u7406\u3002", "motivation": "\u7814\u7a76\u81ea\u7531\u89d2\u52a8\u4e0e\u534f\u8bae\u9009\u62e9\u7684\u52a8\u6001\u7279\u6027\uff0c\u63d0\u4f9b\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684\u6a21\u578b\u6765\u7406\u89e3\u8fc7\u7a0b\u4ea4\u4e92\u7684\u8303\u7574\u884c\u4e3a\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u672f\u8bed\u91cd\u5199\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5728\u9002\u5f53\u7684\u610f\u4e49\u4e0a\u662f\u5408\u6d41\u548c\u7ec8\u6b62\u7684\u3002", "result": "\u8bc1\u660e\u4e86\u81ea\u7531\u89d2\u52a8\u4e0e\u534f\u8bae\u9009\u62e9\u7684\u76f8\u5e72\u6027\u5b9a\u7406\u3002", "conclusion": "\u672f\u8bed\u91cd\u5199\u7cfb\u7edf\u4e3a\u81ea\u7531\u89d2\u52a8\u4e0e\u534f\u8bae\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6a21\u578b\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u76f8\u5e72\u6027\u3002"}}
{"id": "2508.00616", "pdf": "https://arxiv.org/pdf/2508.00616", "abs": "https://arxiv.org/abs/2508.00616", "authors": ["Mingzhe Fan", "Geng Sun", "Hongyang Pan", "Jiacheng Wang", "Jiancheng An", "Hongyang Du", "Chau Yuen"], "title": "Joint Association and Phase Shifts Design for UAV-mounted Stacked Intelligent Metasurfaces-assisted Communications", "categories": ["cs.NI"], "comment": "This papar has been submitted to the IEEE Global Communications\n  Conference. arXiv admin note: substantial text overlap with arXiv:2506.23488", "summary": "Stacked intelligent metasurfaces (SIMs) have emerged as a promising\ntechnology for realizing wave-domain signal processing, while the fixed SIMs\nwill limit the communication performance of the system compared to the mobile\nSIMs. In this work, we consider a UAV-mounted SIMs (UAV-SIMs) assisted\ncommunication system, where UAVs as base stations (BSs) can cache the data\nprocessed by SIMs, and also as mobile vehicles flexibly deploy SIMs to enhance\nthe communication performance. To this end, we formulate a UAV-SIM-based joint\noptimization problem (USBJOP) to comprehensively consider the association\nbetween UAV-SIMs and users, the locations of UAV-SIMs, and the phase shifts of\nUAV-SIMs, aiming to maximize the network capacity. Due to the non-convexity and\nNP-hardness of USBJOP, we decompose it into three sub-optimization problems,\nwhich are the association between UAV-SIMs and users optimization problem\n(AUUOP), the UAV location optimization problem (ULOP), and the UAV-SIM phase\nshifts optimization problem (USPSOP). Then, these three sub-optimization\nproblems are solved by an alternating optimization (AO) strategy. Specifically,\nAUUOP and ULOP are transformed to a convex form and then solved by the CVX\ntool, while we employ a layer-by-layer iterative optimization method for\nUSPSOP. Simulation results verify the effectiveness of the proposed strategy\nunder different simulation setups.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u642d\u8f7d\u667a\u80fd\u8d85\u8868\u9762\uff08UAV-SIMs\uff09\u7684\u901a\u4fe1\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u4e0e\u7528\u6237\u5173\u8054\u3001\u65e0\u4eba\u673a\u4f4d\u7f6e\u548c\u8d85\u8868\u9762\u76f8\u4f4d\u504f\u79fb\uff0c\u4ee5\u6700\u5927\u5316\u7f51\u7edc\u5bb9\u91cf\u3002\u91c7\u7528\u4e86\u4ea4\u66ff\u4f18\u5316\u7b56\u7565\u89e3\u51b3\u975e\u51f8\u548cNP\u96be\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u56fa\u5b9a\u667a\u80fd\u8d85\u8868\u9762\uff08SIMs\uff09\u4f1a\u9650\u5236\u901a\u4fe1\u6027\u80fd\uff0c\u800c\u79fb\u52a8SIMs\u53ef\u4ee5\u7075\u6d3b\u90e8\u7f72\u4ee5\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e0\u4eba\u673a\u642d\u8f7dSIMs\uff08UAV-SIMs\uff09\u7684\u901a\u4fe1\u7cfb\u7edf\u6210\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u8054\u5408\u4f18\u5316\u95ee\u9898\uff08USBJOP\uff09\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u95ee\u9898\uff1a\u65e0\u4eba\u673a\u4e0e\u7528\u6237\u5173\u8054\u4f18\u5316\uff08AUUOP\uff09\u3001\u65e0\u4eba\u673a\u4f4d\u7f6e\u4f18\u5316\uff08ULOP\uff09\u548c\u8d85\u8868\u9762\u76f8\u4f4d\u504f\u79fb\u4f18\u5316\uff08USPSOP\uff09\u3002\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u7b56\u7565\uff0c\u524d\u4e24\u8005\u901a\u8fc7CVX\u5de5\u5177\u7bb1\u6c42\u89e3\uff0c\u540e\u8005\u901a\u8fc7\u9010\u5c42\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\u89e3\u51b3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u5747\u80fd\u6709\u6548\u63d0\u5347\u7f51\u7edc\u5bb9\u91cf\u3002", "conclusion": "\u65e0\u4eba\u673a\u642d\u8f7d\u667a\u80fd\u8d85\u8868\u9762\u7684\u901a\u4fe1\u7cfb\u7edf\u901a\u8fc7\u8054\u5408\u4f18\u5316\u80fd\u591f\u663e\u8457\u63d0\u5347\u901a\u4fe1\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2508.00439", "pdf": "https://arxiv.org/pdf/2508.00439", "abs": "https://arxiv.org/abs/2508.00439", "authors": ["Subin Park", "Jeonghyun Kim", "Jeanne Choi", "Joseph Seering", "Uichin Lee", "Sung-Ju Lee"], "title": "HateBuffer: Safeguarding Content Moderators' Mental Well-Being through Hate Speech Content Modification", "categories": ["cs.HC"], "comment": "Accepted by ACM CSCW 2025; 39 pages (including 6 pages of Appendix)", "summary": "Hate speech remains a persistent and unresolved challenge in online\nplatforms. Content moderators, working on the front lines to review\nuser-generated content and shield viewers from hate speech, often find\nthemselves unprotected from the mental burden as they continuously engage with\noffensive language. To safeguard moderators' mental well-being, we designed\nHateBuffer, which anonymizes targets of hate speech, paraphrases offensive\nexpressions into less offensive forms, and shows the original expressions when\nmoderators opt to see them. Our user study with 80 participants consisted of a\nsimulated hate speech moderation task set on a fictional news platform,\nfollowed by semi-structured interviews. Although participants rated the hate\nseverity of comments lower while using HateBuffer, contrary to our\nexpectations, they did not experience improved emotion or reduced fatigue\ncompared with the control group. In interviews, however, participants described\nHateBuffer as an effective buffer against emotional contagion and the\nnormalization of biased opinions in hate speech. Notably, HateBuffer did not\ncompromise moderation accuracy and even contributed to a slight increase in\nrecall. We explore possible explanations for the discrepancy between the\nperceived benefits of HateBuffer and its measured impact on mental well-being.\nWe also underscore the promise of text-based content modification techniques as\ntools for a healthier content moderation environment.", "AI": {"tldr": "HateBuffer\u662f\u4e00\u6b3e\u65e8\u5728\u4fdd\u62a4\u5185\u5bb9\u5ba1\u6838\u5458\u5fc3\u7406\u5065\u5eb7\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u533f\u540d\u5316\u4ec7\u6068\u8a00\u8bba\u76ee\u6807\u548c\u6539\u5199\u653b\u51fb\u6027\u8868\u8fbe\uff0c\u4f46\u5176\u5b9e\u9645\u6548\u679c\u4e0e\u9884\u671f\u4e0d\u7b26\u3002", "motivation": "\u5728\u7ebf\u5e73\u53f0\u4e0a\u7684\u4ec7\u6068\u8a00\u8bba\u5bf9\u5185\u5bb9\u5ba1\u6838\u5458\u7684\u5fc3\u7406\u5065\u5eb7\u9020\u6210\u4e86\u4e25\u91cd\u8d1f\u62c5\u3002", "method": "\u8bbe\u8ba1\u4e86HateBuffer\u5de5\u5177\uff0c\u901a\u8fc7\u533f\u540d\u5316\u76ee\u6807\u3001\u6539\u5199\u653b\u51fb\u6027\u8868\u8fbe\u7b49\u65b9\u5f0f\u51cf\u8f7b\u5ba1\u6838\u5458\u7684\u5fc3\u7406\u8d1f\u62c5\u3002", "result": "\u4f7f\u7528HateBuffer\u540e\uff0c\u53c2\u4e0e\u8005\u5bf9\u4ec7\u6068\u8a00\u8bba\u4e25\u91cd\u6027\u7684\u8bc4\u5206\u964d\u4f4e\uff0c\u4f46\u5728\u60c5\u7eea\u548c\u75b2\u52b3\u65b9\u9762\u672a\u89c1\u660e\u663e\u6539\u5584\uff1b\u4e0d\u8fc7\uff0cHateBuffer\u63d0\u9ad8\u4e86\u5ba1\u6838\u51c6\u786e\u6027\u5e76\u7565\u5fae\u63d0\u5347\u4e86\u53ec\u56de\u7387\u3002", "conclusion": "HateBuffer\u867d\u672a\u76f4\u63a5\u6539\u5584\u5fc3\u7406\u5065\u5eb7\uff0c\u4f46\u663e\u793a\u51fa\u6587\u672c\u5185\u5bb9\u4fee\u6539\u6280\u672f\u5728\u5065\u5eb7\u5185\u5bb9\u5ba1\u6838\u73af\u5883\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.00749", "pdf": "https://arxiv.org/pdf/2508.00749", "abs": "https://arxiv.org/abs/2508.00749", "authors": ["Johanna Grahl", "Bernhard Rumpe", "Max Stachon", "Sebastian St\u00fcber"], "title": "Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures", "categories": ["cs.SE", "cs.FL", "cs.SC", "68N30", "D.2.4"], "comment": null, "summary": "In the context of model-driven development, ensuring the correctness and\nconsistency of evolving models is paramount. This paper investigates the\napplication of Dynamic Symbolic Execution (DSE) for semantic difference\nanalysis of component-and-connector architectures, specifically utilizing\nMontiArc models. We have enhanced the existing MontiArc-to-Java generator to\ngather both symbolic and concrete execution data at runtime, encompassing\ntransition conditions, visited states, and internal variables of automata. This\ndata facilitates the identification of significant execution traces that\nprovide critical insights into system behavior. We evaluate various execution\nstrategies based on the criteria of runtime efficiency, minimality, and\ncompleteness, establishing a framework for assessing the applicability of DSE\nin semantic difference analysis. Our findings indicate that while DSE shows\npromise for analyzing component and connector architectures, scalability\nremains a primary limitation, suggesting further research is needed to enhance\nits practical utility in larger systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528\u52a8\u6001\u7b26\u53f7\u6267\u884c\uff08DSE\uff09\u8fdb\u884c\u7ec4\u4ef6-\u8fde\u63a5\u5668\u67b6\u6784\u7684\u8bed\u4e49\u5dee\u5f02\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8MontiArc\u6a21\u578b\u3002\u901a\u8fc7\u589e\u5f3aMontiArc\u5230Java\u7684\u751f\u6210\u5668\u6536\u96c6\u8fd0\u884c\u65f6\u6570\u636e\uff0c\u8bc4\u4f30\u4e86DSE\u5728\u8bed\u4e49\u5dee\u5f02\u5206\u6790\u4e2d\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u5728\u6a21\u578b\u9a71\u52a8\u5f00\u53d1\u4e2d\uff0c\u786e\u4fdd\u6f14\u5316\u7684\u6a21\u578b\u7684\u6b63\u786e\u6027\u548c\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u5206\u6790\u8bed\u4e49\u5dee\u5f02\u3002", "method": "\u589e\u5f3aMontiArc-to-Java\u751f\u6210\u5668\u4ee5\u6536\u96c6\u8fd0\u884c\u65f6\u7b26\u53f7\u548c\u5177\u4f53\u6267\u884c\u6570\u636e\uff0c\u5305\u62ec\u8fc7\u6e21\u6761\u4ef6\u3001\u8bbf\u95ee\u72b6\u6001\u548c\u81ea\u52a8\u673a\u5185\u90e8\u53d8\u91cf\uff0c\u4ece\u800c\u8bc6\u522b\u5173\u952e\u6267\u884c\u8f68\u8ff9\u3002", "result": "\u7814\u7a76\u53d1\u73b0DSE\u5728\u7ec4\u4ef6-\u8fde\u63a5\u5668\u67b6\u6784\u5206\u6790\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4e3b\u8981\u5c40\u9650\u662f\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u5347\u5176\u5728\u5927\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "DSE\u5728\u8bed\u4e49\u5dee\u5f02\u5206\u6790\u4e2d\u6709\u524d\u666f\uff0c\u4f46\u5728\u5904\u7406\u5927\u89c4\u6a21\u7cfb\u7edf\u65f6\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u514b\u670d\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2508.00646", "pdf": "https://arxiv.org/pdf/2508.00646", "abs": "https://arxiv.org/abs/2508.00646", "authors": ["Dennis Zyska", "Ilia Kuznetsov", "Florian M\u00fcller", "Iryna Gurevych"], "title": "Pull Requests From The Classroom: Co-Developing Curriculum And Code", "categories": ["cs.HC"], "comment": null, "summary": "Educational technologies often misalign with instructors' pedagogical goals,\nforcing adaptations that compromise teaching efficacy. In this paper, we\npresent a case study on the co-development of curriculum and technology in the\ncontext of a university course on scientific writing. Specifically, we examine\nhow a custom-built peer feedback system was iteratively developed alongside the\ncourse to support annotation, feedback exchange, and revision. Results show\nthat while co-development fostered stronger alignment between software features\nand course goals, it also exposed usability limitations and\ninfrastructure-related frustrations, emphasizing the need for closer\ncoordination between teaching and technical teams.", "AI": {"tldr": "\u6559\u80b2\u6280\u672f\u4e0e\u6559\u5e08\u6559\u5b66\u76ee\u6807\u5e38\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u6559\u5b66\u6548\u679c\u53d7\u635f\u3002\u672c\u6587\u901a\u8fc7\u5927\u5b66\u79d1\u5b66\u5199\u4f5c\u8bfe\u7a0b\u7684\u6848\u4f8b\uff0c\u63a2\u8ba8\u4e86\u8bfe\u7a0b\u4e0e\u6280\u672f\u7684\u5171\u540c\u5f00\u53d1\u3002\u7814\u7a76\u53d1\u73b0\u5171\u540c\u5f00\u53d1\u867d\u80fd\u63d0\u9ad8\u8f6f\u4ef6\u529f\u80fd\u4e0e\u8bfe\u7a0b\u76ee\u6807\u7684\u5951\u5408\u5ea6\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u53ef\u7528\u6027\u548c\u57fa\u7840\u8bbe\u65bd\u95ee\u9898\uff0c\u5f3a\u8c03\u6559\u5b66\u4e0e\u6280\u672f\u56e2\u961f\u9700\u66f4\u7d27\u5bc6\u534f\u4f5c\u3002", "motivation": "\u89e3\u51b3\u6559\u80b2\u6280\u672f\u4e0e\u6559\u5e08\u6559\u5b66\u76ee\u6807\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u6559\u5b66\u6548\u679c\u3002", "method": "\u901a\u8fc7\u5927\u5b66\u79d1\u5b66\u5199\u4f5c\u8bfe\u7a0b\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5171\u540c\u5f00\u53d1\u5b9a\u5236\u5316\u7684\u540c\u884c\u53cd\u9988\u7cfb\u7edf\uff0c\u652f\u6301\u6ce8\u91ca\u3001\u53cd\u9988\u4ea4\u6d41\u548c\u4fee\u8ba2\u3002", "result": "\u5171\u540c\u5f00\u53d1\u589e\u5f3a\u4e86\u8f6f\u4ef6\u529f\u80fd\u4e0e\u8bfe\u7a0b\u76ee\u6807\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u4e5f\u66b4\u9732\u4e86\u53ef\u7528\u6027\u548c\u57fa\u7840\u8bbe\u65bd\u7684\u5c40\u9650\u3002", "conclusion": "\u6559\u5b66\u4e0e\u6280\u672f\u56e2\u961f\u9700\u66f4\u7d27\u5bc6\u534f\u4f5c\uff0c\u4ee5\u4f18\u5316\u6559\u80b2\u6280\u672f\u7684\u5f00\u53d1\u4e0e\u4f7f\u7528\u3002"}}
{"id": "2508.00688", "pdf": "https://arxiv.org/pdf/2508.00688", "abs": "https://arxiv.org/abs/2508.00688", "authors": ["Ruiyang Huang", "Haocheng Wang", "Yixuan Shen", "Ning Gao", "Qiang Ni", "Shi Jin", "Yifan Wu"], "title": "Criticality-Based Dynamic Topology Optimization for Enhancing Aerial-Marine Swarm Resilience", "categories": ["cs.NI", "eess.SP"], "comment": "Submit to INFOCOM 2026", "summary": "Heterogeneous marine-aerial swarm networks encounter substantial difficulties\ndue to targeted communication disruptions and structural weaknesses in\nadversarial environments. This paper proposes a two-step framework to\nstrengthen the network's resilience. Specifically, our framework combines the\nnode prioritization based on criticality with multi-objective topology\noptimization. First, we design a three-layer architecture to represent\nstructural, communication, and task dependencies of the swarm networks. Then,\nwe introduce the SurBi-Ranking method, which utilizes graph convolutional\nnetworks, to dynamically evaluate and rank the criticality of nodes and edges\nin real time. Next, we apply the NSGA-III algorithm to optimize the network\ntopology, aiming to balance communication efficiency, global connectivity, and\nmission success rate. Experiments demonstrate that compared to traditional\nmethods like K-Shell, our SurBi-Ranking method identifies critical nodes and\nedges with greater accuracy, as deliberate attacks on these components cause\nmore significant connectivity degradation. Furthermore, our optimization\napproach, when prioritizing SurBi-Ranked critical components under attack,\nreduces the natural connectivity degradation by around 30%, achieves higher\nmission success rates, and incurs lower communication reconfiguration costs,\nensuring sustained connectivity and mission effectiveness across multi-phase\noperations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u6b65\u6846\u67b6\uff0c\u7ed3\u5408\u8282\u70b9\u5173\u952e\u6027\u6392\u5e8f\u548c\u591a\u76ee\u6807\u62d3\u6251\u4f18\u5316\uff0c\u4ee5\u589e\u5f3a\u5f02\u6784\u6d77\u6d0b-\u7a7a\u4e2d\u7fa4\u7f51\u7edc\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u97e7\u6027\u3002", "motivation": "\u5f02\u6784\u6d77\u6d0b-\u7a7a\u4e2d\u7fa4\u7f51\u7edc\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u9762\u4e34\u901a\u4fe1\u4e2d\u65ad\u548c\u7ed3\u6784\u8106\u5f31\u7684\u6311\u6218\uff0c\u9700\u8981\u63d0\u5347\u7f51\u7edc\u97e7\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u67b6\u6784\u8868\u793a\u7fa4\u7f51\u7edc\u7ed3\u6784\u3001\u901a\u4fe1\u548c\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\uff0c\u8bbe\u8ba1SurBi-Ranking\u65b9\u6cd5\u5b9e\u65f6\u8bc4\u4f30\u8282\u70b9\u548c\u8fb9\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4f7f\u7528NSGA-III\u7b97\u6cd5\u4f18\u5316\u62d3\u6251\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSurBi-Ranking\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u51c6\u786e\u5b9a\u4f4d\u5173\u952e\u8282\u70b9\u548c\u8fb9\uff0c\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u81ea\u7136\u8fde\u63a5\u9000\u531630%\uff0c\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "\u6846\u67b6\u80fd\u6709\u6548\u7ef4\u6301\u591a\u9636\u6bb5\u64cd\u4f5c\u7684\u8fde\u63a5\u6027\u548c\u4efb\u52a1\u6548\u679c\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.00652", "pdf": "https://arxiv.org/pdf/2508.00652", "abs": "https://arxiv.org/abs/2508.00652", "authors": ["Shuning Zhang", "Han Chen", "Yabo Wang", "Yiqun Xu", "Jiaqi Bai", "Yuanyuan Wu", "Shixuan Li", "Xin Yi", "Chunhui Wang", "Hewu Li"], "title": "The Manipulative Power of Voice Characteristics: Investigating Deceptive Patterns in Mandarin Chinese Female Synthetic Speech", "categories": ["cs.HC"], "comment": null, "summary": "Pervasive voice interaction enables deceptive patterns through subtle voice\ncharacteristics, yet empirical investigation into this manipulation lags\nbehind, especially within major non-English language contexts. Addressing this\ngap, our study presents the first systematic investigation into voice\ncharacteristic-based dark patterns employing female synthetic voices in\nMandarin Chinese. This focus is crucial given the prevalence of female personas\nin commercial assistants and the prosodic significance in the Chinese language.\nGuided by the conceptual framework identifying key influencing factors, we\nsystematically evaluate effectiveness variations by manipulating voice\ncharacteristics (five characteristics, three intensities) across different\nscenarios (shopping vs. question-answering) with different commercial aims. A\npreliminary study (N=24) validated the experimental materials and the main\nstudy (N=36) revealed significant behavioral manipulation (up to +2027.6%).\nCrucially, the analysis showed that effectiveness varied significantly with\nvoice characteristics and scenario, mediated by user perception (of tone,\nintonation, timbre) and user demographics (individual preferences, though\nlimited demographic impact). These interconnected findings offer evidence-based\ninsights for ethical design.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u63a2\u8ba8\u4e86\u4e2d\u6587\u666e\u901a\u8bdd\u4e2d\u5973\u6027\u5408\u6210\u58f0\u97f3\u7684\u8bed\u97f3\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u7528\u6237\u884c\u4e3a\uff0c\u63ed\u793a\u4e86\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u8bed\u97f3\u7279\u5f81\u5bf9\u7528\u6237\u51b3\u7b56\u7684\u663e\u8457\u5f71\u54cd\uff0c\u4e3a\u9053\u5fb7\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u8bed\u97f3\u4ea4\u4e92\u4e2d\u7684\u6b3a\u9a97\u6a21\u5f0f\uff08\u5c24\u5176\u662f\u975e\u82f1\u8bed\u8bed\u5883\uff09\u5173\u6ce8\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u4e2d\u6587\u80cc\u666f\u4e0b\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u8ba8\u8bed\u97f3\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u7528\u6237\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u64cd\u7eb5\u4e94\u79cd\u8bed\u97f3\u7279\u5f81\uff08\u4e09\u79cd\u5f3a\u5ea6\uff09\u548c\u4e24\u79cd\u573a\u666f\uff08\u8d2d\u7269\u4e0e\u95ee\u7b54\uff09\uff0c\u7ed3\u5408\u521d\u6b65\u7814\u7a76\uff08N=24\uff09\u548c\u4e3b\u7814\u7a76\uff08N=36\uff09\uff0c\u8bc4\u4f30\u8bed\u97f3\u7279\u5f81\u5bf9\u7528\u6237\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "result": "\u4e3b\u7814\u7a76\u663e\u793a\u8bed\u97f3\u7279\u5f81\u663e\u8457\u5f71\u54cd\u7528\u6237\u884c\u4e3a\uff08\u6700\u9ad8\u8fbe+2027.6%\uff09\uff0c\u6548\u679c\u56e0\u7279\u5f81\u3001\u573a\u666f\u53ca\u7528\u6237\u611f\u77e5\uff08\u5982\u97f3\u8c03\u3001\u97f3\u8272\uff09\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u5dee\u5f02\u800c\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8bed\u97f3\u7279\u5f81\u5728\u7528\u6237\u884c\u4e3a\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u8bed\u97f3\u4ea4\u4e92\u7684\u9053\u5fb7\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2508.00715", "pdf": "https://arxiv.org/pdf/2508.00715", "abs": "https://arxiv.org/abs/2508.00715", "authors": ["Olga Kondrateva", "Grace Li Zhang", "Julian Zobel", "Bj\u00f6rn Scheuermann", "Stefan Dietzel"], "title": "Deep Joint Source-Channel Coding for Small Satellite Applications", "categories": ["cs.NI"], "comment": null, "summary": "Small satellites used for Earth observation generate vast amounts of\nhigh-dimensional data, but their operation in low Earth orbit creates a\nsignificant communication bottleneck due to limited contact times and harsh,\nvarying channel conditions. While deep joint source-channel coding (DJSCC) has\nemerged as a promising technique, its practical application to the complex\nsatellite environment remains an open question. This paper presents a\ncomprehensive DJSCC framework tailored for satellite communications. We first\nestablish a basic system, DJSCC-SAT, and integrate a realistic, multi-state\nstatistical channel model to guide its training and evaluation. To overcome the\nimpracticality of using separate models for every channel condition, we then\nintroduce an adaptable architecture, ADJSCC-SAT, which leverages attention\nmodules to allow a single neural network to adjust to a wide range of channel\nstates with minimal overhead. Through extensive evaluation on Sentinel-2\nmulti-spectral data, we demonstrate that our adaptable approach achieves\nperformance comparable to using multiple specialized networks while\nsignificantly reducing model storage requirements. Furthermore, the adaptable\nmodel shows enhanced robustness to channel estimation errors, outperforming the\nnon-adaptable baseline. The proposed framework is a practical and efficient\nstep toward deploying robust, adaptive DJSCC systems for real-world satellite\nmissions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u536b\u661f\u901a\u4fe1\u7684\u81ea\u9002\u5e94\u6df1\u5ea6\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\uff08DJSCC\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u6a21\u5757\u5b9e\u73b0\u5355\u4e00\u7f51\u7edc\u9002\u5e94\u591a\u79cd\u4fe1\u9053\u72b6\u6001\uff0c\u663e\u8457\u51cf\u5c11\u6a21\u578b\u5b58\u50a8\u9700\u6c42\u5e76\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u5c0f\u536b\u661f\u5728\u5730\u7403\u89c2\u6d4b\u4e2d\u4ea7\u751f\u7684\u9ad8\u7ef4\u6570\u636e\u4f20\u8f93\u74f6\u9888\u95ee\u9898\uff0c\u9002\u5e94\u590d\u6742\u4e14\u591a\u53d8\u7684\u536b\u661f\u901a\u4fe1\u73af\u5883\u3002", "method": "\u63d0\u51faDJSCC-SAT\u57fa\u672c\u7cfb\u7edf\u548cADJSCC-SAT\u81ea\u9002\u5e94\u67b6\u6784\uff0c\u5229\u7528\u591a\u72b6\u6001\u7edf\u8ba1\u4fe1\u9053\u6a21\u578b\u548c\u6ce8\u610f\u529b\u6a21\u5757\u5b9e\u73b0\u7f51\u7edc\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728Sentinel-2\u591a\u5149\u8c31\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u81ea\u9002\u5e94\u65b9\u6cd5\u6027\u80fd\u63a5\u8fd1\u591a\u4e13\u7528\u7f51\u7edc\uff0c\u540c\u65f6\u51cf\u5c11\u5b58\u50a8\u9700\u6c42\u5e76\u589e\u5f3a\u5bf9\u4fe1\u9053\u8bef\u5dee\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b9e\u9645\u536b\u661f\u4efb\u52a1\u4e2d\u90e8\u7f72\u9c81\u68d2\u6027\u81ea\u9002\u5e94DJSCC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00723", "pdf": "https://arxiv.org/pdf/2508.00723", "abs": "https://arxiv.org/abs/2508.00723", "authors": ["Rebecca Yu", "Valerie Chen", "Ameet Talwalkar", "Hoda Heidari"], "title": "Why Do Decision Makers (Not) Use AI? A Cross-Domain Analysis of Factors Impacting AI Adoption", "categories": ["cs.HC"], "comment": "To be published in Proceedings of the Eighth AAAI/ACM Conference on\n  AI, Ethics, and Society (AIES-25). 10 pages, 4 figures, 1 table", "summary": "Growing excitement around deploying AI across various domains calls for a\ncareful assessment of how human decision-makers interact with AI-powered\nsystems. In particular, it is essential to understand when decision-makers\nvoluntarily choose to consult AI tools, which we term decision-maker adoption.\nWe interviewed experts across four domains -- medicine, law, journalism, and\nthe public sector -- to explore current AI use cases and perceptions of\nadoption. From these interviews, we identify key factors that shape\ndecision-maker adoption of AI tools: the decision-maker's background,\nperceptions of the AI, consequences for the decision-maker, and perceived\nimplications for other stakeholders. We translate these factors into an AI\nadoption sheet to analyze how decision-makers approach adoption choices through\ncomparative, cross-domain case studies, highlighting how our factors help\nexplain inter-domain differences in adoption. Our findings offer practical\nguidance for supporting the responsible and context-aware deployment of AI by\nbetter accounting for the decision-maker's perspective.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u51b3\u7b56\u8005\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u81ea\u613f\u91c7\u7528AI\u5de5\u5177\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86AI\u91c7\u7528\u8868\u4ee5\u5206\u6790\u8de8\u9886\u57df\u5dee\u5f02\u3002", "motivation": "\u8bc4\u4f30AI\u5de5\u5177\u5982\u4f55\u88ab\u51b3\u7b56\u8005\u81ea\u613f\u91c7\u7528\uff0c\u4ee5\u652f\u6301AI\u7684\u8d1f\u8d23\u4efb\u90e8\u7f72\u3002", "method": "\u91c7\u8bbf\u4e86\u533b\u5b66\u3001\u6cd5\u5f8b\u3001\u65b0\u95fb\u548c\u516c\u5171\u90e8\u95e8\u7684\u4e13\u5bb6\uff0c\u5206\u6790AI\u4f7f\u7528\u6848\u4f8b\u548c\u91c7\u7528\u611f\u77e5\u3002", "result": "\u786e\u5b9a\u4e86\u5f71\u54cdAI\u91c7\u7528\u7684\u56db\u4e2a\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3aAI\u91c7\u7528\u8868\uff0c\u7528\u4e8e\u8de8\u9886\u57df\u6bd4\u8f83\u5206\u6790\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6307\u5357\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u4ece\u51b3\u7b56\u8005\u89d2\u5ea6\u90e8\u7f72AI\u3002"}}
{"id": "2508.00500", "pdf": "https://arxiv.org/pdf/2508.00500", "abs": "https://arxiv.org/abs/2508.00500", "authors": ["Haoyu Wang", "Chris M. Poskitt", "Jun Sun", "Jiali Wei"], "title": "Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Large Language Model (LLM) agents exhibit powerful autonomous capabilities\nacross domains such as robotics, virtual assistants, and web automation.\nHowever, their stochastic behavior introduces significant safety risks that are\ndifficult to anticipate. Existing rule-based enforcement systems, such as\nAgentSpec, focus on developing reactive safety rules, which typically respond\nonly when unsafe behavior is imminent or has already occurred. These systems\nlack foresight and struggle with long-horizon dependencies and distribution\nshifts. To address these limitations, we propose Pro2Guard, a proactive runtime\nenforcement framework grounded in probabilistic reachability analysis.\nPro2Guard abstracts agent behaviors into symbolic states and learns a\nDiscrete-Time Markov Chain (DTMC) from execution traces. At runtime, it\nanticipates future risks by estimating the probability of reaching unsafe\nstates, triggering interventions before violations occur when the predicted\nrisk exceeds a user-defined threshold. By incorporating semantic validity\nchecks and leveraging PAC bounds, Pro2Guard ensures statistical reliability\nwhile approximating the underlying ground-truth model. We evaluate Pro2Guard\nextensively across two safety-critical domains: embodied household agents and\nautonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early\non up to 93.6% of unsafe tasks using low thresholds, while configurable modes\n(e.g., reflect) allow balancing safety with task success, maintaining up to\n80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%\nprediction of traffic law violations and collisions, anticipating risks up to\n38.66 seconds ahead.", "AI": {"tldr": "LLM\u4ee3\u7406\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u81ea\u4e3b\u80fd\u529b\uff0c\u4f46\u5176\u968f\u673a\u6027\u884c\u4e3a\u5e26\u6765\u4e86\u96be\u4ee5\u9884\u6d4b\u7684\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u89c4\u5219\u7cfb\u7edf\u53cd\u5e94\u6ede\u540e\uff0c\u63d0\u51faPro2Guard\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u7387\u53ef\u8fbe\u6027\u5206\u6790\u9884\u6d4b\u98ce\u9669\uff0c\u63d0\u524d\u5e72\u9884\uff0c\u9a8c\u8bc1\u6548\u679c\u663e\u8457\u3002", "motivation": "LLM\u4ee3\u7406\u7684\u968f\u673a\u884c\u4e3a\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u73b0\u6709\u89c4\u5219\u7cfb\u7edf\u7f3a\u4e4f\u524d\u77bb\u6027\uff0c\u96be\u4ee5\u5904\u7406\u957f\u671f\u4f9d\u8d56\u548c\u5206\u5e03\u504f\u79fb\uff0c\u9700\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u4e3b\u52a8\u5b89\u5168\u6846\u67b6\u3002", "method": "Pro2Guard\u5c06\u4ee3\u7406\u884c\u4e3a\u62bd\u8c61\u4e3a\u7b26\u53f7\u72b6\u6001\uff0c\u4ece\u6267\u884c\u8f68\u8ff9\u5b66\u4e60DTMC\u6a21\u578b\uff0c\u8fd0\u884c\u65f6\u901a\u8fc7\u6982\u7387\u9884\u6d4b\u4e0d\u5b89\u5168\u72b6\u6001\uff0c\u7ed3\u5408\u8bed\u4e49\u68c0\u67e5\u548cPAC\u4fdd\u8bc1\uff0c\u914d\u7f6e\u9608\u503c\u63d0\u524d\u5e72\u9884\u3002", "result": "\u5728\u5bb6\u5ead\u4ee3\u7406\u4efb\u52a1\u4e2d\uff0cPro2Guard\u963b\u6b62\u4e8693.6%\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u4fdd\u630180.4%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff1b\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\uff0c100%\u9884\u6d4b\u8fdd\u89c4\u548c\u78b0\u649e\uff0c\u63d0\u524d38.66\u79d2\u9884\u8b66\u3002", "conclusion": "Pro2Guard\u901a\u8fc7\u4e3b\u52a8\u98ce\u9669\u9884\u6d4b\u6709\u6548\u63d0\u5347LLM\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u5e73\u8861\u5b89\u5168\u4e0e\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u9002\u7528\u4e8e\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2508.00735", "pdf": "https://arxiv.org/pdf/2508.00735", "abs": "https://arxiv.org/abs/2508.00735", "authors": ["Lucas Aubard", "Johan Mazel", "Gilles Guette", "Pierre Chifflier"], "title": "Overlapping IPv4, IPv6, and TCP data: exploring errors, test case context and multiple overlaps inside network stacks and NIDSes with PYROLYSE", "categories": ["cs.NI"], "comment": null, "summary": "IP fragmentation and TCP segmentation allow for splitting large data packets\ninto smaller ones, e.g., for transmission across network links of limited\ncapacity. These mechanisms permit complete or partial overlaps with different\ndata on the overlapping portions. IPv4, IPv6, and TCP reassembly policies,\ni.e., the data chunk preferences that depend on the overlap types, differ\nacross protocol implementations. This leads to vulnerabilities, as NIDSes may\ninterpret the packet differently from the monitored host OSes. Some NIDSes,\nsuch as Suricata or Snort, can be configured so that their policies are\nconsistent with the monitored OSes. The first contribution of the paper is\nPYROLYSE, an audit tool that exhaustively tests and describes the reassembly\npolicies of various IP and TCP implementation types. This tool ensures that\nimplementations reassemble overlapping chunk sequences without errors. The\nsecond contribution is the analysis of PYROLYSE artifacts. We first show that\nthe reassembly policies are much more diverse than previously thought. Indeed,\nby testing all the overlap possibilities for n <= 3 test case chunks and\ndifferent testing scenarios, we observe from 14 to 20 different behaviors out\nof 23 tested implementations depending on the protocol. Second, we report eight\nerrors impacting one OS, two NIDSes, and two embedded stacks, which can lead to\nsecurity issues such as NIDS pattern-matching bypass or DoS attacks. A CVE was\nassigned to a NIDS error. Finally, we show that implemented IP and TCP policies\nobtained through chunk pair testing are usually inconsistent with the observed\ntriplet reassemblies. Therefore, contrarily to what they currently do, NIDSes\nor other network traffic analysis tools should not apply n = 2 pair policies\nwhen the number of overlapping chunks exceeds two.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPYROLYSE\u5de5\u5177\uff0c\u7528\u4e8e\u6d4b\u8bd5IP\u548cTCP\u91cd\u7ec4\u7b56\u7565\u7684\u591a\u6837\u6027\u53ca\u6f5c\u5728\u6f0f\u6d1e\uff0c\u53d1\u73b0\u5b9e\u73b0\u95f4\u7b56\u7565\u5dee\u5f02\u5927\u4e14\u73b0\u6709NIDS\u65b9\u6cd5\u5b58\u5728\u95ee\u9898\u3002", "motivation": "\u7814\u7a76IP\u548cTCP\u91cd\u7ec4\u7b56\u7565\u7684\u591a\u6837\u6027\u53ca\u5176\u5bf9\u7f51\u7edc\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662fNIDS\u4e0e\u4e3b\u673aOS\u89e3\u91ca\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u6f0f\u6d1e\u3002", "method": "\u5f00\u53d1PYROLYSE\u5de5\u5177\uff0c\u5168\u9762\u6d4b\u8bd5\u4e0d\u540c\u534f\u8bae\u5b9e\u73b0\u7684\u91cd\u7ec4\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u591a\u6837\u6027\u548c\u9519\u8bef\u3002", "result": "\u53d1\u73b014\u81f320\u79cd\u4e0d\u540c\u91cd\u7ec4\u884c\u4e3a\uff0c\u62a5\u544a\u4e868\u4e2a\u5b89\u5168\u76f8\u5173\u9519\u8bef\uff0c\u5e76\u6307\u51faNIDS\u5728\u91cd\u53e0\u5757\u8d85\u8fc7\u4e24\u4e2a\u65f6\u4e0d\u9002\u7528\u73b0\u6709\u7b56\u7565\u3002", "conclusion": "NIDS\u9700\u6539\u8fdb\u91cd\u7ec4\u7b56\u7565\u4ee5\u907f\u514d\u5b89\u5168\u98ce\u9669\uff0cPYROLYSE\u4e3a\u76f8\u5173\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2508.00737", "pdf": "https://arxiv.org/pdf/2508.00737", "abs": "https://arxiv.org/abs/2508.00737", "authors": ["S\u00fceda \u00d6zkaya", "Santiago Berrezueta-Guzman", "Stefan Wagner"], "title": "How LLMs are Shaping the Future of Virtual Reality", "categories": ["cs.HC", "cs.AI"], "comment": "Pre-print", "summary": "The integration of Large Language Models (LLMs) into Virtual Reality (VR)\ngames marks a paradigm shift in the design of immersive, adaptive, and\nintelligent digital experiences. This paper presents a comprehensive review of\nrecent research at the intersection of LLMs and VR, examining how these models\nare transforming narrative generation, non-player character (NPC) interactions,\naccessibility, personalization, and game mastering. Drawing from an analysis of\n62 peer reviewed studies published between 2018 and 2025, we identify key\napplication domains ranging from emotionally intelligent NPCs and procedurally\ngenerated storytelling to AI-driven adaptive systems and inclusive gameplay\ninterfaces. We also address the major challenges facing this convergence,\nincluding real-time performance constraints, memory limitations, ethical risks,\nand scalability barriers. Our findings highlight that while LLMs significantly\nenhance realism, creativity, and user engagement in VR environments, their\neffective deployment requires robust design strategies that integrate\nmultimodal interaction, hybrid AI architectures, and ethical safeguards. The\npaper concludes by outlining future research directions in multimodal AI,\naffective computing, reinforcement learning, and open-source development,\naiming to guide the responsible advancement of intelligent and inclusive VR\nsystems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u6e38\u620f\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u5176\u5728\u53d9\u4e8b\u751f\u6210\u3001NPC\u4e92\u52a8\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u4e2a\u6027\u5316\u7b49\u65b9\u9762\u7684\u6f5c\u529b\u4e0e\u6311\u6218\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u6574\u5408LLMs\u63d0\u5347VR\u6e38\u620f\u7684\u6c89\u6d78\u611f\u3001\u9002\u5e94\u6027\u548c\u667a\u80fd\u6027\uff0c\u63a8\u52a8\u66f4\u771f\u5b9e\u7684\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u5206\u6790\u4e862018-2025\u5e74\u95f462\u9879\u540c\u884c\u8bc4\u8bae\u7814\u7a76\uff0c\u603b\u7ed3\u4e86LLMs\u5728VR\u4e2d\u7684\u5e94\u7528\u9886\u57df\u548c\u8bbe\u8ba1\u7b56\u7565\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cLLMs\u80fd\u663e\u8457\u589e\u5f3aVR\u7684\u903c\u771f\u5ea6\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u4f46\u9700\u89e3\u51b3\u5b9e\u65f6\u6027\u80fd\u3001\u4f26\u7406\u7b49\u95ee\u9898\u3002", "conclusion": "\u672a\u6765\u9700\u5173\u6ce8\u591a\u6a21\u6001AI\u3001\u60c5\u611f\u8ba1\u7b97\u7b49\u9886\u57df\uff0c\u4ee5\u4fc3\u8fdb\u667a\u80fd\u4e14\u5305\u5bb9\u7684VR\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2508.00654", "pdf": "https://arxiv.org/pdf/2508.00654", "abs": "https://arxiv.org/abs/2508.00654", "authors": ["Rodrigo Escobar D\u00edaz Guerrero", "Jamile Mohammad Jafari", "Tobias Meyer-Zedler", "Michael Schmitt", "Juergen Popp", "Thomas Bocklitz"], "title": "LEO: An Open-Source Platform for Linking OMERO with Lab Notebooks and Heterogeneous Metadata Sources", "categories": ["cs.CE", "cs.SE"], "comment": null, "summary": "In the interdisciplinary field of microscopy research, managing and\nintegrating large volumes of data stored across disparate platforms remains a\nmajor challenge. Data types such as bioimages, experimental records, and\nspectral information are often maintained in separate repositories, each\nfollowing different management standards. However, linking these data sources\nacross the research lifecycle is essential to align with the FAIR principles of\ndata management: Findability, Accessibility, Interoperability, and Reusability.\nDespite this need, there is a notable lack of tools capable of effectively\nintegrating and linking data from heterogeneous sources. To address this gap,\nwe present LEO (Linking Electronic Lab Notebooks with OMERO), a web-based\nplatform designed to create and manage links between distributed data systems.\nLEO was initially developed to link objects between Electronic Lab Notebooks\n(ELNs) and OMERO, but its functionality has since been extended through a\nplugin-based architecture, allowing the integration of additional data sources.\nThis extensibility makes LEO a scalable and flexible solution for a wide range\nof microscopy research workflows.", "AI": {"tldr": "LEO\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f51\u7edc\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u8fde\u63a5\u548c\u7ba1\u7406\u4e0d\u540c\u6570\u636e\u7cfb\u7edf\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5c24\u5176\u5728\u663e\u5fae\u955c\u7814\u7a76\u4e2d\u6574\u5408\u5206\u5e03\u5f0f\u6570\u636e\u3002", "motivation": "\u663e\u5fae\u955c\u7814\u7a76\u4e2d\uff0c\u591a\u4e2a\u5206\u6563\u5e73\u53f0\u4e0a\u7684\u5927\u91cf\u6570\u636e\u96be\u4ee5\u6574\u5408\u548c\u94fe\u63a5\uff0c\u4e0d\u7b26\u5408FAIR\u6570\u636e\u7ba1\u7406\u539f\u5219\uff0c\u7f3a\u4e4f\u6709\u6548\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e86LEO\u5e73\u53f0\uff0c\u901a\u8fc7\u63d2\u4ef6\u67b6\u6784\u94fe\u63a5\u7535\u5b50\u5b9e\u9a8c\u5ba4\u7b14\u8bb0\u672c\uff08ELNs\uff09\u548cOMERO\u7b49\u6570\u636e\u6e90\u3002", "result": "LEO\u6210\u4e3a\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u663e\u5fae\u955c\u7814\u7a76\u5de5\u4f5c\u6d41\u3002", "conclusion": "LEO\u89e3\u51b3\u4e86\u6570\u636e\u6574\u5408\u7684\u6311\u6218\uff0c\u652f\u6301FAIR\u539f\u5219\uff0c\u63d0\u5347\u4e86\u6570\u636e\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u590d\u7528\u6027\u3002"}}
{"id": "2508.00792", "pdf": "https://arxiv.org/pdf/2508.00792", "abs": "https://arxiv.org/abs/2508.00792", "authors": ["Aashay Arora", "Diego Davila", "Jonathan Guiang", "Frank W\u00fcrthwein", "Harvey Newman", "Justas Balcas", "Tom Lehman", "Xi Yang"], "title": "Data Movement Manager (DMM) for the SENSE-Rucio Interoperation Prototype", "categories": ["cs.NI"], "comment": "Submitted to CHEP 24", "summary": "The Data Movement Manager (DMM) is a prototype interface that connects CERN's\ndata management software, Rucio, with the Sofware-Defined Networking (SDN)\nservice SENSE by ESNet. It enables SDN-enabled high-energy physics data flows\nusing the existing worldwide LHC computing grid infrastructure. A key feature\nof DMM is transfer priority-based bandwidth allocation, optimizing network\nusage. Additionally, it provides fine-grained monitoring of underperforming\nflows by leveraging end-to-end data flow monitoring. This is achieved through\naccess to host-level (network interface) throughput metrics and transfer-tool\n(FTS) data transfer job-level metrics. This paper details the design and\nimplementation of DMM.", "AI": {"tldr": "DMM\u662f\u4e00\u4e2a\u8fde\u63a5Rucio\u548cSENSE\u7684\u63a5\u53e3\u539f\u578b\uff0c\u652f\u6301\u57fa\u4e8eSDN\u7684\u9ad8\u80fd\u7269\u7406\u6570\u636e\u6d41\uff0c\u5e76\u901a\u8fc7\u4f18\u5148\u7ea7\u5e26\u5bbd\u5206\u914d\u4f18\u5316\u7f51\u7edc\u4f7f\u7528\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u9ad8\u80fd\u7269\u7406\u6570\u636e\u6d41\u5728\u7f51\u7edc\u4e2d\u7684\u9ad8\u6548\u4f20\u8f93\u95ee\u9898\uff0cDMM\u8fde\u63a5\u4e86CERN\u7684\u6570\u636e\u7ba1\u7406\u8f6f\u4ef6Rucio\u548cSDN\u670d\u52a1SENSE\u3002", "method": "DMM\u5229\u7528\u4e3b\u673a\u7ea7\u541e\u5410\u91cf\u6307\u6807\u548cFTS\u6570\u636e\u4f20\u8f93\u4efb\u52a1\u7ea7\u6307\u6807\uff0c\u5b9e\u73b0\u57fa\u4e8e\u4f18\u5148\u7ea7\u7684\u5e26\u5bbd\u5206\u914d\u548c\u7ec6\u7c92\u5ea6\u76d1\u63a7\u3002", "result": "DMM\u6210\u529f\u4f18\u5316\u4e86\u7f51\u7edc\u4f7f\u7528\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u4f4e\u6548\u6570\u636e\u6d41\u7684\u7ec6\u7c92\u5ea6\u76d1\u63a7\u80fd\u529b\u3002", "conclusion": "DMM\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\u4e3a\u9ad8\u80fd\u7269\u7406\u6570\u636e\u6d41\u7684\u9ad8\u6548\u4f20\u8f93\u548c\u76d1\u63a7\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00682", "pdf": "https://arxiv.org/pdf/2508.00682", "abs": "https://arxiv.org/abs/2508.00682", "authors": ["Oscar Llorente-Vazquez", "Xabier Ugarte-Pedrero", "Igor Santos-Grueiro", "Pablo Garcia Bringas"], "title": "Unveiling Dynamic Binary Instrumentation Techniques", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Dynamic Binary Instrumentation (DBI) is the set of techniques that enable\ninstrumentation of programs at run-time, making it possible to monitor and\nmodify the execution of compiled binaries or entire systems. DBI is used for\ncountless security applications and analyses, and is extensively used across\nmany fields in both industry and academia. Over the years, several DBI\napproaches have been proposed based on different technologies and implementing\ndiverse techniques. Every solution tries to overcome certain limitations, but\nthey sometimes bring other shortcomings. Some are specialized for one\nparticular domain or task, while others have a wider scope.\n  In this paper, we shed light into the labyrinth of DBI, bringing together\nprocess-level and whole-system approaches. We depict their building blocks and\nanalyze the underlying instrumentation techniques, comparing their ability to\ninstrument different primitives and run-time events. Then, we evaluate their\nperformance when implementing each primitive, and highlight relevant\nobservations. Our results show that no single technique is better than the rest\nin all circumstances.", "AI": {"tldr": "\u5bf9\u52a8\u6001\u4e8c\u8fdb\u5236\u63d2\u6869\uff08DBI\uff09\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u6280\u672f\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u6307\u51fa\u6ca1\u6709\u5355\u4e00\u6280\u672f\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u662f\u6700\u4f18\u7684\u3002", "motivation": "\u7814\u7a76DBI\u6280\u672f\u7684\u591a\u6837\u6027\u548c\u590d\u6742\u6027\uff0c\u6574\u5408\u8fc7\u7a0b\u7ea7\u548c\u5168\u7cfb\u7edf\u7ea7\u522b\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u4ee5\u5e2e\u52a9\u9009\u62e9\u6700\u9002\u5408\u7684\u5de5\u5177\u548c\u6280\u672f\u3002", "method": "\u5206\u6790DBI\u7684\u6784\u5efa\u6a21\u5757\u548c\u5e95\u5c42\u6280\u672f\uff0c\u6bd4\u8f83\u4e0d\u540c\u6280\u672f\u5bf9\u8fd0\u884c\u4e8b\u4ef6\u7684\u63d2\u6869\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u5176\u6027\u80fd\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6ca1\u6709\u4e00\u79cd\u6280\u672f\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u4f18\u4e8e\u5176\u4ed6\u6280\u672f\u3002", "conclusion": "DBI\u6280\u672f\u7684\u9009\u62e9\u5e94\u57fa\u4e8e\u5177\u4f53\u5e94\u7528\u573a\u666f\u7684\u9700\u6c42\u3002"}}
{"id": "2508.00665", "pdf": "https://arxiv.org/pdf/2508.00665", "abs": "https://arxiv.org/abs/2508.00665", "authors": ["Maryam Mosleh", "Marie Devlin", "Ellis Solaiman"], "title": "Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Artificial intelligence-driven adaptive learning systems are reshaping\neducation through data-driven adaptation of learning experiences. Yet many of\nthese systems lack transparency, offering limited insight into how decisions\nare made. Most explainable AI (XAI) techniques focus on technical outputs but\nneglect user roles and comprehension. This paper proposes a hybrid framework\nthat integrates traditional XAI techniques with generative AI models and user\npersonalisation to generate multimodal, personalised explanations tailored to\nuser needs. We redefine explainability as a dynamic communication process\ntailored to user roles and learning goals. We outline the framework's design,\nkey XAI limitations in education, and research directions on accuracy,\nfairness, and personalisation. Our aim is to move towards explainable AI that\nenhances transparency while supporting user-centred experiences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f20\u7edf\u53ef\u89e3\u91caAI\u6280\u672f\u4e0e\u751f\u6210\u5f0fAI\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u65e8\u5728\u751f\u6210\u591a\u6a21\u6001\u4e14\u4e2a\u6027\u5316\u7684\u89e3\u91ca\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u7528\u6237\u7684\u9700\u6c42\u3002", "motivation": "\u5f53\u524dAI\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u4e14\u73b0\u6709XAI\u6280\u672f\u5ffd\u89c6\u4e86\u7528\u6237\u89d2\u8272\u548c\u7406\u89e3\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u6574\u5408\u4f20\u7edfXAI\u6280\u672f\u3001\u751f\u6210\u5f0fAI\u6a21\u578b\u548c\u7528\u6237\u4e2a\u6027\u5316\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u52a8\u6001\u7684\u3001\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u901a\u4fe1\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u89e3\u91ca\u6027\u4e3a\u52a8\u6001\u901a\u4fe1\u8fc7\u7a0b\uff0c\u5e76\u6307\u51fa\u4e86\u6559\u80b2\u4e2dXAI\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u76ee\u6807\u662f\u5f00\u53d1\u51fa\u65e2\u63d0\u5347\u900f\u660e\u5ea6\u53c8\u652f\u6301\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u4f53\u9a8c\u7684\u53ef\u89e3\u91caAI\u3002"}}
{"id": "2508.00674", "pdf": "https://arxiv.org/pdf/2508.00674", "abs": "https://arxiv.org/abs/2508.00674", "authors": ["Banan Alkhateeb", "Ellis Solaiman"], "title": "Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Social media platforms today strive to improve user experience through AI\nrecommendations, yet the value of such recommendations vanishes as users do not\nunderstand the reasons behind them. This issue arises because explainability in\nsocial media is general and lacks alignment with user-specific needs. In this\nvision paper, we outline a user-segmented and context-aware explanation layer\nby proposing a visual explanation system with diverse explanation methods. The\nproposed system is framed by the variety of user needs and contexts, showing\nexplanations in different visualized forms, including a technically detailed\nversion for AI experts and a simplified one for lay users. Our framework is the\nfirst to jointly adapt explanation style (visual vs. numeric) and granularity\n(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will\nvalidate its impact on decision-making and trust.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u6237\u5206\u6bb5\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u89e3\u91ca\u7cfb\u7edf\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u65b9\u6cd5\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u5e94\u4e0d\u540c\u7528\u6237\u9700\u6c42\u3002", "motivation": "\u5f53\u524d\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u7684\u89e3\u91ca\u6027\u666e\u904d\u7f3a\u4e4f\u4e2a\u6027\u5316\uff0c\u5bfc\u81f4\u7528\u6237\u4e0d\u7406\u89e3\u63a8\u8350\u539f\u56e0\uff0c\u964d\u4f4e\u5176\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9\u4e0e\u6570\u5b57\u89e3\u91ca\u98ce\u683c\u7684\u6846\u67b6\uff0c\u6839\u636e\u7528\u6237\u9700\u6c42\u8c03\u6574\u89e3\u91ca\u7c92\u5ea6\uff08\u4e13\u5bb6\u4e0e\u666e\u901a\u7528\u6237\uff09\uff0c\u5e76\u5728\u5355\u4e00\u6d41\u7a0b\u4e2d\u5b9e\u73b0\u3002", "result": "\u5c06\u901a\u8fc730\u540dX\u7528\u6237\u7684\u516c\u5f00\u8bd5\u70b9\u9a8c\u8bc1\u6846\u67b6\u5bf9\u51b3\u7b56\u548c\u4fe1\u4efb\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u9996\u6b21\u5728\u5355\u4e00\u6d41\u7a0b\u4e2d\u8054\u5408\u8c03\u6574\u89e3\u91ca\u98ce\u683c\u548c\u7c92\u5ea6\uff0c\u6709\u671b\u63d0\u5347\u7528\u6237\u5bf9\u63a8\u8350\u7684\u7406\u89e3\u548c\u4fe1\u4efb\u3002"}}
{"id": "2508.00773", "pdf": "https://arxiv.org/pdf/2508.00773", "abs": "https://arxiv.org/abs/2508.00773", "authors": ["Jiankai Tang", "Meng Kang", "Yiru Zhang", "Kegang Wang", "Daniel Mcduff", "Xin Liu", "Yuanchun Shi", "Yuntao Wang"], "title": "Contact Sensors to Remote Cameras: Quantifying Cardiorespiratory Coupling in High-Altitude Exercise Recovery", "categories": ["cs.CE", "cs.HC"], "comment": "UbiComp 25", "summary": "Cardiorespiratory coupling (CRC) captures the dynamic interaction between the\ncardiac and respiratory systems--an interaction strengthened by physical\nexercise and linked to improved physiological function. We examined CRC at high\naltitude in two states, rest and post-exercise recovery, and found significant\ndifferences (p < 0.05). Quantitative analysis revealed that recovery involved\nmore frequent yet less stable episodes of synchronization between respiration\nand pulse. Furthermore, we explored the feasibility of non-contact CRC\nmeasurement with remote photoplethysmography (rPPG), observing a strong\ncorrelation with oximeter-based metrics (Pearson r = 0.96). These findings\nhighlight the potential of CRC as a sensitive marker for autonomic regulation\nand its future application in contactless monitoring. Source code is available\nat GitHub: https://github.com/McJackTang/CRC.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5fc3\u80ba\u8026\u5408\uff08CRC\uff09\u53ef\u4f5c\u4e3a\u81ea\u4e3b\u795e\u7ecf\u8c03\u8282\u7684\u654f\u611f\u6807\u5fd7\uff0c\u5e76\u5728\u975e\u63a5\u89e6\u5f0f\u76d1\u6d4b\u4e2d\u6709\u6f5c\u529b\u3002\u9ad8\u6d77\u62d4\u73af\u5883\u4e0b\uff0c\u6062\u590d\u9636\u6bb5\u7684CRC\u540c\u6b65\u66f4\u9891\u7e41\u4f46\u4e0d\u7a33\u5b9a\uff0c\u4e14rPPG\u4e0e\u8840\u6c27\u4eea\u6307\u6807\u5f3a\u76f8\u5173\u3002", "motivation": "\u63a2\u7d22\u5fc3\u80ba\u8026\u5408\u5728\u9ad8\u6d77\u62d4\u4e0b\u7684\u52a8\u6001\u53d8\u5316\u53ca\u5176\u4f5c\u4e3a\u751f\u7406\u529f\u80fd\u6307\u6807\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u9a8c\u8bc1\u975e\u63a5\u89e6\u5f0f\u6d4b\u91cf\u7684\u53ef\u884c\u6027\u3002", "method": "\u5728\u9ad8\u6d77\u62d4\u5730\u533a\u6d4b\u91cf\u9759\u606f\u548c\u8fd0\u52a8\u6062\u590d\u72b6\u6001\u4e0b\u7684CRC\uff0c\u5e76\u5229\u7528\u8fdc\u7a0b\u5149\u7535\u5bb9\u79ef\u63cf\u8bb0\u672f\uff08rPPG\uff09\u8fdb\u884c\u975e\u63a5\u89e6\u5f0f\u6d4b\u91cf\uff0c\u4e0e\u8840\u6c27\u4eea\u6570\u636e\u5bf9\u6bd4\u3002", "result": "\u6062\u590d\u9636\u6bb5\u7684CRC\u540c\u6b65\u9891\u7387\u66f4\u9ad8\u4f46\u7a33\u5b9a\u6027\u8f83\u4f4e\uff08p < 0.05\uff09\u3002rPPG\u4e0e\u8840\u6c27\u4eea\u6570\u636e\u7684\u76f8\u5173\u6027\u6781\u5f3a\uff08Pearson r = 0.96\uff09\u3002", "conclusion": "CRC\u5728\u9ad8\u6d77\u62d4\u73af\u5883\u4e2d\u663e\u793a\u51fa\u52a8\u6001\u53d8\u5316\u7279\u5f81\uff0c\u4e14\u975e\u63a5\u89e6\u5f0frPPG\u6d4b\u91cf\u65b9\u6cd5\u53ef\u884c\uff0c\u4e3a\u672a\u6765\u65e0\u63a5\u89e6\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
