<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 24]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.LO](#cs.LO) [Total: 8]
- [cs.HC](#cs.HC) [Total: 18]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.AR](#cs.AR) [Total: 3]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.RO](#cs.RO) [Total: 3]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.CL](#cs.CL) [Total: 4]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.AI](#cs.AI) [Total: 2]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.LG](#cs.LG) [Total: 5]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Enhancing Clinical Decision Support and EHR Insights through LLMs and the Model Context Protocol: An Open-Source MCP-FHIR Framework](https://arxiv.org/abs/2506.13800)
*Abul Ehtesham,Aditi Singh,Saket Kumar*

Main category: cs.SE

TL;DR: 提出一种基于代理的开源框架，结合LLMs与FHIR数据，用于动态提取和分析EHR，提升临床决策支持、减轻文档负担并改善患者健康素养。


<details>
  <summary>Details</summary>
Motivation: 解决数字健康领域中临床决策支持、文档负担和患者健康素养等持续存在的挑战。

Method: 基于MCP-FHIR实现，通过JSON配置动态访问FHIR资源，支持实时总结、解释和个性化沟通，使用合成EHR数据进行隐私和可重复性评估。

Result: 框架提供可扩展、可解释和互操作的AI驱动EHR应用，支持多种FHIR格式，为个性化数字健康方案奠定基础。

Conclusion: 代理架构显著提升了EHR应用的灵活性和功能性，为数字健康领域的进一步发展提供了新思路。

Abstract: Enhancing clinical decision support (CDS), reducing documentation burdens, and improving patient health literacy remain persistent challenges in digital health. This paper presents an open-source, agent-based framework that integrates Large Language Models (LLMs) with HL7 FHIR data via the Model Context Protocol (MCP) for dynamic extraction and reasoning over electronic health records (EHRs). Built on the established MCP-FHIR implementation, the framework enables declarative access to diverse FHIR resources through JSON-based configurations, supporting real-time summarization, interpretation, and personalized communication across multiple user personas, including clinicians, caregivers, and patients. To ensure privacy and reproducibility, the framework is evaluated using synthetic EHR data from the SMART Health IT sandbox (https://r4.smarthealthit.org/), which conforms to the FHIR R4 standard. Unlike traditional approaches that rely on hardcoded retrieval and static workflows, the proposed method delivers scalable, explainable, and interoperable AI-powered EHR applications. The agentic architecture further supports multiple FHIR formats, laying a robust foundation for advancing personalized digital health solutions.

</details>


### [2] [Instruction and Solution Probabilities as Heuristics for Inductive Programming](https://arxiv.org/abs/2506.13804)
*Edward McDaid,Sarah McDaid*

Main category: cs.SE

TL;DR: 该研究通过引入指令和解决方案概率作为启发式方法，进一步缩小归纳编程的搜索空间，实现了高达100数量级的缩减。


<details>
  <summary>Details</summary>
Motivation: 通过概率启发式更高效地缩小归纳编程的搜索空间，提升搜索效率。

Method: 利用指令和解决方案概率作为附加启发式，结合代码样本中的频率设定阈值，剪枝搜索树。

Result: 两种概率变体均显著减少搜索空间，最大可达100数量级缩减。

Conclusion: 新方法有效且适用于未见代码，未来工作可进一步优化。

Abstract: Instruction subsets (ISs) are heuristics that can shrink the size of the inductive programming (IP) search space by tens of orders of magnitude. Here, we extend the IS approach by introducing instruction and solution probabilities as additional heuristics. Instruction probability reflects the expectation of an instruction occurring in a solution, based on the frequency of instruction occurrence in a large code sample. The solution probability for a partial or complete program is simply the product of all constituent instruction probabilities, including duplicates. We treat the minimum solution probabilities observed in code sample program units of different sizes as solution probability thresholds. These thresholds are used to prune the search space as partial solutions are constructed, thereby eliminating any branches containing unlikely combinations of instructions. The new approach has been evaluated using a large sample of human code. We tested two formulations of instruction probability: one based on instruction occurrence across the entire code sample and another that measured the distribution separately for each IS. Our results show that both variants produce substantial further reductions in the IP search space size of up to tens of orders of magnitude, depending on solution size. In combination with IS, reductions of over 100 orders of magnitude can be achieved. We also carried out cross-validation testing to show that the heuristics should work effectively with unseen code. The approach is described and the results and some ideas for future work are discussed.

</details>


### [3] [Signal-First Architectures: Rethinking Front-End Reactivity](https://arxiv.org/abs/2506.13815)
*Shrinivass Arunachalam Balasubramanian*

Main category: cs.SE

TL;DR: Signal-First架构通过显式信号声明和优化反应图评估解决了前端框架的响应性管理问题。


<details>
  <summary>Details</summary>
Motivation: 现代前端框架在复杂可观察链和不可预测的重渲染方面存在性能问题，Signal-First架构旨在解决这些问题。

Method: 采用Signal-First架构，通过显式信号声明、计算值和作用域副作用来管理响应性。比较RxJS、NgRx和Signal-First的性能。

Result: 通过Chrome DevTools、内存堆快照和Lighthouse审计等基准测试，量化了Signal-First的优势。

Conclusion: Signal-First架构通过消除隐式订阅和优化反应图评估，实现了确定性行为和性能优势。

Abstract: Modern front-end frameworks face escalating reactivity management challenges, including performance degradation from complex observable chains and unpredictable re-renders. This paper introduces Signal-First Architecture--a novel paradigm where granular, dependency-tracked signals are the atomic unit of reactivity. Unlike traditional RxJS or NgRx patterns, Signal-First enforces reactive flows from explicit signal declarations, with derived values via computed() and side effects scoped to effect(). This model ensures deterministic behavior by eliminating implicit subscriptions and optimizing reactive graph evaluation.
  We present a comparative analysis of three Angular reactivity models: RxJS service-based, NgRx global stores, and pure Signal-First implementations. Through controlled benchmarking, including Chrome DevTools performance tracing, memory heap snapshots, and Lighthouse audits, this study quantifies Signal-First advantages.

</details>


### [4] [Structured Program Synthesis using LLMs: Results and Insights from the IPARC Challenge](https://arxiv.org/abs/2506.13820)
*Shraddha Surana,Ashwin Srinivasan,Michael Bain*

Main category: cs.SE

TL;DR: 本文介绍了使用结构化归纳编程和LLMs成功解决IPARC挑战中的任务，并揭示了LLM在代码生成中的关键作用和人机协作的价值。


<details>
  <summary>Details</summary>
Motivation: IPARC挑战提供了600个难以自动化解决的程序合成任务，旨在评估自动程序构建能力。本文旨在探索LLMs在这些任务中的应用。

Method: 采用结构化归纳编程方法，结合LLMs的代码生成能力，需人工细化生成的结构化代码。

Result: 成功解决了所有IPARC类别的任务，揭示了代码重用、冻结正确代码等关键机制。

Conclusion: LLMs在程序合成中具有潜力，但需人机协作以优化效果。

Abstract: The IPARC Challenge, inspired by ARC, provides controlled program synthesis tasks over synthetic images to evaluate automatic program construction, focusing on sequence, selection, and iteration. This set of 600 tasks has resisted automated solutions. This paper presents a structured inductive programming approach with LLMs that successfully solves tasks across all IPARC categories. The controlled nature of IPARC reveals insights into LLM-based code generation, including the importance of prior structuring, LLMs' ability to aid structuring (requiring human refinement), the need to freeze correct code, the efficiency of code reuse, and how LLM-generated code can spark human creativity. These findings suggest valuable mechanisms for human-LLM collaboration in tackling complex program synthesis.

</details>


### [5] [Role, cost, and complexity of software in the real-world: a case for formal methods](https://arxiv.org/abs/2506.13821)
*Giovanni Bernardi,Adrian Francalanza,Marco Peressotti,Mohammad Reza Mousavi*

Main category: cs.SE

TL;DR: 本章讨论了软件在现代社会中的重要性及其低质量带来的巨大成本，提出了通过形式化软件验证和程序分析来解决问题的必要性。


<details>
  <summary>Details</summary>
Motivation: 展示软件在现代社会中的关键作用及其低质量带来的严重经济后果，论证形式化软件验证和程序分析的研究与应用价值。

Method: 通过回顾过去40年重大软件故障的成本，结合工业实践的成功案例。

Result: 强调形式化软件验证和程序分析在减少软件故障成本上的有效性。

Conclusion: 形式化软件验证和程序分析是解决软件质量问题的关键，需进一步研究和应用。

Abstract: In this chapter we outline the role that software has in modern society, along with the staggering costs of poor software quality. To lay this bare, we recall the costs of some of the major software failures that happened during the last~$40$ years. We argue that these costs justify researching, studying and applying formal software verification and in particular program analysis. This position is supported by successful industrial experiences.

</details>


### [6] [MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios](https://arxiv.org/abs/2506.13824)
*Jinyang Huang,Xiachong Feng,Qiguang Chen,Hanjie Zhao,Zihui Cheng,Jiesong Bai,Jingxuan Zhou,Min Li,Libo Qin*

Main category: cs.SE

TL;DR: 该论文提出了MLDebugging，一个专门用于评估多库Python代码调试难度的新基准，填补了现有研究在多库调试场景中的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注无库或单库调试，而忽视了实际应用中复杂的多库场景，因此作者旨在填补这一空白。

Method: 作者构建了包含126个Python库的MLDebugging基准，涵盖7种多库代码问题类型，并对主流开源和闭源LLMs进行全面评估。

Result: 实验表明，目前LLMs在多库调试场景中表现不佳。

Conclusion: 作者希望通过MLDebugging揭示LLMs在多库调试中的潜力，并为未来研究提供方向。

Abstract: Code debugging is a crucial task in software engineering, which attracts increasing attention. While remarkable success has been made in the era of large language models (LLMs), current research still focuses on the simple no-library or single-library setting, ignoring the complex multi-library scenario in real-world applications. To address this limitation, we make the first attempt to introduce MLDebugging (Multi-Library Debugging), a comprehensive benchmark designed to assess debugging challenges within multi-library Python code. Specifically, MLDebugging encompasses 126 distinct Python libraries, covering a wide range of multi-library code issues, categorized into seven distinct types. Furthermore, we conduct a thorough evaluation of MLDebugging using both mainstream open-source and closed-source LLMs and highlight that current LLMs still struggle to correctly perform code debugging across multi-library scenarios. We hope this work can uncover the potential of LLMs in multi-library debugging scenario and offer insights for future research.

</details>


### [7] [FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation](https://arxiv.org/abs/2506.13832)
*Hongda Zhu,Yiwen Zhang,Bing Zhao,Jingzhe Ding,Siyao Liu,Tong Liu,Dandan Wang,Yanan Liu,Zhaojian Li*

Main category: cs.SE

TL;DR: 提出了FrontendBench，一个由人类和LLMs共同开发的基准，用于更全面、实际地评估前端代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准过于简单、测试用例不够严谨且缺乏端到端验证，难以准确评估模型性能。

Method: FrontendBench将任务按代码功能分类，并引入交互式测试场景，包含148个精心设计的提示-测试用例对。同时开发了自动评估框架，通过沙盒环境执行代码并使用预设脚本评估结果。

Result: 自动评估框架与专家评估的一致率达90.54%，并揭示了不同LLMs在真实前端任务中的显著性能差异。

Conclusion: FrontendBench是一个可靠且可扩展的基准，为前端代码生成的未来研究提供了坚实基础。

Abstract: Large Language Models (LLMs) have made significant strides in front-end code generation. However, existing benchmarks exhibit several critical limitations: many tasks are overly simplistic, test cases often lack rigor, and end-to-end validation is absent. These issues hinder the accurate assessment of model performance. To address these challenges, we present FrontendBench, a benchmark co-developed by humans and LLMs. FrontendBench categorizes tasks based on code functionality and incorporates interactive test scenarios, enabling a more comprehensive and practical evaluation of front-end code generation capabilities. The benchmark comprises 148 meticulously crafted prompt-test case pairs spanning five levels of web components, from basic UI elements to complex interactive features. Each task reflects realistic front-end development challenges. Furthermore, we introduce an automatic evaluation framework that executes generated code within a sandbox environment and assesses outcomes using predefined test scripts. This framework achieves a 90.54% agreement rate with expert human evaluations, demonstrating high reliability. We benchmark several state-of-the-art LLMs on FrontendBench and observe substantial performance disparities in handling real-world front-end tasks. These results highlight FrontendBench as a reliable and scalable benchmark, supporting consistent multimodal evaluation and providing a robust foundation for future research in front-end code generation. Our data and code will be released soon.

</details>


### [8] [How Does LLM Reasoning Work for Code? A Survey and a Call to Action](https://arxiv.org/abs/2506.13932)
*Ira Ceka,Saurabh Pujar,Irene Manotas,Gail Kaiser,Baishakhi Ray,Shyam Ramji*

Main category: cs.SE

TL;DR: 该论文总结了大型语言模型（LLMs）在代码推理任务中的关键技术和方法，提供了分类、基准测试分析及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在代码任务中的广泛应用，研究其在真实软件工程（SWE）任务中的表现和推理技术变得尤为重要。

Method: 论文通过调查、分类和基准测试分析，研究了代码推理的关键技术和策略，并提出了新的研究方向。

Result: 论文提出了一套代码推理的分类法，总结了现有技术的表现，并指出了未来研究的潜在方向。

Conclusion: 代码推理技术仍需进一步探索，尤其是在真实场景中的应用，论文为未来研究提供了重要参考。

Abstract: The rise of large language models (LLMs) has led to dramatic improvements across a wide range of natural language tasks. These advancements have extended into the domain of code, facilitating complex tasks such as code generation, translation, summarization, and repair. However, their utility for real-world deployment in-the-wild has only recently been studied, particularly on software engineering (SWE) tasks such as GitHub issue resolution. In this study, we examine the code reasoning techniques that underlie the ability to perform such tasks, and examine the paradigms used to drive their performance. Our contributions in this paper are: (1) the first dedicated survey on code reasoning for code tasks, highlighting overarching strategies, hybrid and agentic approaches; (2) a taxonomy of various techniques used to drive code reasoning; (3) a comprehensive overview of performance on common benchmarks and a showcase of new, under-explored benchmarks with high potential in SWE; (4) an exploration on how core properties of code can be used to explain different reasoning techniques; and (5) gaps and potentially under-explored areas for future research.

</details>


### [9] [Automatic Qiskit Code Refactoring Using Large Language Models](https://arxiv.org/abs/2506.14535)
*José Manuel Suárez,Luis Mariano Bibbó,Joaquin Bogado,Alejandro Fernandez*

Main category: cs.SE

TL;DR: 论文提出了一种基于大语言模型（LLM）重构Qiskit代码的新方法，解决量子软件框架API快速变化时的兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 量子软件框架（如Qiskit）的API变化快，开发者维护代码兼容性面临挑战。

Method: 从Qiskit官方文档中提取迁移场景的分类法，结合代码输入LLM，识别迁移场景并建议重构方案。

Result: LLM在领域知识的指导下能有效辅助自动化Qiskit代码迁移。

Conclusion: 研究不仅提供了Qiskit代码迁移的分类法和提示，还为评估LLM在量子代码迁移中的能力提供了方法。

Abstract: As quantum software frameworks evolve, developers face increasing challenges in maintaining compatibility with rapidly changing APIs. In this work, we present a novel methodology for refactoring Qiskit code using large language models (LLMs). We begin by extracting a taxonomy of migration scenarios from the different sources of official Qiskit documentation (such as release notes), capturing common patterns such as migration of functionality to different modules and deprecated usage. This taxonomy, along with the original Python source code, is provided as input to an LLM, which is then tasked with identifying instances of migration scenarios in the code and suggesting appropriate refactoring solutions. Our approach is designed to address the context length limitations of current LLMs by structuring the input and reasoning process in a targeted, efficient manner. The results demonstrate that LLMs, when guided by domain-specific migration knowledge, can effectively assist in automating Qiskit code migration. This work contributes both a set of proven prompts and taxonomy for Qiskit code migration from earlier versions to version 0.46 and a methodology to asses the capabilities of LLMs to assist in the migration of quantum code.

</details>


### [10] [CRITICTOOL: Evaluating Self-Critique Capabilities of Large Language Models in Tool-Calling Error Scenarios](https://arxiv.org/abs/2506.13977)
*Shiting Huang,Zhen Fang,Zehui Chen,Siyu Yuan,Junjie Ye,Yu Zeng,Lin Chen,Qi Mao,Feng Zhao*

Main category: cs.SE

TL;DR: 该论文分析了大型语言模型（LLMs）在复杂任务中使用工具时可能遇到的错误，并提出了CRITICTOOL基准测试，用于评估和改进工具学习中的错误处理能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在处理复杂任务时的工具使用增加，错误处理成为重要研究方向，但缺乏系统的评估基准。

Method: 作者首先分析工具调用中的错误类型，然后通过进化策略构建CRITICTOOL基准测试，包含多样化的工具使用错误。

Result: 实验验证了CRITICTOOL的泛化能力和有效性，并分析了不同LLMs的工具反思能力。

Conclusion: CRITICTOOL为工具学习提供了新的评估视角，推动了这一领域的发展。

Abstract: The ability of large language models (LLMs) to utilize external tools has enabled them to tackle an increasingly diverse range of tasks. However, as the tasks become more complex and long-horizon, the intricate tool utilization process may trigger various unexpected errors. Therefore, how to effectively handle such errors, including identifying, diagnosing, and recovering from them, has emerged as a key research direction for advancing tool learning. In this work, we first extensively analyze the types of errors encountered during the function-calling process on several competitive tool evaluation benchmarks. Based on it, we introduce CRITICTOOL, a comprehensive critique evaluation benchmark specialized for tool learning. Building upon a novel evolutionary strategy for dataset construction, CRITICTOOL holds diverse tool-use errors with varying complexities, which better reflects real-world scenarios. We conduct extensive experiments on CRITICTOOL, and validate the generalization and effectiveness of our constructed benchmark strategy. We also provide an in-depth analysis of the tool reflection ability on various LLMs, offering a new perspective on the field of tool learning in LLMs. The code is available at \href{https://github.com/Shellorley0513/CriticTool}{https://github.com/Shellorley0513/CriticTool}.

</details>


### [11] [Characterising Bugs in Jupyter Platform](https://arxiv.org/abs/2506.14055)
*Yutian Tang,Hongchen Cao,Yuxi Chen,David Lo*

Main category: cs.SE

TL;DR: 本文研究了Jupyter平台的387个错误，分类为11种根源和11种症状，并提出了14项主要发现，为开发者提供了新工具开发方向。


<details>
  <summary>Details</summary>
Motivation: 了解Jupyter平台中的错误对其正确性、安全性和鲁棒性至关重要，但此前研究未涉及Jupyter笔记本宿主平台的错误。

Method: 调查了Jupyter平台的387个错误，分类为根源和症状，并总结了主要发现。

Result: 分类了11种错误根源和11种症状，提出了14项对开发者有用的发现。

Conclusion: 研究为检测和修复Jupyter平台错误提供了新方向。

Abstract: As a representative literate programming platform, Jupyter is widely adopted by developers, data analysts, and researchers for replication, data sharing, documentation, interactive data visualization, and more. Understanding the bugs in the Jupyter platform is essential for ensuring its correctness, security, and robustness. Previous studies focused on code reuse, restoration, and repair execution environment for Jupyter notebooks. However, the bugs in Jupyter notebooks' hosting platform Jupyter are not investigated. In this paper, we investigate 387 bugs in the Jupyter platform. These Jupyter bugs are classified into 11 root causes and 11 bug symptoms. We identify 14 major findings for developers. More importantly, our study opens new directions in building tools for detecting and fixing bugs in the Jupyter platform.

</details>


### [12] [A Quantum Annealing Approach for Solving Optimal Feature Selection and Next Release Problems](https://arxiv.org/abs/2506.14129)
*Shuchang Wang,Xiaopeng Qiu,Yingxing Xue,Yanfu Li,Wei Yang*

Main category: cs.SE

TL;DR: 该论文提出了一种基于量子退火（QA）的方法，用于解决基于搜索的软件工程（SBSE）中的多目标优化问题，包括下一版本问题（NRP）和特征选择问题（FSP）。针对不同规模的问题，提出了两种算法，并取得了优于传统方法的计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法和整数线性规划（ILP）在小规模SBSE问题中表现出色，但其在大规模问题中的可扩展性未知。论文尝试利用量子系统的计算潜力，探索量子退火（QA）作为子程序来解决多目标SBSE问题。

Method: 针对小规模问题，通过基于惩罚的映射将多目标优化（MOO）转化为单目标优化（SOO）以适应量子处理；针对大规模问题，采用基于最大能量影响（MEI）的分解策略，结合QA和最陡下降法提升局部搜索效率。

Result: 实验结果表明，与基于ILP的$ε$-约束方法相比，所提方法生成的解数量较少但执行时间显著减少；与启发式NSGA-II相比，获得了更多非支配解且计算效率更高。

Conclusion: 量子退火在解决SBSE问题上展现出潜力，尤其是在可扩展性和计算效率方面，为未来大规模优化问题提供了新思路。

Abstract: Search-based software engineering (SBSE) addresses critical optimization challenges in software engineering, including the next release problem (NRP) and feature selection problem (FSP). While traditional heuristic approaches and integer linear programming (ILP) methods have demonstrated efficacy for small to medium-scale problems, their scalability to large-scale instances remains unknown. Here, we introduce quantum annealing (QA) as a subroutine to tackling multi-objective SBSE problems, leveraging the computational potential of quantum systems. We propose two QA-based algorithms tailored to different problem scales. For small-scale problems, we reformulate multi-objective optimization (MOO) as single-objective optimization (SOO) using penalty-based mappings for quantum processing. For large-scale problems, we employ a decomposition strategy guided by maximum energy impact (MEI), integrating QA with a steepest descent method to enhance local search efficiency. Applied to NRP and FSP, our approaches are benchmarked against the heuristic NSGA-II and the ILP-based $ε$-constraint method. Experimental results reveal that while our methods produce fewer non-dominated solutions than $ε$-constraint, they achieve significant reductions in execution time. Moreover, compared to NSGA-II, our methods deliver more non-dominated solutions with superior computational efficiency. These findings underscore the potential of QA in advancing scalable and efficient solutions for SBSE challenges.

</details>


### [13] [Mobile Application Review Summarization using Chain of Density Prompting](https://arxiv.org/abs/2506.14192)
*Shristi Shrestha,Anas Mahmoud*

Main category: cs.SE

TL;DR: 利用LLMs和CoD提示生成移动应用评论的摘要，提升用户选择应用的效率。


<details>
  <summary>Details</summary>
Motivation: 解决应用商店评论信息过载问题，帮助用户快速获取关键信息。

Method: 使用CoD提示指导GPT-4从评论中提取关键主题并生成摘要。

Result: 生成的摘要语义密度高且易读，经48名参与者验证效果良好。

Conclusion: CoD提示优化后的方法能有效提升移动应用用户体验。

Abstract: Mobile app users commonly rely on app store ratings and reviews to find apps that suit their needs. However, the sheer volume of reviews available on app stores can lead to information overload, thus impeding users' ability to make informed app selection decisions. To address this challenge, we leverage Large Language Models (LLMs) to summarize mobile app reviews. In particular, we use the Chain of Density (CoD) prompt to guide OpenAI GPT-4 to generate abstractive, semantically dense, and easily interpretable summaries of mobile app reviews. The CoD prompt is engineered to iteratively extract salient entities from the source text and fuse them into a fixed-length summary. We evaluate the performance of our approach using a large dataset of mobile app reviews. We further conduct an empirical evaluation with 48 study participants to assess the readability of the generated summaries. Our results demonstrate that adapting the CoD prompt to focus on app features improves its ability to extract key themes from user reviews and generate natural language summaries tailored for end-user consumption. The prompt also manages to maintain the readability of the generated summaries while increasing their semantic density. Our work in this paper aims to improve mobile app users' experience by providing an effective mechanism for summarizing important user feedback in the review stream.

</details>


### [14] [The Tech DEI Backlash -- The Changing Landscape of Diversity, Equity, and Inclusion in Software Engineering](https://arxiv.org/abs/2506.14232)
*Sonja M. Hyrynsalmi,Mary Sanchez-Gordon,Anna Szlavi,Letizia Jaccheri*

Main category: cs.SE

TL;DR: 软件公司对多样性、公平和包容(DEI)倡议的反应因政治环境变化而波动，研究通过灰色文献分析10家领先软件公司的DEI策略变化，并提出DEI宇宙地图可视化趋势。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于当前缺乏关于DEI倡议反弹的学术研究，特别是软件公司如何调整其DEI策略。

Method: 采用灰色文献研究法，分析10家领先软件公司的DEI倡议变化，并进行分类。

Result: 研究发现公司对DEI倡议的反应不一，有的减少或更名，有的坚持原策略，并提出DEI宇宙地图展示趋势。

Conclusion: 结论指出公司DEI策略因外部压力而变化，可视化工具有助于理解行业动态。

Abstract: Not long ago, Diversity, Equity, and Inclusion (DEI) initiatives were a top priority for leading software companies. However, in a short period, a wave of backlash has led many firms to re-assess their DEI strategies. Responding to this DEI backlash is crucial in academic research, especially because, currently, little scholarly research has been done on it. In this paper, therefore, we have set forth the following research question (RQ): "How have leading software companies changed their DEI strategies in recent years?" Given the novelty of the RQ and, consequently, the lack of scholarly research on it, we are conducting a grey literature study, examining the current state of DEI initiatives in 10 leading software companies. Based on our analysis, we have classified companies into categories based on their shift in commitment to DEI. We can identify that companies are indeed responding to the backlash by rethinking their strategy, either by reducing, increasing, or renaming their DEI initiatives. In contrast, some companies keep on with their DEI strategy, at least so far, despite the challenging political climate. To illustrate these changes, we introduce the DEI Universe Map, a visual representation of software industry trends in DEI commitment and actions.

</details>


### [15] [Designing a Custom Chaos Engineering Framework for Enhanced System Resilience at Softtech](https://arxiv.org/abs/2506.14281)
*Ethem Utku Aktas,Burak Tuzlutas,Burak Yesiltas*

Main category: cs.SE

TL;DR: 本文提出了一种为金融领域领先软件公司Softtech定制的混沌工程框架设计提案。


<details>
  <summary>Details</summary>
Motivation: 通过有意引入故障来增强软件系统的弹性，同时考虑金融行业的监管要求。

Method: 基于混沌工程的基础概念和活动，设计一个迭代、可扩展的框架，以适应Softtech的基础设施、业务优先级和组织环境。

Result: 提出了一种针对Softtech需求的定制框架，明确了其关键活动和组成部分。

Conclusion: 该框架有助于Softtech开发团队逐步提升其混沌工程实践。

Abstract: Chaos Engineering is a discipline which enhances software resilience by introducing faults to observe and improve system behavior intentionally. This paper presents a design proposal for a customized Chaos Engineering framework tailored for Softtech, a leading software development company serving the financial sector. It outlines foundational concepts and activities for introducing Chaos Engineering within Softtech, while considering financial sector regulations. Building on these principles, the framework aims to be iterative and scalable, enabling development teams to progressively improve their practices. The study addresses two primary questions: how Softtech's unique infrastructure, business priorities, and organizational context shape the customization of its Chaos Engineering framework and what key activities and components are necessary for creating an effective framework tailored to Softtech's needs.

</details>


### [16] [Anticipating Bugs: Ticket-Level Bug Prediction and Temporal Proximity Effects](https://arxiv.org/abs/2506.14290)
*Daniele La Prova,Emanuele Gentili,Davide Falessi*

Main category: cs.SE

TL;DR: 该论文提出了票级预测（TLP）方法，旨在识别未来可能引入错误的工单，并通过三个阶段验证其准确性。结果表明，TLP的准确性随着工单生命周期的推进而提高，不同特征家族在不同阶段具有不同的预测能力。


<details>
  <summary>Details</summary>
Motivation: 目前错误预测方法主要用于修复而非预防。论文旨在将错误预测提前到工单阶段，以优化测试和开发资源分配。

Method: 采用TLP方法，分析工单的72个特征（属于6大类），通过滑动窗口和机器学习分类器对两个Apache开源项目的10,000个工单进行测试。

Result: TLP准确性随工单生命周期推进而提高，不同阶段的特征预测能力不同：早期开发者特征最重要，后期代码和JIT指标占优，温度特征全程补充。

Conclusion: 研究表明，缺陷预测可提前至工单阶段，为风险感知的工单分类和开发者分配提供机会，扩展了现有错误预测的研究范围。

Abstract: The primary goal of bug prediction is to optimize testing efforts by focusing on software fragments, i.e., classes, methods, commits (JIT), or lines of code, most likely to be buggy. However, these predicted fragments already contain bugs. Thus, the current bug prediction approaches support fixing rather than prevention. The aim of this paper is to introduce and evaluate Ticket-Level Prediction (TLP), an approach to identify tickets that will introduce bugs once implemented. We analyze TLP at three temporal points, each point represents a ticket lifecycle stage: Open, In Progress, or Closed. We conjecture that: (1) TLP accuracy increases as tickets progress towards the closed stage due to improved feature reliability over time, and (2) the predictive power of features changes across these temporal points. Our TLP approach leverages 72 features belonging to six different families: code, developer, external temperature, internal temperature, intrinsic, ticket to tickets, and JIT. Our TLP evaluation uses a sliding-window approach, balancing feature selection and three machine-learning bug prediction classifiers on about 10,000 tickets of two Apache open-source projects. Our results show that TLP accuracy increases with proximity, confirming the expected trade-off between early prediction and accuracy. Regarding the prediction power of feature families, no single feature family dominates across stages; developer-centric signals are most informative early, whereas code and JIT metrics prevail near closure, and temperature-based features provide complementary value throughout. Our findings complement and extend the literature on bug prediction at the class, method, or commit level by showing that defect prediction can be effectively moved upstream, offering opportunities for risk-aware ticket triaging and developer assignment before any code is written.

</details>


### [17] [Quality Assessment of Python Tests Generated by Large Language Models](https://arxiv.org/abs/2506.14297)
*Victor Alves,Carla Bezerra,Ivan Machado,Larissa Rocha,Tássio Virgínio,Publio Silva*

Main category: cs.SE

TL;DR: 研究比较了GPT-4o、Amazon Q和LLama 3.3三种大语言模型在生成Python测试代码时的表现，发现大部分生成的测试套件存在错误或测试异味，提示上下文对质量影响显著。


<details>
  <summary>Details</summary>
Motivation: 手动生成测试脚本耗时且易出错，利用大语言模型自动化生成测试代码可能提高效率，但需验证其质量。

Method: 评估三种大语言模型在Text2Code和Code2Code两种提示上下文下生成的测试代码的结构可靠性，分析错误和测试异味。

Result: GPT-4o表现最佳，错误率最低（C2C 10%、T2C 6%），Amazon Q错误率最高（C2C 19%、T2C 28%）。断言错误最常见（64%），测试异味中“测试用例缺乏内聚性”最多（41%）。

Conclusion: 大语言模型生成的测试代码质量有待提升，未来研究需优化生成场景和提示策略。

Abstract: The manual generation of test scripts is a time-intensive, costly, and error-prone process, indicating the value of automated solutions. Large Language Models (LLMs) have shown great promise in this domain, leveraging their extensive knowledge to produce test code more efficiently. This study investigates the quality of Python test code generated by three LLMs: GPT-4o, Amazon Q, and LLama 3.3. We evaluate the structural reliability of test suites generated under two distinct prompt contexts: Text2Code (T2C) and Code2Code (C2C). Our analysis includes the identification of errors and test smells, with a focus on correlating these issues to inadequate design patterns. Our findings reveal that most test suites generated by the LLMs contained at least one error or test smell. Assertion errors were the most common, comprising 64% of all identified errors, while the test smell Lack of Cohesion of Test Cases was the most frequently detected (41%). Prompt context significantly influenced test quality; textual prompts with detailed instructions often yielded tests with fewer errors but a higher incidence of test smells. Among the evaluated LLMs, GPT-4o produced the fewest errors in both contexts (10% in C2C and 6% in T2C), whereas Amazon Q had the highest error rates (19% in C2C and 28% in T2C). For test smells, Amazon Q had fewer detections in the C2C context (9%), while LLama 3.3 performed best in the T2C context (10%). Additionally, we observed a strong relationship between specific errors, such as assertion or indentation issues, and test case cohesion smells. These findings demonstrate opportunities for improving the quality of test generation by LLMs and highlight the need for future research to explore optimized generation scenarios and better prompt engineering strategies.

</details>


### [18] [Agile and Student-Centred Teaching of Agile/Scrum Concepts](https://arxiv.org/abs/2506.14369)
*Maria Spichkova*

Main category: cs.SE

TL;DR: 本文总结了设计和教授以敏捷/Scrum开发和需求工程为核心的软件工程项目管理课程的经验，探讨了学生为中心的教学方法和真实的评估方式的挑战与解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于疫情后教学方式的变化（如取消面对面考试），真实的评估方式变得更加重要，但评估大规模学生群体的作业和提供及时公正的反馈成为新的挑战。

Method: 课程设计采用学生为中心和灵活的教学方法，注重敏捷/Scrum和需求工程内容，并通过调整课程结构和在线评估方式支持混合学习模式。

Result: 总结了教学经验，提出适用于本科和研究生的敏捷/Scrum教学课程结构，以及大规模学生群体的真实且可扩展的在线评估方案。

Conclusion: 通过调整课程结构和评估方式，可以有效支持混合学习和大规模学生群体的教学需求，同时提升教学质量和学生体验。

Abstract: In this paper, we discuss our experience in designing and teaching a course on Software Engineering Project Management, where the focus is on Agile/Scrum development and Requirement Engineering activities. The course has undergone fundamental changes since 2020 to make the teaching approach more student-centred and flexible. As many universities abandoned having face-to-face exams at the end of the semester, authentic assessments now play an even more important role than before. This makes assessment of students' work even more challenging, especially if we are dealing with large cohorts of students. The complexity is not only in dealing with diversity in the student cohorts when elaborating the assessment tasks, but also in being able to provide feedback and marks in a timely and fairly. We report our lessons learned, which might provide useful insights for teaching Agile/Scrum concepts to undergraduate and postgraduate students. We also analyse what course structure might be effective to support a blended learning approach, as well as what could be a reasonable structure of online assessments, to keep them both authentic and scalable for large cohorts of students.

</details>


### [19] [Defining the Game Producer: A Mapping of Key Characteristics and Differentiators of the Professional Behind Digital Game Production](https://arxiv.org/abs/2506.14409)
*Rafael C. Lopes,Danilo M. Ribeiro*

Main category: cs.SE

TL;DR: 研究通过定性分析确定了数字游戏制作人的核心特征、技能与能力，为培训和招聘提供了基础。


<details>
  <summary>Details</summary>
Motivation: 随着数字游戏复杂性增加，游戏制作人需要整合创意、技术与商业维度，明确其角色定义至关重要。

Method: 采用半结构化访谈（11人）和扎根理论分析，构建基于实践的类别。

Result: 确定了游戏制作人必备的个人特质、实践技能与战略能力，沟通、适应性与项目管理为核心要素。

Conclusion: 研究模型为游戏开发中的领导角色培训、招聘及未来研究提供了基础。

Abstract: Introduction: As digital games grow in complexity, the role of the Game Producer becomes increasingly relevant for aligning creative, technical, and business dimensions. Objective: This study aimed to identify and map the main characteristics, skills, and competencies that define the Digital Game Producer profile. Methodology: A qualitative investigation was conducted with 11 semi-structured interviews, analyzed through Grounded Theory to build categories grounded in professional practice. Results: The study produced a structured set of personal characteristics, practical skills, and strategic competencies considered essential for Game Producers. Communication, adaptability, and project management emerged as central elements across the sample. Conclusion: The resulting model offers a foundation for professional training, recruitment strategies, and future research on leadership roles in game development.

</details>


### [20] [Low-code to fight climate change: the Climaborough project](https://arxiv.org/abs/2506.14623)
*Aaron Conrardy,Armen Sulejmani,Cindy Guerlain,Daniele Pagani,David Hick,Matteo Satta,Jordi Cabot*

Main category: cs.SE

TL;DR: Climaborough项目通过低代码/无代码策略快速部署气候仪表盘，支持欧洲城市实现2030年碳中和目标。


<details>
  <summary>Details</summary>
Motivation: 帮助欧洲城市在本地环境中推动气候转型，通过实时和历史数据监控气候目标的进展。

Method: 采用低代码策略加速仪表盘开发，嵌入无代码理念，使非技术用户能自定义仪表盘。

Result: 开发了Climaborough城市平台，展示用户友好的仪表盘，用于评估本地实验性倡议的效果。

Conclusion: 低代码/无代码策略有效支持了城市快速部署和适应气候仪表盘的需求。

Abstract: The EU-funded Climaborough project supports European cities to achieve carbon neutrality by 2030. Eleven cities in nine countries will deploy in real conditions products and services fostering climate transition in their local environment. The Climaborough City Platform is being developed to monitor the cities' overall progress towards their climate goals by aggregating historic and real-time data and displaying the results in user-friendly dashboards that will be used by non-technical experts to evaluate the effectiveness of local experimental initiatives, identify those that yield significant impact, and assess the potential consequences of scaling them up to a broader level. In this paper, we explain how we have put in place a low-code/no-code strategy in Climaborough in response to the project's aim to quickly deploy climate dashboards. A low-code strategy is used to accelerate the development of the dashboards. The dashboards embed a no-code philosophy that enables all types of citizen profiles to configure and adapt the dashboard to their specific needs.

</details>


### [21] [ACM Survey Draft on Formalising Software Requirements with Large Language Models](https://arxiv.org/abs/2506.14627)
*Arshad Beg,Diarmuid O'Donoghue,Rosemary Monahan*

Main category: cs.SE

TL;DR: 这篇草案是一份工作文档，总结了94篇论文，并包含软件需求可追溯性、形式方法及其工具、编程统一理论等额外部分。


<details>
  <summary>Details</summary>
Motivation: 整理和总结相关领域的研究成果，为后续研究提供参考。

Method: 通过文献综述和分类，对94篇论文进行总结，并扩展了具体主题的讨论。

Result: 文档提供了全面的文献综述和具体领域的深入分析。

Conclusion: 该草案为研究者和实践者提供了有价值的资源，未来可进一步扩展和优化。

Abstract: This draft is a working document, having a summary of nighty-four (94) papers with additional sections on Traceability of Software Requirements (Section 4), Formal Methods and Its Tools (Section 5), Unifying Theories of Programming (UTP) and Theory of Institutions (Section 6). Please refer to abstract of [7,8]. Key difference of this draft from our recently anticipated ones with similar titles, i.e. AACS 2025 [7] and SAIV 2025 [8] is:
  [7] is a two page submission to ADAPT Annual Conference, Ireland. Submitted on 18th of March, 2025, it went through the light-weight blind review and accepted for poster presentation. Conference was held on 15th of May, 2025.
  [8] is a nine page paper with additional nine pages of references and summary tables, submitted to Symposium on AI Verification (SAIV 2025) on 24th of April, 2025. It went through rigorous review process. The uploaded version on arXiv.org [8] is the improved one of the submission, after addressing the specific suggestions to improve the paper.

</details>


### [22] [Navigating the growing field of research on AI for software testing -- the taxonomy for AI-augmented software testing and an ontology-driven literature survey](https://arxiv.org/abs/2506.14640)
*Ina K. Schieferdecker*

Main category: cs.SE

TL;DR: 论文综述了AI在软件测试自动化中的应用，从无自动化到全自动化，并讨论AI带来的新测试形式，提出了新分类法ai4st。


<details>
  <summary>Details</summary>
Motivation: 因软件测试自动化设计、开发、维护和演进的高成本，AI在工程领域的突破为测试自动化提供了新视角。

Method: 综述近期AI增强软件测试自动化的研究，提出并应用新分类法ai4st进行分类。

Result: 提出ai4st分类法，用于分类近期研究并识别未解决问题。

Conclusion: AI为软件测试自动化开辟了新方向，但仍存在许多待研究的开放问题。

Abstract: In industry, software testing is the primary method to verify and validate the functionality, performance, security, usability, and so on, of software-based systems. Test automation has gained increasing attention in industry over the last decade, following decades of intense research into test automation and model-based testing. However, designing, developing, maintaining and evolving test automation is a considerable effort. Meanwhile, AI's breakthroughs in many engineering fields are opening up new perspectives for software testing, for both manual and automated testing. This paper reviews recent research on AI augmentation in software test automation, from no automation to full automation. It also discusses new forms of testing made possible by AI. Based on this, the newly developed taxonomy, ai4st, is presented and used to classify recent research and identify open research questions.

</details>


### [23] [Issue Retrieval and Verification Enhanced Supplementary Code Comment Generation](https://arxiv.org/abs/2506.14649)
*Yanzhen Zou,Xianlin Zhao,Xinglu Pan,Bing Xie*

Main category: cs.SE

TL;DR: IsComment 是一种基于问题的 LLM 检索和验证方法，用于生成代码注释，通过过滤不相关或无法验证的内容来减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 问题报告包含丰富的信息，可用于生成代码注释，但如何减少生成注释中的幻觉仍是一个挑战。

Method: 通过代码-注释-问题分析确定五种补充信息类型，检索相关问题句子生成候选注释，并过滤无关或无法验证的内容。

Result: IsComment 显著提高了注释覆盖率（如 ChatGPT 从 33.6% 提升到 72.2%），并在 MESIA 指标上表现优于现有方法。

Conclusion: IsComment 能生成更丰富、更有用的代码注释，提升代码理解能力。

Abstract: Issue reports have been recognized to contain rich information for retrieval-augmented code comment generation. However, how to minimize hallucinations in the generated comments remains significant challenges. In this paper, we propose IsComment, an issue-based LLM retrieval and verification approach for generating method's design rationale, usage directives, and so on as supplementary code comments. We first identify five main types of code supplementary information that issue reports can provide through code-comment-issue analysis. Next, we retrieve issue sentences containing these types of supplementary information and generate candidate code comments. To reduce hallucinations, we filter out those candidate comments that are irrelevant to the code or unverifiable by the issue report, making the code comment generation results more reliable. Our experiments indicate that compared with LLMs, IsComment increases the coverage of manual supplementary comments from 33.6% to 72.2% for ChatGPT, from 35.8% to 88.4% for GPT-4o, and from 35.0% to 86.2% for DeepSeek-V3. Compared with existing work, IsComment can generate richer and more useful supplementary code comments for programming understanding, which is quantitatively evaluated through the MESIA metric on both methods with and without manual code comments.

</details>


### [24] [Unified Software Engineering agent as AI Software Engineer](https://arxiv.org/abs/2506.14683)
*Leonhard Applis,Yuntong Zhang,Shanchao Liang,Nan Jiang,Lin Tan,Abhik Roychoudhury*

Main category: cs.SE

TL;DR: 本文提出了一个名为USEagent的统一软件工程代理，旨在解决LLM代理是否等同于AI软件工程师的问题，并通过实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM代理是否能胜任AI软件工程师的角色，以及如何通过统一代理处理软件开发中的复杂任务。

Method: 开发了一个统一代理USEagent，结合了编码、测试和修复等多种能力，并通过USEbench（包含多种任务的基准）进行评估。

Result: 在1,271个任务中，USEagent表现优于现有通用代理（如CodeActAgent），但在某些编码任务上仍有不足。

Conclusion: USEagent是AI软件工程师的雏形，未来需进一步改进以填补能力空白。

Abstract: The growth of Large Language Model (LLM) technology has raised expectations for automated coding. However, software engineering is more than coding and is concerned with activities including maintenance and evolution of a project. In this context, the concept of LLM agents has gained traction, which utilize LLMs as reasoning engines to invoke external tools autonomously. But is an LLM agent the same as an AI software engineer? In this paper, we seek to understand this question by developing a Unified Software Engineering agent or USEagent. Unlike existing work which builds specialized agents for specific software tasks such as testing, debugging, and repair, our goal is to build a unified agent which can orchestrate and handle multiple capabilities. This gives the agent the promise of handling complex scenarios in software development such as fixing an incomplete patch, adding new features, or taking over code written by others. We envision USEagent as the first draft of a future AI Software Engineer which can be a team member in future software development teams involving both AI and humans. To evaluate the efficacy of USEagent, we build a Unified Software Engineering bench (USEbench) comprising of myriad tasks such as coding, testing, and patching. USEbench is a judicious mixture of tasks from existing benchmarks such as SWE-bench, SWT-bench, and REPOCOD. In an evaluation on USEbench consisting of 1,271 repository-level software engineering tasks, USEagent shows improved efficacy compared to existing general agents such as OpenHands CodeActAgent. There exist gaps in the capabilities of USEagent for certain coding tasks, which provides hints on further developing the AI Software Engineer of the future.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [25] [Optimized Execution of FreeCHR](https://arxiv.org/abs/2506.14485)
*Sascha Rechenberger,Thom Frühwirth*

Main category: cs.PL

TL;DR: 本文介绍了一种改进的FreeCHR执行算法，并通过基准测试验证了其优化的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有CHR嵌入方法缺乏统一性，影响维护和正确性，FreeCHR框架旨在解决这一问题。

Method: 提出改进的FreeCHR执行算法，并进行了基准测试。

Result: 基准测试表明优化的算法效果显著。

Conclusion: 改进的算法和优化提升了FreeCHR的性能，证明了其有效性。

Abstract: Constraint Handling Rules (CHR) is a rule-based programming language that rewrites collections of constraints. It is typically embedded into a general-purpose language. There exists a plethora of implementations for numerous host languages. However, the existing implementations often re-invent the method of embedding, which impedes maintenance and weakens assertions of correctness. To formalize and thereby unify the embedding of a ground subset of CHR into arbitrary host languages, we introduced the framework FreeCHR and proved it to be a valid representation of classical CHR. For the sake of simplicity, abstract implementations of our framework did not yet include a concrete matching algorithm nor optimizations. In this paper, we introduce an improved execution algorithm for FreeCHR. We also provide an evaluation of the algorithm via benchmarks which suggest the effectiveness of our implemented optimizations.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [26] [The Trip to ZigBee Backscatter across a Decade, a Systematic Review](https://arxiv.org/abs/2506.13822)
*Yang Liu*

Main category: cs.NI

TL;DR: 该论文回顾了反向散射通信技术的变革，从RFID发展到能够支持无电池物联网（IoT）的复杂系统，重点关注其与ZigBee等商用无线协议的交互。文章分析了从概念验证到高吞吐量、跨技术通信架构的演进，并探讨了关键技术和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探索反向散射通信技术如何从简单的RFID技术发展为支持无电池物联网的复杂系统，并分析其与现有无线协议的交互能力，以推动技术的进一步创新和应用。

Method: 系统回顾了过去十年中环境反向散射通信的进展，分析了关键技术如精细调制、鲁棒同步、跨技术物理层模拟和多标签协调，并对现有系统进行了比较分析。

Result: 研究总结了现代反向散射系统在数据速率、范围、功耗和硬件兼容性等方面的核心权衡，指出了当前面临的挑战和未来可能的解决方案。

Conclusion: 反向散射通信技术具有巨大的潜力，但仍需解决网络扩展性、安全性、近远问题等挑战。未来可能与可重构智能表面（RIS）和6G网络结合，进一步扩展其应用范围。

Abstract: The field of backscatter communication has undergone a profound transformation, evolving from a niche technology for radio-frequency identification (RFID) into a sophisticated paradigm poised to enable a truly battery-free Internet of Things (IoT). This evolution is built upon a deepening understanding of the fundamental principles governing these ultra-low-power links. Modern backscatter systems are no longer simple reflectors of continuous waves but are increasingly designed to interact with complex, data-carrying ambient signals from ubiquitous sources like WiFi, ZigBee, and cellular networks. This review systematically charts the journey of ambient backscatter, particularly focusing on its interaction with ZigBee and other commodity wireless protocols over the last decade. We analyze the progression from foundational proof-of-concept systems that established productive backscatter to modern high-throughput, concurrent, and cross-technology communication architectures. Key advancements in fine-grained modulation, robust synchronization, cross-technology physical layer emulation, and multi-tag coordination are detailed. A comparative analysis of state-of-the-art systems highlights the core trade-offs between performance metrics like data rate and range, power consumption, and compatibility with commodity hardware. Finally, we synthesize the primary challenges, including networking scalability, security vulnerabilities, the near-far problem, and practical deployment hurdles, and outline future research directions, such as integration with Reconfigurable Intelligent Surfaces (RIS) and 6G networks, that promise to further expand the capabilities of this transformative technology.

</details>


### [27] [Emerging Networks and Services in Developing Nations -- Barbados Use Case](https://arxiv.org/abs/2506.13934)
*Warren Scantlebury,Milena Radenkovic*

Main category: cs.NI

TL;DR: 比较巴巴多斯与英国诺丁汉和伦敦的DTN性能与特征，分析相似性与差异原因，并探讨DTN在交通领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 通过比较发展中国家与发达国家的DTN性能，填补研究空白，帮助其他研究者更准确地推断研究结论在发展中国家中的应用。

Method: 通过网络模拟，记录并分析两地DTN性能数据，重点关注交通领域的公交车网络。

Result: 展示图形化趋势并分析其存在原因及实际应用意义。

Conclusion: 研究结果为发展中国家DTN应用提供参考，并验证其在交通领域的可行性。

Abstract: This report aims to conduct an in-depth comparison of DTN (Delay/Disconnection Tolerant Network) performance and characteristics in the developing country of Barbados versus two major UK cities Nottingham and London. We aim to detect any common patterns or deviations between the two region areas and use the results of our network simulations to draw well-founded conclusions on the reasons for these similarities and differences. In the end we hope to be able to assimilate specific portions of the island to these major cities in regard to DTN characteristics. We also want to investigate the viability of DTN use in the transport sector which has struggled from a range of issues related to efficiency and finance, by recording and analysing the same metrics for a DTN that consists of only buses. This work is intended to serve as a bridge for expanding the breadth of research done on developed countries allowing other researchers to be able to make well informed assumptions about how that research may apply to developing nations. It will consist of results that show graphical trends and analysis of why these trends might exist and how they apply to real world scenarios.

</details>


### [28] [TraGe: A Generic Packet Representation for Traffic Classification Based on Header-Payload Differences](https://arxiv.org/abs/2506.14151)
*Chungang Lin,Yilong Jiang,Weiyao Zhang,Xuying Meng,Tianyu Zuo,Yujun Zhang*

Main category: cs.NI

TL;DR: TraGe是一种新型的通用数据包表示模型，专门为流量分类设计，通过针对数据包头和负载的不同特性进行差异化预训练，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统流量分类方法依赖特征提取和大规模标注数据，且现有预训练模型未针对流量数据特点设计，导致信息表达不完整甚至破坏协议信息。

Method: 提出TraGe模型，基于数据包头（连续字节）和负载（非连续字节）的差异进行差异化预训练，并引入动态掩码策略防止过拟合。

Result: 实验显示TraGe在两项流量分类任务中显著优于现有方法，性能提升高达6.97%，且对参数波动和采样配置变化具有更强鲁棒性。

Conclusion: TraGe通过针对性预训练和动态掩码策略，有效捕捉流量数据特征，为有限标注数据下的分类任务提供了高效解决方案。

Abstract: Traffic classification has a significant impact on maintaining the Quality of Service (QoS) of the network. Since traditional methods heavily rely on feature extraction and large scale labeled data, some recent pre-trained models manage to reduce the dependency by utilizing different pre-training tasks to train generic representations for network packets. However, existing pre-trained models typically adopt pre-training tasks developed for image or text data, which are not tailored to traffic data. As a result, the obtained traffic representations fail to fully reflect the information contained in the traffic, and may even disrupt the protocol information. To address this, we propose TraGe, a novel generic packet representation model for traffic classification. Based on the differences between the header and payload-the two fundamental components of a network packet-we perform differentiated pre-training according to the byte sequence variations (continuous in the header vs. discontinuous in the payload). A dynamic masking strategy is further introduced to prevent overfitting to fixed byte positions. Once the generic packet representation is obtained, TraGe can be finetuned for diverse traffic classification tasks using limited labeled data. Experimental results demonstrate that TraGe significantly outperforms state-of-the-art methods on two traffic classification tasks, with up to a 6.97% performance improvement. Moreover, TraGe exhibits superior robustness under parameter fluctuations and variations in sampling configurations.

</details>


### [29] [Optimizing System Latency for Blockchain-Encrypted Edge Computing in Internet of Vehicles](https://arxiv.org/abs/2506.14208)
*Cui Zhang,Maoxin Ji,Qiong Wu,Pingyi Fan,Qiang Fan*

Main category: cs.NI

TL;DR: 提出了一个结合区块链Raft共识机制与边缘计算的安全框架，以保护车辆信息，并通过凸优化降低系统延迟，提高可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着车联网技术的进步，边缘计算成为处理复杂任务的重要工具，但任务卸载可能暴露车辆信息，引发安全漏洞。

Method: 结合区块链Raft共识机制与边缘计算，提出安全框架，并通过理论公式和凸优化降低系统延迟。

Result: 仿真结果表明，优化后的数据提取率显著降低系统延迟，且延迟变化相对稳定。

Conclusion: 该模型为未来网络环境（如5G和智能城市系统）的安全性和效率提升提供了有价值的参考。

Abstract: As Internet of Vehicles (IoV) technology continues to advance, edge computing has become an important tool for assisting vehicles in handling complex tasks. However, the process of offloading tasks to edge servers may expose vehicles to malicious external attacks, resulting in information loss or even tampering, thereby creating serious security vulnerabilities. Blockchain technology can maintain a shared ledger among servers. In the Raft consensus mechanism, as long as more than half of the nodes remain operational, the system will not collapse, effectively maintaining the system's robustness and security. To protect vehicle information, we propose a security framework that integrates the Raft consensus mechanism from blockchain technology with edge computing. To address the additional latency introduced by blockchain, we derived a theoretical formula for system delay and proposed a convex optimization solution to minimize the system latency, ensuring that the system meets the requirements for low latency and high reliability. Simulation results demonstrate that the optimized data extraction rate significantly reduces system delay, with relatively stable variations in latency. Moreover, the proposed optimization solution based on this model can provide valuable insights for enhancing security and efficiency in future network environments, such as 5G and next-generation smart city systems.

</details>


### [30] [A Novel Dynamic Bandwidth Allocation Design for 100G Coherent Passive Optical Network](https://arxiv.org/abs/2506.14221)
*Rujia Zou,Haipeng Zhang,Karthik Sundaresan,Zhensheng Jia,Suresh Subramaniam*

Main category: cs.NI

TL;DR: 论文针对100G及以上速率的相干PON技术，提出了一种新型动态带宽分配（DBA）算法Hybrid-Switch DBA，以解决时间错位问题并优化带宽管理。


<details>
  <summary>Details</summary>
Motivation: 随着100G及以上速率相干PON的发展，低延迟带宽管理和高效DBA机制的需求日益迫切。

Method: 分析了两种现有DBA的时间错位问题，并提出了一种新型Hybrid-Switch DBA算法，支持自适应切换以适应实时流量。

Result: 提出了首个针对相干PON中DBA错位问题的解决方案，显著提升了带宽分配效率。

Conclusion: Hybrid-Switch DBA算法为相干PON网络提供了优化性能和适应低延迟应用的解决方案。

Abstract: With the rapid advancements in coherent Passive Optical Network (PON) technologies featuring 100G and higher data rates, this paper addresses the urgent requirement for sophisticated simulation and MAC layer development within the domain of coherent Time Division Multiplexing (TDM) PON and coherent Time and Frequency Division Multiplexing (TFDM) PON networks. The ever-growing demand for latency-sensitive services and expanding user populations in next-generation 100G and beyond coherent PONs, underscores the crucial need for low-latency bandwidth management and efficient Dynamic Bandwidth Allocation (DBA) mechanisms. In this paper, we present a pioneering analysis of two established DBAs from the perspective of temporal misalignments. Subsequently, a novel DBA algorithm tailored for coherent PONs featuring 100 Gbps data rate and up to 512 end-users is introduced, named the Hybrid-Switch DBA. This innovative approach allows for adaptive switching of the DBA scheme in response to real-time traffic conditions. To the best of our knowledge, this paper represents the first attempt to address the misalignment problem of DBA and proposes a novel DBA solution for both TDM- and TFDM-based coherent PON networks. This research significantly contributes to the development of coherent TDM PON and coherent TFDM PON networks by enhancing the efficiency of bandwidth allocation and addressing the challenges associated with misalignments in DBA mechanisms. As optical access networks continue to evolve to meet the ever-increasing demands of modern communication services, the Hybrid-Switch DBA algorithm presented in this paper offers a promising solution for optimizing network performance and accommodating latency-sensitive applications.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [31] [Matching logic -- proof system $\mathcal{G}^c$](https://arxiv.org/abs/2506.13801)
*Laurenţiu Leuştean,Dafina Trufaş*

Main category: cs.LO

TL;DR: 提出了一种新的匹配逻辑证明系统，基于哥德尔的一阶直觉逻辑系统。


<details>
  <summary>Details</summary>
Motivation: 将哥德尔的证明系统适配到匹配逻辑中，以扩展其应用范围。

Method: 调整哥德尔的一阶直觉逻辑证明系统，使其适用于匹配逻辑。

Result: 成功开发出一种新的匹配逻辑证明系统。

Conclusion: 该适配方法为匹配逻辑提供了有效的证明工具。

Abstract: We propose in these notes a new proof system for first-order matching logic with application, obtained by adapting to matching logic Gödel's proof system for first-order intuitionistic logic.

</details>


### [32] [Positive Sharing and Abstract Machines](https://arxiv.org/abs/2506.14131)
*Beniamino Accattoli,Claudio Sacerdoti Coen,Jui-Hsuan Wu*

Main category: cs.LO

TL;DR: Wu的正λ演算简化了共享研究中的技术问题，但自然抽象机效率低下。本文设计了一种优化的机器，解决了二次时间问题。


<details>
  <summary>Details</summary>
Motivation: 研究Wu的正λ演算的自然抽象机，发现其存在效率问题，需设计优化的机器以提高性能。

Method: 定义了自然抽象机并分析其效率问题，随后设计了一种基于新切片技术的优化机器。

Result: 优化的机器证明了高效性，解决了自然抽象机的二次时间问题。

Conclusion: 通过新的切片技术设计的优化机器显著提升了正λ演算的计算效率。

Abstract: Wu's positive $λ$-calculus is a recent call-by-value $λ$-calculus with sharing coming from Miller and Wu's study of the proof-theoretical concept of focalization. Accattoli and Wu showed that it simplifies a technical aspect of the study of sharing; namely it rules out the recurrent issue of renaming chains, that often causes a quadratic time slowdown.
  In this paper, we define the natural abstract machine for the positive $λ$-calculus and show that it suffers from an inefficiency: the quadratic slowdown somehow reappears when analyzing the cost of the machine. We then design an optimized machine for the positive $λ$-calculus, which we prove efficient. The optimization is based on a new slicing technique which is dual to the standard structure of machine environments.

</details>


### [33] [Asymptotically Smaller Encodings for Graph Problems and Scheduling](https://arxiv.org/abs/2506.14042)
*Bernardo Subercaseaux*

Main category: cs.LO

TL;DR: 该论文展示了如何将图形问题（如顶点覆盖、独立集、$k$-着色）编码为CNF，仅需$O(|V|^2 / \lg |V|)$子句，而非标准的$Ω(|V|^2)$约束，并提出了一种新的独立集编码方法，应用于字符串压缩和调度问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统编码方法中约束数量过多的问题，提出更高效的编码方式，为理解和改进预处理工具提供理论基础。

Method: 基于Erdős、Chung和Spencer（1983）的双团覆盖结果，设计新的CNF编码方法，并将其扩展到密集区间图中的独立集问题。

Result: 显著减少了编码子句数量，成功应用于字符串压缩和调度问题，将调度问题的编码大小从$O(NMT^2)$降至$O(NMT + M T^2 \lg T)$。

Conclusion: 论文提出的编码方法不仅理论上高效，还能实际应用于其他领域，展示了其广泛潜力。

Abstract: We show how several graph problems (e.g., vertex-cover, independent-set, $k$-coloring) can be encoded into CNF using only $O(|V|^2 / \lg |V|)$ many clauses, as opposed to the $Ω(|V|^2)$ constraints used by standard encodings. This somewhat surprising result is a simple consequence of a result of Erdős, Chung, and Spencer (1983) about biclique coverings of graphs, and opens theoretical avenues to understand the success of "Bounded Variable Addition'' (Manthey, Heule, and Biere, 2012) as a preprocessing tool. Finally, we show a novel encoding for independent sets in some dense interval graphs using only $O(|V| \lg |V|)$ clauses (the direct encoding uses $Ω(|V|^2)$), which we have successfully applied to a string-compression encoding posed by Bannai et al. (2022). As a direct byproduct, we obtain a reduction in the encoding size of a scheduling problem posed by Mayank and Modal (2020) from $O(NMT^2)$ to $O(NMT + M T^2 \lg T)$, where $N$ is the number of tasks, $T$ the total timespan, and $M$ the number of machines.

</details>


### [34] [A Non-Wellfounded and Labelled Sequent Calculus for Bimodal Provability Logic](https://arxiv.org/abs/2506.14307)
*Justus Becker*

Main category: cs.LO

TL;DR: 本文提出了一种用于双模态可证性逻辑CS的标记和非良基演算，基于其Kripke语义建模，并利用循环证明技术强制要求逆向良基性。


<details>
  <summary>Details</summary>
Motivation: 为双模态可证性逻辑CS提供一种新的演算系统，通过建模其Kripke语义并解决逆向良基性问题。

Method: 采用循环证明理论技术，构建标记和非良基演算系统，证明其相对于语义的可靠性和完备性。

Result: 系统被证明是可靠且完备的，同时提供了原始决策程序和反模型提取方法。

Conclusion: 该演算系统有效解决了CS逻辑的语义建模问题，并提供了实用的决策工具。

Abstract: We present a labelled and non-wellfounded calculus for the bimodal provability logic CS. The system is obtained by modelling the Kripke-like semantics of this logic. As in arXiv:2309.00532, we enforce the second-order property of converse wellfoundedness by using techniques from cyclic proof theory. We will prove soundness and completeness of this system with respect to the semantics and provide a primitive decision procedure together with a way to extract countermodels.

</details>


### [35] [A uniform cut-elimination theorem for linear logics with fixed points and super exponentials](https://arxiv.org/abs/2506.14327)
*Esaïe Bauer,Alexis Saurin*

Main category: cs.LO

TL;DR: 提出了一种统一的消解定理方法，用于参数化系统，结合了固定点的定义和多种指数连接词。


<details>
  <summary>Details</summary>
Motivation: 研究光逻辑中的消解定理问题，解决多种证明系统中消解定理的冗余问题。

Method: 结合固定点定义和指数连接词，采用消解证明和充分条件识别的方法。

Result: 提供了一种统一的消解定理，适用于参数化系统。

Conclusion: 通过统一方法解决了多种光逻辑系统中的消解定理问题，减少了冗余证明。

Abstract: In the realm of light logics deriving from linear logic, a number of variants of exponential rules have been investigated. The profusion of such proof systems induces the need for cut-elimination theorems for each logic, the proof of which may be redundant. A number of approaches in proof theory have been adopted to cope with this need. In the present paper, we consider this issue from the point of view of enhancing linear logic with least and greatest fixed-points and considering such a variety of exponential connectives. Our main contribution is to provide a uniform cut-elimination theorem for a parametrized system with fixed-points by combining two approaches: cut-elimination proofs by reduction (or translation) to another system and the identification of sufficient conditions for cut-elimination. More precisely, we examine a broad range of systems, taking inspiration from Nigam and Miller's subexponentials and from Bauer and Laurent's super exponentials. Our work is motivated on the one hand by Baillot's work on light logics with recursive types and on the other hand by Bauer and Saurin's recent work on the proof theory of the modal μ-calculus.

</details>


### [36] [OSTRICH2: Solver for Complex String Constraints](https://arxiv.org/abs/2506.14363)
*Matthew Hague,Denghang Hu,Artur Jeż,Anthony W. Lin,Oliver Markgraf,Philipp Rümmer,Zhilin Wu*

Main category: cs.LO

TL;DR: OSTRICH2是SMT求解器OSTRICH的最新版本，支持复杂的字符串操作，并保证对特定字符串约束的完整性。它在SMT-LIB的Unicode字符串理论基础上扩展了独特功能，如解析ECMAScript正则表达式和处理用户定义的字符串转换器，并在SMT-COMP基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发OSTRICH2旨在更全面地支持字符串约束求解，尤其是针对复杂的字符串操作和特定约束的完整性保证。通过扩展SMT-LIB理论，提供其他求解器不具备的功能。

Method: OSTRICH2基于OSTRICH框架，增加了对ECMAScript正则表达式的解析（包括环视断言和捕获组）以及用户定义字符串转换器的支持。支持SMT-LIB的Unicode字符串理论扩展。

Result: OSTRICH2在SMT-COMP基准测试中表现出与其他字符串求解器的竞争力，验证了其功能和性能的有效性。

Conclusion: OSTRICH2是功能丰富且高效的字符串求解器，特别适合处理复杂的字符串约束和扩展需求。

Abstract: We present OSTRICH2, the latest evolution of the SMT solver OSTRICH for string constraints. OSTRICH2 supports a wide range of complex functions on strings and provides completeness guarantees for a substantial fragment of string constraints, including the straight-line fragment and the chain-free fragment. OSTRICH2 provides full support for the SMT-LIB theory of Unicode strings, extending the standard with several unique features not found in other solvers: among others, parsing of ECMAScript regular expressions (including look-around assertions and capture groups) and handling of user-defined string transducers. We empirically demonstrate that OSTRICH2 is competitive to other string solvers on SMT-COMP benchmarks.

</details>


### [37] [Varanus: Runtime Verification for CSP](https://arxiv.org/abs/2506.14426)
*Matt Luckcuck,Angelo Ferrando,Fatma Faruq*

Main category: cs.LO

TL;DR: 本文介绍了Varanus，一种运行时验证工具，用于监控系统是否符合基于CSP规范构建的预言机，适用于自主系统。


<details>
  <summary>Details</summary>
Motivation: 自主系统常在多变和未知环境中运行，传统验证方法可能不适用，而运行时验证（RV）能动态检查系统行为是否符合规范。

Method: Varanus通过从CSP规范生成监控器，实现对系统的运行时验证，并在模拟的自主机器人系统中测试其性能。

Result: Varanus能在接近线性时间内从CSP过程合成监控器，并对每个事件进行接近恒定时间的检查，成功检测到规范违规。

Conclusion: Varanus证明了CSP规范在运行时验证中的实用性，为自主系统的动态验证提供了新工具。

Abstract: Autonomous systems are often used in changeable and unknown environments, where traditional verification may not be suitable. Runtime Verification (RV) checks events performed by a system against a formal specification of its intended behaviour, making it highly suitable for ensuring that an autonomous system is obeying its specification at runtime. Communicating Sequential Processes (CSP) is a process algebra usually used in static verification, which captures behaviour as a trace of events, making it useful for RV as well. Further, CSP has more recently been used to specify autonomous and robotic systems. Though CSP is supported by two extant model checkers, so far it has no RV tool. This paper presents Varanus, an RV tool that monitors a system against an oracle built from a CSP specification. This approach enables the reuse without modifications of a specification that was built, e.g during the system's design. We describe the tool, apply it to a simulated autonomous robotic rover inspecting a nuclear waste store, empirically comparing its performance to two other RV tools using different languages, and demonstrate how it can detect violations of the specification. Varanus can synthesise a monitor from a CSP process in roughly linear time, with respect to the number of states and transitions in the model; and checks each event in roughly constant time.

</details>


### [38] [A Logic For Fresh Labelled Transition Systems](https://arxiv.org/abs/2506.14538)
*Mohamed H Bandukara,Nikos Tzevelekos*

Main category: cs.LO

TL;DR: 介绍了一种用于新鲜标记转移系统（FLTS）的带有递归的Hennessy-Milner逻辑，用于表达多种属性，并通过归约到博弈问题分析模型检查的复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究FLTS的性质表达能力，扩展历史相关自动机在无限输入字母表上的计算能力。

Method: 引入新逻辑，通过归约到奇偶博弈分析模型检查问题，使用名义集技术提供复杂性上界。

Result: 证明了模型检查问题的指数级复杂度上界。

Conclusion: 该逻辑扩展了FLTS的表达能力，为处理新鲜数据生成的系统提供了新的分析工具。

Abstract: We introduce a Hennessy-Milner logic with recursion for Fresh Labelled Transition Systems (FLTSs). These are nominal labelled transition systems which keep track of the history, i.e. of data values seen so far, and can capture fresh data generation. In particular, FLTSs generalise the computations of Fresh-Register Automata, which in turn are one of the simplest classes of history-dependent automata operating on infinite input alphabets. Each automaton comes equipped with a finite set of registers where it can store data values and compare them with others from the input. In addition, the automaton can accept an input just if it be fresh: not seen in the computation before. The logic we introduce can express a variety of properties, such as the existence of an infinite path of distinct data values or the existence of a finite path where some taint property is violated. We study the model checking problem and its complexity via reduction to parity games and, using nominal sets techniques, provide an exponential upper bound for it.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [39] [Toward Practical Privacy in XR: Empirical Analysis of Multimodal Anonymization Mechanisms](https://arxiv.org/abs/2506.13882)
*Azim Ibragimov,Ethan Wilson,Kevin R. B. Butler,Eakta Jain*

Main category: cs.HC

TL;DR: 研究了XR环境中行为数据的隐私保护机制，通过结合眼动和身体数据扰动技术，显著降低了重识别率。


<details>
  <summary>Details</summary>
Motivation: 随着XR系统传感器数据的丰富，行为信号可能被用于重识别，需要有效的隐私保护机制。

Method: 系统评估了实时隐私机制，包括四种眼动和十种身体数据扰动方法，结合多模态策略。

Result: 多模态机制将重识别率从80.3%降至26.3%（休闲应用）和84.8%降至26.1%（竞技应用）。

Conclusion: 模态特异性和上下文感知的隐私策略能有效保护XR环境中的行为数据隐私。

Abstract: As extended reality (XR) systems become increasingly immersive and sensor-rich, they enable the collection of fine-grained behavioral signals such as eye and body telemetry. These signals support personalized and responsive experiences and may also contain unique patterns that can be linked back to individuals. However, privacy mechanisms that naively pair unimodal mechanisms (e.g., independently apply privacy mechanisms for eye and body privatization) are often ineffective at preventing re-identification in practice. In this work, we systematically evaluate real-time privacy mechanisms for XR, both individually and in pair, across eye and body modalities. To preserve usability, all mechanisms were tuned based on empirically grounded thresholds for real-time interaction. We evaluated four eye and ten body mechanisms across multiple datasets, comprising up to 407 participants. Our results show that while obfuscating eye telemetry alone offers moderate privacy gains, body telemetry perturbation is substantially more effective. When carefully paired, multimodal mechanisms reduce re-identification rate from 80.3% to 26.3% in casual XR applications (e.g., VRChat and Job Simulator) and from 84.8% to 26.1% in competitive XR applications (e.g., Beat Saber and Synth Riders), all without violating real-time usability requirements. These findings underscore the potential of modality-specific and context-aware privacy strategies for protecting behavioral data in XR environments.

</details>


### [40] [A Systematic Review of User-Centred Evaluation of Explainable AI in Healthcare](https://arxiv.org/abs/2506.13904)
*Ivania Donoso-Guzmán,Kristýna Sirka Kacafírková,Maxwell Szymanski,An Jacobs,Denis Parra,Katrien Verbert*

Main category: cs.HC

TL;DR: 该研究填补了可解释人工智能（XAI）在真实医疗环境中评估方法不足的空白，提出了用户体验框架和评估指南。


<details>
  <summary>Details</summary>
Motivation: XAI方法的实用价值在真实环境中缺乏验证，需上下文感知的评估以确保其可信度和可用性，但目前缺乏明确的评估设计指南。

Method: 通过对82项医疗场景中的用户研究进行系统性综述，结合预定义编码方案和归纳性编码，分析了XAI生成的解释的评估实践。

Result: 研究总结了当前评估实践，揭示了医疗XAI中以人为本的趋势，解释了属性间的相互关系，并更新了框架及提供了具体指南。

Conclusion: 该研究为跨学科团队设计和实施针对特定应用的XAI系统评估策略提供了实用框架和指南。

Abstract: Despite promising developments in Explainable Artificial Intelligence, the practical value of XAI methods remains under-explored and insufficiently validated in real-world settings. Robust and context-aware evaluation is essential, not only to produce understandable explanations but also to ensure their trustworthiness and usability for intended users, but tends to be overlooked because of no clear guidelines on how to design an evaluation with users.
  This study addresses this gap with two main goals: (1) to develop a framework of well-defined, atomic properties that characterise the user experience of XAI in healthcare; and (2) to provide clear, context-sensitive guidelines for defining evaluation strategies based on system characteristics.
  We conducted a systematic review of 82 user studies, sourced from five databases, all situated within healthcare settings and focused on evaluating AI-generated explanations. The analysis was guided by a predefined coding scheme informed by an existing evaluation framework, complemented by inductive codes developed iteratively.
  The review yields three key contributions: (1) a synthesis of current evaluation practices, highlighting a growing focus on human-centred approaches in healthcare XAI; (2) insights into the interrelations among explanation properties; and (3) an updated framework and a set of actionable guidelines to support interdisciplinary teams in designing and implementing effective evaluation strategies for XAI systems tailored to specific application contexts.

</details>


### [41] ["I Cannot Write This Because It Violates Our Content Policy": Understanding Content Moderation Policies and User Experiences in Generative AI Products](https://arxiv.org/abs/2506.14018)
*Lan Gao,Oscar Chen,Rachel Lee,Nick Feamster,Chenhao Tan,Marshini Chetty*

Main category: cs.HC

TL;DR: 研究了生成式AI在线工具的内容审核政策及其执行情况，发现政策虽全面但缺乏实施细则，用户体验不佳。


<details>
  <summary>Details</summary>
Motivation: 探讨现有GAI产品中内容审核的实际表现，填补研究空白。

Method: 分析14个GAI在线工具的审核政策，并通过Reddit讨论评估用户实际体验。

Result: 审核系统能有效拦截恶意内容，但用户因审核失败和支持缺失常感挫败。

Conclusion: 建议优化GAI产品的内容审核政策及用户体验。

Abstract: While recent research has focused on developing safeguards for generative AI (GAI) model-level content safety, little is known about how content moderation to prevent malicious content performs for end-users in real-world GAI products. To bridge this gap, we investigated content moderation policies and their enforcement in GAI online tools -- consumer-facing web-based GAI applications. We first analyzed content moderation policies of 14 GAI online tools. While these policies are comprehensive in outlining moderation practices, they usually lack details on practical implementations and are not specific about how users can aid in moderation or appeal moderation decisions. Next, we examined user-experienced content moderation successes and failures through Reddit discussions on GAI online tools. We found that although moderation systems succeeded in blocking malicious generations pervasively, users frequently experienced frustration in failures of both moderation systems and user support after moderation. Based on these findings, we suggest improvements for content moderation policy and user experiences in real-world GAI products.

</details>


### [42] [FEWSim: A Visual Analytic Framework for Exploring the Nexus of Food-Energy-Water Simulations](https://arxiv.org/abs/2506.14056)
*Fan Lei,David A. Sampson,Jiayi Hong,Yuxin Ma,Giuseppe Mascaro,Dave White,Rimjhim Agarwal,Ross Maciejewski*

Main category: cs.HC

TL;DR: FEWSim是一个视觉分析框架，用于帮助专家探索和解释食品、能源和水（FEW）系统的模拟结果。


<details>
  <summary>Details</summary>
Motivation: 研究FEW系统的相互依赖关系及其强度和脆弱性，但因变量难以观察，阻碍了跨部门分析。

Method: 开发了FEWSim，采用三层异步架构：模型层集成FEW模型，中间件层管理场景配置和执行，可视化层提供交互式探索。

Result: 通过案例研究（美国亚利桑那州凤凰城AMA）展示了FEWSim的实用性。

Conclusion: FEWSim框架有助于跨部门分析和评估可持续发展指标，解决了FEW系统的复杂性问题。

Abstract: The interdependencies of food, energy, and water (FEW) systems create a nexus opportunity to explore the strengths and vulnerabilities of individual and cross-sector interactions within FEW systems. However, the variables quantifying nexus interactions are hard to observe, which hinders the cross-sector analysis. To overcome such challenges, we present FEWSim, a visual analytics framework designed to support domain experts in exploring and interpreting simulation results from a coupled FEW model. FEWSim employs a three-layer asynchronous architecture: the model layer integrates food, energy, and water models to simulate the FEW nexus; the middleware layer manages scenario configuration and execution; and the visualization layer provides interactive visual exploration of simulated time-series results across FEW sectors. The visualization layer further facilitates the exploration across multiple scenarios and evaluates scenario differences in performance using sustainability indices of the FEW nexus. We demonstrate the utility of FEWSim through a case study for the Phoenix Active Management Area (AMA) in Arizona.

</details>


### [43] [The Teacher's Dilemma: Balancing Trade-Offs in Programming Education for Emergent Bilingual Students](https://arxiv.org/abs/2506.14147)
*Emma R. Dodoo,Tamara Nelson-Fromm,Mark Guzdial*

Main category: cs.HC

TL;DR: 讨论K-12计算教师在双语学生课堂中如何选择编程语言和教学材料，平衡语言障碍与课程及职业准备需求。


<details>
  <summary>Details</summary>
Motivation: 探讨教师在面对语言障碍时如何选择编程工具，以实现包容性学习环境、课程指南对齐及职业准备的多重目标。

Method: 分析教师决策过程中如何在可访问性、课程对齐和职业准备之间权衡。

Result: 揭示了教师如何在多重目标中做出选择，以及影响其决策的关键因素。

Conclusion: 研究为支持双语学生的编程教学提供了实践指导，并突出了教师在权衡中的挑战。

Abstract: K-12 computing teachers must navigate complex trade-offs when selecting programming languages and instructional materials for classrooms with emergent bilingual students. While they aim to foster an inclusive learning environment by addressing language barriers that impact student engagement, they must also align with K-12 computer science curricular guidelines and prepare students for industry-standard programming tools. Because programming languages predominantly use English keywords and most instructional materials are written in English, these linguistic barriers introduce cognitive load and accessibility challenges. This paper examines teachers' decisions in balancing these competing priorities, highlighting the tensions between accessibility, curriculum alignment, and workforce preparation. The findings shed light on how our teacher participants negotiate these trade-offs and what factors influence their selection of programming tools to best support EB students while meeting broader educational and professional goals.

</details>


### [44] [StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework](https://arxiv.org/abs/2506.14159)
*Shayan Talaei,Meijin Li,Kanu Grover,James Kent Hippler,Diyi Yang,Amin Saberi*

Main category: cs.HC

TL;DR: StorySage是一个多智能体框架驱动的自传写作系统，通过灵活对话帮助用户整理零散记忆，生成连贯传记。


<details>
  <summary>Details</summary>
Motivation: 个人记忆分散难以整理，现有写作助手缺乏个性化支持，需开发更灵活的系统。

Method: 采用多智能体框架（采访者、记录员、计划员、章节作者、会话协调员），迭代收集记忆并更新自传。

Result: 实验表明系统能高效管理多会话，用户研究表明其优于基线，提升对话流畅性、叙事完整性和用户满意度。

Conclusion: StorySage为自传写作提供了新架构，展示了多智能体系统增强人机创意合作的潜力。

Abstract: Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative, a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N=28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships.

</details>


### [45] [Affective-CARA: A Knowledge Graph Driven Framework for Culturally Adaptive Emotional Intelligence in HCI](https://arxiv.org/abs/2506.14166)
*Nirodya Pussadeniya,Bahareh Nakisa,Mohmmad Naim Rastgoo*

Main category: cs.HC

TL;DR: Affective-CARA是一个结合文化情感知识图谱和强化学习的框架，旨在提升跨文化情感计算的适应性和个性化交互。


<details>
  <summary>Details</summary>
Motivation: 解决情感计算中的文化适应性挑战，通过文化敏感的情感响应促进包容性交互。

Method: 整合文化情感知识图谱（StereoKG）、梯度奖励策略优化和文化意识响应调解器，结合实时用户输入与文化数据。

Result: 在情感对齐、文化适应和叙事质量上优于基线模型，文化语义密度达9.32/10，文化偏见降低61%。

Conclusion: Affective-CARA能生成道德且适应文化的响应，适用于跨文化交流、心理健康支持等领域。

Abstract: Culturally adaptive emotional responses remain a critical challenge in affective computing. This paper introduces Affective-CARA, an agentic framework designed to enhance user-agent interactions by integrating a Cultural Emotion Knowledge Graph (derived from StereoKG) with Valence, Arousal, and Dominance annotations, culture-specific data, and cross-cultural checks to minimize bias. A Gradient-Based Reward Policy Optimization mechanism further refines responses according to cultural alignment, affective appropriateness, and iterative user feedback. A Cultural-Aware Response Mediator coordinates knowledge retrieval, reinforcement learning updates, and historical data fusion. By merging real-time user input with past emotional states and cultural insights, Affective-CARA delivers narratives that are deeply personalized and sensitive to diverse cultural norms. Evaluations on AffectNet, SEMAINE DB, and MERD confirm that the framework consistently outperforms baseline models in sentiment alignment, cultural adaptation, and narrative quality. Affective-CARA achieved a Cultural Semantic Density of 9.32 out of 10 and lowered cultural representation bias by 61% (KL-Divergence: 0.28), demonstrating robust performance in generating ethical, adaptive responses. These findings suggest the potential for more inclusive and empathetic interactions, making Affective-CARA an avenue for fostering culturally grounded user experiences across domains such as cross-cultural communication, mental health support, and education.

</details>


### [46] [Balancing Caregiving and Self-Care: Exploring Mental Health Needs of Alzheimer's and Dementia Caregivers](https://arxiv.org/abs/2506.14196)
*Jiayue Melissa Shi,Keran Wang,Dong Whi Yoo,Ravi Karkar,Koustuv Saha*

Main category: cs.HC

TL;DR: 研究探讨了阿尔茨海默病及相关痴呆症（AD/ADRD）患者家庭照顾者的心理健康问题，分析了他们在护理过程中采取的管理负担的方法及使用的技术，并提出了适应不同护理阶段的动态干预方案。


<details>
  <summary>Details</summary>
Motivation: 现有的支持系统往往忽视照顾者心理健康需求的动态变化，研究旨在填补这一空白，为设计更符合照顾者需求的解决方案提供依据。

Method: 通过对25名AD/ADRD家庭照顾者进行半结构化访谈，研究识别了心理健康问题的成因与影响，并绘制了照顾者在护理旅程三个阶段的心理健康变化图。

Result: 研究发现照顾者的心理健康需求随护理阶段动态变化，现有技术需更具可访问性、可扩展性和个性化，以适应其需求。

Conclusion: 研究为设计动态、分阶段的心理健康干预措施奠定了基础，有助于全面支持照顾者的心理健康，同时惠及患者。

Abstract: Alzheimer's Disease and Related Dementias (AD/ADRD) are progressive neurodegenerative conditions that impair memory, thought processes, and functioning. Family caregivers of individuals with AD/ADRD face significant mental health challenges due to long-term caregiving responsibilities. Yet, current support systems often overlook the evolving nature of their mental wellbeing needs. Our study examines caregivers' mental wellbeing concerns, focusing on the practices they adopt to manage the burden of caregiving and the technologies they use for support. Through semi-structured interviews with 25 family caregivers of individuals with AD/ADRD, we identified the key causes and effects of mental health challenges, and developed a temporal mapping of how caregivers' mental wellbeing evolves across three distinct stages of the caregiving journey. Additionally, our participants shared insights into improvements for existing mental health technologies, emphasizing the need for accessible, scalable, and personalized solutions that adapt to caregivers' changing needs over time. These findings offer a foundation for designing dynamic, stage-sensitive interventions that holistically support caregivers' mental wellbeing, benefiting both caregivers and care recipients.

</details>


### [47] [The Impact of Generative AI on Social Media: An Experimental Study](https://arxiv.org/abs/2506.14295)
*Anders Giovanni Møller,Daniel M. Romero,David Jurgens,Luca Maria Aiello*

Main category: cs.HC

TL;DR: 论文探讨了生成式AI工具在社交媒体中对用户行为和体验的双重影响，包括提高参与度但降低内容质量，并提出了四项设计原则以实现伦理有效的整合。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于填补生成式AI工具对社交媒体内容生产者和用户感知的影响这一研究空白。

Method: 通过包含680名美国参与者的控制实验，设置了五种实验条件（对照组和四种AI干预组），评估AI工具的效果。

Result: 研究发现AI工具虽增加用户参与度和内容量，但降低了讨论质量和真实性，并产生负面溢出效应。

Conclusion: 结论提出四项设计原则：透明披露AI内容、用户个性化设计、情境敏感性和优先直观界面，以指导伦理有效的AI整合。

Abstract: Generative Artificial Intelligence (AI) tools are increasingly deployed across social media platforms, yet their implications for user behavior and experience remain understudied, particularly regarding two critical dimensions: (1) how AI tools affect the behaviors of content producers in a social media context, and (2) how content generated with AI assistance is perceived by users. To fill this gap, we conduct a controlled experiment with a representative sample of 680 U.S. participants in a realistic social media environment. The participants are randomly assigned to small discussion groups, each consisting of five individuals in one of five distinct experimental conditions: a control group and four treatment groups, each employing a unique AI intervention-chat assistance, conversation starters, feedback on comment drafts, and reply suggestions. Our findings highlight a complex duality: some AI-tools increase user engagement and volume of generated content, but at the same time decrease the perceived quality and authenticity of discussion, and introduce a negative spill-over effect on conversations. Based on our findings, we propose four design principles and recommendations aimed at social media platforms, policymakers, and stakeholders: ensuring transparent disclosure of AI-generated content, designing tools with user-focused personalization, incorporating context-sensitivity to account for both topic and user intent, and prioritizing intuitive user interfaces. These principles aim to guide an ethical and effective integration of generative AI into social media.

</details>


### [48] [System 0: Transforming Artificial Intelligence into a Cognitive Extension](https://arxiv.org/abs/2506.14376)
*Massimo Chiriatti,Marianna Bergamaschi Ganapini,Enrico Panai,Brenda K. Wiederhold,Giuseppe Riva*

Main category: cs.HC

TL;DR: 论文介绍了System 0，一个理解AI如何作为认知扩展的新框架，并提出七种方法以优化人机认知协作。


<details>
  <summary>Details</summary>
Motivation: 探讨AI从工具转变为认知伙伴的过程及其对人类思维的潜在影响。

Method: 基于扩展心智假设和Heersmink的认知扩展标准，提出七种证据支持的人机认知整合框架。

Result: AI系统满足认知整合条件，但也可能带来偏见和依赖性问题，需通过框架平衡。

Conclusion: 七种框架旨在将AI转变为人类思维的催化剂，而非替代品，保障人类能动性和批判性思维。

Abstract: This paper introduces System 0, a conceptual framework for understanding how artificial intelligence functions as a cognitive extension preceding both intuitive (System 1) and deliberative (System 2) thinking processes. As AI systems increasingly shape the informational substrate upon which human cognition operates, they transform from passive tools into active cognitive partners. Building on the Extended Mind hypothesis and Heersmink's criteria for cognitive extension, we argue that AI systems satisfy key conditions for cognitive integration. These include reliability, trust, transparency, individualization, and the ability to enhance and transform human mental functions. However, AI integration creates a paradox: while expanding cognitive capabilities, it may simultaneously constrain thinking through sycophancy and bias amplification. To address these challenges, we propose seven evidence-based frameworks for effective human-AI cognitive integration: Enhanced Cognitive Scaffolding, which promotes progressive autonomy; Symbiotic Division of Cognitive Labor, strategically allocating tasks based on comparative strengths; Dialectical Cognitive Enhancement, countering AI sycophancy through productive epistemic tension; Agentic Transparency and Control, ensuring users understand and direct AI influence; Expertise Democratization, breaking down knowledge silos; Social-Emotional Augmentation, addressing affective dimensions of cognitive work; and Duration-Optimized Integration, managing the evolving human-AI relationship over time. Together, these frameworks provide a comprehensive approach for harnessing AI as a genuine cognitive extension while preserving human agency, critical thinking, and intellectual growth, transforming AI from a replacement for human cognition into a catalyst for enhanced thinking.

</details>


### [49] [MERba: Multi-Receptive Field MambaVision for Micro-Expression Recognition](https://arxiv.org/abs/2506.14468)
*Xinglong Mao,Shifeng Liu,Sirui Zhao,Tong Xu,Enhong Chen*

Main category: cs.HC

TL;DR: MERba是一种新型多感受野架构，通过局部-全局特征集成和不对称多扫描策略提升微表情识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时捕捉局部肌肉激活和全局面部依赖关系，而这对识别微表情至关重要。

Method: 提出MERba架构，结合局部提取器和全局自注意力层，引入不对称多扫描策略和双粒度分类模块。

Result: 在基准数据集上优于现有方法，实验验证了各模块的有效性。

Conclusion: MERba通过局部与全局特征的结合，显著提升了微表情识别的性能。

Abstract: Micro-expressions (MEs) are brief, involuntary facial movements that reveal genuine emotions, holding significant potential in psychological diagnosis and criminal investigations. Despite notable advances in automatic ME recognition (MER), existing methods still struggle to jointly capture localized muscle activations and global facial dependencies, both critical for recognizing subtle emotional cues. To tackle this challenge, we propose MERba, a novel multi-receptive field architecture tailored for MER. MERba introduces a series of Local-Global Feature Integration stages, where fine-grained motion features are first extracted by local extractors containing MambaVision Mixers within non-overlapping windows, and then global dependencies across these regions are modeled via lightweight self-attention layers. This hierarchical design enables a progressive transition from localized perception to holistic facial understanding. Furthermore, we introduce an asymmetric multi-scanning strategy to eliminate redundant scanning directions and enhance local spatial perception. To address the high inter-class similarity among negative MEs, we introduce a Dual-Granularity Classification Module that decouples the recognition process into a coarse-to-fine paradigm. Experiments on two benchmark MER datasets demonstrate that MERba outperforms existing methods, with ablation studies confirming the effectiveness of each proposed component.

</details>


### [50] [SimSpark: Interactive Simulation of Social Media Behaviors](https://arxiv.org/abs/2506.14476)
*Ziyue Lin,Yi Shan,Lin Gao,Xinghua Jia,Siming Chen*

Main category: cs.HC

TL;DR: 本文介绍了SimSpark系统，这是一个交互式工具，用于模拟社交媒体行为，解决生成可信行为、验证结果和交互控制等挑战。


<details>
  <summary>Details</summary>
Motivation: 研究社交媒体行为的模拟工具，以克服真实数据分析的困难，并提供灵活的场景和角色模拟。

Method: 提出了SimSpark系统，结合模拟算法和可视化界面，利用大语言模型生成可信行为，支持实时参数调整和结果分析。

Result: 通过案例研究、量化评估和专家访谈验证了系统的有效性。

Conclusion: SimSpark为社交媒体行为模拟提供了灵活且高效的工具，支持更深入的研究。

Abstract: Understanding user behaviors on social media has garnered significant scholarly attention, enhancing our comprehension of how virtual platforms impact society and empowering decision-makers. Simulating social media behaviors provides a robust tool for capturing the patterns of social media behaviors, testing hypotheses, and predicting the effects of various interventions, ultimately contributing to a deeper understanding of social media environments. Moreover, it can overcome difficulties associated with utilizing real data for analysis, such as data accessibility issues, ethical concerns, and the complexity of processing large and heterogeneous datasets. However, researchers and stakeholders need more flexible platforms to investigate different user behaviors by simulating different scenarios and characters, which is not possible yet. Therefore, this paper introduces SimSpark, an interactive system including simulation algorithms and interactive visual interfaces which is capable of creating small simulated social media platforms with customizable characters and social environments. We address three key challenges: generating believable behaviors, validating simulation results, and supporting interactive control for generation and results analysis. A simulation workflow is introduced to generate believable behaviors of agents by utilizing large language models. A visual interface enables real-time parameter adjustment and process monitoring for customizing generation settings. A set of visualizations and interactions are also designed to display the models' outputs for further analysis. Effectiveness is evaluated through case studies, quantitative simulation model assessments, and expert interviews.

</details>


### [51] [Controlling Context: Generative AI at Work in Integrated Circuit Design and Other High-Precision Domains](https://arxiv.org/abs/2506.14567)
*Emanuel Moss,Elizabeth Watkins,Christopher Persaud,Passant Karunaratne,Dawn Nafus*

Main category: cs.HC

TL;DR: 生成式AI工具在工程领域的应用日益广泛，但高精度领域工程师如何保持对错误的警惕性，以及工具使用中的其他问题仍需研究。本文通过访谈集成电路设计领域的工程师及其合作者，分析了他们在使用生成式AI工具时面临的准确性及其他问题，并提出了通过提高交互性来缓解上下文控制难题的建议。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具在工程领域的普及，尤其是在高精度领域（如集成电路设计）中的使用增加，研究这些工具在准确性及其他方面带来的问题变得尤为重要。

Method: 通过对硬件和软件工程师及其合作者的访谈，分析他们在使用生成式AI工具时遇到的问题，并将这些问题映射到生成式AI系统的各个要素中。

Result: 研究发现，工程师在使用生成式AI工具时，最大的挑战之一是交互上下文的控制。

Conclusion: 建议通过提高交互控制的灵活性来缓解上下文控制的难题，以更好地支持高精度领域的工程师使用生成式AI工具。

Abstract: Generative AI tools have become more prevalent in engineering workflows, particularly through chatbots and code assistants. As the perceived accuracy of these tools improves, questions arise about whether and how those who work in high-precision domains might maintain vigilance for errors, and what other aspects of using such tools might trouble their work. This paper analyzes interviews with hardware and software engineers, and their collaborators, who work in integrated circuit design to identify the role accuracy plays in their use of generative AI tools and what other forms of trouble they face in using such tools. The paper inventories these forms of trouble, which are then mapped to elements of generative AI systems, to conclude that controlling the context of interactions between engineers and the generative AI tools is one of the largest challenges they face. The paper concludes with recommendations for mitigating this form of trouble by increasing the ability to control context interactively.

</details>


### [52] [Exploring MLLMs Perception of Network Visualization Principles](https://arxiv.org/abs/2506.14611)
*Jacob Miller,Markus Wallinger,Ludwig Felder,Timo Brand,Henry Förster,Johannes Zink,Chunyang Chen,Stephen Kobourov*

Main category: cs.HC

TL;DR: 论文测试了MLLMs在网络布局属性感知任务中能否达到人类水平，发现其在某些条件下表现优于非专家，甚至接近专家。提示工程可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究MLLMs在网络布局质量感知任务中的表现，验证其是否能达到人类专家的水平。

Method: 复现人类实验，比较GPT-4o和Gemini-2.5与人类的表现，并通过提示工程优化模型表现。

Result: MLLMs表现接近人类专家，优于非专家；提示工程可进一步提升性能。

Conclusion: MLLMs在网络布局感知任务中展现了类似人类的感知能力，提示工程对其性能有显著影响。

Abstract: In this paper, we test whether Multimodal Large Language Models (MLLMs) can match human-subject performance in tasks involving the perception of properties in network layouts. Specifically, we replicate a human-subject experiment about perceiving quality (namely stress) in network layouts using GPT-4o and Gemini-2.5. Our experiments show that giving MLLMs exactly the same study information as trained human participants results in a similar performance to human experts and exceeds the performance of untrained non-experts. Additionally, we show that prompt engineering that deviates from the human-subject experiment can lead to better-than-human performance in some settings. Interestingly, like human subjects, the MLLMs seem to rely on visual proxies rather than computing the actual value of stress, indicating some sense or facsimile of perception. Explanations from the models provide descriptions similar to those used by the human participants (e.g., even distribution of nodes and uniform edge lengths).

</details>


### [53] [How Viable are Energy Savings in Smart Homes? A Call to Embrace Rebound Effects in Sustainable HCI](https://arxiv.org/abs/2506.14653)
*Christina Bremer,Harshit Gujral,Michelle Lin,Lily Hinkers,Christoph Becker,Vlad C. Coroamă*

Main category: cs.HC

TL;DR: 本文探讨了计算、人机交互和智能家居研究中是否考虑了反弹效应及其机制，发现相关研究有限，并提出了HCI领域未来研究的行动分类。


<details>
  <summary>Details</summary>
Motivation: 数字技术被视为能源效率的关键推动力，但可能引发反弹效应，抵消节能效果。目前尚不清楚其他学科（如计算、HCI和智能家居研究）是否考虑了这一问题。

Method: 通过四个科学数据库和SIGCHI语料库进行文献映射。

Result: 发现反弹效应在研究中的关注有限，HCI领域有显著机会推进这一主题。

Conclusion: 提出了HCI领域应对反弹效应的行动分类，以帮助评估能源效率项目的可行性。

Abstract: As part of global climate action, digital technologies are seen as a key enabler of energy efficiency savings. A popular application domain for this work is smart homes. There is a risk, however, that these efficiency gains result in rebound effects, which reduce or even overcompensate the savings. Rebound effects are well-established in economics, but it is less clear whether they also inform smart energy research in other disciplines. In this paper, we ask: to what extent have rebound effects and their underlying mechanisms been considered in computing, HCI and smart home research? To answer this, we conducted a literature mapping drawing on four scientific databases and a SIGCHI corpus. Our results reveal limited consideration of rebound effects and significant opportunities for HCI to advance this topic. We conclude with a taxonomy of actions for HCI to address rebound effects and help determine the viability of energy efficiency projects.

</details>


### [54] [StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery](https://arxiv.org/abs/2506.14670)
*Jina Kim,Leeje Jang,Yao-Yi Chiang,Guanyu Wang,Michelle Pasco*

Main category: cs.HC

TL;DR: StreetLens是一种基于视觉语言模型（VLM）的自动化工具，用于高效、可扩展的社区环境评估，结合社会科学专业知识，支持研究者自定义分析流程。


<details>
  <summary>Details</summary>
Motivation: 传统社区研究方法耗时且依赖专家，现有自动化工具缺乏适应性和灵活性。StreetLens旨在通过定制化的VLM工作流，解决这一问题，实现高效分析。

Method: StreetLens结合社会科学协议设计问题，利用VLM生成街景图像的语义注释，支持研究者自定义提示词和数据集成。

Result: StreetLens能够从客观特征到主观感知生成丰富的注释，提供灵活、可扩展的分析工具，适用于多种研究设计和地理环境。

Conclusion: StreetLens通过将领域知识嵌入AI系统，推动社区研究向高效、灵活的方向发展，支持大规模研究。

Abstract: Traditionally, neighborhood studies have employed interviews, surveys, and manual image annotation guided by detailed protocols to identify environmental characteristics, including physical disorder, decay, street safety, and sociocultural symbols, and to examine their impact on developmental and health outcomes. While these methods yield rich insights, they are time-consuming and require intensive expert intervention. Recent technological advances, including vision-language models (VLMs), have begun to automate parts of this process; however, existing efforts are often ad hoc and lack adaptability across research designs and geographic contexts. In this demo paper, we present StreetLens, a human-centered, researcher-configurable workflow that embeds relevant social science expertise in a VLM for scalable neighborhood environmental assessments. StreetLens mimics the process of trained human coders by grounding the analysis in questions derived from established interview protocols, retrieving relevant street view imagery (SVI), and generating a wide spectrum of semantic annotations from objective features (e.g., the number of cars) to subjective perceptions (e.g., the sense of disorder in an image). By enabling researchers to define the VLM's role through domain-informed prompting, StreetLens places domain knowledge at the core of the analysis process. It also supports the integration of prior survey data to enhance robustness and expand the range of characteristics assessed across diverse settings. We provide a Google Colab notebook to make StreetLens accessible and extensible for researchers working with public or custom SVI datasets. StreetLens represents a shift toward flexible, agentic AI systems that work closely with researchers to accelerate and scale neighborhood studies.

</details>


### [55] [Design an Editable Speech-to-Sign-Language Transformer System: A Human-Centered AI Approach](https://arxiv.org/abs/2506.14677)
*Yingchao Li*

Main category: cs.HC

TL;DR: 提出了一种基于Transformer的实时手语动画系统，支持用户编辑和优化，显著提升了手语的自然性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决现有手语技术的局限性，增强自然性、表现力和用户参与度。

Method: 结合流式Conformer编码器和自回归Transformer-MDN解码器，通过用户可编辑的JSON中间层实现实时动画生成。

Result: 实验显示，用户编辑和反馈显著提升了理解度、自然性、可用性和信任度，同时降低了认知负荷。

Conclusion: 技术和用户参与的创新共同推动了可访问、可解释且用户自适应的手语AI技术。

Abstract: This paper presents a human-centered, real-time, user-adaptive speech-to-sign language animation system that integrates Transformer-based motion generation with a transparent, user-editable JSON intermediate layer. The framework overcomes key limitations in prior sign language technologies by enabling direct user inspection and modification of sign segments, thus enhancing naturalness, expressiveness, and user agency. Leveraging a streaming Conformer encoder and autoregressive Transformer-MDN decoder, the system synchronizes spoken input into upper-body and facial motion for 3D avatar rendering. Edits and user ratings feed into a human-in-the-loop optimization loop for continuous improvement. Experiments with 20 deaf signers and 5 interpreters show that the editable interface and participatory feedback significantly improve comprehension, naturalness, usability, and trust, while lowering cognitive load. With sub-20 ms per-frame inference on standard hardware, the system is ready for real-time communication and education. This work illustrates how technical and participatory innovation together enable accessible, explainable, and user-adaptive AI for sign language technology.

</details>


### [56] [How Warm-Glow Alters the Usability of Technology](https://arxiv.org/abs/2506.14720)
*Antonios Saravanos*

Main category: cs.HC

TL;DR: 传统可用性模型可能无法完全捕捉技术如何与用户价值观对齐，本研究探讨了“温暖效应”对感知可用性的影响。


<details>
  <summary>Details</summary>
Motivation: 技术逐渐与用户个人价值观对齐，传统功能性可用性模型可能不完全适用。

Method: 采用实验方法，参与者评估假设技术，诱发内在或外在温暖效应。

Result: 内在温暖效应显著增强所有感知可用性维度，外在效应仅影响效果和满意度。

Conclusion: 设计师应考虑将温暖效应融入技术设计，以增强用户感知可用性。

Abstract: As technology increasingly aligns with users' personal values, traditional models of usability, focused on functionality and specifically effectiveness, efficiency, and satisfaction, may not fully capture how people perceive and evaluate it. This study investigates how the warm-glow phenomenon, the positive feeling associated with doing good, shapes perceived usability. An experimental approach was taken in which participants evaluated a hypothetical technology under conditions designed to evoke either the intrinsic (i.e., personal fulfillment) or extrinsic (i.e., social recognition) dimensions of warm-glow. A Multivariate Analysis of Variance as well as subsequent follow-up analyses revealed that intrinsic warm-glow significantly enhances all dimensions of perceived usability, while extrinsic warm-glow selectively influences perceived effectiveness and satisfaction. These findings suggest that perceptions of usability extend beyond functionality and are shaped by how technology resonates with users' broader sense of purpose. We conclude by proposing that designers consider incorporating warm-glow into technology as a strategic design decision.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [57] [ReFrame: Layer Caching for Accelerated Inference in Real-Time Rendering](https://arxiv.org/abs/2506.13814)
*Lufei Liu,Tor M. Aamodt*

Main category: cs.GR

TL;DR: 论文提出一种名为ReFrame的缓存策略，用于优化实时渲染中神经网络的计算效率，通过重用中间特征减少冗余计算，实现1.4倍的加速且质量损失可忽略。


<details>
  <summary>Details</summary>
Motivation: 实时渲染中，神经网络的中间计算结果具有时间相关性，重用这些结果可以减少冗余计算，提高效率。

Method: 提出ReFrame框架，探索不同缓存策略，优化渲染任务中质量与性能的权衡，适用于常见的编码器-解码器风格网络。

Result: 实验显示，在三个实时渲染任务中，平均实现1.4倍的加速，且质量损失可忽略。

Conclusion: ReFrame通过有效重用中间特征，显著提升了实时渲染的效率，为渲染管道的优化提供了新思路。

Abstract: Graphics rendering applications increasingly leverage neural networks in tasks such as denoising, supersampling, and frame extrapolation to improve image quality while maintaining frame rates. The temporal coherence inherent in these tasks presents an opportunity to reuse intermediate results from previous frames and avoid redundant computations. Recent work has shown that caching intermediate features to be reused in subsequent inferences is an effective method to reduce latency in diffusion models. We extend this idea to real-time rendering and present ReFrame, which explores different caching policies to optimize trade-offs between quality and performance in rendering workloads. ReFrame can be applied to a variety of encoder-decoder style networks commonly found in rendering pipelines. Experimental results show that we achieve 1.4x speedup on average with negligible quality loss in three real-time rendering tasks. Code available: https://ubc-aamodt-group.github.io/reframe-layer-caching/

</details>


### [58] [Balancing Preservation and Modification: A Region and Semantic Aware Metric for Instruction-Based Image Editing](https://arxiv.org/abs/2506.13827)
*Zhuoying Li,Zhu Xu,Yuxin Peng,Yang Liu*

Main category: cs.GR

TL;DR: 提出了一种名为BPM的新指标，专为基于指令的图像编辑设计，通过分离编辑相关和无关区域，结合区域和语义感知评估，提供更全面的质量评估。


<details>
  <summary>Details</summary>
Motivation: 现有的指标要么人力成本高，要么无法全面评估基于指令的编辑任务，导致评估偏差。

Method: BPM首先定位编辑相关区域，然后通过区域感知和语义感知两个步骤评估编辑质量和无关区域的内容保留。

Result: BPM与人类评估的匹配度最高，验证了其有效性。

Conclusion: BPM为基于指令的图像编辑提供了全面且可解释的评估方法，并可应用于改进编辑质量。

Abstract: Instruction-based image editing, which aims to modify the image faithfully according to the instruction while preserving irrelevant content unchanged, has made significant progress. However, there still lacks a comprehensive metric for assessing the editing quality. Existing metrics either require high human evaluation costs, which hinder large-scale evaluation, or are adapted from other tasks and lose task-specific concerns, failing to comprehensively evaluate both instruction-based modification and preservation of irrelevant regions, resulting in biased evaluation. To tackle this, we introduce a new metric called Balancing Preservation and Modification (BPM), tailored for instruction-based image editing by explicitly disentangling the image into editing-relevant and irrelevant regions for specific consideration. We first identify and locate editing-relevant regions, followed by a two-tier process to assess editing quality: Region-Aware Judge evaluates whether the position and size of the edited region align with the instruction, and Semantic-Aware Judge further assesses the instruction content compliance within editing-relevant regions as well as content preservation within irrelevant regions, yielding comprehensive and interpretable quality assessment. Moreover, the editing-relevant region localization in BPM can be integrated into image editing approaches to improve editing quality, demonstrating its broad applicability. We verify the effectiveness of the BPM metric on comprehensive instruction-editing data, and the results show the highest alignment with human evaluation compared to existing metrics, indicating its efficacy. Code is available at: https://joyli-x.github.io/BPM/

</details>


### [59] [Innovating China's Intangible Cultural Heritage with DeepSeek + MidJourney: The Case of Yangliuqing theme Woodblock Prints](https://arxiv.org/abs/2506.14104)
*RuiKun Yang,ZhongLiang Wei,Longdi Xian*

Main category: cs.GR

TL;DR: 研究采用DeepSeek + MidJourney方法生成以COVID-19为主题和欢乐获胜者为主题的杨柳青木版年画，结合传统元素与现代AI创造力，FID评分最优，参与者反馈积极。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在保护传统杨柳青木版年画的同时，通过AI技术推动其创新发展，解决传统与现代结合的挑战。

Method: 结合DeepSeek生成的主题提示和MidJourney生成的图像，使用FID评分和问卷（62人）评估效果。

Result: 混合方法FID得分最低（150.2，σ=4.9），参与者认为最具代表性，且对推广传统文化和消费AI生成图像兴趣最高。

Conclusion: 该方法有效结合传统艺术与现代AI创新，既保护文化遗产，又赋予其当代价值。

Abstract: Yangliuqing woodblock prints, a cornerstone of China's intangible cultural heritage, are celebrated for their intricate designs and vibrant colors. However, preserving these traditional art forms while fostering innovation presents significant challenges. This study explores the DeepSeek + MidJourney approach to generating creative, themed Yangliuqing woodblock prints focused on the fight against COVID-19 and depicting joyous winners. Using Fréchet Inception Distance (FID) scores for evaluation, the method that combined DeepSeek-generated thematic prompts, MidJourney-generated thematic images, original Yangliuqing prints, and DeepSeek-generated key prompts in MidJourney-generated outputs achieved the lowest mean FID score (150.2) with minimal variability (σ = 4.9). Additionally, feedback from 62 participants, collected via questionnaires, confirmed that this hybrid approach produced the most representative results. Moreover, the questionnaire data revealed that participants demonstrated the highest willingness to promote traditional culture and the strongest interest in consuming the AI-generated images produced through this method. These findings underscore the effectiveness of an innovative approach that seamlessly blends traditional artistic elements with modern AI-driven creativity, ensuring both cultural preservation and contemporary relevance.

</details>


### [60] [ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies](https://arxiv.org/abs/2506.14315)
*Jinyan Yuan,Bangbang Yang,Keke Wang,Panwang Pan,Lin Ma,Xuehai Zhang,Xiao Liu,Zhaopeng Cui,Yuewen Ma*

Main category: cs.GR

TL;DR: 提出了ImmerseGen框架，通过轻量级几何代理和RGBA纹理合成实现逼真的3D场景生成，简化建模过程并提升渲染效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D场景生成方法依赖高精度网格或复杂管道的问题，探索更简洁、逼真的沉浸式体验方案。

Method: 使用分层几何代理（如简化地形和广告牌网格）和RGBA纹理合成，结合VLM代理进行文本提示驱动的场景生成。

Result: 实验表明，ImmerseGen在逼真度、空间一致性和渲染效率上优于现有方法。

Conclusion: ImmerseGen通过轻量级代理和纹理合成，为沉浸式VR提供了高效且逼真的场景生成方案。

Abstract: Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery.This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based modeling agents enhanced with semantic grid-based analysis for improved spatial reasoning and accurate asset placement. ImmerseGen further enriches scenes with dynamic effects and ambient audio to support multisensory immersion. Experiments on scene generation and live VR showcases demonstrate that ImmerseGen achieves superior photorealism, spatial coherence and rendering efficiency compared to prior methods. Project webpage: https://immersegen.github.io.

</details>


### [61] [GHAR: GeoPose-based Handheld Augmented Reality for Architectural Positioning, Manipulation and Visual Exploration](https://arxiv.org/abs/2506.14414)
*Sabahat Israr,Dawar Khan,Zhanglin Cheng,Mukhtaj Khan,Kiyoshi Kiyokawa*

Main category: cs.GR

TL;DR: 论文提出了一种基于GeoPose的无标记手持增强现实框架GHAR，用于建筑模型的可视化和操作，显著优于传统标记方法。


<details>
  <summary>Details</summary>
Motivation: 解决标记技术在HAR中的局限性，如使用困难、光照敏感和标记设计问题。

Method: 采用GeoPose跟踪技术，结合手势操作，实现7自由度控制，并开发了GHAR框架用于建筑模型增强现实。

Result: 通过用户研究发现，无标记GHAR在可用性、操作性和理解性上显著优于基于标记的HAR。

Conclusion: 无标记GHAR框架在建筑领域展示了更高的实用性和用户友好性，为建筑规划和需求分析提供了高效工具。

Abstract: Handheld Augmented Reality (HAR) is revolutionizing the civil infrastructure application domain. The current trend in HAR relies on marker tracking technology. However, marker-based systems have several limitations, such as difficulty in use and installation, sensitivity to light, and marker design. In this paper, we propose a markerless HAR framework with GeoPose-based tracking. We use different gestures for manipulation and achieve 7 DOF (3 DOF each for translation and rotation, and 1 DOF for scaling). The proposed framework, called GHAR, is implemented for architectural building models. It augments virtual CAD models of buildings on the ground, enabling users to manipulate and visualize an architectural model before actual construction. The system offers a quick view of the building infrastructure, playing a vital role in requirement analysis and planning in construction technology. We evaluated the usability, manipulability, and comprehensibility of the proposed system using a standard user study with the System Usability Scale (SUS) and Handheld Augmented Reality User Study (HARUS). We compared our GeoPose-based markerless HAR framework with a marker-based HAR framework, finding significant improvement in the aforementioned three parameters with the markerless framework.

</details>


### [62] [SkinCells: Sparse Skinning using Voronoi Cells](https://arxiv.org/abs/2506.14714)
*Egor Larionov,Igor Santesteban,Hsiao-yu Chen,Gene Lin,Philipp Herholz,Ryan Goldade,Ladislav Kavan,Doug Roble,Tuur Stuyck*

Main category: cs.GR

TL;DR: 提出了一种全自动且鲁棒的皮肤权重生成方法，适用于用户提供的骨架和网格，可直接控制稀疏性，并支持多级别细节优化。


<details>
  <summary>Details</summary>
Motivation: 当前皮肤权重生成多为手动或自动化工具效果不佳，尤其在复杂几何体上，需手动调整，影响大规模移动应用的效率。

Method: 引入新颖的SkinCells函数族，在空间而非离散点上优化权重，支持稀疏控制和多级别细节应用。

Result: 方法在双调和权重计算失败时仍能鲁棒生成高质量皮肤权重，适用于移动平台大规模应用。

Conclusion: 提出的SkinCells方法全自动且高效，解决了复杂几何体的皮肤权重生成问题，适合多级别细节需求的应用。

Abstract: For decades, efficient real-time skinning methods have played a crucial role in animating character rigs for visual effects and games. These methods remain a fundamental component of modern applications. However, animatable digital asset creation predominantly remains a manual process. Current automated tools often fall short of delivering the desired level of quality for intricate and complex geometries, requiring manual touch-ups. We propose a fully automatic and robust method for generating high quality skinning weights given a user-provided skeleton and mesh in A- or T-pose. Notably, our approach provides direct sparsity controls, limiting the number of bone influences per vertex, which is essential for efficient asset creation for large-scale mobile experiences with multiple concurrent users. Our method additionally addresses the need for level-of-detail (LoD) variations in performance-sensitive applications, which are exacerbated on mobile platforms. By optimizing weights in space rather than on discrete points, we enable a single optimization result to be seamlessly applied to all levels of detail of that asset or even variations of that asset. To achieve this, we introduce a novel parameterized family of functions called SkinCells. We demonstrate how our automatic method is able to robustly compute skinning weights in cases where biharmonic weight computation fails.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [63] [Intrinsic Annealing in a Hybrid Memristor-Magnetic Tunnel Junction Ising Machine](https://arxiv.org/abs/2506.14676)
*Mohammed Akib Iftakher,Hugo Levices,Kamel-Eddine Harabi,Adrien Renaudineau,Mathieu-Coumba Faye,Corentin Bouchard,Florian Disdier,Bernard Viala,Elisa Vianello,Philippe Talatchian,Kevin Garello,Damien Querlioz,Louis Hutin*

Main category: cs.ET

TL;DR: 论文介绍了一种结合忆阻器交叉阵列和随机磁性隧道结的伊辛机，用于高效解决大规模优化问题。


<details>
  <summary>Details</summary>
Motivation: 理想的伊辛机需要协同工作的纳米器件支持退火过程，但目前缺乏将两种关键器件结合的方案。

Method: 使用忆阻器交叉阵列存储多级耦合，随机磁性隧道结作为热驱动自旋，通过读取电压自动调节机器温度以实现退火。

Result: 原型机在零磁场下成功解决了24顶点加权MAX-CUT和10顶点三色图着色问题。

Conclusion: 该方案兼容CMOS技术，为紧凑、快速且高效的大规模伊辛求解器提供了可扩展路径。

Abstract: Hardware implementations of the Ising model offer promising solutions to large-scale optimization tasks. In the literature, various nanodevices have been shown to emulate the spin dynamics for such Ising machines with remarkable effectiveness. Other nanodevices have been shown to implement spin-spin coupling with compact footprint and minimal energy dissipation. However, an ideal Ising machine would associate both types of nanodevices, and they must operate synergistically to support annealing: a progressive reduction of machine stochasticity that allows it to settle to energy minimum. Here, we report an Ising machine that combines two nanotechnologies: memristor crossbar -- storing multi-level couplings -- and stochastic magnetic tunnel junction (SMTJ), acting as thermally driven spins. Because the same read voltage that interrogates the crossbar also biases the SMTJs, increasing this voltage automatically lowers the effective temperature of the machine, providing an intrinsic, nearly circuit-free annealing technique. Operating at zero magnetic field, our prototype consistently reaches the global optimum of a 24-vertex weighted MAX-CUT and a 10-vertex, three-color graph-coloring problem. Given that both nanotechnologies in our demonstrator are CMOS-integrated, this approach is compatible with advanced 3D integration, offering a scalable pathway toward compact, fast, and energy-efficient large-scale Ising solvers.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [64] [DAGs for the Masses](https://arxiv.org/abs/2506.13998)
*Michael Anoprenko,Andrei Tonkikh,Alexander Spiegelman,Petr Kuznetsov*

Main category: cs.DC

TL;DR: 论文提出了一种稀疏DAG架构，通过减少节点间的引用数量来提升可扩展性，同时保持与原始协议相同的容错能力。


<details>
  <summary>Details</summary>
Motivation: 现有的DAG协议因节点引用过多而导致可扩展性受限，阻碍大规模部署。

Method: 提出稀疏DAG架构，每个节点仅引用前一轮中的少数随机节点，并基于Bullshark协议实现了一个稀疏版本。

Result: 稀疏DAG在保持$f<n/3$容错能力的同时显著提升网络利用率和可扩展性。

Conclusion: 稀疏DAG方法可推广到类似的图结构协议中，为大规模部署提供了有效解决方案。

Abstract: A recent approach to building consensus protocols on top of Directed Acyclic Graphs (DAGs) shows much promise due to its simplicity and stable throughput. However, as each node in the DAG typically includes a linear number of references to the nodes in the previous round, prior DAG protocols only scale up to a certain point when the overhead of maintaining the graph becomes the bottleneck.
  To enable large-scale deployments of DAG-based protocols, we propose a sparse DAG architecture, where each node includes only a constant number of references to random nodes in the previous round. We present a sparse version of Bullshark -- one of the most prominent DAG-based consensus protocols -- and demonstrate its improved scalability.
  Remarkably, unlike other protocols that use random sampling to reduce communication complexity, we manage to avoid sacrificing resilience: the protocol can tolerate up to $f<n/3$ Byzantine faults (where $n$ is the number of participants), same as its less scalable deterministic counterpart. The proposed ``sparse'' methodology can be applied to any protocol that maintains disseminated system updates and causal relations between them in a graph-like structure. Our simulations show that the considerable reduction of transmitted metadata in sparse DAGs results in more efficient network utilization and better scalability.

</details>


### [65] [Déjà Vu: Efficient Video-Language Query Engine with Learning-based Inter-Frame Computation Reuse](https://arxiv.org/abs/2506.14107)
*Jinwoo Hwang,Daeun Kim,Sangyeop Lee,Yoonsung Kim,Guseul Heo,Hojoon Kim,Yunseok Jeong,Tadiwos Meaza,Eunhyeok Park,Jeongseob Ahn,Jongse Park*

Main category: cs.DC

TL;DR: Déjà Vu是一种视频语言查询引擎，通过重用计算加速ViT-based VideoLMs，提升大规模视频分析的实用性。


<details>
  <summary>Details</summary>
Motivation: 当前VideoLMs生成大规模视频嵌入时计算开销大，阻碍实际应用，需解决与可扩展视频数据管理系统的集成问题。

Method: 提出ReuseViT，一种改进的ViT模型，检测帧间重用机会，并结合内存-计算联合压缩技术实现性能提升。

Result: 在三个VideoLM任务中，Déjà Vu将嵌入生成速度提升最高2.64倍，误差控制在2%以内。

Conclusion: Déjà Vu有效平衡了准确性与重用，显著提升了VideoLMs在大规模视频分析中的实用性。

Abstract: Recently, Video-Language Models (VideoLMs) have demonstrated remarkable capabilities, offering significant potential for flexible and powerful video query systems. These models typically rely on Vision Transformers (ViTs), which process video frames individually to extract visual embeddings. However, generating embeddings for large-scale videos requires ViT inferencing across numerous frames, posing a major hurdle to real-world deployment and necessitating solutions for integration into scalable video data management systems. This paper introduces Déjà Vu, a video-language query engine that accelerates ViT-based VideoLMs by reusing computations across consecutive frames. At its core is ReuseViT, a modified ViT model specifically designed for VideoLM tasks, which learns to detect inter-frame reuse opportunities, striking an effective balance between accuracy and reuse. Although ReuseViT significantly reduces computation, these savings do not directly translate into performance gains on GPUs. To overcome this, Déjà Vu integrates memory-compute joint compaction techniques that convert the FLOP savings into tangible performance gains. Evaluations on three VideoLM tasks show that Déjà Vu accelerates embedding generation by up to a 2.64x within a 2% error bound, dramatically enhancing the practicality of VideoLMs for large-scale video analytics.

</details>


### [66] [The Redundancy of Full Nodes in Bitcoin: A Network-Theoretic Demonstration of Miner-Centric Propagation Topologies](https://arxiv.org/abs/2506.14197)
*Dr Craig S Wright*

Main category: cs.DC

TL;DR: 该论文运用复杂图论分析了BTC和BSV的网络结构，发现家庭托管的全节点无法参与或影响传播拓扑，传播主要由矿工群体主导。


<details>
  <summary>Details</summary>
Motivation: 研究目的是揭示BTC和BSV网络中全节点的实际作用及其在网络拓扑中的位置。

Method: 采用复杂图论、无标度网络和小世界连接模型，通过模拟和特征值中心性分析验证。

Result: 全节点位于网络边缘，无法影响交易到区块的路径，对于共识传播无关键作用。

Conclusion: 全节点在BTC和BSV网络中既非关键也无操作相关性，传播主要由矿工群体主导。

Abstract: This paper formally examines the network structure of Bitcoin CORE (BTC) and Bitcoin Satoshi Vision (BSV) using complex graph theory to demonstrate that home-hosted full nodes are incapable of participating in or influencing the propagation topology. Leveraging established models such as scale-free networks and small-world connectivity, we demonstrate that the propagation graph is dominated by a densely interconnected miner clique, while full nodes reside on the periphery, excluded from all transaction-to-block inclusion paths. Using simulation-backed metrics and eigenvalue centrality analysis, we confirm that full nodes are neither critical nor operationally relevant for consensus propagation.

</details>


### [67] [A Novel Indicator for Quantifying and Minimizing Information Utility Loss of Robot Teams](https://arxiv.org/abs/2506.14237)
*Xiyu Zhao,Qimei Cui,Wei Ni,Quan Z. Sheng,Abbas Jamalipour,Guoshun Nan,Xiaofeng Tao,Ping Zhang*

Main category: cs.DC

TL;DR: 论文提出了一种名为“信息效用损失”（LoIU）的新指标，用于量化机器人团队协作中信息的新鲜度和效用，并通过半分散式多智能体深度确定性策略梯度框架优化传输调度和资源分配，显著提升了信息的新鲜度和效用。


<details>
  <summary>Details</summary>
Motivation: 机器人团队协作中，信息的及时交换受限会导致估计误差，影响协作效果。现有方法在带宽限制下难以高效分配资源，因此需要新指标和优化方法。

Method: 提出LoIU指标，结合置信分布估计LoIU。开发半分散式多智能体策略梯度框架，机器人作为执行者调度传输，中央评论者定期优化其行为。

Result: 仿真显示，该方法将信息新鲜度和效用提升了98%，显著优于其他方法。

Conclusion: LoIU指标和优化框架能有效提升机器人团队协作中的信息交换效率，具有实际应用潜力。

Abstract: The timely exchange of information among robots within a team is vital, but it can be constrained by limited wireless capacity. The inability to deliver information promptly can result in estimation errors that impact collaborative efforts among robots. In this paper, we propose a new metric termed Loss of Information Utility (LoIU) to quantify the freshness and utility of information critical for cooperation. The metric enables robots to prioritize information transmissions within bandwidth constraints. We also propose the estimation of LoIU using belief distributions and accordingly optimize both transmission schedule and resource allocation strategy for device-to-device transmissions to minimize the time-average LoIU within a robot team. A semi-decentralized Multi-Agent Deep Deterministic Policy Gradient framework is developed, where each robot functions as an actor responsible for scheduling transmissions among its collaborators while a central critic periodically evaluates and refines the actors in response to mobility and interference. Simulations validate the effectiveness of our approach, demonstrating an enhancement of information freshness and utility by 98%, compared to alternative methods.

</details>


### [68] [Concepts for designing modern C++ interfaces for MPI](https://arxiv.org/abs/2506.14610)
*C. Nicole Avans,Alfredo A. Correa,Sayan Ghosh,Matthias Schimek,Joseph Schuchart,Anthony Skjellum,Evan D. Suggs,Tim Niklas Uhl*

Main category: cs.DC

TL;DR: 该论文探讨了现代C++与MPI语义之间的不协调问题，提出聚焦类型系统、对象生命周期和通信缓冲区三个关键方面。


<details>
  <summary>Details</summary>
Motivation: 随着现代C++和异构编程模型的兴起，社区需要高性能、可移植且符合C++编程原则的MPI接口。

Method: 论文聚焦类型系统、对象生命周期和通信缓冲区，并识别MPI规范中的不一致性。

Result: 未提出具体解决方案，而是呼吁MPI和C++社区共同探讨。

Conclusion: 未来的高性能C++ MPI接口需平衡C++编程原则与MPI核心性能/可移植性要求。

Abstract: Since the C++ bindings were deleted in 2008, the Message Passing Interface (MPI) community has revived efforts in building high-level modern C++ interfaces. Such interfaces are either built to serve specific scientific application needs (with limited coverage to the underlying MPI functionalities), or as an exercise in general-purpose programming model building, with the hope that bespoke interfaces can be broadly adopted to construct a variety of distributed-memory scientific applications. However, with the advent of modern C++-based heterogeneous programming models, GPUs and widespread Machine Learning (ML) usage in contemporary scientific computing, the role of prospective community-standardized high-level C++ interfaces to MPI is evolving. The success of such an interface clearly will depend on providing robust abstractions and features adhering to the generic programming principles that underpin the C++ programming language, without compromising on either performance and portability, the core principles upon which MPI was founded. However, there is a tension between idiomatic C++ handling of types and lifetimes, and, MPI's loose interpretation of object lifetimes/ownership and insistence on maintaining global states.
  Instead of proposing "yet another" high-level C++ interface to MPI, overlooking or providing partial solutions to work around the key issues concerning the dissonance between MPI semantics and idiomatic C++, this paper focuses on the three fundamental aspects of a high-level interface: type system, object lifetimes and communication buffers, also identifying inconsistencies in the MPI specification. Presumptive solutions can be unrefined, and we hope the broader MPI and C++ communities will engage with us in productive exchange of ideas and concerns.

</details>


### [69] [Keigo: Co-designing Log-Structured Merge Key-Value Stores with a Non-Volatile, Concurrency-aware Storage Hierarchy (Extended Version)](https://arxiv.org/abs/2506.14630)
*Rúben Adão,Zhongjie Wu,Changjun Zhou,Oana Balmau,João Paulo,Ricardo Macedo*

Main category: cs.DC

TL;DR: Keigo是一种存储中间件，通过并发和工作负载感知优化LSM KVS在异构存储设备上的性能，提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有LSM KVS在异构存储设备上的数据放置无法适应所有工作负载，需要动态优化。

Method: 采用并发感知数据放置、持久只读缓存和基于上下文的I/O区分三种技术。

Result: Keigo显著提升了读写性能，写入和读取吞吐量分别提升至4倍和18倍。

Conclusion: Keigo为生产级LSM KVS提供了便携且高效的异构存储解决方案。

Abstract: We present Keigo, a concurrency- and workload-aware storage middleware that enhances the performance of log-structured merge key-value stores (LSM KVS) when they are deployed on a hierarchy of storage devices. The key observation behind Keigo is that there is no one-size-fits-all placement of data across the storage hierarchy that optimizes for all workloads. Hence, to leverage the benefits of combining different storage devices, Keigo places files across different devices based on their parallelism, I/O bandwidth, and capacity. We introduce three techniques - concurrency-aware data placement, persistent read-only caching, and context-based I/O differentiation. Keigo is portable across different LSMs, is adaptable to dynamic workloads, and does not require extensive profiling. Our system enables established production KVS such as RocksDB, LevelDB, and Speedb to benefit from heterogeneous storage setups. We evaluate Keigo using synthetic and realistic workloads, showing that it improves the throughput of production-grade LSMs up to 4x for write- and 18x for read-heavy workloads when compared to general-purpose storage systems and specialized LSM KVS.

</details>


### [70] [Resource Optimization with MPI Process Malleability for Dynamic Workloads in HPC Clusters](https://arxiv.org/abs/2506.14743)
*Sergio Iserte,Iker Martín-Álvarez,Krzysztof Rojek,José I. Aliaga,Maribel Castillo,Weronika Folwarska,Antonio J. Peña*

Main category: cs.DC

TL;DR: 本文研究了高性能计算（HPC）环境中的动态资源管理，通过扩展DMR框架并整合Proteo的可扩展性模块，提出了新的策略，显著提升了资源利用率和效率。


<details>
  <summary>Details</summary>
Motivation: 现代HPC环境中，动态资源管理对优化计算效率至关重要，但由于标准化、互操作性和可用性等问题，生产环境中可扩展技术的应用仍然有限。

Method: 扩展了DMR框架，整合了Proteo的可扩展性模块（MaM），引入了新的MPI通信合并和异步重新配置策略。

Result: 在世界级超级计算机上的评估显示，动态资源管理可将工作负载完成时间减少40%，资源利用率提升20%以上。

Conclusion: 动态资源管理通过新策略显著优化了HPC环境中的资源利用和效率。

Abstract: Dynamic resource management is essential for optimizing computational efficiency in modern high-performance computing (HPC) environments, particularly as systems scale. While research has demonstrated the benefits of malleability in resource management systems (RMS), the adoption of such techniques in production environments remains limited due to challenges in standardization, interoperability, and usability. Addressing these gaps, this paper extends our prior work on the Dynamic Management of Resources (DMR) framework, which provides a modular and user-friendly approach to dynamic resource allocation. Building upon the original DMRlib reconfiguration runtime, this work integrates new methodology from the Malleability Module (MaM) of the Proteo framework, further enhancing reconfiguration capabilities with new spawning strategies and data redistribution methods. In this paper, we explore new malleability strategies in HPC dynamic workloads, such as merging MPI communicators and asynchronous reconfigurations, which offer new opportunities for dramatically reducing memory overhead. The proposed enhancements are rigorously evaluated on a world-class supercomputer, demonstrating improved resource utilization and workload efficiency. Results show that dynamic resource management can reduce the workload completion time by 40% and increase the resource utilization by over 20%, compared to static resource allocation.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [71] [LLM-Driven Data Generation and a Novel Soft Metric for Evaluating Text-to-SQL in Aviation MRO](https://arxiv.org/abs/2506.13785)
*Patrick Sutanto,Jonathan Kenrick,Max Lorenz,Joan Santoso*

Main category: cs.DB

TL;DR: 该论文提出了一种基于F1分数的‘软’度量标准来评估文本到SQL任务的信息重叠，并设计了一个LLM驱动的管道生成领域特定的问题-SQL对。实验表明，这些方法在航空维修领域取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法（如执行准确率）过于刚性且反馈粗糙，同时缺乏领域特定的数据集，限制了LLM在文本到SQL任务中的应用。

Method: 引入基于F1分数的软度量标准和LLM驱动的数据生成管道。

Result: 实验验证了软度量标准的优越性和数据生成管道的有效性。

Conclusion: 论文提出的框架为专业领域中的文本到SQL系统提供了更可靠的评估和发展工具。

Abstract: The application of Large Language Models (LLMs) to text-to-SQL tasks promises to democratize data access, particularly in critical industries like aviation Maintenance, Repair, and Operation (MRO). However, progress is hindered by two key challenges: the rigidity of conventional evaluation metrics such as execution accuracy, which offer coarse, binary feedback, and the scarcity of domain-specific evaluation datasets. This paper addresses these gaps. To enable more nuanced assessment, we introduce a novel F1-score-based 'soft' metric that quantifies the informational overlap between generated and ground-truth SQL results. To address data scarcity, we propose an LLM-driven pipeline that synthesizes realistic question-SQL pairs from database schemas. We demonstrate our contributions through an empirical evaluation on an authentic MRO database. Our experiments show that the proposed soft metric provides more insightful performance analysis than strict accuracy, and our data generation technique is effective in creating a domain-specific benchmark. Together, these contributions offer a robust framework for evaluating and advancing text-to-SQL systems in specialized environments.

</details>


### [72] [Sketched Sum-Product Networks for Joins](https://arxiv.org/abs/2506.14034)
*Brian Tsan,Abylay Amanbayev,Asoke Datta,Florin Rusu*

Main category: cs.DB

TL;DR: 提出使用Sum-Product Networks动态近似草图的方法，解决传统草图需预先构建且无法适应新查询的问题，用于多路连接基数估计。


<details>
  <summary>Details</summary>
Motivation: 传统草图方法在查询优化中高效但需预先构建，限制了其在新查询中的应用，需要更通用的解决方案。

Method: 利用Sum-Product Networks动态近似草图，通过分解和建模多变量分布为多个单变量分布的线性组合，进而高效近似查询选择的草图。

Result: 实现了Fast-AGMS和Bound Sketch方法的近似版本，为查询优化提供了实用替代方案。

Conclusion: 动态近似草图方法扩展了草图技术的适用性，使其能更灵活地应用于多路连接基数估计。

Abstract: Sketches have shown high accuracy in multi-way join cardinality estimation, a critical problem in cost-based query optimization. Accurately estimating the cardinality of a join operation -- analogous to its computational cost -- allows the optimization of query execution costs in relational database systems. However, although sketches have shown high efficacy in query optimization, they are typically constructed specifically for predefined selections in queries that are assumed to be given a priori, hindering their applicability to new queries. As a more general solution, we propose for Sum-Product Networks to dynamically approximate sketches on-the-fly. Sum-Product Networks can decompose and model multivariate distributions, such as relations, as linear combinations of multiple univariate distributions. By representing these univariate distributions as sketches, Sum-Product Networks can combine them element-wise to efficiently approximate the sketch of any query selection. These approximate sketches can then be applied to join cardinality estimation. In particular, we implement the Fast-AGMS and Bound Sketch methods, which have successfully been used in prior work, despite their costly construction. By accurately approximating them instead, our work provides a practical alternative to apply these sketches to query optimization.

</details>


### [73] [HARMONY: A Scalable Distributed Vector Database for High-Throughput Approximate Nearest Neighbor Search](https://arxiv.org/abs/2506.14707)
*Qian Xu,Feng Zhang,Chengxi Li,Lei Cao,Zheng Chen,Jidong Zhai,Xiaoyong Du*

Main category: cs.DB

TL;DR: 论文提出了一种名为Harmony的分布式近似最近邻搜索系统，采用多粒度分区策略和提前停止剪枝机制，显著提升了负载均衡和通信效率，实验显示性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大规模高维向量数据（如推荐系统、图像检索）在单机上处理的存储和计算挑战，以及现有分布式方法在负载均衡和通信开销上的不足。

Method: 提出多粒度分区策略（结合维度分区和向量分区）和基于单调性的提前停止剪枝机制。

Result: 在四个节点上的平均吞吐量提升4.63倍，对倾斜负载的性能提升58%。

Conclusion: Harmony通过创新的分区和优化技术，显著提升了分布式ANNS的性能和效率。

Abstract: Approximate Nearest Neighbor Search (ANNS) is essential for various data-intensive applications, including recommendation systems, image retrieval, and machine learning. Scaling ANNS to handle billions of high-dimensional vectors on a single machine presents significant challenges in memory capacity and processing efficiency. To address these challenges, distributed vector databases leverage multiple nodes for the parallel storage and processing of vectors. However, existing solutions often suffer from load imbalance and high communication overhead, primarily due to traditional partition strategies that fail to effectively distribute the workload. In this paper, we introduce Harmony, a distributed ANNS system that employs a novel multi-granularity partition strategy, combining dimension-based and vector-based partition. This strategy ensures a balanced distribution of computational load across all nodes while effectively minimizing communication costs. Furthermore, Harmony incorporates an early-stop pruning mechanism that leverages the monotonicity of distance computations in dimension-based partition, resulting in significant reductions in both computational and communication overhead. We conducted extensive experiments on diverse real-world datasets, demonstrating that Harmony outperforms leading distributed vector databases, achieving 4.63 times throughput on average in four nodes and 58% performance improvement over traditional distribution for skewed workloads.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [74] [Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems](https://arxiv.org/abs/2506.13905)
*Zhongzhi Yu,Mingjie Liu,Michael Zimmer,Yingyan Celine Lin,Yong Liu,Haoxing Ren*

Main category: cs.AR

TL;DR: 该论文提出了一种名为Spec2RTL-Agent的多智能体系统，旨在直接从复杂的需求文档生成RTL代码，填补了LLM在RTL代码生成领域的实际应用空白。


<details>
  <summary>Details</summary>
Motivation: 现有方法在RTL代码生成中存在实际应用场景与需求之间的差距，要么过于简化硬件描述，要么依赖大量人工指导。本文旨在通过多智能体协作框架解决这一问题。

Method: 系统采用多智能体协作框架，包括三个模块：推理与理解模块、渐进式编码与提示优化模块以及自适应反射模块。通过生成可综合的C++代码并优化为RTL，提升代码的正确性和兼容性。

Result: 在三个需求文档上的评估表明，系统生成的RTL代码准确性高，且人工干预需求比现有方法减少75%。

Conclusion: Spec2RTL-Agent是首个从非结构化需求自动生成RTL代码的多智能体系统，显著减少了硬件设计中的人力依赖。

Abstract: Despite recent progress in generating hardware RTL code with LLMs, existing solutions still suffer from a substantial gap between practical application scenarios and the requirements of real-world RTL code development. Prior approaches either focus on overly simplified hardware descriptions or depend on extensive human guidance to process complex specifications, limiting their scalability and automation potential. In this paper, we address this gap by proposing an LLM agent system, termed Spec2RTL-Agent, designed to directly process complex specification documentation and generate corresponding RTL code implementations, advancing LLM-based RTL code generation toward more realistic application settings. To achieve this goal, Spec2RTL-Agent introduces a novel multi-agent collaboration framework that integrates three key enablers: (1) a reasoning and understanding module that translates specifications into structured, step-by-step implementation plans; (2) a progressive coding and prompt optimization module that iteratively refines the code across multiple representations to enhance correctness and synthesisability for RTL conversion; and (3) an adaptive reflection module that identifies and traces the source of errors during generation, ensuring a more robust code generation flow. Instead of directly generating RTL from natural language, our system strategically generates synthesizable C++ code, which is then optimized for HLS. This agent-driven refinement ensures greater correctness and compatibility compared to naive direct RTL generation approaches. We evaluate Spec2RTL-Agent on three specification documents, showing it generates accurate RTL code with up to 75% fewer human interventions than existing methods. This highlights its role as the first fully automated multi-agent system for RTL generation from unstructured specs, reducing reliance on human effort in hardware design.

</details>


### [75] [Tensor Manipulation Unit (TMU): Reconfigurable, Near-Memory Tensor Manipulation for High-Throughput AI SoC](https://arxiv.org/abs/2506.14364)
*Weiyu Zhou,Zheng Wang,Chao Chen,Yike Li,Yongkui Yang,Zhuoyu Wu,Anupam Chattopadhyay*

Main category: cs.AR

TL;DR: 论文提出了一种名为TMU的可重构近存硬件块，用于高效处理数据密集型张量操作，显著提升了AI SoC的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管AI SoC设计在张量计算加速上取得了进展，但张量操作（以高量数据移动为核心）的研究仍然不足，本文旨在填补这一空白。

Method: 提出Tensor Manipulation Unit（TMU），采用RISC执行模型和统一地址抽象，支持粗细粒度的张量转换，并与TPU集成以提高流水线利用率。

Result: TMU在40nm工艺下仅占0.019 mm2，支持超过10种张量操作，性能相比ARM A72和NVIDIA Jetson TX2分别提升1413倍和8.54倍；与TPU集成后，端到端推理延迟降低34.6%。

Conclusion: TMU展示了可重构张量操作在现代AI SoC中的有效性和可扩展性。

Abstract: While recent advances in AI SoC design have focused heavily on accelerating tensor computation, the equally critical task of tensor manipulation, centered on high,volume data movement with minimal computation, remains underexplored. This work addresses that gap by introducing the Tensor Manipulation Unit (TMU), a reconfigurable, near-memory hardware block designed to efficiently execute data-movement-intensive operators. TMU manipulates long datastreams in a memory-to-memory fashion using a RISC-inspired execution model and a unified addressing abstraction, enabling broad support for both coarse- and fine-grained tensor transformations. Integrated alongside a TPU within a high-throughput AI SoC, the TMU leverages double buffering and output forwarding to improve pipeline utilization. Fabricated in SMIC 40nm technology, the TMU occupies only 0.019 mm2 while supporting over 10 representative tensor manipulation operators. Benchmarking shows that TMU alone achieves up to 1413 and 8.54 operator-level latency reduction compared to ARM A72 and NVIDIA Jetson TX2, respectively. When integrated with the in-house TPU, the complete system achieves a 34.6% reduction in end-to-end inference latency, demonstrating the effectiveness and scalability of reconfigurable tensor manipulation in modern AI SoCs.

</details>


### [76] [Empirically-Calibrated H100 Node Power Models for Reducing Uncertainty in AI Training Energy Estimation](https://arxiv.org/abs/2506.14551)
*Alex C. Newkirk,Jared Fernandez,Jonathan Koomey,Imran Latif,Emma Strubell,Arman Shehabi,Constantine Samaras*

Main category: cs.AR

TL;DR: 论文研究了AI训练中的能源需求特性，结合实测数据和开源基准，开发了计算强度与节点级功耗的统计模型，揭示了实际功耗与制造商标称TDP的差距，并预测了能耗误差显著优于TDP方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI能源需求的增长，了解其需求特性对电网规划和环境评估至关重要，但目前缺乏准确的方法。

Method: 结合实验室实测数据和开源基准数据，开发了计算强度与功耗的统计模型，并校准了浮点运算能耗预测。

Result: 实际功耗仅为TDP标称值的76%，模型预测误差为11.4%，显著优于TDP方法的27-37%。不同架构（如Transformer和CNN）的功耗特征不同，可能影响电网稳定性。

Conclusion: 该研究为AI能源管理提供了更精确的工具，揭示了架构差异对电网的影响，有助于未来基础设施优化。

Abstract: As AI's energy demand continues to grow, it is critical to enhance the understanding of characteristics of this demand, to improve grid infrastructure planning and environmental assessment. By combining empirical measurements from Brookhaven National Laboratory during AI training on 8-GPU H100 systems with open-source benchmarking data, we develop statistical models relating computational intensity to node-level power consumption. We measure the gap between manufacturer-rated thermal design power (TDP) and actual power demand during AI training. Our analysis reveals that even computationally intensive workloads operate at only 76% of the 10.2 kW TDP rating. Our architecture-specific model, calibrated to floating-point operations, predicts energy consumption with 11.4% mean absolute percentage error, significantly outperforming TDP-based approaches (27-37% error). We identified distinct power signatures between transformer and CNN architectures, with transformers showing characteristic fluctuations that may impact grid stability.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [77] [DeepSeq: High-Throughput Single-Cell RNA Sequencing Data Labeling via Web Search-Augmented Agentic Generative AI Foundation Models](https://arxiv.org/abs/2506.13817)
*Saleem A. Al Dajani,Abel Sanchez,John R. Williams*

Main category: q-bio.GN

TL;DR: 利用生成式AI基础模型处理单细胞RNA测序数据，通过实时网络搜索自动化标注数据，准确率高达82.5%，解决了监督学习中的标注瓶颈。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序数据规模迅速扩大，手动标注效率低且易出错，亟需自动化解决方案。

Method: 采用具有实时网络搜索功能的智能基础模型，自动标注实验数据。

Result: 实现了82.5%的标注准确率，支持下游任务如细胞分型和扰动预测。

Conclusion: 该方法可提升标注效率，未来有望超越人工标注，支持大规模扰动筛查和健康监测应用。

Abstract: Generative AI foundation models offer transformative potential for processing structured biological data, particularly in single-cell RNA sequencing, where datasets are rapidly scaling toward billions of cells. We propose the use of agentic foundation models with real-time web search to automate the labeling of experimental data, achieving up to 82.5% accuracy. This addresses a key bottleneck in supervised learning for structured omics data by increasing annotation throughput without manual curation and human error. Our approach enables the development of virtual cell foundation models capable of downstream tasks such as cell-typing and perturbation prediction. As data volume grows, these models may surpass human performance in labeling, paving the way for reliable inference in large-scale perturbation screens. This application demonstrates domain-specific innovation in health monitoring and diagnostics, aligned with efforts like the Human Cell Atlas and Human Tumor Atlas Network.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [78] [Public Acceptance of Cybernetic Avatars in the service sector: Evidence from a Large-Scale Survey in Dubai](https://arxiv.org/abs/2506.14268)
*Laura Aymerich-Franch,Tarek Taha,Takahiro Miyashita,Hiroko Kamide,Hiroshi Ishiguro,Paolo Dario*

Main category: cs.RO

TL;DR: 研究了迪拜多文化社会对赛博化身的接受度，重点关注客户服务机器人，探讨了外观、场景和功能对接受度的影响。


<details>
  <summary>Details</summary>
Motivation: 探究赛博化身在不同文化背景下的接受度，为设计和部署提供依据。

Method: 通过大规模调查（超过1000名参与者）分析外观、场景和任务对接受度的影响。

Result: 物理化身接受度高于数字化身；高度拟人的机器人外观最受欢迎；提供信息的任务最受重视；购物中心等场景接受度高，医疗场景较低；不同文化群体对外观偏好有差异。

Conclusion: 早期纳入用户反馈对提升赛博化身的社会接受度至关重要。

Abstract: Cybernetic avatars are hybrid interaction robots or digital representations that combine autonomous capabilities with teleoperated control. This study investigates the acceptance of cybernetic avatars in the highly multicultural society of Dubai, with particular emphasis on robotic avatars for customer service. Specifically, we explore how acceptance varies as a function of robot appearance (e.g., android, robotic-looking, cartoonish), deployment settings (e.g., shopping malls, hotels, hospitals), and functional tasks (e.g., providing information, patrolling). To this end, we conducted a large-scale survey with over 1,000 participants. Overall, cybernetic avatars received a high level of acceptance, with physical robot avatars receiving higher acceptance than digital avatars. In terms of appearance, robot avatars with a highly anthropomorphic robotic appearance were the most accepted, followed by cartoonish designs and androids. Animal-like appearances received the lowest level of acceptance. Among the tasks, providing information and guidance was rated as the most valued. Shopping malls, airports, public transport stations, and museums were the settings with the highest acceptance, whereas healthcare-related spaces received lower levels of support. An analysis by community cluster revealed among others that Emirati respondents showed significantly greater acceptance of android appearances compared to the overall sample, while participants from the 'Other Asia' cluster were significantly more accepting of cartoonish appearances. Our study underscores the importance of incorporating citizen feedback into the design and deployment of cybernetic avatars from the early stages to enhance acceptance of this technology in society.

</details>


### [79] [TUM Teleoperation: Open Source Software for Remote Driving and Assistance of Automated Vehicles](https://arxiv.org/abs/2506.13933)
*Tobias Kerbl,David Brecht,Nils Gehrke,Nijinshan Karunainayagam,Niklas Krauss,Florian Pfab,Richard Taupitz,Ines Trautmannsheimer,Xiyan Su,Maria-Magdalena Wolf,Frank Diermeyer*

Main category: cs.RO

TL;DR: 提出了一种开源的模块化远程操作软件堆栈，支持远程驾驶和远程协助，并与真实车辆集成。


<details>
  <summary>Details</summary>
Motivation: 解决现有开源软件中缺乏集成远程驾驶、远程协助和实际车辆测试的问题。

Method: 设计模块化开源软件堆栈，提供标准化接口，兼容多种平台，并支持人机界面灵活设计。

Result: 通过模拟和实际测试验证了软件的低延迟和高性能，代码已在GitHub开源。

Conclusion: 该软件为远程操作研究提供了可扩展的协作开发基础，适用于实际测试和用户研究。

Abstract: Teleoperation is a key enabler for future mobility, supporting Automated Vehicles in rare and complex scenarios beyond the capabilities of their automation. Despite ongoing research, no open source software currently combines Remote Driving, e.g., via steering wheel and pedals, Remote Assistance through high-level interaction with automated driving software modules, and integration with a real-world vehicle for practical testing. To address this gap, we present a modular, open source teleoperation software stack that can interact with an automated driving software, e.g., Autoware, enabling Remote Assistance and Remote Driving. The software featuresstandardized interfaces for seamless integration with various real-world and simulation platforms, while allowing for flexible design of the human-machine interface. The system is designed for modularity and ease of extension, serving as a foundation for collaborative development on individual software components as well as realistic testing and user studies. To demonstrate the applicability of our software, we evaluated the latency and performance of different vehicle platforms in simulation and real-world. The source code is available on GitHub

</details>


### [80] [Steering Robots with Inference-Time Interactions](https://arxiv.org/abs/2506.14287)
*Yanwei Wang*

Main category: cs.RO

TL;DR: 该研究提出了一种无需微调的预训练策略修正方法，通过用户交互在推理时指导行为生成。


<details>
  <summary>Details</summary>
Motivation: 预训练策略在部署时可能出现错误，而收集额外数据进行微调效率低下，因此需要一种更高效的修正机制。

Method: 提出两种方法：推理时引导（通过用户交互切换离散技能）和任务与动作模仿（通过用户交互编辑连续动作以满足任务约束）。

Result: 这些框架能够在不需额外训练的情况下修正策略预测，最大化预训练模型的效用。

Conclusion: 该方法实现了推理时用户目标的灵活调整，提高了预训练策略的实用性和适应性。

Abstract: Imitation learning has driven the development of generalist policies capable of autonomously solving multiple tasks. However, when a pretrained policy makes errors during deployment, there are limited mechanisms for users to correct its behavior. While collecting additional data for finetuning can address such issues, doing so for each downstream use case is inefficient at deployment. My research proposes an alternative: keeping pretrained policies frozen as a fixed skill repertoire while allowing user interactions to guide behavior generation toward user preferences at inference time. By making pretrained policies steerable, users can help correct policy errors when the model struggles to generalize-without needing to finetune the policy. Specifically, I propose (1) inference-time steering, which leverages user interactions to switch between discrete skills, and (2) task and motion imitation, which enables user interactions to edit continuous motions while satisfying task constraints defined by discrete symbolic plans. These frameworks correct misaligned policy predictions without requiring additional training, maximizing the utility of pretrained models while achieving inference-time user objectives.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [81] [SoK: Advances and Open Problems in Web Tracking](https://arxiv.org/abs/2506.14057)
*Yash Vekaria,Yohan Beugin,Shaoor Munir,Gunes Acar,Nataliia Bielova,Steven Englehardt,Umar Iqbal,Alexandros Kapravelos,Pierre Laperdrix,Nick Nikiforakis,Jason Polakis,Franziska Roesner,Zubair Shafiq,Sebastian Zimmeck*

Main category: cs.CR

TL;DR: 本文是对网页追踪技术的系统化知识（SoK）综述，旨在整合相关研究，概述技术机制、反制措施及隐私法规，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 网页追踪技术在广告行业变革、浏览器反追踪措施和隐私法规加强的推动下发生巨大变化，但现有研究分散且缺乏系统整合，因此需要全面综述。

Method: 通过系统化知识（SoK）方法，整合和分析了网页追踪的技术机制、反制措施及法规，综述了相关研究的现状与趋势。

Result: 提供了网页追踪技术的全面概述，揭示了当前技术和反制措施的特点，以及隐私法规的影响。

Conclusion: 研究为未来网页追踪领域的研究提供了统一参考，并指出了开放挑战和未来方向，服务于学术界和实务界。

Abstract: Web tracking is a pervasive and opaque practice that enables personalized advertising, retargeting, and conversion tracking. Over time, it has evolved into a sophisticated and invasive ecosystem, employing increasingly complex techniques to monitor and profile users across the web. The research community has a long track record of analyzing new web tracking techniques, designing and evaluating the effectiveness of countermeasures, and assessing compliance with privacy regulations. Despite a substantial body of work on web tracking, the literature remains fragmented across distinctly scoped studies, making it difficult to identify overarching trends, connect new but related techniques, and identify research gaps in the field. Today, web tracking is undergoing a once-in-a-generation transformation, driven by fundamental shifts in the advertising industry, the adoption of anti-tracking countermeasures by browsers, and the growing enforcement of emerging privacy regulations. This Systematization of Knowledge (SoK) aims to consolidate and synthesize this wide-ranging research, offering a comprehensive overview of the technical mechanisms, countermeasures, and regulations that shape the modern and rapidly evolving web tracking landscape. This SoK also highlights open challenges and outlines directions for future research, aiming to serve as a unified reference and introductory material for researchers, practitioners, and policymakers alike.

</details>


### [82] [Vulnerability Disclosure or Notification? Best Practices for Reaching Stakeholders at Scale](https://arxiv.org/abs/2506.14323)
*Ting-Han Chen,Jeroen van der Ham-de Vos*

Main category: cs.CR

TL;DR: 文章探讨了漏洞披露与漏洞通知的区别，总结了近年来的策略变化及最佳实践。


<details>
  <summary>Details</summary>
Motivation: 研究安全漏洞对利益相关者的风险，以及协调漏洞披露（CVD）和多漏洞通知的挑战。

Method: 基于早期披露经验和前人研究，进行元综述，分析策略变化、消息发起方式及结果。

Result: 区分了漏洞披露与漏洞通知，总结了最佳实践，并探讨了各自的挑战和方法。

Conclusion: 漏洞披露和通知需要不同的策略，研究为相关实践提供了指南和改进方向。

Abstract: Security researchers are interested in security vulnerabilities, but these security vulnerabilities create risks for stakeholders. Coordinated Vulnerability Disclosure has been an accepted best practice for many years in disclosing newly discovered vulnerabilities. This practice has mostly worked, but it can become challenging when there are many different parties involved.
  There has also been research into known vulnerabilities, using datasets or active scans to discover how many machines are still vulnerable. The ethical guidelines suggest that researchers also make an effort to notify the owners of these machines. We posit that this differs from vulnerability disclosure, but rather the practice of vulnerability notification. This practice has some similarities with vulnerability disclosure but should be distinguished from it, providing other challenges and requiring a different approach.
  Based on our earlier disclosure experience and on prior work documenting their disclosure and notification operations, we provide a meta-review on vulnerability disclosure and notification to observe the shifts in strategies in recent years. We assess how researchers initiated their messaging and examine the outcomes. We then compile the best practices for the existing disclosure guidelines and for notification operations.

</details>


### [83] [Consensus Power Inequality: A Comparative Study of Blockchain Networks](https://arxiv.org/abs/2506.14393)
*Kamil Tylinski,Abylay Satybaldy,Paolo Tasca*

Main category: cs.CR

TL;DR: 本研究对五个主流区块链网络的共识权力不平等进行了定量评估，发现Hedera和比特币的权力分配较为均衡，而Algorand则表现出明显的中心化趋势。


<details>
  <summary>Details</summary>
Motivation: 区块链网络的共识权力分配对去中心化、安全和公平性具有重要影响，但缺乏系统性的评估方法。

Method: 利用基尼系数和泰尔指数等经济指标，结合2022年1月至2024年7月的数据，分析比特币、以太坊、Cardano、Hedera和Algorand的共识权力分布。

Result: Hedera和比特币的分配最均衡，以太坊转向PoS后权力更集中，Algorand权力集中明显。

Conclusion: 研究提供了评估区块链共识权力不平等的方法论框架，并为更公平的网络设计提出了建议。

Abstract: The distribution of consensus power is a cornerstone of decentralisation, influencing the security, resilience, and fairness of blockchain networks while ensuring equitable impact among participants. This study provides a rigorous evaluation of consensus power inequality across five prominent blockchain networks - Bitcoin, Ethereum, Cardano, Hedera, and Algorand - using data collected from January 2022 to July 2024. Leveraging established economic metrics, including the Gini coefficient and Theil index, the research quantitatively assesses how power is distributed among blockchain network participants. A robust dataset, capturing network-specific characteristics such as mining pools, staking patterns, and consensus nodes, forms the foundation of the analysis, enabling meaningful comparisons across diverse architectures. Through an in-depth comparative study, the paper identifies key disparities in consensus power distribution. Hedera and Bitcoin demonstrate more balanced power distribution, aligning closely with the principles of decentralisation. Ethereum and Cardano demonstrate moderate levels of inequality. However, contrary to expectations, Ethereum has become more concentrated following its transition to Proof-of-Stake. Meanwhile, Algorand shows a pronounced centralisation of power. Moreover, the findings highlight the structural and operational drivers of inequality, including economic barriers, governance models, and network effects, offering actionable insights for more equitable network design. This study establishes a methodological framework for evaluating blockchain consensus power inequality, emphasising the importance of targeted strategies to ensure fairer power distribution and enhancing the sustainability of decentralised systems. Future research will build on these findings by integrating additional metrics and examining the influence of emerging consensus mechanisms.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [84] [A multi-stage augmented multimodal interaction network for fish feeding intensity quantification](https://arxiv.org/abs/2506.14170)
*Shulong Zhang,Mingyuan Yao,Jiayin Zhao,Xiao Liu,Haihua Wang*

Main category: cs.CV

TL;DR: 本文提出了一种多阶段增强多模态交互网络（MAINet）用于量化鱼类摄食强度，通过模态间的交互和证据推理规则显著提高了模型的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前研究在多模态融合模型的模态选择、特征提取与融合以及协同推理方面存在局限性，影响了模型的准确性和可靠性。本文旨在通过MAINet解决这些问题，提高鱼类摄食强度的量化精度。

Method: 1) 提出通用特征提取框架；2) 设计辅助模态增强主模态机制（ARPM），包括通道注意力融合网络（CAFN）和双模态注意力融合网络（DAFN）；3) 引入证据推理（ER）规则进行模态结果融合与决策。

Result: MAINet在准确率、精确率、召回率和F1分数上均达到96.7%以上，性能显著优于对比模型，且通过消融实验验证了改进策略的有效性。

Conclusion: MAINet通过多模态交互和证据推理显著提升了鱼类摄食强度量化的准确性和鲁棒性，为水产养殖中的精准投喂提供了有效工具。

Abstract: In recirculating aquaculture systems, accurate and effective assessment of fish feeding intensity is crucial for reducing feed costs and calculating optimal feeding times. However, current studies have limitations in modality selection, feature extraction and fusion, and co-inference for decision making, which restrict further improvement in the accuracy, applicability and reliability of multimodal fusion models. To address this problem, this study proposes a Multi-stage Augmented Multimodal Interaction Network (MAINet) for quantifying fish feeding intensity. Firstly, a general feature extraction framework is proposed to efficiently extract feature information from input image, audio and water wave datas. Second, an Auxiliary-modality Reinforcement Primary-modality Mechanism (ARPM) is designed for inter-modal interaction and generate enhanced features, which consists of a Channel Attention Fusion Network (CAFN) and a Dual-mode Attention Fusion Network (DAFN). Finally, an Evidence Reasoning (ER) rule is introduced to fuse the output results of each modality and make decisions, thereby completing the quantification of fish feeding intensity. The experimental results show that the constructed MAINet reaches 96.76%, 96.78%, 96.79% and 96.79% in accuracy, precision, recall and F1-Score respectively, and its performance is significantly higher than the comparison models. Compared with models that adopt single-modality, dual-modality fusion and different decision-making fusion methods, it also has obvious advantages. Meanwhile, the ablation experiments further verified the key role of the proposed improvement strategy in improving the robustness and feature utilization efficiency of model, which can effectively improve the accuracy of the quantitative results of fish feeding intensity.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [85] [Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees](https://arxiv.org/abs/2506.14606)
*Ahmed Heakl,Sarim Hashmi,Chaimaa Abi,Celine Lee,Abdulrahman Mahmoud*

Main category: cs.CL

TL;DR: GG是一种结合大语言模型(LLMs)和软件测试的指令集架构(ISA)转换方法，用于复杂指令集(CISC)和精简指令集(RISC)之间的高效翻译。


<details>
  <summary>Details</summary>
Motivation: 硬件生态系统快速变化，需要高效、灵活且准确的低级程序跨指令集架构翻译，以提升代码的可移植性和寿命。复杂与精简指令集之间的翻译尤为困难。

Method: GG利用LLM生成候选翻译，并通过软件测试框架验证其正确性，确保高代码覆盖率和功能正确性。

Result: 在HumanEval和BringupBench程序上分别达到99%和49%的正确性，性能优于Rosetta 2，速度提升1.73倍，能效提高1.47倍，内存使用减少2.41倍。

Conclusion: GG在CISC到RISC的翻译任务中表现出色，开源资源将为未来ISA级代码翻译研究奠定基础。

Abstract: The hardware ecosystem is rapidly evolving, with increasing interest in translating low-level programs across different instruction set architectures (ISAs) in a quick, flexible, and correct way to enhance the portability and longevity of existing code. A particularly challenging class of this transpilation problem is translating between complex- (CISC) and reduced- (RISC) hardware architectures, due to fundamental differences in instruction complexity, memory models, and execution paradigms. In this work, we introduce GG (Guaranteed Guess), an ISA-centric transpilation pipeline that combines the translation power of pre-trained large language models (LLMs) with the rigor of established software testing constructs. Our method generates candidate translations using an LLM from one ISA to another, and embeds such translations within a software-testing framework to build quantifiable confidence in the translation. We evaluate our GG approach over two diverse datasets, enforce high code coverage (>98%) across unit tests, and achieve functional/semantic correctness of 99% on HumanEval programs and 49% on BringupBench programs, respectively. Further, we compare our approach to the state-of-the-art Rosetta 2 framework on Apple Silicon, showcasing 1.73x faster runtime performance, 1.47x better energy efficiency, and 2.41x better memory usage for our transpiled code, demonstrating the effectiveness of GG for real-world CISC-to-RISC translation tasks. We will open-source our codes, data, models, and benchmarks to establish a common foundation for ISA-level code translation research.

</details>


### [86] [An Interdisciplinary Review of Commonsense Reasoning and Intent Detection](https://arxiv.org/abs/2506.14040)
*Md Nazmus Sakib*

Main category: cs.CL

TL;DR: 综述探讨了2020-2025年间28篇关于常识推理和意图检测的论文，总结了方法和应用，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 常识推理和意图检测是自然语言理解的核心挑战，本文通过整合NLP和HCI领域的研究，旨在推动更自适应、多语言和上下文感知的模型发展。

Method: 分析了28篇来自ACL、EMNLP和CHI的论文，按方法和应用分类，总结了常识推理和意图检测的不同技术。

Result: 指出了常识推理在零样本学习、文化适应等方面的进展，意图检测在开放集模型、生成式方法等方面的突破，并总结了当前模型的局限性。

Conclusion: 未来研究需关注模型的泛化能力、基准设计等关键问题，以实现更具适应性的语言理解系统。

Abstract: This review explores recent advances in commonsense reasoning and intent detection, two key challenges in natural language understanding. We analyze 28 papers from ACL, EMNLP, and CHI (2020-2025), organizing them by methodology and application. Commonsense reasoning is reviewed across zero-shot learning, cultural adaptation, structured evaluation, and interactive contexts. Intent detection is examined through open-set models, generative formulations, clustering, and human-centered systems. By bridging insights from NLP and HCI, we highlight emerging trends toward more adaptive, multilingual, and context-aware models, and identify key gaps in grounding, generalization, and benchmark design.

</details>


### [87] [ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations](https://arxiv.org/abs/2506.14200)
*Brihi Joshi,Keyu He,Sahana Ramnath,Sadra Sabouri,Kaitlyn Zhou,Souti Chattopadhyay,Swabha Swayamdipta,Xiang Ren*

Main category: cs.CL

TL;DR: ELI-Why基准测试用于评估语言模型的教学能力，发现GPT-4生成解释的适用性低于人工解释。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型是否能根据不同学习者的需求定制教学解释。

Method: 引入ELI-Why基准，并进行两项人类研究评估模型生成解释的适用性。

Result: GPT-4生成解释的适用性比人工解释低20%，且自动化指标显示模型解释缺乏区分度。

Conclusion: 当前语言模型在定制教学解释方面仍需改进。

Abstract: Language models today are widely used in education, yet their ability to tailor responses for learners with varied informational needs and knowledge backgrounds remains under-explored. To this end, we introduce ELI-Why, a benchmark of 13.4K "Why" questions to evaluate the pedagogical capabilities of language models. We then conduct two extensive human studies to assess the utility of language model-generated explanatory answers (explanations) on our benchmark, tailored to three distinct educational grades: elementary, high-school and graduate school. In our first study, human raters assume the role of an "educator" to assess model explanations' fit to different educational grades. We find that GPT-4-generated explanations match their intended educational background only 50% of the time, compared to 79% for lay human-curated explanations. In our second study, human raters assume the role of a learner to assess if an explanation fits their own informational needs. Across all educational backgrounds, users deemed GPT-4-generated explanations 20% less suited on average to their informational needs, when compared to explanations curated by lay people. Additionally, automated evaluation metrics reveal that explanations generated across different language model families for different informational needs remain indistinguishable in their grade-level, limiting their pedagogical effectiveness.

</details>


### [88] [ELLIS Alicante at CQs-Gen 2025: Winning the critical thinking questions shared task: LLM-based question generation and selection](https://arxiv.org/abs/2506.14371)
*Lucile Favero,Daniel Frases,Juan Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.CL

TL;DR: 论文研究了如何利用大型语言模型（LLMs）生成批判性问题，以促进深度思考而非浅层学习，并在竞赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs可能助长浅层学习的担忧，探索其在辩论中生成批判性问题以挑战模糊主张的潜力。

Method: 提出两步骤框架：先用小型开源模型生成候选问题（Questioner），再用另一模型（Judge）筛选最相关的问题。

Result: 系统在ACL 2025的共享任务竞赛中排名第一，证明了该方法的有效性。

Conclusion: 基于LLM的方法能有效推动对论辩文本的批判性思考。

Abstract: The widespread adoption of chat interfaces based on Large Language Models (LLMs) raises concerns about promoting superficial learning and undermining the development of critical thinking skills. Instead of relying on LLMs purely for retrieving factual information, this work explores their potential to foster deeper reasoning by generating critical questions that challenge unsupported or vague claims in debate interventions. This study is part of a shared task of the 12th Workshop on Argument Mining, co-located with ACL 2025, focused on automatic critical question generation. We propose a two-step framework involving two small-scale open source language models: a Questioner that generates multiple candidate questions and a Judge that selects the most relevant ones. Our system ranked first in the shared task competition, demonstrating the potential of the proposed LLM-based approach to encourage critical engagement with argumentative texts.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [89] [SETI@home: Data Acquisition and Front-End Processing](https://arxiv.org/abs/2506.14718)
*Eric J. Korpela,David P. Anderson,Jeff Cobb,Matt Lebofsky,Wei Liu,Dan Werthimer*

Main category: astro-ph.IM

TL;DR: SETI@home使用分布式计算在家用电脑上分析无线电数据，以搜索外星技术信号，通过高计算能力提升搜索的灵敏度和通用性。


<details>
  <summary>Details</summary>
Motivation: 大多数SETI项目使用专用硬件分析数据，SETI@home则利用志愿者的家用电脑进行分布式计算，以更高效地搜索外星信号。

Method: 通过互联网分发数据，使用相干积分和多普勒漂移率搜索信号，同时检测多种信号类型，并通过前端检测和后端筛选处理数据。

Result: 累计产生约1.2×10¹⁰次检测，后端进一步筛选去除了射频干扰，寻找可能的外星信号。

Conclusion: SETI@home的前端方法通过分布式计算显著提高了搜索能力，为后续分析提供了丰富数据。

Abstract: SETI@home is a radio Search for Extraterrestrial Intelligence (SETI) project, looking for technosignatures in data recorded at multiple observatories from 1998 to 2020. Most radio SETI projects analyze data using dedicated processing hardware. SETI@home uses a different approach: time-domain data is distributed over the Internet to $\gt 10^{5}$ volunteered home computers, which analyze it. The large amount of computing power this affords ($\sim 10^{15}$ floating-point operations per second (FPOP/s)) allows us to increase the sensitivity and generality of our search in three ways. We use coherent integration, a technique in which data is transformed so that the power of drifting signals is confined to a single discrete Fourier transform (DFT) bin. We perform this coherent search over 123 000 Doppler drift rates in the range ($\pm$100 Hz s$^{-1}$). Second, we search for a variety of signal types, such as pulsed signals and arbitrary repeated waveforms. The analysis uses a range of DFT sizes, with frequency resolutions ranging from 0.075 Hz to 1221 Hz. The front end of SETI@home produces a set of detections that exceed thresholds in power and goodness of fit. We accumulated $\sim 1.2\times 10^{10}$ such detections. The back end of SETI@home takes these detections, identifies and removes radio frequency interference (RFI), and looks for groups of detections that are consistent with extraterrestrial origin and that persist over long timescales. This paper describes the front end of SETI@home and provides parameters for the primary data source, the Arecibo Observatory; the back end and its results are described in a companion paper.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [90] [Students' Reliance on AI in Higher Education: Identifying Contributing Factors](https://arxiv.org/abs/2506.13845)
*Griffin Pitts,Neha Rani,Weedguet Mildort,Eva-Marie Cook*

Main category: cs.CY

TL;DR: 研究探讨大学生对AI工具的依赖模式，发现适当的依赖与编程能力、认知需求相关，而过依赖与信任和满意度相关。


<details>
  <summary>Details</summary>
Motivation: 探讨学生在教育环境中过度依赖AI工具的潜在因素及其对学习的影响。

Method: 结合前后调查和实验任务，观察学生在不同AI建议下的依赖行为。

Result: 适当依赖与编程能力、认知需求相关；过依赖与对AI的信任和满意度相关。

Conclusion: 研究结果为开发针对性干预措施提供了依据，以促进学生对AI工具的适当依赖。

Abstract: The increasing availability and use of artificial intelligence (AI) tools in educational settings has raised concerns about students' overreliance on these technologies. Overreliance occurs when individuals accept incorrect AI-generated recommendations, often without critical evaluation, leading to flawed problem solutions and undermining learning outcomes. This study investigates potential factors contributing to patterns of AI reliance among undergraduate students, examining not only overreliance but also appropriate reliance (correctly accepting helpful and rejecting harmful recommendations) and underreliance (incorrectly rejecting helpful recommendations). Our approach combined pre- and post-surveys with a controlled experimental task where participants solved programming problems with an AI assistant that provided both accurate and deliberately incorrect suggestions, allowing direct observation of students' reliance patterns when faced with varying AI reliability. We find that appropriate reliance is significantly related to students' programming self-efficacy, programming literacy, and need for cognition, while showing negative correlations with post-task trust and satisfaction. Overreliance showed significant correlations with post-task trust and satisfaction with the AI assistant. Underreliance was negatively correlated with programming literacy, programming self-efficacy, and need for cognition. Overall, the findings provide insights for developing targeted interventions that promote appropriate reliance on AI tools, with implications for the integration of AI in curriculum and educational technologies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [91] [Enhancing Symbolic Machine Learning by Subsymbolic Representations](https://arxiv.org/abs/2506.14569)
*Stephen Roth,Lennart Baur,Derian Boer,Stefan Kramer*

Main category: cs.AI

TL;DR: 本文提出了一种通过神经嵌入增强符号机器学习的方法，以解决当前神经符号AI系统在简单场景中的效率问题，并展示了其在TILDE中的有效性。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI的目标是结合符号和亚符号AI方法，但现有系统（如LTN和DeepProbLog）在简单场景（如判别式机器学习）中效率较低。本文旨在通过神经嵌入增强符号机器学习，提高其性能。

Method: 通过为符号机器学习方案（如TILDE）提供神经嵌入的访问权限，具体表现为在相似性谓词中使用常量的嵌入。嵌入可以根据符号理论进一步优化。

Result: 在三个真实领域的实验中，该方法在F1分数上优于所有基线方法。

Conclusion: 该方法不仅适用于当前场景，还可扩展到实例间的相似性（如核函数）、类比推理或命题化等其他领域。

Abstract: The goal of neuro-symbolic AI is to integrate symbolic and subsymbolic AI approaches, to overcome the limitations of either. Prominent systems include Logic Tensor Networks (LTN) or DeepProbLog, which offer neural predicates and end-to-end learning. The versatility of systems like LTNs and DeepProbLog, however, makes them less efficient in simpler settings, for instance, for discriminative machine learning, in particular in domains with many constants. Therefore, we follow a different approach: We propose to enhance symbolic machine learning schemes by giving them access to neural embeddings. In the present paper, we show this for TILDE and embeddings of constants used by TILDE in similarity predicates. The approach can be fine-tuned by further refining the embeddings depending on the symbolic theory. In experiments in three real-world domain, we show that this simple, yet effective, approach outperforms all other baseline methods in terms of the F1 score. The approach could be useful beyond this setting: Enhancing symbolic learners in this way could be extended to similarities between instances (effectively working like kernels within a logical language), for analogical reasoning, or for propositionalization.

</details>


### [92] [AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection](https://arxiv.org/abs/2506.14470)
*Zixian Zhang,Takfarinas Saber*

Main category: cs.AI

TL;DR: 论文通过实验评估了基于AST的混合图表示在GNN代码克隆检测中的效果，发现不同表示对不同GNN架构影响各异，其中AST+CFG+DFG对部分模型有益，而FA-AST可能引入复杂性损害性能。GMN在标准AST下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 代码克隆增加维护成本和漏洞风险，其检测是软件工程的关键挑战。现有AST方法缺乏语义深度，需研究混合图表示与GNN的兼容性。

Method: 通过系统比较多种混合图表示（AST+CFG+DFG、FA-AST等）在不同GNN架构（GCN、GAT、GMN等）中的表现。

Result: AST+CFG+DFG提升了卷积和注意力模型的精度，而FA-AST常因结构复杂性降低性能。GMN在标准AST下表现最优。

Conclusion: 混合图表示效果因GNN架构而异，GMN在标准AST下已足够优异，减少了对复杂结构的需求。

Abstract: As one of the most detrimental code smells, code clones significantly increase software maintenance costs and heighten vulnerability risks, making their detection a critical challenge in software engineering. Abstract Syntax Trees (ASTs) dominate deep learning-based code clone detection due to their precise syntactic structure representation, but they inherently lack semantic depth. Recent studies address this by enriching AST-based representations with semantic graphs, such as Control Flow Graphs (CFGs) and Data Flow Graphs (DFGs). However, the effectiveness of various enriched AST-based representations and their compatibility with different graph-based machine learning techniques remains an open question, warranting further investigation to unlock their full potential in addressing the complexities of code clone detection. In this paper, we present a comprehensive empirical study to rigorously evaluate the effectiveness of AST-based hybrid graph representations in Graph Neural Network (GNN)-based code clone detection. We systematically compare various hybrid representations ((CFG, DFG, Flow-Augmented ASTs (FA-AST)) across multiple GNN architectures. Our experiments reveal that hybrid representations impact GNNs differently: while AST+CFG+DFG consistently enhances accuracy for convolution- and attention-based models (Graph Convolutional Networks (GCN), Graph Attention Networks (GAT)), FA-AST frequently introduces structural complexity that harms performance. Notably, GMN outperforms others even with standard AST representations, highlighting its superior cross-code similarity detection and reducing the need for enriched structures.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [93] [Multimodal Fusion with Semi-Supervised Learning Minimizes Annotation Quantity for Modeling Videoconference Conversation Experience](https://arxiv.org/abs/2506.13971)
*Andrew Chang,Chenkai Hu,Ji Qi,Zhuojian Wei,Kexin Zhang,Viswadruth Akkaraju,David Poeppel,Dustin Freeman*

Main category: eess.AS

TL;DR: 论文研究了视频会议中负面体验的预测，通过半监督学习方法在少量标注数据下取得了与传统监督学习接近的性能，显著降低了标注成本。


<details>
  <summary>Details</summary>
Motivation: 视频会议中的负面体验（如不流畅或不愉快）研究较少，且自然数据中这些现象稀少，传统监督学习需要大量标注数据，成本高昂。

Method: 采用半监督学习（SSL），结合标记和未标记的多模态（语音、面部、文本）数据训练深度特征，预测视频会议中的负面体验。

Result: 模态融合的协同训练SSL模型的ROC-AUC达到0.9，F1分数为0.6，优于传统监督学习模型（提升4%）。仅用8%标注数据的SSL模型达到了全数据监督学习模型96%的性能。

Conclusion: 提出了一种标注高效的框架，能够显著减少视频会议体验建模中的标注成本，同时保持高性能。

Abstract: Group conversations over videoconferencing are a complex social behavior. However, the subjective moments of negative experience, where the conversation loses fluidity or enjoyment remain understudied. These moments are infrequent in naturalistic data, and thus training a supervised learning (SL) model requires costly manual data annotation. We applied semi-supervised learning (SSL) to leverage targeted labeled and unlabeled clips for training multimodal (audio, facial, text) deep features to predict non-fluid or unenjoyable moments in holdout videoconference sessions. The modality-fused co-training SSL achieved an ROC-AUC of 0.9 and an F1 score of 0.6, outperforming SL models by up to 4% with the same amount of labeled data. Remarkably, the best SSL model with just 8% labeled data matched 96% of the SL model's full-data performance. This shows an annotation-efficient framework for modeling videoconference experience.

</details>


### [94] [M3SD: Multi-modal, Multi-scenario and Multi-language Speaker Diarization Dataset](https://arxiv.org/abs/2506.14427)
*Shilong Wu,Hang Chen,Jun Du*

Main category: eess.AS

TL;DR: 提出了一种自动构建说话人日志数据集的方法，并发布了多模态、多场景、多语言的M3SD数据集，同时提出了一种场景相关的模型微调策略，结合Adapter和LoRA实现领域自适应。


<details>
  <summary>Details</summary>
Motivation: 解决说话人日志中数据资源不足和深度学习模型泛化能力差的问题。

Method: 通过音视频结合生成伪标签构建数据集，并利用Adapter和LoRA联合微调进行场景适应。

Result: 发布了M3SD数据集，实现了模型的领域自适应。

Conclusion: 提出的方法和策略有效解决了数据不足和泛化问题，推动了说话人日志技术的发展。

Abstract: In the field of speaker diarization, the development of technology is constrained by two problems: insufficient data resources and poor generalization ability of deep learning models. To address these two problems, firstly, we propose an automated method for constructing speaker diarization datasets, which generates more accurate pseudo-labels for massive data through the combination of audio and video. Relying on this method, we have released Multi-modal, Multi-scenario and Multi-language Speaker Diarization (M3SD) datasets. This dataset is derived from real network videos and is highly diverse. In addition, we further propose a scenario-related model fine-tuning strategy. Based on the general model pre-trained using the above dataset, we combine the specific data of the target scenario (e.g., meetings) and achieve targeted optimization by using Adapter and LoRA joint fine-tuning, thus achieving the model's domain adaptation. Our dataset and code have been open-sourced at https://huggingface.co/spaces/OldDragon/m3sd.

</details>


### [95] [ASAP-FE: Energy-Efficient Feature Extraction Enabling Multi-Channel Keyword Spotting on Edge Processors](https://arxiv.org/abs/2506.14657)
*Jongin Choi,Jina Park,Woojoo Lee,Jae-Jin Lee,Massoud Pedram*

Main category: eess.AS

TL;DR: ASAP-FE是一种针对边缘设备的多通道关键词唤醒系统前端优化框架，通过创新的半重叠IIR帧处理、稀疏感知数据减少和动态并行处理技术，大幅降低计算和能耗需求，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备上多通道关键词唤醒系统的高计算和能耗问题，以满足实时处理需求。

Method: 提出ASAP-FE框架，包含半重叠IIR帧处理、稀疏感知数据减少和动态并行处理三大创新技术。

Result: 实验显示ASAP-FE减少平均62.73%的计算量，支持32通道实时处理，准确率损失低于1%。

Conclusion: ASAP-FE为边缘设备提供了高效且实际可行的多通道关键词唤醒解决方案。

Abstract: Multi-channel keyword spotting (KWS) has become crucial for voice-based applications in edge environments. However, its substantial computational and energy requirements pose significant challenges. We introduce ASAP-FE (Agile Sparsity-Aware Parallelized-Feature Extractor), a hardware-oriented front-end designed to address these challenges. Our framework incorporates three key innovations: (1) Half-overlapped Infinite Impulse Response (IIR) Framing: This reduces redundant data by approximately 25% while maintaining essential phoneme transition cues. (2) Sparsity-aware Data Reduction: We exploit frame-level sparsity to achieve an additional 50% data reduction by combining frame skipping with stride-based filtering. (3) Dynamic Parallel Processing: We introduce a parameterizable filter cluster and a priority-based scheduling algorithm that allows parallel execution of IIR filtering tasks, reducing latency and optimizing energy efficiency. ASAP-FE is implemented with various filter cluster sizes on edge processors, with functionality verified on FPGA prototypes and designs synthesized at 45 nm. Experimental results using TC-ResNet8, DS-CNN, and KWT-1 demonstrate that ASAP-FE reduces the average workload by 62.73% while supporting real-time processing for up to 32 channels. Compared to a conventional fully overlapped baseline, ASAP-FE achieves less than a 1% accuracy drop (e.g., 96.22% vs. 97.13% for DS-CNN), which is well within acceptable limits for edge AI. By adjusting the number of filter modules, our design optimizes the trade-off between performance and energy, with 15 parallel filters providing optimal performance for up to 25 channels. Overall, ASAP-FE offers a practical and efficient solution for multi-channel KWS on energy-constrained edge devices.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [96] [AMLgentex: Mobilizing Data-Driven Research to Combat Money Laundering](https://arxiv.org/abs/2506.13989)
*Johan Östman,Edvin Callisen,Anton Chen,Kristiina Ausmees,Emanuel Gårdh,Jovan Zamac,Jolanta Goldsteine,Hugo Wefer,Simon Whelan,Markus Reimegård*

Main category: cs.SI

TL;DR: AMLGentex是一个开源工具，用于生成逼真的、可配置的交易数据，并在模拟真实世界挑战的环境下评估反洗钱方法。


<details>
  <summary>Details</summary>
Motivation: 洗钱活动每年涉及数万亿美元，但极少被揭露。目前合成数据集无法模拟真实洗钱行为的复杂性。

Method: 开发了AMLGentex，一个开源套件，用于生成真实的交易数据并评估检测方法，解决了现有数据集的局限性。

Result: AMLGentex提供了一种系统化评估反洗钱方法的途径，能够模拟真实世界的复杂性。

Conclusion: 该工具为反洗钱系统的评估提供了更真实、可控的环境，有助于提升检测技术的有效性。

Abstract: Money laundering enables organized crime by allowing illicit funds to enter the legitimate economy. Although trillions of dollars are laundered each year, only a small fraction is ever uncovered. This stems from a range of factors, including deliberate evasion by launderers, the rarity of confirmed cases, and the limited visibility each financial institution has into the global transaction network. While several synthetic datasets are available, they fail to model the structural and behavioral complexity of real-world money laundering. In particular, they often overlook partial observability, sparse and uncertain labels, strategic behavior, temporal dynamics, class imbalance, and network-level dependencies. To address these limitations, we present AMLGentex, an open-source suite for generating realistic, configurable transaction data and benchmarking detection methods. It enables systematic evaluation of anti-money laundering (AML) systems in a controlled environment that captures key real-world challenges. We demonstrate how the framework can be used to rigorously evaluate methods under conditions that reflect the complexity of practical AML scenarios.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [97] [Fretting-Transformer: Encoder-Decoder Model for MIDI to Tablature Transcription](https://arxiv.org/abs/2506.14223)
*Anna Hamberger,Sebastian Murgul,Jochen Schmidt,Michael Heizmann*

Main category: cs.SD

TL;DR: 该论文提出了一种名为Fretting-Transformer的模型，用于将MIDI转录为吉他谱，解决了弦位模糊性和可演奏性问题。


<details>
  <summary>Details</summary>
Motivation: 音乐转录在MIR中很重要，但MIDI等符号音乐缺乏吉他演奏的关键信息。本文旨在解决这一问题。

Method: 使用T5变压器架构的编码器-解码器模型，结合新的数据预处理和标记化策略，处理弦位模糊性和可演奏性。

Result: 实验显示，该模型在准确性和可演奏性上优于A*和Guitar Pro等基线方法。

Conclusion: 该模型为自动化吉他转录奠定了基础，未来可通过上下文敏感处理和调音条件进一步优化。

Abstract: Music transcription plays a pivotal role in Music Information Retrieval (MIR), particularly for stringed instruments like the guitar, where symbolic music notations such as MIDI lack crucial playability information. This contribution introduces the Fretting-Transformer, an encoderdecoder model that utilizes a T5 transformer architecture to automate the transcription of MIDI sequences into guitar tablature. By framing the task as a symbolic translation problem, the model addresses key challenges, including string-fret ambiguity and physical playability. The proposed system leverages diverse datasets, including DadaGP, GuitarToday, and Leduc, with novel data pre-processing and tokenization strategies. We have developed metrics for tablature accuracy and playability to quantitatively evaluate the performance. The experimental results demonstrate that the Fretting-Transformer surpasses baseline methods like A* and commercial applications like Guitar Pro. The integration of context-sensitive processing and tuning/capo conditioning further enhances the model's performance, laying a robust foundation for future developments in automated guitar transcription.

</details>


### [98] [Manipulated Regions Localization For Partially Deepfake Audio: A Survey](https://arxiv.org/abs/2506.14396)
*Jiayi He,Jiangyan Yi,Jianhua Tao,Siding Zeng,Hao Gu*

Main category: cs.SD

TL;DR: 本文首次系统综述了部分深度伪造音频的定位任务，包括基本原理、现有方法、当前局限和潜在趋势，为该领域提供了深入见解。


<details>
  <summary>Details</summary>
Motivation: 随着部分深度伪造音频攻击的增加，其隐蔽性使其更难被检测，带来更高安全风险，但缺乏系统综述。因此，本文旨在填补这一空白。

Method: 通过调查现有研究，系统介绍部分深度伪造音频定位任务的基本原理、方法分支、局限与趋势。

Result: 本文提供了对该领域的全面梳理，揭示了现有方法的不足与未来发展方向。

Conclusion: 这项工作为部分深度伪造音频定位任务的研究提供了重要参考，并指出了潜在的技术发展趋势。

Abstract: With the development of audio deepfake techniques, attacks with partially deepfake audio are beginning to rise. Compared to fully deepfake, it is much harder to be identified by the detector due to the partially cryptic manipulation, resulting in higher security risks. Although some studies have been launched, there is no comprehensive review to systematically introduce the current situations and development trends for addressing this issue. Thus, in this survey, we are the first to outline a systematic introduction for partially deepfake audio manipulated region localization tasks, including the fundamentals, branches of existing methods, current limitations and potential trends, providing a revealing insight into this scope.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [99] [ReinDSplit: Reinforced Dynamic Split Learning for Pest Recognition in Precision Agriculture](https://arxiv.org/abs/2506.13935)
*Vishesh Kumar Tanwar,Soumik Sarkar,Asheesh K. Singh,Sajal K. Das*

Main category: cs.LG

TL;DR: 该论文提出了一种基于强化学习的动态分割学习框架ReinDSplit，旨在解决农业生态系统中边缘设备异构性导致的效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统分割学习框架在农业生态系统中无法适应设备的异构性，导致效率低下和性能下降，因此需要一种动态调整分割点的方法。

Method: 论文提出ReinDSplit框架，利用强化学习动态调整每个设备的神经网络分割点，优化资源利用和延迟。

Result: 在三个昆虫分类数据集上，ReinDSplit使用MobileNetV2达到了94.31%的准确率。

Conclusion: ReinDSplit不仅解决了农业领域的效率问题，还为异构环境中的资源优化和隐私保护提供了新思路。

Abstract: To empower precision agriculture through distributed machine learning (DML), split learning (SL) has emerged as a promising paradigm, partitioning deep neural networks (DNNs) between edge devices and servers to reduce computational burdens and preserve data privacy. However, conventional SL frameworks' one-split-fits-all strategy is a critical limitation in agricultural ecosystems where edge insect monitoring devices exhibit vast heterogeneity in computational power, energy constraints, and connectivity. This leads to straggler bottlenecks, inefficient resource utilization, and compromised model performance. Bridging this gap, we introduce ReinDSplit, a novel reinforcement learning (RL)-driven framework that dynamically tailors DNN split points for each device, optimizing efficiency without sacrificing accuracy. Specifically, a Q-learning agent acts as an adaptive orchestrator, balancing workloads and latency thresholds across devices to mitigate computational starvation or overload. By framing split layer selection as a finite-state Markov decision process, ReinDSplit convergence ensures that highly constrained devices contribute meaningfully to model training over time. Evaluated on three insect classification datasets using ResNet18, GoogleNet, and MobileNetV2, ReinDSplit achieves 94.31% accuracy with MobileNetV2. Beyond agriculture, ReinDSplit pioneers a paradigm shift in SL by harmonizing RL for resource efficiency, privacy, and scalability in heterogeneous environments.

</details>


### [100] [Comprehensive Verilog Design Problems: A Next-Generation Benchmark Dataset for Evaluating Large Language Models and Agents on RTL Design and Verification](https://arxiv.org/abs/2506.14074)
*Nathaniel Pinckney,Chenhui Deng,Chia-Tung Ho,Yun-Da Tsai,Mingjie Liu,Wenfei Zhou,Brucek Khailany,Haoxing Ren*

Main category: cs.LG

TL;DR: CVDP是一个新的硬件设计基准数据集，包含783个问题，涵盖13类任务，旨在推动LLM和智能体研究。


<details>
  <summary>Details</summary>
Motivation: 提供更真实和具有挑战性的硬件设计问题，填补现有研究空白。

Method: 采用开源工具和模型评分基础设施，结合BLEU和基于LLM的评估。

Result: 当前模型在代码生成任务中最高仅34%通过率，表明能力不足。

Conclusion: CVDP突显当前模型的局限性，需进一步研究以实现强健的硬件设计自动化。

Abstract: We present the Comprehensive Verilog Design Problems (CVDP) benchmark, a new dataset and infrastructure to advance LLM and agent research in hardware design and verification. CVDP includes 783 problems across 13 task categories, covering RTL generation, verification, debugging, specification alignment, and technical Q&A authored by experienced hardware engineers. Problems are offered in both non-agentic and agentic formats. The benchmark introduces more realistic and challenging contexts than prior work, with state-of-the-art models achieving no more than 34% pass@1 on code generation. Agentic tasks$\unicode{x2013}$especially those involving RTL reuse and verification$\unicode{x2013}$are particularly difficult. Evaluation uses open-source tools and model scoring infrastructure, with comprehension tasks assessed via BLEU and LLM-based judging. CVDP reveals substantial gaps in current model capabilities, underscoring the need for continued research toward robust, real-world hardware design automation.

</details>


### [101] [Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization](https://arxiv.org/abs/2506.13911)
*Arie Soeteman,Balder ten Cate*

Main category: cs.LG

TL;DR: HEGNNs是一种扩展的图神经网络，通过层次化节点个性化来提高表达能力，能够区分同构图。


<details>
  <summary>Details</summary>
Motivation: 受图同构测试中的个性化-细化方法启发，旨在开发更强大的图神经网络模型。

Method: 提出HEGNNs，使用层次化节点个性化扩展GNNs，并结合子图限制进行实验验证。

Result: HEGNNs在表达能力上优于传统GNNs，实验证实其实际可行性。

Conclusion: HEGNNs为图神经网络提供了一个新的层次化框架，提升了模型的表现力。

Abstract: We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), an expressive extension of graph neural networks (GNNs) with hierarchical node individualization, inspired by the Individualization-Refinement paradigm for graph isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchy of increasingly expressive models that, in the limit, can distinguish graphs up to isomorphism. We provide a logical characterization of HEGNN node classifiers, with and without subgraph restrictions, using graded hybrid logic. This characterization enables us to relate the separating power of HEGNNs to that of higher-order GNNs, GNNs enriched with local homomorphism count features, and color refinement algorithms based on Individualization-Refinement. Our experimental results confirm the practical feasibility of HEGNNs and show benefits in comparison with traditional GNN architectures, both with and without local homomorphism count features.

</details>


### [102] [Convergence-Privacy-Fairness Trade-Off in Personalized Federated Learning](https://arxiv.org/abs/2506.14251)
*Xiyu Zhao,Qimei Cui,Weicai Li,Wei Ni,Ekram Hossain,Quan Z. Sheng,Xiaofeng Tao,Ping Zhang*

Main category: cs.LG

TL;DR: DP-Ditto是一种在差分隐私(DP)保护下的个性化联邦学习(PFL)方法，通过平衡隐私保护、模型收敛和性能公平性，在准确性和公平性上优于现有PFL模型。


<details>
  <summary>Details</summary>
Motivation: 解决个性化联邦学习中隐私保护与模型性能的矛盾，确保在差分隐私下仍能实现高准确性和公平性。

Method: 提出DP-Ditto，分析隐私保证、模型收敛和公平性的权衡，推导个性化模型的收敛上界和最优全局聚合次数，并优化收敛与公平性。

Result: 实验显示DP-Ditto在公平性上优于现有模型32.71%，准确性提升9.66%。

Conclusion: DP-Ditto有效平衡隐私与性能，为个性化联邦学习提供了可靠解决方案。

Abstract: Personalized federated learning (PFL), e.g., the renowned Ditto, strikes a balance between personalization and generalization by conducting federated learning (FL) to guide personalized learning (PL). While FL is unaffected by personalized model training, in Ditto, PL depends on the outcome of the FL. However, the clients' concern about their privacy and consequent perturbation of their local models can affect the convergence and (performance) fairness of PL. This paper presents PFL, called DP-Ditto, which is a non-trivial extension of Ditto under the protection of differential privacy (DP), and analyzes the trade-off among its privacy guarantee, model convergence, and performance distribution fairness. We also analyze the convergence upper bound of the personalized models under DP-Ditto and derive the optimal number of global aggregations given a privacy budget. Further, we analyze the performance fairness of the personalized models, and reveal the feasibility of optimizing DP-Ditto jointly for convergence and fairness. Experiments validate our analysis and demonstrate that DP-Ditto can surpass the DP-perturbed versions of the state-of-the-art PFL models, such as FedAMP, pFedMe, APPLE, and FedALA, by over 32.71% in fairness and 9.66% in accuracy.

</details>


### [103] [Sustainable Machine Learning Retraining: Optimizing Energy Efficiency Without Compromising Accuracy](https://arxiv.org/abs/2506.13838)
*Lorena Poenaru-Olaru,June Sallou,Luis Cruz,Jan Rellermeyer,Arie van Deursen*

Main category: cs.LG

TL;DR: 论文研究了机器学习模型重训练技术的能耗问题，提出了更可持续的重训练方法，比如仅使用最新数据或根据需求触发重训练，以减少能耗。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统依赖于定期重训练以保持可靠性，但传统方法能耗高，亟需研究可持续的重训练技术以减少环境影响。

Method: 通过比较不同重训练技术的能耗和准确率，分析仅使用最新数据和基于需求触发的重训练的效果。

Result: 仅使用最新数据重训练可减少25%能耗，基于需求的重训练可减少40%能耗，同时保持模型准确性。

Conclusion: 研究为ML从业者提供了更节能的重训练建议，有助于设计可持续的机器学习系统。

Abstract: The reliability of machine learning (ML) software systems is heavily influenced by changes in data over time. For that reason, ML systems require regular maintenance, typically based on model retraining. However, retraining requires significant computational demand, which makes it energy-intensive and raises concerns about its environmental impact. To understand which retraining techniques should be considered when designing sustainable ML applications, in this work, we study the energy consumption of common retraining techniques. Since the accuracy of ML systems is also essential, we compare retraining techniques in terms of both energy efficiency and accuracy. We showcase that retraining with only the most recent data, compared to all available data, reduces energy consumption by up to 25\%, being a sustainable alternative to the status quo. Furthermore, our findings show that retraining a model only when there is evidence that updates are necessary, rather than on a fixed schedule, can reduce energy consumption by up to 40\%, provided a reliable data change detector is in place. Our findings pave the way for better recommendations for ML practitioners, guiding them toward more energy-efficient retraining techniques when designing sustainable ML software systems.

</details>
