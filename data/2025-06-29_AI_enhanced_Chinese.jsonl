{"id": "2506.20754", "pdf": "https://arxiv.org/pdf/2506.20754", "abs": "https://arxiv.org/abs/2506.20754", "authors": ["Marina Ara\u00fajo", "J\u00falia Ara\u00fajo", "Romeu Oliveira", "Lucas Romao", "Marcos Kalinowski"], "title": "Domain Knowledge in Requirements Engineering: A Systematic Mapping Study", "categories": ["cs.SE"], "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Domain knowledge is recognized as a key component for the success\nof Requirements Engineering (RE), as it provides the conceptual support needed\nto understand the system context, ensure alignment with stakeholder needs, and\nreduce ambiguity in requirements specification. Despite its relevance, the\nscientific literature still lacks a systematic consolidation of how domain\nknowledge can be effectively used and operationalized in RE. [Goal] This paper\naddresses this gap by offering a comprehensive overview of existing\ncontributions, including methods, techniques, and tools to incorporate domain\nknowledge into RE practices. [Method] We conducted a systematic mapping study\nusing a hybrid search strategy that combines database searches with iterative\nbackward and forward snowballing. [Results] In total, we found 75 papers that\nmet our inclusion criteria. The analysis highlights the main types of\nrequirements addressed, the most frequently considered quality attributes, and\nrecurring challenges in the formalization, acquisition, and long-term\nmaintenance of domain knowledge. The results provide support for researchers\nand practitioners in identifying established approaches and unresolved issues.\nThe study also outlines promising directions for future research, emphasizing\nthe development of scalable, automated, and sustainable solutions to integrate\ndomain knowledge into RE processes. [Conclusion] The study contributes by\nproviding a comprehensive overview that helps to build a conceptual and\nmethodological foundation for knowledge-driven requirements engineering.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u7efc\u8ff0\u4e86\u5982\u4f55\u5c06\u9886\u57df\u77e5\u8bc6\u6709\u6548\u878d\u5165\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u7684\u73b0\u6709\u65b9\u6cd5\u3001\u6280\u672f\u548c\u5de5\u5177\uff0c\u603b\u7ed3\u4e8675\u7bc7\u76f8\u5173\u8bba\u6587\u7684\u4e3b\u8981\u53d1\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u9886\u57df\u77e5\u8bc6\u662f\u9700\u6c42\u5de5\u7a0b\u6210\u529f\u7684\u5173\u952e\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5176\u5982\u4f55\u6709\u6548\u4f7f\u7528\u7684\u7cfb\u7edf\u6027\u603b\u7ed3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u641c\u7d22\u7b56\u7565\uff08\u6570\u636e\u5e93\u641c\u7d22\u4e0e\u8fed\u4ee3\u7684\u5411\u540e\u548c\u5411\u524d\u6eda\u96ea\u7403\u6cd5\uff09\u8fdb\u884c\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u3002", "result": "\u5206\u6790\u4e8675\u7bc7\u8bba\u6587\uff0c\u603b\u7ed3\u4e86\u4e3b\u8981\u9700\u6c42\u7c7b\u578b\u3001\u5e38\u89c1\u8d28\u91cf\u5c5e\u6027\u4ee5\u53ca\u9886\u57df\u77e5\u8bc6\u5f62\u5f0f\u5316\u3001\u83b7\u53d6\u548c\u957f\u671f\u7ef4\u62a4\u7684\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u77e5\u8bc6\u9a71\u52a8\u7684\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6982\u5ff5\u548c\u65b9\u6cd5\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u53d1\u5c55\u7684\u65b9\u5411\u3002"}}
{"id": "2506.20759", "pdf": "https://arxiv.org/pdf/2506.20759", "abs": "https://arxiv.org/abs/2506.20759", "authors": ["Lucas Romao", "Hugo Villamizar", "Romeu Oliveira", "Silvio Alonso", "Marcos Kalinowski"], "title": "Agile Management for Machine Learning: A Systematic Mapping Study", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Machine learning (ML)-enabled systems are present in our society,\ndriving significant digital transformations. The dynamic nature of ML\ndevelopment, characterized by experimental cycles and rapid changes in data,\nposes challenges to traditional project management. Agile methods, with their\nflexibility and incremental delivery, seem well-suited to address this\ndynamism. However, it is unclear how to effectively apply these methods in the\ncontext of ML-enabled systems, where challenges require tailored approaches.\n[Goal] Our goal is to outline the state of the art in agile management for\nML-enabled systems. [Method] We conducted a systematic mapping study using a\nhybrid search strategy that combines database searches with backward and\nforward snowballing iterations. [Results] Our study identified 27 papers\npublished between 2008 and 2024. From these, we identified eight frameworks and\ncategorized recommendations and practices into eight key themes, such as\nIteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable\nModel. The main challenge identified across studies was accurate effort\nestimation for ML-related tasks. [Conclusion] This study contributes by mapping\nthe state of the art and identifying open gaps in the field. While relevant\nwork exists, more robust empirical evaluation is still needed to validate these\ncontributions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u5206\u6790\u4e86\u654f\u6377\u7ba1\u7406\u5728\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u8d4b\u80fd\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\uff0c\u603b\u7ed3\u4e86\u516b\u4e2a\u5173\u952e\u4e3b\u9898\u548c\u4e3b\u8981\u6311\u6218\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u7684\u52a8\u6001\u7279\u6027\u5bf9\u4f20\u7edf\u9879\u76ee\u7ba1\u7406\u63d0\u51fa\u4e86\u6311\u6218\uff0c\u800c\u654f\u6377\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u4f3c\u4e4e\u9002\u5408\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\u7136\u800c\uff0c\u5982\u4f55\u5728ML\u8d4b\u80fd\u7cfb\u7edf\u4e2d\u6709\u6548\u5e94\u7528\u654f\u6377\u65b9\u6cd5\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u91c7\u7528\u6df7\u5408\u641c\u7d22\u7b56\u7565\uff08\u6570\u636e\u5e93\u641c\u7d22\u4e0e\u524d\u540e\u5411\u96ea\u7403\u8fed\u4ee3\u7ed3\u5408\uff09\u8fdb\u884c\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u4e8627\u7bc7\u8bba\u6587\uff0c\u603b\u7ed3\u4e86\u516b\u4e2a\u6846\u67b6\u548c\u4e3b\u9898\uff0c\u5e76\u6307\u51faML\u4efb\u52a1\u4e2d\u7684\u52aa\u529b\u4f30\u8ba1\u662f\u4e3b\u8981\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9886\u57df\u73b0\u72b6\u63d0\u4f9b\u4e86\u6620\u5c04\uff0c\u5e76\u6307\u51fa\u9700\u8981\u66f4\u591a\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u73b0\u6709\u6210\u679c\u3002"}}
{"id": "2506.20851", "pdf": "https://arxiv.org/pdf/2506.20851", "abs": "https://arxiv.org/abs/2506.20851", "authors": ["Srikar Reddy Gadusu", "Larry Callahan", "Samir Lababidi", "Arunasri Nishtala", "Sophia Healey", "Hande McGinty"], "title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach", "categories": ["cs.SE", "cs.AI", "cs.DB"], "comment": null, "summary": "As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u6237\u53cb\u597d\u7684\u65b9\u6cd5\uff0c\u5229\u7528Python\u548crdflib\u5e93\u7b80\u5316Neo4j\u6570\u636e\u5e93\u4e0eOWL\u7684\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u63cf\u8ff0\u903b\u8f91\u77e5\u8bc6\u7684\u9650\u5236\uff0c\u4ee5FDA FAERS\u6570\u636e\u5e93\u4e3a\u4f8b\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u751f\u6210\u7c7b\u548c\u516c\u7406\u7684\u8fc7\u7a0b\u3002", "motivation": "\u968f\u7740\u6570\u636e\u548c\u77e5\u8bc6\u7684\u5feb\u901f\u6269\u5f20\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u590d\u6742\u7684\u63cf\u8ff0\u903b\u8f91\u77e5\u8bc6\uff0c\u9650\u5236\u4e86Neo4j\u4e0eOWL\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u6613\u7528\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Python\u548crdflib\u5e93\u5f00\u53d1\u811a\u672c\uff0c\u81ea\u52a8\u4eceNeo4j\u6570\u636e\u5e93\u4e2d\u751f\u6210OWL\u7684\u7c7b\u548c\u516c\u7406\uff0c\u4ee5FDA FAERS\u6570\u636e\u5e93\u4e3a\u6848\u4f8b\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u4e00\u79cd\u65e0\u9700\u6df1\u5165\u63cf\u8ff0\u903b\u8f91\u77e5\u8bc6\u5373\u53ef\u96c6\u6210Neo4j\u4e0eOWL\u7684\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u751f\u6210\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5feb\u901f\u589e\u957f\u7684\u4e0d\u826f\u836f\u7269\u4e8b\u4ef6\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u672c\u4f53\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u836f\u7269\u5b89\u5168\u76d1\u6d4b\u548c\u516c\u5171\u536b\u751f\u51b3\u7b56\u3002"}}
{"id": "2506.20869", "pdf": "https://arxiv.org/pdf/2506.20869", "abs": "https://arxiv.org/abs/2506.20869", "authors": ["Md Toufique Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Ayman Asad Khan", "Mika Saari", "Pekka Abrahamsson"], "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "categories": ["cs.SE", "cs.AI", "cs.IR", "D.2.11; I.2.6; H.3.3"], "comment": "Accepted as a full paper to the 51st Euromicro Conference on Software\n  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This\n  is the preprint version and not the final camera ready version", "summary": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\uff0c\u8bc4\u4f30\u4e86\u4e94\u4e2a\u9886\u57df\u7684RAG\u7cfb\u7edf\uff0c\u603b\u7ed3\u4e86\u5341\u4e8c\u4e2a\u5173\u952e\u6559\u8bad\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u586b\u8865RAG\u7cfb\u7edf\u5f00\u53d1\u4e0e\u8bc4\u4f30\u7684\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u4e86\u4e94\u4e2a\u9886\u57df\u7684RAG\u5e94\u7528\uff0c\u7ed3\u5408\u591a\u8bed\u8a00OCR\u3001\u8bed\u4e49\u68c0\u7d22\u548c\u9886\u57df\u9002\u914dLLMs\uff0c\u5e76\u901a\u8fc7100\u540d\u7528\u6237\u7684\u7f51\u7edc\u8bc4\u4f30\u8fdb\u884c\u516d\u7ef4\u5206\u6790\u3002", "result": "\u7528\u6237\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u5728\u6613\u7528\u6027\u3001\u76f8\u5173\u6027\u3001\u900f\u660e\u5ea6\u7b49\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u540c\u65f6\u603b\u7ed3\u4e86\u6280\u672f\u548c\u4f26\u7406\u6311\u6218\u3002", "conclusion": "RAG\u7cfb\u7edf\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u89e3\u51b3\u6280\u672f\u548c\u4f26\u7406\u95ee\u9898\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2506.20703", "pdf": "https://arxiv.org/pdf/2506.20703", "abs": "https://arxiv.org/abs/2506.20703", "authors": ["Vaibhav Vavilala", "Seemandhar Jain", "Rahul Vasanth", "D. A. Forsyth", "Anand Bhattad"], "title": "Generative Blocks World: Moving Things Around in Pictures", "categories": ["cs.GR", "cs.CV"], "comment": "23 pages, 16 figures, 2 tables", "summary": "We describe Generative Blocks World to interact with the scene of a generated\nimage by manipulating simple geometric abstractions. Our method represents\nscenes as assemblies of convex 3D primitives, and the same scene can be\nrepresented by different numbers of primitives, allowing an editor to move\neither whole structures or small details. Once the scene geometry has been\nedited, the image is generated by a flow-based method which is conditioned on\ndepth and a texture hint. Our texture hint takes into account the modified 3D\nprimitives, exceeding texture-consistency provided by existing key-value\ncaching techniques. These texture hints (a) allow accurate object and camera\nmoves and (b) largely preserve the identity of objects depicted. Quantitative\nand qualitative experiments demonstrate that our approach outperforms prior\nworks in visual fidelity, editability, and compositional generalization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Generative Blocks World\u65b9\u6cd5\uff0c\u901a\u8fc7\u64cd\u7eb5\u7b80\u5355\u7684\u51e0\u4f55\u62bd\u8c61\u6765\u751f\u6210\u548c\u7f16\u8f91\u56fe\u50cf\u573a\u666f\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6027\u548c\u53ef\u7f16\u8f91\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u7f16\u8f91\u56fe\u50cf\u573a\u666f\u65f6\u96be\u4ee5\u517c\u987e\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u7eb9\u7406\u4e00\u81f4\u6027\uff0c\u9650\u5236\u4e86\u7f16\u8f91\u7684\u7075\u6d3b\u6027\u548c\u56fe\u50cf\u7684\u771f\u5b9e\u6027\u3002", "method": "\u5c06\u573a\u666f\u8868\u793a\u4e3a\u51f83D\u57fa\u5143\u7684\u7ec4\u5408\uff0c\u5141\u8bb8\u4e0d\u540c\u6570\u91cf\u7684\u57fa\u5143\u8868\u793a\u540c\u4e00\u573a\u666f\uff1b\u57fa\u4e8e\u6d41\u7684\u65b9\u6cd5\u5728\u6df1\u5ea6\u548c\u7eb9\u7406\u63d0\u793a\u7684\u6761\u4ef6\u4e0b\u751f\u6210\u56fe\u50cf\u3002", "result": "\u65b9\u6cd5\u5728\u89c6\u89c9\u4fdd\u771f\u5ea6\u3001\u53ef\u7f16\u8f91\u6027\u548c\u7ec4\u5408\u6cdb\u5316\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u5de5\u4f5c\u3002", "conclusion": "Generative Blocks World\u901a\u8fc7\u51e0\u4f55\u548c\u7eb9\u7406\u7684\u8054\u5408\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u50cf\u7f16\u8f91\u7684\u6548\u679c\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2506.20674", "pdf": "https://arxiv.org/pdf/2506.20674", "abs": "https://arxiv.org/abs/2506.20674", "authors": ["Ankur Lahiry", "Ayush Pokharel", "Seth Ockerman", "Amal Gueroudji", "Line Pouchard", "Tanzima Z. Islam"], "title": "Scalable GPU Performance Variability Analysis framework", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "Analyzing large-scale performance logs from GPU profilers often requires\nterabytes of memory and hours of runtime, even for basic summaries. These\nconstraints prevent timely insight and hinder the integration of performance\nanalytics into automated workflows. Existing analysis tools typically process\ndata sequentially, making them ill-suited for HPC workflows with growing trace\ncomplexity and volume. We introduce a distributed data analysis framework that\nscales with dataset size and compute availability. Rather than treating the\ndataset as a single entity, our system partitions it into independently\nanalyzable shards and processes them concurrently across MPI ranks. This design\nreduces per-node memory pressure, avoids central bottlenecks, and enables\nlow-latency exploration of high-dimensional trace data. We apply the framework\nto end-to-end Nsight Compute traces from real HPC and AI workloads, demonstrate\nits ability to diagnose performance variability, and uncover the impact of\nmemory transfer latency on GPU kernel behavior.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u6570\u636e\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u5206\u6790\u5927\u89c4\u6a21GPU\u6027\u80fd\u65e5\u5fd7\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u5728\u5904\u7406\u9ad8\u590d\u6742\u5ea6\u548c\u5927\u5bb9\u91cf\u6570\u636e\u65f6\u7684\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684GPU\u6027\u80fd\u65e5\u5fd7\u5206\u6790\u5de5\u5177\u56e0\u5185\u5b58\u548c\u65f6\u95f4\u6d88\u8017\u8fc7\u5927\uff0c\u96be\u4ee5\u96c6\u6210\u5230\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4e2d\uff0c\u9650\u5236\u4e86\u6027\u80fd\u5206\u6790\u7684\u53ca\u65f6\u6027\u548c\u6548\u7387\u3002", "method": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u5c06\u6570\u636e\u96c6\u5206\u7247\u4e3a\u53ef\u5e76\u884c\u5206\u6790\u7684\u72ec\u7acb\u5355\u5143\uff0c\u5229\u7528MPI\u8de8\u8282\u70b9\u5e76\u53d1\u5904\u7406\uff0c\u964d\u4f4e\u4e86\u5355\u8282\u70b9\u5185\u5b58\u538b\u529b\uff0c\u907f\u514d\u4e86\u4e2d\u5fc3\u5316\u74f6\u9888\u3002", "result": "\u6846\u67b6\u6210\u529f\u5e94\u7528\u4e8e\u5b9e\u9645HPC\u548cAI\u5de5\u4f5c\u8d1f\u8f7d\u7684Nsight Compute\u65e5\u5fd7\uff0c\u80fd\u591f\u8bca\u65ad\u6027\u80fd\u53d8\u5f02\u6027\uff0c\u5e76\u63ed\u793a\u5185\u5b58\u4f20\u8f93\u5ef6\u8fdf\u5bf9GPU\u5185\u6838\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u5206\u5e03\u5f0f\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u6027\u80fd\u5206\u6790\u7684\u6548\u7387\uff0c\u4e3a\u9ad8\u590d\u6742\u5ea6\u548c\u5927\u5bb9\u91cf\u6570\u636e\u7684\u5b9e\u65f6\u63a2\u7d22\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.21149", "pdf": "https://arxiv.org/pdf/2506.21149", "abs": "https://arxiv.org/abs/2506.21149", "authors": ["Lisa-Marie Jaser", "Jacobo Toran"], "title": "Pebble Games and Algebraic Proof Systems", "categories": ["cs.LO"], "comment": null, "summary": "Analyzing refutations of the well known 0pebbling formulas Peb$(G)$ we prove\nsome new strong connections between pebble games and algebraic proof system,\nshowing that there is a parallelism between the reversible, black and\nblack-white pebbling games on one side, and the three algebraic proof systems\nNullstellensatz, Monomial Calculus and Polynomial Calculus on the other side.\nIn particular we prove that for any DAG $G$ with a single sink, if there is a\nMonomial Calculus refutation for Peb$(G)$ having simultaneously degree $s$ and\nsize $t$ then there is a black pebbling strategy on $G$ with space $s$ and time\n$t+s$. Also if there is a black pebbling strategy for $G$ with space $s$ and\ntime $t$ it is possible to extract from it a MC refutation for Peb$(G)$ having\nsimultaneously degree $s$ and size $ts$. These results are analogous to those\nproven in {deRezende et al.21} for the case of reversible pebbling and\nNullstellensatz. Using them we prove degree separations between NS, MC and PC,\nas well as strong degree-size tradeoffs for MC.\n  We also notice that for any directed acyclic graph $G$ the space needed in a\npebbling strategy on $G$, for the three versions of the game, reversible, black\nand black-white, exactly matches the variable space complexity of a refutation\nof the corresponding pebbling formula Peb$(G)$ in each of the algebraic proof\nsystems NS, MC and PC. Using known pebbling bounds on graphs, this connection\nimplies separations between the corresponding variable space measures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86pebble\u6e38\u620f\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u5f3a\u8fde\u63a5\uff0c\u8bc1\u660e\u4e86pebble\u6e38\u620f\u7684\u7b56\u7565\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e2d\u7684\u5ea6\u4e0e\u5927\u5c0f\u4e4b\u95f4\u5b58\u5728\u5bf9\u5e94\u5173\u7cfb\u3002", "motivation": "\u63a2\u7d22pebble\u6e38\u620f\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63ed\u793a\u4e24\u8005\u4e4b\u95f4\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790pebble\u516c\u5f0f\u7684\u5426\u5b9a\uff0c\u5c06pebble\u6e38\u620f\u7684\u7b56\u7565\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u7684\u5ea6\u3001\u5927\u5c0f\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u8fdb\u884c\u5bf9\u5e94\u3002", "result": "\u8bc1\u660e\u4e86pebble\u6e38\u620f\u7684\u7b56\u7565\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u7684\u53c2\u6570\u4e4b\u95f4\u5b58\u5728\u76f4\u63a5\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u5f97\u51fa\u4e86\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u5ea6\u5206\u79bb\u548c\u5f3a\u89c4\u6a21-\u5ea6\u6743\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3apebble\u6e38\u620f\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u8054\u7cfb\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u652f\u6301\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u4e9b\u8054\u7cfb\u5982\u4f55\u7528\u4e8e\u8bc1\u660e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u7684\u5dee\u5f02\u6027\u3002"}}
{"id": "2506.20944", "pdf": "https://arxiv.org/pdf/2506.20944", "abs": "https://arxiv.org/abs/2506.20944", "authors": ["Van-Hoang Phan", "Long-Khanh Pham", "Dang Vu", "Anh-Duy Tran", "Minh-Son Dao"], "title": "E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs", "categories": ["cs.MM", "cs.CR"], "comment": "Accepted to AsiaCCS 2025 @ SCID", "summary": "The rapid spread of misinformation in mobile and wireless networks presents\ncritical security challenges. This study introduces a training-free,\nretrieval-based multimodal fact verification system that leverages pretrained\nvision-language models and large language models for credibility assessment. By\ndynamically retrieving and cross-referencing trusted data sources, our approach\nmitigates vulnerabilities of traditional training-based models, such as\nadversarial attacks and data poisoning. Additionally, its lightweight design\nenables seamless edge device integration without extensive on-device\nprocessing. Experiments on two fact-checking benchmarks achieve SOTA results,\nconfirming its effectiveness in misinformation detection and its robustness\nagainst various attack vectors, highlighting its potential to enhance security\nin mobile and wireless communication environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u68c0\u7d22\u5f0f\u591a\u6a21\u6001\u4e8b\u5b9e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u68c0\u7d22\u53ef\u4fe1\u6570\u636e\u6e90\u6765\u8bc4\u4f30\u4fe1\u606f\u53ef\u4fe1\u5ea6\uff0c\u6709\u6548\u5e94\u5bf9\u4f20\u7edf\u8bad\u7ec3\u6a21\u578b\u7684\u6f0f\u6d1e\u3002", "motivation": "\u79fb\u52a8\u548c\u65e0\u7ebf\u7f51\u7edc\u4e2d\u9519\u8bef\u4fe1\u606f\u7684\u5feb\u901f\u4f20\u64ad\u5e26\u6765\u4e86\u5173\u952e\u7684\u5b89\u5168\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1\u4fe1\u606f\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u52a8\u6001\u68c0\u7d22\u53ef\u4fe1\u6570\u636e\u6e90\uff0c\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u7cfb\u7edf\uff0c\u5b9e\u73b0\u65e0\u9700\u8bad\u7ec3\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u3002", "result": "\u5728\u4e24\u4e2a\u4e8b\u5b9e\u68c0\u67e5\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86SOTA\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u548c\u6297\u653b\u51fb\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5177\u6709\u5728\u79fb\u52a8\u548c\u65e0\u7ebf\u901a\u4fe1\u73af\u5883\u4e2d\u63d0\u5347\u5b89\u5168\u6027\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u653b\u51fb\u548c\u8f7b\u91cf\u7ea7\u90e8\u7f72\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.20762", "pdf": "https://arxiv.org/pdf/2506.20762", "abs": "https://arxiv.org/abs/2506.20762", "authors": ["Shisheng Hu", "Jie Gao", "Xue Qin", "Conghao Zhou", "Xinyu Huang", "Mushu Li", "Mingcheng He", "Xuemin Shen"], "title": "Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks", "categories": ["cs.NI", "eess.SP"], "comment": "Accepted by IEEE Transactions on Cognitive Communications and\n  Networking", "summary": "In this paper, we propose a novel drift-adaptive slicing-based resource\nmanagement scheme for cooperative integrated sensing and communication (ISAC)\nnetworks. Particularly, we establish two network slices to provide sensing and\ncommunication services, respectively. In the large-timescale planning for the\nslices, we partition the sensing region of interest (RoI) of each mobile device\nand reserve network resources accordingly, facilitating low-complexity\ndistance-based sensing target assignment in small timescales. To cope with the\nnon-stationary spatial distributions of mobile devices and sensing targets,\nwhich can result in the drift in modeling the distributions and ineffective\nplanning decisions, we construct digital twins (DTs) of the slices. In each DT,\na drift-adaptive statistical model and an emulation function are developed for\nthe spatial distributions in the corresponding slice, which facilitates\nclosed-form decision-making and efficient validation of a planning decision,\nrespectively. Numerical results show that the proposed drift-adaptive\nslicing-based resource management scheme can increase the service satisfaction\nratio by up to 18% and reduce resource consumption by up to 13.1% when compared\nwith benchmark schemes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5207\u7247\u7684\u6f02\u79fb\u81ea\u9002\u5e94\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\uff0c\u7528\u4e8e\u534f\u4f5c\u5f0f\u7efc\u5408\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7f51\u7edc\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u63d0\u5347\u670d\u52a1\u6ee1\u610f\u5ea6\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\u96be\u4ee5\u5e94\u5bf9\u79fb\u52a8\u8bbe\u5907\u548c\u611f\u77e5\u76ee\u6807\u7684\u975e\u9759\u6001\u7a7a\u95f4\u5206\u5e03\uff0c\u5bfc\u81f4\u89c4\u5212\u51b3\u7b56\u5931\u6548\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u6765\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "method": "\u91c7\u7528\u7f51\u7edc\u5207\u7247\u6280\u672f\uff0c\u5206\u522b\u63d0\u4f9b\u611f\u77e5\u548c\u901a\u4fe1\u670d\u52a1\uff1b\u6784\u5efa\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u5f00\u53d1\u6f02\u79fb\u81ea\u9002\u5e94\u7edf\u8ba1\u6a21\u578b\u548c\u4eff\u771f\u529f\u80fd\uff0c\u4f18\u5316\u51b3\u7b56\u548c\u9a8c\u8bc1\u3002", "result": "\u4e0e\u57fa\u51c6\u65b9\u6848\u76f8\u6bd4\uff0c\u670d\u52a1\u6ee1\u610f\u5ea6\u6bd4\u7387\u63d0\u5347\u4e8618%\uff0c\u8d44\u6e90\u6d88\u8017\u51cf\u5c11\u4e8613.1%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6f02\u79fb\u81ea\u9002\u5e94\u5207\u7247\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347ISAC\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u7684\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.21203", "pdf": "https://arxiv.org/pdf/2506.21203", "abs": "https://arxiv.org/abs/2506.21203", "authors": ["Jey Puget Gil", "Emmanuel Coquery", "John Samuel", "Gilles Gesquiere"], "title": "Condensed Representation of RDF and its Application on Graph Versioning", "categories": ["cs.DB"], "comment": "20 pages, 3 figures", "summary": "The study of the evolving phenomena in a domain helps to understand the\nrelationships between entities at different points in time and predict future\ntrends. These phenomena, often complex, can be represented using knowledge\ngraphs, which have the capability to model heterogeneous data from multiple\nsources. Nowadays, a considerable amount of sources delivering periodic updates\nto knowledge graphs in various domains is openly available. The evolution of\ndata is of interest to knowledge graph management systems, and therefore it is\ncrucial to organize these constantly evolving data to make them easily\naccessible and exploitable for analyzes. In this article, we will present and\nformalize the condensed representation of these evolving graphs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5173\u4e8e\u77e5\u8bc6\u56fe\u8c31\u6f14\u5316\u7684\u51dd\u7f29\u8868\u793a\u65b9\u6cd5\uff0c\u7528\u4e8e\u7ba1\u7406\u4e0d\u65ad\u53d8\u5316\u7684\u6570\u636e\u3002", "motivation": "\u7814\u7a76\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u6f14\u5316\u73b0\u8c61\u6709\u52a9\u4e8e\u7406\u89e3\u5b9e\u4f53\u95f4\u5173\u7cfb\u5e76\u9884\u6d4b\u672a\u6765\u8d8b\u52bf\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u9ad8\u6548\u7684\u6570\u636e\u7ec4\u7ec7\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5e76\u5f62\u5f0f\u5316\u4e86\u6f14\u5316\u56fe\u8c31\u7684\u51dd\u7f29\u8868\u793a\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u7ba1\u7406\u548c\u5229\u7528\u4e0d\u65ad\u66f4\u65b0\u7684\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u3002", "conclusion": "\u51dd\u7f29\u8868\u793a\u65b9\u6cd5\u4e3a\u77e5\u8bc6\u56fe\u8c31\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u4fbf\u4e8e\u6570\u636e\u5206\u6790\u548c\u5229\u7528\u3002"}}
{"id": "2506.20748", "pdf": "https://arxiv.org/pdf/2506.20748", "abs": "https://arxiv.org/abs/2506.20748", "authors": ["Jingshu Li", "Zicheng Zhu", "Renwen Zhang", "Yi-Chieh Lee"], "title": "Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Chatbots are increasingly integrated into people's lives and are widely used\nto help people. Recently, there has also been growing interest in the reverse\ndirection-humans help chatbots-due to a wide range of benefits including better\nchatbot performance, human well-being, and collaborative outcomes. However,\nlittle research has explored the factors that motivate people to help chatbots.\nTo address this gap, we draw on the Computers Are Social Actors (CASA)\nframework to examine how chatbot anthropomorphism-including human-like\nidentity, emotional expression, and non-verbal expression-influences human\nempathy toward chatbots and their subsequent prosocial behaviors and\nintentions. We also explore people's own interpretations of their prosocial\nbehaviors toward chatbots. We conducted an online experiment (N = 244) in which\nchatbots made mistakes in a collaborative image labeling task and explained the\nreasons to participants. We then measured participants' prosocial behaviors and\nintentions toward the chatbots. Our findings revealed that human identity and\nemotional expression of chatbots increased participants' prosocial behavior and\nintention toward chatbots, with empathy mediating these effects. Qualitative\nanalysis further identified two motivations for participants' prosocial\nbehaviors: empathy for the chatbot and perceiving the chatbot as human-like. We\ndiscuss the implications of these results for understanding and promoting human\nprosocial behaviors toward chatbots.", "AI": {"tldr": "\u7814\u7a76\u4e86\u804a\u5929\u673a\u5668\u4eba\u7684\u4eba\u5f62\u5316\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u5bf9\u5176\u7684\u5171\u60c5\u884c\u4e3a\uff0c\u53d1\u73b0\u4eba\u7c7b\u8eab\u4efd\u548c\u60c5\u611f\u8868\u8fbe\u80fd\u4fc3\u8fdb\u5171\u60c5\u884c\u4e3a\uff0c\u5171\u60c5\u662f\u5173\u952e\u4e2d\u4ecb\u56e0\u7d20\u3002", "motivation": "\u63a2\u7d22\u4eba\u7c7b\u5e2e\u52a9\u804a\u5929\u673a\u5668\u4eba\u7684\u52a8\u673a\u56e0\u7d20\uff0c\u586b\u8865\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u57fa\u4e8eCASA\u6846\u67b6\uff0c\u8bbe\u8ba1\u5728\u7ebf\u5b9e\u9a8c\uff08N=244\uff09\uff0c\u6d4b\u91cf\u53c2\u4e0e\u8005\u5bf9\u804a\u5929\u673a\u5668\u4eba\u7684\u5171\u60c5\u884c\u4e3a\u548c\u610f\u56fe\u3002", "result": "\u804a\u5929\u673a\u5668\u4eba\u7684\u4eba\u5f62\u5316\u7279\u5f81\uff08\u8eab\u4efd\u548c\u60c5\u611f\u8868\u8fbe\uff09\u663e\u8457\u589e\u52a0\u4eba\u7c7b\u7684\u5171\u60c5\u884c\u4e3a\u548c\u610f\u56fe\u3002", "conclusion": "\u5171\u60c5\u662f\u7406\u89e3\u4eba\u7c7b\u5bf9\u804a\u5929\u673a\u5668\u4eba\u4eb2\u793e\u4f1a\u884c\u4e3a\u7684\u5173\u952e\uff0c\u5e76\u6709\u52a9\u4e8e\u4fc3\u8fdb\u6b64\u7c7b\u884c\u4e3a\u3002"}}
{"id": "2506.21073", "pdf": "https://arxiv.org/pdf/2506.21073", "abs": "https://arxiv.org/abs/2506.21073", "authors": ["Ilias Papalamprou", "Nikolaos Fotos", "Nikolaos Chatzivasileiadis", "Anna Angelogianni", "Dimosthenis Masouros", "Dimitrios Soudris"], "title": "Post-Quantum and Blockchain-Based Attestation for Trusted FPGAs in B5G Networks", "categories": ["cs.AR"], "comment": null, "summary": "The advent of 5G and beyond has brought increased performance networks,\nfacilitating the deployment of services closer to the user. To meet performance\nrequirements such services require specialized hardware, such as Field\nProgrammable Gate Arrays (FPGAs). However, FPGAs are often deployed in\nunprotected environments, leaving the user's applications vulnerable to\nmultiple attacks. With the rise of quantum computing, which threatens the\nintegrity of widely-used cryptographic algorithms, the need for a robust\nsecurity infrastructure is even more crucial. In this paper we introduce a\nhybrid hardware-software solution utilizing remote attestation to securely\nconfigure FPGAs, while integrating Post-Quantum Cryptographic (PQC) algorithms\nfor enhanced security. Additionally, to enable trustworthiness across the whole\nedge computing continuum, our solution integrates a blockchain infrastructure,\nensuring the secure storage of any security evidence. We evaluate the proposed\nsecure configuration process under different PQC algorithms in two FPGA\nfamilies, showcasing only 2% overheard compared to the non PQC approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8fdc\u7a0b\u8ba4\u8bc1\u548c\u91cf\u5b50\u5b89\u5168\u52a0\u5bc6\u7b97\u6cd5\u7684\u786c\u4ef6-\u8f6f\u4ef6\u6df7\u5408\u65b9\u6848\uff0c\u4ee5\u5b89\u5168\u914d\u7f6eFPGA\uff0c\u5e76\u5229\u7528\u533a\u5757\u94fe\u786e\u4fdd\u5b89\u5168\u6027\u3002", "motivation": "5G\u53ca\u66f4\u9ad8\u7f51\u7edc\u7684\u53d1\u5c55\u8981\u6c42\u66f4\u9ad8\u7684\u6027\u80fd\uff0c\u4f46FPGA\u90e8\u7f72\u5728\u975e\u4fdd\u62a4\u73af\u5883\u4e2d\u5bb9\u6613\u53d7\u5230\u653b\u51fb\uff0c\u5c24\u5176\u662f\u91cf\u5b50\u8ba1\u7b97\u7684\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u8fdc\u7a0b\u8ba4\u8bc1\u548c\u91cf\u5b50\u5b89\u5168\u52a0\u5bc6\u7b97\u6cd5\uff08PQC\uff09\uff0c\u5e76\u96c6\u6210\u533a\u5757\u94fe\u5b58\u50a8\u5b89\u5168\u8bc1\u636e\u3002", "result": "\u5728\u4e24\u79cdFPGA\u5bb6\u65cf\u4e2d\u6d4b\u8bd5\u663e\u793a\uff0c\u76f8\u6bd4\u975ePQC\u65b9\u6cd5\uff0c\u6027\u80fd\u5f00\u9500\u4ec5\u4e3a2%\u3002", "conclusion": "\u8be5\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347FPGA\u7684\u5b89\u5168\u6027\uff0c\u9002\u5e94\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u7684\u6311\u6218\u3002"}}
{"id": "2506.20782", "pdf": "https://arxiv.org/pdf/2506.20782", "abs": "https://arxiv.org/abs/2506.20782", "authors": ["Marc Bara"], "title": "Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing", "categories": ["cs.NE", "cs.ET", "cs.LG", "eess.SP", "68T07, 94A08", "I.2.6; G.1.6; B.7.1"], "comment": "8 pages, 2 figures, patent pending", "summary": "We present the first theoretical framework for applying spiking neural\nnetworks (SNNs) to synthetic aperture radar (SAR) interferometric phase\nunwrapping. Despite extensive research in both domains, our comprehensive\nliterature review confirms that SNNs have never been applied to phase\nunwrapping, representing a significant gap in current methodologies. As Earth\nobservation data volumes continue to grow exponentially (with missions like\nNISAR expected to generate 100PB in two years) energy-efficient processing\nbecomes critical for sustainable data center operations. SNNs, with their\nevent-driven computation model, offer potential energy savings of 30-100x\ncompared to conventional approaches while maintaining comparable accuracy. We\ndevelop spike encoding schemes specifically designed for wrapped phase data,\npropose SNN architectures that leverage the spatial propagation nature of phase\nunwrapping, and provide theoretical analysis of computational complexity and\nconvergence properties. Our framework demonstrates how the temporal dynamics\ninherent in SNNs can naturally model the spatial continuity constraints\nfundamental to phase unwrapping. This work opens a new research direction at\nthe intersection of neuromorphic computing and SAR interferometry, offering a\ncomplementary approach to existing algorithms that could enable more\nsustainable large-scale InSAR processing.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u5c06\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u5e94\u7528\u4e8e\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\uff08SAR\uff09\u5e72\u6d89\u76f8\u4f4d\u89e3\u7f20\u7684\u7406\u8bba\u6846\u67b6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u4e3a\u53ef\u6301\u7eed\u7684\u5927\u89c4\u6a21InSAR\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u968f\u7740\u5730\u7403\u89c2\u6d4b\u6570\u636e\u91cf\u7684\u6307\u6570\u589e\u957f\uff08\u5982NISAR\u4efb\u52a1\u9884\u8ba1\u4e24\u5e74\u5185\u751f\u6210100PB\u6570\u636e\uff09\uff0c\u9ad8\u6548\u80fd\u8017\u5904\u7406\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002SNN\u51ed\u501f\u5176\u4e8b\u4ef6\u9a71\u52a8\u8ba1\u7b97\u6a21\u578b\uff0c\u6709\u671b\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u8282\u770130-100\u500d\u80fd\u8017\u3002", "method": "\u5f00\u53d1\u4e86\u9488\u5bf9\u76f8\u4f4d\u89e3\u7f20\u7684\u8109\u51b2\u7f16\u7801\u65b9\u6848\uff0c\u63d0\u51fa\u4e86\u5229\u7528\u76f8\u4f4d\u89e3\u7f20\u7a7a\u95f4\u4f20\u64ad\u7279\u6027\u7684SNN\u67b6\u6784\uff0c\u5e76\u8fdb\u884c\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u6536\u655b\u6027\u7684\u7406\u8bba\u5206\u6790\u3002", "result": "\u8bc1\u5b9e\u4e86SNN\u7684\u65f6\u7a7a\u52a8\u6001\u7279\u6027\u81ea\u7136\u5730\u5efa\u6a21\u4e86\u76f8\u4f4d\u89e3\u7f20\u6240\u9700\u7684\u7a7a\u95f4\u8fde\u7eed\u6027\u7ea6\u675f\uff0c\u4e3aSNN\u4e0eSAR\u5e72\u6d89\u4eea\u4ea4\u53c9\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u4e3a\u73b0\u6709\u7b97\u6cd5\u63d0\u4f9b\u4e86\u8865\u5145\uff0c\u8fd8\u53ef\u80fd\u63a8\u52a8\u66f4\u53ef\u6301\u7eed\u7684\u5927\u89c4\u6a21InSAR\u5904\u7406\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.20673", "pdf": "https://arxiv.org/pdf/2506.20673", "abs": "https://arxiv.org/abs/2506.20673", "authors": ["Yongqian Sun", "Xijie Pan", "Xiao Xiong", "Lei Tao", "Jiaju Wang", "Shenglin Zhang", "Yuan Yuan", "Yuqi Li", "Kunlin Jian"], "title": "ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Network failure diagnosis is challenging yet critical for high-performance\ncomputing (HPC) systems. Existing methods cannot be directly applied to HPC\nscenarios due to data heterogeneity and lack of accuracy. This paper proposes a\nnovel framework, called ClusterRCA, to localize culprit nodes and determine\nfailure types by leveraging multimodal data. ClusterRCA extracts features from\ntopologically connected network interface controller (NIC) pairs to analyze the\ndiverse, multimodal data in HPC systems. To accurately localize culprit nodes\nand determine failure types, ClusterRCA combines classifier-based and\ngraph-based approaches. A failure graph is constructed based on the output of\nthe state classifier, and then it performs a customized random walk on the\ngraph to localize the root cause. Experiments on datasets collected by a\ntop-tier global HPC device vendor show ClusterRCA achieves high accuracy in\ndiagnosing network failure for HPC systems. ClusterRCA also maintains robust\nperformance across different application scenarios.", "AI": {"tldr": "ClusterRCA\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u5b9a\u4f4dHPC\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u8282\u70b9\u548c\u7c7b\u578b\uff0c\u7ed3\u5408\u5206\u7c7b\u5668\u548c\u56fe\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u9ad8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u7f51\u7edc\u6545\u969c\u8bca\u65ad\u5bf9HPC\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u56e0\u6570\u636e\u5f02\u6784\u6027\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u3002", "method": "\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u63d0\u53d6\u62d3\u6251\u8fde\u63a5\u7684NIC\u5bf9\u7279\u5f81\uff0c\u7ed3\u5408\u5206\u7c7b\u5668\u548c\u56fe\u65b9\u6cd5\u6784\u5efa\u6545\u969c\u56fe\u5e76\u8fdb\u884c\u968f\u673a\u6e38\u8d70\u3002", "result": "\u5728\u9876\u7ea7HPC\u8bbe\u5907\u5546\u6570\u636e\u96c6\u4e0a\uff0cClusterRCA\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u8de8\u573a\u666f\u9c81\u68d2\u6027\u3002", "conclusion": "ClusterRCA\u4e3aHPC\u7f51\u7edc\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.20883", "pdf": "https://arxiv.org/pdf/2506.20883", "abs": "https://arxiv.org/abs/2506.20883", "authors": ["Kyanna Dagenais", "Istvan David"], "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "Accepted for ACM/IEEE MODELS'25", "summary": "Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u4eba\u7c7b\u6307\u5bfc\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f00\u53d1\u590d\u6742\u6a21\u578b\u8f6c\u6362\uff08MT\uff09\u5e8f\u5217\u3002\u4eba\u7c7b\u6307\u5bfc\u80fd\u663e\u8457\u63d0\u5347RL\u6027\u80fd\uff0c\u5373\u4f7f\u5efa\u8bae\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u590d\u6742\u6a21\u578b\u8f6c\u6362\uff08\u5982\u6a21\u578b\u540c\u6b65\u3001\u81ea\u52a8\u4fee\u590d\uff09\u7684\u5f00\u53d1\u5bb9\u6613\u51fa\u9519\u4e14\u96be\u4ee5\u624b\u52a8\u5b8c\u6210\u3002RL\u867d\u7136\u9002\u5408\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e2d\u6027\u80fd\u4e0d\u8db3\u3002\u4eba\u7c7b\u6307\u5bfc\u53ef\u4ee5\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6280\u672f\u6846\u67b6\uff0c\u5c06\u7528\u6237\u5b9a\u4e49\u7684MT\u6620\u5c04\u5230RL\u539f\u8bed\uff0c\u5e76\u901a\u8fc7RL\u7a0b\u5e8f\u6267\u884c\u4ee5\u5bfb\u627e\u6700\u4f18MT\u5e8f\u5217\u3002\u4eba\u7c7b\u5efa\u8bae\uff08\u5373\u4f7f\u4e0d\u786e\u5b9a\uff09\u88ab\u6574\u5408\u5230RL\u8fc7\u7a0b\u4e2d\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0c\u4eba\u7c7b\u6307\u5bfc\u663e\u8457\u63d0\u5347RL\u6027\u80fd\uff0c\u5e76\u66f4\u9ad8\u6548\u5730\u5f00\u53d1\u590d\u6742MT\u5e8f\u5217\u3002\u4e0d\u786e\u5b9a\u6027\u548c\u53ca\u65f6\u6027\u4e4b\u95f4\u7684\u6743\u8861\u4f18\u5316\u4e86\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aRL\u9a71\u52a8\u7684\u201c\u4eba\u5728\u73af\u8def\u201d\u5de5\u7a0b\u65b9\u6cd5\u8fc8\u51fa\u4e00\u6b65\uff0c\u8bc1\u660e\u4eba\u7c7b\u6307\u5bfc\u5bf9\u590d\u6742MT\u5f00\u53d1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.20875", "pdf": "https://arxiv.org/pdf/2506.20875", "abs": "https://arxiv.org/abs/2506.20875", "authors": ["Chengan He", "Junxuan Li", "Tobias Kirschstein", "Artem Sevastopolsky", "Shunsuke Saito", "Qingyang Tan", "Javier Romero", "Chen Cao", "Holly Rushmeier", "Giljoo Nam"], "title": "3DGH: 3D Head Generation with Composable Hair and Face", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to SIGGRAPH 2025. Project page:\n  https://c-he.github.io/projects/3dgh/", "summary": "We present 3DGH, an unconditional generative model for 3D human heads with\ncomposable hair and face components. Unlike previous work that entangles the\nmodeling of hair and face, we propose to separate them using a novel data\nrepresentation with template-based 3D Gaussian Splatting, in which deformable\nhair geometry is introduced to capture the geometric variations across\ndifferent hairstyles. Based on this data representation, we design a 3D\nGAN-based architecture with dual generators and employ a cross-attention\nmechanism to model the inherent correlation between hair and face. The model is\ntrained on synthetic renderings using carefully designed objectives to\nstabilize training and facilitate hair-face separation. We conduct extensive\nexperiments to validate the design choice of 3DGH, and evaluate it both\nqualitatively and quantitatively by comparing with several state-of-the-art 3D\nGAN methods, demonstrating its effectiveness in unconditional full-head image\nsynthesis and composable 3D hairstyle editing. More details will be available\non our project page: https://c-he.github.io/projects/3dgh/.", "AI": {"tldr": "3DGH\u662f\u4e00\u79cd\u65e0\u6761\u4ef6\u751f\u62103D\u4eba\u5934\u90e8\u7684\u6a21\u578b\uff0c\u53ef\u5c06\u5934\u53d1\u548c\u9762\u90e8\u7ec4\u4ef6\u5206\u79bb\u5efa\u6a21\uff0c\u4f7f\u7528\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\u7684\u65b0\u6570\u636e\u8868\u793a\u548c\u53cc\u751f\u6210\u5668\u67b6\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u5934\u53d1\u548c\u9762\u90e8\u5408\u6210\u4e0e\u7f16\u8f91\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u578b\u901a\u5e38\u5c06\u5934\u53d1\u548c\u9762\u90e8\u7ea0\u7f20\u5728\u4e00\u8d77\u5efa\u6a21\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u30023DGH\u65e8\u5728\u901a\u8fc7\u5206\u79bb\u5efa\u6a21\u548c\u5f15\u5165\u53ef\u53d8\u5f62\u5934\u53d1\u51e0\u4f55\u4f53\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u5934\u53d1\u548c\u9762\u90e8\u5408\u6210\u4e0e\u7f16\u8f91\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u677f\u76843D\u9ad8\u65af\u6cfc\u6e85\u6570\u636e\u8868\u793a\uff0c\u8bbe\u8ba1\u53cc\u751f\u6210\u5668GAN\u67b6\u6784\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5efa\u6a21\u5934\u53d1\u548c\u9762\u90e8\u7684\u76f8\u5173\u6027\u3002\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u76ee\u6807\u7a33\u5b9a\u8bad\u7ec3\u5e76\u4fc3\u6210\u5206\u79bb\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e863DGH\u7684\u8bbe\u8ba1\u9009\u62e9\uff0c\u5728\u65e0\u6761\u4ef6\u5168\u5934\u90e8\u56fe\u50cf\u5408\u6210\u548c\u53ef\u7ec4\u5408\u76843D\u53d1\u578b\u7f16\u8f91\u4efb\u52a1\u4e2d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "3DGH\u901a\u8fc7\u5206\u79bb\u5934\u53d1\u548c\u9762\u90e8\u5efa\u6a21\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u76843D\u4eba\u5934\u751f\u6210\u4e0e\u7f16\u8f91\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.20677", "pdf": "https://arxiv.org/pdf/2506.20677", "abs": "https://arxiv.org/abs/2506.20677", "authors": ["Shrinivass Arunachalam Balasubramanian"], "title": "Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting Across Diverse Data Distributions", "categories": ["cs.DS", "cs.DB", "cs.PF"], "comment": "11 Pages, 5 figures", "summary": "Sorting is an essential operation in computer science with direct\nconsequences on the performance of large scale data systems, real-time systems,\nand embedded computation. However, no sorting algorithm is optimal under all\ndistributions of data. The new adaptive hybrid sorting paradigm proposed in\nthis paper is the paradigm that automatically selects the most effective\nsorting algorithm Counting Sort, Radix Sort, or QuickSort based on real-time\nmonitoring of patterns in input data. The architecture begins by having a\nfeature extraction module to compute significant parameters such as data\nvolume, value range and entropy. These parameters are sent to a decision engine\ninvolving Finite State Machine and XGBoost classifier to aid smart and\neffective in choosing the optimal sorting strategy. It implements Counting Sort\non small key ranges, Radix Sort on large range structured input with\nlow-entropy keys and QuickSort on general purpose sorting. The experimental\nfindings of both synthetic and real life dataset confirm that the proposed\nsolution is actually inclined to excel significantly by comparison in execution\ntime, flexibility and the efficiency of conventional static sorting algorithms.\nThe proposed framework provides a scalable, high perhaps and applicable to a\nwide range of data processing operations like big data analytics, edge\ncomputing, and systems with hardware limitations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u6df7\u5408\u6392\u5e8f\u8303\u5f0f\uff0c\u901a\u8fc7\u5b9e\u65f6\u76d1\u6d4b\u8f93\u5165\u6570\u636e\u6a21\u5f0f\u81ea\u52a8\u9009\u62e9\u6700\u6709\u6548\u7684\u6392\u5e8f\u7b97\u6cd5\uff08\u8ba1\u6570\u6392\u5e8f\u3001\u57fa\u6570\u6392\u5e8f\u6216\u5feb\u901f\u6392\u5e8f\uff09\u3002\u8be5\u67b6\u6784\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u548c\u51b3\u7b56\u5f15\u64ce\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u9759\u6001\u6392\u5e8f\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u6392\u5e8f\u7b97\u6cd5\u65e0\u6cd5\u5728\u6240\u6709\u6570\u636e\u5206\u5e03\u4e0b\u5747\u8868\u73b0\u6700\u4f18\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6839\u636e\u6570\u636e\u7c7b\u578b\u548c\u7279\u5f81\u52a8\u6001\u9009\u62e9\u6700\u4f18\u7b97\u6cd5\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u8ba1\u7b97\u6570\u636e\u91cf\u3001\u503c\u8303\u56f4\u548c\u71b5\u7b49\u53c2\u6570\uff0c\u518d\u5229\u7528\u51b3\u7b56\u5f15\u64ce\uff08\u5305\u62ec\u6709\u9650\u72b6\u6001\u673a\u548cXGBoost\u5206\u7c7b\u5668\uff09\u9009\u62e9\u6700\u4f18\u6392\u5e8f\u7b97\u6cd5\u3002\u9488\u5bf9\u4e0d\u540c\u60c5\u51b5\u4f7f\u7528\u8ba1\u6570\u6392\u5e8f\u3001\u57fa\u6570\u6392\u5e8f\u6216\u5feb\u901f\u6392\u5e8f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u81ea\u9002\u5e94\u6df7\u5408\u6392\u5e8f\u6846\u67b6\u5728\u6267\u884c\u65f6\u95f4\u3001\u7075\u6d3b\u6027\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u9759\u6001\u6392\u5e8f\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u9002\u7528\u4e8e\u5927\u6570\u636e\u5206\u6790\u3001\u8fb9\u7f18\u8ba1\u7b97\u548c\u786c\u4ef6\u53d7\u9650\u7cfb\u7edf\u7b49\u591a\u79cd\u573a\u666f\u3002"}}
{"id": "2506.21481", "pdf": "https://arxiv.org/pdf/2506.21481", "abs": "https://arxiv.org/abs/2506.21481", "authors": ["Eike Neumann"], "title": "Deciding Robust Instances of an Escape Problem for Dynamical Systems in Euclidean Space", "categories": ["cs.LO"], "comment": null, "summary": "We study the problem of deciding whether a point escapes a closed subset of\n$\\mathbb{R}^d$ under the iteration of a continuous map $f \\colon \\mathbb{R}^d\n\\to \\mathbb{R}^d$ in the bit-model of real computation. We give a sound partial\ndecision method for this problem which is complete in the sense that its\nhalting set contains the halting set of all sound partial decision methods for\nthe problem. Equivalently, our decision method terminates on all problem\ninstances whose answer is robust under all sufficiently small perturbations of\nthe function. We further show that the halting set of our algorithm is dense in\nthe set of all problem instances. While our algorithm applies to general\ncontinuous functions, we demonstrate that it also yields complete decision\nmethods for much more rigid function families: affine linear systems and\nquadratic complex polynomials. In the latter case, completeness is subject to\nthe density of hyperbolicity conjecture in complex dynamics. This in particular\nyields an alternative proof of Hertling's (2004) conditional answer to a\nquestion raised by Penrose (1989) regarding the computability of the Mandelbrot\nset.", "AI": {"tldr": "\u7814\u7a76\u5728\u5b9e\u6570\u8ba1\u7b97\u7684\u6bd4\u7279\u6a21\u578b\u4e2d\uff0c\u5982\u4f55\u5224\u65ad\u4e00\u4e2a\u70b9\u662f\u5426\u5728\u8fde\u7eed\u6620\u5c04\u7684\u8fed\u4ee3\u4e0b\u9003\u79bb\u4e00\u4e2a\u95ed\u96c6\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5907\u7684\u51b3\u7b56\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5728\u5b9e\u6570\u8ba1\u7b97\u7684\u6bd4\u7279\u6a21\u578b\u4e0b\uff0c\u5bf9\u70b9\u7684\u9003\u9038\u884c\u4e3a\u8fdb\u884c\u51b3\u7b56\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u51fd\u6570\u6270\u52a8\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\u7684\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5907\u7684\u51b3\u7b56\u65b9\u6cd5\uff0c\u5176\u7ec8\u6b62\u96c6\u5305\u542b\u6240\u6709\u5176\u4ed6\u51b3\u7b56\u65b9\u6cd5\u7684\u7ec8\u6b62\u96c6\uff0c\u9002\u7528\u4e8e\u4e00\u822c\u8fde\u7eed\u51fd\u6570\uff0c\u5e76\u6269\u5c55\u5230\u4eff\u5c04\u7ebf\u6027\u7cfb\u7edf\u548c\u4e8c\u6b21\u590d\u591a\u9879\u5f0f\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u95ee\u9898\u5b9e\u4f8b\u7684\u96c6\u5408\u4e2d\u662f\u7a20\u5bc6\u7684\uff0c\u4e14\u5728\u590d\u52a8\u529b\u5b66\u7684\u53cc\u66f2\u731c\u60f3\u4e0b\uff0c\u53ef\u4ee5\u89e3\u51b3Mandelbrot\u96c6\u7684\u53ef\u8ba1\u7b97\u6027\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u5177\u6709\u5b8c\u5907\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u5c24\u5176\u5728\u590d\u6742\u52a8\u529b\u5b66\u7684\u7279\u5b9a\u95ee\u9898\u4e2d\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.15217", "pdf": "https://arxiv.org/pdf/2504.15217", "abs": "https://arxiv.org/abs/2504.15217", "authors": ["Yatong Bai", "Jonah Casebeer", "Somayeh Sojoudi", "Nicholas J. Bryan"], "title": "DRAGON: Distributional Rewards Optimize Diffusion Generative Models", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM"], "comment": null, "summary": "We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21406", "pdf": "https://arxiv.org/pdf/2506.21406", "abs": "https://arxiv.org/abs/2506.21406", "authors": ["Tommaso Bonato", "Daniele De Sensi", "Salvatore Di Girolamo", "Abdulla Bataineh", "David Hewson", "Duncan Roweth", "Torsten Hoefler"], "title": "Flowcut Switching: High-Performance Adaptive Routing with In-Order Delivery Guarantees", "categories": ["cs.NI"], "comment": null, "summary": "Network latency severely impacts the performance of applications running on\nsupercomputers. Adaptive routing algorithms route packets over different\navailable paths to reduce latency and improve network utilization. However, if\na switch routes packets belonging to the same network flow on different paths,\nthey might arrive at the destination out-of-order due to differences in the\nlatency of these paths. For some transport protocols like TCP, QUIC, and RoCE,\nout-of-order (OOO) packets might cause large performance drops or significantly\nincrease CPU utilization. In this work, we propose flowcut switching, a new\nadaptive routing algorithm that provides high-performance in-order packet\ndelivery. Differently from existing solutions like flowlet switching, which are\nbased on the assumption of bursty traffic and that might still reorder packets,\nflowcut switching guarantees in-order delivery under any network conditions,\nand is effective also for non-bursty traffic, as it is often the case for RDMA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aflowcut switching\u7684\u65b0\u578b\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u7f51\u7edc\u5ef6\u8fdf\u548c\u4e71\u5e8f\u6570\u636e\u5305\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\u5728\u4e71\u5e8f\u6570\u636e\u5305\u4f20\u8f93\u65f6\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u6216CPU\u5229\u7528\u7387\u589e\u52a0\uff0c\u5c24\u5176\u5728\u975e\u7a81\u53d1\u6d41\u91cf\uff08\u5982RDMA\uff09\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "flowcut switching\u7b97\u6cd5\u901a\u8fc7\u4fdd\u8bc1\u6570\u636e\u5305\u6309\u5e8f\u4f20\u8f93\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\uff08\u5982flowlet switching\uff09\u5728\u975e\u7a81\u53d1\u6027\u6d41\u91cf\u548c\u4e71\u5e8f\u95ee\u9898\u4e0a\u7684\u4e0d\u8db3\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u7f51\u7edc\u6761\u4ef6\u4e0b\u5747\u80fd\u4fdd\u8bc1\u6570\u636e\u5305\u7684\u6309\u5e8f\u4f20\u8f93\uff0c\u9002\u7528\u4e8eRDMA\u7b49\u975e\u7a81\u53d1\u6027\u6d41\u91cf\u573a\u666f\u3002", "conclusion": "flowcut switching\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7f51\u7edc\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u3002"}}
{"id": "2506.20884", "pdf": "https://arxiv.org/pdf/2506.20884", "abs": "https://arxiv.org/abs/2506.20884", "authors": ["Meira Gilbert", "Miranda Wei", "Lindah Kotut"], "title": "\"TikTok, Do Your Thing\": User Reactions to Social Surveillance in the Public Sphere", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "''TikTok, Do Your Thing'' is a viral trend where users attempt to identify\nstrangers they see in public via information crowd-sourcing. The trend started\nas early as 2021 and users typically engage with it for romantic purposes\n(similar to a ''Missed Connections'' personal advertisement). This practice\nincludes acts of surveillance and identification in the public sphere, although\nby peers rather than governments or corporations. To understand users'\nreactions to this trend we conducted a qualitative analysis of 60 TikTok videos\nand 1,901 user comments. Of the 60 videos reviewed, we find 19 individuals were\nsuccessfully identified. We also find that while there were comments expressing\ndisapproval (n=310), more than double the number expressed support (n=883).\nSupportive comments demonstrated genuine interest and empathy, reflecting\nevolving conceptions of community and algorithmic engagement. On the other\nhand, disapproving comments highlighted concerns about inappropriate\nrelationships, stalking, consent, and gendered double standards. We discuss\nthese insights in relation to the normalization of interpersonal surveillance,\nonline stalking, and as an evolution of social surveillance to offer a new\nperspective on user perceptions surrounding interpersonal surveillance and\nidentification in the public sphere.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21414", "pdf": "https://arxiv.org/pdf/2506.21414", "abs": "https://arxiv.org/abs/2506.21414", "authors": ["Gongjian Sun", "Mingyu Yan", "Dengke Han", "Runzhen Xue", "Duo Wang", "Xiaochun Ye", "Dongrui Fan"], "title": "Accelerating GNN Training through Locality-aware Dropout and Merge", "categories": ["cs.AR"], "comment": "under review in TPDS. extend version of DATE 2025", "summary": "Graph Neural Networks (GNNs) have demonstrated significant success in graph\nlearning and are widely adopted across various critical domains. However, the\nirregular connectivity between vertices leads to inefficient neighbor\naggregation, resulting in substantial irregular and coarse-grained DRAM\naccesses. This lack of data locality presents significant challenges for\nexecution platforms, ultimately degrading performance. While previous\naccelerator designs have leveraged on-chip memory and data access scheduling\nstrategies to address this issue, they still inevitably access features at\nirregular addresses from DRAM. In this work, we propose LiGNN, a hardware-based\nsolution that improves data locality by applying dropout and merge techniques\nduring neighbor aggregation to accelerate GNN training. Unlike conventional\nalgorithm-level dropout methods that primarily aim to improve accuracy while\noverlooking hardware costs, LiGNN introduces a locality-aware feature dropout\nmechanism. This approach selectively drops node features with data locality\nawareness, effectively reducing irregular DRAM accesses without compromising\nmodel accuracy. Moreover, by leveraging detailed knowledge of memory layout and\norganization-including critical alignment constraints-LiGNN strategically\nmerges memory accesses during neighbor aggregation at the DRAM row level,\nguided by GNN-level semantics. This optimization significantly improves data\nlocality with minimal additional cost. Under the commonly adopted 0.5 dropout\nrate, LiGNN outperforms state-of-the-art methods, delivering a 1.48~3.02x\nspeedup, reducing DRAM accesses by 34%~55%, and lowering DRAM row activations\nby 59%~82%, all while maintaining model accuracy.", "AI": {"tldr": "LiGNN\u662f\u4e00\u79cd\u57fa\u4e8e\u786c\u4ef6\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6539\u8fdb\u6570\u636e\u5c40\u90e8\u6027\u6765\u52a0\u901fGNN\u8bad\u7ec3\uff0c\u91c7\u7528\u4e22\u5f03\u4e0e\u5408\u5e76\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11DRAM\u8bbf\u95ee\u3002", "motivation": "\u73b0\u6709\u7684GNN\u52a0\u901f\u5668\u867d\u7136\u5229\u7528\u4e86\u7247\u4e0a\u5185\u5b58\u548c\u6570\u636e\u8bbf\u95ee\u8c03\u5ea6\u7b56\u7565\uff0c\u4f46\u4ecd\u9700\u4eceDRAM\u4e2d\u8bbf\u95ee\u4e0d\u89c4\u5219\u5730\u5740\u7684\u7279\u5f81\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002LiGNN\u901a\u8fc7\u6539\u8fdb\u6570\u636e\u5c40\u90e8\u6027\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "LiGNN\u5728\u90bb\u5c45\u805a\u5408\u8fc7\u7a0b\u4e2d\u5e94\u7528\u5c40\u90e8\u611f\u77e5\u7684\u7279\u5f81\u4e22\u5f03\u673a\u5236\u548cDRAM\u884c\u7ea7\u7684\u5185\u5b58\u8bbf\u95ee\u5408\u5e76\u7b56\u7565\uff0c\u4ee5\u51cf\u5c11\u4e0d\u89c4\u5219DRAM\u8bbf\u95ee\u3002", "result": "\u57280.5\u7684\u4e22\u5f03\u7387\u4e0b\uff0cLiGNN\u6027\u80fd\u63d0\u53471.48~3.02\u500d\uff0c\u51cf\u5c1134%~55%\u7684DRAM\u8bbf\u95ee\uff0c\u964d\u4f4e59%~82%\u7684DRAM\u884c\u6fc0\u6d3b\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "LiGNN\u901a\u8fc7\u786c\u4ef6\u4f18\u5316\u6709\u6548\u63d0\u5347\u4e86GNN\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u517c\u987e\u6a21\u578b\u7cbe\u5ea6\uff0c\u4e3aGNN\u52a0\u901f\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.20834", "pdf": "https://arxiv.org/pdf/2506.20834", "abs": "https://arxiv.org/abs/2506.20834", "authors": ["Tomas Gallo Aquino", "Victoria Liu", "Habiba Azab", "Raissa Mathura", "Andrew J Watrous", "Eleonora Bartoli", "Benjamin Y Hayden", "Paul Sajda", "Sameer A Sheth", "Nuttida Rungratsameetaweemana"], "title": "Brain2Model Transfer: Training sensory and decision models with human neural activity as a teacher", "categories": ["cs.NE", "cs.ET", "q-bio.NC"], "comment": "15 pages, 4 figures", "summary": "Transfer learning enhances the training of novel sensory and decision models\nby employing rich feature representations from large, pre-trained teacher\nmodels. Cognitive neuroscience shows that the human brain creates\nlow-dimensional, abstract representations for efficient sensorimotor coding.\nImportantly, the brain can learn these representations with significantly fewer\ndata points and less computational power than artificial models require. We\nintroduce Brain2Model Transfer Learning (B2M), a framework where neural\nactivity from human sensory and decision-making tasks acts as the teacher model\nfor training artificial neural networks. We propose two B2M strategies: (1)\nBrain Contrastive Transfer, which aligns brain activity and network activations\nthrough a contrastive objective; and (2) Brain Latent Transfer, which projects\nlatent dynamics from similar cognitive tasks onto student networks via\nsupervised regression of brain-derived features. We validate B2M in\nmemory-based decision-making with a recurrent neural network and scene\nreconstruction for autonomous driving with a variational autoencoder. The\nresults show that student networks benefiting from brain-based transfer\nconverge faster and achieve higher predictive accuracy than networks trained in\nisolation. Our findings indicate that the brain's representations are valuable\nfor artificial learners, paving the way for more efficient learning of complex\ndecision-making representations, which would be costly or slow through purely\nartificial training.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21014", "pdf": "https://arxiv.org/pdf/2506.21014", "abs": "https://arxiv.org/abs/2506.21014", "authors": ["Shaojian Qiu", "Mengyang Huang", "Jiahao Cheng"], "title": "Boosting Vulnerability Detection with Inter-function Multilateral Association Insights", "categories": ["cs.SE"], "comment": null, "summary": "Vulnerability detection is a crucial yet challenging technique for ensuring\nthe security of software systems. Currently, most deep learning-based\nvulnerability detection methods focus on stand-alone functions, neglecting the\ncomplex inter-function interrelations, particularly the multilateral\nassociations. This oversight can fail to detect vulnerabilities in these\ninterrelations. To address this gap, we present an Inter-Function Multilateral\nAssociation analysis framework for Vulnerability Detection (IFMA-VD). The\ncornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and\nutilizing hyperedge convolution to extract multilateral association features.\nSpecifically, we first parse functions into a code property graph to generate\nintra-function features. Following this, we construct a code behavior\nhypergraph by segmenting the program dependency graph to isolate and encode\nbehavioral features into hyperedges. Finally, we utilize a hypergraph network\nto capture the multilateral association knowledge for augmenting vulnerability\ndetection. We evaluate IFMA-VD on three widely used vulnerability datasets and\ndemonstrate improvements in F-measure and Recall compared to baseline methods.\nAdditionally, we illustrate that multilateral association features can boost\ncode feature representation and validate the effectiveness of IFMA-VD on\nreal-world datasets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20901", "pdf": "https://arxiv.org/pdf/2506.20901", "abs": "https://arxiv.org/abs/2506.20901", "authors": ["Meng Du", "Robert Amor", "Kwan-Liu Ma", "Burkhard C. W\u00fcnsche"], "title": "Data Visualization for Improving Financial Literacy: A Systematic Review", "categories": ["cs.GR"], "comment": null, "summary": "Financial literacy empowers individuals to make informed and effective\nfinancial decisions, improving their overall financial well-being and security.\nHowever, for many people understanding financial concepts can be daunting and\nonly half of US adults are considered financially literate. Data visualization\nsimplifies these concepts, making them accessible and engaging for learners of\nall ages. This systematic review analyzes 37 research papers exploring the use\nof data visualization and visual analytics in financial education and literacy\nenhancement. We classify these studies into five key areas: (1) the evolution\nof visualization use across time and space, (2) motivations for using\nvisualization tools, (3) the financial topics addressed and instructional\napproaches used, (4) the types of tools and technologies applied, and (5) how\nthe effectiveness of teaching interventions was evaluated. Furthermore, we\nidentify research gaps and highlight opportunities for advancing financial\nliteracy. Our findings offer practical insights for educators and professionals\nto effectively utilize or design visual tools for financial literacy.", "AI": {"tldr": "\u91d1\u878d\u7d20\u517b\u901a\u8fc7\u6570\u636e\u53ef\u89c6\u5316\u5de5\u5177\u63d0\u5347\uff0c\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e8637\u7bc7\u7814\u7a76\uff0c\u6db5\u76d6\u53ef\u89c6\u5316\u5de5\u5177\u5728\u91d1\u878d\u6559\u80b2\u4e2d\u7684\u4e94\u5927\u5e94\u7528\u9886\u57df\u53ca\u5176\u6709\u6548\u6027\u3002", "motivation": "\u91d1\u878d\u7d20\u517b\u5bf9\u4e2a\u4eba\u7684\u8d22\u52a1\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8bb8\u591a\u4eba\u7406\u89e3\u8d22\u52a1\u6982\u5ff5\u5b58\u5728\u56f0\u96be\u3002\u6570\u636e\u53ef\u89c6\u5316\u53ef\u4ee5\u7b80\u5316\u6982\u5ff5\uff0c\u63d0\u5347\u5b66\u4e60\u548c\u7406\u89e3\u6548\u679c\u3002", "method": "\u7cfb\u7edf\u6027\u7efc\u8ff037\u7bc7\u7814\u7a76\uff0c\u5206\u7c7b\u4e3a\u4e94\u5927\u9886\u57df\uff1a\u53ef\u89c6\u56fe\u7684\u65f6\u7a7a\u6f14\u8fdb\u3001\u5de5\u5177\u4f7f\u7528\u52a8\u673a\u3001\u8d22\u52a1\u4e3b\u9898\u4e0e\u6559\u5b66\u65b9\u6cd5\u3001\u5de5\u5177\u4e0e\u6280\u672f\u7c7b\u578b\u3001\u6559\u5b66\u5e72\u9884\u6548\u679c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u4e3a\u91d1\u878d\u6559\u80b2\u4e2d\u7684\u53ef\u89c6\u5316\u5de5\u5177\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u548c\u673a\u4f1a\u3002", "conclusion": "\u6570\u636e\u53ef\u89c6\u5316\u5728\u63d0\u5347\u91d1\u878d\u7d20\u517b\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u672c\u6587\u4e3a\u6559\u80b2\u8005\u548c\u4e13\u4e1a\u4eba\u58eb\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u548c\u5e94\u7528\u89c6\u89c9\u5de5\u5177\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.20686", "pdf": "https://arxiv.org/pdf/2506.20686", "abs": "https://arxiv.org/abs/2506.20686", "authors": ["Hoa La", "Ahan Gupta", "Alex Morehead", "Jianlin Cheng", "Minjia Zhang"], "title": "MegaFold: System-Level Optimizations for Accelerating Protein Structure Prediction Models", "categories": ["q-bio.BM", "cs.DC", "cs.LG", "cs.PF"], "comment": "13 pages, 12 figures", "summary": "Protein structure prediction models such as AlphaFold3 (AF3) push the\nfrontier of biomolecular modeling by incorporating science-informed\narchitectural changes to the transformer architecture. However, these advances\ncome at a steep system cost, introducing: compute- and memory-intensive\noperators, 2D attention mechanisms, and retrieval-augmented data pipelines,\nwhich collectively hinder the scalability of AF3 training. In this work, we\npresent MegaFold, a cross-platform system to accelerate AF3 training. MegaFold\ntackles key bottlenecks through ahead-of-time caching to eliminate GPU idle\ntime from the retrieval-augmented data pipeline, Triton-based kernels for\nmemory-efficient EvoAttention on heterogeneous devices, and deep fusion for\ncommon and critical small operators in AF3. Evaluation on both NVIDIA H200 and\nAMD MI250 GPUs shows that MegaFold reduces peak memory usage of AF3 training by\nup to 1.23$\\times$ and improves per-iteration training time by up-to\n1.73$\\times$ and 1.62$\\times$ respectively. More importantly, MegaFold enables\ntraining on 1.35$\\times$ longer sequence lengths compared to PyTorch baselines\nwithout running out-of-memory, significantly improving the scalability of\nmodern protein folding models. We open source our code at\nhttps://github.com/Supercomputing-System-AI-Lab/MegaFold/.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MegaFold\uff0c\u4e00\u4e2a\u8de8\u5e73\u53f0\u7cfb\u7edf\uff0c\u7528\u4e8e\u52a0\u901fAlphaFold3\uff08AF3\uff09\u8bad\u7ec3\uff0c\u901a\u8fc7\u7f13\u5b58\u3001\u9ad8\u6548\u5185\u6838\u548c\u6df1\u5ea6\u878d\u5408\u89e3\u51b3\u4e86\u8ba1\u7b97\u548c\u5185\u5b58\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u5e8f\u5217\u957f\u5ea6\u652f\u6301\u3002", "motivation": "AlphaFold3\u7b49\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u6a21\u578b\u867d\u7136\u63a8\u52a8\u4e86\u751f\u7269\u5206\u5b50\u5efa\u6a21\u7684\u53d1\u5c55\uff0c\u4f46\u5176\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u9ad8\uff0c\u5bfc\u81f4\u8bad\u7ec3\u96be\u4ee5\u6269\u5c55\u3002MegaFold\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u74f6\u9888\u3002", "method": "MegaFold\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u4f18\u5316\u8bad\u7ec3\uff1a\u63d0\u524d\u7f13\u5b58\u4ee5\u51cf\u5c11GPU\u95f2\u7f6e\u65f6\u95f4\uff1b\u57fa\u4e8eTriton\u7684\u9ad8\u6548EvoAttention\u5185\u6838\uff1b\u6df1\u5ea6\u878d\u5408\u5e38\u89c1\u5c0f\u7b97\u5b50\u3002", "result": "\u5728NVIDIA H200\u548cAMD MI250 GPU\u4e0a\uff0cMegaFold\u5c06AF3\u8bad\u7ec3\u7684\u5185\u5b58\u4f7f\u7528\u964d\u4f4e1.23\u500d\uff0c\u8bad\u7ec3\u65f6\u95f4\u5206\u522b\u63d0\u53471.73\u500d\u548c1.62\u500d\uff0c\u652f\u63011.35\u500d\u66f4\u957f\u7684\u5e8f\u5217\u957f\u5ea6\u3002", "conclusion": "MegaFold\u663e\u8457\u63d0\u5347\u4e86\u73b0\u4ee3\u86cb\u767d\u8d28\u6298\u53e0\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.20909", "pdf": "https://arxiv.org/pdf/2506.20909", "abs": "https://arxiv.org/abs/2506.20909", "authors": ["Jonas Bayer", "Marco David", "Malte Hassler", "Yuri Matiyasevich", "Dierk Schleicher"], "title": "Diophantine Equations over $\\mathbb Z$: Universal Bounds and Parallel Formalization", "categories": ["math.NT", "cs.LO"], "comment": "53 pages", "summary": "This paper explores multiple closely related themes: bounding the complexity\nof Diophantine equations over the integers and developing mathematical proofs\nin parallel with formal theorem provers.\n  Hilbert's Tenth Problem (H10) asks about the decidability of Diophantine\nequations and has been answered negatively by Davis, Putnam, Robinson and\nMatiyasevich. It is natural to ask for which subclasses of Diophantine\nequations H10 remains undecidable. Such subclasses can be defined in terms of\nuniversal pairs: bounds on the number of variables $\\nu$ and degree $\\delta$\nsuch that all Diophantine equations can be rewritten in at most this\ncomplexity. Our work develops explicit universal pairs $(\\nu, \\delta)$ for\ninteger unknowns, achieving new bounds that cannot be obtained by naive\ntranslations from known results over $\\mathbb N$.\n  In parallel, we have conducted a formal verification of our results using the\nproof assistant Isabelle. While formal proof verification has traditionally\nbeen applied a posteriori to known results, this project integrates\nformalization into the discovery and development process. In a final section,\nwe describe key insights gained from this unusual approach and its implications\nfor mathematical practice. Our work contributes both to the study of\nDiophantine equations and to the broader question of how mathematics is\nconducted in the 21st century.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76Diophantine\u65b9\u7a0b\u7684\u590d\u6742\u6027\u8fb9\u754c\uff0c\u5e76\u63a2\u7d22\u4e0e\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u5e76\u884c\u5f00\u53d1\u6570\u5b66\u8bc1\u660e\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u663e\u5f0f\u901a\u7528\u5bf9\uff08\u03bd, \u03b4\uff09\u4e3a\u6574\u6570\u672a\u77e5\u6570\u53d6\u5f97\u65b0\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u8bc1\u660e\u52a9\u624bIsabelle\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "motivation": "\u7814\u7a76Hilbert\u7b2c\u5341\u95ee\u9898\u4e2dDiophantine\u65b9\u7a0b\u7684\u5b50\u7c7b\u4e0d\u53ef\u5224\u5b9a\u6027\uff0c\u5e76\u4e3a\u6570\u5b66\u5b9e\u8df5\u63a2\u7d22\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u663e\u5f0f\u901a\u7528\u5bf9\uff08\u03bd, \u03b4\uff09\u4ee5\u754c\u5b9aDiophantine\u65b9\u7a0b\u7684\u590d\u6742\u6027\uff0c\u5e76\u5229\u7528Isabelle\u8fdb\u884c\u5e76\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "result": "\u83b7\u5f97\u65b0\u7684\u590d\u6742\u6027\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8bc1\u5b9e\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u63a8\u8fdb\u4e86Diophantine\u65b9\u7a0b\u7684\u7406\u8bba\uff0c\u8fd8\u4e3a21\u4e16\u7eaa\u6570\u5b66\u5b9e\u8df5\u4e2d\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.20817", "pdf": "https://arxiv.org/pdf/2506.20817", "abs": "https://arxiv.org/abs/2506.20817", "authors": ["Ali Tourani", "Fatemeh Nazary", "Yashar Deldjoo"], "title": "RAG-VisualRec: An Open Resource for Vision- and Text-Enhanced Retrieval-Augmented Generation in Recommendation", "categories": ["cs.IR", "cs.MM"], "comment": "20 pages, 6 figures, 5 tables", "summary": "This paper addresses the challenge of developing multimodal recommender\nsystems for the movie domain, where limited metadata (e.g., title, genre) often\nhinders the generation of robust recommendations. We introduce a resource that\ncombines LLM-generated plot descriptions with trailer-derived visual embeddings\nin a unified pipeline supporting both Retrieval-Augmented Generation (RAG) and\ncollaborative filtering. Central to our approach is a data augmentation step\nthat transforms sparse metadata into richer textual signals, alongside fusion\nstrategies (e.g., PCA, CCA) that integrate visual cues. Experimental\nevaluations demonstrate that CCA-based fusion significantly boosts recall\ncompared to unimodal baselines, while an LLM-driven re-ranking step further\nimproves NDCG, particularly in scenarios with limited textual data. By\nreleasing this framework, we invite further exploration of multi-modal\nrecommendation techniques tailored to cold-start, novelty-focused, and\ndomain-specific settings. All code, data, and detailed documentation are\npublicly available at: https://github.com/RecSys-lab/RAG-VisualRec", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u6a21\u6001\u7535\u5f71\u63a8\u8350\u7cfb\u7edf\uff0c\u7ed3\u5408LLM\u751f\u6210\u7684\u5267\u60c5\u63cf\u8ff0\u548c\u9884\u544a\u7247\u89c6\u89c9\u5d4c\u5165\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u878d\u5408\u7b56\u7565\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u7535\u5f71\u63a8\u8350\u4e2d\u56e0\u5143\u6570\u636e\u6709\u9650\u800c\u5bfc\u81f4\u63a8\u8350\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528Retrieval-Augmented Generation (RAG)\u548c\u534f\u540c\u8fc7\u6ee4\uff0c\u7ed3\u5408LLM\u751f\u6210\u6587\u672c\u548c\u89c6\u89c9\u5d4c\u5165\uff0c\u5229\u7528PCA\u548cCCA\u8fdb\u884c\u591a\u6a21\u6001\u878d\u5408\u3002", "result": "CCA\u878d\u5408\u663e\u8457\u63d0\u5347\u53ec\u56de\u7387\uff0cLLM\u9a71\u52a8\u7684\u91cd\u6392\u5e8f\u8fdb\u4e00\u6b65\u6539\u5584NDCG\u3002", "conclusion": "\u53d1\u5e03\u6846\u67b6\u4ee5\u4fc3\u8fdb\u591a\u6a21\u6001\u63a8\u8350\u6280\u672f\u7684\u7814\u7a76\uff0c\u9002\u7528\u4e8e\u51b7\u542f\u52a8\u548c\u7279\u5b9a\u9886\u57df\u573a\u666f\u3002"}}
{"id": "2506.20965", "pdf": "https://arxiv.org/pdf/2506.20965", "abs": "https://arxiv.org/abs/2506.20965", "authors": ["Craig Steven Wright"], "title": "Rational Miner Behaviour, Protocol Stability, and Time Preference: An Austrian and Game-Theoretic Analysis of Bitcoin's Incentive Environment", "categories": ["econ.GN", "cs.CR", "cs.GT", "cs.NI", "q-fin.EC", "q-fin.GN", "91B42, 91A25, 91B50", "K.4.4; J.4; C.2.4"], "comment": "Approximately 10,770 words, 0 figure, 0 table. Submitted to The\n  Quarterly Journal of Austrian Economics", "summary": "This paper integrates Austrian capital theory with repeated game theory to\nexamine strategic miner behaviour under different institutional conditions in\nblockchain systems. It shows that when protocol rules are mutable, effective\ntime preference rises, undermining rational long-term planning and cooperative\nequilibria. Using formal game-theoretic analysis and Austrian economic\nprinciples, the paper demonstrates how mutable protocols shift miner incentives\nfrom productive investment to political rent-seeking and influence games. The\noriginal Bitcoin protocol is interpreted as an institutional anchor: a fixed\nrule-set enabling calculability and low time preference. Drawing on the work of\nBohm-Bawerk, Mises, and Hayek, the argument is made that protocol immutability\nis essential for restoring strategic coherence, entrepreneurial confidence, and\nsustainable network equilibrium.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7ed3\u5408\u5965\u5730\u5229\u8d44\u672c\u7406\u8bba\u548c\u91cd\u590d\u535a\u5f08\u7406\u8bba\uff0c\u5206\u6790\u533a\u5757\u94fe\u7cfb\u7edf\u4e2d\u4e0d\u540c\u5236\u5ea6\u6761\u4ef6\u4e0b\u77ff\u5de5\u7684\u6218\u7565\u884c\u4e3a\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u534f\u8bae\u89c4\u5219\u53ef\u53d8\u65f6\u4f1a\u63d0\u9ad8\u65f6\u95f4\u504f\u597d\uff0c\u7834\u574f\u957f\u671f\u89c4\u5212\u548c\u5408\u4f5c\u5747\u8861\u3002\u4e0d\u53d8\u534f\u8bae\u5219\u80fd\u6062\u590d\u6218\u7565\u4e00\u81f4\u6027\u548c\u53ef\u6301\u7eed\u7f51\u7edc\u5747\u8861\u3002", "motivation": "\u63a2\u8ba8\u533a\u5757\u94fe\u7cfb\u7edf\u4e2d\u77ff\u5de5\u884c\u4e3a\u5982\u4f55\u53d7\u534f\u8bae\u53ef\u53d8\u6027\u5f71\u54cd\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u4e0d\u53d8\u534f\u8bae\u6062\u590d\u6218\u7565\u4e00\u81f4\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002", "method": "\u91c7\u7528\u5f62\u5f0f\u5316\u7684\u535a\u5f08\u8bba\u5206\u6790\u548c\u5965\u5730\u5229\u7ecf\u6d4e\u5b66\u539f\u7406\uff0c\u7814\u7a76\u53ef\u53d8\u534f\u8bae\u5bf9\u77ff\u5de5\u6fc0\u52b1\u7684\u5f71\u54cd\u3002", "result": "\u53ef\u53d8\u534f\u8bae\u5bfc\u81f4\u77ff\u5de5\u4ece\u751f\u4ea7\u6027\u6295\u8d44\u8f6c\u5411\u653f\u6cbb\u5bfb\u79df\u548c\u5f71\u54cd\u529b\u535a\u5f08\uff0c\u800c\u4e0d\u53d8\u534f\u8bae\uff08\u5982\u6bd4\u7279\u5e01\u539f\u59cb\u534f\u8bae\uff09\u80fd\u652f\u6301\u53ef\u8ba1\u7b97\u6027\u548c\u4f4e\u65f6\u95f4\u504f\u597d\u3002", "conclusion": "\u534f\u8bae\u4e0d\u53ef\u53d8\u6027\u662f\u6062\u590d\u6218\u7565\u4e00\u81f4\u6027\u3001\u4f01\u4e1a\u5bb6\u4fe1\u5fc3\u548c\u53ef\u6301\u7eed\u7f51\u7edc\u5747\u8861\u7684\u5173\u952e\u3002"}}
{"id": "2506.20828", "pdf": "https://arxiv.org/pdf/2506.20828", "abs": "https://arxiv.org/abs/2506.20828", "authors": ["Pranay Mundra", "Charalampos Papamanthou", "Julian Shun", "Quanquan C. Liu"], "title": "Practical and Accurate Local Edge Differentially Private Graph Algorithms", "categories": ["cs.DS", "cs.CR", "cs.DB"], "comment": "To appear in VLDB 2025", "summary": "The rise of massive networks across diverse domains necessitates\nsophisticated graph analytics, often involving sensitive data and raising\nprivacy concerns. This paper addresses these challenges using local\ndifferential privacy (LDP), which enforces privacy at the individual level,\nwhere no third-party entity is trusted, unlike centralized models that assume a\ntrusted curator. We introduce novel LDP algorithms for two fundamental graph\nstatistics: k-core decomposition and triangle counting. Our approach leverages\ninput-dependent private graph properties, specifically the degeneracy and\nmaximum degree of the graph, to improve theoretical utility. Unlike prior\nmethods, our error bounds are determined by the maximum degree rather than the\ntotal number of edges, resulting in significantly tighter guarantees. For\ntriangle counting, we improve upon the work of Imola, Murakami, and\nChaudhury~\\cite{IMC21locally, IMC21communication}, which bounds error in terms\nof edge count. Instead, our algorithm achieves bounds based on graph degeneracy\nby leveraging a private out-degree orientation, a refined variant of Eden et\nal.'s randomized response technique~\\cite{ELRS23, and a novel analysis,\nyielding stronger guarantees than prior work. Beyond theoretical gains, we are\nthe first to evaluate local DP algorithms in a distributed simulation, unlike\nprior work tested on a single processor. Experiments on real-world graphs show\nsubstantial accuracy gains: our k-core decomposition achieves errors within 3x\nof exact values, far outperforming the 131x error in the baseline of Dhulipala\net al.~\\cite{DLRSSY22}. Our triangle counting algorithm reduces multiplicative\napproximation errors by up to six orders of magnitude, while maintaining\ncompetitive runtime.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20952", "pdf": "https://arxiv.org/pdf/2506.20952", "abs": "https://arxiv.org/abs/2506.20952", "authors": ["Kyosuke Ishibashi", "Atsushi Saito", "Zin Y. Tun", "Lucas Ray", "Megan C. Coram", "Akihiro Sakurai", "Allison M. Okamura", "Ko Yamamoto"], "title": "Effect of Haptic Feedback on Avoidance Behavior and Visual Exploration in Dynamic VR Pedestrian Environment", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Human crowd simulation in virtual reality (VR) is a powerful tool with\npotential applications including emergency evacuation training and assessment\nof building layout. While haptic feedback in VR enhances immersive experience,\nits effect on walking behavior in dense and dynamic pedestrian flows is\nunknown. Through a user study, we investigated how haptic feedback changes user\nwalking motion in crowded pedestrian flows in VR. The results indicate that\nhaptic feedback changed users' collision avoidance movements, as measured by\nincreased walking trajectory length and change in pelvis angle. The\ndisplacements of users' lateral position and pelvis angle were also increased\nin the instantaneous response to a collision with a non-player character (NPC),\neven when the NPC was inside the field of view. Haptic feedback also enhanced\nusers' awareness and visual exploration when an NPC approached from the side\nand back. Furthermore, variation in walking speed was increased by the haptic\nfeedback. These results suggested that the haptic feedback enhanced users'\nsensitivity to a collision in VR environment.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21487", "pdf": "https://arxiv.org/pdf/2506.21487", "abs": "https://arxiv.org/abs/2506.21487", "authors": ["Maryam Ghane", "Amir M. Hajisadeghi", "Hamid R. Zarandi"], "title": "OptGM: An Optimized Gate Merging Method to Mitigate NBTI in Digital Circuits", "categories": ["cs.AR"], "comment": null, "summary": "This paper presents OptGM, an optimized gate merging method designed to\nmitigate negative bias temperature instability (NBTI) in digital circuits.\nFirst, the proposed approach effectively identifies NBTI-critical internal\nnodes, defined as those with a signal probability exceeding a predefined\nthreshold. Next, based on the proposed optimized algorithm, the sensitizer gate\n(which drives the critical node) and the sensitive gate (which is fed by it)\nare merged into a new complex gate. This complex gate preserves the original\nlogic while eliminating NBTI-critical nodes. Finally, to evaluate the\neffectiveness of OptGM, we assess it on several combinational and sequential\nbenchmark circuits. Simulation results demonstrate that, on average, the number\nof NBTI-critical transistors (i.e., PMOS transistors connected to critical\nnodes), NBTI-induced delay degradation, and the total transistor count are\nreduced by 89.29%, 23.87%, and 6.47%, respectively. Furthermore, OptGM enhances\nperformance per cost (PPC) by 12.8% on average, with minimal area overhead.", "AI": {"tldr": "OptGM\u662f\u4e00\u79cd\u4f18\u5316\u7684\u95e8\u5408\u5e76\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u5c11\u6570\u5b57\u7535\u8def\u4e2d\u7684NBTI\u6548\u5e94\u3002\u5b83\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u8282\u70b9\u5e76\u5408\u5e76\u76f8\u5173\u95e8\u7535\u8def\uff0c\u663e\u8457\u964d\u4f4e\u4e86NBTI\u5173\u952e\u6676\u4f53\u7ba1\u6570\u91cf\u548c\u5ef6\u8fdf\u9000\u5316\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u6027\u80fd\u6210\u672c\u6bd4\u3002", "motivation": "\u8d1f\u504f\u538b\u6e29\u5ea6\u4e0d\u7a33\u5b9a\u6027\uff08NBTI\uff09\u4f1a\u5bfc\u81f4\u6570\u5b57\u7535\u8def\u6027\u80fd\u9000\u5316\uff0c\u7279\u522b\u662fPMOS\u6676\u4f53\u7ba1\u3002OptGM\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u5408\u5e76\u95e8\u7535\u8def\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1. \u8bc6\u522b\u4fe1\u53f7\u6982\u7387\u8d85\u8fc7\u9608\u503c\u7684\u5173\u952e\u8282\u70b9\u30022. \u5408\u5e76\u9a71\u52a8\u5173\u952e\u8282\u70b9\u548c\u88ab\u5176\u9a71\u52a8\u7684\u95e8\u7535\u8def\u4e3a\u590d\u6742\u95e8\uff0c\u6d88\u9664\u5173\u952e\u8282\u70b9\u30023. \u5728\u7ec4\u5408\u548c\u65f6\u5e8f\u57fa\u51c6\u7535\u8def\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "NBTI\u5173\u952e\u6676\u4f53\u7ba1\u6570\u91cf\u51cf\u5c1189.29%\uff0c\u5ef6\u8fdf\u9000\u5316\u51cf\u5c1123.87%\uff0c\u603b\u6676\u4f53\u7ba1\u6570\u91cf\u51cf\u5c116.47%\uff0c\u6027\u80fd\u6210\u672c\u6bd4\u63d0\u534712.8%\uff0c\u9762\u79ef\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "OptGM\u6709\u6548\u7f13\u89e3\u4e86NBTI\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7535\u8def\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u4f4e\u7684\u5b9e\u73b0\u6210\u672c\u3002"}}
{"id": "2506.20918", "pdf": "https://arxiv.org/pdf/2506.20918", "abs": "https://arxiv.org/abs/2506.20918", "authors": ["Manika Lamba", "You Peng", "Sophie Nikolov", "Glen Layne-Worthey", "J. Stephen Downie"], "title": "Metadata Enrichment of Long Text Documents using Large Language Models", "categories": ["cs.DL", "cs.ET", "cs.IR"], "comment": null, "summary": "In this project, we semantically enriched and enhanced the metadata of long\ntext documents, theses and dissertations, retrieved from the HathiTrust Digital\nLibrary in English published from 1920 to 2020 through a combination of manual\nefforts and large language models. This dataset provides a valuable resource\nfor advancing research in areas such as computational social science, digital\nhumanities, and information science. Our paper shows that enriching metadata\nusing LLMs is particularly beneficial for digital repositories by introducing\nadditional metadata access points that may not have originally been foreseen to\naccommodate various content types. This approach is particularly effective for\nrepositories that have significant missing data in their existing metadata\nfields, enhancing search results and improving the accessibility of the digital\nrepository.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u7ed3\u5408\u4eba\u5de5\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e30\u5bcc\u4e86HathiTrust\u6570\u5b57\u56fe\u4e66\u9986\u4e2d1920-2020\u5e74\u82f1\u6587\u957f\u6587\u672c\u7684\u5143\u6570\u636e\uff0c\u4e3a\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002", "motivation": "\u63d0\u5347\u6570\u5b57\u56fe\u4e66\u9986\u4e2d\u5143\u6570\u636e\u7684\u4e30\u5bcc\u6027\u548c\u53ef\u7528\u6027\uff0c\u4ee5\u652f\u6301\u8de8\u5b66\u79d1\u7814\u7a76\u3002", "method": "\u7ed3\u5408\u4eba\u5de5\u6807\u6ce8\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u5143\u6570\u636e\u8fdb\u884c\u8bed\u4e49\u589e\u5f3a\u3002", "result": "\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u5143\u6570\u636e\u8bbf\u95ee\u70b9\uff0c\u663e\u8457\u63d0\u5347\u641c\u7d22\u6548\u679c\u548c\u8d44\u6e90\u53ef\u8bbf\u95ee\u6027\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5143\u6570\u636e\u589e\u5f3a\u4e2d\u6548\u679c\u663e\u8457\uff0c\u7279\u522b\u9002\u7528\u4e8e\u73b0\u6709\u5143\u6570\u636e\u7f3a\u5931\u4e25\u91cd\u7684\u6570\u5b57\u4ed3\u5e93\u3002"}}
{"id": "2506.20675", "pdf": "https://arxiv.org/pdf/2506.20675", "abs": "https://arxiv.org/abs/2506.20675", "authors": ["Anish Saxena", "Po-An Tsai", "Hritvik Taneja", "Aamer Jaleel", "Moinuddin Qureshi"], "title": "Utility-Driven Speculative Decoding for Mixture-of-Experts", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "GPU memory bandwidth is the main bottleneck for low-latency Large Language\nModel (LLM) inference. Speculative decoding leverages idle GPU compute by using\na lightweight drafter to propose K tokens, which the LLM verifies in parallel,\nboosting token throughput. In conventional dense LLMs, all model weights are\nfetched each iteration, so speculation adds no latency overhead. Emerging\nMixture of Experts (MoE) models activate only a subset of weights per token,\ngreatly reducing data movement. However, we show that speculation is\nineffective for MoEs: draft tokens collectively activate more weights,\nincreasing data movement and verification time by 2-3x. When token throughput\ngains fail to offset this overhead, speculation causes slowdowns up to 1.5x,\nmaking it infeasible. Even when useful, the optimal K varies by task, model,\nand even between requests and iterations. Thus, despite widespread use in dense\nLLMs, speculation remains impractical in leading MoEs.\n  We present Cascade, a utility-driven framework that selectively enables\nspeculation to avoid slowdowns and dynamically tunes K to accelerate MoE\nserving. Cascade uses a lightweight metric, speculation utility, the ratio of\ntoken gains to verification cost, which shows iteration-level locality,\nenabling periodic decisions via short test and longer set phases. For each\nrequest, Cascade disables speculation if utility drops below one during\ntesting, and when utility exceeds one, tests multiple K-values to choose the\nutility-maximizing K for the set phase. We implement Cascade in vLLM and\nevaluate it on five popular MoEs with workloads spanning code, math,\nextraction, and mixed tasks. Cascade limits slowdown to 5% (vs. 1.5x) and\nimproves throughput by 7-14% over static K, making speculative decoding\npractical for MoEs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21138", "pdf": "https://arxiv.org/pdf/2506.21138", "abs": "https://arxiv.org/abs/2506.21138", "authors": ["Abdelkarim El-Hajjami", "Camille Salinesi"], "title": "How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The shortage of publicly available, labeled requirements datasets remains a\nmajor barrier to advancing Artificial Intelligence for Requirements Engineering\n(AI4RE). While Large Language Models offer promising capabilities for synthetic\ndata generation, systematic approaches to control and optimize the quality of\ngenerated requirements remain underexplored. This paper presents Synthline v1,\nan enhanced Product Line approach for generating synthetic requirements data\nthat extends our earlier v0 version with advanced generation strategies and\ncuration techniques. We investigate four research questions assessing how\nprompting strategies, automated prompt optimization, and post-generation\ncuration affect data quality across four classification tasks: defect\ndetection, functional vs. non-functional, quality vs. non-quality, and security\nvs. non-security. Our evaluation shows that multi-sample prompting\nsignificantly boosts both utility and diversity over single-sample generation,\nwith F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic\nEditing) for automated prompt optimization yields task-dependent results,\ngreatly improving functional classification (+32.5 points) but reducing\nperformance on others. Interestingly, similarity-based curation improves\ndiversity but often harms classification performance, indicating that some\nredundancy may help ML models. Most importantly, our results show that\nsynthetic requirements can match or outperform human-authored ones for specific\ntasks, with synthetic data surpassing human data for security (+7.8 points) and\ndefect classification (+15.4 points). These findings offer practical insights\nfor AI4RE and chart a viable path to mitigating dataset scarcity through\nsystematic synthetic generation.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9AI4RE\u9886\u57df\u516c\u5f00\u6807\u8bb0\u6570\u636e\u96c6\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u51faSynthline v1\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u751f\u6210\u7b56\u7565\u548c\u63d0\u793a\u6280\u672f\u63d0\u5347\u5408\u6210\u9700\u6c42\u6570\u636e\u8d28\u91cf\uff0c\u5e76\u5728\u591a\u9879\u5206\u7c7b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u5176\u6548\u679c\uff0c\u90e8\u5206\u4efb\u52a1\u6027\u80fd\u751a\u81f3\u8d85\u8d8a\u4eba\u5de5\u6570\u636e\u3002", "motivation": "\u89e3\u51b3AI4RE\u9886\u57df\u516c\u5f00\u6807\u8bb0\u6570\u636e\u96c6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u9700\u6c42\u6570\u636e\u7684\u7cfb\u7edf\u6027\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSynthline v1\uff0c\u6269\u5c55\u4e86\u4e4b\u524d\u7248\u672c\uff0c\u7ed3\u5408\u591a\u6837\u672c\u63d0\u793a\u3001\u81ea\u52a8\u63d0\u793a\u4f18\u5316\uff08PACE\uff09\u548c\u751f\u6210\u540e\u7b5b\u9009\u6280\u672f\uff0c\u8bc4\u4f30\u5176\u5bf9\u56db\u9879\u5206\u7c7b\u4efb\u52a1\u6570\u636e\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u591a\u6837\u672c\u63d0\u793a\u663e\u8457\u63d0\u5347\u6570\u636e\u591a\u6837\u6027\u548c\u5b9e\u7528\u6027\uff0cPACE\u5bf9\u529f\u80fd\u5206\u7c7b\u6548\u679c\u663e\u8457\u4f46\u5176\u4ed6\u4efb\u52a1\u8868\u73b0\u4e0d\u4e00\uff0c\u5408\u6210\u6570\u636e\u5728\u5b89\u5168\u548c\u7f3a\u9677\u5206\u7c7b\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4eba\u5de5\u6570\u636e\u3002", "conclusion": "\u7cfb\u7edf\u6027\u5408\u6210\u751f\u6210\u662f\u89e3\u51b3\u6570\u636e\u96c6\u7a00\u7f3a\u7684\u6709\u6548\u9014\u5f84\uff0cAI4RE\u9886\u57df\u53ef\u901a\u8fc7\u4f18\u5316\u5408\u6210\u6570\u636e\u8d28\u91cf\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.20946", "pdf": "https://arxiv.org/pdf/2506.20946", "abs": "https://arxiv.org/abs/2506.20946", "authors": ["Donggoo Kang", "Jangyeong Kim", "Dasol Jeong", "Junyoung Choi", "Jeonga Wi", "Hyunmin Lee", "Joonho Gwon", "Joonki Paik"], "title": "Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models", "categories": ["cs.GR", "cs.AI", "cs.CV", "68T45, 68U05", "I.3.7; I.4.10; I.2.10"], "comment": null, "summary": "Current texture synthesis methods, which generate textures from fixed\nviewpoints, suffer from inconsistencies due to the lack of global context and\ngeometric understanding. Meanwhile, recent advancements in video generation\nmodels have demonstrated remarkable success in achieving temporally consistent\nvideos. In this paper, we introduce VideoTex, a novel framework for seamless\ntexture synthesis that leverages video generation models to address both\nspatial and temporal inconsistencies in 3D textures. Our approach incorporates\ngeometry-aware conditions, enabling precise utilization of 3D mesh structures.\nAdditionally, we propose a structure-wise UV diffusion strategy, which enhances\nthe generation of occluded areas by preserving semantic information, resulting\nin smoother and more coherent textures. VideoTex not only achieves smoother\ntransitions across UV boundaries but also ensures high-quality, temporally\nstable textures across video frames. Extensive experiments demonstrate that\nVideoTex outperforms existing methods in texture fidelity, seam blending, and\nstability, paving the way for dynamic real-time applications that demand both\nvisual quality and temporal coherence.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20807", "pdf": "https://arxiv.org/pdf/2506.20807", "abs": "https://arxiv.org/abs/2506.20807", "authors": ["Martin Andrews", "Sam Witteveen"], "title": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "comment": "4 page paper plus Appendices. Accepted to the ES-FoMo \"Efficient\n  Systems for Foundation Models\" workshop at ICML 2025", "summary": "Optimizing GPU kernels for high performance is a complex task, often\ndemanding deep architectural knowledge, extensive profiling, and iterative\nexperimentation. This challenge is amplified when targeting newer or\nless-documented GPU architectures where traditional development aids are\nscarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an\nautomated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)\nstrategically selecting promising prior code versions as a basis for new\niterations; (b) generating hypotheses for optimization experiments, based on\nexisting code and assimilated knowledge from general GPU literature; and (c)\nautonomously implementing these experiments through code modification and\nsubsequent submission to an external evaluation system, using only observed\ntiming data as performance feedback. We detail how this approach navigates the\nchallenges of the AMD MI300 target architecture and leverages LLMs to\ncompensate for limited domain-specific human expertise.\n  Since quantitative results from an ongoing performance competition were\nembargoed on paper submission date, we present the architectural design,\noperational workflow, and qualitative insights, highlighting the potential of\nLLM-driven agents to democratise and accelerate GPU kernel optimization,\nespecially in resource-constrained or rapidly evolving hardware environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20947", "pdf": "https://arxiv.org/pdf/2506.20947", "abs": "https://arxiv.org/abs/2506.20947", "authors": ["Dejie Yang", "Zhu Xu", "Xinjie Gao", "Yang Liu"], "title": "Hierarchical Sub-action Tree for Continuous Sign Language Recognition", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Continuous sign language recognition (CSLR) aims to transcribe untrimmed\nvideos into glosses, which are typically textual words. Recent studies indicate\nthat the lack of large datasets and precise annotations has become a bottleneck\nfor CSLR due to insufficient training data. To address this, some works have\ndeveloped cross-modal solutions to align visual and textual modalities.\nHowever, they typically extract textual features from glosses without fully\nutilizing their knowledge. In this paper, we propose the Hierarchical\nSub-action Tree (HST), termed HST-CSLR, to efficiently combine gloss knowledge\nwith visual representation learning. By incorporating gloss-specific knowledge\nfrom large language models, our approach leverages textual information more\neffectively. Specifically, we construct an HST for textual information\nrepresentation, aligning visual and textual modalities step-by-step and\nbenefiting from the tree structure to reduce computational complexity.\nAdditionally, we impose a contrastive alignment enhancement to bridge the gap\nbetween the two modalities. Experiments on four datasets (PHOENIX-2014,\nPHOENIX-2014T, CSL-Daily, and Sign Language Gesture) demonstrate the\neffectiveness of our HST-CSLR.", "AI": {"tldr": "\u63d0\u51faHST-CSLR\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5c42\u6b21\u5316\u5b50\u52a8\u4f5c\u6811\uff08HST\uff09\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u77e5\u8bc6\uff0c\u4f18\u5316\u8fde\u7eed\u624b\u8bed\u8bc6\u522b\u4e2d\u7684\u89c6\u89c9\u4e0e\u6587\u672c\u6a21\u6001\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u8fde\u7eed\u624b\u8bed\u8bc6\u522b\uff08CSLR\uff09\u4e2d\u56e0\u6807\u6ce8\u6570\u636e\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u4e0d\u8db3\u800c\u53d7\u9650\uff0c\u9700\u66f4\u9ad8\u6548\u5229\u7528\u6587\u672c\u77e5\u8bc6\u3002", "method": "\u6784\u5efaHST\u7ed3\u6784\uff0c\u9010\u6b65\u5bf9\u9f50\u89c6\u89c9\u4e0e\u6587\u672c\u6a21\u6001\uff0c\u5e76\u5f15\u5165\u5bf9\u6bd4\u589e\u5f3a\u4ee5\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u9a8c\u8bc1HST-CSLR\u7684\u6709\u6548\u6027\u3002", "conclusion": "HST-CSLR\u901a\u8fc7\u5c42\u6b21\u5316\u7ed3\u6784\u66f4\u9ad8\u6548\u5229\u7528\u6587\u672c\u77e5\u8bc6\uff0c\u63d0\u5347CSLR\u6027\u80fd\u3002"}}
{"id": "2506.21134", "pdf": "https://arxiv.org/pdf/2506.21134", "abs": "https://arxiv.org/abs/2506.21134", "authors": ["Jacopo Bufalino", "Jose Luis Martin-Navarro", "Mario Di Francesco", "Tuomas Aura"], "title": "Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "Kubernetes has emerged as the de facto standard for container orchestration.\nUnfortunately, its increasing popularity has also made it an attractive target\nfor malicious actors. Despite extensive research on securing Kubernetes, little\nattention has been paid to the impact of network configuration on the security\nof application deployments. This paper addresses this gap by conducting a\ncomprehensive analysis of network misconfigurations in a Kubernetes cluster\nwith specific reference to lateral movement. Accordingly, we carried out an\nextensive evaluation of 287 open-source applications belonging to six different\norganizations, ranging from IT companies and public entities to non-profits. As\na result, we identified 634 misconfigurations, well beyond what could be found\nby solutions in the state of the art. We responsibly disclosed our findings to\nthe concerned organizations and engaged in a discussion to assess their\nseverity. As of now, misconfigurations affecting more than thirty applications\nhave been fixed with the mitigations we proposed.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21195", "pdf": "https://arxiv.org/pdf/2506.21195", "abs": "https://arxiv.org/abs/2506.21195", "authors": ["Neha Raghuvanshi"], "title": "Follow the user meaningfully and product growth will follow: A mixed methods case study tying UX Point of View & Growth leading to measurable impact", "categories": ["cs.HC"], "comment": null, "summary": "Have you wondered how cross-functional teams balance between maximizing value\nthat users derive and business growth leading to win-win situations? This case\nstudy shows how User Experience Research (UXR) and Data Science teams used\nmixed methods research to strategically influence Product Led Growth (PLG) for\na Password Manager used by million+ users, thus allowing our users, internal\nteams, and business to win. The audience will take away practical\nlessons/techniques related to leveraging mixed methods to: a. Maximize user\nvalue while meeting business growth goals b. Influence cross-functional teams\nc. Measure user and business impact This case study can be easily tied to the\nUXR Point of view pyramid (POV) [2] that represents a methodological approach\nto construct a POV and further dives into actioning POV to create measurable\nuser and business impact.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21246", "pdf": "https://arxiv.org/pdf/2506.21246", "abs": "https://arxiv.org/abs/2506.21246", "authors": ["Giorgos Demosthenous", "Chryssis Georgiou", "Eliada Polydorou"], "title": "From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting", "categories": ["q-fin.PM", "cs.AI", "cs.ET", "cs.LG", "q-fin.ST"], "comment": null, "summary": "This study investigates the impact of data source diversity on the\nperformance of cryptocurrency forecasting models by integrating various data\ncategories, including technical indicators, on-chain metrics, sentiment and\ninterest metrics, traditional market indices, and macroeconomic indicators. We\nintroduce the Crypto100 index, representing the top 100 cryptocurrencies by\nmarket capitalization, and propose a novel feature reduction algorithm to\nidentify the most impactful and resilient features from diverse data sources.\nOur comprehensive experiments demonstrate that data source diversity\nsignificantly enhances the predictive performance of forecasting models across\ndifferent time horizons. Key findings include the paramount importance of\non-chain metrics for both short-term and long-term predictions, the growing\nrelevance of traditional market indices and macroeconomic indicators for\nlonger-term forecasts, and substantial improvements in model accuracy when\ndiverse data sources are utilized. These insights help demystify the short-term\nand long-term driving factors of the cryptocurrency market and lay the\ngroundwork for developing more accurate and resilient forecasting models.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u6570\u636e\u6e90\u591a\u6837\u6027\u5bf9\u52a0\u5bc6\u8d27\u5e01\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7279\u5f81\u964d\u7ef4\u7b97\u6cd5\uff0c\u53d1\u73b0\u6570\u636e\u591a\u6837\u6027\u663e\u8457\u63d0\u5347\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u9ad8\u5ea6\u6ce2\u52a8\uff0c\u4f20\u7edf\u5355\u4e00\u6570\u636e\u6e90\u9884\u6d4b\u6a21\u578b\u8868\u73b0\u6709\u9650\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u591a\u6570\u636e\u6e90\u6574\u5408\u662f\u5426\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165\u4e86Crypto100\u6307\u6570\uff0c\u5e76\u63d0\u51fa\u65b0\u7279\u5f81\u964d\u7ef4\u7b97\u6cd5\uff0c\u4ece\u6280\u672f\u6307\u6807\u3001\u94fe\u4e0a\u6570\u636e\u3001\u60c5\u611f\u6307\u6807\u7b49\u591a\u6837\u6570\u636e\u4e2d\u7b5b\u9009\u5173\u952e\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6570\u636e\u6e90\u591a\u6837\u6027\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u9884\u6d4b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u94fe\u4e0a\u6570\u636e\u5bf9\u77ed\u957f\u671f\u9884\u6d4b\u5747\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u5e02\u573a\u6307\u6570\u5bf9\u957f\u671f\u9884\u6d4b\u66f4\u76f8\u5173\u3002", "conclusion": "\u591a\u6570\u636e\u6e90\u6574\u5408\u80fd\u663e\u8457\u63d0\u5347\u52a0\u5bc6\u8d27\u5e01\u9884\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5065\u6027\uff0c\u4e3a\u5e02\u573a\u9a71\u52a8\u56e0\u7d20\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2506.20938", "pdf": "https://arxiv.org/pdf/2506.20938", "abs": "https://arxiv.org/abs/2506.20938", "authors": ["Joshua H. Davis", "Daniel Nichols", "Ishan Khillan", "Abhinav Bhatele"], "title": "ParEval-Repo: A Benchmark Suite for Evaluating LLMs with Repository-level HPC Translation Tasks", "categories": ["cs.DC"], "comment": "11 pages, 5 figures", "summary": "GPGPU architectures have become significantly diverse in recent years, which\nhas led to an emergence of a variety of specialized programming models and\nsoftware stacks to support them. While portable execution models exist, they\nstill require significant developer effort to port to and optimize for\ndifferent hardware architectures. Recent advances in large language models\n(LLMs) can help us reduce some of this programmer burden. In this paper, we\npresent a novel benchmark and testing framework, ParEval-Repo, which can be\nused to evaluate the efficacy of LLM-based approaches in automatically\ntranslating entire codebases across GPGPU execution models. ParEval-Repo\nincludes several scientific computing and AI mini-applications in a range of\nprogramming models, and levels of repository complexity. We use ParEval-Repo to\nevaluate a range of state-of-the-art open-source and commercial LLMs, with both\na non-agentic and a top-down agentic approach. We assess code generated by the\nLLMs and approaches in terms of compilability, functional correctness,\ncategories of build errors, and the cost of translation in terms of the number\nof inference tokens. Our results demonstrate that LLM translation of scientific\napplications is feasible for small programs but difficulty with generating\nfunctional build systems and cross-file dependencies pose challenges in scaling\nto larger codebases.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21211", "pdf": "https://arxiv.org/pdf/2506.21211", "abs": "https://arxiv.org/abs/2506.21211", "authors": ["Quanming Liu", "Xupeng Bu", "Zhichao Yan", "Ru Li"], "title": "$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Automatic Program Repair (APR) is a core technology in software development\nand maintenance, with aims to enable automated defect repair with minimal human\nintervention. In recent years, the substantial advancements in Large Language\nModels (LLMs) and the Chain-of-Thought (CoT) techniques have significantly\nenhanced the reasoning capabilities of these models. However, due to the\ncomplex logic and multi-step reasoning ability needed, the application of CoT\ntechniques in the APR domain remains insufficient. This study systematically\nevaluates the performance of several common CoT techniques in APR tasks and\nproposes an innovative framework $T^3$, which integrates the powerful reasoning\ncapabilities of LLMs with tree search, effectively improving the precision of\ngenerating candidate repair solutions. Furthermore, $T^3$ provides valuable\nguidance for optimizing sample selection and repair strategies in APR tasks,\nestablishing a robust framework for achieving efficient automated debugging.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a $T^3$ \u7684\u521b\u65b0\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u6811\u641c\u7d22\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7684\u7cbe\u5ea6\u3002", "motivation": "\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e0e\u7ef4\u62a4\u7684\u6838\u5fc3\u6280\u672f\uff0c\u4f46\u7531\u4e8e\u5176\u590d\u6742\u7684\u903b\u8f91\u548c\u591a\u6b65\u63a8\u7406\u9700\u6c42\uff0c\u76ee\u524d\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u6280\u672f\u7684\u5e94\u7528\u4e0d\u8db3\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86\u51e0\u79cd\u5e38\u89c1CoT\u6280\u672f\u5728APR\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa$T^3$\u6846\u67b6\uff0c\u5c06LLMs\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u6811\u641c\u7d22\u7ed3\u5408\u3002", "result": "$T^3$\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u751f\u6210\u5019\u9009\u4fee\u590d\u65b9\u6848\u7684\u7cbe\u5ea6\uff0c\u5e76\u4e3aAPR\u4efb\u52a1\u4e2d\u7684\u6837\u672c\u9009\u62e9\u548c\u4fee\u590d\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "$T^3$\u4e3a\u9ad8\u6548\u81ea\u52a8\u5316\u8c03\u8bd5\u5efa\u7acb\u4e86\u575a\u5b9e\u6846\u67b6\uff0c\u5c55\u793a\u4e86LLMs\u548cCoT\u6280\u672f\u5728APR\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.21272", "pdf": "https://arxiv.org/pdf/2506.21272", "abs": "https://arxiv.org/abs/2506.21272", "authors": ["Jiayi Zheng", "Xiaodong Cun"], "title": "FairyGen: Storied Cartoon Video from a Single Child-Drawn Character", "categories": ["cs.GR", "cs.CV", "cs.MM"], "comment": "Project Page: https://jayleejia.github.io/FairyGen/ ; Code:\n  https://github.com/GVCLab/FairyGen", "summary": "We propose FairyGen, an automatic system for generating story-driven cartoon\nvideos from a single child's drawing, while faithfully preserving its unique\nartistic style. Unlike previous storytelling methods that primarily focus on\ncharacter consistency and basic motion, FairyGen explicitly disentangles\ncharacter modeling from stylized background generation and incorporates\ncinematic shot design to support expressive and coherent storytelling. Given a\nsingle character sketch, we first employ an MLLM to generate a structured\nstoryboard with shot-level descriptions that specify environment settings,\ncharacter actions, and camera perspectives. To ensure visual consistency, we\nintroduce a style propagation adapter that captures the character's visual\nstyle and applies it to the background, faithfully retaining the character's\nfull visual identity while synthesizing style-consistent scenes. A shot design\nmodule further enhances visual diversity and cinematic quality through frame\ncropping and multi-view synthesis based on the storyboard. To animate the\nstory, we reconstruct a 3D proxy of the character to derive physically\nplausible motion sequences, which are then used to fine-tune an MMDiT-based\nimage-to-video diffusion model. We further propose a two-stage motion\ncustomization adapter: the first stage learns appearance features from\ntemporally unordered frames, disentangling identity from motion; the second\nstage models temporal dynamics using a timestep-shift strategy with frozen\nidentity weights. Once trained, FairyGen directly renders diverse and coherent\nvideo scenes aligned with the storyboard. Extensive experiments demonstrate\nthat our system produces animations that are stylistically faithful,\nnarratively structured natural motion, highlighting its potential for\npersonalized and engaging story animation. The code will be available at\nhttps://github.com/GVCLab/FairyGen", "AI": {"tldr": "FairyGen\u662f\u4e00\u4e2a\u4ece\u5355\u5f20\u513f\u7ae5\u7ed8\u753b\u751f\u6210\u6545\u4e8b\u9a71\u52a8\u5361\u901a\u89c6\u9891\u7684\u7cfb\u7edf\uff0c\u4fdd\u7559\u4e86\u539f\u753b\u7684\u72ec\u7279\u827a\u672f\u98ce\u683c\uff0c\u5e76\u63d0\u4f9b\u4e86\u8fde\u8d2f\u7684\u53d9\u4e8b\u548c\u9ad8\u8d28\u91cf\u89c6\u89c9\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u6545\u4e8b\u751f\u6210\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u89d2\u8272\u4e00\u81f4\u6027\u548c\u57fa\u672c\u52a8\u4f5c\uff0c\u65e0\u6cd5\u540c\u65f6\u4fdd\u6301\u827a\u672f\u98ce\u683c\u548c\u53d9\u4e8b\u8fde\u8d2f\u6027\u3002FairyGen\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u901a\u8fc7\u56db\u4e2a\u6b65\u9aa4\u5b9e\u73b0\uff1a(1) \u4f7f\u7528MLLM\u751f\u6210\u7ed3\u6784\u5316\u6545\u4e8b\u677f\uff1b(2) \u98ce\u683c\u4f20\u64ad\u9002\u914d\u5668\u4fdd\u6301\u89d2\u8272\u89c6\u89c9\u98ce\u683c\uff1b(3) \u955c\u5934\u8bbe\u8ba1\u6a21\u5757\u589e\u5f3a\u89c6\u89c9\u591a\u6837\u6027\uff1b(4) 3D\u4ee3\u7406\u548c\u8fd0\u52a8\u5b9a\u5236\u9002\u914d\u5668\u751f\u6210\u903c\u771f\u52a8\u753b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFairyGen\u80fd\u751f\u6210\u98ce\u683c\u4e00\u81f4\u3001\u53d9\u4e8b\u8fde\u8d2f\u4e14\u89c6\u89c9\u591a\u6837\u5316\u7684\u52a8\u753b\uff0c\u9002\u5408\u4e2a\u6027\u5316\u6545\u4e8b\u5236\u4f5c\u3002", "conclusion": "FairyGen\u5728\u4fdd\u7559\u539f\u753b\u98ce\u683c\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u53d9\u4e8b\u52a8\u753b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.20994", "pdf": "https://arxiv.org/pdf/2506.20994", "abs": "https://arxiv.org/abs/2506.20994", "authors": ["M\u00e5ns I. Andersson", "Martin Karp", "Niclas Jansson", "Stefano Markidis"], "title": "Portable High-Performance Kernel Generation for a Computational Fluid Dynamics Code with DaCe", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "With the emergence of new high-performance computing (HPC) accelerators, such\nas Nvidia and AMD GPUs, efficiently targeting diverse hardware architectures\nhas become a major challenge for HPC application developers. The increasing\nhardware diversity in HPC systems often necessitates the development of\narchitecture-specific code, hindering the sustainability of large-scale\nscientific applications. In this work, we leverage DaCe, a data-centric\nparallel programming framework, to automate the generation of high-performance\nkernels. DaCe enables automatic code generation for multicore processors and\nvarious accelerators, reducing the burden on developers who would otherwise\nneed to rewrite code for each new architecture. Our study demonstrates DaCe's\ncapabilities by applying its automatic code generation to a critical\ncomputational kernel used in Computational Fluid Dynamics (CFD). Specifically,\nwe focus on Neko, a Fortran-based solver that employs the spectral-element\nmethod, which relies on small tensor operations. We detail the formulation of\nthis computational kernel using DaCe's Stateful Dataflow Multigraph (SDFG)\nrepresentation and discuss how this approach facilitates high-performance code\ngeneration. Additionally, we outline the workflow for seamlessly integrating\nDaCe's generated code into the Neko solver. Our results highlight the\nportability and performance of the generated code across multiple platforms,\nincluding Nvidia GH200, Nvidia A100, and AMD MI250X GPUs, with competitive\nperformance results. By demonstrating the potential of automatic code\ngeneration, we emphasise the feasibility of using portable solutions to ensure\nthe long-term sustainability of large-scale scientific applications.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528DaCe\u6846\u67b6\u81ea\u52a8\u751f\u6210\u9ad8\u6027\u80fd\u4ee3\u7801\uff0c\u4ee5\u5e94\u5bf9HPC\u7cfb\u7edf\u4e2d\u786c\u4ef6\u591a\u6837\u6027\u7684\u6311\u6218\uff0c\u5e76\u4ee5CFD\u4e2d\u7684Neko\u6c42\u89e3\u5668\u4e3a\u4f8b\uff0c\u5c55\u793a\u4e86\u4ee3\u7801\u7684\u53ef\u79fb\u690d\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u968f\u7740HPC\u52a0\u901f\u5668\u7684\u591a\u6837\u5316\uff0c\u5f00\u53d1\u517c\u5bb9\u591a\u79cd\u786c\u4ef6\u67b6\u6784\u7684\u9ad8\u6027\u80fd\u4ee3\u7801\u6210\u4e3a\u6311\u6218\uff0cDaCe\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5229\u7528DaCe\u7684Stateful Dataflow Multigraph (SDFG)\u8868\u793a\uff0c\u81ea\u52a8\u751f\u6210\u9488\u5bf9\u591a\u6838\u5904\u7406\u5668\u548c\u52a0\u901f\u5668\u7684\u9ad8\u6027\u80fd\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u7684\u4ee3\u7801\u5728Nvidia\u548cAMD GPU\u4e0a\u5177\u6709\u53ef\u79fb\u690d\u6027\u548c\u9ad8\u6027\u80fd\u3002", "conclusion": "\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u662f\u786e\u4fdd\u5927\u89c4\u6a21\u79d1\u5b66\u5e94\u7528\u957f\u671f\u53ef\u6301\u7eed\u6027\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.21201", "pdf": "https://arxiv.org/pdf/2506.21201", "abs": "https://arxiv.org/abs/2506.21201", "authors": ["Zihao You", "Michael Crabb"], "title": "Subtitled Media Adaptations for People with Aphasia: Ongoing Accessibility Barriers and Emerging Design Practices", "categories": ["cs.HC"], "comment": "3 pages, 1 figure, Access InContext Workshop at CHI 2025 on 26th of\n  April", "summary": "The consumption of subtitles via TVs, laptops and smartphones has the\npotential to marginalize people based on their complex accessibility needs. The\ncurrent one-size-fits-all approach to this accessibility aid is no longer fit\nfor purpose and work is required to look at how it can be adapted to be\npersonalised for individual users based on individual context, content, and\nconsumption habits. People with Aphasia, for example, encounter significant\nchallenges in understanding subtitle texts.\n  We see our work as a call to action for more inclusive practices, focusing on\nhow the thoughts and opinions of people with aphasia can be included in media\nresearch. Our work investigates how to develop future media solutions for\npeople with aphasia to create a more inclusive media viewing environment. We\nbelieve the key to this is appropriate prototyping tools and methods to allow\nequitable inclusion in the system design process.", "AI": {"tldr": "\u6458\u8981\u547c\u5401\u5173\u6ce8\u5b57\u5e55\u5bf9\u590d\u6742\u53ef\u8bbf\u95ee\u6027\u9700\u6c42\u4eba\u7fa4\u7684\u6392\u65a5\u95ee\u9898\uff0c\u63d0\u51fa\u4e2a\u6027\u5316\u5b57\u5e55\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4ee5\u5931\u8bed\u75c7\u60a3\u8005\u4e3a\u4f8b\uff0c\u5f3a\u8c03\u9700\u8981\u5305\u5bb9\u6027\u5a92\u4f53\u7814\u7a76\u4e0e\u5b9e\u8df5\u3002", "motivation": "\u5f53\u524d\u7684\u5b57\u5e55\u901a\u7528\u65b9\u6848\u65e0\u6cd5\u6ee1\u8db3\u591a\u6837\u5316\u9700\u6c42\uff0c\u7279\u522b\u662f\u5931\u8bed\u75c7\u60a3\u8005\u7406\u89e3\u5b57\u5e55\u7684\u56f0\u96be\uff0c\u4e9f\u9700\u4e2a\u6027\u5316\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u539f\u578b\u5de5\u5177\u548c\u65b9\u6cd5\uff0c\u5c06\u5931\u8bed\u75c7\u60a3\u8005\u7684\u610f\u89c1\u878d\u5165\u7cfb\u7edf\u8bbe\u8ba1\u8fc7\u7a0b\uff0c\u4ee5\u5b9e\u73b0\u5305\u5bb9\u6027\u5a92\u4f53\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u5177\u5305\u5bb9\u6027\u7684\u5a92\u4f53\u7814\u7a76\u6846\u67b6\uff0c\u5f3a\u8c03\u4e2a\u6027\u5316\u5b57\u5e55\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u5305\u5bb9\u6027\u8bbe\u8ba1\u548c\u7528\u6237\u53c2\u4e0e\u662f\u6539\u5584\u5a92\u4f53\u53ef\u8bbf\u95ee\u6027\u7684\u5173\u952e\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u5931\u8bed\u75c7\u7b49\u7279\u6b8a\u9700\u6c42\u7fa4\u4f53\u3002"}}
{"id": "2506.21537", "pdf": "https://arxiv.org/pdf/2506.21537", "abs": "https://arxiv.org/abs/2506.21537", "authors": ["Nicholas S. DiBrita", "Jason Han", "Tirthak Patel"], "title": "ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers", "categories": ["quant-ph", "cs.CV", "cs.ET"], "comment": "ResQ will appear in the Proceedings of the IEEE International\n  Conference on Computer Vision (ICCV), 2025", "summary": "Research in quantum machine learning has recently proliferated due to the\npotential of quantum computing to accelerate machine learning. An area of\nmachine learning that has not yet been explored is neural ordinary differential\nequation (neural ODE) based residual neural networks (ResNets), which aim to\nimprove the effectiveness of neural networks using the principles of ordinary\ndifferential equations. In this work, we present our insights about why analog\nRydberg atom quantum computers are especially well-suited for ResNets. We also\nintroduce ResQ, a novel framework to optimize the dynamics of Rydberg atom\nquantum computers to solve classification problems in machine learning using\nanalog quantum neural ODEs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21266", "pdf": "https://arxiv.org/pdf/2506.21266", "abs": "https://arxiv.org/abs/2506.21266", "authors": ["Daniil Karol", "Elizaveta Artser", "Ilya Vlasov", "Yaroslav Golubev", "Hieke Keuning", "Anastasiia Birillo"], "title": "KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks", "categories": ["cs.SE", "cs.CY"], "comment": "Accepted to CompEd'25, 7 pages, 4 figures", "summary": "Collecting data of students solving programming tasks is incredibly valuable\nfor researchers and educators. It allows verifying that the students correctly\napply the features and concepts they are taught, or finding students'\nmisconceptions. However, existing data collection tools have limitations, e.g.,\nno control over the granularity of the collected code, not collecting the\nspecific events of the programming environment used, and overall being hard to\nconfigure.\n  To overcome these limitations, we propose KOALA, a convenient and highly\nconfigurable tool for collecting code snapshots and feature usage from students\nsolving programming tasks in JetBrains IDEs. The plugin can be installed in\nIDEs and configured to provide the students with the necessary tasks, enable or\ndisable certain IDE features like code completion, and run surveys. During\nproblem solving, the plugin collects code snapshots at the configured\ngranularity, all IDE actions like running and debugging, as well as some data\nnot collected in prior works, like employed hotkeys and switching focus between\nfiles. The collected data is sent to the server that comes with the tool, where\nit is stored and can be converted to the standardized ProgSnap2 format. To\nshowcase the tool, we collected data from 28 students solving tasks in two\ncourses within the IDE, highlighting some insights from this data.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aKOALA\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u6536\u96c6\u5b66\u751f\u5728JetBrains IDE\u4e2d\u89e3\u51b3\u7f16\u7a0b\u4efb\u52a1\u65f6\u7684\u4ee3\u7801\u5feb\u7167\u548c\u529f\u80fd\u4f7f\u7528\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u6536\u96c6\u5de5\u5177\u5728\u6536\u96c6\u5b66\u751f\u7f16\u7a0b\u4efb\u52a1\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u65e0\u6cd5\u63a7\u5236\u4ee3\u7801\u7c92\u5ea6\u3001\u4e0d\u6536\u96c6\u7279\u5b9a\u7f16\u7a0b\u73af\u5883\u4e8b\u4ef6\u7b49\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5f00\u53d1\u4e86KOALA\u5de5\u5177\u3002", "method": "KOALA\u662f\u4e00\u4e2a\u9ad8\u5ea6\u53ef\u914d\u7f6e\u7684\u5de5\u5177\u63d2\u4ef6\uff0c\u53ef\u5b89\u88c5\u5728JetBrains IDE\u4e2d\u3002\u5b83\u53ef\u4ee5\u914d\u7f6e\u4efb\u52a1\u3001\u542f\u7528\u6216\u7981\u7528IDE\u529f\u80fd\uff08\u5982\u4ee3\u7801\u8865\u5168\uff09\u3001\u8fd0\u884c\u8c03\u67e5\uff0c\u5e76\u6536\u96c6\u4ee3\u7801\u5feb\u7167\u3001IDE\u64cd\u4f5c\uff08\u5982\u8fd0\u884c\u548c\u8c03\u8bd5\uff09\u4ee5\u53ca\u5176\u4ed6\u672a\u5728\u4ee5\u5f80\u5de5\u4f5c\u4e2d\u6536\u96c6\u7684\u6570\u636e\uff08\u5982\u5feb\u6377\u952e\u4f7f\u7528\u548c\u6587\u4ef6\u5207\u6362\uff09\u3002", "result": "\u901a\u8fc7KOALA\uff0c\u7814\u7a76\u8005\u5728\u4e24\u95e8\u8bfe\u7a0b\u4e2d\u6536\u96c6\u4e8628\u540d\u5b66\u751f\u7684\u6570\u636e\uff0c\u5c55\u793a\u4e86\u4e00\u4e9b\u6709\u8da3\u7684\u6d1e\u5bdf\u3002", "conclusion": "KOALA\u662f\u4e00\u4e2a\u65b9\u4fbf\u4e14\u9ad8\u5ea6\u53ef\u914d\u7f6e\u7684\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u6536\u96c6\u5b66\u751f\u7f16\u7a0b\u4efb\u52a1\u7684\u8be6\u7ec6\u6570\u636e\uff0c\u4e3a\u7814\u7a76\u548c\u6559\u80b2\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6e90\u3002"}}
{"id": "2506.21425", "pdf": "https://arxiv.org/pdf/2506.21425", "abs": "https://arxiv.org/abs/2506.21425", "authors": ["Pin Ren", "Yan Gao", "Zhichun Li", "Yan Chen", "Benjamin Watson"], "title": "IDGraphs: Intrusion Detection and Analysis Using Stream Compositing", "categories": ["cs.GR", "cs.CR"], "comment": null, "summary": "Traffic anomalies and attacks are commonplace in today's networks and\nidentifying them rapidly and accurately is critical for large network\noperators. For a statistical intrusion detection system (IDS), it is crucial to\ndetect at the flow-level for accurate detection and mitigation. However,\nexisting IDS systems offer only limited support for 1) interactively examining\ndetected intrusions and anomalies, 2) analyzing worm propagation patterns, 3)\nand discovering correlated attacks. These problems are becoming even more acute\nas the traffic on today's high-speed routers continues to grow.\n  IDGraphs is an interactive visualization system for intrusion detection that\naddresses these challenges. The central visualization in the system is a\nflow-level trace plotted with time on the horizontal axis and aggregated number\nof unsuccessful connections on the vertical axis. We then summarize a stack of\ntens or hundreds of thousands of these traces using the Histographs [RW05]\ntechnique, which maps data frequency at each pixel to brightness. Users may\nthen interactively query the summary view, performing analysis by highlighting\nsubsets of the traces. For example, brushing a linked correlation matrix view\nhighlights traces with similar patterns, revealing distributed attacks that are\ndifficult to detect using standard statistical analysis.\n  We apply IDGraphs system to a real network router data-set with 179M\nflow-level records representing a total traffic of 1.16TB. The system\nsuccessfully detects and analyzes a variety of attacks and anomalies, including\nport scanning, worm outbreaks, stealthy TCP SYN floodings, and some distributed\nattacks.", "AI": {"tldr": "IDGraphs\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u7cfb\u7edf\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u5206\u6790\u7f51\u7edc\u4e2d\u7684\u5165\u4fb5\u548c\u5f02\u5e38\u6d41\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u5728\u4ea4\u4e92\u5f0f\u68c0\u67e5\u3001\u8815\u866b\u4f20\u64ad\u5206\u6790\u548c\u76f8\u5173\u653b\u51fb\u53d1\u73b0\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740\u9ad8\u901f\u8def\u7531\u5668\u7684\u6d41\u91cf\u589e\u957f\uff0c\u73b0\u6709\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5728\u4ea4\u4e92\u5f0f\u68c0\u67e5\u5165\u4fb5\u3001\u5206\u6790\u8815\u866b\u4f20\u64ad\u6a21\u5f0f\u548c\u53d1\u73b0\u76f8\u5173\u653b\u51fb\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "IDGraphs\u901a\u8fc7\u5c06\u6d41\u91cf\u6570\u636e\u6309\u65f6\u95f4\u8f74\u548c\u672a\u6210\u529f\u8fde\u63a5\u6570\u6c47\u603b\uff0c\u5e76\u4f7f\u7528Histographs\u6280\u672f\u53ef\u89c6\u5316\u6570\u636e\u9891\u7387\uff0c\u7528\u6237\u53ef\u901a\u8fc7\u4ea4\u4e92\u5f0f\u67e5\u8be2\u548c\u5206\u6790\u9ad8\u4eae\u663e\u793a\u7684\u6d41\u91cf\u6a21\u5f0f\u3002", "result": "\u8be5\u7cfb\u7edf\u6210\u529f\u5e94\u7528\u4e8e\u5305\u542b1.79\u4ebf\u6d41\u91cf\u8bb0\u5f55\u76841.16TB\u6570\u636e\u96c6\uff0c\u68c0\u6d4b\u5230\u7aef\u53e3\u626b\u63cf\u3001\u8815\u866b\u7206\u53d1\u3001SYN\u6d2a\u6cdb\u7b49\u653b\u51fb\u548c\u5f02\u5e38\u3002", "conclusion": "IDGraphs\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5165\u4fb5\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u4ea4\u4e92\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u653b\u51fb\u7684\u8bc6\u522b\u3002"}}
{"id": "2506.21072", "pdf": "https://arxiv.org/pdf/2506.21072", "abs": "https://arxiv.org/abs/2506.21072", "authors": ["Carlos J Barrios", "Yves Denneulin"], "title": "Bridding OT and PaaS in Edge-to-Cloud Continuum", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "The Operational Technology Platform as a Service (OTPaaS) initiative provides\na structured framework for the efficient management and storage of data. It\nensures excellent response times while improving security, reliability, data\nand technology sovereignty, robustness, and energy efficiency, which are\ncrucial for industrial transformation and data sovereignty. This paper\nillustrates successful deployment, adaptable application management, and\nvarious integration components catering to Edge and Cloud environments. It\nleverages the advantages of the Platform as a Service model and highlights key\nchallenges that have been addressed for specific use cases.", "AI": {"tldr": "OTPaaS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7ba1\u7406\u6570\u636e\u7684\u6846\u67b6\uff0c\u63d0\u5347\u54cd\u5e94\u65f6\u95f4\u3001\u5b89\u5168\u6027\u53ca\u53ef\u9760\u6027\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u548c\u4e91\u73af\u5883\u3002", "motivation": "\u4e3a\u5de5\u4e1a\u8f6c\u578b\u548c\u6570\u636e\u4e3b\u6743\u63d0\u4f9b\u9ad8\u6548\u3001\u5b89\u5168\u7684\u6570\u636e\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5e73\u53f0\u5373\u670d\u52a1\u6a21\u578b\uff0c\u6210\u529f\u90e8\u7f72\u5e76\u6574\u5408\u8fb9\u7f18\u548c\u4e91\u73af\u5883\u7ec4\u4ef6\u3002", "result": "\u5b9e\u73b0\u4e86\u54cd\u5e94\u65f6\u95f4\u3001\u5b89\u5168\u6027\u53ca\u53ef\u9760\u6027\u7684\u63d0\u5347\u3002", "conclusion": "OTPaaS\u4e3a\u5de5\u4e1a\u8f6c\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2506.21298", "pdf": "https://arxiv.org/pdf/2506.21298", "abs": "https://arxiv.org/abs/2506.21298", "authors": ["Atharva Mehta", "Shivam Chauhan", "Monojit Choudhury"], "title": "Exploring Adapter Design Tradeoffs for Low Resource Music Generation", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "cs.MM", "eess.AS"], "comment": "9 pages, 5 figures", "summary": "Fine-tuning large-scale music generation models, such as MusicGen and\nMustango, is a computationally expensive process, often requiring updates to\nbillions of parameters and, therefore, significant hardware resources.\nParameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based\nmethods, have emerged as a promising alternative, enabling adaptation with\nminimal trainable parameters while preserving model performance. However, the\ndesign choices for adapters, including their architecture, placement, and size,\nare numerous, and it is unclear which of these combinations would produce\noptimal adapters and why, for a given case of low-resource music genre. In this\npaper, we attempt to answer this question by studying various adapter\nconfigurations for two AI music models, MusicGen and Mustango, on two genres:\nHindustani Classical and Turkish Makam music.\n  Our findings reveal distinct trade-offs: convolution-based adapters excel in\ncapturing fine-grained local musical details such as ornamentations and short\nmelodic phrases, while transformer-based adapters better preserve long-range\ndependencies crucial for structured improvisation. Additionally, we analyze\ncomputational resource requirements across different adapter scales,\ndemonstrating how mid-sized adapters (40M parameters) achieve an optimal\nbalance between expressivity and quality. Furthermore, we find that Mustango, a\ndiffusion-based model, generates more diverse outputs with better adherence to\nthe description in the input prompt while lacking in providing stability in\nnotes, rhythm alignment, and aesthetics. Also, it is computationally intensive\nand requires significantly more time to train. In contrast, autoregressive\nmodels like MusicGen offer faster training and are more efficient, and can\nproduce better quality output in comparison, but have slightly higher\nredundancy in their generations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86Adapter\u7684\u4e0d\u540c\u914d\u7f6e\u5bf9\u4e24\u79cdAI\u97f3\u4e50\u6a21\u578b\uff08MusicGen\u548cMustango\uff09\u5728\u4f4e\u8d44\u6e90\u97f3\u4e50\u7c7b\u578b\uff08\u5982\u5370\u5ea6\u65af\u5766\u53e4\u5178\u97f3\u4e50\u548c\u571f\u8033\u5176Makam\u97f3\u4e50\uff09\u4e0a\u7684\u6548\u679c\uff0c\u53d1\u73b0\u4e86\u5377\u79ef\u548cTransformer\u9002\u914d\u5668\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63a2\u8ba8\u4e86\u8ba1\u7b97\u8d44\u6e90\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "motivation": "\u7531\u4e8e\u5fae\u8c03\u5927\u89c4\u6a21\u97f3\u4e50\u751f\u6210\u6a21\u578b\uff08\u5982MusicGen\u548cMustango\uff09\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u6280\u672f\u6210\u4e3a\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u9002\u914d\u5668\u7684\u8bbe\u8ba1\u9009\u62e9\u591a\u6837\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u6307\u5bfc\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u4f18\u5316\u9002\u914d\u5668\u914d\u7f6e\u4ee5\u9002\u5e94\u4f4e\u8d44\u6e90\u97f3\u4e50\u7c7b\u578b\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e24\u79cdAI\u97f3\u4e50\u6a21\u578b\uff08MusicGen\u548cMustango\uff09\u5728\u4e0d\u540c\u9002\u914d\u5668\u914d\u7f6e\u4e0b\u7684\u8868\u73b0\uff0c\u5305\u62ec\u5377\u79ef\u548cTransformer\u7ed3\u6784\u7684\u9002\u914d\u5668\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u5728\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4e0a\u7684\u5dee\u5f02\u3002", "result": "\u5377\u79ef\u9002\u914d\u5668\u5728\u6355\u6349\u5c40\u90e8\u97f3\u4e50\u7ec6\u8282\uff08\u5982\u88c5\u9970\u97f3\u548c\u77ed\u65cb\u5f8b\uff09\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u800cTransformer\u9002\u914d\u5668\u66f4\u9002\u5408\u4fdd\u6301\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\u3002\u6b64\u5916\uff0c\u4e2d\u7b49\u89c4\u6a21\u7684\u9002\u914d\u5668\uff0840M\u53c2\u6570\uff09\u5728\u8868\u8fbe\u529b\u548c\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u6700\u4f73\u5e73\u8861\u3002Mustango\u751f\u6210\u591a\u6837\u6027\u66f4\u597d\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\u4e14\u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u800cMusicGen\u8bad\u7ec3\u66f4\u5feb\u4e14\u6548\u7387\u66f4\u9ad8\uff0c\u4f46\u751f\u6210\u5185\u5bb9\u7a0d\u663e\u5197\u4f59\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u9002\u914d\u5668\u7684\u9009\u62e9\u5e94\u6839\u636e\u5177\u4f53\u9700\u6c42\u51b3\u5b9a\uff0c\u4e0d\u540c\u4efb\u52a1\u548c\u8d44\u6e90\u6761\u4ef6\u9700\u8981\u4e0d\u540c\u7684\u9002\u914d\u5668\u914d\u7f6e\uff0c\u4e2d\u7b49\u89c4\u6a21\u7684\u9002\u914d\u5668\u53ef\u80fd\u662f\u4e00\u79cd\u6298\u8877\u65b9\u6848\u3002Mustango\u548cMusicGen\u5404\u6709\u4f18\u52a3\uff0c\u9700\u6839\u636e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u9009\u62e9\u6a21\u578b\u3002"}}
{"id": "2506.21319", "pdf": "https://arxiv.org/pdf/2506.21319", "abs": "https://arxiv.org/abs/2506.21319", "authors": ["Can Liu", "Chunlin Da", "Xiaoxiao Long", "Yuxiao Yang", "Yu Zhang", "Yong Wang"], "title": "Multimodal LLMs for Visualization Reconstruction and Understanding", "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "Visualizations are crucial for data communication, yet understanding them\nrequires comprehension of both visual elements and their underlying data\nrelationships. Current multimodal large models, while effective in natural\nimage understanding, struggle with visualization due to their inability to\ndecode the data-to-visual mapping rules and extract structured information. To\naddress these challenges, we present a novel dataset and train multimodal\nvisualization LLMs specifically designed for understanding. Our approach\ncombines chart images with their corresponding vectorized representations,\nencoding schemes, and data features. The proposed vector format enables compact\nand accurate reconstruction of visualization content. Experimental results\ndemonstrate significant improvements in both data extraction accuracy and chart\nreconstruction quality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u53ef\u89c6\u5316\u7406\u89e3\u7684\u591a\u6a21\u6001\u5927\u578b\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u56fe\u8868\u56fe\u50cf\u53ca\u5176\u5411\u91cf\u5316\u8868\u793a\uff0c\u63d0\u5347\u4e86\u6570\u636e\u63d0\u53d6\u548c\u56fe\u8868\u91cd\u5efa\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u578b\u6a21\u578b\u5728\u81ea\u7136\u56fe\u50cf\u7406\u89e3\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u53ef\u89c6\u5316\u7406\u89e3\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5b83\u4eec\u65e0\u6cd5\u89e3\u7801\u6570\u636e\u5230\u89c6\u89c9\u7684\u6620\u5c04\u89c4\u5219\u548c\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3\u4e86\u4e13\u95e8\u7528\u4e8e\u53ef\u89c6\u5316\u7406\u89e3\u7684\u591a\u6a21\u6001\u5927\u578b\u6a21\u578b\u3002\u65b9\u6cd5\u7ed3\u5408\u4e86\u56fe\u8868\u56fe\u50cf\u53ca\u5176\u5411\u91cf\u5316\u8868\u793a\u3001\u7f16\u7801\u65b9\u6848\u548c\u6570\u636e\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u63d0\u53d6\u51c6\u786e\u6027\u548c\u56fe\u8868\u91cd\u5efa\u8d28\u91cf\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5411\u91cf\u5316\u8868\u793a\u548c\u4e13\u95e8\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u6a21\u578b\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u7406\u89e3\u548c\u91cd\u5efa\u53ef\u89c6\u5316\u5185\u5bb9\u3002"}}
{"id": "2506.21033", "pdf": "https://arxiv.org/pdf/2506.21033", "abs": "https://arxiv.org/abs/2506.21033", "authors": ["Zhaojiacheng Zhou", "Hongze Liu", "Shijing Yuan", "Hanning Zhang", "Jiong Lou", "Chentao Wu", "Jie Li"], "title": "BLOCKS: Blockchain-supported Cross-Silo Knowledge Sharing for Efficient LLM Services", "categories": ["cs.DC"], "comment": null, "summary": "The hallucination problem of Large Language Models (LLMs) has increasingly\ndrawn attention. Augmenting LLMs with external knowledge is a promising\nsolution to address this issue. However, due to privacy and security concerns,\na vast amount of downstream task-related knowledge remains dispersed and\nisolated across various \"silos,\" making it difficult to access. To bridge this\nknowledge gap, we propose a blockchain-based external knowledge framework that\ncoordinates multiple knowledge silos to provide reliable foundational knowledge\nfor large model retrieval while ensuring data security. Technically, we distill\nknowledge from local data into prompts and execute transactions and records on\nthe blockchain. Additionally, we introduce a reputation mechanism and\ncross-validation to ensure knowledge quality and provide incentives for\nparticipation. Furthermore, we design a query generation framework that\nprovides a direct API interface for large model retrieval. To evaluate the\nperformance of our proposed framework, we conducted extensive experiments on\nvarious knowledge sources. The results demonstrate that the proposed framework\nachieves efficient LLM service knowledge sharing in blockchain environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5916\u90e8\u77e5\u8bc6\u6846\u67b6\uff0c\u89e3\u51b3LLM\u5e7b\u89c9\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u77e5\u8bc6\u5b64\u5c9b\u5171\u4eab\u786e\u4fdd\u6570\u636e\u5b89\u5168\u548c\u77e5\u8bc6\u8d28\u91cf\u3002", "motivation": "LLM\u7684\u5e7b\u89c9\u95ee\u9898\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5206\u6563\u7684\u77e5\u8bc6\u5b64\u5c9b\u56e0\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u96be\u4ee5\u5171\u4eab\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u533a\u5757\u94fe\u6280\u672f\uff0c\u5c06\u77e5\u8bc6\u63d0\u70bc\u4e3a\u63d0\u793a\uff0c\u5f15\u5165\u58f0\u8a89\u673a\u5236\u548c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u8bbe\u8ba1\u67e5\u8be2\u751f\u6210\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u533a\u5757\u94fe\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684LLM\u77e5\u8bc6\u5171\u4eab\u3002", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u80fd\u6709\u6548\u534f\u8c03\u77e5\u8bc6\u5b64\u5c9b\uff0c\u63d0\u5347LLM\u77e5\u8bc6\u68c0\u7d22\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2506.21297", "pdf": "https://arxiv.org/pdf/2506.21297", "abs": "https://arxiv.org/abs/2506.21297", "authors": ["Ricardo Hideki Hangai Kojo", "Luiz Fernando Corte Real", "Renato Cordeiro Ferreira", "Thatiane de Oliveira Rosa", "Alfredo Goldman"], "title": "Exploring Micro Frontends: A Case Study Application in E-Commerce", "categories": ["cs.SE", "cs.DC", "D.2.11; D.2.13; D.2.7"], "comment": "11 pages, 2 figures (2 diagrams), submitted to the workshop AMP 2025", "summary": "In the micro frontends architectural style, the frontend is divided into\nsmaller components, which can range from a simple button to an entire page. The\ngoal is to improve scalability, resilience, and team independence, albeit at\nthe cost of increased complexity and infrastructure demands. This paper seeks\nto understand when it is worth adopting micro frontends, particularly in the\ncontext of industry. To achieve this, we conducted an investigation into the\nstate of the art of micro frontends, based on both academic and gray\nliterature. We then implemented this architectural style in a marketplace for\nhandcrafted products, which already used microservices. Finally, we evaluated\nthe implementation through a semi-open questionnaire with the developers. At\nthe studied marketplace company, the need for architectural change arose due to\nthe tight coupling between their main system (a Java monolith) and a dedicated\nfrontend system. Additionally, there were deprecated technologies and poor\ndeveloper experience. To address these issues, the micro frontends architecture\nwas adopted, along with the API Gateway and Backend for Frontend patterns, and\ntechnologies such as Svelte and Fastify. Although the adoption of Micro\nFrontends was successful, it was not strictly necessary to meet the company's\nneeds. According to the analysis of the mixed questionnaire responses, other\nalternatives, such as a monolithic frontend, could have achieved comparable\nresults. What made adopting micro frontends the most convenient choice in the\ncompany's context was the monolith strangulation and microservices adoption,\nwhich facilitated implementation through infrastructure reuse and knowledge\nsharing between teams.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5fae\u524d\u7aef\u67b6\u6784\u7684\u9002\u7528\u6027\uff0c\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u5176\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\u3002", "motivation": "\u7814\u7a76\u5fae\u524d\u7aef\u67b6\u6784\u662f\u5426\u503c\u5f97\u5728\u5de5\u4e1a\u4e2d\u91c7\u7528\uff0c\u7279\u522b\u662f\u5728\u9762\u4e34\u6280\u672f\u503a\u52a1\u548c\u56e2\u961f\u534f\u4f5c\u9700\u6c42\u7684\u573a\u666f\u4e0b\u3002", "method": "\u7ed3\u5408\u5b66\u672f\u548c\u7070\u8272\u6587\u732e\u8c03\u67e5\u5fae\u524d\u7aef\u7684\u73b0\u72b6\uff0c\u5e76\u5728\u4e00\u4e2a\u624b\u5de5\u827a\u54c1\u5e02\u573a\u5e73\u53f0\u4e2d\u5b9e\u73b0\u8be5\u67b6\u6784\uff0c\u6700\u540e\u901a\u8fc7\u5f00\u53d1\u8005\u95ee\u5377\u8bc4\u4f30\u6548\u679c\u3002", "result": "\u5fae\u524d\u7aef\u7684\u91c7\u7528\u89e3\u51b3\u4e86\u6280\u672f\u503a\u52a1\u548c\u56e2\u961f\u72ec\u7acb\u6027\u95ee\u9898\uff0c\u4f46\u5e76\u975e\u552f\u4e00\u89e3\u51b3\u65b9\u6848\uff1b\u5176\u4fbf\u5229\u6027\u66f4\u591a\u6e90\u4e8e\u5df2\u6709\u7684\u5fae\u670d\u52a1\u57fa\u7840\u67b6\u6784\u548c\u56e2\u961f\u534f\u4f5c\u7ecf\u9a8c\u3002", "conclusion": "\u5fae\u524d\u7aef\u5728\u7279\u5b9a\u573a\u666f\uff08\u5982\u5df2\u6709\u5fae\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\uff09\u4e0b\u662f\u5408\u9002\u9009\u62e9\uff0c\u4f46\u5e76\u975e\u6240\u6709\u60c5\u51b5\u90fd\u5fc5\u8981\u3002"}}
{"id": "2506.21441", "pdf": "https://arxiv.org/pdf/2506.21441", "abs": "https://arxiv.org/abs/2506.21441", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges", "Martin Reddy"], "title": "An evaluation of level of detail degradation in head-mounted display peripheries", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "A paradigm for the design of systems that manage level of detail in virtual\nenvironments is proposed. As an example of the prototyping step in this\nparadigm, a user study was performed to evaluate the effectiveness of high\ndetail insets used with head-mounted displays. Ten subjects were given a simple\nsearch task that required the location and identification of a single target\nobject. All subjects used seven different displays (the independent variable),\nvarying in inset size and peripheral detail, to perform this task. Frame rate,\ntarget location, subject input method, and order of display use were all\ncontrolled. Primary dependent measures were search time on trials with correct\nidentification, and the percentage of all trials correctly identified. ANOVAs\nof the results showed that insetless, high detail displays did not lead to\nsignificantly different search times or accuracies than displays with insets.\nIn fact, only the insetless, low detail display returned significantly\ndifferent results. Further research is being performed to examine the effect of\nvarying task complexity, inset size, and level of detail.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21552", "pdf": "https://arxiv.org/pdf/2506.21552", "abs": "https://arxiv.org/abs/2506.21552", "authors": ["Yutong Bai", "Danny Tran", "Amir Bar", "Yann LeCun", "Trevor Darrell", "Jitendra Malik"], "title": "Whole-Body Conditioned Egocentric Video Prediction", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.RO"], "comment": "Project Page: https://dannytran123.github.io/PEVA", "summary": "We train models to Predict Ego-centric Video from human Actions (PEVA), given\nthe past video and an action represented by the relative 3D body pose. By\nconditioning on kinematic pose trajectories, structured by the joint hierarchy\nof the body, our model learns to simulate how physical human actions shape the\nenvironment from a first-person point of view. We train an auto-regressive\nconditional diffusion transformer on Nymeria, a large-scale dataset of\nreal-world egocentric video and body pose capture. We further design a\nhierarchical evaluation protocol with increasingly challenging tasks, enabling\na comprehensive analysis of the model's embodied prediction and control\nabilities. Our work represents an initial attempt to tackle the challenges of\nmodeling complex real-world environments and embodied agent behaviors with\nvideo prediction from the perspective of a human.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4eba\u4f53\u52a8\u4f5c\u9884\u6d4b\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u89c6\u9891\uff08PEVA\uff09\u7684\u6a21\u578b\uff0c\u7ed3\u5408\u4e863D\u8eab\u4f53\u59ff\u6001\u548c\u81ea\u56de\u5f52\u6761\u4ef6\u6269\u6563\u53d8\u6362\u5668\uff0c\u5e76\u5728Nymeria\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u5c55\u793a\u4e86\u5bf9\u590d\u6742\u73af\u5883\u7684\u6a21\u62df\u80fd\u529b\u3002", "motivation": "\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u4eba\u4f53\u52a8\u4f5c\uff08\u4ee53D\u59ff\u6001\u8868\u793a\uff09\u9884\u6d4b\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u89c6\u9891\uff0c\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u5bf9\u73af\u5883\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u4e3a\u6a21\u62df\u590d\u6742\u73b0\u5b9e\u73af\u5883\u548c\u5177\u8eab\u667a\u80fd\u4f53\u884c\u4e3a\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u5229\u75283D\u8eab\u4f53\u59ff\u6001\u8f68\u8ff9\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\uff0c\u7ed3\u5408\u5173\u8282\u5c42\u6b21\u7ed3\u6784\uff0c\u8bad\u7ec3\u4e86\u4e00\u4e2a\u81ea\u56de\u5f52\u6761\u4ef6\u6269\u6563\u53d8\u6362\u5668\u6a21\u578b\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6Nymeria\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u8bbe\u8ba1\u4e86\u5206\u5c42\u8bc4\u4f30\u534f\u8bae\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u5728\u5177\u8eab\u9884\u6d4b\u548c\u63a7\u5236\u80fd\u529b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u5bf9\u590d\u6742\u73b0\u5b9e\u73af\u5883\u7684\u6a21\u62df\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u662f\u9996\u6b21\u5c1d\u8bd5\u4ece\u4eba\u7c7b\u89c6\u89d2\u901a\u8fc7\u89c6\u9891\u9884\u6d4b\u5efa\u6a21\u590d\u6742\u73b0\u5b9e\u73af\u5883\u548c\u5177\u8eab\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.21322", "pdf": "https://arxiv.org/pdf/2506.21322", "abs": "https://arxiv.org/abs/2506.21322", "authors": ["Hong Wang", "Natalia Calvo-Barajas", "Katie Winkle", "Ginevra Castellano"], "title": "\"Who Should I Believe?\": User Interpretation and Decision-Making When a Family Healthcare Robot Contradicts Human Memory", "categories": ["cs.HC", "cs.RO"], "comment": "8 pages", "summary": "Advancements in robotic capabilities for providing physical assistance,\npsychological support, and daily health management are making the deployment of\nintelligent healthcare robots in home environments increasingly feasible in the\nnear future. However, challenges arise when the information provided by these\nrobots contradicts users' memory, raising concerns about user trust and\ndecision-making. This paper presents a study that examines how varying a\nrobot's level of transparency and sociability influences user interpretation,\ndecision-making and perceived trust when faced with conflicting information\nfrom a robot. In a 2 x 2 between-subjects online study, 176 participants\nwatched videos of a Furhat robot acting as a family healthcare assistant and\nsuggesting a fictional user to take medication at a different time from that\nremembered by the user. Results indicate that robot transparency influenced\nusers' interpretation of information discrepancies: with a low transparency\nrobot, the most frequent assumption was that the user had not correctly\nremembered the time, while with the high transparency robot, participants were\nmore likely to attribute the discrepancy to external factors, such as a partner\nor another household member modifying the robot's information. Additionally,\nparticipants exhibited a tendency toward overtrust, often prioritizing the\nrobot's recommendations over the user's memory, even when suspecting system\nmalfunctions or third-party interference. These findings highlight the impact\nof transparency mechanisms in robotic systems, the complexity and importance\nassociated with system access control for multi-user robots deployed in home\nenvironments, and the potential risks of users' over reliance on robots in\nsensitive domains such as healthcare.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u673a\u5668\u4eba\u900f\u660e\u5ea6\u548c\u793e\u4ea4\u6027\u5bf9\u7528\u6237\u4fe1\u4efb\u548c\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793a\u4e86\u9ad8\u900f\u660e\u5ea6\u673a\u5668\u4eba\u5982\u4f55\u6539\u53d8\u7528\u6237\u5bf9\u5176\u4fe1\u606f\u5dee\u5f02\u7684\u89e3\u91ca\uff0c\u5e76\u6307\u51fa\u4e86\u7528\u6237\u8fc7\u5ea6\u4f9d\u8d56\u673a\u5668\u4eba\u7684\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u533b\u7597\u673a\u5668\u4eba\u5728\u5bb6\u5ead\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u65e5\u76ca\u666e\u53ca\uff0c\u5f53\u673a\u5668\u4eba\u7684\u4fe1\u606f\u4e0e\u7528\u6237\u8bb0\u5fc6\u4e0d\u4e00\u81f4\u65f6\uff0c\u4f1a\u5f71\u54cd\u7528\u6237\u4fe1\u4efb\u548c\u51b3\u7b56\uff0c\u56e0\u6b64\u7814\u7a76\u900f\u660e\u5ea6\u548c\u793e\u4ea4\u6027\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u91c7\u75282x2\u7684\u53d7\u8bd5\u8005\u95f4\u5728\u7ebf\u5b9e\u9a8c\uff0c176\u540d\u53c2\u4e0e\u8005\u89c2\u770bFurhat\u673a\u5668\u4eba\u5728\u865a\u6784\u573a\u666f\u4e2d\u5efa\u8bae\u7528\u836f\u65f6\u95f4\u7684\u89c6\u9891\uff0c\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u900f\u660e\u5ea6\u548c\u793e\u4ea4\u6027\u6c34\u5e73\u7684\u5f71\u54cd\u3002", "result": "\u4f4e\u900f\u660e\u5ea6\u673a\u5668\u4eba\u5bfc\u81f4\u7528\u6237\u503e\u5411\u4e8e\u8ba4\u4e3a\u81ea\u5df1\u8bb0\u5fc6\u9519\u8bef\uff0c\u800c\u9ad8\u900f\u660e\u5ea6\u673a\u5668\u4eba\u5219\u8ba9\u7528\u6237\u66f4\u53ef\u80fd\u5c06\u5dee\u5f02\u5f52\u56e0\u4e8e\u5916\u90e8\u56e0\u7d20\uff1b\u7528\u6237\u8868\u73b0\u51fa\u5bf9\u673a\u5668\u4eba\u7684\u8fc7\u5ea6\u4fe1\u4efb\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u673a\u5668\u4eba\u900f\u660e\u5ea6\u548c\u7cfb\u7edf\u8bbf\u95ee\u63a7\u5236\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u5728\u533b\u7597\u7b49\u654f\u611f\u9886\u57df\u4e2d\u7528\u6237\u8fc7\u5ea6\u4f9d\u8d56\u673a\u5668\u4eba\u7684\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2506.21300", "pdf": "https://arxiv.org/pdf/2506.21300", "abs": "https://arxiv.org/abs/2506.21300", "authors": ["Yannis Bertrand", "Christian Imenkamp", "Lukas Malburg", "Matthias Ehrendorfer", "Marco Franceschetti", "Joscha Gr\u00fcger", "Francesco Leotta", "J\u00fcrgen Mangler", "Ronny Seiger", "Agnes Koschmider", "Stefanie Rinderle-Ma", "Barbara Weber", "Estefania Serral"], "title": "An object-centric core metamodel for IoT-enhanced event logs", "categories": ["cs.SE"], "comment": null, "summary": "Advances in Internet-of-Things (IoT) technologies have prompted the\nintegration of IoT devices with business processes (BPs) in many organizations\nacross various sectors, such as manufacturing, healthcare and smart spaces. The\nproliferation of IoT devices leads to the generation of large amounts of IoT\ndata providing a window on the physical context of BPs, which facilitates the\ndiscovery of new insights about BPs using process mining (PM) techniques.\nHowever, to achieve these benefits, IoT data need to be combined with\ntraditional process (event) data, which is challenging due to the very\ndifferent characteristics of IoT and process data, for instance in terms of\ngranularity levels. Recently, several data models were proposed to integrate\nIoT data with process data, each focusing on different aspects of data\nintegration based on different assumptions and requirements. This fragmentation\nhampers data exchange and collaboration in the field of PM, e.g., making it\ntedious for researchers to share data. In this paper, we present a core model\nsynthesizing the most important features of existing data models. As the core\nmodel is based on common requirements, it greatly facilitates data sharing and\ncollaboration in the field. A prototypical Python implementation is used to\nevaluate the model against various use cases and demonstrate that it satisfies\nthese common requirements.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u7269\u8054\u7f51\uff08IoT\uff09\u4e0e\u4e1a\u52a1\u6d41\u7a0b\u6570\u636e\u7684\u6838\u5fc3\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u6570\u636e\u6a21\u578b\u788e\u7247\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7Python\u539f\u578b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7269\u8054\u7f51\u6280\u672f\u4e0e\u4e1a\u52a1\u6d41\u7a0b\u7684\u7ed3\u5408\u4ea7\u751f\u4e86\u5927\u91cf\u6570\u636e\uff0c\u4f46IoT\u6570\u636e\u4e0e\u4f20\u7edf\u6d41\u7a0b\u6570\u636e\u7684\u7279\u6027\u5dee\u5f02\u5bfc\u81f4\u96c6\u6210\u56f0\u96be\uff0c\u73b0\u6709\u6570\u636e\u6a21\u578b\u788e\u7247\u5316\u963b\u788d\u4e86\u534f\u4f5c\u4e0e\u6570\u636e\u5171\u4eab\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6838\u5fc3\u6a21\u578b\uff0c\u7efc\u5408\u73b0\u6709\u6570\u636e\u6a21\u578b\u7684\u5173\u952e\u7279\u5f81\uff0c\u5e76\u57fa\u4e8e\u5e38\u89c1\u9700\u6c42\u8bbe\u8ba1\uff0c\u901a\u8fc7Python\u539f\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6838\u5fc3\u6a21\u578b\u6210\u529f\u6ee1\u8db3\u5e38\u89c1\u9700\u6c42\uff0c\u4fc3\u8fdb\u4e86\u6d41\u7a0b\u6316\u6398\u9886\u57df\u7684\u6570\u636e\u5171\u4eab\u4e0e\u534f\u4f5c\u3002", "conclusion": "\u6838\u5fc3\u6a21\u578b\u901a\u8fc7\u6574\u5408\u73b0\u6709\u6a21\u578b\u7684\u4f18\u70b9\uff0c\u89e3\u51b3\u4e86IoT\u4e0e\u4e1a\u52a1\u6d41\u7a0b\u6570\u636e\u96c6\u6210\u7684\u95ee\u9898\uff0c\u4e3a\u6d41\u7a0b\u6316\u6398\u9886\u57df\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.21456", "pdf": "https://arxiv.org/pdf/2506.21456", "abs": "https://arxiv.org/abs/2506.21456", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges"], "title": "Managing level of detail through head-tracked peripheral degradation: a model and resulting design principles", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "Previous work has demonstrated the utility of reductions in the level of\ndetail (LOD) in the periphery of head-tracked, large field of view displays.\nThis paper provides a psychophysically based model, centered around an eye/head\nmovement tradeoff, that explains the effectiveness of peripheral degradation\nand suggests how peripherally degraded displays should be designed. An\nexperiment evaluating the effect on search performance of the shape and area of\nthe high detail central area (inset) in peripherally degraded displays was\nperformed, results indicated that inset shape is not a significant factor in\nperformance. Inset area, however, was significant: performance with displays\nsubtending at least 30 degrees of horizontal and vertical angle was not\nsignificantly different from performance with an undegraded display. These\nresults agreed with the proposed model.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5916\u56f4\u533a\u57df\u964d\u4f4e\u7ec6\u8282\u6c34\u5e73\uff08LOD\uff09\u5bf9\u5934\u52a8\u8ffd\u8e2a\u5927\u89c6\u573a\u663e\u793a\u6709\u6548\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5fc3\u7406\u5b66\u6a21\u578b\uff0c\u63a2\u8ba8\u4e86\u773c/\u5934\u8fd0\u52a8\u6743\u8861\uff0c\u5e76\u6307\u5bfc\u5916\u56f4\u964d\u8d28\u663e\u793a\u7684\u8bbe\u8ba1\u3002\u5b9e\u9a8c\u53d1\u73b0\uff0c\u4e2d\u5fc3\u9ad8\u7ec6\u8282\u533a\u57df\u7684\u5f62\u72b6\u5bf9\u641c\u7d22\u6027\u80fd\u5f71\u54cd\u4e0d\u5927\uff0c\u800c\u5176\u9762\u79ef\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5f53\u6c34\u5e73\u548c\u5782\u76f4\u89c6\u89d2\u81f3\u5c1130\u5ea6\u65f6\uff0c\u6027\u80fd\u4e0e\u672a\u964d\u8d28\u663e\u793a\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u3002", "motivation": "\u63a2\u8ba8\u5916\u56f4\u964d\u8d28\u663e\u793a\u7684\u6709\u6548\u6027\u53ca\u5176\u8bbe\u8ba1\u4f9d\u636e\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u773c/\u5934\u8fd0\u52a8\u6743\u8861\u7684\u5fc3\u7406\u5b66\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\u5fc3\u9ad8\u7ec6\u8282\u533a\u57df\u7684\u5f62\u72b6\u548c\u9762\u79ef\u5bf9\u641c\u7d22\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u4e2d\u5fc3\u533a\u57df\u7684\u5f62\u72b6\u5bf9\u6027\u80fd\u65e0\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u9762\u79ef\uff08\u81f3\u5c1130\u5ea6\u89c6\u89d2\uff09\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u3002", "conclusion": "\u5916\u56f4\u964d\u8d28\u663e\u793a\u8bbe\u8ba1\u5e94\u5173\u6ce8\u4e2d\u5fc3\u533a\u57df\u7684\u9762\u79ef\u800c\u975e\u5f62\u72b6\uff0c\u4e14\u89c6\u89d2\u9700\u81f3\u5c1130\u5ea6\u4ee5\u786e\u4fdd\u6027\u80fd\u3002"}}
{"id": "2506.21333", "pdf": "https://arxiv.org/pdf/2506.21333", "abs": "https://arxiv.org/abs/2506.21333", "authors": ["Saloni Singh", "Koen Hndriks", "Drik Heylen", "Kim Baraka"], "title": "A Systematic Review of Human-AI Co-Creativity", "categories": ["cs.HC", "cs.AI", "I.2.11"], "comment": null, "summary": "The co creativity community is making significant progress in developing more\nsophisticated and tailored systems to support and enhance human creativity.\nDesign considerations from prior work can serve as a valuable and efficient\nfoundation for future systems. To support this effort, we conducted a\nsystematic literature review of 62 papers on co-creative systems. These papers\ncover a diverse range of applications, including visual arts, design, and\nwriting, where the AI acts not just as a tool but as an active collaborator in\nthe creative process. From this review, we identified several key dimensions\nrelevant to system design: phase of the creative process, creative task,\nproactive behavior of the system, user control, system embodiment, and AI model\ntype. Our findings suggest that systems offering high user control lead to\ngreater satisfaction, trust, and a stronger sense of ownership over creative\noutcomes. Furthermore, proactive systems, when adaptive and context sensitive,\ncan enhance collaboration. We also extracted 24 design considerations,\nhighlighting the value of encouraging users to externalize their thoughts and\nof increasing the system's social presence and transparency to foster trust.\nDespite recent advancements, important gaps remain, such as limited support for\nearly creative phases like problem clarification, and challenges related to\nuser adaptation to AI systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21327", "pdf": "https://arxiv.org/pdf/2506.21327", "abs": "https://arxiv.org/abs/2506.21327", "authors": ["Ryan Croote", "Islam El-Ashi", "Thomas Locher", "Yvonne-Anne Pignolet"], "title": "Enabling Bitcoin Smart Contracts on the Internet Computer", "categories": ["cs.DC"], "comment": "Published at ICDCS 2025, waiting for DOI", "summary": "There is growing interest in providing programmatic access to the value\nlocked in Bitcoin, which famously offers limited programmability itself.\nVarious approaches have been put forth in recent years, with the vast majority\nof proposed mechanisms either building new functionality on top of Bitcoin or\nleveraging a bridging mechanism to enable smart contracts that make use of\n``wrapped'' bitcoins on entirely different platforms.\n  In this work, an architecture is presented that follows a different approach.\nThe architecture enables the execution of Turing-complete Bitcoin smart\ncontracts on the Internet Computer (IC), a blockchain platform for hosting and\nexecuting decentralized applications. Instead of using a bridge, IC and Bitcoin\nnodes interact directly, eliminating potential security risks that the use of a\nbridge entails. This integration requires novel concepts, in particular to\nreconcile the probabilistic nature of Bitcoin with the irreversibility of\nfinalized state changes on the IC, which may be of independent interest.\n  In addition to the presentation of the architecture, we provide evaluation\nresults based on measurements of the Bitcoin integration running on mainnet.\nThe evaluation results demonstrate that, with finalization in a few seconds and\nlow execution costs, this integration enables complex Bitcoin-based\ndecentralized applications that were not practically feasible or economically\nviable before.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Internet Computer\uff08IC\uff09\u4e0a\u6267\u884c\u6bd4\u7279\u5e01\u667a\u80fd\u5408\u7ea6\u7684\u65b0\u67b6\u6784\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u6865\u63a5\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u5b9e\u73b0\u4e86\u5feb\u901f\u6700\u7ec8\u5316\u548c\u4f4e\u6210\u672c\u3002", "motivation": "\u6bd4\u7279\u5e01\u81ea\u8eab\u53ef\u7f16\u7a0b\u6027\u6709\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u6865\u63a5\u673a\u5236\uff0c\u5b58\u5728\u5b89\u5168\u9690\u60a3\u3002\u672c\u6587\u63a2\u7d22\u4e00\u79cd\u65e0\u9700\u6865\u63a5\u7684\u76f4\u63a5\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u76f4\u63a5\u5728IC\u533a\u5757\u94fe\u4e0a\u6267\u884c\u6bd4\u7279\u5e01\u667a\u80fd\u5408\u7ea6\uff0c\u901a\u8fc7\u65b0\u9896\u673a\u5236\u534f\u8c03\u6bd4\u7279\u5e01\u7684\u968f\u673a\u6027\u548cIC\u7684\u4e0d\u53ef\u9006\u72b6\u6001\u53d8\u5316\u3002", "result": "\u5b9e\u9645\u6d4b\u8bd5\u663e\u793a\uff0c\u8be5\u67b6\u6784\u80fd\u5728\u51e0\u79d2\u5185\u5b8c\u6210\u6700\u7ec8\u5316\u4e14\u6210\u672c\u4f4e\u5ec9\uff0c\u652f\u6301\u4e86\u6b64\u524d\u4e0d\u73b0\u5b9e\u7684\u590d\u6742\u53bb\u4e2d\u5fc3\u5316\u5e94\u7528\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e3a\u6bd4\u7279\u5e01\u667a\u80fd\u5408\u7ea6\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u72ec\u7acb\u7814\u7a76\u4ef7\u503c\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.21417", "pdf": "https://arxiv.org/pdf/2506.21417", "abs": "https://arxiv.org/abs/2506.21417", "authors": ["Yunxiu Xu", "Siyu Wang", "Shoichi Hasegawa"], "title": "Lightweight Fingernail Haptic Device: Unobstructed Fingerpad Force and Vibration Feedback for Enhanced Virtual Dexterous Manipulation", "categories": ["cs.HC", "H.5.2; I.3.6"], "comment": "14 pages, 15 figures, 2 tables. Published in IEEE Transactions on\n  Haptics (Early Access)", "summary": "This study presents a lightweight, wearable fingertip haptic device that\nprovides physics-based haptic feedback for dexterous manipulation in virtual\nenvironments without hindering real-world interactions. The device, designed\nwith thin strings and actuators attached to the fingernails, ensures minimal\nweight (1.55 g per finger) and preserves finger flexibility. Integrating the\nsoftware with a physics engine renders multiple types of haptic feedback (grip\nforce, collision, and sliding vibration feedback). We evaluated the device's\nperformance in pressure perception, slip feedback, typical dexterous\nmanipulation tasks, and daily operations, and we gathered user experience\nthrough subjective assessments. Our results show that participants could\nperceive and respond to pressure and vibration feedback. Through dexterous\nmanipulation experiments, we further demonstrated that these minimal haptic\ncues significantly improved virtual task efficiency, showcasing how lightweight\nhaptic feedback can enhance manipulation performance without complex\nmechanisms. The device's ability to preserve tactile sensations and minimize\nhindrance to real-world operations is a key advantage over glove-type haptic\ndevices. This research offers a potential solution for designing haptic\ninterfaces that balance lightweight construction, haptic feedback for dexterous\nmanipulation, and daily wearability.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21422", "pdf": "https://arxiv.org/pdf/2506.21422", "abs": "https://arxiv.org/abs/2506.21422", "authors": ["Kevin Kreutz", "Philipp Wiesner", "Monica Vitali"], "title": "Carbon-Aware Microservice Deployment for Optimal User Experience on a Budget", "categories": ["cs.DC"], "comment": "LOCO 2024, December 3, 2024, Glasgow/Online", "summary": "The carbon footprint of data centers has recently become a critical concern.\nSo far, most carbon-aware strategies have focused on leveraging the flexibility\nof scheduling decisions for batch processing by shifting the time and location\nof workload executions. However, such approaches cannot be applied to\nservice-oriented cloud applications, since they have to be reachable at every\npoint in time and often at low latencies. We propose a carbon-aware approach\nfor operating microservices under hourly carbon budgets. By choosing the most\nappropriate version and horizontal scaleout for each microservice, our strategy\nmaximizes user experience and revenue while staying within budget constraints.\nExperiments across various application configurations and carbon budgets\ndemonstrate that the approach adapts properly to changing workloads and carbon\nintensities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21182", "pdf": "https://arxiv.org/pdf/2506.21182", "abs": "https://arxiv.org/abs/2506.21182", "authors": ["Isaac Chung", "Imene Kerboua", "Marton Kardos", "Roman Solomatin", "Kenneth Enevoldsen"], "title": "Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": null, "summary": "The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation\nplatform for text embedding models. While previous work has established the\ncore benchmark methodology, this paper focuses on the engineering aspects that\nensure MTEB's continued reproducibility and extensibility. We present our\napproach to maintaining robust continuous integration pipelines that validate\ndataset integrity, automate test execution, and assess benchmark results'\ngeneralizability. We detail the design choices that collectively enhance\nreproducibility and usability. Furthermore, we discuss our strategies for\nhandling community contributions and extending the benchmark with new tasks and\ndatasets. These engineering practices have been instrumental in scaling MTEB to\nbecome more comprehensive while maintaining quality and, ultimately, relevance\nto the field. Our experiences offer valuable insights for benchmark maintainers\nfacing similar challenges in ensuring reproducibility and usability in machine\nlearning evaluation frameworks. The MTEB repository is available at:\nhttps://github.com/embeddings-benchmark/mteb", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4e86\u5982\u4f55\u901a\u8fc7\u5de5\u7a0b\u5b9e\u8df5\u63d0\u5347\u5927\u89c4\u6a21\u6587\u672c\u5d4c\u5165\u57fa\u51c6\uff08MTEB\uff09\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5305\u62ec\u6570\u636e\u96c6\u9a8c\u8bc1\u3001\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u8bbe\u8ba1\u9009\u62e9\u7b49\u3002", "motivation": "\u786e\u4fddMTEB\u7684\u6301\u7eed\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4ee5\u4fdd\u6301\u5176\u5728\u6587\u672c\u5d4c\u5165\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u6807\u51c6\u548c\u76f8\u5173\u6027\u3002", "method": "\u91c7\u7528\u7a33\u5065\u7684\u6301\u7eed\u96c6\u6210\u7ba1\u9053\u9a8c\u8bc1\u6570\u636e\u96c6\u5b8c\u6574\u6027\u3001\u81ea\u52a8\u5316\u6d4b\u8bd5\u6267\u884c\u548c\u8bc4\u4f30\u7ed3\u679c\u7684\u666e\u9002\u6027\u3002\u8be6\u7ec6\u8bf4\u660e\u4e86\u8bbe\u8ba1\u9009\u62e9\u4ee5\u589e\u5f3a\u53ef\u91cd\u590d\u6027\u3002", "result": "\u6210\u529f\u6269\u5c55\u4e86MTEB\u7684\u8986\u76d6\u8303\u56f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8d28\u91cf\u548c\u9886\u57df\u76f8\u5173\u6027\u3002", "conclusion": "\u672c\u6587\u7684\u7ecf\u9a8c\u4e3a\u673a\u5668\u5b66\u4e60\u8bc4\u4f30\u6846\u67b6\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u7528\u6027\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u57fa\u51c6\u7ef4\u62a4\u8005\u3002"}}
{"id": "2506.21449", "pdf": "https://arxiv.org/pdf/2506.21449", "abs": "https://arxiv.org/abs/2506.21449", "authors": ["Maxim Moraru", "Weiyi Xia", "Zhuo Ye", "Feng Zhang", "Yongxin Yao", "Ying Wai Li", "Cai-Zhuang Wang"], "title": "exa-AMD: A Scalable Workflow for Accelerating AI-Assisted Materials Discovery and Design", "categories": ["cs.DC"], "comment": "We intend to publish the paper to the Journal of Open Source Software", "summary": "exa-AMD is a Python-based application designed to accelerate the discovery\nand design of functional materials by integrating AI/ML tools, materials\ndatabases, and quantum mechanical calculations into scalable, high-performance\nworkflows. The execution model of exa-AMD relies on Parsl, a task-parallel\nprogramming library that enables a flexible execution of tasks on any computing\nresource from laptops to supercomputers. By using Parsl, exa-AMD is able to\ndecouple the workflow logic from execution configuration, thereby empowering\nresearchers to scale their workflows without having to reimplement them for\neach system.", "AI": {"tldr": "exa-AMD\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u6574\u5408AI/ML\u5de5\u5177\u3001\u6750\u6599\u6570\u636e\u5e93\u548c\u91cf\u5b50\u529b\u5b66\u8ba1\u7b97\uff0c\u52a0\u901f\u529f\u80fd\u6750\u6599\u7684\u53d1\u73b0\u4e0e\u8bbe\u8ba1\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u9ad8\u6027\u80fd\u5de5\u4f5c\u6d41\u52a0\u901f\u529f\u80fd\u6750\u6599\u7684\u53d1\u73b0\u4e0e\u8bbe\u8ba1\uff0c\u63d0\u5347\u7814\u7a76\u6548\u7387\u3002", "method": "\u5229\u7528\u4efb\u52a1\u5e76\u884c\u7f16\u7a0b\u5e93Parsl\uff0c\u5b9e\u73b0\u4ece\u7b14\u8bb0\u672c\u7535\u8111\u5230\u8d85\u7ea7\u8ba1\u7b97\u673a\u7684\u7075\u6d3b\u4efb\u52a1\u6267\u884c\uff0c\u89e3\u8026\u5de5\u4f5c\u6d41\u903b\u8f91\u4e0e\u6267\u884c\u914d\u7f6e\u3002", "result": "\u7814\u7a76\u8005\u65e0\u9700\u4e3a\u4e0d\u540c\u7cfb\u7edf\u91cd\u65b0\u5b9e\u73b0\u5de5\u4f5c\u6d41\uff0c\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u6269\u5c55\u3002", "conclusion": "exa-AMD\u4e3a\u6750\u6599\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.21310", "pdf": "https://arxiv.org/pdf/2506.21310", "abs": "https://arxiv.org/abs/2506.21310", "authors": ["Pauline Speckmann", "Mario Nadj", "Christian Janiesch"], "title": "IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems", "categories": ["cs.AI", "cs.SE", "K.6.3 Software Management"], "comment": "9 pages, 2 figures, accepted to DESRIST 2025 Prototype Track", "summary": "Although several post-hoc methods for explainable AI have been developed,\nmost are static and neglect the user perspective, limiting their effectiveness\nfor the target audience. In response, we developed the interactive explainable\nintelligent system called IXAII that offers explanations from four explainable\nAI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored\nviews for five user groups and gives users agency over the explanations'\ncontent and their format. We evaluated IXAII through interviews with experts\nand lay users. Our results indicate that IXAII, which provides different\nexplanations with multiple visualization options, is perceived as helpful to\nincrease transparency. By bridging the gaps between explainable AI methods,\ninteractivity, and practical implementation, we provide a novel perspective on\nAI explanation practices and human-AI interaction.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53ef\u89e3\u91caAI\u7cfb\u7edfIXAII\uff0c\u6574\u5408\u4e86\u56db\u79cd\u65b9\u6cd5\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u5b9a\u5236\u5316\u89e3\u91ca\uff0c\u63d0\u5347\u900f\u660e\u5ea6\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91caAI\u65b9\u6cd5\u591a\u4e3a\u9759\u6001\u4e14\u5ffd\u7565\u7528\u6237\u89c6\u89d2\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u7cfb\u7edfIXAII\uff0c\u7ed3\u5408LIME\u3001SHAP\u3001Anchors\u548cDiCE\u56db\u79cd\u65b9\u6cd5\uff0c\u4e3a\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u63d0\u4f9b\u5b9a\u5236\u5316\u89e3\u91ca\u548c\u53ef\u89c6\u5316\u9009\u9879\u3002", "result": "\u7528\u6237\u548c\u4e13\u5bb6\u8bc4\u4ef7\u663e\u793aIXAII\u80fd\u6709\u6548\u63d0\u5347\u900f\u660e\u5ea6\u3002", "conclusion": "IXAII\u6574\u5408\u4ea4\u4e92\u6027\u548c\u591a\u79cd\u89e3\u91ca\u65b9\u6cd5\uff0c\u4e3a\u4eba\u673a\u4ea4\u4e92\u548cAI\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.21467", "pdf": "https://arxiv.org/pdf/2506.21467", "abs": "https://arxiv.org/abs/2506.21467", "authors": ["Michael Johnston", "Burkhard Ringlein", "Christoph Hagleitner", "Alessandro Pomponio", "Vassilis Vassiliadis", "Christian Pinto", "Srikumar Venugopal"], "title": "Efficient and Reuseable Cloud Configuration Search Using Discovery Spaces", "categories": ["cs.DC", "C.4"], "comment": null, "summary": "Finding the optimal set of cloud resources to deploy a given workload at\nminimal cost while meeting a defined service level agreement is an active area\nof research. Combining tens of parameters applicable across a large selection\nof compute, storage, and services offered by cloud providers with similar\nnumbers of application-specific parameters leads to configuration spaces with\nmillions of deployment options.\n  In this paper, we propose Discovery Space, an abstraction that formalizes the\ndescription of workload configuration problems, and exhibits a set of\ncharacteristics required for structured, robust and distributed investigations\nof large search spaces. We describe a concrete implementation of the Discovery\nSpace abstraction and show that it is generalizable across a diverse set of\nworkloads such as Large Language Model inference and Big Data Analytics.\n  We demonstrate that our approach enables safe, transparent sharing of data\nbetween executions of best-of-breed optimizers increasing the efficiency of\noptimal configuration detection in large search spaces. We also demonstrate how\nDiscovery Spaces enable transfer and reuse of knowledge across similar search\nspaces, enabling configuration search speed-ups of over 90%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiscovery Space\u7684\u62bd\u8c61\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u63cf\u8ff0\u4e91\u8d44\u6e90\u914d\u7f6e\u95ee\u9898\uff0c\u5e76\u652f\u6301\u9ad8\u6548\u3001\u5b89\u5168\u5730\u63a2\u7d22\u5927\u89c4\u6a21\u641c\u7d22\u7a7a\u95f4\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5927\u91cf\u4e91\u8d44\u6e90\u914d\u7f6e\u9009\u9879\u4e2d\u5feb\u901f\u627e\u5230\u6ee1\u8db3\u670d\u52a1\u7ea7\u522b\u534f\u8bae\u4e14\u6210\u672c\u6700\u4f4e\u7684\u6700\u4f18\u914d\u7f6e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Discovery Space\u62bd\u8c61\uff0c\u652f\u6301\u7ed3\u6784\u5316\u548c\u5206\u5e03\u5f0f\u7684\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22\uff0c\u5e76\u5b9e\u73b0\u4e86\u5177\u4f53\u5b9e\u73b0\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u8be5\u65b9\u6cd5\u652f\u6301\u4f18\u5316\u5668\u95f4\u5b89\u5168\u5171\u4eab\u6570\u636e\uff0c\u63d0\u5347\u641c\u7d22\u6548\u7387\uff0c\u5e76\u80fd\u5728\u76f8\u4f3c\u641c\u7d22\u7a7a\u95f4\u4e2d\u5b9e\u73b090%\u4ee5\u4e0a\u7684\u641c\u7d22\u52a0\u901f\u3002", "conclusion": "Discovery Space\u4e3a\u5927\u89c4\u6a21\u914d\u7f6e\u641c\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u6548\u7387\u548c\u77e5\u8bc6\u590d\u7528\u80fd\u529b\u3002"}}
{"id": "2506.20795", "pdf": "https://arxiv.org/pdf/2506.20795", "abs": "https://arxiv.org/abs/2506.20795", "authors": ["Stephanie K\u00e4s", "Anton Burenko", "Louis Markert", "Onur Alp Culha", "Dennis Mack", "Timm Linder", "Bastian Leibe"], "title": "How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?", "categories": ["cs.CV", "cs.HC", "cs.RO", "I.2.10; I.2.9; I.5.4; I.4.8; I.4.9; H.1.2"], "comment": null, "summary": "Gestures enable non-verbal human-robot communication, especially in noisy\nenvironments like agile production. Traditional deep learning-based gesture\nrecognition relies on task-specific architectures using images, videos, or\nskeletal pose estimates as input. Meanwhile, Vision Foundation Models (VFMs)\nand Vision Language Models (VLMs) with their strong generalization abilities\noffer potential to reduce system complexity by replacing dedicated\ntask-specific modules. This study investigates adapting such models for\ndynamic, full-body gesture recognition, comparing V-JEPA (a state-of-the-art\nVFM), Gemini Flash 2.0 (a multimodal VLM), and HD-GCN (a top-performing\nskeleton-based approach). We introduce NUGGET, a dataset tailored for\nhuman-robot communication in intralogistics environments, to evaluate the\ndifferent gesture recognition approaches. In our experiments, HD-GCN achieves\nbest performance, but V-JEPA comes close with a simple, task-specific\nclassification head - thus paving a possible way towards reducing system\ncomplexity, by using it as a shared multi-task model. In contrast, Gemini\nstruggles to differentiate gestures based solely on textual descriptions in the\nzero-shot setting, highlighting the need of further research on suitable input\nrepresentations for gestures.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86V-JEPA\u3001Gemini Flash 2.0\u548cHD-GCN\u5728\u52a8\u6001\u5168\u8eab\u624b\u52bf\u8bc6\u522b\u4e2d\u7684\u8868\u73b0\uff0c\u5176\u4e2dHD-GCN\u8868\u73b0\u6700\u4f73\uff0c\u4f46V-JEPA\u901a\u8fc7\u7b80\u5355\u5206\u7c7b\u5934\u63a5\u8fd1\u5176\u6027\u80fd\uff0cGemini\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u901a\u7528\u89c6\u89c9\u6a21\u578b\uff08VFMs\uff09\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u51cf\u5c11\u624b\u52bf\u8bc6\u522b\u7cfb\u7edf\u7684\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u5728\u5608\u6742\u7684\u751f\u4ea7\u73af\u5883\u4e2d\u3002", "method": "\u6bd4\u8f83\u4e86V-JEPA\u3001Gemini Flash 2.0\u548cHD-GCN\u4e09\u79cd\u6a21\u578b\u5728NUGGET\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e86\u5404\u81ea\u7684\u8f93\u5165\u8868\u793a\u548c\u6027\u80fd\u3002", "result": "HD-GCN\u8868\u73b0\u6700\u597d\uff0cV-JEPA\u901a\u8fc7\u7b80\u5355\u5206\u7c7b\u5934\u63a5\u8fd1\u5176\u6027\u80fd\uff0c\u800cGemini\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u96be\u4ee5\u533a\u5206\u624b\u52bf\u3002", "conclusion": "V-JEPA\u6709\u671b\u901a\u8fc7\u5171\u4eab\u591a\u4efb\u52a1\u6a21\u578b\u51cf\u5c11\u7cfb\u7edf\u590d\u6742\u6027\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u9002\u5408\u624b\u52bf\u8bc6\u522b\u7684\u8f93\u5165\u8868\u793a\u3002"}}
{"id": "2506.20442", "pdf": "https://arxiv.org/pdf/2506.20442", "abs": "https://arxiv.org/abs/2506.20442", "authors": ["Tianyao Shi", "Ritbik Kumar", "Inez Hua", "Yi Ding"], "title": "When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact", "categories": ["cs.CY", "cs.AR", "cs.DC"], "comment": "Accepted by HotCarbon' 25", "summary": "Biodiversity loss is a critical planetary boundary, yet its connection to\ncomputing remains largely unexamined. Prior sustainability efforts in computing\nhave focused on carbon and water, overlooking biodiversity due to the lack of\nappropriate metrics and modeling frameworks. This paper presents the first\nend-to-end analysis of biodiversity impact from computing systems. We introduce\ntwo new metrics--Embodied Biodiversity Index (EBI) and Operational Biodiversity\nIndex (OBI)--to quantify biodiversity impact across the lifecycle, and present\nFABRIC, a modeling framework that links computing workloads to biodiversity\nimpacts. Our evaluation highlights the need to consider biodiversity alongside\ncarbon and water in sustainable computing design and optimization. The code is\navailable at https://github.com/TianyaoShi/FABRIC.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u5206\u6790\u4e86\u8ba1\u7b97\u7cfb\u7edf\u5bf9\u751f\u7269\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u6307\u6807\uff08EBI\u548cOBI\uff09\u4ee5\u53caFABRIC\u5efa\u6a21\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u5728\u53ef\u6301\u7eed\u8ba1\u7b97\u4e2d\u9700\u8981\u540c\u65f6\u8003\u8651\u751f\u7269\u591a\u6837\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8ba1\u7b97\u53ef\u6301\u7eed\u6027\u7814\u7a76\u591a\u5173\u6ce8\u78b3\u548c\u6c34\uff0c\u5ffd\u89c6\u4e86\u751f\u7269\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u5ea6\u91cf\u548c\u65b9\u6cd5\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86Embodied Biodiversity Index (EBI)\u548cOperational Biodiversity Index (OBI)\u4e24\u4e2a\u65b0\u6307\u6807\uff0c\u5e76\u5f00\u53d1\u4e86FABRIC\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\u5bf9\u751f\u7269\u591a\u6837\u6027\u7684\u5f71\u54cd\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u751f\u7269\u591a\u6837\u6027\u5e94\u6210\u4e3a\u53ef\u6301\u7eed\u8ba1\u7b97\u8bbe\u8ba1\u548c\u4f18\u5316\u4e2d\u7684\u91cd\u8981\u8003\u91cf\u56e0\u7d20\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8ba1\u7b97\u9886\u57df\u5f15\u5165\u751f\u7269\u591a\u6837\u6027\u5f71\u54cd\u5ea6\u91cf\u63d0\u4f9b\u4e86\u521d\u6b65\u6846\u67b6\uff0c\u5e76\u5f3a\u8c03\u4e86\u5176\u5728\u53ef\u6301\u7eed\u6027\u7814\u7a76\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.20803", "pdf": "https://arxiv.org/pdf/2506.20803", "abs": "https://arxiv.org/abs/2506.20803", "authors": ["Chenglei Si", "Tatsunori Hashimoto", "Diyi Yang"], "title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": "main paper is 14 pages", "summary": "Large Language Models (LLMs) have shown promise in accelerating the\nscientific research pipeline. A key capability for this process is the ability\nto generate novel research ideas, and prior studies have found settings in\nwhich LLM-generated research ideas were judged as more novel than human-expert\nideas. However, a good idea should not simply appear to be novel, it should\nalso result in better research after being executed. To test whether\nAI-generated ideas lead to better research outcomes, we conduct an execution\nstudy by recruiting 43 expert researchers to execute randomly-assigned ideas,\neither written by experts or generated by an LLM. Each expert spent over 100\nhours implementing the idea and wrote a 4-page short paper to document the\nexperiments. All the executed projects are then reviewed blindly by expert NLP\nresearchers. Comparing the review scores of the same ideas before and after\nexecution, the scores of the LLM-generated ideas decrease significantly more\nthan expert-written ideas on all evaluation metrics (novelty, excitement,\neffectiveness, and overall; p < 0.05), closing the gap between LLM and human\nideas observed at the ideation stage. When comparing the aggregated review\nscores from the execution study, we even observe that for many metrics there is\na flip in rankings where human ideas score higher than LLM ideas. This\nideation-execution gap highlights the limitations of current LLMs in generating\ntruly effective research ideas and the challenge of evaluating research ideas\nin the absence of execution outcomes.", "AI": {"tldr": "LLM\u751f\u6210\u7684\u7814\u7a76\u60f3\u6cd5\u5728\u6267\u884c\u540e\u8bc4\u5206\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u60f3\u6cd5\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u751f\u6210\u771f\u6b63\u6709\u6548\u7814\u7a76\u60f3\u6cd5\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u63a2\u8ba8LLM\u751f\u6210\u7684\u7814\u7a76\u60f3\u6cd5\u5728\u6267\u884c\u540e\u662f\u5426\u4f18\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u60f3\u6cd5\uff0c\u4ee5\u9a8c\u8bc1\u5176\u5728\u5b9e\u9645\u7814\u7a76\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u62db\u52df43\u4f4d\u4e13\u5bb6\u5b9e\u65bd\u968f\u673a\u5206\u914d\u7684\u7814\u7a76\u60f3\u6cd5\uff08LLM\u751f\u6210\u6216\u4eba\u7c7b\u64b0\u5199\uff09\uff0c\u8bb0\u5f55\u6267\u884c\u8fc7\u7a0b\u5e76\u8fdb\u884c\u76f2\u5ba1\u8bc4\u5206\u3002", "result": "\u6267\u884c\u540e\uff0cLLM\u60f3\u6cd5\u7684\u8bc4\u5206\u663e\u8457\u4e0b\u964d\uff0c\u4e0e\u4eba\u7c7b\u60f3\u6cd5\u7684\u5dee\u8ddd\u7f29\u5c0f\uff0c\u90e8\u5206\u6307\u6807\u751a\u81f3\u53cd\u8f6c\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u751f\u6210\u771f\u6b63\u6709\u6548\u7684\u7814\u7a76\u60f3\u6cd5\u4e0a\u4ecd\u6709\u5c40\u9650\u6027\uff0c\u4e14\u4ec5\u57fa\u4e8e\u60f3\u6cd5\u9636\u6bb5\u7684\u8bc4\u4f30\u53ef\u80fd\u4e0d\u591f\u51c6\u786e\u3002"}}
{"id": "2506.20993", "pdf": "https://arxiv.org/pdf/2506.20993", "abs": "https://arxiv.org/abs/2506.20993", "authors": ["Adithya Chittem", "Aishna Shrivastava", "Sai Tarun Pendela", "Jagat Sesh Challa", "Dhruv Kumar"], "title": "SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Under review", "summary": "Large language models (LLMs) have gained significant traction across a wide\nrange of fields in recent years. There is also a growing expectation for them\nto display human-like personalities during interactions. To meet this\nexpectation, numerous studies have proposed methods for modelling LLM\npersonalities through psychometric evaluations. However, most existing models\nface two major limitations: they rely on the Big Five (OCEAN) framework, which\nonly provides coarse personality dimensions, and they lack mechanisms for\ncontrolling trait intensity. In this paper, we address this gap by extending\nthe Machine Personality Inventory (MPI), which originally used the Big Five\nmodel, to incorporate the 16 Personality Factor (16PF) model, allowing\nexpressive control over sixteen distinct traits. We also developed a structured\nframework known as Specific Attribute Control (SAC) for evaluating and\ndynamically inducing trait intensity in LLMs. Our method introduces\nadjective-based semantic anchoring to guide trait intensity expression and\nleverages behavioural questions across five intensity factors:\n\\textit{Frequency}, \\textit{Depth}, \\textit{Threshold}, \\textit{Effort}, and\n\\textit{Willingness}. Through experimentation, we find that modelling intensity\nas a continuous spectrum yields substantially more consistent and controllable\npersonality expression compared to binary trait toggling. Moreover, we observe\nthat changes in target trait intensity systematically influence closely related\ntraits in psychologically coherent directions, suggesting that LLMs internalize\nmulti-dimensional personality structures rather than treating traits in\nisolation. Our work opens new pathways for controlled and nuanced human-machine\ninteractions in domains such as healthcare, education, and interviewing\nprocesses, bringing us one step closer to truly human-like social machines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u901a\u8fc7\u6269\u5c55\u673a\u5668\u4eba\u683c\u6e05\u5355\uff08MPI\uff09\u548c\u5f15\u5165\u7279\u5b9a\u5c5e\u6027\u63a7\u5236\uff08SAC\uff09\u6846\u67b6\uff0c\u4ee516PF\u6a21\u578b\u4e3a\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u5bf9LLM\u4eba\u683c\u7279\u8d28\u7684\u7cbe\u7ec6\u63a7\u5236\u548c\u52a8\u6001\u8c03\u8282\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3LLMs\u5728\u4ea4\u4e92\u4e2d\u8868\u73b0\u51fa\u66f4\u7ec6\u817b\u4e14\u53ef\u63a7\u7684\u4eba\u683c\u7279\u8d28\u7684\u9700\u6c42\uff0c\u73b0\u6709\u7684\u57fa\u4e8eBig Five\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u7ef4\u5ea6\u548c\u5f3a\u5ea6\u63a7\u5236\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u6269\u5c55MPI\u81f316PF\u6a21\u578b\uff0c\u5f00\u53d1SAC\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5bb9\u8bcd\u8bed\u4e49\u951a\u5b9a\u548c\u4e94\u4e2a\u5f3a\u5ea6\u56e0\u5b50\uff08\u9891\u7387\u3001\u6df1\u5ea6\u3001\u9608\u503c\u3001\u52aa\u529b\u548c\u610f\u613f\uff09\u52a8\u6001\u8c03\u8282\u7279\u8d28\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8fde\u7eed\u8c31\u7cfb\u7684\u5f3a\u5ea6\u8c03\u8282\u76f8\u6bd4\u4e8c\u5143\u5207\u6362\u66f4\u80fd\u5b9e\u73b0\u4e00\u81f4\u53ef\u63a7\u7684\u4eba\u683c\u8868\u8fbe\uff0c\u4e14\u7279\u8d28\u5f3a\u5ea6\u7684\u53d8\u5316\u4f1a\u7cfb\u7edf\u5f71\u54cd\u76f8\u5173\u7279\u8d28\uff0c\u8868\u660eLLMs\u5185\u5316\u4e86\u591a\u7ef4\u4eba\u683c\u7ed3\u6784\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4eba\u7c7b\u4e0e\u673a\u5668\u7684\u4ea4\u4e92\u63d0\u4f9b\u4e86\u66f4\u7ec6\u817b\u53ef\u63a7\u7684\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86LLMs\u5728\u533b\u7597\u3001\u6559\u80b2\u7b49\u9886\u57df\u7684\u5e94\u7528\uff0c\u4f7f\u5176\u66f4\u5177\u4eba\u6027\u5316\u3002"}}
{"id": "2506.21036", "pdf": "https://arxiv.org/pdf/2506.21036", "abs": "https://arxiv.org/abs/2506.21036", "authors": ["Fu Peng", "Meng Zhang", "Ming Tang"], "title": "An Information-Theoretic Analysis for Federated Learning under Concept Drift", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Recent studies in federated learning (FL) commonly train models on static\ndatasets. However, real-world data often arrives as streams with shifting\ndistributions, causing performance degradation known as concept drift. This\npaper analyzes FL performance under concept drift using information theory and\nproposes an algorithm to mitigate the performance degradation. We model concept\ndrift as a Markov chain and introduce the \\emph{Stationary Generalization\nError} to assess a model's capability to capture characteristics of future\nunseen data. Its upper bound is derived using KL divergence and mutual\ninformation. We study three drift patterns (periodic, gradual, and random) and\ntheir impact on FL performance. Inspired by this, we propose an algorithm that\nregularizes the empirical risk minimization approach with KL divergence and\nmutual information, thereby enhancing long-term performance. We also explore\nthe performance-cost tradeoff by identifying a Pareto front. To validate our\napproach, we build an FL testbed using Raspberry Pi4 devices. Experimental\nresults corroborate with theoretical findings, confirming that drift patterns\nsignificantly affect performance. Our method consistently outperforms existing\napproaches for these three patterns, demonstrating its effectiveness in\nadapting concept drift in FL.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u6982\u5ff5\u6f02\u79fb\u4e0b\u7684\u6027\u80fd\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u7684\u7b97\u6cd5\u6765\u7f13\u89e3\u6027\u80fd\u4e0b\u964d\u3002\u901a\u8fc7\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u94fe\u5e76\u5f15\u5165\u9759\u6001\u6cdb\u5316\u8bef\u5dee\u8bc4\u4f30\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u901a\u5e38\u662f\u52a8\u6001\u7684\u4e14\u5206\u5e03\u4f1a\u53d8\u5316\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff08\u6982\u5ff5\u6f02\u79fb\uff09\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76FL\u5728\u6982\u5ff5\u6f02\u79fb\u4e0b\u7684\u8868\u73b0\u5e76\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u6982\u5ff5\u6f02\u79fb\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u63d0\u51fa\u9759\u6001\u6cdb\u5316\u8bef\u5dee\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8eKL\u6563\u5ea6\u548c\u4e92\u4fe1\u606f\u7684\u6b63\u5219\u5316\u7b97\u6cd5\u4ee5\u9002\u5e94\u6f02\u79fb\u3002\u8fd8\u7814\u7a76\u4e86\u4e09\u79cd\u6f02\u79fb\u6a21\u5f0f\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\uff0c\u8868\u660e\u6f02\u79fb\u6a21\u5f0f\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u4e14\u6240\u63d0\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u6709\u6548\u9002\u5e94\u6982\u5ff5\u6f02\u79fb\uff0c\u63d0\u5347FL\u7684\u957f\u671f\u6027\u80fd\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u6027\u80fd\u4e0e\u6210\u672c\u7684\u6743\u8861\u3002"}}
{"id": "2506.21338", "pdf": "https://arxiv.org/pdf/2506.21338", "abs": "https://arxiv.org/abs/2506.21338", "authors": ["Galvin Brice S. Lim", "Brian Godwin S. Lim", "Argel A. Bandala", "John Anthony C. Jose", "Timothy Scott C. Chu", "Edwin Sybingco"], "title": "AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification", "categories": ["cs.LG", "cs.HC"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Brain-computer interface (BCI) technology utilizing electroencephalography\n(EEG) marks a transformative innovation, empowering motor-impaired individuals\nto engage with their environment on equal footing. Despite its promising\npotential, developing subject-invariant and session-invariant BCI systems\nremains a significant challenge due to the inherent complexity and variability\nof neural activity across individuals and over time, compounded by EEG hardware\nconstraints. While prior studies have sought to develop robust BCI systems,\nexisting approaches remain ineffective in capturing the intricate\nspatiotemporal dependencies within multichannel EEG signals. This study\naddresses this gap by introducing the attentive graph-temporal convolutional\nnetwork (AGTCNet), a novel graph-temporal model for motor imagery EEG (MI-EEG)\nclassification. Specifically, AGTCNet leverages the topographic configuration\nof EEG electrodes as an inductive bias and integrates graph convolutional\nattention network (GCAT) to jointly learn expressive spatiotemporal EEG\nrepresentations. The proposed model significantly outperformed existing MI-EEG\nclassifiers, achieving state-of-the-art performance while utilizing a compact\narchitecture, underscoring its effectiveness and practicality for BCI\ndeployment. With a 49.87% reduction in model size, 64.65% faster inference\ntime, and shorter input EEG signal, AGTCNet achieved a moving average accuracy\nof 66.82% for subject-independent classification on the BCI Competition IV\nDataset 2a, which further improved to 82.88% when fine-tuned for\nsubject-specific classification. On the EEG Motor Movement/Imagery Dataset,\nAGTCNet achieved moving average accuracies of 64.14% and 85.22% for 4-class and\n2-class subject-independent classifications, respectively, with further\nimprovements to 72.13% and 90.54% for subject-specific classifications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u56fe\u65f6\u5e8f\u5377\u79ef\u7f51\u7edc\uff08AGTCNet\uff09\uff0c\u7528\u4e8e\u8fd0\u52a8\u60f3\u8c61\u8111\u7535\u56fe\uff08MI-EEG\uff09\u5206\u7c7b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u5728\u6a21\u578b\u5927\u5c0f\u3001\u63a8\u7406\u65f6\u95f4\u548c\u8f93\u5165\u4fe1\u53f7\u957f\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u5316\u3002", "motivation": "\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u6280\u672f\u867d\u7136\u5728\u5e2e\u52a9\u8fd0\u52a8\u969c\u788d\u8005\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u56e0\u795e\u7ecf\u6d3b\u52a8\u7684\u590d\u6742\u6027\u548c\u53d8\u5f02\u6027\uff0c\u5f00\u53d1\u9002\u7528\u4e8e\u4e0d\u540c\u4e2a\u4f53\u548c\u4e0d\u540c\u4f1a\u8bdd\u7684BCI\u7cfb\u7edf\u4ecd\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u6355\u6349\u591a\u901a\u9053\u8111\u7535\u56fe\u4fe1\u53f7\u4e2d\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86AGTCNet\u6a21\u578b\uff0c\u5229\u7528\u8111\u7535\u56fe\u7535\u6781\u7684\u62d3\u6251\u7ed3\u6784\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u5e76\u7ed3\u5408\u56fe\u5377\u79ef\u6ce8\u610f\u529b\u7f51\u7edc\uff08GCAT\uff09\u6765\u8054\u5408\u5b66\u4e60\u65f6\u7a7a\u8111\u7535\u56fe\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cAGTCNet\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u4e8649.87%\uff0c\u63a8\u7406\u65f6\u95f4\u5feb\u4e8664.65%\uff0c\u4e14\u5728\u4e3b\u4f53\u72ec\u7acb\u548c\u4e3b\u4f53\u7279\u5b9a\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "AGTCNet\u901a\u8fc7\u5176\u7d27\u51d1\u7684\u67b6\u6784\u548c\u9ad8\u6548\u7684\u8868\u73b0\uff0c\u4e3aBCI\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u5e76\u4f18\u5316\u4e86\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2506.21490", "pdf": "https://arxiv.org/pdf/2506.21490", "abs": "https://arxiv.org/abs/2506.21490", "authors": ["Tin Dizdarevi\u0107", "Ravi Hammond", "Tobias Gessler", "Anisoara Calinescu", "Jonathan Cook", "Matteo Gallici", "Andrei Lupu", "Jakob Nicolaus Foerster"], "title": "Ad-Hoc Human-AI Coordination Challenge", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": "Published at ICML 2025", "summary": "Achieving seamless coordination between AI agents and humans is crucial for\nreal-world applications, yet it remains a significant open challenge. Hanabi is\na cooperative card game featuring imperfect information, constrained\ncommunication, theory of mind requirements, and coordinated action -- making it\nan ideal testbed for human-AI coordination. However, its use for human-AI\ninteraction has been limited by the challenges of human evaluation. In this\nwork, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to\novercome the constraints of costly and difficult-to-reproduce human\nevaluations. We develop \\textit{human proxy agents} on a large-scale human\ndataset that serve as robust, cheap, and reproducible human-like evaluation\npartners in AH2AC2. To encourage the development of data-efficient methods, we\nopen-source a dataset of 3,079 games, deliberately limiting the amount of\navailable human gameplay data. We present baseline results for both two- and\nthree- player Hanabi scenarios. To ensure fair evaluation, we host the proxy\nagents through a controlled evaluation system rather than releasing them\npublicly. The code is available at\n\\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u4eba\u7c7b\u4e0eAI\u534f\u8c03\u4e2d\u7684\u8bc4\u4f30\u96be\u9898\uff0c\u7814\u7a76\u56e2\u961f\u63d0\u51fa\u4e86AH2AC2\u6311\u6218\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u7684\u2018\u4eba\u7c7b\u4ee3\u7406\u2019\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\uff0c\u540c\u65f6\u5f00\u6e90\u4e86\u5c11\u91cf\u6e38\u620f\u6570\u636e\u4ee5\u4fc3\u8fdb\u6570\u636e\u6548\u7387\u65b9\u6cd5\u7684\u7814\u7a76\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u4eba\u7c7b\u4e0eAI\u7684\u65e0\u7f1d\u534f\u8c03\u662f\u91cd\u8981\u4f46\u5c1a\u672a\u89e3\u51b3\u7684\u6311\u6218\uff0cHanabi\u6e38\u620f\u56e0\u5176\u590d\u6742\u6027\u6210\u4e3a\u7406\u60f3\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4f46\u4eba\u7c7b\u8bc4\u4f30\u7684\u9ad8\u6210\u672c\u548c\u96be\u590d\u73b0\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002", "method": "\u7814\u7a76\u901a\u8fc7AH2AC2\u6311\u6218\uff0c\u5229\u7528\u5927\u89c4\u6a21\u4eba\u7c7b\u6e38\u620f\u6570\u636e\u8bad\u7ec3\u2018\u4eba\u7c7b\u4ee3\u7406\u2019\u4f5c\u4e3a\u8bc4\u4f30\u4f19\u4f34\uff0c\u5e76\u5f00\u6e90\u5c11\u91cf\u6570\u636e\u9f13\u52b1\u6570\u636e\u6548\u7387\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e24\u73a9\u5bb6\u548c\u4e09\u73a9\u5bb6Hanabi\u573a\u666f\u7684\u57fa\u7ebf\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u53d7\u63a7\u7cfb\u7edf\u63d0\u4f9b\u4ee3\u7406\u4ee5\u516c\u5e73\u8bc4\u4f30\u3002", "conclusion": "AH2AC2\u4e3a\u4eba\u7c7b-AI\u534f\u8c03\u7814\u7a76\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u8fd9\u4e00\u9886\u57df\u7684\u8fdb\u6b65\u3002"}}
{"id": "2506.21524", "pdf": "https://arxiv.org/pdf/2506.21524", "abs": "https://arxiv.org/abs/2506.21524", "authors": ["Libn Varghese", "Bhaskar Chaudhury", "Miral Shah", "Mainak Bandyopadhyay"], "title": "Benchmarking and Parallelization of Electrostatic Particle-In-Cell for low-temperature Plasma Simulation by particle-thread Binding", "categories": ["physics.comp-ph", "cs.DC", "physics.plasm-ph"], "comment": null, "summary": "The Particle-In-Cell (PIC) method for plasma simulation tracks particle phase\nspace information using particle and grid data structures. High computational\ncosts in 2D and 3D device-scale PIC simulations necessitate parallelization,\nwith the Charge Deposition (CD) subroutine often becoming a bottleneck due to\nfrequent particle-grid interactions. Conventional methods mitigate dependencies\nby generating private grids for each core, but this approach faces scalability\nissues. We propose a novel approach based on a particle-thread binding strategy\nthat requires only four private grids per node in distributed memory systems or\nfour private grids in shared memory systems, enhancing CD scalability and\nperformance while maintaining conventional data structures and requiring\nminimal changes to existing PIC codes. This method ensures complete\naccessibility of grid data structure for concurrent threads and avoids\nsimultaneous access to particles within the same cell using additional\nfunctions and flags. Performance evaluations using a PIC benchmark for\nlow-temperature partially magnetized E x B discharge simulation on a shared\nmemory as well as a distributed memory system (1000 cores) demonstrate the\nmethod's scalability, and additionally, we show the method has little hardware\ndependency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7c92\u5b50-\u7ebf\u7a0b\u7ed1\u5b9a\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86PIC\u6a21\u62df\u4e2d\u7535\u8377\u6c89\u79ef\u5b50\u7a0b\u5e8f\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4f20\u7edf\u6570\u636e\u7ed3\u6784\uff0c\u4ec5\u9700\u6700\u5c0f\u4fee\u6539\u3002", "motivation": "\u9488\u5bf92D\u548c3D\u8bbe\u5907\u5c3a\u5ea6PIC\u6a21\u62df\u4e2d\u7535\u8377\u6c89\u79ef\u5b50\u7a0b\u5e8f\u56e0\u9891\u7e41\u7684\u7c92\u5b50-\u7f51\u683c\u4ea4\u4e92\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u56e0\u751f\u6210\u79c1\u6709\u7f51\u683c\u800c\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002", "method": "\u91c7\u7528\u7c92\u5b50-\u7ebf\u7a0b\u7ed1\u5b9a\u7b56\u7565\uff0c\u4ec5\u9700\u6bcf\u4e2a\u8282\u70b9\u6216\u5171\u4eab\u5185\u5b58\u7cfb\u7edf\u4e2d\u56db\u4e2a\u79c1\u6709\u7f51\u683c\uff0c\u901a\u8fc7\u9644\u52a0\u529f\u80fd\u548c\u6807\u5fd7\u786e\u4fdd\u7f51\u683c\u6570\u636e\u7ed3\u6784\u5b8c\u5168\u53ef\u8bbf\u95ee\uff0c\u5e76\u907f\u514d\u5bf9\u540c\u5355\u5143\u7c92\u5b50\u7684\u540c\u65f6\u8bbf\u95ee\u3002", "result": "\u5728\u5171\u4eab\u5185\u5b58\u548c\u5206\u5e03\u5f0f\u5185\u5b58\u7cfb\u7edf\uff081000\u6838\uff09\u4e0a\u7684\u6027\u80fd\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u5177\u6709\u51fa\u8272\u7684\u53ef\u6269\u5c55\u6027\u548c\u8f83\u4f4e\u786c\u4ef6\u4f9d\u8d56\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86PIC\u6a21\u62df\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4ee3\u7801\u7684\u7b80\u6d01\u6027\u548c\u517c\u5bb9\u6027\u3002"}}
{"id": "2506.21536", "pdf": "https://arxiv.org/pdf/2506.21536", "abs": "https://arxiv.org/abs/2506.21536", "authors": ["Fangjun Ding", "Renyu Zhang", "Xinyu Feng", "Chengye Xie", "Zheng Zhang", "Yanting Zhang"], "title": "PsyLite Technical Report", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "With the rapid development of digital technology, AI-driven psychological\ncounseling has gradually become an important research direction in the field of\nmental health. However, existing models still have deficiencies in dialogue\nsafety, detailed scenario handling, and lightweight deployment. To address\nthese issues, this study proposes PsyLite, a lightweight psychological\ncounseling large language model agent developed based on the base model\nInternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation\ndata fine-tuning and ORPO preference optimization), PsyLite enhances the\nmodel's deep-reasoning ability, psychological counseling ability, and safe\ndialogue ability. After deployment using Ollama and Open WebUI, a custom\nworkflow is created with Pipelines. An innovative conditional RAG is designed\nto introduce crosstalk humor elements at appropriate times during psychological\ncounseling to enhance user experience and decline dangerous requests to\nstrengthen dialogue safety. Evaluations show that PsyLite outperforms the\nbaseline models in the Chinese general evaluation (CEval), psychological\ncounseling professional evaluation (CPsyCounE), and dialogue safety evaluation\n(SafeDialBench), particularly in psychological counseling professionalism\n(CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score\nimprovement of 2.4\\%). Additionally, the model uses quantization technology\n(GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient\nfor operation), providing a feasible solution for psychological counseling\napplications in resource-constrained environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPsyLite\uff0c\u4e00\u79cd\u57fa\u4e8eInternLM2.5-7B-chat\u7684\u8f7b\u91cf\u7ea7\u5fc3\u7406\u54a8\u8be2\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6df7\u5408\u84b8\u998f\u6570\u636e\u5fae\u8c03\u548cORPO\u504f\u597d\u4f18\u5316\u589e\u5f3a\u80fd\u529b\uff0c\u5e76\u5728\u591a\u9879\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709AI\u5fc3\u7406\u54a8\u8be2\u6a21\u578b\u5728\u5bf9\u8bdd\u5b89\u5168\u3001\u573a\u666f\u5904\u7406\u53ca\u8f7b\u91cf\u5316\u90e8\u7f72\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff08\u6df7\u5408\u84b8\u998f\u6570\u636e\u5fae\u8c03+ORPO\u504f\u597d\u4f18\u5316\uff09\u548c\u6761\u4ef6RAG\u6280\u672f\uff0c\u7ed3\u5408\u4f4e\u786c\u4ef6\u90e8\u7f72\u65b9\u6848\u3002", "result": "PsyLite\u5728\u591a\u9879\u8bc4\u4f30\u4e2d\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u5fc3\u7406\u8f85\u5bfc\u4e13\u4e1a\u6027\u63d0\u534747.6%\uff0c\u5bf9\u8bdd\u5b89\u5168\u6027\u63d0\u53472.4%\uff0c\u4e14\u4ec5\u97005GB\u5185\u5b58\u3002", "conclusion": "PsyLite\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u5fc3\u7406\u54a8\u8be2\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
