{"id": "2509.02860", "pdf": "https://arxiv.org/pdf/2509.02860", "abs": "https://arxiv.org/abs/2509.02860", "authors": ["Connor Wojtak", "Darek Gajewski", "Tomas Cerny"], "title": "Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems", "categories": ["cs.SE", "cs.LO"], "comment": "Accepted at MODELS 2025", "summary": "Microservice systems are becoming increasingly adopted due to their\nscalability, decentralized development, and support for continuous integration\nand delivery (CI/CD). However, this decentralized development by separate teams\nand continuous evolution can introduce miscommunication and incompatible\nimplementations, undermining system maintainability and reliability across\naspects from security policy to system architecture. We propose a novel\nmethodology that statically reconstructs microservice source code into a formal\nsystem model. From this model, a Satisfiability Modulo Theories (SMT)\nconstraint set can be derived, enabling formal verification. Our methodology is\nextensible, supporting software verification across multiple cross-cutting\nconcerns. We focus on applying the methodology to verify the system\narchitecture concern, presenting formal reasoning to validate the methodology's\ncorrectness and applicability for this concern. Additional concerns such as\nsecurity policy implementation are considered. Future directions are\nestablished to extend and evaluate the methodology."}
{"id": "2509.03093", "pdf": "https://arxiv.org/pdf/2509.03093", "abs": "https://arxiv.org/abs/2509.03093", "authors": ["Fatih Pehlivan", "Arçin Ülkü Ergüzen", "Sahand Moslemi Yengejeh", "Mayasah Lami", "Anil Koyuncu"], "title": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to ASE2025", "summary": "Traditional static analysis methods struggle to detect semantic design flaws,\nsuch as violations of the SOLID principles, which require a strong\nunderstanding of object-oriented design patterns and principles. Existing\nsolutions typically focus on individual SOLID principles or specific\nprogramming languages, leaving a gap in the ability to detect violations across\nall five principles in multi-language codebases. This paper presents a new\napproach: a methodology that leverages tailored prompt engineering to assess\nLLMs on their ability to detect SOLID violations across multiple languages. We\npresent a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,\nand GPT-4o Mini-on their ability to detect violations of all five SOLID\nprinciples. For this evaluation, we construct a new benchmark dataset of 240\nmanually validated code examples. Using this dataset, we test four distinct\nprompt strategies inspired by established zero-shot, few-shot, and\nchain-of-thought techniques to systematically measure their impact on detection\naccuracy. Our emerging results reveal a stark hierarchy among models, with\nGPT-4o Mini decisively outperforming others, yet even struggles with\nchallenging principles like DIP. Crucially, we show that prompt strategy has a\ndramatic impact, but no single strategy is universally best; for instance, a\ndeliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE\nprompt is superior for DIP violations. Across all experiments, detection\naccuracy is heavily influenced by language characteristics and degrades sharply\nwith increasing code complexity. These initial findings demonstrate that\neffective, AI-driven design analysis requires not a single best model, but a\ntailored approach that matches the right model and prompt to the specific\ndesign context, highlighting the potential of LLMs to support maintainability\nthrough AI-assisted code analysis."}
{"id": "2509.03270", "pdf": "https://arxiv.org/pdf/2509.03270", "abs": "https://arxiv.org/abs/2509.03270", "authors": ["Martin Skoglund", "Fredrik Warg", "Aria Mirzai", "Anders Thorsen", "Karl Lundgren", "Peter Folkesson", "Bastian Havers-zulka"], "title": "AI Safety Assurance in Electric Vehicles: A Case Study on AI-Driven SOC Estimation", "categories": ["cs.SE", "cs.RO"], "comment": "12 pages, 9 figures, EVS38,\n  https://evs38-program.org/en/evs-38-proceedings/all", "summary": "Integrating Artificial Intelligence (AI) technology in electric vehicles (EV)\nintroduces unique challenges for safety assurance, particularly within the\nframework of ISO 26262, which governs functional safety in the automotive\ndomain. Traditional assessment methodologies are not geared toward evaluating\nAI-based functions and require evolving standards and practices. This paper\nexplores how an independent assessment of an AI component in an EV can be\nachieved when combining ISO 26262 with the recently released ISO/PAS 8800,\nwhose scope is AI safety for road vehicles. The AI-driven State of Charge (SOC)\nbattery estimation exemplifies the process. Key features relevant to the\nindependent assessment of this extended evaluation approach are identified. As\npart of the evaluation, robustness testing of the AI component is conducted\nusing fault injection experiments, wherein perturbed sensor inputs are\nsystematically introduced to assess the component's resilience to input\nvariance."}
{"id": "2509.03331", "pdf": "https://arxiv.org/pdf/2509.03331", "abs": "https://arxiv.org/abs/2509.03331", "authors": ["Weizhe Wang", "Wei Ma", "Qiang Hu", "Yao Zhang", "Jianfei Sun", "Bin Wu", "Yang Liu", "Guangquan Xu", "Lingxiao Jiang"], "title": "VulnRepairEval: An Exploit-Based Evaluation Framework for Assessing Large Language Model Vulnerability Repair Capabilities", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "The adoption of Large Language Models (LLMs) for automated software\nvulnerability patching has shown promising outcomes on carefully curated\nevaluation sets. Nevertheless, existing datasets predominantly rely on\nsuperficial validation methods rather than exploit-based verification, leading\nto overestimated performance in security-sensitive applications. This paper\nintroduces VulnRepairEval, an evaluation framework anchored in functional\nProof-of-Concept (PoC) exploits. Our framework delivers a comprehensive,\ncontainerized evaluation pipeline that enables reproducible differential\nassessment, where repair success requires the original exploit to fail\nexecution against the modified code. The benchmark construction involved\nextensive data curation: we processed over 400 CVEs and approximately 2,500\npotential sources to extract a collection of authentic vulnerability instances\n(23 Python CVEs) amenable to automated testing with working PoCs. Through\nVulnRepairEval, we conduct a comprehensive evaluation of 12 popular LLMs and\nobserve a significant performance deficit: even the top-performing model\nsuccessfully addresses merely 5/23 instances (about 21.7%), exposing critical\nweaknesses in security-focused applications. Our failure analysis reveals that\nmost unsuccessful attempts stem from imprecise vulnerability identification and\npatches containing syntactic or semantic errors. Enhanced prompting strategies\nand multi-agent approaches yield minimal improvements, with overall\neffectiveness remaining largely unaffected. This work contributes a stringent,\npractical evaluation framework for LLM-driven vulnerability remediation and\nunderscores the necessity for assessment protocols that authentically reflect\nreal-world exploitation scenarios."}
{"id": "2509.02899", "pdf": "https://arxiv.org/pdf/2509.02899", "abs": "https://arxiv.org/abs/2509.02899", "authors": ["Alan Beadle", "Michael L. Scott", "John Criswell"], "title": "Safe Sharing of Fast Kernel-Bypass I/O Among Nontrusting Applications", "categories": ["cs.OS", "cs.CR"], "comment": "13 pages", "summary": "Protected user-level libraries have been proposed as a way to allow mutually\ndistrusting applications to safely share kernel-bypass services. In this paper,\nwe identify and solve several previously unaddressed obstacles to realizing\nthis design and identify several optimization opportunities. First, to preserve\nthe kernel's ability to reclaim failed processes, protected library functions\nmust complete in modest, bounded time. We show how to move unbounded waits\noutside the library itself, enabling synchronous interaction among processes\nwithout the need for polling. Second, we show how the bounded time requirement\ncan be leveraged to achieve lower and more stable latency for inter-process\ninteractions. Third, we observe that prior work on protected libraries is\nvulnerable to a buffer unmapping attack; we prevent this attack by preventing\napplications from removing pages that they share with the protected library.\nFourth, we show how a trusted daemon can respond to asynchronous events and\ndynamically divide work with application threads in a protected library.\n  By extending and improving the protected library model, our work provides a\nnew way to structure OS services, combining the advantages of kernel bypass and\nmicrokernels. We present a set of safety and performance guidelines for\ndevelopers of protected libraries, and a set of recommendations for developers\nof future protected library operating systems. We demonstrate the convenience\nand performance of our approach with a prototype version of the DDS\ncommunication service. To the best of our knowledge, this prototype represents\nthe first successful sharing of a kernel-bypass NIC among mutually untrusting\napplications. Relative to the commercial FastDDS implementation, we achieve\napproximately 50\\% lower latency and up to 7x throughput, with lower CPU\nutilization."}
{"id": "2509.03430", "pdf": "https://arxiv.org/pdf/2509.03430", "abs": "https://arxiv.org/abs/2509.03430", "authors": ["Vimal Mollyn", "Nathan DeVrio", "Chris Harrison"], "title": "EclipseTouch: Touch Segmentation on Ad Hoc Surfaces using Worn Infrared Shadow Casting", "categories": ["cs.HC", "cs.CV", "cs.GR", "cs.RO"], "comment": "Accepted to UIST 2025", "summary": "The ability to detect touch events on uninstrumented, everyday surfaces has\nbeen a long-standing goal for mixed reality systems. Prior work has shown that\nvirtual interfaces bound to physical surfaces offer performance and ergonomic\nbenefits over tapping at interfaces floating in the air. A wide variety of\napproaches have been previously developed, to which we contribute a new\nheadset-integrated technique called \\systemname. We use a combination of a\ncomputer-triggered camera and one or more infrared emitters to create\nstructured shadows, from which we can accurately estimate hover distance (mean\nerror of 6.9~mm) and touch contact (98.0\\% accuracy). We discuss how our\ntechnique works across a range of conditions, including surface material,\ninteraction orientation, and environmental lighting."}
{"id": "2509.02924", "pdf": "https://arxiv.org/pdf/2509.02924", "abs": "https://arxiv.org/abs/2509.02924", "authors": ["Nefeli Manoudaki", "Mert Toka", "Iason Paterakis", "Diarmid Flatley"], "title": "Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence", "categories": ["cs.MM", "cs.AI", "cs.HC"], "comment": "to be published in IEEE VISAP 2025", "summary": "Simulacra Naturae is a data-driven media installation that explores\ncollective care through the entanglement of biological computation, material\necologies, and generative systems. The work translates pre-recorded neural\nactivity from brain organoids, lab-grown three-dimensional clusters of neurons,\ninto a multi-sensory environment composed of generative visuals, spatial audio,\nliving plants, and fabricated clay artifacts. These biosignals, streamed\nthrough a real-time system, modulate emergent agent behaviors inspired by\nnatural systems such as termite colonies and slime molds. Rather than using\nbiosignals as direct control inputs, Simulacra Naturae treats organoid activity\nas a co-creative force, allowing neural rhythms to guide the growth, form, and\natmosphere of a generative ecosystem. The installation features computationally\nfabricated clay prints embedded with solenoids, adding physical sound\nresonances to the generative surround composition. The spatial environment,\nfilled with live tropical plants and a floor-level projection layer featuring\nreal-time generative AI visuals, invites participants into a sensory field\nshaped by nonhuman cognition. By grounding abstract data in living materials\nand embodied experience, Simulacra Naturae reimagines visualization as a\npractice of care, one that decentralizes human agency and opens new spaces for\nethics, empathy, and ecological attunement within hybrid computational systems."}
{"id": "2509.02578", "pdf": "https://arxiv.org/pdf/2509.02578", "abs": "https://arxiv.org/abs/2509.02578", "authors": ["Abel C. H. Chen"], "title": "Secure Password Generator Based on Secure Pseudo-Random Number Generator", "categories": ["cs.CR", "cs.PF"], "comment": "in Chinese language", "summary": "In recent years, numerous incidents involving the leakage of website accounts\nand text passwords (referred to as passwords) have raised significant concerns\nregarding the potential exposure of personal information. These events\nunderscore the critical importance of both information security and password\nprotection. While many of these breaches are attributable to vulnerabilities\nwithin website infrastructure, the strength and security of the passwords\nthemselves also play a crucial role. Consequently, the creation of secure\npasswords constitutes a fundamental aspect of enhancing overall system security\nand protecting personal data. In response to these challenges, this study\npresents a secure password generation approach utilizing a cryptographically\nsecure Pseudo-Random Number Generator (PRNG). The generator is implemented\nusing a range of Message Authentication Code (MAC) algorithms, including the\nKeyed-Hash Message Authentication Code (HMAC), Cipher-based Message\nAuthentication Code (CMAC), and KECCAK Message Authentication Code (KMAC), to\nproduce robust random values suitable for password generation. To evaluate the\nproposed method, empirical assessments were conducted in accordance with the\nguidelines provided in the National Institute of Standards and Technology\n(NIST) Special Publication (SP) 800-90B. The evaluation focused on two primary\naspects: entropy estimation and verification of independent and identically\ndistributed (IID) properties. Experimental results indicate that the proposed\nmethod satisfies both entropy and IID requirements, thereby demonstrating its\nability to generate passwords with a high degree of randomness and security."}
{"id": "2509.02958", "pdf": "https://arxiv.org/pdf/2509.02958", "abs": "https://arxiv.org/abs/2509.02958", "authors": ["Kaustuv Mukherji", "Jaikrishna Manojkumar Patil", "Dyuman Aditya", "Paulo Shakarian", "Devendra Parkar", "Lahari Pokala", "Clark Dorman", "Gerardo I. Simari"], "title": "Lattice Annotated Temporal (LAT) Logic for Non-Markovian Reasoning", "categories": ["cs.LO", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "We introduce Lattice Annotated Temporal (LAT) Logic, an extension of\nGeneralized Annotated Logic Programs (GAPs) that incorporates temporal\nreasoning and supports open-world semantics through the use of a lower lattice\nstructure. This logic combines an efficient deduction process with temporal\nlogic programming to support non-Markovian relationships and open-world\nreasoning capabilities. The open-world aspect, a by-product of the use of the\nlower-lattice annotation structure, allows for efficient grounding through a\nSkolemization process, even in domains with infinite or highly diverse\nconstants.\n  We provide a suite of theoretical results that bound the computational\ncomplexity of the grounding process, in addition to showing that many of the\nresults on GAPs (using an upper lattice) still hold with the lower lattice and\ntemporal extensions (though different proof techniques are required). Our\nopen-source implementation, PyReason, features modular design, machine-level\noptimizations, and direct integration with reinforcement learning environments.\nEmpirical evaluations across multi-agent simulations and knowledge graph tasks\ndemonstrate up to three orders of magnitude speedup and up to five orders of\nmagnitude memory reduction while maintaining or improving task performance.\nAdditionally, we evaluate LAT Logic's value in reinforcement learning\nenvironments as a non-Markovian simulator, achieving up to three orders of\nmagnitude faster simulation with improved agent performance, including a 26%\nincrease in win rate due to capturing richer temporal dependencies. These\nresults highlight LAT Logic's potential as a unified, extensible framework for\nopen-world temporal reasoning in dynamic and uncertain environments. Our\nimplementation is available at: pyreason.syracuse.edu."}
{"id": "2509.03318", "pdf": "https://arxiv.org/pdf/2509.03318", "abs": "https://arxiv.org/abs/2509.03318", "authors": ["Eduard Kamburjan", "Vidar Norstein Klungre", "Yuanwei Qu", "Rudolf Schlatte", "Egor V. Kostylev", "Martin Giese", "Einar Broch Johnsen"], "title": "Semantically Reflected Programs", "categories": ["cs.PL", "cs.LO"], "comment": null, "summary": "This paper addresses the dichotomy between the formalization of structural\nand the formalization of behavioral knowledge by means of semantically lifted\nprograms, which explore an intuitive connection between programs and knowledge\ngraphs. While knowledge graphs and ontologies are eminently useful to represent\nformal knowledge about a system's individuals and universals, programming\nlanguages are designed to describe the system's evolution. To address this\ndichotomy, we introduce a semantic lifting of the program states of an\nexecuting program into a knowledge graph, for an object-oriented programming\nlanguage. The resulting graph is exposed as a semantic reflection layer within\nthe programming language, allowing programmers to leverage knowledge of the\napplication domain in their programs. In this paper, we formalize semantic\nlifting and semantic reflection for a small programming language, SMOL, explain\nthe operational aspects of the language, and consider type correctness and\nvirtualisation for runtime program queries through the semantic reflection\nlayer. We illustrate semantic lifting and semantic reflection through a case\nstudy of geological modelling and discuss different applications of the\ntechnique. The language implementation is open source and available online."}
{"id": "2509.02594", "pdf": "https://arxiv.org/pdf/2509.02594", "abs": "https://arxiv.org/abs/2509.02594", "authors": ["Sandhanakrishnan Ravichandran", "Shivesh Kumar", "Rogerio Corga Da Silva", "Miguel Romano", "Reinhard Berkels", "Michiel van der Heijden", "Olivier Fail", "Valentine Emmanuel Gnanapragasam"], "title": "OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries", "categories": ["q-bio.QM", "cs.AI", "cs.ET", "cs.IR"], "comment": "13 pages, two graphs", "summary": "Evaluating large language models (LLMs) on their ability to generate\nhigh-quality, accurate, situationally aware answers to clinical questions\nrequires going beyond conventional benchmarks to assess how these systems\nbehave in complex, high-stake clincal scenarios. Traditional evaluations are\noften limited to multiple-choice questions that fail to capture essential\ncompetencies such as contextual reasoning, awareness and uncertainty handling\netc. To address these limitations, we evaluate our agentic, RAG-based clinical\nsupport assistant, DR.INFO, using HealthBench, a rubric-driven benchmark\ncomposed of open-ended, expert-annotated health conversations. On the Hard\nsubset of 1,000 challenging examples, DR.INFO achieves a HealthBench score of\n0.51, substantially outperforming leading frontier LLMs (GPT-5, o3, Grok 3,\nGPT-4, Gemini 2.5, etc.) across all behavioral axes (accuracy, completeness,\ninstruction following, etc.). In a separate 100-sample evaluation against\nsimilar agentic RAG assistants (OpenEvidence, Pathway.md), it maintains a\nperformance lead with a health-bench score of 0.54. These results highlight\nDR.INFOs strengths in communication, instruction following, and accuracy, while\nalso revealing areas for improvement in context awareness and completeness of a\nresponse. Overall, the findings underscore the utility of behavior-level,\nrubric-based evaluation for building a reliable and trustworthy AI-enabled\nclinical support assistant."}
{"id": "2509.02806", "pdf": "https://arxiv.org/pdf/2509.02806", "abs": "https://arxiv.org/abs/2509.02806", "authors": ["Jon Larrea", "Tanya Shreedhar", "Mahesh K. Marina"], "title": "BISCAY: Practical Radio KPI Driven Congestion Control for Mobile Networks", "categories": ["cs.NI"], "comment": null, "summary": "Mobile application performance relies heavily on the congestion control\ndesign of the underlying transport, which is typically bottlenecked by cellular\nlink and has to cope with rapid cellular link bandwidth fluctuations. We\nobserve that radio KPI measurements from the mobile device chipset can be\nexploited for precise and timely measurement of available bandwidth on the\ncellular link. Building on this insight, we propose Biscay, a practical and\nradio KPI-driven congestion control system design for mobile networks. Biscay\nleverages OpenDiag, the in-kernel real-time radio KPI extraction tool we\nintroduce in this paper, along with our KPI-based accurate bandwidth\ndetermination layer towards dynamically adjusting the congestion window to\noptimally use the available bandwidth while keeping delay to the minimum. Our\nsolution is practical and deployable, as shown through our implementation of\nBiscay and OpenDiag on unrooted Android 5G phones. We extensively evaluate\nBiscay against different state-of-the-art congestion control designs including\nBBR and CUBIC with emulations driven by real measurement traces as well as\nreal-world experiments spanning diverse 4G and 5G scenarios, and show that it\nprovides significant average and tail delay improvements (typically over 90%\nreduction) while yielding better or similar throughput. These gains are enabled\nby 100% improvement in the granularity of on-device radio KPI measurements with\nOpenDiag compared to existing alternatives like MobileInsight."}
{"id": "2509.02732", "pdf": "https://arxiv.org/pdf/2509.02732", "abs": "https://arxiv.org/abs/2509.02732", "authors": ["Mauro Diaz", "Luis Sante", "Joel Perca", "João Victor da Silva", "Nivan Ferreira", "Jorge Poco"], "title": "STRive: An association rule-based system for the exploration of spatiotemporal categorical data", "categories": ["cs.HC"], "comment": null, "summary": "Effectively analyzing spatiotemporal data plays a central role in\nunderstanding real-world phenomena and informing decision-making. Capturing the\ninteraction between spatial and temporal dimensions also helps explain the\nunderlying structure of the data. However, most datasets do not reveal\nattribute relationships, requiring additional algorithms to extract meaningful\npatterns. Existing visualization tools often focus either on attribute\nrelationships or spatiotemporal analysis, but rarely support both\nsimultaneously. In this paper, we present STRive (SpatioTemporal Rule\nInteractive Visual Explorer), a visual analytics system that enables users to\nuncover and explore spatial and temporal patterns in data. At the core of\nSTRive lies Association Rule Mining (ARM), which we apply to spatiotemporal\ndatasets to generate interpretable and actionable insights. We combine ARM with\nmultiple interactive mechanisms to analyze the extracted relationships.\nAssociation rules serve as interpretable guidance mechanisms for visual\nanalytics by highlighting the meaningful aspects of the data that users should\ninvestigate. Our methodology includes three key steps: rule generation, rule\nclustering, and interactive visualization. STRive offers two modes of analysis.\nThe first operates at the rule cluster level and includes four coordinated\nviews, each showing a different facet of a cluster, including its temporal and\nspatial behavior. The second mode mirrors the first but focuses on individual\nrules within a selected cluster. We evaluate the effectiveness of STRive\nthrough two case studies involving real-world datasets -- fatal vehicle\naccidents and urban crime. Results demonstrate the system's ability to support\nthe discovery and analysis of interpretable patterns in complex spatiotemporal\ncontexts."}
{"id": "2509.02767", "pdf": "https://arxiv.org/pdf/2509.02767", "abs": "https://arxiv.org/abs/2509.02767", "authors": ["Benedikt Pittl", "Werner Mach", "Erich Schikuta"], "title": "A Novel IaaS Tax Model as Leverage Towards Green Cloud Computing", "categories": ["cs.DC", "cs.CY", "91-08", "J.1; H.1.m"], "comment": null, "summary": "The cloud computing technology uses datacenters, which require energy. Recent\ntrends show that the required energy for these datacenters will rise over time,\nor at least remain constant. Hence, the scientific community developed\ndifferent algorithms, architectures, and approaches for improving the energy\nefficiency of cloud datacenters, which are summarized under the umbrella term\nGreen Cloud computing. In this paper, we use an economic approach - taxes - for\nreducing the energy consumption of datacenters. We developed a tax model called\nGreenCloud tax, which penalizes energy-inefficient datacenters while fostering\ndatacenters that are energy-efficient. Hence, providers running\nenergy-efficient datacenters are able to offer cheaper prices to consumers,\nwhich consequently leads to a shift of workloads from energy-inefficient\ndatacenters to energy-efficient datacenters. The GreenCloud tax approach was\nimplemented using the simulation environment CloudSim. We applied real data\nsets published in the SPEC benchmark for the executed simulation scenarios,\nwhich we used for evaluating the GreenCloud tax."}
{"id": "2509.02873", "pdf": "https://arxiv.org/pdf/2509.02873", "abs": "https://arxiv.org/abs/2509.02873", "authors": ["Zhantong Qiu", "Mahyar Samani", "Jason Lowe-Power"], "title": "Portable Targeted Sampling Framework Using LLVM", "categories": ["cs.AR"], "comment": null, "summary": "Comprehensive architectural evaluation of full workloads is throttled by slow\nsimulation and per-binary sampling pipelines. We present Nugget, a flexible\nframework for portable sampling across simulators and real hardware, ISAs, and\nlibraries. Nugget operates at the LLVM IR level to perform binary-agnostic\ninterval analysis, then emits lightweight, cross-platform\nexecutables--nuggets--that can be validated on real machines before driving\nsimulation. Across SPEC CPU2017, NPB, and LSMS, Nugget cuts interval-analysis\ncost by orders of magnitude relative to functional simulation (up to ~578X on\nmultithreaded NPB), keeps single-thread overhead low, and enables native-speed\nvalidation of selected samples. Case studies with gem5 show that nuggets\nsupport evaluation of system performance and model accuracy. Nugget makes\nsampling methodology research faster and more portable."}
{"id": "2509.02718", "pdf": "https://arxiv.org/pdf/2509.02718", "abs": "https://arxiv.org/abs/2509.02718", "authors": ["Fangzhou Wu", "Sandeep Silwal"], "title": "Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving", "categories": ["cs.DB"], "comment": "31 pages", "summary": "Increasing demand for Large Language Models (LLMs) services imposes\nsubstantial deployment and computation costs on providers. LLM routing offers a\ncost-efficient solution by directing queries to the optimal LLM based on model\nand query features. However, existing works primarily focus on offline\nscenarios and struggle to adapt to online settings with high query volume and\nconstrained token budgets. In this work, we introduce the first training-free\nalgorithm for online routing scenarios. Our algorithm leverages approximate\nnearest neighbor search to efficiently estimate query features and performs a\none-time optimization over a small set of initial queries to learn a routing\nstrategy that guides future routing. We provide theoretical guarantees\ndemonstrating that our algorithm achieves a competitive ratio of $1 - o(1)$\nunder natural assumptions, which is further validated by extensive experiments\nacross 3 benchmark datasets and 8 baselines, showing an average improvement of\n3.55$\\times$ in overall performance, 1.85$\\times$ in cost efficiency, and\nnearly 4.25$\\times$ in throughput."}
{"id": "2509.03463", "pdf": "https://arxiv.org/pdf/2509.03463", "abs": "https://arxiv.org/abs/2509.03463", "authors": ["Parham Khamsepour", "Mark Cole", "Ish Ashraf", "Sandeep Puri", "Mehrdad Sabetzadeh", "Shiva Nejati"], "title": "The Impact of Critique on LLM-Based Model Generation from Natural Language: The Case of Activity Diagrams", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) show strong potential for automating the\ngeneration of models from natural-language descriptions. A common approach is\nan iterative generate-critique-refine loop, where candidate models are\nproduced, evaluated, and updated based on detected issues. This process needs\nto address: (1) structural correctness - compliance with well-formedness rules\n- and (2) semantic alignment - accurate reflection of the intended meaning in\nthe source text. We present LADEX (LLM-based Activity Diagram Extractor), a\npipeline for deriving activity diagrams from natural-language process\ndescriptions using an LLM-driven critique-refine process. Structural checks in\nLADEX can be performed either algorithmically or by an LLM, while alignment\nchecks are always performed by an LLM. We design five ablated variants of LADEX\nto study: (i) the impact of the critique-refine loop itself, (ii) the role of\nLLM-based semantic checks, and (iii) the comparative effectiveness of\nalgorithmic versus LLM-based structural checks.\n  To evaluate LADEX, we compare the generated activity diagrams with\nexpert-created ground truths using trace-based operational semantics. This\nenables automated measurement of correctness and completeness. Experiments on\ntwo datasets indicate that: (1) the critique-refine loop improves structural\nvalidity, correctness, and completeness compared to single-pass generation; (2)\nalgorithmic structural checks eliminate inconsistencies that LLM-based checks\nfail to detect, improving correctness by an average of 17.81% and completeness\nby 13.24% over LLM-only checks; and (3) combining algorithmic structural checks\nwith LLM-based semantic checks, implemented using the reasoning-focused O4\nMini, achieves the best overall performance - yielding average correctness of\nup to 86.37% and average completeness of up to 88.56% - while requiring fewer\nthan five LLM calls on average."}
{"id": "2509.03451", "pdf": "https://arxiv.org/pdf/2509.03451", "abs": "https://arxiv.org/abs/2509.03451", "authors": ["Nathan DeVrio", "Vimal Mollyn", "Chris Harrison"], "title": "SmartPoser: Arm Pose Estimation with a Smartphone and Smartwatch Using UWB and IMU Data", "categories": ["cs.HC", "cs.CV", "cs.GR", "cs.RO"], "comment": "The first two listed authors contributed equally. Published at UIST\n  2023", "summary": "The ability to track a user's arm pose could be valuable in a wide range of\napplications, including fitness, rehabilitation, augmented reality input, life\nlogging, and context-aware assistants. Unfortunately, this capability is not\nreadily available to consumers. Systems either require cameras, which carry\nprivacy issues, or utilize multiple worn IMUs or markers. In this work, we\ndescribe how an off-the-shelf smartphone and smartwatch can work together to\naccurately estimate arm pose. Moving beyond prior work, we take advantage of\nmore recent ultra-wideband (UWB) functionality on these devices to capture\nabsolute distance between the two devices. This measurement is the perfect\ncomplement to inertial data, which is relative and suffers from drift. We\nquantify the performance of our software-only approach using off-the-shelf\ndevices, showing it can estimate the wrist and elbow joints with a \\hl{median\npositional error of 11.0~cm}, without the user having to provide training data."}
{"id": "2509.02990", "pdf": "https://arxiv.org/pdf/2509.02990", "abs": "https://arxiv.org/abs/2509.02990", "authors": ["Liang Xie", "Wenke Huang"], "title": "Automatically Generating High-Precision Simulated Road Networking in Traffic Scenario", "categories": ["cs.MM"], "comment": "7 pages,11 figures", "summary": "Existing lane-level simulation road network generation is labor-intensive,\nresource-demanding, and costly due to the need for large-scale data collection\nand manual post-editing. To overcome these limitations, we propose\nautomatically generating high-precision simulated road networks in traffic\nscenario, an efficient and fully automated solution. Initially, real-world road\nstreet view data is collected through open-source street view map platforms,\nand a large-scale street view lane line dataset is constructed to provide a\nrobust foundation for subsequent analysis. Next, an end-to-end lane line\ndetection approach based on deep learning is designed, where a neural network\nmodel is trained to accurately detect the number and spatial distribution of\nlane lines in street view images, enabling automated extraction of lane\ninformation. Subsequently, by integrating coordinate transformation and map\nmatching algorithms, the extracted lane information from street views is fused\nwith the foundational road topology obtained from open-source map service\nplatforms, resulting in the generation of a high-precision lane-level\nsimulation road network. This method significantly reduces the costs associated\nwith data collection and manual editing while enhancing the efficiency and\naccuracy of simulation road network generation. It provides reliable data\nsupport for urban traffic simulation, autonomous driving navigation, and the\ndevelopment of intelligent transportation systems, offering a novel technical\npathway for the automated modeling of large-scale urban road networks."}
{"id": "2509.03263", "pdf": "https://arxiv.org/pdf/2509.03263", "abs": "https://arxiv.org/abs/2509.03263", "authors": ["David Cortes", "Carlos Juiz", "Belen Bermejo"], "title": "Estudio de la eficiencia en la escalabilidad de GPUs para el entrenamiento de Inteligencia Artificial", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "8 pages, in Spanish language, 8 figures, Conference at SARTECO 2025,\n  Spain", "summary": "Training large-scale deep learning models has become a key challenge for the\nscientific community and industry. While the massive use of GPUs can\nsignificantly speed up training times, this approach has a negative impact on\nefficiency. In this article, we present a detailed analysis of the times\nreported by MLPerf Training v4.1 on four workloads: BERT, Llama2 LoRA,\nRetinaNet, and Stable Diffusion, showing that there are configurations that\noptimise the relationship between performance, GPU usage, and efficiency. The\nresults point to a break-even point that allows training times to be reduced\nwhile maximising efficiency."}
{"id": "2509.02860", "pdf": "https://arxiv.org/pdf/2509.02860", "abs": "https://arxiv.org/abs/2509.02860", "authors": ["Connor Wojtak", "Darek Gajewski", "Tomas Cerny"], "title": "Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems", "categories": ["cs.SE", "cs.LO"], "comment": "Accepted at MODELS 2025", "summary": "Microservice systems are becoming increasingly adopted due to their\nscalability, decentralized development, and support for continuous integration\nand delivery (CI/CD). However, this decentralized development by separate teams\nand continuous evolution can introduce miscommunication and incompatible\nimplementations, undermining system maintainability and reliability across\naspects from security policy to system architecture. We propose a novel\nmethodology that statically reconstructs microservice source code into a formal\nsystem model. From this model, a Satisfiability Modulo Theories (SMT)\nconstraint set can be derived, enabling formal verification. Our methodology is\nextensible, supporting software verification across multiple cross-cutting\nconcerns. We focus on applying the methodology to verify the system\narchitecture concern, presenting formal reasoning to validate the methodology's\ncorrectness and applicability for this concern. Additional concerns such as\nsecurity policy implementation are considered. Future directions are\nestablished to extend and evaluate the methodology."}
{"id": "2509.02958", "pdf": "https://arxiv.org/pdf/2509.02958", "abs": "https://arxiv.org/abs/2509.02958", "authors": ["Kaustuv Mukherji", "Jaikrishna Manojkumar Patil", "Dyuman Aditya", "Paulo Shakarian", "Devendra Parkar", "Lahari Pokala", "Clark Dorman", "Gerardo I. Simari"], "title": "Lattice Annotated Temporal (LAT) Logic for Non-Markovian Reasoning", "categories": ["cs.LO", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "We introduce Lattice Annotated Temporal (LAT) Logic, an extension of\nGeneralized Annotated Logic Programs (GAPs) that incorporates temporal\nreasoning and supports open-world semantics through the use of a lower lattice\nstructure. This logic combines an efficient deduction process with temporal\nlogic programming to support non-Markovian relationships and open-world\nreasoning capabilities. The open-world aspect, a by-product of the use of the\nlower-lattice annotation structure, allows for efficient grounding through a\nSkolemization process, even in domains with infinite or highly diverse\nconstants.\n  We provide a suite of theoretical results that bound the computational\ncomplexity of the grounding process, in addition to showing that many of the\nresults on GAPs (using an upper lattice) still hold with the lower lattice and\ntemporal extensions (though different proof techniques are required). Our\nopen-source implementation, PyReason, features modular design, machine-level\noptimizations, and direct integration with reinforcement learning environments.\nEmpirical evaluations across multi-agent simulations and knowledge graph tasks\ndemonstrate up to three orders of magnitude speedup and up to five orders of\nmagnitude memory reduction while maintaining or improving task performance.\nAdditionally, we evaluate LAT Logic's value in reinforcement learning\nenvironments as a non-Markovian simulator, achieving up to three orders of\nmagnitude faster simulation with improved agent performance, including a 26%\nincrease in win rate due to capturing richer temporal dependencies. These\nresults highlight LAT Logic's potential as a unified, extensible framework for\nopen-world temporal reasoning in dynamic and uncertain environments. Our\nimplementation is available at: pyreason.syracuse.edu."}
{"id": "2509.02909", "pdf": "https://arxiv.org/pdf/2509.02909", "abs": "https://arxiv.org/abs/2509.02909", "authors": ["Gaurav Gaur", "Barun Gorain", "Rishi Ranjan Singh", "Daya Gaur"], "title": "Treasure Hunt in Anonymous Graphs with Quantum Pebbles by Oblivious Agents", "categories": ["quant-ph", "cs.DC", "cs.DS", "cs.ET"], "comment": null, "summary": "We investigate the problem of finding a static treasure in anonymous graphs\nusing oblivious agents and introduce a novel approach that leverages quantum\ninformation. In anonymous graphs, vertices are unlabelled, indistinguishable,\nand edges are locally labelled with port numbers. Agents typically rely on\nstationary classical pebbles placed by an oracle to guide their search.\nHowever, this classical approach is constrained by limited information\ntransmission and high traversal complexity. Classical pebbles are not\nsufficient for search if the agents are oblivious. We propose the first use of\nquantum pebbles for search in anonymous graphs. Quantum pebbles periodically\nemit qubits in a fixed quantum state. Each pebble encodes the port number to\nthe next node using a unique quantum state. The agent determines the correct\npath by performing measurements in multiple bases, exploiting the probabilistic\nnature of quantum measurement to distinguish states. We show that this strategy\nenables an oblivious agent to locate the treasure in $D$ steps using $D$\nquantum pebbles, where $D$ is the length of the shortest path between the\nstarting point and the treasure. Moreover, only $O((\\log D + \\log \\Delta)/(\\log\n1/\\delta))$ measurements per node are required to ensure high success\nprobability in a graph with maximum degree $\\Delta$ where $\\delta =\n\\cos^2(\\frac{\\pi}{2\\Delta})$. We propose the use of quantum information as a\nguidance mechanism in anonymous graph search. We demonstrate that quantum\npebbles can not only emulate the functionality of classical pebbles but can do\nso with improved efficiency, offering a promising direction for future\nquantum-enhanced distributed algorithms."}
{"id": "2509.02811", "pdf": "https://arxiv.org/pdf/2509.02811", "abs": "https://arxiv.org/abs/2509.02811", "authors": ["Alessandro Traspadini", "Michele Zorzi", "Marco Giordani"], "title": "Performance Evaluation of LoRa for IoT Applications in Non-Terrestrial Networks via ns-3", "categories": ["cs.NI"], "comment": "6 pages, 4 figures, 2 tables. Accepted for publication in the 2025\n  IEEE Global Communications Conference (GLOBECOM) \\c{opyright}2025 IEEE. A.\n  Traspadini, M. Zorzi, and M. Giordani \"Performance Evaluation of LoRa for IoT\n  Applications in Non-Terrestrial Networks via ns-3,\" in Proc. IEEE Global\n  Communications Conference (GLOBECOM), 2025", "summary": "The integration of Internet of Things (IoT) and Non-Terrestrial Networks\n(NTNs) has emerged as a key paradigm to provide connectivity for sensors and\nactuators via satellite gateways in remote areas where terrestrial\ninfrastructure is limited or unavailable. Among other Low-Power Wide-Area\nNetwork (LPWAN) technologies for IoT, Long Range (LoRa) holds great potential\ngiven its long range, energy efficiency, and flexibility. In this paper, we\nexplore the feasibility and performance of LoRa to support large-scale IoT\nconnectivity through Low Earth Orbit (LEO) satellite gateways. To do so, we\ndeveloped a new ns3-LoRa-NTN simulation module, which integrates and extends\nthe ns3-LoRa and ns3-NTN modules, to enable full-stack end-to-end simulation of\nsatellite communication in LoRa networks. Our results, given in terms of\naverage data rate and Packet Reception Ratio (PRR), confirm that LoRa can\neffectively support direct communication from the ground to LEO satellites, but\nnetwork optimization is required to mitigate collision probability when end\nnodes use the same Spreading Factors (SFs) over long distances."}
{"id": "2509.02878", "pdf": "https://arxiv.org/pdf/2509.02878", "abs": "https://arxiv.org/abs/2509.02878", "authors": ["Ratanond Koonchanok", "Alex Kale", "Khairi Reda"], "title": "Designing a Lightweight GenAI Interface for Visual Data Analysis", "categories": ["cs.HC"], "comment": null, "summary": "Recent advances in Generative AI have transformed how users interact with\ndata analysis through natural language interfaces. However, many systems rely\ntoo heavily on LLMs, creating risks of hallucination, opaque reasoning, and\nreduced user control. We present a hybrid visual analysis system that\nintegrates GenAI in a constrained, high-level role to support statistical\nmodeling while preserving transparency and user agency. GenAI translates\nnatural language intent into formal statistical formulations, while interactive\nvisualizations surface model behavior, residual patterns, and hypothesis\ncomparisons to guide iterative exploration. Model fitting, diagnostics, and\nhypothesis testing are delegated entirely to a structured R-based backend,\nensuring correctness, interpretability, and reproducibility. By combining\nGenAI-assisted intent translation with visualization-driven reasoning, our\napproach broadens access to modeling tools without compromising rigor. We\npresent an example use case of the tool and discuss challenges and\nopportunities for future research."}
{"id": "2509.03018", "pdf": "https://arxiv.org/pdf/2509.03018", "abs": "https://arxiv.org/abs/2509.03018", "authors": ["Yangtao Deng", "Lei Zhang", "Qinlong Wang", "Xiaoyun Zhi", "Xinlei Zhang", "Zhuo Jiang", "Haohan Xu", "Lei Wang", "Zuquan Song", "Gaohong Liu", "Yang Bai", "Shuguang Wang", "Wencong Xiao", "Jianxi Ye", "Minlan Yu", "Hong Xu"], "title": "Mycroft: Tracing Dependencies in Collective Communication Towards Reliable LLM Training", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Reliability is essential for ensuring efficiency in LLM training. However,\nmany real-world reliability issues remain difficult to resolve, resulting in\nwasted resources and degraded model performance. Unfortunately, today's\ncollective communication libraries operate as black boxes, hiding critical\ninformation needed for effective root cause analysis. We propose Mycroft, a\nlightweight distributed tracing and root cause analysis system designed to\naddress previously hidden reliability issues in collective communication.\nMycroft's key idea is to trace collective communication states and leverage\ninternal control and data dependencies to resolve reliability problems in LLM\ntraining. Mycroft has been deployed at ByteDance for over six months to debug\ncollective communication related issues at runtime. It detected anomalies\nwithin 15 seconds in 90% of cases and identified the root cause within 20\nseconds in 60% of cases. We also conducted extensive fault injection\nexperiments to demonstrate Mycroft's capability and efficiency."}
{"id": "2509.03103", "pdf": "https://arxiv.org/pdf/2509.03103", "abs": "https://arxiv.org/abs/2509.03103", "authors": ["Abdul Rahoof", "Vivek Chaturvedi", "Muhammad Shafique"], "title": "FastCaps: A Design Methodology for Accelerating Capsule Network on Field Programmable Gate Arrays", "categories": ["cs.AR"], "comment": "2023 International Joint Conference on Neural Networks (IJCNN)", "summary": "Capsule Network (CapsNet) has shown significant improvement in understanding\nthe variation in images along with better generalization ability compared to\ntraditional Convolutional Neural Network (CNN). CapsNet preserves spatial\nrelationship among extracted features and apply dynamic routing to efficiently\nlearn the internal connections between capsules. However, due to the capsule\nstructure and the complexity of the routing mechanism, it is non-trivial to\naccelerate CapsNet performance in its original form on Field Programmable Gate\nArray (FPGA). Most of the existing works on CapsNet have achieved limited\nacceleration as they implement only the dynamic routing algorithm on FPGA,\nwhile considering all the processing steps synergistically is important for\nreal-world applications of Capsule Networks. Towards this, we propose a novel\ntwo-step approach that deploys a full-fledged CapsNet on FPGA. First, we prune\nthe network using a novel Look-Ahead Kernel Pruning (LAKP) methodology that\nuses the sum of look-ahead scores of the model parameters. Next, we simplify\nthe nonlinear operations, reorder loops, and parallelize operations of the\nrouting algorithm to reduce CapsNet hardware complexity. To the best of our\nknowledge, this is the first work accelerating a full-fledged CapsNet on FPGA.\nExperimental results on the MNIST and F-MNIST datasets (typical in Capsule\nNetwork community) show that the proposed LAKP approach achieves an effective\ncompression rate of 99.26% and 98.84%, and achieves a throughput of 82 FPS and\n48 FPS on Xilinx PYNQ-Z1 FPGA, respectively. Furthermore, reducing the hardware\ncomplexity of the routing algorithm increases the throughput to 1351 FPS and\n934 FPS respectively. As corroborated by our results, this work enables highly\nperformance-efficient deployment of CapsNets on low-cost FPGA that are popular\nin modern edge devices."}
{"id": "2509.02896", "pdf": "https://arxiv.org/pdf/2509.02896", "abs": "https://arxiv.org/abs/2509.02896", "authors": ["Sepanta Zeighami", "Shreya Shankar", "Aditya Parameswaran"], "title": "Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees", "categories": ["cs.DB", "cs.AI"], "comment": "To appear in SIGMOD'26", "summary": "Large Language Models (LLMs) are being increasingly used as a building block\nin data systems to process large text datasets. To do so, LLM model providers\noffer multiple LLMs with different sizes, spanning various cost-quality\ntrade-offs when processing text at scale. Top-of-the-line LLMs (e.g., GPT-4o,\nClaude Sonnet) operate with high accuracy but are prohibitively expensive when\nprocessing many records. To avoid high costs, more affordable but lower quality\nLLMs (e.g., GPT-4o-mini, Claude Haiku) can be used to process records, but we\nneed to ensure that the overall accuracy does not deviate substantially from\nthat of the top-of-the-line LLMs. The model cascade framework provides a\nblueprint to manage this trade-off, by using the confidence of LLMs in their\noutput (e.g., log-probabilities) to decide on which records to use the\naffordable LLM. However, existing solutions following this framework provide\nonly marginal cost savings and weak theoretical guarantees because of poor\nestimation of the quality of the affordable LLM's outputs. We present BARGAIN,\na method that judiciously uses affordable LLMs in data processing to\nsignificantly reduce cost while providing strong theoretical guarantees on the\nsolution quality. BARGAIN employs a novel adaptive sampling strategy and\nstatistical estimation procedure that uses data and task characteristics and\nbuilds on recent statistical tools to make accurate estimations with tight\ntheoretical guarantees. Variants of BARGAIN can support guarantees on accuracy,\nprecision, or recall of the output. Experimental results across 8 real-world\ndatasets show that BARGAIN reduces cost, on average, by up to 86% more than\nstate-of-the-art, while providing stronger theoretical guarantees on accuracy\nof output, with similar gains when guaranteeing a desired level of precision or\nrecall."}
{"id": "2509.03037", "pdf": "https://arxiv.org/pdf/2509.03037", "abs": "https://arxiv.org/abs/2509.03037", "authors": ["Shuzheng Wang", "Yue Huang", "Zhuoer Xu", "Yuming Huang", "Jing Tang"], "title": "TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum", "categories": ["cs.CR", "cs.ET", "cs.SE"], "comment": null, "summary": "Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet\ncomprehensive security analysis remains difficult due to unverified code,\nproxy-based architectures, and the reliance on manual inspection of complex\nexecution traces. Existing approaches fall into two main categories: anomaly\ntransaction detection, which flags suspicious transactions but offers limited\ninsight into specific attack strategies hidden in execution traces inside\ntransactions, and code vulnerability detection, which cannot analyze unverified\ncontracts and struggles to show how identified flaws are exploited in real\nincidents. As a result, analysts must still manually align transaction traces\nwith contract code to reconstruct attack scenarios and conduct forensics. To\naddress this gap, TraceLLM is proposed as a framework that leverages LLMs to\nintegrate execution trace-level detection with decompiled contract code. We\nintroduce a new anomaly execution path identification algorithm and an\nLLM-refined decompile tool to identify vulnerable functions and provide\nexplicit attack paths to LLM. TraceLLM establishes the first benchmark for\njoint trace and contract code-driven security analysis. For comparison, proxy\nbaselines are created by jointly transmitting the results of three\nrepresentative code analysis along with raw traces to LLM. TraceLLM identifies\nattacker and victim addresses with 85.19\\% precision and produces automated\nreports with 70.37\\% factual precision across 27 cases with ground truth expert\nreports, achieving 25.93\\% higher accuracy than the best baseline. Moreover,\nacross 148 real-world Ethereum incidents, TraceLLM automatically generates\nreports with 66.22\\% expert-verified accuracy, demonstrating strong\ngeneralizability."}
{"id": "2509.02969", "pdf": "https://arxiv.org/pdf/2509.02969", "abs": "https://arxiv.org/abs/2509.02969", "authors": ["Dasong Li", "Sizhuo Ma", "Hang Hua", "Wenjie Li", "Jian Wang", "Chris Wei Zhou", "Fengbin Guan", "Xin Li", "Zihao Yu", "Yiting Lu", "Ru-Ling Liao", "Yan Ye", "Zhibo Chen", "Wei Sun", "Linhan Cao", "Yuqin Cao", "Weixia Zhang", "Wen Wen", "Kaiwei Zhang", "Zijian Chen", "Fangfang Lu", "Xiongkuo Min", "Guangtao Zhai", "Erjia Xiao", "Lingfeng Zhang", "Zhenjie Su", "Hao Cheng", "Yu Liu", "Renjing Xu", "Long Chen", "Xiaoshuai Hao", "Zhenpeng Zeng", "Jianqin Wu", "Xuxu Wang", "Qian Yu", "Bo Hu", "Weiwei Wang", "Pinxin Liu", "Yunlong Tang", "Luchuan Song", "Jinxi He", "Jiaru Wu", "Hanjia Lyu"], "title": "VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results", "categories": ["cs.CV", "cs.MM", "cs.SI"], "comment": "ICCV 2025 VQualA workshop EVQA track", "summary": "This paper presents an overview of the VQualA 2025 Challenge on Engagement\nPrediction for Short Videos, held in conjunction with ICCV 2025. The challenge\nfocuses on understanding and modeling the popularity of user-generated content\n(UGC) short videos on social media platforms. To support this goal, the\nchallenge uses a new short-form UGC dataset featuring engagement metrics\nderived from real-world user interactions. This objective of the Challenge is\nto promote robust modeling strategies that capture the complex factors\ninfluencing user engagement. Participants explored a variety of multi-modal\nfeatures, including visual content, audio, and metadata provided by creators.\nThe challenge attracted 97 participants and received 15 valid test submissions,\ncontributing significantly to progress in short-form UGC video engagement\nprediction."}
{"id": "2509.03394", "pdf": "https://arxiv.org/pdf/2509.03394", "abs": "https://arxiv.org/abs/2509.03394", "authors": ["Amirhossein Shahbazinia", "Darong Huang", "Luis Costero", "David Atienza"], "title": "CloudFormer: An Attention-based Performance Prediction for Public Clouds with Unknown Workload", "categories": ["cs.DC", "cs.LG", "cs.PF"], "comment": null, "summary": "Cloud platforms are increasingly relied upon to host diverse,\nresource-intensive workloads due to their scalability, flexibility, and\ncost-efficiency. In multi-tenant cloud environments, virtual machines are\nconsolidated on shared physical servers to improve resource utilization. While\nvirtualization guarantees resource partitioning for CPU, memory, and storage,\nit cannot ensure performance isolation. Competition for shared resources such\nas last-level cache, memory bandwidth, and network interfaces often leads to\nsevere performance degradation. Existing management techniques, including VM\nscheduling and resource provisioning, require accurate performance prediction\nto mitigate interference. However, this remains challenging in public clouds\ndue to the black-box nature of VMs and the highly dynamic nature of workloads.\nTo address these limitations, we propose CloudFormer, a dual-branch\nTransformer-based model designed to predict VM performance degradation in\nblack-box environments. CloudFormer jointly models temporal dynamics and\nsystem-level interactions, leveraging 206 system metrics at one-second\nresolution across both static and dynamic scenarios. This design enables the\nmodel to capture transient interference effects and adapt to varying workload\nconditions without scenario-specific tuning. Complementing the methodology, we\nprovide a fine-grained dataset that significantly expands the temporal\nresolution and metric diversity compared to existing benchmarks. Experimental\nresults demonstrate that CloudFormer consistently outperforms state-of-the-art\nbaselines across multiple evaluation metrics, achieving robust generalization\nacross diverse and previously unseen workloads. Notably, CloudFormer attains a\nmean absolute error (MAE) of just 7.8%, representing a substantial improvement\nin predictive accuracy and outperforming existing methods at least by 28%."}
{"id": "2509.03249", "pdf": "https://arxiv.org/pdf/2509.03249", "abs": "https://arxiv.org/abs/2509.03249", "authors": ["Daniel Raggi", "Gem Stapleton", "Mateja Jamnik", "Aaron Stockdill", "Grecia Garcia Garcia", "Peter C-H. Cheng"], "title": "Structure Transfer: an Inference-Based Calculus for the Transformation of Representations", "categories": ["cs.LG", "cs.AI", "cs.LO", "03-08", "D.3.1; F.4.1; F.4.1"], "comment": null, "summary": "Representation choice is of fundamental importance to our ability to\ncommunicate and reason effectively. A major unsolved problem, addressed in this\npaper, is how to devise \\textit{representational-system (RS) agnostic}\ntechniques that drive representation transformation and choice. We present a\nnovel calculus, called \\textit{structure transfer}, that enables representation\ntransformation across diverse RSs. Specifically, given a \\textit{source}\nrepresentation drawn from a source RS, the rules of structure transfer allow us\nto generate a \\textit{target} representation for a target RS. The generality of\nstructure transfer comes in part from its ability to ensure that the source\nrepresentation and the generated target representation satisfy \\textit{any}\nspecified relation (such as semantic equivalence). This is done by exploiting\n\\textit{schemas}, which encode knowledge about RSs. Specifically, schemas can\nexpress \\textit{preservation of information} across relations between any pair\nof RSs, and this knowledge is used by structure transfer to derive a structure\nfor the target representation which ensures that the desired relation holds. We\nformalise this using Representational Systems Theory~\\cite{raggi2022rst},\nbuilding on the key concept of a \\textit{construction space}. The abstract\nnature of construction spaces grants them the generality to model RSs of\ndiverse kinds, including formal languages, geometric figures and diagrams, as\nwell as informal notations. Consequently, structure transfer is a\nsystem-agnostic calculus that can be used to identify alternative\nrepresentations in a wide range of practical settings."}
{"id": "2509.02920", "pdf": "https://arxiv.org/pdf/2509.02920", "abs": "https://arxiv.org/abs/2509.02920", "authors": ["Jaliya L. Wijayaraja", "Janaka L. Wijekoon", "Malitha Wijesundara"], "title": "Event Detection and Classification for Long Range Sensing of Elephants Using Seismic Signal", "categories": ["cs.LG", "cs.CY", "cs.ET", "cs.SY", "eess.SY"], "comment": "This article has been accepted for publication in IEEE Access", "summary": "Detecting elephants through seismic signals is an emerging research topic\naimed at developing solutions for Human-Elephant Conflict (HEC). Despite the\npromising results, such solutions heavily rely on manual classification of\nelephant footfalls, which limits their applicability for real-time\nclassification in natural settings. To address this limitation and build on our\nprevious work, this study introduces a classification framework targeting\nresource-constrained implementations, prioritizing both accuracy and\ncomputational efficiency. As part of this framework, a novel event detection\ntechnique named Contextually Customized Windowing (CCW), tailored specifically\nfor detecting elephant footfalls, was introduced, and evaluations were\nconducted by comparing it with the Short-Term Average/Long-Term Average\n(STA/LTA) method. The yielded results show that the maximum validated detection\nrange was 155.6 m in controlled conditions and 140 m in natural environments.\nElephant footfall classification using Support Vector Machine (SVM) with a\nRadial Basis Function (RBF) kernel demonstrated superior performance across\nmultiple settings, achieving an accuracy of 99% in controlled environments, 73%\nin natural elephant habitats, and 70% in HEC-prone human habitats, the most\nchallenging scenario. Furthermore, feature impact analysis using explainable AI\nidentified the number of Zero Crossings and Dynamic Time Warping (DTW)\nAlignment Cost as the most influential factors in all experiments, while\nPredominant Frequency exhibited significant influence in controlled settings."}
{"id": "2509.02824", "pdf": "https://arxiv.org/pdf/2509.02824", "abs": "https://arxiv.org/abs/2509.02824", "authors": ["Yilu Dong", "Tianchang Yang", "Arupjyoti Bhuyan", "Syed Rafiul Hussain"], "title": "GPS Spoofing Attacks on Automated Frequency Coordination System in Wi-Fi 6E and Beyond", "categories": ["cs.NI", "cs.CR", "C.2.1"], "comment": "6 pages, 4 figures, to be published in European Wireless 2025", "summary": "The 6 GHz spectrum, recently opened for unlicensed use under Wi-Fi 6E and\nWi-Fi 7, overlaps with frequencies used by mission-critical incumbent systems\nsuch as public safety communications and utility infrastructure. To prevent\ninterference, the FCC mandates the use of Automated Frequency Coordination\n(AFC) systems, which assign safe frequency and power levels based on Wi-Fi\nAccess Point (AP)-reported locations. In this work, we demonstrate that\nGPS-based location reporting, which Wi-Fi APs use, can be spoofed using\ninexpensive, off-the-shelf radio equipment. This enables attackers to\nmanipulate AP behavior, gain unauthorized spectrum access, cause harmful\ninterference, or disable APs entirely by spoofing them into foreign locations.\nWe validate these attacks in a controlled lab setting against a commercial AP\nand evaluate a commercial AFC system under spoofed scenarios. Our findings\nhighlight critical gaps in the security assumptions of AFC and motivate the\nneed for stronger location integrity protections."}
{"id": "2509.02910", "pdf": "https://arxiv.org/pdf/2509.02910", "abs": "https://arxiv.org/abs/2509.02910", "authors": ["Sandra C. Matz", "C. Blaine Horton", "Sofie Goethals"], "title": "The Basic B*** Effect: The Use of LLM-based Agents Reduces the Distinctiveness and Diversity of People's Choices", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) increasingly act on people's behalf: they write\nemails, buy groceries, and book restaurants. While the outsourcing of human\ndecision-making to AI can be both efficient and effective, it raises a\nfundamental question: how does delegating identity-defining choices to AI\nreshape who people become? We study the impact of agentic LLMs on two\nidentity-relevant outcomes: interpersonal distinctiveness - how unique a\nperson's choices are relative to others - and intrapersonal diversity - the\nbreadth of a single person's choices over time. Using real choices drawn from\nsocial-media behavior of 1,000 U.S. users (110,000 choices in total), we\ncompare a generic and personalized agent to a human baseline. Both agents shift\npeople's choices toward more popular options, reducing the distinctiveness of\ntheir behaviors and preferences. While the use of personalized agents tempers\nthis homogenization (compared to the generic AI), it also more strongly\ncompresses the diversity of people's preference portfolios by narrowing what\nthey explore across topics and psychological affinities. Understanding how AI\nagents might flatten human experience, and how using generic versus\npersonalized agents involves distinctiveness-diversity trade-offs, is critical\nfor designing systems that augment rather than constrain human agency, and for\nsafeguarding diversity in thought, taste, and expression."}
{"id": "2509.03047", "pdf": "https://arxiv.org/pdf/2509.03047", "abs": "https://arxiv.org/abs/2509.03047", "authors": ["Haijun Zhang", "Jinxiang Wang", "Zhenhua Yu", "Yanyong Zhang", "Xuejie Ji", "Kaining Mao", "Jun Zhang", "Yaqing Zhang", "Ting Wu", "Fei Jie", "Xiemin Huang", "Zhifang Cai", "Junhua Cheng", "Shuwei Wang", "Wei Li", "Xiaoming Bao", "Hua Xu", "Shixiong Zhao", "Jun Li", "Hongwei Sun", "Ziyang Zhang", "Yi Xiong", "Chunsheng Li"], "title": "FlashRecovery: Fast and Low-Cost Recovery from Failures for Large-Scale Training of LLMs", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have made a profound impact across various\nfields due to their advanced capabilities. However, training these models at\nunprecedented scales requires extensive AI accelerator clusters and\nsophisticated parallelism strategies, which pose significant challenges in\nmaintaining system reliability over prolonged training periods. A major concern\nis the substantial loss of training time caused by inevitable hardware and\nsoftware failures. To address these challenges, we present FlashRecovery, a\nfast and low-cost failure recovery system comprising three core modules: (1)\nActive and real-time failure detection. This module performs continuous\ntraining state monitoring, enabling immediate identification of hardware and\nsoftware failures within seconds, thus ensuring rapid incident response; (2)\nScale-independent task restart. By employing different recovery strategies for\nnormal and faulty nodes, combined with an optimized communication group\nreconstruction protocol, our approach ensures that the recovery time remains\nnearly constant, regardless of cluster scale; (3) Checkpoint-free recovery\nwithin one step. Our novel recovery mechanism enables single-step restoration,\ncompletely eliminating dependence on traditional checkpointing methods and\ntheir associated overhead. Collectively, these innovations enable FlashRecovery\nto achieve optimal Recovery Time Objective (RTO) and Recovery Point Objective\n(RPO), substantially improving the reliability and efficiency of long-duration\nLLM training. Experimental results demonstrate that FlashRecovery system can\nachieve training restoration on training cluster with 4, 800 devices in 150\nseconds. We also verify that the time required for failure recovery is nearly\nconsistent for different scales of training tasks."}
{"id": "2509.03201", "pdf": "https://arxiv.org/pdf/2509.03201", "abs": "https://arxiv.org/abs/2509.03201", "authors": ["Abdul Rahoof", "Vivek Chaturvedi", "Mahesh Raveendranatha Panicker", "Muhammad Shafique"], "title": "CapsBeam: Accelerating Capsule Network based Beamformer for Ultrasound Non-Steered Plane Wave Imaging on Field Programmable Gate Array", "categories": ["cs.AR"], "comment": null, "summary": "In recent years, there has been a growing trend in accelerating\ncomputationally complex non-real-time beamforming algorithms in ultrasound\nimaging using deep learning models. However, due to the large size and\ncomplexity these state-of-the-art deep learning techniques poses significant\nchallenges when deploying on resource-constrained edge devices. In this work,\nwe propose a novel capsule network based beamformer called CapsBeam, designed\nto operate on raw radio-frequency data and provide an envelope of beamformed\ndata through non-steered plane wave insonification. Experiments on in-vivo\ndata, CapsBeam reduced artifacts compared to the standard Delay-and-Sum (DAS)\nbeamforming. For in-vitro data, CapsBeam demonstrated a 32.31% increase in\ncontrast, along with gains of 16.54% and 6.7% in axial and lateral resolution\ncompared to the DAS. Similarly, in-silico data showed a 26% enhancement in\ncontrast, along with improvements of 13.6% and 21.5% in axial and lateral\nresolution, respectively, compared to the DAS. To reduce the parameter\nredundancy and enhance the computational efficiency, we pruned the model using\nour multi-layer LookAhead Kernel Pruning (LAKP-ML) methodology, achieving a\ncompression ratio of 85% without affecting the image quality. Additionally, the\nhardware complexity of the proposed model is reduced by applying quantization,\nsimplification of non-linear operations, and parallelizing operations. Finally,\nwe proposed a specialized accelerator architecture for the pruned and optimized\nCapsBeam model, implemented on a Xilinx ZU7EV FPGA. The proposed accelerator\nachieved a throughput of 30 GOPS for the convolution operation and 17.4 GOPS\nfor the dynamic routing operation."}
{"id": "2509.03102", "pdf": "https://arxiv.org/pdf/2509.03102", "abs": "https://arxiv.org/abs/2509.03102", "authors": ["Wenrui Zhou", "Qiyu Liu", "Jingshu Peng", "Aoqian Zhang", "Lei Chen"], "title": "CARPO: Leveraging Listwise Learning-to-Rank for Context-Aware Query Plan Optimization", "categories": ["cs.DB"], "comment": null, "summary": "Efficient data processing is increasingly vital, with query optimizers\nplaying a fundamental role in translating SQL queries into optimal execution\nplans. Traditional cost-based optimizers, however, often generate suboptimal\nplans due to flawed heuristics and inaccurate cost models, leading to the\nemergence of Learned Query Optimizers (LQOs). To address challenges in existing\nLQOs, such as the inconsistency and suboptimality inherent in pairwise ranking\nmethods, we introduce CARPO, a generic framework leveraging listwise\nlearning-to-rank for context-aware query plan optimization. CARPO distinctively\nemploys a Transformer-based model for holistic evaluation of candidate plan\nsets and integrates a robust hybrid decision mechanism, featuring\nOut-Of-Distribution (OOD) detection with a top-$k$ fallback strategy to ensure\nreliability. Furthermore, CARPO can be seamlessly integrated with existing plan\nembedding techniques, demonstrating strong adaptability. Comprehensive\nexperiments on TPC-H and STATS benchmarks demonstrate that CARPO significantly\noutperforms both native PostgreSQL and Lero, achieving a Top-1 Rate of\n\\textbf{74.54\\%} on the TPC-H benchmark compared to Lero's 3.63\\%, and reducing\nthe total execution time to 3719.16 ms compared to PostgreSQL's 22577.87 ms."}
{"id": "2509.03242", "pdf": "https://arxiv.org/pdf/2509.03242", "abs": "https://arxiv.org/abs/2509.03242", "authors": ["Gianmarco De Vita", "Nargiz Humbatova", "Paolo Tonella"], "title": "TopoMap: A Feature-based Semantic Discriminator of the Topographical Regions in the Test Input Space", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "Testing Deep Learning (DL)-based systems is an open challenge. Although it is\nrelatively easy to find inputs that cause a DL model to misbehave, the grouping\nof inputs by features that make the DL model under test fail is largely\nunexplored. Existing approaches for DL testing introduce perturbations that may\nfocus on specific failure-inducing features, while neglecting others that\nbelong to different regions of the feature space. In this paper, we create an\nexplicit topographical map of the input feature space. Our approach, named\nTopoMap, is both black-box and model-agnostic as it relies solely on features\nthat characterise the input space. To discriminate the inputs according to the\nspecific features they share, we first apply dimensionality reduction to obtain\ninput embeddings, which are then subjected to clustering. Each DL model might\nrequire specific embedding computations and clustering algorithms to achieve a\nmeaningful separation of inputs into discriminative groups. We propose a novel\nway to evaluate alternative configurations of embedding and clustering\ntechniques. We used a deep neural network (DNN) as an approximation of a human\nevaluator who could tell whether a pair of clusters can be discriminated based\non the features of the included elements. We use such a DNN to automatically\nselect the optimal topographical map of the inputs among all those that are\nproduced by different embedding/clustering configurations. The evaluation\nresults show that the maps generated by TopoMap consist of distinguishable and\nmeaningful regions. In addition, we evaluate the effectiveness of TopoMap using\nmutation analysis. In particular, we assess whether the clusters in our\ntopographical map allow for an effective selection of mutation-killing inputs.\nExperimental results show that our approach outperforms random selection by 35%\non average on killable mutants; by 61% on non-killable ones."}
{"id": "2509.03409", "pdf": "https://arxiv.org/pdf/2509.03409", "abs": "https://arxiv.org/abs/2509.03409", "authors": ["Hoan My Tran", "Damien Lolive", "Aghilas Sini", "Arnaud Delhay", "Pierre-François Marteau", "David Guennec"], "title": "Multi-level SSL Feature Gating for Audio Deepfake Detection", "categories": ["cs.SD", "cs.AI", "cs.MM", "I.2.7"], "comment": "This paper has been accepted by ACM MM 2025", "summary": "Recent advancements in generative AI, particularly in speech synthesis, have\nenabled the generation of highly natural-sounding synthetic speech that closely\nmimics human voices. While these innovations hold promise for applications like\nassistive technologies, they also pose significant risks, including misuse for\nfraudulent activities, identity theft, and security threats. Current research\non spoofing detection countermeasures remains limited by generalization to\nunseen deepfake attacks and languages. To address this, we propose a gating\nmechanism extracting relevant feature from the speech foundation XLS-R model as\na front-end feature extractor. For downstream back-end classifier, we employ\nMulti-kernel gated Convolution (MultiConv) to capture both local and global\nspeech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as\na similarity metric to enforce diversity in learned features across different\nMultiConv layers. By integrating CKA with our gating mechanism, we hypothesize\nthat each component helps improving the learning of distinct synthetic speech\npatterns. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance on in-domain benchmarks while generalizing\nrobustly to out-of-domain datasets, including multilingual speech samples. This\nunderscores its potential as a versatile solution for detecting evolving speech\ndeepfake threats."}
{"id": "2509.03318", "pdf": "https://arxiv.org/pdf/2509.03318", "abs": "https://arxiv.org/abs/2509.03318", "authors": ["Eduard Kamburjan", "Vidar Norstein Klungre", "Yuanwei Qu", "Rudolf Schlatte", "Egor V. Kostylev", "Martin Giese", "Einar Broch Johnsen"], "title": "Semantically Reflected Programs", "categories": ["cs.PL", "cs.LO"], "comment": null, "summary": "This paper addresses the dichotomy between the formalization of structural\nand the formalization of behavioral knowledge by means of semantically lifted\nprograms, which explore an intuitive connection between programs and knowledge\ngraphs. While knowledge graphs and ontologies are eminently useful to represent\nformal knowledge about a system's individuals and universals, programming\nlanguages are designed to describe the system's evolution. To address this\ndichotomy, we introduce a semantic lifting of the program states of an\nexecuting program into a knowledge graph, for an object-oriented programming\nlanguage. The resulting graph is exposed as a semantic reflection layer within\nthe programming language, allowing programmers to leverage knowledge of the\napplication domain in their programs. In this paper, we formalize semantic\nlifting and semantic reflection for a small programming language, SMOL, explain\nthe operational aspects of the language, and consider type correctness and\nvirtualisation for runtime program queries through the semantic reflection\nlayer. We illustrate semantic lifting and semantic reflection through a case\nstudy of geological modelling and discuss different applications of the\ntechnique. The language implementation is open source and available online."}
{"id": "2509.02992", "pdf": "https://arxiv.org/pdf/2509.02992", "abs": "https://arxiv.org/abs/2509.02992", "authors": ["Pratyush Anand", "Louis Follet", "Odiel Hooybergs", "Dirk R. Englund"], "title": "Programmable Quantum Matter: Heralding Large Cluster States in Driven Inhomogeneous Spin Ensembles", "categories": ["quant-ph", "cs.ET", "cs.IT", "math.IT"], "comment": "21 pages main text, 9 figures; 27 pages Supplementary Information, 13\n  figures", "summary": "Atom-like emitters in solids are promising platforms for quantum sensing and\ninformation processing, but inhomogeneities in the emitter fine structure\ncomplicate quantum control. We present a framework that leverages this\ndiversity to reduce the resources for generating optically heralded spin\ncluster states across $N_q$ emitters from the conventional order $O(N_q)$ to\n$O(1)$ in ensembles of $N_q \\sim 10$-$100$. An optimized pulse sequence\nsimultaneously corrects pulse-length and detuning errors, achieving\nsingle-qubit gate fidelities exceeding $99.99\\%$ for errors (normalized\nrelative to the Rabi drive strength) up to 0.3, while maintaining fidelities\nabove $99\\%$ for errors as large as 0.4. Applied as a Carr-Purcell-Meiboom-Gill\n(CPMG) dynamical decoupling protocol to the dominant noise spectrum of\nsilicon-vacancy centers in diamond, it enhances ensemble coherence times by\nover $7\\times$ compared to interleaved bang-bang based CPMG. For\nstate-of-the-art dilution refrigerators, global resonant optimal decoupling\nacross $N_q$ spins sharply reduces heating, addressing the trade-off between\nthe spin coherence and scaling to $N_q \\gg 1$. We further introduce a modified\nsingle-photon entanglement protocol with an efficient algorithm for\ndeterministic entanglement compilation. Depending on the decoupling time\nwindow, our method yields order $O(10^2$-$10^4)$ more entanglement links than\nbang-bang sequences, with theoretical guarantees of order $\\Omega(N_q)$ unique\nlinks, improvable by control tuning. Together, these techniques provide\nscalable tools - including global control, phase denoising, remote\nentanglement, and compilation - for robust quantum computing architectures with\nheterogeneous spin ensembles."}
{"id": "2509.03000", "pdf": "https://arxiv.org/pdf/2509.03000", "abs": "https://arxiv.org/abs/2509.03000", "authors": ["Hexuan Yu", "Md Mohaimin Al Barat", "Yang Xiao", "Y. Thomas Hou", "Wenjing Lou"], "title": "Closing the Visibility Gap: A Monitoring Framework for Verifiable Open RAN Operations", "categories": ["cs.NI", "cs.CR"], "comment": null, "summary": "Open Radio Access Network (Open RAN) is reshaping mobile network architecture\nby promoting openness, disaggregation, and cross-vendor interoperability.\nHowever, this architectural flexibility introduces new security challenges,\nespecially in deployments where multiple mobile network operators (MNOs)\njointly operate shared components. Existing Zero Trust Architectures (ZTA) in\nO-RAN, as defined by governmental and industry standards, implicitly assume\nthat authenticated components will comply with operational policies. However,\nthis assumption creates a critical blind spot: misconfigured or compromised\ncomponents can silently violate policies, misuse resources, or corrupt\ndownstream processes (e.g., ML-based RIC xApps).\n  To address this critical gap, we propose a monitoring framework for low-trust\nO-RAN environments that proactively verifies configuration state and control\nbehavior against tenant-defined policies. Our system provides scalable,\nverifiable oversight to enhance transparency and trust in O-RAN operations. We\nimplement and evaluate the framework using standardized O-RAN configurations,\nwith total processing latency of approximately 200 ms, demonstrating its\nefficiency and practicality for timely policy enforcement and compliance\nauditing in multi-MNO deployments."}
{"id": "2509.02933", "pdf": "https://arxiv.org/pdf/2509.02933", "abs": "https://arxiv.org/abs/2509.02933", "authors": ["Yanming Xiu", "Maria Gorlatova"], "title": "Demonstrating Visual Information Manipulation Attacks in Augmented Reality: A Hands-On Miniature City-Based Setup", "categories": ["cs.HC"], "comment": "The paper has been accepted to 2025 MobiHoc 1st Workshop on Enhancing\n  Security, Privacy, and Trust in Extended Reality (XR) Systems", "summary": "Augmented reality (AR) enhances user interaction with the real world but also\npresents vulnerabilities, particularly through Visual Information Manipulation\n(VIM) attacks. These attacks alter important real-world visual cues, leading to\nuser confusion and misdirected actions. In this demo, we present a hands-on\nexperience using a miniature city setup, where users interact with manipulated\nAR content via the Meta Quest 3. The demo highlights the impact of VIM attacks\non user decision-making and underscores the need for effective security\nmeasures in AR systems. Future work includes a user study and cross-platform\ntesting."}
{"id": "2509.03104", "pdf": "https://arxiv.org/pdf/2509.03104", "abs": "https://arxiv.org/abs/2509.03104", "authors": ["Leonid Kondrashov", "Boxi Zhou", "Hancheng Wang", "Dmitrii Ustiugov"], "title": "The High Cost of Keeping Warm: Characterizing Overhead in Serverless Autoscaling Policies", "categories": ["cs.DC", "68", "D.4.8"], "comment": null, "summary": "Serverless computing is transforming cloud application development, but the\nperformance-cost trade-offs of control plane designs remain poorly understood\ndue to a lack of open, cross-platform benchmarks and detailed system analyses.\nIn this work, we address these gaps by designing a serverless system that\napproximates the scaling behaviors of commercial providers, including AWS\nLambda and Google Cloud Run. We systematically compare the performance and\ncost-efficiency of both synchronous and asynchronous autoscaling policies by\nreplaying real-world workloads and varying key autoscaling parameters.\n  We demonstrate that our open-source systems can closely replicate the\noperational characteristics of commercial platforms, enabling reproducible and\ntransparent experimentation. By evaluating how autoscaling parameters affect\nlatency, memory usage, and CPU overhead, we reveal several key findings. First,\nwe find that serverless systems exhibit significant computational overhead due\nto instance churn equivalent to 10-40% of the CPU cycles spent on request\nhandling, primarily originating from worker nodes. Second, we observe high\nmemory allocation due to scaling policy: 2-10 times more than actively used.\nFinally, we demonstrate that reducing these overheads typically results in\nsignificant performance degradation in the current systems, underscoring the\nneed for new, cost-efficient autoscaling strategies. Additionally, we employ a\nhybrid methodology that combines real control plane deployments with\nlarge-scale simulation to extend our evaluation closer to a production scale,\nthereby bridging the gap between small research clusters and real-world\nenvironments."}
{"id": "2509.03377", "pdf": "https://arxiv.org/pdf/2509.03377", "abs": "https://arxiv.org/abs/2509.03377", "authors": ["Rui Xie", "Asad Ul Haq", "Linsen Ma", "Yunhua Fang", "Zirak Burzin Engineer", "Liu Liu", "Tong Zhang"], "title": "Amplifying Effective CXL Memory Bandwidth for LLM Inference via Transparent Near-Data Processing", "categories": ["cs.AR"], "comment": null, "summary": "Large language model (LLM) inference is bottlenecked by the limited bandwidth\nof CXL-based memory used for capacity expansion. We introduce CXL-NDP, a\ntransparent near-data processing architecture that amplifies effective CXL\nbandwidth without requiring changes to the CXL.mem interface or AI models.\nCXL-NDP integrates a precision-scalable bit-plane layout for dynamic\nquantization with transparent lossless compression of weights and KV caches\ndirectly within the CXL device. In end-to-end serving, CXL-NDP improves\nthroughput by 43%, extends the maximum context length by 87%, and reduces the\nKV cache footprint by 46.9% without accuracy loss. Hardware synthesis confirms\nits practicality with a modest silicon footprint, lowering the barrier for\nadopting efficient, scalable CXL-based memory in generative AI infrastructure."}
{"id": "2509.03136", "pdf": "https://arxiv.org/pdf/2509.03136", "abs": "https://arxiv.org/abs/2509.03136", "authors": ["Chenxia Tang", "Jianchun Liu", "Hongli Xu", "Liusheng Huang"], "title": "Adaptive KV-Cache Compression without Manually Setting Budget", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) inference relies heavily on KV-caches to\naccelerate autoregressive decoding, but the resulting memory footprint grows\nrapidly with sequence length, posing significant efficiency challenges. Current\nKV-cache compression methods suffer from a Procrustes' bed problem: they force\ndiverse workloads into fixed compression ratios, leading to suboptimal resource\nallocation and inference performance. To this end, we present GVote, an\nadaptive KV-cache compression scheme that eliminates manual budget\nspecification while achieving superior accuracy-efficiency trade-offs. GVote\noperates on the principle that the important keys are the aggregation of keys\nrequired by future queries. The method predicts future query attention demands\nby Monte-Carlo style sampling potential queries and aggregating selected keys\nto determine the optimal cache budget without manual specification.\nExperimental evaluation demonstrates GVote's effectiveness across multiple\nbenchmarks, including GSM8K, RULER and Longbench. Compared to baselines, GVote\nexhibits 2$\\times$ memory reduction while the accuracy maintains higher or\ncomparable."}
{"id": "2509.03280", "pdf": "https://arxiv.org/pdf/2509.03280", "abs": "https://arxiv.org/abs/2509.03280", "authors": ["Nils Quetschlich", "Olivia Di Matteo"], "title": "An experience-based classification of quantum bugs in quantum software", "categories": ["quant-ph", "cs.SE"], "comment": "25 pages, 4 figures. To appear in special issue of Computing,\n  \"Pivoting Quantum Computing Using Software Engineering Best Practices\"", "summary": "As quantum computers continue to improve in quality and scale, there is a\ngrowing need for accessible software frameworks for programming them. However,\nthe unique behavior of quantum systems means specialized approaches, beyond\ntraditional software development, are required. This is particularly true for\ndebugging due to quantum bugs, i.e., bugs that occur precisely because an\nalgorithm is a quantum algorithm. Pinpointing a quantum bug's root cause often\nrequires significant developer time, as there is little established guidance\nfor quantum debugging techniques. Developing such guidance is the main\nchallenge we sought to address. In this work, we describe a set of 14 quantum\nbugs, sourced primarily from our experience as quantum software developers, and\nsupplemented by analysis of open-source GitHub repositories. We detail their\ncontext, symptoms, and the techniques applied to identify and fix them. While\nclassifying these bugs based on existing schemes, we observed that most emerged\ndue to unique interactions between multiple aspects of an algorithm or\nworkflow. In other words, they occurred because more than one thing went wrong,\nwhich provided important insight into why quantum debugging is more\nchallenging. Furthermore, based on this clustering, we found that -\nunexpectedly - there is no clear relationship between debugging strategies and\nbug classes. Further research is needed to develop effective and systematic\nquantum debugging strategies."}
{"id": "2509.03037", "pdf": "https://arxiv.org/pdf/2509.03037", "abs": "https://arxiv.org/abs/2509.03037", "authors": ["Shuzheng Wang", "Yue Huang", "Zhuoer Xu", "Yuming Huang", "Jing Tang"], "title": "TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum", "categories": ["cs.CR", "cs.ET", "cs.SE"], "comment": null, "summary": "Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet\ncomprehensive security analysis remains difficult due to unverified code,\nproxy-based architectures, and the reliance on manual inspection of complex\nexecution traces. Existing approaches fall into two main categories: anomaly\ntransaction detection, which flags suspicious transactions but offers limited\ninsight into specific attack strategies hidden in execution traces inside\ntransactions, and code vulnerability detection, which cannot analyze unverified\ncontracts and struggles to show how identified flaws are exploited in real\nincidents. As a result, analysts must still manually align transaction traces\nwith contract code to reconstruct attack scenarios and conduct forensics. To\naddress this gap, TraceLLM is proposed as a framework that leverages LLMs to\nintegrate execution trace-level detection with decompiled contract code. We\nintroduce a new anomaly execution path identification algorithm and an\nLLM-refined decompile tool to identify vulnerable functions and provide\nexplicit attack paths to LLM. TraceLLM establishes the first benchmark for\njoint trace and contract code-driven security analysis. For comparison, proxy\nbaselines are created by jointly transmitting the results of three\nrepresentative code analysis along with raw traces to LLM. TraceLLM identifies\nattacker and victim addresses with 85.19\\% precision and produces automated\nreports with 70.37\\% factual precision across 27 cases with ground truth expert\nreports, achieving 25.93\\% higher accuracy than the best baseline. Moreover,\nacross 148 real-world Ethereum incidents, TraceLLM automatically generates\nreports with 66.22\\% expert-verified accuracy, demonstrating strong\ngeneralizability."}
{"id": "2509.03049", "pdf": "https://arxiv.org/pdf/2509.03049", "abs": "https://arxiv.org/abs/2509.03049", "authors": ["Gaosheng Zhao", "Dong In Kim"], "title": "Multi-layer Digital Twin System for Future Mobile Metaverse", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": "This article has been accepted for publication in IEEE Wireless\n  Communications", "summary": "In the upcoming 6G era, the communication networks are expected to face\nunprecedented challenges in terms of complexity and dynamics. Digital Twin (DT)\ntechnology, with its various digital capabilities, holds great potential to\nfacilitate the transformation of the communication network from passive\nresponding to proactive adaptation. Thus, in this paper, we propose a\nmulti-layer DT system that coordinates local DT, edge DT, and cloud DT for\nfuture network architecture and functions. In our vision, the proposed DT\nsystem will not only achieve real-time data-driven decision-making and digital\nagent functions previously handled by centralized DT, but will do so in a more\ndistributed, mobile, layer-by-layer manner. Moreover, it will supply essential\ndata, pre-trained models, and open interfaces for future metaverse\napplications, enabling creators and users to efficiently develop and experience\nmetaverse services."}
{"id": "2509.03164", "pdf": "https://arxiv.org/pdf/2509.03164", "abs": "https://arxiv.org/abs/2509.03164", "authors": ["Sangbong Yoo", "Seongbum Seo", "Chanyoung Yoon", "Hyelim Lee", "Jeong-Nam Kim", "Chansoo Kim", "Yun Jang", "Takanori Fujiwara"], "title": "OPRA-Vis: Visual Analytics System to Assist Organization-Public Relationship Assessment with Large Language Models", "categories": ["cs.HC"], "comment": null, "summary": "Analysis of public opinions collected from digital media helps organizations\nmaintain positive relationships with the public. Such public relations (PR)\nanalysis often involves assessing opinions, for example, measuring how strongly\npeople trust an organization. Pre-trained Large Language Models (LLMs) hold\ngreat promise for supporting Organization-Public Relationship Assessment (OPRA)\nbecause they can map unstructured public text to OPRA dimensions and articulate\nrationales through prompting. However, adapting LLMs for PR analysis typically\nrequires fine-tuning on large labeled datasets, which is both labor-intensive\nand knowledge-intensive, making it difficult for PR researchers to apply these\nmodels. In this paper, we present OPRA-Vis, a visual analytics system that\nleverages LLMs for OPRA without requiring extensive labeled data. Our framework\nemploys Chain-of-Thought prompting to guide LLMs in analyzing public opinion\ndata by incorporating PR expertise directly into the reasoning process.\nFurthermore, OPRA-Vis provides visualizations that reveal the clues and\nreasoning paths used by LLMs, enabling users to explore, critique, and refine\nmodel decisions. We demonstrate the effectiveness of OPRA-Vis through two\nreal-world use cases and evaluate it quantitatively, through comparisons with\nalternative LLMs and prompting strategies, and qualitatively, through\nassessments of usability, effectiveness, and expert feedback."}
{"id": "2509.03145", "pdf": "https://arxiv.org/pdf/2509.03145", "abs": "https://arxiv.org/abs/2509.03145", "authors": ["Pengkun Ren", "Hai Dong", "Zahir Tari", "Pengcheng Zhang"], "title": "Efficient and Secure Sleepy Model for BFT Consensus", "categories": ["cs.DC"], "comment": "Accepted to ESORICS 2025, 20 pages, 7 figures", "summary": "Byzantine Fault Tolerant (BFT) consensus protocols for dynamically available\nsystems face a critical challenge: balancing latency and security in\nfluctuating node participation. Existing solutions often require multiple\nrounds of voting per decision, leading to high latency or limited resilience to\nadversarial behavior. This paper presents a BFT protocol integrating a\npre-commit mechanism with publicly verifiable secret sharing (PVSS) into\nmessage transmission. By binding users' identities to their messages through\nPVSS, our approach reduces communication rounds. Compared to other\nstate-of-the-art methods, our protocol typically requires only four network\ndelays (4$\\Delta$) in common scenarios while being resilient to up to 1/2\nadversarial participants. This integration enhances the efficiency and security\nof the protocol without compromising integrity. Theoretical analysis\ndemonstrates the robustness of the protocol against Byzantine attacks.\nExperimental evaluations show that, compared to traditional BFT protocols, our\nprotocol significantly prevents fork occurrences and improves chain stability.\nFurthermore, compared to longest-chain protocol, our protocol maintains\nstability and lower latency in scenarios with moderate participation\nfluctuations."}
{"id": "2509.03226", "pdf": "https://arxiv.org/pdf/2509.03226", "abs": "https://arxiv.org/abs/2509.03226", "authors": ["Huiling Li", "Jianliang Xu"], "title": "BAMG: A Block-Aware Monotonic Graph Index for Disk-Based Approximate Nearest Neighbor Search", "categories": ["cs.DB"], "comment": null, "summary": "Approximate Nearest Neighbor Search (ANNS) over high-dimensional vectors is a\nfoundational problem in databases, where disk I/O often emerges as the dominant\nperformance bottleneck at scale. Existing graph indexing solutions for\ndisk-based ANNS typically either optimize the storage layout for a given graph\nor construct the graph independently of the storage layout, thus overlooking\ntheir interaction. In this paper, we propose the Block-aware Monotonic Relative\nNeighborhood Graph (BMRNG), a novel graph structure that jointly considers both\ngeometric distance and storage layout for edge selection, theoretically\nguaranteeing the existence of I/O monotonic search paths. To address the\nscalability challenge of BMRNG construction, we further develop a practical and\nefficient variant, the Block-Aware Monotonic Graph (BAMG), which can be\nconstructed in linear time from a monotonic graph considering the storage\nlayout. BAMG integrates block-aware edge pruning with a decoupled storage\ndesign that separates raw vectors from the graph index, thereby maximizing\nblock utilization and minimizing redundant disk reads. Additionally, we design\na multi-layer navigation graph for adaptive and efficient query entry, along\nwith a block-first search algorithm that prioritizes intra-block traversal to\nfully exploit each disk I/O operation. Extensive experiments on real-world\ndatasets demonstrate that BAMG achieves up to 2.1x higher throughput and\nreduces I/O reads by up to 52% compared to state-of-the-art methods, while\nmaintaining comparable recall."}
{"id": "2509.03310", "pdf": "https://arxiv.org/pdf/2509.03310", "abs": "https://arxiv.org/abs/2509.03310", "authors": ["Evgenii Kniazev", "Arseny Kravchenko", "Igor Rekun", "James Broadhead", "Nikita Shamgunov", "Pranav Sah", "Pratik Nichite", "Ivan Yamshchikov"], "title": "app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "We present app.build (https://github.com/appdotbuild/agent/), an open-source\nframework that improves LLM-based application generation through systematic\nvalidation and structured environments. Our approach combines multi-layered\nvalidation pipelines, stack-specific orchestration, and model-agnostic\narchitecture, implemented across three reference stacks. Through evaluation on\n30 generation tasks, we demonstrate that comprehensive validation achieves\n73.3% viability rate with 30% reaching perfect quality scores, while\nopen-weights models achieve 80.8% of closed-model performance when provided\nstructured environments. The open-source framework has been adopted by the\ncommunity, with over 3,000 applications generated to date. This work\ndemonstrates that scaling reliable AI agents requires scaling environments, not\njust models -- providing empirical insights and complete reference\nimplementations for production-oriented agent systems."}
{"id": "2509.03290", "pdf": "https://arxiv.org/pdf/2509.03290", "abs": "https://arxiv.org/abs/2509.03290", "authors": ["Babak Azkaei", "Kishor Chandra Joshi", "George Exarchakos"], "title": "Machine Learning-Driven Anomaly Detection for 5G O-RAN Performance Metrics", "categories": ["cs.NI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The ever-increasing reliance of critical services on network infrastructure\ncoupled with the increased operational complexity of beyond-5G/6G networks\nnecessitate the need for proactive and automated network fault management. The\nprovision for open interfaces among different radio access network\\,(RAN)\nelements and the integration of AI/ML into network architecture enabled by the\nOpen RAN\\,(O-RAN) specifications bring new possibilities for active network\nhealth monitoring and anomaly detection. In this paper we leverage these\nadvantages and develop an anomaly detection framework that proactively detect\nthe possible throughput drops for a UE and minimize the post-handover failures.\nWe propose two actionable anomaly detection algorithms tailored for real-world\ndeployment. The first algorithm identifies user equipment (UE) at risk of\nsevere throughput degradation by analyzing key performance indicators (KPIs)\nsuch as resource block utilization and signal quality metrics, enabling\nproactive handover initiation. The second algorithm evaluates neighbor cell\nradio coverage quality, filtering out cells with anomalous signal strength or\ninterference levels. This reduces candidate targets for handover by 41.27\\% on\naverage. Together, these methods mitigate post-handover failures and throughput\ndrops while operating much faster than the near-real-time latency constraints.\nThis paves the way for self-healing 6G networks."}
{"id": "2509.03181", "pdf": "https://arxiv.org/pdf/2509.03181", "abs": "https://arxiv.org/abs/2509.03181", "authors": ["Yaniv Goren", "Yuval Cohen", "Alexander Apartsin", "Yehudit Aperstein"], "title": "Beyond Words: Interjection Classification for Improved Human-Computer Interaction", "categories": ["cs.HC", "cs.LG"], "comment": "9 pages", "summary": "In the realm of human-computer interaction, fostering a natural dialogue\nbetween humans and machines is paramount. A key, often overlooked, component of\nthis dialogue is the use of interjections such as \"mmm\" and \"hmm\". Despite\ntheir frequent use to express agreement, hesitation, or requests for\ninformation, these interjections are typically dismissed as \"non-words\" by\nAutomatic Speech Recognition (ASR) engines. Addressing this gap, we introduce a\nnovel task dedicated to interjection classification, a pioneer in the field to\nour knowledge. This task is challenging due to the short duration of\ninterjection signals and significant inter- and intra-speaker variability. In\nthis work, we present and publish a dataset of interjection signals collected\nspecifically for interjection classification. We employ this dataset to train\nand evaluate a baseline deep learning model. To enhance performance, we augment\nthe training dataset using techniques such as tempo and pitch transformation,\nwhich significantly improve classification accuracy, making models more robust.\nThe interjection dataset, a Python library for the augmentation pipeline,\nbaseline model, and evaluation scripts, are available to the research\ncommunity."}
{"id": "2509.03394", "pdf": "https://arxiv.org/pdf/2509.03394", "abs": "https://arxiv.org/abs/2509.03394", "authors": ["Amirhossein Shahbazinia", "Darong Huang", "Luis Costero", "David Atienza"], "title": "CloudFormer: An Attention-based Performance Prediction for Public Clouds with Unknown Workload", "categories": ["cs.DC", "cs.LG", "cs.PF"], "comment": null, "summary": "Cloud platforms are increasingly relied upon to host diverse,\nresource-intensive workloads due to their scalability, flexibility, and\ncost-efficiency. In multi-tenant cloud environments, virtual machines are\nconsolidated on shared physical servers to improve resource utilization. While\nvirtualization guarantees resource partitioning for CPU, memory, and storage,\nit cannot ensure performance isolation. Competition for shared resources such\nas last-level cache, memory bandwidth, and network interfaces often leads to\nsevere performance degradation. Existing management techniques, including VM\nscheduling and resource provisioning, require accurate performance prediction\nto mitigate interference. However, this remains challenging in public clouds\ndue to the black-box nature of VMs and the highly dynamic nature of workloads.\nTo address these limitations, we propose CloudFormer, a dual-branch\nTransformer-based model designed to predict VM performance degradation in\nblack-box environments. CloudFormer jointly models temporal dynamics and\nsystem-level interactions, leveraging 206 system metrics at one-second\nresolution across both static and dynamic scenarios. This design enables the\nmodel to capture transient interference effects and adapt to varying workload\nconditions without scenario-specific tuning. Complementing the methodology, we\nprovide a fine-grained dataset that significantly expands the temporal\nresolution and metric diversity compared to existing benchmarks. Experimental\nresults demonstrate that CloudFormer consistently outperforms state-of-the-art\nbaselines across multiple evaluation metrics, achieving robust generalization\nacross diverse and previously unseen workloads. Notably, CloudFormer attains a\nmean absolute error (MAE) of just 7.8%, representing a substantial improvement\nin predictive accuracy and outperforming existing methods at least by 28%."}
{"id": "2509.03228", "pdf": "https://arxiv.org/pdf/2509.03228", "abs": "https://arxiv.org/abs/2509.03228", "authors": ["Siqi Xiang", "Sheng Wang", "Xiaokui Xiao", "Cong Yue", "Zhanhao Zhao", "Beng Chin Ooi"], "title": "NeurStore: Efficient In-database Deep Learning Model Management System", "categories": ["cs.DB", "cs.LG"], "comment": "15 pages, 14 figures, Accepted at SIGMOD 2026", "summary": "With the prevalence of in-database AI-powered analytics, there is an\nincreasing demand for database systems to efficiently manage the ever-expanding\nnumber and size of deep learning models. However, existing database systems\ntypically store entire models as monolithic files or apply compression\ntechniques that overlook the structural characteristics of deep learning\nmodels, resulting in suboptimal model storage overhead. This paper presents\nNeurStore, a novel in-database model management system that enables efficient\nstorage and utilization of deep learning models. First, NeurStore employs a\ntensor-based model storage engine to enable fine-grained model storage within\ndatabases. In particular, we enhance the hierarchical navigable small world\n(HNSW) graph to index tensors, and only store additional deltas for tensors\nwithin a predefined similarity threshold to ensure tensor-level deduplication.\nSecond, we propose a delta quantization algorithm that effectively compresses\ndelta tensors, thus achieving a superior compression ratio with controllable\nmodel accuracy loss. Finally, we devise a compression-aware model loading\nmechanism, which improves model utilization performance by enabling direct\ncomputation on compressed tensors. Experimental evaluations demonstrate that\nNeurStore achieves superior compression ratios and competitive model loading\nthroughput compared to state-of-the-art approaches."}
{"id": "2509.03381", "pdf": "https://arxiv.org/pdf/2509.03381", "abs": "https://arxiv.org/abs/2509.03381", "authors": ["Sanghoon Lee", "Junha Kang", "Kyung-Joon Park"], "title": "Dependency Chain Analysis of ROS 2 DDS QoS Policies: From Lifecycle Tutorial to Static Verification", "categories": ["cs.NI", "cs.RO"], "comment": "14 pages, 4 figures", "summary": "Robot Operating System 2 (ROS 2) relies on the Data Distribution Service\n(DDS), which offers more than 20 Quality of Service (QoS) policies governing\navailability, reliability, and resource usage. Yet ROS 2 users lack clear\nguidance on safe policy combinations and validation processes prior to\ndeployment, which often leads to trial-and-error tuning and unexpected runtime\nfailures. To address these challenges, we analyze DDS Publisher-Subscriber\ncommunication over a life cycle divided into Discovery, Data Exchange, and\nDisassociation, and provide a user oriented tutorial explaining how 16 QoS\npolicies operate in each phase. Building on this analysis, we derive a QoS\ndependency chain that formalizes inter-policy relationships and classifies 41\ndependency violation rules, capturing constraints that commonly cause\ncommunication failures in practice. Finally, we introduce QoS Guard, a ROS 2\npackage that statically validates DDS XML profiles offline, flags conflicts,\nand enables safe, predeployment tuning without establishing a live ROS 2\nsession. Together, these contributions give ROS 2 users both conceptual insight\nand a concrete tool that enables early detection of misconfigurations,\nimproving the reliability and resource efficiency of ROS 2 based robotic\nsystems."}
{"id": "2509.03199", "pdf": "https://arxiv.org/pdf/2509.03199", "abs": "https://arxiv.org/abs/2509.03199", "authors": ["Sina Hinzmann", "Francesco Vona", "Juliane Henning", "Mohamed Amer", "Omar Abdellatif", "Tanja Kojic", "Jan-Niklas Voigt-Antons"], "title": "Finding My Way: Influence of Different Audio Augmented Reality Navigation Cues on User Experience and Subjective Usefulness", "categories": ["cs.HC"], "comment": null, "summary": "As augmented reality (AR) becomes increasingly prevalent in mobile and\ncontext-aware applications, the role of auditory cues in guiding users through\nphysical environments is becoming critical. This study investigates the\neffectiveness and user experience of various categories of audio cues,\nincluding fully non-verbal sounds and speech-derived Spearcons, during outdoor\nnavigation tasks using the Meta Quest 3 headset. Twenty participants navigated\nfive outdoor routes using audio-only cue types: Artificial Sounds, Nature\nSounds, Spearcons, Musical Instruments, and Auditory Icons. Subjective\nevaluations were collected to assess the perceived effectiveness and user\nexperience of each sound type. Results revealed significant differences in\nperceived novelty and stimulation across sound types. Artificial Sounds and\nMusical Instruments were rated higher than Spearcons in novelty, while\nArtificial Sounds were also rated higher than Spearcons in stimulation. Overall\npreference was evenly split between Nature Sounds and Artificial Sounds. These\nfindings suggest that incorporating aspects of novelty and user engagement in\nauditory feedback design may enhance the effectiveness of AR navigation\nsystems."}
{"id": "2509.02590", "pdf": "https://arxiv.org/pdf/2509.02590", "abs": "https://arxiv.org/abs/2509.02590", "authors": ["Mohammad Dindoost", "Oliver Alvarado Rodriguez", "Bartosz Bryg", "Minhyuk Park", "George Chacko", "Tandy Warnow", "David A. Bader"], "title": "On the Optimization of Methods for Establishing Well-Connected Communities", "categories": ["cs.SI", "cs.DC"], "comment": "12 pages", "summary": "Community detection plays a central role in uncovering meso scale structures\nin networks. However, existing methods often suffer from disconnected or weakly\nconnected clusters, undermining interpretability and robustness. Well-Connected\nClusters (WCC) and Connectivity Modifier (CM) algorithms are post-processing\ntechniques that improve the accuracy of many clustering methods. However, they\nare computationally prohibitive on massive graphs. In this work, we present\noptimized parallel implementations of WCC and CM using the HPE Chapel\nprogramming language. First, we design fast and efficient parallel algorithms\nthat leverage Chapel's parallel constructs to achieve substantial performance\nimprovements and scalability on modern multicore architectures. Second, we\nintegrate this software into Arkouda/Arachne, an open-source, high-performance\nframework for large-scale graph analytics. Our implementations uniquely enable\nwell-connected community detection on massive graphs with more than 2 billion\nedges, providing a practical solution for connectivity-preserving clustering at\nweb scale. For example, our implementations of WCC and CM enable community\ndetection of the over 2-billion edge Open-Alex dataset in minutes using 128\ncores, a result infeasible to compute previously."}
{"id": "2509.02751", "pdf": "https://arxiv.org/pdf/2509.02751", "abs": "https://arxiv.org/abs/2509.02751", "authors": ["Matthew Russo", "Tim Kraska"], "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "categories": ["cs.AI", "cs.DB", "cs.LG", "cs.MA", "I.2.1; H.3.3; H.2.4"], "comment": "6 pages, 2 figures, submitted to CIDR'26", "summary": "With advances in large language models (LLMs), researchers are creating new\nsystems that can perform AI-driven analytics over large unstructured datasets.\nRecent work has explored executing such analytics queries using semantic\noperators -- a declarative set of AI-powered data transformations with natural\nlanguage specifications. However, even when optimized, these operators can be\nexpensive to execute on millions of records and their iterator execution\nsemantics make them ill-suited for interactive data analytics tasks. In another\nline of work, Deep Research systems have demonstrated an ability to answer\nnatural language question(s) over large datasets. These systems use one or more\nLLM agent(s) to plan their execution, process the dataset(s), and iteratively\nrefine their answer. However, these systems do not explicitly optimize their\nquery plans which can lead to poor plan execution. In order for AI-driven\nanalytics to excel, we need a runtime which combines the optimized execution of\nsemantic operators with the flexibility and more dynamic execution of Deep\nResearch systems. As a first step towards this vision, we build a prototype\nwhich enables Deep Research agents to write and execute optimized semantic\noperator programs. We evaluate our prototype and demonstrate that it can\noutperform a handcrafted semantic operator program and open Deep Research\nsystems on two basic queries. Compared to a standard open Deep Research agent,\nour prototype achieves up to 1.95x better F1-score. Furthermore, even if we\ngive the agent access to semantic operators as tools, our prototype still\nachieves cost and runtime savings of up to 76.8% and 72.7% thanks to its\noptimized execution."}
{"id": "2509.03386", "pdf": "https://arxiv.org/pdf/2509.03386", "abs": "https://arxiv.org/abs/2509.03386", "authors": ["Ziye Jia", "Jia He", "Yuanhao Cui", "Qiuming Zhu", "Ligang Yuan", "Fuhui Zhou", "Qihui Wu", "Dusit Niyato", "Zhu Han"], "title": "Hierarchical Low-Altitude Wireless Network Empowered Air Traffic Management", "categories": ["cs.NI"], "comment": "7 pages 6 figures", "summary": "As the increasing development of low-altitude aircrafts, the rational design\nof low-altitude networks directly impacts the aerial safety and resource\nutilization. To address the challenges of environmental complexity and aircraft\ndiversity in the traffic management, we propose a hierarchical low-altitude\nwireless network (HLWN) framework. Empowered by the threedimensional spatial\ndiscretization and integrated wireless monitoring mechanisms in HLWN, we design\nlow-altitude air corridors to guarantee safe operation and optimization.\nBesides, we develop the multi-dimensional flight risk assessment through\nconflict detection and probabilistic collision analysis, facilitating dynamic\ncollision avoidance for heterogeneous aircrafts. Finally, the open issues and\nfuture directions are investigated to provide insights into HLAN development."}
{"id": "2509.03232", "pdf": "https://arxiv.org/pdf/2509.03232", "abs": "https://arxiv.org/abs/2509.03232", "authors": ["Eduard Kuric", "Peter Demcak", "Matus Krajcovic"], "title": "Card Sorting with Fewer Cards and the Same Mental Models? A Re-examination of an Established Practice", "categories": ["cs.HC", "H.5"], "comment": null, "summary": "To keep card sorting with a lot of cards concise, a common strategy for\ngauging mental models involves presenting participants with fewer randomly\nselected cards instead of the full set. This is a decades-old practice, but its\neffects lacked systematic examination. To assess how randomized subsets affect\ndata, we conducted an experiment with 160 participants. We compared results\nbetween full and randomized 60\\% card sets, then analyzed sample size\nrequirements and the impacts of individual personality and cognitive factors.\nOur results demonstrate that randomized subsets can yield comparable similarity\nmatrices to standard card sorting, but thematic patterns in categories can\ndiffer. Increased data variability also warrants larger sample sizes (25-35 for\n60% card subset). Results indicate that personality traits and cognitive\nreflection interact with card sorting. Our research suggests evidence-based\npractices for conducting card sorting while exposing the influence of study\ndesign and individual differences on measurement of mental models."}
{"id": "2509.02629", "pdf": "https://arxiv.org/pdf/2509.02629", "abs": "https://arxiv.org/abs/2509.02629", "authors": ["Mayank Bhatia", "Shaan Doshi", "Daniel Winton", "Brian Doolittle", "Bruno Abreu", "Santiago Núñez-Corrales"], "title": "\\textit{In Silico} Benchmarking of Detectable Byzantine Agreement in Noisy Quantum Networks", "categories": ["quant-ph", "cs.DC", "cs.NI"], "comment": "10 pages, 17 figures", "summary": "Quantum communication resources offer significant advantages for\nfault-tolerant distributed protocols, particularly in Byzantine Agreement (BA),\nwhere reliability against adversarial interference is essential. Quantum\nDetectable Byzantine Agreement (QDBA) enables consensus protocols that surpass\nclassical limitations by leveraging entangled quantum states. In this work, we\nfocus on the practical realization of QDBA using Einstein-Podolsky-Rosen (EPR)\npairs, the simplest maximally entangled quantum resources, making the protocol\nexperimentally accessible across current quantum hardware platforms. We present\na comprehensive computational study of the EPRQDBA protocol under realistic\nquantum network conditions, utilizing the Aliro Quantum Network Simulator to\nevaluate the performance and robustness of the protocol. Our simulations\nsystematically explore the protocol's parameter space --including variations in\nnetwork size, traitorous node count, the amount of entanglement consumed in the\nprotocol, and physically motivated noise models tailored specifically for\nsuperconducting and photonic qubit technologies. Through extensive numerical\nexperiments, we provide insights into how these physically realistic parameters\nimpact protocol performance, establishing critical thresholds and optimal\noperational regimes for experimental implementations. This work bridges\ntheoretical advances in quantum consensus protocols with practical network\nimplementations, offering a concrete reference for experimentalists. Our\nfindings serve as a guideline for evaluating and optimizing QDBA\nimplementations in realistic, noisy environments."}
{"id": "2509.02629", "pdf": "https://arxiv.org/pdf/2509.02629", "abs": "https://arxiv.org/abs/2509.02629", "authors": ["Mayank Bhatia", "Shaan Doshi", "Daniel Winton", "Brian Doolittle", "Bruno Abreu", "Santiago Núñez-Corrales"], "title": "\\textit{In Silico} Benchmarking of Detectable Byzantine Agreement in Noisy Quantum Networks", "categories": ["quant-ph", "cs.DC", "cs.NI"], "comment": "10 pages, 17 figures", "summary": "Quantum communication resources offer significant advantages for\nfault-tolerant distributed protocols, particularly in Byzantine Agreement (BA),\nwhere reliability against adversarial interference is essential. Quantum\nDetectable Byzantine Agreement (QDBA) enables consensus protocols that surpass\nclassical limitations by leveraging entangled quantum states. In this work, we\nfocus on the practical realization of QDBA using Einstein-Podolsky-Rosen (EPR)\npairs, the simplest maximally entangled quantum resources, making the protocol\nexperimentally accessible across current quantum hardware platforms. We present\na comprehensive computational study of the EPRQDBA protocol under realistic\nquantum network conditions, utilizing the Aliro Quantum Network Simulator to\nevaluate the performance and robustness of the protocol. Our simulations\nsystematically explore the protocol's parameter space --including variations in\nnetwork size, traitorous node count, the amount of entanglement consumed in the\nprotocol, and physically motivated noise models tailored specifically for\nsuperconducting and photonic qubit technologies. Through extensive numerical\nexperiments, we provide insights into how these physically realistic parameters\nimpact protocol performance, establishing critical thresholds and optimal\noperational regimes for experimental implementations. This work bridges\ntheoretical advances in quantum consensus protocols with practical network\nimplementations, offering a concrete reference for experimentalists. Our\nfindings serve as a guideline for evaluating and optimizing QDBA\nimplementations in realistic, noisy environments."}
{"id": "2509.03271", "pdf": "https://arxiv.org/pdf/2509.03271", "abs": "https://arxiv.org/abs/2509.03271", "authors": ["Sylvie Delacroix", "Diana Robinson", "Umang Bhatt", "Jacopo Domenicucci", "Jessica Montgomery", "Gael Varoquaux", "Carl Henrik Ek", "Vincent Fortuin", "Yulan He", "Tom Diethe", "Neill Campbell", "Mennatallah El-Assady", "Soren Hauberg", "Ivana Dusparic", "Neil Lawrence"], "title": "Beyond Quantification: Navigating Uncertainty in Professional AI Systems", "categories": ["cs.HC"], "comment": null, "summary": "The growing integration of large language models across professional domains\ntransforms how experts make critical decisions in healthcare, education, and\nlaw. While significant research effort focuses on getting these systems to\ncommunicate their outputs with probabilistic measures of reliability, many\nconsequential forms of uncertainty in professional contexts resist such\nquantification. A physician pondering the appropriateness of documenting\npossible domestic abuse, a teacher assessing cultural sensitivity, or a\nmathematician distinguishing procedural from conceptual understanding face\nforms of uncertainty that cannot be reduced to percentages. This paper argues\nfor moving beyond simple quantification toward richer expressions of\nuncertainty essential for beneficial AI integration. We propose participatory\nrefinement processes through which professional communities collectively shape\nhow different forms of uncertainty are communicated. Our approach acknowledges\nthat uncertainty expression is a form of professional sense-making that\nrequires collective development rather than algorithmic optimization."}
{"id": "2509.02909", "pdf": "https://arxiv.org/pdf/2509.02909", "abs": "https://arxiv.org/abs/2509.02909", "authors": ["Gaurav Gaur", "Barun Gorain", "Rishi Ranjan Singh", "Daya Gaur"], "title": "Treasure Hunt in Anonymous Graphs with Quantum Pebbles by Oblivious Agents", "categories": ["quant-ph", "cs.DC", "cs.DS", "cs.ET"], "comment": null, "summary": "We investigate the problem of finding a static treasure in anonymous graphs\nusing oblivious agents and introduce a novel approach that leverages quantum\ninformation. In anonymous graphs, vertices are unlabelled, indistinguishable,\nand edges are locally labelled with port numbers. Agents typically rely on\nstationary classical pebbles placed by an oracle to guide their search.\nHowever, this classical approach is constrained by limited information\ntransmission and high traversal complexity. Classical pebbles are not\nsufficient for search if the agents are oblivious. We propose the first use of\nquantum pebbles for search in anonymous graphs. Quantum pebbles periodically\nemit qubits in a fixed quantum state. Each pebble encodes the port number to\nthe next node using a unique quantum state. The agent determines the correct\npath by performing measurements in multiple bases, exploiting the probabilistic\nnature of quantum measurement to distinguish states. We show that this strategy\nenables an oblivious agent to locate the treasure in $D$ steps using $D$\nquantum pebbles, where $D$ is the length of the shortest path between the\nstarting point and the treasure. Moreover, only $O((\\log D + \\log \\Delta)/(\\log\n1/\\delta))$ measurements per node are required to ensure high success\nprobability in a graph with maximum degree $\\Delta$ where $\\delta =\n\\cos^2(\\frac{\\pi}{2\\Delta})$. We propose the use of quantum information as a\nguidance mechanism in anonymous graph search. We demonstrate that quantum\npebbles can not only emulate the functionality of classical pebbles but can do\nso with improved efficiency, offering a promising direction for future\nquantum-enhanced distributed algorithms."}
{"id": "2509.03392", "pdf": "https://arxiv.org/pdf/2509.03392", "abs": "https://arxiv.org/abs/2509.03392", "authors": ["Xinyue Chen", "Kunlin Ruan", "Kexin Phyllis Ju", "Nathan Yap", "Xu Wang"], "title": "More AI Assistance Reduces Cognitive Engagement: Examining the AI Assistance Dilemma in AI-Supported Note-Taking", "categories": ["cs.HC"], "comment": "Accepted by CSCW2025", "summary": "As AI tools become increasingly embedded in cognitively demanding tasks such\nas note-taking, questions remain about whether they enhance or undermine\ncognitive engagement. This paper examines the \"AI Assistance Dilemma\" in\nnote-taking, investigating how varying levels of AI support affect user\nengagement and comprehension. In a within-subject experiment, we asked\nparticipants (N=30) to take notes during lecture videos under three conditions:\nAutomated AI (high assistance with structured notes), Intermediate AI (moderate\nassistance with real-time summary, and Minimal AI (low assistance with\ntranscript). Results reveal that Intermediate AI yields the highest post-test\nscores and Automated AI the lowest. Participants, however, preferred the\nautomated setup due to its perceived ease of use and lower cognitive effort,\nsuggesting a discrepancy between preferred convenience and cognitive benefits.\nOur study provides insights into designing AI assistance that preserves\ncognitive engagement, offering implications for designing moderate AI support\nin cognitive tasks."}
{"id": "2509.03075", "pdf": "https://arxiv.org/pdf/2509.03075", "abs": "https://arxiv.org/abs/2509.03075", "authors": ["Mathis Certenais", "François Bodin", "Laurent Morin"], "title": "A description of the radio astronomy data processing tool DDF Pipeline", "categories": ["astro-ph.IM", "cs.DC"], "comment": null, "summary": "This paper presents the DDF Pipeline, a radio astronomy data processing tool\ninitially designed for the LOw-Frequency ARray (LO- FAR) radio-telescope and a\ncandidate for processing data from the Square Kilometre Array (SKA). This work\ndescribes the DDF Pipeline software and presents a coarse-grain profiling\nexecution to characterize its performance."}
{"id": "2509.03430", "pdf": "https://arxiv.org/pdf/2509.03430", "abs": "https://arxiv.org/abs/2509.03430", "authors": ["Vimal Mollyn", "Nathan DeVrio", "Chris Harrison"], "title": "EclipseTouch: Touch Segmentation on Ad Hoc Surfaces using Worn Infrared Shadow Casting", "categories": ["cs.HC", "cs.CV", "cs.GR", "cs.RO"], "comment": "Accepted to UIST 2025", "summary": "The ability to detect touch events on uninstrumented, everyday surfaces has\nbeen a long-standing goal for mixed reality systems. Prior work has shown that\nvirtual interfaces bound to physical surfaces offer performance and ergonomic\nbenefits over tapping at interfaces floating in the air. A wide variety of\napproaches have been previously developed, to which we contribute a new\nheadset-integrated technique called \\systemname. We use a combination of a\ncomputer-triggered camera and one or more infrared emitters to create\nstructured shadows, from which we can accurately estimate hover distance (mean\nerror of 6.9~mm) and touch contact (98.0\\% accuracy). We discuss how our\ntechnique works across a range of conditions, including surface material,\ninteraction orientation, and environmental lighting."}
{"id": "2509.03472", "pdf": "https://arxiv.org/pdf/2509.03472", "abs": "https://arxiv.org/abs/2509.03472", "authors": ["Yubo Gao", "Renbo Tu", "Gennady Pekhimenko", "Nandita Vijaykumar"], "title": "DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Differentially-Private SGD (DP-SGD) is a powerful technique to protect user\nprivacy when using sensitive data to train neural networks. During training,\nconverting model weights and activations into low-precision formats, i.e.,\nquantization, can drastically reduce training times, energy consumption, and\ncost, and is thus a widely used technique. In this work, we demonstrate that\nquantization causes significantly higher accuracy degradation in DP-SGD\ncompared to regular SGD. We observe that this is caused by noise injection in\nDP-SGD, which amplifies quantization variance, leading to disproportionately\nlarge accuracy degradation. To address this challenge, we present QPQuant, a\ndynamic quantization framework that adaptively selects a changing subset of\nlayers to quantize at each epoch. Our method combines two key ideas that\neffectively reduce quantization variance: (i) probabilistic sampling of the\nlayers that rotates which layers are quantized every epoch, and (ii) loss-aware\nlayer prioritization, which uses a differentially private loss sensitivity\nestimator to identify layers that can be quantized with minimal impact on model\nquality. This estimator consumes a negligible fraction of the overall privacy\nbudget, preserving DP guarantees. Empirical evaluations on ResNet18, ResNet50,\nand DenseNet121 across a range of datasets demonstrate that DPQuant\nconsistently outperforms static quantization baselines, achieving near\nPareto-optimal accuracy-compute trade-offs and up to 2.21x theoretical\nthroughput improvements on low-precision hardware, with less than 2% drop in\nvalidation accuracy."}
{"id": "2509.03451", "pdf": "https://arxiv.org/pdf/2509.03451", "abs": "https://arxiv.org/abs/2509.03451", "authors": ["Nathan DeVrio", "Vimal Mollyn", "Chris Harrison"], "title": "SmartPoser: Arm Pose Estimation with a Smartphone and Smartwatch Using UWB and IMU Data", "categories": ["cs.HC", "cs.CV", "cs.GR", "cs.RO"], "comment": "The first two listed authors contributed equally. Published at UIST\n  2023", "summary": "The ability to track a user's arm pose could be valuable in a wide range of\napplications, including fitness, rehabilitation, augmented reality input, life\nlogging, and context-aware assistants. Unfortunately, this capability is not\nreadily available to consumers. Systems either require cameras, which carry\nprivacy issues, or utilize multiple worn IMUs or markers. In this work, we\ndescribe how an off-the-shelf smartphone and smartwatch can work together to\naccurately estimate arm pose. Moving beyond prior work, we take advantage of\nmore recent ultra-wideband (UWB) functionality on these devices to capture\nabsolute distance between the two devices. This measurement is the perfect\ncomplement to inertial data, which is relative and suffers from drift. We\nquantify the performance of our software-only approach using off-the-shelf\ndevices, showing it can estimate the wrist and elbow joints with a \\hl{median\npositional error of 11.0~cm}, without the user having to provide training data."}
{"id": "2509.02624", "pdf": "https://arxiv.org/pdf/2509.02624", "abs": "https://arxiv.org/abs/2509.02624", "authors": ["Minja Axelsson", "Jiaee Cheong", "Rune Nyrup", "Hatice Gunes"], "title": "Who Owns The Robot?: Four Ethical and Socio-technical Questions about Wellbeing Robots in the Real World through Community Engagement", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.RO", "I.2.9; K.4.2; K.4.1"], "comment": "Accepted at the 8th AAAI/ACM Conference on AI, Ethics, and Society.\n  23 pages, 1 figure", "summary": "Recent studies indicate that robotic coaches can play a crucial role in\npromoting wellbeing. However, the real-world deployment of wellbeing robots\nraises numerous ethical and socio-technical questions and concerns. To explore\nthese questions, we undertake a community-centered investigation to examine\nthree different communities' perspectives on using robotic wellbeing coaches in\nreal-world environments. We frame our work as an anticipatory ethical\ninvestigation, which we undertake to better inform the development of robotic\ntechnologies with communities' opinions, with the ultimate goal of aligning\nrobot development with public interest. We conducted workshops with three\ncommunities who are under-represented in robotics development: 1) members of\nthe public at a science festival, 2) women computer scientists at a conference,\nand 3) humanities researchers interested in history and philosophy of science.\nIn the workshops, we collected qualitative data using the Social Robot\nCo-Design Canvas on Ethics. We analysed the collected qualitative data with\nThematic Analysis, informed by notes taken during workshops. Through our\nanalysis, we identify four themes regarding key ethical and socio-technical\nquestions about the real-world use of wellbeing robots. We group participants'\ninsights and discussions around these broad thematic questions, discuss them in\nlight of state-of-the-art literature, and highlight areas for future\ninvestigation. Finally, we provide the four questions as a broad framework that\nroboticists can and should use during robotic development and deployment, in\norder to reflect on the ethics and socio-technical dimensions of their robotic\napplications, and to engage in dialogue with communities of robot users. The\nfour questions are: 1) Is the robot safe and how can we know that?, 2) Who is\nthe robot built for and with?, 3) Who owns the robot and the data?, and 4) Why\na robot?."}
{"id": "2509.02924", "pdf": "https://arxiv.org/pdf/2509.02924", "abs": "https://arxiv.org/abs/2509.02924", "authors": ["Nefeli Manoudaki", "Mert Toka", "Iason Paterakis", "Diarmid Flatley"], "title": "Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence", "categories": ["cs.MM", "cs.AI", "cs.HC"], "comment": "to be published in IEEE VISAP 2025", "summary": "Simulacra Naturae is a data-driven media installation that explores\ncollective care through the entanglement of biological computation, material\necologies, and generative systems. The work translates pre-recorded neural\nactivity from brain organoids, lab-grown three-dimensional clusters of neurons,\ninto a multi-sensory environment composed of generative visuals, spatial audio,\nliving plants, and fabricated clay artifacts. These biosignals, streamed\nthrough a real-time system, modulate emergent agent behaviors inspired by\nnatural systems such as termite colonies and slime molds. Rather than using\nbiosignals as direct control inputs, Simulacra Naturae treats organoid activity\nas a co-creative force, allowing neural rhythms to guide the growth, form, and\natmosphere of a generative ecosystem. The installation features computationally\nfabricated clay prints embedded with solenoids, adding physical sound\nresonances to the generative surround composition. The spatial environment,\nfilled with live tropical plants and a floor-level projection layer featuring\nreal-time generative AI visuals, invites participants into a sensory field\nshaped by nonhuman cognition. By grounding abstract data in living materials\nand embodied experience, Simulacra Naturae reimagines visualization as a\npractice of care, one that decentralizes human agency and opens new spaces for\nethics, empathy, and ecological attunement within hybrid computational systems."}
{"id": "2509.03222", "pdf": "https://arxiv.org/pdf/2509.03222", "abs": "https://arxiv.org/abs/2509.03222", "authors": ["Sophia Bianchi Moyen", "Rickmer Krohn", "Sophie Lueth", "Kay Pompetzki", "Jan Peters", "Vignesh Prasad", "Georgia Chalvatzaki"], "title": "The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation", "categories": ["cs.RO", "cs.HC", "cs.LG"], "comment": "8 pages, 8 figures, Accepted at the IEEE-RAS International Conference\n  on Humanoid Robots (Humanoids) 2025", "summary": "Intuitive Teleoperation interfaces are essential for mobile manipulation\nrobots to ensure high quality data collection while reducing operator workload.\nA strong sense of embodiment combined with minimal physical and cognitive\ndemands not only enhances the user experience during large-scale data\ncollection, but also helps maintain data quality over extended periods. This\nbecomes especially crucial for challenging long-horizon mobile manipulation\ntasks that require whole-body coordination. We compare two distinct robot\ncontrol paradigms: a coupled embodiment integrating arm manipulation and base\nnavigation functions, and a decoupled embodiment treating these systems as\nseparate control entities. Additionally, we evaluate two visual feedback\nmechanisms: immersive virtual reality and conventional screen-based\nvisualization of the robot's field of view. These configurations were\nsystematically assessed across a complex, multi-stage task sequence requiring\nintegrated planning and execution. Our results show that the use of VR as a\nfeedback modality increases task completion time, cognitive workload, and\nperceived effort of the teleoperator. Coupling manipulation and navigation\nleads to a comparable workload on the user as decoupling the embodiments, while\npreliminary experiments suggest that data acquired by coupled teleoperation\nleads to better imitation learning performance. Our holistic view on intuitive\nteleoperation interfaces provides valuable insight into collecting\nhigh-quality, high-dimensional mobile manipulation data at scale with the human\noperator in mind. Project\nwebsite:https://sophiamoyen.github.io/role-embodiment-wbc-moma-teleop/"}
{"id": "2509.03436", "pdf": "https://arxiv.org/pdf/2509.03436", "abs": "https://arxiv.org/abs/2509.03436", "authors": ["Md Mhamud Hussen Sifat", "Md Maruf", "Md Rokunuzzaman"], "title": "Cost-Optimized Systems Engineering for IoT-Enabled Robot Nurse in Infectious Pandemic Management", "categories": ["cs.RO", "cs.HC", "cs.SY", "eess.SY", "I.2.9; C.3; J.3"], "comment": "11 pages, 10 figures, 4 tables, 1 algorithm. Corresponding author: Md\n  Maruf (maruf.mte.17@gmail.com)", "summary": "The utilization of robotic technology has gained traction in healthcare\nfacilities due to progress in the field that enables time and cost savings,\nminimizes waste, and improves patient care. Digital healthcare technologies\nthat leverage automation, such as robotics and artificial intelligence, have\nthe potential to enhance the sustainability and profitability of healthcare\nsystems in the long run. However, the recent COVID-19 pandemic has amplified\nthe need for cyber-physical robots to automate check-ups and medication\nadministration. A robot nurse is controlled by the Internet of Things (IoT) and\ncan serve as an automated medical assistant while also allowing supervisory\ncontrol based on custom commands. This system helps reduce infection risk and\nimproves outcomes in pandemic settings. This research presents a test case with\na nurse robot that can assess a patient's health status and take action\naccordingly. We also evaluate the system's performance in medication\nadministration, health-status monitoring, and life-cycle considerations."}
{"id": "2509.03501", "pdf": "https://arxiv.org/pdf/2509.03501", "abs": "https://arxiv.org/abs/2509.03501", "authors": ["Honglu Zhou", "Xiangyu Peng", "Shrikant Kendre", "Michael S. Ryoo", "Silvio Savarese", "Caiming Xiong", "Juan Carlos Niebles"], "title": "Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "comment": "This technical report serves as the archival version of our paper\n  accepted at the ICCV 2025 Workshop. For more information, please visit our\n  project website: https://strefer.github.io/", "summary": "Next-generation AI companions must go beyond general video understanding to\nresolve spatial and temporal references in dynamic, real-world environments.\nExisting Video Large Language Models (Video LLMs), while capable of\ncoarse-level comprehension, struggle with fine-grained, spatiotemporal\nreasoning, especially when user queries rely on time-based event references for\ntemporal anchoring, or gestural cues for spatial anchoring to clarify object\nreferences and positions. To bridge this critical gap, we introduce Strefer, a\nsynthetic instruction data generation framework designed to equip Video LLMs\nwith spatiotemporal referring and reasoning capabilities. Strefer produces\ndiverse instruction-tuning data using a data engine that pseudo-annotates\ntemporally dense, fine-grained video metadata, capturing rich spatial and\ntemporal information in a structured manner, including subjects, objects, their\nlocations as masklets, and their action descriptions and timelines. Our\napproach enhances the ability of Video LLMs to interpret spatial and temporal\nreferences, fostering more versatile, space-time-aware reasoning essential for\nreal-world AI companions. Without using proprietary models, costly human\nannotation, or the need to annotate large volumes of new videos, experimental\nevaluations show that models trained with data produced by Strefer outperform\nbaselines on tasks requiring spatial and temporal disambiguation. Additionally,\nthese models exhibit enhanced space-time-aware reasoning, establishing a new\nfoundation for perceptually grounded, instruction-tuned Video LLMs."}
