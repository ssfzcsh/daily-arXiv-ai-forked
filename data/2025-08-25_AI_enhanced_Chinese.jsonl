{"id": "2508.15941", "pdf": "https://arxiv.org/pdf/2508.15941", "abs": "https://arxiv.org/abs/2508.15941", "authors": ["Imen Trabelsi", "Brahim Mahmoudi", "Jean Baptiste Minani", "Naouel Moha", "Yann-Ga\u00ebl Gu\u00e9h\u00e9neuc"], "title": "A Systematic Literature Review of Machine Learning Approaches for Migrating Monolithic Systems to Microservices", "categories": ["cs.SE"], "comment": null, "summary": "Scalability and maintainability challenges in monolithic systems have led to\nthe adoption of microservices, which divide systems into smaller, independent\nservices. However, migrating existing monolithic systems to microservices is a\ncomplex and resource-intensive task, which can benefit from machine learning\n(ML) to automate some of its phases. Choosing the right ML approach for\nmigration remains challenging for practitioners. Previous works studied\nseparately the objectives, artifacts, techniques, tools, and benefits and\nchallenges of migrating monolithic systems to microservices. No work has yet\ninvestigated systematically existing ML approaches for this migration to\nunderstand the \\revised{automated migration phases}, inputs used, ML techniques\napplied, evaluation processes followed, and challenges encountered. We present\na systematic literature review (SLR) that aggregates, synthesises, and\ndiscusses the approaches and results of 81 primary studies (PSs) published\nbetween 2015 and 2024. We followed the Preferred Reporting Items for Systematic\nReview and Meta-Analysis (PRISMA) statement to report our findings and answer\nour research questions (RQs). We extract and analyse data from these PSs to\nanswer our RQs. We synthesise the findings in the form of a classification that\nshows the usage of ML techniques in migrating monolithic systems to\nmicroservices. The findings reveal that some phases of the migration process,\nsuch as monitoring and service identification, are well-studied, while others,\nlike packaging microservices, remain unexplored. Additionally, the findings\nhighlight key challenges, including limited data availability, scalability and\ncomplexity constraints, insufficient tool support, and the absence of\nstandardized benchmarking, emphasizing the need for more holistic solutions.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86\u5fae\u670d\u52a1\u8fc1\u79fb\u4e2d\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u5e94\u7528\uff0c\u6307\u51fa\u5f53\u524d\u7814\u7a76\u7684\u4e0d\u8db3\u4e0e\u6311\u6218\uff0c\u5982\u6570\u636e\u6709\u9650\u6027\u548c\u5de5\u5177\u652f\u6301\u4e0d\u8db3\u3002", "motivation": "\u89e3\u51b3\u4ece\u5355\u4f53\u7cfb\u7edf\u8fc1\u79fb\u5230\u5fae\u670d\u52a1\u7684\u590d\u6742\u6027\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u5728\u81ea\u52a8\u5316\u8fc1\u79fb\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\uff0c\u5206\u679081\u7bc72015\u81f32024\u5e74\u7684\u7814\u7a76\uff0c\u4f7f\u7528PRISMA\u6846\u67b6\u62a5\u544a\u7ed3\u679c\u3002", "result": "\u53d1\u73b0\u90e8\u5206\u8fc1\u79fb\u9636\u6bb5\uff08\u5982\u670d\u52a1\u8bc6\u522b\uff09\u7814\u7a76\u8f83\u591a\uff0c\u800c\u5176\u4ed6\u9636\u6bb5\uff08\u5982\u6253\u5305\u5fae\u670d\u52a1\uff09\u4ecd\u6709\u7a7a\u7f3a\uff1b\u4e3b\u8981\u6311\u6218\u5305\u62ec\u6570\u636e\u4e0d\u8db3\u548c\u5de5\u5177\u652f\u6301\u7f3a\u4e4f\u3002", "conclusion": "\u9700\u5f00\u53d1\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u5e94\u5bf9\u5fae\u670d\u52a1\u8fc1\u79fb\u4e2d\u7684\u6311\u6218\uff0c\u586b\u8865\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2508.16025", "pdf": "https://arxiv.org/pdf/2508.16025", "abs": "https://arxiv.org/abs/2508.16025", "authors": ["Saba Naqvi", "Mohammad Baqar"], "title": "Breaking Barriers in Software Testing: The Power of AI-Driven Automation", "categories": ["cs.SE", "cs.AI"], "comment": "10 Pages", "summary": "Software testing remains critical for ensuring reliability, yet traditional\napproaches are slow, costly, and prone to gaps in coverage. This paper presents\nan AI-driven framework that automates test case generation and validation using\nnatural language processing (NLP), reinforcement learning (RL), and predictive\nmodels, embedded within a policy-driven trust and fairness model. The approach\ntranslates natural language requirements into executable tests, continuously\noptimizes them through learning, and validates outcomes with real-time analysis\nwhile mitigating bias. Case studies demonstrate measurable gains in defect\ndetection, reduced testing effort, and faster release cycles, showing that\nAI-enhanced testing improves both efficiency and reliability. By addressing\nintegration and scalability challenges, the framework illustrates how AI can\nshift testing from a reactive, manual process to a proactive, adaptive system\nthat strengthens software quality in increasingly complex environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u5229\u7528NLP\u3001RL\u548c\u9884\u6d4b\u6a21\u578b\u4f18\u5316\u6d4b\u8bd5\u751f\u6210\u4e0e\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u7f3a\u9677\u68c0\u6d4b\u6548\u7387\u548c\u8f6f\u4ef6\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u6d4b\u8bd5\u65b9\u6cd5\u6548\u7387\u4f4e\u3001\u6210\u672c\u9ad8\u4e14\u8986\u76d6\u7387\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u590d\u6742\u8f6f\u4ef6\u9700\u6c42\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528NLP\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u6d4b\u8bd5\u6848\u4f8b\uff0c\u901a\u8fc7RL\u6301\u7eed\u4f18\u5316\u6d4b\u8bd5\u7b56\u7565\uff0c\u5e76\u7ed3\u5408\u5b9e\u65f6\u5206\u6790\u9a8c\u8bc1\u7ed3\u679c\uff0c\u540c\u65f6\u5f15\u5165\u4fe1\u4efb\u4e0e\u516c\u5e73\u6a21\u578b\u51cf\u5c11\u504f\u5dee\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u7f3a\u9677\u68c0\u6d4b\u7387\u3001\u51cf\u5c11\u4e86\u6d4b\u8bd5\u5de5\u4f5c\u91cf\u5e76\u52a0\u901f\u4e86\u53d1\u5e03\u5468\u671f\uff0c\u8bc1\u660e\u4e86AI\u5728\u6d4b\u8bd5\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u6d4b\u8bd5\u4ece\u88ab\u52a8\u3001\u4eba\u5de5\u8fc7\u7a0b\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u3001\u81ea\u9002\u5e94\u7684\u7cfb\u7edf\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e0b\u7684\u8f6f\u4ef6\u8d28\u91cf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u96c6\u6210\u4e0e\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2508.16053", "pdf": "https://arxiv.org/pdf/2508.16053", "abs": "https://arxiv.org/abs/2508.16053", "authors": ["Shadikur Rahman", "Umme Ayman Koana", "Hasibul Karim Shanto", "Mahmuda Akter", "Chitra Roy", "Aras M. Ismael"], "title": "Measuring the effectiveness of code review comments in GitHub repositories: A machine learning approach", "categories": ["cs.SE"], "comment": null, "summary": "This paper illustrates an empirical study of the working efficiency of\nmachine learning techniques in classifying code review text by semantic\nmeaning. The code review comments from the source control repository in GitHub\nwere extracted for development activity from the existing year for three\nopen-source projects. Apart from that, programmers need to be aware of their\ncode and point out their errors. In that case, it is a must to classify the\nsentiment polarity of the code review comments to avoid an error. We manually\nlabelled 13557 code review comments generated by three open source projects in\nGitHub during the existing year. In order to recognize the sentiment polarity\n(or sentiment orientation) of code reviews, we use seven machine learning\nalgorithms and compare those results to find the better ones. Among those\nLinear Support Vector Classifier(SVC) classifier technique achieves higher\naccuracy than others. This study will help programmers to make any solution\nbased on code reviews by avoiding misconceptions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u4e86\u4e03\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u5206\u7c7b\u4ee3\u7801\u5ba1\u67e5\u6587\u672c\u60c5\u611f\u6781\u6027\u4e0a\u7684\u6548\u679c\uff0c\u53d1\u73b0\u7ebf\u6027\u652f\u6301\u5411\u91cf\u5206\u7c7b\u5668\uff08SVC\uff09\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u60c5\u611f\u5206\u7c7b\u6709\u52a9\u4e8e\u7a0b\u5e8f\u5458\u907f\u514d\u8bef\u89e3\u548c\u9519\u8bef\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u3002", "method": "\u4eceGitHub\u4e09\u4e2a\u5f00\u6e90\u9879\u76ee\u4e2d\u63d0\u53d6\u5e76\u624b\u52a8\u6807\u8bb0\u4e8613,557\u6761\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\uff0c\u4f7f\u7528\u4e03\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5206\u7c7b\u6bd4\u8f83\u3002", "result": "\u7ebf\u6027SVC\u5206\u7c7b\u5668\u5728\u60c5\u611f\u6781\u6027\u5206\u7c7b\u4e2d\u51c6\u786e\u7387\u6700\u9ad8\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u7ebf\u6027SVC\u80fd\u6709\u6548\u5206\u7c7b\u4ee3\u7801\u5ba1\u67e5\u60c5\u611f\uff0c\u5e2e\u52a9\u7a0b\u5e8f\u5458\u57fa\u4e8e\u8bc4\u8bba\u505a\u51fa\u66f4\u51c6\u786e\u7684\u51b3\u7b56\u3002"}}
{"id": "2508.16071", "pdf": "https://arxiv.org/pdf/2508.16071", "abs": "https://arxiv.org/abs/2508.16071", "authors": ["Mahinthan Chandramohan", "Jovan Jancic", "Yuntong Zhang", "Padmanabhan Krishnan"], "title": "From Benchmark Data To Applicable Program Repair: An Experience Report", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper describes our approach to automated program repair. We combine\nvarious techniques from the literature to achieve this. Our experiments show\nthat our approach performs better than other techniques on standard benchmarks.\nHowever, on closer inspection, none of these techniques work on realistic\ndefects that we see in industry.\n  We find that augmenting code with formal specifications enables LLMs to\ngenerate higher-quality unit tests, especially for complex production code with\nimproved coverage of edge cases and exception handling. However, specifications\nadd little value for well-understood errors (e.g., null pointer, index out of\nbounds), but are beneficial for logic and string manipulation errors. Despite\nencouraging benchmark results, real-world adoption is limited since passing\ntests do not guarantee correct patches. Current challenges include insufficient\nexpressiveness of the JML specification language, necessitating advanced\nverification tools and richer predicates. Our ongoing work is exploring\ncontract automata, programming by example, and testcase repair, with a focus on\nintegrating human feedback and measuring productivity gains - highlighting the\ngap between academic benchmarks and practical industry needs", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u79cd\u6280\u672f\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5bf9\u5b9e\u9645\u5de5\u4e1a\u7f3a\u9677\u6548\u679c\u6709\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u5728\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u590d\u6742\u751f\u4ea7\u4ee3\u7801\u7684\u4fee\u590d\u3002", "method": "\u7ed3\u5408\u6587\u732e\u4e2d\u7684\u591a\u79cd\u6280\u672f\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u89c4\u8303\u589e\u5f3a\u4ee3\u7801\uff0c\u5229\u7528LLM\u751f\u6210\u9ad8\u8d28\u91cf\u5355\u5143\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f62\u5f0f\u5316\u89c4\u8303\u5bf9\u903b\u8f91\u548c\u5b57\u7b26\u4e32\u9519\u8bef\u6709\u6548\uff0c\u4f46\u5bf9\u7b80\u5355\u9519\u8bef\u65e0\u663e\u8457\u63d0\u5347\uff1b\u771f\u5b9e\u573a\u666f\u91c7\u7528\u53d7\u9650\u3002", "conclusion": "\u9700\u6539\u8fdb\u89c4\u8303\u8bed\u8a00\u7684\u8868\u8fbe\u529b\uff0c\u7ed3\u5408\u4eba\u7c7b\u53cd\u9988\uff0c\u5f25\u5408\u5b66\u672f\u57fa\u51c6\u4e0e\u5de5\u4e1a\u9700\u6c42\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.16024", "pdf": "https://arxiv.org/pdf/2508.16024", "abs": "https://arxiv.org/abs/2508.16024", "authors": ["Prateek Poudel", "Prashant Aryal", "Kirtan Kunwar", "Navin Nepal", "Dinesh Bania Kshatri"], "title": "Wavelet-Space Super-Resolution for Real-Time Rendering", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "We investigate the use of wavelet-space feature decomposition in neural\nsuper-resolution for rendering pipelines. Building on the DFASR framework, we\nintroduce a wavelet-domain representation that separates low- and\nhigh-frequency details before reconstruction, enabling the network to better\npreserve fine textures while maintaining structural consistency. Unlike\nRGB-space regression, our approach leverages the stationary wavelet transform\n(SWT) to avoid spatial down-sampling, ensuring alignment across subbands and\npreserving shift invariance. The model predicts wavelet coefficients\nconditioned on spatial G-buffers and temporally warped history frames, which\nare then recombined through inverse wavelet synthesis. We conduct a\ncomprehensive ablation study across wavelet families, transform types, and\narchitectural variants, showing that incorporating SWT improves PSNR by up to\n1.5 dB and reduces LPIPS by 17% on average, at a computational overhead of\nroughly +24 ms compared to out DFASR baseline. While absolute runtimes on our\nRTX 3050 mobile GPU are higher ( 141ms) than the original DFASR report on RTX\n4090( 11ms), the relative overhead remains modest, suggesting that on\nhigher-end GPUs our method would also remain real-time capable. Taken together,\nour results suggest that wavelet-domain representations are a principled and\neffective way to enhance perceptual quality in neural upscaling for graphics\napplications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u7a7a\u95f4\u7279\u5f81\u5206\u89e3\u7684\u795e\u7ecf\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u91cd\u5efa\u524d\u5206\u79bb\u4f4e\u9891\u548c\u9ad8\u9891\u7ec6\u8282\uff0c\u63d0\u5347\u7eb9\u7406\u4fdd\u7559\u548c\u7ed3\u6784\u4e00\u81f4\u6027\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u4f20\u7edfRGB\u7a7a\u95f4\u56de\u5f52\u5728\u8d85\u5206\u8fa8\u7387\u4e2d\u96be\u4ee5\u540c\u65f6\u4fdd\u7559\u7cbe\u7ec6\u7eb9\u7406\u548c\u7ed3\u6784\u4e00\u81f4\u6027\u7684\u95ee\u9898\uff0c\u5229\u7528\u5c0f\u6ce2\u53d8\u6362\u4f18\u5316\u795e\u7ecf\u6e32\u67d3\u3002", "method": "\u91c7\u7528\u9759\u6b62\u5c0f\u6ce2\u53d8\u6362\uff08SWT\uff09\u907f\u514d\u7a7a\u95f4\u4e0b\u91c7\u6837\uff0c\u901a\u8fc7\u9884\u6d4b\u5c0f\u6ce2\u7cfb\u6570\u5e76\u5408\u6210\u6062\u590d\u56fe\u50cf\uff0c\u7ed3\u5408\u7a7a\u95f4G\u7f13\u51b2\u548c\u65f6\u95f4\u5386\u53f2\u5e27\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSWT\u65b9\u6cd5\u5e73\u5747\u63d0\u53471.5 dB\u7684PSNR\uff0c\u964d\u4f4e17%\u7684LPIPS\uff0c\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\u7ea624ms\u3002", "conclusion": "\u5c0f\u6ce2\u57df\u8868\u793a\u662f\u4e00\u79cd\u63d0\u5347\u56fe\u5f62\u5e94\u7528\u4e2d\u795e\u7ecf\u8d85\u5206\u8fa8\u7387\u611f\u77e5\u8d28\u91cf\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.15866", "pdf": "https://arxiv.org/pdf/2508.15866", "abs": "https://arxiv.org/abs/2508.15866", "authors": ["Lingxiao Li", "Salar Rahili", "Yiwei Zhao"], "title": "Correctness-Guaranteed Code Generation via Constrained Decoding", "categories": ["cs.PL", "cs.LG", "cs.SE"], "comment": "Published at COLM 2025", "summary": "Language Models (LMs) are increasingly being used for code generation, but\nensuring the correctness of generated programs remains a significant challenge.\nAlthough imperfect code may be acceptable during software development with\nhuman oversight, domains such as video games and robotics require one-shot\ncorrectness for runtime-critical components. We present a constrained decoding\nalgorithm for generating semantically correct programs that incorporates a\ncontext-sensitive parser, which, at each step, outputs a regular expression\nthat satisfies a critical non-extensible property to guide the generation of\nthe next token sequence that can continue to a correct program. To build such a\ncontext-sensitive parser, we propose a framework of a dynamic tree of parsers\n(ToP) during parsing, where each parser corresponds to a modular context-free\ngrammar enriched with contextual information such as variable scopes and type\nconstraints, with tree branches representing ambiguity in the future code\nsegment. We demonstrate our approach through sLua, a strongly typed variant of\nLua, showing that our method can generate semantically correct programs\nconforming to any prescribed scripting API. We further show that, with careful\ndesign, our semantic guarantees extend to runtime correctness, as validated in\nthe application of generating game mechanics for a roguelike video game.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ea6\u675f\u89e3\u7801\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u654f\u611f\u89e3\u6790\u5668\u751f\u6210\u8bed\u4e49\u6b63\u786e\u7684\u7a0b\u5e8f\uff0c\u786e\u4fdd\u4e00\u6b21\u6027\u6b63\u786e\u6027\uff0c\u9002\u7528\u4e8e\u6e38\u620f\u548c\u673a\u5668\u4eba\u7b49\u5173\u952e\u9886\u57df\u3002", "motivation": "\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\uff0c\u786e\u4fdd\u751f\u6210\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\u662f\u4e00\u5927\u6311\u6218\uff0c\u5c24\u5176\u5728\u9700\u8981\u4e00\u6b21\u6027\u6b63\u786e\u6027\u7684\u5173\u952e\u9886\u57df\uff08\u5982\u89c6\u9891\u6e38\u620f\u548c\u673a\u5668\u4eba\uff09\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408\u4e0a\u4e0b\u6587\u654f\u611f\u89e3\u6790\u5668\u7684\u7ea6\u675f\u89e3\u7801\u7b97\u6cd5\uff0c\u52a8\u6001\u751f\u6210\u6ee1\u8db3\u975e\u6269\u5c55\u5c5e\u6027\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u4f7f\u7528\u52a8\u6001\u89e3\u6790\u5668\u6811\uff08ToP\uff09\u5904\u7406\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u901a\u8fc7sLua\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u8bed\u4e49\u6b63\u786e\u7684\u7a0b\u5e8f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u6e38\u620f\u673a\u5236\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u786e\u4fdd\u8fd0\u884c\u65f6\u6b63\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u4e00\u6b21\u6027\u6b63\u786e\u7684\u7a0b\u5e8f\uff0c\u9002\u7528\u4e8e\u9700\u9ad8\u53ef\u9760\u6027\u7684\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2508.16148", "pdf": "https://arxiv.org/pdf/2508.16148", "abs": "https://arxiv.org/abs/2508.16148", "authors": ["Ao Zhou", "Zebo Gu", "Tenghao Sun", "Jiawen Chen", "Mingsheng Tu", "Zifeng Cheng", "Yafeng Yin", "Zhiwei Jiang", "Qing Gu"], "title": "Hierarchical Vision-Language Reasoning for Multimodal Multiple-Choice Question Answering", "categories": ["cs.IR", "cs.CL", "cs.MM"], "comment": "This paper has been accepted by ACM MM 2025", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nmultimodal understanding capabilities in Visual Question Answering (VQA) tasks\nby integrating visual and textual features. However, under the challenging\nten-choice question evaluation paradigm, existing methods still exhibit\nsignificant limitations when processing PDF documents with complex layouts and\nlengthy content. Notably, current mainstream models suffer from a strong bias\ntoward English training data, resulting in suboptimal performance for Japanese\nand other language scenarios. To address these challenges, this paper proposes\na novel Japanese PDF document understanding framework that combines multimodal\nhierarchical reasoning mechanisms with Colqwen-optimized retrieval methods,\nwhile innovatively introducing a semantic verification strategy through\nsub-question decomposition. Experimental results demonstrate that our framework\nnot only significantly enhances the model's deep semantic parsing capability\nfor complex documents, but also exhibits superior robustness in practical\napplication scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u6a21\u6001\u5206\u5c42\u63a8\u7406\u548c\u4f18\u5316\u7684\u65e5\u672cPDF\u6587\u6863\u7406\u89e3\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u6587\u6863\u7684\u8bed\u4e49\u89e3\u6790\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709MLLM\u5728\u5904\u7406\u590d\u6742\u5e03\u5c40\u548c\u957f\u7bc7PDF\u6587\u6863\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u65e5\u8bed\u7b49\u975e\u82f1\u8bed\u8bed\u8a00\u7684\u6027\u80fd\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u591a\u6a21\u6001\u5206\u5c42\u63a8\u7406\u673a\u5236\u3001Colqwen\u4f18\u5316\u7684\u68c0\u7d22\u65b9\u6cd5\uff0c\u521b\u65b0\u6027\u5730\u5f15\u5165\u901a\u8fc7\u5b50\u95ee\u9898\u5206\u89e3\u7684\u8bed\u4e49\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6df1\u5ea6\u8bed\u4e49\u89e3\u6790\u80fd\u529b\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u65b0\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742PDF\u6587\u6863\u7684\u7406\u89e3\u95ee\u9898\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u65e5\u8bed\u7b49\u975e\u82f1\u8bed\u8bed\u8a00\u573a\u666f\u3002"}}
{"id": "2508.15856", "pdf": "https://arxiv.org/pdf/2508.15856", "abs": "https://arxiv.org/abs/2508.15856", "authors": ["Mikol\u00e1\u0161 Janota"], "title": "Experimental Results for Vampire on the Equational Theories Project", "categories": ["cs.LO"], "comment": null, "summary": "Equational Theories Project is a collaborative effort, which explores the\nvalidity of certain first-order logic implications of certain kind. The project\nhas been completed but triggered further research. This report investigates how\nmuch can be automatically proven and disproven by the automated theorem prover\nVampire. An interesting conclusion is that Vampire can prove all the considered\nimplications that hold and also is able to refute a vast majority of those that\ndo not hold.", "AI": {"tldr": "\u300a\u7b49\u5f0f\u7406\u8bba\u9879\u76ee\u300b\u901a\u8fc7\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5de5\u5177Vampire\u9a8c\u8bc1\u4e00\u9636\u903b\u8f91\u8574\u542b\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u4e0d\u4ec5\u80fd\u9a8c\u8bc1\u6240\u6709\u6210\u7acb\u7684\u8574\u542b\uff0c\u8fd8\u80fd\u53cd\u9a73\u5927\u90e8\u5206\u4e0d\u6210\u7acb\u7684\u8574\u542b\u3002", "motivation": "\u63a2\u7d22\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5de5\u5177\u5728\u4e00\u9636\u903b\u8f91\u8574\u542b\u9a8c\u8bc1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u4f7f\u7528Vampire\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5de5\u5177\u5bf9\u7279\u5b9a\u7c7b\u578b\u7684\u8574\u542b\u8fdb\u884c\u9a8c\u8bc1\u548c\u53cd\u9a73\u3002", "result": "Vampire\u80fd\u9a8c\u8bc1\u6240\u6709\u6210\u7acb\u7684\u8574\u542b\uff0c\u5e76\u80fd\u53cd\u9a73\u5927\u90e8\u5206\u4e0d\u6210\u7acb\u7684\u8574\u542b\u3002", "conclusion": "\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5de5\u5177\u5728\u903b\u8f91\u9a8c\u8bc1\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u4e14\u5168\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2508.15777", "pdf": "https://arxiv.org/pdf/2508.15777", "abs": "https://arxiv.org/abs/2508.15777", "authors": ["Ortensia Forni", "Alexandre Darmon", "Michael Benzaquen"], "title": "Harmonious Color Pairings: Insights from Human Preference and Natural Hue Statistics", "categories": ["cs.HC", "cs.CV", "physics.soc-ph"], "comment": "7 pages, 7 figures", "summary": "While color harmony has long been studied in art and design, a clear\nconsensus remains elusive, as most models are grounded in qualitative insights\nor limited datasets. In this work, we present a quantitative, data-driven study\nof color pairing preferences using controlled hue-based palettes in the HSL\ncolor space. Participants evaluated combinations of thirteen distinct hues,\nenabling us to construct a preference matrix and define a combinability index\nfor each color. Our results reveal that preferences are highly hue dependent,\nchallenging the assumption of universal harmony rules proposed in the\nliterature. Yet, when averaged over hues, statistically meaningful patterns of\naesthetic preference emerge, with certain hue separations perceived as more\nharmonious. Strikingly, these patterns align with hue distributions found in\nnatural landscapes, pointing to a statistical correspondence between human\ncolor preferences and the structure of color in nature. Together, these\nfindings offer a quantitative framework for studying color harmony and its\npotential perceptual and ecological underpinnings.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9a\u91cf\u7814\u7a76\u63ed\u793a\u4e86\u989c\u8272\u914d\u5bf9\u504f\u597d\u7684\u9ad8\u5ea6\u4f9d\u8d56\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e0e\u81ea\u7136\u666f\u89c2\u989c\u8272\u5206\u5e03\u4e00\u81f4\u7684\u548c\u8c10\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u89e3\u51b3\u8272\u5f69\u548c\u8c10\u7814\u7a76\u4e2d\u5b9a\u6027\u6a21\u578b\u548c\u6709\u9650\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528HSL\u8272\u5f69\u7a7a\u95f4\u4e2d\u7684\u8272\u8c03\u57fa\u7840\u8c03\u8272\u677f\uff0c\u53c2\u4e0e\u8005\u8bc4\u4f30\u4e8613\u79cd\u4e0d\u540c\u8272\u8c03\u7684\u7ec4\u5408\uff0c\u6784\u5efa\u504f\u597d\u77e9\u9635\u548c\u53ef\u7ec4\u5408\u6027\u6307\u6570\u3002", "result": "\u989c\u8272\u504f\u597d\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u8272\u8c03\uff0c\u4f46\u5e73\u5747\u540e\u663e\u73b0\u51fa\u548c\u8c10\u6a21\u5f0f\uff0c\u4e0e\u81ea\u7136\u666f\u89c2\u4e2d\u7684\u8272\u8c03\u5206\u5e03\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8272\u5f69\u548c\u8c10\u53ca\u5176\u611f\u77e5\u548c\u751f\u6001\u57fa\u7840\u63d0\u4f9b\u4e86\u5b9a\u91cf\u6846\u67b6\u3002"}}
{"id": "2508.15814", "pdf": "https://arxiv.org/pdf/2508.15814", "abs": "https://arxiv.org/abs/2508.15814", "authors": ["Marco Calautti", "Ester Livshits", "Andreas Pieris", "Markus Schneider"], "title": "Combined Approximations for Uniform Operational Consistent Query Answering", "categories": ["cs.DB"], "comment": "Expanded version of arXiv:2312.08038", "summary": "Operational consistent query answering (CQA) is a recent framework for CQA\nbased on revised definitions of repairs, which are built by applying a sequence\nof operations (e.g., fact deletions) starting from an inconsistent database\nuntil we reach a database that is consistent w.r.t. the given set of\nconstraints. It has been recently shown that there is an efficient\napproximation for computing the percentage of repairs that entail a given query\nwhen we focus on primary keys, conjunctive queries, and assuming the query is\nfixed (i.e., in data complexity). However, it has been left open whether such\nan approximation exists when the query is part of the input (i.e., in combined\ncomplexity). We show that this is the case when we focus on self-join-free\nconjunctive queries of bounded generelized hypertreewidth. We also show that it\nis unlikely that efficient approximation schemes exist once we give up one of\nthe adopted syntactic restrictions, i.e., self-join-freeness or bounding the\ngenerelized hypertreewidth. Towards the desired approximation, we introduce a\ncounting complexity class, called $\\mathsf{SpanTL}$, show that each problem in\nit admits an efficient approximation scheme by using a recent approximability\nresult about tree automata, and then place the problem of interest in\n$\\mathsf{SpanTL}$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u64cd\u4f5c\u4e00\u81f4\u6027\u67e5\u8be2\u56de\u7b54\uff08CQA\uff09\u6846\u67b6\u4e0b\uff0c\u5bf9\u4e8e\u81ea\u8fde\u63a5\u81ea\u7531\u4e14\u5e7f\u4e49\u8d85\u6811\u5bbd\u5ea6\u6709\u754c\u7684\u8054\u5408\u67e5\u8be2\uff0c\u662f\u5426\u5b58\u5728\u9ad8\u6548\u7684\u67e5\u8be2\u8fd1\u4f3c\u8ba1\u7b97\u65b9\u6848\u3002", "motivation": "\u63a2\u8ba8\u5728\u67e5\u8be2\u4f5c\u4e3a\u8f93\u5165\u7684\u4e00\u90e8\u5206\uff08\u5373\u7ec4\u5408\u590d\u6742\u5ea6\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u9ad8\u6548\u8fd1\u4f3c\u8ba1\u7b97\u6ee1\u8db3\u7ed9\u5b9a\u67e5\u8be2\u7684\u4fee\u590d\u767e\u5206\u6bd4\u3002", "method": "\u5f15\u5165\u8ba1\u6570\u590d\u6742\u6027\u7c7b $\\\\mathsf{SpanTL}$\uff0c\u5e76\u5229\u7528\u6811\u81ea\u52a8\u673a\u7684\u8fd1\u4f3c\u6027\u7ed3\u679c\uff0c\u5c06\u95ee\u9898\u7f6e\u4e8e\u6b64\u7c7b\u4e2d\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u4e0a\u8ff0\u9650\u5236\u6761\u4ef6\u4e0b\uff08\u81ea\u8fde\u63a5\u81ea\u7531\u4e14\u6709\u754c\u5e7f\u4e49\u8d85\u6811\u5bbd\u5ea6\uff09\u5b58\u5728\u9ad8\u6548\u7684\u8fd1\u4f3c\u65b9\u6848\uff1b\u82e5\u653e\u5f03\u4efb\u4e00\u9650\u5236\uff0c\u5219\u4e0d\u53ef\u80fd\u5b58\u5728\u9ad8\u6548\u8fd1\u4f3c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u64cd\u4f5cCQA\u6846\u67b6\u4e0b\u7684\u9ad8\u6548\u67e5\u8be2\u8fd1\u4f3c\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u540c\u65f6\u660e\u786e\u4e86\u9650\u5236\u6761\u4ef6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.16011", "pdf": "https://arxiv.org/pdf/2508.16011", "abs": "https://arxiv.org/abs/2508.16011", "authors": ["Chukwufumnanya Ogbogu", "Gaurav Narang", "Biresh Kumar Joardar", "Janardhan Rao Doppa", "Krishnendu Chakrabarty", "Partha Pratim Pande"], "title": "HePGA: A Heterogeneous Processing-in-Memory based GNN Training Accelerator", "categories": ["cs.ET", "cs.AR", "cs.LG"], "comment": null, "summary": "Processing-In-Memory (PIM) architectures offer a promising approach to\naccelerate Graph Neural Network (GNN) training and inference. However, various\nPIM devices such as ReRAM, FeFET, PCM, MRAM, and SRAM exist, with each device\noffering unique trade-offs in terms of power, latency, area, and\nnon-idealities. A heterogeneous manycore architecture enabled by 3D integration\ncan combine multiple PIM devices on a single platform, to enable\nenergy-efficient and high-performance GNN training. In this work, we propose a\n3D heterogeneous PIM-based accelerator for GNN training referred to as HePGA.\nWe leverage the unique characteristics of GNN layers and associated computing\nkernels to optimize their mapping on to different PIM devices as well as planar\ntiers. Our experimental analysis shows that HePGA outperforms existing\nPIM-based architectures by up to 3.8x and 6.8x in energy-efficiency (TOPS/W)\nand compute efficiency (TOPS/mm2) respectively, without sacrificing the GNN\nprediction accuracy. Finally, we demonstrate the applicability of HePGA to\naccelerate inferencing of emerging transformer models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e3D\u5f02\u6784\u5185\u5b58\u8ba1\u7b97\uff08PIM\uff09\u67b6\u6784\u7684\u52a0\u901f\u5668HePGA\uff0c\u7528\u4e8e\u9ad8\u6548\u8282\u80fd\u5730\u52a0\u901f\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u8bad\u7ec3\uff0c\u5e76\u5728\u6027\u80fd\u548c\u80fd\u6548\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709PIM\u67b6\u6784\u3002", "motivation": "\u73b0\u6709PIM\u8bbe\u5907\uff08\u5982ReRAM\u3001FeFET\u7b49\uff09\u5728\u529f\u8017\u3001\u5ef6\u8fdf\u548c\u9762\u79ef\u7b49\u65b9\u9762\u5b58\u5728\u4e0d\u540c\u7684\u6743\u8861\uff0c\u901a\u8fc73D\u96c6\u6210\u6280\u672f\u5c06\u591a\u79cdPIM\u8bbe\u5907\u7ed3\u5408\u5230\u4e00\u4e2a\u5e73\u53f0\u4e0a\uff0c\u53ef\u4ee5\u4f18\u5316GNN\u8bad\u7ec3\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "method": "\u901a\u8fc7\u5229\u7528GNN\u5c42\u53ca\u5176\u8ba1\u7b97\u6838\u7684\u72ec\u7279\u7279\u6027\uff0c\u5c06\u4efb\u52a1\u4f18\u5316\u6620\u5c04\u5230\u4e0d\u540c\u7684PIM\u8bbe\u5907\u548c\u5e73\u9762\u5c42\u7ea7\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u540d\u4e3aHePGA\u7684\u5f02\u6784PIM\u52a0\u901f\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHePGA\u5728\u80fd\u6548\uff08TOPS/W\uff09\u548c\u8ba1\u7b97\u6548\u7387\uff08TOPS/mm2\uff09\u4e0a\u5206\u522b\u6bd4\u73b0\u6709PIM\u67b6\u6784\u63d0\u5347\u4e863.8\u500d\u548c6.8\u500d\uff0c\u4e14\u4e0d\u5f71\u54cdGNN\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "HePGA\u4e0d\u4ec5\u9002\u7528\u4e8eGNN\u8bad\u7ec3\uff0c\u8fd8\u80fd\u52a0\u901f\u65b0\u5174Transformer\u6a21\u578b\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.15940", "pdf": "https://arxiv.org/pdf/2508.15940", "abs": "https://arxiv.org/abs/2508.15940", "authors": ["Ahmed Allam", "Youssef Mansour", "Mohamed Shalan"], "title": "ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.DC", "cs.MA"], "comment": "2025 IEEE International Conference on LLM-Aided Design (ICLAD)", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nRegister Transfer Level (RTL) design, enabling high-quality code generation\nfrom natural language descriptions. However, LLMs alone face significant\nlimitations in real-world hardware design workflows, including the inability to\nexecute code, lack of debugging capabilities, and absence of long-term memory.\nTo address these challenges, we present ASIC-Agent, an autonomous system\ndesigned specifically for digital ASIC design tasks. ASIC-Agent enhances base\nLLMs with a multi-agent architecture incorporating specialized sub-agents for\nRTL generation, verification, OpenLane hardening, and Caravel chip integration,\nall operating within a comprehensive sandbox environment with access to\nessential hardware design tools. The system leverages a vector database\ncontaining documentation, API references, error knowledge, and curated insights\nfrom the open-source silicon community. To evaluate ASIC-Agent's performance,\nwe introduce ASIC-Agent-Bench, the first benchmark specifically designed to\nassess agentic systems in hardware design tasks. We evaluate ASIC-Agent with\nvarious base LLMs, providing quantitative comparisons and qualitative insights\ninto agent behavior across different design scenarios. Our results demonstrate\nthat ASIC-Agent, when powered by Claude 4 Sonnet, successfully automates a\nbroad range of ASIC design tasks spanning varying levels of complexity, showing\nthe potential of significantly accelerating the ASIC design workflow.", "AI": {"tldr": "ASIC-Agent\u662f\u4e00\u4e2a\u4e3a\u6570\u5b57ASIC\u8bbe\u8ba1\u4efb\u52a1\u8bbe\u8ba1\u7684\u81ea\u4e3b\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u67b6\u6784\u589e\u5f3a\u57fa\u7840LLM\uff0c\u89e3\u51b3\u5176\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u663e\u8457\u52a0\u901fASIC\u8bbe\u8ba1\u6d41\u7a0b\u7684\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728RTL\u8bbe\u8ba1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5b9e\u9645\u786c\u4ef6\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u5b58\u5728\u4ee3\u7801\u6267\u884c\u3001\u8c03\u8bd5\u80fd\u529b\u548c\u957f\u671f\u8bb0\u5fc6\u7684\u4e0d\u8db3\uff0cASIC-Agent\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "ASIC-Agent\u91c7\u7528\u591a\u4ee3\u7406\u67b6\u6784\uff0c\u5305\u542bRTL\u751f\u6210\u3001\u9a8c\u8bc1\u3001OpenLane\u786c\u5316\u548cCaravel\u82af\u7247\u96c6\u6210\u7b49\u5b50\u4ee3\u7406\uff0c\u5e76\u5229\u7528\u5305\u542b\u793e\u533a\u77e5\u8bc6\u548c\u5de5\u5177\u7684\u5411\u91cf\u6570\u636e\u5e93\u3002", "result": "ASIC-Agent\u4e0eClaude 4 Sonnet\u7ed3\u5408\uff0c\u80fd\u81ea\u52a8\u5316\u5b8c\u6210\u591a\u79cd\u590d\u6742\u5ea6\u7684ASIC\u8bbe\u8ba1\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u52a0\u901f\u8bbe\u8ba1\u6d41\u7a0b\u7684\u6f5c\u529b\u3002", "conclusion": "ASIC-Agent\u901a\u8fc7\u591a\u4ee3\u7406\u67b6\u6784\u548c\u793e\u533a\u8d44\u6e90\u6574\u5408\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15919", "pdf": "https://arxiv.org/pdf/2508.15919", "abs": "https://arxiv.org/abs/2508.15919", "authors": ["Zahra Yousefijamarani", "Xinglu Wang", "Qian Wang", "Morgan Lindsay Heisler", "Taha Shabani", "Niloofar Gholipour", "Parham Yassini", "Hong Chang", "Kan Chen", "Qiantao Zhang", "Xiaolong Bai", "Jiannan Wang", "Ying Xiong", "Yong Zhang", "Zhenan Fan"], "title": "HyperFlexis: Joint Design of Algorithms and Systems for Multi-SLO Serving and Fast Scaling", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Modern large language model (LLM) serving systems face challenges from highly\nvariable requests with diverse lengths, priorities, and stage-specific\nservice-level objectives (SLOs). Meeting these requires real-time scheduling,\nrapid and cost-effective scaling, and support for both collocated and\ndisaggregated Prefill/Decode (P/D) architectures.\n  We present \\textbf{HyperFlexis}, a unified LLM serving system that integrates\nalgorithmic and system-level innovations to jointly optimize scheduling and\nscaling under multiple SLOs. It features a multi-SLO-aware scheduler that\nleverages budget estimation and request prioritization to ensure proactive SLO\ncompliance for both new and ongoing requests. The system supports prefill- and\ndecode-stage multi-SLO scheduling for P/D-disaggregated architectures and KV\ncache transfers. It also enables cost-effective scaling decisions,\nprefill-decode instance linking during scaling, and rapid P/D role transitions.\nTo accelerate scaling and reduce cold-start latency, a device-to-device (D2D)\nweight transfer mechanism is proposed that lowers weight loading overhead by up\nto \\textbf{19.39$\\times$}. These optimizations allow the system to achieve up\nto \\textbf{4.44$\\times$} higher SLO attainment, \\textbf{65.82\\%} lower request\nlatency, and cost parity with state-of-the-art baselines. The code will be\nreleased soon.", "AI": {"tldr": "HyperFlexis\u662f\u4e00\u4e2a\u7edf\u4e00\u7684LLM\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u7b97\u6cd5\u548c\u7cfb\u7edf\u7ea7\u521b\u65b0\u4f18\u5316\u8c03\u5ea6\u548c\u6269\u5c55\uff0c\u652f\u6301\u591aSLO\u8c03\u5ea6\u3001\u9ad8\u6548\u6269\u5c55\u548cKV\u7f13\u5b58\u4f20\u8f93\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u73b0\u4ee3LLM\u670d\u52a1\u7cfb\u7edf\u9762\u4e34\u7684\u8bf7\u6c42\u591a\u6837\u6027\u3001\u4f18\u5148\u7ea7\u548c\u670d\u52a1\u7ea7\u76ee\u6807\uff08SLO\uff09\u591a\u53d8\u6027\u7684\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u591aSLO\u611f\u77e5\u8c03\u5ea6\u5668\u3001\u6210\u672c\u6548\u76ca\u6269\u5c55\u51b3\u7b56\u3001\u9884\u586b\u5145-\u89e3\u7801\u5b9e\u4f8b\u94fe\u63a5\uff0c\u4ee5\u53caD2D\u6743\u91cd\u4f20\u8f93\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u6700\u9ad84.44\u500d\u7684SLO\u8fbe\u6210\u7387\u63d0\u5347\uff0c65.82%\u7684\u5ef6\u8fdf\u964d\u4f4e\uff0c\u5e76\u4fdd\u6301\u4e0e\u73b0\u6709\u6280\u672f\u6210\u672c\u6301\u5e73\u3002", "conclusion": "HyperFlexis\u901a\u8fc7\u9ad8\u6548\u8c03\u5ea6\u548c\u6269\u5c55\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u670d\u52a1\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2508.15980", "pdf": "https://arxiv.org/pdf/2508.15980", "abs": "https://arxiv.org/abs/2508.15980", "authors": ["Yiwei Yang", "Yusheng Zheng", "Yiqi Chen", "Zheng Liang", "Kexin Chu", "Zhe Zhou", "Andi Quinn", "Wei Zhang"], "title": "CXLAimPod: CXL Memory is all you need in AI era", "categories": ["cs.OS"], "comment": null, "summary": "The proliferation of data-intensive applications, ranging from large language\nmodels to key-value stores, increasingly stresses memory systems with mixed\nread-write access patterns. Traditional half-duplex architectures such as DDR5\nare ill-suited for such workloads, suffering bus turnaround penalties that\nreduce their effective bandwidth under mixed read-write patterns. Compute\nExpress Link (CXL) offers a breakthrough with its full-duplex channels, yet\nthis architectural potential remains untapped as existing software stacks are\noblivious to this capability. This paper introduces CXLAimPod, an adaptive\nscheduling framework designed to bridge this software-hardware gap through\nsystem support, including cgroup-based hints for application-aware\noptimization. Our characterization quantifies the opportunity, revealing that\nCXL systems achieve 55-61% bandwidth improvement at balanced read-write ratios\ncompared to flat DDR5 performance, demonstrating the benefits of full-duplex\narchitecture. To realize this potential, the CXLAimPod framework integrates\nmultiple scheduling strategies with a cgroup-based hint mechanism to navigate\nthe trade-offs between throughput, latency, and overhead. Implemented\nefficiently within the Linux kernel via eBPF, CXLAimPod delivers significant\nperformance improvements over default CXL configurations. Evaluation on diverse\nworkloads shows 7.4% average improvement for Redis (with up to 150% for\nspecific sequential patterns), 71.6% improvement for LLM text generation, and\n9.1% for vector databases, demon-strating that duplex-aware scheduling can\neffectively exploit CXL's architectural advantages.", "AI": {"tldr": "CXLAimPod \u662f\u4e00\u79cd\u81ea\u9002\u5e94\u8c03\u5ea6\u6846\u67b6\uff0c\u5229\u7528 CXL \u7684\u5168\u53cc\u5de5\u901a\u9053\u63d0\u5347\u5185\u5b58\u7cfb\u7edf\u6027\u80fd\uff0c\u5bf9\u6bd4 DDR5 \u5728\u6df7\u5408\u8bfb\u5199\u6a21\u5f0f\u4e0b\u5e26\u5bbd\u63d0\u5347 55-61%\uff0c\u5e76\u5728\u591a\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf DDR5 \u67b6\u6784\u5728\u6df7\u5408\u8bfb\u5199\u6a21\u5f0f\u4e0b\u56e0\u603b\u7ebf\u8f6c\u5411\u60e9\u7f5a\u800c\u5e26\u5bbd\u53d7\u9650\uff0cCXL \u7684\u5168\u53cc\u5de5\u901a\u9053\u6f5c\u529b\u672a\u88ab\u73b0\u6709\u8f6f\u4ef6\u6808\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51fa CXLAimPod \u6846\u67b6\uff0c\u7ed3\u5408 cgroup \u63d0\u793a\u548c\u591a\u79cd\u8c03\u5ea6\u7b56\u7565\uff0c\u901a\u8fc7 Linux \u5185\u6838 eBPF \u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\u3002", "result": "\u5728 Redis\u3001LLM \u6587\u672c\u751f\u6210\u548c\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u5206\u522b\u83b7\u5f97 7.4%\u300171.6% \u548c 9.1% \u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CXLAimPod \u80fd\u6709\u6548\u6316\u6398 CXL \u67b6\u6784\u6f5c\u529b\uff0c\u663e\u8457\u63d0\u5347\u5185\u5b58\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.16293", "pdf": "https://arxiv.org/pdf/2508.16293", "abs": "https://arxiv.org/abs/2508.16293", "authors": ["Yang Li", "Xing Zhang", "Yunji Zhao", "Wenbo Wang"], "title": "Two-Timescale Dynamic Service Deployment and Task Scheduling with Spatiotemporal Collaboration in Mobile Edge Networks", "categories": ["cs.PF"], "comment": "This paper is accepted by IEEE Globecom 2025", "summary": "Collaborative edge computing addresses the resource constraints of individual\nedge nodes by enabling resource sharing and task co-processing across multiple\nnodes. To fully leverage the advantages of collaborative edge computing, joint\noptimization of service deployment and task scheduling is necessary. Existing\noptimization methods insufficiently address the collaboration across spatial\nand temporal dimensions, which hinders their adaptability to the\nspatiotemporally varying nature of user demands and system states. This paper\nfocuses on optimizing the expected task processing delay in edge networks. We\npropose a two-timescale online optimization framework to jointly determine: i)\nservice deployment decisions at each large timescale; and ii) task scheduling\ndecisions at each small timescale. Specifically, the convex optimization\ntechnique is used to solve the task scheduling problem, while a multi-agent\ndeep reinforcement learning technique is employed for the service deployment\nproblem. These two methods are combined for spatiotemporal co-optimization\nthrough a two-timescale alternating optimization approach. Compared to the\nbaseline algorithms, the proposed scheme achieves better delay performance,\nwhile also exhibiting low running time and favorable convergence behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u65f6\u95f4\u5c3a\u5ea6\u7684\u5728\u7ebf\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u670d\u52a1\u90e8\u7f72\u548c\u4efb\u52a1\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u8d44\u6e90\u5206\u914d\u7684\u65f6\u7a7a\u52a8\u6001\u6027\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4efb\u52a1\u5904\u7406\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u7684\u8fb9\u7f18\u8ba1\u7b97\u4f18\u5316\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u65f6\u7a7a\u7ef4\u5ea6\u7684\u534f\u4f5c\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u7528\u6237\u9700\u6c42\u548c\u7cfb\u7edf\u72b6\u6001\u52a8\u6001\u53d8\u5316\u7684\u9002\u5e94\u6027\u3002\u4e3a\u4e86\u5145\u5206\u5229\u7528\u534f\u4f5c\u8fb9\u7f18\u8ba1\u7b97\u7684\u4f18\u52bf\uff0c\u9700\u8981\u8fdb\u884c\u8054\u5408\u4f18\u5316\u3002", "method": "\u91c7\u7528\u51f8\u4f18\u5316\u6280\u672f\u89e3\u51b3\u4efb\u52a1\u8c03\u5ea6\u95ee\u9898\uff0c\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u89e3\u51b3\u670d\u52a1\u90e8\u7f72\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u65f6\u95f4\u5c3a\u5ea6\u7684\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u65f6\u7a7a\u534f\u540c\u4f18\u5316\u3002", "result": "\u4e0e\u57fa\u7ebf\u7b97\u6cd5\u76f8\u6bd4\uff0c\u63d0\u51fa\u7684\u65b9\u6848\u5728\u5ef6\u8fdf\u6027\u80fd\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u5177\u6709\u8f83\u4f4e\u7684\u8fd0\u884c\u65f6\u95f4\u548c\u826f\u597d\u7684\u6536\u655b\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u548c\u4efb\u52a1\u8c03\u5ea6\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65f6\u7a7a\u534f\u540c\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.15795", "pdf": "https://arxiv.org/pdf/2508.15795", "abs": "https://arxiv.org/abs/2508.15795", "authors": ["Yanheng Liu", "Dalin Li", "Hao Wu", "Zemin Sun", "Weihong Qin", "Jun Li", "Hongyang Du", "Geng Sun"], "title": "Task Offloading and Resource Allocation for MEC-assisted Consumer Internet of Vehicle Systems", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Mobile edge computing (MEC)-assisted internet of vehicle (IoV) is emerging as\na promising paradigm to provide computing services for vehicles. However,\nmeeting the computing-sensitive and computation-intensive demands of vehicles\nposes several challenges, including the discrepancy between the limited\nresource provision and stringent computing requirement, the difficulty in\ncapturing and integrating the intricate features of the MEC-assisted IoV system\ninto the problem formulation, and the need for real-time processing and\nefficient resource management in the dynamic environment. In this work, we\nexplore the AI-enabled task offloading and resource allocation for MEC-assisted\nconsumer IoV systems. Specifically, we first present a multi-MEC-assisted\nconsumer IoV architecture that leverages the computational resources of MEC\nservers to provide offloading services close to vehicles. Subsequently, we\nformulate a system cost minimization optimization problem (SCMOP) by\nintegrating the service delay and energy consumption. To efficiently solve this\nproblem, we design a joint task offloading and computing resource allocation\napproach (JTOCRA) by applying the multi-agent deep deterministic policy\ngradient (MADDPG) algorithm. Finally, simulation results demonstrate that the\nproposed JTOCRA can achieve superior system performances and exhibits better\nscalability compared to other alternative approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdAI\u9a71\u52a8\u7684\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\uff08JTOCRA\uff09\uff0c\u7528\u4e8eMEC\u8f85\u52a9\u7684\u8f66\u8054\u7f51\u7cfb\u7edf\uff0c\u4ee5\u89e3\u51b3\u8d44\u6e90\u6709\u9650\u4e0e\u9ad8\u8ba1\u7b97\u9700\u6c42\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "motivation": "\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u8f85\u52a9\u7684\u8f66\u8054\u7f51\uff08IoV\uff09\u9700\u8981\u6ee1\u8db3\u8f66\u8f86\u7684\u9ad8\u8ba1\u7b97\u9700\u6c42\uff0c\u4f46\u8d44\u6e90\u6709\u9650\u3001\u52a8\u6001\u73af\u5883\u590d\u6742\uff0c\u4e9f\u9700\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08MADDPG\uff09\u7684\u8054\u5408\u4efb\u52a1\u5378\u8f7d\u4e0e\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\uff08JTOCRA\uff09\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cJTOCRA\u5728\u7cfb\u7edf\u6027\u80fd\u548c\u6269\u5c55\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "JTOCRA\u80fd\u6709\u6548\u4f18\u5316MEC\u8f85\u52a9\u8f66\u8054\u7f51\u7cfb\u7edf\u7684\u670d\u52a1\u5ef6\u65f6\u548c\u80fd\u8017\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.16104", "pdf": "https://arxiv.org/pdf/2508.16104", "abs": "https://arxiv.org/abs/2508.16104", "authors": ["Arturo Miguel Russell Bernal", "Maureen Petterson", "Pedro Antonio Alarcon Granadeno", "Michael Murphy", "James Mason", "Jane Cleland-Huang"], "title": "Validating Terrain Models in Digital Twins for Trustworthy sUAS Operations", "categories": ["cs.SE", "cs.RO"], "comment": "Submitted to EDTconf 2025", "summary": "With the increasing deployment of small Unmanned Aircraft Systems (sUAS) in\nunfamiliar and complex environments, Environmental Digital Twins (EDT) that\ncomprise weather, airspace, and terrain data are critical for safe flight\nplanning and for maintaining appropriate altitudes during search and\nsurveillance operations. With the expansion of sUAS capabilities through edge\nand cloud computing, accurate EDT are also vital for advanced sUAS\ncapabilities, like geolocation. However, real-world sUAS deployment introduces\nsignificant sources of uncertainty, necessitating a robust validation process\nfor EDT components. This paper focuses on the validation of terrain models, one\nof the key components of an EDT, for real-world sUAS tasks. These models are\nconstructed by fusing U.S. Geological Survey (USGS) datasets and satellite\nimagery, incorporating high-resolution environmental data to support mission\ntasks. Validating both the terrain models and their operational use by sUAS\nunder real-world conditions presents significant challenges, including limited\ndata granularity, terrain discontinuities, GPS and sensor inaccuracies, visual\ndetection uncertainties, as well as onboard resources and timing constraints.\nWe propose a 3-Dimensions validation process grounded in software engineering\nprinciples, following a workflow across granularity of tests, simulation to\nreal world, and the analysis of simple to edge conditions. We demonstrate our\napproach using a multi-sUAS platform equipped with a Terrain-Aware Digital\nShadow.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\u7684\u4e09\u7ef4\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u7528\u4e8e\u9a8c\u8bc1\u5c0f\u65e0\u4eba\u673a\u7cfb\u7edf\uff08sUAS\uff09\u73af\u5883\u6570\u5b57\u5b6a\u751f\uff08EDT\uff09\u4e2d\u7684\u5730\u5f62\u6a21\u578b\uff0c\u4ee5\u652f\u6301\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u3002", "motivation": "\u968f\u7740\u5c0f\u65e0\u4eba\u673a\u7cfb\u7edf\uff08sUAS\uff09\u5728\u964c\u751f\u590d\u6742\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u73af\u5883\u6570\u5b57\u5b6a\u751f\uff08EDT\uff09\u5bf9\u98de\u884c\u5b89\u5168\u548c\u4efb\u52a1\u6267\u884c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u8bf8\u591a\u4e0d\u786e\u5b9a\u56e0\u7d20\uff0c\u9700\u8981\u9a8c\u8bc1\u5176\u5173\u952e\u7ec4\u4ef6\u5982\u5730\u5f62\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u878d\u5408\u7f8e\u56fd\u5730\u8d28\u8c03\u67e5\u5c40\uff08USGS\uff09\u6570\u636e\u96c6\u548c\u536b\u661f\u56fe\u50cf\u6784\u5efa\u9ad8\u5206\u8fa8\u7387\u5730\u5f62\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u7684\u4e09\u7ef4\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u6d4b\u8bd5\u4ece\u4eff\u771f\u5230\u771f\u5b9e\u73af\u5883\u7684\u4e0d\u540c\u7c92\u5ea6\u548c\u6761\u4ef6\u3002", "result": "\u9a8c\u8bc1\u4e86\u5730\u5f62\u6a21\u578b\u53ca\u5176\u5728\u5c0f\u65e0\u4eba\u673a\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7c92\u5ea6\u4e0d\u8db3\u3001\u4f20\u611f\u5668\u8bef\u5dee\u7b49\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u7ef4\u9a8c\u8bc1\u6d41\u7a0b\u4e3a\u5c0f\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u5730\u5f62\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u652f\u6301\u5176\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u4f7f\u7528\u3002"}}
{"id": "2508.16401", "pdf": "https://arxiv.org/pdf/2508.16401", "abs": "https://arxiv.org/abs/2508.16401", "authors": ["NVIDIA", ":", "Chaeyeon Chung", "Ilya Fedorov", "Michael Huang", "Aleksey Karmanov", "Dmitry Korobchenko", "Roger Ribera", "Yeongho Seol"], "title": "Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars", "categories": ["cs.GR", "cs.HC", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Audio-driven facial animation presents an effective solution for animating\ndigital avatars. In this paper, we detail the technical aspects of NVIDIA\nAudio2Face-3D, including data acquisition, network architecture, retargeting\nmethodology, evaluation metrics, and use cases. Audio2Face-3D system enables\nreal-time interaction between human users and interactive avatars, facilitating\nfacial animation authoring for game characters. To assist digital avatar\ncreators and game developers in generating realistic facial animations, we have\nopen-sourced Audio2Face-3D networks, SDK, training framework, and example\ndataset.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86NVIDIA Audio2Face-3D\u6280\u672f\uff0c\u65e8\u5728\u901a\u8fc7\u97f3\u9891\u9a71\u52a8\u751f\u62103D\u9762\u90e8\u52a8\u753b\uff0c\u652f\u6301\u5b9e\u65f6\u4eba\u673a\u4ea4\u4e92\uff0c\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u89e3\u51b3\u6570\u5b57\u865a\u62df\u89d2\u8272\u7684\u9762\u90e8\u52a8\u753b\u5236\u4f5c\u95ee\u9898\uff0c\u63d0\u5347\u5b9e\u65f6\u4e92\u52a8\u7684\u771f\u5b9e\u6027\u548c\u6548\u7387\uff0c\u670d\u52a1\u4e8e\u6e38\u620f\u5f00\u53d1\u548c\u6570\u5b57\u865a\u62df\u89d2\u8272\u521b\u4f5c\u3002", "method": "\u5305\u62ec\u6570\u636e\u91c7\u96c6\u3001\u7f51\u7edc\u67b6\u6784\u8bbe\u8ba1\u3001\u52a8\u4f5c\u91cd\u5b9a\u5411\u65b9\u6cd5\u3001\u8bc4\u4f30\u6307\u6807\u548c\u4f7f\u7528\u6848\u4f8b\u7684\u4ecb\u7ecd\u3002", "result": "\u5b9e\u73b0\u4e86\u97f3\u9891\u9a71\u52a8\u7684\u5b9e\u65f63D\u9762\u90e8\u52a8\u753b\u751f\u6210\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002", "conclusion": "Audio2Face-3D\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u6570\u5b57\u865a\u62df\u89d2\u8272\u9762\u90e8\u52a8\u753b\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.15898", "pdf": "https://arxiv.org/pdf/2508.15898", "abs": "https://arxiv.org/abs/2508.15898", "authors": ["Matthew Sotoudeh", "Zachary Yedidia"], "title": "Automated Formal Verification of a Software Fault Isolation System", "categories": ["cs.PL", "cs.CR"], "comment": "Short paper to appear at FMCAD 2025, https://fmcad.org/", "summary": "Software fault isolation (SFI) is a popular way to sandbox untrusted\nsoftware. A key component of SFI is the verifier that checks the untrusted code\nis written in a subset of the machine language that guarantees it never reads\nor writes outside of a region of memory dedicated to the sandbox. Soundness\nbugs in the SFI verifier would break the SFI security model and allow the\nsupposedly sandboxed code to read protected memory. In this paper, we address\nthe concern of SFI verifier bugs by performing an automated formal verification\nof a recent SFI system called Lightweight Fault Isolation (LFI). In particular,\nwe formally verify that programs accepted by the LFI verifier never read or\nwrite to memory outside of a designated sandbox region.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5bf9\u8f7b\u91cf\u7ea7\u6545\u969c\u9694\u79bb\uff08LFI\uff09\u7cfb\u7edf\u8fdb\u884c\u81ea\u52a8\u5316\u5f62\u5f0f\u9a8c\u8bc1\u7684\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fdd\u5176\u9a8c\u8bc1\u5668\u65e0\u6f0f\u6d1e\uff0c\u4fdd\u969c\u8f6f\u4ef6\u6545\u969c\u9694\u79bb\uff08SFI\uff09\u7684\u5b89\u5168\u6027\u3002", "motivation": "SFI\u9a8c\u8bc1\u5668\u7684\u6f5c\u5728\u6f0f\u6d1e\u53ef\u80fd\u7834\u574f\u5176\u5b89\u5168\u6a21\u578b\uff0c\u5141\u8bb8\u6c99\u76d2\u4ee3\u7801\u8bbf\u95ee\u53d7\u4fdd\u62a4\u5185\u5b58\uff0c\u56e0\u6b64\u9700\u8981\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4ee5\u786e\u4fdd\u5176\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u5f62\u5f0f\u9a8c\u8bc1\u6280\u672f\uff0c\u5bf9LFI\u9a8c\u8bc1\u5668\u8fdb\u884c\u68c0\u67e5\uff0c\u9a8c\u8bc1\u5176\u662f\u5426\u80fd\u786e\u4fdd\u7a0b\u5e8f\u4ec5\u8bbf\u95ee\u6307\u5b9a\u7684\u6c99\u76d2\u5185\u5b58\u533a\u57df\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86LFI\u7cfb\u7edf\u7684\u6b63\u786e\u6027\uff0c\u5373\u5176\u9a8c\u8bc1\u5668\u786e\u5b9e\u80fd\u9632\u6b62\u7a0b\u5e8f\u8bbf\u95ee\u6c99\u76d2\u5916\u7684\u5185\u5b58\u3002", "conclusion": "\u5f62\u5f0f\u9a8c\u8bc1\u662f\u786e\u4fddSFI\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0cLFI\u9a8c\u8bc1\u5668\u7684\u53ef\u9760\u6027\u5f97\u5230\u4e86\u8bc1\u660e\u3002"}}
{"id": "2508.16448", "pdf": "https://arxiv.org/pdf/2508.16448", "abs": "https://arxiv.org/abs/2508.16448", "authors": ["Lianchen Jia", "Chaoyang Li", "Ziqi Yuan", "Jiahui Chen", "Tianchi Huang", "Jiangchuan Liu", "Lifeng Sun"], "title": "Beyond Interpretability: Exploring the Comprehensibility of Adaptive Video Streaming through Large Language Models", "categories": ["cs.MM", "cs.LG", "eess.IV"], "comment": "ACM Multimedia2025", "summary": "Over the past decade, adaptive video streaming technology has witnessed\nsignificant advancements, particularly driven by the rapid evolution of deep\nlearning techniques. However, the black-box nature of deep learning algorithms\npresents challenges for developers in understanding decision-making processes\nand optimizing for specific application scenarios. Although existing research\nhas enhanced algorithm interpretability through decision tree conversion,\ninterpretability does not directly equate to developers' subjective\ncomprehensibility. To address this challenge, we introduce \\texttt{ComTree},\nthe first bitrate adaptation algorithm generation framework that considers\ncomprehensibility. The framework initially generates the complete set of\ndecision trees that meet performance requirements, then leverages large\nlanguage models to evaluate these trees for developer comprehensibility,\nultimately selecting solutions that best facilitate human understanding and\nenhancement. Experimental results demonstrate that \\texttt{ComTree}\nsignificantly improves comprehensibility while maintaining competitive\nperformance, showing potential for further advancement. The source code is\navailable at https://github.com/thu-media/ComTree.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aComTree\u7684\u6bd4\u7279\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u751f\u6210\u6846\u67b6\uff0c\u5f3a\u8c03\u5f00\u53d1\u8005\u7406\u89e3\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u51b3\u7b56\u6811\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7b97\u6cd5\u7684\u53ef\u7406\u89e3\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7684\u9ed1\u76d2\u7279\u6027\u4f7f\u5f00\u53d1\u8005\u96be\u4ee5\u7406\u89e3\u5176\u51b3\u7b56\u8fc7\u7a0b\uff0c\u73b0\u6709\u7814\u7a76\u901a\u8fc7\u51b3\u7b56\u6811\u8f6c\u6362\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u8fd9\u5e76\u4e0d\u76f4\u63a5\u7b49\u540c\u4e8e\u5f00\u53d1\u8005\u7684\u4e3b\u89c2\u7406\u89e3\u6027\u3002", "method": "ComTree\u6846\u67b6\u9996\u5148\u751f\u6210\u6ee1\u8db3\u6027\u80fd\u8981\u6c42\u7684\u51b3\u7b56\u6811\u5168\u96c6\uff0c\u7136\u540e\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8fd9\u4e9b\u6811\u7684\u5f00\u53d1\u8005\u7406\u89e3\u6027\uff0c\u6700\u7ec8\u9009\u62e9\u6700\u6613\u4e8e\u4eba\u7c7b\u7406\u89e3\u548c\u4f18\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cComTree\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u7b97\u6cd5\u7684\u53ef\u7406\u89e3\u6027\uff0c\u5c55\u73b0\u51fa\u8fdb\u4e00\u6b65\u6539\u8fdb\u7684\u6f5c\u529b\u3002", "conclusion": "ComTree\u901a\u8fc7\u7ed3\u5408\u51b3\u7b56\u6811\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u9996\u6b21\u5728\u6bd4\u7279\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u4e2d\u5b9e\u73b0\u4e86\u5f00\u53d1\u8005\u7406\u89e3\u6027\u7684\u63d0\u5347\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.15878", "pdf": "https://arxiv.org/pdf/2508.15878", "abs": "https://arxiv.org/abs/2508.15878", "authors": ["Terry Jingchen Zhang", "Wenyuan Jiang", "Rongchuan Liu", "Yisong Wang", "Junran Yang", "Ning Wang", "Nicole Ni", "Yinya Huang", "Mrinmaya Sachan"], "title": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "categories": ["cs.LO", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted to AI4MATH@ICML2025", "summary": "Formal theorem proving (FTP) has emerged as a critical foundation for\nevaluating the reasoning capabilities of large language models, enabling\nautomated verification of mathematical proofs at scale. However, progress has\nbeen constrained by limited datasets due to the high cost of manual curation\nand the scarcity of challenging problems with verified formal-informal\ncorrespondences. We propose leveraging theoretical computer science (TCS) as a\nscalable source of rigorous proof problems, where algorithmic definitions\nenable automated generation of arbitrarily many challenging theorem-proof\npairs. We demonstrate this approach on two TCS domains: Busy Beaver problems,\nwhich involve proving bounds on Turing machine halting behavior, and Mixed\nBoolean Arithmetic problems, which combine logical and arithmetic reasoning.\nOur framework automatically synthesizes problems with parallel formal (Lean4)\nand informal (Markdown) specifications, creating a scalable pipeline for\ngenerating verified proof challenges. Evaluation on frontier models reveals\nsubstantial gaps in automated theorem proving: while DeepSeekProver-V2-671B\nachieves 57.5\\% success on Busy Beaver problems, it manages only 12\\% on Mixed\nBoolean Arithmetic problems. These results highlight the difficulty of\nlong-form proof generation even for problems that are computationally easy to\nverify, demonstrating the value of TCS domains for advancing automated\nreasoning research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5229\u7528\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\uff08TCS\uff09\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u4e25\u683c\u8bc1\u660e\u95ee\u9898\u6765\u6e90\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u5b9a\u7406-\u8bc1\u660e\u5bf9\u6765\u89e3\u51b3\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\uff08FTP\uff09\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u6570\u636e\u96c6\u56e0\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u548c\u6311\u6218\u6027\u95ee\u9898\u7a00\u7f3a\u800c\u53d7\u9650\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u751f\u6210\u9a8c\u8bc1\u8fc7\u7684\u5b9a\u7406-\u8bc1\u660e\u5bf9\u3002", "method": "\u91c7\u7528TCS\u4f5c\u4e3a\u95ee\u9898\u6765\u6e90\uff0c\u81ea\u52a8\u751f\u6210\u5f62\u5f0f\uff08Lean4\uff09\u548c\u975e\u5f62\u5f0f\uff08Markdown\uff09\u89c4\u8303\u7684\u5b9a\u7406-\u8bc1\u660e\u5bf9\uff0c\u5e76\u4ee5Busy Beaver\u95ee\u9898\u548cMixed Boolean Arithmetic\u95ee\u9898\u4e3a\u4f8b\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u3002", "result": "\u6d4b\u8bd5\u663e\u793a\uff0c\u5373\u4f7f\u662f\u524d\u6cbf\u6a21\u578bDeepSeekProver-V2-671B\uff0c\u5728Busy Beaver\u95ee\u9898\u4e0a\u6210\u529f\u7387\u4e3a57.5%\uff0c\u800c\u5728Mixed Boolean Arithmetic\u95ee\u9898\u4e0a\u4ec5\u4e3a12%\uff0c\u7a81\u663e\u4e86\u957f\u8bc1\u660e\u751f\u6210\u7684\u96be\u5ea6\u3002", "conclusion": "TCS\u9886\u57df\u4e3a\u63a8\u8fdb\u81ea\u52a8\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.15788", "pdf": "https://arxiv.org/pdf/2508.15788", "abs": "https://arxiv.org/abs/2508.15788", "authors": ["Ujwal M R"], "title": "VR Fire safety training application", "categories": ["cs.HC", "cs.ET", "68U05", "H.5.1; H.5.2; I.3.7"], "comment": "9 pages, 5 figures, 3 tables", "summary": "Fire emergencies can happen without warning and knowing how to respond\nquickly can save lives Unfortunately traditional fire drills can be disruptive\ncostly and often fail to recreate the pressure of a real emergency This project\nintroduces a Virtual Reality VR Fire Safety Training Application that gives\npeople a safe yet realistic way to practice life saving skills Using a VR\nheadset and motion controllers trainees step into a 3D world where fire hazards\nsmoke and evacuation routes are brought to life They can learn how to use a\nfire extinguisher find safe exits and make decisions under pressure without any\nreal danger The training adapts to the users skill level and tracks progress\nmaking it useful for beginners and experienced personnel alike By turning fire\nsafety into an interactive experience this VR approach boosts confidence\nimproves retention and makes learning both safer and more engaging", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u6b3eVR\u6d88\u9632\u5b89\u5168\u57f9\u8bad\u5e94\u7528\uff0c\u901a\u8fc7\u865a\u62df\u73b0\u5b9e\u6280\u672f\u5b89\u5168\u3001\u903c\u771f\u5730\u8bad\u7ec3\u7528\u6237\u5e94\u5bf9\u706b\u707e\u7684\u6280\u80fd\u3002", "motivation": "\u4f20\u7edf\u6d88\u9632\u6f14\u7ec3\u6210\u672c\u9ad8\u3001\u6548\u679c\u5dee\u4e14\u96be\u4ee5\u6a21\u62df\u771f\u5b9e\u7d27\u6025\u60c5\u51b5\u7684\u538b\u529b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u5b89\u5168\u7684\u57f9\u8bad\u65b9\u5f0f\u3002", "method": "\u4f7f\u7528VR\u5934\u663e\u548c\u52a8\u4f5c\u63a7\u5236\u5668\u6784\u5efa3D\u865a\u62df\u73af\u5883\uff0c\u6a21\u62df\u706b\u707e\u573a\u666f\u3001\u70df\u96fe\u548c\u9003\u751f\u8def\u7ebf\uff0c\u63d0\u4f9b\u4e92\u52a8\u5f0f\u57f9\u8bad\u3002", "result": "\u5e94\u7528\u80fd\u6839\u636e\u7528\u6237\u6280\u80fd\u6c34\u5e73\u8c03\u6574\u96be\u5ea6\u5e76\u8ddf\u8e2a\u8fdb\u5ea6\uff0c\u63d0\u5347\u4fe1\u5fc3\u3001\u8bb0\u5fc6\u6548\u679c\uff0c\u540c\u65f6\u5b66\u4e60\u66f4\u5b89\u5168\u3001\u6709\u8da3\u3002", "conclusion": "VR\u6d88\u9632\u57f9\u8bad\u4f5c\u4e3a\u4e00\u79cd\u4e92\u52a8\u4f53\u9a8c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u7684\u7528\u6237\u3002"}}
{"id": "2508.16044", "pdf": "https://arxiv.org/pdf/2508.16044", "abs": "https://arxiv.org/abs/2508.16044", "authors": ["Zhaodonghui Li", "Haitao Yuan", "Jiachen Shi", "Hao Zhang", "Yu Rong", "Gao Cong"], "title": "MAAdvisor: Zero-Shot Index Advisor using Multi-Agent LLMs", "categories": ["cs.DB"], "comment": null, "summary": "Index recommendation is one of the most important problems in database\nmanagement system (DBMS) optimization. Given queries and certain index-related\nconstraints, traditional methods rely on heuristic optimization or\nlearning-based models to select effective indexes and improve query\nperformance. However, heuristic optimization suffers from high computation\ntime, and learning-based models lose generalisability due to training for\ndifferent workloads and database schemas. With the recent rapid development of\nlarge language models (LLMs), methods using prompt tuning have been proposed to\nenhance the efficiency of index selection. However, such methods still can not\nachieve the state-of-the-art (SOTA) results, and preparing the index selection\ndemonstrations is also resource-intensive. To address these issues, we propose\nMAAdvisor, a zero-shot LLM-based index advisor with a multi-agent framework. We\ndecompose the index recommendation problem into sub-steps, including planning,\nselection, combination, revision, and reflection. A set of LLM-embedded agents\nis designed to handle each one of the different sub-steps. Our method utilizes\nglobal agents to control the index selection process and local agents to select\nand revise indexes. Through extensive experiments, we show that our proposed\nMAAdvisor not only achieves the SOTA performance compared to the heuristic\nmethods, but also outperforms learning-based and prompt-based methods with\nhigher efficiency and better zero-shot inference ability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7684\u96f6\u6837\u672cLLM\u7d22\u5f15\u987e\u95eeMAAdvisor\uff0c\u901a\u8fc7\u5206\u89e3\u7d22\u5f15\u63a8\u8350\u95ee\u9898\u4e3a\u5b50\u6b65\u9aa4\u5e76\u8bbe\u8ba1\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u548c\u96f6\u6837\u672c\u63a8\u7406\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u542f\u53d1\u5f0f\u548c\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u7d22\u5f15\u63a8\u8350\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u4ee5\u53ca\u63d0\u793a\u8c03\u4f18\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5c06\u7d22\u5f15\u63a8\u8350\u5206\u89e3\u4e3a\u89c4\u5212\u3001\u9009\u62e9\u3001\u7ec4\u5408\u3001\u4fee\u8ba2\u548c\u53cd\u601d\u7b49\u5b50\u6b65\u9aa4\uff0c\u8bbe\u8ba1\u5168\u5c40\u548c\u5c40\u90e8\u667a\u80fd\u4f53\u5206\u522b\u63a7\u5236\u6d41\u7a0b\u548c\u5177\u4f53\u64cd\u4f5c\u3002", "result": "MAAdvisor\u5728\u5b9e\u9a8c\u4e2d\u8fbe\u5230\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u4e14\u6548\u7387\u548c\u96f6\u6837\u672c\u63a8\u7406\u80fd\u529b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MAAdvisor\u4e3a\u7d22\u5f15\u63a8\u8350\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16200", "pdf": "https://arxiv.org/pdf/2508.16200", "abs": "https://arxiv.org/abs/2508.16200", "authors": ["Mika Leo Hube", "Filip Lemic", "Ethungshan Shitiri", "Gerard Calvo Bartra", "Sergi Abadal", "Xavier Costa P\u00e9rez"], "title": "Set Transformer Architectures and Synthetic Data Generation for Flow-Guided Nanoscale Localization", "categories": ["cs.ET", "cs.AI", "cs.LG", "cs.NI"], "comment": "6 pages, 4 figures, 4 tables, 26 references, accepted at ACM\n  NanoCom'25", "summary": "Flow-guided Localization (FGL) enables the identification of spatial regions\nwithin the human body that contain an event of diagnostic interest. FGL does\nthat by leveraging the passive movement of energy-constrained nanodevices\ncirculating through the bloodstream. Existing FGL solutions rely on graph\nmodels with fixed topologies or handcrafted features, which limit their\nadaptability to anatomical variability and hinder scalability. In this work, we\nexplore the use of Set Transformer architectures to address these limitations.\nOur formulation treats nanodevices' circulation time reports as unordered sets,\nenabling permutation-invariant, variable-length input processing without\nrelying on spatial priors. To improve robustness under data scarcity and class\nimbalance, we integrate synthetic data generation via deep generative models,\nincluding CGAN, WGAN, WGAN-GP, and CVAE. These models are trained to replicate\nrealistic circulation time distributions conditioned on vascular region labels,\nand are used to augment the training data. Our results show that the Set\nTransformer achieves comparable classification accuracy compared to Graph\nNeural Networks (GNN) baselines, while simultaneously providing by-design\nimproved generalization to anatomical variability. The findings highlight the\npotential of permutation-invariant models and synthetic augmentation for robust\nand scalable nanoscale localization.", "AI": {"tldr": "FGL\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u65e0\u5e8f\u96c6\u548c\u751f\u6210\u6a21\u578b\u589e\u5f3a\u7684Set Transformer\u67b6\u6784\uff0c\u7528\u4e8e\u6539\u8fdb\u57fa\u4e8e\u7eb3\u7c73\u8bbe\u5907\u7684\u4f53\u5185\u5b9a\u4f4d\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709FGL\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u62d3\u6251\u6216\u624b\u5de5\u7279\u5f81\uff0c\u96be\u4ee5\u9002\u5e94\u89e3\u5256\u5b66\u53d8\u5f02\uff0c\u4e14\u6269\u5c55\u6027\u53d7\u9650\u3002", "method": "\u91c7\u7528Set Transformer\u5904\u7406\u65e0\u5e8f\u8f93\u5165\uff0c\u7ed3\u5408\u751f\u6210\u6a21\u578b\uff08\u5982CGAN\u3001WGAN\u7b49\uff09\u751f\u6210\u5408\u6210\u6570\u636e\u4ee5\u589e\u5f3a\u8bad\u7ec3\u3002", "result": "Set Transformer\u5728\u5206\u7c7b\u51c6\u786e\u5ea6\u4e0a\u4e0eGNN\u76f8\u5f53\uff0c\u4e14\u80fd\u66f4\u597d\u5730\u9002\u5e94\u89e3\u5256\u5b66\u53d8\u5f02\u3002", "conclusion": "\u5b9e\u9a8c\u8bf4\u660e\u4e86\u7f6e\u6362\u4e0d\u53d8\u6a21\u578b\u548c\u5408\u6210\u6570\u636e\u589e\u5f3a\u5728\u7eb3\u7c73\u7ea7\u5b9a\u4f4d\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.16095", "pdf": "https://arxiv.org/pdf/2508.16095", "abs": "https://arxiv.org/abs/2508.16095", "authors": ["Vineet Kumar", "Ajay Kumar M", "Yike Li", "Shreejith Shanker", "Deepu John"], "title": "Bare-Metal RISC-V + NVDLA SoC for Efficient Deep Learning Inference", "categories": ["cs.AR"], "comment": "Accepted paper in 2025 IEEE 38th International System-on-Chip\n  Conference (SOCC)", "summary": "This paper presents a novel System-on-Chip (SoC) architecture for\naccelerating complex deep learning models for edge computing applications\nthrough a combination of hardware and software optimisations. The hardware\narchitecture tightly couples the open-source NVIDIA Deep Learning Accelerator\n(NVDLA) to a 32-bit, 4-stage pipelined RISC-V core from Codasip called uRISC_V.\nTo offload the model acceleration in software, our toolflow generates\nbare-metal application code (in assembly), overcoming complex OS overheads of\nprevious works that have explored similar architectures. This tightly coupled\narchitecture and bare-metal flow leads to improvements in execution speed and\nstorage efficiency, making it suitable for edge computing solutions. We\nevaluate the architecture on AMD's ZCU102 FPGA board using NVDLA-small\nconfiguration and test the flow using LeNet-5, ResNet-18 and ResNet-50 models.\nOur results show that these models can perform inference in 4.8 ms, 16.2 ms and\n1.1 s respectively, at a system clock frequency of 100 MHz.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bSoC\u67b6\u6784\uff0c\u901a\u8fc7\u786c\u4ef6\u4e0e\u8f6f\u4ef6\u4f18\u5316\u52a0\u901f\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u52a0\u901f\u95ee\u9898\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6848\u7684\u64cd\u4f5c\u7cfb\u7edf\u5f00\u9500\u3002", "method": "\u7ed3\u5408NVDLA\u4e0eRISC-V\u6838\u5fc3\uff0c\u751f\u6210\u88f8\u673a\u5e94\u7528\u4ee3\u7801\u4ee5\u51cf\u5c11\u5f00\u9500\u3002", "result": "\u5728100 MHz\u65f6\u949f\u9891\u7387\u4e0b\uff0cLeNet-5\u3001ResNet-18\u548cResNet-50\u7684\u63a8\u7406\u65f6\u95f4\u5206\u522b\u4e3a4.8 ms\u300116.2 ms\u548c1.1 s\u3002", "conclusion": "\u8be5\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u6267\u884c\u901f\u5ea6\u548c\u5b58\u50a8\u6548\u7387\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u3002"}}
{"id": "2508.16308", "pdf": "https://arxiv.org/pdf/2508.16308", "abs": "https://arxiv.org/abs/2508.16308", "authors": ["Jan Bok", "Avinandan Das", "Anna Gujgiczer", "Nikola Jedli\u010dkov\u00e1"], "title": "Generalizing Brooks' theorem via Partial Coloring is Hard Classically and Locally", "categories": ["cs.DC", "cs.CC", "F.2.2; G.2.2"], "comment": null, "summary": "We investigate the classical and distributed complexity of \\emph{$k$-partial\n$c$-coloring} where $c=k$, a natural generalization of Brooks' theorem where\neach vertex should be colored from the palette $\\{1,\\ldots,c\\} =\n\\{1,\\ldots,k\\}$ such that it must have at least $\\min\\{k, \\deg(v)\\}$ neighbors\ncolored differently. Das, Fraigniaud, and Ros{\\'{e}}n~[OPODIS 2023] showed that\nthe problem of $k$-partial $(k+1)$-coloring admits efficient centralized and\ndistributed algorithms and posed an open problem about the status of the\ndistributed complexity of $k$-partial $k$-coloring. We show that the problem\nbecomes significantly harder when the number of colors is reduced from $k+1$ to\n$k$ for every constant $k\\geq 3$.\n  In the classical setting, we prove that deciding whether a graph admits a\n$k$-partial $k$-coloring is NP-complete for every constant $k \\geq 3$,\nrevealing a sharp contrast with the linear-time solvable $(k+1)$-color case.\nFor the distributed LOCAL model, we establish an $\\Omega(n)$-round lower bound\nfor computing $k$-partial $k$-colorings, even when the graph is guaranteed to\nbe $k$-partial $k$-colorable. This demonstrates an exponential separation from\nthe $O(\\log^2 k \\cdot \\log n)$-round algorithms known for $(k+1)$-colorings.\n  Our results leverage novel structural characterizations of ``hard instances''\nwhere partial coloring reduces to proper coloring, and we construct intricate\ngraph gadgets to prove lower bounds via indistinguishability arguments.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86$k$-partial $k$-coloring\u95ee\u9898\u7684\u7ecf\u5178\u548c\u5206\u5e03\u5f0f\u590d\u6742\u6027\uff0c\u53d1\u73b0\u5f53\u989c\u8272\u6570\u91cf\u4ece$k+1$\u51cf\u5c11\u5230$k$\u65f6\uff0c\u95ee\u9898\u590d\u6742\u5ea6\u663e\u8457\u589e\u52a0\u3002\u7ecf\u5178\u60c5\u51b5\u4e0b\u8be5\u95ee\u9898\u662fNP\u5b8c\u5168\u7684\uff0c\u5206\u5e03\u5f0f\u60c5\u51b5\u4e0b\u5b58\u5728$\\Omega(n)$\u8f6e\u4e0b\u754c\u3002", "motivation": "\u63a2\u8ba8$k$-partial $c$-coloring\u95ee\u9898\u5728$c=k$\u65f6\u7684\u590d\u6742\u6027\uff0c\u4ee5\u6269\u5c55\u5bf9Brooks\u5b9a\u7406\u7684\u7406\u89e3\uff0c\u5e76\u56de\u7b54\u4e4b\u524d\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6784\u9020\u590d\u6742\u56fe\u7ed3\u6784\u548c\u4e0d\u53ef\u533a\u5206\u6027\u8bba\u8bc1\uff0c\u8bc1\u660e\u7ecf\u5178NP\u5b8c\u5168\u6027\u548c\u5206\u5e03\u5f0f\u4e0b\u754c\u3002", "result": "\u7ecf\u5178\u60c5\u51b5\u4e0b$k$-partial $k$-coloring\u5bf9$k\\geq3$\u662fNP\u5b8c\u5168\u7684\uff1b\u5206\u5e03\u5f0f\u60c5\u51b5\u4e0b\u5b58\u5728$\\Omega(n)$\u8f6e\u4e0b\u754c\u3002", "conclusion": "\u989c\u8272\u6570\u91cf\u51cf\u5c11\u81f3$k$\u65f6\uff0c\u95ee\u9898\u590d\u6742\u5ea6\u663e\u8457\u589e\u52a0\uff0c\u63ed\u793a\u4e86\u4e0e$k+1$\u60c5\u51b5\u7684\u5173\u952e\u5dee\u5f02\u3002"}}
{"id": "2508.16449", "pdf": "https://arxiv.org/pdf/2508.16449", "abs": "https://arxiv.org/abs/2508.16449", "authors": ["Qunyou Liu", "Darong Huang", "Marina Zapater", "David Atienza"], "title": "GreenLLM: SLO-Aware Dynamic Frequency Scaling for Energy-Efficient LLM Serving", "categories": ["cs.PF"], "comment": null, "summary": "Large Language Models (LLMs) are becoming the backbone of modern cloud\nservices, yet their inference costs are dominated by GPU energy. Unlike\ntraditional GPU workloads, LLM inference has two stages with different\ncharacteristics: the prefill phase, which is latency sensitive and scales\nquadratically with prompt length, and the decode phase, which progresses token\nby token with unpredictable length. Current GPU power governors (for example,\nNVIDIA's default) overlook this asymmetry and treat both stages uniformly. The\nresult is mismatched voltage and frequency settings, head-of-line blocking, and\nexcessive energy use.\n  We introduce GreenLLM, an SLO-aware serving framework that minimizes GPU\nenergy by explicitly separating prefill and decode control. At ingress,\nrequests are routed into length-based queues so short prompts avoid\nhead-of-line blocking and TTFT improves. For prefill, GreenLLM collects short\ntraces on a GPU node, fits compact latency-power models over SM frequency, and\nsolves a queueing-aware optimization to select energy-minimal clocks per class.\nDuring decode, a lightweight dual-loop controller tracks throughput (tokens per\nsecond) and adjusts frequency with hysteretic, fine-grained steps to hold tail\nTBT within target bounds. Across Alibaba and Azure trace replays, GreenLLM\nreduces total energy by up to 34 percent versus the default DVFS baseline, with\nno loss of throughput and with less than 3.5 percent additional SLO violations.", "AI": {"tldr": "GreenLLM\u662f\u4e00\u79cdSLO\u611f\u77e5\u7684\u670d\u52a1\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u9884\u586b\u5145\u548c\u89e3\u7801\u63a7\u5236\uff0c\u4f18\u5316GPU\u80fd\u6e90\u4f7f\u7528\uff0c\u51cf\u5c11\u80fd\u91cf\u6d88\u801734%\u3002", "motivation": "\u73b0\u6709\u7684GPU\u529f\u7387\u63a7\u5236\u5668\u5ffd\u89c6\u4e86LLM\u63a8\u7406\u7684\u4e24\u4e2a\u9636\u6bb5\uff08\u9884\u586b\u5145\u548c\u89e3\u7801\uff09\u7684\u4e0d\u5bf9\u79f0\u6027\uff0c\u5bfc\u81f4\u80fd\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0b\u964d\u3002", "method": "GreenLLM\u901a\u8fc7\u57fa\u4e8e\u957f\u5ea6\u7684\u961f\u5217\u8def\u7531\u8bf7\u6c42\uff0c\u4e3a\u9884\u586b\u5145\u9636\u6bb5\u6784\u5efa\u7d27\u51d1\u7684\u5ef6\u8fdf-\u529f\u8017\u6a21\u578b\uff0c\u5e76\u4e3a\u89e3\u7801\u9636\u6bb5\u8bbe\u8ba1\u53cc\u73af\u63a7\u5236\u5668\u3002", "result": "\u5728\u963f\u91cc\u4e91\u548cAzure\u7684\u8ddf\u8e2a\u91cd\u653e\u4e2d\uff0cGreenLLM\u6bd4\u9ed8\u8ba4DVFS\u57fa\u8282\u7701\u4e8634%\u7684\u80fd\u6e90\uff0c\u4e14\u541e\u5410\u91cf\u65e0\u635f\u5931\uff0cSLO\u8fdd\u89c4\u589e\u52a0\u5c11\u4e8e3.5%\u3002", "conclusion": "GreenLLM\u663e\u8457\u51cf\u5c11\u4e86LLM\u63a8\u7406\u7684\u80fd\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\u548cSLO\u5408\u89c4\u6027\u3002"}}
{"id": "2508.15816", "pdf": "https://arxiv.org/pdf/2508.15816", "abs": "https://arxiv.org/abs/2508.15816", "authors": ["Mauro Belgiovine", "Chris Dick", "Kaushik Chowdhury"], "title": "Better Together: Leveraging Multiple Digital Twins for Deployment Optimization of Airborne Base Stations", "categories": ["cs.NI", "cs.LG"], "comment": "Submitted to IEEE Transactions on Mobile Computing (second round of\n  review)", "summary": "Airborne Base Stations (ABSs) allow for flexible geographical allocation of\nnetwork resources with dynamically changing load as well as rapid deployment of\nalternate connectivity solutions during natural disasters. Since the radio\ninfrastructure is carried by unmanned aerial vehicles (UAVs) with limited\nflight time, it is important to establish the best location for the ABS without\nexhaustive field trials. This paper proposes a digital twin (DT)-guided\napproach to achieve this through the following key contributions: (i)\nImplementation of an interactive software bridge between two open-source DTs\nsuch that the same scene is evaluated with high fidelity across NVIDIA's Sionna\nand Aerial Omniverse Digital Twin (AODT), highlighting the unique features of\neach of these platforms for this allocation problem, (ii) Design of a\nback-propagation-based algorithm in Sionna for rapidly converging on the\nphysical location of the UAVs, orientation of the antennas and transmit power\nto ensure efficient coverage across the swarm of the UAVs, and (iii) numerical\nevaluation in AODT for large network scenarios (50 UEs, 10 ABS) that identifies\nthe environmental conditions in which there is agreement or divergence of\nperformance results between these twins. Finally, (iv) we propose a resilience\nmechanism to provide consistent coverage to mission-critical devices and\ndemonstrate a use case for bi-directional flow of information between the two\nDTs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408NVIDIA\u7684Sionna\u548cAerial Omniverse Digital Twin\uff08AODT\uff09\u5e73\u53f0\uff0c\u4f18\u5316\u65e0\u4eba\u673a\u57fa\u7ad9\uff08ABS\uff09\u7684\u4f4d\u7f6e\u3001\u5929\u7ebf\u65b9\u5411\u548c\u53d1\u5c04\u529f\u7387\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u8986\u76d6\u3002\u5e76\u901a\u8fc7\u6570\u503c\u8bc4\u4f30\u548c\u63d0\u51fa\u5f39\u6027\u673a\u5236\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u57fa\u7ad9\uff08ABS\uff09\u56e0\u5176\u7075\u6d3b\u7684\u8d44\u6e90\u548c\u5feb\u901f\u90e8\u7f72\u80fd\u529b\uff0c\u5728\u52a8\u6001\u8d1f\u8f7d\u548c\u81ea\u7136\u707e\u5bb3\u6062\u590d\u4e2d\u5177\u6709\u6f5c\u529b\u3002\u7136\u800c\uff0c\u6709\u9650\u7684\u98de\u884c\u65f6\u95f4\u548c\u8d44\u6e90\u8981\u6c42\u4f18\u5316ABS\u4f4d\u7f6e\uff0c\u907f\u514d\u8017\u65f6\u7684\u5b9e\u5730\u8bd5\u9a8c\u3002", "method": "1. \u5b9e\u73b0\u4e24\u4e2a\u5f00\u6e90\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\uff08Sionna\u548cAODT\uff09\u7684\u4ea4\u4e92\u5f0f\u8f6f\u4ef6\u6865\uff0c\u8bc4\u4f30\u573a\u666f\u9ad8\u4fdd\u771f\u5ea6\u30022. \u5728Sionna\u4e2d\u8bbe\u8ba1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff0c\u5feb\u901f\u4f18\u5316\u65e0\u4eba\u673a\u4f4d\u7f6e\u3001\u5929\u7ebf\u65b9\u5411\u548c\u53d1\u5c04\u529f\u7387\u30023. \u5728AODT\u4e2d\u8fdb\u884c\u5927\u89c4\u6a21\u573a\u666f\uff0850\u7528\u6237\uff0c10 ABS\uff09\u6570\u503c\u8bc4\u4f30\u30024. \u63d0\u51fa\u5f39\u6027\u673a\u5236\uff0c\u786e\u4fdd\u5173\u952e\u8bbe\u5907\u8986\u76d6\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u5c55\u793a\u4e86\u4e0d\u540c\u73af\u5883\u6761\u4ef6\u4e0b\u4e24\u4e2a\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\u6027\u80fd\u7684\u4e00\u81f4\u6027\u548c\u5206\u6b67\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002\u5f39\u6027\u673a\u5236\u901a\u8fc7\u53cc\u5411\u4fe1\u606f\u6d41\u5b9e\u73b0\u4e86\u5173\u952e\u8bbe\u5907\u7684\u7a33\u5b9a\u8986\u76d6\u3002", "conclusion": "\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4e3a\u65e0\u4eba\u673a\u57fa\u7ad9\u7684\u4f18\u5316\u548c\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u73af\u5883\u548c\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u3002\u5f39\u6027\u673a\u5236\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2508.16131", "pdf": "https://arxiv.org/pdf/2508.16131", "abs": "https://arxiv.org/abs/2508.16131", "authors": ["Zoe Kotti", "Konstantina Dritsa", "Diomidis Spinellis", "Panos Louridas"], "title": "The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion", "categories": ["cs.SE", "cs.AI"], "comment": "30 pages, 10 figures", "summary": "Code completion entails the task of providing missing tokens given a\nsurrounding context. It can boost developer productivity while providing a\npowerful code discovery tool. Following the Large Language Model (LLM) wave,\ncode completion has been approached with diverse LLMs fine-tuned on code (code\nLLMs). The performance of code LLMs can be assessed with downstream and\nintrinsic metrics. Downstream metrics are usually employed to evaluate the\npractical utility of a model, but can be unreliable and require complex\ncalculations and domain-specific knowledge. In contrast, intrinsic metrics such\nas perplexity, entropy, and mutual information, which measure model confidence\nor uncertainty, are simple, versatile, and universal across LLMs and tasks, and\ncan serve as proxies for functional correctness and hallucination risk in\nLLM-generated code. Motivated by this, we evaluate the confidence of LLMs when\ngenerating code by measuring code perplexity across programming languages,\nmodels, and datasets using various LLMs, and a sample of 1008 files from 657\nGitHub projects. We find that strongly-typed languages exhibit lower perplexity\nthan dynamically typed languages. Scripting languages also demonstrate higher\nperplexity. Perl appears universally high in perplexity, whereas Java appears\nlow. Code perplexity depends on the employed LLM, but not on the code dataset.\nAlthough code comments often increase perplexity, the language ranking based on\nperplexity is barely affected by their presence. LLM researchers, developers,\nand users can employ our findings to assess the benefits and suitability of\nLLM-based code completion in specific software projects based on how language,\nmodel choice, and code characteristics impact model confidence.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u8865\u5168\u4efb\u52a1\uff0c\u901a\u8fc7\u6d4b\u91cf\u4ee3\u7801\u56f0\u60d1\u5ea6\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u65f6\u7684\u7f6e\u4fe1\u5ea6\uff0c\u53d1\u73b0\u5f3a\u7c7b\u578b\u8bed\u8a00\u6bd4\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u56f0\u60d1\u5ea6\u4f4e\uff0c\u4e14\u6a21\u578b\u9009\u62e9\u5bf9\u56f0\u60d1\u5ea6\u6709\u5f71\u54cd\u3002", "motivation": "\u4ee3\u7801\u8865\u5168\u53ef\u4ee5\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u590d\u6742\u4e14\u4e0d\u53ef\u9760\uff0c\u56e0\u6b64\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5185\u5728\u6307\u6807\uff08\u5982\u56f0\u60d1\u5ea6\uff09\u6765\u7b80\u5355\u3001\u901a\u7528\u5730\u8bc4\u4f30\u6a21\u578b\u7f6e\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528\u591a\u79cdLLM\u548c657\u4e2aGitHub\u9879\u76ee\u76841008\u4e2a\u6587\u4ef6\uff0c\u6d4b\u91cf\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u56f0\u60d1\u5ea6\uff0c\u5206\u6790\u8bed\u8a00\u7c7b\u578b\u3001\u6a21\u578b\u9009\u62e9\u548c\u4ee3\u7801\u7279\u6027\u7684\u5f71\u54cd\u3002", "result": "\u5f3a\u7c7b\u578b\u8bed\u8a00\uff08\u5982Java\uff09\u56f0\u60d1\u5ea6\u8f83\u4f4e\uff0c\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\uff08\u5982Perl\uff09\u8f83\u9ad8\uff1b\u6a21\u578b\u9009\u62e9\u5f71\u54cd\u56f0\u60d1\u5ea6\uff0c\u800c\u4ee3\u7801\u6570\u636e\u96c6\u65e0\u663e\u8457\u5f71\u54cd\uff1b\u4ee3\u7801\u6ce8\u91ca\u4f1a\u589e\u52a0\u56f0\u60d1\u5ea6\uff0c\u4f46\u4e0d\u6539\u53d8\u8bed\u8a00\u6392\u540d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u56f0\u60d1\u5ea6\u53ef\u4ee5\u8bc4\u4f30LLM\u4ee3\u7801\u8865\u5168\u7684\u9002\u7528\u6027\uff0c\u4e3a\u5f00\u53d1\u8005\u9009\u62e9\u6a21\u578b\u548c\u8bed\u8a00\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2508.16535", "pdf": "https://arxiv.org/pdf/2508.16535", "abs": "https://arxiv.org/abs/2508.16535", "authors": ["Trung Hieu Pham", "Chanh Minh Tran", "Eiji Kamioka", "Xuan Tan Phan"], "title": "Real-time 3D Light-field Viewing with Eye-tracking on Conventional Displays", "categories": ["cs.GR", "cs.HC", "cs.MM"], "comment": null, "summary": "Creating immersive 3D visual experiences typically requires expensive and\nspecialized hardware such as VR headsets, autostereoscopic displays, or active\nshutter glasses. These constraints limit the accessibility and everyday use of\n3D visualization technologies in resource-constrained settings. To address\nthis, we propose a low-cost system that enables real-time 3D light-field\nviewing using only a standard 2D monitor, a conventional RGB webcam, and\nred-cyan anaglyph glasses. The system integrates real-time eye-tracking to\ndynamically adapt the displayed light-field image to the user's head position\nwith a lightweight rendering pipeline that selects and composites stereoscopic\nviews from pre-captured light-field data. The resulting anaglyph image is\nupdated in real-time, creating a more immersive and responsive 3D experience.\nThe system operates entirely on CPU and maintains a stable frame rate of 30\nFPS, confirming its feasibility on typical consumer-grade hardware. All of\nthese highlight the potential of our approach as an accessible platform for\ninteractive 3D applications in education, digital media, and beyond.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u7cfb\u7edf\uff0c\u5229\u7528\u666e\u901a2D\u663e\u793a\u5668\u3001RGB\u6444\u50cf\u5934\u548c\u7ea2\u9752\u7acb\u4f53\u773c\u955c\u5b9e\u73b0\u5b9e\u65f63D\u5149\u573a\u89c2\u770b\uff0c\u65e0\u9700\u6602\u8d35\u786c\u4ef6\u3002", "motivation": "\u89e3\u51b33D\u53ef\u89c6\u5316\u6280\u672f\u56e0\u786c\u4ef6\u6210\u672c\u9ad8\u800c\u96be\u4ee5\u666e\u53ca\u7684\u95ee\u9898\uff0c\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u96c6\u6210\u5b9e\u65f6\u773c\u7403\u8ffd\u8e2a\u548c\u8f7b\u91cf\u7ea7\u6e32\u67d3\u7ba1\u7ebf\uff0c\u52a8\u6001\u8c03\u6574\u5149\u573a\u56fe\u50cf\u4ee5\u9002\u5e94\u5934\u90e8\u4f4d\u7f6e\u3002", "result": "\u7cfb\u7edf\u5728CPU\u4e0a\u5b9e\u73b030 FPS\u7a33\u5b9a\u5e27\u7387\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u6559\u80b2\u3001\u6570\u5b57\u5a92\u4f53\u7b49\u9886\u57df\u7684\u4ea4\u4e92\u5f0f3D\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u5e73\u53f0\u3002"}}
{"id": "2508.16063", "pdf": "https://arxiv.org/pdf/2508.16063", "abs": "https://arxiv.org/abs/2508.16063", "authors": ["Paul Krogmeier", "P. Madhusudan"], "title": "Synthesizing DSLs for Few-Shot Learning", "categories": ["cs.PL", "cs.FL"], "comment": null, "summary": "We study the problem of synthesizing domain-specific languages (DSLs) for\nfew-shot learning in symbolic domains. Given a base language and instances of\nfew-shot learning problems, where each instance is split into training and\ntesting samples, the DSL synthesis problem asks for a grammar over the base\nlanguage that guarantees that small expressions solving training samples also\nsolve corresponding testing samples. We prove that the problem is decidable for\na class of languages whose semantics over fixed structures can be evaluated by\ntree automata and when expression size corresponds to parse tree depth in the\ngrammar, and, furthermore, the grammars solving the problem correspond to a\nregular set of trees. We also prove decidability results for variants of the\nproblem where DSLs are only required to express solutions for input learning\nproblems and where DSLs are defined using macro grammars.", "AI": {"tldr": "\u7814\u7a76\u5728\u7b26\u53f7\u9886\u57df\u4e3a\u5c11\u6837\u672c\u5b66\u4e60\u5408\u6210\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u53ef\u89e3\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u7b26\u53f7\u57df\u4e2d\u4e3a\u5c11\u6837\u672c\u5b66\u4e60\u8bbe\u8ba1DSL\u7684\u6311\u6218\uff0c\u786e\u4fdd\u8bad\u7ec3\u6837\u672c\u7684\u89e3\u51b3\u65b9\u6848\u9002\u7528\u4e8e\u6d4b\u8bd5\u6837\u672c\u3002", "method": "\u4f7f\u7528\u6811\u81ea\u52a8\u673a\u8bc4\u4f30\u8bed\u4e49\uff0c\u5206\u6790\u8bed\u6cd5\u4e0e\u8868\u8fbe\u5f0f\u5927\u5c0f\u7684\u5173\u7cfb\uff0c\u5e76\u63a2\u8ba8\u6b63\u5219\u6811\u96c6\u7684\u89e3\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0bDSL\u5408\u6210\u95ee\u9898\u662f\u53ef\u89e3\u7684\uff0c\u5e76\u6269\u5c55\u4e86\u5b8f\u8bed\u6cd5\u7684\u53ef\u89e3\u6027\u3002", "conclusion": "DSL\u5408\u6210\u5728\u7b26\u53f7\u57df\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u5177\u6709\u7406\u8bba\u652f\u6301\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8bed\u6cd5\u53d8\u4f53\u3002"}}
{"id": "2508.16454", "pdf": "https://arxiv.org/pdf/2508.16454", "abs": "https://arxiv.org/abs/2508.16454", "authors": ["Lianchen Jia", "Chao Zhou", "Chaoyang Li", "Jiangchuan Liu", "Lifeng Sun"], "title": "Towards User-level QoE: Large-scale Practice in Personalized Optimization of Adaptive Video Streaming", "categories": ["cs.MM", "eess.IV"], "comment": "ACM SIGCOMM 2025", "summary": "Traditional optimization methods based on system-wide Quality of Service\n(QoS) metrics have approached their performance limitations in modern\nlarge-scale streaming systems. However, aligning user-level Quality of\nExperience~(QoE) with algorithmic optimization objectives remains an unresolved\nchallenge. Therefore, we propose \\texttt{LingXi}, the first large-scale\ndeployed system for personalized adaptive video streaming based on user-level\nexperience. \\texttt{LingXi} dynamically optimizes the objectives of adaptive\nvideo streaming algorithms by analyzing user engagement. Utilizing exit rate as\na key metric, we investigate the correlation between QoS indicators and exit\nrates based on production environment logs, subsequently developing a\npersonalized exit rate predictor. Through Monte Carlo sampling and online\nBayesian optimization, we iteratively determine optimal parameters. Large-scale\nA/B testing utilizing 8\\% of traffic on Kuaishou, one of the largest short\nvideo platforms, demonstrates \\texttt{LingXi}'s superior performance.\n\\texttt{LingXi} achieves a 0.15\\% increase in total viewing time, a 0.1\\%\nimprovement in bitrate, and a 1.3\\% reduction in stall time across all users,\nwith particularly significant improvements for low-bandwidth users who\nexperience a 15\\% reduction in stall time.", "AI": {"tldr": "LingXi \u662f\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u4e2a\u6027\u5316\u81ea\u9002\u5e94\u89c6\u9891\u6d41\u7cfb\u7edf\uff0c\u901a\u8fc7\u7528\u6237\u53c2\u4e0e\u5ea6\u52a8\u6001\u4f18\u5316\u7b97\u6cd5\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7cfb\u7edf\u7ea7 QoS \u6307\u6807\u7684\u4f18\u5316\u65b9\u6cd5\u5728\u73b0\u4ee3\u5927\u89c4\u6a21\u6d41\u5a92\u4f53\u7cfb\u7edf\u4e2d\u5df2\u63a5\u8fd1\u6027\u80fd\u6781\u9650\uff0c\u5982\u4f55\u5c06\u7528\u6237\u7ea7 QoE \u4e0e\u7b97\u6cd5\u4f18\u5316\u76ee\u6807\u5bf9\u9f50\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u9000\u51fa\u7387\u4f5c\u4e3a\u5173\u952e\u6307\u6807\uff0c\u5206\u6790 QoS \u6307\u6807\u4e0e\u9000\u51fa\u7387\u7684\u5173\u7cfb\uff0c\u5f00\u53d1\u4e2a\u6027\u5316\u9000\u51fa\u7387\u9884\u6d4b\u5668\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u91c7\u6837\u548c\u5728\u7ebf\u8d1d\u53f6\u65af\u4f18\u5316\u8fed\u4ee3\u786e\u5b9a\u6700\u4f18\u53c2\u6570\u3002", "result": "\u5728\u5927\u89c4\u6a21 A/B \u6d4b\u8bd5\u4e2d\uff0cLingXi \u5b9e\u73b0\u4e86\u603b\u89c2\u770b\u65f6\u95f4\u589e\u52a0 0.15%\uff0c\u6bd4\u7279\u7387\u63d0\u5347 0.1%\uff0c\u5361\u987f\u65f6\u95f4\u51cf\u5c11 1.3%\uff0c\u4f4e\u5e26\u5bbd\u7528\u6237\u5361\u987f\u65f6\u95f4\u51cf\u5c11 15%\u3002", "conclusion": "LingXi \u6210\u529f\u5c06\u7528\u6237\u7ea7 QoE \u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u6d41\u5a92\u4f53\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.16146", "pdf": "https://arxiv.org/pdf/2508.16146", "abs": "https://arxiv.org/abs/2508.16146", "authors": ["Nicolas Fr\u00f6hlich", "Phokion G. Kolaitis", "Arne Meier"], "title": "Disjunctions of Two Dependence Atoms", "categories": ["cs.LO", "cs.DB"], "comment": null, "summary": "Dependence logic is a formalism that augments the syntax of first-order logic\nwith dependence atoms asserting that the value of a variable is determined by\nthe values of some other variables, i.e., dependence atoms express functional\ndependencies in relational databases. On finite structures, dependence logic\ncaptures NP, hence there are sentences of dependence logic whose model-checking\nproblem is NP-complete. In fact, it is known that there are disjunctions of\nthree dependence atoms whose model-checking problem is NP-complete. Motivated\nfrom considerations in database theory, we study the model-checking problem for\ndisjunctions of two unary dependence atoms and establish a trichotomy theorem,\nnamely, for every such formula, one of the following is true for the\nmodel-checking problem: (i) it is NL-complete; (ii) it is LOGSPACE-complete;\n(iii) it is first-order definable (hence, in AC[0]). Furthermore, we classify\nthe complexity of the model-checking problem for disjunctions of two arbitrary\ndependence atoms, and also characterize when such a disjunction is coherent,\ni.e., when it satisfies a certain small-model property. Along the way, we\nidentify a new class of 2CNF-formulas whose satisfiability problem is\nLOGSPACE-complete.", "AI": {"tldr": "\u6587\u7ae0\u7814\u7a76\u4e86\u4f9d\u8d56\u903b\u8f91\u4e2d\u4e24\u4e2a\u4e00\u5143\u4f9d\u8d56\u539f\u5b50\u6790\u53d6\u6a21\u578b\u7684\u590d\u6742\u6027\uff0c\u5efa\u7acb\u4e86\u4e09\u5206\u6cd5\u5b9a\u7406\uff0c\u5e76\u5206\u7c7b\u4e86\u5176\u590d\u6742\u6027\u3002", "motivation": "\u53d7\u6570\u636e\u5e93\u7406\u8bba\u542f\u53d1\uff0c\u7814\u7a76\u4f9d\u8d56\u903b\u8f91\u4e2d\u4e24\u4e2a\u4e00\u5143\u4f9d\u8d56\u539f\u5b50\u6790\u53d6\u6a21\u578b\u7684\u590d\u6742\u6027\u3002", "method": "\u5206\u6790\u4f9d\u8d56\u903b\u8f91\u4e2d\u4e24\u4e2a\u4e00\u5143\u4f9d\u8d56\u539f\u5b50\u6790\u53d6\u6a21\u578b\u7684\u590d\u6742\u6027\uff0c\u5efa\u7acb\u4e09\u5206\u6cd5\u5b9a\u7406\u3002", "result": "\u6a21\u578b\u68c0\u67e5\u95ee\u9898\u7684\u590d\u6742\u6027\u5206\u4e3a\u4e09\u79cd\uff1aNL-complete\u3001LOGSPACE-complete\u6216\u4e00\u9636\u53ef\u5b9a\u4e49\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4f9d\u8d56\u903b\u8f91\u6a21\u578b\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u5206\u7c7b\u548c\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2508.15995", "pdf": "https://arxiv.org/pdf/2508.15995", "abs": "https://arxiv.org/abs/2508.15995", "authors": ["Ignacio Perez-Messina", "Asanobu Kitamoto"], "title": "Kokatsuji: A Visualization Approach for Typographic Forensics of Early Japanese Movable Type", "categories": ["cs.HC", "68U35", "H.5.2"], "comment": "Paper accepted for presentation at VIS4DH workshop, IEEE VIS 2025,\n  Vienna", "summary": "We present a visualization system designed to support typographic forensics\nin the study of Kokatsuji, the short-lived tradition of Japanese movable wooden\ntype printing. Building on recent advances in machine learning for block\nidentification, our system provides expert users with an interactive tool for\nexploring, validating hypothesis, and integrating expert knowledge into\nmodel-generated results about the production process of early printed books.\nThe system is structured around an ontology of four conceptual objects\n(spreads, segments, blocks, and characters) each corresponding to a dedicated\nview in the system. These coordinated views enable scholars to navigate between\nmaterial evidence and computational abstractions, supporting close, near-by,\nand distant reading practices. Preliminary results from expert use of the\nsystem demonstrate its ability to reveal errors in segmentation,\ninconsistencies in clustering, and previously inaccessible patterns of block\nreuse.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u53ef\u89c6\u5316\u7cfb\u7edf\uff0c\u7528\u4e8e\u652f\u6301\u65e5\u672c\u53ef\u52a8\u6728\u6d3b\u5b57\u5370\u5237\u7814\u7a76\u7684\u5b57\u4f53\u9274\u5b9a\u3002", "motivation": "\u901a\u8fc7\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u4e13\u5bb6\u77e5\u8bc6\uff0c\u63d0\u5347\u5bf9\u65e9\u671f\u5370\u5237\u4e66\u7c4d\u751f\u4ea7\u6d41\u7a0b\u7684\u7814\u7a76\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u7cfb\u7edf\u57fa\u4e8e\u56db\u4e2a\u6982\u5ff5\u5bf9\u8c61\uff08\u5c55\u5f00\u3001\u6bb5\u3001\u5757\u548c\u5b57\u7b26\uff09\u6784\u5efa\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u652f\u6301\u4e0d\u540c\u9605\u8bfb\u5b9e\u8df5\u3002", "result": "\u521d\u6b65\u6d4b\u8bd5\u8868\u660e\uff0c\u7cfb\u7edf\u80fd\u53d1\u73b0\u5206\u5272\u9519\u8bef\u3001\u805a\u7c7b\u4e0d\u4e00\u81f4\u53ca\u4e0d\u53ef\u89c1\u7684\u5757\u91cd\u7528\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u4e13\u5bb6\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u5370\u5237\u5de5\u827a\u3002"}}
{"id": "2508.16263", "pdf": "https://arxiv.org/pdf/2508.16263", "abs": "https://arxiv.org/abs/2508.16263", "authors": ["Mocheng Li", "Xiao Yan", "Baotong Lu", "Yue Zhang", "James Cheng", "Chenhao Ma"], "title": "Attribute Filtering in Approximate Nearest Neighbor Search: An In-depth Experimental Study", "categories": ["cs.DB", "cs.IR"], "comment": "15 pages, 15 figures, Accepted at SIGMOD 2026", "summary": "With the growing integration of structured and unstructured data, new methods\nhave emerged for performing similarity searches on vectors while honoring\nstructured attribute constraints, i.e., a process known as Filtering\nApproximate Nearest Neighbor (Filtering ANN) search. Since many of these\nalgorithms have only appeared in recent years and are designed to work with a\nvariety of base indexing methods and filtering strategies, there is a pressing\nneed for a unified analysis that identifies their core techniques and enables\nmeaningful comparisons.\n  In this work, we present a unified Filtering ANN search interface that\nencompasses the latest algorithms and evaluate them extensively from multiple\nperspectives. First, we propose a comprehensive taxonomy of existing Filtering\nANN algorithms based on attribute types and filtering strategies. Next, we\nanalyze their key components, i.e., index structures, pruning strategies, and\nentry point selection, to elucidate design differences and tradeoffs. We then\nconduct a broad experimental evaluation on 10 algorithms and 12 methods across\n4 datasets (each with up to 10 million items), incorporating both synthetic and\nreal attributes and covering selectivity levels from 0.1% to 100%. Finally, an\nin-depth component analysis reveals the influence of pruning, entry point\nselection, and edge filtering costs on overall performance. Based on our\nfindings, we summarize the strengths and limitations of each approach, provide\npractical guidelines for selecting appropriate methods, and suggest promising\ndirections for future research. Our code is available at:\nhttps://github.com/lmccccc/FANNBench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8fc7\u6ee4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u63a5\u53e3\uff0c\u5bf9\u73b0\u6709\u7b97\u6cd5\u8fdb\u884c\u4e86\u5206\u7c7b\u548c\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u6027\u80fd\u6bd4\u8f83\u548c\u5b9e\u7528\u6307\u5357\u3002", "motivation": "\u968f\u7740\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\u7684\u878d\u5408\uff0c\u9700\u8981\u7edf\u4e00\u5206\u6790\u8fc7\u6ee4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7b97\u6cd5\uff0c\u4ee5\u4fbf\u6bd4\u8f83\u548c\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u7b97\u6cd5\u5173\u952e\u7ec4\u4ef6\uff08\u5982\u7d22\u5f15\u7ed3\u6784\u3001\u526a\u679d\u7b56\u7565\u7b49\uff09\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u526a\u679d\u3001\u5165\u53e3\u70b9\u9009\u62e9\u548c\u8fb9\u7f18\u8fc7\u6ee4\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u603b\u7ed3\u4e86\u5404\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "\u603b\u7ed3\u4e86\u6bcf\u79cd\u65b9\u6cd5\u7684\u9002\u7528\u573a\u666f\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.16236", "pdf": "https://arxiv.org/pdf/2508.16236", "abs": "https://arxiv.org/abs/2508.16236", "authors": ["Waleed El-Geresy", "D\u00e1niel Hajt\u00f3", "Gy\u00f6rgy Cserey", "Deniz G\u00fcnd\u00fcz"], "title": "Energy-Information Trade-Off in Self-Directed Channel Memristors", "categories": ["cs.ET", "cs.NE", "physics.app-ph"], "comment": "6 pages, 7 figures. To appear at the 2025 IEEE International Workshop\n  on Machine Learning for Signal Processing", "summary": "Understanding the nature of information storage on memristors is vital to\nenable their use in novel data storage and neuromorphic applications. One key\nconsideration in information storage is the energy cost of storage and what\nimpact the available energy has on the information capacity of the devices. In\nthis paper, we propose and study an energy-information trade-off for a\nparticular kind of memristive device - Self-Directed Channel (SDC) memristors.\nWe perform experiments to model the energy required to set the devices into\nvarious states, as well as assessing the stability of these states over time.\nBased on these results, we employ a generative modelling approach, using a\nconditional Generative Adversarial Network (cGAN) to characterise the storage\nconditional distribution, allowing us to estimate energy-information curves for\na range of storage delays, showing the graceful trade-off between energy\nconsumed and the effective capacity of the devices.", "AI": {"tldr": "\u7814\u7a76\u4e86SDC\u5fc6\u963b\u5668\u7684\u80fd\u91cf-\u4fe1\u606f\u6743\u8861\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5efa\u6a21\u80fd\u91cf\u9700\u6c42\uff0c\u5e76\u5229\u7528cGAN\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u5b58\u50a8\u6761\u4ef6\u5206\u5e03\u3002", "motivation": "\u63a2\u8ba8\u5fc6\u963b\u5668\u5728\u6570\u636e\u5b58\u50a8\u548c\u795e\u7ecf\u5f62\u6001\u5e94\u7528\u4e2d\u7684\u4fe1\u606f\u5b58\u50a8\u80fd\u529b\u53ca\u5176\u80fd\u8017\u5173\u7cfb\u3002", "method": "\u5b9e\u9a8c\u6d4b\u91cfSDC\u5fc6\u963b\u5668\u72b6\u6001\u8bbe\u5b9a\u80fd\u8017\u53ca\u7a33\u5b9a\u6027\uff0c\u5e76\u4f7f\u7528cGAN\u751f\u6210\u6a21\u578b\u5206\u6790\u5b58\u50a8\u6761\u4ef6\u5206\u5e03\u3002", "result": "\u63ed\u793a\u4e86\u80fd\u91cf\u6d88\u8017\u4e0e\u8bbe\u5907\u6709\u6548\u5bb9\u91cf\u4e4b\u95f4\u7684\u4f18\u96c5\u6743\u8861\u3002", "conclusion": "SDC\u5fc6\u963b\u5668\u7684\u80fd\u91cf-\u4fe1\u606f\u6743\u8861\u4e3a\u4f18\u5316\u5b58\u50a8\u8bbe\u5907\u548c\u795e\u7ecf\u5f62\u6001\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.16151", "pdf": "https://arxiv.org/pdf/2508.16151", "abs": "https://arxiv.org/abs/2508.16151", "authors": ["Yang Liu", "Yi Chen", "Yongwei Zhao", "Yifan Hao", "Zifu Zheng", "Weihao Kong", "Zhangmai Li", "Dongchen Jiang", "Ruiyang Xia", "Zhihong Ma", "Zisheng Liu", "Zhaoyong Wan", "Yunqi Lu", "Ximing Liu", "Hongrui Guo", "Zhihao Yang", "Zhe Wang", "Tianrui Ma", "Mo Zou", "Rui Zhang", "Ling Li", "Xing Hu", "Zidong Du", "Zhiwei Xu", "Qi Guo", "Tianshi Chen", "Yunji Chen"], "title": "Hardwired-Neurons Language Processing Units as General-Purpose Cognitive Substrates", "categories": ["cs.AR", "cs.CL"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has established\nlanguage as a core general-purpose cognitive substrate, driving the demand for\nspecialized Language Processing Units (LPUs) tailored for LLM inference. To\novercome the growing energy consumption of LLM inference systems, this paper\nproposes a Hardwired-Neurons Language Processing Unit (HNLPU), which physically\nhardwires LLM weight parameters into the computational fabric, achieving\nseveral orders of magnitude computational efficiency improvement by extreme\nspecialization. However, a significant challenge still lies in the scale of\nmodern LLMs. An ideal estimation on hardwiring gpt-oss 120 B requires\nfabricating at least 6 billion dollars of photomask sets, rendering the\nstraightforward solution economically impractical. Addressing this challenge,\nwe propose the novel Metal-Embedding methodology. Instead of embedding weights\nin a 2D grid of silicon device cells, Metal-Embedding embeds weight parameters\ninto the 3D topology of metal wires. This brings two benefits: (1) a 15x\nincrease in density, and (2) 60 out of 70 layers of photomasks are made\nhomogeneous across chips, including all EUV photomasks. In total,\nMetal-Embedding reduced the photomask cost by 112x, bringing the Non-Recurring\nEngineering (NRE) cost of HNLPU into an economically viable range. Experimental\nresults show that HNLPU achieved 249,960 tokens/s (5,555x/85x of GPU/WSE), 36\ntokens/J (1,047x/283x of GPU/WSE), 13,232 mm2 total die area (29% inscribed\nrectangular area in a 300 mm wafer), \\$184M estimated NRE at 5 nm technology.\nAnalysis shows that HNLPU achieved 8.57x cost-effectiveness and 230x carbon\nfootprint reduction compared to H100 clusters, under an annual weight updating\nassumption.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u8bbe\u8ba1\u7684\u786c\u8fde\u7ebf\u795e\u7ecf\u5143\u8bed\u8a00\u5904\u7406\u5355\u5143\uff08HNLPU\uff09\uff0c\u5e76\u901a\u8fc7\u91d1\u5c5e\u5d4c\u5165\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5236\u9020\u6210\u672c\uff0c\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u80fd\u6e90\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5176\u63a8\u7406\u4efb\u52a1\u5bf9\u80fd\u6e90\u7684\u9700\u6c42\u6025\u5267\u589e\u52a0\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u4e13\u7528\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u786c\u8fde\u7ebf\u6280\u672f\uff0c\u5c06LLM\u6743\u91cd\u53c2\u6570\u76f4\u63a5\u5d4c\u5165\u8ba1\u7b97\u67b6\u6784\u4e2d\uff0c\u5e76\u901a\u8fc7\u521b\u65b0\u7684\u91d1\u5c5e\u5d4c\u5165\u65b9\u6cd5\u63d0\u5347\u5bc6\u5ea6\u548c\u964d\u4f4e\u5236\u9020\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cHNLPU\u5728\u8ba1\u7b97\u6548\u7387\u3001\u80fd\u6e90\u6548\u7387\u548c\u5236\u9020\u6210\u672c\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709GPU\u548cWSE\u6280\u672f\u3002", "conclusion": "HNLPU\u901a\u8fc7\u786c\u8fde\u7ebf\u548c\u91d1\u5c5e\u5d4c\u5165\u6280\u672f\uff0c\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7ecf\u6d4e\u4e14\u73af\u4fdd\u7684\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15833", "pdf": "https://arxiv.org/pdf/2508.15833", "abs": "https://arxiv.org/abs/2508.15833", "authors": ["Linfeng Shen", "Guanzhen Wu", "Cong Zhang", "Xiaoyi Fan", "Jiangchuan Liu"], "title": "Towards Integrated Energy-Communication-Transportation Hub: A Base-Station-Centric Design in 5G and Beyond", "categories": ["cs.NI", "cs.DC"], "comment": null, "summary": "The rise of 5G communication has transformed the telecom industry for\ncritical applications. With the widespread deployment of 5G base stations comes\na significant concern about energy consumption. Key industrial players have\nrecently shown strong interest in incorporating energy storage systems to store\nexcess energy during off-peak hours, reducing costs and participating in demand\nresponse. The fast development of batteries opens up new possibilities, such as\nthe transportation area. An effective method is needed to maximize base station\nbattery utilization and reduce operating costs. In this trend towards\nnext-generation smart and integrated energy-communication-transportation (ECT)\ninfrastructure, base stations are believed to play a key role as service hubs.\nBy exploring the overlap between base station distribution and electric vehicle\ncharging infrastructure, we demonstrate the feasibility of efficiently charging\nEVs using base station batteries and renewable power plants at the Hub. Our\nmodel considers various factors, including base station traffic conditions,\nweather, and EV charging behavior. This paper introduces an incentive mechanism\nfor setting charging prices and employs a deep reinforcement learning-based\nmethod for battery scheduling. Experimental results demonstrate the\neffectiveness of our proposed ECT-Hub in optimizing surplus energy utilization\nand reducing operating costs, particularly through revenue-generating EV\ncharging.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e865G\u57fa\u7ad9\u4f5c\u4e3a\u80fd\u6e90-\u901a\u4fe1-\u4ea4\u901a\uff08ECT\uff09\u67a2\u7ebd\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u4f18\u5316\u7535\u6c60\u8c03\u5ea6\u548cEV\u5145\u7535\u4ef7\u683c\u6fc0\u52b1\u673a\u5236\uff0c\u63d0\u9ad8\u80fd\u6e90\u5229\u7528\u6548\u7387\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "5G\u57fa\u7ad9\u7684\u5e7f\u6cdb\u90e8\u7f72\u5e26\u6765\u9ad8\u80fd\u8017\u95ee\u9898\uff0c\u5de5\u4e1a\u754c\u5bf9\u50a8\u80fd\u7cfb\u7edf\u5174\u8da3\u6d53\u539a\uff0c\u9700\u6709\u6548\u5229\u7528\u57fa\u7ad9\u7535\u6c60\u51cf\u5c11\u8fd0\u8425\u6210\u672c\u5e76\u53c2\u4e0e\u9700\u6c42\u54cd\u5e94\u3002", "method": "\u7ed3\u5408\u57fa\u7ad9\u5206\u5e03\u4e0eEV\u5145\u7535\u8bbe\u65bd\uff0c\u63d0\u51fa\u6fc0\u52b1\u673a\u5236\u8bbe\u5b9a\u5145\u7535\u4ef7\u683c\uff0c\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u7535\u6c60\u8c03\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eECT-Hub\u80fd\u4f18\u5316\u5269\u4f59\u80fd\u6e90\u5229\u7528\uff0c\u901a\u8fc7EV\u5145\u7535\u521b\u6536\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u3002", "conclusion": "\u57fa\u7ad9\u4f5c\u4e3aECT\u67a2\u7ebd\u5177\u5907\u6f5c\u529b\uff0c\u7ed3\u5408\u6fc0\u52b1\u673a\u5236\u548c\u6df1\u5ea6\u5b66\u4e60\u53ef\u9ad8\u6548\u5b9e\u73b0\u80fd\u6e90\u4e0e\u4ea4\u901a\u6574\u5408\u3002"}}
{"id": "2508.15819", "pdf": "https://arxiv.org/pdf/2508.15819", "abs": "https://arxiv.org/abs/2508.15819", "authors": ["Qiang Duan", "Zhihui Lu"], "title": "Agent Communications toward Agentic AI at Edge -- A Case Study of the Agent2Agent Protocol", "categories": ["cs.NI"], "comment": null, "summary": "The current evolution of artificial intelligence introduces a paradigm shift\ntoward agentic AI built upon multi-agent systems (MAS). Agent communications\nserve as a key to effective agent interactions in MAS and thus have a\nsignificant impact on the performance of agentic AI applications. The recent\nresearch on agent communications has made exciting rapid progress that leads to\na variety of protocol designs, among which the Agent2Agent (A2A) protocol is\nconsidered the most representative one. Simultaneously, the rise of edge\nintelligence is expected to enable agentic AI at the network edge. However, the\ncurrent agent communication protocols are designed without sufficient\nconsideration of the special challenges of edge computing, and their\neffectiveness in the edge environment is largely unexamined. In this paper, we\nattempt to assess the abilities of agent communication technologies to face the\nchallenges of edge computing using the A2A protocol as a representative case.\nWe first discuss the core functionalities of agent communications, present a\nlandscape of agent communication protocols, and identify the main challenges\nintroduced by edge computing. Then, we conduct a case study on the A2A protocol\nto examine the key technologies leveraged in the protocol for their\neffectiveness in meeting the requirements of agent communications in edge\ncomputing. Based on the insights obtained from this assessment, we identify\nopen issues in the current agent communication technologies and discuss\ndirections for future research to address these issues.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4ee3\u7406\u901a\u4fe1\u6280\u672f\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4ee5A2A\u534f\u8bae\u4e3a\u4f8b\uff0c\u5206\u6790\u4e86\u5176\u5728\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u8fb9\u7f18\u667a\u80fd\u7684\u5174\u8d77\uff0c\u73b0\u6709\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\u672a\u5145\u5206\u8003\u8651\u8fb9\u7f18\u8ba1\u7b97\u7684\u7279\u6b8a\u6311\u6218\uff0c\u5176\u6709\u6548\u6027\u6709\u5f85\u9a8c\u8bc1\u3002", "method": "\u8bc4\u4f30A2A\u534f\u8bae\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u5176\u5173\u952e\u6280\u672f\uff0c\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "A2A\u534f\u8bae\u5728\u8fb9\u7f18\u73af\u5883\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u9002\u5e94\u8fb9\u7f18\u8ba1\u7b97\u9700\u6c42\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u4e8e\u89e3\u51b3\u5f53\u524d\u4ee3\u7406\u901a\u4fe1\u6280\u672f\u7684\u5f00\u653e\u95ee\u9898\uff0c\u4ee5\u9002\u5e94\u8fb9\u7f18\u8ba1\u7b97\u7684\u9700\u6c42\u3002"}}
{"id": "2508.16165", "pdf": "https://arxiv.org/pdf/2508.16165", "abs": "https://arxiv.org/abs/2508.16165", "authors": ["Sebastian Lubos", "Alexander Felfernig", "Gerhard Leitner", "Julian Schwazer"], "title": "Towards Recommending Usability Improvements with Multimodal Large Language Models", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Usability describes a set of essential quality attributes of user interfaces\n(UI) that influence human-computer interaction. Common evaluation methods, such\nas usability testing and inspection, are effective but resource-intensive and\nrequire expert involvement. This makes them less accessible for smaller\norganizations. Recent advances in multimodal LLMs offer promising opportunities\nto automate usability evaluation processes partly by analyzing textual, visual,\nand structural aspects of software interfaces. To investigate this possibility,\nwe formulate usability evaluation as a recommendation task, where multimodal\nLLMs rank usability issues by severity. We conducted an initial\nproof-of-concept study to compare LLM-generated usability improvement\nrecommendations with usability expert assessments. Our findings indicate the\npotential of LLMs to enable faster and more cost-effective usability\nevaluation, which makes it a practical alternative in contexts with limited\nexpert resources.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u8bc4\u4f30\u7528\u6237\u754c\u9762\u53ef\u7528\u6027\u7684\u6f5c\u529b\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u3001\u4f9d\u8d56\u4e13\u5bb6\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u53ef\u7528\u6027\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982\u6d4b\u8bd5\u548c\u68c0\u67e5\uff09\u867d\u7136\u6709\u6548\uff0c\u4f46\u5bf9\u8d44\u6e90\u8981\u6c42\u9ad8\u4e14\u9700\u4e13\u5bb6\u53c2\u4e0e\uff0c\u9650\u5236\u4e86\u5c0f\u578b\u7ec4\u7ec7\u7684\u4f7f\u7528\u3002\u591a\u6a21\u6001LLM\u7684\u51fa\u73b0\u4e3a\u90e8\u5206\u81ea\u52a8\u5316\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u7814\u7a76\u5c06\u53ef\u7528\u6027\u8bc4\u4f30\u8f6c\u5316\u4e3a\u63a8\u8350\u4efb\u52a1\uff0c\u7531\u591a\u6a21\u6001LLM\u6839\u636e\u4e25\u91cd\u6027\u5bf9\u53ef\u7528\u6027\u95ee\u9898\u8fdb\u884c\u6392\u5e8f\uff0c\u5e76\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u7ed3\u679c\u5bf9\u6bd4\u3002", "result": "\u521d\u6b65\u7814\u7a76\u8868\u660e\uff0cLLM\u80fd\u591f\u751f\u6210\u4e0e\u4e13\u5bb6\u76f8\u8fd1\u7684\u53ef\u7528\u6027\u6539\u8fdb\u5efa\u8bae\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u7ecf\u6d4e\u7684\u8bc4\u4f30\u3002", "conclusion": "\u591a\u6a21\u6001LLM\u5728\u8d44\u6e90\u53d7\u9650\u7684\u573a\u666f\u4e0b\uff0c\u53ef\u4f5c\u4e3a\u5b9e\u7528\u6027\u66ff\u4ee3\u65b9\u6848\u7528\u4e8e\u53ef\u7528\u6027\u8bc4\u4f30\u3002"}}
{"id": "2508.16439", "pdf": "https://arxiv.org/pdf/2508.16439", "abs": "https://arxiv.org/abs/2508.16439", "authors": ["Adil Bahaj", "Mounir Ghogho"], "title": "PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.GR", "cs.MM"], "comment": null, "summary": "Large language models (LLMs) and vision-augmented LLMs (VLMs) have\nsignificantly advanced medical informatics, diagnostics, and decision support.\nHowever, these models exhibit systematic biases, particularly age bias,\ncompromising their reliability and equity. This is evident in their poorer\nperformance on pediatric-focused text and visual question-answering tasks. This\nbias reflects a broader imbalance in medical research, where pediatric studies\nreceive less funding and representation despite the significant disease burden\nin children. To address these issues, a new comprehensive multi-modal pediatric\nquestion-answering benchmark, PediatricsMQA, has been introduced. It consists\nof 3,417 text-based multiple-choice questions (MCQs) covering 131 pediatric\ntopics across seven developmental stages (prenatal to adolescent) and 2,067\nvision-based MCQs using 634 pediatric images from 67 imaging modalities and 256\nanatomical regions. The dataset was developed using a hybrid manual-automatic\npipeline, incorporating peer-reviewed pediatric literature, validated question\nbanks, existing benchmarks, and existing QA resources. Evaluating\nstate-of-the-art open models, we find dramatic performance drops in younger\ncohorts, highlighting the need for age-aware methods to ensure equitable AI\nsupport in pediatric care.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u513f\u79d1\u95ee\u7b54\u57fa\u51c6PediatricsMQA\uff0c\u65e8\u5728\u89e3\u51b3\u533b\u5b66\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u5e74\u9f84\u504f\u89c1\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5728\u513f\u79d1\u4efb\u52a1\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u5e74\u9f84\u611f\u77e5\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u516c\u5e73\u7684AI\u652f\u6301\u3002", "motivation": "\u533b\u5b66\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u5e74\u9f84\u504f\u89c1\uff0c\u5c24\u5176\u5728\u513f\u79d1\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u53cd\u6620\u4e86\u533b\u5b66\u7814\u7a76\u4e2d\u513f\u79d1\u9886\u57df\u7684\u8d44\u91d1\u548c\u4ee3\u8868\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3,417\u4e2a\u6587\u672c\u591a\u9009\u9898\u548c2,067\u4e2a\u89c6\u89c9\u591a\u9009\u9898\u7684\u7efc\u5408\u513f\u79d1\u6570\u636e\u96c6\uff0c\u91c7\u7528\u6df7\u5408\u624b\u52a8-\u81ea\u52a8\u6d41\u7a0b\uff0c\u6574\u5408\u4e86\u591a\u4e2a\u6743\u5a01\u8d44\u6e90\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u5e74\u8f7b\u7fa4\u4f53\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u7a81\u663e\u4e86\u5e74\u9f84\u504f\u89c1\u7684\u4e25\u91cd\u6027\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u5e74\u9f84\u611f\u77e5\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fddAI\u5728\u513f\u79d1\u62a4\u7406\u4e2d\u7684\u516c\u5e73\u6027\u3002"}}
{"id": "2508.16125", "pdf": "https://arxiv.org/pdf/2508.16125", "abs": "https://arxiv.org/abs/2508.16125", "authors": ["Zhenyang Xu", "Hongxu Xu", "Yongqiang Tian", "Xintong Zhou", "Chengnian Sun"], "title": "Leveraging Large Language Models to Detect Missed Peephole Optimizations", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "By replacing small, suboptimal instruction sequences within programs with a\nmore efficient equivalent, peephole optimization can not only directly optimize\ncode size and performance, but also potentially enables further transformations\nin the subsequent optimization pipeline. Although peephole optimization is a\ncritical class of compiler optimizations, discovering new and effective\npeephole optimizations is challenging as the instruction sets can be extremely\ncomplex and diverse. Previous methods either do not scale well or can only\ncapture a limited subset of peephole optimizations. In this work, we leverage\nLarge Language Models (LLMs) to detect missed peephole optimizations. We\npropose Lampo, a novel automated framework that synergistically combines the\ncreative but unreliable code optimization ability of LLMs with rigorous\ncorrectness verification performed by translation validation tools, integrated\nin a feedback-driven iterative process. Through a comprehensive evaluation\nwithin LLVM ecosystems, we show that Lampo can successfully detect up to 17 out\nof 25 previously reported missed optimizations in LLVM on average, and that 22\nout of 25 can potentially be found by Lampo with different LLMs. For\ncomparison, the state-of-the-art superoptimizer for LLVM, Souper, identified 15\nof them. Moreover, within seven months of development and intermittent\nexperiments, Lampo found 26 missed peephole optimizations, 15 of which have\nbeen confirmed and 6 already fixed. These results demonstrate Lampo's strong\npotential in continuously detecting missed peephole optimizations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLampo\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7ed3\u5408\u9a8c\u8bc1\u5de5\u5177\uff0c\u9ad8\u6548\u53d1\u73b0\u5e76\u9a8c\u8bc1\u7f16\u8bd1\u5668\u4e2d\u7684\u6f0f\u6d1e\u4f18\u5316\u673a\u4f1a\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u6307\u4ee4\u96c6\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u53d1\u73b0\u6709\u6548\u7684\u6f0f\u6d1e\u4f18\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0cLampo\u65e8\u5728\u901a\u8fc7LLMs\u7684\u521b\u65b0\u80fd\u529b\u548c\u4e25\u683c\u9a8c\u8bc1\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "Lampo\u7ed3\u5408LLMs\u7684\u4ee3\u7801\u4f18\u5316\u80fd\u529b\u4e0e\u7ffb\u8bd1\u9a8c\u8bc1\u5de5\u5177\uff0c\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u6d41\u7a0b\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4f18\u5316\u673a\u4f1a\u3002", "result": "\u5728LLVM\u751f\u6001\u4e2d\uff0cLampo\u5e73\u5747\u68c0\u6d4b\u523017/25\u7684\u5df2\u77e5\u4f18\u5316\u6f0f\u6d1e\uff0c\u5e76\u53d1\u73b026\u4e2a\u65b0\u4f18\u5316\uff0c\u5176\u4e2d15\u4e2a\u5df2\u786e\u8ba4\uff0c6\u4e2a\u5df2\u4fee\u590d\u3002", "conclusion": "Lampo\u5c55\u793a\u4e86\u5728\u6301\u7eed\u68c0\u6d4b\u6f0f\u6d1e\u4f18\u5316\u65b9\u9762\u7684\u5f3a\u5927\u6f5c\u529b\uff0c\u4e3a\u7f16\u8bd1\u5668\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.16242", "pdf": "https://arxiv.org/pdf/2508.16242", "abs": "https://arxiv.org/abs/2508.16242", "authors": ["Alexander Steen"], "title": "A Reduction of Input/Output Logics to SAT", "categories": ["cs.LO", "cs.AI", "68T27", "I.2.3"], "comment": "32 pages", "summary": "Deontic logics are formalisms for reasoning over norms, obligations,\npermissions and prohibitions. Input/Output (I/O) Logics are a particular family\nof so-called norm-based deontic logics that formalize conditional norms outside\nof the underlying object logic language, where conditional norms do not carry a\ntruth-value themselves. In this paper, an automation approach for I/O logics is\npresented that makes use of suitable reductions to (sequences of) propositional\nsatisfiability problems. A prototypical implementation, named rio (reasoner for\ninput/output logics), of the proposed procedures is presented and applied to\nillustrative examples.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u547d\u9898\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5f52\u7ea6\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406I/O\u903b\u8f91\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u5b9e\u73b0rio\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u4e3aI/O\u903b\u8f91\u63d0\u4f9b\u4e00\u79cd\u81ea\u52a8\u5316\u63a8\u7406\u65b9\u6cd5\uff0c\u5f25\u8865\u5176\u5728\u5f62\u5f0f\u5316\u5904\u7406\u4e2d\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5c06I/O\u903b\u8f91\u95ee\u9898\u5f52\u7ea6\u5230\u547d\u9898\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5e8f\u5217\u4e2d\uff0c\u5e76\u5f00\u53d1\u4e86\u539f\u578b\u5de5\u5177rio\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86I/O\u903b\u8f91\u7684\u81ea\u52a8\u5316\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aI/O\u903b\u8f91\u7684\u81ea\u52a8\u5316\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6269\u5c55\u3002"}}
{"id": "2508.16076", "pdf": "https://arxiv.org/pdf/2508.16076", "abs": "https://arxiv.org/abs/2508.16076", "authors": ["Md Tariquzzaman", "Md Farhan Ishmam", "Saiyma Sittul Muna", "Md Kamrul Hasan", "Hasan Mahmud"], "title": "Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation", "categories": ["cs.HC", "cs.CV"], "comment": "CV4A11y@ICCV 2025", "summary": "Sign Language (SL) enables two-way communication for the deaf and\nhard-of-hearing community, yet many sign languages remain under-resourced in\nthe AI space. Sign Language Instruction Generation (SLIG) produces step-by-step\ntextual instructions that enable non-SL users to imitate and learn SL gestures,\npromoting two-way interaction. We introduce BdSLIG, the first Bengali SLIG\ndataset, used to evaluate Vision Language Models (VLMs) (i) on under-resourced\nSLIG tasks, and (ii) on long-tail visual concepts, as Bengali SL is unlikely to\nappear in the VLM pre-training data. To enhance zero-shot performance, we\nintroduce Sign Parameter-Infused (SPI) prompting, which integrates standard SL\nparameters, like hand shape, motion, and orientation, directly into the textual\nprompts. Subsuming standard sign parameters into the prompt makes the\ninstructions more structured and reproducible than free-form natural text from\nvanilla prompting. We envision that our work would promote inclusivity and\nadvancement in SL learning systems for the under-resourced communities.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7b2c\u4e00\u4e2a\u5b5f\u52a0\u62c9\u624b\u8bed\u6307\u4ee4\u751f\u6210\u6570\u636e\u96c6BdSLIG\uff0c\u5e76\u63d0\u51faSign Parameter-Infused (SPI)\u63d0\u793a\u65b9\u6cd5\u63d0\u5347\u96f6\u6837\u672c\u6027\u80fd\uff0c\u4fc3\u8fdb\u8d44\u6e90\u532e\u4e4f\u793e\u533a\u7684\u624b\u8bed\u5b66\u4e60\u3002", "motivation": "\u4e3a\u89e3\u51b3\u8d44\u6e90\u532e\u4e4f\u624b\u8bed\u5728AI\u9886\u57df\u7684\u7814\u7a76\u4e0d\u8db3\u95ee\u9898\uff0c\u63a8\u52a8\u542c\u969c\u793e\u533a\u7684\u53cc\u5411\u4ea4\u6d41\u4e0e\u5b66\u4e60\u3002", "method": "\u5f15\u5165BdSLIG\u6570\u636e\u96c6\uff0c\u63d0\u51faSPI\u63d0\u793a\u6cd5\uff0c\u5c06\u6807\u51c6\u624b\u8bed\u53c2\u6570\uff08\u5982\u624b\u5f62\u3001\u52a8\u4f5c\u3001\u65b9\u5411\uff09\u878d\u5165\u6587\u672c\u63d0\u793a\u4e2d\u3002", "result": "SPI\u63d0\u793a\u6cd5\u4f7f\u6307\u4ee4\u66f4\u7ed3\u6784\u5316\u3001\u53ef\u590d\u73b0\uff0c\u4f18\u4e8e\u81ea\u7531\u6587\u672c\u63d0\u793a\uff0c\u63d0\u5347\u4e86\u96f6\u6837\u672c\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4fc3\u8fdb\u4e86\u8d44\u6e90\u532e\u4e4f\u793e\u533a\u7684\u624b\u8bed\u5b66\u4e60\u7cfb\u7edf\u7684\u5305\u5bb9\u6027\u4e0e\u6280\u672f\u8fdb\u6b65\u3002"}}
{"id": "2508.15809", "pdf": "https://arxiv.org/pdf/2508.15809", "abs": "https://arxiv.org/abs/2508.15809", "authors": ["Songyuan Sui", "Hongyi Liu", "Serena Liu", "Li Li", "Soo-Hyun Choi", "Rui Chen", "Xia Hu"], "title": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": "9 pages main content, 24 pages total including appendix, 6 figures", "summary": "Table understanding requires structured, multi-step reasoning. Large Language\nModels (LLMs) struggle with it due to the structural complexity of tabular\ndata. Recently, multi-agent frameworks for SQL generation have shown promise in\ntackling the challenges of understanding tabular data, but existing approaches\noften suffer from limitations such as the inability to comprehend table\nstructure for reliable SQL generation, error propagation that results in\ninvalid queries, and over-reliance on execution correctness. To address these\nissues, we propose Chain-of-Query (CoQ), a novel multi-agent framework for\nSQL-aided table understanding. CoQ adopts natural-language-style\nrepresentations of table schemas to abstract away structural noise and enhance\nunderstanding. It employs a clause-by-clause SQL generation strategy to improve\nquery quality and introduces a hybrid reasoning division that separates\nSQL-based mechanical reasoning from LLM-based logical inference, thereby\nreducing reliance on execution outcomes. Experiments with four models (both\nclosed- and open-source) across five widely used benchmarks show that\nChain-of-Query significantly improves accuracy from 61.11% to 74.77% and\nreduces the invalid SQL rate from 9.48% to 3.34%, demonstrating its superior\neffectiveness in table understanding. The code is available at\nhttps://github.com/SongyuanSui/ChainofQuery.", "AI": {"tldr": "CoQ\u662f\u4e00\u79cd\u65b0\u578b\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5f0f\u8868\u683c\u8868\u793a\u548c\u5206\u53e5SQL\u751f\u6210\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8868\u7406\u89e3\u7684\u51c6\u786e\u6027\u548cSQL\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u8868\u683c\u7ed3\u6784\u7406\u89e3\u3001\u9519\u8bef\u4f20\u64ad\u548c\u8fc7\u5ea6\u4f9d\u8d56\u6267\u884c\u6b63\u786e\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u81ea\u7136\u8bed\u8a00\u5f0f\u8868\u683c\u8868\u793a\uff0c\u5206\u53e5\u751f\u6210SQL\uff0c\u5e76\u5206\u79bbSQL\u673a\u68b0\u63a8\u7406\u4e0eLLM\u903b\u8f91\u63a8\u7406\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u51c6\u786e\u7387\u4ece61.11%\u63d0\u5347\u81f374.77%\uff0c\u65e0\u6548SQL\u7387\u4ece9.48%\u964d\u81f33.34%\u3002", "conclusion": "CoQ\u5728\u8868\u7406\u89e3\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.16376", "pdf": "https://arxiv.org/pdf/2508.16376", "abs": "https://arxiv.org/abs/2508.16376", "authors": ["Jiaping Tang", "Jianan Mu", "Zizhen Liu", "Ge Yu", "Tenghui Hua", "Bin Sun", "Silin Liu", "Jing Ye", "Huawei Li"], "title": "RIROS: A Parallel RTL Fault SImulation FRamework with TwO-Dimensional Parallelism and Unified Schedule", "categories": ["cs.AR"], "comment": "Accepted by ICCAD 2025", "summary": "With the rapid development of safety-critical applications such as autonomous\ndriving and embodied intelligence, the functional safety of the corresponding\nelectronic chips becomes more critical. Ensuring chip functional safety\nrequires performing a large number of time-consuming RTL fault simulations\nduring the design phase, significantly increasing the verification cycle. To\nmeet time-to-market demands while ensuring thorough chip verification, parallel\nacceleration of RTL fault simulation is necessary. Due to the dynamic nature of\nfault propagation paths and varying fault propagation capabilities, task loads\nin RTL fault simulation are highly imbalanced, making traditional\nsingledimension parallel methods, such as structural-level parallelism,\nineffective. Through an analysis of fault propagation paths and task loads, we\nidentify two types of tasks in RTL fault simulation: tasks that are few in\nnumber but high in load, and tasks that are numerous but low in load. Based on\nthis insight, we propose a two-dimensional parallel approach that combines\nstructurallevel and fault-level parallelism to minimize bubbles in RTL fault\nsimulation. Structural-level parallelism combining with workstealing mechanism\nis used to handle the numerous low-load tasks, while fault-level parallelism is\napplied to split the high-load tasks. Besides, we deviate from the traditional\nserial execution model of computation and global synchronization in RTL\nsimulation by proposing a unified computation/global synchronization scheduling\napproach, which further eliminates bubbles. Finally, we implemented a parallel\nRTL fault simulation framework, RIROS. Experimental results show a performance\nimprovement of 7.0 times and 11.0 times compared to the state-of-the-art RTL\nfault simulation and a commercial tool.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e8c\u7ef4\u5e76\u884c\u65b9\u6cd5\uff08RIROS\uff09\u6765\u52a0\u901fRTL\u6545\u969c\u6a21\u62df\uff0c\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u7684\u53d1\u5c55\uff0c\u82af\u7247\u529f\u80fd\u5b89\u5168\u7684\u9a8c\u8bc1\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u4f20\u7edf\u5e76\u884c\u65b9\u6cd5\u6548\u7387\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u7ed3\u6784\u7ea7\u548c\u6545\u969c\u7ea7\u5e76\u884c\uff0c\u5f15\u5165\u5de5\u4f5c\u7a83\u53d6\u673a\u5236\u548c\u7edf\u4e00\u8c03\u5ea6\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u5206\u522b\u63d0\u53477\u500d\u548c11\u500d\u3002", "conclusion": "RIROS\u80fd\u9ad8\u6548\u51cf\u5c11RTL\u6545\u969c\u6a21\u62df\u4e2d\u7684\u7a7a\u95f2\u65f6\u95f4\u3002"}}
{"id": "2508.16268", "pdf": "https://arxiv.org/pdf/2508.16268", "abs": "https://arxiv.org/abs/2508.16268", "authors": ["Rob Carson", "Mohamed Chahine Ghanem", "Feriel Bouakkaz"], "title": "Self-Healing Network of Interconnected Edge Devices Empowered by Infrastructure-as-Code and LoRa Communication", "categories": ["cs.NI", "cs.DC"], "comment": null, "summary": "This Paper proposes a self-healing, automated network of Raspberry Pi devices\ndesigned for deployment in scenarios where traditional networking is\nunavailable. Leveraging the low-power, long-range capabilities of the LoRa\n(Long Range) protocol alongside Infrastructure as Code (IaC) methodologies, the\nresearch addresses challenges such as limited bandwidth, data collisions, and\nnode failures. Given that LoRa's packet-based system is incompatible with\nconventional IaC tools like Ansible and Terraform, which rely on TCP/IP\nnetworking, the research adapts IaC principles within a containerised\narchitecture deployed across a Raspberry Pi cluster. Evaluation experiments\nindicate that fragmenting data packets and retransmitting any missed fragments\ncan mitigate LoRa's inherent throughput and packet size limitations, although\nissues such as collisions and line-of-sight interference persist. An automated\nfailover mechanism was integrated into the architecture, enabling unresponsive\nservices to be redeployed to alternative nodes within one second, demonstrating\nthe system's resilience in maintaining operational continuity despite node or\nservice failures. The paper also identifies practical challenges, including the\nnecessity for time-slotting transmissions to prevent data packet overlap and\ncollisions. Future research should explore the integration of mesh networking\nto enhance range, develop more advanced scheduling algorithms, and adopt\ncutting-edge low-power wide-area network (LPWAN) techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRaspberry Pi\u7684\u81ea\u6108\u81ea\u52a8\u7f51\u7edc\uff0c\u5229\u7528LoRa\u534f\u8bae\u548cIaC\u65b9\u6cd5\u89e3\u51b3\u4f20\u7edf\u7f51\u7edc\u4e0d\u53ef\u7528\u573a\u666f\u4e0b\u7684\u6311\u6218\uff0c\u4f46\u5b58\u5728\u541e\u5410\u91cf\u548c\u6570\u636e\u5305\u78b0\u649e\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5728\u4f20\u7edf\u7f51\u7edc\u4e0d\u53ef\u7528\u573a\u666f\u4e0b\u7684\u901a\u4fe1\u95ee\u9898\uff0c\u5229\u7528LoRa\u548cIaC\u5b9e\u73b0\u4f4e\u529f\u8017\u3001\u957f\u8ddd\u79bb\u7684\u81ea\u6108\u7f51\u7edc\u3002", "method": "\u91c7\u7528\u5bb9\u5668\u5316\u67b6\u6784\u90e8\u7f72Raspberry Pi\u96c6\u7fa4\uff0c\u7ed3\u5408LoRa\u534f\u8bae\u548cIaC\u539f\u5219\uff0c\u901a\u8fc7\u6570\u636e\u5305\u5206\u7247\u548c\u91cd\u4f20\u89e3\u51b3\u541e\u5410\u91cf\u95ee\u9898\uff0c\u96c6\u6210\u81ea\u52a8\u6545\u969c\u8f6c\u79fb\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5206\u7247\u548c\u91cd\u4f20\u53ef\u7f13\u89e3LoRa\u7684\u541e\u5410\u91cf\u9650\u5236\uff0c\u81ea\u52a8\u6545\u969c\u8f6c\u79fb\u673a\u5236\u80fd\u57281\u79d2\u5185\u6062\u590d\u670d\u52a1\uff0c\u4f46\u78b0\u649e\u548c\u89c6\u7ebf\u5e72\u6270\u95ee\u9898\u4ecd\u5b58\u5728\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u81ea\u6108\u7f51\u7edc\u7684\u53ef\u884c\u6027\uff0c\u672a\u6765\u9700\u63a2\u7d22\u7f51\u72b6\u7f51\u7edc\u3001\u9ad8\u7ea7\u8c03\u5ea6\u7b97\u6cd5\u548cLPWAN\u6280\u672f\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.16181", "pdf": "https://arxiv.org/pdf/2508.16181", "abs": "https://arxiv.org/abs/2508.16181", "authors": ["Zirui Li", "Stephan Husung", "Haoze Wang"], "title": "LLM-Assisted Semantic Alignment and Integration in Collaborative Model-Based Systems Engineering Using SysML v2", "categories": ["cs.SE", "cs.AI", "cs.SY", "eess.SY"], "comment": "Accepted by IEEE ISSE 2025, DOI pending", "summary": "Cross-organizational collaboration in Model-Based Systems Engineering (MBSE)\nfaces many challenges in achieving semantic alignment across independently\ndeveloped system models. SysML v2 introduces enhanced structural modularity and\nformal semantics, offering a stronger foundation for interoperable modeling.\nMeanwhile, GPT-based Large Language Models (LLMs) provide new capabilities for\nassisting model understanding and integration. This paper proposes a\nstructured, prompt-driven approach for LLM-assisted semantic alignment of SysML\nv2 models. The core contribution lies in the iterative development of an\nalignment approach and interaction prompts, incorporating model extraction,\nsemantic matching, and verification. The approach leverages SysML v2 constructs\nsuch as alias, import, and metadata extensions to support traceable, soft\nalignment integration. It is demonstrated with a GPT-based LLM through an\nexample of a measurement system. Benefits and limitations are discussed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPT\u7684LLM\u8f85\u52a9\u65b9\u6cd5\uff0c\u7528\u4e8eSysML v2\u6a21\u578b\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u901a\u8fc7\u63d0\u793a\u9a71\u52a8\u7684\u65b9\u6cd5\u5b9e\u73b0\u53ef\u8ffd\u6eaf\u7684\u8f6f\u5bf9\u9f50\u96c6\u6210\u3002", "motivation": "\u89e3\u51b3\u8de8\u7ec4\u7ec7MBSE\u534f\u4f5c\u4e2d\u72ec\u7acb\u5f00\u53d1\u7684\u7cfb\u7edf\u6a21\u578b\u95f4\u8bed\u4e49\u5bf9\u9f50\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528SysML v2\u7684\u7ed3\u6784\u6a21\u5757\u5316\u548c\u5f62\u5f0f\u8bed\u4e49\uff0c\u7ed3\u5408LLM\u80fd\u529b\uff0c\u5f00\u53d1\u8fed\u4ee3\u5f0f\u5bf9\u9f50\u65b9\u6cd5\u548c\u4ea4\u4e92\u63d0\u793a\uff0c\u5305\u62ec\u6a21\u578b\u63d0\u53d6\u3001\u8bed\u4e49\u5339\u914d\u548c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u6d4b\u91cf\u7cfb\u7edf\u793a\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8ba8\u8bba\u4e86\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aSysML v2\u6a21\u578b\u7684\u8bed\u4e49\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2508.16522", "pdf": "https://arxiv.org/pdf/2508.16522", "abs": "https://arxiv.org/abs/2508.16522", "authors": ["Rohan Yadav", "Joseph Guman", "Sean Treichler", "Michael Garland", "Alex Aiken", "Fredrik Kjolstad", "Michael Bauer"], "title": "On the Duality of Task and Actor Programming Models", "categories": ["cs.PL", "cs.DC"], "comment": null, "summary": "Programming models for distributed and heterogeneous machines are rapidly\ngrowing in popularity to meet the demands of modern workloads. Task and actor\nmodels are common choices that offer different trade-offs between development\nproductivity and achieved performance. Task-based models offer better\nproductivity and composition of software, whereas actor-based models routinely\ndeliver better peak performance due to lower overheads. While task-based and\nactor-based models appear to be different superficially, we demonstrate these\nprogramming models are duals of each other. Importantly, we show that this\nduality extends beyond functionality to performance, and elucidate techniques\nthat let task-based systems deliver performance competitive with actor-based\nsystems without compromising productivity. We apply these techniques to both\nRealm, an explicitly parallel task-based runtime, as well as Legion, an\nimplicitly parallel task-based runtime. We show these techniques reduce Realm's\noverheads by between 1.7-5.3x, coming within a factor of two of the overheads\nimposed by heavily optimized actor-based systems like Charm++ and MPI. We\nfurther show that our techniques enable between 1.3-5.0x improved strong\nscaling of unmodified Legion applications.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4efb\u52a1\u6a21\u578b\u548c\u884c\u52a8\u8005\u6a21\u578b\u7684\u5bf9\u5076\u6027\uff0c\u5e76\u63d0\u51fa\u6280\u672f\u4f7f\u4efb\u52a1\u6a21\u578b\u5728\u4e0d\u727a\u7272\u751f\u4ea7\u529b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u884c\u52a8\u8005\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5206\u5e03\u5f0f\u548c\u5f02\u6784\u673a\u5668\u4e0a\u7684\u7f16\u7a0b\u6a21\u578b\u9700\u6c42\u589e\u957f\uff0c\u4efb\u52a1\u6a21\u578b\u548c\u884c\u52a8\u8005\u6a21\u578b\u5404\u6709\u4f18\u52a3\uff0c\u4f46\u4e24\u8005\u5b9e\u9645\u4e0a\u662f\u5bf9\u5076\u7684\u3002", "method": "\u5c55\u793a\u4e86\u4efb\u52a1\u6a21\u578b\u4e0e\u884c\u52a8\u8005\u6a21\u578b\u7684\u5bf9\u5076\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u51cf\u5c11\u4efb\u52a1\u6a21\u578b\u5f00\u9500\u7684\u6280\u672f\uff0c\u5e94\u7528\u4e8eRealm\u548cLegion\u8fd0\u884c\u65f6\u3002", "result": "\u6280\u672f\u5728Realm\u4e2d\u964d\u4f4e1.7-5.3\u500d\u5f00\u9500\uff0c\u63a5\u8fd1Charm++\u548cMPI\u7684\u6027\u80fd\uff1bLegion\u5e94\u7528\u5f3a\u6269\u5c55\u6027\u63d0\u53471.3-5.0\u500d\u3002", "conclusion": "\u4efb\u52a1\u6a21\u578b\u53ef\u901a\u8fc7\u4f18\u5316\u63a5\u8fd1\u884c\u52a8\u8005\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5f00\u53d1\u6548\u7387\u3002"}}
{"id": "2508.16345", "pdf": "https://arxiv.org/pdf/2508.16345", "abs": "https://arxiv.org/abs/2508.16345", "authors": ["Asger Horn Brorholt", "Andreas Holck H\u00f8eg-Petersen", "Peter Gj\u00f8l Jensen", "Kim Guldstrand Larsen", "Marius Miku\u010dionis", "Christian Schilling", "Andrzej W\u0105sowski"], "title": "Uppaal Coshy: Automatic Synthesis of Compact Shields for Hybrid Systems", "categories": ["cs.LO", "cs.AI", "cs.LG"], "comment": "12 pages and 6 figures. Additional abstract of 4 pages and 4 figures.\n  Extended version with supplementary material for an article to appear in the\n  2025 International Conference on Reachability Problems (RP)", "summary": "We present Uppaal Coshy, a tool for automatic synthesis of a safety strategy\n-- or shield -- for Markov decision processes over continuous state spaces and\ncomplex hybrid dynamics. The general methodology is to partition the state\nspace and then solve a two-player safety game, which entails a number of\nalgorithmically hard problems such as reachability for hybrid systems. The\ngeneral philosophy of Uppaal Coshy is to approximate hard-to-obtain solutions\nusing simulations. Our implementation is fully automatic and supports the\nexpressive formalism of Uppaal models, which encompass stochastic hybrid\nautomata. The precision of our partition-based approach benefits from using\nfiner grids, which however are not efficient to store. We include an algorithm\ncalled Caap to efficiently compute a compact representation of a shield in the\nform of a decision tree, which yields significant reductions.", "AI": {"tldr": "Uppaal Coshy\u662f\u4e00\u4e2a\u81ea\u52a8\u5408\u6210\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5b89\u5168\u7b56\u7565\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u533a\u72b6\u6001\u7a7a\u95f4\u548c\u6a21\u62df\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u91c7\u7528Caap\u7b97\u6cd5\u9ad8\u6548\u5b58\u50a8\u3002", "motivation": "\u4e3a\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u548c\u590d\u6742\u6df7\u5408\u52a8\u529b\u5b66\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u81ea\u52a8\u5b89\u5168\u7b56\u7565\u5408\u6210\u5de5\u5177\u3002", "method": "\u5206\u533a\u72b6\u6001\u7a7a\u95f4\uff0c\u89e3\u51b3\u53cc\u73a9\u5bb6\u5b89\u5168\u6e38\u620f\uff0c\u91c7\u7528\u6a21\u62df\u8fd1\u4f3c\u89e3\uff0c\u5e76\u7528Caap\u7b97\u6cd5\u9ad8\u6548\u5b58\u50a8\u51b3\u7b56\u6811\u3002", "result": "\u5b9e\u73b0\u4e86\u5b8c\u5168\u81ea\u52a8\u5316\u7684Uppaal\u6a21\u578b\u652f\u6301\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5b58\u50a8\u9700\u6c42\u3002", "conclusion": "Uppaal Coshy\u901a\u8fc7\u5206\u533a\u548c\u9ad8\u6548\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u7cfb\u7edf\u5b89\u5168\u7b56\u7565\u5408\u6210\u7684\u96be\u9898\u3002"}}
{"id": "2508.16077", "pdf": "https://arxiv.org/pdf/2508.16077", "abs": "https://arxiv.org/abs/2508.16077", "authors": ["Ryogo Niwa", "Shigeo Yoshida", "Yuki Koyama", "Yoshitaka Ushiku"], "title": "Cooperative Design Optimization through Natural Language Interaction", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "25 pages, 20 figures, to appear in Proceedings of the 38th Annual ACM\n  Symposium on User Interface Software and Technology (UIST '25), September\n  28-October 1, 2025, Busan, Republic of Korea", "summary": "Designing successful interactions requires identifying optimal design\nparameters. To do so, designers often conduct iterative user testing and\nexploratory trial-and-error. This involves balancing multiple objectives in a\nhigh-dimensional space, making the process time-consuming and cognitively\ndemanding. System-led optimization methods, such as those based on Bayesian\noptimization, can determine for designers which parameters to test next.\nHowever, they offer limited opportunities for designers to intervene in the\noptimization process, negatively impacting the designer's experience. We\npropose a design optimization framework that enables natural language\ninteractions between designers and the optimization system, facilitating\ncooperative design optimization. This is achieved by integrating system-led\noptimization methods with Large Language Models (LLMs), allowing designers to\nintervene in the optimization process and better understand the system's\nreasoning. Experimental results show that our method provides higher user\nagency than a system-led method and shows promising optimization performance\ncompared to manual design. It also matches the performance of an existing\ncooperative method with lower cognitive load.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7cfb\u7edf\u4f18\u5316\u65b9\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bbe\u8ba1\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u63d0\u5347\u8bbe\u8ba1\u5e08\u7684\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684\u7cfb\u7edf\u4f18\u5316\u65b9\u6cd5\u9650\u5236\u4e86\u8bbe\u8ba1\u5e08\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u5e72\u9884\u80fd\u529b\uff0c\u5f71\u54cd\u4e86\u8bbe\u8ba1\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u8bbe\u8ba1\u5e08\u4e0e\u4f18\u5316\u7cfb\u7edf\u7684\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u7528\u6237\u63a7\u5236\u6743\uff0c\u4f18\u5316\u6027\u80fd\u4f18\u4e8e\u624b\u52a8\u8bbe\u8ba1\uff0c\u4e14\u8ba4\u77e5\u8d1f\u8377\u4f4e\u4e8e\u73b0\u6709\u534f\u4f5c\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u7cfb\u7edf\u4f18\u5316\u4e0e\u8bbe\u8ba1\u5e08\u5e72\u9884\u7684\u9700\u6c42\uff0c\u63d0\u5347\u4e86\u8bbe\u8ba1\u6548\u7387\u548c\u4f53\u9a8c\u3002"}}
{"id": "2508.16297", "pdf": "https://arxiv.org/pdf/2508.16297", "abs": "https://arxiv.org/abs/2508.16297", "authors": ["Mateusz Slysz", "Piotr Rydlichowski", "Krzysztof Kurowski", "Omar Bacarezza", "Esperanza Cuenca Gomez", "Zohim Chandani", "Bettina Heim", "Pradnya Khalate", "William R. Clements", "James Fletcher"], "title": "Hybrid Classical-Quantum Supercomputing: A demonstration of a multi-user, multi-QPU and multi-GPU environment", "categories": ["quant-ph", "cs.DC", "cs.ET"], "comment": null, "summary": "Achieving a practical quantum advantage for near-term applications is widely\nexpected to rely on hybrid classical-quantum algorithms. To deliver this\npractical advantage to users, high performance computing (HPC) centers need to\nprovide a suitable software and hardware stack that supports algorithms of this\ntype. In this paper, we describe the world's first implementation of a\nclassical-quantum environment in an HPC center that allows multiple users to\nexecute hybrid algorithms on multiple quantum processing units (QPUs) and GPUs.\nOur setup at the Poznan Supercomputing and Networking Center (PCSS) aligns with\ncurrent HPC norms: the computing hardware including QPUs is installed in an\nactive data center room with standard facilities; there are no special\nconsiderations for networking, power, and cooling; we use Slurm for workload\nmanagement as well as the NVIDIA CUDA-Q extension API for classical-quantum\ninteractions. We demonstrate applications of this environment for hybrid\nclassical-quantum machine learning and optimisation. The aim of this work is to\nprovide the community with an experimental example for further research and\ndevelopment on how quantum computing can practically enhance and extend HPC\ncapabilities.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e16\u754c\u4e0a\u9996\u4e2a\u5728HPC\u4e2d\u5fc3\u5b9e\u73b0\u7684\u591a\u7528\u6237\u6df7\u5408\u7ecf\u5178-\u91cf\u5b50\u8ba1\u7b97\u73af\u5883\uff0c\u7528\u4e8e\u652f\u6301\u6df7\u5408\u7b97\u6cd5\u5728\u591a\u4e2a\u91cf\u5b50\u5904\u7406\u5355\u5143\u548cGPU\u4e0a\u7684\u6267\u884c\u3002", "motivation": "\u4e3a\u4e86\u5c06\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u4f18\u52bf\u5e26\u7ed9\u7528\u6237\uff0c\u9700\u8981\u5728HPC\u4e2d\u5fc3\u63d0\u4f9b\u652f\u6301\u6df7\u5408\u7ecf\u5178-\u91cf\u5b50\u7b97\u6cd5\u7684\u8f6f\u786c\u4ef6\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u5728Poznan\u8d85\u7ea7\u8ba1\u7b97\u4e0e\u7f51\u7edc\u4e2d\u5fc3\uff08PCSS\uff09\u90e8\u7f72\u4e86\u7b26\u5408\u5f53\u524dHPC\u89c4\u8303\u7684\u8bbe\u5907\uff0c\u4f7f\u7528Slurm\u8fdb\u884c\u5de5\u4f5c\u8d1f\u8f7d\u7ba1\u7406\uff0c\u5e76\u7ed3\u5408NVIDIA CUDA-Q\u6269\u5c55API\u5b9e\u73b0\u7ecf\u5178-\u91cf\u5b50\u4ea4\u4e92\u3002", "result": "\u8be5\u7cfb\u7edf\u6210\u529f\u5e94\u7528\u4e8e\u6df7\u5408\u7ecf\u5178-\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u548c\u4f18\u5316\u4efb\u52a1\u3002", "conclusion": "\u672c\u6587\u4e3a\u91cf\u5b50\u8ba1\u7b97\u5982\u4f55\u5b9e\u9645\u589e\u5f3a\u548c\u6269\u5c55HPC\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u6027\u8303\u4f8b\uff0c\u63a8\u52a8\u793e\u533a\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u53d1\u5c55\u3002"}}
{"id": "2508.15838", "pdf": "https://arxiv.org/pdf/2508.15838", "abs": "https://arxiv.org/abs/2508.15838", "authors": ["Jiacheng Wang", "Jialing He", "Geng Sun", "Zehui Xiong", "Dusit Niyato", "Shiwen Mao", "Dong In Kim", "Tao Xiang"], "title": "Safeguarding ISAC Performance in Low-Altitude Wireless Networks Under Channel Access Attack", "categories": ["cs.NI", "cs.GT", "cs.SY", "eess.SY"], "comment": null, "summary": "The increasing saturation of terrestrial resources has driven the exploration\nof low-altitude applications such as air taxis. Low altitude wireless networks\n(LAWNs) serve as the foundation for these applications, and integrated sensing\nand communication (ISAC) constitutes one of the core technologies within LAWNs.\nHowever, the openness nature of low-altitude airspace makes LAWNs vulnerable to\nmalicious channel access attacks, which degrade the ISAC performance.\nTherefore, this paper develops a game-based framework to mitigate the influence\nof the attacks on LAWNs. Concretely, we first derive expressions of\ncommunication data's signal-to-interference-plus-noise ratio and the age of\ninformation of sensing data under attack conditions, which serve as quality of\nservice metrics. Then, we formulate the ISAC performance optimization problem\nas a Stackelberg game, where the attacker acts as the leader, and the\nlegitimate drone and the ground ISAC base station act as second and first\nfollowers, respectively. On this basis, we design a backward induction\nalgorithm that achieves the Stackelberg equilibrium while maximizing the\nutilities of all participants, thereby mitigating the attack-induced\ndegradation of ISAC performance in LAWNs. We further prove the existence and\nuniqueness of the equilibrium. Simulation results show that the proposed\nalgorithm outperforms existing baselines and a static Nash equilibrium\nbenchmark, ensuring that LAWNs can provide reliable service for low-altitude\napplications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u51cf\u8f7b\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u6076\u610f\u653b\u51fb\u5bf9\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u968f\u7740\u5730\u9762\u8d44\u6e90\u65e5\u76ca\u9971\u548c\uff0c\u4f4e\u7a7a\u5e94\u7528\uff08\u5982\u7a7a\u4e2d\u51fa\u79df\u8f66\uff09\u9700\u6c42\u589e\u957f\uff0c\u4f46\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u7684\u5f00\u653e\u6027\u4f7f\u5176\u6613\u53d7\u6076\u610f\u653b\u51fb\uff0c\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u9996\u5148\u63a8\u5bfc\u901a\u4fe1\u6570\u636e\u7684\u4fe1\u566a\u6bd4\u548c\u611f\u77e5\u6570\u636e\u7684\u4fe1\u606f\u5e74\u9f84\u4f5c\u4e3a\u670d\u52a1\u8d28\u91cf\u6307\u6807\uff0c\u7136\u540e\u5c06\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u4e3aStackelberg\u535a\u5f08\uff0c\u5e76\u8bbe\u8ba1\u9006\u5411\u5f52\u7eb3\u7b97\u6cd5\u5b9e\u73b0\u5747\u8861\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u8bc1\u660e\u5176\u80fd\u6709\u6548\u51cf\u8f7b\u653b\u51fb\u5bf9\u6027\u80fd\u7684\u9000\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u535a\u5f08\u6846\u67b6\u548c\u7b97\u6cd5\u80fd\u786e\u4fdd\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e3a\u4f4e\u7a7a\u5e94\u7528\u63d0\u4f9b\u53ef\u9760\u670d\u52a1\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5747\u8861\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\u3002"}}
{"id": "2508.16273", "pdf": "https://arxiv.org/pdf/2508.16273", "abs": "https://arxiv.org/abs/2508.16273", "authors": ["Maria Teresa Rossi", "Martina De Sanctis", "Ludovico Iovino", "Manuel Wimmer"], "title": "A Systematic Mapping Study on Smart Cities Modeling Approaches", "categories": ["cs.SE"], "comment": null, "summary": "The Smart City concept was introduced to define an idealized city\ncharacterized by automation and connection. It then evolved rapidly by\nincluding further aspects, such as economy, environment. Since then, many\npublications have explored various aspects of Smart Cities across different\napplication domains and research communities, acknowledging the\ninterdisciplinary nature of this subject. In particular, our interest focuses\non how smart cities are designed and modeled, as a whole or as regards with\ntheir subsystems, when dealing with the accomplishment of the research goals in\nthis complex and heterogeneous domain. To this aim, we performed a systematic\nmapping study on smart cities modeling approaches identifying the relevant\ncontributions (i) to get an overview of existing research approaches, (ii) to\nidentify whether there are any publication trends, and (iii) to identify\npossible future research directions. We followed the guidelines for conducting\nsystematic mapping studies by Petersen et al. to analyze smart cities modeling\npublications. Our analysis revealed the following main findings: (i) smart\ngovernance is the most investigated and modeled smart city dimension; (ii) the\nmost used modeling approaches are business, architectural, and ontological\nmodeling approaches, spanning multiple application fields; (iii) the great\nmajority of existing technologies for modeling smart cities are not yet proven\nin operational environments; (iv) diverse research communities publish their\nresults in a multitude of different venues which further motivates the\npresented literature study. Researchers can use our results for better\nunderstanding the state-of-the-art in modeling smart cities, and as a\nfoundation for further analysis of specific approaches about smart cities\nmodeling. Lastly, we also discuss the impact of our analysis for the\nModel-Driven Engineering community.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u5206\u6790\u4e86\u667a\u6167\u57ce\u5e02\u5efa\u6a21\u65b9\u6cd5\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u7814\u7a76\u8d8b\u52bf\u3001\u5e38\u7528\u5efa\u6a21\u65b9\u5f0f\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4e86\u89e3\u667a\u6167\u57ce\u5e02\u8bbe\u8ba1\u4e0e\u5efa\u6a21\u7684\u73b0\u72b6\uff0c\u8bc6\u522b\u7814\u7a76\u8d8b\u52bf\u53ca\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u8de8\u5b66\u79d1\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u91c7\u7528Petersen\u7b49\u4eba\u7684\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u6307\u5357\uff0c\u5206\u6790\u667a\u6167\u57ce\u5e02\u7684\u5efa\u6a21\u76f8\u5173\u6587\u732e\u3002", "result": "\u53d1\u73b0\u667a\u80fd\u6cbb\u7406\u662f\u6700\u53d7\u5173\u6ce8\u7684\u7ef4\u5ea6\uff0c\u5e38\u7528\u5efa\u6a21\u65b9\u6cd5\u5305\u62ec\u4e1a\u52a1\u3001\u67b6\u6784\u548c\u672c\u4f53\u5efa\u6a21\uff0c\u4f46\u591a\u6570\u6280\u672f\u5c1a\u672a\u5728\u64cd\u4f5c\u73af\u5883\u4e2d\u9a8c\u8bc1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3\u667a\u6167\u57ce\u5e02\u5efa\u6a21\u7684\u73b0\u72b6\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u793e\u533a\u5177\u6709\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2508.16517", "pdf": "https://arxiv.org/pdf/2508.16517", "abs": "https://arxiv.org/abs/2508.16517", "authors": ["Bingkun Yao", "Ning Wang", "Xiangfeng Liu", "Yuxin Du", "Yuchen Hu", "Hong Gao", "Zhe Jiang", "Nan Guan"], "title": "ARSP: Automated Repair of Verilog Designs via Semantic Partitioning", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Debugging functional Verilog bugs consumes a significant portion of front-end\ndesign time. While Large Language Models (LLMs) have demonstrated great\npotential in mitigating this effort, existing LLM-based automated debugging\nmethods underperform on industrial-scale modules. A major reason for this is\nbug signal dilution in long contexts, where a few bug-relevant tokens are\noverwhelmed by hundreds of unrelated lines, diffusing the model's attention. To\naddress this issue, we introduce ARSP, a two-stage system that mitigates\ndilution via semantics-guided fragmentation. A Partition LLM splits a module\ninto semantically tight fragments; a Repair LLM patches each fragment; edits\nare merged without altering unrelated logic. A synthetic data framework\ngenerates fragment-level training pairs spanning bug types, design styles, and\nscales to supervise both models. Experiments show that ARSP achieves 77.92%\npass@1 and 83.88% pass@5, outperforming mainstream commercial LLMs including\nClaude-3.7 and SOTA automated Verilog debugging tools Strider and MEIC. Also,\nsemantic partitioning improves pass@1 by 11.6% and pass@5 by 10.2% over\nwhole-module debugging, validating the effectiveness of fragment-level scope\nreduction in LLM-based Verilog debugging.", "AI": {"tldr": "ARSP\u662f\u4e00\u79cd\u89e3\u51b3Verilog\u8c03\u8bd5\u4e2d\u4fe1\u53f7\u7a00\u91ca\u95ee\u9898\u7684\u4e24\u9636\u6bb5\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u548c\u4fee\u590dLLM\u5b9e\u73b0\u9ad8\u6548\u8c03\u8bd5\u3002", "motivation": "\u7531\u4e8e\u4f20\u7edfLLM\u5728\u8c03\u8bd5\u5927\u89c4\u6a21Verilog\u6a21\u5757\u65f6\u56e0\u4fe1\u53f7\u7a00\u91ca\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u6539\u8fdb\u8c03\u8bd5\u65b9\u6cd5\u3002", "method": "ARSP\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u5c06\u6a21\u5757\u5206\u6210\u7d27\u5bc6\u7684\u7247\u6bb5\uff0c\u518d\u7531\u4fee\u590dLLM\u4fee\u8865\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u6846\u67b6\u8bad\u7ec3\u4e24\u6a21\u578b\u3002", "result": "ARSP\u5728pass@1\u548cpass@5\u4e0a\u5206\u522b\u8fbe\u523077.92%\u548c83.88%\uff0c\u4f18\u4e8e\u4e3b\u6d41\u5546\u4e1aLLM\u548c\u73b0\u6709\u5de5\u5177\u3002", "conclusion": "\u8bed\u4e49\u5206\u5272\u663e\u8457\u63d0\u5347\u4e86LLM\u5728Verilog\u8c03\u8bd5\u4e2d\u7684\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u7247\u6bb5\u7ea7\u8303\u56f4\u7f29\u51cf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.16014", "pdf": "https://arxiv.org/pdf/2508.16014", "abs": "https://arxiv.org/abs/2508.16014", "authors": ["Anupam Das", "Avgerinos Delkos"], "title": "Prover-Adversary games for systems over (non-deterministic) branching programs", "categories": ["cs.CC", "cs.LO", "math.LO"], "comment": "34 pages, 8 figures", "summary": "We introduce Pudlak-Buss style Prover-Adversary games to characterise proof\nsystems reasoning over deterministic branching programs (BPs) and\nnon-deterministic branching programs (NBPs). Our starting points are the proof\nsystems eLDT and eLNDT, for BPs and NBPs respectively, previously introduced by\nBuss, Das and Knop. We prove polynomial equivalences between these proof\nsystems and the corresponding games we introduce. This crucially requires\naccess to a form of negation of branching programs which, for NBPs, requires us\nto formalise a non-uniform version of the Immerman-Szelepcsenyi theorem that\ncoNL = NL. Thanks to the techniques developed, we further obtain a proof\ncomplexity theoretic version of Immerman-Szelepcsenyi, showing that eLNDT is\npolynomially equivalent to systems over boundedly alternating branching\nprograms.", "AI": {"tldr": "\u901a\u8fc7Pudlak-Buss\u98ce\u683c\u7684\u8bc1\u660e\u8005-\u5bf9\u624b\u6e38\u620f\uff0c\u7814\u7a76\u4e86\u786e\u5b9a\u6027\uff08BPs\uff09\u548c\u975e\u786e\u5b9a\u6027\uff08NBPs\uff09\u5206\u652f\u7a0b\u5e8f\u7684\u8bc1\u660e\u7cfb\u7edf\uff0c\u5e76\u8bc1\u660e\u4e86\u4e0eeLDT\u548ceLNDT\u7cfb\u7edf\u7684\u591a\u9879\u5f0f\u7b49\u4ef7\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6e38\u620f\u7406\u8bba\u65b9\u6cd5\uff0c\u6df1\u5165\u7406\u89e3\u786e\u5b9a\u6027\u53ca\u975e\u786e\u5b9a\u6027\u5206\u652f\u7a0b\u5e8f\u7684\u8bc1\u660e\u7cfb\u7edf\u53ca\u5176\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86Pudlak-Buss\u98ce\u683c\u7684\u8bc1\u660e\u8005-\u5bf9\u624b\u6e38\u620f\uff0c\u5e76\u4e0eBuss\u7b49\u4eba\u63d0\u51fa\u7684eLDT\u548ceLNDT\u7cfb\u7edf\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u7c7b\u6e38\u620f\u4e0eeLDT\u3001eLNDT\u7cfb\u7edf\u95f4\u7684\u591a\u9879\u5f0f\u7b49\u4ef7\u6027\uff0c\u5e76\u6269\u5c55\u4e86Immerman-Szelepcsenyi\u5b9a\u7406\u7684\u975e\u5747\u5300\u7248\u672c\u3002", "conclusion": "\u901a\u8fc7\u6280\u672f\u53d1\u5c55\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86eLNDT\u4e0e\u6709\u9650\u4ea4\u66ff\u5206\u652f\u7a0b\u5e8f\u7cfb\u7edf\u7684\u591a\u9879\u5f0f\u7b49\u4ef7\u6027\u3002"}}
{"id": "2508.16480", "pdf": "https://arxiv.org/pdf/2508.16480", "abs": "https://arxiv.org/abs/2508.16480", "authors": ["Linda Hirsch", "James Fey", "Katherine Isbister"], "title": "Designing Doable and Locally-adapted Action Cards for an Interactive Tabletop Game To Support Bottom-Up Flood Resilience", "categories": ["cs.HC"], "comment": null, "summary": "Serious games can support communities in becoming more flood resilient.\nHowever, the process of identifying and integrating locally relevant and doable\nactions into gameplay is complex and underresearched. We approached the\nchallenge by collaborating with a community-led education center and applying\nan iterative and participatory design process of identifying and defining\nactions that may increase local applicability and relevance. The process\ncomprised a field observation, two expert focus groups (n=4), and an online\nsurvey (n=13). Our findings identified 27 actions related to increasing or\nmaintaining individuals' and communities' flood resilience, which we turned\ninto 20 playing cards. These action cards are a part of a larger interactive\ntabletop game, which we are currently developing. Our work discusses the\npotential of card games to educate non-experts to increase flood resilience,\nand contributes to our process of identifying local needs and conditions, and\nturning them into engaging game artifacts for bottom-up empowerment.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u901a\u8fc7\u5361\u7247\u6e38\u620f\u63d0\u5347\u793e\u533a\u7684\u6d2a\u707e\u97e7\u6027\uff0c\u91c7\u7528\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u6700\u7ec8\u5f00\u53d1\u4e86\u5305\u542b20\u5f20\u884c\u52a8\u5361\u7247\u7684\u684c\u6e38\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5982\u4f55\u901a\u8fc7\u6e38\u620f\u5316\u65b9\u6cd5\u5e2e\u52a9\u793e\u533a\u63d0\u5347\u6d2a\u707e\u97e7\u6027\uff0c\u5c24\u5176\u662f\u5728\u8bc6\u522b\u548c\u6574\u5408\u672c\u5730\u53ef\u884c\u884c\u52a8\u65b9\u9762\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e0e\u793e\u533a\u6559\u80b2\u4e2d\u5fc3\u5408\u4f5c\uff0c\u91c7\u7528\u8fed\u4ee3\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u6d41\u7a0b\uff08\u5b9e\u5730\u89c2\u5bdf\u3001\u4e13\u5bb6\u7126\u70b9\u5c0f\u7ec4\u548c\u5728\u7ebf\u8c03\u67e5\uff09\uff0c\u8bc6\u522b\u548c\u5b9a\u4e49\u884c\u52a8\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u51fa27\u9879\u4e0e\u6d2a\u707e\u97e7\u6027\u76f8\u5173\u7684\u884c\u52a8\uff0c\u5e76\u8f6c\u5316\u4e3a20\u5f20\u6e38\u620f\u5361\u7247\uff0c\u76ee\u524d\u6b63\u5728\u5f00\u53d1\u4e00\u6b3e\u4e92\u52a8\u684c\u6e38\u3002", "conclusion": "\u7ed3\u8bba\u662f\u5361\u7247\u6e38\u620f\u80fd\u6709\u6548\u6559\u80b2\u975e\u4e13\u5bb6\u63d0\u5347\u6d2a\u707e\u97e7\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u4ece\u672c\u5730\u9700\u6c42\u5230\u6e38\u620f\u5316\u8d4b\u6743\u7684\u5b9e\u8df5\u8def\u5f84\u3002"}}
{"id": "2508.15843", "pdf": "https://arxiv.org/pdf/2508.15843", "abs": "https://arxiv.org/abs/2508.15843", "authors": ["Peihao Yan", "Huacheng Zeng", "Y. Thomas Hou"], "title": "xDiff: Online Diffusion Model for Collaborative Inter-Cell Interference Management in 5G O-RAN", "categories": ["cs.NI"], "comment": null, "summary": "Open Radio Access Network (O-RAN) is a key architectural paradigm for 5G and\nbeyond cellular networks, enabling the adoption of intelligent and efficient\nresource management solutions. Meanwhile, diffusion models have demonstrated\nremarkable capabilities in image and video generation, making them attractive\nfor network optimization tasks. In this paper, we propose xDiff, a\ndiffusion-based reinforcement learning(RL) framework for inter-cell\ninterference management (ICIM) in O-RAN. We first formulate ICIM as a resource\nallocation optimization problem aimed at maximizing a user-defined reward\nfunction and then develop an online learning solution by integrating a\ndiffusion model into an RL framework for near-real-time policy generation.\nParticularly, we introduce a novel metric, preference values, as the policy\nrepresentation to enable efficient policy-guided resource allocation within\nO-RAN distributed units (DUs). We implement xDiff on a 5G testbed consisting of\nthree cells and a set of smartphones in two small-cell scenarios. Experimental\nresults demonstrate that xDiff outperforms state-of-the-art ICIM approaches,\nhighlighting the potential of diffusion models for online optimization of\nO-RAN. Source code is available on GitHub [1].", "AI": {"tldr": "\u63d0\u51fa\u4e86xDiff\uff0c\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3O-RAN\u4e2d\u7684\u5c0f\u533a\u95f4\u5e72\u6270\u7ba1\u7406\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "O-RAN\u662f5G\u53ca\u672a\u6765\u7f51\u7edc\u7684\u5173\u952e\u67b6\u6784\uff0c\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u548c\u89c6\u9891\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u7f51\u7edc\u4f18\u5316\u4efb\u52a1\u3002", "method": "\u5c06ICIM\u95ee\u9898\u5efa\u6a21\u4e3a\u8d44\u6e90\u5206\u914d\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u7ed3\u5408\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u6307\u6807\u2018\u504f\u597d\u503c\u2019\u6307\u5bfc\u8d44\u6e90\u5206\u914d\u3002", "result": "\u57285G\u6d4b\u8bd5\u5e8a\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793axDiff\u4f18\u4e8e\u73b0\u6709ICIM\u65b9\u6cd5\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u5728O-RAN\u5728\u7ebf\u4f18\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0cxDiff\u4e3aICIM\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16307", "pdf": "https://arxiv.org/pdf/2508.16307", "abs": "https://arxiv.org/abs/2508.16307", "authors": ["Jinsheng Ba", "Yuancheng Jiang", "Manuel Rigger"], "title": "Metamorphic Coverage", "categories": ["cs.SE"], "comment": null, "summary": "Metamorphic testing is a widely used methodology that examines an expected\nrelation between pairs of executions to automatically find bugs, such as\ncorrectness bugs. We found that code coverage cannot accurately measure the\nextent to which code is validated and mutation testing is computationally\nexpensive for evaluating metamorphic testing methods. In this work, we propose\nMetamorphic Coverage (MC), a coverage metric that examines the distinct code\nexecuted by pairs of test inputs within metamorphic testing. Our intuition is\nthat, typically, a bug can be observed if the corresponding code is executed\nwhen executing either test input but not the other one, so covering more\ndifferential code covered by pairs of test inputs might be more likely to\nexpose bugs. While most metamorphic testing methods have been based on this\ngeneral intuition, our work defines and systematically evaluates MC on five\nwidely used metamorphic testing methods for testing database engines,\ncompilers, and constraint solvers. The code measured by MC overlaps with the\nbug-fix locations of 50 of 64 bugs found by metamorphic testing methods, and MC\nhas a stronger positive correlation with bug numbers than line coverage. MC is\n4x more sensitive than line coverage in distinguishing testing methods'\neffectiveness, and the average value of MC is 6x smaller than line coverage\nwhile still capturing the part of the program that is being tested. MC required\n359x less time than mutation testing. Based on a case study for an automated\ndatabase system testing approach, we demonstrate that when used for feedback\nguidance, MC significantly outperforms code coverage, by finding 41\\% more\nbugs. Consequently, this work might have broad applications for assessing\nmetamorphic testing methods and improving test-case generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u540d\u4e3a\u2018Metamorphic Coverage\u2019\uff08MC\uff09\u7684\u65b0\u8986\u76d6\u7387\u5ea6\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u53d8\u5f62\u6d4b\u8bd5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u6bd4\u4f20\u7edf\u884c\u8986\u76d6\u7387\u548c\u53d8\u5f02\u6d4b\u8bd5\u66f4\u9ad8\u6548\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u8986\u76d6\u7387\u548c\u53d8\u5f02\u6d4b\u8bd5\u5728\u8bc4\u4f30\u53d8\u5f62\u6d4b\u8bd5\u65b9\u6cd5\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u524d\u8005\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u4ee3\u7801\u9a8c\u8bc1\u7a0b\u5ea6\uff0c\u540e\u8005\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faMC\u6307\u6807\uff0c\u901a\u8fc7\u5206\u6790\u53d8\u5f62\u6d4b\u8bd5\u4e2d\u6d4b\u8bd5\u8f93\u5165\u5bf9\u6267\u884c\u7684\u5dee\u5f02\u4ee3\u7801\u6765\u8bc4\u4f30\u6d4b\u8bd5\u6548\u679c\u3002", "result": "MC\u4e0e64\u4e2a\u53d1\u73b0\u7684\u9519\u8bef\u4e2d\u768450\u4e2a\u4fee\u590d\u4f4d\u7f6e\u91cd\u53e0\uff0c\u4e14\u6bd4\u884c\u8986\u76d6\u7387\u66f4\u80fd\u533a\u5206\u6d4b\u8bd5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8ba1\u7b97\u65f6\u95f4\u6bd4\u53d8\u5f02\u6d4b\u8bd5\u5c11359\u500d\u3002", "conclusion": "MC\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u53d8\u5f62\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7684\u6548\u679c\u3002"}}
{"id": "2508.16488", "pdf": "https://arxiv.org/pdf/2508.16488", "abs": "https://arxiv.org/abs/2508.16488", "authors": ["Kayenat Fatmi", "Mohammad Abbas"], "title": "SafeSpace: An Integrated Web Application for Digital Safety and Emotional Well-being", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "5 pages, 2 figures, 1 table. Preprint submitted to arXiv", "summary": "In the digital era, individuals are increasingly exposed to online harms such\nas toxicity, manipulation, and grooming, which often pose emotional and safety\nrisks. Existing systems for detecting abusive content or issuing safety alerts\noperate in isolation and rarely combine digital safety with emotional\nwell-being. In this paper, we present SafeSpace, a unified web application that\nintegrates three modules: (1) toxicity detection in chats and screenshots using\nNLP models and Google's Perspective API, (2) a configurable safety ping system\nthat issues emergency alerts with the user's live location (longitude and\nlatitude) via SMTP-based emails when check-ins are missed or SOS alerts are\nmanually triggered, and (3) a reflective questionnaire that evaluates\nrelationship health and emotional resilience. The system employs Firebase for\nalert management and a modular architecture designed for usability, privacy,\nand scalability. The experimental evaluation shows 93% precision in toxicity\ndetection, 100% reliability in safety alerts under emulator tests, and 92%\nalignment between automated and manual questionnaire scoring. SafeSpace,\nimplemented as a web application, demonstrates the feasibility of integrating\ndetection, protection, and reflection within a single platform, with future\ndeployment envisioned as a mobile application for broader accessibility.", "AI": {"tldr": "SafeSpace \u662f\u4e00\u4e2a\u96c6\u6210\u6bd2\u6027\u68c0\u6d4b\u3001\u5b89\u5168\u8b66\u62a5\u548c\u60c5\u611f\u8bc4\u4f30\u7684\u7edf\u4e00\u7f51\u7edc\u5e94\u7528\uff0c\u65e8\u5728\u63d0\u5347\u6570\u5b57\u5b89\u5168\u548c\u60c5\u611f\u5065\u5eb7\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u65f6\u4ee3\u4e2d\uff0c\u4eba\u4eec\u5728\u7ebf\u4e0a\u9762\u4e34\u6bd2\u6027\u5185\u5bb9\u3001\u64cd\u7eb5\u548c\u9a9a\u6270\u7b49\u98ce\u9669\uff0c\u73b0\u6709\u7cfb\u7edf\u672a\u80fd\u5c06\u6570\u5b57\u5b89\u5168\u4e0e\u60c5\u611f\u5065\u5eb7\u7ed3\u5408\u3002", "method": "SafeSpace \u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u57fa\u4e8e NLP \u548c Google Perspective API \u7684\u6bd2\u6027\u68c0\u6d4b\uff0c\u53ef\u914d\u7f6e\u7684\u5b89\u5168\u8b66\u62a5\u7cfb\u7edf\uff08\u542b\u5b9e\u65f6\u4f4d\u7f6e\uff09\uff0c\u4ee5\u53ca\u5173\u7cfb\u5065\u5eb7\u548c\u60c5\u611f\u97e7\u6027\u7684\u81ea\u8bc4\u95ee\u5377\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6bd2\u6027\u68c0\u6d4b\u51c6\u786e\u7387 93%\uff0c\u5b89\u5168\u8b66\u62a5\u53ef\u9760\u6027 100%\uff08\u6a21\u62df\u6d4b\u8bd5\uff09\uff0c\u95ee\u5377\u81ea\u52a8\u4e0e\u624b\u52a8\u8bc4\u5206\u4e00\u81f4\u7387\u8fbe 92%\u3002", "conclusion": "SafeSpace \u8bc1\u660e\u4e86\u96c6\u6210\u68c0\u6d4b\u3001\u4fdd\u62a4\u548c\u53cd\u601d\u7684\u53ef\u884c\u6027\uff0c\u672a\u6765\u5c06\u6269\u5c55\u4e3a\u79fb\u52a8\u5e94\u7528\u4ee5\u63d0\u5347\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2508.16035", "pdf": "https://arxiv.org/pdf/2508.16035", "abs": "https://arxiv.org/abs/2508.16035", "authors": ["Poorvi Joshi", "Mohan Gurusamy"], "title": "Time Series Based Network Intrusion Detection using MTF-Aided Transformer", "categories": ["cs.NI", "cs.AI"], "comment": "7 pages, 3 figures. Accepted and presented at The Fifth Intelligent\n  Cybersecurity Conference (ICSC 2025), nominated for Best Paper Award", "summary": "This paper introduces a novel approach to time series classification using a\nMarkov Transition Field (MTF)-aided Transformer model, specifically designed\nfor Software-Defined Networks (SDNs). The proposed model integrates the\ntemporal dependency modeling strengths of MTFs with the sophisticated pattern\nrecognition capabilities of Transformer architectures. We evaluate the model's\nperformance using the InSDN dataset, demonstrating that our model outperforms\nbaseline classification models, particularly in data-constrained environments\ncommonly encountered in SDN applications. We also highlight the relationship\nbetween the MTF and Transformer components, which leads to better performance,\neven with limited data. Furthermore, our approach achieves competitive training\nand inference times, making it an efficient solution for real-world SDN\napplications. These findings establish the potential of MTF-aided Transformers\nto address the challenges of time series classification in SDNs, offering a\npromising path for reliable and scalable analysis in scenarios with sparse\ndata.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u8f6c\u79fb\u573a(MTF)\u548cTransformer\u7684\u65b0\u578b\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\uff0c\u7528\u4e8e\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc(SDN)\uff0c\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3SDN\u4e2d\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u95ee\u9898\uff0c\u7279\u522b\u662f\u6570\u636e\u7a00\u758f\u73af\u5883\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408MTF\u7684\u65f6\u95f4\u4f9d\u8d56\u5efa\u6a21\u80fd\u529b\u548cTransformer\u7684\u6a21\u5f0f\u8bc6\u522b\u80fd\u529b\uff0c\u63d0\u51faMTF-aided Transformer\u6a21\u578b\u3002", "result": "\u5728InSDN\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u9ad8\u3002", "conclusion": "MTF-aided Transformer\u4e3aSDN\u4e2d\u6570\u636e\u7a00\u7f3a\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16318", "pdf": "https://arxiv.org/pdf/2508.16318", "abs": "https://arxiv.org/abs/2508.16318", "authors": ["Juan C. Alonso", "Alberto Martin-Lopez", "Sergio Segura", "Gabriele Bavota", "Antonio Ruiz-Cort\u00e9s"], "title": "SATORI: Static Test Oracle Generation for REST APIs", "categories": ["cs.SE"], "comment": "Accepted for publication at 40th IEEE/ACM International Conference on\n  Automated Software Engineering, ASE 2025", "summary": "REST API test case generation tools are evolving rapidly, with growing\ncapabilities for the automated generation of complex tests. However, despite\ntheir strengths in test data generation, these tools are constrained by the\ntypes of test oracles they support, often limited to crashes, regressions, and\nnoncompliance with API specifications or design standards. This paper\nintroduces SATORI (Static API Test ORacle Inference), a black-box approach for\ngenerating test oracles for REST APIs by analyzing their OpenAPI Specification.\nSATORI uses large language models to infer the expected behavior of an API by\nanalyzing the properties of the response fields of its operations, such as\ntheir name and descriptions. To foster its adoption, we extended the\nPostmanAssertify tool to automatically convert the test oracles reported by\nSATORI into executable assertions. Evaluation results on 17 operations from 12\nindustrial APIs show that SATORI can automatically generate up to hundreds of\nvalid test oracles per operation. SATORI achieved an F1-score of 74.3%,\noutperforming the state-of-the-art dynamic approach AGORA+ (69.3%)-which\nrequires executing the API-when generating comparable oracle types. Moreover,\nour findings show that static and dynamic oracle inference methods are\ncomplementary: together, SATORI and AGORA+ found 90% of the oracles in our\nannotated ground-truth dataset. Notably, SATORI uncovered 18 bugs in popular\nAPIs (Amadeus Hotel, Deutschebahn, FDIC, GitLab, Marvel, OMDb and Vimeo)\nleading to documentation updates by the API maintainers.", "AI": {"tldr": "SATORI\u662f\u4e00\u79cd\u57fa\u4e8e\u9759\u6001\u5206\u6790\u7684REST API\u6d4b\u8bd5\u9884\u8a00\u751f\u6210\u5de5\u5177\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790OpenAPI\u89c4\u8303\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u9884\u8a00\u751f\u6210\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709REST API\u6d4b\u8bd5\u5de5\u5177\u5728\u9884\u8a00\u751f\u6210\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u901a\u5e38\u4ec5\u652f\u6301\u6709\u9650\u7684\u9884\u8a00\u7c7b\u578b\uff08\u5982\u5d29\u6e83\u3001\u56de\u5f52\u548c\u89c4\u8303\u5408\u89c4\u6027\uff09\u3002", "method": "SATORI\u901a\u8fc7\u5206\u6790OpenAPI\u89c4\u8303\u4e2d\u7684\u54cd\u5e94\u5b57\u6bb5\u5c5e\u6027\uff08\u5982\u540d\u79f0\u548c\u63cf\u8ff0\uff09\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u65adAPI\u7684\u9884\u671f\u884c\u4e3a\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u65ad\u8a00\u3002", "result": "\u572817\u4e2a\u5de5\u4e1aAPI\u64cd\u4f5c\u4e0a\uff0cSATORI\u80fd\u751f\u6210\u6570\u767e\u4e2a\u6709\u6548\u9884\u8a00\uff0cF1\u5206\u6570\u8fbe74.3%\uff0c\u4f18\u4e8e\u52a8\u6001\u65b9\u6cd5AGORA+\uff0869.3%\uff09\uff0c\u4e24\u8005\u7ed3\u5408\u53ef\u8986\u76d690%\u7684\u9884\u8a00\u3002", "conclusion": "SATORI\u586b\u8865\u4e86\u9759\u6001\u9884\u8a00\u751f\u6210\u7684\u7a7a\u767d\uff0c\u5e76\u4e0e\u52a8\u6001\u65b9\u6cd5\u4e92\u8865\uff0c\u6210\u529f\u53d1\u73b0\u591a\u4e2a\u6d41\u884cAPI\u7684\u6587\u6863\u7f3a\u9677\u3002"}}
{"id": "2508.13284", "pdf": "https://arxiv.org/pdf/2508.13284", "abs": "https://arxiv.org/abs/2508.13284", "authors": ["Nobuyuki Oishi", "Philip Birch", "Daniel Roggen", "Paula Lago"], "title": "Physically Plausible Data Augmentations for Wearable IMU-based Human Activity Recognition Using Physics Simulation", "categories": ["cs.LG", "cs.HC"], "comment": "12 pages, 4 figures", "summary": "The scarcity of high-quality labeled data in sensor-based Human Activity\nRecognition (HAR) hinders model performance and limits generalization across\nreal-world scenarios. Data augmentation is a key strategy to mitigate this\nissue by enhancing the diversity of training datasets. Signal\nTransformation-based Data Augmentation (STDA) techniques have been widely used\nin HAR. However, these methods are often physically implausible, potentially\nresulting in augmented data that fails to preserve the original meaning of the\nactivity labels. In this study, we introduce and systematically characterize\nPhysically Plausible Data Augmentation (PPDA) enabled by physics simulation.\nPPDA leverages human body movement data from motion capture or video-based pose\nestimation and incorporates various realistic variabilities through physics\nsimulation, including modifying body movements, sensor placements, and\nhardware-related effects. We compare the performance of PPDAs with traditional\nSTDAs on three public datasets of daily activities and fitness workouts. First,\nwe evaluate each augmentation method individually, directly comparing PPDAs to\ntheir STDA counterparts. Next, we assess how combining multiple PPDAs can\nreduce the need for initial data collection by varying the number of subjects\nused for training. Experiments show consistent benefits of PPDAs, improving\nmacro F1 scores by an average of 3.7 pp (up to 13 pp) and achieving competitive\nperformance with up to 60% fewer training subjects than STDAs. As the first\nsystematic study of PPDA in sensor-based HAR, these results highlight the\nadvantages of pursuing physical plausibility in data augmentation and the\npotential of physics simulation for generating synthetic Inertial Measurement\nUnit data for training deep learning HAR models. This cost-effective and\nscalable approach therefore helps address the annotation scarcity challenge in\nHAR.", "AI": {"tldr": "\u9488\u5bf9\u4f20\u611f\u5668\u57fa\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u4e2d\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u7269\u7406\u5408\u7406\u6027\u6570\u636e\u589e\u5f3a\uff08PPDA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7269\u7406\u6a21\u62df\u751f\u6210\u591a\u6837\u5316\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u5bf9\u521d\u59cb\u6570\u636e\u6536\u96c6\u7684\u9700\u6c42\u3002", "motivation": "\u4f20\u611f\u5668\u57fa\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u56e0\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u800c\u53d7\u9650\uff0c\u4f20\u7edf\u4fe1\u53f7\u53d8\u6362\u6570\u636e\u589e\u5f3a\uff08STDA\uff09\u65b9\u6cd5\u5b58\u5728\u7269\u7406\u4e0d\u5408\u7406\u6027\uff0c\u53ef\u80fd\u7834\u574f\u6d3b\u52a8\u6807\u7b7e\u7684\u539f\u610f\u3002", "method": "\u63d0\u51faPPDA\u65b9\u6cd5\uff0c\u5229\u7528\u7269\u7406\u6a21\u62df\u6574\u5408\u4eba\u4f53\u8fd0\u52a8\u6570\u636e\u548c\u591a\u79cd\u5b9e\u9645\u53d8\u5f02\u6027\uff08\u5982\u8eab\u4f53\u52a8\u4f5c\u3001\u4f20\u611f\u5668\u4f4d\u7f6e\u548c\u786c\u4ef6\u6548\u5e94\uff09\uff0c\u5e76\u4e0e\u4f20\u7edfSTDA\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPPDA\u5e73\u5747\u63d0\u5347\u5b8fF1\u5206\u65703.7 pp\uff08\u6700\u9ad813 pp\uff09\uff0c\u4e14\u4f7f\u752860%\u66f4\u5c11\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u8fbe\u5230\u4e0eSTDA\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "PPDA\u901a\u8fc7\u7269\u7406\u5408\u7406\u6027\u663e\u8457\u63d0\u5347\u6570\u636e\u589e\u5f3a\u6548\u679c\uff0c\u4e3aHAR\u4e2d\u7684\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16074", "pdf": "https://arxiv.org/pdf/2508.16074", "abs": "https://arxiv.org/abs/2508.16074", "authors": ["Zhiyuan He", "Aashish Gottipati", "Lili Qiu", "Yuqing Yang", "Francis Y. Yan"], "title": "Congestion Control System Optimization with Large Language Models", "categories": ["cs.NI"], "comment": null, "summary": "Congestion control is a fundamental component of Internet infrastructure, and\nresearchers have dedicated considerable effort to developing improved\ncongestion control algorithms. However, despite extensive study, existing\nalgorithms continue to exhibit suboptimal performance across diverse network\nenvironments. In this paper, we introduce a novel approach that automatically\noptimizes congestion control algorithms using large language models (LLMs). Our\nframework consists of a structured algorithm generation process, an\nemulation-based evaluation pipeline covering a broad range of network\nconditions, and a statistically guided method to substantially reduce\nevaluation time. Empirical results from four distinct LLMs validate the\neffectiveness of our approach. We successfully identify algorithms that achieve\nup to 27% performance improvements over the original BBR algorithm in a\nproduction QUIC implementation. Our work demonstrates the potential of LLMs to\naccelerate the design of high-performance network algorithms and paves the way\nfor broader applications in networking systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u4f18\u5316\u62e5\u585e\u63a7\u5236\u7b97\u6cd5\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u62e5\u585e\u63a7\u5236\u7b97\u6cd5\u5728\u4e0d\u540c\u7f51\u7edc\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u666e\u9002\u6027\u4f18\u5316\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u7b97\u6cd5\u751f\u6210\u3001\u5e7f\u6cdb\u7684\u7f51\u7edc\u6761\u4ef6\u4eff\u771f\u8bc4\u4f30\u53ca\u7edf\u8ba1\u6307\u5bfc\u65b9\u6cd5\uff0c\u51cf\u5c11\u8bc4\u4f30\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u65b0\u7b97\u6cd5\u5728QUIC\u5b9e\u73b0\u4e2d\u6bd4\u539fBBR\u7b97\u6cd5\u6027\u80fd\u63d0\u534727%\u3002", "conclusion": "LLMs\u5728\u7f51\u7edc\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u52a0\u901f\u9ad8\u6027\u80fd\u7f51\u7edc\u7cfb\u7edf\u7684\u5f00\u53d1\u3002"}}
{"id": "2508.16341", "pdf": "https://arxiv.org/pdf/2508.16341", "abs": "https://arxiv.org/abs/2508.16341", "authors": ["Sebastian Copei", "Oliver Hohlfeld", "Jens Kosiol"], "title": "The (C)omprehensive (A)rchitecture (P)attern (I)ntegration method: Navigating the sea of technology", "categories": ["cs.SE"], "comment": null, "summary": "The technological landscape changes daily, making it nearly impossible for a\nsingle person to be aware of all trends or available tools that may or may not\nbe suitable for their software project. This makes tool selection and\narchitectural design decisions a complex problem, especially for large-scale\nsoftware systems. To tackle this issue, we introduce CAPI, the Comprehensive\nArchitecture Pattern Integration method that uses a diagnostic decision tree to\nsuggest architectural patterns depending on user needs. By suggesting patterns\ninstead of tools, the overall complexity for further decisions is lower as\nthere are fewer architectural patterns than tools due to the abstract nature of\npatterns. Moreover, since tools implement patterns, each non-proposed pattern\nreduces the number of tools to choose from, reducing complexity. We iteratively\ndeveloped CAPI, evaluating its understandability and usability in small studies\nwith academic participants. When satisfied with the outcome, we performed a\nuser-study with industry representatives to investigate the state-of-the-art in\ntechnology selection and the effectiveness of our proposed method. We find that\ntechnology selection is largely performed via trial and error, that CAPI is\nuniformly perceived as helpful, and that CAPI is able to reproduce the\nproductive architectural environments of our participants.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCAPI\u7684\u7efc\u5408\u67b6\u6784\u6a21\u5f0f\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bca\u65ad\u51b3\u7b56\u6811\u4e3a\u7528\u6237\u9700\u6c42\u63a8\u8350\u67b6\u6784\u6a21\u5f0f\uff0c\u964d\u4f4e\u5de5\u5177\u9009\u62e9\u590d\u6742\u6027\u3002", "motivation": "\u6280\u672f\u53d8\u5316\u5feb\u901f\uff0c\u5355\u4e2a\u5f00\u53d1\u8005\u96be\u4ee5\u638c\u63e1\u6240\u6709\u5de5\u5177\u548c\u8d8b\u52bf\uff0c\u5de5\u5177\u9009\u62e9\u548c\u67b6\u6784\u8bbe\u8ba1\u6210\u4e3a\u590d\u6742\u95ee\u9898\u3002", "method": "\u5f00\u53d1CAPI\u65b9\u6cd5\uff0c\u5229\u7528\u51b3\u7b56\u6811\u63a8\u8350\u67b6\u6784\u6a21\u5f0f\uff0c\u8fed\u4ee3\u8bc4\u4f30\u5176\u53ef\u7406\u89e3\u6027\u548c\u53ef\u7528\u6027\u3002", "result": "\u6280\u672f\u9009\u62e9\u591a\u4f9d\u8d56\u8bd5\u9519\uff0cCAPI\u88ab\u8ba4\u4e3a\u666e\u904d\u6709\u7528\uff0c\u5e76\u80fd\u590d\u73b0\u53c2\u4e0e\u8005\u7684\u751f\u4ea7\u67b6\u6784\u73af\u5883\u3002", "conclusion": "CAPI\u901a\u8fc7\u63a8\u8350\u67b6\u6784\u6a21\u5f0f\u6709\u6548\u7b80\u5316\u4e86\u5de5\u5177\u9009\u62e9\u548c\u67b6\u6784\u8bbe\u8ba1\u95ee\u9898\u3002"}}
{"id": "2508.15801", "pdf": "https://arxiv.org/pdf/2508.15801", "abs": "https://arxiv.org/abs/2508.15801", "authors": ["Seyedali Mohammadi", "Manas Paldhe", "Amit Chhabra"], "title": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": "10 pages", "summary": "Phone call transcript labeling is prohibitively expensive (approximately 2\nUSD per minute) due to privacy regulations, consent requirements, and manual\nannotation costs requiring 3 hours of expert time per hour of audio. Existing\nextraction methods fail on conversational speech containing disfluencies,\ninterruptions, and speaker overlap. We introduce LingVarBench, a synthetic data\ngeneration pipeline that addresses these constraints through automated\nvalidation. First, we prompt an LLM to generate realistic structured field\nvalues across multiple use cases. Second, we recursively prompt the model to\ntransform these values into thousands of natural conversational utterances\ncontaining typical phone call characteristics. Third, we validate each\nsynthetic utterance by testing whether a separate LLM-based extractor can\nrecover the original structured information. We employ DSPy's SIMBA optimizer\nto automatically synthesize extraction prompts from validated synthetic\ntranscripts, eliminating manual prompt engineering. Our optimized prompts\nachieve up to 95 percent accuracy for numeric fields (vs. 88-89 percent\nzero-shot), 90 percent for names (vs. 47-79 percent), and over 80 percent for\ndates (vs. 72-77 percent) on real customer transcripts, demonstrating\nsubstantial gains over zero-shot prompting. The synthetic-to-real transfer\ndemonstrates that conversational patterns learned from generated data\ngeneralize effectively to authentic phone calls containing background noise and\ndomain-specific terminology. LingVarBench provides the first systematic\nbenchmark for structured extraction from synthetic conversational data,\ndemonstrating that automated prompt optimization overcomes cost and privacy\nbarriers preventing large-scale phone call analysis in commercial settings.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86LingVarBench\uff0c\u4e00\u79cd\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u81ea\u52a8\u5316\u9a8c\u8bc1\u89e3\u51b3\u7535\u8bdd\u901a\u8bdd\u8f6c\u5f55\u6807\u6ce8\u9ad8\u6210\u672c\u95ee\u9898\u7684\u7ba1\u9053\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ed3\u6784\u5316\u4fe1\u606f\u63d0\u53d6\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7535\u8bdd\u901a\u8bdd\u8f6c\u5f55\u6807\u6ce8\u56e0\u9690\u79c1\u6cd5\u89c4\u3001\u8bb8\u53ef\u8981\u6c42\u548c\u624b\u52a8\u6807\u6ce8\u7684\u9ad8\u6210\u672c\uff08\u6bcf\u5206\u949f\u7ea62\u7f8e\u5143\uff09\u800c\u6602\u8d35\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5305\u542b\u4e0d\u6d41\u7545\u3001\u6253\u65ad\u548c\u8bf4\u8bdd\u8005\u91cd\u53e0\u7684\u5bf9\u8bdd\u8bed\u97f3\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5229\u7528LLM\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5305\u62ec\u7ed3\u6784\u5316\u5b57\u6bb5\u503c\u548c\u81ea\u7136\u5bf9\u8bdd\u8bed\u53e5\uff0c\u5e76\u901a\u8fc7LLM\u9a8c\u8bc1\u5668\u786e\u4fdd\u5408\u6210\u6570\u636e\u7684\u6709\u6548\u6027\u3002\u4f7f\u7528DSPy\u7684SIMBA\u4f18\u5316\u5668\u81ea\u52a8\u5316\u5408\u6210\u63d0\u53d6\u63d0\u793a\uff0c\u6d88\u9664\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\u3002", "result": "\u4f18\u5316\u63d0\u793a\u5728\u771f\u5b9e\u5ba2\u6237\u901a\u8bdd\u8f6c\u5f55\u4e2d\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1a\u6570\u5b57\u5b57\u6bb5\u51c6\u786e\u738795%\uff08\u96f6\u6837\u672c88-89%\uff09\uff0c\u59d3\u540d90%\uff08\u96f6\u6837\u672c47-79%\uff09\uff0c\u65e5\u671f80%\uff08\u96f6\u6837\u672c72-77%\uff09\u3002", "conclusion": "LingVarBench\u901a\u8fc7\u5408\u6210\u6570\u636e\u5b66\u4e60\u5bf9\u8bdd\u6a21\u5f0f\uff0c\u6709\u6548\u6cdb\u5316\u81f3\u771f\u5b9e\u7535\u8bdd\u901a\u8bdd\uff0c\u4e3a\u5546\u4e1a\u73af\u5883\u4e2d\u5927\u89c4\u6a21\u901a\u8bdd\u5206\u6790\u63d0\u4f9b\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16119", "pdf": "https://arxiv.org/pdf/2508.16119", "abs": "https://arxiv.org/abs/2508.16119", "authors": ["Madhava Gaikwad", "Abhishek Gandhi"], "title": "ANSC: Probabilistic Capacity Health Scoring for Datacenter-Scale Reliability", "categories": ["cs.NI", "cs.AI", "60K20 (Primary), 90B25, 68M15 (Secondary)", "C.2.4; D.4.7; I.2.6"], "comment": "3 pages", "summary": "We present ANSC, a probabilistic capacity health scoring framework for\nhyperscale datacenter fabrics. While existing alerting systems detect\nindividual device or link failures, they do not capture the aggregate risk of\ncascading capacity shortfalls. ANSC provides a color-coded scoring system that\nindicates the urgency of issues \\emph{not solely by current impact, but by the\nprobability of imminent capacity violations}. Our system accounts for both\ncurrent residual capacity and the probability of additional failures,\nnormalized at datacenter and regional level. We demonstrate that ANSC enables\noperators to prioritize remediation across more than 400 datacenters and 60\nregions, reducing noise and aligning SRE focus on the most critical risks.", "AI": {"tldr": "ANSC\u662f\u4e00\u79cd\u7528\u4e8e\u8d85\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u7684\u6982\u7387\u6027\u5bb9\u91cf\u5065\u5eb7\u8bc4\u5206\u6846\u67b6\uff0c\u80fd\u591f\u8bc4\u4f30\u6f5c\u5728\u7684\u7ea7\u8054\u5bb9\u91cf\u4e0d\u8db3\u98ce\u9669\uff0c\u5e2e\u52a9\u8fd0\u7ef4\u4eba\u5458\u4f18\u5148\u5904\u7406\u6700\u5173\u952e\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8b66\u62a5\u7cfb\u7edf\u4ec5\u80fd\u68c0\u6d4b\u5355\u4e2a\u8bbe\u5907\u6216\u94fe\u8def\u6545\u969c\uff0c\u65e0\u6cd5\u6355\u6349\u7ea7\u8054\u5bb9\u91cf\u4e0d\u8db3\u7684\u805a\u5408\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\u3002", "method": "ANSC\u91c7\u7528\u989c\u8272\u7f16\u7801\u8bc4\u5206\u7cfb\u7edf\uff0c\u7ed3\u5408\u5f53\u524d\u5269\u4f59\u5bb9\u91cf\u548c\u989d\u5916\u6545\u969c\u6982\u7387\uff0c\u5728\u6570\u636e\u4e2d\u5fc3\u548c\u533a\u57df\u7ea7\u522b\u8fdb\u884c\u5f52\u4e00\u5316\u8bc4\u4f30\u3002", "result": "ANSC\u5728400\u591a\u4e2a\u6570\u636e\u4e2d\u5fc3\u548c60\u4e2a\u533a\u57df\u4e2d\u6210\u529f\u51cf\u5c11\u4e86\u566a\u97f3\uff0c\u5e76\u5e2e\u52a9SRE\u56e2\u961f\u4e13\u6ce8\u4e8e\u6700\u5173\u952e\u7684\u98ce\u9669\u3002", "conclusion": "ANSC\u901a\u8fc7\u6982\u7387\u6027\u5bb9\u91cf\u8bc4\u5206\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d85\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u7684\u98ce\u9669\u7ba1\u7406\u6548\u7387\u3002"}}
{"id": "2508.16402", "pdf": "https://arxiv.org/pdf/2508.16402", "abs": "https://arxiv.org/abs/2508.16402", "authors": ["Zihan Wang", "Jiaze Chen", "Zhicheng Liu", "Markus Mak", "Yidi Du", "Geonsik Moon", "Luoqi Xu", "Aaron Tua", "Kunshuo Peng", "Jiayi Lu", "Mingfei Xia", "Boqian Zou", "Chenyang Ran", "Guang Tian", "Shoutai Zhu", "Yeheng Duan", "Zhenghui Kang", "Zhenxing Lin", "Shangshu Li", "Qiang Luo", "Qingshen Long", "Zhiyong Chen", "Yihan Xiao", "Yurong Wu", "Daoguang Zan", "Yuyi Fu", "Mingxuan Wang", "Ming Ding"], "title": "AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions", "categories": ["cs.SE", "cs.CL"], "comment": "15 pages", "summary": "Competitive programming has emerged as a critical benchmark for evaluating\nthe reasoning and coding capabilities of Large Language Models (LLMs). Despite\nimpressive progress on existing benchmarks, we argue that current evaluations\noverstate model proficiency, masking a substantial gap between LLMs and elite\nhuman programmers. This gap arises from two key limitations: insufficient\ndifficulty and scope of benchmark problems, and evaluation bias from\nlow-quality test cases. To address these shortcomings, we present AetherCode, a\nnew benchmark that draws problems from premier programming competitions such as\nIOI and ICPC, offering broader coverage and higher difficulty. AetherCode\nfurther incorporates comprehensive, expert-validated test suites built through\na hybrid of automated generation and human curation, ensuring rigorous and\nreliable assessment. By combining challenging problem design with robust\nevaluation, AetherCode provides a more faithful measure of LLM capabilities and\nsets a new standard for future research in code reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5AetherCode\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7a0b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f4e\u4f30\u4e86\u4eba\u7c7b\u7f16\u7a0b\u9ad8\u624b\u4e0eLLMs\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u9700\u8981\u66f4\u96be\u7684\u6d4b\u8bd5\u95ee\u9898\u3002", "method": "\u4ece\u9876\u7ea7\u7f16\u7a0b\u7ade\u8d5b\u4e2d\u9009\u62e9\u95ee\u9898\uff0c\u7ed3\u5408\u81ea\u52a8\u751f\u6210\u548c\u4eba\u5de5\u9a8c\u8bc1\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "AetherCode\u80fd\u66f4\u53ef\u9760\u5730\u8bc4\u4f30LLMs\u7684\u7f16\u7a0b\u80fd\u529b\u3002", "conclusion": "AetherCode\u4e3a\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e0d\u8db3\u63d0\u4f9b\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2508.15826", "pdf": "https://arxiv.org/pdf/2508.15826", "abs": "https://arxiv.org/abs/2508.15826", "authors": ["Andria Andriuzzi", "G\u00e9raldine Michel"], "title": "Embarrassed to observe: The effects of directive language in brand conversation", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.SI"], "comment": "This is an open access article under the terms of the Creative\n  Commons Attribution-NonCommercial-NoDerivs License, which permits use and\n  distribution in any medium, provided the original work is properly cited, the\n  use is non-commercial and no modifications or adaptations are made", "summary": "In social media, marketers attempt to influence consumers by using directive\nlanguage, that is, expressions designed to get consumers to take action. While\nthe literature has shown that directive messages in advertising have mixed\nresults for recipients, we know little about the effects of directive brand\nlanguage on consumers who see brands interacting with other consumers in social\nmedia conversations. On the basis of a field study and three online\nexperiments, this study shows that directive language in brand conversation has\na detrimental downstream effect on engagement of consumers who observe such\nexchanges. Specifically, in line with Goffman's facework theory, because a\nbrand that encourages consumers to react could be perceived as\nface-threatening, consumers who see a brand interacting with others in a\ndirective way may feel vicarious embarrassment and engage less (compared with a\nconversation without directive language). In addition, we find that when the\nconversation is nonproduct-centered (vs. product-centered), consumers expect\nmore freedom, as in mundane conversations, even for others; therefore,\ndirective language has a stronger negative effect. However, in this context,\nthe strength of the brand relationship mitigates this effect. Thus, this study\ncontributes to the literature on directive language and brand-consumer\ninteractions by highlighting the importance of context in interactive\ncommunication, with direct relevance for social media and brand management.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u793e\u4ea4\u5a92\u4f53\u4e2d\u54c1\u724c\u4f7f\u7528\u6307\u4ee4\u6027\u8bed\u8a00\u5bf9\u89c2\u5bdf\u6d88\u8d39\u8005\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u53d1\u73b0\u8fd9\u79cd\u8bed\u8a00\u4f1a\u5f15\u53d1\u95f4\u63a5\u5c34\u5c2c\u5e76\u964d\u4f4e\u53c2\u4e0e\u5ea6\uff0c\u5c24\u5176\u5728\u975e\u4ea7\u54c1\u4e2d\u5fc3\u5bf9\u8bdd\u4e2d\u6548\u679c\u66f4\u663e\u8457\uff0c\u4f46\u54c1\u724c\u5173\u7cfb\u5f3a\u5ea6\u53ef\u4ee5\u7f13\u89e3\u8fd9\u79cd\u5f71\u54cd\u3002", "motivation": "\u867d\u7136\u5e7f\u544a\u4e2d\u7684\u6307\u4ee4\u6027\u8bed\u8a00\u6548\u679c\u4e0d\u4e00\uff0c\u4f46\u793e\u4ea4\u5a92\u4f53\u4e2d\u54c1\u724c\u4f7f\u7528\u6307\u4ee4\u6027\u8bed\u8a00\u5bf9\u89c2\u5bdf\u6d88\u8d39\u8005\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u4e00\u9879\u5b9e\u5730\u7814\u7a76\u548c\u4e09\u4e2a\u5728\u7ebf\u5b9e\u9a8c\uff0c\u7ed3\u5408Goffman\u7684\u9762\u5b50\u7406\u8bba\u5206\u6790\u6d88\u8d39\u8005\u53cd\u5e94\u3002", "result": "\u6307\u4ee4\u6027\u8bed\u8a00\u4f1a\u964d\u4f4e\u89c2\u5bdf\u6d88\u8d39\u8005\u7684\u53c2\u4e0e\u5ea6\uff0c\u975e\u4ea7\u54c1\u4e2d\u5fc3\u5bf9\u8bdd\u4e2d\u8d1f\u9762\u5f71\u54cd\u66f4\u5f3a\uff0c\u54c1\u724c\u5173\u7cfb\u5f3a\u5ea6\u53ef\u7f13\u89e3\u6b64\u6548\u5e94\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u4e92\u52a8\u6c9f\u901a\u4e2d\u60c5\u5883\u7684\u91cd\u8981\u6027\uff0c\u5bf9\u793e\u4ea4\u5a92\u4f53\u548c\u54c1\u724c\u7ba1\u7406\u5177\u6709\u76f4\u63a5\u542f\u793a\u3002"}}
{"id": "2508.16184", "pdf": "https://arxiv.org/pdf/2508.16184", "abs": "https://arxiv.org/abs/2508.16184", "authors": ["Yuhao Zheng", "Ting You", "Kejia Peng", "Chang Liu"], "title": "Joint Cache Placement and Routing in Satellite-Terrestrial Edge Computing Network: A GNN-Enabled DRL Approach", "categories": ["cs.NI"], "comment": "5 pages, 6 figures", "summary": "In this letter, we investigate the problem of joint content caching and\nrouting in satellite-terrestrial edge computing networks (STECNs) to improve\ncaching service for geographically distributed users. To handle the challenges\narising from dynamic low Earth orbit (LEO) satellite topologies and\nheterogeneous content demands, we propose a learning-based framework that\nintegrates graph neural networks (GNNs) with deep reinforcement learning (DRL).\nThe satellite network is represented as a dynamic graph, where GNNs are\nembedded within the DRL agent to capture spatial and topological dependencies\nand support routing-aware decision-making. The caching strategy is optimized by\nformulating the problem as a Markov decision process (MDP) and applying soft\nactor-critic (SAC) algorithm. Simulation results demonstrate that our approach\nsignificantly improves the delivery success rate and reduces communication\ntraffic cost.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u548c\u52a8\u6001\u56fe\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u536b\u661f-\u5730\u9762\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u4e2d\u7684\u8054\u5408\u5185\u5bb9\u7f13\u5b58\u548c\u8def\u7531\u4f18\u5316\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001LEO\u536b\u661f\u62d3\u6251\u548c\u5f02\u6784\u5185\u5bb9\u9700\u6c42\u5e26\u6765\u7684\u6311\u6218\uff0c\u63d0\u5347\u5206\u5e03\u5f0f\u7528\u6237\u7684\u7f13\u5b58\u670d\u52a1\u3002", "method": "\u6574\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u5c06\u536b\u661f\u7f51\u7edc\u8868\u793a\u4e3a\u52a8\u6001\u56fe\uff0c\u5e76\u5e94\u7528\u8f6fActor-Critic\uff08SAC\uff09\u7b97\u6cd5\u4f18\u5316\u7f13\u5b58\u7b56\u7565\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u4ea4\u4ed8\u6210\u529f\u7387\u5e76\u964d\u4f4e\u4e86\u901a\u4fe1\u6d41\u91cf\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b66\u4e60\u6846\u67b6\u5728\u52a8\u6001\u548c\u5f02\u6784\u73af\u5883\u4e0b\u6709\u6548\u4f18\u5316\u4e86\u7f13\u5b58\u548c\u8def\u7531\u95ee\u9898\u3002"}}
{"id": "2508.16419", "pdf": "https://arxiv.org/pdf/2508.16419", "abs": "https://arxiv.org/abs/2508.16419", "authors": ["Akshay Mhatre", "Noujoud Nader", "Patrick Diehl", "Deepti Gupta"], "title": "LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) such as ChatGPT-4, Claude 3, and LLaMA 4 are\nincreasingly embedded in software/application development, supporting tasks\nfrom code generation to debugging. Yet, their real-world effectiveness in\ndetecting diverse software bugs, particularly complex, security-relevant\nvulnerabilities, remains underexplored. This study presents a systematic,\nempirical evaluation of these three leading LLMs using a benchmark of\nfoundational programming errors, classic security flaws, and advanced,\nproduction-grade bugs in C++ and Python. The dataset integrates real code from\nSEED Labs, OpenSSL (via the Suresoft GLaDOS database), and PyBugHive, validated\nthrough local compilation and testing pipelines. A novel multi-stage,\ncontext-aware prompting protocol simulates realistic debugging scenarios, while\na graded rubric measures detection accuracy, reasoning depth, and remediation\nquality. Our results show that all models excel at identifying syntactic and\nsemantic issues in well-scoped code, making them promising for educational use\nand as first-pass reviewers in automated code auditing. Performance diminishes\nin scenarios involving complex security vulnerabilities and large-scale\nproduction code, with ChatGPT-4 and Claude 3 generally providing more nuanced\ncontextual analyses than LLaMA 4. This highlights both the promise and the\npresent constraints of LLMs in serving as reliable code analysis tools.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86ChatGPT-4\u3001Claude 3\u548cLLaMA 4\u5728\u68c0\u6d4b\u591a\u79cd\u8f6f\u4ef6bug\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u7b80\u5355\u4ee3\u7801\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5904\u7406\u590d\u6742\u5b89\u5168\u6f0f\u6d1e\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4b\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6bug\u4e2d\u7684\u5b9e\u9645\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u5b89\u5168\u6f0f\u6d1e\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u5305\u542b\u57fa\u7840\u7f16\u7a0b\u9519\u8bef\u3001\u7ecf\u5178\u5b89\u5168\u6f0f\u6d1e\u548c\u751f\u4ea7\u7ea7bug\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u63d0\u793a\u534f\u8bae\u6a21\u62df\u771f\u5b9e\u8c03\u8bd5\u573a\u666f\u3002", "result": "\u6a21\u578b\u5728\u7b80\u5355\u4ee3\u7801\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u5b89\u5168\u6f0f\u6d1e\u548c\u5927\u89c4\u6a21\u751f\u4ea7\u4ee3\u7801\u4e2d\u6027\u80fd\u4e0b\u964d\uff0cChatGPT-4\u548cClaude 3\u7684\u5206\u6790\u66f4\u7ec6\u81f4\u3002", "conclusion": "LLMs\u5728\u4ee3\u7801\u5206\u6790\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e2d\u4ecd\u6709\u5c40\u9650\u6027\u3002"}}
{"id": "2508.16445", "pdf": "https://arxiv.org/pdf/2508.16445", "abs": "https://arxiv.org/abs/2508.16445", "authors": ["Sonia Nicoletti", "Paolo Ciancarini"], "title": "Using LLMs and Essence to Support Software Practice Adoption", "categories": ["cs.SE"], "comment": null, "summary": "Recent advancements in natural language processing (NLP) have enabled the\ndevelopment of automated tools that support various domains, including software\nengineering. However, while NLP and artificial intelligence (AI) research has\nextensively focused on tasks such as code generation, less attention has been\ngiven to automating support for the adoption of best practices, the evolution\nof ways of working, and the monitoring of process health. This study addresses\nthis gap by exploring the integration of Essence, a standard and thinking\nframework for managing software engineering practices, with large language\nmodels (LLMs). To this end, a specialised chatbot was developed to assist\nstudents and professionals in understanding and applying Essence. The chatbot\nemploys a retrieval-augmented generation (RAG) system to retrieve relevant\ncontextual information from a curated knowledge base. Four different LLMs were\nused to create multiple chatbot configurations, each evaluated both as a base\nmodel and augmented with the RAG system. The system performance was evaluated\nthrough both the relevance of retrieved context and the quality of generated\nresponses. Comparative analysis against the general-purpose LLMs demonstrated\nthat the proposed system consistently outperforms its baseline counterpart in\ndomain-specific tasks. By facilitating access to structured software\nengineering knowledge, this work contributes to bridging the gap between\ntheoretical frameworks and practical application, potentially improving process\nmanagement and the adoption of software development practices. While further\nvalidation through user studies is required, these findings highlight the\npotential of LLM-based automation to enhance learning and decision-making in\nsoftware engineering.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u5c06Essence\u6846\u67b6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e13\u95e8\u804a\u5929\u673a\u5668\u4eba\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u63d0\u9ad8\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524dNLP\u548cAI\u7814\u7a76\u591a\u5173\u6ce8\u4ee3\u7801\u751f\u6210\uff0c\u800c\u5ffd\u7565\u4e86\u81ea\u52a8\u5316\u652f\u6301\u6700\u4f73\u5b9e\u8df5\u91c7\u7eb3\u3001\u5de5\u4f5c\u65b9\u5f0f\u6f14\u8fdb\u548c\u6d41\u7a0b\u5065\u5eb7\u76d1\u63a7\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u57fa\u4e8eEssence\u6846\u67b6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u4ece\u77e5\u8bc6\u5e93\u4e2d\u68c0\u7d22\u4fe1\u606f\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u77e5\u8bc6\u7684\u5b66\u4e60\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6301\u3002", "conclusion": "\u5c3d\u7ba1\u8fd8\u9700\u8fdb\u4e00\u6b65\u7528\u6237\u9a8c\u8bc1\uff0c\u4f46\u7814\u7a76\u8868\u660e\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u5de5\u5177\u5728\u63d0\u5347\u8f6f\u4ef6\u5de5\u7a0b\u5b66\u4e60\u548c\u51b3\u7b56\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.16274", "pdf": "https://arxiv.org/pdf/2508.16274", "abs": "https://arxiv.org/abs/2508.16274", "authors": ["Anton Belichenko", "Daria Trinitatova", "Aigul Nasibullina", "Lev Yakovlev", "Dzmitry Tsetserukou"], "title": "EEG Study of the Influence of Imagined Temperature Sensations on Neuronal Activity in the Sensorimotor Cortex", "categories": ["q-bio.NC", "cs.HC"], "comment": "Accepted to the IEEE International Conference on Systems, Man, and\n  Cybernetics 2025 (IEEE SMC 2025), 6 pages, 6 figures, 1 table", "summary": "Understanding the neural correlates of sensory imagery is crucial for\nadvancing cognitive neuroscience and developing novel Brain-Computer Interface\n(BCI) paradigms. This study investigated the influence of imagined temperature\nsensations (ITS) on neural activity within the sensorimotor cortex. The\nexperimental study involved the evaluation of neural activity using\nelectroencephalography (EEG) during both real thermal stimulation (TS:\n40{\\deg}C Hot, 20{\\deg}C Cold) applied to the participants' hand, and the\nmental temperature imagination (ITS) of the corresponding hot and cold\nsensations. The analysis focused on quantifying the event-related\ndesynchronization (ERD) of the sensorimotor mu-rhythm (8-13 Hz). The\nexperimental results revealed a characteristic mu-ERD localized over central\nscalp regions (e.g., C3) during both TS and ITS conditions. Although the\nmagnitude of mu-ERD during ITS was slightly lower than during TS, this\ndifference was not statistically significant (p>.05). However, ERD during both\nITS and TS was statistically significantly different from the resting baseline\n(p<.001). These findings demonstrate that imagining temperature sensations\nengages sensorimotor cortical mechanisms in a manner comparable to actual\nthermal perception. This insight expands our understanding of the\nneurophysiological basis of sensory imagery and suggests the potential utility\nof ITS for non-motor BCI control and neurorehabilitation technologies.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u60f3\u8c61\u6e29\u5ea6\u611f\u89c9\u5bf9\u795e\u7ecf\u6d3b\u52a8\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u6fc0\u6d3b\u611f\u89c9\u8fd0\u52a8\u76ae\u5c42\u7684\u673a\u5236\u4e0e\u5b9e\u9645\u6e29\u5ea6\u611f\u77e5\u76f8\u4f3c\uff0c\u5bf9\u8111\u673a\u63a5\u53e3\u548c\u795e\u7ecf\u5eb7\u590d\u6280\u672f\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u7406\u89e3\u611f\u89c9\u60f3\u8c61\u7684\u795e\u7ecf\u5173\u8054\u5bf9\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u548c\u8111\u673a\u63a5\u53e3\u6280\u672f\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7EEG\u8bb0\u5f55\u771f\u5b9e\u70ed\u523a\u6fc0\uff0840\u00b0C\u548c20\u00b0C\uff09\u4e0e\u60f3\u8c61\u6e29\u5ea6\u611f\u89c9\u65f6\u7684\u795e\u7ecf\u6d3b\u52a8\uff0c\u5206\u6790\u611f\u89c9\u8fd0\u52a8\u76ae\u5c42mu\u8282\u5f8b\u7684\u4e8b\u4ef6\u76f8\u5173\u53bb\u540c\u6b65\u5316\uff08ERD\uff09\u3002", "result": "\u60f3\u8c61\u6e29\u5ea6\u611f\u89c9\u548c\u5b9e\u9645\u70ed\u523a\u6fc0\u90fd\u80fd\u8bf1\u53d1\u4e2d\u592e\u5934\u76ae\u533a\u57df\u7684mu-ERD\uff0c\u5dee\u5f02\u4e0d\u663e\u8457\uff08p>.05\uff09\uff0c\u4f46\u5747\u663e\u8457\u4e0d\u540c\u4e8e\u57fa\u7ebf\uff08p<.001\uff09\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u60f3\u8c61\u6e29\u5ea6\u611f\u89c9\u53ef\u4ee5\u7c7b\u4f3c\u5b9e\u9645\u611f\u77e5\u6fc0\u6d3b\u611f\u89c9\u8fd0\u52a8\u76ae\u5c42\uff0c\u4e3a\u8111\u673a\u63a5\u53e3\u548c\u795e\u7ecf\u5eb7\u590d\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2508.15821", "pdf": "https://arxiv.org/pdf/2508.15821", "abs": "https://arxiv.org/abs/2508.15821", "authors": ["Bibo Wu", "Fang Fang", "Ming Zeng", "Xianbin Wang"], "title": "Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network", "categories": ["cs.IT", "cs.AI", "cs.NI", "math.IT"], "comment": null, "summary": "Leveraging pinching antennas in wireless network enabled federated learning\n(FL) can effectively mitigate the common \"straggler\" issue in FL by dynamically\nestablishing strong line-of-sight (LoS) links on demand. This letter proposes a\nhybrid conventional and pinching antenna network (HCPAN) to significantly\nimprove communication efficiency in the non-orthogonal multiple access\n(NOMA)-enabled FL system. Within this framework, a fuzzy logic-based client\nclassification scheme is first proposed to effectively balance clients' data\ncontributions and communication conditions. Given this classification, we\nformulate a total time minimization problem to jointly optimize pinching\nantenna placement and resource allocation. Due to the complexity of variable\ncoupling and non-convexity, a deep reinforcement learning (DRL)-based algorithm\nis developed to effectively address this problem. Simulation results validate\nthe superiority of the proposed scheme in enhancing FL performance via the\noptimized deployment of pinching antenna.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u4f20\u7edf\u548c\u634f\u7f29\u5929\u7ebf\u7684\u7f51\u7edc(HCPAN)\uff0c\u901a\u8fc7\u52a8\u6001\u5efa\u7acb\u5f3a\u89c6\u8ddd\u94fe\u63a5\u6765\u7f13\u89e3\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u201c\u62d6\u540e\u817f\u201d\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60(FL)\u4e2d\u5e38\u89c1\u7684\u201c\u62d6\u540e\u817f\u201d\u95ee\u9898\u5f71\u54cd\u4e86\u901a\u4fe1\u6548\u7387\uff0c\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u90e8\u7f72\u548c\u8d44\u6e90\u5206\u914d\u6765\u6539\u5584\u8fd9\u4e00\u72b6\u51b5\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u5ba2\u6237\u7aef\u5206\u7c7b\u65b9\u6848\u30022. \u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u8054\u5408\u4f18\u5316\u5929\u7ebf\u653e\u7f6e\u548c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6848\u901a\u8fc7\u4f18\u5316\u634f\u7f29\u5929\u7ebf\u90e8\u7f72\u663e\u8457\u63d0\u5347\u4e86FL\u6027\u80fd\u3002", "conclusion": "HCPAN\u548cDRL\u7b97\u6cd5\u7684\u7ed3\u5408\u6709\u6548\u89e3\u51b3\u4e86FL\u4e2d\u7684\u901a\u4fe1\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.16499", "pdf": "https://arxiv.org/pdf/2508.16499", "abs": "https://arxiv.org/abs/2508.16499", "authors": ["Kazuki Kusama", "Honglin Shu", "Masanari Kondo", "Yasutaka Kamei"], "title": "How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair", "categories": ["cs.SE"], "comment": null, "summary": "Background: Large language models (LLMs) have greatly improved the accuracy\nof automated program repair (APR) methods. However, LLMs are constrained by\nhigh computational resource requirements. Aims: We focus on small language\nmodels (SLMs), which perform well even with limited computational resources\ncompared to LLMs. We aim to evaluate whether SLMs can achieve competitive\nperformance in APR tasks. Method: We conducted experiments on the QuixBugs\nbenchmark to compare the bug-fixing accuracy of SLMs and LLMs. We also analyzed\nthe impact of int8 quantization on APR performance. Results: The latest SLMs\ncan fix bugs as accurately as--or even more accurately than--LLMs. Also, int8\nquantization had minimal effect on APR accuracy while significantly reducing\nmemory requirements. Conclusions: SLMs present a viable alternative to LLMs for\nAPR, offering competitive accuracy with lower computational costs, and\nquantization can further enhance their efficiency without compromising\neffectiveness.", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u66f4\u4f4e\uff0c\u91cf\u5316\u6280\u672f\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5176\u6548\u7387\u3002", "motivation": "\u7814\u7a76SLMs\u662f\u5426\u80fd\u591f\u5728APR\u4efb\u52a1\u4e2d\u66ff\u4ee3\u9ad8\u8d44\u6e90\u6d88\u8017\u7684LLMs\uff0c\u4ee5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5728QuixBugs\u57fa\u51c6\u4e0a\u6bd4\u8f83SLMs\u548cLLMs\u7684\u4fee\u590d\u51c6\u786e\u6027\uff0c\u5e76\u5206\u6790int8\u91cf\u5316\u7684\u5f71\u54cd\u3002", "result": "SLMs\u4e0eLLMs\u4fee\u590d\u51c6\u786e\u6027\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\uff0c\u91cf\u5316\u5bf9\u5176\u51c6\u786e\u6027\u5f71\u54cd\u6781\u5c0f\u4f46\u663e\u8457\u964d\u4f4e\u5185\u5b58\u9700\u6c42\u3002", "conclusion": "SLMs\u662fLLMs\u5728APR\u4e2d\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u517c\u5177\u9ad8\u51c6\u786e\u6027\u548c\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u91cf\u5316\u6280\u672f\u8fdb\u4e00\u6b65\u4f18\u5316\u6548\u7387\u3002"}}
{"id": "2508.16277", "pdf": "https://arxiv.org/pdf/2508.16277", "abs": "https://arxiv.org/abs/2508.16277", "authors": ["Alexandru Tugui"], "title": "The next question after Turing's question: Introducing the Grow-AI test", "categories": ["cs.AI", "cs.HC", "68T01, 68T05, 68T42, 91A80", "I.2; K.4"], "comment": "9th International Conference on Inventive Systems and Control ICISC\n  2025", "summary": "This study aims to extend the framework for assessing artificial\nintelligence, called GROW-AI (Growth and Realization of Autonomous Wisdom),\ndesigned to answer the question \"Can machines grow up?\" -- a natural successor\nto the Turing Test. The methodology applied is based on a system of six primary\ncriteria (C1-C6), each assessed through a specific \"game\", divided into four\narenas that explore both the human dimension and its transposition into AI. All\ndecisions and actions of the entity are recorded in a standardized AI Journal,\nthe primary source for calculating composite scores. The assessment uses the\nprior expert method to establish initial weights, and the global score -- Grow\nUp Index -- is calculated as the arithmetic mean of the six scores, with\ninterpretation on maturity thresholds. The results show that the methodology\nallows for a coherent and comparable assessment of the level of \"growth\" of AI\nentities, regardless of their type (robots, software agents, LLMs). The\nmulti-game structure highlights strengths and vulnerable areas, and the use of\na unified journal guarantees traceability and replicability in the evaluation.\nThe originality of the work lies in the conceptual transposition of the process\nof \"growing\" from the human world to that of artificial intelligence, in an\nintegrated testing format that combines perspectives from psychology, robotics,\ncomputer science, and ethics. Through this approach, GROW-AI not only measures\nperformance but also captures the evolutionary path of an AI entity towards\nmaturity.", "AI": {"tldr": "\u672c\u7814\u7a76\u6269\u5c55\u4e86GROW-AI\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u516d\u9879\u6807\u51c6\u548c\u56db\u7c7b\u6e38\u620f\u8bc4\u4f30AI\u7684\u201c\u6210\u957f\u201d\u6c34\u5e73\uff0c\u7ed3\u679c\u5c55\u793a\u4e86\u4e00\u79cd\u901a\u7528\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u63d0\u51faGROW-AI\u6846\u67b6\uff0c\u4ee5\u56de\u7b54\u201c\u673a\u5668\u80fd\u5426\u6210\u957f\u201d\u7684\u95ee\u9898\uff0c\u5e76\u8d85\u8d8a\u56fe\u7075\u6d4b\u8bd5\u3002", "method": "\u4f7f\u7528\u516d\u9879\u6807\u51c6\uff08C1-C6\uff09\u548c\u56db\u7c7b\u6e38\u620f\u8fdb\u884c\u8bc4\u4f30\uff0c\u8bb0\u5f55\u5728AI\u65e5\u5fd7\u4e2d\uff0c\u901a\u8fc7\u4e13\u5bb6\u65b9\u6cd5\u8ba1\u7b97\u6210\u957f\u6307\u6570\u3002", "result": "\u65b9\u6cd5\u80fd\u7edf\u4e00\u8bc4\u4f30\u5404\u7c7bAI\u7684\u201c\u6210\u957f\u201d\u6c34\u5e73\uff0c\u5e76\u63ed\u793a\u5176\u4f18\u52a3\u52bf\uff0c\u65e5\u5fd7\u4fdd\u8bc1\u4e86\u8bc4\u4f30\u7684\u53ef\u8ffd\u6eaf\u6027\u3002", "conclusion": "GROW-AI\u901a\u8fc7\u591a\u5b66\u79d1\u6574\u5408\uff0c\u4e0d\u4ec5\u6d4b\u91cf\u6027\u80fd\uff0c\u8fd8\u80fd\u6355\u6349AI\u7684\u6210\u719f\u8def\u5f84\u3002"}}
{"id": "2508.16030", "pdf": "https://arxiv.org/pdf/2508.16030", "abs": "https://arxiv.org/abs/2508.16030", "authors": ["Jinyue Song", "Hansol Ku", "Jayneel Vora", "Nelson Lee", "Ahmad Kamari", "Prasant Mohapatra", "Parth Pathak"], "title": "CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NI"], "comment": "Accepted at ICCCN 2025 (IEEE International Conference on Computer\n  Communications and Networks), Tokyo, Japan, August 2025", "summary": "Automotive FMCW radars remain reliable in rain and glare, yet their sparse,\nnoisy point clouds constrain 3-D object detection. We therefore release\nCoVeRaP, a 21 k-frame cooperative dataset that time-aligns radar, camera, and\nGPS streams from multiple vehicles across diverse manoeuvres. Built on this\ndata, we propose a unified cooperative-perception framework with middle- and\nlate-fusion options. Its baseline network employs a multi-branch PointNet-style\nencoder enhanced with self-attention to fuse spatial, Doppler, and intensity\ncues into a common latent space, which a decoder converts into 3-D bounding\nboxes and per-point depth confidence. Experiments show that middle fusion with\nintensity encoding boosts mean Average Precision by up to 9x at IoU 0.9 and\nconsistently outperforms single-vehicle baselines. CoVeRaP thus establishes the\nfirst reproducible benchmark for multi-vehicle FMCW-radar perception and\ndemonstrates that affordable radar sharing markedly improves detection\nrobustness. Dataset and code are publicly available to encourage further\nresearch.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCoVeRaP\u7684\u591a\u8f66\u534f\u540c\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u7edf\u4e00\u7684\u534f\u540c\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u96f7\u8fbe\u3001\u6444\u50cf\u5934\u548cGPS\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e863D\u7269\u4f53\u68c0\u6d4b\u7684\u7cbe\u5ea6\u3002", "motivation": "\u6c7d\u8f66FMCW\u96f7\u8fbe\u5728\u6076\u52a3\u5929\u6c14\u4e0b\u8868\u73b0\u53ef\u9760\uff0c\u4f46\u5176\u7a00\u758f\u4e14\u5608\u6742\u7684\u70b9\u4e91\u6570\u636e\u9650\u5236\u4e863D\u7269\u4f53\u68c0\u6d4b\u6548\u679c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u591a\u8f66\u534f\u540c\u7684\u6570\u636e\u96c6\u548c\u6846\u67b6\u6765\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "method": "\u4f5c\u8005\u53d1\u5e03\u4e86CoVeRaP\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e2d\u95f4\u548c\u540e\u671f\u878d\u5408\u9009\u9879\u7684\u7edf\u4e00\u534f\u540c\u611f\u77e5\u6846\u67b6\u3002\u57fa\u51c6\u7f51\u7edc\u91c7\u7528\u591a\u5206\u652fPointNet\u98ce\u683c\u7f16\u7801\u5668\uff0c\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u878d\u5408\u7a7a\u95f4\u3001\u591a\u666e\u52d2\u548c\u5f3a\u5ea6\u4fe1\u606f\u5230\u4e00\u4e2a\u5171\u540c\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u89e3\u7801\u5668\u5c06\u5176\u8f6c\u6362\u4e3a3D\u8fb9\u754c\u6846\u548c\u6bcf\u70b9\u6df1\u5ea6\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u5f3a\u5ea6\u7f16\u7801\u7684\u4e2d\u95f4\u878d\u5408\u65b9\u6cd5\u5c06\u5e73\u5747\u7cbe\u5ea6\u63d0\u9ad8\u4e869\u500d\uff08IoU 0.9\uff09\uff0c\u4e14\u6301\u7eed\u4f18\u4e8e\u5355\u8f66\u57fa\u7ebf\u3002", "conclusion": "CoVeRaP\u9996\u6b21\u4e3a\u591a\u8f66FMCW\u96f7\u8fbe\u611f\u77e5\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u51c6\uff0c\u5e76\u8bc1\u660e\u7ecf\u6d4e\u5b9e\u60e0\u7684\u96f7\u8fbe\u5171\u4eab\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u9c81\u68d2\u6027\u3002\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.16078", "pdf": "https://arxiv.org/pdf/2508.16078", "abs": "https://arxiv.org/abs/2508.16078", "authors": ["Nadeem Ahmed", "Lei Zhang", "Aryya Gangopadhyay"], "title": "A Survey of Post-Quantum Cryptography Support in Cryptographic Libraries", "categories": ["cs.CR", "cs.NI"], "comment": "To be published in IEEE International Conference on Quantum Computing\n  and Engineering (QCE) 2025", "summary": "The rapid advancement of quantum computing poses a significant threat to\nmodern cryptographic systems, necessitating the transition to Post-Quantum\nCryptography (PQC). This study evaluates the support for PQC algorithms within\nnine widely used open-source cryptographic libraries -- OpenSSL, wolfSSL,\nBoringSSL, LibreSSL, Bouncy Castle, libsodium, Crypto++, Botan, and MbedTLS --\nfocusing on their implementation of the NIST-selected PQC finalists:\nCRYSTALS-Kyber, CRYSTALS-Dilithium, FALCON, and SPHINCS+. Our analysis, based\non the latest available documentation, release notes, and industry reports as\nof early 2025, reveals a varied state of readiness across these libraries.\nWhile some libraries have integrated PQC support or have clear implementation\nroadmaps, others lag behind, creating potential security risks as quantum\nthreats become more imminent. We discuss key challenges, including performance\ntrade-offs, implementation security, and adoption hurdles in real-world\ncryptographic applications. Our findings highlight the urgent need for\ncontinued research, standardization efforts, and coordinated adoption\nstrategies to ensure a secure transition to the quantum-resistant cryptographic\nlandscape.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4e5d\u4e2a\u5f00\u6e90\u52a0\u5bc6\u5e93\u5bf9NIST\u9009\u5b9a\u7684\u540e\u91cf\u5b50\u5bc6\u7801\uff08PQC\uff09\u7b97\u6cd5\u7684\u652f\u6301\u60c5\u51b5\uff0c\u63ed\u793a\u4e86\u5404\u5e93\u5728\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u65b9\u9762\u7684\u4e0d\u540c\u51c6\u5907\u72b6\u6001\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u5feb\u901f\u53d1\u5c55\u5bf9\u73b0\u4ee3\u52a0\u5bc6\u7cfb\u7edf\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u4e9f\u9700\u5411\u540e\u91cf\u5b50\u5bc6\u7801\u8fc7\u6e21\u3002", "method": "\u7814\u7a76\u57fa\u4e8e\u6700\u65b0\u6587\u6863\u548c\u884c\u4e1a\u62a5\u544a\uff0c\u5206\u6790\u4e86\u4e5d\u4e2a\u5f00\u6e90\u52a0\u5bc6\u5e93\uff08\u5982OpenSSL\u3001Bouncy Castle\u7b49\uff09\u5bf9NIST PQC\u5019\u9009\u7b97\u6cd5\u7684\u652f\u6301\u60c5\u51b5\u3002", "result": "\u90e8\u5206\u5e93\u5df2\u96c6\u6210PQC\u652f\u6301\u6216\u6709\u660e\u786e\u8def\u7ebf\u56fe\uff0c\u800c\u53e6\u4e00\u4e9b\u5219\u843d\u540e\uff0c\u5e26\u6765\u6f5c\u5728\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u9700\u52a0\u7d27\u7814\u7a76\u3001\u6807\u51c6\u5316\u548c\u534f\u540c\u63a8\u8fdb\u540e\u91cf\u5b50\u5bc6\u7801\u7684\u91c7\u7528\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u8fc7\u6e21\u3002"}}
{"id": "2508.16465", "pdf": "https://arxiv.org/pdf/2508.16465", "abs": "https://arxiv.org/abs/2508.16465", "authors": ["Anilkumar Swamy", "Vincent Leroy", "Philippe Weinzaepfel", "Jean-S\u00e9bastien Franco", "Gr\u00e9gory Rogez"], "title": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "cs.RO"], "comment": "12 pages, 8 figures", "summary": "Hand-object 3D reconstruction has become increasingly important for\napplications in human-robot interaction and immersive AR/VR experiences. A\ncommon approach for object-agnostic hand-object reconstruction from RGB\nsequences involves a two-stage pipeline: hand-object 3D tracking followed by\nmulti-view 3D reconstruction. However, existing methods rely on keypoint\ndetection techniques, such as Structure from Motion (SfM) and hand-keypoint\noptimization, which struggle with diverse object geometries, weak textures, and\nmutual hand-object occlusions, limiting scalability and generalization. As a\nkey enabler to generic and seamless, non-intrusive applicability, we propose in\nthis work a robust, keypoint detector-free approach to estimating hand-object\n3D transformations from monocular motion video/images. We further integrate\nthis with a multi-view reconstruction pipeline to accurately recover\nhand-object 3D shape. Our method, named HOSt3R, is unconstrained, does not rely\non pre-scanned object templates or camera intrinsics, and reaches\nstate-of-the-art performance for the tasks of object-agnostic hand-object 3D\ntransformation and shape estimation on the SHOWMe benchmark. We also experiment\non sequences from the HO3D dataset, demonstrating generalization to unseen\nobject categories.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u9c81\u68d2\u65b9\u6cd5HOSt3R\uff0c\u7528\u4e8e\u4ece\u5355\u76ee\u89c6\u9891\u4e2d\u4f30\u8ba1\u624b-\u7269\u4f53\u76843D\u53d8\u6362\uff0c\u5e76\u7ed3\u5408\u591a\u89c6\u89d2\u91cd\u5efa\u6062\u590d\u5f62\u72b6\uff0c\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u591a\u6837\u7269\u4f53\u51e0\u4f55\u548c\u906e\u6321\u7684\u4f9d\u8d56\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5173\u952e\u70b9\u68c0\u6d4b\uff0c\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u7269\u4f53\u51e0\u4f55\u548c\u906e\u6321\uff0c\u9650\u5236\u4e86\u901a\u7528\u6027\u548c\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u89c6\u89d2\u91cd\u5efa\uff0c\u65e0\u9700\u9884\u626b\u63cf\u6a21\u677f\u6216\u76f8\u673a\u5185\u53c2\u3002", "result": "\u5728SHOWMe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u5e76\u5728HO3D\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5bf9\u672a\u89c1\u7269\u4f53\u7c7b\u522b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "HOSt3R\u662f\u4e00\u79cd\u901a\u7528\u6027\u5f3a\u3001\u975e\u4fb5\u5165\u6027\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u624b-\u7269\u4f533D\u91cd\u5efa\u4efb\u52a1\u3002"}}
{"id": "2508.16384", "pdf": "https://arxiv.org/pdf/2508.16384", "abs": "https://arxiv.org/abs/2508.16384", "authors": ["Gabriel Dengler", "Sven Apel", "Holger Hermanns"], "title": "Automata Learning -- Expect Delays!", "categories": ["cs.FL", "cs.SE"], "comment": "Accepted at Integrated Formal Methods (iFM) 2025", "summary": "This paper studies active automata learning (AAL) in the presence of\nstochastic delays. We consider Mealy machines that have stochastic delays\nassociated with each transition and explore how the learner can efficiently\narrive at faithful estimates of those machines, the precision of which\ncrucially relies on repetitive sampling of transition delays. While it is\npossible to na\\\"ively integrate the delay sampling into AAL algorithms such as\n$L^*$, this leads to considerable oversampling near the root of the state\nspace. We address this problem by separating conceptually the learning of\nbehavior and delays such that the learner uses the information gained while\nlearning the logical behavior to arrive at efficient input sequences for\ncollecting the needed delay samples. We put emphasis on treating cases in which\nidentical input/output behaviors might stem from distinct delay\ncharacteristics. Finally, we provide empirical evidence that our method\noutperforms the na\\\"ive baseline across a wide range of benchmarks and\ninvestigate its applicability in a realistic setting by studying the join order\nin a relational database.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5b58\u5728\u968f\u673a\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\uff08AAL\uff09\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u79bb\u5b66\u4e60\u548c\u5ef6\u8fdf\u91c7\u6837\u7684\u65b9\u6cd5\uff0c\u4ee5\u9ad8\u6548\u4f30\u8ba1Mealy\u673a\u5668\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5728\u968f\u673a\u5ef6\u8fdf\u7684\u73af\u5883\u4e2d\uff0c\u4f20\u7edfAAL\u65b9\u6cd5\uff08\u5982$L^*$\uff09\u56e0\u5728\u72b6\u6001\u7a7a\u95f4\u6839\u90e8\u8fc7\u5ea6\u91c7\u6837\u800c\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5ef6\u8fdf\u91c7\u6837\u7b56\u7565\u3002", "method": "\u5c06\u884c\u4e3a\u5b66\u4e60\u548c\u5ef6\u8fdf\u91c7\u6837\u6982\u5ff5\u4e0a\u5206\u79bb\uff0c\u5229\u7528\u903b\u8f91\u884c\u4e3a\u5b66\u4e60\u7684\u4fe1\u606f\u8bbe\u8ba1\u9ad8\u6548\u7684\u8f93\u5165\u5e8f\u5217\u4ee5\u6536\u96c6\u5ef6\u8fdf\u6837\u672c\uff0c\u5e76\u5904\u7406\u76f8\u540c\u8f93\u5165/\u8f93\u51fa\u884c\u4e3a\u53ef\u80fd\u7531\u4e0d\u540c\u5ef6\u8fdf\u7279\u6027\u5f15\u8d77\u7684\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5728\u5173\u7cfb\u6570\u636e\u5e93\u7684\u8fde\u63a5\u987a\u5e8f\u7814\u7a76\u4e2d\u5c55\u73b0\u51fa\u5b9e\u7528\u6f5c\u529b\u3002", "conclusion": "\u5206\u79bb\u884c\u4e3a\u5b66\u4e60\u548c\u5ef6\u8fdf\u91c7\u6837\u7684\u7b56\u7565\u663e\u8457\u63d0\u9ad8\u4e86AAL\u5728\u968f\u673a\u5ef6\u8fdf\u73af\u5883\u4e2d\u7684\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2508.16508", "pdf": "https://arxiv.org/pdf/2508.16508", "abs": "https://arxiv.org/abs/2508.16508", "authors": ["Siddharth Chaturvedi", "Ahmed El-Gazzar", "Marcel van Gerven"], "title": "Abmax: A JAX-based Agent-based Modeling Framework", "categories": ["cs.MA", "cs.SE"], "comment": "12 pages, 7 figures, 4 tables, 2 algorithms", "summary": "Agent-based modeling (ABM) is a principal approach for studying complex\nsystems. By decomposing a system into simpler, interacting agents, agent-based\nmodeling (ABM) allows researchers to observe the emergence of complex\nphenomena. High-performance array computing libraries like JAX can help scale\nsuch computational models to a large number of agents by using automatic\nvectorization and just-in-time (JIT) compilation. One of the caveats of using\nJAX to achieve such scaling is that the shapes of arrays used in the\ncomputational model should remain immutable throughout the simulation. In the\ncontext of agent-based modeling (ABM), this can pose constraints on certain\nagent manipulation operations that require flexible data structures. A subset\nof which is represented by the ability to update a dynamically selected number\nof agents by applying distinct changes to them during a simulation. To this\neffect, we introduce Abmax, an ABM framework based on JAX that implements\nmultiple just-in-time (JIT) compilable algorithms to provide this\nfunctionality. On the canonical predation model benchmark, Abmax achieves\nruntime performance comparable to state-of-the-art implementations. Further, we\nshow that this functionality can also be vectorized, making it possible to run\nmany similar agent-based models in parallel. We also present two examples in\nthe form of a traffic-flow model and a financial market model to show the use\ncase of Abmax.", "AI": {"tldr": "Abmax\u662f\u57fa\u4e8eJAX\u7684\u4ee3\u7406\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7JIT\u7f16\u8bd1\u548c\u5411\u91cf\u5316\u6280\u672f\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u4ee3\u7406\u64cd\u4f5c\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u590d\u6742\u7cfb\u7edf\u7684\u6a21\u62df\u3002", "motivation": "\u89e3\u51b3\u4f7f\u7528JAX\u8fdb\u884c\u4ee3\u7406\u5efa\u6a21\u65f6\uff0c\u7531\u4e8e\u6570\u7ec4\u5f62\u72b6\u4e0d\u53ef\u53d8\u5bfc\u81f4\u7684\u4ee3\u7406\u64cd\u4f5c\u7075\u6d3b\u6027\u53d7\u9650\u95ee\u9898\u3002", "method": "\u5f00\u53d1Abmax\u6846\u67b6\uff0c\u63d0\u4f9b\u591a\u79cdJIT\u7f16\u8bd1\u7b97\u6cd5\uff0c\u652f\u6301\u52a8\u6001\u4ee3\u7406\u66f4\u65b0\u548c\u5e76\u884c\u8fd0\u884c\u591a\u4e2a\u6a21\u578b\u3002", "result": "\u5728\u7ecf\u5178\u6355\u98df\u6a21\u578b\u4e0a\u8868\u73b0\u4e0e\u6700\u4f18\u5b9e\u73b0\u76f8\u5f53\uff0c\u5e76\u80fd\u9ad8\u6548\u8fd0\u884c\u4ea4\u901a\u6d41\u548c\u91d1\u878d\u5e02\u573a\u6a21\u578b\u3002", "conclusion": "Abmax\u4e3a\u4ee3\u7406\u5efa\u6a21\u63d0\u4f9b\u4e86\u517c\u5177\u6027\u80fd\u548c\u7075\u6d3b\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
