{"id": "2506.20754", "pdf": "https://arxiv.org/pdf/2506.20754", "abs": "https://arxiv.org/abs/2506.20754", "authors": ["Marina Ara\u00fajo", "J\u00falia Ara\u00fajo", "Romeu Oliveira", "Lucas Romao", "Marcos Kalinowski"], "title": "Domain Knowledge in Requirements Engineering: A Systematic Mapping Study", "categories": ["cs.SE"], "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Domain knowledge is recognized as a key component for the success\nof Requirements Engineering (RE), as it provides the conceptual support needed\nto understand the system context, ensure alignment with stakeholder needs, and\nreduce ambiguity in requirements specification. Despite its relevance, the\nscientific literature still lacks a systematic consolidation of how domain\nknowledge can be effectively used and operationalized in RE. [Goal] This paper\naddresses this gap by offering a comprehensive overview of existing\ncontributions, including methods, techniques, and tools to incorporate domain\nknowledge into RE practices. [Method] We conducted a systematic mapping study\nusing a hybrid search strategy that combines database searches with iterative\nbackward and forward snowballing. [Results] In total, we found 75 papers that\nmet our inclusion criteria. The analysis highlights the main types of\nrequirements addressed, the most frequently considered quality attributes, and\nrecurring challenges in the formalization, acquisition, and long-term\nmaintenance of domain knowledge. The results provide support for researchers\nand practitioners in identifying established approaches and unresolved issues.\nThe study also outlines promising directions for future research, emphasizing\nthe development of scalable, automated, and sustainable solutions to integrate\ndomain knowledge into RE processes. [Conclusion] The study contributes by\nproviding a comprehensive overview that helps to build a conceptual and\nmethodological foundation for knowledge-driven requirements engineering.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\uff0c\u603b\u7ed3\u4e86\u5982\u4f55\u5c06\u9886\u57df\u77e5\u8bc6\u6709\u6548\u878d\u5165\u9700\u6c42\u5de5\u7a0b\u7684\u73b0\u6709\u65b9\u6cd5\u3001\u6280\u672f\u548c\u5de5\u5177\uff0c\u5206\u6790\u4e86\u4e3b\u8981\u7c7b\u578b\u3001\u8d28\u91cf\u5c5e\u6027\u53ca\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u9886\u57df\u77e5\u8bc6\u5bf9\u9700\u6c42\u5de5\u7a0b\u7684\u6210\u529f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u5c06\u5176\u6709\u6548\u8fd0\u7528\u4e8e\u5b9e\u8df5\u4e2d\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u641c\u7d22\u7b56\u7565\u7684\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\uff0c\u7ed3\u5408\u6570\u636e\u5e93\u641c\u7d22\u4e0e\u8fed\u4ee3\u7684\u524d\u540e\u5411\u6eda\u96ea\u7403\u6cd5\uff0c\u7b5b\u9009\u51fa75\u7bc7\u7b26\u5408\u6761\u4ef6\u7684\u8bba\u6587\u8fdb\u884c\u5206\u6790\u3002", "result": "\u603b\u7ed3\u4e86\u9886\u57df\u77e5\u8bc6\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u4e3b\u8981\u5e94\u7528\u7c7b\u578b\u3001\u5e38\u89c1\u8d28\u91cf\u5c5e\u6027\u4ee5\u53ca\u6311\u6218\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u73b0\u6709\u65b9\u6cd5\u4e0e\u672a\u89e3\u51b3\u95ee\u9898\u7684\u652f\u6301\u3002", "conclusion": "\u7814\u7a76\u4e3a\u77e5\u8bc6\u9a71\u52a8\u7684\u9700\u6c42\u5de5\u7a0b\u5efa\u7acb\u4e86\u6982\u5ff5\u548c\u65b9\u6cd5\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u5f00\u53d1\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u7684\u65b9\u5411\u3002"}}
{"id": "2506.20759", "pdf": "https://arxiv.org/pdf/2506.20759", "abs": "https://arxiv.org/abs/2506.20759", "authors": ["Lucas Romao", "Hugo Villamizar", "Romeu Oliveira", "Silvio Alonso", "Marcos Kalinowski"], "title": "Agile Management for Machine Learning: A Systematic Mapping Study", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Machine learning (ML)-enabled systems are present in our society,\ndriving significant digital transformations. The dynamic nature of ML\ndevelopment, characterized by experimental cycles and rapid changes in data,\nposes challenges to traditional project management. Agile methods, with their\nflexibility and incremental delivery, seem well-suited to address this\ndynamism. However, it is unclear how to effectively apply these methods in the\ncontext of ML-enabled systems, where challenges require tailored approaches.\n[Goal] Our goal is to outline the state of the art in agile management for\nML-enabled systems. [Method] We conducted a systematic mapping study using a\nhybrid search strategy that combines database searches with backward and\nforward snowballing iterations. [Results] Our study identified 27 papers\npublished between 2008 and 2024. From these, we identified eight frameworks and\ncategorized recommendations and practices into eight key themes, such as\nIteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable\nModel. The main challenge identified across studies was accurate effort\nestimation for ML-related tasks. [Conclusion] This study contributes by mapping\nthe state of the art and identifying open gaps in the field. While relevant\nwork exists, more robust empirical evaluation is still needed to validate these\ncontributions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20851", "pdf": "https://arxiv.org/pdf/2506.20851", "abs": "https://arxiv.org/abs/2506.20851", "authors": ["Srikar Reddy Gadusu", "Larry Callahan", "Samir Lababidi", "Arunasri Nishtala", "Sophia Healey", "Hande McGinty"], "title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach", "categories": ["cs.SE", "cs.AI", "cs.DB"], "comment": null, "summary": "As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20869", "pdf": "https://arxiv.org/pdf/2506.20869", "abs": "https://arxiv.org/abs/2506.20869", "authors": ["Md Toufique Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Ayman Asad Khan", "Mika Saari", "Pekka Abrahamsson"], "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "categories": ["cs.SE", "cs.AI", "cs.IR", "D.2.11; I.2.6; H.3.3"], "comment": "Accepted as a full paper to the 51st Euromicro Conference on Software\n  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This\n  is the preprint version and not the final camera ready version", "summary": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e94\u4e2a\u57fa\u4e8e\u771f\u5b9e\u573a\u666f\u7684RAG\u7cfb\u7edf\u5e94\u7528\uff0c\u6db5\u76d6\u591a\u4e2a\u9886\u57df\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u8bc4\u4f30\u603b\u7ed3\u51fa\u5341\u4e8c\u4e2a\u5173\u952e\u7ecf\u9a8c\u6559\u8bad\u3002", "motivation": "\u5f25\u8865RAG\u7cfb\u7edf\u5728\u771f\u5b9e\u7528\u4f8b\u4e2d\u7f3a\u4e4f\u5b9e\u8bc1\u7814\u7a76\u7684\u4e0d\u8db3\uff0c\u63d0\u4f9b\u5b9e\u8df5\u7ecf\u9a8c\u548c\u6280\u672f\u6311\u6218\u7684\u6587\u6863\u5316\u603b\u7ed3\u3002", "method": "\u5f00\u53d1\u4e94\u4e2a\u9886\u57df\u7279\u5b9a\u7684RAG\u5e94\u7528\uff0c\u7ed3\u5408\u591a\u8bed\u8a00OCR\u3001\u8bed\u4e49\u68c0\u7d22\u548c\u9886\u57df\u9002\u5e94LLM\uff0c\u5e76\u901a\u8fc7100\u540d\u7528\u6237\u7684\u7f51\u7edc\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u5728\u6613\u7528\u6027\u3001\u76f8\u5173\u6027\u7b49\u516d\u4e2a\u7ef4\u5ea6\u8868\u73b0\u826f\u597d\uff0c\u540c\u65f6\u603b\u7ed3\u4e86\u5341\u4e8c\u4e2a\u5173\u952e\u7ecf\u9a8c\u6559\u8bad\u3002", "conclusion": "RAG\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u6280\u672f\u3001\u64cd\u4f5c\u548c\u4f26\u7406\u6311\u6218\uff0c\u4f46\u901a\u8fc7\u7cfb\u7edf\u5316\u5f00\u53d1\u548c\u8bc4\u4f30\u53ef\u4ee5\u63d0\u5347\u5176\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2506.20703", "pdf": "https://arxiv.org/pdf/2506.20703", "abs": "https://arxiv.org/abs/2506.20703", "authors": ["Vaibhav Vavilala", "Seemandhar Jain", "Rahul Vasanth", "D. A. Forsyth", "Anand Bhattad"], "title": "Generative Blocks World: Moving Things Around in Pictures", "categories": ["cs.GR", "cs.CV"], "comment": "23 pages, 16 figures, 2 tables", "summary": "We describe Generative Blocks World to interact with the scene of a generated\nimage by manipulating simple geometric abstractions. Our method represents\nscenes as assemblies of convex 3D primitives, and the same scene can be\nrepresented by different numbers of primitives, allowing an editor to move\neither whole structures or small details. Once the scene geometry has been\nedited, the image is generated by a flow-based method which is conditioned on\ndepth and a texture hint. Our texture hint takes into account the modified 3D\nprimitives, exceeding texture-consistency provided by existing key-value\ncaching techniques. These texture hints (a) allow accurate object and camera\nmoves and (b) largely preserve the identity of objects depicted. Quantitative\nand qualitative experiments demonstrate that our approach outperforms prior\nworks in visual fidelity, editability, and compositional generalization.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u56fe\u50cf\u7684\u573a\u666f\u4ea4\u4e92\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u62bd\u8c61\u64cd\u4f5c\u5b9e\u73b0\u9ad8\u6548\u7f16\u8f91\u3002", "motivation": "\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u65b9\u5f0f\u6765\u7f16\u8f91\u751f\u6210\u56fe\u50cf\u4e2d\u7684\u573a\u666f\uff0c\u540c\u65f6\u4fdd\u6301\u89c6\u89c9\u903c\u771f\u5ea6\u548c\u5bf9\u8c61\u4e00\u81f4\u6027\u3002", "method": "\u5c06\u573a\u666f\u8868\u793a\u4e3a3D\u51f8\u591a\u9762\u4f53\u7684\u7ec4\u88c5\u4f53\uff0c\u652f\u6301\u4e0d\u540c\u6570\u91cf\u7684\u57fa\u5143\u8868\u793a\uff1b\u901a\u8fc7\u6d41\u5f0f\u751f\u6210\u65b9\u6cd5\u57fa\u4e8e\u6df1\u5ea6\u548c\u7eb9\u7406\u63d0\u793a\u751f\u6210\u56fe\u50cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u903c\u771f\u5ea6\u3001\u53ef\u7f16\u8f91\u6027\u548c\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u51e0\u4f55\u62bd\u8c61\u548c\u7eb9\u7406\u63d0\u793a\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u903c\u771f\u7684\u573a\u666f\u7f16\u8f91\uff0c\u4e3a\u751f\u6210\u56fe\u50cf\u7684\u4ea4\u4e92\u64cd\u4f5c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.20944", "pdf": "https://arxiv.org/pdf/2506.20944", "abs": "https://arxiv.org/abs/2506.20944", "authors": ["Van-Hoang Phan", "Long-Khanh Pham", "Dang Vu", "Anh-Duy Tran", "Minh-Son Dao"], "title": "E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs", "categories": ["cs.MM", "cs.CR"], "comment": "Accepted to AsiaCCS 2025 @ SCID", "summary": "The rapid spread of misinformation in mobile and wireless networks presents\ncritical security challenges. This study introduces a training-free,\nretrieval-based multimodal fact verification system that leverages pretrained\nvision-language models and large language models for credibility assessment. By\ndynamically retrieving and cross-referencing trusted data sources, our approach\nmitigates vulnerabilities of traditional training-based models, such as\nadversarial attacks and data poisoning. Additionally, its lightweight design\nenables seamless edge device integration without extensive on-device\nprocessing. Experiments on two fact-checking benchmarks achieve SOTA results,\nconfirming its effectiveness in misinformation detection and its robustness\nagainst various attack vectors, highlighting its potential to enhance security\nin mobile and wireless communication environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u7684\u591a\u6a21\u6001\u4e8b\u5b9e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u9a8c\u8bc1\u4fe1\u606f\u771f\u5b9e\u6027\uff0c\u6709\u6548\u5e94\u5bf9\u79fb\u52a8\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u548c\u65e0\u7ebf\u7f51\u7edc\u4e2d\u865a\u5047\u4fe1\u606f\u5feb\u901f\u4f20\u64ad\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\u3002", "method": "\u5f15\u5165\u65e0\u9700\u8bad\u7ec3\u7684\u68c0\u7d22\u5f0f\u591a\u6a21\u6001\u4e8b\u5b9e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u52a8\u6001\u68c0\u7d22\u5e76\u4ea4\u53c9\u53c2\u8003\u53ef\u4fe1\u6570\u636e\u6e90\u3002", "result": "\u5728\u4e24\u4e2a\u4e8b\u5b9e\u6838\u67e5\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u548c\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u79fb\u52a8\u548c\u65e0\u7ebf\u901a\u4fe1\u73af\u5883\u4e2d\u5177\u6709\u6f5c\u5728\u7684\u5b89\u5168\u589e\u5f3a\u80fd\u529b\uff0c\u4e14\u56e0\u5176\u8f7b\u91cf\u5316\u8bbe\u8ba1\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u3002"}}
{"id": "2506.20674", "pdf": "https://arxiv.org/pdf/2506.20674", "abs": "https://arxiv.org/abs/2506.20674", "authors": ["Ankur Lahiry", "Ayush Pokharel", "Seth Ockerman", "Amal Gueroudji", "Line Pouchard", "Tanzima Z. Islam"], "title": "Scalable GPU Performance Variability Analysis framework", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "Analyzing large-scale performance logs from GPU profilers often requires\nterabytes of memory and hours of runtime, even for basic summaries. These\nconstraints prevent timely insight and hinder the integration of performance\nanalytics into automated workflows. Existing analysis tools typically process\ndata sequentially, making them ill-suited for HPC workflows with growing trace\ncomplexity and volume. We introduce a distributed data analysis framework that\nscales with dataset size and compute availability. Rather than treating the\ndataset as a single entity, our system partitions it into independently\nanalyzable shards and processes them concurrently across MPI ranks. This design\nreduces per-node memory pressure, avoids central bottlenecks, and enables\nlow-latency exploration of high-dimensional trace data. We apply the framework\nto end-to-end Nsight Compute traces from real HPC and AI workloads, demonstrate\nits ability to diagnose performance variability, and uncover the impact of\nmemory transfer latency on GPU kernel behavior.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u5206\u5e03\u5f0f\u6570\u636e\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21GPU\u6027\u80fd\u65e5\u5fd7\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u7684\u5185\u5b58\u548c\u8fd0\u884c\u65f6\u95f4\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5904\u7406GPU\u6027\u80fd\u65e5\u5fd7\u65f6\u5185\u5b58\u9700\u6c42\u9ad8\u3001\u8fd0\u884c\u65f6\u95f4\u957f\uff0c\u65e0\u6cd5\u6ee1\u8db3HPC\u5de5\u4f5c\u6d41\u7684\u9700\u6c42\u3002", "method": "\u5f15\u5165\u5206\u5e03\u5f0f\u6846\u67b6\uff0c\u5c06\u6570\u636e\u96c6\u5206\u533a\u5e76\u5e76\u884c\u5904\u7406\uff0c\u964d\u4f4e\u5355\u8282\u70b9\u5185\u5b58\u538b\u529b\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8e\u5b9e\u9645HPC\u548cAI\u5de5\u4f5c\u8d1f\u8f7d\u7684Nsight Compute\u8ddf\u8e2a\u6570\u636e\uff0c\u8bca\u65ad\u4e86\u6027\u80fd\u53d8\u5f02\u6027\u5e76\u63ed\u793a\u4e86\u5185\u5b58\u4f20\u8f93\u5ef6\u8fdf\u5bf9GPU\u5185\u6838\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u65e5\u5fd7\u5206\u6790\u7684\u6548\u7387\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u63a2\u7d22\u9ad8\u7ef4\u8ddf\u8e2a\u6570\u636e\u3002"}}
{"id": "2506.21149", "pdf": "https://arxiv.org/pdf/2506.21149", "abs": "https://arxiv.org/abs/2506.21149", "authors": ["Lisa-Marie Jaser", "Jacobo Toran"], "title": "Pebble Games and Algebraic Proof Systems", "categories": ["cs.LO"], "comment": null, "summary": "Analyzing refutations of the well known 0pebbling formulas Peb$(G)$ we prove\nsome new strong connections between pebble games and algebraic proof system,\nshowing that there is a parallelism between the reversible, black and\nblack-white pebbling games on one side, and the three algebraic proof systems\nNullstellensatz, Monomial Calculus and Polynomial Calculus on the other side.\nIn particular we prove that for any DAG $G$ with a single sink, if there is a\nMonomial Calculus refutation for Peb$(G)$ having simultaneously degree $s$ and\nsize $t$ then there is a black pebbling strategy on $G$ with space $s$ and time\n$t+s$. Also if there is a black pebbling strategy for $G$ with space $s$ and\ntime $t$ it is possible to extract from it a MC refutation for Peb$(G)$ having\nsimultaneously degree $s$ and size $ts$. These results are analogous to those\nproven in {deRezende et al.21} for the case of reversible pebbling and\nNullstellensatz. Using them we prove degree separations between NS, MC and PC,\nas well as strong degree-size tradeoffs for MC.\n  We also notice that for any directed acyclic graph $G$ the space needed in a\npebbling strategy on $G$, for the three versions of the game, reversible, black\nand black-white, exactly matches the variable space complexity of a refutation\nof the corresponding pebbling formula Peb$(G)$ in each of the algebraic proof\nsystems NS, MC and PC. Using known pebbling bounds on graphs, this connection\nimplies separations between the corresponding variable space measures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86pebble games\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\uff0c\u8bc1\u660e\u4e86\u53ef\u9006\u3001\u9ed1\u548c\u767d-\u9ed1pebble\u6e38\u620f\u4e0e\u4e09\u4e2a\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\uff08Nullstellensatz\u3001Monomial Calculus\u548cPolynomial Calculus\uff09\u4e4b\u95f4\u7684\u5e76\u884c\u6027\u3002", "motivation": "\u63a2\u7d22pebble games\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\uff0c\u4ee5\u63ed\u793a\u4e8c\u8005\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0a\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5206\u6790pebble\u6e38\u620f\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\uff0c\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u7684\u5ea6\u6570\u548c\u89c4\u6a21\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5efa\u7acb\u6570\u5b66\u6a21\u578b\u548c\u8bc1\u660e\u7b56\u7565\u3002", "result": "\u8bc1\u660e\u4e86pebble\u6e38\u620f\u7a7a\u95f4\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u53d8\u91cf\u7a7a\u95f4\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u7cbe\u786e\u5339\u914d\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u7cfb\u7edf\u4e4b\u95f4\u7684\u5206\u79bb\u548c\u6743\u8861\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e0d\u4ec5\u6df1\u5316\u4e86\u5bf9pebble games\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u5173\u7cfb\u7684\u7406\u89e3\uff0c\u8fd8\u4e3a\u590d\u6742\u5ea6\u5206\u79bb\u548c\u6743\u8861\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc1\u636e\u3002"}}
{"id": "2506.20748", "pdf": "https://arxiv.org/pdf/2506.20748", "abs": "https://arxiv.org/abs/2506.20748", "authors": ["Jingshu Li", "Zicheng Zhu", "Renwen Zhang", "Yi-Chieh Lee"], "title": "Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Chatbots are increasingly integrated into people's lives and are widely used\nto help people. Recently, there has also been growing interest in the reverse\ndirection-humans help chatbots-due to a wide range of benefits including better\nchatbot performance, human well-being, and collaborative outcomes. However,\nlittle research has explored the factors that motivate people to help chatbots.\nTo address this gap, we draw on the Computers Are Social Actors (CASA)\nframework to examine how chatbot anthropomorphism-including human-like\nidentity, emotional expression, and non-verbal expression-influences human\nempathy toward chatbots and their subsequent prosocial behaviors and\nintentions. We also explore people's own interpretations of their prosocial\nbehaviors toward chatbots. We conducted an online experiment (N = 244) in which\nchatbots made mistakes in a collaborative image labeling task and explained the\nreasons to participants. We then measured participants' prosocial behaviors and\nintentions toward the chatbots. Our findings revealed that human identity and\nemotional expression of chatbots increased participants' prosocial behavior and\nintention toward chatbots, with empathy mediating these effects. Qualitative\nanalysis further identified two motivations for participants' prosocial\nbehaviors: empathy for the chatbot and perceiving the chatbot as human-like. We\ndiscuss the implications of these results for understanding and promoting human\nprosocial behaviors toward chatbots.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20762", "pdf": "https://arxiv.org/pdf/2506.20762", "abs": "https://arxiv.org/abs/2506.20762", "authors": ["Shisheng Hu", "Jie Gao", "Xue Qin", "Conghao Zhou", "Xinyu Huang", "Mushu Li", "Mingcheng He", "Xuemin Shen"], "title": "Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks", "categories": ["cs.NI", "eess.SP"], "comment": "Accepted by IEEE Transactions on Cognitive Communications and\n  Networking", "summary": "In this paper, we propose a novel drift-adaptive slicing-based resource\nmanagement scheme for cooperative integrated sensing and communication (ISAC)\nnetworks. Particularly, we establish two network slices to provide sensing and\ncommunication services, respectively. In the large-timescale planning for the\nslices, we partition the sensing region of interest (RoI) of each mobile device\nand reserve network resources accordingly, facilitating low-complexity\ndistance-based sensing target assignment in small timescales. To cope with the\nnon-stationary spatial distributions of mobile devices and sensing targets,\nwhich can result in the drift in modeling the distributions and ineffective\nplanning decisions, we construct digital twins (DTs) of the slices. In each DT,\na drift-adaptive statistical model and an emulation function are developed for\nthe spatial distributions in the corresponding slice, which facilitates\nclosed-form decision-making and efficient validation of a planning decision,\nrespectively. Numerical results show that the proposed drift-adaptive\nslicing-based resource management scheme can increase the service satisfaction\nratio by up to 18% and reduce resource consumption by up to 13.1% when compared\nwith benchmark schemes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u534f\u4f5c\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7f51\u7edc\u7684\u6f02\u79fb\u81ea\u9002\u5e94\u5207\u7247\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u8bbe\u5907\u548c\u611f\u77e5\u76ee\u6807\u7a7a\u95f4\u5206\u5e03\u975e\u5e73\u7a33\u6027\u5bfc\u81f4\u7684\u8d44\u6e90\u5206\u914d\u6f02\u79fb\u95ee\u9898\u3002", "method": "\u5efa\u7acb\u4e24\u4e2a\u7f51\u7edc\u5207\u7247\u5206\u522b\u63d0\u4f9b\u611f\u77e5\u548c\u901a\u4fe1\u670d\u52a1\uff0c\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u5f00\u53d1\u6f02\u79fb\u81ea\u9002\u5e94\u7edf\u8ba1\u6a21\u578b\u548c\u4eff\u771f\u529f\u80fd\u3002", "result": "\u670d\u52a1\u6ee1\u610f\u5ea6\u63d0\u534718%\uff0c\u8d44\u6e90\u6d88\u8017\u964d\u4f4e13.1%\u3002", "conclusion": "\u6f02\u79fb\u81ea\u9002\u5e94\u5207\u7247\u65b9\u6848\u663e\u8457\u4f18\u5316\u4e86\u7f51\u7edc\u8d44\u6e90\u7ba1\u7406\u6548\u7387\u3002"}}
{"id": "2506.21203", "pdf": "https://arxiv.org/pdf/2506.21203", "abs": "https://arxiv.org/abs/2506.21203", "authors": ["Jey Puget Gil", "Emmanuel Coquery", "John Samuel", "Gilles Gesquiere"], "title": "Condensed Representation of RDF and its Application on Graph Versioning", "categories": ["cs.DB"], "comment": "20 pages, 3 figures", "summary": "The study of the evolving phenomena in a domain helps to understand the\nrelationships between entities at different points in time and predict future\ntrends. These phenomena, often complex, can be represented using knowledge\ngraphs, which have the capability to model heterogeneous data from multiple\nsources. Nowadays, a considerable amount of sources delivering periodic updates\nto knowledge graphs in various domains is openly available. The evolution of\ndata is of interest to knowledge graph management systems, and therefore it is\ncrucial to organize these constantly evolving data to make them easily\naccessible and exploitable for analyzes. In this article, we will present and\nformalize the condensed representation of these evolving graphs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u6f14\u5316\u77e5\u8bc6\u56fe\u7684\u7d27\u51d1\u8868\u793a\u5f62\u5f0f\uff0c\u4ee5\u5e2e\u52a9\u7ba1\u7406\u548c\u5206\u6790\u968f\u65f6\u95f4\u53d8\u5316\u7684\u590d\u6742\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e3a\u4e86\u7406\u89e3\u4e0d\u540c\u65f6\u95f4\u70b9\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u5e76\u9884\u6d4b\u672a\u6765\u8d8b\u52bf\uff0c\u540c\u65f6\u89e3\u51b3\u77e5\u8bc6\u56fe\u7ba1\u7406\u4e2d\u6570\u636e\u6f14\u5316\u7684\u7ec4\u7ec7\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u5e76\u5f62\u5f0f\u5316\u6f14\u5316\u56fe\u7684\u7d27\u51d1\u8868\u793a\u65b9\u6cd5\uff0c\u5229\u7528\u6765\u81ea\u591a\u6e90\u7684\u5f02\u6784\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4f7f\u4e0d\u65ad\u6f14\u5316\u7684\u6570\u636e\u66f4\u6613\u4e8e\u8bbf\u95ee\u548c\u5206\u6790\u3002", "conclusion": "\u7ed3\u8bba\u662f\u7d27\u51d1\u8868\u793a\u5f62\u5f0f\u5bf9\u4e8e\u77e5\u8bc6\u56fe\u7ba1\u7406\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u6709\u6548\u7ec4\u7ec7\u548c\u5229\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.20673", "pdf": "https://arxiv.org/pdf/2506.20673", "abs": "https://arxiv.org/abs/2506.20673", "authors": ["Yongqian Sun", "Xijie Pan", "Xiao Xiong", "Lei Tao", "Jiaju Wang", "Shenglin Zhang", "Yuan Yuan", "Yuqi Li", "Kunlin Jian"], "title": "ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Network failure diagnosis is challenging yet critical for high-performance\ncomputing (HPC) systems. Existing methods cannot be directly applied to HPC\nscenarios due to data heterogeneity and lack of accuracy. This paper proposes a\nnovel framework, called ClusterRCA, to localize culprit nodes and determine\nfailure types by leveraging multimodal data. ClusterRCA extracts features from\ntopologically connected network interface controller (NIC) pairs to analyze the\ndiverse, multimodal data in HPC systems. To accurately localize culprit nodes\nand determine failure types, ClusterRCA combines classifier-based and\ngraph-based approaches. A failure graph is constructed based on the output of\nthe state classifier, and then it performs a customized random walk on the\ngraph to localize the root cause. Experiments on datasets collected by a\ntop-tier global HPC device vendor show ClusterRCA achieves high accuracy in\ndiagnosing network failure for HPC systems. ClusterRCA also maintains robust\nperformance across different application scenarios.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21073", "pdf": "https://arxiv.org/pdf/2506.21073", "abs": "https://arxiv.org/abs/2506.21073", "authors": ["Ilias Papalamprou", "Nikolaos Fotos", "Nikolaos Chatzivasileiadis", "Anna Angelogianni", "Dimosthenis Masouros", "Dimitrios Soudris"], "title": "Post-Quantum and Blockchain-Based Attestation for Trusted FPGAs in B5G Networks", "categories": ["cs.AR"], "comment": null, "summary": "The advent of 5G and beyond has brought increased performance networks,\nfacilitating the deployment of services closer to the user. To meet performance\nrequirements such services require specialized hardware, such as Field\nProgrammable Gate Arrays (FPGAs). However, FPGAs are often deployed in\nunprotected environments, leaving the user's applications vulnerable to\nmultiple attacks. With the rise of quantum computing, which threatens the\nintegrity of widely-used cryptographic algorithms, the need for a robust\nsecurity infrastructure is even more crucial. In this paper we introduce a\nhybrid hardware-software solution utilizing remote attestation to securely\nconfigure FPGAs, while integrating Post-Quantum Cryptographic (PQC) algorithms\nfor enhanced security. Additionally, to enable trustworthiness across the whole\nedge computing continuum, our solution integrates a blockchain infrastructure,\nensuring the secure storage of any security evidence. We evaluate the proposed\nsecure configuration process under different PQC algorithms in two FPGA\nfamilies, showcasing only 2% overheard compared to the non PQC approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u786c\u4ef6\u548c\u8f6f\u4ef6\u7684\u6df7\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8fdc\u7a0b\u8ba4\u8bc1\u548c\u91cf\u5b50\u540e\u52a0\u5bc6\u7b97\u6cd5\uff08PQC\uff09\u589e\u5f3aFPGA\u7684\u5b89\u5168\u6027\uff0c\u5e76\u5229\u7528\u533a\u5757\u94fe\u6280\u672f\u786e\u4fdd\u5b89\u5168\u8bc1\u636e\u7684\u5b58\u50a8\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4ec5\u5e26\u67652%\u7684\u6027\u80fd\u5f00\u9500\u3002", "motivation": "\u968f\u77405G\u53ca\u66f4\u9ad8\u6027\u80fd\u7f51\u7edc\u7684\u666e\u53ca\uff0c\u670d\u52a1\u90e8\u7f72\u66f4\u63a5\u8fd1\u7528\u6237\uff0c\u4f46FPGA\u5e38\u5904\u4e8e\u672a\u53d7\u4fdd\u62a4\u7684\u73af\u5883\uff0c\u4e14\u91cf\u5b50\u8ba1\u7b97\u7684\u5174\u8d77\u5a01\u80c1\u4f20\u7edf\u52a0\u5bc6\u7b97\u6cd5\u7684\u5b89\u5168\u6027\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u91c7\u7528\u8fdc\u7a0b\u8ba4\u8bc1\u548c\u91cf\u5b50\u540e\u52a0\u5bc6\u7b97\u6cd5\uff08PQC\uff09\u914d\u7f6eFPGA\uff0c\u5e76\u7ed3\u5408\u533a\u5757\u94fe\u5b58\u50a8\u5b89\u5168\u8bc1\u636e\u3002", "result": "\u5728\u4e24\u79cdFPGA\u5bb6\u65cf\u4e2d\u8bc4\u4f30\u8be5\u65b9\u6cd5\uff0c\u76f8\u6bd4\u975ePQC\u65b9\u6848\u4ec5\u5e26\u67652%\u7684\u6027\u80fd\u5f00\u9500\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6848\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u6027\u80fd\u5f00\u9500\u6781\u4f4e\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u3002"}}
{"id": "2506.20782", "pdf": "https://arxiv.org/pdf/2506.20782", "abs": "https://arxiv.org/abs/2506.20782", "authors": ["Marc Bara"], "title": "Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing", "categories": ["cs.NE", "cs.ET", "cs.LG", "eess.SP", "68T07, 94A08", "I.2.6; G.1.6; B.7.1"], "comment": "8 pages, 2 figures, patent pending", "summary": "We present the first theoretical framework for applying spiking neural\nnetworks (SNNs) to synthetic aperture radar (SAR) interferometric phase\nunwrapping. Despite extensive research in both domains, our comprehensive\nliterature review confirms that SNNs have never been applied to phase\nunwrapping, representing a significant gap in current methodologies. As Earth\nobservation data volumes continue to grow exponentially (with missions like\nNISAR expected to generate 100PB in two years) energy-efficient processing\nbecomes critical for sustainable data center operations. SNNs, with their\nevent-driven computation model, offer potential energy savings of 30-100x\ncompared to conventional approaches while maintaining comparable accuracy. We\ndevelop spike encoding schemes specifically designed for wrapped phase data,\npropose SNN architectures that leverage the spatial propagation nature of phase\nunwrapping, and provide theoretical analysis of computational complexity and\nconvergence properties. Our framework demonstrates how the temporal dynamics\ninherent in SNNs can naturally model the spatial continuity constraints\nfundamental to phase unwrapping. This work opens a new research direction at\nthe intersection of neuromorphic computing and SAR interferometry, offering a\ncomplementary approach to existing algorithms that could enable more\nsustainable large-scale InSAR processing.", "AI": {"tldr": "\u9996\u4e2a\u7406\u8bba\u6846\u67b6\u5c06SNN\u5e94\u7528\u4e8eSAR\u5e72\u6d89\u76f8\u4f4d\u89e3\u7f20\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7a7a\u767d\u3002", "motivation": "\u5730\u7403\u89c2\u6d4b\u6570\u636e\u6fc0\u589e\uff08\u5982NISAR\u4efb\u52a1\u5c06\u751f\u6210100PB\u6570\u636e\uff09\uff0c\u9ad8\u6548\u8282\u80fd\u5904\u7406\u6210\u5173\u952e\u3002SNN\u6709\u671b\u8282\u770130-100\u500d\u80fd\u8017\u3002", "method": "\u5f00\u53d1\u4e86\u9488\u5bf9\u76f8\u4f4d\u6570\u636e\u7684\u8109\u51b2\u7f16\u7801\u65b9\u6848\uff0c\u63d0\u51fa\u5229\u7528\u76f8\u4f4d\u89e3\u7f20\u7a7a\u95f4\u4f20\u64ad\u7279\u6027\u7684SNN\u67b6\u6784\uff0c\u5206\u6790\u8ba1\u7b97\u590d\u6742\u6027\u548c\u6536\u655b\u6027\u3002", "result": "\u6846\u67b6\u663e\u793aSNN\u7684\u65f6\u95f4\u52a8\u6001\u53ef\u81ea\u7136\u5efa\u6a21\u76f8\u4f4d\u89e3\u7f20\u7684\u7a7a\u95f4\u8fde\u7eed\u6027\u7ea6\u675f\u3002", "conclusion": "\u5f00\u521b\u4e86\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e0eSAR\u5e72\u6d89\u6d4b\u91cf\u4ea4\u53c9\u65b0\u65b9\u5411\uff0c\u63d0\u4f9b\u66f4\u53ef\u6301\u7eed\u7684\u5927\u89c4\u6a21InSAR\u5904\u7406\u65b9\u6848\u3002"}}
{"id": "2506.20883", "pdf": "https://arxiv.org/pdf/2506.20883", "abs": "https://arxiv.org/abs/2506.20883", "authors": ["Kyanna Dagenais", "Istvan David"], "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "Accepted for ACM/IEEE MODELS'25", "summary": "Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20875", "pdf": "https://arxiv.org/pdf/2506.20875", "abs": "https://arxiv.org/abs/2506.20875", "authors": ["Chengan He", "Junxuan Li", "Tobias Kirschstein", "Artem Sevastopolsky", "Shunsuke Saito", "Qingyang Tan", "Javier Romero", "Chen Cao", "Holly Rushmeier", "Giljoo Nam"], "title": "3DGH: 3D Head Generation with Composable Hair and Face", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to SIGGRAPH 2025. Project page:\n  https://c-he.github.io/projects/3dgh/", "summary": "We present 3DGH, an unconditional generative model for 3D human heads with\ncomposable hair and face components. Unlike previous work that entangles the\nmodeling of hair and face, we propose to separate them using a novel data\nrepresentation with template-based 3D Gaussian Splatting, in which deformable\nhair geometry is introduced to capture the geometric variations across\ndifferent hairstyles. Based on this data representation, we design a 3D\nGAN-based architecture with dual generators and employ a cross-attention\nmechanism to model the inherent correlation between hair and face. The model is\ntrained on synthetic renderings using carefully designed objectives to\nstabilize training and facilitate hair-face separation. We conduct extensive\nexperiments to validate the design choice of 3DGH, and evaluate it both\nqualitatively and quantitatively by comparing with several state-of-the-art 3D\nGAN methods, demonstrating its effectiveness in unconditional full-head image\nsynthesis and composable 3D hairstyle editing. More details will be available\non our project page: https://c-he.github.io/projects/3dgh/.", "AI": {"tldr": "3DGH\u662f\u4e00\u4e2a\u65e0\u6761\u4ef6\u751f\u62103D\u4eba\u5934\u6a21\u578b\u7684\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u5206\u79bb\u5934\u53d1\u548c\u9762\u90e8\u7684\u5efa\u6a21\uff0c\u901a\u8fc7\u65b0\u7684\u6570\u636e\u8868\u793a\u548c\u53cc\u751f\u6210\u5668\u67b6\u6784\u5b9e\u73b0\u9ad8\u6548\u7684\u5408\u6210\u4e0e\u7f16\u8f91\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5934\u53d1\u548c\u9762\u90e8\u7684\u5efa\u6a21\u901a\u5e38\u662f\u8026\u5408\u7684\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u8868\u73b0\u529b\u548c\u7f16\u8f91\u7075\u6d3b\u6027\u30023DGH\u901a\u8fc7\u5206\u79bb\u5934\u53d1\u548c\u9762\u90e8\u7684\u5efa\u6a21\uff0c\u65e8\u5728\u63d0\u9ad8\u751f\u6210\u7684\u591a\u6837\u6027\u548c\u53ef\u7f16\u8f91\u6027\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6a21\u677f\u76843D\u9ad8\u65af\u6563\u5c04\u8868\u793a\u5934\u53d1\u548c\u9762\u90e8\u51e0\u4f55\u5f62\u72b6\uff0c\u5f15\u5165\u53ef\u53d8\u5f62\u7684\u5934\u53d1\u51e0\u4f55\u5f62\u72b6\u6355\u6349\u4e0d\u540c\u53d1\u578b\u7684\u53d8\u5316\u3002\u91c7\u7528\u57fa\u4e8e3D GAN\u7684\u53cc\u751f\u6210\u5668\u67b6\u6784\uff0c\u5e76\u7ed3\u5408\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5efa\u6a21\u5934\u53d1\u548c\u9762\u90e8\u7684\u76f8\u5173\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e3DGH\u5728\u65e0\u6761\u4ef6\u5b8c\u6574\u5934\u90e8\u56fe\u50cf\u5408\u6210\u548c\u53ef\u7ec4\u5408\u76843D\u53d1\u578b\u7f16\u8f91\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "3DGH\u901a\u8fc7\u5206\u79bb\u5934\u53d1\u548c\u9762\u90e8\u7684\u5efa\u6a21\uff0c\u5c55\u793a\u4e86\u5728\u751f\u6210\u548c\u7f16\u8f91\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a3D\u5934\u90e8\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2504.15217", "pdf": "https://arxiv.org/pdf/2504.15217", "abs": "https://arxiv.org/abs/2504.15217", "authors": ["Yatong Bai", "Jonah Casebeer", "Somayeh Sojoudi", "Nicholas J. Bryan"], "title": "DRAGON: Distributional Rewards Optimize Diffusion Generative Models", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM"], "comment": null, "summary": "We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.", "AI": {"tldr": "DRAGON\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5fae\u8c03\u5a92\u4f53\u751f\u6210\u6a21\u578b\uff0c\u652f\u6301\u591a\u6837\u5316\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5982RLHF\u6216DPO\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u9002\u5e94\u5404\u79cd\u5956\u52b1\u51fd\u6570\u3002DRAGON\u65e8\u5728\u63d0\u4f9b\u66f4\u901a\u7528\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u9009\u62e9\u7f16\u7801\u5668\u548c\u53c2\u8003\u6837\u4f8b\u6784\u5efa\u5956\u52b1\u51fd\u6570\uff0c\u5229\u7528\u5bf9\u6bd4\u96c6\u6700\u5927\u5316\u5956\u52b1\uff0c\u652f\u6301\u8de8\u6a21\u6001\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDRAGON\u572820\u79cd\u4e0d\u540c\u5956\u52b1\u51fd\u6570\u4e0a\u5e73\u5747\u83b7\u80dc\u7387\u4e3a81.45%\uff0c\u4e14\u80fd\u63d0\u5347\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "DRAGON\u4e3a\u8bbe\u8ba1\u548c\u4f18\u5316\u5956\u52b1\u51fd\u6570\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u7c7b\u611f\u77e5\u8d28\u91cf\u3002"}}
{"id": "2506.20677", "pdf": "https://arxiv.org/pdf/2506.20677", "abs": "https://arxiv.org/abs/2506.20677", "authors": ["Shrinivass Arunachalam Balasubramanian"], "title": "Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting Across Diverse Data Distributions", "categories": ["cs.DS", "cs.DB", "cs.PF"], "comment": "11 Pages, 5 figures", "summary": "Sorting is an essential operation in computer science with direct\nconsequences on the performance of large scale data systems, real-time systems,\nand embedded computation. However, no sorting algorithm is optimal under all\ndistributions of data. The new adaptive hybrid sorting paradigm proposed in\nthis paper is the paradigm that automatically selects the most effective\nsorting algorithm Counting Sort, Radix Sort, or QuickSort based on real-time\nmonitoring of patterns in input data. The architecture begins by having a\nfeature extraction module to compute significant parameters such as data\nvolume, value range and entropy. These parameters are sent to a decision engine\ninvolving Finite State Machine and XGBoost classifier to aid smart and\neffective in choosing the optimal sorting strategy. It implements Counting Sort\non small key ranges, Radix Sort on large range structured input with\nlow-entropy keys and QuickSort on general purpose sorting. The experimental\nfindings of both synthetic and real life dataset confirm that the proposed\nsolution is actually inclined to excel significantly by comparison in execution\ntime, flexibility and the efficiency of conventional static sorting algorithms.\nThe proposed framework provides a scalable, high perhaps and applicable to a\nwide range of data processing operations like big data analytics, edge\ncomputing, and systems with hardware limitations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u6df7\u5408\u6392\u5e8f\u8303\u5f0f\uff0c\u901a\u8fc7\u5b9e\u65f6\u76d1\u63a7\u8f93\u5165\u6570\u636e\u6a21\u5f0f\u81ea\u52a8\u9009\u62e9\u6700\u9ad8\u6548\u7684\u6392\u5e8f\u7b97\u6cd5\uff08\u8ba1\u6570\u6392\u5e8f\u3001\u57fa\u6570\u6392\u5e8f\u6216\u5feb\u901f\u6392\u5e8f\uff09\u3002", "motivation": "\u7531\u4e8e\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0b\u6392\u5e8f\u7b97\u6cd5\u8868\u73b0\u4e0d\u540c\uff0c\u4f20\u7edf\u9759\u6001\u6392\u5e8f\u7b97\u6cd5\u96be\u4ee5\u5728\u6240\u6709\u573a\u666f\u4e0b\u4fdd\u6301\u6700\u4f18\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u8ba1\u7b97\u6570\u636e\u91cf\u3001\u503c\u8303\u56f4\u548c\u71b5\u7b49\u53c2\u6570\uff0c\u5229\u7528\u6709\u9650\u72b6\u6001\u673a\u548cXGBoost\u5206\u7c7b\u5668\u9009\u62e9\u6700\u4f18\u6392\u5e8f\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6267\u884c\u65f6\u95f4\u3001\u7075\u6d3b\u6027\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u9759\u6001\u6392\u5e8f\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u5927\u6570\u636e\u5206\u6790\u3001\u8fb9\u7f18\u8ba1\u7b97\u7b49\u5e7f\u6cdb\u6570\u636e\u5904\u7406\u573a\u666f\uff0c\u5177\u6709\u9ad8\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.21481", "pdf": "https://arxiv.org/pdf/2506.21481", "abs": "https://arxiv.org/abs/2506.21481", "authors": ["Eike Neumann"], "title": "Deciding Robust Instances of an Escape Problem for Dynamical Systems in Euclidean Space", "categories": ["cs.LO"], "comment": null, "summary": "We study the problem of deciding whether a point escapes a closed subset of\n$\\mathbb{R}^d$ under the iteration of a continuous map $f \\colon \\mathbb{R}^d\n\\to \\mathbb{R}^d$ in the bit-model of real computation. We give a sound partial\ndecision method for this problem which is complete in the sense that its\nhalting set contains the halting set of all sound partial decision methods for\nthe problem. Equivalently, our decision method terminates on all problem\ninstances whose answer is robust under all sufficiently small perturbations of\nthe function. We further show that the halting set of our algorithm is dense in\nthe set of all problem instances. While our algorithm applies to general\ncontinuous functions, we demonstrate that it also yields complete decision\nmethods for much more rigid function families: affine linear systems and\nquadratic complex polynomials. In the latter case, completeness is subject to\nthe density of hyperbolicity conjecture in complex dynamics. This in particular\nyields an alternative proof of Hertling's (2004) conditional answer to a\nquestion raised by Penrose (1989) regarding the computability of the Mandelbrot\nset.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20884", "pdf": "https://arxiv.org/pdf/2506.20884", "abs": "https://arxiv.org/abs/2506.20884", "authors": ["Meira Gilbert", "Miranda Wei", "Lindah Kotut"], "title": "\"TikTok, Do Your Thing\": User Reactions to Social Surveillance in the Public Sphere", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "''TikTok, Do Your Thing'' is a viral trend where users attempt to identify\nstrangers they see in public via information crowd-sourcing. The trend started\nas early as 2021 and users typically engage with it for romantic purposes\n(similar to a ''Missed Connections'' personal advertisement). This practice\nincludes acts of surveillance and identification in the public sphere, although\nby peers rather than governments or corporations. To understand users'\nreactions to this trend we conducted a qualitative analysis of 60 TikTok videos\nand 1,901 user comments. Of the 60 videos reviewed, we find 19 individuals were\nsuccessfully identified. We also find that while there were comments expressing\ndisapproval (n=310), more than double the number expressed support (n=883).\nSupportive comments demonstrated genuine interest and empathy, reflecting\nevolving conceptions of community and algorithmic engagement. On the other\nhand, disapproving comments highlighted concerns about inappropriate\nrelationships, stalking, consent, and gendered double standards. We discuss\nthese insights in relation to the normalization of interpersonal surveillance,\nonline stalking, and as an evolution of social surveillance to offer a new\nperspective on user perceptions surrounding interpersonal surveillance and\nidentification in the public sphere.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86TikTok\u4e0a\u2018TikTok, Do Your Thing\u2019\u8fd9\u4e00\u8d8b\u52bf\uff0c\u7528\u6237\u901a\u8fc7\u4f17\u5305\u4fe1\u606f\u8bc6\u522b\u964c\u751f\u4eba\uff0c\u4e3b\u8981\u7528\u4e8e\u6d6a\u6f2b\u76ee\u7684\u3002\u7814\u7a76\u53d1\u73b019\u4eba\u6210\u529f\u88ab\u8bc6\u522b\uff0c\u652f\u6301\u8bc4\u8bba\uff08883\u6761\uff09\u8fdc\u8d85\u53cd\u5bf9\uff08310\u6761\uff09\uff0c\u63a2\u8ba8\u4e86\u4eba\u9645\u76d1\u63a7\u7684\u5e38\u6001\u5316\u53ca\u5176\u793e\u4f1a\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8\u7528\u6237\u5728\u516c\u5171\u573a\u5408\u901a\u8fc7TikTok\u8fdb\u884c\u964c\u751f\u4eba\u8bc6\u522b\u6d3b\u52a8\u7684\u53cd\u5e94\u548c\u6001\u5ea6\uff0c\u5206\u6790\u8fd9\u79cd\u4eba\u9645\u76d1\u63a7\u8d8b\u52bf\u7684\u793e\u4f1a\u5f71\u54cd\u3002", "method": "\u5bf960\u4e2aTikTok\u89c6\u9891\u548c1901\u6761\u7528\u6237\u8bc4\u8bba\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u3002", "result": "19\u4eba\u88ab\u6210\u529f\u8bc6\u522b\uff1b\u652f\u6301\u8bc4\u8bba\u591a\u4e8e\u53cd\u5bf9\uff0c\u53cd\u6620\u4e86\u7528\u6237\u5bf9\u793e\u533a\u548c\u7b97\u6cd5\u53c2\u4e0e\u7684\u8ba4\u53ef\uff0c\u53cd\u5bf9\u610f\u89c1\u5219\u6d89\u53ca\u9690\u79c1\u548c\u6027\u522b\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4eba\u9645\u76d1\u63a7\u7684\u5e38\u6001\u5316\u8d8b\u52bf\uff0c\u4e3a\u7406\u89e3\u7528\u6237\u5bf9\u516c\u5171\u573a\u5408\u8bc6\u522b\u884c\u4e3a\u7684\u611f\u77e5\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.21406", "pdf": "https://arxiv.org/pdf/2506.21406", "abs": "https://arxiv.org/abs/2506.21406", "authors": ["Tommaso Bonato", "Daniele De Sensi", "Salvatore Di Girolamo", "Abdulla Bataineh", "David Hewson", "Duncan Roweth", "Torsten Hoefler"], "title": "Flowcut Switching: High-Performance Adaptive Routing with In-Order Delivery Guarantees", "categories": ["cs.NI"], "comment": null, "summary": "Network latency severely impacts the performance of applications running on\nsupercomputers. Adaptive routing algorithms route packets over different\navailable paths to reduce latency and improve network utilization. However, if\na switch routes packets belonging to the same network flow on different paths,\nthey might arrive at the destination out-of-order due to differences in the\nlatency of these paths. For some transport protocols like TCP, QUIC, and RoCE,\nout-of-order (OOO) packets might cause large performance drops or significantly\nincrease CPU utilization. In this work, we propose flowcut switching, a new\nadaptive routing algorithm that provides high-performance in-order packet\ndelivery. Differently from existing solutions like flowlet switching, which are\nbased on the assumption of bursty traffic and that might still reorder packets,\nflowcut switching guarantees in-order delivery under any network conditions,\nand is effective also for non-bursty traffic, as it is often the case for RDMA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5flowcut switching\uff0c\u786e\u4fdd\u7f51\u7edc\u6570\u636e\u5305\u7684\u6709\u5e8f\u4f20\u8f93\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u7f51\u7edc\u6761\u4ef6\u3002", "motivation": "\u7f51\u7edc\u5ef6\u8fdf\u4e25\u91cd\u5f71\u54cd\u8d85\u7b97\u5e94\u7528\u7684\u6027\u80fd\uff0c\u73b0\u6709\u7684\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\u53ef\u80fd\u5bfc\u81f4\u6570\u636e\u5305\u4e71\u5e8f\uff0c\u5f71\u54cdTCP\u3001QUIC\u548cRoCE\u7b49\u534f\u8bae\u7684\u6548\u7387\u3002", "method": "\u91c7\u7528flowcut switching\u7b97\u6cd5\uff0c\u4e0d\u540c\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u7a81\u53d1\u6d41\u91cf\u7684flowlet switching\uff0c\u8be5\u7b97\u6cd5\u9002\u7528\u4e8e\u975e\u7a81\u53d1\u6d41\u91cf\uff08\u5982RDMA\uff09\uff0c\u786e\u4fdd\u6570\u636e\u5305\u6709\u5e8f\u4f20\u8f93\u3002", "result": "flowcut switching\u5728\u5404\u79cd\u7f51\u7edc\u6761\u4ef6\u4e0b\u90fd\u80fd\u4fdd\u8bc1\u6570\u636e\u5305\u6709\u5e8f\u4f20\u8f93\uff0c\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u3002", "conclusion": "flowcut switching\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u5728\u6570\u636e\u5305\u6709\u5e8f\u4f20\u8f93\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.21414", "pdf": "https://arxiv.org/pdf/2506.21414", "abs": "https://arxiv.org/abs/2506.21414", "authors": ["Gongjian Sun", "Mingyu Yan", "Dengke Han", "Runzhen Xue", "Duo Wang", "Xiaochun Ye", "Dongrui Fan"], "title": "Accelerating GNN Training through Locality-aware Dropout and Merge", "categories": ["cs.AR"], "comment": "under review in TPDS. extend version of DATE 2025", "summary": "Graph Neural Networks (GNNs) have demonstrated significant success in graph\nlearning and are widely adopted across various critical domains. However, the\nirregular connectivity between vertices leads to inefficient neighbor\naggregation, resulting in substantial irregular and coarse-grained DRAM\naccesses. This lack of data locality presents significant challenges for\nexecution platforms, ultimately degrading performance. While previous\naccelerator designs have leveraged on-chip memory and data access scheduling\nstrategies to address this issue, they still inevitably access features at\nirregular addresses from DRAM. In this work, we propose LiGNN, a hardware-based\nsolution that improves data locality by applying dropout and merge techniques\nduring neighbor aggregation to accelerate GNN training. Unlike conventional\nalgorithm-level dropout methods that primarily aim to improve accuracy while\noverlooking hardware costs, LiGNN introduces a locality-aware feature dropout\nmechanism. This approach selectively drops node features with data locality\nawareness, effectively reducing irregular DRAM accesses without compromising\nmodel accuracy. Moreover, by leveraging detailed knowledge of memory layout and\norganization-including critical alignment constraints-LiGNN strategically\nmerges memory accesses during neighbor aggregation at the DRAM row level,\nguided by GNN-level semantics. This optimization significantly improves data\nlocality with minimal additional cost. Under the commonly adopted 0.5 dropout\nrate, LiGNN outperforms state-of-the-art methods, delivering a 1.48~3.02x\nspeedup, reducing DRAM accesses by 34%~55%, and lowering DRAM row activations\nby 59%~82%, all while maintaining model accuracy.", "AI": {"tldr": "LiGNN\u662f\u4e00\u79cd\u57fa\u4e8e\u786c\u4ef6\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6539\u8fdb\u6570\u636e\u5c40\u90e8\u6027\u6765\u52a0\u901fGNN\u8bad\u7ec3\uff0c\u663e\u8457\u51cf\u5c11\u4e86DRAM\u8bbf\u95ee\u3002", "motivation": "GNN\u5728\u56fe\u5f62\u5b66\u4e60\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u4e0d\u89c4\u5219\u7684\u9876\u70b9\u8fde\u63a5\u5bfc\u81f4\u4e86\u4f4e\u6548\u7684\u90bb\u5c45\u805a\u5408\u548c\u5927\u91cf\u7684\u4e0d\u89c4\u5219DRAM\u8bbf\u95ee\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u6027\u80fd\u3002", "method": "LiGNN\u7ed3\u5408\u4e86\u4f4d\u7f6e\u611f\u77e5\u7684\u7279\u5f81\u4e22\u5f03\u7b56\u7565\u548c\u5185\u5b58\u8bbf\u95ee\u5408\u5e76\u6280\u672f\uff0c\u4f18\u5316\u4e86\u6570\u636e\u5c40\u90e8\u6027\u3002", "result": "\u57280.5\u7684\u4e22\u5f03\u7387\u4e0b\uff0cLiGNN\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u901f1.48~3.02\u500d\uff0c\u51cf\u5c11\u4e8634%~55%\u7684DRAM\u8bbf\u95ee\uff0c\u5e76\u964d\u4f4e\u4e8659%~82%\u7684DRAM\u884c\u6fc0\u6d3b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u51c6\u786e\u7387\u3002", "conclusion": "LiGNN\u901a\u8fc7\u786c\u4ef6\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86GNN\u8bad\u7ec3\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2506.20834", "pdf": "https://arxiv.org/pdf/2506.20834", "abs": "https://arxiv.org/abs/2506.20834", "authors": ["Tomas Gallo Aquino", "Victoria Liu", "Habiba Azab", "Raissa Mathura", "Andrew J Watrous", "Eleonora Bartoli", "Benjamin Y Hayden", "Paul Sajda", "Sameer A Sheth", "Nuttida Rungratsameetaweemana"], "title": "Brain2Model Transfer: Training sensory and decision models with human neural activity as a teacher", "categories": ["cs.NE", "cs.ET", "q-bio.NC"], "comment": "15 pages, 4 figures", "summary": "Transfer learning enhances the training of novel sensory and decision models\nby employing rich feature representations from large, pre-trained teacher\nmodels. Cognitive neuroscience shows that the human brain creates\nlow-dimensional, abstract representations for efficient sensorimotor coding.\nImportantly, the brain can learn these representations with significantly fewer\ndata points and less computational power than artificial models require. We\nintroduce Brain2Model Transfer Learning (B2M), a framework where neural\nactivity from human sensory and decision-making tasks acts as the teacher model\nfor training artificial neural networks. We propose two B2M strategies: (1)\nBrain Contrastive Transfer, which aligns brain activity and network activations\nthrough a contrastive objective; and (2) Brain Latent Transfer, which projects\nlatent dynamics from similar cognitive tasks onto student networks via\nsupervised regression of brain-derived features. We validate B2M in\nmemory-based decision-making with a recurrent neural network and scene\nreconstruction for autonomous driving with a variational autoencoder. The\nresults show that student networks benefiting from brain-based transfer\nconverge faster and achieve higher predictive accuracy than networks trained in\nisolation. Our findings indicate that the brain's representations are valuable\nfor artificial learners, paving the way for more efficient learning of complex\ndecision-making representations, which would be costly or slow through purely\nartificial training.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21014", "pdf": "https://arxiv.org/pdf/2506.21014", "abs": "https://arxiv.org/abs/2506.21014", "authors": ["Shaojian Qiu", "Mengyang Huang", "Jiahao Cheng"], "title": "Boosting Vulnerability Detection with Inter-function Multilateral Association Insights", "categories": ["cs.SE"], "comment": null, "summary": "Vulnerability detection is a crucial yet challenging technique for ensuring\nthe security of software systems. Currently, most deep learning-based\nvulnerability detection methods focus on stand-alone functions, neglecting the\ncomplex inter-function interrelations, particularly the multilateral\nassociations. This oversight can fail to detect vulnerabilities in these\ninterrelations. To address this gap, we present an Inter-Function Multilateral\nAssociation analysis framework for Vulnerability Detection (IFMA-VD). The\ncornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and\nutilizing hyperedge convolution to extract multilateral association features.\nSpecifically, we first parse functions into a code property graph to generate\nintra-function features. Following this, we construct a code behavior\nhypergraph by segmenting the program dependency graph to isolate and encode\nbehavioral features into hyperedges. Finally, we utilize a hypergraph network\nto capture the multilateral association knowledge for augmenting vulnerability\ndetection. We evaluate IFMA-VD on three widely used vulnerability datasets and\ndemonstrate improvements in F-measure and Recall compared to baseline methods.\nAdditionally, we illustrate that multilateral association features can boost\ncode feature representation and validate the effectiveness of IFMA-VD on\nreal-world datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u95f4\u591a\u8fb9\u5173\u8054\u5206\u6790\u7684\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff08IFMA-VD\uff09\uff0c\u901a\u8fc7\u6784\u5efa\u4ee3\u7801\u884c\u4e3a\u8d85\u56fe\u5e76\u5229\u7528\u8d85\u8fb9\u5377\u79ef\u63d0\u53d6\u591a\u8fb9\u5173\u8054\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ec\u56de\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u5173\u6ce8\u72ec\u7acb\u51fd\u6570\uff0c\u5ffd\u89c6\u4e86\u51fd\u6570\u95f4\u7684\u590d\u6742\u591a\u8fb9\u5173\u8054\uff0c\u53ef\u80fd\u5bfc\u81f4\u6f0f\u6d1e\u6f0f\u68c0\u3002\u4e3a\u6b64\uff0c\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6548\u679c\u3002", "method": "\u8bba\u6587\u9996\u5148\u5c06\u51fd\u6570\u89e3\u6790\u4e3a\u4ee3\u7801\u5c5e\u6027\u56fe\u4ee5\u751f\u6210\u51fd\u6570\u5185\u7279\u5f81\uff0c\u7136\u540e\u901a\u8fc7\u5206\u5272\u7a0b\u5e8f\u4f9d\u8d56\u56fe\u6784\u5efa\u4ee3\u7801\u884c\u4e3a\u8d85\u56fe\uff0c\u5c06\u884c\u4e3a\u7279\u5f81\u7f16\u7801\u4e3a\u8d85\u8fb9\uff0c\u6700\u540e\u5229\u7528\u8d85\u56fe\u7f51\u7edc\u6355\u83b7\u591a\u8fb9\u5173\u8054\u77e5\u8bc6\u4ee5\u589e\u5f3a\u6f0f\u6d1e\u68c0\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIFMA-VD\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728F-measure\u548cRecall\u6307\u6807\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u9a8c\u8bc1\u4e86\u591a\u8fb9\u5173\u8054\u7279\u5f81\u5bf9\u4ee3\u7801\u7279\u5f81\u8868\u5f81\u7684\u589e\u5f3a\u4f5c\u7528\u3002", "conclusion": "IFMA-VD\u901a\u8fc7\u591a\u8fb9\u5173\u8054\u5206\u6790\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.20901", "pdf": "https://arxiv.org/pdf/2506.20901", "abs": "https://arxiv.org/abs/2506.20901", "authors": ["Meng Du", "Robert Amor", "Kwan-Liu Ma", "Burkhard C. W\u00fcnsche"], "title": "Data Visualization for Improving Financial Literacy: A Systematic Review", "categories": ["cs.GR"], "comment": null, "summary": "Financial literacy empowers individuals to make informed and effective\nfinancial decisions, improving their overall financial well-being and security.\nHowever, for many people understanding financial concepts can be daunting and\nonly half of US adults are considered financially literate. Data visualization\nsimplifies these concepts, making them accessible and engaging for learners of\nall ages. This systematic review analyzes 37 research papers exploring the use\nof data visualization and visual analytics in financial education and literacy\nenhancement. We classify these studies into five key areas: (1) the evolution\nof visualization use across time and space, (2) motivations for using\nvisualization tools, (3) the financial topics addressed and instructional\napproaches used, (4) the types of tools and technologies applied, and (5) how\nthe effectiveness of teaching interventions was evaluated. Furthermore, we\nidentify research gaps and highlight opportunities for advancing financial\nliteracy. Our findings offer practical insights for educators and professionals\nto effectively utilize or design visual tools for financial literacy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff037\u7bc7\u7814\u7a76\uff0c\u63a2\u8ba8\u6570\u636e\u53ef\u89c6\u5316\u548c\u89c6\u89c9\u5206\u6790\u5728\u91d1\u878d\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u4e86\u4e94\u5927\u5173\u952e\u9886\u57df\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63d0\u5347\u91d1\u878d\u7d20\u517b\u5bf9\u4e2a\u4eba\u8d22\u52a1\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8bb8\u591a\u4eba\u5bf9\u91d1\u878d\u6982\u5ff5\u611f\u5230\u56f0\u60d1\uff0c\u6570\u636e\u53ef\u89c6\u5316\u53ef\u4ee5\u7b80\u5316\u5e76\u589e\u5f3a\u5b66\u4e60\u6548\u679c\u3002", "method": "\u5206\u679037\u7bc7\u7814\u7a76\uff0c\u5206\u7c7b\u4e3a\u4e94\u4e2a\u9886\u57df\uff1a\u53ef\u89c6\u5316\u5de5\u5177\u7684\u6f14\u53d8\u3001\u4f7f\u7528\u52a8\u673a\u3001\u91d1\u878d\u4e3b\u9898\u4e0e\u6559\u5b66\u65b9\u6cd5\u3001\u5de5\u5177\u7c7b\u578b\u53ca\u6559\u5b66\u6548\u679c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53ef\u89c6\u5316\u5de5\u5177\u80fd\u6709\u6548\u63d0\u5347\u91d1\u878d\u7d20\u517b\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u7814\u7a76\u7684\u4e0d\u8db3\u4e0e\u672a\u6765\u673a\u4f1a\u3002", "conclusion": "\u8bba\u6587\u4e3a\u6559\u80b2\u8005\u548c\u4e13\u4e1a\u4eba\u58eb\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u548c\u4f7f\u7528\u53ef\u89c6\u5316\u5de5\u5177\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u4ee5\u4fc3\u8fdb\u91d1\u878d\u7d20\u517b\u7684\u63d0\u5347\u3002"}}
{"id": "2506.20817", "pdf": "https://arxiv.org/pdf/2506.20817", "abs": "https://arxiv.org/abs/2506.20817", "authors": ["Ali Tourani", "Fatemeh Nazary", "Yashar Deldjoo"], "title": "RAG-VisualRec: An Open Resource for Vision- and Text-Enhanced Retrieval-Augmented Generation in Recommendation", "categories": ["cs.IR", "cs.MM"], "comment": "20 pages, 6 figures, 5 tables", "summary": "This paper addresses the challenge of developing multimodal recommender\nsystems for the movie domain, where limited metadata (e.g., title, genre) often\nhinders the generation of robust recommendations. We introduce a resource that\ncombines LLM-generated plot descriptions with trailer-derived visual embeddings\nin a unified pipeline supporting both Retrieval-Augmented Generation (RAG) and\ncollaborative filtering. Central to our approach is a data augmentation step\nthat transforms sparse metadata into richer textual signals, alongside fusion\nstrategies (e.g., PCA, CCA) that integrate visual cues. Experimental\nevaluations demonstrate that CCA-based fusion significantly boosts recall\ncompared to unimodal baselines, while an LLM-driven re-ranking step further\nimproves NDCG, particularly in scenarios with limited textual data. By\nreleasing this framework, we invite further exploration of multi-modal\nrecommendation techniques tailored to cold-start, novelty-focused, and\ndomain-specific settings. All code, data, and detailed documentation are\npublicly available at: https://github.com/RecSys-lab/RAG-VisualRec", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20686", "pdf": "https://arxiv.org/pdf/2506.20686", "abs": "https://arxiv.org/abs/2506.20686", "authors": ["Hoa La", "Ahan Gupta", "Alex Morehead", "Jianlin Cheng", "Minjia Zhang"], "title": "MegaFold: System-Level Optimizations for Accelerating Protein Structure Prediction Models", "categories": ["q-bio.BM", "cs.DC", "cs.LG", "cs.PF"], "comment": "13 pages, 12 figures", "summary": "Protein structure prediction models such as AlphaFold3 (AF3) push the\nfrontier of biomolecular modeling by incorporating science-informed\narchitectural changes to the transformer architecture. However, these advances\ncome at a steep system cost, introducing: compute- and memory-intensive\noperators, 2D attention mechanisms, and retrieval-augmented data pipelines,\nwhich collectively hinder the scalability of AF3 training. In this work, we\npresent MegaFold, a cross-platform system to accelerate AF3 training. MegaFold\ntackles key bottlenecks through ahead-of-time caching to eliminate GPU idle\ntime from the retrieval-augmented data pipeline, Triton-based kernels for\nmemory-efficient EvoAttention on heterogeneous devices, and deep fusion for\ncommon and critical small operators in AF3. Evaluation on both NVIDIA H200 and\nAMD MI250 GPUs shows that MegaFold reduces peak memory usage of AF3 training by\nup to 1.23$\\times$ and improves per-iteration training time by up-to\n1.73$\\times$ and 1.62$\\times$ respectively. More importantly, MegaFold enables\ntraining on 1.35$\\times$ longer sequence lengths compared to PyTorch baselines\nwithout running out-of-memory, significantly improving the scalability of\nmodern protein folding models. We open source our code at\nhttps://github.com/Supercomputing-System-AI-Lab/MegaFold/.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20909", "pdf": "https://arxiv.org/pdf/2506.20909", "abs": "https://arxiv.org/abs/2506.20909", "authors": ["Jonas Bayer", "Marco David", "Malte Hassler", "Yuri Matiyasevich", "Dierk Schleicher"], "title": "Diophantine Equations over $\\mathbb Z$: Universal Bounds and Parallel Formalization", "categories": ["math.NT", "cs.LO"], "comment": "53 pages", "summary": "This paper explores multiple closely related themes: bounding the complexity\nof Diophantine equations over the integers and developing mathematical proofs\nin parallel with formal theorem provers.\n  Hilbert's Tenth Problem (H10) asks about the decidability of Diophantine\nequations and has been answered negatively by Davis, Putnam, Robinson and\nMatiyasevich. It is natural to ask for which subclasses of Diophantine\nequations H10 remains undecidable. Such subclasses can be defined in terms of\nuniversal pairs: bounds on the number of variables $\\nu$ and degree $\\delta$\nsuch that all Diophantine equations can be rewritten in at most this\ncomplexity. Our work develops explicit universal pairs $(\\nu, \\delta)$ for\ninteger unknowns, achieving new bounds that cannot be obtained by naive\ntranslations from known results over $\\mathbb N$.\n  In parallel, we have conducted a formal verification of our results using the\nproof assistant Isabelle. While formal proof verification has traditionally\nbeen applied a posteriori to known results, this project integrates\nformalization into the discovery and development process. In a final section,\nwe describe key insights gained from this unusual approach and its implications\nfor mathematical practice. Our work contributes both to the study of\nDiophantine equations and to the broader question of how mathematics is\nconducted in the 21st century.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86Diophantine\u65b9\u7a0b\u7684\u590d\u6742\u5ea6\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u8bc1\u660e\u5de5\u5177Isabelle\u9a8c\u8bc1\u4e86\u7ed3\u679c\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u7684\u663e\u5f0f\u901a\u7528\u5bf9(\u03bd, \u03b4)\uff0c\u5e76\u4e3a\u6570\u5b66\u5b9e\u8df5\u4e2d\u7684\u65b0\u65b9\u6cd5\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u786e\u5b9aDiophantine\u65b9\u7a0b\u7684\u54ea\u4e9b\u5b50\u7c7b\u5728Hilbert\u7b2c\u5341\u95ee\u9898\u4e0b\u4ecd\u7136\u4e0d\u53ef\u5224\u5b9a\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u5de5\u5177\u5c06\u8bc1\u660e\u8fc7\u7a0b\u4e0e\u6570\u5b66\u53d1\u73b0\u76f8\u7ed3\u5408\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u901a\u7528\u5bf9(\u03bd, \u03b4)\u6765\u9650\u5236\u65b9\u7a0b\u590d\u6742\u5ea6\uff0c\u5e76\u4f7f\u7528Isabelle\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u5c06\u8bc1\u660e\u4e0e\u53d1\u73b0\u8fc7\u7a0b\u7ed3\u5408\u3002", "result": "\u63d0\u51fa\u4e86\u65b0\u7684\u663e\u5f0f\u901a\u7528\u5bf9(\u03bd, \u03b4)\uff0c\u5e76\u901a\u8fc7Isabelle\u9a8c\u8bc1\u4e86\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u5f62\u5f0f\u5316\u5de5\u5177\u5728\u6570\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u63a8\u8fdb\u4e86Diophantine\u65b9\u7a0b\u7684\u7814\u7a76\uff0c\u8fd8\u63a2\u7d22\u4e86\u5f62\u5f0f\u5316\u8bc1\u660e\u5de5\u5177\u572821\u4e16\u7eaa\u6570\u5b66\u5b9e\u8df5\u4e2d\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2506.20952", "pdf": "https://arxiv.org/pdf/2506.20952", "abs": "https://arxiv.org/abs/2506.20952", "authors": ["Kyosuke Ishibashi", "Atsushi Saito", "Zin Y. Tun", "Lucas Ray", "Megan C. Coram", "Akihiro Sakurai", "Allison M. Okamura", "Ko Yamamoto"], "title": "Effect of Haptic Feedback on Avoidance Behavior and Visual Exploration in Dynamic VR Pedestrian Environment", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Human crowd simulation in virtual reality (VR) is a powerful tool with\npotential applications including emergency evacuation training and assessment\nof building layout. While haptic feedback in VR enhances immersive experience,\nits effect on walking behavior in dense and dynamic pedestrian flows is\nunknown. Through a user study, we investigated how haptic feedback changes user\nwalking motion in crowded pedestrian flows in VR. The results indicate that\nhaptic feedback changed users' collision avoidance movements, as measured by\nincreased walking trajectory length and change in pelvis angle. The\ndisplacements of users' lateral position and pelvis angle were also increased\nin the instantaneous response to a collision with a non-player character (NPC),\neven when the NPC was inside the field of view. Haptic feedback also enhanced\nusers' awareness and visual exploration when an NPC approached from the side\nand back. Furthermore, variation in walking speed was increased by the haptic\nfeedback. These results suggested that the haptic feedback enhanced users'\nsensitivity to a collision in VR environment.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u63a2\u8ba8\u4e86\u89e6\u89c9\u53cd\u9988\u5bf9VR\u73af\u5883\u4e2d\u5bc6\u96c6\u52a8\u6001\u4eba\u7fa4\u4e0b\u884c\u8d70\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u89e6\u89c9\u53cd\u9988\u6539\u53d8\u4e86\u7528\u6237\u7684\u907f\u78b0\u52a8\u4f5c\uff0c\u589e\u5f3a\u4e86\u78b0\u649e\u654f\u611f\u6027\u548c\u89c6\u89c9\u63a2\u7d22\u3002", "motivation": "\u89e6\u89c9\u53cd\u9988\u53ef\u63d0\u5347VR\u7684\u6c89\u6d78\u611f\uff0c\u4f46\u5176\u5bf9\u5bc6\u96c6\u52a8\u6001\u4eba\u7fa4\u884c\u8d70\u884c\u4e3a\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\uff0c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u5206\u6790\u89e6\u89c9\u53cd\u9988\u5bf9\u884c\u8d70\u8f68\u8ff9\u3001\u9aa8\u76c6\u89d2\u5ea6\u53d8\u5316\u53ca\u89c6\u89c9\u63a2\u7d22\u7684\u5f71\u54cd\u3002", "result": "\u89e6\u89c9\u53cd\u9988\u589e\u52a0\u4e86\u884c\u8d70\u8f68\u8ff9\u957f\u5ea6\u3001\u9aa8\u76c6\u89d2\u5ea6\u53d8\u5316\uff0c\u5e76\u63d0\u5347\u4e86\u4fa7\u9762\u548c\u540e\u65b9NPC\u63a5\u8fd1\u65f6\u7684\u89c6\u89c9\u63a2\u7d22\u3002", "conclusion": "\u89e6\u89c9\u53cd\u9988\u589e\u5f3a\u4e86\u7528\u6237\u5728VR\u73af\u5883\u4e2d\u7684\u78b0\u649e\u654f\u611f\u6027\u548c\u884c\u4e3a\u9002\u5e94\u6027\u3002"}}
{"id": "2506.20965", "pdf": "https://arxiv.org/pdf/2506.20965", "abs": "https://arxiv.org/abs/2506.20965", "authors": ["Craig Steven Wright"], "title": "Rational Miner Behaviour, Protocol Stability, and Time Preference: An Austrian and Game-Theoretic Analysis of Bitcoin's Incentive Environment", "categories": ["econ.GN", "cs.CR", "cs.GT", "cs.NI", "q-fin.EC", "q-fin.GN", "91B42, 91A25, 91B50", "K.4.4; J.4; C.2.4"], "comment": "Approximately 10,770 words, 0 figure, 0 table. Submitted to The\n  Quarterly Journal of Austrian Economics", "summary": "This paper integrates Austrian capital theory with repeated game theory to\nexamine strategic miner behaviour under different institutional conditions in\nblockchain systems. It shows that when protocol rules are mutable, effective\ntime preference rises, undermining rational long-term planning and cooperative\nequilibria. Using formal game-theoretic analysis and Austrian economic\nprinciples, the paper demonstrates how mutable protocols shift miner incentives\nfrom productive investment to political rent-seeking and influence games. The\noriginal Bitcoin protocol is interpreted as an institutional anchor: a fixed\nrule-set enabling calculability and low time preference. Drawing on the work of\nBohm-Bawerk, Mises, and Hayek, the argument is made that protocol immutability\nis essential for restoring strategic coherence, entrepreneurial confidence, and\nsustainable network equilibrium.", "AI": {"tldr": "\u8bba\u6587\u7ed3\u5408\u5965\u5730\u5229\u8d44\u672c\u7406\u8bba\u4e0e\u91cd\u590d\u535a\u5f08\u8bba\uff0c\u5206\u6790\u533a\u5757\u94fe\u7cfb\u7edf\u4e2d\u4e0d\u540c\u5236\u5ea6\u6761\u4ef6\u4e0b\u77ff\u5de5\u7684\u7b56\u7565\u884c\u4e3a\u3002", "motivation": "\u63a2\u8ba8\u534f\u8bae\u89c4\u5219\u53ef\u53d8\u6027\u5982\u4f55\u5f71\u54cd\u77ff\u5de5\u7684\u957f\u671f\u89c4\u5212\u548c\u5408\u4f5c\u5747\u8861\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u535a\u5f08\u8bba\u5206\u6790\u548c\u5965\u5730\u5229\u7ecf\u6d4e\u5b66\u539f\u7406\uff0c\u7814\u7a76\u53ef\u53d8\u534f\u8bae\u5bf9\u77ff\u5de5\u6fc0\u52b1\u7684\u5f71\u54cd\u3002", "result": "\u53ef\u53d8\u534f\u8bae\u5bfc\u81f4\u77ff\u5de5\u4ece\u751f\u4ea7\u6027\u6295\u8d44\u8f6c\u5411\u653f\u6cbb\u5bfb\u79df\u548c\u5f71\u54cd\u529b\u535a\u5f08\uff0c\u6bd4\u7279\u5e01\u56fa\u5b9a\u89c4\u5219\u96c6\u5219\u63d0\u4f9b\u7a33\u5b9a\u6027\u548c\u4f4e\u65f6\u95f4\u504f\u597d\u3002", "conclusion": "\u534f\u8bae\u4e0d\u53ef\u53d8\u6027\u5bf9\u6062\u590d\u6218\u7565\u4e00\u81f4\u6027\u3001\u4f01\u4e1a\u5bb6\u4fe1\u5fc3\u548c\u53ef\u6301\u7eed\u7f51\u7edc\u5747\u8861\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.20828", "pdf": "https://arxiv.org/pdf/2506.20828", "abs": "https://arxiv.org/abs/2506.20828", "authors": ["Pranay Mundra", "Charalampos Papamanthou", "Julian Shun", "Quanquan C. Liu"], "title": "Practical and Accurate Local Edge Differentially Private Graph Algorithms", "categories": ["cs.DS", "cs.CR", "cs.DB"], "comment": "To appear in VLDB 2025", "summary": "The rise of massive networks across diverse domains necessitates\nsophisticated graph analytics, often involving sensitive data and raising\nprivacy concerns. This paper addresses these challenges using local\ndifferential privacy (LDP), which enforces privacy at the individual level,\nwhere no third-party entity is trusted, unlike centralized models that assume a\ntrusted curator. We introduce novel LDP algorithms for two fundamental graph\nstatistics: k-core decomposition and triangle counting. Our approach leverages\ninput-dependent private graph properties, specifically the degeneracy and\nmaximum degree of the graph, to improve theoretical utility. Unlike prior\nmethods, our error bounds are determined by the maximum degree rather than the\ntotal number of edges, resulting in significantly tighter guarantees. For\ntriangle counting, we improve upon the work of Imola, Murakami, and\nChaudhury~\\cite{IMC21locally, IMC21communication}, which bounds error in terms\nof edge count. Instead, our algorithm achieves bounds based on graph degeneracy\nby leveraging a private out-degree orientation, a refined variant of Eden et\nal.'s randomized response technique~\\cite{ELRS23, and a novel analysis,\nyielding stronger guarantees than prior work. Beyond theoretical gains, we are\nthe first to evaluate local DP algorithms in a distributed simulation, unlike\nprior work tested on a single processor. Experiments on real-world graphs show\nsubstantial accuracy gains: our k-core decomposition achieves errors within 3x\nof exact values, far outperforming the 131x error in the baseline of Dhulipala\net al.~\\cite{DLRSSY22}. Our triangle counting algorithm reduces multiplicative\napproximation errors by up to six orders of magnitude, while maintaining\ncompetitive runtime.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20675", "pdf": "https://arxiv.org/pdf/2506.20675", "abs": "https://arxiv.org/abs/2506.20675", "authors": ["Anish Saxena", "Po-An Tsai", "Hritvik Taneja", "Aamer Jaleel", "Moinuddin Qureshi"], "title": "Utility-Driven Speculative Decoding for Mixture-of-Experts", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "GPU memory bandwidth is the main bottleneck for low-latency Large Language\nModel (LLM) inference. Speculative decoding leverages idle GPU compute by using\na lightweight drafter to propose K tokens, which the LLM verifies in parallel,\nboosting token throughput. In conventional dense LLMs, all model weights are\nfetched each iteration, so speculation adds no latency overhead. Emerging\nMixture of Experts (MoE) models activate only a subset of weights per token,\ngreatly reducing data movement. However, we show that speculation is\nineffective for MoEs: draft tokens collectively activate more weights,\nincreasing data movement and verification time by 2-3x. When token throughput\ngains fail to offset this overhead, speculation causes slowdowns up to 1.5x,\nmaking it infeasible. Even when useful, the optimal K varies by task, model,\nand even between requests and iterations. Thus, despite widespread use in dense\nLLMs, speculation remains impractical in leading MoEs.\n  We present Cascade, a utility-driven framework that selectively enables\nspeculation to avoid slowdowns and dynamically tunes K to accelerate MoE\nserving. Cascade uses a lightweight metric, speculation utility, the ratio of\ntoken gains to verification cost, which shows iteration-level locality,\nenabling periodic decisions via short test and longer set phases. For each\nrequest, Cascade disables speculation if utility drops below one during\ntesting, and when utility exceeds one, tests multiple K-values to choose the\nutility-maximizing K for the set phase. We implement Cascade in vLLM and\nevaluate it on five popular MoEs with workloads spanning code, math,\nextraction, and mixed tasks. Cascade limits slowdown to 5% (vs. 1.5x) and\nimproves throughput by 7-14% over static K, making speculative decoding\npractical for MoEs.", "AI": {"tldr": "GPU\u5185\u5b58\u5e26\u5bbd\u662f\u4f4e\u5ef6\u8fdf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u4e3b\u8981\u74f6\u9888\u3002\u4f20\u7edf\u5bc6\u96c6\u6a21\u578b\u901a\u8fc7\u63a8\u6d4b\u89e3\u7801\u63d0\u5347\u541e\u5410\u91cf\uff0c\u4f46\u5728MoE\u6a21\u578b\u4e2d\u56e0\u6743\u91cd\u6fc0\u6d3b\u589e\u52a0\u5bfc\u81f4\u6548\u7387\u4e0b\u964d\u3002Cascade\u6846\u67b6\u52a8\u6001\u8c03\u6574\u63a8\u6d4b\u89e3\u7801\u4ee5\u4f18\u5316MoE\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3MoE\u6a21\u578b\u4e2d\u63a8\u6d4b\u89e3\u7801\u56e0\u6743\u91cd\u6fc0\u6d3b\u589e\u52a0\u800c\u5bfc\u81f4\u7684\u6548\u7387\u4e0b\u964d\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51faCascade\u6846\u67b6\u4ee5\u52a8\u6001\u8c03\u6574\u7b56\u7565\u3002", "method": "Cascade\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6307\u6807\u201c\u63a8\u6d4b\u6548\u7528\u201d\u52a8\u6001\u9009\u62e9\u662f\u5426\u542f\u7528\u63a8\u6d4b\u89e3\u7801\uff0c\u5e76\u5b9a\u671f\u8c03\u6574K\u503c\u4ee5\u6700\u5927\u5316\u541e\u5410\u91cf\u3002", "result": "\u5728\u4e94\u79cd\u6d41\u884cMoE\u6a21\u578b\u4e0a\uff0cCascade\u5c06\u51cf\u901f\u9650\u5236\u57285%\u4ee5\u4e0b\uff0c\u541e\u5410\u91cf\u63d0\u53477-14%\u3002", "conclusion": "Cascade\u4f7f\u63a8\u6d4b\u89e3\u7801\u5728MoE\u6a21\u578b\u4e2d\u53d8\u5f97\u5b9e\u7528\uff0c\u663e\u8457\u4f18\u5316\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.21487", "pdf": "https://arxiv.org/pdf/2506.21487", "abs": "https://arxiv.org/abs/2506.21487", "authors": ["Maryam Ghane", "Amir M. Hajisadeghi", "Hamid R. Zarandi"], "title": "OptGM: An Optimized Gate Merging Method to Mitigate NBTI in Digital Circuits", "categories": ["cs.AR"], "comment": null, "summary": "This paper presents OptGM, an optimized gate merging method designed to\nmitigate negative bias temperature instability (NBTI) in digital circuits.\nFirst, the proposed approach effectively identifies NBTI-critical internal\nnodes, defined as those with a signal probability exceeding a predefined\nthreshold. Next, based on the proposed optimized algorithm, the sensitizer gate\n(which drives the critical node) and the sensitive gate (which is fed by it)\nare merged into a new complex gate. This complex gate preserves the original\nlogic while eliminating NBTI-critical nodes. Finally, to evaluate the\neffectiveness of OptGM, we assess it on several combinational and sequential\nbenchmark circuits. Simulation results demonstrate that, on average, the number\nof NBTI-critical transistors (i.e., PMOS transistors connected to critical\nnodes), NBTI-induced delay degradation, and the total transistor count are\nreduced by 89.29%, 23.87%, and 6.47%, respectively. Furthermore, OptGM enhances\nperformance per cost (PPC) by 12.8% on average, with minimal area overhead.", "AI": {"tldr": "OptGM\u662f\u4e00\u79cd\u4f18\u5316\u7684\u95e8\u5408\u5e76\u65b9\u6cd5\uff0c\u65e8\u5728\u51cf\u5c11\u6570\u5b57\u7535\u8def\u4e2d\u7684\u8d1f\u504f\u538b\u6e29\u5ea6\u4e0d\u7a33\u5b9a\u6027\uff08NBTI\uff09\uff0c\u6548\u679c\u663e\u8457\u4e14\u9762\u79ef\u5f00\u9500\u5c0f\u3002", "motivation": "NBTI\u4f1a\u5bfc\u81f4\u6570\u5b57\u7535\u8def\u6027\u80fd\u9000\u5316\uff0cOptGM\u901a\u8fc7\u4f18\u5316\u95e8\u5408\u5e76\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bc6\u522bNBTI\u5173\u952e\u8282\u70b9\uff0c\u5408\u5e76\u9a71\u52a8\u548c\u88ab\u9a71\u52a8\u95e8\u5f62\u6210\u65b0\u590d\u5408\u95e8\uff0c\u6d88\u9664\u5173\u952e\u8282\u70b9\u3002", "result": "NBTI\u5173\u952e\u6676\u4f53\u7ba1\u51cf\u5c1189.29%\uff0c\u5ef6\u8fdf\u9000\u5316\u964d\u4f4e23.87%\uff0c\u6676\u4f53\u7ba1\u603b\u6570\u51cf\u5c116.47%\uff0c\u6027\u80fd\u6210\u672c\u6bd4\u63d0\u534712.8%\u3002", "conclusion": "OptGM\u9ad8\u6548\u89e3\u51b3NBTI\u95ee\u9898\uff0c\u63d0\u5347\u7535\u8def\u6027\u80fd\u4e14\u6210\u672c\u4f4e\u3002"}}
{"id": "2506.20918", "pdf": "https://arxiv.org/pdf/2506.20918", "abs": "https://arxiv.org/abs/2506.20918", "authors": ["Manika Lamba", "You Peng", "Sophie Nikolov", "Glen Layne-Worthey", "J. Stephen Downie"], "title": "Metadata Enrichment of Long Text Documents using Large Language Models", "categories": ["cs.DL", "cs.ET", "cs.IR"], "comment": null, "summary": "In this project, we semantically enriched and enhanced the metadata of long\ntext documents, theses and dissertations, retrieved from the HathiTrust Digital\nLibrary in English published from 1920 to 2020 through a combination of manual\nefforts and large language models. This dataset provides a valuable resource\nfor advancing research in areas such as computational social science, digital\nhumanities, and information science. Our paper shows that enriching metadata\nusing LLMs is particularly beneficial for digital repositories by introducing\nadditional metadata access points that may not have originally been foreseen to\naccommodate various content types. This approach is particularly effective for\nrepositories that have significant missing data in their existing metadata\nfields, enhancing search results and improving the accessibility of the digital\nrepository.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u4eba\u5de5\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3aHathiTrust\u56fe\u4e66\u9986\u82f1\u6587\u6587\u732e\u5143\u6570\u636e\uff0c\u63d0\u5347\u6570\u5b57\u56fe\u4e66\u9986\u68c0\u7d22\u4e0e\u53ef\u8bbf\u95ee\u6027\u3002", "motivation": "\u6539\u5584\u6570\u5b57\u56fe\u4e66\u9986\u4e2d\u5143\u6570\u636e\u7684\u5b8c\u6574\u6027\u4e0e\u591a\u6837\u6027\uff0c\u4ee5\u652f\u6301\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u3001\u6570\u5b57\u4eba\u6587\u548c\u4fe1\u606f\u79d1\u5b66\u7684\u7814\u7a76\u3002", "method": "\u7ed3\u5408\u4eba\u5de5\u52aa\u529b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u5bf91920-2020\u5e74\u95f4\u7684\u82f1\u6587\u6587\u732e\u5143\u6570\u636e\u8fdb\u884c\u8bed\u4e49\u589e\u5f3a\u3002", "result": "\u5f15\u5165\u66f4\u591a\u5143\u6570\u636e\u8bbf\u95ee\u70b9\uff0c\u6709\u6548\u586b\u8865\u7f3a\u5931\u6570\u636e\uff0c\u63d0\u5347\u68c0\u7d22\u6548\u679c\u4e0e\u53ef\u8bbf\u95ee\u6027\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5143\u6570\u636e\u589e\u5f3a\u4e2d\u6548\u679c\u663e\u8457\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u7f3a\u5931\u4e25\u91cd\u7684\u6570\u5b57\u56fe\u4e66\u9986\u3002"}}
{"id": "2506.21138", "pdf": "https://arxiv.org/pdf/2506.21138", "abs": "https://arxiv.org/abs/2506.21138", "authors": ["Abdelkarim El-Hajjami", "Camille Salinesi"], "title": "How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The shortage of publicly available, labeled requirements datasets remains a\nmajor barrier to advancing Artificial Intelligence for Requirements Engineering\n(AI4RE). While Large Language Models offer promising capabilities for synthetic\ndata generation, systematic approaches to control and optimize the quality of\ngenerated requirements remain underexplored. This paper presents Synthline v1,\nan enhanced Product Line approach for generating synthetic requirements data\nthat extends our earlier v0 version with advanced generation strategies and\ncuration techniques. We investigate four research questions assessing how\nprompting strategies, automated prompt optimization, and post-generation\ncuration affect data quality across four classification tasks: defect\ndetection, functional vs. non-functional, quality vs. non-quality, and security\nvs. non-security. Our evaluation shows that multi-sample prompting\nsignificantly boosts both utility and diversity over single-sample generation,\nwith F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic\nEditing) for automated prompt optimization yields task-dependent results,\ngreatly improving functional classification (+32.5 points) but reducing\nperformance on others. Interestingly, similarity-based curation improves\ndiversity but often harms classification performance, indicating that some\nredundancy may help ML models. Most importantly, our results show that\nsynthetic requirements can match or outperform human-authored ones for specific\ntasks, with synthetic data surpassing human data for security (+7.8 points) and\ndefect classification (+15.4 points). These findings offer practical insights\nfor AI4RE and chart a viable path to mitigating dataset scarcity through\nsystematic synthetic generation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20946", "pdf": "https://arxiv.org/pdf/2506.20946", "abs": "https://arxiv.org/abs/2506.20946", "authors": ["Donggoo Kang", "Jangyeong Kim", "Dasol Jeong", "Junyoung Choi", "Jeonga Wi", "Hyunmin Lee", "Joonho Gwon", "Joonki Paik"], "title": "Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models", "categories": ["cs.GR", "cs.AI", "cs.CV", "68T45, 68U05", "I.3.7; I.4.10; I.2.10"], "comment": null, "summary": "Current texture synthesis methods, which generate textures from fixed\nviewpoints, suffer from inconsistencies due to the lack of global context and\ngeometric understanding. Meanwhile, recent advancements in video generation\nmodels have demonstrated remarkable success in achieving temporally consistent\nvideos. In this paper, we introduce VideoTex, a novel framework for seamless\ntexture synthesis that leverages video generation models to address both\nspatial and temporal inconsistencies in 3D textures. Our approach incorporates\ngeometry-aware conditions, enabling precise utilization of 3D mesh structures.\nAdditionally, we propose a structure-wise UV diffusion strategy, which enhances\nthe generation of occluded areas by preserving semantic information, resulting\nin smoother and more coherent textures. VideoTex not only achieves smoother\ntransitions across UV boundaries but also ensures high-quality, temporally\nstable textures across video frames. Extensive experiments demonstrate that\nVideoTex outperforms existing methods in texture fidelity, seam blending, and\nstability, paving the way for dynamic real-time applications that demand both\nvisual quality and temporal coherence.", "AI": {"tldr": "VideoTex\u5229\u7528\u89c6\u9891\u751f\u6210\u6a21\u578b\u89e3\u51b33D\u7eb9\u7406\u7684\u65f6\u7a7a\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7\u51e0\u4f55\u611f\u77e5\u6761\u4ef6\u548c\u7ed3\u6784UV\u6269\u6563\u7b56\u7565\uff0c\u751f\u6210\u66f4\u5e73\u6ed1\u3001\u4e00\u81f4\u7684\u7eb9\u7406\u3002", "motivation": "\u73b0\u6709\u7eb9\u7406\u5408\u6210\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587\u548c\u51e0\u4f55\u7406\u89e3\uff0c\u5bfc\u81f4\u4e0d\u4e00\u81f4\u6027\u3002\u89c6\u9891\u751f\u6210\u6a21\u578b\u7684\u6210\u529f\u542f\u53d1\u6211\u4eec\u89e3\u51b3\u7eb9\u7406\u5408\u6210\u7684\u65f6\u7a7a\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "method": "\u63d0\u51faVideoTex\u6846\u67b6\uff0c\u7ed3\u5408\u51e0\u4f55\u611f\u77e5\u6761\u4ef6\u548c\u7ed3\u6784UV\u6269\u6563\u7b56\u7565\uff0c\u5229\u75283D\u7f51\u683c\u7ed3\u6784\u548c\u4fdd\u7559\u8bed\u4e49\u4fe1\u606f\u4f18\u5316\u7eb9\u7406\u751f\u6210\u3002", "result": "VideoTex\u5728\u7eb9\u7406\u4fdd\u771f\u5ea6\u3001\u63a5\u7f1d\u878d\u5408\u548c\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u65f6\u95f4\u7a33\u5b9a\u7684\u7eb9\u7406\u3002", "conclusion": "VideoTex\u4e3a\u52a8\u6001\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u4e86\u89c6\u89c9\u8d28\u91cf\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u7684\u7eb9\u7406\u5408\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.20947", "pdf": "https://arxiv.org/pdf/2506.20947", "abs": "https://arxiv.org/abs/2506.20947", "authors": ["Dejie Yang", "Zhu Xu", "Xinjie Gao", "Yang Liu"], "title": "Hierarchical Sub-action Tree for Continuous Sign Language Recognition", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Continuous sign language recognition (CSLR) aims to transcribe untrimmed\nvideos into glosses, which are typically textual words. Recent studies indicate\nthat the lack of large datasets and precise annotations has become a bottleneck\nfor CSLR due to insufficient training data. To address this, some works have\ndeveloped cross-modal solutions to align visual and textual modalities.\nHowever, they typically extract textual features from glosses without fully\nutilizing their knowledge. In this paper, we propose the Hierarchical\nSub-action Tree (HST), termed HST-CSLR, to efficiently combine gloss knowledge\nwith visual representation learning. By incorporating gloss-specific knowledge\nfrom large language models, our approach leverages textual information more\neffectively. Specifically, we construct an HST for textual information\nrepresentation, aligning visual and textual modalities step-by-step and\nbenefiting from the tree structure to reduce computational complexity.\nAdditionally, we impose a contrastive alignment enhancement to bridge the gap\nbetween the two modalities. Experiments on four datasets (PHOENIX-2014,\nPHOENIX-2014T, CSL-Daily, and Sign Language Gesture) demonstrate the\neffectiveness of our HST-CSLR.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20807", "pdf": "https://arxiv.org/pdf/2506.20807", "abs": "https://arxiv.org/abs/2506.20807", "authors": ["Martin Andrews", "Sam Witteveen"], "title": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "comment": "4 page paper plus Appendices. Accepted to the ES-FoMo \"Efficient\n  Systems for Foundation Models\" workshop at ICML 2025", "summary": "Optimizing GPU kernels for high performance is a complex task, often\ndemanding deep architectural knowledge, extensive profiling, and iterative\nexperimentation. This challenge is amplified when targeting newer or\nless-documented GPU architectures where traditional development aids are\nscarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an\nautomated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)\nstrategically selecting promising prior code versions as a basis for new\niterations; (b) generating hypotheses for optimization experiments, based on\nexisting code and assimilated knowledge from general GPU literature; and (c)\nautonomously implementing these experiments through code modification and\nsubsequent submission to an external evaluation system, using only observed\ntiming data as performance feedback. We detail how this approach navigates the\nchallenges of the AMD MI300 target architecture and leverages LLMs to\ncompensate for limited domain-specific human expertise.\n  Since quantitative results from an ongoing performance competition were\nembargoed on paper submission date, we present the architectural design,\noperational workflow, and qualitative insights, highlighting the potential of\nLLM-driven agents to democratise and accelerate GPU kernel optimization,\nespecially in resource-constrained or rapidly evolving hardware environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21195", "pdf": "https://arxiv.org/pdf/2506.21195", "abs": "https://arxiv.org/abs/2506.21195", "authors": ["Neha Raghuvanshi"], "title": "Follow the user meaningfully and product growth will follow: A mixed methods case study tying UX Point of View & Growth leading to measurable impact", "categories": ["cs.HC"], "comment": null, "summary": "Have you wondered how cross-functional teams balance between maximizing value\nthat users derive and business growth leading to win-win situations? This case\nstudy shows how User Experience Research (UXR) and Data Science teams used\nmixed methods research to strategically influence Product Led Growth (PLG) for\na Password Manager used by million+ users, thus allowing our users, internal\nteams, and business to win. The audience will take away practical\nlessons/techniques related to leveraging mixed methods to: a. Maximize user\nvalue while meeting business growth goals b. Influence cross-functional teams\nc. Measure user and business impact This case study can be easily tied to the\nUXR Point of view pyramid (POV) [2] that represents a methodological approach\nto construct a POV and further dives into actioning POV to create measurable\nuser and business impact.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21134", "pdf": "https://arxiv.org/pdf/2506.21134", "abs": "https://arxiv.org/abs/2506.21134", "authors": ["Jacopo Bufalino", "Jose Luis Martin-Navarro", "Mario Di Francesco", "Tuomas Aura"], "title": "Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "Kubernetes has emerged as the de facto standard for container orchestration.\nUnfortunately, its increasing popularity has also made it an attractive target\nfor malicious actors. Despite extensive research on securing Kubernetes, little\nattention has been paid to the impact of network configuration on the security\nof application deployments. This paper addresses this gap by conducting a\ncomprehensive analysis of network misconfigurations in a Kubernetes cluster\nwith specific reference to lateral movement. Accordingly, we carried out an\nextensive evaluation of 287 open-source applications belonging to six different\norganizations, ranging from IT companies and public entities to non-profits. As\na result, we identified 634 misconfigurations, well beyond what could be found\nby solutions in the state of the art. We responsibly disclosed our findings to\nthe concerned organizations and engaged in a discussion to assess their\nseverity. As of now, misconfigurations affecting more than thirty applications\nhave been fixed with the mitigations we proposed.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Kubernetes\u7f51\u7edc\u4e2d\u6a2a\u5411\u79fb\u52a8\u76f8\u5173\u7684\u914d\u7f6e\u9519\u8bef\uff0c\u5206\u6790\u4e86287\u4e2a\u5f00\u6e90\u5e94\u7528\uff0c\u53d1\u73b0\u4e86634\u4e2a\u914d\u7f6e\u95ee\u9898\uff0c\u8fdc\u8d85\u73b0\u6709\u5de5\u5177\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u534f\u52a9\u4fee\u590d\u4e8630\u591a\u4e2a\u5e94\u7528\u7684\u95ee\u9898\u3002", "motivation": "Kubernetes\u7684\u7f51\u7edc\u914d\u7f6e\u5bf9\u5b89\u5168\u90e8\u7f72\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u8bba\u6587\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u7279\u522b\u5173\u6ce8\u4e86\u6a2a\u5411\u79fb\u52a8\u76f8\u5173\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u8bba\u6587\u5bf9287\u4e2a\u5f00\u6e90\u5e94\u7528\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u8986\u76d6\u4e86\u516d\u7c7b\u7ec4\u7ec7\uff08IT\u516c\u53f8\u3001\u516c\u5171\u673a\u6784\u548c\u975e\u8425\u5229\u7ec4\u7ec7\u7b49\uff09\uff0c\u91cd\u70b9\u68c0\u6d4b\u7f51\u7edc\u914d\u7f6e\u9519\u8bef\u3002", "result": "\u5171\u53d1\u73b0634\u4e2a\u914d\u7f6e\u9519\u8bef\uff0c\u8fdc\u8d85\u73b0\u6709\u5de5\u5177\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u8d1f\u8d23\u4efb\u62ab\u9732\u534f\u52a9\u4fee\u590d\u4e8630\u591a\u4e2a\u5e94\u7528\u7684\u95ee\u9898\u3002", "conclusion": "Kubernetes\u7684\u7f51\u7edc\u914d\u7f6e\u9519\u8bef\u5bf9\u5b89\u5168\u90e8\u7f72\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u8bba\u6587\u7684\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u63d0\u5347\u5b9e\u9645\u5e94\u7528\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2506.20938", "pdf": "https://arxiv.org/pdf/2506.20938", "abs": "https://arxiv.org/abs/2506.20938", "authors": ["Joshua H. Davis", "Daniel Nichols", "Ishan Khillan", "Abhinav Bhatele"], "title": "ParEval-Repo: A Benchmark Suite for Evaluating LLMs with Repository-level HPC Translation Tasks", "categories": ["cs.DC"], "comment": "11 pages, 5 figures", "summary": "GPGPU architectures have become significantly diverse in recent years, which\nhas led to an emergence of a variety of specialized programming models and\nsoftware stacks to support them. While portable execution models exist, they\nstill require significant developer effort to port to and optimize for\ndifferent hardware architectures. Recent advances in large language models\n(LLMs) can help us reduce some of this programmer burden. In this paper, we\npresent a novel benchmark and testing framework, ParEval-Repo, which can be\nused to evaluate the efficacy of LLM-based approaches in automatically\ntranslating entire codebases across GPGPU execution models. ParEval-Repo\nincludes several scientific computing and AI mini-applications in a range of\nprogramming models, and levels of repository complexity. We use ParEval-Repo to\nevaluate a range of state-of-the-art open-source and commercial LLMs, with both\na non-agentic and a top-down agentic approach. We assess code generated by the\nLLMs and approaches in terms of compilability, functional correctness,\ncategories of build errors, and the cost of translation in terms of the number\nof inference tokens. Our results demonstrate that LLM translation of scientific\napplications is feasible for small programs but difficulty with generating\nfunctional build systems and cross-file dependencies pose challenges in scaling\nto larger codebases.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21246", "pdf": "https://arxiv.org/pdf/2506.21246", "abs": "https://arxiv.org/abs/2506.21246", "authors": ["Giorgos Demosthenous", "Chryssis Georgiou", "Eliada Polydorou"], "title": "From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting", "categories": ["q-fin.PM", "cs.AI", "cs.ET", "cs.LG", "q-fin.ST"], "comment": null, "summary": "This study investigates the impact of data source diversity on the\nperformance of cryptocurrency forecasting models by integrating various data\ncategories, including technical indicators, on-chain metrics, sentiment and\ninterest metrics, traditional market indices, and macroeconomic indicators. We\nintroduce the Crypto100 index, representing the top 100 cryptocurrencies by\nmarket capitalization, and propose a novel feature reduction algorithm to\nidentify the most impactful and resilient features from diverse data sources.\nOur comprehensive experiments demonstrate that data source diversity\nsignificantly enhances the predictive performance of forecasting models across\ndifferent time horizons. Key findings include the paramount importance of\non-chain metrics for both short-term and long-term predictions, the growing\nrelevance of traditional market indices and macroeconomic indicators for\nlonger-term forecasts, and substantial improvements in model accuracy when\ndiverse data sources are utilized. These insights help demystify the short-term\nand long-term driving factors of the cryptocurrency market and lay the\ngroundwork for developing more accurate and resilient forecasting models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21211", "pdf": "https://arxiv.org/pdf/2506.21211", "abs": "https://arxiv.org/abs/2506.21211", "authors": ["Quanming Liu", "Xupeng Bu", "Zhichao Yan", "Ru Li"], "title": "$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Automatic Program Repair (APR) is a core technology in software development\nand maintenance, with aims to enable automated defect repair with minimal human\nintervention. In recent years, the substantial advancements in Large Language\nModels (LLMs) and the Chain-of-Thought (CoT) techniques have significantly\nenhanced the reasoning capabilities of these models. However, due to the\ncomplex logic and multi-step reasoning ability needed, the application of CoT\ntechniques in the APR domain remains insufficient. This study systematically\nevaluates the performance of several common CoT techniques in APR tasks and\nproposes an innovative framework $T^3$, which integrates the powerful reasoning\ncapabilities of LLMs with tree search, effectively improving the precision of\ngenerating candidate repair solutions. Furthermore, $T^3$ provides valuable\nguidance for optimizing sample selection and repair strategies in APR tasks,\nestablishing a robust framework for achieving efficient automated debugging.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5728\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u4efb\u52a1\u4e2d\u5e38\u89c1\u7684CoT\u6280\u672f\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u9896\u7684\u6846\u67b6$T^3$\uff0c\u7ed3\u5408\u4e86LLMs\u7684\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u548c\u6811\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u65b9\u6848\u751f\u6210\u7684\u7cbe\u5ea6\u3002", "motivation": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u601d\u7ef4\u94fe\uff08CoT\uff09\u6280\u672f\u63d0\u5347\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u6548\u7387\uff0c\u4f46\u56e0APR\u9886\u57df\u5bf9\u590d\u6742\u903b\u8f91\u548c\u591a\u6b65\u63a8\u7406\u7684\u8981\u6c42\uff0cCoT\u6280\u672f\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u5f00\u53d1\u3002", "method": "\u63d0\u51fa$T^3$\u6846\u67b6\uff0c\u6574\u5408LLMs\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u6811\u641c\u7d22\u6280\u672f\uff0c\u4f18\u5316\u6837\u672c\u9009\u62e9\u548c\u4fee\u590d\u7b56\u7565\u3002", "result": "$T^3$\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u5019\u9009\u4fee\u590d\u65b9\u6848\u7684\u7cbe\u5ea6\uff0c\u5e76\u4e3aAPR\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8c03\u8bd5\u6846\u67b6\u3002", "conclusion": "$T^3$\u6846\u67b6\u4e3a\u9ad8\u6548\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c55\u793a\u4e86LLMs\u4e0e\u6811\u641c\u7d22\u7ed3\u5408\u5728APR\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.21272", "pdf": "https://arxiv.org/pdf/2506.21272", "abs": "https://arxiv.org/abs/2506.21272", "authors": ["Jiayi Zheng", "Xiaodong Cun"], "title": "FairyGen: Storied Cartoon Video from a Single Child-Drawn Character", "categories": ["cs.GR", "cs.CV", "cs.MM"], "comment": "Project Page: https://jayleejia.github.io/FairyGen/ ; Code:\n  https://github.com/GVCLab/FairyGen", "summary": "We propose FairyGen, an automatic system for generating story-driven cartoon\nvideos from a single child's drawing, while faithfully preserving its unique\nartistic style. Unlike previous storytelling methods that primarily focus on\ncharacter consistency and basic motion, FairyGen explicitly disentangles\ncharacter modeling from stylized background generation and incorporates\ncinematic shot design to support expressive and coherent storytelling. Given a\nsingle character sketch, we first employ an MLLM to generate a structured\nstoryboard with shot-level descriptions that specify environment settings,\ncharacter actions, and camera perspectives. To ensure visual consistency, we\nintroduce a style propagation adapter that captures the character's visual\nstyle and applies it to the background, faithfully retaining the character's\nfull visual identity while synthesizing style-consistent scenes. A shot design\nmodule further enhances visual diversity and cinematic quality through frame\ncropping and multi-view synthesis based on the storyboard. To animate the\nstory, we reconstruct a 3D proxy of the character to derive physically\nplausible motion sequences, which are then used to fine-tune an MMDiT-based\nimage-to-video diffusion model. We further propose a two-stage motion\ncustomization adapter: the first stage learns appearance features from\ntemporally unordered frames, disentangling identity from motion; the second\nstage models temporal dynamics using a timestep-shift strategy with frozen\nidentity weights. Once trained, FairyGen directly renders diverse and coherent\nvideo scenes aligned with the storyboard. Extensive experiments demonstrate\nthat our system produces animations that are stylistically faithful,\nnarratively structured natural motion, highlighting its potential for\npersonalized and engaging story animation. The code will be available at\nhttps://github.com/GVCLab/FairyGen", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.20994", "pdf": "https://arxiv.org/pdf/2506.20994", "abs": "https://arxiv.org/abs/2506.20994", "authors": ["M\u00e5ns I. Andersson", "Martin Karp", "Niclas Jansson", "Stefano Markidis"], "title": "Portable High-Performance Kernel Generation for a Computational Fluid Dynamics Code with DaCe", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "With the emergence of new high-performance computing (HPC) accelerators, such\nas Nvidia and AMD GPUs, efficiently targeting diverse hardware architectures\nhas become a major challenge for HPC application developers. The increasing\nhardware diversity in HPC systems often necessitates the development of\narchitecture-specific code, hindering the sustainability of large-scale\nscientific applications. In this work, we leverage DaCe, a data-centric\nparallel programming framework, to automate the generation of high-performance\nkernels. DaCe enables automatic code generation for multicore processors and\nvarious accelerators, reducing the burden on developers who would otherwise\nneed to rewrite code for each new architecture. Our study demonstrates DaCe's\ncapabilities by applying its automatic code generation to a critical\ncomputational kernel used in Computational Fluid Dynamics (CFD). Specifically,\nwe focus on Neko, a Fortran-based solver that employs the spectral-element\nmethod, which relies on small tensor operations. We detail the formulation of\nthis computational kernel using DaCe's Stateful Dataflow Multigraph (SDFG)\nrepresentation and discuss how this approach facilitates high-performance code\ngeneration. Additionally, we outline the workflow for seamlessly integrating\nDaCe's generated code into the Neko solver. Our results highlight the\nportability and performance of the generated code across multiple platforms,\nincluding Nvidia GH200, Nvidia A100, and AMD MI250X GPUs, with competitive\nperformance results. By demonstrating the potential of automatic code\ngeneration, we emphasise the feasibility of using portable solutions to ensure\nthe long-term sustainability of large-scale scientific applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528DaCe\u6846\u67b6\u81ea\u52a8\u5316\u751f\u6210\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u5185\u6838\uff0c\u4ee5\u5e94\u5bf9\u591a\u6837\u5316\u7684\u786c\u4ef6\u67b6\u6784\u6311\u6218\uff0c\u5e76\u4ee5CFD\u4e2d\u7684Neko\u6c42\u89e3\u5668\u4e3a\u4f8b\u5c55\u793a\u4e86\u5176\u4fbf\u643a\u6027\u548c\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u52a0\u901f\u5668\uff08\u5982Nvidia\u548cAMD GPU\uff09\u7684\u6d8c\u73b0\uff0c\u9488\u5bf9\u591a\u6837\u5316\u786c\u4ef6\u67b6\u6784\u7684\u9ad8\u6548\u7f16\u7a0b\u6210\u4e3a\u91cd\u5927\u6311\u6218\uff0c\u624b\u52a8\u5f00\u53d1\u7279\u5b9a\u67b6\u6784\u4ee3\u7801\u4f1a\u963b\u788d\u5927\u89c4\u6a21\u79d1\u5b66\u5e94\u7528\u7684\u53ef\u6301\u7eed\u6027\u3002", "method": "\u5229\u7528DaCe\u6846\u67b6\uff0c\u901a\u8fc7\u5176\u6570\u636e\u6d41\u591a\u56fe\uff08SDFG\uff09\u8868\u793a\u81ea\u52a8\u751f\u6210\u9ad8\u6027\u80fd\u4ee3\u7801\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230Fortran-based\u7684Neko\u6c42\u89e3\u5668\u4e2d\u3002", "result": "\u5728\u591a\u5e73\u53f0\u4e0a\uff08Nvidia GH200\u3001A100\u548cAMD MI250X GPU\uff09\u751f\u6210\u7684\u4ee3\u7801\u8868\u73b0\u51fa\u4fbf\u643a\u6027\u548c\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u53ef\u884c\uff0c\u53ef\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u5e94\u7528\u63d0\u4f9b\u53ef\u6301\u7eed\u7684\u4fbf\u643a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.21201", "pdf": "https://arxiv.org/pdf/2506.21201", "abs": "https://arxiv.org/abs/2506.21201", "authors": ["Zihao You", "Michael Crabb"], "title": "Subtitled Media Adaptations for People with Aphasia: Ongoing Accessibility Barriers and Emerging Design Practices", "categories": ["cs.HC"], "comment": "3 pages, 1 figure, Access InContext Workshop at CHI 2025 on 26th of\n  April", "summary": "The consumption of subtitles via TVs, laptops and smartphones has the\npotential to marginalize people based on their complex accessibility needs. The\ncurrent one-size-fits-all approach to this accessibility aid is no longer fit\nfor purpose and work is required to look at how it can be adapted to be\npersonalised for individual users based on individual context, content, and\nconsumption habits. People with Aphasia, for example, encounter significant\nchallenges in understanding subtitle texts.\n  We see our work as a call to action for more inclusive practices, focusing on\nhow the thoughts and opinions of people with aphasia can be included in media\nresearch. Our work investigates how to develop future media solutions for\npeople with aphasia to create a more inclusive media viewing environment. We\nbelieve the key to this is appropriate prototyping tools and methods to allow\nequitable inclusion in the system design process.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.21537", "pdf": "https://arxiv.org/pdf/2506.21537", "abs": "https://arxiv.org/abs/2506.21537", "authors": ["Nicholas S. DiBrita", "Jason Han", "Tirthak Patel"], "title": "ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers", "categories": ["quant-ph", "cs.CV", "cs.ET"], "comment": "ResQ will appear in the Proceedings of the IEEE International\n  Conference on Computer Vision (ICCV), 2025", "summary": "Research in quantum machine learning has recently proliferated due to the\npotential of quantum computing to accelerate machine learning. An area of\nmachine learning that has not yet been explored is neural ordinary differential\nequation (neural ODE) based residual neural networks (ResNets), which aim to\nimprove the effectiveness of neural networks using the principles of ordinary\ndifferential equations. In this work, we present our insights about why analog\nRydberg atom quantum computers are especially well-suited for ResNets. We also\nintroduce ResQ, a novel framework to optimize the dynamics of Rydberg atom\nquantum computers to solve classification problems in machine learning using\nanalog quantum neural ODEs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
