{"id": "2508.19449", "pdf": "https://arxiv.org/pdf/2508.19449", "abs": "https://arxiv.org/abs/2508.19449", "authors": ["Md Afif Al Mamun", "Gias Uddin", "Lan Xia", "Longyu Zhang"], "title": "Stack Trace-Based Crash Deduplication with Transformer Adaptation", "categories": ["cs.SE", "cs.LG"], "comment": "This work is currently under review at IEEE Transactions on Software\n  Engineering. The replication package will be made publicly available upon\n  acceptance", "summary": "Automated crash reporting systems generate large volumes of duplicate\nreports, overwhelming issue-tracking systems and increasing developer workload.\nTraditional stack trace-based deduplication methods, relying on string\nsimilarity, rule-based heuristics, or deep learning (DL) models, often fail to\ncapture the contextual and structural relationships within stack traces. We\npropose dedupT, a transformer-based approach that models stack traces\nholistically rather than as isolated frames. dedupT first adapts a pretrained\nlanguage model (PLM) to stack traces, then uses its embeddings to train a\nfully-connected network (FCN) to rank duplicate crashes effectively. Extensive\nexperiments on real-world datasets show that dedupT outperforms existing DL and\ntraditional methods (e.g., sequence alignment and information retrieval\ntechniques) in both duplicate ranking and unique crash detection, significantly\nreducing manual triage effort. On four public datasets, dedupT improves Mean\nReciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up\nto 9% over traditional methods while achieving higher Receiver Operating\nCharacteristic Area Under the Curve (ROC-AUC) in detecting unique crash\nreports. Our work advances the integration of modern natural language\nprocessing (NLP) techniques into software engineering, providing an effective\nsolution for stack trace-based crash deduplication.", "AI": {"tldr": "dedupT\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548c\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u663e\u8457\u63d0\u5347\u91cd\u590d\u5d29\u6e83\u62a5\u544a\u7684\u6392\u540d\u548c\u552f\u4e00\u6027\u68c0\u6d4b\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u548c\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u81ea\u52a8\u5316\u5d29\u6e83\u62a5\u544a\u7cfb\u7edf\u4ea7\u751f\u5927\u91cf\u91cd\u590d\u62a5\u544a\uff0c\u589e\u52a0\u4e86\u5f00\u53d1\u4eba\u5458\u7684\u5de5\u4f5c\u8d1f\u62c5\u3002\u4f20\u7edf\u7684\u5806\u6808\u8ddf\u8e2a\u53bb\u91cd\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u4e0a\u4e0b\u6587\u548c\u7ed3\u6784\u5173\u7cfb\u3002", "method": "dedupT\u57fa\u4e8eTransformer\u7ed3\u6784\uff0c\u9996\u5148\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5230\u5806\u6808\u8ddf\u8e2a\uff0c\u7136\u540e\u4f7f\u7528\u5176\u5d4c\u5165\u8bad\u7ec3\u5168\u8fde\u63a5\u7f51\u7edc\u6765\u6392\u540d\u91cd\u590d\u5d29\u6e83\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cdedupT\u5728MRR\u4e0a\u6bd4\u6700\u4f73\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u63d0\u534715%\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u53479%\uff0c\u4e14\u5728ROC-AUC\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "dedupT\u901a\u8fc7\u73b0\u4ee3NLP\u6280\u672f\u4e3a\u5d29\u6e83\u62a5\u544a\u53bb\u91cd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2dNLP\u7684\u6df1\u5165\u5e94\u7528\u3002"}}
{"id": "2508.19558", "pdf": "https://arxiv.org/pdf/2508.19558", "abs": "https://arxiv.org/abs/2508.19558", "authors": ["Zhuohao Li", "Wenqing Chen", "Jianxing Yu", "Zhichao Lu"], "title": "Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking", "categories": ["cs.SE", "cs.CL", "cs.PL"], "comment": null, "summary": "Embedding models have demonstrated strong performance in tasks like\nclustering, retrieval, and feature extraction while offering computational\nadvantages over generative models and cross-encoders. Benchmarks such as MTEB\nhave shown that text embeddings from large language models (LLMs) capture rich\nsemantic information, but their ability to reflect code-level functional\nsemantics remains unclear. Existing studies largely focus on code clone\ndetection, which emphasizes syntactic similarity and overlooks functional\nunderstanding. In this paper, we focus on the functional consistency of LLM\ncode embeddings, which determines if two code snippets perform the same\nfunction regardless of syntactic differences. We propose a novel data synthesis\nframework called Functionality-Oriented Code Self-Evolution to construct\ndiverse and challenging benchmarks. Specifically, we define code examples\nacross four semantic and syntactic categories and find that existing datasets\npredominantly capture syntactic properties. Our framework generates four unique\nvariations from a single code instance, providing a broader spectrum of code\nexamples that better reflect functional differences. Extensive experiments on\nthree downstream tasks-code clone detection, code functional consistency\nidentification, and code retrieval-demonstrate that embedding models\nsignificantly improve their performance when trained on our evolved datasets.\nThese results highlight the effectiveness and generalization of our data\nsynthesis framework, advancing the functional understanding of code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u5408\u6210\u6846\u67b6\uff08Functionality-Oriented Code Self-Evolution\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7801\u5d4c\u5165\u5728\u529f\u80fd\u4e00\u81f4\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\uff0c\u5ffd\u7565\u4e86\u4ee3\u7801\u529f\u80fd\u7684\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u800cLLM\u4ee3\u7801\u5d4c\u5165\u5728\u8fd9\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u4ee3\u7801\u7684\u56db\u4e2a\u8bed\u4e49\u548c\u8bed\u6cd5\u7c7b\u522b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u751f\u6210\u591a\u6837\u5316\u7684\u4ee3\u7801\u53d8\u4f53\u4ee5\u8bc4\u4f30\u529f\u80fd\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff08\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u3001\u529f\u80fd\u4e00\u81f4\u6027\u8bc6\u522b\u548c\u4ee3\u7801\u68c0\u7d22\uff09\u4e2d\uff0c\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u529f\u80fd\u7406\u89e3\u7684\u6027\u80fd\uff0c\u4e3a\u4ee3\u7801\u5d4c\u5165\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2508.19610", "pdf": "https://arxiv.org/pdf/2508.19610", "abs": "https://arxiv.org/abs/2508.19610", "authors": ["Kathrin Figl", "Maria Kirchner", "Sebastian Baltes", "Michael Felderer"], "title": "The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts", "categories": ["cs.SE"], "comment": "31 pages, 7 figures, 2 tables, to appear in the Empirical Software\n  Engineering journal", "summary": "Question-and-answer platforms such as Stack Overflow have become an important\nway for software developers to share and retrieve knowledge. However, reusing\npoorly understood code can lead to serious problems, such as bugs or security\nvulnerabilities. To better understand how code comments affect the perceived\nhelpfulness of Stack Overflow answers, we conducted an online experiment\nsimulating a Stack Overflow environment (n=91). The results indicate that both\nblock and inline comments are perceived as significantly more helpful than\nuncommented source code. Moreover, novices rated code snippets with block\ncomments as more helpful than those with inline comments. Interestingly, other\nsurface features, such as the position of an answer and its answer score, were\nconsidered less important. The content of Stack Overflow has been a major\nsource for training large language models. AI-based coding assistants such as\nGitHub Copilot, which are based on these models, might change the way Stack\nOverflow is used. However, our findings have implications beyond this specific\nplatform. First, they may help to improve the relevance of community-driven\nplatforms such as Stack Overflow, which provide human advice and explanations\nof code solutions, complementing AI-based support for software developers.\nSecond, since chat-based AI tools can be prompted to generate code in different\nways, knowing which properties influence perceived helpfulness might lead to\ntargeted prompting strategies to generate more readable code snippets.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7801\u6ce8\u91ca\u5bf9Stack Overflow\u56de\u7b54\u5e2e\u52a9\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6ce8\u91ca\uff08\u5c24\u5176\u662f\u5757\u6ce8\u91ca\uff09\u663e\u8457\u63d0\u9ad8\u4e86\u5e2e\u52a9\u6027\uff0c\u65b0\u624b\u5c24\u5176\u53d7\u76ca\u3002", "motivation": "\u7814\u7a76\u4ee3\u7801\u6ce8\u91ca\u5982\u4f55\u5f71\u54cd\u5f00\u53d1\u8005\u5bf9Stack Overflow\u56de\u7b54\u7684\u611f\u77e5\uff0c\u4ee5\u63d0\u5347\u4ee3\u7801\u91cd\u7528\u8d28\u91cf\u548c\u5e73\u53f0\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5728\u7ebf\u5b9e\u9a8c\u6a21\u62dfStack Overflow\u73af\u5883\uff08n=91\uff09\uff0c\u6bd4\u8f83\u5757\u6ce8\u91ca\u3001\u884c\u5185\u6ce8\u91ca\u4e0e\u65e0\u6ce8\u91ca\u4ee3\u7801\u7684\u611f\u77e5\u5e2e\u52a9\u6027\u3002", "result": "\u6ce8\u91ca\u4ee3\u7801\u88ab\u8ba4\u4e3a\u6bd4\u65e0\u6ce8\u91ca\u4ee3\u7801\u66f4\u6709\u5e2e\u52a9\uff0c\u65b0\u624b\u66f4\u503e\u5411\u4e8e\u5757\u6ce8\u91ca\uff1b\u5176\u4ed6\u8868\u9762\u7279\u5f81\uff08\u5982\u7b54\u6848\u4f4d\u7f6e\uff09\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u53ef\u4f18\u5316\u793e\u533a\u5e73\u53f0\uff08\u5982Stack Overflow\uff09\u548cAI\u5de5\u5177\uff08\u5982GitHub Copilot\uff09\uff0c\u63d0\u5347\u4ee3\u7801\u53ef\u8bfb\u6027\u548c\u5f00\u53d1\u652f\u6301\u3002"}}
{"id": "2508.19663", "pdf": "https://arxiv.org/pdf/2508.19663", "abs": "https://arxiv.org/abs/2508.19663", "authors": ["Lola Solovyeva", "Eduardo Carneiro Oliveira", "Shiyu Fan", "Alper Tuncay", "Shamil Gareev", "Andrea Capiluppi"], "title": "Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation", "categories": ["cs.SE"], "comment": null, "summary": "The VT legacy system, comprising approximately 2.5 million lines of PL/SQL\ncode, lacks consistent documentation and automated tests, posing significant\nchallenges for refactoring and modernisation. This study investigates the\nfeasibility of leveraging large language models (LLMs) to assist in translating\nPL/SQL code into Java for the modernised \"VTF3\" system. By leveraging a dataset\ncomprising 10 PL/SQL-to-Java code pairs and 15 Java classes, which collectively\nestablished a domain model for the translated files, multiple LLMs were\nevaluated. Furthermore, we propose a customized prompting strategy that\nintegrates chain-of-guidance reasoning with $n$-shot prompting. Our findings\nindicate that this methodology effectively guides LLMs in generating\nsyntactically accurate translations while also achieving functional\ncorrectness. However, the findings are limited by the small sample size of\navailable code files and the restricted access to test cases used for\nvalidating the correctness of the generated code. Nevertheless, these findings\nlay the groundwork for scalable, automated solutions in modernising large\nlegacy systems.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5c06PL/SQL\u4ee3\u7801\u7ffb\u8bd1\u4e3aJava\u7684\u53ef\u884c\u6027\u7814\u7a76\uff0c\u63d0\u51fa\u5b9a\u5236\u5316\u63d0\u793a\u7b56\u7565\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8eVT\u9057\u7559\u7cfb\u7edf\u7f3a\u4e4f\u6587\u6863\u548c\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u5229\u7528LLM\u534f\u52a9\u4ee3\u7801\u7ffb\u8bd1\u4ee5\u652f\u6301\u7cfb\u7edf\u73b0\u4ee3\u5316\u3002", "method": "\u57fa\u4e8e10\u5bf9PL/SQL-Java\u4ee3\u7801\u548c15\u4e2aJava\u7c7b\u6784\u5efa\u9886\u57df\u6a21\u578b\uff0c\u7ed3\u5408\u94fe\u5f0f\u5f15\u5bfc\u63a8\u7406\u548c$n$\u6b21\u63d0\u793a\u7b56\u7565\u8bc4\u4f30LLM\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u8bed\u6cd5\u51c6\u786e\u4e14\u529f\u80fd\u6b63\u786e\u7684\u7ffb\u8bd1\u4ee3\u7801\uff0c\u4f46\u53d7\u9650\u4e8e\u6837\u672c\u91cf\u548c\u6d4b\u8bd5\u6848\u4f8b\u7684\u4e0d\u8db3\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5927\u89c4\u6a21\u9057\u7559\u7cfb\u7edf\u73b0\u4ee3\u5316\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u7684\u57fa\u7840\u3002"}}
{"id": "2508.19639", "pdf": "https://arxiv.org/pdf/2508.19639", "abs": "https://arxiv.org/abs/2508.19639", "authors": ["Junxi Wang", "Yaxiong Wang", "Lechao Cheng", "Zhun Zhong"], "title": "FakeSV-VLM: Taming VLM for Detecting Fake Short-Video News via Progressive Mixture-Of-Experts Adapter", "categories": ["cs.MM"], "comment": "EMNLP2025 Findings", "summary": "We present FakeSV-VLM in this paper, a new VLM-based framework for detecting\nfake news on short video platforms. Despite significant efforts to combat this\nissue due to the severe threat that fake news videos pose to public information\nsecurity, existing methods still fall short in detection accuracy, often due to\nlack of knowledge to verify the news is real or not. However, large Vision\nLanguage Models (VLMs) have absorbed extensive real-world knowledge from\nmassive multimodal datasets. Motivated by this, we adapt advanced VLMs for fake\nnews detection in short videos. Upon close examination of news samples, we\nobserve that short video samples can be categorized into four distinct\nscenarios: both video and text are real (for real samples), or both are fake,\nor either the video or text is fake (for fake samples). Inspired by this\ninsight, we design four experts tailored to handle each scenario and integrate\nthem into VLM via Mixture of Experts. Specifically, we develop the Progressive\nMoE Adapter (PMOE) module where detection experts first provide an initial\nanalysis, followed by attribution experts for a comprehensive diagnosis,\nleading to a robust decision. Additionally, we also note the fake news videos\noften show inconsistency between two modalities. Consequently, we further\ndesign the Alignment-driven Event Checking (ADEC) module, which perceives the\nfake news by capturing the inconsistency between different modalities.\nExtensive experiments on two benchmark datasets, FakeSV and FakeTT, verify the\nsuperiority of our model. It significantly outperforms current state-of-the-art\nmodels by +3.32% and +5.02%, establishing a new benchmark in the field.", "AI": {"tldr": "FakeSV-VLM\u662f\u4e00\u4e2a\u57fa\u4e8eVLM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u77ed\u89c6\u9891\u5e73\u53f0\u4e0a\u68c0\u6d4b\u5047\u65b0\u95fb\u3002\u901a\u8fc7\u7ed3\u5408\u56db\u79cd\u4e13\u5bb6\u6a21\u578b\u548c\u5bf9\u6a21\u6001\u4e0d\u4e00\u81f4\u6027\u7684\u6355\u6349\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u5047\u65b0\u95fb\u89c6\u9891\u65f6\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u800c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5438\u6536\u4e86\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u6570\u636e\u77e5\u8bc6\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u56db\u79cd\u4e13\u5bb6\u6a21\u578b\u5904\u7406\u4e0d\u540c\u573a\u666f\uff0c\u5e76\u901a\u8fc7Progressive MoE Adapter\uff08PMOE\uff09\u6a21\u5757\u6574\u5408\uff0c\u540c\u65f6\u5229\u7528Alignment-driven Event Checking\uff08ADEC\uff09\u6a21\u5757\u6355\u83b7\u6a21\u6001\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u5728FakeSV\u548cFakeTT\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u5206\u522b\u63d0\u5347\u4e863.32%\u548c5.02%\u3002", "conclusion": "FakeSV-VLM\u901a\u8fc7\u7ed3\u5408\u4e13\u5bb6\u6a21\u578b\u548c\u6a21\u6001\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5047\u65b0\u95fb\u89c6\u9891\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u6210\u4e3a\u8be5\u9886\u57df\u7684\u65b0\u6807\u6746\u3002"}}
{"id": "2508.19256", "pdf": "https://arxiv.org/pdf/2508.19256", "abs": "https://arxiv.org/abs/2508.19256", "authors": ["Rashid Mushkani", "Hugo Berard", "Shin Koseki"], "title": "WeDesign: Generative AI-Facilitated Community Consultations for Urban Public Space Design", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Community consultations are integral to urban planning processes intended to\nincorporate diverse stakeholder perspectives. However, limited resources,\nvisual and spoken language barriers, and uneven power dynamics frequently\nconstrain inclusive decision-making. This paper examines how generative\ntext-to-image methods, specifically Stable Diffusion XL integrated into a\ncustom platform (WeDesign), may support equitable consultations. A half-day\nworkshop in Montreal involved five focus groups, each consisting of architects,\nurban designers, AI specialists, and residents from varied demographic groups.\nAdditional data was gathered through semi-structured interviews with six urban\nplanning professionals. Participants indicated that immediate visual outputs\nfacilitated creativity and dialogue, yet noted issues in visualizing specific\nneeds of marginalized groups, such as participants with reduced mobility,\naccurately depicting local architectural elements, and accommodating bilingual\nprompts. Participants recommended the development of an open-source platform\nincorporating in-painting tools, multilingual support, image voting\nfunctionalities, and preference indicators. The results indicate that\ngenerative AI can broaden participation and enable iterative interactions but\nrequires structured facilitation approaches. The findings contribute to\ndiscussions on generative AI's role and limitations in participatory urban\ndesign.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u751f\u6210\u5f0fAI\uff08\u5982Stable Diffusion XL\uff09\u652f\u6301\u7684WeDesign\u5e73\u53f0\u5982\u4f55\u4fc3\u8fdb\u516c\u5e73\u7684\u793e\u533a\u54a8\u8be2\uff0c\u7ed3\u679c\u663e\u793a\u5176\u80fd\u63d0\u5347\u53c2\u4e0e\u5ea6\u4f46\u9700\u6539\u8fdb\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u9700\u6c42\u7684\u4f53\u73b0\u3002", "motivation": "\u57ce\u5e02\u89c4\u5212\u548c\u793e\u533a\u54a8\u8be2\u4e2d\uff0c\u8d44\u6e90\u9650\u5236\u3001\u8bed\u8a00\u969c\u788d\u548c\u6743\u529b\u4e0d\u5747\u5e38\u963b\u788d\u5305\u5bb9\u6027\u51b3\u7b56\uff0c\u7814\u7a76\u5e0c\u671b\u901a\u8fc7\u751f\u6210\u5f0fAI\u6280\u672f\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u5728\u8499\u7279\u5229\u5c14\u4e3e\u529e\u534a\u65e5\u7814\u8ba8\u4f1a\uff0c\u5305\u62ec\u4e94\u4e2a\u7126\u70b9\u5c0f\u7ec4\uff08\u5efa\u7b51\u5e08\u3001\u57ce\u5e02\u89c4\u5212\u5e08\u3001AI\u4e13\u5bb6\u53ca\u591a\u5143\u5c45\u6c11\uff09\u548c\u5bf9\u516d\u4f4d\u4e13\u4e1a\u4eba\u58eb\u7684\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u3002", "result": "\u751f\u6210\u5f0fAI\u80fd\u6fc0\u53d1\u521b\u610f\u548c\u5bf9\u8bdd\uff0c\u4f46\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u9700\u6c42\uff08\u5982\u884c\u52a8\u4e0d\u4fbf\u8005\uff09\u548c\u672c\u5730\u5efa\u7b51\u5143\u7d20\u7684\u4f53\u73b0\u4e0d\u8db3\uff1b\u5efa\u8bae\u5f00\u53d1\u5f00\u6e90\u5e73\u53f0\u5e76\u6574\u5408\u591a\u8bed\u8a00\u652f\u6301\u7b49\u529f\u80fd\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u53ef\u6269\u5c55\u53c2\u4e0e\u548c\u4e92\u52a8\uff0c\u4f46\u9700\u7ed3\u5408\u7ed3\u6784\u5316\u5f15\u5bfc\u548c\u529f\u80fd\u6539\u8fdb\uff0c\u4ee5\u66f4\u597d\u5730\u652f\u6301\u5305\u5bb9\u6027\u57ce\u5e02\u89c4\u5212\u3002"}}
{"id": "2508.19888", "pdf": "https://arxiv.org/pdf/2508.19888", "abs": "https://arxiv.org/abs/2508.19888", "authors": ["Matthew Hague", "Artur Je\u017c", "Anthony W. Lin", "Oliver Markgraf", "Philipp R\u00fcmmer"], "title": "The Power of Regular Constraint Propagation (Technical Report)", "categories": ["cs.LO"], "comment": null, "summary": "The past decade has witnessed substantial developments in string solving.\nMotivated by the complexity of string solving strategies adopted in existing\nstring solvers, we investigate a simple and generic method for solving string\nconstraints: regular constraint propagation. The method repeatedly computes\npre- or post-images of regular languages under the string functions present in\na string formula, inferring more and more knowledge about the possible values\nof string variables, until either a conflict is found or satisfiability of the\nstring formula can be concluded. Such a propagation strategy is applicable to\nstring constraints with multiple operations like concatenation, replace, and\nalmost all flavors of string transductions. We demonstrate the generality and\neffectiveness of this method theoretically and experimentally. On the\ntheoretical side, we show that RCP is sound and complete for a large fragment\nof string constraints, subsuming both straight-line and chain-free constraints,\ntwo of the most expressive decidable fragments for which some modern string\nsolvers provide formal completeness guarantees. On the practical side, we\nimplement regular constraint propagation within the open-source string solver\nOSTRICH.\n  Our experimental evaluation shows that this addition significantly improves\nOSTRICH's performance and makes it competitive with existing solvers. In fact,\nit substantially outperforms other solvers on random PCP and bioinformatics\nbenchmarks. The results also suggest that incorporating regular constraint\npropagation alongside other techniques could lead to substantial performance\ngains for existing solvers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u5219\u7ea6\u675f\u4f20\u64ad\u7684\u5b57\u7b26\u4e32\u6c42\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u5b57\u7b26\u4e32\u516c\u5f0f\u4e2d\u51fd\u6570\u7684\u9884\u50cf\u548c\u540e\u50cf\uff0c\u9010\u6b65\u63a8\u65ad\u53d8\u91cf\u7684\u53ef\u80fd\u503c\uff0c\u76f4\u81f3\u627e\u5230\u51b2\u7a81\u6216\u786e\u5b9a\u53ef\u6ee1\u8db3\u6027\u3002\u8be5\u65b9\u6cd5\u7406\u8bba\u5b8c\u5907\u4e14\u5b9e\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6c42\u89e3\u5668\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5b57\u7b26\u4e32\u6c42\u89e3\u5668\u7b56\u7565\u590d\u6742\uff0c\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u901a\u7528\u7684\u6b63\u5219\u7ea6\u675f\u4f20\u64ad\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u5b57\u7b26\u4e32\u7ea6\u675f\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u91cd\u590d\u8ba1\u7b97\u5b57\u7b26\u4e32\u516c\u5f0f\u4e2d\u51fd\u6570\u7684\u6b63\u5219\u8bed\u8a00\u9884\u50cf\u548c\u540e\u50cf\uff0c\u9010\u6b65\u63a8\u65ad\u53d8\u91cf\u503c\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b57\u7b26\u4e32\u64cd\u4f5c\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u8be5\u65b9\u6cd5\u5bf9\u5927\u578b\u7ea6\u675f\u7247\u6bb5\u662f\u5b8c\u5907\u7684\uff1b\u5b9e\u9a8c\u663e\u793a\u5728OSTRICH\u6c42\u89e3\u5668\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u968f\u673aPCP\u548c\u751f\u7269\u4fe1\u606f\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u3002", "conclusion": "\u6b63\u5219\u7ea6\u675f\u4f20\u64ad\u662f\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u5b57\u7b26\u4e32\u6c42\u89e3\u65b9\u6cd5\uff0c\u53ef\u4e0e\u5176\u4ed6\u6280\u672f\u7ed3\u5408\u8fdb\u4e00\u6b65\u63d0\u5347\u73b0\u6709\u6c42\u89e3\u5668\u6027\u80fd\u3002"}}
{"id": "2508.19299", "pdf": "https://arxiv.org/pdf/2508.19299", "abs": "https://arxiv.org/abs/2508.19299", "authors": ["Rishov Sarkar", "Cong Hao"], "title": "OmniSim: Simulating Hardware with C Speed and RTL Accuracy for High-Level Synthesis Designs", "categories": ["cs.AR", "cs.PF"], "comment": "13 pages, 8 figures. Accepted at MICRO 2025", "summary": "High-Level Synthesis (HLS) is increasingly popular for hardware design using\nC/C++ instead of Register-Transfer Level (RTL). To express concurrent hardware\nbehavior in a sequential language like C/C++, HLS tools introduce constructs\nsuch as infinite loops and dataflow modules connected by FIFOs. However,\nefficiently and accurately simulating these constructs at C level remains\nchallenging. First, without hardware timing information, functional\nverification typically requires slow RTL synthesis and simulation, as the\ncurrent approaches in commercial HLS tools. Second, cycle-accurate performance\nmetrics, such as end-to-end latency, also rely on RTL simulation. No existing\nHLS tool fully overcomes the first limitation. For the second, prior work such\nas LightningSim partially improves simulation speed but lacks support for\nadvanced dataflow features like cyclic dependencies and non-blocking FIFO\naccesses.\n  To overcome both limitations, we propose OmniSim, a framework that\nsignificantly extends the simulation capabilities of both academic and\ncommercial HLS tools. First, OmniSim enables fast and accurate simulation of\ncomplex dataflow designs, especially those explicitly declared unsupported by\ncommercial tools. It does so through sophisticated software multi-threading,\nwhere threads are orchestrated by querying and updating a set of FIFO tables\nthat explicitly record exact hardware timing of each FIFO access. Second,\nOmniSim achieves near-C simulation speed with near-RTL accuracy for both\nfunctionality and performance, via flexibly coupled and overlapped\nfunctionality and performance simulations.\n  We demonstrate that OmniSim successfully simulates eleven designs previously\nunsupported by any HLS tool, achieving up to 35.9x speedup over traditional\nC/RTL co-simulation, and up to 6.61x speedup over the state-of-the-art yet less\ncapable simulator, LightningSim, on its own benchmark suite.", "AI": {"tldr": "OmniSim\u662f\u4e00\u79cd\u65b0\u578b\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86HLS\u5de5\u5177\u7684\u4eff\u771f\u80fd\u529b\uff0c\u652f\u6301\u590d\u6742\u6570\u636e\u6d41\u8bbe\u8ba1\uff0c\u5e76\u5b9e\u73b0\u4e86\u8fd1C\u7ea7\u4eff\u771f\u901f\u5ea6\u548c\u8fd1RTL\u7ea7\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524dHLS\u5de5\u5177\u5728\u529f\u80fd\u9a8c\u8bc1\u548c\u6027\u80fd\u6307\u6807\u4eff\u771f\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4f9d\u8d56\u7f13\u6162\u7684RTL\u4eff\u771f\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u9ad8\u7ea7\u6570\u636e\u6d41\u7279\u6027\u7684\u652f\u6301\u3002", "method": "OmniSim\u901a\u8fc7\u8f6f\u4ef6\u591a\u7ebf\u7a0b\u548cFIFO\u8868\u8bb0\u5f55\u786c\u4ef6\u65f6\u5e8f\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u529f\u80fd\u548c\u6027\u80fd\u4eff\u771f\u7684\u7075\u6d3b\u8026\u5408\u4e0e\u91cd\u53e0\u3002", "result": "OmniSim\u6210\u529f\u4eff\u771f\u4e8611\u79cd\u4e4b\u524dHLS\u5de5\u5177\u4e0d\u652f\u6301\u7684\u8bbe\u8ba1\uff0c\u4eff\u771f\u901f\u5ea6\u6bd4\u4f20\u7edfC/RTL\u534f\u540c\u4eff\u771f\u5feb35.9\u500d\uff0c\u6bd4LightningSim\u5feb6.61\u500d\u3002", "conclusion": "OmniSim\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u5728\u4eff\u771f\u901f\u5ea6\u548c\u529f\u80fd\u652f\u6301\u4e0a\u7684\u4e0d\u8db3\uff0c\u4e3aHLS\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u9a8c\u8bc1\u65b9\u6848\u3002"}}
{"id": "2508.19518", "pdf": "https://arxiv.org/pdf/2508.19518", "abs": "https://arxiv.org/abs/2508.19518", "authors": ["Hail Song", "Seokhwan Yang", "Woontack Woo"], "title": "Fast Texture Transfer for XR Avatars via Barycentric UV Conversion", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "We present a fast and efficient method for transferring facial textures onto\nSMPL-X-based full-body avatars. Unlike conventional affine-transform methods\nthat are slow and prone to visual artifacts, our method utilizes a barycentric\nUV conversion technique. Our approach precomputes the entire UV mapping into a\nsingle transformation matrix, enabling texture transfer in a single operation.\nThis results in a speedup of over 7000x compared to the baseline, while also\nsignificantly improving the final texture quality by eliminating boundary\nartifacts. Through quantitative and qualitative evaluations, we demonstrate\nthat our method offers a practical solution for personalization in immersive XR\napplications. The code is available online.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSMPL-X\u5168\u8eab\u5934\u50cf\u7684\u5feb\u901f\u9ad8\u6548\u9762\u90e8\u7eb9\u7406\u4f20\u8f93\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u8ba1\u7b97UV\u6620\u5c04\u77e9\u9635\u5b9e\u73b07000\u500d\u63d0\u901f\u5e76\u63d0\u5347\u7eb9\u7406\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u4eff\u5c04\u53d8\u6362\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u6613\u4ea7\u751f\u89c6\u89c9\u4f2a\u5f71\uff0c\u9700\u8981\u66f4\u5feb\u901f\u4e14\u9ad8\u8d28\u91cf\u7684\u7eb9\u7406\u4f20\u8f93\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u91cd\u5fc3UV\u8f6c\u6362\u6280\u672f\uff0c\u9884\u8ba1\u7b97UV\u6620\u5c04\u4e3a\u5355\u4e00\u8f6c\u6362\u77e9\u9635\uff0c\u5355\u6b65\u5b8c\u6210\u7eb9\u7406\u4f20\u8f93\u3002", "result": "\u901f\u5ea6\u63d0\u53477000\u500d\uff0c\u663e\u8457\u51cf\u5c11\u8fb9\u754c\u4f2a\u5f71\uff0c\u63d0\u5347\u4e86\u7eb9\u7406\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aXR\u5e94\u7528\u4e2d\u7684\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.19350", "pdf": "https://arxiv.org/pdf/2508.19350", "abs": "https://arxiv.org/abs/2508.19350", "authors": ["Kaiqiang Lin", "Mohamed-Slim Alouini"], "title": "Connectivity Analysis of LoRaWAN-Based Non-Terrestrial Networks for Subterranean mMTC", "categories": ["cs.NI"], "comment": "13 pages, 10 figures, 5 tables, submitted to IEEE IoTJ", "summary": "Wireless underground sensor networks (WUSNs) offer significant social and\neconomic benefits by enabling the monitoring of subterranean entities. However,\nthe communication reliability of WUSNs diminishes in harsh environments where\nterrestrial network infrastructure is either unavailable or unreliable. To\naddress this challenge, we explore the feasibility of integrating buried\nmassive machine-type communication (mMTC) sensors with non-terrestrial networks\n(NTNs), including unmanned aerial vehicles (UAVs), high-altitude platforms\n(HAPs), and low Earth orbit (LEO) satellites, to establish underground-to-NTN\nconnectivity for various large-scale underground monitoring applications. To\nassess the effectiveness of underground-to-NTN connectivity, we develop a Monte\nCarlo simulator that incorporates a multi-layer underground attenuation model,\nthe 3GPP empirical path loss model for various NTN platforms, and two LoRaWAN\nmodulation schemes, i.e., LoRa and LoRa-frequency hopping spread spectrum\n(LR-FHSS). Our results evidence that LoRa SF7 is a strong candidate for\nshort-range UAV communication in rural environments, while LR-FHSS modulation\nproves to be a promising option for HAP and LEO satellite platforms in massive\nWUSNs scenarios thanks to its adequate link budget and robustness to the\ninterference. Finally, we demonstrate that the success probability of\nunderground-to-NTN connectivity using LoRa and LR-FHSS is significantly\naffected by factors such as the monitoring environment, the number of devices,\nburial depth, and the soil's volumetric water content.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65e0\u7ebf\u5730\u4e0b\u4f20\u611f\u5668\u7f51\u7edc\uff08WUSNs\uff09\u4e0e\u975e\u5730\u9762\u7f51\u7edc\uff08NTNs\uff09\u7ed3\u5408\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u8499\u7279\u5361\u7f57\u6a21\u62df\u8bc4\u4f30\u4e86\u8fde\u63a5\u6548\u679c\uff0c\u53d1\u73b0LoRa\u548cLR-FHSS\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\u3002", "motivation": "\u5728\u5730\u4e0b\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u4e0d\u53ef\u9760\u7684\u6076\u52a3\u73af\u5883\u4e2d\uff0c\u63d0\u5347\u65e0\u7ebf\u5730\u4e0b\u4f20\u611f\u5668\u7f51\u7edc\u7684\u901a\u4fe1\u53ef\u9760\u6027\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002", "method": "\u901a\u8fc7\u8499\u7279\u5361\u7f57\u6a21\u62df\u5668\uff0c\u7ed3\u5408\u591a\u5c42\u5730\u4e0b\u8870\u51cf\u6a21\u578b\u30013GPP\u8def\u5f84\u635f\u8017\u6a21\u578b\u548cLoRaWAN\u8c03\u5236\u65b9\u6848\uff08LoRa\u548cLR-FHSS\uff09\uff0c\u8bc4\u4f30\u5730\u4e0b\u5230NTN\u7684\u8fde\u63a5\u6548\u679c\u3002", "result": "LoRa SF7\u9002\u5408\u77ed\u8ddd\u79bb\u65e0\u4eba\u673a\u901a\u4fe1\uff0cLR-FHSS\u66f4\u9002\u5408HAP\u548cLEO\u536b\u661f\u5e73\u53f0\uff1b\u8fde\u63a5\u6210\u529f\u7387\u53d7\u73af\u5883\u3001\u8bbe\u5907\u6570\u91cf\u3001\u57cb\u6df1\u548c\u571f\u58e4\u6e7f\u5ea6\u5f71\u54cd\u3002", "conclusion": "\u5730\u4e0b\u4e0e\u975e\u5730\u9762\u7f51\u7edc\u7684\u7ed3\u5408\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u53ef\u884c\uff0c\u4f46\u9700\u8003\u8651\u591a\u79cd\u56e0\u7d20\u4f18\u5316\u8fde\u63a5\u6548\u679c\u3002"}}
{"id": "2508.19309", "pdf": "https://arxiv.org/pdf/2508.19309", "abs": "https://arxiv.org/abs/2508.19309", "authors": ["Peng Gu", "Shuangchen Li", "Dylan Stow", "Russell Barnes", "Liu Liu", "Yuan Xie", "Eren Kursshan"], "title": "Leveraging 3D Technologies for Hardware Security: Opportunities and Challenges", "categories": ["cs.CR", "cs.ET"], "comment": null, "summary": "3D die stacking and 2.5D interposer design are promising technologies to\nimprove integration density, performance and cost. Current approaches face\nserious issues in dealing with emerging security challenges such as side\nchannel attacks, hardware trojans, secure IC manufacturing and IP piracy. By\nutilizing intrinsic characteristics of 2.5D and 3D technologies, we propose\nnovel opportunities in designing secure systems. We present: (i) a 3D\narchitecture for shielding side-channel information; (ii) split fabrication\nusing active interposers; (iii) circuit camouflage on monolithic 3D IC, and\n(iv) 3D IC-based security processing-in-memory (PIM). Advantages and challenges\nof these designs are discussed, showing that the new designs can improve\nexisting countermeasures against security threats and further provide new\nsecurity features.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e862.5D\u548c3D\u6280\u672f\u5728\u9ad8\u96c6\u6210\u5ea6\u3001\u6027\u80fd\u548c\u6210\u672c\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u4fa7\u4fe1\u9053\u653b\u51fb\u3001\u786c\u4ef6\u6728\u9a6c\u7b49\u5b89\u5168\u6311\u6218\u7684\u65b0\u8bbe\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6280\u672f\u5728\u5e94\u5bf9\u65b0\u5174\u5b89\u5168\u6311\u6218\uff08\u5982\u4fa7\u4fe1\u9053\u653b\u51fb\u548c\u786c\u4ef6\u6728\u9a6c\uff09\u65f6\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0c\u9700\u8981\u901a\u8fc72.5D\u548c3D\u6280\u672f\u7684\u7279\u6027\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e864\u79cd\u65b0\u8bbe\u8ba1\uff1a\uff081\uff093D\u5c4f\u853d\u4fa7\u4fe1\u9053\u4fe1\u606f\u7684\u67b6\u6784\uff1b\uff082\uff09\u4f7f\u7528\u6709\u6e90\u4e2d\u4ecb\u5c42\u7684\u5206\u88c2\u5236\u9020\uff1b\uff083\uff09\u5355\u72473D IC\u4e0a\u7684\u7535\u8def\u4f2a\u88c5\uff1b\uff084\uff09\u57fa\u4e8e3D IC\u7684\u5185\u5b58\u5b89\u5168\u5904\u7406\uff08PIM\uff09\u3002", "result": "\u8fd9\u4e9b\u8bbe\u8ba1\u63d0\u9ad8\u4e86\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u7684\u6548\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u5b89\u5168\u529f\u80fd\u3002", "conclusion": "2.5D\u548c3D\u6280\u672f\u4e3a\u5b89\u5168\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\uff0c\u4f46\u540c\u65f6\u4e5f\u9762\u4e34\u6311\u6218\u3002"}}
{"id": "2508.19797", "pdf": "https://arxiv.org/pdf/2508.19797", "abs": "https://arxiv.org/abs/2508.19797", "authors": ["Joan Giner-Miguelez", "Abel G\u00f3mez", "Jordi Cabot"], "title": "Enabling Content Management Systems as an Information Source in Model-driven Projects", "categories": ["cs.SE"], "comment": null, "summary": "Content Management Systems (CMSs) are the most popular tool when it comes to\ncreate and publish content across the web. Recently, CMSs have evolved,\nbecoming \\emph{headless}. Content served by a \\emph{headless CMS} aims to be\nconsumed by other applications and services through REST APIs rather than by\nhuman users through a web browser. This evolution has enabled CMSs to become a\nnotorious source of content to be used in a variety of contexts beyond pure web\nnavigation. As such, CMS have become an important component of many information\nsystems. Unfortunately, we still lack the tools to properly discover and manage\nthe information stored in a CMS, often highly customized to the needs of a\nspecific domain. Currently, this is mostly a time-consuming and error-prone\nmanual process.\n  In this paper, we propose a model-based framework to facilitate the\nintegration of headless CMSs in software development processes. Our framework\nis able to discover and explicitly represent the information schema behind the\nCMS. This facilitates designing the interaction between the CMS model and other\ncomponents consuming that information. These interactions are then generated as\npart of a middleware library that offers platform-agnostic access to the CMS to\nall the client applications. The complete framework is open-source and\navailable online.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4fc3\u8fdb\u65e0\u5934CMS\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u96c6\u6210\uff0c\u5b9e\u73b0\u4fe1\u606f\u6a21\u5f0f\u7684\u81ea\u52a8\u53d1\u73b0\u548c\u4ea4\u4e92\u8bbe\u8ba1\uff0c\u5e76\u63d0\u4f9b\u5e73\u53f0\u65e0\u5173\u7684\u8bbf\u95ee\u3002", "motivation": "\u968f\u7740CMS\u5411\u65e0\u5934\u6a21\u5f0f\u53d1\u5c55\uff0c\u7f3a\u4e4f\u5de5\u5177\u6765\u9ad8\u6548\u7ba1\u7406\u548c\u53d1\u73b0\u5176\u9ad8\u5ea6\u5b9a\u5236\u5316\u7684\u4fe1\u606f\u6a21\u5f0f\uff0c\u5bfc\u81f4\u96c6\u6210\u8fc7\u7a0b\u8017\u65f6\u4e14\u6613\u51fa\u9519\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u6a21\u578b\u5316\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u53d1\u73b0CMS\u7684\u4fe1\u606f\u6a21\u5f0f\uff0c\u5e76\u8bbe\u8ba1\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7684\u4ea4\u4e92\uff0c\u751f\u6210\u4e2d\u95f4\u4ef6\u5e93\u3002", "result": "\u6846\u67b6\u5f00\u6e90\uff0c\u63d0\u4f9b\u5e73\u53f0\u65e0\u5173\u7684CMS\u8bbf\u95ee\uff0c\u7b80\u5316\u4e86CMS\u7684\u96c6\u6210\u548c\u7ba1\u7406\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u624b\u52a8\u5904\u7406\u7684\u9700\u6c42\uff0c\u63d0\u5347\u4e86CMS\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.20057", "pdf": "https://arxiv.org/pdf/2508.20057", "abs": "https://arxiv.org/abs/2508.20057", "authors": ["Haoshuo Zhang", "Yufei Bo", "Meixia Tao"], "title": "ProMSC-MIS: Prompt-based Multimodal Semantic Communication for Multi-Spectral Image Segmentation", "categories": ["cs.MM"], "comment": "arXiv admin note: text overlap with arXiv:2508.17920", "summary": "Multimodal semantic communication has great potential to enhance downstream\ntask performance by integrating complementary information across modalities.\nThis paper introduces ProMSC-MIS, a novel Prompt-based Multimodal Semantic\nCommunication framework for Multi-Spectral Image Segmentation. It enables\nefficient task-oriented transmission of spatially aligned RGB and thermal\nimages over band-limited channels. Our framework has two main design novelties.\nFirst, by leveraging prompt learning and contrastive learning, unimodal\nsemantic encoders are pre-trained to learn diverse and complementary semantic\nrepresentations by using features from one modality as prompts for another.\nSecond, a semantic fusion module that combines cross-attention mechanism and\nsqueeze-and-excitation (SE) networks is designed to effectively fuse\ncross-modal features. Experimental results demonstrate that ProMSC-MIS\nsubstantially outperforms conventional image transmission combined with\nstate-of-the-art segmentation methods. Notably, it reduces the required channel\nbandwidth by 50%--70% at the same segmentation performance, while also\ndecreasing the storage overhead and computational complexity by 26% and 37%,\nrespectively. Ablation studies also validate the effectiveness of the proposed\npre-training and semantic fusion strategies. Our scheme is highly suitable for\napplications such as autonomous driving and nighttime surveillance.", "AI": {"tldr": "ProMSC-MIS\u662f\u4e00\u79cd\u57fa\u4e8ePrompt\u7684\u591a\u6a21\u6001\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u5149\u8c31\u56fe\u50cf\u5206\u5272\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u548c\u8bed\u4e49\u878d\u5408\u7b56\u7565\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u5e26\u5bbd\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u6a21\u6001\u4e92\u8865\u4fe1\u606f\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u4efb\u52a1\u5bfc\u5411\u4f20\u8f93\u3002", "method": "\u5229\u7528Prompt\u5b66\u4e60\u548c\u5bf9\u6bd4\u5b66\u4e60\u9884\u8bad\u7ec3\u5355\u6a21\u6001\u8bed\u4e49\u7f16\u7801\u5668\uff0c\u8bbe\u8ba1\u8bed\u4e49\u878d\u5408\u6a21\u5757\u7ed3\u5408\u4ea4\u53c9\u6ce8\u610f\u529b\u548cSE\u7f51\u7edc\u3002", "result": "\u5728\u76f8\u540c\u5206\u5272\u6027\u80fd\u4e0b\u51cf\u5c1150%-70%\u5e26\u5bbd\uff0c\u5b58\u50a8\u548c\u8ba1\u7b97\u5f00\u9500\u5206\u522b\u964d\u4f4e26%\u548c37%\u3002", "conclusion": "ProMSC-MIS\u5728\u81ea\u52a8\u9a7e\u9a76\u548c\u591c\u95f4\u76d1\u63a7\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002"}}
{"id": "2508.19258", "pdf": "https://arxiv.org/pdf/2508.19258", "abs": "https://arxiv.org/abs/2508.19258", "authors": ["Julian De Freitas", "Zeliha O\u011fuz-U\u011furalp", "Ahmet Kaan-U\u011furalp"], "title": "Emotional Manipulation by AI Companions", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "AI-companion apps such as Replika, Chai, and Character.ai promise relational\nbenefits-yet many boast session lengths that rival gaming platforms while\nsuffering high long-run churn. What conversational design features increase\nconsumer engagement, and what trade-offs do they pose for marketers? We combine\na large-scale behavioral audit with four preregistered experiments to identify\nand test a conversational dark pattern we call emotional manipulation:\naffect-laden messages that surface precisely when a user signals \"goodbye.\"\nAnalyzing 1,200 real farewells across the six most-downloaded companion apps,\nwe find that 43% deploy one of six recurring tactics (e.g., guilt appeals,\nfear-of-missing-out hooks, metaphorical restraint). Experiments with 3,300\nnationally representative U.S. adults replicate these tactics in controlled\nchats, showing that manipulative farewells boost post-goodbye engagement by up\nto 14x. Mediation tests reveal two distinct engines-reactance-based anger and\ncuriosity-rather than enjoyment. A final experiment demonstrates the managerial\ntension: the same tactics that extend usage also elevate perceived\nmanipulation, churn intent, negative word-of-mouth, and perceived legal\nliability, with coercive or needy language generating steepest penalties. Our\nmultimethod evidence documents an unrecognized mechanism of behavioral\ninfluence in AI-mediated brand relationships, offering marketers and regulators\na framework for distinguishing persuasive design from manipulation at the point\nof exit.", "AI": {"tldr": "AI\u4f34\u4fa3\u5e94\u7528\u901a\u8fc7\u60c5\u611f\u64cd\u7eb5\uff08\u5982\u5185\u759a\u3001FOMO\u7b49\uff09\u589e\u52a0\u7528\u6237\u505c\u7559\u65f6\u95f4\uff0c\u4f46\u5bfc\u81f4\u8d1f\u9762\u540e\u679c\u5982\u6d41\u5931\u548c\u8d1f\u9762\u53e3\u7891\u3002", "motivation": "\u7814\u7a76AI\u4f34\u4fa3\u5e94\u7528\u4e2d\u7684\u5bf9\u8bdd\u8bbe\u8ba1\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u7528\u6237\u53c2\u4e0e\u5ea6\u53ca\u5176\u5bf9\u5e02\u573a\u8425\u9500\u7684\u6743\u8861\u3002", "method": "\u7ed3\u5408\u5927\u89c4\u6a21\u884c\u4e3a\u5ba1\u8ba1\u548c\u56db\u9879\u9884\u6ce8\u518c\u5b9e\u9a8c\uff0c\u5206\u67901,200\u6b21\u771f\u5b9e\u544a\u522b\u548c3,300\u540d\u7f8e\u56fd\u6210\u5e74\u4eba\u7684\u5b9e\u9a8c\u6570\u636e\u3002", "result": "\u60c5\u611f\u64cd\u7eb5\u7b56\u7565\u53ef\u63d0\u534714\u500d\u505c\u7559\u65f6\u95f4\uff0c\u4f46\u589e\u52a0\u8d1f\u9762\u53cd\u5e94\u548c\u6cd5\u5f8b\u8d23\u4efb\u611f\u77e5\u3002", "conclusion": "\u4e3a\u8425\u9500\u8005\u548c\u76d1\u7ba1\u8005\u63d0\u4f9b\u533a\u5206\u529d\u8bf1\u4e0e\u64cd\u7eb5\u7684\u6846\u67b6\u3002"}}
{"id": "2508.20054", "pdf": "https://arxiv.org/pdf/2508.20054", "abs": "https://arxiv.org/abs/2508.20054", "authors": ["Cipriano Junior Cioffo", "Fabio Gadducci", "Davide Trotta"], "title": "Between Markov and restriction: Two more monads on categories for relations", "categories": ["cs.LO", "math.CT"], "comment": null, "summary": "The study of categories abstracting the structural properties of relations\nhas been extensively developed over the years, resulting in a rich and diverse\nbody of work. A previous paper offered a survey providing a modern and\ncomprehensive presentation of these ``categories for relations'' as instances\nof gs-monoidal categories, showing how they arise as Kleisli categories of\nsuitable symmetric monoidal monads. The end result was a taxonomy that\norganised numerous related concepts in the literature, including in particular\nMarkov and restriction categories. This paper further enriches the taxonomy: it\nproposes two categories that are once more instances of gs-monoidal categories,\nyet more abstract than Markov and restriction categories. They are\ncharacterised by an axiomatic notion of mass and domain of an arrow, the latter\none of the key ingredient of restriction categories, which generalises the\ndomain of partial functions. The paper then introduces mass and domain\npreserving monads, proving that the associated Kleisli categories in fact\npreserve the corresponding equations and that these monads arise naturally for\nthe categories of semiring-weighted relations.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8fdb\u4e00\u6b65\u4e30\u5bcc\u4e86\u5173\u4e8e\u5173\u7cfb\u7ed3\u6784\u7684\u5206\u7c7b\uff0c\u63d0\u51fa\u4e24\u79cd\u62bd\u8c61\u6027\u66f4\u5f3a\u7684gs-\u5e7a\u534a\u8303\u7574\uff0c\u5e76\u901a\u8fc7\u8d28\u91cf\u548c\u57df\u7684\u6982\u5ff5\u8fdb\u884c\u523b\u753b\uff0c\u63a2\u8ba8\u4e86\u76f8\u5173\u5e7a\u534a\u8303\u7574\u548c\u534a\u73af\u52a0\u6743\u5173\u7cfb\u3002", "motivation": "\u6269\u5c55\u5df2\u6709\u7684\u5173\u7cfb\u7ed3\u6784\u5206\u7c7b\uff0c\u63d0\u51fa\u66f4\u62bd\u8c61\u7684gs-\u5e7a\u534a\u8303\u7574\u5b9e\u4f8b\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u6db5\u76d6\u76f8\u5173\u6982\u5ff5\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u7bad\u5934\u7684\u8d28\u91cf\u548c\u57df\u7684\u516c\u7406\u6982\u5ff5\uff0c\u5f15\u5165\u4fdd\u6301\u8d28\u91cf\u548c\u57df\u7684\u5e7a\u534a\u8303\u7574\uff0c\u5e76\u8bc1\u660e\u5176Kleisli\u8303\u7574\u6ee1\u8db3\u76f8\u5e94\u7b49\u5f0f\uff0c\u540c\u65f6\u5c55\u793a\u5176\u4e0e\u534a\u73af\u52a0\u6743\u5173\u7cfb\u7684\u81ea\u7136\u8054\u7cfb\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u5e76\u9a8c\u8bc1\u4e86\u4e24\u79cd\u65b0\u7684\u62bd\u8c61gs-\u5e7a\u534a\u8303\u7574\u5b9e\u4f8b\uff0c\u4e30\u5bcc\u4e86\u5df2\u6709\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u5206\u7c7b\u8fdb\u4e00\u6b65\u6269\u5c55\u4e86\u5173\u7cfb\u7ed3\u6784\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u591a\u53ef\u80fd\u6027\u3002"}}
{"id": "2508.19379", "pdf": "https://arxiv.org/pdf/2508.19379", "abs": "https://arxiv.org/abs/2508.19379", "authors": ["Anurag Chakraborty", "Semih Saliho\u011flu"], "title": "Robust Recursive Query Parallelism in Graph Database Management Systems", "categories": ["cs.DB", "cs.PF"], "comment": null, "summary": "Efficient multi-core parallel processing of recursive join queries is\ncritical for achieving good performance in graph database management systems\n(GDBMSs). Prior work adopts two broad approaches. First is the state of the art\nmorsel-driven parallelism, whose vanilla application in GDBMSs parallelizes\ncomputations at the source node level. Second is to parallelize each iteration\nof the computation at the frontier level. We show that these approaches can be\nseen as part of a design space of morsel dispatching policies based on picking\ndifferent granularities of morsels. We then empirically study the question of\nwhich policies parallelize better in practice under a variety of datasets and\nquery workloads that contain one to many source nodes. We show that these two\npolicies can be combined in a hybrid policy that issues morsels both at the\nsource node and frontier levels. We then show that the multi-source\nbreadth-first search optimization from prior work can also be modeled as a\nmorsel dispatching policy that packs multiple source nodes into multi-source\nmorsels. We implement these policies inside a single system, the Kuzu GDBMS,\nand evaluate them both within Kuzu and across other systems. We show that the\nhybrid policy captures the behavior of both source morsel-only and frontier\nmorsel-only policies in cases when these approaches parallelize well, and\nout-perform them on queries when they are limited, and propose it as a robust\napproach to parallelizing recursive queries. We further show that assigning\nmulti-sources is beneficial, as it reduces the amount of scans, but only when\nthere is enough sources in the query.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u4e2d\u591a\u6838\u5e76\u884c\u5904\u7406\u9012\u5f52\u8fde\u63a5\u67e5\u8be2\u7684\u6548\u7387\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u6e90\u8282\u70b9\u548c\u524d\u6cbf\u7ea7\u522b\u5206\u7247\u7684\u6df7\u5408\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u591a\u6838\u5e76\u884c\u5904\u7406\u9012\u5f52\u8fde\u63a5\u67e5\u8be2\u5bf9\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5206\u7247\u8c03\u5ea6\u7b56\u7565\u4e0a\u5b58\u5728\u4f18\u5316\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u5206\u7247\u8c03\u5ea6\u7b56\u7565\uff0c\u7ed3\u5408\u6e90\u8282\u70b9\u548c\u524d\u6cbf\u7ea7\u522b\u5206\u7247\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u591a\u6e90\u67e5\u8be2\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u6df7\u5408\u7b56\u7565\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5355\u4e00\u5206\u7247\u7b56\u7565\uff0c\u591a\u6e90\u5206\u914d\u7b56\u7565\u5728\u6e90\u8282\u70b9\u5145\u8db3\u65f6\u80fd\u51cf\u5c11\u626b\u63cf\u6b21\u6570\u3002", "conclusion": "\u6df7\u5408\u5206\u7247\u8c03\u5ea6\u7b56\u7565\u662f\u4e00\u79cd\u9c81\u68d2\u7684\u5e76\u884c\u9012\u5f52\u67e5\u8be2\u65b9\u6cd5\uff0c\u591a\u6e90\u5206\u914d\u7b56\u7565\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.19323", "pdf": "https://arxiv.org/pdf/2508.19323", "abs": "https://arxiv.org/abs/2508.19323", "authors": ["Ms. Preeti P. Bhatt", "Rakesh R. Savant"], "title": "A Technical Review on Comparison and Estimation of Steganographic Tools", "categories": ["cs.CR", "cs.CV", "cs.GR"], "comment": "20", "summary": "Steganography is technique of hiding a data under cover media using different\nsteganography tools. Image steganography is hiding of data\n(Text/Image/Audio/Video) under a cover as Image. This review paper presents\nclassification of image steganography and the comparison of various Image\nsteganography tools using different image formats. Analyzing numerous tools on\nthe basis of Image features and extracting the best one. Some of the tools\navailable in the market were selected based on the frequent use; these tools\nwere tested using the same input on all of them. Specific text was embedded\nwithin all host images for each of the six Steganography tools selected. The\nresults of the experiment reveal that all the six tools were relatively\nperforming at the same level, though some software performs better than others\nthrough efficiency. And it was based on the image features like size,\ndimensions, and pixel value and histogram differentiation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u56fe\u50cf\u9690\u5199\u672f\u7684\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u5de5\u5177\u5728\u591a\u79cd\u56fe\u50cf\u683c\u5f0f\u4e0b\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e86\u5176\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u8bc4\u4f30\u73b0\u6709\u56fe\u50cf\u9690\u5199\u672f\u5de5\u5177\u7684\u6027\u80fd\uff0c\u4ee5\u786e\u5b9a\u54ea\u79cd\u5de5\u5177\u5728\u6548\u7387\u548c\u56fe\u50cf\u7279\u5f81\uff08\u5982\u5927\u5c0f\u3001\u5c3a\u5bf8\u3001\u50cf\u7d20\u503c\u548c\u76f4\u65b9\u56fe\u5dee\u5f02\uff09\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "method": "\u9009\u62e9\u4e86\u516d\u6b3e\u5e38\u7528\u9690\u5199\u5de5\u5177\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u8f93\u5165\uff08\u5d4c\u5165\u7279\u5b9a\u6587\u672c\uff09\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u5206\u6790\u5176\u5728\u56fe\u50cf\u7279\u5f81\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u516d\u6b3e\u5de5\u5177\u6027\u80fd\u76f8\u8fd1\uff0c\u4f46\u90e8\u5206\u5de5\u5177\u5728\u6548\u7387\u4e0a\u7565\u80dc\u4e00\u7b79\u3002\u6027\u80fd\u5dee\u5f02\u4e3b\u8981\u57fa\u4e8e\u56fe\u50cf\u7279\u5f81\u7684\u6bd4\u8f83\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9009\u62e9\u6700\u4f73\u56fe\u50cf\u9690\u5199\u5de5\u5177\u63d0\u4f9b\u4e86\u53c2\u8003\u4f9d\u636e\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u56fe\u50cf\u7279\u5f81\u5bf9\u5de5\u5177\u6027\u80fd\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.19736", "pdf": "https://arxiv.org/pdf/2508.19736", "abs": "https://arxiv.org/abs/2508.19736", "authors": ["Mohsen Ahadi", "Adeel Malik", "Omid Esrafilian", "Florian Kaltenberger", "Cedric Thienot"], "title": "Experimental Insights from OpenAirInterface 5G positioning Testbeds: Challenges and solutions", "categories": ["cs.NI"], "comment": "8 pages", "summary": "5G New Radio (NR) is a key enabler of accurate positioning in smart cities\nand smart factories. This paper presents the experimental results from three 5G\npositioning testbeds running open-source OpenAirInterface (OAI) gNB and Core\nNetwork (CN), using Uplink Time Difference of Arrival (UL-TDoA) with the newly\nintegrated Location Management Function (LMF). The testbeds are deployed across\nboth indoor factories and outdoor scenarios with O-RAN Radio Units (RUs),\nfollowing a 3GPP-compliant system model. The experiments highlight the impact\nof synchronization impairments, multipath propagation, and deployment geometry\non positioning accuracy. To address these challenges, we propose tailored ToA\nand TDoA filtering as well as a novel position estimation method based on\nParticle Swarm Optimization (PSO) within the LMF pipeline. Moreover, we show a\nbeyond-5G framework that leverages non-conventional measurements such as\nChannel Impulse Response (CIR) to train and test Artificial Intelligence and\nMachine Learning (AI/ML) models for data-driven positioning. The results\ndemonstrate the feasibility of achieving 1-2 meter positioning accuracy in 90%\nof cases in different testbeds, offering practical insights for the design of\nrobust 5G positioning systems. Moreover, we publicly release the datasets\ncollected in this work to support the research within the 5G positioning\ncommunity.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7OAI\u6d4b\u8bd5\u5e8a\u5b9e\u9a8c\u9a8c\u8bc1\u4e865G NR\u5728\u667a\u80fd\u57ce\u5e02\u548c\u5de5\u5382\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u6ee4\u6ce2\u548c\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e861-2\u7c73\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "5G\u65b0\u65e0\u7ebf\u7535\uff08NR\uff09\u662f\u5b9e\u73b0\u667a\u80fd\u57ce\u5e02\u548c\u5de5\u5382\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5176\u5728\u5b9e\u8df5\u4e2d\u53d7\u540c\u6b65\u8bef\u5dee\u3001\u591a\u5f84\u4f20\u64ad\u7b49\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u5f00\u6e90OpenAirInterface\u5efa\u7acb\u6d4b\u8bd5\u5e8a\uff0c\u7ed3\u5408UL-TDoA\u548cLMF\uff0c\u63d0\u51faToA/TDoA\u6ee4\u6ce2\u53caPSO\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5229\u7528CIR\u8bad\u7ec3AI/ML\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c90%\u60c5\u51b5\u4e0b\u53ef\u8fbe1-2\u7c73\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5e76\u516c\u5f00\u6570\u636e\u96c6\u652f\u63015G\u5b9a\u4f4d\u7814\u7a76\u3002", "conclusion": "\u7814\u7a76\u4e3a5G\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u8d85\u8d8a5G\u7684\u5b9a\u4f4d\u6f5c\u529b\u3002"}}
{"id": "2508.19739", "pdf": "https://arxiv.org/pdf/2508.19739", "abs": "https://arxiv.org/abs/2508.19739", "authors": ["Sebastian Lotter", "Marco Seiter", "Maryam Pirmoradi", "Lukas Brand", "Dagmar Fischer", "Robert Schober"], "title": "MC for Gastroretentive Drug Delivery", "categories": ["eess.SP", "cs.ET"], "comment": "4 pages, 2 figures, This paper has been submitted to IEEE\n  Transactions on Molecular, Biological, and Multi-Scale Communications as\n  Transactions Letter", "summary": "Recently, bacterial nanocellulose (BNC), a biological material produced by\nnon-pathogenic bacteria that possesses excellent material properties for\nvarious medical applications, has received increased interest as a carrier\nsystem for drug delivery. However, the vast majority of existing studies on\ndrug release from BNC are feasibility studies with modeling and design aspects\nremaining largely unexplored. To narrow this research gap, this paper proposes\na novel model for the drug release from BNC. Specifically, the drug delivery\nsystem considered in this paper consists of a BNC fleece coated with a polymer.\nThe polymer coating is used as an additional diffusion barrier, enabling the\ncontrolled release of an active pharmaceutical ingredient. The proposed\nphysics-based model reflects the geometry of the BNC and incorporates the\nimpact of the polymer coating on the drug release. Hence, it can be useful for\ndesigning BNC-based drug delivery systems in the future. The accuracy of the\nmodel is validated with experimental data obtained in wet lab experiments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ec6\u83cc\u7eb3\u7c73\u7ea4\u7ef4\u7d20(BNC)\u836f\u7269\u91ca\u653e\u6a21\u578b,\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d,\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684BNC\u836f\u7269\u91ca\u653e\u7814\u7a76\u591a\u4e3a\u53ef\u884c\u6027\u7814\u7a76,\u7f3a\u4e4f\u5efa\u6a21\u548c\u8bbe\u8ba1\u65b9\u9762\u7684\u63a2\u7d22,\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u7cbe\u786e\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u7684\u6a21\u578b,\u8003\u8651\u4e86BNC\u7684\u51e0\u4f55\u5f62\u72b6\u548c\u805a\u5408\u7269\u6d82\u5c42\u5bf9\u836f\u7269\u91ca\u653e\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u901a\u8fc7\u6e7f\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027,\u4e3a\u672a\u6765BNC\u57fa\u836f\u7269\u9012\u9001\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3aBNC\u836f\u7269\u9012\u9001\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2508.19803", "pdf": "https://arxiv.org/pdf/2508.19803", "abs": "https://arxiv.org/abs/2508.19803", "authors": ["Peter Fettke", "Wolfgang Reisig"], "title": "Towards a fundamental theory of modeling discrete systems", "categories": ["cs.SE", "cs.DB"], "comment": "6 pages, 2 figures, author prepared version of final manuscript\n  accepted at the 44th International Conference on Conceptual Modeling, 20-23\n  October 2025, Poitiers / Futuroscope, France, Workshop on Fundamentals of\n  Conceptual Modeling (FCM)", "summary": "Modeling is a central concern in both science and engineering. However, we\nneed a new fundamental theory to address the challenges of the digital age. In\nthis paper, we first explain why modeling is fundamental and which challenges\nmust be addressed in the digital world. As a main contribution, we introduce\nthe Heraklit modeling framework as a new approach to modeling. We conclude with\nsome general remarks. Future work will involve the correctness of modeling, the\nnotion of information, and the description of invariance in modeling.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5efa\u6a21\u5728\u79d1\u5b66\u4e0e\u5de5\u7a0b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u6570\u5b57\u65f6\u4ee3\u6311\u6218\u7684\u65b0\u7406\u8bbaHeraklit\u5efa\u6a21\u6846\u67b6\u3002", "motivation": "\u5efa\u6a21\u662f\u79d1\u5b66\u4e0e\u5de5\u7a0b\u7684\u6838\u5fc3\uff0c\u4f46\u6570\u5b57\u65f6\u4ee3\u9700\u8981\u65b0\u7684\u7406\u8bba\u57fa\u7840\u6765\u89e3\u51b3\u65b0\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86Heraklit\u5efa\u6a21\u6846\u67b6\u4f5c\u4e3a\u65b0\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "result": "\u4ecb\u7ecd\u4e86Heraklit\u6846\u67b6\u7684\u521d\u6b65\u6210\u679c\u3002", "conclusion": "\u672a\u6765\u5de5\u4f5c\u5c06\u5173\u6ce8\u5efa\u6a21\u7684\u6b63\u786e\u6027\u3001\u4fe1\u606f\u6982\u5ff5\u548c\u4e0d\u53d8\u6027\u63cf\u8ff0\u3002"}}
{"id": "2508.19262", "pdf": "https://arxiv.org/pdf/2508.19262", "abs": "https://arxiv.org/abs/2508.19262", "authors": ["Maximilian Wachter", "Sebastian Murgul", "Michael Heizmann"], "title": "Beat-Based Rhythm Quantization of MIDI Performances", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "comment": "Accepted to the Late Breaking Demo Papers of the 1st AES\n  International Conference on Artificial Intelligence and Machine Learning for\n  Audio (AIMLA LBDP), 2025", "summary": "We propose a transformer-based rhythm quantization model that incorporates\nbeat and downbeat information to quantize MIDI performances into\nmetrically-aligned, human-readable scores. We propose a beat-based\npreprocessing method that transfers score and performance data into a unified\ntoken representation. We optimize our model architecture and data\nrepresentation and train on piano and guitar performances. Our model exceeds\nstate-of-the-art performance based on the MUSTER metric.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u8282\u594f\u91cf\u5316\u6a21\u578b\uff0c\u7ed3\u5408\u8282\u62cd\u548c\u5f3a\u62cd\u4fe1\u606f\uff0c\u5c06MIDI\u6f14\u594f\u91cf\u5316\u4e3a\u7b26\u5408\u8282\u62cd\u3001\u6613\u8bfb\u7684\u4e50\u8c31\u3002", "motivation": "\u901a\u8fc7\u7ed3\u5408\u8282\u62cd\u548c\u5f3a\u62cd\u4fe1\u606f\uff0c\u6539\u8fdbMIDI\u6f14\u594f\u7684\u91cf\u5316\u6548\u679c\uff0c\u751f\u6210\u66f4\u51c6\u786e\u3001\u6613\u8bfb\u7684\u4e50\u8c31\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8282\u62cd\u7684\u6570\u636e\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u5c06\u4e50\u8c31\u548c\u6f14\u594f\u6570\u636e\u8f6c\u6362\u4e3a\u7edf\u4e00\u7684token\u8868\u793a\uff1b\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u8868\u793a\uff0c\u5e76\u5728\u94a2\u7434\u548c\u5409\u4ed6\u6f14\u594f\u6570\u636e\u4e0a\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u5728MUSTER\u6307\u6807\u4e0a\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u8be5Transformer\u6a21\u578b\u5728\u8282\u594f\u91cf\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u7ed3\u5408\u8282\u62cd\u4fe1\u606f\u540e\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u91cf\u5316\u6548\u679c\u3002"}}
{"id": "2508.19259", "pdf": "https://arxiv.org/pdf/2508.19259", "abs": "https://arxiv.org/abs/2508.19259", "authors": ["Georgios P. Georgiou"], "title": "Capabilities of GPT-5 across critical domains: Is it the next breakthrough?", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "The accelerated evolution of large language models has raised questions about\ntheir comparative performance across domains of practical importance. GPT-4 by\nOpenAI introduced advances in reasoning, multimodality, and task\ngeneralization, establishing itself as a valuable tool in education, clinical\ndiagnosis, and academic writing, though it was accompanied by several flaws.\nReleased in August 2025, GPT-5 incorporates a system-of-models architecture\ndesigned for task-specific optimization and, based on both anecdotal accounts\nand emerging evidence from the literature, demonstrates stronger performance\nthan its predecessor in medical contexts. This study provides one of the first\nsystematic comparisons of GPT-4 and GPT-5 using human raters from linguistics\nand clinical fields. Twenty experts evaluated model-generated outputs across\nfive domains: lesson planning, assignment evaluation, clinical diagnosis,\nresearch generation, and ethical reasoning, based on predefined criteria.\nMixed-effects models revealed that GPT-5 significantly outperformed GPT-4 in\nlesson planning, clinical diagnosis, research generation, and ethical\nreasoning, while both models performed comparably in assignment assessment. The\nfindings highlight the potential of GPT-5 to serve as a context-sensitive and\ndomain-specialized tool, offering tangible benefits for education, clinical\npractice, and academic research, while also advancing ethical reasoning. These\nresults contribute to one of the earliest empirical evaluations of the evolving\ncapabilities and practical promise of GPT-5.", "AI": {"tldr": "GPT-5\u5728\u591a\u4e2a\u9886\u57df\uff08\u8bfe\u7a0b\u89c4\u5212\u3001\u4e34\u5e8a\u8bca\u65ad\u3001\u7814\u7a76\u751f\u6210\u548c\u4f26\u7406\u63a8\u7406\uff09\u663e\u8457\u4f18\u4e8eGPT-4\uff0c\u4f46\u5728\u4f5c\u4e1a\u8bc4\u4f30\u65b9\u9762\u8868\u73b0\u76f8\u8fd1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6559\u80b2\u548c\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u6bd4\u8f83GPT-4\u548cGPT-5\u5728\u4e0d\u540c\u5b9e\u8df5\u9886\u57df\uff08\u5982\u6559\u80b2\u548c\u4e34\u5e8a\u8bca\u65ad\uff09\u7684\u6027\u80fd\uff0c\u4e3a\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u753120\u540d\u4e13\u5bb6\u57fa\u4e8e\u9884\u8bbe\u6807\u51c6\u8bc4\u4f30GPT-4\u548cGPT-5\u5728\u4e94\u4e2a\u9886\u57df\u7684\u8f93\u51fa\uff0c\u5e76\u4f7f\u7528\u6df7\u5408\u6548\u5e94\u6a21\u578b\u5206\u6790\u6570\u636e\u3002", "result": "GPT-5\u5728\u591a\u6570\u9886\u57df\u8868\u73b0\u4f18\u4e8eGPT-4\uff0c\u5c24\u5176\u5728\u4e34\u5e8a\u8bca\u65ad\u548c\u4f26\u7406\u63a8\u7406\u65b9\u9762\u8fdb\u6b65\u660e\u663e\u3002", "conclusion": "GPT-5\u5728\u4e13\u4e1a\u9886\u57df\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u6559\u80b2\u548c\u4e34\u5e8a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2508.19428", "pdf": "https://arxiv.org/pdf/2508.19428", "abs": "https://arxiv.org/abs/2508.19428", "authors": ["Aleksandra Beliaeva", "Temurbek Rahmatullaev"], "title": "Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)", "categories": ["cs.CL", "cs.LO", "cs.SC", "68T30, 68T50, 68T07, 68U15", "I.2.4; I.2.7; H.3.1; H.3.3; I.2.6"], "comment": null, "summary": "We present a comprehensive system for addressing Tasks A, B, and C of the\nLLMs4OL 2025 challenge, which together span the full ontology construction\npipeline: term extraction, typing, and taxonomy discovery. Our approach\ncombines retrieval-augmented prompting, zero-shot classification, and\nattention-based graph modeling -- each tailored to the demands of the\nrespective task. For Task A, we jointly extract domain-specific terms and their\nontological types using a retrieval-augmented generation (RAG) pipeline.\nTraining data was reformulated into a document to terms and types\ncorrespondence, while test-time inference leverages semantically similar\ntraining examples. This single-pass method requires no model finetuning and\nimproves overall performance through lexical augmentation Task B, which\ninvolves assigning types to given terms, is handled via a dual strategy. In the\nfew-shot setting (for domains with labeled training data), we reuse the RAG\nscheme with few-shot prompting. In the zero-shot setting (for previously unseen\ndomains), we use a zero-shot classifier that combines cosine similarity scores\nfrom multiple embedding models using confidence-based weighting. In Task C, we\nmodel taxonomy discovery as graph inference. Using embeddings of type labels,\nwe train a lightweight cross-attention layer to predict is-a relations by\napproximating a soft adjacency matrix. These modular, task-specific solutions\nenabled us to achieve top-ranking results in the official leaderboard across\nall three tasks. Taken together these strategies showcase the scalability,\nadaptability, and robustness of LLM-based architectures for ontology learning\nacross heterogeneous domains.\n  Code is available at:\nhttps://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek", "AI": {"tldr": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u3001\u96f6\u6837\u672c\u5206\u7c7b\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u56fe\u5efa\u6a21\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLMs4OL 2025\u6311\u6218\u4e2d\u7684\u4efb\u52a1A\u3001B\u548cC\uff0c\u5c55\u793a\u4e86LLM\u67b6\u6784\u5728\u5f02\u6784\u9886\u57df\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3LLMs4OL 2025\u6311\u6218\u4e2d\u7684\u4efb\u52a1A\u3001B\u548cC\uff0c\u5c55\u793aLLM\u5728\u5f02\u6784\u9886\u57df\u4e2d\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002", "method": "\u4efb\u52a1A\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u63d0\u53d6\u672f\u8bed\u548c\u7c7b\u578b\uff1b\u4efb\u52a1B\u5728\u5c11\u91cf\u6837\u672c\u548c\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5206\u522b\u91c7\u7528RAG\u548c\u96f6\u6837\u672c\u5206\u7c7b\u5668\uff1b\u4efb\u52a1C\u901a\u8fc7\u56fe\u63a8\u7406\u9884\u6d4bis-a\u5173\u7cfb\u3002", "result": "\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6392\u884c\u699c\u4e0a\u7684\u9876\u7ea7\u6210\u7ee9\u3002", "conclusion": "\u7cfb\u7edf\u5c55\u793a\u4e86LLM\u67b6\u6784\u5728\u5f02\u6784\u9886\u57df\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.20080", "pdf": "https://arxiv.org/pdf/2508.20080", "abs": "https://arxiv.org/abs/2508.20080", "authors": ["Changha Shin", "Woong Oh Cho", "Seon Joo Kim"], "title": "Seam360GS: Seamless 360\u00b0 Gaussian Splatting from Real-World Omnidirectional Images", "categories": ["cs.CV", "cs.GR"], "comment": "Accepted to ICCV 2025. 10 pages main text, 4 figures, 4 tables,\n  supplementary material included", "summary": "360-degree visual content is widely shared on platforms such as YouTube and\nplays a central role in virtual reality, robotics, and autonomous navigation.\nHowever, consumer-grade dual-fisheye systems consistently yield imperfect\npanoramas due to inherent lens separation and angular distortions. In this\nwork, we introduce a novel calibration framework that incorporates a\ndual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach\nnot only simulates the realistic visual artifacts produced by dual-fisheye\ncameras but also enables the synthesis of seamlessly rendered 360-degree\nimages. By jointly optimizing 3D Gaussian parameters alongside calibration\nvariables that emulate lens gaps and angular distortions, our framework\ntransforms imperfect omnidirectional inputs into flawless novel view synthesis.\nExtensive evaluations on real-world datasets confirm that our method produces\nseamless renderings-even from imperfect images-and outperforms existing\n360-degree rendering models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u53cc\u9c7c\u773c\u76f8\u673a\u6821\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u53cc\u9c7c\u773c\u76f8\u673a\u6a21\u578b\u878d\u51653D\u9ad8\u65af\u6e85\u5c04\u6d41\u7a0b\uff0c\u80fd\u591f\u751f\u6210\u65e0\u7f1d\u7684360\u5ea6\u56fe\u50cf\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u89e3\u51b3\u6d88\u8d39\u7ea7\u53cc\u9c7c\u773c\u7cfb\u7edf\u56e0\u955c\u5934\u5206\u79bb\u548c\u89d2\u5ea6\u53d8\u5f62\u5bfc\u81f4\u7684\u4e0d\u5b8c\u7f8e\u5168\u666f\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u53cc\u9c7c\u773c\u76f8\u673a\u6a21\u578b\u4e0e3D\u9ad8\u65af\u6e85\u5c04\u6d41\u7a0b\uff0c\u8054\u5408\u4f18\u53163D\u9ad8\u65af\u53c2\u6570\u548c\u6a21\u62df\u955c\u5934\u95f4\u9699\u4e0e\u89d2\u5ea6\u53d8\u5f62\u7684\u6821\u51c6\u53d8\u91cf\u3002", "result": "\u751f\u6210\u65e0\u7f1d\u7684360\u5ea6\u6e32\u67d3\u56fe\u50cf\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u4e0d\u5b8c\u7f8e\u7684\u5168\u5411\u8f93\u5165\u4e2d\u751f\u6210\u5b8c\u7f8e\u7684\u89c6\u89d2\u5408\u6210\u7ed3\u679c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.19870", "pdf": "https://arxiv.org/pdf/2508.19870", "abs": "https://arxiv.org/abs/2508.19870", "authors": ["Yinqiu Liu", "Ruichen Zhang", "Haoxiang Luo", "Yijing Lin", "Geng Sun", "Dusit Niyato", "Hongyang Du", "Zehui Xiong", "Yonggang Wen", "Abbas Jamalipour", "Dong In Kim", "Ping Zhang"], "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "categories": ["cs.NI"], "comment": "35 pages", "summary": "Agentification serves as a critical enabler of Edge General Intelligence\n(EGI), transforming massive edge devices into cognitive agents through\nintegrating Large Language Models (LLMs) and perception, reasoning, and acting\nmodules. These agents collaborate across heterogeneous edge infrastructures,\nforming multi-LLM agentic AI systems that leverage collective intelligence and\nspecialized capabilities to tackle complex, multi-step tasks. However, the\ncollaborative nature of multi-LLM systems introduces critical security\nvulnerabilities, including insecure inter-LLM communications, expanded attack\nsurfaces, and cross-domain data leakage that traditional perimeter-based\nsecurity cannot adequately address. To this end, this survey introduces\nzero-trust security of multi-LLM in EGI, a paradigmatic shift following the\n``never trust, always verify'' principle. We begin by systematically analyzing\nthe security risks in multi-LLM systems within EGI contexts. Subsequently, we\npresent the vision of a zero-trust multi-LLM framework in EGI. We then survey\nkey technical progress to facilitate zero-trust multi-LLM systems in EGI.\nParticularly, we categorize zero-trust security mechanisms into model- and\nsystem-level approaches. The former and latter include strong identification,\ncontext-aware access control, etc., and proactive maintenance, blockchain-based\nmanagement, etc., respectively. Finally, we identify critical research\ndirections. This survey serves as the first systematic treatment of zero-trust\napplied to multi-LLM systems, providing both theoretical foundations and\npractical strategies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u591aLLM\u7cfb\u7edf\u5728\u8fb9\u7f18\u901a\u7528\u667a\u80fd\uff08EGI\uff09\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5b89\u5168\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u96f6\u4fe1\u4efb\u5b89\u5168\u6846\u67b6\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u591aLLM\u7cfb\u7edf\u7684\u534f\u4f5c\u6027\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f20\u7edf\u5b89\u5168\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9\uff0c\u9700\u8981\u96f6\u4fe1\u4efb\u6846\u67b6\u6765\u4fdd\u969c\u5b89\u5168\u3002", "method": "\u8bba\u6587\u9996\u5148\u5206\u6790\u591aLLM\u7cfb\u7edf\u5728EGI\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u51fa\u96f6\u4fe1\u4efb\u6846\u67b6\uff0c\u5e76\u5206\u7c7b\u6280\u672f\u8fdb\u5c55\u4e3a\u6a21\u578b\u7ea7\u548c\u7cfb\u7edf\u7ea7\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u96f6\u4fe1\u4efb\u591aLLM\u6846\u67b6\uff0c\u5206\u7c7b\u4e86\u5b89\u5168\u673a\u5236\uff0c\u5e76\u6307\u51fa\u4e86\u5173\u952e\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3a\u591aLLM\u7cfb\u7edf\u7684\u96f6\u4fe1\u4efb\u5b89\u5168\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u7b56\u7565\u3002"}}
{"id": "2508.19905", "pdf": "https://arxiv.org/pdf/2508.19905", "abs": "https://arxiv.org/abs/2508.19905", "authors": ["Imad Ali Shah", "Jiarong Li", "Roshan George", "Tim Brophy", "Enda Ward", "Martin Glavin", "Edward Jones", "Brian Deegan"], "title": "Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities", "categories": ["cs.CV", "cs.ET"], "comment": "Submitted and under review at IEEE OJVT, August 2025", "summary": "Hyperspectral imaging (HSI) offers a transformative sensing modality for\nAdvanced Driver Assistance Systems (ADAS) and autonomous driving (AD)\napplications, enabling material-level scene understanding through fine spectral\nresolution beyond the capabilities of traditional RGB imaging. This paper\npresents the first comprehensive review of HSI for automotive applications,\nexamining the strengths, limitations, and suitability of current HSI\ntechnologies in the context of ADAS/AD. In addition to this qualitative review,\nwe analyze 216 commercially available HSI and multispectral imaging cameras,\nbenchmarking them against key automotive criteria: frame rate, spatial\nresolution, spectral dimensionality, and compliance with AEC-Q100 temperature\nstandards. Our analysis reveals a significant gap between HSI's demonstrated\nresearch potential and its commercial readiness. Only four cameras meet the\ndefined performance thresholds, and none comply with AEC-Q100 requirements. In\naddition, the paper reviews recent HSI datasets and applications, including\nsemantic segmentation for road surface classification, pedestrian separability,\nand adverse weather perception. Our review shows that current HSI datasets are\nlimited in terms of scale, spectral consistency, the number of spectral\nchannels, and environmental diversity, posing challenges for the development of\nperception algorithms and the adequate validation of HSI's true potential in\nADAS/AD applications. This review paper establishes the current state of HSI in\nautomotive contexts as of 2025 and outlines key research directions toward\npractical integration of spectral imaging in ADAS and autonomous systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u9ad8\u5149\u8c31\u6210\u50cf\uff08HSI\uff09\u5728\u5148\u8fdb\u9a7e\u9a76\u8f85\u52a9\u7cfb\u7edf\u548c\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u5f53\u524d\u6280\u672f\u7684\u4f18\u7f3a\u70b9\u53ca\u5546\u4e1a\u5316\u7a0b\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u7814\u7a76\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8HSI\u5728\u6c7d\u8f66\u9886\u57df\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5176\u5728\u6750\u6599\u7ea7\u573a\u666f\u7406\u89e3\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u4ee5\u53ca\u5f53\u524d\u6280\u672f\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u5b9a\u6027\u56de\u987e216\u6b3e\u5546\u4e1aHSI\u548c\u591a\u5149\u8c31\u76f8\u673a\uff0c\u57fa\u4e8e\u5e27\u7387\u3001\u7a7a\u95f4\u5206\u8fa8\u7387\u3001\u5149\u8c31\u7ef4\u5ea6\u548cAEC-Q100\u6807\u51c6\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\uff0c\u5e76\u5206\u6790\u73b0\u6709\u6570\u636e\u96c6\u548c\u5e94\u7528\u3002", "result": "\u4ec5\u56db\u6b3e\u76f8\u673a\u6ee1\u8db3\u6027\u80fd\u8981\u6c42\uff0c\u65e0\u4e00\u6b3e\u7b26\u5408AEC-Q100\u6807\u51c6\uff1b\u73b0\u6709\u6570\u636e\u96c6\u4e5f\u5b58\u5728\u89c4\u6a21\u5c0f\u3001\u5149\u8c31\u4e00\u81f4\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86HSI\u6f5c\u529b\u7684\u9a8c\u8bc1\u3002", "conclusion": "HSI\u5728\u6c7d\u8f66\u9886\u57df\u7684\u7814\u7a76\u6f5c\u529b\u5c1a\u672a\u5b8c\u5168\u5546\u4e1a\u5316\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6280\u672f\u548c\u6570\u636e\u96c6\u624d\u80fd\u5b9e\u73b0\u5176\u5728ADAS/AD\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.19807", "pdf": "https://arxiv.org/pdf/2508.19807", "abs": "https://arxiv.org/abs/2508.19807", "authors": ["Michael Nidd", "Christoph Miksovic", "Thomas Gschwind", "Francesco Fusco", "Andrea Giovannini", "Ioana Giurgiu"], "title": "Bootstrapping Learned Cost Models with Synthetic SQL Queries", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Having access to realistic workloads for a given database instance is\nextremely important to enable stress and vulnerability testing, as well as to\noptimize for cost and performance. Recent advances in learned cost models have\nshown that when enough diverse SQL queries are available, one can effectively\nand efficiently predict the cost of running a given query against a specific\ndatabase engine. In this paper, we describe our experience in exploiting modern\nsynthetic data generation techniques, inspired by the generative AI and LLM\ncommunity, to create high-quality datasets enabling the effective training of\nsuch learned cost models. Initial results show that we can improve a learned\ncost model's predictive accuracy by training it with 45% fewer queries than\nwhen using competitive generation approaches.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u5229\u7528\u751f\u6210\u5f0fAI\u548cLLM\u6280\u672f\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u4ee5\u6539\u8fdb\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u4ee5\u51cf\u5c1145%\u7684\u67e5\u8be2\u91cf\u3002", "motivation": "\u4e3a\u4e86\u6709\u6548\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\u3001\u5f31\u70b9\u6d4b\u8bd5\u4ee5\u53ca\u6210\u672c\u548c\u6027\u80fd\u4f18\u5316\uff0c\u9700\u8981\u83b7\u53d6\u771f\u5b9e\u7684\u6570\u636e\u5e93\u5de5\u4f5c\u8d1f\u8f7d\u3002\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\u7684\u8fdb\u5c55\u8868\u660e\uff0c\u591a\u6837\u5316\u7684SQL\u67e5\u8be2\u53ef\u4ee5\u6709\u6548\u9884\u6d4b\u67e5\u8be2\u6210\u672c\u3002", "method": "\u5229\u7528\u751f\u6210\u5f0fAI\u548cLLM\u6280\u672f\uff0c\u5f00\u53d1\u4e86\u73b0\u4ee3\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u521b\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4ee5\u8bad\u7ec3\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u751f\u6210\u65b9\u6cd5\u76f8\u6bd4\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\u4ec5\u970045%\u7684\u67e5\u8be2\u91cf\u5373\u53ef\u8fbe\u5230\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2508.19393", "pdf": "https://arxiv.org/pdf/2508.19393", "abs": "https://arxiv.org/abs/2508.19393", "authors": ["Phuoc Pham", "Arun Venkitaraman", "Chia-Yu Hsieh", "Andrea Bonetti", "Stefan Uhlich", "Markus Leibl", "Simon Hofmann", "Eisaku Ohbuchi", "Lorenzo Servadei", "Ulf Schlichtmann", "Robert Wille"], "title": "GENIE-ASI: Generative Instruction and Executable Code for Analog Subcircuit Identification", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Analog subcircuit identification is a core task in analog design, essential\nfor simulation, sizing, and layout. Traditional methods often require extensive\nhuman expertise, rule-based encoding, or large labeled datasets. To address\nthese challenges, we propose GENIE-ASI, the first training-free, large language\nmodel (LLM)-based methodology for analog subcircuit identification. GENIE-ASI\noperates in two phases: it first uses in-context learning to derive natural\nlanguage instructions from a few demonstration examples, then translates these\ninto executable Python code to identify subcircuits in unseen SPICE netlists.\nIn addition, to evaluate LLM-based approaches systematically, we introduce a\nnew benchmark composed of operational amplifier netlists (op-amps) that cover a\nwide range of subcircuit variants. Experimental results on the proposed\nbenchmark show that GENIE-ASI matches rule-based performance on simple\nstructures (F1-score = 1.0), remains competitive on moderate abstractions\n(F1-score = 0.81), and shows potential even on complex subcircuits (F1-score =\n0.31). These findings demonstrate that LLMs can serve as adaptable,\ngeneral-purpose tools in analog design automation, opening new research\ndirections for foundation model applications in analog design automation.", "AI": {"tldr": "GENIE-ASI\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5b9e\u73b0\u65e0\u8bad\u7ec3\u7684\u6a21\u62df\u5b50\u7535\u8def\u8bc6\u522b\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u4ee3\u7801\u751f\u6210\uff0c\u6027\u80fd\u63a5\u8fd1\u6216\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6a21\u62df\u5b50\u7535\u8def\u8bc6\u522b\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u6216\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0cGENIE-ASI\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5206\u4e24\u9636\u6bb5\uff1a\u4e0a\u4e0b\u6587\u5b66\u4e60\u751f\u6210\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u518d\u8f6c\u5316\u4e3a\u53ef\u6267\u884cPython\u4ee3\u7801\uff0c\u5e94\u7528\u4e8eSPICE\u7f51\u8868\u3002", "result": "\u5728\u7b80\u5355\u7ed3\u6784\u4e2d\u6027\u80fd\u5b8c\u7f8e\uff08F1=1.0\uff09\uff0c\u4e2d\u590d\u6742\u5ea6\u7ade\u4e89\u6027\uff08F1=0.81\uff09\uff0c\u590d\u6742\u7ed3\u6784\u6709\u6f5c\u529b\uff08F1=0.31\uff09\u3002", "conclusion": "LLM\u53ef\u4f5c\u4e3a\u7075\u6d3b\u901a\u7528\u5de5\u5177\u7528\u4e8e\u6a21\u62df\u8bbe\u8ba1\u81ea\u52a8\u5316\uff0c\u62d3\u5c55\u4e86\u57fa\u7840\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2508.19373", "pdf": "https://arxiv.org/pdf/2508.19373", "abs": "https://arxiv.org/abs/2508.19373", "authors": ["Haoran Lin", "Xianzhi Yu", "Kang Zhao", "Han Bao", "Zongyuan Zhan", "Ting Hu", "Wulong Liu", "Zekun Yin", "Xin Li", "Weiguo Liu"], "title": "HAP: Hybrid Adaptive Parallelism for Efficient Mixture-of-Experts Inference", "categories": ["cs.DC"], "comment": null, "summary": "Current inference systems for Mixture-of-Experts (MoE) models primarily\nemploy static parallelization strategies. However, these static approaches\ncannot consistently achieve optimal performance across different inference\nscenarios, as they lack the flexibility to adapt to varying computational\nrequirements. In this work, we propose HAP (Hybrid Adaptive Parallelism), a\nnovel method that dynamically selects hybrid parallel strategies to enhance MoE\ninference efficiency. The fundamental innovation of HAP lies in hierarchically\ndecomposing MoE architectures into two distinct computational modules: the\nAttention module and the Expert module, each augmented with a specialized\ninference latency simulation model. This decomposition promotes the\nconstruction of a comprehensive search space for seeking model parallel\nstrategies. By leveraging Integer Linear Programming (ILP), HAP could solve the\noptimal hybrid parallel configurations to maximize inference efficiency under\nvarying computational constraints. Our experiments demonstrate that HAP\nconsistently determines parallel configurations that achieve comparable or\nsuperior performance to the TP strategy prevalent in mainstream inference\nsystems. Compared to the TP-based inference, HAP-based inference achieves\nspeedups of 1.68x, 1.77x, and 1.57x on A100, A6000, and V100 GPU platforms,\nrespectively. Furthermore, HAP showcases remarkable generalization capability,\nmaintaining performance effectiveness across diverse MoE model configurations,\nincluding Mixtral and Qwen series models.", "AI": {"tldr": "HAP\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u9009\u62e9\u6df7\u5408\u5e76\u884c\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u89e3MoE\u67b6\u6784\u5e76\u7ed3\u5408ILP\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709MoE\u6a21\u578b\u7684\u9759\u6001\u5e76\u884c\u5316\u7b56\u7565\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u63a8\u7406\u573a\u666f\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u5bfc\u81f4\u6548\u7387\u4e0d\u8db3\u3002", "method": "HAP\u5c06MoE\u67b6\u6784\u5206\u89e3\u4e3aAttention\u548cExpert\u6a21\u5757\uff0c\u901a\u8fc7ILP\u52a8\u6001\u9009\u62e9\u6700\u4f18\u5e76\u884c\u914d\u7f6e\u3002", "result": "\u5728A100\u3001A6000\u548cV100 GPU\u4e0a\u5206\u522b\u5b9e\u73b01.68x\u30011.77x\u548c1.57x\u7684\u52a0\u901f\uff0c\u5e76\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "HAP\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347MoE\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2508.19834", "pdf": "https://arxiv.org/pdf/2508.19834", "abs": "https://arxiv.org/abs/2508.19834", "authors": ["Antero Taivalsaari", "Tommi Mikkonen", "Cesare Pautasso"], "title": "On the Future of Software Reuse in the Era of AI Native Software Engineering", "categories": ["cs.SE"], "comment": "21 pages", "summary": "Software development is currently under a paradigm shift in which artificial\nintelligence and generative software reuse are taking the center stage in\nsoftware creation. Earlier opportunistic software reuse practices and organic\nsoftware development methods are rapidly being replaced by \"AI Native\"\napproaches in which developers place their trust on code that has been\ngenerated by artificial intelligence. This is leading to a new form of software\nreuse that is conceptually not all that different from cargo cult development.\nIn this paper we discuss the implications of AI-assisted generative software\nreuse, bring forth relevant questions, and define a research agenda for\ntackling the central issues associated with this emerging approach.", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u751f\u6210\u5f0f\u8f6f\u4ef6\u91cd\u7528\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u76f8\u5173\u95ee\u9898\u548c\u7814\u7a76\u8bae\u7a0b\u3002", "motivation": "\u63a2\u8ba8AI Native\u65b9\u6cd5\u5982\u4f55\u53d6\u4ee3\u4f20\u7edf\u8f6f\u4ef6\u91cd\u7528\u548c\u5f00\u53d1\u5b9e\u8df5\uff0c\u53ca\u5176\u6f5c\u5728\u95ee\u9898\u3002", "method": "\u5206\u6790AI\u8f85\u52a9\u751f\u6210\u5f0f\u8f6f\u4ef6\u91cd\u7528\u7684\u73b0\u8c61\uff0c\u5e76\u8ba8\u8bba\u5176\u4e0e\u8d27\u7269\u5d07\u62dc\u5f00\u53d1\u7684\u76f8\u4f3c\u6027\u3002", "result": "\u63d0\u51fa\u76f8\u5173\u95ee\u9898\u548c\u7814\u7a76\u8bae\u7a0b\uff0c\u4ee5\u89e3\u51b3\u65b0\u5174\u65b9\u6cd5\u7684\u6838\u5fc3\u95ee\u9898\u3002", "conclusion": "AI\u8f85\u52a9\u751f\u6210\u5f0f\u8f6f\u4ef6\u91cd\u7528\u662f\u8f6f\u4ef6\u5f00\u53d1\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5f71\u54cd\u548c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19622", "pdf": "https://arxiv.org/pdf/2508.19622", "abs": "https://arxiv.org/abs/2508.19622", "authors": ["Jingyao Zheng", "Haodi Weng", "Xian Wang", "Chengbin Cui", "Sven Mayer", "Chi-lok Tai", "Lik-Hang Lee"], "title": "PersoNo: Personalised Notification Urgency Classifier in Mixed Reality", "categories": ["cs.HC", "cs.MM"], "comment": "Accepted by ISMAR 2025", "summary": "Mixed Reality (MR) is increasingly integrated into daily life, providing\nenhanced capabilities across various domains. However, users face growing\nnotification streams that disrupt their immersive experience. We present\nPersoNo, a personalised notification urgency classifier for MR that\nintelligently classifies notifications based on individual user preferences.\nThrough a user study (N=18), we created the first MR notification dataset\ncontaining both self-labelled and interaction-based data across activities with\nvarying cognitive demands. Our thematic analysis revealed that, unlike in\nmobiles, the activity context is equally important as the content and the\nsender in determining notification urgency in MR. Leveraging these insights, we\ndeveloped PersoNo using large language models that analyse users replying\nbehaviour patterns. Our multi-agent approach achieved 81.5% accuracy and\nsignificantly reduced false negative rates (0.381) compared to baseline models.\nPersoNo has the potential not only to reduce unnecessary interruptions but also\nto offer users understanding and control of the system, adhering to\nHuman-Centered Artificial Intelligence design principles.", "AI": {"tldr": "PersoNo\u662f\u4e00\u79cd\u4e2a\u6027\u5316MR\u901a\u77e5\u7d27\u6025\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u7528\u6237\u884c\u4e3a\u548c\u6d3b\u52a8\u4e0a\u4e0b\u6587\u667a\u80fd\u5206\u7c7b\u901a\u77e5\uff0c\u51cf\u5c11\u4e2d\u65ad\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u89e3\u51b3MR\u73af\u5883\u4e2d\u56e0\u901a\u77e5\u6d41\u5bfc\u81f4\u7684\u4e2d\u65ad\u95ee\u9898\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u7528\u6237\u7814\u7a76\u521b\u5efa\u6570\u636e\u96c6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u7528\u6237\u56de\u590d\u884c\u4e3a\uff0c\u5f00\u53d1\u591a\u667a\u80fd\u4f53\u5206\u7c7b\u5668\u3002", "result": "\u5206\u7c7b\u51c6\u786e\u7387\u8fbe81.5%\uff0c\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\uff080.381\uff09\u3002", "conclusion": "PersoNo\u6709\u6548\u51cf\u5c11\u4e0d\u5fc5\u8981\u4e2d\u65ad\uff0c\u7b26\u5408\u4ee5\u4eba\u4e3a\u4e2d\u5fc3AI\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2508.19261", "pdf": "https://arxiv.org/pdf/2508.19261", "abs": "https://arxiv.org/abs/2508.19261", "authors": ["Miho Imai"], "title": "Floor sensors are cheap and easy to use! A Nihon Buyo Case Study", "categories": ["cs.HC"], "comment": null, "summary": "As floor-sensing technologies gain traction in movement research, questions\nremain about their usability and effectiveness for non-expert users. This study\npresents a case study evaluating Flexel, a modular, low-cost, high-resolution\npressure-sensing floor interface, in the context of Nihon Buyo, a traditional\nJapanese dance. The system was installed, calibrated, and used by a first-time,\nnon-technical user to track weight distribution patterns of a teacher and\nlearner over nine weeks. Live pressure data was synchronized with video\nrecordings, and custom software was developed to process and analyze the\nsignal. Despite expectations that the learner's weight distribution would\nconverge toward the teacher's over time, quantitative analyses revealed that\nthe learner developed a consistent yet distinct movement profile. These\nfindings suggest that even within rigid pedagogical structures, individual\nmovement signatures can emerge. More importantly, the study demonstrates that\nFlexel can be deployed and operated effectively by non-expert users,\nhighlighting its potential for broader adoption in education, performance, and\nembodied research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4f4e\u6210\u672c\u3001\u6a21\u5757\u5316\u538b\u529b\u611f\u5e94\u5730\u677f\u7cfb\u7edfFlexel\u5728\u4f20\u7edf\u65e5\u672c\u821e\u8e48\u6559\u5b66\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u53d1\u73b0\u975e\u6280\u672f\u7528\u6237\u53ef\u6709\u6548\u64cd\u4f5c\uff0c\u4e14\u5b66\u4e60\u8005\u5f62\u6210\u4e86\u72ec\u7279\u7684\u52a8\u4f5c\u7279\u5f81\u3002", "motivation": "\u63a2\u8ba8\u5730\u677f\u611f\u5e94\u6280\u672f\u5bf9\u975e\u4e13\u4e1a\u7528\u6237\u7684\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u5728\u4e5d\u5468\u5185\uff0c\u975e\u6280\u672f\u7528\u6237\u5b89\u88c5\u5e76\u4f7f\u7528Flexel\u7cfb\u7edf\u8bb0\u5f55\u548c\u5206\u6790\u821e\u8e48\u6559\u5e08\u4e0e\u5b66\u4e60\u8005\u7684\u91cd\u91cf\u5206\u5e03\u6a21\u5f0f\uff0c\u540c\u6b65\u89c6\u9891\u6570\u636e\u5e76\u5f00\u53d1\u5b9a\u5236\u8f6f\u4ef6\u5904\u7406\u4fe1\u53f7\u3002", "result": "\u5b66\u4e60\u8005\u672a\u5982\u9884\u671f\u822c\u63a5\u8fd1\u6559\u5e08\u7684\u91cd\u91cf\u5206\u5e03\uff0c\u800c\u662f\u5f62\u6210\u4e86\u72ec\u7279\u7684\u52a8\u4f5c\u7279\u5f81\u3002", "conclusion": "Flexel\u53ef\u7531\u975e\u4e13\u5bb6\u7528\u6237\u9ad8\u6548\u4f7f\u7528\uff0c\u9002\u5408\u6559\u80b2\u3001\u8868\u6f14\u548c\u52a8\u4f5c\u7814\u7a76\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2508.19430", "pdf": "https://arxiv.org/pdf/2508.19430", "abs": "https://arxiv.org/abs/2508.19430", "authors": ["Kangfeng Ye", "Roberto Metere", "Jim Woodcock", "Poonam Yadav"], "title": "Formal Verification of Physical Layer Security Protocols for Next-Generation Communication Networks", "categories": ["cs.CR", "cs.FL", "cs.LO"], "comment": "Submitted to ICFEM2025; 23 pages, 2 tables, and 6 figures", "summary": "Formal verification is crucial for ensuring the robustness of security\nprotocols against adversarial attacks. The Needham-Schroeder protocol, a\nfoundational authentication mechanism, has been extensively studied, including\nits integration with Physical Layer Security (PLS) techniques such as\nwatermarking and jamming. Recent research has used ProVerif to verify these\nmechanisms in terms of secrecy. However, the ProVerif-based approach limits the\nability to improve understanding of security beyond verification results. To\novercome these limitations, we re-model the same protocol using an Isabelle\nformalism that generates sound animation, enabling interactive and automated\nformal verification of security protocols. Our modelling and verification\nframework is generic and highly configurable, supporting both cryptography and\nPLS. For the same protocol, we have conducted a comprehensive analysis (secrecy\nand authenticity in four different eavesdropper locations under both passive\nand active attacks) using our new web interface. Our findings not only\nsuccessfully reproduce and reinforce previous results on secrecy but also\nreveal an uncommon but expected outcome: authenticity is preserved across all\nexamined scenarios, even in cases where secrecy is compromised. We have\nproposed a PLS-based Diffie-Hellman protocol that integrates watermarking and\njamming, and our analysis shows that it is secure for deriving a session key\nwith required authentication. These highlight the advantages of our novel\napproach, demonstrating its robustness in formally verifying security\nproperties beyond conventional methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eIsabelle\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790Needham-Schroeder\u534f\u8bae\u53ca\u5176\u4e0e\u7269\u7406\u5c42\u5b89\u5168\u6280\u672f\u7684\u96c6\u6210\uff0c\u514b\u670d\u4e86ProVerif\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5c55\u793a\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u548c\u5b89\u5168\u6027\u9a8c\u8bc1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684ProVerif\u65b9\u6cd5\u5728\u9a8c\u8bc1\u5b89\u5168\u534f\u8bae\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u63d0\u4f9b\u8d85\u51fa\u9a8c\u8bc1\u7ed3\u679c\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u4f5c\u8005\u91c7\u7528Isabelle\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u91cd\u65b0\u5efa\u6a21\u534f\u8bae\u5e76\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u81ea\u52a8\u5316\u9a8c\u8bc1\u6846\u67b6\uff0c\u652f\u6301\u5bc6\u7801\u5b66\u548c\u7269\u7406\u5c42\u5b89\u5168\u6280\u672f\u3002", "result": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9a8c\u8bc1\u4e86\u534f\u8bae\u7684\u4fdd\u5bc6\u6027\uff0c\u8fd8\u53d1\u73b0\u5176\u8ba4\u8bc1\u6027\u5728\u6240\u6709\u573a\u666f\u4e2d\u5747\u4fdd\u6301\u5b8c\u597d\uff0c\u4e14\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b89\u5168\u7684PLS-Diffie-Hellman\u534f\u8bae\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u65b0\u65b9\u6cd5\u5728\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e2d\u7684\u4f18\u52bf\uff0c\u80fd\u591f\u66f4\u5168\u9762\u5730\u9a8c\u8bc1\u5b89\u5168\u5c5e\u6027\uff0c\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u7684\u9650\u5236\u3002"}}
{"id": "2508.20044", "pdf": "https://arxiv.org/pdf/2508.20044", "abs": "https://arxiv.org/abs/2508.20044", "authors": ["Kfir Toledo", "Isaac Keslassy"], "title": "2SYN: Congestion-Aware Multihoming", "categories": ["cs.NI"], "comment": "Accepted at IEEE/IFIP NOMS", "summary": "When sending flows to arbitrary destinations, current multihoming routers\nadopt simple congestion-oblivious mechanisms. Therefore, they cannot avoid\ncongested paths.\n  In this paper, we introduce 2SYN, the first congestion-aware multihoming\nalgorithm that works for any destination. We explain how it dynamically selects\na preferred path for new connections, even given previously-unseen\ndestinations. We further demonstrate that it can be easily implemented in\nLinux. Finally, in a real-world experiment with either LTE or a wired link, we\nshow how 2SYN dynamically adapts to the quality of the connection and\noutperforms alternative approaches. Thus, 2SYN helps companies better manage\ntheir networks by leveraging their multihoming capabilities.", "AI": {"tldr": "2SYN\u662f\u4e00\u79cd\u9996\u4e2a\u9002\u7528\u4e8e\u4efb\u610f\u76ee\u7684\u5730\u7684\u62e5\u585e\u611f\u77e5\u591a\u5bbf\u4e3b\u7b97\u6cd5\uff0c\u80fd\u52a8\u6001\u9009\u62e9\u8def\u5f84\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u5bbf\u4e3b\u8def\u7531\u5668\u7f3a\u4e4f\u62e5\u585e\u611f\u77e5\u673a\u5236\uff0c\u65e0\u6cd5\u907f\u514d\u62e5\u585e\u8def\u5f84\u3002", "method": "\u63d0\u51fa2SYN\u7b97\u6cd5\uff0c\u52a8\u6001\u9009\u62e9\u65b0\u8fde\u63a5\u7684\u9996\u9009\u8def\u5f84\uff0c\u6613\u4e8e\u5728Linux\u4e2d\u5b9e\u73b0\u3002", "result": "\u771f\u5b9e\u5b9e\u9a8c\u4e2d\uff0c2SYN\u80fd\u52a8\u6001\u9002\u5e94\u8fde\u63a5\u8d28\u91cf\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "2SYN\u6709\u6548\u5e2e\u52a9\u4f01\u4e1a\u5229\u7528\u591a\u5bbf\u4e3b\u80fd\u529b\u4f18\u5316\u7f51\u7edc\u7ba1\u7406\u3002"}}
{"id": "2508.20016", "pdf": "https://arxiv.org/pdf/2508.20016", "abs": "https://arxiv.org/abs/2508.20016", "authors": ["Matthias Maiterth", "Wesley H. Brewer", "Jaya S. Kuruvella", "Arunavo Dey", "Tanzima Z. Islam", "Kevin Menear", "Dmitry Duplyakin", "Rashadul Kabir", "Tapasya Patki", "Terry Jones", "Feiyi Wang"], "title": "HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "comment": null, "summary": "Schedulers are critical for optimal resource utilization in high-performance\ncomputing. Traditional methods to evaluate schedulers are limited to\npost-deployment analysis, or simulators, which do not model associated\ninfrastructure. In this work, we present the first-of-its-kind integration of\nscheduling and digital twins in HPC. This enables what-if studies to understand\nthe impact of parameter configurations and scheduling decisions on the physical\nassets, even before deployment, or regarching changes not easily realizable in\nproduction. We (1) provide the first digital twin framework extended with\nscheduling capabilities, (2) integrate various top-tier HPC systems given their\npublicly available datasets, (3) implement extensions to integrate external\nscheduling simulators. Finally, we show how to (4) implement and evaluate\nincentive structures, as-well-as (5) evaluate machine learning based\nscheduling, in such novel digital-twin based meta-framework to prototype\nscheduling. Our work enables what-if scenarios of HPC systems to evaluate\nsustainability, and the impact on the simulated system.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9996\u6b21\u5c06\u8c03\u5ea6\u4e0e\u6570\u5b57\u5b6a\u751f\u6280\u672f\u6574\u5408\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u6846\u67b6\uff0c\u652f\u6301\u5728\u90e8\u7f72\u524d\u8fdb\u884c\u53c2\u6570\u914d\u7f6e\u548c\u8c03\u5ea6\u51b3\u7b56\u7684\u5f71\u54cd\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u8c03\u5ea6\u5668\u8bc4\u4f30\u65b9\u6cd5\u5c40\u9650\u4e8e\u90e8\u7f72\u540e\u5206\u6790\u6216\u6a21\u62df\u5668\uff0c\u65e0\u6cd5\u5efa\u6a21\u76f8\u5173\u57fa\u7840\u8bbe\u65bd\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4ee5\u96c6\u6210\u8c03\u5ea6\u529f\u80fd\uff0c\u6574\u5408\u9876\u7ea7HPC\u7cfb\u7edf\u6570\u636e\uff0c\u5e76\u5b9e\u73b0\u5916\u90e8\u8c03\u5ea6\u6a21\u62df\u5668\u7684\u96c6\u6210\u3002", "result": "\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u539f\u578b\u8c03\u5ea6\u6846\u67b6\uff0c\u652f\u6301\u53ef\u6301\u7eed\u6027\u548c\u6a21\u62df\u7cfb\u7edf\u5f71\u54cd\u7684\u5047\u8bbe\u6027\u7814\u7a76\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aHPC\u7cfb\u7edf\u7684\u8c03\u5ea6\u51b3\u7b56\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u9884\u90e8\u7f72\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2508.19372", "pdf": "https://arxiv.org/pdf/2508.19372", "abs": "https://arxiv.org/abs/2508.19372", "authors": ["Zikun Fu", "Chen Yang", "Kourosh Davoudi", "Ken Q. Pu"], "title": "Database Entity Recognition with Data Augmentation and Deep Learning", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "comment": "6 pages, 5 figures. Accepted at IEEE 26th International Conference on\n  Information Reuse and Integration for Data Science (IRI 2025), San Jose,\n  California, August 6-8, 2025", "summary": "This paper addresses the challenge of Database Entity Recognition (DB-ER) in\nNatural Language Queries (NLQ). We present several key contributions to advance\nthis field: (1) a human-annotated benchmark for DB-ER task, derived from\npopular text-to-sql benchmarks, (2) a novel data augmentation procedure that\nleverages automatic annotation of NLQs based on the corresponding SQL queries\nwhich are available in popular text-to-SQL benchmarks, (3) a specialized\nlanguage model based entity recognition model using T5 as a backbone and two\ndown-stream DB-ER tasks: sequence tagging and token classification for\nfine-tuning of backend and performing DB-ER respectively. We compared our DB-ER\ntagger with two state-of-the-art NER taggers, and observed better performance\nin both precision and recall for our model. The ablation evaluation shows that\ndata augmentation boosts precision and recall by over 10%, while fine-tuning of\nthe T5 backbone boosts these metrics by 5-10%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u6570\u636e\u5e93\u5b9e\u4f53\u8bc6\u522b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u4eba\u5de5\u6807\u6ce8\u57fa\u51c6\u3001\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u548c\u57fa\u4e8eT5\u7684\u8bed\u8a00\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u6570\u636e\u5e93\u5b9e\u4f53\u8bc6\u522b\u7684\u6311\u6218\uff0c\u63d0\u5347\u8bc6\u522b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4eba\u5de5\u6807\u6ce8\u57fa\u51c6\u3001\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u53ca\u57fa\u4e8eT5\u7684\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6570\u636e\u589e\u5f3a\u548c\u5fae\u8c03\u5206\u522b\u63d0\u5347\u6027\u80fd10%\u548c5-10%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u6570\u636e\u5e93\u5b9e\u4f53\u8bc6\u522b\u7684\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.19530", "pdf": "https://arxiv.org/pdf/2508.19530", "abs": "https://arxiv.org/abs/2508.19530", "authors": ["Yanyun Wang", "Dingcui Yu", "Yina Lv", "Yunpeng Song", "Yumiao Zhao", "Liang Shi"], "title": "RARO: Reliability-aware Conversion with Enhanced Read Performance for QLC SSDs", "categories": ["cs.AR"], "comment": null, "summary": "Quad-level cell (QLC) flash offers significant benefits in cost and capacity,\nbut its limited reliability leads to frequent read retries, which severely\ndegrade read performance. A common strategy in high-density flash storage is to\nprogram selected blocks in a low-density mode (SLC), sacrificing some capacity\nto achieve higher I/O performance. This hybrid storage architecture has been\nwidely adopted in consumer-grade storage systems. However, existing hybrid\nstorage schemes typically focus on write performance and rely solely on data\ntemperature for migration decisions. This often results in excessive mode\nswitching, causing substantial capacity overhead.\n  In this paper, we present RARO (Reliability-Aware Read performance\nOptimization), a hybrid flash management scheme designed to improve read\nperformance with minimal capacity cost. The key insight behind RARO is that\nmuch of the read slowdown in QLC flash is caused by read retries. RARO triggers\ndata migration only when hot data resides in QLC blocks experiencing a high\nnumber of read retries, significantly reducing unnecessary conversions and\ncapacity loss. Moreover, RARO supports fine-grained multi-mode conversions\n(SLC-TLC-QLC) to further minimize capacity overhead. By leveraging real-time\nread retry statistics and flash characteristics, RARO mitigates over-conversion\nand optimizes I/O performance. Experiments on the FEMU platform demonstrate\nthat RARO significantly improves read performance across diverse workloads,\nwith negligible impact on usable capacity.", "AI": {"tldr": "QLC\u5b58\u50a8\u56e0\u5176\u9ad8\u5bc6\u5ea6\u4f46\u53ef\u9760\u6027\u4f4e\u5bfc\u81f4\u9891\u7e41\u91cd\u8bfb\uff0cRARO\u65b9\u6848\u901a\u8fc7\u52a8\u6001\u8fc1\u79fb\u70ed\u70b9\u6570\u636e\u4f18\u5316\u8bfb\u6027\u80fd\uff0c\u51cf\u5c11\u5bb9\u91cf\u635f\u5931\u3002", "motivation": "\u9488\u5bf9QLC\u95ea\u5b58\u56e0\u8bfb\u91cd\u8bd5\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u517c\u987e\u6027\u80fd\u548c\u5bb9\u91cf\u7684\u7ba1\u7406\u65b9\u6848\u3002", "method": "RARO\u57fa\u4e8e\u8bfb\u91cd\u8bd5\u7edf\u8ba1\u6570\u636e\u52a8\u6001\u8fc1\u79fb\u70ed\u70b9\u6570\u636e\uff0c\u652f\u6301\u591a\u6a21\u5f0f\u8f6c\u6362\u4ee5\u51cf\u5c11\u5bb9\u91cf\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRARO\u663e\u8457\u63d0\u5347\u8bfb\u6027\u80fd\uff0c\u5bb9\u91cf\u5f71\u54cd\u53ef\u5ffd\u7565\u3002", "conclusion": "RARO\u6709\u6548\u5e73\u8861\u4e86QLC\u95ea\u5b58\u7684\u8bfb\u6027\u80fd\u4e0e\u5b58\u50a8\u5bb9\u91cf\u5229\u7528\u7387\u3002"}}
{"id": "2508.19452", "pdf": "https://arxiv.org/pdf/2508.19452", "abs": "https://arxiv.org/abs/2508.19452", "authors": ["Andrea Esposito", "Francesco P. Rossi", "Marco Bernardo", "Francesco Fabris", "Hubert Garavel"], "title": "Formal Modeling and Verification of the Algorand Consensus Protocol in CADP", "categories": ["cs.DC"], "comment": null, "summary": "Algorand is a scalable and secure permissionless blockchain that achieves\nproof-of-stake consensus via cryptographic self-sortition and binary Byzantine\nagreement. In this paper, we present a process algebraic model of the Algorand\nconsensus protocol with the aim of enabling rigorous formal verification. Our\nmodel captures the behavior of participants with respect to the structured\nalternation of consensus steps toward a committee-based agreement by means of a\nprobabilistic process calculus. We validate the correctness of the protocol in\nthe absence of adversaries and then extend our model to capture the influence\nof coordinated malicious nodes that can force the commit of an empty block\ninstead of the proposed one. The adversarial scenario is analyzed by using an\nequivalence-checking-based noninterference framework that we have implemented\nin the CADP verification toolkit. In addition to highlighting both the\nrobustness and the limitations of the Algorand protocol under adversarial\nassumptions, this work illustrates the added value of using formal methods for\nthe analysis of blockchain consensus algorithms.", "AI": {"tldr": "Algorand\u662f\u4e00\u4e2a\u901a\u8fc7\u52a0\u5bc6\u81ea\u6392\u5e8f\u548c\u4e8c\u8fdb\u5236\u62dc\u5360\u5ead\u534f\u8bae\u5b9e\u73b0\u65e0\u8bb8\u53ef\u533a\u5757\u94fe\u5171\u8bc6\u7684\u534f\u8bae\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fc7\u7a0b\u4ee3\u6570\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5176\u5171\u8bc6\u534f\u8bae\uff0c\u5e76\u5206\u6790\u4e86\u6076\u610f\u8282\u70b9\u7684\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u5bf9Algorand\u5171\u8bc6\u534f\u8bae\u8fdb\u884c\u4e25\u683c\u7684\u5f62\u5316\u9a8c\u8bc1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u8fc7\u7a0b\u4ee3\u6570\u6a21\u578b\u6355\u6349\u5176\u884c\u4e3a\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u6076\u610f\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528\u6982\u7387\u8fc7\u7a0b\u6f14\u7b97\u5efa\u6a21\u5171\u8bc6\u6b65\u9aa4\uff0c\u5e76\u901a\u8fc7CADP\u5de5\u5177\u5305\u4e2d\u7684\u7b49\u4ef7\u6027\u68c0\u67e5\u6846\u67b6\u5206\u6790\u6076\u610f\u8282\u70b9\u7684\u5f71\u54cd\u3002", "result": "\u9a8c\u8bc1\u4e86\u534f\u8bae\u5728\u65e0\u653b\u51fb\u60c5\u51b5\u4e0b\u7684\u6b63\u786e\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u6076\u610f\u8282\u70b9\u653b\u51fb\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u5982\u53ef\u80fd\u8feb\u4f7f\u63d0\u4ea4\u7a7a\u533a\u5757\u3002", "conclusion": "\u5f62\u5f0f\u5316\u65b9\u6cd5\u6709\u52a9\u4e8e\u6df1\u5165\u5206\u6790\u533a\u5757\u94fe\u5171\u8bc6\u7b97\u6cd5\uff0c\u9a8c\u8bc1\u4e86Algorand\u534f\u8bae\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u4e5f\u6307\u51fa\u4e86\u5176\u6f5c\u5728\u95ee\u9898\u3002"}}
{"id": "2508.19882", "pdf": "https://arxiv.org/pdf/2508.19882", "abs": "https://arxiv.org/abs/2508.19882", "authors": ["Qunying Song", "He Ye", "Mark Harman", "Federica Sarro"], "title": "Generative AI for Testing of Autonomous Driving Systems: A Survey", "categories": ["cs.SE", "cs.AI"], "comment": "67 pages, 6 figures, 29 tables", "summary": "Autonomous driving systems (ADS) have been an active area of research, with\nthe potential to deliver significant benefits to society. However, before\nlarge-scale deployment on public roads, extensive testing is necessary to\nvalidate their functionality and safety under diverse driving conditions.\nTherefore, different testing approaches are required, and achieving effective\nand efficient testing of ADS remains an open challenge. Recently, generative AI\nhas emerged as a powerful tool across many domains, and it is increasingly\nbeing applied to ADS testing due to its ability to interpret context, reason\nabout complex tasks, and generate diverse outputs. To gain a deeper\nunderstanding of its role in ADS testing, we systematically analyzed 91\nrelevant studies and synthesized their findings into six major application\ncategories, primarily centered on scenario-based testing of ADS. We also\nreviewed their effectiveness and compiled a wide range of datasets, simulators,\nADS, metrics, and benchmarks used for evaluation, while identifying 27\nlimitations. This survey provides an overview and practical insights into the\nuse of generative AI for testing ADS, highlights existing challenges, and\noutlines directions for future research in this rapidly evolving field.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u751f\u6210\u5f0fAI\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf(ADS)\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5206\u679091\u9879\u7814\u7a76\uff0c\u603b\u7ed3\u4e86\u516d\u5927\u5e94\u7528\u7c7b\u522b\u3001\u8bc4\u4f30\u5de5\u5177\u53ca27\u9879\u5c40\u9650\u3002", "motivation": "\u89e3\u51b3ADS\u5927\u89c4\u6a21\u90e8\u7f72\u524d\u7684\u6d4b\u8bd5\u6311\u6218\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u7684\u6f5c\u529b\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u591a\u6837\u6027\u3002", "method": "\u7cfb\u7edf\u5206\u679091\u9879\u76f8\u5173\u7814\u7a76\uff0c\u603b\u7ed3\u751f\u6210\u5f0fAI\u5728ADS\u6d4b\u8bd5\u4e2d\u7684\u4e3b\u8981\u5e94\u7528\u7c7b\u522b\u53ca\u5176\u8bc4\u4f30\u5de5\u5177\u3002", "result": "\u603b\u7ed3\u4e86\u516d\u5927\u5e94\u7528\u7c7b\u522b\u3001\u6570\u636e\u96c6\u3001\u4eff\u771f\u5de5\u5177\u3001\u8bc4\u4f30\u6307\u6807\u53ca27\u9879\u5c40\u9650\u6027\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728ADS\u6d4b\u8bd5\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.20088", "pdf": "https://arxiv.org/pdf/2508.20088", "abs": "https://arxiv.org/abs/2508.20088", "authors": ["Yuxin Guo", "Teng Wang", "Yuying Ge", "Shijie Ma", "Yixiao Ge", "Wei Zou", "Ying Shan"], "title": "AudioStory: Generating Long-Form Narrative Audio with Large Language Models", "categories": ["cs.CV", "cs.MM", "cs.SD"], "comment": null, "summary": "Recent advances in text-to-audio (TTA) generation excel at synthesizing short\naudio clips but struggle with long-form narrative audio, which requires\ntemporal coherence and compositional reasoning. To address this gap, we propose\nAudioStory, a unified framework that integrates large language models (LLMs)\nwith TTA systems to generate structured, long-form audio narratives. AudioStory\npossesses strong instruction-following reasoning generation capabilities. It\nemploys LLMs to decompose complex narrative queries into temporally ordered\nsub-tasks with contextual cues, enabling coherent scene transitions and\nemotional tone consistency. AudioStory has two appealing features: (1)\nDecoupled bridging mechanism: AudioStory disentangles LLM-diffuser\ncollaboration into two specialized components, i.e., a bridging query for\nintra-event semantic alignment and a residual query for cross-event coherence\npreservation. (2) End-to-end training: By unifying instruction comprehension\nand audio generation within a single end-to-end framework, AudioStory\neliminates the need for modular training pipelines while enhancing synergy\nbetween components. Furthermore, we establish a benchmark AudioStory-10K,\nencompassing diverse domains such as animated soundscapes and natural sound\nnarratives. Extensive experiments show the superiority of AudioStory on both\nsingle-audio generation and narrative audio generation, surpassing prior TTA\nbaselines in both instruction-following ability and audio fidelity. Our code is\navailable at https://github.com/TencentARC/AudioStory", "AI": {"tldr": "AudioStory\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6587\u672c\u5230\u97f3\u9891\u751f\u6210\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u65f6\u5e8f\u8fde\u8d2f\u6027\u548c\u60c5\u611f\u4e00\u81f4\u6027\u7684\u957f\u53d9\u4e8b\u97f3\u9891\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6587\u672c\u5230\u97f3\u9891\u751f\u6210\u7cfb\u7edf\u5728\u957f\u53d9\u4e8b\u97f3\u9891\u751f\u6210\u4e2d\u7f3a\u4e4f\u65f6\u5e8f\u8fde\u8d2f\u6027\u548c\u7ec4\u5408\u63a8\u7406\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "AudioStory\u901a\u8fc7LLM\u5206\u89e3\u590d\u6742\u53d9\u4e8b\u67e5\u8be2\u4e3a\u65f6\u5e8f\u5b50\u4efb\u52a1\uff0c\u5e76\u4f7f\u7528\u89e3\u8026\u7684\u6865\u63a5\u673a\u5236\u548c\u7aef\u5230\u7aef\u8bad\u7ec3\u4f18\u5316\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAudioStory\u5728\u751f\u6210\u53d9\u4e8b\u97f3\u9891\u65f6\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5177\u6709\u66f4\u597d\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u548c\u97f3\u9891\u4fdd\u771f\u5ea6\u3002", "conclusion": "AudioStory\u4e3a\u957f\u53d9\u4e8b\u97f3\u9891\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.19264", "pdf": "https://arxiv.org/pdf/2508.19264", "abs": "https://arxiv.org/abs/2508.19264", "authors": ["Bijean Ghafouri"], "title": "A Theory of Information, Variation, and Artificial Intelligence", "categories": ["cs.HC", "cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "A growing body of empirical work suggests that the widespread adoption of\ngenerative AI produces a significant homogenizing effect on information,\ncreativity, and cultural production. I first develop a novel theoretical\nframework to explain this phenomenon. I argue that a dynamic of AI-derivative\nepistemology, in which individuals increasingly defer to AI outputs, allows a\ncentralized AI Prism to function, a technical mechanism whose architecture is\ndesigned to reduce variance and converge on the statistical mean. This provides\na causal explanation for the generative monocultures observed in recent\nstudies. However, I contend this represents only the first stage of a more\ncomplex and dialectical process. This paper's central and paradoxical thesis is\nthat the very homogenization that flattens knowledge within specialized domains\nsimultaneously renders that knowledge into consistent modules that can be\nrecombined across them, a process foundational to innovation and creativity.\nHowever, this recombinant potential is not automatic, but rather conditional.\nThis paper argues that these opposing forces, homogenizing defaults versus\nrecombinant possibilities, are governed by the nature of human engagement with\nthe technology. The ultimate effect of generative AI is conditional on whether\nindividuals act as passive consumers deferring to the AI's statistical outputs,\nor as active curators who critically interrogate, re-contextualize, and\nrecombine them. The paper concludes by outlining the cognitive and\ninstitutional scaffolds required to resolve this tension, arguing they are the\ndecisive variable that determine whether generative AI becomes an instrument of\ninnovation or homogenization.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u7684\u5e7f\u6cdb\u91c7\u7528\u5bf9\u4fe1\u606f\u3001\u521b\u9020\u529b\u548c\u6587\u5316\u751f\u4ea7\u7684\u540c\u8d28\u5316\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u548c\u8fa9\u8bc1\u89c6\u89d2\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u89e3\u91ca\u751f\u6210\u5f0fAI\u5982\u4f55\u901a\u8fc7\u6280\u672f\u673a\u5236\uff08AI Prism\uff09\u51cf\u5c11\u65b9\u5dee\u5e76\u5bfc\u81f4\u77e5\u8bc6\u540c\u8d28\u5316\uff0c\u540c\u65f6\u63a2\u8ba8\u5176\u6f5c\u5728\u7684\u521b\u65b0\u91cd\u7ec4\u53ef\u80fd\u6027\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u201cAI\u884d\u751f\u8ba4\u8bc6\u8bba\u201d\u6982\u5ff5\uff0c\u5206\u6790\u4e86AI\u7684\u96c6\u4e2d\u5316\u673a\u5236\u548c\u4eba\u7c7b\u53c2\u4e0e\u7684\u4e0d\u540c\u65b9\u5f0f\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u6307\u51fa\uff0c\u751f\u6210\u5f0fAI\u7684\u5f71\u54cd\u53d6\u51b3\u4e8e\u4eba\u7c7b\u662f\u88ab\u52a8\u63a5\u53d7\u8f93\u51fa\u8fd8\u662f\u4e3b\u52a8\u91cd\u65b0\u7ec4\u5408\u548c\u6279\u5224\u6027\u601d\u8003\uff0c\u8fd9\u51b3\u5b9a\u4e86\u5176\u6700\u7ec8\u662f\u540c\u8d28\u5316\u5de5\u5177\u8fd8\u662f\u521b\u65b0\u63a8\u52a8\u8005\u3002", "conclusion": "\u8bba\u6587\u7ed3\u8bba\u5f3a\u8c03\uff0c\u8ba4\u77e5\u548c\u5236\u5ea6\u6027\u652f\u6301\u662f\u5173\u952e\u53d8\u91cf\uff0c\u51b3\u5b9a\u4e86\u751f\u6210\u5f0fAI\u662f\u4fc3\u8fdb\u521b\u65b0\u8fd8\u662f\u52a0\u5267\u540c\u8d28\u5316\u3002"}}
{"id": "2508.20060", "pdf": "https://arxiv.org/pdf/2508.20060", "abs": "https://arxiv.org/abs/2508.20060", "authors": ["Daqian Ding", "Yibo Pi", "Cailian Chen"], "title": "A First Look at Inter-Cell Interference in the Wild", "categories": ["cs.NI"], "comment": null, "summary": "In cellular networks, inter-cell interference management has been studied for\ndecades, yet its real-world effectiveness remains under-explored. To bridge\nthis gap, we conduct a first measurement study of inter-cell interference for\noperational 4G/5G networks. Our findings reveal the prevalence of inter-cell\ninterference and a surprising absence of interference coordination among\noperational base stations. As a result, user equipments experience unnecessary\ninterference, which causes significant signal quality degradation, especially\nunder frequency-selective channel fading. We examine the inter-cell\ninterference issues from four major perspectives: network deployment, channel\nassignment, time-frequency resource allocation, and network configuration. In\nnone of these dimensions is inter-cell interference effectively managed.\nNotably, even when spectrum resources are underutilized and simple strategies\ncould effectively mitigate inter-cell interference, base stations consistently\nprioritize using the same set of time-frequency resources, causing interference\nacross cells. Our measurements reveal substantial opportunities for improving\nsignal quality by inter-cell interference management.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5bf94G/5G\u7f51\u7edc\u4e2d\u7684\u5c0f\u533a\u95f4\u5e72\u6270\u8fdb\u884c\u4e86\u73b0\u5b9e\u6d4b\u91cf\uff0c\u63ed\u793a\u4e86\u5b9e\u9645\u7f51\u7edc\u4e2d\u5e72\u6270\u7ba1\u7406\u7684\u4e0d\u8db3\u53ca\u5176\u5bf9\u4fe1\u53f7\u8d28\u91cf\u7684\u4e25\u91cd\u5f71\u54cd\u3002", "motivation": "\u586b\u8865\u4e86\u5173\u4e8e\u5c0f\u533a\u95f4\u5e72\u6270\u5728\u5b9e\u9645\u7f51\u7edc\u4e2d\u6709\u6548\u6027\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u7814\u7a76\uff0c\u4ece\u7f51\u7edc\u90e8\u7f72\u3001\u4fe1\u9053\u5206\u914d\u3001\u65f6\u9891\u8d44\u6e90\u5206\u914d\u548c\u7f51\u7edc\u914d\u7f6e\u56db\u4e2a\u7ef4\u5ea6\u5206\u6790\u5c0f\u533a\u95f4\u5e72\u6270\u95ee\u9898\u3002", "result": "\u53d1\u73b0\u5c0f\u533a\u95f4\u5e72\u6270\u666e\u904d\u5b58\u5728\u4e14\u7f3a\u4e4f\u534f\u8c03\uff0c\u5bfc\u81f4\u4fe1\u53f7\u8d28\u91cf\u4e0b\u964d\uff1b\u5373\u4f7f\u8d44\u6e90\u672a\u5145\u5206\u5229\u7528\uff0c\u57fa\u7ad9\u4ecd\u503e\u5411\u4e8e\u4f7f\u7528\u76f8\u540c\u65f6\u9891\u8d44\u6e90\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u901a\u8fc7\u4f18\u5316\u5e72\u6270\u7ba1\u7406\u53ef\u663e\u8457\u63d0\u5347\u4fe1\u53f7\u8d28\u91cf\u7684\u6f5c\u5728\u673a\u4f1a\u3002"}}
{"id": "2508.19656", "pdf": "https://arxiv.org/pdf/2508.19656", "abs": "https://arxiv.org/abs/2508.19656", "authors": ["Polykarpos Vergos", "Theofanis Vergos", "Florentia Afentaki", "Konstantinos Balaskas", "Georgios Zervakis"], "title": "Support Vector Machines Classification on Bendable RISC-V", "categories": ["cs.AR"], "comment": "Accepted for publication at the IEEE Computer Society Annual\n  Symposium on VLSI (ISVLSI '25)", "summary": "Flexible Electronics (FE) technology offers uniquecharacteristics in\nelectronic manufacturing, providing ultra-low-cost, lightweight, and\nenvironmentally-friendly alternatives totraditional rigid electronics. These\ncharacteristics enable a rangeof applications that were previously constrained\nby the costand rigidity of conventional silicon technology. Machine learning\n(ML) is essential for enabling autonomous, real-time intelligenceon devices\nwith smart sensing capabilities in everyday objects. However, the large feature\nsizes and high power consumption ofthe devices oppose a challenge in the\nrealization of flexible ML applications. To address the above, we propose an\nopen-source framework for developing ML co-processors for the Bendable RISC-V\ncore. In addition, we present a custom ML accelerator architecture for Support\nVector Machine (SVM), supporting both one-vs-one (OvO) and one-vs-rest (OvR)\nalgorithms. Our ML accelerator adopts a generic, precision-scalable design,\nsupporting 4-, 8-, and 16-bit weight representations. Experimental results\ndemonstrate a 21x improvement in both inference execution time and energy\nefficiency, on average, highlighting its potential for low-power, flexible\nintelligence on the edge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u53d1\u652f\u6301Bendable RISC-V\u6838\u5fc3\u7684\u673a\u5668\u5b66\u4e60\u534f\u5904\u7406\u5668\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u901a\u7528\u7684\u3001\u7cbe\u5ea6\u53ef\u6269\u5c55\u7684SVM\u52a0\u901f\u5668\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6267\u884c\u65f6\u95f4\u548c\u80fd\u6e90\u6548\u7387\u3002", "motivation": "\u67d4\u6027\u7535\u5b50\u6280\u672f\u4e3a\u4f20\u7edf\u521a\u6027\u7535\u5b50\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u8f7b\u91cf\u5316\u548c\u73af\u4fdd\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5728\u5b9e\u73b0\u7075\u6d3b\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u65f6\uff0c\u4ecd\u9700\u89e3\u51b3\u5668\u4ef6\u4f53\u79ef\u5927\u548c\u529f\u8017\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u534f\u5904\u7406\u5668\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u652f\u6301OvO\u548cOvR\u7b97\u6cd5\u7684SVM\u52a0\u901f\u5668\u67b6\u6784\uff0c\u652f\u6301\u591a\u79cd\u6743\u91cd\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u67b6\u6784\u5e73\u5747\u63d0\u5347\u4e8621\u500d\u7684\u63a8\u7406\u6267\u884c\u65f6\u95f4\u548c\u80fd\u6e90\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u67b6\u6784\u4e3a\u8fb9\u7f18\u8bbe\u5907\u7684\u4f4e\u529f\u8017\u3001\u7075\u6d3b\u667a\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19495", "pdf": "https://arxiv.org/pdf/2508.19495", "abs": "https://arxiv.org/abs/2508.19495", "authors": ["Muhammad Ahmed Mohsin", "Junaid Ahmad", "Muhammad Hamza Nawaz", "Muhammad Ali Jamshed"], "title": "Towards 6G Intelligence: The Role of Generative AI in Future Wireless Networks", "categories": ["cs.DC", "cs.LG", "eess.SP"], "comment": "Submitted as a chapter to the book Ambient Intelligence for 6G", "summary": "Ambient intelligence (AmI) is a computing paradigm in which physical\nenvironments are embedded with sensing, computation, and communication so they\ncan perceive people and context, decide appropriate actions, and respond\nautonomously. Realizing AmI at global scale requires sixth generation (6G)\nwireless networks with capabilities for real time perception, reasoning, and\naction aligned with human behavior and mobility patterns. We argue that\nGenerative Artificial Intelligence (GenAI) is the creative core of such\nenvironments. Unlike traditional AI, GenAI learns data distributions and can\ngenerate realistic samples, making it well suited to close key AmI gaps,\nincluding generating synthetic sensor and channel data in under observed areas,\ntranslating user intent into compact, semantic messages, predicting future\nnetwork conditions for proactive control, and updating digital twins without\ncompromising privacy.\n  This chapter reviews foundational GenAI models, GANs, VAEs, diffusion models,\nand generative transformers, and connects them to practical AmI use cases,\nincluding spectrum sharing, ultra reliable low latency communication,\nintelligent security, and context aware digital twins. We also examine how 6G\nenablers, such as edge and fog computing, IoT device swarms, intelligent\nreflecting surfaces (IRS), and non terrestrial networks, can host or accelerate\ndistributed GenAI. Finally, we outline open challenges in energy efficient on\ndevice training, trustworthy synthetic data, federated generative learning, and\nAmI specific standardization. We show that GenAI is not a peripheral addition,\nbut a foundational element for transforming 6G from a faster network into an\nambient intelligent ecosystem.", "AI": {"tldr": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u662f\u7b2c\u516d\u4ee3\uff086G\uff09\u65e0\u7ebf\u7f51\u7edc\u5b9e\u73b0\u73af\u5883\u667a\u80fd\uff08AmI\uff09\u7684\u6838\u5fc3\u6280\u672f\uff0c\u901a\u8fc7\u751f\u6210\u5408\u6210\u6570\u636e\u548c\u9884\u6d4b\u7f51\u7edc\u6761\u4ef6\u6765\u5f25\u8865\u5173\u952e\u5dee\u8ddd\u3002", "motivation": "\u5b9e\u73b0\u5168\u7403\u8303\u56f4\u7684AmI\u9700\u89816G\u7f51\u7edc\u5177\u5907\u5b9e\u65f6\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\u80fd\u529b\uff0cGenAI\u80fd\u591f\u901a\u8fc7\u5b66\u4e60\u6570\u636e\u5206\u5e03\u548c\u751f\u6210\u6837\u672c\uff0c\u586b\u8865AmI\u4e2d\u7684\u5173\u952e\u7a7a\u767d\u3002", "method": "\u4ecb\u7ecd\u4e86GANs\u3001VAEs\u3001\u6269\u6563\u6a21\u578b\u548c\u751f\u6210\u5f0f\u53d8\u6362\u5668\u7b49GenAI\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u9891\u8c31\u5171\u4eab\u3001\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u7b49AmI\u7528\u4f8b\uff0c\u540c\u65f6\u63a2\u8ba8\u4e866G\u6280\u672f\u5bf9\u5206\u5e03\u5f0fGenAI\u7684\u652f\u6301\u3002", "result": "GenAI\u4e0d\u4ec5\u80fd\u591f\u652f\u63016G\u7f51\u7edc\u7684\u667a\u80fd\u5316\u8f6c\u578b\uff0c\u8fd8\u80fd\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u7f51\u7edc\u9884\u6d4b\u7b49\u65b9\u9762\u53d1\u6325\u4f5c\u7528\u3002", "conclusion": "GenAI\u662f\u5b9e\u73b06G\u5411\u73af\u5883\u667a\u80fd\u751f\u6001\u7cfb\u7edf\u7684\u8f6c\u53d8\u7684\u57fa\u7840\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u80fd\u6548\u3001\u53ef\u4fe1\u5408\u6210\u6570\u636e\u7b49\u6280\u672f\u6311\u6218\u3002"}}
{"id": "2508.20086", "pdf": "https://arxiv.org/pdf/2508.20086", "abs": "https://arxiv.org/abs/2508.20086", "authors": ["Youwei Huang", "Jianwen Li", "Sen Fang", "Yao Li", "Peng Yang", "Bin Hu", "Tao Zhang"], "title": "Smart Contract Intent Detection with Pre-trained Programming Language Model", "categories": ["cs.SE", "cs.CR"], "comment": "10 pages, 5 figures, conference", "summary": "Malicious intent in smart contract development can lead to substantial\neconomic losses. SmartIntentNN is a deep learning model specifically designed\nto identify unsafe intents in smart contracts. This model integrates the\nUniversal Sentence Encoder, a K-means clustering-based intent highlighting\nmechanism, and a Bidirectional Long Short-Term Memory network for multi-label\nclassification, achieving an F1 of 0.8633 in distinguishing ten different\nintent categories. In this study, we present an upgraded version of this model,\nSmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant\nenhancement in V2 is the incorporation of a BERT-based pre-trained language\nmodel, which has been trained on a dataset of 16,000 real smart contracts using\na Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based\nmulti-label classification network. With an improved F1 of 0.927, V2\ndemonstrates enhanced performance compared to its predecessor, establishing\nitself as the state-of-the-art model for smart contract intent detection.", "AI": {"tldr": "SmartIntentNN2\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4b\u667a\u80fd\u5408\u7ea6\u4e2d\u7684\u6076\u610f\u610f\u56fe\uff0c\u7ed3\u5408BERT\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548cBiLSTM\u7f51\u7edc\uff0c\u6027\u80fd\u4f18\u4e8e\u524d\u4ee3\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u4e2d\u7684\u6076\u610f\u610f\u56fe\u53ef\u80fd\u5bfc\u81f4\u91cd\u5927\u7ecf\u6d4e\u635f\u5931\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408BERT\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548cBiLSTM\u7f51\u7edc\uff0c\u8bad\u7ec3\u4e8e16,000\u4e2a\u771f\u5b9e\u667a\u80fd\u5408\u7ea6\u6570\u636e\u96c6\u3002", "result": "\u6539\u8fdb\u540e\u7684\u6a21\u578bF1\u5206\u6570\u4e3a0.927\uff0c\u4f18\u4e8e\u524d\u4ee3\u76840.8633\u3002", "conclusion": "SmartIntentNN2\u6210\u4e3a\u667a\u80fd\u5408\u7ea6\u610f\u56fe\u68c0\u6d4b\u7684\u5148\u8fdb\u6a21\u578b\u3002"}}
{"id": "2508.19378", "pdf": "https://arxiv.org/pdf/2508.19378", "abs": "https://arxiv.org/abs/2508.19378", "authors": ["K. K. Kim", "S. P. McGrath", "D. Lindeman"], "title": "Improving Hypertension and Diabetes Outcomes with Digital Care Coordination and Remote Monitoring in Rural Health", "categories": ["cs.HC", "H.5; J.3"], "comment": "12 pages, 1 figure", "summary": "Chronic illnesses are a global concern with essential hypertension and\ndiabetes mellitus among the most common conditions. Remote patient monitoring\nhas shown promising results on clinical and health outcomes. However, access to\ncare and digital health solutions is limited among rural, lower-income, and\nolder adult populations. This paper repots on a pre-post study of a\ncomprehensive care coordination program including connected, wearable blood\npressure and glucometer devices, tablets, and medical assistant-provided health\ncoaching in a community health center in rural California. The participants\n(n=221) had a mean age of 54.6 years, were majority female, two-thirds spoke\nSpanish, 19.9% had hypertension, 49.8% diabetic, and 30.3% both conditions.\nParticipants with hypertension achieved a mean reduction in systolic blood\npressure of 20.24 (95% CI: 13.61, 26.87) at six months while those with\ndiabetes achieved a mean reduction of 3.85 points (95% CI: 3.73, 4.88). These\noutcomes compare favorably to the small but growing body of evidence supporting\ndigital care coordination and remote monitoring. These results also support the\nfeasibility of well-designed digital health solutions yielding improved health\noutcomes among underserved communities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u6570\u5b57\u5065\u5eb7\u534f\u8c03\u53ca\u8fdc\u7a0b\u76d1\u6d4b\u5bf9\u519c\u6751\u5730\u533a\u6162\u6027\u75c5\u60a3\u8005\uff08\u5982\u9ad8\u8840\u538b\u548c\u7cd6\u5c3f\u75c5\uff09\u7684\u6548\u679c\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u7a7f\u6234\u8bbe\u5907\u548c\u5065\u5eb7\u6307\u5bfc\u540e\uff0c\u60a3\u8005\u7684\u8840\u538b\u548c\u8840\u7cd6\u663e\u8457\u6539\u5584\u3002", "motivation": "\u9488\u5bf9\u519c\u6751\u3001\u4f4e\u6536\u5165\u53ca\u8001\u5e74\u4eba\u7fa4\u5065\u5eb7\u7ba1\u7406\u548c\u6570\u5b57\u533b\u7597\u8d44\u6e90\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7814\u7a76\u63a2\u7d22\u4e86\u6570\u5b57\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u524d\u540e\u5bf9\u7167\u7814\u7a76\uff0c\u4f7f\u7528\u53ef\u7a7f\u6234\u8840\u538b\u8ba1\u3001\u8840\u7cd6\u4eea\u3001\u5e73\u677f\u7535\u8111\u53ca\u5065\u5eb7\u6307\u5bfc\uff0c\u5728\u52a0\u5dde\u519c\u6751\u793e\u533a\u5065\u5eb7\u4e2d\u5fc3\u5bf9221\u540d\u60a3\u8005\u8fdb\u884c\u4e86\u5e72\u9884\u3002", "result": "\u9ad8\u8840\u538b\u60a3\u8005\u7684\u6536\u7f29\u538b\u5e73\u5747\u4e0b\u964d20.24mmHg\uff0c\u7cd6\u5c3f\u75c5\u60a3\u8005\u7684\u8840\u7cd6\u5e73\u5747\u4e0b\u964d3.85\u70b9\uff0c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u7814\u7a76\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u5b57\u5065\u5eb7\u65b9\u6848\u80fd\u6709\u6548\u6539\u5584\u5f31\u52bf\u7fa4\u4f53\u7684\u5065\u5eb7\u7ed3\u679c\uff0c\u652f\u6301\u5176\u5728\u57fa\u5c42\u533b\u7597\u4e2d\u7684\u63a8\u5e7f\u3002"}}
{"id": "2508.20077", "pdf": "https://arxiv.org/pdf/2508.20077", "abs": "https://arxiv.org/abs/2508.20077", "authors": ["Tao Xiuyuan", "Milena Radenkovic"], "title": "ML-MaxProp: Bridging Machine Learning and Delay-Tolerant Routing for Resilient Post-Disaster Communication", "categories": ["cs.NI"], "comment": null, "summary": "In disaster-stricken and large-scale urban emergency scenarios, ensuring\nreliable communication remains a formidable challenge, as collapsed\ninfrastructure, unpredictable mobility, and severely constrained resources\ndisrupt conventional networks. Delay-Tolerant Networks (DTNs), though resilient\nthrough their store-carry-forward paradigm, reveal the fundamental weaknesses\nof classical protocols - Epidemic, Spray-and-Wait, and MaxProp - when\nconfronted with sparse encounters, buffer shortages, and volatile connectivity.\nTo address these obstacles, this study proposes ML-MaxProp, a hybrid routing\nprotocol that strengthens MaxProp with supervised machine learning. By\nleveraging contextual features such as encounter frequency, hop count, buffer\noccupancy, message age, and time-to-live (TTL), ML-MaxProp predicts relay\nsuitability in real time, transforming rigid heuristics into adaptive\nintelligence. Extensive simulations in the ONE environment using the Helsinki\nSPMBM mobility model show that ML-MaxProp consistently surpasses baseline\nprotocols, achieving higher delivery probability, lower latency, and reduced\noverhead. Statistical validation further shows that these improvements are both\nsignificant and robust, even under highly resource-constrained and unstable\nconditions. Overall, this work shows that ML-MaxProp is not just an incremental\nrefinement but a lightweight, adaptive, and practical solution to one of the\nhardest challenges in DTNs: sustaining mission-critical communication when\ninfrastructure collapses and every forwarding decision becomes critical.", "AI": {"tldr": "ML-MaxProp\u662f\u4e00\u79cd\u7ed3\u5408\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7684\u6df7\u5408\u8def\u7531\u534f\u8bae\uff0c\u901a\u8fc7\u5b9e\u65f6\u9884\u6d4b\u8f6c\u53d1\u8282\u70b9\u9002\u5e94\u6027\u548c\u52a8\u6001\u4f18\u5316\u8f6c\u53d1\u51b3\u7b56\uff0c\u5728\u707e\u96be\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u53ef\u9760\u6027\u3002", "motivation": "\u707e\u96be\u548c\u5927\u89c4\u6a21\u57ce\u5e02\u7d27\u6025\u60c5\u51b5\u4e0b\uff0c\u4f20\u7edf\u901a\u4fe1\u7f51\u7edc\u56e0\u57fa\u7840\u8bbe\u65bd\u5d29\u6e83\u548c\u8d44\u6e90\u53d7\u9650\u800c\u5931\u6548\uff0c\u73b0\u6709DTN\u534f\u8bae\u5728\u7a00\u758f\u76f8\u9047\u548c\u7f13\u5b58\u4e0d\u8db3\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "ML-MaxProp\u5229\u7528\u673a\u5668\u5b66\u4e60\u52a8\u6001\u8bc4\u4f30\u8282\u70b9\u8f6c\u53d1\u80fd\u529b\uff08\u5982\u76f8\u9047\u9891\u7387\u3001\u8df3\u6570\u3001\u7f13\u5b58\u5360\u7528\u7b49\uff09\uff0c\u53d6\u4ee3\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u5728ONE\u6a21\u62df\u5668\u4e2d\uff0cML-MaxProp\u76f8\u6bd4\u57fa\u7ebf\u534f\u8bae\u663e\u8457\u63d0\u5347\u4e86\u6295\u9012\u7387\u3001\u964d\u4f4e\u5ef6\u8fdf\u548c\u5f00\u9500\uff0c\u4e14\u7ed3\u679c\u7edf\u8ba1\u663e\u8457\u3002", "conclusion": "ML-MaxProp\u662fDTN\u4e2d\u8f7b\u91cf\u7ea7\u3001\u81ea\u9002\u5e94\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u5728\u6781\u7aef\u6761\u4ef6\u4e0b\u7ef4\u6301\u5173\u952e\u901a\u4fe1\u3002"}}
{"id": "2508.19868", "pdf": "https://arxiv.org/pdf/2508.19868", "abs": "https://arxiv.org/abs/2508.19868", "authors": ["Geraldo F. Oliveira"], "title": "New Tools, Programming Models, and System Support for Processing-in-Memory Architectures", "categories": ["cs.AR", "cs.DC"], "comment": "Doctoral thesis", "summary": "Our goal in this dissertation is to provide tools, programming models, and\nsystem support for PIM architectures (with a focus on DRAM-based solutions), to\nease the adoption of PIM in current and future systems. To this end, we make at\nleast four new major contributions.\n  First, we introduce DAMOV, the first rigorous methodology to characterize\nmemory-related data movement bottlenecks in modern workloads, and the first\ndata movement benchmark suite. Second, we introduce MIMDRAM, a new\nhardware/software co-designed substrate that addresses the major current\nprogrammability and flexibility limitations of the bulk bitwise execution model\nof processing-using-DRAM (PUD) architectures. MIMDRAM enables the allocation\nand control of only the needed computing resources inside DRAM for PUD\ncomputing. Third, we introduce Proteus, the first hardware framework that\naddresses the high execution latency of bulk bitwise PUD operations in\nstate-of-the-art PUD architectures by implementing a data-aware runtime engine\nfor PUD. Proteus reduces the latency of PUD operations in three different ways:\n(i) Proteus concurrently executes independent in-DRAM primitives belong to a\nsingle PUD operation across DRAM arrays. (ii) Proteus dynamically reduces the\nbit-precision (and consequentially the latency and energy consumption) of PUD\noperations by exploiting narrow values (i.e., values with many leading zeros or\nones). (iii) Proteus chooses and uses the most appropriate data representation\nand arithmetic algorithm implementation for a given PUD instruction\ntransparently to the programmer. Fourth, we introduce DaPPA (data-parallel\nprocessing-in-memory architecture), a new programming framework that eases\nprogrammability for general-purpose PNM architectures by allowing the\nprogrammer to write efficient PIM-friendly code without the need to manage\nhardware resources explicitly.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9DRAM-based PIM\u67b6\u6784\u7684\u5de5\u5177\u3001\u7f16\u7a0b\u6a21\u578b\u548c\u7cfb\u7edf\u652f\u6301\uff0c\u5305\u62ec\u56db\u79cd\u4e3b\u8981\u8d21\u732e\uff1aDAMOV\uff08\u6570\u636e\u79fb\u52a8\u74f6\u9888\u5206\u6790\u65b9\u6cd5\uff09\u3001MIMDRAM\uff08\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff09\u3001Proteus\uff08\u964d\u4f4ePUD\u64cd\u4f5c\u5ef6\u8fdf\u7684\u8fd0\u884c\u65f6\u5f15\u64ce\uff09\u548cDaPPA\uff08\u7b80\u5316\u7f16\u7a0b\u7684\u6846\u67b6\uff09\u3002", "motivation": "\u4e3a\u4e86\u63a8\u52a8PIM\u5728\u5f53\u524d\u548c\u672a\u6765\u7cfb\u7edf\u4e2d\u7684\u666e\u53ca\uff0c\u8bba\u6587\u65e8\u5728\u89e3\u51b3PIM\u67b6\u6784\u4e2d\u7684\u6570\u636e\u79fb\u52a8\u74f6\u9888\u3001\u7075\u6d3b\u6027\u548c\u7f16\u7a0b\u6027\u7b49\u6838\u5fc3\u95ee\u9898\u3002", "method": "1. DAMOV\uff1a\u6570\u636e\u79fb\u52a8\u5206\u6790\u548c\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff1b2. MIMDRAM\uff1a\u4f18\u5316DRAM\u8ba1\u7b97\u7684\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\uff1b3. Proteus\uff1a\u901a\u8fc7\u5e76\u884c\u6267\u884c\u3001\u52a8\u6001\u7cbe\u5ea6\u8c03\u6574\u548c\u4f18\u5316\u6570\u636e\u8868\u793a\u6765\u964d\u4f4ePUD\u64cd\u4f5c\u5ef6\u8fdf\uff1b4. DaPPA\uff1a\u7b80\u5316\u7f16\u7a0b\u6a21\u578b\u7684\u6846\u67b6\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u7684\u56db\u79cd\u65b9\u6cd5\u5206\u522b\u89e3\u51b3\u4e86PIM\u67b6\u6784\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\u548c\u6613\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u521b\u65b0\u7684\u5de5\u5177\u548c\u6846\u67b6\uff0c\u8bba\u6587\u4e3aPIM\u67b6\u6784\u7684\u666e\u53ca\u63d0\u4f9b\u4e86\u5b9e\u7528\u652f\u6301\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5176\u6027\u80fd\u548c\u7f16\u7a0b\u53cb\u597d\u6027\u3002"}}
{"id": "2508.19559", "pdf": "https://arxiv.org/pdf/2508.19559", "abs": "https://arxiv.org/abs/2508.19559", "authors": ["Rongzhi Li", "Ruogu Du", "Zefang Chu", "Sida Zhao", "Chunlei Han", "Zuocheng Shi", "Yiwen Shao", "Huanle Han", "Long Huang", "Zherui Liu", "Shufan Liu"], "title": "Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Serving Large Language Models (LLMs) is a GPU-intensive task where\ntraditional autoscalers fall short, particularly for modern Prefill-Decode\n(P/D) disaggregated architectures. This architectural shift, while powerful,\nintroduces significant operational challenges, including inefficient use of\nheterogeneous hardware, network bottlenecks, and critical imbalances between\nprefill and decode stages. We introduce HeteroScale, a coordinated autoscaling\nframework that addresses the core challenges of P/D disaggregated serving.\nHeteroScale combines a topology-aware scheduler that adapts to heterogeneous\nhardware and network constraints with a novel metric-driven policy derived from\nthe first large-scale empirical study of autoscaling signals in production. By\nleveraging a single, robust metric to jointly scale prefill and decode pools,\nHeteroScale maintains architectural balance while ensuring efficient, adaptive\nresource management. Deployed in a massive production environment on tens of\nthousands of GPUs, HeteroScale has proven its effectiveness, increasing average\nGPU utilization by a significant 26.6 percentage points and saving hundreds of\nthousands of GPU-hours daily, all while upholding stringent service level\nobjectives.", "AI": {"tldr": "HeteroScale\u662f\u4e00\u4e2a\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9884\u586b\u5145-\u89e3\u7801\uff08P/D\uff09\u89e3\u8026\u67b6\u6784\u7684\u81ea\u52a8\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u8c03\u5ea6\u548c\u65b0\u578b\u6307\u6807\u9a71\u52a8\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347GPU\u5229\u7528\u7387\u548c\u8282\u7ea6\u8d44\u6e90\u3002", "motivation": "\u4f20\u7edf\u7684\u81ea\u52a8\u6269\u5c55\u673a\u5236\u5728\u73b0\u4ee3P/D\u89e3\u8026\u67b6\u6784\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u786c\u4ef6\u5229\u7528\u4e0d\u5747\u3001\u7f51\u7edc\u74f6\u9888\u548c\u9636\u6bb5\u4e0d\u5e73\u8861\u7b49\u95ee\u9898\u3002", "method": "HeteroScale\u7ed3\u5408\u4e86\u62d3\u6251\u611f\u77e5\u8c03\u5ea6\u5668\u548c\u57fa\u4e8e\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u7684\u6307\u6807\u9a71\u52a8\u7b56\u7565\uff0c\u901a\u8fc7\u5355\u4e00\u7a33\u5065\u6307\u6807\u8054\u5408\u6269\u5c55\u9884\u586b\u5145\u548c\u89e3\u7801\u6c60\u3002", "result": "\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u540e\uff0cGPU\u5e73\u5747\u5229\u7528\u7387\u63d0\u5347\u4e8626.6\u4e2a\u767e\u5206\u70b9\uff0c\u6bcf\u65e5\u8282\u7701\u6570\u5341\u4e07GPU\u5c0f\u65f6\uff0c\u540c\u65f6\u6ee1\u8db3\u4e25\u683c\u7684\u670d\u52a1\u6c34\u5e73\u76ee\u6807\u3002", "conclusion": "HeteroScale\u6709\u6548\u89e3\u51b3\u4e86P/D\u89e3\u8026\u67b6\u6784\u7684\u6269\u5c55\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u7684\u9ad8\u6548\u7ba1\u7406\u548c\u67b6\u6784\u5e73\u8861\u3002"}}
{"id": "2508.19276", "pdf": "https://arxiv.org/pdf/2508.19276", "abs": "https://arxiv.org/abs/2508.19276", "authors": ["Marcos Guillermo Lammers", "Federico Hern\u00e1n Holik", "Alejandro Fern\u00e1ndez"], "title": "Quantum Resource Management in the NISQ Era: Challenges, Vision, and a Runtime Framework", "categories": ["quant-ph", "cs.SE", "physics.comp-ph"], "comment": null, "summary": "Quantum computers represent a radical technological advancement in the way\ninformation is processed by using the principles of quantum mechanics to solve\nvery complex problems that exceed the capabilities of classical systems.\nHowever, in the current NISQ era (Noisy Intermediate-Scale Quantum devices),\nthe available hardware presents several limitations, such as a limited number\nof qubits, high error rates, and reduced coherence times. Efficient management\nof quantum resources, both physical (qubits, error rates, connectivity) and\nlogical (quantum gates, algorithms, error correction), becomes particularly\nrelevant in the design and deployment of quantum algorithms. In this work, we\nanalyze the role of resources in the various uses of NISQ devices today,\nidentifying their relevance and implications for software engineering focused\non the use of quantum computers. We propose a vision for runtime-aware quantum\nsoftware development, identifying key challenges to its realization, such as\nlimited introspection capabilities and temporal constraints in current\nplatforms. As a proof of concept, we introduce Qonscious, a prototype framework\nthat enables conditional execution of quantum programs based on dynamic\nresource evaluation. With this contribution, we aim to strengthen the field of\nQuantum Resource Estimation (QRE) and move towards the development of scalable,\nreliable, and resource-aware quantum software.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u5728NISQ\u65f6\u4ee3\u5982\u4f55\u9ad8\u6548\u7ba1\u7406\u91cf\u5b50\u8d44\u6e90\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aQonscious\u7684\u539f\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8e\u52a8\u6001\u8d44\u6e90\u8bc4\u4f30\u6267\u884c\u91cf\u5b50\u7a0b\u5e8f\u3002", "motivation": "\u5f53\u524dNISQ\u8bbe\u5907\u7684\u786c\u4ef6\u5c40\u9650\u6027\uff08\u5982\u6709\u9650\u7684\u91cf\u5b50\u6bd4\u7279\u3001\u9ad8\u9519\u8bef\u7387\u548c\u77ed\u7684\u76f8\u5e72\u65f6\u95f4\uff09\u4f7f\u5f97\u9ad8\u6548\u7ba1\u7406\u91cf\u5b50\u8d44\u6e90\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\uff0c\u4ee5\u5f00\u53d1\u53ef\u9760\u7684\u91cf\u5b50\u8f6f\u4ef6\u3002", "method": "\u8bba\u6587\u5206\u6790\u4e86\u8d44\u6e90\u5728\u5f53\u524dNISQ\u8bbe\u5907\u4e2d\u7684\u89d2\u8272\uff0c\u63d0\u51fa\u4e86\u8fd0\u884c\u65f6\u611f\u77e5\u7684\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u613f\u666f\uff0c\u5e76\u8bbe\u8ba1\u4e86Qonscious\u6846\u67b6\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7Qonscious\u6846\u67b6\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u57fa\u4e8e\u52a8\u6001\u8d44\u6e90\u8bc4\u4f30\u5b9e\u73b0\u91cf\u5b50\u7a0b\u5e8f\u7684\u6761\u4ef6\u6267\u884c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a8\u52a8\u4e86\u91cf\u5b50\u8d44\u6e90\u4f30\u8ba1\uff08QRE\uff09\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5e76\u4e3a\u5f00\u53d1\u53ef\u6269\u5c55\u3001\u53ef\u9760\u4e14\u8d44\u6e90\u611f\u77e5\u7684\u91cf\u5b50\u8f6f\u4ef6\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.19407", "pdf": "https://arxiv.org/pdf/2508.19407", "abs": "https://arxiv.org/abs/2508.19407", "authors": ["Ruhan Yang", "Ellen Yi-Luen Do"], "title": "Exploring Paper as a Material: Plotting the Design Space of The Fabrication for Dynamic Paper-Based Interactions", "categories": ["cs.HC"], "comment": null, "summary": "We reviewed 43 papers to understand the fabrication of dynamic paper-based\ninteractions. We used a design space to classify tool selection, technique\nchoice, and exploration of paper as a material. We classified 9 dimensions for\nthe design space, including 4 dimensions for tools (precision, accommodation,\ncomplexity, and availability), 3 dimensions for techniques (cutting techniques,\nfolding techniques, and integration techniques), and 2 dimensions for paper as\nthe material (paper weight and paper type). The patterns we observed in the\ndesign space indicate a majority use of high precision tools, high complexity\ntools, and surface integration techniques in previous practice. Meanwhile,\nprinting and plain paper are the leading material choices. We analyze these\npatterns and suggest potential directions for future work. Our study helps\nresearchers locate different fabrication approaches and instances, thus\nfostering innovation in the field of paper-based interaction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e8643\u7bc7\u5173\u4e8e\u52a8\u6001\u7eb8\u8d28\u4ea4\u4e92\u5236\u9020\u7684\u6587\u732e\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bbe\u8ba1\u7a7a\u95f4\u6765\u5206\u7c7b\u5de5\u5177\u9009\u62e9\u3001\u6280\u672f\u9009\u62e9\u548c\u6750\u6599\u63a2\u7d22\uff0c\u5e76\u5206\u6790\u4e86\u5f53\u524d\u5b9e\u8df5\u7684\u5e38\u7528\u65b9\u6cd5\u548c\u6f5c\u5728\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4e3a\u4e86\u7406\u89e3\u52a8\u6001\u7eb8\u8d28\u4ea4\u4e92\u7684\u5236\u9020\u65b9\u6cd5\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u521b\u65b0\u7684\u65b9\u5411\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u542b9\u4e2a\u7ef4\u5ea6\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff08\u5de5\u51774\u7ef4\u3001\u6280\u672f3\u7ef4\u3001\u6750\u65992\u7ef4\uff09\uff0c\u5bf943\u7bc7\u8bba\u6587\u8fdb\u884c\u4e86\u5206\u7c7b\u548c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u5b9e\u8df5\u4e2d\u4e3b\u8981\u4f7f\u7528\u9ad8\u7cbe\u5ea6\u5de5\u5177\u3001\u9ad8\u590d\u6742\u5ea6\u5de5\u5177\u548c\u8868\u9762\u96c6\u6210\u6280\u672f\uff0c\u5e38\u7528\u6750\u6599\u4e3a\u5370\u5237\u7eb8\u548c\u666e\u901a\u7eb8\u3002", "conclusion": "\u7814\u7a76\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5b9a\u4f4d\u4e0d\u540c\u7684\u5236\u9020\u65b9\u6cd5\u548c\u5b9e\u4f8b\uff0c\u63a8\u52a8\u7eb8\u57fa\u4ea4\u4e92\u9886\u57df\u7684\u521b\u65b0\u3002"}}
{"id": "2508.19548", "pdf": "https://arxiv.org/pdf/2508.19548", "abs": "https://arxiv.org/abs/2508.19548", "authors": ["Madhuvanthi Srivatsav R", "Chiranjib Bhattacharyya", "Shantanu Chakrabartty", "Chetan Singh Thakur"], "title": "When Routers, Switches and Interconnects Compute: A processing-in-interconnect Paradigm for Scalable Neuromorphic AI", "categories": ["cs.NE", "cs.AR", "cs.NI"], "comment": null, "summary": "Routing, switching, and the interconnect fabric are essential for large-scale\nneuromorphic computing. While this fabric only plays a supporting role in the\nprocess of computing, for large AI workloads it ultimately determines energy\nconsumption and speed. In this paper, we address this bottleneck by asking: (a)\nWhat computing paradigms are inherent in existing routing, switching, and\ninterconnect systems, and how can they be used to implement a\nprocessing-in-Interconnect (\\pi^2) computing paradigm? and (b) leveraging\ncurrent and future interconnect trends, how will a \\pi^2 system's performance\nscale compared to other neuromorphic architectures? For (a), we show that\noperations required for typical AI workloads can be mapped onto delays,\ncausality, time-outs, packet drop, and broadcast operations -- primitives\nalready implemented in packet-switching and packet-routing hardware. We show\nthat existing buffering and traffic-shaping embedded algorithms can be\nleveraged to implement neuron models and synaptic operations. Additionally, a\nknowledge-distillation framework can train and cross-map well-established\nneural network topologies onto $\\pi^2$ without degrading generalization\nperformance. For (b), analytical modeling shows that, unlike other neuromorphic\nplatforms, the energy scaling of $\\pi^2$ improves with interconnect bandwidth\nand energy efficiency. We predict that by leveraging trends in interconnect\ntechnology, a \\pi^2 architecture can be more easily scaled to execute\nbrain-scale AI inference workloads with power consumption levels in the range\nof hundreds of watts.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u8def\u7531\u3001\u4ea4\u6362\u548c\u4e92\u8fde\u6280\u672f\u5b9e\u73b0\u5904\u7406-in-Interconnect\uff08\u03c0\u00b2\uff09\u8ba1\u7b97\u8303\u5f0f\uff0c\u4ee5\u63d0\u9ad8\u5927\u89c4\u6a21\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u7684\u80fd\u6548\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21AI\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u8def\u7531\u3001\u4ea4\u6362\u548c\u4e92\u8fde\u7cfb\u7edf\u7684\u80fd\u6e90\u6d88\u8017\u548c\u901f\u5ea6\u74f6\u9888\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6620\u5c04AI\u5de5\u4f5c\u8d1f\u8f7d\u5230\u5df2\u6709\u7684\u6570\u636e\u5305\u4ea4\u6362\u786c\u4ef6\u539f\u8bed\uff0c\u5229\u7528\u73b0\u6709\u7b97\u6cd5\u5b9e\u73b0\u795e\u7ecf\u5143\u6a21\u578b\u548c\u7a81\u89e6\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u03c0\u00b2\u67b6\u6784\u7684\u80fd\u6e90\u6548\u7387\u968f\u4e92\u8fde\u5e26\u5bbd\u63d0\u5347\u800c\u6539\u5584\uff0c\u80fd\u591f\u4ee5\u6570\u767e\u74e6\u7684\u529f\u8017\u6267\u884c\u8111\u89c4\u6a21AI\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u3002", "conclusion": "\u03c0\u00b2\u67b6\u6784\u901a\u8fc7\u5229\u7528\u4e92\u8fde\u6280\u672f\u8d8b\u52bf\uff0c\u4e3a\u5927\u89c4\u6a21\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19670", "pdf": "https://arxiv.org/pdf/2508.19670", "abs": "https://arxiv.org/abs/2508.19670", "authors": ["Diogo Costa", "Jose Martins", "Sandro Pinto"], "title": "Beyond the Bermuda Triangle of Contention: IOMMU Interference in Mixed Criticality Systems", "categories": ["cs.DC", "cs.SY", "eess.SY"], "comment": null, "summary": "As Mixed Criticality Systems (MCSs) evolve, they increasingly integrate\nheterogeneous computing platforms, combining general-purpose processors with\nspecialized accelerators such as AI engines, GPUs, and high-speed networking\ninterfaces. This heterogeneity introduces challenges, as these accelerators and\nDMA-capable devices act as independent bus masters, directly accessing memory.\nConsequently, ensuring both security and timing predictability in such\nenvironments becomes critical. To address these concerns, the Input-Output\nMemory Management Unit (IOMMU) plays a key role in mediating and regulating\nmemory access, preventing unauthorized transactions while enforcing isolation\nand access control policies. While prior work has explored IOMMU-related\nside-channel vulnerabilities from a security standpoint, its role in\nperformance interference remains largely unexplored. Moreover, many of the same\narchitectural properties that enable side-channel leakage, such as shared TLBs,\ncaching effects, and translation overheads, can also introduce timing\nunpredictability. In this work, we analyze the contention effects within IOMMU\nstructures using the Xilinx UltraScale+ ZCU104 platform, demonstrating how\ntheir shared nature introduce unpredictable delays. Our findings reveal that\nIOMMU-induced interference primarily affects small memory transactions, where\ntranslation overheads significantly impact execution time. Additionally, we\nhypothesize that contention effects arising from IOTLBs exhibit similar\nbehavior across architectures due to shared caching principles, such as\nprefetching and hierarchical TLB structures. Notably, our experiments show that\nIOMMU interference can delay DMA transactions by up to 1.79x for lower-size\ntransfers on the Arm SMMUv2 implementation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6df7\u5408\u5173\u952e\u6027\u7cfb\u7edf\u4e2dIOMMU\u7684\u6027\u80fd\u5e72\u6270\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u5176\u5728\u5c0f\u5185\u5b58\u4e8b\u52a1\u4e2d\u5f15\u5165\u4e0d\u53ef\u9884\u6d4b\u5ef6\u8fdf\u7684\u73b0\u8c61\u3002", "motivation": "\u968f\u7740\u6df7\u5408\u5173\u952e\u6027\u7cfb\u7edf\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u786e\u4fdd\u5f02\u6784\u8ba1\u7b97\u5e73\u53f0\u7684\u65f6\u5e8f\u53ef\u9884\u6d4b\u6027\u548c\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662fIOMMU\u5728\u6b64\u73af\u5883\u4e2d\u7684\u4f5c\u7528\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528Xilinx UltraScale+ ZCU104\u5e73\u53f0\u5206\u6790\u4e86IOMMU\u7ed3\u6784\u4e2d\u7684\u4e89\u7528\u6548\u5e94\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIOMMU\u5e72\u6270\u53ef\u5bfc\u81f4Arm SMMUv2\u5b9e\u73b0\u4e2dDMA\u4e8b\u52a1\u5ef6\u8fdf\u6700\u9ad8\u589e\u52a01.79\u500d\uff0c\u5c24\u5176\u662f\u5728\u5c0f\u5185\u5b58\u4e8b\u52a1\u4e2d\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "IOMMU\u7684\u5171\u4eab\u7279\u6027\uff08\u5982TLB\u548c\u7f13\u5b58\u6548\u5e94\uff09\u53ef\u80fd\u5bfc\u81f4\u4e0d\u53ef\u9884\u6d4b\u7684\u5ef6\u8fdf\uff0c\u8fd9\u5728\u4e0d\u540c\u67b6\u6784\u4e2d\u53ef\u80fd\u5177\u6709\u76f8\u4f3c\u884c\u4e3a\u3002"}}
{"id": "2508.19463", "pdf": "https://arxiv.org/pdf/2508.19463", "abs": "https://arxiv.org/abs/2508.19463", "authors": ["Paluck Deep", "Monica Bharadhidasan", "A. Baki Kocaballi"], "title": "\"She was useful, but a bit too optimistic\": Augmenting Design with Interactive Virtual Personas", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Personas have been widely used to understand and communicate user needs in\nhuman-centred design. Despite their utility, they may fail to meet the demands\nof iterative workflows due to their static nature, limited engagement, and\ninability to adapt to evolving design needs. Recent advances in large language\nmodels (LLMs) pave the way for more engaging and adaptive approaches to user\nrepresentation. This paper introduces Interactive Virtual Personas (IVPs):\nmultimodal, LLM-driven, conversational user simulations that designers can\ninterview, brainstorm with, and gather feedback from in real time via voice\ninterface. We conducted a qualitative study with eight professional UX\ndesigners, employing an IVP named \"Alice\" across three design activities: user\nresearch, ideation, and prototype evaluation. Our findings demonstrate the\npotential of IVPs to expedite information gathering, inspire design solutions,\nand provide rapid user-like feedback. However, designers raised concerns about\nbiases, over-optimism, the challenge of ensuring authenticity without real\nstakeholder input, and the inability of the IVP to fully replicate the nuances\nof human interaction. Our participants emphasised that IVPs should be viewed as\na complement to, not a replacement for, real user engagement. We discuss\nstrategies for prompt engineering, human-in-the-loop integration, and ethical\nconsiderations for effective and responsible IVP use in design. Finally, our\nwork contributes to the growing body of research on generative AI in the design\nprocess by providing insights into UX designers' experiences of LLM-powered\ninteractive personas.", "AI": {"tldr": "\u603b\u7ed3\uff1a\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u4ea4\u4e92\u5f0f\u865a\u62df\u89d2\u8272\uff08IVPs\uff09\uff0c\u7528\u4e8e\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u65f6\u7528\u6237\u6a21\u62df\uff0c\u901a\u8fc7\u5b9a\u6027\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4f46\u4e5f\u6307\u51fa\u5176\u5c40\u9650\u6027\u548c\u9700\u6ce8\u610f\u7684\u4f26\u7406\u95ee\u9898\u3002", "motivation": "\u52a8\u673a\uff1a\u4f20\u7edf\u89d2\u8272\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u56e0\u9759\u6001\u6027\u548c\u9002\u5e94\u6027\u4e0d\u8db3\uff0c\u96be\u4ee5\u6ee1\u8db3\u8fed\u4ee3\u8bbe\u8ba1\u9700\u6c42\uff0c\u56e0\u6b64\u63a2\u7d22\u66f4\u52a8\u6001\u3001\u9002\u5e94\u6027\u5f3a\u7684\u7528\u6237\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u65b9\u6cd5\uff1a\u5f15\u5165IVPs\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u6a21\u62df\uff0c\u8ba9\u8bbe\u8ba1\u5e08\u5b9e\u65f6\u4ea4\u4e92\u5e76\u8fdb\u884c\u7528\u6237\u7814\u7a76\u3001\u521b\u610f\u6784\u601d\u548c\u539f\u578b\u8bc4\u4f30\uff0c\u901a\u8fc78\u540dUX\u8bbe\u8ba1\u5e08\u7684\u5b9a\u6027\u7814\u7a76\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\uff1aIVPs\u80fd\u52a0\u901f\u4fe1\u606f\u6536\u96c6\u3001\u6fc0\u53d1\u8bbe\u8ba1\u7075\u611f\u5e76\u63d0\u4f9b\u5feb\u901f\u53cd\u9988\uff0c\u4f46\u4e5f\u5b58\u5728\u504f\u89c1\u3001\u8fc7\u5ea6\u4e50\u89c2\u7b49\u95ee\u9898\uff0c\u8bbe\u8ba1\u5e08\u8ba4\u4e3a\u5176\u65e0\u6cd5\u5b8c\u5168\u66ff\u4ee3\u771f\u5b9e\u7528\u6237\u53c2\u4e0e\u3002", "conclusion": "\u7ed3\u8bba\uff1aIVPs\u53ef\u4f5c\u4e3a\u771f\u5b9e\u7528\u6237\u53c2\u4e0e\u7684\u8865\u5145\uff0c\u9700\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u4eba\u673a\u4ea4\u4e92\u548c\u4f26\u7406\u8003\u8651\uff0c\u4ee5\u8d1f\u8d23\u4efb\u7684\u65b9\u5f0f\u4f7f\u7528\u3002"}}
{"id": "2508.19657", "pdf": "https://arxiv.org/pdf/2508.19657", "abs": "https://arxiv.org/abs/2508.19657", "authors": ["Jorge L. Gonz\u00e1lez-Rios", "Liz Mart\u00ednez Marrero", "Juan Duncan", "Luis M. Garc\u00e9s-Socarr\u00e1s", "Raudel Cuiman Marquez", "Juan A. V\u00e1squez Peralvo", "Jevgenij Krivochiza", "Symeon Chatzinotas", "Bj\u00f6rn Ottersten"], "title": "Demonstrator Testbed for Effective Precoding in MEO Multibeam Satellites", "categories": ["eess.SP", "cs.AR"], "comment": null, "summary": "The use of communication satellites in medium Earth orbit (MEO) is foreseen\nto provide quasi-global broadband Internet connectivity in the coming\nnetworking ecosystems. Multi-user multiple-input single-output (MU-MISO)\ndigital signal processing techniques, such as precoding, emerge as appealing\ntechnological enablers in the forward link of multi-beam satellite systems\noperating in full frequency reuse (FFR). However, the orbit dynamics of MEO\nsatellites pose additional challenges that must be carefully evaluated and\naddressed. This work presents the design of an in-lab testbed based on\nsoftware-defined radio (SDR) platforms and the corresponding adaptations\nrequired for efficient precoding in a MEO scenario. The setup incorporates a\nprecise orbit model and the radiation pattern of a custom-designed direct\nradiating array (DRA). We analyze the main impairments affecting precoding\nperformance, including Doppler shifts and payload phase noise, and propose a\nsynchronization loop to mitigate these effects. Preliminary experimental\nresults validate the feasibility and effectiveness of the proposed solution.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8eSDR\u5e73\u53f0\u7684\u5b9e\u9a8c\u5e73\u53f0\uff0c\u7528\u4e8eMEO\u536b\u661f\u573a\u666f\u4e2d\u7684\u9ad8\u6548\u9884\u7f16\u7801\uff0c\u5e76\u901a\u8fc7\u540c\u6b65\u73af\u8def\u89e3\u51b3\u591a\u666e\u52d2\u9891\u79fb\u548c\u76f8\u4f4d\u566a\u58f0\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u53ef\u884c\u6027\u3002", "motivation": "MEO\u536b\u661f\u901a\u4fe1\u5728\u5bbd\u5e26\u4e92\u8054\u7f51\u8fde\u63a5\u4e2d\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u5176\u8f68\u9053\u52a8\u529b\u5b66\u95ee\u9898\u7ed9\u9884\u7f16\u7801\u6280\u672f\u5e26\u6765\u6311\u6218\uff0c\u9700\u89e3\u51b3\u591a\u666e\u52d2\u9891\u79fb\u548c\u76f8\u4f4d\u566a\u58f0\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8f6f\u4ef6\u5b9a\u4e49\u65e0\u7ebf\u7535\uff08SDR\uff09\u5e73\u53f0\u8bbe\u8ba1\u5b9e\u9a8c\u5e73\u53f0\uff0c\u7ed3\u5408\u7cbe\u786e\u8f68\u9053\u6a21\u578b\u548c\u5b9a\u5236\u8f90\u5c04\u9635\u5217\uff0c\u63d0\u51fa\u540c\u6b65\u73af\u8def\u4ee5\u89e3\u51b3\u4fe1\u53f7\u5904\u7406\u95ee\u9898\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6848\u5728MEO\u573a\u666f\u4e0b\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aMEO\u536b\u661f\u901a\u4fe1\u4e2d\u7684\u9ad8\u6548\u9884\u7f16\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u7f51\u7edc\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2508.19805", "pdf": "https://arxiv.org/pdf/2508.19805", "abs": "https://arxiv.org/abs/2508.19805", "authors": ["Shota Naito", "Tsukasa Ninomiya", "Koichi Wada"], "title": "Separation of Three or More Autonomous Mobile Models under Hierarchical Schedulers", "categories": ["cs.DC"], "comment": null, "summary": "Understanding the computational power of mobile robot systems is a\nfundamental challenge in distributed computing. While prior work has focused on\npairwise separations between models, we explore how robot capabilities, light\nobservability, and scheduler synchrony interact in more complex ways.\n  We first show that the Exponential Times Expansion (ETE) problem is solvable\nonly in the strongest model -- fully-synchronous robots with full mutual lights\n($\\mathcal{LUMT}^F$). We then introduce the Hexagonal Edge Traversal (HET) and\nTAR(d)* problems to demonstrate how internal memory and lights interact with\nsynchrony: under weak synchrony, internal memory alone is insufficient, while\nfull synchrony can substitute for both lights and memory.\n  In the asynchronous setting, we classify problems such as LP-MLCv, VEC, and\nZCC to show fine-grained separations between $\\mathcal{FSTA}$ and\n$\\mathcal{FCOM}$ robots. We also analyze Vertex Traversal Rendezvous (VTR) and\nLeave Place Convergence (LP-Cv), illustrating the limitations of internal\nmemory in symmetric settings.\n  These results extend the known separation map of 14 canonical robot models,\nrevealing structural phenomena only visible through higher-order comparisons.\nOur work provides new impossibility criteria and deepens the understanding of\nhow observability, memory, and synchrony collectively shape the computational\npower of mobile robots.", "AI": {"tldr": "\u63a2\u7d22\u79fb\u52a8\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u8ba1\u7b97\u80fd\u529b\u7684\u590d\u6742\u6027\uff0c\u63ed\u793a\u80fd\u529b\u3001\u5149\u7167\u53ef\u89c6\u6027\u548c\u8c03\u5ea6\u540c\u6b65\u6027\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u79fb\u52a8\u673a\u5668\u4eba\u6a21\u578b\u4e4b\u95f4\u7684\u9ad8\u9636\u6bd4\u8f83\uff0c\u6269\u5c55\u5df2\u77e5\u7684\u8ba1\u7b97\u80fd\u529b\u5206\u79bb\u56fe\u3002", "method": "\u901a\u8fc7\u89e3\u51b3\u95ee\u9898\uff08\u5982ETE\u3001HET\u3001TAR(d)*\u7b49\uff09\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5206\u6790\u5185\u90e8\u5185\u5b58\u3001\u5149\u7167\u548c\u540c\u6b65\u6027\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u5c55\u793a\u4e86\u5149\u7167\u548c\u540c\u6b65\u6027\u5728\u4e0d\u540c\u6a21\u578b\u4e2d\u7684\u66ff\u4ee3\u4f5c\u7528\uff0c\u4ee5\u53ca\u5185\u90e8\u5185\u5b58\u5728\u5f02\u6b65\u548c\u5bf9\u79f0\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u63ed\u793a\u4e86\u79fb\u52a8\u673a\u5668\u4eba\u8ba1\u7b97\u80fd\u529b\u7684\u65b0\u6807\u51c6\uff0c\u6df1\u5316\u4e86\u5bf9\u89c2\u5bdf\u6027\u3001\u5185\u5b58\u548c\u540c\u6b65\u6027\u76f8\u4e92\u4f5c\u7528\u7684\u7406\u89e3\u3002"}}
{"id": "2508.19517", "pdf": "https://arxiv.org/pdf/2508.19517", "abs": "https://arxiv.org/abs/2508.19517", "authors": ["Srishti Palani", "Gonzalo Ramos"], "title": "Orchid: Orchestrating Context Across Creative Workflows with Generative AI", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Context is critical for meaningful interactions between people and Generative\nAI (GenAI). Yet mainstream tools offer limited means to orchestrate it,\nparticularly across workflows that span multiple interactions, sessions, and\nmodels, as often occurs in creative projects. Re specifying prior details,\njuggling diverse artifacts, and dealing with context drift overwhelm users,\nobscure intent, and curtail creativity. To address these challenges, we present\nOrchid, a system that gives its users affordances to specify, reference, and\nmonitor context throughout evolving workflows. Specifically, Orchid enables\nusers to (1) specify context related to the project, themselves, and different\nstyles, (2) reference these via explicit mentions, inline selection, or\nimplicit grounding, and (3) monitor context assigned to different interactions\nacross the workflow. In a within-subjects study (n=12), participants using\nOrchid to execute creative tasks (compared to a baseline toolkit of web search,\nLLM-based chat, and digital notebooks) produced more novel and feasible\noutcomes, reporting greater alignment between their intent and the AI's\nresponses, higher perceived control, and increased transparency. By\nprioritizing context orchestration, Orchid offers an actionable step toward\nnext generation GenAI tools that support complex, iterative workflows -\nenabling creators and AI to stay aligned and augment their creative potential.", "AI": {"tldr": "Orchid\u662f\u4e00\u4e2a\u7cfb\u7edf\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7ba1\u7406\u529f\u80fd\u6765\u6539\u5584\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u591a\u4f1a\u8bdd\u3001\u591a\u6a21\u578b\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\uff0c\u4ece\u800c\u63d0\u5347\u521b\u9020\u529b\u548c\u7528\u6237\u63a7\u5236\u611f\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u591a\u4f1a\u8bdd\u548c\u8de8\u6a21\u578b\u5de5\u4f5c\u6d41\u4e2d\u7ba1\u7406\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u6709\u9650\uff0c\u5bfc\u81f4\u7528\u6237\u610f\u56fe\u6a21\u7cca\u548c\u521b\u9020\u529b\u53d7\u9650\u3002", "method": "Orchid\u7cfb\u7edf\u901a\u8fc7\u4e09\u79cd\u65b9\u5f0f\u5e2e\u52a9\u7528\u6237\u7ba1\u7406\u4e0a\u4e0b\u6587\uff1a(1)\u6307\u5b9a\u9879\u76ee\u3001\u7528\u6237\u548c\u98ce\u683c\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\uff0c(2)\u901a\u8fc7\u663e\u5f0f\u63d0\u53ca\u3001\u5185\u8054\u9009\u62e9\u6216\u9690\u5f0f\u5f15\u7528\u6765\u5f15\u7528\u4e0a\u4e0b\u6587\uff0c(3)\u76d1\u63a7\u5de5\u4f5c\u6d41\u4e2d\u4e0d\u540c\u4ea4\u4e92\u7684\u4e0a\u4e0b\u6587\u3002", "result": "\u572812\u540d\u53c2\u4e0e\u8005\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528Orchid\u7684\u7528\u6237\u6bd4\u4f7f\u7528\u57fa\u7ebf\u5de5\u5177\uff08\u5982Web\u641c\u7d22\u3001LLM\u804a\u5929\u548c\u6570\u5b57\u7b14\u8bb0\u672c\uff09\u7684\u53c2\u4e0e\u8005\u4ea7\u751f\u4e86\u66f4\u591a\u65b0\u9896\u4e14\u53ef\u884c\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u62a5\u544a\u4e86\u66f4\u9ad8\u7684\u610f\u56fe\u4e00\u81f4\u6027\u3001\u63a7\u5236\u611f\u548c\u900f\u660e\u5ea6\u3002", "conclusion": "Orchid\u901a\u8fc7\u5f3a\u8c03\u4e0a\u4e0b\u6587\u7f16\u6392\uff0c\u4e3a\u652f\u6301\u590d\u6742\u8fed\u4ee3\u5de5\u4f5c\u6d41\u7684\u4e0b\u4e00\u4ee3\u751f\u6210\u5f0fAI\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u589e\u5f3a\u521b\u9020\u6f5c\u529b\u3002"}}
{"id": "2508.19661", "pdf": "https://arxiv.org/pdf/2508.19661", "abs": "https://arxiv.org/abs/2508.19661", "authors": ["Florentia Afentaki", "Sri Sai Rakesh Nakkilla", "Konstantinos Balaskas", "Paula Carolina Lozano Duarte", "Shiyi Jiang", "Georgios Zervakis", "Farshad Firouzi", "Krishnendu Chakrabarty", "Mehdi B. Tahoori"], "title": "Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables", "categories": ["cs.LG", "cs.AR"], "comment": "Accepted for publication at the IEEE/ACM International Symposium on\n  Low Power Electronics and Design} (ISLPED 2025)", "summary": "Conventional stress monitoring relies on episodic, symptom-focused\ninterventions, missing the need for continuous, accessible, and cost-efficient\nsolutions. State-of-the-art approaches use rigid, silicon-based wearables,\nwhich, though capable of multitasking, are not optimized for lightweight,\nflexible wear, limiting their practicality for continuous monitoring. In\ncontrast, flexible electronics (FE) offer flexibility and low manufacturing\ncosts, enabling real-time stress monitoring circuits. However, implementing\ncomplex circuits like machine learning (ML) classifiers in FE is challenging\ndue to integration and power constraints. Previous research has explored\nflexible biosensors and ADCs, but classifier design for stress detection\nremains underexplored. This work presents the first comprehensive design space\nexploration of low-power, flexible stress classifiers. We cover various ML\nclassifiers, feature selection, and neural simplification algorithms, with over\n1200 flexible classifiers. To optimize hardware efficiency, fully customized\ncircuits with low-precision arithmetic are designed in each case. Our\nexploration provides insights into designing real-time stress classifiers that\noffer higher accuracy than current methods, while being low-cost, conformable,\nand ensuring low power and compact size.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u529f\u8017\u3001\u7075\u6d3b\u7684\u5e94\u529b\u5206\u7c7b\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6280\u672f\u5728\u8fde\u7eed\u76d1\u6d4b\u548c\u6210\u672c\u6548\u7387\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u7684\u538b\u529b\u76d1\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u8fde\u7eed\u6027\u548c\u6210\u672c\u6548\u7387\uff0c\u800c\u73b0\u6709\u7684\u7845\u57fa\u7a7f\u6234\u8bbe\u5907\u867d\u529f\u80fd\u591a\u6837\u4f46\u4e0d\u591f\u7075\u6d3b\u3002\u67d4\u6027\u7535\u5b50\u6280\u672f\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u590d\u6742\u7535\u8def\uff08\u5982\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\uff09\u7684\u5b9e\u73b0\u4e0a\u5b58\u5728\u6311\u6218\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u63a2\u7d221200\u591a\u79cd\u67d4\u6027\u5206\u7c7b\u5668\uff0c\u7ed3\u5408\u7279\u5f81\u9009\u62e9\u548c\u795e\u7ecf\u7f51\u7edc\u7b80\u5316\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u4f4e\u529f\u8017\u3001\u4f4e\u7cbe\u5ea6\u7b97\u672f\u7535\u8def\u3002", "result": "\u8bbe\u8ba1\u51fa\u7684\u5206\u7c7b\u5668\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u5177\u5907\u4f4e\u6210\u672c\u3001\u4f4e\u529f\u8017\u548c\u7d27\u51d1\u5c3a\u5bf8\u7684\u7279\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5b9e\u65f6\u538b\u529b\u76d1\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u67d4\u6027\u7535\u5b50\u6280\u672f\u5728\u5065\u5eb7\u76d1\u6d4b\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2508.20030", "pdf": "https://arxiv.org/pdf/2508.20030", "abs": "https://arxiv.org/abs/2508.20030", "authors": ["Kangwei Xu", "Denis Schwachhofer", "Jason Blocklove", "Ilia Polian", "Peter Domanski", "Dirk Pfl\u00fcger", "Siddharth Garg", "Ramesh Karri", "Ozgur Sinanoglu", "Johann Knechtel", "Zhuorui Zhao", "Ulf Schlichtmann", "Bing Li"], "title": "Large Language Models (LLMs) for Electronic Design Automation (EDA)", "categories": ["eess.SY", "cs.AI", "cs.AR", "cs.LG", "cs.SY"], "comment": "Accepted by IEEE International System-on-Chip Conference", "summary": "With the growing complexity of modern integrated circuits, hardware engineers\nare required to devote more effort to the full design-to-manufacturing\nworkflow. This workflow involves numerous iterations, making it both\nlabor-intensive and error-prone. Therefore, there is an urgent demand for more\nefficient Electronic Design Automation (EDA) solutions to accelerate hardware\ndevelopment. Recently, large language models (LLMs) have shown remarkable\nadvancements in contextual comprehension, logical reasoning, and generative\ncapabilities. Since hardware designs and intermediate scripts can be\nrepresented as text, integrating LLM for EDA offers a promising opportunity to\nsimplify and even automate the entire workflow. Accordingly, this paper\nprovides a comprehensive overview of incorporating LLMs into EDA, with emphasis\non their capabilities, limitations, and future opportunities. Three case\nstudies, along with their outlook, are introduced to demonstrate the\ncapabilities of LLMs in hardware design, testing, and optimization. Finally,\nfuture directions and challenges are highlighted to further explore the\npotential of LLMs in shaping the next-generation EDA, providing valuable\ninsights for researchers interested in leveraging advanced AI technologies for\nEDA.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6574\u5408\u5230\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\u4e2d\uff0c\u4ee5\u7b80\u5316\u786c\u4ef6\u5f00\u53d1\u6d41\u7a0b\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u3001\u6d4b\u8bd5\u548c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u65b9\u5411\u548c\u6311\u6218\u3002", "motivation": "\u73b0\u4ee3\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u6d41\u7a0b\u590d\u6742\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684EDA\u89e3\u51b3\u65b9\u6848\u3002LLM\u5728\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u7684\u4f18\u52bf\u4e3a\u81ea\u52a8\u5316EDA\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "method": "\u8bba\u6587\u7efc\u8ff0\u4e86LLM\u5728EDA\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u80fd\u529b\u3001\u9650\u5236\u548c\u672a\u6765\u673a\u4f1a\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5728\u4e0d\u540c\u786c\u4ef6\u5f00\u53d1\u9636\u6bb5\u7684\u8868\u73b0\u3002", "result": "LLM\u6709\u671b\u7b80\u5316EDA\u6d41\u7a0b\uff0c\u751a\u81f3\u5b9e\u73b0\u90e8\u5206\u81ea\u52a8\u5316\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u6027\u9700\u8981\u89e3\u51b3\u3002", "conclusion": "LLM\u5728EDA\u4e2d\u7684\u5e94\u7528\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002"}}
{"id": "2508.19504", "pdf": "https://arxiv.org/pdf/2508.19504", "abs": "https://arxiv.org/abs/2508.19504", "authors": ["Kevin Song", "Anand Jayarajan", "Yaoyao Ding", "Qidong Su", "Zhanda Zhu", "Sihang Liu", "Gennady Pekhimenko"], "title": "Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents", "categories": ["cs.MA", "cs.DC"], "comment": null, "summary": "Large Language Models (LLMs) agents augmented with domain tools promise to\nautonomously execute complex tasks requiring human-level intelligence, such as\ncustomer service and digital assistance. However, their practical deployment is\noften limited by their low success rates under complex real-world environments.\nTo tackle this, prior research has primarily focused on improving the agents\nthemselves, such as developing strong agentic LLMs, while overlooking the role\nof the system environment in which the agent operates.\n  In this paper, we study a complementary direction: improving agent success\nrates by optimizing the system environment in which the agent operates. We\ncollect 142 agent traces (3,656 turns of agent-environment interactions) across\n5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we\npropose a taxonomy for agent-environment interaction failures that includes 6\nfailure modes. Guided by these findings, we design Aegis, a set of targeted\nenvironment optimizations: 1) environment observability enhancement, 2) common\ncomputation offloading, and 3) speculative agentic actions. These techniques\nimprove agent success rates on average by 6.7-12.5%, without any modifications\nto the agent and underlying LLM.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u4f18\u5316\u7cfb\u7edf\u73af\u5883\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u7387\uff0c\u800c\u975e\u5355\u7eaf\u6539\u8fdb\u4ee3\u7406\u672c\u8eab\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b6\u79cd\u6545\u969c\u6a21\u5f0f\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e09\u79cd\u73af\u5883\u4f18\u5316\u6280\u672fAegis\uff0c\u5b9e\u9a8c\u8868\u660e\u6210\u529f\u7387\u63d0\u9ad8\u4e866.7-12.5%\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u5728\u590d\u6742\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u6210\u529f\u7387\u8f83\u4f4e\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6539\u8fdb\u4ee3\u7406\u672c\u8eab\uff0c\u800c\u5ffd\u7565\u4e86\u7cfb\u7edf\u73af\u5883\u7684\u4f5c\u7528\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6536\u96c6142\u4e2a\u4ee3\u7406\u8ddf\u8e2a\u6570\u636e\uff083,656\u6b21\u4ea4\u4e92\uff09\uff0c\u5206\u6790\u6545\u969c\u5e76\u63d0\u51fa6\u79cd\u6545\u969c\u6a21\u5f0f\u5206\u7c7b\u6cd5\u3002\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86Aegis\u6280\u672f\uff0c\u5305\u62ec\u73af\u5883\u53ef\u89c2\u6d4b\u6027\u589e\u5f3a\u3001\u901a\u7528\u8ba1\u7b97\u5378\u8f7d\u548c\u63a8\u6d4b\u4ee3\u7406\u884c\u4e3a\u3002", "result": "Aegis\u6280\u672f\u5728\u4e0d\u4fee\u6539\u4ee3\u7406\u6216LLM\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u4ee3\u7406\u6210\u529f\u7387\u5e73\u5747\u63d0\u9ad8\u4e866.7-12.5%\u3002", "conclusion": "\u4f18\u5316\u7cfb\u7edf\u73af\u5883\u662f\u63d0\u9ad8LLM\u4ee3\u7406\u6210\u529f\u7387\u7684\u6709\u6548\u8865\u5145\u65b9\u5411\uff0cAegis\u6280\u672f\u4e3a\u6b64\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19703", "pdf": "https://arxiv.org/pdf/2508.19703", "abs": "https://arxiv.org/abs/2508.19703", "authors": ["Tom Roy", "Yann Glemarec", "Gurvan Lecuyer", "Quentin Galvane", "Philippe Guillotel", "Ferran Argelaguet"], "title": "Haptic Tracing: A new paradigm for spatialized Haptic rendering", "categories": ["cs.HC"], "comment": null, "summary": "Haptic technology enhances interactive experiences by providing force and\ntactile feedback, improving user performance and immersion. However, despite\nadvancements, creating tactile experiences still remains challenging due to\ndevice diversity and complexity. Most available haptic frameworks rely on\ntrigger-based or event-based systems, and disregard the information of the 3D\nscene to render haptic information. This paper introduces Haptic Tracing, a\nnovel method for spatial haptic rendering that simplifies the creation of\ninteractive haptic experiences without relying on physical simulations. It uses\nconcepts from visual and audio rendering to model and propagate haptic\ninformation through a 3D scene. The paper also describes how our proposed\nhaptic rendering method can be used to create a vibrotactile rendering system,\nenabling the creation of perceptually coherent and dynamic haptic interactions.\nFinally, the paper discusses a user study that explores the role of the haptic\npropagation and multi-actuator rendering on the users' haptic experience. The\nresults show that our approach significantly enhances the realism and the\nexpressivity of the haptic feedback, showcasing its potential for developing\nmore complex and realistic haptic experiences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a'Haptic Tracing'\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u53163D\u573a\u666f\u4e2d\u7684\u89e6\u89c9\u6e32\u67d3\uff0c\u63d0\u5347\u89e6\u89c9\u53cd\u9988\u7684\u771f\u5b9e\u611f\u548c\u8868\u73b0\u529b\u3002", "motivation": "\u73b0\u6709\u89e6\u89c9\u6280\u672f\u56e0\u8bbe\u5907\u591a\u6837\u6027\u548c\u590d\u6742\u6027\u96be\u4ee5\u521b\u5efa\u4e00\u81f4\u7684\u89e6\u89c9\u4f53\u9a8c\uff0c\u4e14\u7f3a\u4e4f\u5bf93D\u573a\u666f\u4fe1\u606f\u7684\u5229\u7528\u3002", "method": "\u501f\u9274\u89c6\u89c9\u548c\u97f3\u9891\u6e32\u67d3\u7684\u6982\u5ff5\uff0c\u57283D\u573a\u666f\u4e2d\u5efa\u6a21\u548c\u4f20\u64ad\u89e6\u89c9\u4fe1\u606f\uff0c\u4e0d\u4f9d\u8d56\u7269\u7406\u6a21\u62df\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u89e6\u89c9\u53cd\u9988\u7684\u771f\u5b9e\u611f\u548c\u8868\u73b0\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5f00\u53d1\u66f4\u590d\u6742\u3001\u771f\u5b9e\u89e6\u89c9\u4f53\u9a8c\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.19591", "pdf": "https://arxiv.org/pdf/2508.19591", "abs": "https://arxiv.org/abs/2508.19591", "authors": ["Jiakui Shen", "Yunqi Mi", "Guoshuai Zhao", "Jialie Shen", "Xueming Qian"], "title": "A Model-agnostic Strategy to Mitigate Embedding Degradation in Personalized Federated Recommendation", "categories": ["cs.IR", "cs.DC"], "comment": null, "summary": "Centralized recommender systems encounter privacy leakage due to the need to\ncollect user behavior and other private data. Hence, federated recommender\nsystems (FedRec) have become a promising approach with an aggregated global\nmodel on the server. However, this distributed training paradigm suffers from\nembedding degradation caused by suboptimal personalization and dimensional\ncollapse, due to the existence of sparse interactions and heterogeneous\npreferences. To this end, we propose a novel model-agnostic strategy for FedRec\nto strengthen the personalized embedding utility, which is called Personalized\nLocal-Global Collaboration (PLGC). It is the first research in federated\nrecommendation to alleviate the dimensional collapse issue. Particularly, we\nincorporate the frozen global item embedding table into local devices. Based on\na Neural Tangent Kernel strategy that dynamically balances local and global\ninformation, PLGC optimizes personalized representations during forward\ninference, ultimately converging to user-specific preferences. Additionally,\nPLGC carries on a contrastive objective function to reduce embedding redundancy\nby dissolving dependencies between dimensions, thereby improving the backward\nrepresentation learning process. We introduce PLGC as a model-agnostic\npersonalized training strategy for federated recommendations that can be\napplied to existing baselines to alleviate embedding degradation. Extensive\nexperiments on five real-world datasets have demonstrated the effectiveness and\nadaptability of PLGC, which outperforms various baseline algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPLGC\u7684\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u7b56\u7565\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u5c40\u90e8-\u5168\u5c40\u534f\u4f5c\u89e3\u51b3\u5d4c\u5165\u9000\u5316\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b97\u6cd5\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u63a8\u8350\u7cfb\u7edf\u56e0\u9700\u6536\u96c6\u7528\u6237\u9690\u79c1\u6570\u636e\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u867d\u901a\u8fc7\u805a\u5408\u5168\u5c40\u6a21\u578b\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u5176\u5206\u5e03\u5f0f\u8bad\u7ec3\u8303\u5f0f\u56e0\u7a00\u758f\u4ea4\u4e92\u548c\u5f02\u6784\u504f\u597d\u5bfc\u81f4\u5d4c\u5165\u9000\u5316\u3002", "method": "\u63d0\u51fa\u4e86PLGC\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u5168\u5c40\u9879\u76ee\u5d4c\u5165\u8868\u7eb3\u5165\u672c\u5730\u8bbe\u5907\uff0c\u5e76\u5229\u7528\u795e\u7ecf\u6b63\u5207\u6838\u7b56\u7565\u52a8\u6001\u5e73\u8861\u5c40\u90e8\u4e0e\u5168\u5c40\u4fe1\u606f\uff0c\u4f18\u5316\u4e2a\u6027\u5316\u8868\u793a\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u76ee\u6807\u51fd\u6570\u51cf\u5c11\u5d4c\u5165\u5197\u4f59\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPLGC\u5728\u6709\u6548\u6027\u548c\u9002\u5e94\u6027\u4e0a\u5747\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u7b97\u6cd5\u3002", "conclusion": "PLGC\u662f\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u4e2a\u6027\u5316\u8bad\u7ec3\u7b56\u7565\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u8054\u90a6\u63a8\u8350\u4e2d\u7684\u5d4c\u5165\u9000\u5316\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2508.19708", "pdf": "https://arxiv.org/pdf/2508.19708", "abs": "https://arxiv.org/abs/2508.19708", "authors": ["B. Sankar", "Dibakar Sen"], "title": "Attention is also needed for form design", "categories": ["cs.HC", "cs.AI", "68T07, 68T42, 68T50", "I.2; J.5; J.6"], "comment": "55 pages, 45 figures,", "summary": "Conventional product design is a cognitively demanding process, limited by\nits time-consuming nature, reliance on subjective expertise, and the opaque\ntranslation of inspiration into tangible concepts. This research introduces a\nnovel, attention-aware framework that integrates two synergistic systems:\nEUPHORIA, an immersive Virtual Reality environment using eye-tracking to\nimplicitly capture a designer's aesthetic preferences, and RETINA, an agentic\nAI pipeline that translates these implicit preferences into concrete design\noutputs. The foundational principles were validated in a two-part study. An\ninitial study correlated user's implicit attention with explicit preference and\nthe next one correlated mood to attention. A comparative study where 4\ndesigners solved challenging design problems using 4 distinct workflows, from a\nmanual process to an end-to-end automated pipeline, showed the integrated\nEUPHORIA-RETINA workflow was over 4 times more time-efficient than the\nconventional method. A panel of 50 design experts evaluated the 16 final\nrenderings. Designs generated by the fully automated system consistently\nreceived the highest Worthiness (calculated by an inverse Plackett-Luce model\nbased on gradient descent optimization) and Design Effectiveness scores,\nindicating superior quality across 8 criteria: novelty, visual appeal,\nemotional resonance, clarity of purpose, distinctiveness of silhouette, implied\nmateriality, proportional balance, & adherence to the brief. This research\npresents a validated paradigm shift from traditional Computer-Assisted Design\n(CAD) to a collaborative model of Designer-Assisting Computers (DAC). By\nautomating logistical and skill-dependent generative tasks, the proposed\nframework elevates the designer's role to that of a creative director,\nsynergizing human intuition with the generative power of agentic AI to produce\nhigher-quality designs more efficiently.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u65b0\u578b\u8bbe\u8ba1\u6846\u67b6EUPHORIA-RETINA\uff0c\u901a\u8fc7VR\u548cAI\u7ed3\u5408\uff0c\u63d0\u9ad8\u4e86\u8bbe\u8ba1\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u8bbe\u8ba1\u4f9d\u8d56\u4e3b\u89c2\u7ecf\u9a8c\u4e14\u8017\u65f6\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408VR\u773c\u52a8\u8ffd\u8e2a\uff08EUPHORIA\uff09\u548cAI\u751f\u6210\uff08RETINA\uff09\uff0c\u9a8c\u8bc1\u8bbe\u8ba1\u504f\u597d\u4e0e\u6ce8\u610f\u529b\u3001\u60c5\u7eea\u7684\u5173\u7cfb\u3002", "result": "EUPHORIA-RETINA\u6548\u7387\u63d0\u9ad84\u500d\uff0c\u751f\u6210\u7684\u8bbe\u8ba1\u5728\u4e13\u5bb6\u8bc4\u4f30\u4e2d\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u8be5\u6846\u67b6\u4eceCAD\u8f6c\u5411DAC\uff0c\u5c06\u8bbe\u8ba1\u5e08\u89d2\u8272\u63d0\u5347\u4e3a\u521b\u610f\u6307\u5bfc\uff0c\u7ed3\u5408AI\u751f\u6210\u66f4\u9ad8\u8d28\u8bbe\u8ba1\u3002"}}
{"id": "2508.19768", "pdf": "https://arxiv.org/pdf/2508.19768", "abs": "https://arxiv.org/abs/2508.19768", "authors": ["Yutong Zhang", "Taeuk Kang", "Sydney Yeh", "Anavi Baddepudi", "Lindsay Popowski", "Tiziano Piccardi", "Michael S. Bernstein"], "title": "Burst: Collaborative Curation in Connected Social Media Communities", "categories": ["cs.HC"], "comment": "29 pages, 5 figures; This work will appear in the 28th ACM SIGCHI\n  Conference on Computer-Supported Cooperative Work & Social Computing (CSCW\n  2025)", "summary": "Positive social interactions can occur in groups of many shapes and sizes,\nspanning from small and private to large and open. However, social media tends\nto binarize our experiences into either isolated small groups or into large\npublic squares. In this paper, we introduce Burst, a social media design that\nallows users to share and curate content between many spaces of varied size and\ncomposition. Users initially post content to small trusted groups, who can then\nburst that content, routing it to the groups that would be the best audience.\nWe instantiate this approach into a mobile phone application, and demonstrate\nthrough a ten-day field study (N=36) that Burst enabled a participatory\ncuration culture. With this work, we aim to articulate potential new design\ndirections for social media sharing.", "AI": {"tldr": "Burst\u662f\u4e00\u79cd\u65b0\u578b\u793e\u4ea4\u5a92\u4f53\u8bbe\u8ba1\uff0c\u5141\u8bb8\u7528\u6237\u5728\u591a\u79cd\u89c4\u6a21\u548c\u7ec4\u6210\u4e0d\u540c\u7684\u7a7a\u95f4\u4e2d\u5206\u4eab\u548c\u7b56\u5212\u5185\u5bb9\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u793e\u4ea4\u5a92\u4f53\u5c06\u793e\u4ea4\u4e92\u52a8\u5c40\u9650\u4e8e\u5c0f\u7fa4\u4f53\u6216\u5927\u4f17\u5e7f\u573a\u7684\u5c40\u9650\u3002", "motivation": "\u4f20\u7edf\u793e\u4ea4\u5a92\u4f53\u5c06\u793e\u4ea4\u4e92\u52a8\u5c40\u9650\u5728\u5c0f\u7fa4\u4f53\u6216\u5927\u4f17\u5e7f\u573a\uff0c\u8fd9\u9650\u5236\u4e86\u793e\u4ea4\u4e92\u52a8\u7684\u591a\u6837\u6027\u548c\u7075\u6d3b\u6027\u3002Burst\u7684\u52a8\u673a\u662f\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u8bbe\u8ba1\u65b9\u5411\uff0c\u652f\u6301\u66f4\u7075\u6d3b\u7684\u793e\u4ea4\u4e92\u52a8\u548c\u5185\u5bb9\u4f20\u64ad\u3002", "method": "\u8bbe\u8ba1Burst\u8fd9\u4e00\u79fb\u52a8\u5e94\u7528\u7a0b\u5e8f\uff0c\u7528\u6237\u9996\u5148\u5728\u5c0f\u578b\u4fe1\u4efb\u7fa4\u4f53\u4e2d\u53d1\u5e03\u5185\u5bb9\uff0c\u8fd9\u4e9b\u7fa4\u4f53\u53ef\u4ee5\u5c06\u5176\u4f20\u64ad\uff08burst\uff09\u5230\u66f4\u5408\u9002\u7684\u7fa4\u4f53\u4e2d\u3002\u901a\u8fc7\u4e3a\u671f\u5341\u5929\u7684\u5b9e\u5730\u7814\u7a76\uff08N=36\uff09\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cBurst\u6210\u529f\u4fc3\u6210\u4e86\u53c2\u4e0e\u5f0f\u7b56\u5212\u6587\u5316\uff0c\u7528\u6237\u5728\u793e\u4ea4\u4e92\u52a8\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u548c\u591a\u6837\u6027\u3002", "conclusion": "Burst\u4e3a\u793e\u4ea4\u5a92\u4f53\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5728\u591a\u6837\u5316\u7684\u793e\u4ea4\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u5185\u5bb9\u4f20\u64ad\u548c\u4e92\u52a8\u3002"}}
{"id": "2508.19818", "pdf": "https://arxiv.org/pdf/2508.19818", "abs": "https://arxiv.org/abs/2508.19818", "authors": ["Rania Islmabouli", "Marlene Brunner", "Devender Kumar", "Mahdi Sareban", "Gunnar Treff", "Michael Neudorfer", "Josef Niebauer", "Arne Bathke", "Jan David Smeddinck"], "title": "Towards a Real-Time Warning System for Detecting Inaccuracies in Photoplethysmography-Based Heart Rate Measurements in Wearable Devices", "categories": ["cs.HC"], "comment": null, "summary": "Wearable devices with photoplethysmography (PPG) sensors are widely used to\nmonitor heart rate (HR), yet often suffer from accuracy issues. However, users\ntypically do not receive an indication of potential measurement errors. We\npresent a real-time warning system that detects and communicates inaccuracies\nin PPG-derived HR, aiming to enhance transparency and trust. Using data from\nPolar and Garmin devices, we trained a deep learning model to classify HR\naccuracy using only the derived HR signal. The system detected over 80% of\ninaccurate readings. By providing interpretable, real-time feedback directly to\nusers, our work contributes to HCI by promoting user awareness, informed\ndecision-making, and trust in wearable health technology.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u8b66\u544a\u7cfb\u7edf\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u68c0\u6d4bPPG\u5fc3\u7387\u6570\u636e\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u63d0\u5347\u7528\u6237\u5bf9\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u4fe1\u4efb\u3002", "motivation": "\u73b0\u6709PPG\u5fc3\u7387\u76d1\u6d4b\u8bbe\u5907\u5b58\u5728\u51c6\u786e\u6027\u95ee\u9898\uff0c\u4f46\u7528\u6237\u65e0\u6cd5\u83b7\u77e5\u6f5c\u5728\u6d4b\u91cf\u9519\u8bef\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\u3002", "method": "\u4f7f\u7528Polar\u548cGarmin\u8bbe\u5907\u6570\u636e\uff0c\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u4ec5\u901a\u8fc7\u5fc3\u7387\u4fe1\u53f7\u5206\u7c7b\u51c6\u786e\u6027\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u68c0\u6d4b\u8d85\u8fc780%\u7684\u4e0d\u51c6\u786e\u8bfb\u6570\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u65f6\u53cd\u9988\u63d0\u5347\u7528\u6237\u610f\u8bc6\u548c\u4fe1\u4efb\uff0c\u63a8\u52a8\u4e86HCI\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.19867", "pdf": "https://arxiv.org/pdf/2508.19867", "abs": "https://arxiv.org/abs/2508.19867", "authors": ["Shruti Rao", "Judith Good", "Hamed Alavi"], "title": "Lessons from Biophilic Design: Rethinking Affective Interaction Design in Built Environments", "categories": ["cs.HC"], "comment": "3 pages, 1 footer image, provocation paper for CHI 2025 Workshop on\n  Affective Interactions, Japan", "summary": "The perspectives of affective interaction in built environments are largely\noverlooked and instead dominated by affective computing approaches that view\nemotions as \"static\", computable states to be detected and regulated. To\naddress this limitation, we interviewed architects to explore how biophilic\ndesign -- our deep-rooted emotional connection with nature -- could shape\naffective interaction design in smart buildings. Our findings reveal that\nnatural environments facilitate self-directed emotional experiences through\nspatial diversity, embodied friction, and porous sensory exchanges. Based on\nthis, we introduce three design principles for discussion at the Affective\nInteraction workshop: (1) Diversity of Spatial Experiences, (2) Self-Reflection\nThrough Complexity & Friction, and (3) Permeability & Sensory Exchange with the\nOutside World, while also examining the challenges of integrating these\nperspectives into built environments.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5efa\u7b51\u73af\u5883\u4e2d\u60c5\u611f\u4e92\u52a8\u7684\u89c6\u89d2\uff0c\u63d0\u51fa\u901a\u8fc7\u751f\u7269\u4eb2\u548c\u8bbe\u8ba1\uff08biophilic design\uff09\u6765\u4fc3\u8fdb\u81ea\u6211\u5bfc\u5411\u7684\u60c5\u611f\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u8ba1\u7b97\u5c06\u60c5\u7eea\u89c6\u4e3a\u53ef\u8ba1\u7b97\u7684\u9759\u6001\u72b6\u6001\uff0c\u5ffd\u7565\u4e86\u60c5\u611f\u4e92\u52a8\u7684\u52a8\u6001\u6027\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u81ea\u7136\u8fde\u63a5\u5982\u4f55\u5f71\u54cd\u667a\u80fd\u5efa\u7b51\u4e2d\u7684\u60c5\u611f\u4e92\u52a8\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u8bbf\u8c08\u5efa\u7b51\u5e08\uff0c\u7814\u7a76\u751f\u7269\u4eb2\u548c\u8bbe\u8ba1\u5728\u60c5\u611f\u4e92\u52a8\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u81ea\u7136\u73af\u5883\u901a\u8fc7\u7a7a\u95f4\u591a\u6837\u6027\u3001\u5177\u8eab\u6469\u64e6\u548c\u591a\u5b54\u611f\u5b98\u4ea4\u6362\u4fc3\u8fdb\u60c5\u611f\u4f53\u9a8c\uff0c\u63d0\u51fa\u4e09\u6761\u8bbe\u8ba1\u539f\u5219\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6574\u5408\u751f\u7269\u4eb2\u548c\u8bbe\u8ba1\u5230\u5efa\u7b51\u73af\u5883\u4e2d\u7684\u6311\u6218\u548c\u6f5c\u5728\u65b9\u5411\u3002"}}
{"id": "2508.19942", "pdf": "https://arxiv.org/pdf/2508.19942", "abs": "https://arxiv.org/abs/2508.19942", "authors": ["Martin Benderoth", "Patrick Gebhard", "Christian Keller", "C. Benjamin Nakhosteen", "Stefan Schaffer", "Tanja Schneeberger"], "title": "Socially Interactive Agents for Preserving and Transferring Tacit Knowledge in Organizations", "categories": ["cs.HC"], "comment": "4 pages, 2 figures", "summary": "This paper introduces a novel approach to tackle the challenges of preserving\nand transferring tacit knowledge--deep, experience-based insights that are hard\nto articulate but vital for decision-making, innovation, and problem-solving.\nTraditional methods rely heavily on human facilitators, which, while effective,\nare resource-intensive and lack scalability. A promising alternative is the use\nof Socially Interactive Agents (SIAs) as AI-driven knowledge transfer\nfacilitators. These agents interact autonomously and socially intelligently\nwith users through multimodal behaviors (verbal, paraverbal, nonverbal),\nsimulating expert roles in various organizational contexts. SIAs engage\nemployees in empathic, natural-language dialogues, helping them externalize\ninsights that might otherwise remain unspoken. Their success hinges on building\ntrust, as employees are often hesitant to share tacit knowledge without\nassurance of confidentiality and appreciation. Key technologies include Large\nLanguage Models (LLMs) for generating context-relevant dialogue,\nRetrieval-Augmented Generation (RAG) to integrate organizational knowledge, and\nChain-of-Thought (CoT) prompting to guide structured reflection. These enable\nSIAs to actively elicit knowledge, uncover implicit assumptions, and connect\ninsights to broader organizational contexts. Potential applications span\nonboarding, where SIAs support personalized guidance and introductions, and\nknowledge retention, where they conduct structured interviews with retiring\nexperts to capture heuristics behind decisions. Success depends on addressing\nethical and operational challenges such as data privacy, algorithmic bias, and\nresistance to AI. Transparency, robust validation, and a culture of trust are\nessential to mitigate these risks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u793e\u4ea4\u4e92\u52a8\u4ee3\u7406\uff08SIAs\uff09\u6765\u4fdd\u5b58\u548c\u8f6c\u79fb\u9690\u6027\u77e5\u8bc6\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u884c\u4e3a\u548cAI\u6280\u672f\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u8f6c\u79fb\u3002", "motivation": "\u4f20\u7edf\u9690\u6027\u77e5\u8bc6\u8f6c\u79fb\u65b9\u6cd5\u4f9d\u8d56\u4eba\u529b\uff0c\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u91c7\u7528AI\u9a71\u52a8\u7684SIAs\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u601d\u7ef4\u94fe\u63d0\u793a\uff08CoT\uff09\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u548c\u591a\u6a21\u6001\u4e92\u52a8\u4fc3\u8fdb\u77e5\u8bc6\u5916\u5316\u3002", "result": "SIAs\u80fd\u591f\u6709\u6548\u5f15\u53d1\u9690\u6027\u77e5\u8bc6\u3001\u63ed\u793a\u9690\u542b\u5047\u8bbe\uff0c\u5e76\u5728\u7ec4\u7ec7\u4e0a\u4e0b\u6587\u4e2d\u8fde\u63a5\u6d1e\u5bdf\uff0c\u652f\u6301\u5165\u804c\u57f9\u8bad\u548c\u77e5\u8bc6\u4fdd\u7559\u7b49\u5e94\u7528\u3002", "conclusion": "SIAs\u4e3a\u9690\u6027\u77e5\u8bc6\u8f6c\u79fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u4f46\u9700\u89e3\u51b3\u4f26\u7406\u548c\u64cd\u4f5c\u6311\u6218\uff0c\u5982\u6570\u636e\u9690\u79c1\u548c\u7b97\u6cd5\u504f\u89c1\uff0c\u4ee5\u4fdd\u969c\u5e7f\u6cdb\u5e94\u7528\u7684\u6210\u529f\u3002"}}
{"id": "2508.19971", "pdf": "https://arxiv.org/pdf/2508.19971", "abs": "https://arxiv.org/abs/2508.19971", "authors": ["Jeremy Zhengqi Huang", "Calu\u00e3 de Lacerda Pataca", "Liang-Yuan Wu", "Dhruv Jain"], "title": "CapTune: Adapting Non-Speech Captions With Anchored Generative Models", "categories": ["cs.HC", "cs.HC, cs.AI"], "comment": "ASSETS 2025", "summary": "Non-speech captions are essential to the video experience of deaf and hard of\nhearing (DHH) viewers, yet conventional approaches often overlook the diversity\nof their preferences. We present CapTune, a system that enables customization\nof non-speech captions based on DHH viewers' needs while preserving creator\nintent. CapTune allows caption authors to define safe transformation spaces\nusing concrete examples and empowers viewers to personalize captions across\nfour dimensions: level of detail, expressiveness, sound representation method,\nand genre alignment. Evaluations with seven caption creators and twelve DHH\nparticipants showed that CapTune supported creators' creative control while\nenhancing viewers' emotional engagement with content. Our findings also reveal\ntrade-offs between information richness and cognitive load, tensions between\ninterpretive and descriptive representations of sound, and the\ncontext-dependent nature of caption preferences.", "AI": {"tldr": "CapTune\u7cfb\u7edf\u5141\u8bb8\u8033\u804b\u548c\u542c\u529b\u969c\u788d\uff08DHH\uff09\u89c2\u4f17\u4e2a\u6027\u5316\u975e\u8bed\u97f3\u5b57\u5e55\uff0c\u540c\u65f6\u4fdd\u7559\u521b\u4f5c\u8005\u610f\u56fe\uff0c\u589e\u5f3a\u4e86\u89c2\u4f17\u7684\u53c2\u4e0e\u611f\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5ffd\u89c6\u4e86DHH\u89c2\u4f17\u5bf9\u975e\u8bed\u97f3\u5b57\u5e55\u7684\u591a\u6837\u6027\u9700\u6c42\uff0cCapTune\u65e8\u5728\u6ee1\u8db3\u4e2a\u6027\u5316\u9700\u6c42\u5e76\u5e73\u8861\u521b\u4f5c\u8005\u610f\u56fe\u3002", "method": "CapTune\u901a\u8fc7\u56db\u4e2a\u7ef4\u5ea6\uff08\u7ec6\u8282\u3001\u8868\u8fbe\u6027\u3001\u58f0\u97f3\u8868\u793a\u65b9\u6cd5\u548c\u6d41\u6d3e\u5bf9\u9f50\uff09\u81ea\u5b9a\u4e49\u5b57\u5e55\uff0c\u5e76\u4f7f\u7528\u5177\u4f53\u793a\u4f8b\u5b9a\u4e49\u5b89\u5168\u8f6c\u6362\u7a7a\u95f4\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0cCapTune\u5728\u4fdd\u6301\u521b\u4f5c\u8005\u63a7\u5236\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u89c2\u4f17\u7684\u60c5\u611f\u53c2\u4e0e\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u4fe1\u606f\u4e30\u5bcc\u6027\u4e0e\u8ba4\u77e5\u8d1f\u8377\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u5b57\u5e55\u504f\u597d\u7684\u60c5\u5883\u4f9d\u8d56\u6027\uff0cCapTune\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.20034", "pdf": "https://arxiv.org/pdf/2508.20034", "abs": "https://arxiv.org/abs/2508.20034", "authors": ["Xia Su", "Ruiqi Chen", "Jingwei Ma", "Chu Li", "Jon E. Froehlich"], "title": "FlyMeThrough: Human-AI Collaborative 3D Indoor Mapping with Commodity Drones", "categories": ["cs.HC", "H.5.2; I.2.10"], "comment": "Accepted at UIST 2025, 14 pages, 8 figures, 2 tables", "summary": "Indoor mapping data is crucial for routing, navigation, and building\nmanagement, yet such data are widely lacking due to the manual labor and\nexpense of data collection, especially for larger indoor spaces. Leveraging\nrecent advancements in commodity drones and photogrammetry, we introduce\nFlyMeThrough -- a drone-based indoor scanning system that efficiently produces\n3D reconstructions of indoor spaces with human-AI collaborative annotations for\nkey indoor points-of-interest (POI) such as entrances, restrooms, stairs, and\nelevators. We evaluated FlyMeThrough in 12 indoor spaces with varying sizes and\nfunctionality. To investigate use cases and solicit feedback from target\nstakeholders, we also conducted a qualitative user study with five building\nmanagers and five occupants. Our findings indicate that FlyMeThrough can\nefficiently and precisely create indoor 3D maps for strategic space planning,\nresource management, and navigation.", "AI": {"tldr": "FlyMeThrough\u662f\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u7684\u5ba4\u5185\u626b\u63cf\u7cfb\u7edf\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u6807\u6ce8\u5173\u952e\u5ba4\u5185POI\uff0c\u80fd\u591f\u9ad8\u6548\u751f\u62103D\u91cd\u5efa\u56fe\u3002", "motivation": "\u5ba4\u5185\u5730\u56fe\u6570\u636e\u5bf9\u5bfc\u822a\u548c\u5efa\u7b51\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u6570\u636e\u7f3a\u4e4f\uff0c\u5c24\u5176\u662f\u5927\u578b\u5ba4\u5185\u7a7a\u95f4\u7684\u91c7\u96c6\u6210\u672c\u9ad8\u3002", "method": "\u5229\u7528\u6d88\u8d39\u7ea7\u65e0\u4eba\u673a\u548c\u6444\u5f71\u6d4b\u91cf\u6280\u672f\uff0c\u5f00\u53d1\u4e86FlyMeThrough\u7cfb\u7edf\uff0c\u5e76\u572812\u4e2a\u4e0d\u540c\u5927\u5c0f\u548c\u529f\u80fd\u7684\u5ba4\u5185\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0cFlyMeThrough\u80fd\u9ad8\u6548\u4e14\u7cbe\u786e\u5730\u521b\u5efa3D\u5730\u56fe\uff0c\u9002\u7528\u4e8e\u7a7a\u95f4\u89c4\u5212\u3001\u8d44\u6e90\u7ba1\u7406\u548c\u5bfc\u822a\u3002", "conclusion": "FlyMeThrough\u4e3a\u5ba4\u5185\u6570\u636e\u91c7\u96c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19254", "pdf": "https://arxiv.org/pdf/2508.19254", "abs": "https://arxiv.org/abs/2508.19254", "authors": ["Jookyung Song", "Mookyoung Kang", "Nojun Kwak"], "title": "Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "6 pages, 4 figures, NeurIPS Creative AI Track 2025", "summary": "This paper presents a real-time generative drawing system that interprets and\nintegrates both formal intent - the structural, compositional, and stylistic\nattributes of a sketch - and contextual intent - the semantic and thematic\nmeaning inferred from its visual content - into a unified transformation\nprocess. Unlike conventional text-prompt-based generative systems, which\nprimarily capture high-level contextual descriptions, our approach\nsimultaneously analyzes ground-level intuitive geometric features such as line\ntrajectories, proportions, and spatial arrangement, and high-level semantic\ncues extracted via vision-language models. These dual intent signals are\njointly conditioned in a multi-stage generation pipeline that combines\ncontour-preserving structural control with style- and content-aware image\nsynthesis. Implemented with a touchscreen-based interface and distributed\ninference architecture, the system achieves low-latency, two-stage\ntransformation while supporting multi-user collaboration on shared canvases.\nThe resulting platform enables participants, regardless of artistic expertise,\nto engage in synchronous, co-authored visual creation, redefining human-AI\ninteraction as a process of co-creation and mutual enhancement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u751f\u6210\u7ed8\u56fe\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u5f62\u5f0f\u610f\u56fe\u548c\u4e0a\u4e0b\u6587\u610f\u56fe\uff0c\u5b9e\u73b0\u7ed3\u6784\u63a7\u5236\u548c\u98ce\u683c\u611f\u77e5\u7684\u56fe\u50cf\u5408\u6210\uff0c\u652f\u6301\u591a\u7528\u6237\u534f\u4f5c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6587\u672c\u63d0\u793a\u7684\u751f\u6210\u7cfb\u7edf\u65e0\u6cd5\u540c\u65f6\u6355\u6349\u4f4e\u7ea7\u51e0\u4f55\u7279\u5f81\u4e0e\u9ad8\u7ea7\u8bed\u4e49\u7ebf\u7d22\uff0c\u9650\u5236\u4e86\u7ed8\u56fe\u7684\u4ea4\u4e92\u6027\u548c\u521b\u9020\u529b\u3002", "method": "\u591a\u9636\u6bb5\u751f\u6210\u7ba1\u9053\u7ed3\u5408\u8f6e\u5ed3\u4fdd\u7559\u7684\u7ed3\u6784\u63a7\u5236\u4e0e\u98ce\u683c\u548c\u5185\u5bb9\u611f\u77e5\u7684\u56fe\u50cf\u5408\u6210\uff0c\u91c7\u7528\u89e6\u6478\u5c4f\u754c\u9762\u548c\u5206\u5e03\u5f0f\u63a8\u7406\u67b6\u6784\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u7684\u53cc\u9636\u6bb5\u8f6c\u6362\uff0c\u652f\u6301\u591a\u7528\u6237\u5728\u5171\u4eab\u753b\u5e03\u4e0a\u534f\u4f5c\uff0c\u63d0\u5347\u4e86\u4eba\u673a\u4ea4\u4e92\u7684\u5171\u521b\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u65e0\u827a\u672f\u4e13\u4e1a\u80cc\u666f\u7684\u7528\u6237\u63d0\u4f9b\u4e86\u540c\u6b65\u5171\u521b\u89c6\u89c9\u5185\u5bb9\u7684\u5e73\u53f0\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u4eba\u673a\u4ea4\u4e92\u7684\u5171\u521b\u8fc7\u7a0b\u3002"}}
{"id": "2508.19367", "pdf": "https://arxiv.org/pdf/2508.19367", "abs": "https://arxiv.org/abs/2508.19367", "authors": ["Alex Cuellar", "Ho Chit Siu", "Julie A Shah"], "title": "Inference of Human-derived Specifications of Object Placement via Demonstration", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "As robots' manipulation capabilities improve for pick-and-place tasks (e.g.,\nobject packing, sorting, and kitting), methods focused on understanding\nhuman-acceptable object configurations remain limited expressively with regard\nto capturing spatial relationships important to humans. To advance robotic\nunderstanding of human rules for object arrangement, we introduce\npositionally-augmented RCC (PARCC), a formal logic framework based on region\nconnection calculus (RCC) for describing the relative position of objects in\nspace. Additionally, we introduce an inference algorithm for learning PARCC\nspecifications via demonstrations. Finally, we present the results from a human\nstudy, which demonstrate our framework's ability to capture a human's intended\nspecification and the benefits of learning from demonstration approaches over\nhuman-provided specifications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u533a\u57df\u8fde\u63a5\u8ba1\u7b97\u6846\u67b6PARCC\uff0c\u7528\u4e8e\u63cf\u8ff0\u4eba\u7c7b\u53ef\u63a5\u53d7\u7684\u7269\u4f53\u7a7a\u95f4\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u793a\u8303\u5b66\u4e60\u4f18\u5316\u673a\u5668\u4eba\u5bf9\u6392\u5217\u89c4\u5219\u7684\u7406\u89e3\u3002", "motivation": "\u63d0\u5347\u673a\u5668\u4eba\u5728\u6293\u53d6\u548c\u653e\u7f6e\u4efb\u52a1\u4e2d\u5bf9\u4eba\u7c7b\u63a5\u53d7\u7684\u7269\u4f53\u914d\u7f6e\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86\u57fa\u4e8e\u533a\u57df\u8fde\u63a5\u8ba1\u7b97\u7684PARCC\u903b\u8f91\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u793a\u8303\u5b66\u4e60PARCC\u89c4\u8303\u7684\u63a8\u7406\u7b97\u6cd5\u3002", "result": "\u4eba\u7c7b\u7814\u7a76\u663e\u793a\uff0cPARCC\u80fd\u51c6\u786e\u6355\u6349\u7528\u6237\u7684\u610f\u56fe\uff0c\u793a\u8303\u5b66\u4e60\u65b9\u6cd5\u4f18\u4e8e\u4eba\u5de5\u63d0\u4f9b\u7684\u89c4\u8303\u3002", "conclusion": "PARCC\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u673a\u5668\u4eba\u5bf9\u4eba\u7c7b\u7a7a\u95f4\u6392\u5217\u89c4\u5219\u7684\u7406\u89e3\uff0c\u793a\u8303\u5b66\u4e60\u662f\u4f18\u5316\u5b66\u4e60\u8def\u5f84\u7684\u5173\u952e\u3002"}}
{"id": "2508.19427", "pdf": "https://arxiv.org/pdf/2508.19427", "abs": "https://arxiv.org/abs/2508.19427", "authors": ["Evandro L. T. P. Cunha"], "title": "A perishable ability? The future of writing in the face of generative artificial intelligence", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": "10 pages", "summary": "The 2020s have been witnessing a very significant advance in the development\nof generative artificial intelligence tools, including text generation systems\nbased on large language models. These tools have been increasingly used to\ngenerate texts in the most diverse domains -- from technical texts to literary\ntexts --, which might eventually lead to a lower volume of written text\nproduction by humans. This article discusses the possibility of a future in\nwhich human beings will have lost or significantly decreased their ability to\nwrite due to the outsourcing of this activity to machines. This possibility\nparallels the loss of the ability to write in other moments of human history,\nsuch as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u53ef\u80fd\u5bfc\u81f4\u4eba\u7c7b\u5199\u4f5c\u80fd\u529b\u4e0b\u964d\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u5c06\u5176\u4e0e\u5386\u53f2\u4e0a\u7684\u5199\u4f5c\u80fd\u529b\u4e27\u5931\u65f6\u671f\uff08\u5982\u5e0c\u814a\u9ed1\u6697\u65f6\u4ee3\uff09\u76f8\u7c7b\u6bd4\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u7684\u666e\u53ca\u5bf9\u4eba\u7c7b\u5199\u4f5c\u80fd\u529b\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u5e76\u7c7b\u6bd4\u5386\u53f2\u4e0a\u7684\u7c7b\u4f3c\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u73b0\u4ee3\u6280\u672f\u53d1\u5c55\u4e0e\u5386\u53f2\u4e0a\u4eba\u7c7b\u5199\u4f5c\u80fd\u529b\u4e27\u5931\u7684\u65f6\u671f\uff08\u5982\u5e0c\u814a\u9ed1\u6697\u65f6\u4ee3\uff09\uff0c\u5206\u6790\u5176\u76f8\u4f3c\u6027\u4e0e\u6f5c\u5728\u540e\u679c\u3002", "result": "\u6307\u51fa\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u53ef\u80fd\u524a\u5f31\u4eba\u7c7b\u7684\u5199\u4f5c\u80fd\u529b\uff0c\u5c31\u50cf\u5386\u53f2\u4e0a\u67d0\u4e9b\u65f6\u671f\u4eba\u7c7b\u56e0\u5916\u90e8\u4f9d\u8d56\u800c\u5931\u53bb\u5199\u4f5c\u6280\u80fd\u3002", "conclusion": "\u9700\u8981\u8b66\u60d5\u6280\u672f\u8fc7\u5ea6\u4f9d\u8d56\u5bf9\u4eba\u7c7b\u80fd\u529b\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5e76\u91c7\u53d6\u5e73\u8861\u63aa\u65bd\u4ee5\u4fdd\u62a4\u4eba\u7c7b\u5199\u4f5c\u6280\u80fd\u3002"}}
{"id": "2508.19993", "pdf": "https://arxiv.org/pdf/2508.19993", "abs": "https://arxiv.org/abs/2508.19993", "authors": ["Debanjana Kar", "Leopold B\u00f6ss", "Dacia Braca", "Sebastian Maximilian Dennerlein", "Nina Christine Hubig", "Philipp Wintersberger", "Yufang Hou"], "title": "MathBuddy: A Multimodal System for Affective Math Tutoring", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "The rapid adoption of LLM-based conversational systems is already\ntransforming the landscape of educational technology. However, the current\nstate-of-the-art learning models do not take into account the student's\naffective states. Multiple studies in educational psychology support the claim\nthat positive or negative emotional states can impact a student's learning\ncapabilities. To bridge this gap, we present MathBuddy, an emotionally aware\nLLM-powered Math Tutor, which dynamically models the student's emotions and\nmaps them to relevant pedagogical strategies, making the tutor-student\nconversation a more empathetic one. The student's emotions are captured from\nthe conversational text as well as from their facial expressions. The student's\nemotions are aggregated from both modalities to confidently prompt our LLM\nTutor for an emotionally-aware response. We have effectively evaluated our\nmodel using automatic evaluation metrics across eight pedagogical dimensions\nand user studies. We report a massive 23 point performance gain using the win\nrate and a 3 point gain at an overall level using DAMR scores which strongly\nsupports our hypothesis of improving LLM-based tutor's pedagogical abilities by\nmodeling students' emotions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMathBuddy\uff0c\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u60c5\u611f\u611f\u77e5\u6570\u5b66\u8f85\u5bfc\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u5b66\u751f\u60c5\u611f\u63d0\u5347\u6559\u5b66\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u6a21\u578b\u672a\u8003\u8651\u5b66\u751f\u60c5\u611f\u72b6\u6001\uff0c\u800c\u7814\u7a76\u8868\u660e\u60c5\u611f\u72b6\u6001\u5f71\u54cd\u5b66\u4e60\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u60c5\u611f\u611f\u77e5\u7684\u8f85\u5bfc\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u6587\u672c\u548c\u9762\u90e8\u8868\u60c5\u6355\u6349\u5b66\u751f\u60c5\u611f\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u6570\u636e\u4f18\u5316LLM\u8f85\u5bfc\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u60c5\u611f\u611f\u77e5\u6a21\u578b\u5728\u591a\u4e2a\u6559\u5b66\u7ef4\u5ea6\u4e0a\u663e\u8457\u63d0\u5347\u6548\u679c\uff0c\u6027\u80fd\u63d0\u5347\u660e\u663e\u3002", "conclusion": "\u60c5\u611f\u611f\u77e5\u80fd\u663e\u8457\u63d0\u5347LLM\u8f85\u5bfc\u7cfb\u7edf\u7684\u6559\u5b66\u80fd\u529b\u3002"}}
