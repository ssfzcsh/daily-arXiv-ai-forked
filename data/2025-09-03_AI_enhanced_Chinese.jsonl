{"id": "2509.00644", "pdf": "https://arxiv.org/pdf/2509.00644", "abs": "https://arxiv.org/abs/2509.00644", "authors": ["Jun Suzuki", "Katsuhiko Sano"], "title": "Undecidability of Linear Logics without Weakening", "categories": ["cs.LO"], "comment": null, "summary": "The goal of this paper is to establish that it remains undecidable whether a\nsequent is provable in two systems in which a weakening rule for an exponential\nmodality is completely omitted from classical propositional linear logic\n$\\mathbf{CLL}$ introduced by Girard (1987), which is shown to be undecidable by\nLincoln et al. (1992). We introduce two logical systems, $\\mathbf{CLLR}$ and\n$\\mathbf{CLLRR}$. The first system, $\\mathbf{CLLR}$, is obtained by omitting\nthe weakening rule for the exponential modality of $\\mathbf{CLL}$. The system\n$\\mathbf{CLLR}$ has been studied by several authors, including\nMeli\\`es-Tabareau (2010), but its undecidability was unknown. This paper shows\nthe undecidability of $\\mathbf{CLLR}$ by reducing it to the undecidability of\n$\\mathbf{CLL}$, where the units $\\mathbf{1}$ and $\\bot$ play a crucial role in\nsimulating the weakening rule. We also omit these units from the syntax and\ninference rules of $\\mathbf{CLLR}$ in order to define the second system,\n$\\mathbf{CLLRR}$. The undecidability of $\\mathbf{CLLRR}$ is established by\nshowing that the system can simulate any two-counter machine proposed by Minsky\n(1961).", "AI": {"tldr": "\u8bc1\u660e\u4e86\u5728\u4e24\u79cd\u7ebf\u6027\u903b\u8f91\u7cfb\u7edf\u4e2d\uff08CLLR\u548cCLLRR\uff09\u7684\u53ef\u8bc1\u5e8f\u5217\u95ee\u9898\u662f\u4e0d\u53ef\u5224\u5b9a\u7684\u3002", "motivation": "\u7814\u7a76\u7ebf\u6027\u903b\u8f91\u4e2d\u7701\u7565\u6307\u6570\u6a21\u6001\u524a\u5f31\u89c4\u5219\u7684\u7cfb\u7edf\u662f\u5426\u4ecd\u4fdd\u6301\u4e0d\u53ef\u5224\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u7701\u7565CLL\u4e2d\u7684\u6307\u6570\u6a21\u6001\u524a\u5f31\u89c4\u5219\u5b9a\u4e49CLLR\uff0c\u5e76\u901a\u8fc7\u7701\u7565\u5355\u4f4d\u5143\u5b9a\u4e49CLLRR\uff0c\u5206\u522b\u8bc1\u660e\u5176\u4e0d\u53ef\u5224\u5b9a\u6027\u3002", "result": "\u8bc1\u5b9eCLLR\u548cCLLRR\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\uff0c\u524d\u8005\u901a\u8fc7\u5f52\u7ea6\u5230CLL\uff0c\u540e\u8005\u901a\u8fc7\u6a21\u62dfMinsky\u7684\u53cc\u8ba1\u6570\u5668\u673a\u3002", "conclusion": "\u4e24\u79cd\u7cfb\u7edf\u5728\u7701\u7565\u7279\u5b9a\u89c4\u5219\u540e\u4ecd\u4fdd\u6301\u4e0d\u53ef\u5224\u5b9a\u6027\uff0c\u51f8\u663e\u4e86\u7ebf\u6027\u903b\u8f91\u4e2d\u67d0\u4e9b\u7ed3\u6784\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.01130", "pdf": "https://arxiv.org/pdf/2509.01130", "abs": "https://arxiv.org/abs/2509.01130", "authors": ["Parivash Feyzishendi", "Sophia Hamer", "Jinyu Huang", "Tyler R. Josephson"], "title": "Formal Verification of Isothermal Chemical Reactors", "categories": ["cs.LO"], "comment": null, "summary": "Chemical reactors are dynamic systems that can be described by systems of\nordinary differential equations (ODEs). Reactor safety, regulatory compliance,\nand economics depend on whether certain states are reachable by the reactor,\nand are generally assessed using numerical simulation. In this work, we show\nhow differential dynamic logic (dL), as implemented in the automated theorem\nprover KeYmaera X, can be used to symbolically determine reachability in\nisothermal chemical reactors, providing mathematical guarantees that certain\nconditions are satisfied (for example, that an outlet concentration never\nexceeds a regulatory threshold). First, we apply dL to systems whose dynamics\ncan be solved in closed form, such as first-order reactions in batch reactors,\nproving that such reactors cannot exceed specified concentration limits. We\nextend this method to reaction models as complex as Michaelis-Menten kinetics,\nwhose dynamics require approximations or numerical solutions. In all cases,\nproofs are facilitated by identification of invariants; we find that\nconservation of mass is both a principle proved from the ODEs describing mass\naction kinetics as well as a useful relationship for proving other properties.\nUseful invariants for continuous stirred tank reactors (CSTRs) were not found,\nwhich limited the complexity of reaction networks that could be proved with dL.\nWhile dL provides an interesting symbolic logic approach for reachability in\nchemical reactions, the bounds we obtained are quite broad relative to those\ntypically achieved via numerical reachability analyses.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5229\u7528\u5fae\u5206\u52a8\u6001\u903b\u8f91\uff08dL\uff09\u548c\u5b9a\u7406\u8bc1\u660e\u5de5\u5177KeYmaera X\uff0c\u4e3a\u7b49\u6e29\u5316\u5b66\u53cd\u5e94\u5668\u4e2d\u7684\u72b6\u6001\u53ef\u8fbe\u6027\u63d0\u4f9b\u6570\u5b66\u4fdd\u8bc1\uff0c\u5e76\u9a8c\u8bc1\u4e86\u67d0\u4e9b\u6761\u4ef6\uff08\u5982\u51fa\u53e3\u6d53\u5ea6\u4e0d\u8d85\u6807\uff09\u3002\u65b9\u6cd5\u9002\u7528\u4e8e\u7b80\u5355\u81f3\u590d\u6742\u7684\u53cd\u5e94\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u4f46\u53d7\u9650\u4e8e\u4e0d\u53d8\u91cf\u7684\u53d1\u73b0\uff0c\u5c24\u5176\u662f\u5bf9CSTRs\u7684\u590d\u6742\u53cd\u5e94\u7f51\u7edc\u3002\u5c3d\u7ba1dL\u7684\u7ed3\u679c\u8303\u56f4\u8f83\u5e7f\uff0c\u4f46\u76f8\u5bf9\u6570\u503c\u6a21\u62df\u4ecd\u6709\u9650\u3002", "motivation": "\u5316\u5b66\u53cd\u5e94\u5668\u7684\u5b89\u5168\u6027\u548c\u7ecf\u6d4e\u6027\u4f9d\u8d56\u4e8e\u72b6\u6001\u7684\u53ef\u8fbe\u6027\u8bc4\u4f30\uff0c\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u6570\u503c\u6a21\u62df\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7b26\u53f7\u903b\u8f91\u65b9\u6cd5\uff08dL\uff09\u4e3a\u8fd9\u4e9b\u8bc4\u4f30\u63d0\u4f9b\u6570\u5b66\u8bc1\u660e\uff0c\u786e\u4fdd\u67d0\u4e9b\u6761\u4ef6\uff08\u5982\u6d53\u5ea6\u9650\u5236\uff09\u5f97\u5230\u6ee1\u8db3\u3002", "method": "\u4f7f\u7528\u5fae\u5206\u52a8\u6001\u903b\u8f91\uff08dL\uff09\u548c\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u5de5\u5177KeYmaera X\uff0c\u5bf9\u7b49\u6e29\u5316\u5b66\u53cd\u5e94\u5668\u4e2d\u7684\u72b6\u6001\u53ef\u8fbe\u6027\u8fdb\u884c\u7b26\u53f7\u5206\u6790\u3002\u65b9\u6cd5\u8986\u76d6\u4e86\u4ece\u95ed\u5f0f\u89e3\u7684\u7b80\u5355\u53cd\u5e94\uff08\u5982\u4e00\u7ea7\u6279\u53cd\u5e94\u5668\uff09\u5230\u590d\u6742\u52a8\u529b\u5b66\uff08\u5982Michaelis-Menten\uff09\uff0c\u5e76\u4f9d\u8d56\u4e8e\u4e0d\u53d8\u91cf\u7684\u8bc6\u522b\uff08\u5982\u8d28\u91cf\u5b88\u6052\uff09\u3002", "result": "dL\u6210\u529f\u4e3a\u7b80\u5355\u81f3\u590d\u6742\u53cd\u5e94\u52a8\u529b\u5b66\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u8fbe\u6027\u8bc1\u660e\uff0c\u4f46\u53d7\u9650\u4e8e\u4e0d\u53d8\u91cf\u7684\u53d1\u73b0\uff0c\u5c24\u5176\u662fCSTRs\u7684\u590d\u6742\u53cd\u5e94\u7f51\u7edc\u3002\u5176\u7ed3\u679c\u7684\u8fb9\u754c\u8f83\u6570\u503c\u6a21\u62df\u66f4\u5e7f\u3002", "conclusion": "dL\u4e3a\u5316\u5b66\u53cd\u5e94\u5668\u4e2d\u7684\u53ef\u8fbe\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7b26\u53f7\u903b\u8f91\u65b9\u6cd5\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u6027\u548c\u7cbe\u786e\u6027\u4ecd\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u53cd\u5e94\u7f51\u7edc\u4e2d\u4e0d\u53d8\u91cf\u7684\u53d1\u73b0\u65b9\u9762\u3002"}}
{"id": "2509.01423", "pdf": "https://arxiv.org/pdf/2509.01423", "abs": "https://arxiv.org/abs/2509.01423", "authors": ["Julien Saan Joachim", "Marc de Visme", "Stefan Haar"], "title": "Quantum Petri Nets with Event Structure semantics", "categories": ["cs.LO", "quant-ph"], "comment": null, "summary": "Classical Petri nets provide a canonical model of concurrency, with unfolding\nsemantics linking nets, occurrence nets, and event structures. No comparable\nframework exists for quantum concurrency: existing ''quantum Petri nets'' lack\nrigorous concurrent and sound quantum semantics, analysis tools, and unfolding\ntheory. We introduce Quantum Petri Nets (QPNs), Petri nets equipped with a\nquantum valuation compatible with the quantum event structure semantics of\nClairambault, De Visme, and Winskel (2019). Our contributions are: (i) a local\ndefinition of Quantum Occurrence Nets (LQONs) compatible with quantum event\nstructures, (ii) a construction of QPNs with a well-defined unfolding\nsemantics, (iii) a compositional framework for QPNs. This establishes a\nsemantically well grounded model of quantum concurrency, bridging Petri net\ntheory and quantum programming.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u91cf\u5b50Petri\u7f51(QPNs)\uff0c\u586b\u8865\u4e86\u91cf\u5b50\u5e76\u53d1\u5efa\u6a21\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u8bed\u4e49\u548c\u5c55\u5f00\u7406\u8bba\u3002", "motivation": "\u4e3a\u91cf\u5b50\u5e76\u53d1\u63d0\u4f9b\u4e00\u4e2a\u4e0e\u7ecf\u5178Petri\u7f51\u7c7b\u4f3c\u7684\u4e25\u683c\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u91cf\u5b50Petri\u7f51\u7f3a\u4e4f\u5e76\u53d1\u6027\u548c\u91cf\u5b50\u8bed\u4e49\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5c40\u90e8\u5b9a\u4e49\u7684\u91cf\u5b50\u53d1\u751f\u7f51(LQONs)\uff0c\u5e76\u6784\u5efa\u5177\u6709\u826f\u597d\u5c55\u5f00\u8bed\u4e49\u7684QPNs\uff0c\u540c\u65f6\u63d0\u4f9b\u4e00\u4e2a\u7ec4\u5408\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u8bed\u4e49\u660e\u786e\u7684\u91cf\u5b50\u5e76\u53d1\u6a21\u578b\uff0c\u8fde\u63a5\u4e86Petri\u7f51\u7406\u8bba\u548c\u91cf\u5b50\u7f16\u7a0b\u3002", "conclusion": "QPNs\u4e3a\u91cf\u5b50\u5e76\u53d1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7a7a\u767d\u3002"}}
{"id": "2509.01462", "pdf": "https://arxiv.org/pdf/2509.01462", "abs": "https://arxiv.org/abs/2509.01462", "authors": ["Klaus-Dieter Schewe", "Flavio Ferrarotti", "Peter Rivi\u00e8re", "Neeraj Kumar Singh", "Guillaume Dupont", "Yamine A\u00eft Ameur"], "title": "TREBL -- A Relative Complete Temporal Event-B Logic. Part I: Theory", "categories": ["cs.LO"], "comment": "55 pages (including 10 pages of appendices). To be submitted to\n  Logical Methods in Computer Science", "summary": "The verification of liveness conditions is an important aspect of state-based\nrigorous methods. This article addresses the extension of the logic of Event-B\nto a powerful logic, in which properties of traces of an Event-B machine can be\nexpressed. However, all formulae of this logic are still interpreted over\nstates of an Event-B machine rather than traces. The logic exploits that for an\nEvent-B machine $M$ a state $S$ determines all traces of $M$ starting in $S$.\nWe identify a fragment called TREBL of this logic, in which all liveness\nconditions of interest can be expressed, and define a set of sound derivation\nrules for the fragment. We further show relative completeness of these\nderivation rules in the sense that for every valid entailment of a formula\n$\\varphi$ one can find a derivation, provided the machine $M$ is sufficiently\nrefined. The decisive property is that certain variant terms must be definable\nin the refined machine. We show that such refinements always exist. Throughout\nthe article several examples from the field of security are used to illustrate\nthe theory.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Event-B\u903b\u8f91\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aTREBL\u7684\u7247\u6bb5\uff0c\u7528\u4e8e\u8868\u8fbe\u6d3b\u6027\u6761\u4ef6\uff0c\u5e76\u5b9a\u4e49\u4e86\u5176\u63a8\u5bfc\u89c4\u5219\u548c\u76f8\u5bf9\u5b8c\u5907\u6027\u3002", "motivation": "\u9a8c\u8bc1\u6d3b\u6027\u6761\u4ef6\u662f\u72b6\u6001\u57fa\u4e25\u683c\u65b9\u6cd5\u4e2d\u7684\u91cd\u8981\u65b9\u9762\uff0c\u73b0\u6709Event-B\u903b\u8f91\u9700\u8981\u6269\u5c55\u4ee5\u652f\u6301\u8f68\u8ff9\u5c5e\u6027\u7684\u8868\u8fbe\u3002", "method": "\u63d0\u51fa\u4e86TREBL\u903b\u8f91\u7247\u6bb5\uff0c\u5b9a\u4e49\u4e86\u4e00\u5957\u63a8\u5bfc\u89c4\u5219\uff0c\u5e76\u8bc1\u660e\u5176\u76f8\u5bf9\u5b8c\u5907\u6027\uff0c\u8981\u6c42\u673a\u5668\u8db3\u591f\u7ec6\u5316\u3002", "result": "\u7406\u8bba\u652f\u6301\u901a\u8fc7\u7ec6\u5316\u673a\u5668\u6765\u6ee1\u8db3\u63a8\u5bfc\u89c4\u5219\u7684\u5e94\u7528\u6761\u4ef6\uff0c\u4e14\u8fd9\u79cd\u7ec6\u5316\u603b\u662f\u53ef\u884c\u7684\u3002", "conclusion": "\u6587\u7ae0\u901a\u8fc7\u5b89\u5168\u9886\u57df\u7684\u793a\u4f8b\u9a8c\u8bc1\u4e86TREBL\u903b\u8f91\u53ca\u5176\u63a8\u5bfc\u89c4\u5219\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.00040", "pdf": "https://arxiv.org/pdf/2509.00040", "abs": "https://arxiv.org/abs/2509.00040", "authors": ["Chengkai Dai", "Tao Liu", "Dezhao Guo", "Binzhi Sun", "Guoxin Fang", "Yeung Yam", "Charlie C. L. Wang"], "title": "Curve-based slicer for multi-axis DLP 3D printing", "categories": ["cs.GR", "cs.RO"], "comment": null, "summary": "This paper introduces a novel curve-based slicing method for generating\nplanar layers with dynamically varying orientations in digital light processing\n(DLP) 3D printing. Our approach effectively addresses key challenges in DLP\nprinting, such as regions with large overhangs and staircase artifacts, while\npreserving its intrinsic advantages of high resolution and fast printing\nspeeds. We formulate the slicing problem as an optimization task, in which\nparametric curves are computed to define both the slicing layers and the model\npartitioning through their tangent planes. These curves inherently define\nmotion trajectories for the build platform and can be optimized to meet\ncritical manufacturing objectives, including collision-free motion and\nfloating-free deposition. We validate our method through physical experiments\non a robotic multi-axis DLP printing setup, demonstrating that the optimized\ncurves can robustly guide smooth, high-quality fabrication of complex\ngeometries.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u66f2\u7ebf\u7684\u5207\u7247\u65b9\u6cd5\uff0c\u7528\u4e8e\u6570\u5b57\u5149\u5904\u7406\uff08DLP\uff093D\u6253\u5370\u4e2d\u52a8\u6001\u53d8\u5316\u65b9\u5411\u7684\u5e73\u9762\u5c42\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u5927\u60ac\u5782\u533a\u57df\u548c\u9636\u68af\u4f2a\u5f71\u7b49\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3DLP\u6253\u5370\u4e2d\u5927\u60ac\u5782\u533a\u57df\u548c\u9636\u68af\u4f2a\u5f71\u7684\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5206\u8fa8\u7387\u548c\u5feb\u901f\u6253\u5370\u7684\u4f18\u52bf\u3002", "method": "\u5c06\u5207\u7247\u95ee\u9898\u5efa\u6a21\u4e3a\u4f18\u5316\u4efb\u52a1\uff0c\u901a\u8fc7\u53c2\u6570\u66f2\u7ebf\u5b9a\u4e49\u5207\u7247\u5c42\u548c\u6a21\u578b\u5206\u533a\uff0c\u4f18\u5316\u4ee5\u5b9e\u73b0\u65e0\u78b0\u649e\u8fd0\u52a8\u548c\u6d6e\u52a8\u6c89\u79ef\u3002", "result": "\u5728\u673a\u5668\u4eba\u591a\u8f74DLP\u6253\u5370\u88c5\u7f6e\u4e0a\u8fdb\u884c\u4e86\u7269\u7406\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u4f18\u5316\u66f2\u7ebf\u80fd\u591f\u7a33\u5065\u5730\u6307\u5bfc\u9ad8\u8d28\u91cf\u590d\u6742\u51e0\u4f55\u4f53\u7684\u6253\u5370\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u66f2\u7ebf\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u5e73\u6ed1\u7684DLP\u6253\u5370\uff0c\u9002\u7528\u4e8e\u590d\u6742\u51e0\u4f55\u4f53\u7684\u5236\u9020\u3002"}}
{"id": "2509.00360", "pdf": "https://arxiv.org/pdf/2509.00360", "abs": "https://arxiv.org/abs/2509.00360", "authors": ["Shaan Nagy", "Timothy Zhou", "Nadia Polikarpova", "Loris D'Antoni"], "title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models", "categories": ["cs.PL", "D.3.0"], "comment": null, "summary": "Language models (LMs) can generate code, but cannot guarantee its\ncorrectness--producing outputs that often violate type safety, program\ninvariants, or semantic equivalence. Constrained decoding offers a solution by\nrestricting generation to programs that satisfy desired properties. Yet,\nexisting methods are limited to shallow syntactic constraints or rely on\nbrittle, ad hoc encodings of semantics over token sequences.\n  We present ChopChop, the first programmable framework for semantic\nconstrained decoding, enabling LMs to generate code that provably satisfies\nrich semantic properties. ChopChop connects token-level generation with\nreasoning over abstract program structures using a coinduction-based formalism\nand reduces constraint enforcement to a realizability problem over regular\ncodata. We demonstrate ChopChop's generality through generation constrained by\ntype safety and program equivalence, showing how formal methods can be\nseamlessly integrated into LM-driven code generation. ChopChop transforms\nsemantic constrained decoding from a niche technique into a systematic,\nprincipled extension of LMs--improving success rates across models and tasks\nwhile maintaining practical decoding latency.", "AI": {"tldr": "ChopChop\u662f\u4e00\u4e2a\u53ef\u7f16\u7a0b\u7684\u8bed\u4e49\u7ea6\u675f\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u62bd\u8c61\u7a0b\u5e8f\u7ed3\u6784\u548c\u6b63\u5219\u5171\u6570\u636e\u7684\u53ef\u5b9e\u73b0\u6027\u9a8c\u8bc1\uff0c\u786e\u4fdd\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u6ee1\u8db3\u4e30\u5bcc\u8bed\u4e49\u5c5e\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u96be\u4ee5\u4fdd\u8bc1\u6b63\u786e\u6027\uff0c\u5f53\u524d\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\u4ec5\u9650\u4e8e\u6d45\u5c42\u8bed\u6cd5\u7ea6\u675f\u6216\u8106\u5f31\u7684\u8bed\u4e49\u7f16\u7801\u3002", "method": "ChopChop\u7ed3\u5408\u57fa\u4e8e\u5171\u8bf1\u5bfc\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5c06\u8bed\u4e49\u7ea6\u675f\u8f6c\u5316\u4e3a\u6b63\u5219\u5171\u6570\u636e\u7684\u53ef\u5b9e\u73b0\u6027\u95ee\u9898\u3002", "result": "\u5728\u7c7b\u578b\u5b89\u5168\u548c\u7a0b\u5e8f\u7b49\u4ef7\u7ea6\u675f\u4e0b\uff0cChopChop\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u89e3\u7801\u5ef6\u8fdf\u5728\u53ef\u63a5\u53d7\u8303\u56f4\u3002", "conclusion": "ChopChop\u5c06\u8bed\u4e49\u7ea6\u675f\u89e3\u7801\u4ece\u5c0f\u4f17\u6280\u672f\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u6027\u6269\u5c55\uff0c\u4e3aLM\u9a71\u52a8\u7684\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2509.00105", "pdf": "https://arxiv.org/pdf/2509.00105", "abs": "https://arxiv.org/abs/2509.00105", "authors": ["Shaoting Feng", "Hanchen Li", "Kuntai Du", "Zhuohan Gu", "Yuhan Liu", "Jiayi Yao", "Siddhant Ray", "Samuel Shen", "Yihua Cheng", "Ganesh Ananthanarayanan", "Junchen Jiang"], "title": "AdaptCache: KV Cache Native Storage Hierarchy for Low-Delay and High-Quality Language Model Serving", "categories": ["cs.OS"], "comment": null, "summary": "Large language model (LLM) applications often reuse previously processed\ncontext, such as chat history and documents, which introduces significant\nredundant computation. Existing LLM serving systems address such redundant\ncomputation by storing the KV caches of processed context and loading the\ncorresponding KV cache when a new request reuses the context. Further, as these\nLLM applications scale, the total size of KV caches becomes excessively large\nand requires both DRAM and SSD for full storage.\n  However, prior work that stores KV caches in DRAM and SSD suffers from high\nloading delays, as most KV cache hits come from SSD, which is slow to load. To\nincrease the KV cache hit rate on DRAM, we identify lossy KV cache compression\nas a promising approach. We design a lossy compression system that decides the\ncompression algorithm, compression rate and device placement for each KV cache\nentry to maximise DRAM hits and minimise loading delay without significantly\ndegrading generation quality. Compared to various static compression baselines\nacross three tasks, our system AdaptCache achieves 1.43--2.4 x delay savings at\nthe same quality and 6--55% quality improvements at the same delay.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u538b\u7f29\u7b97\u6cd5\u548c\u901f\u7387\u7684\u7cfb\u7edfAdaptCache\uff0c\u4ee5\u63d0\u9ad8KV\u7f13\u5b58\u7684DRAM\u547d\u4e2d\u7387\u5e76\u51cf\u5c11\u52a0\u8f7d\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LLM\u670d\u52a1\u7cfb\u7edf\u4e2dKV\u7f13\u5b58\u56e0\u89c4\u6a21\u8fc7\u5927\u5bfc\u81f4\u7684\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u7279\u522b\u662fSSD\u52a0\u8f7d\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u52a8\u6001\u635f\u5931\u538b\u7f29\u7cfb\u7edf\uff0c\u6839\u636eKV\u7f13\u5b58\u6761\u76ee\u9009\u62e9\u538b\u7f29\u7b97\u6cd5\u3001\u538b\u7f29\u7387\u548c\u8bbe\u5907\u653e\u7f6e\u4f4d\u7f6e\uff0c\u4ee5\u4f18\u5316DRAM\u547d\u4e2d\u7387\u548c\u5ef6\u8fdf\u3002", "result": "\u4e0e\u9759\u6001\u538b\u7f29\u65b9\u6cd5\u76f8\u6bd4\uff0cAdaptCache\u5728\u76f8\u540c\u8d28\u91cf\u4e0b\u5ef6\u8fdf\u51cf\u5c111.43-2.4\u500d\uff0c\u5728\u76f8\u540c\u5ef6\u8fdf\u4e0b\u8d28\u91cf\u63d0\u53476-55%\u3002", "conclusion": "\u52a8\u6001\u635f\u5931\u538b\u7f29\u662f\u4f18\u5316KV\u7f13\u5b58\u5b58\u50a8\u548c\u52a0\u8f7d\u6548\u7387\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2509.00130", "pdf": "https://arxiv.org/pdf/2509.00130", "abs": "https://arxiv.org/abs/2509.00130", "authors": ["Chang Liu", "T. D. Khoa Le", "Rahul Saini", "Kishor C. Joshi", "George Exarchakos"], "title": "VOTA: Parallelizing 6G-RAN Experimentation with Virtualized Over-The-Air Workloads", "categories": ["cs.NI"], "comment": null, "summary": "Testbed sharing, a practice in which different researchers concurrently\ndevelop independent use cases on top of the same testbed, is ubiquitous in\nwireless experimental research. Its key drawback is experimental inconvenience:\none must delay experiments or tolerate compute and RF interference that harms\nexperimental fidelity. In this paper, we propose \\textbf{VOTA}, an open-source,\nsoftware-only testbed scaling method that leverages real-time virtualization\nand frequency tuning to maximize parallel experiments while controlling\ninterference. In a demonstration of two interference-sensitive 6G use cases --\n\\textit{MIMO iDFT/DFT Offloading} and \\textit{O-RAN DoS Attack} -- running\nside-by-side on a 32-core host, we showcase VOTA capabilities:\n\\textbf{dedicated-like} results while allowing \\textbf{2.67$\\times$} more\nsharing opportunities.", "AI": {"tldr": "VOTA\u662f\u4e00\u79cd\u5f00\u6e90\u3001\u7eaf\u8f6f\u4ef6\u7684\u6d4b\u8bd5\u5e8a\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u65f6\u865a\u62df\u5316\u548c\u9891\u7387\u8c03\u8c10\u6700\u5927\u5316\u5e76\u884c\u5b9e\u9a8c\uff0c\u540c\u65f6\u63a7\u5236\u5e72\u6270\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u5e8a\u5171\u4eab\u6548\u7387\u3002", "motivation": "\u6d4b\u8bd5\u5e8a\u5171\u4eab\u5728\u65e0\u7ebf\u5b9e\u9a8c\u7814\u7a76\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u5176\u4e3b\u8981\u7f3a\u70b9\u662f\u5b9e\u9a8c\u4e0d\u4fbf\uff0c\u5982\u5ef6\u8fdf\u5b9e\u9a8c\u6216\u5bb9\u5fcd\u5bf9\u5b9e\u9a8c\u4fdd\u771f\u5ea6\u6709\u5bb3\u7684\u8ba1\u7b97\u548c\u5c04\u9891\u5e72\u6270\u3002", "method": "\u63d0\u51fa\u4e86VOTA\uff0c\u5229\u7528\u5b9e\u65f6\u865a\u62df\u5316\u548c\u9891\u7387\u8c03\u8c10\uff0c\u63a7\u5236\u5e72\u6270\u5e76\u6700\u5927\u5316\u5e76\u884c\u5b9e\u9a8c\u3002", "result": "\u5728\u4e24\u4e2a\u5e72\u6270\u654f\u611f\u76846G\u7528\u4f8b\u4e2d\u5c55\u793a\u4e86VOTA\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4f3c\u4e13\u7528\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u589e\u52a0\u4e862.67\u500d\u7684\u5171\u4eab\u673a\u4f1a\u3002", "conclusion": "VOTA\u6709\u6548\u89e3\u51b3\u4e86\u6d4b\u8bd5\u5e8a\u5171\u4eab\u4e2d\u7684\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5b9e\u9a8c\u6548\u7387\u3002"}}
{"id": "2509.00352", "pdf": "https://arxiv.org/pdf/2509.00352", "abs": "https://arxiv.org/abs/2509.00352", "authors": ["Yuqing Wei", "Yupeng Wang", "Jiayi Zhao", "Yanjun Liu", "Huxin Gao", "Jiewen Lai"], "title": "Unlocking Mixed Reality for Medical Education: A See-Through Perspective on Head Anatomy", "categories": ["cs.HC"], "comment": null, "summary": "Extended reality (XR), encompassing Virtual Reality (VR), Augmented Reality\n(AR), and Mixed Reality (MR), is emerging as a transformative platform for\nmedical education. Traditional methods such as textbooks, physical models, and\ncadaveric dissections often lack interactivity and fail to convey complex\nspatial relationships effectively. The emerging MR technology addresses these\nlimitations by providing immersive environments that blend virtual elements\nwith real-world contexts. This study presents an MR application for head\nanatomy education, enabling learners to intuitively interact with see-through\n3D anatomical structures via hand gestures and controllers. Our hierarchical\ninformation design supports progressive learning, guiding users from basic\nanatomical labels to detailed structural insights. Additionally, the system\nincorporates an automatic calibration module that aligns virtual anatomical\nmodels with a real human head, thereby facilitating realistic human-model\ninteractions. Experiments show that the system can effectively match the\nanatomical model with real-time scenes, thus enhancing the interactivity and\nimmersion of medical education, providing an innovative tool for teaching\nanatomy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u6df7\u5408\u73b0\u5b9e\uff08MR\uff09\u5e94\u7528\uff0c\u7528\u4e8e\u5934\u90e8\u89e3\u5256\u5b66\u6559\u80b2\uff0c\u901a\u8fc7\u624b\u52bf\u548c\u63a7\u5236\u5668\u4ea4\u4e92\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u533b\u5b66\u6559\u80b2\u65b9\u6cd5\uff08\u5982\u8bfe\u672c\u3001\u7269\u7406\u6a21\u578b\uff09\u7f3a\u4e4f\u4ea4\u4e92\u6027\u548c\u7a7a\u95f4\u5173\u7cfb\u7684\u6709\u6548\u4f20\u8fbe\uff0cMR\u6280\u672f\u53ef\u4ee5\u5f25\u8865\u8fd9\u4e9b\u4e0d\u8db3\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u4e2aMR\u5e94\u7528\uff0c\u7ed3\u5408\u5206\u5c42\u4fe1\u606f\u8bbe\u8ba1\u548c\u81ea\u52a8\u6821\u51c6\u6a21\u5757\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u6709\u6548\u5339\u914d\u865a\u62df\u89e3\u5256\u6a21\u578b\u4e0e\u5b9e\u65f6\u573a\u666f\uff0c\u589e\u5f3a\u533b\u5b66\u6559\u80b2\u7684\u4ea4\u4e92\u6027\u548c\u6c89\u6d78\u611f\u3002", "conclusion": "MR\u6280\u672f\u4e3a\u89e3\u5256\u5b66\u6559\u80b2\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u6559\u5b66\u5de5\u5177\uff0c\u5177\u6709\u663e\u8457\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.00053", "pdf": "https://arxiv.org/pdf/2509.00053", "abs": "https://arxiv.org/abs/2509.00053", "authors": ["Shuo Liu", "Di Yao", "Yan Lin", "Gao Cong", "Jingping Bi"], "title": "Traj-MLLM: Can Multimodal Large Language Models Reform Trajectory Data Mining?", "categories": ["cs.MM", "cs.AI", "cs.CL"], "comment": "20 pages, 10 figures", "summary": "Building a general model capable of analyzing human trajectories across\ndifferent geographic regions and different tasks becomes an emergent yet\nimportant problem for various applications. However, existing works suffer from\nthe generalization problem, \\ie, they are either restricted to train for\nspecific regions or only suitable for a few tasks. Given the recent advances of\nmultimodal large language models (MLLMs), we raise the question: can MLLMs\nreform current trajectory data mining and solve the problem? Nevertheless, due\nto the modality gap of trajectory, how to generate task-independent multimodal\ntrajectory representations and how to adapt flexibly to different tasks remain\nthe foundational challenges. In this paper, we propose \\texttt{Traj-MLLM}},\nwhich is the first general framework using MLLMs for trajectory data mining. By\nintegrating multiview contexts, \\texttt{Traj-MLLM}} transforms raw trajectories\ninto interleaved image-text sequences while preserving key spatial-temporal\ncharacteristics, and directly utilizes the reasoning ability of MLLMs for\ntrajectory analysis. Additionally, a prompt optimization method is proposed to\nfinalize data-invariant prompts for task adaptation. Extensive experiments on\nfour publicly available datasets show that \\texttt{Traj-MLLM}} outperforms\nstate-of-the-art baselines by $48.05\\%$, $15.52\\%$, $51.52\\%$, $1.83\\%$ on\ntravel time estimation, mobility prediction, anomaly detection and\ntransportation mode identification, respectively. \\texttt{Traj-MLLM}} achieves\nthese superior performances without requiring any training data or fine-tuning\nthe MLLM backbones.", "AI": {"tldr": "\u63d0\u51fa\u4e86Traj-MLLM\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u901a\u7528\u6846\u67b6\uff0c\u9996\u6b21\u5e94\u7528\u4e8e\u8f68\u8ff9\u6570\u636e\u6316\u6398\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u591a\u89c6\u89d2\u4e0a\u4e0b\u6587\u5c06\u539f\u59cb\u8f68\u8ff9\u8f6c\u5316\u4e3a\u56fe\u50cf-\u6587\u672c\u5e8f\u5217\uff0c\u5e76\u5229\u7528MLLMs\u7684\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u5206\u6790\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u6216\u5fae\u8c03\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8f68\u8ff9\u5206\u6790\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63a2\u7d22MLLMs\u5728\u8f68\u8ff9\u6570\u636e\u6316\u6398\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u5f15\u5165Traj-MLLM\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u4e0a\u4e0b\u6587\u8f6c\u6362\u8f68\u8ff9\u4e3a\u56fe\u50cf-\u6587\u672c\u5e8f\u5217\uff0c\u5e76\u63d0\u51fa\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4ee5\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u3002", "result": "\u5728\u65c5\u884c\u65f6\u95f4\u4f30\u8ba1\u3001\u79fb\u52a8\u9884\u6d4b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u4ea4\u901a\u65b9\u5f0f\u8bc6\u522b\u7b49\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5206\u522b\u63d0\u534748.05%\u300115.52%\u300151.52%\u548c1.83%\u3002", "conclusion": "Traj-MLLM\u5c55\u793a\u4e86MLLMs\u5728\u8f68\u8ff9\u6570\u636e\u6316\u6398\u4e2d\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u6cdb\u5316\u3002"}}
{"id": "2509.01893", "pdf": "https://arxiv.org/pdf/2509.01893", "abs": "https://arxiv.org/abs/2509.01893", "authors": ["Zhongrui Chen", "Adityo Anggraito", "Diletta Olliaro", "Andrea Marin", "Marco Ajmone Marsan", "Benjamin Berg", "Isaac Grosof"], "title": "Improving Nonpreemptive Multiserver Job Scheduling with Quickswap", "categories": ["cs.PF"], "comment": null, "summary": "Modern data center workloads are composed of multiserver jobs, computational\njobs that require multiple CPU cores in order to run. A data center server can\nrun many multiserver jobs in parallel, as long as it has sufficient resources\nto meet their demands. However, multiserver jobs are generally stateful,\nmeaning that job preemptions incur significant overhead from saving and\nreloading the state associated with running jobs. Hence, most systems try to\navoid these costly job preemptions altogether. Given these constraints, a\nscheduling policy must determine what set of jobs to run in parallel at each\nmoment in time to minimize the mean response time across a stream of arriving\njobs. Unfortunately, simple non-preemptive policies such as FCFS may leave many\ncores idle, resulting in high mean response times or even system instability.\nOur goal is to design and analyze non-preemptive scheduling policies for\nmultiserver jobs that maintain high system utilization to achieve low mean\nresponse time.\n  One well-known non-preemptive policy, Most Servers First (MSF), prioritizes\njobs with higher core requirements and achieves high resource utilization.\nHowever, MSF causes extreme variability in job waiting times, and can perform\nsignificantly worse than FCFS in practice. To address this, we propose and\nanalyze a class of scheduling policies called MSF-Quick Swap (MSFQ) that\nperforms well. MSFQ reduces the variability of job waiting times by\nperiodically granting priority to other jobs in the system. We provide both\nstability results and an analysis of mean response time under MSFQ to prove\nthat our policy dramatically outperforms MSF in the case where jobs request one\ncore or all the cores. In more complex cases, we evaluate MSFQ in simulation.\nWe show that, with some additional optimization, variants of the MSFQ policy\ncan greatly outperform MSF and FCFS on real-world multiserver job workloads.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMSFQ\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u65e8\u5728\u4f18\u5316\u591a\u670d\u52a1\u5668\u4f5c\u4e1a\u7684\u54cd\u5e94\u65f6\u95f4\uff0c\u901a\u8fc7\u51cf\u5c11\u4f5c\u4e1a\u7b49\u5f85\u65f6\u95f4\u7684\u53d8\u5f02\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684MSF\u548cFCFS\u7b56\u7565\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u7684\u591a\u670d\u52a1\u5668\u4f5c\u4e1a\u9700\u8981\u591a\u4e2aCPU\u6838\u5fc3\uff0c\u4e14\u901a\u5e38\u662f\u72b6\u6001\u5316\u7684\uff0c\u62a2\u5360\u4f5c\u4e1a\u4f1a\u5bfc\u81f4\u9ad8\u5f00\u9500\u3002\u4e3a\u907f\u514d\u62a2\u5360\uff0c\u9700\u8bbe\u8ba1\u975e\u62a2\u5360\u5f0f\u8c03\u5ea6\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u7cfb\u7edf\u5229\u7528\u7387\u548c\u4f4e\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u3002", "method": "\u8bba\u6587\u63d0\u51faMSFQ\u7b56\u7565\uff0c\u901a\u8fc7\u5468\u671f\u6027\u8d4b\u4e88\u5176\u4ed6\u4f5c\u4e1a\u4f18\u5148\u7ea7\uff0c\u51cf\u5c11\u4f5c\u4e1a\u7b49\u5f85\u65f6\u95f4\u7684\u53d8\u5f02\u6027\u3002\u7406\u8bba\u5206\u6790\u548c\u4eff\u771f\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "result": "MSFQ\u5728\u4f5c\u4e1a\u8bf7\u6c42\u5355\u6838\u6216\u6240\u6709\u6838\u5fc3\u65f6\u663e\u8457\u4f18\u4e8eMSF\uff1b\u901a\u8fc7\u4f18\u5316\uff0c\u5176\u53d8\u4f53\u5728\u590d\u6742\u573a\u666f\u4e0b\u4e5f\u4f18\u4e8eMSF\u548cFCFS\u3002", "conclusion": "MSFQ\u7b56\u7565\u80fd\u6709\u6548\u964d\u4f4e\u591a\u670d\u52a1\u5668\u4f5c\u4e1a\u7684\u54cd\u5e94\u65f6\u95f4\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u3002"}}
{"id": "2509.00433", "pdf": "https://arxiv.org/pdf/2509.00433", "abs": "https://arxiv.org/abs/2509.00433", "authors": ["Houshu He", "Naifeng Jing", "Li Jiang", "Xiaoyao Liang", "Zhuoran Song"], "title": "AGS: Accelerating 3D Gaussian Splatting SLAM via CODEC-Assisted Frame Covisibility Detection", "categories": ["cs.AR", "cs.RO"], "comment": "15 pages", "summary": "Simultaneous Localization and Mapping (SLAM) is a critical task that enables\nautonomous vehicles to construct maps and localize themselves in unknown\nenvironments. Recent breakthroughs combine SLAM with 3D Gaussian Splatting\n(3DGS) to achieve exceptional reconstruction fidelity. However, existing\n3DGS-SLAM systems provide insufficient throughput due to the need for multiple\ntraining iterations per frame and the vast number of Gaussians.\n  In this paper, we propose AGS, an algorithm-hardware co-design framework to\nboost the efficiency of 3DGS-SLAM based on the intuition that SLAM systems\nprocess frames in a streaming manner, where adjacent frames exhibit high\nsimilarity that can be utilized for acceleration. On the software level: 1) We\npropose a coarse-then-fine-grained pose tracking method with respect to the\nrobot's movement. 2) We avoid redundant computations of Gaussians by sharing\ntheir contribution information across frames. On the hardware level, we propose\na frame covisibility detection engine to extract intermediate data from the\nvideo CODEC. We also implement a pose tracking engine and a mapping engine with\nworkload schedulers to efficiently deploy the AGS algorithm. Our evaluation\nshows that AGS achieves up to $17.12\\times$, $6.71\\times$, and $5.41\\times$\nspeedups against the mobile and high-end GPUs, and a state-of-the-art 3DGS\naccelerator, GSCore.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAGS\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u76f8\u90bb\u5e27\u7684\u9ad8\u76f8\u4f3c\u6027\uff0c\u4f18\u5316\u4e863D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09SLAM\u7cfb\u7edf\u7684\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u76843DGS-SLAM\u7cfb\u7edf\u7531\u4e8e\u6bcf\u5e27\u9700\u8981\u591a\u6b21\u8bad\u7ec3\u8fed\u4ee3\u548c\u9ad8\u65af\u6570\u91cf\u5e9e\u5927\uff0c\u5bfc\u81f4\u541e\u5410\u91cf\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7b97\u6cd5\u548c\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8f6f\u4ef6\u5c42\u9762\u63d0\u51fa\u7c97\u5230\u7ec6\u7684\u4f4d\u59ff\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5e76\u5171\u4eab\u9ad8\u65af\u8d21\u732e\u4fe1\u606f\u4ee5\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff1b\u786c\u4ef6\u5c42\u9762\u8bbe\u8ba1\u4e86\u5e27\u5171\u89c6\u68c0\u6d4b\u5f15\u64ce\u3001\u4f4d\u59ff\u8ddf\u8e2a\u5f15\u64ce\u548c\u6620\u5c04\u5f15\u64ce\uff0c\u7ed3\u5408\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6\u5668\u9ad8\u6548\u90e8\u7f72AGS\u7b97\u6cd5\u3002", "result": "AGS\u5728\u79fb\u52a8\u548c\u9ad8\u6027\u80fdGPU\u4ee5\u53caGSCore\u52a0\u901f\u5668\u4e0a\u7684\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e8617.12\u500d\u30016.71\u500d\u548c5.41\u500d\u3002", "conclusion": "AGS\u901a\u8fc7\u7b97\u6cd5\u548c\u786c\u4ef6\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e863DGS-SLAM\u7684\u6548\u7387\uff0c\u4e3a\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00579", "pdf": "https://arxiv.org/pdf/2509.00579", "abs": "https://arxiv.org/abs/2509.00579", "authors": ["Bo Jiang", "Taolue Yang", "Youyuan Liu", "Chengming Zhang", "Xubin He", "Sian Jin"], "title": "KVComp: A High-Performance, LLM-Aware, Lossy Compression Framework for KV Cache", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Transformer-based large language models (LLMs) demonstrate impressive\npotential in various practical applications. However, long context inference\nposes a significant challenge due to the enormous memory requirements of the\nkey-value (KV) cache, which can scale to multiple gigabytes as sequence length\nand batch size increase. In this paper, we present KVComp, a generic and\nefficient KV cache management framework optimized for long-text generation that\nsynergistically works with both latency-critical and throughput-critical\ninference systems. KVComp employs novel lossy compression techniques\nspecifically designed for KV cache data characteristics, featuring careful\nco-design of compression algorithms and system architecture. Our approach\nmaintains compatibility with the growing nature of KV cache while preserving\nhigh computational efficiency. Experimental results show that KVComp achieves\non average 47\\% and up to 83\\% higher memory reduction rate compared to\nexisting methods with little/no model accuracy degradation. Furthermore, KVComp\nachieves extremely high execution throughput, effectively reducing\ndecompression overhead and, in some cases, even accelerating the matrix-vector\nmultiplication operation and outperform cuBLAS-based attention kernels with\nless data movement.", "AI": {"tldr": "KVComp\u662f\u4e00\u4e2a\u9ad8\u6548\u7684KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u635f\u538b\u7f29\u6280\u672f\u51cf\u5c11\u5185\u5b58\u9700\u6c42\uff0c\u9002\u7528\u4e8e\u957f\u6587\u672c\u751f\u6210\uff0c\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u63a8\u65ad\u4e2d\uff0cKV\u7f13\u5b58\u7684\u9ad8\u5185\u5b58\u9700\u6c42\u662f\u4e3b\u8981\u6311\u6218\uff0c\u9700\u4f18\u5316\u4ee5\u51cf\u5c11\u5185\u5b58\u5360\u7528\u3002", "method": "\u91c7\u7528\u4e13\u4e3aKV\u7f13\u5b58\u8bbe\u8ba1\u7684\u65e0\u635f\u538b\u7f29\u6280\u672f\uff0c\u7ed3\u5408\u538b\u7f29\u7b97\u6cd5\u548c\u7cfb\u7edf\u67b6\u6784\u7684\u534f\u540c\u8bbe\u8ba1\u3002", "result": "KVComp\u5e73\u5747\u51cf\u5c1147%\u5185\u5b58\u5360\u7528\uff0c\u6700\u9ad8\u8fbe83%\uff0c\u65e0\u660e\u663e\u7cbe\u5ea6\u635f\u5931\uff0c\u4e14\u6267\u884c\u541e\u5410\u91cf\u9ad8\u3002", "conclusion": "KVComp\u6709\u6548\u89e3\u51b3\u4e86\u957f\u6587\u672c\u751f\u6210\u4e2d\u7684\u5185\u5b58\u9700\u6c42\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2509.00979", "pdf": "https://arxiv.org/pdf/2509.00979", "abs": "https://arxiv.org/abs/2509.00979", "authors": ["Bhima Sankar Manthina", "Shreyash Gujar", "Sachin Chaudhari", "Kavita Vemuri1", "Shivam Chhirolya"], "title": "IoT-based Noise Monitoring using Mobile Nodes for Smart Cities", "categories": ["cs.ET", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Urban noise pollution poses a significant threat to public health, yet\nexisting monitoring infrastructures offer limited spatial coverage and\nadaptability. This paper presents a scalable, low-cost, IoT-based, real-time\nenvironmental noise monitoring solution using mobile nodes (sensor nodes on a\nmoving vehicle). The system utilizes a low-cost sound sensor integrated with\nGPS-enabled modules to collect geotagged noise data at one-second intervals.\nThe sound nodes are calibrated against a reference sound level meter in a\nlaboratory setting to ensure accuracy using various machine learning (ML)\nalgorithms, such as Simple Linear Regression (SLR), Multiple Linear Regression\n(MLR), Polynomial Regression (PR), Segmented Regression (SR), Support Vector\nRegression (SVR), Decision Tree (DT), and Random Forest Regression (RFR). While\nlaboratory calibration demonstrates high accuracy, it is shown that the\nperformance of the nodes degrades during data collection in a moving vehicle.\nTo address this, it is demonstrated that the calibration must be performed on\nthe IoT-based node based on the data collected in a moving environment along\nwith the reference device. Among the employed ML models, RFR achieved the best\nperformance with an R2 of 0.937 and RMSE of 1.09 for mobile calibration. The\nsystem was deployed in Hyderabad, India, through three measurement campaigns\nacross 27 days, capturing 436,420 data points. Results highlight temporal and\nspatial noise variations across weekdays, weekends, and during Diwali.\nIncorporating vehicular velocity into the calibration significantly improves\naccuracy. The proposed system demonstrates the potential for widespread\ndeployment of IoT-based noise sensing networks in smart cities, enabling\neffective noise pollution management and urban planning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79fb\u52a8\u8f66\u8f86\u7684IoT\u566a\u58f0\u76d1\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6821\u51c6\u4f20\u611f\u5668\uff0c\u5e76\u5728\u5b9e\u9645\u79fb\u52a8\u73af\u5883\u4e2d\u9a8c\u8bc1\u6027\u80fd\uff0c\u7ed3\u679c\u8868\u660e\u968f\u673a\u68ee\u6797\u56de\u5f52\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u57ce\u5e02\u566a\u58f0\u6c61\u67d3\u5bf9\u516c\u5171\u5065\u5eb7\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u76d1\u6d4b\u57fa\u7840\u8bbe\u65bd\u8986\u76d6\u8303\u56f4\u548c\u9002\u5e94\u6027\u6709\u9650\uff0c\u9700\u4f4e\u6210\u672c\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u4f4e\u6210\u672c\u58f0\u97f3\u4f20\u611f\u5668\u548cGPS\u6a21\u5757\u6536\u96c6\u566a\u58f0\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u591a\u79cdML\u7b97\u6cd5\uff08\u5982RFR\uff09\u6821\u51c6\u4f20\u611f\u5668\u3002", "result": "\u79fb\u52a8\u6821\u51c6\u4e2dRFR\u8868\u73b0\u6700\u4f73\uff08R2=0.937\uff09\uff0c\u7cfb\u7edf\u5728\u5370\u5ea6\u6d77\u5f97\u62c9\u5df4\u90e8\u7f72\uff0c\u6355\u6349\u523043.6\u4e07\u6570\u636e\u70b9\uff0c\u663e\u793a\u566a\u58f0\u65f6\u7a7a\u53d8\u5316\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u652f\u6301\u667a\u80fd\u57ce\u5e02\u5e7f\u6cdb\u90e8\u7f72IoT\u566a\u58f0\u76d1\u6d4b\u7f51\u7edc\uff0c\u6709\u6548\u7ba1\u7406\u566a\u58f0\u6c61\u67d3\u3002"}}
{"id": "2509.01479", "pdf": "https://arxiv.org/pdf/2509.01479", "abs": "https://arxiv.org/abs/2509.01479", "authors": ["Bernd Finkbeiner", "Hadar Frenkel", "Julian Siber"], "title": "An Information-Flow Perspective on Explainability Requirements: Specification and Verification", "categories": ["cs.LO", "cs.AI"], "comment": "22nd International Conference on Principles of Knowledge\n  Representation and Reasoning (KR 2025)", "summary": "Explainable systems expose information about why certain observed effects are\nhappening to the agents interacting with them. We argue that this constitutes a\npositive flow of information that needs to be specified, verified, and balanced\nagainst negative information flow that may, e.g., violate privacy guarantees.\nSince both explainability and privacy require reasoning about knowledge, we\ntackle these tasks with epistemic temporal logic extended with quantification\nover counterfactual causes. This allows us to specify that a multi-agent system\nexposes enough information such that agents acquire knowledge on why some\neffect occurred. We show how this principle can be used to specify\nexplainability as a system-level requirement and provide an algorithm for\nchecking finite-state models against such specifications. We present a\nprototype implementation of the algorithm and evaluate it on several\nbenchmarks, illustrating how our approach distinguishes between explainable and\nunexplainable systems, and how it allows to pose additional privacy\nrequirements.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u53ef\u89e3\u91ca\u7cfb\u7edf\u5982\u4f55\u901a\u8fc7\u4fe1\u606f\u6d41\u5b9e\u73b0\u89e3\u91ca\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ba4\u77e5\u65f6\u5e8f\u903b\u8f91\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1\u7cfb\u7edf\u662f\u5426\u6ee1\u8db3\u89e3\u91ca\u6027\u8981\u6c42\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5e73\u8861\u53ef\u89e3\u91ca\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u6d41\uff0c\u786e\u4fdd\u65e2\u80fd\u63d0\u4f9b\u8db3\u591f\u7684\u89e3\u91ca\u4fe1\u606f\uff0c\u53c8\u4e0d\u4fb5\u72af\u9690\u79c1\u3002", "method": "\u4f7f\u7528\u6269\u5c55\u7684\u8ba4\u77e5\u65f6\u5e8f\u903b\u8f91\uff0c\u7ed3\u5408\u53cd\u4e8b\u5b9e\u56e0\u679c\u91cf\u5316\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\u6765\u9a8c\u8bc1\u6709\u9650\u72b6\u6001\u6a21\u578b\u7684\u89e3\u91ca\u6027\u3002", "result": "\u901a\u8fc7\u539f\u578b\u5b9e\u73b0\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u533a\u5206\u53ef\u89e3\u91ca\u4e0e\u4e0d\u53ef\u89e3\u91ca\u7cfb\u7edf\uff0c\u5e76\u80fd\u9644\u52a0\u9690\u79c1\u8981\u6c42\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u7cfb\u7edf\u662f\u5426\u6ee1\u8db3\u89e3\u91ca\u6027\u548c\u9690\u79c1\u7684\u53cc\u91cd\u8981\u6c42\u3002"}}
{"id": "2509.00052", "pdf": "https://arxiv.org/pdf/2509.00052", "abs": "https://arxiv.org/abs/2509.00052", "authors": ["Jianzhi Long", "Wenhao Sun", "Rongcheng Tu", "Dacheng Tao"], "title": "Lightning Fast Caching-based Parallel Denoising Prediction for Accelerating Talking Head Generation", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": null, "summary": "Diffusion-based talking head models generate high-quality, photorealistic\nvideos but suffer from slow inference, limiting practical applications.\nExisting acceleration methods for general diffusion models fail to exploit the\ntemporal and spatial redundancies unique to talking head generation. In this\npaper, we propose a task-specific framework addressing these inefficiencies\nthrough two key innovations. First, we introduce Lightning-fast Caching-based\nParallel denoising prediction (LightningCP), caching static features to bypass\nmost model layers in inference time. We also enable parallel prediction using\ncached features and estimated noisy latents as inputs, efficiently bypassing\nsequential sampling. Second, we propose Decoupled Foreground Attention (DFA) to\nfurther accelerate attention computations, exploiting the spatial decoupling in\ntalking head videos to restrict attention to dynamic foreground regions.\nAdditionally, we remove reference features in certain layers to bring extra\nspeedup. Extensive experiments demonstrate that our framework significantly\nimproves inference speed while preserving video quality.", "AI": {"tldr": "\u9488\u5bf9\u6269\u6563\u5f0f\u8bf4\u8bdd\u5934\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u6162\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4efb\u52a1\u4e13\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u7f13\u5b58\u9759\u6001\u7279\u5f81\u5e76\u884c\u9884\u6d4b\u53ca\u4f18\u5316\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\u4e14\u4e0d\u5f71\u54cd\u89c6\u9891\u8d28\u91cf\u3002", "motivation": "\u6269\u6563\u57fa\u8bf4\u8bdd\u5934\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u89c6\u9891\u4f46\u63a8\u7406\u901f\u5ea6\u6162\uff0c\u73b0\u6709\u901a\u7528\u52a0\u901f\u65b9\u6cd5\u672a\u80fd\u5229\u7528\u5176\u65f6\u7a7a\u5197\u4f59\u7279\u6027\u3002", "method": "\u63d0\u51faLightningCP\u7f13\u5b58\u9759\u6001\u7279\u5f81\u5e76\u884c\u9884\u6d4b\uff0c\u4ee5\u53caDFA\u4f18\u5316\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u4e13\u6ce8\u4e8e\u52a8\u6001\u524d\u666f\u533a\u57df\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u52a0\u5feb\u63a8\u7406\u901f\u5ea6\u5e76\u4fdd\u6301\u89c6\u9891\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u89e3\u51b3\u4e86\u6269\u6563\u5f0f\u8bf4\u8bdd\u5934\u6a21\u578b\u7684\u63a8\u7406\u74f6\u9888\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.00587", "pdf": "https://arxiv.org/pdf/2509.00587", "abs": "https://arxiv.org/abs/2509.00587", "authors": ["Vaibhav Mehta", "Justin Hsu"], "title": "A Hoare Logic for Symmetry Properties", "categories": ["cs.PL"], "comment": "Accepted to OOPSLA '25", "summary": "Many natural program correctness properties can be stated in terms of\n  symmetries, but existing formal methods have little support for reasoning\n  about such properties. We consider how to formally verify a broad class of\n  symmetry properties expressed in terms of group actions. To specify these\n  properties, we design a syntax for group actions, supporting standard\n  constructions and a natural notion of entailment. Then, we develop a\n  Hoare-style logic for verifying symmetry properties of imperative programs,\n  where group actions take the place of the typical pre- and post-condition\n  assertions. Finally, we develop a prototype tool $\\mathsf{SymVerif}$, and use\n  it to verify symmetry properties on a series of handcrafted benchmarks. Our\n  tool uncovered an error in a model of a dynamical system described by\n\\citet{McLachlan_Quispel_2002}.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u652f\u6301\u5bf9\u79f0\u6027\u5c5e\u6027\u9a8c\u8bc1\u7684Hoare\u98ce\u683c\u903b\u8f91\u548c\u5de5\u5177SymVerif\uff0c\u7528\u4e8e\u9a8c\u8bc1\u7a0b\u5e8f\u4e2d\u7684\u5bf9\u79f0\u6027\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d1\u73b0\u4e86\u6587\u732e\u4e2d\u7684\u9519\u8bef\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u5316\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u5bf9\u79f0\u6027\u5c5e\u6027\u7684\u652f\u6301\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65b9\u6cd5\u6765\u9a8c\u8bc1\u8fd9\u4e9b\u5c5e\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u63cf\u8ff0\u7fa4\u52a8\u4f5c\u7684\u8bed\u6cd5\uff0c\u5f00\u53d1\u4e86Hoare\u98ce\u683c\u7684\u903b\u8f91\uff0c\u5e76\u5b9e\u73b0\u4e86\u5de5\u5177SymVerif\u3002", "result": "\u5de5\u5177\u6210\u529f\u9a8c\u8bc1\u4e86\u4e00\u7cfb\u5217\u624b\u5199\u57fa\u51c6\u6d4b\u8bd5\u7684\u5bf9\u79f0\u6027\u5c5e\u6027\uff0c\u5e76\u53d1\u73b0\u4e86\u6587\u732e\u4e2d\u7684\u9519\u8bef\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9a8c\u8bc1\u7a0b\u5e8f\u4e2d\u7684\u5bf9\u79f0\u6027\u5c5e\u6027\uff0c\u4e14\u5de5\u5177\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.01245", "pdf": "https://arxiv.org/pdf/2509.01245", "abs": "https://arxiv.org/abs/2509.01245", "authors": ["Yusheng Zheng", "Yanpeng Hu", "Wei Zhang", "Andi Quinn"], "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "categories": ["cs.AI", "cs.MA", "cs.OS"], "comment": null, "summary": "Operating system schedulers suffer from a fundamental semantic gap, where\nkernel policies fail to understand application-specific needs, leading to\nsuboptimal performance. We introduce SchedCP, the first framework that enables\nfully autonomous Large Language Model (LLM) agents to safely and efficiently\noptimize Linux schedulers without human involvement. Our core insight is that\nthe challenge is not merely to apply a better LLM, but to architect a decoupled\ncontrol plane that separates the AI's role of semantic reasoning (\"what to\noptimize\") from the system's role of execution (\"how to observe and act\").\nImplemented as Model Context Protocol(MCP) server, SchedCP provides a stable\ninterface with three key services: a Workload Analysis Engine, an evolving\nScheduler Policy Repository, and an Execution Verifier that validates all\nAI-generated code and configure before deployment with static and dynamic\nanalysis.\n  We demonstrate this architecture's power with sched-agent, a multi-agent\nsystem that autonomously analyzes workloads, synthesizes custom eBPF scheduling\npolicies, and deploys them via the sched\\_ext infrastructure. Our evaluation\nshows that SchedCP achieves up to an 1.79x performance improvement, and a 13x\ncost reduction compared to naive agentic approaches, all while maintaining high\nsuccess rate. By bridging the semantic gap, SchedCP democratizes expert-level\nsystem optimization and represents a step towards creating truly\nself-optimizing, application-aware operating systems. The code is open-sourced\nin https://github.com/eunomia-bpf/schedcp", "AI": {"tldr": "SchedCP \u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u4e3b\u4f18\u5316 Linux \u8c03\u5ea6\u5668\uff0c\u89e3\u51b3\u4e86\u5185\u6838\u7b56\u7565\u4e0e\u5e94\u7528\u7a0b\u5e8f\u9700\u6c42\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u65e0\u6cd5\u5145\u5206\u7406\u89e3\u5e94\u7528\u7a0b\u5e8f\u7684\u7279\u5b9a\u9700\u6c42\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002\u9700\u8981\u4e00\u79cd\u81ea\u4e3b\u5316\u3001\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "SchedCP \u8bbe\u8ba1\u4e86\u540d\u4e3a Model Context Protocol (MCP) \u7684\u670d\u52a1\u5668\uff0c\u63d0\u4f9b\u4e09\u4e2a\u5173\u952e\u670d\u52a1\uff1a\u5de5\u4f5c\u8d1f\u8f7d\u5206\u6790\u5f15\u64ce\u3001\u52a8\u6001\u6f14\u5316\u7684\u8c03\u5ea6\u7b56\u7565\u5e93\u548c\u6267\u884c\u9a8c\u8bc1\u5668\u3002\u901a\u8fc7\u591a\u4ee3\u7406\u7cfb\u7edf sched-agent \u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u5e76\u751f\u6210\u5b9a\u5236\u7684 eBPF \u8c03\u5ea6\u7b56\u7565\u3002", "result": "SchedCP \u5b9e\u73b0\u4e86\u6700\u9ad8 1.79 \u500d\u7684\u6027\u80fd\u63d0\u5347\u548c 13 \u500d\u7684\u6210\u672c\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6210\u529f\u7387\u3002", "conclusion": "SchedCP \u901a\u8fc7\u6865\u63a5\u8bed\u4e49\u9e3f\u6c9f\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u7ea7\u522b\u7684\u7cfb\u7edf\u4f18\u5316\uff0c\u5e76\u4e3a\u521b\u5efa\u771f\u6b63\u81ea\u9002\u5e94\u7684\u64cd\u4f5c\u7cfb\u7edf\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2509.00286", "pdf": "https://arxiv.org/pdf/2509.00286", "abs": "https://arxiv.org/abs/2509.00286", "authors": ["Rakshitha De Silva", "Shiva Raj Pokhrel", "Jonathan Kua", "Sithamparanathan Kandeepan"], "title": "Intelligent Spectrum Management in Satellite Communications", "categories": ["cs.NI", "cs.AI"], "comment": "30 pages, Under review in IEEE Communications Surveys & Tutorials", "summary": "Satellite Communication (SatCom) networks represent a fundamental pillar in\nmodern global connectivity, facilitating reliable service and extensive\ncoverage across a plethora of applications. The expanding demand for\nhigh-bandwidth services and the proliferation of mega satellite constellations\nhighlight the limitations of traditional exclusive satellite spectrum\nallocation approaches. Cognitive Radio (CR) leading to Cognitive Satellite\n(CogSat) networks through Dynamic Spectrum Management (DSM), which enables the\ndynamic adaptability of radio equipment to environmental conditions for optimal\nperformance, presents a promising solution for the emerging spectrum scarcity.\nIn this survey, we explore the adaptation of intelligent DSM methodologies to\nSatCom, leveraging satellite network integrations. We discuss contributions and\nhurdles in regulations and standardizations in realizing intelligent DSM in\nSatCom, and deep dive into DSM techniques, which enable CogSat networks.\nFurthermore, we extensively evaluate and categorize state-of-the-art Artificial\nIntelligence (AI)/Machine Learning (ML) methods leveraged for DSM while\nexploring operational resilience and robustness of such integrations. In\naddition, performance evaluation metrics critical for adaptive resource\nmanagement and system optimization in CogSat networks are thoroughly\ninvestigated. This survey also identifies open challenges and outlines future\nresearch directions in regulatory frameworks, network architectures, and\nintelligent spectrum management, paving the way for sustainable and scalable\nSatCom networks for enhanced global connectivity.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8ba4\u77e5\u536b\u661f\uff08CogSat\uff09\u7f51\u7edc\u4e2d\u52a8\u6001\u9891\u8c31\u7ba1\u7406\uff08DSM\uff09\u7684\u667a\u80fd\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u536b\u661f\u9891\u8c31\u5206\u914d\u7684\u5c40\u9650\u6027\u3002\u901a\u8fc7AI/ML\u6280\u672f\u4f18\u5316DSM\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6311\u6218\u4e0e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u9ad8\u5e26\u5bbd\u9700\u6c42\u7684\u589e\u957f\u548c\u5927\u578b\u536b\u661f\u661f\u5ea7\u7684\u666e\u53ca\uff0c\u4f20\u7edf\u7684\u9891\u8c31\u5206\u914d\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42\uff0c\u8ba4\u77e5\u65e0\u7ebf\u7535\uff08CR\uff09\u548c\u52a8\u6001\u9891\u8c31\u7ba1\u7406\uff08DSM\uff09\u6210\u4e3a\u89e3\u51b3\u9891\u8c31\u7a00\u7f3a\u95ee\u9898\u7684\u6709\u6548\u9014\u5f84\u3002", "method": "\u672c\u6587\u7efc\u8ff0\u4e86\u667a\u80fdDSM\u65b9\u6cd5\u5728\u536b\u661f\u901a\u4fe1\uff08SatCom\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u7ed3\u5408AI/ML\u6280\u672f\u4f18\u5316\u9891\u8c31\u7ba1\u7406\uff0c\u5e76\u8ba8\u8bba\u4e86\u76f8\u5173\u6cd5\u89c4\u4e0e\u6807\u51c6\u5316\u7684\u6311\u6218\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u667a\u80fdDSM\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347\u536b\u661f\u7f51\u7edc\u7684\u9891\u8c31\u5229\u7528\u7387\u548c\u6027\u80fd\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u6cd5\u89c4\u3001\u7f51\u7edc\u67b6\u6784\u548c\u7cfb\u7edf\u4f18\u5316\u7b49\u65b9\u9762\u7684\u6311\u6218\u3002", "conclusion": "\u8ba4\u77e5\u536b\u661f\u7f51\u7edc\u7ed3\u5408\u667a\u80fdDSM\u6280\u672f\u4e3a\u5168\u7403\u8fde\u63a5\u63d0\u4f9b\u4e86\u53ef\u6301\u7eed\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u6cd5\u89c4\u6846\u67b6\u548c\u6280\u672f\u4f18\u5316\u3002"}}
{"id": "2509.00440", "pdf": "https://arxiv.org/pdf/2509.00440", "abs": "https://arxiv.org/abs/2509.00440", "authors": ["Ibrahim Al-Hazwani", "Ke Er Zhang", "Laura Garrison", "J\u00fcrgen Bernard"], "title": "Data Humanism Decoded: A Characterization of its Principles to Bridge Data Visualization Researchers and Practitioners", "categories": ["cs.HC"], "comment": "5 pages, to be feature in the proceedings of IEEE VIS Short paper\n  track", "summary": "Data Humanism is a human-centered design approach that emphasizes the\npersonal, contextual, and imperfect nature of data. Despite its growing\ninfluence among practitioners, the 13 principles outlined in Giorgia Lupi's\nvisual manifesto remain loosely defined in research contexts, creating a gap\nbetween design practice and systematic application. Through a mixed-methods\napproach, including a systematic literature review, multimedia analysis, and\nexpert interviews, we present a characterization of Data Humanism principles\nfor visualization researchers. Our characterization provides concrete\ndefinitions that maintain interpretive flexibility in operationalizing design\nchoices. We validate our work through direct consultation with Lupi. Moreover,\nwe leverage the characterization to decode a visualization work, mapping Data\nHumanism principles to specific visual design choices. Our work creates a\ncommon language for human-centered visualization, bridging the gap between\npractice and research for future applications and evaluations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff0c\u5b9a\u4e49\u4e86Data Humanism\u768413\u6761\u539f\u5219\uff0c\u4e3a\u53ef\u89c6\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u9a8c\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "Data Humanism\u4f5c\u4e3a\u4e00\u79cd\u4ee5\u4eba\u4e3a\u672c\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u867d\u5728\u8bbe\u8ba1\u5b9e\u8df5\u4e2d\u9010\u6e10\u6d41\u884c\uff0c\u4f46\u5176\u539f\u5219\u5728\u7814\u7a76\u4e2d\u5b9a\u4e49\u6a21\u7cca\uff0c\u5bfc\u81f4\u8bbe\u8ba1\u4e0e\u7cfb\u7edf\u5e94\u7528\u4e4b\u95f4\u5b58\u5728\u9e3f\u6c9f\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u3001\u591a\u5a92\u4f53\u5206\u6790\u548c\u4e13\u5bb6\u8bbf\u8c08\uff0c\u5bf9Data Humanism\u539f\u5219\u8fdb\u884c\u5b9a\u4e49\u548c\u9a8c\u8bc1\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86Data Humanism\u539f\u5219\u7684\u5177\u4f53\u5b9a\u4e49\uff0c\u4fdd\u6301\u4e86\u8bbe\u8ba1\u9009\u62e9\u7684\u64cd\u4f5c\u7075\u6d3b\u6027\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u9a8c\u8bc1\u548c\u5b9e\u9645\u6848\u4f8b\u6620\u5c04\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4ee5\u4eba\u4e3a\u672c\u7684\u53ef\u89c6\u5316\u8bbe\u8ba1\u5efa\u7acb\u4e86\u5171\u540c\u8bed\u8a00\uff0c\u5f25\u5408\u4e86\u5b9e\u8df5\u4e0e\u7814\u7a76\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u672a\u6765\u5e94\u7528\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.01337", "pdf": "https://arxiv.org/pdf/2509.01337", "abs": "https://arxiv.org/abs/2509.01337", "authors": ["Qianrui Zhou", "Hua Xu", "Yifan Wang", "Xinzhi Dong", "Hanlei Zhang"], "title": "LLM-Guided Semantic Relational Reasoning for Multimodal Intent Recognition", "categories": ["cs.MM", "cs.AI", "cs.CL"], "comment": "Accepted by EMNLP 2025 (Main Track, Long Paper)", "summary": "Understanding human intents from multimodal signals is critical for analyzing\nhuman behaviors and enhancing human-machine interactions in real-world\nscenarios. However, existing methods exhibit limitations in their\nmodality-level reliance, constraining relational reasoning over fine-grained\nsemantics for complex intent understanding. This paper proposes a novel\nLLM-Guided Semantic Relational Reasoning (LGSRR) method, which harnesses the\nexpansive knowledge of large language models (LLMs) to establish semantic\nfoundations that boost smaller models' relational reasoning performance.\nSpecifically, an LLM-based strategy is proposed to extract fine-grained\nsemantics as guidance for subsequent reasoning, driven by a shallow-to-deep\nChain-of-Thought (CoT) that autonomously uncovers, describes, and ranks\nsemantic cues by their importance without relying on manually defined priors.\nBesides, we formally model three fundamental types of semantic relations\ngrounded in logical principles and analyze their nuanced interplay to enable\nmore effective relational reasoning. Extensive experiments on multimodal intent\nand dialogue act recognition tasks demonstrate LGSRR's superiority over\nstate-of-the-art methods, with consistent performance gains across diverse\nsemantic understanding scenarios. The complete data and code are available at\nhttps://github.com/thuiar/LGSRR.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdLGSRR\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u5347\u5c0f\u6a21\u578b\u7684\u5173\u7cfb\u63a8\u7406\u80fd\u529b\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u610f\u56fe\u7406\u89e3\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u6001\u4f9d\u8d56\u548c\u7ec6\u7c92\u5ea6\u8bed\u4e49\u63a8\u7406\u4e0a\u7684\u5c40\u9650\uff0c\u63d0\u5347\u590d\u6742\u610f\u56fe\u7406\u89e3\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528LLM\u63d0\u53d6\u7ec6\u7c92\u5ea6\u8bed\u4e49\u4f5c\u4e3a\u6307\u5bfc\uff0c\u901a\u8fc7\u6d45\u5c42\u5230\u6df1\u5c42\u7684Chain-of-Thought\uff08CoT\uff09\u81ea\u52a8\u53d1\u73b0\u548c\u6392\u5e8f\u8bed\u4e49\u7ebf\u7d22\uff0c\u5e76\u5efa\u6a21\u4e09\u79cd\u57fa\u7840\u8bed\u4e49\u5173\u7cfb\u3002", "result": "\u5728\u591a\u6a21\u6001\u610f\u56fe\u548c\u5bf9\u8bdd\u884c\u4e3a\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LGSRR\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bed\u4e49\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u573a\u666f\u3002"}}
{"id": "2509.01999", "pdf": "https://arxiv.org/pdf/2509.01999", "abs": "https://arxiv.org/abs/2509.01999", "authors": ["Junyang Liu", "Weicheng Zhao", "Qingping Wang", "Xiangtian Meng", "Maria Greco", "Fulvio Gini"], "title": "Non-Asymptotic Performance Analysis of DOA Estimation Based on Real-Valued Root-MUSIC", "categories": ["cs.PF"], "comment": null, "summary": "This paper presents a systematic theoretical performance analysis of the\nReal-Valued root-MUSIC (RV-root-MUSIC) algorithm under non-asymptotic\nconditions. However, RV-root-MUSIC suffers from the problem of estimation\nambiguity for the mirror roots, therefore the conventional beamforming (CBF)\ntechnique is typically employed to filter out the mirror roots. Through the\nequivalent subspace based on the conjugate extension method and the equivalence\nof perturbations for both true roots and mirror roots , this paper provides a\ncomprehensive investigation of three critical aspects: noise subspace\nperturbation, true root perturbation, and mirror root perturbation\ncharacteristics in the RV-root-MUSIC algorithm. The statistical model is\nestablished and the generalized expression of perturbation is further\ndeveloped. The simulation results show the correctness and validity of the\nderived statistical characteristics. The results provide a solid theoretical\nfoundation for optimizing the parameter selection of DOA estimation in\npractical applications, particularly in radar systems, communication networks,\nand intelligent sensing technologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9RV-root-MUSIC\u7b97\u6cd5\u5728\u975e\u6e10\u8fd1\u6761\u4ef6\u4e0b\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7406\u8bba\u6027\u80fd\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u955c\u50cf\u6839\u4f30\u8ba1\u6a21\u7cca\u95ee\u9898\uff0c\u5e76\u7ed3\u5408CBF\u6280\u672f\u7814\u7a76\u4e86\u566a\u58f0\u5b50\u7a7a\u95f4\u6270\u52a8\u3001\u771f\u5b9e\u6839\u6270\u52a8\u548c\u955c\u50cf\u6839\u6270\u52a8\u7279\u6027\uff0c\u63d0\u4f9b\u4e86\u53c2\u6570\u4f18\u5316\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "RV-root-MUSIC\u7b97\u6cd5\u5728DOA\u4f30\u8ba1\u4e2d\u5b58\u5728\u955c\u50cf\u6839\u4f30\u8ba1\u6a21\u7cca\u95ee\u9898\uff0c\u9700\u8981\u7406\u8bba\u5206\u6790\u4ee5\u4f18\u5316\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53c2\u6570\u9009\u62e9\uff0c\u7279\u522b\u662f\u5728\u96f7\u8fbe\u548c\u901a\u4fe1\u7cfb\u7edf\u4e2d\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u5171\u8f6d\u6269\u5c55\u65b9\u6cd5\u7684\u7b49\u6548\u5b50\u7a7a\u95f4\u548c\u6270\u52a8\u7b49\u4ef7\u6027\uff0c\u7814\u7a76\u4e86RV-root-MUSIC\u7b97\u6cd5\u4e2d\u7684\u566a\u58f0\u5b50\u7a7a\u95f4\u6270\u52a8\u3001\u771f\u5b9e\u6839\u6270\u52a8\u548c\u955c\u50cf\u6839\u6270\u52a8\u7279\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u5efa\u7acb\u7684\u7edf\u8ba1\u6a21\u578b\u548c\u5e7f\u4e49\u6270\u52a8\u8868\u8fbe\u5f0f\u5177\u6709\u6b63\u786e\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aDOA\u4f30\u8ba1\u7684\u53c2\u6570\u4f18\u5316\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u9002\u7528\u4e8e\u96f7\u8fbe\u3001\u901a\u4fe1\u7f51\u7edc\u548c\u667a\u80fd\u4f20\u611f\u6280\u672f\u7b49\u9886\u57df\u3002"}}
{"id": "2509.00500", "pdf": "https://arxiv.org/pdf/2509.00500", "abs": "https://arxiv.org/abs/2509.00500", "authors": ["Yizhi Chen", "Jingwei Li", "Wenyao Zhu", "Zhonghai Lu"], "title": "Bit Transition Reduction by Data Transmission Ordering in NoC-based DNN Accelerator", "categories": ["cs.AR"], "comment": "Accepted to IEEE SoCC 2025 (38th IEEE International System-on-Chip\n  Conference)", "summary": "As Deep Neural Networks (DNN) are becoming essential, Network-on-Chip\n(NoC)-based DNN accelerators gained increasing popularity. To save link power\nin NoC, many researchers focus on reducing the Bit Transition (BT). We propose\n'1'-bit count-based ordering method to reduce BT for DNN workloads. We provide\na mathematical proof of the efficacy of proposed ordering. We evaluate our\nmethod through experiments without NoC and with NoC. Without NoC, our proposed\nordering method achieves up to 20.38% BT reduction for floating-point-32 data\nand 55.71% for fixed-point-8 data, respectively. We propose two data ordering\nmethods, affiliated-ordering and separated-ordering to process weight and input\njointly or individually and apply them to run full DNNs in NoC-based DNN\naccelerator. We evaluate our approaches under various configurations, including\ndifferent DNN models such as LeNet and DarkNet, various NoC sizes with\ndifferent numbers of memory controllers, random weights and trained weights,\nand different data precision. Our approach efficiently reduces the link power\nby achieving up to 32.01% BT reduction for floating-point-32 data and 40.85% BT\nreduction for fixed-point-8 data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e'1'\u4f4d\u6570\u7edf\u8ba1\u7684\u6392\u5e8f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728NoC-based DNN\u52a0\u901f\u5668\u4e2d\u51cf\u5c11Bit Transition (BT)\uff0c\u4ece\u800c\u964d\u4f4e\u94fe\u8def\u529f\u8017\u3002", "motivation": "\u968f\u7740DNN\u7684\u666e\u53ca\uff0cNoC-based DNN\u52a0\u901f\u5668\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u51cf\u5c11BT\u4ee5\u8282\u7701\u94fe\u8def\u529f\u8017\u6210\u4e3a\u7814\u7a76\u70ed\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6570\u636e\u6392\u5e8f\u65b9\u6cd5\uff08affiliated-ordering\u548cseparated-ordering\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u6570\u5b66\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u4f7f\u7528NoC\u65f6\uff0cBT\u51cf\u5c11\u6700\u9ad8\u8fbe20.38%\uff08FP32\uff09\u548c55.71%\uff08INT8\uff09\uff1b\u5728NoC\u52a0\u901f\u5668\u4e2d\uff0cBT\u51cf\u5c11\u6700\u9ad8\u8fbe32.01%\uff08FP32\uff09\u548c40.85%\uff08INT8\uff09\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6392\u5e8f\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11BT\uff0c\u663e\u8457\u964d\u4f4e\u94fe\u8def\u529f\u8017\uff0c\u9002\u7528\u4e8e\u591a\u79cdDNN\u6a21\u578b\u548c\u914d\u7f6e\u3002"}}
{"id": "2509.00642", "pdf": "https://arxiv.org/pdf/2509.00642", "abs": "https://arxiv.org/abs/2509.00642", "authors": ["Qizheng Yang", "Tung-I Chen", "Siyu Zhao", "Ramesh K. Sitaraman", "Hui Guan"], "title": "HADIS: Hybrid Adaptive Diffusion Model Serving for Efficient Text-to-Image Generation", "categories": ["cs.DC"], "comment": "13 pages, 10 figures", "summary": "Text-to-image diffusion models have achieved remarkable visual quality but\nincur high computational costs, making real-time, scalable deployment\nchallenging. Existing query-aware serving systems mitigate the cost by\ncascading lightweight and heavyweight models, but most rely on a fixed cascade\nconfiguration and route all prompts through an initial lightweight stage,\nwasting resources on complex queries. We present HADIS, a hybrid adaptive\ndiffusion model serving system that jointly optimizes cascade model selection,\nquery routing, and resource allocation. HADIS employs a rule-based prompt\nrouter to send clearly hard queries directly to heavyweight models, bypassing\nthe overhead of the lightweight stage. To reduce the complexity of resource\nmanagement, HADIS uses an offline profiling phase to produce a Pareto-optimal\ncascade configuration table. At runtime, HADIS selects the best cascade\nconfiguration and GPU allocation given latency and workload constraints.\nEmpirical evaluations on real-world traces demonstrate that HADIS improves\nresponse quality by up to 35% while reducing latency violation rates by\n2.7-45$\\times$ compared to state-of-the-art model serving systems.", "AI": {"tldr": "HADIS\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u6269\u6563\u6a21\u578b\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u7ea7\u8054\u6a21\u578b\u9009\u62e9\u3001\u67e5\u8be2\u8def\u7531\u548c\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u867d\u89c6\u89c9\u8d28\u91cf\u9ad8\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u5927\uff0c\u96be\u4ee5\u5b9e\u65f6\u6269\u5c55\u3002\u73b0\u6709\u7cfb\u7edf\u56fa\u5b9a\u7ea7\u8054\u914d\u7f6e\uff0c\u6d6a\u8d39\u8d44\u6e90\u3002", "method": "HADIS\u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u8def\u7531\u5668\u548c\u79bb\u7ebf\u5206\u6790\uff0c\u9009\u62e9\u6700\u4f18\u7ea7\u8054\u914d\u7f6e\u548cGPU\u5206\u914d\u3002", "result": "HADIS\u63d0\u5347\u4e8635%\u54cd\u5e94\u8d28\u91cf\uff0c\u964d\u4f4e\u4e862.7-45\u500d\u7684\u5ef6\u8fdf\u8fdd\u89c4\u7387\u3002", "conclusion": "HADIS\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002"}}
{"id": "2509.01448", "pdf": "https://arxiv.org/pdf/2509.01448", "abs": "https://arxiv.org/abs/2509.01448", "authors": ["Ivan Revenga Riesco", "Borut Lampret", "Connor Myant", "David Boyle"], "title": "5-axis Multi-material Desktop Additive Manufacturing of Conformal Antennas", "categories": ["cs.ET"], "comment": "3 pages, 8 figures, To appear in the Proceedings of the IEEE\n  International Conference on Additively Manufactured Electronic Systems (AMES)\n  2025", "summary": "This paper describes the novel use of low-cost, 5-axis, multi-material\nadditive manufacturing to fabricate functional, complex conformal antennas.\nUsing a customised open source 5-axis desktop printer incorporating conductive\nfilaments, conformal S-band patch and Ultra-Wide Band antennas were fabricated\nand compared against planar-printed counterparts and electromagnetic\nsimulations. Results show the potential of the approach for superior impedance\nmatching, reduced fabrication time, and cost savings; highlighting the\napplicability of multi-axis multi-material prototyping of antennas with complex\ngeometries.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4f4e\u6210\u672c5\u8f74\u591a\u6750\u65993D\u6253\u5370\u6280\u672f\u5236\u9020\u590d\u6742\u5171\u5f62\u5929\u7ebf\u7684\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5229\u7528\u591a\u8f74\u591a\u6750\u65993D\u6253\u5370\u6280\u672f\uff0c\u514b\u670d\u4f20\u7edf\u5929\u7ebf\u5236\u9020\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u963b\u6297\u5339\u914d\u5e76\u964d\u4f4e\u6210\u672c\u3002", "method": "\u4f7f\u7528\u5b9a\u5236\u5316\u5f00\u6e905\u8f74\u684c\u9762\u6253\u5370\u673a\u548c\u5bfc\u7535\u6750\u6599\uff0c\u5236\u9020\u4e86S\u6ce2\u6bb5\u8d34\u7247\u5929\u7ebf\u548c\u8d85\u5bbd\u5e26\u5929\u7ebf\uff0c\u5e76\u4e0e\u5e73\u9762\u6253\u5370\u5929\u7ebf\u53ca\u7535\u78c1\u4eff\u771f\u7ed3\u679c\u5bf9\u6bd4\u3002", "result": "\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u963b\u6297\u5339\u914d\u3001\u5236\u9020\u65f6\u95f4\u548c\u6210\u672c\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u9002\u7528\u4e8e\u590d\u6742\u51e0\u4f55\u5f62\u72b6\u5929\u7ebf\u7684\u5feb\u901f\u539f\u578b\u5236\u4f5c\u3002", "conclusion": "\u591a\u8f74\u591a\u6750\u65993D\u6253\u5370\u6280\u672f\u4e3a\u590d\u6742\u5929\u7ebf\u7684\u5236\u9020\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01758", "pdf": "https://arxiv.org/pdf/2509.01758", "abs": "https://arxiv.org/abs/2509.01758", "authors": ["Juan Pablo Carbonell", "Jos\u00e9 E. Solsona", "Nora Szasz", "\u00c1lvaro Tasistro"], "title": "Derivation and Verification of Array Sorting by Merging, and its Certification in Dafny", "categories": ["cs.LO", "cs.DS"], "comment": null, "summary": "We provide full certifications of two versions of merge sort of arrays in the\nverification-aware programming language Dafny. We start by considering schemas\nfor applying the divide-and-conquer or partition method of solution to\nspecifications given by pre- and post-conditions involving linear arrays. We\nthen derive the merge sort and merging algorithms as instances of these\nschemas, thereby arriving at a fully recursive formulation. Further, the\nanalysis of the tree of subproblems arising from the partition facilitates the\ndesign of loop invariants that allow to derive a fully iterative version\n(sometimes called bottom-up merge sort) that does not employ a stack. We show\nhow the use of the provided schemas conveniently conducts the formalization and\nactual verification in Dafny. The whole method is also applicable to deriving\nvariants of quicksort, which we sketch.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9Dafny\u8bed\u8a00\u4e2d\u7684\u4e24\u79cd\u5f52\u5e76\u6392\u5e8f\u7248\u672c\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5206\u6cbb\u6cd5\u751f\u6210\u5faa\u73af\u4e0d\u53d8\u5f0f\u5e76\u5b9e\u73b0\u8fed\u4ee3\u7248\u672c\u3002", "motivation": "\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u5347\u5f52\u5e76\u6392\u5e8f\u7b97\u6cd5\u7684\u53ef\u9760\u6027\u4e0e\u6b63\u786e\u6027\u3002", "method": "\u4f7f\u7528\u5206\u6cbb\u6cd5\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7Dafny\u8bed\u8a00\u5b9e\u73b0\u9012\u5f52\u548c\u8fed\u4ee3\u7248\u672c\u7684\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86\u9012\u5f52\u548c\u8fed\u4ee3\u7248\u672c\u7684\u5f52\u5e76\u6392\u5e8f\uff0c\u5e76\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u5f52\u5e76\u6392\u5e8f\uff0c\u8fd8\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6392\u5e8f\u7b97\u6cd5\u5982\u5feb\u901f\u6392\u5e8f\u3002"}}
{"id": "2509.00180", "pdf": "https://arxiv.org/pdf/2509.00180", "abs": "https://arxiv.org/abs/2509.00180", "authors": ["Nguyen Phan", "Guoning Chen"], "title": "Evaluate Neighbor Search for Curve-based Vector Field Processing", "categories": ["cs.GR", "cs.CG"], "comment": "12 pages, 17 figures", "summary": "Curve-based representations, particularly integral curves, are often used to\nrepresent large-scale computational fluid dynamic simulations. Processing and\nanalyzing curve-based vector field data sets often involves searching for\nneighboring segments given a query point or curve segment. However, because the\noriginal flow behavior may not be fully represented by the set of integral\ncurves and the input integral curves may not be evenly distributed in space,\npopular neighbor search strategies often return skewed and redundant\nneighboring segments. Yet, there is a lack of systematic and comprehensive\nresearch on how different configurations of neighboring segments returned by\nspecific neighbor search strategies affect subsequent tasks. To fill this gap,\nthis study evaluates the performance of two popular neighbor search strategies\ncombined with different distance metrics on a point-based vector field\nreconstruction task and a segment saliency estimation using input integral\ncurves. A large number of reconstruction tests and saliency calculations are\nconducted for the study. To characterize the configurations of neighboring\nsegments for an effective comparison of different search strategies, a number\nof measures, like average neighbor distance and uniformity, are proposed. Our\nstudy leads to a few observations that partially confirm our expectations about\nthe ideal configurations of a neighborhood while revealing additional findings\nthat were overlooked by the community.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e24\u79cd\u90bb\u8fd1\u641c\u7d22\u7b56\u7565\u5728\u4e0d\u540c\u8ddd\u79bb\u5ea6\u91cf\u4e0b\u7684\u8868\u73b0\uff0c\u7528\u4e8e\u57fa\u4e8e\u70b9\u7684\u5411\u91cf\u573a\u91cd\u5efa\u548c\u6bb5\u663e\u8457\u6027\u4f30\u8ba1\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u8861\u91cf\u6307\u6807\uff0c\u5e76\u63ed\u793a\u4e86\u88ab\u5ffd\u89c6\u7684\u53d1\u73b0\u3002", "motivation": "\u7531\u4e8e\u79ef\u5206\u66f2\u7ebf\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u4ee3\u8868\u539f\u59cb\u6d41\u52a8\u884c\u4e3a\u4e14\u5206\u5e03\u4e0d\u5747\uff0c\u73b0\u6709\u90bb\u8fd1\u641c\u7d22\u7b56\u7565\u5e38\u8fd4\u56de\u504f\u659c\u548c\u5197\u4f59\u7ed3\u679c\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u7ed3\u5408\u4e0d\u540c\u8ddd\u79bb\u5ea6\u91cf\uff0c\u8bc4\u4f30\u4e24\u79cd\u90bb\u8fd1\u641c\u7d22\u7b56\u7565\u5728\u5411\u91cf\u573a\u91cd\u5efa\u548c\u663e\u8457\u6027\u4f30\u8ba1\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u5e73\u5747\u8ddd\u79bb\u548c\u5747\u5300\u6027\u7b49\u8861\u91cf\u6307\u6807\u3002", "result": "\u90e8\u5206\u8bc1\u5b9e\u4e86\u7406\u60f3\u90bb\u8fd1\u914d\u7f6e\u7684\u9884\u671f\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u793e\u533a\u5ffd\u89c6\u7684\u65b0\u53d1\u73b0\u3002", "conclusion": "\u7814\u7a76\u586b\u8865\u4e86\u90bb\u8fd1\u641c\u7d22\u7b56\u7565\u914d\u7f6e\u5f71\u54cd\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u4e3a\u540e\u7eed\u4efb\u52a1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2509.00699", "pdf": "https://arxiv.org/pdf/2509.00699", "abs": "https://arxiv.org/abs/2509.00699", "authors": ["Yumeng He", "Chandrakana Nandi", "Sreepathi Pai"], "title": "Formalizing Linear Motion G-code for Invariant Checking and Differential Testing of Fabrication Tools", "categories": ["cs.PL"], "comment": null, "summary": "The computational fabrication pipeline for 3D printing is much like a\ncompiler - users design models in Computer Aided Design (CAD) tools that are\nlowered to polygon meshes to be ultimately compiled to machine code by 3D\nslicers. For traditional compilers and programming languages, techniques for\nchecking program invariants are well-established. Similarly, methods like\ndifferential testing are often used to uncover bugs in compilers themselves,\nwhich makes them more reliable. The fabrication pipeline would benefit from\nsimilar techniques but traditional approaches do not directly apply to the\nrepresentations used in this domain. Unlike traditional programs, 3D models\nexist both as geometric objects as well as machine code that ultimately runs on\nthe hardware. The machine code, like in traditional compiling, is affected by\nmany factors like the model, the slicer being used, and numerous\nuser-configurable parameters that control the slicing process. In this work, we\npropose a new algorithm for lifting G-code (a common language used in\nfabrication pipelines) by denoting a G-code program to a set of cuboids, and\nthen defining an approximate point cloud representation for efficiently\noperating on these cuboids. Our algorithm opens up new opportunities: we show\nthree use cases that demonstrate how it enables error localization in CAD\nmodels through invariant checking, quantitative comparisons between slicers,\nand evaluating the efficacy of mesh repair tools. We present a prototype\nimplementation of our algorithm in a tool, GlitchFinder, and evaluate it on 58\nreal-world CAD models. Our results show that GlitchFinder is particularly\neffective in identifying slicing issues due to small features, can highlight\ndifferences in how popular slicers (Cura and PrusaSlicer) slice the same model,\nand can identify cases where mesh repair tools (MeshLab and Meshmixer)\nintroduce new errors during repair.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u5c06G\u4ee3\u7801\u8f6c\u6362\u4e3a\u7acb\u65b9\u4f53\u96c6\u5408\u5e76\u5b9a\u4e49\u70b9\u4e91\u8868\u793a\uff0c\u7528\u4e8e3D\u6253\u5370\u4e2d\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u5de5\u5177\u8bc4\u4f30\u3002", "motivation": "\u73b0\u67093D\u6253\u5370\u6d41\u7a0b\u7f3a\u4e4f\u7c7b\u4f3c\u4f20\u7edf\u7f16\u8bd1\u5668\u7684\u7a0b\u5e8f\u4e0d\u53d8\u91cf\u68c0\u67e5\u65b9\u6cd5\uff0c\u4e9f\u9700\u65b0\u5de5\u5177\u63d0\u5347\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u5c06G\u4ee3\u7801\u8f6c\u6362\u4e3a\u7acb\u65b9\u4f53\u96c6\u5408\uff0c\u5e76\u5b9a\u4e49\u8fd1\u4f3c\u70b9\u4e91\u8868\u793a\uff0c\u5b9e\u73b0\u9ad8\u6548\u64cd\u4f5c\u3002", "result": "\u5de5\u5177GlitchFinder\u80fd\u572858\u4e2a\u771f\u5b9eCAD\u6a21\u578b\u4e2d\u6709\u6548\u5b9a\u4f4d\u5c0f\u7279\u5f81\u5f15\u8d77\u7684\u5207\u7247\u95ee\u9898\uff0c\u6bd4\u8f83\u5207\u7247\u5de5\u5177\u5dee\u5f02\u5e76\u68c0\u6d4b\u7f51\u683c\u4fee\u590d\u5de5\u5177\u7684\u9519\u8bef\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a3D\u6253\u5370\u6d41\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u5de5\u5177\u8bc4\u4f30\u624b\u6bb5\u3002"}}
{"id": "2509.00397", "pdf": "https://arxiv.org/pdf/2509.00397", "abs": "https://arxiv.org/abs/2509.00397", "authors": ["Murayyiam Parvez", "Annus Zulfiqar", "Roman Beltiukov", "Shir Landau Feibish", "Walter Willinger", "Arpit Gupta", "Muhammad Shahbaz"], "title": "SpliDT: Partitioned Decision Trees for Scalable Stateful Inference at Line Rate", "categories": ["cs.NI"], "comment": "12 pages", "summary": "Machine learning (ML) is increasingly being deployed in programmable data\nplanes (switches and SmartNICs) to enable real-time traffic analysis, security\nmonitoring, and in-network decision-making. Decision trees (DTs) are\nparticularly well-suited for these tasks due to their interpretability and\ncompatibility with data-plane architectures, i.e., match-action tables (MATs).\nHowever, existing in-network DT implementations are constrained by the need to\ncompute all input features upfront, forcing models to rely on a small, fixed\nset of features per flow. This significantly limits model accuracy and\nscalability under stringent hardware resource constraints.\n  We present SPLIDT, a system that rethinks DT deployment in the data plane by\nenabling partitioned inference over sliding windows of packets. SPLIDT\nintroduces two key innovations: (1) it assigns distinct, variable feature sets\nto individual sub-trees of a DT, grouped into partitions, and (2) it leverages\nan in-band control channel (via recirculation) to reuse data-plane resources\n(both stateful registers and match keys) across partitions at line rate. These\ninsights allow SPLIDT to scale the number of stateful features a model can use\nwithout exceeding hardware limits. To support this architecture, SPLIDT\nincorporates a custom training and design-space exploration (DSE) framework\nthat jointly optimizes feature allocation, tree partitioning, and DT model\ndepth. Evaluation across multiple real-world datasets shows that SPLIDT\nachieves higher accuracy while supporting up to 5x more stateful features than\nprior approaches (e.g., NetBeacon and Leo). It maintains the same low\ntime-to-detection (TTD) as these systems, while scaling to millions of flows\nwith minimal recirculation overhead (<0.05%).", "AI": {"tldr": "SLPIDT\u662f\u4e00\u79cd\u5728\u6570\u636e\u5e73\u9762\u4e2d\u5b9e\u73b0\u5206\u533a\u63a8\u65ad\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u548c\u5206\u533a\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u51b3\u7b56\u6811\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u5e73\u9762\u4e2d\u7684\u51b3\u7b56\u6811\u5b9e\u73b0\u7531\u4e8e\u9700\u8981\u9884\u5148\u8ba1\u7b97\u6240\u6709\u8f93\u5165\u7279\u5f81\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6269\u5c55\u6027\u3002", "method": "SPLIDT\u91c7\u7528\u5206\u533a\u63a8\u65ad\u548c\u6ed1\u52a8\u7a97\u53e3\u6280\u672f\uff0c\u7ed3\u5408\u81ea\u5b9a\u4e49\u8bad\u7ec3\u548c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u6846\u67b6\uff0c\u4f18\u5316\u7279\u5f81\u5206\u914d\u548c\u6811\u5206\u533a\u3002", "result": "SPLIDT\u5728\u591a\u4e2a\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u66f4\u9ad8\u51c6\u786e\u6027\uff0c\u652f\u6301\u591a\u8fbe5\u500d\u7684\u72b6\u6001\u7279\u5f81\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u68c0\u6d4b\u65f6\u95f4\u3002", "conclusion": "SPLIDT\u901a\u8fc7\u521b\u65b0\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u51b3\u7b56\u6811\u5728\u6570\u636e\u5e73\u9762\u4e2d\u7684\u6027\u80fd\u548c\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2509.00572", "pdf": "https://arxiv.org/pdf/2509.00572", "abs": "https://arxiv.org/abs/2509.00572", "authors": ["Filip J. Kucia", "Bartosz Grabek", "Szymon D. Trochimiak", "Anna Wr\u00f3blewska"], "title": "How to Make Museums More Interactive? Case Study of Artistic Chatbot", "categories": ["cs.HC", "cs.IR"], "comment": "7 pages, 3 figures", "summary": "Conversational agents powered by Large Language Models (LLMs) are\nincreasingly utilized in educational settings, in particular in individual\nclosed digital environments, yet their potential adoption in the physical\nlearning environments like cultural heritage sites, museums, and art galleries\nremains relatively unexplored. In this study, we present Artistic Chatbot, a\nvoice-to-voice RAG-powered chat system to support informal learning and enhance\nvisitor engagement during a live art exhibition celebrating the 15th\nanniversary of the Faculty of Media Art at the Warsaw Academy of Fine Arts,\nPoland. The question answering (QA) chatbot responded to free-form spoken\nquestions in Polish using the context retrieved from a curated, domain-specific\nknowledge base consisting of 226 documents provided by the organizers,\nincluding faculty information, art magazines, books, and journals. We describe\nthe key aspects of the system architecture and user interaction design, as well\nas discuss the practical challenges associated with deploying chatbots at\npublic cultural sites. Our findings, based on interaction analysis, demonstrate\nthat chatbots such as Artistic Chatbot effectively maintain responses grounded\nin exhibition content (60\\% of responses directly relevant), even when faced\nwith unpredictable queries outside the target domain, showing their potential\nfor increasing interactivity in public cultural sites.\n  GitHub project page: https://github.com/cinekucia/artistic-chatbot-cikm2025", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aArtistic Chatbot\u7684\u58f0\u97f3\u4ea4\u4e92\u804a\u5929\u673a\u5668\u4eba\uff0c\u7528\u4e8e\u5728\u827a\u672f\u5c55\u89c8\u4e2d\u652f\u6301\u975e\u6b63\u5f0f\u5b66\u4e60\uff0c\u589e\u5f3a\u53c2\u89c2\u8005\u4e92\u52a8\uff0c\u5e76\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5b9e\u4f53\u6587\u5316\u573a\u6240\uff08\u5982\u827a\u672f\u5c55\u89c8\uff09\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u63d0\u5347\u53c2\u89c2\u8005\u7684\u4e92\u52a8\u4f53\u9a8c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eRAG\u6280\u672f\u7684\u8bed\u97f3\u95ee\u7b54\u804a\u5929\u673a\u5668\u4eba\uff0c\u4f7f\u7528\u7b56\u5c55\u4eba\u63d0\u4f9b\u7684226\u4efd\u9886\u57df\u77e5\u8bc6\u6587\u6863\u4f5c\u4e3a\u77e5\u8bc6\u5e93\u3002", "result": "\u804a\u5929\u673a\u5668\u4eba\u5728\u9762\u5bf9\u4e0d\u53ef\u9884\u6d4b\u7684\u67e5\u8be2\u65f6\uff0c60%\u7684\u56de\u7b54\u76f4\u63a5\u76f8\u5173\uff0c\u663e\u793a\u51fa\u5176\u5728\u6587\u5316\u573a\u6240\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "Artistic Chatbot\u5c55\u793a\u4e86\u5728\u516c\u5171\u6587\u5316\u573a\u6240\u4e2d\u589e\u52a0\u4e92\u52a8\u6027\u7684\u6f5c\u529b\uff0c\u4f46\u4e5f\u6307\u51fa\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2509.02232", "pdf": "https://arxiv.org/pdf/2509.02232", "abs": "https://arxiv.org/abs/2509.02232", "authors": ["Liang Xie", "Yanting Li", "Luyang Tang", "Wei Gao"], "title": "Efficient Geometry Compression and Communication for 3D Gaussian Splatting Point Clouds", "categories": ["cs.MM"], "comment": "8 pages,5 figures", "summary": "Storage and transmission challenges in dynamic 3D scene representation based\non the i3DV platform, With increasing scene complexity, the explosive growth of\n3D Gaussian data volume causes excessive storage space occupancy. To address\nthis issue, we propose adopting the AVS PCRM reference software for efficient\ncompression of Gaussian point cloud geometry data. The strategy deeply\nintegrates the advanced encoding capabilities of AVS PCRM into the i3DV\nplatform, forming technical complementarity with the original rate-distortion\noptimization mechanism based on binary hash tables. On one hand, the hash table\nefficiently caches inter-frame Gaussian point transformation relationships,\nwhich allows for high-fidelity transmission within a 40 Mbps bandwidth\nconstraint. On the other hand, AVS PCRM performs precise compression on\ngeometry data. Experimental results demonstrate that the joint framework\nmaintains the advantages of fast rendering and high-quality synthesis in 3D\nGaussian technology while achieving significant 10\\%-25\\% bitrate savings on\nuniversal test sets. It provides a superior rate-distortion tradeoff solution\nfor the storage, transmission, and interaction of 3D volumetric video.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408AVS PCRM\u548ci3DV\u5e73\u53f0\u7684\u52a8\u60013D\u573a\u666f\u538b\u7f29\u65b9\u6848\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u5b58\u50a8\u548c\u4f20\u8f93\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u6e32\u67d3\u6548\u679c\u3002", "motivation": "\u968f\u77403D\u9ad8\u65af\u6570\u636e\u91cf\u7684\u7206\u70b8\u5f0f\u589e\u957f\uff0c\u5b58\u50a8\u548c\u4f20\u8f93\u6210\u4e3a\u52a8\u60013D\u573a\u666f\u8868\u793a\u7684\u4e3b\u8981\u6311\u6218\u3002", "method": "\u91c7\u7528AVS PCRM\u8f6f\u4ef6\u5bf9\u9ad8\u65af\u70b9\u4e91\u51e0\u4f55\u6570\u636e\u8fdb\u884c\u9ad8\u6548\u538b\u7f29\uff0c\u5e76\u7ed3\u5408i3DV\u5e73\u53f0\u7684\u54c8\u5e0c\u8868\u673a\u5236\u4f18\u5316\u7387\u5931\u771f\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u8054\u5408\u6846\u67b6\u572840 Mbps\u5e26\u5bbd\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u4fdd\u771f\u4f20\u8f93\uff0c\u5e76\u8282\u770110%-25%\u7684\u6bd4\u7279\u7387\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a3D\u89c6\u9891\u7684\u5b58\u50a8\u3001\u4f20\u8f93\u548c\u4ea4\u4e92\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u7387\u5931\u771f\u6743\u8861\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00045", "pdf": "https://arxiv.org/pdf/2509.00045", "abs": "https://arxiv.org/abs/2509.00045", "authors": ["Xiang Li", "Chong Zhang", "Hongpeng Wang", "Shreyank Narayana Gowda", "Yushi Li", "Xiaobo Jin"], "title": "Performance is not All You Need: Sustainability Considerations for Algorithms", "categories": ["cs.CV", "cs.PF"], "comment": "18 pages, 6 figures. Accepted Chinese Conference on Pattern\n  Recognition and Computer Vision 2025", "summary": "This work focuses on the high carbon emissions generated by deep learning\nmodel training, specifically addressing the core challenge of balancing\nalgorithm performance and energy consumption. It proposes an innovative\ntwo-dimensional sustainability evaluation system. Different from the\ntraditional single performance-oriented evaluation paradigm, this study\npioneered two quantitative indicators that integrate energy efficiency ratio\nand accuracy: the sustainable harmonic mean (FMS) integrates accumulated energy\nconsumption and performance parameters through the harmonic mean to reveal the\nalgorithm performance under unit energy consumption; the area under the\nsustainability curve (ASC) constructs a performance-power consumption curve to\ncharacterize the energy efficiency characteristics of the algorithm throughout\nthe cycle. To verify the universality of the indicator system, the study\nconstructed benchmarks in various multimodal tasks, including image\nclassification, segmentation, pose estimation, and batch and online learning.\nExperiments demonstrate that the system can provide a quantitative basis for\nevaluating cross-task algorithms and promote the transition of green AI\nresearch from theory to practice. Our sustainability evaluation framework code\ncan be found here, providing methodological support for the industry to\nestablish algorithm energy efficiency standards.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u4e8c\u7ef4\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u7cfb\u7edf\uff0c\u7528\u4e8e\u5e73\u8861\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u7684\u6027\u80fd\u4e0e\u80fd\u8017\uff0c\u5e76\u5f15\u5165\u4e86FMS\u548cASC\u4e24\u4e2a\u91cf\u5316\u6307\u6807\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u4ea7\u751f\u7684\u9ad8\u78b3\u6392\u653e\u95ee\u9898\uff0c\u5e73\u8861\u7b97\u6cd5\u6027\u80fd\u4e0e\u80fd\u6e90\u6d88\u8017\u3002", "method": "\u63d0\u51fa\u53ef\u6301\u7eed\u6027\u8c10\u6ce2\u5747\u503c\uff08FMS\uff09\u548c\u53ef\u6301\u7eed\u6027\u66f2\u7ebf\u4e0b\u9762\u79ef\uff08ASC\uff09\u4e24\u4e2a\u6307\u6807\uff0c\u6784\u5efa\u591a\u6a21\u6001\u4efb\u52a1\u57fa\u51c6\u9a8c\u8bc1\u5176\u666e\u9002\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7cfb\u7edf\u53ef\u4e3a\u8de8\u4efb\u52a1\u7b97\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u91cf\u5316\u4f9d\u636e\uff0c\u63a8\u52a8\u7eff\u8272AI\u7814\u7a76\u4ece\u7406\u8bba\u8f6c\u5411\u5b9e\u8df5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u884c\u4e1a\u5efa\u7acb\u7b97\u6cd5\u80fd\u6548\u6807\u51c6\u63d0\u4f9b\u4e86\u65b9\u6cd5\u652f\u6301\u3002"}}
{"id": "2509.00589", "pdf": "https://arxiv.org/pdf/2509.00589", "abs": "https://arxiv.org/abs/2509.00589", "authors": ["Shafayet M. Anik", "D. G. Perera"], "title": "Real-Time Piano Note Frequency Detection Using FPGA and FFT Core", "categories": ["cs.AR", "cs.SD", "eess.AS"], "comment": "20 pages, 11 Figures", "summary": "Real-time frequency analysis of musical instruments, such as the piano, is an\nessential feature in areas like electronic tuners, music visualizers, and live\nsound monitoring. Traditional methods often rely on software-based digital\nsignal processing (DSP), which may introduce latency and require significant\ncomputational power. In contrast, hardware platforms such as FPGAs (Field\nProgrammable Gate Arrays) offer the ability to perform such analyses with\ngreater speed and determinism due to their parallel processing capabilities.\nThe primary objective of this project was to analyze analog audio signals from\na digital piano using an FPGA-based real-time Fast Fourier Transform (FFT)\nsystem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8eFPGA\u7684\u5b9e\u65f6FFT\u7cfb\u7edf\u7528\u4e8e\u94a2\u7434\u97f3\u9891\u4fe1\u53f7\u7684\u9891\u7387\u5206\u6790\uff0c\u5f3a\u8c03\u5176\u5728\u901f\u5ea6\u548c\u786e\u5b9a\u6027\u4e0a\u7684\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6DSP\u65b9\u6cd5\u5b58\u5728\u5ef6\u8fdf\u548c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\u7684\u95ee\u9898\uff0c\u800cFPGA\u56e0\u5176\u5e76\u884c\u5904\u7406\u80fd\u529b\u53ef\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eFPGA\u7684\u5b9e\u65f6FFT\u7cfb\u7edf\u5bf9\u6570\u5b57\u94a2\u7434\u7684\u6a21\u62df\u97f3\u9891\u4fe1\u53f7\u8fdb\u884c\u9891\u7387\u5206\u6790\u3002", "result": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u6697\u793aFPGA\u5728\u5b9e\u65f6\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "FPGA\u5e73\u53f0\u4e3a\u5b9e\u65f6\u97f3\u9891\u9891\u7387\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u5ef6\u8fdf\u7684\u9009\u62e9\u3002"}}
{"id": "2509.00883", "pdf": "https://arxiv.org/pdf/2509.00883", "abs": "https://arxiv.org/abs/2509.00883", "authors": ["Denis Los", "Igor Petushkov"], "title": "Accelerating Latency-Critical Applications with AI-Powered Semi-Automatic Fine-Grained Parallelization on SMT Processors", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Latency-critical applications tend to show low utilization of functional\nunits due to frequent cache misses and mispredictions during speculative\nexecution in high-performance superscalar processors. However, due to\nsignificant impact on single-thread performance, Simultaneous Multithreading\n(SMT) technology is rarely used with heavy threads of latency-critical\napplications. In this paper, we explore utilization of SMT technology to\nsupport fine-grained parallelization of latency-critical applications.\nFollowing the advancements in the development of Large Language Models (LLMs),\nwe introduce Aira, an AI-powered Parallelization Adviser. To implement Aira, we\nextend AI Coding Agent in Cursor IDE with additional tools connected through\nModel Context Protocol, enabling end-to-end AI Agent for parallelization.\nAdditional connected tools enable LLM-guided hotspot detection, collection of\ndynamic dependencies with Dynamic Binary Instrumentation, SMT-aware performance\nsimulation to estimate performance gains. We apply Aira with Relic parallel\nframework for fine-grained task parallelism on SMT cores to parallelize\nlatency-critical benchmarks representing real-world applications used in\nindustry. We show 17% geomean performance gain from parallelization of\nlatency-critical benchmarks using Aira with Relic framework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAira\uff0c\u4e00\u4e2aAI\u9a71\u52a8\u7684\u5e76\u884c\u5316\u987e\u95ee\uff0c\u7528\u4e8e\u5728SMT\u6838\u5fc3\u4e0a\u4f18\u5316\u5ef6\u8fdf\u5173\u952e\u5e94\u7528\u7684\u7ec6\u7c92\u5ea6\u5e76\u884c\u5316\uff0c\u5b9e\u73b017%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5ef6\u8fdf\u5173\u952e\u5e94\u7528\u5728\u9ad8\u6027\u80fd\u8d85\u6807\u91cf\u5904\u7406\u5668\u4e2d\u7531\u4e8e\u7f13\u5b58\u672a\u547d\u4e2d\u548c\u9884\u6d4b\u9519\u8bef\u5bfc\u81f4\u529f\u80fd\u5355\u5143\u5229\u7528\u7387\u4f4e\uff0c\u800cSMT\u6280\u672f\u5f88\u5c11\u7528\u4e8e\u6b64\u7c7b\u5e94\u7528\u7684\u7c97\u7c92\u5ea6\u7ebf\u7a0b\u3002", "method": "\u901a\u8fc7\u6269\u5c55Cursor IDE\u4e2d\u7684AI\u7f16\u7801\u4ee3\u7406\uff0c\u7ed3\u5408\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff0c\u5f00\u53d1\u4e86Aira\u3002Aira\u5177\u5907LLM\u6307\u5bfc\u7684\u70ed\u70b9\u68c0\u6d4b\u3001\u52a8\u6001\u4f9d\u8d56\u6536\u96c6\u548cSMT\u611f\u77e5\u6027\u80fd\u6a21\u62df\u529f\u80fd\uff0c\u5e76\u91c7\u7528Relic\u6846\u67b6\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4efb\u52a1\u5e76\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAira\u7ed3\u5408Relic\u6846\u67b6\u5728\u5ef6\u8fdf\u5173\u952e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e8617%\u7684\u51e0\u4f55\u5e73\u5747\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "Aira\u5c55\u793a\u4e86AI\u6280\u672f\u5728\u4f18\u5316SMT\u6838\u5fc3\u4e0a\u5ef6\u8fdf\u5173\u952e\u5e94\u7528\u5e76\u884c\u5316\u7684\u6f5c\u529b\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2509.00747", "pdf": "https://arxiv.org/pdf/2509.00747", "abs": "https://arxiv.org/abs/2509.00747", "authors": ["Francesco Caravelli", "Gianluca Milano", "Adam Z. Stieg", "Carlo Ricciardi", "Simon Anthony Brown", "Zdenka Kuncic"], "title": "Self-Organising Memristive Networks as Physical Learning Systems", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall", "cond-mat.soft", "cs.ET", "cs.LG"], "comment": "Perspective paper on SOMN; 20 pages double columns, 5 figures, 2\n  boxes;", "summary": "Learning with physical systems is an emerging paradigm that seeks to harness\nthe intrinsic nonlinear dynamics of physical substrates for learning. The\nimpetus for a paradigm shift in how hardware is used for computational\nintelligence stems largely from the unsustainability of artificial neural\nnetwork software implemented on conventional transistor-based hardware. This\nPerspective highlights one promising approach using physical networks comprised\nof resistive memory nanoscale components with dynamically reconfigurable,\nself-organising electrical circuitry. Experimental advances have revealed the\nnon-trivial interactions within these Self-Organising Memristive Networks\n(SOMNs), offering insights into their collective nonlinear and adaptive\ndynamics, and how these properties can be harnessed for learning using\ndifferent hardware implementations. Theoretical approaches, including\nmean-field theory, graph theory, and concepts from disordered systems, reveal\ndeeper insights into the dynamics of SOMNs, especially during transitions\nbetween different conductance states where criticality and other dynamical\nphase transitions emerge in both experiments and models. Furthermore, parallels\nbetween adaptive dynamics in SOMNs and plasticity in biological neuronal\nnetworks suggest the potential for realising energy-efficient, brain-like\ncontinual learning. SOMNs thus offer a promising route toward embedded edge\nintelligence, unlocking real-time decision-making for autonomous systems,\ndynamic sensing, and personalised healthcare, by enabling embedded learning in\nresource-constrained environments. The overarching aim of this Perspective is\nto show how the convergence of nanotechnology, statistical physics, complex\nsystems, and self-organising principles offers a unique opportunity to advance\na new generation of physical intelligence technologies.", "AI": {"tldr": "\u5229\u7528\u7269\u7406\u7cfb\u7edf\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u8fdb\u884c\u5b66\u4e60\u7684\u65b0\u8303\u5f0f\uff0c\u91cd\u70b9\u5173\u6ce8\u81ea\u7ec4\u7ec7\u5fc6\u963b\u7f51\u7edc\uff08SOMNs\uff09\u5728\u5b9e\u73b0\u9ad8\u6548\u3001\u7c7b\u8111\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6676\u4f53\u7ba1\u7684\u786c\u4ef6\u5728\u4eba\u5de5\u667a\u80fd\u8ba1\u7b97\u4e2d\u7684\u4e0d\u53ef\u6301\u7eed\u6027\u4fc3\u4f7f\u8f6c\u5411\u7269\u7406\u786c\u4ef6\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u548c\u7406\u8bba\u65b9\u6cd5\uff08\u5982\u5e73\u5747\u573a\u7406\u8bba\u3001\u56fe\u8bba\u7b49\uff09\u7814\u7a76\u81ea\u7ec4\u7ec7\u5fc6\u963b\u7f51\u7edc\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u53ca\u5176\u5b66\u4e60\u80fd\u529b\u3002", "result": "SOMNs\u5c55\u73b0\u51fa\u96c6\u4f53\u975e\u7ebf\u6027\u3001\u81ea\u9002\u5e94\u52a8\u529b\u5b66\uff0c\u5e76\u80fd\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u5d4c\u5165\u5f0f\u5b66\u4e60\u548c\u5b9e\u65f6\u51b3\u7b56\u3002", "conclusion": "SOMNs\u4e3a\u65b0\u578b\u7269\u7406\u667a\u80fd\u6280\u672f\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u72ec\u7279\u673a\u4f1a\uff0c\u5c24\u5176\u5728\u5d4c\u5165\u5f0f\u8fb9\u7f18\u667a\u80fd\u9886\u57df\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.00173", "pdf": "https://arxiv.org/pdf/2509.00173", "abs": "https://arxiv.org/abs/2509.00173", "authors": ["Shahiduz Zaman", "Tanzima Hashem", "Sukarna Barua"], "title": "Efficient Computation of Trip-based Group Nearest Neighbor Queries (Full Version)", "categories": ["cs.DB"], "comment": null, "summary": "In recent years, organizing group meetups for entertainment or other\nnecessities has gained significant importance, especially given the busy nature\nof daily schedules. People often combine multiple activities, such as dropping\nkids off at school, commuting to work, and grocery shopping, while seeking\nopportunities to meet others. To address this need, we propose a novel query\ntype, the Trip-based Group Nearest Neighbor (T-GNN) query, which identifies the\noptimal meetup Point of Interest (POI) that aligns with users' existing trips.\nAn individual trip consists of a sequence of locations, allowing users the\nflexibility to detour to the meetup POI at any location within the sequence,\nknown as a detour location. Given a set of trips for the users, the query\nidentifies the optimal meetup POI (e.g., restaurants or movie theaters) and\ndetour locations from each user's trip that minimize the total trip overhead\ndistance. The trip overhead distance refers to the additional distance a user\nmust travel to visit the meetup POI before returning to the next location in\ntheir trip. The sum of these overhead distances for all users constitutes the\ntotal trip overhead distance. The computation time for processing T-GNN queries\nincreases with the number of POIs. To address this, we introduce three\ntechniques to prune the POIs that cannot contribute to the optimal solution,\nand thus refine the search space. We also develop an efficient approach for\nprocessing T-GNN queries in real-time. Extensive experiments validate the\nperformance of the proposed algorithm.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u67e5\u8be2\u65b9\u6cd5T-GNN\uff0c\u7528\u4e8e\u5728\u7528\u6237\u73b0\u6709\u884c\u7a0b\u4e2d\u627e\u5230\u6700\u4f73\u96c6\u5408\u70b9POI\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u603b\u884c\u7a0b\u989d\u5916\u8ddd\u79bb\u6765\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u4e3a\u6ee1\u8db3\u4eba\u4eec\u5728\u7e41\u5fd9\u65e5\u7a0b\u4e2d\u9ad8\u6548\u7ec4\u7ec7\u56e2\u4f53\u6d3b\u52a8\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86T-GNN\u67e5\u8be2\uff0c\u7ed3\u5408\u4e09\u79cd\u526a\u679d\u6280\u672f\u548c\u5b9e\u65f6\u5904\u7406\u7b97\u6cd5\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "T-GNN\u67e5\u8be2\u6709\u6548\u51cf\u5c11\u4e86\u603b\u884c\u7a0b\u989d\u5916\u8ddd\u79bb\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u573a\u666f\u3002"}}
{"id": "2509.02495", "pdf": "https://arxiv.org/pdf/2509.02495", "abs": "https://arxiv.org/abs/2509.02495", "authors": ["Krzysztof Mierzewski"], "title": "Probabilistically stable revision and comparative probability: a representation theorem and applications", "categories": ["cs.LO", "cs.AI", "econ.TH", "math.PR", "03B42, 03B48, 03B70, 60A05, 68T27, 91B12"], "comment": null, "summary": "The stability rule for belief, advocated by Leitgeb [Annals of Pure and\nApplied Logic 164, 2013], is a rule for rational acceptance that captures\ncategorical belief in terms of $\\textit{probabilistically stable\npropositions}$: propositions to which the agent assigns resiliently high\ncredence. The stability rule generates a class of $\\textit{probabilistically\nstable belief revision}$ operators, which capture the dynamics of belief that\nresult from an agent updating their credences through Bayesian conditioning\nwhile complying with the stability rule for their all-or-nothing beliefs. In\nthis paper, we prove a representation theorem that yields a complete\ncharacterisation of such probabilistically stable revision operators and\nprovides a `qualitative' selection function semantics for the (non-monotonic)\nlogic of probabilistically stable belief revision. Drawing on the theory of\ncomparative probability orders, this result gives necessary and sufficient\nconditions for a selection function to be representable as a\nstrongest-stable-set operator on a finite probability space. The resulting\nlogic of probabilistically stable belief revision exhibits strong monotonicity\nproperties while failing the AGM belief revision postulates and satisfying only\nvery weak forms of case reasoning. In showing the main theorem, we prove two\nresults of independent interest to the theory of comparative probability: the\nfirst provides necessary and sufficient conditions for the joint representation\nof a pair of (respectively, strict and non-strict) comparative probability\norders. The second result provides a method for axiomatising the logic of ratio\ncomparisons of the form ``event $A$ is at least $k$ times more likely than\nevent $B$''. In addition to these measurement-theoretic applications, we point\nout two applications of our main result to the theory of simple voting games\nand to revealed preference theory.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u4fe1\u5ff5\u7a33\u5b9a\u6027\u7684\u89c4\u5219\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u7a33\u5b9a\u7684\u547d\u9898\u6765\u63cf\u8ff0\u7406\u6027\u7684\u4fe1\u5ff5\u63a5\u53d7\uff0c\u8bc1\u660e\u4e86\u8868\u793a\u5b9a\u7406\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u975e\u5355\u8c03\u903b\u8f91\u548c\u6bd4\u8f83\u6982\u7387\u7406\u8bba\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u901a\u8fc7\u6982\u7387\u7a33\u5b9a\u7684\u547d\u9898\u548c\u4fe1\u5ff5\u4fee\u8ba2\u64cd\u4f5c\u7b26\uff0c\u6355\u6349\u4fe1\u5ff5\u7684\u52a8\u6001\u53d8\u5316\uff0c\u540c\u65f6\u63d0\u4f9b\u4e00\u4e2a\u5b8c\u6574\u7684\u8868\u793a\u5b9a\u7406\u6765\u5b9a\u6027\u63cf\u8ff0\u6b64\u7c7b\u64cd\u4f5c\u7b26\u3002", "method": "\u901a\u8fc7\u6982\u7387\u7a33\u5b9a\u7684\u547d\u9898\u548c\u8d1d\u53f6\u65af\u6761\u4ef6\u66f4\u65b0\uff0c\u7ed3\u5408\u6bd4\u8f83\u6982\u7387\u7406\u8bba\uff0c\u63d0\u51fa\u5e76\u8bc1\u660e\u4e86\u8868\u793a\u5b9a\u7406\uff0c\u5e76\u63d0\u4f9b\u4e86\u9009\u62e9\u51fd\u6570\u8bed\u4e49\u3002", "result": "\u8bc1\u660e\u4e86\u8868\u793a\u5b9a\u7406\uff0c\u5b8c\u6574\u63cf\u8ff0\u4e86\u6982\u7387\u7a33\u5b9a\u7684\u4fe1\u5ff5\u4fee\u8ba2\u64cd\u4f5c\u7b26\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u975e\u5355\u8c03\u903b\u8f91\u4e2d\u7684\u5f3a\u5355\u8c03\u6027\u7279\u6027\uff0c\u4f46\u672a\u80fd\u6ee1\u8db3AGM\u4fe1\u5ff5\u4fee\u8ba2\u516c\u8bbe\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6982\u7387\u7a33\u5b9a\u7684\u4fe1\u5ff5\u4fee\u8ba2\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u5728\u6bd4\u8f83\u6982\u7387\u7406\u8bba\u3001\u7b80\u5355\u6295\u7968\u6e38\u620f\u548c\u504f\u597d\u7406\u8bba\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2509.00269", "pdf": "https://arxiv.org/pdf/2509.00269", "abs": "https://arxiv.org/abs/2509.00269", "authors": ["Maria Parelli", "Michael Oechsle", "Michael Niemeyer", "Federico Tombari", "Andreas Geiger"], "title": "3D-LATTE: Latent Space 3D Editing from Textual Instructions", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Despite the recent success of multi-view diffusion models for\ntext/image-based 3D asset generation, instruction-based editing of 3D assets\nlacks surprisingly far behind the quality of generation models. The main reason\nis that recent approaches using 2D priors suffer from view-inconsistent editing\nsignals. Going beyond 2D prior distillation methods and multi-view editing\nstrategies, we propose a training-free editing method that operates within the\nlatent space of a native 3D diffusion model, allowing us to directly manipulate\n3D geometry. We guide the edit synthesis by blending 3D attention maps from the\ngeneration with the source object. Coupled with geometry-aware regularization\nguidance, a spectral modulation strategy in the Fourier domain and a refinement\nstep for 3D enhancement, our method outperforms previous 3D editing methods\nenabling high-fidelity, precise, and robust edits across a wide range of shapes\nand semantic manipulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u751f3D\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u514d\u8d39\u7f16\u8f91\u65b9\u6cd5\uff0c\u901a\u8fc73D\u6ce8\u610f\u529b\u56fe\u548c\u51e0\u4f55\u611f\u77e5\u6b63\u5219\u5316\u7b49\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u76843D\u8d44\u4ea7\u7f16\u8f91\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e2D\u5148\u9a8c\u76843D\u8d44\u4ea7\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u89c6\u89d2\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7f16\u8f91\u8d28\u91cf\u8f83\u4f4e\u3002", "method": "\u5728\u539f\u751f3D\u6269\u6563\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u901a\u8fc73D\u6ce8\u610f\u529b\u56fe\u6df7\u5408\u3001\u51e0\u4f55\u611f\u77e5\u6b63\u5219\u5316\u3001\u5085\u91cc\u53f6\u57df\u8c31\u8c03\u5236\u548c3D\u589e\u5f3a\u7ec6\u5316\u6b65\u9aa4\u5b9e\u73b0\u7f16\u8f91\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u79cd\u5f62\u72b6\u548c\u8bed\u4e49\u64cd\u4f5c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u67093D\u7f16\u8f91\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u3001\u7cbe\u786e\u4e14\u9c81\u68d2\u76843D\u7f16\u8f91\uff0c\u89e3\u51b3\u4e86\u89c6\u89d2\u4e0d\u4e00\u81f4\u95ee\u9898\u3002"}}
{"id": "2509.00948", "pdf": "https://arxiv.org/pdf/2509.00948", "abs": "https://arxiv.org/abs/2509.00948", "authors": ["Denghang Hu", "Taolue Chen", "Philipp R\u00fcmmer", "Fu Song", "Zhilin Wu"], "title": "Decision Procedure for A Theory of String Sequences", "categories": ["cs.PL", "cs.FL"], "comment": "21 pages, 2 tables, APLAS 2025", "summary": "The theory of sequences, supported by many SMT solvers, can model program\ndata types including bounded arrays and lists. Sequences are parameterized by\nthe element data type and provide operations such as accessing elements,\nconcatenation, forming sub-sequences and updating elements. Strings and\nsequences are intimately related; many operations, e.g., matching a string\naccording to a regular expression, splitting strings, or joining strings in a\nsequence, are frequently used in string-manipulating programs. Nevertheless,\nthese operations are typically not directly supported by existing SMT solvers,\nwhich instead only consider the generic theory of sequences. In this paper, we\npropose a theory of string sequences and study its satisfiability. We show\nthat, while it is undecidable in general, the decidability can be recovered by\nrestricting to the straight-line fragment. This is shown by encoding each\nstring sequence as a string, and each string sequence operation as a\ncorresponding string operation. We provide pre-image computation for the\nresulting string operations with respect to automata, effectively casting it\ninto the generic OSTRICH string constraint solving framework. We implement the\nnew decision procedure as a tool $\\ostrichseq$, and carry out experiments on\nbenchmark constraints generated from real-world JavaScript programs,\nhand-crafted templates and unit tests. The experiments confirm the efficacy of\nour approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b57\u7b26\u4e32\u5e8f\u5217\u7406\u8bba\uff0c\u7814\u7a76\u4e86\u5176\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u9650\u5236\u4e3a\u76f4\u7ebf\u7247\u6bb5\u6062\u590d\u53ef\u5224\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u5b57\u7b26\u4e32\u5e8f\u5217\u7f16\u7801\u4e3a\u5b57\u7b26\u4e32\uff0c\u5e76\u5728OSTRICH\u6846\u67b6\u4e2d\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709SMT\u6c42\u89e3\u5668\u901a\u5e38\u4e0d\u652f\u6301\u5b57\u7b26\u4e32\u5e8f\u5217\u7684\u5e38\u89c1\u64cd\u4f5c\uff08\u5982\u6b63\u5219\u5339\u914d\u3001\u5206\u5272\u7b49\uff09\uff0c\u800c\u8fd9\u4e9b\u64cd\u4f5c\u5728\u5b57\u7b26\u4e32\u5904\u7406\u7a0b\u5e8f\u4e2d\u9891\u7e41\u4f7f\u7528\u3002\u56e0\u6b64\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b57\u7b26\u4e32\u5e8f\u5217\u7406\u8bba\u4ee5\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "\u5c06\u5b57\u7b26\u4e32\u5e8f\u5217\u7f16\u7801\u4e3a\u5b57\u7b26\u4e32\uff0c\u5e76\u5c06\u5b57\u7b26\u4e32\u5e8f\u5217\u64cd\u4f5c\u6620\u5c04\u4e3a\u76f8\u5e94\u7684\u5b57\u7b26\u4e32\u64cd\u4f5c\u3002\u901a\u8fc7\u9650\u5236\u4e3a\u76f4\u7ebf\u7247\u6bb5\u6062\u590d\u53ef\u5224\u5b9a\u6027\uff0c\u5e76\u5728OSTRICH\u6846\u67b6\u4e2d\u5b9e\u73b0\u9884\u56fe\u50cf\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u4ece\u5b9e\u9645JavaScript\u7a0b\u5e8f\u751f\u6210\u7684\u57fa\u51c6\u7ea6\u675f\u3001\u624b\u5de5\u6a21\u677f\u548c\u5355\u5143\u6d4b\u8bd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b57\u7b26\u4e32\u5e8f\u5217\u7406\u8bba\u5728\u76f4\u7ebf\u7247\u6bb5\u4e0b\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u4e14\u901a\u8fc7\u5b9e\u73b0\u5de5\u5177\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.00567", "pdf": "https://arxiv.org/pdf/2509.00567", "abs": "https://arxiv.org/abs/2509.00567", "authors": ["P. Kumar"], "title": "Interference Between FM Cell Sites and CDMA Cell Sites", "categories": ["cs.NI"], "comment": null, "summary": "Interference is the major problem now days in telecommunication sector. One\ntype of interference which is very common now days is FM Cell sites\ninterference between CDMA Cell sites. Which are the types of interference and\nvarious observations during this interference is discussed below in this paper.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86CDMA\u57fa\u7ad9\u4e0eFM\u57fa\u7ad9\u4e4b\u95f4\u7684\u5e72\u6270\u95ee\u9898\uff0c\u5206\u6790\u4e86\u5e72\u6270\u7c7b\u578b\u548c\u89c2\u5bdf\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u7535\u4fe1\u9886\u57df\u4e2d\u7684FM\u4e0eCDMA\u57fa\u7ad9\u5e72\u6270\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u901a\u4fe1\u8d28\u91cf\u3002", "method": "\u5206\u6790\u5e72\u6270\u7c7b\u578b\u548c\u5e72\u6270\u8fc7\u7a0b\u4e2d\u7684\u5404\u79cd\u73b0\u8c61\u3002", "result": "\u603b\u7ed3\u51fa\u5e72\u6270\u7684\u7c7b\u578b\u548c\u76f8\u5173\u89c2\u5bdf\u7ed3\u679c\u3002", "conclusion": "\u5e72\u6270\u95ee\u9898\u662f\u7535\u4fe1\u9886\u57df\u7684\u91cd\u8981\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00696", "pdf": "https://arxiv.org/pdf/2509.00696", "abs": "https://arxiv.org/abs/2509.00696", "authors": ["Akriti Verma", "Shama Islam", "Valeh Moghaddam", "Adnan Anwar"], "title": "Queuing for Civility: Regulating Emotions and Reducing Toxicity in Digital Discourse", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "comment": null, "summary": "The pervasiveness of online toxicity, including hate speech and trolling,\ndisrupts digital interactions and online well-being. Previous research has\nmainly focused on post-hoc moderation, overlooking the real-time emotional\ndynamics of online conversations and the impact of users' emotions on others.\nThis paper presents a graph-based framework to identify the need for emotion\nregulation within online conversations. This framework promotes self-reflection\nto manage emotional responses and encourage responsible behaviour in real time.\nAdditionally, a comment queuing mechanism is proposed to address intentional\ntrolls who exploit emotions to inflame conversations. This mechanism introduces\na delay in publishing comments, giving users time to self-regulate before\nfurther engaging in the conversation and helping maintain emotional balance.\nAnalysis of social media data from Twitter and Reddit demonstrates that the\ngraph-based framework reduced toxicity by 12%, while the comment queuing\nmechanism decreased the spread of anger by 15%, with only 4% of comments being\ntemporarily held on average. These findings indicate that combining real-time\nemotion regulation with delayed moderation can significantly improve well-being\nin online environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6846\u67b6\u548c\u8bc4\u8bba\u6392\u961f\u673a\u5236\uff0c\u7528\u4e8e\u5b9e\u65f6\u8c03\u8282\u5728\u7ebf\u5bf9\u8bdd\u4e2d\u7684\u60c5\u7eea\uff0c\u51cf\u5c11\u6bd2\u6027\u548c\u6124\u6012\u4f20\u64ad\u3002", "motivation": "\u5728\u7ebf\u6bd2\u6027\u548c\u60c5\u7eea\u52a8\u6001\u5f71\u54cd\u6570\u5b57\u4e92\u52a8\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u4e8b\u540e\u5ba1\u6838\uff0c\u5ffd\u89c6\u4e86\u5b9e\u65f6\u60c5\u7eea\u8c03\u8282\u3002", "method": "\u91c7\u7528\u56fe\u6846\u67b6\u8bc6\u522b\u60c5\u7eea\u8c03\u8282\u9700\u6c42\uff0c\u5f15\u5165\u8bc4\u8bba\u6392\u961f\u673a\u5236\u5ef6\u8fdf\u53d1\u5e03\u8bc4\u8bba\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6bd2\u6027\u51cf\u5c1112%\uff0c\u6124\u6012\u4f20\u64ad\u964d\u4f4e15%\uff0c\u4ec54%\u8bc4\u8bba\u88ab\u4e34\u65f6\u5ef6\u8fdf\u3002", "conclusion": "\u5b9e\u65f6\u60c5\u7eea\u8c03\u8282\u4e0e\u5ef6\u8fdf\u5ba1\u6838\u7ed3\u5408\u53ef\u663e\u8457\u63d0\u5347\u5728\u7ebf\u73af\u5883\u5065\u5eb7\u3002"}}
{"id": "2509.00029", "pdf": "https://arxiv.org/pdf/2509.00029", "abs": "https://arxiv.org/abs/2509.00029", "authors": ["Leo Vitasovic", "Stella Gra\u00dfhof", "Agnes Mercedes Kloft", "Ville V. Lehtola", "Martin Cunneen", "Justyna Starostka", "Glenn McGarry", "Kun Li", "Sami S. Brandt"], "title": "From Sound to Sight: Towards AI-authored Music Videos", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "comment": "1st Workshop on Generative AI for Storytelling (AISTORY), 2025", "summary": "Conventional music visualisation systems rely on handcrafted ad hoc\ntransformations of shapes and colours that offer only limited expressiveness.\nWe propose two novel pipelines for automatically generating music videos from\nany user-specified, vocal or instrumental song using off-the-shelf deep\nlearning models. Inspired by the manual workflows of music video producers, we\nexperiment on how well latent feature-based techniques can analyse audio to\ndetect musical qualities, such as emotional cues and instrumental patterns, and\ndistil them into textual scene descriptions using a language model. Next, we\nemploy a generative model to produce the corresponding video clips. To assess\nthe generated videos, we identify several critical aspects and design and\nconduct a preliminary user evaluation that demonstrates storytelling potential,\nvisual coherency and emotional alignment with the music. Our findings\nunderscore the potential of latent feature techniques and deep generative\nmodels to expand music visualisation beyond traditional approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u6761\u65b0\u6d41\u7a0b\uff0c\u5229\u7528\u73b0\u6210\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u81ea\u52a8\u751f\u6210\u97f3\u4e50\u89c6\u9891\uff0c\u901a\u8fc7\u6f5c\u7279\u5f81\u6280\u672f\u548c\u751f\u6210\u6a21\u578b\u589e\u5f3a\u97f3\u4e50\u53ef\u89c6\u5316\u7684\u8868\u73b0\u529b\u3002", "motivation": "\u4f20\u7edf\u97f3\u4e50\u53ef\u89c6\u5316\u7cfb\u7edf\u4f9d\u8d56\u624b\u5de5\u5236\u4f5c\u7684\u7279\u5b9a\u5f62\u72b6\u548c\u989c\u8272\u8f6c\u6362\uff0c\u8868\u73b0\u529b\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6f5c\u7279\u5f81\u6280\u672f\u548c\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5728\u97f3\u4e50\u53ef\u89c6\u5316\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u6f5c\u7279\u5f81\u6280\u672f\u5206\u6790\u97f3\u9891\uff0c\u68c0\u6d4b\u97f3\u4e50\u60c5\u611f\u548c\u4e50\u5668\u6a21\u5f0f\uff0c\u5e76\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u573a\u666f\u63cf\u8ff0\uff1b\u968f\u540e\u5229\u7528\u751f\u6210\u6a21\u578b\u751f\u6210\u76f8\u5e94\u89c6\u9891\u7247\u6bb5\u3002\u901a\u8fc7\u7528\u6237\u8bc4\u4f30\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u521d\u6b65\u7528\u6237\u8bc4\u4f30\u8868\u660e\uff0c\u751f\u6210\u7684\u89c6\u9891\u5728\u53d9\u4e8b\u6f5c\u529b\u3001\u89c6\u89c9\u8fde\u8d2f\u6027\u548c\u60c5\u611f\u4e0e\u97f3\u4e50\u7684\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u6f5c\u7279\u5f81\u6280\u672f\u548c\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u6709\u671b\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\uff0c\u63d0\u5347\u97f3\u4e50\u53ef\u89c6\u5316\u7684\u8868\u73b0\u529b\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2509.00280", "pdf": "https://arxiv.org/pdf/2509.00280", "abs": "https://arxiv.org/abs/2509.00280", "authors": ["Ahmed E. Helal", "Fabio Checconi", "Jan Laukemann", "Yongseok Soh", "Jesmin Jahan Tithi", "Fabrizio Petrini", "Jee Choi"], "title": "ReLATE: Learning Efficient Sparse Encoding for High-Performance Tensor Decomposition", "categories": ["cs.LG", "cs.DC", "cs.PF"], "comment": null, "summary": "Tensor decomposition (TD) is essential for analyzing high-dimensional sparse\ndata, yet its irregular computations and memory-access patterns pose major\nperformance challenges on modern parallel processors. Prior works rely on\nexpert-designed sparse tensor formats that fail to adapt to irregular tensor\nshapes and/or highly variable data distributions. We present the\nreinforcement-learned adaptive tensor encoding (ReLATE) framework, a novel\nlearning-augmented method that automatically constructs efficient sparse tensor\nrepresentations without labeled training samples. ReLATE employs an autonomous\nagent that discovers optimized tensor encodings through direct interaction with\nthe TD environment, leveraging a hybrid model-free and model-based algorithm to\nlearn from both real and imagined actions. Moreover, ReLATE introduces\nrule-driven action masking and dynamics-informed action filtering mechanisms\nthat ensure functionally correct tensor encoding with bounded execution time,\neven during early learning stages. By automatically adapting to both irregular\ntensor shapes and data distributions, ReLATE generates sparse tensor\nrepresentations that consistently outperform expert-designed formats across\ndiverse sparse tensor data sets, achieving up to 2X speedup compared to the\nbest sparse format, with a geometric-mean speedup of 1.4-1.46X.", "AI": {"tldr": "ReLATE\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u6784\u5efa\u9ad8\u6548\u7a00\u758f\u5f20\u91cf\u8868\u793a\uff0c\u9002\u5e94\u4e0d\u89c4\u5219\u5f20\u91cf\u5f62\u72b6\u548c\u6570\u636e\u5206\u5e03\uff0c\u6027\u80fd\u4f18\u4e8e\u4e13\u5bb6\u8bbe\u8ba1\u683c\u5f0f\u3002", "motivation": "\u4f20\u7edf\u7a00\u758f\u5f20\u91cf\u683c\u5f0f\u65e0\u6cd5\u9002\u5e94\u4e0d\u89c4\u5219\u5f20\u91cf\u5f62\u72b6\u548c\u9ad8\u5ea6\u53d8\u5316\u7684\u6570\u636e\u5206\u5e03\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u65e0\u5173\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u4f5c\u63a9\u7801\u548c\u8fc7\u6ee4\u786e\u4fdd\u529f\u80fd\u6027\u3002", "result": "\u5728\u591a\u79cd\u7a00\u758f\u5f20\u91cf\u6570\u636e\u96c6\u4e0a\uff0cReLATE\u6027\u80fd\u6700\u4f18\uff0c\u6700\u9ad8\u63d0\u901f2\u500d\uff0c\u51e0\u4f55\u5e73\u5747\u63d0\u901f1.4-1.46\u500d\u3002", "conclusion": "ReLATE\u4e3a\u9ad8\u7ef4\u7a00\u758f\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2509.00599", "pdf": "https://arxiv.org/pdf/2509.00599", "abs": "https://arxiv.org/abs/2509.00599", "authors": ["Shubham Negi", "Manik Singhal", "Aayush Ankit", "Sudeep Bhoja", "Kaushik Roy"], "title": "COMET: A Framework for Modeling Compound Operation Dataflows with Explicit Collectives", "categories": ["cs.AR", "cs.DC"], "comment": null, "summary": "Modern machine learning accelerators are designed to efficiently execute deep\nneural networks (DNNs) by optimizing data movement, memory hierarchy, and\ncompute throughput. However, emerging DNN models such as large language models,\nstate space models increasingly rely on compound operations-structured\ncompositions of multiple basic operations-which introduce new challenges for\ndataflow optimization and minimizing off-chip memory traffic. Moreover, as\nmodel size continues to grow, deployment across spatially distributed compute\nclusters becomes essential, requiring frequent and complex collective\ncommunication. Existing dataflow optimization frameworks and performance models\neither focus on single operations or lack explicit modeling of collective\ncommunication cost, limiting their applicability to modern workloads.\n  To address these limitations, we propose, a framework for modeling and\noptimizing dataflow for compound operations on machine learning accelerators.\nCOMET introduces a novel representation that explicitly models collective\ncommunication across spatial clusters, along with latency and energy cost\nmodels that account for both GEMM and non-GEMM operation level dependencies\nwithin compound operations. We demonstrate COMET's capabilities to analyze and\noptimize dataflows for compound operations such as GEMM--Softmax,\nGEMM--LayerNorm, and self-attention, across both edge and cloud accelerator\nconfigurations. Our collective-aware modeling enables exploration of a broader\nmapping space, leading to improved performance and energy efficiency.\nSpecifically, our optimized dataflows achieve up to 1.42$\\times$ speedup for\nGEMM-Softmax, 3.46$\\times$ for GEMM-LayerNorm and 1.82$\\times$ for\nself-attention compared to unfused baselines.", "AI": {"tldr": "COMET\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u52a0\u901f\u5668\u4e2d\u590d\u5408\u64cd\u4f5c\u7684\u5efa\u6a21\u4e0e\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u7a7a\u95f4\u96c6\u7fa4\u95f4\u7684\u96c6\u4f53\u901a\u4fe1\u53ca\u5176\u6210\u672c\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u4ee3DNN\u6a21\u578b\u4f9d\u8d56\u590d\u5408\u64cd\u4f5c\uff0c\u73b0\u6709\u4f18\u5316\u6846\u67b6\u7f3a\u4e4f\u5bf9\u96c6\u4f53\u901a\u4fe1\u6210\u672c\u7684\u663e\u5f0f\u5efa\u6a21\uff0c\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u3002", "method": "COMET\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u8868\u793a\u6cd5\uff0c\u663e\u5f0f\u5efa\u6a21\u96c6\u4f53\u901a\u4fe1\u548c\u64cd\u4f5c\u4f9d\u8d56\uff0c\u4f18\u5316\u6570\u636e\u6d41\u3002", "result": "\u4f18\u5316\u540e\u7684\u6570\u636e\u6d41\u5728\u591a\u4e2a\u590d\u5408\u64cd\u4f5c\uff08\u5982GEMM-Softmax\uff09\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u901f\u5ea6\u548c\u80fd\u6548\u3002", "conclusion": "COMET\u901a\u8fc7\u96c6\u4f53\u901a\u4fe1\u611f\u77e5\u7684\u5efa\u6a21\uff0c\u62d3\u5c55\u4e86\u4f18\u5316\u7a7a\u95f4\uff0c\u4e3a\u73b0\u4ee3DNN\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u52a0\u901f\u65b9\u6848\u3002"}}
{"id": "2509.00937", "pdf": "https://arxiv.org/pdf/2509.00937", "abs": "https://arxiv.org/abs/2509.00937", "authors": ["Paul Ruiz Alliata", "Diana Rubaga", "Daniel Kumlin", "Alberto Puliga"], "title": "Parallelizing Drug Discovery: HPC Pipelines for Alzheimer's Molecular Docking and Simulation", "categories": ["cs.DC"], "comment": "7 pages, 5 figures", "summary": "High-performance computing (HPC) is reshaping computational drug discovery by\nenabling large-scale, time-efficient molecular simulations. In this work, we\nexplore HPC-driven pipelines for Alzheimer's disease drug discovery, focusing\non virtual screening, molecular docking, and molecular dynamics simulations. We\nimplemented a parallelised workflow using GROMACS with hybrid MPI-OpenMP\nstrategies, benchmarking scaling performance across energy minimisation,\nequilibration, and production stages. Additionally, we developed a docking\nprototype that demonstrates significant runtime gains when moving from\nsequential execution to process-based parallelism using Python's\nmultiprocessing library. Case studies on prolinamide derivatives and baicalein\nhighlight the biological relevance of these workflows in targeting amyloid-beta\nand tau proteins. While limitations remain in data management, computational\ncosts, and scaling efficiency, our results underline the potential of HPC to\naccelerate neurodegenerative drug discovery.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u5982\u4f55\u901a\u8fc7\u865a\u62df\u7b5b\u9009\u3001\u5206\u5b50\u5bf9\u63a5\u548c\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u52a0\u901f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u836f\u7269\u53d1\u73b0\uff0c\u5c55\u793a\u4e86\u5e76\u884c\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u4f18\u52bf\u53ca\u5c40\u9650\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5229\u7528HPC\u6280\u672f\u63d0\u9ad8\u836f\u7269\u53d1\u73b0\u7684\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7b49\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u7684\u6cbb\u7597\u4e2d\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5206\u5b50\u6a21\u62df\u52a0\u901f\u7b5b\u9009\u548c\u4f18\u5316\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u4e86\u57fa\u4e8eGROMACS\u7684\u6df7\u5408MPI-OpenMP\u5e76\u884c\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u5f00\u53d1\u4e86\u4f7f\u7528Python\u591a\u8fdb\u7a0b\u5e93\u7684\u5206\u5b50\u5bf9\u63a5\u539f\u578b\uff0c\u6d4b\u8bd5\u4e86\u5728\u80fd\u91cf\u6700\u5c0f\u5316\u3001\u5e73\u8861\u548c\u751f\u4ea7\u9636\u6bb5\u7684\u6027\u80fd\u6269\u5c55\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5e76\u884c\u5316\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u5c24\u5176\u662f\u5728\u5206\u5b50\u5bf9\u63a5\u548c\u52a8\u529b\u5b66\u6a21\u62df\u4e2d\uff0c\u4f46\u4ecd\u9762\u4e34\u6570\u636e\u7ba1\u7406\u3001\u8ba1\u7b97\u6210\u672c\u548c\u6269\u5c55\u6548\u7387\u7684\u6311\u6218\u3002", "conclusion": "HPC\u6280\u672f\u5728\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u836f\u7269\u53d1\u73b0\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u514b\u670d\u5f53\u524d\u7684\u6280\u672f\u548c\u6210\u672c\u9650\u5236\u3002"}}
{"id": "2509.01442", "pdf": "https://arxiv.org/pdf/2509.01442", "abs": "https://arxiv.org/abs/2509.01442", "authors": ["Jo\u00e3o S. Ferreira", "Arianna Crippa", "Astryd Park", "Daniel Bultrini", "Pierre Fromholz", "Roman Lipski", "Karl Jansen", "James R. Wootton"], "title": "Quantum Brush: A quantum computing-based tool for digital painting", "categories": ["cs.GR", "cs.ET", "cs.MM", "physics.soc-ph", "quant-ph"], "comment": null, "summary": "We present Quantum Brush, an open-source digital painting tool that harnesses\nquantum computing to generate novel artistic expressions. The tool includes\nfour different brushes that translate strokes into unique quantum algorithms,\neach highlighting a different way in which quantum effects can produce novel\naesthetics. Each brush is designed to be compatible with the current noisy\nintermediate-scale quantum (NISQ) devices, as demonstrated by executing them on\nIQM's Sirius device.", "AI": {"tldr": "Quantum Brush\u662f\u4e00\u6b3e\u5f00\u6e90\u6570\u5b57\u7ed8\u753b\u5de5\u5177\uff0c\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u751f\u6210\u65b0\u9896\u827a\u672f\u8868\u8fbe\uff0c\u5305\u542b\u56db\u79cd\u4e0d\u540c\u753b\u7b14\uff0c\u5c06\u7b14\u753b\u8f6c\u5316\u4e3a\u72ec\u7279\u7684\u91cf\u5b50\u7b97\u6cd5\uff0c\u5c55\u793a\u91cf\u5b50\u6548\u5e94\u5982\u4f55\u521b\u9020\u65b0\u7f8e\u5b66\uff0c\u517c\u5bb9\u5f53\u524dNISQ\u8bbe\u5907\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u5728\u827a\u672f\u8868\u8fbe\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5f00\u53d1\u5de5\u5177\u5c55\u793a\u91cf\u5b50\u6548\u5e94\u5982\u4f55\u4ea7\u751f\u72ec\u7279\u7f8e\u5b66\u6548\u679c\u3002", "method": "\u5f00\u53d1Quantum Brush\u5de5\u5177\uff0c\u5305\u542b\u56db\u79cd\u753b\u7b14\uff0c\u5c06\u7ed8\u753b\u52a8\u4f5c\u8f6c\u5316\u4e3a\u91cf\u5b50\u7b97\u6cd5\uff0c\u5e76\u5728IQM\u7684Sirius\u8bbe\u5907\u4e0a\u6267\u884c\u3002", "result": "\u5de5\u5177\u6210\u529f\u5c55\u793a\u4e86\u91cf\u5b50\u6548\u5e94\u5728\u827a\u672f\u521b\u4f5c\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u5728\u73b0\u6709NISQ\u8bbe\u5907\u4e0a\u5b9e\u73b0\u3002", "conclusion": "Quantum Brush\u4e3a\u91cf\u5b50\u8ba1\u7b97\u4e0e\u827a\u672f\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u53ef\u80fd\u6027\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u6548\u5e94\u5728\u7f8e\u5b66\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.00277", "pdf": "https://arxiv.org/pdf/2509.00277", "abs": "https://arxiv.org/abs/2509.00277", "authors": ["Changjae Lee", "Zhuoyue Zhao", "Jinjun Xiong"], "title": "SABER: A SQL-Compatible Semantic Document Processing System Based on Extended Relational Algebra", "categories": ["cs.DB", "cs.AI"], "comment": "6 pages, 2 figures", "summary": "The emergence of large-language models (LLMs) has enabled a new class of\nsemantic data processing systems (SDPSs) to support declarative queries against\nunstructured documents. Existing SDPSs are, however, lacking a unified\nalgebraic foundation, making their queries difficult to compose, reason, and\noptimize. We propose a new semantic algebra, SABER (Semantic Algebra Based on\nExtended Relational algebra), opening the possibility of semantic operations'\nlogical plan construction, optimization, and formal correctness guarantees. We\nfurther propose to implement SABER in a SQL-compatible syntax so that it\nnatively supports mixed structured/unstructured data processing. With SABER, we\nshowcase the feasibility of providing a unified interface for existing SDPSs so\nthat it can effectively mix and match any semantically-compatible operator\nimplementation from any SDPS, greatly enhancing SABER's applicability for\ncommunity contributions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSABER\u7684\u8bed\u4e49\u4ee3\u6570\uff0c\u65e8\u5728\u4e3a\u8bed\u4e49\u6570\u636e\u5904\u7406\u7cfb\u7edf\uff08SDPSs\uff09\u63d0\u4f9b\u7edf\u4e00\u7684\u4ee3\u6570\u57fa\u7840\uff0c\u652f\u6301\u903b\u8f91\u8ba1\u5212\u6784\u5efa\u3001\u4f18\u5316\u548c\u5f62\u5f0f\u5316\u6b63\u786e\u6027\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709SDPSs\u7f3a\u4e4f\u7edf\u4e00\u7684\u4ee3\u6570\u57fa\u7840\uff0c\u5bfc\u81f4\u67e5\u8be2\u96be\u4ee5\u7ec4\u5408\u3001\u63a8\u7406\u548c\u4f18\u5316\uff0c\u9650\u5236\u4e86\u5176\u53d1\u5c55\u548c\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6269\u5c55\u5173\u7cfb\u4ee3\u6570\u7684\u8bed\u4e49\u4ee3\u6570SABER\uff0c\u5e76\u91c7\u7528SQL\u517c\u5bb9\u8bed\u6cd5\u5b9e\u73b0\uff0c\u652f\u6301\u6df7\u5408\u7ed3\u6784\u5316/\u975e\u7ed3\u6784\u5316\u6570\u636e\u5904\u7406\u3002", "result": "SABER\u5c55\u793a\u4e86\u4e3a\u73b0\u6709SDPSs\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u6709\u6548\u7ec4\u5408\u4efb\u4f55\u8bed\u4e49\u517c\u5bb9\u7684\u8fd0\u7b97\u7b26\u5b9e\u73b0\uff0c\u6269\u5c55\u4e86\u793e\u533a\u8d21\u732e\u7684\u9002\u7528\u6027\u3002", "conclusion": "SABER\u4e3aSDPSs\u63d0\u4f9b\u4e86\u65b0\u7684\u4ee3\u6570\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u7edf\u4e00\u6027\u7684\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.00140", "pdf": "https://arxiv.org/pdf/2509.00140", "abs": "https://arxiv.org/abs/2509.00140", "authors": ["Songhui Yue"], "title": "LLM-based Triplet Extraction for Automated Ontology Generation in Software Engineering Standards", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Ontologies have supported knowledge representation and whitebox reasoning for\ndecades; thus, the automated ontology generation (AOG) plays a crucial role in\nscaling their use. Software engineering standards (SES) consist of long,\nunstructured text (with high noise) and paragraphs with domain-specific terms.\nIn this setting, relation triple extraction (RTE), together with term\nextraction, constitutes the first stage toward AOG. This work proposes an\nopen-source large language model (LLM)-assisted approach to RTE for SES.\nInstead of solely relying on prompt-engineering-based methods, this study\npromotes the use of LLMs as an aid in constructing ontologies and explores an\neffective AOG workflow that includes document segmentation, candidate term\nmining, LLM-based relation inference, term normalization, and cross-section\nalignment. Golden-standard benchmarks at three granularities are constructed\nand used to evaluate the ontology generated from the study. The results show\nthat it is comparable and potentially superior to the OpenIE method of triple\nextraction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5173\u7cfb\u4e09\u5143\u7ec4\u63d0\u53d6\u65b9\u6cd5\uff0c\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u6807\u51c6\uff08SES\uff09\u7684\u81ea\u52a8\u5316\u672c\u4f53\u751f\u6210\uff08AOG\uff09\uff0c\u5e76\u901a\u8fc7\u591a\u7c92\u5ea6\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u5176\u4f18\u4e8e\u4f20\u7edfOpenIE\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u6807\u51c6\uff08SES\uff09\u6587\u672c\u5197\u957f\u4e14\u975e\u7ed3\u6784\u5316\uff0c\u4f20\u7edf\u672c\u4f53\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528LLM\u8f85\u52a9\u5173\u7cfb\u4e09\u5143\u7ec4\u63d0\u53d6\uff08RTE\uff09\uff0c\u63d0\u5347\u81ea\u52a8\u5316\u672c\u4f53\u751f\u6210\uff08AOG\uff09\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528LLM\u8f85\u52a9\u7684RTE\u65b9\u6cd5\uff0c\u5305\u62ec\u6587\u6863\u5206\u5272\u3001\u5019\u9009\u672f\u8bed\u6316\u6398\u3001LLM\u5173\u7cfb\u63a8\u65ad\u3001\u672f\u8bed\u5f52\u4e00\u5316\u548c\u8de8\u90e8\u5206\u5bf9\u9f50\u3002\u901a\u8fc7Prompt Engineering\u7ed3\u5408LLM\u80fd\u529b\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6709\u6548\u7684AOG\u5de5\u4f5c\u6d41\u3002", "result": "\u751f\u6210\u7684\u672c\u4f53\u5728\u4e09\u7c92\u5ea6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5176\u6027\u80fd\u4e0eOpenIE\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "conclusion": "LLM\u8f85\u52a9\u7684RTE\u65b9\u6cd5\u4e3aSES\u7684\u81ea\u52a8\u5316\u672c\u4f53\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86LLM\u5728\u77e5\u8bc6\u8868\u793a\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.00168", "pdf": "https://arxiv.org/pdf/2509.00168", "abs": "https://arxiv.org/abs/2509.00168", "authors": ["James Cranch", "Georg Struth", "Jana Wagemaker"], "title": "Generalised M\u00f6bius Categories and Convolution Kleene Algebras", "categories": ["cs.FL", "cs.LO", "06F, 16Y60, 18A05, 18N30, 68Q60, 68Q70"], "comment": "32 pages", "summary": "Convolution algebras on maps from structures such as monoids, groups or\ncategories into semirings, rings or fields abound in mathematics and the\nsciences. Of special interest in computing are convolution algebras based on\nvariants of Kleene algebras, which are additively idempotent semirings equipped\nwith a Kleene star. Yet an obstacle to the construction of convolution Kleene\nalgebras on a wide class of structures has so far been the definition of a\nsuitable star. We show that a generalisation of M\\\"obius categories combined\nwith a generalisation of a classical definition of a star for formal power\nseries allow such a construction. We discuss several instances of this\nconstruction on generalised M\\\"obius categories: convolution Kleene algebras\nwith tests, modal convolution Kleene algebras, concurrent convolution Kleene\nalgebras and higher convolution Kleene algebras (e.g. on strict higher\ncategories and higher relational monoids). These are relevant to the\nverification of weighted and probabilistic sequential and concurrent programs,\nusing quantitative Hoare logics or predicate transformer algebras, as well as\nfor algebraic reasoning in higher-dimensional rewriting. We also adapt the\nconvolution Kleene algebra construction to Conway semirings, which is widely\nstudied in the context of weighted automata. Finally, we compare the\nconvolution Kleene algebra construction with a previous construction of\nconvolution quantales and present concrete example structures in preparation\nfor future applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49M\u00f6bius\u8303\u7574\u548c\u5f62\u5f0f\u5e42\u7ea7\u6570\u7684\u661f\u7684\u5e7f\u4e49\u5b9a\u4e49\uff0c\u7528\u4e8e\u6784\u5efa\u5377\u79efKleene\u4ee3\u6570\uff0c\u89e3\u51b3\u4e86\u6b64\u524d\u56e0\u7f3a\u4e4f\u5408\u9002\u7684\u661f\u5b9a\u4e49\u800c\u53d7\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u5377\u79ef\u4ee3\u6570\u5728\u6570\u5b66\u548c\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46\u5728\u6784\u5efa\u5e7f\u6cdb\u7684\u5377\u79efKleene\u4ee3\u6570\u65f6\uff0c\u7f3a\u4e4f\u5408\u9002\u7684\u661f\u5b9a\u4e49\u662f\u4e00\u4e2a\u969c\u788d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u5e7f\u4e49M\u00f6bius\u8303\u7574\u548c\u5f62\u5f0f\u5e42\u7ea7\u6570\u7684\u661f\u7684\u5e7f\u4e49\u5b9a\u4e49\uff0c\u6784\u5efa\u5377\u79efKleene\u4ee3\u6570\uff0c\u5e76\u5728\u591a\u79cd\u7ed3\u6784\u4e2d\u5b9e\u4f8b\u5316\uff0c\u5982\u5e26\u6d4b\u8bd5\u7684\u5377\u79efKleene\u4ee3\u6570\u3001\u6a21\u6001\u5377\u79efKleene\u4ee3\u6570\u7b49\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u9002\u7528\u4e8e\u591a\u79cd\u7ed3\u6784\u7684\u5377\u79efKleene\u4ee3\u6570\uff0c\u5e76\u5728\u52a0\u6743\u548c\u6982\u7387\u7a0b\u5e8f\u9a8c\u8bc1\u3001\u9ad8\u9636\u7ef4\u5ea6\u91cd\u5199\u7b49\u9886\u57df\u5c55\u793a\u4e86\u5176\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6269\u5c55\u4e86\u5377\u79efKleene\u4ee3\u6570\u7684\u9002\u7528\u8303\u56f4\uff0c\u5e76\u4e3a\u672a\u6765\u5e94\u7528\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u793a\u4f8b\u7ed3\u6784\u3002"}}
{"id": "2509.00406", "pdf": "https://arxiv.org/pdf/2509.00406", "abs": "https://arxiv.org/abs/2509.00406", "authors": ["Ahmed H. Mahmoud", "Jonathan Ragan-Kelley", "Justin Solomon"], "title": "Locality-Aware Automatic Differentiation on the GPU for Mesh-Based Computations", "categories": ["cs.GR"], "comment": null, "summary": "We present a high-performance system for automatic differentiation (AD) of\nfunctions defined on triangle meshes that exploits the inherent sparsity and\nlocality of mesh-based energy functions to achieve fast gradient and Hessian\ncomputation on the GPU. Our system is designed around per-element forward-mode\ndifferentiation, enabling all local computations to remain in GPU registers or\nshared memory. Unlike reverse-mode approaches that construct and traverse\nglobal computation graphs, our method performs differentiation on the fly,\nminimizing memory traffic and avoiding global synchronization. Our programming\nmodel allows users to define local energy terms while the system handles\nparallel evaluation, derivative computation, and sparse Hessian assembly. We\nbenchmark our system on a range of applications--cloth simulation, surface\nparameterization, mesh smoothing, and spherical manifold optimization. We\nachieve a geometric mean speedup of 6.2x over optimized PyTorch implementations\nfor second-order derivatives, and 2.76x speedup for Hessian-vector products.\nFor first-order derivatives, our system is 6.38x, 2.89x, and 1.98x faster than\nWarp, JAX, and Dr.JIT, respectively, while remaining on par with hand-written\nderivatives.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9ad8\u6027\u80fd\u7684\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e09\u89d2\u5f62\u7f51\u683c\u4e0a\u7684\u51fd\u6570\uff0c\u5229\u7528GPU\u5b9e\u73b0\u5feb\u901f\u68af\u5ea6\u548cHessian\u8ba1\u7b97\u3002", "motivation": "\u4f20\u7edf\u53cd\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\u65b9\u6cd5\u5728\u5904\u7406\u7f51\u683c\u80fd\u91cf\u51fd\u6570\u65f6\u5b58\u5728\u5168\u5c40\u8ba1\u7b97\u56fe\u548c\u540c\u6b65\u7684\u5f00\u9500\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5c40\u90e8\u8ba1\u7b97\u548cGPU\u4f18\u5316\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5143\u7d20\u7684\u524d\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\uff0c\u6240\u6709\u5c40\u90e8\u8ba1\u7b97\u4fdd\u6301\u5728GPU\u5bc4\u5b58\u5668\u6216\u5171\u4eab\u5185\u5b58\u4e2d\uff0c\u907f\u514d\u5168\u5c40\u540c\u6b65\u548c\u5185\u5b58\u9891\u7e41\u8bbf\u95ee\u3002", "result": "\u5728\u4e8c\u9636\u5bfc\u6570\u8ba1\u7b97\u4e2d\uff0c\u6bd4\u4f18\u5316\u540e\u7684PyTorch\u5b9e\u73b0\u5feb6.2\u500d\uff1bHessian\u5411\u91cf\u79ef\u8ba1\u7b97\u5feb2.76\u500d\uff1b\u4e00\u9636\u5bfc\u6570\u8ba1\u7b97\u4e5f\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u5de5\u5177\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u4fdd\u6301\u4e0e\u624b\u5199\u5bfc\u6570\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5fae\u5206\u5728\u7f51\u683c\u8ba1\u7b97\u4e2d\u7684\u6548\u7387\u3002"}}
{"id": "2509.01511", "pdf": "https://arxiv.org/pdf/2509.01511", "abs": "https://arxiv.org/abs/2509.01511", "authors": ["Zhe Zhou", "Benjamin Delaware", "Suresh Jagannathan"], "title": "Type-Based Incorrectness Reasoning", "categories": ["cs.PL"], "comment": null, "summary": "A coverage type generalizes refinement types found in many functional\nlanguages with support for must-style underapproximate reasoning.\nProperty-based testing frameworks are one particularly useful domain where such\ncapabilities are useful as they allow us to verify the completeness, as well as\nsafety, of test generators. There is a surprising connection between the kind\nof underapproximate reasoning coverage types offer and the style of reasoning\nenabled by recently proposed Incorrectness Logic frameworks. In our\npresentation, we propose to explore this connection more deeply, identifying\nmechanisms that more systematically integrate incorrectness reasoning within an\nexpressive refinement type system and the opportunities that such integration\noffers to functional programmers, program verifiers, and program analyzers and\nrelated tools.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8986\u76d6\u7387\u7c7b\u578b\u4e0e\u4e0d\u6b63\u786e\u6027\u903b\u8f91\u6846\u67b6\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4e0d\u6b63\u786e\u6027\u63a8\u7406\u66f4\u7cfb\u7edf\u5730\u96c6\u6210\u5230\u7ec6\u5316\u7c7b\u578b\u7cfb\u7edf\u4e2d\u7684\u673a\u5236\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u5229\u7528\u8986\u76d6\u7387\u7c7b\u578b\u7684\u4e0d\u5b8c\u5168\u63a8\u7406\u80fd\u529b\uff0c\u9a8c\u8bc1\u6d4b\u8bd5\u751f\u6210\u5668\u7684\u5b8c\u6574\u6027\u548c\u5b89\u5168\u6027\uff0c\u5e76\u63a2\u7d22\u5176\u4e0e\u4e0d\u6b63\u786e\u6027\u903b\u8f91\u6846\u67b6\u7684\u6df1\u5c42\u8054\u7cfb\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u63a2\u7d22\u8986\u76d6\u7387\u7c7b\u578b\u4e0e\u4e0d\u6b63\u786e\u6027\u903b\u8f91\u6846\u67b6\u7684\u8fde\u63a5\uff0c\u63d0\u51fa\u4e00\u79cd\u673a\u5236\u5c06\u5b83\u4eec\u96c6\u6210\u5230\u8868\u8fbe\u6027\u7ec6\u5316\u7c7b\u578b\u7cfb\u7edf\u4e2d\u3002", "result": "\u7ed3\u679c\u4e3a\u8be5\u65b9\u6cd5\u4e3a\u51fd\u6570\u5f0f\u7a0b\u5e8f\u5458\u3001\u7a0b\u5e8f\u9a8c\u8bc1\u8005\u548c\u5206\u6790\u5de5\u5177\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u79cd\u96c6\u6210\u53ef\u4ee5\u4e3a\u7a0b\u5e8f\u9a8c\u8bc1\u548c\u5206\u6790\u5de5\u5177\u5e26\u6765\u66f4\u591a\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.00603", "pdf": "https://arxiv.org/pdf/2509.00603", "abs": "https://arxiv.org/abs/2509.00603", "authors": ["Osama Abu Hamdan", "Hao Che", "Engin Arslan", "Md Arifuzzaman"], "title": "SmartFLow: A Communication-Efficient SDN Framework for Cross-Silo Federated Learning", "categories": ["cs.NI"], "comment": "Submitted to IEEE CCNC 2026", "summary": "Cross-silo Federated Learning (FL) enables multiple institutions to\ncollaboratively train machine learning models while preserving data privacy. In\nsuch settings, clients repeatedly exchange model weights with a central server,\nmaking the overall training time highly sensitive to network performance.\nHowever, conventional routing methods often fail to prevent congestion, leading\nto increased communication latency and prolonged training. Software-Defined\nNetworking (SDN), which provides centralized and programmable control over\nnetwork resources, offers a promising way to address this limitation. To this\nend, we propose SmartFLow, an SDN-based framework designed to enhance\ncommunication efficiency in cross-silo FL. SmartFLow dynamically adjusts\nrouting paths in response to changing network conditions, thereby reducing\ncongestion and improving synchronization efficiency. Experimental results show\nthat SmartFLow decreases parameter synchronization time by up to 47% compared\nto shortest-path routing and 41% compared to capacity-aware routing.\nFurthermore, it achieves these gains with minimal computational overhead and\nscales effectively to networks of up to 50 clients, demonstrating its\npracticality for real-world FL deployments.", "AI": {"tldr": "SmartFLow \u662f\u4e00\u79cd\u57fa\u4e8e SDN \u7684\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u5347\u8de8\u7ec4\u7ec7\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u6548\u7387\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8def\u7531\u8def\u5f84\u51cf\u5c11\u62e5\u585e\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u53c2\u6570\u540c\u6b65\u65f6\u95f4\u6bd4\u6700\u77ed\u8def\u5f84\u8def\u7531\u51cf\u5c11 47%\u3002", "motivation": "\u8de8\u7ec4\u7ec7\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u4f20\u7edf\u8def\u7531\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u51cf\u5c11\u62e5\u585e\uff0c\u5bfc\u81f4\u901a\u4fe1\u5ef6\u8fdf\u589e\u52a0\u548c\u8bad\u7ec3\u65f6\u95f4\u5ef6\u957f\uff0c\u800c SDN \u63d0\u4f9b\u4e86\u96c6\u4e2d\u5316\u3001\u53ef\u7f16\u7a0b\u7684\u7f51\u7edc\u8d44\u6e90\u63a7\u5236\u65b9\u5f0f\uff0c\u4e3a\u89e3\u51b3\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u63d0\u51fa\u4e86 SmartFLow \u6846\u67b6\uff0c\u5229\u7528 SDN \u52a8\u6001\u8c03\u6574\u8def\u7531\u8def\u5f84\uff0c\u4ee5\u5e94\u5bf9\u7f51\u7edc\u6761\u4ef6\u53d8\u5316\uff0c\u4ece\u800c\u964d\u4f4e\u62e5\u585e\u5e76\u63d0\u5347\u540c\u6b65\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSmartFLow \u5c06\u53c2\u6570\u540c\u6b65\u65f6\u95f4\u7f29\u77ed\u4e86 47%\uff08\u76f8\u6bd4\u6700\u77ed\u8def\u5f84\u8def\u7531\uff09\u548c 41%\uff08\u76f8\u6bd4\u5bb9\u91cf\u611f\u77e5\u8def\u7531\uff09\uff0c\u540c\u65f6\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\uff0c\u5e76\u80fd\u6269\u5c55\u5230 50 \u4e2a\u5ba2\u6237\u7aef\u7684\u7f51\u7edc\u4e2d\u3002", "conclusion": "SmartFLow \u5728\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u901a\u4fe1\u6548\u7387\u548c\u540c\u6b65\u901f\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5177\u5907\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u548c\u6269\u5c55\u6027\u3002"}}
{"id": "2509.00852", "pdf": "https://arxiv.org/pdf/2509.00852", "abs": "https://arxiv.org/abs/2509.00852", "authors": ["Yvonne Rogers"], "title": "Why it is worth making an effort with GenAI", "categories": ["cs.HC", "cs.AI", "I.2; J.5"], "comment": "6 pages", "summary": "Students routinely use ChatGPT and the like now to help them with their\nhomework, such as writing an essay. It takes less effort to complete and is\neasier to do than by hand. It can even produce as good if not better output\nthan the student's own work. However, there is a growing concern that\nover-reliance on using GenAI in this way will stifle the development of\nlearning writing and critical thinking skills. How might this trend be\nreversed? What if students were required to make more effort when using GenAI\nto do their homework? It might be more challenging, but the additional effort\ninvolved could result in them learning more and having a greater sense of\nachievement. This tension can be viewed as a form of effort paradox; where\neffort is both viewed as something to be avoided but at the same time is\nvalued. Is it possible to let students learn sometimes with less and other\ntimes more effort? Students are already adept at the former but what about the\nlatter? Could we design new kinds of AI tools that deliberately require more\neffort to use to deepen the learning experience? In this paper, I begin to\noutline what form these might take, for example, asking students to use a\ncombination of GenAI tools with traditional learning approaches (e.g.\nnote-taking while reading). I also discuss how else to design tools to think\nwith that augments human cognition; where students learn more the skills of\nmetacognition and reflection.", "AI": {"tldr": "\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u8c03\u6574\u5b66\u751f\u5bf9\u751f\u6210\u5f0fAI\uff08\u5982ChatGPT\uff09\u7684\u4f7f\u7528\u65b9\u5f0f\uff0c\u4f7f\u5176\u5728\u5b66\u4e60\u4e2d\u6295\u5165\u66f4\u591a\u52aa\u529b\uff0c\u4ece\u800c\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\u5bfc\u81f4\u7684\u5199\u4f5c\u548c\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\u9000\u5316\uff0c\u5e76\u8bbe\u8ba1\u65b0\u5de5\u5177\u4ee5\u63d0\u5347\u5b66\u4e60\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524d\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56\u751f\u6210\u5f0fAI\u5b8c\u6210\u4f5c\u4e1a\uff0c\u53ef\u80fd\u5bfc\u81f4\u5176\u5199\u4f5c\u548c\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\u53d1\u5c55\u53d7\u963b\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u5de5\u5177\u8bbe\u8ba1\u8ba9\u5b66\u751f\u5728AI\u8f85\u52a9\u5b66\u4e60\u4e2d\u6295\u5165\u66f4\u591a\u52aa\u529b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u6df1\u5165\u7684\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51fa\u8ba9\u5b66\u751f\u5728\u4f7f\u7528\u751f\u6210\u5f0fAI\u65f6\u589e\u52a0\u989d\u5916\u52aa\u529b\uff08\u5982\u7ed3\u5408\u4f20\u7edf\u5b66\u4e60\u65b9\u6cd5\uff09\uff0c\u5e76\u8bbe\u8ba1\u65b0\u5de5\u5177\u4ee5\u4fc3\u8fdb\u5143\u8ba4\u77e5\u548c\u53cd\u601d\u80fd\u529b\u7684\u57f9\u517b\u3002", "result": "\u521d\u6b65\u63d0\u51fa\u4e86\u4e00\u4e9b\u5de5\u5177\u8bbe\u8ba1\u601d\u8def\uff0c\u4f8b\u5982\u7ed3\u5408\u751f\u6210\u5f0fAI\u4e0e\u4f20\u7edf\u5b66\u4e60\u65b9\u5f0f\uff0c\u4ee5\u589e\u5f3a\u5b66\u751f\u7684\u5b66\u4e60\u4f53\u9a8c\u548c\u6280\u80fd\u53d1\u5c55\u3002", "conclusion": "\u901a\u8fc7\u6709\u610f\u8bc6\u5730\u8bbe\u8ba1\u9700\u8981\u66f4\u591a\u52aa\u529b\u7684AI\u5de5\u5177\uff0c\u53ef\u4ee5\u5e73\u8861\u5b66\u751f\u5bf9AI\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u4fc3\u8fdb\u5176\u5199\u4f5c\u3001\u6279\u5224\u6027\u601d\u7ef4\u548c\u5143\u8ba4\u77e5\u80fd\u529b\u7684\u5168\u9762\u53d1\u5c55\u3002"}}
{"id": "2509.00051", "pdf": "https://arxiv.org/pdf/2509.00051", "abs": "https://arxiv.org/abs/2509.00051", "authors": ["Faria Binte Kader", "Santu Karmaker"], "title": "A Survey on Evaluation Metrics for Music Generation", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "19 pages, 2 figures", "summary": "Despite significant advancements in music generation systems, the\nmethodologies for evaluating generated music have not progressed as expected\ndue to the complex nature of music, with aspects such as structure, coherence,\ncreativity, and emotional expressiveness. In this paper, we shed light on this\nresearch gap, introducing a detailed taxonomy for evaluation metrics for both\naudio and symbolic music representations. We include a critical review\nidentifying major limitations in current evaluation methodologies which\nincludes poor correlation between objective metrics and human perception,\ncross-cultural bias, and lack of standardization that hinders cross-model\ncomparisons. Addressing these gaps, we further propose future research\ndirections towards building a comprehensive evaluation framework for music\ngeneration evaluation.", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u6307\u6807\u7684\u8be6\u7ec6\u5206\u7c7b\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5982\u5ba2\u89c2\u6307\u6807\u4e0e\u4eba\u7c7b\u611f\u77e5\u7684\u4f4e\u76f8\u5173\u6027\u3001\u8de8\u6587\u5316\u504f\u89c1\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u3002", "motivation": "\u7531\u4e8e\u97f3\u4e50\u7684\u590d\u6742\u6027\uff08\u5982\u7ed3\u6784\u3001\u8fde\u8d2f\u6027\u3001\u521b\u9020\u529b\u548c\u60c5\u611f\u8868\u8fbe\uff09\uff0c\u73b0\u6709\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u7684\u8bc4\u4f30\u65b9\u6cd5\u8fdb\u5c55\u7f13\u6162\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u97f3\u9891\u548c\u7b26\u53f7\u97f3\u4e50\u8868\u793a\u7684\u8bc4\u4f30\u6307\u6807\u5206\u7c7b\uff0c\u5e76\u5bf9\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u8fdb\u884c\u4e86\u6279\u5224\u6027\u56de\u987e\u3002", "result": "\u6307\u51fa\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5982\u5ba2\u89c2\u6307\u6807\u4e0e\u4eba\u7c7b\u611f\u77e5\u76f8\u5173\u6027\u4f4e\u3001\u8de8\u6587\u5316\u504f\u89c1\u548c\u6807\u51c6\u5316\u4e0d\u8db3\u3002", "conclusion": "\u5efa\u8bae\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u6784\u5efa\u5168\u9762\u7684\u97f3\u4e50\u751f\u6210\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2509.00560", "pdf": "https://arxiv.org/pdf/2509.00560", "abs": "https://arxiv.org/abs/2509.00560", "authors": ["Can Cui", "Zilong Fu", "Penghe Huang", "Yuanyuan Li", "Wu Deng", "Dongyan Li"], "title": "An Efficient GNNs-to-KANs Distillation via Self-Attention Dynamic Sampling with Potential for Consumer Electronics Edge Deployment", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "Knowledge distillation (KD) is crucial for deploying deep learning models in\nresource-constrained edge environments, particularly within the consumer\nelectronics sector, including smart home devices, wearable technology, and\nmobile terminals. These applications place higher demands on model compression\nand inference speed, necessitating the transfer of knowledge from Graph Neural\nNetworks (GNNs) to more efficient Multi-Layer Perceptron (MLP) models. However,\ndue to their fixed activation functions and fully connected architecture, MLPs\nface challenges in rapidly capturing the complex neighborhood dependencies\nlearned by GNNs, thereby limiting their performance in edge environments. To\naddress these limitations, this paper introduces an innovative from GNNs to\nKolmogorov-Arnold Networks (KANs) knowledge distillation framework-Self\nAttention Dynamic Sampling Distillation (SA-DSD). This study improved Fourier\nKAN (FR-KAN) and replaced MLP with the improved FR-KAN+ as the student model.\nThrough the incorporation of learnable frequency bases and phase-shift\nmechanisms, along with algorithmic optimization, FR-KAN significantly improves\nits nonlinear fitting capability while effectively reducing computational\ncomplexity. Building on this, a margin-level sampling probability matrix, based\non teacher-student prediction consistency, is constructed, and an adaptive\nweighted loss mechanism is designed to mitigate performance degradation in the\nstudent model due to the lack of explicit neighborhood aggregation. Extensive\nexperiments conducted on six real-world datasets demonstrate that SA-DSD\nachieves performance improvements of 3.05%-3.62% over three GNN teacher models\nand 15.61% over the FR-KAN+ model. Moreover, when compared with key benchmark\nmodels, SA-DSD achieves a 16.96x reduction in parameter count and a 55.75%\ndecrease in inference time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSA-DSD\u7684\u521b\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5230Kolmogorov-Arnold\u7f51\u7edc\uff08KAN\uff09\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u6539\u8fdb\u4e86Fourier KAN\uff08FR-KAN\uff09\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u5b66\u751f\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u5728\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u975e\u7ebf\u6027\u62df\u5408\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660eSA-DSD\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\u3002", "motivation": "\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\uff08\u5982\u667a\u80fd\u5bb6\u5c45\u8bbe\u5907\u3001\u53ef\u7a7f\u6234\u6280\u672f\u548c\u79fb\u52a8\u7ec8\u7aef\uff09\u5bf9\u6a21\u578b\u538b\u7f29\u548c\u63a8\u7406\u901f\u5ea6\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u7531\u4e8e\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u96be\u4ee5\u6355\u6349\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u590d\u6742\u90bb\u57df\u4f9d\u8d56\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf Attention Dynamic Sampling Distillation\uff08SA-DSD\uff09\u7684\u6846\u67b6\uff0c\u6539\u8fdb\u4e86FR-KAN\u5e76\u5c06\u5176\u4f5c\u4e3a\u5b66\u751f\u6a21\u578b\u3002\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u9891\u7387\u57fa\u7840\u548c\u76f8\u4f4d\u504f\u79fb\u673a\u5236\uff0c\u7ed3\u5408\u7b97\u6cd5\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u975e\u7ebf\u6027\u62df\u5408\u80fd\u529b\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u5e08\u751f\u9884\u6d4b\u4e00\u81f4\u6027\u6784\u5efa\u4e86\u91c7\u6837\u6982\u7387\u77e9\u9635\uff0c\u5e76\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u52a0\u6743\u635f\u5931\u673a\u5236\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSA-DSD\u5728\u6027\u80fd\u4e0a\u6bd4GNN\u6559\u5e08\u6a21\u578b\u63d0\u9ad8\u4e863.05%-3.62%\uff0c\u6bd4FR-KAN+\u6a21\u578b\u63d0\u9ad8\u4e8615.61%\u3002\u540c\u65f6\uff0c\u4e0e\u5173\u952e\u57fa\u51c6\u6a21\u578b\u76f8\u6bd4\uff0cSA-DSD\u5b9e\u73b0\u4e8616.96\u500d\u7684\u53c2\u6570\u91cf\u51cf\u5c11\u548c55.75%\u7684\u63a8\u7406\u65f6\u95f4\u964d\u4f4e\u3002", "conclusion": "SA-DSF\u6846\u67b6\u901a\u8fc7\u6539\u8fdb\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u3002"}}
{"id": "2509.00633", "pdf": "https://arxiv.org/pdf/2509.00633", "abs": "https://arxiv.org/abs/2509.00633", "authors": ["Mehdi Elahi", "Mohamed R. Elshamy", "Abdel-Hameed A. Badawy", "Ahmad Patooghy"], "title": "On the Thermal Vulnerability of 3D-Stacked High-Bandwidth Memory Architectures", "categories": ["cs.AR", "cs.CE"], "comment": null, "summary": "3D-stacked High Bandwidth Memory (HBM) architectures provide high-performance\nmemory interactions to address the well-known performance challenge, namely the\nmemory wall. However, these architectures are susceptible to thermal\nvulnerabilities due to the inherent vertical adjacency that occurs during the\nmanufacturing process of HBM architectures. We anticipate that adversaries may\nexploit the intense vertical and lateral adjacency to design and develop\nthermal performance degradation attacks on the memory banks that host\ndata/instructions from victim applications. In such attacks, the adversary\nmanages to inject short and intense heat pulses from vertically and/or\nlaterally adjacent memory banks, creating a convergent thermal wave that\nmaximizes impact and delays the victim application from accessing its\ndata/instructions. As the attacking application does not access any\nout-of-range memory locations, it can bypass both design-time security tests\nand the operating system's memory management policies. In other words, since\nthe attack mimics legitimate workloads, it will be challenging to detect.", "AI": {"tldr": "3D\u5806\u53e0\u9ad8\u5e26\u5bbd\u5185\u5b58\uff08HBM\uff09\u67b6\u6784\u6613\u53d7\u70ed\u653b\u51fb\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u6ce8\u5165\u70ed\u8109\u51b2\u5f71\u54cd\u76f8\u90bb\u5185\u5b58\u5e93\uff0c\u7ed5\u8fc7\u5b89\u5168\u68c0\u6d4b\u3002", "motivation": "\u4e3a\u89e3\u51b3\u5185\u5b58\u5899\u95ee\u9898\uff0cHBM\u67b6\u6784\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u5185\u5b58\u4ea4\u4e92\uff0c\u4f46\u5176\u5782\u76f4\u5806\u53e0\u7ed3\u6784\u6613\u53d7\u70ed\u653b\u51fb\u3002", "method": "\u653b\u51fb\u8005\u901a\u8fc7\u76f8\u90bb\u5185\u5b58\u5e93\u6ce8\u5165\u77ed\u800c\u5f3a\u70c8\u7684\u70ed\u8109\u51b2\uff0c\u5f62\u6210\u70ed\u6ce2\u4ee5\u5ef6\u8fdf\u53d7\u5bb3\u5e94\u7528\u8bbf\u95ee\u6570\u636e\u3002", "result": "\u653b\u51fb\u6a21\u4eff\u5408\u6cd5\u8d1f\u8f7d\uff0c\u7ed5\u8fc7\u8bbe\u8ba1\u65f6\u5b89\u5168\u6d4b\u8bd5\u548c\u64cd\u4f5c\u7cfb\u7edf\u5185\u5b58\u7ba1\u7406\u7b56\u7565\uff0c\u96be\u4ee5\u68c0\u6d4b\u3002", "conclusion": "HBM\u67b6\u6784\u7684\u70ed\u653b\u51fb\u98ce\u9669\u9700\u5f15\u8d77\u91cd\u89c6\uff0c\u672a\u6765\u9700\u5f00\u53d1\u65b0\u7684\u5b89\u5168\u673a\u5236\u5e94\u5bf9\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2509.01083", "pdf": "https://arxiv.org/pdf/2509.01083", "abs": "https://arxiv.org/abs/2509.01083", "authors": ["Mingyu Yang", "Jae-Young Choi", "Kihyo Moon", "Minsung Jang", "Eunjoo Joen"], "title": "DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving", "categories": ["cs.DC", "cs.AI", "cs.IT", "math.IT", "I.2.7; C.2.4"], "comment": "10 pages, 9 figures. Preprint submitted to IEEE BigData 2025", "summary": "Speculative decoding accelerates large language model inference, but its\nreliance on a fixed speculation length is suboptimal in large-batch serving\nenvironments with diverse requests. This paper explores a new direction for\ndynamic adaptation by investigating a novel class of post-hoc, diagnostic\nsignals. We propose Dynamic Speculative Decoding Engine (DSDE), a training-free\nframework built on two primary components: (1) a predictive signal based on the\nvariance of the Kullback-Leibler (KLD) divergence, which diagnoses the\ngeneration's regional stability, and (2) an adaptive speculation length cap to\nmitigate the straggler problem in per-sequence decoding. Experiments\ndemonstrate the potential of using KLD-based stability signals for dynamic\nadaptation. An algorithm guided by these signals achieves end-to-end latency\ncompetitive with leading baselines and exhibits superior robustness across\ndiverse workloads. This robustness is particularly valuable in challenging\nlow-acceptance-rate regimes, where the proposed signal maintains its diagnostic\nutility. Collectively, these findings validate post-hoc signals as a valuable\ncomponent for building more robust and intelligent LLM inference systems, and\nhighlight a promising direction for future research on dynamic speculation\nlength adaptation.", "AI": {"tldr": "\u52a8\u6001\u63a8\u6d4b\u89e3\u7801\u5f15\u64ce\uff08DSDE\uff09\u901a\u8fc7KL\u6563\u5ea6\u65b9\u5dee\u548c\u81ea\u9002\u5e94\u63a8\u6d4b\u957f\u5ea6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u63a8\u6d4b\u89e3\u7801\u56fa\u5b9a\u63a8\u6d4b\u957f\u5ea6\u7684\u65b9\u5f0f\u5728\u5927\u6279\u91cf\u591a\u6837\u8bf7\u6c42\u73af\u5883\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u52a8\u6001\u9002\u5e94\u65b9\u6848\u3002", "method": "\u63d0\u51faDSDE\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8eKL\u6563\u5ea6\u65b9\u5dee\u7684\u9884\u6d4b\u4fe1\u53f7\u548c\u81ea\u9002\u5e94\u63a8\u6d4b\u957f\u5ea6\u4e0a\u9650\u7ec4\u4ef6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aKLD\u7a33\u5b9a\u6027\u4fe1\u53f7\u6709\u6548\uff0c\u7b97\u6cd5\u5728\u5ef6\u8fdf\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f4e\u63a5\u53d7\u7387\u573a\u666f\u3002", "conclusion": "\u4e8b\u540e\u4fe1\u53f7\u4e3a\u52a8\u6001\u63a8\u6d4b\u957f\u5ea6\u9002\u5e94\u63d0\u4f9b\u4e86\u65b0\u7814\u7a76\u65b9\u5411\uff0c\u6709\u671b\u6784\u5efa\u66f4\u9c81\u68d2\u7684LLM\u63a8\u7406\u7cfb\u7edf\u3002"}}
{"id": "2509.01517", "pdf": "https://arxiv.org/pdf/2509.01517", "abs": "https://arxiv.org/abs/2509.01517", "authors": ["Yuan-Hao Jiang", "Yijie Lu", "Ling Dai", "Jiatong Wang", "Ruijia Li", "Bo Jiang"], "title": "Agentic Workflow for Education: Concepts and Applications", "categories": ["cs.CY", "cs.AI", "cs.ET"], "comment": "Proceedings of the 33rd International Conference on Computers in\n  Education (ICCE 2025). Asia-Pacific Society for Computers in Education", "summary": "With the rapid advancement of Large Language Models (LLMs) and Artificial\nIntelligence (AI) agents, agentic workflows are showing transformative\npotential in education. This study introduces the Agentic Workflow for\nEducation (AWE), a four-component model comprising self-reflection, tool\ninvocation, task planning, and multi-agent collaboration. We distinguish AWE\nfrom traditional LLM-based linear interactions and propose a theoretical\nframework grounded in the von Neumann Multi-Agent System (MAS) architecture.\nThrough a paradigm shift from static prompt-response systems to dynamic,\nnonlinear workflows, AWE enables scalable, personalized, and collaborative task\nexecution. We further identify four core application domains: integrated\nlearning environments, personalized AI-assisted learning, simulation-based\nexperimentation, and data-driven decision-making. A case study on automated\nmath test generation shows that AWE-generated items are statistically\ncomparable to real exam questions, validating the model's effectiveness. AWE\noffers a promising path toward reducing teacher workload, enhancing\ninstructional quality, and enabling broader educational innovation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6559\u80b2\u4ee3\u7406\u5de5\u4f5c\u6d41\uff08AWE\uff09\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u975e\u7ebf\u6027\u6d41\u7a0b\u63d0\u5347\u6559\u80b2\u4efb\u52a1\u7684\u4e2a\u6027\u5316\u548c\u534f\u4f5c\u6027\uff0c\u5e76\u5728\u6570\u5b66\u6d4b\u8bd5\u751f\u6210\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548cAI\u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4ee3\u7406\u5de5\u4f5c\u6d41\u5728\u6559\u80b2\u4e2d\u5c55\u73b0\u51fa\u53d8\u9769\u6f5c\u529b\u3002\u4f5c\u8005\u65e8\u5728\u4ece\u4f20\u7edf\u7684\u9759\u6001\u63d0\u793a-\u54cd\u5e94\u7cfb\u7edf\u8f6c\u5411\u52a8\u6001\u975e\u7ebf\u6027\u5de5\u4f5c\u6d41\u3002", "method": "\u63d0\u51faAWE\u6a21\u578b\uff0c\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\uff1a\u81ea\u6211\u53cd\u601d\u3001\u5de5\u5177\u8c03\u7528\u3001\u4efb\u52a1\u89c4\u5212\u548c\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u5e76\u57fa\u4e8e\u51af\u00b7\u8bfa\u4f0a\u66fc\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u67b6\u6784\u6784\u5efa\u7406\u8bba\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u6570\u5b66\u6d4b\u8bd5\u751f\u6210\u6848\u4f8b\u9a8c\u8bc1\uff0cAWE\u751f\u6210\u7684\u9898\u76ee\u4e0e\u771f\u5b9e\u8003\u8bd5\u9898\u5728\u7edf\u8ba1\u4e0a\u5177\u6709\u53ef\u6bd4\u6027\u3002", "conclusion": "AWE\u4e3a\u51cf\u5c11\u6559\u5e08\u5de5\u4f5c\u91cf\u3001\u63d0\u5347\u6559\u5b66\u8d28\u91cf\u548c\u63a8\u52a8\u6559\u80b2\u521b\u65b0\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2509.00293", "pdf": "https://arxiv.org/pdf/2509.00293", "abs": "https://arxiv.org/abs/2509.00293", "authors": ["Aryan Poduri", "Yashwant Tailor"], "title": "Illuminating Patterns of Divergence: DataDios SmartDiff for Large-Scale Data Difference Analysis", "categories": ["cs.DB", "cs.LG", "I.2.6; H.2.8; D.1.3"], "comment": "10 pages, 4 figures", "summary": "Data engineering workflows require reliable differencing across files,\ndatabases, and query outputs, yet existing tools falter under schema drift,\nheterogeneous types, and limited explainability. SmartDiff is a unified system\nthat combines schema-aware mapping, type-specific comparators, and parallel\nexecution. It aligns evolving schemas, compares structured and semi-structured\ndata (strings, numbers, dates, JSON/XML), and clusters results with labels that\nexplain how and why differences occur. On multi-million-row datasets, SmartDiff\nachieves over 95 percent precision and recall, runs 30 to 40 percent faster,\nand uses 30 to 50 percent less memory than baselines; in user studies, it\nreduces root-cause analysis time from 10 hours to 12 minutes. An LLM-assisted\nlabeling pipeline produces deterministic, schema-valid multilabel explanations\nusing retrieval augmentation and constrained decoding; ablations show further\ngains in label accuracy and time to diagnosis over rules-only baselines. These\nresults indicate SmartDiff's utility for migration validation, regression\ntesting, compliance auditing, and continuous data quality monitoring. Index\nTerms: data differencing, schema evolution, data quality, parallel processing,\nclustering, explainable validation, big data", "AI": {"tldr": "SmartDiff\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u9ad8\u6548\u53ef\u9760\u5730\u6bd4\u8f83\u6570\u636e\uff0c\u652f\u6301\u6a21\u5f0f\u6f02\u79fb\u548c\u5f02\u6784\u7c7b\u578b\uff0c\u63d0\u4f9b\u89e3\u91ca\u6027\u6807\u7b7e\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u8bca\u65ad\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5728\u5904\u7406\u6a21\u5f0f\u6f02\u79fb\u3001\u5f02\u6784\u7c7b\u578b\u548c\u89e3\u91ca\u6027\u4e0d\u8db3\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u6613\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "SmartDiff\u7ed3\u5408\u6a21\u5f0f\u611f\u77e5\u6620\u5c04\u3001\u7c7b\u578b\u7279\u5b9a\u6bd4\u8f83\u5668\u548c\u5e76\u884c\u6267\u884c\uff0c\u652f\u6301\u7ed3\u6784\u5316\u4e0e\u534a\u7ed3\u6784\u5316\u6570\u636e\u5bf9\u9f50\uff0c\u5e76\u751f\u6210\u89e3\u91ca\u6027\u6807\u7b7e\u3002", "result": "\u5728\u591a\u767e\u4e07\u884c\u6570\u636e\u96c6\u4e0a\uff0cSmartDiff\u8fbe\u523095%\u4ee5\u4e0a\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\uff0c\u901f\u5ea6\u63d0\u534730-40%\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c1130-50%\uff0c\u6839\u56e0\u5206\u6790\u65f6\u95f4\u4ece10\u5c0f\u65f6\u7f29\u77ed\u81f312\u5206\u949f\u3002", "conclusion": "SmartDiff\u5728\u6570\u636e\u8fc1\u79fb\u9a8c\u8bc1\u3001\u56de\u5f52\u6d4b\u8bd5\u3001\u5408\u89c4\u5ba1\u8ba1\u53ca\u6301\u7eed\u6570\u636e\u8d28\u91cf\u76d1\u6d4b\u4e2d\u5177\u6709\u663e\u8457\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.00256", "pdf": "https://arxiv.org/pdf/2509.00256", "abs": "https://arxiv.org/abs/2509.00256", "authors": ["Yutong Wang", "Cindy Rubio-Gonz\u00e1lez"], "title": "LLM-Based Program Generation for Triggering Numerical Inconsistencies Across Compilers", "categories": ["cs.SE"], "comment": null, "summary": "Floating-point inconsistencies across compilers can undermine the reliability\nof numerical software. We present LLM4FP, the first framework that uses Large\nLanguage Models (LLMs) to generate floating-point programs specifically\ndesigned to trigger such inconsistencies. LLM4FP combines Grammar-Based\nGeneration and Feedback-Based Mutation to produce diverse and valid programs.\nWe evaluate LLM4FP across multiple compilers and optimization levels, measuring\ninconsistency rate, time cost, and program diversity. LLM4FP detects over twice\nas many inconsistencies compared to the state-of-the-art tool, Varity. Notably,\nmost of the inconsistencies involve real-valued differences, rather than\nextreme values like NaN or infinities. LLM4FP also uncovers inconsistencies\nacross a wider range of optimization levels, and finds the most mismatches\nbetween host and device compilers. These results show that LLM-guided program\ngeneration improves the detection of numerical inconsistencies.", "AI": {"tldr": "LLM4FP\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6d6e\u52a8\u70b9\u7a0b\u5e8f\uff0c\u4ee5\u68c0\u6d4b\u7f16\u8bd1\u5668\u4e0d\u4e00\u81f4\u6027\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u5de5\u5177Varity\u3002", "motivation": "\u89e3\u51b3\u4e0d\u540c\u7f16\u8bd1\u5668\u95f4\u6d6e\u52a8\u70b9\u4e0d\u4e00\u81f4\u6027\u5bf9\u6570\u503c\u8f6f\u4ef6\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u8bed\u6cd5\u7684\u751f\u6210\u548c\u57fa\u4e8e\u53cd\u9988\u7684\u53d8\u5f02\uff0c\u751f\u6210\u591a\u6837\u5316\u4e14\u6709\u6548\u7684\u7a0b\u5e8f\u3002", "result": "LLM4FP\u68c0\u6d4b\u5230\u7684\u4e0d\u4e00\u81f4\u6027\u662fVarity\u7684\u4e24\u500d\u4ee5\u4e0a\uff0c\u4e14\u591a\u6570\u4e3a\u5b9e\u9645\u6570\u503c\u5dee\u5f02\u3002", "conclusion": "LLM\u5f15\u5bfc\u7684\u7a0b\u5e8f\u751f\u6210\u663e\u8457\u63d0\u5347\u4e86\u6570\u503c\u4e0d\u4e00\u81f4\u6027\u7684\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2509.00184", "pdf": "https://arxiv.org/pdf/2509.00184", "abs": "https://arxiv.org/abs/2509.00184", "authors": ["Alexandru Baltag", "Malvin Gattinger", "Djanira Gomes"], "title": "Virtual Group Knowledge and Group Belief in Topological Evidence Models (Extended Version)", "categories": ["cs.AI", "cs.LO", "cs.MA", "03B42", "I.2.4"], "comment": null, "summary": "We study notions of (virtual) group knowledge and group belief within\nmulti-agent evidence models, obtained by extending the topological semantics of\nevidence-based belief and fallible knowledge from individuals to groups. We\ncompletely axiomatize and show the decidability of the logic of (\"hard\" and\n\"soft\") group evidence, and do the same for an especially interesting fragment\nof it: the logic of group knowledge and group belief. We also extend these\nlanguages with dynamic evidence-sharing operators, and completely axiomatize\nthe corresponding logics, showing that they are co-expressive with their static\nbases.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u667a\u80fd\u4f53\u8bc1\u636e\u6a21\u578b\u4e2d\u7684\u7fa4\u4f53\u77e5\u8bc6\u4e0e\u4fe1\u5ff5\uff0c\u901a\u8fc7\u62d3\u6251\u8bed\u4e49\u6269\u5c55\u4e86\u4e2a\u4f53\u7684\u8bc1\u636e\u57fa\u7840\u4fe1\u5ff5\u4e0e\u53ef\u9519\u77e5\u8bc6\u5230\u7fa4\u4f53\u5c42\u9762\u3002", "motivation": "\u63a2\u7d22\u7fa4\u4f53\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u77e5\u8bc6\u4e0e\u4fe1\u5ff5\u5f62\u5f0f\u5316\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u62d3\u6251\u8bed\u4e49\u6269\u5c55\u4e2a\u4f53\u8bc1\u636e\u6a21\u578b\u5230\u7fa4\u4f53\u5c42\u9762\uff0c\u5e76\u63d0\u51fa\u52a8\u6001\u8bc1\u636e\u5171\u4eab\u7b97\u5b50\u3002", "result": "\u5b8c\u5168\u516c\u7406\u5316\u5e76\u8bc1\u660e\u4e86\u7fa4\u4f53\u8bc1\u636e\u903b\u8f91\u53ca\u7247\u6bb5\u7684\u53ef\u5224\u5b9a\u6027\uff0c\u52a8\u6001\u6269\u5c55\u4e0e\u539f\u4f53\u7cfb\u7b49\u4ef7\u3002", "conclusion": "\u8bc1\u660e\u52a8\u6001\u8bc1\u636e\u5171\u4eab\u903b\u8f91\u4e0e\u9759\u6001\u57fa\u7840\u903b\u8f91\u7684\u8868\u8fbe\u80fd\u529b\u76f8\u540c\u3002"}}
{"id": "2509.00541", "pdf": "https://arxiv.org/pdf/2509.00541", "abs": "https://arxiv.org/abs/2509.00541", "authors": ["Siyi Liu", "Weiming Chen", "Yushun Tang", "Zhihai He"], "title": "LatentEdit: Adaptive Latent Control for Consistent Semantic Editing", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Accepted by PRCV 2025", "summary": "Diffusion-based Image Editing has achieved significant success in recent\nyears. However, it remains challenging to achieve high-quality image editing\nwhile maintaining the background similarity without sacrificing speed or memory\nefficiency. In this work, we introduce LatentEdit, an adaptive latent fusion\nframework that dynamically combines the current latent code with a reference\nlatent code inverted from the source image. By selectively preserving source\nfeatures in high-similarity, semantically important regions while generating\ntarget content in other regions guided by the target prompt, LatentEdit enables\nfine-grained, controllable editing. Critically, the method requires no internal\nmodel modifications or complex attention mechanisms, offering a lightweight,\nplug-and-play solution compatible with both UNet-based and DiT-based\narchitectures. Extensive experiments on the PIE-Bench dataset demonstrate that\nour proposed LatentEdit achieves an optimal balance between fidelity and\neditability, outperforming the state-of-the-art method even in 8-15 steps.\nAdditionally, its inversion-free variant further halves the number of neural\nfunction evaluations and eliminates the need for storing any intermediate\nvariables, substantially enhancing real-time deployment efficiency.", "AI": {"tldr": "LatentEdit\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u6f5c\u5728\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u7ed3\u5408\u5f53\u524d\u6f5c\u5728\u4ee3\u7801\u548c\u53c2\u8003\u6f5c\u5728\u4ee3\u7801\uff0c\u5728\u4fdd\u6301\u80cc\u666f\u76f8\u4f3c\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\u7f16\u8f91\u3002\u5176\u65e0\u9700\u6a21\u578b\u4fee\u6539\u6216\u590d\u6742\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8f7b\u91cf\u4e14\u517c\u5bb9\u591a\u79cd\u67b6\u6784\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6269\u6563\u57fa\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u5728\u4fdd\u6301\u80cc\u666f\u76f8\u4f3c\u6027\u548c\u9ad8\u6548\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u66f4\u7cbe\u7ec6\u53ef\u63a7\u7684\u7f16\u8f91\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u81ea\u9002\u5e94\u6f5c\u5728\u878d\u5408\u6846\u67b6\u52a8\u6001\u7ed3\u5408\u5f53\u524d\u548c\u53c2\u8003\u6f5c\u5728\u4ee3\u7801\uff0c\u9009\u62e9\u6027\u4fdd\u7559\u9ad8\u76f8\u4f3c\u5ea6\u533a\u57df\u7684\u6e90\u7279\u5f81\uff0c\u5e76\u751f\u6210\u76ee\u6807\u5185\u5bb9\u3002", "result": "\u5728PIE-Bench\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u8861\u4e86\u4fdd\u771f\u5ea6\u548c\u53ef\u7f16\u8f91\u6027\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u4e14\u57288-15\u6b65\u5185\u9ad8\u6548\u5b8c\u6210\u3002", "conclusion": "LatentEdit\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u5373\u63d2\u5373\u7528\u7684\u9ad8\u6548\u56fe\u50cf\u7f16\u8f91\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2509.02428", "pdf": "https://arxiv.org/pdf/2509.02428", "abs": "https://arxiv.org/abs/2509.02428", "authors": ["Yongwei Yuan", "Zhe Zhou", "Julia Belyakova", "Benjamin Delaware", "Suresh Jagannathan"], "title": "From Traces to Program Incorrectness: A Type-Theoretic Approach", "categories": ["cs.PL"], "comment": null, "summary": "We present a type-theoretic framework for reasoning about incorrectness in\nfunctional programs that interact with effectful, opaque library APIs. Our\napproach centers on traces -- temporally-ordered sequences of library API\ninvocations -- which naturally characterize both the preconditions of\nindividual APIs and their composite behavior. We represent these traces using\nsymbolic regular expressions (SREs), enabling formal specification of incorrect\nabstract data type (ADT) behaviors across function boundaries. The core\ncontribution is a novel type inference algorithm that operates modulo specified\nincorrectness properties and leverages the symbolic finite automata (SFAs)\nrepresentations of regexes for compositional reasoning of traces. When the\nalgorithm succeeds, the inferred types witness that an ADT implementation can\nexhibit some subset of the specified incorrect behaviors. This represents the\nfirst systematic approach to underapproximate reasoning against trace-based\nincorrectness specifications, enabling a new form of trace-guided compositional\nanalysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7c7b\u578b\u7406\u8bba\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u529f\u80fd\u7a0b\u5e8f\u4e0e\u5e93API\u4ea4\u4e92\u65f6\u7684\u9519\u8bef\u884c\u4e3a\uff0c\u5229\u7528\u7b26\u53f7\u6b63\u5219\u8868\u8fbe\u5f0f\uff08SREs\uff09\u548c\u7b26\u53f7\u6709\u9650\u81ea\u52a8\u673a\uff08SFAs\uff09\u8fdb\u884c\u63a8\u7406\u3002", "motivation": "\u7814\u7a76\u529f\u80fd\u7a0b\u5e8f\u5728\u8c03\u7528\u5916\u90e8\u5e93API\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u9519\u8bef\u884c\u4e3a\uff0c\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u75d5\u8ff9\uff08API\u8c03\u7528\u7684\u65f6\u95f4\u5e8f\u5217\uff09\u548cSREs\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7c7b\u578b\u63a8\u65ad\u7b97\u6cd5\uff0c\u901a\u8fc7SFAs\u7ec4\u5408\u63a8\u7406\u75d5\u8ff9\u3002", "result": "\u7b97\u6cd5\u6210\u529f\u65f6\uff0c\u63a8\u65ad\u7684\u7c7b\u578b\u80fd\u591f\u8bc1\u660eADT\u5b9e\u73b0\u53ef\u80fd\u8868\u73b0\u51fa\u6307\u5b9a\u7684\u9519\u8bef\u884c\u4e3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9996\u6b21\u7cfb\u7edf\u5316\u5730\u5b9e\u73b0\u4e86\u57fa\u4e8e\u75d5\u8ff9\u7684\u9519\u8bef\u884c\u4e3a\u63a8\u7406\uff0c\u4e3a\u7ec4\u5408\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2509.00621", "pdf": "https://arxiv.org/pdf/2509.00621", "abs": "https://arxiv.org/abs/2509.00621", "authors": ["Osama Abu Hamdan", "Hao Che", "Engin Arslan", "Md Arifuzzaman"], "title": "FLEET: A Federated Learning Emulation and Evaluation Testbed for Holistic Research", "categories": ["cs.NI"], "comment": null, "summary": "Federated Learning (FL) presents a robust paradigm for privacy-preserving,\ndecentralized machine learning. However, a significant gap persists between the\ntheoretical design of FL algorithms and their practical performance, largely\nbecause existing evaluation tools often fail to model realistic operational\nconditions. Many testbeds oversimplify the critical dynamics among algorithmic\nefficiency, client-level heterogeneity, and continuously evolving network\ninfrastructure. To address this challenge, we introduce the Federated Learning\nEmulation and Evaluation Testbed (FLEET). This comprehensive platform provides\na scalable and configurable environment by integrating a versatile,\nframework-agnostic learning component with a high-fidelity network emulator.\nFLEET supports diverse machine learning frameworks, customizable real-world\nnetwork topologies, and dynamic background traffic generation. The testbed\ncollects holistic metrics that correlate algorithmic outcomes with detailed\nnetwork statistics. By unifying the entire experiment configuration, FLEET\nenables researchers to systematically investigate how network constraints, such\nas limited bandwidth, high latency, and packet loss, affect the convergence and\nefficiency of FL algorithms. This work provides the research community with a\nrobust tool to bridge the gap between algorithmic theory and real-world network\nconditions, promoting the holistic and reproducible evaluation of federated\nlearning systems.", "AI": {"tldr": "FLEET\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7b97\u6cd5\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u6a21\u62df\u771f\u5b9e\u7f51\u7edc\u6761\u4ef6\u7684\u95ee\u9898\uff0c\u652f\u6301\u591a\u6837\u5316\u7684\u7f51\u7edc\u73af\u5883\u548c\u673a\u5668\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u8bc4\u4f30\u5de5\u5177\u5e38\u5ffd\u7565\u5b9e\u9645\u7f51\u7edc\u6761\u4ef6\uff0c\u5bfc\u81f4\u7b97\u6cd5\u7406\u8bba\u4e0e\u5b9e\u9645\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u5f00\u53d1FLEET\u5e73\u53f0\uff0c\u6574\u5408\u9ad8\u4fdd\u771f\u7f51\u7edc\u6a21\u62df\u5668\u548c\u901a\u7528\u5b66\u4e60\u7ec4\u4ef6\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u7f51\u7edc\u62d3\u6251\u548c\u52a8\u6001\u6d41\u91cf\u751f\u6210\u3002", "result": "FLEET\u80fd\u7cfb\u7edf\u8bc4\u4f30\u7f51\u7edc\u7ea6\u675f\u5bf9FL\u7b97\u6cd5\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u5b9e\u9a8c\u73af\u5883\u3002", "conclusion": "FLEET\u586b\u8865\u4e86FL\u7406\u8bba\u4e0e\u5b9e\u9645\u7f51\u7edc\u6761\u4ef6\u95f4\u7684\u9e3f\u6c9f\uff0c\u4fc3\u8fdb\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u5168\u9762\u8bc4\u4f30\u3002"}}
{"id": "2509.00944", "pdf": "https://arxiv.org/pdf/2509.00944", "abs": "https://arxiv.org/abs/2509.00944", "authors": ["Clara Sayffaerth", "Annika K\u00f6hler", "Julian Rasch", "Albrecht Schmidt", "Florian M\u00fcller"], "title": "Through the Expert's Eyes: Exploring Asynchronous Expert Perspectives and Gaze Visualizations in XR", "categories": ["cs.HC"], "comment": "11 pages, IEEE International Symposium on Mixed and Augmented Reality\n  (ISMAR)", "summary": "Transferring knowledge across generations is fundamental to human\ncivilization, yet the challenge of passing on complex practical skills\npersists. Methods without a physically present instructor, such as videos,\noften fail to explain complex manual tasks, where spatial and social factors\nare critical. Technologies such as eXtended Reality and Artificial Intelligence\nhold the potential to retain expert knowledge and facilitate the creation of\ntailored, contextualized, and asynchronous explanations regardless of time and\nplace. In contrast to videos, the learner's perspective can be different from\nthe recorded perspective in XR. This paper investigates the impact of\nasynchronous first- and third-person perspectives and gaze visualizations on\nefficiency, feeling of embodiment, and connectedness during manual tasks. The\nempirical results of our study (N=36) show that the first-person perspective is\nbetter in quantitative measures and preferred by users. We identify best\npractices for presenting preserved knowledge and provide guidelines for\ndesigning future systems.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u5728\u590d\u6742\u624b\u52a8\u4efb\u52a1\u7684\u6559\u5b66\u4e2d\u8868\u73b0\u4f18\u4e8e\u7b2c\u4e09\u4eba\u79f0\u89c6\u89d2\uff0c\u4e14\u66f4\u53d7\u7528\u6237\u9752\u7750\u3002", "motivation": "\u89e3\u51b3\u8de8\u4ee3\u4f20\u9012\u590d\u6742\u5b9e\u8df5\u6280\u80fd\u7684\u95ee\u9898\uff0c\u63a2\u7d22XR\u548cAI\u6280\u672f\u5728\u4fdd\u7559\u4e13\u5bb6\u77e5\u8bc6\u548c\u63d0\u4f9b\u4e2a\u6027\u5316\u6559\u5b66\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc736\u4eba\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u5f02\u6b65\u7b2c\u4e00\u4eba\u79f0\u548c\u7b2c\u4e09\u4eba\u79f0\u89c6\u89d2\u53ca\u89c6\u7ebf\u53ef\u89c6\u5316\u5bf9\u6548\u7387\u3001\u4f53\u73b0\u611f\u548c\u8fde\u63a5\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u5728\u91cf\u5316\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4e14\u7528\u6237\u504f\u597d\u5ea6\u66f4\u9ad8\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u5c55\u793a\u4fdd\u7559\u77e5\u8bc6\u7684\u6700\u4f73\u5b9e\u8df5\u548c\u672a\u6765\u7cfb\u7edf\u8bbe\u8ba1\u6307\u5357\u3002"}}
{"id": "2509.00055", "pdf": "https://arxiv.org/pdf/2509.00055", "abs": "https://arxiv.org/abs/2509.00055", "authors": ["Tongtong Feng", "Xin Wang", "Feilin Han", "Leping Zhang", "Wenwu Zhu"], "title": "U2UData-2: A Scalable Swarm UAVs Autonomous Flight Dataset for Long-horizon Tasks", "categories": ["cs.RO", "cs.AI", "cs.MA", "cs.MM"], "comment": null, "summary": "Swarm UAV autonomous flight for Long-Horizon (LH) tasks is crucial for\nadvancing the low-altitude economy. However, existing methods focus only on\nspecific basic tasks due to dataset limitations, failing in real-world\ndeployment for LH tasks. LH tasks are not mere concatenations of basic tasks,\nrequiring handling long-term dependencies, maintaining persistent states, and\nadapting to dynamic goal shifts. This paper presents U2UData-2, the first\nlarge-scale swarm UAV autonomous flight dataset for LH tasks and the first\nscalable swarm UAV data online collection and algorithm closed-loop\nverification platform. The dataset is captured by 15 UAVs in autonomous\ncollaborative flights for LH tasks, comprising 12 scenes, 720 traces, 120\nhours, 600 seconds per trajectory, 4.32M LiDAR frames, and 12.96M RGB frames.\nThis dataset also includes brightness, temperature, humidity, smoke, and\nairflow values covering all flight routes. The platform supports the\ncustomization of simulators, UAVs, sensors, flight algorithms, formation modes,\nand LH tasks. Through a visual control window, this platform allows users to\ncollect customized datasets through one-click deployment online and to verify\nalgorithms by closed-loop simulation. U2UData-2 also introduces an LH task for\nwildlife conservation and provides comprehensive benchmarks with 9 SOTA models.\nU2UData-2 can be found at https://fengtt42.github.io/U2UData-2/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u957f\u65f6\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u96c6\u7fa4\u81ea\u4e3b\u98de\u884c\u6570\u636e\u96c6U2UData-2\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6570\u636e\u6536\u96c6\u4e0e\u7b97\u6cd5\u9a8c\u8bc1\u5e73\u53f0\uff0c\u652f\u6301\u591a\u6837\u5316\u7684\u573a\u666f\u548c\u4efb\u52a1\u5b9a\u5236\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u5173\u6ce8\u57fa\u7840\u4efb\u52a1\uff0c\u53d7\u9650\u4e8e\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u957f\u65f6\u4efb\u52a1\u7684\u771f\u5b9e\u90e8\u7f72\uff0c\u9700\u8981\u5904\u7406\u957f\u671f\u4f9d\u8d56\u3001\u72b6\u6001\u4fdd\u6301\u548c\u76ee\u6807\u52a8\u6001\u53d8\u5316\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faU2UData-2\u6570\u636e\u96c6\u548c\u5728\u7ebf\u6536\u96c6\u4e0e\u95ed\u73af\u9a8c\u8bc1\u5e73\u53f0\uff0c\u5305\u542b12\u4e2a\u573a\u666f\u3001720\u6761\u8f68\u8ff9\u3001120\u5c0f\u65f6\u98de\u884c\u6570\u636e\uff0c\u652f\u6301\u591a\u79cd\u4f20\u611f\u5668\u548c\u4efb\u52a1\u5b9a\u5236\u3002", "result": "\u6570\u636e\u96c6\u89c4\u6a21\u5927\u3001\u8986\u76d6\u5168\u9762\uff0c\u5e73\u53f0\u652f\u6301\u9ad8\u6548\u7b97\u6cd5\u9a8c\u8bc1\uff0c\u5e76\u9488\u5bf9\u91ce\u751f\u52a8\u7269\u4fdd\u62a4\u4efb\u52a1\u63d0\u4f9b\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "U2UData-2\u4e3a\u957f\u65f6\u4efb\u52a1\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u63a8\u52a8\u4e86\u65e0\u4eba\u673a\u96c6\u7fa4\u81ea\u4e3b\u98de\u884c\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.01020", "pdf": "https://arxiv.org/pdf/2509.01020", "abs": "https://arxiv.org/abs/2509.01020", "authors": ["Elena Espinosa", "Rub\u00e9n Rodr\u00edguez \u00c1lvarez", "Jos\u00e9 Miranda", "Rafael Larrosa", "Miguel Pe\u00f3n-Quir\u00f3s", "Oscar Plata", "David Atienza"], "title": "GeneTEK: Low-power, high-performance and scalable genome sequence matching in FPGAs", "categories": ["cs.AR", "cs.PF"], "comment": null, "summary": "The advent of next-generation sequencing (NGS) has revolutionized genomic\nresearch by enabling high-throughput data generation through parallel\nsequencing of a diverse range of organisms at significantly reduced costs. This\nbreakthrough has unleashed a \"Cambrian explosion\" in genomic data volume and\ndiversity. This volume of workloads places genomics among the top four big data\nchallenges anticipated for this decade. In this context, pairwise sequence\nalignment represents a very time- and energy-consuming step in common\nbioinformatics pipelines. Speeding up this step requires the implementation of\nheuristic approaches, optimized algorithms, and/or hardware acceleration.\n  Whereas state-of-the-art CPU and GPU implementations have demonstrated\nsignificant performance gains, recent field programmable gate array (FPGA)\nimplementations have shown improved energy efficiency. However, the latter\noften suffer from limited scalability due to constraints on hardware resources\nwhen aligning longer sequences. In this work, we present a scalable and\nflexible FPGA-based accelerator template that implements Myers's algorithm\nusing high-level synthesis and a worker-based architecture. GeneTEK, an\ninstance of this accelerator template in a Xilinx Zynq UltraScale+ FPGA,\noutperforms state-of-the-art CPU and GPU implementations in both speed and\nenergy efficiency, while overcoming scalability limitations of current FPGA\napproaches. Specifically, GeneTEK achieves at least a 19.4% increase in\nexecution speed and up to 62x reduction in energy consumption compared to\nleading CPU and GPU solutions, while fitting comparison matrices up to 72%\nlarger compared to previous FPGA solutions. These results reaffirm the\npotential of FPGAs as an energy-efficient platform for scalable genomic\nworkloads.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u53ef\u6269\u5c55\u52a0\u901f\u5668\u6a21\u677fGeneTEK\uff0c\u7528\u4e8e\u57fa\u56e0\u7ec4\u5e8f\u5217\u6bd4\u5bf9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901f\u5ea6\u548c\u80fd\u6548\uff0c\u514b\u670d\u4e86\u73b0\u6709FPGA\u65b9\u6cd5\u7684\u6269\u5c55\u9650\u5236\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u6d4b\u5e8f\u6280\u672f\u7684\u9ad8\u901a\u91cf\u6570\u636e\u751f\u6210\u5e26\u6765\u4e86\u5de8\u5927\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u5c24\u5176\u662f\u5e8f\u5217\u6bd4\u5bf9\u6b65\u9aa4\u8017\u65f6\u8017\u80fd\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u91c7\u7528\u9ad8\u7ea7\u7efc\u5408\u548c\u57fa\u4e8e\u5de5\u4f5c\u8005\u7684\u67b6\u6784\uff0c\u5728FPGA\u4e0a\u5b9e\u73b0Myers\u7b97\u6cd5\uff0c\u6784\u5efa\u4e86GeneTEK\u52a0\u901f\u5668\u6a21\u677f\u3002", "result": "GeneTEK\u5728\u901f\u5ea6\u548c\u80fd\u6548\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u7684CPU\u548cGPU\u5b9e\u73b0\uff0c\u6267\u884c\u901f\u5ea6\u63d0\u9ad8\u4e86\u81f3\u5c1119.4%\uff0c\u80fd\u8017\u964d\u4f4e\u9ad8\u8fbe62\u500d\uff0c\u540c\u65f6\u652f\u6301\u66f4\u5927\u7684\u6bd4\u5bf9\u77e9\u9635\u3002", "conclusion": "FPGA\u5728\u53ef\u6269\u5c55\u57fa\u56e0\u7ec4\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u5c55\u73b0\u51fa\u9ad8\u6548\u7684\u6f5c\u529b\uff0cGeneTEK\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00764", "pdf": "https://arxiv.org/pdf/2509.00764", "abs": "https://arxiv.org/abs/2509.00764", "authors": ["Pragun Jaswal", "L. Hemanth Krishna", "B. Srinivasu"], "title": "Low Power Approximate Multiplier Architecture for Deep Neural Networks", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "This paper proposes an low power approximate multiplier architecture for deep\nneural network (DNN) applications. A 4:2 compressor, introducing only a single\ncombination error, is designed and integrated into an 8x8 unsigned multiplier.\nThis integration significantly reduces the usage of exact compressors while\npreserving low error rates. The proposed multiplier is employed within a custom\nconvolution layer and evaluated on neural network tasks, including image\nrecognition and denoising. Hardware evaluation demonstrates that the proposed\ndesign achieves up to 30.24% energy savings compared to the best among existing\nmultipliers. In image denoising, the custom approximate convolution layer\nachieves improved Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity\nIndex Measure (SSIM) compared to other approximate designs. Additionally, when\napplied to handwritten digit recognition, the model maintains high\nclassification accuracy. These results demonstrate that the proposed\narchitecture offers a favorable balance between energy efficiency and\ncomputational precision, making it suitable for low-power AI hardware\nimplementations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u529f\u8017\u8fd1\u4f3c\u4e58\u6cd5\u5668\u67b6\u6784\uff0c\u7528\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4e00\u79cd\u4ec5\u5f15\u5165\u5355\u4e00\u7ec4\u5408\u9519\u8bef\u76844:2\u538b\u7f29\u5668\uff0c\u5b9e\u73b0\u4e86\u80fd\u8017\u8282\u770130.24%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u4f4e\u529f\u8017\u786c\u4ef6\u4e0a\u7684\u9ad8\u6548\u5b9e\u73b0\u9700\u8981\u5e73\u8861\u80fd\u8017\u4e0e\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u800c\u4f20\u7edf\u4e58\u6cd5\u5668\u80fd\u8017\u8f83\u9ad8\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4ec5\u5f15\u5165\u5355\u4e00\u7ec4\u5408\u9519\u8bef\u76844:2\u538b\u7f29\u5668\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u52308x8\u65e0\u7b26\u53f7\u4e58\u6cd5\u5668\u4e2d\uff0c\u964d\u4f4e\u4e86\u7cbe\u786e\u538b\u7f29\u5668\u7684\u4f7f\u7528\u3002", "result": "\u5728\u56fe\u50cf\u53bb\u566a\u4efb\u52a1\u4e2d\u63d0\u5347\u4e86PSNR\u548cSSIM\uff0c\u5728\u624b\u5199\u6570\u5b57\u8bc6\u522b\u4e2d\u4fdd\u6301\u4e86\u9ad8\u5206\u7c7b\u7cbe\u5ea6\uff0c\u80fd\u8017\u8282\u7701\u8fbe30.24%\u3002", "conclusion": "\u8be5\u67b6\u6784\u5728\u80fd\u8017\u4e0e\u8ba1\u7b97\u7cbe\u5ea6\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u4f4e\u529f\u8017AI\u786c\u4ef6\u5b9e\u73b0\u3002"}}
{"id": "2509.01118", "pdf": "https://arxiv.org/pdf/2509.01118", "abs": "https://arxiv.org/abs/2509.01118", "authors": ["Jinyuan Chen"], "title": "Ocior: Ultra-Fast Asynchronous Leaderless Consensus with Two-Round Finality, Linear Overhead, and Adaptive Security", "categories": ["cs.DC"], "comment": "52 pages", "summary": "In this work, we propose Ocior, a practical asynchronous Byzantine\nfault-tolerant (BFT) consensus protocol that achieves the optimal performance\nin resilience, communication, computation, and round complexity. Unlike\ntraditional BFT consensus protocols, Ocior processes incoming transactions\nindividually and concurrently using parallel instances of consensus. While\nleader-based consensus protocols rely on a designated leader to propose\ntransactions, Ocior is a leaderless consensus protocol that guarantees stable\nliveness. Ocior achieves: 1) Optimal resilience: Ocior tolerates up to $t$\nfaulty nodes controlled by an adaptive adversary, for $n\\geq 3t+1$. 2) Optimal\ncommunication complexity: The total expected communication per transaction is\n$O(n)$. 3) Optimal (or near-optimal) computation complexity: The total\ncomputation per transaction is $O(n)$ in the best case, or $O(n \\log^2 n)$ in\nthe worst case. 4) Optimal round complexity: A legitimate two-party transaction\ncan be finalized with a good-case latency of two asynchronous rounds, for any\n$n\\geq 3t+1$. The good case in terms of latency refers to the scenario where\nthe transaction is proposed by any (not necessarily designated) honest node. A\ntwo-party transaction involves the transfer of digital assets from one user (or\ngroup of users) to one or more recipients. To support efficient consensus, we\nintroduce a novel non-interactive threshold signature (TS) scheme called\nOciorBLSts. It offers fast signature aggregation, and is adaptively secure.\nOciorBLSts achieves a signature aggregation computation cost of only $O(n)$ for\nthe best case. Moreover, OciorBLSts supports the property of Instantaneous TS\nAggregation. This enables real-time aggregation of partial signatures as they\narrive, reducing waiting time and improving responsiveness.", "AI": {"tldr": "Ocior\u662f\u4e00\u79cd\u5f02\u6b65\u62dc\u5360\u5ead\u5bb9\u9519\u5171\u8bc6\u534f\u8bae\uff0c\u901a\u8fc7\u5e76\u884c\u5171\u8bc6\u5b9e\u4f8b\u5904\u7406\u4ea4\u6613\uff0c\u8fbe\u5230\u5728\u5bb9\u9519\u3001\u901a\u4fe1\u3001\u8ba1\u7b97\u548c\u8f6e\u590d\u6742\u5ea6\u4e0a\u7684\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u62dc\u5360\u5ead\u5bb9\u9519\u5171\u8bc6\u534f\u8bae\u4f9d\u8d56\u6307\u5b9a\u9886\u5bfc\u8005\uff0c\u6027\u80fd\u53d7\u9650\uff1bOcior\u65e8\u5728\u5b9e\u73b0\u65e0\u9886\u5bfc\u8005\u8bbe\u8ba1\uff0c\u786e\u4fdd\u7a33\u5b9a\u6d3b\u529b\u5e76\u4f18\u5316\u5404\u79cd\u6027\u80fd\u6307\u6807\u3002", "method": "Ocior\u91c7\u7528\u5e76\u884c\u5171\u8bc6\u5b9e\u4f8b\u5904\u7406\u4ea4\u6613\uff0c\u5f15\u5165\u65b0\u578b\u975e\u4ea4\u4e92\u5f0f\u9608\u503c\u7b7e\u540d\u65b9\u6848OciorBLSts\uff0c\u652f\u6301\u5b9e\u65f6\u7b7e\u540d\u805a\u5408\u3002", "result": "Ocior\u5728\u5bb9\u9519\uff08\u5bb9\u5fcd\u6700\u591at\u4e2a\u6545\u969c\u8282\u70b9\uff09\u3001\u901a\u4fe1\uff08O(n)\uff09\u3001\u8ba1\u7b97\uff08O(n)\u6216O(n log\u00b2 n)\uff09\u548c\u8f6e\u590d\u6742\u5ea6\uff08\u6700\u4f18\u4e24\u8f6e\uff09\u65b9\u9762\u5747\u8fbe\u5230\u6700\u4f18\u3002", "conclusion": "Ocior\u901a\u8fc7\u65e0\u9886\u5bfc\u8005\u8bbe\u8ba1\u548cOciorBLSts\u7b7e\u540d\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f02\u6b65\u62dc\u5360\u5ead\u5bb9\u9519\u5171\u8bc6\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u4ea4\u6613\u5904\u7406\u3002"}}
{"id": "2509.01625", "pdf": "https://arxiv.org/pdf/2509.01625", "abs": "https://arxiv.org/abs/2509.01625", "authors": ["Sima Zahedi Fard", "Paolo Tiso", "Parisa Omidvar", "Marc Serra-Garcia"], "title": "Embodying computation in nonlinear perturbative metamaterials", "categories": ["cond-mat.mes-hall", "cs.ET"], "comment": null, "summary": "Designing metamaterials that carry out advanced computations poses a\nsignificant challenge. A powerful design strategy splits the problem into two\nsteps: First, encoding the desired functionality in a discrete or tight-binding\nmodel, and second, identifying a metamaterial geometry that conforms to the\nmodel. Applying this approach to information-processing tasks requires\naccurately mapping nonlinearity -- an essential element for computation -- from\ndiscrete models to geometries. Here we formulate this mapping through a\nnonlinear coordinate transformation that accurately connects tight-binding\ndegrees of freedom to metamaterial excitations in the nonlinear regime. This\ntransformation allows us to design information-processing metamaterials across\nthe broad range of computations that can be expressed as tight-binding models,\na capability we showcase with three examples based on three different computing\nparadigms: a coherent Ising machine that approximates combinatorial\noptimization problems through energy minimization, a mechanical racetrack\nmemory exemplifying in-memory computing, and a speech classification\nmetamaterial based on analog neuromorphic computing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bbe\u8ba1\u5177\u6709\u4fe1\u606f\u5904\u7406\u529f\u80fd\u7684\u8d85\u6750\u6599\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u5750\u6807\u53d8\u6362\u5c06\u7d27\u675f\u7f1a\u6a21\u578b\u7684\u529f\u80fd\u6620\u5c04\u5230\u8d85\u6750\u6599\u51e0\u4f55\u7ed3\u6784\u4e2d\uff0c\u5c55\u793a\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u8ba1\u7b97\u8303\u5f0f\u5e94\u7528\u3002", "motivation": "\u8bbe\u8ba1\u80fd\u591f\u6267\u884c\u9ad8\u7ea7\u8ba1\u7b97\u7684\u8d85\u6750\u6599\u5177\u6709\u6311\u6218\u6027\uff0c\u5173\u952e\u5728\u4e8e\u5c06\u975e\u7ebf\u6027\u529f\u80fd\u4ece\u79bb\u6563\u6a21\u578b\u51c6\u786e\u6620\u5c04\u5230\u51e0\u4f55\u7ed3\u6784\u4e2d\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u7b56\u7565\uff1a\u9996\u5148\u5728\u7d27\u675f\u7f1a\u6a21\u578b\u4e2d\u7f16\u7801\u529f\u80fd\uff0c\u5176\u6b21\u901a\u8fc7\u975e\u7ebf\u6027\u5750\u6807\u53d8\u6362\u5c06\u529f\u80fd\u6620\u5c04\u5230\u8d85\u6750\u6599\u51e0\u4f55\u7ed3\u6784\u4e2d\u3002", "result": "\u6210\u529f\u8bbe\u8ba1\u4e86\u4e09\u79cd\u57fa\u4e8e\u4e0d\u540c\u8ba1\u7b97\u8303\u5f0f\u7684\u4fe1\u606f\u5904\u7406\u8d85\u6750\u6599\uff1a\u76f8\u5e72\u4f0a\u8f9b\u673a\u3001\u673a\u68b0\u8d5b\u9053\u5b58\u50a8\u5668\u548c\u6a21\u62df\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u7684\u8bed\u97f3\u5206\u7c7b\u6750\u6599\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u901a\u8fc7\u7d27\u675f\u7f1a\u6a21\u578b\u8bbe\u8ba1\u5e7f\u6cdb\u7684\u8d85\u6750\u6599\u8ba1\u7b97\u5668\u4ef6\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2509.00303", "pdf": "https://arxiv.org/pdf/2509.00303", "abs": "https://arxiv.org/abs/2509.00303", "authors": ["Fuheng Zhao", "Jiayue Chen", "Yiming Pan", "Tahseen Rabbani", "Divyakant Agrawal", "Amr El Abbadi"], "title": "Access Paths for Efficient Ordering with Large Language Models", "categories": ["cs.DB", "cs.AI", "cs.IR"], "comment": null, "summary": "We present the LLM ORDER BY operator as a logical abstraction and study its\nphysical implementations within a unified evaluation framework. Our experiments\nshow that no single approach is universally optimal, with effectiveness\ndepending on query characteristics and data. We introduce three new designs: an\nagreement-based batch-size policy, a majority voting mechanism for pairwise\nsorting, and a two-way external merge sort adapted for LLMs. With extensive\nexperiments, our agreement-based procedure is effective at determining batch\nsize for value-based methods, the majority-voting mechanism consistently\nstrengthens pairwise comparisons on GPT-4o, and external merge sort achieves\nhigh accuracy-efficiency trade-offs across datasets and models. We further\nobserve a log-linear scaling between compute cost and ordering quality,\noffering the first step toward principled cost models for LLM powered data\nsystems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86LLM ORDER BY\u64cd\u4f5c\u7b26\u7684\u903b\u8f91\u62bd\u8c61\u53ca\u5176\u7269\u7406\u5b9e\u73b0\uff0c\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u65b9\u6cd5\u7684\u6548\u679c\u56e0\u67e5\u8be2\u7279\u6027\u548c\u6570\u636e\u800c\u5f02\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5b83\u4eec\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76LLM ORDER BY\u64cd\u4f5c\u7b26\u7684\u5b9e\u73b0\uff0c\u4ee5\u63a2\u7d22\u5982\u4f55\u5728\u4e0d\u540c\u67e5\u8be2\u548c\u6570\u636e\u6761\u4ef6\u4e0b\u4f18\u5316\u6392\u5e8f\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u8bbe\u8ba1\uff1a\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u6279\u91cf\u5927\u5c0f\u7b56\u7565\u3001\u591a\u6570\u8868\u51b3\u673a\u5236\u548c\u53cc\u5411\u5916\u90e8\u5f52\u5e76\u6392\u5e8f\uff0c\u5e76\u5728\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u4e0b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u7b56\u7565\u80fd\u6709\u6548\u51b3\u5b9a\u6279\u91cf\u5927\u5c0f\uff0c\u591a\u6570\u8868\u51b3\u673a\u5236\u589e\u5f3a\u4e86GPT-4o\u7684\u6392\u5e8f\u51c6\u786e\u6027\uff0c\u5916\u90e8\u5f52\u5e76\u6392\u5e8f\u5728\u6570\u636e\u96c6\u548c\u6a21\u578b\u95f4\u5b9e\u73b0\u4e86\u9ad8\u6548\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u8ba1\u7b97\u6210\u672c\u4e0e\u6392\u5e8f\u8d28\u91cf\u5448\u5bf9\u6570\u7ebf\u6027\u5173\u7cfb\uff0c\u4e3aLLM\u9a71\u52a8\u7684\u6570\u636e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6210\u672c\u6a21\u578b\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.00466", "pdf": "https://arxiv.org/pdf/2509.00466", "abs": "https://arxiv.org/abs/2509.00466", "authors": ["Negar Hashemi", "Amjed Tahir", "Shawn Rasheed", "August Shi", "Rachel Blagojevic"], "title": "JS-TOD: Detecting Order-Dependent Flaky Tests in Jest", "categories": ["cs.SE"], "comment": null, "summary": "We present JS-TOD (JavaScript Test Order-dependency Detector), a tool that\ncan extract, reorder, and rerun Jest tests to reveal possible order-dependent\ntest flakiness. Test order dependency is one of the leading causes of test\nflakiness. Ideally, each test should operate in isolation and yield consistent\nresults no matter the sequence in which tests are run. However, in practice,\ntest outcomes can vary depending on their execution order. JS-TOD employed a\nsystematic approach to randomising tests, test suites, and describe blocks. The\ntool is highly customisable, as one can set the number of orders and reruns\nrequired (the default setting is 10 reorder and 10 reruns for each test and\ntest suite). Our evaluation using JS-TOD reveals two main causes of test order\ndependency flakiness: shared files and shared mocking state between tests.", "AI": {"tldr": "JS-TOD \u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4b JavaScript \u6d4b\u8bd5\u987a\u5e8f\u4f9d\u8d56\u6027\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u968f\u673a\u5316\u6d4b\u8bd5\u987a\u5e8f\u548c\u591a\u6b21\u8fd0\u884c\u6765\u63ed\u793a\u6d4b\u8bd5\u7684\u4e0d\u53ef\u9760\u6027\u3002", "motivation": "\u6d4b\u8bd5\u987a\u5e8f\u4f9d\u8d56\u6027\u662f\u4e00\u79cd\u5e38\u89c1\u7684\u6d4b\u8bd5\u4e0d\u53ef\u9760\u6027\u539f\u56e0\uff0c\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6d4b\u8bd5\u5e94\u5728\u72ec\u7acb\u73af\u5883\u4e0b\u8fd0\u884c\u4e14\u7ed3\u679c\u4e00\u81f4\u3002JS-TOD \u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "JS-TOD \u91c7\u7528\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u968f\u673a\u5316\u6d4b\u8bd5\u3001\u6d4b\u8bd5\u5957\u4ef6\u548c\u63cf\u8ff0\u5757\u7684\u6267\u884c\u987a\u5e8f\uff0c\u5e76\u652f\u6301\u591a\u6b21\u91cd\u6392\u5e8f\u548c\u91cd\u8fd0\u884c\u4ee5\u68c0\u6d4b\u95ee\u9898\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\uff0c\u6d4b\u8bd5\u987a\u5e8f\u4f9d\u8d56\u6027\u7684\u4e3b\u8981\u539f\u56e0\u662f\u6d4b\u8bd5\u95f4\u7684\u5171\u4eab\u6587\u4ef6\u548c\u6a21\u62df\u72b6\u6001\u3002", "conclusion": "JS-TOD \u662f\u4e00\u79cd\u6709\u6548\u5de5\u5177\uff0c\u53ef\u5e2e\u52a9\u5f00\u53d1\u8005\u8bc6\u522b\u5e76\u89e3\u51b3\u6d4b\u8bd5\u987a\u5e8f\u4f9d\u8d56\u6027\u5bfc\u81f4\u7684\u4e0d\u53ef\u9760\u6027\u95ee\u9898\u3002"}}
{"id": "2509.00834", "pdf": "https://arxiv.org/pdf/2509.00834", "abs": "https://arxiv.org/abs/2509.00834", "authors": ["Axel Mezini", "Elena Umili", "Ivan Donadello", "Fabrizio Maria Maggi", "Matteo Mancanelli", "Fabio Patrizi"], "title": "Neuro-Symbolic Predictive Process Monitoring", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.LO", "I.2.4; I.2.6"], "comment": null, "summary": "This paper addresses the problem of suffix prediction in Business Process\nManagement (BPM) by proposing a Neuro-Symbolic Predictive Process Monitoring\n(PPM) approach that integrates data-driven learning with temporal logic-based\nprior knowledge. While recent approaches leverage deep learning models for\nsuffix prediction, they often fail to satisfy even basic logical constraints\ndue to the absence of explicit integration of domain knowledge during training.\nWe propose a novel method to incorporate Linear Temporal Logic over finite\ntraces (LTLf) into the training process of autoregressive sequence predictors.\nOur approach introduces a differentiable logical loss function, defined using a\nsoft approximation of LTLf semantics and the Gumbel-Softmax trick, which can be\ncombined with standard predictive losses. This ensures the model learns to\ngenerate suffixes that are both accurate and logically consistent. Experimental\nevaluation on three real-world datasets shows that our method improves suffix\nprediction accuracy and compliance with temporal constraints. We also introduce\ntwo variants of the logic loss (local and global) and demonstrate their\neffectiveness under noisy and realistic settings. While developed in the\ncontext of BPM, our framework is applicable to any symbolic sequence generation\ntask and contributes toward advancing Neuro-Symbolic AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u548c\u65f6\u5e8f\u903b\u8f91\u5148\u9a8c\u77e5\u8bc6\u7684\u795e\u7ecf\u7b26\u53f7\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u540e\u7f00\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u4e1a\u52a1\u8fc7\u7a0b\u7ba1\u7406\u4e2d\u9884\u6d4b\u540e\u7f00\u65f6\uff0c\u5f80\u5f80\u56e0\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u7684\u663e\u5f0f\u6574\u5408\u800c\u65e0\u6cd5\u6ee1\u8db3\u57fa\u672c\u903b\u8f91\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6709\u9650\u8f68\u8ff9\u4e0a\u7684\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff08LTLf\uff09\u6574\u5408\u5230\u81ea\u56de\u5f52\u5e8f\u5217\u9884\u6d4b\u5668\u8bad\u7ec3\u4e2d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5fae\u7684\u903b\u8f91\u635f\u5931\u51fd\u6570\u5b9e\u73b0\u903b\u8f91\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u540e\u7f00\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u65f6\u5e8f\u7ea6\u675f\u7684\u7b26\u5408\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7b26\u53f7AI\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u7b26\u53f7\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u3002"}}
{"id": "2509.00777", "pdf": "https://arxiv.org/pdf/2509.00777", "abs": "https://arxiv.org/abs/2509.00777", "authors": ["Xiaokang Wei", "Zizheng Yan", "Zhangyang Xiong", "Yiming Hao", "Yipeng Qin", "Xiaoguang Han"], "title": "IntrinsicReal: Adapting IntrinsicAnything from Synthetic to Real Objects", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Estimating albedo (a.k.a., intrinsic image decomposition) from single RGB\nimages captured in real-world environments (e.g., the MVImgNet dataset)\npresents a significant challenge due to the absence of paired images and their\nground truth albedos. Therefore, while recent methods (e.g., IntrinsicAnything)\nhave achieved breakthroughs by harnessing powerful diffusion priors, they\nremain predominantly trained on large-scale synthetic datasets (e.g.,\nObjaverse) and applied directly to real-world RGB images, which ignores the\nlarge domain gap between synthetic and real-world data and leads to suboptimal\ngeneralization performance. In this work, we address this gap by proposing\nIntrinsicReal, a novel domain adaptation framework that bridges the\nabove-mentioned domain gap for real-world intrinsic image decomposition.\nSpecifically, our IntrinsicReal adapts IntrinsicAnything to the real domain by\nfine-tuning it using its high-quality output albedos selected by a novel dual\npseudo-labeling strategy: i) pseudo-labeling with an absolute confidence\nthreshold on classifier predictions, and ii) pseudo-labeling using the relative\npreference ranking of classifier predictions for individual input objects. This\nstrategy is inspired by human evaluation, where identifying the highest-quality\noutputs is straightforward, but absolute scores become less reliable for\nsub-optimal cases. In these situations, relative comparisons of outputs become\nmore accurate. To implement this, we propose a novel two-phase pipeline that\nsequentially applies these pseudo-labeling techniques to effectively adapt\nIntrinsicAnything to the real domain. Experimental results show that our\nIntrinsicReal significantly outperforms existing methods, achieving\nstate-of-the-art results for albedo estimation on both synthetic and real-world\ndatasets.", "AI": {"tldr": "IntrinsicReal \u662f\u4e00\u4e2a\u65b0\u7684\u9886\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u4f2a\u6807\u7b7e\u7b56\u7565\u5c06 IntrinsicAnything \u9002\u5e94\u4e8e\u771f\u5b9e\u4e16\u754c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u7684\u53cd\u5c04\u7387\u4f30\u8ba1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5728\u5408\u6210\u6570\u636e\u4e0a\u8bad\u7ec3\u5e76\u76f4\u63a5\u5e94\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\uff0c\u5ffd\u7565\u4e86\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u9886\u57df\u5dee\u5f02\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u80fd\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa IntrinsicReal\uff0c\u4f7f\u7528\u53cc\u4f2a\u6807\u7b7e\u7b56\u7565\uff08\u7edd\u5bf9\u7f6e\u4fe1\u9608\u503c\u548c\u76f8\u5bf9\u504f\u597d\u6392\u5e8f\uff09\u5bf9 IntrinsicAnything \u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u53cd\u5c04\u7387\u4f30\u8ba1\u6027\u80fd\u3002", "conclusion": "IntrinsicReal \u6210\u529f\u5f25\u5408\u4e86\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u9886\u57df\u5dee\u8ddd\uff0c\u63d0\u5347\u4e86\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u7684\u5185\u5728\u56fe\u50cf\u5206\u89e3\u6027\u80fd\u3002"}}
{"id": "2509.01082", "pdf": "https://arxiv.org/pdf/2509.01082", "abs": "https://arxiv.org/abs/2509.01082", "authors": ["Madhav Kanda", "Shubham Ugare", "Sasa Misailovic"], "title": "REFINESTAT: Efficient Exploration for Probabilistic Program Synthesis", "categories": ["cs.LG", "cs.PL"], "comment": "RefineStat constrains LM decoding with statistical validity checks\n  and uses diagnostic-guided resampling (priors/likelihoods) to transform small\n  LMs' drafts into correct, reliable probabilistic programs that can match or\n  surpass closed-source models", "summary": "Probabilistic programming offers a powerful framework for modeling\nuncertainty, yet statistical model discovery in this domain entails navigating\nan immense search space under strict domain-specific constraints. When small\nlanguage models are tasked with generating probabilistic programs, they\nfrequently produce outputs that suffer from both syntactic and semantic errors,\nsuch as flawed inference constructs. Motivated by probabilistic programmers'\ndomain expertise and debugging strategies, we introduce RefineStat, a language\nmodel--driven framework that enforces semantic constraints ensuring synthesized\nprograms contain valid distributions and well-formed parameters, and then\napplies diagnostic-aware refinement by resampling prior or likelihood\ncomponents whenever reliability checks fail. We evaluate RefineStat on multiple\nprobabilistic-programming code-generation tasks using smaller language models\n(SLMs) and find that it produces programs that are both syntactically sound and\nstatistically reliable, often matching or surpassing those from closed-source\nlarge language models (e.g., OpenAI o3).", "AI": {"tldr": "RefineStat\u662f\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u7b26\u5408\u8bed\u4e49\u7ea6\u675f\u7684\u6982\u7387\u7a0b\u5e8f\uff0c\u5e76\u901a\u8fc7\u8bca\u65ad\u611f\u77e5\u7684\u7ec6\u5316\u65b9\u6cd5\u63d0\u5347\u7a0b\u5e8f\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u6982\u7387\u7f16\u7a0b\u9886\u57df\u4e2d\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7a0b\u5e8f\u5e38\u5b58\u5728\u8bed\u6cd5\u548c\u8bed\u4e49\u9519\u8bef\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "RefineStat\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u8bed\u4e49\u7ea6\u675f\u548c\u8bca\u65ad\u611f\u77e5\u7684\u7ec6\u5316\u65b9\u6cd5\uff08\u5982\u91cd\u65b0\u91c7\u6837\u5148\u9a8c\u6216\u4f3c\u7136\u7ec4\u4ef6\uff09\u6765\u6539\u8fdb\u7a0b\u5e8f\u751f\u6210\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\uff0cRefineStat\u751f\u6210\u7684\u7a0b\u5e8f\u4e0d\u4ec5\u8bed\u6cd5\u6b63\u786e\u4e14\u7edf\u8ba1\u53ef\u9760\uff0c\u8868\u73b0\u4f18\u4e8e\u6216\u5339\u654c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "RefineStat\u4e3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6982\u7387\u7f16\u7a0b\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u7a0b\u5e8f\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2509.00701", "pdf": "https://arxiv.org/pdf/2509.00701", "abs": "https://arxiv.org/abs/2509.00701", "authors": ["Kun Qiu", "Ying Wang", "Baoqian Li", "Wenjun Zhu"], "title": "Unsupervised Dataset Cleaning Framework for Encrypted Traffic Classification", "categories": ["cs.NI", "cs.AI"], "comment": "Accepted in IEEE ICNP 2025 Poster", "summary": "Traffic classification, a technique for assigning network flows to predefined\ncategories, has been widely deployed in enterprise and carrier networks. With\nthe massive adoption of mobile devices, encryption is increasingly used in\nmobile applications to address privacy concerns. Consequently, traditional\nmethods such as Deep Packet Inspection (DPI) fail to distinguish encrypted\ntraffic. To tackle this challenge, Artificial Intelligence (AI), in particular\nMachine Learning (ML), has emerged as a promising solution for encrypted\ntraffic classification. A crucial prerequisite for any ML-based approach is\ntraffic data cleaning, which removes flows that are not useful for training\n(e.g., irrelevant protocols, background activity, control-plane messages, and\nlong-lived sessions). Existing cleaning solutions depend on manual inspection\nof every captured packet, making the process both costly and time-consuming. In\nthis poster, we present an unsupervised framework that automatically cleans\nencrypted mobile traffic. Evaluation on real-world datasets shows that our\nframework incurs only a 2%~2.5% reduction in classification accuracy compared\nwith manual cleaning. These results demonstrate that our method offers an\nefficient and effective preprocessing step for ML-based encrypted traffic\nclassification.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u6e05\u7406\u52a0\u5bc6\u79fb\u52a8\u6d41\u91cf\u6570\u636e\uff0c\u66ff\u4ee3\u4f20\u7edf\u8017\u65f6\u7684\u624b\u52a8\u6e05\u7406\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u5206\u7c7b\u51c6\u786e\u7387\u4ec5\u964d\u4f4e2%~2.5%\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u8bbe\u5907\u52a0\u5bc6\u6d41\u91cf\u7684\u666e\u53ca\uff0c\u4f20\u7edf\u6df1\u5ea6\u5305\u68c0\u6d4b\u65b9\u6cd5\u5931\u6548\uff0c\u800c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u7684\u6570\u636e\u6e05\u7406\u8fc7\u7a0b\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u6846\u67b6\uff0c\u81ea\u52a8\u8bc6\u522b\u5e76\u6e05\u7406\u65e0\u5173\u6d41\u91cf\uff08\u5982\u65e0\u5173\u534f\u8bae\u3001\u540e\u53f0\u6d3b\u52a8\u7b49\uff09\uff0c\u65e0\u9700\u4eba\u5de5\u9010\u5305\u68c0\u67e5\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u6846\u67b6\u7684\u81ea\u52a8\u6e05\u7406\u4ec5\u4f7f\u5206\u7c7b\u51c6\u786e\u7387\u964d\u4f4e2%~2.5%\uff0c\u4e0e\u624b\u52a8\u6e05\u7406\u6548\u679c\u63a5\u8fd1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u52a0\u5bc6\u6d41\u91cf\u5206\u7c7b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6709\u6548\u7684\u9884\u5904\u7406\u6b65\u9aa4\u3002"}}
{"id": "2509.01018", "pdf": "https://arxiv.org/pdf/2509.01018", "abs": "https://arxiv.org/abs/2509.01018", "authors": ["Matthew Varona", "Karen Bonilla", "Maryam Hedayati", "Alark Joshi", "Lane Harrison", "Matthew Kay", "Carolina Nobre"], "title": "The State of the Art in Visualization Literacy", "categories": ["cs.HC"], "comment": "Preprint version. A revised document may follow", "summary": "Research in visualization literacy explores the skills required to engage\nwith visualizations. This state-of-the-art report surveys the current\nliterature in visualization literacy to provide a comprehensive overview of the\nfield. We propose a taxonomy of visualization literacy that organizes the field\ninto competency themes and research categories. To address ambiguity\nsurrounding the term ``visualization literacy'', we provide a framework for\noperationalizing visualization literacy based on application contexts\n(including domain, scenario, and audience) and relevant competencies, which are\ncategorized under consumption, construction, critique, and connection. Research\ncontributions are organized into five categories: ontology, assessment,\nmechanisms, populiteracy, and intervention. For each category, we identify key\ntrends, discuss which competencies are addressed, highlight open challenges,\nand examine how advancements within these areas inform and reinforce each\nother, driving progress in the field.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u53ef\u89c6\u5316\u7d20\u517b\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u64cd\u4f5c\u6846\u67b6\u6765\u5b9a\u4e49\u548c\u5206\u7c7b\u76f8\u5173\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u2018\u53ef\u89c6\u5316\u7d20\u517b\u2019\u6982\u5ff5\u7684\u6a21\u7cca\u6027\uff0c\u4e3a\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u6e05\u6670\u7684\u7ec4\u7ec7\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5e94\u7528\u60c5\u666f\u548c\u80fd\u529b\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u7814\u7a76\u8d21\u732e\u5206\u4e3a\u4e94\u7c7b\u3002", "result": "\u603b\u7ed3\u4e86\u5173\u952e\u8d8b\u52bf\u3001\u5f00\u653e\u6311\u6218\u53ca\u5404\u7c7b\u522b\u95f4\u76f8\u4e92\u4fc3\u8fdb\u7684\u5173\u7cfb\u3002", "conclusion": "\u8be5\u6846\u67b6\u63a8\u52a8\u4e86\u53ef\u89c6\u5316\u7d20\u517b\u9886\u57df\u7684\u8fdb\u6b65\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.00132", "pdf": "https://arxiv.org/pdf/2509.00132", "abs": "https://arxiv.org/abs/2509.00132", "authors": ["Peiwen Xing", "Aske Plaat", "Niki van Stein"], "title": "CoComposer: LLM Multi-agent Collaborative Music Composition", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "comment": null, "summary": "Existing AI Music composition tools are limited in generation duration,\nmusical quality, and controllability. We introduce CoComposer, a multi-agent\nsystem that consists of five collaborating agents, each with a task based on\nthe traditional music composition workflow. Using the AudioBox-Aesthetics\nsystem, we experimentally evaluate CoComposer on four compositional criteria.\nWe test with three LLMs (GPT-4o, DeepSeek-V3-0324, Gemini-2.5-Flash), and find\n(1) that CoComposer outperforms existing multi-agent LLM-based systems in music\nquality, and (2) compared to a single-agent system, in production complexity.\nCompared to non- LLM MusicLM, CoComposer has better interpretability and\neditability, although MusicLM still produces better music.", "AI": {"tldr": "CoComposer\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u97f3\u4e50\u521b\u4f5c\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u73b0\u6709AI\u97f3\u4e50\u5de5\u5177\u5728\u751f\u6210\u65f6\u957f\u3001\u97f3\u4e50\u8d28\u91cf\u548c\u53ef\u63a7\u6027\u4e0a\u53d7\u9650\u3002", "method": "\u901a\u8fc7\u4e94\u4e2a\u534f\u4f5c\u667a\u80fd\u4f53\u6a21\u62df\u4f20\u7edf\u4f5c\u66f2\u6d41\u7a0b\uff0c\u4f7f\u7528AudioBox-Aesthetics\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "CoComposer\u5728\u97f3\u4e50\u8d28\u91cf\u548c\u521b\u4f5c\u590d\u6742\u5ea6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f46\u97f3\u4e50\u8d28\u91cf\u4ecd\u4e0d\u53caMusicLM\u3002", "conclusion": "CoComposer\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6709\u4f18\u52bf\uff0c\u4f46\u97f3\u4e50\u8d28\u91cf\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u3002"}}
{"id": "2509.01811", "pdf": "https://arxiv.org/pdf/2509.01811", "abs": "https://arxiv.org/abs/2509.01811", "authors": ["Chengzhang Li", "Peizhong Ju", "Atilla Eryilmaz", "Ness Shroff"], "title": "Optimal Parallel Scheduling under Concave Speedup Functions", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "Efficient scheduling of parallel computation resources across multiple jobs\nis a fundamental problem in modern cloud/edge computing systems for many\nAI-based applications. Allocating more resources to a job accelerates its\ncompletion, but with diminishing returns. Prior work (heSRPT) solved this\nproblem only for some specific speedup functions with an exponential form,\nproviding a closed-form solution. However, the general case with arbitrary\nconcave speedup functions -- which more accurately capture real-world workloads\n-- has remained open.\n  In this paper, we solve this open problem by developing optimal scheduling\nalgorithms for parallel jobs under general concave speedup functions. We first\ndiscover a fundamental and broadly-applicable rule for optimal parallel\nscheduling, namely the Consistent Derivative Ratio (CDR) Rule, which states\nthat the ratio of the derivatives of the speedup functions across active jobs\nremains constant over time. To efficiently compute the optimal allocations that\nsatisfy the CDR Rule, we propose the General Water-Filling (GWF) method, a more\ngeneral version of classical water-filling in wireless communications.\nCombining these insights, we design the SmartFill Algorithm to solve the\ngeneral scheduling problem. Unlike heSRPT, which always allocates resources to\nall active jobs, SmartFill selectively determines which jobs should receive\nresources and how much they should be allocated. For a broad class of so-called\n\\emph{regular} speedup functions, SmartFill yields closed-form optimal\nsolutions, while for non-regular functions it efficiently computes the optimum\nwith low complexity. Numerical evaluations show that SmartFill can\nsubstantially outperform heSRPT across a wide range of concave speedup\nfunctions.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5728\u4efb\u610f\u51f9\u52a0\u901f\u51fd\u6570\u4e0b\u5e76\u884c\u4f5c\u4e1a\u7684\u6700\u4f18\u8c03\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86CDR\u89c4\u5219\u548cGWF\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86SmartFill\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u4e91\u8ba1\u7b97\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u9ad8\u6548\u5206\u914d\u8d44\u6e90\u4ee5\u52a0\u901f\u591a\u4e2a\u5e76\u884c\u4f5c\u4e1a\u7684\u5b8c\u6210\u662f\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u52a0\u901f\u51fd\u6570\uff0c\u65e0\u6cd5\u5904\u7406\u66f4\u666e\u904d\u7684\u51f9\u52a0\u901f\u51fd\u6570\u3002", "method": "\u63d0\u51fa\u4e86CDR\u89c4\u5219\u4f5c\u4e3a\u8c03\u5ea6\u57fa\u7840\uff0c\u5f00\u53d1\u4e86GWF\u65b9\u6cd5\u8ba1\u7b97\u6700\u4f18\u5206\u914d\uff0c\u5e76\u8bbe\u8ba1\u4e86SmartFill\u7b97\u6cd5\uff0c\u6839\u636e\u4f5c\u4e1a\u9700\u6c42\u52a8\u6001\u9009\u62e9\u8d44\u6e90\u5206\u914d\u7b56\u7565\u3002", "result": "SmartFill\u7b97\u6cd5\u5728\u5e7f\u6cdb\u7684\u51f9\u52a0\u901f\u51fd\u6570\u4e0b\u663e\u8457\u4f18\u4e8eheSRPT\uff0c\u80fd\u591f\u63d0\u4f9b\u5c01\u95ed\u5f62\u5f0f\u7684\u89e3\u6216\u9ad8\u6548\u8ba1\u7b97\u6700\u4f18\u89e3\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7CDR\u89c4\u5219\u548cSmartFill\u7b97\u6cd5\u89e3\u51b3\u4e86\u901a\u7528\u51f9\u52a0\u901f\u51fd\u6570\u4e0b\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00778", "pdf": "https://arxiv.org/pdf/2509.00778", "abs": "https://arxiv.org/abs/2509.00778", "authors": ["Pragun Jaswal", "L. Hemanth Krishna", "B. Srinivasu"], "title": "Energy Efficient Exact and Approximate Systolic Array Architecture for Matrix Multiplication", "categories": ["cs.AR", "cs.CV"], "comment": "Submitted to 39th International Conference on VLSI Design, 2026", "summary": "Deep Neural Networks (DNNs) require highly efficient matrix multiplication\nengines for complex computations. This paper presents a systolic array\narchitecture incorporating novel exact and approximate processing elements\n(PEs), designed using energy-efficient positive partial product and negative\npartial product cells, termed as PPC and NPPC, respectively. The proposed 8-bit\nexact and approximate PE designs are employed in a 8x8 systolic array, which\nachieves a energy savings of 22% and 32%, respectively, compared to the\nexisting design. To demonstrate their effectiveness, the proposed PEs are\nintegrated into a systolic array (SA) for Discrete Cosine Transform (DCT)\ncomputation, achieving high output quality with a PSNR of 38.21,dB.\nFurthermore, in an edge detection application using convolution, the\napproximate PE achieves a PSNR of 30.45,dB. These results highlight the\npotential of the proposed design to deliver significant energy efficiency while\nmaintaining competitive output quality, making it well-suited for\nerror-resilient image and vision processing applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7cbe\u786e\u548c\u8fd1\u4f3c\u5904\u7406\u5355\u5143\u7684\u8109\u52a8\u9635\u5217\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6548\u5e76\u4fdd\u6301\u4e86\u8f93\u51fa\u8d28\u91cf\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u548c\u89c6\u89c9\u5904\u7406\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u9ad8\u6548\u7684\u77e9\u9635\u4e58\u6cd5\u5f15\u64ce\uff0c\u4ee5\u652f\u6301\u590d\u6742\u8ba1\u7b97\uff0c\u73b0\u6709\u8bbe\u8ba1\u5728\u80fd\u6548\u548c\u8f93\u51fa\u8d28\u91cf\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u91c7\u7528\u65b0\u578b\u6b63\u8d1f\u90e8\u5206\u79ef\u5355\u5143\uff08PPC\u548cNPPC\uff09\u76848\u4f4d\u7cbe\u786e\u548c\u8fd1\u4f3cPE\uff0c\u6784\u5efa8x8\u8109\u52a8\u9635\u5217\uff0c\u5e94\u7528\u4e8eDCT\u548c\u5377\u79ef\u8ba1\u7b97\u3002", "result": "\u80fd\u6548\u63d0\u534722%\u548c32%\uff0cDCT\u8ba1\u7b97PSNR\u8fbe38.21dB\uff0c\u5377\u79ef\u8fb9\u7f18\u68c0\u6d4bPSNR\u8fbe30.45dB\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u5728\u80fd\u6548\u548c\u8f93\u51fa\u8d28\u91cf\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u5bb9\u9519\u7684\u56fe\u50cf\u548c\u89c6\u89c9\u5904\u7406\u5e94\u7528\u3002"}}
{"id": "2509.01168", "pdf": "https://arxiv.org/pdf/2509.01168", "abs": "https://arxiv.org/abs/2509.01168", "authors": ["Dmitry Yaremus", "Jianghai Li", "Alisa Kalacheva", "Igor Vodolazov", "Yury Yanovich"], "title": "Detecting Rug Pulls in Decentralized Exchanges: Machine Learning Evidence from the TON Blockchain", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "This paper presents a machine learning framework for the early detection of\nrug pull scams on decentralized exchanges (DEXs) within The Open Network (TON)\nblockchain. TON's unique architecture, characterized by asynchronous execution\nand a massive web2 user base from Telegram, presents a novel and critical\nenvironment for fraud analysis. We conduct a comprehensive study on the two\nlargest TON DEXs, Ston.Fi and DeDust, fusing data from both platforms to train\nour models. A key contribution is the implementation and comparative analysis\nof two distinct rug pull definitions--TVL-based (a catastrophic liquidity\nwithdrawal) and idle-based (a sudden cessation of all trading activity)--within\na single, unified study. We demonstrate that Gradient Boosting models can\neffectively identify rug pulls within the first five minutes of trading, with\nthe TVL-based method achieving superior AUC (up to 0.891) while the idle-based\nmethod excels at recall. Our analysis reveals that while feature sets are\nconsistent across exchanges, their underlying distributions differ\nsignificantly, challenging straightforward data fusion and highlighting the\nneed for robust, platform-aware models. This work provides a crucial\nearly-warning mechanism for investors and enhances the security infrastructure\nof the rapidly growing TON DeFi ecosystem.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u65e9\u671f\u68c0\u6d4bTON\u533a\u5757\u94fe\u4e0aDEX\u7684rug pull\u9a97\u5c40\uff0c\u91cd\u70b9\u6bd4\u8f83\u4e86\u4e24\u79cd\u5b9a\u4e49\u65b9\u6cd5\uff08TVL\u548cidle\uff09\u7684\u6027\u80fd\u3002", "motivation": "TON\u533a\u5757\u94fe\u7684\u72ec\u7279\u67b6\u6784\u548c\u5feb\u901f\u589e\u957f\u7684\u4f7f\u7528\u73af\u5883\uff0c\u4e9f\u9700\u4e00\u79cd\u6709\u6548\u7684\u6b3a\u8bc8\u68c0\u6d4b\u65b9\u6cd5\u4ee5\u4fdd\u62a4\u6295\u8d44\u8005\u3002", "method": "\u7ed3\u5408TVL\u548cidle\u4e24\u79cd\u5b9a\u4e49\uff0c\u8bad\u7ec3\u68af\u5ea6\u63d0\u5347\u6a21\u578b\uff0c\u5e76\u5728TON\u7684\u4e24\u5927DEX\uff08Ston.Fi\u548cDeDust\uff09\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "TVL\u65b9\u6cd5\u5728AUC\u8868\u73b0\u6700\u4f73\uff080.891\uff09\uff0c\u800cidle\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u4e0a\u66f4\u4f18\u3002\u6570\u636e\u5206\u5e03\u5dee\u5f02\u663e\u8457\uff0c\u9700\u5e73\u53f0\u611f\u77e5\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6295\u8d44\u8005\u63d0\u4f9b\u4e86\u65e9\u671f\u9884\u8b66\u673a\u5236\uff0c\u589e\u5f3a\u4e86TON DeFi\u751f\u6001\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2509.01706", "pdf": "https://arxiv.org/pdf/2509.01706", "abs": "https://arxiv.org/abs/2509.01706", "authors": ["Parisa Omidvar", "Markus Bestler", "Sima Zahedi Fard", "Oded Zilberberg", "Marc Serra-Garcia"], "title": "Racetrack computing with a topological boundary ratchet", "categories": ["cond-mat.mes-hall", "cs.ET"], "comment": "12 pages, 9 figures", "summary": "Multistable order parameters provide a natural means of encoding non-volatile\ninformation in spatial domains, a concept that forms the foundation of magnetic\nmemory devices. However, this stability inherently conflicts with the need to\nmove information around the device for processing and readout. While in\nmagnetic systems, domains can be transported using currents or external fields,\nmechanisms to robustly shuttle information-bearing domains across neutral\nsystems are scarce. Here, we experimentally realize a topological boundary\nratchet in an elastic metamaterial, where digital information is encoded in\nbuckling domains and transported in a quantized manner via cyclic loading. The\ntransport is topological in origin: neighboring domains act as different\ntopological pumps for their Bogoliubov excitations, so their interface hosts\ntopological boundary modes. Cyclic loading renders these modes unstable through\ninter-domain pressure, which in turn drives the motion of the domain wall. We\ndemonstrate that the direction of information propagation can be controlled\nthrough adjustable mechanical constraints on the buckling beams, and\nnumerically investigate buckling-based domain-wall logic circuits in an elastic\nmetamaterial network. The underlying tight-binding structure with low-order\nnonlinearities makes this approach a general pathway toward racetrack memories\nin neutral systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u5b9e\u73b0\u4e86\u4e00\u79cd\u5f39\u6027\u8d85\u6750\u6599\u4e2d\u7684\u62d3\u6251\u8fb9\u754c\u68d8\u8f6e\uff0c\u5c55\u793a\u4e86\u7f16\u7801\u5728\u5c48\u66f2\u57df\u4e2d\u7684\u6570\u5b57\u4fe1\u606f\u5982\u4f55\u901a\u8fc7\u5faa\u73af\u52a0\u8f7d\u4ee5\u91cf\u5b50\u5316\u65b9\u5f0f\u4f20\u8f93\u3002", "motivation": "\u89e3\u51b3\u4e2d\u6027\u7cfb\u7edf\u4e2d\u4fe1\u606f\u4f20\u9012\u7a33\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u62d3\u6251\u8fb9\u754c\u6a21\u5f0f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u548c\u6570\u503c\u6a21\u62df\uff0c\u7814\u7a76\u4e86\u5c48\u66f2\u57df\u4e2d\u7684\u4fe1\u606f\u4f20\u8f93\u673a\u5236\uff0c\u5e76\u63a2\u7d22\u4e86\u53ef\u8c03\u673a\u68b0\u7ea6\u675f\u5bf9\u4fe1\u606f\u4f20\u64ad\u65b9\u5411\u7684\u63a7\u5236\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u4fe1\u606f\u5728\u5f39\u6027\u8d85\u6750\u6599\u4e2d\u7684\u91cf\u5b50\u5316\u4f20\u8f93\uff0c\u5e76\u5c55\u793a\u4e86\u53ef\u8c03\u7684\u4f20\u64ad\u65b9\u5411\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e2d\u6027\u7cfb\u7edf\u4e2d\u7684\u8d5b\u9053\u5b58\u50a8\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u9014\u5f84\uff0c\u5177\u6709\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.00365", "pdf": "https://arxiv.org/pdf/2509.00365", "abs": "https://arxiv.org/abs/2509.00365", "authors": ["Zhenxin Li", "Shuibing He", "Jiahao Guo", "Xuechen Zhang", "Xian-He Sun", "Gang Chen"], "title": "CRouting: Reducing Expensive Distance Calls in Graph-Based Approximate Nearest Neighbor Search", "categories": ["cs.DB", "cs.IR"], "comment": null, "summary": "Approximate nearest neighbor search (ANNS) is a crucial problem in\ninformation retrieval and AI applications. Recently, there has been a surge of\ninterest in graph-based ANNS algorithms due to their superior efficiency and\naccuracy. However, the repeated computation of distances in high-dimensional\nspaces constitutes the primary time cost of graph-based methods. To accelerate\nthe search, we propose a novel routing strategy named CRouting, which bypasses\nunnecessary distance computations by exploiting the angle distributions of\nhigh-dimensional vectors. CRouting is designed as a plugin to optimize existing\ngraph-based search with minimal code modifications. Our experiments show that\nCRouting reduces the number of distance computations by up to 41.5% and boosts\nqueries per second by up to 1.48$\\times$ on two predominant graph indexes, HNSW\nand NSG. Code is publicly available at https://github.com/ISCS-ZJU/CRouting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCRouting\u7684\u65b0\u8def\u7531\u7b56\u7565\uff0c\u901a\u8fc7\u5229\u7528\u9ad8\u7ef4\u5411\u91cf\u7684\u89d2\u5ea6\u5206\u5e03\u6765\u7ed5\u8fc7\u4e0d\u5fc5\u8981\u7684\u8ddd\u79bb\u8ba1\u7b97\uff0c\u4ece\u800c\u52a0\u901f\u56fe\u57fa\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff08ANNS\uff09\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCRouting\u51cf\u5c11\u4e8641.5%\u7684\u8ddd\u79bb\u8ba1\u7b97\uff0c\u5e76\u4e14\u5728HNSW\u548cNSG\u4e24\u79cd\u4e3b\u6d41\u56fe\u7d22\u5f15\u4e0a\u63d0\u5347\u4e861.48\u500d\u7684\u67e5\u8be2\u901f\u5ea6\u3002", "motivation": "\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u91cd\u590d\u7684\u8ddd\u79bb\u8ba1\u7b97\u662f\u56fe\u57faANNS\u7b97\u6cd5\u7684\u4e3b\u8981\u65f6\u95f4\u6210\u672c\uff0c\u9650\u5236\u4e86\u5176\u6548\u7387\u3002", "method": "\u63d0\u51faCRouting\u8def\u7531\u7b56\u7565\uff0c\u57fa\u4e8e\u9ad8\u7ef4\u5411\u91cf\u89d2\u5ea6\u5206\u5e03\u7ed5\u8fc7\u4e0d\u5fc5\u8981\u7684\u8ddd\u79bb\u8ba1\u7b97\uff0c\u53ef\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709\u56fe\u57fa\u641c\u7d22\u7b97\u6cd5\u4e2d\u3002", "result": "CRouting\u5c06\u8ddd\u79bb\u8ba1\u7b97\u51cf\u5c11\u4e8641.5%\uff0c\u5728HNSW\u548cNSG\u4e0a\u67e5\u8be2\u901f\u5ea6\u63d0\u53471.48\u500d\u3002", "conclusion": "CRouting\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6613\u4e8e\u96c6\u6210\u7684\u4f18\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u57faANNS\u7684\u6027\u80fd\u3002"}}
{"id": "2509.00785", "pdf": "https://arxiv.org/pdf/2509.00785", "abs": "https://arxiv.org/abs/2509.00785", "authors": ["Elena Masserini", "Daniela Micucci", "Leonardo Mariani"], "title": "Bug Whispering: Towards Audio Bug Reporting", "categories": ["cs.SE"], "comment": "2 pages, 1 figure, IEEE International Symposium on Software\n  Reliability Engineering (ISSRE), 2025, Fast Abstracts Session", "summary": "Bug reporting is a key feature of mobile applications, as it enables\ndevelopers to collect information about faults that escaped testing and thus\naffected end-users. This paper explores the idea of allowing end-users to\nimmediately report the problems that they experience by recording and\nsubmitting audio messages. Audio recording is simple to implement and has the\npotential to increase the number of bug reports that development teams can\ngather, thus potentially improving the rate at which bugs are identified and\nfixed. However, audio bug reports exhibit specific characteristics that\nchallenge existing techniques for reproducing bugs. This paper discusses these\nchallenges based on a preliminary experiment, and motivates further research on\nthe collection and analysis of audio-based bug reports", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u901a\u8fc7\u97f3\u9891\u8bb0\u5f55\u8ba9\u7528\u6237\u76f4\u63a5\u62a5\u544a\u79fb\u52a8\u5e94\u7528\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5176\u4f18\u52bf\u548c\u73b0\u6709\u6280\u672f\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u5e0c\u671b\u901a\u8fc7\u97f3\u9891\u8bb0\u5f55\u7b80\u5316\u7528\u6237\u53cd\u9988\u6d41\u7a0b\uff0c\u589e\u52a0\u5f00\u53d1\u56e2\u961f\u6536\u96c6\u7684\u95ee\u9898\u62a5\u544a\u6570\u91cf\uff0c\u4ece\u800c\u66f4\u5feb\u53d1\u73b0\u548c\u4fee\u590d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7528\u6237\u901a\u8fc7\u97f3\u9891\u6d88\u606f\u5373\u65f6\u62a5\u544a\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u548c\u6311\u6218\u3002", "result": "\u97f3\u9891\u62a5\u544a\u6613\u4e8e\u5b9e\u73b0\uff0c\u4f46\u5b58\u5728\u7279\u5b9a\u6280\u672f\u6311\u6218\uff0c\u5f71\u54cd\u73b0\u6709\u95ee\u9898\u91cd\u73b0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u97f3\u9891\u62a5\u544a\u6709\u6f5c\u529b\u6539\u8fdb\u95ee\u9898\u53cd\u9988\u6548\u7387\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5982\u4f55\u514b\u670d\u5176\u5e26\u6765\u7684\u6280\u672f\u6311\u6218\u3002"}}
{"id": "2509.01508", "pdf": "https://arxiv.org/pdf/2509.01508", "abs": "https://arxiv.org/abs/2509.01508", "authors": ["Anurudh Peduri", "Gilles Barthe", "Michael Walter"], "title": "Traq: Estimating the Quantum Cost of Classical Programs", "categories": ["quant-ph", "cs.LO", "cs.PL", "cs.SE"], "comment": "50 pages", "summary": "Predicting practical speedups offered by future quantum computers has become\na major focus of the quantum computing community. Typically, these predictions\nare supported by lengthy manual analyses and numerical simulations and are\ncarried out for one specific application at a time. In this paper, we present\nTraq, a principled approach towards estimating the quantum speedup of classical\nprograms fully automatically and with provable guarantees. It consists of a\nclassical language that includes high-level primitives amenable to quantum\nspeedups, a cost analysis, and a compilation to low-level quantum programs. Our\ncost analysis upper bounds the complexity of the resulting quantum program in a\nfine-grained way: it captures non-asymptotic information and is sensitive to\nthe input of the program (rather than providing worst-case costs). We also\nprovide a proof-of-concept implementation and a case study inspired by AND-OR\ntrees.", "AI": {"tldr": "Traq\u662f\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u53ef\u8bc1\u660e\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u91cf\u5b50\u8ba1\u7b97\u673a\u5bf9\u7ecf\u5178\u7a0b\u5e8f\u7684\u52a0\u901f\u6548\u679c\uff0c\u5305\u62ec\u8bed\u8a00\u3001\u6210\u672c\u5206\u6790\u548c\u91cf\u5b50\u7a0b\u5e8f\u7f16\u8bd1\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\uff0c\u6548\u7387\u4f4e\u4e14\u9488\u5bf9\u6027\u5355\u4e00\u3002Traq\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u901a\u7528\u7684\u91cf\u5316\u52a0\u901f\u8bc4\u4f30\u5de5\u5177\u3002", "method": "Traq\u91c7\u7528\u4e00\u79cd\u7ecf\u5178\u8bed\u8a00\uff0c\u5305\u542b\u9002\u4e8e\u91cf\u5b50\u52a0\u901f\u7684\u9ad8\u7ea7\u539f\u8bed\uff0c\u8fdb\u884c\u6210\u672c\u5206\u6790\uff0c\u5e76\u7f16\u8bd1\u4e3a\u4f4e\u5c42\u91cf\u5b50\u7a0b\u5e8f\u3002\u6210\u672c\u5206\u6790\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u975e\u6e10\u8fd1\u590d\u6742\u6027\u4e0a\u754c\u3002", "result": "\u901a\u8fc7\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\u548c\u6848\u4f8b\u7814\u7a76\uff08AND-OR\u6811\uff09\uff0c\u8bc1\u660eTraq\u80fd\u591f\u6709\u6548\u91cf\u5316\u91cf\u5b50\u7a0b\u5e8f\u7684\u52a0\u901f\u6f5c\u529b\u3002", "conclusion": "Traq\u4e3a\u91cf\u5b50\u52a0\u901f\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u548c\u81ea\u52a8\u5316\u7684\u5206\u6790\u6846\u67b6\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2509.01134", "pdf": "https://arxiv.org/pdf/2509.01134", "abs": "https://arxiv.org/abs/2509.01134", "authors": ["Xilong Zhou", "Pedro Figueiredo", "Milo\u0161 Ha\u0161an", "Valentin Deschaintre", "Paul Guerrero", "Yiwei Hu", "Nima Khademi Kalantari"], "title": "RealMat: Realistic Materials with Diffusion and Reinforcement Learning", "categories": ["cs.GR", "cs.CV"], "comment": "11 pages, 11 figures", "summary": "Generative models for high-quality materials are particularly desirable to\nmake 3D content authoring more accessible. However, the majority of material\ngeneration methods are trained on synthetic data. Synthetic data provides\nprecise supervision for material maps, which is convenient but also tends to\ncreate a significant visual gap with real-world materials. Alternatively,\nrecent work used a small dataset of real flash photographs to guarantee\nrealism, however such data is limited in scale and diversity. To address these\nlimitations, we propose RealMat, a diffusion-based material generator that\nleverages realistic priors, including a text-to-image model and a dataset of\nrealistic material photos under natural lighting. In RealMat, we first finetune\na pretrained Stable Diffusion XL (SDXL) with synthetic material maps arranged\nin $2 \\times 2$ grids. This way, our model inherits some realism of SDXL while\nlearning the data distribution of the synthetic material grids. Still, this\ncreates a realism gap, with some generated materials appearing synthetic. We\npropose to further finetune our model through reinforcement learning (RL),\nencouraging the generation of realistic materials. We develop a realism reward\nfunction for any material image under natural lighting, by collecting a\nlarge-scale dataset of realistic material images. We show that this approach\nincreases generated materials' realism compared to our base model and related\nwork.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6750\u8d28\u751f\u6210\u65b9\u6cd5RealMat\uff0c\u7ed3\u5408\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u7167\u7247\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u751f\u6210\u6750\u8d28\u7684\u771f\u5b9e\u611f\u3002", "motivation": "\u73b0\u6709\u6750\u8d28\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5408\u6210\u6570\u636e\uff0c\u5b58\u5728\u4e0e\u771f\u5b9e\u6750\u8d28\u7684\u89c6\u89c9\u5dee\u8ddd\uff1b\u800c\u5c0f\u89c4\u6a21\u771f\u5b9e\u7167\u7247\u6570\u636e\u7f3a\u4e4f\u591a\u6837\u6027\u548c\u89c4\u6a21\u3002\u4e3a\u6b64\uff0c\u63d0\u51faRealMat\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5148\u5fae\u8c03\u9884\u8bad\u7ec3\u7684Stable Diffusion XL\uff08SDXL\uff09\u5904\u7406\u5408\u6210\u6750\u8d28\u7f51\u683c\uff0c\u518d\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u5fae\u8c03\u6a21\u578b\uff0c\u5229\u7528\u5927\u89c4\u6a21\u771f\u5b9e\u6750\u8d28\u7167\u7247\u6570\u636e\u96c6\u8bbe\u8ba1\u771f\u5b9e\u611f\u5956\u52b1\u51fd\u6570\u3002", "result": "RealMat\u751f\u6210\u7684\u6750\u8d28\u6bd4\u57fa\u7840\u6a21\u578b\u53ca\u76f8\u5173\u5de5\u4f5c\u66f4\u5177\u771f\u5b9e\u611f\u3002", "conclusion": "RealMat\u901a\u8fc7\u7ed3\u5408\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u7167\u7247\u7684\u6269\u6563\u6a21\u578b\uff0c\u8f85\u4ee5\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6750\u8d28\u7684\u771f\u5b9e\u611f\u3002"}}
{"id": "2509.00708", "pdf": "https://arxiv.org/pdf/2509.00708", "abs": "https://arxiv.org/abs/2509.00708", "authors": ["Jingyi Guan", "Kun Qiu", "Jin Zhao"], "title": "ReWeave: Traffic Engineering with Robust Path Weaving for Localized Link Failure Recover", "categories": ["cs.NI"], "comment": "Accepted in IEEE ICNP 2025", "summary": "Link failures occur frequently in Internet Service Provider (ISP) networks\nand pose significant challenges for Traffic Engineering (TE). Existing TE\nschemes either reroute traffic over vulnerable static paths, leading to\nperformance degradation, or precompute backup routes for a broad range of\nfailure scenarios, which introduces high overhead and limits scalability.\nHence, an effective failure recovery mechanism is required to offer sufficient\npath diversity under constrained overhead, thereby ensuring robust and\nperformant network operation. This paper presents ReWeave, a scalable and\nefficient link-level TE scheme that enables localized rerouting by equipping\neach link with a compact set of adjacent-only backup paths. Upon detecting a\nfailure, only the routers at both ends of the failed link reroute traffic\ndynamically using SRv6-based detours, without controller intervention or\nfull-path recomputation. Evaluation results on large-scale backbone networks\ndemonstrate that ReWeave outperforms existing TE schemes in link failure\nscenarios. Compared to HARP, the state-of-the-art failure recovery scheme based\non centralized control and dynamic traffic reallocation, our approach reduces\nthe average maximum link utilization by 10.5%~20.1%, and lowers the worst-case\nutilization by 29.5%~40.9%. When compared with Flexile, a protection-based\nscheme that precomputes routes for multi-failure scenarios, ReWeave achieves a\nsimilarly low packet loss rate in 90% of failure cases, while maintaining a\nresponse speed comparable to the fastest router-based local rerouting schemes.", "AI": {"tldr": "ReWeave\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u94fe\u8def\u7ea7\u6d41\u91cf\u5de5\u7a0b\u65b9\u6848\uff0c\u901a\u8fc7\u5c40\u90e8\u8def\u7531\u5668\u548c\u7d27\u51d1\u7684\u5907\u4efd\u8def\u5f84\u5b9e\u73b0\u5feb\u901f\u6545\u969c\u6062\u590d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "ISP\u7f51\u7edc\u4e2d\u94fe\u8def\u6545\u969c\u9891\u7e41\uff0c\u73b0\u6709TE\u65b9\u6848\u6216\u56e0\u9759\u6001\u8def\u5f84\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u6216\u56e0\u9884\u8ba1\u7b97\u5907\u4efd\u8def\u5f84\u5f15\u5165\u9ad8\u5f00\u9500\u3002\u9700\u8981\u4e00\u79cd\u4f4e\u5f00\u9500\u3001\u9ad8\u6548\u7684\u6545\u969c\u6062\u590d\u673a\u5236\u3002", "method": "ReWeave\u4e3a\u6bcf\u4e2a\u94fe\u8def\u914d\u5907\u7d27\u51d1\u7684\u4ec5\u76f8\u90bb\u5907\u4efd\u8def\u5f84\uff0c\u5229\u7528SRv6\u52a8\u6001\u7ed5\u884c\uff0c\u65e0\u9700\u63a7\u5236\u5668\u5e72\u9884\u6216\u5168\u8def\u5f84\u91cd\u8ba1\u7b97\u3002", "result": "\u5728\u5927\u89c4\u6a21\u9aa8\u5e72\u7f51\u7edc\u4e2d\uff0cReWeave\u5e73\u5747\u6700\u5927\u94fe\u8def\u5229\u7528\u7387\u964d\u4f4e10.5%~20.1%\uff0c\u6700\u574f\u60c5\u51b5\u964d\u4f4e29.5%~40.9%\uff0c\u4e1490%\u7684\u6545\u969c\u60c5\u51b5\u4e0b\u4e22\u5305\u7387\u63a5\u8fd1Flexile\u3002", "conclusion": "ReWeave\u5728\u6027\u80fd\u548c\u5f00\u9500\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u9002\u5408\u5b9e\u9645\u7f51\u7edc\u90e8\u7f72\u3002"}}
{"id": "2509.01051", "pdf": "https://arxiv.org/pdf/2509.01051", "abs": "https://arxiv.org/abs/2509.01051", "authors": ["Matte Lim", "Catherine Yeh", "Martin Wattenberg", "Fernanda Vi\u00e9gas", "Panagiotis Michalatos"], "title": "Chronotome: Real-Time Topic Modeling for Streaming Embedding Spaces", "categories": ["cs.HC", "cs.CL", "cs.CV", "cs.LG"], "comment": "Accepted to IEEE VIS 2025 Short Paper Track (5 pages, 4 figures)", "summary": "Many real-world datasets -- from an artist's body of work to a person's\nsocial media history -- exhibit meaningful semantic changes over time that are\ndifficult to capture with existing dimensionality reduction methods. To address\nthis gap, we introduce a visualization technique that combines force-based\nprojection and streaming clustering methods to build a spatial-temporal map of\nembeddings. Applying this technique, we create Chronotome, a tool for\ninteractively exploring evolving themes in time-based data -- in real time. We\ndemonstrate the utility of our approach through use cases on text and image\ndata, showing how it offers a new lens for understanding the aesthetics and\nsemantics of temporal datasets.", "AI": {"tldr": "\u4e00\u79cd\u7ed3\u5408\u529b\u5bfc\u5411\u6295\u5f71\u548c\u6d41\u5f0f\u805a\u7c7b\u7684\u53ef\u89c6\u5316\u6280\u672f\uff0c\u7528\u4e8e\u63a2\u7d22\u65f6\u95f4\u6570\u636e\u7684\u6f14\u53d8\u4e3b\u9898\u3002", "motivation": "\u73b0\u6709\u964d\u7ef4\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u65f6\u95f4\u6570\u636e\u4e2d\u7684\u8bed\u4e49\u53d8\u5316\u3002", "method": "\u7ed3\u5408\u529b\u5bfc\u5411\u6295\u5f71\u548c\u6d41\u5f0f\u805a\u7c7b\uff0c\u6784\u5efa\u65f6\u7a7a\u5d4c\u5165\u5730\u56fe\u3002", "result": "\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u5de5\u5177Chronotome\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u6587\u672c\u548c\u56fe\u50cf\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u65f6\u95f4\u6570\u636e\u96c6\u7684\u7f8e\u5b66\u548c\u8bed\u4e49\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2509.00366", "pdf": "https://arxiv.org/pdf/2509.00366", "abs": "https://arxiv.org/abs/2509.00366", "authors": ["Ziyi Guan", "Jason Chun Lok Li", "Zhijian Hou", "Pingping Zhang", "Donglai Xu", "Yuzhi Zhao", "Mengyang Wu", "Jinpeng Chen", "Thanh-Toan Nguyen", "Pengfei Xian", "Wenao Ma", "Shengchao Qin", "Graziano Chesi", "Ngai Wong"], "title": "KG-RAG: Enhancing GUI Agent Decision-Making via Knowledge Graph-Driven Retrieval-Augmented Generation", "categories": ["cs.MA", "cs.CL", "cs.MM"], "comment": "Accepted by the EMNLP 2025", "summary": "Despite recent progress, Graphic User Interface (GUI) agents powered by Large\nLanguage Models (LLMs) struggle with complex mobile tasks due to limited\napp-specific knowledge. While UI Transition Graphs (UTGs) offer structured\nnavigation representations, they are underutilized due to poor extraction and\ninefficient integration. We introduce KG-RAG, a Knowledge Graph-driven\nRetrieval-Augmented Generation framework that transforms fragmented UTGs into\nstructured vector databases for efficient real-time retrieval. By leveraging an\nintent-guided LLM search method, KG-RAG generates actionable navigation paths,\nenhancing agent decision-making. Experiments across diverse mobile apps show\nthat KG-RAG outperforms existing methods, achieving a 75.8% success rate (8.9%\nimprovement over AutoDroid), 84.6% decision accuracy (8.1% improvement), and\nreducing average task steps from 4.5 to 4.1. Additionally, we present\nKG-Android-Bench and KG-Harmony-Bench, two benchmarks tailored to the Chinese\nmobile ecosystem for future research. Finally, KG-RAG transfers to web/desktop\n(+40% SR on Weibo-web; +20% on QQ Music-desktop), and a UTG cost ablation shows\naccuracy saturates at ~4h per complex app, enabling practical deployment\ntrade-offs.", "AI": {"tldr": "KG-RAG\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316UI\u8f6c\u6362\u56fe\u7684\u63d0\u53d6\u4e0e\u96c6\u6210\uff0c\u663e\u8457\u63d0\u5347GUI\u4ee3\u7406\u5728\u590d\u6742\u79fb\u52a8\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684GUI\u4ee3\u7406\u5728\u590d\u6742\u79fb\u52a8\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u5e94\u7528\u7279\u5b9a\u77e5\u8bc6\u4e14UI\u8f6c\u6362\u56fe\u7684\u5229\u7528\u7387\u4f4e\u3002", "method": "\u63d0\u51faKG-RAG\u6846\u67b6\uff0c\u5c06\u788e\u7247\u5316\u7684UI\u8f6c\u6362\u56fe\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u5411\u91cf\u6570\u636e\u5e93\uff0c\u91c7\u7528\u610f\u56fe\u5f15\u5bfc\u7684LLM\u641c\u7d22\u65b9\u6cd5\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u5bfc\u822a\u8def\u5f84\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cKG-RAG\u5728\u591a\u4e2a\u79fb\u52a8\u5e94\u7528\u4e2d\u6210\u529f\u7387\u63d0\u53478.9%\uff0c\u51b3\u7b56\u51c6\u786e\u7387\u63d0\u53478.1%\uff0c\u5e76\u51cf\u5c11\u4e86\u4efb\u52a1\u6b65\u9aa4\u6570\u3002", "conclusion": "KG-RAG\u4e0d\u4ec5\u80fd\u63d0\u5347\u79fb\u52a8\u5e94\u7528\u4e2d\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u8fd8\u80fd\u6269\u5c55\u5230Web\u548c\u684c\u9762\u73af\u5883\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6743\u8861\u65b9\u6848\u3002"}}
{"id": "2509.01919", "pdf": "https://arxiv.org/pdf/2509.01919", "abs": "https://arxiv.org/abs/2509.01919", "authors": ["Seohyun Kim", "Junyoung Lee", "Jongho Park", "Jinhyung Koo", "Sungjin Lee", "Yeseong Kim"], "title": "A Diffusion-Based Framework for Configurable and Realistic Multi-Storage Trace Generation", "categories": ["cs.CV", "cs.PF"], "comment": null, "summary": "We propose DiTTO, a novel diffusion-based framework for generating realistic,\nprecisely configurable, and diverse multi-device storage traces. Leveraging\nadvanced diffusion tech- niques, DiTTO enables the synthesis of high-fidelity\ncontinuous traces that capture temporal dynamics and inter-device dependencies\nwith user-defined configurations. Our experimental results demonstrate that\nDiTTO can generate traces with high fidelity and diversity while aligning\nclosely with guided configurations with only 8% errors.", "AI": {"tldr": "DiTTO\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u4fdd\u771f\u3001\u591a\u6837\u5316\u7684\u591a\u8bbe\u5907\u5b58\u50a8\u8ffd\u8e2a\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u7684\u5b58\u50a8\u8ffd\u8e2a\u6570\u636e\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u9ad8\u4fdd\u771f\u548c\u591a\u6837\u6027\u9700\u6c42\u3002", "method": "\u5229\u7528\u5148\u8fdb\u7684\u6269\u6563\u6280\u672f\u751f\u6210\u8fde\u7eed\u8ffd\u8e2a\u6570\u636e\uff0c\u6355\u6349\u65f6\u95f4\u52a8\u6001\u548c\u8bbe\u5907\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDiTTO\u751f\u6210\u7684\u8ffd\u8e2a\u6570\u636e\u4fdd\u771f\u5ea6\u9ad8\u4e14\u591a\u6837\u5316\uff0c\u914d\u7f6e\u8bef\u5dee\u4ec58%\u3002", "conclusion": "DiTTO\u4e3a\u591a\u8bbe\u5907\u5b58\u50a8\u8ffd\u8e2a\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u914d\u7f6e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00911", "pdf": "https://arxiv.org/pdf/2509.00911", "abs": "https://arxiv.org/abs/2509.00911", "authors": ["Joongho Jo", "Jongsun Park"], "title": "GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing Redundant Sorting while Preserving Rasterization Efficiency", "categories": ["cs.AR", "cs.CV"], "comment": "DAC 2025", "summary": "3D Gaussian Splatting (3D-GS) has emerged as a promising alternative to\nneural radiance fields (NeRF) as it offers high speed as well as high image\nquality in novel view synthesis. Despite these advancements, 3D-GS still\nstruggles to meet the frames per second (FPS) demands of real-time\napplications. In this paper, we introduce GS-TG, a tile-grouping-based\naccelerator that enhances 3D-GS rendering speed by reducing redundant sorting\noperations and preserving rasterization efficiency. GS-TG addresses a critical\ntrade-off issue in 3D-GS rendering: increasing the tile size effectively\nreduces redundant sorting operations, but it concurrently increases unnecessary\nrasterization computations. So, during sorting of the proposed approach, GS-TG\ngroups small tiles (for making large tiles) to share sorting operations across\ntiles within each group, significantly reducing redundant computations. During\nrasterization, a bitmask assigned to each Gaussian identifies relevant small\ntiles, to enable efficient sharing of sorting results. Consequently, GS-TG\nenables sorting to be performed as if a large tile size is used by grouping\ntiles during the sorting stage, while allowing rasterization to proceed with\nthe original small tiles by using bitmasks in the rasterization stage. GS-TG is\na lossless method requiring no retraining or fine-tuning and it can be\nseamlessly integrated with previous 3D-GS optimization techniques. Experimental\nresults show that GS-TG achieves an average speed-up of 1.54 times over\nstate-of-the-art 3D-GS accelerators.", "AI": {"tldr": "3D\u9ad8\u65af\u55b7\u7ed8\uff083D-GS\uff09\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u89c6\u56fe\u5408\u6210\u65b9\u6cd5\uff0c\u4f46\u4ecd\u9700\u63d0\u5347\u5b9e\u65f6\u6027\u3002GS-TG\u901a\u8fc7\u4f18\u5316\u6392\u5e8f\u548c\u5149\u6805\u5316\u64cd\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6e32\u67d3\u901f\u5ea6\u3002", "motivation": "3D-GS\u867d\u5feb\u901f\u4f46\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u5e94\u7528\u7684FPS\u9700\u6c42\uff0cGS-TG\u65e8\u5728\u89e3\u51b3\u6392\u5e8f\u4e0e\u5149\u6805\u5316\u7684\u5197\u4f59\u8ba1\u7b97\u95ee\u9898\u3002", "method": "GS-TG\u901a\u8fc7\u5206\u7ec4\u5c0f\u56fe\u5757\u5171\u4eab\u6392\u5e8f\u64cd\u4f5c\uff0c\u5e76\u4f7f\u7528\u4f4d\u63a9\u7801\u6807\u8bc6\u76f8\u5173\u5c0f\u56fe\u5757\uff0c\u4f18\u5316\u6392\u5e8f\u4e0e\u5149\u6805\u5316\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cGS-TG\u5e73\u5747\u63d0\u901f1.54\u500d\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\u3002", "conclusion": "GS-TG\u662f\u4e00\u79cd\u65e0\u635f\u4f18\u5316\u65b9\u6cd5\uff0c\u53ef\u4e0e\u73b0\u6709\u6280\u672f\u65e0\u7f1d\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u53473D-GS\u7684\u5b9e\u65f6\u6027\u80fd\u3002"}}
{"id": "2509.01193", "pdf": "https://arxiv.org/pdf/2509.01193", "abs": "https://arxiv.org/abs/2509.01193", "authors": ["Sheng Lin", "Fangcheng Fu", "Haoyang Li", "Hao Ge", "Xuanyu Wang", "Jiawen Niu", "Yaofeng Tu", "Bin Cui"], "title": "LobRA: Multi-tenant Fine-tuning over Heterogeneous Data", "categories": ["cs.DC"], "comment": "VLDB 2025, version with appendix", "summary": "With the breakthrough of Transformer-based pre-trained models, the demand for\nfine-tuning (FT) to adapt the base pre-trained models to downstream\napplications continues to grow, so it is essential for service providers to\nreduce the cost of processing FT requests. Low-rank adaption (LoRA) is a widely\nused FT technique that only trains small-scale adapters and keeps the base\nmodel unaltered, conveying the possibility of processing multiple FT tasks by\njointly training different LoRA adapters with a shared base model.\n  Nevertheless, through in-depth analysis, we reveal the efficiency of joint FT\nis dampened by two heterogeneity issues in the training data -- the sequence\nlength variation and skewness. To tackle these issues, we develop LobRA, a\nbrand new framework that supports processing multiple FT tasks by jointly\ntraining LoRA adapters. Two innovative designs are introduced. Firstly, LobRA\ndeploys the FT replicas (i.e., model replicas for FT) with heterogeneous\nresource usages and parallel configurations, matching the diverse workloads\ncaused by the sequence length variation. Secondly, for each training step,\nLobRA takes account of the sequence length skewness and dispatches the training\ndata among the heterogeneous FT replicas to achieve workload balance. We\nconduct experiments to assess the performance of LobRA, validating that it\nsignificantly reduces the GPU seconds required for joint FT by 45.03%-60.67%.", "AI": {"tldr": "LobRA\u6846\u67b6\u901a\u8fc7\u5f02\u6784\u8d44\u6e90\u5206\u914d\u548c\u6570\u636e\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86\u591a\u4efb\u52a1\u8054\u5408\u5fae\u8c03\u4e2d\u7684\u6548\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86GPU\u65f6\u95f4\u6d88\u8017\u3002", "motivation": "\u968f\u7740\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u9700\u6c42\u7684\u589e\u52a0\uff0c\u5982\u4f55\u9ad8\u6548\u5904\u7406\u591a\u4efb\u52a1\u8054\u5408\u5fae\u8c03\u6210\u4e3a\u5173\u952e\u3002LoRA\u6280\u672f\u867d\u80fd\u652f\u6301\u591a\u4efb\u52a1\uff0c\u4f46\u56e0\u8bad\u7ec3\u6570\u636e\u7684\u5f02\u8d28\u6027\uff08\u5e8f\u5217\u957f\u5ea6\u5dee\u5f02\u548c\u504f\u659c\uff09\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86LobRA\u6846\u67b6\uff1a1) \u6839\u636e\u5e8f\u5217\u957f\u5ea6\u53d8\u5316\u90e8\u7f72\u5f02\u6784\u8d44\u6e90\u4f7f\u7528\u7684\u5fae\u8c03\u526f\u672c\uff1b2) \u6839\u636e\u5e8f\u5217\u957f\u5ea6\u504f\u659c\u52a8\u6001\u8c03\u5ea6\u8bad\u7ec3\u6570\u636e\u4ee5\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cLobRA\u5c06\u8054\u5408\u5fae\u8c03\u7684GPU\u65f6\u95f4\u51cf\u5c11\u4e8645.03%-60.67%\u3002", "conclusion": "LobRA\u901a\u8fc7\u9488\u5bf9\u6027\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4efb\u52a1\u5fae\u8c03\u4e2d\u7684\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\uff0c\u4e3a\u670d\u52a1\u63d0\u4f9b\u5546\u964d\u4f4e\u5fae\u8c03\u6210\u672c\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.01891", "pdf": "https://arxiv.org/pdf/2509.01891", "abs": "https://arxiv.org/abs/2509.01891", "authors": ["Amogh PC", "Nagamuthu Vignesh", "Pei Yiyang", "Neelakantam Venkatarayalu", "Pedro Henrique Amorim Rezende", "Shyam Babu Mahato", "Sumei Sun"], "title": "FCT O-RAN: Design and Deployment of a Multi-Vendor End-to-End Private 5G Testbed", "categories": ["cs.NI", "cs.ET"], "comment": "Accepted for presentation at The 3rd Workshop on Next-generation Open\n  and Programmable Radio Access Networks (NG-OPERA 2025), organized in\n  conjunction with IEEE INFOCOM, May 19, 2025", "summary": "The transformation of 5G networks into software-defined, agile, intelligent\nand programmable architectures necessitates a paradigm shift in deployment\nstrategies. To deliver superior performance and surpass traditional systems,\npublic and private 5G networks must adopt software-centric cloud native\nframeworks that enable flexibility through tailored configurations and\noptimized deployment approaches. In Singapore, the Infocomm Media Development\nAuthority (IMDA) and the National Research Foundation Singapore (NRF) launched\nthe Future Communications Research and Development Programme (FCP) to advance\nthe nation's communications and connectivity landscape. At the core of this\ninitiative is the Future Communications Translation Lab (FCT) at the Singapore\nInstitute of Technology (SIT), which focuses on advancing 5G technologies to\nhigher readiness levels, facilitating their adoption across various industries.\nA key component is the deployment of FCT O-RAN, a state-of-the-art multi-vendor\nprivate 5G platform. The setup includes a 5G core network powered by Microsoft\nAffirmed and ENEA, O-RAN Centralized and Distributed Units from Radisys. Indoor\nRemote Units are deployed with Foxconn, while outdoor RUs are deployed with\nBenetel. To optimize the deployment of remote units, a digital twin was created\nusing Wireless InSite, and performance evaluations were conducted for both the\ndigital twin and the private 5G deployment. Smartphones equipped with QualiPoc\nwere used to measure network performance. The testbed demonstrated effective\nperformance with optimized bandwidth allocations for both indoor and outdoor\nenvironments. In the indoor setup, utilizing 50 MHz of bandwidth, a downlink\nthroughput of 713 Mbps and an uplink throughput of 66 Mbps were achieved.\nMeanwhile, the outdoor setup, utilizing 40 MHz of bandwidth, achieved a\ndownlink throughput of 371 Mbps and an uplink throughput of 55 Mbps.", "AI": {"tldr": "\u6458\u8981\u63a2\u8ba8\u4e865G\u7f51\u7edc\u5411\u8f6f\u4ef6\u5b9a\u4e49\u548c\u4e91\u539f\u751f\u67b6\u6784\u7684\u8f6c\u578b\uff0c\u4ecb\u7ecd\u4e86\u65b0\u52a0\u5761FCP\u9879\u76ee\u548cFCT\u5b9e\u9a8c\u5ba4\u57285G\u6280\u672f\u90e8\u7f72\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u548c\u6027\u80fd\u8bc4\u4f30\u4f18\u5316\u7684\u7ed3\u679c\u3002", "motivation": "5G\u7f51\u7edc\u9700\u8981\u5411\u8f6f\u4ef6\u5b9a\u4e49\u548c\u667a\u80fd\u5316\u67b6\u6784\u8f6c\u578b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u7684\u6027\u80fd\u548c\u7075\u6d3b\u6027\uff0cFCP\u9879\u76ee\u65e8\u5728\u63a8\u52a8\u65b0\u52a0\u5761\u5728\u901a\u4fe1\u6280\u672f\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u591a\u5382\u5546\u79c1\u67095G\u5e73\u53f0\uff08FCT O-RAN\uff09\uff0c\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4f18\u5316\u90e8\u7f72\uff0c\u5e76\u901a\u8fc7QualiPoc\u667a\u80fd\u624b\u673a\u6d4b\u91cf\u7f51\u7edc\u6027\u80fd\u3002", "result": "\u5ba4\u5185\u5916\u73af\u5883\u5747\u5b9e\u73b0\u4e86\u4f18\u5316\u7684\u5e26\u5bbd\u5206\u914d\u548c\u9ad8\u541e\u5410\u91cf\uff08\u5ba4\u5185\u4e0b\u884c713 Mbps\uff0c\u4e0a\u884c66 Mbps\uff1b\u5ba4\u5916\u4e0b\u884c371 Mbps\uff0c\u4e0a\u884c55 Mbps\uff09\u3002", "conclusion": "FCT\u5b9e\u9a8c\u5ba4\u76845G\u90e8\u7f72\u5c55\u793a\u4e86\u4e91\u539f\u751f\u548c\u591a\u5382\u5546\u67b6\u6784\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u884c\u4e1a\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u53c2\u8003\u3002"}}
{"id": "2509.00480", "pdf": "https://arxiv.org/pdf/2509.00480", "abs": "https://arxiv.org/abs/2509.00480", "authors": ["Xinkui Zhao", "Rengrong Xiong", "Guanjie Cheng", "Xinhao Jin", "Shawn Shi", "Xiubo Liang", "Gongsheng Yuan", "Xiaoye Miao", "Jianwei Yin", "Shuiguang Deng"], "title": "BPI: A Novel Efficient and Reliable Search Structure for Hybrid Storage Blockchain", "categories": ["cs.DB"], "comment": null, "summary": "Hybrid storage solutions have emerged as potent strategies to alleviate the\ndata storage bottlenecks prevalent in blockchain systems. These solutions\nharness off-chain Storage Services Providers (SPs) in conjunction with\nAuthenticated Data Structures (ADS) to ensure data integrity and accuracy.\nDespite these advancements, the reliance on centralized SPs raises concerns\nabout query correctness. Although ADS can verify the existence of individual\nquery results, they fall short of preventing SPs from omitting valid results.\n  In this paper, we delineate the fundamental distinctions between data search\nin blockchains and traditional database systems. Drawing upon these insights,\nwe introduce BPI, a lightweight framework that enables efficient keyword\nqueries and maintenance with low overhead. We propose \"Articulated Search\", a\nquery pattern specifically designed for blockchain environments that enhances\nsearch efficiency while significantly reducing costs during data user updates.\nFurthermore, BPI employs a suite of validation models to ensure the inclusion\nof all valid content in search results while maintaining low overhead.\n  Extensive experimental evaluations demonstrate that the BPI framework\nachieves outstanding scalability and performance in keyword searches within\nblockchain, surpassing EthMB+ and state of the art search databases commonly\nused in mainstream hybrid storage blockchains (HSB).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6BPI\uff0c\u7528\u4e8e\u89e3\u51b3\u533a\u5757\u94fe\u6df7\u5408\u5b58\u50a8\u4e2d\u7684\u6570\u636e\u67e5\u8be2\u95ee\u9898\uff0c\u901a\u8fc7\u201cArticulated Search\u201d\u6a21\u5f0f\u548c\u9a8c\u8bc1\u6a21\u578b\u63d0\u9ad8\u4e86\u67e5\u8be2\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u533a\u5757\u94fe\u6df7\u5408\u5b58\u50a8\u4f9d\u8d56\u4e2d\u5fc3\u5316\u5b58\u50a8\u670d\u52a1\u63d0\u4f9b\u5546\uff08SPs\uff09\uff0c\u53ef\u80fd\u5bfc\u81f4\u67e5\u8be2\u7ed3\u679c\u9057\u6f0f\u95ee\u9898\uff0c\u73b0\u6709\u8ba4\u8bc1\u6570\u636e\u7ed3\u6784\uff08ADS\uff09\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u8fd9\u4e00\u7f3a\u9677\u3002", "method": "\u63d0\u51faBPI\u6846\u67b6\uff0c\u5f15\u5165\u201cArticulated Search\u201d\u67e5\u8be2\u6a21\u5f0f\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u6a21\u578b\uff0c\u786e\u4fdd\u67e5\u8be2\u7ed3\u679c\u5b8c\u6574\u4e14\u9ad8\u6548\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eBPI\u5728\u533a\u5757\u94fe\u4e2d\u7684\u5173\u952e\u8bcd\u67e5\u8be2\u6027\u80fd\u548c\u6269\u5c55\u6027\u4f18\u4e8eEthMB+\u53ca\u5176\u4ed6\u4e3b\u6d41\u6df7\u5408\u5b58\u50a8\u533a\u5757\u94fe\u7684\u641c\u7d22\u6570\u636e\u5e93\u3002", "conclusion": "BPI\u901a\u8fc7\u521b\u65b0\u7684\u67e5\u8be2\u548c\u9a8c\u8bc1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533a\u5757\u94fe\u6570\u636e\u67e5\u8be2\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.01006", "pdf": "https://arxiv.org/pdf/2509.01006", "abs": "https://arxiv.org/abs/2509.01006", "authors": ["Daniela Damian", "Bachan Ghimire", "Ze Shi Li"], "title": "REConnect: Participatory RE that Matters", "categories": ["cs.SE"], "comment": "23 pages", "summary": "Software increasingly shapes the infrastructures of daily life, making\nrequirements engineering (RE) central to ensuring that systems align with human\nvalues and lived experiences. Yet, current popular practices such as CrowdRE\nand AI-assisted elicitation strategies risk detaching requirements work from\nthe cultural, social, and political contexts that shape lived experiences,\nhuman values, and real user needs. In this paper, we introduce REConnect that\nre-centers RE on the human connection as central to the understanding of lived\nexperiences where impact is sought. REConnect advocates for a human-centered\nparticipatory approach \"that matters\" to the communities and beneficiaries\ninvolved, ensuring alignment with their values and aspirations. Drawing on\nthree case studies of societal impact: BloodSync in rural Nepal, Herluma\nsupporting women at risk of homelessness in Canada, and BridgingRoots to\nrevitalize Indigenous languages in the Canadian Arctic. REConnect argues that\nthree key principles and enablers: building trusting relationships,\nco-designing with and alongside stakeholders, and empowering users as agents of\nchange, can yield requirements that are culturally grounded, socially\nlegitimate, and sustainable beyond system delivery. REConnect also proposes a\nset of actionable practices (REActions) that embed relationality and ongoing\nstakeholder engagement throughout requirements elicitation, analysis, and\nvalidation of solution development. Finally, we situate REConnect in the era of\nGenerative AI. While AI can accelerate and scale certain RE tasks, its\nintegration must be guided by participatory practices that not only preserve\nhuman agency but also empower humans' roles to become guardians of values and\nethics, inclusion amplifiers, curators of AI outputs, and co-reflectors in\niterative review cycles.", "AI": {"tldr": "REConnect\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u4eba\u7c7b\u8fde\u63a5\u4e3a\u4e2d\u5fc3\u7684\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5f3a\u8c03\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\uff0c\u786e\u4fdd\u4e0e\u5229\u76ca\u76f8\u5173\u8005\u7684\u4ef7\u503c\u89c2\u548c\u613f\u666f\u4e00\u81f4\u3002\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5176\u5173\u952e\u539f\u5219\u548c\u5b9e\u8df5\u3002", "motivation": "\u5f53\u524d\u7684\u9700\u6c42\u5de5\u7a0b\u5b9e\u8df5\uff08\u5982CrowdRE\u548cAI\u8f85\u52a9\u7b56\u7565\uff09\u53ef\u80fd\u5ffd\u89c6\u4e86\u6587\u5316\u3001\u793e\u4f1a\u548c\u653f\u6cbb\u80cc\u666f\uff0c\u5bfc\u81f4\u4e0e\u7528\u6237\u9700\u6c42\u548c\u4ef7\u503c\u89c2\u8131\u8282\u3002", "method": "REConnect\u91c7\u7528\u53c2\u4e0e\u5f0f\u65b9\u6cd5\uff0c\u6ce8\u91cd\u5efa\u7acb\u4fe1\u4efb\u5173\u7cfb\u3001\u5171\u540c\u8bbe\u8ba1\u548c\u8d4b\u80fd\u7528\u6237\uff0c\u5e76\u901a\u8fc7REActions\u5d4c\u5165\u6301\u7eed\u7684\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cREConnect\u80fd\u591f\u4ea7\u751f\u6587\u5316\u624e\u6839\u3001\u793e\u4f1a\u5408\u6cd5\u4e14\u53ef\u6301\u7eed\u7684\u9700\u6c42\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "REConnect\u4e3a\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u4ee5\u4eba\u4e3a\u672c\u7684\u6846\u67b6\uff0c\u5c24\u5176\u662f\u5728\u751f\u6210\u5f0fAI\u65f6\u4ee3\uff0c\u9700\u8981\u786e\u4fddAI\u7684\u6574\u5408\u4e0d\u4f1a\u524a\u5f31\u4eba\u7c7b\u7684\u6838\u5fc3\u4f5c\u7528\u3002"}}
{"id": "2509.01728", "pdf": "https://arxiv.org/pdf/2509.01728", "abs": "https://arxiv.org/abs/2509.01728", "authors": ["Parv Kapoor", "Akila Ganlath", "Changliu Liu", "Sebastian Scherer", "Eunsuk Kang"], "title": "Constrained Decoding for Robotics Foundation Models", "categories": ["cs.RO", "cs.LG", "cs.LO"], "comment": null, "summary": "Recent advances in the development of robotic foundation models have led to\npromising end-to-end and general-purpose capabilities in robotic systems. These\nmodels are pretrained on vast datasets of robot trajectories to process multi-\nmodal inputs and directly output a sequence of action that the system then\nexecutes in the real world. Although this approach is attractive from the\nperspective of im- proved generalization across diverse tasks, these models are\nstill data-driven and, therefore, lack explicit notions of behavioral\ncorrectness and safety constraints. We address these limitations by introducing\na constrained decoding framework for robotics foundation models that enforces\nlogical constraints on action trajec- tories in dynamical systems. Our method\nensures that generated actions provably satisfy signal temporal logic (STL)\nspecifications at runtime without retraining, while remaining agnostic of the\nunderlying foundation model. We perform com- prehensive evaluation of our\napproach across state-of-the-art navigation founda- tion models and we show\nthat our decoding-time interventions are useful not only for filtering unsafe\nactions but also for conditional action-generation. Videos available on our\nwebsite: https://constrained-robot-fms.github.io", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ea6\u675f\u89e3\u7801\u6846\u67b6\uff0c\u786e\u4fdd\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b\u751f\u6210\u7684\u884c\u52a8\u5728\u8fd0\u884c\u65f6\u6ee1\u8db3\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u89c4\u8303\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u57fa\u7840\u6a21\u578b\u7684\u72ec\u7acb\u6027\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b\u5728\u591a\u4efb\u52a1\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u5bf9\u884c\u4e3a\u6b63\u786e\u6027\u548c\u5b89\u5168\u7ea6\u675f\u7684\u660e\u786e\u8003\u8651\uff0c\u56e0\u6b64\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u7ea6\u675f\u89e3\u7801\u6846\u67b6\uff0c\u5728\u52a8\u6001\u7cfb\u7edf\u4e2d\u5bf9\u884c\u52a8\u8f68\u8ff9\u5f3a\u5236\u6267\u884c\u903b\u8f91\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u8fc7\u6ee4\u4e0d\u5b89\u5168\u884c\u52a8\uff0c\u8fd8\u80fd\u5b9e\u73b0\u6761\u4ef6\u884c\u52a8\u751f\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8fd0\u884c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u884c\u4e3a\u6b63\u786e\u6027\u3002"}}
{"id": "2509.02197", "pdf": "https://arxiv.org/pdf/2509.02197", "abs": "https://arxiv.org/abs/2509.02197", "authors": ["Afif Boudaoud", "Alexandru Calotoiu", "Marcin Copik", "Torsten Hoefler"], "title": "DaCe AD: Unifying High-Performance Automatic Differentiation for Machine Learning and Scientific Computing", "categories": ["cs.LG", "cs.PF", "cs.PL"], "comment": null, "summary": "Automatic differentiation (AD) is a set of techniques that systematically\napplies the chain rule to compute the gradients of functions without requiring\nhuman intervention. Although the fundamentals of this technology were\nestablished decades ago, it is experiencing a renaissance as it plays a key\nrole in efficiently computing gradients for backpropagation in machine learning\nalgorithms. AD is also crucial for many applications in scientific computing\ndomains, particularly emerging techniques that integrate machine learning\nmodels within scientific simulations and schemes. Existing AD frameworks have\nfour main limitations: limited support of programming languages, requiring code\nmodifications for AD compatibility, limited performance on scientific computing\ncodes, and a naive store-all solution for forward-pass data required for\ngradient calculations. These limitations force domain scientists to manually\ncompute the gradients for large problems. This work presents DaCe AD, a\ngeneral, efficient automatic differentiation engine that requires no code\nmodifications. DaCe AD uses a novel ILP-based algorithm to optimize the\ntrade-off between storing and recomputing to achieve maximum performance within\na given memory constraint. We showcase the generality of our method by applying\nit to NPBench, a suite of HPC benchmarks with diverse scientific computing\npatterns, where we outperform JAX, a Python framework with state-of-the-art\ngeneral AD capabilities, by more than 92 times on average without requiring any\ncode changes.", "AI": {"tldr": "DaCe AD\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u7684\u81ea\u52a8\u5fae\u5206\u5f15\u64ce\uff0c\u65e0\u9700\u4ee3\u7801\u4fee\u6539\uff0c\u901a\u8fc7\u65b0\u9896\u7684ILP\u7b97\u6cd5\u4f18\u5316\u5b58\u50a8\u4e0e\u91cd\u8ba1\u7b97\u7684\u6743\u8861\uff0c\u5728HPC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6027\u80fd\u8d85\u8fc7JAX 92\u500d\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5fae\u5206\u6846\u67b6\u5b58\u5728\u8bed\u8a00\u652f\u6301\u6709\u9650\u3001\u9700\u4ee3\u7801\u4fee\u6539\u3001\u79d1\u5b66\u8ba1\u7b97\u6027\u80fd\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u79d1\u5b66\u5bb6\u9700\u624b\u52a8\u8ba1\u7b97\u68af\u5ea6\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002", "method": "\u63d0\u51faDaCe AD\uff0c\u91c7\u7528ILP\u7b97\u6cd5\u4f18\u5316\u5b58\u50a8\u4e0e\u91cd\u8ba1\u7b97\u7684\u7ba1\u7406\uff0c\u65e0\u9700\u4fee\u6539\u4ee3\u7801\u5373\u53ef\u9ad8\u6548\u8ba1\u7b97\u68af\u5ea6\u3002", "result": "\u5728NPBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDaCe AD\u5e73\u5747\u6027\u80fd\u8d85\u8fc7JAX 92\u500d\uff0c\u65e0\u9700\u4efb\u4f55\u4ee3\u7801\u4fee\u6539\u3002", "conclusion": "DaCe AD\u89e3\u51b3\u4e86\u73b0\u6709\u6846\u67b6\u7684\u591a\u9879\u9650\u5236\uff0c\u4e3a\u79d1\u5b66\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u81ea\u52a8\u5fae\u5206\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00868", "pdf": "https://arxiv.org/pdf/2509.00868", "abs": "https://arxiv.org/abs/2509.00868", "authors": ["Yong Su", "Yiyi Chen", "Shenghong Yi", "Hui Feng", "Yuedong Xu", "Wang Xiang", "Bo Hu"], "title": "A Modular and Scalable Simulator for Connected-UAVs Communication in 5G Networks", "categories": ["cs.NI"], "comment": "a short version is accepted by MSWiM 2025", "summary": "Cellular-connected UAV systems have enabled a wide range of low-altitude\naerial services. However, these systems still face many challenges, such as\nfrequent handovers and the inefficiency of traditional transport protocols. To\nbetter study these issues, we develop a modular and scalable simulation\nplatform specifically designed for UAVs communication leveraging the research\necology in wireless communication of MATLAB. The platform supports flexible 5G\nNR node deployment, customizable UAVs mobility models, and\nmulti-network-interface extensions. It also supports multiple transport\nprotocols including TCP, UDP, QUIC, etc., allowing to investigate how different\ntransport protocols affect UAVs communication performance.In addition, the\nplatform includes a handover management module, enabling the evaluation of both\ntraditional and learning-based handover strategies. Our platform can serve as a\ntestbed for the development and evaluation of advanced transmission strategies\nin cellular-connected UAV systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u4eff\u771f\u5e73\u53f0\uff0c\u7528\u4e8e\u7814\u7a76\u65e0\u4eba\u673a\u901a\u4fe1\u4e2d\u7684\u9891\u7e41\u5207\u6362\u548c\u4f20\u7edf\u4f20\u8f93\u534f\u8bae\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u65e0\u4eba\u673a\u901a\u4fe1\u7cfb\u7edf\u9762\u4e34\u9891\u7e41\u5207\u6362\u548c\u4f20\u7edf\u4f20\u8f93\u534f\u8bae\u6548\u7387\u4f4e\u7684\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u7684\u4eff\u771f\u5e73\u53f0\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u5229\u7528MATLAB\u65e0\u7ebf\u901a\u4fe1\u7814\u7a76\u751f\u6001\uff0c\u5f00\u53d1\u652f\u63015G NR\u8282\u70b9\u90e8\u7f72\u3001\u81ea\u5b9a\u4e49\u65e0\u4eba\u673a\u79fb\u52a8\u6a21\u578b\u548c\u591a\u7f51\u7edc\u63a5\u53e3\u6269\u5c55\u7684\u5e73\u53f0\u3002", "result": "\u5e73\u53f0\u652f\u6301\u591a\u79cd\u4f20\u8f93\u534f\u8bae\u548c\u5207\u6362\u7ba1\u7406\u6a21\u5757\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u534f\u8bae\u548c\u5207\u6362\u7b56\u7565\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u5e73\u53f0\u53ef\u4f5c\u4e3a\u8702\u7a9d\u8fde\u63a5\u65e0\u4eba\u673a\u7cfb\u7edf\u9ad8\u7ea7\u4f20\u8f93\u7b56\u7565\u5f00\u53d1\u548c\u8bc4\u4f30\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2509.01089", "pdf": "https://arxiv.org/pdf/2509.01089", "abs": "https://arxiv.org/abs/2509.01089", "authors": ["Jinjoo Shim", "Jacob Hunecke", "Elgar Fleisch", "Filipe Barata"], "title": "CosinorAge: Unified Python and Web Platform for Biological Age Estimation from Wearable- and Smartwatch-Based Activity Rhythms", "categories": ["cs.HC"], "comment": "7 pages - 4 figures", "summary": "Every day, millions of people worldwide track their steps, sleep, and\nactivity rhythms with smartwatches and fitness trackers. These continuously\ncollected data streams present a remarkable opportunity to transform routine\nself-tracking into meaningful health insights that enable individuals to\nunderstand -- and potentially influence -- their biological aging. Yet most\ntools for analyzing wearable data remain fragmented, proprietary, and\ninaccessible, creating a major barrier between this vast reservoir of personal\nhealth information and its translation into actionable insights on aging.\nCosinorAge is an open-source framework that estimates biological age from\nwearable-derived circadian, physical activity, and sleep metrics. It addresses\nthe lack of unified, reproducible pipelines for jointly analyzing\nrest--activity rhythmicity, physical activity, and sleep, and linking them to\nhealth outcomes. The Python package provides an end-to-end workflow from raw\ndata ingestion and preprocessing to feature computation and biological age\nestimation, supporting multiple input sources across wearables and smartwatch.\nIt also makes available trained model parameters (open weights) derived from\nlarge-scale population datasets such as UK Biobank, enabling reproducibility,\ntransparency, and generalizability across studies. Its companion web-based\nCosinorAge Calculator enables non-technical users to access identical\nanalytical capabilities through an intuitive interface. By combining\ntransparent, reproducible analysis with broad accessibility, CosinorAge\nadvances scalable, personalized health monitoring and bridges digital health\ntechnologies with biological aging research.", "AI": {"tldr": "CosinorAge\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u8bbe\u5907\u6570\u636e\u4f30\u7b97\u751f\u7269\u5e74\u9f84\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5206\u6790\u5de5\u5177\u5206\u6563\u3001\u4e13\u6709\u548c\u96be\u4ee5\u8bbf\u95ee\u7684\u95ee\u9898\u3002", "motivation": "\u5c06\u667a\u80fd\u8bbe\u5907\u6536\u96c6\u7684\u4e2a\u4eba\u5065\u5eb7\u6570\u636e\u8f6c\u5316\u4e3a\u6709\u610f\u4e49\u7684\u5065\u5eb7\u6d1e\u5bdf\uff0c\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u5e76\u5f71\u54cd\u5176\u751f\u7269\u5e74\u9f84\u3002", "method": "\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u5de5\u4f5c\u6d41\uff0c\u4ece\u539f\u59cb\u6570\u636e\u9884\u5904\u7406\u5230\u7279\u5f81\u8ba1\u7b97\u548c\u751f\u7269\u5e74\u9f84\u4f30\u7b97\uff0c\u652f\u6301\u591a\u79cd\u8bbe\u5907\u6570\u636e\u8f93\u5165\uff0c\u5e76\u63d0\u4f9b\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u3002", "result": "CosinorAge\u901a\u8fc7\u7edf\u4e00\u7684\u3001\u53ef\u590d\u73b0\u7684\u7ba1\u9053\u5206\u6790\u663c\u591c\u8282\u5f8b\u3001\u6d3b\u52a8\u548c\u7761\u7720\u6570\u636e\uff0c\u5e76\u94fe\u63a5\u5230\u5065\u5eb7\u7ed3\u679c\u3002", "conclusion": "\u8be5\u5de5\u5177\u7ed3\u5408\u900f\u660e\u53ef\u590d\u73b0\u7684\u5206\u6790\u548c\u5e7f\u6cdb\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u63a8\u52a8\u4e86\u4e2a\u6027\u5316\u5065\u5eb7\u76d1\u63a7\u7684\u53d1\u5c55\uff0c\u5e76\u8fde\u63a5\u4e86\u6570\u5b57\u5065\u5eb7\u6280\u672f\u4e0e\u751f\u7269\u8870\u8001\u7814\u7a76\u3002"}}
{"id": "2509.00654", "pdf": "https://arxiv.org/pdf/2509.00654", "abs": "https://arxiv.org/abs/2509.00654", "authors": ["Ashwin Nagarajan", "Hao-Wen Dong"], "title": "The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "10 pages, 2 figures", "summary": "Text-to-music models capture broad attributes such as instrumentation or\nmood, but fine-grained stylistic control remains an open challenge. Existing\nstylization methods typically require retraining or specialized conditioning,\nwhich complicates reproducibility and limits policy compliance when artist\nnames are restricted. We study whether lightweight, human-readable modifiers\nsampled from a large language model can provide a policy-robust alternative for\nstylistic control. Using MusicGen-small, we evaluate two artists: Billie Eilish\n(vocal pop) and Ludovico Einaudi (instrumental piano). For each artist, we use\nfifteen reference excerpts and evaluate matched seeds under three conditions:\nbaseline prompts, artist-name prompts, and five descriptor sets. All prompts\nare generated using a large language model. Evaluation uses both VGGish and\nCLAP embeddings with distributional and per-clip similarity measures, including\na new min-distance attribution metric. Results show that artist names are the\nstrongest control signal across both artists, while name-free descriptors\nrecover much of this effect. This highlights that existing safeguards such as\nthe restriction of artist names in music generation prompts may not fully\nprevent style imitation. Cross-artist transfers reduce alignment, showing that\ndescriptors encode targeted stylistic cues. We also present a descriptor table\nacross ten contemporary artists to illustrate the breadth of the tokens.\nTogether these findings define the name-free gap, the controllability\ndifference between artist-name prompts and policy-compliant descriptors, shown\nthrough a reproducible evaluation protocol for prompt-level controllability.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u8f7b\u91cf\u7ea7\u3001\u6613\u4e8e\u7406\u89e3\u7684\u4fee\u9970\u7b26\u662f\u5426\u80fd\u66ff\u4ee3\u9700\u8981\u91cd\u8bad\u7ec3\u6216\u4e13\u7528\u6761\u4ef6\u7684\u73b0\u6709\u65b9\u6cd5\uff0c\u7528\u4e8e\u97f3\u4e50\u751f\u6210\u4e2d\u7684\u7ec6\u7c92\u5ea6\u98ce\u683c\u63a7\u5236\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u98ce\u683c\u5316\u65b9\u6cd5\u4e2d\u56e0\u9700\u8981\u91cd\u8bad\u7ec3\u6216\u4e13\u7528\u6761\u4ef6\u800c\u96be\u4ee5\u590d\u73b0\u6216\u53d7\u9650\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u827a\u672f\u5bb6\u540d\u79f0\u88ab\u9650\u5236\u65f6\u65e0\u6cd5\u5408\u89c4\u4f7f\u7528\u3002", "method": "\u57fa\u4e8eMusicGen-small\u6a21\u578b\uff0c\u6bd4\u8f83\u57fa\u7ebf\u63d0\u793a\u3001\u827a\u672f\u5bb6\u540d\u79f0\u63d0\u793a\u548c\u63cf\u8ff0\u7b26\u96c6\u5408\uff0c\u5229\u7528VGGish\u548cCLAP\u5d4c\u5165\u8bc4\u4f30\u98ce\u683c\u63a7\u5236\u6548\u679c\u3002", "result": "\u827a\u672f\u5bb6\u540d\u79f0\u662f\u6700\u5f3a\u7684\u63a7\u5236\u4fe1\u53f7\uff0c\u4f46\u63cf\u8ff0\u7b26\u80fd\u90e8\u5206\u66ff\u4ee3\uff1b\u8de8\u827a\u672f\u5bb6\u4f20\u9012\u6548\u679c\u51cf\u5f31\uff0c\u663e\u793a\u63cf\u8ff0\u7b26\u9488\u5bf9\u7279\u5b9a\u98ce\u683c\u7ebf\u7d22\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5355\u7eaf\u9650\u5236\u827a\u672f\u5bb6\u540d\u79f0\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u9632\u6b62\u98ce\u683c\u6a21\u4eff\uff0c\u9700\u5f00\u53d1\u53ef\u590d\u73b0\u7684\u8bc4\u6d4b\u534f\u8bae\u6765\u586b\u8865\u65e0\u540d\u79f0\u95f4\u9699\u3002"}}
{"id": "2509.01229", "pdf": "https://arxiv.org/pdf/2509.01229", "abs": "https://arxiv.org/abs/2509.01229", "authors": ["Huanqi Hu", "Bowen Xiao", "Shixuan Sun", "Jianian Yin", "Zhexi Zhang", "Xiang Luo", "Chengquan Jiang", "Weiqi Xu", "Xiaoying Jia", "Xin Liu", "Minyi Guo"], "title": "LiquidGEMM: Hardware-Efficient W4A8 GEMM Kernel for High-Performance LLM Serving", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "12 pages, 13 figures", "summary": "Quantization is a critical technique for accelerating LLM inference by\nreducing memory footprint and improving computational efficiency. Among various\nschemes, 4-bit weight and 8-bit activation quantization (W4A8) offers a strong\nbalance between accuracy and performance. However, existing W4A8 GEMM kernels\nfall short in practice due to inefficient dequantization on CUDA Cores, which\ncannot keep pace with the high throughput of Tensor Cores. In this paper, we\npresent LiquidGEMM, a hardware-efficient W4A8 GEMM kernel for efficient LLM\nserving. LiquidGEMM designs two key techniques: LiquidQuant, a\nhardware-efficient quantization method that enables fast, overflow-safe\ndequantization using just two arithmetic instructions per four elements; and an\nimplicit fine-grained pipeline that fully overlaps weight loading,\ndequantization, and MMA across warp groups without software synchronization or\nredundant memory traffic. Experimental results show that LiquidGEMM achieves up\nto 2.90x speedup over state-of-the-art W4A8 kernels and up to 4.94x end-to-end\nsystem-level speedup. Compared to various quantized GEMM kernels in NVIDIA\nTensorRT-LLM, LiquidGEMM delivers 1.12-1.63x performance gains, and achieves up\nto 1.63x system-level speedup.", "AI": {"tldr": "LiquidGEMM\u662f\u4e00\u79cd\u9ad8\u6548\u7684W4A8 GEMM\u6838\u5fc3\uff0c\u901a\u8fc7LiquidQuant\u548c\u9690\u5f0f\u7ec6\u7c92\u5ea6\u7ba1\u9053\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709W4A8 GEMM\u6838\u5fc3\u56e0CUDA Core\u6548\u7387\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528Tensor Core\u9ad8\u541e\u5410\u91cf\uff0c\u9650\u5236\u4e86\u91cf\u5316\u52a0\u901f\u7684\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86LiquidQuant\u786c\u4ef6\u9ad8\u6548\u91cf\u5316\u65b9\u6cd5\u548c\u9690\u5f0f\u7ec6\u7c92\u5ea6\u7ba1\u9053\u6280\u672f\uff0c\u5b9e\u73b0\u65e0\u8f6f\u4ef6\u540c\u6b65\u7684\u6743\u91cd\u52a0\u8f7d\u3001\u53cd\u91cf\u5316\u548cMMA\u91cd\u53e0\u3002", "result": "LiquidGEMM\u6bd4\u73b0\u6709W4A8\u6838\u5fc3\u5feb2.90\u500d\uff0c\u7cfb\u7edf\u7ea7\u52a0\u901f\u8fbe4.94\u500d\uff1b\u5728TensorRT-LLM\u4e2d\u6027\u80fd\u63d0\u53471.12-1.63\u500d\u3002", "conclusion": "LiquidGEMM\u901a\u8fc7\u786c\u4ef6\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86\u91cf\u5316\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u9ad8\u6548LLM\u670d\u52a1\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01954", "pdf": "https://arxiv.org/pdf/2509.01954", "abs": "https://arxiv.org/abs/2509.01954", "authors": ["Nirmalya Thakur", "Madeline D Hartel", "Lane Michael Boden", "Dallas Enriquez", "Boston Joyner Ricks"], "title": "Content and Engagement Trends in COVID-19 YouTube Videos: Evidence from the Late Pandemic", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.ET", "cs.LG", "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"], "comment": null, "summary": "This work investigated about 10,000 COVID-19-related YouTube videos published\nbetween January 2023 and October 2024 to evaluate how temporal, lexical,\nlinguistic, and structural factors influenced engagement during the late\npandemic period. Publishing activity showed consistent weekday effects: in the\nfirst window, average views peaked on Mondays at 92,658; in the second, on\nWednesdays at 115,479; and in the third, on Fridays at 84,874, reflecting a\nshift in audience attention toward mid- and late week. Lexical analysis of\nvideo titles revealed recurring high-frequency keywords related to COVID-19 and\nYouTube features, including COVID, coronavirus, shorts, and live. Frequency\nanalysis revealed sharp spikes, with COVID appearing in 799 video titles in\nAugust 2024, while engagement analysis showed that videos titled with shorts\nattracted very high views, peaking at 2.16 million average views per video in\nJune 2023. Analysis of sentiment of video descriptions in English showed weak\ncorrelation with views in the raw data (Pearson r = 0.0154, p = 0.2987), but\nstronger correlations emerged once outliers were addressed, with Spearman r =\n0.110 (p < 0.001) and Pearson r = 0.0925 (p < 0.001). Category-level analysis\nof video durations revealed contrasting outcomes: long videos focusing on\npeople and blogs averaged 209,114 views, short entertainment videos averaged\n288,675 views, and medium-to-long news and politics videos averaged 51,309 and\n59,226 views, respectively. These results demonstrate that engagement patterns\nof COVID-19-related videos on YouTube during the late pandemic followed\ndistinct characteristics driven by publishing schedules, title vocabulary,\ntopics, and genre-specific duration effects.", "AI": {"tldr": "\u7814\u7a76\u4e862023\u5e74\u81f32024\u5e74\u95f4\u76841\u4e07\u6761COVID-19\u76f8\u5173YouTube\u89c6\u9891\uff0c\u5206\u6790\u4e86\u65f6\u95f4\u3001\u8bcd\u6c47\u3001\u8bed\u8a00\u548c\u7ed3\u6784\u56e0\u7d20\u5bf9\u53d7\u4f17\u53c2\u4e0e\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u75ab\u60c5\u540e\u671fYouTube\u89c6\u9891\u7684\u53d7\u4f17\u53c2\u4e0e\u6a21\u5f0f\uff0c\u63ed\u793a\u53d1\u5e03\u8ba1\u5212\u3001\u6807\u9898\u8bcd\u6c47\u3001\u4e3b\u9898\u548c\u89c6\u9891\u65f6\u957f\u7b49\u56e0\u7d20\u5bf9\u89c2\u770b\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790\u4e86\u89c6\u9891\u7684\u53d1\u5e03\u65f6\u95f4\u3001\u6807\u9898\u8bcd\u6c47\u9891\u7387\u3001\u60c5\u611f\u5206\u6790\u548c\u89c6\u9891\u65f6\u957f\u7b49\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u7edf\u8ba1\u65b9\u6cd5\u8bc4\u4f30\u4e86\u76f8\u5173\u6027\u3002", "result": "\u53d1\u73b0\u53d1\u5e03\u65f6\u95f4\u7684\u5468\u5185\u6548\u5e94\u3001\u7279\u5b9a\u8bcd\u6c47\uff08\u5982\"shorts\"\uff09\u7684\u9ad8\u89c2\u770b\u91cf\uff0c\u4ee5\u53ca\u89c6\u9891\u65f6\u957f\u4e0e\u7c7b\u522b\u7684\u663e\u8457\u5f71\u54cd\u3002\u60c5\u611f\u5206\u6790\u7684\u76f8\u5173\u7cfb\u6570\u5728\u6392\u9664\u5f02\u5e38\u503c\u540e\u589e\u5f3a\u3002", "conclusion": "\u75ab\u60c5\u540e\u671fYouTube\u89c6\u9891\u7684\u53d7\u4f17\u53c2\u4e0e\u6a21\u5f0f\u53d7\u591a\u79cd\u56e0\u7d20\u9a71\u52a8\uff0c\u5305\u62ec\u53d1\u5e03\u65f6\u95f4\u3001\u6807\u9898\u8bcd\u6c47\u548c\u89c6\u9891\u7c7b\u522b\u4e0e\u65f6\u957f\u7684\u7ec4\u5408\u6548\u5e94\u3002"}}
{"id": "2509.00581", "pdf": "https://arxiv.org/pdf/2509.00581", "abs": "https://arxiv.org/abs/2509.00581", "authors": ["Saumya Chaturvedi", "Aman Chadha", "Laurent Bindschaedler"], "title": "SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Converting natural language queries into SQL queries is a crucial challenge\nin both industry and academia, aiming to increase access to databases and\nlarge-scale applications. This work examines how in-context learning and\nchain-of-thought can be utilized to develop a robust solution for text-to-SQL\nsystems. We propose SQL-of-Thought: a multi-agent framework that decomposes the\nText2SQL task into schema linking, subproblem identification, query plan\ngeneration, SQL generation, and a guided correction loop. Unlike prior systems\nthat rely only on execution-based static correction, we introduce\ntaxonomy-guided dynamic error modification informed by in-context learning.\nSQL-of-Thought achieves state-of-the-art results on the Spider dataset and its\nvariants, combining guided error taxonomy with reasoning-based query planning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSQL-of-Thought\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3Text2SQL\u4efb\u52a1\u5e76\u5f15\u5165\u52a8\u6001\u9519\u8bef\u4fee\u6b63\u65b9\u6cd5\uff0c\u5728Spider\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f18\u6548\u679c\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\u67e5\u8be2\u7684\u6311\u6218\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u6570\u636e\u5e93\u548c\u5927\u89c4\u6a21\u5e94\u7528\u7684\u8bbf\u95ee\u6027\u3002", "method": "\u91c7\u7528SQL-of-Thought\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u6a21\u5f0f\u94fe\u63a5\u3001\u5b50\u95ee\u9898\u8bc6\u522b\u3001\u67e5\u8be2\u8ba1\u5212\u751f\u6210\u3001SQL\u751f\u6210\u548c\u52a8\u6001\u9519\u8bef\u4fee\u6b63\u3002", "result": "\u5728Spider\u6570\u636e\u96c6\u53ca\u5176\u53d8\u4f53\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u9519\u8bef\u4fee\u6b63\u548c\u63a8\u7406\u5f0f\u67e5\u8be2\u89c4\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u5230SQL\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2509.01048", "pdf": "https://arxiv.org/pdf/2509.01048", "abs": "https://arxiv.org/abs/2509.01048", "authors": ["Ateeq Sharfuddin", "Travis Breaux"], "title": "Generative Goal Modeling", "categories": ["cs.SE", "D.2.1"], "comment": "11 pages,", "summary": "In software engineering, requirements may be acquired from stakeholders\nthrough elicitation methods, such as interviews, observational studies, and\nfocus groups. When supporting acquisition from interviews, business analysts\nmust review transcripts to identify and document requirements. Goal modeling is\na popular technique for representing early stakeholder requirements as it lends\nitself to various analyses, including refinement to map high-level goals into\nsoftware operations, and conflict and obstacle analysis. In this paper, we\ndescribe an approach to use textual entailment to reliably extract goals from\ninterview transcripts and to construct goal models. The approach has been\nevaluated on 15 interview transcripts across 29 application domains. The\nfindings show that GPT-4o can reliably extract goals from interview\ntranscripts, matching 62.0% of goals acquired by humans from the same\ntranscripts, and that GPT-4o can trace goals to originating text in the\ntranscript with 98.7% accuracy. In addition, when evaluated by human\nannotators, GPT-4o generates goal model refinement relationships among\nextracted goals with 72.2% accuracy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u6587\u672c\u8574\u542b\u6280\u672f\u4ece\u8bbf\u8c08\u8bb0\u5f55\u4e2d\u63d0\u53d6\u76ee\u6807\u5e76\u6784\u5efa\u76ee\u6807\u6a21\u578b\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u572829\u4e2a\u5e94\u7528\u9886\u57df\u768415\u4efd\u8bbf\u8c08\u8bb0\u5f55\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aGPT-4o\u80fd\u591f\u53ef\u9760\u5730\u63d0\u53d6\u76ee\u6807\uff08\u51c6\u786e\u738762.0%\uff09\u548c\u76ee\u6807\u6eaf\u6e90\uff08\u51c6\u786e\u738798.7%\uff09\uff0c\u540c\u65f6\u76ee\u6807\u6a21\u578b\u7ec6\u5316\u5173\u7cfb\u7684\u751f\u6210\u51c6\u786e\u7387\u4e3a72.2%\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\uff0c\u9700\u6c42\u901a\u5e38\u901a\u8fc7\u8bbf\u8c08\u7b49\u65b9\u6cd5\u4ece\u5229\u76ca\u76f8\u5173\u8005\u90a3\u91cc\u83b7\u53d6\uff0c\u4f46\u624b\u52a8\u5206\u6790\u548c\u8bb0\u5f55\u9700\u6c42\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u9ad8\u6548\u51c6\u786e\u5730\u63d0\u53d6\u76ee\u6807\u5e76\u6784\u5efa\u76ee\u6807\u6a21\u578b\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528\u6587\u672c\u8574\u542b\u6280\u672f\u4ece\u8bbf\u8c08\u8bb0\u5f55\u4e2d\u63d0\u53d6\u76ee\u6807\uff0c\u5e76\u4f7f\u7528GPT-4o\u81ea\u52a8\u6784\u5efa\u76ee\u6807\u6a21\u578b\u3002\u5b9e\u9a8c\u8bc4\u4f30\u4e86GPT-4o\u5728\u76ee\u6807\u63d0\u53d6\u3001\u6eaf\u6e90\u548c\u76ee\u6807\u6a21\u578b\u7ec6\u5316\u5173\u7cfb\u751f\u6210\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGPT-4o\u5728\u76ee\u6807\u63d0\u53d6\u4e0a\u4e0e\u4eba\u5de5\u63d0\u53d6\u7684\u76ee\u6807\u5339\u914d\u7387\u4e3a62.0%\uff0c\u76ee\u6807\u6eaf\u6e90\u51c6\u786e\u7387\u4e3a98.7%\uff0c\u76ee\u6807\u6a21\u578b\u7ec6\u5316\u5173\u7cfb\u7684\u751f\u6210\u51c6\u786e\u7387\u4e3a72.2%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u5316\u5730\u4ece\u8bbf\u8c08\u8bb0\u5f55\u4e2d\u63d0\u53d6\u76ee\u6807\u5e76\u6784\u5efa\u76ee\u6807\u6a21\u578b\uff0c\u5177\u6709\u826f\u597d\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u652f\u6301\u3002"}}
{"id": "2509.01832", "pdf": "https://arxiv.org/pdf/2509.01832", "abs": "https://arxiv.org/abs/2509.01832", "authors": ["Negar Monir", "Youssef Ait Si", "Ratnangshu Das", "Pushpak Jagtap", "Adnane Saoud", "Sadegh Soudjani"], "title": "Computation of Feasible Assume-Guarantee Contracts: A Resilience-based Approach", "categories": ["eess.SY", "cs.LO", "cs.SY", "math.DS"], "comment": null, "summary": "We propose a resilience-based framework for computing feasible\nassume-guarantee contracts that ensure the satisfaction of temporal\nspecifications in interconnected discrete-time systems. Interconnection effects\nare modeled as structured disturbances. We use a resilience metric, the maximum\ndisturbance under which local specifications hold, to refine assumptions and\nguarantees across subsystems iteratively. For two subsystems, we demonstrate\ncorrectness, monotone refinement of guarantees, and that the resulting\nassumptions are maximal within ball-shaped sets. Additionally, we extend our\napproach to general networks of L subsystems using weighted combinations of\ninterconnection effects. We instantiate the framework on linear systems by\nmeeting finite-horizon safety, exact-time reachability, and finite-time\nreachability specifications, and on nonlinear systems by fulfilling general\nfinite-horizon specifications. Our approach is demonstrated through numerical\nlinear examples, and a nonlinear DC Microgrid case study, showcasing the impact\nof our framework in verifying temporal logic specifications with compositional\nreasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u97e7\u6027\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8ba1\u7b97\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u4e2d\u6ee1\u8db3\u65f6\u5e8f\u89c4\u8303\u7684\u5047\u8bbe-\u4fdd\u8bc1\u5408\u540c\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u65b9\u6cd5\u4f18\u5316\u5b50\u7cfb\u7edf\u95f4\u7684\u5047\u8bbe\u548c\u4fdd\u8bc1\u3002", "motivation": "\u89e3\u51b3\u4e92\u8054\u7cfb\u7edf\u4e2d\u65f6\u5e8f\u89c4\u8303\u7684\u6ee1\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u97e7\u6027\u5ea6\u91cf\u91cf\u5316\u6270\u52a8\u7684\u5f71\u54cd\uff0c\u5b9e\u73b0\u5b50\u7cfb\u7edf\u95f4\u7684\u534f\u540c\u9a8c\u8bc1\u3002", "method": "\u4f7f\u7528\u97e7\u6027\u5ea6\u91cf\uff08\u6700\u5927\u6270\u52a8\uff09\u8fed\u4ee3\u4f18\u5316\u5047\u8bbe\u548c\u4fdd\u8bc1\uff0c\u6269\u5c55\u5230L\u4e2a\u5b50\u7cfb\u7edf\u4f7f\u7528\u52a0\u6743\u7ec4\u5408\u5efa\u6a21\u4e92\u8054\u6548\u5e94\u3002\u5728\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u5206\u522b\u9a8c\u8bc1\u6709\u9650\u65f6\u95f4\u5b89\u5168\u6027\u548c\u53ef\u8fbe\u6027\u89c4\u8303\u3002", "result": "\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6b63\u786e\u6027\u3001\u5355\u8c03\u6027\u548c\u6700\u5927\u6027\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u548c\u975e\u7ebf\u6027\u5fae\u7535\u7f51\u6848\u4f8b\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7ec4\u5408\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u65f6\u5e8f\u89c4\u8303\u9700\u6c42\u3002"}}
{"id": "2509.01839", "pdf": "https://arxiv.org/pdf/2509.01839", "abs": "https://arxiv.org/abs/2509.01839", "authors": ["Akis Nousias", "Stavros Nousias"], "title": "HodgeFormer: Transformers for Learnable Operators on Triangular Meshes through Data-Driven Hodge Matrices", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "12 pages, 11 figures, 9 tables", "summary": "Currently, prominent Transformer architectures applied on graphs and meshes\nfor shape analysis tasks employ traditional attention layers that heavily\nutilize spectral features requiring costly eigenvalue decomposition-based\nmethods. To encode the mesh structure, these methods derive positional\nembeddings, that heavily rely on eigenvalue decomposition based operations,\ne.g. on the Laplacian matrix, or on heat-kernel signatures, which are then\nconcatenated to the input features. This paper proposes a novel approach\ninspired by the explicit construction of the Hodge Laplacian operator in\nDiscrete Exterior Calculus as a product of discrete Hodge operators and\nexterior derivatives, i.e. $(L := \\star_0^{-1} d_0^T \\star_1 d_0)$. We adjust\nthe Transformer architecture in a novel deep learning layer that utilizes the\nmulti-head attention mechanism to approximate Hodge matrices $\\star_0$,\n$\\star_1$ and $\\star_2$ and learn families of discrete operators $L$ that act\non mesh vertices, edges and faces. Our approach results in a\ncomputationally-efficient architecture that achieves comparable performance in\nmesh segmentation and classification tasks, through a direct learning\nframework, while eliminating the need for costly eigenvalue decomposition\noperations or complex preprocessing operations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.02457", "pdf": "https://arxiv.org/pdf/2509.02457", "abs": "https://arxiv.org/abs/2509.02457", "authors": ["Ajay Singh"], "title": "Safe Memory Reclamation Techniques", "categories": ["cs.DC", "cs.DS", "cs.PF", "cs.PL"], "comment": "Ph.D. Thesis", "summary": "Safe memory reclamation is crucial to memory safety for optimistic and\nlock-free concurrent data structures in non garbage collected programming\nlanguages. However, several challenges arise in designing an ideal safe memory\nreclamation algorithm, including achieving high speed and scalability, easy of\nuse for programmers, applicability to wide class of data structures, managing\nthe large memory footprint caused by delayed freeing of memory for safety and\nperformance, and avoiding asymmetric overhead on data structure operations.\nSeveral approaches to designing safe memory reclamation algorithms are studied\nby blending ideas and tools from across the hardware-software stack. These\nsolutions cross traditional boundaries and exploit features exposed at\ndifferent layers.", "AI": {"tldr": "\u5b89\u5168\u5185\u5b58\u56de\u6536\u5bf9\u975e\u5783\u573e\u6536\u96c6\u8bed\u8a00\u4e2d\u7684\u4e50\u89c2\u548c\u65e0\u9501\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8bbe\u8ba1\u7406\u60f3\u7b97\u6cd5\u9762\u4e34\u901f\u5ea6\u3001\u53ef\u6269\u5c55\u6027\u3001\u6613\u7528\u6027\u3001\u9002\u914d\u6027\u7b49\u591a\u91cd\u6311\u6218\u3002", "motivation": "\u5728\u975e\u5783\u573e\u6536\u96c6\u8bed\u8a00\u4e2d\uff0c\u5b89\u5168\u5185\u5b58\u56de\u6536\u5bf9\u786e\u4fdd\u4e50\u89c2\u548c\u65e0\u9501\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u7684\u5185\u5b58\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u8de8\u786c\u4ef6\u8f6f\u4ef6\u6808\u7684\u6df7\u5408\u8bbe\u8ba1\u548c\u5de5\u5177\u5229\u7528\uff0c\u7814\u7a76\u591a\u79cd\u5b89\u5168\u5185\u5b58\u56de\u6536\u7b97\u6cd5\u3002", "result": "\u89e3\u51b3\u4e86\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u591a\u91cd\u6311\u6218\uff0c\u5305\u62ec\u9ad8\u6027\u80fd\u3001\u6613\u7528\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "conclusion": "\u8de8\u5c42\u89e3\u51b3\u65b9\u6848\u53ef\u4ee5\u6709\u6548\u5e94\u5bf9\u5b89\u5168\u5185\u5b58\u56de\u6536\u7684\u590d\u6742\u6311\u6218\u3002"}}
{"id": "2509.00885", "pdf": "https://arxiv.org/pdf/2509.00885", "abs": "https://arxiv.org/abs/2509.00885", "authors": ["Yi-Chia Cheng", "Cheng-Shang Chang"], "title": "Efficient Multichannel Rendezvous Algorithms without Global Channel Enumeration", "categories": ["cs.NI"], "comment": "Part of this work has been presented in IEEE 2024 33rd Wireless and\n  Optical Communications Conference (WOCC)", "summary": "The multichannel rendezvous problem (MRP) is a critical challenge for\nneighbor discovery in IoT applications, requiring two users to find each other\nby hopping among available channels over time. This paper addresses the MRP in\nscenarios where a global channel enumeration system is unavailable. To tackle\nthis challenge, we propose a suite of low-complexity multichannel rendezvous\nalgorithms based on locality-sensitive hashing (LSH), tailored for environments\nwhere channel labels are unique L-bit identifiers rather than globally\ncoordinated indices. Inspired by consistent hashing techniques in distributed\nsystems, we develop the LC-LSH and LC-LSH4 algorithms for synchronous and\nasynchronous settings, respectively. These algorithms significantly reduce\nimplementation complexity while maintaining expected time-to-rendezvous (ETTR)\nperformance comparable to state-of-the-art methods that require global channel\nenumeration. To ensure bounded maximum time-to-rendezvous (MTTR) in the\nasynchronous setting, we further introduce the ASYM-LC-LSH4 and QR-LC-LSH4\nalgorithms by embedding multiset-enhanced modular clock and quasi-random\ntechniques into our framework. Extensive simulations demonstrate that the\nproposed algorithms achieve performance comparable to state-of-the-art LSH\nalgorithms in both synchronous and asynchronous settings, even without a global\nchannel enumeration system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\uff08LSH\uff09\u7684\u4f4e\u590d\u6742\u5ea6\u591a\u901a\u9053\u4f1a\u5408\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u65e0\u5168\u5c40\u901a\u9053\u679a\u4e3e\u7cfb\u7edf\u7684\u573a\u666f\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u7b97\u6cd5\u76f8\u5f53\u3002", "motivation": "\u89e3\u51b3\u5728\u591a\u901a\u9053\u4f1a\u5408\u95ee\u9898\u4e2d\u7f3a\u4e4f\u5168\u5c40\u901a\u9053\u679a\u4e3e\u7cfb\u7edf\u65f6\u7684\u6311\u6218\uff0c\u63d0\u5347\u7269\u8054\u7f51\u8bbe\u5907\u53d1\u73b0\u6548\u7387\u3002", "method": "\u5229\u7528LSH\u548c\u4e00\u81f4\u6027\u54c8\u5e0c\u6280\u672f\uff0c\u8bbe\u8ba1\u4e86LC-LSH\u548cLC-LSH4\u7b97\u6cd5\uff0c\u5206\u522b\u7528\u4e8e\u540c\u6b65\u548c\u5f02\u6b65\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u5d4c\u5165\u591a\u96c6\u589e\u5f3a\u6a21\u5757\u65f6\u949f\u548c\u51c6\u968f\u673a\u6280\u672f\u786e\u4fddMTTR\u6709\u754c\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\uff0c\u7b97\u6cd5\u6027\u80fd\u4e0e\u73b0\u6709LSH\u7b97\u6cd5\u76f8\u5f53\uff0c\u4e14\u590d\u6742\u5ea6\u66f4\u4f4e\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u65e0\u5168\u5c40\u901a\u9053\u679a\u4e3e\u7cfb\u7edf\u4e0b\u4ecd\u80fd\u9ad8\u6548\u89e3\u51b3\u591a\u901a\u9053\u4f1a\u5408\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u7269\u8054\u7f51\u5e94\u7528\u3002"}}
{"id": "2509.01231", "pdf": "https://arxiv.org/pdf/2509.01231", "abs": "https://arxiv.org/abs/2509.01231", "authors": ["Shyama Sastha Krishnamoorthy Srinivasan", "Mohan Kumar", "Pushpendra Singh"], "title": "Unpacking Personal(?!) Health Informatics: An Investigation of Awareness, Understanding, And Leveraged Utility in India", "categories": ["cs.HC", "cs.CY"], "comment": "25 pages, 2 figures, 4 tables; A qualitative HCI study with prototype\n  evaluation", "summary": "Personal Health Informatics (PHI), which leverages digital tools and\ninformation systems to support health assessment and self-care, holds promise\nfor empowering individuals and transforming healthcare delivery. However,\nbarriers to its adoption remain underexplored in the Indian context. This study\ninvestigates PHI adoption among Indian users and stakeholders using a\nmulti-method approach. An awareness survey (n = 87) examined the usage of\nwearables and general PHI engagement, followed by semi-structured interviews (n\n= 22) that explored motivations, usage patterns, and health information\nsources. Qualitative analysis revealed that while PHI is valued for health\nmonitoring and shared/collective care, its adoption is hindered by factors such\nas low health literacy, usability challenges, and mistrust in digital health\nplatforms. Further stakeholder interviews and co-design workshops informed the\ndevelopment of a Figma-based prototype, which was evaluated for usability.\nBased on these findings, we offer design recommendations for an integrated,\nuser-controlled PHI platform featuring accessible analytics and verifiable\nhealth information. Our insights highlight the socio-technical challenges of\nPHI adoption in India and underscore the need for reliable, user-centric\nsolutions to support proactive healthcare.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5370\u5ea6\u80cc\u666f\u4e0b\u4e2a\u4eba\u5065\u5eb7\u4fe1\u606f\u5b66\uff08PHI\uff09\u7684\u91c7\u7528\u969c\u788d\uff0c\u901a\u8fc7\u591a\u65b9\u6cd5\u7814\u7a76\u53d1\u73b0\u4f4e\u5065\u5eb7\u7d20\u517b\u3001\u53ef\u7528\u6027\u6311\u6218\u548c\u6570\u5b57\u5065\u5eb7\u5e73\u53f0\u7684\u4e0d\u4fe1\u4efb\u662f\u4e3b\u8981\u969c\u788d\uff0c\u5e76\u63d0\u51fa\u4e86\u7528\u6237\u63a7\u5236\u7684\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u4e2a\u4eba\u5065\u5eb7\u4fe1\u606f\u5b66\uff08PHI\uff09\u5728\u652f\u6301\u5065\u5eb7\u8bc4\u4f30\u548c\u81ea\u6211\u62a4\u7406\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u5370\u5ea6\u7684\u91c7\u7528\u969c\u788d\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u91c7\u7528\u591a\u65b9\u6cd5\u7814\u7a76\uff0c\u5305\u62ec\u8c03\u67e5\uff08n=87\uff09\u548c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff08n=22\uff09\uff0c\u5206\u6790PHI\u7684\u4f7f\u7528\u52a8\u673a\u3001\u6a21\u5f0f\u548c\u969c\u788d\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "result": "\u7814\u7a76\u53d1\u73b0PHI\u7684\u5065\u5eb7\u76d1\u6d4b\u4ef7\u503c\u88ab\u8ba4\u53ef\uff0c\u4f46\u4f4e\u5065\u5eb7\u7d20\u517b\u3001\u53ef\u7528\u6027\u95ee\u9898\u548c\u4fe1\u4efb\u95ee\u9898\u963b\u788d\u4e86\u5176\u91c7\u7528\u3002\u63d0\u51fa\u7684\u539f\u578b\u8bbe\u8ba1\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5370\u5ea6PHI\u91c7\u7528\u7684\u793e\u4f1a\u6280\u672f\u6311\u6218\uff0c\u5efa\u8bae\u5f00\u53d1\u53ef\u9760\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00723", "pdf": "https://arxiv.org/pdf/2509.00723", "abs": "https://arxiv.org/abs/2509.00723", "authors": ["Junzhe Chen", "Tianshu Zhang", "Shiyu Huang", "Yuwei Niu", "Chao Sun", "Rongzhou Zhang", "Guanyu Zhou", "Lijie Wen", "Xuming Hu"], "title": "OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination", "categories": ["cs.AI", "cs.MM"], "comment": null, "summary": "Recently, Omni-modal large language models (OLLMs) have sparked a new wave of\nresearch, achieving impressive results in tasks such as audio-video\nunderstanding and real-time environment perception. However, hallucination\nissues still persist. Similar to the bimodal setting, the priors from the text\nmodality tend to dominate, leading OLLMs to rely more heavily on textual cues\nwhile neglecting visual and audio information. In addition, fully multimodal\nscenarios introduce new challenges. Most existing models align visual or\nauditory modalities with text independently during training, while ignoring the\nintrinsic correlations between video and its corresponding audio. This\noversight results in hallucinations when reasoning requires interpreting hidden\naudio cues embedded in video content. To address these challenges, we propose\nOmniDPO, a preference-alignment framework designed to mitigate hallucinations\nin OLLMs. Specifically, OmniDPO incorporates two strategies: (1) constructing\ntext-preference sample pairs to enhance the model's understanding of\naudio-video interactions; and (2) constructing multimodal-preference sample\npairs to strengthen the model's attention to visual and auditory information.\nBy tackling both challenges, OmniDPO effectively improves multimodal grounding\nand reduces hallucination. Experiments conducted on two OLLMs demonstrate that\nOmniDPO not only effectively mitigates multimodal hallucinations but also\nsignificantly enhances the models' reasoning capabilities across modalities.\nAll code and datasets will be released upon paper acceptance.", "AI": {"tldr": "OmniDPO\u6846\u67b6\u901a\u8fc7\u504f\u597d\u5bf9\u9f50\u7b56\u7565\u89e3\u51b3OLLMs\u4e2d\u7684\u591a\u6a21\u6001\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u5347\u97f3\u9891-\u89c6\u9891\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709OLLMs\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u4ecd\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u6587\u672c\u6a21\u6001\u4e3b\u5bfc\u5bfc\u81f4\u5ffd\u89c6\u89c6\u89c9\u548c\u97f3\u9891\u4fe1\u606f\uff0c\u4e14\u7f3a\u4e4f\u6a21\u6001\u95f4\u76f8\u5173\u6027\u5efa\u6a21\u3002", "method": "\u63d0\u51faOmniDPO\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u6587\u672c\u504f\u597d\u548c\u591a\u6a21\u6001\u504f\u597d\u6837\u672c\u5bf9\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u97f3\u9891-\u89c6\u9891\u4ea4\u4e92\u7684\u7406\u89e3\u53ca\u5bf9\u89c6\u89c9\u548c\u542c\u89c9\u4fe1\u606f\u7684\u5173\u6ce8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOmniDPO\u4e0d\u4ec5\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\uff0c\u8fd8\u663e\u8457\u63d0\u5347\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "OmniDPO\u4e3a\u89e3\u51b3OLLMs\u4e2d\u7684\u591a\u6a21\u6001\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u6846\u67b6\u3002"}}
{"id": "2509.01339", "pdf": "https://arxiv.org/pdf/2509.01339", "abs": "https://arxiv.org/abs/2509.01339", "authors": ["Bochen Ye", "Gustavo Naspolini", "Kimmo Salo", "Manil Dev Gomony"], "title": "LinkBo: An Adaptive Single-Wire, Low-Latency, and Fault-Tolerant Communications Interface for Variable-Distance Chip-to-Chip Systems", "categories": ["cs.AR"], "comment": "This paper is full version of SOCC'2025 conference", "summary": "Cost-effective embedded systems necessitate utilizing the single-wire\ncommunication protocol for inter-chip communication, thanks to its reduced pin\ncount in comparison to the multi-wire I2C or SPI protocols. However, current\nsingle-wire protocols suffer from increased latency, restricted throughput, and\nlack of robustness. This paper presents LinkBo, an innovative single-wire\nprotocol that offers reduced latency, enhanced throughput, and greater\nrobustness with hardware-interrupt for variable-distance inter-chip\ncommunication. The LinkBo protocol-level guarantees that high-priority messages\nare delivered with an error detection feature in just 50.4 $\\mu$s, surpassing\ncurrent commercial options, 1-wire and UNI/O by at least 20X and 6.3X,\nrespectively. In addition, we present the hardware architecture for this new\nprotocol and its performance evaluation on a hardware platform consisting of\ntwo FPGAs. Our findings demonstrate that the protocol reliably supports wire\nlengths up to 15 meters with a data rate of 300 kbps, while reaching a maximum\ndata rate of 7.5 Mbps over an 11 cm wire, providing reliable performance for\nvarying inter-chip communication distances.", "AI": {"tldr": "LinkBo\u662f\u4e00\u79cd\u521b\u65b0\u7684\u5355\u7ebf\u901a\u4fe1\u534f\u8bae\uff0c\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u548c\u5f3a\u9c81\u68d2\u6027\uff0c\u652f\u6301\u53ef\u53d8\u8ddd\u79bb\u7684\u82af\u7247\u95f4\u901a\u4fe1\u3002\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5546\u4e1a\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u6210\u672c\u654f\u611f\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u5355\u7ebf\u901a\u4fe1\u534f\u8bae\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u541e\u5410\u53d7\u9650\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4f4e\u6210\u672c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5355\u7ebf\u901a\u4fe1\u65b9\u6848\u3002", "method": "\u63d0\u51faLinkBo\u534f\u8bae\uff0c\u91c7\u7528\u786c\u4ef6\u4e2d\u65ad\u6280\u672f\uff0c\u652f\u6301\u53ef\u53d8\u8ddd\u79bb\u901a\u4fe1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u786c\u4ef6\u67b6\u6784\uff0c\u5728\u4e24\u5757FPGA\u4e0a\u8fdb\u884c\u4e86\u6027\u80fd\u8bc4\u4f30\u3002", "result": "LinkBo\u534f\u8bae\u5b9e\u73b0\u4e8650.4\u5fae\u79d2\u7684\u4f4e\u5ef6\u8fdf\u6570\u636e\u4f20\u8f93\uff0c\u652f\u630115\u7c73\u7ebf\u957f\u4e0b\u7684300 kbps\u901f\u7387\u548c11\u5398\u7c73\u7ebf\u957f\u4e0b\u76847.5 Mbps\u901f\u7387\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "LinkBo\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u7684\u5355\u7ebf\u901a\u4fe1\u534f\u8bae\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8ddd\u79bb\u7684\u82af\u7247\u95f4\u901a\u4fe1\uff0c\u5c24\u5176\u5728\u6210\u672c\u654f\u611f\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2509.01425", "pdf": "https://arxiv.org/pdf/2509.01425", "abs": "https://arxiv.org/abs/2509.01425", "authors": ["Sergio Miguel Martin", "Luca Terracciano", "Kiril Dichev", "Noah Baumann", "Jiashu Lin", "Albert-Jan Yzelman"], "title": "HiCR, an Abstract Model for Distributed Heterogeneous Programming", "categories": ["cs.DC"], "comment": null, "summary": "We present HiCR, a model to represent the semantics of distributed\nheterogeneous applications and runtime systems. The model describes a minimal\nset of abstract operations to enable hardware topology discovery, kernel\nexecution, memory management, communication, and instance management, without\nprescribing any implementation decisions. The goal of the model is to enable\nexecution in current and future systems without the need for significant\nrefactoring, while also being able to serve any governing parallel programming\nparadigm. In terms of software abstraction, HiCR is naturally located between\ndistributed heterogeneous systems and runtime systems. We coin the phrase\n\\emph{Runtime Support Layer} for this level of abstraction. We explain how the\nmodel's components and operations are realized by a plugin-based approach that\ntakes care of device-specific implementation details, and present examples of\nHiCR-based applications that operate equally on a diversity of platforms.", "AI": {"tldr": "HiCR\u662f\u4e00\u79cd\u7528\u4e8e\u63cf\u8ff0\u5206\u5e03\u5f0f\u5f02\u6784\u5e94\u7528\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\u8bed\u4e49\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u62bd\u8c61\u64cd\u4f5c\u652f\u6301\u786c\u4ef6\u62d3\u6251\u53d1\u73b0\u3001\u5185\u6838\u6267\u884c\u3001\u5185\u5b58\u7ba1\u7406\u7b49\u529f\u80fd\uff0c\u65e8\u5728\u5b9e\u73b0\u8de8\u5e73\u53f0\u517c\u5bb9\u6027\u3002", "motivation": "\u4e3a\u5206\u5e03\u5f0f\u5f02\u6784\u7cfb\u7edf\u63d0\u4f9b\u4e00\u79cd\u901a\u7528\u7684\u8fd0\u884c\u65f6\u652f\u6301\u5c42\uff0c\u907f\u514d\u56e0\u786c\u4ef6\u6216\u7f16\u7a0b\u8303\u5f0f\u53d8\u5316\u800c\u9700\u8981\u5927\u89c4\u6a21\u91cd\u6784\u3002", "method": "\u91c7\u7528\u6700\u5c0f\u62bd\u8c61\u64cd\u4f5c\u96c6\u548c\u63d2\u4ef6\u5316\u65b9\u6cd5\u5b9e\u73b0\u8bbe\u5907\u7279\u5b9a\u7684\u7ec6\u8282\u7ba1\u7406\u3002", "result": "HiCR\u6a21\u578b\u80fd\u591f\u5728\u591a\u79cd\u5e73\u53f0\u4e0a\u65e0\u7f1d\u8fd0\u884c\uff0c\u652f\u6301\u4e0d\u540c\u7f16\u7a0b\u8303\u5f0f\u3002", "conclusion": "HiCR\u4f5c\u4e3a\u8fd0\u884c\u65f6\u652f\u6301\u5c42\uff0c\u4e3a\u5206\u5e03\u5f0f\u5f02\u6784\u5e94\u7528\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02124", "pdf": "https://arxiv.org/pdf/2509.02124", "abs": "https://arxiv.org/abs/2509.02124", "authors": ["Mohamed Faten Zhani", "Younes Korbi", "Yamen Mkadem"], "title": "FlexNGIA 2.0: Redesigning the Internet with Agentic AI - Protocols, Services, and Traffic Engineering Designed, Deployed, and Managed by AI", "categories": ["cs.NI", "cs.ET"], "comment": null, "summary": "The escalating demands of immersive communications, alongside advances in\nnetwork softwarization and AI-driven cognition and generative reasoning, create\na pivotal opportunity to rethink and reshape the future Internet. In this\ncontext, we introduce in this paper, FlexNGIA 2.0, an Agentic AI-driven\nInternet architecture that leverages LLM-based AI agents to autonomously\norchestrate, configure, and evolve the network. These agents can, at runtime,\nperceive, reason, coordinate among themselves to dynamically design, implement,\ndeploy, and adapt communication protocols, Service Function Chains (SFCs),\nnetwork functions, resource allocation strategies, congestion control, and\ntraffic engineering schemes, thereby ensuring optimal performance, reliability,\nand efficiency under evolving conditions.\n  The paper first outlines the overall architecture of FlexNGIA 2.0 and its\nconstituent LLM-Based AI agents. For each agent, we detail its design,\nimplementation, inputs and outputs, prompt structures, interactions with tools\nand other agents, followed by preliminary proof-of-concept experiments\ndemonstrating its operation and potential. The results clearly highlight the\nability of these LLM-based AI agents to automate the design, the\nimplementation, the deployment, and the performance evaluation of transport\nprotocols, service function chains, network functions, congestion control\nschemes, and resource allocation strategies.\n  FlexNGIA 2.0 paves the way for a new class of Agentic AI-Driven networks,\nwhere fully cognitive, self-evolving AI agents can autonomously design,\nimplement, adapt and optimize the network's protocols, algorithms, and\nbehaviors to efficiently operate across complex, dynamic, and heterogeneous\nenvironments. To bring this vision to reality, we also identify key research\nchallenges toward achieving fully autonomous, adaptive, and agentic AI-driven\nnetworks.", "AI": {"tldr": "FlexNGIA 2.0\u662f\u4e00\u79cd\u57fa\u4e8eLLM AI\u9a71\u52a8\u7684\u4e92\u8054\u7f51\u67b6\u6784\uff0c\u901a\u8fc7AI\u4ee3\u7406\u81ea\u4e3b\u7ba1\u7406\u548c\u4f18\u5316\u7f51\u7edc\u534f\u8bae\u3001\u529f\u80fd\u53ca\u8d44\u6e90\u5206\u914d\uff0c\u63d0\u5347\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u6c89\u6d78\u5f0f\u901a\u4fe1\u9700\u6c42\u7684\u589e\u957f\u548c\u7f51\u7edc\u8f6f\u5316\u7684\u8fdb\u6b65\uff0c\u91cd\u65b0\u8bbe\u8ba1\u672a\u6765\u4e92\u8054\u7f51\u67b6\u6784\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\u3002", "method": "\u63d0\u51faFlexNGIA 2.0\u67b6\u6784\uff0c\u5229\u7528LLM AI\u4ee3\u7406\u52a8\u6001\u8bbe\u8ba1\u3001\u90e8\u7f72\u548c\u4f18\u5316\u7f51\u7edc\u534f\u8bae\u53ca\u8d44\u6e90\u5206\u914d\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u4ee3\u7406\u5728\u81ea\u52a8\u5316\u8bbe\u8ba1\u3001\u90e8\u7f72\u548c\u6027\u80fd\u8bc4\u4f30\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "FlexNGIA 2.0\u4e3aAI\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u7edc\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u5173\u952e\u7814\u7a76\u6311\u6218\u3002"}}
{"id": "2509.00627", "pdf": "https://arxiv.org/pdf/2509.00627", "abs": "https://arxiv.org/abs/2509.00627", "authors": ["Yuheng Zhang", "Miao Qiao", "Zhencan Peng", "Dong Deng"], "title": "Near-Duplicate Text Alignment under Weighted Jaccard Similarity", "categories": ["cs.DB"], "comment": null, "summary": "Near-duplicate text alignment is the task of identifying, among the texts in\na corpus, all the subsequences (substrings) that are similar to a given query.\nTraditional approaches rely on seeding-extension-filtering heuristics, which\nlack accuracy guarantees and require many hard-to-tune parameters. Recent\nmethods leverage min-hash techniques under a hash-based framework: group\nsubsequences by their min-hash, and for any query, find all sketches similar to\nthe query's sketch. These methods guarantee to report all subsequences whose\nestimated unweighted Jaccard similarity with the query exceeds a user-provided\nthreshold and are efficient. However, they fail to account for token importance\nor frequency, which limits their use in real scenarios where tokens carry\nweights, such as TF-IDF. To address this, we propose MONO, an approach that\nsupports weighted Jaccard similarity using consistent weighted sampling. MONO\nachieves optimality within the hash-based framework. For example, when token\nweights are proportional to frequencies, MONO generates O(n + n log f) groups\nin expectation for a text of length n, where f is the maximum token frequency.\nEach group takes O(1) space and represents a few subsequences sharing the same\nsampling. We prove this bound is tight: any algorithm must produce Omega(n + n\nlog f) groups in expectation in the worst case. Experiments show that MONO\noutperforms the state of the art by up to 26x in index construction time,\nreduces index size by up to 30 percent, and improves query latency by up to 3x,\nwhile scaling well.", "AI": {"tldr": "MONO\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u52a0\u6743Jaccard\u76f8\u4f3c\u5ea6\u7684\u8fd1\u91cd\u590d\u6587\u672c\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u81f4\u7684\u52a0\u6743\u91c7\u6837\u4f18\u5316\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u51c6\u786e\u6027\u4fdd\u8bc1\u4e14\u53c2\u6570\u96be\u4ee5\u8c03\u4f18\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u8003\u8651\u8bcd\u7684\u91cd\u8981\u6027\u6216\u9891\u7387\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "MONO\u5229\u7528\u4e00\u81f4\u7684\u52a0\u6743\u91c7\u6837\u652f\u6301\u52a0\u6743Jaccard\u76f8\u4f3c\u5ea6\uff0c\u5b9e\u73b0\u4e86\u54c8\u5e0c\u6846\u67b6\u5185\u7684\u6700\u4f18\u6027\u3002", "result": "MONO\u5728\u7d22\u5f15\u6784\u5efa\u65f6\u95f4\u3001\u7d22\u5f15\u5927\u5c0f\u548c\u67e5\u8be2\u5ef6\u8fdf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6700\u9ad8\u63d0\u534726\u500d\u6548\u7387\u548c30%\u5b58\u50a8\u7a7a\u95f4\u3002", "conclusion": "MONO\u89e3\u51b3\u4e86\u52a0\u6743\u76f8\u4f3c\u5ea6\u7684\u95ee\u9898\uff0c\u5e76\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2509.01068", "pdf": "https://arxiv.org/pdf/2509.01068", "abs": "https://arxiv.org/abs/2509.01068", "authors": ["Chong Wang", "Haoning Wu", "Peng Liang", "Maya Daneva", "Marten van Sinderen"], "title": "A Survey on the Techniques and Tools for Automated Requirements Elicitation and Analysis of Mobile Apps", "categories": ["cs.SE"], "comment": null, "summary": "[Background:] Research on automated requirements elicitation and analysis of\nmobile apps employed lots of techniques and tools proposed by RE researchers\nand practitioners. However, little is known about the characteristics of these\ntechniques and tools as well as the RE tasks in requirements elicitation and\nanalysis that got supported with the help of respective techniques and tools.\n[Aims:] The goal of this paper is to investigate the state-of-the-art of the\ntechniques and tools used in automated requirements elicitation and analysis of\nmobile apps. [Method:] We carried out a systematic mapping study by following\nthe guidelines of Kitchenham et al. [Results:] Based on 73 selected papers, we\nfound the most frequently used techniques - semi-automatic techniques, and the\nmain characteristics of the tools - open-sourced and non-self-developed tools\nfor requirements analysis and text pre-processing. Plus, the most three\ninvestigated RE tasks are requirements analysis, mining and classification.\n[Conclusions:] Our most important conclusions are: (1) there is a growth in the\nuse of techniques and tools in automated requirements elicitation and analysis\nof mobile apps, (2) semi-automatic techniques are mainly used in the\npublications on this research topic, (3) requirements analysis, mining and\nclassification are the top three RE tasks with the support of automatic\ntechniques and tools, and (4) the most popular tools are open-sourced and\nnon-self-developed, and they are mainly used in requirements analysis and text\nprocessing.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u65b9\u6cd5\u5206\u6790\u4e8673\u7bc7\u8bba\u6587\uff0c\u63a2\u8ba8\u4e86\u79fb\u52a8\u5e94\u7528\u81ea\u52a8\u5316\u9700\u6c42\u83b7\u53d6\u4e0e\u5206\u6790\u7684\u6280\u672f\u548c\u5de5\u5177\u73b0\u72b6\uff0c\u53d1\u73b0\u534a\u81ea\u52a8\u6280\u672f\u3001\u5f00\u6e90\u975e\u81ea\u7814\u5de5\u5177\u53ca\u9700\u6c42\u5206\u6790\u3001\u6316\u6398\u4e0e\u5206\u7c7b\u662f\u4e3b\u8981\u7279\u70b9\u548c\u4efb\u52a1\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u79fb\u52a8\u5e94\u7528\u81ea\u52a8\u5316\u9700\u6c42\u83b7\u53d6\u4e0e\u5206\u6790\u4e2d\u6280\u672f\u548c\u5de5\u5177\u7684\u7279\u70b9\u53ca\u5176\u652f\u6301\u7684\u9700\u6c42\u5de5\u7a0b\u4efb\u52a1\u3002", "method": "\u91c7\u7528Kitchenham\u7b49\u4eba\u7684\u6307\u5357\u8fdb\u884c\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u5206\u6790\u4e8673\u7bc7\u76f8\u5173\u8bba\u6587\u3002", "result": "\u53d1\u73b0\u534a\u81ea\u52a8\u6280\u672f\u6700\u5e38\u7528\uff0c\u5de5\u5177\u591a\u4e3a\u5f00\u6e90\u975e\u81ea\u7814\u4e14\u4e3b\u8981\u7528\u4e8e\u9700\u6c42\u5206\u6790\u548c\u6587\u672c\u9884\u5904\u7406\uff1b\u9700\u6c42\u5206\u6790\u3001\u6316\u6398\u4e0e\u5206\u7c7b\u662f\u4e09\u5927\u4e3b\u8981\u4efb\u52a1\u3002", "conclusion": "\u7814\u7a76\u603b\u7ed3\u51fa\u6280\u672f\u548c\u5de5\u5177\u4f7f\u7528\u589e\u957f\u7684\u8d8b\u52bf\uff0c\u534a\u81ea\u52a8\u6280\u672f\u7684\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4e09\u5927\u4e3b\u8981\u9700\u6c42\u4efb\u52a1\uff0c\u4ee5\u53ca\u5f00\u6e90\u975e\u81ea\u7814\u5de5\u5177\u7684\u6d41\u884c\u3002"}}
{"id": "2509.02393", "pdf": "https://arxiv.org/pdf/2509.02393", "abs": "https://arxiv.org/abs/2509.02393", "authors": ["Arnd Hartmanns", "Robert Modderman"], "title": "DTMC Model Checking by Path Abstraction Revisited (extended version)", "categories": ["cs.FL", "cs.LO"], "comment": "Extended version of the article \"DTMC Model Checking by Path\n  Abstraction Revisited\" presented/published at the 19th International\n  Conference on Reachability Problems (RP 2025), 1-3 October 2025, Madrid,\n  Spain (https://rp25.software.imdea.org/)", "summary": "Computing the probability of reaching a set of goal states G in a\ndiscrete-time Markov chain (DTMC) is a core task of probabilistic model\nchecking. We can do so by directly computing the probability mass of the set of\nall finite paths from the initial state to G; however, when refining\ncounterexamples, it is also interesting to compute the probability mass of\nsubsets of paths. This can be achieved by splitting the computation into path\nabstractions that calculate \"local\" reachability probabilities as shown by\n\\'Abrah\\'am et al. in 2010. In this paper, we complete and extend their work:\nWe prove that splitting the computation into path abstractions indeed yields\nthe same result as the direct approach, and that the splitting does not need to\nfollow the SCC structure. In particular, we prove that path abstraction can be\nperformed along any finite sequence of sets of non-goal states. Our proofs\nproceed in a novel way by interpreting the DTMC as a structure on the free\nmonoid on its state space, which makes them clean and concise. Additionally, we\nprovide a compact reference implementation of path abstraction in PARI/GP.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86\u5728\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u4e2d\uff0c\u901a\u8fc7\u8def\u5f84\u62bd\u8c61\u8ba1\u7b97\u5b50\u8def\u5f84\u7684\u6982\u7387\u4e0e\u76f4\u63a5\u65b9\u6cd5\u7ed3\u679c\u4e00\u81f4\uff0c\u4e14\u65e0\u9700\u9075\u5faaSCC\u7ed3\u6784\uff0c\u652f\u6301\u4efb\u610f\u6709\u9650\u5e8f\u5217\u7684\u975e\u76ee\u6807\u72b6\u6001\u96c6\u5408\u5212\u5206\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6982\u7387\u6a21\u578b\u68c0\u9a8c\u4e2d\u8ba1\u7b97\u5b50\u8def\u5f84\u7684\u6982\u7387\u8d28\u91cf\uff0c\u8865\u5145\u5e76\u6269\u5c55\u4e862010\u5e74Abraham\u7b49\u4eba\u7684\u5de5\u4f5c\u3002", "method": "\u5c06DTMC\u89e3\u91ca\u4e3a\u72b6\u6001\u7a7a\u95f4\u81ea\u7531\u5e7a\u534a\u7fa4\u7684\u7ed3\u6784\uff0c\u901a\u8fc7\u8def\u5f84\u62bd\u8c61\u5212\u5206\u8ba1\u7b97\u3002", "result": "\u8bc1\u660e\u4e86\u8def\u5f84\u62bd\u8c61\u65b9\u6cd5\u7684\u6b63\u786e\u6027\u53ca\u7075\u6d3b\u6027\uff0c\u5e76\u63d0\u4f9bPARI/GP\u7684\u53c2\u8003\u5b9e\u73b0\u3002", "conclusion": "\u8def\u5f84\u62bd\u8c61\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u73b0\u4e0a\u5747\u53ef\u884c\uff0c\u4e3a\u6982\u7387\u6a21\u578b\u68c0\u9a8c\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2509.02141", "pdf": "https://arxiv.org/pdf/2509.02141", "abs": "https://arxiv.org/abs/2509.02141", "authors": ["Mohit Mendiratta", "Mayur Deshmukh", "Kartik Teotia", "Vladislav Golyanik", "Adam Kortylewski", "Christian Theobalt"], "title": "GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned Residuals", "categories": ["cs.GR", "cs.CV"], "comment": "Project page: https://mohitm1994.github.io/GRMM/", "summary": "3D Morphable Models (3DMMs) enable controllable facial geometry and\nexpression editing for reconstruction, animation, and AR/VR, but traditional\nPCA-based mesh models are limited in resolution, detail, and photorealism.\nNeural volumetric methods improve realism but remain too slow for interactive\nuse. Recent Gaussian Splatting (3DGS) based facial models achieve fast,\nhigh-quality rendering but still depend solely on a mesh-based 3DMM prior for\nexpression control, limiting their ability to capture fine-grained geometry,\nexpressions, and full-head coverage. We introduce GRMM, the first full-head\nGaussian 3D morphable model that augments a base 3DMM with residual geometry\nand appearance components, additive refinements that recover high-frequency\ndetails such as wrinkles, fine skin texture, and hairline variations. GRMM\nprovides disentangled control through low-dimensional, interpretable parameters\n(e.g., identity shape, facial expressions) while separately modelling residuals\nthat capture subject- and expression-specific detail beyond the base model's\ncapacity. Coarse decoders produce vertex-level mesh deformations, fine decoders\nrepresent per-Gaussian appearance, and a lightweight CNN refines rasterised\nimages for enhanced realism, all while maintaining 75 FPS real-time rendering.\nTo learn consistent, high-fidelity residuals, we present EXPRESS-50, the first\ndataset with 60 aligned expressions across 50 identities, enabling robust\ndisentanglement of identity and expression in Gaussian-based 3DMMs. Across\nmonocular 3D face reconstruction, novel-view synthesis, and expression\ntransfer, GRMM surpasses state-of-the-art methods in fidelity and expression\naccuracy while delivering interactive real-time performance.", "AI": {"tldr": "GRMM\u662f\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af3D\u53ef\u53d8\u5f62\u6a21\u578b\u7684\u5168\u5934\u6a21\u578b\uff0c\u901a\u8fc7\u6dfb\u52a0\u6b8b\u5dee\u51e0\u4f55\u548c\u5916\u89c2\u7ec4\u4ef6\u6765\u589e\u5f3a\u4f20\u7edf3DMM\uff0c\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u548c\u7ec6\u8282\u7684\u8868\u73b0\u3002\u5b83\u63d0\u4f9b\u4e86\u5b9e\u65f6\u6e32\u67d3\uff0875 FPS\uff09\u548c\u9ad8\u4fdd\u771f\u5ea6\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002EXPRESS-50\u6570\u636e\u96c6\u652f\u6301\u4e86\u8eab\u4efd\u4e0e\u8868\u60c5\u7684\u9c81\u68d2\u89e3\u8026\u3002", "motivation": "\u4f20\u7edfPCA\u57fa\u7840\u76843DMM\u6a21\u578b\u5728\u5206\u8fa8\u7387\u3001\u7ec6\u8282\u548c\u771f\u5b9e\u611f\u4e0a\u53d7\u9650\uff1b\u795e\u7ecf\u4f53\u79ef\u65b9\u6cd5\u867d\u7136\u63d0\u5347\u4e86\u771f\u5b9e\u611f\u4f46\u901f\u5ea6\u6162\uff1b\u800c\u57fa\u4e8e\u9ad8\u65af\u6e85\u5c04\u7684\u9762\u90e8\u6a21\u578b\u4f9d\u8d56\u4e8e3DMM\u5148\u9a8c\uff0c\u65e0\u6cd5\u6355\u6349\u7ec6\u7c92\u5ea6\u51e0\u4f55\u548c\u8868\u60c5\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5b9e\u73b0\u9ad8\u4fdd\u771f\u53c8\u80fd\u5b9e\u65f6\u6e32\u67d3\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "GRMM\u901a\u8fc7\u6b8b\u5dee\u51e0\u4f55\u548c\u5916\u89c2\u7ec4\u4ef6\u589e\u5f3a\u57fa\u78403DMM\uff0c\u4f7f\u7528\u7c97\u89e3\u7801\u5668\u751f\u6210\u7f51\u683c\u53d8\u5f62\uff0c\u7ec6\u89e3\u7801\u5668\u8868\u793a\u9ad8\u65af\u7ea7\u522b\u7684\u5916\u89c2\uff0c\u5e76\u5229\u7528\u8f7b\u91cfCNN\u589e\u5f3a\u6e32\u67d3\u56fe\u50cf\u7684\u771f\u5b9e\u611f\u3002EXPRESS-50\u6570\u636e\u96c6\u7528\u4e8e\u8bad\u7ec3\u548c\u89e3\u8026\u8eab\u4efd\u4e0e\u8868\u60c5\u3002", "result": "GRMM\u5728\u5355\u76ee3D\u4eba\u8138\u91cd\u5efa\u3001\u65b0\u89c6\u89d2\u5408\u6210\u548c\u8868\u60c5\u8fc1\u79fb\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u548c\u8868\u60c5\u7cbe\u786e\u5ea6\uff0c\u540c\u65f6\u4fdd\u630175 FPS\u7684\u5b9e\u65f6\u6e32\u67d3\u6027\u80fd\u3002", "conclusion": "GRMM\u7ed3\u5408\u4e863DMM\u548c\u9ad8\u65af\u6e85\u5c04\u7684\u4f18\u70b9\uff0c\u5b9e\u73b0\u4e86\u9ad8\u5206\u8fa8\u7387\u3001\u7ec6\u8282\u4e30\u5bcc\u7684\u9762\u90e8\u5efa\u6a21\u548c\u5b9e\u65f6\u6e32\u67d3\uff0c\u4e3a\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2509.00967", "pdf": "https://arxiv.org/pdf/2509.00967", "abs": "https://arxiv.org/abs/2509.00967", "authors": ["Nadjib Achir", "Philippe Jacquet"], "title": "BUBBLE-BLUE a multihop private network based on Bluetooth", "categories": ["cs.NI"], "comment": "preprint", "summary": "The BUBBLE-BLUE (BB) project aims to create private Bluetooth bubbles on top\nof smartphones and to create a kind of terrestrial STARLINK network based on\nusers smartphones.. In each private bubble, participants will be able to\ncommunicate autonomously, without recourse to private operator networks,\nneither data nor cellular, relying solely on the Bluetooth technology of\nsmartphones. The routing strategy is based on dynamic Connected Dominant Sets\n(CDS). We present the specific features of a BB network as well as some\nsimulation results on their routing performance.", "AI": {"tldr": "BB\u9879\u76ee\u5229\u7528\u667a\u80fd\u624b\u673a\u84dd\u7259\u6280\u672f\u6784\u5efa\u79c1\u6709\u7f51\u7edc\uff0c\u4e0d\u4f9d\u8d56\u8fd0\u8425\u5546\uff0c\u57fa\u4e8e\u52a8\u6001CDS\u8def\u7531\u7b56\u7565\u3002", "motivation": "\u65e8\u5728\u5b9e\u73b0\u7528\u6237\u901a\u8fc7\u667a\u80fd\u624b\u673a\u84dd\u7259\u81ea\u4e3b\u901a\u4fe1\uff0c\u907f\u514d\u4f9d\u8d56\u8fd0\u8425\u5546\u7f51\u7edc\u3002", "method": "\u91c7\u7528\u52a8\u6001Connected Dominant Sets\uff08CDS\uff09\u8def\u7531\u7b56\u7565\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u5176\u8def\u7531\u6027\u80fd\u826f\u597d\u3002", "conclusion": "BB\u9879\u76ee\u5c55\u793a\u4e86\u84dd\u7259\u6280\u672f\u5728\u79c1\u6709\u901a\u4fe1\u7f51\u7edc\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.01246", "pdf": "https://arxiv.org/pdf/2509.01246", "abs": "https://arxiv.org/abs/2509.01246", "authors": ["Larissa R. de S. Shibata", "Ankit A. Ravankar", "Jose Victorio Salazar Luces", "Yasuhisa Hirata"], "title": "An AI-Based Shopping Assistant System to Support the Visually Impaired", "categories": ["cs.HC", "cs.RO"], "comment": "7 pages, Accepted for 2025 SICE-FES conference (IEEE)", "summary": "Shopping plays a significant role in shaping consumer identity and social\nintegration. However, for individuals with visual impairments, navigating in\nsupermarkets and identifying products can be an overwhelming and challenging\nexperience. This paper presents an AI-based shopping assistant prototype\ndesigned to enhance the autonomy and inclusivity of visually impaired\nindividuals in supermarket environments. The system integrates multiple\ntechnologies, including computer vision, speech recognition, text-to-speech\nsynthesis, and indoor navigation, into a single, user-friendly platform. Using\ncameras for ArUco marker detection and real-time environmental scanning, the\nsystem helps users navigate the store, identify product locations, provide\nreal-time auditory guidance, and gain context about their surroundings. The\nassistant interacts with the user through voice commands and multimodal\nfeedback, promoting a more dynamic and engaging shopping experience. The system\nwas evaluated through experiments, which demonstrated its ability to guide\nusers effectively and improve their shopping experience. This paper contributes\nto the development of inclusive AI-driven assistive technologies aimed at\nenhancing accessibility and user independence for the shopping experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u8d2d\u7269\u52a9\u624b\u539f\u578b\uff0c\u65e8\u5728\u5e2e\u52a9\u89c6\u969c\u4eba\u58eb\u5728\u8d85\u5e02\u73af\u5883\u4e2d\u63d0\u5347\u81ea\u4e3b\u6027\u548c\u5305\u5bb9\u6027\uff0c\u7ed3\u5408\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u8bed\u97f3\u8bc6\u522b\u7b49\u6280\u672f\u3002", "motivation": "\u8d2d\u7269\u5728\u5851\u9020\u6d88\u8d39\u8005\u8eab\u4efd\u548c\u793e\u4f1a\u878d\u5408\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5bf9\u89c6\u969c\u4eba\u58eb\u6765\u8bf4\uff0c\u8d85\u5e02\u8d2d\u7269\u5177\u6709\u6311\u6218\u6027\u3002\u7814\u7a76\u65e8\u5728\u63d0\u5347\u4ed6\u4eec\u7684\u8d2d\u7269\u4f53\u9a8c\u3002", "method": "\u7cfb\u7edf\u6574\u5408\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u8bed\u97f3\u8bc6\u522b\u3001\u6587\u672c\u8f6c\u8bed\u97f3\u5408\u6210\u548c\u5ba4\u5185\u5bfc\u822a\u6280\u672f\uff0c\u901a\u8fc7ArUco\u6807\u8bb0\u68c0\u6d4b\u548c\u5b9e\u65f6\u73af\u5883\u626b\u63cf\u5e2e\u52a9\u7528\u6237\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7cfb\u7edf\u80fd\u6709\u6548\u5f15\u5bfc\u7528\u6237\u5e76\u6539\u5584\u8d2d\u7269\u4f53\u9a8c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u5305\u5bb9\u6027AI\u8f85\u52a9\u6280\u672f\u63d0\u4f9b\u4e86\u8d21\u732e\uff0c\u65e8\u5728\u63d0\u5347\u8d2d\u7269\u4f53\u9a8c\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u7528\u6237\u72ec\u7acb\u6027\u3002"}}
{"id": "2509.01214", "pdf": "https://arxiv.org/pdf/2509.01214", "abs": "https://arxiv.org/abs/2509.01214", "authors": ["Yizhe Yuan", "Bingsen Xue", "Bangzheng Pu", "Chengxiang Wang", "Cheng Jin"], "title": "PRINTER:Deformation-Aware Adversarial Learning for Virtual IHC Staining with In Situ Fidelity", "categories": ["cs.CV", "cs.MM"], "comment": "10 pages, 4 figures", "summary": "Tumor spatial heterogeneity analysis requires precise correlation between\nHematoxylin and Eosin H&E morphology and immunohistochemical (IHC) biomarker\nexpression, yet current methods suffer from spatial misalignment in consecutive\nsections, severely compromising in situ pathological interpretation. In order\nto obtain a more accurate virtual staining pattern, We propose PRINTER, a\nweakly-supervised framework that integrates PRototype-drIven content and\nstaiNing patTERn decoupling and deformation-aware adversarial learning\nstrategies designed to accurately learn IHC staining patterns while preserving\nH&E staining details. Our approach introduces three key innovations: (1) A\nprototype-driven staining pattern transfer with explicit content-style\ndecoupling; and (2) A cyclic registration-synthesis framework GapBridge that\nbridges H&E and IHC domains through deformable structural alignment, where\nregistered features guide cross-modal style transfer while synthesized outputs\niteratively refine the registration;(3) Deformation-Aware Adversarial Learning:\nWe propose a training framework where a generator and deformation-aware\nregistration network jointly adversarially optimize a style-focused\ndiscriminator. Extensive experiments demonstrate that PRINTER effectively\nachieves superior performance in preserving H&E staining details and virtual\nstaining fidelity, outperforming state-of-the-art methods. Our work provides a\nrobust and scalable solution for virtual staining, advancing the field of\ncomputational pathology.", "AI": {"tldr": "PRINTER\u662f\u4e00\u4e2a\u5f31\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u539f\u578b\u9a71\u52a8\u548c\u53d8\u5f62\u611f\u77e5\u5bf9\u6297\u5b66\u4e60\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86H&E\u548cIHC\u67d3\u8272\u6a21\u5f0f\u7684\u7cbe\u786e\u865a\u62df\u67d3\u8272\uff0c\u89e3\u51b3\u4e86\u7a7a\u95f4\u9519\u4f4d\u95ee\u9898\u3002", "motivation": "\u80bf\u7624\u7a7a\u95f4\u5f02\u8d28\u6027\u5206\u6790\u9700\u8981H&E\u5f62\u6001\u5b66\u4e0eIHC\u751f\u7269\u6807\u5fd7\u7269\u8868\u8fbe\u7684\u7cbe\u786e\u5b9a\u4f4d\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u7a7a\u95f4\u9519\u4f4d\u95ee\u9898\u9650\u5236\u4e86\u75c5\u7406\u89e3\u91ca\u7684\u51c6\u786e\u6027\u3002", "method": "PRINTER\u7ed3\u5408\u539f\u578b\u9a71\u52a8\u7684\u5185\u5bb9-\u67d3\u8272\u6a21\u5f0f\u89e3\u8026\u548c\u53d8\u5f62\u611f\u77e5\u5bf9\u6297\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7GapBridge\u6846\u67b6\u5b9e\u73b0H&E\u4e0eIHC\u57df\u7684\u5bf9\u9f50\u4e0e\u865a\u62df\u67d3\u8272\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPRINTER\u5728\u4fdd\u7559H&E\u7ec6\u8282\u548c\u865a\u62df\u67d3\u8272\u4fdd\u771f\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PRINTER\u4e3a\u865a\u62df\u67d3\u8272\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u8ba1\u7b97\u75c5\u7406\u5b66\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.02369", "pdf": "https://arxiv.org/pdf/2509.02369", "abs": "https://arxiv.org/abs/2509.02369", "authors": ["Zacharia A. Rudge", "Dario Izzo", "Moritz Fieback", "Anteneh Gebregiorgis", "Said Hamdioui", "Dominik Dold"], "title": "Guidance and Control Neural Network Acceleration using Memristors", "categories": ["cs.AR", "cs.AI", "cs.SY", "eess.SY"], "comment": "4 pages, SPAICE 2024 conference", "summary": "In recent years, the space community has been exploring the possibilities of\nArtificial Intelligence (AI), specifically Artificial Neural Networks (ANNs),\nfor a variety of on board applications. However, this development is limited by\nthe restricted energy budget of smallsats and cubesats as well as radiation\nconcerns plaguing modern chips. This necessitates research into neural network\naccelerators capable of meeting these requirements whilst satisfying the\ncompute and performance needs of the application. This paper explores the use\nof Phase-Change Memory (PCM) and Resistive Random-Access Memory (RRAM)\nmemristors for on-board in-memory computing AI acceleration in space\napplications. A guidance and control neural network (G\\&CNET) accelerated using\nmemristors is simulated in a variety of scenarios and with both device types to\nevaluate the performance of memristor-based accelerators, considering device\nnon-idealities such as noise and conductance drift. We show that the memristive\naccelerator is able to learn the expert actions, though challenges remain with\nthe impact of noise on accuracy. We also show that re-training after\ndegradation is able to restore performance to nominal levels. This study\nprovides a foundation for future research into memristor-based AI accelerators\nfor space, highlighting their potential and the need for further investigation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u592a\u7a7a\u5e94\u7528\u4e2d\u4f7f\u7528\u76f8\u53d8\u5b58\u50a8\u5668\uff08PCM\uff09\u548c\u7535\u963b\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668\uff08RRAM\uff09\u5fc6\u963b\u5668\u8fdb\u884c\u5185\u5b58\u8ba1\u7b97AI\u52a0\u901f\u7684\u53ef\u884c\u6027\uff0c\u5206\u6790\u4e86\u5176\u6027\u80fd\u53ca\u6311\u6218\u3002", "motivation": "\u5c0f\u578b\u536b\u661f\u548c\u7acb\u65b9\u536b\u661f\u7684\u6709\u9650\u80fd\u91cf\u9884\u7b97\u53ca\u8f90\u5c04\u95ee\u9898\u9650\u5236\u4e86AI\u5728\u592a\u7a7a\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\uff0c\u9700\u8981\u7814\u7a76\u80fd\u6ee1\u8db3\u8ba1\u7b97\u548c\u6027\u80fd\u9700\u6c42\u7684\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u4f7f\u7528PCM\u548cRRAM\u5fc6\u963b\u5668\u52a0\u901f\u7684\u5236\u5bfc\u4e0e\u63a7\u5236\u795e\u7ecf\u7f51\u7edc\uff08G&CNET\uff09\uff0c\u8bc4\u4f30\u5176\u5728\u591a\u79cd\u573a\u666f\u4e0b\u548c\u975e\u7406\u60f3\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u5fc6\u963b\u52a0\u901f\u5668\u80fd\u591f\u5b66\u4e60\u4e13\u5bb6\u52a8\u4f5c\uff0c\u4f46\u566a\u58f0\u5bf9\u51c6\u786e\u6027\u4ecd\u6709\u5f71\u54cd\uff1b\u91cd\u65b0\u8bad\u7ec3\u53ef\u5728\u6027\u80fd\u4e0b\u964d\u540e\u6062\u590d\u81f3\u6b63\u5e38\u6c34\u5e73\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u592a\u7a7a\u5e94\u7528\u4e2d\u57fa\u4e8e\u5fc6\u963b\u5668\u7684AI\u52a0\u901f\u5668\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u53ca\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.01626", "pdf": "https://arxiv.org/pdf/2509.01626", "abs": "https://arxiv.org/abs/2509.01626", "authors": ["Daoce Wang", "Pascal Grosset", "Jesus Pulido", "Jiannan Tian", "Tushar M. Athawale", "Jinda Jia", "Baixi Sun", "Boyuan Zhang", "Sian Jin", "Kai Zhao", "James Ahrens", "Fengguang Song"], "title": "STZ: A High Quality and High Speed Streaming Lossy Compression Framework for Scientific Data", "categories": ["cs.DC", "cs.MM"], "comment": "accepted by SC '25", "summary": "Error-bounded lossy compression is one of the most efficient solutions to\nreduce the volume of scientific data. For lossy compression, progressive\ndecompression and random-access decompression are critical features that enable\non-demand data access and flexible analysis workflows. However, these features\ncan severely degrade compression quality and speed. To address these\nlimitations, we propose a novel streaming compression framework that supports\nboth progressive decompression and random-access decompression while\nmaintaining high compression quality and speed. Our contributions are\nthree-fold: (1) we design the first compression framework that simultaneously\nenables both progressive decompression and random-access decompression; (2) we\nintroduce a hierarchical partitioning strategy to enable both streaming\nfeatures, along with a hierarchical prediction mechanism that mitigates the\nimpact of partitioning and achieves high compression quality -- even comparable\nto state-of-the-art (SOTA) non-streaming compressor SZ3; and (3) our framework\ndelivers high compression and decompression speed, up to 6.7$\\times$ faster\nthan SZ3.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d41\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u652f\u6301\u6e10\u8fdb\u5f0f\u89e3\u538b\u7f29\u548c\u968f\u673a\u8bbf\u95ee\u89e3\u538b\u7f29\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u538b\u7f29\u901f\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u79d1\u5b66\u6570\u636e\u91cf\u5927\uff0c\u73b0\u6709\u7684\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\u5728\u5904\u7406\u6e10\u8fdb\u5f0f\u89e3\u538b\u7f29\u548c\u968f\u673a\u8bbf\u95ee\u89e3\u538b\u7f29\u65f6\u6548\u679c\u4e0d\u4f73\u3002\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u652f\u6301\u8fd9\u4e24\u79cd\u7279\u6027\u7684\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u652f\u6301\u6e10\u8fdb\u5f0f\u548c\u968f\u673a\u8bbf\u95ee\u89e3\u538b\u7f29\u7684\u538b\u7f29\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u5206\u533a\u7b56\u7565\u548c\u5206\u5c42\u9884\u6d4b\u673a\u5236\uff0c\u63d0\u9ad8\u538b\u7f29\u8d28\u91cf\u548c\u901f\u5ea6\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u538b\u7f29\u8d28\u91cf\u4e0eSZ3\u76f8\u5f53\uff0c\u538b\u7f29\u548c\u89e3\u538b\u7f29\u901f\u5ea6\u6bd4SZ3\u5feb6.7\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u9ad8\u6548\u89e3\u51b3\u4e86\u6d41\u5f0f\u538b\u7f29\u4e2d\u7684\u6e10\u8fdb\u5f0f\u548c\u968f\u673a\u8bbf\u95ee\u89e3\u538b\u7f29\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u548c\u901f\u5ea6\u3002"}}
{"id": "2509.02549", "pdf": "https://arxiv.org/pdf/2509.02549", "abs": "https://arxiv.org/abs/2509.02549", "authors": ["Keiwan Soltani", "Vishesh Kumar Tanwar", "Ashish Gupta", "Sajal K. Das"], "title": "Energy-Efficient Split Learning for Resource-Constrained Environments: A Smart Farming Solution", "categories": ["cs.DC", "cs.ET"], "comment": "Accepted at the 22nd IEEE International Conference on Mobile Ad-Hoc\n  and Smart Systems (MASS), 2025", "summary": "Smart farming systems encounter significant challenges, including limited\nresources, the need for data privacy, and poor connectivity in rural areas. To\naddress these issues, we present eEnergy-Split, an energy-efficient framework\nthat utilizes split learning (SL) to enable collaborative model training\nwithout direct data sharing or heavy computation on edge devices. By\ndistributing the model between edge devices and a central server, eEnergy-Split\nreduces on-device energy usage by up to 86 percent compared to federated\nlearning (FL) while safeguarding data privacy. Moreover, SL improves\nclassification accuracy by up to 6.2 percent over FL on ResNet-18 and by more\nmodest amounts on GoogleNet and MobileNetV2. We propose an optimal edge\ndeployment algorithm and a UAV trajectory planning strategy that solves the\nTraveling Salesman Problem (TSP) exactly to minimize flight cost and extend and\nmaximize communication rounds. Comprehensive evaluations on agricultural pest\ndatasets reveal that eEnergy-Split lowers UAV energy consumption compared to\nbaseline methods and boosts overall accuracy by up to 17 percent. Notably, the\nenergy efficiency of SL is shown to be model-dependent-yielding substantial\nsavings in lightweight models like MobileNet, while communication and memory\noverheads may reduce efficiency gains in deeper networks. These results\nhighlight the potential of combining SL with energy-aware design to deliver a\nscalable, privacy-preserving solution for resource-constrained smart farming\nenvironments.", "AI": {"tldr": "eEnergy-Split\u662f\u4e00\u4e2a\u80fd\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5272\u5b66\u4e60\uff08SL\uff09\u51cf\u5c11\u8fb9\u7f18\u8bbe\u5907\u7684\u80fd\u91cf\u6d88\u8017\u5e76\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u76f8\u6bd4\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u964d\u4f4e\u4e8686%\u7684\u80fd\u91cf\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u7387\u3002\u7ed3\u5408\u4f18\u5316\u8fb9\u7f18\u90e8\u7f72\u548c\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\uff0c\u5728\u519c\u4e1a\u5bb3\u866b\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u519c\u4e1a\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u9650\u5236\u3001\u6570\u636e\u9690\u79c1\u9700\u6c42\u548c\u519c\u6751\u5730\u533a\u8fde\u63a5\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u5229\u7528\u5206\u5272\u5b66\u4e60\uff08SL\uff09\u5206\u914d\u6a21\u578b\u8bad\u7ec3\u4efb\u52a1\uff0c\u7ed3\u5408\u8fb9\u7f18\u8bbe\u5907\u548c\u4e2d\u592e\u670d\u52a1\u5668\uff0c\u63d0\u51fa\u8fb9\u7f18\u90e8\u7f72\u7b97\u6cd5\u548c\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u7b56\u7565\u3002", "result": "\u76f8\u6bd4FL\uff0c\u80fd\u91cf\u6d88\u8017\u964d\u4f4e86%\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u53476.2%\uff08ResNet-18\uff09\uff0c\u6574\u4f53\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534717%\u3002", "conclusion": "eEnergy-Split\u901a\u8fc7SL\u548c\u80fd\u91cf\u611f\u77e5\u8bbe\u8ba1\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u667a\u80fd\u519c\u4e1a\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01012", "pdf": "https://arxiv.org/pdf/2509.01012", "abs": "https://arxiv.org/abs/2509.01012", "authors": ["Aamod Khatiwada", "Roee Shraga", "Ren\u00e9e J. Miller"], "title": "Diverse Unionable Tuple Search: Novelty-Driven Discovery in Data Lakes [Technical Report]", "categories": ["cs.DB"], "comment": null, "summary": "Unionable table search techniques input a query table from a user and search\nfor data lake tables that can contribute additional rows to the query table.\nThe definition of unionability is generally based on similarity measures which\nmay include similarity between columns (e.g., value overlap or semantic\nsimilarity of the values in the columns) or tables (e.g., similarity of table\nembeddings). Due to this and the large redundancy in many data lakes (which can\ncontain many copies and versions of the same table), the most unionable tables\nmay be identical or nearly identical to the query table and may contain little\nnew information. Hence, we introduce the problem of identifying unionable\ntuples from a data lake that are diverse with respect to the tuples already\npresent in a query table. We perform an extensive experimental analysis of\nwell-known diversity algorithms applied to this novel problem and identify a\ngap that we address with a novel, clustering-based tuple diversity algorithm\ncalled DUST. DUST uses a novel embedding model to represent unionable tuples\nthat outperforms other tuple representation models by at least 15 % when\nrepresenting unionable tuples. Using real data lake benchmarks, we show that\nour diversification algorithm is more than six times faster than the most\nefficient diversification baseline. We also show that it is more effective in\ndiversifying unionable tuples than existing diversification algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u89e3\u51b3\u6570\u636e\u6e56\u4e2d\u4e0e\u67e5\u8be2\u8868\u591a\u6837\u6027\u7684\u95ee\u9898\u7684\u7b97\u6cd5DUST\uff0c\u901a\u8fc7\u805a\u7c7b\u548c\u5d4c\u5165\u6a21\u578b\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u5408\u8868\u641c\u7d22\u6280\u672f\u53ef\u80fd\u4f1a\u8fd4\u56de\u4e0e\u67e5\u8be2\u8868\u51e0\u4e4e\u76f8\u540c\u7684\u8868\uff0c\u7f3a\u4e4f\u65b0\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u65b0\u7b97\u6cd5DUST\uff0c\u4f7f\u7528\u65b0\u578b\u5d4c\u5165\u6a21\u578b\u8868\u793a\u8054\u5408\u8868\u3002", "result": "DUST\u5728\u6548\u7387\u548c\u591a\u6837\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u901f\u5ea6\u63d0\u5347\u4e866\u500d\u4ee5\u4e0a\uff0c\u5d4c\u5165\u6a21\u578b\u6027\u80fd\u63d0\u9ad8\u4e8615%\u4ee5\u4e0a\u3002", "conclusion": "DUST\u5728\u8054\u5408\u8868\u591a\u6837\u6027\u548c\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01149", "pdf": "https://arxiv.org/pdf/2509.01149", "abs": "https://arxiv.org/abs/2509.01149", "authors": ["Hui Zeng", "Zhihao Xu", "Hui Li", "Siwen Wang", "Qian Ma"], "title": "Compiler Bugs Detection in Logic Synthesis Tools via Linear Upper Confidence Bound", "categories": ["cs.SE"], "comment": null, "summary": "Field-Programmable Gate Arrays (FPGAs) play an indispensable role in\nElectronic Design Automation (EDA), translating Register-Transfer Level (RTL)\ndesigns into gate-level netlists. The correctness and reliability of FPGA logic\nsynthesis tools are critically important, as unnoticed bugs in these tools may\ninfect the final hardware implementations. However, recent approaches often\nrely heavily on random selection strategies, limiting the structural diversity\nof the generated HDL test cases and resulting in inadequate exploration of the\ntool's feature space. To address this limitation, we propose Lin-Hunter, a\nnovel testing framework designed to systematically enhance the diversity of HDL\ntest cases and the efficiency of FPGA logic synthesis tool validation.\nSpecifically, Lin-Hunter introduces a principled set of metamorphic\ntransformation rules to generate functionally equivalent yet structurally\ndiverse HDL test case variants, effectively addressing the limited diversity of\nexisting test inputs. To further enhance bug discovery efficiency, Lin-Hunter\nintegrates an adaptive strategy selection mechanism based on the Linear Upper\nConfidence Bound (LinUCB) method. This method leverages feedback from synthesis\nlogs of previously executed test cases to dynamically prioritize transformation\nstrategies that have empirically demonstrated a higher likelihood of triggering\nsynthesis bugs. Comprehensive experiments conducted over a three-month period\ndemonstrate the practical effectiveness of Lin-Hunter. Our method has\ndiscovered 18 unique bugs, including 10 previously unreported defects, which\nhave been confirmed by official developers. Moreover, our method outperforms\nstate-of-the-art testing methods in both test-case diversity and bug-discovery\nefficiency.", "AI": {"tldr": "Lin-Hunter \u662f\u4e00\u4e2a\u65b0\u578b\u6d4b\u8bd5\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u751f\u6210\u591a\u6837\u5316\u7684 HDL \u6d4b\u8bd5\u7528\u4f8b\u548c\u4f18\u5316 FPGA \u903b\u8f91\u9a8c\u8bc1\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u591a\u6837\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "FPGA \u903b\u8f91\u7efc\u5408\u5de5\u5177\u7684\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u968f\u673a\u7b56\u7565\uff0c\u6d4b\u8bd5\u7528\u4f8b\u7684\u7ed3\u6784\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u5bfc\u81f4\u5de5\u5177\u529f\u80fd\u7a7a\u95f4\u63a2\u7d22\u4e0d\u5145\u5206\u3002", "method": "Lin-Hunter \u91c7\u7528\u4e86\u57fa\u4e8e\u53d8\u5f62\u89c4\u5219\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408 LinUCB \u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\u673a\u5236\uff0c\u52a8\u6001\u4f18\u5316\u6d4b\u8bd5\u7b56\u7565\u4ee5\u63d0\u9ad8\u9519\u8bef\u53d1\u73b0\u6548\u7387\u3002", "result": "\u5728\u4e09\u4e2a\u6708\u5b9e\u9a8c\u4e2d\uff0cLin-Hunter \u53d1\u73b0\u4e86 18 \u4e2a\u72ec\u7279\u9519\u8bef\uff08\u5305\u62ec 10 \u4e2a\u672a\u77e5\u9519\u8bef\uff09\uff0c\u5e76\u5728\u591a\u6837\u6027\u548c\u9519\u8bef\u53d1\u73b0\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Lin-Hunter \u663e\u8457\u63d0\u5347\u4e86 FPGA \u5de5\u5177\u9a8c\u8bc1\u7684\u591a\u6837\u6027\u548c\u6548\u7387\uff0c\u88ab\u5b98\u65b9\u5f00\u53d1\u8005\u786e\u8ba4\u6709\u6548\u3002"}}
{"id": "2509.02491", "pdf": "https://arxiv.org/pdf/2509.02491", "abs": "https://arxiv.org/abs/2509.02491", "authors": ["Charles Pert", "Dalal Alrajeh", "Alessandra Russo"], "title": "RNN Generalization to Omega-Regular Languages", "categories": ["cs.LG", "cs.FL", "cs.LO"], "comment": "7 pages, 3 figures. To be published in OVERLAY 2025, 7th\n  International Workshop on Artificial Intelligence and Formal Verification,\n  Logic, Automata, and Synthesis. See https://overlay.uniud.it/workshop/2025/", "summary": "B\\\"uchi automata (BAs) recognize $\\omega$-regular languages defined by formal\nspecifications like linear temporal logic (LTL) and are commonly used in the\nverification of reactive systems. However, BAs face scalability challenges when\nhandling and manipulating complex system behaviors. As neural networks are\nincreasingly used to address these scalability challenges in areas like model\nchecking, investigating their ability to generalize beyond training data\nbecomes necessary. This work presents the first study investigating whether\nrecurrent neural networks (RNNs) can generalize to $\\omega$-regular languages\nderived from LTL formulas. We train RNNs on ultimately periodic $\\omega$-word\nsequences to replicate target BA behavior and evaluate how well they generalize\nto out-of-distribution sequences. Through experiments on LTL formulas\ncorresponding to deterministic automata of varying structural complexity, from\n3 to over 100 states, we show that RNNs achieve high accuracy on their target\n$\\omega$-regular languages when evaluated on sequences up to $8 \\times$ longer\nthan training examples, with $92.6\\%$ of tasks achieving perfect or\nnear-perfect generalization. These results establish the feasibility of neural\napproaches for learning complex $\\omega$-regular languages, suggesting their\npotential as components in neurosymbolic verification methods.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u63a2\u8ba8\u4e86RNNs\u662f\u5426\u80fd\u6cdb\u5316\u5230LTL\u516c\u5f0f\u884d\u751f\u7684\u03c9-regular\u8bed\u8a00\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aRNNs\u5728\u8bad\u7ec3\u6570\u636e\u5916\u7684\u957f\u5e8f\u5217\u4e0a\u4e5f\u80fd\u9ad8\u51c6\u786e\u7387\u5730\u5b66\u4e60\u590d\u6742\u8bed\u8a00\u3002", "motivation": "B\u00fcchi\u81ea\u52a8\u673a\u5728\u5904\u7406\u590d\u6742\u7cfb\u7edf\u884c\u4e3a\u65f6\u9762\u4e34\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u795e\u7ecf\u7f51\u7edc\u7684\u5f15\u5165\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u4f46\u5176\u6cdb\u5316\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5728\u5468\u671f\u6027\u03c9\u8bcd\u5e8f\u5217\u4e0a\u8bad\u7ec3RNNs\u4ee5\u6a21\u62df\u76ee\u6807B\u00fcchi\u81ea\u52a8\u673a\u7684\u884c\u4e3a\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u5206\u5e03\u5916\u5e8f\u5217\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRNNs\u5728\u6bd4\u8bad\u7ec3\u6570\u636e\u957f8\u500d\u7684\u5e8f\u5217\u4e0a\u4ecd\u80fd\u9ad8\u51c6\u786e\u7387\u5730\u5b66\u4e60\u590d\u6742\u03c9-regular\u8bed\u8a00\uff0c92.6%\u7684\u4efb\u52a1\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u6216\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6cdb\u5316\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u590d\u6742\u03c9-regular\u8bed\u8a00\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u795e\u7ecf\u7b26\u53f7\u5316\u9a8c\u8bc1\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6f5c\u5728\u7ec4\u4ef6\u3002"}}
{"id": "2509.02278", "pdf": "https://arxiv.org/pdf/2509.02278", "abs": "https://arxiv.org/abs/2509.02278", "authors": ["Zikai Huang", "Yihan Zhou", "Xuemiao Xu", "Cheng Xu", "Xiaofen Xing", "Jing Qin", "Shengfeng He"], "title": "Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation", "categories": ["cs.GR", "cs.AI", "cs.MM"], "comment": null, "summary": "Singing-driven 3D head animation is a challenging yet promising task with\napplications in virtual avatars, entertainment, and education. Unlike speech,\nsinging involves richer emotional nuance, dynamic prosody, and lyric-based\nsemantics, requiring the synthesis of fine-grained, temporally coherent facial\nmotion. Existing speech-driven approaches often produce oversimplified,\nemotionally flat, and semantically inconsistent results, which are insufficient\nfor singing animation. To address this, we propose Think2Sing, a\ndiffusion-based framework that leverages pretrained large language models to\ngenerate semantically coherent and temporally consistent 3D head animations,\nconditioned on both lyrics and acoustics. A key innovation is the introduction\nof motion subtitles, an auxiliary semantic representation derived through a\nnovel Singing Chain-of-Thought reasoning process combined with acoustic-guided\nretrieval. These subtitles contain precise timestamps and region-specific\nmotion descriptions, serving as interpretable motion priors. We frame the task\nas a motion intensity prediction problem, enabling finer control over facial\nregions and improving the modeling of expressive motion. To support this, we\ncreate a multimodal singing dataset with synchronized video, acoustic\ndescriptors, and motion subtitles, enabling diverse and expressive motion\nlearning. Extensive experiments show that Think2Sing outperforms\nstate-of-the-art methods in realism, expressiveness, and emotional fidelity,\nwhile also offering flexible, user-controllable animation editing.", "AI": {"tldr": "Think2Sing\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9884\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u6b4c\u8bcd\u4e0e\u58f0\u5b66\u6761\u4ef6\uff0c\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u3001\u65f6\u95f4\u8fde\u8d2f\u76843D\u5934\u90e8\u52a8\u753b\uff0c\u7528\u4e8e\u5531\u6b4c\u9a71\u52a8\u7684\u52a8\u753b\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u97f3\u9a71\u52a8\u65b9\u6cd5\u5728\u5531\u6b4c\u52a8\u753b\u4e2d\u6548\u679c\u4e0d\u4f73\uff0c\u8868\u73b0\u4e3a\u8fc7\u5ea6\u7b80\u5316\u3001\u60c5\u611f\u5e73\u6de1\u548c\u8bed\u4e49\u4e0d\u4e00\u81f4\u3002\u5531\u6b4c\u6d89\u53ca\u66f4\u4e30\u5bcc\u7684\u60c5\u611f\u3001\u52a8\u6001\u97f5\u5f8b\u548c\u6b4c\u8bcd\u8bed\u4e49\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u9762\u90e8\u8fd0\u52a8\u5408\u6210\u3002", "method": "\u63d0\u51faThink2Sing\u6846\u67b6\uff0c\u5f15\u5165\u8fd0\u52a8\u5b57\u5e55\u4f5c\u4e3a\u8f85\u52a9\u8bed\u4e49\u8868\u793a\uff0c\u901a\u8fc7\u5531\u6b4c\u94fe\u5f0f\u63a8\u7406\u548c\u58f0\u5b66\u6307\u5bfc\u68c0\u7d22\u751f\u6210\u8fd0\u52a8\u5f3a\u5ea6\u9884\u6d4b\u95ee\u9898\uff0c\u4ece\u800c\u7cbe\u7ec6\u63a7\u5236\u9762\u90e8\u533a\u57df\u548c\u6539\u8fdb\u8868\u8fbe\u8fd0\u52a8\u7684\u5efa\u6a21\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cThink2Sing\u5728\u771f\u5b9e\u6027\u3001\u8868\u8fbe\u529b\u548c\u60c5\u611f\u4fdd\u771f\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u652f\u6301\u7075\u6d3b\u7684\u52a8\u753b\u7f16\u8f91\u3002", "conclusion": "Think2Sing\u901a\u8fc7\u521b\u65b0\u7684\u8fd0\u52a8\u5b57\u5e55\u548c\u8bed\u4e49\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u5531\u6b4c\u9a71\u52a8\u52a8\u753b\u4e2d\u8bed\u4e49\u548c\u60c5\u611f\u8868\u8fbe\u7684\u6311\u6218\u3002"}}
{"id": "2509.01008", "pdf": "https://arxiv.org/pdf/2509.01008", "abs": "https://arxiv.org/abs/2509.01008", "authors": ["Fatma Chaouech", "Javier Villegas", "Ant\u00f3nio Pereira", "Carlos Baena", "Sergio Fortes", "Raquel Barco", "Dominic Gribben", "Mohammad Dib", "Alba Villarino", "Aser Cortines", "Rom\u00e1n Or\u00fas"], "title": "Quantum-based QoE Optimization in Advanced Cellular Networks: Integration and Cloud Gaming Use Case", "categories": ["cs.NI", "cs.LG", "quant-ph"], "comment": null, "summary": "This work explores the integration of Quantum Machine Learning (QML) and\nQuantum-Inspired (QI) techniques for optimizing end-to-end (E2E) network\nservices in telecommunication systems, particularly focusing on 5G networks and\nbeyond. The application of QML and QI algorithms is investigated, comparing\ntheir performance with classical Machine Learning (ML) approaches. The present\nstudy employs a hybrid framework combining quantum and classical computing\nleveraging the strengths of QML and QI, without the penalty of quantum hardware\navailability. This is particularized for the optimization of the Quality of\nExperience (QoE) over cellular networks. The framework comprises an estimator\nfor obtaining the expected QoE based on user metrics, service settings, and\ncell configuration, and an optimizer that uses the estimation to choose the\nbest cell and service configuration. Although the approach is applicable to any\nQoE-based network management, its implementation is particularized for the\noptimization of network configurations for Cloud Gaming services. Then, it is\nevaluated via performance metrics such as accuracy and model loading and\ninference times for the estimator, and time to solution and solution score for\nthe optimizer. The results indicate that QML models achieve similar or superior\naccuracy to classical ML models for estimation, while decreasing inference and\nloading times. Furthermore, potential for better performance is observed for\nhigher-dimensional data, highlighting promising results for higher complexity\nproblems. Thus, the results demonstrate the promising potential of QML in\nadvancing network optimization, although challenges related to data\navailability and integration complexities between quantum and classical ML are\nidentified as future research lines.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff08QML\uff09\u548c\u91cf\u5b50\u542f\u53d1\uff08QI\uff09\u6280\u672f\u57285G\u53ca\u4ee5\u4e0a\u7f51\u7edc\u4e2d\u4f18\u5316\u7aef\u5230\u7aef\u670d\u52a1\u7684\u5e94\u7528\uff0c\u7ed3\u679c\u8868\u660eQML\u5728\u4f30\u8ba1\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5229\u7528QML\u548cQI\u6280\u672f\u4f18\u5316\u7535\u4fe1\u7f51\u7edc\u4e2d\u7684\u670d\u52a1\u8d28\u91cf\uff08QoE\uff09\uff0c\u5c24\u5176\u662f\u57285G\u53ca\u66f4\u9ad8\u7f51\u7edc\u73af\u5883\u4e0b\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6846\u67b6\u7ed3\u5408\u91cf\u5b50\u4e0e\u7ecf\u5178\u8ba1\u7b97\uff0c\u901a\u8fc7QML\u548cQI\u4f18\u5316\u7f51\u7edc\u914d\u7f6e\uff1b\u5177\u4f53\u5b9e\u73b0\u9488\u5bf9\u4e91\u6e38\u620f\u670d\u52a1\u7684QoE\u4f18\u5316\u3002", "result": "QML\u6a21\u578b\u5728\u4f30\u8ba1\u51c6\u786e\u6027\u4e0a\u4e0e\u4f20\u7edfML\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u4e14\u63a8\u7406\u548c\u52a0\u8f7d\u65f6\u95f4\u66f4\u77ed\uff1b\u9ad8\u7ef4\u6570\u636e\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "QML\u5728\u7f51\u7edc\u4f18\u5316\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u6570\u636e\u53ef\u7528\u6027\u548c\u91cf\u5b50\u4e0e\u7ecf\u5178ML\u7684\u96c6\u6210\u590d\u6742\u6027\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2509.01367", "pdf": "https://arxiv.org/pdf/2509.01367", "abs": "https://arxiv.org/abs/2509.01367", "authors": ["Xuanru Cheng", "Xian Wang", "Chi-lok Tai", "Lik-Hang Lee"], "title": "MetaRoundWorm: A Virtual Reality Escape Room Game for Learning the Lifecycle and Immune Response to Parasitic Infections", "categories": ["cs.HC"], "comment": null, "summary": "Promoting public health is challenging owing to its abstract nature, and\nindividuals may be apprehensive about confronting it. Recently, there has been\nan increasing interest in using the metaverse and gamification as novel\neducational techniques to improve learning experiences related to the immune\nsystem. Thus, we present MetaRoundWorm, an immersive virtual reality (VR)\nescape room game designed to enhance the understanding of parasitic infections\nand host immune responses through interactive, gamified learning. The\napplication simulates the lifecycle of Ascaris lumbricoides and corresponding\nimmunological mechanisms across anatomically accurate environments within the\nhuman body. Integrating serious game mechanics with embodied learning\nprinciples, MetaRoundWorm offers players a task-driven experience combining\nexploration, puzzle-solving, and immune system simulation. To evaluate the\neducational efficacy and user engagement, we conducted a controlled study\ncomparing MetaRoundWorm against a traditional approach, i.e., interactive\nslides. Results indicate that MetaRoundWorm significantly improves immediate\nlearning outcomes, cognitive engagement, and emotional experience, while\nmaintaining knowledge retention over time. Our findings suggest that immersive\nVR gamification holds promise as an effective pedagogical tool for\ncommunicating complex biomedical concepts and advancing digital health\neducation.", "AI": {"tldr": "MetaRoundWorm\u662f\u4e00\u6b3e\u6c89\u6d78\u5f0fVR\u9003\u8131\u6e38\u620f\uff0c\u65e8\u5728\u901a\u8fc7\u6e38\u620f\u5316\u5b66\u4e60\u63d0\u5347\u5bf9\u5bc4\u751f\u866b\u611f\u67d3\u548c\u5bbf\u4e3b\u514d\u75ab\u53cd\u5e94\u7684\u7406\u89e3\u3002\u7814\u7a76\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u4e92\u52a8\u5e7b\u706f\u7247\u76f8\u6bd4\uff0c\u5b83\u80fd\u663e\u8457\u63d0\u9ad8\u5b66\u4e60\u6548\u679c\u548c\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u516c\u5171\u536b\u751f\u6559\u80b2\u5177\u6709\u62bd\u8c61\u6027\u4e14\u6613\u5f15\u53d1\u62b5\u89e6\u60c5\u7eea\uff0c\u4e9f\u9700\u521b\u65b0\u6559\u5b66\u65b9\u6cd5\u3002\u5143\u5b87\u5b99\u548c\u6e38\u620f\u5316\u88ab\u89c6\u4e3a\u6539\u5584\u514d\u75ab\u7cfb\u7edf\u5b66\u4e60\u4f53\u9a8c\u7684\u65b0\u9014\u5f84\u3002", "method": "\u5f00\u53d1\u4e86MetaRoundWorm VR\u6e38\u620f\uff0c\u6a21\u62df\u86d4\u866b\u751f\u547d\u5468\u671f\u53ca\u4eba\u4f53\u514d\u75ab\u53cd\u5e94\u3002\u7ed3\u5408\u4efb\u52a1\u9a71\u52a8\u3001\u63a2\u7d22\u89e3\u8c1c\u7b49\u673a\u5236\uff0c\u5e76\u4e0e\u4f20\u7edf\u4e92\u52a8\u5e7b\u706f\u7247\u8fdb\u884c\u5bf9\u6bd4\u7814\u7a76\u3002", "result": "MetaRoundWorm\u663e\u8457\u63d0\u5347\u4e86\u5373\u65f6\u5b66\u4e60\u6548\u679c\u3001\u8ba4\u77e5\u53c2\u4e0e\u5ea6\u548c\u60c5\u611f\u4f53\u9a8c\uff0c\u4e14\u77e5\u8bc6\u4fdd\u7559\u7387\u7a33\u5b9a\u3002", "conclusion": "\u6c89\u6d78\u5f0fVR\u6e38\u620f\u5316\u662f\u4f20\u64ad\u590d\u6742\u751f\u7269\u533b\u5b66\u6982\u5ff5\u548c\u63a8\u52a8\u6570\u5b57\u5065\u5eb7\u6559\u80b2\u7684\u6709\u6548\u6559\u5b66\u5de5\u5177\u3002"}}
{"id": "2509.01362", "pdf": "https://arxiv.org/pdf/2509.01362", "abs": "https://arxiv.org/abs/2509.01362", "authors": ["Jiayi Gao", "Changcheng Hua", "Qingchao Chen", "Yuxin Peng", "Yang Liu"], "title": "Identity-Preserving Text-to-Video Generation via Training-Free Prompt, Image, and Guidance Enhancement", "categories": ["cs.CV", "cs.MM"], "comment": "7 pages, 3 figures", "summary": "Identity-preserving text-to-video (IPT2V) generation creates videos faithful\nto both a reference subject image and a text prompt. While fine-tuning large\npretrained video diffusion models on ID-matched data achieves state-of-the-art\nresults on IPT2V, data scarcity and high tuning costs hinder broader\nimprovement. We thus introduce a Training-Free Prompt, Image, and Guidance\nEnhancement (TPIGE) framework that bridges the semantic gap between the video\ndescription and the reference image and design sampling guidance that enhances\nidentity preservation and video quality, achieving performance gains at minimal\ncost.Specifically, we first propose Face Aware Prompt Enhancement, using GPT-4o\nto enhance the text prompt with facial details derived from the reference\nimage. We then propose Prompt Aware Reference Image Enhancement, leveraging an\nidentity-preserving image generator to refine the reference image, rectifying\nconflicts with the text prompt. The above mutual refinement significantly\nimproves input quality before video generation. Finally, we propose ID-Aware\nSpatiotemporal Guidance Enhancement, utilizing unified gradients to optimize\nidentity preservation and video quality jointly during generation.Our method\noutperforms prior work and is validated by automatic and human evaluations on a\n1000 video test set, winning first place in the ACM Multimedia 2025\nIdentity-Preserving Video Generation Challenge, demonstrating state-of-the-art\nperformance and strong generality. The code is available at\nhttps://github.com/Andyplus1/IPT2V.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65e0\u8bad\u7ec3\u7684\u63d0\u793a\u3001\u56fe\u50cf\u548c\u5f15\u5bfc\u589e\u5f3a\uff08TPIGE\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u8eab\u4efd\u4fdd\u6301\u6587\u672c\u5230\u89c6\u9891\uff08IPT2V\uff09\u751f\u6210\u7684\u8d28\u91cf\uff0c\u89e3\u51b3\u6570\u636e\u548c\u8c03\u4f18\u6210\u672c\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5927\u91cf\u6570\u636e\u548c\u6602\u8d35\u8c03\u4f18\uff0c\u9650\u5236\u4e86IPT2V\u7684\u5e7f\u6cdb\u6539\u8fdb\u3002", "method": "\u901a\u8fc7GPT-4o\u589e\u5f3a\u6587\u672c\u63d0\u793a\uff0c\u7528\u56fe\u50cf\u751f\u6210\u5668\u4f18\u5316\u53c2\u8003\u56fe\u50cf\uff0c\u5e76\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u7edf\u4e00\u68af\u5ea6\u4f18\u5316\u3002", "result": "\u57281000\u4e2a\u89c6\u9891\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d62\u5f97\u4e86ACM Multimedia 2025\u7ade\u8d5b\u3002", "conclusion": "TPIGE\u6846\u67b6\u5728\u4e0d\u9700\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86IPT2V\u7684\u6027\u80fd\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2509.01742", "pdf": "https://arxiv.org/pdf/2509.01742", "abs": "https://arxiv.org/abs/2509.01742", "authors": ["Yitong Guo", "Hongbo Chen", "Haobin Hiroki Chen", "Yukui Luo", "XiaoFeng Wang", "Chenghong Wang"], "title": "BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure HBM Accelerators", "categories": ["cs.CR", "cs.AR"], "comment": "Accepted by CCS 2025", "summary": "While Trusted Execution Environments provide a strong foundation for secure\ncloud computing, they remain vulnerable to access pattern leakages. Oblivious\nMaps (OMAPs) mitigate this by fully hiding access patterns but suffer from high\noverhead due to randomized remapping and worst-case padding. We argue these\ncosts are not fundamental. Modern accelerators featuring High-Bandwidth Memory\n(HBM) offer a new opportunity: Vaswani et al. [OSDI'18] point out that\neavesdropping on HBM is difficult -- even for physical attackers -- as its\nmemory channels are sealed together with processor cores inside the same\nphysical package. Later, Hunt et al. [NSDI'20] show that, with proper\nisolation, HBM can be turned into an unobservable region where both data and\nmemory traces are hidden. This motivates a rethink of OMAP design with\nHBM-backed solutions to finally overcome their traditional performance limits.\nBuilding on these insights, we present BOLT, a Bandwidth Optimized,\nLightning-fast OMAP accelerator that, for the first time, achieves O(1) +\nO((log log N)^2) bandwidth overhead. BOLT introduces three key innovations: (i)\na new OMAP algorithm that leverages isolated HBM as an unobservable cache to\naccelerate oblivious access to large host memory; (ii) a self-hosted\narchitecture that offloads execution and memory control from the host to\nmitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs\nthat maximize resource efficiency. We implement a prototype BOLT on a Xilinx\nU55C FPGA. Evaluations show that BOLT achieves up to 279x and 480x speedups in\ninitialization and query time, respectively, over state-of-the-art OMAPs,\nincluding an industry implementation from Facebook.", "AI": {"tldr": "BOLT\u662f\u4e00\u79cd\u57fa\u4e8eHBM\u7684\u9ad8\u6027\u80fd\u65e0\u611f\u77e5\u5730\u56fe\uff08OMAP\uff09\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u7b97\u6cd5\u548c\u67b6\u6784\u8bbe\u8ba1\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5e26\u5bbd\u5f00\u9500\u548c\u6027\u80fd\u635f\u8017\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edfOMAP\u56e0\u968f\u673a\u91cd\u6620\u5c04\u548c\u6700\u574f\u60c5\u51b5\u586b\u5145\u5bfc\u81f4\u7684\u9ad8\u5f00\u9500\u95ee\u9898\uff0c\u5229\u7528\u73b0\u4ee3\u52a0\u901f\u5668\u7684HBM\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u9694\u79bbHBM\u4f5c\u4e3a\u4e0d\u53ef\u89c2\u6d4b\u7f13\u5b58\u7684\u65b0\u7b97\u6cd5\u3001\u81ea\u6211\u6258\u7ba1\u67b6\u6784\u4ee5\u53ca\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684OMAP\u52a0\u901f\u3002", "result": "BOLT\u5728\u521d\u59cb\u5316\u548c\u67e5\u8be2\u65f6\u95f4\u4e0a\u5206\u522b\u6bd4\u73b0\u6709OMAP\u5b9e\u73b0\u5feb279\u500d\u548c480\u500d\uff0c\u9996\u6b21\u8fbe\u5230O(1) + O((log log N)^2)\u5e26\u5bbd\u5f00\u9500\u3002", "conclusion": "BOLT\u901a\u8fc7HBM\u548c\u521b\u65b0\u7684\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86OMAP\u7684\u6027\u80fd\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\u9650\u5236\u3002"}}
{"id": "2509.01617", "pdf": "https://arxiv.org/pdf/2509.01617", "abs": "https://arxiv.org/abs/2509.01617", "authors": ["Chris Partridge", "Andrew Mitchell", "Sergio de Cesare", "Oscar Xiberta Soto"], "title": "Disentangling the schema turn: Restoring the information base to conceptual modelling", "categories": ["cs.DB", "cs.AI", "cs.SE", "D.2.10"], "comment": "Fundamentals of Conceptual Modeling - ER2025 Workshop", "summary": "If one looks at contemporary mainstream development practices for conceptual\nmodelling in computer science, these so clearly focus on a conceptual schema\ncompletely separated from its information base that the conceptual schema is\noften just called the conceptual model. These schema-centric practices are\ncrystallized in almost every database textbook. We call this strong, almost\nuniversal, bias towards conceptual schemas the schema turn. The focus of this\npaper is on disentangling this turn within (computer science) conceptual\nmodeling. It aims to shed some light on how it emerged and so show that it is\nnot fundamental. To show that modern technology enables the adoption of an\ninclusive schema-and-base conceptual modelling approach, which in turn enables\nmore automated, and empirically motivated practices. And to show, more\ngenerally, the space of possible conceptual modelling practices is wider than\ncurrently assumed. It also uses the example of bCLEARer to show that the\nimplementations in this wider space will probably need to rely on new\npipeline-based conceptual modelling techniques. So, it is possible that the\nschema turn's complete exclusion of the information base could be merely a\ntemporary evolutionary detour.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u6982\u5ff5\u5efa\u6a21\u7684\u2018\u6a21\u5f0f\u8f6c\u5411\u2019\u73b0\u8c61\uff0c\u63a2\u8ba8\u5176\u8d77\u6e90\u5e76\u5c55\u793a\u5176\u975e\u5fc5\u8981\u6027\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u6a21\u5f0f\u4e0e\u4fe1\u606f\u5e93\u7684\u66f4\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "motivation": "\u63a2\u8ba8\u5f53\u4ee3\u4e3b\u6d41\u6982\u5ff5\u5efa\u6a21\u5b9e\u8df5\u4e2d\u2018\u6a21\u5f0f\u8f6c\u5411\u2019\u73b0\u8c61\u7684\u6210\u56e0\u53ca\u5176\u5c40\u9650\u6027\uff0c\u5c55\u793a\u66f4\u5e7f\u6cdb\u7684\u53ef\u80fd\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5386\u53f2\u548c\u6280\u672f\u53d1\u5c55\uff0c\u8bba\u8bc1\u7ed3\u5408\u6a21\u5f0f\u4e0e\u4fe1\u606f\u5e93\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4ee5bCLEARer\u4e3a\u4f8b\u8bf4\u660e\u65b0\u6280\u672f\u7684\u5b9e\u73b0\u3002", "result": "\u73b0\u4ee3\u6280\u672f\u53ef\u5b9e\u73b0\u6a21\u5f0f\u4e0e\u4fe1\u606f\u5e93\u7ed3\u5408\u7684\u6982\u5ff5\u5efa\u6a21\uff0c\u65b9\u6cd5\u6bd4\u5f53\u524d\u5047\u8bbe\u66f4\u4e30\u5bcc\u3002", "conclusion": "\u2018\u6a21\u5f0f\u8f6c\u5411\u2019\u53ef\u80fd\u53ea\u662f\u6682\u65f6\u7684\u8fdb\u5316\u5f2f\u8def\uff0c\u672a\u6765\u6216\u6709\u66f4\u5305\u5bb9\u7684\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2509.01255", "pdf": "https://arxiv.org/pdf/2509.01255", "abs": "https://arxiv.org/abs/2509.01255", "authors": ["Oleksii Novikov", "Davide Fucci", "Oleksandr Adamov", "Daniel Mendez"], "title": "Policy-driven Software Bill of Materials on GitHub: An Empirical Study", "categories": ["cs.SE"], "comment": "To be published in the proceedings of PROFES2025", "summary": "Background. The Software Bill of Materials (SBOM) is a machine-readable list\nof all the software dependencies included in a software. SBOM emerged as way to\nassist securing the software supply chain. However, despite mandates from\ngovernments to use SBOM, research on this artifact is still in its early\nstages. Aims. We want to understand the current state of SBOM in open-source\nprojects, focusing specifically on policy-driven SBOMs, i.e., SBOM created to\nachieve security goals, such as enhancing project transparency and ensuring\ncompliance, rather than being used as fixtures for tools or artificially\ngenerated for benchmarking or academic research purposes. Method. We performed\na mining software repository study to collect and carefully select SBOM files\nhosted on GitHub. We analyzed the information reported in policy-driven SBOMs\nand the vulnerabilities associated with the declared dependencies by means of\ndescriptive statistics. Results. We show that only 0.56% of popular GitHub\nrepositories contain policy-driven SBOM. The declared dependencies contain\n2,202 unique vulnerabilities, while 22% of them do not report licensing\ninformation. Conclusion. Our findings provide insights for SBOM usage to\nsupport security assessment and licensing.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u4ec5\u67090.56%\u7684GitHub\u70ed\u95e8\u4ed3\u5e93\u5305\u542b\u7b56\u7565\u9a71\u52a8\u7684SBOM\uff0c\u8fd9\u4e9bSBOM\u4e2d\u5b58\u5728\u5927\u91cf\u6f0f\u6d1e\uff0c\u4e1422%\u672a\u62a5\u544a\u8bb8\u53ef\u8bc1\u4fe1\u606f\u3002", "motivation": "SBOM\u6709\u52a9\u4e8e\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\uff0c\u4f46\u5b9e\u9645\u7814\u7a76\u548c\u5e94\u7528\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u5f00\u6e90\u9879\u76ee\u4e2d\u7b56\u7565\u9a71\u52a8SBOM\u7684\u73b0\u72b6\u3002", "method": "\u901a\u8fc7\u6316\u6398GitHub\u4ed3\u5e93\u4e2d\u7684SBOM\u6587\u4ef6\uff0c\u5206\u6790\u5176\u5305\u542b\u7684\u4fe1\u606f\u548c\u76f8\u5173\u6f0f\u6d1e\uff0c\u4f7f\u7528\u63cf\u8ff0\u6027\u7edf\u8ba1\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u7b56\u7565\u9a71\u52a8SBOM\u7684\u666e\u53ca\u7387\u6781\u4f4e\uff0c\u5b58\u57282202\u4e2a\u552f\u4e00\u6f0f\u6d1e\uff0c22%\u7684\u4f9d\u8d56\u9879\u672a\u63d0\u4f9b\u8bb8\u53ef\u8bc1\u4fe1\u606f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aSBOM\u7684\u5b89\u5168\u8bc4\u4f30\u548c\u8bb8\u53ef\u8bc1\u7ba1\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2509.02474", "pdf": "https://arxiv.org/pdf/2509.02474", "abs": "https://arxiv.org/abs/2509.02474", "authors": ["Nina Wiedemann", "Sainan Liu", "Quentin Leboutet", "Katelyn Gao", "Benjamin Ummenhofer", "Michael Paulitsch", "Kai Yuan"], "title": "Unifi3D: A Study on 3D Representations for Generation and Reconstruction in a Common Framework", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "Following rapid advancements in text and image generation, research has\nincreasingly shifted towards 3D generation. Unlike the well-established\npixel-based representation in images, 3D representations remain diverse and\nfragmented, encompassing a wide variety of approaches such as voxel grids,\nneural radiance fields, signed distance functions, point clouds, or octrees,\neach offering distinct advantages and limitations. In this work, we present a\nunified evaluation framework designed to assess the performance of 3D\nrepresentations in reconstruction and generation. We compare these\nrepresentations based on multiple criteria: quality, computational efficiency,\nand generalization performance. Beyond standard model benchmarking, our\nexperiments aim to derive best practices over all steps involved in the 3D\ngeneration pipeline, including preprocessing, mesh reconstruction, compression\nwith autoencoders, and generation. Our findings highlight that reconstruction\nerrors significantly impact overall performance, underscoring the need to\nevaluate generation and reconstruction jointly. We provide insights that can\ninform the selection of suitable 3D models for various applications,\nfacilitating the development of more robust and application-specific solutions\nin 3D generation. The code for our framework is available at\nhttps://github.com/isl-org/unifi3d.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u8f83\u4e0d\u540c3D\u8868\u793a\u65b9\u6cd5\u5728\u91cd\u5efa\u548c\u751f\u6210\u4e2d\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u5173\u6ce8\u8d28\u91cf\u3001\u8ba1\u7b97\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u6587\u672c\u548c\u56fe\u50cf\u751f\u6210\u7684\u5feb\u901f\u53d1\u5c55\uff0c3D\u751f\u6210\u7814\u7a76\u9010\u6e10\u5174\u8d77\uff0c\u4f463D\u8868\u793a\u65b9\u6cd5\u591a\u6837\u4e14\u5206\u6563\uff0c\u7f3a\u4e4f\u7edf\u4e00\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u6bd4\u4e86\u591a\u79cd3D\u8868\u793a\u65b9\u6cd5\uff08\u5982\u4f53\u7d20\u7f51\u683c\u3001\u795e\u7ecf\u8f90\u5c04\u573a\u7b49\uff09\uff0c\u5e76\u4ece\u9884\u5904\u7406\u3001\u91cd\u5efa\u3001\u538b\u7f29\u5230\u751f\u6210\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u91cd\u5efa\u9519\u8bef\u5bf9\u6574\u4f53\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0c\u751f\u6210\u548c\u91cd\u5efa\u9700\u8981\u8054\u5408\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u76843D\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u9c81\u68d2\u4e14\u4e13\u7528\u76843D\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01201", "pdf": "https://arxiv.org/pdf/2509.01201", "abs": "https://arxiv.org/abs/2509.01201", "authors": ["Suhwan Jung", "Seokwoo Choi", "Youngkeun Yoon", "Ho-kyung Son", "Hyoil Kim"], "title": "Modeling and Analysis of Coexistence Between MLO NSTR-based Wi-Fi 7 and Legacy Wi-Fi", "categories": ["cs.NI"], "comment": null, "summary": "Wi-Fi 7 introduces Multi-link operation (MLO) to enhance throughput and\nlatency performance compared to legacy Wi-Fi standards. MLO enables\nsimultaneous transmission and reception through multiple links, departing from\nconventional single-link operations (SLO). To fully exploit MLO's potential, it\nis essential to investigate Wi-Fi 7's coexistence performance with legacy Wi-Fi\ndevices. Existing approaches, however, have overlooked some crucial aspects of\nMLO, necessitating the development of a standards-compliant analytical\nframework to model the actual channel access mechanism of MLO. Therefore, this\npaper tries to fill the gap by proposing a set of novel Markov chains (MC) to\naccurately model the MLO operation aligned with multi-link backoff behaviors\nspecified by the standard. Specifically, we design two separate MCs for AP and\nnon-AP multi-link devices (MLD) respectively, based on which transmit and\ncollision probabilities are derived under the saturated traffic condition.\nThen, we also derive closed-form expressions for the throughput of various\ndevice types in the coexistence scenario between Wi-Fi 7 and legacy Wi-Fi,\nincluding AP MLD, non- AP MLD, and legacy devices. To validate the accuracy of\nour proposed models, we developed an ns-3 based simulator by implementing both\nSTR(simultaneous transmission and reception) and NSTR(non-STR) based MLO\noperations. Our ns-3 based extensive simulations have demonstrated that the\nproposed analytic model provides accurate estimates on the per device\nthroughput performance, while also revealing the dynamics of inter-WLAN\ncoexistence scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Wi-Fi 7\u7684\u591a\u94fe\u8def\u64cd\u4f5c\uff08MLO\uff09\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMarkov\u94fe\u7684\u6a21\u578b\u6765\u5206\u6790\u5176\u5171\u5b58\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "Wi-Fi 7\u7684MLO\u6280\u672f\u867d\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u4e0e\u65e7\u7248Wi-Fi\u8bbe\u5907\u7684\u5171\u5b58\u6027\u80fd\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u5f00\u53d1\u6807\u51c6\u5316\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eMarkov\u94fe\u7684\u6a21\u578b\uff0c\u5206\u522b\u9488\u5bf9AP\u548c\u975eAP\u591a\u94fe\u8def\u8bbe\u5907\uff08MLD\uff09\uff0c\u63a8\u5bfc\u4e86\u4f20\u8f93\u548c\u78b0\u649e\u6982\u7387\uff0c\u5e76\u5f00\u53d1\u4e86ns-3\u4eff\u771f\u5668\u9a8c\u8bc1\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u9971\u548c\u6d41\u91cf\u6761\u4ef6\u4e0b\u51c6\u786e\u9884\u6d4b\u4e86\u8bbe\u5907\u541e\u5410\u91cf\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u8bbe\u5907\u7c7b\u578b\uff08AP MLD\u3001\u975eAP MLD\u3001\u65e7\u7248\u8bbe\u5907\uff09\u7684\u5171\u5b58\u52a8\u6001\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u6790\u6a21\u578b\u80fd\u6709\u6548\u8bc4\u4f30Wi-Fi 7 MLO\u4e0e\u65e7\u7248Wi-Fi\u7684\u5171\u5b58\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2509.01414", "pdf": "https://arxiv.org/pdf/2509.01414", "abs": "https://arxiv.org/abs/2509.01414", "authors": ["Yutong Lin", "Suyuan Liu", "Kaiwen Guo", "Haohua Du", "Chao Liu", "Xiang-Yang Li"], "title": "AttenTrack: Mobile User Attention Awareness Based on Context and External Distractions", "categories": ["cs.HC"], "comment": null, "summary": "In the mobile internet era, managing limited attention amid information\noverload is crucial for enhancing collaboration and information delivery.\nHowever, current attention-aware systems often depend on wearables or\npersonalized data, limiting their scalability and cross-context adaptability.\nInspired by psychological theories, we attempt to treat mobile notifications as\nnaturally occurring external distractions and infer users' attention states\nbased on their response behaviors and contextual information. Our goal is to\nbuild an attention-aware model that does not rely on personalized historical\ndata or complex subjective input, while ensuring strong cold-start capability\nand cross-context adaptability. To this end, We design a field study framework\nintegrating subjective and objective data, closely aligned with real-world\nexternal distractions (i.e., mobile notifications). Through field studies, we\nconstruct a fine-grained and interpretable dataset centered on the relationship\namong current context - external distractions - subjective attention. Through\nour field studies, we conduct an in-depth analysis of the relationships among\nusers' response behaviors, response motivations, contextual information, and\nattention states. Building on our findings, we propose AttenTrack, a\nlightweight, privacy-friendly attention awareness model with strong cold-start\ncapability. The model relies solely on non-privacy-sensitive objective data\navailable on mobile devices, and can be applied to a variety of attention\nmanagement tasks. In addition, we will publicly release the constructed dataset\nto support future research and advance the field of mobile attention awareness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAttenTrack\u7684\u8f7b\u91cf\u7ea7\u6ce8\u610f\u529b\u611f\u77e5\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790\u7528\u6237\u7684\u54cd\u5e94\u884c\u4e3a\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u63a8\u65ad\u6ce8\u610f\u529b\u72b6\u6001\uff0c\u65e0\u9700\u4f9d\u8d56\u4e2a\u6027\u5316\u5386\u53f2\u6570\u636e\u6216\u590d\u6742\u4e3b\u89c2\u8f93\u5165\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u51b7\u542f\u52a8\u80fd\u529b\u548c\u8de8\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u53ef\u7a7f\u6234\u8bbe\u5907\u6216\u4e2a\u6027\u5316\u6570\u636e\u7684\u6ce8\u610f\u529b\u611f\u77e5\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u548c\u8de8\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u6709\u9650\uff0c\u8bba\u6587\u8bd5\u56fe\u901a\u8fc7\u5fc3\u7406\u5b66\u7406\u8bba\uff0c\u5c06\u79fb\u52a8\u901a\u77e5\u89c6\u4e3a\u81ea\u7136\u7684\u5916\u90e8\u5e72\u6270\uff0c\u6784\u5efa\u4e0d\u4f9d\u8d56\u4e2a\u6027\u5316\u6570\u636e\u7684\u6ce8\u610f\u529b\u611f\u77e5\u6a21\u578b\u3002", "method": "\u8bbe\u8ba1\u4e86\u7ed3\u5408\u4e3b\u89c2\u548c\u5ba2\u89c2\u6570\u636e\u7684\u73b0\u573a\u7814\u7a76\u6846\u67b6\uff0c\u56f4\u7ed5\u5f53\u524d\u4e0a\u4e0b\u6587-\u5916\u90e8\u5e72\u6270-\u4e3b\u89c2\u6ce8\u610f\u529b\u7684\u5173\u7cfb\u6784\u5efa\u7ec6\u7c92\u5ea6\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u975e\u9690\u79c1\u654f\u611f\u6570\u636e\u7684AttenTrack\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u73b0\u573a\u7814\u7a76\u6df1\u5165\u5206\u6790\u7528\u6237\u54cd\u5e94\u884c\u4e3a\u3001\u52a8\u673a\u3001\u4e0a\u4e0b\u6587\u548c\u6ce8\u610f\u529b\u72b6\u6001\u7684\u5173\u7cfb\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u51b7\u542f\u52a8\u80fd\u529b\u548c\u9002\u7528\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684AttenTrack\u6a21\u578b\u5177\u6709\u8f7b\u91cf\u3001\u9690\u79c1\u53cb\u597d\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u5e76\u5c06\u516c\u5f00\u6570\u636e\u96c6\u4ee5\u63a8\u52a8\u79fb\u52a8\u6ce8\u610f\u529b\u611f\u77e5\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2509.01383", "pdf": "https://arxiv.org/pdf/2509.01383", "abs": "https://arxiv.org/abs/2509.01383", "authors": ["Long Zhang", "Peipei Song", "Jianfeng Dong", "Kun Li", "Xun Yang"], "title": "Enhancing Partially Relevant Video Retrieval with Robust Alignment Learning", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted at EMNLP 2025", "summary": "Partially Relevant Video Retrieval (PRVR) aims to retrieve untrimmed videos\npartially relevant to a given query. The core challenge lies in learning robust\nquery-video alignment against spurious semantic correlations arising from\ninherent data uncertainty: 1) query ambiguity, where the query incompletely\ncharacterizes the target video and often contains uninformative tokens, and 2)\npartial video relevance, where abundant query-irrelevant segments introduce\ncontextual noise in cross-modal alignment. Existing methods often focus on\nenhancing multi-scale clip representations and retrieving the most relevant\nclip. However, the inherent data uncertainty in PRVR renders them vulnerable to\ndistractor videos with spurious similarities, leading to suboptimal\nperformance. To fill this research gap, we propose Robust Alignment Learning\n(RAL) framework, which explicitly models the uncertainty in data. Key\ninnovations include: 1) we pioneer probabilistic modeling for PRVR by encoding\nvideos and queries as multivariate Gaussian distributions. This not only\nquantifies data uncertainty but also enables proxy-level matching to capture\nthe variability in cross-modal correspondences; 2) we consider the\nheterogeneous informativeness of query words and introduce learnable confidence\ngates to dynamically weight similarity. As a plug-and-play solution, RAL can be\nseamlessly integrated into the existing architectures. Extensive experiments\nacross diverse retrieval backbones demonstrate its effectiveness.", "AI": {"tldr": "RAL\u6846\u67b6\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u548c\u52a8\u6001\u6743\u91cd\u76f8\u4f3c\u6027\u6765\u89e3\u51b3PRVR\u4e2d\u7684\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "PRVR\u7684\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u5b66\u4e60\u9c81\u68d2\u7684\u67e5\u8be2-\u89c6\u9891\u5bf9\u9f50\uff0c\u4ee5\u907f\u514d\u7531\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u5f15\u8d77\u7684\u865a\u5047\u8bed\u4e49\u76f8\u5173\u6027\u3002", "method": "RAL\u6846\u67b6\u91c7\u7528\u591a\u5143\u9ad8\u65af\u5206\u5e03\u7f16\u7801\u89c6\u9891\u548c\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7f6e\u4fe1\u95e8\u52a8\u6001\u52a0\u6743\u76f8\u4f3c\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRAL\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u591a\u79cd\u68c0\u7d22\u67b6\u6784\u7684\u6027\u80fd\u3002", "conclusion": "RAL\u4f5c\u4e3a\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347PRVR\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2509.01928", "pdf": "https://arxiv.org/pdf/2509.01928", "abs": "https://arxiv.org/abs/2509.01928", "authors": ["Debraj Banerjee", "Santanu Mahapatra", "Kunal Narayan Chaudhury"], "title": "A Continuous Energy Ising Machine Leveraging Difference-of-Convex Programming", "categories": ["cs.DC", "math-ph", "math.MP", "math.OC", "quant-ph", "90C26, 90C59, 82B20, 68W40, 65K10, 82C32"], "comment": "41 pages, 24 figures, journal paper", "summary": "Many combinatorial optimization problems can be reformulated as the task of\nfinding the ground state of a physical system, such as the Ising model. Most\nexisting Ising solvers are inspired by simulated annealing. Although annealing\ntechniques offer scalability, they lack convergence guarantees and are\nsensitive to the cooling schedule. We propose to solve the Ising problem by\nrelaxing the binary spins to continuous variables and introducing a potential\nfunction (attractor) that steers the solution toward binary spin\nconfigurations. The resulting Hamiltonian can be expressed as a difference of\nconvex functions, enabling the design of efficient iterative algorithms that\nrequire a single matrix-vector multiplication per iteration and are backed by\nconvergence guarantees. We implement our Ising solver across a range of GPU\nplatforms: from edge devices to high-performance computing clusters and\ndemonstrate that it consistently outperforms existing solvers across problem\nsizes ranging from small ($10^3$ spins) to ultra-large ($10^8$ spins).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f0a\u8f9b\u95ee\u9898\u6c42\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4e8c\u5143\u81ea\u65cb\u677e\u5f1b\u4e3a\u8fde\u7eed\u53d8\u91cf\u5e76\u5f15\u5165\u52bf\u51fd\u6570\uff0c\u8bbe\u8ba1\u51fa\u9ad8\u6548\u4e14\u5177\u6709\u6536\u655b\u4fdd\u8bc1\u7684\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u4f0a\u8f9b\u6c42\u89e3\u5668\uff08\u5982\u6a21\u62df\u9000\u706b\u6cd5\uff09\u7f3a\u4e4f\u6536\u655b\u4fdd\u8bc1\u4e14\u5bf9\u51b7\u5374\u8ba1\u5212\u654f\u611f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u5c06\u4e8c\u5143\u81ea\u65cb\u677e\u5f1b\u4e3a\u8fde\u7eed\u53d8\u91cf\uff0c\u5f15\u5165\u52bf\u51fd\u6570\u5f15\u5bfc\u89e3\u5411\u4e8c\u5143\u81ea\u65cb\u914d\u7f6e\uff0c\u5229\u7528\u51f8\u5dee\u51fd\u6570\u8bbe\u8ba1\u9ad8\u6548\u8fed\u4ee3\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u79cdGPU\u5e73\u53f0\u4e0a\u5b9e\u73b0\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6c42\u89e3\u5668\uff0c\u9002\u7528\u4e8e\u5c0f\u89c4\u6a21\uff0810^3\u81ea\u65cb\uff09\u5230\u8d85\u5927\u89c4\u6a21\uff0810^8\u81ea\u65cb\uff09\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u5177\u6709\u6536\u655b\u4fdd\u8bc1\u7684\u4f0a\u8f9b\u95ee\u9898\u6c42\u89e3\u65b9\u6848\u3002"}}
{"id": "2509.01966", "pdf": "https://arxiv.org/pdf/2509.01966", "abs": "https://arxiv.org/abs/2509.01966", "authors": ["Soon Hwang", "Junhyeok Park", "Junghyun Ryu", "Seonghoon Ahn", "Jeoungahn Park", "Jeongjin Lee", "Soonyeal Yang", "Jungki Noh", "Woosuk Chung", "Hoshik Kim", "Youngjae Kim"], "title": "OASIS: Object-based Analytics Storage for Intelligent SQL Query Offloading in Scientific Tabular Workloads", "categories": ["cs.DB", "cs.DC"], "comment": "12 Pages, 10 Figures", "summary": "Computation-Enabled Object Storage (COS) systems, such as MinIO and Ceph,\nhave recently emerged as promising storage solutions for post hoc, SQL-based\nanalysis on large-scale datasets in High-Performance Computing (HPC)\nenvironments. By supporting object-granular layouts, COS facilitates\ncolumn-oriented access and supports in-storage execution of data reduction\noperators, such as filters, close to where the data resides. Despite growing\ninterest and adoption, existing COS systems exhibit several fundamental\nlimitations that hinder their effectiveness. First, they impose rigid\nconstraints on output data formats, limiting flexibility and interoperability.\nSecond, they support offloading for only a narrow set of operators and\nexpressions, restricting their applicability to more complex analytical tasks.\nThird--and perhaps most critically--they fail to incorporate design strategies\nthat enable compute offloading optimized for the characteristics of deep\nstorage hierarchies. To address these challenges, this paper proposes OASIS, a\nnovel COS system that features: (i) flexible and interoperable output delivery\nthrough diverse formats, including columnar layouts such as Arrow; (ii) broad\nsupport for complex operators (e.g., aggregate, sort) and array-aware\nexpressions, including element-wise predicates over array structures; and (iii)\ndynamic selection of optimal execution paths across internal storage layers,\nguided by operator characteristics and data movement costs. We implemented a\nprototype of OASIS and integrated it into the Spark analytics framework.\nThrough extensive evaluation using real-world scientific queries from HPC\nworkflows, OASIS achieves up to a 32.7% performance improvement over Spark\nconfigured with existing COS-based storage systems.", "AI": {"tldr": "OASIS\u662f\u4e00\u79cd\u65b0\u578bCOS\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709COS\u7cfb\u7edf\u5728\u8f93\u51fa\u683c\u5f0f\u3001\u64cd\u4f5c\u7b26\u652f\u6301\u548c\u5b58\u50a8\u5c42\u6b21\u4f18\u5316\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u73b0\u6709COS\u7cfb\u7edf\u5728\u7075\u6d3b\u6027\u3001\u64cd\u4f5c\u7b26\u652f\u6301\u548c\u5b58\u50a8\u5c42\u6b21\u4f18\u5316\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faOASIS\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u6837\u5316\u8f93\u51fa\u683c\u5f0f\u3001\u590d\u6742\u64cd\u4f5c\u7b26\u548c\u8868\u8fbe\u5f0f\uff0c\u5e76\u5728\u5b58\u50a8\u5c42\u6b21\u4e2d\u52a8\u6001\u9009\u62e9\u6700\u4f18\u6267\u884c\u8def\u5f84\u3002", "result": "\u5728HPC\u5de5\u4f5c\u6d41\u7684\u771f\u5b9e\u79d1\u5b66\u67e5\u8be2\u4e2d\uff0cOASIS\u6bd4\u73b0\u6709COS\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u8fbe32.7%\u3002", "conclusion": "OASIS\u901a\u8fc7\u7075\u6d3b\u6027\u548c\u4f18\u5316\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86COS\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2509.01294", "pdf": "https://arxiv.org/pdf/2509.01294", "abs": "https://arxiv.org/abs/2509.01294", "authors": ["Helge Spieker", "Nadjib Lazaar", "Arnaud Gotlieb", "Nassim Belmecheri"], "title": "Metamorphic Testing of Multimodal Human Trajectory Prediction", "categories": ["cs.SE", "cs.RO"], "comment": "Information and Software Technology", "summary": "Context: Predicting human trajectories is crucial for the safety and\nreliability of autonomous systems, such as automated vehicles and mobile\nrobots. However, rigorously testing the underlying multimodal Human Trajectory\nPrediction (HTP) models, which typically use multiple input sources (e.g.,\ntrajectory history and environment maps) and produce stochastic outputs\n(multiple possible future paths), presents significant challenges. The primary\ndifficulty lies in the absence of a definitive test oracle, as numerous future\ntrajectories might be plausible for any given scenario. Objectives: This\nresearch presents the application of Metamorphic Testing (MT) as a systematic\nmethodology for testing multimodal HTP systems. We address the oracle problem\nthrough metamorphic relations (MRs) adapted for the complexities and stochastic\nnature of HTP. Methods: We present five MRs, targeting transformations of both\nhistorical trajectory data and semantic segmentation maps used as an\nenvironmental context. These MRs encompass: 1) label-preserving geometric\ntransformations (mirroring, rotation, rescaling) applied to both trajectory and\nmap inputs, where outputs are expected to transform correspondingly. 2)\nMap-altering transformations (changing semantic class labels, introducing\nobstacles) with predictable changes in trajectory distributions. We propose\nprobabilistic violation criteria based on distance metrics between probability\ndistributions, such as the Wasserstein or Hellinger distance. Conclusion: This\nstudy introduces tool, a MT framework for the oracle-less testing of\nmultimodal, stochastic HTP systems. It allows for assessment of model\nrobustness against input transformations and contextual changes without\nreliance on ground-truth trajectories.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u6001\u6d4b\u8bd5\uff08MT\uff09\u7684\u7cfb\u7edf\u65b9\u6cd5\u6765\u6d4b\u8bd5\u591a\u6a21\u6001\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\uff08HTP\uff09\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u7f3a\u4e4f\u786e\u5b9a\u6027\u6d4b\u8bd5\u9884\u8a00\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u7684\u8f93\u5165\u591a\u6e90\u4e14\u8f93\u51fa\u968f\u673a\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u6d4b\u8bd5\u9884\u8a00\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e94\u79cd\u53d8\u6001\u5173\u7cfb\uff08MRs\uff09\uff0c\u5305\u62ec\u8f68\u8ff9\u548c\u5730\u56fe\u8f93\u5165\u7684\u6807\u7b7e\u4fdd\u7559\u51e0\u4f55\u53d8\u6362\uff08\u955c\u50cf\u3001\u65cb\u8f6c\u3001\u7f29\u653e\uff09\u4ee5\u53ca\u5730\u56fe\u4fee\u6539\u53d8\u6362\uff08\u6539\u53d8\u8bed\u4e49\u6807\u7b7e\u3001\u5f15\u5165\u969c\u788d\u7269\uff09\u3002", "result": "\u901a\u8fc7\u6982\u7387\u8fdd\u53cd\u6807\u51c6\uff08\u5982Wasserstein\u6216Hellinger\u8ddd\u79bb\uff09\u8bc4\u4f30\u6a21\u578b\u5bf9\u8f93\u5165\u53d8\u6362\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5MT\u6846\u67b6\u53ef\u5728\u65e0\u9700\u5730\u9762\u771f\u5b9e\u8f68\u8ff9\u7684\u60c5\u51b5\u4e0b\u6d4b\u8bd5\u591a\u6a21\u6001\u968f\u673aHTP\u7cfb\u7edf\uff0c\u8bc4\u4f30\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.00066", "pdf": "https://arxiv.org/pdf/2509.00066", "abs": "https://arxiv.org/abs/2509.00066", "authors": ["Chuanxiang Yang", "Yuanfeng Zhou", "Guangshun Wei", "Siyu Ren", "Yuan Liu", "Junhui Hou", "Wenping Wang"], "title": "T-MLP: Tailed Multi-Layer Perceptron for Level-of-Detail Signal Representation", "categories": ["cs.LG", "cs.GR", "eess.IV"], "comment": null, "summary": "Level-of-detail (LoD) representation is critical for efficiently modeling and\ntransmitting various types of signals, such as images and 3D shapes. In this\nwork, we present a novel neural architecture that supports LoD signal\nrepresentation. Our architecture is based on an elaborate modification of the\nwidely used Multi-Layer Perceptron (MLP), which inherently operates at a single\nscale and therefore lacks native support for LoD. Specifically, we introduce\nthe Tailed Multi-Layer Perceptron (T-MLP) that extends the MLP by attaching\nmultiple output branches, also called tails, to its hidden layers, enabling\ndirect supervision at multiple depths. Our loss formulation and training\nstrategy allow each hidden layer to effectively learn a target signal at a\nspecific LoD, thus enabling multi-scale modeling. Extensive experimental\nresults show that our T-MLP outperforms other neural LoD baselines across a\nvariety of signal representation tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784T-MLP\uff0c\u901a\u8fc7\u4e3aMLP\u6dfb\u52a0\u591a\u8f93\u51fa\u5206\u652f\uff08\u5c3e\u90e8\uff09\uff0c\u5b9e\u73b0\u4e86\u591a\u5c3a\u5ea6\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u53f7\u7684LOD\u8868\u793a\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u9ad8\u6548\u5efa\u6a21\u548c\u4f20\u8f93\u4fe1\u53f7\uff08\u5982\u56fe\u50cf\u548c3D\u5f62\u72b6\uff09\uff0c\u9700\u8981\u652f\u6301\u591a\u5c3a\u5ea6\uff08LoD\uff09\u7684\u8868\u793a\u65b9\u6cd5\u3002\u4f20\u7edfMLP\u56e0\u5355\u5c3a\u5ea6\u64cd\u4f5c\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u63d0\u51faT-MLP\u67b6\u6784\uff0c\u4e3aMLP\u9690\u85cf\u5c42\u6dfb\u52a0\u591a\u4e2a\u8f93\u51fa\u5206\u652f\uff0c\u901a\u8fc7\u76f4\u63a5\u76d1\u7763\u4e0d\u540c\u6df1\u5ea6\u5b9e\u73b0\u591a\u5c3a\u5ea6\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cT-MLP\u5728\u591a\u79cd\u4fe1\u53f7\u8868\u793a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u795e\u7ecf\u7f51\u7edcLoD\u57fa\u7ebf\u3002", "conclusion": "T-MLP\u901a\u8fc7\u591a\u5206\u652f\u8bbe\u8ba1\u6709\u6548\u5b9e\u73b0\u4e86\u4fe1\u53f7\u7684\u591a\u5c3a\u5ea6\u8868\u793a\uff0c\u4e3aLoD\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.01276", "pdf": "https://arxiv.org/pdf/2509.01276", "abs": "https://arxiv.org/abs/2509.01276", "authors": ["He Shiwen", "Dong Haolei", "Wang Liangpeng", "An Zhenyu"], "title": "A Real-time Data Collection Approach for 6G AI-native Networks", "categories": ["cs.NI"], "comment": null, "summary": "During the development of the Sixth Generation (6G) networks, the integration\nof Artificial Intelligence (AI) into network systems has become a focal point,\nleading to the concept of AI-native networks. High quality data is essential\nfor developing such networks. Although some studies have explored data\ncollection and analysis in 6G networks, significant challenges remain,\nparticularly in real-time data acquisition and processing. This paper proposes\na comprehensive data collection method that operates in parallel with bitstream\nprocessing for wireless communication networks. By deploying data probes, the\nsystem captures real-time network and system status data in software-defined\nwireless communication networks. Furthermore, a data support system is\nimplemented to integrate heterogeneous data and provide automatic support for\nAI model training and decision making. Finally, a 6G communication testbed\nusing OpenAirInterface5G and Open5GS is built on Kubernetes, as well as the\nsystem's functionality is demonstrated via a network traffic prediction case\nstudy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57286G\u7f51\u7edc\u4e2d\u5b9e\u65f6\u91c7\u96c6\u548c\u5904\u7406\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u90e8\u7f72\u6570\u636e\u63a2\u9488\u548c\u6784\u5efa\u6570\u636e\u652f\u6301\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u5b9e\u65f6\u6570\u636e\u83b7\u53d6\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u4e86\u7cfb\u7edf\u7684\u529f\u80fd\u3002", "motivation": "\u57286G\u7f51\u7edc\u4e2d\uff0cAI\u7684\u96c6\u6210\u9700\u8981\u9ad8\u8d28\u91cf\u6570\u636e\u652f\u6301\uff0c\u4f46\u5b9e\u65f6\u6570\u636e\u83b7\u53d6\u548c\u5904\u7406\u4ecd\u5b58\u5728\u6311\u6218\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u884c\u4e8e\u6bd4\u7279\u6d41\u5904\u7406\u7684\u7efc\u5408\u6570\u636e\u91c7\u96c6\u65b9\u6cd5\uff0c\u5e76\u90e8\u7f72\u6570\u636e\u63a2\u9488\u6355\u83b7\u5b9e\u65f6\u7f51\u7edc\u72b6\u6001\u6570\u636e\uff0c\u540c\u65f6\u6784\u5efa\u6570\u636e\u652f\u6301\u7cfb\u7edf\u96c6\u6210\u5f02\u6784\u6570\u636e\u3002", "result": "\u5728Kubernetes\u4e0a\u642d\u5efa\u4e866G\u901a\u4fe1\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u901a\u8fc7\u7f51\u7edc\u6d41\u91cf\u9884\u6d4b\u6848\u4f8b\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u529f\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aAI\u539f\u751f\u7f51\u7edc\u7684\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5b9e\u65f6\u6570\u636e\u652f\u6301\uff0c\u5c55\u73b0\u4e86\u5176\u57286G\u7f51\u7edc\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.01420", "pdf": "https://arxiv.org/pdf/2509.01420", "abs": "https://arxiv.org/abs/2509.01420", "authors": ["Evan G. Center", "Matti Pouke", "Alessandro Nardi", "Lukas Gehrke", "Klaus Gramann", "Timo Ojala", "Steven M. LaValle"], "title": "Body Ownership Affects the Processing of Sensorimotor Contingencies in Virtual Reality", "categories": ["cs.HC", "cs.MM"], "comment": "Dr. Center and Dr. Pouke contributed equally to this work", "summary": "Presence in virtual reality (VR), the subjective sense of \"being there\" in a\nvirtual environment, is notoriously difficult to measure.\nElectroencephalography (EEG) may offer a promising, unobtrusive means of\nassessing a user's momentary state of presence. Unlike traditional\nquestionnaires, EEG does not interrupt the experience or rely on users'\nretrospective self-reports, thereby avoiding interference with the very state\nit aims to capture. Previous research has attempted to quantify presence in\nvirtual environments using event-related potentials (ERPs). We contend,\nhowever, that previous efforts have fallen short of fully realizing this goal,\nfailing to either A) independently manipulate presence, B) validate their\nmeasure of presence against traditional techniques, C) adequately separate the\nconstructs of presence and attention, and/or D) implement a realistic and\nimmersive environment and task. We address these shortcomings in a\npreregistered ERP experiment in which participants play an engaging target\nshooting game in VR. ERPs are time-locked to the release of a ball from a\nsling. We induce breaks in presence (BIPs) by freezing the ball's release on a\nminority of trials. Embodiment is manipulated by allowing manual manipulation\nof the sling with a realistic avatar in one condition (embodied condition) and\npassive manipulation with only controllers in another (non-embodied condition).\nWe support our predictions that the N2, the P3b, and the N400, are selectively\nsensitive towards specific components of these manipulations. The pattern of\nfindings carries significant implications for theories of presence, which have\nbeen seldom addressed in previous ERP investigations on this topic.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.02186", "pdf": "https://arxiv.org/pdf/2509.02186", "abs": "https://arxiv.org/abs/2509.02186", "authors": ["Phani Sahasra Akkinepally", "Manaswini Piduguralla", "Sushant Joshi", "Sathya Peri", "Sandeep Kulkarni"], "title": "Fault-Tolerant Decentralized Distributed Asynchronous Federated Learning with Adaptive Termination Detection", "categories": ["cs.DC"], "comment": null, "summary": "Federated Learning (FL) facilitates collaborative model training across\ndistributed clients while ensuring data privacy. Traditionally, FL relies on a\ncentralized server to coordinate learning, which creates bottlenecks and a\nsingle point of failure. Decentralized FL architectures eliminate the need for\na central server and can operate in either synchronous or asynchronous modes.\nSynchronous FL requires all clients to compute updates and wait for one another\nbefore aggregation, guaranteeing consistency but often suffering from delays\ndue to slower participants. Asynchronous FL addresses this by allowing clients\nto update independently, offering better scalability and responsiveness in\nheterogeneous environments.\n  Our research develops an asynchronous decentralized FL approach in two\nprogressive phases. (a) In Phase 1, we develop an asynchronous FL framework\nthat enables clients to learn and update independently, removing the need for\nstrict synchronization. (b) In Phase 2, we extend this framework with fault\ntolerance mechanisms to handle client failures and message drops, ensuring\nrobust performance even under unpredictable conditions. As a central\ncontribution, we propose Client-Confident Convergence and Client-Responsive\nTermination novel techniques that provide each client with the ability to\nautonomously determine appropriate termination points. These methods ensure\nthat all active clients conclude meaningfully and efficiently, maintaining\nreliable convergence despite the challenges of asynchronous communication and\nfaults.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5f02\u6b65\u53bb\u4e2d\u5fc3\u5316\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\u5141\u8bb8\u5ba2\u6237\u7aef\u72ec\u7acb\u5b66\u4e60\u548c\u66f4\u65b0\uff1b\u5176\u6b21\u5f15\u5165\u5bb9\u9519\u673a\u5236\uff0c\u786e\u4fdd\u5728\u4e0d\u53ef\u9884\u6d4b\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u4f9d\u8d56\u4e2d\u5fc3\u5316\u670d\u52a1\u5668\uff0c\u53ef\u80fd\u4ea7\u751f\u74f6\u9888\u548c\u5355\u70b9\u6545\u969c\uff1b\u800c\u53bb\u4e2d\u5fc3\u5316\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u80fd\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u54cd\u5e94\u6027\u3002", "method": "\u5206\u4e24\u4e2a\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5f00\u53d1\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u5bb9\u9519\u673a\u5236\u548c\u81ea\u4e3b\u7ec8\u6b62\u6280\u672f\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u786e\u4fdd\u4e86\u5ba2\u6237\u7aef\u7684\u9ad8\u6548\u7ec8\u6b62\u548c\u53ef\u9760\u6536\u655b\uff0c\u9002\u5e94\u5f02\u6b65\u901a\u4fe1\u548c\u6545\u969c\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5f02\u6784\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.02106", "pdf": "https://arxiv.org/pdf/2509.02106", "abs": "https://arxiv.org/abs/2509.02106", "authors": ["Feng Yao", "Xiaokang Yang", "Shufeng Gong", "Song Yu", "Yanfeng Zhang", "Ge Yu"], "title": "GeoLayer: Towards Low-Latency and Cost-Efficient Geo-Distributed Graph Stores with Layered Graph", "categories": ["cs.DB"], "comment": null, "summary": "The inherent connectivity and dependency of graph-structured data, combined\nwith its unique topology-driven access patterns, pose fundamental challenges to\nconventional data replication and request routing strategies in geo-distributed\ncloud storage systems. In this paper, we propose GeoLayer, a geo-distributed\ngraph storage framework that jointly optimizes graph replica placement and\npattern request routing. We first construct a latency-aware layered graph\narchitecture that decomposes the graph topology into multiple layers, aiming to\nreduce the decision space and computational complexity of the optimization\nproblem, while mitigating the impact of network heterogeneity in\ngeo-distributed environments. Building on the layered graph, we introduce an\noverlap-centric replica placement scheme to accommodate the diversity of graph\npattern accesses, along with a directed heat diffusion model that captures heat\nconduction and superposition effects to guide data allocation. For request\nrouting, we develop a stepwise layered routing strategy that performs\nprogressive expansion over the layered graph to efficiently retrieve the\nrequired data. Experimental results show that, compared to state-of-the-art\nreplica placement and routing schemes, GeoLayer achieves a 1.34x - 3.67x\nimprovement in response times for online graph pattern requests and a 1.28x -\n3.56x speedup in offline graph analysis performance.", "AI": {"tldr": "GeoLayer\u662f\u4e00\u4e2a\u5730\u7406\u5206\u5e03\u5f0f\u56fe\u5b58\u50a8\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u56fe\u67b6\u6784\u548c\u91cd\u53e0\u4e2d\u5fc3\u526f\u672c\u653e\u7f6e\u4f18\u5316\u56fe\u5f62\u526f\u672c\u653e\u7f6e\u548c\u8bf7\u6c42\u8def\u7531\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u54cd\u5e94\u65f6\u95f4\u548c\u5206\u6790\u6027\u80fd\u3002", "motivation": "\u56fe\u6570\u636e\u7684\u56fa\u6709\u8fde\u901a\u6027\u548c\u4f9d\u8d56\u6027\u4ee5\u53ca\u5176\u72ec\u7279\u7684\u62d3\u6251\u9a71\u52a8\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4f7f\u5f97\u4f20\u7edf\u7684\u590d\u5236\u548c\u8bf7\u6c42\u8def\u7531\u7b56\u7565\u5728\u5730\u7406\u5206\u5e03\u5f0f\u4e91\u5b58\u50a8\u7cfb\u7edf\u4e2d\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u56fe\u67b6\u6784\u4ee5\u51cf\u5c11\u4f18\u5316\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u5f15\u5165\u91cd\u53e0\u4e2d\u5fc3\u526f\u672c\u653e\u7f6e\u65b9\u6848\u548c\u5b9a\u5411\u70ed\u6269\u6563\u6a21\u578b\u6307\u5bfc\u6570\u636e\u5206\u914d\uff0c\u5f00\u53d1\u9010\u6b65\u5206\u5c42\u8def\u7531\u7b56\u7565\u9ad8\u6548\u68c0\u7d22\u6570\u636e\u3002", "result": "\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0cGeoLayer\u4f7f\u5728\u7ebf\u56fe\u5f62\u6a21\u5f0f\u8bf7\u6c42\u7684\u54cd\u5e94\u65f6\u95f4\u63d0\u9ad8\u4e861.34x - 3.67x\uff0c\u79bb\u7ebf\u56fe\u5f62\u5206\u6790\u6027\u80fd\u63d0\u9ad8\u4e861.28x - 3.56x\u3002", "conclusion": "GeoLayer\u901a\u8fc7\u8054\u5408\u4f18\u5316\u526f\u672c\u653e\u7f6e\u548c\u8bf7\u6c42\u8def\u7531\uff0c\u6709\u6548\u5e94\u5bf9\u4e86\u5730\u7406\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u56fe\u6570\u636e\u5b58\u50a8\u548c\u8bbf\u95ee\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2509.01313", "pdf": "https://arxiv.org/pdf/2509.01313", "abs": "https://arxiv.org/abs/2509.01313", "authors": ["Zhao Tian", "Junjie Chen"], "title": "Aligning Requirement for Large Language Model's Code Generation", "categories": ["cs.SE"], "comment": "Accepted by ICSE 2026", "summary": "Code generation refers to the automatic generation of source code based on a\ngiven programming specification, which has garnered significant attention\nparticularly with the advancement of large language models (LLMs). However, due\nto the inherent complexity of real-world problems, the LLM-generated code often\nfails to fully align with the provided specification. While state-of-the-art\nagent-based techniques have been proposed to enhance LLM code generation, they\noverlook the critical issue of specification perception, resulting in\npersistent misalignment issues. Given that accurate perception of programming\nspecifications serves as the foundation of the LLM-based code generation\nparadigm, ensuring specification alignment is particularly crucial. In this\nwork, we draw on software requirements engineering to propose Specine, a novel\nspecification alignment technique for LLM code generation. Its key idea is to\nidentify misaligned input specifications, lift LLM-perceived specifications,\nand align them to enhance the code generation performance of LLMs. Our\ncomprehensive experiments on four state-of-the-art LLMs across five challenging\ncompetitive benchmarks by comparing with ten state-of-the-art baselines,\ndemonstrate the effectiveness of Specine. For example, Specine outperforms the\nmost effective baseline, achieving an average improvement of 29.60\\% across all\nsubjects in terms of Pass@1.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpecine\u7684\u6280\u672f\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5bf9\u8f93\u5165\u89c4\u8303\u611f\u77e5\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u751f\u6210\u4ee3\u7801\u4e0e\u89c4\u8303\u7684\u5339\u914d\u5ea6\u3002", "motivation": "\u7531\u4e8e\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u7684\u590d\u6742\u6027\uff0cLLM\u751f\u6210\u7684\u4ee3\u7801\u5f80\u5f80\u65e0\u6cd5\u5b8c\u5168\u7b26\u5408\u7ed9\u5b9a\u7684\u7f16\u7a0b\u89c4\u8303\uff0c\u800c\u73b0\u6709\u6280\u672f\u5ffd\u89c6\u4e86\u89c4\u8303\u611f\u77e5\u8fd9\u4e00\u5173\u952e\u95ee\u9898\u3002", "method": "\u8bba\u6587\u501f\u9274\u8f6f\u4ef6\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\uff0c\u63d0\u51faSpecine\u6280\u672f\uff0c\u901a\u8fc7\u8bc6\u522b\u672a\u5bf9\u9f50\u7684\u8f93\u5165\u89c4\u8303\u3001\u63d0\u53d6LLM\u611f\u77e5\u7684\u89c4\u8303\u5e76\u8fdb\u884c\u5bf9\u9f50\uff0c\u4ee5\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "result": "\u5728\u56db\u4e2a\u5148\u8fdbLLM\u548c\u4e94\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSpecine\u7684\u5e73\u5747Pass@1\u6027\u80fd\u63d0\u5347\u4e8629.60%\uff0c\u4f18\u4e8e\u5341\u79cd\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Specine\u901a\u8fc7\u6539\u8fdb\u89c4\u8303\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u89c4\u8303\u611f\u77e5\u4e0d\u8db3\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00114", "pdf": "https://arxiv.org/pdf/2509.00114", "abs": "https://arxiv.org/abs/2509.00114", "authors": ["Johan Malmstedt", "Giacomo Nanni", "Dario Rodighiero"], "title": "The Living Library of Trees: Mapping Knowledge Ecology in the Arnold Arboretum", "categories": ["cs.CY", "cs.GR"], "comment": null, "summary": "As biodiversity loss and climate change accelerate, botanical gardens serve\nas vital infrastructures for research, education, and conservation. This\nproject focuses on the Arnold Arboretum of Harvard University, a 281-acre\nliving museum founded in 1872 in Boston. Drawing on more than a century of\ncuratorial data, the research combines historical analysis with computational\nmethods to visualize the biographies of plants and people. The resulting\nplatform reveals patterns of care and scientific observations, along with the\ncollective dimensions embedded in botanical data. Using techniques from\nartificial intelligence, geospatial mapping, and information design, the\nproject frames the arboretum as a system of shared agency--an active archive of\nmore-than-human affinities that records the layered memory of curatorial labor,\nthe situated nature of knowledge production, and the potential of design to\nbridge archival record and future care.", "AI": {"tldr": "\u672c\u9879\u76ee\u63a2\u8ba8\u54c8\u4f5b\u5927\u5b66\u963f\u8bfa\u5fb7\u690d\u7269\u56ed\u5728\u751f\u7269\u591a\u6837\u6027\u4e0e\u6c14\u5019\u53d8\u5316\u80cc\u666f\u4e0b\u7684\u7814\u7a76\u4ef7\u503c\uff0c\u7ed3\u5408\u5386\u53f2\u6570\u636e\u4e0e\u8ba1\u7b97\u65b9\u6cd5\uff0c\u63ed\u793a\u690d\u7269\u4e0e\u4eba\u4e4b\u95f4\u7684\u4f20\u8bb0\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5c55\u793a\u690d\u7269\u56ed\u4f5c\u4e3a\u57fa\u7840\u8bbe\u65bd\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u901a\u8fc7\u6570\u636e\u53ef\u89c6\u5316\u63a2\u7d22\u690d\u7269\u4e0e\u4eba\u7c7b\u6d3b\u52a8\u7684\u591a\u7ef4\u5ea6\u8054\u7cfb\u3002", "method": "\u7ed3\u5408\u5386\u53f2\u5206\u6790\u4e0e\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8fd0\u7528\u4eba\u5de5\u667a\u80fd\u3001\u5730\u7406\u7a7a\u95f4\u7ed8\u56fe\u4e0e\u4fe1\u606f\u8bbe\u8ba1\u6280\u672f\uff0c\u5206\u6790\u690d\u7269\u56ed\u6570\u636e\u3002", "result": "\u6784\u5efa\u7684\u5e73\u53f0\u63ed\u793a\u4e86\u690d\u7269\u62a4\u7406\u4e0e\u79d1\u5b66\u89c2\u5bdf\u7684\u6a21\u5f0f\uff0c\u4ee5\u53ca\u690d\u7269\u6570\u636e\u4e2d\u7684\u96c6\u4f53\u7ef4\u5ea6\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u690d\u7269\u56ed\u662f\u4e00\u4e2a\u5171\u4eab\u4ee3\u7406\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u8bbe\u8ba1\u5728\u8fde\u63a5\u6863\u6848\u8bb0\u5f55\u4e0e\u672a\u6765\u62a4\u7406\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.01427", "pdf": "https://arxiv.org/pdf/2509.01427", "abs": "https://arxiv.org/abs/2509.01427", "authors": ["Zifan Lang", "Guixia Liu", "Jiahui Li", "Geng Sun", "Zemin Sun", "Jiacheng Wang", "Dusit Niyato", "Victor C. M. Leung"], "title": "Multi-AAV-enabled Distributed Beamforming in Low-Altitude Wireless Networking for AoI-Sensitive IoT Data Forwarding", "categories": ["cs.NI"], "comment": null, "summary": "With the rapid development of low-altitude wireless networking, autonomous\naerial vehicles (AAVs) have emerged as critical enablers for timely and\nreliable data delivery, particularly in remote or underserved areas. In this\ncontext, the age of information (AoI) has emerged as a critical performance\nmetric for evaluating the freshness and timeliness of transmitted information\nin Internet of things (IoT) networks. However, conventional AAV-assisted data\ntransmission is fundamentally limited by finite communication coverage ranges,\nwhich requires periodic return flights for data relay operations. This\npropulsion-repositioning cycle inevitably introduces latency spikes that raise\nthe AoI while degrading service reliability. To address these challenges, this\npaper proposes a AAV-assisted forwarding system based on distributed\nbeamforming to enhance the AoI in IoT. Specifically, AAVs collaborate via\ndistributed beamforming to collect and relay data between the sensor nodes and\nremote base station. Then, we formulate an optimization problem to minimize the\nAoI and AAV energy consumption, by jointly optimizing the AAV trajectories and\ncommunication schedules. Due to the non-convex nature of the problem and its\npronounced temporal variability, we introduce a deep reinforcement learning\nsolution that incorporates temporal sequence input, layer normalization gated\nrecurrent unit, and a squeeze-and-excitation block to capture long-term\ndependencies, thereby improving decision-making stability and accuracy, and\nreducing computational complexity. Simulation results demonstrate that the\nproposed SAC-TLS algorithm outperforms baseline algorithms in terms of\nconvergence, time average AoI, and energy consumption of AAVs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u5f0f\u6ce2\u675f\u6210\u5f62\u7684AAV\u8f85\u52a9\u8f6c\u53d1\u7cfb\u7edf\uff0c\u4ee5\u4f18\u5316\u7269\u8054\u7f51\u4e2d\u7684\u4fe1\u606f\u65f6\u6548\u6027\uff08AoI\uff09\u548cAAV\u80fd\u8017\u3002", "motivation": "\u4f20\u7edfAAV\u8f85\u52a9\u6570\u636e\u4f20\u8f93\u53d7\u9650\u4e8e\u901a\u4fe1\u8986\u76d6\u8303\u56f4\u548c\u5468\u671f\u6027\u8fd4\u7a0b\u98de\u884c\uff0c\u5bfc\u81f4AoI\u589e\u52a0\u548c\u670d\u52a1\u53ef\u9760\u6027\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u5206\u5e03\u5f0f\u6ce2\u675f\u6210\u5f62\u6280\u672f\u534f\u540cAAV\u6536\u96c6\u548c\u4e2d\u7ee7\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4f18\u5316AAV\u8f68\u8ff9\u548c\u901a\u4fe1\u8c03\u5ea6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684SAC-TLS\u7b97\u6cd5\u5728\u6536\u655b\u6027\u3001\u5e73\u5747AoI\u548cAAV\u80fd\u8017\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u4fe1\u606f\u65f6\u6548\u6027\u5e76\u964d\u4f4e\u4e86AAV\u80fd\u8017\uff0c\u9002\u7528\u4e8e\u7269\u8054\u7f51\u7f51\u7edc\u3002"}}
{"id": "2509.01460", "pdf": "https://arxiv.org/pdf/2509.01460", "abs": "https://arxiv.org/abs/2509.01460", "authors": ["Manuel Schmidt", "Daniel A. Keim", "Frederik L. Dennig"], "title": "Dissecting Atomic Facts: Visual Analytics for Improving Fact Annotations in Language Model Evaluation", "categories": ["cs.HC"], "comment": "2 pages text plus poster, 2 figures, LaTeX", "summary": "Factuality evaluation of large language model (LLM) outputs requires\ndecomposing text into discrete \"atomic\" facts. However, existing definitions of\natomicity are underspecified, with empirical results showing high disagreement\namong annotators, both human and model-based, due to unresolved ambiguity in\nfact decomposition. We present a visual analytics concept to expose and analyze\nannotation inconsistencies in fact extraction. By visualizing semantic\nalignment, granularity and referential dependencies, our approach aims to\nenable systematic inspection of extracted facts and facilitate convergence\nthrough guided revision loops, establishing a more stable foundation for\nfactuality evaluation benchmarks and improving LLM evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u66b4\u9732\u548c\u5206\u6790\u4e8b\u5b9e\u63d0\u53d6\u4e2d\u7684\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u65e8\u5728\u6539\u5584LLM\u7684\u4e8b\u5b9e\u6027\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u539f\u5b50\u4e8b\u5b9e\u5b9a\u4e49\u4e0d\u660e\u786e\uff0c\u5bfc\u81f4\u4eba\u5de5\u548c\u6a21\u578b\u6807\u6ce8\u8005\u4e4b\u95f4\u9ad8\u5206\u6b67\uff0c\u5f71\u54cdLLM\u4e8b\u5b9e\u6027\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u53ef\u89c6\u5316\u8bed\u4e49\u5bf9\u9f50\u3001\u7c92\u5ea6\u548c\u6307\u4ee3\u4f9d\u8d56\u6027\uff0c\u7cfb\u7edf\u6027\u68c0\u67e5\u63d0\u53d6\u7684\u4e8b\u5b9e\uff0c\u5e76\u901a\u8fc7\u5f15\u5bfc\u4fee\u8ba2\u5faa\u73af\u4fc3\u8fdb\u4e00\u81f4\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u7a33\u5b9a\u7684\u4e8b\u5b9e\u6027\u8bc4\u4f30\u57fa\u51c6\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u6539\u5584LLM\u7684\u4e8b\u5b9e\u6027\u8bc4\u4f30\u6548\u679c\u3002", "conclusion": "\u8be5\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\u80fd\u6709\u6548\u51cf\u5c11\u6807\u6ce8\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3aLLM\u4e8b\u5b9e\u6027\u8bc4\u4f30\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u57fa\u7840\u3002"}}
{"id": "2509.01439", "pdf": "https://arxiv.org/pdf/2509.01439", "abs": "https://arxiv.org/abs/2509.01439", "authors": ["Artur D\u00edaz-Juan", "Coloma Ballester", "Gloria Haro"], "title": "SoccerHigh: A Benchmark Dataset for Automatic Soccer Video Summarization", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted at MMSports 2025 (Dublin, Ireland)", "summary": "Video summarization aims to extract key shots from longer videos to produce\nconcise and informative summaries. One of its most common applications is in\nsports, where highlight reels capture the most important moments of a game,\nalong with notable reactions and specific contextual events. Automatic summary\ngeneration can support video editors in the sports media industry by reducing\nthe time and effort required to identify key segments. However, the lack of\npublicly available datasets poses a challenge in developing robust models for\nsports highlight generation. In this paper, we address this gap by introducing\na curated dataset for soccer video summarization, designed to serve as a\nbenchmark for the task. The dataset includes shot boundaries for 237 matches\nfrom the Spanish, French, and Italian leagues, using broadcast footage sourced\nfrom the SoccerNet dataset. Alongside the dataset, we propose a baseline model\nspecifically designed for this task, which achieves an F1 score of 0.3956 in\nthe test set. Furthermore, we propose a new metric constrained by the length of\neach target summary, enabling a more objective evaluation of the generated\ncontent. The dataset and code are available at\nhttps://ipcv.github.io/SoccerHigh/.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8db3\u7403\u89c6\u9891\u6458\u8981\u7684\u516c\u5f00\u6570\u636e\u96c6\u548c\u57fa\u7ebf\u6a21\u578b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u7684\u4e0d\u8db3\uff0c\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u4f53\u80b2\u89c6\u9891\u6458\u8981\u7684\u9c81\u68d2\u6a21\u578b\u9762\u4e34\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u4f9b237\u573a\u8db3\u7403\u6bd4\u8d5b\u7684\u955c\u5934\u8fb9\u754c\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u57fa\u7ebf\u6a21\u578b\u548c\u65b0\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u57fa\u7ebf\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0aF1\u5f97\u5206\u4e3a0.3956\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8db3\u7403\u89c6\u9891\u6458\u8981\u63d0\u4f9b\u4e86\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.02421", "pdf": "https://arxiv.org/pdf/2509.02421", "abs": "https://arxiv.org/abs/2509.02421", "authors": ["Ramesh Adhikari", "Costas Busch", "Dariusz R. Kowalski"], "title": "Near-Optimal Stability for Distributed Transaction Processing in Blockchain Sharding", "categories": ["cs.DC"], "comment": "13 pages, 1 figure, accepted for publication in Proceedings of the\n  27th International Symposium on Stabilization, Safety, and Security of\n  Distributed Systems (SSS 2025)", "summary": "In blockchain sharding, $n$ processing nodes are divided into $s$ shards, and\neach shard processes transactions in parallel. A key challenge in such a system\nis to ensure system stability for any ``tractable'' pattern of generated\ntransactions; this is modeled by an adversary generating transactions with a\ncertain rate of at most $\\rho$ and burstiness $b$. This model captures\nworst-case scenarios and even some attacks on transactions' processing, e.g.,\nDoS. A stable system ensures bounded transaction queue sizes and bounded\ntransaction latency. It is known that the absolute upper bound on the maximum\ninjection rate for which any scheduler could guarantee bounded queues and\nlatency of transactions is $\\max\\left\\{ \\frac{2}{k+1}, \\frac{2}{\n\\left\\lfloor\\sqrt{2s}\\right\\rfloor}\\right\\}$, where $k$ is the maximum number\nof shards that each transaction accesses. Here, we first provide a single\nleader scheduler that guarantees stability under injection rate $\\rho \\leq\n\\max\\left\\{ \\frac{1}{16k}, \\frac{1}{16\\lceil \\sqrt{s} \\rceil}\\right\\}$.\nMoreover, we also give a distributed scheduler with multiple leaders that\nguarantees stability under injection rate $\\rho \\leq \\frac{1}{16c_1 \\log D \\log\ns}\\max\\left\\{ \\frac{1}{k}, \\frac{1}{\\lceil \\sqrt{s} \\rceil} \\right\\}$, where\n$c_1$ is some positive constant and $D$ is the diameter of shard graph $G_s$.\nThis bound is within a poly-log factor from the optimal injection rate, and\nsignificantly improves the best previous known result for the distributed\nsetting by Adhikari et al., SPAA 2024.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u533a\u5757\u94fe\u5206\u7247\u7cfb\u7edf\u4e2d\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5355\u9886\u5bfc\u548c\u591a\u9886\u5bfc\u8c03\u5ea6\u5668\uff0c\u4ee5\u5728\u4e00\u5b9a\u4ea4\u6613\u6ce8\u5165\u7387\u4e0b\u4fdd\u8bc1\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "motivation": "\u786e\u4fdd\u533a\u5757\u94fe\u5206\u7247\u7cfb\u7edf\u5728\u4efb\u610f\u4ea4\u6613\u6a21\u5f0f\u4e0b\u4fdd\u6301\u7a33\u5b9a\u662f\u5173\u952e\u6311\u6218\uff0c\u5c24\u5176\u662f\u5bf9\u6297\u9ad8\u6ce8\u5165\u7387\u548c\u7a81\u53d1\u4ea4\u6613\u7684\u60c5\u51b5\u3002", "method": "\u8bbe\u8ba1\u4e86\u5355\u9886\u5bfc\u548c\u591a\u9886\u5bfc\u8c03\u5ea6\u5668\uff0c\u5206\u522b\u5728\u4e0d\u540c\u4ea4\u6613\u6ce8\u5165\u7387\u4e0b\u4fdd\u8bc1\u961f\u5217\u548c\u5ef6\u8fdf\u7684\u6709\u754c\u6027\u3002", "result": "\u5355\u9886\u5bfc\u8c03\u5ea6\u5668\u5728\u6ce8\u5165\u7387\u03c1\u22641/(16k)\u62161/(16\u2308\u221as\u2309)\u65f6\u7a33\u5b9a\uff0c\u591a\u9886\u5bfc\u8c03\u5ea6\u5668\u5728\u03c1\u22641/(16c\u2081logDlogs)max{1/k,1/\u2308\u221as\u2309}\u65f6\u7a33\u5b9a\u3002", "conclusion": "\u591a\u9886\u5bfc\u8c03\u5ea6\u5668\u7684\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\uff0c\u663e\u8457\u4f18\u4e8e\u5df2\u6709\u7ed3\u679c\uff0c\u4e3a\u5206\u5e03\u5f0f\u533a\u5757\u94fe\u5206\u7247\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7a33\u5b9a\u6027\u4fdd\u969c\u3002"}}
{"id": "2509.02121", "pdf": "https://arxiv.org/pdf/2509.02121", "abs": "https://arxiv.org/abs/2509.02121", "authors": ["Junyi Shen", "Noppanat Wadlom", "Yao Lu"], "title": "Batch Query Processing and Optimization for Agentic Workflows", "categories": ["cs.DB", "cs.DC"], "comment": null, "summary": "Large Language Models (LLMs) in agentic workflows combine multi-step\nreasoning, tool use, and collaboration across multiple specialized agents.\nExisting LLM serving engines optimize indi- vidual calls in isolation, while\nmulti-agent frameworks focus on orchestration without system-level performance\nplanning. As a result, repeated prompts, overlapping contexts, and concurrent\nex- ecutions create substantial redundancy and poor GPU utilization, especially\nin batch analytics scenarios. We introduce Halo, a system that brings batch\nquery processing and optimization into agentic LLM workflows. Halo represents\neach workflow as a structured query plan DAG and constructs a consoli- dated\ngraph for batched queries that exposes shared computation. Guided by a cost\nmodel that jointly considers prefill and decode costs, cache reuse, and GPU\nplacement, Halo performs plan-level op- timization to minimize redundant\nexecution. Its runtime integrates adaptive batching, KV-cache sharing and\nmigration, along with compute-communication overlap to maximize hardware\nefficiency. Evaluation across six benchmarks shows that Halo achieves up to\n18.6x speedup for batch inference and 4.7x throughput im- provement under\nonline serving, scaling to workloads of tens of thousands of queries and\ncomplex graphs. These gains are achieved without compromising output quality.\nBy unifying query optimiza- tion with LLM serving, Halo enables efficient\nagentic workflows in data analytics and decision-making applications.", "AI": {"tldr": "Halo\u7cfb\u7edf\u901a\u8fc7\u4f18\u5316\u6279\u5904\u7406\u67e5\u8be2\u548c\u8d44\u6e90\u5171\u4eab\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u4ee3\u7406LLM\u5de5\u4f5c\u6d41\u7684\u6267\u884c\u6548\u7387\u548c\u786c\u4ef6\u5229\u7528\u7387\u3002", "motivation": "\u73b0\u6709LLM\u670d\u52a1\u5f15\u64ce\u5728\u591a\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u5b58\u5728\u5197\u4f59\u6267\u884c\u548cGPU\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6279\u5904\u7406\u5206\u6790\u573a\u666f\u4e2d\u3002", "method": "Halo\u5c06\u5de5\u4f5c\u6d41\u8868\u793a\u4e3a\u7ed3\u6784\u5316\u67e5\u8be2\u8ba1\u5212DAG\uff0c\u901a\u8fc7\u6210\u672c\u6a21\u578b\u548c\u8fd0\u884c\u65f6\u4f18\u5316\u6280\u672f\uff08\u5982\u81ea\u9002\u5e94\u6279\u5904\u7406\u3001KV\u7f13\u5b58\u5171\u4eab\uff09\u51cf\u5c11\u5197\u4f59\u3002", "result": "Halo\u5728\u6279\u5904\u7406\u63a8\u7406\u548c\u5728\u7ebf\u670d\u52a1\u4e2d\u5206\u522b\u5b9e\u73b0\u4e8618.6x\u548c4.7x\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u4e0d\u5f71\u54cd\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "Halo\u901a\u8fc7\u7edf\u4e00\u67e5\u8be2\u4f18\u5316\u548cLLM\u670d\u52a1\uff0c\u4e3a\u6570\u636e\u5206\u6790\u548c\u51b3\u7b56\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u591a\u4ee3\u7406\u5de5\u4f5c\u6d41\u652f\u6301\u3002"}}
{"id": "2509.01318", "pdf": "https://arxiv.org/pdf/2509.01318", "abs": "https://arxiv.org/abs/2509.01318", "authors": ["Chiara Ghinami", "Jonas Winzer", "Nils Bosbach", "Lennart M. Reimann", "Lukas J\u00fcnger", "Simon W\u00f6rner", "Rainer Leupers"], "title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "categories": ["cs.SE"], "comment": null, "summary": "SystemC-based virtual prototypes have emerged as widely adopted tools to test\nsoftware ahead of hardware availability, reducing the time-to-market and\nimproving software reliability. Recently, fuzzing has become a popular method\nfor automated software testing due to its ability to quickly identify\ncorner-case errors. However, its application to embedded software is still\nlimited. Simulator tools can help bridge this gap by providing a more powerful\nand controlled execution environment for testing. Existing solutions, however,\noften tightly couple fuzzers with built-in simulators that lack support for\nhardware peripherals and of- fer limited flexibility, restricting their ability\nto test embedded software. To address these limitations, we present a framework\nthat allows the integration of American-Fuzzy-Lop-based fuzzers and\nSystemC-based simulators. The framework provides a harness to decouple the\nadopted fuzzer and simulator. In addition, it intercepts peripheral accesses\nand queries the fuzzer for values, effectively linking peripheral behavior to\nthe fuzzer. This solution enables flexible interchangeability of peripher- als\nwithin the simulation environment and supports the interfacing of different\nSystemC-based virtual prototypes. The flexibility of the pro- posed solution is\ndemonstrated by integrating the harness with different simulators and by\ntesting various softwares.", "AI": {"tldr": "SystemC\u865a\u62df\u539f\u578b\u548c\u6a21\u7cca\u6d4b\u8bd5\u7684\u7ed3\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u6d4b\u8bd5\u3002", "motivation": "\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u6a21\u7cca\u6d4b\u8bd5\u7684\u5e94\u7528\u53d7\u9650\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u5bf9\u5916\u8bbe\u7684\u652f\u6301\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u6846\u67b6\uff0c\u5c06AFL\u6a21\u7cca\u6d4b\u8bd5\u4e0eSystemC\u6a21\u62df\u5668\u89e3\u8026\uff0c\u62e6\u622a\u5916\u8bbe\u8bbf\u95ee\u5e76\u6a21\u7cca\u6d4b\u8bd5\u503c\u3002", "result": "\u6846\u67b6\u652f\u6301\u4e0d\u540c\u6a21\u62df\u5668\u548c\u865a\u62df\u539f\u578b\u7684\u7075\u6d3b\u96c6\u6210\uff0c\u6d4b\u8bd5\u4e86\u591a\u79cd\u8f6f\u4ef6\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u5347\u4e86\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2509.00674", "pdf": "https://arxiv.org/pdf/2509.00674", "abs": "https://arxiv.org/abs/2509.00674", "authors": ["Lingkai Meng", "Long Yuan", "Xuemin Lin", "Wenjie Zhang", "Ying Zhang"], "title": "Triangle Counting in Hypergraph Streams: A Complete and Practical Approach", "categories": ["cs.DS", "cs.GR"], "comment": null, "summary": "Triangle counting in hypergraph streams, including both hyper-vertex and\nhyper-edge triangles, is a fundamental problem in hypergraph analytics, with\nbroad applications. However, existing methods face two key limitations: (i) an\nincomplete classification of hyper-vertex triangle structures, typically\nconsidering only inner or outer triangles; and (ii) inflexible sampling schemes\nthat predefine the number of sampled hyperedges, which is impractical under\nstrict memory constraints due to highly variable hyperedge sizes. To address\nthese challenges, we first introduce a complete classification of hyper-vertex\ntriangles, including inner, hybrid, and outer triangles. Based on this, we\ndevelop HTCount, a reservoir-based algorithm that dynamically adjusts the\nsample size based on the available memory M. To further improve memory\nutilization and reduce estimation error, we develop HTCount-P, a\npartition-based variant that adaptively partitions unused memory into\nindependent sample subsets. We provide theoretical analysis of the unbiasedness\nand variance bounds of the proposed algorithms. Case studies demonstrate the\nexpressiveness of our triangle structures in revealing meaningful interaction\npatterns. Extensive experiments on real-world hypergraphs show that both our\nalgorithms achieve highly accurate triangle count estimates under strict memory\nconstraints, with relative errors that are 1 to 2 orders of magnitude lower\nthan those of existing methods and consistently high throughput.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d85\u56fe\u6d41\u4e2d\u4e09\u89d2\u5f62\u8ba1\u6570\u65b9\u6cd5HTCount\u548cHTCount-P\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8d85\u9876\u70b9\u4e09\u89d2\u5f62\u5206\u7c7b\u548c\u4e0d\u7075\u6d3b\u91c7\u6837\u65b9\u6848\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u5b58\u5229\u7528\u6548\u7387\u548c\u8ba1\u6570\u51c6\u786e\u6027\u3002", "motivation": "\u8d85\u56fe\u4e2d\u7684\u4e09\u89d2\u5f62\u8ba1\u6570\uff08\u5305\u62ec\u8d85\u9876\u70b9\u548c\u8d85\u8fb9\u4e09\u89d2\u5f62\uff09\u662f\u4e00\u4e2a\u57fa\u7840\u6027\u95ee\u9898\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8d85\u56fe\u5206\u6790\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8d85\u9876\u70b9\u4e09\u89d2\u5f62\u5206\u7c7b\u4e0d\u5b8c\u6574\u548c\u91c7\u6837\u65b9\u6848\u4e0d\u7075\u6d3b\u7684\u5c40\u9650\u6027\u3002", "method": "\u9996\u5148\u5b8c\u6574\u5206\u7c7b\u8d85\u9876\u70b9\u4e09\u89d2\u5f62\uff08\u5185\u3001\u6df7\u5408\u548c\u5916\u4e09\u89d2\u5f62\uff09\uff0c\u7136\u540e\u5f00\u53d1\u4e86\u57fa\u4e8e\u6c34\u5e93\u91c7\u6837\u7684HTCount\u7b97\u6cd5\uff0c\u52a8\u6001\u8c03\u6574\u6837\u672c\u5927\u5c0f\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faHTCount-P\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5206\u533a\u63d0\u9ad8\u5185\u5b58\u5229\u7528\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u7b97\u6cd5\u5728\u4e25\u683c\u5185\u5b58\u9650\u5236\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u4e09\u89d2\u5f62\u8ba1\u6570\uff0c\u76f8\u5bf9\u8bef\u5dee\u6bd4\u73b0\u6709\u65b9\u6cd5\u4f4e1-2\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e14\u4fdd\u6301\u4e86\u9ad8\u541e\u5410\u91cf\u3002", "conclusion": "HTCount\u548cHTCount-P\u5728\u5185\u5b58\u7ea6\u675f\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u4e09\u89d2\u5f62\u8ba1\u6570\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u6269\u5c55\u4e86\u8d85\u56fe\u5206\u6790\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2509.01694", "pdf": "https://arxiv.org/pdf/2509.01694", "abs": "https://arxiv.org/abs/2509.01694", "authors": ["Quang Minh Nguyen", "Eytan Modiano"], "title": "A QoS Framework for Service Provision in Multi-Infrastructure-Sharing Networks", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": "Accepted to ACM MobiHoc '25", "summary": "We propose a framework for resource provisioning with QoS guarantees in\nshared infrastructure networks. Our novel framework provides tunable\nprobabilistic service guarantees for throughput and delay. Key to our approach\nis a Modified Dirft-plus-Penalty (MDP) policy that ensures long-term stability\nwhile capturing short-term probabilistic service guarantees using linearized\nupper-confidence bounds. We characterize the feasible region of service\nguarantees and show that our MDP procedure achieves mean rate stability and an\noptimality gap that vanishes with the frame size over which service guarantees\nare provided. Finally, empirical simulations validate our theory and\ndemonstrate the favorable performance of our algorithm in handling QoS in\nmulti-infrastructure networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\u4e2d\u63d0\u4f9bQoS\u4fdd\u8bc1\u7684\u8d44\u6e90\u8c03\u914d\u6846\u67b6\uff0c\u4f7f\u7528\u6539\u8fdb\u7684Dirft-plus-Penalty (MDP)\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u957f\u671f\u7a33\u5b9a\u6027\u548c\u77ed\u671f\u7684\u6982\u7387\u6027\u670d\u52a1\u4fdd\u8bc1\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\u4e2d\u8d44\u6e90\u8c03\u914d\u7684QoS\u4fdd\u8bc1\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u65b9\u9762\u7684\u6982\u7387\u6027\u670d\u52a1\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684Dirft-plus-Penalty (MDP)\u7b56\u7565\uff0c\u7ed3\u5408\u7ebf\u6027\u5316\u7684\u4e0a\u7f6e\u4fe1\u754c\uff0c\u786e\u4fdd\u957f\u671f\u7a33\u5b9a\u6027\u548c\u77ed\u671f\u670d\u52a1\u4fdd\u8bc1\u3002", "result": "MDP\u7b56\u7565\u5b9e\u73b0\u4e86\u5e73\u5747\u901f\u7387\u7a33\u5b9a\u6027\u548c\u6700\u4f18\u6027\u5dee\u8ddd\uff0c\u4e14\u968f\u7740\u670d\u52a1\u4fdd\u8bc1\u7684\u65f6\u95f4\u5e27\u589e\u5927\u800c\u6d88\u5931\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u8bc1\u6a21\u62df\u9a8c\u8bc1\u4e86\u7406\u8bba\uff0c\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u591a\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\u4e2d\u5904\u7406QoS\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.01609", "pdf": "https://arxiv.org/pdf/2509.01609", "abs": "https://arxiv.org/abs/2509.01609", "authors": ["Yannick Weiss", "Marlene Eder", "Oguzhan Cesur", "Steeven Villa"], "title": "Quantifying the Effect of Thermal Illusions in Virtual Reality", "categories": ["cs.HC"], "comment": "10 pages, 4 figures", "summary": "Thermal sensations are central to how we experience the world, yet most\nvirtual and extended reality systems fail to simulate them effectively. While\nhardware-based thermal displays can provide accurate temperature changes, they\nare often bulky, power-intensive, and restrict user mobility. Consequently,\nrecent works have explored thermal illusions, perceptual effects that rely on\ncross-modal interactions, to achieve thermal experiences without physical\nheating or cooling. While thermal illusions have been shown to consistently\nalter subjective ratings, the actual extent of their effect on the perceived\ntemperature of interacted objects remains unexplored. To address this, we\ncontribute the findings of two user studies following psychophysical\nprocedures. We first ordered and scaled the effects of a variety of visual and\nauditory cues (N=20) and subsequently quantified their isolated and combined\nefficacy in offsetting physical temperature changes (N=24). We found that\nthermal illusions elicited robust changes in subjective judgments, and auditory\ncues showed potential as an alternative or complementary approach to\nestablished visual techniques. However, the actual effects induced by thermal\nillusions were relatively small (+-0.5{\\deg}C) and did not consistently align\nwith abstract ratings, suggesting a need to reconsider how future thermal\nillusions or experiences are designed and evaluated.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u70ed\u9519\u89c9\uff08\u901a\u8fc7\u89c6\u89c9\u548c\u542c\u89c9\u7ebf\u7d22\u6a21\u62df\u6e29\u5ea6\u611f\u77e5\uff09\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u5bf9\u4e3b\u89c2\u611f\u77e5\u6709\u660e\u663e\u5f71\u54cd\uff0c\u4f46\u5b9e\u9645\u6e29\u5ea6\u611f\u77e5\u53d8\u5316\u8f83\u5c0f\u3002", "motivation": "\u865a\u62df\u548c\u6269\u5c55\u73b0\u5b9e\u7cfb\u7edf\u96be\u4ee5\u6709\u6548\u6a21\u62df\u70ed\u611f\uff0c\u786c\u4ef6\u8bbe\u5907\u7b28\u91cd\u4e14\u9650\u5236\u7528\u6237\u6d3b\u52a8\uff0c\u56e0\u6b64\u63a2\u7d22\u70ed\u9519\u89c9\u4f5c\u4e3a\u4e00\u79cd\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u8fdb\u884c\u4e86\u4e24\u9879\u7528\u6237\u7814\u7a76\uff0c\u901a\u8fc7\u5fc3\u7406\u7269\u7406\u7a0b\u5e8f\u8bc4\u4f30\u89c6\u89c9\u548c\u542c\u89c9\u7ebf\u7d22\u5bf9\u6e29\u5ea6\u611f\u77e5\u7684\u5f71\u54cd\u3002", "result": "\u70ed\u9519\u89c9\u80fd\u663e\u8457\u6539\u53d8\u4e3b\u89c2\u8bc4\u4ef7\uff0c\u4f46\u5b9e\u9645\u6e29\u5ea6\u611f\u77e5\u53d8\u5316\u8f83\u5c0f\uff08\u7ea6\u00b10.5\u00b0C\uff09\uff0c\u4e14\u542c\u89c9\u7ebf\u7d22\u53ef\u4f5c\u4e3a\u89c6\u89c9\u6280\u672f\u7684\u8865\u5145\u3002", "conclusion": "\u672a\u6765\u70ed\u9519\u89c9\u8bbe\u8ba1\u9700\u91cd\u65b0\u8003\u8651\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u6a21\u62df\u6e29\u5ea6\u611f\u77e5\u3002"}}
{"id": "2509.02440", "pdf": "https://arxiv.org/pdf/2509.02440", "abs": "https://arxiv.org/abs/2509.02440", "authors": ["Marie Reinbigler", "Rishi Sharma", "Rafael Pires", "Elisabeth Brunet", "Anne-Marie Kermarrec", "Catalin Fetita"], "title": "Efficient Pyramidal Analysis of Gigapixel Images on a Decentralized Modest Computer Cluster", "categories": ["cs.DC", "cs.CV"], "comment": "Accepted at the 31st International European Conference on Parallel\n  and Distributed Computing (Euro-Par'25)", "summary": "Analyzing gigapixel images is recognized as computationally demanding. In\nthis paper, we introduce PyramidAI, a technique for analyzing gigapixel images\nwith reduced computational cost. The proposed approach adopts a gradual\nanalysis of the image, beginning with lower resolutions and progressively\nconcentrating on regions of interest for detailed examination at higher\nresolutions. We investigated two strategies for tuning the accuracy-computation\nperformance trade-off when implementing the adaptive resolution selection,\nvalidated against the Camelyon16 dataset of biomedical images. Our results\ndemonstrate that PyramidAI substantially decreases the amount of processed data\nrequired for analysis by up to 2.65x, while preserving the accuracy in\nidentifying relevant sections on a single computer. To ensure democratization\nof gigapixel image analysis, we evaluated the potential to use mainstream\ncomputers to perform the computation by exploiting the parallelism potential of\nthe approach. Using a simulator, we estimated the best data distribution and\nload balancing algorithm according to the number of workers. The selected\nalgorithms were implemented and highlighted the same conclusions in a\nreal-world setting. Analysis time is reduced from more than an hour to a few\nminutes using 12 modest workers, offering a practical solution for efficient\nlarge-scale image analysis.", "AI": {"tldr": "PyramidAI\u662f\u4e00\u79cd\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u5343\u5146\u50cf\u7d20\u56fe\u50cf\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u9010\u6b65\u5206\u6790\u56fe\u50cf\u5206\u8fa8\u7387\u5e76\u4f18\u5316\u8ba1\u7b97\u8d1f\u8f7d\uff0c\u663e\u8457\u51cf\u5c11\u6570\u636e\u5904\u7406\u91cf\u3002", "motivation": "\u5343\u5146\u50cf\u7d20\u56fe\u50cf\u5206\u6790\u901a\u5e38\u8ba1\u7b97\u91cf\u5927\uff0cPyramidAI\u65e8\u5728\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u5e76\u5728\u666e\u901a\u8ba1\u7b97\u673a\u4e0a\u5b9e\u73b0\u9ad8\u6548\u5206\u6790\u3002", "method": "\u91c7\u7528\u9010\u6b65\u5206\u6790\u7b56\u7565\uff0c\u4ece\u4f4e\u5206\u8fa8\u7387\u5f00\u59cb\uff0c\u9010\u6b65\u805a\u7126\u611f\u5174\u8da3\u533a\u57df\u8fdb\u884c\u9ad8\u5206\u8fa8\u7387\u5206\u6790\u3002\u7814\u7a76\u4e86\u4e24\u79cd\u81ea\u9002\u5e94\u5206\u8fa8\u7387\u9009\u62e9\u7b56\u7565\uff0c\u5e76\u5728Camelyon16\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u3002", "result": "PyramidAI\u51cf\u5c11\u591a\u8fbe2.65\u500d\u7684\u6570\u636e\u5904\u7406\u91cf\uff0c\u5206\u6790\u65f6\u95f4\u4ece\u8d85\u8fc7\u4e00\u5c0f\u65f6\u7f29\u77ed\u5230\u51e0\u5206\u949f\uff08\u4f7f\u752812\u4e2a\u5de5\u4f5c\u8282\u70b9\uff09\u3002", "conclusion": "PyramidAI\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u5343\u5146\u50cf\u7d20\u56fe\u50cf\u5206\u6790\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u56fe\u50cf\u5904\u7406\u3002"}}
{"id": "2509.02473", "pdf": "https://arxiv.org/pdf/2509.02473", "abs": "https://arxiv.org/abs/2509.02473", "authors": ["Ziting Wang", "Shize Zhang", "Haitao Yuan", "Jinwei Zhu", "Shifu Li", "Wei Dong", "Gao Cong"], "title": "FDABench: A Benchmark for Data Agents on Analytical Queries over Heterogeneous Data", "categories": ["cs.DB"], "comment": null, "summary": "The growing demand for data-driven decision-making has created an urgent need\nfor data agents that can integrate structured and unstructured data for\nanalysis. While data agents show promise for enabling users to perform complex\nanalytics tasks, this field still suffers from three critical limitations:\nfirst, comprehensive data agent benchmarks remain absent due to the difficulty\nof designing test cases that evaluate agents' abilities across multi-source\nanalytical tasks; second, constructing reliable test cases that combine\nstructured and unstructured data remains costly and prohibitively complex;\nthird, existing benchmarks exhibit limited adaptability and generalizability,\nresulting in narrow evaluation scope.\n  To address these challenges, we present FDABench, the first data agent\nbenchmark specifically designed for evaluating agents in multi-source data\nanalytical scenarios. Our contributions include: (i) we construct a\nstandardized benchmark with 2,007 diverse tasks across different data sources,\ndomains, difficulty levels, and task types to comprehensively evaluate data\nagent performance; (ii) we design an agent-expert collaboration framework\nensuring reliable and efficient benchmark construction over heterogeneous data;\n(iii) we equip FDABench with robust generalization capabilities across diverse\ntarget systems and frameworks. We use FDABench to evaluate various data agent\nsystems, revealing that each system exhibits distinct advantages and\nlimitations regarding response quality, accuracy, latency, and token cost.", "AI": {"tldr": "FDABench\u662f\u4e00\u4e2a\u4e13\u4e3a\u591a\u6e90\u6570\u636e\u5206\u6790\u573a\u666f\u8bbe\u8ba1\u7684\u6570\u636e\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u5168\u9762\u6027\u3001\u53ef\u9760\u6027\u548c\u901a\u7528\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u9700\u6c42\u589e\u957f\u63a8\u52a8\u4e86\u6570\u636e\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u7f3a\u4e4f\u5168\u9762\u6027\u3001\u6d4b\u8bd5\u7528\u4f8b\u6784\u5efa\u590d\u6742\u548c\u9002\u5e94\u6027\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u4e86FDABench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b2,007\u4e2a\u591a\u6837\u5316\u4efb\u52a1\uff0c\u91c7\u7528\u4ee3\u7406-\u4e13\u5bb6\u534f\u4f5c\u6846\u67b6\u6784\u5efa\uff0c\u5e76\u5177\u5907\u901a\u7528\u6027\u3002", "result": "FDABench\u8bc4\u4f30\u4e86\u591a\u4e2a\u6570\u636e\u4ee3\u7406\u7cfb\u7edf\uff0c\u63ed\u793a\u4e86\u5404\u7cfb\u7edf\u5728\u54cd\u5e94\u8d28\u91cf\u3001\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u65b9\u9762\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "FDABench\u4e3a\u591a\u6e90\u6570\u636e\u4ee3\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5168\u9762\u4e14\u53ef\u9760\u7684\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.01389", "pdf": "https://arxiv.org/pdf/2509.01389", "abs": "https://arxiv.org/abs/2509.01389", "authors": ["Diego Clerissi", "Elena Masserini", "Daniela Micucci", "Leonardo Mariani"], "title": "Towards Multi-Platform Mutation Testing of Task-based Chatbots", "categories": ["cs.SE"], "comment": "4 pages, 1 figure, Accepted at 9th International Workshop on Software\n  Faults 2025", "summary": "Chatbots, also known as conversational agents, have become ubiquitous,\noffering services for a multitude of domains. Unlike general-purpose chatbots,\ntask-based chatbots are software designed to prioritize the completion of tasks\nof the domain they handle (e.g., flight booking). Given the growing popularity\nof chatbots, testing techniques that can generate full conversations as test\ncases have emerged. Still, thoroughly testing all the possible conversational\nscenarios implemented by a task-based chatbot is challenging, resulting in\nincorrect behaviors that may remain unnoticed. To address this challenge, we\nproposed MUTABOT, a mutation testing approach for injecting faults in\nconversations and producing faulty chatbots that emulate defects that may\naffect the conversational aspects. In this paper, we present our extension of\nMUTABOT to multiple platforms (Dialogflow and Rasa), and present experiments\nthat show how mutation testing can be used to reveal weaknesses in test suites\ngenerated by the Botium state-of-the-art test generator.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MUTABOT\u65b9\u6cd5\u7684\u6269\u5c55\uff0c\u652f\u6301\u591a\u5e73\u53f0\uff08Dialogflow\u548cRasa\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u5982\u4f55\u5229\u7528\u7a81\u53d8\u6d4b\u8bd5\u63ed\u793aBotium\u6d4b\u8bd5\u5957\u4ef6\u7684\u5f31\u70b9\u3002", "motivation": "\u7531\u4e8e\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u5728\u6d4b\u8bd5\u4e2d\u5b58\u5728\u96be\u4ee5\u8986\u76d6\u6240\u6709\u5bf9\u8bdd\u573a\u666f\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6f5c\u5728\u7f3a\u9677\u672a\u88ab\u53d1\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6539\u8fdb\u6d4b\u8bd5\u6548\u679c\u3002", "method": "\u6269\u5c55MUTABOT\u81f3\u591a\u5e73\u53f0\uff08Dialogflow\u548cRasa\uff09\uff0c\u5229\u7528\u7a81\u53d8\u6d4b\u8bd5\u6ce8\u5165\u6545\u969c\u5e76\u751f\u6210\u6709\u7f3a\u9677\u7684\u804a\u5929\u673a\u5668\u4eba\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u7a81\u53d8\u6d4b\u8bd5\u53ef\u4ee5\u6709\u6548\u63ed\u793aBotium\u751f\u6210\u7684\u6d4b\u8bd5\u5957\u4ef6\u7684\u4e0d\u8db3\u3002", "conclusion": "MUTABOT\u6269\u5c55\u652f\u6301\u591a\u5e73\u53f0\uff0c\u4e3a\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u7684\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2509.01628", "pdf": "https://arxiv.org/pdf/2509.01628", "abs": "https://arxiv.org/abs/2509.01628", "authors": ["Md. Moktader Moula", "Israt Jahan Shonom", "Azharul Islam", "Mohammad Mosharraf Hossain"], "title": "An Interactive Google Earth Engine Application for Global Multi-Scale Vegetation Analysis Using NDVI Thresholding", "categories": ["cs.HC"], "comment": null, "summary": "Monitoring vegetation dynamics is crucial for addressing global environmental\nchallenges like degradation and deforestation, but traditional remote sensing\nmethods are often complex and resource-intensive. To overcome these barriers,\nwe developed an interactive, cloud-based application on the Google Earth Engine\n(GEE) platform for few clicks on-demand global vegetation analysis without\ncomplex technical knowledge. The application automates the calculation of\nvegetated areas using the Normalized Difference Vegetation Index (NDVI) derived\nfrom Sentinel-2 and Landsat imagery. It utilizes a median composite of images\nover a selected period to create a single, robust, cloud-free image, minimizing\natmospheric noise and other artifacts. It offers a flexible, global multi-scale\nanalytical platform, allowing users to define regions of interest based on\nadministrative boundaries, protected areas, or custom-drawn polygons. The\nuser-friendly interface enables the selection of specific time periods and NDVI\nthresholds to quantify vegetation cover in real time, eliminating the need for\nmanual and time intensive data handling and processing. A validation of the\nplatform was conducted for two protected areas in Bangladesh which demonstrated\nhigh accuracy, with area estimates showing over 97% agreement with published\nreference data. By simplifying access to powerful geospatial analytics to\ngeneral people, this tool provides a scalable and practical solution for\nresearchers, land managers, policymakers, and any interested person to monitor\nvegetation trends, support conservation efforts, to inform decision making in\nspatial context where policy maker need to use insights in few clicks and\ninform environmental policy.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eGoogle Earth Engine\u7684\u4ea4\u4e92\u5f0f\u4e91\u5e94\u7528\u7a0b\u5e8f\uff0c\u7b80\u5316\u5168\u7403\u690d\u88ab\u5206\u6790\uff0c\u65e0\u9700\u590d\u6742\u6280\u672f\u77e5\u8bc6\uff0c\u652f\u6301\u5b9e\u65f6\u690d\u88ab\u8986\u76d6\u91cf\u5316\u3002", "motivation": "\u4f20\u7edf\u9065\u611f\u65b9\u6cd5\u76d1\u6d4b\u690d\u88ab\u52a8\u6001\u590d\u6742\u4e14\u8d44\u6e90\u5bc6\u96c6\uff0c\u9700\u8981\u7b80\u5316\u6280\u672f\u6d41\u7a0b\uff0c\u4e3a\u51b3\u7b56\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6613\u7528\u5de5\u5177\u3002", "method": "\u5229\u7528GEE\u5e73\u53f0\uff0c\u901a\u8fc7NDVI\u6307\u6570\u548cSentinel-2\u3001Landsat\u5f71\u50cf\uff0c\u81ea\u52a8\u5316\u8ba1\u7b97\u690d\u88ab\u9762\u79ef\uff0c\u652f\u6301\u591a\u5c3a\u5ea6\u5206\u6790\u548c\u81ea\u5b9a\u4e49\u533a\u57df\u3002", "result": "\u5728\u5b5f\u52a0\u62c9\u56fd\u4e24\u4e2a\u4fdd\u62a4\u533a\u9a8c\u8bc1\u4e2d\uff0c\u51c6\u786e\u7387\u8fbe97%\u4ee5\u4e0a\uff0c\u5de5\u5177\u53ef\u6269\u5c55\u4e14\u5b9e\u7528\u3002", "conclusion": "\u8be5\u5de5\u5177\u7b80\u5316\u4e86\u5730\u7406\u7a7a\u95f4\u5206\u6790\uff0c\u652f\u6301\u653f\u7b56\u5236\u5b9a\u548c\u73af\u5883\u4fdd\u62a4\u51b3\u7b56\u3002"}}
{"id": "2509.01588", "pdf": "https://arxiv.org/pdf/2509.01588", "abs": "https://arxiv.org/abs/2509.01588", "authors": ["Andrea Poltronieri", "Xavier Serra", "Mart\u00edn Rocamora"], "title": "From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "9 pages, 3 figures, 3 tables", "summary": "Audio Chord Estimation (ACE) holds a pivotal role in music information\nresearch, having garnered attention for over two decades due to its relevance\nfor music transcription and analysis. Despite notable advancements, challenges\npersist in the task, particularly concerning unique characteristics of harmonic\ncontent, which have resulted in existing systems' performances reaching a glass\nceiling. These challenges include annotator subjectivity, where varying\ninterpretations among annotators lead to inconsistencies, and class imbalance\nwithin chord datasets, where certain chord classes are over-represented\ncompared to others, posing difficulties in model training and evaluation. As a\nfirst contribution, this paper presents an evaluation of inter-annotator\nagreement in chord annotations, using metrics that extend beyond traditional\nbinary measures. In addition, we propose a consonance-informed distance metric\nthat reflects the perceptual similarity between harmonic annotations. Our\nanalysis suggests that consonance-based distance metrics more effectively\ncapture musically meaningful agreement between annotations. Expanding on these\nfindings, we introduce a novel ACE conformer-based model that integrates\nconsonance concepts into the model through consonance-based label smoothing.\nThe proposed model also addresses class imbalance by separately estimating\nroot, bass, and all note activations, enabling the reconstruction of chord\nlabels from decomposed outputs.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u97f3\u9891\u548c\u5f26\u6807\u6ce8\u8005\u95f4\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u534f\u548c\u5ea6\u7684\u8ddd\u79bb\u5ea6\u91cf\u3002\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684Conformer\u6a21\u578b\uff0c\u901a\u8fc7\u534f\u548c\u5ea6\u6807\u7b7e\u5e73\u6ed1\u548c\u5206\u89e3\u8f93\u51fa\u89e3\u51b3\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u97f3\u9891\u548c\u5f26\u6807\u6ce8\u4e2d\u6807\u6ce8\u8005\u4e3b\u89c2\u6027\u548c\u6570\u636e\u96c6\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u534f\u548c\u5ea6\u8ddd\u79bb\u5ea6\u91cf\u8bc4\u4f30\u6807\u6ce8\u4e00\u81f4\u6027\uff0c\u5e76\u8bbe\u8ba1Conformer\u6a21\u578b\u7ed3\u5408\u534f\u548c\u5ea6\u6807\u7b7e\u5e73\u6ed1\u4e0e\u5206\u89e3\u8f93\u51fa\u65b9\u6cd5\u3002", "result": "\u534f\u548c\u5ea6\u5ea6\u91cf\u66f4\u6709\u6548\u6355\u6349\u6807\u6ce8\u95f4\u97f3\u4e50\u610f\u4e49\u4e00\u81f4\u6027\uff0c\u65b0\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u534f\u548c\u5ea6\u6982\u5ff5\u548c\u5f26\u5206\u89e3\u7b56\u7565\u4e3a\u89e3\u51b3ACE\u4efb\u52a1\u4e2d\u7684\u6807\u6ce8\u5206\u6b67\u548c\u7c7b\u4e0d\u5e73\u8861\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2509.02447", "pdf": "https://arxiv.org/pdf/2509.02447", "abs": "https://arxiv.org/abs/2509.02447", "authors": ["Xinrui Zhong", "Xinze Feng", "Jingwei Zuo", "Fanjiang Ye", "Yi Mu", "Junfeng Guo", "Heng Huang", "Myungjin Lee", "Yuke Wang"], "title": "An Efficient and Adaptive Watermark Detection System with Tile-based Error Correction", "categories": ["cs.DC"], "comment": null, "summary": "Efficient and reliable detection of generated images is critical for the\nresponsible deployment of generative models. Existing approaches primarily\nfocus on improving detection accuracy and robustness under various image\ntransformations and adversarial manipulations, yet they largely overlook the\nefficiency challenges of watermark detection across large-scale image\ncollections. To address this gap, we propose QRMark, an efficient and adaptive\nend-to-end method for detecting embedded image watermarks. The core idea of\nQRMark is to combine QR Code inspired error correction with tailored tiling\ntechniques to improve detection efficiency while preserving accuracy and\nrobustness. At the algorithmic level, QRMark employs a Reed-Solomon error\ncorrection mechanism to mitigate the accuracy degradation introduced by tiling.\nAt the system level, QRMark implements a resource-aware stream allocation\npolicy that adaptively assigns more streams to GPU-intensive stages of the\ndetection pipeline. It further employs a tile-based workload interleaving\nstrategy to overlap data-loading overhead with computation and schedules\nkernels across stages to maximize efficiency. End-to-end evaluations show that\nQRMark achieves an average 2.43x inference speedup over the sequential\nbaseline.", "AI": {"tldr": "QRMark \u662f\u4e00\u79cd\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u5d4c\u5165\u7684\u56fe\u50cf\u6c34\u5370\uff0c\u901a\u8fc7\u7ed3\u5408 QR \u7801\u7ea0\u9519\u548c\u5206\u5757\u6280\u672f\u6765\u63d0\u9ad8\u68c0\u6d4b\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u6c34\u5370\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u5728\u5927\u89c4\u6a21\u56fe\u50cf\u96c6\u5408\u4e2d\u7684\u6548\u7387\u95ee\u9898\u3002", "method": "QRMark \u91c7\u7528\u4e86 Reed-Solomon \u7ea0\u9519\u673a\u5236\u548c\u57fa\u4e8e\u5206\u5757\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4ea4\u9519\u7b56\u7565\uff0c\u5e76\u5b9e\u73b0\u4e86\u8d44\u6e90\u611f\u77e5\u7684\u6d41\u5206\u914d\u7b56\u7565\u3002", "result": "QRMark \u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u663e\u793a\uff0c\u5176\u63a8\u7406\u901f\u5ea6\u5e73\u5747\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5feb 2.43 \u500d\u3002", "conclusion": "QRMark \u5728\u4fdd\u6301\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6c34\u5370\u68c0\u6d4b\u7684\u6548\u7387\u3002"}}
{"id": "2509.00092", "pdf": "https://arxiv.org/pdf/2509.00092", "abs": "https://arxiv.org/abs/2509.00092", "authors": ["G. Charbel N. Kindji", "Elisa Fromont", "Lina Maria Rojas-Barahona", "Tanguy Urvoy"], "title": "Robust Detection of Synthetic Tabular Data under Schema Variability", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "The rise of powerful generative models has sparked concerns over data\nauthenticity. While detection methods have been extensively developed for\nimages and text, the case of tabular data, despite its ubiquity, has been\nlargely overlooked. Yet, detecting synthetic tabular data is especially\nchallenging due to its heterogeneous structure and unseen formats at test time.\nWe address the underexplored task of detecting synthetic tabular data in the\nwild, where tables have variable and previously unseen schemas. We introduce a\nnovel datum-wise transformer architecture that significantly outperforms the\nonly previously published baseline, improving both AUC and accuracy by 7\npoints. By incorporating a table-adaptation component, our model gains an\nadditional 7 accuracy points, demonstrating enhanced robustness. This work\nprovides the first strong evidence that detecting synthetic tabular data in\nreal-world conditions is not only feasible, but can be done with high\nreliability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u68c0\u6d4b\u5408\u6210\u8868\u683c\u6570\u636e\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u521b\u65b0\u7684Transformer\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u7684\u666e\u53ca\u5f15\u53d1\u4e86\u5bf9\u6570\u636e\u771f\u5b9e\u6027\u7684\u62c5\u5fe7\uff0c\u4f46\u8868\u683c\u6570\u636e\u7531\u4e8e\u5176\u5f02\u6784\u6027\u548c\u6d4b\u8bd5\u65f6\u7684\u672a\u77e5\u683c\u5f0f\uff0c\u68c0\u6d4b\u5408\u6210\u8868\u683c\u6570\u636e\u7684\u4efb\u52a1\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u578b\u7684datum-wise Transformer\u67b6\u6784\uff0c\u5e76\u52a0\u5165\u4e86\u8868\u683c\u9002\u5e94\u7ec4\u4ef6\uff0c\u4ee5\u5904\u7406\u5177\u6709\u53d8\u91cf\u548c\u672a\u77e5\u6a21\u5f0f\u7684\u8868\u683c\u6570\u636e\u3002", "result": "\u65b0\u65b9\u6cd5\u5728AUC\u548c\u51c6\u786e\u7387\u4e0a\u5747\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u5347\u4e867\u4e2a\u767e\u5206\u70b9\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u8bc1\u5b9e\uff0c\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u68c0\u6d4b\u5408\u6210\u8868\u683c\u6570\u636e\u4e0d\u4ec5\u53ef\u884c\uff0c\u800c\u4e14\u53ef\u4ee5\u9ad8\u53ef\u9760\u6027\u5b9e\u73b0\u3002"}}
{"id": "2509.01445", "pdf": "https://arxiv.org/pdf/2509.01445", "abs": "https://arxiv.org/abs/2509.01445", "authors": ["Muhammad Ovais Ahmad", "Tomas Gustavsson"], "title": "Non Technical Debt in Agile Software Development", "categories": ["cs.SE"], "comment": null, "summary": "NonTechnical Debt (NTD) is a common challenge in agile software development,\nmanifesting in four critical forms, Process Debt, Social Debt, People Debt,\nOrganizational debt. NODLA project is a collaboration between Karlstad\nUniversity and four leading Swedish industrial partners, reveals how various\ndebt types disrupt large scale Agile Software Development (ASD) environments.\nThrough extensive surveys, indepth interviews, and statistical analyses\ninvolving a diverse group of software professionals, we identified key drivers\nof NTD and their impacts. Our findings emphasize (1) Well structured, highly\ncohesive teams learn faster, adapt more effectively, and innovate consistently.\n(2) Psychological safety, fostered by proactive leadership, is essential for\ninnovation, experimentation, and keeping employees. (3) Inefficient processes\nand unclear roles contribute significantly to drops in job satisfaction,\nproductivity and team morale. (4) Social fragmentation, particularly in remote\nand hybrid settings, breeds rework, delays, and increased costs. (5) Neglected\nhuman resource needs, such as delayed hiring or insufficient training, limit an\norganization ability to meet growing demands. This white paper distils these\ninsights into practical, evidence based strategies, such as refining team\ncomposition, clarifying roles, fostering psychological safety, streamlining\nworkflows, and embracing failure as a learning tool. By implementing these\nstrategies, organizations can reduce NTD, reclaim agility, and unlock their\nteams full potential.", "AI": {"tldr": "\u975e\u6280\u672f\u503a\u52a1\uff08NTD\uff09\u662f\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e38\u89c1\u95ee\u9898\uff0c\u5206\u4e3a\u6d41\u7a0b\u503a\u52a1\u3001\u793e\u4f1a\u503a\u52a1\u3001\u4eba\u5458\u503a\u52a1\u548c\u7ec4\u7ec7\u503a\u52a1\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u9ad8\u6548\u56e2\u961f\u548c\u5fc3\u7406\u5b89\u5168\u5bf9\u521b\u65b0\u81f3\u5173\u91cd\u8981\uff0c\u800c\u4f4e\u6548\u6d41\u7a0b\u548c\u89d2\u8272\u6a21\u7cca\u4f1a\u964d\u4f4e\u6ee1\u610f\u5ea6\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63ed\u793a\u975e\u6280\u672f\u503a\u52a1\uff08NTD\uff09\u5728\u654f\u6377\u5f00\u53d1\u4e2d\u7684\u5f71\u54cd\uff0c\u5e2e\u52a9\u56e2\u961f\u548c\u9886\u5bfc\u8005\u901a\u8fc7\u79d1\u5b66\u65b9\u6cd5\u51cf\u5c11\u503a\u52a1\uff0c\u63d0\u5347\u6548\u7387\u3002", "method": "\u91c7\u7528\u95ee\u5377\u8c03\u67e5\u3001\u6df1\u5ea6\u8bbf\u8c08\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u7ed3\u5408\u5de5\u4e1a\u5408\u4f5c\u4f19\u4f34\u7684\u5b9e\u9645\u7ecf\u9a8c\uff0c\u5206\u6790NTD\u7684\u9a71\u52a8\u56e0\u7d20\u53ca\u5176\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u9ad8\u6548\u56e2\u961f\u3001\u5fc3\u7406\u5b89\u5168\u3001\u6e05\u6670\u89d2\u8272\u548c\u6d41\u7a0b\u4f18\u5316\u5bf9\u51cf\u5c11NTD\u81f3\u5173\u91cd\u8981\uff1b\u793e\u4ea4\u788e\u7247\u5316\u548c\u4eba\u529b\u8d44\u6e90\u95ee\u9898\u5219\u4f1a\u964d\u4f4e\u751f\u4ea7\u529b\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u56e2\u961f\u7ed3\u6784\u3001\u660e\u786e\u89d2\u8272\u3001\u63d0\u5347\u5fc3\u7406\u5b89\u5168\u548c\u6d41\u7a0b\u6548\u7387\uff0c\u7ec4\u7ec7\u53ef\u4ee5\u51cf\u5c11NTD\uff0c\u91ca\u653e\u56e2\u961f\u6f5c\u529b\u3002"}}
{"id": "2509.01906", "pdf": "https://arxiv.org/pdf/2509.01906", "abs": "https://arxiv.org/abs/2509.01906", "authors": ["Tam Thanh Nguyen", "Tuan Van Ngo", "Long Thanh Le", "Yong Hao Pua", "Mao Van Ngo", "Binbin Chen", "Tony Q. S. Quek"], "title": "Adaptive AI Model Partitioning over 5G Networks", "categories": ["cs.NI"], "comment": "6 pages. Accepted version for presentation at the IEEE Global\n  Communications Conference (Globecom), Taipei, Taiwan, Dec. 2025. \\c{opyright}\n  2025 IEEE. Personal use of this material is permitted. Permission from IEEE\n  must be obtained for all other uses", "summary": "Mobile devices increasingly rely on deep neural networks (DNNs) for complex\ninference tasks, but running entire models locally drains the device battery\nquickly. Offloading computation entirely to cloud or edge servers reduces\nprocessing load at devices but poses privacy risks and can incur high network\nbandwidth consumption and long delays. Split computing (SC) mitigates these\nchallenges by partitioning DNNs between user equipment (UE) and edge servers.\nHowever, 5G wireless channels are time-varying and a fixed splitting scheme can\nlead to sub-optimal solutions. This paper addresses the limitations of fixed\nmodel partitioning in privacy-focused image processing and explores trade-offs\nin key performance metrics, including end-to-end (E2E) latency, energy\nconsumption, and privacy, by developing an adaptive ML partitioning scheme\nbased on real-time AI-powered throughput estimation. Evaluation in multiple\nscenarios demonstrates significant performance gains of our scheme.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b9e\u65f6AI\u4f30\u8ba1\u7684\u81ea\u9002\u5e94DNN\u5206\u5272\u65b9\u6848\uff0c\u7528\u4e8e\u4f18\u5316\u79fb\u52a8\u8bbe\u5907\u4e0e\u8fb9\u7f18\u670d\u52a1\u5668\u4e4b\u95f4\u7684\u8ba1\u7b97\u4efb\u52a1\u5206\u914d\uff0c\u4ee5\u5e73\u8861\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u9690\u79c1\u3002", "motivation": "\u79fb\u52a8\u8bbe\u5907\u8fd0\u884c\u5b8c\u6574DNN\u6a21\u578b\u80fd\u8017\u9ad8\uff0c\u800c\u5168\u5378\u8f7d\u5230\u4e91\u7aef\u6216\u8fb9\u7f18\u670d\u52a1\u5668\u5219\u5b58\u5728\u9690\u79c1\u548c\u5e26\u5bbd\u95ee\u9898\u3002\u56fa\u5b9a\u5206\u5272\u65b9\u6848\u5728\u65f6\u53d85G\u4fe1\u9053\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u81ea\u9002\u5e94DNN\u5206\u5272\u65b9\u6848\uff0c\u57fa\u4e8e\u5b9e\u65f6AI\u541e\u5410\u91cf\u4f30\u8ba1\uff0c\u52a8\u6001\u8c03\u6574\u6a21\u578b\u5206\u5272\u70b9\u3002", "result": "\u5728\u591a\u79cd\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6848\u5728\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u9690\u79c1\u65b9\u9762\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u81ea\u9002\u5e94\u5206\u5272\u65b9\u6848\u80fd\u591f\u6709\u6548\u5e73\u8861\u6027\u80fd\u4e0e\u9690\u79c1\u9700\u6c42\uff0c\u4f18\u4e8e\u56fa\u5b9a\u5206\u5272\u7b56\u7565\u3002"}}
{"id": "2509.01786", "pdf": "https://arxiv.org/pdf/2509.01786", "abs": "https://arxiv.org/abs/2509.01786", "authors": ["Vimal Mollyn", "Chris Harrison"], "title": "EgoTouch: On-Body Touch Input Using AR/VR Headset Cameras", "categories": ["cs.HC", "cs.CV", "cs.RO"], "comment": "Published at UIST 2024. More info at\n  https://www.figlab.com/research/2024/egotouch", "summary": "In augmented and virtual reality (AR/VR) experiences, a user's arms and hands\ncan provide a convenient and tactile surface for touch input. Prior work has\nshown on-body input to have significant speed, accuracy, and ergonomic benefits\nover in-air interfaces, which are common today. In this work, we demonstrate\nhigh accuracy, bare hands (i.e., no special instrumentation of the user) skin\ninput using just an RGB camera, like those already integrated into all modern\nXR headsets. Our results show this approach can be accurate, and robust across\ndiverse lighting conditions, skin tones, and body motion (e.g., input while\nwalking). Finally, our pipeline also provides rich input metadata including\ntouch force, finger identification, angle of attack, and rotation. We believe\nthese are the requisite technical ingredients to more fully unlock on-skin\ninterfaces that have been well motivated in the HCI literature but have lacked\nrobust and practical methods.", "AI": {"tldr": "\u6458\u8981\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRGB\u6444\u50cf\u5934\u7684\u9ad8\u7cbe\u5ea6\u88f8\u624b\u76ae\u80a4\u8f93\u5165\u65b9\u6cd5\uff0c\u9002\u7528\u4e8eAR/VR\u73af\u5883\uff0c\u65e0\u9700\u7279\u6b8a\u8bbe\u5907\uff0c\u4e14\u5728\u5404\u79cd\u5149\u7167\u3001\u80a4\u8272\u548c\u8eab\u4f53\u8fd0\u52a8\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u73b0\u6709AR/VR\u4e2d\u7a7a\u4e2d\u8f93\u5165\u754c\u9762\u7684\u901f\u5ea6\u3001\u7cbe\u5ea6\u548c\u4eba\u4f53\u5de5\u5b66\u95ee\u9898\uff0c\u63a2\u7d22\u66f4\u4fbf\u6377\u7684\u76ae\u80a4\u8f93\u5165\u65b9\u5f0f\u3002", "method": "\u5229\u7528\u73b0\u4ee3XR\u5934\u663e\u5185\u7f6e\u7684RGB\u6444\u50cf\u5934\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u7cbe\u5ea6\u88f8\u624b\u76ae\u80a4\u8f93\u5165\u6280\u672f\uff0c\u652f\u6301\u591a\u79cd\u8f93\u5165\u5143\u6570\u636e\uff08\u5982\u89e6\u6478\u529b\u3001\u624b\u6307\u8bc6\u522b\u7b49\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u7cbe\u5ea6\u9ad8\uff0c\u80fd\u9002\u5e94\u4e0d\u540c\u5149\u7167\u3001\u80a4\u8272\u548c\u8eab\u4f53\u8fd0\u52a8\u6761\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u8f93\u5165\u5143\u6570\u636e\u3002", "conclusion": "\u8be5\u6280\u672f\u4e3a\u76ae\u80a4\u8f93\u5165\u754c\u9762\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63a8\u52a8\u5176\u5728HCI\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2509.02449", "pdf": "https://arxiv.org/pdf/2509.02449", "abs": "https://arxiv.org/abs/2509.02449", "authors": ["Mohsen Seyedkazemi Ardebili", "Andrea Bartolini"], "title": "KubeIntellect: A Modular LLM-Orchestrated Agent Framework for End-to-End Kubernetes Management", "categories": ["cs.DC"], "comment": null, "summary": "Kubernetes has become the foundation of modern cloud-native infrastructure,\nyet its management remains complex and fragmented. Administrators must navigate\na vast API surface, manage heterogeneous workloads, and coordinate tasks across\ndisconnected tools - often requiring precise commands, YAML configuration, and\ncontextual expertise.\n  This paper presents KubeIntellect, a Large Language Model (LLM)-powered\nsystem for intelligent, end-to-end Kubernetes control. Unlike existing tools\nthat focus on observability or static automation, KubeIntellect supports\nnatural language interaction across the full spectrum of Kubernetes API\noperations, including read, write, delete, exec, access control, lifecycle, and\nadvanced verbs. The system uses modular agents aligned with functional domains\n(e.g., logs, metrics, RBAC), orchestrated by a supervisor that interprets user\nqueries, maintains workflow memory, invokes reusable tools, or synthesizes new\nones via a secure Code Generator Agent.\n  KubeIntellect integrates memory checkpoints, human-in-the-loop clarification,\nand dynamic task sequencing into a structured orchestration framework.\nEvaluation results show a 93% tool synthesis success rate and 100% reliability\nacross 200 natural language queries, demonstrating the system's ability to\noperate efficiently under diverse workloads. An automated demo environment is\nprovided on Azure, with additional support for local testing via kind. This\nwork introduces a new class of interpretable, extensible, and LLM-driven\nsystems for managing complex infrastructure.", "AI": {"tldr": "KubeIntellect\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fdKubernetes\u63a7\u5236\u7cfb\u7edf\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u63d0\u9ad8\u4e86\u64cd\u4f5c\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "Kubernetes\u7ba1\u7406\u590d\u6742\u4e14\u5206\u6563\uff0c\u73b0\u6709\u5de5\u5177\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u5168\u8c31API\u64cd\u4f5c\u7684\u9700\u6c42\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "KubeIntellect\u901a\u8fc7\u6a21\u5757\u5316\u4ee3\u7406\u548c\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u6574\u5408\u4e86\u68c0\u67e5\u70b9\u548c\u52a8\u6001\u4efb\u52a1\u6392\u5e8f\u3002", "result": "\u7cfb\u7edf\u5728200\u4e2a\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u5de5\u5177\u5408\u6210\u6210\u529f\u7387\u8fbe93%\uff0c\u53ef\u9760\u6027100%\u3002", "conclusion": "KubeIntellect\u4e3a\u590d\u6742\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u3001\u53ef\u6269\u5c55\u7684\u65b0\u578bLLM\u9a71\u52a8\u7cfb\u7edf\u3002"}}
{"id": "2509.00728", "pdf": "https://arxiv.org/pdf/2509.00728", "abs": "https://arxiv.org/abs/2509.00728", "authors": ["Pengyue Li", "Sheng Wang", "Hua Dai", "Zhiyu Chen", "Zhifeng Bao", "Brian D. Davison"], "title": "A Survey on Open Dataset Search in the LLM Era: Retrospectives and Perspectives", "categories": ["cs.IR", "cs.DB"], "comment": null, "summary": "High-quality datasets are typically required for accomplishing data-driven\ntasks, such as training medical diagnosis models, predicting real-time traffic\nconditions, or conducting experiments to validate research hypotheses.\nConsequently, open dataset search, which aims to ensure the efficient and\naccurate fulfillment of users' dataset requirements, has emerged as a critical\nresearch challenge and has attracted widespread interest. Recent studies have\nmade notable progress in enhancing the flexibility and intelligence of open\ndataset search, and large language models (LLMs) have demonstrated strong\npotential in addressing long-standing challenges in this area. Therefore, a\nsystematic and comprehensive review of the open dataset search problem is\nessential, detailing the current state of research and exploring future\ndirections. In this survey, we focus on recent advances in open dataset search\nbeyond traditional approaches that rely on metadata and keywords. From the\nperspective of dataset modalities, we place particular emphasis on\nexample-based dataset search, advanced similarity measurement techniques based\non dataset content, and efficient search acceleration techniques. In addition,\nwe emphasize the mutually beneficial relationship between LLMs and open dataset\nsearch. On the one hand, LLMs help address complex challenges in query\nunderstanding, semantic modeling, and interactive guidance within open dataset\nsearch. In turn, advances in dataset search can support LLMs by enabling more\neffective integration into retrieval-augmented generation (RAG) frameworks and\ndata selection processes, thereby enhancing downstream task performance.\nFinally, we summarize open research problems and outline promising directions\nfor future work. This work aims to offer a structured reference for researchers\nand practitioners in the field of open dataset search.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5f00\u653e\u6570\u636e\u96c6\u641c\u7d22\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5f3a\u8c03\u57fa\u4e8e\u793a\u4f8b\u7684\u641c\u7d22\u3001\u9ad8\u7ea7\u76f8\u4f3c\u6027\u6d4b\u91cf\u548c\u641c\u7d22\u52a0\u901f\u6280\u672f\uff0c\u5e76\u63a2\u8ba8\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6b64\u9886\u57df\u7684\u5e94\u7528\u4e0e\u4e92\u60e0\u5173\u7cfb\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5bf9\u6570\u636e\u9a71\u52a8\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5982\u4f55\u9ad8\u6548\u51c6\u786e\u5730\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u5f00\u653e\u6570\u636e\u96c6\u641c\u7d22\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\u3002", "method": "\u805a\u7126\u4e8e\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u7684\u5f00\u653e\u6570\u636e\u96c6\u641c\u7d22\u6280\u672f\uff0c\u5305\u62ec\u57fa\u4e8e\u793a\u4f8b\u7684\u641c\u7d22\u3001\u5185\u5bb9\u76f8\u4f3c\u6027\u6d4b\u91cf\u548c\u641c\u7d22\u52a0\u901f\u6280\u672f\u3002", "result": "LLMs\u5728\u67e5\u8be2\u7406\u89e3\u3001\u8bed\u4e49\u5efa\u6a21\u548c\u4ea4\u4e92\u6307\u5bfc\u65b9\u9762\u5c55\u73b0\u4e86\u6f5c\u529b\uff0c\u540c\u65f6\u6570\u636e\u96c6\u641c\u7d22\u7684\u8fdb\u6b65\u53ef\u652f\u6301LLMs\u7684\u63d0\u5347\u3002", "conclusion": "\u603b\u7ed3\u4e86\u5f00\u653e\u6570\u636e\u96c6\u641c\u7d22\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u53c2\u8003\u3002"}}
{"id": "2509.01494", "pdf": "https://arxiv.org/pdf/2509.01494", "abs": "https://arxiv.org/abs/2509.01494", "authors": ["Zhengran Zeng", "Ruikai Shi", "Keke Han", "Yixin Li", "Kaicheng Sun", "Yidong Wang", "Zhuohao Yu", "Rui Xie", "Wei Ye", "Shikun Zhang"], "title": "Benchmarking and Studying the LLM-based Code Review", "categories": ["cs.SE"], "comment": null, "summary": "Automated Code Review (ACR) is crucial for software quality, yet existing\nbenchmarks often fail to reflect real-world complexities, hindering the\nevaluation of modern Large Language Models (LLMs). Current benchmarks\nfrequently focus on fine-grained code units, lack complete project context, and\nuse inadequate evaluation metrics. To address these limitations, we introduce\nSWRBench , a new benchmark comprising 1000 manually verified Pull Requests\n(PRs) from GitHub, offering PR-centric review with full project context.\nSWRBench employs an objective LLM-based evaluation method that aligns strongly\nwith human judgment (~90 agreement) by verifying if issues from a structured\nground truth are covered in generated reviews. Our systematic evaluation of\nmainstream ACR tools and LLMs on SWRBench reveals that current systems\nunderperform, and ACR tools are more adept at detecting functional errors.\nSubsequently, we propose and validate a simple multi-review aggregation\nstrategy that significantly boosts ACR performance, increasing F1 scores by up\nto 43.67%. Our contributions include the SWRBench benchmark, its objective\nevaluation method, a comprehensive study of current ACR capabilities, and an\neffective enhancement approach, offering valuable insights for advancing ACR\nresearch.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aSWRBench\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u6027\u80fd\u7684\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\uff0c\u9650\u5236\u4e86\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8bc4\u4f30\u3002", "method": "\u57fa\u4e8e1000\u4e2a\u624b\u52a8\u9a8c\u8bc1\u7684GitHub\u62c9\u53d6\u8bf7\u6c42\uff08PRs\uff09\uff0c\u63d0\u51faPR\u4e2d\u5fc3\u5316\u7684\u5ba1\u67e5\u65b9\u6cd5\uff0c\u4f7f\u7528LLM\u5ba2\u89c2\u8bc4\u4f30\u3002", "result": "\u5f53\u524dACR\u5de5\u5177\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u66f4\u64c5\u957f\u68c0\u6d4b\u529f\u80fd\u9519\u8bef\uff1b\u591a\u5ba1\u67e5\u805a\u5408\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "SWRBench\u4e3aACR\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u6539\u8fdb\u7b56\u7565\u3002"}}
{"id": "2509.01926", "pdf": "https://arxiv.org/pdf/2509.01926", "abs": "https://arxiv.org/abs/2509.01926", "authors": ["Md Kamran Chowdhury Shisher", "Vishrant Tripathi", "Mung Chiang", "Christopher G. Brinton"], "title": "AoI-based Scheduling of Correlated Sources for Timely Inference", "categories": ["cs.NI", "cs.IT", "math.IT"], "comment": null, "summary": "We investigate a real-time remote inference system where multiple correlated\nsources transmit observations over a communication channel to a receiver. The\nreceiver utilizes these observations to infer multiple time-varying targets.\nDue to limited communication resources, the delivered observations may not be\nfresh. To quantify data freshness, we employ the Age of Information (AoI)\nmetric. To minimize the inference error, we aim to design a signal-agnostic\nscheduling policy that leverages AoI without requiring knowledge of the actual\ntarget values or the source observations. This scheduling problem is a restless\nmulti-armed bandit (RMAB) problem with a non-separable penalty function. Unlike\ntraditional RMABs, the correlation among sources introduces a unique challenge:\nthe penalty function of each source depends on the AoI of other correlated\nsources, preventing decomposition of the problem into multiple independent\nMarkov Decision Processes (MDPs), a key step in applying traditional RMAB\nsolutions. To address this, we propose a novel approach by approximating the\npenalty function of each source and establish an analytical bound on the\napproximation error. We then develop scheduling policies for two scenarios: (i)\nfull knowledge of the penalty functions and (ii) no knowledge of the penalty\nfunctions. For the case of known penalty functions, we present an upper bound\non the optimality gap of our policy in the asymptotic regime. For the case of\nunknown penalty functions and signal distributions, we develop an online\nlearning approach that utilizes bandit feedback to learn an online Maximum Gain\nFirst (MGF) policy. Simulation results demonstrate the effectiveness of our\nproposed policies in minimizing inference error and achieving scalability in\nthe number of sources.", "AI": {"tldr": "\u7814\u7a76\u4e86\u591a\u6e90\u5b9e\u65f6\u8fdc\u7a0b\u63a8\u65ad\u7cfb\u7edf\uff0c\u91c7\u7528AoI\u5ea6\u91cf\u6570\u636e\u65b0\u9c9c\u5ea6\uff0c\u63d0\u51fa\u4fe1\u53f7\u65e0\u5173\u8c03\u5ea6\u7b56\u7565\uff0c\u89e3\u51b3\u76f8\u5173\u6027\u5e26\u6765\u7684RMAB\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u5728\u591a\u6e90\u5b9e\u65f6\u8fdc\u7a0b\u63a8\u65ad\u7cfb\u7edf\u4e2d\uff0c\u901a\u4fe1\u8d44\u6e90\u6709\u9650\u5bfc\u81f4\u6570\u636e\u4e0d\u65b0\u9c9c\uff0c\u9700\u8bbe\u8ba1\u4e0d\u9700\u8981\u76ee\u6807\u503c\u6216\u6e90\u89c2\u6d4b\u77e5\u8bc6\u7684\u8c03\u5ea6\u7b56\u7565\u4ee5\u6700\u5c0f\u5316\u63a8\u65ad\u8bef\u5dee\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eAoI\u7684\u4fe1\u53f7\u65e0\u5173\u8c03\u5ea6\u7b56\u7565\uff0c\u8fd1\u4f3c\u60e9\u7f5a\u51fd\u6570\u5e76\u5206\u6790\u8bef\u5dee\u754c\u9650\uff0c\u9488\u5bf9\u5df2\u77e5/\u672a\u77e5\u60e9\u7f5a\u51fd\u6570\u573a\u666f\u5206\u522b\u8bbe\u8ba1\u7b56\u7565\uff0c\u5f00\u53d1\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u6240\u63d0\u7b56\u7565\u80fd\u6709\u6548\u6700\u5c0f\u5316\u63a8\u65ad\u8bef\u5dee\uff0c\u5e76\u5728\u6e90\u6570\u91cf\u589e\u52a0\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u6e90\u76f8\u5173\u6027\u7cfb\u7edf\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u4e3aAoI\u548cRMAB\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.01845", "pdf": "https://arxiv.org/pdf/2509.01845", "abs": "https://arxiv.org/abs/2509.01845", "authors": ["Gabriel Spadon", "Oladapo Oyebode", "Camilo M. Botero", "Tushar Sharma", "Floris Goerlandt", "Ronald Pelot"], "title": "Community-Centered Spatial Intelligence for Climate Adaptation at Nova Scotia's Eastern Shore", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "This paper presents an overview of a human-centered initiative aimed at\nstrengthening climate resilience along Nova Scotia's Eastern Shore. This\nregion, a collection of rural villages with deep ties to the sea, faces\nexistential threats from climate change that endanger its way of life. Our\nproject moves beyond a purely technical response, weaving together expertise\nfrom Computer Science, Industrial Engineering, and Coastal Geography to\nco-create tools with the community. By integrating generational knowledge of\nresidents, particularly elders, through the Eastern Shore Citizen Science\nCoastal Monitoring Network, this project aims to collaborate in building a\nliving digital archive. This effort is hosted under Dalhousie University's\nTransforming Climate Action (TCA) initiative, specifically through its\nTransformative Adaptations to Social-Ecological Climate Change Trajectories\n(TranSECT) and TCA Artificial Intelligence (TCA-AI) projects. This work is\ndriven by a collaboration model in which student teams work directly with\nresidents. We present a detailed project timeline and a replicable model for\nhow technology can support traditional communities, enabling them to navigate\nclimate transformation more effectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6982\u8ff0\u4e86\u4e00\u9879\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u8ba1\u5212\uff0c\u65e8\u5728\u589e\u5f3a\u65b0\u65af\u79d1\u820d\u7701\u4e1c\u90e8\u6d77\u5cb8\u7684\u6c14\u5019\u97e7\u6027\u3002\u901a\u8fc7\u591a\u5b66\u79d1\u5408\u4f5c\u548c\u793e\u533a\u53c2\u4e0e\uff0c\u9879\u76ee\u6784\u5efa\u4e86\u4e00\u4e2a\u6570\u5b57\u5316\u6863\u6848\uff0c\u5e2e\u52a9\u4f20\u7edf\u793e\u533a\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3002", "motivation": "\u4e1c\u90e8\u6d77\u5cb8\u7684\u4e61\u6751\u793e\u533a\u56e0\u6c14\u5019\u53d8\u5316\u9762\u4e34\u751f\u5b58\u5a01\u80c1\uff0c\u9879\u76ee\u65e8\u5728\u901a\u8fc7\u6280\u672f\u548c\u793e\u533a\u77e5\u8bc6\u7684\u7ed3\u5408\u589e\u5f3a\u5176\u6c14\u5019\u97e7\u6027\u3002", "method": "\u7ed3\u5408\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u5de5\u4e1a\u5de5\u7a0b\u548c\u6d77\u5cb8\u5730\u7406\u5b66\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e0e\u793e\u533a\u5171\u540c\u521b\u5efa\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u516c\u6c11\u79d1\u5b66\u7f51\u7edc\u6574\u5408\u5c45\u6c11\u77e5\u8bc6\u3002", "result": "\u9879\u76ee\u5efa\u7acb\u4e86\u4e00\u4e2a\u6570\u5b57\u5316\u6863\u6848\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u5957\u53ef\u590d\u5236\u7684\u6280\u672f\u6a21\u578b\uff0c\u652f\u6301\u4f20\u7edf\u793e\u533a\u66f4\u6709\u6548\u5730\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3002", "conclusion": "\u8be5\u9879\u76ee\u5c55\u793a\u4e86\u6280\u672f\u5982\u4f55\u4e0e\u4f20\u7edf\u793e\u533a\u77e5\u8bc6\u7ed3\u5408\uff0c\u4e3a\u6c14\u5019\u53d8\u5316\u7684\u9002\u5e94\u63d0\u4f9b\u6709\u6548\u652f\u6301\u3002"}}
{"id": "2509.00997", "pdf": "https://arxiv.org/pdf/2509.00997", "abs": "https://arxiv.org/abs/2509.00997", "authors": ["Shu Liu", "Soujanya Ponnapalli", "Shreya Shankar", "Sepanta Zeighami", "Alan Zhu", "Shubham Agarwal", "Ruiqi Chen", "Samion Suwito", "Shuo Yuan", "Ion Stoica", "Matei Zaharia", "Alvin Cheung", "Natacha Crooks", "Joseph E. Gonzalez", "Aditya G. Parameswaran"], "title": "Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First", "categories": ["cs.AI", "cs.DB"], "comment": null, "summary": "Large Language Model (LLM) agents, acting on their users' behalf to\nmanipulate and analyze data, are likely to become the dominant workload for\ndata systems in the future. When working with data, agents employ a\nhigh-throughput process of exploration and solution formulation for the given\ntask, one we call agentic speculation. The sheer volume and inefficiencies of\nagentic speculation can pose challenges for present-day data systems. We argue\nthat data systems need to adapt to more natively support agentic workloads. We\ntake advantage of the characteristics of agentic speculation that we identify,\ni.e., scale, heterogeneity, redundancy, and steerability - to outline a number\nof new research opportunities for a new agent-first data systems architecture,\nranging from new query interfaces, to new query processing techniques, to new\nagentic memory stores.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5c06\u6210\u4e3a\u672a\u6765\u6570\u636e\u7cfb\u7edf\u7684\u4e3b\u8981\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f46\u5176\u63a2\u7d22\u548c\u89e3\u51b3\u95ee\u9898\u7684\u8fc7\u7a0b\uff08\u79f0\u4e3a\u4ee3\u7406\u63a8\u6d4b\uff09\u7684\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u6548\u6027\u5bf9\u73b0\u6709\u7cfb\u7edf\u63d0\u51fa\u6311\u6218\u3002\u6570\u636e\u7cfb\u7edf\u9700\u8981\u539f\u751f\u652f\u6301\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u5229\u7528\u4ee3\u7406\u63a8\u6d4b\u7684\u7279\u6027\uff08\u5982\u89c4\u6a21\u3001\u5f02\u6784\u6027\u3001\u5197\u4f59\u548c\u53ef\u64cd\u63a7\u6027\uff09\u6765\u8bbe\u8ba1\u65b0\u7684\u67b6\u6784\u3002", "motivation": "\u63a2\u8ba8LLM\u4ee3\u7406\u5728\u6570\u636e\u5904\u7406\u4e2d\u7684\u4e3b\u5bfc\u4f5c\u7528\uff0c\u53ca\u5176\u5bf9\u73b0\u6709\u6570\u636e\u7cfb\u7edf\u7684\u6311\u6218\uff0c\u63d0\u51fa\u5982\u4f55\u4f18\u5316\u7cfb\u7edf\u4ee5\u652f\u6301\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4ee3\u7406\u63a8\u6d4b\u7684\u7279\u6027\uff08\u89c4\u6a21\u3001\u5f02\u6784\u6027\u3001\u5197\u4f59\u3001\u53ef\u64cd\u63a7\u6027\uff09\uff0c\u63d0\u51fa\u9002\u5e94\u4ee3\u7406\u4f18\u5148\u7684\u6570\u636e\u7cfb\u7edf\u67b6\u6784\u7684\u7814\u7a76\u65b9\u5411\u3002", "result": "\u8bc6\u522b\u4e86\u4ee3\u7406\u63a8\u6d4b\u7684\u6311\u6218\u548c\u673a\u4f1a\uff0c\u4e3a\u8bbe\u8ba1\u65b0\u67e5\u8be2\u63a5\u53e3\u3001\u5904\u7406\u6280\u672f\u548c\u5b58\u50a8\u65b9\u6848\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "conclusion": "\u6570\u636e\u7cfb\u7edf\u9700\u4e3aLLM\u4ee3\u7406\u7684\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u63d0\u5347\u6548\u7387\u5e76\u652f\u6301\u5176\u72ec\u7279\u9700\u6c42\u3002"}}
{"id": "2509.01527", "pdf": "https://arxiv.org/pdf/2509.01527", "abs": "https://arxiv.org/abs/2509.01527", "authors": ["Amirreza Nayyeri", "Abbas Rasoolzadegan"], "title": "A Privacy-Preserving Recommender for Filling Web Forms Using a Local Large Language Model", "categories": ["cs.SE"], "comment": null, "summary": "Web applications are increasingly used in critical domains such as education,\nfinance, and e-commerce. This highlights the need to ensure their failure-free\nperformance. One effective method for evaluating failure-free performance is\nweb form testing, where defining effective test scenarios is key to a complete\nand accurate evaluation. A core aspect of this process involves filling form\nfields with suitable values to create effective test cases. However, manually\ngenerating these values is time-consuming and prone to errors. To address this,\nvarious tools have been developed to assist testers. With the appearance of\nlarge language models (LLMs), a new generation of tools seeks to handle this\ntask more intelligently. Although many LLM-based tools have been introduced, as\nthese models typically rely on cloud infrastructure, their use in testing\nconfidential web forms raises concerns about unintended data leakage and\nbreaches of confidentiality. This paper introduces a privacy-preserving\nrecommender that operates locally using a large language model. The tool\nassists testers in web form testing by suggesting effective field values. This\ntool analyzes the HTML structure of forms, detects input types, and extracts\nconstraints based on each field's type and contextual content, guiding proper\nfield filling.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u63a8\u8350\u5de5\u5177\uff0c\u7528\u4e8e\u672c\u5730\u5316\u751f\u6210\u6709\u6548\u7684\u7f51\u9875\u8868\u5355\u6d4b\u8bd5\u7528\u4f8b\uff0c\u907f\u514d\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002", "motivation": "\u7f51\u9875\u8868\u5355\u6d4b\u8bd5\u4e2d\u624b\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u73b0\u6709\u4e91\u57fa\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u5b58\u5728\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u4e00\u4e2a\u672c\u5730\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5de5\u5177\u901a\u8fc7\u5206\u6790HTML\u7ed3\u6784\u3001\u68c0\u6d4b\u8f93\u5165\u7c7b\u578b\u5e76\u63d0\u53d6\u7ea6\u675f\u6761\u4ef6\uff0c\u57fa\u4e8e\u672c\u5730\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6709\u6548\u7684\u5b57\u6bb5\u586b\u5145\u5efa\u8bae\u3002", "result": "\u5f00\u53d1\u51fa\u4e00\u79cd\u672c\u5730\u5316\u64cd\u4f5c\u7684\u5de5\u5177\uff0c\u80fd\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u9ad8\u6548\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "conclusion": "\u8be5\u5de5\u5177\u4e3a\u7f51\u9875\u8868\u5355\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u4e14\u667a\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u6cc4\u9732\u95ee\u9898\u5e76\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u7387\u3002"}}
{"id": "2509.01957", "pdf": "https://arxiv.org/pdf/2509.01957", "abs": "https://arxiv.org/abs/2509.01957", "authors": ["Evan Chen", "Seyyedali Hosseinalipour", "Christopher G. Brinton", "David J. Love"], "title": "Federated Foundation Models in Harsh Wireless Environments: Prospects, Challenges, and Future Directions", "categories": ["cs.NI"], "comment": "This paper is under review in IEEE Network Magazine Special Issue on\n  Large AI Models for the Internet of Everything", "summary": "Foundation models (FMs) have shown remarkable capabilities in generalized\nintelligence, multimodal understanding, and adaptive learning across a wide\nrange of domains. However, their deployment in harsh or austere environments --\ncharacterized by intermittent connectivity, limited computation, noisy data,\nand dynamically changing network topologies -- remains an open challenge.\nExisting distributed learning methods such as federated learning (FL) struggle\nto adapt in such settings due to their reliance on stable infrastructure,\nsynchronized updates, and resource-intensive training. In this work, we explore\nthe potential of Federated Foundation Models (FFMs) as a promising paradigm to\naddress these limitations. By integrating the scalability and generalization\npower of FMs with novel decentralized, communication-aware FL frameworks, we\naim to enable robust, energy-efficient, and adaptive intelligence in extreme\nand adversarial conditions. We present a detailed breakdown of system-level\nconstraints in harsh environments, and discuss the open research challenges in\ncommunication design, model robustness, and energy-efficient personalization\nfor these unique settings.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u8054\u90a6\u57fa\u7840\u6a21\u578b\uff08FFMs\uff09\u5728\u6076\u52a3\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u7ed3\u5408\u4e86\u57fa\u7840\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53bb\u4e2d\u5fc3\u5316\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u8d44\u6e90\u6709\u9650\u3001\u4e0d\u7a33\u5b9a\u7684\u73af\u5883\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u867d\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u5728\u6076\u52a3\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u5206\u5e03\u5f0f\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u8054\u90a6\u5b66\u4e60\uff09\u56e0\u4f9d\u8d56\u7a33\u5b9a\u57fa\u7840\u8bbe\u65bd\u800c\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u8054\u90a6\u57fa\u7840\u6a21\u578b\uff08FFMs\uff09\uff0c\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53bb\u4e2d\u5fc3\u5316\u3001\u901a\u4fe1\u611f\u77e5\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u9002\u5e94\u6076\u52a3\u73af\u5883\u4e2d\u7684\u9700\u6c42\u3002", "result": "\u8bba\u6587\u5206\u6790\u4e86\u6076\u52a3\u73af\u5883\u4e2d\u7684\u7cfb\u7edf\u7ea7\u7ea6\u675f\uff0c\u5e76\u63a2\u8ba8\u4e86\u901a\u4fe1\u8bbe\u8ba1\u3001\u6a21\u578b\u9c81\u68d2\u6027\u548c\u80fd\u6548\u4e2a\u6027\u5316\u7b49\u65b9\u9762\u7684\u7814\u7a76\u6311\u6218\u3002", "conclusion": "FFMs\u4e3a\u89e3\u51b3\u6076\u52a3\u73af\u5883\u4e2d\u7684\u667a\u80fd\u90e8\u7f72\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2509.02100", "pdf": "https://arxiv.org/pdf/2509.02100", "abs": "https://arxiv.org/abs/2509.02100", "authors": ["Sharjeel Tahir", "Judith Johnson", "Jumana Abu-Khalaf", "Syed Afaq Ali Shah"], "title": "E-THER: A PCT-Grounded Dataset for Benchmarking Empathic AI", "categories": ["cs.HC", "cs.CL"], "comment": "15 pages, 4 figures. Preprint", "summary": "A prevalent shortfall among current empathic AI systems is their inability to\nrecognize when verbal expressions may not fully reflect underlying emotional\nstates. This is because the existing datasets, used for the training of these\nsystems, focus on surface-level emotion recognition without addressing the\ncomplex verbal-visual incongruence (mismatch) patterns useful for empathic\nunderstanding. In this paper, we present E-THER, the first Person-Centered\nTherapy-grounded multimodal dataset with multidimensional annotations for\nverbal-visual incongruence detection, enabling training of AI systems that\ndevelop genuine rather than performative empathic capabilities. The annotations\nincluded in the dataset are drawn from humanistic approach, i.e., identifying\nverbal-visual emotional misalignment in client-counsellor interactions -\nforming a framework for training and evaluating AI on empathy tasks. Additional\nengagement scores provide behavioral annotations for research applications.\nNotable gains in empathic and therapeutic conversational qualities are observed\nin state-of-the-art vision-language models (VLMs), such as IDEFICS and\nVideoLLAVA, using evaluation metrics grounded in empathic and therapeutic\nprinciples. Empirical findings indicate that our incongruence-trained models\noutperform general-purpose models in critical traits, such as sustaining\ntherapeutic engagement, minimizing artificial or exaggerated linguistic\npatterns, and maintaining fidelity to PCT theoretical framework.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86E-THER\u6570\u636e\u96c6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709AI\u7cfb\u7edf\u5728\u5171\u60c5\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u6807\u6ce8\u7684\u8a00\u8bed-\u89c6\u89c9\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\uff0c\u8bad\u7ec3AI\u5b9e\u73b0\u66f4\u771f\u5b9e\u7684\u5171\u60c5\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5171\u60c5AI\u7cfb\u7edf\u65e0\u6cd5\u8bc6\u522b\u8a00\u8bed\u8868\u8fbe\u4e0e\u60c5\u611f\u72b6\u6001\u7684\u4e0d\u4e00\u81f4\uff0c\u56e0\u4e3a\u73b0\u6709\u6570\u636e\u96c6\u4ec5\u5173\u6ce8\u8868\u9762\u60c5\u611f\u8bc6\u522b\uff0c\u7f3a\u4e4f\u5bf9\u8a00\u8bed-\u89c6\u89c9\u4e0d\u4e00\u81f4\u6a21\u5f0f\u7684\u5173\u6ce8\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7597\u6cd5\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6E-THER\uff0c\u5305\u542b\u8a00\u8bed-\u89c6\u89c9\u4e0d\u4e00\u81f4\u6027\u6807\u6ce8\uff0c\u5e76\u5229\u7528\u8be5\u6570\u636e\u96c6\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u4e0d\u4e00\u81f4\u6027\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u5171\u60c5\u548c\u5bf9\u8bdd\u8d28\u91cf\u4e0a\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u5c24\u5176\u5728\u7ef4\u6301\u6cbb\u7597\u53c2\u4e0e\u5ea6\u548c\u51cf\u5c11\u865a\u5047\u8bed\u8a00\u6a21\u5f0f\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "E-THER\u6570\u636e\u96c6\u4e3aAI\u7cfb\u7edf\u7684\u5171\u60c5\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\uff0c\u9a8c\u8bc1\u4e86\u8a00\u8bed-\u89c6\u89c9\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u5bf9\u63d0\u5347AI\u5171\u60c5\u6548\u679c\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.02281", "pdf": "https://arxiv.org/pdf/2509.02281", "abs": "https://arxiv.org/abs/2509.02281", "authors": ["Shijie Wang", "Li Zhang", "Xinyan Liang", "Yuhua Qian", "Shen Hu"], "title": "Balanced Multimodal Learning: An Unidirectional Dynamic Interaction Perspective", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "Multimodal learning typically utilizes multimodal joint loss to integrate\ndifferent modalities and enhance model performance. However, this joint\nlearning strategy can induce modality imbalance, where strong modalities\noverwhelm weaker ones and limit exploitation of individual information from\neach modality and the inter-modality interaction information.Existing\nstrategies such as dynamic loss weighting, auxiliary objectives and gradient\nmodulation mitigate modality imbalance based on joint loss. These methods\nremain fundamentally reactive, detecting and correcting imbalance after it\narises, while leaving the competitive nature of the joint loss untouched. This\nlimitation drives us to explore a new strategy for multimodal imbalance\nlearning that does not rely on the joint loss, enabling more effective\ninteractions between modalities and better utilization of information from\nindividual modalities and their interactions. In this paper, we introduce\nUnidirectional Dynamic Interaction (UDI), a novel strategy that abandons the\nconventional joint loss in favor of a proactive, sequential training scheme.\nUDI first trains the anchor modality to convergence, then uses its learned\nrepresentations to guide the other modality via unsupervised loss. Furthermore,\nthe dynamic adjustment of modality interactions allows the model to adapt to\nthe task at hand, ensuring that each modality contributes optimally. By\ndecoupling modality optimization and enabling directed information flow, UDI\nprevents domination by any single modality and fosters effective cross-modal\nfeature learning. Our experimental results demonstrate that UDI outperforms\nexisting methods in handling modality imbalance, leading to performance\nimprovement in multimodal learning tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5UDI\uff0c\u901a\u8fc7\u653e\u5f03\u4f20\u7edf\u7684\u8054\u5408\u635f\u5931\uff0c\u91c7\u7528\u987a\u5e8f\u8bad\u7ec3\u65b9\u6848\u6765\u89e3\u51b3\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u8054\u5408\u635f\u5931\uff0c\u4f46\u4f1a\u5bfc\u81f4\u6a21\u6001\u4e0d\u5e73\u8861\uff0c\u5f3a\u6a21\u6001\u538b\u5236\u5f31\u6a21\u6001\uff0c\u9650\u5236\u4e86\u4fe1\u606f\u7684\u6709\u6548\u5229\u7528\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u4e00\u79cd\u4e0d\u4f9d\u8d56\u8054\u5408\u635f\u5931\u7684\u65b0\u7b56\u7565\u662f\u5fc5\u8981\u7684\u3002", "method": "\u63d0\u51fa\u4e86Unidirectional Dynamic Interaction (UDI)\u7b56\u7565\uff0c\u9996\u5148\u8bad\u7ec3\u951a\u5b9a\u6a21\u6001\u81f3\u6536\u655b\uff0c\u518d\u7528\u5176\u8868\u793a\u901a\u8fc7\u65e0\u76d1\u7763\u635f\u5931\u6307\u5bfc\u5176\u4ed6\u6a21\u6001\uff0c\u52a8\u6001\u8c03\u6574\u6a21\u6001\u4ea4\u4e92\u4ee5\u4f18\u5316\u5404\u81ea\u8d21\u732e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cUDI\u5728\u89e3\u51b3\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "UDI\u901a\u8fc7\u89e3\u8026\u6a21\u6001\u4f18\u5316\u548c\u5b9a\u5411\u4fe1\u606f\u6d41\uff0c\u907f\u514d\u4e86\u5355\u4e00\u6a21\u6001\u7684\u652f\u914d\uff0c\u4fc3\u8fdb\u4e86\u8de8\u6a21\u6001\u7279\u5f81\u5b66\u4e60\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.02480", "pdf": "https://arxiv.org/pdf/2509.02480", "abs": "https://arxiv.org/abs/2509.02480", "authors": ["Avinash Maurya", "M. Mustafa Rafique", "Franck Cappello", "Bogdan Nicolae"], "title": "MLP-Offload: Multi-Level, Multi-Path Offloading for LLM Pre-training to Break the GPU Memory Wall", "categories": ["cs.DC", "cs.AI", "cs.LG", "H.2.0; E.2; I.2.11"], "comment": "SC'25: The International Conference for High Performance Computing,\n  Networking, Storage and Analysis", "summary": "Training LLMs larger than the aggregated memory of multiple GPUs is\nincreasingly necessary due to the faster growth of LLM sizes compared to GPU\nmemory. To this end, multi-tier host memory or disk offloading techniques are\nproposed by state of art. Despite advanced asynchronous multi-tier read/write\nstrategies, such offloading strategies result in significant I/O overheads in\nthe critical path of training, resulting in slower iterations. To this end, we\npropose MLP-Offload, a novel multi-level, multi-path offloading engine\nspecifically designed for optimizing LLM training on resource-constrained\nsetups by mitigating I/O bottlenecks. We make several key observations that\ndrive the design of MLP-Offload, such as I/O overheads during the update\ndominate the iteration time; I/O bandwidth of the third-level remote storage\ntier remains unutilized; and, contention due to concurrent offloading amplifies\nI/O bottlenecks. Driven by these insights, we design and implement MLP-Offload\nto offload the optimizer states across multiple tiers in a cache-efficient and\nconcurrency-controlled fashion to mitigate I/O bottlenecks during the backward\nand update phases. Evaluations on models up to 280B parameters shows that\nMLP-Offload achieves 2.5$\\times$ faster iterations compared to the\nstate-of-the-art LLM training runtimes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MLP-Offload\u6280\u672f\uff0c\u901a\u8fc7\u591a\u7ea7\u591a\u8def\u5f84\u5378\u8f7d\u5f15\u64ce\u4f18\u5316\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684LLM\u8bad\u7ec3\uff0c\u663e\u8457\u51cf\u5c11I/O\u74f6\u9888\uff0c\u5b9e\u73b0\u6bd4\u73b0\u6709\u6280\u672f\u5feb2.5\u500d\u7684\u8fed\u4ee3\u901f\u5ea6\u3002", "motivation": "\u7531\u4e8eLLM\u89c4\u6a21\u589e\u957f\u901f\u5ea6\u8fdc\u5feb\u4e8eGPU\u5185\u5b58\u5bb9\u91cf\uff0c\u8bad\u7ec3\u8d85\u5927\u578bLLM\u9700\u8981\u8de8\u591aGPU\u5185\u5b58\u6216\u78c1\u76d8\u5378\u8f7d\u6280\u672f\uff0c\u4f46\u73b0\u6709\u5378\u8f7d\u7b56\u7565\u5728\u5173\u952e\u8bad\u7ec3\u8def\u5f84\u4e2d\u4ea7\u751f\u663e\u8457\u7684I/O\u5f00\u9500\uff0c\u5f71\u54cd\u8bad\u7ec3\u8fed\u4ee3\u901f\u5ea6\u3002", "method": "\u63d0\u51faMLP-Offload\uff0c\u4e00\u79cd\u591a\u7ea7\u591a\u8def\u5f84\u5378\u8f7d\u5f15\u64ce\uff0c\u901a\u8fc7\u9ad8\u6548\u7f13\u5b58\u548c\u5e76\u53d1\u63a7\u5236\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u548c\u66f4\u65b0\u9636\u6bb5\u8de8\u591a\u5c42\u7ea7\u5378\u8f7d\u4f18\u5316\u5668\u72b6\u6001\uff0c\u4ee5\u51cf\u5c11I/O\u74f6\u9888\u3002", "result": "\u5728280B\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0cMLP-Offload\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6280\u672f\u5feb2.5\u500d\u7684\u8fed\u4ee3\u901f\u5ea6\u3002", "conclusion": "MLP-Offload\u901a\u8fc7\u521b\u65b0\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86LLM\u8bad\u7ec3\u4e2d\u7684I/O\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2509.01308", "pdf": "https://arxiv.org/pdf/2509.01308", "abs": "https://arxiv.org/abs/2509.01308", "authors": ["Mattia Tritto", "Giuseppe Farano", "Dario Di Palma", "Gaetano Rossiello", "Fedelucio Narducci", "Dharmashankar Subramanian", "Tommaso Di Noia"], "title": "GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.DB"], "comment": null, "summary": "Text-to-SQL, the task of translating natural language questions into SQL\nqueries, has significantly advanced with the introduction of Large Language\nModels (LLMs), broadening database accessibility for a wide range of users.\nDespite substantial progress in generating valid SQL, current LLMs still\nstruggle with complex queries that require precise alignment between user\nintent and the database schema. To mitigate this, test-time strategies such as\nBest-of-N (BoN) and Majority Voting (Maj) are often employed, based on the\nassumption that LLMs can generate correct answers but may require multiple\nattempts. However, these methods rely on surface-level heuristics, selecting\neither the syntactically correct query through execution-based BoN (ex-BoN) or\nthe most frequently generated query with Maj. Recently, Outcome Reward Models\n(ORMs), which assign utility scores to generated outputs based on semantic\ncorrectness, have emerged as a promising approach for better aligning model\npredictions with user intent. Nevertheless, their application to Text-to-SQL\nremains largely underexplored.\n  In this work, we evaluate ORMs as an effective heuristic for BoN, compare\nthem with ex-BoN and Maj, and introduce a framework for training ORMs for the\nText-to-SQL task. We evaluate our ORMs on the BIRD and SPIDER benchmarks,\nfinetuning various open-source LLMs, including the Qwen2, Granite3, and Llama3\nmodel families. Our results show that ORMs outperform ex-BoN and Maj, achieving\nexecution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and\n+2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that\nfinetuning models already aligned with SQL generation, such as OmniSQL, yields\nsuperior ORM performance. Additionally, we observe that ORMs achieve\ncompetitive results on simple queries and benefit more from an increased number\nof candidates compared to ex-BoN and Maj.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u7ed3\u679c\u5956\u52b1\u6a21\u578b\uff08ORMs\uff09\u4f5c\u4e3aText-to-SQL\u4efb\u52a1\u4e2d\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u6bd4\u4f20\u7edf\u7684Best-of-N\u548cMajority Voting\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Text-to-SQL\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u590d\u6742\u67e5\u8be2\u4e2d\u7528\u6237\u610f\u56fe\u4e0e\u6570\u636e\u5e93\u6a21\u5f0f\u7684\u7cbe\u786e\u5bf9\u9f50\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8868\u9762\u542f\u53d1\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3ORMs\u7684\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u4e0eex-BoN\u548cMaj\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u540c\u65f6\u5728BIRD\u548cSPIDER\u57fa\u51c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "ORMs\u5728BIRD\u548cSpider\u57fa\u51c6\u4e0a\u7684\u6267\u884c\u51c6\u786e\u7387\u5206\u522b\u6bd4ex-BoN\u9ad8\u51fa4.33%\u548c2.10%\uff0c\u6bd4Maj\u9ad8\u51fa2.91%\u548c0.93%\u3002", "conclusion": "ORMs\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5df2\u5bf9\u9f50SQL\u751f\u6210\u7684\u6a21\u578b\u4e0a\u8868\u73b0\u66f4\u4f73\uff0c\u4e14\u5728\u7b80\u5355\u67e5\u8be2\u548c\u5019\u9009\u751f\u6210\u6570\u91cf\u589e\u52a0\u65f6\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2509.01612", "pdf": "https://arxiv.org/pdf/2509.01612", "abs": "https://arxiv.org/abs/2509.01612", "authors": ["Omur Sahin", "Man Zhang", "Andrea Arcuri"], "title": "WFC/WFD: Web Fuzzing Commons, Dataset and Guidelines to Support Experimentation in REST API Fuzzing", "categories": ["cs.SE"], "comment": null, "summary": "Fuzzing REST APIs is an important research problem, with practical\napplications and impact in industry. As such, a lot of research work has been\ncarried out on this topic in the last few years. However, there are three major\nissues that hinder further progress: how to deal with API authentication; how\nto catalog and compare different fault types found by different fuzzers; and\nwhat to use as case study to facilitate fair comparisons among fuzzers. To\naddress these important challenges, we present Web Fuzzing Commons (WFC) and\nWeb Fuzzing Dataset (WFD). WFC is a set of open-source libraries and schema\ndefinitions to declaratively specify authentication info and catalog different\ntypes of faults that fuzzers can automatically detect. WFD is a collection of\n36 open-source APIs with all necessary scaffolding to easily run experiments\nwith fuzzers, supported by WFC. To show the usefulness of WFC/WFD, a set of\nexperiments is carried out with EvoMaster, a state-of-the-art fuzzer for Web\nAPIs. However, any fuzzer can benefit from WFC and WFD. We compare EvoMaster\nwith other state-of-the-art tools such as ARAT-RL, EmRest, LLamaRestTest,\nRESTler, and Schemathesis. We discuss common pitfalls in tool comparisons, as\nwell as providing guidelines with support of WFC/WFD to avoid them.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Web Fuzzing Commons (WFC)\u548cWeb Fuzzing Dataset (WFD)\uff0c\u4ee5\u89e3\u51b3REST API\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u7684\u4e09\u5927\u6311\u6218\uff1aAPI\u8ba4\u8bc1\u3001\u6545\u969c\u7c7b\u578b\u5206\u7c7b\u4e0e\u6bd4\u8f83\u3001\u4ee5\u53ca\u516c\u5e73\u6bd4\u8f83\u7528\u7684\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u89e3\u51b3REST API\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u5173\u4e8e\u8ba4\u8bc1\u3001\u6545\u969c\u5206\u7c7b\u548c\u516c\u5e73\u6bd4\u8f83\u7684\u4e09\u5927\u95ee\u9898\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u63d0\u51fa\u4e86WFC\uff08\u5f00\u6e90\u7684\u5e93\u548c\u6a21\u5f0f\u5b9a\u4e49\uff09\u548cWFD\uff0836\u4e2a\u5f00\u6e90API\u96c6\u5408\uff09\uff0c\u652f\u6301\u5b9e\u9a8c\u8fd0\u884c\u548c\u6545\u969c\u5206\u7c7b\u3002\u901a\u8fc7EvoMaster\u7b49\u5de5\u5177\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "WFC\u548cWFD\u4e3a\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6846\u67b6\u548c\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u4e09\u5927\u6311\u6218\uff0c\u5e76\u5c55\u793a\u4e86\u4e0e\u5176\u4ed6\u5de5\u5177\u7684\u5bf9\u6bd4\u7ed3\u679c\u3002", "conclusion": "WFC\u548cWFD\u4e3aREST API\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u652f\u6301\u516c\u5e73\u6bd4\u8f83\u548c\u6807\u51c6\u5316\u7814\u7a76\uff0c\u63a8\u52a8\u4e86\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2509.02132", "pdf": "https://arxiv.org/pdf/2509.02132", "abs": "https://arxiv.org/abs/2509.02132", "authors": ["Dragan Ahmetovic", "Matteo Manzoni", "Filippo Corti", "Sergio Mascetti"], "title": "Shared Control for Game Accessibility: Understanding Current Human Cooperation Practices to Inform the Design of Partial Automation Solutions", "categories": ["cs.HC"], "comment": "26 pages, 1 figure", "summary": "Shared control is a form of video gaming accessibility support that allows\nplayers with disabilities to delegate inaccessible controls to another person.\nThrough interviews involving 14 individuals with lived experience of accessible\ngaming in shared control, we explore the ways in which shared control\ntechnologies are adopted in practice, the accessibility challenges they\naddress, and how the support currently provided in shared control can be\nautomated to remove the need for a human assistant. Findings indicate that\nshared control is essential for enabling access to otherwise inaccessible\ngames, but its reliance on human support is a key limitation. Participants\nwelcomed the idea of automating the support with software agents, while also\nidentifying limitations and design requirements. Accordingly, this work\ncontributes insights into current practices and proposes guidelines for\ndeveloping automated support systems.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5171\u4eab\u63a7\u5236\u5728\u6b8b\u75be\u73a9\u5bb6\u6e38\u620f\u4e2d\u7684\u5b9e\u8df5\u5e94\u7528\u53ca\u5176\u81ea\u52a8\u5316\u9700\u6c42\u3002", "motivation": "\u5171\u4eab\u63a7\u5236\u6280\u672f\u5e2e\u52a9\u6b8b\u75be\u73a9\u5bb6\u89e3\u51b3\u6e38\u620f\u64cd\u4f5c\u969c\u788d\uff0c\u4f46\u4f9d\u8d56\u4eba\u529b\u652f\u6301\u662f\u4e3b\u8981\u9650\u5236\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u81ea\u52a8\u5316\u6539\u8fdb\u3002", "method": "\u901a\u8fc714\u4f4d\u6b8b\u75be\u73a9\u5bb6\u7684\u8bbf\u8c08\uff0c\u5206\u6790\u5171\u4eab\u63a7\u5236\u7684\u4f7f\u7528\u5b9e\u8df5\u3001\u6311\u6218\u53ca\u81ea\u52a8\u5316\u8bbe\u8ba1\u9700\u6c42\u3002", "result": "\u5171\u4eab\u63a7\u5236\u5bf9\u6e38\u620f\u53ef\u8bbf\u95ee\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u81ea\u52a8\u5316\u652f\u6301\u662f\u672a\u6765\u53d1\u5c55\u65b9\u5411\uff0c\u9700\u6ee1\u8db3\u7279\u5b9a\u8bbe\u8ba1\u9700\u6c42\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u81ea\u52a8\u5316\u5171\u4eab\u63a7\u5236\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6d1e\u5bdf\u548c\u8bbe\u8ba1\u6307\u5357\u3002"}}
{"id": "2509.01565", "pdf": "https://arxiv.org/pdf/2509.01565", "abs": "https://arxiv.org/abs/2509.01565", "authors": ["Madan Krishnamurthy", "Surya Saha", "Pierrette Lo", "Patricia L. Whetzel", "Tursynay Issabekova", "Jamed Ferreris Vargas", "Jack DiGiovanna", "Melissa A Haendel"], "title": "Enabling Down Syndrome Research through a Knowledge Graph-Driven Analytical Framework", "categories": ["q-bio.QM", "cs.AI", "cs.DB", "cs.LG"], "comment": null, "summary": "Trisomy 21 results in Down syndrome, a multifaceted genetic disorder with\ndiverse clinical phenotypes, including heart defects, immune dysfunction,\nneurodevelopmental differences, and early-onset dementia risk. Heterogeneity\nand fragmented data across studies challenge comprehensive research and\ntranslational discovery. The NIH INCLUDE (INvestigation of Co-occurring\nconditions across the Lifespan to Understand Down syndromE) initiative has\nassembled harmonized participant-level datasets, yet realizing their potential\nrequires integrative analytical frameworks. We developed a knowledge\ngraph-driven platform transforming nine INCLUDE studies, comprising 7,148\nparticipants, 456 conditions, 501 phenotypes, and over 37,000 biospecimens,\ninto a unified semantic infrastructure. Cross-resource enrichment with Monarch\nInitiative data expands coverage to 4,281 genes and 7,077 variants. The\nresulting knowledge graph contains over 1.6 million semantic associations,\nenabling AI-ready analysis with graph embeddings and path-based reasoning for\nhypothesis generation. Researchers can query the graph via SPARQL or natural\nlanguage interfaces. This framework converts static data repositories into\ndynamic discovery environments, supporting cross-study pattern recognition,\npredictive modeling, and systematic exploration of genotype-phenotype\nrelationships in Down syndrome.", "AI": {"tldr": "\u6458\u8981\u4ecb\u7ecd\u4e86NIH INCLUDE\u8ba1\u5212\u6574\u5408\u5510\u6c0f\u7efc\u5408\u75c7\u6570\u636e\u7684\u77e5\u8bc6\u56fe\u8c31\u5e73\u53f0\uff0c\u901a\u8fc7\u8bed\u4e49\u5173\u8054\u5b9e\u73b0\u8de8\u7814\u7a76\u548cAI\u5206\u6790\u3002", "motivation": "\u5510\u6c0f\u7efc\u5408\u75c7\u7684\u4e34\u5e8a\u8868\u578b\u591a\u6837\u4e14\u6570\u636e\u5206\u6563\uff0c\u9700\u8981\u6574\u5408\u5de5\u5177\u4ee5\u4fc3\u8fdb\u7814\u7a76\u548c\u8f6c\u5316\u53d1\u73b0\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31\u5e73\u53f0\uff0c\u6574\u5408\u4e869\u9879\u7814\u7a76\u7684\u6570\u636e\uff0c\u6db5\u76d67148\u540d\u53c2\u4e0e\u8005\u3001456\u79cd\u75be\u75c5\u548c37000\u591a\u4e2a\u751f\u7269\u6837\u672c\uff0c\u5e76\u901a\u8fc7Monarch Initiative\u6269\u5c55\u4e86\u6570\u636e\u8986\u76d6\u8303\u56f4\u3002", "result": "\u77e5\u8bc6\u56fe\u8c31\u5305\u542b160\u4e07\u6761\u8bed\u4e49\u5173\u8054\uff0c\u652f\u6301AI\u5206\u6790\u548c\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u4fc3\u8fdb\u8de8\u7814\u7a76\u6a21\u5f0f\u8bc6\u522b\u548c\u57fa\u56e0\u578b-\u8868\u578b\u5173\u7cfb\u63a2\u7d22\u3002", "conclusion": "\u8be5\u5e73\u53f0\u5c06\u9759\u6001\u6570\u636e\u8f6c\u5316\u4e3a\u52a8\u6001\u53d1\u73b0\u73af\u5883\uff0c\u4e3a\u5510\u6c0f\u7efc\u5408\u75c7\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2509.01616", "pdf": "https://arxiv.org/pdf/2509.01616", "abs": "https://arxiv.org/abs/2509.01616", "authors": ["Konstantinos Kitsios", "Marco Castelluccio", "Alberto Bacchelli"], "title": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing", "categories": ["cs.SE", "D.2.5"], "comment": "13 pages, 8 figures, accepted for publication (to appear) in the 40th\n  IEEE/ACM International Conference on Automated Software Engineering, ASE 2025", "summary": "Issue-reproducing tests fail on buggy code and pass once a patch is applied,\nthus increasing developers' confidence that the issue has been resolved and\nwill not be re-introduced. However, past research has shown that developers\noften commit patches without such tests, making the automated generation of\nissue-reproducing tests an area of interest. We propose BLAST, a tool for\nautomatically generating issue-reproducing tests from issue-patch pairs by\ncombining LLMs and search-based software testing (SBST). For the LLM part, we\ncomplement the issue description and the patch by extracting relevant context\nthrough git history analysis, static analysis, and SBST-generated tests. For\nthe SBST part, we adapt SBST for generating issue-reproducing tests; the issue\ndescription and the patch are fed into the SBST optimization through an\nintermediate LLM-generated seed, which we deserialize into SBST-compatible\nform. BLAST successfully generates issue-reproducing tests for 151/426 (35.4%)\nof the issues from a curated Python benchmark, outperforming the\nstate-of-the-art (23.5%). Additionally, to measure the real-world impact of\nBLAST, we built a GitHub bot that runs BLAST whenever a new pull request (PR)\nlinked to an issue is opened, and if BLAST generates an issue-reproducing test,\nthe bot proposes it as a comment in the PR. We deployed the bot in three\nopen-source repositories for three months, gathering data from 32 PRs-issue\npairs. BLAST generated an issue-reproducing test in 11 of these cases, which we\nproposed to the developers. By analyzing the developers' feedback, we discuss\nchallenges and opportunities for researchers and tool builders. Data and\nmaterial: https://doi.org/10.5281/zenodo.16949042", "AI": {"tldr": "BLAST\u662f\u4e00\u79cd\u7ed3\u5408LLM\u548cSBST\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u81ea\u52a8\u4ece\u95ee\u9898-\u8865\u4e01\u5bf9\u4e2d\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5f00\u53d1\u8005\u5e38\u5728\u4e0d\u5e26\u6d4b\u8bd5\u7684\u60c5\u51b5\u4e0b\u63d0\u4ea4\u8865\u4e01\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u4ee5\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\u3002", "method": "BLAST\u901a\u8fc7LLM\u7ed3\u5408git\u5386\u53f2\u5206\u6790\u3001\u9759\u6001\u5206\u6790\u548cSBST\u751f\u6210\u7684\u6d4b\u8bd5\uff0c\u8865\u5145\u95ee\u9898\u63cf\u8ff0\u548c\u8865\u4e01\u4fe1\u606f\uff0c\u5e76\u5229\u7528SBST\u4f18\u5316\u751f\u6210\u6d4b\u8bd5\u3002", "result": "BLAST\u5728426\u4e2aPython\u95ee\u9898\u4e2d\u6210\u529f\u751f\u6210\u4e86151\u4e2a\u6d4b\u8bd5\uff0835.4%\uff09\uff0c\u572832\u4e2aPR-\u95ee\u9898\u5bf9\u4e2d\u751f\u6210\u4e8611\u4e2a\u6d4b\u8bd5\u3002", "conclusion": "BLAST\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u7684\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6539\u8fdb\u4ee5\u9002\u5e94\u5f00\u53d1\u8005\u9700\u6c42\u3002"}}
{"id": "2509.02149", "pdf": "https://arxiv.org/pdf/2509.02149", "abs": "https://arxiv.org/abs/2509.02149", "authors": ["Jintao Liang", "Pablo G. Madoery", "Chung-Horng Lung", "Halim Yanikomeroglu", "Gunes Karabulut Kurt"], "title": "Green Traffic Engineering for Satellite Networks Using Segment Routing Flexible Algorithm", "categories": ["cs.NI", "cs.SY", "eess.SP", "eess.SY"], "comment": "Accepted for at GlobeCom 2025 GCSN", "summary": "Large-scale low-Earth-orbit (LEO) constellations demand routing that\nsimultaneously minimizes energy, guarantees delivery under congestion, and\nmeets latency requirements for time-critical flows. We present a segment\nrouting over IPv6 (SRv6) flexible algorithm (Flex-Algo) framework that consists\nof three logical slices: an energy-efficient slice (Algo 130), a\nhigh-reliability slice (Algo 129), and a latency-sensitive slice (Algo 128).\nThe framework provides a unified mixed-integer linear program (MILP) that\ncombines satellite CPU power, packet delivery rate (PDR), and end-to-end\nlatency into a single objective, allowing a lightweight software-defined\nnetwork (SDN) controller to steer traffic from the source node. Emulation of\nTelesat's Lightspeed constellation shows that, compared with different routing\nschemes, the proposed design reduces the average CPU usage by 73%, maintains a\nPDR above 91% during traffic bursts, and decreases urgent flow delay by 18 ms\nbetween Ottawa and Vancouver. The results confirm Flex-Algo's value as a\nslice-based traffic engineering (TE) tool for resource-constrained satellite\nnetworks.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSRv6 Flex-Algo\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u536b\u661f\u7f51\u7edc\u7684\u80fd\u6548\u3001\u53ef\u9760\u6027\u548c\u4f4e\u5ef6\u8fdf\u8def\u7531\u4f18\u5316\uff0c\u901a\u8fc7MILP\u7edf\u4e00\u76ee\u6807\u5b9e\u73b0\u8d44\u6e90\u9ad8\u6548\u5206\u914d\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21LEO\u661f\u5ea7\u7f51\u7edc\u4e2d\u540c\u65f6\u4f18\u5316\u80fd\u6e90\u6d88\u8017\u3001\u786e\u4fdd\u9ad8\u53ef\u9760\u6027\u548c\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u9700\u6c42\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528SRv6 Flex-Algo\u6846\u67b6\uff0c\u5206\u4e3a\u80fd\u6548\u3001\u9ad8\u53ef\u9760\u6027\u548c\u4f4e\u5ef6\u8fdf\u4e09\u4e2a\u903b\u8f91\u5207\u7247\uff0c\u7ed3\u5408MILP\u7edf\u4e00\u4f18\u5316\u76ee\u6807\uff0c\u5e76\u901a\u8fc7SDN\u63a7\u5236\u5668\u5b9e\u73b0\u6d41\u91cf\u8c03\u5ea6\u3002", "result": "\u5728Telesat Lightspeed\u661f\u5ea7\u7684\u4eff\u771f\u4e2d\uff0c\u5e73\u5747CPU\u4f7f\u7528\u7387\u964d\u4f4e73%\uff0c\u7a81\u53d1\u6d41\u91cf\u4e0bPDR\u4fdd\u6301\u572891%\u4ee5\u4e0a\uff0c\u5173\u952e\u6d41\u5ef6\u8fdf\u51cf\u5c1118ms\u3002", "conclusion": "Flex-Algo\u4f5c\u4e3a\u4e00\u79cd\u57fa\u4e8e\u5207\u7247\u7684TE\u5de5\u5177\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u536b\u661f\u7f51\u7edc\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2509.02144", "pdf": "https://arxiv.org/pdf/2509.02144", "abs": "https://arxiv.org/abs/2509.02144", "authors": ["Arthur Bran Herbener", "Malene Flensborg Damholdt"], "title": "A Theoretical Framework of the Processes of Change in Psychotherapy Delivered by Artificial Agents", "categories": ["cs.HC", "cs.AI"], "comment": "Submitted on 19 March 2025", "summary": "The question of whether artificial agents (e.g., chatbots and social robots)\ncan replace human therapists has received notable attention following the\nrecent launch of large language models. However, little is known about the\nprocesses of change in psychotherapy delivered by artificial agents. To\nfacilitate hypothesis development and stimulate scientific debate, the present\narticle offers the first theoretical framework of the processes of change in\npsychotherapy delivered by artificial agents. The theoretical framework rests\nupon a conceptual analysis of what active ingredients may be inherently linked\nto the presence of human therapists. We propose that human therapists'\nontological status as human beings and sociocultural status as socially\nsanctioned healthcare professionals play crucial roles in promoting treatment\noutcomes. In the absence of the ontological and sociocultural status of human\ntherapists, we propose what we coin the genuineness gap and credibility gap can\nemerge and undermine key processes of change in psychotherapy. Based on these\npropositions, we propose avenues for scientific investigations and practical\napplications aimed at leveraging the strengths of artificial agents and human\ntherapists respectively. We also highlight the intricate agentic nature of\nartificial agents and discuss how this complicates endeavors to establish\nuniversally applicable propositions regarding the processes of change in these\ninterventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5173\u4e8e\u7531\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u7684\u5fc3\u7406\u6cbb\u7597\u53d8\u5316\u8fc7\u7a0b\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63a2\u8ba8\u4e86\u4eba\u7c7b\u6cbb\u7597\u5e08\u4e0eAI\u4ee3\u7406\u5728\u6cbb\u7597\u8fc7\u7a0b\u4e2d\u7684\u5dee\u5f02\u53ca\u5176\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u51fa\uff0c\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u662f\u5426\u80fd\u66ff\u4ee3\u4eba\u7c7b\u6cbb\u7597\u5e08\u5f15\u53d1\u5173\u6ce8\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9AI\u4ee3\u7406\u63d0\u4f9b\u5fc3\u7406\u6cbb\u7597\u53d8\u5316\u8fc7\u7a0b\u7684\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u5206\u6790\uff0c\u7814\u7a76\u4e86\u4eba\u7c7b\u6cbb\u7597\u5e08\u7684\u67d0\u4e9b\u7279\u8d28\uff08\u5982\u672c\u4f53\u8bba\u548c\u793e\u4f1a\u6587\u5316\u5730\u4f4d\uff09\u5982\u4f55\u5f71\u54cd\u6cbb\u7597\u6548\u679c\uff0c\u5e76\u63d0\u51fa\u4e86\u201c\u771f\u8bda\u6027\u5dee\u8ddd\u201d\u548c\u201c\u53ef\u4fe1\u6027\u5dee\u8ddd\u201d\u7684\u6982\u5ff5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u6cbb\u7597\u5e08\u7684\u672c\u4f53\u8bba\u548c\u793e\u4f1a\u6587\u5316\u5730\u4f4d\u53ef\u80fd\u5bfc\u81f4\u6cbb\u7597\u6548\u679c\u7684\u5173\u952e\u53d8\u5316\u8fc7\u7a0b\u53d7\u963b\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u4e86\u672a\u6765\u79d1\u5b66\u7814\u7a76\u548c\u5b9e\u8df5\u5e94\u7528\u7684\u65b9\u5411\uff0c\u5f3a\u8c03\u7ed3\u5408AI\u4ee3\u7406\u548c\u4eba\u7c7b\u6cbb\u7597\u5e08\u7684\u5404\u81ea\u4f18\u52bf\uff0c\u5e76\u8ba8\u8bba\u4e86AI\u4ee3\u7406\u7684\u590d\u6742\u6027\u5bf9\u666e\u904d\u9002\u7528\u6027\u547d\u9898\u7684\u6311\u6218\u3002"}}
{"id": "2509.00217", "pdf": "https://arxiv.org/pdf/2509.00217", "abs": "https://arxiv.org/abs/2509.00217", "authors": ["Ruokai Yin", "Sattwik Deb Mishra", "Xuan Zuo", "Hokchhay Tann", "Preyas Shah", "Apala Guha"], "title": "Learning to Shard: RL for Co-optimizing the Parallelism Degrees and Per-operator Sharding Dimensions in Distributed LLM Inference", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Distributed LLM inference requires careful coordination of parallelization\nstrategies across hundreds to thousands of NPUs to meet production SLOs.\nCurrent systems like Megatron-LM rely on static heuristics that separately\nconfigure parallelism degrees and per-operator sharding dimensions, leaving\nsignificant performance on the table as models scale and hardware topologies\ndiversify. We introduce Learn to Shard, to our knowledge, the first RL-based\napproach to co-optimize both coarse-grained parallelism degrees and\nfine-grained per-operator sharding dimensions for distributed LLM inference.\nOur method employs an attention-based policy over an elite history that learns\nfrom high-performing strategies to efficiently navigate the vast combinatorial\nsearch space. Evaluated on H100 clusters with MoE models up to 1.6T parameters,\nLearn to Shard achieves up to 3.5x throughput improvement over metaheuristic\nbaselines and 1.06x over Megatron heuristics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLearn to Shard\u7684RL\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u5206\u5e03\u5f0fLLM\u63a8\u7406\u4e2d\u7684\u5e76\u884c\u6027\u7b56\u7565\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\uff08\u5982Megatron-LM\uff09\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u96be\u4ee5\u9002\u5e94\u6a21\u578b\u89c4\u6a21\u548c\u786c\u4ef6\u62d3\u6251\u7684\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u7c97\u7c92\u5ea6\u5e76\u884c\u5ea6\u4e0e\u7ec6\u7c92\u5ea6\u5206\u7247\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u7b56\u7565\u4ece\u9ad8\u6027\u80fd\u5386\u53f2\u4e2d\u5b66\u4e60\u3002", "result": "\u5728H100\u96c6\u7fa4\u4e0a\u6d4b\u8bd5\uff0c\u4f7f\u75281.6T\u53c2\u6570\u7684MoE\u6a21\u578b\uff0cLearn to Shard\u7684\u541e\u5410\u91cf\u6bd4\u5143\u542f\u53d1\u5f0f\u57fa\u7ebf\u63d0\u53473.5\u500d\uff0c\u6bd4Megatron\u542f\u53d1\u5f0f\u63d0\u53471.06\u500d\u3002", "conclusion": "Learn to Shard\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0fLLM\u63a8\u7406\u7684\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01946", "pdf": "https://arxiv.org/pdf/2509.01946", "abs": "https://arxiv.org/abs/2509.01946", "authors": ["Aarsh Shah", "Cleyton Magalhaes", "Kiev Gama", "Ronnie de Souza Santos"], "title": "Tether: A Personalized Support Assistant for Software Engineers with ADHD", "categories": ["cs.SE"], "comment": null, "summary": "Equity, diversity, and inclusion in software engineering often overlook\nneurodiversity, particularly the experiences of developers with Attention\nDeficit Hyperactivity Disorder (ADHD). Despite the growing awareness about that\npopulation in SE, few tools are designed to support their cognitive challenges\n(e.g., sustained attention, task initiation, self-regulation) within\ndevelopment workflows. We present Tether, an LLM-powered desktop application\ndesigned to support software engineers with ADHD by delivering adaptive,\ncontext-aware assistance. Drawing from engineering research methodology, Tether\ncombines local activity monitoring, retrieval-augmented generation (RAG), and\ngamification to offer real-time focus support and personalized dialogue. The\nsystem integrates operating system level system tracking to prompt engagement\nand its chatbot leverages ADHD-specific resources to offer relevant responses.\nPreliminary validation through self-use revealed improved contextual accuracy\nfollowing iterative prompt refinements and RAG enhancements. Tether\ndifferentiates itself from generic tools by being adaptable and aligned with\nsoftware-specific workflows and ADHD-related challenges. While not yet\nevaluated by target users, this work lays the foundation for future\nneurodiversity-aware tools in SE and highlights the potential of LLMs as\npersonalized support systems for underrepresented cognitive needs.", "AI": {"tldr": "Tether\u662f\u4e00\u6b3e\u4e13\u4e3aADHD\u5f00\u53d1\u8005\u8bbe\u8ba1\u7684LLM\u684c\u9762\u5e94\u7528\uff0c\u901a\u8fc7\u5b9e\u65f6\u76d1\u63a7\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u6e38\u620f\u5316\u63d0\u4f9b\u4e2a\u6027\u5316\u652f\u6301\uff0c\u521d\u6b65\u9a8c\u8bc1\u8868\u660e\u5176\u4e0a\u4e0b\u6587\u51c6\u786e\u6027\u6709\u6240\u63d0\u5347\uff0c\u672a\u6765\u6709\u671b\u6210\u4e3a\u795e\u7ecf\u591a\u6837\u6027\u5de5\u5177\u7684\u57fa\u7840\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u591a\u6837\u6027\u4e0e\u5305\u5bb9\u6027\u5e38\u5ffd\u89c6\u795e\u7ecf\u591a\u6837\u6027\uff0c\u5c24\u5176\u662fADHD\u5f00\u53d1\u8005\u7684\u8ba4\u77e5\u6311\u6218\u3002\u73b0\u6709\u5de5\u5177\u8f83\u5c11\u9488\u5bf9\u5176\u7279\u5b9a\u9700\u6c42\u8bbe\u8ba1\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86Tether\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7ed3\u5408\u672c\u5730\u6d3b\u52a8\u76d1\u63a7\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u6e38\u620f\u5316\uff0cTether\u63d0\u4f9b\u5b9e\u65f6\u4e13\u6ce8\u652f\u6301\u548c\u4e2a\u6027\u5316\u5bf9\u8bdd\uff0c\u96c6\u6210\u64cd\u4f5c\u7cfb\u7edf\u7ea7\u8ddf\u8e2a\u4ee5\u63d0\u793a\u4efb\u52a1\u53c2\u4e0e\u3002", "result": "\u521d\u6b65\u81ea\u6211\u9a8c\u8bc1\u8868\u660e\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u548cRAG\u589e\u5f3a\uff0c\u7cfb\u7edf\u7684\u4e0a\u4e0b\u6587\u51c6\u786e\u6027\u6709\u6240\u6539\u5584\u3002", "conclusion": "Tether\u4e3a\u672a\u6765\u795e\u7ecf\u591a\u6837\u6027\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86LLM\u4f5c\u4e3a\u4e2a\u6027\u5316\u652f\u6301\u7cfb\u7edf\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u672a\u88ab\u5145\u5206\u4ee3\u8868\u7684\u8ba4\u77e5\u9700\u6c42\u3002"}}
{"id": "2509.02317", "pdf": "https://arxiv.org/pdf/2509.02317", "abs": "https://arxiv.org/abs/2509.02317", "authors": ["Chenguang Du", "Chuyi Wang", "Yihan Chao", "Xiaohui Xie", "Yong Cui"], "title": "AI Agent Communication from Internet Architecture Perspective: Challenges and Opportunities", "categories": ["cs.NI"], "comment": "Work in Progress", "summary": "The rapid development of AI agents leads to a surge in communication demands.\nAlongside this rise, a variety of frameworks and protocols emerge. While these\nefforts demonstrate the vitality of the field, they also highlight increasing\nfragmentation, with redundant innovation and siloed designs hindering\ncross-domain interoperability. These challenges underscore the need for a\nsystematic perspective to guide the development of scalable, secure, and\nsustainable AI agent ecosystems. To address this need, this paper provides the\nfirst systematic analysis of AI agent communication from the standpoint of\nInternet architecture-the most successful global-scale distributed system in\nhistory. Specifically, we distill decades of Internet evolution into five key\nelements that are directly relevant to agent communication: scalability,\nsecurity, real-time performance, high performance, and manageability. We then\nuse these elements to examine both the opportunities and the bottlenecks in\ndeveloping robust multi-agent ecosystems. Overall, this paper bridges Internet\narchitecture and AI agent communication for the first time, providing a new\nlens for guiding the sustainable growth of AI agent communication ecosystems.", "AI": {"tldr": "\u672c\u6587\u4ece\u4e92\u8054\u7f51\u67b6\u6784\u7684\u89d2\u5ea6\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86AI\u4ee3\u7406\u901a\u4fe1\uff0c\u63d0\u51fa\u4e86\u4e94\u4e2a\u5173\u952e\u8981\u7d20\uff08\u53ef\u6269\u5c55\u6027\u3001\u5b89\u5168\u6027\u3001\u5b9e\u65f6\u6027\u80fd\u3001\u9ad8\u6027\u80fd\u548c\u7ba1\u7406\u6027\uff09\uff0c\u4ee5\u6307\u5bfc\u53ef\u6301\u7eed\u7684\u591a\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "AI\u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u901a\u4fe1\u9700\u6c42\u7684\u6fc0\u589e\uff0c\u4f46\u73b0\u6709\u7684\u6846\u67b6\u548c\u534f\u8bae\u5b58\u5728\u788e\u7247\u5316\u548c\u4e92\u64cd\u4f5c\u6027\u95ee\u9898\uff0c\u9700\u8981\u4ece\u7cfb\u7edf\u5316\u7684\u89d2\u5ea6\u6307\u5bfc\u53ef\u6301\u7eed\u7684\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\u3002", "method": "\u4ece\u5386\u53f2\u4e0a\u6700\u6210\u529f\u7684\u5168\u7403\u5206\u5e03\u5f0f\u7cfb\u7edf\u2014\u2014\u4e92\u8054\u7f51\u67b6\u6784\u4e2d\u63d0\u70bc\u51fa\u4e94\u4e2a\u5173\u952e\u8981\u7d20\uff08\u53ef\u6269\u5c55\u6027\u3001\u5b89\u5168\u6027\u3001\u5b9e\u65f6\u6027\u80fd\u3001\u9ad8\u6027\u80fd\u548c\u7ba1\u7406\u6027\uff09\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eAI\u4ee3\u7406\u901a\u4fe1\u7684\u5206\u6790\u3002", "result": "\u901a\u8fc7\u4e92\u8054\u7f51\u67b6\u6784\u7684\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u5f00\u53d1\u7a33\u5065\u591a\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u673a\u9047\u548c\u74f6\u9888\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5c06\u4e92\u8054\u7f51\u67b6\u6784\u4e0eAI\u4ee3\u7406\u901a\u4fe1\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u53ef\u6301\u7eed\u7684AI\u4ee3\u7406\u901a\u4fe1\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u6307\u5bfc\u89c6\u89d2\u3002"}}
{"id": "2509.02274", "pdf": "https://arxiv.org/pdf/2509.02274", "abs": "https://arxiv.org/abs/2509.02274", "authors": ["Stefan Schiffer", "Anna Milena Rothermel", "Alexander Ferrein", "Astrid Rosenthal-von der P\u00fctten"], "title": "Look: AI at Work! - Analysing Key Aspects of AI-support at the Work Place", "categories": ["cs.HC", "cs.AI"], "comment": "10 pages, accepted at the German Conference on Artificial\n  Intelligence KI 2024 Workshop \"HuMaIn\"", "summary": "In this paper we present an analysis of technological and psychological\nfactors of applying artificial intelligence (AI) at the work place. We do so\nfor a number of twelve application cases in the context of a project where AI\nis integrated at work places and in work systems of the future. From a\ntechnological point of view we mainly look at the areas of AI that the\napplications are concerned with. This allows to formulate recommendations in\nterms of what to look at in developing an AI application and what to pay\nattention to with regards to building AI literacy with different stakeholders\nusing the system. This includes the importance of high-quality data for\ntraining learning-based systems as well as the integration of human expertise,\nespecially with knowledge-based systems. In terms of the psychological factors\nwe derive research questions to investigate in the development of AI supported\nwork systems and to consider in future work, mainly concerned with topics such\nas acceptance, openness, and trust in an AI system.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u5de5\u4f5c\u573a\u6240\u5e94\u7528\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u7684\u6280\u672f\u548c\u5fc3\u7406\u56e0\u7d20\uff0c\u57fa\u4e8e12\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u5f00\u53d1AI\u5e94\u7528\u548c\u63d0\u5347AI\u7d20\u517b\u7684\u5efa\u8bae\uff0c\u5e76\u63a2\u8ba8\u4e86AI\u652f\u6301\u7684\u672a\u6765\u5de5\u4f5c\u7cfb\u7edf\u4e2d\u9700\u7814\u7a76\u7684\u5fc3\u7406\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8AI\u5728\u5de5\u4f5c\u573a\u6240\u5e94\u7528\u65f6\u6d89\u53ca\u7684\u6280\u672f\u6311\u6218\uff08\u5982\u9ad8\u8d28\u91cf\u6570\u636e\u548c\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u6574\u5408\uff09\u53ca\u5fc3\u7406\u56e0\u7d20\uff08\u5982\u63a5\u53d7\u5ea6\u4e0e\u4fe1\u4efb\uff09\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u901a\u8fc712\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u4ece\u6280\u672f\u548c\u5fc3\u7406\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790AI\u5728\u5de5\u4f5c\u573a\u6240\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5173\u6ce8AI\u76f8\u5173\u6280\u672f\u548c\u5fc3\u7406\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u603b\u7ed3\u4e86AI\u5e94\u7528\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u6280\u672f\u548cAI\u7d20\u517b\u63d0\u5347\u5efa\u8bae\uff0c\u5e76\u63d0\u51fa\u4e86\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5fc3\u7406\u95ee\u9898\uff08\u5982\u63a5\u53d7\u5ea6\u3001\u5f00\u653e\u6027\u548c\u4fe1\u4efb\uff09\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u5728\u5de5\u4f5c\u573a\u6240\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u6280\u672f\u548c\u5fc3\u7406\u5c42\u9762\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u8d28\u91cf\u3001\u4eba\u7c7b\u53c2\u4e0e\u548c\u5fc3\u7406\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.01947", "pdf": "https://arxiv.org/pdf/2509.01947", "abs": "https://arxiv.org/abs/2509.01947", "authors": ["Mahdi Farzandway", "Fatemeh Ghassemi"], "title": "Automated Repair of C Programs Using Large Language Models", "categories": ["cs.SE"], "comment": null, "summary": "This study explores the potential of Large Language Models (LLMs) in\nautomating the repair of C programs. We present a framework that integrates\nspectrum-based fault localization (SBFL), runtime feedback, and\nChain-of-Thought-structured prompting into an autonomous repair loop. Unlike\nprior approaches, our method explicitly combines statistical program analysis\nwith LLM reasoning. The iterative repair cycle leverages a structured\nChain-of-Thought (CoT) prompting approach, where the model reasons over failing\ntests, suspicious code regions, and prior patch outcomes, before generating new\ncandidate patches. The model iteratively changes the code, evaluates the\nresults, and incorporates reasoning from previous attempts into subsequent\nmodifications, reducing repeated errors and clarifying why some bugs remain\nunresolved. Our evaluation spans 3,902 bugs from the Codeflaws benchmark, where\nour approach achieves 44.93% repair accuracy, representing a 3.61% absolute\nimprovement over strong state-of-the-art APR baselines such as GPT-4 with CoT.\nThis outcome highlights a practical pathway toward integrating statistical\nprogram analysis with generative AI in automated debugging.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9891\u8c31\u5f0f\u6545\u969c\u5b9a\u4f4d\u3001\u8fd0\u884c\u65f6\u53cd\u9988\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u4fee\u590dC\u7a0b\u5e8f\uff0c\u5b9e\u73b0\u4e8644.93%\u7684\u4fee\u590d\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728C\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u4e2d\u7684\u6f5c\u529b\uff0c\u7ed3\u5408\u7edf\u8ba1\u7a0b\u5e8f\u5206\u6790\u548cLLM\u63a8\u7406\uff0c\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u8fed\u4ee3\u4fee\u590d\u5faa\u73af\uff0c\u5229\u7528\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u7ed3\u5408\u5931\u8d25\u6d4b\u8bd5\u3001\u53ef\u7591\u4ee3\u7801\u533a\u57df\u548c\u5148\u524d\u8865\u4e01\u7ed3\u679c\u751f\u6210\u65b0\u8865\u4e01\u3002", "result": "\u5728Codeflaws\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fee\u590d\u4e8644.93%\u7684\u6f0f\u6d1e\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\uff08\u5982GPT-4\u52a0\u601d\u7ef4\u94fe\uff09\u63d0\u5347\u4e863.61%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u7edf\u8ba1\u7a0b\u5e8f\u5206\u6790\u4e0e\u751f\u6210\u5f0fAI\u7ed3\u5408\u662f\u81ea\u52a8\u8c03\u8bd5\u7684\u53ef\u884c\u65b9\u5411\u3002"}}
{"id": "2509.02366", "pdf": "https://arxiv.org/pdf/2509.02366", "abs": "https://arxiv.org/abs/2509.02366", "authors": ["Tianwen Zhu", "Hao Wang", "Zhiwei Cao", "Jiarong Xi", "Yonggang Wen"], "title": "Towards Intelligent Battery Management via A Five-Tier Digital Twin Framework", "categories": ["cs.NI"], "comment": null, "summary": "Battery management systems (BMSs) are critical to ensuring safety,\nefficiency, and longevity across electronics, transportation, and energy\nstorage. However, with the rapid growth of lithium-ion batteries, conventional\nreactive BMS approaches face limitations in health prediction and advanced\nmaintenance management, resulting in increased safety risks and economic costs.\nTo address these challenges, we propose a five-tier digital twin framework for\nintelligent battery management. The framework spans geometric visualization,\npredictive modeling, prescriptive optimization, and autonomous operation,\nenabling full lifecycle optimization. In validation, an electrochemical model\ncalibrated via Bayesian optimization achieved strong alignment with measured\nvoltage and temperature, with Mean Absolute Percentage Errors (MAPE) below\n1.57\\% and 0.39\\%. A Physics-Informed Neural Network (PINN) then combined data\nand simulations to predict State of Health (SOH), attaining MAPE under 3\\% with\nquantified uncertainty. This framework elevates BMSs into intelligent systems\ncapable of proactive management and autonomous optimization, advancing safety\nand reliability in critical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e94\u5c42\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u7528\u4e8e\u667a\u80fd\u7535\u6c60\u7ba1\u7406\uff0c\u901a\u8fc7\u9884\u6d4b\u5efa\u6a21\u548c\u81ea\u4e3b\u64cd\u4f5c\u4f18\u5316\u7535\u6c60\u751f\u547d\u5468\u671f\u7ba1\u7406\u3002", "motivation": "\u4f20\u7edf\u53cd\u5e94\u5f0f\u7535\u6c60\u7ba1\u7406\u7cfb\u7edf\u5728\u5065\u5eb7\u9884\u6d4b\u548c\u9ad8\u7ea7\u7ef4\u62a4\u7ba1\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u589e\u52a0\u4e86\u5b89\u5168\u98ce\u9669\u548c\u7ecf\u6d4e\u6210\u672c\u3002", "method": "\u91c7\u7528\u4e94\u5c42\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u6821\u51c6\u7684\u7535\u5316\u5b66\u6a21\u578b\u548c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u8fdb\u884c\u5065\u5eb7\u72b6\u6001\u9884\u6d4b\u3002", "result": "\u7535\u5316\u5b66\u6a21\u578b\u7684\u7535\u538b\u548c\u6e29\u5ea6\u9884\u6d4b\u8bef\u5dee\u5206\u522b\u4f4e\u4e8e1.57%\u548c0.39%\uff0cPINN\u7684\u5065\u5eb7\u72b6\u6001\u9884\u6d4b\u8bef\u5dee\u4f4e\u4e8e3%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u7535\u6c60\u7ba1\u7406\u7cfb\u7edf\u63d0\u5347\u4e3a\u80fd\u591f\u4e3b\u52a8\u7ba1\u7406\u548c\u81ea\u4e3b\u4f18\u5316\u7684\u667a\u80fd\u7cfb\u7edf\uff0c\u63d0\u5347\u4e86\u5173\u952e\u5e94\u7528\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.02284", "pdf": "https://arxiv.org/pdf/2509.02284", "abs": "https://arxiv.org/abs/2509.02284", "authors": ["Hajnal Gyeviki", "Mih\u00e1ly Mink\u00f3", "Mary Karyda", "Damla \u00c7ay"], "title": "Balaton Borders: Data Ceramics for Ecological Reflection", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Balaton Borders translates ecological data from Lake Balaton into ceramic\ntableware that represents human impact on the landscape, from reedbed reduction\nto shoreline modification and land erosion. Designed for performative dining,\nthe pieces turn shared meals into multisensory encounters where food and data\nceramics spark collective reflection on ecological disruption.", "AI": {"tldr": "\u5c06\u751f\u6001\u6570\u636e\u8f6c\u5316\u4e3a\u9676\u74f7\u9910\u5177\uff0c\u901a\u8fc7\u5171\u4eab\u996e\u98df\u4f53\u9a8c\u5f15\u53d1\u5bf9\u751f\u6001\u7834\u574f\u7684\u53cd\u601d\u3002", "motivation": "\u901a\u8fc7\u827a\u672f\u4e0e\u751f\u6001\u6570\u636e\u7684\u7ed3\u5408\uff0c\u5524\u8d77\u4eba\u4eec\u5bf9\u4eba\u7c7b\u6d3b\u52a8\u5bf9\u81ea\u7136\u666f\u89c2\u5f71\u54cd\u7684\u5173\u6ce8\u3002", "method": "\u5c06Lake Balaton\u7684\u751f\u6001\u6570\u636e\uff08\u5982\u82a6\u82c7\u51cf\u5c11\u3001\u6d77\u5cb8\u7ebf\u53d8\u5316\u7b49\uff09\u8f6c\u5316\u4e3a\u9676\u74f7\u9910\u5177\uff0c\u5e76\u5728\u5171\u4eab\u9910\u996e\u4e2d\u4f7f\u7528\u3002", "result": "\u521b\u9020\u51fa\u4e00\u79cd\u591a\u611f\u5b98\u4f53\u9a8c\uff0c\u4fc3\u8fdb\u5bf9\u751f\u6001\u7834\u574f\u7684\u96c6\u4f53\u53cd\u601d\u3002", "conclusion": "\u827a\u672f\u4e0e\u751f\u6001\u6570\u636e\u7684\u7ed3\u5408\u80fd\u6709\u6548\u5f15\u53d1\u516c\u4f17\u5bf9\u73af\u5883\u95ee\u9898\u7684\u5173\u6ce8\u548c\u8ba8\u8bba\u3002"}}
{"id": "2509.02012", "pdf": "https://arxiv.org/pdf/2509.02012", "abs": "https://arxiv.org/abs/2509.02012", "authors": ["Katrine Christensen", "Mahsa Varshosaz", "Ra\u00fal Pardo"], "title": "ProbTest: Unit Testing for Probabilistic Programs (Extended Version)", "categories": ["cs.SE"], "comment": "Pre-print of paper to appear in the proceedings of the 23nd edition\n  of the International Conference on Software Engineering and Formal Methods\n  (SEFM'25)", "summary": "Testing probabilistic programs is non-trivial due to their stochastic nature.\nGiven an input, the program may produce different outcomes depending on the\nunderlying stochastic choices in the program. This means testing the expected\noutcomes of probabilistic programs requires repeated test executions unlike\ndeterministic programs where a single execution may suffice for each test\ninput. This raises the following question: how many times should we run a\nprobabilistic program to effectively test it? This work proposes a novel\nblack-box unit testing method, ProbTest, for testing the outcomes of\nprobabilistic programs. Our method is founded on the theory surrounding a\nwell-known combinatorial problem, the coupon collector's problem. Using this\nmethod, developers can write unit tests as usual without extra effort while the\nnumber of required test executions is determined automatically with statistical\nguarantees for the results. We implement ProbTest as a plug-in for PyTest, a\nwell-known unit testing tool for python programs. Using this plug-in,\ndevelopers can write unit tests similar to any other Python program and the\nnecessary test executions are handled automatically. We evaluate the method on\ncase studies from the Gymnasium reinforcement learning library and a randomized\ndata structure.", "AI": {"tldr": "ProbTest\u662f\u4e00\u79cd\u57fa\u4e8e\u4f18\u60e0\u5238\u6536\u96c6\u95ee\u9898\u7406\u8bba\u7684\u9ed1\u76d2\u5355\u5143\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u6982\u7387\u7a0b\u5e8f\u7684\u8f93\u51fa\u7ed3\u679c\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u50cf\u5e73\u5e38\u4e00\u6837\u7f16\u5199\u5355\u5143\u6d4b\u8bd5\uff0c\u65e0\u9700\u989d\u5916\u52aa\u529b\uff0c\u540c\u65f6\u81ea\u52a8\u786e\u5b9a\u6240\u9700\u7684\u6d4b\u8bd5\u6267\u884c\u6b21\u6570\u5e76\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u3002", "motivation": "\u7531\u4e8e\u6982\u7387\u7a0b\u5e8f\u7684\u968f\u673a\u6027\uff0c\u6d4b\u8bd5\u5176\u8f93\u51fa\u7ed3\u679c\u9700\u8981\u591a\u6b21\u6267\u884c\uff0c\u800c\u4f20\u7edf\u786e\u5b9a\u6027\u7a0b\u5e8f\u53ea\u9700\u5355\u6b21\u6267\u884c\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u786e\u5b9a\u8fd0\u884c\u6b21\u6570\u4ee5\u6709\u6548\u6d4b\u8bd5\u6982\u7387\u7a0b\u5e8f\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aProbTest\u7684\u9ed1\u76d2\u5355\u5143\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4f18\u60e0\u5238\u6536\u96c6\u95ee\u9898\u7406\u8bba\uff0c\u81ea\u52a8\u786e\u5b9a\u6d4b\u8bd5\u6267\u884c\u6b21\u6570\u5e76\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7PyTest\u63d2\u4ef6\u5b9e\u73b0\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u50cf\u7f16\u5199\u666e\u901aPython\u7a0b\u5e8f\u4e00\u6837\u7f16\u5199\u6d4b\u8bd5\u3002", "result": "\u5728Gymnasium\u5f3a\u5316\u5b66\u4e60\u5e93\u548c\u968f\u673a\u5316\u6570\u636e\u7ed3\u6784\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cProbTest\u88ab\u9a8c\u8bc1\u4e3a\u6709\u6548\u7684\u65b9\u6cd5\u3002", "conclusion": "ProbTest\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u4fbf\u4e14\u7edf\u8ba1\u53ef\u9760\u7684\u65b9\u5f0f\u6765\u6d4b\u8bd5\u6982\u7387\u7a0b\u5e8f\uff0c\u51cf\u5c11\u4e86\u5f00\u53d1\u8005\u7684\u624b\u52a8\u8d1f\u62c5\uff0c\u5e76\u80fd\u81ea\u52a8\u786e\u5b9a\u6d4b\u8bd5\u6b21\u6570\u3002"}}
{"id": "2509.02373", "pdf": "https://arxiv.org/pdf/2509.02373", "abs": "https://arxiv.org/abs/2509.02373", "authors": ["Francisco L\u00e1zaro", "\u010cedomir Stefanovi\u0107"], "title": "Tree algorithms for set reconciliation", "categories": ["cs.NI", "cs.DS", "cs.IT", "math.IT"], "comment": null, "summary": "In this work, a set reconciliation setting is considered in which two parties\nhave similar sets that they would like to reconcile. In particular, we focus on\na divide-and-conquer strategy known as partitioned set reconciliation (PSR), in\nwhich the sets to be reconciled are successively partitioned until they contain\na number of differences below some predetermined value. Borrowing techniques\nfrom tree-algorithms for random-access protocols, we present and analyze a\nnovel set reconciliation scheme that we term enhanced partitioned set\nreconciliation (EPSR). This approach improves the efficiency in terms of\noverhead, i.e., it yields a lower communication cost, while keeping the same\ntime and communication round complexity as PSR. Additionally, we simulate the\nperformance of the proposed algorithm in an event-driven simulator. Our\nfindings indicate that this novel protocol nearly halves the communication cost\nof PSR while maintaining the same time complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEPSR\u7684\u65b0\u578b\u96c6\u5408\u534f\u8c03\u65b9\u6848\uff0c\u901a\u8fc7\u5206\u533a\u7b56\u7565\u548c\u6811\u7b97\u6cd5\u6539\u8fdb\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5206\u533a\u96c6\u5408\u534f\u8c03(PSR)\u4e2d\u901a\u4fe1\u6210\u672c\u8f83\u9ad8\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5206\u533a\u7b56\u7565\u548c\u6811\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u589e\u5f3a\u5206\u533a\u96c6\u5408\u534f\u8c03(EPSR)\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u4e8b\u4ef6\u9a71\u52a8\u6a21\u62df\u5668\u8bc4\u4f30\u6027\u80fd\u3002", "result": "EPSR\u5c06PSR\u7684\u901a\u4fe1\u6210\u672c\u964d\u4f4e\u8fd1\u4e00\u534a\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "EPSR\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u6210\u672c\uff0c\u9002\u7528\u4e8e\u96c6\u5408\u534f\u8c03\u573a\u666f\u3002"}}
{"id": "2509.02367", "pdf": "https://arxiv.org/pdf/2509.02367", "abs": "https://arxiv.org/abs/2509.02367", "authors": ["Xuetong Wang", "Ching Christie Pang", "Pan Hui"], "title": "Talking Spell: A Wearable System Enabling Real-Time Anthropomorphic Voice Interaction with Everyday Objects", "categories": ["cs.HC"], "comment": null, "summary": "Virtual assistants (VAs) have become ubiquitous in daily life, integrated\ninto smartphones and smart devices, sparking interest in AI companions that\nenhance user experiences and foster emotional connections. However, existing\ncompanions are often embedded in specific objects-such as glasses, home\nassistants, or dolls-requiring users to form emotional bonds with unfamiliar\nitems, which can lead to reduced engagement and feelings of detachment. To\naddress this, we introduce Talking Spell, a wearable system that empowers users\nto imbue any everyday object with speech and anthropomorphic personas through a\nuser-centric radiative network. Leveraging advanced computer vision (e.g.,\nYOLOv11 for object detection), large vision-language models (e.g., QWEN-VL for\npersona generation), speech-to-text and text-to-speech technologies, Talking\nSpell guides users through three stages of emotional connection: acquaintance,\nfamiliarization, and bonding. We validated our system through a user study\ninvolving 12 participants, utilizing Talking Spell to explore four interaction\nintentions: entertainment, companionship, utility, and creativity. The results\ndemonstrate its effectiveness in fostering meaningful interactions and\nemotional significance with everyday objects. Our findings indicate that\nTalking Spell creates engaging and personalized experiences, as demonstrated\nthrough various devices, ranging from accessories to essential wearables.", "AI": {"tldr": "Talking Spell\u662f\u4e00\u79cd\u53ef\u7a7f\u6234\u7cfb\u7edf\uff0c\u901a\u8fc7\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u5927\u8bed\u8a00\u6a21\u578b\u6280\u672f\uff0c\u8d4b\u4e88\u65e5\u5e38\u7269\u54c1\u8bed\u97f3\u548c\u62df\u4eba\u5316\u7279\u5f81\uff0c\u5e2e\u52a9\u7528\u6237\u4e0e\u7269\u54c1\u5efa\u7acb\u60c5\u611f\u8fde\u63a5\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5de5\u667a\u80fd\u4f34\u4fa3\u901a\u5e38\u5d4c\u5165\u7279\u5b9a\u7269\u54c1\u4e2d\uff0c\u7528\u6237\u9700\u4e0e\u964c\u751f\u7269\u54c1\u5efa\u7acb\u60c5\u611f\u8054\u7cfb\uff0c\u5bfc\u81f4\u53c2\u4e0e\u5ea6\u964d\u4f4e\u548c\u758f\u79bb\u611f\u3002Talking Spell\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5229\u7528YOLOv11\u8fdb\u884c\u7269\u4f53\u68c0\u6d4b\uff0cQWEN-VL\u751f\u6210\u62df\u4eba\u5316\u89d2\u8272\uff0c\u7ed3\u5408\u8bed\u97f3\u6280\u672f\uff0c\u7cfb\u7edf\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\uff08\u8ba4\u8bc6\u3001\u719f\u6089\u3001\u7ed1\u5b9a\uff09\u5f15\u5bfc\u7528\u6237\u5efa\u7acb\u60c5\u611f\u8fde\u63a5\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cTalking Spell\u5728\u5a31\u4e50\u3001\u966a\u4f34\u3001\u5b9e\u7528\u548c\u521b\u9020\u529b\u56db\u4e2a\u65b9\u9762\u6709\u6548\u4fc3\u8fdb\u4e86\u7528\u6237\u4e0e\u7269\u54c1\u7684\u4e92\u52a8\u548c\u60c5\u611f\u8054\u7cfb\u3002", "conclusion": "Talking Spell\u901a\u8fc7\u4e2a\u6027\u5316\u4f53\u9a8c\u589e\u5f3a\u4e86\u7528\u6237\u4e0e\u65e5\u5e38\u7269\u54c1\u7684\u60c5\u611f\u4e92\u52a8\uff0c\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.00615", "pdf": "https://arxiv.org/pdf/2509.00615", "abs": "https://arxiv.org/abs/2509.00615", "authors": ["Narasimha Raghavan Veeraragavan", "Jan Franz Nyg\u00e5rd"], "title": "Federated Survival Analysis with Node-Level Differential Privacy: Private Kaplan-Meier Curves", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "comment": "This is the author's accepted version of the paper in IEEE FLTA 2025.\n  The final version of record will appear in Proceedings of the IEEE\n  International Conference on Federated Learning Technologies and Applications\n  (FLTA 2025)", "summary": "We investigate how to calculate Kaplan-Meier survival curves across multiple\nhealth-care jurisdictions while protecting patient privacy with node-level\ndifferential privacy. Each site discloses its curve only once, adding Laplace\nnoise whose scale is determined by the length of the common time grid; the\nserver then averages the noisy curves, so the overall privacy budget remains\nunchanged. We benchmark four one-shot smoothing techniques: Discrete Cosine\nTransform, Haar Wavelet shrinkage, adaptive Total-Variation denoising, and a\nparametric Weibull fit on the NCCTG lung-cancer cohort under five privacy\nlevels and three partition scenarios (uniform, moderately skewed, highly\nimbalanced). Total-Variation gives the best mean accuracy, whereas the\nfrequency-domain smoothers offer stronger worst-case robustness and the Weibull\nmodel shows the most stable behaviour at the strictest privacy setting. Across\nall methods the released curves keep the empirical log-rank type-I error below\nfifteen percent for privacy budgets of 0.5 and higher, demonstrating that\nclinically useful survival information can be shared without iterative training\nor heavy cryptography.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u7528\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u7684\u60a3\u8005\u6570\u636e\u8ba1\u7b97\u591a\u533a\u57dfKaplan-Meier\u66f2\u7ebf\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u5e73\u6ed1\u6280\u672f\uff0c\u663e\u793a\u5168\u53d8\u5dee\u65b9\u6cd5\u6700\u4f18\uff0c\u4e14\u5728\u9690\u79c1\u9884\u7b97\u8f83\u9ad8\u65f6\u4e34\u5e8a\u4fe1\u606f\u53ef\u5b89\u5168\u5171\u4eab\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\uff08\u901a\u8fc7\u8282\u70b9\u7ea7\u5dee\u5206\u9690\u79c1\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u8ba1\u7b97\u591a\u4e2a\u533b\u7597\u7ba1\u8f96\u533a\u7684Kaplan-Meier\u751f\u5b58\u66f2\u7ebf\u3002", "method": "\u6bcf\u4e2a\u7ad9\u70b9\u4ec5\u62ab\u9732\u4e00\u6b21\u5176\u66f2\u7ebf\uff0c\u5e76\u5728\u901a\u7528\u65f6\u95f4\u7f51\u683c\u957f\u5ea6\u51b3\u5b9a\u7684\u5c3a\u5ea6\u4e0a\u6dfb\u52a0Laplace\u566a\u58f0\uff1b\u670d\u52a1\u5668\u5bf9\u8fd9\u4e9b\u5e26\u566a\u58f0\u7684\u66f2\u7ebf\u8fdb\u884c\u5e73\u5747\uff0c\u4ece\u800c\u4fdd\u6301\u603b\u4f53\u9690\u79c1\u9884\u7b97\u4e0d\u53d8\u3002\u7814\u7a76\u6d4b\u8bd5\u4e86\u56db\u79cd\u4e00\u6b21\u5e73\u6ed1\u6280\u672f\uff1a\u79bb\u6563\u4f59\u5f26\u53d8\u6362\u3001Haar\u5c0f\u6ce2\u6536\u7f29\u3001\u81ea\u9002\u5e94\u5168\u53d8\u5dee\u53bb\u566a\u548c\u53c2\u6570Weibull\u62df\u5408\uff0c\u5e76\u5728\u4e94\u79cd\u9690\u79c1\u7ea7\u522b\u548c\u4e09\u79cd\u5206\u533a\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5168\u53d8\u5dee\u65b9\u6cd5\u5728\u5e73\u5747\u7cbe\u5ea6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u9891\u57df\u5e73\u6ed1\u65b9\u6cd5\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u800cWeibull\u6a21\u578b\u5728\u6700\u4e25\u683c\u7684\u9690\u79c1\u8bbe\u7f6e\u4e0b\u8868\u73b0\u6700\u7a33\u5b9a\u3002\u6240\u6709\u65b9\u6cd5\u5728\u9690\u79c1\u9884\u7b97\u4e3a0.5\u53ca\u4ee5\u4e0a\u65f6\uff0c\u91ca\u653e\u7684\u66f2\u7ebf\u5c06\u7ecf\u9a8c\u5bf9\u6570\u79e9I\u578b\u8bef\u5dee\u63a7\u5236\u572815%\u4ee5\u4e0b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u65e0\u9700\u8fed\u4ee3\u8bad\u7ec3\u6216\u590d\u6742\u52a0\u5bc6\u6280\u672f\uff0c\u5373\u53ef\u5171\u4eab\u5177\u6709\u4e34\u5e8a\u4ef7\u503c\u7684\u751f\u5b58\u4fe1\u606f\u3002"}}
{"id": "2509.02022", "pdf": "https://arxiv.org/pdf/2509.02022", "abs": "https://arxiv.org/abs/2509.02022", "authors": ["Bj\u00f8rnar Haugstad J\u00e5tten", "Simon Boye J\u00f8rgensen", "Rasmus Petersen", "Ra\u00fal Pardo"], "title": "Scalable Thread-Safety Analysis of Java Classes with CodeQL", "categories": ["cs.SE"], "comment": null, "summary": "In object-oriented languages software developers rely on thread-safe classes\nto implement concurrent applications. However, determining whether a class is\nthread-safe is a challenging task. This paper presents a highly scalable method\nto analyze thread-safety in Java classes. We provide a definition of\nthread-safety for Java classes founded on the correctness principle of the Java\nmemory model, data race freedom. We devise a set of properties for Java classes\nthat are proven to ensure thread-safety. We encode these properties in the\nstatic analysis tool CodeQL to automatically analyze Java source code. We\nperform an evaluation on the top 1000 GitHub repositories. The evaluation\ncomprises 3632865 Java classes; with 1992 classes annotated as @ThreadSafe from\n71 repositories. These repositories include highly popular software such as\nApache Flink (24.6k stars), Facebook Fresco (17.1k stars), PrestoDB (16.2k\nstarts), and gRPC (11.6k starts). Our queries detected thousands of\nthread-safety errors. The running time of our queries is below 2 minutes for\nrepositories up to 200k lines of code, 20k methods, 6000 fields, and 1200\nclasses. We have submitted a selection of detected concurrency errors as PRs,\nand developers positively reacted to these PRs. We have submitted our CodeQL\nqueries to the main CodeQL repository, and they are currently in the process of\nbecoming available as part of GitHub actions. The results demonstrate the\napplicability and scalability of our method to analyze thread-safety in\nreal-world code bases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u5ea6\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u5206\u6790Java\u7c7b\u7684\u7ebf\u7a0b\u5b89\u5168\u6027\uff0c\u57fa\u4e8eJava\u5185\u5b58\u6a21\u578b\u7684\u6b63\u786e\u6027\u539f\u5219\u5b9a\u4e49\u4e86\u7ebf\u7a0b\u5b89\u5168\uff0c\u5e76\u901a\u8fc7\u9759\u6001\u5206\u6790\u5de5\u5177CodeQL\u81ea\u52a8\u68c0\u6d4b\u4ee3\u7801\u3002", "motivation": "\u5728\u9762\u5411\u5bf9\u8c61\u8bed\u8a00\u4e2d\uff0c\u5f00\u53d1\u4eba\u5458\u4f9d\u8d56\u7ebf\u7a0b\u5b89\u5168\u7684\u7c7b\u6765\u5b9e\u73b0\u5e76\u53d1\u5e94\u7528\uff0c\u4f46\u5224\u65ad\u4e00\u4e2a\u7c7b\u662f\u5426\u7ebf\u7a0b\u5b89\u5168\u662f\u4e00\u9879\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u786e\u4fdd\u7ebf\u7a0b\u5b89\u5168\u7684\u4e00\u7ec4\u5c5e\u6027\uff0c\u5e76\u5c06\u5176\u7f16\u7801\u5230CodeQL\u4e2d\uff0c\u5bf9GitHub\u524d1000\u4e2a\u4ed3\u5e93\u4e2d\u7684Java\u7c7b\u8fdb\u884c\u4e86\u5206\u6790\u3002", "result": "\u57283632865\u4e2aJava\u7c7b\u4e2d\u68c0\u6d4b\u5230\u6570\u5343\u4e2a\u7ebf\u7a0b\u5b89\u5168\u9519\u8bef\uff0c\u8fd0\u884c\u65f6\u95f4\u77ed\uff0c\u5f00\u53d1\u8005\u5bf9\u63d0\u4ea4\u7684\u9519\u8bef\u4fee\u590dPR\u53cd\u5e94\u79ef\u6781\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u4ee3\u7801\u5e93\uff0c\u5177\u6709\u9ad8\u5ea6\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.02420", "pdf": "https://arxiv.org/pdf/2509.02420", "abs": "https://arxiv.org/abs/2509.02420", "authors": ["Fahim Bashar", "Asheesh Tripathi", "Mayukh Roy Chowdhury", "Aloizio Da Silva", "Alexandre Huff"], "title": "Inter-DU Load Balancing in an Experimental Over-the-Air 5G Open Radio Access Network", "categories": ["cs.NI"], "comment": null, "summary": "This paper presents the first ever fully open-source implementation of Load\nBalancing (LB) in an experimental Fifth Generation (5G) New Radio (NR)\nStandalone (SA) network using Open Radio Access Network (O-RAN) architecture.\nThe deployment leverages the O-RAN Software Community (SC) Near Real-Time RAN\nIntelligent Controller (Near-RT RIC), srsRAN stack, Open5GS core, and\nSoftware-Defined Radios (SDRs), with Commercial Off-The-Shelf (COTS) User\nEquipments (UEs). The implementation extends the srsRAN stack to support E2\nService Model for RAN Control (E2SM-RC) Style 3 Action 1 to facilitate\nHandovers (HOs) and adds Medium Access Control (MAC) downlink (DL) buffer\nvolume reporting to srsRAN's E2 Service Model for Key Performance Measurement\n(E2SM-KPM). The deployment demonstrates Near-RT RIC closed-loop control where\nour Mobility Load Balancing (MLB) xApp makes HO decisions based on network load\nmetrics for LB between two Open Distributed Units (O-DUs) operating at\ndifferent frequencies in the same band.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5b9e\u73b0\u4e86\u57fa\u4e8eO-RAN\u67b6\u6784\u76845G NR SA\u7f51\u7edc\u4e2d\u7684\u8d1f\u8f7d\u5747\u8861\uff08LB\uff09\u5168\u5f00\u6e90\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u95ed\u73af\u63a7\u5236\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u4e3a\u4e86\u9a8c\u8bc1\u5728\u5f00\u653e\u76845G\u7f51\u7edc\u4e2d\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\u7684\u53ef\u884c\u6027\uff0c\u540c\u65f6\u63a8\u52a8O-RAN\u67b6\u6784\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5229\u7528O-RAN SC\u7684Near-RT RIC\u3001srsRAN\u534f\u8bae\u6808\u3001Open5GS\u6838\u5fc3\u7f51\u53caSDR\u8bbe\u5907\uff0c\u6269\u5c55\u4e86srsRAN\u4ee5\u652f\u6301E2SM-RC\u548cE2SM-KPM\u7684\u8d1f\u8f7d\u5747\u8861\u529f\u80fd\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u7f51\u7edc\u8d1f\u8f7d\u6307\u6807\u7684\u79fb\u52a8\u8d1f\u8f7d\u5747\u8861\uff08MLB\uff09xApp\uff0c\u5728\u4e24\u4e2a\u9891\u6bb5\u4e0d\u540c\u7684O-DU\u4e4b\u95f4\u8fdb\u884c\u5207\u6362\u51b3\u7b56\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\u4e86O-RAN\u67b6\u6784\u4e0b\u8d1f\u8f7d\u5747\u8861\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u6e90\u57fa\u7840\u3002"}}
{"id": "2509.02537", "pdf": "https://arxiv.org/pdf/2509.02537", "abs": "https://arxiv.org/abs/2509.02537", "authors": ["Irene Zeng", "Neda Barbazi", "Ji Youn Shin", "Gurumurthy Hiremath", "Carlye Anne Lauff"], "title": "Octo's Heartland: Supporting Children with Congenital Heart Disease through Digital Health Education", "categories": ["cs.HC"], "comment": null, "summary": "Children with congenital heart disease (CHD) often face challenges that\nrequire them to understand complex medical information from an early age in\norder to support lifelong care and improve health outcomes. However, prior\nresearch has rarely included young children in designing and evaluating digital\ntools to support health education using developmentally appropriate strategies.\nThis study is part of a multi-phase research involving participatory design\n(PD), user testing, and iterative development. We present the design and\nrefinement of a digital application that introduces basic information about\nCHD, including heart anatomy and healthy habits, through metaphor-based\ngameplay. User testing sessions with 30 children informed the redesign of\ninteractive activities aligned with specific health conditions. Findings\nhighlight usability, engagement, and comprehension outcomes and reveal design\nopportunities for supporting health literacy through serious game (SG)\nprinciples. These results inform the next phase, including further testing,\nrefinement, and deployment in home and clinical settings.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5229\u7528\u9690\u55bb\u6e38\u620f\u8bbe\u8ba1\u6570\u5b57\u5e94\u7528\uff0c\u5e2e\u52a9\u5148\u5929\u6027\u5fc3\u810f\u75c5\u513f\u7ae5\u7406\u89e3\u533b\u5b66\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u6d4b\u8bd5\u4f18\u5316\u8bbe\u8ba1\u3002", "motivation": "\u5148\u5929\u6027\u5fc3\u810f\u75c5\u513f\u7ae5\u9700\u8981\u4ece\u65e9\u671f\u7406\u89e3\u590d\u6742\u533b\u5b66\u4fe1\u606f\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u4ed6\u4eec\u7684\u6570\u5b57\u5065\u5eb7\u5de5\u5177\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\uff08PD\uff09\u548c\u7528\u6237\u6d4b\u8bd5\uff0c\u5f00\u53d1\u4e86\u4e00\u6b3e\u57fa\u4e8e\u9690\u55bb\u6e38\u620f\u7684\u6570\u5b57\u5e94\u7528\uff0c\u5e76\u901a\u8fc730\u540d\u513f\u7ae5\u6d4b\u8bd5\u4f18\u5316\u3002", "result": "\u5e94\u7528\u5728\u53ef\u7528\u6027\u3001\u53c2\u4e0e\u5ea6\u548c\u7406\u89e3\u5ea6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u5c55\u73b0\u4e86\u901a\u8fc7\u4e25\u8083\u6e38\u620f\u63d0\u5347\u5065\u5eb7\u7d20\u517b\u7684\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u548c\u4f18\u5316\uff0c\u4ee5\u63a8\u5e7f\u81f3\u5bb6\u5ead\u548c\u4e34\u5e8a\u73af\u5883\u3002"}}
{"id": "2509.01322", "pdf": "https://arxiv.org/pdf/2509.01322", "abs": "https://arxiv.org/abs/2509.01322", "authors": ["Meituan LongCat Team", "Bayan", "Bei Li", "Bingye Lei", "Bo Wang", "Bolin Rong", "Chao Wang", "Chao Zhang", "Chen Gao", "Chen Zhang", "Cheng Sun", "Chengcheng Han", "Chenguang Xi", "Chi Zhang", "Chong Peng", "Chuan Qin", "Chuyu Zhang", "Cong Chen", "Congkui Wang", "Dan Ma", "Daoru Pan", "Defei Bu", "Dengchang Zhao", "Deyang Kong", "Dishan Liu", "Feiye Huo", "Fengcun Li", "Fubao Zhang", "Gan Dong", "Gang Liu", "Gang Xu", "Ge Li", "Guoqiang Tan", "Guoyuan Lin", "Haihang Jing", "Haomin Fu", "Haonan Yan", "Haoxing Wen", "Haozhe Zhao", "Hong Liu", "Hongmei Shi", "Hongyan Hao", "Hongyin Tang", "Huantian Lv", "Hui Su", "Jiacheng Li", "Jiahao Liu", "Jiahuan Li", "Jiajun Yang", "Jiaming Wang", "Jian Yang", "Jianchao Tan", "Jiaqi Sun", "Jiaqi Zhang", "Jiawei Fu", "Jiawei Yang", "Jiaxi Hu", "Jiayu Qin", "Jingang Wang", "Jiyuan He", "Jun Kuang", "Junhui Mei", "Kai Liang", "Ke He", "Kefeng Zhang", "Keheng Wang", "Keqing He", "Liang Gao", "Liang Shi", "Lianhui Ma", "Lin Qiu", "Lingbin Kong", "Lingtong Si", "Linkun Lyu", "Linsen Guo", "Liqi Yang", "Lizhi Yan", "Mai Xia", "Man Gao", "Manyuan Zhang", "Meng Zhou", "Mengxia Shen", "Mingxiang Tuo", "Mingyang Zhu", "Peiguang Li", "Peng Pei", "Peng Zhao", "Pengcheng Jia", "Pingwei Sun", "Qi Gu", "Qianyun Li", "Qingyuan Li", "Qiong Huang", "Qiyuan Duan", "Ran Meng", "Rongxiang Weng", "Ruichen Shao", "Rumei Li", "Shizhe Wu", "Shuai Liang", "Shuo Wang", "Suogui Dang", "Tao Fang", "Tao Li", "Tefeng Chen", "Tianhao Bai", "Tianhao Zhou", "Tingwen Xie", "Wei He", "Wei Huang", "Wei Liu", "Wei Shi", "Wei Wang", "Wei Wu", "Weikang Zhao", "Wen Zan", "Wenjie Shi", "Xi Nan", "Xi Su", "Xiang Li", "Xiang Mei", "Xiangyang Ji", "Xiangyu Xi", "Xiangzhou Huang", "Xianpeng Li", "Xiao Fu", "Xiao Liu", "Xiao Wei", "Xiaodong Cai", "Xiaolong Chen", "Xiaoqing Liu", "Xiaotong Li", "Xiaowei Shi", "Xiaoyu Li", "Xili Wang", "Xin Chen", "Xing Hu", "Xingyu Miao", "Xinyan He", "Xuemiao Zhang", "Xueyuan Hao", "Xuezhi Cao", "Xunliang Cai", "Xurui Yang", "Yan Feng", "Yang Bai", "Yang Chen", "Yang Yang", "Yaqi Huo", "Yerui Sun", "Yifan Lu", "Yifan Zhang", "Yipeng Zang", "Yitao Zhai", "Yiyang Li", "Yongjing Yin", "Yongkang Lv", "Yongwei Zhou", "Yu Yang", "Yuchen Xie", "Yueqing Sun", "Yuewen Zheng", "Yuhua Wei", "Yulei Qian", "Yunfan Liang", "Yunfang Tai", "Yunke Zhao", "Zeyang Yu", "Zhao Zhang", "Zhaohua Yang", "Zhenchao Zhang", "Zhikang Xia", "Zhiye Zou", "Zhizhao Zeng", "Zhongda Su", "Zhuofan Chen", "Zijian Zhang", "Ziwen Wang", "Zixu Jiang", "Zizhe Zhao", "Zongyu Wang", "Zunhai Su"], "title": "LongCat-Flash Technical Report", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE)\nlanguage model designed for both computational efficiency and advanced agentic\ncapabilities. Stemming from the need for scalable efficiency, LongCat-Flash\nadopts two novel designs: (a) Zero-computation Experts, which enables dynamic\ncomputational budget allocation and activates 18.6B-31.3B (27B on average) per\ntoken depending on contextual demands, optimizing resource usage. (b)\nShortcut-connected MoE, which enlarges the computation-communication overlap\nwindow, demonstrating notable gains in inference efficiency and throughput\ncompared to models of a comparable scale. We develop a comprehensive scaling\nframework for large models that combines hyperparameter transfer, model-growth\ninitialization, a multi-pronged stability suite, and deterministic computation\nto achieve stable and reproducible training. Notably, leveraging the synergy\namong scalable architectural design and infrastructure efforts, we complete\nmodel training on more than 20 trillion tokens within 30 days, while achieving\nover 100 tokens per second (TPS) for inference at a cost of \\$0.70 per million\noutput tokens. To cultivate LongCat-Flash towards agentic intelligence, we\nconduct a large-scale pre-training on optimized mixtures, followed by targeted\nmid- and post-training on reasoning, code, and instructions, with further\naugmentation from synthetic data and tool use tasks. Comprehensive evaluations\ndemonstrate that, as a non-thinking foundation model, LongCat-Flash delivers\nhighly competitive performance among other leading models, with exceptional\nstrengths in agentic tasks. The model checkpoint of LongCat-Flash is\nopen-sourced to foster community research.\n  LongCat Chat: https://longcat.ai\n  Hugging Face: https://huggingface.co/meituan-longcat\n  GitHub: https://github.com/meituan-longcat", "AI": {"tldr": "LongCat-Flash\u662f\u4e00\u4e2a5600\u4ebf\u53c2\u6570\u7684\u6df7\u5408\u4e13\u5bb6\u8bed\u8a00\u6a21\u578b\uff0c\u5f3a\u8c03\u8ba1\u7b97\u6548\u7387\u548c\u667a\u80fd\u4ee3\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u52a8\u6001\u8d44\u6e90\u5206\u914d\u548c\u9ad8\u6548\u63a8\u7406\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u7a33\u5b9a\u8bad\u7ec3\u548c\u9ad8\u6027\u80fd\u63a8\u65ad\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u667a\u80fd\u4ee3\u7406\u80fd\u529b\uff0c\u7814\u7a76\u56e2\u961f\u5f00\u53d1\u4e86LongCat-Flash\u6a21\u578b\u3002", "method": "\u91c7\u7528\u96f6\u8ba1\u7b97\u4e13\u5bb6\u548c\u5feb\u6377\u8fde\u63a5MoE\u8bbe\u8ba1\uff0c\u7ed3\u5408\u8d85\u53c2\u6570\u8f6c\u79fb\u3001\u6a21\u578b\u589e\u957f\u521d\u59cb\u5316\u7b49\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u8bad\u7ec3\u4e0e\u63a8\u7406\u3002", "result": "\u6a21\u578b\u572830\u5929\u5185\u5b8c\u6210\u4e8620\u4e07\u4ebftoken\u7684\u8bad\u7ec3\uff0c\u63a8\u65ad\u6027\u80fd\u8fbe\u5230\u6bcf\u79d2100token\uff0c\u5e76\u5728\u667a\u80fd\u4ee3\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "LongCat-Flash\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u5f00\u6e90\u6a21\u578b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u667a\u80fd\u4ee3\u7406\u4efb\u52a1\u3002"}}
{"id": "2509.02025", "pdf": "https://arxiv.org/pdf/2509.02025", "abs": "https://arxiv.org/abs/2509.02025", "authors": ["Junda He", "Zhou Yang", "Jieke Shi", "Chengran Yang", "Kisub Kim", "Bowen Xu", "Xin Zhou", "David Lo"], "title": "Curiosity-Driven Testing for Sequential Decision-Making Process", "categories": ["cs.SE"], "comment": "Update the Replication Package URL", "summary": "Sequential decision-making processes (SDPs) are fundamental for complex\nreal-world challenges, such as autonomous driving, robotic control, and traffic\nmanagement. While recent advances in Deep Learning (DL) have led to mature\nsolutions for solving these complex problems, SDMs remain vulnerable to\nlearning unsafe behaviors, posing significant risks in safety-critical\napplications. However, developing a testing framework for SDMs that can\nidentify a diverse set of crash-triggering scenarios remains an open challenge.\nTo address this, we propose CureFuzz, a novel curiosity-driven black-box fuzz\ntesting approach for SDMs. CureFuzz proposes a curiosity mechanism that allows\na fuzzer to effectively explore novel and diverse scenarios, leading to\nimproved detection of crashtriggering scenarios. Additionally, we introduce a\nmulti-objective seed selection technique to balance the exploration of novel\nscenarios and the generation of crash-triggering scenarios, thereby optimizing\nthe fuzzing process. We evaluate CureFuzz on various SDMs and experimental\nresults demonstrate that CureFuzz outperforms the state-of-the-art method by a\nsubstantial margin in the total number of faults and distinct types of\ncrash-triggering scenarios. We also demonstrate that the crash-triggering\nscenarios found by CureFuzz can repair SDMs, highlighting CureFuzz as a\nvaluable tool for testing SDMs and optimizing their performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCureFuzz\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\uff08SDMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u597d\u5947\u5fc3\u9a71\u52a8\u548c\u591a\u76ee\u6807\u79cd\u5b50\u9009\u62e9\u6280\u672f\uff0c\u6709\u6548\u53d1\u73b0\u591a\u6837\u5316\u7684\u89e6\u53d1\u5d29\u6e83\u573a\u666f\u3002", "motivation": "\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\uff08SDMs\uff09\u5728\u590d\u6742\u73b0\u5b9e\u95ee\u9898\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5bb9\u6613\u4ea7\u751f\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u8bc6\u522b\u591a\u6837\u5316\u5d29\u6e83\u89e6\u53d1\u573a\u666f\u7684\u6d4b\u8bd5\u6846\u67b6\u3002", "method": "\u63d0\u51faCureFuzz\u65b9\u6cd5\uff0c\u7ed3\u5408\u597d\u5947\u5fc3\u673a\u5236\u548c\u591a\u76ee\u6807\u79cd\u5b50\u9009\u62e9\u6280\u672f\uff0c\u4ee5\u4f18\u5316\u9ed1\u76d2\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u5d29\u6e83\u573a\u666f\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "result": "CureFuzz\u5728\u591a\u79cdSDMs\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d1\u73b0\u66f4\u591a\u6545\u969c\u548c\u591a\u6837\u5316\u7684\u5d29\u6e83\u89e6\u53d1\u573a\u666f\uff0c\u5e76\u80fd\u4fee\u590dSDMs\u3002", "conclusion": "CureFuzz\u662f\u4e00\u79cd\u6709\u6548\u7684\u6d4b\u8bd5\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u4f18\u5316SDMs\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2509.02551", "pdf": "https://arxiv.org/pdf/2509.02551", "abs": "https://arxiv.org/abs/2509.02551", "authors": ["Zifan Zhang", "Minghong Fang", "Mingzhe Chen", "Yuchen Liu"], "title": "On Transferring, Merging, and Splitting Task-Oriented Network Digital Twins", "categories": ["cs.NI", "cs.LG"], "comment": "Accepted by IEEE MobiWac 2025", "summary": "The integration of digital twinning technologies is driving next-generation\nnetworks toward new capabilities, allowing operators to thoroughly understand\nnetwork conditions, efficiently analyze valuable radio data, and innovate\napplications through user-friendly, immersive interfaces. Building on this\nfoundation, network digital twins (NDTs) accurately depict the operational\nprocesses and attributes of network infrastructures, facilitating predictive\nmanagement through real-time analysis and measurement. However, constructing\nprecise NDTs poses challenges, such as integrating diverse data sources,\nmapping necessary attributes from physical networks, and maintaining\nscalability for various downstream tasks. Unlike previous works that focused on\nthe creation and mapping of NDTs from scratch, we explore intra- and\ninter-operations among NDTs within a Unified Twin Transformation (UTT)\nframework, which uncovers a new computing paradigm for efficient transfer,\nmerging, and splitting of NDTs to create task-oriented twins. By leveraging\njoint multi-modal and distributed mapping mechanisms, UTT optimizes resource\nutilization and reduces the cost of creating NDTs, while ensuring twin model\nconsistency. A theoretical analysis of the distributed mapping problem is\nconducted to establish convergence bounds for this multi-modal gated\naggregation process. Evaluations on real-world twin-assisted applications, such\nas trajectory reconstruction, human localization, and sensory data generation,\ndemonstrate the feasibility and effectiveness of interoperability among NDTs\nfor corresponding task development.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\uff08NDTs\uff09\u4e2d\u901a\u8fc7\u7edf\u4e00\u5b6a\u751f\u8f6c\u6362\uff08UTT\uff09\u6846\u67b6\u5b9e\u73b0NDTs\u4e4b\u95f4\u7684\u4e92\u64cd\u4f5c\uff0c\u4ee5\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u548c\u964d\u4f4e\u521b\u5efa\u6210\u672c\uff0c\u540c\u65f6\u786e\u4fdd\u6a21\u578b\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524d\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\u6280\u672f\u9762\u4e34\u6570\u636e\u6574\u5408\u3001\u5c5e\u6027\u6620\u5c04\u548c\u53ef\u6269\u5c55\u6027\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u4f18\u5316NDTs\u7684\u4e92\u64cd\u4f5c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u5b6a\u751f\u8f6c\u6362\uff08UTT\uff09\u6846\u67b6\uff0c\u652f\u6301NDTs\u7684\u9ad8\u6548\u8f6c\u79fb\u3001\u5408\u5e76\u548c\u62c6\u5206\uff0c\u5e76\u5229\u7528\u591a\u6a21\u6001\u548c\u5206\u5e03\u5f0f\u6620\u5c04\u673a\u5236\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u5e94\u7528\uff08\u5982\u8f68\u8ff9\u91cd\u5efa\u3001\u4eba\u5458\u5b9a\u4f4d\uff09\u9a8c\u8bc1\u4e86UTT\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u53ef\u884c\u6027\u3002", "conclusion": "UTT\u6846\u67b6\u4e3a\u4efb\u52a1\u5bfc\u5411\u7684\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86NDTs\u7684\u4e92\u64cd\u4f5c\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.00167", "pdf": "https://arxiv.org/pdf/2509.00167", "abs": "https://arxiv.org/abs/2509.00167", "authors": ["W. F. Lamberti", "S. R. Lawrence", "D. White", "S. Kim", "S. Abdullah"], "title": "Pilot Study on Generative AI and Critical Thinking in Higher Education Classrooms", "categories": ["cs.CY", "cs.AI", "cs.HC", "stat.AP"], "comment": null, "summary": "Generative AI (GAI) tools have seen rapid adoption in educational settings,\nyet their role in fostering critical thinking remains underexplored. While\nprevious studies have examined GAI as a tutor for specific lessons or as a tool\nfor completing assignments, few have addressed how students critically evaluate\nthe accuracy and appropriateness of GAI-generated responses. This pilot study\ninvestigates students' ability to apply structured critical thinking when\nassessing Generative AI outputs in introductory Computational and Data Science\ncourses. Given that GAI tools often produce contextually flawed or factually\nincorrect answers, we designed learning activities that require students to\nanalyze, critique, and revise AI-generated solutions. Our findings offer\ninitial insights into students' ability to engage critically with GAI content\nand lay the groundwork for more comprehensive studies in future semesters.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u5bf9\u5b66\u751f\u6279\u5224\u6027\u601d\u7ef4\u7684\u57f9\u517b\u4f5c\u7528\u4ecd\u6709\u5f85\u63a2\u7d22\u3002\u672c\u7814\u7a76\u901a\u8fc7\u5b66\u751f\u5bf9AI\u751f\u6210\u5185\u5bb9\u7684\u8bc4\u4f30\uff0c\u521d\u6b65\u63a2\u8ba8\u4e86\u4ed6\u4eec\u5728\u8ba1\u7b97\u4e0e\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u4e2d\u7684\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u5f0fAI\u5728\u5b66\u751f\u6279\u5224\u6027\u601d\u7ef4\u57f9\u517b\u4e2d\u7684\u6f5c\u5728\u4f5c\u7528\uff0c\u5c24\u5176\u662f\u5728\u8bc4\u4f30AI\u751f\u6210\u5185\u5bb9\u7684\u51c6\u786e\u6027\u548c\u9002\u7528\u6027\u65b9\u9762\u3002", "method": "\u8bbe\u8ba1\u5b66\u4e60\u6d3b\u52a8\uff0c\u8981\u6c42\u5b66\u751f\u5206\u6790\u3001\u6279\u8bc4\u5e76\u4fee\u6539AI\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6d4b\u8bd5\u5176\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\u3002", "result": "\u521d\u6b65\u53d1\u73b0\u5b66\u751f\u5728\u6279\u5224\u6027\u8bc4\u4f30AI\u5185\u5bb9\u65b9\u9762\u5177\u6709\u4e00\u5b9a\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u66f4\u5168\u9762\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u6559\u80b2\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u66f4\u591a\u7814\u7a76\u6765\u4f18\u5316\u5176\u5728\u6279\u5224\u6027\u601d\u7ef4\u57f9\u517b\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2509.01434", "pdf": "https://arxiv.org/pdf/2509.01434", "abs": "https://arxiv.org/abs/2509.01434", "authors": ["Handi Chen", "Jing Deng", "Xiuzhe Wu", "Zhihan Jiang", "Xinchen Zhang", "Xianhao Chen", "Edith C. H. Ngai"], "title": "LiFeChain: Lightweight Blockchain for Secure and Efficient Federated Lifelong Learning in IoT", "categories": ["cs.CR", "cs.DC"], "comment": null, "summary": "The expansion of Internet of Things (IoT) devices constantly generates\nheterogeneous data streams, driving demand for continuous, decentralized\nintelligence. Federated Lifelong Learning (FLL) provides an ideal solution by\nincorporating federated and lifelong learning to overcome catastrophic\nforgetting. The extended lifecycle of FLL in IoT systems increases their\nvulnerability to persistent attacks, and these risks may be obscured by\nperformance degradation caused by spatial-temporal data heterogeneity.\nMoreover, this problem is exacerbated by the standard single-server\narchitecture, as its single point of failure makes it difficult to maintain a\nreliable audit trail for long-term threats. Blockchain provides a tamper-proof\nfoundation for trustworthy FLL systems. Nevertheless, directly applying\nblockchain to FLL significantly increases computational and retrieval costs\nwith the expansion of the knowledge base, slowing down the training on IoT\ndevices. To address these challenges, we propose LiFeChain, a lightweight\nblockchain for secure and efficient federated lifelong learning by providing a\ntamper-resistant ledger with minimal on-chain disclosure and bidirectional\nverification. To the best of our knowledge, LiFeChain is the first blockchain\ntailored for FLL. LiFeChain incorporates two complementary mechanisms: the\nproof-of-model-correlation (PoMC) consensus on the server, which couples\nlearning and unlearning mechanisms to mitigate negative transfer, and segmented\nzero-knowledge arbitration (Seg-ZA) on the client, which detects and arbitrates\nabnormal committee behavior without compromising privacy. LiFeChain is designed\nas a plug-and-play component that can be seamlessly integrated into existing\nFLL algorithms. Experimental results demonstrate that LiFeChain not only\nenhances model performance against two long-term attacks but also sustains high\nefficiency and scalability.", "AI": {"tldr": "LiFeChain\u662f\u4e00\u79cd\u4e13\u4e3a\u8054\u90a6\u7ec8\u8eab\u5b66\u4e60\uff08FLL\uff09\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u533a\u5757\u94fe\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u94fe\u4e0a\u62ab\u9732\u548c\u53cc\u5411\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u9632\u7be1\u6539\u8d26\u672c\uff0c\u89e3\u51b3\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\u957f\u671f\u653b\u51fb\u548c\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u751f\u6210\u5f02\u6784\u6570\u636e\u6d41\uff0c\u9700\u8981\u6301\u7eed\u53bb\u4e2d\u5fc3\u5316\u667a\u80fd\u89e3\u51b3\u65b9\u6848\u3002FLL\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u548c\u7ec8\u8eab\u5b66\u4e60\u4ee5\u514b\u670d\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u957f\u671f\u653b\u51fb\uff0c\u4e14\u6807\u51c6\u5355\u670d\u52a1\u5668\u67b6\u6784\u5b58\u5728\u5355\u70b9\u6545\u969c\u98ce\u9669\u3002", "method": "LiFeChain\u7ed3\u5408\u4e24\u79cd\u673a\u5236\uff1a\u670d\u52a1\u5668\u4e0a\u7684Proof-of-Model-Correlation\uff08PoMC\uff09\u5171\u8bc6\uff0c\u8026\u5408\u5b66\u4e60\u548c\u9057\u5fd8\u673a\u5236\u4ee5\u51cf\u5c11\u8d1f\u8fc1\u79fb\uff1b\u5ba2\u6237\u7aef\u7684\u5206\u6bb5\u96f6\u77e5\u8bc6\u4ef2\u88c1\uff08Seg-ZA\uff09\uff0c\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\u800c\u4e0d\u6cc4\u9732\u9690\u79c1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLiFeChain\u4e0d\u4ec5\u80fd\u62b5\u5fa1\u4e24\u79cd\u957f\u671f\u653b\u51fb\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "LiFeChain\u662f\u9996\u4e2a\u4e13\u4e3aFLL\u8bbe\u8ba1\u7684\u533a\u5757\u94fe\uff0c\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7ec4\u4ef6\u65e0\u7f1d\u96c6\u6210\u73b0\u6709\u7b97\u6cd5\uff0c\u63d0\u5347\u5b89\u5168\u6027\u4e0e\u6548\u7387\u3002"}}
{"id": "2509.02150", "pdf": "https://arxiv.org/pdf/2509.02150", "abs": "https://arxiv.org/abs/2509.02150", "authors": ["Pin Ji", "Yang Feng", "Zongtai Li", "Xiangchi Zhou", "Jia Liu", "Jun Sun", "Zhihong Zhao"], "title": "Txt2Sce: Scenario Generation for Autonomous Driving System Testing Based on Textual Reports", "categories": ["cs.SE"], "comment": null, "summary": "With the rapid advancement of deep learning and related technologies,\nAutonomous Driving Systems (ADSs) have made significant progress and are\ngradually being widely applied in safety-critical fields. However, numerous\naccident reports show that ADSs still encounter challenges in complex\nscenarios. As a result, scenario-based testing has become essential for\nidentifying defects and ensuring reliable performance. In particular,\nreal-world accident reports offer valuable high-risk scenarios for more\ntargeted ADS testing. Despite their potential, existing methods often rely on\nvisual data, which demands large memory and manual annotation. Additionally,\nsince existing methods do not adopt standardized scenario formats (e.g.,\nOpenSCENARIO), the generated scenarios are often tied to specific platforms and\nADS implementations, limiting their scalability and portability. To address\nthese challenges, we propose Txt2Sce, a method for generating test scenarios in\nOpenSCENARIO format based on textual accident reports. Txt2Sce first uses a LLM\nto convert textual accident reports into corresponding OpenSCENARIO scenario\nfiles. It then generates a derivation-based scenario file tree through scenario\ndisassembly, scenario block mutation, and scenario assembly. By utilizing the\nderivation relationships between nodes in the scenario tree, Txt2Sce helps\ndevelopers identify the scenario conditions that trigger unexpected behaviors\nof ADSs. In the experiments, we employ Txt2Sce to generate 33 scenario file\ntrees, resulting in a total of 4,373 scenario files for testing the open-source\nADS, Autoware. The experimental results show that Txt2Sce successfully converts\ntextual reports into valid OpenSCENARIO files, enhances scenario diversity\nthrough mutation, and effectively detects unexpected behaviors of Autoware in\nterms of safety, smartness, and smoothness.", "AI": {"tldr": "Txt2Sce\u662f\u4e00\u79cd\u57fa\u4e8e\u6587\u672c\u4e8b\u6545\u62a5\u544a\u751f\u6210OpenSCENARIO\u683c\u5f0f\u6d4b\u8bd5\u573a\u666f\u7684\u65b9\u6cd5\uff0c\u5229\u7528LLM\u8f6c\u6362\u6587\u672c\u5e76\u751f\u6210\u591a\u6837\u5316\u7684\u573a\u666f\u6587\u4ef6\u6811\uff0c\u6709\u6548\u68c0\u6d4b\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08\u5982Autoware\uff09\u7684\u5f02\u5e38\u884c\u4e3a\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u590d\u6742\u573a\u666f\u4e2d\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u73b0\u6709\u6d4b\u8bd5\u65b9\u6cd5\u4f9d\u8d56\u89c6\u89c9\u6570\u636e\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u683c\u5f0f\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002", "method": "Txt2Sce\u901a\u8fc7LLM\u5c06\u6587\u672c\u4e8b\u6545\u62a5\u544a\u8f6c\u6362\u4e3aOpenSCENARIO\u6587\u4ef6\uff0c\u7136\u540e\u901a\u8fc7\u573a\u666f\u5206\u89e3\u3001\u5757\u53d8\u5f02\u548c\u7ec4\u88c5\u751f\u6210\u573a\u666f\u6587\u4ef6\u6811\u3002", "result": "\u5b9e\u9a8c\u751f\u6210\u4e8633\u4e2a\u573a\u666f\u6587\u4ef6\u6811\uff08\u51714,373\u4e2a\u6587\u4ef6\uff09\uff0c\u6210\u529f\u68c0\u6d4b\u5230Autoware\u5728\u5b89\u5168\u6027\u3001\u667a\u80fd\u6027\u548c\u5e73\u7a33\u6027\u65b9\u9762\u7684\u5f02\u5e38\u884c\u4e3a\u3002", "conclusion": "Txt2Sce\u80fd\u9ad8\u6548\u751f\u6210\u6807\u51c6\u5316\u6d4b\u8bd5\u573a\u666f\uff0c\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\u7684\u591a\u6837\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2509.01257", "pdf": "https://arxiv.org/pdf/2509.01257", "abs": "https://arxiv.org/abs/2509.01257", "authors": ["Andrea Fox", "Francesco De Pellegrini", "Eitan Altman"], "title": "Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "Submitted at AI4NextG @ NeurIPS'25 Workshop", "summary": "In edge computing systems, autonomous agents must make fast local decisions\nwhile competing for shared resources. Existing MARL methods often resume to\ncentralized critics or frequent communication, which fail under limited\nobservability and communication constraints. We propose a decentralized\nframework in which each agent solves a constrained Markov decision process\n(CMDP), coordinating implicitly through a shared constraint vector. For the\nspecific case of offloading, e.g., constraints prevent overloading shared\nserver resources. Coordination constraints are updated infrequently and act as\na lightweight coordination mechanism. They enable agents to align with global\nresource usage objectives but require little direct communication. Using safe\nreinforcement learning, agents learn policies that meet both local and global\ngoals. We establish theoretical guarantees under mild assumptions and validate\nour approach experimentally, showing improved performance over centralized and\nindependent baselines, especially in large-scale settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u7ea6\u675f\u5411\u91cf\u5b9e\u73b0\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u81ea\u4e3b\u4ee3\u7406\u7684\u9690\u5f0f\u534f\u8c03\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6709\u9650\u53ef\u89c2\u6d4b\u6027\u548c\u901a\u4fe1\u9650\u5236\u4e0b\u7684\u4e0d\u8db3\u3002", "motivation": "\u5728\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e2d\uff0c\u81ea\u4e3b\u4ee3\u7406\u9700\u8981\u5728\u7ade\u4e89\u5171\u4eab\u8d44\u6e90\u65f6\u5feb\u901f\u505a\u51fa\u672c\u5730\u51b3\u7b56\uff0c\u4f46\u73b0\u6709\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u8bc4\u4f30\u6216\u9891\u7e41\u901a\u4fe1\uff0c\u65e0\u6cd5\u6ee1\u8db3\u53d7\u9650\u73af\u5883\u548c\u901a\u4fe1\u6761\u4ef6\u3002", "method": "\u6bcf\u4e2a\u4ee3\u7406\u901a\u8fc7\u89e3\u51b3\u7ea6\u675f\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08CMDP\uff09\uff0c\u5229\u7528\u5171\u4eab\u7ea6\u675f\u5411\u91cf\u5b9e\u73b0\u9690\u5f0f\u534f\u8c03\uff0c\u901a\u8fc7\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u540c\u65f6\u6ee1\u8db3\u672c\u5730\u548c\u5168\u5c40\u76ee\u6807\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u578b\u7cfb\u7edf\u4e2d\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u72ec\u7acb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u7684\u8f7b\u91cf\u7ea7\u534f\u8c03\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u517c\u5177\u9ad8\u6027\u80fd\u548c\u4f4e\u901a\u4fe1\u5f00\u9500\u3002"}}
{"id": "2509.00381", "pdf": "https://arxiv.org/pdf/2509.00381", "abs": "https://arxiv.org/abs/2509.00381", "authors": ["Runtong Wu", "Jiayao Song", "Fei Teng", "Xianhao Ren", "Yuyan Gao", "Kailun Yang"], "title": "Visually Grounded Narratives: Reducing Cognitive Burden in Researcher-Participant Interaction", "categories": ["cs.CV", "cs.HC"], "comment": null, "summary": "Narrative inquiry has been one of the prominent application domains for the\nanalysis of human experience, aiming to know more about the complexity of human\nsociety. However, researchers are often required to transform various forms of\ndata into coherent hand-drafted narratives in storied form throughout narrative\nanalysis, which brings an immense burden of data analysis. Participants, too,\nare expected to engage in member checking and presentation of these narrative\nproducts, which involves reviewing and responding to large volumes of\ndocuments. Given the dual burden and the need for more efficient and\nparticipant-friendly approaches to narrative making and representation, we made\na first attempt: (i) a new paradigm is proposed, NAME, as the initial attempt\nto push the field of narrative inquiry. Name is able to transfer research\ndocuments into coherent story images, alleviating the cognitive burden of\ninterpreting extensive text-based materials during member checking for both\nresearchers and participants. (ii) We develop an actor location and shape\nmodule to facilitate plausible image generation. (iii) We have designed a set\nof robust evaluation metrics comprising three key dimensions to objectively\nmeasure the perceptual quality and narrative consistency of generated\ncharacters. Our approach consistently demonstrates state-of-the-art performance\nacross different data partitioning schemes. Remarkably, while the baseline\nrelies on the full 100% of the available data, our method requires only 0.96%\nyet still reduces the FID score from 195 to 152. Under identical data volumes,\nour method delivers substantial improvements: for the 70:30 split, the FID\nscore decreases from 175 to 152, and for the 95:5 split, it is nearly halved\nfrom 96 to 49. Furthermore, the proposed model achieves a score of 3.62 on the\nnewly introduced metric, surpassing the baseline score of 2.66.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u8303\u5f0fNAME\uff0c\u5c06\u7814\u7a76\u6587\u6863\u8f6c\u5316\u4e3a\u6545\u4e8b\u56fe\u50cf\uff0c\u51cf\u8f7b\u4e86\u53d9\u4e8b\u5206\u6790\u4e2d\u6570\u636e\u89e3\u8bfb\u7684\u8d1f\u62c5\uff0c\u5e76\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u8bc4\u4f30\u6307\u6807\u63d0\u5347\u4e86\u751f\u6210\u56fe\u50cf\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u4f20\u7edf\u53d9\u4e8b\u5206\u6790\u9700\u8981\u5927\u91cf\u624b\u52a8\u5904\u7406\u6587\u672c\u6570\u636e\uff0c\u589e\u52a0\u4e86\u7814\u7a76\u8005\u548c\u53c2\u4e0e\u8005\u7684\u8d1f\u62c5\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u4e14\u53cb\u597d\u7684\u53d9\u4e8b\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86NAME\u8303\u5f0f\uff0c\u5305\u542b\u89d2\u8272\u5b9a\u4f4d\u4e0e\u5f62\u72b6\u751f\u6210\u6a21\u5757\uff0c\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8bc4\u4f30\u6307\u6807\u6765\u8861\u91cf\u751f\u6210\u56fe\u50cf\u7684\u611f\u77e5\u8d28\u91cf\u548c\u53d9\u4e8b\u4e00\u81f4\u6027\u3002", "result": "\u65b9\u6cd5\u5728\u6570\u636e\u91cf\u4ec5\u4e3a\u57fa\u7ebf0.96%\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u663e\u8457\u964d\u4f4e\u4e86FID\u5206\u6570\uff0c\u5e76\u5728\u4e0d\u540c\u6570\u636e\u5212\u5206\u65b9\u6848\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "NAME\u8303\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u53d9\u4e8b\u5206\u6790\u7684\u6548\u7387\u548c\u751f\u6210\u56fe\u50cf\u7684\u8d28\u91cf\uff0c\u4e3a\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2509.01683", "pdf": "https://arxiv.org/pdf/2509.01683", "abs": "https://arxiv.org/abs/2509.01683", "authors": ["Matej Steinbacher", "Mitja Steinbacher", "Matjaz Steinbacher"], "title": "The Impact of Sequential versus Parallel Clearing Mechanisms in Agent-Based Simulations of Artificial Limit Order Book Exchanges", "categories": ["q-fin.TR", "cs.DC"], "comment": null, "summary": "This study examines the impact of different computing implementations of\nclearing mechanisms on multi-asset price dynamics within an artificial stock\nmarket framework. We show that sequential processing of order books introduces\na systematic and significant bias by affecting the allocation of traders'\ncapital within a single time step. This occurs because applying budget\nconstraints sequentially grants assets processed earlier preferential access to\nfunds, distorting individual asset demand and consequently their price\ntrajectories. The findings highlight that while the overall price level is\nprimarily driven by macro factors like the money-to-stock ratio, the market's\nmicrostructural clearing mechanism plays a critical role in the allocation of\nvalue among individual assets. This underscores the necessity for careful\nconsideration and validation of clearing mechanisms in artificial markets to\naccurately model complex financial behaviors.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e0d\u540c\u6e05\u7b97\u673a\u5236\u5bf9\u591a\u8d44\u4ea7\u4ef7\u683c\u52a8\u6001\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u987a\u5e8f\u5904\u7406\u8ba2\u5355\u7c3f\u4f1a\u5f15\u5165\u7cfb\u7edf\u6027\u504f\u5dee\u3002", "motivation": "\u63a2\u8ba8\u6e05\u7b97\u673a\u5236\u5982\u4f55\u5f71\u54cd\u5e02\u573a\u4e2d\u8d44\u4ea7\u4ef7\u683c\u7684\u52a8\u6001\u548c\u8d44\u91d1\u5206\u914d\u3002", "method": "\u5728\u4eba\u5de5\u80a1\u7968\u5e02\u573a\u4e2d\u6a21\u62df\u4e0d\u540c\u6e05\u7b97\u673a\u5236\uff0c\u5206\u6790\u987a\u5e8f\u5904\u7406\u8ba2\u5355\u7c3f\u7684\u5f71\u54cd\u3002", "result": "\u987a\u5e8f\u6e05\u7b97\u4f1a\u5bfc\u81f4\u65e9\u671f\u5904\u7406\u7684\u8d44\u4ea7\u83b7\u5f97\u8d44\u91d1\u4f18\u5148\u6743\uff0c\u626d\u66f2\u4ef7\u683c\u8f68\u8ff9\u3002", "conclusion": "\u6e05\u7b97\u673a\u5236\u5728\u5e02\u573a\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u9700\u8c28\u614e\u8bbe\u8ba1\u548c\u9a8c\u8bc1\u4ee5\u51c6\u786e\u6a21\u62df\u91d1\u878d\u884c\u4e3a\u3002"}}
{"id": "2509.02221", "pdf": "https://arxiv.org/pdf/2509.02221", "abs": "https://arxiv.org/abs/2509.02221", "authors": ["Martin Skoglund", "Fredrik Warg", "Anders Thors\u00e9n", "Sasikumar Punnekkat", "Hans Hansson"], "title": "Formalizing Operational Design Domains with the Pkl Language", "categories": ["cs.SE"], "comment": "8 pages, 9 figures, IV 2025", "summary": "The deployment of automated functions that can operate without direct human\nsupervision has changed safety evaluation in domains seeking higher levels of\nautomation. Unlike conventional systems that rely on human operators, these\nfunctions require new assessment frameworks to demonstrate that they do not\nintroduce unacceptable risks under real-world conditions. To make a convincing\nsafety claim, the developer must present a thorough justification argument,\nsupported by evidence, that a function is free from unreasonable risk when\noperated in its intended context. The key concept relevant to the presented\nwork is the intended context, often captured by an Operational Design Domain\nspecification (ODD). ODD formalization is challenging due to the need to\nmaintain flexibility in adopting diverse specification formats while preserving\nconsistency and traceability and integrating seamlessly into the development,\nvalidation, and assessment. This paper presents a way to formalize an ODD in\nthe Pkl language, addressing central challenges in specifying ODDs while\nimproving usability through specialized configuration language features. The\napproach is illustrated with an automotive example but can be broadly applied\nto ensure rigorous assessments of operational contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528Pkl\u8bed\u8a00\u5f62\u5f0f\u5316\u64cd\u4f5c\u8bbe\u8ba1\u57df\uff08ODD\uff09\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3ODD\u89c4\u8303\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u6c7d\u8f66\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u5316\u529f\u80fd\u7684\u90e8\u7f72\uff0c\u4f20\u7edf\u4f9d\u8d56\u4eba\u5de5\u64cd\u4f5c\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u5df2\u4e0d\u9002\u7528\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u8bc1\u660e\u81ea\u52a8\u5316\u529f\u80fd\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u4e0d\u5f15\u5165\u4e0d\u53ef\u63a5\u53d7\u7684\u98ce\u9669\u3002", "method": "\u91c7\u7528Pkl\u8bed\u8a00\u5f62\u5f0f\u5316ODD\uff0c\u5229\u7528\u5176\u4e13\u95e8\u7684\u914d\u7f6e\u8bed\u8a00\u7279\u6027\u63d0\u9ad8\u53ef\u7528\u6027\uff0c\u540c\u65f6\u89e3\u51b3\u89c4\u8303\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u4e00\u81f4\u6027\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u6c7d\u8f66\u793a\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u786e\u4fdd\u5bf9\u64cd\u4f5c\u73af\u5883\u7684\u4e25\u683c\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u6c7d\u8f66\u9886\u57df\uff0c\u8fd8\u53ef\u5e7f\u6cdb\u7528\u4e8e\u5176\u4ed6\u9700\u8981\u4e25\u683c\u8bc4\u4f30\u64cd\u4f5c\u73af\u5883\u7684\u573a\u666f\u3002"}}
{"id": "2509.02130", "pdf": "https://arxiv.org/pdf/2509.02130", "abs": "https://arxiv.org/abs/2509.02130", "authors": ["Kim Hammar", "Rolf Stadler"], "title": "Online Identification of IT Systems through Active Causal Learning", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Identifying a causal model of an IT system is fundamental to many branches of\nsystems engineering and operation. Such a model can be used to predict the\neffects of control actions, optimize operations, diagnose failures, detect\nintrusions, etc., which is central to achieving the longstanding goal of\nautomating network and system management tasks. Traditionally, causal models\nhave been designed and maintained by domain experts. This, however, proves\nincreasingly challenging with the growing complexity and dynamism of modern IT\nsystems. In this paper, we present the first principled method for online,\ndata-driven identification of an IT system in the form of a causal model. The\nmethod, which we call active causal learning, estimates causal functions that\ncapture the dependencies among system variables in an iterative fashion using\nGaussian process regression based on system measurements, which are collected\nthrough a rollout-based intervention policy. We prove that this method is\noptimal in the Bayesian sense and that it produces effective interventions.\nExperimental validation on a testbed shows that our method enables accurate\nidentification of a causal system model while inducing low interference with\nsystem operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u4e3b\u52a8\u56e0\u679c\u5b66\u4e60\u7684\u5728\u7ebf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efaIT\u7cfb\u7edf\u7684\u56e0\u679c\u6a21\u578b\uff0c\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u548c\u57fa\u4e8e\u5e72\u9884\u7684\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u4f4e\u5e72\u6270\u7684\u6a21\u578b\u8bc6\u522b\u3002", "motivation": "\u4f20\u7edf\u7684\u56e0\u679c\u6a21\u578b\u4f9d\u8d56\u4e8e\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u4f46\u968f\u7740IT\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\u548c\u52a8\u6001\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u81ea\u52a8\u5316\u3001\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u56e0\u679c\u6a21\u578b\uff0c\u4ee5\u652f\u6301\u7cfb\u7edf\u9884\u6d4b\u3001\u4f18\u5316\u548c\u6545\u969c\u8bca\u65ad\u7b49\u4efb\u52a1\u3002", "method": "\u65b9\u6cd5\u91c7\u7528\u4e3b\u52a8\u56e0\u679c\u5b66\u4e60\uff0c\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u8fed\u4ee3\u4f30\u8ba1\u7cfb\u7edf\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u51fd\u6570\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u5e72\u9884\u7684\u7b56\u7565\u6536\u96c6\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8d1d\u53f6\u65af\u610f\u4e49\u4e0b\u6700\u4f18\uff0c\u5e76\u80fd\u751f\u6210\u6709\u6548\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u540c\u65f6\u5728\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u4f4e\u5e72\u6270\u6027\u3002", "conclusion": "\u4e3b\u52a8\u56e0\u679c\u5b66\u4e60\u65b9\u6cd5\u4e3a\u590d\u6742\u52a8\u6001IT\u7cfb\u7edf\u7684\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.00482", "pdf": "https://arxiv.org/pdf/2509.00482", "abs": "https://arxiv.org/abs/2509.00482", "authors": ["Saksorn Ruangtanusak", "Pittawat Taveekitworachai", "Kunat Pipatanakul"], "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "17 pages, 2 figures", "summary": "This report investigates approaches for prompting a tool-augmented large\nlanguage model (LLM) to act as a role-playing dialogue agent in the API track\nof the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this\nsetting, dialogue agents often produce overly long in-character responses\n(over-speaking) while failing to use tools effectively according to the persona\n(under-acting), such as generating function calls that do not exist or making\nunnecessary tool calls before answering. We explore four prompting approaches\nto address these issues: 1) basic role prompting, 2) human-crafted role\nprompting, 3) automatic prompt optimization (APO), and 4) rule-based role\nprompting. The rule-based role prompting (RRP) approach achieved the best\nperformance through two novel techniques--character-card/scene-contract design\nand strict enforcement of function calling--which led to an overall score of\n0.571, improving on the zero-shot baseline score of 0.519. These findings\ndemonstrate that RRP design can substantially improve the effectiveness and\nreliability of role-playing dialogue agents compared with more elaborate\nmethods such as APO. To support future efforts in developing persona prompts,\nwe are open-sourcing all of our best-performing prompts and the APO tool.\nSource code is available at https://github.com/scb-10x/apo.", "AI": {"tldr": "\u8be5\u62a5\u544a\u63a2\u8ba8\u4e86\u56db\u79cd\u63d0\u793a\u65b9\u6cd5\uff0c\u4ee5\u4f18\u5316\u5de5\u5177\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\uff0c\u5176\u4e2d\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u793a\u65b9\u6cd5\uff08RRP\uff09\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u4ee3\u7406\u4e2d\u8fc7\u5ea6\u53d1\u8a00\u548c\u5de5\u5177\u4f7f\u7528\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4e86\u56db\u79cd\u63d0\u793a\u65b9\u6cd5\uff1a\u57fa\u672c\u89d2\u8272\u63d0\u793a\u3001\u4eba\u5de5\u5236\u4f5c\u89d2\u8272\u63d0\u793a\u3001\u81ea\u52a8\u63d0\u793a\u4f18\u5316\uff08APO\uff09\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u89d2\u8272\u63d0\u793a\uff08RRP\uff09\u3002", "result": "RRP\u65b9\u6cd5\u901a\u8fc7\u65b0\u9896\u6280\u672f\uff08\u89d2\u8272\u5361/\u573a\u666f\u5408\u540c\u8bbe\u8ba1\u548c\u4e25\u683c\u51fd\u6570\u8c03\u7528\uff09\u53d6\u5f97\u6700\u4f73\u6548\u679c\uff0c\u4f18\u4e8e\u96f6\u6837\u672c\u57fa\u7ebf\u3002", "conclusion": "RRP\u8bbe\u8ba1\u663e\u8457\u63d0\u9ad8\u4e86\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u4ee3\u7406\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u4f18\u4e8e\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u5982APO\u3002"}}
{"id": "2509.01868", "pdf": "https://arxiv.org/pdf/2509.01868", "abs": "https://arxiv.org/abs/2509.01868", "authors": ["Komala Subramanyam Cherukuri", "Kewei Sha", "Zhenhua Huang"], "title": "Enabling Federated Object Detection for Connected Autonomous Vehicles: A Deployment-Oriented Evaluation", "categories": ["cs.CV", "cs.DC"], "comment": null, "summary": "Object detection is crucial for Connected Autonomous Vehicles (CAVs) to\nperceive their surroundings and make safe driving decisions. Centralized\ntraining of object detection models often achieves promising accuracy, fast\nconvergence, and simplified training process, but it falls short in\nscalability, adaptability, and privacy-preservation. Federated learning (FL),\nby contrast, enables collaborative, privacy-preserving, and continuous training\nacross naturally distributed CAV fleets. However, deploying FL in real-world\nCAVs remains challenging due to the substantial computational demands of\ntraining and inference, coupled with highly diverse operating conditions.\nPractical deployment must address three critical factors: (i) heterogeneity\nfrom non-IID data distributions, (ii) constrained onboard computing hardware,\nand (iii) environmental variability such as lighting and weather, alongside\nsystematic evaluation to ensure reliable performance. This work introduces the\nfirst holistic deployment-oriented evaluation of FL-based object detection in\nCAVs, integrating model performance, system-level resource profiling, and\nenvironmental robustness. Using state-of-the-art detectors, YOLOv5, YOLOv8,\nYOLOv11, and Deformable DETR, evaluated on the KITTI, BDD100K, and nuScenes\ndatasets, we analyze trade-offs between detection accuracy, computational cost,\nand resource usage under diverse resolutions, batch sizes, weather and lighting\nconditions, and dynamic client participation, paving the way for robust FL\ndeployment in CAVs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8fde\u63a5\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08CAVs\uff09\u4e2d\u4f7f\u7528\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u53ef\u884c\u6027\u548c\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u90e8\u7f72\u5bfc\u5411\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u6a21\u578b\u6027\u80fd\u3001\u7cfb\u7edf\u8d44\u6e90\u5206\u6790\u548c\u73af\u5883\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5728\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u800c\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u5206\u5e03\u5f0f\u534f\u4f5c\u8bad\u7ec3\u7684\u53ef\u80fd\u6027\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4ecd\u9762\u4e34\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u548c\u73af\u5883\u591a\u6837\u6027\u7b49\u6311\u6218\u3002", "method": "\u7814\u7a76\u91c7\u7528YOLOv5\u3001YOLOv8\u3001YOLOv11\u548cDeformable DETR\u7b49\u5148\u8fdb\u68c0\u6d4b\u5668\uff0c\u5728KITTI\u3001BDD100K\u548cnuScenes\u6570\u636e\u96c6\u4e0a\uff0c\u901a\u8fc7\u591a\u5206\u8fa8\u7387\u3001\u6279\u91cf\u5927\u5c0f\u3001\u73af\u5883\u6761\u4ef6\u548c\u52a8\u6001\u5ba2\u6237\u7aef\u53c2\u4e0e\u4e0b\u7684\u5b9e\u9a8c\u5206\u6790FL\u90e8\u7f72\u7684\u6743\u8861\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5728\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u3001\u8ba1\u7b97\u6210\u672c\u548c\u8d44\u6e90\u4f7f\u7528\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e3aCAVs\u4e2dFL\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u672c\u7814\u7a76\u4e3a\u5728CAVs\u4e2d\u5b9e\u73b0\u9c81\u68d2\u7684\u8054\u90a6\u5b66\u4e60\u76ee\u6807\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u8df5\u8def\u5f84\uff0c\u5f3a\u8c03\u4e86\u591a\u65b9\u6743\u8861\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.02311", "pdf": "https://arxiv.org/pdf/2509.02311", "abs": "https://arxiv.org/abs/2509.02311", "authors": ["Martin Skoglund", "Fredrik Warg", "Anders Thoren", "Sasikumar Punnekkat", "Hans Hansson"], "title": "Methodology for Test Case Allocation based on a Formalized ODD", "categories": ["cs.SE"], "comment": "12 pages, 8 figures, DECSoS, SAFECOMP 2025", "summary": "The emergence of Connected, Cooperative, and Automated Mobility (CCAM)\nsystems has significantly transformed the safety assessment landscape. Because\nthey integrate automated vehicle functions beyond those managed by a human\ndriver, new methods are required to evaluate their safety. Approaches that\ncompile evidence from multiple test environments have been proposed for\ntype-approval and similar evaluations, emphasizing scenario coverage within the\nsystems Operational Design Domain (ODD). However, aligning diverse test\nenvironment requirements with distinct testing capabilities remains\nchallenging. This paper presents a method for evaluating the suitability of\ntest case allocation to various test environments by drawing on and extending\nan existing ODD formalization with key testing attributes. The resulting\nconstruct integrates ODD parameters and additional test attributes to capture a\ngiven test environments relevant capabilities. This approach supports automatic\nsuitability evaluation and is demonstrated through a case study on an automated\nreversing truck function. The system's implementation fidelity is tied to ODD\nparameters, facilitating automated test case allocation based on each\nenvironments capacity for object-detection sensor assessment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6269\u5c55ODD\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u8bc4\u4f30\u6d4b\u8bd5\u6848\u4f8b\u5728\u4e0d\u540c\u6d4b\u8bd5\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u6d4b\u8bd5\u6848\u4f8b\u5206\u914d\u3002", "motivation": "\u968f\u7740CCAM\u7cfb\u7edf\u7684\u51fa\u73b0\uff0c\u4f20\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u5df2\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5176\u5b89\u5168\u6027\u3002\u4e0d\u540c\u6d4b\u8bd5\u73af\u5883\u7684\u80fd\u529b\u548c\u9700\u6c42\u5b58\u5728\u5dee\u5f02\uff0c\u5982\u4f55\u5bf9\u9f50\u8fd9\u4e9b\u5dee\u5f02\u662f\u4e00\u9879\u6311\u6218\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u73b0\u6709\u7684ODD\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u6574\u5408ODD\u53c2\u6570\u548c\u6d4b\u8bd5\u5c5e\u6027\uff0c\u4ee5\u6355\u83b7\u6d4b\u8bd5\u73af\u5883\u7684\u76f8\u5173\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u81ea\u52a8\u5316\u7684\u9002\u7528\u6027\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u81ea\u52a8\u5012\u8f66\u5361\u8f66\u529f\u80fd\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7cfb\u7edf\u5b9e\u73b0\u7cbe\u5ea6\u4e0eODD\u53c2\u6570\u7ed1\u5b9a\uff0c\u652f\u6301\u57fa\u4e8e\u73af\u5883\u80fd\u529b\u7684\u6d4b\u8bd5\u6848\u4f8b\u81ea\u52a8\u5206\u914d\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3aCCAM\u7cfb\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6d4b\u8bd5\u6848\u4f8b\u5206\u914d\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6d4b\u8bd5\u73af\u5883\u591a\u6837\u6027\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2509.02395", "pdf": "https://arxiv.org/pdf/2509.02395", "abs": "https://arxiv.org/abs/2509.02395", "authors": ["Christo Kurisummoottil Thomas", "Omar Hashash", "Kimia Ehsani", "Walid Saad"], "title": "Next-Generation Sustainable Wireless Systems: Energy Efficiency Meets Environmental Impact", "categories": ["cs.IT", "cs.NI", "math.IT"], "comment": null, "summary": "Aligning with the global mandates pushing towards advanced technologies with\nreduced resource consumption and environmental impacts, the sustainability of\nwireless networks becomes a significant concern in 6G systems. To address this\nconcern, a native integration of sustainability into the operations of\nnext-generation networks through novel designs and metrics is necessary.\nNevertheless, existing wireless sustainability efforts remain limited to\nenergy-efficient network designs which fail to capture the environmental impact\nof such systems. In this paper, a novel sustainability metric is proposed that\ncaptures emissions per bit, providing a rigorous measure of the environmental\nfoot- print associated with energy consumption in 6G networks. This metric also\ncaptures how energy, computing, and communication resource parameters influence\nthe reduction of emissions per bit. Then, the problem of allocating the energy,\ncomputing and communication resources is posed as a multi-objective (MO)\noptimization problem. To solve the resulting non-convex problem, our framework\nleverages MO reinforcement learning (MORL) to maximize the novel sustainability\nmetric alongside minimizing energy consumption and average delays in\nsuccessfully delivering the data, all while adhering to constraints on energy\nresource capacity. The proposed MORL methodology computes a global policy that\nachieves a Pareto-optimal tradeoff among multiple objectives, thereby balancing\nenvironmental sustainability with network performance. Simulation results show\nthat the proposed approach reduces the average emissions per bit by around 26%\ncompared to state-of-the-art methods that do not explicitly integrate carbon\nemissions into their control objectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u6301\u7eed\u6027\u6307\u6807\uff08\u6bcf\u6bd4\u7279\u6392\u653e\u91cf\uff09\uff0c\u5e76\u901a\u8fc7\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4f18\u53166G\u7f51\u7edc\u7684\u8d44\u6e90\u5206\u914d\uff0c\u5e73\u8861\u73af\u5883\u53ef\u6301\u7eed\u6027\u4e0e\u7f51\u7edc\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65e0\u7ebf\u7f51\u7edc\u7684\u53ef\u6301\u7eed\u6027\u8bbe\u8ba1\u4ec5\u5173\u6ce8\u80fd\u6548\uff0c\u672a\u80fd\u5168\u9762\u8861\u91cf\u73af\u5883\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u6307\u6807\u548c\u65b9\u6cd5\u6765\u6574\u5408\u53ef\u6301\u7eed\u6027\u3002", "method": "\u7ed3\u5408\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff08MORL\uff09\u4f18\u5316\u80fd\u6e90\u3001\u8ba1\u7b97\u548c\u901a\u4fe1\u8d44\u6e90\u7684\u5206\u914d\uff0c\u4ee5\u6bcf\u6bd4\u7279\u6392\u653e\u91cf\u4e3a\u5173\u952e\u6307\u6807\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u6280\u672f\u5e73\u5747\u51cf\u5c1126%\u7684\u6bcf\u6bd4\u7279\u6392\u653e\u91cf\u3002", "conclusion": "\u901a\u8fc7\u65b0\u6307\u6807\u548cMORL\u6846\u67b6\uff0c\u6210\u529f\u57286G\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4e86\u73af\u5883\u53ef\u6301\u7eed\u6027\u4e0e\u6027\u80fd\u7684\u5e73\u8861\u3002"}}
{"id": "2509.00575", "pdf": "https://arxiv.org/pdf/2509.00575", "abs": "https://arxiv.org/abs/2509.00575", "authors": ["Himanshu Verma", "Kirtan Path", "Eva Thelisson"], "title": "Can AI be Auditable?", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Auditability is defined as the capacity of AI systems to be independently\nassessed for compliance with ethical, legal, and technical standards throughout\ntheir lifecycle. The chapter explores how auditability is being formalized\nthrough emerging regulatory frameworks, such as the EU AI Act, which mandate\ndocumentation, risk assessments, and governance structures. It analyzes the\ndiverse challenges facing AI auditability, including technical opacity,\ninconsistent documentation practices, lack of standardized audit tools and\nmetrics, and conflicting principles within existing responsible AI frameworks.\nThe discussion highlights the need for clear guidelines, harmonized\ninternational regulations, and robust socio-technical methodologies to\noperationalize auditability at scale. The chapter concludes by emphasizing the\nimportance of multi-stakeholder collaboration and auditor empowerment in\nbuilding an effective AI audit ecosystem. It argues that auditability must be\nembedded in AI development practices and governance infrastructures to ensure\nthat AI systems are not only functional but also ethically and legally aligned.", "AI": {"tldr": "AI\u7cfb\u7edf\u7684\u53ef\u5ba1\u8ba1\u6027\u9700\u8981\u72ec\u7acb\u8bc4\u4f30\u5176\u5408\u89c4\u6027\uff0c\u53d7\u6cd5\u89c4\u63a8\u52a8\u4f46\u4ecd\u9762\u4e34\u6280\u672f\u548c\u7ba1\u7406\u6311\u6218\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u6cd5\u89c4\u548c\u534f\u4f5c\u786e\u4fddAI\u7cfb\u7edf\u5728\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u6280\u672f\u4e0a\u7684\u5408\u89c4\u6027\u3002", "method": "\u5206\u6790\u73b0\u6709\u6cd5\u89c4\uff08\u5982\u6b27\u76dfAI\u6cd5\u6848\uff09\u548c\u6311\u6218\uff08\u5982\u6280\u672f\u4e0d\u900f\u660e\u3001\u7f3a\u4e4f\u6807\u51c6\u5de5\u5177\uff09\u3002", "result": "\u9700\u8981\u6e05\u6670\u7684\u6307\u5357\u3001\u56fd\u9645\u534f\u8c03\u548c\u591a\u65b9\u534f\u4f5c\u6765\u5b9e\u73b0\u6709\u6548\u7684AI\u5ba1\u8ba1\u751f\u6001\u3002", "conclusion": "\u53ef\u5ba1\u8ba1\u6027\u5fc5\u987b\u878d\u5165AI\u5f00\u53d1\u548c\u6cbb\u7406\uff0c\u4ee5\u786e\u4fdd\u7cfb\u7edf\u529f\u80fd\u548c\u4f26\u7406\u6cd5\u5f8b\u4e00\u81f4\u3002"}}
{"id": "2509.02330", "pdf": "https://arxiv.org/pdf/2509.02330", "abs": "https://arxiv.org/abs/2509.02330", "authors": ["Yicong Zhao", "Shisong Chen", "Jiacheng Zhang", "Zhixu Li"], "title": "ReCode: Improving LLM-based Code Repair with Fine-Grained Retrieval-Augmented Generation", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by CIKM 2025", "summary": "Recent advances in large language models (LLMs) have demonstrated impressive\ncapabilities in code-related tasks, such as code generation and automated\nprogram repair. Despite their promising performance, most existing approaches\nfor code repair suffer from high training costs or computationally expensive\ninference. Retrieval-augmented generation (RAG), with its efficient in-context\nlearning paradigm, offers a more scalable alternative. However, conventional\nretrieval strategies, which are often based on holistic code-text embeddings,\nfail to capture the structural intricacies of code, resulting in suboptimal\nretrieval quality. To address the above limitations, we propose ReCode, a\nfine-grained retrieval-augmented in-context learning framework designed for\naccurate and efficient code repair. Specifically, ReCode introduces two key\ninnovations: (1) an algorithm-aware retrieval strategy that narrows the search\nspace using preliminary algorithm type predictions; and (2) a modular\ndual-encoder architecture that separately processes code and textual inputs,\nenabling fine-grained semantic matching between input and retrieved contexts.\nFurthermore, we propose RACodeBench, a new benchmark constructed from\nreal-world user-submitted buggy code, which addresses the limitations of\nsynthetic benchmarks and supports realistic evaluation. Experimental results on\nRACodeBench and competitive programming datasets demonstrate that ReCode\nachieves higher repair accuracy with significantly reduced inference cost,\nhighlighting its practical value for real-world code repair scenarios.", "AI": {"tldr": "ReCode\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u68c0\u7d22\u589e\u5f3a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7b97\u6cd5\u611f\u77e5\u68c0\u7d22\u548c\u6a21\u5757\u5316\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u4ee3\u7801\u4fee\u590d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u4fee\u590d\u65b9\u6cd5\u5b58\u5728\u9ad8\u8bad\u7ec3\u6210\u672c\u6216\u8ba1\u7b97\u6602\u8d35\u7684\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u68c0\u7d22\u7b56\u7565\u65e0\u6cd5\u6355\u6349\u4ee3\u7801\u7684\u7ed3\u6784\u7ec6\u8282\u3002", "method": "ReCode\u5f15\u5165\u4e86\u7b97\u6cd5\u611f\u77e5\u68c0\u7d22\u7b56\u7565\u548c\u6a21\u5757\u5316\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5b9e\u73b0\u5bf9\u8f93\u5165\u548c\u4e0a\u4e0b\u6587\u7684\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5339\u914d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cReCode\u5728\u5b9e\u9645\u4ee3\u7801\u4fee\u590d\u573a\u666f\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u4fee\u590d\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u4e86\u63a8\u7406\u6210\u672c\u3002", "conclusion": "ReCode\u4e3a\u73b0\u5b9e\u4e16\u754c\u7684\u4ee3\u7801\u4fee\u590d\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2509.00616", "pdf": "https://arxiv.org/pdf/2509.00616", "abs": "https://arxiv.org/abs/2509.00616", "authors": ["Azul Garza", "Rene\u00e9 Rosillo"], "title": "TimeCopilot", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": null, "summary": "We introduce TimeCopilot, the first open-source agentic framework for\nforecasting that combines multiple Time Series Foundation Models (TSFMs) with\nLarge Language Models (LLMs) through a single unified API. TimeCopilot\nautomates the forecasting pipeline: feature analysis, model selection,\ncross-validation, and forecast generation, while providing natural language\nexplanations and supporting direct queries about the future. The framework is\nLLM-agnostic, compatible with both commercial and open-source models, and\nsupports ensembles across diverse forecasting families. Results on the\nlarge-scale GIFT-Eval benchmark show that TimeCopilot achieves state-of-the-art\nprobabilistic forecasting performance at low cost. Our framework provides a\npractical foundation for reproducible, explainable, and accessible agentic\nforecasting systems.", "AI": {"tldr": "TimeCopilot\u662f\u9996\u4e2a\u5f00\u6e90\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u4f9b\u81ea\u52a8\u5316\u9884\u6d4b\u751f\u6210\u4e0e\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709\u9884\u6d4b\u7cfb\u7edf\u901a\u5e38\u7f3a\u4e4f\u900f\u660e\u5ea6\u4e0e\u53ef\u89e3\u91ca\u6027\uff0cTimeCopilot\u65e8\u5728\u901a\u8fc7\u7edf\u4e00API\u63d0\u4f9b\u81ea\u52a8\u5316\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u8bbf\u95ee\u7684\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002", "method": "TimeCopilot\u6574\u5408\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u7279\u5f81\u5206\u6790\u3001\u6a21\u578b\u9009\u62e9\u3001\u4ea4\u53c9\u9a8c\u8bc1\u7b49\u529f\u80fd\uff0c\u5e76\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5728GIFT-Eval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTimeCopilot\u4ee5\u4f4e\u6210\u672c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6982\u7387\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "TimeCopilot\u4e3a\u53ef\u91cd\u590d\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u8bbf\u95ee\u7684\u9884\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2509.00113", "pdf": "https://arxiv.org/pdf/2509.00113", "abs": "https://arxiv.org/abs/2509.00113", "authors": ["Nicholas J. Sullivan", "Julio J. Vald\u00e9s", "Kirk H. Bevan", "Peter Grutter"], "title": "afspm: A Framework for Manufacturer-Agnostic Automation in Scanning Probe Microscopy", "categories": ["physics.ins-det", "cond-mat.mtrl-sci", "cs.SE"], "comment": null, "summary": "Scanning probe microscopy (SPM) is a valuable technique by which one can\ninvestigate the physical characteristics of the surfaces of materials. However,\nits widespread use is hampered by the time-consuming nature of running an\nexperiment and the significant domain knowledge required. Recent studies have\nshown the value of multiple forms of automation in improving this, but their\nuse is limited due to the difficulty of integrating them with SPMs other than\nthe one it was developed for. With this in mind, we propose an automation\nframework for SPMs aimed toward facilitating code sharing and reusability of\ndeveloped components. Our framework defines generic control and data structure\nschemas which are passed among independent software processes (components),\nwith the final SPM commands sent after passing through an SPM-specific\ntranslator. This approach permits multi-language support and allows for\nexperimental components to be decoupled among multiple computers. Our mediation\nlogic limits access to the SPM to a single component at a time, with a simple\noverride mechanism in order to correct detected experiment problems. To\nvalidate our proposal, we integrated and tested it with two SPMs from separate\nmanufacturers, and ran an experiment involving a thermal drift correction\ncomponent.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2aSPM\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u4ee3\u7801\u5171\u4eab\u548c\u7ec4\u4ef6\u91cd\u7528\u6027\uff0c\u652f\u6301\u591a\u8bed\u8a00\u548c\u591a\u8ba1\u7b97\u673a\u534f\u4f5c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "SPM\u6280\u672f\u7684\u65f6\u95f4\u548c\u77e5\u8bc6\u95e8\u69db\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6848\u96be\u4ee5\u8de8\u8bbe\u5907\u517c\u5bb9\u3002", "method": "\u8bbe\u8ba1\u4e86\u901a\u7528\u7684\u63a7\u5236\u548c\u6570\u636e\u7ed3\u6784\u6a21\u5f0f\uff0c\u901a\u8fc7\u72ec\u7acb\u8f6f\u4ef6\u7ec4\u4ef6\u548cSPM\u7279\u5b9a\u7ffb\u8bd1\u5668\u5b9e\u73b0\u81ea\u52a8\u5316\u64cd\u4f5c\u3002", "result": "\u6210\u529f\u96c6\u6210\u5e76\u6d4b\u8bd5\u4e86\u4e24\u6b3e\u4e0d\u540c\u5382\u5546\u7684SPM\u8bbe\u5907\uff0c\u8fd0\u884c\u4e86\u70ed\u6f02\u79fb\u6821\u6b63\u5b9e\u9a8c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86SPM\u81ea\u52a8\u5316\u4e2d\u7684\u517c\u5bb9\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2509.00660", "pdf": "https://arxiv.org/pdf/2509.00660", "abs": "https://arxiv.org/abs/2509.00660", "authors": ["Felipe Arias-Russi", "Yuanchen Bai", "Angelique Taylor"], "title": "CARIS: A Context-Adaptable Robot Interface System for Personalized and Scalable Human-Robot Interaction", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "The human-robot interaction (HRI) field has traditionally used Wizard-of-Oz\n(WoZ) controlled robots to explore navigation, conversational dynamics,\nhuman-in-the-loop interactions, and more to explore appropriate robot behaviors\nin everyday settings. However, existing WoZ tools are often limited to one\ncontext, making them less adaptable across different settings, users, and\nrobotic platforms. To mitigate these issues, we introduce a Context-Adaptable\nRobot Interface System (CARIS) that combines advanced robotic capabilities such\nteleoperation, human perception, human-robot dialogue, and multimodal data\nrecording. Through pilot studies, we demonstrate the potential of CARIS to WoZ\ncontrol a robot in two contexts: 1) mental health companion and as a 2) tour\nguide. Furthermore, we identified areas of improvement for CARIS, including\nsmoother integration between movement and communication, clearer functionality\nseparation, recommended prompts, and one-click communication options to enhance\nthe usability wizard control of CARIS. This project offers a publicly\navailable, context-adaptable tool for the HRI community, enabling researchers\nto streamline data-driven approaches to intelligent robot behavior.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86CARIS\u7cfb\u7edf\uff0c\u4e00\u79cd\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u7684\u4eba\u673a\u4ea4\u4e92\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u73b0\u6709WoZ\u5de5\u5177\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u9002\u5e94\u6027\u95ee\u9898\u3002\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u5c55\u793a\u4e86\u5176\u6f5c\u529b\uff0c\u5e76\u6307\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfWoZ\u5de5\u5177\u5728\u4e0d\u540c\u60c5\u5883\u3001\u7528\u6237\u548c\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u7684\u9002\u5e94\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86CARIS\u7cfb\u7edf\uff0c\u7ed3\u5408\u8fdc\u7a0b\u64cd\u63a7\u3001\u4eba\u7c7b\u611f\u77e5\u3001\u4eba\u673a\u5bf9\u8bdd\u548c\u591a\u6a21\u6001\u6570\u636e\u8bb0\u5f55\u7b49\u529f\u80fd\u3002", "result": "\u5728\u5fc3\u7406\u5065\u5eb7\u4f34\u4fa3\u548c\u5bfc\u6e38\u4e24\u4e2a\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86CARIS\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "CARIS\u4e3aHRI\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u5de5\u5177\uff0c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u667a\u80fd\u673a\u5668\u4eba\u884c\u4e3a\u7814\u7a76\u3002"}}
{"id": "2509.00272", "pdf": "https://arxiv.org/pdf/2509.00272", "abs": "https://arxiv.org/abs/2509.00272", "authors": ["Boqi Chen", "Kua Chen", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "Gunter Mussbacher", "D\u00e1niel Varr\u00f3", "Amir Feizpour"], "title": "SHERPA: A Model-Driven Framework for Large Language Model Execution", "categories": ["cs.AI", "cs.SE"], "comment": "MODELS 2025", "summary": "Recently, large language models (LLMs) have achieved widespread application\nacross various fields. Despite their impressive capabilities, LLMs suffer from\na lack of structured reasoning ability, particularly for complex tasks\nrequiring domain-specific best practices, which are often unavailable in the\ntraining data. Although multi-step prompting methods incorporating human best\npractices, such as chain-of-thought and tree-of-thought, have gained\npopularity, they lack a general mechanism to control LLM behavior. In this\npaper, we propose SHERPA, a model-driven framework to improve the LLM\nperformance on complex tasks by explicitly incorporating domain-specific best\npractices into hierarchical state machines. By structuring the LLM execution\nprocesses using state machines, SHERPA enables more fine-grained control over\ntheir behavior via rules or decisions driven by machine learning-based\napproaches, including LLMs. We show that SHERPA is applicable to a wide variety\nof tasks-specifically, code generation, class name generation, and question\nanswering-replicating previously proposed approaches while further improving\nthe performance. We demonstrate the effectiveness of SHERPA for the\naforementioned tasks using various LLMs. Our systematic evaluation compares\ndifferent state machine configurations against baseline approaches without\nstate machines. Results show that integrating well-designed state machines\nsignificantly improves the quality of LLM outputs, and is particularly\nbeneficial for complex tasks with well-established human best practices but\nlacking data used for training LLMs.", "AI": {"tldr": "SHERPA\u662f\u4e00\u4e2a\u901a\u8fc7\u5206\u5c42\u72b6\u6001\u673a\u5c06\u9886\u57df\u7279\u5b9a\u6700\u4f73\u5b9e\u8df5\u878d\u5165LLM\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u4efb\u52a1\u4e2dLLM\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u662f\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u6700\u4f73\u5b9e\u8df5\u7684\u8bad\u7ec3\u6570\u636e\u3002", "method": "SHERPA\u901a\u8fc7\u5206\u5c42\u72b6\u6001\u673a\u7ed3\u6784\u5316LLM\u7684\u6267\u884c\u8fc7\u7a0b\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6216\u89c4\u5219\u8fdb\u884c\u884c\u4e3a\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSHERPA\u5728\u4ee3\u7801\u751f\u6210\u3001\u7c7b\u540d\u751f\u6210\u548c\u95ee\u7b54\u7b49\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u7f3a\u4e4f\u8bad\u7ec3\u6570\u636e\u7684\u590d\u6742\u4efb\u52a1\u4e2d\u3002", "conclusion": "SHERPA\u4e3aLLMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u63a7\u5236\u673a\u5236\uff0c\u63d0\u5347\u4e86\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2509.00670", "pdf": "https://arxiv.org/pdf/2509.00670", "abs": "https://arxiv.org/abs/2509.00670", "authors": ["Gursimran Singh", "Aviral Chharia", "Rahul Upadhyay", "Vinay Kumar", "Luca Longo"], "title": "PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces", "categories": ["eess.SP", "cs.HC", "q-bio.NC"], "comment": "PLoS One 2025. Project Website: https://neurodiag.github.io/PyNoetic", "summary": "Electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) have\nemerged as a transformative technology with applications spanning robotics,\nvirtual reality, medicine, and rehabilitation. However, existing BCI frameworks\nface several limitations, including a lack of stage-wise flexibility essential\nfor experimental research, steep learning curves for researchers without\nprogramming expertise, elevated costs due to reliance on proprietary software,\nand a lack of all-inclusive features leading to the use of multiple external\ntools affecting research outcomes. To address these challenges, we present\nPyNoetic, a modular BCI framework designed to cater to the diverse needs of BCI\nresearch. PyNoetic is one of the very few frameworks in Python that encompasses\nthe entire BCI design pipeline, from stimulus presentation and data acquisition\nto channel selection, filtering, feature extraction, artifact removal, and\nfinally simulation and visualization. Notably, PyNoetic introduces an intuitive\nand end-to-end GUI coupled with a unique pick-and-place configurable flowchart\nfor no-code BCI design, making it accessible to researchers with minimal\nprogramming experience. For advanced users, it facilitates the seamless\nintegration of custom functionalities and novel algorithms with minimal coding,\nensuring adaptability at each design stage. PyNoetic also includes a rich array\nof analytical tools such as machine learning models, brain-connectivity\nindices, systematic testing functionalities via simulation, and evaluation\nmethods of novel paradigms. PyNoetic's strengths lie in its versatility for\nboth offline and real-time BCI development, which streamlines the design\nprocess, allowing researchers to focus on more intricate aspects of BCI\ndevelopment and thus accelerate their research endeavors. Project Website:\nhttps://neurodiag.github.io/PyNoetic", "AI": {"tldr": "PyNoetic\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709BCI\u5de5\u5177\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u5168\u6d41\u7a0b\u8bbe\u8ba1\u529f\u80fd\u548c\u65e0\u4ee3\u7801GUI\uff0c\u9002\u5408\u4e0d\u540c\u6c34\u5e73\u7684\u7814\u7a76\u8005\u3002", "motivation": "\u73b0\u6709BCI\u6846\u67b6\u7f3a\u4e4f\u7075\u6d3b\u6027\u3001\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u3001\u4f9d\u8d56\u4e13\u6709\u8f6f\u4ef6\u4e14\u529f\u80fd\u4e0d\u5168\u9762\uff0cPyNoetic\u65e8\u5728\u586b\u8865\u8fd9\u4e9b\u7a7a\u767d\u3002", "method": "PyNoetic\u63d0\u4f9b\u4ece\u523a\u6fc0\u5448\u73b0\u5230\u6570\u636e\u53ef\u89c6\u5316\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u652f\u6301\u65e0\u4ee3\u7801\u8bbe\u8ba1\u548c\u81ea\u5b9a\u4e49\u529f\u80fd\u96c6\u6210\u3002", "result": "PyNoetic\u652f\u6301\u79bb\u7ebf\u548c\u5b9e\u65f6BCI\u5f00\u53d1\uff0c\u7b80\u5316\u8bbe\u8ba1\u6d41\u7a0b\uff0c\u52a0\u901f\u7814\u7a76\u8fdb\u5c55\u3002", "conclusion": "PyNoetic\u662f\u4e00\u4e2a\u591a\u529f\u80fd\u4e14\u6613\u4e8e\u4f7f\u7528\u7684BCI\u6846\u67b6\uff0c\u9002\u5408\u5e7f\u6cdb\u7684\u7814\u7a76\u9700\u6c42\u3002"}}
{"id": "2509.02481", "pdf": "https://arxiv.org/pdf/2509.02481", "abs": "https://arxiv.org/abs/2509.02481", "authors": ["Aishwarya Sarkar", "Autrin Hakimi", "Xiaoqiong Chen", "Hai Huang", "Chaoqun Lu", "Ibrahim Demir", "Ali Jannesari"], "title": "HydroGAT: Distributed Heterogeneous Graph Attention Transformer for Spatiotemporal Flood Prediction", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted to The 33rd ACM International Conference on Advances in\n  Geographic Information Systems (SIGSPATIAL 25)", "summary": "Accurate flood forecasting remains a challenge for water-resource management,\nas it demands modeling of local, time-varying runoff drivers (e.g.,\nrainfall-induced peaks, baseflow trends) and complex spatial interactions\nacross a river network. Traditional data-driven approaches, such as\nconvolutional networks and sequence-based models, ignore topological\ninformation about the region. Graph Neural Networks (GNNs) propagate\ninformation exactly along the river network, which is ideal for learning\nhydrological routing. However, state-of-the-art GNN-based flood prediction\nmodels collapse pixels to coarse catchment polygons as the cost of training\nexplodes with graph size and higher resolution. Furthermore, most existing\nmethods treat spatial and temporal dependencies separately, either applying\nGNNs solely on spatial graphs or transformers purely on temporal sequences,\nthus failing to simultaneously capture spatiotemporal interactions critical for\naccurate flood prediction. We introduce a heterogenous basin graph where every\nland and river pixel is a node connected by physical hydrological flow\ndirections and inter-catchment relationships. We propose HydroGAT, a\nspatiotemporal network that adaptively learns local temporal importance and the\nmost influential upstream locations. Evaluated in two Midwestern US basins and\nacross five baseline architectures, our model achieves higher NSE (up to 0.97),\nimproved KGE (up to 0.96), and low bias (PBIAS within $\\pm$5%) in hourly\ndischarge prediction, while offering interpretable attention maps that reveal\nsparse, structured intercatchment influences. To support high-resolution\nbasin-scale training, we develop a distributed data-parallel pipeline that\nscales efficiently up to 64 NVIDIA A100 GPUs on NERSC Perlmutter supercomputer,\ndemonstrating up to 15x speedup across machines. Our code is available at\nhttps://github.com/swapp-lab/HydroGAT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f02\u6784\u56fe\u548c\u52a8\u6001\u6ce8\u610f\u529b\u7684HydroGAT\u6a21\u578b\uff0c\u7528\u4e8e\u9ad8\u5206\u8fa8\u7387\u6cb3\u6d41\u7f51\u7edc\u4e2d\u65f6\u7a7a\u4ea4\u4e92\u7684\u6d2a\u6c34\u9884\u6d4b\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6d2a\u6c34\u9884\u6d4b\u65b9\u6cd5\u5ffd\u89c6\u62d3\u6251\u4fe1\u606f\u6216\u65f6\u7a7a\u4ea4\u4e92\uff0c\u73b0\u6709GNN\u65b9\u6cd5\u56e0\u8ba1\u7b97\u6210\u672c\u96be\u4ee5\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u3002", "method": "\u6784\u5efa\u5f02\u8d28\u6d41\u57df\u56fe\uff0c\u63d0\u51faHydroGAT\u7ed3\u5408\u52a8\u6001\u6ce8\u610f\u529b\u548c\u5206\u5e03\u5f0f\u8bad\u7ec3\uff0c\u540c\u65f6\u5efa\u6a21\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u4e24\u4e2a\u7f8e\u56fd\u4e2d\u897f\u90e8\u6d41\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u578b\u5728NSE\u3001KGE\u548cPBIAS\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e76\u652f\u6301\u9ad8\u5206\u8fa8\u7387\u8bad\u7ec3\u3002", "conclusion": "HydroGAT\u901a\u8fc7\u81ea\u9002\u5e94\u65f6\u7a7a\u5efa\u6a21\u548c\u9ad8\u6548\u5206\u5e03\u5f0f\u8bad\u7ec3\uff0c\u4e3a\u6d2a\u6c34\u9884\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01459", "pdf": "https://arxiv.org/pdf/2509.01459", "abs": "https://arxiv.org/abs/2509.01459", "authors": ["Ozan Baris Mulayim", "Yuvraj Agarwal", "Mario Berg\u00e9s", "Steve Schaefer", "Mitali Shah", "Derek Supple"], "title": "Semantic Technologies in Practical Demand Response: An Informational Requirement-based Roadmap", "categories": ["eess.SY", "cs.SE", "cs.SY"], "comment": "Under review by journal of Advanced Engineering Informatics. It\n  includes 25 pages, 7 figures, 8 tables,", "summary": "The future grid will be highly complex and decentralized, requiring\nsophisticated coordination across numerous human and software agents that\nmanage distributed resources such as Demand Response (DR). Realizing this\nvision demands significant advances in semantic interoperability, which enables\nscalable and cost-effective automation across heterogeneous systems. While\nsemantic technologies have progressed in commercial building and DR domains,\ncurrent ontologies have two critical limitations: they are often developed\nwithout a formal framework that reflects real-world DR requirements, and\nproposals for integrating general and application-specific ontologies remain\nmostly conceptual, lacking formalization or empirical validation.\n  In this paper, we address these gaps by applying a formal ontology\nevaluation/development approach to define the informational requirements (IRs)\nnecessary for semantic interoperability in the area of incentive-based DR for\ncommercial buildings. We identify the IRs associated with each stage of the\nwholesale incentive-based DR process, focusing on the perspective of building\nowners. Using these IRs, we evaluate how well existing ontologies (Brick,\nDELTA, and EFOnt) support the operational needs of DR participation. Our\nfindings reveal substantial misalignments between current ontologies and\npractical DR requirements. Based on our assessments, we propose a roadmap of\nnecessary extensions and integrations for these ontologies. This work\nultimately aims to enhance the interoperability of today's and future smart\ngrid, thereby facilitating scalable integration of DR systems into the grid's\ncomplex operational framework.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5f62\u5f0f\u5316\u672c\u4f53\u8bc4\u4f30/\u5f00\u53d1\u65b9\u6cd5\uff0c\u660e\u786e\u4e86\u5546\u4e1a\u5efa\u7b51\u6fc0\u52b1\u578b\u9700\u6c42\u54cd\u5e94\uff08DR\uff09\u4e2d\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u7684\u4fe1\u606f\u9700\u6c42\uff08IRs\uff09\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u672c\u4f53\uff08Brick\u3001DELTA\u3001EFOnt\uff09\u7684\u652f\u6301\u7a0b\u5ea6\uff0c\u63ed\u793a\u4e86\u5176\u4e0e\u5b9e\u9645\u9700\u6c42\u7684\u504f\u5dee\uff0c\u63d0\u51fa\u4e86\u6269\u5c55\u8def\u5f84\u3002", "motivation": "\u672a\u6765\u7535\u7f51\u5c06\u9ad8\u5ea6\u590d\u6742\u548c\u5206\u6563\u5316\uff0c\u9700\u652f\u6301\u5f02\u6784\u7cfb\u7edf\u7684\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff1b\u5f53\u524d\u672c\u4f53\u7f3a\u4e4f\u5f62\u5f0f\u5316\u6846\u67b6\u4e14\u6574\u5408\u65b9\u6848\u591a\u4e3a\u6982\u5ff5\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9eDR\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5f62\u5f0f\u5316\u672c\u4f53\u8bc4\u4f30/\u5f00\u53d1\u65b9\u6cd5\uff0c\u8bc6\u522b\u5546\u4e1a\u5efa\u7b51DR\u7684\u4fe1\u606f\u9700\u6c42\uff08IRs\uff09\uff0c\u8bc4\u4f30\u73b0\u6709\u672c\u4f53\uff08Brick\u3001DELTA\u3001EFOnt\uff09\u5bf9\u5176\u7684\u652f\u6301\u7a0b\u5ea6\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u672c\u4f53\u4e0eDR\u5b9e\u9645\u9700\u6c42\u5b58\u5728\u663e\u8457\u504f\u5dee\uff0c\u63d0\u51fa\u4e86\u6269\u5c55\u548c\u6574\u5408\u7684\u8def\u7ebf\u56fe\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347\u5f53\u524d\u53ca\u672a\u6765\u667a\u80fd\u7535\u7f51\u7684\u4e92\u64cd\u4f5c\u6027\u3001\u4fc3\u8fdbDR\u7cfb\u7edf\u89c4\u6a21\u5316\u96c6\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.00780", "pdf": "https://arxiv.org/pdf/2509.00780", "abs": "https://arxiv.org/abs/2509.00780", "authors": ["Yiluo Wei", "Jiahui He", "Gareth Tyson"], "title": "Understanding Fanchuan in Livestreaming Platforms: A New Form of Online Antisocial Behavior", "categories": ["cs.CY", "cs.HC"], "comment": "Accepted to CSCW 2025: The 28th ACM SIGCHI Conference on\n  Computer-Supported Cooperative Work & Social Computing", "summary": "Recently, a distinct form of online antisocial behavior, known as \"fanchuan\",\nhas emerged across online platforms, particularly in livestreaming chats.\nFanchuan is an indirect attack on a specific entity, such as a celebrity, video\ngame, or brand. It entails two main actions: (i) individuals first feign\nsupport for the entity, and exhibit this allegiance widely; (ii) they then\nengage in offensive or irritating behavior, attempting to undermine the entity\nby association. This deceptive conduct is designed to tarnish the reputation of\nthe target and/or its fan community. Fanchuan is a novel, covert and indirect\nform of social attack, occurring outside the targeted community (often in a\nsimilar or broader community), with strategic long-term objectives. This\ndistinguishes fanchuan from other types of antisocial behavior and presents\nsignificant new challenges in moderation. We argue it is crucial to understand\nand combat this new malicious behavior. Therefore, we conduct the first\nempirical study on fanchuan behavior in livestreaming chats, focusing on\nBilibili, a leading livestreaming platform in China. Our dataset covers 2.7\nmillion livestreaming sessions on Bilibili, featuring 3.6 billion chat\nmessages. We identify 130k instances of fanchuan behavior across 37.4k\nlivestreaming sessions. Through various types of analysis, our research offers\nvaluable insights into fanchuan behavior and its perpetrators.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u65b0\u5174\u7684\u5728\u7ebf\u53cd\u793e\u4f1a\u884c\u4e3a'\u53cd\u4e32'\uff08fanchuan\uff09\uff0c\u901a\u8fc7\u5206\u6790Bilibili\u5e73\u53f0\u7684\u76f4\u64ad\u804a\u5929\u6570\u636e\uff0c\u63ed\u793a\u4e86\u5176\u7279\u70b9\u548c\u4f20\u64ad\u65b9\u5f0f\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e3a\u4e86\u7406\u89e3\u5e76\u5e94\u5bf9'\u53cd\u4e32'\u8fd9\u79cd\u5177\u6709\u9690\u853d\u6027\u548c\u957f\u671f\u6218\u7565\u76ee\u6807\u7684\u6076\u610f\u884c\u4e3a\uff0c\u5176\u72ec\u7279\u6027\u548c\u5bf9\u5185\u5bb9\u5ba1\u6838\u7684\u65b0\u6311\u6218\u4fc3\u4f7f\u4e86\u8fd9\u9879\u7814\u7a76\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u662f\u57fa\u4e8eBilibili\u5e73\u53f0\u76842.7\u767e\u4e07\u76f4\u64ad\u4f1a\u8bdd\u548c3.6\u4ebf\u6761\u804a\u5929\u6d88\u606f\u7684\u6570\u636e\u96c6\uff0c\u8bc6\u522b\u5e76\u5206\u6790\u4e8613\u4e07\u6b21'\u53cd\u4e32'\u884c\u4e3a\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86'\u53cd\u4e32'\u884c\u4e3a\u7684\u7279\u70b9\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u4e8e\u5176\u4f20\u64ad\u65b9\u5f0f\u548c\u884c\u4e3a\u8005\u7684\u91cd\u8981\u89c1\u89e3\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u7406\u89e3'\u53cd\u4e32'\u884c\u4e3a\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5bf9\u6297\u8fd9\u4e00\u65b0\u5174\u6076\u610f\u884c\u4e3a\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.01031", "pdf": "https://arxiv.org/pdf/2509.01031", "abs": "https://arxiv.org/abs/2509.01031", "authors": ["Xiaozhou Ye", "Kevin I-Kai Wang"], "title": "Reinforcement Learning Driven Generalizable Feature Representation for Cross-User Activity Recognition", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": null, "summary": "Human Activity Recognition (HAR) using wearable sensors is crucial for\nhealthcare, fitness tracking, and smart environments, yet cross-user\nvariability -- stemming from diverse motion patterns, sensor placements, and\nphysiological traits -- hampers generalization in real-world settings.\nConventional supervised learning methods often overfit to user-specific\npatterns, leading to poor performance on unseen users. Existing domain\ngeneralization approaches, while promising, frequently overlook temporal\ndependencies or depend on impractical domain-specific labels. We propose\nTemporal-Preserving Reinforcement Learning Domain Generalization (TPRL-DG), a\nnovel framework that redefines feature extraction as a sequential\ndecision-making process driven by reinforcement learning. TPRL-DG leverages a\nTransformer-based autoregressive generator to produce temporal tokens that\ncapture user-invariant activity dynamics, optimized via a multi-objective\nreward function balancing class discrimination and cross-user invariance. Key\ninnovations include: (1) an RL-driven approach for domain generalization, (2)\nautoregressive tokenization to preserve temporal coherence, and (3) a\nlabel-free reward design eliminating the need for target user annotations.\nEvaluations on the DSADS and PAMAP2 datasets show that TPRL-DG surpasses\nstate-of-the-art methods in cross-user generalization, achieving superior\naccuracy without per-user calibration. By learning robust, user-invariant\ntemporal patterns, TPRL-DG enables scalable HAR systems, facilitating\nadvancements in personalized healthcare, adaptive fitness tracking, and\ncontext-aware environments.", "AI": {"tldr": "TPRL-DG\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u7a7f\u6234\u5f0f\u4f20\u611f\u5668\u5728\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u4e2d\u7684\u8de8\u7528\u6237\u6cdb\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u65f6\u5e8f\u4fdd\u7559\u548c\u6807\u7b7e\u81ea\u7531\u7684\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u672a\u89c1\u8fc7\u7528\u6237\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u7a7f\u6234\u5f0f\u4f20\u611f\u5668\u5728\u5065\u5eb7\u76d1\u6d4b\u548c\u667a\u80fd\u73af\u5883\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u7528\u6237\u95f4\u7684\u8fd0\u52a8\u6a21\u5f0f\u3001\u4f20\u611f\u5668\u4f4d\u7f6e\u548c\u751f\u7406\u7279\u5f81\u5dee\u5f02\u5bfc\u81f4\u6a21\u578b\u6cdb\u5316\u6027\u80fd\u5dee\u3002\u73b0\u6709\u65b9\u6cd5\u5e38\u5ffd\u7565\u65f6\u5e8f\u4f9d\u8d56\u6216\u4f9d\u8d56\u4e0d\u73b0\u5b9e\u7684\u9886\u57df\u6807\u7b7e\u3002", "method": "TPRL-DG\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548cTransformer\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u56de\u5f52\u751f\u6210\u65f6\u5e8f\u4ee4\u724c\u6355\u83b7\u7528\u6237\u4e0d\u53d8\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\u5e73\u8861\u7c7b\u533a\u5206\u548c\u8de8\u7528\u6237\u4e0d\u53d8\u6027\u3002", "result": "\u5728DSADS\u548cPAMAP2\u6570\u636e\u96c6\u4e0a\uff0cTPRL-DG\u5728\u8de8\u7528\u6237\u6cdb\u5316\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u65e0\u9700\u7528\u6237\u7279\u5b9a\u6821\u51c6\u5373\u5b9e\u73b0\u66f4\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "TPRL-DG\u901a\u8fc7\u5b66\u4e60\u9c81\u68d2\u7684\u7528\u6237\u4e0d\u53d8\u65f6\u5e8f\u6a21\u5f0f\uff0c\u63a8\u52a8\u4e86\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u6709\u52a9\u4e8e\u4e2a\u6027\u5316\u533b\u7597\u548c\u667a\u80fd\u73af\u5883\u7684\u5e94\u7528\u3002"}}
{"id": "2509.01177", "pdf": "https://arxiv.org/pdf/2509.01177", "abs": "https://arxiv.org/abs/2509.01177", "authors": ["Junxiang Liu", "Junming Lin", "Jiangtong Li", "Jie Li"], "title": "DynaMind: Reconstructing Dynamic Visual Scenes from EEG by Aligning Temporal Dynamics and Multimodal Semantics to Guided Diffusion", "categories": ["cs.CV", "cs.AI", "cs.HC", "eess.SP"], "comment": "14 pages, 6 figures", "summary": "Reconstruction dynamic visual scenes from electroencephalography (EEG)\nsignals remains a primary challenge in brain decoding, limited by the low\nspatial resolution of EEG, a temporal mismatch between neural recordings and\nvideo dynamics, and the insufficient use of semantic information within brain\nactivity. Therefore, existing methods often inadequately resolve both the\ndynamic coherence and the complex semantic context of the perceived visual\nstimuli. To overcome these limitations, we introduce DynaMind, a novel\nframework that reconstructs video by jointly modeling neural dynamics and\nsemantic features via three core modules: a Regional-aware Semantic Mapper\n(RSM), a Temporal-aware Dynamic Aligner (TDA), and a Dual-Guidance Video\nReconstructor (DGVR). The RSM first utilizes a regional-aware encoder to\nextract multimodal semantic features from EEG signals across distinct brain\nregions, aggregating them into a unified diffusion prior. In the mean time, the\nTDA generates a dynamic latent sequence, or blueprint, to enforce temporal\nconsistency between the feature representations and the original neural\nrecordings. Together, guided by the semantic diffusion prior, the DGVR\ntranslates the temporal-aware blueprint into a high-fidelity video\nreconstruction. On the SEED-DV dataset, DynaMind sets a new state-of-the-art\n(SOTA), boosting reconstructed video accuracies (video- and frame-based) by\n12.5 and 10.3 percentage points, respectively. It also achieves a leap in\npixel-level quality, showing exceptional visual fidelity and temporal coherence\nwith a 9.4% SSIM improvement and a 19.7% FVMD reduction. This marks a critical\nadvancement, bridging the gap between neural dynamics and high-fidelity visual\nsemantics.", "AI": {"tldr": "DynaMind\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u795e\u7ecf\u52a8\u6001\u548c\u8bed\u4e49\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u4eceEEG\u4fe1\u53f7\u91cd\u5efa\u52a8\u6001\u89c6\u89c9\u573a\u666f\u7684\u521b\u65b0\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cd\u5efa\u89c6\u9891\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002", "motivation": "EEG\u4fe1\u53f7\u7684\u4f4e\u7a7a\u95f4\u5206\u8fa8\u7387\u3001\u795e\u7ecf\u8bb0\u5f55\u4e0e\u89c6\u9891\u52a8\u6001\u7684\u65f6\u95f4\u4e0d\u5339\u914d\uff0c\u4ee5\u53ca\u8111\u6d3b\u52a8\u4e2d\u8bed\u4e49\u4fe1\u606f\u7684\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u52a8\u6001\u89c6\u89c9\u573a\u666f\u7684\u91cd\u5efa\u6548\u679c\u3002", "method": "DynaMind\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u533a\u57df\u611f\u77e5\u8bed\u4e49\u6620\u5c04\u5668\uff08RSM\uff09\u3001\u65f6\u95f4\u611f\u77e5\u52a8\u6001\u5bf9\u9f50\u5668\uff08TDA\uff09\u548c\u53cc\u5f15\u5bfc\u89c6\u9891\u91cd\u5efa\u5668\uff08DGVR\uff09\uff0c\u5171\u540c\u5efa\u6a21\u795e\u7ecf\u52a8\u6001\u548c\u8bed\u4e49\u7279\u5f81\u3002", "result": "\u5728SEED-DV\u6570\u636e\u96c6\u4e0a\uff0cDynaMind\u5b9e\u73b0\u4e86\u65b0\u7684SOTA\uff0c\u89c6\u9891\u548c\u5e27\u7ea7\u522b\u51c6\u786e\u7387\u5206\u522b\u63d0\u5347\u4e8612.5\u548c10.3\u4e2a\u767e\u5206\u70b9\uff0c\u50cf\u7d20\u7ea7\u8d28\u91cf\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u4e5f\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "DynaMind\u5728\u795e\u7ecf\u52a8\u6001\u548c\u9ad8\u4fdd\u771f\u89c6\u89c9\u8bed\u4e49\u4e4b\u95f4\u67b6\u8d77\u4e86\u6865\u6881\uff0c\u6807\u5fd7\u7740\u91cd\u8981\u7684\u6280\u672f\u8fdb\u6b65\u3002"}}
{"id": "2509.02360", "pdf": "https://arxiv.org/pdf/2509.02360", "abs": "https://arxiv.org/abs/2509.02360", "authors": ["Shubham Gandhi", "Jason Tsay", "Jatin Ganhotra", "Kiran Kate", "Yara Rizk"], "title": "When Agents go Astray: Course-Correcting SWE Agents with PRMs", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Large Language Model (LLM) agents are increasingly deployed for complex,\nmulti-step software engineering (SWE) tasks. However, their trajectories often\ncontain costly inefficiencies, such as redundant exploration, looping, and\nfailure to terminate once a solution is reached. Prior work has largely treated\nthese errors in a post-hoc manner, diagnosing failures only after execution. In\nthis paper, we introduce SWE-PRM, an inference-time Process Reward Model (PRM)\nthat intervenes during execution to detect and course-correct trajectory-level\nerrors. Our PRM design leverages a taxonomy of common inefficiencies and\ndelivers lightweight, interpretable feedback without modifying the underlying\npolicy. On SWE-bench Verified, closed-source PRMs improve resolution from 40.0%\nto 50.6% (+10.6 p.p.), with the largest gains on medium and hard tasks. Among\nfeedback strategies, taxonomy-guided PRMs outperform unguided or explicit\naction-prescriptive variants, increasing success rate while reducing trajectory\nlength. These benefits come at an acceptable added inference cost of as low as\n$0.2, making PRMs a practical and scalable mechanism for improving SWE agents'\nreliability and efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u7406\u65f6\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08SWE-PRM\uff09\uff0c\u7528\u4e8e\u5373\u65f6\u68c0\u6d4b\u5e76\u7ea0\u6b63\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u8f68\u8ff9\u9519\u8bef\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u89e3\u51b3\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u6267\u884c\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u65f6\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5982\u5197\u4f59\u63a2\u7d22\u548c\u65e0\u6cd5\u53ca\u65f6\u7ec8\u6b62\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u4e8b\u540e\u8bca\u65ad\u3002", "method": "\u5f15\u5165SWE-PRM\u6a21\u578b\uff0c\u57fa\u4e8e\u5e38\u89c1\u4f4e\u6548\u884c\u4e3a\u7684\u5206\u7c7b\uff0c\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u4e14\u53ef\u89e3\u91ca\u7684\u53cd\u9988\uff0c\u65e0\u9700\u4fee\u6539\u5e95\u5c42\u7b56\u7565\u3002", "result": "\u5728SWE-bench\u9a8c\u8bc1\u96c6\u4e0a\uff0cPRM\u5c06\u4efb\u52a1\u89e3\u51b3\u7387\u4ece40.0%\u63d0\u5347\u81f350.6%\uff0c\u5e76\u5728\u4e2d\u7b49\u548c\u56f0\u96be\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "SWE-PRM\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u673a\u5236\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u4e14\u63a8\u7406\u6210\u672c\u4f4e\u3002"}}
{"id": "2509.01182", "pdf": "https://arxiv.org/pdf/2509.01182", "abs": "https://arxiv.org/abs/2509.01182", "authors": ["Wonduk Seo", "Taesub Shin", "Hyunjin An", "Dokyun Kim", "Seunghyun Lee"], "title": "Question-to-Knowledge: Multi-Agent Generation of Inspectable Facts for Product Mapping", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR", "cs.MA"], "comment": "Preprint", "summary": "Identifying whether two product listings refer to the same Stock Keeping Unit\n(SKU) is a persistent challenge in ecommerce, especially when explicit\nidentifiers are missing and product names vary widely across platforms. Rule\nbased heuristics and keyword similarity often misclassify products by\noverlooking subtle distinctions in brand, specification, or bundle\nconfiguration. To overcome these limitations, we propose Question to Knowledge\n(Q2K), a multi agent framework that leverages Large Language Models (LLMs) for\nreliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates\ntargeted disambiguation questions, (2) a Knowledge Agent that resolves them via\nfocused web searches, and (3) a Deduplication Agent that reuses validated\nreasoning traces to reduce redundancy and ensure consistency. A human in the\nloop mechanism further refines uncertain cases. Experiments on real world\nconsumer goods datasets show that Q2K surpasses strong baselines, achieving\nhigher accuracy and robustness in difficult scenarios such as bundle\nidentification and brand origin disambiguation. By reusing retrieved reasoning\ninstead of issuing repeated searches, Q2K balances accuracy with efficiency,\noffering a scalable and interpretable solution for product integration.", "AI": {"tldr": "Q2K \u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b3\u7535\u5546\u4e2d SKU \u6620\u5c04\u7684\u6311\u6218\uff0c\u901a\u8fc7\u63a8\u7406\u3001\u77e5\u8bc6\u83b7\u53d6\u548c\u53bb\u91cd\u4ee3\u7406\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u7535\u5546\u4e2d\u7f3a\u5c11\u660e\u786e\u6807\u8bc6\u548c\u5546\u54c1\u540d\u79f0\u5dee\u5f02\u5927\u5bfc\u81f4 SKU \u6620\u5c04\u56f0\u96be\uff0c\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u5bb9\u6613\u56e0\u5ffd\u7565\u54c1\u724c\u3001\u89c4\u683c\u7b49\u7ec6\u8282\u800c\u8bef\u5206\u7c7b\u3002", "method": "Q2K \u5305\u542b\u63a8\u7406\u4ee3\u7406\u751f\u6210\u6d88\u6b67\u95ee\u9898\u3001\u77e5\u8bc6\u4ee3\u7406\u901a\u8fc7\u641c\u7d22\u89e3\u51b3\u95ee\u9898\u3001\u53bb\u91cd\u4ee3\u7406\u590d\u7528\u5df2\u9a8c\u8bc1\u63a8\u7406\u4ee5\u51cf\u5c11\u5197\u4f59\uff0c\u5e76\u7ed3\u5408\u4eba\u5de5\u53cd\u9988\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e Q2K \u5728\u771f\u5b9e\u5546\u54c1\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u6346\u7ed1\u8bc6\u522b\u548c\u54c1\u724c\u6765\u6e90\u6d88\u6b67\u7b49\u590d\u6742\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u51c6\u786e\u548c\u9c81\u68d2\u3002", "conclusion": "Q2K \u901a\u8fc7\u590d\u7528\u63a8\u7406\u800c\u975e\u91cd\u590d\u641c\u7d22\uff0c\u5e73\u8861\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u4ea7\u54c1\u96c6\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02372", "pdf": "https://arxiv.org/pdf/2509.02372", "abs": "https://arxiv.org/abs/2509.02372", "authors": ["Zhiyang Chen", "Tara Saba", "Xun Deng", "Xujie Si", "Fan Long"], "title": "Poisoned at Scale: A Scalable Audit Uncovers Hidden Scam Endpoints in Production LLMs", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": "10 pages, 4 figures", "summary": "Large Language Models (LLMs) have become critical to modern software\ndevelopment, but their reliance on internet datasets for training introduces a\nsignificant security risk: the absorption and reproduction of malicious\ncontent. To evaluate this threat, this paper introduces a scalable, automated\naudit framework that synthesizes innocuous, developer-style prompts from known\nscam databases to query production LLMs and determine if they generate code\ncontaining harmful URLs. We conducted a large-scale evaluation across four\nproduction LLMs (GPT-4o, GPT-4o-mini, Llama-4-Scout, and DeepSeek-V3), and\nfound a systemic vulnerability, with all tested models generating malicious\ncode at a non-negligible rate. On average, 4.2\\% of programs generated in our\nexperiments contained malicious URLs. Crucially, this malicious code is often\ngenerated in response to benign prompts. We manually validate the prompts which\ncause all four LLMs to generate malicious code, and resulting in 177 innocuous\nprompts that trigger all models to produce harmful outputs. These results\nprovide strong empirical evidence that the training data of production LLMs has\nbeen successfully poisoned at scale, underscoring the urgent need for more\nrobust defense mechanisms and post-generation safety checks to mitigate the\npropagation of hidden security threats.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.01399", "pdf": "https://arxiv.org/pdf/2509.01399", "abs": "https://arxiv.org/abs/2509.01399", "authors": ["Runduo Han", "Yanxin Hu", "Yihui Fu", "Zihan Zhang", "Yukai Jv", "Li Chen", "Lei Xie"], "title": "CabinSep: IR-Augmented Mask-Based MVDR for Real-Time In-Car Speech Separation with Distributed Heterogeneous Arrays", "categories": ["cs.SD", "cs.AI", "cs.HC", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "Separating overlapping speech from multiple speakers is crucial for effective\nhuman-vehicle interaction. This paper proposes CabinSep, a lightweight neural\nmask-based minimum variance distortionless response (MVDR) speech separation\napproach, to reduce speech recognition errors in back-end automatic speech\nrecognition (ASR) models. Our contributions are threefold: First, we utilize\nchannel information to extract spatial features, which improves the estimation\nof speech and noise masks. Second, we employ MVDR during inference, reducing\nspeech distortion to make it more ASR-friendly. Third, we introduce a data\naugmentation method combining simulated and real-recorded impulse responses\n(IRs), improving speaker localization at zone boundaries and further reducing\nspeech recognition errors. With a computational complexity of only 0.4 GMACs,\nCabinSep achieves a 17.5% relative reduction in speech recognition error rate\nin a real-recorded dataset compared to the state-of-the-art DualSep model.\nDemos are available at: https://cabinsep.github.io/cabinsep/.", "AI": {"tldr": "CabinSep\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8bed\u97f3\u5206\u79bb\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u5c11\u8bed\u97f3\u8bc6\u522b\u9519\u8bef\uff0c\u901a\u8fc7\u7ed3\u5408\u7a7a\u95f4\u7279\u5f81\u3001MVDR\u6280\u672f\u548c\u6570\u636e\u589e\u5f3a\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9519\u8bef\u7387\u3002", "motivation": "\u63d0\u9ad8\u4eba\u673a\u4ea4\u4e92\u4e2d\u91cd\u53e0\u8bed\u97f3\u7684\u5206\u79bb\u6548\u679c\uff0c\u51cf\u5c11\u540e\u7aef\u8bed\u97f3\u8bc6\u522b\u7684\u9519\u8bef\u3002", "method": "\u5229\u7528\u901a\u9053\u4fe1\u606f\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\u3001\u5e94\u7528MVDR\u51cf\u5c11\u8bed\u97f3\u5931\u771f\u3001\u7ed3\u5408\u6a21\u62df\u548c\u771f\u5b9e\u5f55\u97f3\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u4ec5\u4e3a0.4 GMACs\u65f6\uff0c\u4e0e\u73b0\u6709\u6700\u4f73\u6a21\u578b\u76f8\u6bd4\uff0c\u8bed\u97f3\u8bc6\u522b\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e\u4e8617.5%\u3002", "conclusion": "CabinSep\u5728\u8f7b\u91cf\u5316\u548c\u6027\u80fd\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u573a\u666f\uff0c\u5c24\u5176\u662f\u8f66\u8f7d\u73af\u5883\u3002"}}
{"id": "2509.01450", "pdf": "https://arxiv.org/pdf/2509.01450", "abs": "https://arxiv.org/abs/2509.01450", "authors": ["Ane San Martin", "Michael Hagenow", "Julie Shah", "Johan Kildal", "Elena Lazkano"], "title": "Analyzing Reluctance to Ask for Help When Cooperating With Robots: Insights to Integrate Artificial Agents in HRC", "categories": ["cs.RO", "cs.HC"], "comment": "8 pages, 5 figures. Accepted for IEEE RO-MAN 2025", "summary": "As robot technology advances, collaboration between humans and robots will\nbecome more prevalent in industrial tasks. When humans run into issues in such\nscenarios, a likely future involves relying on artificial agents or robots for\naid. This study identifies key aspects for the design of future user-assisting\nagents. We analyze quantitative and qualitative data from a user study\nexamining the impact of on-demand assistance received from a remote human in a\nhuman-robot collaboration (HRC) assembly task. We study scenarios in which\nusers require help and we assess their experiences in requesting and receiving\nassistance. Additionally, we investigate participants' perceptions of future\nnon-human assisting agents and whether assistance should be on-demand or\nunsolicited. Through a user study, we analyze the impact that such design\ndecisions (human or artificial assistant, on-demand or unsolicited help) can\nhave on elicited emotional responses, productivity, and preferences of humans\nengaged in HRC tasks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4eba\u4e0e\u673a\u5668\u4eba\u534f\u4f5c\u4e2d\uff0c\u672a\u6765\u8f85\u52a9\u4ee3\u7406\u7684\u8bbe\u8ba1\u5173\u952e\uff0c\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u5206\u6790\u8fdc\u7a0b\u4eba\u7c7b\u8f85\u52a9\u53ca\u672a\u6765\u975e\u4eba\u7c7b\u4ee3\u7406\u7684\u63a5\u53d7\u5ea6\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u6280\u672f\u8fdb\u6b65\uff0c\u4eba\u673a\u534f\u4f5c\u5728\u5de5\u4e1a\u4efb\u52a1\u4e2d\u65e5\u76ca\u666e\u904d\uff0c\u7814\u7a76\u76ee\u6807\u662f\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u7528\u6237\u8f85\u52a9\u4ee3\u7406\u3002", "method": "\u901a\u8fc7\u5b9a\u6027\u4e0e\u5b9a\u91cf\u6570\u636e\u5206\u6790\u7528\u6237\u7814\u7a76\u4e2d\u8fdc\u7a0b\u4eba\u7c7b\u8f85\u52a9\u5bf9\u4eba\u673a\u534f\u4f5c\u88c5\u914d\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u7528\u6237\u5728\u6c42\u52a9\u53ca\u63a5\u53d7\u5e2e\u52a9\u65f6\u7684\u4f53\u9a8c\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u7528\u6237\u5bf9\u975e\u4eba\u7c7b\u8f85\u52a9\u4ee3\u7406\u7684\u63a5\u53d7\u5ea6\uff0c\u4ee5\u53ca\u8f85\u52a9\u8bf7\u6c42\u65b9\u5f0f\uff08\u9700\u6c42\u9a71\u52a8\u4e0e\u975e\u8bf7\u6c42\u5f0f\uff09\u5bf9\u60c5\u7eea\u3001\u751f\u4ea7\u529b\u548c\u504f\u597d\u7684\u5f71\u54cd\u3002", "conclusion": "\u672a\u6765\u8f85\u52a9\u4ee3\u7406\u8bbe\u8ba1\u9700\u5e73\u8861\u7528\u6237\u63a5\u53d7\u5ea6\u4e0e\u4efb\u52a1\u6548\u7387\uff0c\u660e\u786e\u8f85\u52a9\u65b9\u5f0f\u7684\u9009\u62e9\u5bf9\u534f\u4f5c\u6548\u679c\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.01643", "pdf": "https://arxiv.org/pdf/2509.01643", "abs": "https://arxiv.org/abs/2509.01643", "authors": ["Minja Axelsson"], "title": "Speculative Design of Equitable Robotics: Queer Fictions and Futures", "categories": ["cs.RO", "cs.CY", "cs.HC", "I.2.9; J.5; K.4.2"], "comment": "Accepted at the British Computer Society's Special Interest Group in\n  Human Computer Interaction Conference (BCS HCI 2025), Futures track. 5 pages,\n  no figures", "summary": "This paper examines the speculative topic of equitable robots through an\nexploratory essay format. It focuses specifically on robots by and for LGBTQ+\npopulations. It aims to provoke thought and conversations in the field about\nwhat aspirational queer robotics futures may look like, both in the arts and\nsciences. First, it briefly reviews the state-of-the-art of queer robotics in\nfiction and science, drawing together threads from each. Then, it discusses\nqueering robots through three speculative design proposals for queer robot\nroles: 1) reflecting the queerness of their ''in-group'' queer users, building\nand celebrating ''in-group'' identity, 2) a new kind of queer activism by\nimplementing queer robot identity performance to interact with ''out-group''\nusers, with a goal of reducing bigotry through familiarisation, and 3) a\nnetwork of queer-owned robots, through which the community could reach each\nother, and distribute and access important resources. The paper then questions\nwhether robots should be queered, and what ethical implications this raises.\nFinally, the paper makes suggestions for what aspirational queer robotics\nfutures may look like, and what would be required to get there.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u63a2\u7d22\u6027\u8bba\u6587\u5f62\u5f0f\u63a2\u8ba8\u4e86\u516c\u5e73\u673a\u5668\u4eba\u8fd9\u4e00\u8bdd\u9898\uff0c\u7279\u522b\u5173\u6ce8LGBTQ+\u7fa4\u4f53\u8bbe\u8ba1\u548c\u4f7f\u7528\u7684\u673a\u5668\u4eba\uff0c\u65e8\u5728\u5f15\u53d1\u5173\u4e8e\u7406\u60f3\u5316\u9177\u513f\u673a\u5668\u4eba\u672a\u6765\u7684\u601d\u8003\u3002", "motivation": "\u6fc0\u53d1\u5173\u4e8e\u9177\u513f\u673a\u5668\u4eba\u672a\u6765\u5728\u827a\u672f\u548c\u79d1\u5b66\u9886\u57df\u7684\u8ba8\u8bba\uff0c\u63a2\u7d22\u5176\u6f5c\u529b\u548c\u4f26\u7406\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u4e09\u4e2a\u63a8\u6d4b\u6027\u8bbe\u8ba1\u63d0\u6848\uff1a1\uff09\u53cd\u6620\u9177\u513f\u7528\u6237\u7684\u8eab\u4efd\uff1b2\uff09\u7528\u9177\u513f\u673a\u5668\u4eba\u8eab\u4efd\u8868\u6f14\u51cf\u5c11\u504f\u89c1\uff1b3\uff09\u5efa\u7acb\u9177\u513f\u673a\u5668\u4eba\u7f51\u7edc\u5171\u4eab\u8d44\u6e90\u3002", "result": "\u63d0\u51fa\u4e86\u9177\u513f\u673a\u5668\u4eba\u7684\u6f5c\u5728\u89d2\u8272\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\uff0c\u5e76\u63a2\u8ba8\u4e86\u4f26\u7406\u95ee\u9898\u3002", "conclusion": "\u6587\u7ae0\u603b\u7ed3\u4e86\u9177\u513f\u673a\u5668\u4eba\u7684\u672a\u6765\u53ef\u80fd\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u73b0\u8fd9\u4e00\u613f\u666f\u6240\u9700\u7684\u52aa\u529b\u3002"}}
{"id": "2509.01814", "pdf": "https://arxiv.org/pdf/2509.01814", "abs": "https://arxiv.org/abs/2509.01814", "authors": ["Shreyas Tirumala", "Nishant Jain", "Danny D. Leybzon", "Trent D. Buskirk"], "title": "Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Transformer-based Large Language Models (LLMs) have paved the way for \"AI\ninterviewers\" that can administer voice-based surveys with respondents in\nreal-time. This position paper reviews emerging evidence to understand when\nsuch AI interviewing systems are fit for purpose for collecting data within\nquantitative and qualitative research contexts. We evaluate the capabilities of\nAI interviewers as well as current Interactive Voice Response (IVR) systems\nacross two dimensions: input/output performance (i.e., speech recognition,\nanswer recording, emotion handling) and verbal reasoning (i.e., ability to\nprobe, clarify, and handle branching logic). Field studies suggest that AI\ninterviewers already exceed IVR capabilities for both quantitative and\nqualitative data collection, but real-time transcription error rates, limited\nemotion detection abilities, and uneven follow-up quality indicate that the\nutility, use and adoption of current AI interviewer technology may be\ncontext-dependent for qualitative data collection efforts.", "AI": {"tldr": "Transformer\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u50ac\u751f\u4e86\u201cAI\u9762\u8bd5\u5b98\u201d\uff0c\u80fd\u591f\u5b9e\u65f6\u8fdb\u884c\u8bed\u97f3\u8c03\u67e5\u3002\u672c\u6587\u63a2\u8ba8\u4e86AI\u9762\u8bd5\u7cfb\u7edf\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5206\u6790\u5176\u8f93\u5165/\u8f93\u51fa\u6027\u80fd\u4e0e\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u3002AI\u9762\u8bd5\u5b98\u5728\u6570\u636e\u6536\u96c6\u65b9\u9762\u5df2\u4f18\u4e8e\u4f20\u7edfIVR\u7cfb\u7edf\uff0c\u4f46\u5728\u8f6c\u5f55\u9519\u8bef\u7387\u3001\u60c5\u611f\u68c0\u6d4b\u548c\u540e\u7eed\u95ee\u9898\u8d28\u91cf\u4e0a\u4ecd\u6709\u5c40\u9650\uff0c\u9002\u7528\u6027\u9700\u7ed3\u5408\u5177\u4f53\u60c5\u5883\u3002", "motivation": "\u8bc4\u4f30AI\u9762\u8bd5\u7cfb\u7edf\u7684\u9002\u7528\u6027\uff0c\u4ee5\u786e\u5b9a\u5176\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83AI\u9762\u8bd5\u5b98\u4e0e\u4f20\u7edfIVR\u7cfb\u7edf\u5728\u8f93\u5165/\u8f93\u51fa\u6027\u80fd\u548c\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u5408\u5b9e\u5730\u7814\u7a76\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "AI\u9762\u8bd5\u5b98\u5728\u6570\u636e\u6536\u96c6\u65b9\u9762\u4f18\u4e8eIVR\u7cfb\u7edf\uff0c\u4f46\u5728\u5b9e\u65f6\u8f6c\u5f55\u9519\u8bef\u7387\u3001\u60c5\u611f\u68c0\u6d4b\u548c\u540e\u7eed\u95ee\u9898\u8d28\u91cf\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u5f53\u524dAI\u9762\u8bd5\u6280\u672f\u6548\u679c\u663e\u8457\uff0c\u5c24\u5176\u5728\u5b9a\u91cf\u7814\u7a76\u4e2d\uff0c\u4f46\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u9002\u7528\u6027\u53d7\u9650\u4e8e\u5176\u6280\u672f\u7f3a\u9677\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2509.01909", "pdf": "https://arxiv.org/pdf/2509.01909", "abs": "https://arxiv.org/abs/2509.01909", "authors": ["Ranjie Duan", "Jiexi Liu", "Xiaojun Jia", "Shiji Zhao", "Ruoxi Cheng", "Fengxiang Wang", "Cheng Wei", "Yong Xie", "Chang Liu", "Defeng Li", "Yinpeng Dong", "Yichi Zhang", "Yuefeng Chen", "Chongwen Wang", "Xingjun Ma", "Xingxing Wei", "Yang Liu", "Hang Su", "Jun Zhu", "Xinfeng Li", "Yitong Sun", "Jie Zhang", "Jinzhao Hu", "Sha Xu", "Yitong Yang", "Jialing Tao", "Hui Xue"], "title": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SC"], "comment": "Technical Report", "summary": "Large language models (LLMs) typically deploy safety mechanisms to prevent\nharmful content generation. Most current approaches focus narrowly on risks\nposed by malicious actors, often framing risks as adversarial events and\nrelying on defensive refusals. However, in real-world settings, risks also come\nfrom non-malicious users seeking help while under psychological distress (e.g.,\nself-harm intentions). In such cases, the model's response can strongly\ninfluence the user's next actions. Simple refusals may lead them to repeat,\nescalate, or move to unsafe platforms, creating worse outcomes. We introduce\nConstructive Safety Alignment (CSA), a human-centric paradigm that protects\nagainst malicious misuse while actively guiding vulnerable users toward safe\nand helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic\nanticipation of user reactions, fine-grained risk boundary discovery, and\ninterpretable reasoning control, turning safety into a trust-building process.\nOy1 achieves state-of-the-art safety among open models while retaining high\ngeneral capabilities. On our Constructive Benchmark, it shows strong\nconstructive engagement, close to GPT-5, and unmatched robustness on the\nStrata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from\nrefusal-first to guidance-first safety, CSA redefines the model-user\nrelationship, aiming for systems that are not just safe, but meaningfully\nhelpful. We release Oy1, code, and the benchmark to support responsible,\nuser-centered AI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Constructive Safety Alignment (CSA)\uff0c\u4e00\u79cd\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5b89\u5168\u8303\u5f0f\uff0c\u4e0d\u4ec5\u9632\u6b62\u6076\u610f\u4f7f\u7528\uff0c\u8fd8\u4e3b\u52a8\u5f15\u5bfc\u5fc3\u7406\u56f0\u6270\u7684\u7528\u6237\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u673a\u5236\u4e3b\u8981\u5173\u6ce8\u5bf9\u6297\u6027\u98ce\u9669\uff0c\u5ffd\u89c6\u4e86\u975e\u6076\u610f\u7528\u6237\u7684\u5fc3\u7406\u9700\u6c42\uff0c\u7b80\u5355\u7684\u62d2\u7edd\u53ef\u80fd\u5e26\u6765\u8d1f\u9762\u540e\u679c\u3002", "method": "CSA\u7ed3\u5408\u535a\u5f08\u8bba\u7684\u7528\u6237\u53cd\u5e94\u9884\u6d4b\u3001\u7ec6\u7c92\u5ea6\u98ce\u9669\u8fb9\u754c\u53d1\u73b0\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u63a7\u5236\uff0c\u901a\u8fc7Oy1\u6a21\u578b\u5b9e\u73b0\u3002", "result": "Oy1\u5728\u5b89\u5168\u6027\u548c\u901a\u7528\u80fd\u529b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1GPT-5\u7684\u5f15\u5bfc\u6548\u679c\uff0c\u4e14\u5728Strata-Sword\u6570\u636e\u96c6\u4e0a\u63a5\u8fd1GPT-o1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "CSA\u4ece\u62d2\u7edd\u4f18\u5148\u8f6c\u5411\u5f15\u5bfc\u4f18\u5148\u7684\u5b89\u5168\u673a\u5236\uff0c\u91cd\u5851\u6a21\u578b\u4e0e\u7528\u6237\u5173\u7cfb\uff0c\u63a8\u52a8AI\u7684\u8d1f\u8d23\u4efb\u53d1\u5c55\u3002"}}
{"id": "2509.01996", "pdf": "https://arxiv.org/pdf/2509.01996", "abs": "https://arxiv.org/abs/2509.01996", "authors": ["Chi Sun", "Xian Wang", "Abhishek Kumar", "Chengbin Cui", "Lik-Hang Lee"], "title": "MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation", "categories": ["cs.RO", "cs.HC"], "comment": "Accepted by ISMAR 2025", "summary": "Effective human-robot interaction (HRI) in multi-object teleoperation tasks\nfaces significant challenges due to perceptual ambiguities in virtual reality\n(VR) environments and the limitations of single-modality intention recognition.\nThis paper proposes a shared control framework that combines a virtual\nadmittance (VA) model with a Multimodal-CNN-based Human Intention Perception\nNetwork (MMIPN) to enhance teleoperation performance and user experience. The\nVA model employs artificial potential fields to guide operators toward target\nobjects by adjusting admittance force and optimizing motion trajectories. MMIPN\nprocesses multimodal inputs, including gaze movement, robot motions, and\nenvironmental context, to estimate human grasping intentions, helping to\novercome depth perception challenges in VR. Our user study evaluated four\nconditions across two factors, and the results showed that MMIPN significantly\nimproved grasp success rates, while the VA model enhanced movement efficiency\nby reducing path lengths. Gaze data emerged as the most crucial input modality.\nThese findings demonstrate the effectiveness of combining multimodal cues with\nimplicit guidance in VR-based teleoperation, providing a robust solution for\nmulti-object grasping tasks and enabling more natural interactions across\nvarious applications in the future.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u865a\u62df\u5bfc\u7eb3\u6a21\u578b\u548c\u591a\u6a21\u6001CNN\u7f51\u7edc\u7684\u5171\u4eab\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u591a\u7269\u4f53\u9065\u64cd\u4f5c\u4e2d\u7684\u4eba\u673a\u4ea4\u4e92\u6027\u80fd\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u89e3\u51b3\u865a\u62df\u73b0\u5b9e\u73af\u5883\u4e2d\u591a\u7269\u4f53\u9065\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u611f\u77e5\u6a21\u7cca\u6027\u548c\u5355\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u865a\u62df\u5bfc\u7eb3\u6a21\u578b\u4f18\u5316\u8fd0\u52a8\u8f68\u8ff9\uff0c\u5e76\u7ed3\u5408\u591a\u6a21\u6001CNN\u7f51\u7edc\uff08MMIPN\uff09\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u4ee5\u4f30\u8ba1\u4eba\u7c7b\u6293\u53d6\u610f\u56fe\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cMMIPN\u663e\u8457\u63d0\u9ad8\u4e86\u6293\u53d6\u6210\u529f\u7387\uff0c\u865a\u62df\u5bfc\u7eb3\u6a21\u578b\u51cf\u5c11\u4e86\u8def\u5f84\u957f\u5ea6\u3002", "conclusion": "\u7ed3\u5408\u591a\u6a21\u6001\u7ebf\u7d22\u548c\u9690\u5f0f\u6307\u5bfc\u5728\u591a\u7269\u4f53\u6293\u53d6\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u672a\u6765\u66f4\u81ea\u7136\u7684\u4ea4\u4e92\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02355", "pdf": "https://arxiv.org/pdf/2509.02355", "abs": "https://arxiv.org/abs/2509.02355", "authors": ["Caterina Fuster-Barcelo", "Gonzalo R. Rios-Munoz", "Arrate Munoz-Barrutia"], "title": "Scaffolding Collaborative Learning in STEM: A Two-Year Evaluation of a Tool-Integrated Project-Based Methodology", "categories": ["cs.LG", "cs.CY", "cs.HC"], "comment": null, "summary": "This study examines the integration of digital collaborative tools and\nstructured peer evaluation in the Machine Learning for Health master's program,\nthrough the redesign of a Biomedical Image Processing course over two academic\nyears. The pedagogical framework combines real-time programming with Google\nColab, experiment tracking and reporting via Weights & Biases, and\nrubric-guided peer assessment to foster student engagement, transparency, and\nfair evaluation. Compared to a pre-intervention cohort, the two implementation\nyears showed increased grade dispersion and higher entropy in final project\nscores, suggesting improved differentiation and fairness in assessment. The\nsurvey results further indicate greater student engagement with the subject and\ntheir own learning process. These findings highlight the potential of\nintegrating tool-supported collaboration and structured evaluation mechanisms\nto enhance both learning outcomes and equity in STEM education.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6574\u5408\u6570\u5b57\u534f\u4f5c\u5de5\u5177\u548c\u7ed3\u6784\u5316\u540c\u4f34\u8bc4\u4f30\uff0c\u6539\u8fdb\u4e86\u751f\u7269\u533b\u5b66\u56fe\u50cf\u5904\u7406\u8bfe\u7a0b\u7684\u6559\u5b66\u6548\u679c\uff0c\u63d0\u5347\u4e86\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u8bc4\u4f30\u516c\u5e73\u6027\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u6570\u5b57\u5de5\u5177\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\u673a\u5236\u63d0\u5347STEM\u6559\u80b2\u4e2d\u7684\u5b66\u4e60\u6548\u679c\u548c\u516c\u5e73\u6027\u3002", "method": "\u7ed3\u5408Google Colab\u5b9e\u65f6\u7f16\u7a0b\u3001Weights & Biases\u5b9e\u9a8c\u8ffd\u8e2a\u4e0e\u62a5\u544a\uff0c\u4ee5\u53ca\u57fa\u4e8e\u91cf\u89c4\u7684\u540c\u4f34\u8bc4\u4f30\u3002", "result": "\u5b9e\u65bd\u540e\u6210\u7ee9\u79bb\u6563\u5ea6\u548c\u6700\u7ec8\u9879\u76ee\u5f97\u5206\u71b5\u503c\u589e\u52a0\uff0c\u8c03\u67e5\u663e\u793a\u5b66\u751f\u53c2\u4e0e\u5ea6\u63d0\u9ad8\u3002", "conclusion": "\u6570\u5b57\u534f\u4f5c\u5de5\u5177\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\u673a\u5236\u6709\u52a9\u4e8e\u4f18\u5316STEM\u6559\u80b2\u7684\u5b66\u4e60\u6548\u679c\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2509.02425", "pdf": "https://arxiv.org/pdf/2509.02425", "abs": "https://arxiv.org/abs/2509.02425", "authors": ["Yifan Xu", "Qianwei Wang", "Vineet Kamat", "Carol Menassa"], "title": "OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments", "categories": ["cs.RO", "cs.HC"], "comment": "32 pages, 6 figures", "summary": "Indoor built environments like homes and offices often present complex and\ncluttered layouts that pose significant challenges for individuals who are\nblind or visually impaired, especially when performing tasks that involve\nlocating and gathering multiple objects. While many existing assistive\ntechnologies focus on basic navigation or obstacle avoidance, few systems\nprovide scalable and efficient multi-object search capabilities in real-world,\npartially observable settings. To address this gap, we introduce OpenGuide, an\nassistive mobile robot system that combines natural language understanding with\nvision-language foundation models (VLM), frontier-based exploration, and a\nPartially Observable Markov Decision Process (POMDP) planner. OpenGuide\ninterprets open-vocabulary requests, reasons about object-scene relationships,\nand adaptively navigates and localizes multiple target items in novel\nenvironments. Our approach enables robust recovery from missed detections\nthrough value decay and belief-space reasoning, resulting in more effective\nexploration and object localization. We validate OpenGuide in simulated and\nreal-world experiments, demonstrating substantial improvements in task success\nrate and search efficiency over prior methods. This work establishes a\nfoundation for scalable, human-centered robotic assistance in assisted living\nenvironments.", "AI": {"tldr": "OpenGuide\u662f\u4e00\u4e2a\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8f85\u52a9\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u7528\u4e8e\u5e2e\u52a9\u89c6\u969c\u4eba\u58eb\u5728\u590d\u6742\u5ba4\u5185\u73af\u5883\u4e2d\u9ad8\u6548\u641c\u7d22\u591a\u5bf9\u8c61\u3002", "motivation": "\u73b0\u6709\u8f85\u52a9\u6280\u672f\u591a\u5173\u6ce8\u57fa\u7840\u5bfc\u822a\u6216\u969c\u788d\u907f\u8ba9\uff0c\u4f46\u5728\u590d\u6742\u3001\u90e8\u5206\u53ef\u89c2\u5bdf\u73af\u5883\u4e2d\u7f3a\u4e4f\u9ad8\u6548\u7684\u591a\u5bf9\u8c61\u641c\u7d22\u80fd\u529b\u3002", "method": "\u7cfb\u7edf\u6574\u5408\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3001\u524d\u6cbf\u63a2\u7d22\u548cPOMDP\u89c4\u5212\u5668\uff0c\u652f\u6301\u5f00\u653e\u8bcd\u6c47\u8bf7\u6c42\u548c\u9002\u5e94\u6027\u5bfc\u822a\u3002", "result": "\u5b9e\u9a8c\u663e\u793aOpenGuide\u5728\u641c\u7d22\u6210\u529f\u7387\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8f85\u52a9\u751f\u6d3b\u73af\u5883\u4e2d\u7684\u89c4\u6a21\u5316\u3001\u4eba\u672c\u5316\u673a\u5668\u4eba\u534f\u52a9\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.02442", "pdf": "https://arxiv.org/pdf/2509.02442", "abs": "https://arxiv.org/abs/2509.02442", "authors": ["Chen Sun", "Wenqi Zhang", "Bizhu Wang", "Xiaodong Xu", "Chau Yuen", "Yan Zhang", "Ping Zhang"], "title": "Know What, Know Why: Semantic Hazard Communication for Intelligent V2X Systems", "categories": ["eess.SP", "cs.HC"], "comment": null, "summary": "In current vehicle-to-everything (V2X) communication systems, roadside units\n(RSUs) broadcast brief warning messages that alert nearby vehicles to avoid\npotential hazards. However, these messages lack contextual information on why a\nwarning is issued, leading to excessive caution or inefficient driving\nbehaviors. To avoid such a situation, we propose a semantic-enhanced and\nexplainable V2X (SEE-V2X) system. In the proposed system, RSUs equipped with\nsmart cameras detect obstructions and transmit context-aware messages to\nvehicles. By understanding both what the hazard is and why it occurs, drivers\ncan make more intelligent decisions based on their specific driving situation.\nFurthermore, through a real-field demonstration, we show the new \"see-through\"\nfeature in the proposed system, which enables drivers to visualize hidden\npedestrians behind obstacles. We also perform simulations to compare\ntraditional V2X with SEE-V2X under different traffic conditions. The results\nshow that SEE-V2X significantly improves traffic efficiency and reduces\nunnecessary deceleration.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u589e\u5f3a\u4e14\u53ef\u89e3\u91ca\u7684V2X\uff08SEE-V2X\uff09\u7cfb\u7edf\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8b66\u544a\u4fe1\u606f\uff0c\u5e2e\u52a9\u9a7e\u9a76\u5458\u505a\u51fa\u66f4\u660e\u667a\u7684\u9a7e\u9a76\u51b3\u7b56\u3002", "motivation": "\u5f53\u524d\u7684V2X\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u8def\u8fb9\u5355\u5143\uff08RSUs\uff09\u5e7f\u64ad\u7684\u8b66\u544a\u4fe1\u606f\u7f3a\u4e4f\u4e0a\u4e0b\u6587\uff0c\u5bfc\u81f4\u9a7e\u9a76\u5458\u8fc7\u5ea6\u8c28\u614e\u6216\u9a7e\u9a76\u884c\u4e3a\u4f4e\u6548\u3002", "method": "\u63d0\u51faSEE-V2X\u7cfb\u7edf\uff0cRSUs\u914d\u5907\u667a\u80fd\u6444\u50cf\u5934\u68c0\u6d4b\u969c\u788d\u7269\uff0c\u5e76\u4f20\u8f93\u4e0a\u4e0b\u6587\u611f\u77e5\u4fe1\u606f\uff1b\u901a\u8fc7\u5b9e\u5730\u6f14\u793a\u5c55\u793a\u201c\u900f\u89c6\u201d\u529f\u80fd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cSEE-V2X\u663e\u8457\u63d0\u9ad8\u4e86\u4ea4\u901a\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u51cf\u901f\u3002", "conclusion": "SEE-V2X\u901a\u8fc7\u589e\u5f3a\u4fe1\u606f\u7684\u8bed\u4e49\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f18\u5316\u4e86\u9a7e\u9a76\u51b3\u7b56\u548c\u4ea4\u901a\u6d41\u3002"}}
{"id": "2509.02444", "pdf": "https://arxiv.org/pdf/2509.02444", "abs": "https://arxiv.org/abs/2509.02444", "authors": ["Jingru Fan", "Yufan Dang", "Jingyao Wu", "Huatao Li", "Runde Yang", "Xiyuan Yang", "Yuheng Wang", "Zhong Zhang", "Yaxi Lu", "Yankai Lin", "Zhiyuan Liu", "Dahai Li", "Chen Qian"], "title": "AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": "Project at https://github.com/OpenBMB/AppCopilot", "summary": "With the raid evolution of large language models and multimodal foundation\nmodels, the mobile-agent landscape has proliferated without converging on the\nfundamental challenges. This paper identifies four core problems that must be\nsolved for mobile agents to deliver practical, scalable impact: (1)\ngeneralization across tasks, modalities, apps, and devices; (2) accuracy,\nspecifically precise on-screen interaction and click targeting; (3)\nlong-horizon capability for sustained, multi-step goals; and (4) efficiency,\nspecifically high-performance runtime on resource-constrained devices. We\npresent AppCopilot, a multimodal, multi-agent, general-purpose on-device\nassistant that operates across applications and constitutes a full-stack,\nclosed-loop system from data to deployment. AppCopilot operationalizes this\nposition through an end-to-end autonomous pipeline spanning data collection,\ntraining, deployment, high-quality and efficient inference, and mobile\napplication development. At the model layer, it integrates multimodal\nfoundation models with robust Chinese-English support. At the reasoning and\ncontrol layer, it combines chain-of-thought reasoning, hierarchical task\nplanning and decomposition, and multi-agent collaboration. At the execution\nlayer, it enables user personalization and experiential adaptation, voice\ninteraction, function calling, cross-app and cross-device orchestration, and\ncomprehensive mobile app support. The system design incorporates\nprofiling-driven optimization for latency, memory, and energy across\nheterogeneous hardware. Empirically, AppCopilot achieves significant\nimprovements along all four dimensions: stronger generalization,\nhigher-precision on-screen actions, more reliable long-horizon task completion,\nand faster, more resource-efficient runtime.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86AppCopilot\uff0c\u4e00\u4e2a\u591a\u6a21\u6001\u3001\u591a\u4ee3\u7406\u7684\u901a\u7528\u8bbe\u5907\u52a9\u624b\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8\u4ee3\u7406\u5728\u6cdb\u5316\u6027\u3001\u51c6\u786e\u6027\u3001\u957f\u8fdc\u4efb\u52a1\u80fd\u529b\u548c\u6548\u7387\u65b9\u9762\u7684\u56db\u5927\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u79fb\u52a8\u4ee3\u7406\u9886\u57df\u9762\u4e34\u7684\u6311\u6218\u5c1a\u672a\u6536\u655b\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u6cdb\u5316\u6027\u3001\u51c6\u786e\u6027\u3001\u957f\u8fdc\u4efb\u52a1\u80fd\u529b\u548c\u6548\u7387\u56db\u5927\u6838\u5fc3\u95ee\u9898\uff0c\u4ee5\u5b9e\u73b0\u5b9e\u7528\u5316\u3001\u53ef\u6269\u5c55\u7684\u79fb\u52a8\u4ee3\u7406\u5e94\u7528\u3002", "method": "AppCopilot\u91c7\u7528\u7aef\u5230\u7aef\u81ea\u4e3b\u7ba1\u9053\uff0c\u6574\u5408\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u548c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u3001\u5206\u5c42\u4efb\u52a1\u89c4\u5212\u4e0e\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u5e76\u901a\u8fc7\u4e2a\u6027\u5316\u914d\u7f6e\u548c\u5f02\u6784\u786c\u4ef6\u4f18\u5316\u5b9e\u73b0\u9ad8\u6548\u8fd0\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAppCopilot\u5728\u56db\u5927\u6838\u5fc3\u95ee\u9898\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff1a\u66f4\u5f3a\u7684\u6cdb\u5316\u6027\u3001\u66f4\u9ad8\u7cbe\u5ea6\u7684\u5c4f\u5e55\u64cd\u4f5c\u3001\u66f4\u53ef\u9760\u7684\u957f\u8fdc\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\u4ee5\u53ca\u66f4\u9ad8\u6548\u7684\u8fd0\u884c\u3002", "conclusion": "AppCopilot\u901a\u8fc7\u7cfb\u7edf\u8bbe\u8ba1\u548c\u4f18\u5316\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u79fb\u52a8\u4ee3\u7406\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02544", "pdf": "https://arxiv.org/pdf/2509.02544", "abs": "https://arxiv.org/abs/2509.02544", "authors": ["Haoming Wang", "Haoyang Zou", "Huatong Song", "Jiazhan Feng", "Junjie Fang", "Junting Lu", "Longxiang Liu", "Qinyu Luo", "Shihao Liang", "Shijue Huang", "Wanjun Zhong", "Yining Ye", "Yujia Qin", "Yuwen Xiong", "Yuxin Song", "Zhiyong Wu", "Bo Li", "Chen Dun", "Chong Liu", "Fuxing Leng", "Hanbin Wang", "Hao Yu", "Haobin Chen", "Hongyi Guo", "Jing Su", "Jingjia Huang", "Kai Shen", "Kaiyu Shi", "Lin Yan", "Peiyao Zhao", "Pengfei Liu", "Qinghao Ye", "Renjie Zheng", "Wayne Xin Zhao", "Wen Heng", "Wenhao Huang", "Wenqian Wang", "Xiaobo Qin", "Yi Lin", "Youbin Wu", "Zehui Chen", "Zihao Wang", "Baoquan Zhong", "Xinchun Zhang", "Xujing Li", "Yuanfan Li", "Zhongkai Zhao", "Chengquan Jiang", "Faming Wu", "Haotian Zhou", "Jinlin Pang", "Li Han", "Qianli Ma", "Siyao Liu", "Songhua Cai", "Wenqi Fu", "Xin Liu", "Zhi Zhang", "Bo Zhou", "Guoliang Li", "Jiajun Shi", "Jiale Yang", "Jie Tang", "Li Li", "Taoran Lu", "Woyu Lin", "Xiaokang Tong", "Xinyao Li", "Yichi Zhang", "Yu Miao", "Zhengxuan Jiang", "Zili Li", "Ziyuan Zhao", "Chenxin Li", "Dehua Ma", "Feng Lin", "Ge Zhang", "Haihua Yang", "Hangyu Guo", "Hongda Zhu", "Jiaheng Liu", "Junda Du", "Kai Cai", "Kuanye Li", "Lichen Yuan", "Meilan Han", "Minchao Wang", "Shuyue Guo", "Tianhao Cheng", "Xiaobo Ma", "Xiaojun Xiao", "Xiaolong Huang", "Xinjie Chen", "Yidi Du", "Yilin Chen", "Yiwen Wang", "Zhaojian Li", "Zhenzhu Yang", "Zhiyuan Zeng", "Chaolin Jin", "Chen Li", "Hao Chen", "Haoli Chen", "Jian Chen", "Qinghao Zhao", "Guang Shi"], "title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": null, "summary": "The development of autonomous agents for graphical user interfaces (GUIs)\npresents major challenges in artificial intelligence. While recent advances in\nnative agent models have shown promise by unifying perception, reasoning,\naction, and memory through end-to-end learning, open problems remain in data\nscalability, multi-turn reinforcement learning (RL), the limitations of\nGUI-only operation, and environment stability. In this technical report, we\npresent UI-TARS-2, a native GUI-centered agent model that addresses these\nchallenges through a systematic training methodology: a data flywheel for\nscalable data generation, a stabilized multi-turn RL framework, a hybrid GUI\nenvironment that integrates file systems and terminals, and a unified sandbox\nplatform for large-scale rollouts. Empirical evaluation demonstrates that\nUI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.\nOn GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on\nWindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines\nsuch as Claude and OpenAI agents. In game environments, it attains a mean\nnormalized score of 59.8 across a 15-game suite-roughly 60% of human-level\nperformance-and remains competitive with frontier proprietary models (e.g.,\nOpenAI o3) on LMGame-Bench. Additionally, the model can generalize to\nlong-horizon information-seeking tasks and software engineering benchmarks,\nhighlighting its robustness across diverse agent tasks. Detailed analyses of\ntraining dynamics further provide insights into achieving stability and\nefficiency in large-scale agent RL. These results underscore UI-TARS-2's\npotential to advance the state of GUI agents and exhibit strong generalization\nto real-world interactive scenarios.", "AI": {"tldr": "UI-TARS-2\u662f\u4e00\u4e2a\u9762\u5411\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u7684\u81ea\u4e3b\u4ee3\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u8bad\u7ec3\u65b9\u6cd5\uff08\u5982\u6570\u636e\u98de\u8f6e\u3001\u591a\u56de\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7b49\uff09\u89e3\u51b3\u4e86\u6570\u636e\u6269\u5c55\u6027\u3001\u73af\u5883\u7a33\u5b9a\u6027\u7b49\u95ee\u9898\uff0c\u5e76\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f00\u53d1\u81ea\u4e3bGUI\u4ee3\u7406\u9762\u4e34\u6570\u636e\u6269\u5c55\u6027\u3001\u591a\u56de\u5408\u5f3a\u5316\u5b66\u4e60\u7b49\u6311\u6218\uff0cUI-TARS-2\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6570\u636e\u98de\u8f6e\u751f\u6210\u53ef\u6269\u5c55\u6570\u636e\u3001\u7a33\u5b9a\u7684\u591a\u56de\u5408RL\u6846\u67b6\u3001\u6df7\u5408GUI\u73af\u5883\u53ca\u7edf\u4e00\u6c99\u76d2\u5e73\u53f0\u3002", "result": "\u5728GUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5982Online-Mind2Web\uff0888.2\u5206\uff09\uff0c\u5e76\u5728\u6e38\u620f\u73af\u5883\u548c\u957f\u65f6\u4fe1\u606f\u4efb\u52a1\u4e2d\u5c55\u73b0\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "UI-TARS-2\u663e\u8457\u63a8\u8fdb\u4e86GUI\u4ee3\u7406\u7684\u73b0\u72b6\uff0c\u5e76\u5728\u5b9e\u9645\u4ea4\u4e92\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002"}}
