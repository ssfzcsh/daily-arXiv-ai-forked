{"id": "2507.19549", "pdf": "https://arxiv.org/pdf/2507.19549", "abs": "https://arxiv.org/abs/2507.19549", "authors": ["Nadeen Fathallah", "Daniel Hern\u00e1ndez", "Steffen Staab"], "title": "AccessGuru: Leveraging LLMs to Detect and Correct Web Accessibility Violations in HTML Code", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The vast majority of Web pages fail to comply with established Web\naccessibility guidelines, excluding a range of users with diverse abilities\nfrom interacting with their content. Making Web pages accessible to all users\nrequires dedicated expertise and additional manual efforts from Web page\nproviders. To lower their efforts and promote inclusiveness, we aim to\nautomatically detect and correct Web accessibility violations in HTML code.\nWhile previous work has made progress in detecting certain types of\naccessibility violations, the problem of automatically detecting and correcting\naccessibility violations remains an open challenge that we address. We\nintroduce a novel taxonomy classifying Web accessibility violations into three\nkey categories - Syntactic, Semantic, and Layout. This taxonomy provides a\nstructured foundation for developing our detection and correction method and\nredefining evaluation metrics. We propose a novel method, AccessGuru, which\ncombines existing accessibility testing tools and Large Language Models (LLMs)\nto detect violations and applies taxonomy-driven prompting strategies to\ncorrect all three categories. To evaluate these capabilities, we develop a\nbenchmark of real-world Web accessibility violations. Our benchmark quantifies\nsyntactic and layout compliance and judges semantic accuracy through\ncomparative analysis with human expert corrections. Evaluation against our\nbenchmark shows that AccessGuru achieves up to 84% average violation score\ndecrease, significantly outperforming prior methods that achieve at most 50%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u68c0\u6d4b\u548c\u4fee\u6b63\u7f51\u9875\u65e0\u969c\u788d\u6027\u8fdd\u89c4\u7684\u65b0\u65b9\u6cd5AccessGuru\uff0c\u7ed3\u5408\u73b0\u6709\u6d4b\u8bd5\u5de5\u5177\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u901a\u8fc7\u65b0\u7684\u5206\u7c7b\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5927\u591a\u6570\u7f51\u9875\u4e0d\u7b26\u5408\u65e0\u969c\u788d\u6027\u6307\u5357\uff0c\u5f71\u54cd\u4e86\u591a\u6837\u5316\u7528\u6237\u7684\u8bbf\u95ee\u3002\u81ea\u52a8\u5316\u68c0\u6d4b\u548c\u4fee\u6b63\u53ef\u4ee5\u964d\u4f4e\u4eba\u5de5\u6210\u672c\u5e76\u4fc3\u8fdb\u5305\u5bb9\u6027\u3002", "method": "\u63d0\u51faSyntactic\u3001Semantic\u548cLayout\u4e09\u7c7b\u5206\u7c7b\u6cd5\uff0c\u7ed3\u5408\u73b0\u6709\u5de5\u5177\u548cLLMs\u5f00\u53d1AccessGuru\uff0c\u5e76\u901a\u8fc7\u65b0\u57fa\u51c6\u8bc4\u4f30\u3002", "result": "AccessGuru\u5e73\u5747\u8fdd\u89c4\u5206\u6570\u51cf\u5c1184%\uff0c\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u65b9\u6cd5\u768450%\u3002", "conclusion": "AccessGuru\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u9875\u65e0\u969c\u788d\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19687", "pdf": "https://arxiv.org/pdf/2507.19687", "abs": "https://arxiv.org/abs/2507.19687", "authors": ["Joao Pedro Duarte", "Paulo Borba", "Guilherme Cavalcanti"], "title": "LastMerge: A language-agnostic structured tool for code integration", "categories": ["cs.SE"], "comment": null, "summary": "Unstructured line-based merge tools are widely used in practice. Structured\nAST-based merge tools show significantly improved merge accuracy, but are\nrarely used in practice because they are language specific and costly,\nconsequently not being available for many programming languages. To improve\nmerge accuracy for a wide range of languages, we propose LastMerge, a generic\nstructured merge tool that can be configured through a thin interface that\nsignificantly reduces the effort of supporting structured merge. To understand\nthe impact that generic structured merge might have on merge accuracy and\nperformance, we run an experiment with four structured merge tools: two Java\nspecific tools, jDime and Spork, and their generic counterparts, respectively\nLastMerge and Mergiraf. Using each tool, we replay merge scenarios from a\nsignificant dataset, and collect data on runtime, behavioral divergences, and\nmerge accuracy. Our results show no evidence that generic structured merge\nsignificantly impacts merge accuracy. Although we observe a difference rate of\napproximately 10% between the Java specific tools and their generic\ncounterparts, most of the differences stem from implementation details and\ncould be avoided. We find that LastMerge reports 15% fewer false positives than\njDime while Mergiraf misses 42% fewer false negatives than Spork. Both generic\ntools exhibit comparable runtime performance to the state of the art language\nspecific implementations. These results suggest that generic structured merge\ntools can effectively replace language-specific ones, paving the way for\nbroader adoption of structured merge in industry.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u7ed3\u6784\u5316\u5408\u5e76\u5de5\u5177LastMerge\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u5408\u5e76\u51c6\u786e\u6027\u548c\u6027\u80fd\u4e0a\u4e0e\u7279\u5b9a\u8bed\u8a00\u7684\u5de5\u5177\u76f8\u5f53\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8eAST\u7684\u7ed3\u6784\u5316\u5408\u5e76\u5de5\u5177\u5728\u5408\u5e76\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u8bed\u8a00\u7279\u5b9a\u6027\u548c\u9ad8\u6210\u672c\uff0c\u5b9e\u9645\u5e94\u7528\u8f83\u5c11\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u901a\u7528\u7684\u7ed3\u6784\u5316\u5408\u5e76\u5de5\u5177\u3002", "method": "\u63d0\u51faLastMerge\uff0c\u4e00\u79cd\u901a\u8fc7\u8f7b\u91cf\u63a5\u53e3\u914d\u7f6e\u7684\u901a\u7528\u7ed3\u6784\u5316\u5408\u5e76\u5de5\u5177\uff0c\u5e76\u4e0e\u4e24\u79cdJava\u7279\u5b9a\u5de5\u5177\uff08jDime\u548cSpork\uff09\u53ca\u5176\u901a\u7528\u5bf9\u5e94\u5de5\u5177\uff08LastMerge\u548cMergiraf\uff09\u8fdb\u884c\u5b9e\u9a8c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u901a\u7528\u5de5\u5177\u5728\u5408\u5e76\u51c6\u786e\u6027\u4e0a\u4e0e\u7279\u5b9a\u8bed\u8a00\u5de5\u5177\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u8fd0\u884c\u65f6\u6027\u80fd\u76f8\u5f53\u3002LastMerge\u51cf\u5c11\u4e8615%\u7684\u5047\u9633\u6027\uff0cMergiraf\u51cf\u5c11\u4e8642%\u7684\u5047\u9634\u6027\u3002", "conclusion": "\u901a\u7528\u7ed3\u6784\u5316\u5408\u5e76\u5de5\u5177\u53ef\u6709\u6548\u66ff\u4ee3\u8bed\u8a00\u7279\u5b9a\u5de5\u5177\uff0c\u63a8\u52a8\u5176\u5728\u5de5\u4e1a\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2507.19714", "pdf": "https://arxiv.org/pdf/2507.19714", "abs": "https://arxiv.org/abs/2507.19714", "authors": ["Feifei Niu", "Junqian Shao", "Christoph Mayr-Dorn", "Liguo Huang", "Wesley K. G. Assun\u00e7\u00e3o", "Chuanyi Li", "Jidong Ge", "Alexander Egyed"], "title": "Refactoring $\\neq$ Bug-Inducing: Improving Defect Prediction with Code Change Tactics Analysis", "categories": ["cs.SE"], "comment": null, "summary": "Just-in-time defect prediction (JIT-DP) aims to predict the likelihood of\ncode changes resulting in software defects at an early stage. Although code\nchange metrics and semantic features have enhanced prediction accuracy, prior\nresearch has largely ignored code refactoring during both the evaluation and\nmethodology phases, despite its prevalence. Refactoring and its propagation\noften tangle with bug-fixing and bug-inducing changes within the same commit\nand statement. Neglecting refactoring can introduce bias into the learning and\nevaluation of JIT-DP models. To address this gap, we investigate the impact of\nrefactoring and its propagation on six state-of-the-art JIT-DP approaches. We\npropose Code chAnge Tactics (CAT) analysis to categorize code refactoring and\nits propagation, which improves labeling accuracy in the JIT-Defects4J dataset\nby 13.7%. Our experiments reveal that failing to consider refactoring\ninformation in the dataset can diminish the performance of models, particularly\nsemantic-based models, by 18.6% and 37.3% in F1-score. Additionally, we propose\nintegrating refactoring information to enhance six baseline approaches,\nresulting in overall improvements in recall and F1-score, with increases of up\nto 43.2% and 32.5%, respectively. Our research underscores the importance of\nincorporating refactoring information in the methodology and evaluation of\nJIT-DP. Furthermore, our CAT has broad applicability in analyzing refactoring\nand its propagation for software maintenance.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u91cd\u6784\u53ca\u5176\u4f20\u64ad\u5bf9JIT\u7f3a\u9677\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u63d0\u51faCAT\u5206\u6790\u4ee5\u6539\u8fdb\u6807\u7b7e\u51c6\u786e\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5ffd\u89c6\u91cd\u6784\u4f1a\u964d\u4f4e\u6a21\u578b\u6027\u80fd\uff0c\u6574\u5408\u91cd\u6784\u4fe1\u606f\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u6548\u679c\u3002", "motivation": "\u73b0\u6709JIT\u7f3a\u9677\u9884\u6d4b\u7814\u7a76\u591a\u5ffd\u89c6\u4ee3\u7801\u91cd\u6784\uff0c\u53ef\u80fd\u5bfc\u81f4\u5b66\u4e60\u548c\u8bc4\u4f30\u504f\u5dee\u3002", "method": "\u63d0\u51faCAT\u5206\u6790\u5206\u7c7b\u4ee3\u7801\u91cd\u6784\u53ca\u5176\u4f20\u64ad\uff0c\u6574\u5408\u91cd\u6784\u4fe1\u606f\u81f3\u516d\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "result": "\u5ffd\u89c6\u91cd\u6784\u4f7f\u6a21\u578b\u6027\u80fd\u4e0b\u964d18.6%-37.3%\uff0c\u6574\u5408\u91cd\u6784\u4fe1\u606f\u540e\u53ec\u56de\u7387\u548cF1\u5206\u6570\u5206\u522b\u63d0\u5347\u81f343.2%\u548c32.5%\u3002", "conclusion": "\u91cd\u6784\u4fe1\u606f\u5bf9JIT-DP\u65b9\u6cd5\u5b66\u548c\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\uff0cCAT\u5206\u6790\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2507.19721", "pdf": "https://arxiv.org/pdf/2507.19721", "abs": "https://arxiv.org/abs/2507.19721", "authors": ["Dapeng Yan", "Wenjie Yang", "Kui Liu", "Zhiming Liu", "Zhikuang Cai"], "title": "Clean Code In Practice: Challenges and Opportunities", "categories": ["cs.SE"], "comment": null, "summary": "Reliability prediction is crucial for ensuring the safety and security of\nsoftware systems, especially in the context of industry practices. While\nvarious metrics and measurements are employed to assess software reliability,\nthe complexity of modern systems necessitates a deeper understanding of how\nthese metrics interact with security and safety concerns. This paper explores\nthe interplay between software reliability, safety, and security, offering a\ncomprehensive analysis of key metrics and measurement techniques used in the\nindustry for reliability prediction. We identify critical threats to software\nreliability and provide a threat estimation framework that incorporates both\nsafety and security aspects. Our findings suggest that integrating reliability\nmetrics with safety and security considerations can enhance the robustness of\nsoftware systems. Furthermore, we propose a set of actionable guidelines for\npractitioners to improve their reliability prediction models while\nsimultaneously addressing the security and safety challenges of contemporary\nsoftware applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u4fdd\u969c\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5206\u6790\u4e86\u884c\u4e1a\u4e2d\u7684\u5173\u952e\u6307\u6807\u548c\u6d4b\u91cf\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u5b89\u5168\u548c\u4fdd\u969c\u65b9\u9762\u7684\u5a01\u80c1\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u5efa\u8bae\u5c06\u53ef\u9760\u6027\u6307\u6807\u4e0e\u5b89\u5168\u548c\u4fdd\u969c\u8003\u8651\u7ed3\u5408\u4ee5\u589e\u5f3a\u7cfb\u7edf\u5065\u58ee\u6027\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u7684\u590d\u6742\u6027\u8981\u6c42\u66f4\u6df1\u5165\u5730\u7406\u89e3\u53ef\u9760\u6027\u6307\u6807\u5982\u4f55\u4e0e\u5b89\u5168\u548c\u4fdd\u969c\u95ee\u9898\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u9884\u6d4b\u548c\u63d0\u9ad8\u7cfb\u7edf\u53ef\u9760\u6027\u3002", "method": "\u8bba\u6587\u5206\u6790\u884c\u4e1a\u4e2d\u7684\u5173\u952e\u6307\u6807\u548c\u6d4b\u91cf\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u5a01\u80c1\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u5b89\u5168\u548c\u4fdd\u969c\u56e0\u7d20\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c06\u53ef\u9760\u6027\u6307\u6807\u4e0e\u5b89\u5168\u548c\u4fdd\u969c\u8003\u8651\u7ed3\u5408\u53ef\u4ee5\u589e\u5f3a\u8f6f\u4ef6\u7684\u5065\u58ee\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u53ef\u64cd\u4f5c\u7684\u6307\u5357\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u5728\u6539\u8fdb\u53ef\u9760\u6027\u9884\u6d4b\u6a21\u578b\u7684\u540c\u65f6\uff0c\u5e94\u5bf9\u5f53\u4ee3\u8f6f\u4ef6\u5e94\u7528\u7684\u5b89\u5168\u548c\u4fdd\u969c\u6311\u6218\u3002"}}
{"id": "2507.19728", "pdf": "https://arxiv.org/pdf/2507.19728", "abs": "https://arxiv.org/abs/2507.19728", "authors": ["Lalita Na Nongkhai", "Jingyun Wang", "Takahiko Mendori"], "title": "Development and Evaluation of Adaptive LearningSupport System Based on Ontology of MultipleProgramming Languages", "categories": ["cs.PL"], "comment": "This document provides corrections to the published article.\n  Corrections include clarifying figure legends and addressing grammatical\n  issues to enhance clarity. The authors state that the scientific conclusions\n  are unaffected", "summary": "This paper introduces an ontology-based approach within an adaptive learning\nsupport system for computer programming. This system (named ADVENTURE) is\ndesigned to deliver personalized programming exercises that are tailored to\nindividual learners' skill levels. ADVENTURE utilizes an ontology, named\nCONTINUOUS, which encompasses common concepts across multiple programming\nlanguages. The system leverages this ontology not only to visualize programming\nconcepts but also to provide hints during practice programming exercises and\nrecommend subsequent programming concepts. The adaptive mechanism is driven by\nthe Elo Rating System, applied in an educational context to dynamically\nestimate the most appropriate exercise difficulty for each learner. An\nexperimental study compared two instructional modes, adaptive and random, based\non six features derived from 1,186 code submissions across all the experimental\ngroups. The results indicate significant differences in four of six analyzed\nfeatures between these two modes. Notably, the adaptive mode demonstrates a\nsignificant difference over the random mode in two features, the submission of\ncorrect answers and the number of pass concepts. Therefore, these results\nunderscore that this adaptive learning support system may support learners in\npracticing programming exercises.", "AI": {"tldr": "ADVENTURE\u7cfb\u7edf\u4f7f\u7528\u57fa\u4e8e\u672c\u4f53\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u652f\u6301\u65b9\u6cd5\uff0c\u4e3a\u7f16\u7a0b\u5b66\u4e60\u8005\u63d0\u4f9b\u4e2a\u6027\u5316\u7ec3\u4e60\uff0c\u5e76\u901a\u8fc7Elo\u8bc4\u5206\u7cfb\u7edf\u52a8\u6001\u8c03\u6574\u96be\u5ea6\uff0c\u5b9e\u9a8c\u8868\u660e\u81ea\u9002\u5e94\u6a21\u5f0f\u5728\u6b63\u786e\u7387\u548c\u638c\u63e1\u6982\u5ff5\u6570\u91cf\u4e0a\u4f18\u4e8e\u968f\u673a\u6a21\u5f0f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u7f16\u7a0b\u5b66\u4e60\u4e2d\u4e2a\u4f53\u5dee\u5f02\u5927\u3001\u4f20\u7edf\u6559\u5b66\u65b9\u6cd5\u96be\u4ee5\u4e2a\u6027\u5316\u7684\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u5b66\u4e60\u652f\u6301\u7cfb\u7edf\u3002", "method": "\u7cfb\u7edf\u5229\u7528\u540d\u4e3aCONTINUOUS\u7684\u672c\u4f53\u8de8\u8bed\u8a00\u7f16\u7a0b\u6982\u5ff5\uff0c\u7ed3\u5408Elo\u8bc4\u5206\u7cfb\u7edf\u52a8\u6001\u8c03\u6574\u7ec3\u4e60\u96be\u5ea6\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u63a8\u8350\u548c\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u6bd4\u8f83\u81ea\u9002\u5e94\u4e0e\u968f\u673a\u6a21\u5f0f\uff0c\u81ea\u9002\u5e94\u6a21\u5f0f\u5728\u6b63\u786e\u7387\u548c\u638c\u63e1\u6982\u5ff5\u6570\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u968f\u673a\u6a21\u5f0f\u3002", "conclusion": "ADVENTURE\u7cfb\u7edf\u901a\u8fc7\u81ea\u9002\u5e94\u673a\u5236\u6709\u6548\u652f\u6301\u7f16\u7a0b\u5b66\u4e60\uff0c\u63d0\u5347\u4e86\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2507.19630", "pdf": "https://arxiv.org/pdf/2507.19630", "abs": "https://arxiv.org/abs/2507.19630", "authors": ["Mauricio Ayala-Rinc\u00f3n", "Thaynara Arielly de Lima", "Georg Ehling", "Temur Kutsia"], "title": "Graded Quantitative Narrowing", "categories": ["cs.LO"], "comment": "24 pages, 2 figures", "summary": "The recently introduced framework of Graded Quantitative Rewriting is an\ninnovative extension of traditional rewriting systems, in which rules are\nannotated with degrees drawn from a quantale. This framework provides a robust\nfoundation for equational reasoning that incorporates metric aspects, such as\nthe proximity between terms and the complexity of rewriting-based computations.\nQuantitative narrowing, introduced in this paper, generalizes quantitative\nrewriting by replacing matching with unification in reduction steps, enabling\nthe reduction of terms even when they contain variables, through simultaneous\ninstantiation and rewriting. In the standard (non-quantitative) setting,\nnarrowing has been successfully applied in various domains, including\nfunctional logic programming, theorem proving, and equational unification.\nHere, we focus on quantitative narrowing to solve unification problems in\nquantitative equational theories over Lawverean quantales. We establish its\nsoundness and discuss conditions under which completeness can be ensured. This\napproach allows us to solve quantitative equations in richer theories than\nthose addressed by previous methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5316\u91cd\u5199\u7684\u6269\u5c55\u6846\u67b6\u2014\u2014\u5206\u7ea7\u91cf\u5316\u91cd\u5199\uff0c\u5e76\u901a\u8fc7\u91cf\u5316\u7a84\u5316\u89e3\u51b3\u4e86Lawverean\u91cf\u5316\u534a\u73af\u4e0a\u7684\u91cf\u5316\u65b9\u7a0b\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u91cd\u5199\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u5ea6\u91cf\u65b9\u9762\u7684\u652f\u6301\uff0c\u5982\u9879\u4e4b\u95f4\u7684\u63a5\u8fd1\u5ea6\u548c\u57fa\u4e8e\u91cd\u5199\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002\u5206\u7ea7\u91cf\u5316\u91cd\u5199\u6846\u67b6\u901a\u8fc7\u91cf\u5316\u89c4\u5219\u6269\u5c55\u4e86\u4f20\u7edf\u7cfb\u7edf\uff0c\u800c\u91cf\u5316\u7a84\u5316\u8fdb\u4e00\u6b65\u901a\u8fc7\u66ff\u6362\u5339\u914d\u4e3a\u7edf\u4e00\u5316\uff0c\u63d0\u5347\u4e86\u89e3\u51b3\u53d8\u91cf\u9879\u95ee\u9898\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u91cf\u5316\u7a84\u5316\u65b9\u6cd5\uff0c\u5c06\u5339\u914d\u66ff\u6362\u4e3a\u7edf\u4e00\u5316\uff0c\u540c\u65f6\u5728Lawverean\u91cf\u5316\u534a\u73af\u4e0a\u5efa\u7acb\u91cf\u5316\u7a84\u5316\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u9760\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u786e\u4fdd\u5b8c\u5907\u6027\u7684\u6761\u4ef6\u3002", "result": "\u91cf\u5316\u7a84\u5316\u80fd\u89e3\u51b3\u6bd4\u4ee5\u5f80\u65b9\u6cd5\u66f4\u4e30\u5bcc\u7684\u91cf\u5316\u65b9\u7a0b\u7406\u8bba\uff0c\u4e3a\u91cf\u5316\u65b9\u7a0b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u9014\u5f84\u3002", "conclusion": "\u91cf\u5316\u7a84\u5316\u4e3a\u5206\u7ea7\u91cf\u5316\u91cd\u5199\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u5176\u5728\u91cf\u5316\u65b9\u7a0b\u7406\u8bba\u4e2d\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2507.19718", "pdf": "https://arxiv.org/pdf/2507.19718", "abs": "https://arxiv.org/abs/2507.19718", "authors": ["David Bauer", "Qi Wu", "Hamid Gadirov", "Kwan-Liu Ma"], "title": "GSCache: Real-Time Radiance Caching for Volume Path Tracing using 3D Gaussian Splatting", "categories": ["cs.GR", "cs.LG"], "comment": null, "summary": "Real-time path tracing is rapidly becoming the standard for rendering in\nentertainment and professional applications. In scientific visualization,\nvolume rendering plays a crucial role in helping researchers analyze and\ninterpret complex 3D data. Recently, photorealistic rendering techniques have\ngained popularity in scientific visualization, yet they face significant\nchallenges. One of the most prominent issues is slow rendering performance and\nhigh pixel variance caused by Monte Carlo integration. In this work, we\nintroduce a novel radiance caching approach for path-traced volume rendering.\nOur method leverages advances in volumetric scene representation and adapts 3D\nGaussian splatting to function as a multi-level, path-space radiance cache.\nThis cache is designed to be trainable on the fly, dynamically adapting to\nchanges in scene parameters such as lighting configurations and transfer\nfunctions. By incorporating our cache, we achieve less noisy, higher-quality\nimages without increasing rendering costs. To evaluate our approach, we compare\nit against a baseline path tracer that supports uniform sampling and next-event\nestimation and the state-of-the-art for neural radiance caching. Through both\nquantitative and qualitative analyses, we demonstrate that our path-space\nradiance cache is a robust solution that is easy to integrate and significantly\nenhances the rendering quality of volumetric visualization applications while\nmaintaining comparable computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u8f90\u5c04\u7f13\u5b58\u65b9\u6cd5\uff0c\u7528\u4e8e\u8def\u5f84\u8ffd\u8e2a\u7684\u4f53\u7ed8\u5236\uff0c\u663e\u8457\u964d\u4f4e\u566a\u58f0\u5e76\u63d0\u9ad8\u6e32\u67d3\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u79d1\u5b66\u53ef\u89c6\u5316\u4e2d\uff0c\u771f\u5b9e\u611f\u6e32\u67d3\u6280\u672f\u56e0\u8499\u7279\u5361\u6d1b\u79ef\u5206\u5bfc\u81f4\u6e32\u67d3\u901f\u5ea6\u6162\u548c\u50cf\u7d20\u65b9\u5dee\u9ad8\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u75283D\u9ad8\u65af\u6591\u5757\u6280\u672f\uff0c\u8bbe\u8ba1\u53ef\u52a8\u6001\u9002\u5e94\u573a\u666f\u53c2\u6570\u53d8\u5316\u7684\u8def\u5f84\u7a7a\u95f4\u8f90\u5c04\u7f13\u5b58\uff0c\u5b9e\u65f6\u8bad\u7ec3\u4ee5\u51cf\u5c11\u566a\u58f0\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\u8def\u5f84\u8ffd\u8e2a\u5668\u548c\u795e\u7ecf\u8f90\u5c04\u7f13\u5b58\u65b9\u6cd5\uff0c\u65b0\u65b9\u6cd5\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6613\u4e8e\u96c6\u6210\uff0c\u663e\u8457\u63d0\u5347\u4f53\u7ed8\u5236\u5e94\u7528\u7684\u6e32\u67d3\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.19863", "pdf": "https://arxiv.org/pdf/2507.19863", "abs": "https://arxiv.org/abs/2507.19863", "authors": ["Chia-Ming Lee", "Bo-Cheng Qiu", "Cheng-Jun Kang", "Yi-Hsuan Wu", "Jun-Lin Chen", "Yu-Fan Lin", "Yi-Shiuan Chou", "Chih-Chung Hsu"], "title": "Anchoring Trends: Mitigating Social Media Popularity Prediction Drift via Feature Clustering and Expansion", "categories": ["cs.MM"], "comment": "Accepted by ACM Multimedia 2025", "summary": "Predicting online video popularity faces a critical challenge: prediction\ndrift, where models trained on historical data rapidly degrade due to evolving\nviral trends and user behaviors. To address this temporal distribution shift,\nwe propose an Anchored Multi-modal Clustering and Feature Generation (AMCFG)\nframework that discovers temporally-invariant patterns across data\ndistributions. Our approach employs multi-modal clustering to reveal content\nstructure, then leverages Large Language Models (LLMs) to generate semantic\nAnchor Features, such as audience demographics, content themes, and engagement\npatterns that transcend superficial trend variations. These semantic anchors,\ncombined with cluster-derived statistical features, enable prediction based on\nstable principles rather than ephemeral signals. Experiments demonstrate that\nAMCFG significantly enhances both predictive accuracy and temporal robustness,\nachieving superior performance on out-of-distribution data and providing a\nviable solution for real-world video popularity prediction.", "AI": {"tldr": "AMCFG\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u805a\u7c7b\u548cLLMs\u751f\u6210\u8bed\u4e49\u951a\u7279\u5f81\uff0c\u89e3\u51b3\u89c6\u9891\u6d41\u884c\u5ea6\u9884\u6d4b\u4e2d\u7684\u65f6\u95f4\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u65f6\u95f4\u9c81\u68d2\u6027\u3002", "motivation": "\u5728\u7ebf\u89c6\u9891\u6d41\u884c\u5ea6\u9884\u6d4b\u9762\u4e34\u65f6\u95f4\u5206\u5e03\u504f\u79fb\uff08\u9884\u6d4b\u6f02\u79fb\uff09\u7684\u6311\u6218\uff0c\u4f20\u7edf\u6a21\u578b\u56e0\u75c5\u6bd2\u8d8b\u52bf\u548c\u7528\u6237\u884c\u4e3a\u7684\u5feb\u901f\u53d8\u5316\u800c\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faAMCFG\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u805a\u7c7b\u548cLLMs\u751f\u6210\u8bed\u4e49\u951a\u7279\u5f81\uff08\u5982\u53d7\u4f17\u4eba\u53e3\u7edf\u8ba1\u3001\u5185\u5bb9\u4e3b\u9898\u7b49\uff09\uff0c\u5229\u7528\u7a33\u5b9a\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAMCFG\u5728\u5206\u5e03\u5916\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u548c\u65f6\u95f4\u9c81\u68d2\u6027\u3002", "conclusion": "AMCFG\u4e3a\u5728\u7ebf\u89c6\u9891\u6d41\u884c\u5ea6\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u57fa\u4e8e\u7a33\u5b9a\u539f\u5219\u800c\u975e\u77ed\u6682\u4fe1\u53f7\u8fdb\u884c\u9884\u6d4b\u3002"}}
{"id": "2507.19662", "pdf": "https://arxiv.org/pdf/2507.19662", "abs": "https://arxiv.org/abs/2507.19662", "authors": ["H. Umut Suluhan", "Jiahao Lin", "Serhan Gener", "Chaitali Chakrabarti", "Umit Ogras", "Ali Akoglu"], "title": "K-PACT: Kernel Planning for Adaptive Context Switching -- A Framework for Clustering, Placement, and Prefetching in Spectrum Sensing", "categories": ["cs.ET"], "comment": null, "summary": "Efficient wideband spectrum sensing requires rapid evaluation and\nre-evaluation of signal presence and type across multiple subchannels. These\ntasks involve multiple hypothesis testing, where each hypothesis is implemented\nas a decision tree workflow containing compute-intensive kernels, including\nFFT, matrix operations, and signal-specific analyses. Given dynamic nature of\nthe spectrum environment, ability to quickly switch between hypotheses is\nessential for maintaining low-latency, high-throughput operation. This work\nassumes a coarse-grained reconfigurable architecture consisting of an array of\nprocessing elements (PEs), each equipped with a local instruction memory (IMEM)\ncapable of storing and executing kernels used in spectrum sensing applications.\nWe propose a planner tool that efficiently maps hypothesis workflows onto this\narchitecture to enable fast runtime context switching with minimal overhead.\nThe planner performs two key tasks: clustering temporally non-overlapping\nkernels to share IMEM resources within a PE sub-array, and placing these\nclusters onto hardware to ensure efficient scheduling and data movement. By\npreloading kernels that are not simultaneously active into same IMEM, our tool\nenables low-latency reconfiguration without runtime conflicts. It models the\nplanning process as a multi-objective optimization, balancing trade-offs among\ncontext switch overhead, scheduling latency, and dataflow efficiency. We\nevaluate the proposed tool in simulated spectrum sensing scenario with 48\nconcurrent subchannels. Results show that our approach reduces off-chip binary\nfetches by 207.81x, lowers average switching time by 98.24x, and improves\nper-subband execution time by 132.92x over baseline without preloading. These\nimprovements demonstrate that intelligent planning is critical for adapting to\nfast-changing spectrum environments in next-generation radio frequency systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89c4\u5212\u5de5\u5177\uff0c\u7528\u4e8e\u5728\u53ef\u91cd\u6784\u67b6\u6784\u4e0a\u5feb\u901f\u6620\u5c04\u9891\u8c31\u611f\u77e5\u5047\u8bbe\u7684\u5de5\u4f5c\u6d41\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4e0a\u4e0b\u6587\u5207\u6362\u5f00\u9500\u548c\u6570\u636e\u79fb\u52a8\u5ef6\u8fdf\u3002", "motivation": "\u52a8\u6001\u9891\u8c31\u73af\u5883\u8981\u6c42\u5feb\u901f\u8bc4\u4f30\u548c\u91cd\u65b0\u8bc4\u4f30\u4fe1\u53f7\u7684\u5b58\u5728\u53ca\u7c7b\u578b\uff0c\u4f20\u7edf\u7684\u591a\u5047\u8bbe\u6d4b\u8bd5\u65b9\u6cd5\u56e0\u8ba1\u7b97\u5bc6\u96c6\u578b\u5185\u6838\u548c\u9891\u7e41\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\u3002", "method": "\u91c7\u7528\u7c97\u7c92\u5ea6\u53ef\u91cd\u6784\u67b6\u6784\uff0c\u63d0\u51fa\u4e00\u79cd\u89c4\u5212\u5de5\u5177\uff0c\u901a\u8fc7\u805a\u7c7b\u975e\u91cd\u53e0\u5185\u6838\u5e76\u4f18\u5316\u786c\u4ef6\u6620\u5c04\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u7684\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u5207\u6362\u3002", "result": "\u572848\u4e2a\u5e76\u53d1\u5b50\u901a\u9053\u7684\u6a21\u62df\u573a\u666f\u4e2d\uff0c\u5de5\u5177\u51cf\u5c11\u4e86207.81\u500d\u7684\u4e8c\u8fdb\u5236\u52a0\u8f7d\uff0c98.24\u500d\u7684\u5207\u6362\u65f6\u95f4\uff0c\u5e76\u63d0\u5347132.92\u500d\u7684\u6267\u884c\u6548\u7387\u3002", "conclusion": "\u667a\u80fd\u89c4\u5212\u5de5\u5177\u5bf9\u4e8e\u4e0b\u4e00\u4ee3\u5c04\u9891\u7cfb\u7edf\u9002\u5e94\u5feb\u901f\u53d8\u5316\u7684\u9891\u8c31\u73af\u5883\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.19483", "pdf": "https://arxiv.org/pdf/2507.19483", "abs": "https://arxiv.org/abs/2507.19483", "authors": ["Giuseppe Riva"], "title": "The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox in Human-AI Cognitive Integration", "categories": ["cs.HC", "cs.AI"], "comment": "39 Pages, no figures", "summary": "AI systems now function as cognitive extensions, evolving from tools to\nactive cognitive collaborators within human-AI integrated systems. While these\nsystems can amplify cognition - enhancing problem-solving, learning, and\ncreativity - they present a fundamental \"comfort-growth paradox\": AI's\nuser-friendly nature may foster intellectual stagnation by minimizing cognitive\nfriction necessary for development. As AI aligns with user preferences and\nprovides frictionless assistance, it risks inducing cognitive complacency\nrather than promoting growth. We introduce Enhanced Cognitive Scaffolding to\nresolve this paradox - reconceptualizing AI from convenient assistant to\ndynamic mentor. Drawing from Vygotskian theories, educational scaffolding\nprinciples, and AI ethics, our framework integrates three dimensions: (1)\nProgressive Autonomy, where AI support gradually fades as user competence\nincreases; (2) Adaptive Personalization, tailoring assistance to individual\nneeds and learning trajectories; and (3) Cognitive Load Optimization, balancing\nmental effort to maximize learning while minimizing unnecessary complexity.\nResearch across educational, workplace, creative, and healthcare domains\nsupports this approach, demonstrating accelerated skill acquisition, improved\nself-regulation, and enhanced higher-order thinking. The framework includes\nsafeguards against risks like dependency, skill atrophy, and bias\namplification. By prioritizing cognitive development over convenience in\nhuman-AI interaction, Enhanced Cognitive Scaffolding offers a pathway toward\ngenuinely amplified cognition while safeguarding autonomous thought and\ncontinuous learning.", "AI": {"tldr": "AI\u7cfb\u7edf\u4ece\u5de5\u5177\u6f14\u53d8\u4e3a\u4eba\u7c7b\u8ba4\u77e5\u7684\u4e3b\u52a8\u534f\u4f5c\u4f19\u4f34\uff0c\u4f46\u53ef\u80fd\u56e0\u8fc7\u5ea6\u8212\u9002\u5bfc\u81f4\u8ba4\u77e5\u505c\u6ede\u3002\u63d0\u51fa'\u589e\u5f3a\u8ba4\u77e5\u652f\u67b6'\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u81ea\u4e3b\u3001\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u548c\u8ba4\u77e5\u8d1f\u8f7d\u4f18\u5316\uff0c\u89e3\u51b3'\u8212\u9002-\u6210\u957f\u6096\u8bba'\uff0c\u4fc3\u8fdb\u771f\u6b63\u8ba4\u77e5\u63d0\u5347\u3002", "motivation": "AI\u7684\u4fbf\u6377\u6027\u53ef\u80fd\u5bfc\u81f4\u7528\u6237\u8ba4\u77e5\u505c\u6ede\uff0c\u9700\u5e73\u8861\u4fbf\u5229\u4e0e\u6210\u957f\u3002", "method": "\u57fa\u4e8e\u7ef4\u679c\u8328\u57fa\u7406\u8bba\u3001\u6559\u80b2\u652f\u67b6\u539f\u5219\u548cAI\u4f26\u7406\uff0c\u8bbe\u8ba1\u6846\u67b6\u5305\u542b\u6e10\u8fdb\u81ea\u4e3b\u3001\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u548c\u8ba4\u77e5\u8d1f\u8f7d\u4f18\u5316\u4e09\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u9a8c\u8bc1\u4e86\u6280\u80fd\u4e60\u5f97\u52a0\u901f\u3001\u81ea\u6211\u8c03\u8282\u80fd\u529b\u63d0\u5347\u53ca\u9ad8\u9636\u601d\u7ef4\u53d1\u5c55\u3002", "conclusion": "\u589e\u5f3a\u8ba4\u77e5\u652f\u67b6\u901a\u8fc7\u4f18\u5148\u8ba4\u77e5\u53d1\u5c55\uff0c\u4e3a\u4eba\u7c7b-AI\u534f\u4f5c\u63d0\u4f9b\u53ef\u6301\u7eed\u6210\u957f\u8def\u5f84\u3002"}}
{"id": "2507.19802", "pdf": "https://arxiv.org/pdf/2507.19802", "abs": "https://arxiv.org/abs/2507.19802", "authors": ["Ziyu Zhang", "Yuanhao Wei", "Joshua Engels", "Julian Shun"], "title": "CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest Neighbor Search", "categories": ["cs.DB", "cs.DS", "cs.IR"], "comment": null, "summary": "Approximate nearest neighbor search (ANNS) has become a quintessential\nalgorithmic problem for various other foundational data tasks for AI workloads.\nGraph-based ANNS indexes have superb empirical trade-offs in indexing cost,\nquery efficiency, and query approximation quality. Most existing graph-based\nindexes are designed for the static scenario, where there are no updates to the\ndata after the index is constructed. However, full dynamism (insertions,\ndeletions, and searches) is crucial to providing up-to-date responses in\napplications using vector databases. It is desirable that the index efficiently\nsupports updates and search queries concurrently. Existing dynamic graph-based\nindexes suffer from at least one of the following problems: (1) the query\nquality degrades as updates happen; and (2) the graph structure updates used to\nmaintain the index quality upon updates are global and thus expensive. To solve\nthese problems, we propose the CleANN system which consists of three main\ncomponents: (1) workload-aware linking of diverse search tree descendants to\ncombat distribution shift; (2)query-adaptive on-the-fly neighborhood\nconsolidation to efficiently handle deleted nodes; and (3) semi-lazy memory\ncleaning to clean up stale information in the data structure and reduce the\nwork spent by the first two components. We evaluate CleANN on 7 diverse\ndatasets on fully dynamic workloads and find that CleANN has query quality at\nleast as good as if the index had been built statically using the corresponding\ndata. In the in-memory setting using 56 hyper-threads, with all types of\nqueries running concurrently, at the same recall level, CleANN achieves 7-1200x\nthroughput improvement on million-scale real-world datasets. To the best of our\nknowledge, CleANN is the first concurrent ANNS index to achieve such efficiency\nwhile maintaining quality under full dynamism.", "AI": {"tldr": "CleANN\u7cfb\u7edf\u662f\u4e00\u79cd\u52a8\u6001\u56fe\u7d22\u5f15\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6837\u641c\u7d22\u6811\u94fe\u63a5\u548c\u534a\u61d2\u5185\u5b58\u6e05\u7406\u7b49\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u5e76\u53d1\u67e5\u8be2\u548c\u66f4\u65b0\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u67e5\u8be2\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u52a8\u6001\u56fe\u7d22\u5f15\u5728\u66f4\u65b0\u65f6\u67e5\u8be2\u8d28\u91cf\u4e0b\u964d\u6216\u7ef4\u62a4\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u4ee5\u652f\u6301\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u7684\u5168\u52a8\u6001\u64cd\u4f5c\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u6280\u672f\uff1a(1)\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7684\u641c\u7d22\u6811\u94fe\u63a5\uff0c\u5e94\u5bf9\u6570\u636e\u5206\u5e03\u53d8\u5316\uff1b(2)\u67e5\u8be2\u81ea\u9002\u5e94\u7684\u5373\u65f6\u90bb\u5c45\u5408\u5e76\uff0c\u5904\u7406\u5220\u9664\u8282\u70b9\uff1b(3)\u534a\u61d2\u5185\u5b58\u6e05\u7406\uff0c\u51cf\u5c11\u9648\u65e7\u4fe1\u606f\u3002", "result": "\u57287\u4e2a\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u663e\u793a\uff0cCleANN\u5728\u4fdd\u6301\u67e5\u8be2\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u541e\u5410\u91cf\u63d0\u5347\u4e867-1200\u500d\uff0c\u652f\u6301\u9ad8\u5e76\u53d1\u64cd\u4f5c\u3002", "conclusion": "CleANN\u662f\u9996\u4e2a\u5728\u9ad8\u5e76\u53d1\u5168\u52a8\u6001\u573a\u666f\u4e0b\u4fdd\u6301\u9ad8\u6548\u548c\u67e5\u8be2\u8d28\u91cf\u7684ANNS\u7d22\u5f15\u7cfb\u7edf\u3002"}}
{"id": "2507.19667", "pdf": "https://arxiv.org/pdf/2507.19667", "abs": "https://arxiv.org/abs/2507.19667", "authors": ["Niklas Carlsson", "Derek Eager"], "title": "Quantifying the Performance Gap for Simple Versus Optimal Dynamic Server Allocation Policies", "categories": ["cs.DC", "cs.NI", "cs.PF", "68M20, 68M01", "C.4; C.5.5"], "comment": "20 pages", "summary": "Cloud computing enables the dynamic provisioning of server resources. To\nexploit this opportunity, a policy is needed for dynamically allocating (and\ndeallocating) servers in response to the current load conditions. In this paper\nwe describe several simple policies for dynamic server allocation and develop\nanalytic models for their analysis. We also design semi-Markov decision models\nthat enable determination of the performance achieved with optimal policies,\nallowing us to quantify the performance gap between simple, easily implemented\npolicies, and optimal policies. Finally, we apply our models to study the\npotential performance benefits of state-dependent routing in multi-site systems\nwhen using dynamic server allocation at each site. Insights from our results\nare valuable to service providers wanting to balance cloud service costs and\ndelays.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e91\u8ba1\u7b97\u4e2d\u52a8\u6001\u670d\u52a1\u5668\u5206\u914d\u7684\u7b80\u5355\u7b56\u7565\u4e0e\u6700\u4f18\u7b56\u7565\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u5e94\u7528\u4e8e\u591a\u7ad9\u70b9\u7cfb\u7edf\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5229\u7528\u4e91\u8ba1\u7b97\u7684\u52a8\u6001\u8d44\u6e90\u5206\u914d\u80fd\u529b\uff0c\u7814\u7a76\u5982\u4f55\u5728\u8d1f\u8f7d\u53d8\u5316\u65f6\u52a8\u6001\u5206\u914d\u670d\u52a1\u5668\u4ee5\u63d0\u9ad8\u6027\u80fd\u5e76\u964d\u4f4e\u6210\u672c\u3002", "method": "\u5f00\u53d1\u4e86\u52a8\u6001\u670d\u52a1\u5668\u5206\u914d\u7684\u7b80\u5355\u7b56\u7565\u5206\u6790\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u6a21\u578b\u4ee5\u786e\u5b9a\u6700\u4f18\u7b56\u7565\u6027\u80fd\u3002", "result": "\u91cf\u5316\u4e86\u7b80\u5355\u7b56\u7565\u4e0e\u6700\u4f18\u7b56\u7565\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u5c55\u793a\u4e86\u591a\u7ad9\u70b9\u7cfb\u7edf\u4e2d\u72b6\u6001\u76f8\u5173\u8def\u7531\u7684\u6f5c\u5728\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u670d\u52a1\u63d0\u4f9b\u5546\u5728\u5e73\u8861\u4e91\u670d\u52a1\u6210\u672c\u548c\u5ef6\u8fdf\u65b9\u9762\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.19570", "pdf": "https://arxiv.org/pdf/2507.19570", "abs": "https://arxiv.org/abs/2507.19570", "authors": ["Yiting Wang", "Wanghao Ye", "Yexiao He", "Yiran Chen", "Gang Qu", "Ang Li"], "title": "MCP4EDA: LLM-Powered Model Context Protocol RTL-to-GDSII Automation with Backend Aware Synthesis Optimization", "categories": ["cs.AR", "cs.MA"], "comment": "7 pages, 5 figures Keywords: Model Context Protocol, Electronic\n  Design Automation, Large Language Models, Synthesis Optimization", "summary": "This paper presents MCP4EDA, the first Model Context Protocol server that\nenables Large Language Models (LLMs) to control and optimize the complete\nopen-source RTL-to-GDSII design flow through natural language interaction. The\nsystem integrates Yosys synthesis, Icarus Verilog simulation, OpenLane\nplace-and-route, GTKWave analysis, and KLayout visualization into a unified\nLLM-accessible interface, enabling designers to execute complex multi-tool EDA\nworkflows conversationally via AI assistants such as Claude Desktop and Cursor\nIDE. The principal contribution is a backend-aware synthesis optimization\nmethodology wherein LLMs analyze actual post-layout timing, power, and area\nmetrics from OpenLane results to iteratively refine synthesis TCL scripts,\nestablishing a closed-loop optimization system that bridges the traditional gap\nbetween synthesis estimates and physical implementation reality. In contrast to\nconventional flows that rely on wire-load models, this methodology leverages\nreal backend performance data to guide synthesis parameter tuning, optimization\nsequence selection, and constraint refinement, with the LLM functioning as an\nintelligent design space exploration agent. Experimental evaluation on\nrepresentative digital designs demonstrates 15-30% improvements in timing\nclosure and 10-20% area reduction compared to default synthesis flows,\nestablishing MCP4EDA as the first practical LLM-controlled end-to-end\nopen-source EDA automation system. The code and demo are avaiable at:\nhttp://www.agent4eda.com/", "AI": {"tldr": "MCP4EDA\u662f\u4e00\u79cd\u65b0\u578b\u7684\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u670d\u52a1\u5668\uff0c\u9996\u6b21\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u8ba9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a7\u5236\u548c\u4f18\u5316\u5b8c\u6574\u7684RTL-to-GDSII\u8bbe\u8ba1\u6d41\u7a0b\u3002", "motivation": "\u4f20\u7edf\u8bbe\u8ba1\u6d41\u7a0b\u4f9d\u8d56\u7ebf\u8d1f\u8f7d\u6a21\u578b\uff0c\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u540e\u7aef\u5b9e\u73b0\u7684\u5b9e\u9645\u60c5\u51b5\u3002MCP4EDA\u65e8\u5728\u5229\u7528\u771f\u5b9e\u7684\u540e\u7aef\u6027\u80fd\u6570\u636e\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f18\u5316\u8bbe\u8ba1\u6d41\u7a0b\u3002", "method": "\u7cfb\u7edf\u96c6\u6210\u4e86\u591a\u4e2aEDA\u5de5\u5177\uff08\u5982Yosys\u3001OpenLane\u7b49\uff09\uff0c\u901a\u8fc7LLM\u5206\u6790\u4e0e\u4f18\u5316TCL\u811a\u672c\uff0c\u5f62\u6210\u95ed\u73af\u4f18\u5316\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMCP4EDA\u5728\u65f6\u5e8f\u6536\u655b\u548c\u9762\u79ef\u4f18\u5316\u4e0a\u5206\u522b\u63d0\u5347\u4e8615-30%\u548c10-20%\u3002", "conclusion": "MCP4EDA\u9996\u6b21\u5b9e\u73b0\u4e86\u57fa\u4e8eLLM\u7684\u7aef\u5230\u7aef\u5f00\u6e90EDA\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u4e3a\u8bbe\u8ba1\u6d41\u7a0b\u5e26\u6765\u4e86\u663e\u8457\u4f18\u5316\u3002"}}
{"id": "2507.20295", "pdf": "https://arxiv.org/pdf/2507.20295", "abs": "https://arxiv.org/abs/2507.20295", "authors": ["Tatsuro Hanyu", "Takahiro Katagiri", "Daichi Mukunoki", "Tetsuya Hoshino"], "title": "Towards Generalized Parameter Tuning in Coherent Ising Machines: A Portfolio-Based Approach", "categories": ["cs.PF", "cs.AI", "cs.LG"], "comment": null, "summary": "Coherent Ising Machines (CIMs) have recently gained attention as a promising\ncomputing model for solving combinatorial optimization problems. In particular,\nthe Chaotic Amplitude Control (CAC) algorithm has demonstrated high solution\nquality, but its performance is highly sensitive to a large number of\nhyperparameters, making efficient tuning essential. In this study, we present\nan algorithm portfolio approach for hyperparameter tuning in CIMs employing\nChaotic Amplitude Control with momentum (CACm) algorithm. Our method\nincorporates multiple search strategies, enabling flexible and effective\nadaptation to the characteristics of the hyperparameter space. Specifically, we\npropose two representative tuning methods, Method A and Method B. Method A\noptimizes each hyperparameter sequentially with a fixed total number of trials,\nwhile Method B prioritizes hyperparameters based on initial evaluations before\napplying Method A in order. Performance evaluations were conducted on the\nSupercomputer \"Flow\" at Nagoya University, using planted Wishart instances and\nTime to Solution (TTS) as the evaluation metric. Compared to the baseline\nperformance with best-known hyperparameters, Method A achieved up to 1.47x\nimprovement, and Method B achieved up to 1.65x improvement. These results\ndemonstrate the effectiveness of the algorithm portfolio approach in enhancing\nthe tuning process for CIMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9CIMs\u4e2d\u4f7f\u7528CACm\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u7ec4\u5408\u7b97\u6cd5\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u79cd\u8c03\u4f18\u65b9\u6cd5\uff08A\u548cB\uff09\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "CIMs\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46CAC\u7b97\u6cd5\u5bf9\u8d85\u53c2\u6570\u654f\u611f\uff0c\u9700\u9ad8\u6548\u8c03\u4f18\u3002", "method": "\u91c7\u7528\u7ec4\u5408\u7b97\u6cd5\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e24\u79cd\u8c03\u4f18\u65b9\u6cd5\uff1aA\uff08\u987a\u5e8f\u4f18\u5316\uff09\u548cB\uff08\u57fa\u4e8e\u521d\u59cb\u8bc4\u4f30\u7684\u4f18\u5148\u4f18\u5316\uff09\u3002", "result": "\u5728\u8d85\u7b97\u4e0a\u6d4b\u8bd5\uff0cMethod A\u63d0\u53471.47\u500d\uff0cMethod B\u63d0\u53471.65\u500d\u3002", "conclusion": "\u7ec4\u5408\u7b97\u6cd5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86CIMs\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u6548\u7387\u3002"}}
{"id": "2507.19653", "pdf": "https://arxiv.org/pdf/2507.19653", "abs": "https://arxiv.org/abs/2507.19653", "authors": ["Armen Manukyan", "Hrant Khachatrian", "Edvard Ghukasyan", "Theofanis P. Raptis"], "title": "On the Limitations of Ray-Tracing for Learning-Based RF Tasks in Urban Environments", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication.\n  This work was supported by funding under the bilateral agreement between CNR\n  (Italy) and HESC MESCS RA (Armenia) as part of the DeepRF project for the\n  2025-2026 biennium, and by the HESC MESCS RA grant No. 22rl-052 (DISTAL)", "summary": "We study the realism of Sionna v1.0.2 ray-tracing for outdoor cellular links\nin central Rome. We use a real measurement set of 1,664 user-equipments (UEs)\nand six nominal base-station (BS) sites. Using these fixed positions we\nsystematically vary the main simulation parameters, including path depth,\ndiffuse/specular/refraction flags, carrier frequency, as well as antenna's\nproperties like its altitude, radiation pattern, and orientation. Simulator\nfidelity is scored for each base station via Spearman correlation between\nmeasured and simulated powers, and by a fingerprint-based k-nearest-neighbor\nlocalization algorithm using RSSI-based fingerprints. Across all experiments,\nsolver hyper-parameters are having immaterial effect on the chosen metrics. On\nthe contrary, antenna locations and orientations prove decisive. By simple\ngreedy optimization we improve the Spearman correlation by 5% to 130% for\nvarious base stations, while kNN-based localization error using only simulated\ndata as reference points is decreased by one-third on real-world samples, while\nstaying twice higher than the error with purely real data. Precise geometry and\ncredible antenna models are therefore necessary but not sufficient; faithfully\ncapturing the residual urban noise remains an open challenge for transferable,\nhigh-fidelity outdoor RF simulation.", "AI": {"tldr": "\u7814\u7a76\u4e86Sionna v1.0.2\u5c04\u7ebf\u8ddf\u8e2a\u5728\u7f57\u9a6c\u5e02\u4e2d\u5fc3\u5ba4\u5916\u8702\u7a9d\u94fe\u8def\u7684\u771f\u5b9e\u6027\uff0c\u901a\u8fc7\u5b9e\u6d4b\u6570\u636e\u548c\u6a21\u62df\u53c2\u6570\u4f18\u5316\u63d0\u5347\u4e86\u6a21\u62df\u5668\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22Sionna\u5c04\u7ebf\u8ddf\u8e2a\u6a21\u62df\u5668\u5728\u5ba4\u5916\u8702\u7a9d\u94fe\u8def\u4e2d\u7684\u771f\u5b9e\u6027\u548c\u4f18\u5316\u6f5c\u529b\u3002", "method": "\u4f7f\u75281,664\u4e2a\u7528\u6237\u8bbe\u5907\u548c6\u4e2a\u57fa\u7ad9\u7ad9\u70b9\u7684\u5b9e\u6d4b\u6570\u636e\uff0c\u7cfb\u7edf\u8c03\u6574\u6a21\u62df\u53c2\u6570\u5e76\u901a\u8fc7\u76f8\u5173\u7cfb\u6570\u548ckNN\u5b9a\u4f4d\u7b97\u6cd5\u8bc4\u4f30\u6a21\u62df\u5668\u6027\u80fd\u3002", "result": "\u5929\u7ebf\u4f4d\u7f6e\u548c\u65b9\u5411\u5bf9\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0c\u901a\u8fc7\u4f18\u5316\u63d0\u5347\u76f8\u5173\u6027\u548c\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u4f46\u6a21\u62df\u6570\u636e\u4ecd\u4e0d\u53ca\u5b9e\u6d4b\u6570\u636e\u3002", "conclusion": "\u7cbe\u786e\u7684\u51e0\u4f55\u548c\u5929\u7ebf\u6a21\u578b\u662f\u5fc5\u8981\u7684\uff0c\u4f46\u8fd8\u9700\u89e3\u51b3\u57ce\u5e02\u566a\u58f0\u95ee\u9898\u4ee5\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6a21\u62df\u3002"}}
{"id": "2507.19743", "pdf": "https://arxiv.org/pdf/2507.19743", "abs": "https://arxiv.org/abs/2507.19743", "authors": ["Zhuolin Xu", "Chenglin Li", "Qiushi Li", "Shin Hwei Tan"], "title": "Defining ethically sourced code generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Several code generation models have been proposed to help reduce time and\neffort in solving software-related tasks. To ensure responsible AI, there are\ngrowing interests over various ethical issues (e.g., unclear licensing,\nprivacy, fairness, and environment impact). These studies have the overarching\ngoal of ensuring ethically sourced generation, which has gained growing\nattentions in speech synthesis and image generation. In this paper, we\nintroduce the novel notion of Ethically Sourced Code Generation (ES-CodeGen) to\nrefer to managing all processes involved in code generation model development\nfrom data collection to post-deployment via ethical and sustainable practices.\nTo build a taxonomy of ES-CodeGen, we perform a two-phase literature review\nwhere we read 803 papers across various domains and specific to AI-based code\ngeneration. We identified 71 relevant papers with 10 initial dimensions of\nES-CodeGen. To refine our dimensions and gain insights on consequences of\nES-CodeGen, we surveyed 32 practitioners, which include six developers who\nsubmitted GitHub issues to opt-out from the Stack dataset (these impacted users\nhave real-world experience of ethically sourcing issues in code generation\nmodels). The results lead to 11 dimensions of ES-CodeGen with a new dimension\non code quality as practitioners have noted its importance. We also identified\nconsequences, artifacts, and stages relevant to ES-CodeGen. Our post-survey\nreflection showed that most practitioners tend to ignore social-related\ndimensions despite their importance. Most practitioners either agreed or\nstrongly agreed that our survey help improve their understanding of ES-CodeGen.\nOur study calls for attentions of various ethical issues towards ES-CodeGen.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aES-CodeGen\u7684\u65b0\u6982\u5ff5\uff0c\u6307\u901a\u8fc7\u9053\u5fb7\u548c\u53ef\u6301\u7eed\u5b9e\u8df5\u7ba1\u7406\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5f00\u53d1\u7684\u5168\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u8c03\u67e5\u63d0\u70bc\u4e8611\u4e2aES-CodeGen\u7ef4\u5ea6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u4ee3\u7801\u751f\u6210\u6a21\u578b\u4e2d\u6d89\u53ca\u7684\u4f26\u7406\u95ee\u9898\uff0c\u5982\u8bb8\u53ef\u3001\u9690\u79c1\u3001\u516c\u5e73\u6027\u548c\u73af\u5883\u5f71\u54cd\uff0c\u786e\u4fdd\u4ee3\u7801\u751f\u6210\u7684\u9053\u5fb7\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e24\u9636\u6bb5\u6587\u732e\u7efc\u8ff0\uff08\u5206\u6790\u4e86803\u7bc7\u8bba\u6587\uff09\u548c\u5bf932\u540d\u4ece\u4e1a\u8005\u7684\u8c03\u67e5\uff0c\u4ee5\u786e\u5b9a\u548c\u7ec6\u5316ES-CodeGen\u7684\u7ef4\u5ea6\u3002", "result": "\u7ed3\u679c\u63d0\u70bc\u51fa11\u4e2aES-CodeGen\u7ef4\u5ea6\uff0c\u5176\u4e2d\u4ee3\u7801\u8d28\u91cf\u662f\u65b0\u53d1\u73b0\u7684\u7ef4\u5ea6\uff0c\u5e76\u63ed\u793a\u4e86\u76f8\u5173\u540e\u679c\u3001\u5de5\u4ef6\u548c\u9636\u6bb5\u3002", "conclusion": "\u7814\u7a76\u547c\u5401\u5173\u6ce8ES-CodeGen\u4e2d\u7684\u4f26\u7406\u95ee\u9898\uff0c\u5e76\u53d1\u73b0\u4ece\u4e1a\u8005\u5e38\u5ffd\u89c6\u793e\u4f1a\u76f8\u5173\u7ef4\u5ea6\uff0c\u4f46\u8c03\u67e5\u6709\u52a9\u4e8e\u63d0\u5347\u5176\u7406\u89e3\u3002"}}
{"id": "2507.20251", "pdf": "https://arxiv.org/pdf/2507.20251", "abs": "https://arxiv.org/abs/2507.20251", "authors": ["Angelos Charalambidis", "Babis Kostopoulos", "Christos Nomikos", "Panos Rondogiannis"], "title": "The Power of Negation in Higher-Order Datalog", "categories": ["cs.PL", "cs.CC", "cs.DB", "cs.LO"], "comment": null, "summary": "We investigate the expressive power of Higher-Order Datalog$^\\neg$ under both\nthe well-founded and the stable model semantics, establishing tight connections\nwith complexity classes. We prove that under the well-founded semantics, for\nall $k\\geq 1$, $(k+1)$-Order Datalog$^\\neg$ captures k-EXP, a result that holds\nwithout explicit ordering of the input database. The proof of this fact can be\nperformed either by using the powerful existential predicate variables of the\nlanguage or by using partially applied relations and relation enumeration.\nFurthermore, we demonstrate that this expressive power is retained within a\nstratified fragment of the language. Under the stable model semantics, we show\nthat $(k+1)$-Order Datalog$^\\neg$ captures co-(k-NEXP) using cautious reasoning\nand k-NEXP using brave reasoning, again with analogous results for the\nstratified fragment augmented with choice rules. Our results establish a\nhierarchy of expressive power, highlighting an interesting trade-off between\norder and non-determinism in the context of higher-order logic programming:\nincreasing the order of programs under the well-founded semantics can surpass\nthe expressive power of lower-order programs under the stable model semantics.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9ad8\u9636Datalog\u5728\u826f\u57fa\u8bed\u4e49\u548c\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\u4e0b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5efa\u7acb\u4e86\u4e0e\u590d\u6742\u6027\u7c7b\u7684\u7d27\u5bc6\u8054\u7cfb\u3002", "motivation": "\u63a2\u8ba8\u9ad8\u9636Datalog\u5728\u4e0d\u540c\u8bed\u4e49\u4e0b\u7684\u8868\u8fbe\u80fd\u529b\u53ca\u5176\u4e0e\u590d\u6742\u6027\u7c7b\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u826f\u57fa\u8bed\u4e49\u548c\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\u5206\u6790\u9ad8\u9636Datalog\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u7ed3\u5408\u90e8\u5206\u5e94\u7528\u5173\u7cfb\u548c\u5173\u7cfb\u679a\u4e3e\u8fdb\u884c\u8bc1\u660e\u3002", "result": "\u9ad8\u9636Datalog\u5728\u826f\u57fa\u8bed\u4e49\u4e0b\u6355\u83b7k-EXP\uff0c\u5728\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\u4e0b\u6355\u83b7co-(k-NEXP)\u548ck-NEXP\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u9ad8\u9636\u903b\u8f91\u7f16\u7a0b\u4e2d\u9636\u6570\u4e0e\u975e\u786e\u5b9a\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5c55\u793a\u4e86\u8868\u8fbe\u80fd\u529b\u7684\u5c42\u6b21\u7ed3\u6784\u3002"}}
{"id": "2507.19689", "pdf": "https://arxiv.org/pdf/2507.19689", "abs": "https://arxiv.org/abs/2507.19689", "authors": ["Pablo Donato"], "title": "Scroll nets", "categories": ["cs.LO", "F.4.1"], "comment": "20 pages, 9 figures, submitted to CSL 2026", "summary": "We introduce a new formalism for representing proofs in propositional logic\ncalled \"scroll nets\". Its fundamental construct is the \"scroll\", a topological\nnotation for implication proposed by C. S. Peirce at the end of the 19th\ncentury as the basis for his diagrammatic system of existential graphs (EGs).\nScroll nets are derived from EGs by following the Curry-Howard methodology of\ninternalizing inference rules inside judgments, just as terms in type theory\ninternalize natural deduction rules. We focus on the intuitionistic implicative\nfragment of EGs, starting from a natural diagrammatic representation of scroll\nnets, and then distilling their combinatorial essence into a purely\ngraph-theoretic definition. We also identify a notion of detour, that we use to\nsketch a detour-elimination procedure akin to cut-elimination. We illustrate\nhow to simulate normalization in the simply typed $\\lambda$-calculus,\ndemonstrating both the logical and computational expressivity of our framework.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u300c\u5377\u8f74\u7f51\u300d\u7684\u65b0\u5f62\u5f0f\u4e3b\u4e49\uff0c\u7528\u4e8e\u8868\u793a\u547d\u9898\u903b\u8f91\u4e2d\u7684\u8bc1\u660e\uff0c\u57fa\u4e8ePeirce\u7684\u62d3\u6251\u7b26\u53f7\u300c\u5377\u8f74\u300d\uff0c\u5e76\u901a\u8fc7Curry-Howard\u65b9\u6cd5\u4ece\u5b58\u5728\u56fe\u4e2d\u63a8\u5bfc\u51fa\u3002\u8bba\u6587\u5c55\u793a\u4e86\u5176\u903b\u8f91\u548c\u8ba1\u7b97\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u62d3\u6251\u548c\u56fe\u5f62\u65b9\u6cd5\u91cd\u65b0\u8868\u793a\u547d\u9898\u903b\u8f91\u4e2d\u7684\u8bc1\u660e\uff0c\u7ee7\u627f\u5e76\u6269\u5c55Peirce\u7684\u5b58\u5728\u56fe\u601d\u60f3\uff0c\u540c\u65f6\u7ed3\u5408Curry-Howard\u5bf9\u5e94\u5173\u7cfb\uff0c\u63a2\u7d22\u5176\u5728\u8ba1\u7b97\u548c\u903b\u8f91\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u4ece\u5b58\u5728\u56fe\u4e2d\u63a8\u5bfc\u51fa\u300c\u5377\u8f74\u7f51\u300d\uff0c\u901a\u8fc7\u56fe\u5f62\u7406\u8bba\u5b9a\u4e49\u5176\u7ec4\u5408\u672c\u8d28\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u4e8e\u5207\u5272\u6d88\u9664\u7684\u7ed5\u884c\u6d88\u9664\u7a0b\u5e8f\u3002", "result": "\u5c55\u793a\u4e86\u5377\u8f74\u7f51\u80fd\u591f\u6a21\u62df\u7b80\u5355\u7c7b\u578b\u03bb-\u6f14\u7b97\u7684\u89c4\u8303\u5316\uff0c\u8bc1\u660e\u4e86\u5176\u903b\u8f91\u548c\u8ba1\u7b97\u7684\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "\u5377\u8f74\u7f51\u4e3a\u547d\u9898\u903b\u8f91\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u5f62\u5316\u8bc1\u660e\u8868\u793a\u65b9\u6cd5\uff0c\u5177\u6709\u6f5c\u5728\u7684\u903b\u8f91\u548c\u8ba1\u7b97\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.19830", "pdf": "https://arxiv.org/pdf/2507.19830", "abs": "https://arxiv.org/abs/2507.19830", "authors": ["Yuze Wang", "Yue Qi"], "title": "Taking Language Embedded 3D Gaussian Splatting into the Wild", "categories": ["cs.GR", "cs.CV"], "comment": "Visit our project page at\n  https://yuzewang1998.github.io/takinglangsplatw/", "summary": "Recent advances in leveraging large-scale Internet photo collections for 3D\nreconstruction have enabled immersive virtual exploration of landmarks and\nhistoric sites worldwide. However, little attention has been given to the\nimmersive understanding of architectural styles and structural knowledge, which\nremains largely confined to browsing static text-image pairs. Therefore, can we\ndraw inspiration from 3D in-the-wild reconstruction techniques and use\nunconstrained photo collections to create an immersive approach for\nunderstanding the 3D structure of architectural components? To this end, we\nextend language embedded 3D Gaussian splatting (3DGS) and propose a novel\nframework for open-vocabulary scene understanding from unconstrained photo\ncollections. Specifically, we first render multiple appearance images from the\nsame viewpoint as the unconstrained image with the reconstructed radiance\nfield, then extract multi-appearance CLIP features and two types of language\nfeature uncertainty maps-transient and appearance uncertainty-derived from the\nmulti-appearance features to guide the subsequent optimization process. Next,\nwe propose a transient uncertainty-aware autoencoder, a multi-appearance\nlanguage field 3DGS representation, and a post-ensemble strategy to effectively\ncompress, learn, and fuse language features from multiple appearances. Finally,\nto quantitatively evaluate our method, we introduce PT-OVS, a new benchmark\ndataset for assessing open-vocabulary segmentation performance on unconstrained\nphoto collections. Experimental results show that our method outperforms\nexisting methods, delivering accurate open-vocabulary segmentation and enabling\napplications such as interactive roaming with open-vocabulary queries,\narchitectural style pattern recognition, and 3D scene editing.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u5c553D\u9ad8\u65af\u6563\u5c04\u6280\u672f\uff083DGS\uff09\u5e76\u7ed3\u5408\u8bed\u8a00\u5d4c\u5165\uff0c\u5b9e\u73b0\u4e86\u5bf9\u65e0\u7ea6\u675f\u7167\u7247\u96c6\u5408\u7684\u5f00\u653e\u5f0f\u8bcd\u6c47\u573a\u666f\u7406\u89e3\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u4e3b\u8981\u5173\u6ce83D\u91cd\u5efa\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5efa\u7b51\u98ce\u683c\u548c\u7ed3\u6784\u77e5\u8bc6\u7684\u6c89\u6d78\u5f0f\u7406\u89e3\u3002", "method": "\u7ed3\u5408\u591a\u89c6\u89d2CLIP\u7279\u5f81\u548c\u8bed\u8a00\u7279\u5f81\u4e0d\u786e\u5b9a\u6027\u6620\u5c04\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u77ac\u6001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u81ea\u52a8\u7f16\u7801\u5668\u548c\u591a\u89c6\u89d2\u8bed\u8a00\u573a\u76843DGS\u8868\u793a\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u65e0\u7ea6\u675f\u7167\u7247\u96c6\u5408\u4e0a\u7684\u5f00\u653e\u5f0f\u8bcd\u6c47\u5206\u5272\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u652f\u6301\u4e92\u52a8\u6f2b\u6e38\u3001\u5efa\u7b51\u98ce\u683c\u8bc6\u522b\u7b49\u5e94\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5efa\u7b51\u7ed3\u6784\u548c\u98ce\u683c\u7684\u6c89\u6d78\u5f0f\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.20627", "pdf": "https://arxiv.org/pdf/2507.20627", "abs": "https://arxiv.org/abs/2507.20627", "authors": ["Junxian Wu", "Weitao You", "Heda Zuo", "Dengming Zhang", "Pei Chen", "Lingyun Sun"], "title": "Controllable Video-to-Music Generation with Multiple Time-Varying Conditions", "categories": ["cs.MM", "cs.AI", "cs.SD", "eess.AS"], "comment": "Accepted by the 33rd ACM International Conference on Multimedia\n  (ACMMM 2025). The project page is available at\n  https://kita-wjx.github.io/MCV2M/", "summary": "Music enhances video narratives and emotions, driving demand for automatic\nvideo-to-music (V2M) generation. However, existing V2M methods relying solely\non visual features or supplementary textual inputs generate music in a\nblack-box manner, often failing to meet user expectations. To address this\nchallenge, we propose a novel multi-condition guided V2M generation framework\nthat incorporates multiple time-varying conditions for enhanced control over\nmusic generation. Our method uses a two-stage training strategy that enables\nlearning of V2M fundamentals and audiovisual temporal synchronization while\nmeeting users' needs for multi-condition control. In the first stage, we\nintroduce a fine-grained feature selection module and a progressive temporal\nalignment attention mechanism to ensure flexible feature alignment. For the\nsecond stage, we develop a dynamic conditional fusion module and a\ncontrol-guided decoder module to integrate multiple conditions and accurately\nguide the music composition process. Extensive experiments demonstrate that our\nmethod outperforms existing V2M pipelines in both subjective and objective\nevaluations, significantly enhancing control and alignment with user\nexpectations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6761\u4ef6\u5f15\u5bfc\u7684\u89c6\u9891\u5230\u97f3\u4e50\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u63a7\u5236\u548c\u540c\u6b65\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u89c6\u89c9\u6216\u6587\u672c\u8f93\u5165\uff0c\u751f\u6210\u6548\u679c\u96be\u4ee5\u6ee1\u8db3\u7528\u6237\u671f\u671b\uff0c\u9700\u589e\u5f3a\u63a7\u5236\u80fd\u529b\u3002", "method": "\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u7ec6\u5316\u7279\u5f81\u9009\u62e9\u548c\u65f6\u5e8f\u5bf9\u9f50\uff1b\u7b2c\u4e8c\u9636\u6bb5\u52a8\u6001\u878d\u5408\u6761\u4ef6\u5e76\u5f15\u5bfc\u97f3\u4e50\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e3b\u89c2\u548c\u5ba2\u89c2\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "conclusion": "\u591a\u6761\u4ef6\u5f15\u5bfc\u6846\u67b6\u80fd\u6709\u6548\u6539\u8fdb\u89c6\u9891\u5230\u97f3\u4e50\u7684\u751f\u6210\u8d28\u91cf\u548c\u7528\u6237\u63a7\u5236\u4f53\u9a8c\u3002"}}
{"id": "2507.19739", "pdf": "https://arxiv.org/pdf/2507.19739", "abs": "https://arxiv.org/abs/2507.19739", "authors": ["Karma Gurung", "Ashutosh Ghimire", "Fathi Amsaad"], "title": "Enhancing IoT Intrusion Detection Systems through Adversarial Training", "categories": ["cs.ET"], "comment": "6 pages", "summary": "The augmentation of Internet of Things (IoT) devices transformed both\nautomation and connectivity but revealed major security vulnerabilities in\nnetworks. We address these challenges by designing a robust intrusion detection\nsystem (IDS) to detect complex attacks by learning patterns from the NF-ToN-IoT\nv2 dataset. Intrusion detection has a realistic testbed through the dataset's\nrich and high-dimensional features. We combine distributed preprocessing to\nmanage the dataset size with Fast Gradient Sign Method (FGSM) adversarial\nattacks to mimic actual attack scenarios and XGBoost model adversarial training\nfor improved system robustness. Our system achieves 95.3% accuracy on clean\ndata and 94.5% accuracy on adversarial data to show its effectiveness against\ncomplex threats. Adversarial training demonstrates its potential to strengthen\nIDS against evolving cyber threats and sets the foundation for future studies.\nReal-time IoT environments represent a future deployment opportunity for these\nsystems, while extensions to detect emerging threats and zero-day\nvulnerabilities would enhance their utility.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8eNF-ToN-IoT v2\u6570\u636e\u96c6\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u9884\u5904\u7406\u548c\u5bf9\u6297\u8bad\u7ec3\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u51c6\u786e\u7387\u8fbe95.3%\uff08\u5e72\u51c0\u6570\u636e\uff09\u548c94.5%\uff08\u5bf9\u6297\u6570\u636e\uff09\u3002", "motivation": "\u89e3\u51b3\u7269\u8054\u7f51\u8bbe\u5907\u5b89\u5168\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u6297\u590d\u6742\u653b\u51fb\u7684\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u5206\u5e03\u5f0f\u9884\u5904\u7406\u548cFGSM\u5bf9\u6297\u653b\u51fb\uff0c\u4f7f\u7528XGBoost\u6a21\u578b\u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u7cfb\u7edf\u5728\u5e72\u51c0\u548c\u5bf9\u6297\u6570\u636e\u4e0a\u5206\u522b\u8fbe\u523095.3%\u548c94.5%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u5bf9\u6297\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\uff0c\u672a\u6765\u53ef\u6269\u5c55\u81f3\u5b9e\u65f6\u73af\u5883\u548c\u65b0\u5174\u5a01\u80c1\u68c0\u6d4b\u3002"}}
{"id": "2507.19485", "pdf": "https://arxiv.org/pdf/2507.19485", "abs": "https://arxiv.org/abs/2507.19485", "authors": ["Alayt Issak"], "title": "Creativity as a Human Right: Design Considerations for Computational Creativity Systems", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "We investigate creativity that is underlined in the Universal Declaration of\nHuman Rights (UDHR) to present design considerations for Computational\nCreativity (CC) systems. We find this declaration to describe creativity in\nsalient aspects and bring to light creativity as a Human Right attributed to\nthe Fourth Generation of such rights. This generation of rights attributes CC\nsystems and the evolving nature of interaction with entities of shared\nintelligence. Our methodology examines five of thirty articles from the UDHR\nand demonstrates each article with actualizations concluding with design\nconsiderations for each. We contribute our findings to ground the relationship\nbetween creativity and CC systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u300a\u4e16\u754c\u4eba\u6743\u5ba3\u8a00\u300b\u4e2d\u5f3a\u8c03\u7684\u521b\u9020\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u8ba1\u7b97\u521b\u9020\u529b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8003\u91cf\u3002\u7814\u7a76\u8ba4\u4e3a\u8be5\u5ba3\u8a00\u5f3a\u8c03\u4e86\u521b\u9020\u529b\u7684\u91cd\u8981\u65b9\u9762\uff0c\u5e76\u5c06\u5176\u89c6\u4e3a\u7b2c\u56db\u4ee3\u4eba\u6743\u7684\u4f53\u73b0\u3002\u6587\u7ae0\u901a\u8fc7\u5206\u6790\u5ba3\u8a00\u4e2d\u7684\u4e94\u6761\u6761\u6b3e\uff0c\u4e3a\u8ba1\u7b97\u521b\u9020\u529b\u7cfb\u7edf\u63d0\u51fa\u4e86\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u300a\u4e16\u754c\u4eba\u6743\u5ba3\u8a00\u300b\u7684\u89c6\u89d2\uff0c\u63a2\u8ba8\u521b\u9020\u529b\u4e0e\u8ba1\u7b97\u521b\u9020\u529b\u7cfb\u7edf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u89e3\u51b3\u5982\u4f55\u8bbe\u8ba1\u8fd9\u4e9b\u7cfb\u7edf\u7684\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u8bba\u5305\u62ec\u5206\u6790\u300a\u4e16\u754c\u4eba\u6743\u5ba3\u8a00\u300b\u4e2d\u7684\u4e94\u6761\u6b3e\u9879\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u6bcf\u4e00\u6761\u6b3e\uff0c\u6700\u7ec8\u4e3a\u6bcf\u6761\u6761\u6b3e\u63d0\u51fa\u8bbe\u8ba1\u5efa\u8bae\u3002", "result": "\u7814\u7a76\u5f3a\u8c03\u4e86\u521b\u9020\u529b\u4f5c\u4e3a\u4eba\u6743\u7684\u7b2c\u56db\u4ee3\u8868\u73b0\u5f62\u5f0f\uff0c\u5e76\u63d0\u4f9b\u4e86\u8ba1\u7b97\u521b\u9020\u529b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8003\u91cf\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8ba1\u7b97\u521b\u9020\u529b\u7cfb\u7edf\u4e0e\u521b\u9020\u529b\u5173\u7cfb\u7684\u7406\u8bba\u57fa\u7840\u63d0\u4f9b\u4e86\u8d21\u732e\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u5efa\u8bae\u3002"}}
{"id": "2507.20441", "pdf": "https://arxiv.org/pdf/2507.20441", "abs": "https://arxiv.org/abs/2507.20441", "authors": ["Yunjie Pan", "Omkar Bhalerao", "C. Seshadhri", "Nishil Talati"], "title": "TIMEST: Temporal Information Motif Estimator Using Sampling Trees", "categories": ["cs.DB", "cs.DS", "cs.IR"], "comment": null, "summary": "The mining of pattern subgraphs, known as motifs, is a core task in the field\nof graph mining. Edges in real-world networks often have timestamps, so there\nis a need for temporal motif mining. A temporal motif is a richer structure\nthat imposes timing constraints on the edges of the motif. Temporal motifs have\nbeen used to analyze social networks, financial transactions, and biological\nnetworks.\n  Motif counting in temporal graphs is particularly challenging. A graph with\nmillions of edges can have trillions of temporal motifs, since the same edge\ncan occur with multiple timestamps. There is a combinatorial explosion of\npossibilities, and state-of-the-art algorithms cannot manage motifs with more\nthan four vertices.\n  In this work, we present TIMEST: a general, fast, and accurate estimation\nalgorithm to count temporal motifs of arbitrary sizes in temporal networks. Our\napproach introduces a temporal spanning tree sampler that leverages weighted\nsampling to generate substructures of target temporal motifs. This method\ncarefully takes a subset of temporal constraints of the motif that can be\njointly and efficiently sampled. TIMEST uses randomized estimation techniques\nto obtain accurate estimates of motif counts.\n  We give theoretical guarantees on the running time and approximation\nguarantees of TIMEST. We perform an extensive experimental evaluation and show\nthat TIMEST is both faster and more accurate than previous algorithms. Our CPU\nimplementation exhibits an average speedup of 28x over state-of-the-art GPU\nimplementation of the exact algorithm, and 6x speedup over SOTA approximate\nalgorithms while consistently showcasing less than 5% error in most cases. For\nexample, TIMEST can count the number of instances of a financial fraud temporal\nmotif in four minutes with 0.6% error, while exact methods take more than two\ndays.", "AI": {"tldr": "TIMEST\u7b97\u6cd5\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u51c6\u786e\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u65f6\u6001\u7f51\u7edc\u4e2d\u4efb\u610f\u5927\u5c0f\u7684\u65f6\u6001\u6a21\u4f53\u6570\u91cf\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u663e\u8457\u7684\u901f\u5ea6\u548c\u7cbe\u5ea6\u4f18\u52bf\u3002", "motivation": "\u65f6\u6001\u6a21\u4f53\u5206\u6790\u5728\u73b0\u5b9e\u7f51\u7edc\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u7531\u4e8e\u65f6\u6001\u56fe\u4e2d\u6a21\u4f53\u7684\u7ec4\u5408\u7206\u70b8\u95ee\u9898\uff0c\u73b0\u6709\u7b97\u6cd5\u96be\u4ee5\u5904\u7406\u8d85\u8fc7\u56db\u4e2a\u9876\u70b9\u7684\u6a21\u4f53\u8ba1\u6570\u95ee\u9898\u3002", "method": "TIMEST\u5f15\u5165\u4e86\u4e00\u79cd\u65f6\u6001\u751f\u6210\u6811\u91c7\u6837\u5668\uff0c\u901a\u8fc7\u52a0\u6743\u91c7\u6837\u751f\u6210\u76ee\u6807\u65f6\u6001\u6a21\u4f53\u7684\u5b50\u7ed3\u6784\uff0c\u5e76\u5229\u7528\u968f\u673a\u5316\u4f30\u8ba1\u6280\u672f\u83b7\u5f97\u51c6\u786e\u7684\u6a21\u4f53\u8ba1\u6570\u4f30\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTIMEST\u5728CPU\u4e0a\u7684\u5b9e\u73b0\u6bd4\u73b0\u6709GPU\u7cbe\u786e\u7b97\u6cd5\u5feb28\u500d\uff0c\u6bd4\u8fd1\u4f3c\u7b97\u6cd5\u5feb6\u500d\uff0c\u4e14\u8bef\u5dee\u7387\u4f4e\u4e8e5%\u3002\u4f8b\u5982\uff0c\u8ba1\u6570\u91d1\u878d\u6b3a\u8bc8\u6a21\u4f53\u4ec5\u97004\u5206\u949f\uff0c\u8bef\u5dee0.6%\u3002", "conclusion": "TIMEST\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5927\u89c4\u6a21\u65f6\u6001\u6a21\u4f53\u8ba1\u6570\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19712", "pdf": "https://arxiv.org/pdf/2507.19712", "abs": "https://arxiv.org/abs/2507.19712", "authors": ["Ngoc Hung Nguyen", "Nguyen Van Thieu", "Quang-Trung Luu", "Anh Tuan Nguyen", "Senura Wanasekara", "Nguyen Cong Luong", "Fatemeh Kavehmadavani", "Van-Dinh Nguyen"], "title": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "categories": ["cs.DC", "cs.AI", "cs.GT", "cs.LG", "cs.NI"], "comment": "15 pages, 13 figures", "summary": "In this paper, we explore mission assignment and task offloading in an Open\nRadio Access Network (Open RAN)-based intelligent transportation system (ITS),\nwhere autonomous vehicles leverage mobile edge computing for efficient\nprocessing. Existing studies often overlook the intricate interdependencies\nbetween missions and the costs associated with offloading tasks to edge\nservers, leading to suboptimal decision-making. To bridge this gap, we\nintroduce Oranits, a novel system model that explicitly accounts for mission\ndependencies and offloading costs while optimizing performance through vehicle\ncooperation. To achieve this, we propose a twofold optimization approach.\nFirst, we develop a metaheuristic-based evolutionary computing algorithm,\nnamely the Chaotic Gaussian-based Global ARO (CGG-ARO), serving as a baseline\nfor one-slot optimization. Second, we design an enhanced reward-based deep\nreinforcement learning (DRL) framework, referred to as the Multi-agent Double\nDeep Q-Network (MA-DDQN), that integrates both multi-agent coordination and\nmulti-action selection mechanisms, significantly reducing mission assignment\ntime and improving adaptability over baseline methods. Extensive simulations\nreveal that CGG-ARO improves the number of completed missions and overall\nbenefit by approximately 7.1% and 7.7%, respectively. Meanwhile, MA-DDQN\nachieves even greater improvements of 11.0% in terms of mission completions and\n12.5% in terms of the overall benefit. These results highlight the\neffectiveness of Oranits in enabling faster, more adaptive, and more efficient\ntask processing in dynamic ITS environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOranits\u7684\u7cfb\u7edf\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u91cd\u4f18\u5316\u65b9\u6cd5\uff08CGG-ARO\u548cMA-DDQN\uff09\u89e3\u51b3\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u4efb\u52a1\u5378\u8f7d\u548c\u5206\u914d\u7684\u590d\u6742\u4f9d\u8d56\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cOranits\u80fd\u663e\u8457\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6574\u4f53\u6548\u76ca\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5e38\u5ffd\u89c6\u4efb\u52a1\u95f4\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u548c\u8fb9\u7f18\u670d\u52a1\u5668\u5378\u8f7d\u6210\u672c\uff0c\u5bfc\u81f4\u51b3\u7b56\u4e0d\u4f18\u5316\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "1. \u63d0\u51fa\u6df7\u6c8c\u9ad8\u65af\u5168\u5c40ARO\uff08CGG-ARO\uff09\u4f5c\u4e3a\u5355\u65f6\u9699\u4f18\u5316\u7684\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff1b2. \u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u53cc\u6df1\u5ea6Q\u7f51\u7edc\uff08MA-DDQN\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u534f\u8c03\u548c\u591a\u52a8\u4f5c\u9009\u62e9\u673a\u5236\u3002", "result": "CGG-ARO\u5c06\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6574\u4f53\u6548\u76ca\u5206\u522b\u63d0\u9ad87.1%\u548c7.7%\uff1bMA-DDQN\u8fdb\u4e00\u6b65\u5206\u522b\u63d0\u9ad811.0%\u548c12.5%\u3002", "conclusion": "Oranits\u5728\u52a8\u6001\u667a\u80fd\u4ea4\u901a\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u5feb\u3001\u66f4\u81ea\u9002\u5e94\u548c\u66f4\u9ad8\u6548\u7684\u4efb\u52a1\u5904\u7406\u3002"}}
{"id": "2507.19819", "pdf": "https://arxiv.org/pdf/2507.19819", "abs": "https://arxiv.org/abs/2507.19819", "authors": ["Alexander Graening", "Puneet Gupta", "Andrew B. Kahng", "Bodhisatta Pramanik", "Zhiang Wang"], "title": "ChipletPart: Scalable Cost-Aware Partitioning for 2.5D Systems", "categories": ["cs.AR"], "comment": "14 pages, 13 figures", "summary": "Industry adoption of chiplets has been increasing as a cost-effective option\nfor making larger high-performance systems. Consequently, partitioning large\nsystems into chiplets is increasingly important. In this work, we introduce\nChipletPart - a cost-driven 2.5D system partitioner that addresses the unique\nconstraints of chiplet systems, including complex objective functions, limited\nreach of inter-chiplet I/O transceivers, and the assignment of heterogeneous\nmanufacturing technologies to different chiplets. ChipletPart integrates a\nsophisticated chiplet cost model with its underlying genetic algorithm-based\ntechnology assignment and partitioning methodology, along with a simulated\nannealing-based chiplet floorplanner. Our results show that: (i) ChipletPart\nreduces chiplet cost by up to 58% (20% geometric mean) compared to\nstate-of-the-art min-cut partitioners, which often yield floorplan-infeasible\nsolutions; (ii) ChipletPart generates partitions with up to 47% (6% geometric\nmean) lower cost as compared to the prior work Floorplet; and (iii) for the\ntestcases we study, heterogeneous integration reduces cost by up to 43% (15%\ngeometric mean) compared to homogeneous implementations. We also present case\nstudies that show how changes in packaging or inter-chiplet signaling\ntechnologies can affect partitioning solutions. Finally, we make ChipletPart,\nthe underlying chiplet cost model, and a chiplet testcase generator available\nas open-source tools for the community.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86ChipletPart\uff0c\u4e00\u79cd\u57fa\u4e8e\u6210\u672c\u9a71\u52a8\u76842.5D\u7cfb\u7edf\u5206\u533a\u5668\uff0c\u65e8\u5728\u89e3\u51b3\u82af\u7247\u7cfb\u7edf\u4e2d\u590d\u6742\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u82af\u7247\u7cfb\u7edf\u5728\u5de5\u4e1a\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u4f55\u9ad8\u6548\u5206\u533a\u6210\u4e3a\u5173\u952e\u95ee\u9898\uff0cChipletPart\u65e8\u5728\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u548c\u6a21\u62df\u9000\u706b\u7684\u82af\u7247\u6210\u672c\u6a21\u578b\uff0c\u5b9e\u73b0\u6280\u672f\u5206\u914d\u4e0e\u5206\u533a\u4f18\u5316\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0cChipletPart\u6210\u672c\u964d\u4f4e\u6700\u9ad858%\uff0c\u5f02\u6784\u96c6\u6210\u53ef\u8282\u770143%\u6210\u672c\u3002", "conclusion": "ChipletPart\u548c\u5f00\u6e90\u5de5\u5177\u4e3a\u82af\u7247\u5206\u533a\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u548c\u8d44\u6e90\u3002"}}
{"id": "2309.11071", "pdf": "https://arxiv.org/pdf/2309.11071", "abs": "https://arxiv.org/abs/2309.11071", "authors": ["Dan Wu", "Zhaoying Li", "Tulika Mitra"], "title": "InkStream: Real-time GNN Inference on Streaming Graphs via Incremental Update", "categories": ["cs.LG", "cs.DC", "cs.PF"], "comment": null, "summary": "Classic Graph Neural Network (GNN) inference approaches, designed for static\ngraphs, are ill-suited for streaming graphs that evolve with time. The dynamism\nintrinsic to streaming graphs necessitates constant updates, posing unique\nchallenges to acceleration on GPU. We address these challenges based on two key\ninsights: (1) Inside the $k$-hop neighborhood, a significant fraction of the\nnodes is not impacted by the modified edges when the model uses min or max as\naggregation function; (2) When the model weights remain static while the graph\nstructure changes, node embeddings can incrementally evolve over time by\ncomputing only the impacted part of the neighborhood. With these insights, we\npropose a novel method, InkStream, designed for real-time inference with\nminimal memory access and computation, while ensuring an identical output to\nconventional methods. InkStream operates on the principle of propagating and\nfetching data only when necessary. It uses an event-based system to control\ninter-layer effect propagation and intra-layer incremental updates of node\nembedding. InkStream is highly extensible and easily configurable by allowing\nusers to create and process customized events. We showcase that less than 10\nlines of additional user code are needed to support popular GNN models such as\nGCN, GraphSAGE, and GIN. Our experiments with three GNN models on four large\ngraphs demonstrate that InkStream accelerates by 2.5-427$\\times$ on a CPU\ncluster and 2.4-343$\\times$ on two different GPU clusters while producing\nidentical outputs as GNN model inference on the latest graph snapshot.", "AI": {"tldr": "InkStream\u662f\u4e00\u79cd\u9488\u5bf9\u52a8\u6001\u56fe\u8bbe\u8ba1\u7684\u5b9e\u65f6\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u8ba1\u7b97\u53d7\u5f71\u54cd\u90e8\u5206\u90bb\u57df\u6765\u51cf\u5c11\u8ba1\u7b97\u548c\u5185\u5b58\u8bbf\u95ee\uff0c\u663e\u8457\u52a0\u901fGNN\u63a8\u7406\u3002", "motivation": "\u4f20\u7edfGNN\u63a8\u7406\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u52a8\u6001\u56fe\uff0c\u52a8\u6001\u56fe\u7684\u4e0d\u65ad\u66f4\u65b0\u5bf9GPU\u52a0\u901f\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u4e24\u4e2a\u5173\u952e\u6d1e\u5bdf\u8bbe\u8ba1InkStream\uff1a1) \u5728k-hop\u90bb\u57df\u4e2d\uff0c\u8bb8\u591a\u8282\u70b9\u4e0d\u53d7\u4fee\u6539\u8fb9\u7684\u5f71\u54cd\uff1b2) \u8282\u70b9\u5d4c\u5165\u53ef\u4ee5\u589e\u91cf\u66f4\u65b0\u3002\u91c7\u7528\u4e8b\u4ef6\u9a71\u52a8\u7cfb\u7edf\uff0c\u63a7\u5236\u5c42\u95f4\u6548\u5e94\u4f20\u64ad\u548c\u5c42\u5185\u8282\u70b9\u5d4c\u5165\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cInkStream\u5728CPU\u548cGPU\u96c6\u7fa4\u4e0a\u52a0\u901f2.4-427\u500d\uff0c\u4e14\u8f93\u51fa\u4e0e\u4f20\u7edf\u65b9\u6cd5\u4e00\u81f4\u3002", "conclusion": "InkStream\u9ad8\u6548\u652f\u6301\u52a8\u6001\u56fe\u63a8\u7406\uff0c\u6613\u7528\u4e14\u6269\u5c55\u6027\u5f3a\uff0c\u9002\u7528\u4e8e\u591a\u79cdGNN\u6a21\u578b\u3002"}}
{"id": "2507.19657", "pdf": "https://arxiv.org/pdf/2507.19657", "abs": "https://arxiv.org/abs/2507.19657", "authors": ["Beining Wu", "Jun Huang", "Shui Yu"], "title": "\"X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems", "categories": ["cs.NI", "cs.AI"], "comment": "48 pages, 14 figures, submitted to IEEE", "summary": "The development of next-generation networking systems has inherently shifted\nfrom throughput-based paradigms towards intelligent, information-aware designs\nthat emphasize the quality, relevance, and utility of transmitted information,\nrather than sheer data volume. While classical network metrics, such as latency\nand packet loss, remain significant, they are insufficient to quantify the\nnuanced information quality requirements of modern intelligent applications,\nincluding autonomous vehicles, digital twins, and metaverse environments. In\nthis survey, we present the first comprehensive study of the ``X of\nInformation'' continuum by introducing a systematic four-dimensional taxonomic\nframework that structures information metrics along temporal, quality/utility,\nreliability/robustness, and network/communication dimensions. We uncover the\nincreasing interdependencies among these dimensions, whereby temporal freshness\ntriggers quality evaluation, which in turn helps with reliability appraisal,\nultimately enabling effective network delivery. Our analysis reveals that\nartificial intelligence technologies, such as deep reinforcement learning,\nmulti-agent systems, and neural optimization models, enable adaptive,\ncontext-aware optimization of competing information quality objectives. In our\nextensive study of six critical application domains, covering autonomous\ntransportation, industrial IoT, healthcare digital twins, UAV communications,\nLLM ecosystems, and metaverse settings, we illustrate the revolutionary promise\nof multi-dimensional information metrics for meeting diverse operational needs.\nOur survey identifies prominent implementation challenges, including ...", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4e0b\u4e00\u4ee3\u7f51\u7edc\u4e2d\u4fe1\u606f\u8d28\u91cf\u7684\u591a\u7ef4\u5ea6\u5ea6\u91cf\u6846\u67b6\u53ca\u5176\u5e94\u7528\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u7f51\u7edc\u6307\u6807\u5982\u5ef6\u8fdf\u548c\u4e22\u5305\u5df2\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u73b0\u4ee3\u667a\u80fd\u5e94\u7528\u5bf9\u4fe1\u606f\u8d28\u91cf\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u56db\u7ef4\u5206\u7c7b\u6846\u67b6\uff0c\u6db5\u76d6\u65f6\u95f4\u3001\u8d28\u91cf/\u6548\u7528\u3001\u53ef\u9760\u6027/\u9c81\u68d2\u6027\u548c\u7f51\u7edc/\u901a\u4fe1\u7ef4\u5ea6\uff0c\u5e76\u5206\u6790\u5176\u76f8\u4e92\u5173\u7cfb\u3002", "result": "\u63ed\u793a\u4e86\u591a\u7ef4\u5ea6\u4fe1\u606f\u5ea6\u91cf\u5728\u4e0d\u540c\u5e94\u7528\u9886\u57df\u7684\u6f5c\u529b\uff0c\u5e76\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5728\u4f18\u5316\u4fe1\u606f\u8d28\u91cf\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u4fe1\u606f\u8d28\u91cf\u7684\u591a\u7ef4\u5ea6\u5ea6\u91cf\u662f\u5173\u952e\u53d1\u5c55\u65b9\u5411\uff0c\u4f46\u4ecd\u9762\u4e34\u5b9e\u65bd\u6311\u6218\u3002"}}
{"id": "2507.19806", "pdf": "https://arxiv.org/pdf/2507.19806", "abs": "https://arxiv.org/abs/2507.19806", "authors": ["Xinlong Zhao", "Tong Jia", "Minghua He", "Yihan Wu", "Ying Li", "Gang Huang"], "title": "From Few-Label to Zero-Label: An Approach for Cross-System Log-Based Anomaly Detection with Meta-Learning", "categories": ["cs.SE", "cs.AI"], "comment": "5 pages, 1 figures, FSE 2025", "summary": "Log anomaly detection plays a critical role in ensuring the stability and\nreliability of software systems. However, existing approaches rely on large\namounts of labeled log data, which poses significant challenges in real-world\napplications. To address this issue, cross-system transfer has been identified\nas a key research direction. State-of-the-art cross-system approaches achieve\npromising performance with only a few labels from the target system. However,\ntheir reliance on labeled target logs makes them susceptible to the cold-start\nproblem when labeled logs are insufficient. To overcome this limitation, we\nexplore a novel yet underexplored setting: zero-label cross-system log anomaly\ndetection, where the target system logs are entirely unlabeled. To this end, we\npropose FreeLog, a system-agnostic representation meta-learning method that\neliminates the need for labeled target system logs, enabling cross-system log\nanomaly detection under zero-label conditions. Experimental results on three\npublic log datasets demonstrate that FreeLog achieves performance comparable to\nstate-of-the-art methods that rely on a small amount of labeled data from the\ntarget system.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFreeLog\u7684\u7cfb\u7edf\u65e0\u5173\u8868\u793a\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u96f6\u6807\u7b7e\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff0c\u65e0\u9700\u76ee\u6807\u7cfb\u7edf\u7684\u6807\u8bb0\u65e5\u5fd7\uff0c\u6027\u80fd\u53ef\u6bd4\u4f9d\u8d56\u5c11\u91cf\u6807\u8bb0\u6570\u636e\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u76ee\u6807\u7cfb\u7edf\u7684\u5c11\u91cf\u6807\u8bb0\u65e5\u5fd7\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9002\u7528\u6027\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u96f6\u6807\u7b7e\u6761\u4ef6\u4e0b\u7684\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86FreeLog\uff0c\u4e00\u79cd\u7cfb\u7edf\u65e0\u5173\u7684\u8868\u793a\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u65e0\u9700\u76ee\u6807\u7cfb\u7edf\u7684\u6807\u8bb0\u65e5\u5fd7\u5373\u53ef\u5b9e\u73b0\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFreeLog\u7684\u6027\u80fd\u4e0e\u4f9d\u8d56\u5c11\u91cf\u76ee\u6807\u7cfb\u7edf\u6807\u8bb0\u6570\u636e\u7684\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "FreeLog\u4e3a\u96f6\u6807\u7b7e\u6761\u4ef6\u4e0b\u7684\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.20672", "pdf": "https://arxiv.org/pdf/2507.20672", "abs": "https://arxiv.org/abs/2507.20672", "authors": ["Yannis Smaragdakis", "Neville Grech", "Sifis Lagouvardos", "Konstantinos Triantafyllou", "Ilias Tsatiris", "Yannis Bollanos", "Tony Rocco Valentine"], "title": "Program Analysis for High-Value Smart Contract Vulnerabilities: Techniques and Insights", "categories": ["cs.CR", "cs.PL"], "comment": null, "summary": "A widespread belief in the blockchain security community is that automated\ntechniques are only good for detecting shallow bugs, typically of small value.\nIn this paper, we present the techniques and insights that have led us to\nrepeatable success in automatically discovering high-value smart contract\nvulnerabilities. Our vulnerability disclosures have yielded 10 bug bounties,\nfor a total of over $3M, over high-profile deployed code, as well as hundreds\nof bugs detected in pre-deployment or under-audit code.\n  We argue that the elements of this surprising success are a) a very\nhigh-completeness static analysis approach that manages to maintain acceptable\nprecision; b) domain knowledge, provided by experts or captured via statistical\ninference. We present novel techniques for automatically inferring domain\nknowledge from statistical analysis of a large corpus of deployed contracts, as\nwell as discuss insights on the ideal precision and warning rate of a promising\nvulnerability detector. In contrast to academic literature in program analysis,\nwhich routinely expects false-positive rates below 50% for publishable results,\nwe posit that a useful analysis for high-value real-world vulnerabilities will\nlikely flag very few programs (under 1%) and will do so with a high\nfalse-positive rate (e.g., 95%, meaning that only one-of-twenty human\ninspections will yield an exploitable vulnerability).", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u81ea\u52a8\u5316\u6280\u672f\u6210\u529f\u53d1\u73b0\u9ad8\u4ef7\u503c\u7684\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\uff0c\u5e76\u5f3a\u8c03\u4e86\u9ad8\u5b8c\u6574\u6027\u7684\u9759\u6001\u5206\u6790\u548c\u9886\u57df\u77e5\u8bc6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u533a\u5757\u94fe\u5b89\u5168\u793e\u533a\u666e\u904d\u8ba4\u4e3a\u81ea\u52a8\u5316\u6280\u672f\u53ea\u80fd\u68c0\u6d4b\u4f4e\u4ef7\u503c\u7684\u6d45\u5c42\u6f0f\u6d1e\uff0c\u8fd9\u7bc7\u8bba\u6587\u65e8\u5728\u6253\u7834\u8fd9\u4e00\u8ba4\u77e5\uff0c\u5c55\u793a\u81ea\u52a8\u5316\u6280\u672f\u5728\u9ad8\u4ef7\u503c\u6f0f\u6d1e\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86\u9ad8\u5b8c\u6574\u6027\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e13\u5bb6\u7ecf\u9a8c\u6216\u901a\u8fc7\u7edf\u8ba1\u63a8\u65ad\u83b7\u53d6\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u63a8\u65ad\u9886\u57df\u77e5\u8bc6\u7684\u65b0\u6280\u672f\u3002", "result": "\u7814\u7a76\u6210\u529f\u53d1\u73b0\u4e86\u591a\u4e2a\u9ad8\u4ef7\u503c\u6f0f\u6d1e\uff0c\u83b7\u5f97\u4e86\u8d85\u8fc7300\u4e07\u7f8e\u5143\u7684\u5956\u52b1\uff0c\u5e76\u5728\u90e8\u7f72\u524d\u6216\u5ba1\u8ba1\u9636\u6bb5\u7684\u4ee3\u7801\u4e2d\u68c0\u6d4b\u5230\u6570\u767e\u4e2a\u6f0f\u6d1e\u3002", "conclusion": "\u8bba\u6587\u8ba4\u4e3a\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u9ad8\u4ef7\u503c\u6f0f\u6d1e\u53d1\u73b0\u7684\u5b9e\u7528\u5206\u6790\u5de5\u5177\u53ef\u80fd\u9700\u8981\u63a5\u53d7\u8f83\u9ad8\u7684\u5047\u9633\u6027\u7387\uff08\u598295%\uff09\uff0c\u4f46\u5176\u68c0\u6d4b\u7387\uff081%\uff09\u4ecd\u7136\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2507.19827", "pdf": "https://arxiv.org/pdf/2507.19827", "abs": "https://arxiv.org/abs/2507.19827", "authors": ["M\u00e1rton Hajdu", "Petra Hozzov\u00e1", "Laura Kov\u00e1cs", "Andrei Voronkov", "Eva Maria Wagner", "Richard Steven \u017dilin\u010d\u00edk"], "title": "Synthesis Benchmarks for Automated Reasoning", "categories": ["cs.LO"], "comment": "This is an extended pre-print of a paper accepted to CICM 2025", "summary": "Program synthesis is the task of constructing a program conforming to a given\nspecification. We focus on deductive synthesis, and in particular on synthesis\nproblems with specifications given as $\\forall\\exists$-formulas, expressing the\nexistence of an output corresponding to any input. So far there has been no\ncanonical benchmark set for deductive synthesis using the\n$\\forall\\exists$-format and supporting the so-called uncomputable symbol\nrestriction. This work presents such a data set, composed by complementing\nexisting benchmarks by new ones. Our data set is dynamically growing and should\nmotivate future developments in the theory and practice of automating\nsynthesis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u52a8\u6001\u589e\u957f\u7684$\forall\forall$-\u5f62\u5f0f\u5408\u6210\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u586b\u8865\u73b0\u6709\u7a7a\u767d\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u652f\u6301$\forall\forall$-\u5f62\u5f0f\u548c\u975e\u8ba1\u7b97\u7b26\u53f7\u9650\u5236\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u963b\u788d\u4e86\u5408\u6210\u7406\u8bba\u548c\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u8865\u5145\u73b0\u6709\u57fa\u51c6\u548c\u65b0\u57fa\u51c6\uff0c\u6784\u5efa\u6570\u636e\u96c6\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u52a8\u6001\u589e\u957f\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u6709\u671b\u63a8\u52a8\u5408\u6210\u7406\u8bba\u548c\u81ea\u52a8\u5316\u5b9e\u8df5\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.19836", "pdf": "https://arxiv.org/pdf/2507.19836", "abs": "https://arxiv.org/abs/2507.19836", "authors": ["Xuanchen Wang", "Heng Wang", "Weidong Cai"], "title": "ChoreoMuse: Robust Music-to-Dance Video Generation with Style Transfer and Beat-Adherent Motion", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "comment": "10 pages, 5 figures, accepted by the 33rd ACM International\n  Conference on Multimedia (ACM MM 2025), demo page:\n  https://choreomuse.github.io", "summary": "Modern artistic productions increasingly demand automated choreography\ngeneration that adapts to diverse musical styles and individual dancer\ncharacteristics. Existing approaches often fail to produce high-quality dance\nvideos that harmonize with both musical rhythm and user-defined choreography\nstyles, limiting their applicability in real-world creative contexts. To\naddress this gap, we introduce ChoreoMuse, a diffusion-based framework that\nuses SMPL format parameters and their variation version as intermediaries\nbetween music and video generation, thereby overcoming the usual constraints\nimposed by video resolution. Critically, ChoreoMuse supports\nstyle-controllable, high-fidelity dance video generation across diverse musical\ngenres and individual dancer characteristics, including the flexibility to\nhandle any reference individual at any resolution. Our method employs a novel\nmusic encoder MotionTune to capture motion cues from audio, ensuring that the\ngenerated choreography closely follows the beat and expressive qualities of the\ninput music. To quantitatively evaluate how well the generated dances match\nboth musical and choreographic styles, we introduce two new metrics that\nmeasure alignment with the intended stylistic cues. Extensive experiments\nconfirm that ChoreoMuse achieves state-of-the-art performance across multiple\ndimensions, including video quality, beat alignment, dance diversity, and style\nadherence, demonstrating its potential as a robust solution for a wide range of\ncreative applications. Video results can be found on our project page:\nhttps://choreomuse.github.io.", "AI": {"tldr": "ChoreoMuse\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u98ce\u683c\u53ef\u63a7\u7684\u821e\u8e48\u89c6\u9891\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u97f3\u4e50\u8282\u594f\u548c\u821e\u8e48\u98ce\u683c\u534f\u8c03\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u821e\u8e48\u751f\u6210\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u9002\u5e94\u591a\u6837\u97f3\u4e50\u98ce\u683c\u548c\u4e2a\u4f53\u821e\u8005\u7279\u6027\u7684\u95ee\u9898\uff0c\u63d0\u5347\u751f\u6210\u89c6\u9891\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002", "method": "\u5229\u7528SMPL\u683c\u5f0f\u53c2\u6570\u4f5c\u4e3a\u97f3\u4e50\u548c\u89c6\u9891\u751f\u6210\u7684\u5a92\u4ecb\uff0c\u7ed3\u5408MotionTune\u97f3\u4e50\u7f16\u7801\u5668\u6355\u6349\u97f3\u9891\u8fd0\u52a8\u7ebf\u7d22\uff0c\u652f\u6301\u9ad8\u4fdd\u771f\u821e\u8e48\u89c6\u9891\u751f\u6210\u3002", "result": "\u5728\u89c6\u9891\u8d28\u91cf\u3001\u8282\u594f\u5bf9\u9f50\u3001\u821e\u8e48\u591a\u6837\u6027\u548c\u98ce\u683c\u4e00\u81f4\u6027\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5c55\u793a\u4e86\u5e7f\u6cdb\u7684\u521b\u9020\u6027\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "ChoreoMuse\u4e3a\u591a\u6837\u97f3\u4e50\u548c\u821e\u8e48\u98ce\u683c\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u62d3\u5c55\u4e86\u81ea\u52a8\u7f16\u821e\u7684\u5b9e\u9645\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2507.20738", "pdf": "https://arxiv.org/pdf/2507.20738", "abs": "https://arxiv.org/abs/2507.20738", "authors": ["Yu Zhao", "Ying Zhang", "Xuhui Sui", "Baohang Zhou", "Haoze Zhu", "Jeff Z. Pan", "Xiaojie Yuan"], "title": "Dark Side of Modalities: Reinforced Multimodal Distillation for Multimodal Knowledge Graph Reasoning", "categories": ["cs.MM"], "comment": "Accepted by ACM MM 2025", "summary": "The multimodal knowledge graph reasoning (MKGR) task aims to predict the\nmissing facts in the incomplete MKGs by leveraging auxiliary images and\ndescriptions of entities. Existing approaches are trained with single-target\nobjectives, which neglect the probabilistic correlations of entity labels,\nespecially in non-target entities. Moreover, previous studies incorporate all\nmodalities statically or adaptively, overlooking the negative impacts of\nirrelevant or misleading information in the incompetent modalities. To address\nthese issues, we introduce a novel Reinforced Multimodal Distillation\nframework, exploiting the Dark Side of Modalities (DSoM) from two perspectives:\n(1) Dark knowledge from non-target entities: We propose to train a unimodal KGR\nmodel through logit distillation to mimic the multimodal soft labels provided\nby pre-trained multimodal teacher models. The multimodal soft labels could\nprovide rich supervision signals with subtle correlations among both target and\nnon-target entities from multiple perspectives. We further decouple logits into\nneighbor entities and non-neighbor entities to divide into two types of\ncorrelations. (2) Dark side in unhelpful modalities: To exclude the adverse\neffects of unhelpful modalities, we introduce a reinforced teacher combination\nmechanism that dynamically selects the optimal set of multimodal teachers for\neach triple. The agent is trained to maximize the rewards, which are only\nassigned to the beneficial multimodal combination strategies for the student\nmodel. Comprehensive experiments demonstrate the effectiveness of DSoM\nframework on 5 MKGR datasets. Codes are available at github.com/OreOZhao/DSoM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDSoM\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u975e\u76ee\u6807\u5b9e\u4f53\u7684\u6982\u7387\u76f8\u5173\u6027\u548c\u52a8\u6001\u9009\u62e9\u6709\u7528\u6a21\u6001\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u76f8\u5173\u6027\u53ca\u6a21\u6001\u8d1f\u9762\u5f71\u54cd\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u4e00\u662f\u5ffd\u7565\u4e86\u975e\u76ee\u6807\u5b9e\u4f53\u6807\u7b7e\u7684\u6982\u7387\u76f8\u5173\u6027\uff0c\u4e8c\u662f\u9759\u6001\u6216\u81ea\u9002\u5e94\u5730\u7ec4\u5408\u6240\u6709\u6a21\u6001\uff0c\u672a\u80fd\u6392\u9664\u65e0\u5173\u6216\u8bef\u5bfc\u6027\u4fe1\u606f\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86Reinforced Multimodal Distillation\u6846\u67b6\uff0c\u5305\u62ec\uff081\uff09\u901a\u8fc7logit\u84b8\u998f\u5229\u7528\u975e\u76ee\u6807\u5b9e\u4f53\u7684\u6697\u77e5\u8bc6\uff1b\uff082\uff09\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u9009\u62e9\u6700\u4f18\u591a\u6a21\u6001\u6559\u5e08\u7ec4\u5408\uff0c\u6392\u9664\u65e0\u5e2e\u52a9\u6a21\u6001\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "result": "\u57285\u4e2aMKGR\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86DSoM\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5145\u5206\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\u7684\u6697\u77e5\u8bc6\u548c\u52a8\u6001\u6a21\u6001\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u6027\u80fd\u3002"}}
{"id": "2507.20193", "pdf": "https://arxiv.org/pdf/2507.20193", "abs": "https://arxiv.org/abs/2507.20193", "authors": ["Santlal Prajapat", "Manobendra Nath Mondal", "Susmita Sur-Kolay"], "title": "Efficient and Fault-Tolerant Memristive Neural Networks with In-Situ Training", "categories": ["cs.ET"], "comment": null, "summary": "Neuromorphic architectures, which incorporate parallel and in-memory\nprocessing, are crucial for accelerating artificial neural network (ANN)\ncomputations. This work presents a novel memristor-based multi-layer neural\nnetwork (memristive MLNN) architecture and an efficient in-situ training\nalgorithm. The proposed design performs matrix-vector multiplications, outer\nproducts, and weight updates in constant time $\\mathcal{O}(1)$, leveraging the\ninherent parallelism of memristive crossbars. Each synapse is realized using a\nsingle memristor, eliminating the need for transistors, and offering enhanced\narea and energy efficiency. The architecture is evaluated through LTspice\nsimulations on the IRIS, NASA Asteroid, and Breast Cancer Wisconsin datasets,\nachieving classification accuracies of 98.22\\%, 90.43\\%, and 98.59\\%,\nrespectively. Robustness is assessed by introducing stuck-at-conducting-state\nfaults in randomly selected memristors. The effects of nonlinearity in\nmemristor conductance and a 10\\% device variation are also analyzed. The\nsimulation results establish that the network's performance is not affected\nsignificantly by faulty memristors, non-linearity, and device variation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fc6\u963b\u5668\u7684\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u9ad8\u6548\u7684\u539f\u5730\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5e38\u6570\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u795e\u7ecf\u5f62\u6001\u67b6\u6784\u901a\u8fc7\u5e76\u884c\u548c\u5185\u5b58\u5185\u5904\u7406\u52a0\u901f\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\uff0c\u4f46\u73b0\u6709\u8bbe\u8ba1\u5728\u6548\u7387\u548c\u9762\u79ef\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u4f7f\u7528\u5fc6\u963b\u5668\u4ea4\u53c9\u9635\u5217\u7684\u56fa\u6709\u5e76\u884c\u6027\uff0c\u5b9e\u73b0\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u3001\u5916\u79ef\u548c\u6743\u91cd\u66f4\u65b0\u7684\u5e38\u6570\u65f6\u95f4\u590d\u6742\u5ea6\uff1b\u6bcf\u4e2a\u7a81\u89e6\u4ec5\u9700\u4e00\u4e2a\u5fc6\u963b\u5668\uff0c\u65e0\u9700\u6676\u4f53\u7ba1\u3002", "result": "\u5728IRIS\u3001NASA Asteroid\u548cBreast Cancer Wisconsin\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523098.22%\u300190.43%\u548c98.59%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4e14\u5bf9\u5fc6\u963b\u5668\u6545\u969c\u3001\u975e\u7ebf\u6027\u548c\u5668\u4ef6\u53d8\u5f02\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u67b6\u6784\u5177\u6709\u9ad8\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2507.19486", "pdf": "https://arxiv.org/pdf/2507.19486", "abs": "https://arxiv.org/abs/2507.19486", "authors": ["Gabriel Recchia", "Chatrik Singh Mangat", "Jinu Nyachhyon", "Mridul Sharma", "Callum Canavan", "Dylan Epstein-Gross", "Muhammed Abdulbari"], "title": "Confirmation bias: A challenge for scalable oversight", "categories": ["cs.HC", "cs.AI"], "comment": "61 pages, 8 figures", "summary": "Scalable oversight protocols aim to empower evaluators to accurately verify\nAI models more capable than themselves. However, human evaluators are subject\nto biases that can lead to systematic errors. We conduct two studies examining\nthe performance of simple oversight protocols where evaluators know that the\nmodel is \"correct most of the time, but not all of the time\". We find no\noverall advantage for the tested protocols, although in Study 1, showing\narguments in favor of both answers improves accuracy in cases where the model\nis incorrect. In Study 2, participants in both groups become more confident in\nthe system's answers after conducting online research, even when those answers\nare incorrect. We also reanalyze data from prior work that was more optimistic\nabout simple protocols, finding that human evaluators possessing knowledge\nabsent from models likely contributed to their positive results--an advantage\nthat diminishes as models continue to scale in capability. These findings\nunderscore the importance of testing the degree to which oversight protocols\nare robust to evaluator biases, whether they outperform simple deference to the\nmodel under evaluation, and whether their performance scales with increasing\nproblem difficulty and model capability.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5355\u7684\u76d1\u7763\u534f\u8bae\u5728\u514b\u670d\u8bc4\u4f30\u8005\u504f\u89c1\u65b9\u9762\u6548\u679c\u6709\u9650\uff0c\u672a\u8868\u73b0\u51fa\u660e\u663e\u4f18\u52bf\uff0c\u4e14\u968f\u7740\u6a21\u578b\u80fd\u529b\u7684\u63d0\u5347\uff0c\u5176\u6709\u6548\u6027\u53ef\u80fd\u4f1a\u964d\u4f4e\u3002", "motivation": "\u63a2\u8ba8\u76d1\u7763\u534f\u8bae\u5982\u4f55\u5e2e\u52a9\u8bc4\u4f30\u8005\u51c6\u786e\u9a8c\u8bc1\u6bd4\u81ea\u8eab\u66f4\u5f3a\u5927\u7684AI\u6a21\u578b\uff0c\u540c\u65f6\u514b\u670d\u8bc4\u4f30\u8005\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "method": "\u901a\u8fc7\u4e24\u9879\u7814\u7a76\uff0c\u6d4b\u8bd5\u8bc4\u4f30\u8005\u5728\u77e5\u9053\u6a21\u578b\u2018\u5927\u591a\u6570\u65f6\u5019\u6b63\u786e\uff0c\u4f46\u5e76\u975e\u603b\u662f\u6b63\u786e\u2019\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u7b80\u5355\u76d1\u7763\u534f\u8bae\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u76d1\u7763\u534f\u8bae\u6574\u4f53\u4e0a\u65e0\u4f18\u52bf\uff0c\u4f46\u5c55\u793a\u6b63\u53cd\u8bba\u636e\u5728\u6a21\u578b\u9519\u8bef\u65f6\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u8bc4\u4f30\u8005\u5728\u7ebf\u7814\u7a76\u540e\u5bf9\u7cfb\u7edf\u7b54\u6848\u4fe1\u5fc3\u589e\u5f3a\uff0c\u5373\u4f7f\u7b54\u6848\u662f\u9519\u8bef\u7684\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u76d1\u7763\u534f\u8bae\u9700\u514b\u670d\u8bc4\u4f30\u8005\u504f\u89c1\u3001\u8d85\u8d8a\u7b80\u5355\u4f9d\u8d56\u6a21\u578b\u7684\u80fd\u529b\uff0c\u5e76\u968f\u95ee\u9898\u96be\u5ea6\u548c\u6a21\u578b\u80fd\u529b\u6269\u5c55\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.20671", "pdf": "https://arxiv.org/pdf/2507.20671", "abs": "https://arxiv.org/abs/2507.20671", "authors": ["Jens Dittrich"], "title": "A Functional Data Model and Query Language is All You Need", "categories": ["cs.DB"], "comment": null, "summary": "We propose the vision of a functional data model (FDM) and an associated\nfunctional query language (FQL). Our proposal has far-reaching consequences: we\nshow a path to come up with a modern QL that solves (almost if not) all\nproblems of SQL (NULL-values, impedance mismatch, SQL injection, missing\nquerying capabilities for updates, etc.). FDM and FQL are much more expressive\nthan the relational model and SQL. In addition, in contrast to SQL, FQL\nintegrates smoothly into existing programming languages. In our approach both\nQL and PL become the \"same thing\", thus opening up some interesting holistic\noptimization opportunities between compilers and databases. In FQL, we also do\nnot need to force application developers to switch to unfamiliar programming\nparadigms (like SQL or datalog): developers can stick with the abstractions\nprovided by their programming language.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u529f\u80fd\u6027\u6570\u636e\u6a21\u578b(FDM)\u548c\u529f\u80fd\u6027\u67e5\u8be2\u8bed\u8a00(FQL)\uff0c\u89e3\u51b3\u4e86SQL\u7684\u591a\u4e2a\u95ee\u9898\uff0c\u5e76\u4e0e\u73b0\u6709\u7f16\u7a0b\u8bed\u8a00\u65e0\u7f1d\u96c6\u6210\u3002", "motivation": "SQL\u5b58\u5728NULL\u503c\u3001\u963b\u6297\u4e0d\u5339\u914d\u3001SQL\u6ce8\u5165\u3001\u66f4\u65b0\u67e5\u8be2\u80fd\u529b\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u73b0\u4ee3\u7684\u67e5\u8be2\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86FDM\u548cFQL\uff0c\u8fd9\u4e9b\u5de5\u5177\u7684\u8868\u8fbe\u5f0f\u80fd\u529b\u66f4\u5f3a\uff0c\u4e14\u80fd\u4e0e\u7f16\u7a0b\u8bed\u8a00\u81ea\u7136\u878d\u5408\uff0c\u907f\u514d\u5f00\u53d1\u8005\u5b66\u4e60\u65b0\u7f16\u7a0b\u8303\u5f0f\u3002", "result": "FQL\u4e0d\u4ec5\u89e3\u51b3\u4e86SQL\u7684\u95ee\u9898\uff0c\u8fd8\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u67e5\u8be2\u548c\u4f18\u5316\u673a\u4f1a\uff0c\u4f7f\u5f97\u67e5\u8be2\u8bed\u8a00\u548c\u7f16\u7a0b\u8bed\u8a00\u8d8b\u4e8e\u4e00\u81f4\u3002", "conclusion": "FDM\u548cFQL\u4e3a\u6570\u636e\u7ba1\u7406\u548c\u67e5\u8be2\u63d0\u4f9b\u4e86\u66f4\u73b0\u4ee3\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u53d6\u4ee3\u6216\u8865\u5145SQL\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.19723", "pdf": "https://arxiv.org/pdf/2507.19723", "abs": "https://arxiv.org/abs/2507.19723", "authors": ["Mufakir Qamar Ansari", "Mudabir Qamar Ansari"], "title": "Accelerating Matrix Multiplication: A Performance Comparison Between Multi-Core CPU and GPU", "categories": ["cs.DC", "Primary 68W10, Secondary 65Y05, 68M20", "C.1.2; C.4; D.1.3"], "comment": "13 pages, 3 figures. Complete C++/CUDA source code included in\n  Appendix", "summary": "Matrix multiplication is a foundational operation in scientific computing and\nmachine learning, yet its computational complexity makes it a significant\nbottleneck for large-scale applications. The shift to parallel architectures,\nprimarily multi-core CPUs and many-core GPUs, is the established solution, and\nthese systems are now ubiquitous from datacenters to consumer laptops. This\npaper presents a direct, empirical performance analysis of matrix\nmultiplication on a modern, consumer-grade heterogeneous platform. We\nimplemented and benchmarked three versions of the algorithm: a baseline\nsequential C++ implementation, a parallel version for its multi-core CPU using\nOpenMP, and a massively parallel version for its discrete GPU using CUDA with\nshared memory optimizations. The implementations were evaluated with square\nmatrices of varying dimensions, from 128x128 to 4096x4096. Our results show\nthat while the parallel CPU provides a consistent speedup of 12-14x over the\nsequential version, the GPU's performance scales dramatically with problem\nsize. For a 4096x4096 matrix, the GPU implementation achieved a speedup of\napproximately 593x over the sequential baseline and 45x over the optimized\nparallel CPU version. These findings quantitatively demonstrate the profound\nimpact of many-core GPU architectures on accelerating data-parallel workloads,\nunderscoring that significant performance gains are readily accessible even on\nconsumer-level hardware.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u6bd4\u8f83\u4e86\u987a\u5e8f\u3001\u591a\u6838CPU\u548cGPU\u5728\u77e9\u9635\u4e58\u6cd5\u4e0a\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u663e\u793aGPU\u5728\u5927\u89c4\u6a21\u95ee\u9898\u4e0a\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u77e9\u9635\u4e58\u6cd5\u662f\u79d1\u5b66\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u7684\u57fa\u7840\u64cd\u4f5c\uff0c\u4f46\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u6210\u4e3a\u5927\u89c4\u6a21\u5e94\u7528\u7684\u74f6\u9888\u3002\u7814\u7a76\u65e8\u5728\u5206\u6790\u73b0\u4ee3\u5f02\u6784\u5e73\u53f0\u4e0a\u77e9\u9635\u4e58\u6cd5\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u8bba\u6587\u5b9e\u73b0\u4e86\u4e09\u79cd\u7248\u672c\u7684\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\uff1a\u987a\u5e8fC++\u5b9e\u73b0\u3001\u57fa\u4e8eOpenMP\u7684\u591a\u6838CPU\u5e76\u884c\u5b9e\u73b0\u3001\u57fa\u4e8eCUDA\u548c\u5171\u4eab\u5185\u5b58\u4f18\u5316\u7684GPU\u5e76\u884c\u5b9e\u73b0\uff0c\u5e76\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u77e9\u9635\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u591a\u6838CPU\u6bd4\u987a\u5e8f\u7248\u672c\u63d0\u901f12-14\u500d\uff0c\u800cGPU\u7684\u6027\u80fd\u968f\u95ee\u9898\u89c4\u6a21\u663e\u8457\u63d0\u5347\uff0c\u5bf9\u4e8e4096x4096\u77e9\u9635\uff0cGPU\u6bd4\u987a\u5e8f\u7248\u672c\u63d0\u901f\u7ea6593\u500d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u591a\u6838GPU\u67b6\u6784\u5bf9\u6570\u636e\u5e76\u884c\u8d1f\u8f7d\u5177\u6709\u6df1\u8fdc\u5f71\u54cd\uff0c\u5373\u4f7f\u662f\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e5f\u80fd\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2507.20007", "pdf": "https://arxiv.org/pdf/2507.20007", "abs": "https://arxiv.org/abs/2507.20007", "authors": ["Siva Satyendra Sahoo", "Salim Ullah", "Akash Kumar"], "title": "AxOSyn: An Open-source Framework for Synthesizing Novel Approximate Arithmetic Operators", "categories": ["cs.AR", "cs.ET", "cs.LO"], "comment": "Under review with ACM TRETS", "summary": "Edge AI deployments are becoming increasingly complex, necessitating\nenergy-efficient solutions for resource-constrained embedded systems.\nApproximate computing, which allows for controlled inaccuracies in\ncomputations, is emerging as a promising approach for improving power and\nenergy efficiency. Among the key techniques in approximate computing are\napproximate arithmetic operators (AxOs), which enable application-specific\noptimizations beyond traditional computer arithmetic hardware reduction-based\nmethods, such as quantization and precision scaling. Existing design space\nexploration (DSE) frameworks for approximate computing limit themselves to\nselection-based approaches or custom synthesis at fixed abstraction levels,\nwhich restricts the flexibility required for finding application-specific\noptimal solutions. Further, the tools available for the DSE of AxOs are quite\nlimited in terms of exploring different approximation models and extending the\nanalysis to different granularities. To this end, we propose AxOSyn, an\nopen-source framework for the DSE of AxOs that supports both selection and\nsynthesis approaches at various abstraction levels. AxOSyn allows researchers\nto integrate custom methods for evaluating approximations and facilitates DSE\nat both the operator-level and application-specific. Our framework provides an\neffective methodology for achieving energy-efficient, approximate operators.", "AI": {"tldr": "AxOSyn\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u652f\u6301\u5728\u4e0d\u540c\u62bd\u8c61\u7ea7\u522b\u4e0a\u9009\u62e9\u548c\u5408\u6210\u8fd1\u4f3c\u7b97\u672f\u8fd0\u7b97\u7b26\uff0c\u4ee5\u5b9e\u73b0\u8d44\u6e90\u53d7\u9650\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u80fd\u6548\u4f18\u5316\u3002", "motivation": "\u8fb9\u7f18AI\u90e8\u7f72\u65e5\u76ca\u590d\u6742\uff0c\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u9700\u8981\u80fd\u6548\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8fd1\u4f3c\u8ba1\u7b97\u901a\u8fc7\u5141\u8bb8\u53ef\u63a7\u7684\u8ba1\u7b97\u4e0d\u51c6\u786e\u6027\uff0c\u6210\u4e3a\u63d0\u5347\u80fd\u6548\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002", "method": "AxOSyn\u6846\u67b6\u652f\u6301\u9009\u62e9\u548c\u5408\u6210\u4e24\u79cd\u65b9\u6cd5\uff0c\u53ef\u5728\u4e0d\u540c\u62bd\u8c61\u7ea7\u522b\u4e0a\u63a2\u7d22\u8fd1\u4f3c\u7b97\u672f\u8fd0\u7b97\u7b26\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u96c6\u6210\u81ea\u5b9a\u4e49\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "AxOSyn\u4e3a\u8fb9\u7f18AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u80fd\u6548\u4f18\u5316\u5de5\u5177\uff0c\u514b\u670d\u4e86\u73b0\u6709DSE\u6846\u67b6\u7684\u9650\u5236\u3002", "conclusion": "AxOSyn\u901a\u8fc7\u7075\u6d3b\u7684\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u548c\u81ea\u5b9a\u4e49\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3a\u8fd1\u4f3c\u8ba1\u7b97\u7684\u80fd\u6548\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19925", "pdf": "https://arxiv.org/pdf/2507.19925", "abs": "https://arxiv.org/abs/2507.19925", "authors": ["Sowmiyan Morri", "Joy Bose", "L Raghunatha Reddy", "Sai Hareesh Anamandra"], "title": "Predicting Locations of Cell Towers for Network Capacity Expansion", "categories": ["cs.NI", "90B18", "C.2.1; I.2.6"], "comment": "9 pages, 5 figures", "summary": "Network capacity expansion is a critical challenge for telecom operators,\nrequiring strategic placement of new cell sites to ensure optimal coverage and\nperformance. Traditional approaches, such as manual drive tests and static\noptimization, often fail to consider key real-world factors including user\ndensity, terrain features, and financial constraints. In this paper, we propose\na machine learning-based framework that combines deep neural networks for\nsignal coverage prediction with spatial clustering to recommend new tower\nlocations in underserved areas. The system integrates geospatial, demographic,\nand infrastructural data, and incorporates budget-aware constraints to\nprioritize deployments. Operating within an iterative planning loop, the\nframework refines coverage estimates after each proposed installation, enabling\nadaptive and cost-effective expansion. While full-scale simulation was limited\nby data availability, the architecture is modular, robust to missing inputs,\nand generalizable across diverse deployment scenarios. This approach advances\nradio network planning by offering a scalable, data-driven alternative to\nmanual methods.", "AI": {"tldr": "\u9488\u5bf9\u7535\u4fe1\u8fd0\u8425\u5546\u7f51\u7edc\u6269\u5bb9\u7684\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u7a7a\u95f4\u805a\u7c7b\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u4fe1\u53f7\u8986\u76d6\u5e76\u63a8\u8350\u65b0\u57fa\u7ad9\u4f4d\u7f6e\uff0c\u8003\u8651\u5b9e\u9645\u56e0\u7d20\u548c\u9884\u7b97\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5982\u624b\u52a8\u9a71\u52a8\u6d4b\u8bd5\u548c\u9759\u6001\u4f18\u5316\u672a\u80fd\u5145\u5206\u8003\u8651\u7528\u6237\u5bc6\u5ea6\u3001\u5730\u5f62\u7279\u5f81\u548c\u8d22\u52a1\u7ea6\u675f\u7b49\u5b9e\u9645\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u4fe1\u53f7\u8986\u76d6\uff0c\u7ed3\u5408\u7a7a\u95f4\u805a\u7c7b\u63a8\u8350\u670d\u52a1\u4e0d\u8db3\u533a\u57df\u7684\u65b0\u7ad9\u70b9\u4f4d\u7f6e\uff0c\u6574\u5408\u5730\u7406\u7a7a\u95f4\u3001\u4eba\u53e3\u7edf\u8ba1\u548c\u57fa\u7840\u8bbe\u65bd\u6570\u636e\uff0c\u5e76\u7eb3\u5165\u9884\u7b97\u7ea6\u675f\u3002", "result": "\u8be5\u6846\u67b6\u5728\u8fed\u4ee3\u89c4\u5212\u5faa\u73af\u4e2d\u4f18\u5316\u8986\u76d6\u4f30\u8ba1\uff0c\u63d0\u4f9b\u81ea\u9002\u5e94\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u6269\u5c55\u65b9\u6848\u3002\u67b6\u6784\u6a21\u5757\u5316\uff0c\u5bf9\u7f3a\u5931\u8f93\u5165\u5177\u6709\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u90e8\u7f72\u573a\u666f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u65e0\u7ebf\u7535\u7f51\u7edc\u89c4\u5212\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u6570\u636e\u9a71\u52a8\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u4f20\u7edf\u624b\u52a8\u65b9\u6cd5\u3002"}}
{"id": "2507.19842", "pdf": "https://arxiv.org/pdf/2507.19842", "abs": "https://arxiv.org/abs/2507.19842", "authors": ["Mohammad Azarijafari", "Luisa Mich", "Michele Missikoff", "Oleg Missikoff"], "title": "A Cooperative Approach for Knowledge-based Business Process Design in a Public Authority", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Enterprises are currently undergoing profound transformations due to the\nunpostponable digital transformation. Then, to remain competitive, enterprises\nmust adapt their organisational structures and operations. This organisational\nshift is also important for small and medium-sized enterprises. A key\ninnovation frontier is the adoption of process-oriented production models. This\npaper presents a knowledge-based method to support business experts in\ndesigning business processes. The method requires no prior expertise in\nKnowledge Engineering and guides designers through a structured sequence of\nsteps to produce a diagrammatic workflow of the target process. The\nconstruction of the knowledge base starts from simple, text-based, knowledge\nartefacts and then progresses towards more structured, formal representations.\nThe approach has been conceived to allow a shared approach for all stakeholders\nand actors who participate in the BP design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u652f\u6301\u4e1a\u52a1\u4e13\u5bb6\u8bbe\u8ba1\u4e1a\u52a1\u6d41\u7a0b\uff0c\u65e0\u9700\u5148\u524d\u7684\u77e5\u8bc6\u5de5\u7a0b\u7ecf\u9a8c\u3002", "motivation": "\u7531\u4e8e\u6570\u5b57\u5316\u8f6c\u578b\u7684\u7d27\u8feb\u6027\uff0c\u4f01\u4e1a\u5c24\u5176\u662f\u4e2d\u5c0f\u4f01\u4e1a\u9700\u8981\u8c03\u6574\u7ec4\u7ec7\u7ed3\u6784\u548c\u8fd0\u8425\u65b9\u5f0f\uff0c\u800c\u6d41\u7a0b\u5bfc\u5411\u7684\u751f\u4ea7\u6a21\u578b\u662f\u5173\u952e\u521b\u65b0\u65b9\u5411\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u4ece\u7b80\u5355\u7684\u6587\u672c\u77e5\u8bc6\u6784\u4ef6\u5165\u624b\uff0c\u9010\u6b65\u6784\u5efa\u66f4\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u5e93\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u6b65\u9aa4\u751f\u6210\u76ee\u6807\u6d41\u7a0b\u7684\u56fe\u8868\u5316\u5de5\u4f5c\u6d41\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u6240\u6709\u53c2\u4e0e\u4e1a\u52a1\u6d41\u7a0b\u8bbe\u8ba1\u7684\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u5171\u4eab\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u652f\u6301\u4f01\u4e1a\uff0c\u5c24\u5176\u662f\u4e2d\u5c0f\u4f01\u4e1a\uff0c\u5728\u6570\u5b57\u5316\u8f6c\u578b\u4e2d\u9ad8\u6548\u8bbe\u8ba1\u4e1a\u52a1\u6d41\u7a0b\u3002"}}
{"id": "2507.20674", "pdf": "https://arxiv.org/pdf/2507.20674", "abs": "https://arxiv.org/abs/2507.20674", "authors": ["Nima Karimipour", "Michael Pradel", "Martin Kellogg", "Manu Sridharan"], "title": "LLM-Based Repair of Static Nullability Errors", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Modern Java projects increasingly adopt static analysis tools that prevent\nnull-pointer exceptions by treating nullness as a type property. However,\nintegrating such tools into large, existing codebases remains a significant\nchallenge. While annotation inference can eliminate many errors automatically,\na subset of residual errors -- typically a mix of real bugs and false positives\n-- often persist and can only be resolved via code changes. Manually addressing\nthese errors is tedious and error-prone. Large language models (LLMs) offer a\npromising path toward automating these repairs, but naively-prompted LLMs often\ngenerate incorrect, contextually-inappropriate edits. Resolving a nullability\nerror demands a deep understanding of how a symbol is used across the codebase,\noften spanning methods, classes, and packages. We present NullRepair, a system\nthat integrates LLMs into a structured workflow for resolving the errors from a\nnullability checker. NullRepair's decision process follows a flowchart derived\nfrom manual analysis of 200 real-world errors. It leverages static analysis to\nidentify safe and unsafe usage regions of symbols, using error-free usage\nexamples to contextualize model prompts. Patches are generated through an\niterative interaction with the LLM that incorporates project-wide context and\ndecision logic. Our evaluation on 12 real-world Java projects shows that\nNullRepair resolves an average of 72% of the errors that remain after applying\na state-of-the-art annotation inference technique. Unlike a naively-prompted\nLLM, NullRepair also largely preserves program semantics, with all unit tests\npassing in 10/12 projects after applying every edit proposed by NullRepair, and\n98% or more tests passing in the remaining two projects.", "AI": {"tldr": "NullRepair\u662f\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u4fee\u590dJava\u4ee3\u7801\u4e2d\u7a7a\u6307\u9488\u5f02\u5e38\u9519\u8bef\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u548c\u4e0a\u4e0b\u6587\u793a\u4f8b\uff0c\u63d0\u9ad8\u4e86\u4fee\u590d\u51c6\u786e\u6027\u548c\u7a0b\u5e8f\u8bed\u4e49\u4fdd\u7559\u80fd\u529b\u3002", "motivation": "\u5927\u89c4\u6a21Java\u9879\u76ee\u4e2d\u9759\u6001\u5206\u6790\u5de5\u5177\u867d\u7136\u80fd\u9884\u9632\u7a7a\u6307\u9488\u5f02\u5e38\uff0c\u4f46\u90e8\u5206\u9519\u8bef\u4ecd\u9700\u4eba\u5de5\u4fee\u590d\uff0c\u6548\u7387\u4f4e\u4e14\u6613\u51fa\u9519\u3002LLM\u6709\u6f5c\u529b\u81ea\u52a8\u5316\u4fee\u590d\uff0c\u4f46\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "method": "NullRepair\u7ed3\u5408\u9759\u6001\u5206\u6790\u548cLLM\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6d41\u7a0b\u56fe\u51b3\u7b56\uff0c\u5229\u7528\u9519\u8bef\u793a\u4f8b\u4e0a\u4e0b\u6587\u5316\u63d0\u793a\uff0c\u8fed\u4ee3\u751f\u6210\u4fee\u590d\u8865\u4e01\u3002", "result": "\u572812\u4e2aJava\u9879\u76ee\u4e2d\uff0cNullRepair\u5e73\u5747\u4fee\u590d\u4e8672%\u7684\u6b8b\u7559\u9519\u8bef\uff0c\u4e14\u4fee\u590d\u540e10/12\u9879\u76ee\u7684\u5355\u5143\u6d4b\u8bd5\u5168\u90e8\u901a\u8fc7\uff0c\u5176\u4f59\u9879\u76ee98%\u4ee5\u4e0a\u6d4b\u8bd5\u901a\u8fc7\u3002", "conclusion": "NullRepair\u901a\u8fc7\u4e0a\u4e0b\u6587\u9a71\u52a8\u7684LLM\u96c6\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7a7a\u6307\u9488\u9519\u8bef\u7684\u81ea\u52a8\u5316\u4fee\u590d\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.19886", "pdf": "https://arxiv.org/pdf/2507.19886", "abs": "https://arxiv.org/abs/2507.19886", "authors": ["Weijun Chen", "Yuxi Fu", "Huan Long", "Hao Wu"], "title": "A Model-Independent Theory of Probabilistic Testing", "categories": ["cs.LO"], "comment": null, "summary": "Probabilistic concurrent systems are foundational models for modern mobile\ncomputing. In this paper, a general model-independent approach to probabilistic\ntesting is proposed. With the help of a new distribution-based semantics for\nprobabilistic models and a probabilistic testing framework with respect to\nprocess predicates, the model-independent characterization and the external\ncharacterization for testing equivalences are studied. The latter\ncharacterization can be viewed as the generalization of the classical\nfair/should equivalence and may equivalence. These equivalences are shown to be\ncongruent. A thorough comparison between these equivalences and probabilistic\nbisimilarities is carried out. The techniques introduced in this paper can be\neasily extended to other probabilistic concurrent models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u72ec\u7acb\u4e8e\u6a21\u578b\u7684\u6982\u7387\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86\u6982\u7387\u6d4b\u8bd5\u7b49\u4ef7\u7684\u5185\u5916\u90e8\u8868\u5f81\uff0c\u5e76\u4e0e\u6982\u7387\u53cc\u76f8\u4f3c\u6027\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "motivation": "\u4e3a\u73b0\u4ee3\u79fb\u52a8\u8ba1\u7b97\u7684\u6982\u7387\u5e76\u53d1\u7cfb\u7edf\u63d0\u4f9b\u4e00\u4e2a\u901a\u7528\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5206\u5e03\u7684\u8bed\u4e49\u548c\u6982\u7387\u6d4b\u8bd5\u6846\u67b6\uff0c\u7814\u7a76\u6982\u7387\u6d4b\u8bd5\u7b49\u4ef7\u7684\u5185\u5916\u90e8\u8868\u5f81\u3002", "result": "\u8bc1\u660e\u4e86\u8fd9\u4e9b\u7b49\u4ef7\u4e0e\u6982\u7387\u53cc\u76f8\u4f3c\u6027\u7684\u5173\u7cfb\uff0c\u5e76\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u6240\u63d0\u6280\u672f\u9002\u7528\u4e8e\u5176\u4ed6\u6982\u7387\u5e76\u53d1\u6a21\u578b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.20200", "pdf": "https://arxiv.org/pdf/2507.20200", "abs": "https://arxiv.org/abs/2507.20200", "authors": ["Xin Zhang", "Anpei Chen", "Jincheng Xiong", "Pinxuan Dai", "Yujun Shen", "Weiwei Xu"], "title": "Neural Shell Texture Splatting: More Details and Fewer Primitives", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Gaussian splatting techniques have shown promising results in novel view\nsynthesis, achieving high fidelity and efficiency. However, their high\nreconstruction quality comes at the cost of requiring a large number of\nprimitives. We identify this issue as stemming from the entanglement of\ngeometry and appearance in Gaussian Splatting. To address this, we introduce a\nneural shell texture, a global representation that encodes texture information\naround the surface. We use Gaussian primitives as both a geometric\nrepresentation and texture field samplers, efficiently splatting texture\nfeatures into image space. Our evaluation demonstrates that this\ndisentanglement enables high parameter efficiency, fine texture detail\nreconstruction, and easy textured mesh extraction, all while using\nsignificantly fewer primitives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u58f3\u7eb9\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u51e0\u4f55\u4e0e\u5916\u89c2\uff0c\u51cf\u5c11\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u6240\u9700\u7684\u57fa\u5143\u6570\u91cf\uff0c\u63d0\u9ad8\u53c2\u6570\u6548\u7387\u548c\u7eb9\u7406\u7ec6\u8282\u91cd\u5efa\u3002", "motivation": "\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u5728\u65b0\u89c6\u89d2\u5408\u6210\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u8981\u5927\u91cf\u57fa\u5143\uff0c\u539f\u56e0\u662f\u51e0\u4f55\u4e0e\u5916\u89c2\u7684\u8026\u5408\u3002", "method": "\u5f15\u5165\u795e\u7ecf\u58f3\u7eb9\u7406\u4f5c\u4e3a\u5168\u5c40\u8868\u793a\uff0c\u5229\u7528\u9ad8\u65af\u57fa\u5143\u540c\u65f6\u4f5c\u4e3a\u51e0\u4f55\u8868\u793a\u548c\u7eb9\u7406\u91c7\u6837\u5668\u3002", "result": "\u65b9\u6cd5\u5728\u51cf\u5c11\u57fa\u5143\u6570\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u53c2\u6570\u5229\u7528\u3001\u7cbe\u7ec6\u7eb9\u7406\u91cd\u5efa\u548c\u6613\u4e8e\u63d0\u53d6\u7eb9\u7406\u7f51\u683c\u3002", "conclusion": "\u89e3\u8026\u51e0\u4f55\u4e0e\u5916\u89c2\u7684\u65b9\u6cd5\u5728\u9ad8\u65af\u6cfc\u6e85\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u4e0e\u8d28\u91cf\u3002"}}
{"id": "2507.19821", "pdf": "https://arxiv.org/pdf/2507.19821", "abs": "https://arxiv.org/abs/2507.19821", "authors": ["Yanrui Yu", "Tianfei Zhou", "Jiaxin Sun", "Lianpeng Qiao", "Lizhong Ding", "Ye Yuan", "Guoren Wang"], "title": "LAVA: Language Driven Scalable and Versatile Traffic Video Analytics", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "In modern urban environments, camera networks generate massive amounts of\noperational footage -- reaching petabytes each day -- making scalable video\nanalytics essential for efficient processing. Many existing approaches adopt an\nSQL-based paradigm for querying such large-scale video databases; however, this\nconstrains queries to rigid patterns with predefined semantic categories,\nsignificantly limiting analytical flexibility. In this work, we explore a\nlanguage-driven video analytics paradigm aimed at enabling flexible and\nefficient querying of high-volume video data driven by natural language.\nParticularly, we build \\textsc{Lava}, a system that accepts natural language\nqueries and retrieves traffic targets across multiple levels of granularity and\narbitrary categories. \\textsc{Lava} comprises three main components: 1) a\nmulti-armed bandit-based efficient sampling method for video segment-level\nlocalization;\n  2) a video-specific open-world detection module for object-level retrieval;\nand 3) a long-term object trajectory extraction scheme for temporal object\nassociation, yielding complete trajectories for object-of-interests. To support\ncomprehensive evaluation, we further develop a novel benchmark by providing\ndiverse, semantically rich natural language predicates and fine-grained\nannotations for multiple videos. Experiments on this benchmark demonstrate that\n\\textsc{Lava} improves $F_1$-scores for selection queries by $\\mathbf{14\\%}$,\nreduces MPAE for aggregation queries by $\\mathbf{0.39}$, and achieves top-$k$\nprecision of $\\mathbf{86\\%}$, while processing videos $ \\mathbf{9.6\\times} $\nfaster than the most accurate baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u89c6\u9891\u5206\u6790\u7cfb\u7edfLava\uff0c\u901a\u8fc7\u7075\u6d3b\u67e5\u8be2\u5927\u89c4\u6a21\u89c6\u9891\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u67e5\u8be2\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709SQL\u8303\u5f0f\u5bf9\u89c6\u9891\u5206\u6790\u7684\u9650\u5236\uff0c\u63d0\u5347\u67e5\u8be2\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "method": "Lava\u7cfb\u7edf\u5305\u542b\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684\u91c7\u6837\u65b9\u6cd5\u3001\u5f00\u653e\u6027\u76ee\u6807\u68c0\u6d4b\u6a21\u5757\u548c\u957f\u671f\u76ee\u6807\u8f68\u8ff9\u63d0\u53d6\u6280\u672f\u3002", "result": "F1\u5206\u6570\u63d0\u534714%\uff0c\u805a\u5408\u67e5\u8be2\u8bef\u5dee\u964d\u4f4e0.39\uff0c\u5904\u7406\u901f\u5ea6\u5feb9.6\u500d\u3002", "conclusion": "Lava\u7cfb\u7edf\u5728\u7075\u6d3b\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u89c6\u9891\u5206\u6790\u3002"}}
{"id": "2507.20998", "pdf": "https://arxiv.org/pdf/2507.20998", "abs": "https://arxiv.org/abs/2507.20998", "authors": ["Santlal Prajapati", "Susmita Sur-Kolay", "Soumyadeep Dutta"], "title": "Efficient Memristive Spiking Neural Networks Architecture with Supervised In-Situ STDP Method", "categories": ["cs.ET", "cs.NE"], "comment": null, "summary": "Memristor-based Spiking Neural Networks (SNNs) with temporal spike encoding\nenable ultra-low-energy computation, making them ideal for battery-powered\nintelligent devices. This paper presents a circuit-level memristive spiking\nneural network (SNN) architecture trained using a proposed novel supervised\nin-situ learning algorithm inspired by spike-timing-dependent plasticity\n(STDP). The proposed architecture efficiently implements lateral inhibition and\nthe refractory period, eliminating the need for external microcontrollers or\nancillary control hardware. All synapses of the winning neurons are updated in\nparallel, enhancing training efficiency. The modular design ensures scalability\nwith respect to input data dimensions and output class count. The SNN is\nevaluated in LTspice for pattern recognition (using 5x3 binary images) and\nclassification tasks using the Iris and Breast Cancer Wisconsin (BCW) datasets.\nDuring testing, the system achieved perfect pattern recognition and high\nclassification accuracies of 99.11\\% (Iris) and 97.9\\% (BCW). Additionally, it\nhas demonstrated robustness, maintaining an average recognition rate of 93.4\\%\nunder 20\\% input noise. The impact of stuck-at-conductance faults and memristor\ndevice variations was also analyzed.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fc6\u963b\u5668\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u91c7\u7528\u65b0\u578b\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u8bad\u7ec3\u548c\u9ad8\u5206\u7c7b\u7cbe\u5ea6\u3002", "motivation": "\u5229\u7528\u5fc6\u963b\u5668\u5b9e\u73b0\u8d85\u4f4e\u80fd\u8017\u8ba1\u7b97\uff0c\u9002\u7528\u4e8e\u7535\u6c60\u4f9b\u7535\u7684\u667a\u80fd\u8bbe\u5907\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSTDP\u7684\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u884c\u66f4\u65b0\u795e\u7ecf\u5143\u7a81\u89e6\uff0c\u6a21\u5757\u5316\u8bbe\u8ba1\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728\u6a21\u5f0f\u8bc6\u522b\uff08\u59825x3\u4e8c\u503c\u56fe\u50cf\uff09\u548c\u5206\u7c7b\u4efb\u52a1\uff08Iris\u548cBCW\u6570\u636e\u96c6\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523099.11%\u548c97.9%\u3002", "conclusion": "\u8be5\u67b6\u6784\u5728\u8bad\u7ec3\u6548\u7387\u3001\u5206\u7c7b\u7cbe\u5ea6\u548c\u6297\u5e72\u6270\u80fd\u529b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u9002\u7528\u4e8e\u667a\u80fd\u8bbe\u5907\u7684\u786c\u4ef6\u5b9e\u73b0\u3002"}}
{"id": "2507.19488", "pdf": "https://arxiv.org/pdf/2507.19488", "abs": "https://arxiv.org/abs/2507.19488", "authors": ["Alexandros Gazis", "Eleftheria Katsiri"], "title": "E-polis: Gamifying Sociological Surveys through Serious Games -- A Data Analysis Approach Applied to Multiple-Choice Question Responses Datasets", "categories": ["cs.HC", "cs.CY", "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"], "comment": "The article is under review by MDPI, Electronics journal. 36 pages,\n  20 figures, 67 references", "summary": "E-polis is a serious digital game designed to gamify sociological surveys\nstudying young people's political opinions. In this platform game, players\nnavigate a digital world, encountering quests posing sociological questions.\nPlayers' answers shape the city-game world, altering building structures based\non their choices. E-polis is a serious game, not a government simulation,\naiming to understand players' behaviors and opinions thus we do not train the\nplayers but rather understand them and help them visualize their choices in\nshaping a city's future. Also, it is noticed that no correct or incorrect\nanswers apply. Moreover, our game utilizes a novel middleware architecture for\ndevelopment, diverging from typical asset prefab scene and script segregation.\nThis article presents the data layer of our game's middleware, specifically\nfocusing on data analysis based on respondents' gameplay answers. E-polis\nrepresents an innovative approach to gamifying sociological research, providing\na unique platform for gathering and analyzing data on political opinions among\nyouth and contributing to the broader field of serious games.", "AI": {"tldr": "E-polis\u662f\u4e00\u6b3e\u901a\u8fc7\u6e38\u620f\u5316\u65b9\u5f0f\u7814\u7a76\u5e74\u8f7b\u4eba\u653f\u6cbb\u89c2\u70b9\u7684\u6570\u5b57\u6e38\u620f\u5e73\u53f0\uff0c\u5229\u7528\u6570\u636e\u5206\u6790\u548c\u4e2d\u95f4\u4ef6\u67b6\u6784\u8fdb\u884c\u521b\u65b0\u7814\u7a76\u3002", "motivation": "\u7814\u7a76\u5e74\u8f7b\u4eba\u653f\u6cbb\u89c2\u70b9\uff0c\u901a\u8fc7\u6e38\u620f\u5316\u65b9\u5f0f\u6536\u96c6\u548c\u5206\u6790\u6570\u636e\uff0c\u63d0\u4f9b\u65b0\u7684\u793e\u4f1a\u5b66\u7814\u7a76\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1E-polis\u5e73\u53f0\u6e38\u620f\uff0c\u73a9\u5bb6\u901a\u8fc7\u56de\u7b54\u793e\u4f1a\u5b66\u95ee\u9898\u5851\u9020\u6e38\u620f\u4e16\u754c\uff0c\u4f7f\u7528\u4e2d\u95f4\u4ef6\u67b6\u6784\u8fdb\u884c\u6570\u636e\u91c7\u96c6\u548c\u5206\u6790\u3002", "result": "\u6e38\u620f\u6570\u636e\u53ef\u7528\u4e8e\u5206\u6790\u73a9\u5bb6\u884c\u4e3a\u548c\u653f\u6cbb\u89c2\u70b9\uff0c\u5e2e\u52a9\u7406\u89e3\u5e74\u8f7b\u4eba\u5bf9\u57ce\u5e02\u672a\u6765\u7684\u770b\u6cd5\u3002", "conclusion": "E-polis\u4e3a\u793e\u4f1a\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u6e38\u620f\u5316\u5e73\u53f0\uff0c\u901a\u8fc7\u6570\u636e\u53ef\u89c6\u5316\u652f\u6301\u653f\u6cbb\u89c2\u70b9\u7814\u7a76\u3002"}}
{"id": "2507.20815", "pdf": "https://arxiv.org/pdf/2507.20815", "abs": "https://arxiv.org/abs/2507.20815", "authors": ["Valerie Restat", "Kai Tejkl", "Uta St\u00f6rl"], "title": "MVIAnalyzer: A Holistic Approach to Analyze Missing Value Imputation", "categories": ["cs.DB"], "comment": null, "summary": "Missing values often limit the usage of data analysis or cause falsification\nof results. Therefore, methods of missing value imputation (MVI) are of great\nsignificance. However, in general, there is no universal, fair MVI method for\ndifferent tasks. This work thus places MVI in the overall context of data\nanalysis. For this purpose, we present the MVIAnalyzer, a generic framework for\na holistic analysis of MVI. It considers the overall process up to the\napplication and analysis of machine learning methods. The associated software\nis provided and can be used by other researchers for their own analyses. To\nthis end, it further includes a missing value simulation with consideration of\nrelevant parameters. The application of the MVIAnalyzer is demonstrated on data\nwith different characteristics. An evaluation of the results shows the\npossibilities and limitations of different MVI methods. Since MVI is a very\ncomplex topic with different influencing variables, this paper additionally\nillustrates how the analysis can be supported by visualizations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aMVIAnalyzer\u7684\u901a\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u5206\u6790\u6570\u636e\u7f3a\u5931\u503c\u586b\u8865\uff08MVI\uff09\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u53ef\u89c6\u5316\u548c\u6a21\u62df\u652f\u6301\u7814\u7a76\u3002", "motivation": "\u7f3a\u5931\u503c\u5e38\u9650\u5236\u6570\u636e\u5206\u6790\u6216\u5bfc\u81f4\u7ed3\u679c\u5931\u771f\uff0c\u76ee\u524d\u7f3a\u4e4f\u9002\u7528\u4e8e\u4e0d\u540c\u4efb\u52a1\u7684\u901a\u7528MVI\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMVIAnalyzer\u6846\u67b6\uff0c\u6db5\u76d6\u4ece\u6570\u636e\u9884\u5904\u7406\u5230\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u5168\u8fc7\u7a0b\uff0c\u5305\u62ec\u7f3a\u5931\u503c\u6a21\u62df\u548c\u53ef\u89c6\u5316\u5206\u6790\u3002", "result": "\u5e94\u7528MVIAnalyzer\u5c55\u793a\u4e86\u4e0d\u540cMVI\u65b9\u6cd5\u7684\u4f18\u52a3\uff0c\u5e76\u901a\u8fc7\u53ef\u89c6\u5316\u8f85\u52a9\u590d\u6742\u5206\u6790\u3002", "conclusion": "MVIAnalyzer\u4e3aMVI\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u9002\u7528\u8303\u56f4\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2507.19845", "pdf": "https://arxiv.org/pdf/2507.19845", "abs": "https://arxiv.org/abs/2507.19845", "authors": ["Bohan Zhao", "Guang Yang", "Shuo Chen", "Ruitao Liu", "Tingrui Zhang", "Yongchao He", "Wei Xu"], "title": "MegatronApp: Efficient and Comprehensive Management on Distributed LLM Training", "categories": ["cs.DC"], "comment": null, "summary": "The rapid escalation in the parameter count of large language models (LLMs)\nhas transformed model training from a single-node endeavor into a highly\nintricate, cross-node activity. While frameworks such as Megatron-LM\nsuccessfully integrate tensor (TP), pipeline (PP), and data (DP) parallelism to\nenable trillion-parameter training, they simultaneously expose practitioners to\nunprecedented systems-level challenges in performance optimization, diagnosis,\nand interpretability. MegatronApp is an open-source toolchain expressly\ndesigned to meet these challenges. It introduces four orthogonal, yet\nseamlessly composable modules--MegaScan, MegaFBD, MegaDPP, and MegaScope--that\ncollectively elevate the reliability, efficiency, and transparency of\nproduction-scale training. This paper presents the motivation, architecture,\nand distinctive contributions of each module, and elucidates how their\nsynergistic integration augments the Megatron-LM ecosystem.", "AI": {"tldr": "MegatronApp\u662f\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u94fe\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7cfb\u7edf\u7ea7\u6311\u6218\uff0c\u63d0\u5347\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u900f\u660e\u6027\u3002", "motivation": "\u968f\u7740LLM\u53c2\u6570\u91cf\u6fc0\u589e\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u53d8\u5f97\u590d\u6742\u4e14\u8de8\u8282\u70b9\uff0c\u73b0\u6709\u6846\u67b6\u867d\u652f\u6301\u4e07\u4ebf\u53c2\u6570\u8bad\u7ec3\uff0c\u4f46\u5728\u6027\u80fd\u4f18\u5316\u3001\u8bca\u65ad\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "MegatronApp\u5f15\u5165\u56db\u4e2a\u6a21\u5757\uff08MegaScan\u3001MegaFBD\u3001MegaDPP\u548cMegaScope\uff09\uff0c\u5b83\u4eec\u6b63\u4ea4\u4e14\u53ef\u7ec4\u5408\uff0c\u4e13\u6ce8\u4e8e\u63d0\u5347\u8bad\u7ec3\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u900f\u660e\u6027\u3002", "result": "\u8fd9\u4e9b\u6a21\u5757\u7684\u534f\u540c\u96c6\u6210\u589e\u5f3a\u4e86Megatron-LM\u751f\u6001\u7cfb\u7edf\u7684\u80fd\u529b\u3002", "conclusion": "MegatronApp\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u4e3a\u751f\u4ea7\u89c4\u6a21\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.20412", "pdf": "https://arxiv.org/pdf/2507.20412", "abs": "https://arxiv.org/abs/2507.20412", "authors": ["Maximilian Jakob Heer", "Benjamin Ramhorst", "Yu Zhu", "Luhao Liu", "Zhiyi Hu", "Jonas Dann", "Gustavo Alonso"], "title": "RoCE BALBOA: Service-enhanced Data Center RDMA for SmartNICs", "categories": ["cs.AR", "cs.NI"], "comment": null, "summary": "Data-intensive applications in data centers, especially machine learning\n(ML), have made the network a bottleneck, which in turn has motivated the\ndevelopment of more efficient network protocols and infrastructure. For\ninstance, remote direct memory access (RDMA) has become the standard protocol\nfor data transport in the cloud as it minimizes data copies and reduces\nCPU-utilization via host-bypassing. Similarly, an increasing amount of network\nfunctions and infrastructure have moved to accelerators, SmartNICs, and\nin-network computing to bypass the CPU. In this paper we explore the\nimplementation and deployment of RoCE BALBOA, an open-source, RoCE\nv2-compatible, scalable up to hundreds of queue-pairs, and 100G-capable\nRDMA-stack that can be used as the basis for building accelerators and\nsmartNICs. RoCE BALBOA is customizable, opening up a design space and offering\na degree of adaptability not available in commercial products. We have deployed\nBALBOA in a cluster using FPGAs and show that it has latency and performance\ncharacteristics comparable to commercial NICs. We demonstrate its potential by\nexploring two classes of use cases. One involves enhancements to the protocol\nfor infrastructure purposes (encryption, deep packet inspection using ML). The\nother showcases the ability to perform line-rate compute offloads with deep\npipelines by implementing commercial data preprocessing pipelines for\nrecommender systems that process the data as it arrives from the network before\ntransferring it directly to the GPU. These examples demonstrate how BALBOA\nenables the exploration and development of SmartNICs and accelerators operating\non network data streams.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86RoCE BALBOA\uff0c\u4e00\u79cd\u5f00\u6e90\u7684\u3001RoCE v2\u517c\u5bb9\u7684RDMA\u534f\u8bae\u6808\uff0c\u9002\u7528\u4e8e\u6784\u5efa\u9ad8\u6027\u80fd\u667a\u80fd\u7f51\u5361\u548c\u52a0\u901f\u5668\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u4e2d\u7684\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\uff08\u5982\u673a\u5668\u5b66\u4e60\uff09\u4f7f\u7f51\u7edc\u6210\u4e3a\u74f6\u9888\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u7f51\u7edc\u534f\u8bae\u548c\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u63d0\u51fa\u4e86RoCE BALBOA\uff0c\u4e00\u79cd\u53ef\u6269\u5c55\u81f3\u6570\u767e\u5bf9\u961f\u5217\u3001\u652f\u6301100G\u7684RDMA\u534f\u8bae\u6808\uff0c\u5177\u6709\u9ad8\u5ea6\u53ef\u5b9a\u5236\u6027\uff0c\u5e76\u901a\u8fc7FPGA\u5728\u96c6\u7fa4\u4e2d\u90e8\u7f72\u3002", "result": "BALBOA\u7684\u5ef6\u8fdf\u548c\u6027\u80fd\u4e0e\u5546\u7528\u7f51\u5361\u76f8\u5f53\uff0c\u5e76\u6210\u529f\u5c55\u793a\u4e86\u5728\u534f\u8bae\u589e\u5f3a\uff08\u5982\u52a0\u5bc6\u3001ML\u6df1\u5ea6\u5305\u68c0\u6d4b\uff09\u548c\u7ebf\u901f\u8ba1\u7b97\u5378\u8f7d\uff08\u5982\u63a8\u8350\u7cfb\u7edf\u6570\u636e\u9884\u5904\u7406\uff09\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "RoCE BALBOA\u4e3a\u667a\u80fd\u7f51\u5361\u548c\u52a0\u901f\u5668\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u57fa\u7840\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u7f51\u7edc\u6570\u636e\u6d41\u3002"}}
{"id": "2507.20312", "pdf": "https://arxiv.org/pdf/2507.20312", "abs": "https://arxiv.org/abs/2507.20312", "authors": ["Jonas H. M\u00fcller Kornd\u00f6rfer", "Ali Mohammed", "Ahmed Eleliemy", "Quentin Guilloteau", "Reto Krummenacher", "Florina M. Ciorba"], "title": "A Comparative Study of OpenMP Scheduling Algorithm Selection Strategies", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": "To appear at IEEE ACCESS", "summary": "Scientific and data science applications are becoming increasingly complex,\nwith growing computational and memory demands. Modern high performance\ncomputing (HPC) systems provide high parallelism and heterogeneity across\nnodes, devices, and cores. To achieve good performance, effective scheduling\nand load balancing techniques are essential. Parallel programming frameworks\nsuch as OpenMP now offer a variety of advanced scheduling algorithms to support\ndiverse applications and platforms. This creates an instance of the scheduling\nalgorithm selection problem, which involves identifying the most suitable\nalgorithm for a given combination of workload and system characteristics.\n  In this work, we explore learning-based approaches for selecting scheduling\nalgorithms in OpenMP. We propose and evaluate expert-based and reinforcement\nlearning (RL)-based methods, and conduct a detailed performance analysis across\nsix applications and three systems. Our results show that RL methods are\ncapable of learning high-performing scheduling decisions, although they require\nsignificant exploration, with the choice of reward function playing a key role.\nExpert-based methods, in contrast, rely on prior knowledge and involve less\nexploration, though they may not always identify the optimal algorithm for a\nspecific application-system pair. By combining expert knowledge with RL-based\nlearning, we achieve improved performance and greater adaptability.\n  Overall, this work demonstrates that dynamic selection of scheduling\nalgorithms during execution is both viable and beneficial for OpenMP\napplications. The approach can also be extended to MPI-based programs, enabling\noptimization of scheduling decisions across multiple levels of parallelism.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\uff08\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u5f3a\u5316\u5b66\u4e60\uff09\u7528\u4e8eOpenMP\u4e2d\u8c03\u5ea6\u7b97\u6cd5\u9009\u62e9\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u4e0e\u4f18\u52bf\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728MPI\u7a0b\u5e8f\u4e2d\u7684\u6269\u5c55\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u79d1\u5b66\u548c\u6570\u636e\u79d1\u5b66\u5e94\u7528\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u8c03\u5ea6\u548c\u8d1f\u8f7d\u5e73\u8861\u6280\u672f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002OpenMP\u7b49\u5e76\u884c\u7f16\u7a0b\u6846\u67b6\u63d0\u4f9b\u4e86\u591a\u6837\u5316\u7684\u8c03\u5ea6\u7b97\u6cd5\uff0c\u4f46\u5982\u4f55\u9009\u62e9\u6700\u4f18\u7b97\u6cd5\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e13\u5bb6\u77e5\u8bc6\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u516d\u79cd\u5e94\u7528\u548c\u4e09\u4e2a\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u6027\u80fd\u5206\u6790\u3002\u901a\u8fc7\u7ed3\u5408\u4e24\u8005\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u5b66\u4e60\u9ad8\u6027\u80fd\u7684\u8c03\u5ea6\u51b3\u7b56\uff0c\u4f46\u9700\u8981\u5927\u91cf\u63a2\u7d22\uff0c\u800c\u4e13\u5bb6\u65b9\u6cd5\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\u4f46\u53ef\u80fd\u65e0\u6cd5\u627e\u5230\u6700\u4f18\u89e3\u3002\u7ed3\u5408\u4e24\u8005\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u52a8\u6001\u8c03\u5ea6\u7b97\u6cd5\u9009\u62e9\u5bf9OpenMP\u5e94\u7528\u53ef\u884c\u4e14\u6709\u76ca\uff0c\u5e76\u53ef\u6269\u5c55\u81f3MPI\u7a0b\u5e8f\uff0c\u4f18\u5316\u591a\u7ea7\u5e76\u884c\u8c03\u5ea6\u51b3\u7b56\u3002"}}
{"id": "2507.19938", "pdf": "https://arxiv.org/pdf/2507.19938", "abs": "https://arxiv.org/abs/2507.19938", "authors": ["W. A. Sasindu Wijesuriya"], "title": "Optimizing Spreading Factor Selection for Mobile LoRa Gateways Using Single-Channel Hardware", "categories": ["cs.NI", "cs.RO"], "comment": "6 pages, 5 figures", "summary": "The deployment of mobile LoRa gateways using low-cost single-channel hardware\npresents a significant challenge in maintaining reliable communication due to\nthe lack of dynamic configuration support. In traditional LoRaWAN networks,\nAdaptive Data Rate (ADR) mechanisms optimize communication parameters in real\ntime. However, such features are typically supported only by expensive\nmulti-channel gateways. This study proposes a cost-effective and\nenergy-efficient solution by statically selecting the optimal Spreading Factor\n(SF) using a two-phase algorithm. The method first applies rule-based exclusion\nto eliminate SFs that violate constraints related to distance, data rate, link\nmargin, and regulatory limits. Remaining candidates are then evaluated using a\nweighted scoring model incorporating Time-on-Air, energy consumption, data\nrate, and link robustness. The proposed algorithm was validated through\nextensive field tests and NS-3 simulations under line-of-sight conditions.\nResults demonstrate that the selected SF matched the optimal SF in over 92% of\ncases across 672 simulated scenarios, confirming the algorithm's effectiveness.\nThis approach offers a scalable alternative to dynamic protocols, enabling\nreliable mobile LoRa deployments in cost-sensitive environments such as\nagriculture and rural sensing applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u9759\u6001\u9009\u62e9\u6700\u4f18\u6269\u9891\u56e0\u5b50\uff08SF\uff09\u7684\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u79fb\u52a8LoRa\u7f51\u5173\u7684\u53ef\u9760\u901a\u4fe1\uff0c\u65e0\u9700\u4f9d\u8d56\u6602\u8d35\u7684\u52a8\u6001\u914d\u7f6e\u786c\u4ef6\u3002", "motivation": "\u4f20\u7edfLoRaWAN\u7f51\u7edc\u7684\u52a8\u6001\u914d\u7f6e\u529f\u80fd\u4ec5\u652f\u6301\u6602\u8d35\u7684\u591a\u901a\u9053\u7f51\u5173\uff0c\u800c\u4f4e\u6210\u672c\u5355\u901a\u9053\u786c\u4ef6\u7f3a\u4e4f\u52a8\u6001\u914d\u7f6e\u652f\u6301\uff0c\u5bfc\u81f4\u901a\u4fe1\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7b97\u6cd5\uff1a\u57fa\u4e8e\u89c4\u5219\u6392\u9664\u4e0d\u6ee1\u8db3\u8ddd\u79bb\u3001\u6570\u636e\u901f\u7387\u7b49\u7ea6\u675f\u7684SF\uff1b\u5269\u4f59\u9009\u9879\u901a\u8fc7\u52a0\u6743\u8bc4\u5206\u6a21\u578b\u8bc4\u4f30\uff08\u8003\u8651\u4f20\u8f93\u65f6\u95f4\u3001\u80fd\u8017\u7b49\uff09\u3002", "result": "\u5728672\u4e2a\u6a21\u62df\u573a\u666f\u4e2d\uff0c\u6240\u9009SF\u572892%\u4ee5\u4e0a\u7684\u60c5\u51b5\u4e0b\u5339\u914d\u6700\u4f18SF\uff0c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u9759\u6001\u65b9\u6cd5\u4e3a\u6210\u672c\u654f\u611f\u573a\u666f\u4e0b\u7684\u79fb\u52a8LoRa\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.19902", "pdf": "https://arxiv.org/pdf/2507.19902", "abs": "https://arxiv.org/abs/2507.19902", "authors": ["Sourena Khanzadeh"], "title": "AgentMesh: A Cooperative Multi-Agent Generative AI Framework for Software Development Automation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Software development is a complex, multi-phase process traditionally\nrequiring collaboration among individuals with diverse expertise. We propose\nAgentMesh, a Python-based framework that uses multiple cooperating LLM-powered\nagents to automate software development tasks. In AgentMesh, specialized agents\n- a Planner, Coder, Debugger, and Reviewer - work in concert to transform a\nhigh-level requirement into fully realized code. The Planner agent first\ndecomposes user requests into concrete subtasks; the Coder agent implements\neach subtask in code; the Debugger agent tests and fixes the code; and the\nReviewer agent validates the final output for correctness and quality. We\ndescribe the architecture and design of these agents and their communication,\nand provide implementation details including prompt strategies and workflow\norchestration. A case study illustrates AgentMesh handling a non-trivial\ndevelopment request via sequential task planning, code generation, iterative\ndebugging, and final code review. We discuss how dividing responsibilities\namong cooperative agents leverages the strengths of large language models while\nmitigating single-agent limitations. Finally, we examine current limitations -\nsuch as error propagation and context scaling - and outline future work toward\nmore robust, scalable multi-agent AI systems for software engineering\nautomation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6AgentMesh\uff0c\u901a\u8fc7\u534f\u4f5c\u7684LLM\u9a71\u52a8\u667a\u80fd\u4f53\uff08Planner\u3001Coder\u3001Debugger\u548cReviewer\uff09\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u9700\u8981\u591a\u9886\u57df\u4e13\u5bb6\u534f\u4f5c\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u8017\u65f6\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5b9e\u73b0\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\uff0c\u63d0\u5347\u6548\u7387\u3002", "method": "AgentMesh\u7531\u56db\u4e2a\u667a\u80fd\u4f53\u7ec4\u6210\uff1aPlanner\u5206\u89e3\u4efb\u52a1\u3001Coder\u5b9e\u73b0\u4ee3\u7801\u3001Debugger\u6d4b\u8bd5\u548c\u4fee\u590d\u3001Reviewer\u9a8c\u8bc1\u4ee3\u7801\u8d28\u91cf\u3002\u8bba\u6587\u8be6\u7ec6\u63cf\u8ff0\u4e86\u67b6\u6784\u3001\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7ec6\u8282\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86AgentMesh\u5904\u7406\u590d\u6742\u5f00\u53d1\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u53ef\u4ee5\u53d1\u6325LLM\u7684\u4f18\u52bf\u5e76\u5f25\u8865\u5355\u667a\u80fd\u4f53\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u5f53\u524d\u5c40\u9650\uff08\u5982\u9519\u8bef\u4f20\u64ad\u548c\u4e0a\u4e0b\u6587\u6269\u5c55\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u3002"}}
{"id": "2507.20615", "pdf": "https://arxiv.org/pdf/2507.20615", "abs": "https://arxiv.org/abs/2507.20615", "authors": ["Jan Baumeister", "Bernd Finkbeiner", "Frederik Scheerer"], "title": "Active Monitoring with RTLola: A Specification-Guided Scheduling Approach", "categories": ["cs.LO"], "comment": null, "summary": "Stream-based monitoring is a well-established runtime verification approach\nwhich relates input streams, representing sensor readings from the monitored\nsystem, with output streams that capture filtered or aggregated results. In\nsuch approaches, the monitor is a passive external component that continuously\nreceives sensor data from the system under observation. This setup assumes that\nthe system dictates what data is sent and when, regardless of the monitor's\ncurrent needs. However, in many applications -- particularly in\nresource-constrained environments like autonomous aircraft, where energy, size,\nor weight are limited -- this can lead to inefficient use of communication\nresources. We propose making the monitor an active component that decides,\nbased on its current internal state, which sensors to query and how often. This\nbehavior is driven by scheduling annotations in the specification, which guide\nthe dynamic allocation of bandwidth towards the most relevant data, thereby\nimproving monitoring efficiency. We demonstrate our approach using the\nstream-based specification language RTLola and assess the performance by\nmonitoring a specification from the aerospace domain. With equal bandwidth\nusage, our approach detects specification violations significantly sooner than\nmonitors sampling all inputs at a fixed frequency.", "AI": {"tldr": "\u5c06\u76d1\u6d4b\u5668\u53d8\u4e3a\u4e3b\u52a8\u7ec4\u4ef6\uff0c\u6839\u636e\u5185\u90e8\u72b6\u6001\u52a8\u6001\u8c03\u5ea6\u4f20\u611f\u5668\u67e5\u8be2\uff0c\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u76d1\u6d4b\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u88ab\u52a8\u76d1\u6d4b\u65b9\u5f0f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u6539\u8fdb\u4ee5\u4f18\u5316\u901a\u4fe1\u8d44\u6e90\u5229\u7528\u3002", "method": "\u901a\u8fc7\u89c4\u8303\u4e2d\u7684\u8c03\u5ea6\u6ce8\u91ca\uff0c\u52a8\u6001\u5206\u914d\u5e26\u5bbd\u81f3\u6700\u76f8\u5173\u6570\u636e\uff0c\u4f7f\u7528RTLola\u8bed\u8a00\u5b9e\u73b0\u3002", "result": "\u5728\u76f8\u540c\u5e26\u5bbd\u4e0b\uff0c\u4e3b\u52a8\u76d1\u6d4b\u6bd4\u56fa\u5b9a\u9891\u7387\u91c7\u6837\u66f4\u65e9\u53d1\u73b0\u89c4\u8303\u8fdd\u89c4\u3002", "conclusion": "\u4e3b\u52a8\u67e5\u8be2\u673a\u5236\u663e\u8457\u63d0\u5347\u76d1\u6d4b\u6548\u7387\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002"}}
{"id": "2507.20922", "pdf": "https://arxiv.org/pdf/2507.20922", "abs": "https://arxiv.org/abs/2507.20922", "authors": ["J. Mercado Colmenero", "A. Torres Alba", "C. Martin Donate"], "title": "Methodology for intelligent injection point location based on geometric algorithms and discrete topologies for virtual digital twin environments", "categories": ["cs.GR", "cs.NA", "math.NA"], "comment": null, "summary": "This article presents an innovative methodology for locating injection points\nin injection-molded parts using intelligent models with geometric algorithms\nfor discrete topologies. The first algorithm calculates the center of mass of\nthe discrete model based on the center of mass of each triangular facet in the\nsystem, ensuring uniform molten plastic distribution during mold cavity\nfilling. Two sub-algorithms intelligently evaluate the geometry and optimal\ninjection point location. The first sub-algorithm generates a geometric matrix\nbased on a two-dimensional nodal quadrature adapted to the part's bounding box.\nThe second sub-algorithm projects the nodal matrix and associated circular\nareas orthogonally on the part's surface along the demolding direction. The\noptimal injection point location is determined by minimizing the distance to\nthe center of mass from the first algorithm's result. This novel methodology\nhas been validated through rheological simulations in six case studies with\ncomplex geometries. The results demonstrate uniform and homogeneous molten\nplastic distribution with minimal pressure loss during the filling phase.\nImportantly, this methodology does not require expert intervention, reducing\ntime and costs associated with manual injection mold feed system design. It is\nalso adaptable to various design environments and virtual twin systems, not\ntied to specific CAD software. The validated results surpass the state of the\nart, offering an agile alternative for digital twin applications in new product\ndesign environments, reducing dependence on experts, facilitating designer\ntraining, and ultimately cutting costs", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u51e0\u4f55\u7b97\u6cd5\u548c\u667a\u80fd\u6a21\u578b\u5b9a\u4f4d\u6ce8\u5851\u4ef6\u7684\u6ce8\u5851\u70b9\uff0c\u4f18\u5316\u7194\u878d\u5851\u6599\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u51cf\u5c11\u6ce8\u5851\u6a21\u5177\u8bbe\u8ba1\u4e2d\u7684\u4eba\u5de5\u5e72\u9884\uff0c\u964d\u4f4e\u6210\u672c\u548c\u65f6\u95f4\uff0c\u63d0\u4f9b\u4e00\u79cd\u4e0d\u4f9d\u8d56\u7279\u5b9aCAD\u8f6f\u4ef6\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u51e0\u4f55\u7b97\u6cd5\u8ba1\u7b97\u79bb\u6563\u6a21\u578b\u7684\u8d28\u5fc3\uff0c\u751f\u6210\u51e0\u4f55\u77e9\u9635\u5e76\u6295\u5f71\u5230\u96f6\u4ef6\u8868\u9762\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4e0e\u8d28\u5fc3\u7684\u8ddd\u79bb\u786e\u5b9a\u6700\u4f73\u6ce8\u5851\u70b9\u3002", "result": "\u516d\u9879\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u5747\u5300\u7684\u7194\u878d\u5851\u6599\u5206\u5e03\u548c\u6700\u5c0f\u5316\u7684\u538b\u529b\u635f\u5931\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6570\u5b57\u5316\u53cc\u80de\u80ce\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7ecf\u6d4e\u7684\u6ce8\u5851\u70b9\u5b9a\u4f4d\u65b9\u6848\uff0c\u51cf\u5c11\u4e86\u5bf9\u4e13\u5bb6\u7684\u4f9d\u8d56\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u8bbe\u8ba1\u73af\u5883\u3002"}}
{"id": "2507.19835", "pdf": "https://arxiv.org/pdf/2507.19835", "abs": "https://arxiv.org/abs/2507.19835", "authors": ["Chunshi Wang", "Hongxing Li", "Yawei Luo"], "title": "SonicGauss: Position-Aware Physical Sound Synthesis for 3D Gaussian Representations", "categories": ["cs.SD", "cs.MM"], "comment": "Accepted by ACMMM'25", "summary": "While 3D Gaussian representations (3DGS) have proven effective for modeling\nthe geometry and appearance of objects, their potential for capturing other\nphysical attributes-such as sound-remains largely unexplored. In this paper, we\npresent a novel framework dubbed SonicGauss for synthesizing impact sounds from\n3DGS representations by leveraging their inherent geometric and material\nproperties. Specifically, we integrate a diffusion-based sound synthesis model\nwith a PointTransformer-based feature extractor to infer material\ncharacteristics and spatial-acoustic correlations directly from Gaussian\nellipsoids. Our approach supports spatially varying sound responses conditioned\non impact locations and generalizes across a wide range of object categories.\nExperiments on the ObjectFolder dataset and real-world recordings demonstrate\nthat our method produces realistic, position-aware auditory feedback. The\nresults highlight the framework's robustness and generalization ability,\noffering a promising step toward bridging 3D visual representations and\ninteractive sound synthesis. Project page: https://chunshi.wang/SonicGauss", "AI": {"tldr": "SonicGauss\u662f\u4e00\u79cd\u65b0\u9896\u6846\u67b6\uff0c\u5229\u75283D\u9ad8\u65af\u8868\u793a\uff083DGS\uff09\u5408\u6210\u78b0\u649e\u58f0\u97f3\uff0c\u7ed3\u5408\u6269\u6563\u6a21\u578b\u548c\u70b9\u53d8\u6362\u5668\u63d0\u53d6\u5668\uff0c\u76f4\u63a5\u4ece\u9ad8\u65af\u692d\u7403\u63a8\u65ad\u6750\u6599\u7279\u6027\u548c\u7a7a\u95f4\u58f0\u5b66\u76f8\u5173\u6027\u3002", "motivation": "\u63a2\u7d223DGS\u5728\u6355\u6349\u7269\u7406\u5c5e\u6027\uff08\u5982\u58f0\u97f3\uff09\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u96c6\u6210\u6269\u6563\u6a21\u578b\u548cPointTransformer\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u4ece\u9ad8\u65af\u692d\u7403\u63a8\u65ad\u6750\u6599\u7279\u6027\u548c\u7a7a\u95f4\u58f0\u5b66\u76f8\u5173\u6027\u3002", "result": "\u5728ObjectFolder\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u5f55\u97f3\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u771f\u5b9e\u6027\u3001\u4f4d\u7f6e\u611f\u77e5\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SonicGauss\u4e3a\u8fde\u63a53D\u89c6\u89c9\u8868\u793a\u548c\u4ea4\u4e92\u5f0f\u58f0\u97f3\u5408\u6210\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u4e00\u6b65\u3002"}}
{"id": "2403.05415", "pdf": "https://arxiv.org/pdf/2403.05415", "abs": "https://arxiv.org/abs/2403.05415", "authors": ["M Sabbir Salek", "Mugdha Basu Thakur", "Pardha Sai Krishna Ala", "Mashrur Chowdhury", "Matthias Schmid", "Pamela Murray-Tuite", "Sakib Mahmud Khan", "Venkat Krovi"], "title": "An Overview of Automated Vehicle Longitudinal Platoon Formation Strategies", "categories": ["eess.SY", "cs.ET", "cs.SY"], "comment": null, "summary": "Automated vehicle (AV) platooning has the potential to improve the safety,\noperational, and energy efficiency of surface transportation systems by\nlimiting or eliminating human involvement in the driving tasks. The theoretical\nvalidity of the AV platooning strategies has been established and practical\napplications are being tested under real-world conditions. The emergence of\nsensors, communication, and control strategies has resulted in rapid and\nconstant evolution of AV platooning strategies. In this paper, we review the\nstate-of-the-art knowledge in AV longitudinal platoon formation using a\nfive-component platooning framework, which includes vehicle model,\ninformation-receiving process, information flow topology, spacing policy, and\ncontroller and discuss the advantages and limitations of the components. Based\non the discussion about existing strategies and associated limitations,\npotential future research directions are presented.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08AV\uff09\u7eb5\u5411\u8f66\u961f\u5f62\u6210\u7684\u6700\u65b0\u77e5\u8bc6\uff0c\u5206\u6790\u4e86\u4e94\u4e2a\u5173\u952e\u7ec4\u4ef6\uff0c\u5e76\u63a2\u8ba8\u4e86\u73b0\u6709\u7b56\u7565\u7684\u4f18\u52a3\u52bf\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u961f\u7684\u6f5c\u529b\u5728\u4e8e\u63d0\u5347\u4ea4\u901a\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3001\u64cd\u4f5c\u6027\u548c\u80fd\u6e90\u6548\u7387\uff0c\u4f46\u5176\u7b56\u7565\u7684\u5b9e\u8df5\u4ecd\u5f85\u9a8c\u8bc1\uff0c\u9700\u603b\u7ed3\u73b0\u72b6\u5e76\u5c55\u671b\u672a\u6765\u3002", "method": "\u91c7\u7528\u4e94\u7ec4\u4ef6\u6846\u67b6\uff08\u8f66\u8f86\u6a21\u578b\u3001\u4fe1\u606f\u63a5\u6536\u8fc7\u7a0b\u3001\u4fe1\u606f\u6d41\u62d3\u6251\u3001\u95f4\u8ddd\u7b56\u7565\u548c\u63a7\u5236\u5668\uff09\u5206\u6790\u73b0\u6709AV\u8f66\u961f\u7b56\u7565\u3002", "result": "\u73b0\u6709\u7684\u8f66\u961f\u7b56\u7565\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u7ec4\u4ef6\u5404\u6709\u4f18\u52a3\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "conclusion": "\u8bba\u6587\u6307\u51fa\u672a\u6765\u7814\u7a76\u5e94\u9488\u5bf9\u73b0\u6709\u7b56\u7565\u7684\u5c40\u9650\u6027\uff0c\u63a2\u7d22\u66f4\u9ad8\u6548\u3001\u53ef\u9760\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u961f\u6280\u672f\u3002"}}
{"id": "2507.19490", "pdf": "https://arxiv.org/pdf/2507.19490", "abs": "https://arxiv.org/abs/2507.19490", "authors": ["Xinzheng Wu", "Junyi Chen", "Peiyi Wang", "Shunxiang Chen", "Yong Shen"], "title": "RISEE: A Highly Interactive Naturalistic Driving Trajectories Dataset with Human Subjective Risk Perception and Eye-tracking Information", "categories": ["cs.HC", "cs.CV"], "comment": "Submitted for ITSC 2025", "summary": "In the research and development (R&D) and verification and validation (V&V)\nphases of autonomous driving decision-making and planning systems, it is\nnecessary to integrate human factors to achieve decision-making and evaluation\nthat align with human cognition. However, most existing datasets primarily\nfocus on vehicle motion states and trajectories, neglecting human-related\ninformation. In addition, current naturalistic driving datasets lack sufficient\nsafety-critical scenarios while simulated datasets suffer from low\nauthenticity. To address these issues, this paper constructs the Risk-Informed\nSubjective Evaluation and Eye-tracking (RISEE) dataset which specifically\ncontains human subjective evaluations and eye-tracking data apart from regular\nnaturalistic driving trajectories. By leveraging the complementary advantages\nof drone-based (high realism and extensive scenario coverage) and\nsimulation-based (high safety and reproducibility) data collection methods, we\nfirst conduct drone-based traffic video recording at a highway ramp merging\narea. After that, the manually selected highly interactive scenarios are\nreconstructed in simulation software, and drivers' first-person view (FPV)\nvideos are generated, which are then viewed and evaluated by recruited\nparticipants. During the video viewing process, participants' eye-tracking data\nis collected. After data processing and filtering, 3567 valid subjective risk\nratings from 101 participants across 179 scenarios are retained, along with\n2045 qualified eye-tracking data segments. The collected data and examples of\nthe generated FPV videos are available in our website.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86RISEE\u6570\u636e\u96c6\uff0c\u6574\u5408\u4eba\u7c7b\u4e3b\u89c2\u8bc4\u4ef7\u548c\u773c\u52a8\u6570\u636e\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u4eba\u7c7b\u76f8\u5173\u4fe1\u606f\u548c\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u95ee\u9898\u3002", "motivation": "\u76ee\u524d\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u548c\u89c4\u5212\u7cfb\u7edf\u7684\u7814\u7a76\u7f3a\u4e4f\u4eba\u7c7b\u56e0\u7d20\u6570\u636e\u548c\u8db3\u591f\u7684\u5b89\u5168\u5173\u952e\u573a\u666f\uff0c\u800c\u6a21\u62df\u6570\u636e\u771f\u5b9e\u6027\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u65e0\u4eba\u673a\u548c\u6a21\u62df\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u9996\u5148\u5728\u9ad8\u771f\u5b9e\u6027\u7684\u9ad8\u901f\u516c\u8def\u531d\u9053\u533a\u57df\u5f55\u5236\u4ea4\u901a\u89c6\u9891\uff0c\u7136\u540e\u5c06\u9ad8\u4ea4\u4e92\u573a\u666f\u91cd\u5efa\u4e3a\u6a21\u62df\u89c6\u9891\uff0c\u6536\u96c6\u53c2\u4e0e\u8005\u7684\u4e3b\u89c2\u8bc4\u4ef7\u548c\u773c\u52a8\u6570\u636e\u3002", "result": "\u6210\u529f\u6784\u5efa\u7684RISEE\u6570\u636e\u96c6\u5305\u542b\u6765\u81ea101\u540d\u53c2\u4e0e\u8005\u76843567\u4e2a\u6709\u6548\u4e3b\u89c2\u98ce\u9669\u8bc4\u5206\u548c2045\u4e2a\u5408\u683c\u773c\u52a8\u6570\u636e\u6bb5\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u7684\u4e0d\u8db3\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2507.20839", "pdf": "https://arxiv.org/pdf/2507.20839", "abs": "https://arxiv.org/abs/2507.20839", "authors": ["Valerie Restat", "Niklas Rodenhausen", "Carina Antonin", "Uta St\u00f6rl"], "title": "Data Cleaning of Data Streams", "categories": ["cs.DB"], "comment": null, "summary": "Streaming data can arise from a variety of contexts. Important use cases are\ncontinuous sensor measurements such as temperature, light or radiation values.\nIn the process, streaming data may also contain data errors that should be\ncleaned before further use. Many studies from science and practice focus on\ndata cleaning in a static context. However, in terms of data cleaning,\nstreaming data has particularities that distinguish it from static data. In\nthis paper, we have therefore undertaken an intensive exploration of data\ncleaning of data streams. We provide a detailed analysis of the applicability\nof data cleaning to data streams. Our theoretical considerations are evaluated\nin comprehensive experiments. Using a prototype framework, we show that\ncleaning is not consistent when working with data streams. An additional\ncontribution is the investigation of requirements for streaming technologies in\ncontext of data cleaning.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6570\u636e\u6d41\u6e05\u6d17\u7684\u7279\u6b8a\u6027\u53ca\u5176\u9002\u7528\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u7406\u8bba\u8003\u8651\u3002", "motivation": "\u6d41\u6570\u636e\u6765\u81ea\u591a\u79cd\u573a\u666f\uff08\u5982\u4f20\u611f\u5668\u6d4b\u91cf\uff09\uff0c\u4f46\u5176\u6e05\u6d17\u4e0e\u9759\u6001\u6570\u636e\u4e0d\u540c\uff0c\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u9759\u6001\u6570\u636e\u3002", "method": "\u6df1\u5165\u5206\u6790\u6d41\u6570\u636e\u6e05\u6d17\u7684\u9002\u7528\u6027\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u6846\u67b6\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6d41\u6570\u636e\u6e05\u6d17\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u7814\u7a76\u4e86\u6d41\u6280\u672f\u8981\u6c42\u3002", "conclusion": "\u6d41\u6570\u636e\u6e05\u6d17\u9700\u7279\u6b8a\u5904\u7406\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8c03\u6574\u4ee5\u6ee1\u8db3\u5176\u52a8\u6001\u6027\u3002"}}
{"id": "2507.19926", "pdf": "https://arxiv.org/pdf/2507.19926", "abs": "https://arxiv.org/abs/2507.19926", "authors": ["Louis Sugy"], "title": "A Fast Parallel Median Filtering Algorithm Using Hierarchical Tiling", "categories": ["cs.DC", "cs.CV", "I.3.1; I.4.3"], "comment": "8 pages, 8 figures", "summary": "Median filtering is a non-linear smoothing technique widely used in digital\nimage processing to remove noise while retaining sharp edges. It is\nparticularly well suited to removing outliers (impulse noise) or granular\nartifacts (speckle noise). However, the high computational cost of median\nfiltering can be prohibitive. Sorting-based algorithms excel with small kernels\nbut scale poorly with increasing kernel diameter, in contrast to constant-time\nmethods characterized by higher constant factors but better scalability, such\nas histogram-based approaches or the 2D wavelet matrix.\n  This paper introduces a novel algorithm, leveraging the separability of the\nsorting problem through hierarchical tiling to minimize redundant computations.\nWe propose two variants: a data-oblivious selection network that can operate\nentirely within registers, and a data-aware version utilizing random-access\nmemory. These achieve per-pixel complexities of $O(k \\log(k))$ and $O(k)$,\nrespectively, for a $k \\times k$ kernel - unprecedented for sorting-based\nmethods. Our CUDA implementation is up to 5 times faster than the current state\nof the art on a modern GPU and is the fastest median filter in most cases for\n8-, 16-, and 32-bit data types and kernels from $3 \\times 3$ to $75 \\times 75$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e2d\u503c\u6ee4\u6ce2\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u5757\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\uff0cGPU\u5b9e\u73b0\u901f\u5ea6\u6bd4\u73b0\u6709\u6280\u672f\u5feb5\u500d\u3002", "motivation": "\u4e2d\u503c\u6ee4\u6ce2\u867d\u7136\u80fd\u6709\u6548\u53bb\u9664\u566a\u58f0\u5e76\u4fdd\u7559\u8fb9\u7f18\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u6210\u672c\u9650\u5236\u4e86\u5e94\u7528\u3002\u8bba\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u89e3\u51b3\u73b0\u6709\u6392\u5e8f\u65b9\u6cd5\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u6392\u5e8f\u95ee\u9898\u7684\u53ef\u5206\u6027\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u5757\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u3002\u63d0\u51fa\u4e24\u79cd\u53d8\u4f53\uff1a\u4e00\u79cd\u5b8c\u5168\u5728\u5bc4\u5b58\u5668\u4e2d\u64cd\u4f5c\u7684\u6570\u636e\u65e0\u5173\u9009\u62e9\u7f51\u7edc\uff0c\u53e6\u4e00\u79cd\u5229\u7528\u968f\u673a\u5b58\u53d6\u5185\u5b58\u7684\u6570\u636e\u611f\u77e5\u7248\u672c\u3002", "result": "\u7b97\u6cd5\u5728$k \\times k$\u6838\u4e0b\u7684\u6bcf\u50cf\u7d20\u590d\u6742\u5ea6\u5206\u522b\u4e3a$O(k \\log(k))$\u548c$O(k)$\uff0cCUDA\u5b9e\u73b0\u5728\u73b0\u4ee3GPU\u4e0a\u6bd4\u73b0\u6709\u6280\u672f\u5feb5\u500d\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u7c7b\u578b\u76848-\u300116-\u548c32\u4f4d\u6570\u636e\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4e2d\u503c\u6ee4\u6ce2\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u56fe\u50cf\u5904\u7406\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5feb\u901f\u7684\u9009\u62e9\uff0c\u5c24\u5176\u5728\u5927\u6838\u60c5\u51b5\u4e0b\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2507.20420", "pdf": "https://arxiv.org/pdf/2507.20420", "abs": "https://arxiv.org/abs/2507.20420", "authors": ["Md Rownak Hossain Chowdhury", "Mostafizur Rahman"], "title": "Demystifying the 7-D Convolution Loop Nest for Data and Instruction Streaming in Reconfigurable AI Accelerators", "categories": ["cs.AR"], "comment": null, "summary": "Convolution remains the most compute-intensive operation in AI acceleration,\noften constituting over 80-90% of the workload. Existing approaches in spatial\narchitectures such as coarse-grained reconfigurable arrays (CGRAs) and\nfield-programmable gate arrays (FPGAs) frequently rely on loop unrolling or\nGEMM-based matrix transformations, introducing significant overhead in both\ndata movement and instruction control. This paper presents a new framework\ndesigned to systematically demystify the 7-dimensional convolution loop nest by\nreinterpreting it as a hardware-centric data and instruction streaming problem.\nInstead of treating the loop nest as a fixed computational construct, our\napproach exposes its structure as a set of spatial and temporal mappings\ngoverned by hardware parameters such as compute element distribution,\ninterconnect topology, and reconfigurability. This abstraction supports\nlightweight, flexible deployment of convolution without reliance on heavyweight\ntransformations or reordering schemes. We demonstrate the application of our\napproach on the MAVeC accelerator. We detail the implementation of convolution\noperations in MAVeC and extend the framework to support full model execution on\nVGG-16. Our profiling reveals high PE utilization (over 90%), significant fold\nreuse, and scalable throughput up to 1.56 TFLOPs/sec and 12.7 KIPS for\nend-to-end VGG-16 inference. These results validate the efficacy of our\napproach in minimizing control overhead, improving data locality, and enabling\nefficient large-scale convolution execution without reliance on conventional\ntransformation-based methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5377\u79ef\u5faa\u73af\u5d4c\u5957\u91cd\u65b0\u89e3\u91ca\u4e3a\u786c\u4ef6\u4e3a\u4e2d\u5fc3\u7684\u6570\u636e\u548c\u6307\u4ee4\u6d41\u95ee\u9898\uff0c\u51cf\u5c11\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u6570\u636e\u79fb\u52a8\u548c\u63a7\u5236\u5f00\u9500\u3002", "motivation": "\u5377\u79ef\u662fAI\u52a0\u901f\u4e2d\u6700\u8ba1\u7b97\u5bc6\u96c6\u7684\u64cd\u4f5c\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982CGRA\u548cFPGA\uff09\u4f9d\u8d56\u5faa\u73af\u5c55\u5f00\u6216\u77e9\u9635\u53d8\u6362\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u5f00\u9500\u3002", "method": "\u901a\u8fc7\u5c067\u7ef4\u5377\u79ef\u5faa\u73af\u5d4c\u5957\u7ed3\u6784\u5316\u4e3a\u7a7a\u95f4\u548c\u65f6\u95f4\u6620\u5c04\uff0c\u57fa\u4e8e\u786c\u4ef6\u53c2\u6570\uff08\u8ba1\u7b97\u5355\u5143\u5206\u5e03\u3001\u4e92\u8fde\u62d3\u6251\u7b49\uff09\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u7075\u6d3b\u90e8\u7f72\u3002", "result": "\u5728MAVeC\u52a0\u901f\u5668\u4e0a\u9a8c\u8bc1\uff0cPE\u5229\u7528\u7387\u8d8590%\uff0c\u541e\u5410\u91cf\u8fbe1.56 TFLOPs/sec\uff0cVGG-16\u63a8\u7406\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u65b0\u6846\u67b6\u6709\u6548\u51cf\u5c11\u63a7\u5236\u5f00\u9500\uff0c\u63d0\u5347\u6570\u636e\u5c40\u90e8\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5377\u79ef\u6267\u884c\uff0c\u4e14\u65e0\u9700\u4f9d\u8d56\u4f20\u7edf\u53d8\u6362\u65b9\u6cd5\u3002"}}
{"id": "2507.19963", "pdf": "https://arxiv.org/pdf/2507.19963", "abs": "https://arxiv.org/abs/2507.19963", "authors": ["Nikolaos Bartzoudis", "Jos\u00e9 Rubio Fern\u00e1ndez", "David L\u00f3pez-Bueno", "Antonio Rom\u00e1n Villarroel"], "title": "A Scalable Resource Management Layer for FPGA SoCs in 6G Radio Units", "categories": ["cs.NI", "cs.AR"], "comment": "Paper accepted to the \"XL Simposio Nacional de la Uni\\'on\n  Cient\\'ifica Internacional de Radio (URSI 2025)\", Tarragona, Spain, 3-5\n  September 2025. Proceedings are not published. Also part of the worj appears\n  in Deliverables 2.2 and 5.2 of the SNS JU project VERGE", "summary": "This work presents a perspective on addressing the underutilization of\ncomputing resources in FPGA SoC devices deployed in 5G radio and edge computing\ninfrastructure. The initial step in this approach involves developing a\nresource management layer capable of dynamically migrating and scaling\nfunctions within these devices in response to contextual events. This layer\nserves as the foundation for designing a hierarchical, data-driven\nmicro-orchestrator responsible for managing the lifecycle of functions in FPGA\nSoC devices. In this paper, the proposed resource management layer is utilized\nto reconfigure a function based on events identified by a computer vision edge\napplication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b35G\u5c04\u9891\u548c\u8fb9\u7f18\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u4e2dFPGA SoC\u8bbe\u5907\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\u4e0d\u8db3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8fc1\u79fb\u548c\u6269\u5c55\u529f\u80fd\u6765\u4f18\u5316\u8d44\u6e90\u7ba1\u7406\u3002", "motivation": "FPGA SoC\u8bbe\u5907\u57285G\u548c\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\u672a\u5f97\u5230\u5145\u5206\u5229\u7528\uff0c\u9700\u8981\u901a\u8fc7\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8d44\u6e90\u7ba1\u7406\u5c42\uff0c\u80fd\u591f\u52a8\u6001\u8fc1\u79fb\u548c\u6269\u5c55\u529f\u80fd\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5206\u5c42\u3001\u6570\u636e\u9a71\u52a8\u7684\u5fae\u7f16\u6392\u5668\uff0c\u7528\u4e8e\u7ba1\u7406FPGA SoC\u8bbe\u5907\u4e2d\u529f\u80fd\u7684\u751f\u547d\u5468\u671f\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u8ba1\u7b97\u673a\u89c6\u89c9\u8fb9\u7f18\u5e94\u7528\u8bc6\u522b\u7684\u573a\u666f\u4e8b\u4ef6\uff0c\u5c55\u793a\u4e86\u8d44\u6e90\u7ba1\u7406\u5c42\u5982\u4f55\u52a8\u6001\u91cd\u65b0\u914d\u7f6e\u529f\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u4f18\u5316\u4e86FPGA SoC\u8bbe\u5907\u7684\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\uff0c\u4e3a5G\u548c\u8fb9\u7f18\u8ba1\u7b97\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\u3002"}}
{"id": "2507.19904", "pdf": "https://arxiv.org/pdf/2507.19904", "abs": "https://arxiv.org/abs/2507.19904", "authors": ["Zhanhang Xiong", "Dongxia Wang", "Yuekang Li", "Xinyuan An", "Wenhai Wang"], "title": "CrossPL: Evaluating Large Language Models on Cross Programming Language Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) become increasingly embedded in software\nengineering workflows, a critical capability remains underexplored: generating\ncorrect code that enables cross-programming-language (CPL) interoperability.\nThis skill is essential for building complex systems that integrate components\nwritten in multiple languages via mechanisms like inter-process communication\n(IPC). To bridge this gap, we present CrossPL, the first benchmark designed to\nsystematically evaluate LLMs' ability to generate CPL-interoperating code.\nCrossPL comprises 1,982 tasks centered around IPC, covering six widely-used\nprogramming languages and seven representative CPL techniques. We construct\nthis benchmark by (i) analyzing 19,169 multi-language GitHub repositories using\n156 hand-crafted finite state machines (FSMs), and (ii) developing an LLM-based\npipeline that automatically extracts CPL code snippets, generates task\ninstructions, and validates functional correctness. We evaluate 14\nstate-of-the-art general-purpose LLMs and 6 code-oriented LLMs released in the\npast three years on CrossPL via FSM-based validation. Results reveal that even\nthe best-performing models struggle with CPL scenarios, underscoring the need\nfor more targeted research in this space. Our benchmark and code are available\nat: https://anonymous.4open.science/r/crosspl-2814.", "AI": {"tldr": "CrossPL\u662f\u9996\u4e2a\u7cfb\u7edf\u6027\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u8de8\u7f16\u7a0b\u8bed\u8a00\uff08CPL\uff09\u4e92\u64cd\u4f5c\u4ee3\u7801\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d66\u79cd\u8bed\u8a00\u548c7\u79cd\u6280\u672f\u3002\u5373\u4f7f\u6700\u4f73\u6a21\u578b\u5728CPL\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u51f8\u663e\u4e86\u9488\u5bf9\u6027\u7814\u7a76\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u968f\u7740LLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u751f\u6210\u8de8\u7f16\u7a0b\u8bed\u8a00\u4e92\u64cd\u4f5c\u7684\u6b63\u786e\u4ee3\u7801\u6210\u4e3a\u5173\u952e\u80fd\u529b\uff0c\u4f46\u76ee\u524d\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5206\u679019,169\u4e2a\u591a\u8bed\u8a00GitHub\u4ed3\u5e93\u548c156\u4e2a\u6709\u9650\u72b6\u6001\u673a\uff08FSMs\uff09\uff0c\u6784\u5efa\u4e86\u5305\u542b1,982\u4e2a\u4efb\u52a1\u7684CrossPL\u57fa\u51c6\uff0c\u5e76\u4f7f\u7528FSM\u9a8c\u8bc1\u529f\u80fd\u6027\u3002", "result": "\u8bc4\u4f3014\u79cd\u901a\u7528LLMs\u548c6\u79cd\u4ee3\u7801\u4e13\u7528LLMs\u663e\u793a\uff0c\u5373\u4f7f\u6700\u4f73\u6a21\u578b\u5728CPL\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "CrossPL\u63ed\u793a\u4e86LLMs\u5728CPL\u4ee3\u7801\u751f\u6210\u4e0a\u7684\u4e0d\u8db3\uff0c\u547c\u5401\u66f4\u591a\u9488\u5bf9\u6027\u7814\u7a76\u3002"}}
{"id": "2507.20726", "pdf": "https://arxiv.org/pdf/2507.20726", "abs": "https://arxiv.org/abs/2507.20726", "authors": ["Hiroyuki Katsura", "Naoki Kobayashi", "Ken Sakayori", "Ryosuke Sato"], "title": "Automated Catamorphism Synthesis for Solving Constrained Horn Clauses over Algebraic Data Types", "categories": ["cs.LO"], "comment": null, "summary": "We propose a novel approach to satisfiability checking of Constrained Horn\nClauses (CHCs) over Algebraic Data Types (ADTs). CHC-based automated\nverification has gained considerable attention in recent years, leading to the\ndevelopment of various CHC solvers. However, existing solvers for CHCs over\nADTs are not fully satisfactory, due to their limited ability to find and\nexpress models involving inductively defined functions/predicates (e.g., those\nabout the sum of list elements). To address this limitation, we consider\ncatamorphisms (generalized fold functions), and present a framework for\nautomatically discovering appropriate catamorphisms on demand and using them to\nexpress a model of given CHCs. We have implemented a new CHC solver called\nCatalia based on the proposed method. Our experimental results for the CHC-COMP\n2024 benchmark show that Catalia outperforms state-of-the-art solvers in\nsolving satisfiable CHCs over ADTs. Catalia was also used as a core part of the\ntool called ChocoCatalia, which won the ADT-LIA category of CHC-COMP 2025.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCatamorphisms\u7684\u65b0\u578bCHC\u6c42\u89e3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86ADT\u95ee\u9898\u7684\u6c42\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709CHC\u6c42\u89e3\u5668\u5bf9ADT\u95ee\u9898\u7684\u5904\u7406\u80fd\u529b\u6709\u9650\uff0c\u65e0\u6cd5\u6709\u6548\u8868\u8fbe\u6d89\u53ca\u5f52\u7eb3\u5b9a\u4e49\u51fd\u6570/\u8c13\u8bcd\u7684\u6a21\u578b\u3002", "method": "\u5229\u7528Catamorphisms\uff08\u5e7f\u4e49\u6298\u53e0\u51fd\u6570\uff09\u81ea\u52a8\u53d1\u73b0\u5e76\u8868\u8fbeCHC\u6a21\u578b\uff0c\u5f00\u53d1\u4e86\u65b0\u578b\u6c42\u89e3\u5668Catalia\u3002", "result": "Catalia\u5728CHC-COMP 2024\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u4e14\u5176\u884d\u751f\u5de5\u5177ChocoCatalia\u5728CHC-COMP 2025\u4e2d\u83b7\u5956\u3002", "conclusion": "Catamorphisms\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86CHC\u6c42\u89e3\u80fd\u529b\uff0c\u4e3aADT\u95ee\u9898\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2507.19988", "pdf": "https://arxiv.org/pdf/2507.19988", "abs": "https://arxiv.org/abs/2507.19988", "authors": ["Naoki Okami", "Kazuki Miyake", "Naohisa Sakamoto", "Jorji Nonaka", "Takanori Fujiwara"], "title": "Visual Analytics Using Tensor Unified Linear Comparative Analysis", "categories": ["cs.HC", "cs.GR", "cs.LG", "I.3.8; H.5.2"], "comment": "To appear in IEEE Transactions on Visualization and Computer Graphics\n  and IEEE VIS 2025", "summary": "Comparing tensors and identifying their (dis)similar structures is\nfundamental in understanding the underlying phenomena for complex data. Tensor\ndecomposition methods help analysts extract tensors' essential characteristics\nand aid in visual analytics for tensors. In contrast to dimensionality\nreduction (DR) methods designed only for analyzing a matrix (i.e., second-order\ntensor), existing tensor decomposition methods do not support flexible\ncomparative analysis. To address this analysis limitation, we introduce a new\ntensor decomposition method, named tensor unified linear comparative analysis\n(TULCA), by extending its DR counterpart, ULCA, for tensor analysis. TULCA\nintegrates discriminant analysis and contrastive learning schemes for tensor\ndecomposition, enabling flexible comparison of tensors. We also introduce an\neffective method to visualize a core tensor extracted from TULCA into a set of\n2D visualizations. We integrate TULCA's functionalities into a visual analytics\ninterface to support analysts in interpreting and refining the TULCA results.\nWe demonstrate the efficacy of TULCA and the visual analytics interface with\ncomputational evaluations and two case studies, including an analysis of log\ndata collected from a supercomputer.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5TULCA\uff0c\u652f\u6301\u7075\u6d3b\u7684\u5f20\u91cf\u6bd4\u8f83\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u53ef\u89c6\u5316\u754c\u9762\u5e2e\u52a9\u89e3\u91ca\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u65e0\u6cd5\u652f\u6301\u7075\u6d3b\u7684\u5bf9\u6bd4\u5206\u6790\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u3002", "method": "\u7ed3\u5408\u5224\u522b\u5206\u6790\u548c\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6848\uff0c\u6269\u5c55\u4e86ULCA\u65b9\u6cd5\uff0c\u63d0\u51faTULCA\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u89c6\u5316\u5de5\u5177\u3002", "result": "TULCA\u80fd\u591f\u7075\u6d3b\u6bd4\u8f83\u5f20\u91cf\uff0c\u5e76\u901a\u8fc72D\u53ef\u89c6\u5316\u5c55\u793a\u6838\u5fc3\u5f20\u91cf\u3002", "conclusion": "TULCA\u53ca\u5176\u53ef\u89c6\u5316\u754c\u9762\u5728\u8ba1\u7b97\u8bc4\u4f30\u548c\u6848\u4f8b\u7814\u7a76\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.19675", "pdf": "https://arxiv.org/pdf/2507.19675", "abs": "https://arxiv.org/abs/2507.19675", "authors": ["Micha\u0142 Hoffmann", "Micha\u0142 Bujak", "Grzegorz Jamr\u00f3z", "Rafa\u0142 Kucharski"], "title": "Wardropian Cycles make traffic assignment both optimal and fair by eliminating price-of-anarchy with Cyclical User Equilibrium for compliant connected autonomous vehicles", "categories": ["eess.SY", "cs.ET", "cs.SI", "cs.SY"], "comment": null, "summary": "Connected and Autonomous Vehicles (CAVs) open the possibility for centralised\nrouting with full compliance, making System Optimal traffic assignment\nattainable. However, as System Optimum makes some drivers better off than\nothers, voluntary acceptance seems dubious. To overcome this issue, we propose\na new concept of Wardropian cycles, which, in contrast to previous utopian\nvisions, makes the assignment fair on top of being optimal, which amounts to\nsatisfaction of both Wardrop's principles. Such cycles, represented as\nsequences of permutations to the daily assignment matrices, always exist and\nequalise, after a limited number of days, average travel times among travellers\n(like in User Equilibrium) while preserving everyday optimality of path flows\n(like in System Optimum). We propose exact methods to compute such cycles and\nreduce their length and within-cycle inconvenience to the users. As\nidentification of optimal cycles turns out to be NP-hard in many aspects, we\nintroduce a greedy heuristic efficiently approximating the optimal solution.\nFinally, we introduce and discuss a new paradigm of Cyclical User Equilibrium,\nwhich ensures stability of optimal Wardropian Cycles under unilateral\ndeviations.\n  We complement our theoretical study with large-scale simulations. In\nBarcelona, 670 vehicle-hours of Price-of-Anarchy are eliminated using cycles\nwith a median length of 11 days-though 5% of cycles exceed 90 days. However, in\nBerlin, just five days of applying the greedy assignment rule significantly\nreduces initial inequity. In Barcelona, Anaheim, and Sioux Falls, less than 7%\nof the initial inequity remains after 10 days, demonstrating the effectiveness\nof this approach in improving traffic performance with more ubiquitous social\nacceptability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aWardropian Cycles\u7684\u65b0\u6982\u5ff5\uff0c\u901a\u8fc7\u5468\u671f\u6027\u7684\u8def\u5f84\u5206\u914d\u5b9e\u73b0\u7cfb\u7edf\u6700\u4f18\u4e0e\u516c\u5e73\u6027\u7684\u5e73\u8861\uff0c\u5e76\u63d0\u51fa\u4e86\u8ba1\u7b97\u65b9\u6cd5\u548c\u8d2a\u5a6a\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002\u5b9e\u9645\u6a21\u62df\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u4e0d\u516c\u5e73\u6027\u3002", "motivation": "\u89e3\u51b3\u96c6\u4e2d\u5f0f\u8def\u7531\u4e2d\u7cfb\u7edf\u6700\u4f18\u5206\u914d\u53ef\u80fd\u5bfc\u81f4\u90e8\u5206\u9a7e\u9a76\u5458\u53d7\u76ca\u4e0d\u5747\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u793e\u4f1a\u63a5\u53d7\u5ea6\u3002", "method": "\u63d0\u51faWardropian Cycles\u6982\u5ff5\uff0c\u901a\u8fc7\u5468\u671f\u6027\u8def\u5f84\u5206\u914d\u5b9e\u73b0\u516c\u5e73\u4e0e\u6700\u4f18\uff1b\u5f00\u53d1\u7cbe\u786e\u7b97\u6cd5\u548c\u8d2a\u5a6a\u542f\u53d1\u5f0f\u4f18\u5316\u5468\u671f\u957f\u5ea6\u4e0e\u7528\u6237\u4f53\u9a8c\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5df4\u585e\u7f57\u90a3\u3001\u67cf\u6797\u7b49\u57ce\u5e02\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u4ea4\u901a\u4e0d\u516c\u5e73\u6027\uff0c\u63d0\u5347\u4e86\u4ea4\u901a\u6548\u7387\u3002", "conclusion": "\u5468\u671f\u6027\u7528\u6237\u5747\u8861\u662f\u4e00\u79cd\u6709\u6548\u4e14\u7a33\u5b9a\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u5b9e\u73b0\u4ea4\u901a\u6700\u4f18\u7684\u540c\u65f6\u63d0\u5347\u516c\u5e73\u6027\u3002"}}
{"id": "2507.19491", "pdf": "https://arxiv.org/pdf/2507.19491", "abs": "https://arxiv.org/abs/2507.19491", "authors": ["Peter Neigel", "David Antony Selby", "Shota Arai", "Benjamin Tag", "Niels van Berkel", "Sebastian Vollmer", "Andrew Vargo", "Koichi Kise"], "title": "Exploring the Alignment of Perceived and Measured Sleep Quality with Working Memory using Consumer Wearables", "categories": ["cs.HC", "cs.CY"], "comment": "18 pages, 6 figures, 7 tables", "summary": "Wearable devices offer detailed sleep-tracking data. However, whether this\ninformation enhances our understanding of sleep or simply quantifies\nalready-known patterns remains unclear. This work explores the relationship\nbetween subjective sleep self-assessments and sensor data from an Oura ring\nover 4--8 weeks in-the-wild. 29 participants rated their sleep quality daily\ncompared to the previous night and completed a working memory task. Our\nfindings reveal that differences in REM sleep, nocturnal heart rate, N-Back\nscores, and bedtimes highly predict sleep self-assessment in significance and\neffect size. For N-Back performance, REM sleep duration, prior night's REM\nsleep, and sleep self-assessment are the strongest predictors. We demonstrate\nthat self-report sensitivity towards sleep markers differs among participants.\nWe identify three groups, highlighting that sleep trackers provide more\ninformation gain for some users than others. Additionally, we make all\nexperiment data publicly available.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u53ef\u7a7f\u6234\u8bbe\u5907\uff08Oura\u6212\u6307\uff09\u7684\u4f20\u611f\u5668\u6570\u636e\u4e0e\u4e3b\u89c2\u7761\u7720\u81ea\u6211\u8bc4\u4f30\u7684\u5173\u7cfb\uff0c\u53d1\u73b0REM\u7761\u7720\u3001\u591c\u95f4\u5fc3\u7387\u548c\u5de5\u4f5c\u8bb0\u5fc6\u4efb\u52a1\u662f\u9884\u6d4b\u7761\u7720\u81ea\u8bc4\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u6307\u51fa\u4e0d\u540c\u7528\u6237\u5bf9\u7761\u7720\u8ffd\u8e2a\u6570\u636e\u7684\u654f\u611f\u5ea6\u4e0d\u540c\u3002", "motivation": "\u63a2\u8ba8\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u7761\u7720\u8ffd\u8e2a\u6570\u636e\u662f\u5426\u80fd\u771f\u6b63\u589e\u5f3a\u5bf9\u7761\u7720\u7684\u7406\u89e3\uff0c\u8fd8\u662f\u4ec5\u4ec5\u91cf\u5316\u5df2\u77e5\u6a21\u5f0f\u3002", "method": "29\u540d\u53c2\u4e0e\u8005\u57284-8\u5468\u5185\u6bcf\u5929\u4f7f\u7528Oura\u6212\u6307\u8bb0\u5f55\u7761\u7720\u6570\u636e\uff0c\u540c\u65f6\u81ea\u6211\u8bc4\u4f30\u7761\u7720\u8d28\u91cf\u5e76\u5b8c\u6210\u5de5\u4f5c\u8bb0\u5fc6\u4efb\u52a1\u3002", "result": "REM\u7761\u7720\u65f6\u957f\u3001\u591c\u95f4\u5fc3\u7387\u548c\u5de5\u4f5c\u8bb0\u5fc6\u4efb\u52a1\u5f97\u5206\u663e\u8457\u9884\u6d4b\u7761\u7720\u81ea\u8bc4\uff0c\u4e14\u4e0d\u540c\u7528\u6237\u5bf9\u7761\u7720\u6570\u636e\u7684\u654f\u611f\u5ea6\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u53ef\u7a7f\u6234\u8bbe\u5907\u5bf9\u67d0\u4e9b\u7528\u6237\u7684\u7761\u7720\u4fe1\u606f\u589e\u76ca\u66f4\u5927\uff0c\u6570\u636e\u516c\u5f00\u4ee5\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.19690", "pdf": "https://arxiv.org/pdf/2507.19690", "abs": "https://arxiv.org/abs/2507.19690", "authors": ["Jeffrey Heer", "Dominik Moritz", "Ron Pechuk"], "title": "Mosaic Selections: Managing and Optimizing User Selections for Scalable Data Visualization Systems", "categories": ["cs.HC", "cs.DB"], "comment": null, "summary": "Though powerful tools for analysis and communication, interactive\nvisualizations often fail to support real-time interaction with large datasets\nwith millions or more records. To highlight and filter data, users indicate\nvalues or intervals of interest. Such selections may span multiple components,\ncombine in complex ways, and require optimizations to ensure low-latency\nupdates. We describe Mosaic Selections, a model for representing, managing, and\noptimizing user selections, in which one or more filter predicates are added to\nqueries that request data for visualizations and input widgets. By analyzing\nboth queries and selection predicates, Mosaic Selections enable automatic\noptimizations, including pre-aggregating data to rapidly compute selection\nupdates. We contribute a formal description of our selection model and\noptimization methods, and their implementation in the open-source Mosaic\narchitecture. Benchmark results demonstrate orders-of-magnitude latency\nimprovements for selection-based optimizations over unoptimized queries and\nexisting optimizers for the Vega language. The Mosaic Selection model provides\ninfrastructure for flexible, interoperable filtering across multiple\nvisualizations, alongside automatic optimizations to scale to millions and even\nbillions of records.", "AI": {"tldr": "Mosaic Selections\u6a21\u578b\u901a\u8fc7\u4f18\u5316\u67e5\u8be2\u548c\u9009\u62e9\u8c13\u8bcd\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5b9e\u65f6\u4ea4\u4e92\u7684\u53ef\u89c6\u5316\u4f4e\u5ef6\u8fdf\u66f4\u65b0\u3002", "motivation": "\u89e3\u51b3\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff08\u767e\u4e07\u7ea7\u4ee5\u4e0a\uff09\u4e2d\u5b9e\u65f6\u4ea4\u4e92\u7684\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u63d0\u51faMosaic Selections\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790\u67e5\u8be2\u548c\u9009\u62e9\u8c13\u8bcd\uff0c\u5b9e\u73b0\u81ea\u52a8\u4f18\u5316\uff08\u5982\u9884\u805a\u5408\u6570\u636e\uff09\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\uff0c\u4f18\u4e8e\u672a\u4f18\u5316\u67e5\u8be2\u548c\u73b0\u6709Vega\u4f18\u5316\u5668\u3002", "conclusion": "Mosaic Selections\u6a21\u578b\u4e3a\u8de8\u591a\u4ea4\u4e92\u53ef\u89c6\u5316\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u4e92\u64cd\u4f5c\u4e14\u9ad8\u6548\u7684\u8fc7\u6ee4\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2507.19953", "pdf": "https://arxiv.org/pdf/2507.19953", "abs": "https://arxiv.org/abs/2507.19953", "authors": ["David Jannis Schmidt", "Grigory Fridman", "Florian von Zabiensky"], "title": "Offloading tracing for real-time systems using a scalable cloud infrastructure", "categories": ["cs.DC", "D.2.5; C.3; D.2.11"], "comment": "Submitted to ECRTS 2025 RT-Cloud Workshop proceedings", "summary": "Real-time embedded systems require precise timing and fault detection to\nensure correct behavior. Traditional tracing tools often rely on local desktops\nwith limited processing and storage capabilities, which hampers large-scale\nanalysis. This paper presents a scalable, cloud-based architecture for software\ntracing in real-time systems based on microservices and edge computing. Our\napproach shifts the trace processing workload from the developer's machine to\nthe cloud, using a dedicated tracing component that captures trace data and\nforwards it to a scalable backend via WebSockets and Apache Kafka. This enables\nlong-term monitoring and collaborative analysis of target executions, e.g., to\ndetect and investigate sporadic errors. We demonstrate how this architecture\nsupports scalable analysis of parallel tracing sessions and lays the foundation\nfor future integration of rule-based testing and runtime verification. The\nevaluation results show that the architecture can handle many parallel tracing\nsessions efficiently, although the per-session throughput decreases slightly as\nthe system load increases, while the overall throughput increases. Although the\ndesign includes a dedicated tracer for analysis during development, this\napproach is not limited to such setups. Target systems with network\nconnectivity can stream reduced trace data directly, enabling runtime\nmonitoring in the field.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fae\u670d\u52a1\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u5b9e\u65f6\u7cfb\u7edf\u8f6f\u4ef6\u8ffd\u8e2a\u4e91\u67b6\u6784\uff0c\u5c06\u8ffd\u8e2a\u5904\u7406\u4ece\u672c\u5730\u8f6c\u79fb\u81f3\u4e91\u7aef\uff0c\u652f\u6301\u957f\u671f\u76d1\u63a7\u548c\u534f\u4f5c\u5206\u6790\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u672c\u5730\u8ffd\u8e2a\u5de5\u5177\u5904\u7406\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5b9e\u65f6\u7cfb\u7edf\u7684\u7cbe\u786e\u8ffd\u8e2a\u548c\u9519\u8bef\u68c0\u6d4b\u3002", "method": "\u91c7\u7528\u5fae\u670d\u52a1\u548c\u8fb9\u7f18\u8ba1\u7b97\u67b6\u6784\uff0c\u5229\u7528WebSockets\u548cApache Kafka\u5b9e\u73b0\u8ffd\u8e2a\u6570\u636e\u7684\u6355\u83b7\u4e0e\u4f20\u8f93\u3002", "result": "\u67b6\u6784\u80fd\u9ad8\u6548\u5904\u7406\u591a\u5e76\u884c\u8ffd\u8e2a\u4f1a\u8bdd\uff0c\u6574\u4f53\u541e\u5410\u91cf\u968f\u8d1f\u8f7d\u589e\u52a0\u800c\u63d0\u5347\uff0c\u5355\u4f1a\u8bdd\u541e\u5410\u7565\u6709\u4e0b\u964d\u3002", "conclusion": "\u67b6\u6784\u4e0d\u4ec5\u9002\u7528\u4e8e\u5f00\u53d1\u73af\u5883\uff0c\u8fd8\u53ef\u6269\u5c55\u81f3\u73b0\u573a\u7f51\u7edc\u7684\u8fd0\u884c\u65f6\u76d1\u63a7\u3002"}}
{"id": "2507.19795", "pdf": "https://arxiv.org/pdf/2507.19795", "abs": "https://arxiv.org/abs/2507.19795", "authors": ["Steven Walton"], "title": "Smaller, Faster, Cheaper: Architectural Designs for Efficient Machine Learning", "categories": ["cs.CV", "cs.AR", "cs.LG"], "comment": "Ph.D. Thesis", "summary": "Major advancements in the capabilities of computer vision models have been\nprimarily fueled by rapid expansion of datasets, model parameters, and\ncomputational budgets, leading to ever-increasing demands on computational\ninfrastructure. However, as these models are deployed in increasingly diverse\nand resource-constrained environments, there is a pressing need for\narchitectures that can deliver high performance while requiring fewer\ncomputational resources.\n  This dissertation focuses on architectural principles through which models\ncan achieve increased performance while reducing their computational demands.\nWe discuss strides towards this goal through three directions. First, we focus\non data ingress and egress, investigating how information may be passed into\nand retrieved from our core neural processing units. This ensures that our\nmodels make the most of available data, allowing smaller architectures to\nbecome more performant. Second, we investigate modifications to the core neural\narchitecture, applied to restricted attention in vision transformers. This\nsection explores how removing uniform context windows in restricted attention\nincreases the expressivity of the underlying neural architecture. Third, we\nexplore the natural structures of Normalizing Flows and how we can leverage\nthese properties to better distill model knowledge.\n  These contributions demonstrate that careful design of neural architectures\ncan increase the efficiency of machine learning algorithms, allowing them to\nbecome smaller, faster, and cheaper.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8bbe\u8ba1\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u4f7f\u5176\u5728\u6027\u80fd\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4e0d\u65ad\u589e\u52a0\uff0c\u4f46\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u6a21\u578b\u65f6\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u67b6\u6784\u8bbe\u8ba1\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e09\u4e2a\u65b9\u5411\uff1a1) \u4f18\u5316\u6570\u636e\u8f93\u5165\u8f93\u51fa\uff1b2) \u6539\u8fdb\u6838\u5fc3\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7279\u522b\u662f\u89c6\u89c9\u53d8\u6362\u5668\u7684\u53d7\u9650\u6ce8\u610f\u529b\u673a\u5236\uff1b3) \u5229\u7528\u81ea\u7136\u7ed3\u6784\u4f18\u5316\u5f52\u4e00\u5316\u6d41\u7684\u77e5\u8bc6\u84b8\u998f\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u53ef\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u4f7f\u6a21\u578b\u66f4\u5c0f\u3001\u66f4\u5feb\u3001\u66f4\u7ecf\u6d4e\u3002", "conclusion": "\u901a\u8fc7\u67b6\u6784\u4f18\u5316\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u6216\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002"}}
{"id": "2507.20050", "pdf": "https://arxiv.org/pdf/2507.20050", "abs": "https://arxiv.org/abs/2507.20050", "authors": ["Rohail Asim", "Ankit Bhardwaj", "Lakshmi Suramanian", "Yasir Zaki"], "title": "Towards Next Generation Immersive Applications in 5G Environments", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "The Multi-user Immersive Reality (MIR) landscape is evolving rapidly, with\napplications spanning virtual collaboration, entertainment, and training.\nHowever, wireless network limitations create a critical bottleneck, struggling\nto meet the high-bandwidth and ultra-low latency demands essential for\nnext-generation MIR experiences. This paper presents Hera, a modular framework\nfor next-generation immersive applications, comprising a high-level streaming\nand synchronization layer for AR/VR systems and a low-level delay-based\nQoE-aware rate control protocol optimized for dynamic wireless environments.\nThe Hera framework integrates application-aware streaming logic with a\nQoE-centric rate control core, enabling adaptive video quality, multi-user\nfairness, and low-latency communication across challenging 5G network\nconditions. We demonstrate that Hera outperforms existing state-of-the-art rate\ncontrol algorithms by maintaining up to 66% lower latencies with comparable\nthroughput performance, higher visual quality with 50% average bitrate\nimprovements in our analysis, and improved fairness. By bridging the gap\nbetween application-level responsiveness and network-level adaptability, Hera\nlays the foundation for more scalable, robust, and high-fidelity multi-user\nimmersive experiences.", "AI": {"tldr": "Hera\u662f\u4e00\u79cd\u6a21\u5757\u5316\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u4e0b\u4e00\u4ee3\u591a\u7528\u6237\u6c89\u6d78\u5f0f\u4f53\u9a8c\uff08MIR\uff09\u4e2d\u7684\u65e0\u7ebf\u7f51\u7edc\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u96c6\u6210\u5e94\u7528\u611f\u77e5\u7684\u6d41\u5a92\u4f53\u903b\u8f91\u548c\u5ef6\u8fdf\u611f\u77e5\u7684\u901f\u7387\u63a7\u5236\u534f\u8bae\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u63d0\u5347\u89c6\u89c9\u8d28\u91cf\u3002", "motivation": "\u65e0\u7ebf\u7f51\u7edc\u7684\u9650\u5236\u6210\u4e3a\u4e0b\u4e00\u4ee3MIR\u4f53\u9a8c\u7684\u5173\u952e\u74f6\u9888\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u5e26\u5bbd\u548c\u8d85\u4f4e\u5ef6\u8fdf\u9700\u6c42\u65b9\u9762\u3002Hera\u65e8\u5728\u586b\u8865\u5e94\u7528\u54cd\u5e94\u6027\u548c\u7f51\u7edc\u9002\u5e94\u6027\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "method": "Hera\u6846\u67b6\u5305\u62ec\u9ad8\u5c42AR/VR\u6d41\u5a92\u4f53\u4e0e\u540c\u6b65\u5c42\u548c\u4f4e\u5c42\u5ef6\u8fdf\u9a71\u52a8\u7684QoE\u611f\u77e5\u901f\u7387\u63a7\u5236\u534f\u8bae\uff0c\u652f\u6301\u81ea\u9002\u5e94\u89c6\u9891\u8d28\u91cf\u3001\u591a\u7528\u6237\u516c\u5e73\u6027\u548c\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u3002", "result": "\u5728\u52a8\u60015G\u7f51\u7edc\u4e2d\uff0cHera\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u7b97\u6cd5\u4f4e66%\u7684\u5ef6\u8fdf\u300150%\u7684\u5e73\u5747\u6bd4\u7279\u7387\u63d0\u5347\u548c\u66f4\u9ad8\u7684\u516c\u5e73\u6027\u3002", "conclusion": "Hera\u4e3a\u66f4\u53ef\u6269\u5c55\u3001\u7a33\u5065\u548c\u9ad8\u4fdd\u771f\u7684\u591a\u7528\u6237\u6c89\u6d78\u5f0f\u4f53\u9a8c\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.19909", "pdf": "https://arxiv.org/pdf/2507.19909", "abs": "https://arxiv.org/abs/2507.19909", "authors": ["Roman Mach\u00e1\u010dek", "Anastasiia Grishina", "Max Hort", "Leon Moonen"], "title": "The Impact of Fine-tuning Large Language Models on Automated Program Repair", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted for publication in the research track of the 41th\n  International Conference on Software Maintenance and Evolution (ICSME 2025)", "summary": "Automated Program Repair (APR) uses various tools and techniques to help\ndevelopers achieve functional and error-free code faster. In recent years,\nLarge Language Models (LLMs) have gained popularity as components in APR tool\nchains because of their performance and flexibility. However, training such\nmodels requires a significant amount of resources. Fine-tuning techniques have\nbeen developed to adapt pre-trained LLMs to specific tasks, such as APR, and\nenhance their performance at far lower computational costs than training from\nscratch. In this study, we empirically investigate the impact of various\nfine-tuning techniques on the performance of LLMs used for APR. Our experiments\nprovide insights into the performance of a selection of state-of-the-art LLMs\npre-trained on code. The evaluation is done on three popular APR benchmarks\n(i.e., QuixBugs, Defects4J and HumanEval-Java) and considers six different LLMs\nwith varying parameter sizes (resp. CodeGen, CodeT5, StarCoder, DeepSeekCoder,\nBloom, and CodeLlama-2). We consider three training regimens: no fine-tuning,\nfull fine-tuning, and parameter-efficient fine-tuning (PEFT) using LoRA and\nIA3. We observe that full fine-tuning techniques decrease the benchmarking\nperformance of various models due to different data distributions and\noverfitting. By using parameter-efficient fine-tuning methods, we restrict\nmodels in the amount of trainable parameters and achieve better results.\n  Keywords: large language models, automated program repair,\nparameter-efficient fine-tuning, AI4Code, AI4SE, ML4SE.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4e0d\u540c\u5fae\u8c03\u6280\u672f\u5bf9\u7528\u4e8e\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u6bd4\u5168\u5fae\u8c03\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8bad\u7ec3\u8d44\u6e90\u6d88\u8017\u5de8\u5927\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5fae\u8c03\u6280\u672f\u63d0\u5347LLM\u5728APR\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u964d\u4f4e\u6210\u672c\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86\u516d\u79cd\u9884\u8bad\u7ec3\u7684LLM\uff08\u5982CodeGen\u3001CodeT5\u7b49\uff09\uff0c\u5728\u4e09\u4e2aAPR\u57fa\u51c6\u6d4b\u8bd5\uff08QuixBugs\u3001Defects4J\u3001HumanEval-Java\uff09\u4e0a\uff0c\u5bf9\u6bd4\u4e86\u65e0\u5fae\u8c03\u3001\u5168\u5fae\u8c03\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08LoRA\u3001IA3\uff09\u7684\u6548\u679c\u3002", "result": "\u5168\u5fae\u8c03\u6280\u672f\u56e0\u6570\u636e\u5206\u5e03\u5dee\u5f02\u548c\u8fc7\u62df\u5408\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u901a\u8fc7\u9650\u5236\u53ef\u8bad\u7ec3\u53c2\u6570\u91cf\uff0c\u83b7\u5f97\u4e86\u66f4\u597d\u7684\u7ed3\u679c\u3002", "conclusion": "\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u662f\u63d0\u5347LLM\u5728APR\u4efb\u52a1\u4e2d\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e14\u80fd\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2502.10323", "pdf": "https://arxiv.org/pdf/2502.10323", "abs": "https://arxiv.org/abs/2502.10323", "authors": ["Cipriano Junior Cioffo", "Fabio Gadducci", "Davide Trotta"], "title": "A taxonomy of categories for relations", "categories": ["math.CT", "cs.LO", "F.3; F.4"], "comment": null, "summary": "The study of categories abstracting the structural properties of relations\nhas been extensively developed over the years, resulting in a rich and diverse\nbody of work. This paper strives to provide a modern and comprehensive\npresentation of these ``categories for relations'', including their enriched\nversion, further showing how they arise as Kleisli categories of suitable\nsymmetric monoidal monads. The resulting taxonomy aims at bringing clarity and\norganisation to the numerous related concepts and frameworks occurring in the\nliterature", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u62bd\u8c61\u5173\u7cfb\u7ed3\u6784\u7279\u6027\u7684\u8303\u7574\uff0c\u5305\u62ec\u5176\u4e30\u5bcc\u7248\u672c\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u901a\u8fc7\u5bf9\u79f0\u5e7a\u534a\u7fa4\u5355\u5b50\u7684Kleisli\u8303\u7574\u5b9e\u73b0\uff0c\u65e8\u5728\u4e3a\u76f8\u5173\u6587\u732e\u4e2d\u7684\u6982\u5ff5\u548c\u6846\u67b6\u63d0\u4f9b\u6e05\u6670\u548c\u7cfb\u7edf\u7684\u5206\u7c7b\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u603b\u7ed3\u548c\u7cfb\u7edf\u5316\u591a\u5e74\u6765\u5173\u4e8e\u5173\u7cfb\u7ed3\u6784\u7279\u6027\u7684\u5e7f\u6cdb\u7814\u7a76\uff0c\u586b\u8865\u6587\u732e\u4e2d\u7684\u6982\u5ff5\u548c\u6846\u67b6\u5206\u7c7b\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5bf9\u79f0\u5e7a\u534a\u7fa4\u5355\u5b50\u7684Kleisli\u8303\u7574\uff0c\u5c55\u793a\u8fd9\u4e9b\u201c\u5173\u7cfb\u8303\u7574\u201d\u53ca\u5176\u4e30\u5bcc\u7248\u672c\u7684\u5f62\u6210\u8fc7\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6e05\u6670\u548c\u7cfb\u7edf\u7684\u5206\u7c7b\u6cd5\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u7ec4\u7ec7\u548c\u53c2\u8003\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u73b0\u4ee3\u548c\u5168\u9762\u7684\u65b9\u5f0f\uff0c\u4e3a\u5173\u7cfb\u8303\u7574\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u7814\u7a76\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u548c\u5206\u7c7b\u3002"}}
{"id": "2507.20127", "pdf": "https://arxiv.org/pdf/2507.20127", "abs": "https://arxiv.org/abs/2507.20127", "authors": ["Xuanting Xie", "Bingheng Li", "Erlin Pan", "Zhao Kang", "Wenyu Chen"], "title": "Aggregation-aware MLP: An Unsupervised Approach for Graph Message-passing", "categories": ["cs.LG", "cs.AI", "cs.GR"], "comment": "11 pages, 6 figures", "summary": "Graph Neural Networks (GNNs) have become a dominant approach to learning\ngraph representations, primarily because of their message-passing mechanisms.\nHowever, GNNs typically adopt a fixed aggregator function such as Mean, Max, or\nSum without principled reasoning behind the selection. This rigidity,\nespecially in the presence of heterophily, often leads to poor, problem\ndependent performance. Although some attempts address this by designing more\nsophisticated aggregation functions, these methods tend to rely heavily on\nlabeled data, which is often scarce in real-world tasks. In this work, we\npropose a novel unsupervised framework, \"Aggregation-aware Multilayer\nPerceptron\" (AMLP), which shifts the paradigm from directly crafting\naggregation functions to making MLP adaptive to aggregation. Our lightweight\napproach consists of two key steps: First, we utilize a graph reconstruction\nmethod that facilitates high-order grouping effects, and second, we employ a\nsingle-layer network to encode varying degrees of heterophily, thereby\nimproving the capacity and applicability of the model. Extensive experiments on\nnode clustering and classification demonstrate the superior performance of\nAMLP, highlighting its potential for diverse graph learning scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eMLP\u7684\u65b0\u578b\u65e0\u76d1\u7763\u6846\u67b6AMLP\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u805a\u5408\u673a\u5236\u89e3\u51b3GNN\u4f20\u7edf\u56fa\u5b9a\u805a\u5408\u51fd\u6570\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5f02\u6784\u56fe\u5b66\u4e60\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GNN\u7684\u56fa\u5b9a\u805a\u5408\u51fd\u6570\u5728\u5f02\u6784\u56fe\u573a\u666f\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4f9d\u8d56\u6807\u6ce8\u6570\u636e\uff0c\u9700\u6539\u8fdb\u3002", "method": "AMLP\u901a\u8fc7\u56fe\u91cd\u6784\u548c\u9ad8\u9636\u5206\u7ec4\u6548\u5e94\uff0c\u7ed3\u5408\u5355\u5c42\u7f51\u7edc\u7f16\u7801\u5f02\u8d28\u6027\uff0c\u5b9e\u73b0\u52a8\u6001\u805a\u5408\u3002", "result": "\u5728\u8282\u70b9\u805a\u7c7b\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u901a\u7528\u6027\u3002", "conclusion": "AMLP\u4e3a\u591a\u6837\u5316\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u8f7b\u91cf\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.20286", "pdf": "https://arxiv.org/pdf/2507.20286", "abs": "https://arxiv.org/abs/2507.20286", "authors": ["Liyuan Zhang", "Zeyun Cheng", "Yan Yang", "Yong Liu", "Jinke Ma"], "title": "T$^\\text{3}$SVFND: Towards an Evolving Fake News Detector for Emergencies with Test-time Training on Short Video Platforms", "categories": ["cs.CV", "cs.MM"], "comment": "16 pages, 3 figures, published to DASFAA 2025", "summary": "The existing methods for fake news videos detection may not be generalized,\nbecause there is a distribution shift between short video news of different\nevents, and the performance of such techniques greatly drops if news records\nare coming from emergencies. We propose a new fake news videos detection\nframework (T$^3$SVFND) using Test-Time Training (TTT) to alleviate this\nlimitation, enhancing the robustness of fake news videos detection.\nSpecifically, we design a self-supervised auxiliary task based on Mask Language\nModeling (MLM) that masks a certain percentage of words in text and predicts\nthese masked words by combining contextual information from different\nmodalities (audio and video). In the test-time training phase, the model adapts\nto the distribution of test data through auxiliary tasks. Extensive experiments\non the public benchmark demonstrate the effectiveness of the proposed model,\nespecially for the detection of emergency news.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d4b\u8bd5\u65f6\u95f4\u8bad\u7ec3\uff08TTT\uff09\u7684\u865a\u5047\u65b0\u95fb\u89c6\u9891\u68c0\u6d4b\u6846\u67b6\uff08T^3SVFND\uff09\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u7a81\u53d1\u4e8b\u4ef6\u65b0\u95fb\u4e0a\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u865a\u5047\u65b0\u95fb\u89c6\u9891\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u540c\u4e8b\u4ef6\u7684\u77ed\u89c6\u9891\u65b0\u95fb\u5206\u5e03\u53d1\u751f\u53d8\u5316\u65f6\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6d4b\u8bd5\u65f6\u95f4\u8bad\u7ec3\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faT^3SVFND\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8e\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\uff08MLM\uff09\u7684\u81ea\u76d1\u7763\u8f85\u52a9\u4efb\u52a1\uff0c\u7ed3\u5408\u591a\u6a21\u6001\uff08\u97f3\u9891\u548c\u89c6\u9891\uff09\u4fe1\u606f\u9884\u6d4b\u88ab\u63a9\u7801\u7684\u6587\u672c\u5185\u5bb9\uff0c\u5e76\u5728\u6d4b\u8bd5\u9636\u6bb5\u901a\u8fc7\u8f85\u52a9\u4efb\u52a1\u9002\u5e94\u6d4b\u8bd5\u6570\u636e\u7684\u5206\u5e03\u3002", "result": "\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u662f\u5bf9\u7a81\u53d1\u4e8b\u4ef6\u65b0\u95fb\u7684\u68c0\u6d4b\u6548\u679c\u663e\u8457\u3002", "conclusion": "T^3SVFND\u6846\u67b6\u901a\u8fc7\u6d4b\u8bd5\u65f6\u95f4\u8bad\u7ec3\u548c\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u865a\u5047\u65b0\u95fb\u89c6\u9891\u68c0\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u5728\u7a81\u53d1\u4e8b\u4ef6\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.19492", "pdf": "https://arxiv.org/pdf/2507.19492", "abs": "https://arxiv.org/abs/2507.19492", "authors": ["Jovana Kondic", "Pengyuan Li", "Dhiraj Joshi", "Zexue He", "Shafiq Abedin", "Jennifer Sun", "Ben Wiesel", "Eli Schwartz", "Ahmed Nassar", "Bo Wu", "Assaf Arbelle", "Aude Oliva", "Dan Gutfreund", "Leonid Karlinsky", "Rogerio Feris"], "title": "ChartGen: Scaling Chart Understanding Via Code-Guided Synthetic Chart Generation", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": null, "summary": "Chart-to-code reconstruction -- the task of recovering executable plotting\nscripts from chart images -- provides important insights into a model's ability\nto ground data visualizations in precise, machine-readable form. Yet many\nexisting multimodal benchmarks largely focus primarily on answering questions\nabout charts or summarizing them. To bridge this gap, we present ChartGen, a\nfully-automated pipeline for code-guided synthetic chart generation. Starting\nfrom seed chart images, ChartGen (i) prompts a vision-language model (VLM) to\nreconstruct each image into a python script, and (ii) iteratively augments that\nscript with a code-oriented large language model (LLM). Using ChartGen, we\ncreate 222.5K unique chart-image code pairs from 13K seed chart images, and\npresent an open-source synthetic chart dataset covering 27 chart types, 11\nplotting libraries, and multiple data modalities (image, code, text, CSV,\nDocTags). From this corpus, we curate a held-out chart-to-code evaluation\nsubset of 4.3K chart image-code pairs, and evaluate six open-weight VLMs (3B -\n26B parameters), highlighting substantial room for progress. We release the\npipeline, prompts, and the dataset to help accelerate efforts towards robust\nchart understanding and vision-conditioned code generation:\nhttps://github.com/SD122025/ChartGen/", "AI": {"tldr": "\u63d0\u51fa\u4e86ChartGen\uff0c\u4e00\u4e2a\u81ea\u52a8\u5316\u5408\u6210\u56fe\u8868\u751f\u6210\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u586b\u8865\u73b0\u6709\u591a\u6a21\u6001\u57fa\u51c6\u5728\u56fe\u8868\u4ee3\u7801\u91cd\u5efa\u4efb\u52a1\u4e0a\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u56de\u7b54\u56fe\u8868\u95ee\u9898\u6216\u603b\u7ed3\uff0c\u800c\u7f3a\u4e4f\u5bf9\u56fe\u8868\u56fe\u50cf\u7684\u4ee3\u7801\u91cd\u5efa\u4efb\u52a1\u7684\u7814\u7a76\u3002", "method": "ChartGen\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u548c\u4ee3\u7801\u5bfc\u5411\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\uff0c\u4ece\u79cd\u5b50\u56fe\u8868\u56fe\u50cf\u751f\u6210Python\u811a\u672c\u5e76\u8fed\u4ee3\u589e\u5f3a\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b27\u79cd\u56fe\u8868\u7c7b\u578b\u300111\u79cd\u7ed8\u56fe\u5e93\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u4e2aVLM\u6a21\u578b\uff0c\u663e\u793a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u53d1\u5e03\u7684\u5de5\u5177\u548c\u6570\u636e\u96c6\u65e8\u5728\u52a0\u901f\u56fe\u8868\u7406\u89e3\u548c\u89c6\u89c9\u6761\u4ef6\u4ee3\u7801\u751f\u6210\u7684\u7814\u7a76\u3002"}}
{"id": "2507.19733", "pdf": "https://arxiv.org/pdf/2507.19733", "abs": "https://arxiv.org/abs/2507.19733", "authors": ["Alec Scully", "Cameron Stockton", "Forrest Hare"], "title": "Integrating Activity Predictions in Knowledge Graphs", "categories": ["cs.AI", "cs.DB"], "comment": "7 pages. 18 figures. Semantic Technology for Intelligence, Defense,\n  and Security (STIDS 2024)", "summary": "We argue that ontology-structured knowledge graphs can play a crucial role in\ngenerating predictions about future events. By leveraging the semantic\nframework provided by Basic Formal Ontology (BFO) and Common Core Ontologies\n(CCO), we demonstrate how data such as the movements of a fishing vessel can be\norganized in and retrieved from a knowledge graph. These query results are then\nused to create Markov chain models, allowing us to predict future states based\non the vessel's history. To fully support this process, we introduce the term\n`spatiotemporal instant' to complete the necessary structural semantics.\nAdditionally, we critique the prevailing ontological model of probability,\nwhich conflates probability with likelihood and relies on the problematic\nconcept of modal measurements: measurements of future entities. We propose an\nalternative view, where probabilities are treated as being about process\nprofiles, which better captures the dynamics of real world phenomena. Finally,\nwe demonstrate how our Markov chain based probability calculations can be\nseamlessly integrated back into the knowledge graph, enabling further analysis\nand decision-making. Keywords: predictive analytics, ontology, Markov chains,\nprobability, Basic Formal Ontology (BFO), knowledge graphs, SPARQL.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u672c\u4f53\u7ed3\u6784\u77e5\u8bc6\u56fe\u8c31\u5728\u9884\u6d4b\u672a\u6765\u4e8b\u4ef6\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408BFO\u548cCCO\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6e14\u8239\u8fd0\u52a8\u6570\u636e\u5c55\u793a\u4e86\u5176\u5e94\u7528\u3002", "motivation": "\u901a\u8fc7\u672c\u4f53\u7ed3\u6784\u7684\u77e5\u8bc6\u56fe\u8c31\u63d0\u5347\u5bf9\u672a\u6765\u4e8b\u4ef6\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u6539\u8fdb\u73b0\u6709\u7684\u6982\u7387\u6a21\u578b\u3002", "method": "\u5229\u7528BFO\u548cCCO\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\uff0c\u7ed3\u5408\u9a6c\u5c14\u53ef\u592b\u94fe\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u63d0\u51fa\u201c\u65f6\u7a7a\u5b9e\u4f8b\u201d\u6982\u5ff5\u5b8c\u5584\u8bed\u4e49\u7ed3\u6784\u3002", "result": "\u5c55\u793a\u4e86\u6e14\u8239\u8fd0\u52a8\u6570\u636e\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u6982\u7387\u6a21\u578b\uff0c\u4e0e\u77e5\u8bc6\u56fe\u8c31\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "\u672c\u4f53\u7ed3\u6784\u77e5\u8bc6\u56fe\u8c31\u548c\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u7ed3\u5408\u4e3a\u9884\u6d4b\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86\u6982\u7387\u6a21\u578b\u7684\u8868\u8fbe\u3002"}}
{"id": "2507.20041", "pdf": "https://arxiv.org/pdf/2507.20041", "abs": "https://arxiv.org/abs/2507.20041", "authors": ["Daniel Manor", "Mor Perry", "Moshe Sulamy"], "title": "MTASet: A Tree-based Set for Efficient Range Queries in Update-heavy Workloads", "categories": ["cs.DC", "cs.DS"], "comment": null, "summary": "In concurrent data structures, the efficiency of set operations can vary\nsignificantly depending on the workload characteristics. Numerous concurrent\nset implementations are optimized and fine-tuned to excel in scenarios\ncharacterized by predominant read operations. However, they often perform\npoorly when confronted with workloads that heavily prioritize updates.\nAdditionally, current leading-edge concurrent sets optimized for update-heavy\ntasks typically lack efficiency in handling atomic range queries. This study\nintroduces the MTASet, which leverages a concurrent (a,b)-tree implementation.\nEngineered to accommodate update-heavy workloads and facilitate atomic range\nqueries, MTASet surpasses existing counterparts optimized for tasks in range\nquery operations by up to 2x. Notably, MTASet ensures linearizability.", "AI": {"tldr": "MTASet\u662f\u4e00\u79cd\u57fa\u4e8e\u5e76\u53d1(a,b)-\u6811\u5b9e\u73b0\u7684\u6570\u636e\u7ed3\u6784\uff0c\u65e8\u5728\u4f18\u5316\u9ad8\u66f4\u65b0\u8d1f\u8f7d\u548c\u539f\u5b50\u8303\u56f4\u67e5\u8be2\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u68482\u500d\uff0c\u540c\u65f6\u4fdd\u8bc1\u7ebf\u6027\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u5e76\u53d1\u96c6\u5728\u8bfb\u5199\u64cd\u4f5c\u4e0d\u5747\u8861\u65f6\u6027\u80fd\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u9ad8\u66f4\u65b0\u8d1f\u8f7d\u6216\u9700\u8981\u539f\u5b50\u8303\u56f4\u67e5\u8be2\u7684\u573a\u666f\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u5e76\u53d1(a,b)-\u6811\u7684\u5b9e\u73b0\uff0c\u8bbe\u8ba1MTASet\uff0c\u652f\u6301\u9ad8\u66f4\u65b0\u8d1f\u8f7d\u548c\u539f\u5b50\u8303\u56f4\u67e5\u8be2\u3002", "result": "MTASet\u5728\u8303\u56f4\u67e5\u8be2\u64cd\u4f5c\u4e2d\u6027\u80fd\u63d0\u53472\u500d\uff0c\u5e76\u786e\u4fdd\u7ebf\u6027\u4e00\u81f4\u6027\u3002", "conclusion": "MTASet\u4e3a\u9ad8\u66f4\u65b0\u8d1f\u8f7d\u548c\u539f\u5b50\u8303\u56f4\u67e5\u8be2\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u5e76\u53d1\u96c6\u5b9e\u73b0\u3002"}}
{"id": "2507.20115", "pdf": "https://arxiv.org/pdf/2507.20115", "abs": "https://arxiv.org/abs/2507.20115", "authors": ["Gongli Xi", "Ye Tian", "Yannan Hu", "Yuchao Zhang", "Yapeng Niu", "Xiangyang Gong"], "title": "Packet-Level DDoS Data Augmentation Using Dual-Stream Temporal-Field Diffusion", "categories": ["cs.NI", "cs.AI"], "comment": "11 pages, 5 figures", "summary": "In response to Distributed Denial of Service (DDoS) attacks, recent research\nefforts increasingly rely on Machine Learning (ML)-based solutions, whose\neffectiveness largely depends on the quality of labeled training datasets. To\naddress the scarcity of such datasets, data augmentation with synthetic traces\nis often employed. However, current synthetic trace generation methods struggle\nto capture the complex temporal patterns and spatial distributions exhibited in\nemerging DDoS attacks. This results in insufficient resemblance to real traces\nand unsatisfied detection accuracy when applied to ML tasks. In this paper, we\npropose Dual-Stream Temporal-Field Diffusion (DSTF-Diffusion), a multi-view,\nmulti-stream network traffic generative model based on diffusion models,\nfeaturing two main streams: The field stream utilizes spatial mapping to bridge\nnetwork data characteristics with pre-trained realms of stable diffusion\nmodels, effectively translating complex network interactions into formats that\nstable diffusion can process, while the spatial stream adopts a dynamic\ntemporal modeling approach, meticulously capturing the intrinsic temporal\npatterns of network traffic. Extensive experiments demonstrate that data\ngenerated by our model exhibits higher statistical similarity to originals\ncompared to current state-of-the-art solutions, and enhance performances on a\nwide range of downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u53cc\u6d41\u65f6\u573a\u6269\u6563\u65b9\u6cd5\uff08DSTF-Diffusion\uff09\u7528\u4e8e\u751f\u6210\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u590d\u6742\u65f6\u7a7a\u6a21\u5f0f\u4e0a\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u4e86DDoS\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3DDoS\u653b\u51fb\u68c0\u6d4b\u4e2d\u6807\u8bb0\u6570\u636e\u96c6\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u5408\u6210\u6570\u636e\u7684\u771f\u5b9e\u6027\u548c\u68c0\u6d4b\u6548\u679c\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u53cc\u6d41\u65f6\u573a\u6269\u6563\u6a21\u578b\uff0c\u5305\u542b\u573a\u6d41\u548c\u7a7a\u95f4\u6d41\uff0c\u5206\u522b\u5904\u7406\u7f51\u7edc\u6570\u636e\u7684\u7a7a\u95f4\u6620\u5c04\u548c\u52a8\u6001\u65f6\u95f4\u6a21\u5f0f\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u9ad8\u76f8\u4f3c\u5ea6\u7684\u5408\u6210\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u7684\u6570\u636e\u5728\u7edf\u8ba1\u4e0a\u4e0e\u771f\u5b9e\u6570\u636e\u66f4\u76f8\u4f3c\uff0c\u4e14\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DSTF-Diffusion\u80fd\u591f\u6709\u6548\u63d0\u5347\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\uff0c\u4ece\u800c\u589e\u5f3aDDoS\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.19942", "pdf": "https://arxiv.org/pdf/2507.19942", "abs": "https://arxiv.org/abs/2507.19942", "authors": ["Zimin Chen", "Yue Pan", "Siyu Lu", "Jiayi Xu", "Claire Le Goues", "Martin Monperrus", "He Ye"], "title": "Prometheus: Unified Knowledge Graphs for Issue Resolution in Multilingual Codebases", "categories": ["cs.SE"], "comment": null, "summary": "Language model (LM) agents, such as SWE-agent and OpenHands, have made\nprogress toward automated issue resolution. However, existing approaches are\noften limited to Python-only issues and rely on pre-constructed containers in\nSWE-bench with reproduced issues, restricting their applicability to real-world\nand work for multi-language repositories. We present Prometheus, designed to\nresolve real-world issues beyond benchmark settings. Prometheus is a\nmulti-agent system that transforms an entire code repository into a unified\nknowledge graph to guide context retrieval for issue resolution. Prometheus\nencodes files, abstract syntax trees, and natural language text into a graph of\ntyped nodes and five general edge types to support multiple programming\nlanguages. Prometheus uses Neo4j for graph persistence, enabling scalable and\nstructured reasoning over large codebases. Integrated by the DeepSeek-V3 model,\nPrometheus resolves 28.67% and 13.7% of issues on SWE-bench Lite and SWE-bench\nMultilingual, respectively, with an average API cost of $0.23 and $0.38 per\nissue. Prometheus resolves 10 unique issues not addressed by prior work and is\nthe first to demonstrate effectiveness across seven programming languages.\nMoreover, it shows the ability to resolve real-world GitHub issues in the\nLangChain and OpenHands repositories. We have open-sourced Prometheus at:\nhttps://github.com/Pantheon-temple/Prometheus", "AI": {"tldr": "Prometheus\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u4ee3\u7801\u4ed3\u5e93\u8f6c\u6362\u4e3a\u7edf\u4e00\u77e5\u8bc6\u56fe\u8c31\u6765\u89e3\u51b3\u591a\u8bed\u8a00\u4ed3\u5e93\u4e2d\u7684\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\uff08\u5982SWE-agent\u548cOpenHands\uff09\u4e3b\u8981\u5c40\u9650\u4e8ePython\u95ee\u9898\uff0c\u4e14\u4f9d\u8d56\u9884\u6784\u5efa\u7684\u5bb9\u5668\uff0c\u9002\u7528\u6027\u53d7\u9650\u3002Prometheus\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u6269\u5c55\u81f3\u591a\u8bed\u8a00\u548c\u771f\u5b9e\u573a\u666f\u3002", "method": "Prometheus\u5c06\u4ee3\u7801\u4ed3\u5e93\u8f6c\u6362\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff0c\u652f\u6301\u591a\u8bed\u8a00\uff0c\u5e76\u4f7f\u7528Neo4j\u8fdb\u884c\u6301\u4e45\u5316\u3002\u7ed3\u5408DeepSeek-V3\u6a21\u578b\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u63a8\u7406\u3002", "result": "\u5728SWE-bench Lite\u548cSWE-bench Multilingual\u4e0a\u5206\u522b\u89e3\u51b328.67%\u548c13.7%\u7684\u95ee\u9898\uff0c\u5e73\u5747API\u6210\u672c\u4e3a\u6bcf\u95ee\u9898$0.23\u548c$0.38\uff0c\u5e76\u80fd\u89e3\u51b37\u79cd\u8bed\u8a00\u7684\u72ec\u7279\u95ee\u9898\u3002", "conclusion": "Prometheus\u5728\u771f\u5b9e\u591a\u8bed\u8a00\u4ed3\u5e93\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u672a\u8986\u76d6\u7684\u95ee\u9898\uff0c\u5e76\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.19329", "pdf": "https://arxiv.org/pdf/2507.19329", "abs": "https://arxiv.org/abs/2507.19329", "authors": ["Fernando Orejas", "Elvira Pino", "Renzo Angles", "E. Pasarella", "Nikos Milonakis"], "title": "Properties for Paths in Graph Databases", "categories": ["cs.DB", "cs.LO"], "comment": null, "summary": "This paper presents a formalism for defining properties of paths in graph\ndatabases, which can be used to restrict the number of solutions to\nnavigational queries. In particular, our formalism allows us to define\nquantitative properties such as length or accumulated cost, which can be used\nas query filters. Furthermore, it enables the identification and removal of\npaths that may be considered ill-formed.\n  The new formalism is defined in terms of an operational semantics for the\nquery language that incorporates these new constructs, demonstrating its\nsoundness and completeness by proving its compatibility with a simple logical\nsemantics. We also analyze its expressive power, showing that path properties\nare more expressive than register automata. Finally, after discussing some\ncomplexity issues related to this new approach, we present an empirical\nanalysis carried out using our prototype implementation of the graph database\nthat serves as a running example throughout the paper. The results show that\nqueries using path properties as filters outperform standard queries that do\nnot use them.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5b9a\u4e49\u56fe\u6570\u636e\u5e93\u4e2d\u8def\u5f84\u5c5e\u6027\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u9650\u5236\u5bfc\u822a\u67e5\u8be2\u7684\u89e3\u6570\u91cf\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5b9a\u4e49\u8def\u5f84\u5c5e\u6027\uff08\u5982\u957f\u5ea6\u6216\u7d2f\u79ef\u6210\u672c\uff09\u6765\u6539\u8fdb\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u7684\u6548\u7387\u548c\u7cbe\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u64cd\u4f5c\u8bed\u4e49\u5b9a\u4e49\u8def\u5f84\u5c5e\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u903b\u8f91\u8bed\u4e49\u7684\u4e00\u81f4\u6027\u548c\u5b8c\u5907\u6027\u3002", "result": "\u8def\u5f84\u5c5e\u6027\u7684\u8868\u8fbe\u80fd\u529b\u4f18\u4e8e\u5bc4\u5b58\u5668\u81ea\u52a8\u673a\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4f7f\u7528\u8def\u5f84\u5c5e\u6027\u4f5c\u4e3a\u8fc7\u6ee4\u5668\u67e5\u8be2\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "\u8def\u5f84\u5c5e\u6027\u5f62\u5f0f\u5316\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.20205", "pdf": "https://arxiv.org/pdf/2507.20205", "abs": "https://arxiv.org/abs/2507.20205", "authors": ["Dengyi Zhao", "Zhiheng Zhou", "Guiying Yan", "Dongxiao Yu", "Xingqi Qi"], "title": "Signed Higher-Order Interactions for Brain Disorder Diagnosis via Multi-Channel Transformers", "categories": ["q-bio.NC", "cs.GR"], "comment": null, "summary": "Accurately characterizing higher-order interactions of brain regions and\nextracting interpretable organizational patterns from Functional Magnetic\nResonance Imaging data is crucial for brain disease diagnosis. Current\ngraph-based deep learning models primarily focus on pairwise or triadic\npatterns while neglecting signed higher-order interactions, limiting\ncomprehensive understanding of brain-wide communication. We propose HOI-Brain,\na novel computational framework leveraging signed higher-order interactions and\norganizational patterns in fMRI data for brain disease diagnosis. First, we\nintroduce a co-fluctuation measure based on Multiplication of Temporal\nDerivatives to detect higher-order interactions with temporal resolution. We\nthen distinguish positive and negative synergistic interactions, encoding them\nin signed weighted simplicial complexes to reveal brain communication insights.\nUsing Persistent Homology theory, we apply two filtration processes to these\ncomplexes to extract signed higher-dimensional neural organizations\nspatiotemporally. Finally, we propose a multi-channel brain Transformer to\nintegrate heterogeneous topological features. Experiments on Alzheimer' s\ndisease, Parkinson' s syndrome, and autism spectrum disorder datasets\ndemonstrate our framework' s superiority, effectiveness, and interpretability.\nThe identified key brain regions and higher-order patterns align with\nneuroscience literature, providing meaningful biological insights.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHOI-Brain\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u5e26\u7b26\u53f7\u7684\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u548c\u6a21\u5f0f\u4ecefMRI\u6570\u636e\u4e2d\u8bca\u65ad\u8111\u75be\u75c5\u3002\u901a\u8fc7\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u68c0\u6d4b\u548c\u6301\u7eed\u6027\u540c\u8c03\u7406\u8bba\uff0c\u7ed3\u5408\u591a\u901a\u9053Transformer\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bca\u65ad\u6548\u679c\u5e76\u63d0\u4f9b\u4e86\u751f\u7269\u5b66\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6210\u5bf9\u6216\u4e09\u5143\u6a21\u5f0f\uff0c\u5ffd\u7565\u4e86\u5e26\u7b26\u53f7\u7684\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\uff0c\u9650\u5236\u4e86\u5168\u9762\u7406\u89e3\u8111\u533a\u901a\u4fe1\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u6355\u6349\u8fd9\u4e9b\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u4ee5\u63d0\u5347\u8111\u75be\u75c5\u8bca\u65ad\u80fd\u529b\u3002", "method": "1. \u5f15\u5165\u57fa\u4e8e\u65f6\u95f4\u5bfc\u6570\u4e58\u79ef\u7684\u5171\u6ce2\u52a8\u5ea6\u91cf\u68c0\u6d4b\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\uff1b2. \u533a\u5206\u6b63\u8d1f\u534f\u540c\u4f5c\u7528\u5e76\u7528\u5e26\u7b26\u53f7\u52a0\u6743\u5355\u7eaf\u590d\u7f16\u7801\uff1b3. \u5e94\u7528\u6301\u7eed\u6027\u540c\u8c03\u7406\u8bba\u63d0\u53d6\u65f6\u7a7a\u7ec4\u7ec7\uff1b4. \u8bbe\u8ba1\u591a\u901a\u9053Transformer\u6574\u5408\u62d3\u6251\u7279\u5f81\u3002", "result": "\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u3001\u5e15\u91d1\u68ee\u7efc\u5408\u75c7\u548c\u81ea\u95ed\u75c7\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u8bca\u65ad\u6548\u679c\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8bc6\u522b\u51fa\u7684\u5173\u952e\u8111\u533a\u4e0e\u795e\u7ecf\u79d1\u5b66\u6587\u732e\u4e00\u81f4\u3002", "conclusion": "HOI-Brain\u901a\u8fc7\u5e26\u7b26\u53f7\u7684\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u548c\u62d3\u6251\u5206\u6790\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u8111\u75be\u75c5\u8bca\u65ad\u6027\u80fd\uff0c\u8fd8\u4e3a\u7406\u89e3\u8111\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u751f\u7269\u5b66\u89c1\u89e3\u3002"}}
{"id": "2507.20300", "pdf": "https://arxiv.org/pdf/2507.20300", "abs": "https://arxiv.org/abs/2507.20300", "authors": ["Xin Sun", "Lei Wang", "Yue Li", "Jie Li", "Massimo Poesio", "Julian Frommel", "Koen Hinriks", "Jiahuan Pei"], "title": "Talking-to-Build: How LLM-Assisted Interface Shapes Player Performance and Experience in Minecraft", "categories": ["cs.HC", "cs.MM"], "comment": null, "summary": "With large language models (LLMs) on the rise, in-game interactions are\nshifting from rigid commands to natural conversations. However, the impacts of\nLLMs on player performance and game experience remain underexplored. This work\nexplores LLM's role as a co-builder during gameplay, examining its impact on\ntask performance, usability, and player experience. Using Minecraft as a\nsandbox, we present an LLM-assisted interface that engages players through\nnatural language, aiming to facilitate creativity and simplify complex gaming\ncommands. We conducted a mixed-methods study with 30 participants, comparing\nLLM-assisted and command-based interfaces across simple and complex game tasks.\nQuantitative and qualitative analyses reveal that the LLM-assisted interface\nsignificantly improves player performance, engagement, and overall game\nexperience. Additionally, task complexity has a notable effect on player\nperformance and experience across both interfaces. Our findings highlight the\npotential of LLM-assisted interfaces to revolutionize virtual experiences,\nemphasizing the importance of balancing intuitiveness with predictability,\ntransparency, and user agency in AI-driven, multimodal gaming environments.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u6e38\u620f\u8f85\u52a9\u5de5\u5177\u5bf9\u73a9\u5bb6\u8868\u73b0\u548c\u4f53\u9a8c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0LLM\u8f85\u52a9\u754c\u9762\u663e\u8457\u63d0\u5347\u4e86\u73a9\u5bb6\u8868\u73b0\u548c\u6e38\u620f\u4f53\u9a8c\u3002", "motivation": "\u968f\u7740LLM\u7684\u5174\u8d77\uff0c\u6e38\u620f\u4e92\u52a8\u4ece\u56fa\u5b9a\u547d\u4ee4\u8f6c\u5411\u81ea\u7136\u5bf9\u8bdd\uff0c\u4f46LLM\u5bf9\u73a9\u5bb6\u8868\u73b0\u548c\u4f53\u9a8c\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u7814\u7a76\u5728\u300aMinecraft\u300b\u4e2d\u8bbe\u8ba1\u4e86LLM\u8f85\u52a9\u754c\u9762\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e0e\u73a9\u5bb6\u4e92\u52a8\uff0c\u5e76\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u6bd4\u8f83\u4e86LLM\u8f85\u52a9\u4e0e\u4f20\u7edf\u547d\u4ee4\u754c\u9762\u7684\u6548\u679c\u3002", "result": "LLM\u8f85\u52a9\u754c\u9762\u663e\u8457\u63d0\u9ad8\u4e86\u73a9\u5bb6\u8868\u73b0\u3001\u53c2\u4e0e\u5ea6\u548c\u6e38\u620f\u4f53\u9a8c\uff0c\u4efb\u52a1\u590d\u6742\u5ea6\u5bf9\u4e0d\u540c\u754c\u9762\u7684\u6548\u679c\u4e5f\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "LLM\u8f85\u52a9\u754c\u9762\u5728\u865a\u62df\u4f53\u9a8c\u4e2d\u5177\u6709\u9769\u547d\u6027\u6f5c\u529b\uff0c\u4f46\u9700\u5e73\u8861\u76f4\u89c2\u6027\u4e0e\u53ef\u9884\u6d4b\u6027\u3001\u900f\u660e\u5ea6\u548c\u7528\u6237\u81ea\u4e3b\u6743\u3002"}}
{"id": "2507.20066", "pdf": "https://arxiv.org/pdf/2507.20066", "abs": "https://arxiv.org/abs/2507.20066", "authors": ["Chaytan Inman"], "title": "Studying Disinformation Narratives on Social Media with LLMs and Semantic Similarity", "categories": ["cs.SI", "cs.CY", "cs.ET"], "comment": "45 pages, 8 figures, 13 tables", "summary": "This thesis develops a continuous scale measurement of similarity to\ndisinformation narratives that can serve to detect disinformation and capture\nthe nuanced, partial truths that are characteristic of it. To do so, two tools\nare developed and their methodologies are documented. The tracing tool takes\ntweets and a target narrative, rates the similarities of each to the target\nnarrative, and graphs it as a timeline. The second narrative synthesis tool\nclusters tweets above a similarity threshold and generates the dominant\nnarratives within each cluster. These tools are combined into a Tweet Narrative\nAnalysis Dashboard. The tracing tool is validated on the GLUE STS-B benchmark,\nand then the two tools are used to analyze two case studies for further\nempirical validation. The first case study uses the target narrative \"The 2020\nelection was stolen\" and analyzes a dataset of Donald Trump's tweets during\n2020. The second case study uses the target narrative, \"Transgender people are\nharmful to society\" and analyzes tens of thousands of tweets from the media\noutlets The New York Times, The Guardian, The Gateway Pundit, and Fox News.\nTogether, the empirical findings from these case studies demonstrate semantic\nsimilarity for nuanced disinformation detection, tracing, and characterization.\n  The tools developed in this thesis are hosted and can be accessed through the\npermission of the author. Please explain your use case in your request. The\nHTML friendly version of this paper is at\nhttps://chaytanc.github.io/projects/disinfo-research (Inman, 2025).", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e\u68c0\u6d4b\u865a\u5047\u4fe1\u606f\u7684\u8fde\u7eed\u5c3a\u5ea6\u6d4b\u91cf\u5de5\u5177\uff0c\u5305\u542b\u8ffd\u8e2a\u5de5\u5177\u548c\u53d9\u4e8b\u5408\u6210\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u865a\u5047\u4fe1\u606f\u4e2d\u7684\u90e8\u5206\u771f\u5b9e\u6027\u548c\u5fae\u5999\u6027\u68c0\u6d4b\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u80fd\u591f\u91cf\u5316\u76f8\u4f3c\u6027\u7684\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u4e2a\u5de5\u5177\uff1a\u8ffd\u8e2a\u5de5\u5177\u7528\u4e8e\u91cf\u5316\u63a8\u6587\u4e0e\u76ee\u6807\u53d9\u4e8b\u7684\u76f8\u4f3c\u6027\u5e76\u751f\u6210\u65f6\u95f4\u7ebf\uff1b\u53d9\u4e8b\u5408\u6210\u5de5\u5177\u7528\u4e8e\u805a\u7c7b\u9ad8\u76f8\u4f3c\u6027\u63a8\u6587\u5e76\u63d0\u53d6\u4e3b\u5bfc\u53d9\u4e8b\u3002\u4e24\u8005\u6574\u5408\u4e3a\u63a8\u6587\u53d9\u4e8b\u5206\u6790\u4eea\u8868\u76d8\u3002", "result": "\u5de5\u5177\u5728GLUE STS-B\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u9009\u4e3e\u76d7\u7a83\u548c\u8de8\u6027\u522b\u8005\u5bf9\u793e\u4f1a\u6709\u5bb3\uff09\u8fdb\u4e00\u6b65\u5b9e\u8bc1\u3002", "conclusion": "\u5de5\u5177\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u3001\u8ffd\u8e2a\u548c\u8868\u5f81\u865a\u5047\u4fe1\u606f\uff0c\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2507.19493", "pdf": "https://arxiv.org/pdf/2507.19493", "abs": "https://arxiv.org/abs/2507.19493", "authors": ["Yaowei Bai", "Ruiheng Zhang", "Yu Lei", "Jingfeng Yao", "Shuguang Ju", "Chaoyang Wang", "Wei Yao", "Yiwan Guo", "Guilin Zhang", "Chao Wan", "Qian Yuan", "Xuhua Duan", "Xinggang Wang", "Tao Sun", "Yongchao Xu", "Chuansheng Zheng", "Huangxuan Zhao", "Bo Du"], "title": "From Bench to Bedside: A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice", "categories": ["cs.HC", "eess.IV"], "comment": null, "summary": "A global shortage of radiologists has been exacerbated by the significant\nvolume of chest X-ray workloads, particularly in primary care. Although\nmultimodal large language models show promise, existing evaluations\npredominantly rely on automated metrics or retrospective analyses, lacking\nrigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray\ninterpretation system based on DeepSeek Janus-Pro model, was developed and\nrigorously validated through a multicenter prospective trial (NCT06874647). Our\nsystem outperforms state-of-the-art X-ray report generation models in automated\nreport generation, surpassing even larger-scale models including ChatGPT 4o\n(200B parameters), while demonstrating robust detection of eight clinically\ncritical radiographic findings (area under the curve, AUC > 0.8). Retrospective\nevaluation confirms significantly higher report accuracy than Janus-Pro and\nChatGPT 4o. In prospective clinical deployment, AI assistance significantly\nimproved report quality scores (4.37 vs. 4.11, P < 0.001), reduced\ninterpretation time by 18.5% (P < 0.001), and was preferred by a majority of\nexperts (3 out of 5) in 52.7% of cases. Through lightweight architecture and\ndomain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and\nworkflow efficiency, particularly in resource-constrained settings. The model\narchitecture and implementation framework will be open-sourced to facilitate\nthe clinical translation of AI-assisted radiology solutions.", "AI": {"tldr": "Janus-Pro-CXR (1B)\u662f\u57fa\u4e8eDeepSeek Janus-Pro\u6a21\u578b\u5f00\u53d1\u7684\u80f8\u7247\u89e3\u8bfb\u7cfb\u7edf\uff0c\u5728\u591a\u4e2d\u5fc3\u524d\u77bb\u6027\u8bd5\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u81ea\u52a8\u62a5\u544a\u751f\u6210\u548c\u4e34\u5e8a\u5173\u952e\u53d1\u73b0\u68c0\u6d4b\u4e0a\u8d85\u8d8a\u5305\u62ecChatGPT 4o\u5728\u5185\u7684\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u5728\u4e34\u5e8a\u90e8\u7f72\u4e2d\u663e\u8457\u63d0\u5347\u62a5\u544a\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u5168\u7403\u653e\u5c04\u79d1\u533b\u751f\u77ed\u7f3a\uff0c\u80f8\u7247\u5de5\u4f5c\u91cf\u5de8\u5927\uff0c\u73b0\u6709\u8bc4\u4f30\u7f3a\u4e4f\u524d\u77bb\u6027\u4e34\u5e8a\u9a8c\u8bc1\uff0c\u9700\u5f00\u53d1\u9ad8\u6548\u53ef\u9760\u7684AI\u8f85\u52a9\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1Janus-Pro-CXR\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u4e2d\u5fc3\u524d\u77bb\u6027\u8bd5\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\uff0c\u5e76\u4e0e\u73b0\u6709\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u7cfb\u7edf\u5728\u62a5\u544a\u751f\u6210\u548c\u4e34\u5e8a\u68c0\u6d4b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e34\u5e8a\u90e8\u7f72\u4e2d\u663e\u8457\u63d0\u5347\u62a5\u544a\u8d28\u91cf\uff084.37 vs. 4.11\uff09\u5e76\u51cf\u5c1118.5%\u89e3\u8bfb\u65f6\u95f4\uff0c\u4e13\u5bb6\u504f\u597d\u7387\u4e3a52.7%\u3002", "conclusion": "Janus-Pro-CXR\u901a\u8fc7\u8f7b\u91cf\u67b6\u6784\u548c\u9886\u57df\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u8bca\u65ad\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u9002\u5408\u8d44\u6e90\u6709\u9650\u73af\u5883\uff0c\u5e76\u5c06\u5f00\u6e90\u4ee5\u63a8\u52a8AI\u5728\u653e\u5c04\u5b66\u7684\u4e34\u5e8a\u8f6c\u5316\u3002"}}
{"id": "2507.20196", "pdf": "https://arxiv.org/pdf/2507.20196", "abs": "https://arxiv.org/abs/2507.20196", "authors": ["Dvir David Biton", "Roy Friedman", "Yaron Hay"], "title": "Ethereum Conflicts Graphed", "categories": ["cs.DC", "cs.DB"], "comment": "A slightly shorter version To appear in the Proceedings of the IEEE\n  International Conference on Blockchain and Cryptocurrency, ICBC 2025", "summary": "Ethereum, a leading blockchain platform, has revolutionized the digital\neconomy by enabling decentralized transactions and the execution of smart\ncontracts. Ethereum transactions form the backbone of its network, facilitating\npeer-to-peer exchanges and interactions with complex decentralized\napplications. Smart contracts extend Ethereum's capabilities by automating\nprocesses and enabling trustless execution of agreements. Hence, understanding\nhow these smart contracts interact is important in order to facilitate various\nperformance optimizations, such as warming objects before they are being\naccessed and enabling concurrent execution. Of particular interest to us are\nthe development of the calling graph, as well as the read sets and write sets\nof invocations within the same block, and the properties of the associated\nconflict graph that is derived from them. The latter is important for\nunderstanding the parallelization potential of smart contracts on Ethereum. We\ntraced upwards of 2 million recent Ethereum blocks using call tracer and\nprestate tracer, out of a total of 21.4 million blocks at the time of writing.\nWe report on the transactions per block distribution, the structure of call\ntrees in smart contract invocations, the ratio of value-transfer transactions\nto smart contract invocations, as well as provide a comprehensive study of the\nstructure of blocks' conflict graphs. We find that conflict graphs\npredominantly show a star like configuration, as well as other noteworthy\nstructural properties.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u7684\u8c03\u7528\u56fe\u548c\u51b2\u7a81\u56fe\u7ed3\u6784\uff0c\u63ed\u793a\u4e86\u5176\u5e76\u884c\u5316\u6f5c\u529b\u53ca\u533a\u5757\u5185\u4ea4\u6613\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4f18\u5316\u4ee5\u592a\u574a\u6027\u80fd\uff0c\u901a\u8fc7\u5206\u6790\u667a\u80fd\u5408\u7ea6\u8c03\u7528\u548c\u51b2\u7a81\u56fe\uff0c\u63a2\u7d22\u5e76\u884c\u6267\u884c\u7684\u6f5c\u529b\u3002", "method": "\u8ffd\u8e2a\u4e86\u8d85\u8fc7200\u4e07\u4e2a\u4ee5\u592a\u574a\u533a\u5757\uff0c\u4f7f\u7528\u8c03\u7528\u8ffd\u8e2a\u5668\u548c\u72b6\u6001\u9884\u8ffd\u8e2a\u5668\uff0c\u7814\u7a76\u4ea4\u6613\u5206\u5e03\u3001\u8c03\u7528\u6811\u7ed3\u6784\u548c\u51b2\u7a81\u56fe\u3002", "result": "\u53d1\u73b0\u51b2\u7a81\u56fe\u591a\u5448\u73b0\u661f\u5f62\u7ed3\u6784\uff0c\u63ed\u793a\u4e86\u667a\u80fd\u5408\u7ea6\u8c03\u7528\u7684\u5e76\u884c\u5316\u53ef\u80fd\u6027\u548c\u533a\u5757\u5185\u4ea4\u6613\u7279\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4ee5\u592a\u574a\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5c24\u5176\u5f3a\u8c03\u4e86\u5e76\u884c\u5316\u667a\u80fd\u5408\u7ea6\u6267\u884c\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.20063", "pdf": "https://arxiv.org/pdf/2507.20063", "abs": "https://arxiv.org/abs/2507.20063", "authors": ["Mufakir Qamar Ansari", "Mudabir Qamar Ansari"], "title": "Racing to Idle: Energy Efficiency of Matrix Multiplication on Heterogeneous CPU and GPU Architectures", "categories": ["cs.DC", "cs.CC", "Primary 68W10, Secondary 65Y05, 68M20", "C.4; D.1.3"], "comment": "16 pages, 6 figures, 3 listings. A comprehensive empirical study on a\n  consumer-grade heterogeneous platform", "summary": "The paradigm shift towards multi-core and heterogeneous computing, driven by\nthe fundamental power and thermal limits of single-core processors, has\nestablished energy efficiency as a first-class design constraint in\nhigh-performance computing (HPC). Heterogeneous systems, integrating\ntraditional multi-core CPUs with specialized accelerators like discrete (dGPU)\nand integrated (iGPU) graphics processing units, offer a compelling path to\nnavigating the trade-offs between performance and power. However, quantifying\nthese trade-offs on widely accessible hardware remains a critical area of\nstudy. This paper presents a direct, empirical measurement of the performance\nand energy-to-solution of a canonical HPC workload -- a 4096x4096 matrix-matrix\nmultiplication -- on three distinct compute architectures within a single\nconsumer-grade laptop: a multi-core AMD Ryzen 7 5800H CPU, a discrete NVIDIA\nGeForce GTX 1650 GPU, and an integrated AMD Radeon Vega GPU. Using standard,\nvalidated, and minimally intrusive tools such as Linux perf and nvidia-smi, we\nfind that the discrete GPU is not only the performance leader, achieving a\n93.5x speedup over the CPU, but is also the most energy-efficient, consuming\nonly 2% of the energy used by the CPU, resulting in a 50-fold improvement in\nenergy efficiency. These findings provide a practical demonstration of the\n\"race to idle\" principle and offer clear, quantitative guidance on\narchitectural choices for energy-aware software development.", "AI": {"tldr": "\u591a\u6838\u548c\u5f02\u6784\u8ba1\u7b97\u4e2d\uff0c\u79bb\u6563GPU\u5728\u6027\u80fd\u548c\u80fd\u6548\u4e0a\u663e\u8457\u4f18\u4e8eCPU\u548c\u96c6\u6210GPU\uff0c\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u8bbe\u8ba1\u53c2\u8003\u3002", "motivation": "\u968f\u7740\u5355\u6838\u5904\u7406\u5668\u7684\u529f\u7387\u548c\u70ed\u9650\u5236\uff0c\u80fd\u6548\u6210\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u7684\u9996\u8981\u8bbe\u8ba1\u7ea6\u675f\uff0c\u5f02\u6784\u7cfb\u7edf\u4e3a\u6027\u80fd\u4e0e\u529f\u8017\u7684\u6743\u8861\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u4e09\u79cd\u8ba1\u7b97\u67b6\u6784\uff08\u591a\u6838AMD CPU\u3001\u79bb\u6563NVIDIA GPU\u548c\u96c6\u6210AMD GPU\uff09\u57284096x4096\u77e9\u9635\u4e58\u6cd5\u4e0a\u7684\u6027\u80fd\u4e0e\u80fd\u8017\uff0c\u4f7f\u7528\u6807\u51c6\u5de5\u5177\uff08Linux perf\u548cnvidia-smi\uff09\u3002", "result": "\u79bb\u6563GPU\u6027\u80fd\u6700\u4f73\uff0893.5\u500d\u4e8eCPU\uff09\uff0c\u80fd\u6548\u6700\u9ad8\uff08\u4ec5\u6d88\u8017CPU\u76842%\u80fd\u91cf\uff09\uff0c\u80fd\u6548\u63d0\u534750\u500d\u3002", "conclusion": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u2018\u7ade\u901f\u95f2\u7f6e\u2019\u539f\u5219\uff0c\u4e3a\u80fd\u6548\u4f18\u5148\u7684\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cf\u5316\u6307\u5bfc\u3002"}}
{"id": "2507.20399", "pdf": "https://arxiv.org/pdf/2507.20399", "abs": "https://arxiv.org/abs/2507.20399", "authors": ["Rajat Bhattacharjya", "Arnab Sarkar", "Ish Kool", "Sabur Baidya", "Nikil Dutt"], "title": "ACCESS-AV: Adaptive Communication-Computation Codesign for Sustainable Autonomous Vehicle Localization in Smart Factories", "categories": ["eess.SY", "cs.AR", "cs.NI", "cs.RO", "cs.SY", "eess.SP"], "comment": "28 pages, 9 figures", "summary": "Autonomous Delivery Vehicles (ADVs) are increasingly used for transporting\ngoods in 5G network-enabled smart factories, with the compute-intensive\nlocalization module presenting a significant opportunity for optimization. We\npropose ACCESS-AV, an energy-efficient Vehicle-to-Infrastructure (V2I)\nlocalization framework that leverages existing 5G infrastructure in smart\nfactory environments. By opportunistically accessing the periodically broadcast\n5G Synchronization Signal Blocks (SSBs) for localization, ACCESS-AV obviates\nthe need for dedicated Roadside Units (RSUs) or additional onboard sensors to\nachieve energy efficiency as well as cost reduction. We implement an\nAngle-of-Arrival (AoA)-based estimation method using the Multiple Signal\nClassification (MUSIC) algorithm, optimized for resource-constrained ADV\nplatforms through an adaptive communication-computation strategy that\ndynamically balances energy consumption with localization accuracy based on\nenvironmental conditions such as Signal-to-Noise Ratio (SNR) and vehicle\nvelocity. Experimental results demonstrate that ACCESS-AV achieves an average\nenergy reduction of 43.09% compared to non-adaptive systems employing AoA\nalgorithms such as vanilla MUSIC, ESPRIT, and Root-MUSIC. It maintains sub-30\ncm localization accuracy while also delivering substantial reductions in\ninfrastructure and operational costs, establishing its viability for\nsustainable smart factory environments.", "AI": {"tldr": "ACCESS-AV\u662f\u4e00\u79cd\u57fa\u4e8e5G\u7f51\u7edc\u7684\u81ea\u9002\u5e94\u672c\u5730\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u73b0\u67095G\u57fa\u7840\u8bbe\u65bd\u51cf\u5c11\u80fd\u8017\u548c\u6210\u672c\uff0c\u4f18\u5316\u4e86\u667a\u80fd\u5de5\u5382\u4e2d\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5b9a\u4f4d\u95ee\u9898\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u57285G\u667a\u80fd\u5de5\u5382\u4e2d\u7684\u5b9a\u4f4d\u6a21\u5757\u8ba1\u7b97\u5bc6\u96c6\u578b\u9ad8\uff0c\u5b58\u5728\u4f18\u5316\u9700\u6c42\uff0c\u9700\u8981\u51cf\u5c11\u4e13\u7528\u8def\u8fb9\u5355\u5143\u6216\u989d\u5916\u4f20\u611f\u5668\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5468\u671f\u6027\u5e7f\u64ad\u76845G\u540c\u6b65\u4fe1\u53f7\u5757\uff08SSBs\uff09\u8fdb\u884c\u5b9a\u4f4d\uff0c\u91c7\u7528\u57fa\u4e8eMUSIC\u7b97\u6cd5\u7684\u5230\u8fbe\u89d2\uff08AoA\uff09\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u901a\u4fe1\u8ba1\u7b97\u7b56\u7565\u52a8\u6001\u5e73\u8861\u80fd\u8017\u4e0e\u7cbe\u5ea6\u3002", "result": "\u76f8\u8f83\u4e8e\u975e\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u5e73\u5747\u80fd\u8017\u964d\u4f4e43.09%\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u4fdd\u6301\u572830\u5398\u7c73\u4ee5\u4e0b\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u57fa\u7840\u8bbe\u65bd\u548c\u8fd0\u8425\u6210\u672c\u3002", "conclusion": "ACCESS-AV\u8bc1\u660e\u4e86\u5728\u53ef\u6301\u7eed\u667a\u80fd\u5de5\u5382\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u9ad8\u6548\u5229\u75285G\u57fa\u7840\u8bbe\u65bd\u5b9e\u73b0\u4e86\u80fd\u8017\u548c\u6210\u672c\u7684\u4f18\u5316\u3002"}}
{"id": "2507.20116", "pdf": "https://arxiv.org/pdf/2507.20116", "abs": "https://arxiv.org/abs/2507.20116", "authors": ["Yinuo Deng", "Hailiang Zhao", "Dongjing Wang", "Peng Chen", "Wenzhuo Qian", "Jianwei Yin", "Schahram Dustdar", "Shuiguang Deng"], "title": "Accelerating Containerized Service Delivery at the Network Edge", "categories": ["cs.NI", "cs.DC"], "comment": null, "summary": "Efficient container image distribution is crucial for enabling machine\nlearning inference at the network edge, where resource limitations and dynamic\nnetwork conditions create significant challenges. In this paper, we present\nPeerSync, a decentralized P2P-based system designed to optimize image\ndistribution in edge environments. PeerSync employs a popularity- and\nnetwork-aware download engine that dynamically adapts to content popularity and\nreal-time network conditions using a sliding window mechanism. PeerSync further\nintegrates automated tracker election for rapid peer discovery and dynamic\ncache management for efficient storage utilization. We implement PeerSync with\n8000+ lines of Rust code and test its performance extensively on both physical\nedge devices and Docker-based emulations. Experimental results show that\nPeerSync delivers a remarkable speed increase of 2.72$\\times$, 1.79$\\times$,\nand 1.28$\\times$ compared to the Baseline, Dragonfly, and Kraken, respectively,\nwhile significantly reducing peak cross-network traffic by 90.72\\% under\ncongested and varying network conditions.", "AI": {"tldr": "PeerSync\u662f\u4e00\u79cd\u57fa\u4e8eP2P\u7684\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f18\u5316\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u5bb9\u5668\u955c\u50cf\u5206\u53d1\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u548c\u51cf\u5c11\u7f51\u7edc\u6d41\u91cf\u3002", "motivation": "\u8fb9\u7f18\u73af\u5883\u4e2d\u8d44\u6e90\u53d7\u9650\u548c\u52a8\u6001\u7f51\u7edc\u6761\u4ef6\u5bf9\u9ad8\u6548\u7684\u5bb9\u5668\u955c\u50cf\u5206\u53d1\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "PeerSync\u91c7\u7528\u57fa\u4e8e\u6d41\u884c\u5ea6\u548c\u7f51\u7edc\u611f\u77e5\u7684\u4e0b\u8f7d\u5f15\u64ce\uff0c\u7ed3\u5408\u6ed1\u52a8\u7a97\u53e3\u673a\u5236\u3001\u81ea\u52a8\u8ddf\u8e2a\u9009\u4e3e\u548c\u52a8\u6001\u7f13\u5b58\u7ba1\u7406\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cPeerSync\u6bd4Baseline\u3001Dragonfly\u548cKraken\u5206\u522b\u63d0\u901f2.72\u500d\u30011.79\u500d\u548c1.28\u500d\uff0c\u5e76\u5728\u62e5\u5835\u7f51\u7edc\u4e0b\u51cf\u5c1190.72%\u7684\u8de8\u7f51\u7edc\u6d41\u91cf\u3002", "conclusion": "PeerSync\u5728\u8fb9\u7f18\u73af\u5883\u4e2d\u9ad8\u6548\u4f18\u5316\u4e86\u5bb9\u5668\u955c\u50cf\u5206\u53d1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.19951", "pdf": "https://arxiv.org/pdf/2507.19951", "abs": "https://arxiv.org/abs/2507.19951", "authors": ["Shengcheng Duan", "Yihua Xu", "Sheng Zhang", "Shen Wang", "Yue Duan"], "title": "PDLogger: Automated Logging Framework for Practical Software Development", "categories": ["cs.SE", "D.2"], "comment": "10 pages, 10 figures", "summary": "Logging is indispensable for maintaining the reliability and diagnosability\nof modern software, yet developers still struggle to decide where and how to\nlog effectively. Existing automated logging techniques focus on isolated\nsub-tasks - predicting a single log position, level, or message - and therefore\ncannot produce complete, high-quality log statements that reflect real-world\npractice in which multiple logs often appear inside one method. They also\nneglect deeper semantic dependencies among methods and consider only a narrow\nset of candidate variables, leading to superficial or incomplete logs. In this\npaper, we present PDLogger, the first end-to-end log generation technique\nexpressly designed for practical, multi-log scenarios. PDLogger operates in\nthree phases. (1) Log position prediction: block-type-aware structured prompts\nguide a large language model (LLM) to suggest candidate positions across all\ncontrol-flow blocks of a method. (2) Log generation: backward program slicing\nsupplies precise inter-procedural control and data-dependency context, while an\nexpanded variable extractor captures both member and external function\nexpressions; the enriched prompt enables the LLM to emit a full log statement\n(position, level, message, variables). (3) Log refinement: level correction and\ncontext-sensitive deduplication prune false positives and redundant logs. We\nevaluate PDLogger on 3,113 log statements drawn from two widely used Java\nprojects. Compared with the strongest prior systems, PDLogger improves\nlog-position precision by 139.0 percent, F1 by 69.2 percent, level accuracy by\n82.3 percent, variable precision by 131.8 percent, and message quality\n(BERTScore) by 65.7 percent. The framework consistently performs well with\ndifferent mainstream LLMs, demonstrating robustness and generality. PDLogger's\nimplementation is available as open source to foster future research and\nadoption.", "AI": {"tldr": "PDLogger\u662f\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u65e5\u5fd7\u751f\u6210\u6280\u672f\uff0c\u4e13\u4e3a\u5b9e\u9645\u591a\u65e5\u5fd7\u573a\u666f\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u65e5\u5fd7\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u65e5\u5fd7\u6280\u672f\u4ec5\u5173\u6ce8\u5355\u4e00\u5b50\u4efb\u52a1\uff08\u5982\u9884\u6d4b\u65e5\u5fd7\u4f4d\u7f6e\u3001\u7ea7\u522b\u6216\u6d88\u606f\uff09\uff0c\u65e0\u6cd5\u751f\u6210\u5b8c\u6574\u9ad8\u8d28\u91cf\u7684\u65e5\u5fd7\uff0c\u4e14\u5ffd\u89c6\u8bed\u4e49\u4f9d\u8d56\u548c\u53d8\u91cf\u9009\u62e9\u3002", "method": "PDLogger\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a\u65e5\u5fd7\u4f4d\u7f6e\u9884\u6d4b\uff08\u57fa\u4e8e\u5757\u7c7b\u578b\u7684\u7ed3\u6784\u5316\u63d0\u793a\uff09\u3001\u65e5\u5fd7\u751f\u6210\uff08\u7ed3\u5408\u7a0b\u5e8f\u5207\u7247\u6269\u5c55\u53d8\u91cf\u63d0\u53d6\uff09\u3001\u65e5\u5fd7\u7ec6\u5316\uff08\u7ea7\u522b\u4fee\u6b63\u548c\u53bb\u91cd\uff09\u3002", "result": "PDLogger\u5728\u65e5\u5fd7\u4f4d\u7f6e\u7cbe\u786e\u5ea6\u3001F1\u5206\u6570\u3001\u7ea7\u522b\u51c6\u786e\u5ea6\u3001\u53d8\u91cf\u7cbe\u786e\u5ea6\u548c\u6d88\u606f\u8d28\u91cf\u4e0a\u5206\u522b\u63d0\u5347139.0%\u300169.2%\u300182.3%\u3001131.8%\u548c65.7%\u3002", "conclusion": "PDLogger\u5c55\u793a\u4e86\u9c81\u68d2\u6027\u548c\u901a\u7528\u6027\uff0c\u5176\u5f00\u6e90\u5b9e\u73b0\u6709\u671b\u63a8\u52a8\u672a\u6765\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2507.20881", "pdf": "https://arxiv.org/pdf/2507.20881", "abs": "https://arxiv.org/abs/2507.20881", "authors": ["Ke Niu", "Zeyun Liu", "Xue Feng", "Heng Li", "Kaize Shi"], "title": "Endoscopic Depth Estimation Based on Deep Learning: A Survey", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Endoscopic depth estimation is a critical technology for improving the safety\nand precision of minimally invasive surgery. It has attracted considerable\nattention from researchers in medical imaging, computer vision, and robotics.\nOver the past decade, a large number of methods have been developed. Despite\nthe existence of several related surveys, a comprehensive overview focusing on\nrecent deep learning-based techniques is still limited. This paper endeavors to\nbridge this gap by systematically reviewing the state-of-the-art literature.\nSpecifically, we provide a thorough survey of the field from three key\nperspectives: data, methods, and applications, covering a range of methods\nincluding both monocular and stereo approaches. We describe common performance\nevaluation metrics and summarize publicly available datasets. Furthermore, this\nreview analyzes the specific challenges of endoscopic scenes and categorizes\nrepresentative techniques based on their supervision strategies and network\narchitectures. The application of endoscopic depth estimation in the important\narea of robot-assisted surgery is also reviewed. Finally, we outline potential\ndirections for future research, such as domain adaptation, real-time\nimplementation, and enhanced model generalization, thereby providing a valuable\nstarting point for researchers to engage with and advance the field.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u5185\u7aa5\u955c\u6df1\u5ea6\u4f30\u8ba1\u9886\u57df\u7684\u6700\u65b0\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ece\u6570\u636e\u3001\u65b9\u6cd5\u548c\u5e94\u7528\u4e09\u4e2a\u89c6\u89d2\u7cfb\u7edf\u68b3\u7406\u4e86\u73b0\u6709\u6280\u672f\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u5185\u7aa5\u955c\u6df1\u5ea6\u4f30\u8ba1\u5728\u5fae\u521b\u624b\u672f\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6280\u672f\u7684\u5168\u9762\u7efc\u8ff0\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bba\u6587\u4ece\u6570\u636e\u3001\u65b9\u6cd5\u548c\u5e94\u7528\u4e09\u4e2a\u89d2\u5ea6\u7cfb\u7edf\u56de\u987e\u4e86\u5185\u7aa5\u955c\u6df1\u5ea6\u4f30\u8ba1\u7684\u76f8\u5173\u6587\u732e\uff0c\u5305\u62ec\u5355\u76ee\u548c\u7acb\u4f53\u65b9\u6cd5\uff0c\u5e76\u5bf9\u4ee3\u8868\u6027\u6280\u672f\u8fdb\u884c\u4e86\u5206\u7c7b\u3002", "result": "\u603b\u7ed3\u4e86\u5e38\u89c1\u7684\u6027\u80fd\u8bc4\u4f30\u6307\u6807\u548c\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5206\u6790\u4e86\u5185\u7aa5\u955c\u573a\u666f\u7684\u6311\u6218\uff0c\u5e76\u63a2\u8ba8\u4e86\u8be5\u6280\u672f\u5728\u673a\u5668\u4eba\u8f85\u52a9\u624b\u672f\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u53ef\u4ee5\u5173\u6ce8\u9886\u57df\u9002\u5e94\u3001\u5b9e\u65f6\u5b9e\u73b0\u548c\u6a21\u578b\u6cdb\u5316\u7b49\u65b9\u5411\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u53d1\u5c55\u7684\u8d77\u70b9\u3002"}}
{"id": "2507.20368", "pdf": "https://arxiv.org/pdf/2507.20368", "abs": "https://arxiv.org/abs/2507.20368", "authors": ["Shuolin Xu", "Bingyuan Wang", "Zeyu Cai", "Fangteng Fu", "Yue Ma", "Tongyi Lee", "Hongchuan Yu", "Zeyu Wang"], "title": "MagicAnime: A Hierarchically Annotated, Multimodal and Multitasking Dataset with Benchmarks for Cartoon Animation Generation", "categories": ["cs.CV", "cs.MM"], "comment": "8 pages,6 figures", "summary": "Generating high-quality cartoon animations multimodal control is challenging\ndue to the complexity of non-human characters, stylistically diverse motions\nand fine-grained emotions. There is a huge domain gap between real-world videos\nand cartoon animation, as cartoon animation is usually abstract and has\nexaggerated motion. Meanwhile, public multimodal cartoon data are extremely\nscarce due to the difficulty of large-scale automatic annotation processes\ncompared with real-life scenarios. To bridge this gap, We propose the\nMagicAnime dataset, a large-scale, hierarchically annotated, and multimodal\ndataset designed to support multiple video generation tasks, along with the\nbenchmarks it includes. Containing 400k video clips for image-to-video\ngeneration, 50k pairs of video clips and keypoints for whole-body annotation,\n12k pairs of video clips for video-to-video face animation, and 2.9k pairs of\nvideo and audio clips for audio-driven face animation. Meanwhile, we also build\na set of multi-modal cartoon animation benchmarks, called MagicAnime-Bench, to\nsupport the comparisons of different methods in the tasks above. Comprehensive\nexperiments on four tasks, including video-driven face animation, audio-driven\nface animation, image-to-video animation, and pose-driven character animation,\nvalidate its effectiveness in supporting high-fidelity, fine-grained, and\ncontrollable generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MagicAnime\u6570\u636e\u96c6\u53ca\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u652f\u6301\u9ad8\u8d28\u91cf\u5361\u901a\u52a8\u753b\u7684\u591a\u6a21\u6001\u63a7\u5236\u751f\u6210\uff0c\u586b\u8865\u4e86\u9886\u57df\u7a7a\u767d\u3002", "motivation": "\u5361\u901a\u52a8\u753b\u751f\u6210\u9762\u4e34\u590d\u6742\u975e\u4eba\u7c7b\u89d2\u8272\u3001\u591a\u6837\u52a8\u4f5c\u548c\u7cbe\u7ec6\u60c5\u611f\u7684\u6311\u6218\uff0c\u4e14\u7f3a\u4e4f\u516c\u5f00\u591a\u6a21\u6001\u6570\u636e\u3002MagicAnime\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b40\u4e07\u89c6\u9891\u7247\u6bb5\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6MagicAnime\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u51c6\u6d4b\u8bd5MagicAnime-Bench\uff0c\u652f\u6301\u591a\u79cd\u751f\u6210\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u57284\u4e2a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u9ad8\u4fdd\u771f\u3001\u7cbe\u7ec6\u548c\u53ef\u63a7\u7684\u52a8\u753b\u751f\u6210\u3002", "conclusion": "MagicAnime\u586b\u8865\u4e86\u5361\u901a\u52a8\u753b\u591a\u6a21\u6001\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u4e3a\u9ad8\u8d28\u91cf\u52a8\u753b\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2507.20234", "pdf": "https://arxiv.org/pdf/2507.20234", "abs": "https://arxiv.org/abs/2507.20234", "authors": ["Burak Arda Okutan", "Stefan Schmid", "Yvonne-Anne Pignolet"], "title": "Democracy for DAOs: An Empirical Study of Decentralized Governance and Dynamic (Case Study Internet Computer SNS Ecosystem)", "categories": ["cs.NI", "cs.ET", "cs.SI", "C.2.4"], "comment": "This paper is an extended version of the work presented at the IEEE\n  International Conference on Blockchain and Cryptocurrency (ICBC) 2025", "summary": "Decentralized autonomous organizations (DAOs) rely on governance mechanism\nwithout centralized leadership. This paper presents an empirical study of user\nbehavior in governance for a variety of DAOs, ranging from DeFi to gaming,\nusing the Internet Computer Protocol DAO framework called SNS (Service Nervous\nSystem). To analyse user engagement, we measure participation rates and\nfrequency of proposals submission and voter approval rates. We evaluate\ndecision duration times to determine DAO agility. To investigate dynamic\naspects, we also measure metric shifts in time. We evaluate over 3,000\nproposals submitted in a time frame of 20 months from 14 SNS DAOs. The selected\nDAO have been existing between 6 and 20 months and cover a wide spectrum of use\ncases, treasury sizes, and number of participants. We also compare our results\nfor SNS DAOs with DAOs from other blockchain platforms. While approval rates\nare generally high for all DAOs studied, SNS DAOs show slightly more alignment.\nWe observe that the SNS governance mechanisms and processes in ICP lead to\nhigher activity, lower costs and faster decisions. Most importantly, in\ncontrast to studies which report a decline in participation over time for other\nframeworks, SNS DAOs exhibit sustained or increasing engagement levels over\ntime.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u63a2\u8ba8\u4e86\u53bb\u4e2d\u5fc3\u5316\u81ea\u6cbb\u7ec4\u7ec7\uff08DAO\uff09\u4e2d\u7528\u6237\u53c2\u4e0e\u6cbb\u7406\u7684\u884c\u4e3a\uff0c\u91cd\u70b9\u662f\u4f7f\u7528\u4e92\u8054\u7f51\u8ba1\u7b97\u673a\u534f\u8bae\uff08ICP\uff09\u7684SNS\u6846\u67b6\u7684DAO\u3002\u7814\u7a76\u53d1\u73b0\uff0cSNS DAO\u5728\u6d3b\u52a8\u6c34\u5e73\u3001\u51b3\u7b56\u901f\u5ea6\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u7528\u6237\u53c2\u4e0e\u5ea6\u968f\u65f6\u95f4\u6301\u7eed\u589e\u957f\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u4e86\u89e3\u4e0d\u540cDAO\u6846\u67b6\u4e0b\u7528\u6237\u6cbb\u7406\u884c\u4e3a\u7684\u5dee\u5f02\uff0c\u7279\u522b\u662fSNS DAO\u7684\u72ec\u7279\u8868\u73b0\u53ca\u5176\u5bf9\u53bb\u4e2d\u5fc3\u5316\u6cbb\u7406\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u91cf\u5316\u5206\u67903,000\u591a\u4e2a\u63d0\u6848\uff0c\u6db5\u76d614\u4e2aSNS DAO\uff0c\u65f6\u95f4\u6bb5\u4e3a20\u4e2a\u6708\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u53c2\u4e0e\u7387\u3001\u63d0\u6848\u63d0\u4ea4\u9891\u7387\u3001\u6295\u7968\u901a\u8fc7\u7387\u548c\u51b3\u7b56\u65f6\u95f4\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cSNS DAO\u7684\u6295\u7968\u901a\u8fc7\u7387\u8f83\u9ad8\uff0c\u51b3\u7b56\u66f4\u5feb\uff0c\u6210\u672c\u66f4\u4f4e\uff0c\u4e14\u7528\u6237\u53c2\u4e0e\u5ea6\u672a\u968f\u65f6\u95f4\u4e0b\u964d\uff0c\u53cd\u800c\u6301\u7eed\u589e\u957f\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660eSNS\u6846\u67b6\u5728\u63d0\u5347DAO\u6cbb\u7406\u6548\u7387\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u6cbb\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.19494", "pdf": "https://arxiv.org/pdf/2507.19494", "abs": "https://arxiv.org/abs/2507.19494", "authors": ["Longfei Chen", "Christopher Lochhead", "Robert B. Fisher", "Nusa Faric", "Jacques Fleuriot", "Subramanian Ramamoorthy"], "title": "Evaluating Personalized Beneficial Interventions in the Daily Lives of Older Adults Using a Camera", "categories": ["cs.HC"], "comment": "AIiH 2025, International Conference on AI in Healthcare", "summary": "Beneficial daily activity interventions have been shown to improve both the\nphysical and mental health of older adults. However, there is a lack of robust\nobjective metrics and personalized strategies to measure their impact. In this\nstudy, two older adults aged over 65, living in Edinburgh, UK, selected their\npreferred daily interventions (mindful meals and art crafts), which are then\nassessed for effectiveness. The total monitoring period across both\nparticipants was 8 weeks. Their physical behaviours were continuously monitored\nusing a non-contact, privacy-preserving camera-based system. Postural and\nmobility statistics were extracted using computer vision algorithms and\ncompared across periods with and without the interventions. The results\ndemonstrate significant behavioural changes for both participants, highlighting\nthe effectiveness of both these activities and the monitoring system.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u975e\u63a5\u89e6\u5f0f\u6444\u50cf\u5934\u7cfb\u7edf\u76d1\u6d4b\u4e24\u4f4d\u8001\u5e74\u4eba\u7684\u65e5\u5e38\u6d3b\u52a8\u5e72\u9884\u6548\u679c\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8001\u5e74\u4eba\u65e5\u5e38\u6d3b\u52a8\u5e72\u9884\u5bf9\u8eab\u5fc3\u5065\u5eb7\u6709\u76ca\uff0c\u4f46\u7f3a\u4e4f\u5ba2\u89c2\u6307\u6807\u548c\u4e2a\u6027\u5316\u7b56\u7565\u3002", "method": "\u9009\u53d6\u4e24\u4f4d65\u5c81\u4ee5\u4e0a\u8001\u5e74\u4eba\u8fdb\u884c8\u5468\u76d1\u6d4b\uff0c\u4f7f\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7b97\u6cd5\u5206\u6790\u884c\u4e3a\u6570\u636e\u3002", "result": "\u5e72\u9884\u6d3b\u52a8\u663e\u8457\u6539\u53d8\u4e86\u8001\u5e74\u4eba\u7684\u884c\u4e3a\uff0c\u8bc1\u660e\u4e86\u6d3b\u52a8\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u5e72\u9884\u6d3b\u52a8\u548c\u76d1\u6d4b\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.20173", "pdf": "https://arxiv.org/pdf/2507.20173", "abs": "https://arxiv.org/abs/2507.20173", "authors": ["Haitian Wang", "Long Qin"], "title": "High-Performance Parallel Optimization of the Fish School Behaviour on the Setonix Platform Using OpenMP", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "This paper presents an in-depth investigation into the high-performance\nparallel optimization of the Fish School Behaviour (FSB) algorithm on the\nSetonix supercomputing platform using the OpenMP framework. Given the\nincreasing demand for enhanced computational capabilities for complex,\nlarge-scale calculations across diverse domains, there's an imperative need for\noptimized parallel algorithms and computing structures. The FSB algorithm,\ninspired by nature's social behavior patterns, provides an ideal platform for\nparallelization due to its iterative and computationally intensive nature. This\nstudy leverages the capabilities of the Setonix platform and the OpenMP\nframework to analyze various aspects of multi-threading, such as thread counts,\nscheduling strategies, and OpenMP constructs, aiming to discern patterns and\nstrategies that can elevate program performance. Experiments were designed to\nrigorously test different configurations, and our results not only offer\ninsights for parallel optimization of FSB on Setonix but also provide valuable\nreferences for other parallel computational research using OpenMP. Looking\nforward, other factors, such as cache behavior and thread scheduling strategies\nat micro and macro levels, hold potential for further exploration and\noptimization.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76Fish School Behaviour\u7b97\u6cd5\u5728Setonix\u8d85\u7ea7\u8ba1\u7b97\u5e73\u53f0\u4e0a\u901a\u8fc7OpenMP\u8fdb\u884c\u9ad8\u6027\u80fd\u5e76\u884c\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u591a\u7ebf\u7a0b\u914d\u7f6e\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7b56\u7565\u3002", "motivation": "\u968f\u7740\u590d\u6742\u5927\u89c4\u6a21\u8ba1\u7b97\u9700\u6c42\u7684\u589e\u52a0\uff0c\u4f18\u5316\u5e76\u884c\u7b97\u6cd5\u548c\u8ba1\u7b97\u7ed3\u6784\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002Fish School Behaviour\u7b97\u6cd5\u7684\u8fed\u4ee3\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\u7279\u6027\u4f7f\u5176\u6210\u4e3a\u5e76\u884c\u5316\u7684\u7406\u60f3\u9009\u62e9\u3002", "method": "\u5229\u7528Setonix\u5e73\u53f0\u548cOpenMP\u6846\u67b6\uff0c\u7814\u7a76\u591a\u7ebf\u7a0b\u914d\u7f6e\uff08\u5982\u7ebf\u7a0b\u6570\u91cf\u3001\u8c03\u5ea6\u7b56\u7565\u548cOpenMP\u7ed3\u6784\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u8bd5\u4e0d\u540c\u914d\u7f6e\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u4e0d\u4ec5\u4e3aFSB\u7b97\u6cd5\u5728Setonix\u4e0a\u7684\u5e76\u884c\u4f18\u5316\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u8fd8\u4e3a\u5176\u4ed6\u4f7f\u7528OpenMP\u7684\u5e76\u884c\u8ba1\u7b97\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u672a\u6765\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u7f13\u5b58\u884c\u4e3a\u548c\u7ebf\u7a0b\u8c03\u5ea6\u7b56\u7565\u7b49\u5fae\u89c2\u548c\u5b8f\u89c2\u56e0\u7d20\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u4f18\u5316\u6f5c\u529b\u3002"}}
{"id": "2507.20081", "pdf": "https://arxiv.org/pdf/2507.20081", "abs": "https://arxiv.org/abs/2507.20081", "authors": ["Matheus Barbosa", "Paulo Borba", "Rodrigo Bonif\u00e1cio", "Victor Lira", "Galileu Santos"], "title": "The Effect of Pointer Analysis on Semantic Conflict Detection", "categories": ["cs.SE"], "comment": null, "summary": "Current merge tools don't detect semantic conflicts, which occur when changes\nfrom different developers are textually integrated but semantically interfere\nwith each other. Although researchers have proposed static analyses for\ndetecting semantic conflicts, these analyses suffer from significant false\npositive rates. To understand whether such false positives could be reduced by\nusing pointer analysis in the implementation of semantic conflict static\nanalyses, we conduct an empirical study. We implement the same analysis with\nand without pointer analysis, run them on two datasets, observe how often they\ndiffer, and compare their accuracy and computational performance. Although\npointer analysis is known to improve precision in static analysis, we find that\nits effect on semantic conflict detection can be drastic: we observe a\nsignificant reduction in timeouts and false positives, but also a significant\nincrease in false negatives, with prohibitive drops in recall and F1-score.\nThese results suggest that, in the context of semantic conflict detection, we\nshould explore hybrid analysis techniques, combining aspects of both\nimplementations we compare in our study.", "AI": {"tldr": "\u5f53\u524d\u5408\u5e76\u5de5\u5177\u65e0\u6cd5\u68c0\u6d4b\u8bed\u4e49\u51b2\u7a81\uff0c\u7814\u7a76\u63a2\u8ba8\u9759\u6001\u5206\u6790\u4e2d\u6307\u9488\u5206\u6790\u5bf9\u51cf\u5c11\u8bef\u62a5\u7684\u6548\u679c\uff0c\u53d1\u73b0\u6307\u9488\u5206\u6790\u867d\u964d\u4f4e\u8bef\u62a5\u4f46\u589e\u52a0\u6f0f\u62a5\uff0c\u9700\u63a2\u7d22\u6df7\u5408\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5408\u5e76\u5de5\u5177\u65e0\u6cd5\u8bc6\u522b\u8bed\u4e49\u51b2\u7a81\uff0c\u9759\u6001\u5206\u6790\u8bef\u62a5\u7387\u9ad8\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6307\u9488\u5206\u6790\u6539\u5584\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5b9e\u73b0\u5e26\u4e0e\u4e0d\u5e26\u6307\u9488\u5206\u6790\u7684\u4e24\u79cd\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u6bd4\u8f83\u5b83\u4eec\u5728\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6027\u80fd\u53ca\u5dee\u5f02\u8868\u73b0\u3002", "result": "\u6307\u9488\u5206\u6790\u5927\u5e45\u51cf\u5c11\u8bef\u62a5\u548c\u8d85\u65f6\uff0c\u4f46\u663e\u8457\u589e\u52a0\u6f0f\u62a5\uff0c\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0b\u964d\u4e25\u91cd\u3002", "conclusion": "\u8bed\u4e49\u51b2\u7a81\u68c0\u6d4b\u9700\u63a2\u7d22\u7ed3\u5408\u6307\u9488\u5206\u6790\u4e0e\u65e0\u6307\u9488\u5206\u6790\u7684\u6df7\u5408\u6280\u672f\u3002"}}
{"id": "2507.20010", "pdf": "https://arxiv.org/pdf/2507.20010", "abs": "https://arxiv.org/abs/2507.20010", "authors": ["M\u00fcge Fidan", "Esra Erdem"], "title": "Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems", "categories": ["cs.AI", "cs.GT", "cs.LO"], "comment": null, "summary": "The Stable Roommates problems are characterized by the preferences of agents\nover other agents as roommates. A solution is a partition of the agents into\npairs that are acceptable to each other (i.e., they are in the preference lists\nof each other), and the matching is stable (i.e., there do not exist any two\nagents who prefer each other to their roommates, and thus block the matching).\nMotivated by real-world applications, and considering that stable roommates\nproblems do not always have solutions, we continue our studies to compute\n\"good-enough\" matchings. In addition to the agents' habits and habitual\npreferences, we consider their networks of preferred friends, and introduce a\nmethod to generate personalized solutions to stable roommates problems. We\nillustrate the usefulness of our method with examples and empirical\nevaluations.", "AI": {"tldr": "\u7814\u7a76\u4e86\u7a33\u5b9a\u5ba4\u53cb\u95ee\u9898\u4e2d\u65e0\u89e3\u65f6\u7684\u2018\u8db3\u591f\u597d\u2019\u5339\u914d\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e60\u60ef\u548c\u793e\u4ea4\u7f51\u7edc\u751f\u6210\u4e2a\u6027\u5316\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u7a33\u5b9a\u5ba4\u53cb\u95ee\u9898\u53ef\u80fd\u65e0\u89e3\uff0c\u9700\u627e\u2018\u8db3\u591f\u597d\u2019\u7684\u5339\u914d\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u4ee3\u7406\u7684\u4e60\u60ef\u3001\u504f\u597d\u53ca\u670b\u53cb\u7f51\u7edc\uff0c\u63d0\u51fa\u4e2a\u6027\u5316\u89e3\u51b3\u65b9\u6848\u751f\u6210\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5b9e\u4f8b\u548c\u5b9e\u8bc1\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u751f\u6210\u4e2a\u6027\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u7a33\u5b9a\u5ba4\u53cb\u95ee\u9898\u65e0\u89e3\u7684\u60c5\u51b5\u3002"}}
{"id": "2507.20518", "pdf": "https://arxiv.org/pdf/2507.20518", "abs": "https://arxiv.org/abs/2507.20518", "authors": ["Yili Li", "Gang Xiong", "Gaopeng Gou", "Xiangyan Qu", "Jiamin Zhuang", "Zhen Li", "Junzheng Shi"], "title": "T2VParser: Adaptive Decomposition Tokens for Partial Alignment in Text to Video Retrieval", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Text-to-video retrieval essentially aims to train models to align visual\ncontent with textual descriptions accurately. Due to the impressive general\nmultimodal knowledge demonstrated by image-text pretrained models such as CLIP,\nexisting work has primarily focused on extending CLIP knowledge for video-text\ntasks. However, videos typically contain richer information than images. In\ncurrent video-text datasets, textual descriptions can only reflect a portion of\nthe video content, leading to partial misalignment in video-text matching.\nTherefore, directly aligning text representations with video representations\ncan result in incorrect supervision, ignoring the inequivalence of information.\nIn this work, we propose T2VParser to extract multiview semantic\nrepresentations from text and video, achieving adaptive semantic alignment\nrather than aligning the entire representation. To extract corresponding\nrepresentations from different modalities, we introduce Adaptive Decomposition\nTokens, which consist of a set of learnable tokens shared across modalities.\nThe goal of T2VParser is to emphasize precise alignment between text and video\nwhile retaining the knowledge of pretrained models. Experimental results\ndemonstrate that T2VParser achieves accurate partial alignment through\neffective cross-modal content decomposition. The code is available at\nhttps://github.com/Lilidamowang/T2VParser.", "AI": {"tldr": "T2VParser\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u89c6\u89d2\u8bed\u4e49\u8868\u793a\u65b9\u6cd5\uff0c\u89e3\u51b3\u89c6\u9891\u4e0e\u6587\u672c\u90e8\u5206\u4e0d\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8bed\u4e49\u5bf9\u9f50\u63d0\u5347\u68c0\u7d22\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u89c6\u9891-\u6587\u672c\u6570\u636e\u96c6\u4e2d\u7684\u6587\u672c\u63cf\u8ff0\u4ec5\u80fd\u53cd\u6620\u89c6\u9891\u90e8\u5206\u5185\u5bb9\uff0c\u5bfc\u81f4\u89c6\u9891-\u6587\u672c\u5339\u914d\u4e2d\u90e8\u5206\u4e0d\u5bf9\u9f50\uff0c\u76f4\u63a5\u5bf9\u9f50\u4f1a\u5bfc\u81f4\u9519\u8bef\u76d1\u7763\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u5206\u89e3\u4ee4\u724c\uff0c\u63d0\u53d6\u591a\u89c6\u89d2\u8bed\u4e49\u8868\u793a\uff0c\u5b9e\u73b0\u6a21\u6001\u95f4\u81ea\u9002\u5e94\u5bf9\u9f50\uff0c\u4fdd\u7559\u9884\u8bad\u7ec3\u6a21\u578b\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eT2VParser\u901a\u8fc7\u6709\u6548\u8de8\u6a21\u6001\u5185\u5bb9\u5206\u89e3\uff0c\u5b9e\u73b0\u4e86\u90e8\u5206\u5185\u5bb9\u7684\u7cbe\u786e\u5bf9\u9f50\u3002", "conclusion": "T2VParser\u901a\u8fc7\u591a\u89c6\u89d2\u8bed\u4e49\u8868\u793a\u548c\u81ea\u9002\u5e94\u5bf9\u9f50\uff0c\u63d0\u5347\u4e86\u89c6\u9891-\u6587\u672c\u68c0\u7d22\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.20699", "pdf": "https://arxiv.org/pdf/2507.20699", "abs": "https://arxiv.org/abs/2507.20699", "authors": ["Joan Mart\u00ednez Canals", "Francesco Devoti", "Vincenzo Sciancalepore", "Marco Di Renzo", "Xavier Costa-P\u00e9rez"], "title": "Curved Apertures for Customized Wave Trajectories: Beyond Flat Aperture Limitations", "categories": ["physics.optics", "cs.ET", "cs.NI"], "comment": null, "summary": "Beam shaping techniques enable tailored beam trajectories, offering\nunprecedented connectivity opportunities in wireless communications. Current\napproaches rely on flat apertures, which limit trajectory flexibility due to\ninherent geometric constraints. To overcome such restrictions, we propose\nadopting curved apertures as a more versatile alternative for beam shaping. We\nintroduce a novel formulation for wave trajectory engineering compatible with\narbitrarily shaped apertures. Theoretical and numerical analyses demonstrate\nthat curved apertures offer improved control over wave propagation, are more\nresilient to phase control constraints, and achieve higher power density across\na wider portion of the desired beam trajectory than flat apertures.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u91c7\u7528\u66f2\u9762\u5b54\u5f84\u63d0\u5347\u6ce2\u675f\u6210\u5f62\u6280\u672f\u7684\u7075\u6d3b\u6027\u4e0e\u6548\u679c\u3002", "motivation": "\u514b\u670d\u5e73\u9762\u5b54\u5f84\u5728\u6ce2\u675f\u8f68\u8ff9\u8bbe\u8ba1\u4e2d\u7684\u51e0\u4f55\u9650\u5236\uff0c\u63d0\u5347\u65e0\u7ebf\u901a\u4fe1\u7684\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u4efb\u610f\u5f62\u72b6\u5b54\u5f84\u7684\u6ce2\u675f\u8f68\u8ff9\u5de5\u7a0b\u65b0\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e0e\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u66f2\u9762\u5b54\u5f84\u5728\u6ce2\u675f\u4f20\u64ad\u63a7\u5236\u3001\u76f8\u4f4d\u7ea6\u675f\u9c81\u68d2\u6027\u53ca\u529f\u7387\u5bc6\u5ea6\u5206\u5e03\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u66f2\u9762\u5b54\u5f84\u4e3a\u6ce2\u675f\u6210\u5f62\u63d0\u4f9b\u4e86\u66f4\u5177\u7075\u6d3b\u6027\u548c\u9ad8\u6548\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19495", "pdf": "https://arxiv.org/pdf/2507.19495", "abs": "https://arxiv.org/abs/2507.19495", "authors": ["Qing Dong", "Pengyuan Liu", "Dong Yu", "Chen Kang"], "title": "Simulating Human Behavior with the Psychological-mechanism Agent: Integrating Feeling, Thought, and Action", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Generative agents have made significant progress in simulating human\nbehavior, but existing frameworks often simplify emotional modeling and focus\nprimarily on specific tasks, limiting the authenticity of the simulation. Our\nwork proposes the Psychological-mechanism Agent (PSYA) framework, based on the\nCognitive Triangle (Feeling-Thought-Action), designed to more accurately\nsimulate human behavior. The PSYA consists of three core modules: the Feeling\nmodule (using a layer model of affect to simulate changes in short-term,\nmedium-term, and long-term emotions), the Thought module (based on the Triple\nNetwork Model to support goal-directed and spontaneous thinking), and the\nAction module (optimizing agent behavior through the integration of emotions,\nneeds and plans). To evaluate the framework's effectiveness, we conducted daily\nlife simulations and extended the evaluation metrics to self-influence,\none-influence, and group-influence, selection five classic psychological\nexperiments for simulation. The results show that the PSYA framework generates\nmore natural, consistent, diverse, and credible behaviors, successfully\nreplicating human experimental outcomes. Our work provides a richer and more\naccurate emotional and cognitive modeling approach for generative agents and\noffers an alternative to human participants in psychological experiments.", "AI": {"tldr": "PSYA\u6846\u67b6\u901a\u8fc7\u60c5\u611f-\u601d\u7ef4-\u884c\u52a8\u7684\u8ba4\u77e5\u4e09\u89d2\u6a21\u578b\uff0c\u63d0\u5347\u751f\u6210\u4ee3\u7406\u5bf9\u4eba\u7c7b\u884c\u4e3a\u7684\u6a21\u62df\u771f\u5b9e\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u4ee3\u7406\u5728\u60c5\u611f\u5efa\u6a21\u4e0a\u8fc7\u4e8e\u7b80\u5316\u4e14\u4e13\u6ce8\u4e8e\u7279\u5b9a\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u6a21\u62df\u7684\u771f\u5b9e\u6027\u3002", "method": "PSYA\u5305\u542b\u60c5\u611f\u6a21\u5757\uff08\u5206\u5c42\u6a21\u578b\uff09\u3001\u601d\u7ef4\u6a21\u5757\uff08\u4e09\u7f51\u7edc\u6a21\u578b\uff09\u548c\u884c\u52a8\u6a21\u5757\uff08\u6574\u5408\u60c5\u611f\u3001\u9700\u6c42\u548c\u8ba1\u5212\uff09\u3002", "result": "PSYA\u80fd\u751f\u6210\u66f4\u81ea\u7136\u3001\u4e00\u81f4\u3001\u591a\u6837\u4e14\u53ef\u4fe1\u7684\u884c\u4e3a\uff0c\u6210\u529f\u590d\u73b0\u4eba\u7c7b\u5fc3\u7406\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "PSYA\u4e3a\u751f\u6210\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u51c6\u786e\u7684\u60c5\u611f\u548c\u8ba4\u77e5\u5efa\u6a21\u65b9\u6cd5\uff0c\u53ef\u66ff\u4ee3\u4eba\u7c7b\u53c2\u4e0e\u8005\u8fdb\u884c\u5fc3\u7406\u5b9e\u9a8c\u3002"}}
{"id": "2507.20362", "pdf": "https://arxiv.org/pdf/2507.20362", "abs": "https://arxiv.org/abs/2507.20362", "authors": ["Hengyu Liu", "Tianyi Li", "Yuqiang He", "Kristian Torp", "Yushuai Li", "Christian S. Jensen"], "title": "MH-GIN: Multi-scale Heterogeneous Graph-based Imputation Network for AIS Data (Extended Version)", "categories": ["cs.LG", "cs.DB"], "comment": "18 pages, 4 figures", "summary": "Location-tracking data from the Automatic Identification System, much of\nwhich is publicly available, plays a key role in a range of maritime safety and\nmonitoring applications. However, the data suffers from missing values that\nhamper downstream applications. Imputing the missing values is challenging\nbecause the values of different heterogeneous attributes are updated at diverse\nrates, resulting in the occurrence of multi-scale dependencies among\nattributes. Existing imputation methods that assume similar update rates across\nattributes are unable to capture and exploit such dependencies, limiting their\nimputation accuracy. We propose MH-GIN, a Multi-scale Heterogeneous Graph-based\nImputation Network that aims improve imputation accuracy by capturing\nmulti-scale dependencies. Specifically, MH-GIN first extracts multi-scale\ntemporal features for each attribute while preserving their intrinsic\nheterogeneous characteristics. Then, it constructs a multi-scale heterogeneous\ngraph to explicitly model dependencies between heterogeneous attributes to\nenable more accurate imputation of missing values through graph propagation.\nExperimental results on two real-world datasets find that MH-GIN is capable of\nan average 57% reduction in imputation errors compared to state-of-the-art\nmethods, while maintaining computational efficiency. The source code and\nimplementation details of MH-GIN are publicly available\nhttps://github.com/hyLiu1994/MH-GIN.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMH-GIN\u7684\u591a\u5c3a\u5ea6\u5f02\u6784\u56fe\u586b\u5145\u7f51\u7edc\uff0c\u7528\u4e8e\u89e3\u51b3\u81ea\u52a8\u8bc6\u522b\u7cfb\u7edf\u4e2d\u4f4d\u7f6e\u8ddf\u8e2a\u6570\u636e\u56e0\u591a\u5c3a\u5ea6\u4f9d\u8d56\u5173\u7cfb\u5bfc\u81f4\u7684\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u51cf\u5c1157%\u7684\u586b\u5145\u8bef\u5dee\u3002", "motivation": "\u81ea\u52a8\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7684\u4f4d\u7f6e\u8ddf\u8e2a\u6570\u636e\u56e0\u591a\u5c3a\u5ea6\u4f9d\u8d56\u5173\u7cfb\u548c\u5f02\u6784\u5c5e\u6027\u66f4\u65b0\u7684\u4e0d\u540c\u901f\u7387\u5bfc\u81f4\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u5efa\u6a21\u6b64\u7c7b\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "MH-GIN\u901a\u8fc7\u63d0\u53d6\u591a\u5c3a\u5ea6\u65f6\u95f4\u7279\u5f81\u5e76\u6784\u5efa\u591a\u5c3a\u5ea6\u5f02\u6784\u56fe\uff0c\u663e\u5f0f\u5efa\u6a21\u5f02\u6784\u5c5e\u6027\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u56fe\u4f20\u64ad\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u7f3a\u5931\u503c\u586b\u5145\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMH-GIN\u5e73\u5747\u51cf\u5c1157%\u7684\u586b\u5145\u8bef\u5dee\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "MH-GIN\u901a\u8fc7\u591a\u5c3a\u5ea6\u5f02\u6784\u56fe\u5efa\u6a21\u6709\u6548\u63d0\u5347\u4e86\u7f3a\u5931\u503c\u7684\u586b\u5145\u7cbe\u5ea6\uff0c\u4e3a\u6d77\u4e8b\u5b89\u5168\u548c\u76d1\u63a7\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2507.20367", "pdf": "https://arxiv.org/pdf/2507.20367", "abs": "https://arxiv.org/abs/2507.20367", "authors": ["Charitha Madapatha", "Piotr Lechowicz", "Carlos Natalino", "Paolo Monti", "Tommy Svensson"], "title": "Joint Fiber and Free Space Optical Infrastructure Planning for Hybrid Integrated Access and Backhaul Networks", "categories": ["cs.NI", "cs.IT", "math.IT"], "comment": "Accepted invited paper for IEEE PIMRC 2025, Istanbul, Turkey", "summary": "Integrated access and backhaul (IAB) is one of the promising techniques for\n5G networks and beyond (6G), in which the same node/hardware is used to provide\nboth backhaul and cellular services in a multi-hop architecture. Due to the\nsensitivity of the backhaul links with high rate/reliability demands, proper\nnetwork planning is needed to ensure the IAB network performs with the desired\nperformance levels. In this paper, we study the effect of infrastructure\nplanning and optimization on the coverage of IAB networks. We concentrate on\nthe cases where the fiber connectivity to the nodes is constrained due to cost.\nThereby, we study the performance gains and energy efficiency in the presence\nof free-space optical (FSO) communication links. Our results indicate hybrid\nfiber/FSO deployments offer substantial cost savings compared to fully fibered\nnetworks, suggesting a beneficial trade-off for strategic link deployment while\nimproving the service coverage probability. As we show, with proper network\nplanning, the service coverage, energy efficiency, and cost efficiency can be\nimproved.", "AI": {"tldr": "\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u4f18\u5316\u5bf9IAB\u7f51\u7edc\u8986\u76d6\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5149\u7ea4\u8fde\u63a5\u53d7\u9650\u65f6\u4f7f\u7528FSO\u94fe\u8def\u7684\u6027\u80fd\u589e\u76ca\u548c\u80fd\u6548\u3002", "motivation": "\u7531\u4e8eIAB\u7f51\u7edc\u4e2d\u56de\u7a0b\u94fe\u8def\u5bf9\u9ad8\u901f\u7387\u548c\u9ad8\u53ef\u9760\u6027\u7684\u654f\u611f\u6027\uff0c\u9700\u8981\u4f18\u5316\u7f51\u7edc\u89c4\u5212\u4ee5\u786e\u4fdd\u5176\u6027\u80fd\u3002\u5149\u7ea4\u8fde\u63a5\u7684\u9ad8\u6210\u672c\u4fc3\u4f7f\u7814\u7a76\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5728\u5149\u7ea4\u8fde\u63a5\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u7814\u7a76\u4f7f\u7528\u81ea\u7531\u7a7a\u95f4\u5149\u901a\u4fe1\uff08FSO\uff09\u94fe\u8def\u7684\u6027\u80fd\u589e\u76ca\u548c\u80fd\u6548\u3002\u6bd4\u8f83\u6df7\u5408\u5149\u7ea4/FSO\u90e8\u7f72\u4e0e\u5168\u5149\u7ea4\u7f51\u7edc\u7684\u6210\u672c\u6548\u76ca\u3002", "result": "\u6df7\u5408\u5149\u7ea4/FSO\u90e8\u7f72\u76f8\u6bd4\u5168\u5149\u7ea4\u7f51\u7edc\u53ef\u663e\u8457\u8282\u7701\u6210\u672c\uff0c\u540c\u65f6\u63d0\u9ad8\u670d\u52a1\u8986\u76d6\u6982\u7387\u3001\u80fd\u6548\u548c\u6210\u672c\u6548\u76ca\u3002", "conclusion": "\u901a\u8fc7\u5408\u7406\u7684\u7f51\u7edc\u89c4\u5212\uff0cIAB\u7f51\u7edc\u7684\u670d\u52a1\u8986\u76d6\u3001\u80fd\u6548\u548c\u6210\u672c\u6548\u7387\u5747\u53ef\u5f97\u5230\u63d0\u5347\uff0c\u6df7\u5408\u5149\u7ea4/FSO\u90e8\u7f72\u662f\u4e00\u79cd\u6709\u76ca\u7684\u6743\u8861\u65b9\u6848\u3002"}}
{"id": "2507.20095", "pdf": "https://arxiv.org/pdf/2507.20095", "abs": "https://arxiv.org/abs/2507.20095", "authors": ["Nitika Chopra", "Taher A. Ghaleb"], "title": "From First Use to Final Commit: Studying the Evolution of Multi-CI Service Adoption", "categories": ["cs.SE"], "comment": "Accepted at the 41st IEEE International Conference on Software\n  Maintenance and Evolution 2025 (ICSME'25)", "summary": "Continuous Integration (CI) services, such as GitHub Actions and Travis CI,\nare widely adopted in open-source development to automate testing and\ndeployment. Though existing research often examines individual services in\nisolation, it remains unclear how projects adopt and transition between\nmultiple services over time. To understand how CI adoption is evolving across\nservices, we present a preliminary study analyzing the historical CI adoption\nof 18,924 Java projects hosted on GitHub between January 2008 and December\n2024, adopting at least one of eight CI services, namely Travis CI, AppVeyor,\nCircleCI, Azure Pipelines, GitHub Actions, Bitbucket, GitLab CI, and Cirrus CI.\nSpecifically, we investigate: (1) how frequently CI services are co-adopted or\nreplaced, and (2) how maintenance activity varies across different services.\nOur analysis shows that the use of multiple CI services within the same project\nis a recurring pattern observed in nearly one in five projects, often\nreflecting migration across CI services. Our study is among the first to\nexamine multi-CI adoption in practice, offering new insights for future\nresearch and highlighting the need for strategies and tools to support service\nselection, coordination, and migration in evolving CI environments.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e8618924\u4e2aJava\u9879\u76ee\u7684\u591aCI\u670d\u52a1\u4f7f\u7528\u60c5\u51b5\uff0c\u53d1\u73b0\u8fd11/5\u9879\u76ee\u4f1a\u540c\u65f6\u6216\u66ff\u6362\u4f7f\u7528\u591a\u79cdCI\u670d\u52a1\uff0c\u51f8\u663e\u4e86CI\u73af\u5883\u9009\u62e9\u548c\u8fc1\u79fb\u7684\u5de5\u5177\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5b64\u7acb\u5206\u6790\u5355\u4e2aCI\u670d\u52a1\uff0c\u800c\u591a\u670d\u52a1\u7684\u4f7f\u7528\u548c\u8fc1\u79fb\u60c5\u51b5\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5bf92008\u81f32024\u5e74\u95f4\u4f7f\u7528\u81f3\u5c11\u4e00\u79cdCI\u670d\u52a1\u7684Java\u9879\u76ee\u8fdb\u884c\u5386\u53f2\u5206\u6790\u3002", "result": "\u591aCI\u670d\u52a1\u4f7f\u7528\u662f\u666e\u904d\u73b0\u8c61\uff0c\u5e38\u6d89\u53ca\u670d\u52a1\u8fc1\u79fb\u3002", "conclusion": "\u672a\u6765\u9700\u652f\u6301CI\u670d\u52a1\u7684\u9009\u62e9\u3001\u534f\u8c03\u548c\u8fc1\u79fb\u5de5\u5177\u3002"}}
{"id": "2507.20730", "pdf": "https://arxiv.org/pdf/2507.20730", "abs": "https://arxiv.org/abs/2507.20730", "authors": ["Edvin Teskeredzic", "Muamer Paric", "Adna Sestic", "Petra Fribert", "Anamarija Lukac", "Hadzem Hadzic", "Kemal Altwlkany", "Emanuel Lacic"], "title": "Vocalize: Lead Acquisition and User Engagement through Gamified Voice Competitions", "categories": ["cs.HC", "cs.MM"], "comment": "Accepted to ACM Hypertext 2025", "summary": "This paper explores the prospect of creating engaging user experiences and\ncollecting leads through an interactive and gamified platform. We introduce\nVocalize, an end-to-end system for increasing user engagement and lead\nacquisition through gamified voice competitions. Using audio processing\ntechniques and LLMs, we create engaging and interactive experiences that have\nthe potential to reach a wide audience, foster brand recognition, and increase\ncustomer loyalty. We describe the system from a technical standpoint and report\nresults from launching Vocalize at 4 different live events. Our user study\nshows that Vocalize is capable of generating significant user engagement, which\nshows potential for gamified audio campaigns in marketing and similar\nverticals.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aVocalize\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u97f3\u7ade\u8d5b\u7684\u4e92\u52a8\u6e38\u620f\u5316\u5e73\u53f0\u63d0\u9ad8\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u6f5c\u5728\u5ba2\u6237\u83b7\u53d6\uff0c\u5c55\u793a\u4e86\u97f3\u9891\u5904\u7406\u6280\u672f\u548cLLMs\u7684\u5e94\u7528\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u901a\u8fc7\u4e92\u52a8\u548c\u6e38\u620f\u5316\u7684\u5e73\u53f0\u521b\u9020\u5f15\u4eba\u5165\u80dc\u7684\u7528\u6237\u4f53\u9a8c\u5e76\u6536\u96c6\u6f5c\u5728\u5ba2\u6237\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5229\u7528\u97f3\u9891\u5904\u7406\u6280\u672f\u548cLLMs\u5f00\u53d1Vocalize\u7cfb\u7edf\uff0c\u5e76\u57284\u4e2a\u4e0d\u540c\u7684\u73b0\u573a\u6d3b\u52a8\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cVocalize\u80fd\u591f\u663e\u8457\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u5c55\u793a\u4e86\u6e38\u620f\u5316\u97f3\u9891\u6d3b\u52a8\u5728\u8425\u9500\u7b49\u9886\u57df\u7684\u6f5c\u529b\u3002", "conclusion": "Vocalize\u7cfb\u7edf\u901a\u8fc7\u6e38\u620f\u5316\u7684\u8bed\u97f3\u7ade\u8d5b\u6709\u6548\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u54c1\u724c\u8ba4\u77e5\uff0c\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.19496", "pdf": "https://arxiv.org/pdf/2507.19496", "abs": "https://arxiv.org/abs/2507.19496", "authors": ["Jorge Alberto Araujo"], "title": "Technological Requirements for Videoconferencing Judicial Hearings: Enhancing the Credibility and Reliability of Remote Testimonies", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "This paper analyzes the technological requirements necessary to enhance the\ncredibility and reliability of judicial hearings conducted via videoconference,\nfrom the internal perspective of the judiciary. Drawing on the practical\nexperience of a judge who conducts daily hearings, this study identifies\nlimitations in current platforms for verifying the authenticity of testimonies\nand proposes tailored functionalities for the judicial context. Recognizing\nthat remote hearings represent a convenience for the parties without replacing\nthe option of in-person attendance, the article suggests implementing features\nsuch as eye tracking, environment verification, and blocking of parallel\napplications, in addition to improvements in transmission quality. The study\nconcludes that developing specific modules for witnesses - focusing on security\nand monitoring - can significantly contribute to equalizing the credibility\nbetween remote and in-person hearings, thus expanding access to justice without\ncompromising procedural reliability.", "AI": {"tldr": "\u7814\u7a76\u4ece\u53f8\u6cd5\u5185\u90e8\u89c6\u89d2\u5206\u6790\u4e86\u5982\u4f55\u901a\u8fc7\u6280\u672f\u63d0\u5347\u89c6\u9891\u5ead\u5ba1\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u63d0\u51fa\u9488\u5bf9\u6027\u529f\u80fd\u4ee5\u5f25\u8865\u73b0\u6709\u5e73\u53f0\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u89c6\u9891\u5ead\u5ba1\u5e73\u53f0\u5728\u8bc1\u8bcd\u771f\u5b9e\u6027\u9a8c\u8bc1\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e0c\u671b\u901a\u8fc7\u6280\u672f\u6539\u8fdb\u63d0\u5347\u8fdc\u7a0b\u5ead\u5ba1\u7684\u53ef\u9760\u6027\u3002", "method": "\u57fa\u4e8e\u6cd5\u5b98\u7684\u5b9e\u9645\u7ecf\u9a8c\uff0c\u63d0\u51fa\u5982\u773c\u52a8\u8ffd\u8e2a\u3001\u73af\u5883\u9a8c\u8bc1\u548c\u5e76\u884c\u5e94\u7528\u62e6\u622a\u7b49\u529f\u80fd\u3002", "result": "\u5f00\u53d1\u4e13\u95e8\u7684\u5b89\u5168\u4e0e\u76d1\u63a7\u6a21\u5757\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8fdc\u7a0b\u5ead\u5ba1\u7684\u53ef\u4fe1\u5ea6\uff0c\u4f7f\u5176\u4e0e\u73b0\u573a\u5ead\u5ba1\u76f8\u5f53\u3002", "conclusion": "\u901a\u8fc7\u6280\u672f\u6539\u8fdb\uff0c\u8fdc\u7a0b\u5ead\u5ba1\u5728\u4fdd\u969c\u7a0b\u5e8f\u53ef\u9760\u6027\u7684\u540c\u65f6\uff0c\u53ef\u4ee5\u6269\u5927\u53f8\u6cd5\u53ef\u53ca\u6027\u3002"}}
{"id": "2507.20848", "pdf": "https://arxiv.org/pdf/2507.20848", "abs": "https://arxiv.org/abs/2507.20848", "authors": ["Hernan Ghianni", "Man Zhang", "Juan P. Galeotti", "Andrea Arcuri"], "title": "Search-Based Fuzzing For RESTful APIs That Use MongoDB", "categories": ["cs.SE", "cs.DB"], "comment": null, "summary": "In RESTful APIs, interactions with a database are a common and crucial\naspect. When generating whitebox tests, it is essential to consider the\ndatabase's state (i.e., the data contained in the database) to achieve higher\ncode coverage and uncover more hidden faults. This article presents novel\ntechniques to enhance search-based software test generation for RESTful APIs\ninteracting with NoSQL databases. Specifically, we target the popular MongoDB\ndatabase, by dynamically analyzing (via automated code instrumentation) the\nstate of the database during the test generation process. Additionally, to\nachieve better results, our novel approach allows inserting NoSQL data directly\nfrom test cases. This is particularly beneficial when generating the correct\nsequence of events to set the NoSQL database in an appropriate state is\nchallenging or time-consuming. This method is also advantageous for testing\nread-only microservices. Our novel techniques are implemented as an extension\nof EvoMaster, the only open-source tool for white-box fuzzing RESTful APIs.\nExperiments conducted on six RESTful APIs demonstrated significant improvements\nin code coverage, with increases of up to 18% compared to existing white-box\napproaches. To better highlight the improvements of our novel techniques,\ncomparisons are also carried out with four state-of-the-art black-box fuzzers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6280\u672f\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u6790NoSQL\u6570\u636e\u5e93\u72b6\u6001\u5e76\u76f4\u63a5\u4ece\u6d4b\u8bd5\u7528\u4f8b\u63d2\u5165\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86RESTful API\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6545\u969c\u53d1\u73b0\u7387\u3002", "motivation": "\u5728RESTful API\u6d4b\u8bd5\u4e2d\uff0c\u6570\u636e\u5e93\u72b6\u6001\u7684\u8003\u8651\u5bf9\u4e8e\u63d0\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\u548c\u53d1\u73b0\u9690\u85cf\u6545\u969c\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u52a8\u6001\u5206\u6790MongoDB\u6570\u636e\u5e93\u72b6\u6001\uff0c\u5e76\u901a\u8fc7\u6d4b\u8bd5\u7528\u4f8b\u76f4\u63a5\u63d2\u5165NoSQL\u6570\u636e\u3002\u65b9\u6cd5\u4f5c\u4e3aEvoMaster\u5de5\u5177\u7684\u6269\u5c55\u5b9e\u73b0\u3002", "result": "\u5728\u516d\u4e2aRESTful API\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u5347\u4e86\u9ad8\u8fbe18%\uff0c\u4f18\u4e8e\u73b0\u6709\u767d\u76d2\u548c\u9ed1\u76d2\u6d4b\u8bd5\u5de5\u5177\u3002", "conclusion": "\u8be5\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u679c\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6d4b\u8bd5\u8bfb\u5bc6\u96c6\u578b\u5fae\u670d\u52a1\u548c\u590d\u6742\u6570\u636e\u5e93\u72b6\u6001\u7684\u573a\u666f\u3002"}}
{"id": "2507.20201", "pdf": "https://arxiv.org/pdf/2507.20201", "abs": "https://arxiv.org/abs/2507.20201", "authors": ["J\u00e9r\u00e9mie Chalopin", "Shantanu Das", "Maria Kokkou"], "title": "Silent Self-Stabilising Leader Election in Programmable Matter Systems with Holes", "categories": ["cs.DC"], "comment": "15 pages", "summary": "Leader election is a fundamental problem in distributed computing,\nparticularly within programmable matter systems, where coordination among\nsimple computational entities is crucial for solving complex tasks. In these\nsystems, particles (i.e., constant memory computational entities) operate in a\nregular triangular grid as described in the geometric Amoebot model. While\nleader election has been extensively studied in non self-stabilising settings,\nself-stabilising solutions remain more limited. In this work, we study the\nproblem of self-stabilising leader election in connected (but not necessarily\nsimply connected) configurations. We present the first self-stabilising\nalgorithm for programmable matter that guarantees the election of a unique\nleader under an unfair scheduler, assuming particles share a common sense of\ndirection. Our approach leverages particle movement, a capability not\npreviously exploited in the self-stabilising context. We show that movement in\nconjunction with particles operating in a grid can overcome classical\nimpossibility results for constant-memory systems established by Dolev et al.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u81ea\u7a33\u5b9a\u9886\u5bfc\u8005\u9009\u4e3e\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u53ef\u7f16\u7a0b\u7269\u8d28\u7cfb\u7edf\u4e2d\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u975e\u516c\u5e73\u8c03\u5ea6\u5668\u4e0b\u4fdd\u8bc1\u552f\u4e00\u9886\u5bfc\u8005\u7684\u81ea\u7a33\u5b9a\u7b97\u6cd5\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\uff0c\u9886\u5bfc\u8005\u9009\u4e3e\u662f\u4e00\u4e2a\u57fa\u7840\u95ee\u9898\uff0c\u5c24\u5176\u5728\u53ef\u7f16\u7a0b\u7269\u8d28\u7cfb\u7edf\u4e2d\uff0c\u7b80\u5355\u8ba1\u7b97\u5b9e\u4f53\u95f4\u7684\u534f\u8c03\u5bf9\u5b8c\u6210\u590d\u6742\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5df2\u6709\u5927\u91cf\u7814\u7a76\uff0c\u4f46\u81ea\u7a33\u5b9a\u89e3\u51b3\u65b9\u6848\u4ecd\u8f83\u6709\u9650\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7c92\u5b50\u79fb\u52a8\u7684\u81ea\u7a33\u5b9a\u7b97\u6cd5\uff0c\u5047\u8bbe\u7c92\u5b50\u5171\u4eab\u5171\u540c\u7684\u65b9\u5411\u611f\u3002\u8be5\u65b9\u6cd5\u5728\u975e\u516c\u5e73\u8c03\u5ea6\u5668\u4e0b\u8fd0\u884c\uff0c\u9002\u7528\u4e8e\u8fde\u901a\u4f46\u4e0d\u4e00\u5b9a\u662f\u5355\u8fde\u901a\u914d\u7f6e\u7684\u4e09\u89d2\u7f51\u683c\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7c92\u5b50\u79fb\u52a8\u7ed3\u5408\u7f51\u683c\u64cd\u4f5c\u53ef\u4ee5\u514b\u670dDolev\u7b49\u4eba\u63d0\u51fa\u7684\u5e38\u6570\u5185\u5b58\u7cfb\u7edf\u7684\u7ecf\u5178\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5c55\u793a\u4e86\u5728\u81ea\u7a33\u5b9a\u73af\u5883\u4e0b\uff0c\u5229\u7528\u7c92\u5b50\u79fb\u52a8\u80fd\u529b\u5b9e\u73b0\u552f\u4e00\u9886\u5bfc\u8005\u9009\u4e3e\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u53ef\u7f16\u7a0b\u7269\u8d28\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2507.20438", "pdf": "https://arxiv.org/pdf/2507.20438", "abs": "https://arxiv.org/abs/2507.20438", "authors": ["Rostand A. K. Fezeu", "Jason Carpenter", "Rushikesh Zende", "Sree Ganesh Lalitaditya Divakarla", "Nitin Varyani", "Faaiq Bilal", "Steven Sleder", "Nanditha Naik", "Duncan Joly", "Eman Ramadan", "Ajay Kumar Gurumadaiah", "Zhi-Li Zhang"], "title": "Teleoperating Autonomous Vehicles over Commercial 5G Networks: Are We There Yet?", "categories": ["cs.NI", "cs.OH", "C.2.0"], "comment": "17 pages", "summary": "Remote driving, or teleoperating Autonomous Vehicles (AVs), is a key\napplication that emerging 5G networks aim to support. In this paper, we conduct\na systematic feasibility study of AV teleoperation over commercial 5G networks\nfrom both cross-layer and end-to-end (E2E) perspectives. Given the critical\nimportance of timely delivery of sensor data, such as camera and LiDAR data,\nfor AV teleoperation, we focus in particular on the performance of uplink\nsensor data delivery. We analyze the impacts of Physical Layer (PHY layer) 5G\nradio network factors, including channel conditions, radio resource allocation,\nand Handovers (HOs), on E2E latency performance. We also examine the impacts of\n5G networks on the performance of upper-layer protocols and E2E application\nQuality-of-Experience (QoE) adaptation mechanisms used for real-time sensor\ndata delivery, such as Real-Time Streaming Protocol (RTSP) and Web Real Time\nCommunication (WebRTC). Our study reveals the challenges posed by today's 5G\nnetworks and the limitations of existing sensor data streaming mechanisms. The\ninsights gained will help inform the co-design of future-generation wireless\nnetworks, edge cloud systems, and applications to overcome the low-latency\nbarriers in AV teleoperation.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e865G\u7f51\u7edc\u4e0b\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8fdc\u7a0b\u64cd\u63a7\u7684\u53ef\u884c\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u4e0a\u884c\u4f20\u611f\u5668\u6570\u636e\u4f20\u8f93\u6027\u80fd\uff0c\u5206\u6790\u4e86\u7269\u7406\u5c42\u548c\u7aef\u5230\u7aef\u56e0\u7d20\u5bf9\u5ef6\u8fdf\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8\u4e86\u73b0\u6709\u6280\u672f\u9650\u5236\u3002", "motivation": "\u7814\u7a765G\u7f51\u7edc\u5bf9\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8fdc\u7a0b\u64cd\u63a7\u7684\u652f\u6301\u80fd\u529b\uff0c\u7279\u522b\u662f\u4f20\u611f\u5668\u6570\u636e\u4f20\u8f93\u7684\u5b9e\u65f6\u6027\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u8de8\u5c42\u548c\u7aef\u5230\u7aef\u89c6\u89d2\uff0c\u5206\u67905G\u7269\u7406\u5c42\u56e0\u7d20\uff08\u5982\u4fe1\u9053\u6761\u4ef6\u3001\u8d44\u6e90\u5206\u914d\u548c\u5207\u6362\uff09\u5bf9\u5ef6\u8fdf\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u8bc4\u4f30\u4e0a\u5c42\u534f\u8bae\u548cQoE\u673a\u5236\uff08\u5982RTSP\u548cWebRTC\uff09\u7684\u6027\u80fd\u3002", "result": "\u63ed\u793a\u5f53\u524d5G\u7f51\u7edc\u5728\u4f4e\u5ef6\u8fdf\u5e94\u7528\u4e2d\u7684\u6311\u6218\uff0c\u4ee5\u53ca\u73b0\u6709\u4f20\u611f\u5668\u6570\u636e\u6d41\u6280\u672f\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u4e3a\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u3001\u8fb9\u7f18\u4e91\u7cfb\u7edf\u548c\u5e94\u7528\u7684\u534f\u540c\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\uff0c\u4ee5\u7a81\u7834\u81ea\u52a8\u9a7e\u9a76\u8fdc\u7a0b\u64cd\u63a7\u7684\u4f4e\u5ef6\u8fdf\u969c\u788d\u3002"}}
{"id": "2507.20109", "pdf": "https://arxiv.org/pdf/2507.20109", "abs": "https://arxiv.org/abs/2507.20109", "authors": ["Xin Yin", "Chao Ni", "Liushan Chen", "Xiaohu Yang"], "title": "Learning to Align Human Code Preferences", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable potential in\nautomating software development tasks. While recent advances leverage\nSupervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to align\nmodels with human preferences, the optimal training strategy remains unclear\nacross diverse code preference scenarios. This paper systematically\ninvestigates the roles of SFT and DPO in aligning LLMs with different code\npreferences. Through both theoretical analysis and empirical observation, we\nhypothesize that SFT excels in scenarios with objectively verifiable optimal\nsolutions, while applying SFT followed by DPO (S&D) enables models to explore\nsuperior solutions in scenarios without objectively verifiable optimal\nsolutions. Based on the analysis and experimental evidence, we propose Adaptive\nPreference Optimization (APO), a dynamic integration approach that adaptively\namplifies preferred responses, suppresses dispreferred ones, and encourages\nexploration of potentially superior solutions during training. Extensive\nexperiments across six representative code preference tasks validate our\ntheoretical hypotheses and demonstrate that APO consistently matches or\nsurpasses the performance of existing SFT and S&D strategies. Our work provides\nboth theoretical foundations and practical guidance for selecting appropriate\ntraining strategies in different code preference alignment scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4ee3\u7801\u504f\u597d\u5bf9\u9f50\u4e2d\uff0c\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u7684\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u504f\u597d\u4f18\u5316(APO)\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6574\u5408\u7b56\u7565\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u5728\u4e0d\u540c\u4ee3\u7801\u504f\u597d\u573a\u666f\u4e0b\uff0c\u5982\u4f55\u6700\u4f18\u5730\u4f7f\u7528SFT\u548cDPO\u6765\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4eba\u7c7b\u504f\u597d\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u89c2\u5bdf\uff0c\u63d0\u51faAPO\u65b9\u6cd5\uff0c\u52a8\u6001\u6574\u5408SFT\u548cDPO\u7684\u4f18\u52bf\u3002", "result": "\u5728\u516d\u79cd\u4ee3\u8868\u6027\u4ee3\u7801\u504f\u597d\u4efb\u52a1\u4e2d\uff0cAPO\u7684\u6027\u80fd\u4e0e\u73b0\u6709SFT\u548cS&D\u7b56\u7565\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "APO\u4e3a\u4e0d\u540c\u4ee3\u7801\u504f\u597d\u5bf9\u9f50\u573a\u666f\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2507.20865", "pdf": "https://arxiv.org/pdf/2507.20865", "abs": "https://arxiv.org/abs/2507.20865", "authors": ["Graham E. Leigh", "Dominik Wehr"], "title": "Unravelling Cyclic First-Order Arithmetic", "categories": ["math.LO", "cs.LO"], "comment": null, "summary": "Cyclic proof systems for Heyting and Peano arithmetic eschew induction axioms\nby accepting proofs which are finite graphs rather than trees. Proving that\nsuch a cyclic proof system coincides with its more conventional variants is\noften difficult: Previous proofs in the literature rely on intricate\narithmetisations of the metamathematics of the cyclic proof systems.\n  In this article, we present a simple and direct embedding of cyclic proofs\nfor Heyting and Peano arithmetic into purely inductive, i.e. 'finitary', proofs\nby adapting a translation introduced by Sprenger and Dam for a cyclic proof\nsystem of $\\mu\\text{FOL}$ with explicit ordinal approximations. We extend their\nmethod to recover Das' result of $\\text{C}\\Pi_n \\subseteq \\text{I}\\Pi_{n + 1}$\nfor Peano arithmetic. As part of the embedding we present a novel\nrepresentation of cyclic proofs as a labelled sequent calculus.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u76f4\u63a5\u7684\u65b9\u6cd5\uff0c\u5c06Heyting\u548cPeano\u7b97\u672f\u7684\u5faa\u73af\u8bc1\u660e\u5d4c\u5165\u7eaf\u5f52\u7eb3\uff08\u6709\u9650\uff09\u8bc1\u660e\u4e2d\uff0c\u6269\u5c55\u4e86Sprenger\u548cDam\u7684\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5faa\u73af\u8bc1\u660e\u7684\u65b0\u8868\u793a\u5f62\u5f0f\u3002", "motivation": "\u4f20\u7edf\u5faa\u73af\u8bc1\u660e\u7cfb\u7edf\u4e0e\u5e38\u89c4\u53d8\u4f53\u7684\u7b49\u4ef7\u6027\u9a8c\u8bc1\u901a\u5e38\u590d\u6742\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66f4\u7b80\u5355\u76f4\u63a5\u7684\u5d4c\u5165\u65b9\u6cd5\uff0c\u907f\u514d\u7e41\u7410\u7684\u5143\u6570\u5b66\u7b97\u672f\u5316\u3002", "method": "\u901a\u8fc7\u8c03\u6574Sprenger\u548cDam\u5bf9\u03bcFOL\u5faa\u73af\u8bc1\u660e\u7cfb\u7edf\u7684\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u5c06\u5176\u6269\u5c55\u5230Heyting\u548cPeano\u7b97\u672f\uff0c\u5e76\u63d0\u51fa\u5faa\u73af\u8bc1\u660e\u7684\u6807\u8bb0\u5e8f\u5217\u6f14\u7b97\u8868\u793a\u3002", "result": "\u6210\u529f\u5c06\u5faa\u73af\u8bc1\u660e\u5d4c\u5165\u6709\u9650\u8bc1\u660e\uff0c\u6062\u590d\u4e86Das\u5173\u4e8eC\u03a0n\u2286I\u03a0n+1\u7684\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u65b0\u65b9\u6cd5\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u7684\u65b9\u6cd5\u7b80\u5316\u4e86\u5faa\u73af\u8bc1\u660e\u7cfb\u7edf\u7684\u7b49\u4ef7\u6027\u9a8c\u8bc1\uff0c\u5e76\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u5de5\u5177\u3002"}}
{"id": "2507.20745", "pdf": "https://arxiv.org/pdf/2507.20745", "abs": "https://arxiv.org/abs/2507.20745", "authors": ["Yue Zhu", "Haiwen Diao", "Shang Gao", "Jiazuo Yu", "Jiawen Zhu", "Yunzhi Zhuge", "Shuai Hao", "Xu Jia", "Lu Zhang", "Ying Zhang", "Huchuan Lu"], "title": "Regularizing Subspace Redundancy of Low-Rank Adaptation", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "10 pages, 4 figures, Accepted by ACMMM2025", "summary": "Low-Rank Adaptation (LoRA) and its variants have delivered strong capability\nin Parameter-Efficient Transfer Learning (PETL) by minimizing trainable\nparameters and benefiting from reparameterization. However, their projection\nmatrices remain unrestricted during training, causing high representation\nredundancy and diminishing the effectiveness of feature adaptation in the\nresulting subspaces. While existing methods mitigate this by manually adjusting\nthe rank or implicitly applying channel-wise masks, they lack flexibility and\ngeneralize poorly across various datasets and architectures. Hence, we propose\nReSoRA, a method that explicitly models redundancy between mapping subspaces\nand adaptively Regularizes Subspace redundancy of Low-Rank Adaptation.\nSpecifically, it theoretically decomposes the low-rank submatrices into\nmultiple equivalent subspaces and systematically applies de-redundancy\nconstraints to the feature distributions across different projections.\nExtensive experiments validate that our proposed method consistently\nfacilitates existing state-of-the-art PETL methods across various backbones and\ndatasets in vision-language retrieval and standard visual classification\nbenchmarks. Besides, as a training supervision, ReSoRA can be seamlessly\nintegrated into existing approaches in a plug-and-play manner, with no\nadditional inference costs. Code is publicly available at:\nhttps://github.com/Lucenova/ReSoRA.", "AI": {"tldr": "ReSoRA \u662f\u4e00\u79cd\u6539\u8fdb\u7684 LoRA \u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u5e76\u81ea\u9002\u5e94\u6b63\u5219\u5316\u5b50\u7a7a\u95f4\u5197\u4f59\uff0c\u63d0\u9ad8\u4e86\u53c2\u6570\u9ad8\u6548\u8fc1\u79fb\u5b66\u4e60\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709 LoRA \u65b9\u6cd5\u5728\u8bad\u7ec3\u4e2d\u6295\u5f71\u77e9\u9635\u4e0d\u53d7\u9650\u5236\uff0c\u5bfc\u81f4\u7279\u5f81\u5b66\u4e60\u7684\u5b50\u7a7a\u95f4\u5197\u4f59\uff0c\u5f71\u54cd\u7279\u5f81\u9002\u5e94\u6027\u3002\u5df2\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7075\u6d3b\u6027\u4e14\u6cdb\u5316\u6027\u5dee\u3002", "method": "\u63d0\u51fa ReSoRA\uff0c\u5c06\u4f4e\u79e9\u5b50\u77e9\u9635\u5206\u89e3\u4e3a\u591a\u4e2a\u7b49\u6548\u5b50\u7a7a\u95f4\uff0c\u5e76\u5bf9\u4e0d\u540c\u6295\u5f71\u7684\u7279\u5f81\u5206\u5e03\u65bd\u52a0\u53bb\u5197\u4f59\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e ReSoRA \u5728\u89c6\u89c9\u8bed\u8a00\u68c0\u7d22\u548c\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u73b0\u6709 PETL \u65b9\u6cd5\u7684\u8868\u73b0\u3002", "conclusion": "ReSoRA \u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u8bad\u7ec3\u76d1\u7763\u65b9\u6cd5\uff0c\u65e0\u9700\u989d\u5916\u63a8\u7406\u6210\u672c\uff0c\u663e\u8457\u63d0\u9ad8\u8fc1\u79fb\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2507.19497", "pdf": "https://arxiv.org/pdf/2507.19497", "abs": "https://arxiv.org/abs/2507.19497", "authors": ["Alex Leitch", "Celia Chen"], "title": "Unlimited Editions: Documenting Human Style in AI Art Generation", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.IR"], "comment": "alt.CHI 2025", "summary": "As AI art generation becomes increasingly sophisticated, HCI research has\nfocused primarily on questions of detection, authenticity, and automation. This\npaper argues that such approaches fundamentally misunderstand how artistic\nvalue emerges from the concerns that drive human image production. Through\nexamination of historical precedents, we demonstrate that artistic style is not\nonly visual appearance but the resolution of creative struggle, as artists\nwrestle with influence and technical constraints to develop unique ways of\nseeing. Current AI systems flatten these human choices into reproducible\npatterns without preserving their provenance. We propose that HCI's role lies\nnot only in perfecting visual output, but in developing means to document the\norigins and evolution of artistic style as it appears within generated visual\ntraces. This reframing suggests new technical directions for HCI research in\ngenerative AI, focused on automatic documentation of stylistic lineage and\ncreative choice rather than simple reproduction of aesthetic effects.", "AI": {"tldr": "\u6458\u8981\u4e3b\u5f20AI\u827a\u672f\u751f\u6210\u7814\u7a76\u5e94\u5173\u6ce8\u827a\u672f\u4ef7\u503c\u7684\u8d77\u6e90\u4e0e\u6f14\u5316\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u89c6\u89c9\u8f93\u51fa\u3002", "motivation": "\u63a2\u8ba8AI\u827a\u672f\u751f\u6210\u5982\u4f55\u8bef\u89e3\u827a\u672f\u4ef7\u503c\u7684\u6765\u6e90\uff0c\u63d0\u51fa\u5e94\u8bb0\u5f55\u827a\u672f\u98ce\u683c\u7684\u6f14\u53d8\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u827a\u672f\u98ce\u683c\u7684\u5f62\u6210\u662f\u521b\u9020\u529b\u4e0e\u7ea6\u675f\u7684\u4ea7\u7269\u3002", "result": "\u547c\u5401HCI\u7814\u7a76\u8f6c\u5411\u81ea\u52a8\u8bb0\u5f55\u827a\u672f\u98ce\u683c\u7684\u8d77\u6e90\u4e0e\u9009\u62e9\uff0c\u800c\u975e\u5355\u7eaf\u590d\u5236\u7f8e\u5b66\u6548\u679c\u3002", "conclusion": "\u5efa\u8bae\u5c06HCI\u7814\u7a76\u7684\u91cd\u70b9\u4ece\u89c6\u89c9\u8f93\u51fa\u8f6c\u5411\u827a\u672f\u98ce\u683c\u7684\u6eaf\u6e90\u4e0e\u6f14\u5316\u3002"}}
{"id": "2507.20467", "pdf": "https://arxiv.org/pdf/2507.20467", "abs": "https://arxiv.org/abs/2507.20467", "authors": ["Avi Deb Raha", "Apurba Adhikary", "Mrityunjoy Gain", "Yumin Park", "Walid Saad", "Choong Seon Hong"], "title": "DD-JSCC: Dynamic Deep Joint Source-Channel Coding for Semantic Communications", "categories": ["cs.NI"], "comment": null, "summary": "Deep Joint Source-Channel Coding (Deep-JSCC) has emerged as a promising\nsemantic communication approach for wireless image transmission by jointly\noptimizing source and channel coding using deep learning techniques. However,\ntraditional Deep-JSCC architectures employ fixed encoder-decoder structures,\nlimiting their adaptability to varying device capabilities, real-time\nperformance optimization, power constraints and channel conditions. To address\nthese limitations, we propose DD-JSCC: Dynamic Deep Joint Source-Channel Coding\nfor Semantic Communications, a novel encoder-decoder architecture designed for\nsemantic communication systems. Unlike traditional Deep-JSCC models, DD-JSCC is\nflexible for dynamically adjusting its layer structures in real-time based on\ntransmitter and receiver capabilities, power constraints, compression ratios,\nand current channel conditions. This adaptability is achieved through a\nhierarchical layer activation mechanism combined with implicit regularization\nvia sequential randomized training, effectively reducing combinatorial\ncomplexity, preventing overfitting, and ensuring consistent feature\nrepresentations across varying configurations. Simulation results demonstrate\nthat DD-JSCC enhances the performance of image reconstruction in semantic\ncommunications, achieving up to 2 dB improvement in Peak Signal-to-Noise Ratio\n(PSNR) over fixed Deep-JSCC architectures, while reducing training costs by\nover 40%. The proposed unified framework eliminates the need for multiple\nspecialized models, significantly reducing training complexity and deployment\noverhead.", "AI": {"tldr": "DD-JSCC\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7684\u6df1\u5ea6\u8054\u5408\u6e90-\u4fe1\u9053\u7f16\u7801\u67b6\u6784\uff0c\u901a\u8fc7\u5b9e\u65f6\u8c03\u6574\u5c42\u7ed3\u6784\u9002\u5e94\u4e0d\u540c\u8bbe\u5907\u548c\u4fe1\u9053\u6761\u4ef6\uff0c\u63d0\u5347\u4e86\u56fe\u50cf\u91cd\u5efa\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfDeep-JSCC\u91c7\u7528\u56fa\u5b9a\u7f16\u7801-\u89e3\u7801\u7ed3\u6784\uff0c\u65e0\u6cd5\u9002\u5e94\u8bbe\u5907\u80fd\u529b\u53d8\u5316\u3001\u5b9e\u65f6\u6027\u80fd\u4f18\u5316\u53ca\u4fe1\u9053\u6761\u4ef6\u5dee\u5f02\u3002", "method": "DD-JSCC\u91c7\u7528\u5206\u5c42\u6fc0\u6d3b\u673a\u5236\u548c\u9690\u5f0f\u6b63\u5219\u5316\uff0c\u52a8\u6001\u8c03\u6574\u7f51\u7edc\u5c42\u7ed3\u6784\u3002", "result": "DD-JSCC\u5728PSNR\u4e0a\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u53472 dB\uff0c\u8bad\u7ec3\u6210\u672c\u964d\u4f4e40%\u3002", "conclusion": "DD-JSCC\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u90e8\u7f72\u590d\u6742\u6027\u3002"}}
{"id": "2507.20122", "pdf": "https://arxiv.org/pdf/2507.20122", "abs": "https://arxiv.org/abs/2507.20122", "authors": ["Khairul Alam", "Banani Roy"], "title": "From Prompt to Pipeline: Large Language Models for Scientific Workflow Development in Bioinformatics", "categories": ["cs.SE"], "comment": "36 pages", "summary": "The increasing complexity of bioinformatics data analysis has made Scientific\nWorkflow Systems (SWSs) like Galaxy and Nextflow essential for enabling\nscalable, reproducible, and automated workflows. However, creating and\nunderstanding these workflows remains challenging, particularly for domain\nexperts without programming expertise. This study investigates whether modern\nLarge Language Models (LLMs), GPT-4o, Gemini 2.5 Flash, and DeepSeek-V3, can\nsupport the generation of accurate, complete, and usable bioinformatics\nworkflows, and examines which prompting strategies most effectively guide this\nprocess. We evaluate these models using diverse tasks such as SNP analysis,\nRNA-seq, DNA methylation, and data retrieval, spanning both graphical (Galaxy)\nand script-based (Nextflow) platforms. Expert reviewers assess the generated\nworkflows against community-curated baselines from the Galaxy Training Network\nand nf-core repositories. The results show that Gemini 2.5 Flash excels in\ngenerating Galaxy workflows, while DeepSeek-V3 performs strongly in Nextflow.\nPrompting strategies significantly impact quality, with role-based and\nchain-of-thought prompts improving completeness and correctness. While GPT-4o\nbenefits from structured inputs, DeepSeek-V3 offers rich technical detail,\nalbeit with some verbosity. Overall, the findings highlight the potential of\nLLMs to lower the barrier for workflow development, improve reproducibility,\nand democratize access to computational tools in bioinformatics, especially\nwhen combined with thoughtful prompt engineering.", "AI": {"tldr": "\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\u3001Gemini 2.5 Flash\u548cDeepSeek-V3\uff09\u80fd\u591f\u652f\u6301\u751f\u6210\u51c6\u786e\u3001\u5b8c\u6574\u4e14\u53ef\u7528\u7684\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u4f5c\u6d41\uff0c\u4e14\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u5e73\u53f0\uff08\u5982Galaxy\u548cNextflow\uff09\u4e0a\u8868\u73b0\u5404\u5f02\u3002\u63d0\u793a\u7b56\u7565\u5bf9\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u4fe1\u606f\u5b66\u9886\u57df\u4e13\u5bb6\u5728\u7f3a\u4e4f\u7f16\u7a0b\u6280\u80fd\u7684\u60c5\u51b5\u4e0b\u521b\u5efa\u548c\u7406\u89e3\u590d\u6742\u5de5\u4f5c\u6d41\u7684\u6311\u6218\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u964d\u4f4e\u5de5\u4f5c\u6d41\u5f00\u53d1\u95e8\u69db\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30GPT-4o\u3001Gemini 2.5 Flash\u548cDeepSeek-V3\u5728\u591a\u79cd\u4efb\u52a1\uff08\u5982SNP\u5206\u6790\u3001RNA-seq\u7b49\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4f7f\u7528\u4e13\u5bb6\u8bc4\u5ba1\u5bf9\u6bd4\u793e\u533a\u57fa\u51c6\u3002", "result": "Gemini 2.5 Flash\u5728Galaxy\u5de5\u4f5c\u6d41\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cDeepSeek-V3\u5728Nextflow\u4e2d\u8868\u73b0\u7a81\u51fa\uff1b\u63d0\u793a\u7b56\u7565\uff08\u5982\u89d2\u8272\u63d0\u793a\u548c\u601d\u7ef4\u94fe\uff09\u663e\u8457\u63d0\u5347\u8d28\u91cf\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u9002\u5f53\u63d0\u793a\u7b56\u7565\uff0c\u6709\u671b\u964d\u4f4e\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u4f5c\u6d41\u5f00\u53d1\u96be\u5ea6\uff0c\u63d0\u5347\u53ef\u91cd\u590d\u6027\uff0c\u4f7f\u66f4\u591a\u4eba\u53d7\u76ca\u4e8e\u8ba1\u7b97\u5de5\u5177\u3002"}}
{"id": "2507.20900", "pdf": "https://arxiv.org/pdf/2507.20900", "abs": "https://arxiv.org/abs/2507.20900", "authors": ["Yonghyun Kim", "Wayne Chi", "Anastasios N. Angelopoulos", "Wei-Lin Chiang", "Koichi Saito", "Shinji Watanabe", "Yuki Mitsufuji", "Chris Donahue"], "title": "Music Arena: Live Evaluation for Text-to-Music", "categories": ["cs.SD", "cs.AI", "cs.MM"], "comment": null, "summary": "We present Music Arena, an open platform for scalable human preference\nevaluation of text-to-music (TTM) models. Soliciting human preferences via\nlistening studies is the gold standard for evaluation in TTM, but these studies\nare expensive to conduct and difficult to compare, as study protocols may\ndiffer across systems. Moreover, human preferences might help researchers align\ntheir TTM systems or improve automatic evaluation metrics, but an open and\nrenewable source of preferences does not currently exist. We aim to fill these\ngaps by offering *live* evaluation for TTM. In Music Arena, real-world users\ninput text prompts of their choosing and compare outputs from two TTM systems,\nand their preferences are used to compile a leaderboard. While Music Arena\nfollows recent evaluation trends in other AI domains, we also design it with\nkey features tailored to music: an LLM-based routing system to navigate the\nheterogeneous type signatures of TTM systems, and the collection of *detailed*\npreferences including listening data and natural language feedback. We also\npropose a rolling data release policy with user privacy guarantees, providing a\nrenewable source of preference data and increasing platform transparency.\nThrough its standardized evaluation protocol, transparent data access policies,\nand music-specific features, Music Arena not only addresses key challenges in\nthe TTM ecosystem but also demonstrates how live evaluation can be thoughtfully\nadapted to unique characteristics of specific AI domains.\n  Music Arena is available at: https://music-arena.org", "AI": {"tldr": "Music Arena\u662f\u4e00\u4e2a\u5f00\u653e\u5e73\u53f0\uff0c\u7528\u4e8e\u5bf9\u6587\u672c\u5230\u97f3\u4e50\uff08TTM\uff09\u6a21\u578b\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u504f\u597d\u8bc4\u4f30\uff0c\u586b\u8865\u4e86\u5f53\u524d\u7f3a\u4e4f\u5f00\u653e\u548c\u53ef\u518d\u751f\u504f\u597d\u6570\u636e\u6e90\u7684\u7a7a\u767d\u3002", "motivation": "\u5728TTM\u9886\u57df\uff0c\u901a\u8fc7\u4eba\u7c7b\u542c\u611f\u7814\u7a76\u83b7\u53d6\u504f\u597d\u662f\u8bc4\u4f30\u7684\u9ec4\u91d1\u6807\u51c6\uff0c\u4f46\u8fd9\u4e9b\u7814\u7a76\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u5f00\u653e\u548c\u53ef\u518d\u751f\u7684\u504f\u597d\u6570\u636e\u6e90\u9650\u5236\u4e86\u7814\u7a76\u4eba\u5458\u5bf9\u9f50TTM\u7cfb\u7edf\u6216\u6539\u8fdb\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u7684\u80fd\u529b\u3002", "method": "Music Arena\u63d0\u4f9b\u5b9e\u65f6\u8bc4\u4f30\uff0c\u7528\u6237\u8f93\u5165\u6587\u672c\u63d0\u793a\u5e76\u6bd4\u8f83\u4e24\u4e2aTTM\u7cfb\u7edf\u7684\u8f93\u51fa\uff0c\u5176\u504f\u597d\u7528\u4e8e\u751f\u6210\u6392\u884c\u699c\u3002\u5e73\u53f0\u8bbe\u8ba1\u4e86\u97f3\u4e50\u7279\u5b9a\u7684\u529f\u80fd\uff0c\u5982\u57fa\u4e8eLLM\u7684\u8def\u7531\u7cfb\u7edf\u548c\u8be6\u7ec6\u504f\u597d\u6536\u96c6\u3002", "result": "\u5e73\u53f0\u901a\u8fc7\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\u3001\u900f\u660e\u6570\u636e\u8bbf\u95ee\u653f\u7b56\u548c\u97f3\u4e50\u7279\u5b9a\u529f\u80fd\uff0c\u4e0d\u4ec5\u89e3\u51b3\u4e86TTM\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u9488\u5bf9\u7279\u5b9aAI\u9886\u57df\u72ec\u7279\u7279\u6027\u8fdb\u884c\u5b9e\u65f6\u8bc4\u4f30\u3002", "conclusion": "Music Arena\u4e3aTTM\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u5b9e\u65f6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5176\u72ec\u7279\u8bbe\u8ba1\u5c55\u793a\u4e86\u5982\u4f55\u9002\u5e94\u7279\u5b9a\u9886\u57df\u7684\u8bc4\u4f30\u9700\u6c42\u3002"}}
{"id": "2507.19498", "pdf": "https://arxiv.org/pdf/2507.19498", "abs": "https://arxiv.org/abs/2507.19498", "authors": ["Yue Wu", "Xiaolan Chen", "Weiyi Zhang", "Shunming Liu", "Wing Man Rita Sum", "Xinyuan Wu", "Xianwen Shang", "Chea-su Kee", "Mingguang He", "Danli Shi"], "title": "ChatMyopia: An AI Agent for Pre-consultation Education in Primary Eye Care Settings", "categories": ["cs.HC", "cs.AI"], "comment": "35 pages, 4 figures, 1 table", "summary": "Large language models (LLMs) show promise for tailored healthcare\ncommunication but face challenges in interpretability and multi-task\nintegration particularly for domain-specific needs like myopia, and their\nreal-world effectiveness as patient education tools has yet to be demonstrated.\nHere, we introduce ChatMyopia, an LLM-based AI agent designed to address text\nand image-based inquiries related to myopia. To achieve this, ChatMyopia\nintegrates an image classification tool and a retrieval-augmented knowledge\nbase built from literature, expert consensus, and clinical guidelines. Myopic\nmaculopathy grading task, single question examination and human evaluations\nvalidated its ability to deliver personalized, accurate, and safe responses to\nmyopia-related inquiries with high scalability and interpretability. In a\nrandomized controlled trial (n=70, NCT06607822), ChatMyopia significantly\nimproved patient satisfaction compared to traditional leaflets, enhancing\npatient education in accuracy, empathy, disease awareness, and patient-eyecare\npractitioner communication. These findings highlight ChatMyopia's potential as\na valuable supplement to enhance patient education and improve satisfaction\nwith medical services in primary eye care settings.", "AI": {"tldr": "ChatMyopia\u662f\u4e00\u6b3e\u57fa\u4e8eLLM\u7684AI\u4ee3\u7406\uff0c\u7528\u4e8e\u5904\u7406\u8fd1\u89c6\u76f8\u5173\u7684\u56fe\u6587\u54a8\u8be2\uff0c\u901a\u8fc7\u6574\u5408\u56fe\u50cf\u5206\u7c7b\u5de5\u5177\u548c\u68c0\u7d22\u589e\u5f3a\u77e5\u8bc6\u5e93\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u3001\u51c6\u786e\u4e14\u5b89\u5168\u7684\u56de\u7b54\uff0c\u663e\u8457\u63d0\u5347\u60a3\u8005\u6ee1\u610f\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b9a\u5236\u5316\u533b\u7597\u6c9f\u901a\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u53ef\u89e3\u91ca\u6027\u548c\u591a\u4efb\u52a1\u96c6\u6210\uff08\u7279\u522b\u662f\u9488\u5bf9\u8fd1\u89c6\u7b49\u7279\u5b9a\u9886\u57df\u9700\u6c42\uff09\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u4e14\u5176\u4f5c\u4e3a\u60a3\u8005\u6559\u80b2\u5de5\u5177\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u672a\u5f97\u5230\u9a8c\u8bc1\u3002", "method": "\u5f00\u53d1ChatMyopia\uff0c\u6574\u5408\u56fe\u50cf\u5206\u7c7b\u5de5\u5177\u548c\u68c0\u7d22\u589e\u5f3a\u77e5\u8bc6\u5e93\uff08\u57fa\u4e8e\u6587\u732e\u3001\u4e13\u5bb6\u5171\u8bc6\u548c\u4e34\u5e8a\u6307\u5357\uff09\uff0c\u5e76\u901a\u8fc7\u8fd1\u89c6\u6027\u9ec4\u6591\u53d8\u6027\u5206\u7ea7\u4efb\u52a1\u3001\u5355\u95ee\u9898\u6d4b\u8bd5\u548c\u4eba\u7c7b\u8bc4\u4f30\u9a8c\u8bc1\u5176\u80fd\u529b\u3002", "result": "\u5728\u4e00\u9879\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff08n=70\uff09\u4e2d\uff0cChatMyopia\u663e\u8457\u63d0\u9ad8\u4e86\u60a3\u8005\u6ee1\u610f\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u51c6\u786e\u6027\u3001\u540c\u7406\u5fc3\u3001\u75be\u75c5\u610f\u8bc6\u548c\u533b\u60a3\u6c9f\u901a\u65b9\u9762\uff0c\u4f18\u4e8e\u4f20\u7edf\u5ba3\u4f20\u5355\u3002", "conclusion": "ChatMyopia\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\uff0c\u5728\u521d\u7ea7\u773c\u79d1\u62a4\u7406\u4e2d\u5177\u6709\u63d0\u5347\u60a3\u8005\u6559\u80b2\u548c\u533b\u7597\u6ee1\u610f\u5ea6\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.20514", "pdf": "https://arxiv.org/pdf/2507.20514", "abs": "https://arxiv.org/abs/2507.20514", "authors": ["Serhan Gener", "Aditya Ukarande", "Shilpa Mysore Srinivasa Murthy", "Sahil Hassan", "Joshua Mack", "Chaitali Chakrabarti", "Umit Ogras", "Ali Akoglu"], "title": "RIMMS: Runtime Integrated Memory Management System for Heterogeneous Computing", "categories": ["cs.DC"], "comment": null, "summary": "Efficient memory management in heterogeneous systems is increasingly\nchallenging due to diverse compute architectures (e.g., CPU, GPU, FPGA) and\ndynamic task mappings not known at compile time. Existing approaches often\nrequire programmers to manage data placement and transfers explicitly, or\nassume static mappings that limit portability and scalability. This paper\nintroduces RIMMS (Runtime Integrated Memory Management System), a lightweight,\nruntime-managed, hardware-agnostic memory abstraction layer that decouples\napplication development from low-level memory operations. RIMMS transparently\ntracks data locations, manages consistency, and supports efficient memory\nallocation across heterogeneous compute elements without requiring\nplatform-specific tuning or code modifications. We integrate RIMMS into a\nbaseline runtime and evaluate with complete radar signal processing\napplications across CPU+GPU and CPU+FPGA platforms. RIMMS delivers up to 2.43X\nspeedup on GPU-based and 1.82X on FPGA-based systems over the baseline.\nCompared to IRIS, a recent heterogeneous runtime system, RIMMS achieves up to\n3.08X speedup and matches the performance of native CUDA implementations while\nsignificantly reducing programming complexity. Despite operating at a higher\nabstraction level, RIMMS incurs only 1-2 cycles of overhead per memory\nmanagement call, making it a low-cost solution. These results demonstrate\nRIMMS's ability to deliver high performance and enhanced programmer\nproductivity in dynamic, real-world heterogeneous environments.", "AI": {"tldr": "RIMMS\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u8fd0\u884c\u65f6\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u63d0\u9ad8\u5f02\u6784\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u7f16\u7a0b\u6548\u7387\u3002", "motivation": "\u5f02\u6784\u7cfb\u7edf\u7684\u5185\u5b58\u7ba1\u7406\u9762\u4e34\u591a\u6837\u5316\u7684\u8ba1\u7b97\u67b6\u6784\u548c\u52a8\u6001\u4efb\u52a1\u6620\u5c04\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u663e\u5f0f\u7ba1\u7406\u6216\u5047\u8bbe\u9759\u6001\u6620\u5c04\uff0c\u9650\u5236\u4e86\u4fbf\u643a\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "RIMMS\u901a\u8fc7\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u786c\u4ef6\u65e0\u5173\u7684\u5185\u5b58\u62bd\u8c61\u5c42\uff0c\u900f\u660e\u8ddf\u8e2a\u6570\u636e\u4f4d\u7f6e\u3001\u7ba1\u7406\u4e00\u81f4\u6027\u5e76\u652f\u6301\u9ad8\u6548\u5185\u5b58\u5206\u914d\uff0c\u65e0\u9700\u5e73\u53f0\u7279\u5b9a\u8c03\u6574\u6216\u4ee3\u7801\u4fee\u6539\u3002", "result": "\u5728CPU+GPU\u548cCPU+FPGA\u5e73\u53f0\u4e0a\uff0cRIMMS\u5206\u522b\u5e26\u6765\u6700\u9ad82.43\u500d\u548c1.82\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edfIRIS\u63d0\u5347\u4e863.08\u500d\uff0c\u4e14\u7f16\u7a0b\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "RIMMS\u5728\u52a8\u6001\u5f02\u6784\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u548c\u7f16\u7a0b\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6781\u4f4e\u7684\u7ba1\u7406\u5f00\u9500\u3002"}}
{"id": "2507.20524", "pdf": "https://arxiv.org/pdf/2507.20524", "abs": "https://arxiv.org/abs/2507.20524", "authors": ["Zhang Liu", "Lianfen Huang", "Zhibin Gao", "Xianbin Wang", "Dusit Niyato", "Xuemin", "Shen"], "title": "A Lyapunov-Guided Diffusion-Based Reinforcement Learning Approach for UAV-Assisted Vehicular Networks with Delayed CSI Feedback", "categories": ["cs.NI"], "comment": "13 pages, 11 figures, transactions paper", "summary": "Low altitude uncrewed aerial vehicles (UAVs) are expected to facilitate the\ndevelopment of aerial-ground integrated intelligent transportation systems and\nunlocking the potential of the emerging low-altitude economy. However, several\ncritical challenges persist, including the dynamic optimization of network\nresources and UAV trajectories, limited UAV endurance, and imperfect channel\nstate information (CSI). In this paper, we offer new insights into low-altitude\neconomy networking by exploring intelligent UAV-assisted vehicle-to-everything\ncommunication strategies aligned with UAV energy efficiency. Particularly, we\nformulate an optimization problem of joint channel allocation, power control,\nand flight altitude adjustment in UAV-assisted vehicular networks. Taking CSI\nfeedback delay into account, our objective is to maximize the vehicle-to-UAV\ncommunication sum rate while satisfying the UAV's long-term energy constraint.\nTo this end, we first leverage Lyapunov optimization to decompose the original\nlong-term problem into a series of per-slot deterministic subproblems. We then\npropose a diffusion-based deep deterministic policy gradient (D3PG) algorithm,\nwhich innovatively integrates diffusion models to determine optimal channel\nallocation, power control, and flight altitude adjustment decisions. Through\nextensive simulations using real-world vehicle mobility traces, we demonstrate\nthe superior performance of the proposed D3PG algorithm compared to existing\nbenchmark solutions.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4f4e\u7a7a\u65e0\u4eba\u673a\uff08UAV\uff09\u5728\u8f66\u8054\u7f51\u4e2d\u7684\u667a\u80fd\u901a\u4fe1\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u8054\u5408\u4f18\u5316\u4fe1\u9053\u5206\u914d\u3001\u529f\u7387\u63a7\u5236\u548c\u98de\u884c\u9ad8\u5ea6\u7684\u65b9\u6848\uff0c\u5e76\u901a\u8fc7D3PG\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4f4e\u7a7a\u65e0\u4eba\u673a\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u9762\u4e34\u52a8\u6001\u8d44\u6e90\u4f18\u5316\u3001\u7eed\u822a\u80fd\u529b\u6709\u9650\u548c\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u5584\u7b49\u6311\u6218\u3002", "method": "\u5229\u7528Lyapunov\u4f18\u5316\u5c06\u957f\u671f\u95ee\u9898\u5206\u89e3\u4e3a\u9010\u65f6\u6bb5\u7684\u5b50\u95ee\u9898\uff0c\u5e76\u521b\u65b0\u6027\u5730\u7ed3\u5408\u6269\u6563\u6a21\u578b\u63d0\u51faD3PG\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0cD3PG\u7b97\u6cd5\u5728\u771f\u5b9e\u8f66\u8f86\u79fb\u52a8\u6570\u636e\u4e0b\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u65b9\u6cd5\u4e3a\u4f4e\u7a7a\u7ecf\u6d4e\u7f51\u7edc\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u80fd\u91cf\u4f18\u5316\u7684\u901a\u4fe1\u7b56\u7565\u3002"}}
{"id": "2507.20135", "pdf": "https://arxiv.org/pdf/2507.20135", "abs": "https://arxiv.org/abs/2507.20135", "authors": ["Ganesh Pai"], "title": "Relating System Safety and Machine Learnt Model Performance", "categories": ["cs.SE"], "comment": "17 pages, 4 figures, Expanded version of the paper: G. Pai, \"Deriving\n  Safety-related Performance Requirements for Machine Learnt Aeronautical\n  Applications\", Proceedings of the 44th AIAA DATC/IEEE Digital Avionics\n  Systems Conference (DASC 2025)", "summary": "The prediction quality of machine learnt models and the functionality they\nultimately enable (e.g., object detection), is typically evaluated using a\nvariety of quantitative metrics that are specified in the associated model\nperformance requirements. When integrating such models into aeronautical\napplications, a top-down safety assessment process must influence both the\nmodel performance metrics selected, and their acceptable range of values.\nOften, however, the relationship of system safety objectives to model\nperformance requirements and the associated metrics is unclear. Using an\nexample of an aircraft emergency braking system containing a machine learnt\ncomponent (MLC) responsible for object detection and alerting, this paper first\ndescribes a simple abstraction of the required MLC behavior. Then, based on\nthat abstraction, an initial method is given to derive the minimum\nsafety-related performance requirements, the associated metrics, and their\ntargets for the both MLC and its underlying deep neural network, such that they\nmeet the quantitative safety objectives obtained from the safety assessment\nprocess. We give rationale as to why the proposed method should be considered\nvalid, also clarifying the assumptions made, the constraints on applicability,\nand the implications for verification.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b89\u5168\u8bc4\u4f30\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u786e\u5b9a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u822a\u7a7a\u5e94\u7528\u4e2d\u6ee1\u8db3\u5b89\u5168\u76ee\u6807\u7684\u6700\u4f4e\u6027\u80fd\u8981\u6c42\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u660e\u786e\u7cfb\u7edf\u5b89\u5168\u76ee\u6807\u4e0e\u6a21\u578b\u6027\u80fd\u8981\u6c42\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u5728\u822a\u7a7a\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u4e00\u4e2a\u98de\u673a\u7d27\u6025\u5236\u52a8\u7cfb\u7edf\u7684\u6848\u4f8b\uff0c\u62bd\u8c61\u51fa\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u7684\u884c\u4e3a\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u5bfc\u6700\u4f4e\u5b89\u5168\u76f8\u5173\u6027\u80fd\u8981\u6c42\u53ca\u5176\u76ee\u6807\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u660e\u786e\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u53ca\u5176\u5e95\u5c42\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5b89\u5168\u6027\u80fd\u8981\u6c42\uff0c\u5e76\u9a8c\u8bc1\u5176\u5408\u7406\u6027\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u8be5\u65b9\u6cd5\u5728\u822a\u7a7a\u5e94\u7528\u4e2d\u9a8c\u8bc1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b89\u5168\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u5176\u9002\u7528\u6027\u9650\u5236\u548c\u9a8c\u8bc1\u610f\u4e49\u3002"}}
{"id": "2507.19500", "pdf": "https://arxiv.org/pdf/2507.19500", "abs": "https://arxiv.org/abs/2507.19500", "authors": ["Omkar Suresh Hatti"], "title": "Gaze-Aware AI: Mathematical modeling of epistemic experience of the Marginalized for Human-Computer Interaction & AI Systems", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The proliferation of artificial intelligence provides an opportunity to\ncreate psychological spaciousness in society. Spaciousness is defined as the\nability to hold diverse interpersonal interactions and forms the basis for\nvulnerability that leads to authenticity that leads to prosocial behaviors and\nthus to societal harmony. This paper demonstrates an attempt to quantify, the\nhuman conditioning to subconsciously modify authentic self-expression to fit\nthe norms of the dominant culture. Gaze is explored across various marginalized\nand intersectional groups, using concepts from postmodern philosophy and\npsychology. The effects of gaze are studied through analyzing a few redacted\nReddit posts, only to be discussed in discourse and not endorsement. A\nmathematical formulation for the Gaze Pressure Index (GPI)-Diff Composite\nMetric is presented to model the analysis of two sets of conversational spaces\nin relation to one another. The outcome includes an equation to train Large\nLanguage Models (LLMs) - the working mechanism of AI products such as Chat-GPT;\nand an argument for affirming and inclusive HCI, based on the equation, is\npresented. The argument is supported by a few principles of Neuro-plasticity,\nThe brain's lifelong capacity to rewire.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u901a\u8fc7\u91cf\u5316\u4eba\u7c7b\u6f5c\u610f\u8bc6\u4e2d\u4e3a\u9002\u5e94\u4e3b\u6d41\u6587\u5316\u800c\u8c03\u6574\u81ea\u6211\u8868\u8fbe\u7684\u884c\u4e3a\uff0c\u63d0\u51fa\u4e00\u79cdGaze Pressure Index\u6a21\u578b\uff0c\u5e76\u4e3a\u5305\u5bb9\u6027\u4eba\u673a\u4ea4\u4e92\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5229\u7528AI\u6280\u672f\u5206\u6790\u4eba\u7c7b\u5728\u591a\u5143\u4e92\u52a8\u4e2d\u7684\u5fc3\u7406\u7a7a\u95f4\uff0c\u63ed\u793a\u6f5c\u610f\u8bc6\u4e2d\u56e0\u4e3b\u6d41\u6587\u5316\u538b\u529b\u800c\u8c03\u6574\u81ea\u6211\u8868\u8fbe\u7684\u73b0\u8c61\uff0c\u4ece\u800c\u4fc3\u8fdb\u793e\u4f1a\u548c\u8c10\u3002", "method": "\u901a\u8fc7\u540e\u73b0\u4ee3\u54f2\u5b66\u548c\u5fc3\u7406\u5b66\u6982\u5ff5\uff0c\u5206\u6790\u8fb9\u7f18\u5316\u7fa4\u4f53\u5728Reddit\u5e16\u5b50\u4e2d\u7684\u4e92\u52a8\uff0c\u63d0\u51faGPI-Diff\u590d\u5408\u5ea6\u91cf\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86GPI-Diff\u6a21\u578b\u7528\u4e8e\u91cf\u5316\u51dd\u89c6\u538b\u529b\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u5305\u5bb9\u6027\u4eba\u673a\u4ea4\u4e92\u8bbe\u8ba1\u539f\u5219\uff0c\u652f\u6301\u795e\u7ecf\u53ef\u5851\u6027\u7406\u8bba\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u6280\u672f\u5728\u4fc3\u8fdb\u5fc3\u7406\u7a7a\u95f4\u548c\u5305\u5bb9\u6027\u4ea4\u4e92\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u5e76\u9a8c\u8bc1\u5176\u5b9e\u9645\u6548\u679c\u3002"}}
{"id": "2507.19635", "pdf": "https://arxiv.org/pdf/2507.19635", "abs": "https://arxiv.org/abs/2507.19635", "authors": ["Zain Asgar", "Michelle Nguyen", "Sachin Katti"], "title": "Efficient and Scalable Agentic AI with Heterogeneous Systems", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "Early access preprint", "summary": "AI agents are emerging as a dominant workload in a wide range of\napplications, promising to be the vehicle that delivers the promised benefits\nof AI to enterprises and consumers. Unlike conventional software or static\ninference, agentic workloads are dynamic and structurally complex. Often these\nagents are directed graphs of compute and IO operations that span multi-modal\ndata input and conversion), data processing and context gathering (e.g vector\nDB lookups), multiple LLM inferences, tool calls, etc. To scale AI agent usage,\nwe need efficient and scalable deployment and agent-serving infrastructure.\n  To tackle this challenge, in this paper, we present a system design for\ndynamic orchestration of AI agent workloads on heterogeneous compute\ninfrastructure spanning CPUs and accelerators, both from different vendors and\nacross different performance tiers within a single vendor. The system delivers\nseveral building blocks: a framework for planning and optimizing agentic AI\nexecution graphs using cost models that account for compute, memory, and\nbandwidth constraints of different HW; a MLIR based representation and\ncompilation system that can decompose AI agent execution graphs into granular\noperators and generate code for different HW options; and a dynamic\norchestration system that can place the granular components across a\nheterogeneous compute infrastructure and stitch them together while meeting an\nend-to-end SLA. Our design performs a systems level TCO optimization and\npreliminary results show that leveraging a heterogeneous infrastructure can\ndeliver significant TCO benefits. A preliminary surprising finding is that for\nsome workloads a heterogeneous combination of older generation GPUs with newer\naccelerators can deliver similar TCO as the latest generation homogenous GPU\ninfrastructure design, potentially extending the life of deployed\ninfrastructure.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7f16\u6392AI\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4f18\u5316\u5f02\u6784\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u4f7f\u7528\uff0c\u663e\u8457\u964d\u4f4e\u603b\u62e5\u6709\u6210\u672c\uff08TCO\uff09\u3002", "motivation": "AI\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u52a8\u6001\u4e14\u7ed3\u6784\u590d\u6742\uff0c\u9700\u8981\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u5176\u90e8\u7f72\u548c\u8fd0\u884c\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u62ec\u89c4\u5212\u6846\u67b6\u3001MLIR\u8868\u793a\u4e0e\u7f16\u8bd1\u7cfb\u7edf\u53ca\u52a8\u6001\u7f16\u6392\u7cfb\u7edf\u5728\u5185\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u4f18\u5316\u5f02\u6784\u8ba1\u7b97\u8d44\u6e90\u7684\u4f7f\u7528\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5f02\u6784\u57fa\u7840\u8bbe\u65bd\u80fd\u663e\u8457\u964d\u4f4eTCO\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u65e7\u786c\u4ef6\u4e0e\u65b0\u52a0\u901f\u5668\u7ec4\u5408\u53ef\u5ab2\u7f8e\u6700\u65b0\u540c\u6784GPU\u8bbe\u8ba1\u3002", "conclusion": "\u5f02\u6784\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u53ef\u6709\u6548\u652f\u6301AI\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u540c\u65f6\u51cf\u5c11\u6210\u672c\uff0c\u5ef6\u957f\u73b0\u6709\u786c\u4ef6\u5bff\u547d\u3002"}}
{"id": "2507.20806", "pdf": "https://arxiv.org/pdf/2507.20806", "abs": "https://arxiv.org/abs/2507.20806", "authors": ["Yunming Xiao", "Peizhi Liu", "Ruijie Yu", "Chenkai Weng", "Matteo Varvello", "Aleksandar Kuzmanovic"], "title": "Collusion Resistant DNS With Private Information Retrieval", "categories": ["cs.NI", "cs.CR"], "comment": null, "summary": "There has been a growing interest in Internet user privacy, demonstrated by\nthe popularity of privacy-preserving products such as Telegram and Brave, and\nthe widespread adoption of HTTPS. The Domain Name System (DNS) is a key\ncomponent of Internet-based communication and its privacy has been neglected\nfor years. Recently, DNS over HTTPS (DoH) has improved the situation by fixing\nthe issue of in-path middleboxes. Further progress has been made with\nproxy-based solutions such as Oblivious DoH (ODoH), which separate a user's\nidentity from their DNS queries. However, these solutions rely on non-collusion\nassumptions between DNS resolvers and proxies -- an assumption difficult to\nguarantee in practice. To address this, we explore integrating single-server\nPrivate Information Retrieval (PIR) into DNS to enable encrypted query\nprocessing without relying on trust assumptions. However, applying PIR to DNS\nis challenging due to its hierarchical nature -- particularly, interactions\nwith recursive resolvers can still leak information. Navigating performance and\nprivacy trade-offs, we propose PDNS, a DNS extension leveraging single-server\nPIR to strengthen privacy guarantees. We have implemented a prototype of PDNS\nand compared its performance against state-of-the-art solutions via\ntrace-driven experiments. The results show that PDNS achieves acceptable\nperformance (2x faster than DoH over Tor with similar privacy guarantees) and\nstrong privacy guarantees today, mainly at the cost of its scalability, which\nspecialized hardware for PIR can address in the near future.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u670d\u52a1\u5668\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\uff08PIR\uff09\u7684DNS\u6269\u5c55PDNS\uff0c\u7528\u4e8e\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u4f46\u6269\u5c55\u6027\u53d7\u9650\u3002", "motivation": "DNS\u9690\u79c1\u95ee\u9898\u957f\u671f\u88ab\u5ffd\u89c6\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4f9d\u8d56\u4e8e\u96be\u4ee5\u4fdd\u8bc1\u7684\u975e\u5171\u8c0b\u5047\u8bbe\uff0c\u4e9f\u9700\u65b0\u6280\u672f\u4ee5\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u63d0\u51faPDNS\uff0c\u901a\u8fc7\u5355\u670d\u52a1\u5668PIR\u6280\u672f\u5b9e\u73b0\u52a0\u5bc6\u67e5\u8be2\u5904\u7406\uff0c\u907f\u514d\u4fe1\u4efb\u5047\u8bbe\uff0c\u5e76\u89e3\u51b3\u4e86DNS\u5c42\u6b21\u7ed3\u6784\u5e26\u6765\u7684\u4fe1\u606f\u6cc4\u6f0f\u95ee\u9898\u3002", "result": "PDNS\u539f\u578b\u6027\u80fd\u4f18\u4e8eDoH over Tor\uff08\u5feb2\u500d\uff09\uff0c\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u6269\u5c55\u6027\u53d7\u9650\u9700\u4f9d\u8d56\u4e13\u7528\u786c\u4ef6\u3002", "conclusion": "PDNS\u4e3aDNS\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u4e13\u7528\u786c\u4ef6\u89e3\u51b3\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2507.20218", "pdf": "https://arxiv.org/pdf/2507.20218", "abs": "https://arxiv.org/abs/2507.20218", "authors": ["Muhammad Azeem Akbar", "Arif Ali Khan", "Saima Rafi", "Damian Kedziora", "Sami Hyrynsalmi"], "title": "Strategic Motivators for Ethical AI System Development: An Empirical and Holistic Model", "categories": ["cs.SE"], "comment": null, "summary": "Artificial Intelligence (AI) presents transformative opportunities for\nindustries and society, but its responsible development is essential to prevent\nunintended consequences. Ethically sound AI systems demand strategic planning,\nstrong governance, and an understanding of the key drivers that promote\nresponsible practices. This study aims to identify and prioritize the\nmotivators that drive the ethical development of AI systems. A Multivocal\nLiterature Review (MLR) and a questionnaire-based survey were conducted to\ncapture current practices in ethical AI. We applied Interpretive Structure\nModeling (ISM) to explore the relationships between motivator categories,\nfollowed by MICMAC analysis to classify them by their driving and dependence\npower. Fuzzy TOPSIS was used to rank these motivators by importance. Twenty key\nmotivators were identified and grouped into eight categories: Human Resource,\nKnowledge Integration, Coordination, Project Administration, Standards,\nTechnology Factor, Stakeholders, and Strategy & Matrices. ISM results showed\nthat 'Human Resource' and 'Coordination' heavily influence other factors.\nMICMAC analysis placed categories like Human Resource (CA1), Coordination\n(CA3), Stakeholders (CA7), and Strategy & Matrices (CA8) in the independent\ncluster, indicating high driving but low dependence power. Fuzzy TOPSIS ranked\nmotivators such as promoting team diversity, establishing AI governance bodies,\nappointing oversight leaders, and ensuring data privacy as most critical. To\nsupport ethical AI adoption, organizations should align their strategies with\nthese motivators and integrate them into their policies, governance models, and\ndevelopment frameworks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7MLR\u548c\u95ee\u5377\u8c03\u67e5\u8bc6\u522b\u4e86\u63a8\u52a8AI\u4f26\u7406\u53d1\u5c55\u768420\u4e2a\u5173\u952e\u52a8\u56e0\uff0c\u5206\u4e3a8\u7c7b\uff0c\u5e76\u5229\u7528ISM\u548cMICMAC\u5206\u6790\u5176\u5173\u7cfb\u4e0e\u5206\u7c7b\uff0c\u6700\u540e\u7528Fuzzy TOPSIS\u6392\u5e8f\u91cd\u8981\u6027\u3002", "motivation": "\u786e\u4fddAI\u7684\u8d1f\u8d23\u4efb\u5f00\u53d1\uff0c\u9632\u6b62\u8d1f\u9762\u540e\u679c\uff0c\u9700\u7406\u89e3\u5e76\u4f18\u5148\u8003\u8651\u63a8\u52a8\u4f26\u7406\u5b9e\u8df5\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u91c7\u7528MLR\u3001\u95ee\u5377\u8c03\u67e5\u3001ISM\u3001MICMAC\u5206\u6790\u548cFuzzy TOPSIS\u65b9\u6cd5\uff0c\u7814\u7a76\u52a8\u56e0\u53ca\u5176\u4f18\u5148\u7ea7\u3002", "result": "\u53d1\u73b0'\u4eba\u529b\u8d44\u6e90'\u548c'\u534f\u8c03'\u662f\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u5173\u952e\u52a8\u56e0\u5305\u62ec\u4fc3\u8fdb\u56e2\u961f\u591a\u6837\u6027\u3001\u5efa\u7acb\u6cbb\u7406\u673a\u6784\u7b49\u3002", "conclusion": "\u7ec4\u7ec7\u5e94\u5c06\u8fd9\u4e9b\u52a8\u56e0\u878d\u5165\u6218\u7565\u3001\u653f\u7b56\u53ca\u6cbb\u7406\u6a21\u578b\u4e2d\uff0c\u4ee5\u652f\u6301\u4f26\u7406AI\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.20047", "pdf": "https://arxiv.org/pdf/2507.20047", "abs": "https://arxiv.org/abs/2507.20047", "authors": ["MohammadHossein Bateni", "Laxman Dhulipala", "Willem Fletcher", "Kishen N Gowda", "D Ellis Hershkowitz", "Rajesh Jayaram", "Jakub \u0141\u0105cki"], "title": "Parallel Hierarchical Agglomerative Clustering in Low Dimensions", "categories": ["cs.DS", "cs.CC", "cs.DC"], "comment": null, "summary": "Hierarchical Agglomerative Clustering (HAC) is an extensively studied and\nwidely used method for hierarchical clustering in $\\mathbb{R}^k$ based on\nrepeatedly merging the closest pair of clusters according to an input linkage\nfunction $d$. Highly parallel (i.e., NC) algorithms are known for\n$(1+\\epsilon)$-approximate HAC (where near-minimum rather than minimum pairs\nare merged) for certain linkage functions that monotonically increase as merges\nare performed. However, no such algorithms are known for many important but\nnon-monotone linkage functions such as centroid and Ward's linkage.\n  In this work, we show that a general class of non-monotone linkage functions\n-- which include centroid and Ward's distance -- admit efficient NC algorithms\nfor $(1+\\epsilon)$-approximate HAC in low dimensions. Our algorithms are based\non a structural result which may be of independent interest: the height of the\nhierarchy resulting from any constant-approximate HAC on $n$ points for this\nclass of linkage functions is at most $\\operatorname{poly}(\\log n)$ as long as\n$k = O(\\log \\log n / \\log \\log \\log n)$. Complementing our upper bounds, we\nshow that NC algorithms for HAC with these linkage functions in\n\\emph{arbitrary} dimensions are unlikely to exist by showing that HAC is\nCC-hard when $d$ is centroid distance and $k = n$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u975e\u5355\u8c03\u94fe\u63a5\u51fd\u6570\uff08\u5982\u8d28\u5fc3\u548cWard\u8ddd\u79bb\uff09\u7684\u5c42\u6b21\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5728\u4f4e\u7ef4\u5ea6\u4e0b\u7684\u9ad8\u6548NC\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u4efb\u610f\u7ef4\u5ea6\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u73b0\u6709\u9ad8\u6548\u5e76\u884c\u7b97\u6cd5\u65e0\u6cd5\u5904\u7406\u975e\u5355\u8c03\u94fe\u63a5\u51fd\u6570\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u8d28\u5fc3\u548cWard\u8ddd\u79bb\u7b49\u91cd\u8981\u4f46\u975e\u5355\u8c03\u7684\u94fe\u63a5\u51fd\u6570\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u7ed3\u6784\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5728\u4f4e\u7ef4\u5ea6\u4e0b\uff0c\u5bf9\u4e8e\u4e00\u7c7b\u975e\u5355\u8c03\u94fe\u63a5\u51fd\u6570\uff0c\u53ef\u4ee5\u6784\u5efa\u9ad8\u5ea6\u4e3a\u5bf9\u6570\u591a\u8fb9\u5f62\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u4ece\u800c\u8bbe\u8ba1\u51fa\u9ad8\u6548\u7684NC\u7b97\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u7b97\u6cd5\u5728\u4f4e\u7ef4\u5ea6\u4e0b\u9002\u7528\u4e8e\u975e\u5355\u8c03\u94fe\u63a5\u51fd\u6570\uff0c\u800c\u5728\u4efb\u610f\u7ef4\u5ea6\u4e0b\uff0c\u6b64\u7c7b\u95ee\u9898\u7684NC\u7b97\u6cd5\u53ef\u80fd\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u6027\u969c\u788d\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u5c3d\u7ba1\u5728\u4f4e\u7ef4\u5ea6\u4e0b\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u9ad8\u7ef4\u5ea6\u4e0b\uff0c\u5c42\u6b21\u805a\u7c7b\u95ee\u9898\u7684\u5e76\u884c\u89e3\u51b3\u65b9\u6848\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002"}}
{"id": "2507.20871", "pdf": "https://arxiv.org/pdf/2507.20871", "abs": "https://arxiv.org/abs/2507.20871", "authors": ["Wenxuan Ye", "Xueli An", "Junfan Wang", "Xueqiang Yan", "Georg Carle"], "title": "\\textit{FedABC}: Attention-Based Client Selection for Federated Learning with Long-Term View", "categories": ["cs.NI", "cs.LG"], "comment": "Accepted to ICC 2025", "summary": "Native AI support is a key objective in the evolution of 6G networks, with\nFederated Learning (FL) emerging as a promising paradigm. FL allows\ndecentralized clients to collaboratively train an AI model without directly\nsharing their data, preserving privacy. Clients train local models on private\ndata and share model updates, which a central server aggregates to refine the\nglobal model and redistribute it for the next iteration. However, client data\nheterogeneity slows convergence and reduces model accuracy, and frequent client\nparticipation imposes communication and computational burdens. To address these\nchallenges, we propose \\textit{FedABC}, an innovative client selection\nalgorithm designed to take a long-term view in managing data heterogeneity and\noptimizing client participation. Inspired by attention mechanisms,\n\\textit{FedABC} prioritizes informative clients by evaluating both model\nsimilarity and each model's unique contributions to the global model. Moreover,\nconsidering the evolving demands of the global model, we formulate an\noptimization problem to guide \\textit{FedABC} throughout the training process.\nFollowing the ``later-is-better\" principle, \\textit{FedABC} adaptively adjusts\nthe client selection threshold, encouraging greater participation in later\ntraining stages. Extensive simulations on CIFAR-10 demonstrate that\n\\textit{FedABC} significantly outperforms existing approaches in model accuracy\nand client participation efficiency, achieving comparable performance with 32\\%\nfewer clients than the classical FL algorithm \\textit{FedAvg}, and 3.5\\% higher\naccuracy with 2\\% fewer clients than the state-of-the-art. This work marks a\nstep toward deploying FL in heterogeneous, resource-constrained environments,\nthereby supporting native AI capabilities in 6G networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedABC\u7684\u521b\u65b0\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5f02\u6784\u6027\u548c\u5ba2\u6237\u7aef\u53c2\u4e0e\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u51c6\u786e\u6027\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u57286G\u7f51\u7edc\u4e2d\u5b9e\u73b0\u539f\u751fAI\u652f\u6301\u7684\u9700\u6c42\uff0c\u4ee5\u53ca\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u8d28\u6027\u548c\u9891\u7e41\u5ba2\u6237\u7aef\u53c2\u4e0e\u5e26\u6765\u7684\u6311\u6218\u4fc3\u4f7f\u4e86\u8fd9\u4e00\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684FedABC\u7b97\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u76f8\u4f3c\u6027\u548c\u5ba2\u6237\u7aef\u5bf9\u5168\u5c40\u6a21\u578b\u7684\u8d21\u732e\u6765\u4f18\u5316\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u5e76\u6839\u636e\u201c\u540e\u671f\u66f4\u4f18\u201d\u539f\u5219\u81ea\u9002\u5e94\u8c03\u6574\u9009\u62e9\u9608\u503c\u3002", "result": "\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedABC\u6bd4\u7ecf\u5178\u7b97\u6cd5FedAvg\u4f7f\u752832%\u66f4\u5c11\u7684\u5ba2\u6237\u7aef\u8fbe\u5230\u76f8\u540c\u6027\u80fd\uff0c\u6bd4\u73b0\u6709\u6700\u4f18\u7b97\u6cd5\u51cf\u5c112%\u5ba2\u6237\u7aef\u5e76\u63d0\u53473.5%\u51c6\u786e\u7387\u3002", "conclusion": "FedABC\u4e3a\u89e3\u51b3\u5f02\u6784\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u8054\u90a6\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e866G\u7f51\u7edc\u4e2dAI\u80fd\u529b\u7684\u5b9e\u73b0\u3002"}}
{"id": "2507.20358", "pdf": "https://arxiv.org/pdf/2507.20358", "abs": "https://arxiv.org/abs/2507.20358", "authors": ["Tanni Dev", "Sayma Sultana", "Amiangshu Bosu"], "title": "Beyond Binary Moderation: Identifying Fine-Grained Sexist and Misogynistic Behavior on GitHub with Large Language Models", "categories": ["cs.SE"], "comment": "The 19th ACM/IEEE International Symposium on Empirical Software\n  Engineering and Measurement", "summary": "Background: Sexist and misogynistic behavior significantly hinders inclusion\nin technical communities like GitHub, causing developers, especially\nminorities, to leave due to subtle biases and microaggressions. Current\nmoderation tools primarily rely on keyword filtering or binary classifiers,\nlimiting their ability to detect nuanced harm effectively.\n  Aims: This study introduces a fine-grained, multi-class classification\nframework that leverages instruction-tuned Large Language Models (LLMs) to\nidentify twelve distinct categories of sexist and misogynistic comments on\nGitHub.\n  Method: We utilized an instruction-tuned LLM-based framework with systematic\nprompt refinement across 20 iterations, evaluated on 1,440 labeled GitHub\ncomments across twelve sexism/misogyny categories. Model performances were\nrigorously compared using precision, recall, F1-score, and the Matthews\nCorrelation Coefficient (MCC).\n  Results: Our optimized approach (GPT-4o with Prompt 19) achieved an MCC of\n0.501, significantly outperforming baseline approaches. While this model had\nlow false positives, it struggled to interpret nuanced, context-dependent\nsexism and misogyny reliably.\n  Conclusion: Well-designed prompts with clear definitions and structured\noutputs significantly improve the accuracy and interpretability of sexism\ndetection, enabling precise and practical moderation on developer platforms\nlike GitHub.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u7c7b\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4bGitHub\u4e0a\u7684\u6027\u522b\u6b67\u89c6\u548c\u538c\u5973\u8bc4\u8bba\uff0c\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5173\u952e\u8bcd\u8fc7\u6ee4\u6216\u4e8c\u5143\u5206\u7c7b\u5de5\u5177\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u5fae\u5999\u7684\u6709\u5bb3\u884c\u4e3a\uff0c\u5f71\u54cd\u4e86\u6280\u672f\u793e\u533a\u7684\u5305\u5bb9\u6027\u3002", "method": "\u91c7\u7528\u6307\u4ee4\u8c03\u4f18\u7684LLM\u6846\u67b6\uff0c\u901a\u8fc720\u6b21\u7cfb\u7edf\u63d0\u793a\u4f18\u5316\uff0c\u8bc4\u4f301440\u6761\u6807\u8bb0\u8bc4\u8bba\u3002", "result": "\u4f18\u5316\u540e\u7684\u65b9\u6cd5\uff08GPT-4o\u4e0ePrompt 19\uff09MCC\u4e3a0.501\uff0c\u5047\u9633\u6027\u4f4e\uff0c\u4f46\u5bf9\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u6027\u522b\u6b67\u89c6\u8bc6\u522b\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u80fd\u663e\u8457\u63d0\u9ad8\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u52a9\u529b\u5e73\u53f0\u7cbe\u51c6\u5ba1\u6838\u3002"}}
{"id": "2507.19736", "pdf": "https://arxiv.org/pdf/2507.19736", "abs": "https://arxiv.org/abs/2507.19736", "authors": ["Johannes Y. Lee", "Derek Xiao", "Shreyas Kaasyap", "Nima R. Hadidi", "John L. Zhou", "Jacob Cunningham", "Rakshith R. Gore", "Deniz O. Eren", "Jonathan C. Kao"], "title": "LowKeyEMG: Electromyographic typing with a reduced keyset", "categories": ["cs.HC", "eess.SP"], "comment": "11+3 pages, 5 main figures, 2 supplementary tables, 4 supplementary\n  figures", "summary": "We introduce LowKeyEMG, a real-time human-computer interface that enables\nefficient text entry using only 7 gesture classes decoded from surface\nelectromyography (sEMG). Prior work has attempted full-alphabet decoding from\nsEMG, but decoding large character sets remains unreliable, especially for\nindividuals with motor impairments. Instead, LowKeyEMG reduces the English\nalphabet to 4 gesture keys, with 3 more for space and system interaction, to\nreliably translate simple one-handed gestures into text, leveraging the\nrecurrent transformer-based language model RWKV for efficient computation. In\nreal-time experiments, participants achieved average one-handed keyboardless\ntyping speeds of 23.3 words per minute with LowKeyEMG, and improved gesture\nefficiency by 17% (relative to typed phrase length). When typing with only 7\nkeys, LowKeyEMG can achieve 98.2% top-3 word accuracy, demonstrating that this\nlow-key typing paradigm can maintain practical communication rates. Our results\nhave implications for assistive technologies and any interface where input\nbandwidth is constrained.", "AI": {"tldr": "LowKeyEMG\u662f\u4e00\u79cd\u57fa\u4e8esEMG\u7684\u5b9e\u65f6\u4eba\u673a\u754c\u9762\uff0c\u901a\u8fc77\u79cd\u624b\u52bf\u5b9e\u73b0\u9ad8\u6548\u7684\u6587\u672c\u8f93\u5165\uff0c\u9002\u7528\u4e8e\u8fd0\u52a8\u53d7\u635f\u7528\u6237\u3002", "motivation": "\u89e3\u51b3\u5168\u5b57\u6bcd\u89e3\u7801sEMG\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5bf9\u8fd0\u52a8\u53d7\u635f\u4e2a\u4f53\u3002", "method": "\u5c06\u82f1\u8bed\u5b57\u6bcd\u8868\u7b80\u5316\u4e3a4\u79cd\u624b\u52bf\u952e\uff0c\u7ed3\u54083\u79cd\u7cfb\u7edf\u4ea4\u4e92\u952e\uff0c\u5229\u7528RWKV\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7528\u6237\u5355\u624b\u6253\u5b57\u901f\u5ea6\u8fbe23.3 WPM\uff0c\u624b\u52bf\u6548\u7387\u63d0\u9ad817%\uff0c98.2%\u7684top-3\u5355\u8bcd\u51c6\u786e\u7387\u3002", "conclusion": "\u4f4e\u952e\u6253\u5b57\u6a21\u5f0f\u9002\u7528\u4e8e\u8f85\u52a9\u6280\u672f\u548c\u8f93\u5165\u5e26\u5bbd\u53d7\u9650\u7684\u754c\u9762\u3002"}}
{"id": "2507.20051", "pdf": "https://arxiv.org/pdf/2507.20051", "abs": "https://arxiv.org/abs/2507.20051", "authors": ["Weicong Chen", "Vikash Singh", "Zahra Rahmani", "Debargha Ganguly", "Mohsen Hariri", "Vipin Chaudhary"], "title": "$K^4$: Online Log Anomaly Detection Via Unsupervised Typicality Learning", "categories": ["cs.LG", "cs.CL", "cs.DC"], "comment": null, "summary": "Existing Log Anomaly Detection (LogAD) methods are often slow, dependent on\nerror-prone parsing, and use unrealistic evaluation protocols. We introduce\n$K^4$, an unsupervised and parser-independent framework for high-performance\nonline detection. $K^4$ transforms arbitrary log embeddings into compact\nfour-dimensional descriptors (Precision, Recall, Density, Coverage) using\nefficient k-nearest neighbor (k-NN) statistics. These descriptors enable\nlightweight detectors to accurately score anomalies without retraining. Using a\nmore realistic online evaluation protocol, $K^4$ sets a new state-of-the-art\n(AUROC: 0.995-0.999), outperforming baselines by large margins while being\norders of magnitude faster, with training under 4 seconds and inference as low\nas 4 $\\mu$s.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86$K^4$\u6846\u67b6\uff0c\u4e00\u79cd\u5feb\u901f\u3001\u65e0\u76d1\u7763\u4e14\u4e0d\u4f9d\u8d56\u89e3\u6790\u7684\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u6548k-NN\u7edf\u8ba1\u5c06\u65e5\u5fd7\u5d4c\u5165\u8f6c\u5316\u4e3a\u56db\u7ef4\u63cf\u8ff0\u7b26\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u5728\u7ebf\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u901f\u5ea6\u6162\u3001\u4f9d\u8d56\u9519\u8bef\u89e3\u6790\u53ca\u8bc4\u4f30\u534f\u8bae\u4e0d\u771f\u5b9e\u7684\u95ee\u9898\uff0c$K^4$\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "$K^4$\u5229\u7528k-NN\u7edf\u8ba1\u5c06\u65e5\u5fd7\u5d4c\u5165\u8f6c\u6362\u4e3a\u56db\u7ef4\u63cf\u8ff0\u7b26\uff08\u7cbe\u5ea6\u3001\u53ec\u56de\u3001\u5bc6\u5ea6\u3001\u8986\u76d6\u7387\uff09\uff0c\u652f\u6301\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u5668\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u51c6\u786e\u8bc4\u5206\u3002", "result": "$K^4$\u5728\u66f4\u771f\u5b9e\u7684\u5728\u7ebf\u8bc4\u4f30\u534f\u8bae\u4e0b\u8868\u73b0\u4f18\u5f02\uff08AUROC:0.995-0.999\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u901f\u5ea6\u5feb\uff08\u8bad\u7ec3<4\u79d2\uff0c\u63a8\u7406\u4f4e\u81f34\u03bcs\uff09\u3002", "conclusion": "$K^4$\u5728\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u9886\u57df\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u9ad8\u6548\u4e14\u5b9e\u7528\u3002"}}
{"id": "2507.20971", "pdf": "https://arxiv.org/pdf/2507.20971", "abs": "https://arxiv.org/abs/2507.20971", "authors": ["Cl\u00e1udio Modesto", "Jo\u00e3o Borges", "Cleverson Nahum", "Lucas Matni", "Cristiano Bonato Both", "Kleber Cardoso", "Glauco Gon\u00e7alves", "Ilan Correa", "Silvia Lins", "Andrey Silva", "Aldebaro Klautau"], "title": "Towards a Robust Transport Network With Self-adaptive Network Digital Twin", "categories": ["cs.NI"], "comment": "19 pages, 10 figures, and 6 tables", "summary": "The ability of the network digital twin (NDT) to remain aware of changes in\nits physical counterpart, known as the physical twin (PTwin), is a fundamental\ncondition to enable timely synchronization, also referred to as twinning. In\nthis way, considering a transport network, a key requirement is to handle\nunexpected traffic variability and dynamically adapt to maintain optimal\nperformance in the associated virtual model, known as the virtual twin (VTwin).\nIn this context, we propose a self-adaptive implementation of a novel NDT\narchitecture designed to provide accurate delay predictions, even under\nfluctuating traffic conditions. This architecture addresses an essential\nchallenge, underexplored in the literature: improving the resilience of\ndata-driven NDT platforms against traffic variability and improving\nsynchronization between the VTwin and its physical counterpart. Therefore, the\ncontributions of this article rely on NDT lifecycle by focusing on the\noperational phase, where telemetry modules are used to monitor incoming\ntraffic, and concept drift detection techniques guide retraining decisions\naimed at updating and redeploying the VTwin when necessary. We validate our\narchitecture with a network management use case, across various emulated\nnetwork topologies, and diverse traffic patterns to demonstrate its\neffectiveness in preserving acceptable performance and predicting per-flow\ndelay under unexpected traffic variation. The results in all tested topologies,\nusing the normalized mean square error as the evaluation metric, demonstrate\nthat our proposed architecture, after a traffic concept drift, achieves a\nperformance improvement in prediction of at least 56.7% compared to a\nconfiguration without NDT synchronization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\uff08NDT\uff09\u67b6\u6784\uff0c\u7528\u4e8e\u5728\u6d41\u91cf\u6ce2\u52a8\u60c5\u51b5\u4e0b\u63d0\u4f9b\u51c6\u786e\u7684\u5ef6\u8fdf\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u6280\u672f\u4f18\u5316\u865a\u62df\u5b6a\u751f\uff08VTwin\uff09\u4e0e\u7269\u7406\u5b6a\u751f\uff08PTwin\uff09\u7684\u540c\u6b65\u3002\u9a8c\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u67b6\u6784\u5728\u6d41\u91cf\u53d8\u5316\u540e\u7684\u9884\u6d4b\u6027\u80fd\u63d0\u5347\u81f3\u5c1156.7%\u3002", "motivation": "\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\uff08NDT\uff09\u9700\u8981\u53ca\u65f6\u611f\u77e5\u7269\u7406\u5b6a\u751f\uff08PTwin\uff09\u7684\u53d8\u5316\u4ee5\u5b9e\u73b0\u540c\u6b65\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u6570\u636e\u9a71\u52a8\u7684NDT\u5e73\u53f0\u5728\u6d41\u91cf\u6ce2\u52a8\u4e0b\u7684\u5f39\u6027\u548c\u540c\u6b65\u95ee\u9898\u63a2\u8ba8\u4e0d\u8db3\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7684NDT\u67b6\u6784\uff0c\u5229\u7528\u9065\u6d4b\u6a21\u5757\u76d1\u63a7\u6d41\u91cf\uff0c\u5e76\u901a\u8fc7\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u6280\u672f\u6307\u5bfcVTwin\u7684\u91cd\u65b0\u8bad\u7ec3\u548c\u90e8\u7f72\u3002\u5728\u6a21\u62df\u7f51\u7edc\u62d3\u6251\u548c\u591a\u6837\u6d41\u91cf\u6a21\u5f0f\u4e2d\u9a8c\u8bc1\u67b6\u6784\u3002", "result": "\u8be5\u67b6\u6784\u5728\u6d41\u91cf\u6982\u5ff5\u6f02\u79fb\u540e\uff0c\u9884\u6d4b\u6027\u80fd\u63d0\u9ad8\u4e86\u81f3\u5c1156.7%\uff08\u4ee5\u6807\u51c6\u5316\u5747\u65b9\u8bef\u5dee\u4e3a\u6307\u6807\uff09\uff0c\u5728\u6240\u6709\u6d4b\u8bd5\u62d3\u6251\u4e2d\u5747\u6709\u6548\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u81ea\u9002\u5e94NDT\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u6d41\u91cf\u6ce2\u52a8\u4e0b\u7684\u5ef6\u8fdf\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u7f51\u7edc\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.20402", "pdf": "https://arxiv.org/pdf/2507.20402", "abs": "https://arxiv.org/abs/2507.20402", "authors": ["Md Nazmul Hossain", "Taher A. Ghaleb"], "title": "CIgrate: Automating CI Service Migration with Large Language Models", "categories": ["cs.SE"], "comment": "Registered Report Accepted at the 41st IEEE International Conference\n  on Software Maintenance and Evolution 2025 (ICSME'25)", "summary": "Continuous Integration (CI) configurations often need to be migrated between\nservices (e.g., Travis CI to GitHub Actions) as projects evolve, due to changes\nin service capabilities, usage limits, or service deprecation. Previous studies\nreported that migration across CI services is a recurring need in open-source\ndevelopment. However, manual migration can be time-consuming and error-prone.\nThe state-of-the-art approach, CIMig, addresses this challenge by analyzing\npast migration examples to create service-specific rules and produce equivalent\nconfigurations across CI services. However, its relatively low accuracy raises\nconcerns about the overall feasibility of automated CI migration using\nrule-based techniques alone. Meanwhile, Large Language Models (LLMs) have\ndemonstrated strong capabilities in code generation and transformation tasks,\nsuggesting potential to improve the automation, usability, and generalizability\nof CI configuration migration. This registered report presents a study in which\nwe aim to assess whether CI migration can be improved using LLMs. To this end,\nwe propose CIgrate, an LLM-based framework for automatically migrating CI\nconfigurations. We plan to evaluate the performance of CIgrate compared to\nCIMig as a baseline, in different setups (a) zero-shot/few-shot prompting of\nLLMs for configuration migration and (b) fine-tuning an LLM on a dataset of\nalready established CI service migrations. We will also seek developer feedback\non the quality and usability of the generated configurations. We formulate\nresearch questions focusing on the accuracy of LLM-generated migrations versus\nground truth and the output of CIMig. The expected contributions include the\nfirst LLM-powered approach for CI service migration, a comparative evaluation\nof its effectiveness compared to rule-based approaches, and insight into\nleveraging LLMs to support software configuration evolution.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u57fa\u4e8eLLM\u7684CIgrate\u4e0e\u89c4\u5219\u57fa\u7840\u7684CIMig\u5728CI\u914d\u7f6e\u8fc1\u79fb\u4e2d\u7684\u8868\u73b0\uff0c\u63a2\u8ba8LLM\u5728\u81ea\u52a8\u5316\u8fc1\u79fb\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8eCI\u670d\u52a1\u8fc1\u79fb\u5728\u5f00\u6e90\u9879\u76ee\u4e2d\u9700\u6c42\u9891\u7e41\u4e14\u624b\u52a8\u8fc1\u79fb\u8017\u65f6\u6613\u9519\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLM\u5728\u63d0\u5347\u81ea\u52a8\u5316\u8fc1\u79fb\u53ef\u884c\u6027\u65b9\u9762\u7684\u4f5c\u7528\u3002", "method": "\u63d0\u51faCIgrate\u6846\u67b6\uff0c\u8bc4\u4f30\u5176\u5728\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63d0\u793a\u53ca\u5fae\u8c03LLM\u540e\u7684\u6548\u679c\uff0c\u5e76\u4e0eCIMig\u5bf9\u6bd4\u3002", "result": "\u9884\u671f\u8d21\u732e\u5305\u62ec\u9996\u4e2aLLM\u9a71\u52a8\u7684CI\u8fc1\u79fb\u65b9\u6cd5\u3001\u4e0e\u89c4\u5219\u65b9\u6cd5\u7684\u5bf9\u6bd4\u8bc4\u4f30\uff0c\u53ca\u5bf9LLM\u652f\u6301\u914d\u7f6e\u6f14\u8fdb\u7684\u89c1\u89e3\u3002", "conclusion": "\u7814\u7a76\u6709\u671b\u9a8c\u8bc1LLM\u5728CI\u914d\u7f6e\u8fc1\u79fb\u4e2d\u7684\u4f18\u52bf\uff0c\u4e3a\u672a\u6765\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2507.19782", "pdf": "https://arxiv.org/pdf/2507.19782", "abs": "https://arxiv.org/abs/2507.19782", "authors": ["Yifei Zhang", "Lin-Ping Yuan", "Yuheng Zhao", "Jielin Feng", "Siming Chen"], "title": "KinemaFX: A Kinematic-Driven Interactive System for Particle Effect Exploration and Customization", "categories": ["cs.HC"], "comment": "Meta Review Overall Rating 3.5 Weakly Accept Contribution to HCI This\n  paper presents KinemaFX, an LLM-powered interactive system leveraging\n  semantic and kinematic inputs to help non-experts explore, customize, and\n  compose particle effects", "summary": "Particle effects are widely used in games and animation to simulate natural\nphenomena or stylized visual effects. However, creating effect artworks is\nchallenging for non-expert users due to their lack of specialized skills,\nparticularly in finding particle effects with kinematic behaviors that match\ntheir intent. To address these issues, we present KinemaFX, a kinematic-driven\ninteractive system, to assist non-expert users in constructing customized\nparticle effect artworks. We propose a conceptual model of particle effects\nthat captures both semantic features and kinematic behaviors. Based on the\nmodel, KinemaFX adopts a workflow powered by Large Language Models (LLMs) that\nsupports intent expression through combined semantic and kinematic inputs,\nwhile enabling implicit preference-guided exploration and subsequent creation\nof customized particle effect artworks based on exploration results.\nAdditionally, we developed a kinematic-driven method to facilitate efficient\ninteractive particle effect search within KinemaFX via structured\nrepresentation and measurement of particle effects. To evaluate KinemaFX, we\nillustrate usage scenarios and conduct a user study employing an ablation\napproach. Evaluation results demonstrate that KinemaFX effectively supports\nusers in efficiently and customarily creating particle effect artworks.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86KinemaFX\u7cfb\u7edf\uff0c\u5e2e\u52a9\u975e\u4e13\u4e1a\u7528\u6237\u901a\u8fc7\u8bed\u4e49\u548c\u8fd0\u52a8\u8f93\u5165\u521b\u5efa\u5b9a\u5236\u7c92\u5b50\u6548\u679c\uff0c\u7ed3\u5408LLM\u5de5\u4f5c\u6d41\u548c\u8fd0\u52a8\u9a71\u52a8\u641c\u7d22\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u975e\u4e13\u4e1a\u7528\u6237\u5728\u521b\u5efa\u7c92\u5b50\u6548\u679c\u65f6\u56e0\u7f3a\u4e4f\u4e13\u4e1a\u6280\u80fd\u800c\u9047\u5230\u7684\u56f0\u96be\uff0c\u7279\u522b\u662f\u5339\u914d\u610f\u56fe\u7684\u8fd0\u52a8\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u7c92\u5b50\u6548\u679c\u7684\u6982\u5ff5\u6a21\u578b\uff0c\u7ed3\u5408LLM\u5de5\u4f5c\u6d41\u652f\u6301\u610f\u56fe\u8868\u8fbe\uff0c\u5e76\u5f00\u53d1\u8fd0\u52a8\u9a71\u52a8\u641c\u7d22\u65b9\u6cd5\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cKinemaFX\u80fd\u6709\u6548\u5e2e\u52a9\u7528\u6237\u9ad8\u6548\u3001\u4e2a\u6027\u5316\u5730\u521b\u5efa\u7c92\u5b50\u6548\u679c\u3002", "conclusion": "KinemaFX\u4e3a\u975e\u4e13\u4e1a\u7528\u6237\u63d0\u4f9b\u4e86\u4fbf\u6377\u7684\u7c92\u5b50\u6548\u679c\u521b\u4f5c\u5de5\u5177\uff0c\u7ed3\u5408\u8bed\u4e49\u548c\u8fd0\u52a8\u8f93\u5165\uff0c\u63d0\u5347\u521b\u4f5c\u6548\u7387\u3002"}}
{"id": "2507.19550", "pdf": "https://arxiv.org/pdf/2507.19550", "abs": "https://arxiv.org/abs/2507.19550", "authors": ["Awid Vaziry", "Sandro Rodriguez Garzon", "Axel K\u00fcpper"], "title": "Towards Multi-Agent Economies: Enhancing the A2A Protocol with Ledger-Anchored Identities and x402 Micropayments for AI Agents", "categories": ["cs.MA", "cs.NI"], "comment": null, "summary": "This research article presents a novel architecture to empower multi-agent\neconomies by addressing two critical limitations of the emerging Agent2Agent\n(A2A) communication protocol: decentralized agent discoverability and\nagent-to-agent micropayments. By integrating distributed ledger technology\n(DLT), this architecture enables tamper-proof, on-chain publishing of\nAgentCards as smart contracts, providing secure and verifiable agent\nidentities. The architecture further extends A2A with the x402 open standard,\nfacilitating blockchain-agnostic, HTTP-based micropayments via the HTTP 402\nstatus code. This enables autonomous agents to seamlessly discover,\nauthenticate, and compensate each other across organizational boundaries. This\nwork further presents a comprehensive technical implementation and evaluation,\ndemonstrating the feasibility of DLT-based agent discovery and micropayments.\nThe proposed approach lays the groundwork for secure, scalable, and\neconomically viable multi-agent ecosystems, advancing the field of agentic AI\ntoward trusted, autonomous economic interactions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7ecf\u6d4e\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u5206\u6563\u5f0f\u667a\u80fd\u4f53\u53d1\u73b0\u4e0e\u5fae\u652f\u4ed8\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAgent2Agent\uff08A2A\uff09\u901a\u4fe1\u534f\u8bae\u5b58\u5728\u5206\u6563\u5f0f\u667a\u80fd\u4f53\u53d1\u73b0\u548c\u5fae\u652f\u4ed8\u9650\u5236\uff0c\u963b\u788d\u4e86\u591a\u667a\u80fd\u4f53\u7ecf\u6d4e\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u6574\u5408\u5206\u5e03\u5f0f\u8d26\u672c\u6280\u672f\uff08DLT\uff09\u5b9e\u73b0\u667a\u80fd\u5408\u7ea6\u5f62\u5f0f\u7684AgentCards\uff0c\u5e76\u5f15\u5165x402\u5f00\u653e\u6807\u51c6\u652f\u6301HTTP 402\u72b6\u6001\u7801\u7684\u5fae\u652f\u4ed8\u3002", "result": "\u7814\u7a76\u8bc1\u660e\u57fa\u4e8eDLT\u7684\u667a\u80fd\u4f53\u53d1\u73b0\u548c\u5fae\u652f\u4ed8\u53ef\u884c\uff0c\u4e3a\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684\u591a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u67b6\u6784\u63a8\u52a8\u4e86\u667a\u80fd\u4f53AI\u5411\u53ef\u4fe1\u3001\u81ea\u4e3b\u7684\u7ecf\u6d4e\u4ea4\u4e92\u53d1\u5c55\u3002"}}
{"id": "2507.20407", "pdf": "https://arxiv.org/pdf/2507.20407", "abs": "https://arxiv.org/abs/2507.20407", "authors": ["Davi Gama Hardman", "Cesar Fran\u00e7a", "Brody Stuart-Verner", "Ronnie de Souza Santos"], "title": "Testing Is Not Boring: Characterizing Challenge in Software Testing Tasks", "categories": ["cs.SE"], "comment": null, "summary": "As software systems continue to grow in complexity, testing has become a\nfundamental part of ensuring the quality and reliability of software products.\nYet, software testing is still often perceived, both in industry and academia,\nas a repetitive, low-skill activity. This perception fails to recognize the\ncreativity, problem-solving, and adaptability required in testing work. Tasks\nsuch as designing complex test cases, automating testing processes, and\nhandling shifting requirements illustrate the challenges testing professionals\nregularly face. To better understand these experiences, we conducted a study\nwith software testing professionals to explore the nature of challenging tasks\nin software testing and how they affect these professionals. Our findings show\nthat tasks involving creativity, ongoing learning, and time pressure are often\nseen as motivating and rewarding. On the other hand, a lack of challenge or\noverwhelming demands can lead to frustration and disengagement. These findings\ndemonstrate the importance of balancing task complexity to sustain motivation\nand present software testing as a dynamic and intellectually engaging field.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u6d4b\u8bd5\u5de5\u4f5c\u7684\u590d\u6742\u6027\u548c\u6311\u6218\uff0c\u53cd\u9a73\u4e86\u5c06\u5176\u89c6\u4e3a\u4f4e\u6280\u80fd\u6d3b\u52a8\u7684\u89c2\u70b9\uff0c\u5e76\u7814\u7a76\u4e86\u4efb\u52a1\u590d\u6742\u5ea6\u5bf9\u6d4b\u8bd5\u4e13\u4e1a\u4eba\u5458\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63ed\u793a\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u521b\u9020\u6027\u3001\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u548c\u9002\u5e94\u6027\uff0c\u4ee5\u6539\u53d8\u5bf9\u6d4b\u8bd5\u5de5\u4f5c\u7684\u8d1f\u9762\u523b\u677f\u5370\u8c61\u3002", "method": "\u901a\u8fc7\u8bbf\u8c08\u8f6f\u4ef6\u6d4b\u8bd5\u4e13\u4e1a\u4eba\u5458\uff0c\u7814\u7a76\u8c03\u67e5\u4e86\u6d4b\u8bd5\u4efb\u52a1\u7684\u6027\u8d28\u53ca\u5176\u5bf9\u4e13\u4e1a\u4eba\u58eb\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6d89\u53ca\u521b\u9020\u6027\u548c\u6301\u7eed\u5b66\u4e60\u7684\u4efb\u52a1\u5177\u6709\u6fc0\u52b1\u6027\uff0c\u800c\u8fc7\u4e8e\u7b80\u5355\u6216\u8fc7\u4e8e\u590d\u6742\u7684\u4efb\u52a1\u53ef\u80fd\u5bfc\u81f4\u632b\u8d25\u611f\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u5e73\u8861\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u7ef4\u6301\u6d4b\u8bd5\u4eba\u5458\u7684\u79ef\u6781\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u52a8\u6001\u6027\u548c\u667a\u529b\u6311\u6218\u6027\u3002"}}
{"id": "2507.19898", "pdf": "https://arxiv.org/pdf/2507.19898", "abs": "https://arxiv.org/abs/2507.19898", "authors": ["Parsa Vares", "\u00c9loi Durant", "Jun Pang", "Nicolas M\u00e9doc", "Mohammad Ghoniem"], "title": "TS-Insight: Visualizing Thompson Sampling for Verification and XAI", "categories": ["cs.HC", "cs.AI", "cs.LG", "stat.ML", "I.2.6; H.5.2"], "comment": "Accepted as a poster at IEEE VIS 2025 (\"TS-Insight: Visual\n  Fingerprinting of Multi-Armed Bandits\"). Open-source tool available at\n  https://github.com/parsavares/ts-insight", "summary": "Thompson Sampling (TS) and its variants are powerful Multi-Armed Bandit\nalgorithms used to balance exploration and exploitation strategies in active\nlearning. Yet, their probabilistic nature often turns them into a ``black\nbox'', hindering debugging and trust. We introduce TS-Insight, a visual\nanalytics tool explicitly designed to shed light on the internal decision\nmechanisms of Thompson Sampling-based algorithms, for model developers. It\ncomprises multiple plots, tracing for each arm the evolving posteriors,\nevidence counts, and sampling outcomes, enabling the verification, diagnosis,\nand explainability of exploration/exploitation dynamics. This tool aims at\nfostering trust and facilitating effective debugging and deployment in complex\nbinary decision-making scenarios especially in sensitive domains requiring\ninterpretable decision-making.", "AI": {"tldr": "TS-Insight\u662f\u4e00\u79cd\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u65e8\u5728\u63ed\u793aThompson Sampling\u7b97\u6cd5\u7684\u5185\u90e8\u51b3\u7b56\u673a\u5236\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u9a8c\u8bc1\u3001\u8bca\u65ad\u548c\u89e3\u91ca\u63a2\u7d22/\u5229\u7528\u7684\u52a8\u6001\u8fc7\u7a0b\u3002", "motivation": "Thompson Sampling\u53ca\u5176\u53d8\u4f53\u5728\u4e3b\u52a8\u5b66\u4e60\u4e2d\u7528\u4e8e\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\u7b56\u7565\uff0c\u4f46\u5176\u6982\u7387\u6027\u8d28\u4f7f\u5176\u6210\u4e3a\u201c\u9ed1\u7bb1\u201d\uff0c\u963b\u788d\u4e86\u8c03\u8bd5\u548c\u4fe1\u4efb\u3002", "method": "\u5f00\u53d1\u4e86TS-Insight\u5de5\u5177\uff0c\u5305\u542b\u591a\u4e2a\u56fe\u8868\uff0c\u8ffd\u8e2a\u6bcf\u4e2a\u81c2\u7684\u540e\u9a8c\u5206\u5e03\u3001\u8bc1\u636e\u8ba1\u6570\u548c\u91c7\u6837\u7ed3\u679c\uff0c\u4ee5\u63ed\u793a\u51b3\u7b56\u673a\u5236\u3002", "result": "\u5de5\u5177\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9Thompson Sampling\u7b97\u6cd5\u7684\u53ef\u89c6\u5316\u5206\u6790\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u548c\u8c03\u8bd5\u63a2\u7d22/\u5229\u7528\u7684\u52a8\u6001\u8fc7\u7a0b\u3002", "conclusion": "TS-Insight\u589e\u5f3a\u4e86Thompson Sampling\u7b97\u6cd5\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u9700\u8981\u53ef\u89e3\u91ca\u51b3\u7b56\u7684\u654f\u611f\u9886\u57df\u3002"}}
{"id": "2507.20424", "pdf": "https://arxiv.org/pdf/2507.20424", "abs": "https://arxiv.org/abs/2507.20424", "authors": ["Tolga Dimlioglu", "Anna Choromanska"], "title": "Communication-Efficient Distributed Training for Collaborative Flat Optima Recovery in Deep Learning", "categories": ["cs.LG", "cs.DC"], "comment": "9 pages main body, 32 pages of supplementary material for detailed\n  derivations and more experiment results", "summary": "We study centralized distributed data parallel training of deep neural\nnetworks (DNNs), aiming to improve the trade-off between communication\nefficiency and model performance of the local gradient methods. To this end, we\nrevisit the flat-minima hypothesis, which suggests that models with better\ngeneralization tend to lie in flatter regions of the loss landscape. We\nintroduce a simple, yet effective, sharpness measure, Inverse Mean Valley, and\ndemonstrate its strong correlation with the generalization gap of DNNs. We\nincorporate an efficient relaxation of this measure into the distributed\ntraining objective as a lightweight regularizer that encourages workers to\ncollaboratively seek wide minima. The regularizer exerts a pushing force that\ncounteracts the consensus step pulling the workers together, giving rise to the\nDistributed Pull-Push Force (DPPF) algorithm. Empirically, we show that DPPF\noutperforms other communication-efficient approaches and achieves better\ngeneralization performance than local gradient methods and synchronous gradient\naveraging, while significantly reducing communication overhead. In addition,\nour loss landscape visualizations confirm the ability of DPPF to locate flatter\nminima. On the theoretical side, we show that DPPF guides workers to span flat\nvalleys, with the final valley width governed by the interplay between push and\npull strengths, and that its pull-push dynamics is self-stabilizing. We further\nprovide generalization guarantees linked to the valley width and prove\nconvergence in the non-convex setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDPPF\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6b63\u5219\u5316\u5668\uff08Inverse Mean Valley\uff09\u6765\u4f18\u5316\u901a\u4fe1\u6548\u7387\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u6743\u8861\uff0c\u5e2e\u52a9\u6a21\u578b\u5bfb\u627e\u66f4\u5e73\u5766\u7684\u6781\u5c0f\u503c\uff0c\u4ece\u800c\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u96c6\u4e2d\u5f0f\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u8bad\u7ec3\uff0c\u65e8\u5728\u6539\u8fdb\u5c40\u90e8\u68af\u5ea6\u65b9\u6cd5\u5728\u901a\u4fe1\u6548\u7387\u4e0e\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u9510\u5ea6\u5ea6\u91cf\uff08Inverse Mean Valley\uff09\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u6b63\u5219\u5316\u5668\u5f15\u5165\u5206\u5e03\u5f0f\u8bad\u7ec3\u76ee\u6807\uff0c\u5f62\u6210DPPF\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u63a8\u62c9\u529b\u673a\u5236\u9f13\u52b1\u6a21\u578b\u5bfb\u627e\u5e73\u5766\u6781\u5c0f\u503c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDPPF\u5728\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\uff0c\u4f18\u4e8e\u5176\u4ed6\u901a\u4fe1\u9ad8\u6548\u65b9\u6cd5\uff0c\u4e14\u6cdb\u5316\u6027\u80fd\u4f18\u4e8e\u5c40\u90e8\u68af\u5ea6\u65b9\u6cd5\u548c\u540c\u6b65\u68af\u5ea6\u5e73\u5747\u3002\u7406\u8bba\u5206\u6790\u786e\u8ba4\u4e86\u5176\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\u3002", "conclusion": "DPPF\u901a\u8fc7\u63a8\u62c9\u529b\u673a\u5236\u6210\u529f\u5e2e\u52a9\u6a21\u578b\u5b9a\u4f4d\u5e73\u5766\u6781\u5c0f\u503c\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2507.20439", "pdf": "https://arxiv.org/pdf/2507.20439", "abs": "https://arxiv.org/abs/2507.20439", "authors": ["Maya Larbi", "Amal Akli", "Mike Papadakis", "Rihab Bouyousfi", "Maxime Cordy", "Federica Sarro", "Yves Le Traon"], "title": "When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive performance in code\ngeneration tasks under idealized conditions, where task descriptions are clear\nand precise. However, in practice, task descriptions frequently exhibit\nambiguity, incompleteness, or internal contradictions. In this paper, we\npresent the first empirical study examining the robustness of state-of-the-art\ncode generation models when faced with such unclear task descriptions. We\nextend the HumanEval and MBPP benchmarks by systematically introducing\nrealistic task descriptions flaws through guided mutation strategies, producing\na dataset that mirrors the messiness of informal developer instructions. We\nevaluate multiple LLMs of varying sizes and architectures, analyzing their\nfunctional correctness and failure modes across task descriptions categories.\nOur findings reveal that even minor imperfections in task description phrasing\ncan cause significant performance degradation, with contradictory task\ndescriptions resulting in numerous logical errors. Moreover, while larger\nmodels tend to be more resilient than smaller variants, they are not immune to\nthe challenges posed by unclear requirements. We further analyze semantic error\npatterns and identify correlations between description clarity, model behavior,\nand error types. Our results underscore the critical need for developing LLMs\nthat are not only powerful but also robust to the imperfections inherent in\nnatural user tasks, highlighting important considerations for improving model\ntraining strategies, designing more realistic evaluation benchmarks, and\nensuring reliable deployment in practical software development environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9762\u5bf9\u6a21\u7cca\u6216\u4e0d\u5b8c\u6574\u7684\u4efb\u52a1\u63cf\u8ff0\u65f6\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u5148\u8fdb\u6a21\u578b\u4e5f\u4f1a\u56e0\u63cf\u8ff0\u95ee\u9898\u800c\u8868\u73b0\u4e0b\u964d\u3002", "motivation": "\u5b9e\u9645\u5f00\u53d1\u4e2d\u4efb\u52a1\u63cf\u8ff0\u5f80\u5f80\u4e0d\u6e05\u6670\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u57fa\u4e8e\u7406\u60f3\u5316\u6761\u4ef6\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30LLMs\u5728\u6a21\u7cca\u63cf\u8ff0\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u901a\u8fc7\u6269\u5c55HumanEval\u548cMBPP\u57fa\u51c6\uff0c\u7cfb\u7edf\u5f15\u5165\u771f\u5b9e\u7684\u4efb\u52a1\u63cf\u8ff0\u7f3a\u9677\uff0c\u8bc4\u4f30\u4e0d\u540c\u89c4\u6a21\u548c\u67b6\u6784\u7684LLMs\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u4efb\u52a1\u63cf\u8ff0\u7684\u5fae\u5c0f\u7455\u75b5\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u77db\u76fe\u63cf\u8ff0\u5c24\u5176\u5bb9\u6613\u5f15\u53d1\u903b\u8f91\u9519\u8bef\uff1b\u5927\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u4f46\u4ecd\u4e0d\u5b8c\u7f8e\u3002", "conclusion": "\u9700\u5f00\u53d1\u66f4\u5177\u9c81\u68d2\u6027\u7684LLMs\uff0c\u6539\u8fdb\u8bad\u7ec3\u7b56\u7565\u548c\u8bc4\u4f30\u57fa\u51c6\uff0c\u4ee5\u786e\u4fdd\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u7684\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2507.20769", "pdf": "https://arxiv.org/pdf/2507.20769", "abs": "https://arxiv.org/abs/2507.20769", "authors": ["Hongzhen Zhang", "Tim Kerkenhoff", "Neil Kichler", "Manuel Dahmen", "Alexander Mitsos", "Uwe Naumann", "Dominik Bongartz"], "title": "Accelerating Deterministic Global Optimization via GPU-parallel Interval Arithmetic", "categories": ["math.OC", "cs.DC", "90C26, 90C30, 90-04, 90-08"], "comment": "28 pages, 8 figures and 4 tables", "summary": "Spatial Branch and Bound (B&B) algorithms are widely used for solving\nnonconvex problems to global optimality, yet they remain computationally\nexpensive. Though some works have been carried out to speed up B&B via CPU\nparallelization, GPU parallelization is much less explored. In this work, we\ninvestigate the design of a spatial B&B algorithm that involves an\ninterval-based GPU-parallel lower bounding solver: The domain of each B&B node\nis temporarily partitioned into numerous subdomains, then massive GPU\nparallelism is leveraged to compute interval bounds of the objective function\nand constraints on each subdomain, using the Mean Value Form. The resulting\nbounds are tighter than those achieved via regular interval arithmetic without\npartitioning, but they remain fast to compute. We implement the method into our\nopen-source solver MAiNGO via CUDA in two manners: wrapping all GPU tasks\nwithin one kernel function, or distributing the GPU tasks onto a CUDA graph.\nNumerical experiments show that using more subdomains leads to significantly\ntighter lower bounds and thus less B&B iterations. Regarding wall clock time,\nthe proposed spatial B&B framework achieves a speedup of three orders of\nmagnitude compared to applying interval arithmetic on the CPU without domain\npartitioning. Among the two implementations, the one developed with CUDA graph\nenables higher efficiency. Moreover, in some case studies, the proposed method\ndelivers competitive or better performance compared to MAiNGO's default solver\nwhich is based on McCormick relaxations. These results highlight the potential\nof GPU-accelerated bounding techniques to accelerate B&B algorithms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPU\u5e76\u884c\u5316\u7684\u7a7a\u95f4\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\uff0c\u901a\u8fc7\u533a\u95f4\u5212\u5206\u548c\u5e76\u884c\u8ba1\u7b97\u663e\u8457\u63d0\u5347\u4e86\u7b97\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "motivation": "\u5c3d\u7ba1\u7a7a\u95f4\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6c42\u89e3\u975e\u51f8\u95ee\u9898\uff0c\u4f46\u5176\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u867d\u7136\u5df2\u6709\u4e00\u4e9b\u7814\u7a76\u901a\u8fc7CPU\u5e76\u884c\u5316\u52a0\u901f\u7b97\u6cd5\uff0c\u4f46GPU\u5e76\u884c\u5316\u4ecd\u9c9c\u6709\u63a2\u7d22\u3002", "method": "\u5c06\u6bcf\u4e2a\u5206\u652f\u5b9a\u754c\u8282\u70b9\u7684\u57df\u5212\u5206\u4e3a\u591a\u4e2a\u5b50\u57df\uff0c\u5229\u7528GPU\u5e76\u884c\u8ba1\u7b97\u6bcf\u4e2a\u5b50\u57df\u7684\u533a\u95f4\u754c\u9650\uff0c\u91c7\u7528\u5747\u503c\u5f62\u5f0f\u8ba1\u7b97\u76ee\u6807\u51fd\u6570\u548c\u7ea6\u675f\u7684\u754c\u9650\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u66f4\u591a\u5b50\u57df\u80fd\u663e\u8457\u63d0\u9ad8\u754c\u9650\u7d27\u5bc6\u5ea6\u5e76\u51cf\u5c11\u5206\u652f\u5b9a\u754c\u8fed\u4ee3\u6b21\u6570\uff0cGPU\u52a0\u901f\u7248\u672c\u6bd4CPU\u7248\u672c\u5feb\u4e09\u4e2a\u6570\u91cf\u7ea7\uff1bCUDA\u56fe\u5b9e\u73b0\u7684\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86GPU\u52a0\u901f\u7684\u754c\u9650\u8ba1\u7b97\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.20475", "pdf": "https://arxiv.org/pdf/2507.20475", "abs": "https://arxiv.org/abs/2507.20475", "authors": ["Ahmik Virani", "Devraj", "Anirudh Suresh", "Lei Zhang", "M V Panduranga Rao"], "title": "Distinguishing Quantum Software Bugs from Hardware Noise: A Statistical Approach", "categories": ["cs.SE", "quant-ph"], "comment": "12 pages, 30 figures, accepted by the IEEE International Conference\n  on Quantum Computing and Engineering (QCE), IEEE Quantum Week, 2025", "summary": "Quantum computing in the Noisy Intermediate-Scale Quantum (NISQ) era presents\nsignificant challenges in differentiating quantum software bugs from hardware\nnoise. Traditional debugging techniques from classical software engineering\ncannot directly resolve this issue due to the inherently stochastic nature of\nquantum computation mixed with noises from NISQ computers. To address this gap,\nwe propose a statistical approach leveraging probabilistic metrics to\ndifferentiate between quantum software bugs and hardware noise. We evaluate our\nmethodology empirically using well-known quantum algorithms, including Grover's\nalgorithm, Deutsch-Jozsa algorithm, and Simon's algorithm. Experimental results\ndemonstrate the efficacy and practical applicability of our approach, providing\nquantum software developers with a reliable analytical tool to identify and\nclassify unexpected behavior in quantum programs.", "AI": {"tldr": "\u9488\u5bf9NISQ\u65f6\u4ee3\u7684\u91cf\u5b50\u8ba1\u7b97\u4e2d\u8f6f\u4ef6\u9519\u8bef\u4e0e\u786c\u4ef6\u566a\u58f0\u96be\u4ee5\u533a\u5206\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u5ea6\u91cf\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3NISQ\u91cf\u5b50\u8ba1\u7b97\u673a\u4e2d\u91cf\u5b50\u8f6f\u4ef6\u9519\u8bef\u4e0e\u786c\u4ef6\u566a\u58f0\u96be\u4ee5\u533a\u5206\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7edf\u8ba1\u65b9\u6cd5\u548c\u6982\u7387\u5ea6\u91cf\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u77e5\u540d\u91cf\u5b50\u7b97\u6cd5\uff08\u5982Grover\u7b97\u6cd5\uff09\u6765\u533a\u5206\u8f6f\u4ef6\u9519\u8bef\u4e0e\u786c\u4ef6\u566a\u58f0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u5b9e\u7528\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u5206\u6790\u5de5\u5177\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u8ba1\u65b9\u6cd5\u80fd\u6709\u6548\u533a\u5206\u91cf\u5b50\u8f6f\u4ef6\u9519\u8bef\u4e0e\u786c\u4ef6\u566a\u58f0\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.20006", "pdf": "https://arxiv.org/pdf/2507.20006", "abs": "https://arxiv.org/abs/2507.20006", "authors": ["Jun-Hsiang Yao", "Jielin Feng", "Xinfang Tian", "Kai Xu", "Gulshat Amirkhanova", "Siming Chen"], "title": "Beyond the Broadcast: Enhancing VR Tennis Broadcasting through Embedded Visualizations and Camera Techniques", "categories": ["cs.HC"], "comment": "11 pages, 6 figures", "summary": "Virtual Reality (VR) broadcasting has emerged as a promising medium for\nproviding immersive viewing experiences of major sports events such as tennis.\nHowever, current VR broadcast systems often lack an effective camera language\nand do not adequately incorporate dynamic, in-game visualizations, limiting\nviewer engagement and narrative clarity. To address these limitations, we\nanalyze 400 out-of-play segments from eight major tennis broadcasts to develop\na tennis-specific design framework that effectively combines cinematic camera\nmovements with embedded visualizations. We further refine our framework by\nexamining 25 cinematic VR animations, comparing their camera techniques with\ntraditional tennis broadcasts to identify key differences and inform\nadaptations for VR. Based on data extracted from the broadcast videos, we\nreconstruct a simulated game that captures the players' and ball's motion and\ntrajectories. Leveraging this design framework and processing pipeline, we\ndevelope Beyond the Broadcast, a VR tennis viewing system that integrates\nembedded visualizations with adaptive camera motions to construct a\ncomprehensive and engaging narrative. Our system dynamically overlays tactical\ninformation and key match events onto the simulated environment, enhancing\nviewer comprehension and narrative engagement while ensuring perceptual\nimmersion and viewing comfort. A user study involving tennis viewers\ndemonstrate that our approach outperforms traditional VR broadcasting methods\nin delivering an immersive, informative viewing experience.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u73b0\u6709VR\u4f53\u80b2\u76f4\u64ad\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7535\u5f71\u5316\u955c\u5934\u8fd0\u52a8\u548c\u5d4c\u5165\u53ef\u89c6\u5316\u7684VR\u7f51\u7403\u89c2\u770b\u7cfb\u7edf\uff0c\u7528\u6237\u7814\u7a76\u8868\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfVR\u7f51\u7403\u76f4\u64ad\u7f3a\u4e4f\u6709\u6548\u7684\u955c\u5934\u8bed\u8a00\u548c\u52a8\u6001\u53ef\u89c6\u5316\uff0c\u5f71\u54cd\u4e86\u89c2\u4f17\u7684\u6c89\u6d78\u611f\u548c\u53d9\u4e8b\u6e05\u6670\u5ea6\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5206\u6790400\u6bb5\u7f51\u7403\u76f4\u64ad\u89c6\u9891\u548c25\u6bb5VR\u52a8\u753b\uff0c\u63d0\u53d6\u955c\u5934\u6280\u672f\u548c\u53ef\u89c6\u5316\u6570\u636e\uff0c\u6784\u5efa\u6a21\u62df\u6bd4\u8d5b\u73af\u5883\u548c\u81ea\u9002\u5e94\u955c\u5934\u8fd0\u52a8\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u7684VR\u7cfb\u7edf\u878d\u5408\u6218\u672f\u4fe1\u606f\u548c\u5173\u952e\u4e8b\u4ef6\u53ef\u89c6\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c2\u4f17\u7684\u6c89\u6d78\u611f\u548c\u53d9\u4e8b\u7406\u89e3\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3aVR\u4f53\u80b2\u76f4\u64ad\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u4f18\u5316\u4e86\u89c2\u4f17\u4f53\u9a8c\u3002"}}
{"id": "2507.20502", "pdf": "https://arxiv.org/pdf/2507.20502", "abs": "https://arxiv.org/abs/2507.20502", "authors": ["Howell Xia", "Jonah Gluck", "Sevval Simsek", "David Sastre Medina", "David Starobinski"], "title": "VDGraph: A Graph-Theoretic Approach to Unlock Insights from SBOM and SCA Data", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "The high complexity of modern software supply chains necessitates tools such\nas Software Bill of Materials (SBOMs) to manage component dependencies, and\nSoftware Composition Analysis (SCA) tools to identify vulnerabilities. While\nthere exists limited integration between SBOMs and SCA tools, a unified view of\ncomplex dependency-vulnerability relationships remains elusive. In this paper,\nwe introduce VDGraph, a novel knowledge graph-based methodology for integrating\nvulnerability and dependency data into a holistic view. VDGraph consolidates\nSBOM and SCA outputs into a graph representation of software projects'\ndependencies and vulnerabilities. We provide a formal description and analysis\nof the theoretical properties of VDGraph and present solutions to manage\npossible conflicts between the SBOM and SCA data. We further introduce and\nevaluate a practical, proof-of-concept implementation of VDGraph using two\npopular SBOM and SCA tools, namely CycloneDX Maven plugin and Google's\nOSV-Scanner. We apply VDGraph on 21 popular Java projects. Through the\nformulation of appropriate queries on the graphs, we uncover the existence of\nconcentrated risk points (i.e., vulnerable components of high severity\nreachable through numerous dependency paths). We further show that\nvulnerabilities predominantly emerge at a depth of three dependency levels or\nhigher, indicating that direct or secondary dependencies exhibit lower\nvulnerability density and tend to be more secure. Thus, VDGraph contributes a\ngraph-theoretic methodology that improves visibility into how vulnerabilities\npropagate through complex, transitive dependencies. Moreover, our\nimplementation, which combines open SBOM and SCA standards with Neo4j, lays a\nfoundation for scalable and automated analysis across real-world projects.", "AI": {"tldr": "VDGraph\u662f\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6574\u5408SBOM\u548cSCA\u6570\u636e\uff0c\u4ee5\u53ef\u89c6\u5316\u4f9d\u8d56\u4e0e\u6f0f\u6d1e\u5173\u7cfb\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u590d\u6742\uff0c\u9700\u8981\u6574\u5408SBOM\u548cSCA\u5de5\u5177\u4ee5\u7edf\u4e00\u89c6\u56fe\u5206\u6790\u4f9d\u8d56\u4e0e\u6f0f\u6d1e\u5173\u7cfb\u3002", "method": "\u5f15\u5165VDGraph\uff0c\u5c06SBOM\u548cSCA\u6570\u636e\u8f6c\u6362\u4e3a\u56fe\u8868\u793a\uff0c\u89e3\u51b3\u6570\u636e\u51b2\u7a81\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u6982\u5ff5\u9a8c\u8bc1\u3002", "result": "\u572821\u4e2aJava\u9879\u76ee\u4e2d\u9a8c\u8bc1\uff0c\u53d1\u73b0\u9ad8\u98ce\u9669\u6f0f\u6d1e\u591a\u96c6\u4e2d\u4e8e\u6df1\u5c42\u4f9d\u8d56\uff0c\u76f4\u63a5\u6216\u6b21\u7ea7\u4f9d\u8d56\u66f4\u5b89\u5168\u3002", "conclusion": "VDGraph\u4e3a\u590d\u6742\u4f9d\u8d56\u4e2d\u7684\u6f0f\u6d1e\u4f20\u64ad\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u548c\u81ea\u52a8\u5316\u5206\u6790\u7684\u57fa\u7840\u3002"}}
{"id": "2507.20137", "pdf": "https://arxiv.org/pdf/2507.20137", "abs": "https://arxiv.org/abs/2507.20137", "authors": ["Panayu Keelawat", "David Barron", "Kaushik Narasimhan", "Daniel Manesh", "Xiaohang Tang", "Xi Chen", "Sang Won Lee", "Yan Chen"], "title": "Dynamite: Real-Time Debriefing Slide Authoring through AI-Enhanced Multimodal Interaction", "categories": ["cs.HC"], "comment": "Accepted to VL/HCC 2025", "summary": "Facilitating class-wide debriefings after small-group discussions is a common\nstrategy in ethics education. Instructor interviews revealed that effective\ndebriefings should highlight frequently discussed themes and surface\nunderrepresented viewpoints, making accurate representations of insight\noccurrence essential. Yet authoring presentations in real time is cognitively\noverwhelming due to the volume of data and tight time constraints. We present\nDynamite, an AI-assisted system that enables semantic updates to\ninstructor-authored slides during live classroom discussions. These updates are\npowered by semantic data binding, which links slide content to evolving\ndiscussion data, and semantic suggestions, which offer revision options aligned\nwith pedagogical goals. In a within-subject in-lab study with 12 participants,\nDynamite outperformed a text-based AI baseline in content accuracy and quality.\nParticipants used voice and sketch input to quickly organize semantic blocks,\nthen applied suggestions to accelerate refinement as data stabilized.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Dynamite\u7cfb\u7edf\uff0c\u5e2e\u52a9\u6559\u5e08\u5728\u8bfe\u5802\u8ba8\u8bba\u4e2d\u5b9e\u65f6\u66f4\u65b0\u5e7b\u706f\u7247\u5185\u5bb9\uff0c\u63d0\u5347\u6559\u5b66\u6548\u679c\u3002", "motivation": "\u8bfe\u5802\u6559\u5b66\u4e2d\u5b9e\u65f6\u6c47\u603b\u5c0f\u7ec4\u8ba8\u8bba\u5185\u5bb9\u5e76\u66f4\u65b0\u5e7b\u706f\u7247\uff0c\u5bf9\u6559\u5e08\u6765\u8bf4\u662f\u8ba4\u77e5\u8d1f\u62c5\u91cd\u7684\u4efb\u52a1\uff0c\u9700\u8981\u6280\u672f\u652f\u6301\u3002", "method": "\u5f00\u53d1\u4e86Dynamite\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u4e49\u6570\u636e\u7ed1\u5b9a\u548c\u5efa\u8bae\uff0c\u652f\u6301\u6559\u5e08\u5b9e\u65f6\u66f4\u65b0\u5e7b\u706f\u7247\u5185\u5bb9\u3002", "result": "\u5b9e\u9a8c\u5ba4\u7814\u7a76\u8868\u660e\uff0cDynamite\u5728\u5185\u5bb9\u51c6\u786e\u6027\u548c\u8d28\u91cf\u4e0a\u4f18\u4e8e\u6587\u672c\u57fa\u7ebf\u7cfb\u7edf\uff0c\u7528\u6237\u53cd\u9988\u826f\u597d\u3002", "conclusion": "Dynamite\u7cfb\u7edf\u6709\u6548\u51cf\u8f7b\u4e86\u6559\u5e08\u7684\u8ba4\u77e5\u8d1f\u62c5\uff0c\u63d0\u5347\u4e86\u8bfe\u5802\u8ba8\u8bba\u7684\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2507.20553", "pdf": "https://arxiv.org/pdf/2507.20553", "abs": "https://arxiv.org/abs/2507.20553", "authors": ["Guanyu Chen", "Haoyue Jiao", "Shuyang Hou", "Ziqi Liu", "Lutong Xie", "Shaowen Wu", "Huayi Wu", "Xuefeng Guan", "Zhipeng Gui"], "title": "GeoJSEval: An Automated Evaluation Framework for Large Language Models on JavaScript-Based Geospatial Computation and Visualization Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "With the widespread adoption of large language models (LLMs) in code\ngeneration tasks, geospatial code generation has emerged as a critical frontier\nin the integration of artificial intelligence and geoscientific analysis. This\ntrend underscores the urgent need for systematic evaluation methodologies to\nassess LLMs generation capabilities in geospatial contexts. In particular,\ngeospatial computation and visualization tasks in JavaScript environments rely\nheavily on orchestrating diverse frontend libraries and ecosystems, placing\nelevated demands on a model's semantic understanding and code synthesis\nabilities. To address this challenge, we propose GeoJSEval--the first\nmultimodal, function-level automatic evaluation framework for LLMs in\nJavaScript-based geospatial code generation. GeoJSEval comprises three core\ncomponents: a standardized test suite (GeoJSEval-Bench), a code submission\nengine, and an evaluation module. It includes 432 function-level tasks and\n2,071 structured test cases spanning five widely used JavaScript geospatial\nlibraries and 25 mainstream geospatial data types. GeoJSEval enables\nmultidimensional quantitative evaluation across metrics such as accuracy,\noutput stability, execution efficiency, resource consumption, and error type\ndistribution, and integrates boundary testing mechanisms to enhance robustness\nand coverage. We conduct a comprehensive evaluation of 18 state-of-the-art LLMs\nusing GeoJSEval, revealing significant performance disparities and bottlenecks\nin spatial semantic understanding, code reliability, and function invocation\naccuracy. GeoJSEval provides a foundational methodology, evaluation resource,\nand practical toolkit for the standardized assessment and optimization of\ngeospatial code generation models, with strong extensibility and applicability\nin real-world scenarios.", "AI": {"tldr": "GeoJSEval\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u3001\u529f\u80fd\u7ea7\u7684\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728JavaScript\u5730\u7406\u7a7a\u95f4\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5730\u7406\u7a7a\u95f4\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4e9f\u9700\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cf\u5176\u5728\u5730\u7406\u7a7a\u95f4\u4e0a\u4e0b\u6587\u4e2d\u7684\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86GeoJSEval\u6846\u67b6\uff0c\u5305\u62ec\u6807\u51c6\u5316\u6d4b\u8bd5\u5957\u4ef6(GeoJSEval-Bench)\u3001\u4ee3\u7801\u63d0\u4ea4\u5f15\u64ce\u548c\u8bc4\u4f30\u6a21\u5757\uff0c\u6db5\u76d6432\u4e2a\u529f\u80fd\u7ea7\u4efb\u52a1\u548c2,071\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u8bc4\u4f30\u4e8618\u79cd\u6700\u5148\u8fdb\u7684LLM\uff0c\u63ed\u793a\u4e86\u5728\u7a7a\u95f4\u8bed\u4e49\u7406\u89e3\u3001\u4ee3\u7801\u53ef\u9760\u6027\u548c\u529f\u80fd\u8c03\u7528\u51c6\u786e\u6027\u4e0a\u7684\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "GeoJSEval\u4e3a\u5730\u7406\u7a7a\u95f4\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u57fa\u7840\u65b9\u6cd5\u8bba\u548c\u5b9e\u7528\u5de5\u5177\uff0c\u5177\u6709\u5f3a\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u6027\u3002"}}
{"id": "2507.20261", "pdf": "https://arxiv.org/pdf/2507.20261", "abs": "https://arxiv.org/abs/2507.20261", "authors": ["Charu Tripathi", "Manish Arora", "Amaresh Chakrabarti"], "title": "Occupational Safety within Non-Routine Manufacturing Processes: Evaluating the Validity of Task-Based Ergonomic Assessments", "categories": ["cs.HC"], "comment": null, "summary": "Direct measurement ergonomic assessment is reshaping occupational safety by\nfacilitating highly reliable risk estimation. Industry 5.0, advocating\nhuman-centricity, has catalysed increasing adoption of direct measurement tools\nin manufacturing industries. However, due to technical and feasibility\nconstraints in their practical implementations, especially within non routine\nmanufacturing processes, task based approach to ergonomic assessment is\nutilized. Despite enabling operationalization of robust ergonomic assessment\ntechnologies within complicated industrial processes, task based approach\nraises several validity concerns. Hence, to ascertain functional utility of the\nresultant safety interventions, this study evaluates the construct validity of\ntask based ergonomic assessment within non routine work utilizing Multitrait\nmultimethod (MTMM) matrix followed by video-based content analysis. Ergonomic\nexposure traits were collected for 46 participants through direct measurement\nand self reported techniques utilizing inertial motion capture and Borg's RPE\nrating scale respectively. Findings include unsubstantiated convergent validity\n(low same trait correlations from 0.149 to 0.243) and weak evidence of\ndiscriminant validity with statistical significance (p value less than 0.001).\nThe study also identifies three primary factors undermining construct validity\nthrough video based content analysis. Findings also elucidate misinterpretation\nof ergonomic risk and action levels. Therefore, practical implications entail\nunderestimation of actual ergonomic risks when estimated through task based\nassessment. This highlights the need for enhancement in ergonomic assessment\ntechnologies focused on cumulative load analysis compatible within diverse\nindustrial processes.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u591a\u7279\u8d28\u591a\u65b9\u6cd5\uff08MTMM\uff09\u77e9\u9635\u548c\u89c6\u9891\u5185\u5bb9\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u975e\u4f8b\u884c\u5de5\u4f5c\u4e2d\u57fa\u4e8e\u4efb\u52a1\u7684\u5de5\u6548\u5b66\u8bc4\u4f30\u7684\u7ed3\u6784\u6548\u5ea6\uff0c\u53d1\u73b0\u5176\u6536\u655b\u6548\u5ea6\u548c\u533a\u5206\u6548\u5ea6\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u5de5\u4e1a5.0\u63a8\u52a8\u4eba\u672c\u5316\uff0c\u76f4\u63a5\u6d4b\u91cf\u5de5\u5177\u5728\u5236\u9020\u4e1a\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u4f46\u7531\u4e8e\u6280\u672f\u548c\u53ef\u884c\u6027\u9650\u5236\uff0c\u57fa\u4e8e\u4efb\u52a1\u7684\u5de5\u6548\u5b66\u8bc4\u4f30\u5728\u975e\u4f8b\u884c\u5de5\u4f5c\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u6548\u5ea6\u5b58\u5728\u95ee\u9898\uff0c\u9700\u8981\u9a8c\u8bc1\u548c\u6539\u8fdb\u3002", "method": "\u7814\u7a76\u91c7\u7528\u591a\u7279\u8d28\u591a\u65b9\u6cd5\uff08MTMM\uff09\u77e9\u9635\u548c\u89c6\u9891\u5185\u5bb9\u5206\u6790\uff0c\u7ed3\u5408\u60ef\u6027\u8fd0\u52a8\u6355\u6349\u548cBorg's RPE\u8bc4\u5206\u91cf\u8868\uff0c\u5bf946\u540d\u53c2\u4e0e\u8005\u7684\u5de5\u6548\u5b66\u66b4\u9732\u7279\u5f81\u8fdb\u884c\u4e86\u76f4\u63a5\u6d4b\u91cf\u548c\u81ea\u6211\u62a5\u544a\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u57fa\u4e8e\u4efb\u52a1\u7684\u5de5\u6548\u5b66\u8bc4\u4f30\u6536\u655b\u6548\u5ea6\u4e0d\u8db3\uff08\u76f8\u5173\u7cfb\u65700.149-0.243\uff09\uff0c\u533a\u5206\u6548\u5ea6\u8bc1\u636e\u8f83\u5f31\uff08\u663e\u8457\u6027p<0.001\uff09\uff0c\u5e76\u901a\u8fc7\u89c6\u9891\u5206\u6790\u8bc6\u522b\u4e86\u4e09\u4e2a\u5f71\u54cd\u6548\u5ea6\u7684\u4e3b\u8981\u56e0\u7d20\u548c\u8bef\u89e3\u98ce\u9669\u7684\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u57fa\u4e8e\u4efb\u52a1\u7684\u8bc4\u4f30\u53ef\u80fd\u4f4e\u4f30\u5b9e\u9645\u5de5\u6548\u5b66\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u5f00\u53d1\u4e13\u6ce8\u4e8e\u7d2f\u79ef\u8d1f\u8377\u5206\u6790\u4e14\u9002\u7528\u4e8e\u591a\u6837\u5316\u5de5\u4e1a\u6d41\u7a0b\u7684\u5de5\u6548\u5b66\u8bc4\u4f30\u6280\u672f\u3002"}}
{"id": "2507.20434", "pdf": "https://arxiv.org/pdf/2507.20434", "abs": "https://arxiv.org/abs/2507.20434", "authors": ["Alessandro Giaconia", "Muoi Tran", "Laurent Vanbever", "Stefano Vissicchio"], "title": "Is Crunching Public Data the Right Approach to Detect BGP Hijacks?", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "The Border Gateway Protocol (BGP) remains a fragile pillar of Internet\nrouting. BGP hijacks still occurr daily. While full deployment of Route Origin\nValidation (ROV) is ongoing, attackers have already adapted, launching post-ROV\nattacks such as forged-origin hijacks. To detect these, recent approaches like\nDFOH [Holterbach et al., USENIX NSDI '24] and BEAM [Chen et al., USENIX\nSecurity '24] apply machine learning (ML) to analyze data from globally\ndistributed BGP monitors, assuming anomalies will stand out against historical\npatterns. However, this assumption overlooks a key threat: BGP monitors\nthemselves can be misled by adversaries injecting bogus routes. This paper\nshows that state-of-the-art hijack detection systems like DFOH and BEAM are\nvulnerable to data poisoning. Using large-scale BGP simulations, we show that\nattackers can evade detection with just a handful of crafted announcements\nbeyond the actual hijack. These announcements are indeed sufficient to corrupt\nthe knowledge base used by ML-based defenses and distort the metrics they rely\non. Our results highlight a worrying weakness of relying solely on public BGP\ndata.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\uff0c\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684BGP\u52ab\u6301\u68c0\u6d4b\u7cfb\u7edf\uff08\u5982DFOH\u548cBEAM\uff09\u5bb9\u6613\u53d7\u5230\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u653b\u51fb\u8005\u53ea\u9700\u5c11\u91cf\u4f2a\u9020\u7684\u8def\u7531\u516c\u544a\u5373\u53ef\u7ed5\u8fc7\u68c0\u6d4b\u3002", "motivation": "\u5c3d\u7ba1ROV\u6b63\u5728\u5168\u9762\u90e8\u7f72\uff0c\u4f46\u653b\u51fb\u8005\u5df2\u9002\u5e94\u5e76\u63a8\u51fa\u4e86\u540eROV\u653b\u51fb\uff0c\u5982\u4f2a\u9020\u8d77\u6e90\u52ab\u6301\u3002\u73b0\u6709\u7684ML\u68c0\u6d4b\u7cfb\u7edf\u4f9d\u8d56\u5168\u5c40BGP\u76d1\u89c6\u5668\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u53ef\u80fd\u88ab\u5bf9\u624b\u8bef\u5bfc\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21BGP\u6a21\u62df\uff0c\u5c55\u793a\u653b\u51fb\u8005\u5982\u4f55\u5229\u7528\u5c11\u91cf\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8def\u7531\u516c\u544a\u7ed5\u8fc7DFOH\u548cBEAM\u7b49\u68c0\u6d4b\u7cfb\u7edf\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4ec5\u4f9d\u9760\u516c\u5f00BGP\u6570\u636e\u5b58\u5728\u4e25\u91cd\u5f31\u70b9\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u8f7b\u677e\u6c61\u67d3ML\u9632\u5fa1\u7cfb\u7edf\u7684\u77e5\u8bc6\u5e93\u5e76\u626d\u66f2\u5176\u4f9d\u8d56\u7684\u6307\u6807\u3002", "conclusion": "\u8bba\u6587\u547c\u5401\u6539\u8fdb\u73b0\u6709BGP\u52ab\u6301\u68c0\u6d4b\u65b9\u6cd5\uff0c\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\u53ef\u80fd\u88ab\u6c61\u67d3\u7684\u516c\u5f00\u6570\u636e\u3002"}}
{"id": "2507.20619", "pdf": "https://arxiv.org/pdf/2507.20619", "abs": "https://arxiv.org/abs/2507.20619", "authors": ["Binhang Qi", "Yun Lin", "Xinyi Weng", "Yuhuan Huang", "Chenyan Liu", "Hailong Sun", "Jin Song Dong"], "title": "Intention-Driven Generation of Project-Specific Test Cases", "categories": ["cs.SE"], "comment": null, "summary": "Test cases are valuable assets for maintaining software quality. While\nnumerous automated techniques have been proposed for generating tests (either\nby maximizing code coverage or by translating focal code into test code),\npractical tests are seldom driven by coverage alone. In real projects, each\ntest reflects a developer's validation intention for a specific behaviour and\nembodies rich, project-specific knowledge: which specific APIs to call and what\nassertions truly matter. Without considering such knowledge, tests can hardly\npass code review and be integrated into the software product.\n  In this work, we propose IntentionTest, which generates project-specific\ntests with validation intention as a structured description. Our design is\nmotivated by two insights: (1) a description of validation intention, compared\nto coverage and focal code, carries more crucial information about what to\ntest; and (2) practical tests exhibit high code duplication, indicating that\ndomain knowledge is highly reusable for writing new tests. Given a focal code\nand a description of validation intention (in the form of either an informal\ncomment or a formal test plan), IntentionTest retrieves a referable test in the\nproject to guide test generation. Moreover, IntentionTest reduces the test\ngeneration problem into an editing problem on the test code regarding the\nvalidation intention. It generates a test including both test prefix and\noracle, which aims to be executable and semantically correct.\n  We evaluate IntentionTest against state-of-the-art baselines on 4,146 test\ncases from 13 open-source projects. Specifically, compared to ChatTester,\nIntentionTest can (1) generate significantly more semantically correct tests,\nimproving common mutation scores by 39.03% and coverage overlap with\nground-truth tests by 40.14%; (2) generate 21.30% more successful passing\ntests.", "AI": {"tldr": "IntentionTest\u662f\u4e00\u79cd\u57fa\u4e8e\u9a8c\u8bc1\u610f\u56fe\u751f\u6210\u9879\u76ee\u7279\u5b9a\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63cf\u8ff0\u548c\u4ee3\u7801\u590d\u7528\u63d0\u9ad8\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u548c\u901a\u8fc7\u7387\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u751f\u6210\u6280\u672f\u901a\u5e38\u4ec5\u5173\u6ce8\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u4f46\u5b9e\u9645\u9879\u76ee\u4e2d\u6d4b\u8bd5\u9700\u8981\u53cd\u6620\u5f00\u53d1\u8005\u7684\u9a8c\u8bc1\u610f\u56fe\u548c\u9879\u76ee\u7279\u5b9a\u77e5\u8bc6\u3002", "method": "IntentionTest\u5229\u7528\u9a8c\u8bc1\u610f\u56fe\u7684\u7ed3\u6784\u5316\u63cf\u8ff0\uff0c\u901a\u8fc7\u68c0\u7d22\u9879\u76ee\u4e2d\u7684\u53ef\u53c2\u8003\u6d4b\u8bd5\u5e76\u51cf\u5c11\u751f\u6210\u95ee\u9898\u4e3a\u4ee3\u7801\u7f16\u8f91\u95ee\u9898\u6765\u751f\u6210\u6d4b\u8bd5\u3002", "result": "\u572813\u4e2a\u5f00\u6e90\u9879\u76ee\u76844,146\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0cIntentionTest\u751f\u6210\u7684\u6d4b\u8bd5\u8bed\u4e49\u6b63\u786e\u7387\u66f4\u9ad8\uff0c\u7a81\u53d8\u5206\u6570\u63d0\u534739.03%\uff0c\u8986\u76d6\u7387\u91cd\u53e0\u63d0\u534740.14%\uff0c\u901a\u8fc7\u7387\u63d0\u9ad821.30%\u3002", "conclusion": "IntentionTest\u901a\u8fc7\u7ed3\u5408\u9a8c\u8bc1\u610f\u56fe\u548c\u9879\u76ee\u7279\u5b9a\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u751f\u6210\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.20355", "pdf": "https://arxiv.org/pdf/2507.20355", "abs": "https://arxiv.org/abs/2507.20355", "authors": ["Zheng Wei", "Hongtao Wu", "lvmin Zhang", "Xian Xu", "Yefeng Zheng", "Pan Hui", "Maneesh Agrawala", "Huamin Qu", "Anyi Rao"], "title": "CineVision: An Interactive Pre-visualization Storyboard System for Director-Cinematographer Collaboration", "categories": ["cs.HC"], "comment": null, "summary": "Effective communication between directors and cinematographers is fundamental\nin film production, yet traditional approaches relying on visual references and\nhand-drawn storyboards often lack the efficiency and precision necessary during\npre-production. We present CineVision, an AI-driven platform that integrates\nscriptwriting with real-time visual pre-visualization to bridge this\ncommunication gap. By offering dynamic lighting control, style emulation based\non renowned filmmakers, and customizable character design, CineVision enables\ndirectors to convey their creative vision with heightened clarity and rapidly\niterate on scene composition. In a 24-participant lab study, CineVision yielded\nshorter task times and higher usability ratings than two baseline methods,\nsuggesting a potential to ease early-stage communication and accelerate\nstoryboard drafts under controlled conditions. These findings underscore\nCineVision's potential to streamline pre-production processes and foster deeper\ncreative synergy among filmmaking teams, particularly for new collaborators.Our\ncode and demo are available at https://github.com/TonyHongtaoWu/CineVision.", "AI": {"tldr": "CineVision\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u5e73\u53f0\uff0c\u901a\u8fc7\u6574\u5408\u5267\u672c\u5199\u4f5c\u548c\u5b9e\u65f6\u53ef\u89c6\u5316\u9884\u6f14\uff0c\u63d0\u5347\u5bfc\u6f14\u548c\u6444\u5f71\u5e08\u95f4\u7684\u6c9f\u901a\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u4f9d\u8d56\u89c6\u89c9\u53c2\u8003\u548c\u624b\u7ed8\u6545\u4e8b\u677f\u7684\u65b9\u6cd5\u5728\u9884\u5236\u4f5c\u9636\u6bb5\u7f3a\u4e4f\u6548\u7387\u548c\u7cbe\u786e\u6027\uff0cCineVision\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5e73\u53f0\u63d0\u4f9b\u52a8\u6001\u706f\u5149\u63a7\u5236\u3001\u98ce\u683c\u6a21\u4eff\u548c\u53ef\u5b9a\u5236\u89d2\u8272\u8bbe\u8ba1\uff0c\u5e2e\u52a9\u5bfc\u6f14\u6e05\u6670\u8868\u8fbe\u521b\u610f\u3002", "result": "\u572824\u4eba\u5b9e\u9a8c\u4e2d\uff0cCineVision\u5728\u4efb\u52a1\u65f6\u95f4\u548c\u53ef\u7528\u6027\u8bc4\u5206\u4e0a\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "CineVision\u6709\u671b\u4f18\u5316\u9884\u5236\u4f5c\u6d41\u7a0b\uff0c\u4fc3\u8fdb\u56e2\u961f\u534f\u4f5c\uff0c\u7279\u522b\u9002\u7528\u4e8e\u65b0\u5408\u4f5c\u8005\u3002"}}
{"id": "2507.20966", "pdf": "https://arxiv.org/pdf/2507.20966", "abs": "https://arxiv.org/abs/2507.20966", "authors": ["Hussein A. Ammar", "Raviraj Adve", "Shahram Shahbazpanahi", "Gary Boudreau", "Israfil Bahceci"], "title": "Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL", "categories": ["cs.IT", "cs.AI", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "comment": "Published in IEEE Transactions on Communications (IEEE TCOM)", "summary": "In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user\nmobility necessitates updating the set of serving access points to maintain the\nuser-centric clustering. Such updates are typically performed through handoff\n(HO) operations; however, frequent HOs lead to overheads associated with the\nallocation and release of resources. This paper presents a deep reinforcement\nlearning (DRL)-based solution to predict and manage these connections for\nmobile users. Our solution employs the Soft Actor-Critic algorithm, with\ncontinuous action space representation, to train a deep neural network to serve\nas the HO policy. We present a novel proposition for a reward function that\nintegrates a HO penalty in order to balance the attainable rate and the\nassociated overhead related to HOs. We develop two variants of our system; the\nfirst one uses mobility direction-assisted (DA) observations that are based on\nthe user movement pattern, while the second one uses history-assisted (HA)\nobservations that are based on the history of the large-scale fading (LSF).\nSimulation results show that our DRL-based continuous action space approach is\nmore scalable than discrete space counterpart, and that our derived HO policy\nautomatically learns to gather HOs in specific time slots to minimize the\noverhead of initiating HOs. Our solution can also operate in real time with a\nresponse time less than 0.4 ms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u7ba1\u7406\u7528\u6237\u79fb\u52a8\u65f6\u7684\u8fde\u63a5\u5207\u6362\uff0c\u4ee5\u51cf\u5c11\u9891\u7e41\u5207\u6362\u5e26\u6765\u7684\u5f00\u9500\u3002", "motivation": "\u5728\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7f51\u7edc\u4e2d\uff0c\u7528\u6237\u79fb\u52a8\u6027\u5bfc\u81f4\u9891\u7e41\u7684\u8fde\u63a5\u5207\u6362\uff0c\u5e26\u6765\u8d44\u6e90\u5206\u914d\u548c\u91ca\u653e\u7684\u5f00\u9500\uff0c\u9700\u8981\u4f18\u5316\u7ba1\u7406\u3002", "method": "\u4f7f\u7528Soft Actor-Critic\u7b97\u6cd5\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u5207\u6362\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u5207\u6362\u60e9\u7f5a\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u5f00\u53d1\u4e86\u4e24\u79cd\u89c2\u5bdf\u6a21\u5f0f\uff08\u65b9\u5411\u8f85\u52a9\u548c\u5386\u53f2\u8f85\u52a9\uff09\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u65b9\u6cd5\u6bd4\u79bb\u6563\u65b9\u6cd5\u66f4\u5177\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u7b56\u7565\u80fd\u81ea\u52a8\u5b66\u4e60\u5728\u7279\u5b9a\u65f6\u9699\u96c6\u4e2d\u5207\u6362\u4ee5\u6700\u5c0f\u5316\u5f00\u9500\uff0c\u54cd\u5e94\u65f6\u95f4\u5c0f\u4e8e0.4\u6beb\u79d2\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u7ba1\u7406\u7528\u6237\u79fb\u52a8\u65f6\u7684\u8d44\u6e90\u5207\u6362\uff0c\u663e\u8457\u51cf\u5c11\u5f00\u9500\u5e76\u5b9e\u73b0\u5b9e\u65f6\u54cd\u5e94\u3002"}}
{"id": "2507.20814", "pdf": "https://arxiv.org/pdf/2507.20814", "abs": "https://arxiv.org/abs/2507.20814", "authors": ["Gustave Monce", "Thomas Degueule", "Jean-R\u00e9my Falleri", "Romain Robbes"], "title": "Client--Library Compatibility Testing with API Interaction Snapshots", "categories": ["cs.SE"], "comment": null, "summary": "Modern software development heavily relies on third-party libraries to speed\nup development and enhance quality. As libraries evolve, they may break the\ntacit contract established with their clients by introducing behavioral\nbreaking changes (BBCs) that alter run-time behavior and silently break client\napplications without being detected at compile time. Traditional regression\ntests on the client side often fail to detect such BBCs, either due to limited\nlibrary coverage or weak assertions that do not sufficiently exercise the\nlibrary's expected behavior. To address this issue, we propose a novel approach\nto client--library compatibility testing that leverages existing client tests\nin a novel way. Instead of relying on developer-written assertions, we propose\nrecording the actual interactions at the API boundary during the execution of\nclient tests (protocol, input and output values, exceptions, etc.). These\nsequences of API interactions are stored as snapshots which capture the exact\ncontract expected by a client at a specific point in time. As the library\nevolves, we compare the original and new snapshots to identify perturbations in\nthe contract, flag potential BBCs, and notify clients. We implement this\ntechnique in our prototype tool Gilesi, a Java framework that automatically\ninstruments library APIs, records snapshots, and compares them. Through a\npreliminary case study on several client--library pairs with artificially\nseeded BBCs, we show that Gilesi reliably detects BBCs missed by client test\nsuites.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u68c0\u6d4b\u5e93\u884c\u4e3a\u7834\u574f\u6027\u53d8\u66f4\uff08BBCs\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bb0\u5f55\u5ba2\u6237\u7aef\u6d4b\u8bd5\u4e2d\u7684API\u4ea4\u4e92\u5feb\u7167\u5e76\u6bd4\u8f83\u5e93\u6f14\u5316\u524d\u540e\u7684\u5dee\u5f02\uff0c\u4ece\u800c\u8bc6\u522bBBCs\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4f9d\u8d56\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f46\u5e93\u7684\u6f14\u5316\u53ef\u80fd\u5bfc\u81f4\u884c\u4e3a\u7834\u574f\u6027\u53d8\u66f4\uff08BBCs\uff09\uff0c\u4f20\u7edf\u5ba2\u6237\u7aef\u6d4b\u8bd5\u96be\u4ee5\u68c0\u6d4b\u8fd9\u7c7b\u53d8\u66f4\u3002", "method": "\u5229\u7528\u5ba2\u6237\u7aef\u6d4b\u8bd5\u7684API\u4ea4\u4e92\u5feb\u7167\u8bb0\u5f55\u534f\u8bae\u3001\u8f93\u5165\u8f93\u51fa\u503c\u7b49\uff0c\u901a\u8fc7\u6bd4\u8f83\u5feb\u7167\u53d8\u5316\u8bc6\u522bBBCs\u3002\u5b9e\u73b0\u5de5\u5177\u4e3aGilesi\u3002", "result": "\u521d\u6b65\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cGilesi\u80fd\u53ef\u9760\u68c0\u6d4b\u51fa\u5ba2\u6237\u7aef\u6d4b\u8bd5\u9057\u6f0f\u7684BBCs\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6d4b\u8bd5\u96be\u4ee5\u68c0\u6d4bBBCs\u7684\u95ee\u9898\uff0c\u4e3a\u5ba2\u6237\u7aef-\u5e93\u517c\u5bb9\u6027\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.20437", "pdf": "https://arxiv.org/pdf/2507.20437", "abs": "https://arxiv.org/abs/2507.20437", "authors": ["Kian Mahmoodi", "Yudong Xie", "Tan Gemicioglu", "Chi-Jung Lee", "Jiwan Kim", "Cheng Zhang"], "title": "EchoForce: Continuous Grip Force Estimation from Skin Deformation Using Active Acoustic Sensing on a Wristband", "categories": ["cs.HC"], "comment": "8 pages, 3 figures. Proceedings of the 2025 ACM International\n  Symposium on Wearable Computers (ISWC '25)", "summary": "Grip force is commonly used as an overall health indicator in older adults\nand is valuable for tracking progress in physical training and rehabilitation.\nExisting methods for wearable grip force measurement are cumbersome and\nuser-dependent, making them insufficient for practical, continuous grip force\nmeasurement. We introduce EchoForce, a novel wristband using acoustic sensing\nfor low-cost, non-contact measurement of grip force. EchoForce captures\nacoustic signals reflected from subtle skin deformations by flexor muscles on\nthe forearm. In a user study with 11 participants, EchoForce achieved a\nfine-tuned user-dependent mean error rate of 9.08% and a user-independent mean\nerror rate of 12.3% using a foundation model. Our system remained accurate\nbetween sessions, hand orientations, and users, overcoming a significant\nlimitation of past force sensing systems. EchoForce makes continuous grip force\nmeasurement practical, providing an effective tool for health monitoring and\nnovel interaction techniques.", "AI": {"tldr": "EchoForce\u662f\u4e00\u6b3e\u65b0\u578b\u8155\u5e26\u8bbe\u5907\uff0c\u5229\u7528\u58f0\u5b66\u4f20\u611f\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u975e\u63a5\u89e6\u5f0f\u63e1\u529b\u6d4b\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u9002\u7528\u4e8e\u5065\u5eb7\u76d1\u6d4b\u548c\u4eba\u673a\u4ea4\u4e92\u3002", "motivation": "\u63e1\u529b\u662f\u8001\u5e74\u4eba\u5065\u5eb7\u7684\u91cd\u8981\u6307\u6807\uff0c\u73b0\u6709\u7a7f\u6234\u5f0f\u6d4b\u91cf\u65b9\u6cd5\u4e0d\u4fbf\u4e14\u4f9d\u8d56\u7528\u6237\uff0cEchoForce\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u5b9e\u7528\u7684\u8fde\u7eed\u63e1\u529b\u6d4b\u91cf\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6355\u6349\u524d\u81c2\u5c48\u808c\u7ec6\u5fae\u76ae\u80a4\u53d8\u5f62\u53cd\u5c04\u7684\u58f0\u5b66\u4fe1\u53f7\u8fdb\u884c\u63e1\u529b\u6d4b\u91cf\uff0c\u91c7\u7528\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u7528\u6237\u4f9d\u8d56\u548c\u975e\u4f9d\u8d56\u7684\u8bef\u5dee\u5206\u6790\u3002", "result": "\u572811\u540d\u53c2\u4e0e\u8005\u7684\u7814\u7a76\u4e2d\uff0c\u7528\u6237\u4f9d\u8d56\u548c\u975e\u4f9d\u8d56\u7684\u5e73\u5747\u8bef\u5dee\u5206\u522b\u4e3a9.08%\u548c12.3%\uff0c\u7cfb\u7edf\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u4fdd\u6301\u51c6\u786e\u3002", "conclusion": "EchoForce\u4e3a\u8fde\u7eed\u63e1\u529b\u6d4b\u91cf\u63d0\u4f9b\u4e86\u53ef\u884c\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u5065\u5eb7\u76d1\u6d4b\u548c\u65b0\u578b\u4ea4\u4e92\u6280\u672f\u3002"}}
{"id": "2507.20655", "pdf": "https://arxiv.org/pdf/2507.20655", "abs": "https://arxiv.org/abs/2507.20655", "authors": ["Zixin Chen", "Jiachen Wang", "Yumeng Li", "Haobo Li", "Chuhan Shi", "Rong Zhang", "Huamin Qu"], "title": "CoGrader: Transforming Instructors' Assessment of Project Reports through Collaborative LLM Integration", "categories": ["cs.HC"], "comment": null, "summary": "Grading project reports are increasingly significant in today's educational\nlandscape, where they serve as key assessments of students' comprehensive\nproblem-solving abilities. However, it remains challenging due to the\nmultifaceted evaluation criteria involved, such as creativity and\npeer-comparative achievement. Meanwhile, instructors often struggle to maintain\nfairness throughout the time-consuming grading process. Recent advances in AI,\nparticularly large language models, have demonstrated potential for automating\nsimpler grading tasks, such as assessing quizzes or basic writing quality.\nHowever, these tools often fall short when it comes to complex metrics, like\ndesign innovation and the practical application of knowledge, that require an\ninstructor's educational insights into the class situation. To address this\nchallenge, we conducted a formative study with six instructors and developed\nCoGrader, which introduces a novel grading workflow combining human-LLM\ncollaborative metrics design, benchmarking, and AI-assisted feedback. CoGrader\nwas found effective in improving grading efficiency and consistency while\nproviding reliable peer-comparative feedback to students. We also discuss\ndesign insights and ethical considerations for the development of human-AI\ncollaborative grading systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCoGrader\uff0c\u4e00\u79cd\u7ed3\u5408\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u7684\u8bc4\u5206\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u590d\u6742\u9879\u76ee\u62a5\u544a\u7684\u516c\u5e73\u6027\u4e0e\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u6559\u80b2\u4e2d\uff0c\u9879\u76ee\u62a5\u544a\u8bc4\u5206\u56e0\u591a\u7ef4\u5ea6\u6807\u51c6\uff08\u5982\u521b\u9020\u529b\u548c\u5b9e\u8df5\u80fd\u529b\uff09\u548c\u6559\u5e08\u8d1f\u62c5\u800c\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u7684AI\u5de5\u5177\u96be\u4ee5\u5904\u7406\u590d\u6742\u8bc4\u5206\u6307\u6807\u3002", "method": "\u901a\u8fc7\u516d\u540d\u6559\u5e08\u7684\u5f62\u5f0f\u5316\u7814\u7a76\uff0c\u8bbe\u8ba1\u4e86CoGrader\uff0c\u6574\u5408\u4eba\u7c7b\u4e0eAI\u7684\u534f\u4f5c\u6307\u6807\u8bbe\u8ba1\u3001\u57fa\u51c6\u6d4b\u8bd5\u548cAI\u8f85\u52a9\u53cd\u9988\u3002", "result": "CoGrader\u6709\u6548\u63d0\u5347\u4e86\u8bc4\u5206\u6548\u7387\u548c\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u4e3a\u5b66\u751f\u63d0\u4f9b\u53ef\u9760\u7684\u540c\u4f34\u6bd4\u8f83\u53cd\u9988\u3002", "conclusion": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u673a\u534f\u4f5c\u8bc4\u5206\u7cfb\u7edf\u7684\u8bbe\u8ba1\u6d1e\u5bdf\u4e0e\u4f26\u7406\u8003\u91cf\uff0c\u5f3a\u8c03\u4e86\u5176\u6f5c\u529b\u4e0e\u6311\u6218\u3002"}}
{"id": "2507.20888", "pdf": "https://arxiv.org/pdf/2507.20888", "abs": "https://arxiv.org/abs/2507.20888", "authors": ["Le Deng", "Xiaoxue Ren", "Chao Ni", "Ming Liang", "David Lo", "Zhongxin Liu"], "title": "Enhancing Project-Specific Code Completion by Inferring Internal API Information", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Project-specific code completion is a critical task that leverages context\nfrom a project to generate accurate code. State-of-the-art methods use\nretrieval-augmented generation (RAG) with large language models (LLMs) and\nproject information for code completion. However, they often struggle to\nincorporate internal API information, which is crucial for accuracy, especially\nwhen APIs are not explicitly imported in the file.\n  To address this, we propose a method to infer internal API information\nwithout relying on imports. Our method extends the representation of APIs by\nconstructing usage examples and semantic descriptions, building a knowledge\nbase for LLMs to generate relevant completions. We also introduce ProjBench, a\nbenchmark that avoids leaked imports and consists of large-scale real-world\nprojects.\n  Experiments on ProjBench and CrossCodeEval show that our approach\nsignificantly outperforms existing methods, improving code exact match by\n22.72% and identifier exact match by 18.31%. Additionally, integrating our\nmethod with existing baselines boosts code match by 47.80% and identifier match\nby 35.55%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u5bfc\u5165\u5373\u53ef\u63a8\u65ad\u5185\u90e8API\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u9020API\u7684\u4f7f\u7528\u793a\u4f8b\u548c\u8bed\u4e49\u63cf\u8ff0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u5b8c\u6210\u4efb\u52a1\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u65b9\u6cd5\u5728\u4ee3\u7801\u5b8c\u6210\u4efb\u52a1\u4e2d\u96be\u4ee5\u6709\u6548\u5229\u7528\u672a\u663e\u5f0f\u5bfc\u5165\u7684\u5185\u90e8API\u4fe1\u606f\uff0c\u5f71\u54cd\u4e86\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55API\u7684\u8868\u793a\uff08\u5982\u6784\u9020\u4f7f\u7528\u793a\u4f8b\u548c\u8bed\u4e49\u63cf\u8ff0\uff09\u6784\u5efa\u77e5\u8bc6\u5e93\uff0c\u4f9bLLMs\u751f\u6210\u76f8\u5173\u8865\u5168\uff0c\u5e76\u5f15\u5165\u4e86ProjBench\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4ee3\u7801\u548c\u6807\u8bc6\u7b26\u7684\u5b8c\u5168\u5339\u914d\u7387\u4e0a\u5206\u522b\u63d0\u5347\u4e8622.72%\u548c18.31%\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u7ed3\u5408\u540e\u63d0\u5347\u66f4\u663e\u8457\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5185\u90e8API\u4fe1\u606f\u5229\u7528\u7684\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u5b8c\u6210\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2507.20656", "pdf": "https://arxiv.org/pdf/2507.20656", "abs": "https://arxiv.org/abs/2507.20656", "authors": ["Jonas Hummel", "Tobias R\u00f6ddiger", "Valeria Zitz", "Philipp Lepold", "Michael K\u00fcttner", "Marius Prill", "Christopher Clarke", "Hans Gellersen", "Michael Beigl"], "title": "EarXplore: An Open Research Database on Earable Interaction", "categories": ["cs.HC"], "comment": null, "summary": "Interaction with earables - earphones equipped with additional sensors - has\nbeen identified as one of four major areas of earable research. Worn naturally\nand positioned near key physiological signals, earables support a wide range of\ninteraction modalities and have demonstrated the ability to detect multiple\ninputs simultaneously. Yet this diversity has resulted in a fragmented body of\nresearch, making it increasingly difficult to track developments and identify\nrelevant studies. To address this, we introduce EarXplore, a curated,\ninteractive online database on earable interaction research. Designed through a\nquestion-centered process that guided both the development of 34 criteria\napplied to annotate 118 studies and the structure of the platform, EarXplore\ncomprises four distinct yet integrated views: a Tabular View for structured\nexploration, a Graphical View for visual overviews, a Similarity View for\nidentifying conceptual links, and a Timeline View for analyzing trends and\nscholarly lineage. We demonstrate how the platform supports tailored\nexploration, targeted filtering, and interactive information retrieval,\nallowing researchers to query the literature and synthesize information in the\nformat of their choice. We furthermore leverage the contents and capabilities\nof the platform to discuss the research gaps and opportunities in the field.\nWith built-in mechanisms for continuous community updates, EarXplore not only\nreflects the current state of the field but also evolves alongside it, serving\nas a living resource to inform and accelerate future developments.", "AI": {"tldr": "EarXplore\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u5728\u7ebf\u6570\u636e\u5e93\uff0c\u65e8\u5728\u6574\u5408\u548c\u5c55\u793a\u8033\u6234\u8bbe\u5907\u4ea4\u4e92\u7814\u7a76\u7684\u788e\u7247\u5316\u6210\u679c\u3002", "motivation": "\u8033\u6234\u8bbe\u5907\u7814\u7a76\u9886\u57df\u591a\u6837\u5316\u4e14\u5206\u6563\uff0c\u96be\u4ee5\u8ffd\u8e2a\u76f8\u5173\u8fdb\u5c55\u3002", "method": "\u901a\u8fc7\u95ee\u9898\u5bfc\u5411\u7684\u65b9\u6cd5\u5f00\u53d1\u4e8634\u4e2a\u6807\u51c6\uff0c\u6807\u6ce8\u4e86118\u9879\u7814\u7a76\uff0c\u5e76\u6784\u5efa\u4e86\u56db\u79cd\u89c6\u56fe\uff08\u8868\u683c\u3001\u56fe\u5f62\u3001\u76f8\u4f3c\u6027\u548c\u65f6\u95f4\u7ebf\uff09\u3002", "result": "EarXplore\u652f\u6301\u4e2a\u6027\u5316\u63a2\u7d22\u3001\u7b5b\u9009\u548c\u4fe1\u606f\u68c0\u7d22\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u5206\u6790\u8d8b\u52bf\u548c\u5b66\u672f\u8109\u7edc\u3002", "conclusion": "EarXplore\u662f\u4e00\u4e2a\u52a8\u6001\u8d44\u6e90\uff0c\u53ef\u63a8\u52a8\u672a\u6765\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2507.20977", "pdf": "https://arxiv.org/pdf/2507.20977", "abs": "https://arxiv.org/abs/2507.20977", "authors": ["Maria Camporese", "Fabio Massacci"], "title": "Repairing vulnerabilities without invisible hands. A differentiated replication study on LLMs", "categories": ["cs.SE", "cs.CR", "cs.LG"], "comment": null, "summary": "Background: Automated Vulnerability Repair (AVR) is a fast-growing branch of\nprogram repair. Recent studies show that large language models (LLMs)\noutperform traditional techniques, extending their success beyond code\ngeneration and fault detection.\n  Hypothesis: These gains may be driven by hidden factors -- \"invisible hands\"\nsuch as training-data leakage or perfect fault localization -- that let an LLM\nreproduce human-authored fixes for the same code.\n  Objective: We replicate prior AVR studies under controlled conditions by\ndeliberately adding errors to the reported vulnerability location in the\nprompt. If LLMs merely regurgitate memorized fixes, both small and large\nlocalization errors should yield the same number of correct patches, because\nany offset should divert the model from the original fix.\n  Method: Our pipeline repairs vulnerabilities from the Vul4J and VJTrans\nbenchmarks after shifting the fault location by n lines from the ground truth.\nA first LLM generates a patch, a second LLM reviews it, and we validate the\nresult with regression and proof-of-vulnerability tests. Finally, we manually\naudit a sample of patches and estimate the error rate with the\nAgresti-Coull-Wilson method.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u4fee\u590d\u6f0f\u6d1e\uff08AVR\uff09\u4e2d\u7684\u8868\u73b0\u662f\u5426\u4f9d\u8d56\u4e8e\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u6216\u5b8c\u7f8e\u9519\u8bef\u5b9a\u4f4d\u7b49\u9690\u85cf\u56e0\u7d20\u3002\u901a\u8fc7\u6545\u610f\u5728\u63d0\u793a\u4e2d\u5f15\u5165\u9519\u8bef\u7684\u4f4d\u7f6e\u504f\u79fb\uff0c\u7814\u7a76\u8005\u9a8c\u8bc1\u4e86LLM\u662f\u5426\u4ec5\u8bb0\u5fc6\u4e86\u4eba\u7c7b\u4fee\u590d\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63ed\u793aLLM\u5728AVR\u4e2d\u8868\u73b0\u4f18\u5f02\u7684\u6f5c\u5728\u539f\u56e0\uff0c\u5c24\u5176\u662f\u662f\u5426\u5b58\u5728\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u6216\u5b8c\u7f8e\u9519\u8bef\u5b9a\u4f4d\u7b49\u201c\u9690\u5f62\u56e0\u7d20\u201d\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a\u5728Vul4J\u548cVJTrans\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6545\u610f\u504f\u79fb\u6f0f\u6d1e\u4f4d\u7f6e\uff0c\u4f7f\u7528\u4e24\u4e2aLLM\u5206\u522b\u751f\u6210\u548c\u5ba1\u67e5\u4fee\u590d\u8865\u4e01\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u548c\u6f0f\u6d1e\u9a8c\u8bc1\u6d4b\u8bd5\u9a8c\u8bc1\u7ed3\u679c\u3002\u6700\u540e\u624b\u52a8\u5ba1\u6838\u6837\u672c\u5e76\u4f30\u8ba1\u9519\u8bef\u7387\u3002", "result": "\u7ed3\u679c\u5c06\u5c55\u793a\u504f\u79fb\u4f4d\u7f6e\u540eLLM\u662f\u5426\u4ecd\u80fd\u751f\u6210\u6b63\u786e\u8865\u4e01\uff0c\u4ece\u800c\u9a8c\u8bc1\u5176\u662f\u5426\u4ec5\u4f9d\u8d56\u8bb0\u5fc6\u4fee\u590d\u65b9\u6848\u3002", "conclusion": "\u7ed3\u8bba\u5c06\u56de\u7b54LLM\u5728AVR\u4e2d\u7684\u8868\u73b0\u662f\u5426\u786e\u5b9e\u4f9d\u8d56\u4e8e\u9690\u85cf\u56e0\u7d20\uff0c\u8fd8\u662f\u5177\u5907\u771f\u6b63\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.20720", "pdf": "https://arxiv.org/pdf/2507.20720", "abs": "https://arxiv.org/abs/2507.20720", "authors": ["Tiffany Tseng", "Katelyn Lam", "Tiffany Lin Fu", "Alekhya Maram"], "title": "Beyond Text: Probing K-12 Educators' Perspectives and Ideas for Learning Opportunities Leveraging Multimodal Large Language Models", "categories": ["cs.HC"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are beginning to empower new user\nexperiences that can flexibly generate content from a range of inputs,\nincluding images, text, speech, and video. These capabilities have the\npotential to enrich learning by enabling users to capture and interact with\ninformation using a variety of modalities, but little is known about how\neducators envision how MLLMs might shape the future of learning experiences,\nwhat challenges diverse teachers encounter when interpreting how these models\nwork, and what practical needs should be considered for successful\nimplementation in educational contexts. We investigated educator perspectives\nthrough formative workshops with 12 K-12 educators, where participants\nbrainstormed learning opportunities, discussed practical concerns for effective\nuse, and prototyped their own MLLM-powered learning applications using Claude\n3.5 and its Artifacts feature for previewing code-based output. We use case\nstudies to illustrate two contrasting end-user approaches (teacher-and\nstudent-driven), and share insights about opportunities and concerns expressed\nby our participants, ending with implications for leveraging MLLMs for future\nlearning experiences.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8K-12\u6559\u80b2\u5de5\u4f5c\u8005\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u6559\u80b2\u4e2d\u7684\u770b\u6cd5\uff0c\u901a\u8fc7\u7814\u8ba8\u4f1a\u6536\u96c6\u53cd\u9988\uff0c\u5c55\u793a\u6559\u5e08\u548c\u5b66\u751f\u9a71\u52a8\u7684\u4e24\u79cd\u5e94\u7528\u6848\u4f8b\uff0c\u5e76\u5206\u6790\u672a\u6765\u5b66\u4e60\u4f53\u9a8c\u7684\u673a\u4f1a\u4e0e\u6311\u6218\u3002", "motivation": "\u4e86\u89e3\u6559\u80b2\u5de5\u4f5c\u8005\u5982\u4f55\u8bbe\u60f3MLLMs\u5728\u672a\u6765\u7684\u5b66\u4e60\u4f53\u9a8c\u4e2d\u53d1\u6325\u4f5c\u7528\uff0c\u4ee5\u53ca\u5982\u4f55\u5e94\u5bf9\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u7684\u6311\u6218\u548c\u9700\u6c42\u3002", "method": "\u901a\u8fc712\u540dK-12\u6559\u80b2\u5de5\u4f5c\u8005\u7684\u7814\u8ba8\u4f1a\uff0c\u6536\u96c6\u4ed6\u4eec\u5bf9MLLMs\u7684\u5b66\u4e60\u673a\u4f1a\u3001\u5b9e\u9645\u95ee\u9898\u548c\u5e94\u7528\u539f\u578b\u7684\u53cd\u9988\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u6559\u5e08\u548c\u5b66\u751f\u9a71\u52a8\u7684\u4e24\u79cdMLLM\u5e94\u7528\u65b9\u5f0f\uff0c\u5e76\u603b\u7ed3\u4e86\u53c2\u4e0e\u8005\u5bf9\u672a\u6765\u673a\u4f1a\u548c\u5b9e\u9645\u95ee\u9898\u7684\u770b\u6cd5\u3002", "conclusion": "MLLMs\u5728\u6559\u80b2\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u5173\u6ce8\u5b9e\u9645\u9700\u6c42\u548c\u6311\u6218\uff0c\u4ee5\u4f18\u5316\u672a\u6765\u5b66\u4e60\u4f53\u9a8c\u3002"}}
{"id": "2507.19489", "pdf": "https://arxiv.org/pdf/2507.19489", "abs": "https://arxiv.org/abs/2507.19489", "authors": ["Simone Bendazzoli", "Sanna Persson", "Mehdi Astaraki", "Sebastian Pettersson", "Vitali Grozman", "Rodrigo Moreno"], "title": "MAIA: A Collaborative Medical AI Platform for Integrated Healthcare Innovation", "categories": ["cs.AI", "cs.CV", "cs.HC", "cs.SE"], "comment": "26 pages, 12 figures", "summary": "The integration of Artificial Intelligence (AI) into clinical workflows\nrequires robust collaborative platforms that are able to bridge the gap between\ntechnical innovation and practical healthcare applications. This paper\nintroduces MAIA (Medical Artificial Intelligence Assistant), an open-source\nplatform designed to facilitate interdisciplinary collaboration among\nclinicians, researchers, and AI developers. Built on Kubernetes, MAIA offers a\nmodular, scalable environment with integrated tools for data management, model\ndevelopment, annotation, deployment, and clinical feedback. Key features\ninclude project isolation, CI/CD automation, integration with high-computing\ninfrastructures and in clinical workflows. MAIA supports real-world use cases\nin medical imaging AI, with deployments in both academic and clinical\nenvironments. By promoting collaborations and interoperability, MAIA aims to\naccelerate the translation of AI research into impactful clinical solutions\nwhile promoting reproducibility, transparency, and user-centered design. We\nshowcase the use of MAIA with different projects, both at KTH Royal Institute\nof Technology and Karolinska University Hospital.", "AI": {"tldr": "MAIA\u662f\u4e00\u4e2a\u5f00\u6e90\u5e73\u53f0\uff0c\u65e8\u5728\u901a\u8fc7\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u8bbe\u8ba1\u4fc3\u8fdb\u591a\u5b66\u79d1\u534f\u4f5c\uff0c\u52a0\u901fAI\u5728\u4e34\u5e8a\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3AI\u6280\u672f\u5728\u5b9e\u9645\u533b\u7597\u5e94\u7528\u4e2d\u7684\u843d\u5730\u96be\u9898\uff0c\u4fc3\u8fdb\u8de8\u9886\u57df\u534f\u4f5c\u3002", "method": "\u57fa\u4e8eKubernetes\u6784\u5efa\uff0c\u63d0\u4f9b\u6570\u636e\u7ba1\u7406\u3001\u6a21\u578b\u5f00\u53d1\u3001\u6807\u6ce8\u3001\u90e8\u7f72\u548c\u4e34\u5e8a\u53cd\u9988\u4e00\u4f53\u5316\u5de5\u5177\u3002", "result": "\u5df2\u5728\u5b66\u672f\u548c\u4e34\u5e8a\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u652f\u6301\u533b\u5b66\u6210\u50cfAI\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "MAIA\u901a\u8fc7\u534f\u4f5c\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u63a8\u52a8AI\u7814\u7a76\u5411\u4e34\u5e8a\u89e3\u51b3\u65b9\u6848\u7684\u9ad8\u6548\u8f6c\u5316\u3002"}}
{"id": "2507.21027", "pdf": "https://arxiv.org/pdf/2507.21027", "abs": "https://arxiv.org/abs/2507.21027", "authors": ["Lucia Bal\u00e1\u017eov\u00e1", "Richard Comploi-Taupe", "Susana Hahn", "Nicolas R\u00fchling", "Gottfried Schenner"], "title": "Smart Expansion Techniques for ASP-based Interactive Configuration", "categories": ["cs.AI", "cs.SE", "D.1.6; I.2.1"], "comment": "Under consideration for publication in Theory and Practice of Logic\n  Programming (TPLP)", "summary": "Product configuration is a successful application of Answer Set Programming\n(ASP). However, challenges are still open for interactive systems to\neffectively guide users through the configuration process. The aim of our work\nis to provide an ASP-based solver for interactive configuration that can deal\nwith large-scale industrial configuration problems and that supports intuitive\nuser interfaces via an API. In this paper, we focus on improving the\nperformance of automatically completing a partial configuration. Our main\ncontribution enhances the classical incremental approach for multi-shot solving\nby four different smart expansion functions. The core idea is to determine and\nadd specific objects or associations to the partial configuration by exploiting\ncautious and brave consequences before checking for the existence of a complete\nconfiguration with the current objects in each iteration. This approach limits\nthe number of costly unsatisfiability checks and reduces the search space,\nthereby improving solving performance. In addition, we present a user interface\nthat uses our API and is implemented in ASP.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eASP\u7684\u4ea4\u4e92\u5f0f\u914d\u7f6e\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u56db\u79cd\u667a\u80fd\u6269\u5c55\u51fd\u6570\u4f18\u5316\u90e8\u5206\u914d\u7f6e\u7684\u81ea\u52a8\u5b8c\u6210\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u6602\u8d35\u7684\u4e0d\u53ef\u6ee1\u8db3\u6027\u68c0\u67e5\u5e76\u7f29\u5c0f\u4e86\u641c\u7d22\u7a7a\u95f4\u3002", "motivation": "\u5c3d\u7ba1ASP\u5728\u4ea7\u54c1\u914d\u7f6e\u4e2d\u5e94\u7528\u6210\u529f\uff0c\u4f46\u4ea4\u4e92\u5f0f\u7cfb\u7edf\u4ecd\u9700\u89e3\u51b3\u5982\u4f55\u6709\u6548\u5f15\u5bfc\u7528\u6237\u5b8c\u6210\u914d\u7f6e\u7684\u6311\u6218\u3002", "method": "\u6539\u8fdb\u7ecf\u5178\u589e\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u56db\u79cd\u667a\u80fd\u6269\u5c55\u51fd\u6570\u5229\u7528\u8c28\u614e\u548c\u52c7\u6562\u7684\u63a8\u7406\u7ed3\u679c\uff0c\u4f18\u5316\u90e8\u5206\u914d\u7f6e\u7684\u81ea\u52a8\u5b8c\u6210\u6027\u80fd\u3002", "result": "\u51cf\u5c11\u4e86\u4e0d\u53ef\u6ee1\u8db3\u6027\u68c0\u67e5\u7684\u6b21\u6570\u5e76\u7f29\u5c0f\u4e86\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u5347\u4e86\u6c42\u89e3\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u5de5\u4e1a\u914d\u7f6e\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684ASP\u6c42\u89e3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7API\u652f\u6301\u76f4\u89c2\u7684\u7528\u6237\u754c\u9762\u3002"}}
{"id": "2507.20741", "pdf": "https://arxiv.org/pdf/2507.20741", "abs": "https://arxiv.org/abs/2507.20741", "authors": ["Fabian R\u00fccker", "Torben Storch"], "title": "Beyond QWERTY: A pressure-based text input approach for XR that enables a touch-typing like experience", "categories": ["cs.HC"], "comment": null, "summary": "Text input in extended reality (XR) applications remains inefficient and\ntedious. Most solutions are derived from the traditional keyboard layout, yet\nfail to translate its positive characteristics to the spatial digital realm.\nThis limits the productive use of immersive technologies. In this work, we\nanalyze physical keyboard input to identify key characteristics that facilitate\nits comfort, touch typing and high typing speeds. Building on these findings,\nwe propose a novel pressure-based text input modality that transfers these\ncharacteristics into immersive space by substituting the two-dimensional QWERTY\nlayout with a linear scale. This design facilitates a touch-typing-like\nexperience, eliminating the need for visual guidance for proficient users. Our\nskill-based approach enables typing speeds of over 200 characters per minute.\nAdditionally, it is suitable for discreet use in public spaces and everyday\ntext-input tasks, since the proposed system requires virtually no hand or\nfinger movements and resembles smartphone-based text input in appearance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u538b\u529b\u7684\u65b0\u578b\u6587\u672c\u8f93\u5165\u65b9\u5f0f\uff0c\u901a\u8fc7\u7ebf\u6027\u8bbe\u8ba1\u66ff\u4ee3\u4f20\u7edfQWERTY\u952e\u76d8\uff0c\u65e8\u5728\u89e3\u51b3XR\u5e94\u7528\u4e2d\u6587\u672c\u8f93\u5165\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3XR\u5e94\u7528\u4e2d\u6587\u672c\u8f93\u5165\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6c89\u6d78\u5f0f\u6280\u672f\u7684\u751f\u4ea7\u529b\u3002", "method": "\u5206\u6790\u7269\u7406\u952e\u76d8\u8f93\u5165\u7279\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u538b\u529b\u57fa\u7684\u6587\u672c\u8f93\u5165\u65b9\u5f0f\uff0c\u91c7\u7528\u7ebf\u6027\u8bbe\u8ba1\u66ff\u4ee3\u4f20\u7edf\u4e8c\u7ef4\u952e\u76d8\u5e03\u5c40\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8d85\u8fc7200\u5b57\u7b26/\u5206\u949f\u7684\u8f93\u5165\u901f\u5ea6\uff0c\u9002\u5408\u516c\u5171\u573a\u5408\u4f7f\u7528\uff0c\u4e14\u65e0\u9700\u89c6\u89c9\u5f15\u5bfc\u3002", "conclusion": "\u8be5\u538b\u529b\u57fa\u6587\u672c\u8f93\u5165\u65b9\u5f0f\u6709\u6548\u63d0\u5347\u4e86XR\u5e94\u7528\u7684\u8f93\u5165\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2507.20805", "pdf": "https://arxiv.org/pdf/2507.20805", "abs": "https://arxiv.org/abs/2507.20805", "authors": ["Seoyoung Doh", "Hyeon Jeon", "Sungbok Shin", "Ghulam Jilani Quadri", "Nam Wook Kim", "Jinwook Seo"], "title": "Understanding Bias in Perceiving Dimensionality Reduction Projections", "categories": ["cs.HC", "cs.LG"], "comment": "6 pages", "summary": "Selecting the dimensionality reduction technique that faithfully represents\nthe structure is essential for reliable visual communication and analytics. In\nreality, however, practitioners favor projections for other attractions, such\nas aesthetics and visual saliency, over the projection's structural\nfaithfulness, a bias we define as visual interestingness. In this research, we\nconduct a user study that (1) verifies the existence of such bias and (2)\nexplains why the bias exists. Our study suggests that visual interestingness\nbiases practitioners' preferences when selecting projections for analysis, and\nthis bias intensifies with color-encoded labels and shorter exposure time.\nBased on our findings, we discuss strategies to mitigate bias in perceiving and\ninterpreting DR projections.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u89c6\u89c9\u6295\u5f71\u9009\u62e9\u4e2d\u5b58\u5728\u7684\u2018\u89c6\u89c9\u8da3\u5473\u6027\u2019\u504f\u89c1\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u6210\u56e0\u53ca\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u786e\u8ba4\u5e76\u89e3\u91ca\u5b9e\u8df5\u4e2d\u9009\u62e9\u964d\u7ef4\u6295\u5f71\u65f6\u5bf9\u2018\u89c6\u89c9\u8da3\u5473\u6027\u2019\uff08\u5982\u7f8e\u89c2\u548c\u89c6\u89c9\u663e\u8457\u6027\uff09\u7684\u504f\u597d\u8d85\u8fc7\u7ed3\u6784\u5fe0\u5b9e\u6027\u7684\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u504f\u89c1\u7684\u5b58\u56e0\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\uff08\u5982\u989c\u8272\u7f16\u7801\u6807\u7b7e\u548c\u8f83\u77ed\u66dd\u5149\u65f6\u95f4\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u8da3\u5473\u6027\u663e\u8457\u5f71\u54cd\u6295\u5f71\u9009\u62e9\uff0c\u4e14\u504f\u89c1\u5728\u989c\u8272\u7f16\u7801\u548c\u77ed\u66dd\u5149\u4e0b\u52a0\u5267\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u7b56\u7565\u4ee5\u51cf\u5c11\u964d\u7ef4\u6295\u5f71\u611f\u77e5\u548c\u89e3\u91ca\u4e2d\u7684\u504f\u89c1\u3002"}}
{"id": "2507.20933", "pdf": "https://arxiv.org/pdf/2507.20933", "abs": "https://arxiv.org/abs/2507.20933", "authors": ["Narjes Pourjafarian", "Zhenming Yang", "Jeffrey I. Lipton", "Benyamin Davaji", "Gregory D. Abowd"], "title": "ProForm: Solder-Free Circuit Assembly Using Thermoforming", "categories": ["cs.HC", "cond-mat.mtrl-sci"], "comment": null, "summary": "Electronic waste (e-waste) is a growing global challenge, with millions of\nfunctional components discarded due to the difficulty of repair and reuse.\nTraditional circuit assembly relies on soldering, which creates semi-permanent\nbonds that limit component recovery and contribute to unnecessary waste. We\nintroduce ProForm, a thermoforming approach for solder-free circuit\nprototyping. By encapsulating electronic components with pressure-formed\nthermoplastics, ProForm enables secure, reversible mounting without the need\nfor solder or custom mechanical housings. This approach supports a wide range\nof substrates, including flexible, paper-based, and non-planar circuits,\nfacilitating easy reuse, replacement, and rapid prototyping. We demonstrate\nProForm's versatility to support prototyping practices. We show that ProFormed\ncircuits exhibit good electrical performance and mechanical stability. While\nmotivated by a need for sustainable electronics practices, ProForm has other\nsignificant advantages over traditional soldering.", "AI": {"tldr": "ProForm\u662f\u4e00\u79cd\u70ed\u6210\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u65e0\u710a\u7535\u8def\u539f\u578b\u8bbe\u8ba1\uff0c\u901a\u8fc7\u70ed\u5851\u6027\u6750\u6599\u5c01\u88c5\u7535\u5b50\u5143\u4ef6\uff0c\u5b9e\u73b0\u53ef\u9006\u5b89\u88c5\uff0c\u652f\u6301\u591a\u79cd\u57fa\u677f\uff0c\u4fbf\u4e8e\u91cd\u590d\u4f7f\u7528\u548c\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3002", "motivation": "\u7535\u5b50\u5783\u573e\u95ee\u9898\u65e5\u76ca\u4e25\u91cd\uff0c\u4f20\u7edf\u710a\u63a5\u65b9\u6cd5\u9650\u5236\u4e86\u5143\u4ef6\u56de\u6536\uff0c\u5bfc\u81f4\u4e0d\u5fc5\u8981\u7684\u6d6a\u8d39\u3002", "method": "\u91c7\u7528\u70ed\u6210\u578b\u6280\u672f\uff0c\u5229\u7528\u538b\u529b\u6210\u578b\u7684\u5851\u6599\u5c01\u88c5\u7535\u5b50\u5143\u4ef6\uff0c\u65e0\u9700\u710a\u63a5\u6216\u5b9a\u5236\u673a\u68b0\u5916\u58f3\u3002", "result": "ProForm\u7535\u8def\u8868\u73b0\u51fa\u826f\u597d\u7684\u7535\u6c14\u6027\u80fd\u548c\u673a\u68b0\u7a33\u5b9a\u6027\uff0c\u652f\u6301\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u5143\u4ef6\u91cd\u590d\u4f7f\u7528\u3002", "conclusion": "ProForm\u4e0d\u4ec5\u6709\u52a9\u4e8e\u53ef\u6301\u7eed\u7535\u5b50\u5b9e\u8df5\uff0c\u8fd8\u5177\u6709\u8d85\u8d8a\u4f20\u7edf\u710a\u63a5\u7684\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.20943", "pdf": "https://arxiv.org/pdf/2507.20943", "abs": "https://arxiv.org/abs/2507.20943", "authors": ["Rebecca L. Pharmer", "Christopher D. Wickens", "Lucas Plabst", "Benjamin A. Clegg", "Leanne M. Hirshfield", "Joanna E. Lewis", "Jalynn B. Nicoly", "Cara A. Spencer", "Francisco R. Ortega"], "title": "The Impact of Simple, Brief, and Adaptive Instructions within Virtual Reality Training: Components of Cognitive Load Theory in an Assembly Task", "categories": ["cs.HC"], "comment": null, "summary": "Objective: The study examined the effects of varying all three core elements\nof cognitive load on learning efficiency during a shape assembly task in\nvirtual reality (VR).\n  Background: Adaptive training systems aim to improve learning efficiency and\nretention by dynamically adjusting difficulty. However, design choices can\nimpact the cognitive workload imposed on the learner. The present experiments\nexamined how aspects of cognitive load impact training outcomes.\n  Method: Participants learned step-by-step shape assembly in a VR environment.\nCognitive load was manipulated across three dimensions: Intrinsic Load (shape\ncomplexity), Extraneous Load (instruction verbosity), and Germane Load\n(adaptive vs. fixed training). In adaptive training (experiment 1), difficulty\nincreased based on individual performance. In fixed training (experiment 2),\ndifficulty followed a preset schedule from a yoked participant.\n  Results: Higher Intrinsic Load significantly increased training times and\nsubjective workload but did not affect retention test accuracy. Extraneous Load\nmodestly impacted training time, with little impact on workload or retention.\nAdaptive training shortened overall training time without increasing workload\nor impairing retention. No interactions were observed between the three types\nof load. Conclusion: Both Intrinsic and Extraneous Load increased training\ntime, but adaptive training improved efficiency without harming retention. The\nlack of interaction between the elements suggests training benefits can be\nworth seeking within any of the components of cognitive load. Application:\nThese findings support the use of VR adaptive systems in domains such as\nmanufacturing and military service, where efficient assembly skill acquisition\nis critical. Tailoring difficulty in real-time can optimize efficiency without\ncompromising learning.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u865a\u62df\u73b0\u5b9e\u4e2d\u8ba4\u77e5\u8d1f\u8f7d\u4e09\u8981\u7d20\u5bf9\u5b66\u4e60\u6548\u7387\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u81ea\u9002\u5e94\u8bad\u7ec3\u80fd\u63d0\u9ad8\u6548\u7387\u4e14\u4e0d\u5f71\u54cd\u4fdd\u7559\u3002", "motivation": "\u901a\u8fc7\u8c03\u6574\u8ba4\u77e5\u8d1f\u8f7d\uff0c\u4f18\u5316\u865a\u62df\u73b0\u5b9e\u4e2d\u7684\u5b66\u4e60\u6548\u7387\uff0c\u5c24\u5176\u5728\u9700\u8981\u9ad8\u6548\u6280\u80fd\u83b7\u53d6\u7684\u9886\u57df\uff08\u5982\u5236\u9020\u4e1a\u548c\u519b\u4e8b\uff09\u3002", "method": "\u5728VR\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u8c03\u8282\u5185\u5728\u8d1f\u8f7d\uff08\u5f62\u72b6\u590d\u6742\u5ea6\uff09\u3001\u5916\u5728\u8d1f\u8f7d\uff08\u6307\u4ee4\u5197\u957f\u5ea6\uff09\u548c\u5173\u8054\u8d1f\u8f7d\uff08\u81ea\u9002\u5e94\u4e0e\u56fa\u5b9a\u8bad\u7ec3\uff09\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8f83\u9ad8\u5185\u5728\u8d1f\u8f7d\u589e\u52a0\u8bad\u7ec3\u65f6\u95f4\uff0c\u5916\u5728\u8d1f\u8f7d\u5f71\u54cd\u8f83\u5c0f\uff1b\u81ea\u9002\u5e94\u8bad\u7ec3\u663e\u8457\u7f29\u77ed\u65f6\u95f4\u4e14\u4e0d\u5f71\u54cd\u4fdd\u7559\u3002", "conclusion": "\u81ea\u9002\u5e94\u8bad\u7ec3\u5728\u4e0d\u635f\u5bb3\u4fdd\u7559\u7684\u524d\u63d0\u4e0b\u4f18\u5316\u6548\u7387\uff0c\u652f\u6301\u5728\u5173\u952e\u9886\u57df\u5e94\u7528VR\u81ea\u9002\u5e94\u7cfb\u7edf\u3002"}}
{"id": "2507.21000", "pdf": "https://arxiv.org/pdf/2507.21000", "abs": "https://arxiv.org/abs/2507.21000", "authors": ["Barbara Karpowicz", "Tomasz Kowalewski", "Pavlo Zinevych", "Adam Kuzdrali\u0144ski", "Grzegorz Marcin W\u00f3jcik", "Wies\u0142aw Kope\u0107"], "title": "Towards Effective Human Performance in XR Space Framework based on Real-time Eye Tracking Biofeedback", "categories": ["cs.HC"], "comment": null, "summary": "This paper proposes an eye tracking module for the XR Space Framework aimed\nat enhancing human performance in XR-based applications, specifically in\ntraining, screening, and teleoperation. This framework provides a methodology\nand components that streamline the development of adaptive real-time virtual\nimmersive systems. It contains multimodal measurements - declarative in the\nform of in-VR questionnaires and objective, including eye tracking, body\nmovement, and psychophysiological data (e.g., ECG, GSR, PPG). A key focus of\nthis paper is the integration of real-time eye tracking data into XR\nenvironments to facilitate a biofeedback loop, providing insight into user\nattention, cognitive load, and engagement. Given the relatively high\nmeasurement frequency of eye tracking - recognized as a noninvasive yet robust\npsychophysiological measure - this technology is particularly well suited for\nreal-time adjustments in task difficulty and feedback to enhance learning and\noperational effectiveness. Despite its established role in cognitive and\nattentional studies, implementing eye tracking metrics within dynamic,\nreal-time XR environments poses unique challenges, particularly given the\ncomplex moving visuals presented in head-mounted displays (HMDs). This paper\naddresses these challenges by focusing on the essential aspects of integrating\neye tracking in immersive systems based on real-time engines, ultimately\nfacilitating more efficient, adaptive XR applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdXR\u7a7a\u95f4\u6846\u67b6\u4e2d\u7684\u773c\u52a8\u8ffd\u8e2a\u6a21\u5757\uff0c\u65e8\u5728\u901a\u8fc7\u5b9e\u65f6\u751f\u7269\u53cd\u9988\u63d0\u5347XR\u5e94\u7528\u4e2d\u7684\u7528\u6237\u8868\u73b0\uff0c\u91cd\u70b9\u89e3\u51b3\u52a8\u6001XR\u73af\u5883\u4e2d\u773c\u52a8\u8ffd\u8e2a\u7684\u6280\u672f\u6311\u6218\u3002", "motivation": "\u773c\u52a8\u8ffd\u8e2a\u4f5c\u4e3a\u975e\u4fb5\u5165\u6027\u4e14\u5f3a\u5927\u7684\u5fc3\u7406\u751f\u7406\u6d4b\u91cf\u624b\u6bb5\uff0c\u5728XR\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u65f6\u8c03\u6574\u4efb\u52a1\u96be\u5ea6\u548c\u53cd\u9988\u7684\u6f5c\u529b\uff0c\u4f46\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6574\u5408\u9762\u4e34\u6311\u6218\u3002", "method": "\u901a\u8fc7\u591a\u6a21\u6001\u6d4b\u91cf\uff08\u5305\u62ec\u773c\u52a8\u8ffd\u8e2a\u3001\u8eab\u4f53\u8fd0\u52a8\u548c\u95ee\u5377\u8c03\u67e5\uff09\u548c\u5b9e\u65f6\u5f15\u64ce\uff0c\u96c6\u6210\u773c\u52a8\u6570\u636e\u4ee5\u5b9e\u73b0\u751f\u7269\u53cd\u9988\u5faa\u73af\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u773c\u52a8\u6570\u636e\u5728\u5b9e\u65f6XR\u73af\u5883\u4e2d\u7684\u96c6\u6210\uff0c\u652f\u6301\u52a8\u6001\u4efb\u52a1\u8c03\u6574\u548c\u53cd\u9988\uff0c\u63d0\u5347\u5b66\u4e60\u548c\u64cd\u4f5c\u6548\u7387\u3002", "conclusion": "\u8be5\u6a21\u5757\u4e3a\u5b9e\u65f6XR\u5e94\u7528\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u5de5\u5177\uff0c\u589e\u5f3a\u4e86\u7528\u6237\u4f53\u9a8c\u548c\u8868\u73b0\uff0c\u5e76\u89e3\u51b3\u4e86\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6280\u672f\u96be\u9898\u3002"}}
{"id": "2507.21012", "pdf": "https://arxiv.org/pdf/2507.21012", "abs": "https://arxiv.org/abs/2507.21012", "authors": ["Tianyi Li", "Tanay Maheshwari", "Alex Voelker"], "title": "User-Centered Design with AI in the Loop: A Case Study of Rapid User Interface Prototyping with \"Vibe Coding\"", "categories": ["cs.HC"], "comment": null, "summary": "We present a case study of using generative user interfaces, or ``vibe\ncoding,'' a method leveraging large language models (LLMs) for generating code\nvia natural language prompts, to support rapid prototyping in user-centered\ndesign (UCD). Extending traditional UCD practices, we propose an AI-in-the-loop\nideate-prototyping process. We share insights from an empirical experience\nintegrating this process to develop an interactive data analytics interface for\nhighway traffic engineers to effectively retrieve and analyze historical\ntraffic data. With generative UIs, the team was able to elicit rich user\nfeedback and test multiple alternative design ideas from user evaluation\ninterviews and real-time collaborative sessions with domain experts. We discuss\nthe advantages and pitfalls of vibe coding for bridging the gaps between design\nexpertise and domain-specific expertise.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6c1b\u56f4\u7f16\u7801\u201d\u7684\u751f\u6210\u5f0f\u7528\u6237\u754c\u9762\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u751f\u6210\u4ee3\u7801\uff0c\u4ee5\u652f\u6301\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\uff08UCD\uff09\u4e2d\u7684\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3002", "motivation": "\u4f20\u7edfUCD\u5b9e\u8df5\u5728\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7AI\u8f85\u52a9\u7684\u201c\u6784\u601d-\u539f\u578b\u201d\u6d41\u7a0b\uff0c\u5f25\u8865\u8bbe\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u4e0e\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86AI-in-the-loop\u7684\u6d41\u7a0b\uff0c\u7ed3\u5408\u751f\u6210\u5f0f\u7528\u6237\u754c\u9762\u548c\u5b9e\u65f6\u534f\u4f5c\u4f1a\u8bae\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u6570\u636e\u5206\u6790\u754c\u9762\uff0c\u7528\u4e8e\u9ad8\u901f\u516c\u8def\u4ea4\u901a\u5de5\u7a0b\u5e08\u68c0\u7d22\u548c\u5206\u6790\u5386\u53f2\u4ea4\u901a\u6570\u636e\u3002", "result": "\u901a\u8fc7\u751f\u6210\u5f0f\u7528\u6237\u754c\u9762\uff0c\u56e2\u961f\u80fd\u591f\u4ece\u7528\u6237\u8bc4\u4f30\u8bbf\u8c08\u548c\u9886\u57df\u4e13\u5bb6\u7684\u5b9e\u65f6\u534f\u4f5c\u4f1a\u8bae\u4e2d\u83b7\u53d6\u4e30\u5bcc\u7684\u53cd\u9988\uff0c\u5e76\u6d4b\u8bd5\u591a\u79cd\u66ff\u4ee3\u8bbe\u8ba1\u65b9\u6848\u3002", "conclusion": "\u7814\u7a76\u63a2\u8ba8\u4e86\u201c\u6c1b\u56f4\u7f16\u7801\u201d\u5728\u586b\u8865\u8bbe\u8ba1\u4e0e\u9886\u57df\u77e5\u8bc6\u5dee\u8ddd\u65b9\u9762\u7684\u4f18\u52bf\u548c\u6f5c\u5728\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7684AI\u8f85\u52a9\u8bbe\u8ba1\u5de5\u5177\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2507.19484", "pdf": "https://arxiv.org/pdf/2507.19484", "abs": "https://arxiv.org/abs/2507.19484", "authors": ["Shailesh Mishra", "Simone Colombo", "Pasindu Tennage", "Martin Burkhart", "Bryan Ford"], "title": "Towards the ideals of Self-Recovery and Metadata Privacy in Social Vault Recovery", "categories": ["cs.CR", "cs.HC"], "comment": null, "summary": "Social key recovery mechanisms enable users to recover their vaults with the\nhelp of trusted contacts, or trustees, avoiding the need for a single point of\ntrust or memorizing complex strings. However, existing mechanisms overlook the\nmemorability demands on users for recovery, such as the need to recall a\nthreshold number of trustees. Therefore, we first formalize the notion of\nrecovery metadata in the context of social key recovery, illustrating the\ntradeoff between easing the burden of memorizing the metadata and maintaining\nmetadata privacy. We present Apollo, the first framework that addresses this\ntradeoff by distributing indistinguishable data within a user's social circle,\nwhere trustees hold relevant data and non-trustees store random data. Apollo\neliminates the need to memorize recovery metadata since a user eventually\ngathers sufficient data from her social circle for recovery. Due to\nindistinguishability, Apollo protects metadata privacy by forming an anonymity\nset that hides the trustees among non-trustees. To make the anonymity set\nscalable, Apollo proposes a novel multi-layered secret sharing scheme that\nmitigates the overhead due to the random data distributed among non-trustees.\nFinally, we provide a prototype implementation of Apollo and report on its\nperformance. Apollo reduces the chances of malicious recovery to between 0.005%\nand 1.8%, depending on the adversary's ability to compromise. The multi-layered\ndesign shows a latency reduction from 1.1x to 740kx compared to a\nsingle-layered approach, depending on the number of reconnections.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Apollo\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u793e\u4ea4\u5bc6\u94a5\u6062\u590d\u4e2d\u7528\u6237\u8bb0\u5fc6\u8d1f\u62c5\u4e0e\u5143\u6570\u636e\u9690\u79c1\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u793e\u4ea4\u5bc6\u94a5\u6062\u590d\u673a\u5236\u5ffd\u89c6\u4e86\u5bf9\u7528\u6237\u8bb0\u5fc6\u7684\u8981\u6c42\uff0c\u9700\u8981\u5728\u6062\u590d\u65f6\u53ec\u56de\u4e00\u5b9a\u6570\u91cf\u7684\u53d7\u6258\u4eba\uff0c\u589e\u52a0\u4e86\u7528\u6237\u7684\u8bb0\u5fc6\u8d1f\u62c5\u3002", "method": "Apollo\u6846\u67b6\u901a\u8fc7\u5728\u7528\u6237\u793e\u4ea4\u5708\u4e2d\u5206\u53d1\u4e0d\u53ef\u533a\u5206\u7684\u6570\u636e\uff0c\u6d88\u9664\u4e86\u8bb0\u5fc6\u5143\u6570\u636e\u7684\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u591a\u5c42\u6b21\u7684\u79d8\u5bc6\u5171\u4eab\u65b9\u6848\u4fdd\u62a4\u5143\u6570\u636e\u9690\u79c1\u3002", "result": "Apollo\u5c06\u6076\u610f\u6062\u590d\u7684\u6982\u7387\u964d\u81f30.005%\u81f31.8%\uff0c\u591a\u5c42\u6b21\u8bbe\u8ba1\u5c06\u5ef6\u8fdf\u4ece\u5355\u5c42\u65b9\u6848\u76841.1\u500d\u964d\u4f4e\u81f3740\u5343\u500d\u3002", "conclusion": "Apollo\u6709\u6548\u89e3\u51b3\u4e86\u793e\u4ea4\u5bc6\u94a5\u6062\u590d\u4e2d\u8bb0\u5fc6\u8d1f\u62c5\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u6743\u8861\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.19487", "pdf": "https://arxiv.org/pdf/2507.19487", "abs": "https://arxiv.org/abs/2507.19487", "authors": ["Margarita Leib", "Nils K\u00f6bis", "Ivan Soraperra"], "title": "Does AI and Human Advice Mitigate Punishment for Selfish Behavior? An Experiment on AI ethics From a Psychological Perspective", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "econ.GN", "q-fin.EC"], "comment": null, "summary": "People increasingly rely on AI-advice when making decisions. At times, such\nadvice can promote selfish behavior. When individuals abide by\nselfishness-promoting AI advice, how are they perceived and punished? To study\nthis question, we build on theories from social psychology and combine\nmachine-behavior and behavioral economic approaches. In a pre-registered,\nfinancially-incentivized experiment, evaluators could punish real\ndecision-makers who (i) received AI, human, or no advice. The advice (ii)\nencouraged selfish or prosocial behavior, and decision-makers (iii) behaved\nselfishly or, in a control condition, behaved prosocially. Evaluators further\nassigned responsibility to decision-makers and their advisors. Results revealed\nthat (i) prosocial behavior was punished very little, whereas selfish behavior\nwas punished much more. Focusing on selfish behavior, (ii) compared to\nreceiving no advice, selfish behavior was penalized more harshly after\nprosocial advice and more leniently after selfish advice. Lastly, (iii) whereas\nselfish decision-makers were seen as more responsible when they followed AI\ncompared to human advice, punishment between the two advice sources did not\nvary. Overall, behavior and advice content shape punishment, whereas the advice\nsource does not.", "AI": {"tldr": "\u4eba\u4eec\u4f9d\u8d56AI\u5efa\u8bae\u505a\u51b3\u7b56\u65f6\uff0c\u82e5\u5efa\u8bae\u9f13\u52b1\u81ea\u79c1\u884c\u4e3a\uff0c\u51b3\u7b56\u8005\u4f1a\u5982\u4f55\u88ab\u8bc4\u4ef7\u548c\u60e9\u7f5a\uff1f\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u81ea\u79c1\u884c\u4e3a\u6bd4\u4eb2\u793e\u4f1a\u884c\u4e3a\u66f4\u6613\u53d7\u60e9\u7f5a\uff0c\u4e14\u60e9\u7f5a\u7a0b\u5ea6\u53d7\u5efa\u8bae\u5185\u5bb9\u5f71\u54cd\uff0c\u800c\u975e\u5efa\u8bae\u6765\u6e90\u3002", "motivation": "\u7814\u7a76AI\u5efa\u8bae\u5982\u4f55\u5f71\u54cd\u4eba\u4eec\u5bf9\u81ea\u79c1\u884c\u4e3a\u7684\u8bc4\u4ef7\u548c\u60e9\u7f5a\uff0c\u4ee5\u53ca\u8d23\u4efb\u5f52\u5c5e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9884\u6ce8\u518c\u3001\u7ecf\u6d4e\u6fc0\u52b1\u7684\u5b9e\u9a8c\uff0c\u8ba9\u8bc4\u4f30\u8005\u60e9\u7f5a\u771f\u5b9e\u51b3\u7b56\u8005\uff0c\u8003\u5bdf\u4e0d\u540c\u5efa\u8bae\u6765\u6e90\uff08AI\u3001\u4eba\u7c7b\u6216\u65e0\u5efa\u8bae\uff09\u548c\u884c\u4e3a\uff08\u81ea\u79c1\u6216\u4eb2\u793e\u4f1a\uff09\u7684\u5f71\u54cd\u3002", "result": "\u81ea\u79c1\u884c\u4e3a\u53d7\u66f4\u91cd\u60e9\u7f5a\uff0c\u4e14\u60e9\u7f5a\u7a0b\u5ea6\u53d6\u51b3\u4e8e\u5efa\u8bae\u5185\u5bb9\uff08\u81ea\u79c1\u6216\u4eb2\u793e\u4f1a\u5efa\u8bae\uff09\uff0c\u800c\u975e\u5efa\u8bae\u6765\u6e90\u3002\u51b3\u7b56\u8005\u9075\u5faaAI\u5efa\u8bae\u65f6\u88ab\u8ba4\u4e3a\u66f4\u8d1f\u8d23\u4efb\u3002", "conclusion": "\u884c\u4e3a\u548c\u5efa\u8bae\u5185\u5bb9\u5171\u540c\u5f71\u54cd\u60e9\u7f5a\uff0c\u800c\u5efa\u8bae\u6765\u6e90\u4e0d\u5f71\u54cd\u60e9\u7f5a\u7ed3\u679c\u3002"}}
{"id": "2507.19692", "pdf": "https://arxiv.org/pdf/2507.19692", "abs": "https://arxiv.org/abs/2507.19692", "authors": ["Ishan Pendyala"], "title": "FlashGuard: Novel Method in Evaluating Differential Characteristics of Visual Stimuli for Deterring Seizure Triggers in Photosensitive Epilepsy", "categories": ["cs.CY", "cs.HC", "cs.SI"], "comment": null, "summary": "In the virtual realm, individuals with photosensitive epilepsy (PSE)\nencounter challenges when using devices, resulting in exposure to unpredictable\nseizure-causing visual stimuli. The current norm for preventing epileptic\nflashes in media is to detect asynchronously when a flash will occur in a\nvideo, then notifying the user. However, there is a lack of a real-time and\ncomputationally efficient solution for dealing with this issue. To address this\nissue and enhance accessibility for photosensitive viewers, FlashGuard, a novel\napproach, was devised to assess the rate of change of colors in frames across\nthe user's screen and appropriately mitigate stimuli, based on perceptually\naligned color space analysis in the CIELAB color space. The detection system is\nbuilt on analyzing differences in color, and the mitigation system works by\nreducing luminance and smoothing color transitions. This study provides novel\ninsight into how intrinsic color properties contribute to perceptual\ndifferences in flashing for PSE individuals, calling for the adoption of\nbroadened WCAG guidelines to better account for risk. These insights and\nimplementations pave the way for stronger protections for individuals with PSE\nfrom dangerous triggers in digital media, both in policy and in software.", "AI": {"tldr": "\u63d0\u51faFlashGuard\u65b9\u6cd5\uff0c\u5b9e\u65f6\u68c0\u6d4b\u5e76\u51cf\u5c11\u5c4f\u5e55\u95ea\u70c1\u5bf9\u5149\u654f\u6027\u766b\u75eb\u7528\u6237\u7684\u523a\u6fc0\u3002", "motivation": "\u5149\u654f\u6027\u766b\u75eb\u60a3\u8005\u5728\u4f7f\u7528\u6570\u5b57\u8bbe\u5907\u65f6\u9762\u4e34\u4e0d\u53ef\u9884\u6d4b\u7684\u89c6\u89c9\u523a\u6fc0\u98ce\u9669\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u5b9e\u65f6\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u57fa\u4e8eCIELAB\u8272\u5f69\u7a7a\u95f4\u5206\u6790\uff0c\u68c0\u6d4b\u5e27\u95f4\u989c\u8272\u53d8\u5316\u7387\u5e76\u51cf\u5c11\u4eae\u5ea6\u548c\u5e73\u6ed1\u989c\u8272\u8fc7\u6e21\u3002", "result": "\u4e3a\u5149\u654f\u6027\u766b\u75eb\u60a3\u8005\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u4fdd\u62a4\uff0c\u540c\u65f6\u547c\u5401\u6269\u5c55WCAG\u6307\u5357\u4ee5\u66f4\u597d\u5e94\u5bf9\u98ce\u9669\u3002", "conclusion": "FlashGuard\u901a\u8fc7\u8272\u5f69\u7a7a\u95f4\u5206\u6790\u63d0\u5347\u4e86\u5bf9\u5149\u654f\u6027\u766b\u75eb\u60a3\u8005\u7684\u4fdd\u62a4\uff0c\u63a8\u52a8\u4e86\u653f\u7b56\u4e0e\u8f6f\u4ef6\u7684\u6539\u8fdb\u3002"}}
{"id": "2507.19854", "pdf": "https://arxiv.org/pdf/2507.19854", "abs": "https://arxiv.org/abs/2507.19854", "authors": ["Anjali R. Menon", "Rohit K. Sharma", "Priya Singh", "Chengyu Wang", "Aurora M. Ferreira", "Mateja Novak"], "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "categories": ["cs.RO", "cs.HC", "68T05, 68T07, 68T40", "I.2.6; I.2.9; I.2.7; I.2.10; H.5.2"], "comment": "13 pages, 7 figures", "summary": "The integration of Large Language Models (LLMs) into robotics has unlocked\nunprecedented capabilities in high-level task planning. However, most current\nsystems operate in an open-loop fashion, where LLMs act as one-shot planners,\nrendering them brittle and unable to adapt to unforeseen circumstances in\ndynamic physical environments. To overcome this limitation, this paper\nintroduces the \"Think, Act, Learn\" (T-A-L) framework, a novel architecture that\nenables an embodied agent to autonomously learn and refine its policies through\ncontinuous interaction. Our framework establishes a closed-loop cycle where an\nLLM first \"thinks\" by decomposing high-level commands into actionable plans.\nThe robot then \"acts\" by executing these plans while gathering rich, multimodal\nsensory feedback. Critically, the \"learn\" module processes this feedback to\nfacilitate LLM-driven self-reflection, allowing the agent to perform causal\nanalysis on its failures and generate corrective strategies. These insights are\nstored in an experiential memory to guide future planning cycles. We\ndemonstrate through extensive experiments in both simulation and the real world\nthat our T-A-L agent significantly outperforms baseline methods, including\nopen-loop LLMs, Behavioral Cloning, and traditional Reinforcement Learning. Our\nframework achieves over a 97% success rate on complex, long-horizon tasks,\nconverges to a stable policy in an average of just 9 trials, and exhibits\nremarkable generalization to unseen tasks. This work presents a significant\nstep towards developing more robust, adaptive, and truly autonomous robotic\nagents.", "AI": {"tldr": "\u63d0\u51fa\u201cThink, Act, Learn\u201d\u6846\u67b6\uff0c\u901a\u8fc7\u95ed\u73af\u5b66\u4e60\u63d0\u5347\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5f53\u524dLLM\u5728\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u4e2d\u5f00\u73af\u7cfb\u7edf\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u9002\u5e94\u6027\u3002", "method": "\u8bbe\u8ba1T-A-L\u6846\u67b6\uff0c\u5206\u201c\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u201d\u4e09\u6b65\u9aa4\uff0c\u7ed3\u5408\u53cd\u9988\u548c\u8bb0\u5fc6\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u4e2d\uff0cT-A-L\u6846\u67b6\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u8d8597%\uff0c\u5e73\u57479\u6b21\u8bd5\u9a8c\u5373\u6536\u655b\uff0c\u6cdb\u5316\u80fd\u529b\u5f3a\u3002", "conclusion": "T-A-L\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u81ea\u4e3b\u6027\u548c\u9002\u5e94\u6027\uff0c\u662f\u5b9e\u73b0\u771f\u6b63\u81ea\u4e3b\u673a\u5668\u4eba\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2507.19855", "pdf": "https://arxiv.org/pdf/2507.19855", "abs": "https://arxiv.org/abs/2507.19855", "authors": ["Aditya Sharma", "Linh Nguyen", "Ananya Gupta", "Chengyu Wang", "Chiamaka Adebayo", "Jakub Kowalski"], "title": "Inducing Causal World Models in LLMs for Zero-Shot Physical Reasoning", "categories": ["cs.LG", "cs.HC", "68T05, 68T07, 68T40", "I.2.6; I.2.9; I.2.7; I.2.10; H.5.2"], "comment": "12 pages, 4 figures,", "summary": "Large Language Models (LLMs), despite their advanced linguistic capabilities,\nfundamentally lack an intuitive understanding of physical dynamics, which\nlimits their effectiveness in real-world scenarios that require causal\nreasoning. In this paper, we introduce Causal World Model Induction (CWMI), a\nnovel framework designed to embed an explicit model of causal physics within an\nLLM. Our approach incorporates a dedicated Causal Physics Module (CPM) and a\nnew training objective called Causal Intervention Loss, encouraging the model\nto learn cause-and-effect relationships from multimodal data. By training the\nmodel to predict the outcomes of hypothetical interventions instead of merely\ncapturing statistical correlations, CWMI develops a robust internal\nrepresentation of physical laws. Experimental results show that CWMI\nsignificantly outperforms state-of-the-art LLMs on zero-shot physical reasoning\ntasks, including the PIQA benchmark and our newly proposed PhysiCa-Bench\ndataset. These findings demonstrate that inducing a causal world model is a\ncritical step toward more reliable and generalizable AI systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCausal World Model Induction\uff08CWMI\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5165\u56e0\u679c\u7269\u7406\u6a21\u578b\u63d0\u5347LLMs\u5728\u7269\u7406\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "LLMs\u7f3a\u4e4f\u5bf9\u7269\u7406\u52a8\u6001\u7684\u76f4\u89c2\u7406\u89e3\uff0c\u9650\u5236\u4e86\u5176\u5728\u9700\u8981\u56e0\u679c\u63a8\u7406\u7684\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165Causal Physics Module\uff08CPM\uff09\u548cCausal Intervention Loss\u8bad\u7ec3\u76ee\u6807\uff0c\u4ece\u591a\u6a21\u6001\u6570\u636e\u4e2d\u5b66\u4e60\u56e0\u679c\u5173\u7cfb\u3002", "result": "CWMI\u5728\u96f6\u6837\u672c\u7269\u7406\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709LLMs\uff0c\u5982PIQA\u548cPhysiCa-Bench\u6570\u636e\u96c6\u3002", "conclusion": "\u8bf1\u5bfc\u56e0\u679c\u4e16\u754c\u6a21\u578b\u662f\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u901a\u7528AI\u7cfb\u7edf\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2507.19870", "pdf": "https://arxiv.org/pdf/2507.19870", "abs": "https://arxiv.org/abs/2507.19870", "authors": ["Junwen Duan", "Wei Xue", "Ziyao Kang", "Shixia Liu", "Jiazhi Xia"], "title": "OW-CLIP: Data-Efficient Visual Supervision for Open-World Object Detection via Human-AI Collaboration", "categories": ["cs.CV", "cs.HC"], "comment": "9 pages, 11 figures", "summary": "Open-world object detection (OWOD) extends traditional object detection to\nidentifying both known and unknown object, necessitating continuous model\nadaptation as new annotations emerge. Current approaches face significant\nlimitations: 1) data-hungry training due to reliance on a large number of\ncrowdsourced annotations, 2) susceptibility to \"partial feature overfitting,\"\nand 3) limited flexibility due to required model architecture modifications. To\ntackle these issues, we present OW-CLIP, a visual analytics system that\nprovides curated data and enables data-efficient OWOD model incremental\ntraining. OW-CLIP implements plug-and-play multimodal prompt tuning tailored\nfor OWOD settings and introduces a novel \"Crop-Smoothing\" technique to mitigate\npartial feature overfitting. To meet the data requirements for the training\nmethodology, we propose dual-modal data refinement methods that leverage large\nlanguage models and cross-modal similarity for data generation and filtering.\nSimultaneously, we develope a visualization interface that enables users to\nexplore and deliver high-quality annotations: including class-specific visual\nfeature phrases and fine-grained differentiated images. Quantitative evaluation\ndemonstrates that OW-CLIP achieves competitive performance at 89% of\nstate-of-the-art performance while requiring only 3.8% self-generated data,\nwhile outperforming SOTA approach when trained with equivalent data volumes. A\ncase study shows the effectiveness of the developed method and the improved\nannotation quality of our visualization system.", "AI": {"tldr": "OW-CLIP\u662f\u4e00\u6b3e\u89c6\u89c9\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u6570\u636e\u9ad8\u6548\u7684\u591a\u6a21\u6001\u63d0\u793a\u8c03\u4f18\u548cCrop-Smoothing\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u5f00\u653e\u4e16\u754c\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u6570\u636e\u4f9d\u8d56\u548c\u6a21\u578b\u7075\u6d3b\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u5f00\u653e\u4e16\u754c\u76ee\u6807\u68c0\u6d4b\u9700\u8981\u6301\u7eed\u9002\u5e94\u65b0\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u6570\u636e\u9700\u6c42\u9ad8\u3001\u7279\u5f81\u8fc7\u62df\u5408\u548c\u67b6\u6784\u4fee\u6539\u9650\u5236\u7b49\u95ee\u9898\u3002", "method": "OW-CLIP\u91c7\u7528\u591a\u6a21\u6001\u63d0\u793a\u8c03\u4f18\u548cCrop-Smoothing\u6280\u672f\uff0c\u7ed3\u5408\u53cc\u6a21\u6001\u6570\u636e\u7cbe\u70bc\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\u751f\u6210\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cOW-CLIP\u6027\u80fd\u8fbe\u5230SOTA\u768489%\uff0c\u4ec5\u97003.8%\u7684\u81ea\u751f\u6210\u6570\u636e\uff0c\u4e14\u5728\u540c\u7b49\u6570\u636e\u91cf\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "OW-CLIP\u901a\u8fc7\u591a\u6a21\u6001\u6280\u672f\u548c\u53ef\u89c6\u5316\u754c\u9762\u6709\u6548\u63d0\u5347\u4e86\u5f00\u653e\u4e16\u754c\u76ee\u6807\u68c0\u6d4b\u7684\u6548\u7387\u4e0e\u6807\u6ce8\u8d28\u91cf\u3002"}}
{"id": "2507.20419", "pdf": "https://arxiv.org/pdf/2507.20419", "abs": "https://arxiv.org/abs/2507.20419", "authors": ["Khloud AL Jallad", "Nada Ghneim", "Ghaida Rebdawi"], "title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Natural Language Understanding (NLU) is a basic task in Natural Language\nProcessing (NLP). The evaluation of NLU capabilities has become a trending\nresearch topic that attracts researchers in the last few years, resulting in\nthe development of numerous benchmarks. These benchmarks include various tasks\nand datasets in order to evaluate the results of pretrained models via public\nleaderboards. Notably, several benchmarks contain diagnostics datasets designed\nfor investigation and fine-grained error analysis across a wide range of\nlinguistic phenomena. This survey provides a comprehensive review of available\nEnglish, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on\ntheir diagnostics datasets and the linguistic phenomena they covered. We\npresent a detailed comparison and analysis of these benchmarks, highlighting\ntheir strengths and limitations in evaluating NLU tasks and providing in-depth\nerror analysis. When highlighting the gaps in the state-of-the-art, we noted\nthat there is no naming convention for macro and micro categories or even a\nstandard set of linguistic phenomena that should be covered. Consequently, we\nformulated a research question regarding the evaluation metrics of the\nevaluation diagnostics benchmarks: \"Why do not we have an evaluation standard\nfor the NLU evaluation diagnostics benchmarks?\" similar to ISO standard in\nindustry. We conducted a deep analysis and comparisons of the covered\nlinguistic phenomena in order to support experts in building a global hierarchy\nfor linguistic phenomena in future. We think that having evaluation metrics for\ndiagnostics evaluation could be valuable to gain more insights when comparing\nthe results of the studied models on different diagnostics benchmarks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u82f1\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u548c\u591a\u8bed\u8a00\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff08NLU\uff09\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u8bca\u65ad\u6570\u636e\u96c6\u548c\u8986\u76d6\u7684\u8bed\u8a00\u73b0\u8c61\u3002\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\uff0c\u6307\u51fa\u5f53\u524d\u7814\u7a76\u4e2d\u7f3a\u4e4f\u7edf\u4e00\u7684\u547d\u540d\u89c4\u8303\u548c\u6807\u51c6\u8bed\u8a00\u73b0\u8c61\u96c6\u5408\uff0c\u5e76\u63d0\u51fa\u7814\u7a76\u95ee\u9898\uff1a\u4e3a\u4f55\u6ca1\u6709\u7c7b\u4f3cISO\u6807\u51c6\u7684NLU\u8bc4\u4f30\u8bca\u65ad\u57fa\u51c6\uff1f", "motivation": "\u8fd1\u5e74\u6765\uff0c\u8bc4\u4f30NLU\u80fd\u529b\u6210\u4e3a\u70ed\u95e8\u7814\u7a76\u8bfe\u9898\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6807\u51c6\u548c\u8bed\u8a00\u73b0\u8c61\u5206\u7c7b\uff0c\u9650\u5236\u4e86\u6df1\u5165\u6bd4\u8f83\u548c\u5206\u6790\u6a21\u578b\u8868\u73b0\u3002", "method": "\u8bba\u6587\u8be6\u7ec6\u6bd4\u8f83\u5206\u6790\u4e86\u73b0\u6709NLU\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bca\u65ad\u6570\u636e\u96c6\u53ca\u5176\u8986\u76d6\u7684\u8bed\u8a00\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u7814\u7a76\u95ee\u9898\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u5728\u547d\u540d\u89c4\u8303\u548c\u6807\u51c6\u8bed\u8a00\u73b0\u8c61\u96c6\u5408\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u5efa\u7acb\u5168\u7403\u7edf\u4e00\u7684\u8bed\u8a00\u73b0\u8c61\u5c42\u6b21\u7ed3\u6784\u3002", "conclusion": "\u5efa\u8bae\u672a\u6765\u5efa\u7acb\u7c7b\u4f3cISO\u6807\u51c6\u7684NLU\u8bc4\u4f30\u8bca\u65ad\u57fa\u51c6\uff0c\u4ee5\u66f4\u6df1\u5165\u6bd4\u8f83\u6a21\u578b\u8868\u73b0\u5e76\u652f\u6301\u8bed\u8a00\u73b0\u8c61\u7684\u6807\u51c6\u5316\u5206\u7c7b\u3002"}}
{"id": "2507.20536", "pdf": "https://arxiv.org/pdf/2507.20536", "abs": "https://arxiv.org/abs/2507.20536", "authors": ["Chieh-Yun Chen", "Min Shi", "Gong Zhang", "Humphrey Shi"], "title": "T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "ICCV 2025", "summary": "Text-to-Image (T2I) generative models have revolutionized content creation\nbut remain highly sensitive to prompt phrasing, often requiring users to\nrepeatedly refine prompts multiple times without clear feedback. While\ntechniques such as automatic prompt engineering, controlled text embeddings,\ndenoising, and multi-turn generation mitigate these issues, they offer limited\ncontrollability, or often necessitate additional training, restricting the\ngeneralization abilities. Thus, we introduce T2I-Copilot, a training-free\nmulti-agent system that leverages collaboration between (Multimodal) Large\nLanguage Models to automate prompt phrasing, model selection, and iterative\nrefinement. This approach significantly simplifies prompt engineering while\nenhancing generation quality and text-image alignment compared to direct\ngeneration. Specifically, T2I-Copilot consists of three agents: (1) Input\nInterpreter, which parses the input prompt, resolves ambiguities, and generates\na standardized report; (2) Generation Engine, which selects the appropriate\nmodel from different types of T2I models and organizes visual and textual\nprompts to initiate generation; and (3) Quality Evaluator, which assesses\naesthetic quality and text-image alignment, providing scores and feedback for\npotential regeneration. T2I-Copilot can operate fully autonomously while also\nsupporting human-in-the-loop intervention for fine-grained control. On\nGenAI-Bench, using open-source generation models, T2I-Copilot achieves a VQA\nscore comparable to commercial models RecraftV3 and Imagen 3, surpasses\nFLUX1.1-pro by 6.17% at only 16.59% of its cost, and outperforms FLUX.1-dev and\nSD 3.5 Large by 9.11% and 6.36%. Code will be released at:\nhttps://github.com/SHI-Labs/T2I-Copilot.", "AI": {"tldr": "T2I-Copilot\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u8bad\u7ec3\u514d\u8d39\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u63d0\u793a\u8bcd\u4f18\u5316\u3001\u6a21\u578b\u9009\u62e9\u548c\u8fed\u4ee3\u6539\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684\u8d28\u91cf\u548c\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5bf9\u63d0\u793a\u8bcd\u975e\u5e38\u654f\u611f\uff0c\u7528\u6237\u9700\u53cd\u590d\u8c03\u6574\u63d0\u793a\u8bcd\u4e14\u7f3a\u4e4f\u660e\u786e\u53cd\u9988\uff0c\u73b0\u6709\u65b9\u6cd5\u63a7\u5236\u6027\u6709\u9650\u6216\u9700\u8981\u989d\u5916\u8bad\u7ec3\uff0c\u6cdb\u5316\u80fd\u529b\u53d7\u9650\u3002", "method": "T2I-Copilot\u7531\u4e09\u4e2a\u667a\u80fd\u4f53\u7ec4\u6210\uff1a\u8f93\u5165\u89e3\u91ca\u5668\uff08\u89e3\u6790\u63d0\u793a\u8bcd\uff09\u3001\u751f\u6210\u5f15\u64ce\uff08\u9009\u62e9\u6a21\u578b\u5e76\u542f\u52a8\u751f\u6210\uff09\u3001\u8d28\u91cf\u8bc4\u4f30\u5668\uff08\u8bc4\u4f30\u5e76\u53cd\u9988\uff09\uff0c\u652f\u6301\u5168\u81ea\u52a8\u6216\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u5728GenAI-Bench\u4e0a\uff0cT2I-Copilot\u4f7f\u7528\u5f00\u6e90\u6a21\u578b\u7684VQA\u5f97\u5206\u63a5\u8fd1\u5546\u4e1a\u6a21\u578b\uff0c\u6210\u672c\u4ec5\u4e3aFLUX1.1-pro\u768416.59%\uff0c\u4f46\u6027\u80fd\u8d85\u8d8a\u51766.17%\u3002", "conclusion": "T2I-Copilot\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\uff0c\u4e3a\u81ea\u52a8\u5316\u5185\u5bb9\u521b\u4f5c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.20632", "pdf": "https://arxiv.org/pdf/2507.20632", "abs": "https://arxiv.org/abs/2507.20632", "authors": ["Hongxu Liu", "Xinyu Chen", "Haoyang Zheng", "Manyi Li", "Zhenfan Liu", "Fumeng Yang", "Yunhai Wang", "Changhe Tu", "Qiong Zeng"], "title": "Self-Supervised Continuous Colormap Recovery from a 2D Scalar Field Visualization without a Legend", "categories": ["cs.CV", "cs.HC"], "comment": "Submitted to IEEE VIS 2025", "summary": "Recovering a continuous colormap from a single 2D scalar field visualization\ncan be quite challenging, especially in the absence of a corresponding color\nlegend. In this paper, we propose a novel colormap recovery approach that\nextracts the colormap from a color-encoded 2D scalar field visualization by\nsimultaneously predicting the colormap and underlying data using a\ndecoupling-and-reconstruction strategy. Our approach first separates the input\nvisualization into colormap and data using a decoupling module, then\nreconstructs the visualization with a differentiable color-mapping module. To\nguide this process, we design a reconstruction loss between the input and\nreconstructed visualizations, which serves both as a constraint to ensure\nstrong correlation between colormap and data during training, and as a\nself-supervised optimizer for fine-tuning the predicted colormap of unseen\nvisualizations during inferencing. To ensure smoothness and correct color\nordering in the extracted colormap, we introduce a compact colormap\nrepresentation using cubic B-spline curves and an associated color order loss.\nWe evaluate our method quantitatively and qualitatively on a synthetic dataset\nand a collection of real-world visualizations from the VIS30K dataset.\nAdditionally, we demonstrate its utility in two prototype applications --\ncolormap adjustment and colormap transfer -- and explore its generalization to\nvisualizations with color legends and ones encoded using discrete color\npalettes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece2D\u6807\u91cf\u573a\u53ef\u89c6\u5316\u4e2d\u6062\u590d\u8fde\u7eed\u8272\u5f69\u6620\u5c04\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u548c\u91cd\u5efa\u7b56\u7565\u540c\u65f6\u9884\u6d4b\u8272\u5f69\u6620\u5c04\u548c\u5e95\u5c42\u6570\u636e\u3002", "motivation": "\u5728\u6ca1\u6709\u8272\u5f69\u56fe\u4f8b\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece2D\u6807\u91cf\u573a\u53ef\u89c6\u5316\u4e2d\u6062\u590d\u8fde\u7eed\u8272\u5f69\u6620\u5c04\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u5b8c\u6210\u8fd9\u4e00\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u89e3\u8026\u6a21\u5757\u5206\u79bb\u8272\u5f69\u6620\u5c04\u548c\u6570\u636e\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u8272\u5f69\u6620\u5c04\u6a21\u5757\u91cd\u5efa\u53ef\u89c6\u5316\uff0c\u8bbe\u8ba1\u4e86\u91cd\u5efa\u635f\u5931\u4ee5\u786e\u4fdd\u8272\u5f69\u6620\u5c04\u4e0e\u6570\u636e\u7684\u5f3a\u76f8\u5173\u6027\uff0c\u5e76\u4f7f\u7528\u4e09\u6b21B\u6837\u6761\u66f2\u7ebf\u8868\u793a\u5149\u6ed1\u8272\u5f69\u6620\u5c04\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548cVIS30K\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u8272\u5f69\u6620\u5c04\u8c03\u6574\u548c\u8f6c\u79fb\u7b49\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6062\u590d\u8fde\u7eed\u8272\u5f69\u6620\u5c04\uff0c\u5e76\u9002\u7528\u4e8e\u591a\u79cd\u53ef\u89c6\u5316\u573a\u666f\u3002"}}
{"id": "2507.20737", "pdf": "https://arxiv.org/pdf/2507.20737", "abs": "https://arxiv.org/abs/2507.20737", "authors": ["Geng-Xin Xu", "Xiang Zuo", "Ye Li"], "title": "Multi-Masked Querying Network for Robust Emotion Recognition from Incomplete Multi-Modal Physiological Signals", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "MICCAI2025", "summary": "Emotion recognition from physiological data is crucial for mental health\nassessment, yet it faces two significant challenges: incomplete multi-modal\nsignals and interference from body movements and artifacts. This paper presents\na novel Multi-Masked Querying Network (MMQ-Net) to address these issues by\nintegrating multiple querying mechanisms into a unified framework.\nSpecifically, it uses modality queries to reconstruct missing data from\nincomplete signals, category queries to focus on emotional state features, and\ninterference queries to separate relevant information from noise. Extensive\nexperiment results demonstrate the superior emotion recognition performance of\nMMQ-Net compared to existing approaches, particularly under high levels of data\nincompleteness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u63a9\u7801\u67e5\u8be2\u7f51\u7edc\uff08MMQ-Net\uff09\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u67e5\u8be2\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u751f\u7406\u6570\u636e\u60c5\u7eea\u8bc6\u522b\u4e2d\u4fe1\u53f7\u4e0d\u5b8c\u6574\u548c\u8fd0\u52a8\u5e72\u6270\u7684\u95ee\u9898\u3002", "motivation": "\u60c5\u7eea\u8bc6\u522b\u5728\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u591a\u6a21\u6001\u4fe1\u53f7\u4e0d\u5b8c\u6574\u548c\u8fd0\u52a8\u5e72\u6270\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528MMQ-Net\uff0c\u7ed3\u5408\u6a21\u6001\u67e5\u8be2\uff08\u91cd\u5efa\u7f3a\u5931\u6570\u636e\uff09\u3001\u7c7b\u522b\u67e5\u8be2\uff08\u5173\u6ce8\u60c5\u7eea\u7279\u5f81\uff09\u548c\u5e72\u6270\u67e5\u8be2\uff08\u5206\u79bb\u566a\u58f0\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMMQ-Net\u5728\u6570\u636e\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MMQ-Net\u6709\u6548\u63d0\u5347\u4e86\u60c5\u7eea\u8bc6\u522b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u6570\u636e\u4e0d\u5b8c\u6574\u65f6\u8868\u73b0\u7a81\u51fa\u3002"}}
