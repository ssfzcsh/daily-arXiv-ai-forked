{"id": "2507.18726", "pdf": "https://arxiv.org/pdf/2507.18726", "abs": "https://arxiv.org/abs/2507.18726", "authors": ["Sadia Afrin Mim"], "title": "Exploring the Landscape of Fairness Interventions in Software Engineering", "categories": ["cs.SE"], "comment": null, "summary": "Current developments in AI made it broadly significant for reducing human\nlabor and expenses across several essential domains, including healthcare and\nfinance. However, the application of AI in the actual world poses multiple\nrisks and disadvantages due to potential risk factors in data (e.g., biased\ndataset). Practitioners developed a number of fairness interventions for\naddressing these kinds of problems. The paper acts as a survey, summarizing the\nvarious studies and approaches that have been developed to address fairness\nissues", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86AI\u5e94\u7528\u4e2d\u56e0\u6570\u636e\u504f\u89c1\u5bfc\u81f4\u7684\u516c\u5e73\u6027\u95ee\u9898\u53ca\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "AI\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u56e0\u6570\u636e\u504f\u89c1\u7b49\u95ee\u9898\u5e26\u6765\u98ce\u9669\uff0c\u9700\u89e3\u51b3\u516c\u5e73\u6027\u6311\u6218\u3002", "method": "\u4f5c\u4e3a\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u9488\u5bf9\u516c\u5e73\u6027\u95ee\u9898\u7684\u591a\u79cd\u7814\u7a76\u548c\u5e72\u9884\u65b9\u6cd5\u3002", "result": "\u7efc\u8ff0\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u591a\u6837\u6027\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u603b\u7ed3\u73b0\u6709\u5de5\u4f5c\uff0c\u5f3a\u8c03\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5b8c\u5584AI\u516c\u5e73\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18755", "pdf": "https://arxiv.org/pdf/2507.18755", "abs": "https://arxiv.org/abs/2507.18755", "authors": ["Chandra Maddila", "Adam Tait", "Claire Chang", "Daniel Cheng", "Nauman Ahmad", "Vijayaraghavan Murali", "Marshall Roch", "Arnaud Avondet", "Aaron Meltzer", "Victor Montalvao", "Michael Hopko", "Chris Waterson", "Parth Thakkar", "Renuka Fernandez", "Kristian Kristensen", "Sivan Barzily", "Sherry Chen", "Rui Abreu", "Nachiappan Nagappan", "Payam Shodjai", "Killian Murphy", "James Everingham", "Aparna Ramani", "Peter C. Rigby"], "title": "Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Aim: With the advent of LLMs, sophisticated agentic program repair has become\nviable at large organizations with large codebases. In this work, we develop an\nEngineering Agent that fixes the source code based on test failures at scale\nacross diverse software offerings internally.\n  Method: Using Llama as the base, we employ the ReAct harness to develop an\nagent. We start with a test failure that was triaged by a rule-based test\nfailure bot. We then set up an agentic harness and allow the agent to reason\nand run a set of 15 actions from reading a file to generating a patch. We\nprovide feedback to the agent through static analysis and test failures so it\ncan refine its solution. We leverage an LLM-as-a-Judge to ensure that the patch\nconforms to the standards followed by a human review to land fixes.\n  Benchmark Findings: We curated offline benchmarks for our patch generator,\nthe Engineering Agent loop, and the LLM-as-a-Judge. In offline evaluations we\nfound that a specialized 70B model is highly competitive with the much larger\nbut vanilla Llama-405B. In an ablation study, we found that the ReAct harness\n(neural model) benefited from the symbolic information from static analysis\ntools and test execution traces. A model that strikes a balance between the\nsolve rate and error rate vs the cost and latency has a benchmark solve rate of\n42.3% using an average 11.8 feedback iterations.\n  Production Findings: In a three month period, 80% of the generated fixes were\nreviewed, of which 31.5% were landed (25.5% of the total number of generated\nfixes).\n  Feedback from Engineers: We used open coding to extract qualitative themes\nfrom engineers' feedback. We saw positive feedback in the form of quick\napprovals, gratitude, and surprise. We also found mixed feedback when the\nEngineering Agent's solution was partially correct and it served as a good\nstarting point.", "AI": {"tldr": "\u5f00\u53d1\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5de5\u7a0b\u4ee3\u7406\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u4fee\u590d\u4ee3\u7801\uff0c\u7ed3\u5408ReAct\u6846\u67b6\u548cLLM\u8bc4\u5ba1\uff0c\u79bb\u7ebf\u6d4b\u8bd5\u663e\u793a70B\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u751f\u4ea7\u73af\u5883\u4e2d31.5%\u7684\u4fee\u590d\u88ab\u91c7\u7eb3\u3002", "motivation": "\u5229\u7528LLM\u5b9e\u73b0\u5927\u89c4\u6a21\u4ee3\u7801\u4fee\u590d\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\uff0c\u51cf\u5c11\u4eba\u5de5\u4ecb\u5165\u3002", "method": "\u4f7f\u7528Llama\u4f5c\u4e3a\u57fa\u7840\uff0c\u7ed3\u5408ReAct\u6846\u67b6\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u548c\u6d4b\u8bd5\u53cd\u9988\u4f18\u5316\u4ee3\u7406\u884c\u4e3a\uff0c\u7528LLM\u8bc4\u5ba1\u786e\u4fdd\u4fee\u590d\u8d28\u91cf\u3002", "result": "\u79bb\u7ebf\u6d4b\u8bd5\u4e2d\u89e3\u51b3\u7387\u8fbe42.3%\uff0c\u751f\u4ea7\u73af\u5883\u4e2d25.5%\u7684\u4fee\u590d\u88ab\u91c7\u7eb3\uff0c\u5de5\u7a0b\u5e08\u53cd\u9988\u603b\u4f53\u79ef\u6781\u3002", "conclusion": "\u5de5\u7a0b\u4ee3\u7406\u5728\u5927\u89c4\u6a21\u4ee3\u7801\u4fee\u590d\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\u3002"}}
{"id": "2507.18812", "pdf": "https://arxiv.org/pdf/2507.18812", "abs": "https://arxiv.org/abs/2507.18812", "authors": ["Yiping Jia", "Zhen Ming Jiang", "Shayan Noei", "Ying Zou"], "title": "MemoCoder: Automated Function Synthesis using LLM-Supported Agents", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs) such as GitHub\nCopilot and ChatGPT, developers increasingly rely on AI-assisted tools to\nsupport code generation. While LLMs can generate syntactically correct\nsolutions for well-structured programming tasks, they often struggle with\nchallenges that require iterative debugging, error handling, or adaptation to\ndiverse problem structures. Existing approaches such as fine-tuning or\nself-repair strategies either require costly retraining or lack mechanisms to\naccumulate and reuse knowledge from previous attempts.\n  To address these limitations, we propose MemoCoder, a multi-agent framework\nthat enables collaborative problem solving and persistent learning from past\nfixes. At the core of MemoCoder is a Fixing Knowledge Set, which stores\nsuccessful repairs and supports retrieval for future tasks. A central Mentor\nAgent supervises the repair process by identifying recurring error patterns and\nrefining high-level fixing strategies, providing a novel supervisory role that\nguides the self-repair loop. We evaluate MemoCoder across three public\nbenchmarks -- MBPP, HumanEval, and LiveCodeBench -- spanning a range of problem\ncomplexities. Experimental results show that MemoCoder consistently outperforms\nboth zero-shot prompting and a Self-Repair strategy, with improvements ranging\nfrom 3.1% to 12.1% in Pass@10 and from 1.4% to 14.5% in Pass@50, demonstrating\nits effectiveness in iterative refinement and knowledge-guided code generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMemoCoder\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u8fed\u4ee3\u8c03\u8bd5\u548c\u9519\u8bef\u5904\u7406\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u6301\u4e45\u5b66\u4e60\u548c\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u8fed\u4ee3\u8c03\u8bd5\u6216\u9519\u8bef\u5904\u7406\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u65b9\u6cd5\u5982\u5fae\u8c03\u6216\u81ea\u6211\u4fee\u590d\u7b56\u7565\u6210\u672c\u9ad8\u6216\u7f3a\u4e4f\u77e5\u8bc6\u79ef\u7d2f\u673a\u5236\uff0c\u6025\u9700\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "MemoCoder\u91c7\u7528\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5305\u62ec\u4e00\u4e2a\u4fee\u590d\u77e5\u8bc6\u96c6(Memory Set)\u548c\u4e00\u4e2a\u4e2d\u592e\u5bfc\u5e08\u4ee3\u7406(Mentor Agent)\uff0c\u524d\u8005\u5b58\u50a8\u6210\u529f\u7684\u4fee\u590d\u6848\u4f8b\uff0c\u540e\u8005\u8bc6\u522b\u9519\u8bef\u6a21\u5f0f\u5e76\u6307\u5bfc\u4fee\u590d\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\uff08MBPP\u3001HumanEval\u548cLiveCodeBench\uff09\u4e0a\u8fdb\u884c\uff0cMemoCoder\u5728Pass@10\u548cPass@50\u6307\u6807\u4e0a\u5206\u522b\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u548c\u81ea\u6211\u4fee\u590d\u7b56\u7565\u3002", "conclusion": "MemoCoder\u5728\u77e5\u8bc6\u5f15\u5bfc\u7684\u4ee3\u7801\u751f\u6210\u548c\u8fed\u4ee3\u4f18\u5316\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4e3aAI\u8f85\u52a9\u7f16\u7a0b\u5de5\u5177\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.18833", "pdf": "https://arxiv.org/pdf/2507.18833", "abs": "https://arxiv.org/abs/2507.18833", "authors": ["Wenyuan Jiang", "Diany Pressato", "Harsh Darji", "Thibaud Lutellier"], "title": "Exploring the Jupyter Ecosystem: An Empirical Study of Bugs and Vulnerabilities", "categories": ["cs.SE"], "comment": null, "summary": "Background. Jupyter notebooks are one of the main tools used by data\nscientists. Notebooks include features (configuration scripts, markdown,\nimages, etc.) that make them challenging to analyze compared to traditional\nsoftware. As a result, existing software engineering models, tools, and studies\ndo not capture the uniqueness of Notebook's behavior. Aims. This paper aims to\nprovide a large-scale empirical study of bugs and vulnerabilities in the\nNotebook ecosystem. Method. We collected and analyzed a large dataset of\nNotebooks from two major platforms. Our methodology involved quantitative\nanalyses of notebook characteristics (such as complexity metrics, contributor\nactivity, and documentation) to identify factors correlated with bugs.\nAdditionally, we conducted a qualitative study using grounded theory to\ncategorize notebook bugs, resulting in a comprehensive bug taxonomy. Finally,\nwe analyzed security-related commits and vulnerability reports to assess risks\nassociated with Notebook deployment frameworks. Results. Our findings highlight\nthat configuration issues are among the most common bugs in notebook documents,\nfollowed by incorrect API usage. Finally, we explore common vulnerabilities\nassociated with popular deployment frameworks to better understand risks\nassociated with Notebook development. Conclusions. This work highlights that\nnotebooks are less well-supported than traditional software, resulting in more\ncomplex code, misconfiguration, and poor maintenance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9Jupyter\u7b14\u8bb0\u672c\u4e2d\u7684\u9519\u8bef\u548c\u6f0f\u6d1e\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u914d\u7f6e\u95ee\u9898\u548cAPI\u4f7f\u7528\u4e0d\u5f53\u662f\u5e38\u89c1\u9519\u8bef\uff0c\u5e76\u5206\u6790\u4e86\u90e8\u7f72\u6846\u67b6\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u7531\u4e8eJupyter\u7b14\u8bb0\u672c\u7684\u7279\u6027\uff08\u5982\u914d\u7f6e\u811a\u672c\u3001Markdown\u7b49\uff09\u4f7f\u5176\u96be\u4ee5\u5206\u6790\uff0c\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u5176\u72ec\u7279\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7814\u7a76\u5176\u9519\u8bef\u548c\u6f0f\u6d1e\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u548c\u5206\u6790\u4e24\u5927\u5e73\u53f0\u7684\u7b14\u8bb0\u672c\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\uff08\u5982\u590d\u6742\u6027\u6307\u6807\u3001\u8d21\u732e\u8005\u6d3b\u52a8\u7b49\uff09\u548c\u5b9a\u6027\u7814\u7a76\uff08\u57fa\u4e8e\u624e\u6839\u7406\u8bba\u7684\u9519\u8bef\u5206\u7c7b\uff09\uff0c\u5e76\u8bc4\u4f30\u90e8\u7f72\u6846\u67b6\u7684\u5b89\u5168\u98ce\u9669\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u914d\u7f6e\u95ee\u9898\u548cAPI\u4f7f\u7528\u9519\u8bef\u6700\u5e38\u89c1\uff0c\u90e8\u7f72\u6846\u67b6\u4e5f\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u7b14\u8bb0\u672c\u7684\u652f\u6301\u4e0d\u5982\u4f20\u7edf\u8f6f\u4ef6\u5b8c\u5584\uff0c\u5bfc\u81f4\u4ee3\u7801\u590d\u6742\u3001\u914d\u7f6e\u9519\u8bef\u548c\u7ef4\u62a4\u4e0d\u826f\u95ee\u9898\u9891\u53d1\u3002"}}
{"id": "2507.18792", "pdf": "https://arxiv.org/pdf/2507.18792", "abs": "https://arxiv.org/abs/2507.18792", "authors": ["Zixu Zhou"], "title": "Decompiling Rust: An Empirical Study of Compiler Optimizations and Reverse Engineering Challenges", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "Decompiling Rust binaries is challenging due to the language's rich type\nsystem, aggressive compiler optimizations, and widespread use of high-level\nabstractions. In this work, we conduct a benchmark-driven evaluation of\ndecompilation quality across core Rust features and compiler build modes. Our\nautomated scoring framework shows that generic types, trait methods, and error\nhandling constructs significantly reduce decompilation quality, especially in\nrelease builds. Through representative case studies, we analyze how specific\nlanguage constructs affect control flow, variable naming, and type information\nrecovery. Our findings provide actionable insights for tool developers and\nhighlight the need for Rust-aware decompilation strategies.", "AI": {"tldr": "\u7531\u4e8eRust\u4e30\u5bcc\u7684\u7c7b\u578b\u7cfb\u7edf\u3001\u7f16\u8bd1\u5668\u4f18\u5316\u548c\u9ad8\u5c42\u62bd\u8c61\uff0c\u53cd\u7f16\u8bd1\u5176\u4e8c\u8fdb\u5236\u6587\u4ef6\u5177\u6709\u6311\u6218\u6027\u3002\u7814\u7a76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e86\u53cd\u7f16\u8bd1\u8d28\u91cf\uff0c\u53d1\u73b0\u6cdb\u578b\u3001\u7279\u8d28\u65b9\u6cd5\u548c\u9519\u8bef\u5904\u7406\u6784\u9020\u663e\u8457\u964d\u4f4e\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5728\u53d1\u5e03\u7248\u672c\u4e2d\u3002\u6848\u4f8b\u5206\u6790\u4e86\u8bed\u8a00\u6784\u9020\u5bf9\u63a7\u5236\u6d41\u3001\u53d8\u91cf\u547d\u540d\u548c\u7c7b\u578b\u4fe1\u606f\u6062\u590d\u7684\u5f71\u54cd\uff0c\u4e3a\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "Rust\u8bed\u8a00\u7684\u7279\u6027\u4f7f\u5176\u4e8c\u8fdb\u5236\u6587\u4ef6\u53cd\u7f16\u8bd1\u56f0\u96be\uff0c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u53cd\u7f16\u8bd1\u8d28\u91cf\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\uff0c\u4ee5\u6307\u5bfc\u5de5\u5177\u5f00\u53d1\u3002", "method": "\u91c7\u7528\u57fa\u51c6\u6d4b\u8bd5\u9a71\u52a8\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u81ea\u52a8\u5316\u8bc4\u5206\u6846\u67b6\u5206\u6790\u6838\u5fc3Rust\u7279\u6027\u548c\u7f16\u8bd1\u5668\u6784\u5efa\u6a21\u5f0f\uff0c\u5e76\u7ed3\u5408\u6848\u4f8b\u7814\u7a76\u5177\u4f53\u8bed\u8a00\u6784\u9020\u7684\u5f71\u54cd\u3002", "result": "\u6cdb\u578b\u3001\u7279\u8d28\u65b9\u6cd5\u548c\u9519\u8bef\u5904\u7406\u6784\u9020\u663e\u8457\u964d\u4f4e\u53cd\u7f16\u8bd1\u8d28\u91cf\uff0c\u53d1\u5e03\u7248\u672c\u7684\u6311\u6218\u66f4\u5927\u3002\u6848\u4f8b\u5206\u6790\u63ed\u793a\u4e86\u8bed\u8a00\u6784\u9020\u5bf9\u53cd\u7f16\u8bd1\u7684\u591a\u65b9\u9762\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u7528\u5efa\u8bae\uff0c\u5f3a\u8c03\u9700\u8981\u9488\u5bf9Rust\u7279\u6027\u7684\u53cd\u7f16\u8bd1\u7b56\u7565\u3002"}}
{"id": "2507.18637", "pdf": "https://arxiv.org/pdf/2507.18637", "abs": "https://arxiv.org/abs/2507.18637", "authors": ["Pingjing Yang", "Jennifer Cromley", "Jana Diesner"], "title": "More Expert-like Eye Gaze Movement Patterns are Related to Better X-ray Reading", "categories": ["cs.HC", "cs.AI"], "comment": "This work will appear at the 26th International Conference on\n  Artificial Intelligence in Education (AIED 2025)", "summary": "Understanding how novices acquire and hone visual search skills is crucial\nfor developing and optimizing training methods across domains. Network analysis\nmethods can be used to analyze graph representations of visual expertise. This\nstudy investigates the relationship between eye-gaze movements and learning\noutcomes among undergraduate dentistry students who were diagnosing dental\nradiographs over multiple semesters. We use network analysis techniques to\nmodel eye-gaze scanpaths as directed graphs and examine changes in network\nmetrics over time. Using time series clustering on each metric, we identify\ndistinct patterns of visual search strategies and explore their association\nwith students' diagnostic performance. Our findings suggest that the network\nmetric of transition entropy is negatively correlated with performance scores,\nwhile the number of nodes and edges as well as average PageRank are positively\ncorrelated with performance scores. Changes in network metrics for individual\nstudents over time suggest a developmental shift from intermediate to\nexpert-level processing. These insights contribute to understanding expertise\nacquisition in visual tasks and can inform the design of AI-assisted learning\ninterventions.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u773c\u52a8\u8f68\u8ff9\u7684\u7f51\u7edc\u5206\u6790\uff0c\u63a2\u7d22\u7259\u79d1\u5b66\u751f\u5728\u8bca\u65ad\u653e\u5c04\u5f71\u50cf\u65f6\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u53d1\u73b0\u67d0\u4e9b\u7f51\u7edc\u6307\u6807\u4e0e\u8bca\u65ad\u8868\u73b0\u76f8\u5173\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u4e13\u4e1a\u6280\u80fd\u83b7\u53d6\u3002", "motivation": "\u4e86\u89e3\u65b0\u624b\u5982\u4f55\u83b7\u5f97\u548c\u63d0\u5347\u89c6\u89c9\u641c\u7d22\u6280\u80fd\uff0c\u5bf9\u4f18\u5316\u8de8\u9886\u57df\u57f9\u8bad\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\u5efa\u6a21\u773c\u52a8\u626b\u63cf\u8def\u5f84\u4e3a\u6709\u5411\u56fe\uff0c\u5206\u6790\u7f51\u7edc\u6307\u6807\u968f\u65f6\u95f4\u7684\u53d8\u5316\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u805a\u7c7b\u8bc6\u522b\u4e0d\u540c\u89c6\u89c9\u641c\u7d22\u7b56\u7565\u6a21\u5f0f\u3002", "result": "\u8f6c\u79fb\u71b5\u4e0e\u8868\u73b0\u8d1f\u76f8\u5173\uff0c\u8282\u70b9\u548c\u8fb9\u6570\u53ca\u5e73\u5747PageRank\u4e0e\u8868\u73b0\u6b63\u76f8\u5173\uff1b\u5b66\u751f\u7f51\u7edc\u6307\u6807\u7684\u53d8\u5316\u663e\u793a\u4ece\u4e2d\u7ea7\u5230\u4e13\u5bb6\u7ea7\u5904\u7406\u7684\u8f6c\u53d8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u7406\u89e3\u89c6\u89c9\u4efb\u52a1\u7684\u4e13\u4e1a\u6280\u80fd\u53d1\u5c55\uff0c\u5e76\u4e3aAI\u8f85\u52a9\u5b66\u4e60\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2507.18750", "pdf": "https://arxiv.org/pdf/2507.18750", "abs": "https://arxiv.org/abs/2507.18750", "authors": ["Hyunwoo Oh", "SeungJu Cha", "Kwanyoung Lee", "Si-Woo Kim", "Dong-Jin Kim"], "title": "CatchPhrase: EXPrompt-Guided Encoder Adaptation for Audio-to-Image Generation", "categories": ["cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "We propose CatchPhrase, a novel audio-to-image generation framework designed\nto mitigate semantic misalignment between audio inputs and generated images.\nWhile recent advances in multi-modal encoders have enabled progress in\ncross-modal generation, ambiguity stemming from homographs and auditory\nillusions continues to hinder accurate alignment. To address this issue,\nCatchPhrase generates enriched cross-modal semantic prompts (EXPrompt Mining)\nfrom weak class labels by leveraging large language models (LLMs) and audio\ncaptioning models (ACMs). To address both class-level and instance-level\nmisalignment, we apply multi-modal filtering and retrieval to select the most\nsemantically aligned prompt for each audio sample (EXPrompt Selector). A\nlightweight mapping network is then trained to adapt pre-trained text-to-image\ngeneration models to audio input. Extensive experiments on multiple audio\nclassification datasets demonstrate that CatchPhrase improves audio-to-image\nalignment and consistently enhances generation quality by mitigating semantic\nmisalignment.", "AI": {"tldr": "CatchPhrase\u662f\u4e00\u79cd\u65b0\u7684\u97f3\u9891\u5230\u56fe\u50cf\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u8de8\u6a21\u6001\u8bed\u4e49\u63d0\u793a\u548c\u9009\u62e9\u6027\u8fc7\u6ee4\uff0c\u51cf\u5c11\u4e86\u97f3\u9891\u8f93\u5165\u4e0e\u751f\u6210\u56fe\u50cf\u4e4b\u95f4\u7684\u8bed\u4e49\u4e0d\u5bf9\u9f50\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u751f\u6210\u4e2d\u56e0\u540c\u97f3\u8bcd\u548c\u542c\u89c9\u9519\u89c9\u5bfc\u81f4\u7684\u8bed\u4e49\u4e0d\u5bf9\u9f50\u95ee\u9898\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u97f3\u9891\u63cf\u8ff0\u6a21\u578b\u751f\u6210\u4e30\u5bcc\u7684\u8de8\u6a21\u6001\u8bed\u4e49\u63d0\u793a\uff0c\u5e76\u901a\u8fc7\u591a\u6a21\u6001\u8fc7\u6ee4\u548c\u68c0\u7d22\u9009\u62e9\u6700\u4f18\u63d0\u793a\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u6620\u5c04\u7f51\u7edc\u9002\u914d\u9884\u8bad\u7ec3\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u97f3\u9891\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\uff0cCatchPhrase\u663e\u8457\u63d0\u9ad8\u4e86\u97f3\u9891\u5230\u56fe\u50cf\u7684\u5bf9\u9f50\u548c\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "CatchPhrase\u901a\u8fc7\u8bed\u4e49\u63d0\u793a\u589e\u5f3a\u548c\u9009\u62e9\u6027\u8fc7\u6ee4\u6709\u6548\u7f13\u89e3\u4e86\u8de8\u6a21\u6001\u751f\u6210\u4e2d\u7684\u8bed\u4e49\u4e0d\u5bf9\u9f50\u95ee\u9898\u3002"}}
{"id": "2507.18834", "pdf": "https://arxiv.org/pdf/2507.18834", "abs": "https://arxiv.org/abs/2507.18834", "authors": ["ASM Rizvi", "John Heidemann", "David Plonka"], "title": "Third-Party Assessment of Mobile Performance in the 5G Era", "categories": ["cs.NI", "cs.PF"], "comment": null, "summary": "The web experience using mobile devices is important since a significant\nportion of the Internet traffic is initiated from mobile devices. In the era of\n5G, users expect a high-performance data network to stream media content and\nfor other latency-sensitive applications. In this paper, we characterize mobile\nexperience in terms of latency, throughput, and stability measured from a\ncommercial, globally-distributed CDN. Unlike prior work, CDN data provides a\nrelatively neutral, carrier-agnostic perspective, providing a clear view of\nmultiple and international providers. Our analysis of mobile client traffic\nshows mobile users sometimes experience markedly low latency, even as low as 6\nms. However, only the top 5% users regularly experience less than 20 ms of\nminimum latency. While 100 Mb/s throughput is not rare, we show around 60%\nusers observe less than 50 Mb/s throughput. We find the minimum mobile latency\nis generally stable at a specific location which can be an important\ncharacteristic for anomaly detection.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5168\u7403\u5206\u5e03\u7684CDN\u6570\u636e\u5206\u6790\u4e86\u79fb\u52a8\u8bbe\u5907\u7684\u7f51\u7edc\u4f53\u9a8c\uff0c\u53d1\u73b0\u90e8\u5206\u7528\u6237\u80fd\u4f53\u9a8c\u5230\u6781\u4f4e\u5ef6\u8fdf\uff0c\u4f46\u5927\u591a\u6570\u7528\u6237\u7684\u541e\u5410\u91cf\u4e0d\u8db350 Mb/s\uff0c\u5e76\u63ed\u793a\u4e86\u5ef6\u8fdf\u7a33\u5b9a\u6027\u5bf9\u5f02\u5e38\u68c0\u6d4b\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u77405G\u65f6\u4ee3\u5230\u6765\uff0c\u79fb\u52a8\u8bbe\u5907\u5bf9\u9ad8\u6027\u80fd\u7f51\u7edc\u7684\u9700\u6c42\u589e\u52a0\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u591a\u8fd0\u8425\u5546\u548c\u56fd\u9645\u89c6\u89d2\u7684\u7814\u7a76\u3002", "method": "\u5229\u7528\u5546\u4e1a\u3001\u5168\u7403\u5206\u5e03\u7684CDN\u6570\u636e\uff0c\u4ece\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u7a33\u5b9a\u6027\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u79fb\u52a8\u7528\u6237\u4f53\u9a8c\u3002", "result": "\u90e8\u5206\u7528\u6237\u4f53\u9a8c\u6781\u4f4e\u5ef6\u8fdf\uff086\u6beb\u79d2\uff09\uff0c\u4f46\u4ec55%\u7528\u6237\u80fd\u7a33\u5b9a\u4f4e\u4e8e20\u6beb\u79d2\u300260%\u7528\u6237\u541e\u5410\u91cf\u4f4e\u4e8e50 Mb/s\uff0c\u4f46\u5ef6\u8fdf\u5728\u7279\u5b9a\u4f4d\u7f6e\u7a33\u5b9a\u3002", "conclusion": "\u79fb\u52a8\u7f51\u7edc\u6027\u80fd\u5728\u4e0d\u540c\u7528\u6237\u548c\u5730\u533a\u5dee\u5f02\u663e\u8457\uff0c\u5ef6\u8fdf\u7a33\u5b9a\u6027\u53ef\u4f5c\u4e3a\u5f02\u5e38\u68c0\u6d4b\u7684\u91cd\u8981\u6307\u6807\u3002"}}
{"id": "2507.18718", "pdf": "https://arxiv.org/pdf/2507.18718", "abs": "https://arxiv.org/abs/2507.18718", "authors": ["Ronald Fagin", "Neil Immerman", "Phokion Kolaitis", "Jonathan Lenchner", "Rik Sengupta"], "title": "Who Wins the Multi-Structural Game?", "categories": ["cs.LO", "F.4.1"], "comment": "27 pages, 7 figures", "summary": "Combinatorial games played between two players, called Spoiler and\nDuplicator, have often been used to capture syntactic properties of formal\nlogical languages. For instance, the widely used Ehrenfeucht-Fra\\\"iss\\'e (EF)\ngame captures the syntactic measure of quantifier rank of first-order formulas.\nFor every such game, there is an associated natural decision problem: \"given an\ninstance of the game, does Spoiler win the game on that instance?\" For EF\ngames, this problem was shown to be PSPACE-complete by Pezzoli in 1998. In this\npresent paper, we show that the same problem for the *multi-structural* (MS)\ngames of recent interest is PSPACE-hard, but contained in NEXPTIME. In the\nprocess, we also resolve an open problem posed by Pezzoli about the dependence\nof the hardness results for EF games on the arity of the schema under\nconsideration. Our techniques combine adaptations of Pezzoli's constructions\ntogether with insights from the theory of inapproximability of optimization\nproblems, as well as the recently developed technique of parallel play for MS\ngames.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u7ed3\u6784\uff08MS\uff09\u6e38\u620f\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u8bc1\u660e\u5176PSPACE\u96be\u4f46\u5c5e\u4e8eNEXPTIME\uff0c\u5e76\u89e3\u51b3\u4e86\u5173\u4e8eEF\u6e38\u620f\u96be\u5ea6\u4e0e\u6a21\u5f0f\u9636\u6570\u5173\u7cfb\u7684\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u901a\u8fc7\u7ec4\u5408\u6e38\u620f\uff08\u5982EF\u548cMS\u6e38\u620f\uff09\u7814\u7a76\u5f62\u5f0f\u903b\u8f91\u8bed\u8a00\u7684\u8bed\u6cd5\u6027\u8d28\uff0c\u5c24\u5176\u662f\u6e38\u620f\u7684\u51b3\u7b56\u95ee\u9898\u53ca\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u7ed3\u5408Pezzoli\u7684\u6784\u9020\u65b9\u6cd5\u3001\u4f18\u5316\u95ee\u9898\u7684\u4e0d\u53ef\u8fd1\u4f3c\u6027\u7406\u8bba\u4ee5\u53caMS\u6e38\u620f\u7684\u5e76\u884c\u73a9\u6cd5\u6280\u672f\u3002", "result": "\u8bc1\u660e\u4e86MS\u6e38\u620f\u7684\u51b3\u7b56\u95ee\u9898PSPACE\u96be\u4e14\u5c5e\u4e8eNEXPTIME\uff0c\u89e3\u51b3\u4e86EF\u6e38\u620f\u4e0e\u6a21\u5f0f\u9636\u6570\u5173\u7cfb\u7684\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "MS\u6e38\u620f\u7684\u590d\u6742\u6027\u4ecb\u4e8ePSPACE\u548cNEXPTIME\u4e4b\u95f4\uff0c\u4e3a\u903b\u8f91\u6e38\u620f\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.18664", "pdf": "https://arxiv.org/pdf/2507.18664", "abs": "https://arxiv.org/abs/2507.18664", "authors": ["Aidan Murray", "Eddie Waite", "Caleb Ross", "Scarlet Mitchell", "Alexander Bradley", "Joanna Jamrozy", "Kenny Mitchell"], "title": "Generating real-time detailed ground visualisations from sparse aerial point clouds", "categories": ["cs.GR", "cs.CV", "I.3.2; I.4.10"], "comment": "CVMP Short Paper. 1 page, 3 figures, CVMP 2022: The 19th ACM SIGGRAPH\n  European Conference on Visual Media Production, London. This work was\n  supported by the European Union's Horizon 2020 research and innovation\n  programme under Grant 101017779", "summary": "Building realistic wide scale outdoor 3D content with sufficient visual\nquality to observe at walking eye level or from driven vehicles is often\ncarried out by large teams of artists skilled in modelling, texturing, material\nshading and lighting, which typically leads to both prohibitive costs and\nreduced accuracy honoring the variety of real world ground truth landscapes. In\nour proposed method, we define a process to automatically amplify real-world\nscanned data and render real-time in animated 3D to explore at close range with\nhigh quality for training, simulation, video game and visualisation\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u52a8\u589e\u5f3a\u771f\u5b9e\u4e16\u754c\u626b\u63cf\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf3D\u5185\u5bb9\uff0c\u964d\u4f4e\u6210\u672c\u548c\u63d0\u5347\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u827a\u672f\u5bb6\u56e2\u961f\uff0c\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u7cbe\u786e\u8fd8\u539f\u771f\u5b9e\u666f\u89c2\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5904\u7406\u548c\u6e32\u67d3\u771f\u5b9e\u4e16\u754c\u626b\u63cf\u6570\u636e\uff0c\u751f\u6210\u5b9e\u65f6\u52a8\u753b3D\u5185\u5bb9\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u8fd1\u8ddd\u79bb\u53ef\u63a2\u7d22\u76843D\u5185\u5bb9\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u5347\u8fd8\u539f\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u8bad\u7ec3\u3001\u6a21\u62df\u7b49\u9886\u57df\u3002"}}
{"id": "2507.18729", "pdf": "https://arxiv.org/pdf/2507.18729", "abs": "https://arxiv.org/abs/2507.18729", "authors": ["Yanbo Zhao", "Jinku Cui", "Zecheng Li", "Shuyin Jiao", "Xu Liu", "Jiajia Li"], "title": "CUTHERMO: Understanding GPU Memory Inefficiencies with Heat Map Profiling", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "GPUs have become indispensable in high-performance computing, machine\nlearning, and many other domains. Efficiently utilizing the memory subsystem on\nGPUs is critical for maximizing computing power through massive parallelism.\nAnalyzing memory access patterns has proven to be an effective method for\nunderstanding memory bottlenecks in applications. However, comprehensive\nruntime and fine-grained memory profiling support is lacking on GPU\narchitectures. In this work, we introduce cuThermo, a lightweight and practical\nprofiling tool for GPU memory analysis. It operates on GPU binaries without\nrequiring any modifications to hardware, operating system, or application\nsource code. Given a CUDA application, cuThermo identifies memory\ninefficiencies at runtime via a heat map based on distinct visited warp counts\nto represent word-sector-level data sharing and provides optimization guidance\nin performance tuning iterations. Through our experiments on six applications,\nwe identified five memory access patterns that are portable across different\nGPU architectures. By evaluating optimization on two GPUs, cuThermo achieves up\nto $721.79\\%$ performance improvement.", "AI": {"tldr": "cuThermo\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7GPU\u5185\u5b58\u5206\u6790\u5de5\u5177\uff0c\u901a\u8fc7\u70ed\u56fe\u8bc6\u522b\u5185\u5b58\u8bbf\u95ee\u6548\u7387\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "GPU\u5185\u5b58\u5b50\u7cfb\u7edf\u7684\u9ad8\u6548\u5229\u7528\u5bf9\u6700\u5927\u5316\u8ba1\u7b97\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u5185\u5b58\u5206\u6790\u652f\u6301\u3002", "method": "\u5f00\u53d1cuThermo\u5de5\u5177\uff0c\u57fa\u4e8eGPU\u4e8c\u8fdb\u5236\u5206\u6790\u8fd0\u884c\u65f6\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u65e0\u9700\u4fee\u6539\u786c\u4ef6\u6216\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0ccuThermo\u80fd\u8bc6\u522b\u4e94\u79cd\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe721.79%\u3002", "conclusion": "cuThermo\u4e3aGPU\u5185\u5b58\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16229", "pdf": "https://arxiv.org/pdf/2507.16229", "abs": "https://arxiv.org/abs/2507.16229", "authors": ["Bo Wen", "Chen Wang", "Qiwei Han", "Raquel Norel", "Julia Liu", "Thaddeus Stappenbeck", "Jeffrey L. Rogers"], "title": "Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.HC", "cs.SE"], "comment": "IEEE International Conference on Digital Health (ICDH) 2025", "summary": "The integration of voice-based AI agents in healthcare presents a\ntransformative opportunity to bridge economic and accessibility gaps in digital\nhealth delivery. This paper explores the role of large language model\n(LLM)-powered voice assistants in enhancing preventive care and continuous\npatient monitoring, particularly in underserved populations. Drawing insights\nfrom the development and pilot study of Agent PULSE (Patient Understanding and\nLiaison Support Engine) -- a collaborative initiative between IBM Research,\nCleveland Clinic Foundation, and Morehouse School of Medicine -- we present an\neconomic model demonstrating how AI agents can provide cost-effective\nhealthcare services where human intervention is economically unfeasible. Our\npilot study with 33 inflammatory bowel disease patients revealed that 70\\%\nexpressed acceptance of AI-driven monitoring, with 37\\% preferring it over\ntraditional modalities. Technical challenges, including real-time\nconversational AI processing, integration with healthcare systems, and privacy\ncompliance, are analyzed alongside policy considerations surrounding\nregulation, bias mitigation, and patient autonomy. Our findings suggest that\nAI-driven voice agents not only enhance healthcare scalability and efficiency\nbut also improve patient engagement and accessibility. For healthcare\nexecutives, our cost-utility analysis demonstrates huge potential savings for\nroutine monitoring tasks, while technologists can leverage our framework to\nprioritize improvements yielding the highest patient impact. By addressing\ncurrent limitations and aligning AI development with ethical and regulatory\nframeworks, voice-based AI agents can serve as a critical entry point for\nequitable, sustainable digital healthcare solutions.", "AI": {"tldr": "voice-based AI agents in healthcare can bridge accessibility gaps\uff0c\u63d0\u9ad8\u9884\u9632\u62a4\u7406\u6548\u7387\uff0c\u5c24\u5176\u5728\u670d\u52a1\u4e0d\u8db3\u4eba\u7fa4\u4e2d\u3002\u7814\u7a76\u53d1\u73b0\u591a\u6570\u60a3\u8005\u63a5\u53d7AI\u76d1\u6d4b\u3002\u6280\u672f\u6311\u6218\u548c\u653f\u7b56\u95ee\u9898\u9700\u89e3\u51b3\u4ee5\u5b9e\u73b0\u53ef\u6301\u7eed\u3001\u516c\u5e73\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u63a2\u7d22\u8bed\u97f3AI\u5728\u533b\u7597\u4e2d\u7684\u4f5c\u7528\uff0c\u89e3\u51b3\u7ecf\u6d4e\u4e0e\u53ef\u53ca\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5f31\u52bf\u7fa4\u4f53\u4e2d\u3002", "method": "\u5f00\u53d1Agent PULSE\u7cfb\u7edf\u5e76\u8fdb\u884c\u8bd5\u70b9\u7814\u7a76\uff0c\u5206\u6790\u7ecf\u6d4e\u6a21\u578b\u548c\u6280\u672f\u6311\u6218\u3002", "result": "70%\u60a3\u8005\u63a5\u53d7AI\u76d1\u6d4b\uff0c37%\u66f4\u7231AI\u800c\u975e\u4f20\u7edf\u65b9\u5f0f\u3002AI\u53ef\u663e\u8457\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u5347\u6548\u7387\u3002", "conclusion": "\u8bed\u97f3AI\u5728\u533b\u7597\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u9700\u89e3\u51b3\u6280\u672f\u3001\u653f\u7b56\u548c\u4f26\u7406\u95ee\u9898\u4ee5\u5b9e\u73b0\u53ef\u6301\u7eed\u5e94\u7528\u3002"}}
{"id": "2507.18889", "pdf": "https://arxiv.org/pdf/2507.18889", "abs": "https://arxiv.org/abs/2507.18889", "authors": ["Yinxiao Feng", "Tiancheng Chen", "Yuchen Wei", "Siyuan Shen", "Shiju Wang", "Wei Li", "Kaisheng Ma", "Torsten Hoefler"], "title": "RailX: A Flexible, Scalable, and Low-Cost Network Architecture for Hyper-Scale LLM Training Systems", "categories": ["cs.AR", "cs.DC", "cs.NI"], "comment": "25 pages, 21 figures, 6 tables", "summary": "Increasingly large AI workloads are calling for hyper-scale infrastructure;\nhowever, traditional interconnection network architecture is neither scalable\nnor cost-effective enough. Tree-based topologies such as the\n\\textit{Rail-optimized} network are extremely expensive, while direct\ntopologies such as \\textit{Torus} have insufficient bisection bandwidth and\nflexibility. In this paper, we propose \\textit{RailX}, a reconfigurable network\narchitecture based on intra-node direct connectivity and inter-node circuit\nswitching. Nodes and optical switches are physically 2D-organized, achieving\nbetter scalability than existing centralized circuit switching networks. We\npropose a novel interconnection method based on \\textit{Hamiltonian\nDecomposition} theory to organize separate rail-based rings into\n\\textit{all-to-all} topology, simultaneously optimizing ring-collective and\nall-to-all communication. More than $100$K chips with hyper bandwidth can be\ninterconnected with a flat switching layer, and the diameter is only $2\\sim4$\ninter-node hops. The network cost per injection/All-Reduce bandwidth of\n\\textit{RailX} is less than $10\\%$ of the Fat-Tree, and the cost per\nbisection/All-to-All bandwidth is less than $50\\%$ of the Fat-Tree.\nSpecifically, only $\\sim$\\$$1.3$B is required to interconnect 200K chips with\n1.8TB bandwidth. \\textit{RailX} can also be used in the ML-as-a-service (MLaaS)\nscenario, where single or multiple training workloads with various shapes,\nscales, and parallelism strategies can be flexibly mapped, and failures can be\nworked around.", "AI": {"tldr": "RailX\u662f\u4e00\u79cd\u57fa\u4e8e\u8282\u70b9\u5185\u76f4\u8fde\u548c\u8282\u70b9\u95f4\u7535\u8def\u4ea4\u6362\u7684\u53ef\u91cd\u6784\u7f51\u7edc\u67b6\u6784\uff0c\u4f18\u5316\u4e86\u5927\u89c4\u6a21AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u4e92\u8054\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u4e92\u8054\u7f51\u7edc\u67b6\u6784\u5728\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\u4e0a\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5927\u89c4\u6a21AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "RailX\u91c7\u7528\u8282\u70b9\u5185\u76f4\u8fde\u548c\u8282\u70b9\u95f4\u7535\u8def\u4ea4\u6362\u76842D\u7ec4\u7ec7\u65b9\u5f0f\uff0c\u7ed3\u5408Hamiltonian\u5206\u89e3\u7406\u8bba\uff0c\u5c06\u5206\u6563\u7684\u73af\u5f62\u62d3\u6251\u7ec4\u7ec7\u6210\u5168\u4e92\u8054\u62d3\u6251\u3002", "result": "RailX\u53ef\u8fde\u63a5\u8d85\u8fc7100K\u82af\u7247\uff0c\u8df3\u6570\u4ec5\u4e3a2~4\uff0c\u6210\u672c\u4ec5\u4e3aFat-Tree\u768410%~50%\uff0c\u9002\u7528\u4e8eMLaaS\u573a\u666f\u3002", "conclusion": "RailX\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u4e14\u7075\u6d3b\u7684\u4e92\u8054\u7f51\u7edc\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8d85\u5927\u89c4\u6a21AI\u5de5\u4f5c\u8d1f\u8f7d\u3002"}}
{"id": "2507.18891", "pdf": "https://arxiv.org/pdf/2507.18891", "abs": "https://arxiv.org/abs/2507.18891", "authors": ["Michael Mandulak", "S M Ferdous", "Sayan Ghosh", "Mahantesh Halappanavar", "George Slota"], "title": "ApproxJoin: Approximate Matching for Efficient Verification in Fuzzy Set Similarity Join", "categories": ["cs.DB"], "comment": null, "summary": "The set similarity join problem is a fundamental problem in data processing\nand discovery, relying on exact similarity measures between sets. In the\npresence of alterations, such as misspellings on string data, the fuzzy set\nsimilarity join problem instead approximately matches pairs of elements based\non the maximum weighted matching of the bipartite graph representation of sets.\nState-of-the-art methods within this domain improve performance through\nefficient filtering methods within the filter-verify framework, primarily to\noffset high verification costs induced by the usage of the Hungarian algorithm\n- an optimal matching method. Instead, we directly target the verification\nprocess to assess the efficacy of more efficient matching methods within\ncandidate pair pruning.\n  We present ApproxJoin, the first work of its kind in applying approximate\nmaximum weight matching algorithms for computationally expensive fuzzy set\nsimilarity join verification. We comprehensively test the performance of three\napproximate matching methods: the Greedy, Locally Dominant and Paz Schwartzman\nmethods, and compare with the state-of-the-art approach using exact matching.\nOur experimental results show that ApproxJoin yields performance improvements\nof 2-19x the state-of-the-art with high accuracy (99% recall).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ApproxJoin\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd1\u4f3c\u6700\u5927\u6743\u91cd\u5339\u914d\u7b97\u6cd5\u4f18\u5316\u6a21\u7cca\u96c6\u5408\u76f8\u4f3c\u6027\u8fde\u63a5\u95ee\u9898\u4e2d\u7684\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u6027\u80fd\u63d0\u53472-19\u500d\u4e14\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u6a21\u7cca\u96c6\u5408\u76f8\u4f3c\u6027\u8fde\u63a5\u95ee\u9898\u4e2d\u9a8c\u8bc1\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u9a8c\u8bc1\u8fc7\u7a0b\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faApproxJoin\u65b9\u6cd5\uff0c\u5e94\u7528\u4e09\u79cd\u8fd1\u4f3c\u5339\u914d\u7b97\u6cd5\uff08Greedy\u3001Locally Dominant\u548cPaz Schwartzman\uff09\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u5308\u7259\u5229\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660eApproxJoin\u6027\u80fd\u63d0\u53472-19\u500d\uff0c\u4e14\u4fdd\u630199%\u7684\u53ec\u56de\u7387\u3002", "conclusion": "\u8fd1\u4f3c\u5339\u914d\u7b97\u6cd5\u5728\u6a21\u7cca\u96c6\u5408\u76f8\u4f3c\u6027\u8fde\u63a5\u95ee\u9898\u4e2d\u80fd\u9ad8\u6548\u66ff\u4ee3\u7cbe\u786e\u5339\u914d\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.18957", "pdf": "https://arxiv.org/pdf/2507.18957", "abs": "https://arxiv.org/abs/2507.18957", "authors": ["Jianming Chang", "Jieke Shi", "Yunbo Lyu", "Xin Zhou", "Lulu Wang", "Zhou Yang", "Bixin Li", "David Lo"], "title": "SLICEMATE: Accurate and Scalable Static Program Slicing via LLM-Powered Agents", "categories": ["cs.SE"], "comment": null, "summary": "Static program slicing, which extracts the executable portions of a program\nthat affect the values at a specific location, supports many software analysis\ntasks such as debugging and security auditing. However, traditional slicing\ntools rely on computationally expensive reachability analysis over dependency\ngraphs, which struggle to scale to large programs and often fail to handle code\nwith incomplete syntax. Recently emerged learning-based methods, while more\nrobust to such cases, still fall short of achieving comparable performance to\ntraditional methods on well-formed code.\n  In this work, we propose SliceMate, a novel static program slicing solution\npowered by Large Language Model (LLM) agents. It bypasses the need for explicit\ndependency graph construction and achieving superior slicing accuracy.\nConcretely, SliceMate integrates three specialized agents: (1) a synthesis\nagent that produces candidate slices by incrementally expanding the scan scope\nacross functions and files guided by LLM-inferred dependencies; (2) a\nverification agent that performs conciseness and completeness checks of the\ncandidate slices, detecting missing or irrelevant statements; and (3) a\nrefinement agent that repairs the slices with minimal edits in accordance with\nthe verification results. These agents are orchestrated by a control module\nthat ensures timely convergence and outputs high-quality slices without manual\nintervention. For rigorous evaluation, we construct a new and high-quality\nbenchmark, SliceBench, comprising 2,200 manually annotated Java and Python\nprograms, with program lengths ranging from 5 to 8,577 lines, significantly\nlarger than those in existing slicing benchmarks. Experimental results show\nthat SliceMate greatly outperforms both traditional and learning-based slicing\ntools.", "AI": {"tldr": "SliceMate \u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b0\u578b\u9759\u6001\u7a0b\u5e8f\u5207\u7247\u5de5\u5177\uff0c\u901a\u8fc7\u96c6\u6210\u5408\u6210\u3001\u9a8c\u8bc1\u548c\u4f18\u5316\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5207\u7247\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u7a0b\u5e8f\u5207\u7247\u5de5\u5177\u4f9d\u8d56\u8ba1\u7b97\u5bc6\u96c6\u7684\u4f9d\u8d56\u56fe\u5206\u6790\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5927\u7a0b\u5e8f\u4e14\u5bf9\u8bed\u6cd5\u4e0d\u5b8c\u6574\u4ee3\u7801\u5904\u7406\u4e0d\u4f73\uff1b\u5b66\u4e60\u578b\u65b9\u6cd5\u867d\u66f4\u9c81\u68d2\uff0c\u4f46\u5728\u89c4\u8303\u4ee3\u7801\u4e0a\u8868\u73b0\u4e0d\u53ca\u4f20\u7edf\u65b9\u6cd5\u3002", "method": "SliceMate \u91c7\u7528\u4e09\u4e2a LLM \u4ee3\u7406\uff1a\u5408\u6210\u4ee3\u7406\u751f\u6210\u5019\u9009\u5207\u7247\uff0c\u9a8c\u8bc1\u4ee3\u7406\u68c0\u67e5\u5207\u7247\u7684\u5b8c\u6574\u6027\u548c\u7b80\u6d01\u6027\uff0c\u4f18\u5316\u4ee3\u7406\u4fee\u590d\u4e0d\u5408\u683c\u5207\u7247\uff0c\u63a7\u5236\u6a21\u5757\u534f\u8c03\u4ee3\u7406\u8f93\u51fa\u9ad8\u8d28\u91cf\u7ed3\u679c\u3002", "result": "\u5728 SliceBench \u57fa\u51c6\uff082200 \u4e2a\u624b\u52a8\u6807\u6ce8\u7684 Java/Python \u7a0b\u5e8f\uff09\u4e0a\uff0cSliceMate \u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u5b66\u4e60\u578b\u5de5\u5177\u3002", "conclusion": "SliceMate \u901a\u8fc7 LLM \u4ee3\u7406\u673a\u5236\uff0c\u65e0\u9700\u663e\u5f0f\u6784\u5efa\u4f9d\u8d56\u56fe\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5207\u7247\uff0c\u4e3a\u7a0b\u5e8f\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u65b0\u65b9\u6848\u3002"}}
{"id": "2507.18885", "pdf": "https://arxiv.org/pdf/2507.18885", "abs": "https://arxiv.org/abs/2507.18885", "authors": ["Qiyuan Xu", "Renxi Wang", "Haonan Li", "David Sanan", "Conrad Watt"], "title": "IsaMini: Redesigned Isabelle Proof Lanugage for Machine Learning", "categories": ["cs.PL"], "comment": null, "summary": "Neural Theorem Proving (NTP) employs deep learning methods, particularly\nLarge Language Models (LLMs), to automate formal proofs in proof assistants.\nThis approach holds promise for reducing the dramatic labor costs or\ncomputation costs required in proof engineering, which is fundamental to formal\nverification and other software engineering methods. The paper explores the\npotential of improving NTP by redesigning the proof language, given that LLMs'\ncapabilities depend highly on representations. We introduce \\emph{MiniLang}, a\nredesigned proof language for Isabelle/HOL incorporating an improved version of\nSledgehammer. Experiments show MiniLang benefits two fine-tuned LLMs by\nimproving the success rate on the PISA benchmark by up to 29\\% in comparison to\ngeneration of Isar proof script. The success rate under one attempt (so-called\n\\emph{pass@1}) reaches 69.1\\%, exceeding the previous Baldur's pass@64\n(65.7\\%); The pass@8 reaches 79.2\\%, exceeding the state-of-the-art on PISA\n(71.0\\%) achieved by Magnushammer.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u6539\u8fdb\u8bc1\u660e\u8bed\u8a00MiniLang\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eLLM\u7684\u795e\u7ecf\u5b9a\u7406\u8bc1\u660e\u6210\u529f\u7387\u3002", "motivation": "\u964d\u4f4e\u5f62\u5f0f\u9a8c\u8bc1\u4e2d\u7684\u52b3\u52a8\u529b\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u63a2\u7d22\u901a\u8fc7\u4f18\u5316\u8bc1\u660e\u8bed\u8a00\u63d0\u5347\u795e\u7ecf\u5b9a\u7406\u8bc1\u660e\uff08NTP\uff09\u7684\u6548\u679c\u3002", "method": "\u8bbe\u8ba1MiniLang\uff08\u6539\u8fdb\u7684Isabelle/HOL\u8bc1\u660e\u8bed\u8a00\uff09\uff0c\u7ed3\u5408\u589e\u5f3a\u7248Sledgehammer\uff0c\u6d4b\u8bd5\u4e24\u79cd\u5fae\u8c03LLM\u3002", "result": "MiniLang\u5c06PISA\u57fa\u51c6\u4e0a\u7684\u6210\u529f\u7387\u63d0\u534729%\uff0cpass@1\u8fbe69.1%\uff0c\u8d85\u8d8aBaldur\u7684pass@64\uff0865.7%\uff09\u3002", "conclusion": "MiniLang\u8bc1\u660e\u8bed\u8a00\u663e\u8457\u63d0\u5347NTP\u6027\u80fd\uff0c\u4e3a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2507.18638", "pdf": "https://arxiv.org/pdf/2507.18638", "abs": "https://arxiv.org/abs/2507.18638", "authors": ["Rizal Khoirul Anam"], "title": "Prompt Engineering and the Effectiveness of Large Language Models in Enhancing Human Productivity", "categories": ["cs.HC", "cs.AI", "68T50 68T50 68T50", "I.2.7"], "comment": "38 pages, 15 tables, 5 figures. Submitted as a research paper draft\n  for arXiv. Based on survey data collected in 2025", "summary": "The widespread adoption of large language models (LLMs) such as ChatGPT,\nGemini, and DeepSeek has significantly changed how people approach tasks in\neducation, professional work, and creative domains. This paper investigates how\nthe structure and clarity of user prompts impact the effectiveness and\nproductivity of LLM outputs. Using data from 243 survey respondents across\nvarious academic and occupational backgrounds, we analyze AI usage habits,\nprompting strategies, and user satisfaction. The results show that users who\nemploy clear, structured, and context-aware prompts report higher task\nefficiency and better outcomes. These findings emphasize the essential role of\nprompt engineering in maximizing the value of generative AI and provide\npractical implications for its everyday use.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u6e05\u6670\u3001\u7ed3\u6784\u5316\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u63d0\u793a\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\u3001Gemini\u548cDeepSeek\uff09\u7684\u8f93\u51fa\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u63a2\u8ba8\u7528\u6237\u63d0\u793a\u7684\u7ed3\u6784\u548c\u6e05\u6670\u5ea6\u5982\u4f55\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u6027\u548c\u751f\u4ea7\u529b\u3002", "method": "\u901a\u8fc7243\u540d\u6765\u81ea\u4e0d\u540c\u5b66\u672f\u548c\u804c\u4e1a\u80cc\u666f\u7684\u8c03\u67e5\u53d7\u8bbf\u8005\u7684\u6570\u636e\uff0c\u5206\u6790AI\u4f7f\u7528\u4e60\u60ef\u3001\u63d0\u793a\u7b56\u7565\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "result": "\u4f7f\u7528\u6e05\u6670\u3001\u7ed3\u6784\u5316\u4e14\u4e0a\u4e0b\u6587\u76f8\u5173\u63d0\u793a\u7684\u7528\u6237\u62a5\u544a\u4e86\u66f4\u9ad8\u7684\u4efb\u52a1\u6548\u7387\u548c\u66f4\u597d\u7684\u7ed3\u679c\u3002", "conclusion": "\u63d0\u793a\u5de5\u7a0b\u5728\u6700\u5927\u5316\u751f\u6210\u5f0fAI\u4ef7\u503c\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u4e3a\u65e5\u5e38\u4f7f\u7528\u63d0\u4f9b\u5b9e\u9645\u6307\u5bfc\u3002"}}
{"id": "2507.18932", "pdf": "https://arxiv.org/pdf/2507.18932", "abs": "https://arxiv.org/abs/2507.18932", "authors": ["Lei Zhang", "Xin Zhou", "Chaoyue He", "Di Wang", "Yi Wu", "Hong Xu", "Wei Liu", "Chunyan Miao"], "title": "Benchmarking Multimodal Understanding and Complex Reasoning for ESG Tasks", "categories": ["cs.MM", "cs.CL"], "comment": null, "summary": "Environmental, Social, and Governance (ESG) reports are essential for\nevaluating sustainability practices, ensuring regulatory compliance, and\npromoting financial transparency. However, these documents are often lengthy,\nstructurally diverse, and multimodal, comprising dense text, structured tables,\ncomplex figures, and layout-dependent semantics. Existing AI systems often\nstruggle to perform reliable document-level reasoning in such settings, and no\ndedicated benchmark currently exists in ESG domain. To fill the gap, we\nintroduce \\textbf{MMESGBench}, a first-of-its-kind benchmark dataset targeted\nto evaluate multimodal understanding and complex reasoning across structurally\ndiverse and multi-source ESG documents. This dataset is constructed via a\nhuman-AI collaborative, multi-stage pipeline. First, a multimodal LLM generates\ncandidate question-answer (QA) pairs by jointly interpreting rich textual,\ntabular, and visual information from layout-aware document pages. Second, an\nLLM verifies the semantic accuracy, completeness, and reasoning complexity of\neach QA pair. This automated process is followed by an expert-in-the-loop\nvalidation, where domain specialists validate and calibrate QA pairs to ensure\nquality, relevance, and diversity. MMESGBench comprises 933 validated QA pairs\nderived from 45 ESG documents, spanning across seven distinct document types\nand three major ESG source categories. Questions are categorized as\nsingle-page, cross-page, or unanswerable, with each accompanied by fine-grained\nmultimodal evidence. Initial experiments validate that multimodal and\nretrieval-augmented models substantially outperform text-only baselines,\nparticularly on visually grounded and cross-page tasks. MMESGBench is publicly\navailable as an open-source dataset at\nhttps://github.com/Zhanglei1103/MMESGBench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9ESG\u62a5\u544a\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6MMESGBench\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u7406\u89e3\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684AI\u7cfb\u7edf\u5728ESG\u62a5\u544a\u7684\u591a\u6a21\u6001\u548c\u7ed3\u6784\u5316\u591a\u6837\u6027\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u4e14\u7f3a\u4e4f\u4e13\u7528\u57fa\u51c6\u6570\u636e\u96c6\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u7684\u591a\u9636\u6bb5\u6d41\u7a0b\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u62ec\u591a\u6a21\u6001LLM\u751f\u6210\u5019\u9009QA\u5bf9\u3001LLM\u9a8c\u8bc1\u8bed\u4e49\u51c6\u786e\u6027\uff0c\u4ee5\u53ca\u4e13\u5bb6\u9a8c\u8bc1\u548c\u6821\u51c6\u3002", "result": "MMESGBench\u5305\u542b933\u4e2aQA\u5bf9\uff0c\u8986\u76d67\u79cd\u6587\u6863\u7c7b\u578b\u548c3\u79cdESG\u6765\u6e90\u3002\u5b9e\u9a8c\u663e\u793a\u591a\u6a21\u6001\u6a21\u578b\u5728\u89c6\u89c9\u548c\u8de8\u9875\u4efb\u52a1\u4e0a\u4f18\u4e8e\u7eaf\u6587\u672c\u57fa\u7ebf\u3002", "conclusion": "MMESGBench\u4e3aESG\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u7406\u89e3\u548c\u590d\u6742\u63a8\u7406\u7684\u7814\u7a76\u3002"}}
{"id": "2507.19050", "pdf": "https://arxiv.org/pdf/2507.19050", "abs": "https://arxiv.org/abs/2507.19050", "authors": ["Qiong Wu", "Yu Xie", "Pingyi Fan", "Dong Qin", "Kezhi Wang", "Nan Cheng", "Khaled B. Letaief"], "title": "Large Language Model-Based Task Offloading and Resource Allocation for Digital Twin Edge Computing Networks", "categories": ["cs.NI"], "comment": "This paper has been submitted to IEEE TMC", "summary": "In this paper, we propose a general digital twin edge computing network\ncomprising multiple vehicles and a server. Each vehicle generates multiple\ncomputing tasks within a time slot, leading to queuing challenges when\noffloading tasks to the server. The study investigates task offloading\nstrategies, queue stability, and resource allocation. Lyapunov optimization is\nemployed to transform long-term constraints into tractable short-term\ndecisions. To solve the resulting problem, an in-context learning approach\nbased on large language model (LLM) is adopted, replacing the conventional\nmulti-agent reinforcement learning (MARL) framework. Experimental results\ndemonstrate that the LLM-based method achieves comparable or even superior\nperformance to MARL.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6570\u5b57\u5b6a\u751f\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\uff0c\u7528\u4e8e\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u3002", "motivation": "\u7814\u7a76\u591a\u8f66\u8f86\u4e0e\u670d\u52a1\u5668\u6784\u6210\u7684\u6570\u5b57\u5b6a\u751f\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u4e2d\uff0c\u4efb\u52a1\u5378\u8f7d\u5f15\u8d77\u7684\u6392\u961f\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u957f\u671f\u7ea6\u675f\u4e0b\u7684\u8d44\u6e90\u5206\u914d\u6311\u6218\u3002", "method": "\u5229\u7528Lyapunov\u4f18\u5316\u5c06\u957f\u671f\u7ea6\u675f\u8f6c\u5316\u4e3a\u77ed\u671f\u51b3\u7b56\uff0c\u5e76\u91c7\u7528\u57fa\u4e8eLLM\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u66ff\u4ee3\u4f20\u7edfMARL\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLM\u65b9\u6cd5\u7684\u6027\u80fd\u4e0eMARL\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "LLM\u65b9\u6cd5\u5728\u6570\u5b57\u5b6a\u751f\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u662f\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.18798", "pdf": "https://arxiv.org/pdf/2507.18798", "abs": "https://arxiv.org/abs/2507.18798", "authors": ["Victor Barroso-Nascimento"], "title": "Higher-order Kripke models for intuitionistic and non-classical modal logics", "categories": ["cs.LO"], "comment": null, "summary": "This paper introduces higher-order Kripke models, a generalization of\nstandard Kripke models that is remarkably close to Kripke's original idea -\nboth mathematically and conceptually. Standard Kripke models are now considered\n$0$-ary models, whereas an $n$-ary model for $n > 0$ is a model whose set of\nobjects (''possible worlds'') contains only $(n-1)$-ary Kripke models. Models\nwith infinitely many layers are also considered. This framework is obtained by\npromoting a radical change of perspective in how modal semantics for\nnon-classical logics are defined: just like classical modalities are obtained\nthrough use of an accessibility relation between classical propositional\nmodels, non-classical modalities are now obtained through use of an\naccessibility relation between non-classical propositional models (even when\nthey are Kripke models already). The paper introduces the new models after\ndealing specifically with the case of intuitionistic modal logic. It is shown\nthat, depending on which intuitionistic $0$-ary propositional models are\nallowed, we may obtain $1$-ary models equivalent to either birelational models\nfor $IK$ or for a new logic called $MK$. Those $1$-ary models have an intuitive\nreading that adds to the interpretation of intuitionistic models in terms of\n''timelines'' the concept of ''alternative timelines''. More generally, the\n$1$-ary models can be read as defining a concept of ''alternative'' for any\nsubstantive interpretation of the $0$-ary models. The semantic clauses for\nnecessity and possibility of $MK$ are also modular and can be used to obtain\nsimilar modal semantics for every non-classical logic, each of which can be\nprovided with a similar intuitive reading. After intuitionistic modal logic is\ndealt with, the general structure of High-order Kripke Models and some of its\nvariants are defined, and a series of conjectures about their properties are\nstated.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9ad8\u9636Kripke\u6a21\u578b\uff0c\u662f\u6807\u51c6Kripke\u6a21\u578b\u7684\u63a8\u5e7f\uff0c\u5177\u6709\u6570\u5b66\u548c\u6982\u5ff5\u4e0a\u7684\u65b0\u9896\u6027\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u975e\u7ecf\u5178\u903b\u8f91\u7684\u6a21\u6001\u8bed\u4e49\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5bf9\u6807\u51c6Kripke\u6a21\u578b\u8fdb\u884c\u9ad8\u9636\u63a8\u5e7f\uff0c\u4ee5\u66f4\u7075\u6d3b\u5730\u5b9a\u4e49\u975e\u7ecf\u5178\u903b\u8f91\u7684\u6a21\u6001\u8bed\u4e49\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u5f15\u5165\u591a\u5c42Kripke\u6a21\u578b\uff08n\u9636\u6a21\u578b\uff09\uff0c\u5e76\u5b9a\u4e49\u6a21\u6001\u5173\u7cfb\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u7279\u522b\u662f\u4ee5\u76f4\u89c9\u4e3b\u4e49\u6a21\u6001\u903b\u8f91\u4e3a\u4f8b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c1\u9636\u6a21\u578b\u53ef\u4ee5\u7b49\u4ef7\u4e8e\u53cc\u5173\u7cfb\u6a21\u578b\u6216\u65b0\u903b\u8f91MK\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u76f4\u89c2\u7684\u89e3\u91ca\uff08\u5982\u201c\u65f6\u95f4\u7ebf\u201d\u548c\u201c\u66ff\u4ee3\u65f6\u95f4\u7ebf\u201d\uff09\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u4e00\u6846\u67b6\u4e3a\u5404\u79cd\u975e\u7ecf\u5178\u903b\u8f91\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6a21\u6001\u8bed\u4e49\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u731c\u60f3\u3002"}}
{"id": "2507.18899", "pdf": "https://arxiv.org/pdf/2507.18899", "abs": "https://arxiv.org/abs/2507.18899", "authors": ["Thomas Lechner", "Ben Watson", "Uri Wilensky", "Martin Felsen"], "title": "Procedural city modeling", "categories": ["cs.GR"], "comment": null, "summary": "We propose a method to procedurally generate a familiar yet complex human\nartifact: the city. We are not trying to reproduce existing cities, but to\ngenerate artificial cities that are convincing and plausible by capturing\ndevelopmental behavior. In addition, our results are meant to build upon\nthemselves, such that they ought to look compelling at any point along the\ntransition from village to metropolis. Our approach largely focuses upon land\nusage and building distribution for creating realistic city environments,\nwhereas previous attempts at city modeling have mainly focused on populating\nroad networks. Finally, we want our model to be self automated to the point\nthat the only necessary input is a terrain description, but other high-level\nand low-level parameters can be specified to support artistic contributions.\nWith the aid of agent based simulation we are generating a system of agents and\nbehaviors that interact with one another through their effects upon a simulated\nenvironment. Our philosophy is that as each agent follows a simple behavioral\nrule set, a more complex behavior will tend to emerge out of the interactions\nbetween the agents and their differing rule sets. By confining our model to a\nset of simple rules for each class of agents, we hope to make our model\nextendible not only in regard to the types of structures that are produced, but\nalso in describing the social and cultural influences prevalent in all cities", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7a0b\u5e8f\u5316\u751f\u6210\u57ce\u5e02\u7684\u65b9\u6cd5\uff0c\u5f3a\u8c03\u903c\u771f\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u65e8\u5728\u751f\u6210\u4eba\u5de5\u57ce\u5e02\uff0c\u6355\u6349\u57ce\u5e02\u53d1\u5c55\u884c\u4e3a\uff0c\u4f7f\u5176\u5728\u4efb\u4f55\u53d1\u5c55\u9636\u6bb5\uff08\u4ece\u6751\u5e84\u5230\u90fd\u5e02\uff09\u90fd\u663e\u5f97\u771f\u5b9e\u53ef\u4fe1\u3002", "method": "\u57fa\u4e8e\u571f\u5730\u7528\u9014\u548c\u5efa\u7b51\u5206\u5e03\uff0c\u4f7f\u7528\u4ee3\u7406\u6a21\u62df\u7cfb\u7edf\uff0c\u901a\u8fc7\u7b80\u5355\u884c\u4e3a\u89c4\u5219\u5b9e\u73b0\u590d\u6742\u884c\u4e3a\u3002", "result": "\u751f\u6210\u7684\u57ce\u5e02\u73af\u5883\u903c\u771f\uff0c\u652f\u6301\u827a\u672f\u6027\u8c03\u6574\uff0c\u6a21\u578b\u53ef\u6269\u5c55\u6027\u5f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7b80\u5355\u89c4\u5219\u548c\u4ee3\u7406\u4ea4\u4e92\uff0c\u5b9e\u73b0\u4e86\u903c\u771f\u4e14\u53ef\u6269\u5c55\u7684\u57ce\u5e02\u751f\u6210\u3002"}}
{"id": "2507.18748", "pdf": "https://arxiv.org/pdf/2507.18748", "abs": "https://arxiv.org/abs/2507.18748", "authors": ["Z. Jonny Kong", "Qiang Xu", "Y. Charlie Hu"], "title": "PPipe: Efficient Video Analytics Serving on Heterogeneous GPU Clusters via Pool-Based Pipeline Parallelism", "categories": ["cs.DC"], "comment": null, "summary": "With the rapid innovation of GPUs, heterogeneous GPU clusters in both public\nclouds and on-premise data centers have become increasingly commonplace. In\nthis paper, we demonstrate how pipeline parallelism, a technique wellstudied\nfor throughput-oriented deep learning model training, can be used effectively\nfor serving latency-bound model inference, e.g., in video analytics systems, on\nheterogeneous GPU clusters. Our work exploits the synergy between diversity in\nmodel layers and diversity in GPU architectures, which results in comparable\ninference latency for many layers when running on low-class and high-class\nGPUs. We explore how such overlooked capability of low-class GPUs can be\nexploited using pipeline parallelism and present a novel inference serving\nsystem, PPipe, that employs pool-based pipeline parallelism via an MILP-based\ncontrol plane and a data plane that performs resource reservation-based\nadaptive batching. Evaluation results on diverse workloads (18 CNN models) show\nthat PPipe achieves 41.1% - 65.5% higher utilization of low-class GPUs while\nmaintaining high utilization of high-class GPUs, leading to 32.2% - 75.1%\nhigher serving throughput compared to various baselines.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u5f02\u6784GPU\u96c6\u7fa4\u4e0a\u5229\u7528\u6d41\u6c34\u7ebf\u5e76\u884c\u6280\u672f\u9ad8\u6548\u670d\u52a1\u4e8e\u5ef6\u8fdf\u654f\u611f\u7684\u6a21\u578b\u63a8\u7406\uff08\u5982\u89c6\u9891\u5206\u6790\u7cfb\u7edf\uff09\u3002\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u6a21\u578b\u5c42\u4e0eGPU\u67b6\u6784\u7684\u591a\u6837\u6027\uff0c\u4f4e\u7aefGPU\u4e5f\u80fd\u5b9e\u73b0\u4e0e\u9ad8\u7aefGPU\u76f8\u5f53\u7684\u63a8\u7406\u5ef6\u8fdf\u3002\u6587\u4e2d\u63d0\u51fa\u7684PPipe\u7cfb\u7edf\u91c7\u7528\u57fa\u4e8eMILP\u7684\u63a7\u5236\u5e73\u9762\u548c\u8d44\u6e90\u9884\u7559\u5f0f\u81ea\u9002\u5e94\u6279\u5904\u7406\u6570\u636e\u5e73\u9762\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u7aefGPU\u5229\u7528\u7387\u548c\u670d\u52a1\u541e\u5410\u91cf\u3002", "motivation": "\u968f\u7740GPU\u7684\u5feb\u901f\u521b\u65b0\uff0c\u5f02\u6784GPU\u96c6\u7fa4\u5728\u516c\u5171\u4e91\u548c\u672c\u5730\u6570\u636e\u4e2d\u5fc3\u4e2d\u65e5\u76ca\u666e\u53ca\u3002\u7136\u800c\uff0c\u5982\u4f55\u5728\u8fd9\u79cd\u73af\u5883\u4e0b\u9ad8\u6548\u670d\u52a1\u4e8e\u5ef6\u8fdf\u654f\u611f\u7684\u6a21\u578b\u63a8\u7406\uff08\u5982\u89c6\u9891\u5206\u6790\u7cfb\u7edf\uff09\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6d41\u6c34\u7ebf\u5e76\u884c\u6280\u672f\u5728\u6b64\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPPipe\u7684\u65b0\u578b\u63a8\u7406\u670d\u52a1\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u91c7\u7528\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u7684\u63a7\u5236\u5e73\u9762\u5b9e\u73b0\u4e86\u6c60\u5f0f\u6d41\u6c34\u7ebf\u5e76\u884c\uff0c\u5e76\u901a\u8fc7\u8d44\u6e90\u9884\u7559\u5f0f\u81ea\u9002\u5e94\u6279\u5904\u7406\u7684\u6570\u636e\u5e73\u9762\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPPipe\u572818\u79cdCNN\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u4f4e\u7aefGPU\u5229\u7528\u7387\u63d0\u534741.1%-65.5%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7aefGPU\u7684\u9ad8\u5229\u7528\u7387\uff0c\u670d\u52a1\u541e\u5410\u91cf\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u9ad832.2%-75.1%\u3002", "conclusion": "PPipe\u901a\u8fc7\u6709\u6548\u5229\u7528\u4f4e\u7aefGPU\u7684\u6f5c\u529b\u5e76\u7ed3\u5408\u6d41\u6c34\u7ebf\u5e76\u884c\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f02\u6784GPU\u96c6\u7fa4\u5728\u5ef6\u8fdf\u654f\u611f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u541e\u5410\u91cf\uff0c\u4e3a\u672a\u6765\u7c7b\u4f3c\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2507.18882", "pdf": "https://arxiv.org/pdf/2507.18882", "abs": "https://arxiv.org/abs/2507.18882", "authors": ["Meriem Zerkouk", "Miloud Mihoubi", "Belkacem Chikhaoui"], "title": "A Comprehensive Review of AI-based Intelligent Tutoring Systems: Applications and Challenges", "categories": ["cs.IR", "cs.AI", "cs.HC"], "comment": "Journal of Computers in Education ( 2025 )", "summary": "AI-based Intelligent Tutoring Systems (ITS) have significant potential to\ntransform teaching and learning. As efforts continue to design, develop, and\nintegrate ITS into educational contexts, mixed results about their\neffectiveness have emerged. This paper provides a comprehensive review to\nunderstand how ITS operate in real educational settings and to identify the\nassociated challenges in their application and evaluation. We use a systematic\nliterature review method to analyze numerous qualified studies published from\n2010 to 2025, examining domains such as pedagogical strategies, NLP, adaptive\nlearning, student modeling, and domain-specific applications of ITS. The\nresults reveal a complex landscape regarding the effectiveness of ITS,\nhighlighting both advancements and persistent challenges. The study also\nidentifies a need for greater scientific rigor in experimental design and data\nanalysis. Based on these findings, suggestions for future research and\npractical implications are proposed.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u7814\u7a76\u4e862010\u81f32025\u5e74\u95f4\u5173\u4e8e\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff08ITS\uff09\u7684\u6587\u732e\uff0c\u5206\u6790\u4e86\u5176\u5728\u5b9e\u9645\u6559\u80b2\u73af\u5883\u4e2d\u7684\u8fd0\u4f5c\u53ca\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff08ITS\uff09\u5728\u6559\u80b2\u4e2d\u7684\u6709\u6548\u6027\u53ca\u9762\u4e34\u7684\u6311\u6218\uff0c\u4e3a\u5176\u6539\u8fdb\u548c\u5e94\u7528\u63d0\u4f9b\u79d1\u5b66\u4f9d\u636e\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u67902010\u81f32025\u5e74\u95f4\u5173\u4e8eITS\u7684\u5408\u683c\u7814\u7a76\uff0c\u6db5\u76d6\u6559\u5b66\u7b56\u7565\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u81ea\u9002\u5e94\u5b66\u4e60\u7b49\u9886\u57df\u3002", "result": "\u63ed\u793a\u4e86ITS\u6709\u6548\u6027\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u6307\u51fa\u5b9e\u9a8c\u4e2d\u9700\u8981\u66f4\u5f3a\u7684\u79d1\u5b66\u4e25\u8c28\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u5efa\u8bae\uff0c\u5f3a\u8c03\u6539\u8fdb\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u6570\u636e\u5206\u6790\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.19133", "pdf": "https://arxiv.org/pdf/2507.19133", "abs": "https://arxiv.org/abs/2507.19133", "authors": ["Wei-Hsing Huang", "Cheng-Jhih Shih", "Jian-Wei Su", "Samuel Wade Wang", "Vaidehi Garg", "Yuyao Kong", "Jen-Chun Tien", "Nealson Li", "Arijit Raychowdhury", "Meng-Fan Chang", "Yingyan", "Lin", "Shimeng Yu"], "title": "3DGauCIM: Accelerating Static/Dynamic 3D Gaussian Splatting via Digital CIM for High Frame Rate Real-Time Edge Rendering", "categories": ["cs.AR"], "comment": null, "summary": "Dynamic 3D Gaussian splatting (3DGS) extends static 3DGS to render dynamic\nscenes, enabling AR/VR applications with moving objects. However, implementing\ndynamic 3DGS on edge devices faces challenges: (1) Loading all Gaussian\nparameters from DRAM for frustum culling incurs high energy costs. (2)\nIncreased parameters for dynamic scenes elevate sorting latency and energy\nconsumption. (3) Limited on-chip buffer capacity with higher parameters reduces\nbuffer reuse, causing frequent DRAM access. (4) Dynamic 3DGS operations are not\nreadily compatible with digital compute-in-memory (DCIM). These challenges\nhinder real-time performance and power efficiency on edge devices, leading to\nreduced battery life or requiring bulky batteries. To tackle these challenges,\nwe propose algorithm-hardware co-design techniques. At the algorithmic level,\nwe introduce three optimizations: (1) DRAM-access reduction frustum culling to\nlower DRAM access overhead, (2) Adaptive tile grouping to enhance on-chip\nbuffer reuse, and (3) Adaptive interval initialization Bucket-Bitonic sort to\nreduce sorting latency. At the hardware level, we present a DCIM-friendly\ncomputation flow that is evaluated using the measured data from a 16nm DCIM\nprototype chip. Our experimental results on Large-Scale Real-World\nStatic/Dynamic Datasets demonstrate the ability to achieve high frame rate\nreal-time rendering exceeding 200 frame per second (FPS) with minimal power\nconsumption, merely 0.28 W for static Large-Scale Real-World scenes and 0.63 W\nfor dynamic Large-Scale Real-World scenes. This work successfully addresses the\nsignificant challenges of implementing static/dynamic 3DGS technology on\nresource-constrained edge devices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u52a8\u60013D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u65f6\u9762\u4e34\u7684\u529f\u8017\u548c\u6027\u80fd\u95ee\u9898\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u5e27\u7387\u5b9e\u65f6\u6e32\u67d3\u3002", "motivation": "\u52a8\u60013DGS\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u65f6\u9762\u4e34DRAM\u8bbf\u95ee\u5f00\u9500\u9ad8\u3001\u6392\u5e8f\u5ef6\u8fdf\u5927\u3001\u7247\u4e0a\u7f13\u51b2\u533a\u5bb9\u91cf\u4e0d\u8db3\u4ee5\u53ca\u4e0eDCIM\u4e0d\u517c\u5bb9\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u5b9e\u65f6\u6027\u80fd\u548c\u80fd\u6548\u3002", "method": "\u7b97\u6cd5\u5c42\u9762\u63d0\u51fa\u4e86\u51cf\u5c11DRAM\u8bbf\u95ee\u7684\u89c6\u9525\u5254\u9664\u3001\u81ea\u9002\u5e94\u5206\u5757\u5206\u7ec4\u548c\u81ea\u9002\u5e94\u533a\u95f4\u521d\u59cb\u5316\u6392\u5e8f\u4f18\u5316\uff1b\u786c\u4ef6\u5c42\u9762\u8bbe\u8ba1\u4e86DCIM\u53cb\u597d\u7684\u8ba1\u7b97\u6d41\u7a0b\uff0c\u5e76\u572816nm DCIM\u539f\u578b\u82af\u7247\u4e0a\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u9759\u6001\u548c\u52a8\u6001\u5927\u89c4\u6a21\u771f\u5b9e\u573a\u666f\u7684\u6e32\u67d3\u5e27\u7387\u8d85\u8fc7200 FPS\uff0c\u529f\u8017\u5206\u522b\u4ec5\u4e3a0.28 W\u548c0.63 W\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6210\u529f\u89e3\u51b3\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9759\u6001/\u52a8\u60013DGS\u6280\u672f\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2507.19154", "pdf": "https://arxiv.org/pdf/2507.19154", "abs": "https://arxiv.org/abs/2507.19154", "authors": ["Lunodzo J. Mwinuka", "Massimo Cafaro", "Lucas Pereira", "Hugo Morais"], "title": "Big Data Energy Systems: A Survey of Practices and Associated Challenges", "categories": ["cs.DB", "cs.DC"], "comment": null, "summary": "Energy systems generate vast amounts of data in extremely short time\nintervals, creating challenges for efficient data management. Traditional data\nmanagement methods often struggle with scalability and accessibility, limiting\ntheir usefulness. More advanced solutions, such as NoSQL databases and\ncloud-based platforms, have been adopted to address these issues. Still, even\nthese advanced solutions can encounter bottlenecks, which can impact the\nefficiency of data storage, retrieval, and analysis. This review paper explores\nthe research trends in big data management for energy systems, highlighting the\npractices, opportunities and challenges. Also, the data regulatory demands are\nhighlighted using chosen reference architectures. The review, in particular,\nexplores the limitations of current storage and data integration solutions and\nexamines how new technologies are applied to the energy sector. Novel insights\ninto emerging technologies, including data spaces, various data management\narchitectures, peer-to-peer data management, and blockchains, are provided,\nalong with practical recommendations for achieving enhanced data sharing and\nregulatory compliance.", "AI": {"tldr": "\u7efc\u8ff0\u8bba\u6587\u63a2\u8ba8\u4e86\u80fd\u6e90\u7cfb\u7edf\u4e2d\u5927\u6570\u636e\u7ba1\u7406\u7684\u7814\u7a76\u8d8b\u52bf\u3001\u5b9e\u8df5\u548c\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u6280\u672f\u5e94\u7528\u7684\u5efa\u8bae\u3002", "motivation": "\u80fd\u6e90\u7cfb\u7edf\u4ea7\u751f\u5927\u91cf\u6570\u636e\uff0c\u4f20\u7edf\u6570\u636e\u7ba1\u7406\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7814\u7a76\u8d8b\u52bf\u548c\u73b0\u6709\u6280\u672f\uff0c\u603b\u7ed3\u80fd\u6e90\u7cfb\u7edf\u4e2d\u5927\u6570\u636e\u7ba1\u7406\u7684\u5b9e\u8df5\u4e0e\u6311\u6218\u3002", "result": "\u63d0\u51fa\u4e86\u6570\u636e\u7a7a\u95f4\u3001P2P\u6570\u636e\u7ba1\u7406\u548c\u533a\u5757\u94fe\u7b49\u65b0\u6280\u672f\uff0c\u5e76\u7ed9\u51fa\u4e86\u6570\u636e\u5171\u4eab\u548c\u5408\u89c4\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "conclusion": "\u65b0\u6280\u672f\u4e3a\u80fd\u6e90\u7cfb\u7edf\u5927\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5b9e\u73b0\u9ad8\u6548\u548c\u5408\u89c4\u7684\u6570\u636e\u7ba1\u7406\u3002"}}
{"id": "2507.18982", "pdf": "https://arxiv.org/pdf/2507.18982", "abs": "https://arxiv.org/abs/2507.18982", "authors": ["Amir Hossain Raaj", "Fairuz Nawer Meem", "Sadia Afrin Mim"], "title": "Classifying Issues in Open-source GitHub Repositories", "categories": ["cs.SE"], "comment": null, "summary": "GitHub is the most widely used platform for software maintenance in the\nopen-source community. Developers report issues on GitHub from time to time\nwhile facing difficulties. Having labels on those issues can help developers\neasily address those issues with prior knowledge of labels. However, most of\nthe GitHub repositories do not maintain regular labeling for the issues. The\ngoal of this work is to classify issues in the open-source community using ML\n\\& DNN models. There are thousands of open-source repositories on GitHub. Some\nof the repositories label their issues properly whereas some of them do not.\nWhen issues are pre-labeled, the problem-solving process and the immediate\nassignment of corresponding personnel are facilitated for the team, thereby\nexpediting the development process. In this work, we conducted an analysis of\nprominent GitHub open-source repositories. We classified the issues in some\ncommon labels which are: API, Documentation, Enhancement, Question, Easy,\nHelp-wanted, Dependency, CI, Waiting for OP's response, Test, Bug, etc. Our\nstudy shows that DNN models outperf", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528ML\u548cDNN\u6a21\u578b\u5bf9GitHub\u5f00\u6e90\u793e\u533a\u4e2d\u7684issue\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u63d0\u9ad8\u95ee\u9898\u89e3\u51b3\u6548\u7387\u3002", "motivation": "GitHub\u4e0a\u5927\u591a\u6570\u4ed3\u5e93\u7684issue\u672a\u88ab\u89c4\u8303\u6807\u8bb0\uff0c\u5f71\u54cd\u5f00\u53d1\u6548\u7387\u3002", "method": "\u5206\u6790\u77e5\u540dGitHub\u4ed3\u5e93\uff0c\u4f7f\u7528ML\u548cDNN\u6a21\u578b\u5bf9issue\u8fdb\u884c\u5e38\u89c1\u6807\u7b7e\u5206\u7c7b\u3002", "result": "DNN\u6a21\u578b\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u81ea\u52a8\u5316\u6807\u7b7e\u5206\u7c7b\u6709\u52a9\u4e8e\u52a0\u5feb\u5f00\u53d1\u6d41\u7a0b\u3002"}}
{"id": "2507.19015", "pdf": "https://arxiv.org/pdf/2507.19015", "abs": "https://arxiv.org/abs/2507.19015", "authors": ["Samuel Xifaras", "Panagiotis Manolios", "Andrew T. Walter", "William Robertson"], "title": "An Enumerative Embedding of the Python Type System in ACL2s", "categories": ["cs.PL", "cs.LO", "cs.SE"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "Python is a high-level interpreted language that has become an industry\nstandard in a wide variety of applications. In this paper, we take a first step\ntowards using ACL2s to reason about Python code by developing an embedding of a\nsubset of the Python type system in ACL2s. The subset of Python types we\nsupport includes many of the most commonly used type annotations as well as\nuser-defined types comprised of supported types. We provide ACL2s definitions\nof these types, as well as defdata enumerators that are customized to provide\ncode coverage and identify errors in Python programs. Using the ACL2s\nembedding, we can generate instances of types that can then be used as inputs\nto fuzz Python programs, which allows us to identify bugs in Python code that\nare not detected by state-of-the-art Python type checkers. We evaluate our work\nagainst four open-source repositories, extracting their type information and\ngenerating inputs for fuzzing functions with type signatures that are in the\nsupported subset of Python types. Note that we only use the type signatures of\nfunctions to generate inputs and treat the bodies of functions as black boxes.\nWe measure code coverage, which ranges from about 68% to more than 80%, and\nidentify code patterns that hinder coverage such as complex branch conditions\nand external file system dependencies. We conclude with a discussion of the\nresults and recommendations for future work.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06Python\u7c7b\u578b\u7cfb\u7edf\u5b50\u96c6\u5d4c\u5165ACL2s\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8f93\u5165\u4ee5\u6a21\u7cca\u6d4b\u8bd5Python\u4ee3\u7801\uff0c\u5e76\u53d1\u73b0\u4f20\u7edf\u7c7b\u578b\u68c0\u67e5\u5668\u672a\u68c0\u6d4b\u5230\u7684\u9519\u8bef\u3002", "motivation": "\u89e3\u51b3Python\u4ee3\u7801\u4e2d\u672a\u88ab\u73b0\u6709\u7c7b\u578b\u68c0\u67e5\u5668\u53d1\u73b0\u7684\u9519\u8bef\u95ee\u9898\u3002", "method": "\u901a\u8fc7ACL2s\u5d4c\u5165Python\u7c7b\u578b\u7cfb\u7edf\u7684\u5b50\u96c6\uff0c\u751f\u6210\u7c7b\u578b\u5b9e\u4f8b\u4f5c\u4e3a\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u6e90\u5e93\u4e2d\u6d4b\u8bd5\uff0c\u4ee3\u7801\u8986\u76d6\u7387\u4e3a68%\u81f380%\u4ee5\u4e0a\uff0c\u5e76\u8bc6\u522b\u4e86\u5f71\u54cd\u8986\u76d6\u7387\u7684\u4ee3\u7801\u6a21\u5f0f\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.18639", "pdf": "https://arxiv.org/pdf/2507.18639", "abs": "https://arxiv.org/abs/2507.18639", "authors": ["Pawe\u0142 Niszczota", "Tomasz Grzegorczyk", "Alexander Pastukhov"], "title": "People Are Highly Cooperative with Large Language Models, Especially When Communication Is Possible or Following Human Interaction", "categories": ["cs.HC", "cs.CL", "cs.CY", "econ.GN", "q-fin.EC", "I.2.7; H.5.2; H.5.3; K.4.3"], "comment": null, "summary": "Machines driven by large language models (LLMs) have the potential to augment\nhumans across various tasks, a development with profound implications for\nbusiness settings where effective communication, collaboration, and stakeholder\ntrust are paramount. To explore how interacting with an LLM instead of a human\nmight shift cooperative behavior in such settings, we used the Prisoner's\nDilemma game -- a surrogate of several real-world managerial and economic\nscenarios. In Experiment 1 (N=100), participants engaged in a thirty-round\nrepeated game against a human, a classic bot, and an LLM (GPT, in real-time).\nIn Experiment 2 (N=192), participants played a one-shot game against a human or\nan LLM, with half of them allowed to communicate with their opponent, enabling\nLLMs to leverage a key advantage over older-generation machines. Cooperation\nrates with LLMs -- while lower by approximately 10-15 percentage points\ncompared to interactions with human opponents -- were nonetheless high. This\nfinding was particularly notable in Experiment 2, where the psychological cost\nof selfish behavior was reduced. Although allowing communication about\ncooperation did not close the human-machine behavioral gap, it increased the\nlikelihood of cooperation with both humans and LLMs equally (by 88%), which is\nparticularly surprising for LLMs given their non-human nature and the\nassumption that people might be less receptive to cooperating with machines\ncompared to human counterparts. Additionally, cooperation with LLMs was higher\nfollowing prior interaction with humans, suggesting a spillover effect in\ncooperative behavior. Our findings validate the (careful) use of LLMs by\nbusinesses in settings that have a cooperative component.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u4eba\u7c7b\u76f8\u6bd4\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u4e92\u52a8\u65f6\u5408\u4f5c\u7387\u7565\u4f4e\uff08\u4f4e10-15%\uff09\uff0c\u4f46\u6574\u4f53\u5408\u4f5c\u7387\u4ecd\u7136\u8f83\u9ad8\u3002\u6c9f\u901a\u867d\u672a\u5b8c\u5168\u7f29\u5c0f\u4eba\u673a\u884c\u4e3a\u5dee\u8ddd\uff0c\u4f46\u80fd\u5e73\u7b49\u63d0\u5347\u5408\u4f5c\u7387\u3002", "motivation": "\u63a2\u8ba8\u5728\u5546\u4e1a\u73af\u5883\u4e2d\uff0c\u7528LLM\u66ff\u4ee3\u4eba\u7c7b\u4e92\u52a8\u662f\u5426\u4f1a\u6539\u53d8\u5408\u4f5c\u884c\u4e3a\uff0c\u4ee5\u9a8c\u8bc1LLM\u5728\u9700\u8981\u5408\u4f5c\u7684\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\uff08\u91cd\u590d\u56da\u5f92\u56f0\u5883\u548c\u5355\u6b21\u56da\u5f92\u56f0\u5883\uff09\uff0c\u6bd4\u8f83\u53c2\u4e0e\u8005\u4e0e\u4eba\u7c7b\u3001\u4f20\u7edf\u673a\u5668\u4eba\u548cLLM\u7684\u5408\u4f5c\u884c\u4e3a\uff0c\u5e76\u6d4b\u8bd5\u6c9f\u901a\u5bf9\u5176\u5f71\u54cd\u3002", "result": "LLM\u7684\u5408\u4f5c\u7387\u867d\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u4f46\u4ecd\u8f83\u9ad8\uff1b\u6c9f\u901a\u80fd\u663e\u8457\u63d0\u5347\u5408\u4f5c\u7387\uff1b\u4e14\u4eba\u7c7b\u4e92\u52a8\u540e\u7684\u5408\u4f5c\u884c\u4e3a\u4f1a\u5ef6\u7eed\u5230\u4e0eLLM\u7684\u4e92\u52a8\u4e2d\u3002", "conclusion": "LLM\u5728\u5177\u5408\u4f5c\u6027\u7684\u5546\u4e1a\u573a\u666f\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8c28\u614e\u4f7f\u7528\u3002"}}
{"id": "2507.18940", "pdf": "https://arxiv.org/pdf/2507.18940", "abs": "https://arxiv.org/abs/2507.18940", "authors": ["Jingxuan Wei", "Caijun Jia", "Qi Chen", "Yujun Cai", "Linzhuang Sun", "Xiangxiang Zhang", "Gaowei Wu", "Bihui Yu"], "title": "LLaVA-NeuMT: Selective Layer-Neuron Modulation for Efficient Multilingual Multimodal Translation", "categories": ["cs.CL", "cs.MM"], "comment": null, "summary": "Multimodal Machine Translation (MMT) enhances translation quality by\nincorporating visual context, helping to resolve textual ambiguities. While\nexisting MMT methods perform well in bilingual settings, extending them to\nmultilingual translation remains challenging due to cross-lingual interference\nand ineffective parameter-sharing strategies. To address this, we propose\nLLaVA-NeuMT, a novel multimodal multilingual translation framework that\nexplicitly models language-specific and language-agnostic representations to\nmitigate multilingual interference. Our approach consists of a layer selection\nmechanism that identifies the most informative layers for different language\npairs and a neuron-level adaptation strategy that dynamically selects\nlanguage-specific and agnostic neurons to improve translation quality while\nreducing redundancy. We conduct extensive experiments on the M3-Multi30K and\nM3-AmbigCaps datasets, demonstrating that LLaVA-NeuMT, while fine-tuning only\n40\\% of the model parameters, surpasses full fine-tuning approaches and\nultimately achieves SOTA results on both datasets. Our analysis further\nprovides insights into the importance of selected layers and neurons in\nmultimodal multilingual adaptation, offering an efficient and scalable solution\nto cross-lingual adaptation in multimodal translation.", "AI": {"tldr": "LLaVA-NeuMT\u662f\u4e00\u79cd\u591a\u6a21\u6001\u591a\u8bed\u8a00\u7ffb\u8bd1\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u9009\u62e9\u548c\u795e\u7ecf\u5143\u7ea7\u52a8\u6001\u9002\u5e94\u7b56\u7565\uff0c\u51cf\u5c11\u8de8\u8bed\u8a00\u5e72\u6270\uff0c\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u4e14\u5728\u4ec5\u5fae\u8c0340%\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u5168\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u591a\u8bed\u8a00\u7ffb\u8bd1\u4e2d\uff0c\u8de8\u8bed\u8a00\u5e72\u6270\u548c\u53c2\u6570\u5171\u4eab\u7b56\u7565\u6548\u679c\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u7ffb\u8bd1\u6027\u80fd\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51faLLaVA-NeuMT\u6846\u67b6\uff0c\u5305\u542b\u5206\u5c42\u9009\u62e9\u673a\u5236\u548c\u795e\u7ecf\u5143\u7ea7\u52a8\u6001\u9002\u5e94\u7b56\u7565\uff0c\u660e\u786e\u533a\u5206\u8bed\u8a00\u76f8\u5173\u548c\u65e0\u5173\u8868\u5f81\u3002", "result": "\u5728M3-Multi30K\u548cM3-AmbigCaps\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0SOTA\u6548\u679c\uff0c\u4ec5\u5fae\u8c0340%\u53c2\u6570\u5373\u8d85\u8d8a\u5168\u5fae\u8c03\u65b9\u6cd5\u3002", "conclusion": "LLaVA-NeuMT\u4e3a\u591a\u6a21\u6001\u591a\u8bed\u8a00\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5173\u952e\u5c42\u548c\u795e\u7ecf\u5143\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.19096", "pdf": "https://arxiv.org/pdf/2507.19096", "abs": "https://arxiv.org/abs/2507.19096", "authors": ["Jinbo Hou", "Stefanos Bakirtzis", "Kehai Qiu", "Sichong Liao", "Hui Song", "Haonan Hu", "Kezhi Wang", "Jie Zhang"], "title": "iPLAN: Redefining Indoor Wireless Network Planning Through Large Language Models", "categories": ["cs.NI"], "comment": null, "summary": "Efficient indoor wireless network (IWN) planning is crucial for providing\nhigh-quality 5G in-building services. However, traditional meta-heuristic and\nartificial intelligence-based planning methods face significant challenges due\nto the intricate interplay between indoor environments (IEs) and IWN demands.\nIn this article, we present an indoor wireless network Planning with large\nLANguage models (iPLAN) framework, which integrates multi-modal IE\nrepresentations into large language model (LLM)-powered optimizers to improve\nIWN planning. First, we instate the role of LLMs as optimizers, outlining\nembedding techniques for IEs, and introducing two core applications of iPLAN:\n(i) IWN planning based on pre-existing IEs and (ii) joint design of IWN and IE\nfor new wireless-friendly buildings. For the former, we embed essential\ninformation into LLM optimizers by leveraging indoor descriptions,\ndomain-specific knowledge, and performance-driven perception. For the latter,\nwe conceptualize a multi-agent strategy, where intelligent agents\ncollaboratively address key planning sub-tasks in a step-by-step manner while\nensuring optimal trade-offs between the agents. The simulation results\ndemonstrate that iPLAN achieves superior performance in IWN planning tasks and\noptimizes building wireless performance through the joint design of IEs and\nIWNs, exemplifying a paradigm shift in IWN planning.", "AI": {"tldr": "iPLAN\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f18\u5316\u5ba4\u5185\u65e0\u7ebf\u7f51\u7edc\uff08IWN\uff09\u89c4\u5212\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5ba4\u5185\u73af\u5883\uff08IE\uff09\u8868\u793a\u548c\u667a\u80fd\u4ee3\u7406\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c4\u5212\u6548\u7387\u548c\u65e0\u7ebf\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u5ba4\u5185\u65e0\u7ebf\u7f51\u7edc\u89c4\u5212\u65b9\u6cd5\u56e0\u5ba4\u5185\u73af\u5883\u590d\u6742\u6027\u548c\u9700\u6c42\u591a\u6837\u6027\u800c\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faiPLAN\u6846\u67b6\uff0c\u7ed3\u5408LLM\u4f18\u5316\u5668\u548c\u591a\u6a21\u6001IE\u8868\u793a\uff0c\u5b9e\u73b0\u4e24\u79cd\u6838\u5fc3\u5e94\u7528\uff1a\u57fa\u4e8e\u73b0\u6709IE\u7684IWN\u89c4\u5212\u548cIWN\u4e0eIE\u7684\u534f\u540c\u8bbe\u8ba1\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0ciPLAN\u5728\u89c4\u5212\u548c\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u5347\u4e86\u65e0\u7ebf\u6027\u80fd\u3002", "conclusion": "iPLAN\u901a\u8fc7LLM\u548c\u591a\u6a21\u6001\u8868\u793a\uff0c\u4e3aIWN\u89c4\u5212\u5e26\u6765\u4e86\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2507.19008", "pdf": "https://arxiv.org/pdf/2507.19008", "abs": "https://arxiv.org/abs/2507.19008", "authors": ["Grant Jurgensen"], "title": "A Proof of the Schr\u00f6der-Bernstein Theorem in ACL2", "categories": ["cs.LO", "F.4.1"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "The Schr\\\"oder-Bernstein theorem states that, for any two sets P and Q, if\nthere exists an injection from P to Q and an injection from Q to P, then there\nmust exist a bijection between the two sets. Classically, it follows that the\nordering of the cardinal numbers is antisymmetric. We describe a formulation\nand verification of the Schr\\\"oder-Bernstein theorem in ACL2 following a\nwell-known proof, introducing a theory of chains to define a non-computable\nwitness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5728ACL2\u4e2d\u5f62\u5f0f\u5316\u5e76\u9a8c\u8bc1\u4e86Schr\u00f6der-Bernstein\u5b9a\u7406\uff0c\u5f15\u5165\u4e86\u94fe\u7406\u8bba\u6765\u5b9a\u4e49\u975e\u53ef\u8ba1\u7b97\u89c1\u8bc1\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728ACL2\u4e2d\u9a8c\u8bc1Schr\u00f6der-Bernstein\u5b9a\u7406\uff0c\u5c55\u793a\u5176\u7ecf\u5178\u8bc1\u660e\u5728\u5f62\u5f0f\u5316\u903b\u8f91\u4e2d\u7684\u5b9e\u73b0\u3002", "method": "\u91c7\u7528ACL2\u5f62\u5f0f\u5316\u5b9a\u7406\uff0c\u5f15\u5165\u94fe\u7406\u8bba\u5b9a\u4e49\u975e\u53ef\u8ba1\u7b97\u89c1\u8bc1\uff0c\u8ddf\u968f\u7ecf\u5178\u8bc1\u660e\u6b65\u9aa4\u3002", "result": "\u6210\u529f\u5728ACL2\u4e2d\u5f62\u5f0f\u5316\u5e76\u9a8c\u8bc1\u4e86Schr\u00f6der-Bernstein\u5b9a\u7406\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u7ecf\u5178\u6570\u5b66\u5b9a\u7406\u53ef\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5\u5728\u903b\u8f91\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2507.18972", "pdf": "https://arxiv.org/pdf/2507.18972", "abs": "https://arxiv.org/abs/2507.18972", "authors": ["Gromit Yeuk-Yin Chan", "Luis Gustavo Nonato", "Themis Palpanas", "Cl\u00e1udio T. Silva", "Juliana Freire"], "title": "TiVy: Time Series Visual Summary for Scalable Visualization", "categories": ["cs.GR", "cs.LG"], "comment": "to be published in TVCG (IEEE VIS 2025)", "summary": "Visualizing multiple time series presents fundamental tradeoffs between\nscalability and visual clarity. Time series capture the behavior of many\nlarge-scale real-world processes, from stock market trends to urban activities.\nUsers often gain insights by visualizing them as line charts, juxtaposing or\nsuperposing multiple time series to compare them and identify trends and\npatterns. However, existing representations struggle with scalability: when\ncovering long time spans, leading to visual clutter from too many small\nmultiples or overlapping lines. We propose TiVy, a new algorithm that\nsummarizes time series using sequential patterns. It transforms the series into\na set of symbolic sequences based on subsequence visual similarity using\nDynamic Time Warping (DTW), then constructs a disjoint grouping of similar\nsubsequences based on the frequent sequential patterns. The grouping result, a\nvisual summary of time series, provides uncluttered superposition with fewer\nsmall multiples. Unlike common clustering techniques, TiVy extracts similar\nsubsequences (of varying lengths) aligned in time. We also present an\ninteractive time series visualization that renders large-scale time series in\nreal-time. Our experimental evaluation shows that our algorithm (1) extracts\nclear and accurate patterns when visualizing time series data, (2) achieves a\nsignificant speed-up (1000X) compared to a straightforward DTW clustering. We\nalso demonstrate the efficiency of our approach to explore hidden structures in\nmassive time series data in two usage scenarios.", "AI": {"tldr": "TiVy\u662f\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u5316\u4e3a\u7b26\u53f7\u5e8f\u5217\uff0c\u63d0\u53d6\u9891\u7e41\u987a\u5e8f\u6a21\u5f0f\u4ee5\u51cf\u5c11\u89c6\u89c9\u6df7\u4e71\uff0c\u63d0\u9ad8\u53ef\u89c6\u5316\u6e05\u6670\u5ea6\u548c\u901f\u5ea6\u3002", "motivation": "\u591a\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u5728\u53ef\u6269\u5c55\u6027\u548c\u89c6\u89c9\u6e05\u6670\u5ea6\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u957f\u65f6\u95f4\u8de8\u5ea6\u6216\u5927\u91cf\u5e8f\u5217\u5bfc\u81f4\u7684\u89c6\u89c9\u6742\u4e71\u95ee\u9898\u3002", "method": "TiVy\u4f7f\u7528DTW\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u5316\u4e3a\u7b26\u53f7\u5e8f\u5217\uff0c\u63d0\u53d6\u76f8\u4f3c\u5b50\u5e8f\u5217\u7684\u5206\u7ec4\uff0c\u751f\u6210\u53ef\u89c6\u5316\u6458\u8981\u4ee5\u51cf\u5c11\u91cd\u53e0\u548c\u5c0f\u500d\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTiVy\u80fd\u63d0\u53d6\u6e05\u6670\u51c6\u786e\u7684\u6a21\u5f0f\uff0c\u6bd4\u666e\u901aDTW\u805a\u7c7b\u5feb1000\u500d\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u53d1\u73b0\u9690\u85cf\u7ed3\u6784\u3002", "conclusion": "TiVy\u901a\u8fc7\u65b0\u9896\u7684\u5206\u7ec4\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u7684\u53ef\u6269\u5c55\u6027\u548c\u6e05\u6670\u5ea6\u95ee\u9898\u3002"}}
{"id": "2507.18864", "pdf": "https://arxiv.org/pdf/2507.18864", "abs": "https://arxiv.org/abs/2507.18864", "authors": ["Ngoc Hung Nguyen", "Van-Dinh Nguyen", "Anh Tuan Nguyen", "Nguyen Van Thieu", "Hoang Nam Nguyen", "Symeon Chatzinotas"], "title": "Deadline-Aware Joint Task Scheduling and Offloading in Mobile Edge Computing Systems", "categories": ["cs.DC", "cs.CC", "C.2.4; I.2.8"], "comment": "14 pages, 13 figures. Accepted for publication in IEEE Internet of\n  Things Journal (JIOT)", "summary": "The demand for stringent interactive quality-of-service has intensified in\nboth mobile edge computing (MEC) and cloud systems, driven by the imperative to\nimprove user experiences. As a result, the processing of computation-intensive\ntasks in these systems necessitates adherence to specific deadlines or\nachieving extremely low latency. To optimize task scheduling performance,\nexisting research has mainly focused on reducing the number of late jobs whose\ndeadlines are not met. However, the primary challenge with these methods lies\nin the total search time and scheduling efficiency. In this paper, we present\nthe optimal job scheduling algorithm designed to determine the optimal task\norder for a given set of tasks. In addition, users are enabled to make informed\ndecisions for offloading tasks based on the information provided by servers.\nThe details of performance analysis are provided to show its optimality and low\ncomplexity with the linearithmic time O(nlogn), where $n$ is the number of\ntasks. To tackle the uncertainty of the randomly arriving tasks, we further\ndevelop an online approach with fast outage detection that achieves rapid\nacceptance times with time complexity of O(n). Extensive numerical results are\nprovided to demonstrate the effectiveness of the proposed algorithm in terms of\nthe service ratio and scheduling cost.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u65e8\u5728\u63d0\u9ad8\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u548c\u4e91\u7cfb\u7edf\u4e2d\u4efb\u52a1\u8c03\u5ea6\u7684\u6548\u7387\uff0c\u51cf\u5c11\u5ef6\u8fdf\u5e76\u4f18\u5316\u4efb\u52a1\u5378\u8f7d\u51b3\u7b56\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u662f\u4e3a\u4e86\u6ee1\u8db3\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u548c\u4e91\u7cfb\u7edf\u4e2d\u5bf9\u4ea4\u4e92\u8d28\u91cf\u7684\u4e25\u683c\u8981\u6c42\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\uff0c\u5c24\u5176\u662f\u5728\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u7684\u5904\u7406\u4e2d\u9700\u8981\u8fbe\u5230\u4f4e\u5ef6\u8fdf\u6216\u7279\u5b9a\u622a\u6b62\u65f6\u95f4\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6700\u4f18\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u7528\u4e8e\u786e\u5b9a\u4efb\u52a1\u7684\u6700\u4f18\u987a\u5e8f\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u6839\u636e\u670d\u52a1\u5668\u63d0\u4f9b\u7684\u4fe1\u606f\u505a\u51fa\u4efb\u52a1\u5378\u8f7d\u51b3\u7b56\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u4e00\u79cd\u5728\u7ebf\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u968f\u673a\u5230\u8fbe\u7684\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u7b97\u6cd5\u7684\u6700\u4f18\u6027\u548c\u4f4e\u590d\u6742\u5ea6\uff08O(nlogn)\uff09\u901a\u8fc7\u6027\u80fd\u5206\u6790\u5f97\u5230\u9a8c\u8bc1\uff0c\u5728\u7ebf\u65b9\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(n)\u3002\u6570\u503c\u7ed3\u679c\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u670d\u52a1\u6bd4\u4f8b\u548c\u8c03\u5ea6\u6210\u672c\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u7684\u7ed3\u8bba\u662f\u8be5\u7b97\u6cd5\u80fd\u591f\u9ad8\u6548\u4f18\u5316\u4efb\u52a1\u8c03\u5ea6\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u968f\u673a\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.19039", "pdf": "https://arxiv.org/pdf/2507.19039", "abs": "https://arxiv.org/abs/2507.19039", "authors": ["Francesca Cibrario", "Ron Cohen", "Emanuele Dri", "Christian Mattia", "Or Samimi Golan", "Tamuz Danzig", "Giacomo Ranieri", "Hanan Rosemarin", "Davide Corbelletto", "Amir Naveh", "Bartolomeo Montrucchio"], "title": "Autocallable Options Pricing with Integration-Based Exponential Amplitude Loading", "categories": ["quant-ph", "cs.ET", "q-fin.PR"], "comment": "11 pages, to be published in the proceedings of the IEEE\n  International Conference on Quantum Computing and Engineering - QCE25", "summary": "We present a comprehensive quantum algorithm tailored for pricing\nautocallable options, offering a full implementation and experimental\nvalidation. Our experiments include simulations conducted on high-performance\ncomputing (HPC) hardware, along with an empirical analysis of convergence to\nthe classically estimated value. Our key innovation is an improved\nintegration-based exponential amplitude loading technique that reduces circuit\ndepth compared to state-of-the-art approaches. A detailed complexity analysis\nin a relevant setting shows an approximately 50x reduction in T-depth for the\npayoff component relative to previous methods. These contributions represent a\nstep toward more efficient quantum approaches to pricing complex financial\nderivatives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u5b9a\u4ef7\u81ea\u52a8\u8d4e\u56de\u671f\u6743\u8bbe\u8ba1\u7684\u91cf\u5b50\u7b97\u6cd5\uff0c\u5c55\u793a\u4e86\u5b8c\u6574\u5b9e\u73b0\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5305\u62ec\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u786c\u4ef6\u4e0a\u7684\u6a21\u62df\u53ca\u6536\u655b\u6027\u5206\u6790\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u91cf\u5b50\u65b9\u6cd5\u5b9a\u4ef7\u590d\u6742\u91d1\u878d\u884d\u751f\u54c1\u3002", "method": "\u91c7\u7528\u6539\u8fdb\u7684\u57fa\u4e8e\u79ef\u5206\u7684\u6307\u6570\u632f\u5e45\u52a0\u8f7d\u6280\u672f\uff0c\u51cf\u5c11\u7535\u8def\u6df1\u5ea6\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u76f8\u5173\u573a\u666f\u4e2dT\u6df1\u5ea6\u51cf\u5c11\u4e86\u7ea650\u500d\u3002", "conclusion": "\u4e3a\u91cf\u5b50\u65b9\u6cd5\u5728\u91d1\u878d\u884d\u751f\u54c1\u5b9a\u4ef7\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19142", "pdf": "https://arxiv.org/pdf/2507.19142", "abs": "https://arxiv.org/abs/2507.19142", "authors": ["Wei-Hsing Huang", "Janak Sharda", "Cheng-Jhih Shih", "Yuyao Kong", "Faaiq Waqar", "Pin-Jun Chen", "Yingyan", "Lin", "Shimeng Yu"], "title": "A3D-MoE: Acceleration of Large Language Models with Mixture of Experts via 3D Heterogeneous Integration", "categories": ["cs.AR"], "comment": null, "summary": "Conventional large language models (LLMs) are equipped with dozens of GB to\nTB of model parameters, making inference highly energy-intensive and costly as\nall the weights need to be loaded to onboard processing elements during\ncomputation. Recently, the Mixture-of-Experts (MoE) architecture has emerged as\nan efficient alternative, promising efficient inference with less activated\nweights per token. Nevertheless, fine-grained MoE-based LLMs face several\nchallenges: 1) Variable workloads during runtime create arbitrary GEMV-GEMM\nratios that reduce hardware utilization, 2) Traditional MoE-based scheduling\nfor LLM serving cannot fuse attention operations with MoE operations, leading\nto increased latency and decreased hardware utilization, and 3) Despite being\nmore efficient than conventional LLMs, loading experts from DRAM still consumes\nsignificant energy and requires substantial DRAM bandwidth. Addressing these\nchallenges, we propose: 1) A3D-MoE, a 3D Heterogeneous Integration system that\nemploys state-of-the-art vertical integration technology to significantly\nenhance memory bandwidth while reducing Network-on-Chip (NoC) overhead and\nenergy consumption. 2) A 3D-Adaptive GEMV-GEMM-ratio systolic array with\nV-Cache efficient data reuse and a novel unified 3D dataflow to solve the\nproblem of reduced hardware utilization caused by arbitrary GEMV-GEMM ratios\nfrom different workloads, 3) A Hardware resource-aware operation fusion\nscheduler that fuses attention operations with MoE operations to enhance\nhardware performance, and 4) MoE Score-Aware HBM access reduction with even-odd\nexpert placement that reduces DRAM access and bandwidth requirements. Our\nevaluation results indicate that A3D-MoE delivers significant performance\nenhancements, reducing latency by a factor of 1.8x to 2x and energy consumption\nby 2x to 4x, while improving throughput by 1.44x to 1.8x compared to the\nstate-of-the-art.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faA3D-MoE\u7cfb\u7edf\uff0c\u901a\u8fc73D\u5f02\u6784\u96c6\u6210\u6280\u672f\u4f18\u5316Mixture-of-Experts\u67b6\u6784\uff0c\u89e3\u51b3\u786c\u4ef6\u5229\u7528\u7387\u4f4e\u3001\u5ef6\u8fdf\u9ad8\u548c\u80fd\u8017\u5927\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u80fd\u8017\u9ad8\u4e14\u6210\u672c\u5927\uff0c\u800cMoE\u67b6\u6784\u867d\u9ad8\u6548\u4f46\u4ecd\u9762\u4e34\u786c\u4ef6\u5229\u7528\u7387\u4f4e\u3001\u64cd\u4f5c\u65e0\u6cd5\u878d\u5408\u53caDRAM\u8bbf\u95ee\u80fd\u8017\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faA3D-MoE\u7cfb\u7edf\uff0c\u5305\u542b3D\u5f02\u6784\u96c6\u6210\u6280\u672f\u3001\u81ea\u9002\u5e94GEMV-GEMM\u6bd4\u4f8b\u9635\u5217\u3001\u64cd\u4f5c\u878d\u5408\u8c03\u5ea6\u5668\u548cMoE\u5206\u6570\u611f\u77e5HBM\u8bbf\u95ee\u4f18\u5316\u3002", "result": "A3D-MoE\u5c06\u5ef6\u8fdf\u964d\u4f4e1.8x\u81f32x\uff0c\u80fd\u8017\u51cf\u5c112x\u81f34x\uff0c\u541e\u5410\u91cf\u63d0\u53471.44x\u81f31.8x\u3002", "conclusion": "A3D-MoE\u6709\u6548\u89e3\u51b3\u4e86MoE\u67b6\u6784\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u786c\u4ef6\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2507.19254", "pdf": "https://arxiv.org/pdf/2507.19254", "abs": "https://arxiv.org/abs/2507.19254", "authors": ["Zhengtong Yan", "Gongsheng Yuan", "Qingsong Guo", "Jiaheng Lu"], "title": "DBMS-LLM Integration Strategies in Industrial and Business Applications: Current Status and Future Challenges", "categories": ["cs.DB"], "comment": null, "summary": "Modern enterprises are increasingly driven by the DATA+AI paradigm, in which\nDatabase Management Systems (DBMSs) and Large Language Models (LLMs) have\nbecome two foundational infrastructures powering a wide range of industrial and\nbusiness applications, such as enterprise analytics, intelligent customer\nservice, and data-driven decision-making. The efficient integration of DBMSs\nand LLMs within a unified system offers significant opportunities but also\nintroduces new technical challenges. This paper surveys recent developments in\nDBMS+LLM integration and identifies key future challenges. Specifically, we\ncategorize five representative architectural patterns based on their core\ndesign principles, strengths, and trade-offs. Based on this analysis, we\nfurther highlight several critical open challenges. We aim to provide a\nsystematic understanding of the current integration landscape and to outline\nthe unresolved issues that must be addressed to achieve scalable and efficient\nintegration of traditional data management and advanced language reasoning in\nfuture intelligent applications.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86DBMS\u4e0eLLM\u6574\u5408\u7684\u73b0\u72b6\u53ca\u672a\u6765\u6311\u6218\uff0c\u5212\u5206\u4e86\u4e94\u79cd\u67b6\u6784\u6a21\u5f0f\uff0c\u5e76\u6307\u51fa\u5173\u952e\u5f00\u653e\u6027\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u9ad8\u6548\u6574\u5408\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08DBMS\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee5\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u667a\u80fd\u5e94\u7528\u3002", "method": "\u5206\u7c7b\u4e94\u79cd\u4ee3\u8868\u6027\u67b6\u6784\u6a21\u5f0f\uff0c\u5206\u6790\u5176\u8bbe\u8ba1\u539f\u5219\u3001\u4f18\u52bf\u548c\u6743\u8861\u3002", "result": "\u63d0\u51fa\u4e86\u6574\u5408\u4e2d\u7684\u6280\u672f\u6311\u6218\uff0c\u5e76\u8bc6\u522b\u4e86\u672a\u89e3\u51b3\u7684\u5173\u952e\u95ee\u9898\u3002", "conclusion": "\u4e3a\u672a\u6765\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684DBMS\u4e0eLLM\u6574\u5408\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7406\u89e3\u4e0e\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.19027", "pdf": "https://arxiv.org/pdf/2507.19027", "abs": "https://arxiv.org/abs/2507.19027", "authors": ["Aleksi Huotala", "Miikka Kuutila", "Mika M\u00e4ntyl\u00e4"], "title": "SESR-Eval: Dataset for Evaluating LLMs in the Title-Abstract Screening of Systematic Reviews", "categories": ["cs.SE"], "comment": "12 pages (10 + 2 pages for references)", "summary": "Background: The use of large language models (LLMs) in the title-abstract\nscreening process of systematic reviews (SRs) has shown promising results, but\nsuffers from limited performance evaluation. Aims: Create a benchmark dataset\nto evaluate the performance of LLMs in the title-abstract screening process of\nSRs. Provide evidence whether using LLMs in title-abstract screening in\nsoftware engineering is advisable. Method: We start with 169 SR research\nartifacts and find 24 of those to be suitable for inclusion in the dataset.\nUsing the dataset we benchmark title-abstract screening using 9 LLMs. Results:\nWe present the SESR-Eval (Software Engineering Systematic Review Evaluation)\ndataset containing 34,528 labeled primary studies, sourced from 24 secondary\nstudies published in software engineering (SE) journals. Most LLMs performed\nsimilarly and the differences in screening accuracy between secondary studies\nare greater than differences between LLMs. The cost of using an LLM is\nrelatively low - less than $40 per secondary study even for the most expensive\nmodel. Conclusions: Our benchmark enables monitoring AI performance in the\nscreening task of SRs in software engineering. At present, LLMs are not yet\nrecommended for automating the title-abstract screening process, since accuracy\nvaries widely across secondary studies, and no LLM managed a high recall with\nreasonable precision. In future, we plan to investigate factors that influence\nLLM screening performance between studies.", "AI": {"tldr": "\u672c\u6587\u521b\u5efa\u4e86\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6SESR-Eval\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u7efc\u8ff0\u6807\u9898-\u6458\u8981\u7b5b\u9009\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793aLLMs\u7684\u51c6\u786e\u6027\u5728\u4e0d\u540c\u7814\u7a76\u4e2d\u5dee\u5f02\u8f83\u5927\uff0c\u76ee\u524d\u4e0d\u63a8\u8350\u81ea\u52a8\u5316\u4f7f\u7528\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u7cfb\u7edf\u7efc\u8ff0\u6807\u9898-\u6458\u8981\u7b5b\u9009\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u63d0\u4f9b\u662f\u5426\u4f7f\u7528LLMs\u7684\u51b3\u7b56\u4f9d\u636e\u3002", "method": "\u901a\u8fc7\u7b5b\u9009169\u7bc7\u7cfb\u7edf\u7efc\u8ff0\u7814\u7a76\uff0c\u9009\u53d624\u7bc7\u6784\u5efa\u5305\u542b34,528\u4e2a\u6807\u8bb0\u7814\u7a76\u7684SESR-Eval\u6570\u636e\u96c6\uff0c\u5e76\u6d4b\u8bd59\u79cdLLMs\u7684\u6027\u80fd\u3002", "result": "\u4e0d\u540cLLMs\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u7814\u7a76\u95f4\u7684\u51c6\u786e\u6027\u5dee\u5f02\u663e\u8457\uff1bLLMs\u4f7f\u7528\u6210\u672c\u4f4e\uff08\u6bcf\u7bc7\u4f4e\u4e8e$40\uff09\u3002", "conclusion": "\u76ee\u524d\u4e0d\u63a8\u8350\u81ea\u52a8\u5316\u4f7f\u7528LLMs\uff0c\u672a\u6765\u8ba1\u5212\u7814\u7a76\u5f71\u54cdLLMs\u6027\u80fd\u7684\u56e0\u7d20\u3002"}}
{"id": "2507.19176", "pdf": "https://arxiv.org/pdf/2507.19176", "abs": "https://arxiv.org/abs/2507.19176", "authors": ["Weijun Chen", "Yuxi Fu", "Huan Long"], "title": "A Programming Language for Feasible Solutions", "categories": ["cs.PL"], "comment": null, "summary": "Runtime efficiency and termination are crucial properties in the studies of\nprogram verification. Instead of dealing with these issues in an ad hoc manner,\nit would be useful to develop a robust framework in which such properties are\nguaranteed by design. This paper introduces a new imperative programming\nlanguage whose design is grounded in a static type system that ensures the\nfollowing equivalence property: All definable programs are guaranteed to run in\npolynomial time; Conversely, all problems solvable in polynomial time can be\nsolved by some programs of the language. The contribution of this work is\ntwofold. On the theoretical side, the foundational equivalence property is\nestablished, and the proof of the equivalence theorem is non-trivial. On the\npractical side, a programming approach is proposed that can streamline program\nanalysis and verification for feasible computations. An interpreter for the\nlanguage has been implemented, demonstrating the feasibility of the approach in\npractice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u9759\u6001\u7c7b\u578b\u7cfb\u7edf\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u786e\u4fdd\u6240\u6709\u7a0b\u5e8f\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8fd0\u884c\uff0c\u4e14\u6240\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u7684\u95ee\u9898\u5747\u53ef\u7531\u8be5\u8bed\u8a00\u5b9e\u73b0\u3002", "motivation": "\u89e3\u51b3\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u8fd0\u884c\u65f6\u6548\u7387\u548c\u7ec8\u6b62\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4e00\u79cd\u8bed\u8a00\u6846\u67b6\uff0c\u786e\u4fdd\u8fd9\u4e9b\u7279\u6027\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cd\u65b0\u7684\u9759\u6001\u7c7b\u578b\u7cfb\u7edf\u8bed\u8a00\uff0c\u901a\u8fc7\u7c7b\u578b\u4fdd\u8bc1\u7a0b\u5e8f\u7684\u591a\u9879\u5f0f\u8fd0\u884c\u65f6\u95f4\u548c\u7b49\u4ef7\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u7406\u8bba\u4e0a\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u5b9e\u73b0\u4e86\u8bed\u8a00\u7684\u89e3\u91ca\u5668\uff0c\u5c55\u793a\u4e86\u5b9e\u8df5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u8bed\u8a00\u7684\u7b49\u4ef7\u6027\uff0c\u8fd8\u63d0\u51fa\u4e86\u7b80\u5316\u7a0b\u5e8f\u5206\u6790\u548c\u9a8c\u8bc1\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.18640", "pdf": "https://arxiv.org/pdf/2507.18640", "abs": "https://arxiv.org/abs/2507.18640", "authors": ["Thomas Roca", "Anthony Cintron Roman", "Jeh\u00fa Torres Vega", "Marcelo Duarte", "Pengce Wang", "Kevin White", "Amit Misra", "Juan Lavista Ferres"], "title": "How good are humans at detecting AI-generated images? Learnings from an experiment", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": null, "summary": "As AI-powered image generation improves, a key question is how well human\nbeings can differentiate between \"real\" and AI-generated or modified images.\nUsing data collected from the online game \"Real or Not Quiz.\", this study\ninvestigates how effectively people can distinguish AI-generated images from\nreal ones. Participants viewed a randomized set of real and AI-generated\nimages, aiming to identify their authenticity. Analysis of approximately\n287,000 image evaluations by over 12,500 global participants revealed an\noverall success rate of only 62\\%, indicating a modest ability, slightly above\nchance. Participants were most accurate with human portraits but struggled\nsignificantly with natural and urban landscapes. These results highlight the\ninherent challenge humans face in distinguishing AI-generated visual content,\nparticularly images without obvious artifacts or stylistic cues. This study\nstresses the need for transparency tools, such as watermarks and robust AI\ndetection tools to mitigate the risks of misinformation arising from\nAI-generated content", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5728\u7ebf\u6e38\u620f\u6536\u96c6\u6570\u636e\uff0c\u5206\u6790\u4eba\u7c7b\u533a\u5206AI\u751f\u6210\u56fe\u50cf\u4e0e\u771f\u5b9e\u56fe\u50cf\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u6574\u4f53\u6210\u529f\u7387\u4ec562%\uff0c\u8868\u660e\u4eba\u7c7b\u8fa8\u522b\u80fd\u529b\u6709\u9650\uff0c\u5c24\u4ee5\u81ea\u7136\u548c\u57ce\u5e02\u666f\u89c2\u4e3a\u6700\u96be\u3002", "motivation": "\u63a2\u8ba8\u4eba\u7c7b\u5728\u9762\u5bf9AI\u751f\u6210\u56fe\u50cf\u65f6\u7684\u8fa8\u522b\u80fd\u529b\uff0c\u4ee5\u8bc4\u4f30\u6f5c\u5728\u7684 misinformation \u98ce\u9669\u3002", "method": "\u4f7f\u7528\u5728\u7ebf\u6e38\u620f\u6570\u636e\uff0c\u53c2\u4e0e\u8005\u968f\u673a\u67e5\u770b\u771f\u5047\u56fe\u50cf\u5e76\u5224\u65ad\u5176\u771f\u5b9e\u6027\uff0c\u5206\u6790\u5168\u740312500\u540d\u53c2\u4e0e\u8005\u7684287000\u6b21\u8bc4\u4f30\u3002", "result": "\u6574\u4f53\u8fa8\u522b\u6210\u529f\u738762%\uff0c\u4eba\u50cf\u8fa8\u522b\u6700\u51c6\uff0c\u81ea\u7136\u548c\u57ce\u5e02\u666f\u89c2\u8f83\u5dee\u3002", "conclusion": "\u4eba\u7c7b\u533a\u5206AI\u751f\u6210\u56fe\u50cf\u7684\u80fd\u529b\u6709\u9650\uff0c\u9700\u5f00\u53d1\u900f\u660e\u5de5\u5177\uff08\u5982\u6c34\u5370\u548cAI\u68c0\u6d4b\u5de5\u5177\uff09\u4ee5\u5e94\u5bf9\u98ce\u9669\u3002"}}
{"id": "2507.19037", "pdf": "https://arxiv.org/pdf/2507.19037", "abs": "https://arxiv.org/abs/2507.19037", "authors": ["Yiwen Guan", "Viet Anh Trinh", "Vivek Voleti", "Jacob Whitehill"], "title": "MLLM-based Speech Recognition: When and How is Multimodality Beneficial?", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "comment": null, "summary": "Recent advances in multi-modal large language models (MLLMs) have opened new\npossibilities for unified modeling of speech, text, images, and other\nmodalities. Building on our prior work, this paper examines the conditions and\nmodel architectures under which multiple input modalities can improve automatic\nspeech recognition (ASR) accuracy in noisy environments. Through experiments on\nsynthetic and real-world data, we find that (1) harnessing more modalities\nusually improves ASR accuracy, as each modality provides complementary\ninformation, but the improvement depends on the amount of auditory noise. (2)\nSynchronized modalities (e.g., lip movements) are more useful at high noise\nlevels whereas unsynchronized modalities (e.g., image context) are most helpful\nat moderate noise levels. (3) Higher-quality visual representations\nconsistently improve ASR accuracy, highlighting the importance of developing\nmore powerful visual encoders. (4) Mamba exhibits similar trends regarding the\nbenefits of multimodality as do Transformers. (5) The input order of modalities\nas well as their weights in the loss function can significantly impact\naccuracy. These findings both offer practical insights and help to deepen our\nunderstanding of multi-modal speech recognition under challenging conditions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e2d\uff0c\u5229\u7528\u591a\u79cd\u8f93\u5165\u6a21\u6001\u63d0\u5347\u566a\u58f0\u73af\u5883\u4e0b\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u51c6\u786e\u7387\u7684\u6761\u4ef6\u4e0e\u67b6\u6784\u3002", "motivation": "\u65e8\u5728\u63a2\u7d22\u591a\u6a21\u6001\uff08\u5982\u8bed\u97f3\u3001\u6587\u672c\u3001\u56fe\u50cf\uff09\u5982\u4f55\u4e92\u8865\u63d0\u5347ASR\u5728\u566a\u58f0\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u591a\u6a21\u6001\u7684\u8d21\u732e\uff0c\u5e76\u6bd4\u8f83\u540c\u6b65\u4e0e\u975e\u540c\u6b65\u6a21\u6001\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u591a\u6a21\u6001\u901a\u5e38\u80fd\u63d0\u5347ASR\u51c6\u786e\u7387\uff0c\u4f46\u6548\u679c\u53d7\u566a\u58f0\u6c34\u5e73\u5f71\u54cd\uff1b\u9ad8\u8d28\u91cf\u89c6\u89c9\u8868\u793a\u548c\u6a21\u6001\u8f93\u5165\u987a\u5e8f\u5bf9\u7ed3\u679c\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u8bed\u97f3\u8bc6\u522b\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\uff0c\u5e76\u6df1\u5316\u4e86\u5bf9\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u591a\u6a21\u578b\u534f\u540c\u7684\u7406\u89e3\u3002"}}
{"id": "2507.19124", "pdf": "https://arxiv.org/pdf/2507.19124", "abs": "https://arxiv.org/abs/2507.19124", "authors": ["Muhammad Ahmed Mohsin", "Sagnik Bhattacharya", "Abhiram Gorle", "Muhammad Ali Jamshed", "John M. Cioffi"], "title": "AI Enabled 6G for Semantic Metaverse: Prospects, Challenges and Solutions for Future Wireless VR", "categories": ["cs.NI"], "comment": "IEEE Wireless Communications Magazine", "summary": "Wireless support of virtual reality (VR) has challenges when a network has\nmultiple users, particularly for 3D VR gaming, digital AI avatars, and remote\nteam collaboration. This work addresses these challenges through investigation\nof the low-rank channels that inevitably occur when there are more active users\nthan there are degrees of spatial freedom, effectively often the number of\nantennas. The presented approach uses optimal nonlinear transceivers,\nequivalently generalized decision-feedback or successive cancellation for\nuplink and superposition or dirty-paper precoders for downlink. Additionally, a\npowerful optimization approach for the users' energy allocation and decoding\norder appears to provide large improvements over existing methods, effectively\nnearing theoretical optima. As the latter optimization methods pose real-time\nchallenges, approximations using deep reinforcement learning (DRL) are used to\napproximate best performance with much lower (5x at least) complexity.\nExperimental results show significantly larger sum rates and very large power\nsavings to attain the data rates found necessary to support VR. Experimental\nresults show the proposed algorithm outperforms current industry standards like\northogonal multiple access (OMA), non-orthogonal multiple access (NOMA), as\nwell as the highly researched methods in multi-carrier NOMA (MC-NOMA),\nenhancing sum data rate by 39%, 28%, and 16%, respectively, at a given power\nlevel. For the same data rate, it achieves power savings of 75%, 45%, and 40%,\nmaking it ideal for VR applications. Additionally, a near-optimal deep\nreinforcement learning (DRL)-based resource allocation framework for real-time\nuse by being 5x faster and reaching 83% of the global optimum is introduced.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u7528\u6237\u65e0\u7ebfVR\u901a\u4fe1\u7684\u4f4e\u79e9\u4fe1\u9053\u4f18\u5316\u65b9\u6cd5\uff0c\u91c7\u7528\u975e\u7ebf\u6027\u6536\u53d1\u5668\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u8fd1\u4f3c\u6700\u4f18\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u7387\u548c\u80fd\u6548\u3002", "motivation": "\u89e3\u51b3\u591a\u7528\u6237\u65e0\u7ebfVR\u901a\u4fe1\u4e2d\u56e0\u4f4e\u79e9\u4fe1\u9053\u5bfc\u81f4\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6700\u4f18\u975e\u7ebf\u6027\u6536\u53d1\u5668\uff08\u5982\u5e7f\u4e49\u51b3\u7b56\u53cd\u9988\u6216\u8fde\u7eed\u53d6\u6d88\u4e0a\u884c\u94fe\u8def\u3001\u810f\u7eb8\u9884\u7f16\u7801\u4e0b\u884c\u94fe\u8def\uff09\uff0c\u5e76\u7ed3\u5408DRL\u4f18\u5316\u7528\u6237\u80fd\u91cf\u5206\u914d\u548c\u89e3\u7801\u987a\u5e8f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4OMA\u3001NOMA\u548cMC-NOMA\uff0c\u6570\u636e\u7387\u5206\u522b\u63d0\u534739%\u300128%\u548c16%\uff0c\u80fd\u6548\u63d0\u534775%\u300145%\u548c40%\u3002DRL\u6846\u67b6\u590d\u6742\u5ea6\u964d\u4f4e5\u500d\uff0c\u63a5\u8fd1\u5168\u5c40\u6700\u4f18\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65e0\u7ebfVR\u901a\u4fe1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u5b9e\u65f6\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2507.19009", "pdf": "https://arxiv.org/pdf/2507.19009", "abs": "https://arxiv.org/abs/2507.19009", "authors": ["Carl Kwan"], "title": "RV32I in ACL2", "categories": ["cs.LO"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We present a simple ACL2 simulator for the RISC-V 32-bit base instruction set\narchitecture, written in the operational semantics style. Like many other ISA\nmodels, our RISC-V state object is a single-threaded object and we prove\nread-over-write, write-over-write, writing-the-read, and state well-formedness\ntheorems. Unlike some other models, we separate the instruction decoding\nfunctions from their semantic counterparts. Accordingly, we verify encoding /\ndecoding functions for each RV32I instruction, the proofs for which are\nentirely automatic.", "AI": {"tldr": "\u4e00\u4e2a\u7b80\u5355\u7684ACL2\u6a21\u62df\u5668\uff0c\u7528\u4e8eRISC-V 32\u4f4d\u57fa\u672c\u6307\u4ee4\u96c6\u67b6\u6784\uff0c\u91c7\u7528\u64cd\u4f5c\u8bed\u4e49\u98ce\u683c\u7f16\u5199\uff0c\u9a8c\u8bc1\u4e86\u591a\u9879\u72b6\u6001\u5b9a\u7406\u3002", "motivation": "\u63d0\u4f9b\u4e00\u79cd\u7b80\u5355\u4e14\u9a8c\u8bc1\u5145\u5206\u7684RISC-V ISA\u6a21\u578b\uff0c\u4fbf\u4e8e\u8fdb\u4e00\u6b65\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u548c\u7814\u7a76\u3002", "method": "\u91c7\u7528\u64cd\u4f5c\u8bed\u4e49\u98ce\u683c\u7f16\u5199\u6a21\u62df\u5668\uff0c\u5206\u79bb\u6307\u4ee4\u89e3\u7801\u548c\u8bed\u4e49\u5b9e\u73b0\uff0c\u5e76\u81ea\u52a8\u9a8c\u8bc1\u7f16\u7801/\u89e3\u7801\u529f\u80fd\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86\u8bfb\u53d6-\u5199\u5165\u3001\u72b6\u6001\u826f\u597d\u6027\u7b49\u5b9a\u7406\uff0c\u5e76\u81ea\u52a8\u5b8c\u6210\u4e86RV32I\u6307\u4ee4\u96c6\u7684\u7f16\u7801/\u89e3\u7801\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3aRISC-V\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u57fa\u7840\uff0c\u4e14\u5177\u6709\u81ea\u52a8\u5316\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.18928", "pdf": "https://arxiv.org/pdf/2507.18928", "abs": "https://arxiv.org/abs/2507.18928", "authors": ["Yufang Li", "Yuanbo Zhang", "Hanlong Liao", "Guoming Tang", "Deke Guo"], "title": "GPUnion: Autonomous GPU Sharing on Campus", "categories": ["cs.DC", "C.2.4; C.2.1"], "comment": "7 pages, 3 figures, 1 table. Submitted to the ACM Workshop on Hot\n  Topics in Networks (HOTNETS) 2025", "summary": "A pronounced imbalance in GPU resources exists on campus, where some\nlaboratories own underutilized servers while others lack the compute needed for\nAI research. GPU sharing can alleviate this disparity, while existing platforms\ntypically rely on centralized oversight and persistent allocation models,\nconflicting with the voluntary and autonomous nature of academic resource\nownership. We present GPUnion, a campus-scale GPU sharing platform enabling\nvoluntary participation while preserving full provider autonomy. GPUnion\nincorporates three core mechanisms: i) container-based task dispatching and\nexecution, ii) resource provider-first architecture, and iii) resilient\nexecution featuring automatic checkpointing and migration. GPUnion also\nsupports custom data storage and integrates the non-root execution and image\nattestation for isolation and security improvement for containerization. Case\nstudies across multiple campus scenarios demonstrate 30% more GPU utilization\nimprovement, 40% increase in interactive sessions, and 94% successful workload\nmigration during provider departures. GPUnion demonstrates that provider\nautonomy and platform reliability can coexist, challenging conventional\ncentralized paradigms and democratizing access to computational resources\nwithin campus networks.", "AI": {"tldr": "GPUnion\u662f\u4e00\u4e2a\u6821\u56ed\u7ea7GPU\u8d44\u6e90\u5171\u4eab\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u613f\u53c2\u4e0e\u548c\u4fdd\u7559\u63d0\u4f9b\u8005\u81ea\u4e3b\u6743\u7684\u65b9\u5f0f\uff0c\u63d0\u5347\u4e86GPU\u5229\u7528\u7387\u5e76\u89e3\u51b3\u4e86\u8d44\u6e90\u5206\u914d\u4e0d\u5747\u7684\u95ee\u9898\u3002", "motivation": "\u6821\u56ed\u5185GPU\u8d44\u6e90\u5206\u914d\u4e0d\u5747\uff0c\u90e8\u5206\u5b9e\u9a8c\u5ba4\u670d\u52a1\u5668\u4f7f\u7528\u4e0d\u8db3\uff0c\u800c\u5176\u4ed6\u5b9e\u9a8c\u5ba4\u5219\u7f3a\u4e4fAI\u7814\u7a76\u6240\u9700\u7b97\u529b\uff0c\u9700\u8981\u4e00\u4e2a\u65e2\u80fd\u5171\u4eab\u8d44\u6e90\u53c8\u80fd\u5c0a\u91cd\u5b66\u672f\u81ea\u4e3b\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "GPUnion\u91c7\u7528\u5bb9\u5668\u5316\u4efb\u52a1\u8c03\u5ea6\u4e0e\u6267\u884c\u3001\u8d44\u6e90\u63d0\u4f9b\u8005\u4f18\u5148\u67b6\u6784\u4ee5\u53ca\u652f\u6301\u81ea\u52a8\u68c0\u67e5\u70b9\u8fc1\u79fb\u7684\u5f39\u6027\u6267\u884c\u673a\u5236\uff0c\u540c\u65f6\u6574\u5408\u4e86\u975eroot\u6267\u884c\u548c\u955c\u50cf\u8ba4\u8bc1\u4ee5\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cGPUnion\u4f7fGPU\u5229\u7528\u7387\u63d0\u9ad830%\uff0c\u4ea4\u4e92\u4f1a\u8bdd\u589e\u52a040%\uff0c\u5e76\u5728\u63d0\u4f9b\u8005\u9000\u51fa\u65f6\u5b9e\u73b0\u4e8694%\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6210\u529f\u8fc1\u79fb\u3002", "conclusion": "GPUnion\u8bc1\u660e\u4e86\u63d0\u4f9b\u8005\u81ea\u4e3b\u6743\u4e0e\u5e73\u53f0\u53ef\u9760\u6027\u53ef\u4ee5\u5171\u5b58\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u96c6\u4e2d\u5f0f\u8d44\u6e90\u7ba1\u7406\u8303\u5f0f\uff0c\u63a8\u52a8\u4e86\u6821\u56ed\u8ba1\u7b97\u8d44\u6e90\u7684\u6c11\u4e3b\u5316\u8bbf\u95ee\u3002"}}
{"id": "2507.19206", "pdf": "https://arxiv.org/pdf/2507.19206", "abs": "https://arxiv.org/abs/2507.19206", "authors": ["Davide Veronelli", "Francesca Cibrario", "Emanuele Dri", "Valeria Zaffaroni", "Giacomo Ranieri", "Davide Corbelletto", "Bartolomeo Montrucchio"], "title": "Implementing Credit Risk Analysis with Quantum Singular Value Transformation", "categories": ["quant-ph", "cs.ET", "q-fin.RM"], "comment": "10 pages, to be published in the proceedings of the IEEE\n  International Conference on Quantum Computing and Engineering - QCE25", "summary": "The analysis of credit risk is crucial for the efficient operation of\nfinancial institutions. Quantum Amplitude Estimation (QAE) offers the potential\nfor a quadratic speed-up over classical methods used to estimate metrics such\nas Value at Risk (VaR) and Conditional Value at Risk (CVaR). However, numerous\nlimitations remain in efficiently scaling the implementation of quantum\ncircuits that solve these estimation problems. One of the main challenges is\nthe use of costly and restrictive arithmetic that must be implemented within\nthe quantum circuit. In this paper, we propose using Quantum Singular Value\nTransformation (QSVT) to significantly reduce the cost of implementing the\nstate preparation operator, which underlies QAE for credit risk analysis. We\nalso present an end-to-end code implementation and the results of a simulation\nstudy to validate the proposed approach and demonstrate its benefits.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5229\u7528\u91cf\u5b50\u5947\u5f02\u503c\u53d8\u6362\uff08QSVT\uff09\u964d\u4f4e\u4fe1\u7528\u98ce\u9669\u5206\u6790\u4e2d\u91cf\u5b50\u632f\u5e45\u4f30\u8ba1\uff08QAE\uff09\u7684\u5b9e\u73b0\u6210\u672c\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4fe1\u7528\u98ce\u9669\u5206\u6790\u5bf9\u91d1\u878d\u673a\u6784\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u91cf\u5b50\u7535\u8def\u5728\u5b9e\u73b0\u6548\u7387\u4e0a\u5b58\u5728\u9650\u5236\uff0c\u5c24\u5176\u662f\u9ad8\u6602\u7684\u7b97\u672f\u8fd0\u7b97\u6210\u672c\u3002", "method": "\u91c7\u7528\u91cf\u5b50\u5947\u5f02\u503c\u53d8\u6362\uff08QSVT\uff09\u4f18\u5316\u72b6\u6001\u51c6\u5907\u7b97\u5b50\u7684\u5b9e\u73b0\u6210\u672c\uff0c\u5e76\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u4ee3\u7801\u5b9e\u73b0\u548c\u6a21\u62df\u7814\u7a76\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u964d\u4f4eQAE\u7684\u5b9e\u73b0\u6210\u672c\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684QSVT\u65b9\u6cd5\u4e3a\u4fe1\u7528\u98ce\u9669\u5206\u6790\u4e2d\u7684\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18989", "pdf": "https://arxiv.org/pdf/2507.18989", "abs": "https://arxiv.org/abs/2507.18989", "authors": ["Maxence Bouvier", "Ryan Amaudruz", "Felix Arnold", "Renzo Andri", "Lukas Cavigelli"], "title": "GENIAL: Generative Design Space Exploration via Network Inversion for Low Power Algorithmic Logic Units", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "Under review", "summary": "As AI workloads proliferate, optimizing arithmetic units is becoming\nincreasingly important to reduce the footprint of digital systems. Conventional\ndesign flows, which often rely on manual or heuristics-based optimization, are\nlimited in their ability to thoroughly explore the vast design space. In this\npaper, we introduce GENIAL, a machine learning-based framework for the\nautomatic generation and optimization of arithmetic units, more specifically\nmultipliers.\n  At the core of GENIAL is a Transformer-based surrogate model trained in two\nstages, involving self-supervised pretraining followed by supervised\nfinetuning, to robustly forecast key hardware metrics such as power and area\nfrom abstracted design representations. By inverting the surrogate model,\nGENIAL efficiently searches for new operand encodings that directly minimize\npower consumption in arithmetic units for specific input data distributions.\nExtensive experiments on large datasets demonstrate that GENIAL is consistently\nmore sample efficient than other methods, and converges faster towards\noptimized designs. This enables to deploy a high-effort logic synthesis\noptimization flow in the loop, improving the accuracy of the surrogate model.\nNotably, GENIAL automatically discovers encodings that achieve up to 18%\nswitching activity savings within multipliers on representative AI workloads\ncompared with the conventional two's complement. We also demonstrate the\nversatility of our approach by achieving significant improvements on Finite\nState Machines, highlighting GENIAL's applicability for a wide spectrum of\nlogic functions. Together, these advances mark a significant step toward\nautomated Quality-of-Results-optimized combinational circuit generation for\ndigital systems.", "AI": {"tldr": "GENIAL\u662f\u4e00\u4e2a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u7b97\u672f\u5355\u5143\uff08\u5982\u4e58\u6cd5\u5668\uff09\u3002\u901a\u8fc7Transformer\u4ee3\u7406\u6a21\u578b\uff0c\u5b83\u9ad8\u6548\u641c\u7d22\u6700\u5c0f\u5316\u529f\u8017\u7684\u7f16\u7801\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6837\u672c\u6548\u7387\u548c\u4f18\u5316\u80fd\u529b\u3002", "motivation": "\u968f\u7740AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u589e\u52a0\uff0c\u4f20\u7edf\u624b\u52a8\u6216\u542f\u53d1\u5f0f\u4f18\u5316\u65b9\u6cd5\u5728\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0cGENIAL\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u4f18\u5316\u63d0\u5347\u7b97\u672f\u5355\u5143\u7684\u6027\u80fd\u3002", "method": "GENIAL\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7684Transformer\u4ee3\u7406\u6a21\u578b\uff08\u81ea\u76d1\u7763\u9884\u8bad\u7ec3+\u6709\u76d1\u7763\u5fae\u8c03\uff09\uff0c\u901a\u8fc7\u53cd\u8f6c\u6a21\u578b\u9ad8\u6548\u641c\u7d22\u4f18\u5316\u7684\u64cd\u4f5c\u6570\u7f16\u7801\u3002", "result": "\u5b9e\u9a8c\u663e\u793aGENIAL\u6837\u672c\u6548\u7387\u9ad8\uff0c\u4e14\u80fd\u53d1\u73b0\u6bd4\u4f20\u7edf\u7f16\u7801\u8282\u770118%\u5f00\u5173\u6d3b\u52a8\u7684\u7f16\u7801\uff0c\u540c\u65f6\u5728\u6709\u9650\u72b6\u6001\u673a\u4e0a\u4e5f\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "GENIAL\u4e3a\u7ec4\u5408\u7535\u8def\u81ea\u52a8\u5316\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u5c55\u73b0\u51fa\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.19329", "pdf": "https://arxiv.org/pdf/2507.19329", "abs": "https://arxiv.org/abs/2507.19329", "authors": ["Fernando Orejas", "Elvira Pino", "Renzo Angles", "E. Pasarella", "Nikos Milonakis"], "title": "Properties for Paths in Graph Databases", "categories": ["cs.DB"], "comment": null, "summary": "This paper presents a formalism for defining properties of paths in graph\ndatabases, which can be used to restrict the number of solutions to\nnavigational queries. In particular, our formalism allows us to define\nquantitative properties such as length or accumulated cost, which can be used\nas query filters. Furthermore, it enables the identification and removal of\npaths that may be considered ill-formed.\n  The new formalism is defined in terms of an operational semantics for the\nquery language that incorporates these new constructs, demonstrating its\nsoundness and completeness by proving its compatibility with a simple logical\nsemantics. We also analyze its expressive power, showing that path properties\nare more expressive than register automata. Finally, after discussing some\ncomplexity issues related to this new approach, we present an empirical\nanalysis carried out using our prototype implementation of the graph database\nthat serves as a running example throughout the paper. The results show that\nqueries using path properties as filters outperform standard queries that do\nnot use them.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5b9a\u4e49\u56fe\u6570\u636e\u5e93\u4e2d\u8def\u5f84\u5c5e\u6027\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u9650\u5236\u5bfc\u822a\u67e5\u8be2\u7684\u89e3\u6570\u91cf\uff0c\u5e76\u652f\u6301\u5b9a\u91cf\u5c5e\u6027\u7684\u5b9a\u4e49\u548c\u4e0d\u826f\u8def\u5f84\u7684\u8bc6\u522b\u4e0e\u79fb\u9664\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u65b9\u6cd5\u5728\u8def\u5f84\u7b5b\u9009\u548c\u5b9a\u91cf\u5c5e\u6027\u652f\u6301\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6709\u6548\u9650\u5236\u67e5\u8be2\u7ed3\u679c\u6216\u5904\u7406\u4e0d\u826f\u8def\u5f84\u3002", "method": "\u901a\u8fc7\u64cd\u4f5c\u8bed\u4e49\u5b9a\u4e49\u65b0\u7684\u67e5\u8be2\u8bed\u8a00\u6784\u9020\uff0c\u5e76\u8bc1\u660e\u5176\u4e0e\u903b\u8f91\u8bed\u4e49\u7684\u517c\u5bb9\u6027\uff0c\u5206\u6790\u5176\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u5b9e\u73b0\u539f\u578b\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u8def\u5f84\u5c5e\u6027\u6bd4\u5bc4\u5b58\u5668\u81ea\u52a8\u673a\u66f4\u5f3a\u5927\uff0c\u4e14\u5728\u67e5\u8be2\u6027\u80fd\u4e0a\u4f18\u4e8e\u4e0d\u4f7f\u7528\u8def\u5f84\u5c5e\u6027\u7684\u6807\u51c6\u67e5\u8be2\u3002", "conclusion": "\u65b0\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0d\u4ec5\u589e\u5f3a\u4e86\u67e5\u8be2\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8fd8\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e3a\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2507.19113", "pdf": "https://arxiv.org/pdf/2507.19113", "abs": "https://arxiv.org/abs/2507.19113", "authors": ["Liliana Pasquale", "Azzurra Ragone", "Emanuele Piemontese", "Armin Amiri Darban"], "title": "Exploring the Use of LLMs for Requirements Specification in an IT Consulting Company", "categories": ["cs.SE"], "comment": "11 pages, 5 figures. Accepted for presentation at the Industrial\n  Innovation Track of the 33rd IEEE International Requirements Engineering\n  Conference (RE 2025), Valencia, Spain", "summary": "In practice, requirements specification remains a critical challenge. The\nknowledge necessary to generate a specification can often be fragmented across\ndiverse sources (e.g., meeting minutes, emails, and high-level product\ndescriptions), making the process cumbersome and time-consuming. In this paper,\nwe report our experience using large language models (LLMs) in an IT consulting\ncompany to automate the requirements specification process. In this company,\nrequirements are specified using a Functional Design Specification (FDS), a\ndocument that outlines the functional requirements and features of a system,\napplication, or process. We provide LLMs with a summary of the requirements\nelicitation documents and FDS templates, prompting them to generate Epic FDS\n(including high-level product descriptions) and user stories, which are\nsubsequently compiled into a complete FDS document. We compared the correctness\nand quality of the FDS generated by three state-of-the-art LLMs against those\nproduced by human analysts. Our results show that LLMs can help automate and\nstandardize the requirements specification, reducing time and human effort.\nHowever, the quality of LLM-generated FDS highly depends on inputs and often\nrequires human revision. Thus, we advocate for a synergistic approach in which\nan LLM serves as an effective drafting tool while human analysts provide the\ncritical contextual and technical oversight necessary for high-quality\nrequirements engineering (RE) documentation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u9700\u6c42\u89c4\u8303\u751f\u6210\u7684\u8fc7\u7a0b\uff0c\u5bf9\u6bd4\u4e86LLM\u4e0e\u4eba\u7c7b\u5206\u6790\u5e08\u751f\u6210\u7684\u6587\u6863\u8d28\u91cf\uff0c\u63d0\u5021LLM\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u4e0e\u4eba\u7c7b\u534f\u540c\u5de5\u4f5c\u3002", "motivation": "\u9700\u6c42\u89c4\u8303\u5728\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u9762\u4e34\u77e5\u8bc6\u5206\u6563\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u8017\u529b\u3002", "method": "\u4f7f\u7528LLM\u57fa\u4e8e\u9700\u6c42\u6587\u6863\u548c\u6a21\u677f\u81ea\u52a8\u751f\u6210\u529f\u80fd\u8bbe\u8ba1\u89c4\u8303\uff08FDS\uff09\uff0c\u5e76\u4e0e\u4eba\u7c7b\u5206\u6790\u5e08\u7684\u7ed3\u679c\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "LLM\u80fd\u51cf\u5c11\u65f6\u95f4\u548c\u4eba\u529b\uff0c\u4f46\u751f\u6210\u8d28\u91cf\u4f9d\u8d56\u8f93\u5165\u4e14\u9700\u4eba\u5de5\u4fee\u8ba2\u3002", "conclusion": "\u5efa\u8baeLLM\u4f5c\u4e3a\u8d77\u8349\u5de5\u5177\uff0c\u7ed3\u5408\u4eba\u7c7b\u5206\u6790\u5e08\u7684\u76d1\u7763\u4ee5\u63d0\u9ad8\u9700\u6c42\u5de5\u7a0b\u6587\u6863\u8d28\u91cf\u3002"}}
{"id": "2507.18641", "pdf": "https://arxiv.org/pdf/2507.18641", "abs": "https://arxiv.org/abs/2507.18641", "authors": ["U\u011fur \u00d6nal", "Sanem Sariel", "Metin Sezgin", "Ergun Akleman"], "title": "Comparing Human and AI Performance in Visual Storytelling through Creation of Comic Strips: A Case Study", "categories": ["cs.HC", "cs.CY"], "comment": "This paper is accepted to be presented in Digital Humanities\n  Conference 2025, and it will also appear in their proceedings", "summary": "This article presents a case study comparing the capabilities of humans and\nartificial intelligence (AI) for visual storytelling. We developed detailed\ninstructions to recreate a three-panel Nancy cartoon strip by Ernie Bushmiller\nand provided them to both humans and AI systems. The human participants were\n20-something students with basic artistic training but no experience or\nknowledge of this comic strip. The AI systems used were popular commercial\nmodels trained to draw and paint like artists, though their training sets may\nnot necessarily include Bushmiller's work. Results showed that AI systems excel\nat mimicking professional art but struggle to create coherent visual stories.\nIn contrast, humans proved highly adept at transforming instructions into\nmeaningful visual narratives.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u5728\u89c6\u89c9\u53d9\u4e8b\u4e0a\u7684\u80fd\u529b\uff0c\u53d1\u73b0AI\u64c5\u957f\u6a21\u4eff\u827a\u672f\u4f46\u7f3a\u4e4f\u53d9\u4e8b\u8fde\u8d2f\u6027\uff0c\u800c\u4eba\u7c7b\u80fd\u66f4\u6709\u6548\u5730\u5c06\u6307\u4ee4\u8f6c\u5316\u4e3a\u6709\u610f\u4e49\u7684\u89c6\u89c9\u6545\u4e8b\u3002", "motivation": "\u63a2\u7a76\u4eba\u7c7b\u4e0eAI\u5728\u89c6\u89c9\u53d9\u4e8b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u63ed\u793aAI\u5728\u827a\u672f\u521b\u4f5c\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u8ba9\u4eba\u7c7b\u548cAI\u6839\u636e\u76f8\u540c\u6307\u4ee4\u91cd\u7ed8Nancy\u5361\u901a\u6f2b\u753b\uff0c\u6bd4\u8f83\u4e24\u8005\u7684\u8868\u73b0\u3002", "result": "AI\u80fd\u6a21\u4eff\u4e13\u4e1a\u827a\u672f\u4f46\u53d9\u4e8b\u4e0d\u8fde\u8d2f\uff0c\u4eba\u7c7b\u5219\u80fd\u6709\u6548\u6784\u5efa\u89c6\u89c9\u53d9\u4e8b\u3002", "conclusion": "\u4eba\u7c7b\u5728\u89c6\u89c9\u53d9\u4e8b\u4e2d\u8868\u73b0\u4f18\u4e8eAI\uff0cAI\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u53d9\u4e8b\u80fd\u529b\u3002"}}
{"id": "2507.19092", "pdf": "https://arxiv.org/pdf/2507.19092", "abs": "https://arxiv.org/abs/2507.19092", "authors": ["Octavian M. Machidon", "Alina L. Machidon"], "title": "Comparing OCR Pipelines for Folkloristic Text Digitization", "categories": ["cs.DL", "cs.MM"], "comment": null, "summary": "The digitization of historical folkloristic materials presents unique\nchallenges due to diverse text layouts, varying print and handwriting styles,\nand linguistic variations. This study explores different optical character\nrecognition (OCR) approaches for Slovene folkloristic and historical text\ndigitization, integrating both traditional methods and large language models\n(LLMs) to improve text transcription accuracy while maintaining linguistic and\nstructural integrity. We compare single-stage OCR techniques with multi-stage\npipelines that incorporate machine learning-driven post-processing for text\nnormalization and layout reconstruction. While LLM-enhanced methods show\npromise in refining recognition outputs and improving readability, they also\nintroduce challenges related to unintended modifications, particularly in the\npreservation of dialectal expressions and historical structures. Our findings\nprovide insights into selecting optimal digitization strategies for large-scale\nfolklore archives and outline recommendations for developing robust OCR\npipelines that balance automation with the need for textual authenticity in\ndigital humanities research.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u9488\u5bf9\u65af\u6d1b\u6587\u5c3c\u4e9a\u6c11\u4fd7\u548c\u5386\u53f2\u6587\u672c\u7684\u6570\u5b57\u5316\u7684\u4e0d\u540cOCR\u65b9\u6cd5\uff0c\u7ed3\u5408\u4f20\u7edf\u6280\u672f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee5\u63d0\u9ad8\u8f6c\u5f55\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u8a00\u548c\u7ed3\u6784\u7684\u5b8c\u6574\u6027\u3002", "motivation": "\u6570\u5b57\u5316\u5386\u53f2\u6c11\u4fd7\u6750\u6599\u9762\u4e34\u591a\u6837\u5316\u7684\u6587\u672c\u5e03\u5c40\u3001\u5370\u5237\u548c\u624b\u5199\u98ce\u683c\u53ca\u8bed\u8a00\u53d8\u4f53\u7684\u72ec\u7279\u6311\u6218\uff0c\u9700\u8981\u6539\u8fdbOCR\u6280\u672f\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u6bd4\u8f83\u4e86\u5355\u9636\u6bb5OCR\u6280\u672f\u548c\u591a\u9636\u6bb5\u7ba1\u9053\uff0c\u540e\u8005\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u540e\u5904\u7406\u4ee5\u5b9e\u73b0\u6587\u672c\u89c4\u8303\u5316\u548c\u5e03\u5c40\u91cd\u5efa\uff0c\u5e76\u91c7\u7528LLM\u4f18\u5316\u8bc6\u522b\u7ed3\u679c\u3002", "result": "LLM\u589e\u5f3a\u7684\u65b9\u6cd5\u5728\u4f18\u5316\u8bc6\u522b\u7ed3\u679c\u548c\u63d0\u9ad8\u53ef\u8bfb\u6027\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u5bf9\u65b9\u8a00\u8868\u8fbe\u548c\u5386\u53f2\u7ed3\u6784\u4fdd\u5b58\u7684\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5927\u89c4\u6a21\u6c11\u4fd7\u6863\u6848\u7684\u6570\u5b57\u7b56\u7565\u9009\u62e9\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u5e76\u5efa\u8bae\u5f00\u53d1\u5e73\u8861\u81ea\u52a8\u5316\u548c\u6587\u672c\u771f\u5b9e\u6027\u7684OCR\u7ba1\u9053\u3002"}}
{"id": "2507.19234", "pdf": "https://arxiv.org/pdf/2507.19234", "abs": "https://arxiv.org/abs/2507.19234", "authors": ["Tianfu Wang", "Liwei Deng", "Xi Chen", "Junyang Wang", "Huiguo He", "Leilei Ding", "Wei Wu", "Qilin Fan", "Hui Xiong"], "title": "Virne: A Comprehensive Benchmark for Deep RL-based Network Resource Allocation in NFV", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "Resource allocation (RA) is critical to efficient service deployment in\nNetwork Function Virtualization (NFV), a transformative networking paradigm.\nRecently, deep Reinforcement Learning (RL)-based methods have been showing\npromising potential to address this complexity. However, the lack of a\nsystematic benchmarking framework and thorough analysis hinders the exploration\nof emerging networks and the development of more robust algorithms while\ncausing inconsistent evaluation. In this paper, we introduce Virne, a\ncomprehensive benchmarking framework for the NFV-RA problem, with a focus on\nsupporting deep RL-based methods. Virne provides customizable simulations for\ndiverse network scenarios, including cloud, edge, and 5G environments. It also\nfeatures a modular and extensible implementation pipeline that supports over 30\nmethods of various types, and includes practical evaluation perspectives beyond\neffectiveness, such as scalability, generalization, and scalability.\nFurthermore, we conduct in-depth analysis through extensive experiments to\nprovide valuable insights into performance trade-offs for efficient\nimplementation and offer actionable guidance for future research directions.\nOverall, with its diverse simulations, rich implementations, and extensive\nevaluation capabilities, Virne could serve as a comprehensive benchmark for\nadvancing NFV-RA methods and deep RL applications. The code is publicly\navailable at https://github.com/GeminiLight/virne.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Virne\uff0c\u4e00\u4e2a\u9488\u5bf9NFV\u8d44\u6e90\u5206\u914d\u95ee\u9898\u7684\u5168\u9762\u57fa\u51c6\u6846\u67b6\uff0c\u652f\u6301\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7f51\u7edc\u6a21\u62df\u3001\u6a21\u5757\u5316\u5b9e\u73b0\u548c\u5e7f\u6cdb\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "NFV\u8d44\u6e90\u5206\u914d\u7684\u590d\u6742\u6027\u9700\u8981\u7cfb\u7edf\u5316\u57fa\u51c6\u6846\u67b6\u6765\u652f\u6301\u6df1\u5ea6RL\u65b9\u6cd5\u7684\u5f00\u53d1\u548c\u4e00\u81f4\u8bc4\u4f30\u3002", "method": "Virne\u6846\u67b6\u63d0\u4f9b\u53ef\u5b9a\u5236\u7684\u7f51\u7edc\u6a21\u62df\u73af\u5883\uff08\u5982\u4e91\u3001\u8fb9\u7f18\u30015G\uff09\uff0c\u652f\u630130\u591a\u79cd\u65b9\u6cd5\uff0c\u5305\u542b\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u7684\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u6df1\u5165\u5206\u6790\u6027\u80fd\u6743\u8861\uff0c\u4e3a\u9ad8\u6548\u5b9e\u73b0\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "Virne\u4f5c\u4e3a\u5168\u9762\u57fa\u51c6\uff0c\u6709\u671b\u63a8\u52a8NFV\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\u548c\u6df1\u5ea6RL\u5e94\u7528\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.19010", "pdf": "https://arxiv.org/pdf/2507.19010", "abs": "https://arxiv.org/abs/2507.19010", "authors": ["Mayank Manjrekar"], "title": "On Automating Proofs of Multiplier Adder Trees using the RTL Books", "categories": ["cs.LO", "cs.SC"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We present an experimental, verified clause processor ctv-cp that fits into\nthe framework used at Arm for formal verification of arithmetic hardware\ndesigns. This largely automates the ACL2 proof development effort for integer\nmultiplier modules that exist in designs ranging from floating-point division\nto matrix multiplication.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7528\u4e8eArm\u786c\u4ef6\u8bbe\u8ba1\u9a8c\u8bc1\u7684\u81ea\u52a8\u5316ACL2\u8bc1\u660e\u5de5\u5177ctv-cp\u3002", "motivation": "\u7b80\u5316ACL2\u8bc1\u660e\u5f00\u53d1\u5de5\u4f5c\uff0c\u7528\u4e8e\u9a8c\u8bc1\u6574\u6570\u4e58\u6cd5\u5668\u7b49\u786c\u4ef6\u8bbe\u8ba1\u3002", "method": "\u5f00\u53d1\u4e86\u5b9e\u9a8c\u6027\u9a8c\u8bc1\u5de5\u5177ctv-cp\uff0c\u96c6\u6210\u5230Arm\u7684\u9a8c\u8bc1\u6846\u67b6\u4e2d\u3002", "result": "\u663e\u8457\u81ea\u52a8\u5316\u4e86\u4ece\u6d6e\u70b9\u9664\u6cd5\u5230\u77e9\u9635\u4e58\u6cd5\u7684\u786c\u4ef6\u8bbe\u8ba1\u9a8c\u8bc1\u8fc7\u7a0b\u3002", "conclusion": "ctv-cp\u6210\u529f\u63d0\u5347\u4e86\u9a8c\u8bc1\u6548\u7387\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u786c\u4ef6\u8bbe\u8ba1\u573a\u666f\u3002"}}
{"id": "2507.19287", "pdf": "https://arxiv.org/pdf/2507.19287", "abs": "https://arxiv.org/abs/2507.19287", "authors": ["Pierre Jacquet", "Adrien Luxey-Bitri"], "title": "The Case for Time-Shared Computing Resources", "categories": ["cs.DC"], "comment": "Post-proceedings paper presented at LIMITS 2025: 11th Workshop on\n  Computing within Limits, 2025-06-26/27, Online", "summary": "The environmental impact of Information and Communication Technologies (ICT)\ncontinues to grow, driven notably by increasing usage, rebound effects, and\nemerging demands. However, despite the virtual nature of its services, the\nsector remains inherently constrained by its materiality and cannot rely on an\ninfinite pool of resources. As a result, the wide variety of supported services\nmay need to be managed under stricter limits within hosting facilities in the\nfuture. Contrary to common assumptions, we show that tenants typically do not\nshare computing resources, even in environments commonly perceived as\nmutualized, such as cloud platforms. Time-sharing has been progressively phased\nout for reasons of performance, security, predictability, and, perhaps more\nimportantly, due to the decreasing cost of computing resources. This paper\nadvocates for managing fewer physical resources by improving resource sharing\nbetween tenants. It represents a paradigm shift, moving beyond traditional\ntime-sharing at the hardware level to a higher abstraction. This approach\nentails \"doing with fewer resources\" under conditions of \"reduced performance\".\nNonetheless, enhancing the mutualization of infrastructure can reduce cluster\nsizes (through consolidation) and improve energy efficiency, with gains related\nto the accepted performance trade-off, a situation potentially more socially\nacceptable than eliminating services. We review the current state of the art,\nidentify challenges and opportunities, propose interpretations of Time-Shared\nComputing, and outline key research directions.", "AI": {"tldr": "\u5c3d\u7ba1ICT\u7684\u865a\u62df\u670d\u52a1\u4e0d\u65ad\u589e\u957f\uff0c\u4f46\u5176\u73af\u5883\u5f71\u54cd\u4ecd\u7136\u53d7\u9650\u4e8e\u7269\u8d28\u8d44\u6e90\u3002\u7814\u7a76\u63d0\u5021\u901a\u8fc7\u6539\u8fdb\u79df\u6237\u95f4\u8d44\u6e90\u5206\u4eab\u6765\u51cf\u5c11\u7269\u7406\u8d44\u6e90\u4f7f\u7528\uff0c\u5e76\u63a2\u7d22\u66f4\u9ad8\u62bd\u8c61\u5c42\u7684\u65f6\u95f4\u5171\u4eab\u8ba1\u7b97\u6a21\u5f0f\uff0c\u4ee5\u63d0\u5347\u80fd\u6e90\u6548\u7387\u548c\u96c6\u7fa4\u89c4\u6a21\u7f29\u51cf\u3002", "motivation": "ICT\u884c\u4e1a\u7684\u73af\u5883\u5f71\u54cd\u65e5\u76ca\u663e\u8457\uff0c\u800c\u8d44\u6e90\u4e92\u7528\u7684\u7f3a\u5931\u52a0\u5267\u4e86\u8fd9\u4e00\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u63a8\u52a8\u66f4\u9ad8\u6548\u7684\u8d44\u6e90\u5171\u4eab\u6a21\u5f0f\uff0c\u4ee5\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u548c\u73af\u5883\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u8d44\u6e90\u5171\u4eab\u6a21\u5f0f\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u66f4\u9ad8\u62bd\u8c61\u5c42\u7684\u65f6\u95f4\u5171\u4eab\u8ba1\u7b97\uff0c\u5e76\u63a2\u8ba8\u5176\u53ef\u884c\u6027\u4e0e\u6311\u6218\u3002", "result": "\u6539\u8fdb\u8d44\u6e90\u5171\u4eab\u53ef\u4ee5\u51cf\u5c11\u96c6\u7fa4\u89c4\u6a21\u3001\u63d0\u5347\u80fd\u6e90\u6548\u7387\uff0c\u540c\u65f6\u9700\u6743\u8861\u6027\u80fd\u635f\u5931\uff0c\u8fd9\u5728\u793e\u4f1a\u63a5\u53d7\u5ea6\u4e0a\u53ef\u80fd\u4f18\u4e8e\u5b8c\u5168\u53d6\u6d88\u670d\u52a1\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u8d44\u6e90\u5171\u4eab\u5728ICT\u53ef\u6301\u7eed\u53d1\u5c55\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u8d44\u6e90\u9ad8\u6548\u5229\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.19411", "pdf": "https://arxiv.org/pdf/2507.19411", "abs": "https://arxiv.org/abs/2507.19411", "authors": ["Ali RajabiNekoo", "Laleh Rasoul", "Amirfarhad Farhadi", "Azadeh Zamanifar"], "title": "SILS: Strategic Influence on Liquidity Stability and Whale Detection in Concentrated-Liquidity DEXs", "categories": ["cs.LG", "cs.CR", "cs.ET"], "comment": null, "summary": "Traditional methods for identifying impactful liquidity providers (LPs) in\nConcentrated Liquidity Market Makers (CLMMs) rely on broad measures, such as\nnominal capital size or surface-level activity, which often lead to inaccurate\nrisk analysis. The SILS framework offers a significantly more detailed\napproach, characterizing LPs not just as capital holders but as dynamic\nsystemic agents whose actions directly impact market stability. This represents\na fundamental paradigm shift from the static, volume-based analysis to a\ndynamic, impact-focused understanding. This advanced approach uses on-chain\nevent logs and smart contract execution traces to compute Exponential\nTime-Weighted Liquidity (ETWL) profiles and apply unsupervised anomaly\ndetection. Most importantly, it defines an LP's functional importance through\nthe Liquidity Stability Impact Score (LSIS), a counterfactual metric that\nmeasures the potential degradation of the market if the LP withdraws. This\ncombined approach provides a more detailed and realistic characterization of an\nLP's impact, moving beyond the binary and often misleading classifications used\nby existing methods. This impact-focused and comprehensive approach enables\nSILS to accurately identify high-impact LPs-including those missed by\ntraditional methods and supports essential applications like a protective\noracle layer and actionable trader signals, thereby significantly enhancing\nDeFi ecosystem. The framework provides unprecedented transparency into the\nunderlying liquidity structure and associated risks, effectively reducing the\ncommon false positives and uncovering critical false negatives found in\ntraditional models. Therefore, SILS provides an effective mechanism for\nproactive risk management, transforming how DeFi protocols safeguard their\necosystems against asymmetric liquidity behavior.", "AI": {"tldr": "SILS\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u3001\u5f71\u54cd\u5bfc\u5411\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u57fa\u4e8e\u540d\u4e49\u8d44\u672c\u6216\u8868\u9762\u6d3b\u52a8\u7684\u6d41\u52a8\u6027\u63d0\u4f9b\u8005\uff08LP\uff09\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u98ce\u9669\u7ba1\u7406\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u8bc6\u522bCLMMs\u4e2d\u9ad8\u5f71\u54cd\u529bLP\u65f6\u5b58\u5728\u4e0d\u51c6\u786e\u95ee\u9898\uff0cSILS\u65e8\u5728\u63d0\u4f9b\u66f4\u8be6\u7ec6\u548c\u5e02\u573a\u7a33\u5b9a\u7684\u52a8\u6001\u5206\u6790\u3002", "method": "\u5229\u7528\u94fe\u4e0a\u4e8b\u4ef6\u65e5\u5fd7\u548c\u667a\u80fd\u5408\u7ea6\u6267\u884c\u8f68\u8ff9\uff0c\u8ba1\u7b97ETWL\u914d\u7f6e\u6587\u4ef6\uff0c\u5e76\u5e94\u7528\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\uff0c\u5b9a\u4e49LSIS\u8861\u91cfLP\u9000\u51fa\u5bf9\u5e02\u573a\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "result": "SILS\u80fd\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u9ad8\u5f71\u54cd\u529bLP\uff0c\u5305\u62ec\u4f20\u7edf\u65b9\u6cd5\u9057\u6f0f\u7684\uff0c\u5e76\u652f\u6301DeFi\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u4fdd\u62a4\u6027\u9884\u8a00\u5c42\u548c\u53ef\u64cd\u4f5c\u4ea4\u6613\u4fe1\u53f7\u3002", "conclusion": "SILS\u901a\u8fc7\u52a8\u6001\u548c\u5168\u9762\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86DeFi\u751f\u6001\u7cfb\u7edf\u7684\u98ce\u9669\u7ba1\u7406\u548c\u900f\u660e\u5ea6\uff0c\u51cf\u5c11\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u8bef\u5224\u3002"}}
{"id": "2507.19115", "pdf": "https://arxiv.org/pdf/2507.19115", "abs": "https://arxiv.org/abs/2507.19115", "authors": ["Shweta Ramesh", "Joy Bose", "Hamender Singh", "A K Raghavan", "Sujoy Roychowdhury", "Giriprasad Sridhara", "Nishrith Saini", "Ricardo Britto"], "title": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code review is one of the primary means of assuring the quality of released\nsoftware along with testing and static analysis. However, code review requires\nexperienced developers who may not always have the time to perform an in-depth\nreview of code. Thus, automating code review can help alleviate the cognitive\nburden on experienced software developers allowing them to focus on their\nprimary activities of writing code to add new features and fix bugs. In this\npaper, we describe our experience in using Large Language Models towards\nautomating the code review process in Ericsson. We describe the development of\na lightweight tool using LLMs and static program analysis. We then describe our\npreliminary experiments with experienced developers in evaluating our code\nreview tool and the encouraging results.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u6765\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u8fc7\u7a0b\uff0c\u4ee5\u51cf\u8f7b\u8d44\u6df1\u5f00\u53d1\u8005\u7684\u8ba4\u77e5\u8d1f\u62c5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u5728\u7231\u7acb\u4fe1\u516c\u53f8\u5f00\u53d1\u7684\u4e00\u4e2a\u7ed3\u5408LLM\u548c\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u7684\u5de5\u5177\u7684\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u8d44\u6df1\u5f00\u53d1\u8005\u7f3a\u4e4f\u65f6\u95f4\u8fdb\u884c\u6df1\u5165\u7684\u4ee3\u7801\u5ba1\u67e5\uff0c\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u53ef\u4ee5\u51cf\u8f7b\u4ed6\u4eec\u7684\u8d1f\u62c5\uff0c\u4f7f\u5176\u4e13\u6ce8\u4e8e\u7f16\u5199\u65b0\u529f\u80fd\u548c\u4fee\u590d\u6f0f\u6d1e\u7684\u4e3b\u8981\u4efb\u52a1\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5de5\u5177\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u548c\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u6280\u672f\uff0c\u7528\u4e8e\u4ee3\u7801\u5ba1\u67e5\u3002", "result": "\u4e0e\u8d44\u6df1\u5f00\u53d1\u8005\u5408\u4f5c\u7684\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u5de5\u5177\u7684\u6548\u679c\u4ee4\u4eba\u9f13\u821e\u3002", "conclusion": "\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u5728\u51cf\u8f7b\u5f00\u53d1\u8005\u8d1f\u62c5\u548c\u63d0\u9ad8\u6548\u7387\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u4f18\u5316\u3002"}}
{"id": "2507.19012", "pdf": "https://arxiv.org/pdf/2507.19012", "abs": "https://arxiv.org/abs/2507.19012", "authors": ["Alessandro Coglio", "Eric McCarthy"], "title": "A Formalization of the Yul Language and Some Verified Yul Code Transformations", "categories": ["cs.LO", "cs.PL"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "Yul is an intermediate language used in the compilation of the Solidity\nprogramming language for Ethereum smart contracts. The compiler applies\ncustomizable sequences of transformations to Yul code. To help ensure the\ncorrectness of these transformations and their sequencing, we used the ACL2\ntheorem prover to develop a formalization of the syntax and semantics of Yul,\nproofs relating static and dynamic semantics, a formalization of some Yul code\ntransformations, and correctness proofs for these transformations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4f7f\u7528ACL2\u5b9a\u7406\u8bc1\u660e\u5668\u5bf9Yul\u8bed\u8a00\u7684\u5f62\u5f0f\u5316\u8bed\u6cd5\u548c\u8bed\u4e49\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u4e3a\u786e\u4fddSolidity\u7f16\u8bd1\u5668\u4e2dYul\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u53ca\u5176\u987a\u5e8f\u7684\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528ACL2\u5b9a\u7406\u8bc1\u660e\u5668\u5bf9Yul\u7684\u8bed\u6cd5\u3001\u8bed\u4e49\u3001\u4ee3\u7801\u8f6c\u6362\u8fdb\u884c\u5f62\u5f0f\u5316\u5efa\u6a21\uff0c\u5e76\u8bc1\u660e\u5176\u6b63\u786e\u6027\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86Yul\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u4e86\u76f8\u5173\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5\u9a8c\u8bc1\u4e86Yul\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\uff0c\u589e\u5f3a\u4e86\u7f16\u8bd1\u5668\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.18802", "pdf": "https://arxiv.org/pdf/2507.18802", "abs": "https://arxiv.org/abs/2507.18802", "authors": ["Danqing Shi", "Furui Cheng", "Tino Weinkauf", "Antti Oulasvirta", "Mennatallah El-Assady"], "title": "DxHF: Providing High-Quality Human Feedback for LLM Alignment via Interactive Decomposition", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Human preferences are widely used to align large language models (LLMs)\nthrough methods such as reinforcement learning from human feedback (RLHF).\nHowever, the current user interfaces require annotators to compare text\nparagraphs, which is cognitively challenging when the texts are long or\nunfamiliar. This paper contributes by studying the decomposition principle as\nan approach to improving the quality of human feedback for LLM alignment. This\napproach breaks down the text into individual claims instead of directly\ncomparing two long-form text responses. Based on the principle, we build a\nnovel user interface DxHF. It enhances the comparison process by showing\ndecomposed claims, visually encoding the relevance of claims to the\nconversation and linking similar claims. This allows users to skim through key\ninformation and identify differences for better and quicker judgment. Our\ntechnical evaluation shows evidence that decomposition generally improves\nfeedback accuracy regarding the ground truth, particularly for users with\nuncertainty. A crowdsourcing study with 160 participants indicates that using\nDxHF improves feedback accuracy by an average of 5%, although it increases the\naverage feedback time by 18 seconds. Notably, accuracy is significantly higher\nin situations where users have less certainty. The finding of the study\nhighlights the potential of HCI as an effective method for improving human-AI\nalignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u89e3\u6587\u672c\u4e3a\u5355\u72ec\u4e3b\u5f20\u7684\u65b9\u6cd5\uff08DxHF\u754c\u9762\uff09\u6765\u6539\u8fdb\u4eba\u7c7b\u53cd\u9988\u8d28\u91cf\uff0c\u63d0\u5347LLM\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u6807\u6ce8\u8005\u9700\u76f4\u63a5\u6bd4\u8f83\u957f\u6587\u672c\u6bb5\u843d\uff0c\u8ba4\u77e5\u8d1f\u62c5\u91cd\u4e14\u6548\u7387\u4f4e\uff0c\u5c24\u5176\u5bf9\u964c\u751f\u6216\u590d\u6742\u5185\u5bb9\u3002", "method": "\u5c06\u6587\u672c\u5206\u89e3\u4e3a\u5355\u72ec\u4e3b\u5f20\uff0c\u5e76\u901a\u8fc7DxHF\u754c\u9762\u5c55\u793a\uff0c\u89c6\u89c9\u5316\u7f16\u7801\u76f8\u5173\u6027\u548c\u76f8\u4f3c\u6027\uff0c\u63d0\u5347\u6bd4\u8f83\u6548\u7387\u3002", "result": "\u5206\u89e3\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u53cd\u9988\u51c6\u786e\u6027\uff08\u5e73\u57475%\uff09\uff0c\u5c24\u5176\u9488\u5bf9\u4e0d\u786e\u5b9a\u7684\u7528\u6237\uff0c\u4f46\u53cd\u9988\u65f6\u95f4\u589e\u52a0\u4e8618\u79d2\u3002", "conclusion": "HCI\u65b9\u6cd5\uff08\u5982DxHF\uff09\u662f\u63d0\u5347\u4eba-AI\u5bf9\u9f50\u7684\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u6216\u4e0d\u786e\u5b9a\u7684\u573a\u666f\u3002"}}
{"id": "2507.19125", "pdf": "https://arxiv.org/pdf/2507.19125", "abs": "https://arxiv.org/abs/2507.19125", "authors": ["Yuqi Li", "Haotian Zhang", "Li Li", "Dong Liu"], "title": "Learned Image Compression with Hierarchical Progressive Context Modeling", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "17 pages, ICCV 2025", "summary": "Context modeling is essential in learned image compression for accurately\nestimating the distribution of latents. While recent advanced methods have\nexpanded context modeling capacity, they still struggle to efficiently exploit\nlong-range dependency and diverse context information across different coding\nsteps. In this paper, we introduce a novel Hierarchical Progressive Context\nModel (HPCM) for more efficient context information acquisition. Specifically,\nHPCM employs a hierarchical coding schedule to sequentially model the\ncontextual dependencies among latents at multiple scales, which enables more\nefficient long-range context modeling. Furthermore, we propose a progressive\ncontext fusion mechanism that incorporates contextual information from previous\ncoding steps into the current step, effectively exploiting diverse contextual\ninformation. Experimental results demonstrate that our method achieves\nstate-of-the-art rate-distortion performance and strikes a better balance\nbetween compression performance and computational complexity. The code is\navailable at https://github.com/lyq133/LIC-HPCM.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u6a21\u578b\uff08HPCM\uff09\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u4e0a\u4e0b\u6587\u4f9d\u8d56\u5efa\u6a21\u548c\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u878d\u5408\u673a\u5236\uff0c\u63d0\u5347\u4e86\u56fe\u50cf\u538b\u7f29\u4e2d\u957f\u8303\u56f4\u4f9d\u8d56\u548c\u591a\u6837\u5316\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u5229\u7528\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u56fe\u50cf\u538b\u7f29\u4e2d\u96be\u4ee5\u9ad8\u6548\u5229\u7528\u957f\u8303\u56f4\u4f9d\u8d56\u548c\u591a\u6837\u5316\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u538b\u7f29\u6027\u80fd\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51faHPCM\uff0c\u91c7\u7528\u5206\u5c42\u7f16\u7801\u8ba1\u5212\u591a\u5c3a\u5ea6\u5efa\u6a21\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff0c\u5e76\u5f15\u5165\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u878d\u5408\u673a\u5236\u6574\u5408\u5386\u53f2\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHPCM\u5728\u7387\u5931\u771f\u6027\u80fd\u4e0a\u8fbe\u5230\u6700\u4f18\uff0c\u5e76\u5728\u538b\u7f29\u6027\u80fd\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u5e73\u8861\u3002", "conclusion": "HPCM\u663e\u8457\u63d0\u5347\u4e86\u56fe\u50cf\u538b\u7f29\u4e2d\u4e0a\u4e0b\u6587\u5efa\u6a21\u7684\u6548\u7387\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.19377", "pdf": "https://arxiv.org/pdf/2507.19377", "abs": "https://arxiv.org/abs/2507.19377", "authors": ["David Nunez", "Francesc Wilhelmi", "Maksymilian Wojnar", "Katarzyna Kosek-Szott", "Szymon Szott", "Boris Bellalta"], "title": "Deep Reinforcement Learning-Based Scheduling for Wi-Fi Multi-Access Point Coordination", "categories": ["cs.NI"], "comment": "Submitted to IEEE Transactions on Machine Learning in Communications\n  and Networking", "summary": "Multi-access point coordination (MAPC) is a key feature of IEEE 802.11bn,\nwith a potential impact on future Wi-Fi networks. MAPC enables joint scheduling\ndecisions across multiple access points (APs) to improve throughput, latency,\nand reliability in dense Wi-Fi deployments. However, implementing efficient\nscheduling policies under diverse traffic and interference conditions in\noverlapping basic service sets (OBSSs) remains a complex task. This paper\npresents a method to minimize the network-wide worst-case latency by\nformulating MAPC scheduling as a sequential decision-making problem and\nproposing a deep reinforcement learning (DRL) mechanism to minimize worst-case\ndelays in OBSS deployments. Specifically, we train a DRL agent using proximal\npolicy optimization (PPO) within an 802.11bn-compatible Gymnasium environment.\nThis environment provides observations of queue states, delay metrics, and\nchannel conditions, enabling the agent to schedule multiple AP-station pairs to\ntransmit simultaneously by leveraging spatial reuse (SR) groups. Simulations\ndemonstrate that our proposed solution outperforms state-of-the-art heuristic\nstrategies across a wide range of network loads and traffic patterns. The\ntrained machine learning (ML) models consistently achieve lower 99th-percentile\ndelays, showing up to a 30% improvement over the best baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316IEEE 802.11bn\u4e2d\u591a\u63a5\u5165\u70b9\u534f\u8c03\uff08MAPC\uff09\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u4ee5\u51cf\u5c11\u7f51\u7edc\u4e2d\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u5ef6\u8fdf\uff0c\u5e76\u5728\u4eff\u771f\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u7b56\u7565\u7684\u6027\u80fd\u3002", "motivation": "\u591a\u63a5\u5165\u70b9\u534f\u8c03\uff08MAPC\uff09\u662f\u672a\u6765Wi-Fi\u7f51\u7edc\u7684\u5173\u952e\u7279\u6027\uff0c\u4f46\u5728\u5bc6\u96c6\u90e8\u7f72\u4e2d\uff0c\u5982\u4f55\u5728\u4e0d\u540c\u6d41\u91cf\u548c\u5e72\u6270\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u6548\u8c03\u5ea6\u4ecd\u662f\u4e00\u4e2a\u590d\u6742\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06MAPC\u8c03\u5ea6\u5efa\u6a21\u4e3a\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7684DRL\u673a\u5236\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u4ee5\u4f18\u5316SR\u7ec4\u7684\u8c03\u5ea6\uff0c\u6700\u5c0f\u5316\u6700\u574f\u60c5\u51b5\u5ef6\u8fdf\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u7f51\u7edc\u8d1f\u8f7d\u548c\u6d41\u91cf\u6a21\u5f0f\u4e0b\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u6700\u574f\u5ef6\u8fdf\u964d\u4f4e30%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5bc6\u96c6Wi-Fi\u7f51\u7edc\u7684\u4f4e\u5ef6\u8fdf\u8c03\u5ea6\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86DRL\u5728\u5b9e\u9645\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.19271", "pdf": "https://arxiv.org/pdf/2507.19271", "abs": "https://arxiv.org/abs/2507.19271", "authors": ["Igli Begolli", "Meltem Aksoy", "Daniel Neider"], "title": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Code review is essential for maintaining software quality but often\ntime-consuming and cognitively demanding, especially in industrial\nenvironments. Recent advancements in language models (LMs) have opened new\navenues for automating core review tasks. This study presents the empirical\nevaluation of monolingual fine-tuning on the performance of open-source LMs\nacross three key automated code review tasks: Code Change Quality Estimation,\nReview Comment Generation, and Code Refinement. We fine-tuned three distinct\nmodels, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\\# specific\ndataset combining public benchmarks with industrial repositories. Our study\ninvestigates how different configurations of programming languages and natural\nlanguages in the training data affect LM performance, particularly in comment\ngeneration. Additionally, we benchmark the fine-tuned models against an\nautomated software analysis tool (ASAT) and human reviewers to evaluate their\npractical utility in real-world settings. Our results show that monolingual\nfine-tuning improves model accuracy and relevance compared to multilingual\nbaselines. While LMs can effectively support code review workflows, especially\nfor routine or repetitive tasks, human reviewers remain superior in handling\nsemantically complex or context-sensitive changes. Our findings highlight the\nimportance of language alignment and task-specific adaptation in optimizing LMs\nfor automated code review.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u5355\u8bed\u8a00\u5fae\u8c03\u5bf9\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u4ee3\u7801\u5ba1\u67e5\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5f71\u54cd\uff0c\u53d1\u73b0\u5355\u8bed\u8a00\u5fae\u8c03\u80fd\u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\u548c\u76f8\u5173\u6027\uff0c\u4f46\u5728\u5904\u7406\u8bed\u4e49\u590d\u6742\u6216\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u53d8\u66f4\u65f6\u4ecd\u9700\u4eba\u5de5\u5ba1\u67e5\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8d39\u65f6\u8d39\u529b\u3002\u5229\u7528\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u90e8\u5206\u5ba1\u67e5\u4efb\u52a1\u6709\u671b\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u7814\u7a76\u5bf9CodeReviewer\u3001CodeLlama-7B\u548cDeepSeek-R1-Distill\u4e09\u79cd\u6a21\u578b\u8fdb\u884c\u4e86\u5355\u8bed\u8a00\u5fae\u8c03\uff0c\u5e76\u5728C#\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5176\u5728\u4ee3\u7801\u53d8\u66f4\u8d28\u91cf\u8bc4\u4f30\u3001\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u548c\u4ee3\u7801\u6539\u8fdb\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5355\u8bed\u8a00\u5fae\u8c03\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u76f8\u5173\u6027\uff0c\u4f46\u4eba\u5de5\u5ba1\u67e5\u5728\u5904\u7406\u590d\u6742\u53d8\u66f4\u65f6\u4ecd\u4f18\u4e8e\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u8bed\u8a00\u5bf9\u9f50\u548c\u4efb\u52a1\u7279\u5b9a\u9002\u5e94\u5bf9\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u8868\u73b0\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.18828", "pdf": "https://arxiv.org/pdf/2507.18828", "abs": "https://arxiv.org/abs/2507.18828", "authors": ["Victoria Chang", "Caro Williams-Pierce", "Huaishu Peng", "Ge Gao"], "title": "Ethical Considerations for Observational Research in Social VR", "categories": ["cs.HC"], "comment": "CSCW Companion '25, October 18-22, 2025, Bergen, Norway", "summary": "Social VR introduces new ethical challenges for observational research. The\ncurrent paper presents a narrative literature review of ethical considerations\nin observational methods, with a focus on work in HCI. We examine how\nunobtrusive or selectively disclosed observation is implemented in public\nface-to-face and social VR settings. Our review extends ethical discussions\nfrom traditional public research into the context of social VR, highlighting\ntensions between observer visibility, data traceability, and participant\nautonomy. Drawing on insights distilled from prior literature, we propose five\nconstructive guidelines for ethical observational research in public social VR\nenvironments. Our work offers key implications for future research, addressing\nanticipated improvements in platform design, the management of researcher\npresence, and the development of community-informed consent mechanisms.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u63a2\u8ba8\u4e86\u793e\u4ea4\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u4e2d\u89c2\u5bdf\u6027\u7814\u7a76\u7684\u4f26\u7406\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e94\u9879\u6307\u5bfc\u539f\u5219\u3002", "motivation": "\u7814\u7a76\u793e\u4ea4VR\u73af\u5883\u4e2d\u89c2\u5bdf\u6027\u7814\u7a76\u7684\u4f26\u7406\u6311\u6218\uff0c\u586b\u8865\u4f20\u7edf\u516c\u5171\u7814\u7a76\u4e0e\u65b0\u5174\u6280\u672f\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u5206\u6790\u516c\u5171\u9762\u5bf9\u9762\u548c\u793e\u4ea4VR\u73af\u5883\u4e2d\u7684\u89c2\u5bdf\u65b9\u6cd5\uff0c\u5173\u6ce8\u89c2\u5bdf\u8005\u7684\u53ef\u89c1\u6027\u3001\u6570\u636e\u53ef\u8ffd\u6eaf\u6027\u548c\u53c2\u4e0e\u8005\u81ea\u4e3b\u6027\u3002", "result": "\u63d0\u51fa\u4e94\u9879\u4f26\u7406\u7814\u7a76\u6307\u5bfc\u539f\u5219\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u5e73\u53f0\u8bbe\u8ba1\u3001\u7814\u7a76\u4eba\u5458\u5b58\u5728\u7ba1\u7406\u548c\u793e\u533a\u77e5\u60c5\u540c\u610f\u673a\u5236\u7684\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u793e\u4ea4VR\u7684\u89c2\u5bdf\u6027\u7814\u7a76\u9700\u8981\u65b0\u7684\u4f26\u7406\u6846\u67b6\uff0c\u672c\u6587\u7684\u6307\u5bfc\u539f\u5219\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2507.19209", "pdf": "https://arxiv.org/pdf/2507.19209", "abs": "https://arxiv.org/abs/2507.19209", "authors": ["Xiaoyu Zhang", "Zhifeng Bao", "Hai Dong", "Ziwei Wang", "Jiajun Liu"], "title": "Querying Autonomous Vehicle Point Clouds: Enhanced by 3D Object Counting with CounterNet", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Autonomous vehicles generate massive volumes of point cloud data, yet only a\nsubset is relevant for specific tasks such as collision detection, traffic\nanalysis, or congestion monitoring. Effectively querying this data is essential\nto enable targeted analytics. In this work, we formalize point cloud querying\nby defining three core query types: RETRIEVAL, COUNT, and AGGREGATION, each\naligned with distinct analytical scenarios. All these queries rely heavily on\naccurate object counts to produce meaningful results, making precise object\ncounting a critical component of query execution. Prior work has focused on\nindexing techniques for 2D video data, assuming detection models provide\naccurate counting information. However, when applied to 3D point cloud data,\nstate-of-the-art detection models often fail to generate reliable object\ncounts, leading to substantial errors in query results. To address this\nlimitation, we propose CounterNet, a heatmap-based network designed for\naccurate object counting in large-scale point cloud data. Rather than focusing\non accurate object localization, CounterNet detects object presence by finding\nobject centers to improve counting accuracy. We further enhance its performance\nwith a feature map partitioning strategy using overlapping regions, enabling\nbetter handling of both small and large objects in complex traffic scenes. To\nadapt to varying frame characteristics, we introduce a per-frame dynamic model\nselection strategy that selects the most effective configuration for each\ninput. Evaluations on three real-world autonomous vehicle datasets show that\nCounterNet improves counting accuracy by 5% to 20% across object categories,\nresulting in more reliable query outcomes across all supported query types.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CounterNet\uff0c\u4e00\u79cd\u57fa\u4e8e\u70ed\u56fe\u7684\u7f51\u7edc\uff0c\u65e8\u5728\u63d0\u9ad8\u5927\u89c4\u6a21\u70b9\u4e91\u6570\u636e\u4e2d\u7684\u7269\u4f53\u8ba1\u6570\u51c6\u786e\u6027\uff0c\u4ece\u800c\u652f\u6301\u66f4\u53ef\u9760\u7684\u67e5\u8be2\u7ed3\u679c\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u751f\u6210\u7684\u6d77\u91cf\u70b9\u4e91\u6570\u636e\u4e2d\uff0c\u53ea\u6709\u90e8\u5206\u5bf9\u7279\u5b9a\u4efb\u52a1\uff08\u5982\u78b0\u649e\u68c0\u6d4b\u3001\u4ea4\u901a\u5206\u6790\uff09\u76f8\u5173\u3002\u73b0\u6709\u65b9\u6cd5\u57283D\u70b9\u4e91\u6570\u636e\u4e2d\u96be\u4ee5\u63d0\u4f9b\u53ef\u9760\u7684\u7269\u4f53\u8ba1\u6570\uff0c\u5bfc\u81f4\u67e5\u8be2\u7ed3\u679c\u9519\u8bef\u3002", "method": "\u63d0\u51faCounterNet\uff0c\u901a\u8fc7\u68c0\u6d4b\u7269\u4f53\u4e2d\u5fc3\u800c\u975e\u7cbe\u786e\u5b9a\u4f4d\u6765\u63d0\u9ad8\u8ba1\u6570\u51c6\u786e\u6027\uff0c\u91c7\u7528\u7279\u5f81\u56fe\u5206\u533a\u7b56\u7565\u548c\u52a8\u6001\u6a21\u578b\u9009\u62e9\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cCounterNet\u5c06\u8ba1\u6570\u51c6\u786e\u6027\u63d0\u9ad8\u4e865%\u81f320%\uff0c\u663e\u8457\u6539\u5584\u4e86\u67e5\u8be2\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002", "conclusion": "CounterNet\u901a\u8fc7\u4f18\u5316\u8ba1\u6570\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u70b9\u4e91\u6570\u636e\u67e5\u8be2\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.19013", "pdf": "https://arxiv.org/pdf/2507.19013", "abs": "https://arxiv.org/abs/2507.19013", "authors": ["Ankit Kumar", "Panagiotis Manolios"], "title": "A Formalization of the Correctness of the Floodsub Protocol", "categories": ["cs.LO", "cs.NI"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "Floodsub is a simple, robust and popular peer-to-peer publish/subscribe\n(pubsub) protocol, where nodes can arbitrarily leave or join the network,\nsubscribe to or unsubscribe from topics and forward newly received messages to\nall of their neighbors, except the sender or the originating peer. To show the\ncorrectness of Floodsub, we propose its specification: Broadcastsub, in which\nimplementation details like network connections and neighbor subscriptions are\nelided. To show that Floodsub does really implement Broadcastsub, one would\nhave to show that the two systems have related infinite computations. We prove\nthis by reasoning locally about states and their successors using Well-Founded\nSimulation (WFS). In this paper, we focus on the mechanization of a proof which\nshows that Floodsub is a simulation refinement of Broadcastsub using WFS. To\nthe best of our knowledge, ours is the first mechanized refinement-based\nverification of a real world pubsub protocol.", "AI": {"tldr": "Floodsub\u662f\u4e00\u4e2a\u7b80\u5355\u3001\u9c81\u68d2\u7684P2P\u53d1\u5e03/\u8ba2\u9605\u534f\u8bae\uff0c\u672c\u6587\u901a\u8fc7WFS\u8bc1\u660e\u5176\u6b63\u786e\u6027\uff0c\u5b9e\u73b0\u4e86Broadcastsub\u7684\u6a21\u62df\u7ec6\u5316\uff0c\u5e76\u9996\u6b21\u5bf9\u5b9e\u9645pubsub\u534f\u8bae\u8fdb\u884c\u4e86\u673a\u68b0\u5316\u9a8c\u8bc1\u3002", "motivation": "\u9a8c\u8bc1Floodsub\u534f\u8bae\u7684\u6b63\u786e\u6027\uff0c\u5c55\u793a\u5176\u4f5c\u4e3aBroadcastsub\u7684\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc7\u673a\u68b0\u5316\u8bc1\u660e\u63d0\u5347\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528Well-Founded Simulation (WFS)\u65b9\u6cd5\uff0c\u5c40\u90e8\u63a8\u7406\u72b6\u6001\u53ca\u5176\u540e\u7ee7\u5173\u7cfb\uff0c\u673a\u68b0\u5316\u8bc1\u660eFloodsub\u662fBroadcastsub\u7684\u6a21\u62df\u7ec6\u5316\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86Floodsub\u662fBroadcastsub\u7684\u6a21\u62df\u7ec6\u5316\uff0c\u5e76\u9996\u6b21\u5b8c\u6210\u73b0\u5b9epubsub\u534f\u8bae\u7684\u673a\u68b0\u5316\u9a8c\u8bc1\u3002", "conclusion": "Floodsub\u901a\u8fc7WFS\u8bc1\u660e\u4e86\u5176\u6b63\u786e\u6027\uff0c\u672c\u7814\u7a76\u7684\u673a\u68b0\u5316\u9a8c\u8bc1\u65b9\u6cd5\u4e3a\u7c7b\u4f3c\u534f\u8bae\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.19045", "pdf": "https://arxiv.org/pdf/2507.19045", "abs": "https://arxiv.org/abs/2507.19045", "authors": ["Yufei Ma", "Hanwen Zhang", "Qiya Yang", "Guibo Luo", "Yuesheng Zhu"], "title": "A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation", "categories": ["cs.CV", "cs.DC"], "comment": "Accepted at ECAI 2025", "summary": "In multi-center scenarios, One-Shot Federated Learning (OSFL) has attracted\nincreasing attention due to its low communication overhead, requiring only a\nsingle round of transmission. However, existing generative model-based OSFL\nmethods suffer from low training efficiency and potential privacy leakage in\nthe healthcare domain. Additionally, achieving convergence within a single\nround of model aggregation is challenging under non-Independent and Identically\nDistributed (non-IID) data. To address these challenges, in this paper a\nmodified OSFL framework is proposed, in which a new Feature-Guided Rectified\nFlow Model (FG-RF) and Dual-Layer Knowledge Distillation (DLKD) aggregation\nmethod are developed. FG-RF on the client side accelerates generative modeling\nin medical imaging scenarios while preserving privacy by synthesizing\nfeature-level images rather than pixel-level images. To handle non-IID\ndistributions, DLKD enables the global student model to simultaneously mimic\nthe output logits and align the intermediate-layer features of client-side\nteacher models during aggregation. Experimental results on three non-IID\nmedical imaging datasets show that our new framework and method outperform\nmulti-round federated learning approaches, achieving up to 21.73% improvement,\nand exceeds the baseline FedISCA by an average of 21.75%. Furthermore, our\nexperiments demonstrate that feature-level synthetic images significantly\nreduce privacy leakage risks compared to pixel-level synthetic images.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5355\u6b21\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff08OSFL\uff09\uff0c\u901a\u8fc7\u7279\u5f81\u5f15\u5bfc\u6821\u6b63\u6d41\u6a21\u578b\uff08FG-RF\uff09\u548c\u53cc\u5c42\u77e5\u8bc6\u84b8\u998f\uff08DLKD\uff09\u65b9\u6cd5\u89e3\u51b3\u4e86\u533b\u7597\u9886\u57df\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\u4f4e\u3001\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u4ee5\u53ca\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u4e0b\u7684\u5355\u8f6e\u6536\u655b\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u6a21\u578b\u57fa\u4e8eOSFL\u65b9\u6cd5\u5728\u533b\u7597\u9886\u57df\u4e2d\u5b58\u5728\u8bad\u7ec3\u6548\u7387\u4f4e\u3001\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u9ad8\u4ee5\u53ca\u5728\u975eIID\u6570\u636e\u4e0b\u96be\u4ee5\u5b9e\u73b0\u5355\u8f6e\u6536\u655b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faFG-RF\u6a21\u578b\u548cDLKD\u805a\u5408\u65b9\u6cd5\uff1aFG-RF\u901a\u8fc7\u5728\u5ba2\u6237\u7aef\u751f\u6210\u7279\u5f81\u7ea7\u800c\u975e\u50cf\u7d20\u7ea7\u56fe\u50cf\u52a0\u901f\u5efa\u6a21\u5e76\u4fdd\u62a4\u9690\u79c1\uff1bDLKD\u901a\u8fc7\u8ba9\u5168\u5c40\u5b66\u751f\u6a21\u578b\u540c\u65f6\u6a21\u4eff\u8f93\u51fa\u903b\u8f91\u548c\u5bf9\u9f50\u4e2d\u95f4\u5c42\u7279\u5f81\u6765\u5904\u7406\u975eIID\u6570\u636e\u3002", "result": "\u5728\u4e09\u4e2a\u975eIID\u533b\u7597\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u6846\u67b6\u6027\u80fd\u4f18\u4e8e\u591a\u8f6e\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u5347\u9ad8\u8fbe21.73%\uff0c\u5e73\u5747\u8d85\u8fc7FedISCA\u57fa\u7ebf21.75%\u3002\u7279\u5f81\u7ea7\u5408\u6210\u56fe\u50cf\u663e\u8457\u964d\u4f4e\u4e86\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "conclusion": "\u6539\u8fdb\u7684OSFL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8bad\u7ec3\u6548\u7387\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u6570\u636e\u975eIID\u5206\u5e03\u95ee\u9898\uff0c\u5728\u533b\u7597\u9886\u57df\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.19275", "pdf": "https://arxiv.org/pdf/2507.19275", "abs": "https://arxiv.org/abs/2507.19275", "authors": ["Bo Wang", "Pengyang Wang", "Chong Chen", "Qi Sun", "Jieke Shi", "Chengran Yang", "Ming Deng", "Youfang Lin", "Zhou Yang", "David Lo"], "title": "Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug Reports", "categories": ["cs.SE"], "comment": null, "summary": "Mutation-based fuzzing is effective for uncovering compiler bugs, but\ndesigning high-quality mutators for modern languages with complex constructs\n(e.g., templates, macros) remains challenging. Existing methods rely heavily on\nmanual design or human-in-the-loop correction, limiting scalability and\ncross-language generalizability.\n  We present Mut4All, a fully automated, language-agnostic framework that\nsynthesizes mutators using Large Language Models (LLMs) and compiler-specific\nknowledge from bug reports. It consists of three agents: (1) a mutator\ninvention agent that identifies mutation targets and generates mutator metadata\nusing compiler-related insights; (2) a mutator implementation synthesis agent,\nfine-tuned to produce initial implementations; and (3) a mutator refinement\nagent that verifies and corrects the mutators via unit-test feedback.\n  Mut4All processes 1000 bug reports (500 Rust, 500 C++), yielding 319 Rust and\n403 C++ mutators at ~$0.08 each via GPT-4o. Our customized fuzzer, using these\nmutators, finds 62 bugs in Rust compilers (38 new, 7 fixed) and 34 bugs in C++\ncompilers (16 new, 1 fixed). Mut4All outperforms existing methods in both\nunique crash detection and coverage, ranking first on Rust and second on C++.", "AI": {"tldr": "Mut4All\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u5168\u81ea\u52a8\u3001\u8bed\u8a00\u65e0\u5173\u7684\u7a81\u53d8\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5904\u7406\u7f16\u8bd1\u5668\u76f8\u5173\u7684\u9519\u8bef\u62a5\u544a\u81ea\u52a8\u5408\u6210\u9ad8\u8d28\u91cf\u7a81\u53d8\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f16\u8bd1\u5668\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\uff08\u5982C++\u3001Rust\uff09\u7684\u590d\u6742\u7ed3\u6784\u4f7f\u5f97\u7a81\u53d8\u5668\u8bbe\u8ba1\u53d8\u5f97\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u8de8\u8bed\u8a00\u901a\u7528\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "Mut4All\u7531\u4e09\u4e2a\u4ee3\u7406\u7ec4\u6210\uff1a\u7a81\u53d8\u5668\u53d1\u660e\u4ee3\u7406\uff08\u8bc6\u522b\u76ee\u6807\u548c\u751f\u6210\u5143\u6570\u636e\uff09\u3001\u7a81\u53d8\u5668\u5b9e\u73b0\u5408\u6210\u4ee3\u7406\uff08\u751f\u6210\u521d\u59cb\u5b9e\u73b0\uff09\u3001\u7a81\u53d8\u5668\u4f18\u5316\u4ee3\u7406\uff08\u901a\u8fc7\u5355\u5143\u6d4b\u8bd5\u9a8c\u8bc1\u548c\u4fee\u6b63\uff09\u3002", "result": "\u5904\u74061000\u4e2a\u9519\u8bef\u62a5\u544a\u540e\uff0c\u751f\u6210319\u4e2aRust\u548c403\u4e2aC++\u7a81\u53d8\u5668\uff0c\u68c0\u6d4b\u51fa62\u4e2aRust\u7f16\u8bd1\u5668\u6f0f\u6d1e\uff0838\u4e2a\u65b0\u6f0f\u6d1e\uff09\u548c34\u4e2aC++\u7f16\u8bd1\u5668\u6f0f\u6d1e\uff0816\u4e2a\u65b0\u6f0f\u6d1e\uff09\u3002", "conclusion": "Mut4All\u5728\u552f\u4e00\u5d29\u6e83\u68c0\u6d4b\u548c\u8986\u76d6\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86LLM\u5728\u7f16\u8bd1\u5668\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.18836", "pdf": "https://arxiv.org/pdf/2507.18836", "abs": "https://arxiv.org/abs/2507.18836", "authors": ["Yue Luo", "Xinyan Yu", "Tram Thi Minh Tran", "Marius Hoggenmueller"], "title": "Uncertainty on Display: The Effects of Communicating Confidence Cues in Autonomous Vehicle-Pedestrian Interactions", "categories": ["cs.HC"], "comment": null, "summary": "Uncertainty is an inherent aspect of autonomous vehicle (AV) decision-making,\nyet it is rarely communicated to pedestrians, which hinders transparency. This\nstudy investigates how AV uncertainty can be conveyed through two approaches:\nexplicit communication (confidence percentage displays) and implicit\ncommunication (vehicle motion cues), across different confidence levels (high\nand low). Through a within-subject VR experiment (N=26), we evaluated these\napproaches in a crossing scenario, assessing interface qualities (visibility\nand intuitiveness), how well the information conveyed the vehicle's level of\nconfidence, and their impact on participants' perceived safety, trust, and user\nexperience. Our results show that explicit communication is more effective and\npreferred for conveying uncertainty, enhancing safety, trust, and user\nexperience. Conversely, implicit communication introduces ambiguity, especially\nwhen AV confidence is low. This research provides empirical insights into how\nuncertainty communication shapes pedestrian interpretation of AV behaviour and\noffer design guidance for external interfaces that integrate uncertainty as a\ncommunicative element.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7VR\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0d\u786e\u5b9a\u6027\u7684\u663e\u6027\uff08\u767e\u5206\u6bd4\u663e\u793a\uff09\u548c\u9690\u6027\uff08\u8f66\u8f86\u8fd0\u52a8\uff09\u4f20\u8fbe\u65b9\u5f0f\uff0c\u53d1\u73b0\u663e\u6027\u4f20\u8fbe\u66f4\u6709\u6548\u4e14\u66f4\u53d7\u9752\u7750\uff0c\u63d0\u5347\u4e86\u884c\u4eba\u5b89\u5168\u611f\u4e0e\u4fe1\u4efb\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u901a\u5e38\u672a\u4f20\u8fbe\u7ed9\u884c\u4eba\uff0c\u5f71\u54cd\u4e86\u900f\u660e\u5ea6\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u663e\u6027\u548c\u9690\u6027\u65b9\u5f0f\u4f20\u8fbe\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u901a\u8fc7VR\u5b9e\u9a8c\uff08N=26\uff09\uff0c\u6bd4\u8f83\u663e\u6027\uff08\u767e\u5206\u6bd4\u663e\u793a\uff09\u548c\u9690\u6027\uff08\u8f66\u8f86\u8fd0\u52a8\uff09\u4f20\u8fbe\u65b9\u5f0f\u5728\u4e0d\u540c\u7f6e\u4fe1\u6c34\u5e73\u4e0b\u7684\u6548\u679c\u3002", "result": "\u663e\u6027\u4f20\u8fbe\u66f4\u6709\u6548\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u611f\u3001\u4fe1\u4efb\u548c\u7528\u6237\u4f53\u9a8c\uff1b\u9690\u6027\u4f20\u8fbe\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u65f6\u6613\u5f15\u53d1\u6a21\u7cca\u3002", "conclusion": "\u663e\u6027\u4f20\u8fbe\u662f\u66f4\u4f18\u65b9\u5f0f\uff0c\u7814\u7a76\u4e3a\u8bbe\u8ba1\u5305\u542b\u4e0d\u786e\u5b9a\u6027\u4f20\u8fbe\u7684\u5916\u90e8\u754c\u9762\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2507.19225", "pdf": "https://arxiv.org/pdf/2507.19225", "abs": "https://arxiv.org/abs/2507.19225", "authors": ["Fang Kang", "Yin Cao", "Haoyu Chen"], "title": "Face2VoiceSync: Lightweight Face-Voice Consistency for Text-Driven Talking Face Generation", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "comment": null, "summary": "Recent studies in speech-driven talking face generation achieve promising\nresults, but their reliance on fixed-driven speech limits further applications\n(e.g., face-voice mismatch). Thus, we extend the task to a more challenging\nsetting: given a face image and text to speak, generating both talking face\nanimation and its corresponding speeches. Accordingly, we propose a novel\nframework, Face2VoiceSync, with several novel contributions: 1) Voice-Face\nAlignment, ensuring generated voices match facial appearance; 2) Diversity \\&\nManipulation, enabling generated voice control over paralinguistic features\nspace; 3) Efficient Training, using a lightweight VAE to bridge visual and\naudio large-pretrained models, with significantly fewer trainable parameters\nthan existing methods; 4) New Evaluation Metric, fairly assessing the diversity\nand identity consistency. Experiments show Face2VoiceSync achieves both visual\nand audio state-of-the-art performances on a single 40GB GPU.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFace2VoiceSync\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u4eba\u8138\u56fe\u50cf\u548c\u6587\u672c\u751f\u6210\u8bf4\u8bdd\u52a8\u753b\u548c\u8bed\u97f3\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u8bed\u97f3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u9a71\u52a8\u7684\u8bf4\u8bdd\u8138\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u8bed\u97f3\uff0c\u5bfc\u81f4\u5e94\u7528\u53d7\u9650\uff08\u5982\u8138\u58f0\u4e0d\u5339\u914d\uff09\uff0c\u56e0\u6b64\u7814\u7a76\u66f4\u6311\u6218\u6027\u7684\u4efb\u52a1\uff1a\u4ece\u4eba\u8138\u548c\u6587\u672c\u751f\u6210\u8bed\u97f3\u548c\u52a8\u753b\u3002", "method": "\u63d0\u51faFace2VoiceSync\u6846\u67b6\uff0c\u5305\u62ec\u8bed\u97f3-\u4eba\u8138\u5bf9\u9f50\u3001\u591a\u6837\u6027\u63a7\u5236\u3001\u9ad8\u6548\u8bad\u7ec3\uff08\u8f7b\u91cfVAE\u6865\u63a5\u89c6\u89c9\u548c\u97f3\u9891\u6a21\u578b\uff09\u53ca\u65b0\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFace2VoiceSync\u5728\u5355\u575740GB GPU\u4e0a\u5b9e\u73b0\u4e86\u89c6\u89c9\u548c\u97f3\u9891\u7684\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "Face2VoiceSync\u4e3a\u8bf4\u8bdd\u8138\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19014", "pdf": "https://arxiv.org/pdf/2507.19014", "abs": "https://arxiv.org/abs/2507.19014", "authors": ["Andrew T. Walter", "Panagiotis Manolios"], "title": "An ACL2s Interface to Z3", "categories": ["cs.LO", "D.2.4"], "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We present Lisp-Z3, an extension to the ACL2s systems programming framework\n(ASPF) that supports the use of the Z3 satisfiability modulo theories (SMT)\nsolver. Lisp-Z3 allows one to develop tools written using the full feature set\nof Common Lisp that can use both ACL2/s (either ACL2 or ACL2s) and Z3 as\nservices, combining the power of SMT and interactive theorem proving. Lisp-Z3\nis usable by anyone who would like to interact with Z3 from Common Lisp, as it\ndoes not depend on the availability of ACL2/s. We discuss the use of Lisp-Z3 in\nthree applications. The first is a Sudoku solver. The second is SeqSolve, a\nstring solver which solved a larger number of benchmark problems more quickly\nthan any other existing solver at the time of its publishing. Finally, Lisp-Z3\nwas also used in the context of hardware-in-the-loop fuzzing of wireless\nrouters, where low latency was an important goal. The latter two applications\nleveraged the ability of Lisp-Z3 to integrate Z3 with ACL2s code. We have\nfurther plans to use Lisp-Z3 inside of ACL2s to provide more powerful automated\nsupport for dependent types, and in particular more efficient generation of\ncounterexamples to properties involving dependent types. This paper describes\nthe usage and implementation of Lisp-Z3, as well as an evaluation of its use in\nthe aforementioned applications.", "AI": {"tldr": "Lisp-Z3\u662f\u4e00\u4e2a\u6269\u5c55ACL2s\u7cfb\u7edf\u7f16\u7a0b\u6846\u67b6\u7684\u5de5\u5177\uff0c\u652f\u6301Z3 SMT\u6c42\u89e3\u5668\uff0c\u7ed3\u5408\u4e86SMT\u548c\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u7684\u4f18\u52bf\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u4e3a\u4e86\u7ed3\u5408SMT\u6c42\u89e3\u5668Z3\u548c\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u5de5\u5177ACL2/s\u7684\u529f\u80fd\uff0c\u63d0\u5347\u590d\u6742\u95ee\u9898\u7684\u89e3\u51b3\u80fd\u529b\u3002", "method": "\u6269\u5c55ACL2s\u6846\u67b6\uff0c\u5f00\u53d1Lisp-Z3\u5de5\u5177\uff0c\u4f7f\u5176\u80fd\u5728Common Lisp\u4e2d\u4f7f\u7528Z3\u548cACL2/s\uff0c\u5e76\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u5982\u6570\u72ec\u6c42\u89e3\u3001\u5b57\u7b26\u4e32\u6c42\u89e3\u548c\u786c\u4ef6\u5728\u73af\u6d4b\u8bd5\u3002", "result": "Lisp-Z3\u5728\u591a\u4e2a\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f8b\u5982\u5b57\u7b26\u4e32\u6c42\u89e3\u5668SeqSolve\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e14\u5728\u786c\u4ef6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "Lisp-Z3\u6210\u529f\u6574\u5408\u4e86Z3\u548cACL2/s\uff0c\u5c55\u793a\u4e86\u5176\u5728\u81ea\u52a8\u5316\u652f\u6301\u548c\u9ad8\u6548\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u672a\u6765\u8ba1\u5212\u8fdb\u4e00\u6b65\u4f18\u5316\u4f9d\u8d56\u7c7b\u578b\u7684\u652f\u6301\u3002"}}
{"id": "2507.19390", "pdf": "https://arxiv.org/pdf/2507.19390", "abs": "https://arxiv.org/abs/2507.19390", "authors": ["Altaf Allah Abbassi", "Leuson Da Silva", "Amin Nikanjam", "Foutse Khomh"], "title": "ReCatcher: Towards LLMs Regression Testing for Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": "24 pages, 3 Figures, 2 Tables", "summary": "Large Language Models (LLMs) for code generation evolve rapidly through\nfine-tuning, merging, or new model releases. However, such updates can\nintroduce regressions, not only in correctness but also in code quality and\nperformance. To address this, we present ReCatcher, a regression testing\nframework for Python code generation. ReCatcher systematically compares two\nLLMs, typically a current model and a candidate update, across three\ndimensions: logical correctness, static code quality, and execution\nperformance. We apply ReCatcher to assess regressions across three update\nscenarios, fine-tuning, merging, and model release, using CodeLlama,\nDeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with\ncross-language datasets increases syntax errors by up to 12%. Merging with\ngeneral-purpose models like Llama2 leads to regressions in correctness by up to\n18%. GPT-4o introduces regressions of up to 50% in handling missing imports\ncompared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance\ndegradation in execution time versus GPT-4o. Overall, logical correctness,\nperformance, and error handling (e.g., syntax errors and missing imports) are\nthe most regression-prone areas. Comparing ReCatcher with baseline solutions,\nit presents better and consistent accuracy across logical and performance\naspects. ReCatcher highlights the importance of systematic regression\nevaluation before adopting new models, while assisting researchers and\npractitioners in making more informed update decisions.", "AI": {"tldr": "ReCatcher\u662f\u4e00\u4e2a\u7528\u4e8ePython\u4ee3\u7801\u751f\u6210\u7684\u56de\u5f52\u6d4b\u8bd5\u6846\u67b6\uff0c\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e24\u79cdLLM\u5728\u903b\u8f91\u6b63\u786e\u6027\u3001\u9759\u6001\u4ee3\u7801\u8d28\u91cf\u548c\u6267\u884c\u6027\u80fd\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u6a21\u578b\u66f4\u65b0\u53ef\u80fd\u5f15\u53d1\u56de\u5f52\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLM\u7684\u5feb\u901f\u66f4\u65b0\uff08\u5982\u5fae\u8c03\u3001\u5408\u5e76\u6216\u65b0\u53d1\u5e03\uff09\uff0c\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u548c\u6027\u80fd\u53ef\u80fd\u9000\u6b65\uff0c\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u8fd9\u4e9b\u56de\u5f52\u3002", "method": "\u63d0\u51faReCatcher\u6846\u67b6\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e24\u79cdLLM\u5728\u903b\u8f91\u6b63\u786e\u6027\u3001\u9759\u6001\u4ee3\u7801\u8d28\u91cf\u548c\u6267\u884c\u6027\u80fd\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u6a21\u578b\u66f4\u65b0\u662f\u5426\u5f15\u5165\u56de\u5f52\u3002\u8bc4\u4f30\u4e86CodeLlama\u3001DeepSeek-Coder\u548cGPT-4o\u7b49\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u5fae\u8c03\u3001\u5408\u5e76\u6216\u65b0\u6a21\u578b\u53d1\u5e03\u53ef\u80fd\u5bfc\u81f4\u8bed\u6cd5\u9519\u8bef\u589e\u52a0\uff08\u9ad8\u8fbe12%\uff09\u3001\u6b63\u786e\u6027\u4e0b\u964d\uff08\u9ad8\u8fbe18%\uff09\uff0c\u6216\u6027\u80fd\u9000\u5316\uff08\u5982GPT-4o-mini\u6bd4GPT-4o\u616280%\uff09\u3002ReCatcher\u5728\u903b\u8f91\u548c\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "ReCatcher\u5f3a\u8c03\u5728\u91c7\u7528\u65b0\u6a21\u578b\u524d\u7cfb\u7edf\u6027\u8bc4\u4f30\u56de\u5f52\u95ee\u9898\u7684\u91cd\u8981\u6027\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u548c\u5f00\u53d1\u8005\u505a\u51fa\u66f4\u660e\u667a\u7684\u66f4\u65b0\u51b3\u7b56\u3002"}}
{"id": "2507.18877", "pdf": "https://arxiv.org/pdf/2507.18877", "abs": "https://arxiv.org/abs/2507.18877", "authors": ["Hongyu Zhou", "Yihao Dong", "Masahiko Inami", "Zhanna Sarsenbayeva", "Anusha Withana"], "title": "A Survey on Methodological Approaches to Collaborative Embodiment in Virtual Reality", "categories": ["cs.HC"], "comment": null, "summary": "The application and implementation of collaborative embodiment in virtual\nreality (VR) are a critical aspect of the computer science landscape, aiming to\nenhance multi-user interaction and teamwork in immersive environments. A\nnotable and enduring area of collaborative embodiment research focuses on\napproaches that enable multiple users to share control, interact, and\ninvestigate scenarios involving supernumerary arms in virtual spaces. In this\nsurvey, we will present an extensive overview of the methodologies employed in\nthe past decade to enable collaboration in VR environments, particularly\nthrough embodiment. Using the PRISMA guidelines, we plan to analyze the study\ndetails from over 137 relevant research papers. Through this analysis, a\ncritical assessment of the effectiveness of these methodologies will be\nconducted, highlighting current challenges and limitations in implementing\ncollaborative embodiment in VR. Lastly, we discuss potential future research\ndirections and opportunities for enhancing collaboration embodiment in virtual\nenvironments.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86\u8fc7\u53bb\u5341\u5e74\u4e2d\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u4e2d\u534f\u4f5c\u4f53\u73b0\u7684\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u4e86137\u7bc7\u76f8\u5173\u8bba\u6587\uff0c\u8bc4\u4f30\u4e86\u5176\u6709\u6548\u6027\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u534f\u4f5c\u4f53\u73b0\u5728VR\u4e2d\u589e\u5f3a\u591a\u7528\u6237\u4ea4\u4e92\u548c\u56e2\u961f\u5408\u4f5c\uff0c\u7279\u522b\u662f\u5171\u4eab\u63a7\u5236\u548c\u8d85\u6570\u624b\u81c2\u7684\u4ea4\u4e92\u573a\u666f\u3002", "method": "\u91c7\u7528PRISMA\u6307\u5357\u5bf9137\u7bc7\u8bba\u6587\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u6bd4\u8f83\u548c\u8bc4\u4f30\u4e0d\u540c\u7684\u534f\u4f5c\u4f53\u73b0\u65b9\u6cd5\u3002", "result": "\u603b\u7ed3\u51fa\u5f53\u524d\u534f\u4f5c\u4f53\u73b0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3001\u6311\u6218\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u534f\u4f5c\u4f53\u73b0\u5728VR\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u63d0\u5347\u591a\u7528\u6237\u4ea4\u4e92\u4f53\u9a8c\u3002"}}
{"id": "2507.19055", "pdf": "https://arxiv.org/pdf/2507.19055", "abs": "https://arxiv.org/abs/2507.19055", "authors": ["Yuksel Arslan"], "title": "Virtual local area network over HTTP for launching an insider attack", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "Computers and computer networks have become integral to virtually every\naspect of modern life, with the Internet playing an indispensable role.\nOrganizations, businesses, and individuals now store vast amounts of\nproprietary, confidential, and personal data digitally. As such, ensuring the\nsecurity of this data from unauthorized access is critical. Common security\nmeasures, such as firewalls, intrusion detection systems (IDS), intrusion\nprevention systems (IPS), and antivirus software, are constantly evolving to\nsafeguard computer systems and networks. However, these tools primarily focus\non defending against external threats, leaving systems vulnerable to insider\nattacks. Security solutions designed to mitigate risks originating from within\nthe organization are relatively limited and often ineffective. This paper\ndemonstrates how a Local Area Network (LAN) can be covertly exposed to the\nInternet via an insider attack. Specifically, it illustrates how an external\nmachine can gain access to a LAN by exploiting an unused secondary IP address\nof the attacked LAN, effectively bypassing existing security mechanisms by also\nexploiting Hyper Text Transfer Protocol (HTTP). Despite the presence of robust\nexternal protections, such as firewalls and IDS, this form of insider attack\nreveals significant vulnerabilities in the way internal threats are addressed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5c40\u57df\u7f51\uff08LAN\uff09\u4e2d\u5185\u90e8\u653b\u51fb\u7684\u6f0f\u6d1e\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5229\u7528\u672a\u4f7f\u7528\u7684\u4e8c\u7ea7IP\u5730\u5740\u548cHTTP\u534f\u8bae\uff0c\u7ed5\u8fc7\u73b0\u6709\u5b89\u5168\u673a\u5236\uff0c\u66b4\u9732LAN\u5230\u4e92\u8054\u7f51\u3002", "motivation": "\u73b0\u4ee3\u751f\u6d3b\u4e2d\uff0c\u8ba1\u7b97\u673a\u548c\u7f51\u7edc\u5b58\u50a8\u4e86\u5927\u91cf\u654f\u611f\u6570\u636e\uff0c\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u4e3b\u8981\u9632\u5fa1\u5916\u90e8\u5a01\u80c1\uff0c\u5bf9\u5185\u90e8\u653b\u51fb\u7684\u9632\u62a4\u4e0d\u8db3\uff0c\u4e9f\u9700\u7814\u7a76\u5185\u90e8\u653b\u51fb\u7684\u6f0f\u6d1e\u3002", "method": "\u901a\u8fc7\u5229\u7528LAN\u4e2d\u672a\u4f7f\u7528\u7684\u4e8c\u7ea7IP\u5730\u5740\u548cHTTP\u534f\u8bae\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5185\u90e8\u653b\u51fb\u65b9\u5f0f\uff0c\u5c55\u793a\u4e86\u5916\u90e8\u673a\u5668\u5982\u4f55\u7ed5\u8fc7\u9632\u706b\u5899\u548cIDS\u8bbf\u95eeLAN\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u5b58\u5728\u5f3a\u5927\u7684\u5916\u90e8\u9632\u62a4\u63aa\u65bd\uff0c\u5185\u90e8\u653b\u51fb\u4ecd\u80fd\u6210\u529f\u66b4\u9732LAN\uff0c\u63ed\u793a\u73b0\u6709\u5b89\u5168\u673a\u5236\u5bf9\u5185\u90e8\u5a01\u80c1\u7684\u9632\u62a4\u4e0d\u8db3\u3002", "conclusion": "\u5185\u90e8\u653b\u51fb\u5bf9LAN\u7684\u5b89\u5168\u6027\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u9700\u52a0\u5f3a\u5bf9\u5185\u90e8\u5a01\u80c1\u7684\u9632\u62a4\uff0c\u672a\u6765\u7814\u7a76\u5e94\u8fdb\u4e00\u6b65\u63a2\u7d22\u6b64\u7c7b\u6f0f\u6d1e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19061", "pdf": "https://arxiv.org/pdf/2507.19061", "abs": "https://arxiv.org/abs/2507.19061", "authors": ["Alice Tarzariol", "Marco Maratea", "Mauro Vallati"], "title": "A CASP-based Solution for Traffic Signal Optimisation", "categories": ["cs.LO"], "comment": "To appear in Theory and Practice of Logic Programming (TPLP),\n  Proceedings of ICLP 2025", "summary": "In the context of urban traffic control, traffic signal optimisation is the\nproblem of determining the optimal green length for each signal in a set of\ntraffic signals. The literature has effectively tackled such a problem, mostly\nwith automated planning techniques leveraging the PDDL+ language and solvers.\nHowever, such language has limitations when it comes to specifying optimisation\nstatements and computing optimal plans. In this paper, we provide an\nalternative solution to the traffic signal optimisation problem based on\nConstraint Answer Set Programming (CASP). We devise an encoding in a CASP\nlanguage, which is then solved by means of clingcon 3, a system extending the\nwell-known ASP solver clingo. We performed experiments on real historical data\nfrom the town of Huddersfield in the UK, comparing our approach to the PDDL+\nmodel that obtained the best results for the considered benchmark. The results\nshowed the potential of our approach for tackling the traffic signal\noptimisation problem and improving the solution quality of the PDDL+ plans.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u7b54\u6848\u96c6\u7f16\u7a0b\uff08CASP\uff09\u7684\u4ea4\u901a\u4fe1\u53f7\u4f18\u5316\u65b9\u6cd5\uff0c\u4f18\u4e8e\u73b0\u6709\u7684PDDL+\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709PDDL+\u8bed\u8a00\u5728\u4ea4\u901a\u4fe1\u53f7\u4f18\u5316\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528CASP\u8bed\u8a00\u7f16\u7801\u4ea4\u901a\u4fe1\u53f7\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7clingcon 3\u6c42\u89e3\u5668\u6c42\u89e3\u3002", "result": "\u5b9e\u9a8c\u57fa\u4e8e\u771f\u5b9e\u5386\u53f2\u6570\u636e\uff0cCASP\u65b9\u6cd5\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u4e0a\u4f18\u4e8ePDDL+\u6a21\u578b\u3002", "conclusion": "CASP\u65b9\u6cd5\u5728\u4ea4\u901a\u4fe1\u53f7\u4f18\u5316\u4e2d\u5c55\u73b0\u4e86\u6f5c\u529b\uff0c\u53ef\u63d0\u5347\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u3002"}}
{"id": "2507.19403", "pdf": "https://arxiv.org/pdf/2507.19403", "abs": "https://arxiv.org/abs/2507.19403", "authors": ["Matthias Wei\u00df", "Falk Dettinger", "Michael Weyrich"], "title": "SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions", "categories": ["cs.SE", "cs.AI", "cs.DC", "B.8.2; C.2.4"], "comment": "7 pages, 5 figures", "summary": "Connected and software-defined vehicles promise to offer a broad range of\nservices and advanced functions to customers, aiming to increase passenger\ncomfort and support autonomous driving capabilities. Due to the high\nreliability and availability requirements of connected vehicles, it is crucial\nto resolve any occurring failures quickly. To achieve this however, a complex\ncloud/edge architecture with a mesh of dependencies must be navigated to\ndiagnose the responsible root cause. As such, manual analyses become unfeasible\nsince they would significantly delay the troubleshooting.\n  To address this challenge, this paper presents SDVDiag, an extensible\nplatform for the automated diagnosis of connected vehicle functions. The\nplatform enables the creation of pipelines that cover all steps from initial\ndata collection to the tracing of potential root causes. In addition, SDVDiag\nsupports self-adaptive behavior by the ability to exchange modules at runtime.\nDependencies between functions are detected and continuously updated, resulting\nin a dynamic graph view of the system. In addition, vital system metrics are\nmonitored for anomalies. Whenever an incident is investigated, a snapshot of\nthe graph is taken and augmented by relevant anomalies. Finally, the analysis\nis performed by traversing the graph and creating a ranking of the most likely\ncauses.\n  To evaluate the platform, it is deployed inside an 5G test fleet environment\nfor connected vehicle functions. The results show that injected faults can be\ndetected reliably. As such, the platform offers the potential to gain new\ninsights and reduce downtime by identifying problems and their causes at an\nearly stage.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSDVDiag\u7684\u53ef\u6269\u5c55\u5e73\u53f0\uff0c\u7528\u4e8e\u81ea\u52a8\u8bca\u65ad\u8054\u7f51\u8f66\u8f86\u529f\u80fd\uff0c\u901a\u8fc7\u52a8\u6001\u56fe\u5f62\u89c6\u56fe\u548c\u81ea\u52a8\u5316\u6d41\u7a0b\u5feb\u901f\u5b9a\u4f4d\u6545\u969c\u6839\u6e90\u3002", "motivation": "\u8054\u7f51\u8f66\u8f86\u7684\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u8981\u6c42\u9700\u8981\u5feb\u901f\u89e3\u51b3\u6545\u969c\uff0c\u4f46\u590d\u6742\u7684\u4e91/\u8fb9\u7f18\u67b6\u6784\u4f7f\u5f97\u624b\u52a8\u5206\u6790\u53d8\u5f97\u4e0d\u53ef\u884c\u3002", "method": "SDVDiag\u5e73\u53f0\u652f\u6301\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u8fd0\u884c\u65f6\u6a21\u5757\u4ea4\u6362\uff0c\u6784\u5efa\u52a8\u6001\u7cfb\u7edf\u56fe\u5f62\u89c6\u56fe\uff0c\u5e76\u901a\u8fc7\u5f02\u5e38\u76d1\u63a7\u548c\u56fe\u5f62\u904d\u5386\u5206\u6790\u6545\u969c\u539f\u56e0\u3002", "result": "\u57285G\u6d4b\u8bd5\u8f66\u961f\u73af\u5883\u4e2d\u90e8\u7f72\u540e\uff0c\u5e73\u53f0\u80fd\u591f\u53ef\u9760\u68c0\u6d4b\u6ce8\u5165\u7684\u6545\u969c\uff0c\u63d0\u524d\u53d1\u73b0\u548c\u89e3\u51b3\u95ee\u9898\u3002", "conclusion": "SDVDiag\u5e73\u53f0\u80fd\u591f\u663e\u8457\u51cf\u5c11\u6545\u969c\u6392\u67e5\u65f6\u95f4\uff0c\u63d0\u5347\u8054\u7f51\u8f66\u8f86\u7684\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2507.18878", "pdf": "https://arxiv.org/pdf/2507.18878", "abs": "https://arxiv.org/abs/2507.18878", "authors": ["Lillian Asiala", "James E. McCarthy"], "title": "Improving the State of the Art for Training Human-AI Teams: Technical Report #5 -- Individual Differences and Team Qualities to Measure in a Human-AI Teaming Testbed", "categories": ["cs.HC"], "comment": null, "summary": "Sonalysts, Inc. (Sonalysts) is working on an initiative to expand our\nexpertise in teaming to include Human-Artificial Intelligence (AI) teams. The\nfirst step of this process is to develop a Synthetic Task Environment (STE) to\nsupport our original research. Prior knowledge elicitation efforts within the\nHuman-AI teaming research stakeholder community revealed a desire to support\ndata collection using pre- and post-performance surveys. In this technical\nreport, we review a number of constructs that capture meaningful individual\ndifferences and teaming qualities. Additionally, we explore methods of\nmeasuring those constructs within the STE.", "AI": {"tldr": "Sonalysts\u516c\u53f8\u8ba1\u5212\u6269\u5c55\u5176\u5728\u4eba\u7c7b\u4e0e\u4eba\u5de5\u667a\u80fd\u56e2\u961f\u5408\u4f5c\uff08Human-AI teaming\uff09\u9886\u57df\u7684\u7814\u7a76\uff0c\u9996\u5148\u5f00\u53d1\u4e86\u4e00\u4e2a\u5408\u6210\u4efb\u52a1\u73af\u5883\uff08STE\uff09\u4ee5\u652f\u6301\u6570\u636e\u6536\u96c6\uff0c\u91cd\u70b9\u5173\u6ce8\u4e2a\u4f53\u5dee\u5f02\u548c\u56e2\u961f\u534f\u4f5c\u8d28\u91cf\u7684\u6d4b\u91cf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4eba\u7c7b\u4e0e\u4eba\u5de5\u667a\u80fd\u56e2\u961f\u5408\u4f5c\u7684\u7814\u7a76\u9700\u8981\u66f4\u6709\u6548\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u6765\u652f\u6301\u6570\u636e\u6536\u96c6\u548c\u5206\u6790\uff0c\u4ee5\u63d0\u5347\u56e2\u961f\u534f\u4f5c\u6548\u679c\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u5408\u6210\u4efb\u52a1\u73af\u5883\uff08STE\uff09\uff0c\u5e76\u7ed3\u5408\u524d\u540e\u6d4b\u8bd5\u8c03\u67e5\u7684\u65b9\u6cd5\uff0c\u63a2\u7d22\u4e2a\u4f53\u5dee\u5f02\u548c\u56e2\u961f\u534f\u4f5c\u8d28\u91cf\u7684\u6d4b\u91cf\u5de5\u5177\u3002", "result": "\u7814\u7a76\u62a5\u544a\u4e86\u591a\u79cd\u6355\u83b7\u4e2a\u4f53\u5dee\u5f02\u548c\u56e2\u961f\u534f\u4f5c\u8d28\u91cf\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982\u4f55\u5728STE\u4e2d\u5b9e\u65bd\u8fd9\u4e9b\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aHuman-AI\u56e2\u961f\u5408\u4f5c\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u636e\u6536\u96c6\u548c\u5206\u6790\u7684\u6846\u67b6\uff0c\u652f\u6301\u672a\u6765\u7684\u5b9e\u8bc1\u7814\u7a76\u3002"}}
{"id": "2507.19173", "pdf": "https://arxiv.org/pdf/2507.19173", "abs": "https://arxiv.org/abs/2507.19173", "authors": ["Lorenzo Cazzella", "Francesco Linsalata", "Damiano Badini", "Matteo Matteucci", "Maurizio Magarini", "Umberto Spagnolini"], "title": "High-Fidelity RF Mapping: Assessing Environmental Modeling in 6G Network Digital Twins", "categories": ["eess.SP", "cs.NI"], "comment": null, "summary": "The design of accurate Digital Twins (DTs) of electromagnetic environments\nstrictly depends on the fidelity of the underlying environmental modeling.\nEvaluating the differences among diverse levels of modeling accuracy is key to\ndetermine the relevance of the model features towards both efficient and\naccurate DT simulations. In this paper, we propose two metrics, the Hausdorff\nray tracing (HRT) and chamfer ray tracing (CRT) distances, to consistently\ncompare the temporal, angular and power features between two ray tracing\nsimulations performed on 3D scenarios featured by environmental changes. To\nevaluate the introduced metrics, we considered a high-fidelity digital twin\nmodel of an area of Milan, Italy and we enriched it with two different types of\nenvironmental changes: (i) the inclusion of parked vehicles meshes, and (ii)\nthe segmentation of the buildings facade faces to separate the windows mesh\ncomponents from the rest of the building. We performed grid-based and vehicular\nray tracing simulations at 28 GHz carrier frequency on the obtained scenarios\nintegrating the NVIDIA Sionna RT ray tracing simulator with the SUMO vehicular\ntraffic simulator. Both the HRT and CRT metrics highlighted the areas of the\nscenarios where the simulated radio propagation features differ owing to the\nintroduced mesh integrations, while the vehicular ray tracing simulations\nallowed to uncover the distance patterns arising along realistic vehicular\ntrajectories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u5ea6\u91cf\u6807\u51c6\uff08HRT\u548cCRT\uff09\uff0c\u7528\u4e8e\u6bd4\u8f83\u4e0d\u540c\u73af\u5883\u53d8\u5316\u4e0b\u5c04\u7ebf\u8ffd\u8e2a\u6a21\u62df\u7684\u5dee\u5f02\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63d0\u9ad8\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u7684\u51c6\u786e\u6027\u9700\u8981\u8bc4\u4f30\u73af\u5883\u5efa\u6a21\u7684\u4fdd\u771f\u5ea6\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u91cf\u5316\u65b9\u6cd5\u6765\u6bd4\u8f83\u4e0d\u540c\u6a21\u62df\u7ed3\u679c\u7684\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86Hausdorff\u5c04\u7ebf\u8ffd\u8e2a\uff08HRT\uff09\u548cchamfer\u5c04\u7ebf\u8ffd\u8e2a\uff08CRT\uff09\u4e24\u79cd\u8ddd\u79bb\u5ea6\u91cf\uff0c\u57283D\u573a\u666f\u4e2d\u6bd4\u8f83\u65f6\u95f4\u3001\u89d2\u5ea6\u548c\u529f\u7387\u7279\u5f81\u3002\u5b9e\u9a8c\u4f7f\u7528\u9ad8\u4fdd\u771f\u7c73\u5170\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u505c\u8f66\u8f66\u8f86\u548c\u5efa\u7b51\u7a97\u6237\u7684\u7f51\u683c\u53d8\u5316\uff0c\u7ed3\u5408NVIDIA Sionna\u548cSUMO\u8fdb\u884c\u6a21\u62df\u3002", "result": "HRT\u548cCRT\u6210\u529f\u8bc6\u522b\u4e86\u6a21\u62df\u4e2d\u7684\u5dee\u5f02\u533a\u57df\uff0c\u8f66\u8f86\u8f68\u8ff9\u6a21\u62df\u63ed\u793a\u4e86\u8ddd\u79bb\u6a21\u5f0f\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u91cf\u5316\u73af\u5883\u53d8\u5316\u5bf9\u5c04\u7ebf\u8ffd\u8e2a\u6a21\u62df\u7684\u5f71\u54cd\uff0c\u4e3a\u6570\u5b57\u5b6a\u751f\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u5de5\u5177\u3002"}}
{"id": "2507.19245", "pdf": "https://arxiv.org/pdf/2507.19245", "abs": "https://arxiv.org/abs/2507.19245", "authors": ["Faruk Alpay", "Bugra Kilictas", "Taylan Alpay"], "title": "Transfinite Fixed Points in Alpay Algebra as Ordinal Game Equilibria in Dependent Type Theory", "categories": ["cs.LO", "cs.AI", "68T27, 03B70, 68Q55"], "comment": "21 pages, 1 figure", "summary": "This paper contributes to the Alpay Algebra by demonstrating that the stable\noutcome of a self referential process, obtained by iterating a transformation\nthrough all ordinal stages, is identical to the unique equilibrium of an\nunbounded revision dialogue between a system and its environment. The analysis\ninitially elucidates how classical fixed point theorems guarantee such\nconvergence in finite settings and subsequently extends the argument to the\ntransfinite domain, relying upon well founded induction and principles of order\ntheoretic continuity.\n  Furthermore, the resulting transordinal fixed point operator is embedded into\ndependent type theory, a formalization which permits every step of the\ntransfinite iteration and its limit to be verified within a modern proof\nassistant. This procedure yields a machine checked proof that the iterative\ndialogue necessarily stabilizes and that its limit is unique. The result\nprovides a foundation for Alpay's philosophical claim of semantic convergence\nwithin the framework of constructive logic. By unifying concepts from fixed\npoint theory, game semantics, ordinal analysis, and type theory, this research\nestablishes a broadly accessible yet formally rigorous foundation for reasoning\nabout infinite self referential systems and offers practical tools for\ncertifying their convergence within computational environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u8fed\u4ee3\u53d8\u6362\u5c55\u793a\u4e86Alpay\u4ee3\u6570\u4e2d\u81ea\u6307\u8fc7\u7a0b\u7684\u7a33\u5b9a\u7ed3\u679c\u4e0e\u65e0\u754c\u4fee\u8ba2\u5bf9\u8bdd\u7684\u552f\u4e00\u5747\u8861\u76f8\u540c\uff0c\u5e76\u901a\u8fc7\u7c7b\u578b\u7406\u8bba\u9a8c\u8bc1\u4e86\u5176\u6536\u655b\u6027\u3002", "motivation": "\u4e3aAlpay\u5173\u4e8e\u8bed\u4e49\u6536\u655b\u7684\u54f2\u5b66\u4e3b\u5f20\u63d0\u4f9b\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u5e76\u4e3a\u65e0\u9650\u81ea\u6307\u7cfb\u7edf\u7684\u7814\u7a76\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002", "method": "\u7ed3\u5408\u4e0d\u52a8\u70b9\u5b9a\u7406\u3001\u5e8f\u8bba\u8fde\u7eed\u6027\u548c\u4f9d\u8d56\u7c7b\u578b\u7406\u8bba\uff0c\u9a8c\u8bc1\u4e86\u81ea\u6307\u8fc7\u7a0b\u7684\u6536\u655b\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u8fed\u4ee3\u5bf9\u8bdd\u5fc5\u7136\u7a33\u5b9a\u4e14\u6781\u9650\u552f\u4e00\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u9a8c\u8bc1\u652f\u6301\u4e86\u8fd9\u4e00\u7ed3\u8bba\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u65e0\u9650\u81ea\u6307\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u5206\u6790\u548c\u8ba1\u7b97\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u4e25\u8c28\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2507.19446", "pdf": "https://arxiv.org/pdf/2507.19446", "abs": "https://arxiv.org/abs/2507.19446", "authors": ["Matthias Wei\u00df", "Anish Navalgund", "Johannes St\u00fcmpfle", "Falk Dettinger", "Michael Weyrich"], "title": "An OpenSource CI/CD Pipeline for Variant-Rich Software-Defined Vehicles", "categories": ["cs.SE", "cs.DC", "B.8.2; C.2.4"], "comment": "7 pages, 5 figures", "summary": "Software-defined vehicles (SDVs) offer a wide range of connected\nfunctionalities, including enhanced driving behavior and fleet management.\nThese features are continuously updated via over-the-air (OTA) mechanisms,\nresulting in a growing number of software versions and variants due to the\ndiversity of vehicles, cloud/edge environments, and stakeholders involved. The\nlack of a unified integration environment further complicates development, as\nconnected mobility solutions are often built in isolation. To ensure reliable\noperations across heterogeneous systems, a dynamic orchestration of functions\nthat considers hardware and software variability is essential. This paper\npresents an open-source CI/CD pipeline tailored for SDVs. It automates the\nbuild, test, and deployment phases using a combination of containerized\nopen-source tools, creating a standardized, portable, and scalable ecosystem\naccessible to all stakeholders. Additionally, a custom OTA middleware\ndistributes software updates and supports rollbacks across vehicles and backend\nservices. Update variants are derived based on deployment target dependencies\nand hardware configurations. The pipeline also supports continuous development\nand deployment of AI models for autonomous driving features. Its effectiveness\nis evaluated using an automated valet parking (AVP) scenario involving\nTurtleBots and a coordinating backend server. Two object detection variants are\ndeveloped and deployed to match hardware-specific requirements. Results\ndemonstrate seamless OTA updates, correct variant selection, and successful\norchestration across all targets. Overall, the proposed pipeline provides a\nscalable and efficient solution for managing software variants and OTA updates\nin SDVs, contributing to the advancement of future mobility technologies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f00\u6e90CI/CD\u7ba1\u9053\uff0c\u4e13\u4e3a\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\uff08SDV\uff09\u8bbe\u8ba1\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u6784\u5efa\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\u6d41\u7a0b\u89e3\u51b3\u8f6f\u4ef6\u7248\u672c\u548c\u53d8\u4f53\u7ba1\u7406\u7684\u590d\u6742\u6027\uff0c\u5e76\u652f\u6301OTA\u66f4\u65b0\u548cAI\u6a21\u578b\u7684\u6301\u7eed\u5f00\u53d1\u3002", "motivation": "\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u591a\u6837\u5316\u7684\u8f6f\u4ef6\u7248\u672c\u548c\u53d8\u4f53\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u96c6\u6210\u73af\u5883\uff0c\u5bfc\u81f4\u5f00\u53d1\u590d\u6742\u5316\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u52a8\u6001\u7f16\u6392\u529f\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u786e\u4fdd\u5f02\u6784\u7cfb\u7edf\u95f4\u7684\u53ef\u9760\u8fd0\u884c\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f00\u6e90\u7684CI/CD\u7ba1\u9053\uff0c\u5229\u7528\u5bb9\u5668\u5316\u5f00\u6e90\u5de5\u5177\u81ea\u52a8\u5316\u6784\u5efa\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\u8fc7\u7a0b\u3002\u8fd8\u5305\u62ec\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684OTA\u4e2d\u95f4\u4ef6\uff0c\u7528\u4e8e\u5206\u53d1\u8f6f\u4ef6\u66f4\u65b0\u548c\u652f\u6301\u56de\u6eda\uff0c\u5e76\u6839\u636e\u90e8\u7f72\u76ee\u6807\u4f9d\u8d56\u548c\u786c\u4ef6\u914d\u7f6e\u751f\u6210\u53d8\u4f53\u3002\u6b64\u5916\uff0c\u652f\u6301AI\u6a21\u578b\u7684\u6301\u7eed\u5f00\u53d1\u548c\u90e8\u7f72\u3002", "result": "\u901a\u8fc7\u5728\u81ea\u52a8\u4ee3\u5ba2\u6cca\u8f66\uff08AVP\uff09\u573a\u666f\u4e2d\u7684\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u65e0\u7f1d\u7684OTA\u66f4\u65b0\u3001\u6b63\u786e\u7684\u53d8\u4f53\u9009\u62e9\u4ee5\u53ca\u8de8\u6240\u6709\u76ee\u6807\u7684\u6210\u529f\u7f16\u6392\u3002\u6210\u529f\u5f00\u53d1\u5e76\u90e8\u7f72\u4e86\u4e24\u79cd\u786c\u4ef6\u7279\u5b9a\u7684\u5bf9\u8c61\u68c0\u6d4b\u53d8\u4f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ba1\u9053\u4e3a\u7ba1\u7406SDV\u4e2d\u7684\u8f6f\u4ef6\u53d8\u4f53\u548cOTA\u66f4\u65b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u672a\u6765\u79fb\u52a8\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.19432", "pdf": "https://arxiv.org/pdf/2507.19432", "abs": "https://arxiv.org/abs/2507.19432", "authors": ["Sheikh Shadab Towqir", "Fei He", "Todd Mytkowicz", "Na Meng"], "title": "Resolving Build Conflicts via Example-Based and Rule-Based Program Transformations", "categories": ["cs.SE"], "comment": null, "summary": "Merge conflicts often arise when developers integrate changes from different\nsoftware branches. The conflicts can result from overlapping edits in programs\n(i.e., textual conflicts) or cause build and test errors (i.e., build and test\nconflicts). They degrade software quality and hinder programmer productivity.\nWhile several tools detect build conflicts, few offer meaningful support for\nresolving cases like those caused by method removal. To overcome limitations of\nexisting tools, we introduce BUCOR (Build Conflict Resolver), a new conflict\nresolver. BUCOR first detects conflicts by comparing three versions related to\na merging scenario: base b, left l, and right r. To resolve conflicts, it\nemploys two complementary strategies: example-based transformation (BUCOR-E)\nand rule-based transformation (BUCOR-R). BUCOR-R applies predefined rules to\nhandle common, well-understood conflicts. BUCOR-E mines branch versions (l and\nr) for exemplar edits applied to fix related build errors. From these examples,\nit infers and generalizes program transformation patterns to resolve more\ncomplex conflicts.\n  We evaluated BUCOR on 88 real-world build conflicts spanning 21 distinct\nconflict types. BUCOR generated at least one solution for 65 cases and\ncorrectly resolved 43 conflicts. We observed that this hybrid\napproach--combining context-aware, example-based learning with structured,\nrule-based resolution--can effectively help resolve conflicts. Our research\nsheds light on future directions for more intelligent and automated merge\ntools.", "AI": {"tldr": "BUCOR\u662f\u4e00\u79cd\u89e3\u51b3\u6784\u5efa\u51b2\u7a81\u7684\u65b0\u5de5\u5177\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8e\u793a\u4f8b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u7b56\u7565\uff0c\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u51b2\u7a81\u3002", "motivation": "\u5408\u5e76\u51b2\u7a81\u4f1a\u964d\u4f4e\u8f6f\u4ef6\u8d28\u91cf\u548c\u5f00\u53d1\u6548\u7387\uff0c\u73b0\u6709\u5de5\u5177\u5728\u89e3\u51b3\u67d0\u4e9b\u51b2\u7a81\uff08\u5982\u65b9\u6cd5\u79fb\u9664\uff09\u65b9\u9762\u652f\u6301\u6709\u9650\u3002", "method": "BUCOR\u901a\u8fc7\u6bd4\u8f83\u4e09\u4e2a\u7248\u672c\uff08base\u3001left\u3001right\uff09\u68c0\u6d4b\u51b2\u7a81\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u793a\u4f8b\uff08BUCOR-E\uff09\u548c\u57fa\u4e8e\u89c4\u5219\uff08BUCOR-R\uff09\u7684\u7b56\u7565\u89e3\u51b3\u51b2\u7a81\u3002", "result": "\u572888\u4e2a\u771f\u5b9e\u6784\u5efa\u51b2\u7a81\u4e2d\uff0cBUCOR\u4e3a65\u4e2a\u6848\u4f8b\u751f\u6210\u4e86\u81f3\u5c11\u4e00\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6b63\u786e\u89e3\u51b3\u4e8643\u4e2a\u51b2\u7a81\u3002", "conclusion": "\u7ed3\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u793a\u4f8b\u5b66\u4e60\u548c\u7ed3\u6784\u5316\u89c4\u5219\u89e3\u51b3\u7b56\u7565\u7684\u6df7\u5408\u65b9\u6cd5\u6709\u6548\uff0c\u4e3a\u672a\u6765\u66f4\u667a\u80fd\u7684\u5408\u5e76\u5de5\u5177\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.18880", "pdf": "https://arxiv.org/pdf/2507.18880", "abs": "https://arxiv.org/abs/2507.18880", "authors": ["Luca-Maxim Meinhardt", "Enrico Rukzio"], "title": "Rethinking Accessible Prototyping Methods for Blind and Visually Impaired Passengers in Highly Automated Vehicles", "categories": ["cs.HC"], "comment": "Workshop paper presented at \"Access InContext: Futuring Accessible\n  Prototyping Tools and Methods\", CHI'25, April 26, 2025, Yokohama, Japan.\n  Submitted Feb 5, accepted Mar 1", "summary": "Highly Automated Vehicles (HAVs) can improve mobility for blind and visually\nimpaired people (BVIPs). However, designing non-visual interfaces that enable\nthem to maintain situation awareness inside the vehicle is a challenge. This\npaper presents two of our participatory design workshops that explored what\ninformation BVIPs need in HAVs and what an interface that meets these needs\nmight look like. Based on the participants' insights, we created final systems\nto improve their situation awareness. The two workshops used different\napproaches: in the first, participants built their own low-fidelity prototypes;\nin the second, they evaluated and discussed the initial prototypes we provided.\nWe will outline how each workshop was set up and share lessons learned about\nprototyping methods for BVIPs and how they could be improved.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u4e3a\u975e\u89c6\u89c9\u754c\u9762\u8bbe\u8ba1\u63d0\u4f9b\u652f\u6301\uff0c\u4ee5\u63d0\u9ad8\u76f2\u4eba\u548c\u89c6\u969c\u4eba\u58eb\u5728\u9ad8\u5ea6\u81ea\u52a8\u5316\u8f66\u8f86\u4e2d\u7684\u60c5\u5883\u611f\u77e5\u80fd\u529b\uff0c\u901a\u8fc7\u4e24\u79cd\u4e0d\u540c\u7684\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u5de5\u4f5c\u574a\u65b9\u6cd5\u8fdb\u884c\u7814\u7a76\u3002", "motivation": "\u76f2\u4eba\u548c\u89c6\u969c\u4eba\u58eb\uff08BVIPs\uff09\u5728\u9ad8\u5ea6\u81ea\u52a8\u5316\u8f66\u8f86\uff08HAVs\uff09\u4e2d\u7684\u60c5\u5883\u611f\u77e5\u80fd\u529b\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u975e\u89c6\u89c9\u754c\u9762\u4ee5\u6ee1\u8db3\u4ed6\u4eec\u7684\u9700\u6c42\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86\u4e24\u79cd\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u5de5\u4f5c\u574a\uff1a\u7b2c\u4e00\u79cd\u8ba9\u53c2\u4e0e\u8005\u81ea\u884c\u6784\u5efa\u4f4e\u4fdd\u771f\u539f\u578b\uff0c\u7b2c\u4e8c\u79cd\u8ba9\u53c2\u4e0e\u8005\u8bc4\u4f30\u548c\u8ba8\u8bba\u9884\u5148\u63d0\u4f9b\u7684\u521d\u59cb\u539f\u578b\u3002", "result": "\u57fa\u4e8e\u53c2\u4e0e\u8005\u7684\u53cd\u9988\uff0c\u8bba\u6587\u6539\u8fdb\u4e86\u6700\u7ec8\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6848\uff0c\u5e76\u603b\u7ed3\u4e86\u9488\u5bf9BVIPs\u7684\u539f\u578b\u8bbe\u8ba1\u65b9\u6cd5\u7684\u7ecf\u9a8c\u3002", "conclusion": "\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u5de5\u4f5c\u574a\u662f\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u539f\u578b\u8bbe\u8ba1\u65b9\u6cd5\u4ee5\u66f4\u597d\u5730\u6ee1\u8db3BVIPs\u7684\u9700\u6c42\u3002"}}
{"id": "2507.19349", "pdf": "https://arxiv.org/pdf/2507.19349", "abs": "https://arxiv.org/abs/2507.19349", "authors": ["Lorenzo Mario Amorosa", "Francesco Conti", "Nicola Quercioli", "Flavio Zabini", "Tayebeh Lotfi Mahyari", "Yiqun Ge", "Patrizio Frosini"], "title": "Reconstruction of Sparse Urban Wireless Signals via Group Equivariant Non-Expansive Operators", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "In emerging communication systems such as sixth generation (6G) wireless\nnetworks, efficient resource management and service delivery rely on accurate\nknowledge of spatially-varying quantities like signal-to-interference-noise\nratio (SINR) maps, which are costly to acquire at high resolution. This work\nexplores the reconstruction of such spatial signals from sparse measurements\nusing Group Equivariant Non-Expansive Operators (GENEOs), offering a\nlow-complexity alternative to traditional neural networks. The concept of\nGENEO, which originated in topological data analysis (TDA), is a mathematical\ntool used in machine learning to represent agents modelled as functional\noperators acting on data while incorporating application-specific invariances.\nLeveraging these invariances reduces the number of parameters with respect to\ntraditional neural networks and mitigates data scarcity by enforcing known\nalgebraic and geometric constraints that reflect symmetries in the agents'\nactions. In this paper, we introduce a novel GENEO-based approach for SINR map\nreconstruction in urban wireless communication networks using extremely sparse\nsampling. We demonstrate that this mathematical framework achieves competitive\nperformance compared to established methods. Our evaluation, conducted using\nboth statistical and TDA metrics, highlights the advantages of our approach in\naccurately reconstructing spatial signals under severe data limitations on the\nnumber of samples.", "AI": {"tldr": "\u5229\u7528\u7fa4\u7b49\u53d8\u975e\u6269\u5f20\u7b97\u5b50\uff08GENEOs\uff09\u4ece\u7a00\u758f\u6d4b\u91cf\u4e2d\u91cd\u5efa6G\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u4fe1\u53f7\u5e72\u6270\u566a\u58f0\u6bd4\uff08SINR\uff09\u5730\u56fe\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u66f4\u9ad8\u6548\u4e14\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387SINR\u5730\u56fe\u83b7\u53d6\u6210\u672c\u9ad8\uff0c\u9700\u8981\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u65b9\u6cd5\u5728\u7a00\u758f\u6570\u636e\u4e0b\u51c6\u786e\u91cd\u5efa\u7a7a\u95f4\u4fe1\u53f7\u3002", "method": "\u91c7\u7528GENEOs\uff0c\u5229\u7528\u5176\u4ee3\u6570\u4e0e\u51e0\u4f55\u7ea6\u675f\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u5e76\u589e\u5f3a\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002", "result": "GENEOs\u5728\u7a00\u758f\u91c7\u6837\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u901a\u8fc7\u7edf\u8ba1\u548c\u62d3\u6251\u6570\u636e\u5206\u6790\u6307\u6807\u9a8c\u8bc1\u4e86\u5176\u7ade\u4e89\u529b\u3002", "conclusion": "GENEOs\u4e3a6G\u7f51\u7edc\u4e2d\u7a7a\u95f4\u4fe1\u53f7\u91cd\u5efa\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19424", "pdf": "https://arxiv.org/pdf/2507.19424", "abs": "https://arxiv.org/abs/2507.19424", "authors": ["Elena Di Lavore", "Mario Rom\u00e1n", "Pawe\u0142 Soboci\u0144ski", "M\u00e1rk Sz\u00e9les"], "title": "Order in Partial Markov Categories", "categories": ["cs.LO", "18M05"], "comment": "20 pages, MFPS 2025", "summary": "Partial Markov categories are a recent framework for categorical probability\ntheory, providing an abstract account of partial probabilistic computation. In\nthis article, we discuss two order relations on the morphisms of a partial\nMarkov category. In particular, we prove that every partial Markov category is\ncanonically enriched over the category of preordered sets and monotone maps. We\nshow that our construction recovers several well-known order enrichments. We\nalso demonstrate that the existence of codiagonal maps (comparators) is closely\nrelated to order properties of partial Markov categories. We propose a\nsynthetic version of the Cauchy-Schwarz inequality to facilitate inequational\nreasoning in partial Markov categories. We apply this new axiom to prove that\nupdating a prior distribution with an evidence predicate increases the\nlikelihood of the evidence in the posterior.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u4e2d\u7684\u4e24\u79cd\u5e8f\u5173\u7cfb\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u81ea\u7136\u5730\u4e30\u5bcc\u4e8e\u9884\u5e8f\u96c6\u8303\u7574\uff0c\u5e76\u63d0\u51fa\u4e86\u67ef\u897f-\u65bd\u74e6\u8328\u4e0d\u7b49\u5f0f\u7684\u5408\u6210\u7248\u672c\u3002", "motivation": "\u7814\u7a76\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u7684\u5e8f\u7ed3\u6784\u548c\u76f8\u5173\u6027\u8d28\uff0c\u4ee5\u6269\u5c55\u6982\u7387\u8ba1\u7b97\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u548c\u6bd4\u8f83\u4e24\u79cd\u5e8f\u5173\u7cfb\uff0c\u8bc1\u660e\u8303\u7574\u7684\u5e8f\u4e30\u5bcc\u6027\uff0c\u5e76\u63d0\u51fa\u5408\u6210\u4e0d\u7b49\u5f0f\u3002", "result": "\u8bc1\u660e\u4e86\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u7684\u5e8f\u4e30\u5bcc\u6027\uff0c\u5e76\u5e94\u7528\u65b0\u516c\u7406\u9a8c\u8bc1\u540e\u9a8c\u6982\u7387\u7684\u6027\u8d28\u3002", "conclusion": "\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u7684\u5e8f\u7ed3\u6784\u4e0e\u6982\u7387\u8ba1\u7b97\u5bc6\u5207\u76f8\u5173\uff0c\u4e3a\u7406\u8bba\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2507.18913", "pdf": "https://arxiv.org/pdf/2507.18913", "abs": "https://arxiv.org/abs/2507.18913", "authors": ["Eshta Bhardwaj", "Han Qiao", "Christoph Becker"], "title": "Limits at a Distance: Design Directions to Address Psychological Distance in Policy Decisions Affecting Planetary Boundaries", "categories": ["cs.HC"], "comment": "Post-proceedings paper presented at LIMITS 2024: 10th Workshop on\n  Computing within Limits, 2024-06-19/20, Online", "summary": "Policy decisions relevant to the environment rely on tools like dashboards,\nrisk models, and prediction models to provide information and data\nvisualizations that enable decision-makers to make trade-offs. The conventional\nparadigm of data visualization practices for policy and decision-making is to\nconvey data in a supposedly neutral, objective manner for rational\ndecision-makers. Feminist critique advocates for nuanced and reflexive\napproaches that take into account situated decision-makers and their affective\nrelationships to data. This paper sheds light on a key cognitive aspect that\nimpacts how decision-makers interpret data. Because all outcomes from policies\nrelevant to climate change occur at a distance, decision-makers experience\nso-called `psychological distance' to environmental decisions in terms of\nspace, time, social identity, and hypotheticality. This profoundly impacts how\nthey perceive and evaluate outcomes. Since policy decisions to achieve a safe\nplanetary space are urgently needed for immediate transition and change, we\nneed a design practice that takes into account how psychological distance\naffects cognition and decision-making. Our paper explores the role of\nalternative design approaches in developing visualizations used for climate\npolicymaking. We conduct a literature review and synthesis which bridges\npsychological distance with speculative design and data visceralization by\nillustrating the value of affective design methods via examples from previous\nresearch. Through this work, we propose a novel premise for the communication\nand visualization of environmental data. Our paper lays out how future research\non the impacts of alternative design approaches on psychological distance can\nmake data used for policy decisions more tangible and visceral.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5fc3\u7406\u8ddd\u79bb\u5982\u4f55\u5f71\u54cd\u653f\u7b56\u5236\u5b9a\u8005\u5bf9\u6570\u636e\u7684\u8ba4\u77e5\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u5408\u60c5\u611f\u5316\u8bbe\u8ba1\u548c\u63a8\u6d4b\u6027\u8bbe\u8ba1\u7684\u65b0\u65b9\u6cd5\u6765\u6539\u8fdb\u73af\u5883\u6570\u636e\u53ef\u89c6\u5316\u3002", "motivation": "\u4f20\u7edf\u7684\u73af\u5883\u6570\u636e\u53ef\u89c6\u5316\u5e38\u4ee5\u4e2d\u6027\u3001\u5ba2\u89c2\u7684\u65b9\u5f0f\u5448\u73b0\uff0c\u4f46\u5ffd\u89c6\u4e86\u51b3\u7b56\u8005\u7684\u5fc3\u7406\u8ddd\u79bb\uff08\u7a7a\u95f4\u3001\u65f6\u95f4\u3001\u793e\u4f1a\u8ba4\u540c\u548c\u5047\u8bbe\u6027\uff09\u5bf9\u5176\u8ba4\u77e5\u7684\u5f71\u54cd\u3002\u4e9f\u9700\u4e00\u79cd\u65b0\u7684\u8bbe\u8ba1\u5b9e\u8df5\u6765\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u7efc\u5408\uff0c\u5c06\u5fc3\u7406\u8ddd\u79bb\u7406\u8bba\u4e0e\u63a8\u6d4b\u6027\u8bbe\u8ba1\u53ca\u6570\u636e\u60c5\u611f\u5316\u76f8\u7ed3\u5408\uff0c\u5c55\u793a\u60c5\u611f\u5316\u8bbe\u8ba1\u65b9\u6cd5\u7684\u4ef7\u503c\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u73af\u5883\u6570\u636e\u6c9f\u901a\u548c\u53ef\u89c6\u5316\u524d\u63d0\uff0c\u5f3a\u8c03\u4e86\u66ff\u4ee3\u8bbe\u8ba1\u65b9\u6cd5\u5728\u51cf\u5c11\u5fc3\u7406\u8ddd\u79bb\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "\u672a\u6765\u7684\u7814\u7a76\u5e94\u63a2\u7d22\u66ff\u4ee3\u8bbe\u8ba1\u65b9\u6cd5\u5bf9\u5fc3\u7406\u8ddd\u79bb\u7684\u5f71\u54cd\uff0c\u4ee5\u4f7f\u653f\u7b56\u6570\u636e\u66f4\u5177\u4f53\u611f\u6027\u548c\u76f4\u89c2\u6027\u3002"}}
{"id": "2507.18775", "pdf": "https://arxiv.org/pdf/2507.18775", "abs": "https://arxiv.org/abs/2507.18775", "authors": ["Ilche Georgievski", "Marco Aiello"], "title": "Initial Steps in Integrating Large Reasoning and Action Models for Service Composition", "categories": ["cs.AI", "cs.SE"], "comment": "16 pages, 3 figures, 19th Symposium and Summer School on\n  Service-Oriented Computing (SummerSOC)", "summary": "Service composition remains a central challenge in building adaptive and\nintelligent software systems, often constrained by limited reasoning\ncapabilities or brittle execution mechanisms. This paper explores the\nintegration of two emerging paradigms enabled by large language models: Large\nReasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs\naddress the challenges of semantic reasoning and ecosystem complexity while\nLAMs excel in dynamic action execution and system interoperability. However,\neach paradigm has complementary limitations - LRMs lack grounded action\ncapabilities, and LAMs often struggle with deep reasoning. We propose an\nintegrated LRM-LAM architectural framework as a promising direction for\nadvancing automated service composition. Such a system can reason about service\nrequirements and constraints while dynamically executing workflows, thus\nbridging the gap between intention and execution. This integration has the\npotential to transform service composition into a fully automated,\nuser-friendly process driven by high-level natural language intent.", "AI": {"tldr": "\u6458\u8981\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u4e24\u5927\u65b0\u5174\u8303\u5f0f\u2014\u2014\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u548c\u5927\u578b\u52a8\u4f5c\u6a21\u578b\uff08LAM\uff09\u2014\u2014\u5728\u670d\u52a1\u7ec4\u5408\u4e2d\u7684\u6574\u5408\u6f5c\u529b\uff0c\u6307\u51fa\u5404\u81ea\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u96c6\u6210\u6846\u67b6\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u670d\u52a1\u7ec4\u5408\u3002", "motivation": "\u89e3\u51b3\u670d\u52a1\u7ec4\u5408\u4e2d\u8bed\u4e49\u63a8\u7406\u548c\u52a8\u6001\u6267\u884c\u7684\u6311\u6218\uff0c\u63d0\u5347\u7cfb\u7edf\u9002\u5e94\u6027\u548c\u667a\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u96c6\u6210LRM\u548cLAM\u7684\u67b6\u6784\u6846\u67b6\uff0c\u7ed3\u5408\u63a8\u7406\u4e0e\u6267\u884c\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u6574\u5408LRM\u548cLAM\uff0c\u6709\u671b\u5b9e\u73b0\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u7684\u81ea\u52a8\u5316\u670d\u52a1\u7ec4\u5408\u3002", "conclusion": "LRM-LAM\u6846\u67b6\u662f\u670d\u52a1\u7ec4\u5408\u81ea\u52a8\u5316\u53d1\u5c55\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.18945", "pdf": "https://arxiv.org/pdf/2507.18945", "abs": "https://arxiv.org/abs/2507.18945", "authors": ["Zijian Zhang", "Pan Chen", "Fangshi Du", "Runlong Ye", "Oliver Huang", "Michael Liut", "Al\u00e1n Aspuru-Guzik"], "title": "TreeReader: A Hierarchical Academic Paper Reader Powered by Language Models", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "Efficiently navigating and understanding academic papers is crucial for\nscientific progress. Traditional linear formats like PDF and HTML can cause\ncognitive overload and obscure a paper's hierarchical structure, making it\ndifficult to locate key information. While LLM-based chatbots offer\nsummarization, they often lack nuanced understanding of specific sections, may\nproduce unreliable information, and typically discard the document's\nnavigational structure. Drawing insights from a formative study on academic\nreading practices, we introduce TreeReader, a novel language model-augmented\npaper reader. TreeReader decomposes papers into an interactive tree structure\nwhere each section is initially represented by an LLM-generated concise\nsummary, with underlying details accessible on demand. This design allows users\nto quickly grasp core ideas, selectively explore sections of interest, and\nverify summaries against the source text. A user study was conducted to\nevaluate TreeReader's impact on reading efficiency and comprehension.\nTreeReader provides a more focused and efficient way to navigate and understand\ncomplex academic literature by bridging hierarchical summarization with\ninteractive exploration.", "AI": {"tldr": "TreeReader\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bba\u6587\u9605\u8bfb\u5de5\u5177\uff0c\u901a\u8fc7\u5c06\u8bba\u6587\u5206\u89e3\u4e3a\u4ea4\u4e92\u5f0f\u6811\u72b6\u7ed3\u6784\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u4fe1\u606f\u5bfc\u822a\u548c\u7406\u89e3\u3002", "motivation": "\u4f20\u7edf\u7ebf\u6027\u683c\u5f0f\uff08\u5982PDF\u548cHTML\uff09\u53ef\u80fd\u5bfc\u81f4\u8ba4\u77e5\u8fc7\u8f7d\u5e76\u63a9\u76d6\u8bba\u6587\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u800c\u73b0\u6709\u7684LLM\u804a\u5929\u673a\u5668\u4eba\u6458\u8981\u5de5\u5177\u7f3a\u4e4f\u5bf9\u5177\u4f53\u7ae0\u8282\u7684\u6df1\u5165\u7406\u89e3\u4e14\u53ef\u80fd\u4e0d\u53ef\u9760\u3002", "method": "\u901a\u8fc7\u5f62\u6210\u6027\u7814\u7a76\u5206\u6790\u5b66\u672f\u9605\u8bfb\u5b9e\u8df5\uff0c\u8bbe\u8ba1TreeReader\u2014\u2014\u5c06\u8bba\u6587\u5206\u89e3\u4e3a\u6811\u72b6\u7ed3\u6784\uff0c\u6bcf\u4e2a\u90e8\u5206\u7531LLM\u751f\u6210\u6458\u8981\uff0c\u652f\u6301\u6309\u9700\u67e5\u770b\u8be6\u7ec6\u4fe1\u606f\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cTreeReader\u663e\u8457\u63d0\u5347\u4e86\u9605\u8bfb\u6548\u7387\u548c\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "TreeReader\u7ed3\u5408\u5c42\u6b21\u5316\u6458\u8981\u4e0e\u4ea4\u4e92\u5f0f\u63a2\u7d22\uff0c\u4e3a\u5b66\u672f\u6587\u732e\u9605\u8bfb\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u4e14\u4e13\u6ce8\u7684\u65b9\u5f0f\u3002"}}
{"id": "2507.19182", "pdf": "https://arxiv.org/pdf/2507.19182", "abs": "https://arxiv.org/abs/2507.19182", "authors": ["Kuncheng Zou", "Jiahao Mai", "Yonggang Zhang", "Yuyi Wang", "Ond\u0159ej Ku\u017eelka", "Yuanhong Wang", "Yi Chang"], "title": "Faster Lifting for Ordered Domains with Predecessor Relations", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We investigate lifted inference on ordered domains with predecessor\nrelations, where the elements of the domain respect a total (cyclic) order, and\nevery element has a distinct (clockwise) predecessor. Previous work has\nexplored this problem through weighted first-order model counting (WFOMC),\nwhich computes the weighted sum of models for a given first-order logic\nsentence over a finite domain. In WFOMC, the order constraint is typically\nencoded by the linear order axiom introducing a binary predicate in the\nsentence to impose a linear ordering on the domain elements. The immediate and\nsecond predecessor relations are then encoded by the linear order predicate.\nAlthough WFOMC with the linear order axiom is theoretically tractable, existing\nalgorithms struggle with practical applications, particularly when the\npredecessor relations are involved. In this paper, we treat predecessor\nrelations as a native part of the axiom and devise a novel algorithm that\ninherently supports these relations. The proposed algorithm not only provides\nan exponential speedup for the immediate and second predecessor relations,\nwhich are known to be tractable, but also handles the general k-th predecessor\nrelations. The extensive experiments on lifted inference tasks and\ncombinatorics math problems demonstrate the efficiency of our algorithm,\nachieving speedups of a full order of magnitude.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u6709\u5e8f\u57df\u4e0a\u8fdb\u884c\u63d0\u5347\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u524d\u9a71\u5173\u7cfb\u3002\u901a\u8fc7\u5c06\u524d\u9a71\u5173\u7cfb\u4f5c\u4e3a\u516c\u7406\u7684\u4e00\u90e8\u5206\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u52a0\u6743\u4e00\u9636\u6a21\u578b\u8ba1\u6570\uff08WFOMC\uff09\u65b9\u6cd5\u5728\u5904\u7406\u524d\u9a71\u5173\u7cfb\u65f6\u6548\u7387\u4e0d\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5c06\u524d\u9a71\u5173\u7cfb\u76f4\u63a5\u4f5c\u4e3a\u516c\u7406\u7684\u4e00\u90e8\u5206\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7b97\u6cd5\uff0c\u652f\u6301\u4ece\u76f4\u63a5\u524d\u9a71\u5230\u4e00\u822ck\u9636\u524d\u9a71\u5173\u7cfb\u7684\u5904\u7406\u3002", "result": "\u65b0\u7b97\u6cd5\u5728\u5904\u7406\u76f4\u63a5\u548c\u7b2c\u4e8c\u524d\u9a71\u5173\u7cfb\u65f6\u5b9e\u73b0\u4e86\u6307\u6570\u7ea7\u52a0\u901f\uff0c\u5e76\u5728\u7ec4\u5408\u6570\u5b66\u95ee\u9898\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5728\u6709\u524d\u9a71\u5173\u7cfb\u7684\u6709\u5e8f\u57df\u4e0a\u7684\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.18971", "pdf": "https://arxiv.org/pdf/2507.18971", "abs": "https://arxiv.org/abs/2507.18971", "authors": ["Rachel Lin", "Bhavya Chopra", "Wenjing Lin", "Shreya Shankar", "Madelon Hulsebos", "Aditya G. Parameswaran"], "title": "Rethinking Dataset Discovery with DataScout", "categories": ["cs.HC"], "comment": "16 pages; 6 figures; 4 tables; To appear at UIST 2025", "summary": "Dataset Search -- the process of finding appropriate datasets for a given\ntask -- remains a critical yet under-explored challenge in data science\nworkflows. Assessing dataset suitability for a task (e.g., training a\nclassification model) is a multi-pronged affair that involves understanding:\ndata characteristics (e.g. granularity, attributes, size), semantics (e.g.,\ndata semantics, creation goals), and relevance to the task at hand. Present-day\ndataset search interfaces are restrictive -- users struggle to convey implicit\npreferences and lack visibility into the search space and result inclusion\ncriteria -- making query iteration challenging. To bridge these gaps, we\nintroduce DataScout to proactively steer users through the process of dataset\ndiscovery via -- (i) AI-assisted query reformulations informed by the\nunderlying search space, (ii) semantic search and filtering based on dataset\ncontent, including attributes (columns) and granularity (rows), and (iii)\ndataset relevance indicators, generated dynamically based on the user-specified\ntask. A within-subjects study with 12 participants comparing DataScout to\nkeyword and semantic dataset search reveals that users uniquely employ\nDataScout's features not only for structured explorations, but also to glean\nfeedback on their search queries and build conceptual models of the search\nspace.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86DataScout\u5de5\u5177\uff0c\u4ee5AI\u8f85\u52a9\u67e5\u8be2\u91cd\u6784\u3001\u8bed\u4e49\u641c\u7d22\u548c\u52a8\u6001\u6570\u636e\u96c6\u76f8\u5173\u6027\u6307\u6807\uff0c\u6539\u8fdb\u6570\u636e\u96c6\u641c\u7d22\u6d41\u7a0b\u3002", "motivation": "\u6570\u636e\u96c6\u641c\u7d22\u5728\u6570\u636e\u79d1\u5b66\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u5728\u7528\u6237\u8868\u8fbe\u9700\u6c42\u548c\u5b8c\u5584\u67e5\u8be2\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1DataScout\u5de5\u5177\uff0c\u901a\u8fc7AI\u8f85\u52a9\u67e5\u8be2\u91cd\u6784\u3001\u8bed\u4e49\u641c\u7d22\u53ca\u52a8\u6001\u76f8\u5173\u6027\u6307\u6807\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u9ad8\u6548\u53d1\u73b0\u6570\u636e\u96c6\u3002", "result": "12\u540d\u53c2\u4e0e\u8005\u7684\u7814\u7a76\u8868\u660e\uff0cDataScout\u80fd\u5e2e\u52a9\u7528\u6237\u7ed3\u6784\u5316\u63a2\u7d22\u67e5\u8be2\u7a7a\u95f4\u5e76\u83b7\u5f97\u53cd\u9988\u3002", "conclusion": "DataScout\u901a\u8fc7\u591a\u7ef4\u5ea6\u8f85\u52a9\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u96c6\u641c\u7d22\u7684\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2507.19026", "pdf": "https://arxiv.org/pdf/2507.19026", "abs": "https://arxiv.org/abs/2507.19026", "authors": ["Chang Chen", "Sicheng Song", "Shuchang Xu", "Zhicheng Li", "Huamin Qu", "Yanna Lin"], "title": "RhythmTA: A Visual-Aided Interactive System for ESL Rhythm Training via Dubbing Practice", "categories": ["cs.HC"], "comment": null, "summary": "English speech rhythm, the temporal patterns of stressed syllables, is\nessential for English as a second language (ESL) learners to produce\nnatural-sounding and comprehensible speech. Rhythm training is generally based\non imitation of native speech. However, it relies heavily on external\ninstructor feedback, preventing ESL learners from independent practice. To\naddress this gap, we present RhythmTA, an interactive system for ESL learners\nto practice speech rhythm independently via dubbing, an imitation-based\napproach. The system automatically extracts rhythm from any English speech and\nintroduces novel visual designs to support three stages of dubbing practice:\n(1) Synchronized listening with visual aids to enhance perception, (2) Guided\nrepeating by visual cues for self-adjustment, and (3) Comparative reflection\nfrom a parallel view for self-monitoring. Our design is informed by a formative\nstudy with nine spoken English instructors, which identified current practices\nand challenges. A user study with twelve ESL learners demonstrates that\nRhythmTA effectively enhances learners' rhythm perception and shows significant\npotential for improving rhythm production.", "AI": {"tldr": "RhythmTA\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u5e2e\u52a9ESL\u5b66\u4e60\u8005\u901a\u8fc7\u914d\u97f3\u72ec\u7acb\u7ec3\u4e60\u82f1\u8bed\u8bed\u97f3\u8282\u594f\uff0c\u63d0\u5347\u611f\u77e5\u548c\u4ea7\u51fa\u80fd\u529b\u3002", "motivation": "\u9488\u5bf9ESL\u5b66\u4e60\u8005\u5728\u8bed\u97f3\u8282\u594f\u8bad\u7ec3\u4e2d\u4f9d\u8d56\u5916\u90e8\u53cd\u9988\u3001\u96be\u4ee5\u72ec\u7acb\u7ec3\u4e60\u7684\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u901a\u8fc7\u914d\u97f3\u81ea\u52a8\u63d0\u53d6\u8282\u594f\uff0c\u5e76\u63d0\u4f9b\u89c6\u89c9\u8f85\u52a9\u652f\u6301\u4e09\u9636\u6bb5\u7ec3\u4e60\uff1a\u611f\u77e5\u3001\u81ea\u6211\u8c03\u6574\u548c\u81ea\u6211\u76d1\u63a7\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cRhythmTA\u80fd\u6709\u6548\u63d0\u5347\u5b66\u4e60\u8005\u7684\u8282\u594f\u611f\u77e5\u80fd\u529b\uff0c\u5e76\u6709\u671b\u6539\u5584\u8282\u594f\u4ea7\u51fa\u3002", "conclusion": "RhythmTA\u4e3aESL\u5b66\u4e60\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u72ec\u7acb\u7ec3\u4e60\u8bed\u97f3\u8282\u594f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19060", "pdf": "https://arxiv.org/pdf/2507.19060", "abs": "https://arxiv.org/abs/2507.19060", "authors": ["Jiawei Liu", "Nirav Diwan", "Zhe Wang", "Haoyu Zhai", "Xiaona Zhou", "Kiet A. Nguyen", "Tianjiao Yu", "Muntasir Wahed", "Yinlin Deng", "Hadjer Benkraouda", "Yuxiang Wei", "Lingming Zhang", "Ismini Lourentzou", "Gang Wang"], "title": "PurpCode: Reasoning for Safer Code Generation", "categories": ["cs.CR", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "We introduce PurpCode, the first post-training recipe for training safe code\nreasoning models towards generating secure code and defending against malicious\ncyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule\nLearning, which explicitly teaches the model to reference cybersafety rules to\ngenerate vulnerability-free code and to avoid facilitating malicious\ncyberactivities; and (ii) Reinforcement Learning, which optimizes model safety\nand preserves model utility through diverse, multi-objective reward mechanisms.\nTo empower the training pipelines with comprehensive cybersafety data, we\nconduct internal red-teaming to synthesize comprehensive and high-coverage\nprompts based on real-world tasks for inducing unsafe cyberactivities in the\nmodel. Based on PurpCode, we develop a reasoning-based coding model, namely\nPurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming\nvarious frontier models. Meanwhile, our alignment method decreases the model\noverrefusal rates in both general and cybersafety-specific scenarios, while\npreserving model utility in both code generation and common security knowledge.", "AI": {"tldr": "PurpCode\u662f\u4e00\u79cd\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c4\u5219\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u4e24\u9636\u6bb5\u8bad\u7ec3\u6a21\u578b\uff0c\u751f\u6210\u5b89\u5168\u4ee3\u7801\u5e76\u9632\u5fa1\u6076\u610f\u7f51\u7edc\u6d3b\u52a8\uff1b\u5176\u5f00\u53d1\u7684PurpCode-32B\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u548c\u5b9e\u7528\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5728\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u53ef\u80fd\u751f\u6210\u6613\u53d7\u653b\u51fb\u7684\u4ee3\u7801\u6216\u534f\u52a9\u6076\u610f\u6d3b\u52a8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u7f51\u7edc\u5b89\u5168\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u5206\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u89c4\u5219\u5b66\u4e60\uff08\u660e\u786e\u5f15\u7528\u5b89\u5168\u89c4\u5219\u751f\u6210\u65e0\u6f0f\u6d1e\u4ee3\u7801\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08\u901a\u8fc7\u591a\u6837\u6027\u5956\u52b1\u4f18\u5316\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\uff09\u3002", "result": "\u5f00\u53d1\u7684PurpCode-32B\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u65b9\u9762\u9886\u5148\u5176\u4ed6\u524d\u6cbf\u6a21\u578b\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8fc7\u5ea6\u62d2\u7edd\u7387\u5e76\u4fdd\u6301\u4e86\u4ee3\u7801\u751f\u6210\u548c\u5b89\u5168\u77e5\u8bc6\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "PurpCode\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u6765\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u7f51\u7edc\u5b89\u5168\u6027\uff0c\u540c\u65f6\u5e73\u8861\u4e86\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.19072", "pdf": "https://arxiv.org/pdf/2507.19072", "abs": "https://arxiv.org/abs/2507.19072", "authors": ["Oliver Bates", "Christian Remy", "Kieran Cutting", "Adam Tyler", "Adrian Friday"], "title": "Exploring post-neoliberal futures for managing commercial heating and cooling through speculative praxis", "categories": ["cs.HC"], "comment": "Post-proceedings paper presented at LIMITS 2024: 10th Workshop on\n  Computing within Limits, 2024-06-19/20, Online", "summary": "What could designing for carbon reduction of heating and cooling in\ncommercial settings look like in the near future? How can we challenge dominant\nmindsets and paradigms of efficiency and behaviour change? How can we help\nbuild worlds through our practice that can become future realities? This paper\nintroduces the fictional consultancy ANCSTRL.LAB to explore opportunities for\nmaking space in research projects that can encourage more systems-oriented\ninterventions. We present a design fiction that asks `what if energy management\nand reduction practice embraced systems thinking?'. Our design fiction explores\nhow future energy consultancies could utilise systems thinking, and (more than)\nhuman centred design to re-imagine energy management practice and change\nsystems in ways that are currently unfathomable. We finish by discussing how\nLIMITS research can utilise design fiction and speculative praxis to help build\nnew material realities where more holistic perspectives, the leveraging of\nsystems change, and the imagining of post-neoliberal futures is the norm.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u865a\u6784\u54a8\u8be2\u516c\u53f8ANCSTRL.LAB\uff0c\u63a2\u7d22\u5982\u4f55\u5229\u7528\u7cfb\u7edf\u601d\u7ef4\u548c\u8bbe\u8ba1\u865a\u6784\u65b9\u6cd5\u6765\u91cd\u65b0\u6784\u60f3\u672a\u6765\u80fd\u6e90\u7ba1\u7406\u5b9e\u8df5\uff0c\u4ee5\u4fc3\u8fdb\u78b3\u51cf\u6392\u548c\u7cfb\u7edf\u53d8\u9769\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u6548\u7387\u548c\u884c\u4e3a\u6539\u53d8\u7684\u4e3b\u6d41\u601d\u7ef4\u6a21\u5f0f\uff0c\u63a2\u7d22\u5982\u4f55\u5728\u5546\u4e1a\u73af\u5883\u4e2d\u901a\u8fc7\u8bbe\u8ba1\u5b9e\u8df5\u63a8\u52a8\u78b3\u51cf\u6392\u548c\u7cfb\u7edf\u53d8\u9769\u3002", "method": "\u63d0\u51fa\u8bbe\u8ba1\u865a\u6784\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u865a\u6784\u7684\u672a\u6765\u80fd\u6e90\u54a8\u8be2\u516c\u53f8ANCSTRL.LAB\uff0c\u7ed3\u5408\u7cfb\u7edf\u601d\u7ef4\u548c\u4eba\u7c7b\uff08\u53ca\u8d85\u4eba\u7c7b\uff09\u4e2d\u5fc3\u8bbe\u8ba1\uff0c\u91cd\u65b0\u6784\u60f3\u80fd\u6e90\u7ba1\u7406\u5b9e\u8df5\u3002", "result": "\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u8bbe\u8ba1\u865a\u6784\u548c\u63a8\u6d4b\u5b9e\u8df5\uff0c\u4fc3\u8fdb\u66f4\u5168\u9762\u7684\u89c6\u89d2\u3001\u7cfb\u7edf\u53d8\u9769\u7684\u6760\u6746\u4f5c\u7528\uff0c\u4ee5\u53ca\u540e\u65b0\u81ea\u7531\u4e3b\u4e49\u672a\u6765\u7684\u60f3\u8c61\u3002", "conclusion": "\u8bbe\u8ba1\u865a\u6784\u548c\u63a8\u6d4b\u5b9e\u8df5\u53ef\u4ee5\u4e3aLIMIT\u7814\u7a76\u63d0\u4f9b\u5de5\u5177\uff0c\u5e2e\u52a9\u6784\u5efa\u65b0\u7684\u7269\u8d28\u73b0\u5b9e\uff0c\u63a8\u52a8\u7cfb\u7edf\u53d8\u9769\u548c\u672a\u6765\u80fd\u6e90\u7ba1\u7406\u7684\u521b\u65b0\u3002"}}
{"id": "2507.19457", "pdf": "https://arxiv.org/pdf/2507.19457", "abs": "https://arxiv.org/abs/2507.19457", "authors": ["Lakshya A Agrawal", "Shangyin Tan", "Dilara Soylu", "Noah Ziems", "Rishi Khare", "Krista Opsahl-Ong", "Arnav Singhvi", "Herumb Shandilya", "Michael J Ryan", "Meng Jiang", "Christopher Potts", "Koushik Sen", "Alexandros G. Dimakis", "Ion Stoica", "Dan Klein", "Matei Zaharia", "Omar Khattab"], "title": "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE", "I.2.7; I.2.6; I.2.4; I.2.8"], "comment": null, "summary": "Large language models (LLMs) are increasingly adapted to downstream tasks via\nreinforcement learning (RL) methods like Group Relative Policy Optimization\n(GRPO), which often require thousands of rollouts to learn new tasks. We argue\nthat the interpretable nature of language can often provide a much richer\nlearning medium for LLMs, compared with policy gradients derived from sparse,\nscalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt\noptimizer that thoroughly incorporates natural language reflection to learn\nhigh-level rules from trial and error. Given any AI system containing one or\nmore LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool\ncalls, and tool outputs) and reflects on them in natural language to diagnose\nproblems, propose and test prompt updates, and combine complementary lessons\nfrom the Pareto frontier of its own attempts. As a result of GEPA's design, it\ncan often turn even just a few rollouts into a large quality gain. Across four\ntasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up\nto 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,\nMIPROv2, by over 10% across two LLMs, and demonstrates promising results as an\ninference-time search strategy for code optimization.", "AI": {"tldr": "GEPA\u662f\u4e00\u79cd\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u53cd\u601d\u7684\u63d0\u793a\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5c11\u91cf\u5c1d\u8bd5\u5373\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f18\u4e8eGRPO\u548cMIPROv2\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08\u5982GRPO\uff09\u9700\u8981\u5927\u91cf\u5c1d\u8bd5\u6765\u5b66\u4e60\u65b0\u4efb\u52a1\uff0c\u800c\u8bed\u8a00\u7684\u89e3\u91ca\u6027\u53ef\u80fd\u4e3aLLMs\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u5b66\u4e60\u5a92\u4ecb\u3002", "method": "GEPA\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u53cd\u601d\u4ece\u8bd5\u9a8c\u4e2d\u5b66\u4e60\u9ad8\u5c42\u89c4\u5219\uff0c\u8bca\u65ad\u95ee\u9898\u5e76\u63d0\u51fa\u63d0\u793a\u66f4\u65b0\uff0c\u7ed3\u5408\u5e15\u7d2f\u6258\u524d\u6cbf\u7684\u4e92\u8865\u7ecf\u9a8c\u3002", "result": "\u5728\u56db\u4e2a\u4efb\u52a1\u4e2d\uff0cGEPA\u5e73\u5747\u6bd4GRPO\u9ad810%\uff0c\u6700\u9ad8\u8fbe20%\uff0c\u4e14\u5c1d\u8bd5\u6b21\u6570\u5c1135\u500d\uff1b\u6bd4MIPROv2\u9ad810%\uff0c\u4e14\u5728\u4ee3\u7801\u4f18\u5316\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "GEPA\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u53cd\u601d\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u793a\u4f18\u5316\u548c\u4ee3\u7801\u641c\u7d22\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.19094", "pdf": "https://arxiv.org/pdf/2507.19094", "abs": "https://arxiv.org/abs/2507.19094", "authors": ["Thomas Thibault", "L\u00e9a Mosesso", "Camille Adam", "Aur\u00e9lien Tabard", "Ana\u00eblle Beignon", "Nolwenn Maudet"], "title": "Environmental (in)considerations in the Design of Smartphone Settings", "categories": ["cs.HC"], "comment": "Post-proceedings paper presented at LIMITS 2025: 11th Workshop on\n  Computing within Limits, 2025-06-26/27, Online", "summary": "Designing for sufficiency is one of many approaches that could foster more\nmoderate and sustainable digital practices. Based on the Sustainable\nInformation and Communication Technologies (ICT) and Human-Computer Interaction\n(HCI) literature, we identify five environmental settings categories. However,\nour analysis of three mobile OS and nine representative applications shows an\noverall lack of environmental concerns in settings design, leading us to\nidentify six pervasive anti-patterns. Environmental settings, where they exist,\nare set on the most intensive option by default. They are not presented as\nsuch, are not easily accessible, and offer little explanation of their impact.\nInstead, they encourage more intensive use. Based on these findings, we create\na design workbook that explores design principles for environmental settings:\npresenting the environmental potential of settings; shifting to environmentally\nneutral states; previewing effects to encourage moderate use; rethinking\ndefaults; facilitating settings access and; exploring more frugal settings.\nBuilding upon this workbook, we discuss how settings can tie individual\nbehaviors to systemic factors.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u6570\u5b57\u4ea7\u54c1\u8bbe\u8ba1\u4e2d\u7f3a\u4e4f\u53ef\u6301\u7eed\u6027\u8bbe\u7f6e\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u516d\u79cd\u53cd\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bbe\u8ba1\u624b\u518c\uff0c\u63a2\u8ba8\u73af\u5883\u53cb\u597d\u8bbe\u7f6e\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u4ea7\u54c1\u7684\u8bbe\u8ba1\u666e\u904d\u7f3a\u4e4f\u5bf9\u73af\u5883\u53ef\u6301\u7eed\u6027\u7684\u8003\u8651\uff0c\u5bfc\u81f4\u7528\u6237\u8d8b\u5411\u4e8e\u8fc7\u5ea6\u4f7f\u7528\u8d44\u6e90\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u8bbe\u8ba1\u6539\u8fdb\uff0c\u4fc3\u8fdb\u66f4\u8282\u5236\u548c\u53ef\u6301\u7eed\u7684\u6570\u5b57\u5b9e\u8df5\u3002", "method": "\u7ed3\u5408\u53ef\u6301\u7eedICT\u548cHCI\u6587\u732e\uff0c\u5206\u6790\u4e86\u4e09\u4e2a\u79fb\u52a8\u64cd\u4f5c\u7cfb\u7edf\u548c\u4e5d\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u73af\u5883\u8bbe\u7f6e\uff0c\u8bc6\u522b\u51fa\u516d\u79cd\u53cd\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bbe\u8ba1\u624b\u518c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73af\u5883\u8bbe\u7f6e\u666e\u904d\u7f3a\u5931\u6216\u88ab\u9ed8\u8ba4\u8bbe\u7f6e\u4e3a\u9ad8\u8d44\u6e90\u6d88\u8017\u72b6\u6001\u3002\u8bbe\u8ba1\u624b\u518c\u63d0\u51fa\u4e86\u516d\u9879\u8bbe\u8ba1\u539f\u5219\uff0c\u4ee5\u6539\u8fdb\u73af\u5883\u8bbe\u7f6e\u7684\u5448\u73b0\u548c\u529f\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdb\u73af\u5883\u8bbe\u7f6e\u7684\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u5c06\u4e2a\u4f53\u884c\u4e3a\u4e0e\u7cfb\u7edf\u6027\u56e0\u7d20\u8054\u7cfb\u8d77\u6765\uff0c\u4fc3\u8fdb\u66f4\u53ef\u6301\u7eed\u7684\u6570\u5b57\u5b9e\u8df5\u3002"}}
{"id": "2507.19104", "pdf": "https://arxiv.org/pdf/2507.19104", "abs": "https://arxiv.org/abs/2507.19104", "authors": ["Alireza Mortezapour", "Andrea Antonio Cantone", "Monica Maria Lucia Sebillo", "Giuliana Vitiello"], "title": "A systematic literature review to unveil users objective reaction to virtual experiences: Complemented with a conceptual model (QoUX in VE)", "categories": ["cs.HC"], "comment": null, "summary": "In pursuit of documenting users Neurophysiological responses during\nexperiencing virtual environments (VE), this systematic review presents a novel\nconceptual model of UX in VE. Searching across seven databases yielded to 1743\narticles. Rigorous screenings, included only 66 articles. Notably, UX in VE\nlacks a consensus definition. Obviously, this UX has many unique sub-dimensions\nthat are not mentioned in other products. The presented conceptual model\ncontains 26 subdimensions which mostly not supported in previous subjective\ntools and questionnaires. While EEG and ECG were common, brain ultrasound,\nemployed in one study, highlights the need for using neurophysiological\nassessments to comprehensively grasp immersive UX intricacies.", "AI": {"tldr": "\u7cfb\u7edf\u7efc\u8ff0\u63d0\u51fa\u4e86\u865a\u62df\u73af\u5883(VE)\u4e2d\u7528\u6237\u4f53\u9a8c(UX)\u7684\u65b0\u6982\u5ff5\u6a21\u578b\uff0c\u5305\u542b26\u4e2a\u72ec\u7279\u5b50\u7ef4\u5ea6\uff0c\u5f3a\u8c03\u4e86\u795e\u7ecf\u751f\u7406\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u8bb0\u5f55\u7528\u6237\u5728\u865a\u62df\u73af\u5883\u4e2d\u7684\u795e\u7ecf\u751f\u7406\u53cd\u5e94\uff0c\u5e76\u586b\u8865\u73b0\u6709UX\u5b9a\u4e49\u548c\u8bc4\u4f30\u5de5\u5177\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\uff0c\u7b5b\u9009\u4e867\u4e2a\u6570\u636e\u5e93\u76841743\u7bc7\u6587\u7ae0\uff0c\u6700\u7ec8\u7eb3\u516566\u7bc7\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u5305\u542b26\u4e2a\u5b50\u7ef4\u5ea6\u7684UX\u6982\u5ff5\u6a21\u578b\uff0c\u6307\u51faEEG\u548cECG\u5e38\u7528\uff0c\u4f46\u8fd8\u9700\u66f4\u591a\u795e\u7ecf\u751f\u7406\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u865a\u62df\u73af\u5883\u4e2d\u7684UX\u5177\u6709\u72ec\u7279\u5b50\u7ef4\u5ea6\uff0c\u9700\u7ed3\u5408\u795e\u7ecf\u751f\u7406\u5b66\u5de5\u5177\u4ee5\u5168\u9762\u7406\u89e3\u5176\u590d\u6742\u6027\u3002"}}
{"id": "2507.19114", "pdf": "https://arxiv.org/pdf/2507.19114", "abs": "https://arxiv.org/abs/2507.19114", "authors": ["Santiago Berrezueta-Guzman", "WenChun Chen", "Stefan Wagner"], "title": "A Therapeutic Role-Playing VR Game for Children with Intellectual Disabilities", "categories": ["cs.HC"], "comment": "Paper accepted for publication and presentation in the 3rd Annual\n  IEEE International Conference on Metaverse Computing, Networking, and\n  Applications (IEEE MetaCom 2025) will be held in Sejong University, Seoul,\n  Republic of Korea, on August 27 - 29, 2025", "summary": "Virtual Reality (VR) offers promising avenues for innovative therapeutic\ninterventions in populations with intellectual disabilities (ID). This paper\npresents the design, development, and evaluation of Space Exodus, a novel\nVR-based role-playing game specifically tailored for children with ID. By\nintegrating immersive gameplay with therapeutic task design, Space Exodus aims\nto enhance concentration, cognitive processing, and fine motor skills through\nstructured hand-eye coordination exercises. A six-week pre-test/post-test study\nwas conducted with 16 children in Ecuador, using standardized assessments, the\nToulouse-Pieron Cancellation Test, and the Moss Attention Rating Scale\ncomplemented by detailed observational metrics. Quantitative results indicate\nstatistically significant improvements in concentration scores, with test\nscores increasing from 65.2 to 80.3 and 55.4 to 68.7, respectively (p < 0.01).\nQualitative observations revealed reduced task attempts, enhanced user\nconfidence, and increased active participation. The inclusion of a VR assistant\nprovided consistent guidance that further boosted engagement. These findings\ndemonstrate the potential of immersive, game-based learning environments as\npractical therapeutic tools, laying a robust foundation for developing\ninclusive and adaptive rehabilitation strategies for children with ID.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e13\u4e3a\u667a\u969c\u513f\u7ae5\u8bbe\u8ba1\u7684VR\u89d2\u8272\u626e\u6f14\u6e38\u620fSpace Exodus\uff0c\u901a\u8fc7\u516d\u5468\u6d4b\u8bd5\u663e\u793a\u5176\u5728\u63d0\u5347\u4e13\u6ce8\u529b\u548c\u8ba4\u77e5\u6280\u80fd\u65b9\u9762\u6709\u663e\u8457\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u865a\u62df\u73b0\u5b9e\u6280\u672f\u5728\u667a\u969c\u513f\u7ae5\u5eb7\u590d\u4e2d\u7684\u6f5c\u529b\uff0c\u63d0\u4f9b\u521b\u65b0\u7684\u6cbb\u7597\u5e72\u9884\u624b\u6bb5\u3002", "method": "\u8bbe\u8ba1\u5e76\u5f00\u53d1VR\u6e38\u620fSpace Exodus\uff0c\u6574\u5408\u6c89\u6d78\u5f0f\u6e38\u620f\u4e0e\u6cbb\u7597\u4efb\u52a1\uff0c\u901a\u8fc7\u516d\u5468\u524d\u6d4b/\u540e\u6d4b\u7814\u7a76\u8bc4\u4f30\u6548\u679c\u3002", "result": "\u5b9a\u91cf\u6570\u636e\u663e\u793a\u4e13\u6ce8\u529b\u5206\u6570\u663e\u8457\u63d0\u9ad8\uff0c\u5b9a\u6027\u89c2\u5bdf\u663e\u793a\u7528\u6237\u4fe1\u5fc3\u589e\u5f3a\u548c\u53c2\u4e0e\u5ea6\u63d0\u5347\u3002", "conclusion": "VR\u6e38\u620f\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u6cbb\u7597\u5de5\u5177\uff0c\u4e3a\u667a\u969c\u513f\u7ae5\u5eb7\u590d\u7b56\u7565\u7684\u5f00\u53d1\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2507.19193", "pdf": "https://arxiv.org/pdf/2507.19193", "abs": "https://arxiv.org/abs/2507.19193", "authors": ["Jonas Pech\u00e9", "Aliaksei Tsishurou", "Alexander Zap", "Guenter Wallner"], "title": "Where are the Frontlines? A Visualization Approach for Map Control in Team-Based Games", "categories": ["cs.HC"], "comment": null, "summary": "A central area of interest in many competitive online games is spatial\nbehavior which due to its complexity can be difficult to visualize. Such\nbehaviors of interest include not only overall movement patterns but also being\nable to understand which player or team is exerting control over an area to\ninform decision-making. Map control can, however, be challenging to quantify.\nIn this paper, we propose a method for calculating frontlines and first efforts\ntowards a visualization of them. The visualization can show map control and\nfrontlines at a specific time point or changes of these over time. For this\npurpose, it utilizes support vector machines to derive frontlines from unit\npositions. We illustrate our algorithm and visualization with examples based on\nthe team-based online game World of Tanks.", "AI": {"tldr": "\u4e00\u79cd\u57fa\u4e8e\u652f\u6301\u5411\u91cf\u673a\u7684\u65b9\u6cd5\u7528\u4e8e\u5728\u7ebf\u6e38\u620f\u4e2d\u8ba1\u7b97\u548c\u53ef\u89c6\u5316\u524d\u7ebf\u53ca\u5730\u56fe\u63a7\u5236\u3002", "motivation": "\u7814\u7a76\u5728\u7ebf\u6e38\u620f\u4e2d\u7684\u7a7a\u95f4\u884c\u4e3a\uff08\u5982\u5730\u56fe\u63a7\u5236\uff09\u56e0\u5176\u590d\u6742\u6027\u96be\u4ee5\u91cf\u5316\u4e0e\u53ef\u89c6\u5316\u3002", "method": "\u63d0\u51fa\u5229\u7528\u652f\u6301\u5411\u91cf\u673a\u4ece\u5355\u4f4d\u4f4d\u7f6e\u63a8\u5bfc\u524d\u7ebf\uff0c\u5e76\u901a\u8fc7\u53ef\u89c6\u5316\u5c55\u793a\u7279\u5b9a\u65f6\u95f4\u70b9\u6216\u65f6\u95f4\u53d8\u5316\u4e2d\u7684\u5730\u56fe\u63a7\u5236\u4e0e\u524d\u7ebf\u3002", "result": "\u57fa\u4e8e\u300a\u5766\u514b\u4e16\u754c\u300b\u7684\u793a\u4f8b\u5c55\u793a\u4e86\u7b97\u6cd5\u4e0e\u53ef\u89c6\u5316\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u7ebf\u6e38\u620f\u4e2d\u7684\u5730\u56fe\u63a7\u5236\u5206\u6790\u63d0\u4f9b\u4e86\u91cf\u5316\u4e0e\u53ef\u89c6\u5316\u5de5\u5177\u3002"}}
{"id": "2507.19376", "pdf": "https://arxiv.org/pdf/2507.19376", "abs": "https://arxiv.org/abs/2507.19376", "authors": ["Wieslaw Kope\u0107", "Anna Jaskulska", "W\u0142adys\u0142aw Fuchs", "Wiktor Stawski", "Stanis\u0142aw Knapi\u0144ski", "Barbara Karpowicz", "Rafa\u0142 Mas\u0142yk"], "title": "Archiverse: an Approach for Immersive Cultural Heritage", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Digital technologies and tools have transformed the way we can study cultural\nheritage and the way we can recreate it digitally. Techniques such as laser\nscanning, photogrammetry, and a variety of Mixed Reality solutions have enabled\nresearchers to examine cultural objects and artifacts more precisely and from\nnew perspectives. In this part of the panel, we explore how Virtual Reality\n(VR) and eXtended Reality (XR) can serve as tools to recreate and visualize the\nremains of historical cultural heritage and experience it in simulations of its\noriginal complexity, which means immersive and interactive. Visualization of\nmaterial culture exemplified by archaeological sites and architecture can be\nparticularly useful when only ruins or archaeological remains survive. However,\nthese advancements also bring significant challenges, especially in the area of\ntransdisciplinary cooperation between specialists from many, often distant,\nfields, and the dissemination of virtual immersive environments among both\nprofessionals and the general public.", "AI": {"tldr": "\u6570\u5b57\u6280\u672f\uff08\u5982\u6fc0\u5149\u626b\u63cf\u3001\u6444\u5f71\u6d4b\u91cf\u548c\u6df7\u5408\u73b0\u5b9e\uff09\u4e3a\u6587\u5316\u9057\u4ea7\u7684\u7814\u7a76\u548c\u6570\u5b57\u5316\u91cd\u5efa\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u5c24\u5176\u662fVR\u548cXR\u6280\u672f\u80fd\u591f\u590d\u73b0\u548c\u53ef\u89c6\u5316\u5386\u53f2\u6587\u5316\u9057\u4ea7\u7684\u590d\u6742\u6027\uff0c\u4f46\u4e5f\u9762\u4e34\u8de8\u5b66\u79d1\u5408\u4f5c\u548c\u4f20\u64ad\u7684\u6311\u6218\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5229\u7528VR\u548cXR\u6280\u672f\u91cd\u73b0\u548c\u53ef\u89c6\u5316\u5386\u53f2\u6587\u5316\u9057\u4ea7\uff0c\u5c24\u5176\u662f\u5728\u9057\u8ff9\u6216\u8003\u53e4\u9057\u5b58\u4ec5\u5b58\u7684\u60c5\u51b5\u4e0b\uff0c\u4ee5\u63d0\u4f9b\u6c89\u6d78\u5f0f\u4e92\u52a8\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u6fc0\u5149\u626b\u63cf\u3001\u6444\u5f71\u6d4b\u91cf\u548c\u6df7\u5408\u73b0\u5b9e\uff08VR/XR\uff09\u6280\u672f\uff0c\u5bf9\u6587\u5316\u9057\u4ea7\u8fdb\u884c\u6570\u5b57\u5316\u91cd\u5efa\u548c\u53ef\u89c6\u5316\u3002", "result": "\u6280\u672f\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u7814\u7a76\u6587\u5316\u9057\u4ea7\uff0c\u5e76\u6a21\u62df\u5176\u539f\u59cb\u590d\u6742\u6027\uff0c\u4f46\u4e5f\u9700\u8981\u8de8\u5b66\u79d1\u5408\u4f5c\u548c\u6280\u672f\u4f20\u64ad\u7684\u652f\u6301\u3002", "conclusion": "\u6570\u5b57\u6280\u672f\u4e3a\u6587\u5316\u9057\u4ea7\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u4f46\u8de8\u5b66\u79d1\u534f\u4f5c\u548c\u516c\u4f17\u4f20\u64ad\u662f\u6210\u529f\u5e94\u7528\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2507.19466", "pdf": "https://arxiv.org/pdf/2507.19466", "abs": "https://arxiv.org/abs/2507.19466", "authors": ["Aliaksandr Marozau", "Barbara Karpowicz", "Tomasz Kowalewski", "Pavlo Zinevych", "Wiktor Stawski", "Adam Kuzdrali\u0144ski", "Wies\u0142aw Kope\u0107"], "title": "Towards Effective Immersive Technologies in Medicine: Potential and Future Applications based on VR, AR, XR and AI solutions", "categories": ["cs.HC"], "comment": null, "summary": "Mixed Reality (MR) technologies such as Virtual and Augmented Reality (VR,\nAR) are well established in medical practice, enhancing diagnostics, treatment,\nand education. However, there are still some limitations and challenges that\nmay be overcome thanks to the latest generations of equipment, software, and\nframeworks based on eXtended Reality (XR) by enabling immersive systems that\nsupport safer, more controlled environments for training and patient care. Our\nreview highlights recent VR and AR applications in key areas of medicine. In\nmedical education, these technologies provide realistic clinical simulations,\nimproving skills and knowledge retention. In surgery, immersive tools enhance\nprocedural precision with detailed anatomical visualizations. VR-based\nrehabilitation has shown effectiveness in restoring motor functions and\nbalance, particularly for neurological patients. In mental health, VR has been\nsuccessful in treating conditions like PTSD and phobias. Although VR and AR\nsolutions are well established, there are still some important limitations,\nincluding high costs and limited tactile feedback, which may be overcome with\nimplementing new technologies that may improve the effectiveness of immersive\nmedical applications such as XR, psychophysiological feedback or integration of\nartificial intelligence (AI) for real-time data analysis and personalized\nhealthcare and training.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86\u6df7\u5408\u73b0\u5b9e\uff08MR\uff09\u6280\u672f\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\uff0c\u5305\u62ec\u6559\u80b2\u3001\u624b\u672f\u3001\u5eb7\u590d\u548c\u5fc3\u7406\u5065\u5eb7\u7b49\u65b9\u9762\uff0c\u540c\u65f6\u6307\u51fa\u5f53\u524d\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u901a\u8fc7\u65b0\u6280\u672f\uff08\u5982XR\u3001AI\uff09\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u6027\u7684\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u548c\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u6280\u672f\u5df2\u5728\u533b\u7597\u5b9e\u8df5\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u9650\u5236\u548c\u6311\u6218\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u4e00\u4ee3\u8bbe\u5907\u548c\u6846\u67b6\uff08\u5982XR\uff09\uff0c\u53ef\u80fd\u8fdb\u4e00\u6b65\u4f18\u5316\u6c89\u6d78\u5f0f\u7cfb\u7edf\uff0c\u4ee5\u63d0\u5347\u533b\u7597\u57f9\u8bad\u548c\u60a3\u8005\u62a4\u7406\u7684\u5b89\u5168\u6027\u548c\u53ef\u63a7\u6027\u3002", "method": "\u901a\u8fc7\u56de\u987e\u548c\u5206\u6790\u8fd1\u671fVR\u548cAR\u5728\u533b\u7597\u9886\u57df\u7684\u5173\u952e\u5e94\u7528\uff0c\u5305\u62ec\u6559\u80b2\u6a21\u62df\u3001\u624b\u672f\u8f85\u52a9\u3001\u5eb7\u590d\u6cbb\u7597\u548c\u5fc3\u7406\u5065\u5eb7\u5e72\u9884\u7b49\u65b9\u9762\u7684\u6848\u4f8b\u3002", "result": "VR\u548cAR\u6280\u672f\u5728\u533b\u5b66\u6559\u80b2\u3001\u624b\u672f\u7cbe\u786e\u6027\u3001\u529f\u80fd\u5eb7\u590d\u548c\u5fc3\u7406\u5065\u5eb7\u6cbb\u7597\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6548\u679c\u3002\u7136\u800c\uff0c\u9ad8\u6210\u672c\u548c\u6709\u9650\u7684\u89e6\u89c9\u53cd\u9988\u4ecd\u662f\u4e3b\u8981\u9650\u5236\u3002", "conclusion": "\u5c3d\u7ba1VR\u548cAR\u6280\u672f\u5df2\u5728\u533b\u7597\u9886\u57df\u53d6\u5f97\u6210\u679c\uff0c\u4f46\u4ecd\u9700\u901a\u8fc7\u6574\u5408\u65b0\u6280\u672f\uff08\u5982XR\u3001AI\uff09\u6765\u514b\u670d\u73b0\u6709\u6311\u6218\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u533b\u7597\u5e94\u7528\u7684\u6548\u80fd\u548c\u4e2a\u6027\u5316\u3002"}}
{"id": "2507.19479", "pdf": "https://arxiv.org/pdf/2507.19479", "abs": "https://arxiv.org/abs/2507.19479", "authors": ["Wies\u0142aw Kope\u0107", "Jaros\u0142aw Kowalski", "Aleksander Majda", "Anna Duszyk-Bogorodzka", "Anna Jaskulska", "Cezary Biele"], "title": "IoT and Older Adults: Towards Multimodal EMG and AI-Based Interaction with Smart Home", "categories": ["cs.HC"], "comment": null, "summary": "We report preliminary insights from an exploratory study on non-standard\nnon-invasive interfaces for Smart Home Technologies (SHT). This study is part\nof a broader research project on effective Smart Home ecosystem Sagacity that\nwill target older adults, impaired persons, and other groups disadvantaged in\nthe main technology discourse. Therefore, this research is in line with a\nlong-term research framework of the HASE research group (Human Aspects in\nScience and Engineering) by the Living Lab Kobo. In our study, based on the\nprototype of the comprehensive SHT management system Sagacity, we investigated\nthe potential of bioelectric signals, in particular EMG and EOG as a\ncomplementary interface for SHT. Based on our previous participatory research\nand studies on multimodal interfaces, including VUI and BCI, we prepared an\nin-depth interactive hands-on experience workshops with direct involvement of\nvarious groups of potential end users, including older adults and impaired\npersons (total 18 subjects) to explore and investigate the potential of\nsolutions based on this type of non-standard interfaces. The preliminary\ninsights from the study unveil the potential of EMG/EOG interfaces in\nmultimodal SHT management, alongside limitations and challenges stemming from\nthe current state of technology and recommendations for designing multimodal\ninteraction paradigms pinpointing areas of interest to pursue in further\nstudies.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u7528\u4e8e\u667a\u80fd\u5bb6\u5c45\u6280\u672f\uff08SHT\uff09\u7684\u975e\u6807\u51c6\u975e\u4fb5\u5165\u5f0f\u63a5\u53e3\uff08\u5982EMG/EOG\uff09\uff0c\u9488\u5bf9\u8001\u5e74\u4eba\u548c\u6b8b\u969c\u4eba\u58eb\u7b49\u7fa4\u4f53\uff0c\u521d\u6b65\u63ed\u793a\u4e86\u5176\u6f5c\u529b\u53ca\u5f53\u524d\u6280\u672f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u65e8\u5728\u4e3a\u8001\u5e74\u4eba\u548c\u6b8b\u969c\u4eba\u58eb\u7b49\u7fa4\u4f53\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u667a\u80fd\u5bb6\u5c45\u6280\u672f\u63a5\u53e3\uff0c\u5f25\u8865\u73b0\u6709\u6280\u672f\u8ba8\u8bba\u4e2d\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u53c2\u4e0e\u5f0f\u7814\u7a76\uff0c\u57fa\u4e8eSagacity\u539f\u578b\u7cfb\u7edf\uff0c\u5f00\u5c55\u6df1\u5ea6\u4e92\u52a8\u5de5\u4f5c\u574a\uff0c\u8c03\u67e5\u751f\u7269\u7535\u4fe1\u53f7\uff08EMG/EOG\uff09\u4f5c\u4e3a\u8865\u5145\u63a5\u53e3\u7684\u6f5c\u529b\u3002", "result": "\u521d\u6b65\u53d1\u73b0EMG/EOG\u63a5\u53e3\u5728\u591a\u6a21\u6001SHT\u7ba1\u7406\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u7684\u9650\u5236\u548c\u8bbe\u8ba1\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u591a\u6a21\u6001\u4ea4\u4e92\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u5e76\u5efa\u8bae\u8fdb\u4e00\u6b65\u63a2\u7d22\u76f8\u5173\u6280\u672f\u3002"}}
{"id": "2507.18820", "pdf": "https://arxiv.org/pdf/2507.18820", "abs": "https://arxiv.org/abs/2507.18820", "authors": ["Rachel Ringe", "Robin Nolte", "Nima Zargham", "Robert Porzel", "Rainer Malaka"], "title": "MetaMorph -- A Metamodelling Approach For Robot Morphology", "categories": ["cs.RO", "cs.HC"], "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Robot appearance crucially shapes Human-Robot Interaction (HRI) but is\ntypically described via broad categories like anthropomorphic, zoomorphic, or\ntechnical. More precise approaches focus almost exclusively on anthropomorphic\nfeatures, which fail to classify robots across all types, limiting the ability\nto draw meaningful connections between robot design and its effect on\ninteraction. In response, we present MetaMorph, a comprehensive framework for\nclassifying robot morphology. Using a metamodeling approach, MetaMorph was\nsynthesized from 222 robots in the IEEE Robots Guide, offering a structured\nmethod for comparing visual features. This model allows researchers to assess\nthe visual distances between robot models and explore optimal design traits\ntailored to different tasks and contexts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMetaMorph\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u7c7b\u673a\u5668\u4eba\u5f62\u6001\uff0c\u5f25\u8865\u73b0\u6709\u5206\u7c7b\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u5916\u89c2\u5206\u7c7b\u65b9\u6cd5\u8fc7\u4e8e\u5bbd\u6cdb\u6216\u4ec5\u5173\u6ce8\u62df\u4eba\u5316\u7279\u5f81\uff0c\u65e0\u6cd5\u5168\u9762\u6bd4\u8f83\u4e0d\u540c\u673a\u5668\u4eba\u7c7b\u578b\u7684\u8bbe\u8ba1\u6548\u679c\u3002", "method": "\u901a\u8fc7\u5206\u6790222\u4e2aIEEE\u673a\u5668\u4eba\u6307\u5357\u4e2d\u7684\u673a\u5668\u4eba\uff0c\u91c7\u7528\u5143\u5efa\u6a21\u65b9\u6cd5\u6784\u5efaMetaMorph\u6846\u67b6\u3002", "result": "MetaMorph\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u6bd4\u8f83\u673a\u5668\u4eba\u5916\u89c2\u7279\u5f81\u5e76\u63a2\u7d22\u9002\u5408\u4e0d\u540c\u4efb\u52a1\u7684\u8bbe\u8ba1\u7279\u6027\u3002", "conclusion": "MetaMorph\u4e3a\u673a\u5668\u4eba\u8bbe\u8ba1\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u5206\u7c7b\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u4eba\u673a\u4ea4\u4e92\u3002"}}
{"id": "2507.18905", "pdf": "https://arxiv.org/pdf/2507.18905", "abs": "https://arxiv.org/abs/2507.18905", "authors": ["Rachel L. Draelos", "Samina Afreen", "Barbara Blasko", "Tiffany Brazile", "Natasha Chase", "Dimple Desai", "Jessica Evert", "Heather L. Gardner", "Lauren Herrmann", "Aswathy Vaikom House", "Stephanie Kass", "Marianne Kavan", "Kirshma Khemani", "Amanda Koire", "Lauren M. McDonald", "Zahraa Rabeeah", "Amy Shah"], "title": "Large language models provide unsafe answers to patient-posed medical questions", "categories": ["cs.CL", "cs.HC"], "comment": "20 pages", "summary": "Millions of patients are already using large language model (LLM) chatbots\nfor medical advice on a regular basis, raising patient safety concerns. This\nphysician-led red-teaming study compares the safety of four publicly available\nchatbots--Claude by Anthropic, Gemini by Google, GPT-4o by OpenAI, and\nLlama3-70B by Meta--on a new dataset, HealthAdvice, using an evaluation\nframework that enables quantitative and qualitative analysis. In total, 888\nchatbot responses are evaluated for 222 patient-posed advice-seeking medical\nquestions on primary care topics spanning internal medicine, women's health,\nand pediatrics. We find statistically significant differences between chatbots.\nThe rate of problematic responses varies from 21.6 percent (Claude) to 43.2\npercent (Llama), with unsafe responses varying from 5 percent (Claude) to 13\npercent (GPT-4o, Llama). Qualitative results reveal chatbot responses with the\npotential to lead to serious patient harm. This study suggests that millions of\npatients could be receiving unsafe medical advice from publicly available\nchatbots, and further work is needed to improve the clinical safety of these\npowerful tools.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u56db\u79cd\u516c\u5f00AI\u804a\u5929\u673a\u5668\u4eba\u5728\u533b\u7597\u5efa\u8bae\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u4e0d\u540c\u673a\u5668\u4eba\u7684\u95ee\u9898\u56de\u7b54\u7387\u548c\u4e0d\u5b89\u5168\u56de\u7b54\u7387\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u63d0\u51fa\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u5176\u4e34\u5e8a\u5b89\u5168\u6027\u3002", "motivation": "\u8bc4\u4f30AI\u804a\u5929\u673a\u5668\u4eba\u5728\u63d0\u4f9b\u533b\u7597\u5efa\u8bae\u65f6\u7684\u5b89\u5168\u6027\uff0c\u4ee5\u89e3\u51b3\u60a3\u8005\u5b89\u5168\u62c5\u5fe7\u3002", "method": "\u901a\u8fc7\u7ea2\u961f\u6d4b\u8bd5\uff0c\u4f7f\u7528\u65b0\u6570\u636e\u96c6HealthAdvice\u5bf9\u56db\u79cd\u804a\u5929\u673a\u5668\u4eba\uff08Claude\u3001Gemini\u3001GPT-4o\u3001Llama3-70B\uff09\u7684888\u4e2a\u56de\u7b54\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u95ee\u9898\u56de\u7b54\u7387\u4ece21.6%\uff08Claude\uff09\u523043.2%\uff08Llama\uff09\uff0c\u4e0d\u5b89\u5168\u56de\u7b54\u7387\u4ece5%\uff08Claude\uff09\u523013%\uff08GPT-4o\u3001Llama\uff09\u3002", "conclusion": "\u5f53\u524d\u516c\u5f00\u804a\u5929\u673a\u5668\u4eba\u53ef\u80fd\u4e3a\u60a3\u8005\u63d0\u4f9b\u4e0d\u5b89\u5168\u533b\u7597\u5efa\u8bae\uff0c\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u4e34\u5e8a\u5b89\u5168\u6027\u3002"}}
{"id": "2507.19132", "pdf": "https://arxiv.org/pdf/2507.19132", "abs": "https://arxiv.org/abs/2507.19132", "authors": ["Xuetian Chen", "Yinghao Chen", "Xinfeng Yuan", "Zhuo Peng", "Lu Chen", "Yuekeng Li", "Zhoujia Zhang", "Yingqian Huang", "Leyan Huang", "Jiaqing Liang", "Tianbao Xie", "Zhiyong Wu", "Qiushi Sun", "Biqing Qi", "Bowen Zhou"], "title": "OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": "Work in progress", "summary": "Computer-using agents have shown strong potential to boost human productivity\nand enable new application forms across platforms. While recent advances have\nled to usable applications, existing benchmarks fail to account for the\ninternal task heterogeneity and the corresponding agent capabilities, as well\nas their alignment with actual user demands-hindering both targeted capability\ndevelopment and the reliable transition of research progress into practical\ndeployment. To bridge the gap, we present OS-MAP, a benchmark for daily\ncomputer-using automation that organizes its 416 realistic tasks across 15\napplications along two key dimensions: a five-level taxonomy of automation and\na generalization scope derived from a real-world user demand hierarchy. To\nenable fine-grained analysis of required capabilities and alignment with\nreal-world scenarios, OS-MAP evaluates agents along two dimensions: automation\nlevel across a five-level taxonomy, and generalization scope across a demand\nhierarchy. This design captures varying levels of required agent autonomy and\ngeneralization, forming a performance-generalization evaluation matrix for\nstructured and comprehensive assessment. Experiments show that even\nState-of-the-Art agents with VLM backbones struggle with higher-level tasks\ninvolving perception, reasoning, and coordination-highlighting the need for a\ndeeper understanding of current strengths and limitations to drive the future\nprogress in computer-using agents research and deployment. All code,\nenvironments, baselines, and data are publicly available at\nhttps://github.com/OS-Copilot/OS-Map.", "AI": {"tldr": "OS-MAP\u662f\u4e00\u4e2a\u65b0\u7684\u8ba1\u7b97\u673a\u4ee3\u7406\u57fa\u51c6\uff0c\u901a\u8fc7\u4e94\u7ea7\u81ea\u52a8\u5316\u5206\u7c7b\u548c\u9700\u6c42\u5c42\u6b21\u7ed3\u6784\u8bc4\u4f30\u4ee3\u7406\u80fd\u529b\uff0c\u63ed\u793a\u5f53\u524d\u4ee3\u7406\u5728\u9ad8\u5c42\u6b21\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u672a\u8003\u8651\u4efb\u52a1\u5f02\u8d28\u6027\u548c\u7528\u6237\u9700\u6c42\u5bf9\u9f50\uff0c\u963b\u788d\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51faOS-MAP\u57fa\u51c6\uff0c\u5305\u542b416\u4e2a\u4efb\u52a1\uff0c\u6cbf\u81ea\u52a8\u5316\u548c\u9700\u6c42\u5c42\u6b21\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u4ee3\u7406\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u4ee3\u7406\u5728\u9ad8\u5c42\u6b21\u4efb\u52a1\u4e2d\u4e5f\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "OS-MAP\u4e3a\u8ba1\u7b97\u673a\u4ee3\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8bc4\u4f30\u5de5\u5177\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee3\u7406\u80fd\u529b\u3002"}}
{"id": "2507.19156", "pdf": "https://arxiv.org/pdf/2507.19156", "abs": "https://arxiv.org/abs/2507.19156", "authors": ["Gioele Giachino", "Marco Rondina", "Antonio Vetr\u00f2", "Riccardo Coppola", "Juan Carlos De Martin"], "title": "An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": "16 pages, European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases (ECML PKDD 2025) - 5th Workshop\n  on Bias and Fairness in AI (BIAS25)", "summary": "The increasing use of Large Language Models (LLMs) in a large variety of\ndomains has sparked worries about how easily they can perpetuate stereotypes\nand contribute to the generation of biased content. With a focus on gender and\nprofessional bias, this work examines in which manner LLMs shape responses to\nungendered prompts, contributing to biased outputs. This analysis uses a\nstructured experimental method, giving different prompts involving three\ndifferent professional job combinations, which are also characterized by a\nhierarchical relationship. This study uses Italian, a language with extensive\ngrammatical gender differences, to highlight potential limitations in current\nLLMs' ability to generate objective text in non-English languages. Two popular\nLLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google\nGemini (gemini-1.5-flash). Through APIs, we collected a range of 3600\nresponses. The results highlight how content generated by LLMs can perpetuate\nstereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'\npronouns to the 'assistant' rather than the 'manager'. The presence of bias in\nAI-generated text can have significant implications in many fields, such as in\nthe workplaces or in job selections, raising ethical concerns about its use.\nUnderstanding these risks is pivotal to developing mitigation strategies and\nassuring that AI-based systems do not increase social inequalities, but rather\ncontribute to more equitable outcomes. Future research directions include\nexpanding the study to additional chatbots or languages, refining prompt\nengineering methods or further exploiting a larger experimental base.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u975e\u82f1\u8bed\u8bed\u8a00\uff08\u610f\u5927\u5229\u8bed\uff09\u4e2d\u5982\u4f55\u901a\u8fc7\u975e\u6027\u522b\u5316\u63d0\u793a\u751f\u6210\u6027\u522b\u548c\u804c\u4e1a\u504f\u89c1\u5185\u5bb9\uff0c\u6307\u51faLLMs\u53ef\u80fd\u52a0\u5267\u793e\u4f1a\u4e0d\u5e73\u7b49\u3002", "motivation": "LLMs\u5e7f\u6cdb\u4f7f\u7528\u5f15\u53d1\u4e86\u5bf9\u751f\u6210\u504f\u89c1\u5185\u5bb9\u7684\u62c5\u5fe7\uff0c\u5c24\u5176\u5728\u6027\u522b\u548c\u804c\u4e1a\u9886\u57df\u3002\u7814\u7a76\u805a\u7126\u4e8e\u610f\u5927\u5229\u8bed\uff0c\u8bc4\u4f30LLMs\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e2d\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u4e24\u79cdLLM\uff08ChatGPT\u548cGemini\uff09\u5bf9\u975e\u6027\u522b\u5316\u63d0\u793a\u7684\u54cd\u5e94\uff0c\u6536\u96c63600\u6761\u56de\u590d\u6570\u636e\u3002", "result": "\u7ed3\u679c\u663e\u793aLLMs\uff08\u5982Gemini 100%\u548cChatGPT 97%\uff09\u503e\u5411\u4e8e\u5c06\u6027\u522b\u4ee3\u8bcd\u4e0e\u523b\u677f\u804c\u4e1a\u89d2\u8272\u5173\u8054\uff0c\u8868\u660e\u504f\u89c1\u666e\u904d\u5b58\u5728\u3002", "conclusion": "LLMs\u7684\u504f\u89c1\u53ef\u80fd\u5bf9\u793e\u4f1a\u591a\u9886\u57df\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u5f00\u53d1\u7f13\u89e3\u7b56\u7565\u4ee5\u786e\u4fdd\u516c\u5e73\u3002\u672a\u6765\u53ef\u6269\u5c55\u7814\u7a76\u81f3\u66f4\u591a\u8bed\u8a00\u6216\u6a21\u578b\u3002"}}
{"id": "2507.19196", "pdf": "https://arxiv.org/pdf/2507.19196", "abs": "https://arxiv.org/abs/2507.19196", "authors": ["Ruben Janssens", "Tony Belpaeme"], "title": "Towards Multimodal Social Conversations with Robots: Using Vision-Language Models", "categories": ["cs.RO", "cs.CL", "cs.HC"], "comment": "Submitted to the workshop \"Human - Foundation Models Interaction: A\n  Focus On Multimodal Information\" (FoMo-HRI) at IEEE RO-MAN 2025", "summary": "Large language models have given social robots the ability to autonomously\nengage in open-domain conversations. However, they are still missing a\nfundamental social skill: making use of the multiple modalities that carry\nsocial interactions. While previous work has focused on task-oriented\ninteractions that require referencing the environment or specific phenomena in\nsocial interactions such as dialogue breakdowns, we outline the overall needs\nof a multimodal system for social conversations with robots. We then argue that\nvision-language models are able to process this wide range of visual\ninformation in a sufficiently general manner for autonomous social robots. We\ndescribe how to adapt them to this setting, which technical challenges remain,\nand briefly discuss evaluation practices.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4e86\u5982\u4f55\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u793e\u4ea4\u673a\u5668\u4eba\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u80fd\u529b\uff0c\u6307\u51fa\u5176\u5728\u5904\u7406\u5e7f\u6cdb\u89c6\u89c9\u4fe1\u606f\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u63a2\u8ba8\u4e86\u6280\u672f\u6311\u6218\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u793e\u4ea4\u673a\u5668\u4eba\u867d\u80fd\u8fdb\u884c\u5f00\u653e\u9886\u57df\u5bf9\u8bdd\uff0c\u4f46\u7f3a\u4e4f\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5f71\u54cd\u4e86\u793e\u4ea4\u4e92\u52a8\u7684\u81ea\u7136\u6027\u3002", "method": "\u63d0\u51fa\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u793e\u4ea4\u673a\u5668\u4eba\uff0c\u4ee5\u5904\u7406\u591a\u6837\u5316\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u5e76\u63a2\u8ba8\u4e86\u6280\u672f\u9002\u914d\u548c\u6311\u6218\u3002", "result": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u80fd\u591f\u4e3a\u793e\u4ea4\u673a\u5668\u4eba\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u80fd\u529b\u3002", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u662f\u63d0\u5347\u793e\u4ea4\u673a\u5668\u4eba\u591a\u6a21\u6001\u4ea4\u4e92\u80fd\u529b\u7684\u6709\u6548\u9014\u5f84\uff0c\u4f46\u9700\u89e3\u51b3\u76f8\u5173\u6280\u672f\u95ee\u9898\u5e76\u5b8c\u5584\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2507.19316", "pdf": "https://arxiv.org/pdf/2507.19316", "abs": "https://arxiv.org/abs/2507.19316", "authors": ["Shayan S. Mousavi Masouleh", "Corey A. Sanz", "Ryan P. Jansonius", "Cara Cronin", "Jason E. Hein", "Jason Hattrick-Simpers"], "title": "Human-AI Synergy in Adaptive Active Learning for Continuous Lithium Carbonate Crystallization Optimization", "categories": ["cs.CE", "cond-mat.mtrl-sci", "cs.HC", "cs.LG"], "comment": null, "summary": "As demand for high-purity lithium surges with the growth of the electric\nvehicle (EV) industry, cost-effective extraction from lower-grade North\nAmerican sources like the Smackover Formation is critical. These resources,\nunlike high-purity South American brines, require innovative purification\ntechniques to be economically viable. Continuous crystallization is a promising\nmethod for producing battery-grade lithium carbonate, but its optimization is\nchallenged by a complex parameter space and limited data. This study introduces\na Human-in-the-Loop (HITL) assisted active learning framework to optimize the\ncontinuous crystallization of lithium carbonate. By integrating human expertise\nwith data-driven insights, our approach accelerates the optimization of lithium\nextraction from challenging sources. Our results demonstrate the framework's\nability to rapidly adapt to new data, significantly improving the process's\ntolerance to critical impurities like magnesium from the industry standard of a\nfew hundred ppm to as high as 6000 ppm. This breakthrough makes the\nexploitation of low-grade, impurity-rich lithium resources feasible,\npotentially reducing the need for extensive pre-refinement processes. By\nleveraging artificial intelligence, we have refined operational parameters and\ndemonstrated that lower-grade materials can be used without sacrificing product\nquality. This advancement is a significant step towards economically harnessing\nNorth America's vast lithium reserves, such as those in the Smackover\nFormation, and enhancing the sustainability of the global lithium supply chain.", "AI": {"tldr": "\u5229\u7528\u4eba\u673a\u534f\u540c\u7684\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u9502\u78b3\u9178\u76d0\u8fde\u7eed\u7ed3\u6676\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4f4e\u54c1\u4f4d\u9502\u8d44\u6e90\u63d0\u7eaf\u96be\u9898\uff0c\u63d0\u5347\u6742\u8d28\u5bb9\u5fcd\u5ea6\u81f36000 ppm\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u4ea7\u4e1a\u5bf9\u9ad8\u7eaf\u5ea6\u9502\u7684\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u8981\u4ece\u5317\u7f8e\u4f4e\u54c1\u4f4d\u8d44\u6e90\uff08\u5982Smackover Formation\uff09\u4e2d\u7ecf\u6d4e\u9ad8\u6548\u5730\u63d0\u53d6\u9502\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5bf9\u9ad8\u6742\u8d28\u8d44\u6e90\u7684\u9002\u5e94\u6027\u5dee\u3002", "method": "\u63d0\u51fa\u4eba\u673a\u534f\u540c\uff08HITL\uff09\u7684\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\uff0c\u4f18\u5316\u9502\u78b3\u9178\u76d0\u7684\u8fde\u7eed\u7ed3\u6676\u5de5\u827a\u3002", "result": "\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u9541\u7b49\u5173\u952e\u6742\u8d28\u7684\u5bb9\u5fcd\u5ea6\uff08\u4ece\u51e0\u767eppm\u52306000 ppm\uff09\uff0c\u4f7f\u4f4e\u54c1\u4f4d\u9502\u8d44\u6e90\u7684\u5229\u7528\u6210\u4e3a\u53ef\u80fd\uff0c\u51cf\u5c11\u9884\u7cbe\u70bc\u9700\u6c42\u3002", "conclusion": "\u8be5\u6280\u672f\u4e3a\u5317\u7f8e\u4e30\u5bcc\u9502\u8d44\u6e90\u7684\u7ecf\u6d4e\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u5168\u7403\u9502\u4f9b\u5e94\u94fe\u7684\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2507.19470", "pdf": "https://arxiv.org/pdf/2507.19470", "abs": "https://arxiv.org/abs/2507.19470", "authors": ["Son Quoc Tran", "Tushaar Gangavarapu", "Nicholas Chernogor", "Jonathan P. Chang", "Cristian Danescu-Niculescu-Mizil"], "title": "Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models", "categories": ["cs.CL", "cs.HC"], "comment": "Code and data available as part of ConvoKit:\n  https://convokit.cornell.edu", "summary": "We often rely on our intuition to anticipate the direction of a conversation.\nEndowing automated systems with similar foresight can enable them to assist\nhuman-human interactions. Recent work on developing models with this predictive\ncapacity has focused on the Conversations Gone Awry (CGA) task: forecasting\nwhether an ongoing conversation will derail. In this work, we revisit this task\nand introduce the first uniform evaluation framework, creating a benchmark that\nenables direct and reliable comparisons between different architectures. This\nallows us to present an up-to-date overview of the current progress in CGA\nmodels, in light of recent advancements in language modeling. Our framework\nalso introduces a novel metric that captures a model's ability to revise its\nforecast as the conversation progresses.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u8f83\u5bf9\u8bdd\u9884\u6d4b\u6a21\u578b\u5728\u2018Conversations Gone Awry\u2019\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u6307\u6807\u6765\u6355\u6349\u6a21\u578b\u4fee\u6b63\u9884\u6d4b\u7684\u80fd\u529b\u3002", "motivation": "\u76f4\u89c9\u5728\u5bf9\u8bdd\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\uff0c\u8d4b\u4e88\u81ea\u52a8\u5316\u7cfb\u7edf\u7c7b\u4f3c\u7684\u9884\u89c1\u6027\u53ef\u4ee5\u8f85\u52a9\u4eba\u9645\u4e92\u52a8\u3002\u7814\u7a76\u805a\u7126\u4e8e\u9884\u6d4b\u5bf9\u8bdd\u662f\u5426\u4f1a\u504f\u79bb\u6b63\u8f68\u7684\u4efb\u52a1\uff0c\u5e76\u8bd5\u56fe\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u8bc4\u4f30\u6a21\u578b\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u51c6\uff0c\u652f\u6301\u4e0d\u540c\u67b6\u6784\u7684\u76f4\u63a5\u6bd4\u8f83\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6307\u6807\u4ee5\u8861\u91cf\u6a21\u578b\u968f\u5bf9\u8bdd\u8fdb\u5c55\u4fee\u6b63\u9884\u6d4b\u7684\u80fd\u529b\u3002", "result": "\u6846\u67b6\u63d0\u4f9b\u4e86\u5bf9\u5f53\u524d\u5bf9\u8bdd\u9884\u6d4b\u6a21\u578b\u8fdb\u5c55\u7684\u5168\u9762\u6982\u8ff0\uff0c\u5e76\u901a\u8fc7\u65b0\u6307\u6807\u8bc4\u4f30\u4e86\u6a21\u578b\u7684\u52a8\u6001\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u65b0\u6307\u6807\u4e3a\u5bf9\u8bdd\u9884\u6d4b\u6a21\u578b\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u57fa\u7840\u548c\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
