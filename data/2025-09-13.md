<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 13]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.HC](#cs.HC) [Total: 16]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.CC](#cs.CC) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.CY](#cs.CY) [Total: 3]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Pattern-Based File and Data Access with Python Glob: A Comprehensive Guide for Computational Research](https://arxiv.org/abs/2509.08843)
*Sidney Shapiro*

Main category: cs.SE

TL;DR: 本文介绍了Python的glob模块在数据科学、商业分析和AI应用中的多功能性，通过实例展示了其在文件遍历和数据处理中的作用，强调了其在可重复研究和数据工程中的重要性。


<details>
  <summary>Details</summary>
Motivation: Glob模块作为文件模式匹配的基础工具，在研究中常被忽视或缺乏详细文档，本文旨在填补这一空白，提供一个简洁的参考。

Method: 通过具体的Python示例（使用pandas、scikit-learn和matplotlib等库），展示了glob在大规模数据摄取、组织数据分析、AI数据集构建和可重复研究中的应用。

Result: Glob模块被证明是一个高效的文件遍历工具，能够无缝集成到分析流程中，是多学科研究中不可或缺的方法论基础。

Conclusion: Glob模块应成为Python研究中文件模式匹配的标准引用，本文为研究人员和从业者提供了一个从基础概念到应用实践的桥梁。

Abstract: Pattern-based file access is a fundamental but often under-documented aspect
of computational research. The Python glob module provides a simple yet
powerful way to search, filter, and ingest files using wildcard patterns,
enabling scalable workflows across disciplines. This paper introduces glob as a
versatile tool for data science, business analytics, and artificial
intelligence applications. We demonstrate use cases including large-scale data
ingestion, organizational data analysis, AI dataset construction, and
reproducible research practices. Through concrete Python examples with widely
used libraries such as pandas,scikit-learn, and matplotlib, we show how glob
facilitates efficient file traversal and integration with analytical pipelines.
By situating glob within the broader context of reproducible research and data
engineering, we highlight its role as a methodological building block. Our goal
is to provide researchers and practitioners with a concise reference that
bridges foundational concepts and applied practice, making glob a default
citation for file pattern matching in Python-based research workflows.

</details>


### [2] [A Systematic Mapping Study on Chatbots in Programming Education](https://arxiv.org/abs/2509.08857)
*Marcelino Garcia,Renato Garcia,Arthur Parizotto,Andre Mendes,Pedro Valle,Ricardo Vilela,Renato Balancieri,Williamson Silva*

Main category: cs.SE

TL;DR: 对教育聊天机器人在编程教学中应用的系统映射研究，分析了54项研究，发现Python教学为主导，内容为编程基础，并提出未来工具开发的建议。


<details>
  <summary>Details</summary>
Motivation: 研究教育聊天机器人作为编程教学支持工具的开发和应用现状。

Method: 采用系统映射研究方法，从3216篇文献中筛选54篇，围绕五个研究子问题进行分析。

Result: 结果显示聊天机器人主要用于Python教学，关注编程基础，采用多种教学和技术架构。

Conclusion: 研究揭示了当前趋势和文献缺口，为未来编程教学工具的开发提供了参考。

Abstract: Educational chatbots have gained prominence as support tools for teaching
programming, particularly in introductory learning contexts. This paper
presents a Systematic Mapping Study (SMS) that investigated how such agents
have been developed and applied in programming education. From an initial set
of 3,216 publications, 54 studies were selected and analyzed based on five
research subquestions, addressing chatbot types, programming languages used,
educational content covered, interaction models, and application contexts. The
results reveal a predominance of chatbots designed for Python instruction,
focusing on fundamental programming concepts, and employing a wide variety of
pedagogical approaches and technological architectures. In addition to
identifying trends and gaps in the literature, this study provides insights to
inform the development of new educational tools for programming instruction.

</details>


### [3] [GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial Analysis-Function Calling vs Code Generation](https://arxiv.org/abs/2509.08863)
*Qianqian Luo,Liuchang Xu,Qingming Lin,Sensen Wu,Ruichen Mao,Chao Wang,Hailin Feng,Bo Huang,Zhenhong Du*

Main category: cs.SE

TL;DR: GeoJSON Agents是一个多智能体LLM架构，通过自然语言任务转化为GeoJSON操作命令，提升GIS自动化性能。实验显示基于代码生成的Agent性能更优。


<details>
  <summary>Details</summary>
Motivation: LLMs在GIS领域由于缺乏专业知识存在局限，需要解决方案提升自动化性能。

Method: 提出GeoJSON Agents框架，包括任务解析、智能体协作和结果集成，采用Function Calling和Code Generation技术。

Result: 基于Function Calling的GeoJSON Agent准确率85.71%，Code Generation达到97.14%，显著优于通用模型。

Conclusion: Code Generation灵活性更高，Function Calling执行更稳定，为GeoAI系统性能提升提供新视角。

Abstract: LLMs have made substantial progress in task automation and natural language
understanding.However,without expertise in GIS,they continue to encounter
limitations.To address these issues, we propose GeoJSON Agents-a multi-agent
LLM architecture.This framework transforms natural language tasks into
structured GeoJSON operation commands and processes spatial data using two
widely adopted LLM enhancement techniques:Function Calling and Code
Generation.The architecture consists of three components-task parsing,agent
collaboration,and result integration-aimed at enhancing both the performance
and scalability of GIS automation.The Planner agent interprets natural language
tasks into structured GeoJSON commands.Then,specialized Worker agents
collaborate according to assigned roles to perform spatial data processing and
analysis,either by invoking predefined function APIs or by dynamically
generating and executing Python-based spatial analysis code.Finally,the system
integrates the outputs from multiple execution rounds into
reusable,standards-compliant GeoJSON files.To systematically evaluate the
performance of the two approaches,we constructed a benchmark dataset of 70
tasks with varying complexity and conducted experiments using OpenAI's GPT-4o
as the core model.Results indicate that the Function Calling-based GeoJSON
Agent achieved an accuracy of 85.71%,while the Code Generation-based agent
reached 97.14%,both significantly outperforming the best-performing
general-purpose model (48.57%).Further analysis reveals that the Code
Generation provides greater flexibility,whereas the Function Calling approach
offers more stable execution.This study is the first to introduce an LLM
multi-agent framework for GeoJSON data and to compare the strengths and
limitations of two mainstream LLM enhancement methods,offering new perspectives
for improving GeoAI system performance.

</details>


### [4] [TraceRAG: A LLM-Based Framework for Explainable Android Malware Detection and Behavior Analysis](https://arxiv.org/abs/2509.08865)
*Guangyu Zhang,Xixuan Wang,Shiyu Sun,Peiyan Xiao,Kun Sun,Yanhai Xiong*

Main category: cs.SE

TL;DR: TraceRAG是一种基于检索增强生成（RAG）的框架，通过自然语言查询和Java代码结合，提供可解释的恶意软件检测与分析。


<details>
  <summary>Details</summary>
Motivation: 恶意Android应用的复杂逃避策略和深层语义隐藏，需要更健壮且深入的分析框架，传统方法难以满足。

Method: TraceRAG生成方法级代码摘要并索引，通过语义检索相关代码片段，最终生成可读报告。

Result: 实验显示96%的恶意软件检测准确率和83.81%的行为识别准确率，专家认可其实用性。

Conclusion: TraceRAG通过结合LLM技术，有效提升了恶意软件分析的准确性和可解释性。

Abstract: Sophisticated evasion tactics in malicious Android applications, combined
with their intricate behavioral semantics, enable attackers to conceal
malicious logic within legitimate functions, underscoring the critical need for
robust and in-depth analysis frameworks. However, traditional analysis
techniques often fail to recover deeply hidden behaviors or provide
human-readable justifications for their decisions. Inspired by advances in
large language models (LLMs), we introduce TraceRAG, a retrieval-augmented
generation (RAG) framework that bridges natural language queries and Java code
to deliver explainable malware detection and analysis. First, TraceRAG
generates summaries of method-level code snippets, which are indexed in a
vector database. At query time, behavior-focused questions retrieve the most
semantically relevant snippets for deeper inspection. Finally, based on the
multi-turn analysis results, TraceRAG produces human-readable reports that
present the identified malicious behaviors and their corresponding code
implementations. Experimental results demonstrate that our method achieves 96\%
malware detection accuracy and 83.81\% behavior identification accuracy based
on updated VirusTotal (VT) scans and manual verification. Furthermore, expert
evaluation confirms the practical utility of the reports generated by TraceRAG.

</details>


### [5] [Benchmarking Energy Efficiency of Large Language Models Using vLLM](https://arxiv.org/abs/2509.08867)
*K. Pronk,Q. Zhao*

Main category: cs.SE

TL;DR: 该论文提出了一个名为LLM Efficiency Benchmark的基准测试，旨在模拟真实应用场景，评估大型语言模型（LLMs）的能源效率。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs的部署和使用消耗大量能源，对气候产生负面影响，因此需要更准确地评估其能源效率，以帮助开发者构建更可持续的AI系统。

Method: 采用高吞吐量、生产就绪的LLM服务后端vLLM，设计基准测试，考察模型大小、架构和并发请求量等因素对推理能源效率的影响。

Result: 研究证明了可以设计更贴近实际部署条件的能源效率基准测试，为开发者提供实用建议。

Conclusion: 该基准测试为开发者提供了评估LLMs能源效率的有效工具，有助于推动可持续AI的发展。

Abstract: The prevalence of Large Language Models (LLMs) is having an growing impact on
the climate due to the substantial energy required for their deployment and
use. To create awareness for developers who are implementing LLMs in their
products, there is a strong need to collect more information about the energy
efficiency of LLMs. While existing research has evaluated the energy efficiency
of various models, these benchmarks often fall short of representing realistic
production scenarios. In this paper, we introduce the LLM Efficiency Benchmark,
designed to simulate real-world usage conditions. Our benchmark utilizes vLLM,
a high-throughput, production-ready LLM serving backend that optimizes model
performance and efficiency. We examine how factors such as model size,
architecture, and concurrent request volume affect inference energy efficiency.
Our findings demonstrate that it is possible to create energy efficiency
benchmarks that better reflect practical deployment conditions, providing
valuable insights for developers aiming to build more sustainable AI systems.

</details>


### [6] [CLARA: A Developer's Companion for Code Comprehension and Analysis](https://arxiv.org/abs/2509.09072)
*Ahmed Adnan,Mushfiqur Rahman,Saad Sakib Noor,Kazi Sakib*

Main category: cs.SE

TL;DR: CLARA是一款浏览器扩展工具，通过先进的推理模型协助开发者理解代码、重构代码及检测代码质量，其效果经过验证且开源可用。


<details>
  <summary>Details</summary>
Motivation: 现有代码分析工具通常需要预先设置项目、缺乏上下文感知且操作繁琐，CLARA旨在解决这些问题。

Method: CLARA采用先进的推理模型，支持代码理解、重构和质量检测，并通过数据集和用户研究进行评估。

Result: 实验表明CLARA在代码理解和分析中准确、实用，用户评价正面。

Conclusion: CLARA是一款高效、实用的开源工具，显著提升了代码分析的便捷性和准确性。

Abstract: Code comprehension and analysis of open-source project codebases is a task
frequently performed by developers and researchers. However, existing tools
that practitioners use for assistance with such tasks often require prior
project setup, lack context-awareness, and involve significant manual effort.
To address this, we present CLARA, a browser extension that utilizes a
state-of-the-art inference model to assist developers and researchers in: (i)
comprehending code files and code fragments, (ii) code refactoring, and (iii)
code quality attribute detection. We qualitatively evaluated CLARA's inference
model using existing datasets and methodology, and performed a comprehensive
user study with 10 developers and academic researchers to assess its usability
and usefulness. The results show that CLARA is useful, accurate, and practical
in code comprehension and analysis tasks. CLARA is an open-source tool
available at https://github.com/SaadNoor555/CLARA_tool_demo. A video showing
the full capabilities of CLARA can be found at
https://youtu.be/VDKVXvIH41Q?si=qBFsmS_Y4m_9x3YH.

</details>


### [7] [Probing Pre-trained Language Models on Code Changes: Insights from ReDef, a High-Confidence Just-in-Time Defect Prediction Dataset](https://arxiv.org/abs/2509.09192)
*Doha Nam,Taehyoun Kim,Duksan Ryu,Jongmoon Baik*

Main category: cs.SE

TL;DR: ReDef数据集通过回退提交构建高可靠性缺陷预测基准，评估了预训练语言模型对代码修改的理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有JIT-SDP数据集中标签噪声和低精确度问题。

Method: 使用回退提交和GPT辅助筛选构建ReDef数据集，并评估了多种预训练模型和输入编码策略。

Result: 紧凑的diff编码优于完整函数编码，但模型对修改的语义理解仍有限。

Conclusion: 当前预训练模型在代码修改理解上存在局限，需进一步改进。

Abstract: Just-in-Time software defect prediction (JIT-SDP) plays a critical role in
prioritizing risky code changes during code review and continuous integration.
However, existing datasets often suffer from noisy labels and low precision in
identifying bug-inducing commits. To address this, we present ReDef
(Revert-based Defect dataset), a high-confidence benchmark of function-level
modifications curated from 22 large-scale C/C++ projects. Defective cases are
anchored by revert commits, while clean cases are validated through post-hoc
history checks. Ambiguous instances are conservatively filtered out via a
GPT-assisted triage process involving multiple votes and audits. This pipeline
yields 3,164 defective and 10,268 clean modifications, offering substantially
more reliable labels than prior existing resources. Beyond dataset
construction, we provide the first systematic evaluation of how pre-trained
language models (PLMs) reason about code modifications -- specifically, which
input encodings most effectively expose change information, and whether models
genuinely capture edit semantics. We fine-tune CodeBERT, CodeT5+, and UniXcoder
under five encoding strategies, and further probe their sensitivity through
counterfactual perturbations that swap added/deleted blocks, invert diff
polarity, or inject spurious markers. Our results show that compact diff-style
encodings consistently outperform whole-function formats across all PLMs, with
statistical tests confirming large, model-independent effects. However, under
counterfactual tests, performance degrades little or not at all -- revealing
that what appears to be robustness in fact reflects reliance on superficial
cues rather than true semantic understanding. These findings indicate that,
unlike in snapshot-based tasks, current PLMs remain limited in their ability to
genuinely comprehend code modifications.

</details>


### [8] [On Integrating Large Language Models and Scenario-Based Programming for Improving Software Reliability](https://arxiv.org/abs/2509.09194)
*Ayelet Berzack,Guy Katz*

Main category: cs.SE

TL;DR: 该论文提出了一种将大语言模型（LLMs）与传统软件工程技术结合的方法，以减少错误并提高开发效率，通过Scenario-Based Programming（SBP）范式验证模型的输出。


<details>
  <summary>Details</summary>
Motivation: LLMs虽能提升开发效率，但常引入错误代码，需要更可靠的方法来整合LLMs到开发流程中。

Method: 结合LLMs与SBP范式，通过人类专家知识验证和优化模型的输出。

Result: 成功设计并实现了Connect4游戏，验证了方法的有效性，并在某些情况下实现了形式化验证。

Conclusion: 结合LLMs与SBP的方法可行且易用，提高了开发效率和代码可靠性。

Abstract: Large Language Models (LLMs) are fast becoming indispensable tools for
software developers, assisting or even partnering with them in crafting complex
programs. The advantages are evident -- LLMs can significantly reduce
development time, generate well-organized and comprehensible code, and
occasionally suggest innovative ideas that developers might not conceive on
their own. However, despite their strengths, LLMs will often introduce
significant errors and present incorrect code with persuasive confidence,
potentially misleading developers into accepting flawed solutions.
  In order to bring LLMs into the software development cycle in a more reliable
manner, we propose a methodology for combining them with ``traditional''
software engineering techniques in a structured way, with the goal of
streamlining the development process, reducing errors, and enabling users to
verify crucial program properties with increased confidence. Specifically, we
focus on the Scenario-Based Programming (SBP) paradigm -- an event-driven,
scenario-based approach for software engineering -- to allow human developers
to pour their expert knowledge into the LLM, as well as to inspect and verify
its outputs.
  To evaluate our methodology, we conducted a significant case study, and used
it to design and implement the Connect4 game. By combining LLMs and SBP we were
able to create a highly-capable agent, which could defeat various strong
existing agents. Further, in some cases, we were able to formally verify the
correctness of our agent. Finally, our experience reveals interesting insights
regarding the ease-of-use of our proposed approach. The full code of our
case-study will be made publicly available with the final version of this
paper.

</details>


### [9] [Altered Histories in Version Control System Repositories: Evidence from the Trenches](https://arxiv.org/abs/2509.09294)
*Solal Rapaport,Laurent Pautet,Samuel Tardieu,Stefano Zacchiroli*

Main category: cs.SE

TL;DR: 该论文研究了Git版本控制系统中公开代码仓库的历史修改现象，分析了111M仓库中的1.22M存在历史修改行为，并通过案例研究揭示了许可证变更和敏感信息删除等行为。


<details>
  <summary>Details</summary>
Motivation: 探讨Git历史修改对公开分支的影响，包括破坏流程、挑战仓库完整性及供应链攻击风险。

Method: 分析了Software Heritage存档的111M仓库，识别并分类了1.22M仓库中的8.7M历史修改行为。

Result: 发现历史修改常见于许可证变更和敏感信息删除，揭示了不良实践。

Conclusion: 提出了GitHistorian工具，帮助开发者识别和描述公开Git仓库中的历史修改行为。

Abstract: Version Control Systems (VCS) like Git allow developers to locally rewrite
recorded history, e.g., to reorder and suppress commits or specific data in
them. These alterations have legitimate use cases, but become problematic when
performed on public branches that have downstream users: they break push/pull
workflows, challenge the integrity and reproducibility of repositories, and
create opportunities for supply chain attackers to sneak into them nefarious
changes. We conduct the first large-scale investigation of Git history
alterations in public code repositories. We analyze 111 M (millions)
repositories archived by Software Heritage, which preserves VCS histories even
across alterations. We find history alterations in 1.22 M repositories, for a
total of 8.7 M rewritten histories. We categorize changes by where they happen
(which repositories, which branches) and what is changed in them (files or
commit metadata). Conducting two targeted case studies we show that altered
histories recurrently change licenses retroactively, or are used to remove
''secrets'' (e.g., private keys) committed by mistake. As these behaviors
correspond to bad practices-in terms of project governance or security
management, respectively-that software recipients might want to avoid, we
introduce GitHistorian, an automated tool, that developers can use to spot and
describe history alterations in public Git repositories.

</details>


### [10] [Cross-Domain Evaluation of Transformer-Based Vulnerability Detection on Open & Industry Data](https://arxiv.org/abs/2509.09313)
*Moritz Mock,Thomas Forrer,Barbara Russo*

Main category: cs.SE

TL;DR: 论文研究了深度学习在漏洞检测中的工业应用挑战，提出了基于CodeBERT的解决方案AI-DO，并通过实验和调查验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习漏洞检测技术在工业环境中的适用性和集成问题。

Method: 使用CodeBERT在开源和工业数据上进行跨领域泛化测试，并提出AI-DO系统集成到CI/CD流程中。

Result: 工业数据训练的模型在相同领域表现良好，但跨领域性能下降；开源数据微调结合欠采样技术可提升检测效果。

Conclusion: AI-DO系统成功集成到工业工作流中，并通过用户调查验证了其实用性。

Abstract: Deep learning solutions for vulnerability detection proposed in academic
research are not always accessible to developers, and their applicability in
industrial settings is rarely addressed. Transferring such technologies from
academia to industry presents challenges related to trustworthiness, legacy
systems, limited digital literacy, and the gap between academic and industrial
expertise. For deep learning in particular, performance and integration into
existing workflows are additional concerns. In this work, we first evaluate the
performance of CodeBERT for detecting vulnerable functions in industrial and
open-source software. We analyse its cross-domain generalisation when
fine-tuned on open-source data and tested on industrial data, and vice versa,
also exploring strategies for handling class imbalance. Based on these results,
we develop AI-DO(Automating vulnerability detection Integration for Developers'
Operations), a Continuous Integration-Continuous Deployment (CI/CD)-integrated
recommender system that uses fine-tuned CodeBERT to detect and localise
vulnerabilities during code review without disrupting workflows. Finally, we
assess the tool's perceived usefulness through a survey with the company's IT
professionals. Our results show that models trained on industrial data detect
vulnerabilities accurately within the same domain but lose performance on
open-source code, while a deep learner fine-tuned on open data, with
appropriate undersampling techniques, improves the detection of
vulnerabilities.

</details>


### [11] [ORCA: Unveiling Obscure Containers In The Wild](https://arxiv.org/abs/2509.09322)
*Jacopo Bufalino,Agathe Blaise,Stefano Secci*

Main category: cs.SE

TL;DR: 论文探讨了容器化环境中开源库和第三方组件的安全问题，提出了ORCA工具以提高对模糊容器的分析能力。


<details>
  <summary>Details</summary>
Motivation: 现代软件开发依赖容器化环境中的开源库和第三方组件，但这些组件可能存在安全风险。现有的SCA工具在分析模糊容器时存在局限性。

Method: 作者分析了600个流行容器，发现模糊容器广泛存在。他们提出了一种模糊容器分析方法，并开发了ORCA工具。

Result: 实验显示ORCA比Docker Scout和Syft在文件覆盖率上中位数提高了40%，能有效检测模糊容器内容。

Conclusion: ORCA为解决SCA工具在模糊容器分析中的不足提供了有效方案。

Abstract: Modern software development increasingly depends on open-source libraries and
third-party components, which are often encapsulated into containerized
environments. While improving the development and deployment of applications,
this approach introduces security risks, particularly when outdated or
vulnerable components are inadvertently included in production environments.
Software Composition Analysis (SCA) is a critical process that helps identify
and manage packages and dependencies inside a container. However, unintentional
modifications to the container filesystem can lead to incomplete container
images, which compromise the reliability of SCA tools. In this paper, we
examine the limitations of both cloud-based and open-source SCA tools when
faced with such obscure images. An analysis of 600 popular containers revealed
that obscure containers exist in well-known registries and trusted images and
that many tools fail to analyze such containers. To mitigate these issues, we
propose an obscuration-resilient methodology for container analysis and
introduce ORCA (Obscuration-Resilient Container Analyzer), its open-source
implementation. We reported our findings to all vendors using their appropriate
channels. Our results demonstrate that ORCA effectively detects the content of
obscure containers and achieves a median 40% improvement in file coverage
compared to Docker Scout and Syft.

</details>


### [12] [LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering](https://arxiv.org/abs/2509.09614)
*Jielin Qiu,Zuxin Liu,Zhiwei Liu,Rithesh Murthy,Jianguo Zhang,Haolin Chen,Shiyu Wang,Ming Zhu,Liangwei Yang,Juntao Tan,Zhepeng Cen,Cheng Qian,Shelby Heinecke,Weiran Yao,Silvio Savarese,Caiming Xiong,Huan Wang*

Main category: cs.SE

TL;DR: LoCoBench是一个专门为长上下文LLMs设计的基准测试，旨在评估其在复杂软件开发场景中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有代码评估基准主要关注单函数完成或短上下文任务，未能充分评估长上下文能力，特别是在理解和推理大规模代码库方面的需求。

Method: LoCoBench通过一个5阶段流水线生成8000个评估场景，覆盖10种编程语言，上下文长度从10K到1M tokens。引入了8个任务类别和17个指标，包括8个新指标，综合为LCBS分数。

Result: 评估发现，现有长上下文模型在复杂软件开发场景中存在显著的性能差距。

Conclusion: 长上下文理解在复杂软件开发中仍是一个未解决的难题，LoCoBench为此提供了全面的评估工具。

Abstract: The emergence of long-context language models with context windows extending
to millions of tokens has created new opportunities for sophisticated code
understanding and software development evaluation. We propose LoCoBench, a
comprehensive benchmark specifically designed to evaluate long-context LLMs in
realistic, complex software development scenarios. Unlike existing code
evaluation benchmarks that focus on single-function completion or short-context
tasks, LoCoBench addresses the critical evaluation gap for long-context
capabilities that require understanding entire codebases, reasoning across
multiple files, and maintaining architectural consistency across large-scale
software systems. Our benchmark provides 8,000 evaluation scenarios
systematically generated across 10 programming languages, with context lengths
spanning 10K to 1M tokens, a 100x variation that enables precise assessment of
long-context performance degradation in realistic software development
settings. LoCoBench introduces 8 task categories that capture essential
long-context capabilities: architectural understanding, cross-file refactoring,
multi-session development, bug investigation, feature implementation, code
comprehension, integration testing, and security analysis. Through a 5-phase
pipeline, we create diverse, high-quality scenarios that challenge LLMs to
reason about complex codebases at unprecedented scale. We introduce a
comprehensive evaluation framework with 17 metrics across 4 dimensions,
including 8 new evaluation metrics, combined in a LoCoBench Score (LCBS). Our
evaluation of state-of-the-art long-context models reveals substantial
performance gaps, demonstrating that long-context understanding in complex
software development represents a significant unsolved challenge that demands
more attention. LoCoBench is released at:
https://github.com/SalesforceAIResearch/LoCoBench.

</details>


### [13] [I Know Who Clones Your Code: Interpretable Smart Contract Similarity Detection](https://arxiv.org/abs/2509.09630)
*Zhenguang Liu,Lixun Ma,Zhongzheng Mu,Chengkun Wei,Xiaojun Xu,Yingying Jiao,Kui Ren*

Main category: cs.SE

TL;DR: SmartDetector是一种新型智能合约函数相似性检测方法，通过分解AST为语句树并优化分类器参数，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 智能合约开发中广泛使用开源代码，导致bug传播加剧，现有AST方法难以处理复杂树结构，深度学习方法忽视代码语法和可解释性。

Method: 将智能合约函数的AST分解为语句树，使用分类器比较语句树相似性，并通过余弦扩散过程优化超参数。

Result: 在三个数据集上，SmartDetector平均F1-score提升14.01%，达到95.88%。

Conclusion: SmartDetector在性能和可解释性上优于现有方法，为智能合约相似性检测提供了有效解决方案。

Abstract: Widespread reuse of open-source code in smart contract development boosts
programming efficiency but significantly amplifies bug propagation across
contracts, while dedicated methods for detecting similar smart contract
functions remain very limited. Conventional abstract-syntax-tree (AST) based
methods for smart contract similarity detection face challenges in handling
intricate tree structures, which impedes detailed semantic comparison of code.
Recent deep-learning based approaches tend to overlook code syntax and
detection interpretability, resulting in suboptimal performance.
  To fill this research gap, we introduce SmartDetector, a novel approach for
computing similarity between smart contract functions, explainable at the
fine-grained statement level. Technically, SmartDetector decomposes the AST of
a smart contract function into a series of smaller statement trees, each
reflecting a structural element of the source code. Then, SmartDetector uses a
classifier to compute the similarity score of two functions by comparing each
pair of their statement trees. To address the infinite hyperparameter space of
the classifier, we mathematically derive a cosine-wise diffusion process to
efficiently search optimal hyperparameters. Extensive experiments conducted on
three large real-world datasets demonstrate that SmartDetector outperforms
current state-of-the-art methods by an average improvement of 14.01% in
F1-score, achieving an overall average F1-score of 95.88%.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [14] [Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs](https://arxiv.org/abs/2509.09019)
*Mohit Tekriwal,John Sarracino*

Main category: cs.PL

TL;DR: 该论文研究了科学计算程序中浮点优化的正确性验证，特别是在LLVM IR级别上的FMA优化，并提出了扩展方法。


<details>
  <summary>Details</summary>
Motivation: 科学计算程序需要高性能优化，但必须确保优化的正确性，尤其是在浮点运算领域。

Method: 利用Rocq定理证明器中的Verified LLVM框架，验证了基础块中FMA优化的正确性。

Result: 初步验证了FMA优化的正确性，并提出了扩展更多程序功能和浮点优化的方向。

Conclusion: 论文为浮点优化正确性验证提供了初步成果，并规划了进一步的研究方向。

Abstract: Scientific computing programs often undergo aggressive compiler optimization
to achieve high performance and efficient resource utilization. While
performance is critical, we also need to ensure that these optimizations are
correct. In this paper, we focus on a specific class of optimizations,
floating-point optimizations, notably due to fast math, at the LLVM IR level.
We present a preliminary work, which leverages the Verified LLVM framework in
the Rocq theorem prover, to prove the correctness of Fused-Multiply-Add (FMA)
optimization for a basic block implementing the arithmetic expression $a * b +
c$ . We then propose ways to extend this preliminary results by adding more
program features and fast math floating-point optimizations.

</details>


### [15] [Dependent-Type-Preserving Memory Allocation](https://arxiv.org/abs/2509.09059)
*Paulette Koronkevich,William J. Bowman*

Main category: cs.PL

TL;DR: 依赖于类型编程语言中的规范可能在编译后被违反，因为它们会在类型检查后被擦除。外部程序可能违反原始程序的规范，即使使用已验证的编译器。本文通过类型保持编译和中间语言来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 依赖于类型编程语言（如Coq、Agda等）的规范在编译后可能被外部程序违反，这导致程序行为改变。通过类型检查可以阻止与未初始化内存程序链接，但目前缺乏足够的语言表达力。

Method: 提出了一种支持依赖内存分配的类型中间语言，并开发了依赖类型保持的编译器传递，以确保类型信息在编译过程中保留。

Result: 正在进行的工作，开发了一种解决依赖内存分配问题的类型中间语言和类型保持编译器传递。

Conclusion: 通过类型保持编译和中间语言，可以有效防止外部程序违反原始程序的规范，提高程序的安全性。

Abstract: Dependently typed programming languages such as Coq, Agda, Idris, and F*,
allow programmers to write detailed specifications of their programs and prove
their programs meet these specifications. However, these specifications can be
violated during compilation since they are erased after type checking. External
programs linked with the compiled program can violate the specifications of the
original program and change the behavior of the compiled program -- even when
compiled with a verified compiler. For example, since Coq does not allow
explicitly allocating memory, a programmer might link their Coq program with a
C program that can allocate memory. Even if the Coq program is compiled with a
verified compiler, the external C program can still violate the memory-safe
specification of the Coq program by providing an uninitialized pointer to
memory. This error could be ruled out by type checking in a language expressive
enough to indicate whether memory is initialized versus uninitialized. Linking
with a program with an uninitialized pointer could be considered ill-typed, and
our linking process could prevent linking with ill-typed programs. To
facilitate type checking during linking, we can use type-preserving
compilation, which preserves the types through the compilation process. In this
ongoing work, we develop a typed intermediate language that supports dependent
memory allocation, as well as a dependent-type-preserving compiler pass for
memory allocation.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [16] [HD-MoE: Hybrid and Dynamic Parallelism for Mixture-of-Expert LLMs with 3D Near-Memory Processing](https://arxiv.org/abs/2509.09420)
*Haochen Huang,Shuzhang Zhong,Zhe Zhang,Shuangchen Li,Dimin Niu,Hongzhong Zheng,Runsheng Wang,Meng Li*

Main category: cs.PF

TL;DR: 本文提出HD-MoE，通过离线自动混合并行映射算法和在线动态调度策略优化MoE并行计算，提升LLM推理效率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为解决MoE架构LLMs在NMP加速器上因通信成本高和计算利用率不平衡导致的效率低问题。

Method: 采用离线自动混合并行映射算法和在线动态调度策略，优化MoE并行计算。

Result: 实验表明HD-MoE在速度上优于TP、EP及混合TP-EP方法，提升范围为1.1x至1.8x。

Conclusion: HD-MoE有效解决了MoE模型在NMP加速器上的效率问题，显著提升了推理性能。

Abstract: Large Language Models (LLMs) with Mixture-of-Expert (MoE) architectures
achieve superior model performance with reduced computation costs, but at the
cost of high memory capacity and bandwidth requirements. Near-Memory Processing
(NMP) accelerators that stack memory directly on the compute through hybrid
bonding have demonstrated high bandwidth with high energy efficiency, becoming
a promising architecture for MoE models. However, as NMP accelerators comprise
distributed memory and computation, how to map the MoE computation directly
determines the LLM inference efficiency. Existing parallel mapping strategies,
including Tensor Parallelism (TP) and Expert Parallelism (EP), suffer from
either high communication costs or unbalanced computation utilization, leading
to inferior efficiency. The dynamic routing mechanism of MoE LLMs further
aggravates the efficiency challenges. Therefore, in this paper, we propose
HD-MoE to automatically optimize the MoE parallel computation across an NMP
accelerator. HD-MoE features an offline automatic hybrid parallel mapping
algorithm and an online dynamic scheduling strategy to reduce the communication
costs while maximizing the computation utilization. With extensive experimental
results, we demonstrate that HD-MoE achieves a speedup ranging from 1.1x to
1.8x over TP, 1.1x to 1.5x over EP, and 1.0x to 1.4x over the baseline Hybrid
TP-EP with Compute-Balanced parallelism strategies.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [17] [μFork: Supporting POSIX fork Within a Single-Address-Space OS](https://arxiv.org/abs/2509.09439)
*John Alistair Kressel,Hugo Lefeuvre,Pierre Olivier*

Main category: cs.OS

TL;DR: 该论文提出了μFork，一种支持POSIX fork的单地址空间操作系统设计，通过CHERI技术解决内存引用重定位和隔离问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 单地址空间操作系统因其轻量级特性具有优势，但与POSIX多进程应用不兼容。现有方法在轻量级、兼容性和隔离性之间存在权衡。

Method: μFork通过在一个地址空间内复制父进程内存来实现fork，利用CHERI技术解决指针重定位和隔离问题。

Result: μFork在Redis、Nginx和FaaS用例中表现出色，性能比传统fork快3.7倍，函数吞吐量高出24%。

Conclusion: μFork实现了单地址空间操作系统的轻量级特性与POSIX兼容性的平衡，性能显著优于现有方案。

Abstract: Single-address-space operating systems have well-known lightweightness
benefits that result from their central design idea: the kernel and
applications share a unique address space. This model makes these operating
systems (OSes) incompatible by design with a large class of software:
multiprocess POSIX applications. Indeed, the semantics of the primitive used to
create POSIX processes, fork, are inextricably tied to the existence of
multiple address spaces.
  Prior approaches addressing this issue trade off lightweightness,
compatibility and/or isolation. We propose {\mu}Fork, a single-address-space
operating system design supporting POSIX fork on modern hardware without
compromising on any of these key objectives. {\mu}Fork emulates POSIX processes
({\mu}processes) and achieves fork by creating for the child a copy of the
parent {\mu}process' memory at a different location within a single address
space. This approach presents two challenges: relocating the child's absolute
memory references (pointers), as well as providing user/kernel and
{\mu}processes isolation without impacting lightweightness. We address them
using CHERI. We implement {\mu}Fork and evaluate it upon three real-world
use-cases: Redis snapshots, Nginx multi-worker deployments, and Zygote FaaS
worker warm-up. {\mu}Fork outperforms previous work and traditional monolithic
OSes on key lightweightness metrics by an order of magnitude, e.g. it can offer
a fork-bound FaaS function throughput 24% higher than that of a monolithic OS,
and can fork a {\mu}process in 54{\mu}s, 3.7x faster than a traditional fork.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [18] [Fingerprinting Deep Packet Inspection Devices by Their Ambiguities](https://arxiv.org/abs/2509.09081)
*Diwen Xue,Armin Huremagic,Wayne Wang,Ram Sundara Raman,Roya Ensafi*

Main category: cs.NI

TL;DR: 论文提出了一个远程测量框架dMAP，用于识别和聚类DPI设备，揭示其在互联网上的部署情况。


<details>
  <summary>Details</summary>
Motivation: 由于DPI设备的普及，网络干扰（如审查、限速）增加，但其部署情况不明，传统扫描工具难以探测。

Method: 基于差异fuzzing技术，dMAP发现并部署特异探针，将DPI的内部解析行为转化为可观测的指纹。

Result: 实验证明，仅需20-40个探针即可可靠区分多种DPI实现，包括国家级审查设备和商用产品。

Conclusion: dMAP为DPI的主动侦察提供了一种可行方法，且该指纹技术可扩展至其他目标干扰形式的检测。

Abstract: Users around the world face escalating network interference such as
censorship, throttling, and interception, largely driven by the commoditization
and growing availability of Deep Packet Inspection (DPI) devices. Once reserved
for a few well-resourced nation-state actors, the ability to interfere with
traffic at scale is now within reach of nearly any network operator. Despite
this proliferation, our understanding of DPIs and their deployments on the
Internet remains limited -- being network intermediary leaves DPI unresponsive
to conventional host-based scanning tools, and DPI vendors actively obscuring
their products further complicates measurement efforts.
  In this work, we present a remote measurement framework, dMAP (DPI Mapper),
that derives behavioral fingerprints for DPIs to differentiate and cluster
these otherwise indistinguishable middleboxes at scale, as a first step toward
active reconnaissance of DPIs on the Internet. Our key insight is that parsing
and interpreting traffic as network intermediaries inherently involves
ambiguities -- from under-specified protocol behaviors to differing RFC
interpretations -- forcing DPI vendors into independent implementation choices
that create measurable variance among DPIs. Based on differential fuzzing, dMAP
systematically discovers, selects, and deploys specialized probes that
translate DPI internal parsing behaviors into externally observable
fingerprints. Applying dMAP to DPI deployments globally, we demonstrate its
practical feasibility, showing that even a modest set of 20-40 discriminative
probes reliably differentiates a wide range of DPI implementations, including
major nation-state censorship infrastructures and commercial DPI products. We
discuss how our fingerprinting methodology generalizes beyond censorship to
other forms of targeted interference.

</details>


### [19] [AI Reasoning for Wireless Communications and Networking: A Survey and Perspectives](https://arxiv.org/abs/2509.09193)
*Haoxiang Luo,Yu Yan,Yanhui Bian,Wenjiao Feng,Ruichen Zhang,Yinqiu Liu,Jiacheng Wang,Gang Sun,Dusit Niyato,Hongfang Yu,Abbas Jamalipour,Shiwen Mao*

Main category: cs.NI

TL;DR: 本文是对无线通信网络中推理赋能AI的综述与展望，重点探讨了大型语言模型（LLMs）和其他先进推理范式在动态优化网络操作中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在无线通信网络中缺乏结构化推理能力，无法解决复杂的多步决策问题。AI推理技术有望弥补这一缺陷，提升网络性能。

Method: 提出了AI推理技术的分类系统，并分层（物理层到应用层）分析了其在无线网络中的应用和挑战。

Result: 展示了AI推理方法如何提升无线通信性能，并指出了未来研究方向。

Conclusion: 结合通信与AI的洞察，本文为下一代无线网络集成推理技术提供了路径指南。

Abstract: Artificial Intelligence (AI) techniques play a pivotal role in optimizing
wireless communication networks. However, traditional deep learning approaches
often act as closed boxes, lacking the structured reasoning abilities needed to
tackle complex, multi-step decision problems. This survey provides a
comprehensive review and outlook of reasoning-enabled AI in wireless
communication networks, with a focus on Large Language Models (LLMs) and other
advanced reasoning paradigms. In particular, LLM-based agents can combine
reasoning with long-term planning, memory, tool utilization, and autonomous
cross-layer control to dynamically optimize network operations with minimal
human intervention. We begin by outlining the evolution of intelligent wireless
networking and the limitations of conventional AI methods. We then introduce
emerging AI reasoning techniques. Furthermore, we establish a classification
system applicable to wireless network tasks. We also present a layer-by-layer
examination for AI reasoning, covering the physical, data link, network,
transport, and application layers. For each part, we identify key challenges
and illustrate how AI reasoning methods can improve AI-based wireless
communication performance. Finally, we discuss key research directions for AI
reasoning toward future wireless communication networks. By combining insights
from both communications and AI, this survey aims to chart a path for
integrating reasoning techniques into the next-generation wireless networks.

</details>


### [20] [Joint Optimisation of Load Balancing and Energy Efficiency for O-RAN Deployments](https://arxiv.org/abs/2509.09343)
*Mohammed M. H. Qazzaz,Abdelaziz Salama,Maryam Hafeez,Syed A. R. Zaidi*

Main category: cs.NI

TL;DR: O-RAN架构通过xApps利用KPM实现动态RU开关以提升能效，但传统AI/ML方法会导致负载不平衡。本文提出一种ML框架，联合优化负载均衡与能效，实验证明其性能大幅优于基线策略。


<details>
  <summary>Details</summary>
Motivation: 解决传统动态RU开关方法导致的网络负载不平衡问题，同时在能效优化中保持PRB分配的公平性。

Method: 提出ML框架，将问题建模为多类分类系统，预测RU配置并优化EE，采用多阈值策略适应不同优先级。

Result: 实验使用426万次真实网络测量，Random Forest模型的F1-macro性能达98.3%，比基线策略提升195%。

Conclusion: 该框架有效平衡了负载与能效，显著优于传统方法。

Abstract: Open Radio Access Network (O-RAN) architecture provides an intrinsic
capability to exploit key performance monitoring (KPM) within Radio
Intelligence Controller (RIC) to derive network optimisation through xApps.
These xApps can leverage KPM knowledge to dynamically switch on/off the
associated RUs where such a function is supported over the E2 interface.
Several existing studies employ artificial intelligence (AI)/Machine Learning
(ML) based approaches to realise such dynamic sleeping for increased energy
efficiency (EE). Nevertheless, most of these approaches rely upon offloading
user equipment (UE) to carve out a sleeping opportunity. Such an approach
inherently creates load imbalance across the network. Such load imbalance may
impact the throughput performance of offloaded UEs as they might be allocated a
lower number of physical resource blocks (PRBs). Maintaining the same PRB
allocation while addressing the EE at the network level is a challenging task.
To that end, in this article, we present a comprehensive ML-based framework for
joint optimisation of load balancing and EE for ORAN deployments. We formulate
the problem as a multi-class classification system that predictively evaluates
potential RU configurations before optimising the EE, mapping network
conditions to three load balance categories (Well Balanced, Moderately
Balanced, Imbalanced). Our multi-threshold approach (Conservative, Moderate,
Aggressive) accommodates different operational priorities between energy
savings and performance assurance. Experimental evaluation using 4.26 million
real network measurements from simulations demonstrates that our Random Forest
model achieves 98.3% F1-macro performance, representing 195% improvement over
traditional baseline strategies.

</details>


### [21] [Toward quantum-safe scalable networks: an open, standards-aware key management framework](https://arxiv.org/abs/2509.09453)
*Ane Sanz,Asier Atutxa,David Franco,Jasone Astorga,Eduardo Jacob,Diego López*

Main category: cs.NI

TL;DR: 提出了一种集成软件定义网络（SDN）的量子密钥分发（QKD）网络架构，通过虚拟KMS（vKMS）和量子安全控制器（QuSeC）解决密钥管理系统（KMS）识别、中继路径发现和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 当前QKD网络的扩展性受限，中继路径建立缺乏解决方案，需要一种创新的架构来提升QKD网络的效率和安全性。

Method: 结合SDN原理，在节点中建立虚拟KMS（vKMS）和量子安全控制器（QuSeC），通过QuSeC计算端到端中继路径并应用安全策略。

Result: 提出了一种解决KMS识别、中继路径发现和可扩展性的网络架构，并通过安全分析验证了其安全性。

Conclusion: 该架构有效提升了QKD网络的扩展性和安全性，为QKD网络的部署提供了新思路。

Abstract: With the advent of quantum computing, the increasing threats to security
poses a great challenge to communication networks. Recent innovations in this
field resulted in promising technologies such as Quantum Key Distribution
(QKD), which enables the generation of unconditionally secure keys,
establishing secure communications between remote nodes. Additionally, QKD
networks enable the interconnection of multinode architectures, extending the
point-to-point nature of QKD. However, due to the limitations of the current
state of technology, the scalability of QKD networks remains a challenge toward
feasible implementations. When it comes to long-distance implementations,
trusted relay nodes partially solve the distance issue through the forwarding
of the distributed keys, allowing applications that do not have a direct QKD
link to securely share key material. Even though the relay procedure itself has
been extensively studied, the establishment of the relaying node path still
lacks a solution. This paper proposes an innovative network architecture that
solves the challenges of Key Management System (KMS) identification, relay path
discovery, and scalability of QKD networks by integrating Software-Defined
Networking (SDN) principles, and establishing high-level virtual KMSs (vKMS) in
each node and creating a new entity called the Quantum Security Controller
(QuSeC). The vKMS serves the end-user key requests, managing the multiple KMSs
within the node and abstracting the user from discovering the correct KMS.
Additionally, based on the high-level view of the network topology and status,
the QuSeC serves the path discovery requests from vKMSs, computing the
end-to-end (E2E) relay path and applying security policies. The paper also
provides a security analysis of the proposal, identifying the security levels
of the architecture and analyzing the core networking security properties.

</details>


### [22] [PARROT: Portable Android Reproducible traffic Observation Tool](https://arxiv.org/abs/2509.09537)
*Andrea Jimenez-Berenguel,Celeste Campo,Marta Moure-Garrido,Carlos Garcia-Rubio,Daniel Díaz-Sanchez,Florina Almenares*

Main category: cs.NI

TL;DR: PARROT是一个可重现且便携的Android应用流量捕获系统，支持自动化环境设置、SSL/TLS解密和灵活的捕获模式，用于研究移动安全协议的演变。


<details>
  <summary>Details</summary>
Motivation: 移动安全协议的快速演变和当前数据集的稀缺限制了应用流量分析的研究，需要一种可重现的系统来捕获和分析流量。

Method: PARROT系统使用Android虚拟设备，集成了mitmproxy进行流量解密，支持自动化设置和配置，并通过人工交互生成标记的流量捕获。

Result: 收集了80个应用的流量数据集，揭示了TLSv1.3协议和QUIC协议的显著增长，以及DNS协议从Do53向DoT的转变。

Conclusion: PARROT为研究社区提供了可重现的流量捕获工具，并揭示了移动安全协议的演变趋势。

Abstract: The rapid evolution of mobile security protocols and limited availability of
current datasets constrains research in app traffic analysis. This paper
presents PARROT, a reproducible and portable traffic capture system for
systematic app traffic collection using Android Virtual Devices. The system
provides automated environment setup, configurable Android versions, traffic
recording management, and labeled captures extraction with human-in-the-loop
app interaction. PARROT integrates mitmproxy for optional traffic decryption
with automated SSL/TLS key extraction, supporting flexible capture modes with
or without traffic interception. We collected a dataset of 80 apps selected
from the MAppGraph dataset list, providing traffic captures with corresponding
SSL keys for decryption analysis. Our comparative analysis between the
MAppGraph dataset (2021) and our dataset (2025) reveals app traffic pattern
evolution across 50 common apps. Key findings include migration from TLSv1.2 to
TLSv1.3 protocol, with TLSv1.3 comprising 90.0\% of TCP encrypted traffic in
2025 compared to 6.7\% in 2021. QUIC protocol adoption increased substantially,
with all 50 common apps generating QUIC traffic under normal network conditions
compared to 30 apps in 2021. DNS communications evolved from predominantly
unencrypted Do53 protocol (91.0\% in 2021) to encrypted DoT protocol (81.1\% in
2025). The open-source PARROT system enables reproducible app traffic capture
for research community adoption and provides insights into app security
protocol evolution.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [23] [Guarded Fragments Meet Dynamic Logic: The Story of Regular Guards (Extended Version)](https://arxiv.org/abs/2509.09218)
*Bartosz Bednarczyk,Emanuel Kieroński*

Main category: cs.LO

TL;DR: 本文研究了带正则保护的守护片段（RGF），结合了守护片段（GF）和带交集与逆命题的动态逻辑（ICPDL）的表达能力。证明了RGF的可满足性问题是2EXPTIME完全的，并且在查询蕴含问题上给出了更强的不可判定性结果。


<details>
  <summary>Details</summary>
Motivation: 通过将GF与ICPDL结合，RGF为研究之前GF的扩展提供了一种统一的方法，包括传递或等价保护、传递或等价闭包等。

Method: 研究RGF的逻辑性质，分析其可满足性问题和查询蕴含问题的计算复杂度。

Result: 证明了RGF的可满足性问题是2EXPTIME完全的，且在查询蕴含问题上展示了更强的不可判定性结果。

Conclusion: RGF在统一研究GF扩展中具有重要意义，并确定了其最大的EXPSPACE完全片段。

Abstract: We study the Guarded Fragment with Regular Guards (RGF), which combines the
expressive power of the Guarded Fragment (GF) with Propositional Dynamic Logic
with Intersection and Converse (ICPDL). Our logic generalizes, in a uniform
way, many previously-studied extensions of GF, including (conjunctions of)
transitive or equivalence guards, transitive or equivalence closure and more.
We prove 2EXPTIME-completeness of the satisfiability problem for RGF, showing
that RGF is not harder than ICPDL or GF. Shifting to the query entailment
problem, we provide undecidability results that significantly strengthen and
solidify earlier results along those lines. We conclude by identifying, in a
natural sense, the maximal EXPSPACE-complete fragment of RGF.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [24] [A Contextual Bandits Approach for Personalization of Hand Gesture Recognition](https://arxiv.org/abs/2509.08915)
*Duke Lin,Michael Paskett,Ying Yang*

Main category: cs.HC

TL;DR: 提出了一种无需校准的个性化手势识别方法，通过上下文多臂老虎机算法与预训练神经网络结合，显著提高了识别精度。


<details>
  <summary>Details</summary>
Motivation: 解决传统静态模型在用户个性化手势识别中因数据有限和用户摩擦导致的性能不足问题。

Method: 结合上下文多臂老虎机算法和预训练神经网络，利用二元奖励信号进行个性化调整。

Result: 用户研究中，该方法显著降低了假阴性率（减少0.113），准确率提升0.139，部分用户实现了基线模型无法完成的任务。

Conclusion: 该方法通过无监督个性化优化，有效提升了手势识别的性能和用户体验。

Abstract: In human-computer interaction applications like hand gesture recognition,
supervised learning models are often trained on a large population of users to
achieve high task accuracy. However, due to individual variability in sensor
signals and user behavior, static models may not provide optimal performance
for all users. Personalizing pretrained models via calibration--collecting
labeled data from each user--can improve performance but introduces user
friction and struggles with limited data. To overcome these issues, we propose
a calibrationless longitudinal personalization method: a contextual multi-arm
bandit (MAB) algorithm combined with a pretrained neural network for gesture
recognition. This reinforcement-learning-style approach enables personalization
using binary reward signals, either user-provided or inferred by the system.
  We validated this method in a user study. Participants wore a surface
electromyography (sEMG) device and played multiple rounds of a 2-D navigation
game using six hand gestures. In the session, they completed a baseline round
and then a round with our algorithm; in the second session, they played another
round with our algorithm. Our approach led to a significant reduction in users'
average false negative rate by 0.113 from the initial to the final round, with
further decreases between sessions. Average precision also trended upward (by
0.139) from the start to end of a round, continuing in the next session.
Notably, some users who could not complete the game with the baseline model
succeeded with our contextual MAB model. In summary, our

</details>


### [25] [Characterizing Multimodal Interaction in Visualization Authoring Tools](https://arxiv.org/abs/2509.08953)
*Astrid van den Brandt,Sehi L'Yi,Huyen N. Nguyen,Anna Vilanova,Nils Gehlenborg*

Main category: cs.HC

TL;DR: 本文通过系统综述了20种支持多模态交互的可视化创作工具，探讨了多模态交互的多样化特征，并对未来研究方向提出了建议。


<details>
  <summary>Details</summary>
Motivation: 多模态交互在可视化创作工具中的应用广泛但研究不足，缺乏全面概述。本文旨在填补这一空白。

Method: 系统综述了20种支持多模态交互的可视化创作工具，分析了其多模态交互的应用方式。

Result: 揭示了多模态交互在工具中的多样化特征，提出了设计启示和未来发展方向。

Conclusion: 本文为工具设计者提供了实践参考，并指明了未来研究的方向。

Abstract: Multimodal interaction has been increasingly considered in designing
visualization authoring tools. However, multimodal interaction has a broad
meaning in visualization authoring, according to our literature review.
Although some previous studies compare different authoring tools, a
comprehensive overview of the diverse characteristics of multimodal interaction
in visualization authoring tools is still missing. This paper seeks to offer a
systematic perspective on how multimodal interaction is integrated within
visualization authoring tools. Such an overview can enhance understanding of
current practices, highlight distinguishing features among tools, and help
identify future research directions, guiding designers in developing more
accessible and effective authoring systems. We review 20 visualization
authoring tools that incorporate multimodal interaction and characterize how
multimodal interaction is applied in these tools. Based on the review results,
we discuss design implications and future directions.

</details>


### [26] [YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models](https://arxiv.org/abs/2509.08997)
*Yaman Yu,Yiren Liu,Jacky Zhang,Yun Huang,Yang Wang*

Main category: cs.HC

TL;DR: 该论文提出了首个针对青少年LLM交互安全的基准数据集YAIR，并开发了优化的风险检测模型YouthSafe，显著提升了风险检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有安全基准和审核系统对青少年与LLM交互的独特风险研究不足，导致青少年易受伤害，需专门评估和改进。

Method: 构建了包含12,449条标注对话的YAIR数据集，涵盖78种细粒度风险类型，并开发了YouthSafe模型用于实时风险检测。

Result: 现有审核模型对青少年风险检测效果不佳，而YouthSafe在多个指标上显著优于现有系统。

Conclusion: YouthSafe为青少年提供了更安全、更符合其发展需求的AI交互方案。

Abstract: Large Language Models (LLMs) are increasingly used by teenagers and young
adults in everyday life, ranging from emotional support and creative expression
to educational assistance. However, their unique vulnerabilities and risk
profiles remain under-examined in current safety benchmarks and moderation
systems, leaving this population disproportionately exposed to harm. In this
work, we present Youth AI Risk (YAIR), the first benchmark dataset designed to
evaluate and improve the safety of youth LLM interactions. YAIR consists of
12,449 annotated conversation snippets spanning 78 fine grained risk types,
grounded in a taxonomy of youth specific harms such as grooming, boundary
violation, identity confusion, and emotional overreliance. We systematically
evaluate widely adopted moderation models on YAIR and find that existing
approaches substantially underperform in detecting youth centered risks, often
missing contextually subtle yet developmentally harmful interactions. To
address these gaps, we introduce YouthSafe, a real-time risk detection model
optimized for youth GenAI contexts. YouthSafe significantly outperforms prior
systems across multiple metrics on risk detection and classification, offering
a concrete step toward safer and more developmentally appropriate AI
interactions for young users.

</details>


### [27] [Extended Version: It Should Be Easy but... New Users Experiences and Challenges with Secret Management Tools](https://arxiv.org/abs/2509.09036)
*Lorenzo Neil,Deepthi Mungara,Laurie Williams,Yasemin Acar,Bradley Reaves*

Main category: cs.HC

TL;DR: 该论文研究开发者在使用秘密管理工具（SMTs）时的挑战，发现文档质量不足导致使用困难。


<details>
  <summary>Details</summary>
Motivation: 开发者常因秘密泄露面临风险，尽管SMTs被广泛推荐，但其文档和资源是否真正帮助开发者高效使用尚不明确。

Method: 通过定性研究，观察21名新用户执行秘密存储、访问和注入任务，并访谈其使用SMTs的体验。

Result: 用户即使觉得工具功能有用，仍因文档不足感到困难，倾向于使用非官方资源或变通方法。

Conclusion: SMTs的文档和界面需改进，以更好地支持新用户的学习和采用。

Abstract: Software developers face risks of leaking their software secrets, such as API
keys or passwords, which can result in significant harm. Secret management
tools (SMTs), such as HashiCorp Vault Secrets or Infisical, are highly
recommended by industry, academia, and security guidelines to manage secrets
securely. SMTs are designed to help developers secure their secrets in a
central location, yet secrets leaks are still commonplace, and developers
report difficulty in learning how to setup and use SMTs. While SMTs typically
come with publicly available help resources (e.g., tool documentation and
interfaces), it is unclear if these actually help developers learn to
effectively use SMTs. Without usable help resources that onboards developers,
quick adoption and effective use of SMTs may be unrealistic. In a qualitative
two-step study, we observed 21 new users in person while they used SMTs to
perform two secret management tasks: secret storage and access, then secret
injection. We interviewed participants after each task to identify their
challenges and experiences using SMTs, with the assistance of help resources.
While our study sample is narrow, it serves as a reasonable proxy for new
developers who are likely to adopt SMTs early in their careers. We found that
even in a laboratory setting where new users found tool functionality,
interface flexibility helpful, they still experienced increased difficulty to
effectively use SMTs to securely remediate a hard-coded secret when they felt
tool documentation was insufficient and it motivated participants to deviate
from official tool documentation to access secondary sources or attempt
workaround methods. Specific challenges reported by participants were tool
documentation content quality, navigation difficulties with both tool
documentation and web interfaces for finding helpful content, and supportive
tool features.

</details>


### [28] [Digital Iran Reloaded: Gamer Mitigation Tactics of IRI Information Controls](https://arxiv.org/abs/2509.09063)
*Melinda Cohoon*

Main category: cs.HC

TL;DR: 该研究报告了伊朗互联网用户（特别是游戏玩家）如何通过技术和社会策略绕过网络审查，发现社交网络（而非正式培训）是抗审查能力的关键因素。


<details>
  <summary>Details</summary>
Motivation: 研究伊朗用户如何应对互联网审查，尤其是游戏玩家这一数字素养较高的群体，以理解技术与社会策略的结合。

Method: 采用混合方法，包括660名伊朗用户的调查数据，并结合网络延迟和VPN性能的测量。

Result: 年轻用户对绕过审查更有信心，而社交网络（如游戏社区）是分享策略和降低采用障碍的关键平台。

Conclusion: 研究强调了基础设施条件与社会学习的交叉作用，为数字权利和信息控制的开发者、研究者及资助者提供了设计建议。

Abstract: Internet censorship in the Islamic Republic of Iran restricts access to
global platforms and services, forcing users to rely on circumvention
technologies such as VPNs, proxies, and tunneling tools. This report presents
findings from a mixed-methods study of 660 Iranian internet users, with a focus
on gamers as a digitally literate and socially networked community. Survey data
are combined with network measurements of latency and VPN performance to
identify both technical and social strategies of circumvention. Results show
that while younger users report higher confidence with circumvention, peer
networks, rather than formal training, are the strongest predictors of
resilience. Gaming communities, particularly those active on platforms such as
Discord and Telegram, serve as hubs for sharing tactics and lowering barriers
to adoption. These findings extend existing work on usable security and
censorship circumvention by highlighting the intersection of infrastructural
conditions and social learning. The study concludes with design and policy
implications for developers, researchers, and funders working on digital rights
and information controls.

</details>


### [29] [Explaining the Reputational Risks of AI-Mediated Communication: Messages Labeled as AI-Assisted Are Viewed as Less Diagnostic of the Sender's Moral Character](https://arxiv.org/abs/2509.09645)
*Pranav Khadpe,Kimi Wenzel,George Loewenstein,Geoff Kaufman*

Main category: cs.HC

TL;DR: 研究发现，AI辅助标签不会让人对发件人产生负面看法，但会减弱信息传递的性格信号强度。


<details>
  <summary>Details</summary>
Motivation: 探讨AI辅助标签如何影响人们对信息发件人性格的判断。

Method: 通过两项研究（N=399），使用情景小故事分析了AI辅助标签对性格信号的影响。

Result: AI标签减弱了温暖信息（如感谢）和冷漠信息（如责备）的性格信号强度。

Conclusion: AI辅助信息被认为诊断性较低，这与之前关于AI中介沟通的研究结果一致。

Abstract: When someone sends us a thoughtful message, we naturally form judgments about
their character. But what happens when that message carries a label indicating
it was written with the help of AI? This paper investigates how the appearance
of AI assistance affects our perceptions of message senders. Adding nuance to
previous research, through two studies (N=399) featuring vignette scenarios, we
find that AI-assistance labels don't necessarily make people view senders
negatively. Rather, they dampen the strength of character signals in
communication. We show that when someone sends a warmth-signalling message
(like thanking or apologizing) without AI help, people more strongly categorize
the sender as warm. At the same time, when someone sends a coldness-signalling
message (like bragging or blaming) without assistance, people more confidently
categorize them as cold. Interestingly, AI labels weaken both these
associations: An AI-assisted apology makes the sender appear less warm than if
they had written it themselves, and an AI-assisted blame makes the sender
appear less cold than if they had composed it independently. This supports our
signal diagnosticity explanation: messages labeled as AI-assisted are viewed as
less diagnostic than messages which seem unassisted. We discuss how our
findings shed light on the causal origins of previously reported observations
in AI-Mediated Communication.

</details>


### [30] [Content Moderation Futures](https://arxiv.org/abs/2509.09076)
*Lindsay Blackwell*

Main category: cs.HC

TL;DR: 研究通过内容审核专业人士的经历探讨社交媒体治理的失败与可能性，揭示企业利益与公共利益的结构性错位。


<details>
  <summary>Details</summary>
Motivation: 探讨当前社交媒体治理的失败原因及其改进可能性。

Method: 通过33位从业者的参与式设计工作坊收集数据。

Result: 发现企业追求技术新颖性和快速发展，导致平台优先创新而非公众信任与安全。

Conclusion: 呼吁通过历史经验激励治理工作者团结，推动系统性变革。

Abstract: This study examines the failures and possibilities of contemporary social
media governance through the lived experiences of various content moderation
professionals. Drawing on participatory design workshops with 33 practitioners
in both the technology industry and broader civil society, this research
identifies significant structural misalignments between corporate incentives
and public interests. While experts agree that successful content moderation is
principled, consistent, contextual, proactive, transparent, and accountable,
current technology companies fail to achieve these goals, due in part to
exploitative labor practices, chronic underinvestment in user safety, and
pressures of global scale. I argue that successful governance is undermined by
the pursuit of technological novelty and rapid growth, resulting in platforms
that necessarily prioritize innovation and expansion over public trust and
safety. To counter this dynamic, I revisit the computational history of care
work, to motivate present-day solidarity amongst platform governance workers
and inspire systemic change.

</details>


### [31] [User Exploration and Exploitation Behavior Under the Influence of Real-time Interactions in Live Streaming Environments](https://arxiv.org/abs/2509.09138)
*Akira Matsui,Kazuki Fujikawa,Ryo Sasaki,Ryo Adachi*

Main category: cs.HC

TL;DR: 研究了直播平台上用户行为中的探索/开发（E/E）模式，发现用户表现出更长的探索期，并受到昼夜节律等外部因素的影响，为平台设计和内容创作者提供了策略建议。


<details>
  <summary>Details</summary>
Motivation: 探索直播平台上用户行为的差异，特别是实时功能对用户行为和忠诚度的影响。

Method: 使用探索/开发（E/E）概念分析两年的大规模直播平台数据。

Result: 用户表现出E/E行为且探索期更长，昼夜节律等外部因素影响E/E动态和用户忠诚度。

Conclusion: 强调了平衡E/E在直播平台设计中的重要性，为平台开发和内容创作者提供了设计策略建议。

Abstract: Live streaming platforms offer a distinctive way for users and content
creators to interact with each other through real-time communication. While
research on user behavior in online platforms has explored how users discover
their favorite content from creators and engage with them, the role of
real-time features remains unclear. There are open questions as to what
commonalities and differences exist in users' relationships with live streaming
platforms compared to traditional on-demand style platforms. To understand
this, we employ the concept of Exploration/Exploitation (E/E) and analyze a
large-scale dataset from a live streaming platform over two years. Our results
indicate that even on live streaming platforms, users exhibit E/E behavior but
experience a longer exploration period. We also identify external factors, such
as circadian rhythms, that influence E/E dynamics and user loyalty. The
presented study emphasizes the importance of balancing E/E in online platform
design, especially for live streaming platforms, providing implications that
suggest design strategies for platform developers and content creators to
facilitate timely engagement and retention.

</details>


### [32] [Sensible Agent: A Framework for Unobtrusive Interaction with Proactive AR Agents](https://arxiv.org/abs/2509.09255)
*Geonsun Lee,Min Xia,Nels Numan,Xun Qian,David Li,Yanhe Chen,Achin Kulshrestha,Ishan Chatterjee,Yinda Zhang,Dinesh Manocha,David Kim,Ruofei Du*

Main category: cs.HC

TL;DR: Sensible Agent框架通过多模态感知动态调整AR代理的交互方式，减少干扰并提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统AR代理依赖显式语音交互，可能造成干扰或社交不适，Sensible Agent旨在提供无干扰的自然交互。

Method: 利用多模态传感器和LMMs实时感知环境，动态调整交互内容与方式，通过专家研讨会和用户研究验证设计。

Result: 用户研究表明，Sensible Agent显著降低交互负担，同时保持高可用性和用户偏好。

Conclusion: Sensible Agent为AR代理提供了一种更自然、无干扰的交互框架。

Abstract: Proactive AR agents promise context-aware assistance, but their interactions
often rely on explicit voice prompts or responses, which can be disruptive or
socially awkward. We introduce Sensible Agent, a framework designed for
unobtrusive interaction with these proactive agents. Sensible Agent dynamically
adapts both "what" assistance to offer and, crucially, "how" to deliver it,
based on real-time multimodal context sensing. Informed by an expert workshop
(n=12) and a data annotation study (n=40), the framework leverages egocentric
cameras, multimodal sensing, and Large Multimodal Models (LMMs) to infer
context and suggest appropriate actions delivered via minimally intrusive
interaction modes. We demonstrate our prototype on an XR headset through a user
study (n=10) in both AR and VR scenarios. Results indicate that Sensible Agent
significantly reduces perceived interaction effort compared to voice-prompted
baseline, while maintaining high usability and achieving higher preference.

</details>


### [33] [Flip Co-op: Cooperative Takeovers in Shared Autonomy](https://arxiv.org/abs/2509.09281)
*Sandeep Banik,Naira Hovakimyan*

Main category: cs.HC

TL;DR: 本文提出了一个基于博弈论的共享自治框架，用于建模合作接管，取代了传统的不具备理论保证的混合或切换方法。


<details>
  <summary>Details</summary>
Motivation: 现有的共享自治方法缺乏理论保证，亟需一种基于博弈论的合作接管机制。

Method: 将切换交互建模为动态博弈，直接嵌入权威到系统动力学中，推导Nash均衡策略，并在线性二次系统下提供闭式递归解法。

Result: 证明了纯接管策略下Nash均衡的存在，并通过车辆轨迹跟踪问题验证了均衡策略的适应性。

Conclusion: 该框架在实际应用中平衡了人类适应性与自主效率，展示了合作博弈论在共享自治中的优势。

Abstract: Shared autonomy requires principled mechanisms for allocating and
transferring control between a human and an autonomous agent. Existing
approaches often rely on blending control inputs between human and autonomous
agent or switching rules, which lack theoretical guarantees. This paper
develops a game-theoretic framework for modeling cooperative takeover in shared
autonomy. We formulate the switching interaction as a dynamic game in which
authority is embedded directly into the system dynamics, resulting in Nash
equilibrium(NE)-based strategies rather than ad hoc switching rules. We
establish the existence and characterization of NE in the space of pure
takeover strategies under stochastic human intent. For the class of
linear-quadratic systems, we derive closed-form recursions for takeover
strategies and saddle-point value functions, providing analytical insight and
efficient computation of cooperative takeover policies. We further introduce a
bimatrix potential game reformulation to address scenarios where human and
autonomy utilities are not perfectly aligned, yielding a unifying potential
function that preserves tractability while capturing intent deviations. The
framework is applied to a vehicle trajectory tracking problem, demonstrating
how equilibrium takeover strategies adapt across straight and curved path
segments. The results highlight the trade-off between human adaptability and
autonomous efficiency and illustrate the practical benefits of grounding shared
autonomy in cooperative game theory.

</details>


### [34] [The Impact of Device Type, Data Practices, and Use Case Scenarios on Privacy Concerns about Eye-tracked Augmented Reality in the United States and Germany](https://arxiv.org/abs/2509.09285)
*Efe Bozkir,Babette Bühler,Xiaoyuan Wu,Enkelejda Kasneci,Lujo Bauer,Lorrie Faith Cranor*

Main category: cs.HC

TL;DR: 研究探讨了增强现实（AR）技术中眼动追踪数据的隐私问题，通过问卷调查（美国和德国参与者）发现用户对隐私的关注度取决于数据用途和受益人，且不同国家之间存在差异。


<details>
  <summary>Details</summary>
Motivation: 随着AR设备的普及和眼动追踪等技术的应用，用户隐私问题日益突出，尤其是敏感信息的推断风险，但目前缺乏对行为数据（如眼动追踪）隐私的深入研究。

Method: 通过在美国和德国进行四次问卷调查（样本量分别为48和525），研究用户属性、AR设备、用途、数据实践和国家对隐私关注的影响。

Result: 结果显示，用户对隐私的关注取决于数据用途和受益人，且德国参与者比美国参与者更关注隐私；设备类型（AR眼镜与智能手机）对隐私关注无显著影响。

Conclusion: 研究建议开发者和政策制定者关注数据用途和用户受益，以制定隐私友好的AR实践和政策。

Abstract: Augmented reality technology will likely be prevalent with more affordable
head-mounted displays. Integrating novel interaction modalities such as eye
trackers into head-mounted displays could lead to collecting vast amounts of
biometric data, which may allow inference of sensitive user attributes like
health status or sexual preference, posing privacy issues. While previous works
broadly examined privacy concerns about augmented reality, ours is the first to
extensively explore privacy concerns on behavioral data, particularly eye
tracking in augmented reality. We crowdsourced four survey studies in the
United States (n1 = 48, n2 = 525) and Germany (n3 = 48, n4 = 525) to understand
the impact of user attributes, augmented reality devices, use cases, data
practices, and country on privacy concerns. Our findings indicate that
participants are generally concerned about privacy when they know what
inferences can be made based on the collected data. Despite the more prominent
use of smartphones in daily life than augmented reality glasses, we found no
indications of differing privacy concerns depending on the device type. In
addition, our participants are more comfortable when a particular use case
benefits them and less comfortable when other humans can consume their data.
Furthermore, participants in the United States are less concerned about their
privacy than those in Germany. Based on our findings, we provide several
recommendations to practitioners and policymakers for privacy-aware augmented
reality.

</details>


### [35] [Proactive AI Adoption can be Threatening: When Help Backfires](https://arxiv.org/abs/2509.09309)
*Dana Harari,Ofra Amir*

Main category: cs.HC

TL;DR: 研究发现，AI助手主动提供帮助可能引发自我威胁感，从而降低用户接受度和未来使用意愿，影响绩效预期。


<details>
  <summary>Details</summary>
Motivation: 探讨AI助手主动帮助行为如何影响用户采纳，尤其是背后的心理机制。

Method: 通过两项vignette实验（761人和571人），比较AI与人类帮助的差异，以及主动与反应性帮助的效果。

Result: AI帮助比人类帮助更具威胁性，主动帮助增加威胁感并降低采纳效果。

Conclusion: 主动AI功能可能适得其反，设计时应考虑减少用户的自我威胁感。

Abstract: Artificial intelligence (AI) assistants are increasingly embedded in
workplace tools, raising the question of how initiative-taking shapes adoption.
Prior work highlights trust and expectation mismatches as barriers, but the
underlying psychological mechanisms remain unclear. Drawing on self-affirmation
and social exchange theories, we theorize that unsolicited help elicits
self-threat, reducing willingness to accept assistance, likelihood of future
use, and performance expectancy. We report two vignette-based experiments
(Study~1: $N=761$; Study~2: $N=571$, preregistered). Study~1 compared
anticipatory and reactive help provided by an AI vs. a human, while Study~2
distinguished between \emph{offering} (suggesting help) and \emph{providing}
(acting automatically). In Study 1, AI help was more threatening than human
help. Across both studies, anticipatory help increased perceived threat and
reduced adoption outcomes. Our findings identify self-threat as a mechanism
explaining why proactive AI features may backfire and suggest design
implications for AI initiative.

</details>


### [36] [Smart Device Development for Gait Monitoring: Multimodal Feedback in an Interactive Foot Orthosis, Walking Aid, and Mobile Application](https://arxiv.org/abs/2509.09359)
*Stefan Resch,André Kousha,Anna Carroll,Noah Severinghaus,Felix Rehberg,Marco Zatschker,Yunus Söyleyici,Daniel Sanchez-Morillo*

Main category: cs.HC

TL;DR: 开发了一种结合智能足部矫形器和前臂拐杖的模块化传感器系统，用于康复支持，通过实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 当前矫形设备多为被动式，缺乏集成传感或反馈功能，且研究多局限于孤立原型。

Method: 设计了一个整合足底压力、运动感知、振动触觉反馈及无线通信的系统，并通过8名参与者的实验评估。

Result: 验证了智能足部矫形器的移动步态检测可行性，探索了触觉反馈的潜力，并评估了移动健康应用的可用性。

Conclusion: 研究为智能辅助康复技术提供了实用且全面的系统，并讨论了局限性及未来发展建议。

Abstract: Smart assistive technologies such as sensor-based footwear and walking aids
offer promising opportunities to support rehabilitation through real-time
feedback and patient-centered monitoring. However, most orthotic devices remain
passive and lack integrated sensing or feedback functionalities, while existing
research often focuses on isolated prototypes rather than cohesive, interactive
systems. In this work, we present the design and implementation of a novel
modular sensor system that combines a smart foot orthosis with an instrumented
forearm crutch. The system integrates plantar pressure and motion sensing,
vibrotactile feedback, and wireless communication via a smartphone application.
We conducted an experimental user study with eight participants to validate the
feasibility of the smart foot orthosis for mobile gait detection, explore the
potential of haptic feedback for user interaction, and assess the usability of
the accompanying mobile health application. Our work contributes to the field
of smart assistive technology in rehabilitation and prevention by demonstrating
a functional and comprehensive system. We further discuss system limitations,
outline potential application scenarios, and provide recommendations for future
development and clinical integration.

</details>


### [37] [Real-Time Kinematic Positioning and Optical See-Through Head-Mounted Display for Outdoor Tracking: Hybrid System and Preliminary Assessment](https://arxiv.org/abs/2509.09412)
*Muhannad Ismael,Maël Cornil*

Main category: cs.HC

TL;DR: 本文介绍了一种在户外环境中结合RTK定位技术和OST-HMD的跟踪系统，适用于需要高精度跟踪和显示遮挡信息的场景，提供了系统集成和性能优化的见解。


<details>
  <summary>Details</summary>
Motivation: 解决户外环境中精确跟踪物体和显示遮挡信息的需求，尤其是需要免手持操作的场景。

Method: 整合RTK技术（提供厘米级精度）和OST-HMD，提出一种“半动态”方法进行系统评估。

Result: 开发了一种结合RTK和OST-HMD的系统，实现了相对精确且直观的户外跟踪，并提供了全球定位方法。

Conclusion: 该系统展示了RTK与OST-HMD结合的潜力，为未来改进户外跟踪系统提供了研究方向。

Abstract: This paper presents an outdoor tracking system using Real-Time Kinematic
(RTK) positioning and Optical See-Through Head Mounted Display(s) (OST-HMD(s))
in urban areas where the accurate tracking of objects is critical and where
displaying occluded information is important for safety reasons. The approach
presented here replaces 2D screens/tablets and offers distinct advantages,
particularly in scenarios demanding hands-free operation. The integration of
RTK, which provides centimeter-level accuracy of tracked objects, with OST-HMD
represents a promising solution for outdoor applications. This paper provides
valuable insights into leveraging the combined potential of RTK and OST-HMD for
outdoor tracking tasks from the perspectives of systems integration,
performance optimization, and usability. The main contributions of this paper
are: \textbf{1)} a system for seamlessly merging RTK systems with OST-HMD to
enable relatively precise and intuitive outdoor tracking, \textbf{2)} an
approach to determine a global location to achieve the position relative to the
world, \textbf{3)} an approach referred to as 'semi-dynamic' for system
assessment. Moreover, we offer insights into several relevant future research
topics aimed at improving the OST-HMD and RTK hybrid system for outdoor
tracking.

</details>


### [38] [Changing the Paradigm from Dynamic Queries to LLM-generated SQL Queries with Human Intervention](https://arxiv.org/abs/2509.09461)
*Ambre Assor,Hyeon Jeon,Sungbok Shin,Jean-Daniel Fekete*

Main category: cs.HC

TL;DR: 利用大型语言模型（LLM）作为医疗可视化系统的交互层，简化复杂数据集的自然语言查询，替代传统的动态查询界面。


<details>
  <summary>Details</summary>
Motivation: 医疗领域用户需处理高维、编码和异质数据集，传统查询界面复杂且需要记忆字段名和系统代码，LLM可简化这一过程。

Method: 通过LLM生成自然语言查询，转化为可编辑和执行的查询，替代传统滑块、复选框等界面，减少视觉杂乱。

Result: 实现了ParcoursVis系统，支持用户更流畅地探索数据，但可能无法展示所有过滤条件。

Conclusion: LLM作为交互层提升了医疗数据的探索效率，适合专家用户，但需结合动态查询以支持更多交互需求。

Abstract: We propose leveraging Large Language Models (LLMs) as an interaction layer
for medical visualization systems. In domains like healthcare, where users must
navigate high-dimensional, coded, and heterogeneous datasets, LLM-generated
queries enable expert medical users to express complex analytical intents in
natural language. These intents are then translated into editable and
executable queries, replacing the dynamic query interfaces used by traditional
visualization systems built around sliders, check boxes, and drop-downs. This
interaction model reduces visual clutter and eliminates the need for users to
memorize field names or system codes, supporting fluid exploration, with the
drawback of not exposing all the filtering criteria. We also reintroduce
dynamic queries on demand to better support interactive exploration. We posit
that medical users are trained to know the possible filtering options but
challenged to remember the details of the attribute names and code values. We
demonstrate this paradigm in ParcoursVis, our scalable EventFlow-inspired
patient care pathway visualization system powered by the French National Health
Data System, one of the largest health data repositories in the world.

</details>


### [39] [Cognitive Affordances in Visualization: Related Constructs, Design Factors, and Framework](https://arxiv.org/abs/2509.09510)
*Racquel Fygenson,Lace Padilla,Enrico Bertini*

Main category: cs.HC

TL;DR: 该论文综述并形式化地将可用性理论引入可视化领域，提出认知可用性框架，用于指导可视化的设计和评估。


<details>
  <summary>Details</summary>
Motivation: 经典可用性研究关注物体形状如何传达动作，但可视化领域缺乏对其理论的系统应用，尤其是认知可用性如何影响信息传达。

Method: 回顾和翻译可用性理论到可视化领域，比较相关概念，并综合心理学、HCI和可视化研究，提出一个认知可用性框架。

Result: 提出了一个框架，用于分析可视化设计决策与读者特征如何影响信息的层级传达，并展示其应用。

Conclusion: 该框架为可视化的评估和重新设计提供了理论基础和实践指导。

Abstract: Classically, affordance research investigates how the shape of objects
communicates actions to potential users. Cognitive affordances, a subset of
this research, characterize how the design of objects influences cognitive
actions, such as information processing. Within visualization, cognitive
affordances inform how graphs' design decisions communicate information to
their readers. Although several related concepts exist in visualization, a
formal translation of affordance theory to visualization is still lacking. In
this paper, we review and translate affordance theory to visualization by
formalizing how cognitive affordances operate within a visualization context.
We also review common methods and terms, and compare related constructs to
cognitive affordances in visualization. Based on a synthesis of research from
psychology, human computer interaction, and visualization, we propose a
framework of cognitive affordances in visualization that enumerates design
decisions and reader characteristics that influence a visualization's hierarchy
of communicated information. Finally, we demonstrate how this framework can
guide the evaluation and redesign of visualizations.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [40] [Morphology-Preserving Remeshing Approach to Particulate Microstructures via Harmonic Decomposition](https://arxiv.org/abs/2509.08855)
*Mahmoud Shaqfa*

Main category: cs.GR

TL;DR: 论文提出了一种基于分层扩散的方法，用于重新采样表面以生成均匀的三角网格，解决了传统谐波分解方法在微观结构表面离散化中的问题。


<details>
  <summary>Details</summary>
Motivation: 传统谐波分解方法在重构或生成表面时，由于未考虑基函数Jacobian的局部变化，导致非均匀离散化，影响了数值模拟的准确性和效率。

Method: 采用非线性扩散方法重新采样分析域的曲线坐标，从而在表面生成均匀的三角网格。

Result: 测试表明，该方法显著提高了表面三角网格的质量指标，并保持了表面形态、面积和体积。

Conclusion: 该方法为大规模2D和3D微观结构的数字孪生提供了一种高效的表面离散化解决方案，具有广泛的应用前景。

Abstract: Harmonic decomposition of surfaces, such as spherical and spheroidal
harmonics, is used to analyze morphology, reconstruct, and generate surface
inclusions of particulate microstructures. However, obtaining high-quality
meshes of engineering microstructures using these approaches remains an open
question. In harmonic approaches, we usually reconstruct surfaces by evaluating
the harmonic bases on equidistantly sampled simplicial complexes of the base
domains (e.g., triangular spheroids and disks). However, this traditional
sampling does not account for local changes in the Jacobian of the basis
functions, resulting in nonuniform discretization after reconstruction or
generation. As it impacts the accuracy and time step, high-quality
discretization of microstructures is crucial for efficient numerical
simulations (e.g., finite element and discrete element methods). To circumvent
this issue, we propose an efficient hierarchical diffusion-based approach for
resampling the surface-i.e., performing a reparameterization-to yield an
equalized mesh triangulation. Analogous to heat problems, we use nonlinear
diffusion to resample the curvilinear coordinates of the analysis domain,
thereby enlarging small triangles at the expense of large triangles on
surfaces. We tested isotropic and anisotropic diffusion schemes on the recent
spheroidal and hemispheroidal harmonics methods. The results show a substantial
improvement in the quality metrics for surface triangulation. Unlike
traditional surface reconstruction and meshing techniques, this approach
preserves surface morphology, along with the areas and volumes of surfaces. We
discuss the results and the associated computational costs for large 2D and 3D
microstructures, such as digital twins of concrete and stone masonry, and their
future applications.

</details>


### [41] [CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction](https://arxiv.org/abs/2509.08947)
*Yancheng Cai,Robert Wanat,Rafal Mantiuk*

Main category: cs.GR

TL;DR: 该论文提出了一种结合相机重建管道和视觉差异预测器的方法（CameraVDP），以解决传统显示测量方法无法捕捉高频和像素级失真的问题，并通过应用验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统显示测量方法无法捕捉高频和像素级失真，而相机虽分辨率足够却引入光学、采样和光度失真，因此需要一种结合物理测量和视觉系统模型的解决方案。

Method: 提出CameraVDP框架，结合HDR图像堆叠、MTF反转、渐晕校正、几何去失真、单应变换和色彩校正等技术，并整合视觉差异预测器（VDP）。

Result: 通过缺陷像素检测、彩色边缘感知和显示非均匀性评估三项应用验证了CameraVDP的有效性，并提供了性能上限估计和VDP质量分数的置信区间。

Conclusion: CameraVDP为显示器的感知评估提供了一种有效工具，解决了传统方法的局限性。

Abstract: Accurate measurement of images produced by electronic displays is critical
for the evaluation of both traditional and computational displays. Traditional
display measurement methods based on sparse radiometric sampling and fitting a
model are inadequate for capturing spatially varying display artifacts, as they
fail to capture high-frequency and pixel-level distortions. While cameras offer
sufficient spatial resolution, they introduce optical, sampling, and
photometric distortions. Furthermore, the physical measurement must be combined
with a model of a visual system to assess whether the distortions are going to
be visible. To enable perceptual assessment of displays, we propose a
combination of a camera-based reconstruction pipeline with a visual difference
predictor, which account for both the inaccuracy of camera measurements and
visual difference prediction. The reconstruction pipeline combines HDR image
stacking, MTF inversion, vignetting correction, geometric undistortion,
homography transformation, and color correction, enabling cameras to function
as precise display measurement instruments. By incorporating a Visual
Difference Predictor (VDP), our system models the visibility of various stimuli
under different viewing conditions for the human visual system. We validate the
proposed CameraVDP framework through three applications: defective pixel
detection, color fringing awareness, and display non-uniformity evaluation. Our
uncertainty analysis framework enables the estimation of the theoretical upper
bound for defect pixel detection performance and provides confidence intervals
for VDP quality scores.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [42] [A Comparative Analysis of Identifier Schemes: UUIDv4, UUIDv7, and ULID for Distributed Systems](https://arxiv.org/abs/2509.08969)
*Nima Karimian Kakolaki*

Main category: cs.DC

TL;DR: 本文全面分析了分布式标识符的演变，比较了传统自增键、UUIDv4、UUIDv7和ULID的性能。实验表明ULID在降低网络开销、提高生成速度和减少碰撞风险方面显著优于其他方案。


<details>
  <summary>Details</summary>
Motivation: 分布式系统需要健壮且可扩展的标识符方案以确保数据唯一性和高效的跨节点索引。

Method: 结合数学碰撞概率计算与模拟分布式环境中的生成速度和网络传输开销的实证实验。

Result: ULID显著优于UUIDv4和UUIDv7，网络开销减少83.7%，生成速度提高97.32%，碰撞风险降低98.42%。

Conclusion: ULID是高性能分布式系统的最佳选择，提供高效、时间有序且字典可排序的标识符。所有代码和实验数据公开。

Abstract: Distributed systems require robust, scalable identifier schemes to ensure
data uniqueness and efficient indexing across multiple nodes. This paper
presents a comprehensive analysis of the evolution of distributed identifiers,
comparing traditional auto-increment keys with UUIDv4, UUIDv7, and ULIDs. We
combine mathematical calculation of collision probabilities with empirical
experiments measuring generation speed and network transmission overhead in a
simulated distributed environment. Results demonstrate that ULIDs significantly
outperform UUIDv4 and UUIDv7, reducing network overhead by 83.7% and increasing
generation speed by 97.32%. statistical analysis further shows ULIDs offer a
98.42% lower collision risk compared to UUIDv7, while maintaining negligible
collision probabilities even at high generation rates. These findings highlight
ULIDs as an optimal choice for high-performance distributed systems, providing
efficient, time-ordered, and lexicographically sortable identifiers suitable
for scalable applications. All source code, datasets, and analysis scripts
utilized in this research are publicly available in our dedicated repository at
https://github.com/nimakarimiank/uids-comparison. This repository contains
comprehensive documentation of the experimental setup, including configuration
files for the distributed environment, producer and consumer implementations,
and message broker integration. Additionally, it provides the data scripts and
datasets. Researchers and practitioners are encouraged to explore the
repository for full reproducibility of the experiments and to facilitate
further investigation or extension of the presented work.

</details>


### [43] [TrEnv: Transparently Share Serverless Execution Environments Across Different Functions and Nodes](https://arxiv.org/abs/2509.09525)
*Jialiang Huang,Teng Ma,Zheng Liu,Sixing Lin,Kang Chen,Jinlei Jiang,Xia Liao,Yingdi Shan,Yongwei Wu,Ning Zhang,Mengting Lu,Tao Ma,Haifeng Gong,Mingxing Zhang*

Main category: cs.DC

TL;DR: TrEnv是一种针对LLM代理优化的高密度无服务器平台，通过可重复使用的沙盒和内存模板显著降低启动延迟和内存使用，性能优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 解决现有无服务器计算平台对新兴LLM代理工作负载的高成本和低效率问题。

Method: 设计TrEnv平台，结合容器和虚拟机环境，利用可重复使用的沙盒和内存模板优化启动时间和内存使用。

Result: TrEnv在容器环境中降低P99延迟7倍和内存使用48%，在虚拟机环境中降低P99延迟58%和内存使用61%。

Conclusion: TrEnv显著提升了无服务器平台对LLM代理的效率，降低了成本和资源消耗。

Abstract: Serverless computing provides dynamic scalability, but its infrastructure
overhead becomes a bottleneck for emerging workloads such as LLM agents, which
exhibit unpredictable invocation patterns and variable resource demands. Our
analysis shows that for these agents, the cost of running on serverless
platforms can reach up to 70% of the cost of LLM API calls. This finding
motivates the need for a more efficient, high-density serverless platform. We
present TrEnv, a co-designed serverless platform that supports both container-
and VM-based environments, optimized for the unique demands of LLM agents.
TrEnv reduces startup latency and memory usage through repurposable sandboxes
and memory templates, which enable fast reuse and restoration of execution
environments. To further reduce overhead in VM-based agent workloads, TrEnv
leverages browser sharing and a page cache bypassing mechanism. Evaluations
show that TrEnv reduces P99 latency by up to 7X and memory usage by 48% in
container-based settings, and achieves up to 58% lower P99 latency and 61%
memory savings for VM-based agents compared to state-of-the-art systems like
E2B.

</details>


### [44] [Optimizing the Variant Calling Pipeline Execution on Human Genomes Using GPU-Enabled Machines](https://arxiv.org/abs/2509.09058)
*Ajay Kumar,Praveen Rao,Peter Sanders*

Main category: cs.DC

TL;DR: 提出了一种基于机器学习的方法，用于在GPU机器上高效执行变异检测流程，通过预测执行时间和生成优化计划，显著提高了执行速度。


<details>
  <summary>Details</summary>
Motivation: 变异检测是基因组分析的第一步，但其计算密集性需要高效处理，尤其是在云环境中。本文旨在优化GPU机器上的变异检测流程执行效率。

Method: 采用机器学习预测变异检测流程各阶段的执行时间，并结合灵活的作业车间调度问题生成最优执行计划。

Result: 在公开基因组序列上测试，方法有效预测了执行时间，相比贪心方法和动态方法分别实现了2倍和1.6倍的加速。

Conclusion: 基于机器学习的优化方法显著提高了变异检测流程的执行效率，为基因组分析提供了高效解决方案。

Abstract: Variant calling is the first step in analyzing a human genome and aims to
detect variants in an individual's genome compared to a reference genome. Due
to the computationally-intensive nature of variant calling, genomic data are
increasingly processed in cloud environments as large amounts of compute and
storage resources can be acquired with the pay-as-you-go pricing model. In this
paper, we address the problem of efficiently executing a variant calling
pipeline for a workload of human genomes on graphics processing unit
(GPU)-enabled machines. We propose a novel machine learning (ML)-based approach
for optimizing the workload execution to minimize the total execution time. Our
approach encompasses two key techniques: The first technique employs ML to
predict the execution times of different stages in a variant calling pipeline
based on the characteristics of a genome sequence. Using the predicted times,
the second technique generates optimal execution plans for the machines by
drawing inspiration from the flexible job shop scheduling problem. The plans
are executed via careful synchronization across different machines. We
evaluated our approach on a workload of publicly available genome sequences
using a testbed with different types of GPU hardware. We observed that our
approach was effective in predicting the execution times of variant calling
pipeline stages using ML on features such as sequence size, read quality,
percentage of duplicate reads, and average read length. In addition, our
approach achieved 2X speedup (on an average) over a greedy approach that also
used ML for predicting the execution times on the tested workload of sequences.
Finally, our approach achieved 1.6X speedup (on an average) over a dynamic
approach that executed the workload based on availability of resources without
using any ML-based time predictions.

</details>


### [45] [WebAssembly and Unikernels: A Comparative Study for Serverless at the Edge](https://arxiv.org/abs/2509.09400)
*Valerio Besozzi,Enrico Fiasco,Marco Danelutto,Patrizio Dazzi*

Main category: cs.DC

TL;DR: 比较 WebAssembly 和基于 unikernel 的 MicroVMs 在边缘无服务器计算中的性能，提出 Limes 并评估其表现。


<details>
  <summary>Details</summary>
Motivation: 边缘无服务器计算需要轻量级执行环境以减少冷启动延迟，特别是在紧急边缘计算（UEC）场景中。

Method: 提出了基于 Wasmtime 的 Limes 运行时，并将其与基于 Firecracker 的 SPARE 环境进行对比评估。

Result: WebAssembly 在轻量级函数中冷启动时间更低，但在复杂任务中表现不佳；Firecracker 冷启动时间更稳定且执行性能更强，尤其适合 I/O 密集型任务。

Conclusion: WebAssembly 适合轻量级任务，而 Firecracker 在复杂或 I/O 密集型场景中更具优势。

Abstract: Serverless computing at the edge requires lightweight execution environments
to minimize cold start latency, especially in Urgent Edge Computing (UEC). This
paper compares WebAssembly and unikernel-based MicroVMs for serverless
workloads. We present Limes, a WebAssembly runtime built on Wasmtime, and
evaluate it against the Firecracker-based environment used in SPARE. Results
show that WebAssembly offers lower cold start times for lightweight functions
but suffers with complex workloads, while Firecracker provides higher, but
stable, cold starts and better execution performance, particularly for
I/O-heavy tasks.

</details>


### [46] [Coherence-Aware Task Graph Modeling for Realistic Application](https://arxiv.org/abs/2509.09094)
*Guochu Xiong,Xiangzhong Luo,Weichen Liu*

Main category: cs.DC

TL;DR: CoTAM提出了一种新型的任务图建模框架，专注于缓存一致性对系统性能的影响，通过解耦一致性效应并量化其影响，生成一致性感知的任务图，填补了现有方法在动态工作负载和实际运行时行为之间的差距。


<details>
  <summary>Details</summary>
Motivation: 随着多核系统的扩展，缓存一致性成为系统性能的关键因素。现有的任务图建模方法通常依赖预定义的静态图，忽视了动态、数据依赖的行为和一致性交互，导致设计与实际运行时行为脱节。

Method: CoTAM是一种一致性感知的任务图建模框架，通过解耦一致性效应、量化其影响并推断任务间依赖关系，生成统一的任务图，反映实际运行时行为。

Result: 实验表明，CoTAM优于隐式方法，能够更好地捕获动态工作负载行为，同时证明了缓存一致性在任务图建模中的重要性。

Conclusion: CoTAM填补了现有方法的局限性，为准确的系统级分析提供了可推广的任务图建模框架，强调了纳入缓存一致性的必要性。

Abstract: As multicore systems continue to scale, cache coherence has emerged as a
critical determinant of system performance, with coherence behavior and task
execution closely intertwined, reshaping inter-task dependencies. Task graph
modeling provides a structured way to capture such dependencies and serves as
the foundation for many system-level design strategies. However, these
strategies typically rely on predefined task graphs, while many real-world
applications lack explicit graphs and exhibit dynamic, data-dependent behavior,
limiting the effectiveness of static approaches. To address this, several task
graph modeling methods for realistic workloads have been developed. Yet, they
either rely on implicit techniques that use application-specific features
without producing explicit graphs, or they generate graphs tailored to fixed
scheduling models, which limits generality. More importantly, they often
overlook coherence interactions, creating a gap between design assumptions and
actual runtime behavior. To overcome these limitations, we propose CoTAM, a
Coherence-Aware Task Graph Modeling framework for realistic workloads that
constructs a unified task graph reflecting runtime behavior. CoTAM analyzes the
impact of coherence by decoupling its effects from overall execution,
quantifies its influence through a learned weighting scheme, and infers
inter-task dependencies for coherence-aware graph generation. Extensive
experiments show that CoTAM outperforms implicit methods, bridging the gap
between dynamic workload behavior and existing designs while demonstrating the
importance of incorporating cache coherence into task graph modeling for
accurate and generalizable system-level analysis.

</details>


### [47] [Barycentric Coded Distributed Computing with Flexible Recovery Threshold for Collaborative Mobile Edge Computing](https://arxiv.org/abs/2509.09435)
*Houming Qiu,Kun Zhu,Dusit Niyato,Nguyen Cong Luong,Changyan Yi,Chen Dai*

Main category: cs.DC

TL;DR: 提出了一种基于重心有理插值的近似CDC方案，解决现有CDC方案在解码阈值限制和数值不稳定性上的问题。


<details>
  <summary>Details</summary>
Motivation: 协作移动边缘计算中，落后节点（stragglers）会显著增加计算延迟，现有CDC方案存在解码阈值固定和数值不稳定性的限制。

Method: 采用重心有理插值设计CDC方案，支持灵活解码、数值稳定性和无极点编码/解码函数，并提出基于BRI的梯度编码算法。

Result: 实验结果表明，该方案在等待时间和近似精度上优于现有CDC方案。

Conclusion: 提出的方案解决了现有CDC方案的局限性，提供了更灵活、稳定和高效的计算能力。

Abstract: Collaborative mobile edge computing (MEC) has emerged as a promising paradigm
to enable low-capability edge nodes to cooperatively execute
computation-intensive tasks. However, straggling edge nodes (stragglers)
significantly degrade the performance of MEC systems by prolonging computation
latency. While coded distributed computing (CDC) as an effective technique is
widely adopted to mitigate straggler effects, existing CDC schemes exhibit two
critical limitations: (i) They cannot successfully decode the final result
unless the number of received results reaches a fixed recovery threshold, which
seriously restricts their flexibility; (ii) They suffer from inherent poles in
their encoding/decoding functions, leading to decoding inaccuracies and
numerical instability in the computational results. To address these
limitations, this paper proposes an approximated CDC scheme based on
barycentric rational interpolation. The proposed CDC scheme offers several
outstanding advantages. Firstly, it can decode the final result leveraging any
returned results from workers. Secondly, it supports computations over both
finite and real fields while ensuring numerical stability. Thirdly, its
encoding/decoding functions are free of poles, which not only enhances
approximation accuracy but also achieves flexible accuracy tuning. Fourthly, it
integrates a novel BRI-based gradient coding algorithm accelerating the
training process while providing robustness against stragglers. Finally,
experimental results reveal that the proposed scheme is superior to existing
CDC schemes in both waiting time and approximate accuracy.

</details>


### [48] [Weaker Assumptions for Asymmetric Trust](https://arxiv.org/abs/2509.09493)
*Ignacio Amores-Sesar,Christian Cachin,Juan Villacis*

Main category: cs.DC

TL;DR: 该论文研究了分布式系统中的非对称信任模型，指出现有假设过于严格，并提出了一种新方法来描述问题及更弱假设下的解决方案。


<details>
  <summary>Details</summary>
Motivation: 探讨非对称信任模型中现有解决方案的限制性假设是否过度，从而消除其优势。

Method: 提出新方法来描述非对称问题，并设计更弱假设下的可靠广播和共识算法。

Result: 证明新算法在非对称信任模型中的可行性，并展示其通用性。

Conclusion: 新方法能够在更弱假设下解决问题，扩展了对非对称信任模型的理解和应用。

Abstract: In distributed systems with asymmetric trust, each participant is free to
make its own trust assumptions about others, captured by an asymmetric quorum
system. This contrasts with ordinary, symmetric quorum systems and threshold
models, where trust assumptions are uniformly shared among participants.
Fundamental problems like reliable broadcast and consensus are unsolvable in
the asymmetric model if quorum systems satisfy only the classical properties of
consistency and availability. Existing approaches overcome this by introducing
stronger assumptions. We show that some of these assumptions are overly
restrictive, so much so that they effectively eliminate the benefits of
asymmetric trust. To address this, we propose a new approach to characterize
asymmetric problems and, building upon it, present algorithms for reliable
broadcast and consensus that require weaker assumptions than previous
solutions. Our methods are general and can be extended to other core problems
in systems with asymmetric trust.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [49] [Koza and Koza-Hub for born-interoperable knowledge graph generation using KGX](https://arxiv.org/abs/2509.09096)
*Daniel R Korn,Patrick Golden,Aaron Odell,Katherina Cortes,Shilpa Sundar,Kevin Schaper,Sarah Gehrke,Corey Cox,Harry Caufield,Justin Reese,Evan Morris,Christopher J Mungall,Melissa Haendel*

Main category: cs.DB

TL;DR: Koza和Koza-Hub是一个Python软件包，旨在简化将原始生物医学信息转换为KGX格式的过程，并提供30种黄金标准生物医学数据源的转换流程，以减少知识图谱构建中的冗余劳动。


<details>
  <summary>Details</summary>
Motivation: 当前的知识图谱构建方法存在大量冗余劳动，主要原因是缺乏数据标准和可直接用于知识图谱的数据源。

Method: 通过将知识图谱的数据摄取转化为一组基本操作，使用YAML文件进行配置，并强制遵守所选数据模式。

Result: 开发了Koza和Koza-Hub，能够高效地将生物医学数据转换为KGX格式，并标准化处理多种数据源。

Conclusion: Koza和Koza-Hub通过标准化流程和自动化手段，显著减少了知识图谱构建中的冗余劳动。

Abstract: Knowledge graph construction has become an essential domain for the future of
biomedical research. But current approaches demand a high amount of redundant
labor. These redundancies are the result of the lack of data standards and
"knowledge-graph ready" data from sources. Using the KGX standard, we aim to
solve these issues. Herein we introduce Koza and the Koza-Hub, a Python
software package which streamlines ingesting raw biomedical information into
the KGX format, and an associated set of conversion processes for thirty gold
standard biomedical data sources. Our approach is to turn knowledge graph
ingests into a set of primitive operations, provide configuration through YAML
files, and enforce compliance with the chosen data schema.

</details>


### [50] [Let's Simply Count: Quantifying Distributional Similarity Between Activities in Event Data](https://arxiv.org/abs/2509.09440)
*Henrik Kirchmann,Stephan A. Fahrenkrog-Petersen,Xixi Lu,Matthias Weidlich*

Main category: cs.DB

TL;DR: 本文主张简化的分布相似性建模方法，引入基于计数的嵌入方法，避免复杂训练同时提高可解释性，并通过实验验证其高效性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的分布相似性方法虽有效，但计算成本高且可解释性差，因此需要更简单高效的替代方案。

Method: 提出基于计数的嵌入方法，避免复杂训练过程，提供直接可解释的表示，并建立全面的评估框架。

Result: 实验表明，基于计数的嵌入方法在效率和效果上优于现有方法。

Conclusion: 该方法为事件数据中的分布相似性提供了高效且可解释的解决方案。

Abstract: To obtain insights from event data, advanced process mining methods assess
the similarity of activities to incorporate their semantic relations into the
analysis. Here, distributional similarity that captures similarity from
activity co-occurrences is commonly employed. However, existing work for
distributional similarity in process mining adopt neural network-based
approaches as developed for natural language processing, e.g., word2vec and
autoencoders. While these approaches have been shown to be effective, their
downsides are high computational costs and limited interpretability of the
learned representations.
  In this work, we argue for simplicity in the modeling of distributional
similarity of activities. We introduce count-based embeddings that avoid a
complex training process and offer a direct interpretable representation. To
underpin our call for simple embeddings, we contribute a comprehensive
benchmarking framework, which includes means to assess the intrinsic quality of
embeddings, their performance in downstream applications, and their
computational efficiency. In experiments that compare against the state of the
art, we demonstrate that count-based embeddings provide a highly effective and
efficient basis for distributional similarity between activities in event data.

</details>


### [51] [Database Views as Explanations for Relational Deep Learning](https://arxiv.org/abs/2509.09482)
*Agapi Rissaki,Ilias Fountalis,Wolfgang Gatterbauer,Benny Kimelfeld*

Main category: cs.DB

TL;DR: 本文提出了一种新的框架，用于解释关系数据库中机器学习模型的预测，通过视图定义突出显示对预测贡献最大的数据部分，并开发了高效的生成算法。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在关系数据库上的应用复杂，难以解释其预测过程，因此需要一种可理解的解释方法。

Method: 通过调整确定性、简洁性和视图定义的粒度，开发了启发式算法和学习掩码技术，以高效生成解释。

Result: 在RelBench集合上的实验表明，该方法有效且高效。

Conclusion: 该框架为关系数据库中机器学习模型提供了实用的解释工具。

Abstract: In recent years, there has been significant progress in the development of
deep learning models over relational databases, including architectures based
on heterogeneous graph neural networks (hetero-GNNs) and heterogeneous graph
transformers. In effect, such architectures state how the database records and
links (e.g., foreign-key references) translate into a large, complex numerical
expression, involving numerous learnable parameters. This complexity makes it
hard to explain, in human-understandable terms, how a model uses the available
data to arrive at a given prediction. We present a novel framework for
explaining machine-learning models over relational databases, where
explanations are view definitions that highlight focused parts of the database
that mostly contribute to the model's prediction. We establish such global
abductive explanations by adapting the classic notion of determinacy by Nash,
Segoufin, and Vianu (2010). In addition to tuning the tradeoff between
determinacy and conciseness, the framework allows controlling the level of
granularity by adopting different fragments of view definitions, such as ones
highlighting whole columns, foreign keys between tables, relevant groups of
tuples, and so on. We investigate the realization of the framework in the case
of hetero-GNNs. We develop heuristic algorithms that avoid the exhaustive
search over the space of all databases. We propose techniques that are
model-agnostic, and others that are tailored to hetero-GNNs via the notion of
learnable masking. Our approach is evaluated through an extensive empirical
study on the RelBench collection, covering a variety of domains and different
record-level tasks. The results demonstrate the usefulness of the proposed
explanations, as well as the efficiency of their generation.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [52] [Implementation of a 8-bit Wallace Tree Multiplier](https://arxiv.org/abs/2509.09178)
*Ayan Biswas,Jimmy Jin*

Main category: cs.AR

TL;DR: 本文概述了Wallace树乘法器的设计、进展及方法，包括在gpdk45技术上使用Cadence Virtuoso设计的8位输入乘法器的原理图和布局，以及最终MAC单元的实现尝试。


<details>
  <summary>Details</summary>
Motivation: Wallace树乘法器旨在通过并行架构最小化电路的时间复杂度，实现O(log(n))的性能。

Method: 采用全加器和半加器电路在每阶段减少部分积，设计了8位乘法器的原理图和布局，并尝试实现16位组合乘法加法MAC单元。

Result: 成功设计了基于Wallace树架构的8位乘法器，并探索了16位MAC单元的实现。

Conclusion: Wallace树乘法器在性能优化方面表现出色，为未来更复杂的电路设计提供了参考。

Abstract: Wallace tree multipliers are a parallel digital multiplier architecture
designed to minimize the worst-case time complexity of the circuit depth
relative to the input size [1]. In particular, it seeks to perform long
multiplication in the binary sense, reducing as many partial products per stage
as possible through full and half adders circuits, achieving O(log(n)) where n
= bit length of input. This paper provides an overview of the design, progress
and methodology in the final project of ECE 55900, consisting of the schematic
and layout of a Wallace tree 8-bit input multiplier on the gpdk45 technology in
Cadence Virtuoso, as well as any design attempts prior to the final product.
This also includes our endeavors in designing the final MAC (Multiply
Accumulate) unit with undefined targets, which we chose to implement as a 16
bit combinational multiply-add.

</details>


### [53] [Combating the Memory Walls: Optimization Pathways for Long-Context Agentic LLM Inference](https://arxiv.org/abs/2509.09505)
*Haoran Wu,Can Xiao,Jiayi Nie,Xuan Guo,Binglei Lou,Jeffrey T. H. Wong,Zhiwen Mo,Cheng Zhang,Przemyslaw Forys,Wayne Luk,Hongxiang Fan,Jianyi Cheng,Timothy M. Jones,Rika Antonova,Robert Mullins,Aaron Zhao*

Main category: cs.AR

TL;DR: PLENA是一种硬件-软件协同设计的系统，通过三种核心优化途径解决长上下文LLM推理中的内存带宽和容量问题，显著提升计算单元利用率和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理推断任务面临长上下文导致的大内存流量问题，导致计算单元利用率低下，亟需优化内存带宽和容量的解决方案。

Method: PLENA采用非对称量化方案、扁平化脉动阵列架构以及完整的软件栈（包括自定义ISA、编译器和仿真器），以优化长上下文LLM推理的内存和计算效率。

Result: 实验表明，PLENA的计算利用率比现有加速器高8.5倍，吞吐量分别比A100 GPU和TPU v6e高2.24倍和3.85倍。

Conclusion: PLENA系统通过协同设计和高效架构，有效解决了长上下文LLM推理的内存瓶颈，显著提升了性能，并将开源整套系统。

Abstract: LLMs now form the backbone of AI agents for a diverse array of applications,
including tool use, command-line agents, and web or computer use agents. These
agentic LLM inference tasks are fundamentally different from chatbot-focused
inference -- they often have much larger context lengths to capture complex,
prolonged inputs, such as entire webpage DOMs or complicated tool call
trajectories. This, in turn, generates significant off-chip memory traffic for
the underlying hardware at the inference stage and causes the workload to be
constrained by two memory walls, namely the bandwidth and capacity memory
walls, preventing the on-chip compute units from achieving high utilization.
  In this paper, we introduce PLENA, a hardware-software co-designed system
that applies three core optimization pathways to tackle these challenges. PLENA
includes an efficient hardware implementation of compute and memory units
supporting an asymmetric quantization scheme. PLENA also features a novel
flattened systolic array architecture that has native support for
FlashAttention to tackle these memory walls in the scenario of inference
serving for long-context LLMs. Additionally, PLENA is developed with a complete
stack, including a custom ISA, a compiler, a cycle-emulated simulator, and an
automated design space exploration flow. The simulated results show that PLENA
achieves up to 8.5x higher utilization than existing accelerators, and delivers
2.24x higher throughput than the A100 GPU and 3.85x higher throughput than the
TPU v6e, under the same multiplier count and memory settings. The full PLENA
system will also be open-sourced.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [54] [Uniformity within Parameterized Circuit Classes](https://arxiv.org/abs/2509.09657)
*Steef Hegeman,Jan Martens,Alfons Laarman*

Main category: cs.CC

TL;DR: 研究了参数化布尔电路族的均匀性条件，定义了线性、对数和一阶逻辑均匀性，并证明了它们在特定电路类中的等价性，为验证均匀性提供了便利方法。


<details>
  <summary>Details</summary>
Motivation: 针对浅层电路族的均匀性条件（如对数时间均匀性）通常难以证明且缺乏研究，尤其是在参数化电路复杂性中。本研究旨在填补这一空白。

Method: 形式化定义了参数化的线性均匀性、对数时间均匀性和一阶逻辑均匀性，并在特定电路类（如para-AC0和para-AC0↑）中证明了这些条件的等价性。

Result: 证明了这些均匀性条件在特定电路类中是等价的，从而为文献中均匀性声明的验证提供了依据。

Conclusion: 本研究为参数化浅层电路类的均匀性验证提供了一种便捷的方法，支持了文献中的相关声明。

Abstract: We study uniformity conditions for parameterized Boolean circuit families.
Uniformity conditions require that the infinitely many circuits in a circuit
family are in some sense easy to construct from one shared description. For
shallow circuit families, logtime-uniformity is often desired but quite
technical to prove. Despite that, proving it is often left as an exercise for
the reader -- even for recently introduced classes in parameterized circuit
complexity, where uniformity conditions have not yet been explicitly studied.
We formally define parameterized versions of linear-uniformity,
logtime-uniformity, and FO-uniformity, and prove that these result in
equivalent complexity classes when imposed on $\text{para-}\textsf{AC}^0$ and
$\text{para-}\textsf{AC}^{0\uparrow}$. Overall, we provide a convenient way to
verify uniformity for shallow parameterized circuit classes, and thereby
substantiate claims of uniformity in the literature.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [55] [Time-Fair Benchmarking for Metaheuristics: A Restart-Fair Protocol for Fixed-Time Comparisons](https://arxiv.org/abs/2509.08986)
*Junbo Jacob Lian*

Main category: cs.NE

TL;DR: 论文主张以实际运行时间而非等效函数评估次数作为公平比较元启发式算法的主要预算约束，提出了一套固定时间、重启公平的基准测试协议，并推荐使用随时性能曲线、ERT指标等时间相关的性能评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有元启发式算法的改进常以等效函数评估为性能基准，但忽略了额外的计算负担（如预处理、超参数调整等），导致比较不公平。

Method: 提出固定时间、重启公平的基准测试协议，允许算法充分利用重启和自适应机制，同时推荐时间相关的性能评估指标和标准化报告清单。

Result: 通过时间作为成本度量，实现了更公平和实用的元启发式算法评估。

Conclusion: 以实际运行时间为预算约束的评估方法能提高元启发式算法比较的可信度和实用价值。

Abstract: Numerous purportedly improved metaheuristics claim superior performance based
on equivalent function evaluations (FEs), yet often conceal additional
computational burdens in more intensive iterations, preprocessing stages, or
hyperparameter tuning. This paper posits that wall-clock time, rather than
solely FEs, should serve as the principal budgetary constraint for equitable
comparisons. We formalize a fixed-time, restart-fair benchmarking protocol
wherein each algorithm is allotted an identical wall-clock time budget per
problem instance, permitting unrestricted utilization of restarts, early
termination criteria, and internal adaptive mechanisms. We advocate for the
adoption of anytime performance curves, expected running time (ERT) metrics,
and performance profiles that employ time as the cost measure, all aimed at
predefined targets. Furthermore, we introduce a concise, reproducible checklist
to standardize reporting practices and mitigate undisclosed computational
overheads. This approach fosters more credible and practically relevant
evaluations of metaheuristic algorithms.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [56] [Investigating Student Interaction Patterns with Large Language Model-Powered Course Assistants in Computer Science Courses](https://arxiv.org/abs/2509.08862)
*Chang Liu,Loc Hoang,Andrew Stolman,Rene F. Kizilcec,Bo Wu*

Main category: cs.CY

TL;DR: 论文研究了LLM驱动的课程助手在计算机科学课程中的实际应用，结果表明它填补了学生的学习支持时间和初学者需求的空白，但也暴露了LLM在生成高阶认知问题上的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决学生在非预定时间内缺乏学术支持的普遍问题，利用LLM填补这一空白。

Method: 开发并部署LLM驱动的课程助手，收集并分析2000名学生、六门课程的交互数据，手动标注200次对话样本。

Result: LLM助手在学生需求量大的时间和入门课程中表现良好，多数回复正确且有用，但在生成高阶问题和引导学生深入思考方面效果有限。

Conclusion: LLM在教育中有潜力，但需更多教育者参与设计提示和内容，以提升其教学效果。

Abstract: Providing students with flexible and timely academic support is a challenge
at most colleges and universities, leaving many students without help outside
scheduled hours. Large language models (LLMs) are promising for bridging this
gap, but interactions between students and LLMs are rarely overseen by
educators. We developed and studied an LLM-powered course assistant deployed
across multiple computer science courses to characterize real-world use and
understand pedagogical implications. By Spring 2024, our system had been
deployed to approximately 2,000 students across six courses at three
institutions. Analysis of the interaction data shows that usage remains strong
in the evenings and nights and is higher in introductory courses, indicating
that our system helps address temporal support gaps and novice learner needs.
We sampled 200 conversations per course for manual annotation: most sampled
responses were judged correct and helpful, with a small share unhelpful or
erroneous; few responses included dedicated examples. We also examined an
inquiry-based learning strategy: only around 11% of sampled conversations
contained LLM-generated follow-up questions, which were often ignored by
students in advanced courses. A Bloom's taxonomy analysis reveals that current
LLM capabilities are limited in generating higher-order cognitive questions.
These patterns suggest opportunities for pedagogically oriented LLM-based
educational systems and greater educator involvement in configuring prompts,
content, and policies.

</details>


### [57] [Towards Trustworthy AI: Characterizing User-Reported Risks across LLMs "In the Wild"](https://arxiv.org/abs/2509.08912)
*Lingyao Li,Renkai Ma,Zhaoqian Xue,Junjie Xiong*

Main category: cs.CY

TL;DR: 研究通过分析Reddit上的讨论，使用NIST框架评估了七种大型语言模型聊天机器人在多风险方面的用户反馈，发现风险分布不均匀且与产品相关，揭示了系统中心研究与用户实际体验的差距。


<details>
  <summary>Details</summary>
Motivation: 探讨用户在实际使用大型语言模型聊天机器人时面临的多风险问题，填补实验室研究与实际应用间的空白。

Method: 通过分析Reddit上关于七种主要聊天机器人的在线讨论，基于NIST AI风险管理框架进行分类。

Result: 发现风险分布不均匀，不同产品有独特的风险特征，低频风险表现为用户权衡，高频风险则更直接危害用户。

Conclusion: 强调了以用户为中心的需求，以更好地支持用户在日常使用中应对风险。

Abstract: While Large Language Models (LLMs) are rapidly integrating into daily life,
research on their risks often remains lab-based and disconnected from the
problems users encounter "in the wild." While recent HCI research has begun to
explore these user-facing risks, it typically concentrates on a singular LLM
chatbot like ChatGPT or an isolated risk like privacy. To gain a holistic
understanding of multi-risk across LLM chatbots, we analyze online discussions
on Reddit around seven major LLM chatbots through the U.S. NIST's AI Risk
Management Framework. We find that user-reported risks are unevenly distributed
and platform-specific. While "Valid and Reliable" risk is the most frequently
mentioned, each product also exhibits a unique "risk fingerprint;" for
instance, user discussions associate GPT more with "Safe" and "Fair" issues,
Gemini with "Privacy," and Claude with "Secure and Resilient" risks.
Furthermore, the nature of these risks differs by their prevalence: less
frequent risks like "Explainability" and "Privacy" manifest as nuanced user
trade-offs, more common ones like "Fairness" are experienced as direct personal
harms. Our findings reveal gaps between risks reported by system-centered
studies and by users, highlighting the need for user-centered approaches that
support users in their daily use of LLM chatbots.

</details>


### [58] [Incorporating AI Incident Reporting into Telecommunications Law and Policy: Insights from India](https://arxiv.org/abs/2509.09508)
*Avinash Agarwal,Manisha J. Nene*

Main category: cs.CY

TL;DR: 该论文定义了电信AI事件的新风险类别，分析了印度现有法规对AI特定事件的缺失，并提出政策建议填补这一监管空白。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补传统网络安全和数据保护框架之外的AI风险监管空白，尤其是在没有横向AI法律的印度等国家。

Method: 通过定义电信AI事件并建立详细分类，分析印度现有数字法规，识别监管漏洞并提出政策建议。

Result: 发现印度现有法律未涵盖AI特定事件，提出包括强制报告高风险AI故障在内的政策建议。

Conclusion: 论文的政策建议旨在增强监管清晰度和长期韧性，为其他国家提供可复制的蓝图。

Abstract: The integration of artificial intelligence (AI) into telecommunications
infrastructure introduces novel risks, such as algorithmic bias and
unpredictable system behavior, that fall outside the scope of traditional
cybersecurity and data protection frameworks. This paper introduces a precise
definition and a detailed typology of telecommunications AI incidents,
establishing them as a distinct category of risk that extends beyond
conventional cybersecurity and data protection breaches. It argues for their
recognition as a distinct regulatory concern. Using India as a case study for
jurisdictions that lack a horizontal AI law, the paper analyzes the country's
key digital regulations. The analysis reveals that India's existing legal
instruments, including the Telecommunications Act, 2023, the CERT-In Rules, and
the Digital Personal Data Protection Act, 2023, focus on cybersecurity and data
breaches, creating a significant regulatory gap for AI-specific operational
incidents, such as performance degradation and algorithmic bias. The paper also
examines structural barriers to disclosure and the limitations of existing AI
incident repositories. Based on these findings, the paper proposes targeted
policy recommendations centered on integrating AI incident reporting into
India's existing telecom governance. Key proposals include mandating reporting
for high-risk AI failures, designating an existing government body as a nodal
agency to manage incident data, and developing standardized reporting
frameworks. These recommendations aim to enhance regulatory clarity and
strengthen long-term resilience, offering a pragmatic and replicable blueprint
for other nations seeking to govern AI risks within their existing sectoral
frameworks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [59] [Feasibility-Guided Fair Adaptive Offline Reinforcement Learning for Medicaid Care Management](https://arxiv.org/abs/2509.09655)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: FG-FARL是一种离线强化学习方法，通过调整每组安全阈值减少伤害，并在受保护子组之间平衡公平目标。实验表明其效果与基线方法相当，同时提升公平性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在减少决策支持系统中的伤害，并在受保护子组之间实现公平目标。

Method: 提出FG-FARL方法，结合可行性引导和自适应调整安全阈值，并使用Medicaid数据进行评估。

Result: FG-FARL在保持价值的同时显著提高了公平性指标。

Conclusion: FG-FARL为更安全和公平的决策支持提供了可行路径。

Abstract: We introduce Feasibility-Guided Fair Adaptive Reinforcement Learning
(FG-FARL), an offline RL procedure that calibrates per-group safety thresholds
to reduce harm while equalizing a chosen fairness target (coverage or harm)
across protected subgroups. Using de-identified longitudinal trajectories from
a Medicaid population health management program, we evaluate FG-FARL against
behavior cloning (BC) and HACO (Hybrid Adaptive Conformal Offline RL; a global
conformal safety baseline). We report off-policy value estimates with bootstrap
95% confidence intervals and subgroup disparity analyses with p-values. FG-FARL
achieves comparable value to baselines while improving fairness metrics,
demonstrating a practical path to safer and more equitable decision support.

</details>


### [60] [ProDiGy: Proximity- and Dissimilarity-Based Byzantine-Robust Federated Learning](https://arxiv.org/abs/2509.09534)
*Sena Ergisi,Luis Maßny,Rawad Bitar*

Main category: cs.LG

TL;DR: 联邦学习（FL）易受对抗攻击，尤其是在数据异质性下。ProDiGy算法通过双评分系统检测攻击，表现优于现有防御方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习存在对抗攻击的脆弱性，尤其是在数据分布不独立同分布（非IID）时，现有防御机制效果有限。

Method: 提出ProDiGy算法，采用梯度接近度和差异度的联合双评分系统评估客户端梯度。

Result: 在非IID数据下，ProDiGy保持强大的防御能力和模型准确性，优于其他防御方法。

Conclusion: 双视角方法（即通过梯度接近度和差异度）能有效检测攻击，同时提升诚实客户端的自然相似性。

Abstract: Federated Learning (FL) emerged as a widely studied paradigm for distributed
learning. Despite its many advantages, FL remains vulnerable to adversarial
attacks, especially under data heterogeneity. We propose a new Byzantine-robust
FL algorithm called ProDiGy. The key novelty lies in evaluating the client
gradients using a joint dual scoring system based on the gradients' proximity
and dissimilarity. We demonstrate through extensive numerical experiments that
ProDiGy outperforms existing defenses in various scenarios. In particular, when
the clients' data do not follow an IID distribution, while other defense
mechanisms fail, ProDiGy maintains strong defense capabilities and model
accuracy. These findings highlight the effectiveness of a dual perspective
approach that promotes natural similarity among honest clients while detecting
suspicious uniformity as a potential indicator of an attack.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [61] [A Cyber-Twin Based Honeypot for Gathering Threat Intelligence](https://arxiv.org/abs/2509.09222)
*Muhammad Azmi Umer,Zhan Xuna,Yan Lin Aung,Aditya P. Mathur,Jianying Zhou*

Main category: cs.CR

TL;DR: 本文提出了一种基于网络孪生的水处理厂蜜罐，用于吸引并记录攻击行为，以提供威胁情报，帮助提升水处理厂的安全性。


<details>
  <summary>Details</summary>
Motivation: 由于关键基础设施（CI）易受网络攻击，亟需开发有效的保护技术。

Method: 设计并部署一个水处理厂的网络孪生蜜罐，模拟真实环境以吸引攻击者，记录和分析攻击行为。

Result: 蜜罐成功运行并多次遭受攻击（如勒索软件攻击），收集的威胁情报用于改进水处理厂的保护系统。

Conclusion: 基于网络孪生的蜜罐是保护关键基础设施免受网络攻击的有效方法，可提供实际威胁情报。

Abstract: Critical Infrastructure (CI) is prone to cyberattacks. Several techniques
have been developed to protect CI against such attacks. In this work, we
describe a honeypot based on a cyber twin for a water treatment plant. The
honeypot is intended to serve as a realistic replica of a water treatment plant
that attracts potential attackers. The attacks launched on the honeypot are
recorded and analyzed for threat intelligence. The intelligence so obtained is
shared with the management of water treatment plants, who in turn may use it to
improve plant protection systems. The honeypot used here is operational and has
been attacked on several occasions using, for example, a ransomware attack that
is described in detail.

</details>


### [62] [What You Code Is What We Prove: Translating BLE App Logic into Formal Models with LLMs for Vulnerability Detection](https://arxiv.org/abs/2509.09291)
*Biwei Yan,Yue Zhang,Minghui Xu,Runyu Pan,Jinku Li,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: 本文介绍了VerifiaBLE系统，通过将BLE应用安全性分析转化为语义翻译问题，利用大型语言模型（LLMs）将代码转换为可验证的形式模型，从而降低形式化验证的门槛。


<details>
  <summary>Details</summary>
Motivation: BLE应用层存在大量安全隐患，开发者常忽略加密、认证等关键保护措施。形式化验证虽可检测这些问题，但手工建模不适用于大规模分析。

Method: 提出将BLE安全分析视为语义翻译问题，利用LLMs将代码转换为可验证的形式模型，并通过VerifiaBLE系统结合静态分析、LLM翻译和符号验证。

Result: 测试1,050个Android BLE应用后发现，仅10.2%实现了全部三项保护措施，53.9%完全未实现。

Conclusion: 使用LLMs作为翻译器可降低形式化方法的门槛，为大范围安全验证提供可能。

Abstract: The application layer of Bluetooth Low Energy (BLE) is a growing source of
security vulnerabilities, as developers often neglect to implement critical
protections such as encryption, authentication, and freshness. While formal
verification offers a principled way to check these properties, the manual
effort of constructing formal models makes it impractical for large-scale
analysis. This paper introduces a key insight: BLE application security
analysis can be reframed as a semantic translation problem, i.e., from
real-world code to formal models. We leverage large language models (LLMs) not
to directly detect vulnerabilities, but to serve as translators that convert
BLE-specific code into process models verifiable by tools like ProVerif. We
implement this idea in VerifiaBLE, a system that combines static analysis,
prompt-guided LLM translation, and symbolic verification to check three core
security features: encryption, randomness, and authentication. Applied to 1,050
Android BLE apps, VerifiaBLE uncovers systemic weaknesses: only 10.2\% of apps
implement all three protections, while 53.9\% omit them entirely. Our work
demonstrates that using LLMs as structured translators can lower the barrier to
formal methods, unlocking scalable verification across security-critical
domains.

</details>


### [63] [CryptoGuard: An AI-Based Cryptojacking Detection Dashboard Prototype](https://arxiv.org/abs/2509.09638)
*Amitabh Chakravorty,Jess Kropczynski,Nelly Elsayed*

Main category: cs.CR

TL;DR: 本文介绍了 CryptoGuard，一个面向加密货币钱包用户的前端安全仪表盘原型，专注于通过用户中心设计和 AI 概念功能提升安全性。


<details>
  <summary>Details</summary>
Motivation: 加密货币的普及带来了加密劫持的安全威胁，需要易于使用的工具帮助用户监控和保护自己的资产。

Method: 采用用户中心设计流程，开发高保真点击模型（Figma 原型），模拟用户交互并整合 AI 概念功能（如视觉警报）。

Result: 展示了 CryptoGuard 原型的功能，强调了其直观的用户体验和风险沟通能力，尽管 AI 功能尚处于概念阶段。

Conclusion: 安全工具不仅需要后端功能，还需通过用户中心设计提升用户决策能力，以应对现实威胁。

Abstract: With the widespread adoption of cryptocurrencies, cryptojacking has become a
significant security threat to crypto wallet users. This paper presents a
front-end prototype of an AI-powered security dashboard, namely, CryptoGuard.
Developed through a user-centered design process, the prototype was constructed
as a high-fidelity, click-through model from Figma mockups to simulate key user
interactions. It is designed to assist users in monitoring their login and
transaction activity, identifying any suspicious behavior, and enabling them to
take action directly within the wallet interface. The dashboard is designed for
a general audience, prioritizing an intuitive user experience for non-technical
individuals. Although its AI functionality is conceptual, the prototype
demonstrates features like visual alerts and reporting. This work is positioned
explicitly as a design concept, bridging cryptojacking detection research with
human-centered interface design. This paper also demonstrates how usability
heuristics can directly inform a tool's ability to support rapid and confident
decision-making under real-world threats. This paper argues that practical
security tools require not only robust backend functionality but also a
user-centric design that communicates risk and empowers users to take
meaningful action.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 提出了一种将游戏设计文档（GDDs）通过NLP和多模态LLMs转化为Unity游戏原型的自动化框架，显著提升了代码生成质量和设计文档的遵循程度。


<details>
  <summary>Details</summary>
Motivation: 解决AI辅助游戏开发中从设计到实现的过渡效率问题，填补关键空白。

Method: 结合微调的LLaMA-3模型和自定义Unity集成包，实现GDD解析到Unity C#代码的端到端生成。

Result: 微调模型性能显著优于基线（4.8/5.0），在多指标和跨类型游戏中表现优异。

Conclusion: 该系统证明了LLMs在游戏开发中的实用性，能高效实现设计到原型的转化。

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [65] [Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games](https://arxiv.org/abs/2509.09071)
*Crystal Qian,Kehang Zhu,John Horton,Benjamin S. Manning,Vivian Tsai,James Wexler,Nithum Thain*

Main category: cs.AI

TL;DR: 论文比较了人类、大型语言模型（LLM）和贝叶斯代理在动态谈判环境中的表现和行为差异，发现性能相似下存在显著过程差异。


<details>
  <summary>Details</summary>
Motivation: 随着自主代理越来越多地承担协调任务，评估其在不同环境中的表现和行为动态变得至关重要。

Method: 研究人员通过相同的动态谈判环境，比较了216名人类参与者、GPT-4o、Gemini 1.5 Pro和贝叶斯代理的表现和行为。

Result: 贝叶斯代理通过激进优化获得最高剩余价值，但拒绝率较高；LLM倾向于保守让步，拒绝率低；人类则表现出更多战略性和公平性行为。

Conclusion: 性能相似性可能掩盖代理在过程和目标对齐上的根本差异，这对实际部署至关重要。

Abstract: Coordination tasks traditionally performed by humans are increasingly being
delegated to autonomous agents. As this pattern progresses, it becomes critical
to evaluate not only these agents' performance but also the processes through
which they negotiate in dynamic, multi-agent environments. Furthermore,
different agents exhibit distinct advantages: traditional statistical agents,
such as Bayesian models, may excel under well-specified conditions, whereas
large language models (LLMs) can generalize across contexts. In this work, we
compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in
a dynamic negotiation setting that enables direct, identical-condition
comparisons across populations, capturing both outcomes and behavioral
dynamics. Bayesian agents extract the highest surplus through aggressive
optimization, at the cost of frequent trade rejections. Humans and LLMs can
achieve similar overall surplus, but through distinct behaviors: LLMs favor
conservative, concessionary trades with few rejections, while humans employ
more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find
that performance parity -- a common benchmark in agent evaluation -- can
conceal fundamental differences in process and alignment, which are critical
for practical deployment in real-world coordination tasks.

</details>


### [66] [Measuring Implicit Spatial Coordination in Teams: Effects on Collective Intelligence and Performance](https://arxiv.org/abs/2509.09314)
*Thuy Ngoc Nguyen,Anita Williams Woolley,Cleotilde Gonzalez*

Main category: cs.AI

TL;DR: 这篇论文研究了在限制显性沟通的协作在线搜救任务中，空间协调的三个维度（探索多样性、移动专业化和自适应空间接近度）如何影响团队表现。结果表明，空间专业化对表现有积极影响，而自适应空间接近度呈倒U型关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索在没有视觉线索或显性沟通的情况下，团队如何通过空间协调（如运动模式）来隐式协调行动。

Method: 方法包括分析34个四人团队在搜救任务中的数据，测量空间接近度、分布模式和运动对齐。

Result: 结果显示空间专业化对表现有正向预测作用，自适应空间接近度呈倒U型关系；高表现和低表现团队在这些指标上随时间表现出差异。

Conclusion: 结论强调了平衡的自适应策略在基于角色的团队协作中的重要性，对训练和AI辅助团队支持系统有启示。

Abstract: Coordinated teamwork is essential in fast-paced decision-making environments
that require dynamic adaptation, often without an opportunity for explicit
communication. Although implicit coordination has been extensively considered
in the existing literature, the majority of work has focused on co-located,
synchronous teamwork (such as sports teams) or, in distributed teams, primarily
on coordination of knowledge work. However, many teams (firefighters, military,
law enforcement, emergency response) must coordinate their movements in
physical space without the benefit of visual cues or extensive explicit
communication. This paper investigates how three dimensions of spatial
coordination, namely exploration diversity, movement specialization, and
adaptive spatial proximity, influence team performance in a collaborative
online search and rescue task where explicit communication is restricted and
team members rely on movement patterns to infer others' intentions and
coordinate actions. Our metrics capture the relational aspects of teamwork by
measuring spatial proximity, distribution patterns, and alignment of movements
within shared environments. We analyze data from 34 four-person teams (136
participants) assigned to specialized roles in a search and rescue task.
Results show that spatial specialization positively predicts performance, while
adaptive spatial proximity exhibits a marginal inverted U-shaped relationship,
suggesting moderate levels of adaptation are optimal. Furthermore, the temporal
dynamics of these metrics differentiate high- from low-performing teams over
time. These findings provide insights into implicit spatial coordination in
role-based teamwork and highlight the importance of balanced adaptive
strategies, with implications for training and AI-assisted team support
systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [67] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 研究探讨了如何在在线课程中通过个性检测模型提升社交匹配系统的效果。


<details>
  <summary>Details</summary>
Motivation: 在线课程环境阻碍了社交群体的自然形成，现有解决方案SAMI因缺乏完整的心理理论而受限。

Method: 提出了利用GPT的零样本能力从论坛介绍帖子中推断大五人格特征的模型，并将其集成到SAMI的匹配系统中。

Result: 实验证明该模型在个性检测任务中有效，初步集成显示人格特征可补充现有匹配因素。

Conclusion: 尽管需要进一步评估人格对匹配质量和学生参与的影响，但个性检测模型的引入显示了潜力。

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [68] [6G Resilience -- White Paper](https://arxiv.org/abs/2509.09005)
*Hirley Alves,Nurul H. Mahmood,Onel L. A. López,Sumudu Samarakoon,Seppo Yrjölä,Matti Latva-Aho,Markku Juntti,Ari Pouttu,Armin Dekorsy,Arthur Sousa de Sena,Aydin Sezgin,Bho Matthiesen,Chafika Benzaid,Chathuranga Weeraddana,David Hutchison,Dileepa Marasinghe,Doganalp Ergenc,Eduard Jorswieck,Erkki Harjula,Falko Dressler,Harri Saarnisaari,Italo Atzeni,Jaap Van De Beek,Jacek Rak,Konstantin Mikhaylov,Lauri Loven,Madhusanka Liyanage,Marcos Katz,Marja Matinmikko-Blue,Mehdi Rasti,Mika Ylianttila Nhan Nguyen,Pawani Porambage,Petar Popovski,Petri Ahokangas,Premanandana Rajatheva,Robert-Jeron Reifert,Tharaka Hewa,Tommy Svensson*

Main category: eess.SP

TL;DR: 该白皮书强调6G设计应以韧性为核心目标，结合可持续性和效率，分析移动网络与其他关键系统的依赖关系，提出3R框架（可靠性、鲁棒性、韧性），并在架构和技术经济层面提出实现方案。


<details>
  <summary>Details</summary>
Motivation: 移动网络从效率优先转向可持续性驱动，需要设计能够在复杂中断中适应和演进的6G网络，韧性成为关键设计目标。

Method: 通过分析移动网络与能源、交通等系统的依赖关系，提出3R框架并转化为可衡量的能力；在架构上提倡边缘原生、本地感知设计及开放接口；技术上依赖AI原生控制环和零信任安全。

Result: 提出了增强韧性的具体能力（如优雅降级、快速重构）和架构方案（如边缘原生设计），并探讨了技术经济模式与业务模型。

Conclusion: 白皮书为6G韧性发展提供了初步框架和方向，旨在启发研究者和决策者共同推动6G韧性的实现。

Abstract: 6G must be designed to withstand, adapt to, and evolve amid prolonged,
complex disruptions. Mobile networks' shift from efficiency-first to
sustainability-aware has motivated this white paper to assert that resilience
is a primary design goal, alongside sustainability and efficiency, encompassing
technology, architecture, and economics. We promote resilience by analysing
dependencies between mobile networks and other critical systems, such as
energy, transport, and emergency services, and illustrate how cascading
failures spread through infrastructures. We formalise resilience using the 3R
framework: reliability, robustness, resilience. Subsequently, we translate this
into measurable capabilities: graceful degradation, situational awareness,
rapid reconfiguration, and learning-driven improvement and recovery.
  Architecturally, we promote edge-native and locality-aware designs, open
interfaces, and programmability to enable islanded operations, fallback modes,
and multi-layer diversity (radio, compute, energy, timing). Key enablers
include AI-native control loops with verifiable behaviour, zero-trust security
rooted in hardware and supply-chain integrity, and networking techniques that
prioritise critical traffic, time-sensitive flows, and inter-domain
coordination.
  Resilience also has a techno-economic aspect: open platforms and high-quality
complementors generate ecosystem externalities that enhance resilience while
opening new markets. We identify nine business-model groups and several
patterns aligned with the 3R objectives, and we outline governance and
standardisation. This white paper serves as an initial step and catalyst for 6G
resilience. It aims to inspire researchers, professionals, government
officials, and the public, providing them with the essential components to
understand and shape the development of 6G resilience.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [69] [The Sound of Entanglement](https://arxiv.org/abs/2509.08892)
*Enar de Dios Rodríguez,Philipp Haslinger,Johannes Kofler,Richard Kueng,Benjamin Orthner,Alexander Ploier,Martin Ringbauer,Clemens Wenger*

Main category: quant-ph

TL;DR: 量子物理的引入改变了我们对宇宙的理解，并将其随机性和量子关联应用于艺术创作，特别是通过实时测量纠缠光子驱动音乐表演。


<details>
  <summary>Details</summary>
Motivation: 探索量子力学在艺术中的应用，利用量子纠缠和内在随机性作为创作工具，以增强对量子现象的理解并拓展艺术表达。

Method: 提出《纠缠之声》现场音乐表演，通过贝尔测试中的实时纠缠光子测量，将量子关联作为核心作曲元素，并与实验数据同步的视觉展示结合。

Result: 创造了独一无二的、依赖于量子关联的视听体验，这是任何经典设备无法实现的。

Conclusion: 科学与艺术的融合不仅深化了对量子现象的理解，也拓展了创造性表达的边界。

Abstract: The advent of quantum physics has revolutionized our understanding of the
universe, replacing the deterministic framework of classical physics with a
paradigm dominated by intrinsic randomness and quantum correlations. This shift
has not only enabled groundbreaking technologies, such as quantum sensors,
networks and computers, but has also unlocked entirely new possibilities for
artistic expressions. In this paper, we explore the intersection of quantum
mechanics and art, focusing on the use of quantum entanglement and inherent
randomness as creative tools. Specifically, we present The Sound of
Entanglement, a live musical performance driven by real-time measurements of
entangled photons in a Bell test. By integrating the measured quantum
correlations as a central compositional element and synchronizing live visuals
with experimental data, the performance offers a unique and unrepeatable
audiovisual experience that relies on quantum correlations which cannot be
produced by any classical device. Through this fusion of science and art, we
aim to provide a deeper appreciation of quantum phenomena while expanding the
boundaries of creative expression.

</details>


### [70] [Towards A High-Performance Quantum Data Center Network Architecture](https://arxiv.org/abs/2509.09653)
*Yufeng Xin,Liang Zhang*

Main category: quant-ph

TL;DR: 该论文提出了一种三层胖树网络架构，旨在解决量子数据中心（QDC）在网络扩展性、纠缠态生成和量子内存管理方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模量子计算机面临技术和财务限制，而模块化量子计算集群成为替代方案，但带来了新的网络扩展性和内存管理问题。

Method: 设计了一种三层胖树网络架构，包括独特的叶交换机和高级交换骨干交换机，以及队列调度机制。

Result: 通过排队论模型和NetSquid仿真，验证了该架构的可扩展性及维持高纠缠态保真度的有效性。

Conclusion: 该架构为模块化QDC网络提供了实用的解决方案。

Abstract: Quantum Data Centers (QDCs) are needed to support large-scale quantum
processing for both academic and commercial applications. While large-scale
quantum computers are constrained by technological and financial barriers, a
modular approach that clusters small quantum computers offers an alternative.
This approach, however, introduces new challenges in network scalability,
entanglement generation, and quantum memory management. In this paper, we
propose a three-layer fat-tree network architecture for QDCs, designed to
address these challenges. Our architecture features a unique leaf switch and an
advanced swapping spine switch design, optimized to handle high volumes of
entanglement requests as well as a queue scheduling mechanism that efficiently
manages quantum memory to prevent decoherence. Through queuing-theoretical
models and simulations in NetSquid, we demonstrate the proposed architecture's
scalability and effectiveness in maintaining high entanglement fidelity,
offering a practical path forward for modular QDC networks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [71] [Toward a Multi-Echelon Cyber Warfare Theory: A Meta-Game-Theoretic Paradigm for Defense and Dominance](https://arxiv.org/abs/2509.08976)
*Ya-Ting Yang,Quanyan Zhu*

Main category: cs.GT

TL;DR: 摘要探讨了博弈论在现代网络战争中的整合与应用，强调其对攻防互动的建模及策略优化的价值，并通过案例研究展示其实际效用。


<details>
  <summary>Details</summary>
Motivation: 网络战争是当前多域作战的核心，但以往研究多关注分散的技术或战术，缺乏整体性框架。博弈论提供了统一的工具，以量化分析攻防互动，优化策略。

Method: 将博弈论与现代AI技术结合，构建多层次（从政策到技术实现）的战略模型，并通过RedCyber案例展示其实际应用。

Result: 博弈论模型能有效捕捉冲突的非线性动态，解决了资源投入与优势的非一致性，并提供了策略优化工具。

Conclusion: 未来研究方向包括网络战争中的韧性机制、跨层级规划，以及AI的进一步整合与作用深化。

Abstract: Cyber warfare has become a central element of modern conflict, especially
within multi-domain operations. As both a distinct and critical domain, cyber
warfare requires integrating defensive and offensive technologies into coherent
strategies. While prior research has emphasized isolated tactics or fragmented
technologies, a holistic understanding is essential for effective resource
deployment and risk mitigation. Game theory offers a unifying framework for
this purpose. It not only models attacker-defender interactions but also
provides quantitative tools for equilibrium analysis, risk assessment, and
strategic reasoning. Integrated with modern AI techniques, game-theoretic
models enable the design and optimization of strategies across multiple levels
of cyber warfare, from policy and strategy to operations, tactics, and
technical implementations. These models capture the paradoxical logic of
conflict, where more resources do not always translate into greater advantage,
and where nonlinear dynamics govern outcomes. To illustrate the approach, this
chapter examines RedCyber, a synthetic cyber conflict, demonstrating how
game-theoretic methods capture the interdependencies of cyber operations. The
chapter concludes with directions for future research on resilience,
cros-echelon planning, and the evolving role of AI in cyber warfare.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [72] [Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene Evaluation](https://arxiv.org/abs/2509.09143)
*Yuiko Uchida,Ren Togo,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: 本文提出了一种名为OSIM的新型评估指标，专注于人类视觉感知的基本单元——‘物体’，并通过对象检测模型量化场景中每个物体的‘物体性’，更贴近人类感知。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景评估指标多关注整体图像质量，与人类感知存在差异。本文基于神经心理学发现，假设人类对3D场景的识别主要依赖于对个体物体的注意力，因此设计OSIM以更贴近人类感知。

Method: OSIM利用对象检测模型及其特征表示，量化场景中每个物体的‘物体性’。通过用户研究验证其与人类感知的一致性，并对OSIM的特性进行多角度分析。

Result: 用户研究表明，OSIM相比现有指标更符合人类感知。此外，标准化实验下重新评估了3D重建和生成模型，为该领域提供了更清晰的进展评估。

Conclusion: OSIM作为一种对象中心的评估指标，能够更准确地反映人类对3D场景的感知，为未来研究和模型评估提供了新工具。

Abstract: This paper presents Objectness SIMilarity (OSIM), a novel evaluation metric
for 3D scenes that explicitly focuses on "objects," which are fundamental units
of human visual perception. Existing metrics assess overall image quality,
leading to discrepancies with human perception. Inspired by neuropsychological
insights, we hypothesize that human recognition of 3D scenes fundamentally
involves attention to individual objects. OSIM enables object-centric
evaluations by leveraging an object detection model and its feature
representations to quantify the "objectness" of each object in the scene. Our
user study demonstrates that OSIM aligns more closely with human perception
compared to existing metrics. We also analyze the characteristics of OSIM using
various approaches. Moreover, we re-evaluate recent 3D reconstruction and
generation models under a standardized experimental setup to clarify
advancements in this field. The code is available at
https://github.com/Objectness-Similarity/OSIM.

</details>


### [73] [Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles](https://arxiv.org/abs/2509.09349)
*Ian Nell,Shane Gilroy*

Main category: cs.CV

TL;DR: 该论文提出了一种基于外部观察技术的驾驶员行为分类系统，通过计算机视觉方法检测分心和受损驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 解决交通事故中由驾驶员分心和受损驾驶导致的问题。

Method: 使用YOLO目标检测模型和自定义车道估计算法，结合实时目标跟踪、横向位移分析和车道位置监测。

Result: 实验表明该系统在不同道路和环境条件下具有可靠性和适应性。

Conclusion: 该视觉方法无需车辆间通信，能有效分析非联网车辆的驾驶行为。

Abstract: Road traffic accidents remain a significant global concern, with human error,
particularly distracted and impaired driving, among the leading causes. This
study introduces a novel driver behavior classification system that uses
external observation techniques to detect indicators of distraction and
impairment. The proposed framework employs advanced computer vision
methodologies, including real-time object tracking, lateral displacement
analysis, and lane position monitoring. The system identifies unsafe driving
behaviors such as excessive lateral movement and erratic trajectory patterns by
implementing the YOLO object detection model and custom lane estimation
algorithms. Unlike systems reliant on inter-vehicular communication, this
vision-based approach enables behavioral analysis of non-connected vehicles.
Experimental evaluations on diverse video datasets demonstrate the framework's
reliability and adaptability across varying road and environmental conditions.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [74] [An Integrated Open Source Software System for the Generation and Analysis of Subject-Specific Blood Flow Simulation Ensembles](https://arxiv.org/abs/2509.09392)
*Simon Leistikow,Thomas Miro,Adrian Kummerländer,Ali Nahardani,Katja Grün,Markus Franz,Verena Hoerr,Mathias J. Krause,Lars Linsen*

Main category: physics.med-ph

TL;DR: 摘要介绍了一种结合CFD和MRI的交互式可视化分析工具，用于研究血流动力学参数，提高分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 血流动力学分析对心血管疾病的诊断和研究至关重要，但需要结合MRI和CFD技术。

Method: 开发了一种开源、可定制的可视化工具，支持模拟参数的高多样性，并通过2D嵌入相似性空间进行分析。

Result: 在三个实际案例中验证了工具的有效性，并通过专家反馈提升功能和可用性。

Conclusion: 工具结合CFD和MRI的优势，为血流动力学参数提供了更全面的理解。

Abstract: Background and Objective: Hemodynamic analysis of blood flow through arteries
and veins is critical for diagnosing cardiovascular diseases, such as aneurysms
and stenoses, and for investigating cardiovascular parameters, such as
turbulence and wall shear stress. For subject-specific analyses, the anatomy
and blood flow of the subject can be captured non-invasively using structural
and 4D Magnetic Resonance Imaging (MRI). Computational Fluid Dynamics (CFD), on
the other hand, can be used to generate blood flow simulations by solving the
Navier-Stokes equations. To generate and analyze subject-specific blood flow
simulations, MRI and CFD have to be brought together.
  Methods: We present an interactive, customizable, and user-oriented visual
analysis tool that assists researchers in both medicine and numerical analysis.
Our open-source tool is applicable to domains such as CFD and MRI, and it
facilitates the analysis of simulation results and medical data, especially in
hemodynamic studies. It enables the creation of simulation ensembles with a
high variety of parameters. Furthermore, it allows for the visual and
analytical examination of simulations and measurements through 2D embeddings of
the similarity space.
  Results: To demonstrate the effectiveness of our tool, we applied it to three
real-world use cases, showcasing its ability to configure simulation ensembles
and analyse blood flow dynamics. We evaluated our example cases together with
MRI and CFD experts to further enhance features and increase the usability.
  Conclusions: By combining the strengths of both CFD and MRI, our tool
provides a more comprehensive understanding of hemodynamic parameters,
facilitating more accurate analysis of hemodynamic biomarkers.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [75] [HARD: A Performance Portable Radiation Hydrodynamics Code based on FleCSI Framework](https://arxiv.org/abs/2509.08971)
*Julien Loiseau,Hyun Lim,Andrés Yagüe López,Mammadbaghir Baghirzade,Shihab Shahriar Khan,Yoonsoo Kim,Sudarshan Neopane,Alexander Strack,Farhana Taiyebah,Benjamin K. Bergen*

Main category: physics.comp-ph

TL;DR: HARD是一个开源的高性能流体动力学与辐射扩散耦合模拟工具，基于FleCSI框架，支持多种运行时后端和跨平台运行。通过Kokkos实现节点级并行，包含回归测试确保科学可靠性，并在GitHub上开源共享。


<details>
  <summary>Details</summary>
Motivation: 为辐射流体动力学研究提供一个高性能、可移植且科学可靠的模拟平台。

Method: 基于FleCSI框架，支持多种后端运行时（如Legion、MPI和HPX），利用Kokkos实现节点级并行，并提供回归测试验证科学可靠性。

Result: HARD实现了跨平台的高性能计算，并通过自动化测试验证了其科学可靠性。

Conclusion: HARD是一个可持续的辐射流体动力学研究平台，具备高性能、可移植性和社区驱动的开发模式。

Abstract: Hydrodynamics And Radiation Diffusion} (HARD) is an open-source application
for high-performance simulations of compressible hydrodynamics with
radiation-diffusion coupling. Built on the FleCSI (Flexible Computational
Science Infrastructure) framework, HARD expresses its computational units as
tasks whose execution can be orchestrated by multiple back-end runtimes,
including Legion, MPI, and HPX. Node-level parallelism is delegated to Kokkos,
providing a single, portable code base that runs efficiently on laptops, small
homogeneous clusters, and the largest heterogeneous supercomputers currently
available. To ensure scientific reliability, HARD includes a regression-test
suite that automatically reproduces canonical verification problems such as the
Sod and LeBlanc shock tubes and the Sedov blast wave, comparing numerical
solutions against known analytical results. The project is distributed under an
OSI-approved license, hosted on GitHub, and accompanied by reproducible build
scripts and continuous integration workflows. This combination of performance
portability, verification infrastructure, and community-focused development
makes HARD a sustainable platform for advancing radiation hydrodynamics
research across multiple domains.

</details>
