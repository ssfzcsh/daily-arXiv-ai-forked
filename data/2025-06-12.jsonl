{"id": "2506.09230", "pdf": "https://arxiv.org/pdf/2506.09230", "abs": "https://arxiv.org/abs/2506.09230", "authors": ["Juan Carlos Recio Abad", "Ruben Saborido", "Francisco Chicano"], "title": "Formal Methods Meets Readability: Auto-Documenting JML Java Code", "categories": ["cs.SE"], "comment": null, "summary": "This paper investigates whether formal specifications using Java Modeling\nLanguage (JML) can enhance the quality of Large Language Model (LLM)-generated\nJavadocs. While LLMs excel at producing documentation from code alone, we\nhypothesize that incorporating formally verified invariants yields more\ncomplete and accurate results. We present a systematic comparison of\ndocumentation generated from JML-annotated and non-annotated Java classes,\nevaluating quality through both automated metrics and expert analysis. Our\nfindings demonstrate that JML significantly improves class-level documentation\ncompleteness, with more moderate gains at the method level. Formal\nspecifications prove particularly effective in capturing complex class\ninvariants and design contracts that are frequently overlooked in code-only\ndocumentation. A threshold effect emerges, where the benefits of JML become\nmore pronounced for classes with richer sets of invariants. While JML enhances\nspecification coverage, its impact on core descriptive quality is limited,\nsuggesting that formal specifications primarily ensure comprehensive coverage\nrather than fundamentally altering implementation descriptions. These results\noffer actionable insights for software teams adopting formal methods in\ndocumentation workflows, highlighting scenarios where JML provides clear\nadvantages. The study contributes to AI-assisted software documentation\nresearch by demonstrating how formal methods and LLMs can synergistically\nimprove documentation quality."}
{"id": "2506.09289", "pdf": "https://arxiv.org/pdf/2506.09289", "abs": "https://arxiv.org/abs/2506.09289", "authors": ["Boxi Yu", "Yuxuan Zhu", "Pinjia He", "Daniel Kang"], "title": "UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench", "categories": ["cs.SE", "cs.CL", "D.0; I.2"], "comment": null, "summary": "The advent of Large Language Models (LLMs) has spurred the development of\ncoding agents for real-world code generation. As a widely used benchmark for\nevaluating the code generation capabilities of these agents, SWE-Bench uses\nreal-world problems based on GitHub issues and their corresponding pull\nrequests. However, the manually written test cases included in these pull\nrequests are often insufficient, allowing generated patches to pass the tests\nwithout resolving the underlying issue. To address this challenge, we introduce\nUTGenerator, an LLM-driven test case generator that automatically analyzes\ncodebases and dependencies to generate test cases for real-world Python\nprojects. Building on UTGenerator, we propose UTBoost, a comprehensive\nframework for test case augmentation. In our evaluation, we identified 36 task\ninstances with insufficient test cases and uncovered 345 erroneous patches\nincorrectly labeled as passed in the original SWE Bench. These corrections,\nimpacting 40.9% of SWE-Bench Lite and 24.4% of SWE-Bench Verified leaderboard\nentries, yield 18 and 11 ranking changes, respectively."}
{"id": "2506.09370", "pdf": "https://arxiv.org/pdf/2506.09370", "abs": "https://arxiv.org/abs/2506.09370", "authors": ["Rohit Mehra", "Priyavanshi Pathania", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Assessing the Impact of Refactoring Energy-Inefficient Code Patterns on Software Sustainability: An Industry Case Study", "categories": ["cs.SE"], "comment": "3 pages. To be published in the proceedings of 38th IEEE/ACM\n  International Conference on Automated Software Engineering (ASE 2023),\n  Kirchberg, Luxembourg", "summary": "Advances in technologies like artificial intelligence and metaverse have led\nto a proliferation of software systems in business and everyday life. With this\nwidespread penetration, the carbon emissions of software are rapidly growing as\nwell, thereby negatively impacting the long-term sustainability of our\nenvironment. Hence, optimizing software from a sustainability standpoint\nbecomes more crucial than ever. We believe that the adoption of automated tools\nthat can identify energy-inefficient patterns in the code and guide appropriate\nrefactoring can significantly assist in this optimization. In this extended\nabstract, we present an industry case study that evaluates the sustainability\nimpact of refactoring energy-inefficient code patterns identified by automated\nsoftware sustainability assessment tools for a large application. Preliminary\nresults highlight a positive impact on the application's sustainability\npost-refactoring, leading to a 29% decrease in per-user per-month energy\nconsumption."}
{"id": "2506.09396", "pdf": "https://arxiv.org/pdf/2506.09396", "abs": "https://arxiv.org/abs/2506.09396", "authors": ["Zongjie Li", "Shuai Wang"], "title": "Reasoning as a Resource: Optimizing Fast and Slow Thinking in Code Generation Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This position paper proposes a fundamental shift in designing code generation\nmodels: treating reasoning depth as a controllable resource. Rather than being\nan incidental byproduct of prompting, we argue that the trade-off between\nrapid, direct answers (\"fast thinking\") and elaborate, chain-of-thought\ndeliberation (\"slow thinking\") must be explicitly managed. We contend that\noptimizing reasoning budgets across the entire model lifecycle - from synthetic\ndata creation and benchmarking to real-world deploymen - can unlock superior\ntrade-offs among accuracy, latency, and cost. This paper outlines how adaptive\ncontrol over reasoning can enrich supervision signals, motivate new\nmulti-dimensional benchmarks, and inform cost-aware, security-conscious\ndeployment policies. By viewing fast and slow thinking as complementary modes\nto be scheduled, we envision coding agents that think deep when necessary and\nact fast when possible."}
{"id": "2506.09089", "pdf": "https://arxiv.org/pdf/2506.09089", "abs": "https://arxiv.org/abs/2506.09089", "authors": ["Xia Li"], "title": "Designing conflict-based communicative tasks in Teaching Chinese as a Foreign Language with ChatGPT", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "in French language", "summary": "In developing the teaching program for a course in Oral Expression in\nTeaching Chinese as a Foreign Language at the university level, the teacher\ndesigns communicative tasks based on conflicts to encourage learners to engage\nin interactive dynamics and develop their oral interaction skills. During the\ndesign of these tasks, the teacher uses ChatGPT to assist in finalizing the\nprogram. This article aims to present the key characteristics of the\ninteractions between the teacher and ChatGPT during this program development\nprocess, as well as to examine the use of ChatGPT and its impacts in this\nspecific context."}
{"id": "2506.09070", "pdf": "https://arxiv.org/pdf/2506.09070", "abs": "https://arxiv.org/abs/2506.09070", "authors": ["Chenqi Zhang", "Yu Feng", "Jieru Zhao", "Guangda Liu", "Wenchao Ding", "Chentao Wu", "Minyi Guo"], "title": "STREAMINGGS: Voxel-Based Streaming 3D Gaussian Splatting with Memory Optimization and Architectural Support", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has gained popularity for its efficiency and\nsparse Gaussian-based representation. However, 3DGS struggles to meet the\nreal-time requirement of 90 frames per second (FPS) on resource-constrained\nmobile devices, achieving only 2 to 9 FPS.Existing accelerators focus on\ncompute efficiency but overlook memory efficiency, leading to redundant DRAM\ntraffic. We introduce STREAMINGGS, a fully streaming 3DGS\nalgorithm-architecture co-design that achieves fine-grained pipelining and\nreduces DRAM traffic by transforming from a tile-centric rendering to a\nmemory-centric rendering. Results show that our design achieves up to 45.7\n$\\times$ speedup and 62.9 $\\times$ energy savings over mobile Ampere GPUs."}
{"id": "2506.09480", "pdf": "https://arxiv.org/pdf/2506.09480", "abs": "https://arxiv.org/abs/2506.09480", "authors": ["Luca Fehlings", "Muhtasim Alam Chowdhury", "Banafsheh Saber Latibari", "Soheil Salehi", "Erika Covi"], "title": "Reliability of Capacitive Read in Arrays of Ferroelectric Capacitors", "categories": ["cs.ET", "physics.app-ph"], "comment": "4 pages, 6 figures, submitted and presented at ISCAS 2025, London", "summary": "The non-destructive capacitance read-out of ferroelectric capacitors (FeCaps)\nbased on doped HfO$_2$ metal-ferroelectric-metal (MFM) structures offers the\npotential for low-power and highly scalable crossbar arrays. This is due to a\nnumber of factors, including the selector-less design, the absence of sneak\npaths, the power-efficient charge-based read operation, and the reduced IR\ndrop. Nevertheless, a reliable capacitive readout presents certain challenges,\nparticularly in regard to device variability and the trade-off between read\nyield and read disturbances, which can ultimately result in bit-flips. This\npaper presents a digital read macro for HfO$_2$ FeCaps and provides design\nguidelines for capacitive readout of HfO$_2$ FeCaps, taking device-centric\nreliability and yield challenges into account. An experimentally calibrated\nphysics-based compact model of HfO$_2$ FeCaps is employed to investigate the\nreliability of the read-out operation of the FeCap macro through Monte Carlo\nsimulations. Based on this analysis, we identify limitations posed by the\ndevice variability and propose potential mitigation strategies through\ndesign-technology co-optimization (DTCO) of the FeCap device characteristics\nand the CMOS circuit design. Finally, we examine the potential applications of\nthe FeCap macro in the context of secure hardware. We identify potential\nsecurity threats and propose strategies to enhance the robustness of the\nsystem."}
{"id": "2506.09061", "pdf": "https://arxiv.org/pdf/2506.09061", "abs": "https://arxiv.org/abs/2506.09061", "authors": ["Alyssa Pinnock", "Shakya Jayakody", "Kawsher A Roxy", "Md Rubel Ahmed"], "title": "EdgeProfiler: A Fast Profiling Framework for Lightweight LLMs on Edge Using Analytical Model", "categories": ["cs.DC", "cs.AI", "cs.PF"], "comment": "4 figures, 7 pages, IEEE conference template", "summary": "This paper introduces EdgeProfiler, a fast profiling framework designed for\nevaluating lightweight Large Language Models (LLMs) on edge systems. While LLMs\noffer remarkable capabilities in natural language understanding and generation,\ntheir high computational, memory, and power requirements often confine them to\ncloud environments. EdgeProfiler addresses these challenges by providing a\nsystematic methodology for assessing LLM performance in resource-constrained\nedge settings. The framework profiles compact LLMs, including TinyLLaMA,\nGemma3.1B, Llama3.2-1B, and DeepSeek-r1-1.5B, using aggressive quantization\ntechniques and strict memory constraints. Analytical modeling is used to\nestimate latency, FLOPs, and energy consumption. The profiling reveals that\n4-bit quantization reduces model memory usage by approximately 60-70%, while\nmaintaining accuracy within 2-5% of full-precision baselines. Inference speeds\nare observed to improve by 2-3x compared to FP16 baselines across various edge\ndevices. Power modeling estimates a 35-50% reduction in energy consumption for\nINT4 configurations, enabling practical deployment on hardware such as\nRaspberry Pi 4/5 and Jetson Orin Nano Super. Our findings emphasize the\nimportance of efficient profiling tailored to lightweight LLMs in edge\nenvironments, balancing accuracy, energy efficiency, and computational\nfeasibility."}
{"id": "2506.09226", "pdf": "https://arxiv.org/pdf/2506.09226", "abs": "https://arxiv.org/abs/2506.09226", "authors": ["Bowen Wu", "Wei Cui", "Carlo Curino", "Matteo Interlandi", "Rathijit Sen"], "title": "Terabyte-Scale Analytics in the Blink of an Eye", "categories": ["cs.DB", "cs.DC", "cs.PF"], "comment": null, "summary": "For the past two decades, the DB community has devoted substantial research\nto take advantage of cheap clusters of machines for distributed data analytics\n-- we believe that we are at the beginning of a paradigm shift. The scaling\nlaws and popularity of AI models lead to the deployment of incredibly powerful\nGPU clusters in commercial data centers. Compared to CPU-only solutions, these\nclusters deliver impressive improvements in per-node compute, memory bandwidth,\nand inter-node interconnect performance. In this paper, we study the problem of\nscaling analytical SQL queries on distributed clusters of GPUs, with the stated\ngoal of establishing an upper bound on the likely performance gains. To do so,\nwe build a prototype designed to maximize performance by leveraging ML/HPC best\npractices, such as group communication primitives for cross-device data\nmovements. This allows us to conduct thorough performance experimentation to\npoint our community towards a massive performance opportunity of at least\n60$\\times$. To make these gains more relatable, before you can blink twice, our\nsystem can run all 22 queries of TPC-H at a 1TB scale factor!"}
{"id": "2506.09426", "pdf": "https://arxiv.org/pdf/2506.09426", "abs": "https://arxiv.org/abs/2506.09426", "authors": ["Brian Zhao", "Yiwei Yang", "Yusheng Zheng", "Andi Quinn"], "title": "Exploiting Control-flow Enforcement Technology for Sound and Precise Static Binary Disassembly", "categories": ["cs.AR"], "comment": null, "summary": "Rewriting x86_64 binaries-whether for security hardening, dynamic\ninstrumentation, or performance profiling is notoriously difficult due to\nvariable-length instructions, interleaved code and data, and indirect jumps to\narbitrary byte offsets. Existing solutions (e.g., \"superset disassembly\")\nensure soundness but incur significant overhead and produce large rewritten\nbinaries, especially for on-the-fly instrumentation. This paper addresses these\nchallenges by introducing the Time Variance Authority (TVA), which leverages\nIntel's Control-Flow Enforcement Technology (CET). By recognizing endbr64 as\nthe only valid indirect jump target, TVA prunes spurious disassembly paths\nwhile preserving soundness and emulates CET constraints on processors lacking\nnative CET support, effectively mitigating ROP/JOP exploits without new\nhardware. We implement TVA by modernizing the Multiverse rewriter for 64-bit\nLinux. Our evaluation on SPEC CPU2017 and real-world applications shows that\nTVA-guided rewriting achieves up to 1.3x faster instrumentation time. These\nresults underscore TVA's feasibility as a high-performance, uprobes-free\nalternative for robust x86_64 binary analysis and rewriting."}
{"id": "2506.09506", "pdf": "https://arxiv.org/pdf/2506.09506", "abs": "https://arxiv.org/abs/2506.09506", "authors": ["Bastian Jäckl", "Vojtěch Kloda", "Daniel A. Keim", "Jakub Lokoč"], "title": "Dynamic Sub-region Search in Homogeneous Collections Using CLIP", "categories": ["cs.MM", "68U10", "H.3.3; I.4.10; H.2.8"], "comment": "18 pages, 4 figures, 5 tables", "summary": "Querying with text-image-based search engines in highly homogeneous\ndomain-specific image collections is challenging for users, as they often\nstruggle to provide descriptive text queries. For example, in an underwater\ndomain, users can usually characterize entities only with abstract labels, such\nas corals and fish, which leads to low recall rates. Our work investigates\nwhether recall can be improved by supplementing text queries with position\ninformation. Specifically, we explore dynamic image partitioning approaches\nthat divide candidates into semantically meaningful regions of interest.\nInstead of querying entire images, users can specify regions they recognize.\nThis enables the use of position constraints while preserving the semantic\ncapabilities of multimodal models. We introduce and evaluate strategies for\nintegrating position constraints into semantic search models and compare them\nagainst static partitioning approaches. Our evaluation highlights both the\npotential and the limitations of sub-region-based search methods using dynamic\npartitioning. Dynamic search models achieve up to double the retrieval\nperformance compared to static partitioning approaches but are highly sensitive\nto perturbations in the specified query positions."}
{"id": "2506.09159", "pdf": "https://arxiv.org/pdf/2506.09159", "abs": "https://arxiv.org/abs/2506.09159", "authors": ["Antonio Calagna", "Yenchia Yu", "Paolo Giaccone", "Carla Fabiana Chiasserini"], "title": "MOSE: A Novel Orchestration Framework for Stateful Microservice Migration at the Edge", "categories": ["cs.NI"], "comment": null, "summary": "Stateful migration has emerged as the dominant technology to support\nmicroservice mobility at the network edge while ensuring a satisfying\nexperience to mobile end users. This work addresses two pivotal challenges,\nnamely, the implementation and the orchestration of the migration process. We\nfirst introduce a novel framework that efficiently implements stateful\nmigration and effectively orchestrates the migration process by fulfilling both\nnetwork and application KPI targets. Through experimental validation using\nrealistic microservices, we then show that our solution (i) greatly improves\nmigration performance, yielding up to 77% decrease of the migration downtime\nwith respect to the state of the art, and (ii) successfully addresses the\nstrict user QoE requirements of critical scenarios featuring latency-sensitive\nmicroservices. Further, we consider two practical use cases, featuring,\nrespectively, a UAV autopilot microservice and a multi-object tracking task,\nand demonstrate how our framework outperforms current state-of-the-art\napproaches in configuring the migration process and in meeting KPI targets."}
{"id": "2506.09758", "pdf": "https://arxiv.org/pdf/2506.09758", "abs": "https://arxiv.org/abs/2506.09758", "authors": ["Zikai Liu", "Jasmin Schult", "Pengcheng Xu", "Timothy Roscoe"], "title": "Mainframe-style channel controllers for modern disaggregated memory systems", "categories": ["cs.OS", "cs.AR", "cs.ET"], "comment": null, "summary": "Despite the promise of alleviating the main memory bottleneck, and the\nexistence of commercial hardware implementations, techniques for Near-Data\nProcessing have seen relatively little real-world deployment. The idea has\nreceived renewed interest with the appearance of disaggregated or \"far\" memory,\nfor example in the use of CXL memory pools.\n  However, we argue that the lack of a clear OS-centric abstraction of\nNear-Data Processing is a major barrier to adoption of the technology. Inspired\nby the channel controllers which interface the CPU to disk drives in mainframe\nsystems, we propose memory channel controllers as a convenient, portable, and\nvirtualizable abstraction of Near-Data Processing for modern disaggregated\nmemory systems.\n  In addition to providing a clean abstraction that enables OS integration\nwhile requiring no changes to CPU architecture, memory channel controllers\nincorporate another key innovation: they exploit the cache coherence provided\nby emerging interconnects to provide a much richer programming model, with more\nfine-grained interaction, than has been possible with existing designs."}
{"id": "2506.09550", "pdf": "https://arxiv.org/pdf/2506.09550", "abs": "https://arxiv.org/abs/2506.09550", "authors": ["Fanpeng Yang", "Xu Ma", "Shuling Wang", "Xiong Xu", "Qinxiang Cao", "Naijun Zhan", "Xiaofeng Li", "Bin Gu"], "title": "Automated Synthesis of Formally Verified Multi-Abstraction Function Summaries", "categories": ["cs.SE"], "comment": null, "summary": "Function summaries, which characterize the behavior of code segments\n(typically functions) through preconditions and postconditions, are essential\nfor understanding, reusing, and verifying software, particularly in\nsafety-critical domains like aerospace embedded systems. However, these\nmission-critical legacy code serving as a valuable reused asset often lacks\nformal specifications. It is challenging to automatically generate function\nsummaries for C programs, due to the existence of complex features such as\nloops, nested function calls, pointer aliasing, and so on. Moreover, function\nsummaries should support multiple abstraction levels to meet diverse\nrequirements, e.g. precise summaries capturing full functionality for formal\nverification and intuitive summaries for human understanding.\n  To address these challenges, we first propose a novel framework that combines\nsymbolic execution, large language models (LLMs), and formal verification to\ngenerate Relatively Strongest Postconditions (RSPs) and build function\nsummaries that fully capture program behavior. Our approach leverages VST-A's\nsymbolic execution to precisely track program execution paths and state\ntransitions, employs LLMs to infer loop invariants based on predefined\ntemplates, and uses Frama-C to guarantee soundness of generated summaries in an\niterative refinement loop. Furthermore, from generated RSPs, we automatically\nsynthesize strongest non-redundant postconditions expressed within given domain\nspecific language. We compare our approach with existing work through extensive\nexperiments."}
{"id": "2506.09153", "pdf": "https://arxiv.org/pdf/2506.09153", "abs": "https://arxiv.org/abs/2506.09153", "authors": ["Tanjil Hasan Sakib", "Samia Jahan Mojumder", "Rajan Das Gupta", "Md Imrul Hasan Showmick", "Md. Yeasin Rahat", "Md. Jakir Hossen"], "title": "Real-Time Confidence Detection through Facial Expressions and Hand Gestures", "categories": ["cs.HC"], "comment": "Accepted in MECON 2025", "summary": "Real-time face orientation recognition is a cutting-edge technology meant to\ntrack and analyze facial movements in virtual environments such as online\ninterviews, remote meetings, and virtual classrooms. As the demand for virtual\ninteractions grows, it becomes increasingly important to measure participant\nengagement, attention, and overall interaction. This research presents a novel\nsolution that leverages the Media Pipe Face Mesh framework to identify facial\nlandmarks and extract geometric data for calculating Euler angles, which\ndetermine head orientation in real time. The system tracks 3D facial landmarks\nand uses this data to compute head movements with a focus on accuracy and\nresponsiveness. By studying Euler angles, the system can identify a user's head\norientation with an accuracy of 90\\%, even at a distance of up to four feet.\nThis capability offers significant enhancements for monitoring user\ninteraction, allowing for more immersive and interactive virtual ex-periences.\nThe proposed method shows its reliability in evaluating participant\nattentiveness during online assessments and meetings. Its application goes\nbeyond engagement analysis, potentially providing a means for improving the\nquality of virtual communication, fostering better understanding between\nparticipants, and ensuring a higher level of interaction in digital spaces.\nThis study offers a basis for future developments in enhancing virtual user\nexperiences by integrating real-time facial tracking technologies, paving the\nway for more adaptive and interactive web-based platform."}
{"id": "2506.09075", "pdf": "https://arxiv.org/pdf/2506.09075", "abs": "https://arxiv.org/abs/2506.09075", "authors": ["Elly Akhoundi", "Hung Yu Ling", "Anup Anand Deshmukh", "Judith Butepage"], "title": "SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted to CVPR 2025 Human Motion Generation Workshop. 10 pages, 3\n  figures, 5 Tables, and 40 References", "summary": "Motion in-betweening is a crucial tool for animators, enabling intricate\ncontrol over pose-level details in each keyframe. Recent machine learning\nsolutions for motion in-betweening rely on complex models, incorporating\nskeleton-aware architectures or requiring multiple modules and training steps.\nIn this work, we introduce a simple yet effective Transformer-based framework,\nemploying a single Transformer encoder to synthesize realistic motions for\nmotion in-betweening tasks. We find that data modeling choices play a\nsignificant role in improving in-betweening performance. Among others, we show\nthat increasing data volume can yield equivalent or improved motion\ntransitions, that the choice of pose representation is vital for achieving\nhigh-quality results, and that incorporating velocity input features enhances\nanimation performance. These findings challenge the assumption that model\ncomplexity is the primary determinant of animation quality and provide insights\ninto a more data-centric approach to motion interpolation. Additional videos\nand supplementary material are available at https://silk-paper.github.io."}
{"id": "2506.09963", "pdf": "https://arxiv.org/pdf/2506.09963", "abs": "https://arxiv.org/abs/2506.09963", "authors": ["Shane Sweeney", "Krishnendu Guha"], "title": "Dynamic Hypergraph Partitioning of Quantum Circuits with Hybrid Execution", "categories": ["cs.ET", "quant-ph"], "comment": "11 pages", "summary": "Quantum algorithms offer an exponential speedup over classical algorithms for\na range of computational problems. The fundamental mechanisms underlying\nquantum computation required the development and construction of quantum\ncomputers. These devices are referred to as NISQ (Noisy Intermediate-Scale\nQuantum) devices. Not only are NISQ devices extremely limited in their qubit\ncount but they also suffer from noise during computation and this problem only\ngets worse as the size of the circuit increases which limits the practical use\nof quantum computers for modern day applications. This paper will focus on\nutilizing quantum circuit partitioning to overcome the inherent issues of NISQ\ndevices. Partitioning a quantum circuit into smaller subcircuits has allowed\nfor the execution of quantum circuits that are too large to fit on one quantum\ndevice. There have been many previous approaches to quantum circuit\npartitioning and each of these approaches differ in how they work with some\nfocusing on hardware-aware partitioning, optimal graph-based partitioning,\nmulti-processor architectures and many more. These approaches achieve success\nin their objective but they often fail to scale well which impacts cost and\nnoise. The ultimate goal of this paper is to mitigate these issues by\nminimizing 3 important metrics; noise, time and cost. To achieve this we use\ndynamic partitioning for practical circuit cutting and we take advantage of the\nbenefits of hybrid execution where classical computation will be used alongside\nquantum hardware. This approach has proved to be beneficial with respect to\nnoise with classical execution enabling a 42.30% reduction in noise and a 40%\nreduction in the number of qubits required in cases where a mixture of\nclassical and quantum computation were required."}
{"id": "2506.09242", "pdf": "https://arxiv.org/pdf/2506.09242", "abs": "https://arxiv.org/abs/2506.09242", "authors": ["Jonas Latt", "Christophe Coreixas"], "title": "Multi-GPU Acceleration of PALABOS Fluid Solver using C++ Standard Parallelism", "categories": ["cs.DC"], "comment": null, "summary": "This article presents the principles, software architecture, and performance\nanalysis of the GPU port of the lattice Boltzmann software library Palabos (J.\nLatt et al., \"Palabos: Parallel lattice Boltzmann solver\", Comput. Math. Appl.\n81, 334-350, (2021)). A hybrid CPU-GPU execution model is adopted, in which\nnumerical components are selectively assigned to either the CPU or the GPU,\ndepending on considerations of performance or convenience. This design enables\na progressive porting strategy, allowing most features of the original\nCPU-based codebase to be gradually and seamlessly adapted to GPU execution. The\nnew architecture builds upon two complementary paradigms: a classical\nobject-oriented structure for CPU execution, and a data-oriented counterpart\nfor GPUs, which reproduces the modularity of the original code while\neliminating object-oriented overhead detrimental to GPU performance. Central to\nthis approach is the use of modern C++, including standard parallel algorithms\nand template metaprogramming techniques, which permit the generation of\nhardware-agnostic computational kernels. This facilitates the development of\nuser-defined, GPU-accelerated components such as collision operators or\nboundary conditions, while preserving compatibility with the existing codebase\nand avoiding the need for external libraries or non-standard language\nextensions. The correctness and performance of the GPU-enabled Palabos are\ndemonstrated through a series of three-dimensional multiphysics benchmarks,\nincluding the laminar-turbulent transition in a Taylor-Green vortex, lid-driven\ncavity flow, and pore-scale flow in Berea sandstone. Despite the high-level\nabstraction of the implementation, the single-GPU performance is similar to\nCUDA-native solvers, and multi-GPU tests exhibit good weak and strong scaling\nacross all test cases."}
{"id": "2506.09467", "pdf": "https://arxiv.org/pdf/2506.09467", "abs": "https://arxiv.org/abs/2506.09467", "authors": ["Wu Min", "Qiao Yuncong", "Yu Tan", "Chenghu Yang"], "title": "ArcNeural: A Multi-Modal Database for the Gen-AI Era", "categories": ["cs.DB"], "comment": null, "summary": "ArcNeural introduces a novel multimodal database tailored for the demands of\nGenerative AI and Large Language Models, enabling efficient management of\ndiverse data types such as graphs, vectors, and documents. Its storage-compute\nseparated architecture integrates graph technology, advanced vector indexing,\nand transaction processing to support real-time analytics and AI-driven\napplications. Key features include a unified storage layer, adaptive edge\ncollection in MemEngine, and seamless integration of transaction and analytical\nprocessing. Experimental evaluations demonstrate ArcNeural's superior\nperformance and scalability compared to state-of-the-art systems. This system\nbridges structured and unstructured data management, offering a versatile\nsolution for enterprise-grade AI applications.\n  ArcNeural's design addresses the challenges of multimodal data processing,\nproviding a robust framework for intelligent, data-driven solutions in the Gen\nAI era."}
{"id": "2506.09596", "pdf": "https://arxiv.org/pdf/2506.09596", "abs": "https://arxiv.org/abs/2506.09596", "authors": ["Ali Ranjbar", "Elham Esmaeili", "Roghayeh Rafieisangari", "Nabiollah Shiri"], "title": "FPGA-Based Multiplier with a New Approximate Full Adder for Error-Resilient Applications", "categories": ["cs.AR"], "comment": null, "summary": "Electronic devices primarily aim to offer low power consumption, high speed,\nand a compact area. The performance of very large-scale integration (VLSI)\ndevices is influenced by arithmetic operations, where multiplication is a\ncrucial operation. Therefore, a high-speed multiplier is essential for\ndeveloping any signal-processing module. Numerous multipliers have been\nreviewed in existing literature, and their speed is largely determined by how\npartial products (PPs) are accumulated. To enhance the speed of multiplication\nbeyond current methods, an approximate adder-based multiplier is introduced.\nThis approach allows for the simultaneous addition of PPs from two consecutive\nbits using a novel approximate adder. The proposed multiplier is utilized in a\nmean filter structure and implemented in ISE Design Suite 14.7 using VHDL and\nsynthesized on the Xilinx Spartan3-XC3S400 FPGA board. Compared to the\nliterature, the proposed multiplier achieves power and power-delay product\n(PDP) improvements of 56.09% and 73.02%, respectively. The validity of the\nexpressed multiplier is demonstrated through the mean filter system. Results\nshow that it achieves power savings of 33.33%. Additionally, the proposed\nmultiplier provides more accurate results than other approximate multipliers by\nexpressing higher values of peak signal-to-noise ratio (PSNR), (30.58%), and\nstructural similarity index metric (SSIM), (22.22%), while power consumption is\nin a low range."}
{"id": "2506.09795", "pdf": "https://arxiv.org/pdf/2506.09795", "abs": "https://arxiv.org/abs/2506.09795", "authors": ["Amritha Premkumar", "Prajit T Rajendran", "Vignesh V Menon"], "title": "Learning Quality from Complexity and Structure: A Feature-Fused XGBoost Model for Video Quality Assessment", "categories": ["cs.MM"], "comment": "ICME 2025", "summary": "This paper presents a novel approach for reduced-reference video quality\nassessment (VQA), developed as part of the recent VQA Grand Challenge. Our\nmethod leverages low-level complexity and structural information from reference\nand test videos to predict perceptual quality scores. Specifically, we extract\nspatio-temporal features using Video Complexity Analyzer (VCA) and compute SSIM\nvalues from the test video to capture both texture and structural\ncharacteristics. These features are aggregated through temporal pooling, and\nresidual features are calculated by comparing the original and distorted\nfeature sets. The combined features are used to train an XGBoost regression\nmodel that estimates the overall video quality. The pipeline is fully\nautomated, interpretable, and highly scalable, requiring no deep neural\nnetworks or GPU inference. Experimental results on the challenge dataset\ndemonstrate that our proposed method achieves competitive correlation with\nsubjective quality scores while maintaining a low computational footprint. The\nmodel's lightweight design and strong generalization performance suit real-time\nstreaming quality monitoring and adaptive encoding scenarios."}
{"id": "2506.09197", "pdf": "https://arxiv.org/pdf/2506.09197", "abs": "https://arxiv.org/abs/2506.09197", "authors": ["Sushi Anna George", "Vinay Joseph"], "title": "Adaptive Bandwidth Sharing for Optimizing QoE of Real-Time Video", "categories": ["cs.NI"], "comment": "arXiv admin note: text overlap with arXiv:2401.10681", "summary": "The concept of spectrum or bandwidth sharing has gained significant global\nattention as a means to enhance the efficiency of real-time traffic management\nin wireless networks. Effective bandwidth sharing enables optimal utilization\nof available resources, reducing congestion and improving QoE for\ndelay-sensitive applications such as real-time video transmission. In this\npaper, we propose a novel iterative semi-static bandwidth sharing policy that\nbalances the advantages of both static and dynamic sharing approaches. Our\napproach minimizes the frequency of coordination between network operators\nwhile ensuring efficient resource allocation and meeting the stringent QoE\ndemands of real-time traffic. The proposed policy iteratively optimizes both\nthe spectrum sharing between operators and the resource allocation for\nindividual clients. We establish strong theoretical guarantees for the\noptimality of the proposed policy and prove that it converges to the optimal\nstatic sharing policy irrespective of initial conditions or fluctuations in\ntraffic arrival rates. Additionally, we conduct extensive simulations to\nevaluate the impact of key system parameters - including step size, hyperperiod\nlength, and arrival process dynamics - on the performance of our policy. Our\nresults demonstrate the effectiveness of the proposed approach in achieving\nnear-optimal bandwidth allocation with reduced overhead, making it a practical\nsolution for real-time wireless applications."}
{"id": "2506.09825", "pdf": "https://arxiv.org/pdf/2506.09825", "abs": "https://arxiv.org/abs/2506.09825", "authors": ["Mordechai Guri"], "title": "On the Impossibility of a Perfect Hypervisor", "categories": ["cs.OS", "cs.AR", "cs.CR"], "comment": null, "summary": "We establish a fundamental impossibility result for a `perfect hypervisor',\none that (1) preserves every observable behavior of any program exactly as on\nbare metal and (2) adds zero timing or resource overhead.\n  Within this model we prove two theorems. (1) Indetectability Theorem. If such\na hypervisor existed, no guest-level program, measurement, or timing test could\ndistinguish it from native execution; all traces, outputs, and timings would be\nidentical.\n  (2) Impossibility Theorem. Despite that theoretical indetectability, a\nperfect hypervisor cannot exist on any machine with finite computational\nresources.\n  These results are architecture-agnostic and extend beyond hypervisors to any\nvirtualization layer emulators, sandboxes, containers, or\nruntime-instrumentation frameworks. Together they provide a formal foundation\nfor future work on the principles and limits of virtualization."}
{"id": "2506.09453", "pdf": "https://arxiv.org/pdf/2506.09453", "abs": "https://arxiv.org/abs/2506.09453", "authors": ["Liron Cohen", "Ariel Grunfeld", "Dominik Kirst", "Étienne Miquey"], "title": "From Partial to Monadic: Combinatory Algebra with Effects", "categories": ["cs.LO"], "comment": null, "summary": "Partial Combinatory Algebras (PCAs) provide a foundational model of the\nuntyped $\\lambda$-calculus and serve as the basis for many notions of\ncomputability, such as realizability theory. However, PCAs support a very\nlimited notion of computation by only incorporating non-termination as a\ncomputational effect. To provide a framework that better internalizes a wide\nrange of computational effects, this paper puts forward the notion of Monadic\nCombinatory Algebras (MCAs). MCAs generalize the notion of PCAs by structuring\nthe combinatory algebra over an underlying computational effect, embodied by a\nmonad. We show that MCAs can support various side effects through the\nunderlying monad, such as non-determinism, stateful computation and\ncontinuations. We further obtain a categorical characterization of MCAs within\nFreyd Categories, following a similar connection for PCAs. Moreover, we explore\nthe application of MCAs in realizability theory, presenting constructions of\neffectful realizability triposes and assemblies derived through evidenced\nframes, thereby generalizing traditional PCA-based realizability semantics. The\nmonadic generalization of the foundational notion of PCAs provides a\ncomprehensive and powerful framework for internally reasoning about effectful\ncomputations, paving the path to a more encompassing study of computation and\nits relationship with realizability models and programming languages."}
{"id": "2506.09601", "pdf": "https://arxiv.org/pdf/2506.09601", "abs": "https://arxiv.org/abs/2506.09601", "authors": ["Sota Nakashima", "Yuta Ishimoto", "Masanari Kondo", "Tao Xiao", "Yasutaka Kamei"], "title": "ASTAGEN: Empirical Evaluation of Automated SATD Taxonomy Generation with LLMs", "categories": ["cs.SE"], "comment": null, "summary": "Technical debt refers to suboptimal code that degrades software quality. When\ndevelopers intentionally introduce such debt, it is called self-admitted\ntechnical debt (SATD). Since SATD hinders maintenance, identifying its\ncategories is key to uncovering quality issues. Traditionally, constructing\nsuch taxonomies requires manually inspecting SATD comments and surrounding\ncode, which is time-consuming, labor-intensive, and often inconsistent due to\nannotator subjectivity. This study presents ASTAGEN, an initial step toward\nautomating SATD taxonomy generation using large language models (LLMs). Given a\ncomment and its surrounding code, ASTAGEN first generates a concise explanation\nfor each SATD comment, then incrementally generates and updates categories to\nconstruct a taxonomy. We evaluate ASTAGEN on SATD datasets from three domains:\nquantum software, smart contracts, and machine learning. It successfully\nrecovers domain-specific categories reported in prior work, such as Layer\nConfiguration in machine learning. Compared to a naive use of an LLM, ASTAGEN\nproduces more consistent category assignments due to its explanation-driven,\niterative design. It also completes taxonomy generation in under two hours and\nfor less than one USD, even on the largest dataset. These results suggest that\nwhile full automation remains challenging, ASTAGEN is able to support\nsemi-automated taxonomy construction. Furthermore, our work opens up avenues\nfor future work, such as automatic taxonomy generation in other areas."}
{"id": "2506.09212", "pdf": "https://arxiv.org/pdf/2506.09212", "abs": "https://arxiv.org/abs/2506.09212", "authors": ["Lucas Joos", "Gavin J. Mooney", "Maximilian T. Fischer", "Daniel A. Keim", "Falk Schreiber", "Helen C. Purchase", "Karsten Klein"], "title": "Show Me Your Best Side: Characteristics of User-Preferred Perspectives for 3D Graph Drawings", "categories": ["cs.HC"], "comment": null, "summary": "The visual analysis of graphs in 3D has become increasingly popular,\naccelerated by the rise of immersive technology, such as augmented and virtual\nreality. Unlike 2D drawings, 3D graph layouts are highly viewpoint-dependent,\nmaking perspective selection critical for revealing structural and relational\npatterns. Despite its importance, there is limited empirical evidence guiding\nwhat constitutes an effective or preferred viewpoint from the user's\nperspective. In this paper, we present a systematic investigation into\nuser-preferred viewpoints in 3D graph visualisations. We conducted a controlled\nstudy with 23 participants in a virtual reality environment, where users\nselected their most and least preferred viewpoints for 36 different graphs\nvarying in size and layout. From this data, enriched by qualitative feedback,\nwe distil common strategies underlying viewpoint choice. We further analyse the\nalignment of user preferences with classical 2D aesthetic criteria (e.g.,\nCrossings), 3D-specific measures (e.g., Node-Node Occlusion), and introduce a\nnovel measure capturing the perceivability of a graph's principal axes\n(Isometric Viewpoint Deviation). Our data-driven analysis indicates that\nStress, Crossings, Gabriel Ratio, Edge-Node Overlap, and Isometric Viewpoint\nDeviation are key indicators of viewpoint preference. Beyond our findings, we\ncontribute a publicly available dataset consisting of the graphs and computed\naesthetic measures, supporting further research and the development of\nviewpoint evaluation measures for 3D graph drawing."}
{"id": "2506.09665", "pdf": "https://arxiv.org/pdf/2506.09665", "abs": "https://arxiv.org/abs/2506.09665", "authors": ["Jacob Munkberg", "Zian Wang", "Ruofan Liang", "Tianchang Shen", "Jon Hasselgren"], "title": "VideoMat: Extracting PBR Materials from Video Diffusion Models", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "We leverage finetuned video diffusion models, intrinsic decomposition of\nvideos, and physically-based differentiable rendering to generate high quality\nmaterials for 3D models given a text prompt or a single image. We condition a\nvideo diffusion model to respect the input geometry and lighting condition.\nThis model produces multiple views of a given 3D model with coherent material\nproperties. Secondly, we use a recent model to extract intrinsics (base color,\nroughness, metallic) from the generated video. Finally, we use the intrinsics\nalongside the generated video in a differentiable path tracer to robustly\nextract PBR materials directly compatible with common content creation tools."}
{"id": "2506.09160", "pdf": "https://arxiv.org/pdf/2506.09160", "abs": "https://arxiv.org/abs/2506.09160", "authors": ["Griffin Pitts", "Sanaz Motamedi"], "title": "Understanding Human-AI Trust in Education", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC"], "comment": null, "summary": "As AI chatbots become increasingly integrated in education, students are\nturning to these systems for guidance, feedback, and information. However, the\nanthropomorphic characteristics of these chatbots create ambiguity regarding\nwhether students develop trust toward them as they would a human peer or\ninstructor, based in interpersonal trust, or as they would any other piece of\ntechnology, based in technology trust. This ambiguity presents theoretical\nchallenges, as interpersonal trust models may inappropriately ascribe human\nintentionality and morality to AI, while technology trust models were developed\nfor non-social technologies, leaving their applicability to anthropomorphic\nsystems unclear. To address this gap, we investigate how human-like and\nsystem-like trusting beliefs comparatively influence students' perceived\nenjoyment, trusting intention, behavioral intention to use, and perceived\nusefulness of an AI chatbot - factors associated with students' engagement and\nlearning outcomes. Through partial least squares structural equation modeling,\nwe found that human-like and system-like trust significantly influenced student\nperceptions, with varied effects. Human-like trust more strongly predicted\ntrusting intention, while system-like trust better predicted behavioral\nintention and perceived usefulness. Both had similar effects on perceived\nenjoyment. Given the partial explanatory power of each type of trust, we\npropose that students develop a distinct form of trust with AI chatbots\n(human-AI trust) that differs from human-human and human-technology models of\ntrust. Our findings highlight the need for new theoretical frameworks specific\nto human-AI trust and offer practical insights for fostering appropriately\ncalibrated trust, which is critical for the effective adoption and pedagogical\nimpact of AI in education."}
{"id": "2506.09275", "pdf": "https://arxiv.org/pdf/2506.09275", "abs": "https://arxiv.org/abs/2506.09275", "authors": ["Jonas Svedas", "Hannah Watson", "Nathan Laubeuf", "Diksha Moolchandani", "Abubakr Nada", "Arjun Singh", "Dwaipayan Biswas", "James Myers", "Debjyoti Bhattacharjee"], "title": "A Survey of End-to-End Modeling for Distributed DNN Training: Workloads, Simulators, and TCO", "categories": ["cs.DC"], "comment": null, "summary": "Distributed deep neural networks (DNNs) have become a cornerstone for scaling\nmachine learning to meet the demands of increasingly complex applications.\nHowever, the rapid growth in model complexity far outpaces CMOS technology\nscaling, making sustainable and efficient system design a critical challenge.\nAddressing this requires coordinated co-design across software, hardware, and\ntechnology layers. Due to the prohibitive cost and complexity of deploying\nfull-scale training systems, simulators play a pivotal role in enabling this\ndesign exploration. This survey reviews the landscape of distributed DNN\ntraining simulators, focusing on three major dimensions: workload\nrepresentation, simulation infrastructure, and models for total cost of\nownership (TCO) including carbon emissions. It covers how workloads are\nabstracted and used in simulation, outlines common workload representation\nmethods, and includes comprehensive comparison tables covering both simulation\nframeworks and TCO/emissions models, detailing their capabilities, assumptions,\nand areas of focus. In addition to synthesizing existing tools, the survey\nhighlights emerging trends, common limitations, and open research challenges\nacross the stack. By providing a structured overview, this work supports\ninformed decision-making in the design and evaluation of distributed training\nsystems."}
{"id": "2506.09186", "pdf": "https://arxiv.org/pdf/2506.09186", "abs": "https://arxiv.org/abs/2506.09186", "authors": ["Aaron Hurst", "Andrey V. Kalinichev", "Klaus Koren", "Daniel E. Lucani"], "title": "Not all those who drift are lost: Drift correction and calibration scheduling for the IoT", "categories": ["eess.SP", "cs.DB"], "comment": null, "summary": "Sensors provide a vital source of data that link digital systems with the\nphysical world. However, as sensors age, the relationship between what they\nmeasure and what they output changes. This is known as sensor drift and poses a\nsignificant challenge that, combined with limited opportunity for\nre-calibration, can severely limit data quality over time. Previous approaches\nto drift correction typically require large volumes of ground truth data and do\nnot consider measurement or prediction uncertainty. In this paper, we propose a\nprobabilistic sensor drift correction method that takes a fundamental approach\nto modelling the sensor response using Gaussian Process Regression. Tested\nusing dissolved oxygen sensors, our method delivers mean squared error (MSE)\nreductions of up to 90% and more than 20% on average. We also propose a novel\nuncertainty-driven calibration schedule optimisation approach that builds on\ntop of drift correction and further reduces MSE by up to 15.7%."}
{"id": "2506.09198", "pdf": "https://arxiv.org/pdf/2506.09198", "abs": "https://arxiv.org/abs/2506.09198", "authors": ["Ali Rezaei", "Luc Jaulmes", "Maria Bahna", "Oliver Thomson Brown", "Antonio Barbalace"], "title": "Low-Level and NUMA-Aware Optimization for High-Performance Quantum Simulation", "categories": ["quant-ph", "cs.AR"], "comment": "12 pages, 9 figures, 2 tables, 2 pseudocodes", "summary": "Scalable classical simulation of quantum circuits is crucial for advancing\nboth quantum algorithm development and hardware validation. In this work, we\nfocus on performance enhancements through meticulous low-level tuning on a\nsingle-node system, thereby not only advancing the performance of classical\nquantum simulations but also laying the groundwork for scalable, heterogeneous\nimplementations that may eventually bridge the gap toward noiseless quantum\ncomputing. Although similar efforts in low-level tuning have been reported in\nthe literature, such implementations have not been released as open-source\nsoftware, thereby impeding independent evaluation and further development. We\nintroduce an open-source, high-performance extension to the QuEST simulator\nthat brings state-of-the-art low-level and NUMA optimizations to modern\ncomputers. Our approach emphasizes locality-aware computation and incorporates\nhardware-specific optimizations such as NUMA-aware memory allocation, thread\npinning, AVX-512 vectorization, aggressive loop unrolling, and explicit memory\nprefetching. Experiments demonstrate significant speedups - 5.5-6.5x for\nsingle-qubit gate operations, 4.5x for two-qubit gates, 4x for Random Quantum\nCircuits (RQC), and 1.8x for Quantum Fourier Transform (QFT), demonstrating\nthat rigorous performance tuning can substantially extend the practical\nsimulation capacity of classical quantum simulators on current hardware."}
{"id": "2506.09650", "pdf": "https://arxiv.org/pdf/2506.09650", "abs": "https://arxiv.org/abs/2506.09650", "authors": ["Kunyu Peng", "Junchao Huang", "Xiangsheng Huang", "Di Wen", "Junwei Zheng", "Yufan Chen", "Kailun Yang", "Jiamin Wu", "Chongqing Hao", "Rainer Stiefelhagen"], "title": "HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.RO", "eess.IV"], "comment": "The code is available at https://github.com/KPeng9510/HopaDIFF.git", "summary": "Action segmentation is a core challenge in high-level video understanding,\naiming to partition untrimmed videos into segments and assign each a label from\na predefined action set. Existing methods primarily address single-person\nactivities with fixed action sequences, overlooking multi-person scenarios. In\nthis work, we pioneer textual reference-guided human action segmentation in\nmulti-person settings, where a textual description specifies the target person\nfor segmentation. We introduce the first dataset for Referring Human Action\nSegmentation, i.e., RHAS133, built from 133 movies and annotated with 137\nfine-grained actions with 33h video data, together with textual descriptions\nfor this new task. Benchmarking existing action recognition methods on RHAS133\nusing VLM-based feature extractors reveals limited performance and poor\naggregation of visual cues for the target person. To address this, we propose a\nholistic-partial aware Fourier-conditioned diffusion framework, i.e., HopaDIFF,\nleveraging a novel cross-input gate attentional xLSTM to enhance\nholistic-partial long-range reasoning and a novel Fourier condition to\nintroduce more fine-grained control to improve the action segmentation\ngeneration. HopaDIFF achieves state-of-the-art results on RHAS133 in diverse\nevaluation settings. The code is available at\nhttps://github.com/KPeng9510/HopaDIFF.git."}
{"id": "2506.09245", "pdf": "https://arxiv.org/pdf/2506.09245", "abs": "https://arxiv.org/abs/2506.09245", "authors": ["Muthukrishnan Senthilkumar", "Aresh Dadlani", "Hina Tabassum"], "title": "Age of Information in Unreliable Tandem Queues", "categories": ["cs.NI"], "comment": null, "summary": "Stringent demands for timely information delivery, driven by the widespread\nadoption of real-time applications and the Internet of Things, have established\nthe age of information (AoI) as a critical metric for quantifying data\nfreshness. Existing AoI models often assume multi-hop communication networks\nwith fully reliable nodes, which may not accurately capture scenarios involving\nnode transmission failures. This paper presents an analytical framework for two\nconfigurations of tandem queue systems, where status updates generated by a\nsingle sensor are relayed to a destination monitor through unreliable\nintermediate nodes. Using the probability generating function, we first derive\nthe sojourn time distribution for an infinite-buffer M/M/1 tandem system with\ntwo unreliable nodes. We then extend our analysis to an M/G/1 tandem system\nwith an arbitrary number of unreliable nodes, employing the supplementary\nvariable technique while assuming that only the first node has an infinite\nbuffer. Numerical results demonstrate the impact of key system parameters on\nthe average AoI in unreliable tandem queues with Markovian and non-Markovian\nservice times."}
{"id": "2506.09455", "pdf": "https://arxiv.org/pdf/2506.09455", "abs": "https://arxiv.org/abs/2506.09455", "authors": ["Yizhak Yisrael Elboher", "Omri Isac", "Guy Katz", "Tobias Ladner", "Haoze Wu"], "title": "Abstraction-Based Proof Production in Formal Verification of Neural Networks", "categories": ["cs.LO", "cs.AI"], "comment": "To appear in SAIV 2025", "summary": "Modern verification tools for deep neural networks (DNNs) increasingly rely\non abstraction to scale to realistic architectures. In parallel, proof\nproduction is becoming a critical requirement for increasing the reliability of\nDNN verification results. However, current proofproducing verifiers do not\nsupport abstraction-based reasoning, creating a gap between scalability and\nprovable guarantees. We address this gap by introducing a novel framework for\nproof-producing abstraction-based DNN verification. Our approach modularly\nseparates the verification task into two components: (i) proving the\ncorrectness of an abstract network, and (ii) proving the soundness of the\nabstraction with respect to the original DNN. The former can be handled by\nexisting proof-producing verifiers, whereas we propose the first method for\ngenerating formal proofs for the latter. This preliminary work aims to enable\nscalable and trustworthy verification by supporting common abstraction\ntechniques within a formal proof framework."}
{"id": "2506.09636", "pdf": "https://arxiv.org/pdf/2506.09636", "abs": "https://arxiv.org/abs/2506.09636", "authors": ["Joe Hare", "Leo Freitas", "Ken Pierce"], "title": "Translating a VDM Model of a Medical Device into Kapture", "categories": ["cs.SE"], "comment": "Presented at the 23rd Overture workshop, June 2025\n  (arXiv:cs/2506.08680)", "summary": "As the complexity of safety-critical medical devices increases, so does the\nneed for clear, verifiable, software requirements. This paper explores the use\nof Kapture, a formal modelling tool developed by D-RisQ, to translate an\nexisting formal VDM model of a medical implant for treating focal epilepsy\ncalled CANDO. The work was undertaken without prior experience in formal\nmethods. The paper assess Kapture's usability, the challenges of formal\nmodelling, and the effectiveness of the translated model. The result is a model\nin Kapture which covers over 90% of the original VDM model, and produces\nmatching traces of results. While several issues were encountered during design\nand implementation, mainly due to the initial learning curve, this paper\ndemonstrates that complex systems can be effectively modelled in Kapture by\ninexperienced users and highlights some difficulties in translating VDM\nspecifications to Kapture."}
{"id": "2506.09216", "pdf": "https://arxiv.org/pdf/2506.09216", "abs": "https://arxiv.org/abs/2506.09216", "authors": ["Qing", "Xia", "Advait Sarkar", "Duncan Brumby", "Anna Cox"], "title": "\"How do you even know that stuff?\": Barriers to expertise sharing among spreadsheet users", "categories": ["cs.HC", "cs.CY", "H.5"], "comment": "Accepted at CSCW 2025", "summary": "Spreadsheet collaboration provides valuable opportunities for learning and\nexpertise sharing between colleagues. Sharing expertise is essential for the\nretention of important technical skillsets within organisations, but previous\nstudies suggest that spreadsheet experts often fail to disseminate their\nknowledge to others. We suggest that social norms and beliefs surrounding the\nvalue of spreadsheet use significantly influence user engagement in sharing\nbehaviours. To explore this, we conducted 31 semi-structured interviews with\nprofessional spreadsheet users from two separate samples. We found that\nspreadsheet providers face challenges in adapting highly personalised\nstrategies to often subjective standards and evaluating the appropriate social\ntiming of sharing. In addition, conflicted self-evaluations of one's\nspreadsheet expertise, dismissive normative beliefs about the value of this\nknowledge, and concerns about the potential disruptions associated with\ncollaboration can further deter sharing. We suggest these observations reflect\nthe challenges of long-term learning in feature-rich software designed\nprimarily with initial learnability in mind. We therefore provide implications\nfor design to navigate this tension. Overall, our findings demonstrate how the\ncomplex interaction between technology design and social dynamics can shape\ncollaborative learning behaviours in the context of feature-rich software."}
{"id": "2506.09909", "pdf": "https://arxiv.org/pdf/2506.09909", "abs": "https://arxiv.org/abs/2506.09909", "authors": ["Yijie Deng", "Lei Han", "Lu Fang"], "title": "TransGI: Real-Time Dynamic Global Illumination With Object-Centric Neural Transfer Model", "categories": ["cs.GR"], "comment": null, "summary": "Neural rendering algorithms have revolutionized computer graphics, yet their\nimpact on real-time rendering under arbitrary lighting conditions remains\nlimited due to strict latency constraints in practical applications. The key\nchallenge lies in formulating a compact yet expressive material representation.\nTo address this, we propose TransGI, a novel neural rendering method for\nreal-time, high-fidelity global illumination. It comprises an object-centric\nneural transfer model for material representation and a radiance-sharing\nlighting system for efficient illumination. Traditional BSDF representations\nand spatial neural material representations lack expressiveness, requiring\nthousands of ray evaluations to converge to noise-free colors. Conversely,\nreal-time methods trade quality for efficiency by supporting only diffuse\nmaterials. In contrast, our object-centric neural transfer model achieves\ncompactness and expressiveness through an MLP-based decoder and vertex-attached\nlatent features, supporting glossy effects with low memory overhead. For\ndynamic, varying lighting conditions, we introduce local light probes capturing\nscene radiance, coupled with an across-probe radiance-sharing strategy for\nefficient probe generation. We implemented our method in a real-time rendering\nengine, combining compute shaders and CUDA-based neural networks. Experimental\nresults demonstrate that our method achieves real-time performance of less than\n10 ms to render a frame and significantly improved rendering quality compared\nto baseline methods."}
{"id": "2506.09182", "pdf": "https://arxiv.org/pdf/2506.09182", "abs": "https://arxiv.org/abs/2506.09182", "authors": ["Hang Zhou", "Chengyuan Ma", "Shiyu Shen", "Xiaopeng Li"], "title": "Towards Full-Scenario Safety Evaluation of Automated Vehicles: A Volume-Based Method", "categories": ["cs.RO", "cs.ET"], "comment": "NA", "summary": "With the rapid development of automated vehicles (AVs) in recent years,\ncommercially available AVs are increasingly demonstrating high-level automation\ncapabilities. However, most existing AV safety evaluation methods are primarily\ndesigned for simple maneuvers such as car-following and lane-changing. While\nsuitable for basic tests, these methods are insufficient for assessing\nhigh-level automation functions deployed in more complex environments. First,\nthese methods typically use crash rate as the evaluation metric, whose accuracy\nheavily depends on the quality and completeness of naturalistic driving\nenvironment data used to estimate scenario probabilities. Such data is often\ndifficult and expensive to collect. Second, when applied to diverse scenarios,\nthese methods suffer from the curse of dimensionality, making large-scale\nevaluation computationally intractable. To address these challenges, this paper\nproposes a novel framework for full-scenario AV safety evaluation. A unified\nmodel is first introduced to standardize the representation of diverse driving\nscenarios. This modeling approach constrains the dimension of most scenarios to\na regular highway setting with three lanes and six surrounding background\nvehicles, significantly reducing dimensionality. To further avoid the\nlimitations of probability-based method, we propose a volume-based evaluation\nmethod that quantifies the proportion of risky scenarios within the entire\nscenario space. For car-following scenarios, we prove that the set of safe\nscenarios is convex under specific settings, enabling exact volume computation.\nExperimental results validate the effectiveness of the proposed volume-based\nmethod using both AV behavior models from existing literature and six\nproduction AV models calibrated from field-test trajectory data in the Ultra-AV\ndataset. Code and data will be made publicly available upon acceptance of this\npaper."}
{"id": "2506.09280", "pdf": "https://arxiv.org/pdf/2506.09280", "abs": "https://arxiv.org/abs/2506.09280", "authors": ["Haitian Jiang", "Shaowei Zhu", "Zhen Zhang", "Zhenyu Song", "Xinwei Fu", "Zhen Jia", "Yida Wang", "Jinyang Li"], "title": "TTrace: Lightweight Error Checking and Diagnosis for Distributed Training", "categories": ["cs.DC", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Distributed training is essential for scaling the training of large neural\nnetwork models, such as large language models (LLMs), across thousands of GPUs.\nHowever, the complexity of distributed training programs makes them\nparticularly prone to silent bugs, which do not produce explicit error signal\nbut lead to incorrect training outcome. Effectively detecting and localizing\nsuch silent bugs in distributed training is challenging. Common debugging\npractice using metrics like training loss or gradient norm curves can be\ninefficient and ineffective. Additionally, obtaining intermediate tensor values\nand determining whether they are correct during silent bug localization is\ndifficult, particularly in the context of low-precision training.\n  To address those challenges, we design and implement TTrace, the first system\ncapable of detecting and localizing silent bugs in distributed training. TTrace\ncollects intermediate tensors from distributing training in a fine-grained\nmanner and compares them against those from a trusted single-device reference\nimplementation. To properly compare the floating-point values in the tensors,\nwe propose novel mathematical analysis that provides a guideline for setting\nthresholds, enabling TTrace to distinguish bug-induced errors from\nfloating-point round-off errors. Experimental results demonstrate that TTrace\neffectively detects 11 existing bugs and 3 new bugs in the widely used\nMegatron-LM framework, while requiring fewer than 10 lines of code change.\nTTrace is effective in various training recipes, including low-precision\nrecipes involving BF16 and FP8."}
{"id": "2506.09530", "pdf": "https://arxiv.org/pdf/2506.09530", "abs": "https://arxiv.org/abs/2506.09530", "authors": ["Fakhri Momeni", "Janete Saldanha Bach", "Brigitte Mathiak", "Peter Mutschke"], "title": "Linking Data Citation to Repository Visibility: An Empirical Study", "categories": ["cs.DL", "cs.DB"], "comment": null, "summary": "In today's data-driven research landscape, dataset visibility and\naccessibility play a crucial role in advancing scientific knowledge. At the\nsame time, data citation is essential for maintaining academic integrity,\nacknowledging contributions, validating research outcomes, and fostering\nscientific reproducibility. As a critical link, it connects scholarly\npublications with the datasets that drive scientific progress. This study\ninvestigates whether repository visibility influences data citation rates. We\nhypothesize that repositories with higher visibility, as measured by search\nengine metrics, are associated with increased dataset citations. Using OpenAlex\ndata and repository impact indicators (including the visibility index from\nSistrix, the h-index of repositories, and citation metrics such as mean and\nmedian citations), we analyze datasets in Social Sciences and Economics to\nexplore their relationship. Our findings suggest that datasets hosted on more\nvisible web domains tend to receive more citations, with a positive correlation\nobserved between web domain visibility and dataset citation counts,\nparticularly for datasets with at least one citation. However, when analyzing\ndomain-level citation metrics, such as the h-index, mean, and median citations,\nthe correlations are inconsistent and weaker. While higher visibility domains\ntend to host datasets with greater citation impact, the distribution of\ncitations across datasets varies significantly. These results suggest that\nwhile visibility plays a role in increasing citation counts, it is not the sole\nfactor influencing dataset citation impact. Other elements, such as dataset\nquality, research trends, and disciplinary norms, also contribute significantly\nto citation patterns."}
{"id": "2506.09464", "pdf": "https://arxiv.org/pdf/2506.09464", "abs": "https://arxiv.org/abs/2506.09464", "authors": ["Ruby Kumari", "Gaurav Purohit", "Abhijit Karmakar"], "title": "Efficient Modular Multiplier over GF (2^m) for ECPM", "categories": ["cs.CR", "cs.AR"], "comment": null, "summary": "Elliptic curve cryptography (ECC) has emerged as the dominant public-key\nprotocol, with NIST standardizing parameters for binary field GF(2^m) ECC\nsystems. This work presents a hardware implementation of a Hybrid\nMultiplication technique for modular multiplication over binary field GF(2m),\ntargeting NIST B-163, 233, 283, and 571 parameters. The design optimizes the\ncombination of conventional multiplication (CM) and Karatsuba multiplication\n(KM) to enhance elliptic curve point multiplication (ECPM). The key innovation\nuses CM for smaller operands (up to 41 bits for m=163) and KM for larger ones,\nreducing computational complexity and enhancing efficiency. The design is\nevaluated in three areas: Resource Utilization For m=163, the hybrid design\nuses 6,812 LUTs, a 39.82% reduction compared to conventional methods. For\nm=233, LUT usage reduces by 45.53% and 70.70% compared to overlap-free and\nbit-parallel implementations. Delay Performance For m=163, achieves 13.31ns\ndelay, improving by 37.60% over bit-parallel implementations. For m=233,\nmaintains 13.39ns delay. Area-Delay Product For m=163, achieves ADP of 90,860,\noutperforming bit-parallel (75,337) and digit-serial (43,179) implementations.\nFor m=233, demonstrates 16.86% improvement over overlap-free and 96.10% over\nbit-parallel designs. Results show the hybrid technique significantly improves\nspeed, hardware efficiency, and resource utilization for ECC cryptographic\nsystems."}
{"id": "2506.09792", "pdf": "https://arxiv.org/pdf/2506.09792", "abs": "https://arxiv.org/abs/2506.09792", "authors": ["Wenxuan Wu", "Shuai Wang", "Xixin Wu", "Helen Meng", "Haizhou Li"], "title": "Incorporating Linguistic Constraints from External Knowledge Source for Audio-Visual Target Speech Extraction", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "Audio-visual target speaker extraction (AV-TSE) models primarily rely on\ntarget visual cues to isolate the target speaker's voice from others. We know\nthat humans leverage linguistic knowledge, such as syntax and semantics, to\nsupport speech perception. Inspired by this, we explore the potential of\npre-trained speech-language models (PSLMs) and pre-trained language models\n(PLMs) as auxiliary knowledge sources for AV-TSE. In this study, we propose\nincorporating the linguistic constraints from PSLMs or PLMs for the AV-TSE\nmodel as additional supervision signals. Without introducing any extra\ncomputational cost during inference, the proposed approach consistently\nimproves speech quality and intelligibility. Furthermore, we evaluate our\nmethod in multi-language settings and visual cue-impaired scenarios and show\nrobust performance gains."}
{"id": "2506.09268", "pdf": "https://arxiv.org/pdf/2506.09268", "abs": "https://arxiv.org/abs/2506.09268", "authors": ["Henri Alam", "Antonio de Domenico", "Tareq Si Salem", "Florian Kaltenberger"], "title": "A Multi-Armed Bandit Framework for Online Optimisation in Green Integrated Terrestrial and Non-Terrestrial Networks", "categories": ["cs.NI", "cs.AI"], "comment": "To be published in 2025 IEEE International Workshop on Signal\n  Processing and Artificial Intelligence in Wireless Communications (IEEE SPAWC\n  2025)", "summary": "Integrated terrestrial and non-terrestrial network (TN-NTN) architectures\noffer a promising solution for expanding coverage and improving capacity for\nthe network. While non-terrestrial networks (NTNs) are primarily exploited for\nthese specific reasons, their role in alleviating terrestrial network (TN) load\nand enabling energy-efficient operation has received comparatively less\nattention. In light of growing concerns associated with the densification of\nterrestrial deployments, this work aims to explore the potential of NTNs in\nsupporting a more sustainable network. In this paper, we propose a novel online\noptimisation framework for integrated TN-NTN architectures, built on a\nmulti-armed bandit (MAB) formulation and leveraging the Bandit-feedback\nConstrained Online Mirror Descent (BCOMD) algorithm. Our approach adaptively\noptimises key system parameters--including bandwidth allocation, user equipment\n(UE) association, and macro base station (MBS) shutdown--to balance network\ncapacity and energy efficiency in real time. Extensive system-level simulations\nover a 24-hour period show that our framework significantly reduces the\nproportion of unsatisfied UEs during peak hours and achieves up to 19%\nthroughput gains and 5% energy savings in low-traffic periods, outperforming\nstandard network settings following 3GPP recommendations."}
{"id": "2506.09458", "pdf": "https://arxiv.org/pdf/2506.09458", "abs": "https://arxiv.org/abs/2506.09458", "authors": ["Liron Cohen", "Ariel Grunfeld", "Dominik Kirst", "Étienne Miquey"], "title": "Syntactic Effectful Realizability in Higher-Order Logic", "categories": ["cs.LO"], "comment": null, "summary": "Realizability interprets propositions as specifications for computational\nentities in programming languages. Specifically, syntactic realizability is a\npowerful machinery that handles realizability as a syntactic translation of\npropositions into new propositions that describe what it means to realize the\ninput proposition. This paper introduces EffHOL (Effectful Higher-Order Logic),\na novel framework that expands syntactic realizability to uniformly support\nmodern programming paradigms with side effects. EffHOL combines higher-kinded\npolymorphism, enabling typing of realizers for higher-order propositions, with\na computational term language that uses monads to represent and reason about\neffectful computations. We craft a syntactic realizability translation from\n(intuitionistic) higher-order logic (HOL) to EffHOL, ensuring the extraction of\ncomputable realizers through a constructive soundness proof. EffHOL's\nparameterization by monads allows for the synthesis of effectful realizers for\npropositions unprovable in pure HOL, bridging the gap between traditional and\neffectful computational paradigms. Examples, including continuations and\nmemoization, showcase EffHOL's capability to unify diverse computational\nmodels, with traditional ones as special cases. For a semantic connection, we\nshow that any instance of EffHOL induces an evidenced frame, which, in turn,\nyields a tripos and a realizability topos."}
{"id": "2506.09683", "pdf": "https://arxiv.org/pdf/2506.09683", "abs": "https://arxiv.org/abs/2506.09683", "authors": ["Priyavanshi Pathania", "Nikhil Bamby", "Rohit Mehra", "Samarth Sikand", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Calculating Software's Energy Use and Carbon Emissions: A Survey of the State of Art, Challenges, and the Way Ahead", "categories": ["cs.SE", "cs.CY"], "comment": "8 pages. To be published in the proceedings of 9th International\n  Workshop on Green and Sustainable Software (GREENS '25), April 29, 2025,\n  Ottawa, Canada (Co-located with ICSE 2025)", "summary": "The proliferation of software and AI comes with a hidden risk: its growing\nenergy and carbon footprint. As concerns regarding environmental sustainability\ncome to the forefront, understanding and optimizing how software impacts the\nenvironment becomes paramount. In this paper, we present a state-of-the-art\nreview of methods and tools that enable the measurement of software and\nAI-related energy and/or carbon emissions. We introduce a taxonomy to\ncategorize the existing work as Monitoring, Estimation, or Black-Box\napproaches. We delve deeper into the tools and compare them across different\ndimensions and granularity - for example, whether their measurement encompasses\nenergy and carbon emissions and the components considered (like CPU, GPU, RAM,\netc.). We present our observations on the practical use (component wise\nconsolidation of approaches) as well as the challenges that we have identified\nacross the current state-of-the-art. As we start an initiative to address these\nchallenges, we emphasize active collaboration across the community in this\nimportant field."}
{"id": "2506.09220", "pdf": "https://arxiv.org/pdf/2506.09220", "abs": "https://arxiv.org/abs/2506.09220", "authors": ["Karen Joy", "Tawfiq Ammari", "Alyssa Sheehan"], "title": "Beyond the Hype: Mapping Uncertainty and Gratification in AI Assistant Use", "categories": ["cs.HC"], "comment": null, "summary": "This paper examines the gap between the promises and real-world performance\nof emerging AI personal assistants. Drawing on interviews with early adopters\nof devices like Rabbit R1 and Humane AI Pin, as well as services like Ohai and\nDocus, we map user experiences through the lens of Uses and Gratifications and\nUncertainty Reduction Theory. We identify three core types of user uncertainty,\nfunctional, interactional, and social, and explore how each disrupts different\nuser gratifications. We show that while marketing hype fuels initial adoption,\nunmet expectations often result in frustration or abandonment. Our findings\nhighlight the importance of transparency, task-specific design, and user\ncontrol over contextual memory and personalization. We provide design and\npolicy recommendations, including user-facing explainability tools and calls\nfor regulatory benchmarks such as CI Bench, to guide ethical and interpretable\nAI integration. Our study offers actionable insights for creating more usable,\ntrustworthy, and socially aligned AI assistants."}
{"id": "2506.09997", "pdf": "https://arxiv.org/pdf/2506.09997", "abs": "https://arxiv.org/abs/2506.09997", "authors": ["Chieh Hubert Lin", "Zhaoyang Lv", "Songyin Wu", "Zhen Xu", "Thu Nguyen-Phuoc", "Hung-Yu Tseng", "Julian Straub", "Numair Khan", "Lei Xiao", "Ming-Hsuan Yang", "Yuheng Ren", "Richard Newcombe", "Zhao Dong", "Zhengqin Li"], "title": "DGS-LRM: Real-Time Deformable 3D Gaussian Reconstruction From Monocular Videos", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Project page: https://hubert0527.github.io/dgslrm/", "summary": "We introduce the Deformable Gaussian Splats Large Reconstruction Model\n(DGS-LRM), the first feed-forward method predicting deformable 3D Gaussian\nsplats from a monocular posed video of any dynamic scene. Feed-forward scene\nreconstruction has gained significant attention for its ability to rapidly\ncreate digital replicas of real-world environments. However, most existing\nmodels are limited to static scenes and fail to reconstruct the motion of\nmoving objects. Developing a feed-forward model for dynamic scene\nreconstruction poses significant challenges, including the scarcity of training\ndata and the need for appropriate 3D representations and training paradigms. To\naddress these challenges, we introduce several key technical contributions: an\nenhanced large-scale synthetic dataset with ground-truth multi-view videos and\ndense 3D scene flow supervision; a per-pixel deformable 3D Gaussian\nrepresentation that is easy to learn, supports high-quality dynamic view\nsynthesis, and enables long-range 3D tracking; and a large transformer network\nthat achieves real-time, generalizable dynamic scene reconstruction. Extensive\nqualitative and quantitative experiments demonstrate that DGS-LRM achieves\ndynamic scene reconstruction quality comparable to optimization-based methods,\nwhile significantly outperforming the state-of-the-art predictive dynamic\nreconstruction method on real-world examples. Its predicted physically grounded\n3D deformation is accurate and can readily adapt for long-range 3D tracking\ntasks, achieving performance on par with state-of-the-art monocular video 3D\ntracking methods."}
{"id": "2506.09505", "pdf": "https://arxiv.org/pdf/2506.09505", "abs": "https://arxiv.org/abs/2506.09505", "authors": ["Dumitrel Loghin", "Shuang Liang", "Shengwei Liu", "Xiong Liu", "Pingcheng Ruan", "Zhigang Ye"], "title": "On the Performance of Cloud-based ARM SVE for Zero-Knowledge Proving Systems", "categories": ["cs.DC", "cs.ET", "cs.PF"], "comment": null, "summary": "Zero-knowledge proofs (ZKP) are becoming a gold standard in scaling\nblockchains and bringing Web3 to life. At the same time, ZKP for transactions\nrunning on the Ethereum Virtual Machine require powerful servers with hundreds\nof CPU cores. The current zkProver implementation from Polygon is optimized for\nx86-64 CPUs by vectorizing key operations, such as Merkle tree building with\nPoseidon hashes over the Goldilocks field, with Advanced Vector Extensions (AVX\nand AVX512). With these optimizations, a ZKP for a batch of transactions is\ngenerated in less than two minutes. With the advent of cloud servers with ARM\nwhich are at least 10% cheaper than x86-64 servers and the implementation of\nARM Scalable Vector Extension (SVE), we wonder if ARM servers can take over\ntheir x86-64 counterparts. Unfortunately, our analysis shows that current ARM\nCPUs are not a match for their x86-64 competitors. Graviton4 from Amazon Web\nServices (AWS) and Axion from Google Cloud Platform (GCP) are 1.6X and 1.4X\nslower compared to the latest AMD EPYC and Intel Xeon servers from AWS with AVX\nand AVX512, respectively, when building a Merkle tree with over four million\nleaves. This low performance is due to (1) smaller vector size in these ARM\nCPUs (128 bits versus 512 bits in AVX512) and (2) lower clock frequency. On the\nother hand, ARM SVE/SVE2 Instruction Set Architecture (ISA) is at least as\npowerful as AVX/AVX512 but more flexible. Moreover, we estimate that increasing\nthe vector size to 512 bits will enable higher performance in ARM CPUs compared\nto their x86-64 counterparts while maintaining their price advantage."}
{"id": "2506.09282", "pdf": "https://arxiv.org/pdf/2506.09282", "abs": "https://arxiv.org/abs/2506.09282", "authors": ["Dhruv Parikh", "Viktor Prasanna"], "title": "ScalableHD: Scalable and High-Throughput Hyperdimensional Computing Inference on Multi-Core CPUs", "categories": ["cs.DC", "cs.LG"], "comment": "IC3", "summary": "Hyperdimensional Computing (HDC) is a brain-inspired computing paradigm that\nrepresents and manipulates information using high-dimensional vectors, called\nhypervectors (HV). Traditional HDC methods, while robust to noise and\ninherently parallel, rely on single-pass, non-parametric training and often\nsuffer from low accuracy. To address this, recent approaches adopt iterative\ntraining of base and class HVs, typically accelerated on GPUs. Inference,\nhowever, remains lightweight and well-suited for real-time execution. Yet,\nefficient HDC inference has been studied almost exclusively on specialized\nhardware such as FPGAs and GPUs, with limited attention to general-purpose\nmulti-core CPUs. To address this gap, we propose ScalableHD for scalable and\nhigh-throughput HDC inference on multi-core CPUs. ScalableHD employs a\ntwo-stage pipelined execution model, where each stage is parallelized across\ncores and processes chunks of base and class HVs. Intermediate results are\nstreamed between stages using a producer-consumer mechanism, enabling\non-the-fly consumption and improving cache locality. To maximize performance,\nScalableHD integrates memory tiling and NUMA-aware worker-to-core binding.\nFurther, it features two execution variants tailored for small and large batch\nsizes, each designed to exploit compute parallelism based on workload\ncharacteristics while mitigating the memory-bound compute pattern that limits\nHDC inference performance on modern multi-core CPUs. ScalableHD achieves up to\n10x speedup in throughput (samples per second) over state-of-the-art baselines\nsuch as TorchHD, across a diverse set of tasks ranging from human activity\nrecognition to image classification, while preserving task accuracy.\nFurthermore, ScalableHD exhibits robust scalability: increasing the number of\ncores yields near-proportional throughput improvements."}
{"id": "2506.09938", "pdf": "https://arxiv.org/pdf/2506.09938", "abs": "https://arxiv.org/abs/2506.09938", "authors": ["Aaditaa Vashisht", "Rekha B S"], "title": "Microservices and Real-Time Processing in Retail IT: A Review of Open-Source Toolchains and Deployment Strategies", "categories": ["cs.SE", "cs.DB"], "comment": null, "summary": "With the rapid pace of digital transformation, the retail industry is\nincreasingly depending on real-time, scalable, and resilient systems to manage\nfinancial transactions, analyze customer behavior, and streamline order\nprocessing. This literature review explores how modern event-driven and\nmicroservices-based architectures, particularly those leveraging Apache Kafka,\nSpring Boot, MongoDB, and Kubernetes are transforming retail and financial\nsystems. By systematically reviewing academic publications, technical white\npapers, and industry reports from recent years, this study synthesizes key\nthemes and implementation strategies. The analysis reveals that technologies\nlike Kafka and Spring Boot are instrumental in building low-latency,\nevent-driven applications that support real-time analytics and fraud detection,\nwhile MongoDB, when deployed on Kubernetes, ensures fault tolerance and high\navailability in inventory and transaction systems. Kubernetes itself plays a\ncrucial role in automating deployment and scaling of microservices. These\nfindings provide valuable insights for industry practitioners aiming to design\nscalable infrastructures, identify research opportunities in hybrid deployment\nmodels, and offer educators a foundation to integrate modern system\narchitectures into professional and technical communication training."}
{"id": "2506.09758", "pdf": "https://arxiv.org/pdf/2506.09758", "abs": "https://arxiv.org/abs/2506.09758", "authors": ["Zikai Liu", "Jasmin Schult", "Pengcheng Xu", "Timothy Roscoe"], "title": "Mainframe-style channel controllers for modern disaggregated memory systems", "categories": ["cs.OS", "cs.AR", "cs.ET"], "comment": null, "summary": "Despite the promise of alleviating the main memory bottleneck, and the\nexistence of commercial hardware implementations, techniques for Near-Data\nProcessing have seen relatively little real-world deployment. The idea has\nreceived renewed interest with the appearance of disaggregated or \"far\" memory,\nfor example in the use of CXL memory pools.\n  However, we argue that the lack of a clear OS-centric abstraction of\nNear-Data Processing is a major barrier to adoption of the technology. Inspired\nby the channel controllers which interface the CPU to disk drives in mainframe\nsystems, we propose memory channel controllers as a convenient, portable, and\nvirtualizable abstraction of Near-Data Processing for modern disaggregated\nmemory systems.\n  In addition to providing a clean abstraction that enables OS integration\nwhile requiring no changes to CPU architecture, memory channel controllers\nincorporate another key innovation: they exploit the cache coherence provided\nby emerging interconnects to provide a much richer programming model, with more\nfine-grained interaction, than has been possible with existing designs."}
{"id": "2506.09647", "pdf": "https://arxiv.org/pdf/2506.09647", "abs": "https://arxiv.org/abs/2506.09647", "authors": ["Lei Deng", "Wenhan Xu", "Jingwei Li", "Danny H. K. Tsang"], "title": "Real-Time Network Traffic Forecasting with Missing Data: A Generative Model Approach", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "Real-time network traffic forecasting is crucial for network management and\nearly resource allocation. Existing network traffic forecasting approaches\noperate under the assumption that the network traffic data is fully observed.\nHowever, in practical scenarios, the collected data are often incomplete due to\nvarious human and natural factors. In this paper, we propose a generative model\napproach for real-time network traffic forecasting with missing data. Firstly,\nwe model the network traffic forecasting task as a tensor completion problem.\nSecondly, we incorporate a pre-trained generative model to achieve the low-rank\nstructure commonly associated with tensor completion. The generative model\neffectively captures the intrinsic low-rank structure of network traffic data\nduring pre-training and enables the mapping from a compact latent\nrepresentation to the tensor space. Thirdly, rather than directly optimizing\nthe high-dimensional tensor, we optimize its latent representation, which\nsimplifies the optimization process and enables real-time forecasting. We also\nestablish a theoretical recovery guarantee that quantifies the error bound of\nthe proposed approach. Experiments on real-world datasets demonstrate that our\napproach achieves accurate network traffic forecasting within 100 ms, with a\nmean absolute error (MAE) below 0.002, as validated on the Abilene dataset."}
{"id": "2506.09545", "pdf": "https://arxiv.org/pdf/2506.09545", "abs": "https://arxiv.org/abs/2506.09545", "authors": ["Kinnari Dave", "Alejandro Díaz-Caro", "Vladimir Zamdzhiev"], "title": "IMALL with a Mixed-State Modality: A Logical Approach to Quantum Computation", "categories": ["cs.LO"], "comment": null, "summary": "We introduce a proof language for Intuitionistic Multiplicative Additive\nLinear Logic (IMALL), extended with a modality B to capture mixed-state quantum\ncomputation. The language supports algebraic constructs such as linear\ncombinations, and embeds pure quantum computations within a mixed-state\nframework via B, interpreted categorically as a functor from a category of\nHilbert Spaces to a category of finite-dimensional C*-algebras. Measurement\narises as a definable term, not as a constant, and the system avoids the use of\nquantum configurations, which are part of the theory of the quantum lambda\ncalculus. Cut-elimination is defined via a composite reduction relation, and\nshown to be sound with respect to the denotational interpretation. We prove n\nthat any linear map on C 2 can be represented within the system, and illustrate\nthis expressiveness with examples such as quantum teleportation and the quantum\nswitch."}
{"id": "2506.09702", "pdf": "https://arxiv.org/pdf/2506.09702", "abs": "https://arxiv.org/abs/2506.09702", "authors": ["Huu Hung Nguyen", "Duc Manh Tran", "Yiran Cheng", "Thanh Le-Cong", "Hong Jin Kang", "Ratnadira Widyasari", "Shar Lwin Khin", "Ouh Eng Lieh", "Ting Zhang", "David Lo"], "title": "Mapping NVD Records to Their VFCs: How Hard is it?", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Mapping National Vulnerability Database (NVD) records to vulnerability-fixing\ncommits (VFCs) is crucial for vulnerability analysis but challenging due to\nsparse explicit links in NVD references.This study explores this mapping's\nfeasibility through an empirical approach. Manual analysis of NVD references\nshowed Git references enable over 86% success, while non-Git references achieve\nunder 14%. Using these findings, we built an automated pipeline extracting\n31,942 VFCs from 20,360 NVD records (8.7% of 235,341) with 87% precision,\nmainly from Git references. To fill gaps, we mined six external security\ndatabases, yielding 29,254 VFCs for 18,985 records (8.1%) at 88.4% precision,\nand GitHub repositories, adding 3,686 VFCs for 2,795 records (1.2%) at 73%\nprecision. Combining these, we mapped 26,710 unique records (11.3% coverage)\nfrom 7,634 projects, with overlap between NVD and external databases, plus\nunique GitHub contributions. Despite success with Git references, 88.7% of\nrecords remain unmapped, highlighting the difficulty without Git links. This\nstudy offers insights for enhancing vulnerability datasets and guiding future\nautomated security research."}
{"id": "2506.09236", "pdf": "https://arxiv.org/pdf/2506.09236", "abs": "https://arxiv.org/abs/2506.09236", "authors": ["Erin Argo", "Tanim Ahmed", "Sarah Gable", "Callie Hampton", "Jeronimo Grandi", "Regis Kopper"], "title": "Augmented Reality User Interfaces for First Responders: A Scoping Literature Review", "categories": ["cs.HC"], "comment": "19 pages, 4 figures, 8 tables", "summary": "During the past decade, there has been a significant increase in research\nfocused on integrating AR User Interfaces into public safety applications,\nparticularly for first responders in the domains of Emergency Medical Services,\nFirefighting, and Law Enforcement. This paper presents the results of a scoping\nreview involving the application of AR user interfaces in the public safety\ndomain and applies an established systematic review methodology to provide a\ncomprehensive analysis of the current research landscape, identifying key\ntrends, challenges, and gaps in the literature. This review includes\npeer-reviewed publications indexed by the major scientific databases up to\nApril 2025. A basic keyword search retrieved 1,751 papers, of which 90 were\ndeemed relevant for this review. An in-depth analysis of the literature allowed\nthe development of a faceted taxonomy that categorizes AR user interfaces for\npublic safety. This classification lays a solid foundation for future research,\nwhile also highlighting key design considerations, challenges, and gaps in the\nliterature. This review serves as a valuable resource for researchers and\ndevelopers, offering insights that can drive further advances in the field."}
{"id": "2506.09485", "pdf": "https://arxiv.org/pdf/2506.09485", "abs": "https://arxiv.org/abs/2506.09485", "authors": ["Yuxin Liu", "Zhenghao Peng", "Xuanhao Cui", "Bolei Zhou"], "title": "Adv-BMT: Bidirectional Motion Transformer for Safety-Critical Traffic Scenario Generation", "categories": ["cs.RO", "cs.AI", "cs.GR"], "comment": null, "summary": "Scenario-based testing is essential for validating the performance of\nautonomous driving (AD) systems. However, such testing is limited by the\nscarcity of long-tailed, safety-critical scenarios in existing datasets\ncollected in the real world. To tackle the data issue, we propose the Adv-BMT\nframework, which augments real-world scenarios with diverse and realistic\nadversarial interactions. The core component of Adv-BMT is a bidirectional\nmotion transformer (BMT) model to perform inverse traffic motion predictions,\nwhich takes agent information in the last time step of the scenario as input,\nand reconstruct the traffic in the inverse of chronological order until the\ninitial time step. The Adv-BMT framework is a two-staged pipeline: it first\nconducts adversarial initializations and then inverse motion predictions.\nDifferent from previous work, we do not need any collision data for\npretraining, and are able to generate realistic and diverse collision\ninteractions. Our experimental results validate the quality of generated\ncollision scenarios by Adv-BMT: training in our augmented dataset would reduce\nepisode collision rates by 20\\% compared to previous work."}
{"id": "2506.09758", "pdf": "https://arxiv.org/pdf/2506.09758", "abs": "https://arxiv.org/abs/2506.09758", "authors": ["Zikai Liu", "Jasmin Schult", "Pengcheng Xu", "Timothy Roscoe"], "title": "Mainframe-style channel controllers for modern disaggregated memory systems", "categories": ["cs.OS", "cs.AR", "cs.ET"], "comment": null, "summary": "Despite the promise of alleviating the main memory bottleneck, and the\nexistence of commercial hardware implementations, techniques for Near-Data\nProcessing have seen relatively little real-world deployment. The idea has\nreceived renewed interest with the appearance of disaggregated or \"far\" memory,\nfor example in the use of CXL memory pools.\n  However, we argue that the lack of a clear OS-centric abstraction of\nNear-Data Processing is a major barrier to adoption of the technology. Inspired\nby the channel controllers which interface the CPU to disk drives in mainframe\nsystems, we propose memory channel controllers as a convenient, portable, and\nvirtualizable abstraction of Near-Data Processing for modern disaggregated\nmemory systems.\n  In addition to providing a clean abstraction that enables OS integration\nwhile requiring no changes to CPU architecture, memory channel controllers\nincorporate another key innovation: they exploit the cache coherence provided\nby emerging interconnects to provide a much richer programming model, with more\nfine-grained interaction, than has been possible with existing designs."}
{"id": "2506.09397", "pdf": "https://arxiv.org/pdf/2506.09397", "abs": "https://arxiv.org/abs/2506.09397", "authors": ["Xiangchen Li", "Dimitrios Spatharakis", "Saeid Ghafouri", "Jiakun Fan", "Dimitrios Nikolopoulos"], "title": "SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.NI", "68T07, 68M14", "I.2.6; C.2.4; C.1.4"], "comment": "6 pages, 9 figures, 2 tables", "summary": "Regardless the advancements in device capabilities, efficient inferencing\nadvanced large language models (LLMs) at the edge remains challenging due to\nlimited device memory and power constraints. Existing strategies, such as\naggressive quantization, pruning, or remote inference, trade accuracy for\nefficiency or lead to substantial cost burdens. This position paper introduces\na new approach that leverages speculative decoding, previously viewed primarily\nas a decoding acceleration technique for autoregressive generation of LLMs, as\na promising approach specifically adapted for edge computing by orchestrating\ncomputation across heterogeneous devices. We propose SLED, a method that allows\nlightweight edge devices to draft multiple candidate tokens locally using\ndiverse draft models, while a single, shared edge server efficiently batches\nand verifies the tokens utilizing a more precise target model. This approach\nsupports device heterogeneity and reduces server-side memory footprint by\navoiding the need to deploy multiple target models. Our initial experiments\nwith Jetson Orin Nano, Raspberry Pi 5, and an RTX 6000 edge server indicate\nsubstantial benefits: significantly reduced latency, improved energy\nefficiency, and increased concurrent inference sessions, all without\nsacrificing model accuracy."}
{"id": "2506.09825", "pdf": "https://arxiv.org/pdf/2506.09825", "abs": "https://arxiv.org/abs/2506.09825", "authors": ["Mordechai Guri"], "title": "On the Impossibility of a Perfect Hypervisor", "categories": ["cs.OS", "cs.AR", "cs.CR"], "comment": null, "summary": "We establish a fundamental impossibility result for a `perfect hypervisor',\none that (1) preserves every observable behavior of any program exactly as on\nbare metal and (2) adds zero timing or resource overhead.\n  Within this model we prove two theorems. (1) Indetectability Theorem. If such\na hypervisor existed, no guest-level program, measurement, or timing test could\ndistinguish it from native execution; all traces, outputs, and timings would be\nidentical.\n  (2) Impossibility Theorem. Despite that theoretical indetectability, a\nperfect hypervisor cannot exist on any machine with finite computational\nresources.\n  These results are architecture-agnostic and extend beyond hypervisors to any\nvirtualization layer emulators, sandboxes, containers, or\nruntime-instrumentation frameworks. Together they provide a formal foundation\nfor future work on the principles and limits of virtualization."}
{"id": "2506.09703", "pdf": "https://arxiv.org/pdf/2506.09703", "abs": "https://arxiv.org/abs/2506.09703", "authors": ["Huan Lin", "Chenguang Zhu", "Lianghui Ding", "Feng Yang"], "title": "Multi-Level Damage-Aware Graph Learning for Resilient UAV Swarm Networks", "categories": ["cs.NI", "68M18", "C.2.1"], "comment": "15 pages. arXiv admin note: text overlap with arXiv:2411.11342", "summary": "Unmanned aerial vehicle (UAV) swarm networks leverage resilient algorithms to\naddress communication network split issues and restore connectivity. However,\nexisting graph learning-based resilient algorithms face over-aggregation and\nnon-convergence problems caused by uneven and sparse topology under massive\ndamage scenarios. To alleviate these problems, we propose a novel Multi-Level\nDamage-Aware Graph Learning (ML-DAGL) algorithm, which generates recovery\ntrajectories by mining information from destroyed UAVs. We first introduce a\nMulti-Branch Damage Attention (MBDA) module, which forms a sequence of\nmulti-hop Damage Attentive Graphs (mDAG) with different ranges of receptive\nfields. Each mDAG links only remaining and damaged nodes to ensure a more even\ndegree distribution for mitigating over-aggregation, and utilizes multi-hop\ndilation to establish more links for sparse topology enhancement. To resort to\nthe mDAG, we propose a Dilated Graph Convolution Network (DGCN), which\ngenerates the optimal recovery trajectories with theoretically proven\nconvergence under massive damage cases. Simulation results show that the\nproposed algorithm can guarantee the connectivity restoration under large swarm\nand damage scales, while significantly expediting the recovery time by 75.94%\nand improving the topology uniformity after recovery."}
{"id": "2506.09671", "pdf": "https://arxiv.org/pdf/2506.09671", "abs": "https://arxiv.org/abs/2506.09671", "authors": ["Iman Poernomo"], "title": "DHoTT: A Temporal Extension of Homotopy Type Theory for Semantic Drift", "categories": ["cs.LO", "03B70", "F.4.1"], "comment": null, "summary": "We introduce Dynamic Homotopy Type Theory (DHoTT), a temporal extension of\nHomotopy Type Theory (HoTT) designed to reason formally about concepts whose\nmeanings evolve continuously or rupture discontinuously over time. While\ntraditional HoTT captures identity and equivalence within a fixed semantic\nlandscape, DHoTT enriches this framework by explicitly indexing types with a\ntemporal parameter, allowing types themselves to deform, rupture, and\nreassemble as contexts shift.\n  Formally, we show that DHoTT serves as the internal language of a presheaf\ntopos over the linearly ordered time category. As a result, DHoTT (1)\nconservatively extends HoTT, recovering standard homotopy-theoretic reasoning\nwhen time is held constant; (2) preserves foundational structures such as\nunivalence and higher inductive types; and (3) introduces new constructs (drift\npaths and rupture types) for precisely capturing semantic evolution and\ndiscontinuity.\n  We illustrate the expressiveness of DHoTT through a worked example derived\nfrom conversational dynamics in large language models, highlighting its\nrelevance to posthuman intelligence and the formal modeling of evolving\nmeaning."}
{"id": "2506.09713", "pdf": "https://arxiv.org/pdf/2506.09713", "abs": "https://arxiv.org/abs/2506.09713", "authors": ["Mugeng Liu", "Siqi Zhong", "Weichen Bi", "Yixuan Zhang", "Zhiyang Chen", "Zhenpeng Chen", "Xuanzhe Liu", "Yun Ma"], "title": "A First Look at Bugs in LLM Inference Engines", "categories": ["cs.SE"], "comment": "Under review", "summary": "Large language model-specific inference engines (in short as \\emph{LLM\ninference engines}) have become a fundamental component of modern AI\ninfrastructure, enabling the deployment of LLM-powered applications (LLM apps)\nacross cloud and local devices. Despite their critical role, LLM inference\nengines are prone to bugs due to the immense resource demands of LLMs and the\ncomplexities of cross-platform compatibility. However, a systematic\nunderstanding of these bugs remains lacking. To bridge this gap, we present the\nfirst empirical study on bugs in LLM inference engines. We mine official\nrepositories of 5 widely adopted LLM inference engines, constructing a\ncomprehensive dataset of 929 real-world bugs. Through a rigorous open coding\nprocess, we analyze these bugs to uncover their symptoms, root causes, and\ncommonality. Our findings reveal six major bug symptoms and a taxonomy of 28\nroot causes, shedding light on the key challenges in bug detection and location\nwithin LLM inference engines. Based on these insights, we propose a series of\nactionable implications for researchers, inference engine vendors, and LLM app\ndevelopers."}
{"id": "2506.09292", "pdf": "https://arxiv.org/pdf/2506.09292", "abs": "https://arxiv.org/abs/2506.09292", "authors": ["Brooklyn J. Corbett", "Jason M. Tangen"], "title": "AI Tutors vs. Tenacious Myths: Evidence from Personalised Dialogue Interventions in Education", "categories": ["cs.HC"], "comment": "Originally posted as https://doi.org/10.31234/osf.io/x4wqh_v1", "summary": "Misconceptions in psychology and education persist despite clear\ncontradictory evidence, resisting traditional correction methods. This study\ninvestigated whether personalised AI dialogue could effectively correct these\nstubborn beliefs. In a preregistered experiment (N = 375), participants holding\nstrong psychology misconceptions engaged in one of three interventions: (1)\npersonalised AI dialogue targeting their specific misconception, (2) generic\ntextbook-style refutation, or (3) neutral AI dialogue (control). Results showed\nthat personalised AI dialogue produced significantly larger immediate belief\nreductions compared to both textbook reading and neutral dialogue. This\nadvantage persisted at 10-day follow-up but diminished by 2 months, where AI\ndialogue and textbook conditions converged while both remained superior to\ncontrol. Both AI conditions generated significantly higher engagement and\nconfidence than textbook reading, demonstrating the motivational benefits of\nconversational interaction. These findings demonstrate that AI dialogue can\naccelerate initial belief correction through personalised, interactive\nengagement that disrupts the cognitive processes maintaining misconceptions.\nHowever, the convergence of effects over time suggests brief interventions\nrequire reinforcement for lasting change. Future applications should integrate\nAI tutoring into structured educational programs with spaced reinforcement to\nsustain the initial advantages of personalised dialogue."}
{"id": "2506.09463", "pdf": "https://arxiv.org/pdf/2506.09463", "abs": "https://arxiv.org/abs/2506.09463", "authors": ["Soumyajit Chatterjee", "Rahul Utkoor", "Uppu Eshwar", "Sathya Peri", "V. Krishna Nandivada"], "title": "Efficient Task Graph Scheduling for Parallel QR Factorization in SLSQP", "categories": ["cs.DC"], "comment": null, "summary": "Efficient task scheduling is paramount in parallel programming on multi-core\narchitectures, where tasks are fundamental computational units. QR\nfactorization is a critical sub-routine in Sequential Least Squares Quadratic\nProgramming (SLSQP) for solving non-linear programming (NLP) problems. QR\nfactorization decomposes a matrix into an orthogonal matrix Q and an upper\ntriangular matrix R, which are essential for solving systems of linear\nequations arising from optimization problems. SLSQP uses an in-place version of\nQR factorization, which requires storing intermediate results for the next\nsteps of the algorithm. Although DAG-based approaches for QR factorization are\nprevalent in the literature, they often lack control over the intermediate\nkernel results, providing only the final output matrices Q and R. This\nlimitation is particularly challenging in SLSQP, where intermediate results of\nQR factorization are crucial for back-substitution logic at each iteration. Our\nwork introduces novel scheduling techniques using a two-queue approach to\nexecute the QR factorization kernel effectively. This approach, implemented in\nhigh-level C++ programming language, facilitates compiler optimizations and\nallows storing intermediate results required by back-substitution logic.\nEmpirical evaluations demonstrate substantial performance gains, including a\n10x improvement over the sequential QR version of the SLSQP algorithm."}
{"id": "2506.09878", "pdf": "https://arxiv.org/pdf/2506.09878", "abs": "https://arxiv.org/abs/2506.09878", "authors": ["Ryan Barker"], "title": "Virtualizing RAN: Science, Strategy, and Architecture of Software-Defined Mobile Networks", "categories": ["cs.NI"], "comment": "12 pages, 4 figures, 8 tables", "summary": "Virtualising the Radio Access Network (RAN) is widely touted as the\ncorner-stone of affordable 5G and a prerequisite for AI-native 6G. Yet current\ndiscourse often isolates spectrum policy, cloud engineering and organisational\nreadiness into silos. This paper delivers an integrated analysis that spans\nscience, technology, business strategy and culture. I first review\nspectrum-auction economics and show-via a comparative study of T-Mobile US and\nVerizon-that mid-band contiguity leveraged through software-defined carrier\naggregation outperforms mmWave-centric deployments in both coverage and churn\nmetrics. I then formalise the technical foundations of virtualised and open\nRAN, deriving capacity limits from contiguous and dis-contiguous spectrum maths\nand quantifying hardware ceilings for 400 MHz mmWave channels. Edge compute\nplatforms (NVIDIA EGX, Samsung vRAN 3.0) and SDN-controlled RAN Intelligent\nControllers are examined alongside AI ML pipelines that enable\ndigital-twin-driven optimisation. A security cost model extends recent O-RAN\nmeasurements to show how 256-bit cipher enforcement adds 35-60 us latency\nunless mitigated by inline crypto off-load. Finally, a national automation case\nstudy of live vRAN sites -- demonstrates an 81 to 13 day cycle-time reduction\nonce cultural change errors are corrected. I conclude with open research\nchallenges for sub-THz 6G, energy-neutral AI accelerators and zero-trust\norchestration, offering actionable recommendations for operators, vendors and\nresearchers."}
{"id": "2506.09791", "pdf": "https://arxiv.org/pdf/2506.09791", "abs": "https://arxiv.org/abs/2506.09791", "authors": ["Esaïe Bauer", "Alexis Saurin"], "title": "On the cut-elimination of the modal $μ$-calculus: Linear Logic to the rescue", "categories": ["cs.LO"], "comment": "Accepted to FoSSaCS 2025", "summary": "This paper presents a proof-theoretic analysis of the modal $\\mu$-calculus.\nMore precisely, we prove a syntactic cut-elimination for the non-wellfounded\nmodal $\\mu$-calculus, using methods from linear logic and its exponential\nmodalities. To achieve this, we introduce a new system, \\muLLmodinf{}, which is\na linear version of the modal $\\mu$-calculus, intertwining the modalities from\nthe modal $\\mu$-calculus with the exponential modalities from linear logic. Our\nstrategy for proving cut-elimination involves (i) proving cut-elimination for\n\\muLLmodinf{} and (ii) translating proofs of the modal mu-calculus into this\nnew system via a ``linear translation'', allowing us to extract the\ncut-elimination result."}
{"id": "2506.09759", "pdf": "https://arxiv.org/pdf/2506.09759", "abs": "https://arxiv.org/abs/2506.09759", "authors": ["Abhijit Paul", "Proma Chowdhury", "Kazi Sakib"], "title": "Towards Bridging Formal Methods and Human Interpretability", "categories": ["cs.SE"], "comment": "Need to improve data annotation process in methodology section", "summary": "Labeled Transition Systems (LTS) are integral to model checking and design\nrepair tools. System engineers frequently examine LTS designs during model\nchecking or design repair to debug, identify inconsistencies, and validate\nsystem behavior. Despite LTS's significance, no prior research has examined\nhuman comprehension of these designs. To address this, we draw on traditional\nsoftware engineering and graph theory, identifying 7 key metrics: cyclomatic\ncomplexity, state space size, average branching factor, maximum depth, Albin\ncomplexity, modularity, and redundancy. We created a dataset of 148 LTS\ndesigns, sampling 48 for 324 paired comparisons, and ranked them using the\nBradley-Terry model. Through Kendall's Tau correlation analysis, we found that\nAlbin complexity ($\\tau = 0.444$), state space size ($\\tau = 0.420$),\ncyclomatic complexity ($\\tau = 0.366$), and redundancy ($\\tau = 0.315$) most\naccurately reflect human comprehension of LTS designs. To showcase the metrics'\nutility, we applied the Albin complexity metric within the Fortis design repair\ntool, ranking system redesigns. This ranking reduced annotators' comprehension\ntime by 39\\%, suggesting that metrics emphasizing human factors can enhance\nformal design interpretability."}
{"id": "2506.09354", "pdf": "https://arxiv.org/pdf/2506.09354", "abs": "https://arxiv.org/abs/2506.09354", "authors": ["Kellie Yu Hui Sim", "Roy Ka-Wei Lee", "Kenny Tsu Wei Choo"], "title": "\"Is This Really a Human Peer Supporter?\": Misalignments Between Peer Supporters and Experts in LLM-Supported Interactions", "categories": ["cs.HC", "cs.AI", "H.5.0"], "comment": null, "summary": "Mental health is a growing global concern, prompting interest in AI-driven\nsolutions to expand access to psychosocial support. Peer support, grounded in\nlived experience, offers a valuable complement to professional care. However,\nvariability in training, effectiveness, and definitions raises concerns about\nquality, consistency, and safety. Large Language Models (LLMs) present new\nopportunities to enhance peer support interactions, particularly in real-time,\ntext-based interactions. We present and evaluate an AI-supported system with an\nLLM-simulated distressed client, context-sensitive LLM-generated suggestions,\nand real-time emotion visualisations. 2 mixed-methods studies with 12 peer\nsupporters and 5 mental health professionals (i.e., experts) examined the\nsystem's effectiveness and implications for practice. Both groups recognised\nits potential to enhance training and improve interaction quality. However, we\nfound a key tension emerged: while peer supporters engaged meaningfully,\nexperts consistently flagged critical issues in peer supporter responses, such\nas missed distress cues and premature advice-giving. This misalignment\nhighlights potential limitations in current peer support training, especially\nin emotionally charged contexts where safety and fidelity to best practices are\nessential. Our findings underscore the need for standardised, psychologically\ngrounded training, especially as peer support scales globally. They also\ndemonstrate how LLM-supported systems can scaffold this development--if\ndesigned with care and guided by expert oversight. This work contributes to\nemerging conversations on responsible AI integration in mental health and the\nevolving role of LLMs in augmenting peer-delivered care."}
{"id": "2506.09505", "pdf": "https://arxiv.org/pdf/2506.09505", "abs": "https://arxiv.org/abs/2506.09505", "authors": ["Dumitrel Loghin", "Shuang Liang", "Shengwei Liu", "Xiong Liu", "Pingcheng Ruan", "Zhigang Ye"], "title": "On the Performance of Cloud-based ARM SVE for Zero-Knowledge Proving Systems", "categories": ["cs.DC", "cs.ET", "cs.PF"], "comment": null, "summary": "Zero-knowledge proofs (ZKP) are becoming a gold standard in scaling\nblockchains and bringing Web3 to life. At the same time, ZKP for transactions\nrunning on the Ethereum Virtual Machine require powerful servers with hundreds\nof CPU cores. The current zkProver implementation from Polygon is optimized for\nx86-64 CPUs by vectorizing key operations, such as Merkle tree building with\nPoseidon hashes over the Goldilocks field, with Advanced Vector Extensions (AVX\nand AVX512). With these optimizations, a ZKP for a batch of transactions is\ngenerated in less than two minutes. With the advent of cloud servers with ARM\nwhich are at least 10% cheaper than x86-64 servers and the implementation of\nARM Scalable Vector Extension (SVE), we wonder if ARM servers can take over\ntheir x86-64 counterparts. Unfortunately, our analysis shows that current ARM\nCPUs are not a match for their x86-64 competitors. Graviton4 from Amazon Web\nServices (AWS) and Axion from Google Cloud Platform (GCP) are 1.6X and 1.4X\nslower compared to the latest AMD EPYC and Intel Xeon servers from AWS with AVX\nand AVX512, respectively, when building a Merkle tree with over four million\nleaves. This low performance is due to (1) smaller vector size in these ARM\nCPUs (128 bits versus 512 bits in AVX512) and (2) lower clock frequency. On the\nother hand, ARM SVE/SVE2 Instruction Set Architecture (ISA) is at least as\npowerful as AVX/AVX512 but more flexible. Moreover, we estimate that increasing\nthe vector size to 512 bits will enable higher performance in ARM CPUs compared\nto their x86-64 counterparts while maintaining their price advantage."}
{"id": "2506.09397", "pdf": "https://arxiv.org/pdf/2506.09397", "abs": "https://arxiv.org/abs/2506.09397", "authors": ["Xiangchen Li", "Dimitrios Spatharakis", "Saeid Ghafouri", "Jiakun Fan", "Dimitrios Nikolopoulos"], "title": "SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.NI", "68T07, 68M14", "I.2.6; C.2.4; C.1.4"], "comment": "6 pages, 9 figures, 2 tables", "summary": "Regardless the advancements in device capabilities, efficient inferencing\nadvanced large language models (LLMs) at the edge remains challenging due to\nlimited device memory and power constraints. Existing strategies, such as\naggressive quantization, pruning, or remote inference, trade accuracy for\nefficiency or lead to substantial cost burdens. This position paper introduces\na new approach that leverages speculative decoding, previously viewed primarily\nas a decoding acceleration technique for autoregressive generation of LLMs, as\na promising approach specifically adapted for edge computing by orchestrating\ncomputation across heterogeneous devices. We propose SLED, a method that allows\nlightweight edge devices to draft multiple candidate tokens locally using\ndiverse draft models, while a single, shared edge server efficiently batches\nand verifies the tokens utilizing a more precise target model. This approach\nsupports device heterogeneity and reduces server-side memory footprint by\navoiding the need to deploy multiple target models. Our initial experiments\nwith Jetson Orin Nano, Raspberry Pi 5, and an RTX 6000 edge server indicate\nsubstantial benefits: significantly reduced latency, improved energy\nefficiency, and increased concurrent inference sessions, all without\nsacrificing model accuracy."}
{"id": "2506.09487", "pdf": "https://arxiv.org/pdf/2506.09487", "abs": "https://arxiv.org/abs/2506.09487", "authors": ["Taesoo Park", "Mungwi Jeong", "Mingyu Park", "Narae Kim", "Junyoung Kim", "Mujung Kim", "Jisang Yoo", "Hoyun Lee", "Sanghoon Kim", "Soonchul Kwon"], "title": "BemaGANv2: A Tutorial and Comparative Survey of GAN-based Vocoders for Long-Term Audio Generation", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.LO", "eess.AS", "I.2.6; H.5.5; I.5.1"], "comment": "11 pages, 7 figures. Survey and tutorial paper. Currently under\n  review at ICT Express as an extended version of our ICAIIC 2025 paper", "summary": "This paper presents a tutorial-style survey and implementation guide of\nBemaGANv2, an advanced GAN-based vocoder designed for high-fidelity and\nlong-term audio generation. Built upon the original BemaGAN architecture,\nBemaGANv2 incorporates major architectural innovations by replacing traditional\nResBlocks in the generator with the Anti-aliased Multi-Periodicity composition\n(AMP) module, which internally applies the Snake activation function to better\nmodel periodic structures. In the discriminator framework, we integrate the\nMulti-Envelope Discriminator (MED), a novel architecture we originally\nproposed, to extract rich temporal envelope features crucial for periodicity\ndetection. Coupled with the Multi-Resolution Discriminator (MRD), this\ncombination enables more accurate modeling of long-range dependencies in audio.\nWe systematically evaluate various discriminator configurations, including MSD\n+ MED, MSD + MRD, and MPD + MED + MRD, using objective metrics (FAD, SSIM,\nPLCC, MCD) and subjective evaluations (MOS, SMOS). This paper also provides a\ncomprehensive tutorial on the model architecture, training methodology, and\nimplementation to promote reproducibility. The code and pre-trained models are\navailable at: https://github.com/dinhoitt/BemaGANv2."}
{"id": "2506.09845", "pdf": "https://arxiv.org/pdf/2506.09845", "abs": "https://arxiv.org/abs/2506.09845", "authors": ["Tobias Heß", "Lukas Ostheimer", "Tobias Betz", "Simon Karrer", "Tim Jannik Schmidt", "Pierre Coquet", "Sean Semmler", "Thomas Thüm"], "title": "variability.dev: Towards an Online Toolbox for Feature Modeling", "categories": ["cs.SE"], "comment": "Presented at 6th International Workshop on Languages for Modelling\n  Variability (MODEVAR'24) (arXiv:cs/2402.15511). 5 pages, 3 figures", "summary": "The emergence of feature models as the default to model the variability in\nconfigurable systems fosters a rich diversity in applications, application\ndomains, and perspectives. Independent of their domain, modelers require to\nopen, view, edit, transform, save, and configure models as well as to\ncollaborate with others. However, at the time of writing, the top five results\nwhen googling ``Online Editor Feature Model'' point to editors that either have\nminimal functionality, are unmaintained or defunct, or require an offline\ninstallation, such as FeatureIDE. In this work we present a preview of our\nin-development online toolbox for feature modeling, variability.dev. In\nparticular, we showcase our collaborative feature-model editor and our online\nconfigurator both of which are built on top of the FeatureIDE library."}
{"id": "2506.09362", "pdf": "https://arxiv.org/pdf/2506.09362", "abs": "https://arxiv.org/abs/2506.09362", "authors": ["Kellie Yu Hui Sim", "Kenny Tsu Wei Choo"], "title": "\"I Said Things I Needed to Hear Myself\": Peer Support as an Emotional, Organisational, and Sociotechnical Practice in Singapore", "categories": ["cs.HC", "cs.AI", "H.5.0"], "comment": null, "summary": "Peer support plays a vital role in expanding access to mental health care by\nproviding empathetic, community-based support outside formal clinical systems.\nAs digital platforms increasingly mediate such support, the design and impact\nof these technologies remain under-examined, particularly in Asian contexts.\nThis paper presents findings from an interview study with 20 peer supporters in\nSingapore, who operate across diverse online, offline, and hybrid environments.\nThrough a thematic analysis, we unpack how participants start, conduct, and\nsustain peer support, highlighting their motivations, emotional labour, and the\nsociocultural dimensions shaping their practices. Building on this grounded\nunderstanding, we surface design directions for culturally responsive digital\ntools that scaffold rather than supplant relational care. Drawing insights from\nqualitative accounts, we offer a situated perspective on how AI might\nresponsibly augment peer support. This research contributes to human-centred\ncomputing by articulating the lived realities of peer supporters and proposing\ndesign implications for trustworthy and context-sensitive AI in mental health."}
{"id": "2506.09554", "pdf": "https://arxiv.org/pdf/2506.09554", "abs": "https://arxiv.org/abs/2506.09554", "authors": ["Mayank Arya", "Yogesh Simmhan"], "title": "Understanding the Performance and Power of LLM Inferencing on Edge Accelerators", "categories": ["cs.DC"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated exceptional benefits to a wide\nrange of domains, for tasks as diverse as code generation and robot navigation.\nWhile LLMs are usually served from cloud data centers, mission-critical and\nprivacy-sensitive applications may require local hosting of open LLM models.\nGiven the large GPU memory footprint needed for LLMs, edge accelerators such as\nNvidia Jetson Orin AGX with 64GB of shared GPU-CPU RAM are a compelling choice.\nHowever, the feasibility and performance of LLM inference on edge accelerators\nis under-explored. This study presents a detailed evaluation of LLM inference\non the NVIDIA Jetson Orin AGX, on four SOTA models ranging from 2.7B to 32.8B\nparameters, such as Meta Llama3.1, Microsoft-Phi2, Deepseek-R1-Qwen.We\ninvestigate the impact of varying batch sizes, sequence lengths, and\nquantization levels on latency, throughput, and perplexity, and also explore\nvarious custom power modes on the Orin AGX to perform power and energy\nconsumption analysis. Our findings offer interesting insights on the trade-offs\nbetween efficiency, inference speed and resource use, e.g., increasing the\nsequence length causes a decrease in token throughput and quantization causes\nsmaller LLMs to be slower. These results can help optimize LLM serving on edge\naccelerators for practical applications."}
{"id": "2506.09418", "pdf": "https://arxiv.org/pdf/2506.09418", "abs": "https://arxiv.org/abs/2506.09418", "authors": ["Ryan Barker", "Fatemeh Afghah"], "title": "Securing Open RAN: A Survey of Cryptographic Challenges and Emerging Solutions for 5G", "categories": ["cs.CR", "cs.NI"], "comment": "4 pages, 1 figure", "summary": "The advent of Open Radio Access Networks (O-RAN) introduces modularity and\nflexibility into 5G deployments but also surfaces novel security challenges\nacross disaggregated interfaces. This literature review synthesizes recent\nresearch across thirteen academic and industry sources, examining\nvulnerabilities such as cipher bidding-down attacks, partial encryption\nexposure on control/user planes, and performance trade-offs in securing O-RAN\ninterfaces like E2 and O1. The paper surveys key cryptographic tools -- SNOW-V,\nAES-256, and ZUC-256 -- evaluating their throughput, side-channel resilience,\nand adaptability to heterogeneous slices (eMBB, URLLC, mMTC). Emphasis is\nplaced on emerging testbeds and AI-driven controllers that facilitate dynamic\norchestration, anomaly detection, and secure configuration. We conclude by\noutlining future research directions, including hardware offloading,\ncross-layer cipher adaptation, and alignment with 3GPP TS 33.501 and O-RAN\nAlliance security mandates, all of which point toward the need for integrated,\nzero-trust architectures in 6G."}
{"id": "2506.09873", "pdf": "https://arxiv.org/pdf/2506.09873", "abs": "https://arxiv.org/abs/2506.09873", "authors": ["Emma Kallina", "Thomas Bohné", "Jat Singh"], "title": "Stakeholder Participation for Responsible AI Development: Disconnects Between Guidance and Current Practice", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "Published at the 2025 ACM Conference on Fairness, Accountability, and\n  Transparency FAccT'25", "summary": "Responsible AI (rAI) guidance increasingly promotes stakeholder involvement\n(SHI) during AI development. At the same time, SHI is already common in\ncommercial software development, but with potentially different foci. This\nstudy clarifies the extent to which established SHI practices are able to\ncontribute to rAI efforts as well as potential disconnects -- essential\ninsights to inform and tailor future interventions that further shift industry\npractice towards rAI efforts. First, we analysed 56 rAI guidance documents to\nidentify why SHI is recommended (i.e. its expected benefits for rAI) and\nuncovered goals such as redistributing power, improving socio-technical\nunderstandings, anticipating risks, and enhancing public oversight. To\nunderstand why and how SHI is currently practised in commercial settings, we\nthen conducted an online survey (n=130) and semi-structured interviews (n=10)\nwith AI practitioners. Our findings reveal that SHI in practice is primarily\ndriven by commercial priorities (e.g. customer value, compliance) and several\nfactors currently discourage more rAI-aligned SHI practices. This suggests that\nestablished SHI practices are largely not contributing to rAI efforts. To\naddress this disconnect, we propose interventions and research opportunities to\nadvance rAI development in practice."}
{"id": "2506.09696", "pdf": "https://arxiv.org/pdf/2506.09696", "abs": "https://arxiv.org/abs/2506.09696", "authors": ["Joseph Corneli", "Charles J. Danoff", "Raymond S. Puzio", "Sridevi Ayloo", "Serge Belich", "Mary Tedeschi"], "title": "Patterns of Patterns III", "categories": ["cs.HC"], "comment": "18 pages; submitted to Pattern Languages of Programs 2025", "summary": "Building on earlier installments, this paper re-examines the PLACARD pattern.\nWe report on a series of workshops where PLACARD was used to scaffold\ncollaborative reflection, speculative inquiry, and stimulate design pattern\ngeneration. These accounts are enriched by a comparison case: virtual workshops\ncarried out with simple AI-based chatbots. We discuss limitations and lessons\nlearned from both the human and multi-agent settings. We conclude by outlining\na future development strategy at the intersection of AI agents, design\npatterns, and institutional governance."}
{"id": "2506.09823", "pdf": "https://arxiv.org/pdf/2506.09823", "abs": "https://arxiv.org/abs/2506.09823", "authors": ["Stephen Buttolph", "Andrew Lewis-Pye", "Kevin Sekniqi"], "title": "Frosty for partial synchrony", "categories": ["cs.DC"], "comment": "arXiv admin note: substantial text overlap with arXiv:2404.14250,\n  arXiv:2501.15904", "summary": "Snowman is the consensus protocol used by blockchains on Avalanche. Recent\nwork has shown both how to augment Snowman with a `liveness' module called\n`Frosty' that protects against liveness attacks, and also how to modify Snowman\nso as to be consistent in partial synchrony. Since Frosty assumes (a strong\nform of) synchrony, the aim of this note is to show how to modify Frosty to\ndeal with the partially synchronous version of Snowman."}
{"id": "2506.09929", "pdf": "https://arxiv.org/pdf/2506.09929", "abs": "https://arxiv.org/abs/2506.09929", "authors": ["Scott Schnelle", "Francesca Favaro", "Laura Fraade-Blanar", "David Wichner", "Holland Broce", "Justin Miranda"], "title": "Assessing a Safety Case: Bottom-up Guidance for Claims and Evidence Evaluation", "categories": ["cs.SE", "cs.CY"], "comment": null, "summary": "As Automated Driving Systems (ADS) technology advances, ensuring safety and\npublic trust requires robust assurance frameworks, with safety cases emerging\nas a critical tool toward such a goal. This paper explores an approach to\nassess how a safety case is supported by its claims and evidence, toward\nestablishing credibility for the overall case. Starting from a description of\nthe building blocks of a safety case (claims, evidence, and optional\nformat-dependent entries), this paper delves into the assessment of support of\neach claim through the provided evidence. Two domains of assessment are\noutlined for each claim: procedural support (formalizing process specification)\nand implementation support (demonstrating process application). Additionally,\nan assessment of evidence status is also undertaken, independently from the\nclaims support. Scoring strategies and evaluation guidelines are provided,\nincluding detailed scoring tables for claim support and evidence status\nassessment. The paper further discusses governance, continual improvement, and\ntiming considerations for safety case assessments. Reporting of results and\nfindings is contextualized within its primary use for internal decision-making\non continual improvement efforts. The presented approach builds on state of the\nart auditing practices, but specifically tackles the question of judging the\ncredibility of a safety case. While not conclusive on its own, it provides a\nstarting point toward a comprehensive \"Case Credibility Assessment\" (CCA),\nstarting from the evaluation of the support for each claim (individually and in\naggregate), as well as every piece of evidence provided. By delving into the\ntechnical intricacies of ADS safety cases, this work contributes to the ongoing\ndiscourse on safety assurance and aims to facilitate the responsible\nintegration of ADS technology into society."}
{"id": "2506.09801", "pdf": "https://arxiv.org/pdf/2506.09801", "abs": "https://arxiv.org/abs/2506.09801", "authors": ["Qihan Yang", "Xin Zhou", "Adam J. Spiers"], "title": "Investigating the Perception of Translational Shape-Changing Haptic Interfaces", "categories": ["cs.HC"], "comment": "7 pages, 8 figures. Accepted version to appear in: Proceedings of the\n  IEEE World Haptics Conference (WHC), 2025", "summary": "Shape-changing haptic interfaces (SCHIs) are a promising and emerging field.\nHowever, compared to more established stimulus modalities, such as vibration,\nthere is sparse literature on the perception of dynamic shapes. Furthermore,\nthe influence of properties such as grasp types and displacement\nmagnitude/direction has not been formally evaluated. This work attempts to\ninitiate a formal perceptual evaluation of SCHIs via a psychophysical user\nstudy involving a 1-DOF translational shape-changing interface that can move\nits body with 1.25-micrometer resolution. Participants completed a Method of\nConstant Stimulus study while holding the device with three different grasps.\nStimuli direction occurred both toward and away from the thumb, while the\nstandard stimuli varied between small (0.48 mm) and large (6 mm). Our results\nindicate that translational SCHIs should maximize the translation magnitude\nrather than the number of fingers in contact. We also demonstrated how to apply\nour findings to real-world applications via a simple 'paddle game', where we\ncompared conventional linear mapping with non-linear mapping derived from our\nperceptual experiment outcomes between the device position and its represented\nvalue. Results indicate that the non-linear mapping was more effective, with\nimproved error distribution. We hope this work inspires further formal\nperceptual investigation into other SCHI morphologies."}
{"id": "2506.09199", "pdf": "https://arxiv.org/pdf/2506.09199", "abs": "https://arxiv.org/abs/2506.09199", "authors": ["Hariharan Ramesh", "Jyotikrishna Dass"], "title": "FLoRIST: Singular Value Thresholding for Efficient and Accurate Federated Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "21 pages, 12 figures", "summary": "Integrating Low-Rank Adaptation (LoRA) into federated learning offers a\npromising solution for parameter-efficient fine-tuning of Large Language Models\n(LLMs) without sharing local data. However, several methods designed for\nfederated LoRA present significant challenges in balancing communication\nefficiency, model accuracy, and computational cost, particularly among\nheterogeneous clients. These methods either rely on simplistic averaging of\nlocal adapters, which introduces aggregation noise, require transmitting large\nstacked local adapters, leading to poor communication efficiency, or\nnecessitate reconstructing memory-dense global weight-update matrix and\nperforming computationally expensive decomposition to design client-specific\nlow-rank adapters. In this work, we propose FLoRIST, a federated fine-tuning\nframework that achieves mathematically accurate aggregation without incurring\nhigh communication or computational overhead. Instead of constructing the full\nglobal weight-update matrix at the server, FLoRIST employs an efficient\ndecomposition pipeline by performing singular value decomposition on stacked\nlocal adapters separately. This approach operates within a compact intermediate\nspace to represent the accumulated information from local LoRAs. We introduce\ntunable singular value thresholding for server-side optimal rank selection to\nconstruct a pair of global low-rank adapters shared by all clients. Extensive\nempirical evaluations across multiple datasets and LLMs demonstrate that\nFLoRIST consistently strikes the best balance between superior communication\nefficiency and competitive performance in both homogeneous and heterogeneous\nsetups."}
{"id": "2506.09938", "pdf": "https://arxiv.org/pdf/2506.09938", "abs": "https://arxiv.org/abs/2506.09938", "authors": ["Aaditaa Vashisht", "Rekha B S"], "title": "Microservices and Real-Time Processing in Retail IT: A Review of Open-Source Toolchains and Deployment Strategies", "categories": ["cs.SE", "cs.DB"], "comment": null, "summary": "With the rapid pace of digital transformation, the retail industry is\nincreasingly depending on real-time, scalable, and resilient systems to manage\nfinancial transactions, analyze customer behavior, and streamline order\nprocessing. This literature review explores how modern event-driven and\nmicroservices-based architectures, particularly those leveraging Apache Kafka,\nSpring Boot, MongoDB, and Kubernetes are transforming retail and financial\nsystems. By systematically reviewing academic publications, technical white\npapers, and industry reports from recent years, this study synthesizes key\nthemes and implementation strategies. The analysis reveals that technologies\nlike Kafka and Spring Boot are instrumental in building low-latency,\nevent-driven applications that support real-time analytics and fraud detection,\nwhile MongoDB, when deployed on Kubernetes, ensures fault tolerance and high\navailability in inventory and transaction systems. Kubernetes itself plays a\ncrucial role in automating deployment and scaling of microservices. These\nfindings provide valuable insights for industry practitioners aiming to design\nscalable infrastructures, identify research opportunities in hybrid deployment\nmodels, and offer educators a foundation to integrate modern system\narchitectures into professional and technical communication training."}
{"id": "2506.09968", "pdf": "https://arxiv.org/pdf/2506.09968", "abs": "https://arxiv.org/abs/2506.09968", "authors": ["Wentao Ge", "Yuqing Sun", "Ziyan Wang", "Haoyue Zheng", "Weiyang He", "Piaohong Wang", "Qianyu Zhu", "Benyou Wang"], "title": "SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance", "categories": ["cs.HC", "I.2.1; I.2.6"], "comment": "14 pages", "summary": "Self-regulated learning (SRL) is crucial for college students navigating\nincreased academic demands and independence. Insufficient SRL skills can lead\nto disorganized study habits, low motivation, and poor time management,\nundermining learners ability to thrive in challenging environments. Through a\nformative study involving 59 college students, we identified key challenges\nstudents face in developing SRL skills, including difficulties with\ngoal-setting, time management, and reflective learning. To address these\nchallenges, we introduce SRLAgent, an LLM-assisted system that fosters SRL\nskills through gamification and adaptive support from large language models\n(LLMs). Grounded in Zimmermans three-phase SRL framework, SRLAgent enables\nstudents to engage in goal-setting, strategy execution, and self-reflection\nwithin an interactive game-based environment. The system offers real-time\nfeedback and scaffolding powered by LLMs to support students independent study\nefforts. We evaluated SRLAgent using a between-subjects design, comparing it to\na baseline system (SRL without Agent features) and a traditional multimedia\nlearning condition. Results showed significant improvements in SRL skills\nwithin the SRLAgent group (p < .001, Cohens d = 0.234) and higher engagement\ncompared to the baselines. This work highlights the value of embedding SRL\nscaffolding and real-time AI support within gamified environments, offering\ndesign implications for educational technologies that aim to promote deeper\nlearning and metacognitive skill development."}
{"id": "2506.09226", "pdf": "https://arxiv.org/pdf/2506.09226", "abs": "https://arxiv.org/abs/2506.09226", "authors": ["Bowen Wu", "Wei Cui", "Carlo Curino", "Matteo Interlandi", "Rathijit Sen"], "title": "Terabyte-Scale Analytics in the Blink of an Eye", "categories": ["cs.DB", "cs.DC", "cs.PF"], "comment": null, "summary": "For the past two decades, the DB community has devoted substantial research\nto take advantage of cheap clusters of machines for distributed data analytics\n-- we believe that we are at the beginning of a paradigm shift. The scaling\nlaws and popularity of AI models lead to the deployment of incredibly powerful\nGPU clusters in commercial data centers. Compared to CPU-only solutions, these\nclusters deliver impressive improvements in per-node compute, memory bandwidth,\nand inter-node interconnect performance. In this paper, we study the problem of\nscaling analytical SQL queries on distributed clusters of GPUs, with the stated\ngoal of establishing an upper bound on the likely performance gains. To do so,\nwe build a prototype designed to maximize performance by leveraging ML/HPC best\npractices, such as group communication primitives for cross-device data\nmovements. This allows us to conduct thorough performance experimentation to\npoint our community towards a massive performance opportunity of at least\n60$\\times$. To make these gains more relatable, before you can blink twice, our\nsystem can run all 22 queries of TPC-H at a 1TB scale factor!"}
{"id": "2506.09790", "pdf": "https://arxiv.org/pdf/2506.09790", "abs": "https://arxiv.org/abs/2506.09790", "authors": ["Zhenran Xu", "Yiyu Wang", "Xue Yang", "Longyue Wang", "Weihua Luo", "Kaifu Zhang", "Baotian Hu", "Min Zhang"], "title": "ComfyUI-R1: Exploring Reasoning Models for Workflow Generation", "categories": ["cs.CL", "cs.CV", "cs.SE"], "comment": "Work in progress. Try it out in ComfyUI-Copilot\n  https://github.com/AIDC-AI/ComfyUI-Copilot", "summary": "AI-generated content has evolved from monolithic models to modular workflows,\nparticularly on platforms like ComfyUI, enabling customization in creative\npipelines. However, crafting effective workflows requires great expertise to\norchestrate numerous specialized components, presenting a steep learning curve\nfor users. To address this challenge, we introduce ComfyUI-R1, the first large\nreasoning model for automated workflow generation. Starting with our curated\ndataset of 4K workflows, we construct long chain-of-thought (CoT) reasoning\ndata, including node selection, workflow planning, and code-level workflow\nrepresentation. ComfyUI-R1 is trained through a two-stage framework: (1) CoT\nfine-tuning for cold start, adapting models to the ComfyUI domain; (2)\nreinforcement learning for incentivizing reasoning capability, guided by a\nfine-grained rule-metric hybrid reward, ensuring format validity, structural\nintegrity, and node-level fidelity. Experiments show that our 7B-parameter\nmodel achieves a 97\\% format validity rate, along with high pass rate,\nnode-level and graph-level F1 scores, significantly surpassing prior\nstate-of-the-art methods that employ leading closed-source models such as\nGPT-4o and Claude series. Further analysis highlights the critical role of the\nreasoning process and the advantage of transforming workflows into code.\nQualitative comparison reveals our strength in synthesizing intricate workflows\nwith diverse nodes, underscoring the potential of long CoT reasoning in AI art\ncreation."}
{"id": "2506.09054", "pdf": "https://arxiv.org/pdf/2506.09054", "abs": "https://arxiv.org/abs/2506.09054", "authors": ["Mohammad Attar", "Andrew Carse", "Yeming Chen", "Thomas Green", "Jeong-Yeon Ha", "Yanbai Jin", "Amy McWilliams", "Theirry Panggabean", "Zhengyu Peng", "Lujin Sun", "Jing Ru", "Jiacheng She", "Jialin Wang", "Zilun Wei", "Jiayuan Zhu", "Lachlan McGinness"], "title": "Particle Builder -- Learn about the Standard Model while playing against an AI", "categories": ["physics.ed-ph", "cs.HC"], "comment": "This demo has been accepted for presentation at the AIED 2025\n  Interactive Events Track", "summary": "Particle Builder Online is a web-based education game designed for high\nschool physics students. Students can play against an AI opponent or peers to\nfamiliarise themselves with the Standard Model of Particle Physics. The game is\naimed at a high school level and tailored to the International Baccalaureate\nand the Australian Curriculum. Students from four schools in Canberra took\npre/post-tests and a survey while completing a lesson where they played\nParticle Builder. Students' understanding of particle physics concepts improved\nsignificantly. Students found the game more enjoyable and effective than\nregular classroom lessons."}
{"id": "2506.09438", "pdf": "https://arxiv.org/pdf/2506.09438", "abs": "https://arxiv.org/abs/2506.09438", "authors": ["Haoxiang Ye", "Tao Sun", "Qing Ling"], "title": "Generalization Error Analysis for Attack-Free and Byzantine-Resilient Decentralized Learning with Data Heterogeneity", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Decentralized learning, which facilitates joint model training across\ngeographically scattered agents, has gained significant attention in the field\nof signal and information processing in recent years. While the optimization\nerrors of decentralized learning algorithms have been extensively studied,\ntheir generalization errors remain relatively under-explored. As the\ngeneralization errors reflect the scalability of trained models on unseen data\nand are crucial in determining the performance of trained models in real-world\napplications, understanding the generalization errors of decentralized learning\nis of paramount importance. In this paper, we present fine-grained\ngeneralization error analysis for both attack-free and Byzantine-resilient\ndecentralized learning with heterogeneous data as well as under mild\nassumptions, in contrast to prior studies that consider homogeneous data and/or\nrely on a stringent bounded stochastic gradient assumption. Our results shed\nlight on the impact of data heterogeneity, model initialization and stochastic\ngradient noise -- factors that have not been closely investigated before -- on\nthe generalization error of decentralized learning. We also reveal that\nByzantine attacks performed by malicious agents largely affect the\ngeneralization error, and their negative impact is inherently linked to the\ndata heterogeneity while remaining independent on the sample size. Numerical\nexperiments on both convex and non-convex tasks are conducted to validate our\ntheoretical findings."}
{"id": "2506.09073", "pdf": "https://arxiv.org/pdf/2506.09073", "abs": "https://arxiv.org/abs/2506.09073", "authors": ["J. Parsons", "R. Lukyanenko", "B. Greenwood", "C. Cooper"], "title": "Understanding and Improving Data Repurposing", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "We live in an age of unprecedented opportunities to use existing data for\ntasks not anticipated when those data were collected, resulting in widespread\ndata repurposing. This commentary defines and maps the scope of data\nrepurposing to highlight its importance for organizations and society and the\nneed to study data repurposing as a frontier of data management. We explain how\nrepurposing differs from original data use and data reuse and then develop a\nframework for data repurposing consisting of concepts and activities for\nadapting existing data to new tasks. The framework and its implications are\nillustrated using two examples of repurposing, one in healthcare and one in\ncitizen science. We conclude by suggesting opportunities for research to better\nunderstand data repurposing and enable more effective data repurposing\npractices."}
{"id": "2506.09660", "pdf": "https://arxiv.org/pdf/2506.09660", "abs": "https://arxiv.org/abs/2506.09660", "authors": ["Baran Can Gül", "Stefanos Tziampazis", "Nasser Jazdi", "Michael Weyrich"], "title": "SyncFed: Time-Aware Federated Learning through Explicit Timestamping and Synchronization", "categories": ["cs.LG", "cs.DC"], "comment": "Preprint version. Accepted for publication at IEEE ETFA 2025", "summary": "As Federated Learning (FL) expands to larger and more distributed\nenvironments, consistency in training is challenged by network-induced delays,\nclock unsynchronicity, and variability in client updates. This combination of\nfactors may contribute to misaligned contributions that undermine model\nreliability and convergence. Existing methods like staleness-aware aggregation\nand model versioning address lagging updates heuristically, yet lack mechanisms\nto quantify staleness, especially in latency-sensitive and cross-regional\ndeployments. In light of these considerations, we introduce \\emph{SyncFed}, a\ntime-aware FL framework that employs explicit synchronization and timestamping\nto establish a common temporal reference across the system. Staleness is\nquantified numerically based on exchanged timestamps under the Network Time\nProtocol (NTP), enabling the server to reason about the relative freshness of\nclient updates and apply temporally informed weighting during aggregation. Our\nempirical evaluation on a geographically distributed testbed shows that, under\n\\emph{SyncFed}, the global model evolves within a stable temporal context,\nresulting in improved accuracy and information freshness compared to\nround-based baselines devoid of temporal semantics."}
{"id": "2506.09160", "pdf": "https://arxiv.org/pdf/2506.09160", "abs": "https://arxiv.org/abs/2506.09160", "authors": ["Griffin Pitts", "Sanaz Motamedi"], "title": "Understanding Human-AI Trust in Education", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC"], "comment": null, "summary": "As AI chatbots become increasingly integrated in education, students are\nturning to these systems for guidance, feedback, and information. However, the\nanthropomorphic characteristics of these chatbots create ambiguity regarding\nwhether students develop trust toward them as they would a human peer or\ninstructor, based in interpersonal trust, or as they would any other piece of\ntechnology, based in technology trust. This ambiguity presents theoretical\nchallenges, as interpersonal trust models may inappropriately ascribe human\nintentionality and morality to AI, while technology trust models were developed\nfor non-social technologies, leaving their applicability to anthropomorphic\nsystems unclear. To address this gap, we investigate how human-like and\nsystem-like trusting beliefs comparatively influence students' perceived\nenjoyment, trusting intention, behavioral intention to use, and perceived\nusefulness of an AI chatbot - factors associated with students' engagement and\nlearning outcomes. Through partial least squares structural equation modeling,\nwe found that human-like and system-like trust significantly influenced student\nperceptions, with varied effects. Human-like trust more strongly predicted\ntrusting intention, while system-like trust better predicted behavioral\nintention and perceived usefulness. Both had similar effects on perceived\nenjoyment. Given the partial explanatory power of each type of trust, we\npropose that students develop a distinct form of trust with AI chatbots\n(human-AI trust) that differs from human-human and human-technology models of\ntrust. Our findings highlight the need for new theoretical frameworks specific\nto human-AI trust and offer practical insights for fostering appropriately\ncalibrated trust, which is critical for the effective adoption and pedagogical\nimpact of AI in education."}
{"id": "2506.09870", "pdf": "https://arxiv.org/pdf/2506.09870", "abs": "https://arxiv.org/abs/2506.09870", "authors": ["Maximilian Egger", "Rawad Bitar"], "title": "Private Aggregation for Byzantine-Resilient Heterogeneous Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "Ensuring resilience to Byzantine clients while maintaining the privacy of the\nclients' data is a fundamental challenge in federated learning (FL). When the\nclients' data is homogeneous, suitable countermeasures were studied from an\ninformation-theoretic perspective utilizing secure aggregation techniques while\nensuring robust aggregation of the clients' gradients. However, the\ncountermeasures used fail when the clients' data is heterogeneous. Suitable\npre-processing techniques, such as nearest neighbor mixing, were recently shown\nto enhance the performance of those countermeasures in the heterogeneous\nsetting. Nevertheless, those pre-processing techniques cannot be applied with\nthe introduced privacy-preserving mechanisms.\n  We propose a multi-stage method encompassing a careful co-design of\nverifiable secret sharing, secure aggregation, and a tailored symmetric private\ninformation retrieval scheme to achieve information-theoretic privacy\nguarantees and Byzantine resilience under data heterogeneity. We evaluate the\neffectiveness of our scheme on a variety of attacks and show how it outperforms\nthe previously known techniques. Since the communication overhead of secure\naggregation is non-negligible, we investigate the interplay with zero-order\nestimation methods that reduce the communication cost in state-of-the-art FL\ntasks and thereby make private aggregation scalable."}
{"id": "2506.09420", "pdf": "https://arxiv.org/pdf/2506.09420", "abs": "https://arxiv.org/abs/2506.09420", "authors": ["Henry Peng Zou", "Wei-Chieh Huang", "Yaozu Wu", "Chunyu Miao", "Dongyuan Li", "Aiwei Liu", "Yue Zhou", "Yankai Chen", "Weizhi Zhang", "Yangning Li", "Liancheng Fang", "Renhe Jiang", "Philip S. Yu"], "title": "A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG", "cs.MA"], "comment": null, "summary": "Recent improvements in large language models (LLMs) have led many researchers\nto focus on building fully autonomous AI agents. This position paper questions\nwhether this approach is the right path forward, as these autonomous systems\nstill have problems with reliability, transparency, and understanding the\nactual requirements of human. We suggest a different approach: LLM-based\nHuman-Agent Systems (LLM-HAS), where AI works with humans rather than replacing\nthem. By keeping human involved to provide guidance, answer questions, and\nmaintain control, these systems can be more trustworthy and adaptable. Looking\nat examples from healthcare, finance, and software development, we show how\nhuman-AI teamwork can handle complex tasks better than AI working alone. We\nalso discuss the challenges of building these collaborative systems and offer\npractical solutions. This paper argues that progress in AI should not be\nmeasured by how independent systems become, but by how well they can work with\nhumans. The most promising future for AI is not in systems that take over human\nroles, but in those that enhance human capabilities through meaningful\npartnership."}
{"id": "2506.09707", "pdf": "https://arxiv.org/pdf/2506.09707", "abs": "https://arxiv.org/abs/2506.09707", "authors": ["Suhas BN", "Andrew M. Sherrill", "Jyoti Alaparthi", "Dominik Mattioli", "Rosa I. Arriaga", "Chris W. Wiese", "Saeed Abdullah"], "title": "Fine-Tuning Large Audio-Language Models with LoRA for Precise Temporal Localization of Prolonged Exposure Therapy Elements", "categories": ["eess.AS", "cs.CL", "cs.HC", "68T07", "I.2.7; I.5.4; H.5.2"], "comment": "5 pages, 2 figures", "summary": "Prolonged Exposure (PE) therapy is an effective treatment for post-traumatic\nstress disorder (PTSD), but evaluating therapist fidelity remains\nlabor-intensive due to the need for manual review of session recordings. We\npresent a method for the automatic temporal localization of key PE fidelity\nelements -- identifying their start and stop times -- directly from session\naudio and transcripts. Our approach fine-tunes a large pre-trained\naudio-language model, Qwen2-Audio, using Low-Rank Adaptation (LoRA) to process\nfocused 30-second windows of audio-transcript input. Fidelity labels for three\ncore protocol phases -- therapist orientation (P1), imaginal exposure (P2), and\npost-imaginal processing (P3) -- are generated via LLM-based prompting and\nverified by trained raters. The model is trained to predict normalized boundary\noffsets using soft supervision guided by task-specific prompts. On a dataset of\n313 real PE sessions, our best configuration (LoRA rank 8, 30s windows)\nachieves a mean absolute error (MAE) of 5.3 seconds across tasks. We further\nanalyze the effects of window size and LoRA rank, highlighting the importance\nof context granularity and model adaptation. This work introduces a scalable\nframework for fidelity tracking in PE therapy, with potential to support\nclinician training, supervision, and quality assurance."}
{"id": "2506.09873", "pdf": "https://arxiv.org/pdf/2506.09873", "abs": "https://arxiv.org/abs/2506.09873", "authors": ["Emma Kallina", "Thomas Bohné", "Jat Singh"], "title": "Stakeholder Participation for Responsible AI Development: Disconnects Between Guidance and Current Practice", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "Published at the 2025 ACM Conference on Fairness, Accountability, and\n  Transparency FAccT'25", "summary": "Responsible AI (rAI) guidance increasingly promotes stakeholder involvement\n(SHI) during AI development. At the same time, SHI is already common in\ncommercial software development, but with potentially different foci. This\nstudy clarifies the extent to which established SHI practices are able to\ncontribute to rAI efforts as well as potential disconnects -- essential\ninsights to inform and tailor future interventions that further shift industry\npractice towards rAI efforts. First, we analysed 56 rAI guidance documents to\nidentify why SHI is recommended (i.e. its expected benefits for rAI) and\nuncovered goals such as redistributing power, improving socio-technical\nunderstandings, anticipating risks, and enhancing public oversight. To\nunderstand why and how SHI is currently practised in commercial settings, we\nthen conducted an online survey (n=130) and semi-structured interviews (n=10)\nwith AI practitioners. Our findings reveal that SHI in practice is primarily\ndriven by commercial priorities (e.g. customer value, compliance) and several\nfactors currently discourage more rAI-aligned SHI practices. This suggests that\nestablished SHI practices are largely not contributing to rAI efforts. To\naddress this disconnect, we propose interventions and research opportunities to\nadvance rAI development in practice."}
