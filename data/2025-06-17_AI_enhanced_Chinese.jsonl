{"id": "2506.12084", "pdf": "https://arxiv.org/pdf/2506.12084", "abs": "https://arxiv.org/abs/2506.12084", "authors": ["Michele Alberti", "Fran\u00e7ois Bobot", "Julien Girard-Satabin", "Alban Grastien", "Aymeric Varasse", "Zakaria Chihani"], "title": "The CAISAR Platform: Extending the Reach of Machine Learning Specification and Verification", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.FL", "cs.NE"], "comment": null, "summary": "The formal specification and verification of machine learning programs saw\nremarkable progress in less than a decade, leading to a profusion of tools.\nHowever, diversity may lead to fragmentation, resulting in tools that are\ndifficult to compare, except for very specific benchmarks. Furthermore, this\nprogress is heavily geared towards the specification and verification of a\ncertain class of property, that is, local robustness properties. But while\nprovers are becoming more and more efficient at solving local robustness\nproperties, even slightly more complex properties, involving multiple neural\nnetworks for example, cannot be expressed in the input languages of winners of\nthe International Competition of Verification of Neural Networks VNN-Comp. In\nthis tool paper, we present CAISAR, an open-source platform dedicated to\nmachine learning specification and verification. We present its specification\nlanguage, suitable for modelling complex properties on neural networks, support\nvector machines and boosted trees. We show on concrete use-cases how\nspecifications written in this language are automatically translated to queries\nto state-of-the-art provers, notably by using automated graph editing\ntechniques, making it possible to use their off-the-shelf versions. The\nartifact to reproduce the paper claims is available at the following DOI:\nhttps://doi.org/10.5281/zenodo.15209510", "AI": {"tldr": "CAISAR\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u673a\u5668\u5b66\u4e60\u89c4\u8303\u4e0e\u9a8c\u8bc1\u5e73\u53f0\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u5de5\u5177\u5728\u5904\u7406\u590d\u6742\u5c5e\u6027\u65f6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u7a0b\u5e8f\u7684\u89c4\u8303\u4e0e\u9a8c\u8bc1\u5de5\u5177\u5728\u5904\u7406\u590d\u6742\u5c5e\u6027\uff08\u5982\u6d89\u53ca\u591a\u4e2a\u795e\u7ecf\u7f51\u7edc\u7684\u5c5e\u6027\uff09\u65f6\u5b58\u5728\u8868\u8fbe\u80fd\u529b\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5f00\u53d1CAISAR\u5e73\u53f0\u53ca\u5176\u89c4\u8303\u8bed\u8a00\uff0c\u652f\u6301\u590d\u6742\u5c5e\u6027\u7684\u5efa\u6a21\uff0c\u5e76\u81ea\u52a8\u8f6c\u5316\u4e3a\u73b0\u6709\u8bc1\u660e\u5668\u7684\u67e5\u8be2\u3002", "result": "CAISAR\u80fd\u591f\u9ad8\u6548\u5904\u7406\u590d\u6742\u5c5e\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u7528\u4f8b\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "CAISAR\u4e3a\u673a\u5668\u5b66\u4e60\u89c4\u8303\u4e0e\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.12111", "pdf": "https://arxiv.org/pdf/2506.12111", "abs": "https://arxiv.org/abs/2506.12111", "authors": ["Oscar Boullosa Dapena"], "title": "Quantum-Inspired Differentiable Integral Neural Networks (QIDINNs): A Feynman-Based Architecture for Continuous Learning Over Streaming Data", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Real-time continuous learning over streaming data remains a central challenge\nin deep learning and AI systems. Traditional gradient-based models such as\nbackpropagation through time (BPTT) face computational and stability\nlimitations when dealing with temporally unbounded data. In this paper, we\nintroduce a novel architecture, Quantum-Inspired Differentiable Integral Neural\nNetworks (QIDINNs), which leverages the Feynman technique of differentiation\nunder the integral sign to formulate neural updates as integrals over\nhistorical data. This reformulation allows for smoother, more stable learning\ndynamics that are both physically interpretable and computationally tractable.\nInspired by Feynman's path integral formalism and compatible with quantum\ngradient estimation frameworks, QIDINNs open a path toward hybrid\nclassical-quantum neural computation. We demonstrate our model's effectiveness\non synthetic and real-world streaming tasks, and we propose directions for\nquantum extensions and scalable implementations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u67b6\u6784QIDINNs\uff0c\u901a\u8fc7\u79ef\u5206\u5386\u53f2\u6570\u636e\u5b9e\u73b0\u66f4\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u7684\u6d41\u6570\u636e\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u68af\u5ea6\u65b9\u6cd5\uff08\u5982BPTT\uff09\u5728\u5904\u7406\u6d41\u6570\u636e\u65f6\u7684\u8ba1\u7b97\u548c\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u8d39\u66fc\u79ef\u5206\u6280\u672f\uff0c\u5c06\u795e\u7ecf\u66f4\u65b0\u8868\u793a\u4e3a\u5386\u53f2\u6570\u636e\u7684\u79ef\u5206\uff0c\u63d0\u51faQIDINNs\u67b6\u6784\u3002", "result": "\u5728\u5408\u6210\u548c\u5b9e\u9645\u6d41\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u91cf\u5b50\u6269\u5c55\u65b9\u5411\u3002", "conclusion": "QIDINNs\u4e3a\u6df7\u5408\u7ecf\u5178-\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.12278", "pdf": "https://arxiv.org/pdf/2506.12278", "abs": "https://arxiv.org/abs/2506.12278", "authors": ["Zheyuan Yang", "Zexi Kuang", "Xue Xia", "Yilun Zhao"], "title": "Can LLMs Generate High-Quality Test Cases for Algorithm Problems? TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure", "categories": ["cs.SE", "cs.CL"], "comment": "ACL 2025", "summary": "We introduce TestCase-Eval, a new benchmark for systematic evaluation of LLMs\nin test-case generation. TestCase-Eval includes 500 algorithm problems and\n100,000 human-crafted solutions from the Codeforces platform. It focuses on two\npivotal tasks: (1) Fault Coverage, which measures how well LLM-generated test\nsets probe diverse input scenarios and cover a wide range of potential failure\nmodes. (2) Fault Exposure, which evaluates whether LLMs can craft a tailored\ntest input that reveals a specific incorrect code implementation. We provide a\ncomprehensive assessment of 19 state-of-the-art open-source and proprietary\nLLMs on TestCase-Eval, offering insights into their strengths and limitations\nin generating effective test cases for algorithm problems.", "AI": {"tldr": "TestCase-Eval \u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30 LLM \u5728\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u542b 500 \u4e2a\u7b97\u6cd5\u95ee\u9898\u548c 10 \u4e07\u4e2a\u4eba\u5de5\u7f16\u5199\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u91cd\u70b9\u5173\u6ce8\u6545\u969c\u8986\u76d6\u548c\u6545\u969c\u66b4\u9732\u4e24\u4e2a\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9 LLM \u5728\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4e2d\u8868\u73b0\u7684\u5168\u9762\u8bc4\u4f30\uff0cTestCase-Eval \u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e2e\u52a9\u7406\u89e3 LLM \u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u6765\u81ea Codeforces \u5e73\u53f0\u7684 500 \u4e2a\u7b97\u6cd5\u95ee\u9898\u548c 10 \u4e07\u4e2a\u4eba\u5de5\u89e3\u51b3\u65b9\u6848\uff0c\u8bc4\u4f30 19 \u79cd\u5f00\u6e90\u548c\u4e13\u6709 LLM \u5728\u6545\u969c\u8986\u76d6\u548c\u6545\u969c\u66b4\u9732\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9 19 \u79cd LLM \u7684\u7efc\u5408\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u751f\u6210\u6709\u6548\u6d4b\u8bd5\u7528\u4f8b\u65f6\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "TestCase-Eval \u4e3a LLM \u5728\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u7814\u7a76\u548c\u6539\u8fdb\u3002"}}
{"id": "2506.12320", "pdf": "https://arxiv.org/pdf/2506.12320", "abs": "https://arxiv.org/abs/2506.12320", "authors": ["Weipeng Jiang", "Xiaoyu Zhang", "Xiaofei Xie", "Jiongchi Yu", "Yuhan Zhi", "Shiqing Ma", "Chao Shen"], "title": "The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) libraries have emerged as the foundational\ninfrastructure powering today's AI revolution, serving as the backbone for LLM\ndeployment, inference optimization, fine-tuning, and production serving across\ndiverse applications. Despite their critical role in the LLM ecosystem, these\nlibraries face frequent quality issues and bugs that threaten the reliability\nof AI systems built upon them. To address this knowledge gap, we present the\nfirst comprehensive empirical investigation into bug characteristics and\ntesting practices in modern LLM libraries. We examine 313 bug-fixing commits\nextracted across two widely-adopted LLM libraries: HuggingFace Transformers and\nvLLM.Through rigorous manual analysis, we establish comprehensive taxonomies\ncategorizing bug symptoms into 5 types and root causes into 14 distinct\ncategories.Our primary discovery shows that API misuse has emerged as the\npredominant root cause (32.17%-48.19%), representing a notable transition from\nalgorithm-focused defects in conventional deep learning frameworks toward\ninterface-oriented problems. Additionally, we examine 7,748 test functions to\nidentify 7 distinct test oracle categories employed in current testing\napproaches, with predefined expected outputs (such as specific tensors and text\nstrings) being the most common strategy. Our assessment of existing testing\neffectiveness demonstrates that the majority of bugs escape detection due to\ninadequate test cases (41.73%), lack of test drivers (32.37%), and weak test\noracles (25.90%). Drawing from these findings, we offer some recommendations\nfor enhancing LLM library quality assurance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u73b0\u4ee3LLM\u5e93\u4e2d\u7684\u9519\u8bef\u7279\u5f81\u548c\u6d4b\u8bd5\u5b9e\u8df5\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e86313\u4e2a\u9519\u8bef\u4fee\u590d\u63d0\u4ea4\uff0c\u53d1\u73b0API\u6ee5\u7528\u662f\u4e3b\u8981\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6d4b\u8bd5\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "LLM\u5e93\u4f5c\u4e3aAI\u9769\u547d\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u5176\u8d28\u91cf\u95ee\u9898\u4e25\u91cd\u5f71\u54cd\u4e86\u4f9d\u8d56\u5b83\u4eec\u7684AI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5176\u9519\u8bef\u7279\u5f81\u548c\u6d4b\u8bd5\u5b9e\u8df5\u7684\u5168\u9762\u7814\u7a76\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u624b\u52a8\u5206\u6790313\u4e2a\u9519\u8bef\u4fee\u590d\u63d0\u4ea4\uff0c\u6db5\u76d6HuggingFace Transformers\u548cvLLM\u4e24\u4e2a\u4e3b\u6d41LLM\u5e93\uff0c\u5efa\u7acb\u9519\u8bef\u5206\u7c7b\u6cd5\uff0c\u5e76\u5ba1\u67e57,748\u4e2a\u6d4b\u8bd5\u51fd\u6570\u3002", "result": "API\u6ee5\u7528\u662f\u6700\u4e3b\u8981\u7684\u9519\u8bef\u6839\u6e90\uff0832.17%-48.19%\uff09\u3002\u73b0\u6709\u6d4b\u8bd5\u4e3b\u8981\u7f3a\u9677\u4e3a\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u8db3\uff0841.73%\uff09\u3001\u7f3a\u4e4f\u6d4b\u8bd5\u9a71\u52a8\uff0832.37%\uff09\u548c\u5f31\u6d4b\u8bd5\u9884\u8a00\uff0825.90%\uff09\u3002", "conclusion": "\u5efa\u8bae\u6539\u8fdb\u6d4b\u8bd5\u5b9e\u8df5\u4ee5\u63d0\u5347LLM\u5e93\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8\u63a5\u53e3\u95ee\u9898\u548c\u6d4b\u8bd5\u8986\u76d6\u3002"}}
{"id": "2506.13028", "pdf": "https://arxiv.org/pdf/2506.13028", "abs": "https://arxiv.org/abs/2506.13028", "authors": ["Bimal Raj Gyawali", "Saikrishna Achalla", "Konstantinos Kallas", "Sam Kumar"], "title": "NaSh: Guardrails for an LLM-Powered Natural Language Shell", "categories": ["cs.OS", "cs.AI"], "comment": "7 pages, 3 figures", "summary": "We explore how a shell that uses an LLM to accept natural language input\nmight be designed differently from the shells of today. As LLMs may produce\nunintended or unexplainable outputs, we argue that a natural language shell\nshould provide guardrails that empower users to recover from such errors. We\nconcretize some ideas for doing so by designing a new shell called NaSh,\nidentify remaining open problems in this space, and discuss research directions\nto address them.", "AI": {"tldr": "\u63a2\u8ba8\u5982\u4f55\u8bbe\u8ba1\u4e00\u79cd\u4f7f\u7528LLM\u63a5\u53d7\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u7684\u65b0\u5f0fshell\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aNaSh\u7684\u8bbe\u8ba1\u539f\u578b\u3002", "motivation": "\u5f53\u524dshell\u4e0eLLM\u7ed3\u5408\u65f6\u53ef\u80fd\u4ea7\u751f\u4e0d\u53ef\u63a7\u6216\u96be\u4ee5\u89e3\u91ca\u7684\u8f93\u51fa\uff0c\u9700\u63d0\u4f9b\u4fdd\u969c\u63aa\u65bd\u5e2e\u52a9\u7528\u6237\u4ece\u9519\u8bef\u4e2d\u6062\u590d\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u65b0\u7684shell\uff08NaSh\uff09\uff0c\u5177\u4f53\u5316\u4e86\u76f8\u5173\u60f3\u6cd5\uff0c\u5e76\u8bc6\u522b\u4e86\u8be5\u9886\u57df\u7684\u672a\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86NaSh\u8bbe\u8ba1\u539f\u578b\uff0c\u8ba8\u8bba\u4e86\u81ea\u7136\u8bed\u8a00shell\u7684\u6f5c\u5728\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00shell\u9700\u8981\u66f4\u591a\u7814\u7a76\u6765\u89e3\u51b3\u5176\u8f93\u51fa\u4e0d\u53ef\u63a7\u7684\u95ee\u9898\uff0cNaSh\u662f\u4e00\u4e2a\u521d\u6b65\u5c1d\u8bd5\u3002"}}
{"id": "2506.12269", "pdf": "https://arxiv.org/pdf/2506.12269", "abs": "https://arxiv.org/abs/2506.12269", "authors": ["Babak Naderi", "Ross Cutler", "Juhee Cho", "Nabakumar Khongbantabam", "Dejan Ivkovic"], "title": "ICME 2025 Grand Challenge on Video Super-Resolution for Video Conferencing", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": null, "summary": "Super-Resolution (SR) is a critical task in computer vision, focusing on\nreconstructing high-resolution (HR) images from low-resolution (LR) inputs. The\nfield has seen significant progress through various challenges, particularly in\nsingle-image SR. Video Super-Resolution (VSR) extends this to the temporal\ndomain, aiming to enhance video quality using methods like local, uni-,\nbi-directional propagation, or traditional upscaling followed by restoration.\nThis challenge addresses VSR for conferencing, where LR videos are encoded with\nH.265 at fixed QPs. The goal is to upscale videos by a specific factor,\nproviding HR outputs with enhanced perceptual quality under a low-delay\nscenario using causal models. The challenge included three tracks:\ngeneral-purpose videos, talking head videos, and screen content videos, with\nseparate datasets provided by the organizers for training, validation, and\ntesting. We open-sourced a new screen content dataset for the SR task in this\nchallenge. Submissions were evaluated through subjective tests using a\ncrowdsourced implementation of the ITU-T Rec P.910.", "AI": {"tldr": "\u8bba\u6587\u6458\u8981\u4ecb\u7ecd\u4e86\u89c6\u9891\u8d85\u5206\u8fa8\u7387\uff08VSR\uff09\u6280\u672f\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4f1a\u8bae\u573a\u666f\u7684\u4f4e\u5206\u8fa8\u7387\u89c6\u9891\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4f4e\u5ef6\u8fdf\u60c5\u51b5\u4e0b\u4f7f\u7528\u56e0\u679c\u6a21\u578b\u589e\u5f3a\u89c6\u9891\u611f\u77e5\u8d28\u91cf\u7684\u65b9\u6cd5\u3002", "motivation": "\u89c6\u9891\u8d85\u5206\u8fa8\u7387\u6280\u672f\u5728\u4f1a\u8bae\u7b49\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\uff0c\u80fd\u591f\u4ece\u4f4e\u5206\u8fa8\u7387\u89c6\u9891\u4e2d\u6062\u590d\u9ad8\u8d28\u91cf\u56fe\u50cf\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86\u5c40\u90e8\u3001\u5355\u5411\u3001\u53cc\u5411\u4f20\u64ad\u6216\u4f20\u7edf\u4e0a\u91c7\u6837\u540e\u6062\u590d\u7b49\u65b9\u6cd5\uff0c\u9488\u5bf9H.265\u7f16\u7801\u7684\u56fa\u5b9aQP\u4f4e\u5206\u8fa8\u7387\u89c6\u9891\u8fdb\u884c\u4e0a\u91c7\u6837\u3002", "result": "\u7814\u7a76\u4e2d\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5c4f\u5e55\u5185\u5bb9\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u4e3b\u89c2\u6d4b\u8bd5\uff08\u57fa\u4e8eITU-T Rec P.910\u7684\u4f17\u5305\u5b9e\u73b0\uff09\u5bf9\u63d0\u4ea4\u7ed3\u679c\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6311\u6218\u5c55\u793a\u4e86\u89c6\u9891\u8d85\u5206\u8fa8\u7387\u6280\u672f\u5728\u4f4e\u5ef6\u8fdf\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.12461", "pdf": "https://arxiv.org/pdf/2506.12461", "abs": "https://arxiv.org/abs/2506.12461", "authors": ["Zhiyi Zhu", "Eiji Takimoto", "Patrick Finnertyn", "Junjun Zheng", "Shoma Suzuki", "Chikara Ohta"], "title": "NR Cell Identity-based Handover Decision-making Algorithm for High-speed Scenario within Dual Connectivity", "categories": ["cs.NI", "cs.PF"], "comment": null, "summary": "The dense deployment of 5G heterogeneous networks (HetNets) has improved\nnetwork capacity. However, it also brings frequent and unnecessary handover\nchallenges to high-speed mobile user equipment (UE), resulting in unstable\ncommunication and degraded quality of service. Traditional handovers ignore the\ntype of target next-generation Node B (gNB), resulting in high-speed UEs being\nable to be handed over to any gNB. This paper proposes a NR cell identity\n(NCI)-based handover decision-making algorithm (HDMA) to address this issue.\nThe proposed HDMA identifies the type of the target gNB (macro/small/mmWave\ngNB) using the gNB identity (ID) within the NCI to improve the handover\ndecision-making strategy. The proposed HDMA aims to improve the communication\nstability of high-speed mobile UE by enabling high-speed UEs to identify the\ntarget gNB type during the HDMA using the gNB ID. Simulation results show that\nthe proposed HDMA outperforms other HDMAs in enhanced connection stability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eNR\u5c0f\u533a\u8eab\u4efd\uff08NCI\uff09\u7684\u5207\u6362\u51b3\u7b56\u7b97\u6cd5\uff08HDMA\uff09\uff0c\u901a\u8fc7\u8bc6\u522b\u76ee\u6807gNB\u7c7b\u578b\uff08\u5b8f/\u5c0f/\u6beb\u7c73\u6ce2gNB\uff09\u6765\u6539\u8fdb\u5207\u6362\u7b56\u7565\uff0c\u63d0\u5347\u9ad8\u901f\u79fb\u52a8\u7528\u6237\u8bbe\u5907\u7684\u901a\u4fe1\u7a33\u5b9a\u6027\u3002", "motivation": "5G\u5f02\u6784\u7f51\u7edc\u7684\u5bc6\u96c6\u90e8\u7f72\u867d\u7136\u63d0\u5347\u4e86\u7f51\u7edc\u5bb9\u91cf\uff0c\u4f46\u4e5f\u5bfc\u81f4\u9ad8\u901f\u79fb\u52a8\u8bbe\u5907\u9891\u7e41\u548c\u4e0d\u5fc5\u8981\u7684\u5207\u6362\uff0c\u5f71\u54cd\u901a\u4fe1\u7a33\u5b9a\u6027\u3002\u4f20\u7edf\u5207\u6362\u7b97\u6cd5\u5ffd\u7565\u76ee\u6807gNB\u7c7b\u578b\uff0c\u5bfc\u81f4\u95ee\u9898\u52a0\u5267\u3002", "method": "\u63d0\u51faHDMA\u7b97\u6cd5\uff0c\u5229\u7528NCI\u4e2d\u7684gNB\u8eab\u4efd\uff08ID\uff09\u8bc6\u522b\u76ee\u6807gNB\u7c7b\u578b\uff08\u5b8f/\u5c0f/\u6beb\u7c73\u6ce2\uff09\uff0c\u6539\u8fdb\u5207\u6362\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0HDMA\u5728\u63d0\u5347\u8fde\u63a5\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u5207\u6362\u7b97\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u76ee\u6807gNB\u7c7b\u578b\uff0cHDMA\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u901f\u79fb\u52a8\u8bbe\u5907\u7684\u5207\u6362\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u901a\u4fe1\u7a33\u5b9a\u6027\u3002"}}
{"id": "2506.13491", "pdf": "https://arxiv.org/pdf/2506.13491", "abs": "https://arxiv.org/abs/2506.13491", "authors": ["Tobias G\u00fcrtler", "Benjamin Lucien Kaminski"], "title": "Programming and Reasoning in Partially Observable Probabilistic Environments", "categories": ["cs.LO"], "comment": "54 pages, 6 figures, to be published in QEST + FORMATS 2025", "summary": "Probabilistic partial observability is a phenomenon occuring when computer\nsystems are deployed in environments that behave probabilistically and whose\nexact state cannot be fully observed. In this work, we lay the theoretical\ngroundwork for a probabilistic belief programming language pBLIMP, which\nmaintains a probability distribution over the possible environment states,\ncalled a belief state. pBLIMP has language features to symbolically model the\nbehavior of and interaction with the partially observable environment and to\ncondition the belief state based on explicit observations. In particular,\npBLIMP programs can perform state estimation and base their decisions (i.e. the\ncontrol flow) on the likelihood that certain conditions hold in the current\nstate. Furthermore, pBLIMP features unbounded loops, which sets it apart from\nmany other probabilistic programming languages. For reasoning about pBLIMP\nprograms and the situations they model, we present a weakest-precondition-style\ncalculus (wp) that is capable of reasoning about unbounded loops. Soundness of\nour wp calculus is proven with respect to an operational semantics. We further\ndemonstrate how our wp calculus reasons about (unbounded) loops with loop\ninvariants.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u6982\u7387\u4fe1\u5ff5\u7f16\u7a0b\u8bed\u8a00pBLIMP\uff0c\u7528\u4e8e\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u6982\u7387\u884c\u4e3a\uff0c\u652f\u6301\u72b6\u6001\u4f30\u8ba1\u548c\u57fa\u4e8e\u5faa\u73af\u4e0d\u53d8\u91cf\u7684\u65e0\u754c\u5faa\u73af\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u8ba1\u7b97\u673a\u7cfb\u7edf\u5728\u6982\u7387\u6027\u4e14\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u73af\u5883\u4e2d\u8fd0\u884c\u65f6\u7684\u7406\u8bba\u5efa\u6a21\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1pBLIMP\u8bed\u8a00\uff0c\u5305\u542b\u7b26\u53f7\u5efa\u6a21\u3001\u89c2\u5bdf\u6761\u4ef6\u548c\u65e0\u754c\u5faa\u73af\u7279\u6027\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6700\u5f31\u524d\u63d0\u6761\u4ef6\u7684\u6f14\u7b97\u65b9\u6cd5\uff08wp\uff09\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86wp\u6f14\u7b97\u76f8\u5bf9\u4e8e\u64cd\u4f5c\u8bed\u4e49\u7684\u6b63\u786e\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5904\u7406\u65e0\u754c\u5faa\u73af\u3002", "conclusion": "pBLIMP\u548cwp\u6f14\u7b97\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u7a0b\u5e8f\u63a8\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\u652f\u6301\u3002"}}
{"id": "2506.12202", "pdf": "https://arxiv.org/pdf/2506.12202", "abs": "https://arxiv.org/abs/2506.12202", "authors": ["Stephen Mell", "Botong Zhang", "David Mell", "Shuo Li", "Ramya Ramalingam", "Nathan Yu", "Steve Zdancewic", "Osbert Bastani"], "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "categories": ["cs.PL", "cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "Modern large language models (LLMs) are often deployed as agents, calling\nexternal tools adaptively to solve tasks. Rather than directly calling tools,\nit can be more effective for LLMs to write code to perform the tool calls,\nenabling them to automatically generate complex control flow such as\nconditionals and loops. Such code actions are typically provided as Python\ncode, since LLMs are quite proficient at it; however, Python may not be the\nideal language due to limited built-in support for performance, security, and\nreliability. We propose a novel programming language for code actions, called\nQuasar, which has several benefits: (1) automated parallelization to improve\nperformance, (2) uncertainty quantification to improve reliability and mitigate\nhallucinations, and (3) security features enabling the user to validate\nactions. LLMs can write code in a subset of Python, which is automatically\ntranspiled to Quasar. We evaluate our approach on the ViperGPT visual question\nanswering agent, applied to the GQA dataset, demonstrating that LLMs with\nQuasar actions instead of Python actions retain strong performance, while\nreducing execution time when possible by 42%, improving security by reducing\nuser approval interactions when possible by 52%, and improving reliability by\napplying conformal prediction to achieve a desired target coverage level.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuasar\u7684\u65b0\u7f16\u7a0b\u8bed\u8a00\uff0c\u7528\u4e8eLLMs\u751f\u6210\u4ee3\u7801\u52a8\u4f5c\uff0c\u4ee5\u63d0\u9ad8\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "LLMs\u901a\u5e38\u4ee5Python\u751f\u6210\u4ee3\u7801\u52a8\u4f5c\uff0c\u4f46Python\u5728\u6027\u80fd\u3001\u5b89\u5168\u548c\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faQuasar\u8bed\u8a00\uff0c\u652f\u6301\u81ea\u52a8\u5e76\u884c\u5316\u3001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u5b89\u5168\u6027\u9a8c\u8bc1\uff0c\u5e76\u5c06Python\u5b50\u96c6\u81ea\u52a8\u8f6c\u6362\u4e3aQuasar\u3002", "result": "\u5728ViperGPT\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cQuasar\u5c06\u6267\u884c\u65f6\u95f4\u51cf\u5c1142%\uff0c\u7528\u6237\u4ea4\u4e92\u51cf\u5c1152%\uff0c\u5e76\u901a\u8fc7\u5171\u5f62\u9884\u6d4b\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "conclusion": "Quasar\u80fd\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347LLMs\u4ee3\u7801\u52a8\u4f5c\u7684\u5b89\u5168\u6027\u3001\u53ef\u9760\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.12348", "pdf": "https://arxiv.org/pdf/2506.12348", "abs": "https://arxiv.org/abs/2506.12348", "authors": ["Zaiqiang Wu", "I-Chao Shen", "Takeo Igarashi"], "title": "Real-Time Per-Garment Virtual Try-On with Temporal Consistency for Loose-Fitting Garments", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Per-garment virtual try-on methods collect garment-specific datasets and\ntrain networks tailored to each garment to achieve superior results. However,\nthese approaches often struggle with loose-fitting garments due to two key\nlimitations: (1) They rely on human body semantic maps to align garments with\nthe body, but these maps become unreliable when body contours are obscured by\nloose-fitting garments, resulting in degraded outcomes; (2) They train garment\nsynthesis networks on a per-frame basis without utilizing temporal information,\nleading to noticeable jittering artifacts. To address these challenges, we\npropose a two-stage approach for robust semantic map estimation. First, we\nextract a garment-invariant representation from the raw input image. This\nrepresentation is then passed through an auxiliary network to estimate the\nsemantic map. This enhances the robustness of semantic map estimation under\nloose-fitting garments during garment-specific dataset generation. Furthermore,\nwe introduce a recurrent garment synthesis framework that incorporates temporal\ndependencies to improve frame-to-frame coherence while maintaining real-time\nperformance. We conducted qualitative and quantitative evaluations to\ndemonstrate that our method outperforms existing approaches in both image\nquality and temporal coherence. Ablation studies further validate the\neffectiveness of the garment-invariant representation and the recurrent\nsynthesis framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u5bbd\u677e\u670d\u88c5\u865a\u62df\u8bd5\u7a7f\u7684\u8bed\u4e49\u56fe\u4f30\u8ba1\u548c\u5408\u6210\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u56fe\u50cf\u8d28\u91cf\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5bbd\u677e\u670d\u88c5\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u5176\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684\u8bed\u4e49\u56fe\u548c\u5ffd\u7565\u65f6\u95f4\u4fe1\u606f\uff0c\u5bfc\u81f4\u7ed3\u679c\u5dee\u548c\u6296\u52a8\u3002", "method": "\u4f7f\u7528\u670d\u88c5\u65e0\u5173\u8868\u793a\u589e\u5f3a\u8bed\u4e49\u56fe\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5f15\u5165\u5305\u542b\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u5faa\u73af\u5408\u6210\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u5728\u56fe\u50cf\u8d28\u91cf\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6d88\u878d\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u89e3\u51b3\u4e86\u5bbd\u677e\u670d\u88c5\u865a\u62df\u8bd5\u7a7f\u7684\u5173\u952e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u679c\u548c\u6548\u7387\u3002"}}
{"id": "2506.12070", "pdf": "https://arxiv.org/pdf/2506.12070", "abs": "https://arxiv.org/abs/2506.12070", "authors": ["Thomas Hoger", "Philippe Owezarski"], "title": "Multi-domain anomaly detection in a 5G network", "categories": ["cs.NI", "cs.CR"], "comment": "in French language. Rendez-vous de la Recherche et de l'Enseignement\n  de la S{\\'e}curit{\\'e} des Syst{\\`e}mes d'Information (RESSI), May 2025,\n  Quimper, France", "summary": "With the advent of 5G, mobile networks are becoming more dynamic and will\ntherefore present a wider attack surface. To secure these new systems, we\npropose a multi-domain anomaly detection method that is distinguished by the\nstudy of traffic correlation on three dimensions: temporal by analyzing message\nsequences, semantic by abstracting the parameters these messages contain, and\ntopological by linking them in the form of a graph. Unlike traditional\napproaches, which are limited to considering these domains independently, our\nmethod studies their correlations to obtain a global, coherent and explainable\nview of anomalies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u7ef4\u5ea6\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u65f6\u95f4\u3001\u8bed\u4e49\u548c\u62d3\u6251\u5206\u67905G\u7f51\u7edc\u5b89\u5168\u3002", "motivation": "5G\u7f51\u7edc\u7684\u52a8\u6001\u6027\u589e\u52a0\u4e86\u653b\u51fb\u9762\uff0c\u9700\u66f4\u5168\u9762\u7684\u5b89\u5168\u9632\u62a4\u3002", "method": "\u7814\u7a76\u6d88\u606f\u5e8f\u5217\uff08\u65f6\u95f4\uff09\u3001\u53c2\u6570\uff08\u8bed\u4e49\uff09\u548c\u56fe\u5f62\u5316\u94fe\u63a5\uff08\u62d3\u6251\uff09\u7684\u5173\u8054\u3002", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u80fd\u63d0\u4f9b\u5168\u5c40\u3001\u4e00\u81f4\u4e14\u53ef\u89e3\u91ca\u7684\u5f02\u5e38\u89c6\u56fe\u3002", "conclusion": "\u591a\u7ef4\u5ea6\u5173\u8054\u5206\u6790\u63d0\u5347\u4e865G\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u7684\u6548\u679c\u3002"}}
{"id": "2506.12244", "pdf": "https://arxiv.org/pdf/2506.12244", "abs": "https://arxiv.org/abs/2506.12244", "authors": ["Paul van Schaik", "Karen Renaud"], "title": "Extended Version of Paper Presented at ICISSP, Porto 20-22 February, 2025 A Value-Driven Approach to the Online Consent Conundrum -- A Study with the Unemployed", "categories": ["cs.HC", "H.4.0 General"], "comment": "Extended Version of ICISSP 2025 Paper", "summary": "Online services are required to gain informed consent from users to collect,\nstore and analyse their personal data, both intentionally divulged and derived\nduring their use of the service. There are many issues with these forms: they\nare too long, too complex and demand the user's attention too frequently. Many\nusers consent without reading so do not know what they are agreeing to. As\nsuch,granted consent is effectively uninformed. In this paper, we report on two\nstudies we carried out to arrive at a value-driven approach to inform efforts\nto reduce the length of consent forms. The first study interviewed unemployed\nusers to identify the values they want these forms to satisfy. The second\nsurvey study helped us to quantify the values and value creators. To ensure\nthat we understood the particular valuation of the unemployed, we compared\ntheir responses to those of an employed demographic and observed no significant\ndifferences between their prioritisation on any of the values. However, we did\nfind substantial differences between values and value creators, with effort\nminimisation being most valued by our participants.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u4e24\u9879\u7814\u7a76\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u4ef7\u503c\u9a71\u52a8\u7684\u65b9\u6cd5\u7b80\u5316\u5197\u957f\u7684\u540c\u610f\u8868\u5355\uff0c\u53d1\u73b0\u7528\u6237\u6700\u91cd\u89c6\u7684\u662f\u51cf\u5c11\u52aa\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u5728\u7ebf\u670d\u52a1\u540c\u610f\u8868\u5355\u8fc7\u4e8e\u5197\u957f\u548c\u590d\u6742\uff0c\u5bfc\u81f4\u7528\u6237\u7ecf\u5e38\u672a\u7ecf\u9605\u8bfb\u5373\u540c\u610f\uff0c\u4f7f\u5f97\u540c\u610f\u5b9e\u9645\u4e0a\u662f\u975e\u77e5\u60c5\u540c\u610f\u3002", "method": "\u8fdb\u884c\u4e86\u4e24\u9879\u7814\u7a76\uff1a1\uff09\u91c7\u8bbf\u5931\u4e1a\u7528\u6237\u4ee5\u8bc6\u522b\u4ed6\u4eec\u5e0c\u671b\u8868\u5355\u6ee1\u8db3\u7684\u4ef7\u503c\u89c2\uff1b2\uff09\u901a\u8fc7\u8c03\u67e5\u91cf\u5316\u8fd9\u4e9b\u4ef7\u503c\u89c2\u53ca\u5176\u5b9e\u73b0\u65b9\u5f0f\u3002", "result": "\u5931\u4e1a\u7528\u6237\u548c\u5c31\u4e1a\u7528\u6237\u5728\u4ef7\u503c\u89c2\u4f18\u5148\u987a\u5e8f\u4e0a\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u53d1\u73b0\u4ef7\u503c\u89c2\u4e0e\u5b9e\u73b0\u65b9\u5f0f\u4e4b\u95f4\u5b58\u5728\u8f83\u5927\u5dee\u5f02\uff0c\u7528\u6237\u6700\u91cd\u89c6\u51cf\u5c11\u52aa\u529b\u3002", "conclusion": "\u7814\u7a76\u652f\u6301\u901a\u8fc7\u4ef7\u503c\u9a71\u52a8\u7684\u65b9\u6cd5\u7b80\u5316\u540c\u610f\u8868\u5355\uff0c\u5c24\u5176\u662f\u51cf\u5c11\u7528\u6237\u7684\u52aa\u529b\u3002"}}
{"id": "2506.12234", "pdf": "https://arxiv.org/pdf/2506.12234", "abs": "https://arxiv.org/abs/2506.12234", "authors": ["Tetiana Gladkykh", "Kyrylo Kirykov"], "title": "Datrics Text2SQL: A Framework for Natural Language to SQL Query Generation", "categories": ["cs.DB", "cs.AI", "cs.CL", "H.2.3; I.2.7"], "comment": "28 pages, 6 figures, initial whitepaper version 1.0, submitted March\n  2025", "summary": "Text-to-SQL systems enable users to query databases using natural language,\ndemocratizing access to data analytics. However, they face challenges in\nunderstanding ambiguous phrasing, domain-specific vocabulary, and complex\nschema relationships. This paper introduces Datrics Text2SQL, a\nRetrieval-Augmented Generation (RAG)-based framework designed to generate\naccurate SQL queries by leveraging structured documentation, example-based\nlearning, and domain-specific rules. The system builds a rich Knowledge Base\nfrom database documentation and question-query examples, which are stored as\nvector embeddings and retrieved through semantic similarity. It then uses this\ncontext to generate syntactically correct and semantically aligned SQL code.\nThe paper details the architecture, training methodology, and retrieval logic,\nhighlighting how the system bridges the gap between user intent and database\nstructure without requiring SQL expertise.", "AI": {"tldr": "Datrics Text2SQL\u662f\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u5229\u7528\u7ed3\u6784\u5316\u6587\u6863\u3001\u57fa\u4e8e\u793a\u4f8b\u7684\u5b66\u4e60\u548c\u9886\u57df\u7279\u5b9a\u89c4\u5219\u751f\u6210\u51c6\u786e\u7684SQL\u67e5\u8be2\u3002", "motivation": "\u89e3\u51b3\u6587\u672c\u5230SQL\u7cfb\u7edf\u4e2d\u6a21\u7cca\u8868\u8fbe\u3001\u9886\u57df\u7279\u5b9a\u8bcd\u6c47\u548c\u590d\u6742\u6a21\u5f0f\u5173\u7cfb\u7684\u6311\u6218\uff0c\u8ba9\u975eSQL\u4e13\u5bb6\u80fd\u591f\u8f7b\u677e\u67e5\u8be2\u6570\u636e\u5e93\u3002", "method": "\u7cfb\u7edf\u6784\u5efa\u4e86\u4e00\u4e2a\u4e30\u5bcc\u7684\u77e5\u8bc6\u5e93\uff0c\u5305\u542b\u6570\u636e\u5e93\u6587\u6863\u548c\u67e5\u8be2\u793a\u4f8b\uff0c\u8fd9\u4e9b\u5185\u5bb9\u4ee5\u5411\u91cf\u5d4c\u5165\u5f62\u5f0f\u5b58\u50a8\u5e76\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u6027\u68c0\u7d22\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u4e14\u8bed\u4e49\u5bf9\u9f50\u7684SQL\u4ee3\u7801\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u8fde\u63a5\u7528\u6237\u610f\u56fe\u548c\u6570\u636e\u5e93\u7ed3\u6784\uff0c\u751f\u6210\u9ad8\u8d28\u91cfSQL\u67e5\u8be2\u3002", "conclusion": "Datrics Text2SQL\u586b\u8865\u4e86\u975eSQL\u4e13\u5bb6\u4e0e\u6570\u636e\u5e93\u67e5\u8be2\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u901a\u8fc7RAG\u6846\u67b6\u63d0\u5347\u4e86\u67e5\u8be2\u7684\u51c6\u786e\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2506.12210", "pdf": "https://arxiv.org/pdf/2506.12210", "abs": "https://arxiv.org/abs/2506.12210", "authors": ["Sri Krishna Vadlamani", "Kfir Sulimany", "Zhihui Gao", "Tingjun Chen", "Dirk Englund"], "title": "Machine Intelligence on Wireless Edge Networks", "categories": ["cs.ET", "cs.LG"], "comment": "13 pages, 6 figures", "summary": "Deep neural network (DNN) inference on power-constrained edge devices is\nbottlenecked by costly weight storage and data movement. We introduce MIWEN, a\nradio-frequency (RF) analog architecture that ``disaggregates'' memory by\nstreaming weights wirelessly and performing classification in the analog front\nend of standard transceivers. By encoding weights and activations onto RF\ncarriers and using native mixers as computation units, MIWEN eliminates local\nweight memory and the overhead of analog-to-digital and digital-to-analog\nconversion. We derive the effective number of bits of radio-frequency analog\ncomputation under thermal noise, quantify the energy--precision trade-off, and\ndemonstrate digital-comparable MNIST accuracy at orders-of-magnitude lower\nenergy, unlocking real-time inference on low-power, memory-free edge devices.", "AI": {"tldr": "MIWEN\u662f\u4e00\u79cdRF\u6a21\u62df\u67b6\u6784\uff0c\u901a\u8fc7\u65e0\u7ebf\u4f20\u8f93\u6743\u91cd\u5e76\u5728\u6a21\u62df\u524d\u7aef\u6267\u884c\u5206\u7c7b\uff0c\u89e3\u51b3\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e2dDNN\u63a8\u7406\u7684\u5b58\u50a8\u548c\u80fd\u8017\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u4e2d\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u56e0\u6743\u91cd\u5b58\u50a8\u548c\u6570\u636e\u79fb\u52a8\u5bfc\u81f4\u7684\u80fd\u8017\u95ee\u9898\u3002", "method": "\u5229\u7528RF\u6a21\u62df\u67b6\u6784\uff0c\u901a\u8fc7\u65e0\u7ebf\u4f20\u8f93\u6743\u91cd\u5e76\u4f7f\u7528\u6a21\u62df\u524d\u7aef\u8fdb\u884c\u63a8\u7406\uff0c\u907f\u514d\u672c\u5730\u5b58\u50a8\u548c\u6570\u5b57\u8f6c\u6362\u3002", "result": "\u5728\u4f4e\u80fd\u8017\u4e0b\u5b9e\u73b0\u4e0e\u6570\u5b57\u65b9\u6cd5\u76f8\u5f53\u7684MNIST\u5206\u7c7b\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u4f4e\u529f\u8017\u8fb9\u7f18\u8bbe\u5907\u3002", "conclusion": "MIWEN\u901a\u8fc7RF\u6a21\u62df\u8ba1\u7b97\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u672c\u5730\u5b58\u50a8\u7684\u9ad8\u6548\u8fb9\u7f18\u63a8\u7406\u3002"}}
{"id": "2506.12359", "pdf": "https://arxiv.org/pdf/2506.12359", "abs": "https://arxiv.org/abs/2506.12359", "authors": ["Ruby Kumari", "Tapas Rout", "Babul Saini", "Jai Gopal Pandey", "Abhijit Karmakar"], "title": "An Efficient Hardware Implementation of Elliptic Curve Point Multiplication over $GF(2^m)$ on FPGA", "categories": ["cs.AR"], "comment": null, "summary": "Elliptic Curve Cryptography (ECC) is widely accepted for ensuring secure data\nexchange between resource-limited IoT devices. The National Institute of\nStandards and Technology (NIST) recommended implementation, such as B-163, is\nparticularly well-suited for Internet of Things (IoT) applications. Here,\nElliptic Curve Point Multiplication (ECPM) is the most time-critical and\nresource-intensive operation due to the finite field multiplier. This paper\nproposes a new implementation method of finite field multiplication using a\nhybrid Karatsuba multiplier, which achieves a significant improvement in\ncomputation time while maintaining a reasonable area footprint. The proposed\nmultiplier, along with a finite field adder, squarer, and extended Euclidean\ninversion circuit, is used to implement an architecture for ECPM using the\nMontgomery algorithm. The architecture is evaluated for $GF(2^{163})$ on the\nXilinx Virtex-7 FPGA platform, achieving a maximum frequency of 213~MHz and\noccupying 14,195 Lookup Tables (LUTs). The results demonstrate a significant\nspeedup in computation time and overall performance compared to other reported\ndesigns.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408Karatsuba\u4e58\u6cd5\u5668\u7684\u6709\u9650\u57df\u4e58\u6cd5\u65b0\u5b9e\u73b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86ECC\u7684\u8ba1\u7b97\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5408\u7406\u7684\u786c\u4ef6\u8d44\u6e90\u5360\u7528\u3002", "motivation": "\u692d\u5706\u66f2\u7ebf\u5bc6\u7801\u5b66\uff08ECC\uff09\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT\u8bbe\u5907\u4e2d\u5e38\u7528\u4e8e\u5b89\u5168\u6570\u636e\u4ea4\u6362\uff0c\u800c\u6709\u9650\u57df\u4e58\u6cd5\u662f\u5176\u6838\u5fc3\u64cd\u4f5c\uff0c\u4f18\u5316\u5176\u6027\u80fd\u5bf9\u63d0\u5347ECC\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u6df7\u5408Karatsuba\u4e58\u6cd5\u5668\u5b9e\u73b0\u6709\u9650\u57df\u4e58\u6cd5\uff0c\u7ed3\u5408\u6709\u9650\u57df\u52a0\u6cd5\u5668\u3001\u5e73\u65b9\u5668\u548c\u6269\u5c55\u6b27\u51e0\u91cc\u5f97\u53cd\u6f14\u7535\u8def\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8eMontgomery\u7b97\u6cd5\u7684ECPM\u67b6\u6784\u3002", "result": "\u5728Xilinx Virtex-7 FPGA\u4e0a\u5b9e\u73b0\u4e86GF(2^163)\u7684ECPM\u67b6\u6784\uff0c\u6700\u5927\u9891\u7387\u8fbe\u5230213 MHz\uff0c\u5360\u752814,195 LUT\uff0c\u8ba1\u7b97\u901f\u5ea6\u548c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u8bbe\u8ba1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408Karatsuba\u4e58\u6cd5\u5668\u65b9\u6cd5\u5728ECC\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u8ba1\u7b97\uff0c\u4e3aIoT\u5e94\u7528\u63d0\u4f9b\u4e86\u4f18\u5316\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12282", "pdf": "https://arxiv.org/pdf/2506.12282", "abs": "https://arxiv.org/abs/2506.12282", "authors": ["Hugo Mirault", "Peter Robinson"], "title": "Towards Energy-Efficient Distributed Agreement", "categories": ["cs.DC", "cs.DS"], "comment": "To appear at PODC 2025 as brief announcement", "summary": "We study fault-tolerant consensus in a variant of the synchronous message\npassing model, where, in each round, every node can choose to be awake or\nasleep. This is known as the sleeping model (Chatterjee, Gmyr, Pandurangan PODC\n2020) and defines the awake complexity (also called \\emph{energy complexity}),\nwhich measures the maximum number of rounds that any node is awake throughout\nthe execution. Only awake nodes can send and receive messages in a given round\nand all messages sent to sleeping nodes are lost. We present new deterministic\nconsensus algorithms that tolerate up to $f<n$ crash failures, where $n$ is the\nnumber of nodes. Our algorithms match the optimal time complexity lower bound\nof $f+1$ rounds. For multi-value consensus, where the input values are chosen\nfrom some possibly large set, we achieve an energy complexity of ${O}(\\lceil\nf^2 / n \\rceil)$ rounds, whereas for binary consensus, we show that ${O}(\\lceil\nf / \\sqrt{n} \\rceil)$ rounds are possible.", "AI": {"tldr": "\u7814\u7a76\u5728\u540c\u6b65\u6d88\u606f\u4f20\u9012\u6a21\u578b\u4e2d\uff0c\u8282\u70b9\u53ef\u4ee5\u9009\u62e9\u5524\u9192\u6216\u4f11\u7720\u60c5\u51b5\u4e0b\u7684\u5bb9\u9519\u5171\u8bc6\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u7684\u786e\u5b9a\u6027\u5171\u8bc6\u7b97\u6cd5\uff0c\u5339\u914d\u6700\u4f18\u65f6\u95f4\u590d\u6742\u6027\u4e0b\u9650\uff0c\u5e76\u5206\u522b\u9488\u5bf9\u591a\u503c\u548c\u4e8c\u8fdb\u5236\u5171\u8bc6\u4f18\u5316\u4e86\u80fd\u91cf\u590d\u6742\u6027\u3002", "motivation": "\u63a2\u7d22\u5728\u8282\u70b9\u53ef\u4f11\u7720\u7684\u540c\u6b65\u6d88\u606f\u4f20\u9012\u6a21\u578b\u4e2d\uff0c\u5982\u4f55\u9ad8\u6548\u5b9e\u73b0\u5bb9\u9519\u5171\u8bc6\uff0c\u4ee5\u964d\u4f4e\u80fd\u91cf\u6d88\u8017\u3002", "method": "\u63d0\u51fa\u786e\u5b9a\u6027\u5171\u8bc6\u7b97\u6cd5\uff0c\u5bb9\u5fcd\u6700\u591af<n\u7684\u5d29\u6e83\u6545\u969c\uff0c\u9488\u5bf9\u591a\u503c\u548c\u4e8c\u8fdb\u5236\u5171\u8bc6\u5206\u522b\u4f18\u5316\u80fd\u91cf\u590d\u6742\u6027\u3002", "result": "\u7b97\u6cd5\u8fbe\u5230\u6700\u4f18\u65f6\u95f4\u590d\u6742\u6027f+1\u8f6e\uff0c\u591a\u503c\u5171\u8bc6\u80fd\u91cf\u590d\u6742\u6027\u4e3aO(\u2308f\u00b2/n\u2309)\uff0c\u4e8c\u8fdb\u5236\u5171\u8bc6\u4e3aO(\u2308f/\u221an\u2309)\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u65f6\u95f4\u548c\u80fd\u91cf\u590d\u6742\u6027\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u5bb9\u9519\u5171\u8bc6\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12347", "pdf": "https://arxiv.org/pdf/2506.12347", "abs": "https://arxiv.org/abs/2506.12347", "authors": ["Aayush Kumar", "Yasharth Bajpai", "Sumit Gulwani", "Gustavo Soares", "Emerson Murphy-Hill"], "title": "How Developers Use AI Agents: When They Work, When They Don't, and Why", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "Software Engineering Agents (SWE agents) can autonomously perform development\ntasks on benchmarks like SWE Bench, but still face challenges when tackling\ncomplex and ambiguous real-world tasks. Consequently, SWE agents are often\ndesigned to allow interactivity with developers, enabling collaborative\nproblem-solving. To understand how developers collaborate with SWE agents and\nthe communication challenges that arise in such interactions, we observed 19\ndevelopers using an in-IDE agent to resolve 33 open issues in repositories to\nwhich they had previously contributed. Participants successfully resolved about\nhalf of these issues, with participants solving issues incrementally having\ngreater success than those using a one-shot approach. Participants who actively\ncollaborated with the agent and iterated on its outputs were also more\nsuccessful, though they faced challenges in trusting the agent's responses and\ncollaborating on debugging and testing. These results have implications for\nsuccessful developer-agent collaborations, and for the design of more effective\nSWE agents.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5f00\u53d1\u8005\u4e0eSWE\u4ee3\u7406\u5728\u534f\u4f5c\u4e2d\u7684\u4e92\u52a8\u6a21\u5f0f\u53ca\u6311\u6218\uff0c\u53d1\u73b0\u9010\u6b65\u89e3\u51b3\u95ee\u9898\u548c\u79ef\u6781\u8fed\u4ee3\u7684\u534f\u4f5c\u65b9\u5f0f\u66f4\u6709\u6548\uff0c\u4f46\u4fe1\u4efb\u548c\u6d4b\u8bd5\u8c03\u8bd5\u4ecd\u662f\u96be\u70b9\u3002", "motivation": "\u7406\u89e3\u5f00\u53d1\u8005\u5982\u4f55\u4e0eSWE\u4ee3\u7406\u534f\u4f5c\uff0c\u4ee5\u53ca\u4e92\u52a8\u4e2d\u51fa\u73b0\u7684\u6c9f\u901a\u95ee\u9898\uff0c\u4ee5\u4f18\u5316\u4ee3\u7406\u8bbe\u8ba1\u3002", "method": "\u89c2\u5bdf19\u540d\u5f00\u53d1\u8005\u4f7f\u7528IDE\u5185\u4ee3\u7406\u89e3\u51b333\u4e2a\u5f00\u6e90\u4ed3\u5e93\u95ee\u9898\uff0c\u5206\u6790\u534f\u4f5c\u6a21\u5f0f\u4e0e\u6210\u529f\u56e0\u7d20\u3002", "result": "\u9010\u6b65\u89e3\u51b3\u95ee\u9898\u7684\u5f00\u53d1\u8005\u6210\u529f\u7387\u66f4\u9ad8\uff1b\u4e3b\u52a8\u8fed\u4ee3\u4ee3\u7406\u8f93\u51fa\u7684\u56e2\u961f\u66f4\u6210\u529f\uff0c\u4f46\u4fe1\u4efb\u548c\u8c03\u8bd5\u4ecd\u662f\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4f18\u5316SWE\u4ee3\u7406\u8bbe\u8ba1\u53ca\u6539\u8fdb\u5f00\u53d1\u8005-\u4ee3\u7406\u534f\u4f5c\u6a21\u5f0f\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2506.12204", "pdf": "https://arxiv.org/pdf/2506.12204", "abs": "https://arxiv.org/abs/2506.12204", "authors": ["Wenyue Hua", "Dujian Ding", "Yile Gu", "Yujie Ren", "Kai Mei", "Minghua Ma", "William Yang Wang"], "title": "Semantic Scheduling for LLM Inference", "categories": ["cs.LG", "cs.AI", "cs.OS"], "comment": "18 pages, 3 figures", "summary": "Conventional operating system scheduling algorithms are largely\ncontent-ignorant, making decisions based on factors such as latency or fairness\nwithout considering the actual intents or semantics of processes. Consequently,\nthese algorithms often do not prioritize tasks that require urgent attention or\ncarry higher importance, such as in emergency management scenarios. However,\nrecent advances in language models enable semantic analysis of processes,\nallowing for more intelligent and context-aware scheduling decisions. In this\npaper, we introduce the concept of semantic scheduling in scheduling of\nrequests from large language models (LLM), where the semantics of the process\nguide the scheduling priorities. We present a novel scheduling algorithm with\noptimal time complexity, designed to minimize the overall waiting time in\nLLM-based prompt scheduling. To illustrate its effectiveness, we present a\nmedical emergency management application, underscoring the potential benefits\nof semantic scheduling for critical, time-sensitive tasks. The code and data\nare available at\nhttps://github.com/Wenyueh/latency_optimization_with_priority_constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u5206\u6790\u7684\u8c03\u5ea6\u7b97\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u8fdb\u7a0b\u7684\u8bed\u4e49\u4fe1\u606f\u6765\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bf7\u6c42\u7684\u8c03\u5ea6\u4f18\u5148\u7ea7\u3002", "motivation": "\u4f20\u7edf\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u7b97\u6cd5\u901a\u5e38\u5ffd\u7565\u5185\u5bb9\u8bed\u4e49\uff0c\u53ef\u80fd\u5bfc\u81f4\u7d27\u6025\u6216\u91cd\u8981\u4efb\u52a1\u672a\u88ab\u4f18\u5148\u5904\u7406\u3002\u5229\u7528\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u5206\u6790\u80fd\u529b\uff0c\u53ef\u4ee5\u66f4\u667a\u80fd\u5730\u8c03\u5ea6\u4efb\u52a1\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5177\u6709\u6700\u4f18\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u8c03\u5ea6\u7b97\u6cd5\uff0c\u65e8\u5728\u6700\u5c0f\u5316LLM\u63d0\u793a\u8c03\u5ea6\u7684\u603b\u4f53\u7b49\u5f85\u65f6\u95f4\u3002", "result": "\u901a\u8fc7\u533b\u7597\u7d27\u6025\u7ba1\u7406\u5e94\u7528\u5c55\u793a\u4e86\u8be5\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u5728\u5173\u952e\u3001\u65f6\u95f4\u654f\u611f\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "conclusion": "\u8bed\u4e49\u8c03\u5ea6\u5728\u4f18\u5316\u5173\u952e\u4efb\u52a1\u5904\u7406\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.12573", "pdf": "https://arxiv.org/pdf/2506.12573", "abs": "https://arxiv.org/abs/2506.12573", "authors": ["Haven Kim", "Zachary Novack", "Weihan Xu", "Julian McAuley", "Hao-Wen Dong"], "title": "Video-Guided Text-to-Music Generation Using Public Domain Movie Collections", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "ISMIR 2025 regular paper. Dataset and code available at\n  https://havenpersona.github.io/ossl-v1", "summary": "Despite recent advancements in music generation systems, their application in\nfilm production remains limited, as they struggle to capture the nuances of\nreal-world filmmaking, where filmmakers consider multiple factors-such as\nvisual content, dialogue, and emotional tone-when selecting or composing music\nfor a scene. This limitation primarily stems from the absence of comprehensive\ndatasets that integrate these elements. To address this gap, we introduce Open\nScreen Sound Library (OSSL), a dataset consisting of movie clips from public\ndomain films, totaling approximately 36.5 hours, paired with high-quality\nsoundtracks and human-annotated mood information. To demonstrate the\neffectiveness of our dataset in improving the performance of pre-trained models\non film music generation tasks, we introduce a new video adapter that enhances\nan autoregressive transformer-based text-to-music model by adding video-based\nconditioning. Our experimental results demonstrate that our proposed approach\neffectively enhances MusicGen-Medium in terms of both objective measures of\ndistributional and paired fidelity, and subjective compatibility in mood and\ngenre. The dataset and code are available at\nhttps://havenpersona.github.io/ossl-v1.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Open Screen Sound Library\uff08OSSL\uff09\u6570\u636e\u96c6\uff0c\u65e8\u5728\u89e3\u51b3\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u5728\u7535\u5f71\u5236\u4f5c\u4e2d\u5e94\u7528\u53d7\u9650\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u9891\u9002\u914d\u5668\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u56e0\u7f3a\u4e4f\u7efc\u5408\u6570\u636e\u96c6\u800c\u96be\u4ee5\u6ee1\u8db3\u7535\u5f71\u5236\u4f5c\u7684\u591a\u56e0\u7d20\u9700\u6c42\uff08\u5982\u89c6\u89c9\u5185\u5bb9\u3001\u5bf9\u8bdd\u548c\u60c5\u611f\u57fa\u8c03\uff09\uff0c\u9650\u5236\u4e86\u5176\u5728\u7535\u5f71\u5236\u4f5c\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165OSSL\u6570\u636e\u96c6\uff08\u542b\u516c\u5171\u9886\u57df\u7535\u5f71\u7684\u7247\u6bb5\u3001\u9ad8\u8d28\u91cf\u914d\u4e50\u548c\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u7eea\u4fe1\u606f\uff09\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u89c6\u9891\u9002\u914d\u5668\u6765\u589e\u5f3a\u57fa\u4e8e\u81ea\u56de\u5f52\u53d8\u6362\u5668\u7684\u6587\u672c\u5230\u97f3\u4e50\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86MusicGen-Medium\u6a21\u578b\u5728\u5206\u5e03\u6027\u548c\u914d\u5bf9\u4fdd\u771f\u5ea6\u7684\u5ba2\u89c2\u6307\u6807\uff0c\u4ee5\u53ca\u60c5\u7eea\u548c\u7c7b\u578b\u7684\u4e3b\u89c2\u517c\u5bb9\u6027\u3002", "conclusion": "OSSL\u6570\u636e\u96c6\u548c\u63d0\u51fa\u7684\u89c6\u9891\u9002\u914d\u5668\u6709\u6548\u89e3\u51b3\u4e86\u97f3\u4e50\u751f\u6210\u4e0e\u7535\u5f71\u5236\u4f5c\u9700\u6c42\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u548c\u6570\u636e\u8d44\u6e90\u3002"}}
{"id": "2506.12809", "pdf": "https://arxiv.org/pdf/2506.12809", "abs": "https://arxiv.org/abs/2506.12809", "authors": ["Hans Krupakar", "Kandappan V A"], "title": "A Review of the Long Horizon Forecasting Problem in Time Series Analysis", "categories": ["cs.LG", "cs.ET", "cs.PF", "stat.ML"], "comment": "Submitted to International Journal of Forecasting", "summary": "The long horizon forecasting (LHF) problem has come up in the time series\nliterature for over the last 35 years or so. This review covers aspects of LHF\nin this period and how deep learning has incorporated variants of trend,\nseasonality, fourier and wavelet transforms, misspecification bias reduction\nand bandpass filters while contributing using convolutions, residual\nconnections, sparsity reduction, strided convolutions, attention masks, SSMs,\nnormalization methods, low-rank approximations and gating mechanisms. We\nhighlight time series decomposition techniques, input data preprocessing and\ndataset windowing schemes that improve performance. Multi-layer perceptron\nmodels, recurrent neural network hybrids, self-attention models that improve\nand/or address the performances of the LHF problem are described, with an\nemphasis on the feature space construction. Ablation studies are conducted over\nthe ETTm2 dataset in the multivariate and univariate high useful load (HUFL)\nforecasting contexts, evaluated over the last 4 months of the dataset. The\nheatmaps of MSE averages per time step over test set series in the horizon show\nthat there is a steady increase in the error proportionate to its length except\nwith xLSTM and Triformer models and motivate LHF as an error propagation\nproblem. The trained models are available here: https://bit.ly/LHFModelZoo", "AI": {"tldr": "\u56de\u987e\u4e8635\u5e74\u6765\u957f\u65f6\u57df\u9884\u6d4b\uff08LHF\uff09\u95ee\u9898\u7684\u53d1\u5c55\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4f7f\u7528\u7684\u6280\u672f\uff08\u5982\u5377\u79ef\u3001\u6ce8\u610f\u529b\u673a\u5236\u7b49\uff09\u53ca\u5176\u5728LHF\u4e2d\u7684\u5e94\u7528\u3002\u901a\u8fc7ETTm2\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\uff0c\u53d1\u73b0xLSTM\u548cTriformer\u6a21\u578b\u5728\u9519\u8bef\u4f20\u64ad\u95ee\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u5206\u6790\u4e86\u957f\u65f6\u57df\u9884\u6d4b\u95ee\u9898\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u63a2\u7d22\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u6027\u80fd\u6539\u8fdb\u3002", "method": "\u4f7f\u7528\u5377\u79ef\u3001\u6b8b\u5dee\u8fde\u63a5\u3001\u6ce8\u610f\u529b\u63a9\u7801\u7b49\u6280\u672f\uff0c\u7ed3\u5408\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u548c\u8f93\u5165\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7ETTm2\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u9519\u8bef\u968f\u9884\u6d4b\u65f6\u57df\u957f\u5ea6\u589e\u52a0\u800c\u7a33\u5b9a\u4e0a\u5347\uff0c\u4f46xLSTM\u548cTriformer\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u7a81\u51fa\u4e86LHF\u7684\u8bef\u5dee\u4f20\u64ad\u95ee\u9898\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5728LHF\u95ee\u9898\u4e2d\u6709\u663e\u8457\u8fdb\u5c55\uff0c\u5c24\u5176\u662fxLSTM\u548cTriformer\u6a21\u578b\u7684\u6027\u80fd\u8868\u660e\u5176\u5728\u957f\u65f6\u57df\u9884\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.12061", "pdf": "https://arxiv.org/pdf/2506.12061", "abs": "https://arxiv.org/abs/2506.12061", "authors": ["Uddalok Sarkar", "Sourav Chakraborty", "Kuldeep S. Meel"], "title": "Assessing the Quality of Binomial Samplers: A Statistical Distance Framework", "categories": ["stat.CO", "cs.LO"], "comment": "The full version of the conference paper to be published at CAV-25", "summary": "Randomized algorithms depend on accurate sampling from probability\ndistributions, as their correctness and performance hinge on the quality of the\ngenerated samples. However, even for common distributions like Binomial, exact\nsampling is computationally challenging, leading standard library\nimplementations to rely on heuristics. These heuristics, while efficient,\nsuffer from approximation and system representation errors, causing deviations\nfrom the ideal distribution. Although seemingly minor, such deviations can\naccumulate in downstream applications requiring large-scale sampling,\npotentially undermining algorithmic guarantees. In this work, we propose\nstatistical distance as a robust metric for analyzing the quality of Binomial\nsamplers, quantifying deviations from the ideal distribution. We derive\nrigorous bounds on the statistical distance for standard implementations and\ndemonstrate the practical utility of our framework by enhancing APSEst, a DNF\nmodel counter, with improved reliability and error guarantees. To support\npractical adoption, we propose an interface extension that allows users to\ncontrol and monitor statistical distance via explicit input/output parameters.\nOur findings emphasize the critical need for thorough and systematic error\nanalysis in sampler design. As the first work to focus exclusively on Binomial\nsamplers, our approach lays the groundwork for extending rigorous analysis to\nother common distributions, opening avenues for more robust and reliable\nrandomized algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7edf\u8ba1\u8ddd\u79bb\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u4e8c\u9879\u5206\u5e03\u91c7\u6837\u5668\u7684\u8d28\u91cf\uff0c\u5e76\u5bf9\u6807\u51c6\u5b9e\u73b0\u7684\u504f\u5dee\u8fdb\u884c\u4e86\u4e25\u683c\u8fb9\u754c\u63a8\u5bfc\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u4e8c\u9879\u5206\u5e03\u91c7\u6837\u5668\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5bfc\u81f4\u504f\u5dee\u7d2f\u79ef\uff0c\u53ef\u80fd\u5f71\u54cd\u4e0b\u6e38\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u548c\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u7edf\u8ba1\u8ddd\u79bb\u91cf\u5316\u91c7\u6837\u5668\u4e0e\u7406\u60f3\u5206\u5e03\u7684\u504f\u5dee\uff0c\u5e76\u63a8\u5bfc\u5176\u8fb9\u754c\u3002", "result": "\u63d0\u9ad8\u4e86APSEst\u7684\u53ef\u9760\u6027\u548c\u9519\u8bef\u4fdd\u8bc1\uff0c\u63d0\u51fa\u4e86\u63a5\u53e3\u6269\u5c55\u4ee5\u63a7\u5236\u7edf\u8ba1\u8ddd\u79bb\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u91c7\u6837\u5668\u8bbe\u8ba1\u4e2d\u7cfb\u7edf\u8bef\u5dee\u5206\u6790\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u5176\u4ed6\u5e38\u89c1\u5206\u5e03\u7684\u4e25\u683c\u5206\u6790\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.12212", "pdf": "https://arxiv.org/pdf/2506.12212", "abs": "https://arxiv.org/abs/2506.12212", "authors": ["Grant VanDomelen", "Gan Shen", "Lindsey Kuper", "Yao Li"], "title": "Freer Arrows and Why You Need Them in Haskell", "categories": ["cs.PL"], "comment": "In submission to the Haskell Symposium 2025", "summary": "Freer monads are a useful structure commonly used in various domains due to\ntheir expressiveness. However, a known issue with freer monads is that they are\nnot amenable to static analysis. This paper explores freer arrows, a relatively\nexpressive structure that is amenable to static analysis. We propose several\nvariants of freer arrows. We conduct a case study on choreographic programming\nto demonstrate the usefulness of freer arrows in Haskell.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86Freer arrows\u4f5c\u4e3a\u4e00\u79cd\u53ef\u9759\u6001\u5206\u6790\u7684\u8868\u8fbe\u7ed3\u6784\uff0c\u5e76\u63d0\u51fa\u4e86\u51e0\u79cd\u53d8\u4f53\uff0c\u901a\u8fc7\u7f16\u821e\u7f16\u7a0b\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u5728Haskell\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "Freer monads\u867d\u5177\u8868\u8fbe\u6027\u4f46\u96be\u4ee5\u9759\u6001\u5206\u6790\uff0c\u63a2\u7d22Freer arrows\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u591a\u79cdFreer arrows\u53d8\u4f53\uff0c\u5e76\u901a\u8fc7\u7f16\u821e\u7f16\u7a0b\u6848\u4f8b\u9a8c\u8bc1\u3002", "result": "Freer arrows\u5728\u4fdd\u6301\u8868\u8fbe\u6027\u7684\u540c\u65f6\u652f\u6301\u9759\u6001\u5206\u6790\u3002", "conclusion": "Freer arrows\u662fFreer monads\u7684\u6709\u6548\u66ff\u4ee3\uff0c\u9002\u7528\u4e8e\u9700\u8981\u9759\u6001\u5206\u6790\u7684\u573a\u666f\u3002"}}
{"id": "2506.12847", "pdf": "https://arxiv.org/pdf/2506.12847", "abs": "https://arxiv.org/abs/2506.12847", "authors": ["Zhelun Shen", "Chenming Wu", "Junsheng Zhou", "Chen Zhao", "Kaisiyuan Wang", "Hang Zhou", "Yingying Li", "Haocheng Feng", "Wei He", "Jingdong Wang"], "title": "iDiT-HOI: Inpainting-based Hand Object Interaction Reenactment via Video Diffusion Transformer", "categories": ["cs.GR", "cs.CV"], "comment": "Technical report, 12 pages", "summary": "Digital human video generation is gaining traction in fields like education\nand e-commerce, driven by advancements in head-body animation and lip-syncing\ntechnologies. However, realistic Hand-Object Interaction (HOI) - the complex\ndynamics between human hands and objects - continues to pose challenges.\nGenerating natural and believable HOI reenactments is difficult due to issues\nsuch as occlusion between hands and objects, variations in object shapes and\norientations, and the necessity for precise physical interactions, and\nimportantly, the ability to generalize to unseen humans and objects. This paper\npresents a novel framework iDiT-HOI that enables in-the-wild HOI reenactment\ngeneration. Specifically, we propose a unified inpainting-based token process\nmethod, called Inp-TPU, with a two-stage video diffusion transformer (DiT)\nmodel. The first stage generates a key frame by inserting the designated object\ninto the hand region, providing a reference for subsequent frames. The second\nstage ensures temporal coherence and fluidity in hand-object interactions. The\nkey contribution of our method is to reuse the pretrained model's context\nperception capabilities without introducing additional parameters, enabling\nstrong generalization to unseen objects and scenarios, and our proposed\nparadigm naturally supports long video generation. Comprehensive evaluations\ndemonstrate that our approach outperforms existing methods, particularly in\nchallenging real-world scenes, offering enhanced realism and more seamless\nhand-object interactions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aiDiT-HOI\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u903c\u771f\u7684\u624b-\u7269\u4f53\u4ea4\u4e92\uff08HOI\uff09\u89c6\u9891\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u4e2d\u7684\u906e\u6321\u3001\u7269\u4f53\u5f62\u72b6\u53d8\u5316\u548c\u7269\u7406\u4ea4\u4e92\u7cbe\u5ea6\u7b49\u95ee\u9898\u3002", "motivation": "\u624b-\u7269\u4f53\u4ea4\u4e92\uff08HOI\uff09\u5728\u6570\u5b57\u4eba\u89c6\u9891\u751f\u6210\u4e2d\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u5982\u906e\u6321\u3001\u7269\u4f53\u5f62\u72b6\u53d8\u5316\u4ee5\u53ca\u7269\u7406\u4ea4\u4e92\u7cbe\u5ea6\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u573a\u666f\u548c\u5bf9\u8c61\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fee\u590d\u7684\u6807\u8bb0\u5904\u7406\u65b9\u6cd5\uff08Inp-TPU\uff09\uff0c\u7ed3\u5408\u4e24\u9636\u6bb5\u89c6\u9891\u6269\u6563\u53d8\u6362\u5668\uff08DiT\uff09\u6a21\u578b\u3002\u7b2c\u4e00\u9636\u6bb5\u751f\u6210\u5173\u952e\u5e27\uff0c\u4e3a\u540e\u7eed\u5e27\u63d0\u4f9b\u53c2\u8003\uff1b\u7b2c\u4e8c\u9636\u6bb5\u786e\u4fdd\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u4ea4\u4e92\u6d41\u7545\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0ciDiT-HOI\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u903c\u771f\u5ea6\u548c\u66f4\u6d41\u7545\u7684\u4ea4\u4e92\uff0c\u4e14\u65e0\u9700\u989d\u5916\u53c2\u6570\u5373\u53ef\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u5bf9\u8c61\u548c\u573a\u666f\u3002", "conclusion": "iDiT-HOI\u6846\u67b6\u5728HOI\u89c6\u9891\u751f\u6210\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u6cdb\u5316\u80fd\u529b\u548c\u957f\u65f6\u95f4\u89c6\u9891\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.12074", "pdf": "https://arxiv.org/pdf/2506.12074", "abs": "https://arxiv.org/abs/2506.12074", "authors": ["Han Zhang", "Akram Bin Sediq", "Ali Afana", "Melike Erol-Kantarci"], "title": "Mobile Traffic Prediction using LLMs with Efficient In-context Demonstration Selection", "categories": ["cs.NI"], "comment": null, "summary": "Mobile traffic prediction is an important enabler for optimizing resource\nallocation and improving energy efficiency in mobile wireless networks.\nBuilding on the advanced contextual understanding and generative capabilities\nof large language models (LLMs), this work introduces a context-aware wireless\ntraffic prediction framework powered by LLMs. To further enhance prediction\naccuracy, we leverage in-context learning (ICL) and develop a novel two-step\ndemonstration selection strategy, optimizing the performance of LLM-based\npredictions. The initial step involves selecting ICL demonstrations using the\neffectiveness rule, followed by a second step that determines whether the\nchosen demonstrations should be utilized, based on the informativeness rule. We\nalso provide an analytical framework for both informativeness and effectiveness\nrules. The effectiveness of the proposed framework is demonstrated with a\nreal-world fifth-generation (5G) dataset with different application scenarios.\nAccording to the numerical results, the proposed framework shows lower mean\nsquared error and higher R2-Scores compared to the zero-shot prediction method\nand other demonstration selection methods, such as constant ICL demonstration\nselection and distance-only-based ICL demonstration selection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u65e0\u7ebf\u6d41\u91cf\u9884\u6d4b\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u4e24\u6b65\u9aa4\u6f14\u793a\u9009\u62e9\u7b56\u7565\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u79fb\u52a8\u6d41\u91cf\u9884\u6d4b\u5bf9\u4f18\u5316\u8d44\u6e90\u5206\u914d\u548c\u63d0\u9ad8\u79fb\u52a8\u65e0\u7ebf\u7f51\u7edc\u7684\u80fd\u6548\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u548c\u4e24\u6b65\u9aa4\u6f14\u793a\u9009\u62e9\u7b56\u7565\uff1a\u9996\u6b65\u57fa\u4e8e\u6709\u6548\u6027\u89c4\u5219\u9009\u62e9\u6f14\u793a\uff0c\u6b21\u6b65\u57fa\u4e8e\u4fe1\u606f\u6027\u89c4\u5219\u51b3\u5b9a\u662f\u5426\u4f7f\u7528\u6240\u9009\u6f14\u793a\u3002", "result": "\u5728\u771f\u5b9e5G\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6846\u67b6\u6bd4\u96f6\u6837\u672c\u9884\u6d4b\u548c\u5176\u4ed6\u6f14\u793a\u9009\u62e9\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\uff08\u5747\u65b9\u8bef\u5dee\u66f4\u4f4e\uff0cR2\u5206\u6570\u66f4\u9ad8\uff09\u3002", "conclusion": "\u7ed3\u5408LLM\u548c\u4e24\u6b65\u9aa4\u6f14\u793a\u9009\u62e9\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u6d41\u91cf\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2506.12259", "pdf": "https://arxiv.org/pdf/2506.12259", "abs": "https://arxiv.org/abs/2506.12259", "authors": ["Jieyu Zhou", "Rui Shen", "Yue You", "Carl DiSalvo", "Lynn Dombrowski", "Christopher MacLellan"], "title": "Improving Public Service Chatbot Design and Civic Impact: Investigation of Citizens' Perceptions of a Metro City 311 Chatbot", "categories": ["cs.HC"], "comment": null, "summary": "As governments increasingly adopt digital tools, public service chatbots have\nemerged as a growing communication channel. This paper explores the design\nconsiderations and engagement opportunities of public service chatbots, using a\n311 chatbot from a metropolitan city as a case study. Our qualitative study\nconsisted of official survey data and 16 interviews examining stakeholder\nexperiences and design preferences for the chatbot. We found two key areas of\nconcern regarding these public chatbots: individual-level and community-level.\nAt the individual level, citizens experience three key challenges:\ninterpretation, transparency, and social contextualization. Moreover, the\ncurrent chatbot design prioritizes the efficient completion of individual tasks\nbut neglects the broader community perspective. It overlooks how individuals\ninteract and discuss problems collectively within their communities. To address\nthese concerns, we offer design opportunities for creating more intelligent,\ntransparent, community-oriented chatbots that better engage individuals and\ntheir communities.", "AI": {"tldr": "\u63a2\u8ba8\u516c\u5171\u670d\u52a1\u804a\u5929\u673a\u5668\u4eba\u7684\u8bbe\u8ba1\u8003\u8651\u548c\u53c2\u4e0e\u673a\u4f1a\uff0c\u53d1\u73b0\u4e2a\u4f53\u548c\u793e\u533a\u5c42\u9762\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u653f\u5e9c\u91c7\u7528\u6570\u5b57\u5de5\u5177\u7684\u589e\u52a0\uff0c\u516c\u5171\u670d\u52a1\u804a\u5929\u673a\u5668\u4eba\u6210\u4e3a\u91cd\u8981\u6c9f\u901a\u6e20\u9053\uff0c\u4f46\u5176\u8bbe\u8ba1\u548c\u4f7f\u7528\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5b98\u65b9\u8c03\u67e5\u6570\u636e\u548c16\u6b21\u8bbf\u8c08\uff0c\u5206\u6790\u5229\u76ca\u76f8\u5173\u8005\u7684\u7ecf\u9a8c\u548c\u8bbe\u8ba1\u504f\u597d\u3002", "result": "\u53d1\u73b0\u4e2a\u4f53\u5c42\u9762\u7684\u89e3\u91ca\u3001\u900f\u660e\u5ea6\u548c\u793e\u4ea4\u8bed\u5883\u95ee\u9898\uff0c\u4ee5\u53ca\u793e\u533a\u89c6\u89d2\u7684\u7f3a\u5931\u3002", "conclusion": "\u63d0\u51fa\u66f4\u667a\u80fd\u3001\u900f\u660e\u3001\u793e\u533a\u5bfc\u5411\u7684\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u673a\u4f1a\u3002"}}
{"id": "2506.12238", "pdf": "https://arxiv.org/pdf/2506.12238", "abs": "https://arxiv.org/abs/2506.12238", "authors": ["Alessandro Berti", "Wil M. P. van der Aalst"], "title": "CPN-Py: A Python-Based Tool for Modeling and Analyzing Colored Petri Nets", "categories": ["cs.DB"], "comment": null, "summary": "Colored Petri Nets (CPNs) are an established formalism for modeling processes\nwhere tokens carry data. Although tools like CPN Tools and CPN IDE excel at\nCPN-based simulation, they are often separate from modern data science\necosystems. Meanwhile, Python has become the de facto language for process\nmining, machine learning, and data analytics. In this paper, we introduce\nCPN-Py, a Python library that faithfully preserves the core concepts of Colored\nPetri Nets -- including color sets, timed tokens, guard logic, and hierarchical\nstructures -- while providing seamless integration with the Python environment.\nWe discuss its design, highlight its synergy with PM4Py (including stochastic\nreplay, process discovery, and decision mining functionalities), and illustrate\nhow the tool supports state space analysis and hierarchical CPNs. We also\noutline how CPN-Py accommodates large language models, which can generate or\nrefine CPN models through a dedicated JSON-based format.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86CPN-Py\uff0c\u4e00\u4e2aPython\u5e93\uff0c\u7528\u4e8e\u5c06Colored Petri Nets\uff08CPN\uff09\u4e0e\u73b0\u4ee3\u6570\u636e\u79d1\u5b66\u751f\u6001\u7cfb\u7edf\u65e0\u7f1d\u96c6\u6210\uff0c\u652f\u6301\u6838\u5fc3\u529f\u80fd\u5e76\u6574\u5408\u4e86PM4Py\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684CPN\u5de5\u5177\uff08\u5982CPN Tools\u548cCPN IDE\uff09\u4e0e\u73b0\u4ee3\u6570\u636e\u79d1\u5b66\u751f\u6001\u7cfb\u7edf\uff08\u5982Python\uff09\u5206\u79bb\uff0c\u9650\u5236\u4e86\u5176\u5728\u6570\u636e\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86CPN-Py\u5e93\uff0c\u4fdd\u7559\u4e86CPN\u7684\u6838\u5fc3\u6982\u5ff5\uff08\u5982\u989c\u8272\u96c6\u3001\u5b9a\u65f6\u4ee4\u724c\u3001\u4fdd\u62a4\u903b\u8f91\u548c\u5c42\u6b21\u7ed3\u6784\uff09\uff0c\u5e76\u63d0\u4f9b\u4e0ePython\u73af\u5883\u53caPM4Py\u7684\u96c6\u6210\u529f\u80fd\u3002", "result": "CPN-Py\u6210\u529f\u652f\u6301\u72b6\u6001\u7a7a\u95f4\u5206\u6790\u548c\u5c42\u6b21\u5316CPN\uff0c\u540c\u65f6\u901a\u8fc7JSON\u683c\u5f0f\u9002\u5e94\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "CPN-Py\u4e3aCPN\u6a21\u578b\u7684\u5f00\u53d1\u548c\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.12264", "pdf": "https://arxiv.org/pdf/2506.12264", "abs": "https://arxiv.org/abs/2506.12264", "authors": ["Tianci Miao", "Qihang Zheng", "Yangyang Hu", "Xiaoyu Cheng", "Jie Liang", "Liang Chen", "Aiying Guo", "Jingjing Liu", "Kailin Ren", "Jianhua Zhang"], "title": "A Novel Thermal Network Model and Electro-Thermal Coupling Study for NSFETs and CFETs Considering Thermal Crosstalk", "categories": ["cs.ET", "cs.AR"], "comment": null, "summary": "As the technology node continues to shrink, nanosheet field effect\ntransistors (NSFETs) and complementary FETs (CFETs) become valid candidates for\nthe 3nm and sub-nanometre nodes. However, due to the shrinking device size,\nself-heating and inter-device thermal crosstalk of NSFETs and CFETs become more\nsevere. It is important to accurately calculate the self-heating and thermal\ncrosstalk of devices and to study the electrical and thermal characteristics of\nlogic gates, etc. In this work, a thermal network model considering the thermal\ncrosstalk of neighboring devices is proposed, which can accurately calculate\nthe self-heating and thermal crosstalk. The electrical and thermal\ncharacteristics of NSFETs and CFETs are compared, and it is found that CFETs\nhave more severe self-heating and thermal crosstalk. The electro-thermal\ncharacteristics of inverters, logic gates and ring oscillators composed of\nNSFETs and CFETs are further investigated. Compared with NSFETs, logic gates\nand ring oscillators composed of CFETs are more seriously affected by\nself-heating and should be given extra attention. The thermal network model\nproposed in this paper can be further used to study the thermal optimization\nstrategy of devices and circuits to enhance the electrical performance,\nachieving the design technology co-optimizations (DTCO).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u7eb3\u7c73\u7247\u573a\u6548\u5e94\u6676\u4f53\u7ba1\uff08NSFETs\uff09\u548c\u4e92\u8865\u573a\u6548\u5e94\u6676\u4f53\u7ba1\uff08CFETs\uff09\u57283nm\u53ca\u66f4\u5c0f\u8282\u70b9\u4e2d\u7684\u81ea\u70ed\u548c\u70ed\u4e32\u6270\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u90bb\u8fd1\u5668\u4ef6\u70ed\u4e32\u6270\u7684\u70ed\u7f51\u7edc\u6a21\u578b\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e24\u8005\u7684\u7535\u70ed\u7279\u6027\u3002", "motivation": "\u968f\u7740\u5de5\u827a\u8282\u70b9\u7684\u7f29\u5c0f\uff0cNSFETs\u548cCFETs\u7684\u81ea\u70ed\u548c\u70ed\u4e32\u6270\u95ee\u9898\u65e5\u76ca\u4e25\u91cd\uff0c\u9700\u8981\u51c6\u786e\u8ba1\u7b97\u548c\u4f18\u5316\u8fd9\u4e9b\u6548\u5e94\u4ee5\u63d0\u9ad8\u5668\u4ef6\u548c\u7535\u8def\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u90bb\u8fd1\u5668\u4ef6\u70ed\u4e32\u6270\u7684\u70ed\u7f51\u7edc\u6a21\u578b\uff0c\u7528\u4ee5\u51c6\u786e\u8ba1\u7b97\u81ea\u70ed\u548c\u70ed\u4e32\u6270\uff0c\u5e76\u7814\u7a76\u4e86NSFETs\u548cCFETs\u7684\u7535\u70ed\u7279\u6027\u53ca\u5176\u5728\u903b\u8f91\u95e8\u548c\u73af\u5f62\u632f\u8361\u5668\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0CFETs\u7684\u81ea\u70ed\u548c\u70ed\u4e32\u6270\u66f4\u4e3a\u4e25\u91cd\uff0c\u7531\u5176\u7ec4\u6210\u7684\u903b\u8f91\u95e8\u548c\u73af\u5f62\u632f\u8361\u5668\u53d7\u81ea\u70ed\u5f71\u54cd\u66f4\u5927\uff1b\u63d0\u51fa\u7684\u70ed\u7f51\u7edc\u6a21\u578b\u53ef\u7528\u4e8e\u4f18\u5316\u5668\u4ef6\u548c\u7535\u8def\u7684\u70ed\u8bbe\u8ba1\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u70ed\u7f51\u7edc\u6a21\u578b\u4e3a\u7814\u7a76\u5668\u4ef6\u548c\u7535\u8def\u7684\u70ed\u4f18\u5316\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u8bbe\u8ba1\u4e0e\u6280\u672f\u7684\u534f\u540c\u4f18\u5316\uff08DTCO\uff09\u3002"}}
{"id": "2506.12947", "pdf": "https://arxiv.org/pdf/2506.12947", "abs": "https://arxiv.org/abs/2506.12947", "authors": ["Ismail Emir Yuksel", "Akash Sood", "Ataberk Olgun", "O\u011fuzhan Canpolat", "Haocong Luo", "F. Nisa Bostanc\u0131", "Mohammad Sadrosadati", "A. Giray Ya\u011fl\u0131k\u00e7\u0131", "Onur Mutlu"], "title": "PuDHammer: Experimental Analysis of Read Disturbance Effects of Processing-using-DRAM in Real DRAM Chips", "categories": ["cs.AR", "cs.CR"], "comment": "Extended version of our publication at the 52nd International\n  Symposium on Computer Architecture (ISCA-52), 2025", "summary": "Processing-using-DRAM (PuD) is a promising paradigm for alleviating the data\nmovement bottleneck using DRAM's massive internal parallelism and bandwidth to\nexecute very wide operations. Performing a PuD operation involves activating\nmultiple DRAM rows in quick succession or simultaneously, i.e., multiple-row\nactivation. Multiple-row activation is fundamentally different from\nconventional memory access patterns that activate one DRAM row at a time.\nHowever, repeatedly activating even one DRAM row (e.g., RowHammer) can induce\nbitflips in unaccessed DRAM rows because modern DRAM is subject to read\ndisturbance. Unfortunately, no prior work investigates the effects of\nmultiple-row activation on DRAM read disturbance.\n  In this paper, we present the first characterization study of read\ndisturbance effects of multiple-row activation-based PuD (which we call\nPuDHammer) using 316 real DDR4 DRAM chips from four major DRAM manufacturers.\nOur detailed characterization show that 1) PuDHammer significantly exacerbates\nthe read disturbance vulnerability, causing up to 158.58x reduction in the\nminimum hammer count required to induce the first bitflip ($HC_{first}$),\ncompared to RowHammer, 2) PuDHammer is affected by various operational\nconditions and parameters, 3) combining RowHammer with PuDHammer is more\neffective than using RowHammer alone to induce read disturbance error, e.g.,\ndoing so reduces $HC_{first}$ by 1.66x on average, and 4) PuDHammer bypasses an\nin-DRAM RowHammer mitigation mechanism (Target Row Refresh) and induces more\nbitflips than RowHammer.\n  To develop future robust PuD-enabled systems in the presence of PuDHammer, we\n1) develop three countermeasures and 2) adapt and evaluate the state-of-the-art\nRowHammer mitigation standardized by industry, called Per Row Activation\nCounting (PRAC). We show that the adapted PRAC incurs large performance\noverheads (48.26%, on average).", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86DRAM\u591a\u884c\u6fc0\u6d3b\uff08PuDHammer\uff09\u5bf9\u8bfb\u53d6\u5e72\u6270\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u663e\u8457\u52a0\u5267\u4e86\u8bfb\u53d6\u5e72\u6270\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u5e94\u5bf9\u63aa\u65bd\u3002", "motivation": "DRAM\u7684\u591a\u884c\u6fc0\u6d3b\u6a21\u5f0f\uff08\u7528\u4e8ePuD\uff09\u4e0e\u4f20\u7edf\u7684\u5355\u884c\u6fc0\u6d3b\u4e0d\u540c\uff0c\u4f46\u5176\u5bf9\u8bfb\u53d6\u5e72\u6270\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u7814\u7a76\u3002", "method": "\u4f7f\u7528316\u4e2aDDR4 DRAM\u82af\u7247\uff0c\u5bf9\u6bd4RowHammer\u548cPuDHammer\u7684\u8868\u73b0\uff0c\u5206\u6790\u5176\u8bfb\u53d6\u5e72\u6270\u6548\u5e94\u3002", "result": "PuDHammer\u5bfc\u81f4\u9996\u6b21\u4f4d\u7ffb\u8f6c\u6240\u9700\u7684\u9524\u51fb\u6b21\u6570\u5927\u5e45\u51cf\u5c11\uff0c\u4e14\u80fd\u7ed5\u8fc7\u73b0\u6709\u7684RowHammer\u7f13\u89e3\u673a\u5236\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u79cd\u5e94\u5bf9\u63aa\u65bd\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u884c\u4e1a\u6807\u51c6\u7f13\u89e3\u673a\u5236\u7684\u9002\u5e94\u6027\uff0c\u4f46\u6027\u80fd\u5f00\u9500\u8f83\u9ad8\u3002"}}
{"id": "2506.12370", "pdf": "https://arxiv.org/pdf/2506.12370", "abs": "https://arxiv.org/abs/2506.12370", "authors": ["Tianze Wang", "Yifei Liu", "Chen Chen", "Pengfei Zuo", "Jiawei Zhang", "Qizhen Weng", "Yin Chen", "Zhenhua Han", "Jieru Zhao", "Quan Chen", "Minyi Guo"], "title": "Efficient Unified Caching for Accelerating Heterogeneous AI Workloads", "categories": ["cs.DC", "cs.LG"], "comment": "15 pages, 17 figures", "summary": "Modern AI clusters, which host diverse workloads like data pre-processing,\ntraining and inference, often store the large-volume data in cloud storage and\nemploy caching frameworks to facilitate remote data access. To avoid\ncode-intrusion complexity and minimize cache space wastage, it is desirable to\nmaintain a unified cache shared by all the workloads. However, existing cache\nmanagement strategies, designed for specific workloads, struggle to handle the\nheterogeneous AI workloads in a cluster -- which usually exhibit heterogeneous\naccess patterns and item storage granularities. In this paper, we propose\nIGTCache, a unified, high-efficacy cache for modern AI clusters. IGTCache\nleverages a hierarchical access abstraction, AccessStreamTree, to organize the\nrecent data accesses in a tree structure, facilitating access pattern detection\nat various granularities. Using this abstraction, IGTCache applies hypothesis\ntesting to categorize data access patterns as sequential, random, or skewed.\nBased on these detected access patterns and granularities, IGTCache tailors\noptimal cache management strategies including prefetching, eviction, and space\nallocation accordingly. Experimental results show that IGTCache increases the\ncache hit ratio by 55.6% over state-of-the-art caching frameworks, reducing the\noverall job completion time by 52.2%.", "AI": {"tldr": "IGTCache\u662f\u4e00\u79cd\u7528\u4e8e\u73b0\u4ee3AI\u96c6\u7fa4\u7684\u7edf\u4e00\u9ad8\u6548\u7f13\u5b58\u65b9\u6848\uff0c\u901a\u8fc7\u5206\u5c42\u8bbf\u95ee\u62bd\u8c61\u548c\u5047\u8bbe\u6d4b\u8bd5\u4f18\u5316\u7f13\u5b58\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u547d\u4e2d\u7387\u548c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u3002", "motivation": "\u73b0\u4ee3AI\u96c6\u7fa4\u9700\u8981\u5904\u7406\u591a\u6837\u5316\u7684\u8d1f\u8f7d\u548c\u5f02\u6784\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\uff0c\u73b0\u6709\u7f13\u5b58\u7b56\u7565\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u63d0\u51faIGTCache\uff0c\u5229\u7528AccessStreamTree\u62bd\u8c61\u5c42\u6b21\u5316\u6570\u636e\u8bbf\u95ee\uff0c\u5e76\u901a\u8fc7\u5047\u8bbe\u6d4b\u8bd5\u8bc6\u522b\u8bbf\u95ee\u6a21\u5f0f\uff08\u987a\u5e8f\u3001\u968f\u673a\u6216\u503e\u659c\uff09\uff0c\u636e\u6b64\u4f18\u5316\u7f13\u5b58\u7b56\u7565\uff08\u9884\u53d6\u3001\u56de\u6536\u548c\u7a7a\u95f4\u5206\u914d\uff09\u3002", "result": "\u5b9e\u9a8c\u663e\u793aIGTCache\u6bd4\u73b0\u6709\u7f13\u5b58\u6846\u67b6\u547d\u4e2d\u7387\u63d0\u9ad855.6%\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1152.2%\u3002", "conclusion": "IGTCache\u6210\u529f\u89e3\u51b3\u4e86\u5f02\u6784\u8d1f\u8f7d\u7684\u7edf\u4e00\u7f13\u5b58\u7ba1\u7406\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.12590", "pdf": "https://arxiv.org/pdf/2506.12590", "abs": "https://arxiv.org/abs/2506.12590", "authors": ["Breno Alves de Andrade", "Rodrigo Siqueira", "Lidiane Gomes", "Antonio Oliveira", "Danilo Monteiro Ribeiro"], "title": "A Mapping Study About Training in Industry Context in Software Engineering", "categories": ["cs.SE"], "comment": null, "summary": "Context: Corporate training plays a strategic role in the continuous\ndevelopment of professionals in the software engineering industry. However,\nthere is a lack of systematized understanding of how training initiatives are\ndesigned, implemented, and evaluated within this domain.\n  Objective: This study aims to map the current state of research on corporate\ntraining in software engineering in industry settings, using Eduardo Salas'\ntraining framework as an analytical lens.\n  Method: A systematic mapping study was conducted involving the selection and\nanalysis of 26 primary studies published in the field. Each study was\ncategorized according to Salas' four key areas: Training Needs Analysis,\nAntecedent Training Conditions, Training Methods and Instructional Strategies,\nand Post-Training Conditions.\n  Results: The findings show a predominance of studies focusing on Training\nMethods and Instructional Strategies. Significant gaps were identified in other\nareas, particularly regarding Job/Task Analysis and Simulation-based Training\nand Games. Most studies were experience reports, lacking methodological rigor\nand longitudinal assessment.\n  Conclusions: The study offers a structured overview of how corporate training\nis approached in software engineering, revealing underexplored areas and\nproposing directions for future research. It contributes to both academic and\npractical communities by highlighting challenges, methodological trends, and\nopportunities for designing more effective training programs in industry.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u5206\u6790\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u4f01\u4e1a\u57f9\u8bad\u7814\u7a76\u73b0\u72b6\uff0c\u53d1\u73b0\u7814\u7a76\u96c6\u4e2d\u5728\u57f9\u8bad\u65b9\u6cd5\u548c\u7b56\u7565\u4e0a\uff0c\u5176\u4ed6\u9886\u57df\u5b58\u5728\u660e\u663e\u7a7a\u767d\u3002", "motivation": "\u63a2\u7a76\u8f6f\u4ef6\u5de5\u7a0b\u884c\u4e1a\u4e2d\u4f01\u4e1a\u57f9\u8bad\u7684\u8bbe\u8ba1\u3001\u5b9e\u65bd\u548c\u8bc4\u4f30\u7684\u7cfb\u7edf\u5316\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u5206\u6790\u4e8626\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u5e76\u4ee5Salas\u7684\u57f9\u8bad\u6846\u67b6\u4e3a\u5206\u6790\u5de5\u5177\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u591a\u6570\u7814\u7a76\u96c6\u4e2d\u4e8e\u57f9\u8bad\u65b9\u6cd5\u548c\u7b56\u7565\uff0c\u800c\u5728\u5de5\u4f5c/\u4efb\u52a1\u5206\u6790\u53ca\u6a21\u62df\u57f9\u8bad\u7b49\u9886\u57df\u5b58\u5728\u663e\u8457\u7a7a\u7f3a\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4f01\u4e1a\u57f9\u8bad\u7684\u7ed3\u6784\u5316\u6982\u89c8\uff0c\u6307\u51fa\u4e86\u672a\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.12935", "pdf": "https://arxiv.org/pdf/2506.12935", "abs": "https://arxiv.org/abs/2506.12935", "authors": ["Xingjian Diao", "Chunhui Zhang", "Keyi Kong", "Weiyi Wu", "Chiyu Ma", "Zhongyu Ouyang", "Peijun Qing", "Soroush Vosoughi", "Jiang Gui"], "title": "SoundMind: RL-Incentivized Logic Reasoning for Audio-Language Models", "categories": ["cs.CL", "cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "While large language models have shown reasoning capabilities, their\napplication to the audio modality, particularly in large audio-language models\n(ALMs), remains significantly underdeveloped. Addressing this gap requires a\nsystematic approach, involving a capable base model, high-quality\nreasoning-oriented audio data, and effective training algorithms. In this\nstudy, we present a comprehensive solution: we introduce the Audio Logical\nReasoning (ALR) dataset, consisting of 6,446 text-audio annotated samples\nspecifically designed for complex reasoning tasks. Building on this resource,\nwe propose SoundMind, a rule-based reinforcement learning (RL) algorithm\ntailored to endow ALMs with deep bimodal reasoning abilities. By training\nQwen2.5-Omni-7B on the ALR dataset using SoundMind, our approach achieves\nstate-of-the-art performance in audio logical reasoning. This work highlights\nthe impact of combining high-quality, reasoning-focused datasets with\nspecialized RL techniques, advancing the frontier of auditory intelligence in\nlanguage models. Our code and the proposed dataset are available at\nhttps://github.com/xid32/SoundMind.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u63d0\u51faAudio Logical Reasoning (ALR)\u6570\u636e\u96c6\u548cSoundMind\u7b97\u6cd5\uff0c\u7ed3\u5408\u9ad8\u8d28\u91cf\u97f3\u9891\u6570\u636e\u548c\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u63d0\u5347\u4e86\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b(ALMs)\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8fbe\u5230\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u9891\u6a21\u6001\u7684\u63a8\u7406\u80fd\u529b\u4ecd\u663e\u4e0d\u8db3\uff0c\u9700\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faALR\u6570\u636e\u96c6\uff086,446\u4e2a\u6837\u672c\uff09\u548cSoundMind\u89c4\u5219\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3Qwen2.5-Omni-7B\u6a21\u578b\u3002", "result": "SoundMind\u5728ALR\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u540e\uff0c\u5b9e\u73b0\u4e86\u97f3\u9891\u903b\u8f91\u63a8\u7406\u7684\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u96c6\u7ed3\u5408\u4e13\u95e8\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u63a8\u52a8\u4e86\u542c\u89c9\u667a\u80fd\u7684\u524d\u6cbf\u53d1\u5c55\u3002"}}
{"id": "2506.12667", "pdf": "https://arxiv.org/pdf/2506.12667", "abs": "https://arxiv.org/abs/2506.12667", "authors": ["Alexis R. Tudor", "Yankai Zeng", "Huaduo Wang", "Joaquin Arias", "Gopal Gupta"], "title": "Building Trustworthy AI by Addressing its 16+2 Desiderata with Goal-Directed Commonsense Reasoning", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Current advances in AI and its applicability have highlighted the need to\nensure its trustworthiness for legal, ethical, and even commercial reasons.\nSub-symbolic machine learning algorithms, such as the LLMs, simulate reasoning\nbut hallucinate and their decisions cannot be explained or audited (crucial\naspects for trustworthiness). On the other hand, rule-based reasoners, such as\nCyc, are able to provide the chain of reasoning steps but are complex and use a\nlarge number of reasoners. We propose a middle ground using s(CASP), a\ngoal-directed constraint-based answer set programming reasoner that employs a\nsmall number of mechanisms to emulate reliable and explainable human-style\ncommonsense reasoning. In this paper, we explain how s(CASP) supports the 16\ndesiderata for trustworthy AI introduced by Doug Lenat and Gary Marcus (2023),\nand two additional ones: inconsistency detection and the assumption of\nalternative worlds. To illustrate the feasibility and synergies of s(CASP), we\npresent a range of diverse applications, including a conversational chatbot and\na virtually embodied reasoner.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u89c4\u5219\u63a8\u7406\u4e0e\u7ea6\u675f\u903b\u8f91\u7684\u65b9\u6cd5s(CASP)\uff0c\u4ee5\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e14\u53ef\u9760\u7684\u4eba\u5de5\u667a\u80fd\uff0c\u6ee1\u8db316\u9879\u53ef\u4fe1AI\u8981\u6c42\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524dAI\uff08\u5982LLMs\uff09\u7684\u4e0d\u53ef\u89e3\u91ca\u6027\u548c\u89c4\u5219\u63a8\u7406\u7cfb\u7edf\u7684\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u6298\u4e2d\u65b9\u6848\u4ee5\u589e\u5f3aAI\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528s(CASP)\u8fd9\u4e00\u57fa\u4e8e\u76ee\u6807\u5bfc\u5411\u7684\u7ea6\u675f\u903b\u8f91\u7f16\u7a0b\u63a8\u7406\u5668\uff0c\u6a21\u62df\u4eba\u7c7b\u5e38\u8bc6\u63a8\u7406\u3002", "result": "s(CASP)\u80fd\u591f\u6ee1\u8db316\u9879\u53ef\u4fe1AI\u8981\u6c42\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u5e94\u7528\uff08\u5982\u804a\u5929\u673a\u5668\u4eba\u548c\u865a\u62df\u63a8\u7406\u5668\uff09\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002", "conclusion": "s(CASP)\u4e3a\u53ef\u89e3\u91ca\u548c\u53ef\u9760\u7684AI\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u6837\u5316\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.13383", "pdf": "https://arxiv.org/pdf/2506.13383", "abs": "https://arxiv.org/abs/2506.13383", "authors": ["Jules Jacobs", "Nate Foster", "Tobias Kapp\u00e9", "Dexter Kozen", "Lily Saada", "Alexandra Silva", "Jana Wagemaker"], "title": "StacKAT: Infinite State Network Verification", "categories": ["cs.PL"], "comment": null, "summary": "We develop StacKAT, a network verification language featuring loops, finite\nstate variables, nondeterminism, and - most importantly - access to a stack\nwith accompanying push and pop operations. By viewing the variables and stack\nas the (parsed) headers and (to-be-parsed) contents of a network packet,\nStacKAT can express a wide range of network behaviors including parsing, source\nrouting, and telemetry. These behaviors are difficult or impossible to model\nusing existing languages like NetKAT. We develop a decision procedure for\nStacKAT program equivalence, based on finite automata. This decision procedure\nprovides the theoretical basis for verifying network-wide properties and is\nable to provide counterexamples for inequivalent programs. Finally, we provide\nan axiomatization of StacKAT equivalence and establish its completeness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStacKAT\u7684\u7f51\u7edc\u9a8c\u8bc1\u8bed\u8a00\uff0c\u652f\u6301\u5faa\u73af\u3001\u6709\u9650\u72b6\u6001\u53d8\u91cf\u3001\u975e\u786e\u5b9a\u6027\u53ca\u5806\u6808\u64cd\u4f5c\uff0c\u53ef\u8868\u8fbe\u590d\u6742\u7684\u7f51\u7edc\u884c\u4e3a\uff0c\u5e76\u63d0\u4f9b\u4e86\u7b49\u4ef7\u6027\u5224\u5b9a\u7a0b\u5e8f\u548c\u516c\u7406\u5316\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u7684\u7f51\u7edc\u9a8c\u8bc1\u8bed\u8a00\uff08\u5982NetKAT\uff09\u96be\u4ee5\u8868\u8fbe\u590d\u6742\u7684\u7f51\u7edc\u884c\u4e3a\uff08\u5982\u89e3\u6790\u3001\u6e90\u8def\u7531\u548c\u9065\u6d4b\uff09\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u66f4\u5f3a\u5927\u7684\u8bed\u8a00\u3002", "method": "\u5f00\u53d1\u4e86StacKAT\u8bed\u8a00\uff0c\u5f15\u5165\u4e86\u5806\u6808\u3001\u72b6\u6001\u53d8\u91cf\u548c\u975e\u786e\u5b9a\u6027\uff0c\u5e76\u57fa\u4e8e\u6709\u9650\u81ea\u52a8\u673a\u6784\u5efa\u4e86\u7528\u4e8e\u5224\u5b9a\u7a0b\u5e8f\u7b49\u4ef7\u6027\u7684\u51b3\u7b56\u7a0b\u5e8f\u3002", "result": "StacKAT\u80fd\u591f\u8868\u8fbe\u5e7f\u6cdb\u7684\u7f51\u7edc\u884c\u4e3a\uff0c\u51b3\u7b56\u7a0b\u5e8f\u53ef\u4ee5\u9a8c\u8bc1\u7f51\u7edc\u8303\u56f4\u5c5e\u6027\u5e76\u63d0\u4f9b\u53cd\u4f8b\uff0c\u540c\u65f6\u516c\u7406\u5316\u7cfb\u7edf\u5b8c\u5907\u6027\u5f97\u5230\u8bc1\u660e\u3002", "conclusion": "StacKAT\u5f25\u8865\u4e86\u73b0\u6709\u8bed\u8a00\u7684\u4e0d\u8db3\uff0c\u4e3a\u7f51\u7edc\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u548c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2506.13050", "pdf": "https://arxiv.org/pdf/2506.13050", "abs": "https://arxiv.org/abs/2506.13050", "authors": ["Pengfei Wang", "Qiujie Dong", "Fangtian Liang", "Hao Pan", "Lei Yang", "Congyi Zhang", "Guying Lin", "Caiming Zhang", "Yuanfeng Zhou", "Changhe Tu", "Shiqing Xin", "Alla Sheffer", "Xin Li", "Wenping Wang"], "title": "NeuVAS: Neural Implicit Surfaces for Variational Shape Modeling", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Neural implicit shape representation has drawn significant attention in\nrecent years due to its smoothness, differentiability, and topological\nflexibility. However, directly modeling the shape of a neural implicit surface,\nespecially as the zero-level set of a neural signed distance function (SDF),\nwith sparse geometric control is still a challenging task. Sparse input shape\ncontrol typically includes 3D curve networks or, more generally, 3D curve\nsketches, which are unstructured and cannot be connected to form a curve\nnetwork, and therefore more difficult to deal with. While 3D curve networks or\ncurve sketches provide intuitive shape control, their sparsity and varied\ntopology pose challenges in generating high-quality surfaces to meet such curve\nconstraints. In this paper, we propose NeuVAS, a variational approach to shape\nmodeling using neural implicit surfaces constrained under sparse input shape\ncontrol, including unstructured 3D curve sketches as well as connected 3D curve\nnetworks. Specifically, we introduce a smoothness term based on a functional of\nsurface curvatures to minimize shape variation of the zero-level set surface of\na neural SDF. We also develop a new technique to faithfully model G0 sharp\nfeature curves as specified in the input curve sketches. Comprehensive\ncomparisons with the state-of-the-art methods demonstrate the significant\nadvantages of our method.", "AI": {"tldr": "\u6458\u8981\u8ba8\u8bba\u4e86\u795e\u7ecf\u9690\u5f0f\u5f62\u72b6\u8868\u793a\u5728\u7a00\u758f\u51e0\u4f55\u63a7\u5236\u4e0b\u5efa\u6a21\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeuVAS\u7684\u53d8\u5206\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5e73\u6ed1\u6027\u9879\u548c\u65b0\u6280\u672f\u6765\u4f18\u5316\u8868\u9762\u5f62\u72b6\u548c\u9510\u7279\u5f81\u66f2\u7ebf\u3002", "motivation": "\u795e\u7ecf\u9690\u5f0f\u5f62\u72b6\u8868\u793a\u867d\u7136\u5177\u6709\u5e73\u6ed1\u6027\u548c\u7075\u6d3b\u6027\uff0c\u4f46\u5728\u7a00\u758f\u8f93\u5165\u5f62\u72b6\u63a7\u5236\uff08\u59823D\u66f2\u7ebf\u7f51\u7edc\u6216\u8349\u56fe\uff09\u4e0b\u76f4\u63a5\u5efa\u6a21\u4ecd\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8868\u9762\u4ee5\u6ee1\u8db3\u66f2\u7ebf\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u4e86NeuVAS\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5206\u65b9\u6cd5\u7ed3\u5408\u8868\u9762\u66f2\u7387\u7684\u529f\u80fd\u5e73\u6ed1\u9879\u548c\u65b0\u6280\u672f\uff0c\u4ee5\u4f18\u5316\u795e\u7ecfSDF\u96f6\u6c34\u5e73\u96c6\u8868\u9762\u7684\u5f62\u72b6\uff0c\u5e76\u5fe0\u5b9e\u5efa\u6a21\u8f93\u5165\u66f2\u7ebf\u8349\u56fe\u4e2d\u7684G0\u9510\u7279\u5f81\u66f2\u7ebf\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cNeuVAS\u5728\u7a00\u758f\u8f93\u5165\u5f62\u72b6\u63a7\u5236\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u8868\u9762\u751f\u6210\u8d28\u91cf\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u6ee1\u8db3\u66f2\u7ebf\u7ea6\u675f\u3002", "conclusion": "NeuVAS\u4e3a\u7a00\u758f\u51e0\u4f55\u63a7\u5236\u4e0b\u7684\u795e\u7ecf\u9690\u5f0f\u5f62\u72b6\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5f15\u5165\u5e73\u6ed1\u6027\u548c\u65b0\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f62\u72b6\u5efa\u6a21\u7684\u8868\u73b0\u3002"}}
{"id": "2506.12081", "pdf": "https://arxiv.org/pdf/2506.12081", "abs": "https://arxiv.org/abs/2506.12081", "authors": ["Shaba Shaon", "Van-Dinh Nguyen", "Dinh C. Nguyen"], "title": "Latency Optimization for Wireless Federated Learning in Multihop Networks", "categories": ["cs.NI", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at IEEE Transactions on Vehicular Technology (IEEE TVT),\n  code is available at https://github.com/ShabaGit/Multihop_FL", "summary": "In this paper, we study a novel latency minimization problem in wireless\nfederated learning (FL) across multi-hop networks. The system comprises\nmultiple routes, each integrating leaf and relay nodes for FL model training.\nWe explore a personalized learning and adaptive aggregation-aware FL (PAFL)\nframework that effectively addresses data heterogeneity across participating\nnodes by harmonizing individual and collective learning objectives. We\nformulate an optimization problem aimed at minimizing system latency through\nthe joint optimization of leaf and relay nodes, as well as relay routing\nindicator. We also incorporate an additional energy harvesting scheme for the\nrelay nodes to help with their relay tasks. This formulation presents a\ncomputationally demanding challenge, and thus we develop a simple yet efficient\nalgorithm based on block coordinate descent and successive convex approximation\n(SCA) techniques. Simulation results illustrate the efficacy of our proposed\njoint optimization approach for leaf and relay nodes with relay routing\nindicator. We observe significant latency savings in the wireless multi-hop\nPAFL system, with reductions of up to 69.37% compared to schemes optimizing\nonly one node type, traditional greedy algorithm, and scheme without relay\nrouting indicator.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u5728\u591a\u8df3\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u7684\u65b0\u578b\u5ef6\u8fdf\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e2a\u6027\u5316\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u805a\u5408\u7684FL\u6846\u67b6\uff08PAFL\uff09\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53f6\u8282\u70b9\u548c\u4e2d\u7ee7\u8282\u70b9\u4ee5\u53ca\u8def\u7531\u6307\u793a\u5668\u6765\u6700\u5c0f\u5316\u7cfb\u7edf\u5ef6\u8fdf\uff0c\u5e76\u5f15\u5165\u80fd\u91cf\u6536\u96c6\u65b9\u6848\u3002", "motivation": "\u591a\u8df3\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ef6\u8fdf\u95ee\u9898\u662f\u5f53\u524d\u7814\u7a76\u7684\u96be\u70b9\uff0c\u6570\u636e\u5f02\u6784\u6027\u4f7f\u5f97\u5b66\u4e60\u4efb\u52a1\u66f4\u52a0\u590d\u6742\u3002", "method": "\u8bbe\u8ba1\u4e86PAFL\u6846\u67b6\uff0c\u901a\u8fc7\u5757\u5750\u6807\u4e0b\u964d\u548c\u8fde\u7eed\u51f8\u8fd1\u4f3c\uff08SCA\uff09\u6280\u672f\u8054\u5408\u4f18\u5316\u53f6\u8282\u70b9\u3001\u4e2d\u7ee7\u8282\u70b9\u548c\u8def\u7531\u6307\u793a\u5668\u3002", "result": "\u63d0\u51fa\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\uff0c\u6700\u9ad8\u8282\u770169.37%\uff0c\u4f18\u4e8e\u4f20\u7edf\u8d2a\u5a6a\u7b97\u6cd5\u548c\u5355\u8282\u70b9\u4f18\u5316\u65b9\u6848\u3002", "conclusion": "PAFL\u6846\u67b6\u5728\u591a\u8df3\u65e0\u7ebfFL\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8054\u5408\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2506.12332", "pdf": "https://arxiv.org/pdf/2506.12332", "abs": "https://arxiv.org/abs/2506.12332", "authors": ["Ziheng Huang", "Tal August", "Hari Sundaram"], "title": "TermSight: Making Service Contracts Approachable", "categories": ["cs.HC"], "comment": null, "summary": "Terms of Service (ToS) are ubiquitous, legally binding contracts that govern\nconsumers' digital interactions. However, ToS are not designed to be read: they\nare filled with pages of ambiguous and complex legal terminology that burden\npotential users. We introduce TermSight, an intelligent reading interface\ndesigned to make ToS more approachable. TermSight offers visual summaries that\nhighlight the relevance and power balance of information in a ToS. TermSight\nalso categorizes and simplifies information within the ToS into concise\nplain-language summaries. To aid in reading the original text, TermSight offers\ncontextualized definitions and scenarios for unfamiliar phrases. Our\nwithin-subjects evaluation of TermSight (N=20) revealed that TermSight\nsignificantly reduced the difficulty of reading ToS and increased participants'\nwillingness to do so. We also observed emerging strategies that participants\ntook when interacting with AI-powered features that highlight the diverse ways\nthat TermSight assisted ToS reading.", "AI": {"tldr": "TermSight\u662f\u4e00\u4e2a\u667a\u80fd\u9605\u8bfb\u754c\u9762\uff0c\u65e8\u5728\u901a\u8fc7\u53ef\u89c6\u5316\u6458\u8981\u548c\u7b80\u5316\u8bed\u8a00\u4f7fToS\u66f4\u6613\u4e8e\u7406\u89e3\u3002", "motivation": "ToS\u901a\u5e38\u5185\u5bb9\u590d\u6742\u4e14\u5197\u957f\uff0c\u7528\u6237\u96be\u4ee5\u9605\u8bfb\u548c\u7406\u89e3\u3002", "method": "TermSight\u63d0\u4f9b\u53ef\u89c6\u5316\u6458\u8981\u3001\u5206\u7c7b\u548c\u7b80\u5316\u4fe1\u606f\u3001\u4e0a\u4e0b\u6587\u5b9a\u4e49\u548c\u573a\u666f\u8bf4\u660e\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cTermSight\u663e\u8457\u964d\u4f4e\u9605\u8bfb\u96be\u5ea6\u5e76\u63d0\u9ad8\u7528\u6237\u9605\u8bfb\u610f\u613f\u3002", "conclusion": "TermSight\u901a\u8fc7AI\u529f\u80fd\u591a\u6837\u5316\u8f85\u52a9ToS\u9605\u8bfb\uff0c\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2506.12488", "pdf": "https://arxiv.org/pdf/2506.12488", "abs": "https://arxiv.org/abs/2506.12488", "authors": ["Skander Krid", "Mihail Stoian", "Andreas Kipf"], "title": "Redbench: A Benchmark Reflecting Real Workloads", "categories": ["cs.DB"], "comment": "Eighth International Workshop on Exploiting Artificial Intelligence\n  Techniques for Data Management (aiDM 2025)", "summary": "Instance-optimized components have made their way into production systems. To\nsome extent, this adoption is due to the characteristics of customer workloads,\nwhich can be individually leveraged during the model training phase. However,\nthere is a gap between research and industry that impedes the development of\nrealistic learned components: the lack of suitable workloads. Existing ones,\nsuch as TPC-H and TPC-DS, and even more recent ones, such as DSB and CAB, fail\nto exhibit real workload patterns, particularly distribution shifts.\n  In this paper, we introduce Redbench, a collection of 30 workloads that\nreflect query patterns observed in the real world. The workloads were obtained\nby sampling queries from support benchmarks and aligning them with workload\ncharacteristics observed in Redset.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Redbench\uff0c\u4e00\u4e2a\u5305\u542b30\u4e2a\u771f\u5b9e\u67e5\u8be2\u6a21\u5f0f\u7684\u5de5\u4f5c\u8d1f\u8f7d\u96c6\u5408\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u672a\u5728\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982TPC-H\u3001TPC-DS\u3001DSB\u3001CAB\uff09\u4e2d\u4f53\u73b0\uff0c\u963b\u788d\u4e86\u5b66\u4e60\u7ec4\u4ef6\u7684\u5b9e\u9645\u5e94\u7528\u5f00\u53d1\u3002", "method": "\u901a\u8fc7\u4ece\u652f\u6301\u57fa\u51c6\u4e2d\u91c7\u6837\u67e5\u8be2\u5e76\u4e0eRedset\u4e2d\u89c2\u5bdf\u5230\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u5bf9\u9f50\uff0c\u6784\u5efaRedbench\u3002", "result": "Redbench\u63d0\u4f9b\u4e8630\u4e2a\u53cd\u6620\u771f\u5b9e\u67e5\u8be2\u6a21\u5f0f\u7684\u5de5\u4f5c\u8d1f\u8f7d\u3002", "conclusion": "Redbench\u586b\u8865\u4e86\u7814\u7a76\u548c\u884c\u4e1a\u4e4b\u95f4\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6570\u636e\u7f3a\u53e3\uff0c\u63a8\u52a8\u4e86\u66f4\u73b0\u5b9e\u7684\u5b66\u4e60\u7ec4\u4ef6\u5f00\u53d1\u3002"}}
{"id": "2506.12794", "pdf": "https://arxiv.org/pdf/2506.12794", "abs": "https://arxiv.org/abs/2506.12794", "authors": ["Evgenii Vinogradov", "Abdul Saboor", "Zhuangzhuang Cui", "Aymen Fakhreddine"], "title": "Spatially Consistent Air-to-Ground Channel Modeling with Probabilistic LOS/NLOS Segmentation", "categories": ["cs.ET", "eess.SP"], "comment": "accepted for IEEE VTC-Spring 2025 workshop on Innovations in Advanced\n  Air Mobility and Non-Terrestrial Networks", "summary": "In this paper, we present a spatially consistent A2G channel model based on\nprobabilistic LOS/NLOS segmentation to parameterize the deterministic path loss\nand stochastic shadow fading model. Motivated by the limitations of existing\nUnmanned Aerial Vehicle (UAV) channel models that overlook spatial correlation,\nour approach reproduces LOS/NLOS transitions along ground user trajectories in\nurban environments. This model captures environment-specific obstructions by\nmeans of azimuth and elevation-dependent LOS probabilities without requiring a\nfull detailed 3D representation of the surroundings. We validate our framework\nagainst a geometry-based simulator by evaluating it across various urban\nsettings. The results demonstrate its accuracy and computational efficiency,\nenabling further realistic derivations of path loss and shadow fading models\nand thorough outage analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387LOS/NLOS\u5206\u5272\u7684\u7a7a\u95f4\u4e00\u81f4\u6027A2G\u4fe1\u9053\u6a21\u578b\uff0c\u7528\u4e8e\u53c2\u6570\u5316\u786e\u5b9a\u6027\u8def\u5f84\u635f\u8017\u548c\u968f\u673a\u9634\u5f71\u8870\u843d\u6a21\u578b\u3002", "motivation": "\u73b0\u6709UAV\u4fe1\u9053\u6a21\u578b\u5ffd\u89c6\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u672c\u6587\u6a21\u578b\u80fd\u91cd\u73b0\u57ce\u5e02\u73af\u5883\u4e2d\u5730\u9762\u7528\u6237\u8f68\u8ff9\u7684LOS/NLOS\u8fc7\u6e21\u3002", "method": "\u901a\u8fc7\u65b9\u4f4d\u89d2\u548c\u4ef0\u89d2\u76f8\u5173\u7684LOS\u6982\u7387\u6355\u6349\u73af\u5883\u906e\u6321\uff0c\u65e0\u9700\u5b8c\u65743D\u73af\u5883\u6a21\u578b\uff0c\u5e76\u7528\u51e0\u4f55\u4eff\u771f\u5668\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u5728\u591a\u79cd\u57ce\u5e02\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u652f\u6301\u8def\u5f84\u635f\u8017\u548c\u9634\u5f71\u8870\u843d\u6a21\u578b\u7684\u751f\u6210\u53ca\u4e2d\u65ad\u5206\u6790\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3aA2G\u4fe1\u9053\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u57ce\u5e02\u73af\u5883\u3002"}}
{"id": "2506.12968", "pdf": "https://arxiv.org/pdf/2506.12968", "abs": "https://arxiv.org/abs/2506.12968", "authors": ["Vasileios Leon", "Charalampos Bezaitis", "George Lentaris", "Dimitrios Soudris", "Dionysios Reisis", "Elissaios-Alexios Papatheofanous", "Angelos Kyriakos", "Aubrey Dunne", "Arne Samuelsson", "David Steenari"], "title": "FPGA & VPU Co-Processing in Space Applications: Development and Testing with DSP/AI Benchmarks", "categories": ["cs.AR"], "comment": "Presented at the 28th IEEE ICECS Conference", "summary": "The advent of computationally demanding algorithms and high data rate\ninstruments in new space applications pushes the space industry to explore\ndisruptive solutions for on-board data processing. We examine heterogeneous\ncomputing architectures involving high-performance and low-power commercial\nSoCs. The current paper implements an FPGA with VPU co-processing architecture\nutilizing the CIF & LCD interfaces for I/O data transfers. A Kintex FPGA serves\nas our framing processor and heritage accelerator, while we offload novel\nDSP/AI functions to a Myriad2 VPU. We prototype our architecture in the lab to\nevaluate the interfaces, the FPGA resource utilization, the VPU computational\nthroughput, as well as the entire data handling system's performance, via\ncustom benchmarking.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u822a\u5929\u5e94\u7528\u4e2d\u5f02\u6784\u8ba1\u7b97\u67b6\u6784\u7684\u4f7f\u7528\uff0c\u91c7\u7528FPGA\u548cVPU\u534f\u540c\u5904\u7406\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u822a\u5929\u5e94\u7528\u4e2d\u5bf9\u9ad8\u6027\u80fd\u548c\u4f4e\u529f\u8017\u8ba1\u7b97\u7684\u9700\u6c42\u63a8\u52a8\u4e86\u5f02\u6784\u8ba1\u7b97\u67b6\u6784\u7684\u7814\u7a76\u3002", "method": "\u4f7f\u7528Kintex FPGA\u4f5c\u4e3a\u6846\u67b6\u5904\u7406\u5668\uff0cMyriad2 VPU\u7528\u4e8eDSP/AI\u529f\u80fd\uff0c\u901a\u8fc7CIF\u548cLCD\u63a5\u53e3\u4f20\u8f93\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u539f\u578b\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u63a5\u53e3\u6027\u80fd\u3001FPGA\u8d44\u6e90\u5229\u7528\u7387\u548cVPU\u8ba1\u7b97\u541e\u5410\u91cf\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6570\u636e\u5904\u7406\u80fd\u529b\u3002", "conclusion": "\u5f02\u6784\u8ba1\u7b97\u67b6\u6784\u5728\u822a\u5929\u6570\u636e\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u80fd\u591f\u6ee1\u8db3\u9ad8\u6027\u80fd\u548c\u4f4e\u529f\u8017\u9700\u6c42\u3002"}}
{"id": "2506.12415", "pdf": "https://arxiv.org/pdf/2506.12415", "abs": "https://arxiv.org/abs/2506.12415", "authors": ["Ashutosh Shankar", "Astha Kumari"], "title": "QoS-aware Scheduling of Periodic Real-time Task Graphs on Heterogeneous Pre-occupied MECs", "categories": ["cs.DC"], "comment": "9 pages, 8 figures, 1 table,2 algorithm", "summary": "In latency-sensitive applications, efficient task scheduling is crucial for\nmaintaining Quality of Service (QoS) while meeting strict timing constraints.\nThis paper addresses the challenge of scheduling periodic tasks structured as\ndirected acyclic graphs (DAGs) within heterogeneous, pre-occupied Mobile Edge\nComputing (MEC) networks. We propose a modified version of the Heterogeneous\nEarliest Finish Time (HEFT) algorithm designed to exploit residual processing\ncapacity in preoccupied MEC environments. Our approach dynamically identifies\nidle intervals on processors to create a feasible hyperperiodic schedule that\nspecifies an allocated virtual machine (VM), task version, and start time for\neach task. This scheduling strategy maximizes the aggregate QoS by optimizing\ntask execution without disrupting the existing periodic workload, while also\nadhering to periodicity, precedence, and resource constraints.Experimental\nresults demonstrate that our method achieves enhanced load balancing and\nresource utilization, highlighting its potential to improve performance in\nheterogeneous MEC infrastructures supporting real-time, periodic applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684HEFT\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u5f02\u6784\u3001\u9884\u5360\u7528\u7684\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u4e2d\u8c03\u5ea6\u5468\u671f\u6027DAG\u4efb\u52a1\uff0c\u4ee5\u4f18\u5316QoS\u5e76\u6ee1\u8db3\u4e25\u683c\u7684\u65f6\u95f4\u7ea6\u675f\u3002", "motivation": "\u5728\u5ef6\u8fdf\u654f\u611f\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\uff0c\u9ad8\u6548\u7684\u8c03\u5ea6\u5bf9\u4e8e\u4fdd\u6301\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u81f3\u5173\u91cd\u8981\u3002\u7279\u522b\u662f\u5728\u5f02\u6784\u3001\u9884\u5360\u7528\u7684MEC\u7f51\u7edc\u4e2d\uff0c\u5982\u4f55\u5229\u7528\u5269\u4f59\u5904\u7406\u80fd\u529b\u8c03\u5ea6\u5468\u671f\u6027DAG\u4efb\u52a1\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u8bc6\u522b\u5904\u7406\u5668\u4e0a\u7684\u7a7a\u95f2\u65f6\u6bb5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684HEFT\u7b97\u6cd5\uff0c\u751f\u6210\u8d85\u5468\u671f\u8c03\u5ea6\u65b9\u6848\uff0c\u4f18\u5316\u4efb\u52a1\u6267\u884c\u800c\u4e0d\u5e72\u6270\u73b0\u6709\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8d1f\u8f7d\u5747\u8861\u548c\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5408\u652f\u6301\u5b9e\u65f6\u5468\u671f\u6027\u5e94\u7528\u7684\u5f02\u6784MEC\u57fa\u7840\u8bbe\u65bd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1QoS\u548c\u8d44\u6e90\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86MEC\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u8c03\u5ea6\u6548\u7387\u3002"}}
{"id": "2506.12616", "pdf": "https://arxiv.org/pdf/2506.12616", "abs": "https://arxiv.org/abs/2506.12616", "authors": ["Debasish Jana", "Pinakpani Pal", "Pawan Kumar"], "title": "Real-Time Agile Software Management for Edge and Fog Computing Based Smart City Infrastructure", "categories": ["cs.SE"], "comment": "The paper has been published at the Fifth International Conference on\n  Computing and Communication Networks (ICCCN 2025), Volume 1", "summary": "The evolution of smart cities demands scalable, secure, and energy-efficient\narchitectures for real-time data processing. With the number of IoT devices\nexpected to exceed 40 billion by 2030, traditional cloud-based systems are\nincreasingly constrained by bandwidth, latency, and energy limitations. This\npaper leverages the ROOF (Real-time Onsite Operations Facilitation) framework\nwith decentralized computing at intermediary fog and peripheral edge network\nlayers to reduce latency by processing data near its point of origin. ROOF\nfeatures fog caching to avoid redundancy, ultra-low-power wireless transmission\nfor energy savings, and AI-driven resource allocation for efficiency. Security\nis enhanced through TLS encryption, blockchain-based authentication, and\nedge-level access control. Case studies from Bhubaneswar, Barcelona and\nCopenhagen validate the use of ROOF in traffic systems and environmental\nmonitoring. The paper concludes by outlining key challenges and prospects of\nAI-driven analytics in smart urban infrastructure.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86ROOF\u6846\u67b6\uff0c\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u8ba1\u7b97\u548c\u8fb9\u7f18\u7f51\u7edc\u5206\u5c42\u964d\u4f4e\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u80fd\u6548\uff0c\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4e91\u7cfb\u7edf\u5728\u5e26\u5bbd\u3001\u5ef6\u8fdf\u548c\u80fd\u6e90\u65b9\u9762\u7684\u9650\u5236\uff0c\u6ee1\u8db3\u667a\u80fd\u57ce\u5e02\u5bf9\u5b9e\u65f6\u6570\u636e\u5904\u7406\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528ROOF\u6846\u67b6\uff0c\u7ed3\u5408\u96fe\u8ba1\u7b97\u548c\u8fb9\u7f18\u7f51\u7edc\u5206\u5c42\uff0c\u5229\u7528AI\u9a71\u52a8\u7684\u8d44\u6e90\u5206\u914d\u548c\u5b89\u5168\u6280\u672f\uff08\u5982TLS\u52a0\u5bc6\u548c\u533a\u5757\u94fe\u8ba4\u8bc1\uff09\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cROOF\u5728\u4ea4\u901a\u7cfb\u7edf\u548c\u73af\u5883\u76d1\u6d4b\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u4e86\u80fd\u6548\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86AI\u9a71\u52a8\u5206\u6790\u5728\u667a\u80fd\u57ce\u5e02\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u6311\u6218\u548c\u524d\u666f\u3002"}}
{"id": "2506.13001", "pdf": "https://arxiv.org/pdf/2506.13001", "abs": "https://arxiv.org/abs/2506.13001", "authors": ["Christian Zhou-Zheng", "Philippe Pasquier"], "title": "Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS", "I.2.1; I.2.6; H.5.5; J.5"], "comment": null, "summary": "Existing work in automatic music generation has primarily focused on\nend-to-end systems that produce complete compositions or continuations.\nHowever, because musical composition is typically an iterative process, such\nsystems make it difficult to engage in the back-and-forth between human and\nmachine that is essential to computer-assisted creativity. In this study, we\naddress the task of personalizable, multi-track, long-context, and controllable\nsymbolic music infilling to enhance the process of computer-assisted\ncomposition. We present MIDI-RWKV, a novel model based on the RWKV-7 linear\narchitecture, to enable efficient and coherent musical cocreation on edge\ndevices. We also demonstrate that MIDI-RWKV admits an effective method of\nfinetuning its initial state for personalization in the very-low-sample regime.\nWe evaluate MIDI-RWKV and its state tuning on several quantitative and\nqualitative metrics, and release model weights and code at\nhttps://github.com/christianazinn/MIDI-RWKV.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRWKV-7\u7ebf\u6027\u67b6\u6784\u7684\u65b0\u6a21\u578bMIDI-RWKV\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u3001\u591a\u8f68\u9053\u3001\u957f\u4e0a\u4e0b\u6587\u548c\u53ef\u63a7\u7684\u7b26\u53f7\u97f3\u4e50\u586b\u5145\uff0c\u4ee5\u589e\u5f3a\u8ba1\u7b97\u673a\u8f85\u52a9\u4f5c\u66f2\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u97f3\u4e50\u751f\u6210\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u7aef\u5230\u7aef\u7cfb\u7edf\u751f\u6210\u5b8c\u6574\u4f5c\u54c1\u6216\u5ef6\u7eed\uff0c\u4f46\u7f3a\u4e4f\u4eba\u673a\u4ea4\u4e92\u7684\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u9650\u5236\u4e86\u8ba1\u7b97\u673a\u8f85\u52a9\u521b\u4f5c\u7684\u6548\u679c\u3002", "method": "\u91c7\u7528RWKV-7\u7ebf\u6027\u67b6\u6784\u8bbe\u8ba1MIDI-RWKV\u6a21\u578b\uff0c\u652f\u6301\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u534f\u540c\u521b\u4f5c\uff0c\u5e76\u63d0\u4f9b\u521d\u59cb\u72b6\u6001\u5fae\u8c03\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u4f4e\u6837\u672c\u4e2a\u6027\u5316\u3002", "result": "\u5b9e\u9a8c\u901a\u8fc7\u591a\u9879\u5b9a\u91cf\u548c\u5b9a\u6027\u6307\u6807\u8bc4\u4f30\u4e86MIDI-RWKV\u53ca\u5176\u72b6\u6001\u5fae\u8c03\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "MIDI-RWKV\u4e3a\u8ba1\u7b97\u673a\u8f85\u52a9\u4f5c\u66f2\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u534f\u540c\u521b\u4f5c\u5de5\u5177\uff0c\u540c\u65f6\u901a\u8fc7\u72b6\u6001\u5fae\u8c03\u5b9e\u73b0\u4e86\u4f4e\u6837\u672c\u4e2a\u6027\u5316\u3002"}}
{"id": "2506.13157", "pdf": "https://arxiv.org/pdf/2506.13157", "abs": "https://arxiv.org/abs/2506.13157", "authors": ["Theofanis Aravanis"], "title": "Machine Learning as Iterated Belief Change a la Darwiche and Pearl", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.NE"], "comment": null, "summary": "Artificial Neural Networks (ANNs) are powerful machine-learning models\ncapable of capturing intricate non-linear relationships. They are widely used\nnowadays across numerous scientific and engineering domains, driving\nadvancements in both research and real-world applications. In our recent work,\nwe focused on the statics and dynamics of a particular subclass of ANNs, which\nwe refer to as binary ANNs. A binary ANN is a feed-forward network in which\nboth inputs and outputs are restricted to binary values, making it particularly\nsuitable for a variety of practical use cases. Our previous study approached\nbinary ANNs through the lens of belief-change theory, specifically the\nAlchourron, Gardenfors and Makinson (AGM) framework, yielding several key\ninsights. Most notably, we demonstrated that the knowledge embodied in a binary\nANN (expressed through its input-output behaviour) can be symbolically\nrepresented using a propositional logic language. Moreover, the process of\nmodifying a belief set (through revision or contraction) was mapped onto a\ngradual transition through a series of intermediate belief sets. Analogously,\nthe training of binary ANNs was conceptualized as a sequence of such belief-set\ntransitions, which we showed can be formalized using full-meet AGM-style belief\nchange. In the present article, we extend this line of investigation by\naddressing some critical limitations of our previous study. Specifically, we\nshow that Dalal's method for belief change naturally induces a structured,\ngradual evolution of states of belief. More importantly, given the known\nshortcomings of full-meet belief change, we demonstrate that the training\ndynamics of binary ANNs can be more effectively modelled using robust AGM-style\nchange operations -- namely, lexicographic revision and moderate contraction --\nthat align with the Darwiche-Pearl framework for iterated belief change.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e8c\u8fdb\u5236\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANNs\uff09\u7684\u9759\u6001\u548c\u52a8\u6001\u7279\u6027\uff0c\u901a\u8fc7\u4fe1\u5ff5\u53d8\u5316\u7406\u8bba\uff08\u5982AGM\u6846\u67b6\uff09\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u6539\u8fdb\u4e86\u5148\u524d\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4f7f\u7528Dalal\u65b9\u6cd5\u548cDarwiche-Pearl\u6846\u67b6\u6765\u66f4\u6709\u6548\u5730\u63cf\u8ff0ANN\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "motivation": "\u4e8c\u8fdb\u5236ANNs\u56e0\u5176\u8f93\u5165\u8f93\u51fa\u7684\u4e8c\u8fdb\u5236\u7279\u6027\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u5e7f\u6cdb\u7528\u9014\u3002\u5148\u524d\u7684\u7814\u7a76\u901a\u8fc7AGM\u6846\u67b6\u4e3a\u4e8c\u8fdb\u5236ANNs\u63d0\u4f9b\u4e86\u7b26\u53f7\u5316\u7684\u903b\u8f91\u8868\u793a\u548c\u8bad\u7ec3\u52a8\u6001\u7684\u6a21\u578b\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\u6027\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u8db3\u3002", "method": "\u91c7\u7528Dalal\u7684\u4fe1\u5ff5\u53d8\u5316\u65b9\u6cd5\u548cDarwiche-Pearl\u6846\u67b6\u4e2d\u7684\u8bcd\u5178\u4fee\u8ba2\u4e0e\u9002\u5ea6\u6536\u7f29\u64cd\u4f5c\uff0c\u4ee5\u66ff\u4ee3\u4e4b\u524d\u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u5168\u4ea4\u4fe1\u5ff5\u53d8\u5316\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cDalal\u65b9\u6cd5\u80fd\u81ea\u7136\u5730\u8bf1\u5bfc\u4fe1\u5ff5\u72b6\u6001\u7684\u6e10\u8fdb\u6f14\u5316\uff0c\u800c\u8bcd\u5178\u4fee\u8ba2\u548c\u9002\u5ea6\u6536\u7f29\u64cd\u4f5c\u80fd\u66f4\u6709\u6548\u5730\u5efa\u6a21\u4e8c\u8fdb\u5236ANNs\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u5bf9\u4e8c\u8fdb\u5236ANNs\u7684\u7406\u89e3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u4fe1\u5ff5\u53d8\u5316\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2506.13212", "pdf": "https://arxiv.org/pdf/2506.13212", "abs": "https://arxiv.org/abs/2506.13212", "authors": ["Filippo Maggioli", "Marco Livesu", "Simone Melzi"], "title": "Volumetric Functional Maps", "categories": ["cs.GR", "cs.CG", "68U05", "I.3"], "comment": null, "summary": "The computation of volumetric correspondences between 3D shapes has great\npotential for medical and industrial applications. In this work, we pave the\nway for spectral volume mapping, extending for the first time the functional\nmaps framework from the surface setting to the volumetric domain. We show that\nthe eigenfunctions of the volumetric Laplace operator define a functional space\nthat is suitable for high-quality signal transfer. We also experiment with\nvarious techniques that edit this functional space, porting them from the\nsurface to the volume setting. We validate our method on novel volumetric\ndatasets and on tetrahedralizations of well established surface datasets, also\nshowcasing practical applications involving both discrete and continuous signal\nmapping, for segmentation transfer, mesh connectivity transfer and solid\ntexturing. Last but not least, we show that considering the volumetric spectrum\ngreatly improves the accuracy for classical shape matching tasks among\nsurfaces, consistently outperforming existing surface-only spectral methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u529f\u80fd\u6620\u5c04\u6846\u67b6\u4ece\u8868\u9762\u6269\u5c55\u5230\u4f53\u79ef\u57df\u7684\u5149\u8c31\u4f53\u79ef\u6620\u5c04\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u4fe1\u53f7\u4f20\u8f93\u548c\u5f62\u72b6\u5339\u914d\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u6027\u3002", "motivation": "\u4f53\u79ef\u5bf9\u5e94\u8ba1\u7b97\u5728\u533b\u5b66\u548c\u5de5\u4e1a\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\u9700\u6c42\uff0c\u4f46\u76ee\u524d\u529f\u80fd\u6620\u5c04\u6846\u67b6\u4ec5\u9002\u7528\u4e8e\u8868\u9762\uff0c\u6269\u5c55\u81f3\u4f53\u79ef\u57df\u5177\u6709\u6f5c\u5728\u4ef7\u503c\u3002", "method": "\u5229\u7528\u4f53\u79ef\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u7684\u7279\u5f81\u51fd\u6570\u6784\u5efa\u529f\u80fd\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u7f16\u8f91\u8be5\u7a7a\u95f4\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4fe1\u53f7\u4f20\u8f93\u3002", "result": "\u65b9\u6cd5\u5728\u4f53\u79ef\u6570\u636e\u96c6\u548c\u8868\u9762\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u652f\u6301\u79bb\u6563\u548c\u8fde\u7eed\u4fe1\u53f7\u6620\u5c04\uff0c\u63d0\u5347\u4e86\u5f62\u72b6\u5339\u914d\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5149\u8c31\u4f53\u79ef\u6620\u5c04\u4e0d\u4ec5\u6269\u5c55\u4e86\u529f\u80fd\u6620\u5c04\u7684\u5e94\u7528\u8303\u56f4\uff0c\u8fd8\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u8868\u9762\u8c31\u65b9\u6cd5\u3002"}}
{"id": "2506.12118", "pdf": "https://arxiv.org/pdf/2506.12118", "abs": "https://arxiv.org/abs/2506.12118", "authors": ["Arijeet Ganguli", "Marco Ruffini"], "title": "Real-Time Capable, Low-latency Upstream Scheduling in Multi-Tenant, SLA Compliant TWDM PON", "categories": ["cs.NI"], "comment": null, "summary": "Virtualized Passive Optical Networks (vPONs) offer a promising solution for\nmodern access networks, bringing enhanced flexibility, reduced capital\nexpenditures (CapEx), and support for multi-tenancy. By decoupling network\nfunctions from physical infrastructure, vPONs enable service providers to\nefficiently share network resources among multiple tenants. In this paper, we\npropose a novel merging DBA algorithm, called the Dynamic Time and Wavelength\nAllocation (DTWA) algorithm, for a virtualized DBA (vDBA) architecture in\nmulti-tenant PON environments. The Algorithm, which enables the merging of\nmultiple virtual DBAs into a physical bandwidth map, introduces multi-channel\nsupport, allowing each Optical Network Unit (ONU) to dynamically change, taking\ninto consideration different switching times, transmission wavelength.\nLeveraging the Numba APIs for high-performance optimization, the algorithm\nachieves real-time performance with minimal additional latency, meeting the\nstringent requirements of SLA-compliant, latency-critical 6G applications and\nservices. Our analysis highlights an important trade-off in terms of throughput\nin multi-tenant conditions, between single-channel vs. multi-channel PONs, as a\nfunction of ONUs tuning time. We also compare the performance of our algorithm\nfor different traffic distributions. Finally, in order to assess the time\ncomputing penalty of dynamic wavelength optimisation in the merging DBA\nalgorithm, we compare it against a baseline Static Wavelength Allocation (SWA)\nalgorithm, where ONUs are designated a fixed wavelength for transmission.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684DTWA\u7b97\u6cd5\uff0c\u7528\u4e8e\u591a\u79df\u6237PON\u73af\u5883\u4e0b\u7684vDBA\u67b6\u6784\uff0c\u652f\u6301\u591a\u901a\u9053\u52a8\u6001\u5206\u914d\uff0c\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u9700\u6c42\uff0c\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u73b0\u4ee3\u63a5\u5165\u7f51\u7edc\u9700\u8981\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u548c\u591a\u79df\u6237\u652f\u6301\uff0cvPONs\u901a\u8fc7\u89e3\u8026\u7f51\u7edc\u529f\u80fd\u4e0e\u7269\u7406\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9700\u8981\u9ad8\u6548\u7684DBA\u7b97\u6cd5\u6765\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "method": "\u63d0\u51faDTWA\u7b97\u6cd5\uff0c\u7ed3\u5408\u591a\u901a\u9053\u652f\u6301\u548c\u52a8\u6001\u6ce2\u957f\u5206\u914d\uff0c\u5229\u7528Numba API\u5b9e\u73b0\u9ad8\u6027\u80fd\u4f18\u5316\uff0c\u5b9e\u65f6\u5904\u7406\u5e26\u5bbd\u6620\u5c04\u3002", "result": "\u7b97\u6cd5\u5728\u591a\u79df\u6237\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u541e\u5410\u91cf\uff0c\u4f46\u9700\u6743\u8861\u5355\u901a\u9053\u4e0e\u591a\u901a\u9053PON\u7684\u6027\u80fd\u53d7ONU\u8c03\u8c10\u65f6\u95f4\u5f71\u54cd\u3002", "conclusion": "DTWA\u7b97\u6cd5\u5728\u591a\u79df\u6237PON\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u9002\u7528\u4e8e6G\u5e94\u7528\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u9002\u914d\u4e0d\u540c\u4e1a\u52a1\u5206\u5e03\u3002"}}
{"id": "2506.12339", "pdf": "https://arxiv.org/pdf/2506.12339", "abs": "https://arxiv.org/abs/2506.12339", "authors": ["Ruiyan Zhu", "Xi Cheng", "Ke Liu", "Brian Zhu", "Daniel Jin", "Neeraj Parihar", "Zhoutian Xu", "Oliver Gao"], "title": "SheetMind: An End-to-End LLM-Powered Multi-Agent Framework for Spreadsheet Automation", "categories": ["cs.HC", "cs.AI"], "comment": "Ruiyan Zhu and Xi Cheng contributed equally to this work", "summary": "We present SheetMind, a modular multi-agent framework powered by large\nlanguage models (LLMs) for spreadsheet automation via natural language\ninstructions. The system comprises three specialized agents: a Manager Agent\nthat decomposes complex user instructions into subtasks; an Action Agent that\ntranslates these into structured commands using a Backus Naur Form (BNF)\ngrammar; and a Reflection Agent that validates alignment between generated\nactions and the user's original intent. Integrated into Google Sheets via a\nWorkspace extension, SheetMind supports real-time interaction without requiring\nscripting or formula knowledge. Experiments on benchmark datasets demonstrate\nan 80 percent success rate on single step tasks and approximately 70 percent on\nmulti step instructions, outperforming ablated and baseline variants. Our\nresults highlight the effectiveness of multi agent decomposition and grammar\nbased execution for bridging natural language and spreadsheet functionalities.", "AI": {"tldr": "SheetMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u5757\u5316\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u81ea\u52a8\u5316\u7535\u5b50\u8868\u683c\u64cd\u4f5c\uff0c\u5305\u542b\u4e09\u4e2a\u4ee3\u7406\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5355\u6b65\u548c\u591a\u6b65\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u76ee\u7684\u662f\u901a\u8fc7\u591a\u4ee3\u7406\u7cfb\u7edf\u548c\u7ed3\u6784\u5316\u547d\u4ee4\uff0c\u8ba9\u7528\u6237\u65e0\u9700\u7f16\u7a0b\u77e5\u8bc6\u5373\u53ef\u7528\u81ea\u7136\u8bed\u8a00\u64cd\u4f5c\u7535\u5b50\u8868\u683c\uff0c\u63d0\u5347\u6548\u7387\u548c\u6613\u7528\u6027\u3002", "method": "\u6846\u67b6\u5305\u542bManager Agent\uff08\u5206\u89e3\u4efb\u52a1\uff09\u3001Action Agent\uff08\u7528BNF\u8bed\u6cd5\u751f\u6210\u547d\u4ee4\uff09\u3001Reflection Agent\uff08\u9a8c\u8bc1\u4efb\u52a1\u4e00\u81f4\u6027\uff09\uff0c\u5e76\u96c6\u6210\u5230Google Sheets\u4e2d\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5355\u6b65\u4efb\u52a1\u6210\u529f\u738780%\uff0c\u591a\u6b65\u4efb\u52a1\u7ea670%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u591a\u4ee3\u7406\u5206\u89e3\u548c\u8bed\u6cd5\u9a71\u52a8\u7684\u6267\u884c\u80fd\u6709\u6548\u8fde\u63a5\u81ea\u7136\u8bed\u8a00\u4e0e\u7535\u5b50\u8868\u683c\u529f\u80fd\u3002"}}
{"id": "2506.12837", "pdf": "https://arxiv.org/pdf/2506.12837", "abs": "https://arxiv.org/abs/2506.12837", "authors": ["Haodi Zhang", "Siqi Ning", "Qiyong Zheng", "Jinyin Nie", "Liangjie Zhang", "Weicheng Wang", "Yuanfeng Song"], "title": "Towards Visualizing Electronic Medical Records via Natural Language Queries", "categories": ["cs.DB"], "comment": null, "summary": "Electronic medical records (EMRs) contain essential data for patient care and\nclinical research. With the diversity of structured and unstructured data in\nEHR, data visualization is an invaluable tool for managing and explaining these\ncomplexities. However, the scarcity of relevant medical visualization data and\nthe high cost of manual annotation required to develop such datasets pose\nsignificant challenges to advancing medical visualization techniques. To\naddress this issue, we propose an innovative approach using large language\nmodels (LLMs) for generating visualization data without labor-intensive manual\nannotation. We introduce a new pipeline for building text-to-visualization\nbenchmarks suitable for EMRs, enabling users to visualize EMR statistics\nthrough natural language queries (NLQs). The dataset presented in this paper\nprimarily consists of paired text medical records, NLQs, and corresponding\nvisualizations, forming the first large-scale text-to-visual dataset for\nelectronic medical record information called MedicalVis with 35,374 examples.\nAdditionally, we introduce an LLM-based approach called MedCodeT5, showcasing\nits viability in generating EMR visualizations from NLQs, outperforming various\nstrong text-to-visualization baselines. Our work facilitates standardized\nevaluation of EMR visualization methods while providing researchers with tools\nto advance this influential field of application. In a nutshell, this study and\ndataset have the potential to promote advancements in eliciting medical\ninsights through visualization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7535\u5b50\u75c5\u5386\u53ef\u89c6\u5316\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u624b\u52a8\u6807\u6ce8\u7684\u9ad8\u6210\u672c\uff0c\u5e76\u521b\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u7535\u5b50\u75c5\u5386\u6587\u672c-\u53ef\u89c6\u5316\u6570\u636e\u96c6MedicalVis\u3002", "motivation": "\u7535\u5b50\u75c5\u5386\u6570\u636e\u590d\u6742\u4e14\u7f3a\u4e4f\u76f8\u5173\u53ef\u89c6\u5316\u6570\u636e\u96c6\uff0c\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u4e9f\u9700\u521b\u65b0\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u5efa\u6587\u672c\u5230\u53ef\u89c6\u5316\u7684\u7ba1\u9053\uff0c\u751f\u6210NLQs\u4e0e\u5bf9\u5e94\u7684\u53ef\u89c6\u5316\u6570\u636e\uff0c\u5e76\u63d0\u51faMedCodeT5\u6a21\u578b\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b35,374\u4e2a\u793a\u4f8b\u7684MedicalVis\u6570\u636e\u96c6\uff0cMedCodeT5\u5728\u751f\u6210\u7535\u5b50\u75c5\u5386\u53ef\u89c6\u5316\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7535\u5b50\u75c5\u5386\u53ef\u89c6\u5316\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u901a\u8fc7\u53ef\u89c6\u5316\u63d0\u53d6\u533b\u5b66\u6d1e\u5bdf\u7684\u8fdb\u5c55\u3002"}}
{"id": "2506.12795", "pdf": "https://arxiv.org/pdf/2506.12795", "abs": "https://arxiv.org/abs/2506.12795", "authors": ["Mehdi Bennis"], "title": "Resilient-native and Intelligent NextG Systems", "categories": ["cs.ET", "cs.AI"], "comment": null, "summary": "Just like power, water and transportation systems, wireless networks are a\ncrucial societal infrastructure. As natural and human-induced disruptions\ncontinue to grow, wireless networks must be resilient to unforeseen events,\nable to withstand and recover from unexpected adverse conditions, shocks,\nunmodeled disturbances and cascading failures. Despite its critical importance,\nresilience remains an elusive concept, with its mathematical foundations still\nunderdeveloped. Unlike robustness and reliability, resilience is premised on\nthe fact that disruptions will inevitably happen. Resilience, in terms of\nelasticity, focuses on the ability to bounce back to favorable states, while\nresilience as plasticity involves agents (or networks) that can flexibly expand\ntheir states, hypotheses and course of actions, by transforming through\nreal-time adaptation and reconfiguration. This constant situational awareness\nand vigilance of adapting world models and counterfactually reasoning about\npotential system failures and the corresponding best responses, is a core\naspect of resilience. This article seeks to first define resilience and\ndisambiguate it from reliability and robustness, before delving into the\nmathematics of resilience. Finally, the article concludes by presenting nuanced\nmetrics and discussing trade-offs tailored to the unique characteristics of\nnetwork resilience.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u65e0\u7ebf\u7f51\u7edc\u4f5c\u4e3a\u5173\u952e\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u7684\u97e7\u6027\uff0c\u533a\u5206\u4e86\u97e7\u6027\u4e0e\u53ef\u9760\u6027\u3001\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u97e7\u6027\u7684\u6570\u5b66\u57fa\u7840\u548c\u5ea6\u91cf\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u81ea\u7136\u548c\u4eba\u4e3a\u4e2d\u65ad\u4e8b\u4ef6\u7684\u589e\u52a0\uff0c\u65e0\u7ebf\u7f51\u7edc\u9700\u8981\u5177\u5907\u62b5\u5fa1\u548c\u6062\u590d\u7684\u80fd\u529b\uff0c\u800c\u97e7\u6027\u7684\u6570\u5b66\u57fa\u7840\u5c1a\u672a\u5b8c\u5584\u3002", "method": "\u6587\u7ae0\u9996\u5148\u5b9a\u4e49\u97e7\u6027\u5e76\u533a\u5206\u5176\u4e0e\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7136\u540e\u6df1\u5165\u63a2\u8ba8\u97e7\u6027\u7684\u6570\u5b66\u57fa\u7840\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9\u7f51\u7edc\u97e7\u6027\u7279\u70b9\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u76f8\u5173\u6743\u8861\u3002", "conclusion": "\u6587\u7ae0\u5f3a\u8c03\u4e86\u97e7\u6027\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2506.12970", "pdf": "https://arxiv.org/pdf/2506.12970", "abs": "https://arxiv.org/abs/2506.12970", "authors": ["Vasileios Leon", "George Lentaris", "Dimitrios Soudris", "Simon Vellas", "Mathieu Bernou"], "title": "Towards Employing FPGA and ASIP Acceleration to Enable Onboard AI/ML in Space Applications", "categories": ["cs.AR"], "comment": "Presented at the 30th IFIP/IEEE VLSI-SoC Conference", "summary": "The success of AI/ML in terrestrial applications and the commercialization of\nspace are now paving the way for the advent of AI/ML in satellites. However,\nthe limited processing power of classical onboard processors drives the\ncommunity towards extending the use of FPGAs in space with both rad-hard and\nCommercial-Off-The-Shelf devices. The increased performance of FPGAs can be\ncomplemented with VPU or TPU ASIP co-processors to further facilitate\nhigh-level AI development and in-flight reconfiguration. Thus, selecting the\nmost suitable devices and designing the most efficient avionics architecture\nbecomes crucial for the success of novel space missions. The current work\npresents industrial trends, comparative studies with in-house benchmarking, as\nwell as architectural designs utilizing FPGAs and AI accelerators towards\nenabling AI/ML in future space missions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u536b\u661f\u4e2d\u5229\u7528FPGA\u548cAI\u52a0\u901f\u5668\u5b9e\u73b0AI/ML\u6280\u672f\uff0c\u5305\u62ec\u786c\u4ef6\u9009\u62e9\u548c\u67b6\u6784\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740AI/ML\u5728\u9646\u5730\u5e94\u7528\u4e2d\u7684\u6210\u529f\u548c\u5546\u4e1a\u822a\u5929\u7684\u53d1\u5c55\uff0c\u536b\u661f\u4e2d\u5f15\u5165AI/ML\u6280\u672f\u6210\u4e3a\u53ef\u80fd\uff0c\u4f46\u4f20\u7edf\u7684\u673a\u8f7d\u5904\u7406\u5668\u6027\u80fd\u6709\u9650\uff0c\u9700\u8981\u501f\u52a9FPGA\u548cAI\u52a0\u901f\u5668\u3002", "method": "\u901a\u8fc7\u5de5\u4e1a\u8d8b\u52bf\u5206\u6790\u3001\u5bf9\u6bd4\u7814\u7a76\u548c\u5185\u90e8\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bbe\u8ba1\u57fa\u4e8eFPGA\u548cAI\u52a0\u901f\u5668\u7684\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u4e86\u5229\u7528FPGA\u548cVPU/TPU\u534f\u5904\u7406\u5668\u5b9e\u73b0\u9ad8\u6027\u80fdAI\u5f00\u53d1\u548c\u52a8\u6001\u91cd\u6784\u7684\u65b9\u6848\u3002", "conclusion": "\u9009\u62e9\u5408\u9002\u7684\u8bbe\u5907\u548c\u8bbe\u8ba1\u9ad8\u6548\u67b6\u6784\u5bf9\u822a\u5929\u4efb\u52a1\u7684\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.12417", "pdf": "https://arxiv.org/pdf/2506.12417", "abs": "https://arxiv.org/abs/2506.12417", "authors": ["Zachary Douchet", "Rishi Sharma", "Martijn de Vos", "Rafael Pires", "Anne-Marie Kermarrec", "Oana Balmau"], "title": "HarMoEny: Efficient Multi-GPU Inference of MoE Models", "categories": ["cs.DC"], "comment": null, "summary": "Mixture-of-Experts (MoE) models offer computational efficiency during\ninference by activating only a subset of specialized experts for a given input.\nThis enables efficient model scaling on multi-GPU systems that use expert\nparallelism without compromising performance. However, load imbalance among\nexperts and GPUs introduces waiting times, which can significantly increase\ninference latency. To address this challenge, we propose HarMoEny, a novel\nsolution to address MoE load imbalance through two simple techniques: (i)\ndynamic token redistribution to underutilized GPUs and (ii) asynchronous\nprefetching of experts from the system to GPU memory. These techniques achieve\na near-perfect load balance among experts and GPUs and mitigate delays caused\nby overloaded GPUs. We implement HarMoEny and compare its latency and\nthroughput with four MoE baselines using real-world and synthetic datasets.\nUnder heavy load imbalance, HarMoEny increases throughput by 37%-70% and\nreduces time-to-first-token by 34%-41%, compared to the next-best baseline.\nMoreover, our ablation study demonstrates that HarMoEny's scheduling policy\nreduces the GPU idling time by up to 84% compared to the baseline policies.", "AI": {"tldr": "HarMoEny\u901a\u8fc7\u52a8\u6001\u4ee4\u724c\u91cd\u65b0\u5206\u914d\u548c\u5f02\u6b65\u9884\u53d6\u4e13\u5bb6\u6570\u636e\uff0c\u89e3\u51b3\u4e86MoE\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5747\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u5e76\u51cf\u5c11\u4e86\u5ef6\u8fdf\u3002", "motivation": "MoE\u6a21\u578b\u5728\u63a8\u7406\u65f6\u4ec5\u6709\u90e8\u5206\u4e13\u5bb6\u88ab\u6fc0\u6d3b\uff0c\u5bfc\u81f4GPU\u95f4\u8d1f\u8f7d\u4e0d\u5747\u548c\u7b49\u5f85\u65f6\u95f4\u589e\u52a0\uff0c\u5f71\u54cd\u63a8\u7406\u6548\u7387\u3002", "method": "\u91c7\u7528\u52a8\u6001\u4ee4\u724c\u91cd\u65b0\u5206\u914d\u548c\u5f02\u6b65\u9884\u53d6\u4e13\u5bb6\u6570\u636e\u7684\u6280\u672f\uff0c\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\u548c\u5ef6\u8fdf\u4f18\u5316\u3002", "result": "HarMoEny\u5728\u4e25\u91cd\u8d1f\u8f7d\u4e0d\u5747\u60c5\u51b5\u4e0b\uff0c\u541e\u5410\u91cf\u63d0\u534737%-70%\uff0c\u9996\u4ee4\u724c\u65f6\u95f4\u51cf\u5c1134%-41%\u3002", "conclusion": "HarMoEny\u6709\u6548\u89e3\u51b3\u4e86MoE\u6a21\u578b\u7684\u8d1f\u8f7d\u4e0d\u5747\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u548cGPU\u5229\u7528\u7387\u3002"}}
{"id": "2506.12643", "pdf": "https://arxiv.org/pdf/2506.12643", "abs": "https://arxiv.org/abs/2506.12643", "authors": ["Prachnachai Meakpaiboonwattana", "Warittha Tarntong", "Thai Mekratanavorakul", "Chaiyong Ragkhitwetsagul", "Pattaraporn Sangaroonsilp", "Raula Kula", "Morakot Choetkiertikul", "Kenichi Matsumoto", "Thanwadee Sunetnanta"], "title": "Social Media Reactions to Open Source Promotions: AI-Powered GitHub Projects on Hacker News", "categories": ["cs.SE"], "comment": null, "summary": "Social media platforms have become more influential than traditional news\nsources, shaping public discourse and accelerating the spread of information.\nWith the rapid advancement of artificial intelligence (AI), open-source\nsoftware (OSS) projects can leverage these platforms to gain visibility and\nattract contributors. In this study, we investigate the relationship between\nHacker News, a social news site focused on computer science and\nentrepreneurship, and the extent to which it influences developer activity on\nthe promoted GitHub AI projects.\n  We analyzed 2,195 Hacker News (HN) stories and their corresponding comments\nover a two-year period. Our findings reveal that at least 19\\% of AI developers\npromoted their GitHub projects on Hacker News, often receiving positive\nengagement from the community. By tracking activity on the associated 1,814\nGitHub repositories after they were shared on Hacker News, we observed a\nsignificant increase in forks, stars, and contributors. These results suggest\nthat Hacker News serves as a viable platform for AI-powered OSS projects, with\nthe potential to gain attention, foster community engagement, and accelerate\nsoftware development.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86Hacker News\u5bf9GitHub\u4e0aAI\u9879\u76ee\u5f00\u53d1\u8005\u6d3b\u52a8\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u901a\u8fc7\u8be5\u5e73\u53f0\u63a8\u5e7f\u80fd\u663e\u8457\u589e\u52a0\u9879\u76ee\u7684\u5173\u6ce8\u5ea6\u548c\u8d21\u732e\u8005\u3002", "motivation": "\u63a2\u7d22\u793e\u4ea4\u65b0\u95fb\u5e73\u53f0Hacker News\u5982\u4f55\u5f71\u54cd\u5f00\u6e90AI\u9879\u76ee\u7684\u5f00\u53d1\u8005\u6d3b\u52a8\uff0c\u4ee5\u9a8c\u8bc1\u5176\u4f5c\u4e3a\u63a8\u5e7f\u5de5\u5177\u7684\u6f5c\u529b\u3002", "method": "\u5206\u67902,195\u7bc7Hacker News\u6545\u4e8b\u53ca\u76f8\u5173\u8bc4\u8bba\uff0c\u5e76\u8ddf\u8e2a1,814\u4e2aGitHub\u4ed3\u5e93\u5728\u88ab\u5206\u4eab\u540e\u7684\u6d3b\u52a8\u53d8\u5316\u3002", "result": "19%\u7684AI\u5f00\u53d1\u8005\u5728Hacker News\u4e0a\u63a8\u5e7f\u9879\u76ee\uff0c\u5e76\u89c2\u5bdf\u5230\u9879\u76ee\u5206\u53c9\u3001\u70b9\u8d5e\u548c\u8d21\u732e\u8005\u663e\u8457\u589e\u52a0\u3002", "conclusion": "Hacker News\u662f\u63a8\u5e7f\u5f00\u6e90AI\u9879\u76ee\u7684\u6709\u6548\u5e73\u53f0\uff0c\u80fd\u63d0\u5347\u9879\u76ee\u53ef\u89c1\u6027\u548c\u793e\u533a\u53c2\u4e0e\u5ea6\u3002"}}
{"id": "2506.13038", "pdf": "https://arxiv.org/pdf/2506.13038", "abs": "https://arxiv.org/abs/2506.13038", "authors": ["Zijian Zhang", "Xuecheng Wu", "Danlei Huang", "Siyu Yan", "Chong Peng", "Xuezhi Cao"], "title": "HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Driven by the rapid progress in vision-language models (VLMs), the\nresponsible behavior of large-scale multimodal models has become a prominent\nresearch area, particularly focusing on hallucination detection and factuality\nchecking. In this paper, we present the solution for the two tracks of\nResponsible AI challenge. Inspirations from the general domain demonstrate that\na smaller distilled VLM can often outperform a larger VLM that is directly\ntuned on downstream tasks, while achieving higher efficiency. We thus jointly\ntackle two tasks from the perspective of knowledge distillation and propose a\nprogressive hybrid knowledge distillation framework termed HKD4VLM.\nSpecifically, the overall framework can be decomposed into Pyramid-like\nProgressive Online Distillation and Ternary-Coupled Refinement Distillation,\nhierarchically moving from coarse-grained knowledge alignment to fine-grained\nrefinement. Besides, we further introduce the mapping shift-enhanced inference\nand diverse augmentation strategies to enhance model performance and\nrobustness. Extensive experimental results demonstrate the effectiveness of our\nHKD4VLM. Ablation studies provide insights into the critical design choices\ndriving performance gains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHKD4VLM\u7684\u6e10\u8fdb\u5f0f\u6df7\u5408\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u68c0\u6d4b\u548c\u4e8b\u5b9e\u6027\u68c0\u67e5\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u84b8\u998f\u548c\u589e\u5f3a\u63a8\u7406\u7b56\u7565\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6a21\u578b\u7684\u8d1f\u8d23\u4efb\u884c\u4e3a\uff08\u5982\u5e7b\u89c9\u68c0\u6d4b\u548c\u4e8b\u5b9e\u6027\u68c0\u67e5\uff09\u6210\u4e3a\u7814\u7a76\u91cd\u70b9\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u63d0\u5347\u6a21\u578b\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51faHKD4VLM\u6846\u67b6\uff0c\u5305\u542b\u91d1\u5b57\u5854\u5f0f\u6e10\u8fdb\u5728\u7ebf\u84b8\u998f\u548c\u4e09\u91cd\u8026\u5408\u7cbe\u70bc\u84b8\u998f\uff0c\u4ece\u7c97\u5230\u7ec6\u5206\u5c42\u5bf9\u9f50\u77e5\u8bc6\uff0c\u5e76\u5f15\u5165\u6620\u5c04\u504f\u79fb\u589e\u5f3a\u63a8\u7406\u548c\u591a\u6837\u5316\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eHKD4VLM\u7684\u6709\u6548\u6027\uff0c\u6d88\u878d\u7814\u7a76\u63ed\u793a\u4e86\u5173\u952e\u8bbe\u8ba1\u5bf9\u6027\u80fd\u63d0\u5347\u7684\u8d21\u732e\u3002", "conclusion": "HKD4VLM\u901a\u8fc7\u5206\u5c42\u84b8\u998f\u548c\u589e\u5f3a\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8d1f\u8d23\u4efbAI\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2506.13348", "pdf": "https://arxiv.org/pdf/2506.13348", "abs": "https://arxiv.org/abs/2506.13348", "authors": ["Mae Younes", "Adnane Boukhayma"], "title": "TextureSplat: Per-Primitive Texture Mapping for Reflective Gaussian Splatting", "categories": ["cs.GR", "cs.CV"], "comment": "Code will be available at https://github.com/maeyounes/TextureSplat", "summary": "Gaussian Splatting have demonstrated remarkable novel view synthesis\nperformance at high rendering frame rates. Optimization-based inverse rendering\nwithin complex capture scenarios remains however a challenging problem. A\nparticular case is modelling complex surface light interactions for highly\nreflective scenes, which results in intricate high frequency specular radiance\ncomponents. We hypothesize that such challenging settings can benefit from\nincreased representation power. We hence propose a method that tackles this\nissue through a geometrically and physically grounded Gaussian Splatting borne\nradiance field, where normals and material properties are spatially variable in\nthe primitive's local space. Using per-primitive texture maps for this purpose,\nwe also propose to harness the GPU hardware to accelerate rendering at test\ntime via unified material texture atlas.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u9ad8\u65af\u6cfc\u6e85\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u51e0\u4f55\u548c\u7269\u7406\u57fa\u7840\u7684\u8f90\u5c04\u573a\uff0c\u89e3\u51b3\u9ad8\u53cd\u5c04\u573a\u666f\u4e2d\u590d\u6742\u5149\u7ebf\u4ea4\u4e92\u7684\u5efa\u6a21\u95ee\u9898\u3002", "motivation": "\u9ad8\u53cd\u5c04\u573a\u666f\u4e2d\u7684\u590d\u6742\u8868\u9762\u5149\u7ebf\u4ea4\u4e92\u662f\u9006\u6e32\u67d3\u4e2d\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u7684\u8868\u793a\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u5229\u7528\u5177\u6709\u7a7a\u95f4\u53ef\u53d8\u6cd5\u7ebf\u548c\u6750\u8d28\u5c5e\u6027\u7684\u9ad8\u65af\u6cfc\u6e85\u8f90\u5c04\u573a\uff0c\u5e76\u901a\u8fc7GPU\u786c\u4ef6\u52a0\u901f\u6e32\u67d3\uff0c\u4f7f\u7528\u7edf\u4e00\u7684\u6750\u8d28\u7eb9\u7406\u56fe\u96c6\u3002", "result": "\u89e3\u51b3\u4e86\u9ad8\u53cd\u5c04\u573a\u666f\u4e2d\u9ad8\u9891\u955c\u9762\u8f90\u5c04\u5206\u91cf\u7684\u5efa\u6a21\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u589e\u5f3a\u8868\u793a\u80fd\u529b\u548c\u4f18\u5316\u6e32\u67d3\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u9ad8\u53cd\u5c04\u573a\u666f\u7684\u590d\u6742\u5149\u7ebf\u4ea4\u4e92\u3002"}}
{"id": "2506.12265", "pdf": "https://arxiv.org/pdf/2506.12265", "abs": "https://arxiv.org/abs/2506.12265", "authors": ["Federico Giarr\u00e8", "Holger Karl"], "title": "Surfing the SWAVES: Lifecycle-aware Service Placement in MEC", "categories": ["cs.NI"], "comment": null, "summary": "In Multi-access Edge Computing (MEC) networks, users covered by a mobile\nnetwork can exploit edge clouds (ECs), computational resources located at the\nnetwork's edge, to execute virtual network functions (VNFs). ECs are\nparticularly useful when deploying VNFs with strict delay and availability\nrequirements. As users roam in the network and get handed over between cells,\ndeployed VNFs must follow users to retain the benefits of edge computing. Yet,\nhaving VNFs ready at the closest EC can be challenging: (i) ECs are not usually\npowerful enough to store and run any combination of VNFs simultaneously; (ii)\nif a VNF is not available at the needed EC, a series of time-consuming\noperations has to be performed before the VNF becomes operational. These\nlimitations can be addressed by proactively starting VNFs instances at (likely)\nfuture locations, balancing better latency properties against higher resource\nusage. Such proactive deployment does need forecasting of user movements, but\nthese will be imperfect, creating yet another tradeoff. We present our approach\nto this service provisioning problem, SWAVES. When compared on the ratio of\nusers' unsuccessful packets, SWAVES improves such metric by orders of magnitude\nwith respect to other proposed heuristic.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSWAVES\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u7f51\u7edc\u4e2d\u4f18\u5316\u865a\u62df\u7f51\u7edc\u529f\u80fd\uff08VNFs\uff09\u7684\u4e3b\u52a8\u90e8\u7f72\uff0c\u4ee5\u5e94\u5bf9\u7528\u6237\u79fb\u52a8\u6027\u5e26\u6765\u7684\u6311\u6218\u3002\u76f8\u6bd4\u5176\u4ed6\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0cSWAVES\u663e\u8457\u964d\u4f4e\u4e86\u7528\u6237\u6570\u636e\u5305\u5931\u8d25\u7387\u3002", "motivation": "\u5728MEC\u7f51\u7edc\u4e2d\uff0c\u7528\u6237\u79fb\u52a8\u6027\u5bfc\u81f4VNFs\u9700\u8981\u9891\u7e41\u8fc1\u79fb\u4ee5\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u53ef\u7528\u6027\u9700\u6c42\u3002\u4f46\u7531\u4e8e\u8fb9\u7f18\u4e91\uff08ECs\uff09\u8d44\u6e90\u6709\u9650\u4e14VNFs\u90e8\u7f72\u8017\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86SWAVES\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u79fb\u52a8\u6027\u5e76\u4e3b\u52a8\u5728\u53ef\u80fd\u7684\u4f4d\u7f6e\u63d0\u524d\u90e8\u7f72VNFs\u5b9e\u4f8b\uff0c\u4ee5\u5e73\u8861\u5ef6\u8fdf\u548c\u8d44\u6e90\u4f7f\u7528\u3002", "result": "\u76f8\u6bd4\u5176\u4ed6\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0cSWAVES\u5c06\u7528\u6237\u6570\u636e\u5305\u5931\u8d25\u7387\u964d\u4f4e\u4e86\u6570\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "SWAVES\u901a\u8fc7\u4e3b\u52a8\u90e8\u7f72\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86MEC\u7f51\u7edc\u4e2dVNFs\u7684\u670d\u52a1\u8d28\u91cf\uff0c\u4e3a\u5e94\u5bf9\u7528\u6237\u79fb\u52a8\u6027\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12356", "pdf": "https://arxiv.org/pdf/2506.12356", "abs": "https://arxiv.org/abs/2506.12356", "authors": ["Nima Hadidi", "Jason Chan", "Ebrahim Feghhi", "Jonathan Kao"], "title": "SplashNet: Split-and-Share Encoders for Accurate and Efficient Typing with Surface Electromyography", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Surface electromyography (sEMG) at the wrists could enable natural,\nkeyboard-free text entry, yet the state-of-the-art emg2qwerty baseline still\nmisrecognizes $51.8\\%$ of characters in the zero-shot setting on unseen users\nand $7.0\\%$ after user-specific fine-tuning. We trace many of these errors to\nmismatched cross-user signal statistics, fragile reliance on high-order feature\ndependencies, and the absence of architectural inductive biases aligned with\nthe bilateral nature of typing. To address these issues, we introduce three\nsimple modifications: (i) Rolling Time Normalization, which adaptively aligns\ninput distributions across users; (ii) Aggressive Channel Masking, which\nencourages reliance on low-order feature combinations more likely to generalize\nacross users; and (iii) a Split-and-Share encoder that processes each hand\nindependently with weight-shared streams to reflect the bilateral symmetry of\nthe neuromuscular system. Combined with a five-fold reduction in spectral\nresolution ($33\\!\\rightarrow\\!6$ frequency bands), these components yield a\ncompact Split-and-Share model, SplashNet-mini, which uses only $\\tfrac14$ the\nparameters and $0.6\\times$ the FLOPs of the baseline while reducing\ncharacter-error rate (CER) to $36.4\\%$ zero-shot and $5.9\\%$ after fine-tuning.\nAn upscaled variant, SplashNet ($\\tfrac12$ the parameters, $1.15\\times$ the\nFLOPs of the baseline), further lowers error to $35.7\\%$ and $5.5\\%$,\nrepresenting relative improvements of $31\\%$ and $21\\%$ in the zero-shot and\nfine-tuned settings, respectively. SplashNet therefore establishes a new state\nof the art without requiring additional data.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u6539\u8fdbsEMG\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff0c\u63d0\u51faSplashNet\u548cSplashNet-mini\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b57\u7b26\u9519\u8bef\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u624b\u8155\u8868\u9762\u808c\u7535\u4fe1\u53f7\uff08sEMG\uff09\u7684\u6587\u672c\u8f93\u5165\u7cfb\u7edf\u5728\u8de8\u7528\u6237\u6216\u672a\u7ecf\u5fae\u8c03\u65f6\u9519\u8bef\u7387\u8f83\u9ad8\uff0c\u9700\u8981\u6539\u8fdb\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u548c\u6a21\u578b\u67b6\u6784\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u6539\u8fdb\u63aa\u65bd\uff1a\u6eda\u52a8\u65f6\u95f4\u5f52\u4e00\u5316\u3001\u6fc0\u8fdb\u901a\u9053\u63a9\u7801\u548c\u5206\u800c\u5171\u4eab\u7f16\u7801\u5668\uff0c\u5e76\u7ed3\u5408\u964d\u4f4e\u9891\u8c31\u5206\u8fa8\u7387\uff0c\u8bbe\u8ba1\u4e86\u7d27\u51d1\u7684Split-and-Share\u6a21\u578b\u3002", "result": "SplashNet-mini\u548cSplashNet\u6a21\u578b\u5206\u522b\u5c06\u96f6\u6837\u672c\u548c\u5fae\u8c03\u540e\u7684\u5b57\u7b26\u9519\u8bef\u7387\u964d\u4f4e\u81f336.4%/5.9%\u548c35.7%/5.5%\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u4e9b\u6539\u8fdb\uff0cSplashNet\u5728\u4e0d\u589e\u52a0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u65b0\u7684\u6027\u80fd\u6807\u6746\u3002"}}
{"id": "2506.12990", "pdf": "https://arxiv.org/pdf/2506.12990", "abs": "https://arxiv.org/abs/2506.12990", "authors": ["Sreeram Marimuthu", "Nina Klimenkova", "Roee Shraga"], "title": "Humans, Machine Learning, and Language Models in Union: A Cognitive Study on Table Unionability", "categories": ["cs.DB", "cs.LG"], "comment": "6 Pages, 4 figures, ACM SIGMOD HILDA '25 (Status-Accepted)", "summary": "Data discovery and table unionability in particular became key tasks in\nmodern Data Science. However, the human perspective for these tasks is still\nunder-explored. Thus, this research investigates the human behavior in\ndetermining table unionability within data discovery. We have designed an\nexperimental survey and conducted a comprehensive analysis, in which we assess\nhuman decision-making for table unionability. We use the observations from the\nanalysis to develop a machine learning framework to boost the (raw) performance\nof humans. Furthermore, we perform a preliminary study on how LLM performance\nis compared to humans indicating that it is typically better to consider a\ncombination of both. We believe that this work lays the foundations for\ndeveloping future Human-in-the-Loop systems for efficient data discovery.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4eba\u7c7b\u5728\u6570\u636e\u53d1\u73b0\u4e2d\u51b3\u5b9a\u8868\u53ef\u8054\u5408\u6027\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8c03\u67e5\u548c\u673a\u5668\u5b66\u4e60\u6846\u67b6\u63d0\u5347\u4eba\u7c7b\u51b3\u7b56\u6027\u80fd\uff0c\u5e76\u521d\u6b65\u6bd4\u8f83\u4e86LLM\u4e0e\u4eba\u7c7b\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u4eba\u673a\u534f\u540c\u6570\u636e\u53d1\u73b0\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u79d1\u5b66\u4e2d\uff0c\u8868\u53ef\u8054\u5408\u6027\u662f\u5173\u952e\u4efb\u52a1\uff0c\u4f46\u4eba\u7c7b\u89c6\u89d2\u7684\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u5b9e\u9a8c\u8c03\u67e5\u8bc4\u4f30\u4eba\u7c7b\u51b3\u7b56\u884c\u4e3a\uff0c\u5e76\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u6846\u67b6\u63d0\u5347\u6027\u80fd\uff0c\u521d\u6b65\u6bd4\u8f83LLM\u4e0e\u4eba\u7c7b\u8868\u73b0\u3002", "result": "\u4eba\u7c7b\u51b3\u7b56\u6027\u80fd\u53ef\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u63d0\u5347\uff0cLLM\u8868\u73b0\u4f18\u4e8e\u4eba\u7c7b\uff0c\u4f46\u7ed3\u5408\u4e24\u8005\u66f4\u4f73\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u4eba\u673a\u534f\u540c\u6570\u636e\u53d1\u73b0\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.12962", "pdf": "https://arxiv.org/pdf/2506.12962", "abs": "https://arxiv.org/abs/2506.12962", "authors": ["Dewan Saiham", "Di Wu", "Sazadur Rahman"], "title": "Leveraging Photonic Interconnects for Scalable and Efficient Fully Homomorphic Encryption", "categories": ["cs.ET"], "comment": null, "summary": "Fully Homomorphic Encryption (FHE) facilitates secure computations on\nencrypted data but imposes significant demands on memory bandwidth and\ncomputational power. While current FHE accelerators focus on optimizing\ncomputation, they often face bandwidth limitations that result in performance\nbottlenecks, particularly in memory-intensive operations. This paper presents\nOptoLink, a scalable photonic interconnect architecture designed to address\nthese bandwidth and latency challenges in FHE systems. OptoLink achieves a\nthroughput of 1.6 TB/s with 128 channels, providing 300 times the bandwidth of\nconventional electrical interconnects. The proposed architecture improves data\nthroughput, scalability, and reduces latency, making it an effective solution\nfor meeting the high memory and data transfer requirements of modern FHE\naccelerators.", "AI": {"tldr": "OptoLink\u662f\u4e00\u79cd\u5149\u5b50\u4e92\u8054\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86FHE\u7cfb\u7edf\u7684\u5e26\u5bbd\u548c\u6027\u80fd\u3002", "motivation": "\u5f53\u524dFHE\u52a0\u901f\u5668\u56e0\u5e26\u5bbd\u9650\u5236\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\uff0c\u5c24\u5176\u662f\u5185\u5b58\u5bc6\u96c6\u578b\u64cd\u4f5c\u3002", "method": "\u63d0\u51faOptoLink\uff0c\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5149\u5b50\u4e92\u8054\u67b6\u6784\uff0c\u652f\u6301128\u901a\u9053\u548c1.6 TB/s\u541e\u5410\u91cf\u3002", "result": "OptoLink\u7684\u5e26\u5bbd\u662f\u4f20\u7edf\u7535\u4e92\u8054\u7684300\u500d\uff0c\u964d\u4f4e\u4e86\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u4e86\u6570\u636e\u541e\u5410\u91cf\u3002", "conclusion": "OptoLink\u662f\u89e3\u51b3FHE\u52a0\u901f\u5668\u9ad8\u5185\u5b58\u548c\u6570\u636e\u4f20\u8f93\u9700\u6c42\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2506.12971", "pdf": "https://arxiv.org/pdf/2506.12971", "abs": "https://arxiv.org/abs/2506.12971", "authors": ["Vasileios Leon", "Elissaios Alexios Papatheofanous", "George Lentaris", "Charalampos Bezaitis", "Nikolaos Mastorakis", "Georgios Bampilis", "Dionysios Reisis", "Dimitrios Soudris"], "title": "Combining Fault Tolerance Techniques and COTS SoC Accelerators for Payload Processing in Space", "categories": ["cs.AR"], "comment": "Presented at the 30th IFIP/IEEE VLSI-SoC Conference", "summary": "The ever-increasing demand for computational power and I/O throughput in\nspace applications is transforming the landscape of on-board computing. A\nvariety of Commercial-Off-The-Shelf (COTS) accelerators emerges as an\nattractive solution for payload processing to outperform the traditional\nradiation-hardened devices. Towards increasing the reliability of such COTS\naccelerators, the current paper explores and evaluates fault-tolerance\ntechniques for the Zynq FPGA and the Myriad VPU, which are two device families\nbeing integrated in industrial space avionics architectures/boards, such as\nUbotica's CogniSat, Xiphos' Q7S, and Cobham Gaisler's GR-VPX-XCKU060. On the\nFPGA side, we combine techniques such as memory scrubbing, partial\nreconfiguration, triple modular redundancy, and watchdogs. On the VPU side, we\ndetect and correct errors in the instruction and data memories, as well as we\napply redundancy at processor level (SHAVE cores). When considering FPGA with\nVPU co-processing, we also develop a fault-tolerant interface between the two\ndevices based on the CIF/LCD protocols and our custom CRC error-detecting code.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u592a\u7a7a\u5e94\u7528\u4e2d\u4e3aZynq FPGA\u548cMyriad VPU\u8fd9\u4e24\u79cd\u5546\u7528\u73b0\u6210\u52a0\u901f\u5668\u8bbe\u8ba1\u5bb9\u9519\u6280\u672f\uff0c\u4ee5\u63d0\u9ad8\u5176\u53ef\u9760\u6027\u3002", "motivation": "\u968f\u7740\u592a\u7a7a\u5e94\u7528\u5bf9\u8ba1\u7b97\u80fd\u529b\u548cI/O\u541e\u5410\u91cf\u9700\u6c42\u7684\u589e\u52a0\uff0c\u5546\u7528\u73b0\u6210\u52a0\u901f\u5668\u56e0\u5176\u6027\u80fd\u4f18\u52bf\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u9700\u63d0\u9ad8\u5176\u53ef\u9760\u6027\u3002", "method": "\u9488\u5bf9FPGA\u91c7\u7528\u5185\u5b58\u6e05\u7406\u3001\u90e8\u5206\u91cd\u65b0\u914d\u7f6e\u3001\u4e09\u6a21\u5197\u4f59\u548c\u770b\u95e8\u72d7\u7b49\u6280\u672f\uff1b\u5bf9VPU\u5219\u68c0\u6d4b\u5e76\u7ea0\u6b63\u6307\u4ee4\u548c\u6570\u636e\u5185\u5b58\u9519\u8bef\uff0c\u5e76\u5728\u5904\u7406\u5668\u5c42\u9762\u5e94\u7528\u5197\u4f59\u3002", "result": "\u5f00\u53d1\u4e86FPGA\u4e0eVPU\u534f\u540c\u5904\u7406\u7684\u5bb9\u9519\u63a5\u53e3\uff0c\u7ed3\u5408CIF/LCD\u534f\u8bae\u548c\u81ea\u5b9a\u4e49CRC\u9519\u8bef\u68c0\u6d4b\u7801\u3002", "conclusion": "\u63d0\u51fa\u7684\u5bb9\u9519\u6280\u672f\u80fd\u591f\u6709\u6548\u63d0\u5347\u5546\u7528\u73b0\u6210\u52a0\u901f\u5668\u5728\u592a\u7a7a\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.12425", "pdf": "https://arxiv.org/pdf/2506.12425", "abs": "https://arxiv.org/abs/2506.12425", "authors": ["Pranjal Naman", "Yogesh Simmhan"], "title": "Optimizing Federated Learning using Remote Embeddings for Graph Neural Networks", "categories": ["cs.DC", "cs.LG"], "comment": "Preprint of paper in the proceedings of the 30th International\n  European Conference on Parallel and Distributed Computing (Euro-Par)", "summary": "Graph Neural Networks (GNNs) have experienced rapid advancements in recent\nyears due to their ability to learn meaningful representations from graph data\nstructures. Federated Learning (FL) has emerged as a viable machine learning\napproach for training a shared model on decentralized data, addressing privacy\nconcerns while leveraging parallelism. Existing methods that address the unique\nrequirements of federated GNN training using remote embeddings to enhance\nconvergence accuracy are limited by their diminished performance due to large\ncommunication costs with a shared embedding server. In this paper, we present\nOpES, an optimized federated GNN training framework that uses remote\nneighbourhood pruning, and overlaps pushing of embeddings to the server with\nlocal training to reduce the network costs and training time. The modest drop\nin per-round accuracy due to pre-emptive push of embeddings is out-stripped by\nthe reduction in per-round training time for large and dense graphs like Reddit\nand Products, converging up to $\\approx2\\times$ faster than the\nstate-of-the-art technique using an embedding server and giving up to $20\\%$\nbetter accuracy than vanilla federated GNN learning.", "AI": {"tldr": "OpES\u662f\u4e00\u79cd\u4f18\u5316\u7684\u8054\u90a6GNN\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u8fdc\u7a0b\u90bb\u5c45\u526a\u679d\u548c\u91cd\u53e0\u63a8\u9001\u5d4c\u5165\u4e0e\u672c\u5730\u8bad\u7ec3\uff0c\u964d\u4f4e\u4e86\u7f51\u7edc\u5f00\u9500\u548c\u8bad\u7ec3\u65f6\u95f4\uff0c\u5728\u5927\u578b\u5bc6\u96c6\u56fe\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8054\u90a6GNN\u8bad\u7ec3\u65b9\u6cd5\u56e0\u9ad8\u901a\u4fe1\u6210\u672c\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u8fdc\u7a0b\u90bb\u5c45\u526a\u679d\u6280\u672f\uff0c\u5e76\u91cd\u53e0\u63a8\u9001\u5d4c\u5165\u4e0e\u672c\u5730\u8bad\u7ec3\uff0c\u4ee5\u51cf\u5c11\u7f51\u7edc\u5f00\u9500\u548c\u8bad\u7ec3\u65f6\u95f4\u3002", "result": "\u5728Reddit\u548cProducts\u7b49\u5927\u578b\u5bc6\u96c6\u56fe\u4e0a\uff0cOpES\u6bd4\u73b0\u6709\u6280\u672f\u5feb\u7ea62\u500d\uff0c\u51c6\u786e\u6027\u63d0\u534720%\u3002", "conclusion": "OpES\u5728\u63d0\u5347\u8054\u90a6GNN\u8bad\u7ec3\u6548\u7387\u548c\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5927\u578b\u5bc6\u96c6\u56fe\u3002"}}
{"id": "2506.12669", "pdf": "https://arxiv.org/pdf/2506.12669", "abs": "https://arxiv.org/abs/2506.12669", "authors": ["Anrafel Fernandes Pereira", "Marcos Kalinowski", "Maria Teresa Baldassarre", "J\u00fcrgen B\u00f6rstler", "Nauman bin Ali", "Daniel Mendez"], "title": "Towards Lean Research Inception: Assessing Practical Relevance of Formulated Research Problems", "categories": ["cs.SE"], "comment": "Accepted for publication at EASE 2025", "summary": "[Context] The lack of practical relevance in many Software Engineering (SE)\nresearch contributions is often rooted in oversimplified views of industrial\npractice, weak industry connections, and poorly defined research problems.\nClear criteria for evaluating SE research problems can help align their value,\nfeasibility, and applicability with industrial needs. [Goal] In this paper, we\nintroduce the Lean Research Inception (LRI) framework, designed to support the\nformulation and assessment of practically relevant research problems in SE. We\ndescribe its initial evaluation strategy conducted in a workshop with a network\nof SE researchers experienced in industry-academia collaboration and report the\nevaluation of its three assessment criteria (valuable, feasible, and\napplicable) regarding their importance in assessing practical relevance.\n[Method] We applied LRI retroactively to a published research paper, engaging\nworkshop participants in discussing and assessing the research problem by\napplying the proposed criteria using a semantic differential scale.\nParticipants provided feedback on the criteria's importance and completeness,\ndrawn from their own experiences in industry-academia collaboration. [Results]\nThe findings reveal an overall agreement on the importance of the three\ncriteria - valuable (83.3%), feasible (76.2%), and applicable (73.8%) - for\naligning research problems with industrial needs. Qualitative feedback\nsuggested adjustments in terminology with a clearer distinction between\nfeasible and applicable, and refinements for valuable by more clearly\nconsidering business value, ROI, and originality. [Conclusion] While LRI\nconstitutes ongoing research and requires further evaluation, our results\nstrengthen our confidence that the three criteria applied using the semantic\ndifferential scale can already help the community assess the practical\nrelevance of SE research problems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLean Research Inception (LRI)\u6846\u67b6\uff0c\u65e8\u5728\u8bc4\u4f30\u8f6f\u4ef6\u5de5\u7a0b(SE)\u7814\u7a76\u7684\u5b9e\u7528\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7814\u8ba8\u4f1a\u9a8c\u8bc1\u5176\u4e09\u4e2a\u8bc4\u4f30\u6807\u51c6\uff08\u6709\u4ef7\u503c\u3001\u53ef\u884c\u3001\u9002\u7528\uff09\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8bb8\u591aSE\u7814\u7a76\u7f3a\u4e4f\u5b9e\u9645\u76f8\u5173\u6027\uff0c\u539f\u56e0\u662f\u5de5\u4e1a\u5b9e\u8df5\u7684\u7b80\u5316\u89c6\u89d2\u3001\u4ea7\u5b66\u7814\u8054\u7cfb\u8584\u5f31\u53ca\u7814\u7a76\u95ee\u9898\u5b9a\u4e49\u4e0d\u6e05\u3002LRI\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7814\u8ba8\u4f1a\u5e94\u7528LRI\u6846\u67b6\uff0c\u53c2\u4e0e\u8005\u4f7f\u7528\u8bed\u4e49\u5dee\u5f02\u91cf\u8868\u8bc4\u4f30\u7814\u7a76\u95ee\u9898\uff0c\u53cd\u9988\u6807\u51c6\u7684\u5b8c\u6574\u6027\u548c\u91cd\u8981\u6027\u3002", "result": "\u53c2\u4e0e\u8005\u4e00\u81f4\u8ba4\u4e3a\u4e09\u4e2a\u6807\u51c6\u5bf9\u5de5\u4e1a\u9700\u6c42\u81f3\u5173\u91cd\u8981\uff08\u6709\u4ef7\u503c83.3%\uff0c\u53ef\u884c76.2%\uff0c\u9002\u752873.8%\uff09\uff0c\u5e76\u5efa\u8bae\u672f\u8bed\u8c03\u6574\u3002", "conclusion": "LRI\u6846\u67b6\u4ecd\u9700\u8fdb\u4e00\u6b65\u8bc4\u4f30\uff0c\u4f46\u5f53\u524d\u7ed3\u679c\u8bc1\u660e\u5176\u80fd\u6709\u6548\u5e2e\u52a9\u793e\u533a\u8bc4\u4f30SE\u7814\u7a76\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.13756", "pdf": "https://arxiv.org/pdf/2506.13756", "abs": "https://arxiv.org/abs/2506.13756", "authors": ["Jingwei Ma", "Vivek Jayaram", "Brian Curless", "Ira Kemelmacher-Shlizerman", "Steven M. Seitz"], "title": "UltraZoom: Generating Gigapixel Images from Regular Photos", "categories": ["cs.GR", "cs.CV"], "comment": "Project page: https://ultra-zoom.github.io/", "summary": "We present UltraZoom, a system for generating gigapixel-resolution images of\nobjects from casually captured inputs, such as handheld phone photos. Given a\nfull-shot image (global, low-detail) and one or more close-ups (local,\nhigh-detail), UltraZoom upscales the full image to match the fine detail and\nscale of the close-up examples. To achieve this, we construct a per-instance\npaired dataset from the close-ups and adapt a pretrained generative model to\nlearn object-specific low-to-high resolution mappings. At inference, we apply\nthe model in a sliding window fashion over the full image. Constructing these\npairs is non-trivial: it requires registering the close-ups within the full\nimage for scale estimation and degradation alignment. We introduce a simple,\nrobust method for getting registration on arbitrary materials in casual,\nin-the-wild captures. Together, these components form a system that enables\nseamless pan and zoom across the entire object, producing consistent,\nphotorealistic gigapixel imagery from minimal input.", "AI": {"tldr": "UltraZoom\u662f\u4e00\u4e2a\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ece\u624b\u6301\u8bbe\u5907\u62cd\u6444\u7684\u7167\u7247\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u7684\u5bf9\u8c61\u56fe\u50cf\uff0c\u5229\u7528\u5168\u5c40\u548c\u5c40\u90e8\u56fe\u50cf\u914d\u5bf9\u6570\u636e\u8bad\u7ec3\u6a21\u578b\uff0c\u5b9e\u73b0\u65e0\u7f1d\u7f29\u653e\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u4ece\u968f\u610f\u62cd\u6444\u7684\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u3001\u4e00\u81f4\u6027\u7684\u5343\u5146\u50cf\u7d20\u56fe\u50cf\u7684\u6311\u6218\u3002", "method": "\u6784\u5efa\u6bcf\u5b9e\u4f8b\u914d\u5bf9\u6570\u636e\u96c6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u5b66\u4e60\u5bf9\u8c61\u7279\u5b9a\u7684\u4f4e\u5230\u9ad8\u5206\u8fa8\u7387\u6620\u5c04\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u6ed1\u52a8\u7a97\u53e3\u5e94\u7528\u6a21\u578b\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u4e00\u81f4\u4e14\u903c\u771f\u7684\u5343\u5146\u50cf\u7d20\u56fe\u50cf\uff0c\u5b9e\u73b0\u65e0\u7f1d\u7684\u5e73\u79fb\u548c\u7f29\u653e\u529f\u80fd\u3002", "conclusion": "UltraZoom\u901a\u8fc7\u521b\u65b0\u7684\u914d\u5bf9\u6570\u636e\u96c6\u6784\u5efa\u548c\u6a21\u578b\u9002\u5e94\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u7684\u751f\u6210\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2506.12357", "pdf": "https://arxiv.org/pdf/2506.12357", "abs": "https://arxiv.org/abs/2506.12357", "authors": ["Sharifa Sultana", "Hafsah Mahzabin Chowdhury", "Zinnat Sultana", "Nervo Verdezoto"], "title": "`Socheton': A Culturally Appropriate AI Tool to Support Reproductive Well-being", "categories": ["cs.HC"], "comment": null, "summary": "Reproductive well-being education in the Global South is often challenged as\nmany communities perceive many of its contents as misinformation,\nmisconceptions, and language-inappropriate. Our ten-month-long ethnographic\nstudy (n=41) investigated the impact of sociocultural landscape, cultural\nbeliefs, and healthcare infrastructure on Bangladeshi people's access to\nquality reproductive healthcare and set four design goals: combating\nmisinformation, including culturally appropriate language, professionals'\naccountable moderation, and promoting users' democratic participation. Building\non the model of `\\textit{Distributive Justice,}' we designed and evaluated\n\\textit{`Socheton,'} a culturally appropriate AI-mediated tool for reproductive\nwell-being that includes healthcare professionals, AI-language teachers, and\ncommunity members to moderate and run the activity-based platform. Our user\nstudy (n=28) revealed that only combating misinformation and language\ninappropriateness may still leave the community with a conservative mob culture\nand patronize reproductive care-seeking. This guides well-being HCI design\ntoward being culturally appropriate in the context of reproductive justice with\nsensitive marginalized communities.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5168\u7403\u5357\u65b9\u5730\u533a\u751f\u6b96\u5065\u5eb7\u6559\u80b2\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u7b26\u5408\u6587\u5316\u7684AI\u5de5\u5177\"Socheton\"\u6765\u6539\u5584\u751f\u6b96\u5065\u5eb7\u670d\u52a1\u8bbf\u95ee\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4ec5\u89e3\u51b3\u9519\u8bef\u4fe1\u606f\u548c\u8bed\u8a00\u95ee\u9898\u4e0d\u8db3\u4ee5\u6539\u53d8\u4fdd\u5b88\u6587\u5316\u5bf9\u751f\u6b96\u5065\u5eb7\u7684\u504f\u89c1\u3002", "motivation": "\u5168\u7403\u5357\u65b9\u5730\u533a\u7684\u751f\u6b96\u5065\u5eb7\u6559\u80b2\u5e38\u56e0\u6587\u5316\u4fe1\u4ef0\u548c\u8bed\u8a00\u95ee\u9898\u88ab\u89c6\u4e3a\u9519\u8bef\u4fe1\u606f\uff0c\u5bfc\u81f4\u670d\u52a1\u8d28\u91cf\u4f4e\u4e0b\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u6587\u5316\u654f\u611f\u6027\u548c\u6280\u672f\u624b\u6bb5\uff0c\u63d0\u5347\u751f\u6b96\u5065\u5eb7\u670d\u52a1\u7684\u53ef\u53ca\u6027\u548c\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u5341\u4e2a\u6708\u7684\u6c11\u65cf\u5fd7\u7814\u7a76\uff0c\u7ed3\u5408\"\u5206\u914d\u6b63\u4e49\"\u7406\u8bba\uff0c\u8bbe\u8ba1\u4e86AI\u5de5\u5177\"Socheton\"\uff0c\u5e76\u8fdb\u884c\u4e86\u7528\u6237\u7814\u7a76\uff08n=28\uff09\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4ec5\u7ea0\u6b63\u9519\u8bef\u4fe1\u606f\u548c\u4f7f\u7528\u9002\u5f53\u8bed\u8a00\u65e0\u6cd5\u5b8c\u5168\u6539\u53d8\u793e\u533a\u7684\u4fdd\u5b88\u6587\u5316\uff0c\u4ecd\u53ef\u80fd\u963b\u788d\u751f\u6b96\u5065\u5eb7\u670d\u52a1\u7684\u5bfb\u6c42\u884c\u4e3a\u3002", "conclusion": "\u751f\u6b96\u5065\u5eb7\u8bbe\u8ba1\u9700\u5728\u6587\u5316\u654f\u611f\u6027\u548c\u516c\u6b63\u6027\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u8003\u8651\u8fb9\u7f18\u5316\u793e\u533a\u7684\u7279\u6b8a\u9700\u6c42\uff0c\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u751f\u6b96\u6b63\u4e49\u3002"}}
{"id": "2506.13144", "pdf": "https://arxiv.org/pdf/2506.13144", "abs": "https://arxiv.org/abs/2506.13144", "authors": ["Xiaoyao Zhong", "Jiabao Jin", "Peng Cheng", "Mingyu Yang", "Lei Chen", "Haoyang Li", "Zhitao Shen", "Xuemin Lin", "Heng Tao Shen", "Jingkuan Song"], "title": "EnhanceGraph: A Continuously Enhanced Graph-based Index for High-dimensional Approximate Nearest Neighbor Search", "categories": ["cs.DB"], "comment": null, "summary": "Recently, Approximate Nearest Neighbor Search in high-dimensional vector\nspaces has garnered considerable attention due to the rapid advancement of deep\nlearning techniques. We observed that a substantial amount of search and\nconstruction logs are generated throughout the lifespan of a graph-based index.\nHowever, these two types of valuable logs are not fully exploited due to the\nstatic nature of existing indexes. We present the EnhanceGraph framework, which\nintegrates two types of logs into a novel structure called a conjugate graph.\nThe conjugate graph is then used to improve search quality. Through theoretical\nanalyses and observations of the limitations of graph-based indexes, we propose\nseveral optimization methods. For the search logs, the conjugate graph stores\nthe edges from local optima to global optima to enhance routing to the nearest\nneighbor. For the construction logs, the conjugate graph stores the pruned\nedges from the proximity graph to enhance retrieving of k nearest neighbors.\nOur experimental results on several public and real-world industrial datasets\nshow that EnhanceGraph significantly improves search accuracy with the greatest\nimprovement on recall from 41.74% to 93.42%, but does not sacrifices search\nefficiency. In addition, our EnhanceGraph algorithm has been integrated into\nAnt Group's open-source vector library, VSAG.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86EnhanceGraph\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u641c\u7d22\u548c\u6784\u5efa\u65e5\u5fd7\uff08\u79f0\u4e3a\u5171\u8f6d\u56fe\uff09\u6765\u6539\u8fdb\u9ad8\u7ef4\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u8d28\u91cf\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u641c\u7d22\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u56fe\u7d22\u5f15\u7684\u9759\u6001\u6027\u8d28\u5bfc\u81f4\u641c\u7d22\u548c\u6784\u5efa\u65e5\u5fd7\u672a\u80fd\u5145\u5206\u5229\u7528\uff0c\u56e0\u6b64\u5e0c\u671b\u901a\u8fc7\u52a8\u6001\u6574\u5408\u8fd9\u4e9b\u65e5\u5fd7\u63d0\u5347\u641c\u7d22\u6027\u80fd\u3002", "method": "\u63d0\u51faEnhanceGraph\u6846\u67b6\uff0c\u6784\u5efa\u5171\u8f6d\u56fe\u6765\u5b58\u50a8\u641c\u7d22\u65e5\u5fd7\uff08\u5c40\u90e8\u6700\u4f18\u5230\u5168\u5c40\u6700\u4f18\u7684\u8fb9\uff09\u548c\u6784\u5efa\u65e5\u5fd7\uff08\u526a\u679d\u540e\u7684\u8fd1\u90bb\u56fe\u8fb9\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cEnhanceGraph\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u51c6\u786e\u7387\uff08\u53ec\u56de\u7387\u4ece41.74%\u63d0\u5347\u81f393.42%\uff09\uff0c\u4e14\u672a\u727a\u7272\u6548\u7387\u3002", "conclusion": "EnhanceGraph\u5728\u63d0\u5347\u641c\u7d22\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5df2\u88ab\u96c6\u6210\u5230\u5f00\u6e90\u5411\u91cf\u5e93VSAG\u4e2d\u3002"}}
{"id": "2506.13744", "pdf": "https://arxiv.org/pdf/2506.13744", "abs": "https://arxiv.org/abs/2506.13744", "authors": ["Spiros Gkousis", "Evina Katsou"], "title": "lcpy: an open-source python package for parametric and dynamic Life Cycle Assessment and Life Cycle Costing", "categories": ["cs.ET"], "comment": "Associated repository at https://github.com/spirdgk/lcpy and\n  https://doi.org/10.5281/zenodo.15675940", "summary": "This article describes lcpy, an open-source python package that allows for\nadvanced parametric Life Cycle Assessment (LCA) and Life Cycle Costing (LCC)\nanalysis. The package is designed to allow the user to model a process with a\nflexible, modular design based on dictionaries and lists. The modeling can\nconsider in-time variations, uncertainty, and allows for dynamic analysis,\nuncertainty assessment, as well as conventional static LCA and LCC. The package\nis compatible with optimization and uncertainty analysis libraries as well as\npython packages for prospective LCA. Its goal is to allow for easy\nimplementation of dynamic LCA and LCC and for simple integration with tools for\nuncertainty assessment and optimization towards a more widened implementation\nof advanced enviro-economic analysis. The open-source code can be found at\nhttps://github.com/spirdgk/lcpy.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3alcpy\u7684Python\u5f00\u6e90\u5305\uff0c\u7528\u4e8e\u9ad8\u7ea7\u53c2\u6570\u5316\u751f\u547d\u5468\u671f\u8bc4\u4f30\uff08LCA\uff09\u548c\u751f\u547d\u5468\u671f\u6210\u672c\uff08LCC\uff09\u5206\u6790\u3002", "motivation": "\u65e8\u5728\u7b80\u5316\u52a8\u6001LCA\u548cLCC\u7684\u5b9e\u73b0\uff0c\u5e76\u4fbf\u4e8e\u4e0e\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u548c\u4f18\u5316\u5de5\u5177\u96c6\u6210\u3002", "method": "\u57fa\u4e8e\u5b57\u5178\u548c\u5217\u8868\u7684\u7075\u6d3b\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u652f\u6301\u65f6\u95f4\u53d8\u5316\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u52a8\u6001\u5206\u6790\u3002", "result": "\u5b9e\u73b0\u4e86\u52a8\u6001LCA\u548cLCC\u5206\u6790\uff0c\u517c\u5bb9\u4f18\u5316\u548c\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u5e93\u3002", "conclusion": "lcpy\u4e3a\u9ad8\u7ea7\u73af\u5883\u7ecf\u6d4e\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u5b9e\u65bd\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.13151", "pdf": "https://arxiv.org/pdf/2506.13151", "abs": "https://arxiv.org/abs/2506.13151", "authors": ["Songqi Wang", "Yue Zhang", "Jia Chen", "Xinyuan Zhang", "Yi Li", "Ning Lin", "Yangu He", "Jichang Yang", "Yingjie Yu", "Yi Li", "Zhongrui Wang", "Xiaojuan Qi", "Han Wang"], "title": "Reconfigurable Digital RRAM Logic Enables In-Situ Pruning and Learning for Edge AI", "categories": ["cs.AR"], "comment": null, "summary": "The human brain simultaneously optimizes synaptic weights and topology by\ngrowing, pruning, and strengthening synapses while performing all computation\nentirely in memory. In contrast, modern artificial-intelligence systems\nseparate weight optimization from topology optimization and depend on\nenergy-intensive von Neumann architectures. Here, we present a\nsoftware-hardware co-design that bridges this gap. On the algorithmic side, we\nintroduce a real-time dynamic weight-pruning strategy that monitors weight\nsimilarity during training and removes redundancies on the fly, reducing\noperations by 26.80% on MNIST and 59.94% on ModelNet10 without sacrificing\naccuracy (91.44% and 77.75%, respectively). On the hardware side, we fabricate\na reconfigurable, fully digital compute-in-memory (CIM) chip based on 180 nm\none-transistor-one-resistor (1T1R) RRAM arrays. Each array embeds flexible\nBoolean logic (NAND, AND, XOR, OR), enabling both convolution and similarity\nevaluation inside memory and eliminating all ADC/DAC overhead. The digital\ndesign achieves zero bit-error, reduces silicon area by 72.30% and overall\nenergy by 57.26% compared to analogue RRAM CIM, and lowers energy by 75.61% and\n86.53% on MNIST and ModelNet10, respectively, relative to an NVIDIA RTX 4090.\nTogether, our co-design establishes a scalable brain-inspired paradigm for\nadaptive, energy-efficient edge intelligence in the future.", "AI": {"tldr": "\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u52a8\u6001\u526a\u679d\u7b56\u7565\u548c\u57fa\u4e8eRRAM\u7684\u5168\u6570\u5b57\u5b58\u5185\u8ba1\u7b97\u82af\u7247\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u5e76\u4fdd\u6301\u4e86\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u6a21\u4eff\u4eba\u8111\u540c\u65f6\u4f18\u5316\u7a81\u89e6\u6743\u91cd\u548c\u62d3\u6251\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u5f53\u524dAI\u7cfb\u7edf\u5728\u6b64\u65b9\u9762\u7684\u4e0d\u8db3\u53ca\u9ad8\u80fd\u8017\u95ee\u9898\u3002", "method": "\u7b97\u6cd5\u5c42\u9762\u5f15\u5165\u5b9e\u65f6\u52a8\u6001\u526a\u679d\u7b56\u7565\uff0c\u786c\u4ef6\u5c42\u9762\u8bbe\u8ba1\u57fa\u4e8e1T1R RRAM\u7684\u53ef\u91cd\u6784\u5168\u6570\u5b57\u5b58\u5185\u8ba1\u7b97\u82af\u7247\u3002", "result": "\u5728MNIST\u548cModelNet10\u4e0a\u5206\u522b\u51cf\u5c1126.80%\u548c59.94%\u7684\u64cd\u4f5c\uff0c\u80fd\u8017\u964d\u4f4e57.26%\u81f386.53%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u534f\u540c\u8bbe\u8ba1\u4e3a\u672a\u6765\u81ea\u9002\u5e94\u3001\u9ad8\u80fd\u6548\u7684\u8fb9\u7f18\u667a\u80fd\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12611", "pdf": "https://arxiv.org/pdf/2506.12611", "abs": "https://arxiv.org/abs/2506.12611", "authors": ["Piotr Kica", "Sabina Licho\u0142ai", "Micha\u0142 Orzechowski", "Maciej Malawski"], "title": "Accelerating Cloud-Based Transcriptomics: Performance Analysis and Optimization of the STAR Aligner Workflow", "categories": ["cs.DC"], "comment": "Accepted at ICCS2025", "summary": "In this work, we explore the Transcriptomics Atlas pipeline adapted for\ncost-efficient and high-throughput computing in the cloud. We propose a\nscalable, cloud-native architecture designed for running a resource-intensive\naligner -- STAR -- and processing tens or hundreds of terabytes of\nRNA-sequencing data. We implement multiple optimization techniques that give\nsignificant execution time and cost reduction. The impact of particular\noptimizations is measured in medium-scale experiments followed by a large-scale\nexperiment that leverages all of them and validates the current design. Early\nstopping optimization allows a reduction in total alignment time by 23%. We\nanalyze the scalability and efficiency of one of the most widely used sequence\naligners. For the cloud environment, we identify one of the most suitable EC2\ninstance types and verify the applicability of spot instances usage.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u4e91\u7aef\u7684\u8f6c\u5f55\u7ec4\u5b66\u56fe\u8c31\u6d41\u7a0b\uff0c\u901a\u8fc7\u4f18\u5316\u6280\u672f\u663e\u8457\u964d\u4f4e\u4e86\u6267\u884c\u65f6\u95f4\u548c\u6210\u672c\u3002", "motivation": "\u4e3a\u4e86\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21RNA\u6d4b\u5e8f\u6570\u636e\uff0c\u63a2\u7d22\u6210\u672c\u6548\u76ca\u9ad8\u7684\u4e91\u8ba1\u7b97\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53ef\u6269\u5c55\u7684\u4e91\u539f\u751f\u67b6\u6784\uff0c\u4f18\u5316STAR\u6bd4\u5bf9\u5668\uff0c\u5e76\u9a8c\u8bc1spot\u5b9e\u4f8b\u7684\u9002\u7528\u6027\u3002", "result": "\u4f18\u5316\u6280\u672f\u4f7f\u6bd4\u5bf9\u65f6\u95f4\u51cf\u5c1123%\uff0c\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u67b6\u6784\u53ca\u4f18\u5316\u6280\u672f\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8f6c\u5f55\u7ec4\u6570\u636e\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2506.12691", "pdf": "https://arxiv.org/pdf/2506.12691", "abs": "https://arxiv.org/abs/2506.12691", "authors": ["Bianca Trinkenreich", "Fabio Calefato", "Geir Hanssen", "Kelly Blincoe", "Marcos Kalinowski", "Mauro Pezz\u00e8", "Paolo Tell", "Margaret-Anne Storey"], "title": "Get on the Train or be Left on the Station: Using LLMs for Software Engineering Research", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted for publication at the 1st Workshop on Human-Centered AI for\n  SE (Human AISE) held at the 33rd ACM International Conference on the\n  Foundations of Software Engineering (FSE Companion '25), June 23-28, 2025,\n  Trondheim, Norway", "summary": "The adoption of Large Language Models (LLMs) is not only transforming\nsoftware engineering (SE) practice but is also poised to fundamentally disrupt\nhow research is conducted in the field. While perspectives on this\ntransformation range from viewing LLMs as mere productivity tools to\nconsidering them revolutionary forces, we argue that the SE research community\nmust proactively engage with and shape the integration of LLMs into research\npractices, emphasizing human agency in this transformation. As LLMs rapidly\nbecome integral to SE research - both as tools that support investigations and\nas subjects of study - a human-centric perspective is essential. Ensuring human\noversight and interpretability is necessary for upholding scientific rigor,\nfostering ethical responsibility, and driving advancements in the field.\nDrawing from discussions at the 2nd Copenhagen Symposium on Human-Centered AI\nin SE, this position paper employs McLuhan's Tetrad of Media Laws to analyze\nthe impact of LLMs on SE research. Through this theoretical lens, we examine\nhow LLMs enhance research capabilities through accelerated ideation and\nautomated processes, make some traditional research practices obsolete,\nretrieve valuable aspects of historical research approaches, and risk reversal\neffects when taken to extremes. Our analysis reveals opportunities for\ninnovation and potential pitfalls that require careful consideration. We\nconclude with a call to action for the SE research community to proactively\nharness the benefits of LLMs while developing frameworks and guidelines to\nmitigate their risks, to ensure continued rigor and impact of research in an\nAI-augmented future.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u7814\u7a76\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u9700\u8981\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u89d2\u5ea6\u6765\u6574\u5408LLMs\uff0c\u4ee5\u4fdd\u969c\u79d1\u5b66\u4e25\u8c28\u6027\u548c\u4f26\u7406\u8d23\u4efb\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5206\u6790LLMs\u5982\u4f55\u6539\u53d8SE\u7814\u7a76\u5b9e\u8df5\uff0c\u5e76\u547c\u5401\u5b66\u672f\u754c\u4e3b\u52a8\u5f15\u5bfc\u8fd9\u4e00\u53d8\u9769\uff0c\u786e\u4fdd\u4eba\u7c7b\u5728\u5176\u4e2d\u7684\u4e3b\u5bfc\u5730\u4f4d\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u662f\u901a\u8fc7McLuhan\u7684\u5a92\u4f53\u56db\u5143\u5f8b\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790LLMs\u5bf9SE\u7814\u7a76\u7684\u589e\u5f3a\u3001\u6dd8\u6c70\u3001\u91cd\u73b0\u548c\u9006\u8f6c\u6548\u5e94\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cLLMs\u80fd\u52a0\u901f\u521b\u65b0\u4f46\u4e5f\u5e26\u6765\u4f20\u7edf\u65b9\u6cd5\u6dd8\u6c70\u548c\u6781\u7aef\u98ce\u9669\uff0c\u9700\u8981\u6846\u67b6\u5f15\u5bfc\u4ee5\u626c\u957f\u907f\u77ed\u3002", "conclusion": "\u7ed3\u8bba\u547c\u5401SE\u7814\u7a76\u793e\u533a\u4e3b\u52a8\u5229\u7528LLMs\u4f18\u52bf\uff0c\u540c\u65f6\u5236\u5b9a\u6307\u5bfc\u6846\u67b6\u4ee5\u964d\u4f4e\u98ce\u9669\uff0c\u786e\u4fddAI\u589e\u5f3a\u672a\u6765\u7684\u7814\u7a76\u8d28\u91cf\u3002"}}
{"id": "2506.12462", "pdf": "https://arxiv.org/pdf/2506.12462", "abs": "https://arxiv.org/abs/2506.12462", "authors": ["Xuchuang Wang", "Maoli Liu", "Xutong Liu", "Zhuohua Li", "Mohammad Hajiesmaili", "John C. S. Lui", "Don Towsley"], "title": "Learning Best Paths in Quantum Networks", "categories": ["cs.NI", "cs.LG", "quant-ph"], "comment": "Accepted at INFOCOM 2025", "summary": "Quantum networks (QNs) transmit delicate quantum information across noisy\nquantum channels. Crucial applications, like quantum key distribution (QKD) and\ndistributed quantum computation (DQC), rely on efficient quantum information\ntransmission. Learning the best path between a pair of end nodes in a QN is key\nto enhancing such applications. This paper addresses learning the best path in\na QN in the online learning setting. We explore two types of feedback:\n\"link-level\" and \"path-level\". Link-level feedback pertains to QNs with\nadvanced quantum switches that enable link-level benchmarking. Path-level\nfeedback, on the other hand, is associated with basic quantum switches that\npermit only path-level benchmarking. We introduce two online learning\nalgorithms, BeQuP-Link and BeQuP-Path, to identify the best path using\nlink-level and path-level feedback, respectively. To learn the best path,\nBeQuP-Link benchmarks the critical links dynamically, while BeQuP-Path relies\non a subroutine, transferring path-level observations to estimate link-level\nparameters in a batch manner. We analyze the quantum resource complexity of\nthese algorithms and demonstrate that both can efficiently and, with high\nprobability, determine the best path. Finally, we perform NetSquid-based\nsimulations and validate that both algorithms accurately and efficiently\nidentify the best path.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u91cf\u5b50\u7f51\u7edc\uff08QN\uff09\u4e2d\u6700\u4f73\u8def\u5f84\u7684\u5728\u7ebf\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u4e0d\u540c\u53cd\u9988\u673a\u5236\u7684\u7b97\u6cd5\uff08BeQuP-Link\u548cBeQuP-Path\uff09\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u91cf\u5b50\u7f51\u7edc\u5728\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u548c\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\uff08DQC\uff09\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u5728\u7ebf\u5b66\u4e60\u627e\u5230\u6700\u4f73\u8def\u5f84\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8fd9\u4e9b\u5e94\u7528\u7684\u6548\u7387\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1aBeQuP-Link\uff08\u4f7f\u7528\u94fe\u8def\u7ea7\u53cd\u9988\u52a8\u6001\u8bc4\u4f30\u5173\u952e\u94fe\u8def\uff09\u548cBeQuP-Path\uff08\u901a\u8fc7\u8def\u5f84\u7ea7\u53cd\u9988\u6279\u91cf\u4f30\u8ba1\u94fe\u8def\u53c2\u6570\uff09\u3002", "result": "\u4e24\u79cd\u7b97\u6cd5\u5747\u80fd\u4ee5\u9ad8\u6982\u7387\u9ad8\u6548\u5730\u627e\u5230\u6700\u4f73\u8def\u5f84\uff0c\u5e76\u901a\u8fc7NetSquid\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u4e0d\u540c\u53cd\u9988\u673a\u5236\u7684\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u91cf\u5b50\u7f51\u7edc\u4e2d\u6700\u4f73\u8def\u5f84\u7684\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u91cf\u5b50\u7f51\u7edc\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2506.12437", "pdf": "https://arxiv.org/pdf/2506.12437", "abs": "https://arxiv.org/abs/2506.12437", "authors": ["Vivek Chavan", "Arsen Cenaj", "Shuyuan Shen", "Ariane Bar", "Srishti Binwani", "Tommaso Del Becaro", "Marius Funk", "Lynn Greschner", "Roberto Hung", "Stina Klein", "Romina Kleiner", "Stefanie Krause", "Sylwia Olbrych", "Vishvapalsinhji Parmar", "Jaleh Sarafraz", "Daria Soroko", "Daksitha Withanage Don", "Chang Zhou", "Hoang Thuy Duong Vu", "Parastoo Semnani", "Daniel Weinhardt", "Elisabeth Andre", "J\u00f6rg Kr\u00fcger", "Xavier Fresquet"], "title": "Feeling Machines: Ethics, Culture, and the Rise of Emotional AI", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "From the Spring School 2025 by AI Grid and SCAI (Sorbonne\n  University), 16 pages", "summary": "This paper explores the growing presence of emotionally responsive artificial\nintelligence through a critical and interdisciplinary lens. Bringing together\nthe voices of early-career researchers from multiple fields, it explores how AI\nsystems that simulate or interpret human emotions are reshaping our\ninteractions in areas such as education, healthcare, mental health, caregiving,\nand digital life. The analysis is structured around four central themes: the\nethical implications of emotional AI, the cultural dynamics of human-machine\ninteraction, the risks and opportunities for vulnerable populations, and the\nemerging regulatory, design, and technical considerations. The authors\nhighlight the potential of affective AI to support mental well-being, enhance\nlearning, and reduce loneliness, as well as the risks of emotional\nmanipulation, over-reliance, misrepresentation, and cultural bias. Key\nchallenges include simulating empathy without genuine understanding, encoding\ndominant sociocultural norms into AI systems, and insufficient safeguards for\nindividuals in sensitive or high-risk contexts. Special attention is given to\nchildren, elderly users, and individuals with mental health challenges, who may\ninteract with AI in emotionally significant ways. However, there remains a lack\nof cognitive or legal protections which are necessary to navigate such\nengagements safely. The report concludes with ten recommendations, including\nthe need for transparency, certification frameworks, region-specific\nfine-tuning, human oversight, and longitudinal research. A curated\nsupplementary section provides practical tools, models, and datasets to support\nfurther work in this domain.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8de8\u5b66\u79d1\u89c6\u89d2\u63a2\u8ba8\u4e86\u60c5\u611f\u4eba\u5de5\u667a\u80fd\u7684\u5174\u8d77\u53ca\u5176\u5f71\u54cd\uff0c\u91cd\u70b9\u5173\u6ce8\u4f26\u7406\u3001\u6587\u5316\u3001\u98ce\u9669\u548c\u76d1\u7ba1\u7b49\u65b9\u9762\u3002", "motivation": "\u7814\u7a76\u60c5\u611fAI\u5728\u591a\u4e2a\u9886\u57df\uff08\u5982\u6559\u80b2\u3001\u533b\u7597\uff09\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u6f5c\u5728\u98ce\u9669\u4e0e\u673a\u9047\uff0c\u5c24\u5176\u662f\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u591a\u5b66\u79d1\u7814\u7a76\u89c6\u89d2\uff0c\u56f4\u7ed5\u4f26\u7406\u3001\u6587\u5316\u3001\u98ce\u9669\u4e0e\u76d1\u7ba1\u56db\u5927\u4e3b\u9898\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63ed\u793a\u4e86\u60c5\u611fAI\u5728\u5fc3\u7406\u5065\u5eb7\u3001\u5b66\u4e60\u652f\u6301\u7b49\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4f46\u4e5f\u6307\u51fa\u4e86\u60c5\u611f\u64cd\u7eb5\u3001\u4f9d\u8d56\u7b49\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u5341\u9879\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "\u5efa\u8bae\u52a0\u5f3a\u900f\u660e\u5ea6\u3001\u76d1\u7ba1\u6846\u67b6\u548c\u957f\u671f\u7814\u7a76\uff0c\u4ee5\u5b89\u5168\u63a8\u52a8\u60c5\u611fAI\u7684\u53d1\u5c55\uff0c\u5e76\u9644\u5de5\u5177\u548c\u6570\u636e\u96c6\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.13670", "pdf": "https://arxiv.org/pdf/2506.13670", "abs": "https://arxiv.org/abs/2506.13670", "authors": ["Mihail Stoian", "Andreas Zimmerer", "Skander Krid", "Amadou Latyr Ngom", "Jialin Ding", "Tim Kraska", "Andreas Kipf"], "title": "Parachute: Single-Pass Bi-Directional Information Passing", "categories": ["cs.DB"], "comment": "To appear at VLDB 2025", "summary": "Sideways information passing is a well-known technique for mitigating the\nimpact of large build sides in a database query plan. As currently implemented\nin production systems, sideways information passing enables only a\nuni-directional information flow, as opposed to instance-optimal algorithms,\nsuch as Yannakakis'. On the other hand, the latter require an additional pass\nover the input, which hinders adoption in production systems.\n  In this paper, we make a step towards enabling single-pass bi-directional\ninformation passing during query execution. We achieve this by statically\nanalyzing between which tables the information flow is blocked and by\nleveraging precomputed join-induced fingerprint columns on FK-tables. On the\nJOB benchmark, Parachute improves DuckDB v1.2's end-to-end execution time\nwithout and with semi-join filtering by 1.54x and 1.24x, respectively, when\nallowed to use 15% extra space.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u6b21\u53cc\u5411\u4fe1\u606f\u4f20\u9012\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u548c\u9884\u8ba1\u7b97\u6307\u7eb9\u5217\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u6267\u884c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6a2a\u5411\u4fe1\u606f\u4f20\u9012\u6280\u672f\u4ec5\u652f\u6301\u5355\u5411\u4fe1\u606f\u6d41\uff0c\u800c\u5b9e\u4f8b\u6700\u4f18\u7b97\u6cd5\uff08\u5982Yannakakis\uff09\u9700\u8981\u989d\u5916\u8f93\u5165\u626b\u63cf\uff0c\u9650\u5236\u4e86\u5176\u5728\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u91c7\u7528\u3002", "method": "\u901a\u8fc7\u5bf9\u4fe1\u606f\u6d41\u88ab\u963b\u585e\u7684\u8868\u8fdb\u884c\u9759\u6001\u5206\u6790\uff0c\u5e76\u5229\u7528\u9884\u8ba1\u7b97\u7684\u5916\u952e\u8868\u6307\u7eb9\u5217\uff0c\u5b9e\u73b0\u67e5\u8be2\u6267\u884c\u4e2d\u7684\u5355\u6b21\u53cc\u5411\u4fe1\u606f\u4f20\u9012\u3002", "result": "\u5728JOB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cParachute\u5c06DuckDB v1.2\u7684\u7aef\u5230\u7aef\u6267\u884c\u65f6\u95f4\u5206\u522b\u63d0\u5347\u4e861.54\u500d\uff08\u65e0\u534a\u8fde\u63a5\u8fc7\u6ee4\uff09\u548c1.24\u500d\uff08\u5e26\u534a\u8fde\u63a5\u8fc7\u6ee4\uff09\uff0c\u989d\u5916\u7a7a\u95f4\u5360\u7528\u4e3a15%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u9ad8\u6548\u7684\u67e5\u8be2\u6267\u884c\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u901a\u8fc7\u5355\u6b21\u53cc\u5411\u4fe1\u606f\u4f20\u9012\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2506.12096", "pdf": "https://arxiv.org/pdf/2506.12096", "abs": "https://arxiv.org/abs/2506.12096", "authors": ["Huma Habib Shadan", "Sardar Islam"], "title": "Quantum Computing and Cybersecurity in Accounting and Finance: Current and the Future Challenges and Opportunities for Securing Accounting and Finance Systems", "categories": ["cs.CR", "cs.ET"], "comment": "45 Pages, 2 Figures, 4 Tables, 1 Flow Diagram", "summary": "Quantum computing is revolutionising information systems and will have a\nsignificant impact on accounting and finance, especially in the area of\ncybersecurity. It presents both opportunities and risks in ensuring\nconfidentiality and protecting financial data. The purpose of this thesis is to\nshow the application of quantum technologies in accounting cybersecurity,\nutilising quantum algorithms and QKD to overcome the limitations of classical\ncomputing.\n  The literature review reveals the vulnerabilities of the current accounting\ncybersecurity to quantum attacks and the need for quantum-resistant\ncryptographic mechanisms. It elaborates on the risks associated with\nconventional encryption in the context of quantum capabilities. This study\ncontributes to the understanding of how quantum computing can revolutionise\naccounting cybersecurity by enhancing quantum-resistant algorithms and\nutilising quantum key distribution (QKD) in accounting.\n  The study employs PSALSAR systematic review methodology to ensure rigour and\ndepth. The analysis shows that quantum computing enhances encryption techniques\nto superior possibilities than classical ones. Using quantum technologies in\naccounting minimises data breaches and unauthorised access. The study concludes\nthat quantum-resistant algorithms and quantum key distribution (QKD) are\nnecessary for securing the accounting and finance systems of the future.\n  Keywords Quantum Computing, Cybersecurity, Accounting, Machine Learning,\nArtificial Intelligence, Quantum Key Distribution, Operations Management", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u4f1a\u8ba1\u4e0e\u91d1\u878d\u9886\u57df\u7684\u7f51\u7edc\u5b89\u5168\u5e94\u7528\uff0c\u5206\u6790\u4e86\u5176\u5e26\u6765\u7684\u673a\u9047\u4e0e\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u91cf\u5b50\u6297\u6027\u7b97\u6cd5\u548c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u4f1a\u8ba1\u7f51\u7edc\u5b89\u5168\u5728\u91cf\u5b50\u653b\u51fb\u4e0b\u5b58\u5728\u6f0f\u6d1e\uff0c\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u9762\u4e34\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u91cf\u5b50\u8ba1\u7b97\u5982\u4f55\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e86PSALSAR\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u52a0\u5bc6\u6280\u672f\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5bf9\u7f51\u7edc\u5b89\u5168\u7684\u5f71\u54cd\u3002", "result": "\u91cf\u5b50\u8ba1\u7b97\u80fd\u591f\u63d0\u5347\u52a0\u5bc6\u6280\u672f\uff0c\u51cf\u5c11\u6570\u636e\u6cc4\u9732\u548c\u672a\u7ecf\u6388\u6743\u7684\u8bbf\u95ee\u3002", "conclusion": "\u91cf\u5b50\u6297\u6027\u7b97\u6cd5\u548c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u662f\u672a\u6765\u4fdd\u62a4\u4f1a\u8ba1\u4e0e\u91d1\u878d\u7cfb\u7edf\u5b89\u5168\u7684\u5173\u952e\u6280\u672f\u3002"}}
{"id": "2506.12200", "pdf": "https://arxiv.org/pdf/2506.12200", "abs": "https://arxiv.org/abs/2506.12200", "authors": ["Yujie Zhao", "Zhijing Wu", "Hejia Zhang", "Zhongming Yu", "Wentao Ni", "Chia-Tung Ho", "Haoxing Ren", "Jishen Zhao"], "title": "PRO-V: An Efficient Program Generation Multi-Agent System for Automatic RTL Verification", "categories": ["cs.AI", "cs.AR"], "comment": null, "summary": "LLM-assisted hardware verification is gaining substantial attention due to\nits potential to significantly reduce the cost and effort of crafting effective\ntestbenches. It also serves as a critical enabler for LLM-aided end-to-end\nhardware language design. However, existing current LLMs often struggle with\nRegister Transfer Level (RTL) code generation, resulting in testbenches that\nexhibit functional errors in Hardware Description Languages (HDL) logic.\nMotivated by the strong performance of LLMs in Python code generation under\ninference-time sampling strategies, and their promising capabilities as judge\nagents, we propose PRO-V a fully program generation multi-agent system for\nrobust RTL verification. Pro-V incorporates an efficient best-of-n iterative\nsampling strategy to enhance the correctness of generated testbenches.\nMoreover, it introduces an LLM-as-a-judge aid validation framework featuring an\nautomated prompt generation pipeline. By converting rule-based static analysis\nfrom the compiler into natural language through in-context learning, this\npipeline enables LLMs to assist the compiler in determining whether\nverification failures stem from errors in the RTL design or the testbench.\nPRO-V attains a verification accuracy of 87.17% on golden RTL implementations\nand 76.28% on RTL mutants. Our code is open-sourced at\nhttps://github.com/stable-lab/Pro-V.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aPRO-V\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u63d0\u5347LLM\u5728\u786c\u4ef6\u9a8c\u8bc1\u4e2d\u7684RTL\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u901a\u8fc7\u6700\u4f73\u62bd\u6837\u7b56\u7565\u548cLLM\u8f85\u52a9\u9a8c\u8bc1\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u5e73\u53f0\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5728\u751f\u6210RTL\u4ee3\u7801\u65f6\u5b58\u5728\u529f\u80fd\u9519\u8bef\uff0c\u800c\u5176\u5728Python\u4ee3\u7801\u751f\u6210\u548c\u4f5c\u4e3a\u8bc4\u5224\u4ee3\u7406\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u56e0\u6b64\u7814\u7a76\u8005\u63d0\u51faPRO-V\u4ee5\u6539\u8fdb\u786c\u4ef6\u9a8c\u8bc1\u3002", "method": "\u63d0\u51faPRO-V\u7cfb\u7edf\uff0c\u5229\u7528\u6700\u4f73\u62bd\u6837\u7b56\u7565\u4f18\u5316\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\uff0c\u5e76\u5f15\u5165LLM\u4f5c\u4e3a\u8bc4\u5224\u4ee3\u7406\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u9759\u6001\u5206\u6790\u89c4\u5219\u8fdb\u884c\u8f85\u52a9\u9a8c\u8bc1\u3002", "result": "\u5728\u9ec4\u91d1RTL\u5b9e\u73b0\u548cRTL\u7a81\u53d8\u4f53\u4e0a\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523087.17%\u548c76.28%\u3002", "conclusion": "PRO-V\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548cLLM\u8f85\u52a9\u9a8c\u8bc1\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u786c\u4ef6\u9a8c\u8bc1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.12686", "pdf": "https://arxiv.org/pdf/2506.12686", "abs": "https://arxiv.org/abs/2506.12686", "authors": ["Chuanchao Gao", "Niraj Kumar", "Arvind Easwaran"], "title": "Energy-Efficient Real-Time Job Mapping and Resource Management in Mobile-Edge Computing", "categories": ["cs.DC"], "comment": null, "summary": "Mobile-edge computing (MEC) has emerged as a promising paradigm for enabling\nInternet of Things (IoT) devices to handle computation-intensive jobs. Due to\nthe imperfect parallelization of algorithms for job processing on servers and\nthe impact of IoT device mobility on data communication quality in wireless\nnetworks, it is crucial to jointly consider server resource allocation and IoT\ndevice mobility during job scheduling to fully benefit from MEC, which is often\noverlooked in existing studies. By jointly considering job scheduling, server\nresource allocation, and IoT device mobility, we investigate the\ndeadline-constrained job offloading and resource management problem in MEC with\nboth communication and computation contentions, aiming to maximize the total\nenergy saved for IoT devices. For the offline version of the problem, where job\ninformation is known in advance, we formulate it as an Integer Linear\nProgramming problem and propose an approximation algorithm, $\\mathtt{LHJS}$,\nwith a constant performance guarantee. For the online version, where job\ninformation is only known upon release, we propose a heuristic algorithm,\n$\\mathtt{LBS}$, that is invoked whenever a job is released. Finally, we conduct\nexperiments with parameters from real-world applications to evaluate their\nperformance.", "AI": {"tldr": "\u7814\u7a76\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u4e2d\u7ed3\u5408\u4efb\u52a1\u8c03\u5ea6\u3001\u670d\u52a1\u5668\u8d44\u6e90\u5206\u914d\u548c\u7269\u8054\u7f51\u8bbe\u5907\u79fb\u52a8\u6027\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u79bb\u7ebf\u548c\u5728\u7ebf\u7b97\u6cd5\u4ee5\u6700\u5927\u5316\u8282\u7ea6\u7269\u8054\u7f51\u8bbe\u5907\u80fd\u91cf\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5e38\u5ffd\u89c6\u670d\u52a1\u5668\u8d44\u6e90\u5206\u914d\u4e0e\u7269\u8054\u7f51\u8bbe\u5907\u79fb\u52a8\u6027\u7684\u8054\u5408\u8003\u8651\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5145\u5206\u5229\u7528MEC\u6f5c\u529b\u3002", "method": "\u79bb\u7ebf\u95ee\u9898\u5efa\u6a21\u4e3a\u6574\u6570\u7ebf\u6027\u89c4\u5212\u5e76\u63d0\u51fa\u8fd1\u4f3c\u7b97\u6cd5LHJS\uff1b\u5728\u7ebf\u95ee\u9898\u63d0\u51fa\u542f\u53d1\u5f0f\u7b97\u6cd5LBS\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u8054\u5408\u4f18\u5316\u80fd\u6709\u6548\u63d0\u5347MEC\u7cfb\u7edf\u6027\u80fd\uff0c\u663e\u8457\u8282\u7ea6\u7269\u8054\u7f51\u8bbe\u5907\u80fd\u91cf\u3002"}}
{"id": "2506.12713", "pdf": "https://arxiv.org/pdf/2506.12713", "abs": "https://arxiv.org/abs/2506.12713", "authors": ["Xiangyang Li", "Xiaopeng Li", "Kuicai Dong", "Quanhu Zhang", "Rongju Ruan", "Xinyi Dai", "Xiaoshuang Liu", "Shengchun Xu", "Yasheng Wang", "Ruiming Tang"], "title": "Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Code generation is a core capability of large language models (LLMs), yet\nmainstream benchmarks (e.g., APPs and LiveCodeBench) contain questions with\nmedium-level difficulty and pose no challenge to advanced LLMs. To better\nreflected the advanced reasoning and code generation ability, We introduce\nHumanity's Last Code Exam (HLCE), comprising 235 most challenging problems from\nthe International Collegiate Programming Contest (ICPC World Finals) and the\nInternational Olympiad in Informatics (IOI) spanning 2010 - 2024. As part of\nHLCE, we design a harmonized online-offline sandbox that guarantees fully\nreproducible evaluation. Through our comprehensive evaluation, we observe that\neven the strongest reasoning LLMs: o4-mini(high) and Gemini-2.5 Pro, achieve\npass@1 rates of only 15.9% and 11.4%, respectively. Meanwhile, we propose a\nnovel \"self-recognition\" task to measure LLMs' awareness of their own\ncapabilities. Results indicate that LLMs' self-recognition abilities are not\nproportionally correlated with their code generation performance. Finally, our\nempirical validation of test-time scaling laws reveals that current advanced\nLLMs have substantial room for improvement on complex programming tasks. We\nexpect HLCE to become a milestone challenge for code generation and to catalyze\nadvances in high-performance reasoning and human-AI collaborative programming.\nOur code and dataset are also public\navailable(https://github.com/Humanity-s-Last-Code-Exam/HLCE).", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86HLCE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b235\u4e2a\u9ad8\u96be\u5ea6\u7f16\u7a0b\u95ee\u9898\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u7684\u9ad8\u7ea7\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002\u6700\u5148\u8fdb\u7684LLMs\u5728\u8be5\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u81ea\u6211\u8ba4\u77e5\u80fd\u529b\u4e0e\u4ee3\u7801\u751f\u6210\u80fd\u529b\u4e0d\u76f8\u5173\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u9ad8\u7ea7LLMs\u6311\u6218\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5176\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u96be\u7684\u6d4b\u8bd5\u96c6\u3002", "method": "\u8bbe\u8ba1\u4e86HLCE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542bICPC\u548cIOI\u7684235\u4e2a\u9ad8\u96be\u5ea6\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u91cd\u73b0\u7684\u5728\u7ebf-\u79bb\u7ebf\u6c99\u76d2\u8bc4\u4f30\u73af\u5883\u3002", "result": "\u6700\u5f3aLLMs\u7684\u901a\u8fc7\u7387\u4ec515.9%\u548c11.4%\uff0c\u4e14\u81ea\u6211\u8ba4\u77e5\u80fd\u529b\u4e0e\u4ee3\u7801\u751f\u6210\u80fd\u529b\u65e0\u663e\u8457\u76f8\u5173\u6027\u3002", "conclusion": "HLCE\u5c06\u6210\u4e3a\u4ee3\u7801\u751f\u6210\u7684\u91cc\u7a0b\u7891\u6311\u6218\uff0c\u63a8\u52a8\u9ad8\u6027\u80fd\u63a8\u7406\u548c\u4eba-AI\u534f\u4f5c\u7f16\u7a0b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.13003", "pdf": "https://arxiv.org/pdf/2506.13003", "abs": "https://arxiv.org/abs/2506.13003", "authors": ["Yunyi Wu", "Yongbing Zhang"], "title": "Cost-Efficient Design for 5G-Enabled MEC Servers under Uncertain User Demands", "categories": ["cs.NI"], "comment": "8 pages, 8 figures", "summary": "Mobile edge computing (MEC) enhances the performance of 5G networks by\nenabling low-latency, high-speed services through deploying data units of the\nbase station on edge servers located near mobile users. However, determining\nthe optimal capacity of these servers while dynamically offloading tasks and\nallocating computing resources to meet uncertain user demands presents\nsignificant challenges. This paper focuses on the design and planning of edge\nservers with the dual objectives of minimizing capacity requirements and\nreducing service latency for 5G services. To handle the complexity of uncertain\nuser demands, we formulate the problem as a two-stage stochastic model, which\ncan be linearized into a mixed-integer linear programming (MILP) problem. We\npropose a novel approach called accelerated Benders decomposition (ABD) to\nsolve the problem at a large network scale. Numerical experiments demonstrate\nthat ABD achieves the optimal solution of MILP while significantly reducing\ncomputation time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a0\u901fBenders\u5206\u89e3\uff08ABD\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u53165G\u7f51\u7edc\u4e2d\u7684\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u670d\u52a1\u5668\u89c4\u5212\u548c\u8d44\u6e90\u5206\u914d\uff0c\u4ee5\u6700\u5c0f\u5316\u5bb9\u91cf\u9700\u6c42\u548c\u670d\u52a1\u5ef6\u8fdf\u3002", "motivation": "\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u901a\u8fc7\u5c06\u6570\u636e\u5355\u5143\u90e8\u7f72\u5728\u9760\u8fd1\u7528\u6237\u7684\u4f4d\u7f6e\uff0c\u63d0\u5347\u4e865G\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u4f46\u5728\u52a8\u6001\u5378\u8f7d\u4efb\u52a1\u548c\u8d44\u6e90\u5206\u914d\u4e2d\u9762\u4e34\u7528\u6237\u9700\u6c42\u4e0d\u786e\u5b9a\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u968f\u673a\u6a21\u578b\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u95ee\u9898\uff0c\u5e76\u63d0\u51faABD\u65b9\u6cd5\u6765\u9ad8\u6548\u6c42\u89e3\u5927\u89c4\u6a21\u7f51\u7edc\u95ee\u9898\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0cABD\u80fd\u591f\u5728\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u7684\u540c\u65f6\uff0c\u5f97\u5230MILP\u7684\u6700\u4f18\u89e3\u3002", "conclusion": "ABD\u65b9\u6cd5\u5728\u4f18\u5316\u8fb9\u7f18\u670d\u52a1\u5668\u89c4\u5212\u548c\u8d44\u6e90\u5206\u914d\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\uff0c\u9002\u7528\u4e8e5G\u7f51\u7edc\u4e2d\u7684MEC\u573a\u666f\u3002"}}
{"id": "2506.12469", "pdf": "https://arxiv.org/pdf/2506.12469", "abs": "https://arxiv.org/abs/2506.12469", "authors": ["K. J. Kevin Feng", "David W. McDonald", "Amy X. Zhang"], "title": "Levels of Autonomy for AI Agents", "categories": ["cs.HC", "cs.AI"], "comment": "Forthcoming paper in the Knight First Amendment Institute's \"AI and\n  Democratic Freedoms\" essay series", "summary": "Autonomy is a double-edged sword for AI agents, simultaneously unlocking\ntransformative possibilities and serious risks. How can agent developers\ncalibrate the appropriate levels of autonomy at which their agents should\noperate? We argue that an agent's level of autonomy can be treated as a\ndeliberate design decision, separate from its capability and operational\nenvironment. In this work, we define five levels of escalating agent autonomy,\ncharacterized by the roles a user can take when interacting with an agent:\noperator, collaborator, consultant, approver, and observer. Within each level,\nwe describe the ways by which a user can exert control over the agent and open\nquestions for how to design the nature of user-agent interaction. We then\nhighlight a potential application of our framework towards AI autonomy\ncertificates to govern agent behavior in single- and multi-agent systems. We\nconclude by proposing early ideas for evaluating agents' autonomy. Our work\naims to contribute meaningful, practical steps towards responsibly deployed and\nuseful AI agents in the real world.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u4ee3\u7406\u7684\u81ea\u4e3b\u6027\u8bbe\u8ba1\uff0c\u63d0\u51fa\u4e94\u7ea7\u81ea\u4e3b\u6027\u6846\u67b6\uff0c\u5e76\u8ba8\u8bba\u4e86\u7528\u6237\u4e0e\u4ee3\u7406\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u81ea\u6cbb\u8bc1\u4e66\u8bc4\u4f30\u4ee3\u7406\u884c\u4e3a\u3002", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5728\u81ea\u4e3b\u6027\u8bbe\u8ba1\u4e2d\u5982\u4f55\u5e73\u8861\u6f5c\u529b\u4e0e\u98ce\u9669\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u5176\u8d1f\u8d23\u4efb\u5730\u90e8\u7f72\u3002", "method": "\u5b9a\u4e49\u4e86\u4e94\u7ea7\u6e10\u8fdb\u7684\u81ea\u4e3b\u6027\u6c34\u5e73\uff0c\u63cf\u8ff0\u4e86\u7528\u6237\u5728\u4e0d\u540c\u7ea7\u522b\u4e2d\u7684\u89d2\u8272\u53ca\u63a7\u5236\u65b9\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86\u81ea\u6cbb\u8bc1\u4e66\u7684\u6f5c\u5728\u5e94\u7528\u6846\u67b6\uff0c\u4ee5\u53ca\u8bc4\u4f30\u4ee3\u7406\u81ea\u4e3b\u6027\u7684\u521d\u6b65\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6846\u67b6\u548c\u5b9e\u8df5\u65b9\u6cd5\uff0c\u63a8\u52a8AI\u4ee3\u7406\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8d1f\u8d23\u4efb\u548c\u6709\u6548\u90e8\u7f72\u3002"}}
{"id": "2506.12365", "pdf": "https://arxiv.org/pdf/2506.12365", "abs": "https://arxiv.org/abs/2506.12365", "authors": ["Asifullah khan", "Muhammad Zaeem Khan", "Saleha Jamshed", "Sadia Ahmad", "Aleesha Zainab", "Kaynat Khatib", "Faria Bibi", "Abdul Rehman"], "title": "Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "This survey paper outlines the key developments in the field of Large\nLanguage Models (LLMs), such as enhancing their reasoning skills, adaptability\nto various tasks, increased computational efficiency, and ability to make\nethical decisions. The techniques that have been most effective in bridging the\ngap between human and machine communications include the Chain-of-Thought\nprompting, Instruction Tuning, and Reinforcement Learning from Human Feedback.\nThe improvements in multimodal learning and few-shot or zero-shot techniques\nhave further empowered LLMs to handle complex jobs with minor input. They also\nmanage to do more with less by applying scaling and optimization tricks for\ncomputing power conservation. This survey also offers a broader perspective on\nrecent advancements in LLMs going beyond isolated aspects such as model\narchitecture or ethical concerns. It categorizes emerging methods that enhance\nLLM reasoning, efficiency, and ethical alignment. It also identifies\nunderexplored areas such as interpretability, cross-modal integration and\nsustainability. With recent progress, challenges like huge computational costs,\nbiases, and ethical risks remain constant. Addressing these requires bias\nmitigation, transparent decision-making, and clear ethical guidelines. Future\nresearch will focus on enhancing models ability to handle multiple input,\nthereby making them more intelligent, safe, and reliable.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u6982\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9886\u57df\u7684\u5173\u952e\u8fdb\u5c55\uff0c\u5305\u62ec\u63a8\u7406\u80fd\u529b\u63d0\u5347\u3001\u4efb\u52a1\u9002\u5e94\u6027\u589e\u5f3a\u3001\u8ba1\u7b97\u6548\u7387\u63d0\u9ad8\u548c\u4f26\u7406\u51b3\u7b56\u80fd\u529b\u7b49\u3002\u6709\u6548\u65b9\u6cd5\u5305\u62ec\u94fe\u5f0f\u601d\u8003\u63d0\u793a\u3001\u6307\u4ee4\u5fae\u8c03\u548c\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u3002\u591a\u6a21\u6001\u5b66\u4e60\u548c\u5c11\u6837\u672c/\u96f6\u6837\u672c\u6280\u672f\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86LLM\u5904\u7406\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\u3002", "motivation": "\u63a2\u8ba8LLM\u7684\u6700\u65b0\u53d1\u5c55\uff0c\u4ee5\u63d0\u5347\u5176\u63a8\u7406\u3001\u6548\u7387\u3001\u4f26\u7406\u5bf9\u9f50\u7b49\u65b9\u9762\u7684\u80fd\u529b\uff0c\u540c\u65f6\u6307\u51fa\u672a\u5145\u5206\u7814\u7a76\u7684\u9886\u57df\u5982\u53ef\u89e3\u91ca\u6027\u3001\u8de8\u6a21\u6001\u6574\u5408\u548c\u53ef\u6301\u7eed\u6027\u3002", "method": "\u7efc\u8ff0\u4e86\u94fe\u5f0f\u601d\u8003\u63d0\u793a\u3001\u6307\u4ee4\u5fae\u8c03\u3001\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u7b49\u5173\u952e\u6280\u672f\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u5b66\u4e60\u548c\u5c11\u6837\u672c/\u96f6\u6837\u672c\u6280\u672f\u7684\u5e94\u7528\u3002", "result": "LLM\u5728\u63a8\u7406\u3001\u6548\u7387\u548c\u4f26\u7406\u5bf9\u9f50\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4ecd\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u504f\u89c1\u548c\u4f26\u7406\u98ce\u9669\u7b49\u6311\u6218\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5c06\u805a\u7126\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u591a\u8f93\u5165\u5904\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u66f4\u667a\u80fd\u3001\u5b89\u5168\u548c\u53ef\u9760\uff0c\u540c\u65f6\u901a\u8fc7\u900f\u660e\u51b3\u7b56\u548c\u4f26\u7406\u51c6\u5219\u5e94\u5bf9\u73b0\u6709\u6311\u6218\u3002"}}
{"id": "2506.12378", "pdf": "https://arxiv.org/pdf/2506.12378", "abs": "https://arxiv.org/abs/2506.12378", "authors": ["Barra White", "Krishnendu Guha"], "title": "Component Based Quantum Machine Learning Explainability", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG"], "comment": "11 pages", "summary": "Explainable ML algorithms are designed to provide transparency and insight\ninto their decision-making process. Explaining how ML models come to their\nprediction is critical in fields such as healthcare and finance, as it provides\ninsight into how models can help detect bias in predictions and help comply\nwith GDPR compliance in these fields. QML leverages quantum phenomena such as\nentanglement and superposition, offering the potential for computational\nspeedup and greater insights compared to classical ML. However, QML models also\ninherit the black-box nature of their classical counterparts, requiring the\ndevelopment of explainability techniques to be applied to these QML models to\nhelp understand why and how a particular output was generated.\n  This paper will explore the idea of creating a modular, explainable QML\nframework that splits QML algorithms into their core components, such as\nfeature maps, variational circuits (ansatz), optimizers, kernels, and\nquantum-classical loops. Each component will be analyzed using explainability\ntechniques, such as ALE and SHAP, which have been adapted to analyse the\ndifferent components of these QML algorithms. By combining insights from these\nparts, the paper aims to infer explainability to the overall QML model.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff08QML\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3QML\u7b97\u6cd5\u7684\u6838\u5fc3\u7ec4\u4ef6\u5e76\u5e94\u7528\u89e3\u91ca\u6027\u6280\u672f\uff08\u5982ALE\u548cSHAP\uff09\u6765\u5206\u6790\u6bcf\u4e2a\u7ec4\u4ef6\uff0c\u4ece\u800c\u63d0\u9ad8QML\u6a21\u578b\u7684\u900f\u660e\u5ea6\u3002", "motivation": "\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u9886\u57df\uff0c\u6a21\u578b\u7684\u900f\u660e\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u5e2e\u52a9\u53d1\u73b0\u9884\u6d4b\u4e2d\u7684\u504f\u89c1\u5e76\u7b26\u5408GDPR\u5408\u89c4\u8981\u6c42\u3002QML\u867d\u7136\u5177\u6709\u91cf\u5b50\u4f18\u52bf\uff0c\u4f46\u5176\u9ed1\u76d2\u7279\u6027\u4e5f\u9700\u8981\u89e3\u91ca\u6027\u6280\u672f\u7684\u652f\u6301\u3002", "method": "\u5c06QML\u7b97\u6cd5\u62c6\u5206\u4e3a\u7279\u5f81\u6620\u5c04\u3001\u53d8\u5206\u7535\u8def\u3001\u4f18\u5316\u5668\u7b49\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5e76\u4f7f\u7528\u9002\u5e94\u6027\u89e3\u91ca\u6027\u6280\u672f\uff08\u5982ALE\u548cSHAP\uff09\u5206\u6790\u6bcf\u4e2a\u7ec4\u4ef6\uff0c\u4ece\u800c\u63a8\u65ad\u6574\u4f53\u6a21\u578b\u7684\u89e3\u91ca\u6027\u3002", "result": "\u8bba\u6587\u7684\u76ee\u6807\u662f\u901a\u8fc7\u5bf9\u5404\u7ec4\u4ef6\u7684\u5206\u6790\uff0c\u63d0\u4f9bQML\u6a21\u578b\u7684\u6574\u4f53\u89e3\u91ca\u6027\uff0c\u5e2e\u52a9\u7406\u89e3\u5176\u8f93\u51fa\u751f\u6210\u7684\u8fc7\u7a0b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aQML\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u6709\u671b\u5728\u9700\u8981\u9ad8\u900f\u660e\u5ea6\u7684\u9886\u57df\u4e2d\u63a8\u52a8QML\u7684\u5e94\u7528\u3002"}}
{"id": "2506.12708", "pdf": "https://arxiv.org/pdf/2506.12708", "abs": "https://arxiv.org/abs/2506.12708", "authors": ["Pengfei Zuo", "Huimin Lin", "Junbo Deng", "Nan Zou", "Xingkun Yang", "Yingyu Diao", "Weifeng Gao", "Ke Xu", "Zhangyu Chen", "Shirui Lu", "Zhao Qiu", "Peiyang Li", "Xianyu Chang", "Zhengzhong Yu", "Fangzheng Miao", "Jia Zheng", "Ying Li", "Yuan Feng", "Bei Wang", "Zaijian Zong", "Mosong Zhou", "Wenli Zhou", "Houjiang Chen", "Xingyu Liao", "Yipeng Li", "Wenxiao Zhang", "Ping Zhu", "Yinggang Wang", "Chuanjie Xiao", "Depeng Liang", "Dong Cao", "Juncheng Liu", "Yongqiang Yang", "Xiaolong Bai", "Yi Li", "Huaguo Xie", "Huatao Wu", "Zhibin Yu", "Lv Chen", "Hu Liu", "Yujun Ding", "Haipei Zhu", "Jing Xia", "Yi Xiong", "Zhou Yu", "Heng Liao"], "title": "Serving Large Language Models on Huawei CloudMatrix384", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.LG"], "comment": "59 pages, 24 figures", "summary": "The rapid evolution of large language models (LLMs), driven by growing\nparameter scales, adoption of mixture-of-experts (MoE) architectures, and\nexpanding context lengths, imposes unprecedented demands on AI infrastructure.\nTraditional AI clusters face limitations in compute intensity, memory\nbandwidth, inter-chip communication, and latency, compounded by variable\nworkloads and strict service-level objectives. Addressing these issues requires\nfundamentally redesigned hardware-software integration. This paper introduces\nHuawei CloudMatrix, a next-generation AI datacenter architecture, realized in\nthe production-grade CloudMatrix384 supernode. It integrates 384 Ascend 910C\nNPUs and 192 Kunpeng CPUs interconnected via an ultra-high-bandwidth Unified\nBus (UB) network, enabling direct all-to-all communication and dynamic pooling\nof resources. These features optimize performance for communication-intensive\noperations, such as large-scale MoE expert parallelism and distributed\nkey-value cache access. To fully leverage CloudMatrix384, we propose\nCloudMatrix-Infer, an advanced LLM serving solution incorporating three core\ninnovations: a peer-to-peer serving architecture that independently scales\nprefill, decode, and caching; a large-scale expert parallelism strategy\nsupporting EP320 via efficient UB-based token dispatch; and hardware-aware\noptimizations including specialized operators, microbatch-based pipelining, and\nINT8 quantization. Evaluation with the DeepSeek-R1 model shows\nCloudMatrix-Infer achieves state-of-the-art efficiency: prefill throughput of\n6,688 tokens/s per NPU and decode throughput of 1,943 tokens/s per NPU (<50 ms\nTPOT). It effectively balances throughput and latency, sustaining 538 tokens/s\neven under stringent 15 ms latency constraints, while INT8 quantization\nmaintains model accuracy across benchmarks.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u534e\u4e3a\u4e91\u77e9\u9635CloudMatrix384\uff0c\u4e00\u79cd\u9762\u5411\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u578bAI\u6570\u636e\u4e2d\u5fc3\u67b6\u6784\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u786c\u4ef6-\u8f6f\u4ef6\u96c6\u6210\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfAI\u96c6\u7fa4\u5728\u8ba1\u7b97\u5f3a\u5ea6\u3001\u5185\u5b58\u5e26\u5bbd\u3001\u82af\u7247\u95f4\u901a\u4fe1\u548c\u5ef6\u8fdf\u7b49\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5927\u8bed\u8a00\u6a21\u578b\u5feb\u901f\u53d1\u5c55\u7684\u9700\u6c42\u3002", "method": "\u8bba\u6587\u63d0\u51faCloudMatrix384\u67b6\u6784\uff0c\u7ed3\u5408384\u4e2aAscend 910C NPU\u548c192\u4e2aKunpeng CPU\uff0c\u901a\u8fc7\u7edf\u4e00\u603b\u7ebf\u7f51\u7edc\u5b9e\u73b0\u52a8\u6001\u8d44\u6e90\u6c60\u5316\uff1b\u5e76\u63d0\u51fa\u4e86CloudMatrix-Infer\u670d\u52a1\u89e3\u51b3\u65b9\u6848\uff0c\u4f18\u5316\u4e86\u9884\u586b\u5145\u3001\u89e3\u7801\u548c\u7f13\u5b58\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cCloudMatrix-Infer\u5728\u9884\u586b\u5145\u548c\u89e3\u7801\u541e\u5410\u91cf\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff086,688\u548c1,943 tokens/s/NPU\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u534e\u4e3a\u4e91\u77e9\u9635\u4e3a\u5927\u89c4\u6a21AI\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u786c\u4ef6-\u8f6f\u4ef6\u96c6\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2506.12728", "pdf": "https://arxiv.org/pdf/2506.12728", "abs": "https://arxiv.org/abs/2506.12728", "authors": ["Yibo Wang", "Zhihao Peng", "Ying Wang", "Zhao Wei", "Hai Yu", "Zhiliang Zhu"], "title": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution", "categories": ["cs.SE"], "comment": null, "summary": "LLMs demonstrate strong performance in auto-mated software engineering,\nparticularly for code generation and issue resolution. While proprietary models\nlike GPT-4o achieve high benchmarks scores on SWE-bench, their API dependence,\ncost, and privacy concerns limit adoption. Open-source alternatives offer\ntransparency but underperform in complex tasks, especially sub-100B parameter\nmodels. Although quality Chain-of-Thought (CoT) data can enhance reasoning,\ncurrent methods face two critical flaws: (1) weak rejection sampling reduces\ndata quality, and (2) inadequate step validation causes error accumulation.\nThese limitations lead to flawed reasoning chains that impair LLMs'ability to\nlearn reliable issue resolution. The paper proposes MCTS-REFINE, an enhanced\nMonte Carlo Tree Search (MCTS)-based algorithm that dynamically validates and\noptimizes intermediate reasoning steps through a rigorous rejection sampling\nstrategy, generating high-quality CoT data to improve LLM performance in issue\nresolution tasks. Key innovations include: (1) augmenting MCTS with a\nreflection mechanism that corrects errors via rejection sampling and\nrefinement, (2) decomposing issue resolution into three subtasks-File\nLocalization, Fault Localization, and Patch Generation-each with clear\nground-truth criteria, and (3) enforcing a strict sampling protocol where\nintermediate outputs must exactly match verified developer patches, ensuring\ncorrectness across reasoning paths. Experiments on SWE-bench Lite and SWE-bench\nVerified demonstrate that LLMs fine-tuned with our CoT dataset achieve\nsubstantial improvements over baselines.Notably, Qwen2.5-72B- Instruct achieves\n28.3%(Lite) and 35.0%(Verified) resolution rates, surpassing SOTA baseline\nSWE-Fixer-Qwen-72B with the same parameter scale, which only reached\n24.7%(Lite) and 32.8%(Verified).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMCTS-REFINE\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u9a8c\u8bc1\u548c\u4f18\u5316\u63a8\u7406\u6b65\u9aa4\u751f\u6210\u9ad8\u8d28\u91cfCoT\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u4ee3\u7801\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u4ee3\u7801\u751f\u6210\u548c\u95ee\u9898\u89e3\u51b3\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u6570\u636e\u8d28\u91cf\u5dee\u548c\u63a8\u7406\u6b65\u9aa4\u9a8c\u8bc1\u4e0d\u8db3\u800c\u53d7\u9650\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u91c7\u7528MCTS-REFINE\u7b97\u6cd5\uff0c\u7ed3\u5408\u53cd\u5c04\u673a\u5236\u548c\u4e25\u683c\u91c7\u6837\u534f\u8bae\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u4efb\u52a1\u5e76\u786e\u4fdd\u4e2d\u95f4\u6b65\u9aa4\u6b63\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4f7f\u7528MCTS-REFINE\u751f\u6210\u7684CoT\u6570\u636e\u5fae\u8c03\u7684\u6a21\u578b\u5728SWE-bench\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MCTS-REFINE\u901a\u8fc7\u63d0\u5347\u6570\u636e\u8d28\u91cf\u548c\u63a8\u7406\u9a8c\u8bc1\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u95ee\u9898\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.13153", "pdf": "https://arxiv.org/pdf/2506.13153", "abs": "https://arxiv.org/abs/2506.13153", "authors": ["DongNyeong Heo", "Daniela Noemi Rim", "Heeyoul Choi"], "title": "Dynamic Preference Multi-Objective Reinforcement Learning for Internet Network Management", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "An internet network service provider manages its network with multiple\nobjectives, such as high quality of service (QoS) and minimum computing\nresource usage. To achieve these objectives, a reinforcement learning-based\n(RL) algorithm has been proposed to train its network management agent.\nUsually, their algorithms optimize their agents with respect to a single static\nreward formulation consisting of multiple objectives with fixed importance\nfactors, which we call preferences. However, in practice, the preference could\nvary according to network status, external concerns and so on. For example,\nwhen a server shuts down and it can cause other servers' traffic overloads\nleading to additional shutdowns, it is plausible to reduce the preference of\nQoS while increasing the preference of minimum computing resource usages. In\nthis paper, we propose new RL-based network management agents that can select\nactions based on both states and preferences. With our proposed approach, we\nexpect a single agent to generalize on various states and preferences.\nFurthermore, we propose a numerical method that can estimate the distribution\nof preference that is advantageous for unbiased training. Our experiment\nresults show that the RL agents trained based on our proposed approach\nsignificantly generalize better with various preferences than the previous RL\napproaches, which assume static preference during training. Moreover, we\ndemonstrate several analyses that show the advantages of our numerical\nestimation method.", "AI": {"tldr": "\u7f51\u7edc\u7ba1\u7406\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u80fd\u6839\u636e\u7f51\u7edc\u72b6\u6001\u52a8\u6001\u8c03\u6574\u76ee\u6807\u504f\u597d\uff0c\u4ee5\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7f51\u7edc\u7ba1\u7406\u7b97\u6cd5\u7684\u76ee\u6807\u504f\u597d\u662f\u9759\u6001\u7684\uff0c\u4f46\u5b9e\u9645\u4e2d\u504f\u597d\u4f1a\u56e0\u7f51\u7edc\u72b6\u6001\u6216\u5916\u90e8\u56e0\u7d20\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7f51\u7edc\u7ba1\u7406\u4ee3\u7406\uff0c\u52a8\u6001\u7ed3\u5408\u72b6\u6001\u548c\u504f\u597d\u9009\u62e9\u52a8\u4f5c\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u6570\u503c\u65b9\u6cd5\u4f30\u8ba1\u504f\u597d\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a8\u6001\u504f\u597d\u7684\u4ee3\u7406\u6bd4\u9759\u6001\u504f\u597d\u7684\u4ee3\u7406\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\uff0c\u6570\u503c\u4f30\u8ba1\u65b9\u6cd5\u4e5f\u663e\u793a\u51fa\u4f18\u52bf\u3002", "conclusion": "\u52a8\u6001\u8c03\u6574\u504f\u597d\u5728\u7f51\u7edc\u7ba1\u7406\u4e2d\u66f4\u7075\u6d3b\uff0c\u6cdb\u5316\u6027\u80fd\u66f4\u597d\uff0c\u6570\u503c\u65b9\u6cd5\u6709\u52a9\u4e8e\u65e0\u504f\u8bad\u7ec3\u3002"}}
{"id": "2506.12540", "pdf": "https://arxiv.org/pdf/2506.12540", "abs": "https://arxiv.org/abs/2506.12540", "authors": ["Renee Sirbu", "Jessica Morley", "Tyler Schroder", "Mariarosaria Taddeo", "Raghavendra Pradyumna Pothukuchi", "Muhammed Ugur", "Abhishek Bhattacharjee", "Luciano Floridi"], "title": "Regulating Next-Generation Implantable Brain-Computer Interfaces: Recommendations for Ethical Development and Implementation", "categories": ["cs.HC", "cs.CY", "cs.ET"], "comment": "35 pages, 3 tables, 2 appendices", "summary": "Brain-computer interfaces offer significant therapeutic opportunities for a\nvariety of neurophysiological and neuropsychiatric disorders and may perhaps\none day lead to augmenting the cognition and decision-making of the healthy\nbrain. However, existing regulatory frameworks designed for implantable medical\ndevices are inadequate to address the unique ethical, legal, and social risks\nassociated with next-generation networked brain-computer interfaces. In this\narticle, we make nine recommendations to support developers in the design of\nBCIs and nine recommendations to support policymakers in the application of\nBCIs, drawing insights from the regulatory history of IMDs and principles from\nAI ethics. We begin by outlining the historical development of IMDs and the\nregulatory milestones that have shaped their oversight. Next, we summarize\nsimilarities between IMDs and emerging implantable BCIs, identifying existing\nprovisions for their regulation. We then use two case studies of emerging\ncutting-edge BCIs, the HALO and SCALO computer systems, to highlight\ndistinctive features in the design and application of next-generation BCIs\narising from contemporary chip architectures, which necessitate reevaluating\nregulatory approaches. We identify critical ethical considerations for these\nBCIs, including unique conceptions of autonomy, identity, and mental privacy.\nBased on these insights, we suggest potential avenues for the ethical\nregulation of BCIs, emphasizing the importance of interdisciplinary\ncollaboration and proactive mitigation of potential harms. The goal is to\nsupport the responsible design and application of new BCIs, ensuring their safe\nand ethical integration into medical practice.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u7684\u76d1\u7ba1\u4e0d\u8db3\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u5f00\u53d1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u7684\u5efa\u8bae\uff0c\u4ee5\u5e94\u5bf9\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u793e\u4f1a\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u76d1\u7ba1\u6846\u67b6\u65e0\u6cd5\u6ee1\u8db3\u65b0\u4e00\u4ee3\u8054\u7f51\u8111\u673a\u63a5\u53e3\u7684\u72ec\u7279\u9700\u6c42\uff0c\u9700\u91cd\u65b0\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5206\u6790\u690d\u5165\u5f0f\u533b\u7597\u8bbe\u5907\uff08IMD\uff09\u7684\u76d1\u7ba1\u5386\u53f2\u548cAI\u4f26\u7406\u539f\u5219\uff0c\u63d0\u51fa18\u6761\u5efa\u8bae\uff0c\u5e76\u7ed3\u5408HALO\u548cSCALO\u7cfb\u7edf\u7684\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u8bc6\u522b\u4e86BCI\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u4f26\u7406\u95ee\u9898\uff08\u5982\u81ea\u4e3b\u6027\u3001\u8eab\u4efd\u548c\u9690\u79c1\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u4f26\u7406\u76d1\u7ba1\u7684\u6f5c\u5728\u9014\u5f84\u3002", "conclusion": "\u5efa\u8bae\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u4e3b\u52a8\u51cf\u5c11\u6f5c\u5728\u5371\u5bb3\uff0c\u4ee5\u786e\u4fddBCI\u7684\u5b89\u5168\u548c\u4f26\u7406\u5e94\u7528\u3002"}}
{"id": "2506.12523", "pdf": "https://arxiv.org/pdf/2506.12523", "abs": "https://arxiv.org/abs/2506.12523", "authors": ["Matteo Marco Montanari", "Alessandro Aldini"], "title": "Privacy-preserving and reward-based mechanisms of proof of engagement", "categories": ["cs.CR", "cs.ET", "C.2.4; D.2.11; K.6.5"], "comment": null, "summary": "Proof-of-Attendance (PoA) mechanisms are typically employed to demonstrate a\nspecific user's participation in an event, whether virtual or in-person. The\ngoal of this study is to extend such mechanisms to broader contexts where the\nuser wishes to digitally demonstrate her involvement in a specific activity\n(Proof-of-Engagement, PoE). This work explores different solutions, including\nDLTs as well as established technologies based on centralized systems. The main\naspects we consider include the level of privacy guaranteed to users, the scope\nof PoA/PoE (both temporal and spatial), the transferability of the proof, and\nthe integration with incentive mechanisms.", "AI": {"tldr": "\u7814\u7a76\u6269\u5c55\u4e86PoA\u673a\u5236\u4ee5\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u6570\u5b57\u53c2\u4e0e\u8bc1\u660e\uff08PoE\uff09\uff0c\u63a2\u8ba8\u4e86\u5305\u62ec\u5206\u5e03\u5f0f\u8d26\u672c\u6280\u672f\u548c\u4e2d\u5fc3\u5316\u7cfb\u7edf\u5728\u5185\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5173\u6ce8\u9690\u79c1\u3001\u65f6\u7a7a\u8303\u56f4\u3001\u8bc1\u660e\u53ef\u8f6c\u79fb\u6027\u53ca\u6fc0\u52b1\u673a\u5236\u6574\u5408\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u6269\u5c55PoA\u673a\u5236\uff0c\u4ee5\u652f\u6301\u7528\u6237\u901a\u8fc7\u6570\u5b57\u65b9\u5f0f\u8bc1\u660e\u5176\u5bf9\u7279\u5b9a\u6d3b\u52a8\u7684\u53c2\u4e0e\uff08PoE\uff09\u3002", "method": "\u63a2\u8ba8\u4e86\u4e0d\u540c\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u5206\u5e03\u5f0f\u8d26\u672c\u6280\u672f\uff08DLT\uff09\u548c\u4e2d\u5fc3\u5316\u7cfb\u7edf\uff0c\u91cd\u70b9\u5173\u6ce8\u9690\u79c1\u3001\u65f6\u7a7a\u8303\u56f4\u3001\u8bc1\u660e\u53ef\u8f6c\u79fb\u6027\u53ca\u6fc0\u52b1\u673a\u5236\u6574\u5408\u3002", "result": "\u63d0\u51fa\u4e86\u591a\u79cd\u6280\u672f\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u9690\u79c1\u4fdd\u62a4\u3001\u8303\u56f4\u8986\u76d6\u53ca\u6fc0\u52b1\u673a\u5236\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6570\u5b57\u53c2\u4e0e\u8bc1\u660e\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c55\u793a\u4e86DLT\u548c\u4e2d\u5fc3\u5316\u7cfb\u7edf\u7684\u6f5c\u529b\u53ca\u5176\u6743\u8861\u3002"}}
{"id": "2506.12900", "pdf": "https://arxiv.org/pdf/2506.12900", "abs": "https://arxiv.org/abs/2506.12900", "authors": ["Shlomi Dolev", "Amit Hendin", "Maurice Herlihy", "Maria Potop Butucaru", "Elad Michael Schiller"], "title": "Self-Stabilizing Replicated State Machine Coping with Byzantine and Recurring Transient Faults", "categories": ["cs.DC", "cs.CR"], "comment": null, "summary": "The ability to perform repeated Byzantine agreement lies at the heart of\nimportant applications such as blockchain price oracles or replicated state\nmachines. Any such protocol requires the following properties: (1)\n\\textit{Byzantine fault-tolerance}, because not all participants can be assumed\nto be honest, (2) r\\textit{ecurrent transient fault-tolerance}, because even\nhonest participants may be subject to transient ``glitches'', (3)\n\\textit{accuracy}, because the results of quantitative queries (such as price\nquotes) must lie within the interval of honest participants' inputs, and (4)\n\\textit{self-stabilization}, because it is infeasible to reboot a distributed\nsystem following a fault.\n  This paper presents the first protocol for repeated Byzantine agreement that\nsatisfies the properties listed above. Specifically, starting in an arbitrary\nsystem configuration, our protocol establishes consistency. It preserves\nconsistency in the face of up to $\\lceil n/3 \\rceil -1$ Byzantine participants\n{\\em and} constant recurring (``noise'') transient faults, of up to $\\lceil n/6\n\\rceil-1$ additional malicious transient faults, or even more than $\\lceil n/6\n\\rceil-1$ (uniformly distributed) random transient faults, in each repeated\nByzantine agreement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6ee1\u8db3\u62dc\u5360\u5ead\u5bb9\u9519\u3001\u77ac\u6001\u6545\u969c\u5bb9\u9519\u3001\u51c6\u786e\u6027\u548c\u81ea\u7a33\u5b9a\u6027\u7684\u91cd\u590d\u62dc\u5360\u5ead\u534f\u8bae\uff0c\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u56e0\u62dc\u5360\u5ead\u8282\u70b9\u548c\u77ac\u65f6\u6545\u969c\u5bfc\u81f4\u7684\u5171\u8bc6\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u533a\u5757\u94fe\u4ef7\u683c\u9884\u8a00\u673a\u7b49\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u534f\u8bae\uff0c\u80fd\u5728\u4efb\u610f\u7cfb\u7edf\u914d\u7f6e\u4e0b\u5efa\u7acb\u5e76\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u5bb9\u5fcd\u62dc\u5360\u5ead\u8282\u70b9\u548c\u77ac\u65f6\u6545\u969c\u3002", "result": "\u534f\u8bae\u5728\u5bb9\u5fcd\u6700\u591a1/3\u62dc\u5360\u5ead\u8282\u70b9\u548c1/6\u6076\u610f\u77ac\u65f6\u6545\u969c\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u534f\u8bae\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u5bb9\u9519\u7684\u91cd\u590d\u62dc\u5360\u5ead\u5171\u8bc6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12760", "pdf": "https://arxiv.org/pdf/2506.12760", "abs": "https://arxiv.org/abs/2506.12760", "authors": ["Lantian Li", "Yejian Liang", "Zhongxing Yu"], "title": "IDOL: Improved Different Optimization Levels Testing for Solidity Compilers", "categories": ["cs.SE"], "comment": "Accepted by QRS 2025 (Fast Abstracts track)", "summary": "As blockchain technology continues to evolve and mature, smart contracts have\nbecome a key driving force behind the digitization and automation of\ntransactions. Smart contracts greatly simplify and refine the traditional\nbusiness transaction processes, and thus have had a profound impact on various\nindustries such as finance and supply chain management. However, because smart\ncontracts cannot be modified once deployed, any vulnerabilities or design flaws\nwithin the contract cannot be easily fixed, potentially leading to significant\nfinancial losses or even legal issues. The compiler, as a critical component in\nthe development process, directly affects the quality and security of smart\ncontracts. This paper innovatively proposes a method, known as the Improved\nDifferent Optimization Levels (IDOL), for testing the Solidity compiler. The\nkey idea behind IDOL is to perform reverse optimization transformations (i.e.,\nchange optimized form into unoptimized form) to generate semantically\nequivalent variants of the smart contracts under test, aiming to maximize the\nopportunities to trigger the optimization logic of compilers. We conducted a\npreliminary evaluation of IDOL and three confirmed compiler optimization bugs\nhave been uncovered at the time of writing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIDOL\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5Solidity\u7f16\u8bd1\u5668\uff0c\u901a\u8fc7\u53cd\u5411\u4f18\u5316\u8f6c\u6362\u751f\u6210\u8bed\u4e49\u7b49\u6548\u7684\u667a\u80fd\u5408\u7ea6\u53d8\u4f53\uff0c\u4ee5\u89e6\u53d1\u7f16\u8bd1\u5668\u4f18\u5316\u903b\u8f91\uff0c\u5e76\u5df2\u53d1\u73b03\u4e2a\u7f16\u8bd1\u5668\u4f18\u5316\u6f0f\u6d1e\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u4e00\u65e6\u90e8\u7f72\u4fbf\u65e0\u6cd5\u4fee\u6539\uff0c\u5176\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u91cd\u5927\u8d22\u52a1\u6216\u6cd5\u5f8b\u95ee\u9898\uff0c\u800c\u7f16\u8bd1\u5668\u76f4\u63a5\u5f71\u54cd\u667a\u80fd\u5408\u7ea6\u7684\u8d28\u91cf\u548c\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51faIDOL\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cd\u5411\u4f18\u5316\u8f6c\u6362\u751f\u6210\u8bed\u4e49\u7b49\u6548\u7684\u667a\u80fd\u5408\u7ea6\u53d8\u4f53\uff0c\u4ee5\u6d4b\u8bd5\u7f16\u8bd1\u5668\u4f18\u5316\u903b\u8f91\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u4e2d\uff0c\u53d1\u73b0\u4e863\u4e2a\u7f16\u8bd1\u5668\u4f18\u5316\u6f0f\u6d1e\u3002", "conclusion": "IDOL\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4bSolidity\u7f16\u8bd1\u5668\u4e2d\u7684\u4f18\u5316\u6f0f\u6d1e\uff0c\u63d0\u5347\u667a\u80fd\u5408\u7ea6\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2506.13287", "pdf": "https://arxiv.org/pdf/2506.13287", "abs": "https://arxiv.org/abs/2506.13287", "authors": ["Kamran Shafafi", "Alaa Awad Abdellatif", "Manuel Ricardo", "Rui Campos"], "title": "Joint Optimization of Multi-UAV Deployment and 3D Positioning in Traffic-Aware Aerial Networks", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Unmanned Aerial Vehicles (UAVs) have emerged as a key enabler for\nnext-generation wireless networks due to their on-demand deployment, high\nmobility, and ability to provide Line-of-Sight (LoS) connectivity. These\nfeatures make UAVs particularly well-suited for dynamic and mission-critical\napplications such as intelligent transportation systems and emergency\ncommunications. However, effectively positioning multiple UAVs in real-time to\nmeet non-uniform, time-varying traffic demands remains a significant challenge,\nespecially when aiming to optimize network throughput and resource utilization.\nIn this paper, we propose an Efficient Multi-UAV Traffic-Aware Deployment\n(EMTAD) Algorithm, a scalable and adaptive framework that dynamically adjusts\nUAV placements based on real-time user locations and spatial traffic\ndistribution. In contrast to existing methods, EMTAD jointly optimizes UAV\npositioning and minimizes the number of deployed UAVs, ensuring efficient\nUE-UAV association while satisfying the traffic demand of users. Simulation\nresults demonstrate that EMTAD significantly improves network performance while\nreducing deployment overhead by minimizing the number of UAVs required in\ndynamic and traffic-aware environments.", "AI": {"tldr": "\u65e0\u4eba\u673a\uff08UAV\uff09\u56e0\u5176\u7075\u6d3b\u90e8\u7f72\u548c\u9ad8\u673a\u52a8\u6027\u6210\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5b9e\u65f6\u4f18\u5316\u591a\u65e0\u4eba\u673a\u90e8\u7f72\u4ecd\u5177\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u7684EMTAD\u7b97\u6cd5\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u65e0\u4eba\u673a\u4f4d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f51\u7edc\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u65e0\u4eba\u673a\u6570\u91cf\u3002", "motivation": "\u65e0\u4eba\u673a\u56e0\u5176\u6309\u9700\u90e8\u7f72\u3001\u9ad8\u673a\u52a8\u6027\u548c\u89c6\u8ddd\u8fde\u63a5\u80fd\u529b\uff0c\u6210\u4e3a\u52a8\u6001\u548c\u5173\u952e\u4efb\u52a1\u5e94\u7528\u7684\u7406\u60f3\u9009\u62e9\uff0c\u4f46\u5b9e\u65f6\u9002\u5e94\u975e\u5747\u5300\u3001\u65f6\u53d8\u6d41\u91cf\u9700\u6c42\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684EMTAD\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u65e0\u4eba\u673a\u4f4d\u7f6e\u548c\u6700\u5c0f\u5316\u90e8\u7f72\u6570\u91cf\uff0c\u4f18\u5316\u7f51\u7edc\u541e\u5410\u91cf\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u52a8\u6001\u548c\u6d41\u91cf\u611f\u77e5\u73af\u5883\u4e2d\uff0cEMTAD\u663e\u8457\u63d0\u9ad8\u4e86\u7f51\u7edc\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u6240\u9700\u65e0\u4eba\u673a\u7684\u6570\u91cf\u3002", "conclusion": "EMTAD\u7b97\u6cd5\u4e3a\u89e3\u51b3\u591a\u65e0\u4eba\u673a\u5b9e\u65f6\u90e8\u7f72\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12605", "pdf": "https://arxiv.org/pdf/2506.12605", "abs": "https://arxiv.org/abs/2506.12605", "authors": ["Yutong Zhang", "Dora Zhao", "Jeffrey T. Hancock", "Robert Kraut", "Diyi Yang"], "title": "The Rise of AI Companions: How Human-Chatbot Relationships Influence Well-Being", "categories": ["cs.HC"], "comment": null, "summary": "As large language models (LLMs)-enhanced chatbots grow increasingly\nexpressive and socially responsive, many users are beginning to form\ncompanionship-like bonds with them, particularly with simulated AI partners\ndesigned to mimic emotionally attuned interlocutors. These emerging AI\ncompanions raise critical questions: Can such systems fulfill social needs\ntypically met by human relationships? How do they shape psychological\nwell-being? And what new risks arise as users develop emotional ties to\nnon-human agents? This study investigates how people interact with AI\ncompanions, especially simulated partners on Character.AI, and how this use is\nassociated with users' psychological well-being. We analyzed survey data from\n1,131 users and 4,363 chat sessions (413,509 messages) donated by 244\nparticipants, focusing on three dimensions of use: nature of the interaction,\ninteraction intensity, and self-disclosure. By triangulating self-reports\nprimary motivation, open-ended relationship descriptions, and annotated chat\ntranscripts, we identify patterns in how users engage with AI companions and\nits associations with well-being. Findings suggest that people with smaller\nsocial networks are more likely to turn to chatbots for companionship, but that\ncompanionship-oriented chatbot usage is consistently associated with lower\nwell-being, particularly when people use the chatbots more intensively, engage\nin higher levels of self-disclosure, and lack strong human social support. Even\nthough some people turn to chatbots to fulfill social needs, these uses of\nchatbots do not fully substitute for human connection. As a result, the\npsychological benefits may be limited, and the relationship could pose risks\nfor more socially isolated or emotionally vulnerable users.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u6237\u4e0eAI\u4f34\u4fa3\uff08\u5982Character.AI\u4e0a\u7684\u6a21\u62df\u4f34\u4fa3\uff09\u7684\u4e92\u52a8\u5982\u4f55\u5f71\u54cd\u5176\u5fc3\u7406\u5065\u5eb7\uff0c\u53d1\u73b0\u793e\u4ea4\u5708\u8f83\u5c0f\u7684\u4eba\u66f4\u503e\u5411\u4e8e\u4f7f\u7528\u804a\u5929\u673a\u5668\u4eba\uff0c\u4f46\u8fd9\u79cd\u4e92\u52a8\u4e0e\u8f83\u4f4e\u7684\u5fc3\u7406\u5065\u5eb7\u6c34\u5e73\u76f8\u5173\uff0c\u5c24\u5176\u662f\u5f53\u7528\u6237\u8fc7\u5ea6\u4f9d\u8d56\u6216\u7f3a\u4e4f\u4eba\u7c7b\u793e\u4ea4\u652f\u6301\u65f6\u3002", "motivation": "\u968f\u7740LLM\u589e\u5f3a\u7684\u804a\u5929\u673a\u5668\u4eba\u53d8\u5f97\u66f4\u5177\u8868\u73b0\u529b\u548c\u793e\u4ea4\u6027\uff0c\u7528\u6237\u5f00\u59cb\u4e0e\u5b83\u4eec\u5efa\u7acb\u7c7b\u4f3c\u4f34\u4fa3\u7684\u5173\u7cfb\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9AI\u4f34\u4fa3\u662f\u5426\u80fd\u6ee1\u8db3\u4eba\u7c7b\u793e\u4ea4\u9700\u6c42\u53ca\u5176\u5bf9\u5fc3\u7406\u5065\u5eb7\u5f71\u54cd\u7684\u7591\u95ee\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5206\u67901,131\u540d\u7528\u6237\u7684\u8c03\u67e5\u6570\u636e\u548c244\u540d\u53c2\u4e0e\u8005\u6350\u8d60\u76844,363\u6b21\u804a\u5929\u4f1a\u8bdd\uff08413,509\u6761\u6d88\u606f\uff09\uff0c\u4ece\u4e92\u52a8\u6027\u8d28\u3001\u5f3a\u5ea6\u548c\u81ea\u6211\u62ab\u9732\u4e09\u4e2a\u7ef4\u5ea6\u63a2\u8ba8\u7528\u6237\u884c\u4e3a\u4e0e\u5fc3\u7406\u5065\u5eb7\u7684\u5173\u7cfb\u3002", "result": "\u793e\u4ea4\u5708\u8f83\u5c0f\u7684\u7528\u6237\u66f4\u53ef\u80fd\u4f9d\u8d56AI\u4f34\u4fa3\uff0c\u4f46\u8fd9\u79cd\u4f9d\u8d56\u4e0e\u8f83\u4f4e\u7684\u5fc3\u7406\u5065\u5eb7\u6c34\u5e73\u76f8\u5173\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u5f3a\u5ea6\u4f7f\u7528\u3001\u9ad8\u5ea6\u81ea\u6211\u62ab\u9732\u548c\u7f3a\u4e4f\u4eba\u7c7b\u793e\u4ea4\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "AI\u4f34\u4fa3\u672a\u80fd\u5b8c\u5168\u66ff\u4ee3\u4eba\u7c7b\u793e\u4ea4\u8054\u7cfb\uff0c\u53ef\u80fd\u5bf9\u793e\u4ea4\u5b64\u7acb\u6216\u60c5\u611f\u8106\u5f31\u7684\u7528\u6237\u6784\u6210\u98ce\u9669\uff0c\u5176\u5fc3\u7406\u76ca\u5904\u6709\u9650\u3002"}}
{"id": "2506.12959", "pdf": "https://arxiv.org/pdf/2506.12959", "abs": "https://arxiv.org/abs/2506.12959", "authors": ["Kenneth Odoh"], "title": "Distributed Computing From First Principles", "categories": ["cs.DC", "cs.DS", "cs.SE"], "comment": null, "summary": "This book on Distributed Computing aims to benefit a diverse audience,\nranging from aspiring engineers, and seasoned researchers, to a wide range of\nprofessionals. Driven by my passion for making the core concepts of distributed\ncomputing accessible, this work is a significant undertaking designed to\nempower individuals from all backgrounds to gain valuable insight. Have you\never wondered how a typical distributed system works under the hood? Are you\nlooking for a pedagogical guide with complete implementations? In this work, we\nhave implemented several foundational algorithms in Distributed Computing.\nWhether your expertise lies in the theoretical foundations or the practical\napplications of the principles of Distributed Systems, this book is for you.", "AI": {"tldr": "\u672c\u4e66\u65e8\u5728\u4e3a\u5404\u7c7b\u8bfb\u8005\u63d0\u4f9b\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684\u6838\u5fc3\u6982\u5ff5\u548c\u5b9e\u73b0\uff0c\u9002\u5408\u5de5\u7a0b\u5e08\u3001\u7814\u7a76\u4eba\u5458\u548c\u4e13\u4e1a\u4eba\u58eb\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u672c\u4e66\u4f7f\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684\u6838\u5fc3\u6982\u5ff5\u66f4\u6613\u7406\u89e3\uff0c\u5e2e\u52a9\u4e0d\u540c\u80cc\u666f\u7684\u8bfb\u8005\u638c\u63e1\u76f8\u5173\u77e5\u8bc6\u548c\u6280\u80fd\u3002", "method": "\u4e66\u4e2d\u5b9e\u73b0\u4e86\u591a\u4e2a\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684\u57fa\u7840\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684\u5b9e\u73b0\u793a\u4f8b\u4f5c\u4e3a\u6559\u5b66\u6307\u5357\u3002", "result": "\u8bfb\u8005\u53ef\u4ee5\u901a\u8fc7\u672c\u4e66\u6df1\u5165\u7406\u89e3\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u5e94\u7528\u3002", "conclusion": "\u672c\u4e66\u662f\u7406\u8bba\u548c\u5b9e\u8df5\u5e76\u91cd\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u5b66\u4e60\u8d44\u6e90\uff0c\u9002\u5408\u5e7f\u6cdb\u8bfb\u8005\u7fa4\u4f53\u3002"}}
{"id": "2506.12858", "pdf": "https://arxiv.org/pdf/2506.12858", "abs": "https://arxiv.org/abs/2506.12858", "authors": ["Nick Battle", "Peter Gorm Larsen"], "title": "Towards Operation Proof Obligation Generation for VDM", "categories": ["cs.SE"], "comment": "Presented at the 23rd Overture workshop, June 2025\n  (arXiv:cs/2506.08680)", "summary": "All formalisms have the ability to ensure that their models are internally\nconsistent. Potential inconsistencies are generally highlighted by assertions\ncalled proof obligations, and the generation of these obligations is an\nimportant role of the tools that support the method. This capability has been\navailable for VDM tools for many years. However, support for obligation\ngeneration for explicit operation bodies has always been limited. This work\ndescribes the current state of work to address this, showing the capabilities\nso far and highlighting the work remaining.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5f62\u5f0f\u5316\u65b9\u6cd5\u5de5\u5177\u4e2d\u8bc1\u660e\u4e49\u52a1\u751f\u6210\u7684\u73b0\u72b6\uff0c\u5c24\u5176\u662f\u5bf9\u663e\u5f0f\u64cd\u4f5c\u4f53\u7684\u652f\u6301\u4e0d\u8db3\uff0c\u5e76\u5c55\u793a\u4e86\u5f53\u524d\u8fdb\u5c55\u548c\u672a\u6765\u5de5\u4f5c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f62\u5f0f\u5316\u65b9\u6cd5\u5de5\u5177\u5728\u751f\u6210\u663e\u5f0f\u64cd\u4f5c\u4f53\u7684\u8bc1\u660e\u4e49\u52a1\u65b9\u9762\u7684\u5c40\u9650\u3002", "method": "\u5206\u6790\u4e86\u73b0\u6709\u5de5\u5177\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5f53\u524d\u8fdb\u5c55\u3002", "result": "\u63d0\u51fa\u4e86\u5f53\u524d\u5de5\u5177\u7684\u80fd\u529b\u548c\u672a\u6765\u9700\u8981\u6539\u8fdb\u7684\u65b9\u5411\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u5de5\u4f5c\u4ee5\u5b8c\u5584\u663e\u5f0f\u64cd\u4f5c\u4f53\u7684\u8bc1\u660e\u4e49\u52a1\u751f\u6210\u80fd\u529b\u3002"}}
{"id": "2506.13626", "pdf": "https://arxiv.org/pdf/2506.13626", "abs": "https://arxiv.org/abs/2506.13626", "authors": ["Jinkun Zhang", "Yuezhou Liu", "Edmund Yeh"], "title": "Delay-optimal Congestion-aware Routing and Computation Offloading in Arbitrary Network", "categories": ["cs.NI"], "comment": "Submitted to IEEE/ACM Transactions on Networking", "summary": "Emerging edge computing paradigms enable heterogeneous devices to collaborate\non complex computation applications. However, for arbitrary heterogeneous edge\nnetworks, delay-optimal forwarding and computation offloading remains an open\nproblem. In this paper, we jointly optimize data/result routing and computation\nplacement in arbitrary networks with heterogeneous node capabilities, and\ncongestion-dependent nonlinear transmission and processing delay. Despite the\nnon-convexity of the formulated problem, based on analyzing the KKT condition,\nwe provide a set of sufficient optimality conditions that solve the problem\nglobally. To provide the insights for such global optimality, we show that the\nproposed non-convex problem is geodesic-convex with mild assumptions. We also\nshow that the proposed sufficient optimality condition leads to a lower\nhemicontinuous solution set, providing stability against user-input\nperturbation. We then extend the framework to incorporate utility-based\ncongestion control and fairness. A fully distributed algorithm is developed to\nconverge to the global optimum. Numerical results demonstrate significant\nimprovements over multiple baselines algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5f02\u6784\u8fb9\u7f18\u7f51\u7edc\u4e2d\u8054\u5408\u4f18\u5316\u6570\u636e\u4f20\u8f93\u3001\u7ed3\u679c\u8def\u7531\u548c\u8ba1\u7b97\u653e\u7f6e\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u975e\u51f8\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0f\u7b97\u6cd5\u5b9e\u73b0\u4e86\u5168\u5c40\u6700\u4f18\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784\u8fb9\u7f18\u7f51\u7edc\u4e2d\u5ef6\u8fdf\u6700\u4f18\u7684\u6570\u636e\u8f6c\u53d1\u548c\u8ba1\u7b97\u5378\u8f7d\u95ee\u9898\u3002", "method": "\u5206\u6790KKT\u6761\u4ef6\uff0c\u63d0\u51fa\u8db3\u591f\u7684\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u95ee\u9898\u5177\u6709\u6d4b\u5730\u51f8\u6027\u3002\u5f00\u53d1\u4e86\u5b8c\u5168\u5206\u5e03\u5f0f\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u7b97\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5168\u5c40\u4f18\u5316\u5f02\u6784\u7f51\u7edc\u4e2d\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5ef6\u8fdf\uff0c\u5177\u6709\u7a33\u5b9a\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.12739", "pdf": "https://arxiv.org/pdf/2506.12739", "abs": "https://arxiv.org/abs/2506.12739", "authors": ["Yashodip Dharmendra Jagtap"], "title": "Shelter Soul: Bridging Shelters and Adopters Through Technology", "categories": ["cs.HC", "cs.SE"], "comment": "14 Pages, 4 Table, 5 Figure", "summary": "Pet adoption processes often face inefficiencies, including limited\naccessibility, lack of real-time information, and mismatched expectations\nbetween shelters and adopters. To address these challenges, this study presents\nShelter Soul, a technology-based solution designed to streamline pet adoption\nthrough an integrated, web-based platform. Developed using the MERN stack and\nGraphQL, Shelter Soul is a prototype system built to improve pet matching\naccuracy, shelter management efficiency, and secure online donations. The\nsystem includes modules for intelligent pet matching, shelter administration,\ndonation processing, volunteer coordination, and analytics. Prototype testing\n(performance load tests, usability studies, and security assessments)\ndemonstrated that the system meets its design goals: it handled 500 concurrent\nusers with a 99.2% transaction success rate and an average response time of 250\nms, and usability feedback rated the interface highly (4.5/5). These results\nindicate Shelter Soul's potential as a practical solution to enhance animal\nshelter operations and adoption outcomes.", "AI": {"tldr": "Shelter Soul\u662f\u57fa\u65bcMERN\u5806\u758a\u548cGraphQL\u8a2d\u8a08\u7684\u539f\u578b\u7cfb\u7d71\uff0c\u65e8\u5728\u89e3\u6c7a\u6536\u5bb9\u6240\u5bf5\u7269\u9818\u990a\u6548\u7387\u4f4e\u4e0b\u554f\u984c\uff0c\u63d0\u4f9b\u667a\u80fd\u5339\u914d\u3001\u7ba1\u7406\u7b49\u529f\u80fd\uff0c\u6e2c\u8a66\u8868\u660e\u5176\u5be6\u7528\u6027\u548c\u6027\u80fd\u8868\u73fe\u512a\u79c0\u3002", "motivation": "\u6536\u5bb9\u6240\u5bf5\u7269\u9818\u990a\u904e\u7a0b\u4e2d\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u4fe1\u606f\u4e0d\u900f\u660e\u548c\u5339\u914d\u4e0d\u6e96\u78ba\u7b49\u554f\u984c\uff0c\u9700\u8981\u6280\u8853\u89e3\u6c7a\u65b9\u6848\u3002", "method": "\u4f7f\u7528MERN\u5806\u758a\u548cGraphQL\u958b\u767c\u96c6\u6210\u7db2\u7d61\u5e73\u53f0\uff0c\u5305\u542b\u667a\u80fd\u5339\u914d\u3001\u6536\u5bb9\u6240\u7ba1\u7406\u3001\u6350\u8d08\u8655\u7406\u7b49\u529f\u80fd\u3002", "result": "\u539f\u578b\u6e2c\u8a66\u986f\u793a\u7cfb\u7d71\u6027\u80fd\u5f37\u52c1\uff0c\u652f\u6301500\u4e26\u767c\u7528\u6236\uff0c\u4ea4\u6613\u6210\u529f\u738799.2%\uff0c\u754c\u9762\u8a55\u52064.5/5\u3002", "conclusion": "Shelter Soul\u80fd\u6709\u6548\u63d0\u5347\u6536\u5bb9\u6240\u904b\u71df\u6548\u7387\u548c\u5bf5\u7269\u9818\u990a\u6210\u679c\uff0c\u5177\u6709\u5be6\u969b\u61c9\u7528\u6f5b\u529b\u3002"}}
{"id": "2506.12600", "pdf": "https://arxiv.org/pdf/2506.12600", "abs": "https://arxiv.org/abs/2506.12600", "authors": ["Jie Pan", "Tianyi Wang", "Christian Claudel", "Jing Shi"], "title": "Trust-MARL: Trust-Based Multi-Agent Reinforcement Learning Framework for Cooperative On-Ramp Merging Control in Heterogeneous Traffic Flow", "categories": ["cs.MA", "cs.AI", "cs.ET", "cs.GT", "cs.RO"], "comment": "34 pages, 7 figures, 4 tables", "summary": "Intelligent transportation systems require connected and automated vehicles\n(CAVs) to conduct safe and efficient cooperation with human-driven vehicles\n(HVs) in complex real-world traffic environments. However, the inherent\nunpredictability of human behaviour, especially at bottlenecks such as highway\non-ramp merging areas, often disrupts traffic flow and compromises system\nperformance. To address the challenge of cooperative on-ramp merging in\nheterogeneous traffic environments, this study proposes a trust-based\nmulti-agent reinforcement learning (Trust-MARL) framework. At the macro level,\nTrust-MARL enhances global traffic efficiency by leveraging inter-agent trust\nto improve bottleneck throughput and mitigate traffic shockwave through\nemergent group-level coordination. At the micro level, a dynamic trust\nmechanism is designed to enable CAVs to adjust their cooperative strategies in\nresponse to real-time behaviors and historical interactions with both HVs and\nother CAVs. Furthermore, a trust-triggered game-theoretic decision-making\nmodule is integrated to guide each CAV in adapting its cooperation factor and\nexecuting context-aware lane-changing decisions under safety, comfort, and\nefficiency constraints. An extensive set of ablation studies and comparative\nexperiments validates the effectiveness of the proposed Trust-MARL approach,\ndemonstrating significant improvements in safety, efficiency, comfort, and\nadaptability across varying CAV penetration rates and traffic densities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u4efb\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08Trust-MARL\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u5f02\u6784\u4ea4\u901a\u73af\u5883\u4e2d\u9ad8\u901f\u516c\u8def\u531d\u9053\u5408\u5e76\u7684\u534f\u4f5c\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u3001\u6548\u7387\u548c\u8212\u9002\u6027\u3002", "motivation": "\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\u7684\u4e0d\u53ef\u9884\u6d4b\u6027\uff08\u5c24\u5176\u5728\u9ad8\u901f\u516c\u8def\u531d\u9053\u5408\u5e76\u533a\uff09\u4f1a\u7834\u574f\u4ea4\u901a\u6d41\u548c\u7cfb\u7edf\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5b9e\u73b0CAV\u4e0eHV\u7684\u5b89\u5168\u9ad8\u6548\u534f\u4f5c\u3002", "method": "\u91c7\u7528Trust-MARL\u6846\u67b6\uff0c\u5b8f\u89c2\u4e0a\u901a\u8fc7\u667a\u80fd\u4f53\u95f4\u4fe1\u4efb\u63d0\u5347\u5168\u5c40\u6548\u7387\uff0c\u5fae\u89c2\u4e0a\u8bbe\u8ba1\u52a8\u6001\u4fe1\u4efb\u673a\u5236\uff0c\u5e76\u7ed3\u5408\u4fe1\u4efb\u89e6\u53d1\u7684\u535a\u5f08\u8bba\u51b3\u7b56\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTrust-MARL\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u540cCAV\u6e17\u900f\u7387\u548c\u4ea4\u901a\u5bc6\u5ea6\u4e0b\u7684\u5b89\u5168\u3001\u6548\u7387\u3001\u8212\u9002\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "Trust-MARL\u4e3a\u89e3\u51b3\u5f02\u6784\u4ea4\u901a\u73af\u5883\u4e2d\u7684\u534f\u4f5c\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2506.13497", "pdf": "https://arxiv.org/pdf/2506.13497", "abs": "https://arxiv.org/abs/2506.13497", "authors": ["Heyang Huang", "Cunchen Hu", "Jiaqi Zhu", "Ziyuan Gao", "Liangliang Xu", "Yizhou Shan", "Yungang Bao", "Sun Ninghui", "Tianwei Zhang", "Sa Wang"], "title": "DDiT: Dynamic Resource Allocation for Diffusion Transformer Model Serving", "categories": ["cs.DC"], "comment": null, "summary": "The Text-to-Video (T2V) model aims to generate dynamic and expressive videos\nfrom textual prompts. The generation pipeline typically involves multiple\nmodules, such as language encoder, Diffusion Transformer (DiT), and Variational\nAutoencoders (VAE). Existing serving systems often rely on monolithic model\ndeployment, while overlooking the distinct characteristics of each module,\nleading to inefficient GPU utilization. In addition, DiT exhibits varying\nperformance gains across different resolutions and degrees of parallelism, and\nsignificant optimization potential remains unexplored. To address these\nproblems, we present DDiT, a flexible system that integrates both inter-phase\nand intra-phase optimizations. DDiT focuses on two key metrics: optimal degree\nof parallelism, which prevents excessive parallelism for specific resolutions,\nand starvation time, which quantifies the sacrifice of each request. To this\nend, DDiT introduces a decoupled control mechanism to minimize the\ncomputational inefficiency caused by imbalances in the degree of parallelism\nbetween the DiT and VAE phases. It also designs a greedy resource allocation\nalgorithm with a novel scheduling mechanism that operates at the single-step\ngranularity, enabling dynamic and timely resource scaling. Our evaluation on\nthe T5 encoder, OpenSora SDDiT, and OpenSora VAE models across diverse datasets\nreveals that DDiT significantly outperforms state-of-the-art baselines by up to\n1.44x in p99 latency and 1.43x in average latency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDDiT\u7684\u7075\u6d3b\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u5e76\u884c\u5ea6\u548c\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86Text-to-Video (T2V)\u6a21\u578b\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709T2V\u6a21\u578b\u7684\u90e8\u7f72\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u6a21\u5757\u7279\u6027\uff0c\u4e14DiT\u5728\u4e0d\u540c\u5206\u8fa8\u7387\u548c\u5e76\u884c\u5ea6\u4e0b\u8868\u73b0\u4e0d\u4e00\uff0c\u4f18\u5316\u6f5c\u529b\u672a\u88ab\u53d1\u6398\u3002", "method": "DDiT\u96c6\u6210\u4e86\u9636\u6bb5\u95f4\u548c\u9636\u6bb5\u5185\u4f18\u5316\uff0c\u901a\u8fc7\u89e3\u8026\u63a7\u5236\u673a\u5236\u548c\u8d2a\u5a6a\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\uff0c\u52a8\u6001\u8c03\u6574\u8d44\u6e90\u914d\u7f6e\u3002", "result": "\u5728T5\u7f16\u7801\u5668\u3001OpenSora SDDiT\u548cOpenSora VAE\u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cDDiT\u5728p99\u5ef6\u8fdf\u548c\u5e73\u5747\u5ef6\u8fdf\u4e0a\u5206\u522b\u63d0\u53471.44\u500d\u548c1.43\u500d\u3002", "conclusion": "DDiT\u901a\u8fc7\u7cbe\u7ec6\u5316\u7684\u4f18\u5316\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86T2V\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.13114", "pdf": "https://arxiv.org/pdf/2506.13114", "abs": "https://arxiv.org/abs/2506.13114", "authors": ["Yanzhou Mu", "Rong Wang", "Juan Zhai", "Chunrong Fang", "Xiang Chen", "Jiacong Wu", "An Guo", "Jiawei Shen", "Bingzhuo Li", "Zhenyu Chen"], "title": "Designing Deep Learning Frameworks for LLMs:Challenges, Expectations, and Opportunities", "categories": ["cs.SE"], "comment": "12 pages, 2 figures", "summary": "Large language models (LLMs) drive significant advancements in real industry\napplications. LLMs rely on DL frameworks for efficient model construction,\ndistributed execution, and optimized deployment. Their large parameter scale\nand long execution cycles place extreme demands on DL frameworks in terms of\nscalability, stability, and efficiency. Therefore, poor usability, limited\nfunctionality, and subtle bugs in DL frameworks may hinder development\nefficiency and cause severe failures or resource waste. However, a fundamental\nquestion remains underinvestigated, i.e., What challenges do DL frameworks face\nin supporting LLMs? To seek an answer, we investigate these challenges through\na large-scale analysis of issue reports from three major DL frameworks\n(MindSpore, PyTorch, TensorFlow) and eight associated LLM toolkits (e.g.,\nMegatron). We construct a taxonomy of LLM-centric bugs, requirements, and user\nquestions and enrich it through interviews with 11 LLM users and eight DL\nframework developers, uncovering key technical challenges and misalignments\nbetween user needs and developer priorities. Our contributions are threefold:\n(1) we develop a comprehensive taxonomy comprising four question themes (nine\nsub-themes), four requirement themes (15 sub-themes), and ten bug themes (45\nsub-themes); (2) we assess the perceived importance and priority of these\nchallenges based on practitioner insights; and (3) we identify five key\nfindings across the LLM development and propose five actionable recommendations\nto improve the reliability, usability, and testability of DL frameworks. Our\nresults highlight critical limitations in current DL frameworks and offer\nconcrete guidance for advancing their support for the next generation of LLM\nconstruction and applications.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5728\u652f\u6301\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5206\u6790\u95ee\u9898\u62a5\u544a\u548c\u8bbf\u8c08\u5f00\u53d1\u8005\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4f9d\u8d56\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4f46\u5176\u89c4\u6a21\u548c\u6267\u884c\u5468\u671f\u5bf9\u6846\u67b6\u7684\u7a33\u5b9a\u6027\u3001\u529f\u80fd\u548c\u8c03\u8bd5\u80fd\u529b\u63d0\u51fa\u4e86\u6781\u9ad8\u8981\u6c42\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u6311\u6218\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5bf9\u4e09\u5927\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u548c\u516b\u4e2a\u76f8\u5173\u5de5\u5177\u5305\u7684\u95ee\u9898\u62a5\u544a\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\uff0c\u5e76\u7ed3\u5408\u7528\u6237\u548c\u5f00\u53d1\u8005\u7684\u8bbf\u8c08\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u5305\u542b\u95ee\u9898\u3001\u9700\u6c42\u548c\u9519\u8bef\u7684\u8be6\u5c3d\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u901a\u8fc7\u5b9e\u8df5\u8005\u53cd\u9988\u8bc4\u4f30\u4e86\u5176\u91cd\u8981\u6027\uff0c\u6700\u7ec8\u7ed9\u51fa\u4e94\u9879\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u63d0\u5347\u5176\u53ef\u9760\u6027\u548c\u7528\u6237\u4f53\u9a8c\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\uff0c\u4ee5\u652f\u6301\u4e0b\u4e00\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u53d1\u4e0e\u5e94\u7528\u3002"}}
{"id": "2506.12160", "pdf": "https://arxiv.org/pdf/2506.12160", "abs": "https://arxiv.org/abs/2506.12160", "authors": ["Dan Sturm", "Marzieyh Rezaei", "Alana Dee", "Sajjad Moazeni"], "title": "C2PO: Coherent Co-packaged Optics using offset-QAM-16 for Beyond PAM-4 Optical I/O", "categories": ["eess.SY", "cs.NI", "cs.SY", "physics.app-ph"], "comment": null, "summary": "Co-packaged optics (CPO) has emerged as a promising solution for achieving\nthe ultra-high bandwidths, shoreline densities, and energy efficiencies\nrequired by future GPUs and network switches for AI. Microring modulators\n(MRMs) are well suited for transmitters due to their compact size, high energy\nefficiency, and natural compatibility with dense wavelength-division\nmultiplexing (DWDM). However, extending beyond the recently demonstrated 200\nGb/s will require more advanced modulation formats, such as higher-order\ncoherent modulation (e.g., QAM-16).\n  In this work, we show how microring resonators (MRMs) can be efficiently used\nto implement phase-constant amplitude modulators and form the building blocks\nof a transmitter for offset QAM-16, which has been shown to simplify\ncarrier-phase recovery relative to conventional QAM. We simulate and evaluate\nthe performance of our proposed MRM-based coherent CPO (C2PO) transmitters\nusing a foundry-provided commercial silicon photonics process, demonstrating an\ninput-normalized electric field amplitude contrast of 0.64 per dimension.\nThrough full link-level bit error rate modeling, we show that our design\nachieves 400 Gb/s using offset QAM-16 at a total optical laser power of 9.65\ndBm-comparable to that required by conventional QAM-16 MZI-based links, despite\nusing 10-100x less area. We further conduct a thermal simulation to assess the\ntransmitter's thermal stability at the MRM input optical power required to meet\na target BER at the desired data rates. Finally, as a proof of concept, we\ndemonstrate 25 Gb/s MRM-based offset QAM-4 modulation with a chip fabricated in\nthe GlobalFoundries 45 nm monolithic silicon photonics process.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fae\u73af\u8c03\u5236\u5668\uff08MRM\uff09\u7684\u76f8\u5e72\u5171\u5c01\u88c5\u5149\u5668\u4ef6\uff08C2PO\uff09\u53d1\u5c04\u5668\uff0c\u7528\u4e8e\u5b9e\u73b0\u9ad8\u9636\u8c03\u5236\u683c\u5f0f\uff0c\u5c55\u793a\u51fa\u9ad8\u5e26\u5bbd\u3001\u4f4e\u529f\u8017\u548c\u5c0f\u5c3a\u5bf8\u7684\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u7684\u5171\u5c01\u88c5\u5149\u5668\u4ef6\uff08CPO\uff09\u5728\u6ee1\u8db3\u672a\u6765GPU\u548c\u7f51\u7edc\u4ea4\u6362\u673a\u5bf9AI\u5e94\u7528\u7684\u9ad8\u5e26\u5bbd\u548c\u9ad8\u80fd\u6548\u9700\u6c42\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u5148\u8fdb\u7684\u8c03\u5236\u683c\u5f0f\u3002", "method": "\u5229\u7528\u5fae\u73af\u8c10\u632f\u5668\uff08MRMs\uff09\u5b9e\u73b0\u76f8\u4f4d\u6052\u5b9a\u5e45\u5ea6\u8c03\u5236\uff0c\u6784\u5efa\u53d1\u5c04\u5668\uff0c\u5e76\u901a\u8fc7\u5546\u4e1a\u7845\u5149\u5b50\u5de5\u827a\u8fdb\u884c\u4eff\u771f\u548c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u8bbe\u8ba1\u7684\u53d1\u5c04\u5668\u5b9e\u73b0\u4e86400 Gb/s\u7684\u4f20\u8f93\u901f\u7387\uff0c\u529f\u8017\u4e0e\u4f20\u7edfQAM-16\u8c03\u5236\u76f8\u5f53\uff0c\u4f46\u9762\u79ef\u51cf\u5c11\u4e8610-100\u500d\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8eMRM\u7684C2PO\u53d1\u5c04\u5668\u5728\u9ad8\u9636\u8c03\u5236\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u9ad8\u5e26\u5bbd\u548c\u80fd\u6548\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.12792", "pdf": "https://arxiv.org/pdf/2506.12792", "abs": "https://arxiv.org/abs/2506.12792", "authors": ["David Gr\u00fcning", "Julia Kamin"], "title": "Prosocial Design in Trust and Safety", "categories": ["cs.HC", "cs.CY", "cs.SI", "econ.GN", "q-fin.EC", "J.4; K.4.1"], "comment": "29 pages, no figures, to be published in \"T&S Past, Present, and\n  Future.\"", "summary": "This chapter presents an overview of Prosocial Design, an approach to\nplatform design and governance that recognizes design choices influence\nbehavior and that those choices can or should be made toward supporting healthy\ninteractions and other prosocial outcomes. The authors discuss several core\nprinciples of Prosocial Design and its relationship to Trust and Safety and\nother related fields. As a primary contribution, the chapter reviews relevant\nresearch to demonstrate how Prosocial Design can be an effective approach to\nreducing rule-breaking and other harmful behavior and how it can help to stem\nthe spread of harmful misinformation. Prosocial Design is a nascent and\nevolving field and research is still limited. The authors hope this chapter\nwill not only inspire more research and the adoption of a prosocial design\napproach, but that it will also provoke discussion about the principles of\nProsocial Design and its potential to support Trust and Safety.", "AI": {"tldr": "\u672c\u7ae0\u4ecb\u7ecd\u4e86\u2018\u4eb2\u793e\u4f1a\u8bbe\u8ba1\u2019\u7684\u6982\u8ff0\uff0c\u8fd9\u662f\u4e00\u79cd\u5e73\u53f0\u8bbe\u8ba1\u548c\u6cbb\u7406\u65b9\u6cd5\uff0c\u5f3a\u8c03\u8bbe\u8ba1\u9009\u62e9\u5bf9\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u5021\u5bfc\u5229\u7528\u8fd9\u4e9b\u9009\u62e9\u4fc3\u8fdb\u5065\u5eb7\u4e92\u52a8\u548c\u5176\u4ed6\u4eb2\u793e\u4f1a\u7ed3\u679c\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u8bbe\u8ba1\u9009\u62e9\u548c\u6cbb\u7406\u652f\u6301\u5065\u5eb7\u4e92\u52a8\u548c\u51cf\u5c11\u6709\u5bb3\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u8fdd\u89c4\u884c\u4e3a\u548c\u865a\u5047\u4fe1\u606f\u65b9\u9762\u3002", "method": "\u8ba8\u8bba\u4e86\u4eb2\u793e\u4f1a\u8bbe\u8ba1\u7684\u6838\u5fc3\u539f\u5219\u53ca\u5176\u4e0e\u4fe1\u4efb\u4e0e\u5b89\u5168\u7b49\u76f8\u5173\u9886\u57df\u7684\u5173\u7cfb\uff0c\u5e76\u56de\u987e\u4e86\u76f8\u5173\u7814\u7a76\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4eb2\u793e\u4f1a\u8bbe\u8ba1\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u8fdd\u89c4\u884c\u4e3a\u548c\u865a\u5047\u4fe1\u606f\u7684\u4f20\u64ad\u3002", "conclusion": "\u4eb2\u793e\u4f1a\u8bbe\u8ba1\u662f\u4e00\u4e2a\u65b0\u5174\u4e14\u4e0d\u65ad\u53d1\u5c55\u7684\u9886\u57df\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u672c\u7ae0\u6fc0\u53d1\u66f4\u591a\u7814\u7a76\u548c\u8ba8\u8bba\uff0c\u63a8\u52a8\u8be5\u8bbe\u8ba1\u7684\u5e94\u7528\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2506.13720", "pdf": "https://arxiv.org/pdf/2506.13720", "abs": "https://arxiv.org/abs/2506.13720", "authors": ["Pengyu Liu", "Jatin Arora", "Mingkuan Xu", "Umut A. Acar"], "title": "POPQC: Parallel Optimization for Quantum Circuits (Extended Version)", "categories": ["cs.DC", "quant-ph"], "comment": "SPAA25", "summary": "Optimization of quantum programs or circuits is a fundamental problem in\nquantum computing and remains a major challenge. State-of-the-art quantum\ncircuit optimizers rely on heuristics and typically require superlinear, and\neven exponential, time. Recent work proposed a new approach that pursues a\nweaker form of optimality called local optimality. Parameterized by a natural\nnumber $\\Omega$, local optimality insists that each and every $\\Omega$-segment\nof the circuit is optimal with respect to an external optimizer, called the\noracle. Local optimization can be performed using only a linear number of calls\nto the oracle but still incurs quadratic computational overheads in addition to\noracle calls. Perhaps most importantly, the algorithm is sequential.\n  In this paper, we present a parallel algorithm for local optimization of\nquantum circuits. To ensure efficiency, the algorithm operates by keeping a set\nof fingers into the circuit and maintains the invariant that a $\\Omega$-deep\ncircuit needs to be optimized only if it contains a finger. Operating in\nrounds, the algorithm selects a set of fingers, optimizes in parallel the\nsegments containing the fingers, and updates the finger set to ensure the\ninvariant. For constant $\\Omega$, we prove that the algorithm requires\n$O(n\\lg{n})$ work and $O(r\\lg{n})$ span, where $n$ is the circuit size and $r$\nis the number of rounds. We prove that the optimized circuit returned by the\nalgorithm is locally optimal in the sense that any $\\Omega$-segment of the\ncircuit is optimal with respect to the oracle.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u884c\u7b97\u6cd5\uff0c\u7528\u4e8e\u91cf\u5b50\u7535\u8def\u7684\u5c40\u90e8\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4f18\u5316\u5668\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u5e8f\u5217\u5316\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u9ad8\u6548\u6027\u548c\u6700\u4f18\u6027\u3002", "motivation": "\u91cf\u5b50\u7535\u8def\u4f18\u5316\u662f\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\u3002\u901a\u8fc7\u5c40\u90e8\u4f18\u5316\u548c\u5e76\u884c\u5316\uff0c\u53ef\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u884c\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ef4\u62a4\u4e00\u7ec4\u6307\u9488\u5e76\u5728\u591a\u8f6e\u64cd\u4f5c\u4e2d\u5e76\u884c\u4f18\u5316\u542b\u6307\u9488\u7684\u7535\u8def\u6bb5\uff0c\u786e\u4fdd\u5c40\u90e8\u6700\u4f18\u6027\u3002", "result": "\u8bc1\u660e\u7b97\u6cd5\u5bf9\u5e38\u6570\u03a9\u5177\u6709O(n lg n)\u5de5\u4f5c\u91cf\u548cO(r lg n)\u8de8\u5ea6\uff0c\u4f18\u5316\u540e\u7684\u7535\u8def\u7b26\u5408\u5c40\u90e8\u6700\u4f18\u6027\u3002", "conclusion": "\u8be5\u5e76\u884c\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u91cf\u5b50\u7535\u8def\u5c40\u90e8\u4f18\u5316\u7684\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u3002"}}
{"id": "2506.13171", "pdf": "https://arxiv.org/pdf/2506.13171", "abs": "https://arxiv.org/abs/2506.13171", "authors": ["Lukasz Mazur", "Nenad Petrovic", "James Pontes Miranda", "Ansgar Radermacher", "Robert Rasche", "Alois Knoll"], "title": "Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) offer new opportunities for interacting with\ncomplex software artifacts, such as software models, through natural language.\nThey present especially promising benefits for large software models that are\ndifficult to grasp in their entirety, making traditional interaction and\nanalysis approaches challenging. This paper investigates two approaches for\nleveraging LLMs to answer questions over software models: direct prompting,\nwhere the whole software model is provided in the context, and an agentic\napproach combining LLM-based agents with general-purpose file access tools. We\nevaluate these approaches using an Ecore metamodel designed for timing analysis\nand software optimization in automotive and embedded domains. Our findings show\nthat while the agentic approach achieves accuracy comparable to direct\nprompting, it is significantly more efficient in terms of token usage. This\nefficiency makes the agentic approach particularly suitable for the automotive\nindustry, where the large size of software models makes direct prompting\ninfeasible, establishing LLM agents as not just a practical alternative but the\nonly viable solution. Notably, the evaluation was conducted using small LLMs,\nwhich are more feasible to be executed locally - an essential advantage for\nmeeting strict requirements around privacy, intellectual property protection,\nand regulatory compliance. Future work will investigate software models in\ndiverse formats, explore more complex agent architectures, and extend agentic\nworkflows to support not only querying but also modification of software\nmodels.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u4e24\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u56de\u7b54\u8f6f\u4ef6\u6a21\u578b\u95ee\u9898\u7684\u65b9\u6cd5\uff1a\u76f4\u63a5\u63d0\u793a\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u4ee3\u7406\u65b9\u6cd5\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4ee4\u724c\u4f7f\u7528\uff0c\u66f4\u9002\u5408\u6c7d\u8f66\u884c\u4e1a\u7684\u5927\u578b\u6a21\u578b\u3002", "motivation": "\u5927\u578b\u8f6f\u4ef6\u6a21\u578b\u96be\u4ee5\u5b8c\u5168\u7406\u89e3\uff0c\u4f20\u7edf\u7684\u4ea4\u4e92\u548c\u5206\u6790\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff0cLLM\u4e3a\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e0e\u8f6f\u4ef6\u6a21\u578b\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "\u6bd4\u8f83\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u76f4\u63a5\u63d0\u793a\uff08\u5c06\u6574\u4e2a\u6a21\u578b\u653e\u5165\u4e0a\u4e0b\u6587\uff09\u548c\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u5de5\u5177\u8bbf\u95ee\u65b9\u6cd5\uff0c\u4f7f\u7528Ecore\u5143\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4ee3\u7406\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u4e0a\u4e0e\u76f4\u63a5\u63d0\u793a\u76f8\u5f53\uff0c\u4f46\u4ee4\u724c\u4f7f\u7528\u6548\u7387\u66f4\u9ad8\uff0c\u7279\u522b\u9002\u5408\u6c7d\u8f66\u884c\u4e1a\u7684\u5927\u578b\u6a21\u578b\u3002", "conclusion": "LLM\u4ee3\u7406\u662f\u5904\u7406\u5927\u578b\u8f6f\u4ef6\u6a21\u578b\u7684\u552f\u4e00\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u5c06\u63a2\u7d22\u66f4\u591a\u590d\u6742\u4ee3\u7406\u67b6\u6784\u548c\u6a21\u578b\u4fee\u6539\u529f\u80fd\u3002"}}
{"id": "2506.12195", "pdf": "https://arxiv.org/pdf/2506.12195", "abs": "https://arxiv.org/abs/2506.12195", "authors": ["Shakil Ahmed", "Muhammad Kamran Saeed", "Ashfaq Khokhar"], "title": "OSI Stack Redesign for Quantum Networks: Requirements, Technologies, Challenges, and Future Directions", "categories": ["quant-ph", "cs.CR", "cs.IT", "cs.LG", "cs.NI", "math.IT"], "comment": null, "summary": "Quantum communication is poised to become a foundational element of\nnext-generation networking, offering transformative capabilities in security,\nentanglement-based connectivity, and computational offloading. However, the\nclassical OSI model-designed for deterministic and error-tolerant\nsystems-cannot support quantum-specific phenomena such as coherence fragility,\nprobabilistic entanglement, and the no-cloning theorem. This paper provides a\ncomprehensive survey and proposes an architectural redesign of the OSI model\nfor quantum networks in the context of 7G. We introduce a Quantum-Converged OSI\nstack by extending the classical model with Layer 0 (Quantum Substrate) and\nLayer 8 (Cognitive Intent), supporting entanglement, teleportation, and\nsemantic orchestration via LLMs and QML. Each layer is redefined to incorporate\nquantum mechanisms such as enhanced MAC protocols, fidelity-aware routing, and\ntwin-based applications. This survey consolidates over 150 research works from\nIEEE, ACM, MDPI, arXiv, and Web of Science (2018-2025), classifying them by OSI\nlayer, enabling technologies such as QKD, QEC, PQC, and RIS, and use cases such\nas satellite QKD, UAV swarms, and quantum IoT. A taxonomy of cross-layer\nenablers-such as hybrid quantum-classical control, metadata-driven\norchestration, and blockchain-integrated quantum trust-is provided, along with\nsimulation tools including NetSquid, QuNetSim, and QuISP. We present several\ndomain-specific applications, including quantum healthcare telemetry, entangled\nvehicular networks, and satellite mesh overlays. An evaluation framework is\nproposed based on entropy throughput, coherence latency, and entanglement\nfidelity. Key future directions include programmable quantum stacks, digital\ntwins, and AI-defined QNet agents, laying the groundwork for a scalable,\nintelligent, and quantum-compliant OSI framework for 7G and beyond.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u91cf\u5b50\u7f51\u7edc\u7684OSI\u6a21\u578b\u91cd\u65b0\u8bbe\u8ba1\uff0c\u5f15\u5165\u4e86\u91cf\u5b50\u878d\u5408OSI\u6808\uff0c\u652f\u6301\u91cf\u5b50\u7279\u6027\u548c\u667a\u80fd\u7f16\u6392\uff0c\u4e3a7G\u7f51\u7edc\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u7ecf\u5178OSI\u6a21\u578b\u65e0\u6cd5\u652f\u6301\u91cf\u5b50\u901a\u4fe1\u7684\u7279\u6b8a\u73b0\u8c61\uff08\u5982\u76f8\u5e72\u6027\u8106\u5f31\u3001\u6982\u7387\u7ea0\u7f20\u548c\u4e0d\u53ef\u514b\u9686\u5b9a\u7406\uff09\uff0c\u56e0\u6b64\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u9002\u5408\u91cf\u5b50\u7f51\u7edc\u7684\u67b6\u6784\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u7ecf\u5178OSI\u6a21\u578b\uff0c\u5f15\u5165\u91cf\u5b50\u5c42\uff08Layer 0\uff09\u548c\u8ba4\u77e5\u610f\u56fe\u5c42\uff08Layer 8\uff09\uff0c\u5b9a\u4e49\u5404\u5c42\u7684\u91cf\u5b50\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u8de8\u5c42\u8d4b\u80fd\u6280\u672f\u548c\u4eff\u771f\u5de5\u5177\u3002", "result": "\u8bba\u6587\u7efc\u5408\u4e86150\u591a\u9879\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u71b5\u541e\u5410\u3001\u76f8\u5e72\u5ef6\u8fdf\u548c\u7ea0\u7f20\u4fdd\u771f\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u9886\u57df\u7279\u5b9a\u5e94\u7528\u3002", "conclusion": "\u8bba\u6587\u4e3a7G\u53ca\u672a\u6765\u7684\u91cf\u5b50\u7f51\u7edc\u63d0\u51fa\u4e86\u53ef\u6269\u5c55\u3001\u667a\u80fd\u4e14\u5408\u89c4\u7684OSI\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.12840", "pdf": "https://arxiv.org/pdf/2506.12840", "abs": "https://arxiv.org/abs/2506.12840", "authors": ["Renato Cordeiro Ferreira", "Renata Santos Miranda", "Alfredo Goldman"], "title": "The Journey of CodeLab: How University Hackathons Built a Community of Engaged Students", "categories": ["cs.HC", "cs.SE", "K.4.3; K.3.2; D.2.m"], "comment": "4 pages, 2 figures (1 collage with 12 pictures, 2 tables), published\n  at ICGJ24", "summary": "This paper presents the journey of CodeLab: a student-organized initiative\nfrom the University of S\\~ao Paulo that has grown thanks to university\nhackathons. It summarizes patterns, challenges, and lessons learned over 15\ncompetitions organized by the group from 2015 to 2020. By describing these\nexperiences, this report aims to help CodeLab to resume its events after the\nCOVID-19 pandemic, and foster similar initiatives around the world.", "AI": {"tldr": "\u603b\u7ed3\u4e86CodeLab\u81ea2015\u5e74\u81f32020\u5e74\u7ec4\u7ec7\u768415\u573a\u5927\u5b66\u9ed1\u5ba2\u9a6c\u62c9\u677e\u4e2d\u7684\u6a21\u5f0f\u3001\u6311\u6218\u4e0e\u7ecf\u9a8c\u6559\u8bad\uff0c\u65e8\u5728\u5e2e\u52a9\u5176\u6062\u590d\u75ab\u60c5\u540e\u6d3b\u52a8\u5e76\u63a8\u52a8\u5168\u7403\u7c7b\u4f3c\u9879\u76ee\u3002", "motivation": "\u8bb0\u5f55CodeLab\u7684\u7ecf\u9a8c\u4ee5\u5e2e\u52a9\u5176\u5728\u75ab\u60c5\u540e\u91cd\u542f\u6d3b\u52a8\uff0c\u5e76\u6fc0\u52b1\u5168\u7403\u8303\u56f4\u5185\u7684\u7c7b\u4f3c\u5b66\u751f\u7ec4\u7ec7\u3002", "method": "\u901a\u8fc7\u56de\u987e15\u573a\u7ade\u8d5b\u7684\u7ec4\u7ec7\u8fc7\u7a0b\uff0c\u603b\u7ed3\u6a21\u5f0f\u4e0e\u6311\u6218\u3002", "result": "\u63d0\u4f9b\u4e86\u5173\u4e8e\u7ec4\u7ec7\u5b66\u751f\u9ed1\u5ba2\u9a6c\u62c9\u677e\u7684\u5b9e\u7528\u7ecf\u9a8c\u4e0e\u6559\u8bad\u3002", "conclusion": "\u5e0c\u671b\u8fd9\u4e9b\u7ecf\u9a8c\u80fd\u5e2e\u52a9CodeLab\u672a\u6765\u6d3b\u52a8\u7684\u6062\u590d\uff0c\u5e76\u4fc3\u8fdb\u5168\u7403\u7c7b\u4f3c\u5b66\u751f\u9879\u76ee\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.13505", "pdf": "https://arxiv.org/pdf/2506.13505", "abs": "https://arxiv.org/abs/2506.13505", "authors": ["Vasiliki Balaska", "Ioannis Tsampikos Papapetros", "Katerina Maria Oikonomou", "Loukas Bampis", "Antonios Gasteratos"], "title": "UAV Object Detection and Positioning in a Mining Industrial Metaverse with Custom Geo-Referenced Data", "categories": ["eess.IV", "cs.AI", "cs.ET", "cs.RO"], "comment": null, "summary": "The mining sector increasingly adopts digital tools to improve operational\nefficiency, safety, and data-driven decision-making. One of the key challenges\nremains the reliable acquisition of high-resolution, geo-referenced spatial\ninformation to support core activities such as extraction planning and on-site\nmonitoring. This work presents an integrated system architecture that combines\nUAV-based sensing, LiDAR terrain modeling, and deep learning-based object\ndetection to generate spatially accurate information for open-pit mining\nenvironments. The proposed pipeline includes geo-referencing, 3D\nreconstruction, and object localization, enabling structured spatial outputs to\nbe integrated into an industrial digital twin platform. Unlike traditional\nstatic surveying methods, the system offers higher coverage and automation\npotential, with modular components suitable for deployment in real-world\nindustrial contexts. While the current implementation operates in post-flight\nbatch mode, it lays the foundation for real-time extensions. The system\ncontributes to the development of AI-enhanced remote sensing in mining by\ndemonstrating a scalable and field-validated geospatial data workflow that\nsupports situational awareness and infrastructure safety.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u65e0\u4eba\u673a\u4f20\u611f\u3001\u6fc0\u5149\u96f7\u8fbe\u5730\u5f62\u5efa\u6a21\u548c\u6df1\u5ea6\u5b66\u4e60\u5bf9\u8c61\u68c0\u6d4b\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u7528\u4e8e\u9732\u5929\u77ff\u73af\u5883\u7684\u9ad8\u5206\u8fa8\u7387\u7a7a\u95f4\u4fe1\u606f\u83b7\u53d6\uff0c\u652f\u6301\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\u3002", "motivation": "\u89e3\u51b3\u91c7\u77ff\u884c\u4e1a\u5728\u9ad8\u6548\u3001\u5b89\u5168\u83b7\u53d6\u9ad8\u5206\u8fa8\u7387\u5730\u7406\u7a7a\u95f4\u4fe1\u606f\u65b9\u9762\u7684\u6311\u6218\uff0c\u4ee5\u652f\u6301\u5f00\u91c7\u89c4\u5212\u548c\u73b0\u573a\u76d1\u63a7\u3002", "method": "\u96c6\u6210\u65e0\u4eba\u673a\u4f20\u611f\u3001LiDAR\u5730\u5f62\u5efa\u6a21\u548c\u6df1\u5ea6\u5b66\u4e60\u5bf9\u8c61\u68c0\u6d4b\uff0c\u901a\u8fc7\u5730\u7406\u53c2\u8003\u30013D\u91cd\u5efa\u548c\u5bf9\u8c61\u5b9a\u4f4d\u751f\u6210\u7ed3\u6784\u5316\u7a7a\u95f4\u6570\u636e\u3002", "result": "\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u8986\u76d6\u7387\u548c\u81ea\u52a8\u5316\u6f5c\u529b\uff0c\u5e76\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u7684\u5b9e\u5730\u9a8c\u8bc1\u5730\u7406\u6570\u636e\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91c7\u77ff\u884c\u4e1a\u7684AI\u589e\u5f3a\u9065\u611f\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u652f\u6301\u5b9e\u65f6\u6269\u5c55\u548c\u5de5\u4e1a\u5e94\u7528\u3002"}}
{"id": "2506.13730", "pdf": "https://arxiv.org/pdf/2506.13730", "abs": "https://arxiv.org/abs/2506.13730", "authors": ["Tain\u00e3 Coleman", "Hena Ahmed", "Ravi Shende", "Ismael Perez", "\u00cflkay Altinta\u015f"], "title": "BanditWare: A Contextual Bandit-based Framework for Hardware Prediction", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Distributed computing systems are essential for meeting the demands of modern\napplications, yet transitioning from single-system to distributed environments\npresents significant challenges. Misallocating resources in shared systems can\nlead to resource contention, system instability, degraded performance, priority\ninversion, inefficient utilization, increased latency, and environmental\nimpact.\n  We present BanditWare, an online recommendation system that dynamically\nselects the most suitable hardware for applications using a contextual\nmulti-armed bandit algorithm. BanditWare balances exploration and exploitation,\ngradually refining its hardware recommendations based on observed application\nperformance while continuing to explore potentially better options. Unlike\ntraditional statistical and machine learning approaches that rely heavily on\nlarge historical datasets, BanditWare operates online, learning and adapting in\nreal-time as new workloads arrive.\n  We evaluated BanditWare on three workflow applications: Cycles (an\nagricultural science scientific workflow) BurnPro3D (a web-based platform for\nfire science) and a matrix multiplication application. Designed for seamless\nintegration with the National Data Platform (NDP), BanditWare enables users of\nall experience levels to optimize resource allocation efficiently.", "AI": {"tldr": "BanditWare\u662f\u4e00\u4e2a\u5728\u7ebf\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u7684\u786c\u4ef6\u8d44\u6e90\u6765\u4f18\u5316\u5206\u5e03\u5f0f\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\uff0c\u89e3\u51b3\u4e86\u5355\u7cfb\u7edf\u5230\u5206\u5e03\u5f0f\u73af\u5883\u8fc7\u6e21\u4e2d\u7684\u8d44\u6e90\u51b2\u7a81\u548c\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u5206\u5e03\u5f0f\u8ba1\u7b97\u7cfb\u7edf\u5bf9\u73b0\u4ee3\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8d44\u6e90\u5206\u914d\u4e0d\u5f53\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3001\u7cfb\u7edf\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002BanditWare\u65e8\u5728\u901a\u8fc7\u5b9e\u65f6\u5b66\u4e60\u548c\u9002\u5e94\u65b0\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "method": "BanditWare\u4f7f\u7528\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\uff0c\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u7684\u786c\u4ef6\u8d44\u6e90\uff0c\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\uff0c\u9010\u6b65\u4f18\u5316\u63a8\u8350\u3002", "result": "\u5728\u4e09\u4e2a\u5de5\u4f5c\u6d41\u5e94\u7528\uff08Cycles\u3001BurnPro3D\u548c\u77e9\u9635\u4e58\u6cd5\u5e94\u7528\uff09\u4e2d\u8bc4\u4f30\uff0cBanditWare\u80fd\u591f\u9ad8\u6548\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u5e76\u652f\u6301\u65e0\u7f1d\u96c6\u6210\u5230\u56fd\u5bb6\u6570\u636e\u5e73\u53f0\uff08NDP\uff09\u3002", "conclusion": "BanditWare\u901a\u8fc7\u5b9e\u65f6\u5b66\u4e60\u548c\u9002\u5e94\uff0c\u4e3a\u5206\u5e03\u5f0f\u8ba1\u7b97\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8d44\u6e90\u5206\u914d\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u7684\u7528\u6237\u3002"}}
{"id": "2506.13182", "pdf": "https://arxiv.org/pdf/2506.13182", "abs": "https://arxiv.org/abs/2506.13182", "authors": ["Anh Ho", "Thanh Le-Cong", "Bach Le", "Christine Rizkallah"], "title": "From Empirical Evaluation to Context-Aware Enhancement: Repairing Regression Errors with LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "[...] Since then, various APR approaches, especially those leveraging the\npower of large language models (LLMs), have been rapidly developed to fix\ngeneral software bugs. Unfortunately, the effectiveness of these advanced\ntechniques in the context of regression bugs remains largely unexplored. This\ngap motivates the need for an empirical study evaluating the effectiveness of\nmodern APR techniques in fixing real-world regression bugs.\n  In this work, we conduct an empirical study of APR techniques on Java\nregression bugs. To facilitate our study, we introduce RegMiner4APR, a\nhigh-quality benchmark of Java regression bugs integrated into a framework\ndesigned to facilitate APR research. The current benchmark includes 99\nregression bugs collected from 32 widely used real-world Java GitHub\nrepositories. We begin by conducting an in-depth analysis of the benchmark,\ndemonstrating its diversity and quality. Building on this foundation, we\nempirically evaluate the capabilities of APR to regression bugs by assessing\nboth traditional APR tools and advanced LLM-based APR approaches. Our\nexperimental results show that classical APR tools fail to repair any bugs,\nwhile LLM-based APR approaches exhibit promising potential. Motivated by these\nresults, we investigate impact of incorporating bug-inducing change information\ninto LLM-based APR approaches for fixing regression bugs. Our results highlight\nthat this context-aware enhancement significantly improves the performance of\nLLM-based APR, yielding 1.8x more successful repairs compared to using\nLLM-based APR without such context.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u73b0\u4ee3\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u6280\u672f\u5728\u4fee\u590d\u56de\u5f52Bug\u4e2d\u7684\u6548\u679c\uff0c\u5e76\u5f15\u5165RegMiner4APR\u57fa\u51c6\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4f20\u7edfAPR\u5de5\u5177\u6548\u679c\u4e0d\u4f73\uff0c\u800c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684APR\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u7ed3\u5408Bug\u8bf1\u5bfc\u4fe1\u606f\u540e\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u56de\u5f52Bug\u4fee\u590d\u7684\u7814\u7a76\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u73b0\u4ee3APR\u6280\u672f\u7684\u6548\u679c\uff0c\u5c24\u5176\u662f\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6784\u5efaRegMiner4APR\u57fa\u51c6\uff0c\u5305\u542b99\u4e2aJava\u56de\u5f52Bug\uff0c\u8bc4\u4f30\u4f20\u7edfAPR\u5de5\u5177\u548cLLM-based APR\u7684\u6027\u80fd\uff0c\u5e76\u7814\u7a76\u7ed3\u5408Bug\u8bf1\u5bfc\u4fe1\u606f\u7684\u6548\u679c\u3002", "result": "\u4f20\u7edfAPR\u5de5\u5177\u65e0\u6cd5\u4fee\u590d\u4efb\u4f55Bug\uff0c\u800cLLM-based APR\u8868\u73b0\u826f\u597d\uff1b\u7ed3\u5408Bug\u8bf1\u5bfc\u4fe1\u606f\u540e\uff0c\u6210\u529f\u7387\u63d0\u9ad81.8\u500d\u3002", "conclusion": "LLM-based APR\u5728\u56de\u5f52Bug\u4fee\u590d\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u7ed3\u5408Bug\u8bf1\u5bfc\u4fe1\u606f\u53ef\u663e\u8457\u63d0\u5347\u5176\u6027\u80fd\u3002"}}
{"id": "2506.13261", "pdf": "https://arxiv.org/pdf/2506.13261", "abs": "https://arxiv.org/abs/2506.13261", "authors": ["Timo Salomon", "Mehmet Mueller", "Philipp Meyer", "Thomas C. Schmidt"], "title": "Building Automotive Security on Internet Standards: An Integration of DNSSEC, DANE, and DANCE to Authenticate and Authorize In-Car Services", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "The automotive industry is undergoing a software-as-a-service transformation\nthat enables software-defined functions and post-sale updates via cloud and\nvehicle-to-everything communication. Connectivity in cars introduces\nsignificant security challenges, as remote attacks on vehicles have become\nincreasingly prevalent. Current automotive designs call for security solutions\nthat address the entire lifetime of a vehicle. In this paper, we propose to\nauthenticate and authorize in-vehicle services by integrating DNSSEC, DANE, and\nDANCE with automotive middleware. Our approach decouples the cryptographic\nauthentication of the service from that of the service deployment with the help\nof DNSSEC and thereby largely simplifies key management. We propose to\nauthenticate in-vehicle services by certificates that are solely generated by\nthe service suppliers but published on deployment via DNSSEC TLSA records\nsolely signed by the OEM. Building on well-established Internet standards\nensures interoperability with various current and future protocols, scalable\nmanagement of credentials for millions of connected vehicles at\nwell-established security levels. We back our design proposal by a security\nanalysis using the STRIDE threat model and by evaluations in a realistic\nin-vehicle setup that demonstrate its effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u96c6\u6210DNSSEC\u3001DANE\u548cDANCE\u5230\u6c7d\u8f66\u4e2d\u95f4\u4ef6\u6765\u8ba4\u8bc1\u548c\u6388\u6743\u8f66\u8f7d\u670d\u52a1\u7684\u65b9\u6cd5\uff0c\u7b80\u5316\u4e86\u5bc6\u94a5\u7ba1\u7406\u5e76\u589e\u5f3a\u4e86\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u6c7d\u8f66\u884c\u4e1a\u5411\u8f6f\u4ef6\u5373\u670d\u52a1\u8f6c\u578b\uff0c\u8fdc\u7a0b\u653b\u51fb\u98ce\u9669\u589e\u52a0\uff0c\u9700\u8981\u8986\u76d6\u8f66\u8f86\u5168\u751f\u547d\u5468\u671f\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528DNSSEC\u5206\u79bb\u670d\u52a1\u7684\u52a0\u5bc6\u8ba4\u8bc1\u4e0e\u90e8\u7f72\u8ba4\u8bc1\uff0c\u670d\u52a1\u4f9b\u5e94\u5546\u751f\u6210\u8bc1\u4e66\u5e76\u7531OEM\u901a\u8fc7DNSSEC TLSA\u8bb0\u5f55\u7b7e\u540d\u53d1\u5e03\u3002", "result": "\u57fa\u4e8e\u6210\u719f\u4e92\u8054\u7f51\u6807\u51c6\u7684\u8bbe\u8ba1\u652f\u6301\u9ad8\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5b89\u5168\u5206\u6790\u548c\u5b9e\u9645\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8f66\u8f7d\u670d\u52a1\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u4e92\u64cd\u4f5c\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u6570\u767e\u4e07\u8054\u7f51\u8f66\u8f86\u3002"}}
{"id": "2506.12879", "pdf": "https://arxiv.org/pdf/2506.12879", "abs": "https://arxiv.org/abs/2506.12879", "authors": ["Frederic Gmeiner", "Kaitao Luo", "Ye Wang", "Kenneth Holstein", "Nikolas Martelaro"], "title": "Exploring the Potential of Metacognitive Support Agents for Human-AI Co-Creation", "categories": ["cs.HC", "cs.AI"], "comment": "26 pages, to be published in the proceedings of the Designing\n  Interactive Systems Conference (DIS'25)", "summary": "Despite the potential of generative AI (GenAI) design tools to enhance design\nprocesses, professionals often struggle to integrate AI into their workflows.\nFundamental cognitive challenges include the need to specify all design\ncriteria as distinct parameters upfront (intent formulation) and designers'\nreduced cognitive involvement in the design process due to cognitive\noffloading, which can lead to insufficient problem exploration,\nunderspecification, and limited ability to evaluate outcomes. Motivated by\nthese challenges, we envision novel metacognitive support agents that assist\ndesigners in working more reflectively with GenAI. To explore this vision, we\nconducted exploratory prototyping through a Wizard of Oz elicitation study with\n20 mechanical designers probing multiple metacognitive support strategies. We\nfound that agent-supported users created more feasible designs than\nnon-supported users, with differing impacts between support strategies. Based\non these findings, we discuss opportunities and tradeoffs of metacognitive\nsupport agents and considerations for future AI-based design tools.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u8bbe\u8ba1\u5de5\u5177\u5728\u4e13\u4e1a\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u7684\u6574\u5408\u96be\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u5143\u8ba4\u77e5\u652f\u6301\u4ee3\u7406\u63d0\u5347\u8bbe\u8ba1\u5e08\u7684\u53cd\u601d\u80fd\u529b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u79cd\u652f\u6301\u80fd\u63d0\u9ad8\u8bbe\u8ba1\u53ef\u884c\u6027\u3002", "motivation": "\u8bbe\u8ba1\u5e08\u5728\u4f7f\u7528\u751f\u6210\u5f0fAI\u5de5\u5177\u65f6\u5e38\u9762\u4e34\u8ba4\u77e5\u6311\u6218\uff0c\u5982\u610f\u56fe\u8868\u8fbe\u7684\u5c40\u9650\u6027\u548c\u8ba4\u77e5\u5378\u8f7d\u5bfc\u81f4\u7684\u53c2\u4e0e\u5ea6\u964d\u4f4e\uff0c\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u8bbe\u8ba1\u8d28\u91cf\u548c\u95ee\u9898\u63a2\u7d22\u3002", "method": "\u901a\u8fc7Wizard of Oz\u7814\u7a76\uff0c\u5bf920\u4f4d\u673a\u68b0\u8bbe\u8ba1\u5e08\u8fdb\u884c\u63a2\u7d22\u6027\u539f\u578b\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e0d\u540c\u5143\u8ba4\u77e5\u652f\u6301\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6709\u5143\u8ba4\u77e5\u652f\u6301\u4ee3\u7406\u534f\u52a9\u7684\u8bbe\u8ba1\u5e08\u80fd\u521b\u4f5c\u51fa\u66f4\u53ef\u884c\u7684\u8bbe\u8ba1\uff0c\u4e14\u4e0d\u540c\u652f\u6301\u7b56\u7565\u6548\u679c\u5404\u5f02\u3002", "conclusion": "\u8bba\u6587\u8ba8\u8bba\u4e86\u5143\u8ba4\u77e5\u652f\u6301\u4ee3\u7406\u7684\u6f5c\u529b\u4e0e\u6743\u8861\uff0c\u4e3a\u672a\u6765AI\u8bbe\u8ba1\u5de5\u5177\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u601d\u8003\u65b9\u5411\u3002"}}
{"id": "2506.13538", "pdf": "https://arxiv.org/pdf/2506.13538", "abs": "https://arxiv.org/abs/2506.13538", "authors": ["Mohammed Mehedi Hasan", "Hao Li", "Emad Fallahzadeh", "Bram Adams", "Ahmed E. Hassan"], "title": "Model Context Protocol (MCP) at First Glance: Studying the Security and Maintainability of MCP Servers", "categories": ["cs.SE", "cs.ET"], "comment": null, "summary": "Although Foundation Models (FMs), such as GPT-4, are increasingly used in\ndomains like finance and software engineering, reliance on textual interfaces\nlimits these models' real-world interaction. To address this, FM providers\nintroduced tool calling-triggering a proliferation of frameworks with distinct\ntool interfaces. In late 2024, Anthropic introduced the Model Context Protocol\n(MCP) to standardize this tool ecosystem, which has become the de facto\nstandard with over eight million weekly SDK downloads. Despite its adoption,\nMCP's AI-driven, non-deterministic control flow introduces new risks to\nsustainability, security, and maintainability, warranting closer examination.\n  Towards this end, we present the first large-scale empirical study of MCP.\nUsing state-of-the-art health metrics and a hybrid analysis pipeline, combining\na general-purpose static analysis tool with an MCP-specific scanner, we\nevaluate 1,899 open-source MCP servers to assess their health, security, and\nmaintainability. Despite MCP servers demonstrating strong health metrics, we\nidentify eight distinct vulnerabilities-only three overlapping with traditional\nsoftware vulnerabilities. Additionally, 7.2% of servers contain general\nvulnerabilities and 5.5% exhibit MCP-specific tool poisoning. Regarding\nmaintainability, while 66% exhibit code smells, 14.4% contain ten bug patterns\noverlapping prior research. These findings highlight the need for MCP-specific\nvulnerability detection techniques while reaffirming the value of traditional\nanalysis and refactoring practices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Model Context Protocol (MCP)\u5728\u5065\u5eb7\u3001\u5b89\u5168\u548c\u53ef\u7ef4\u62a4\u6027\u65b9\u9762\u7684\u98ce\u9669\uff0c\u9996\u6b21\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u3002", "motivation": "\u5c3d\u7ba1MCP\u5df2\u6210\u4e3a\u6807\u51c6\u5de5\u5177\u751f\u6001\u7cfb\u7edf\uff0c\u4f46\u5176\u975e\u786e\u5b9a\u6027\u63a7\u5236\u6d41\u5e26\u6765\u4e86\u65b0\u7684\u53ef\u6301\u7eed\u6027\u3001\u5b89\u5168\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u98ce\u9669\uff0c\u9700\u6df1\u5165\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u5148\u8fdb\u7684\u5065\u5eb7\u6307\u6807\u548c\u6df7\u5408\u5206\u6790\u7ba1\u9053\uff0c\u7ed3\u5408\u901a\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\u548cMCP\u4e13\u7528\u626b\u63cf\u5668\uff0c\u8bc4\u4f30\u4e861,899\u4e2a\u5f00\u6e90MCP\u670d\u52a1\u5668\u3002", "result": "\u5c3d\u7ba1MCP\u670d\u52a1\u5668\u5065\u5eb7\u6307\u6807\u826f\u597d\uff0c\u4f46\u4ecd\u8bc6\u522b\u51fa8\u79cd\u72ec\u7279\u6f0f\u6d1e\uff0c\u5176\u4e2d7.2%\u5b58\u5728\u901a\u7528\u6f0f\u6d1e\uff0c5.5%\u5b58\u5728MCP\u4e13\u7528\u5de5\u5177\u4e2d\u6bd2\u95ee\u9898\uff1b66%\u5b58\u5728\u4ee3\u7801\u5f02\u5473\uff0c14.4%\u5305\u542b10\u79cd\u5df2\u77e5\u9519\u8bef\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86MCP\u4e13\u7528\u6f0f\u6d1e\u68c0\u6d4b\u6280\u672f\u7684\u5fc5\u8981\u6027\uff0c\u540c\u65f6\u80af\u5b9a\u4e86\u4f20\u7edf\u5206\u6790\u548c\u91cd\u6784\u5b9e\u8df5\u7684\u4ef7\u503c\u3002"}}
{"id": "2506.12213", "pdf": "https://arxiv.org/pdf/2506.12213", "abs": "https://arxiv.org/abs/2506.12213", "authors": ["Zikai Zhang", "Ping Liu", "Jiahao Xu", "Rui Hu"], "title": "Fed-HeLLo: Efficient Federated Foundation Model Fine-Tuning with Heterogeneous LoRA Allocation", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted to TNNLS 2025", "summary": "Federated Learning has recently been utilized to collaboratively fine-tune\nfoundation models across multiple clients. Notably, federated low-rank\nadaptation LoRA-based fine-tuning methods have recently gained attention, which\nallows clients to fine-tune FMs with a small portion of trainable parameters\nlocally. However, most existing methods do not account for the heterogeneous\nresources of clients or lack an effective local training strategy to maximize\nglobal fine-tuning performance under limited resources. In this work, we\npropose Fed-HeLLo, a novel federated LoRA-based fine-tuning framework that\nenables clients to collaboratively fine-tune an FM with different local\ntrainable LoRA layers. To ensure its effectiveness, we develop several\nheterogeneous LoRA allocation (HLA) strategies that adaptively allocate local\ntrainable LoRA layers based on clients' resource capabilities and the layer\nimportance. Specifically, based on the dynamic layer importance, we design a\nFisher Information Matrix score-based HLA that leverages dynamic gradient norm\ninformation. To better stabilize the training process, we consider the\nintrinsic importance of LoRA layers and design a Geometrically-Defined HLA\nstrategy. It shapes the collective distribution of trainable LoRA layers into\nspecific geometric patterns, such as Triangle, Inverted Triangle, Bottleneck,\nand Uniform. Moreover, we extend GD-HLA into a randomized version, named\nRandomized Geometrically-Defined HLA, for enhanced model accuracy with\nrandomness. By co-designing the proposed HLA strategies, we incorporate both\nthe dynamic and intrinsic layer importance into the design of our HLA strategy.\nWe evaluate our approach on five datasets under diverse federated LoRA\nfine-tuning settings, covering three levels of data distribution from IID to\nextreme Non-IID. Results show that Fed-HeLLo with HLA strategies is both\neffective and efficient.", "AI": {"tldr": "Fed-HeLLo\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLoRA\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u6784LoRA\u5206\u914d\u7b56\u7565\uff08HLA\uff09\u4f18\u5316\u5ba2\u6237\u7aef\u7684\u672c\u5730\u8bad\u7ec3\uff0c\u63d0\u5347\u5168\u5c40\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u5ba2\u6237\u7aef\u8d44\u6e90\u5f02\u6784\u6027\u6216\u7f3a\u4e4f\u6709\u6548\u7684\u672c\u5730\u8bad\u7ec3\u7b56\u7565\uff0cFed-HeLLo\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u79cdHLA\u7b56\u7565\uff0c\u5305\u62ec\u57fa\u4e8eFisher\u4fe1\u606f\u77e9\u9635\u7684\u52a8\u6001\u68af\u5ea6\u89c4\u8303\u5206\u914d\u548c\u57fa\u4e8e\u51e0\u4f55\u5b9a\u4e49\u7684\u5206\u914d\u7b56\u7565\uff0c\u4ee5\u53ca\u968f\u673a\u5316\u7248\u672c\u3002", "result": "\u5728\u4e94\u79cd\u6570\u636e\u96c6\u548c\u4e0d\u540c\u6570\u636e\u5206\u5e03\u8bbe\u7f6e\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFed-HeLLo\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u8868\u73b0\u9ad8\u6548\u4e14\u6709\u6548\u3002", "conclusion": "Fed-HeLLo\u901a\u8fc7\u7ed3\u5408\u52a8\u6001\u548c\u56fa\u5b9a\u7684\u5c42\u91cd\u8981\u6027\uff0c\u4f18\u5316\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684LoRA\u5fae\u8c03\u6548\u679c\u3002"}}
{"id": "2506.13186", "pdf": "https://arxiv.org/pdf/2506.13186", "abs": "https://arxiv.org/abs/2506.13186", "authors": ["Jiajun Sun", "Fengjie Li", "Xinzhu Qi", "Hongyu Zhang", "Jiajun Jiang"], "title": "Empirical Evaluation of Large Language Models in Automated Program Repair", "categories": ["cs.SE"], "comment": null, "summary": "The increasing prevalence of software bugs has made automated program repair\n(APR) a key research focus. Large language models (LLMs) offer new\nopportunities for APR, but existing studies mostly rely on smaller,\nearlier-generation models and Java benchmarks. The repair capabilities of\nmodern, large-scale LLMs across diverse languages and scenarios remain\nunderexplored. To address this, we conduct a comprehensive empirical study of\nfour open-source LLMs, CodeLlama, LLaMA, StarCoder, and DeepSeek-Coder,\nspanning 7B to 33B parameters, diverse architectures, and purposes. We evaluate\nthem across two bug scenarios (enterprise-grades and algorithmic), three\nlanguages (Java, C/C++, Python), and four prompting strategies, analyzing over\n600K generated patches on six benchmarks. Key findings include: (1) model\nspecialization (e.g., CodeLlama) can outperform larger general-purpose models\n(e.g., LLaMA); (2) repair performance does not scale linearly with model size;\n(3) correct patches often appear early in generation; and (4) prompts\nsignificantly affect results. These insights offer practical guidance for\ndesigning effective and efficient LLM-based APR systems.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5728\u591a\u8bed\u8a00\u3001\u591a\u573a\u666f\u4e0b\u6a21\u578b\u4e13\u4e00\u6027\u548c\u63d0\u793a\u7b56\u7565\u5bf9\u4fee\u590d\u6548\u679c\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u63a2\u7d22\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u7f16\u7a0b\u8bed\u8a00\u548c\u573a\u666f\u4e2d\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u80fd\u529b\u3002", "method": "\u5bf9\u56db\u4e2a\u5f00\u6e90LLM\uff08CodeLlama\u3001LLaMA\u3001StarCoder\u3001DeepSeek-Coder\uff09\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u8986\u76d6\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u3001\u67b6\u6784\u548c\u7528\u9014\uff0c\u8bc4\u4f30\u5176\u5728\u4e24\u79cd\u9519\u8bef\u573a\u666f\u548c\u4e09\u79cd\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u4e13\u4e00\u6027\u4f18\u4e8e\u901a\u7528\u6027\uff0c\u4fee\u590d\u6548\u679c\u4e0e\u6a21\u578b\u5927\u5c0f\u4e0d\u5b8c\u5168\u6b63\u76f8\u5173\uff0c\u4e14\u6b63\u786e\u7684\u8865\u4e01\u5e38\u65e9\u671f\u751f\u6210\uff1b\u63d0\u793a\u7b56\u7565\u5bf9\u7ed3\u679c\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bbe\u8ba1\u9ad8\u6548\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2506.13408", "pdf": "https://arxiv.org/pdf/2506.13408", "abs": "https://arxiv.org/abs/2506.13408", "authors": ["Miguel Camelo Botero", "Esra Aycan Beyazit", "Nina Slamnik-Krije\u0161torac", "Johann M. Marquez-Barja"], "title": "HELENA: High-Efficiency Learning-based channel Estimation using dual Neural Attention", "categories": ["eess.SP", "cs.LG", "cs.NI"], "comment": null, "summary": "Accurate channel estimation is critical for high-performance Orthogonal\nFrequency-Division Multiplexing systems such as 5G New Radio, particularly\nunder low signal-to-noise ratio and stringent latency constraints. This letter\npresents HELENA, a compact deep learning model that combines a lightweight\nconvolutional backbone with two efficient attention mechanisms: patch-wise\nmulti-head self-attention for capturing global dependencies and a\nsqueeze-and-excitation block for local feature refinement. Compared to CEViT, a\nstate-of-the-art vision transformer-based estimator, HELENA reduces inference\ntime by 45.0\\% (0.175\\,ms vs.\\ 0.318\\,ms), achieves comparable accuracy\n($-16.78$\\,dB vs.\\ $-17.30$\\,dB), and requires $8\\times$ fewer parameters\n(0.11M vs.\\ 0.88M), demonstrating its suitability for low-latency, real-time\ndeployment.", "AI": {"tldr": "HELENA\u662f\u4e00\u79cd\u7d27\u51d1\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9ad8\u6548\u4fe1\u9053\u4f30\u8ba1\uff0c\u7ed3\u5408\u8f7b\u91cf\u5377\u79ef\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u57285G NR\u7b49OFDM\u7cfb\u7edf\u4e2d\uff0c\u4f4e\u4fe1\u566a\u6bd4\u548c\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\uff0c\u9ad8\u7cbe\u5ea6\u4fe1\u9053\u4f30\u8ba1\u81f3\u5173\u91cd\u8981\u3002", "method": "HELENA\u91c7\u7528\u8f7b\u91cf\u5377\u79ef\u4e3b\u5e72\u548c\u4e24\u79cd\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\uff08\u5168\u5c40\u6355\u6349\u7684patch-wise\u591a\u5934\u81ea\u6ce8\u610f\u529b\u548c\u5c40\u90e8\u7279\u5f81\u4f18\u5316\u7684\u538b\u7f29\u6fc0\u52b1\u5757\uff09\u3002", "result": "\u76f8\u6bd4CEViT\uff0cHELENA\u63a8\u7406\u65f6\u95f4\u51cf\u5c1145%\uff0c\u53c2\u6570\u51cf\u5c118\u500d\uff0c\u7cbe\u5ea6\u76f8\u5f53\uff08-16.78 dB vs. -17.30 dB\uff09\u3002", "conclusion": "HELENA\u9002\u7528\u4e8e\u4f4e\u5ef6\u8fdf\u5b9e\u65f6\u90e8\u7f72\uff0c\u662f\u9ad8\u6548\u4fe1\u9053\u4f30\u8ba1\u7684\u7406\u60f3\u9009\u62e9\u3002"}}
{"id": "2506.12910", "pdf": "https://arxiv.org/pdf/2506.12910", "abs": "https://arxiv.org/abs/2506.12910", "authors": ["ATM Mizanur Rahman", "Md Romael Haque", "Sharifa Sultana"], "title": "DAIEM: Decolonizing Algorithm's Role as a Team-member in Informal E-market", "categories": ["cs.HC"], "comment": null, "summary": "In Bangladesh's rapidly expanding informal e-market, small-scale sellers use\nsocial media platforms like Facebook to run businesses outside formal\ninfrastructures. These sellers rely heavily on platform algorithms, not just\nfor visibility, but as active collaborators in business operations. Drawing on\n37 in-depth interviews with sellers, buyers, and stakeholders, this paper\nexamines how people in informal e-markets perceive and interact with the\nalgorithm as a \"team member\" that performs sales, marketing, and customer\nengagement tasks. We found that while sellers and local tech entrepreneurs are\ninterested in developing services to support this industry, buyers and\ninvestors place greater trust in human interactions. This reveals a\npostcolonial tension involving cultural values, local tech education and\ntraining, and a mismatch between the global and Bangladeshi e-market growth. We\nexpand this discussion using perspectives from HCI, political design, and AI\ndesign. We also support the decoloniality movement in informal e-markets by\nproposing the DAIEM framework, which includes six components: autonomy and\nagency; resistance; locality, culture, and history; rationality; materiality;\nand advocacy. DAIEM serves as both a guideline for algorithm design and an\nanalytical tool.", "AI": {"tldr": "\u5b5f\u52a0\u62c9\u56fd\u975e\u6b63\u5f0f\u7535\u5b50\u5e02\u573a\u4e2d\uff0c\u5c0f\u89c4\u6a21\u5356\u5bb6\u4f9d\u8d56\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\uff08\u5982Facebook\uff09\u548c\u7b97\u6cd5\u4f5c\u4e3a\u4e1a\u52a1\u5408\u4f5c\u7684\u201c\u56e2\u961f\u6210\u5458\u201d\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u672c\u5730\u4e0e\u5168\u7403\u7535\u5b50\u5e02\u573a\u589e\u957f\u7684\u6587\u5316\u548c\u6280\u672f\u51b2\u7a81\uff0c\u5e76\u63d0\u51fa\u4e86DAIEM\u6846\u67b6\u652f\u6301\u975e\u6b96\u6c11\u5316\u3002", "motivation": "\u63a2\u8ba8\u975e\u6b63\u5f0f\u7535\u5b50\u5e02\u573a\u4e2d\u5356\u5bb6\u5982\u4f55\u5c06\u5e73\u53f0\u7b97\u6cd5\u89c6\u4e3a\u4e1a\u52a1\u5408\u4f5c\u7684\u201c\u56e2\u961f\u6210\u5458\u201d\uff0c\u5e76\u5206\u6790\u5176\u4e2d\u7684\u6587\u5316\u3001\u6559\u80b2\u548c\u6280\u672f\u51b2\u7a81\u3002", "method": "\u901a\u8fc737\u6b21\u6df1\u5ea6\u8bbf\u8c08\uff0c\u6536\u96c6\u5356\u5bb6\u3001\u4e70\u5bb6\u548c\u5229\u76ca\u76f8\u5173\u8005\u7684\u770b\u6cd5\uff0c\u7ed3\u5408HCI\u3001\u653f\u6cbb\u8bbe\u8ba1\u548cAI\u8bbe\u8ba1\u89c6\u89d2\u3002", "result": "\u5356\u5bb6\u548c\u6280\u672f\u521b\u4e1a\u8005\u503e\u5411\u4e8e\u4f9d\u8d56\u7b97\u6cd5\uff0c\u800c\u4e70\u5bb6\u548c\u6295\u8d44\u8005\u66f4\u4fe1\u4efb\u4eba\u9645\u4e92\u52a8\uff0c\u63ed\u793a\u4e86\u5168\u7403\u4e0e\u672c\u5730\u5e02\u573a\u7684\u4e0d\u5339\u914d\u3002", "conclusion": "\u63d0\u51faDAIEM\u6846\u67b6\u4f5c\u4e3a\u7b97\u6cd5\u8bbe\u8ba1\u6307\u5357\u548c\u5206\u6790\u5de5\u5177\uff0c\u652f\u6301\u975e\u6b63\u5f0f\u7535\u5b50\u5e02\u573a\u7684\u975e\u6b96\u6c11\u5316\u53d1\u5c55\u3002"}}
{"id": "2506.12335", "pdf": "https://arxiv.org/pdf/2506.12335", "abs": "https://arxiv.org/abs/2506.12335", "authors": ["Chuntao Ding", "Jianhang Xie", "Junna Zhang", "Salman Raza", "Shangguang Wang", "Jiannong Cao"], "title": "GroupNL: Low-Resource and Robust CNN Design over Cloud and Device", "categories": ["cs.CV", "cs.AI", "cs.DC"], "comment": "13 pages, 10 figures", "summary": "It has become mainstream to deploy Convolutional Neural Network (CNN) models\non ubiquitous Internet of Things (IoT) devices with the help of the cloud to\nprovide users with a variety of high-quality services. Most existing methods\nhave two limitations: (i) low robustness in handling corrupted image data\ncollected by IoT devices; and (ii) high consumption of computational and\ntransmission resources. To this end, we propose the Grouped NonLinear\ntransformation generation method (GroupNL), which generates diversified feature\nmaps by utilizing data-agnostic Nonlinear Transformation Functions (NLFs) to\nimprove the robustness of the CNN model. Specifically, partial convolution\nfilters are designated as seed filters in a convolutional layer, and a small\nset of feature maps, i.e., seed feature maps, are first generated based on\nvanilla convolution operation. Then, we split seed feature maps into several\ngroups, each with a set of different NLFs, to generate corresponding diverse\nfeature maps with in-place nonlinear processing. Moreover, GroupNL effectively\nreduces the parameter transmission between multiple nodes during model training\nby setting the hyperparameters of NLFs to random initialization and not\nupdating them during model training, and reduces the computing resources by\nusing NLFs to generate feature maps instead of most feature maps generated\nbased on sliding windows. Experimental results on CIFAR-10, GTSRB, CIFAR-10-C,\nIcons50, and ImageNet-1K datasets in NVIDIA RTX GPU platforms show that the\nproposed GroupNL outperforms other state-of-the-art methods in model robust and\ntraining acceleration. Specifically, on the Icons-50 dataset, the accuracy of\nGroupNL-ResNet-18 achieves approximately 2.86% higher than the vanilla\nResNet-18. GroupNL improves training speed by about 53% compared to vanilla CNN\nwhen trained on a cluster of 8 NVIDIA RTX 4090 GPUs on the ImageNet-1K dataset.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faGroupNL\u65b9\u6cd5\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u53d8\u6362\u51fd\u6570\u589e\u5f3aCNN\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u548c\u4f20\u8f93\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406IoT\u8bbe\u5907\u91c7\u96c6\u7684\u635f\u574f\u56fe\u50cf\u65f6\u9c81\u68d2\u6027\u4f4e\uff0c\u4e14\u8ba1\u7b97\u548c\u4f20\u8f93\u8d44\u6e90\u6d88\u8017\u9ad8\uff0cGroupNL\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "GroupNL\u5229\u7528\u6570\u636e\u65e0\u5173\u7684\u975e\u7ebf\u6027\u53d8\u6362\u51fd\u6570\u751f\u6210\u591a\u6837\u5316\u7279\u5f81\u56fe\uff0c\u6539\u8fdb\u90e8\u5206\u5377\u79ef\u6ee4\u6ce2\u5668\u8bbe\u8ba1\uff0c\u51cf\u5c11\u53c2\u6570\u4f20\u8f93\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cGroupNL\u5728\u6a21\u578b\u9c81\u68d2\u6027\u548c\u8bad\u7ec3\u52a0\u901f\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u548c\u8bad\u7ec3\u901f\u5ea6\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GroupNL\u663e\u8457\u63d0\u5347\u4e86CNN\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u9002\u7528\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u4e2d\u7684\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2506.13273", "pdf": "https://arxiv.org/pdf/2506.13273", "abs": "https://arxiv.org/abs/2506.13273", "authors": ["Charaka Geethal Kapugama"], "title": "Isolating Noisy Labelled Test Cases in Human-in-the-Loop Oracle Learning", "categories": ["cs.SE"], "comment": "2025 International Research Conference on Smart Computing and Systems\n  Engineering (SCSE)", "summary": "Incorrectly labelled test cases can adversely affect the training process of\nhuman-in-the-loop oracle learning tech-niques. This paper introduces ISONOISE,\na technique designed to identify such mislabelled test cases introduced during\nhuman-in-the-loop oracle learning. This technique can be applied to programs\ntaking numeric inputs. Given a compromised automatic test oracle and its\ntraining test suite, ISONOISE first isolates thetest cases suspected of being\nmislabelled. This task is performed based on the level of disagreement of a\ntest case with respect to the others. An intermediate automatic test oracle is\ntrained based on the slightly disagreeing test cases. Based on the predictions\nof this intermediate oracle, the test cases suspected of being mislabelled are\nsystematically presented for relabelling. When mislabelled test cases are\nfound, the intermediate test oracle is updated. This process repeats until no\nmislabelled test case is found in relabelling. ISONOISE was evaluated within\nthe human-in-the-loop oracle learning method used in LEARN2FIX. Experimental\nresults demonstrate that ISONOISE can identify mislabelled test cases\nintroduced by the human in LEARN2FIX with over 67% accuracy, while requiring\nonly a small number of relabelling queries. These findings highlight the\npotential of ISONOISE to enhance the reliability of human-in-the-loop oracle\nlearning.", "AI": {"tldr": "ISONOISE\u662f\u4e00\u79cd\u6280\u672f\uff0c\u65e8\u5728\u8bc6\u522b\u4eba\u7c7b\u53c2\u4e0e\u7684Oracle\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u9519\u8bef\u6807\u8bb0\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63d0\u9ad8\u8bad\u7ec3\u8fc7\u7a0b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u9519\u8bef\u6807\u8bb0\u7684\u6d4b\u8bd5\u7528\u4f8b\u4f1a\u8d1f\u9762\u5f71\u54cd\u4eba\u7c7b\u53c2\u4e0e\u7684Oracle\u5b66\u4e60\u6280\u672f\uff0cISONOISE\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u9694\u79bb\u4e0e\u5176\u5b83\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u4e00\u81f4\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8bad\u7ec3\u4e2d\u95f4Oracle\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u91cd\u65b0\u6807\u8bb0\u53ef\u7591\u6d4b\u8bd5\u7528\u4f8b\uff0c\u76f4\u5230\u65e0\u9519\u8bef\u6807\u8bb0\u4e3a\u6b62\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cISONOISE\u80fd\u4ee5\u8d85\u8fc767%\u7684\u51c6\u786e\u7387\u8bc6\u522b\u9519\u8bef\u6807\u8bb0\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4e14\u53ea\u9700\u5c11\u91cf\u91cd\u65b0\u6807\u8bb0\u67e5\u8be2\u3002", "conclusion": "ISONOISE\u5c55\u793a\u4e86\u63d0\u5347\u4eba\u7c7b\u53c2\u4e0e\u7684Oracle\u5b66\u4e60\u53ef\u9760\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.13466", "pdf": "https://arxiv.org/pdf/2506.13466", "abs": "https://arxiv.org/abs/2506.13466", "authors": ["Leon Janzen", "Florentin Putz", "Marc-Andr\u00e9 Kaufhold", "Kolja Straub", "Matthias Hollick"], "title": "The User Perspective on Island-Ready 6G Communication: A Survey of Future Smartphone Usage in Crisis-Struck Areas with Local Cellular Connectivity", "categories": ["cs.HC", "cs.NI"], "comment": "22 pages, 6 figures, the dataset is available at\n  https://doi.org/10.5281/zenodo.14812894", "summary": "Using smartphone apps during crises is well-established, proving critical for\nefficient crisis response. However, such apps become futile without an Internet\nconnection, which is a common issue during crises. The ongoing 6G\nstandardization explores the capability to provide local cellular connectivity\nfor areas cut off from the Internet in crises. This paper introduces to the HCI\ncommunity the concept of cellular island connectivity in isolated areas,\npromising a seamless transition from normal operation to island operation with\nlocal-only cellular connectivity. It presents findings from a survey (N = 857)\namong adult smartphone users from major German cities regarding their\nsmartphone usage preferences in this model. Results show a shift in app demand,\nwith users favoring general-purpose apps over dedicated crisis apps in specific\nscenarios. We prioritize smartphone services based on their criticality,\ndistinguishing between apps essential for crisis response and those supporting\nroutines. Our findings provide operators, developers, and authorities insights\ninto making user-centric design decisions for implementing island-ready 6G\ncommunication.", "AI": {"tldr": "\u667a\u80fd\u624b\u673a\u5e94\u7528\u5728\u5371\u673a\u671f\u95f4\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u65e0\u4e92\u8054\u7f51\u8fde\u63a5\u65f6\u4f1a\u5931\u6548\u30026G\u6807\u51c6\u5316\u63a2\u7d22\u4e86\u5728\u65ad\u7f51\u5371\u673a\u533a\u57df\u63d0\u4f9b\u672c\u5730\u8702\u7a9d\u8fde\u63a5\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63d0\u51fa\u8702\u7a9d\u5c9b\u8fde\u63a5\u6982\u5ff5\uff0c\u652f\u6301\u65e0\u7f1d\u5207\u6362\u5230\u672c\u5730\u8fde\u63a5\u6a21\u5f0f\u3002\u901a\u8fc7\u8c03\u67e5\uff08N=857\uff09\u53d1\u73b0\u7528\u6237\u66f4\u503e\u5411\u901a\u7528\u5e94\u7528\u800c\u975e\u4e13\u7528\u5371\u673a\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u667a\u80fd\u624b\u673a\u5e94\u7528\u5728\u5371\u673a\u671f\u95f4\u7684\u4f7f\u7528\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u65e0\u4e92\u8054\u7f51\u8fde\u63a5\u65f6\u7684\u529f\u80fd\u7f3a\u5931\uff0c\u63a2\u7d226G\u672c\u5730\u8fde\u63a5\u65b9\u6848\u4ee5\u63d0\u5347\u5371\u673a\u5e94\u5bf9\u6548\u7387\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u6765\u81ea\u5fb7\u56fd\u4e3b\u8981\u57ce\u5e02\u7684857\u540d\u6210\u5e74\u667a\u80fd\u624b\u673a\u7528\u6237\uff0c\u5206\u6790\u5176\u5728\u8702\u7a9d\u5c9b\u8fde\u63a5\u6a21\u5f0f\u4e0b\u7684\u5e94\u7528\u4f7f\u7528\u504f\u597d\u3002", "result": "\u7528\u6237\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u66f4\u504f\u597d\u901a\u7528\u5e94\u7528\u800c\u975e\u4e13\u7528\u5371\u673a\u5e94\u7528\uff0c\u7814\u7a76\u8fd8\u533a\u5206\u4e86\u5371\u673a\u5e94\u5bf9\u4e0e\u65e5\u5e38\u652f\u6301\u7684\u4f18\u5148\u7ea7\u3002", "conclusion": "\u4e3a\u8fd0\u8425\u5546\u3001\u5f00\u53d1\u8005\u548c\u5f53\u5c40\u63d0\u4f9b\u4e866G\u8702\u7a9d\u5c9b\u8fde\u63a5\u6a21\u5f0f\u4e0b\u7684\u7528\u6237\u5bfc\u5411\u8bbe\u8ba1\u5efa\u8bae\uff0c\u4f18\u5316\u5371\u673a\u5e94\u5bf9\u80fd\u529b\u3002"}}
{"id": "2506.13129", "pdf": "https://arxiv.org/pdf/2506.13129", "abs": "https://arxiv.org/abs/2506.13129", "authors": ["Yi He", "Yuqi Liu", "Chenpu Li", "Ruoyan Chen", "Chuer Chen", "Shengqi Dang", "Nan Cao"], "title": "ChartBlender: An Interactive System for Authoring and Synchronizing Visualization Charts in Video", "categories": ["cs.HC"], "comment": "11 pages, 7 figures", "summary": "Embedding data visualizations in video can enhance the communication of\ncomplex information. However, this process is often labor-intensive, requiring\ndesigners to adjust visualizations frame by frame manually. In this work, we\npresent ChartBlender, a novel system that streamlines this process by enabling\nusers to create data visualizations, embed them seamlessly into video scenes,\nand automatically synchronize them with both camera motion and moving objects.\nParticularly, ChartBlender incorporates a tracking algorithm that supports both\nobject and camera tracking, ensuring robust alignment of visualizations with\ndynamic video content. To maintain visual clarity and aesthetic coherence, we\nalso explore the design space of video-suited visualizations and develop a\nlibrary of customizable templates optimized for video embedding. We evaluate\n\\oursName\\ChartBlender through two controlled experiments and expert interviews\nwith five domain experts. Results show that our system enables accurate\nsynchronization and accelerates the production of data-driven videos.", "AI": {"tldr": "ChartBlender\u662f\u4e00\u4e2a\u7b80\u5316\u6570\u636e\u53ef\u89c6\u5316\u5d4c\u5165\u89c6\u9891\u7684\u7cfb\u7edf\uff0c\u652f\u6301\u81ea\u52a8\u540c\u6b65\u6444\u50cf\u5934\u548c\u5bf9\u8c61\u8fd0\u52a8\u3002", "motivation": "\u624b\u52a8\u9010\u5e27\u8c03\u6574\u53ef\u89c6\u5316\u5d4c\u5165\u89c6\u9891\u8017\u65f6\u8d39\u529b\uff0cChartBlender\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u8ddf\u8e2a\u7b97\u6cd5\u548c\u81ea\u5b9a\u4e49\u6a21\u677f\u5e93\uff0c\u5b9e\u73b0\u53ef\u89c6\u5316\u4e0e\u52a8\u6001\u89c6\u9891\u5185\u5bb9\u7684\u540c\u6b65\u3002", "result": "\u5b9e\u9a8c\u548c\u4e13\u5bb6\u8bbf\u8c08\u8bc1\u660e\u7cfb\u7edf\u80fd\u7cbe\u786e\u540c\u6b65\u5e76\u52a0\u901f\u751f\u4ea7\u6570\u636e\u9a71\u52a8\u89c6\u9891\u3002", "conclusion": "ChartBlender\u4e3a\u6570\u636e\u53ef\u89c6\u5316\u5d4c\u5165\u89c6\u9891\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12479", "pdf": "https://arxiv.org/pdf/2506.12479", "abs": "https://arxiv.org/abs/2506.12479", "authors": ["Hongjun An", "Sida Huang", "Siqi Huang", "Ruanjun Li", "Yuanzhi Liang", "Jiawei Shao", "Zihan Wang", "Cheng Yuan", "Chi Zhang", "Hongyuan Zhang", "Wenhao Zhuang", "Xuelong Li"], "title": "AI Flow: Perspectives, Scenarios, and Approaches", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.DC", "eess.SP"], "comment": "Authors are with Institute of Artificial Intelligence (TeleAI), China\n  Telecom, China. Author names are listed alphabetically by surname. This work\n  was conducted at TeleAI, facilitated by Dr. Jiawei Shao (e-mail:\n  shaojw2@chinatelecom.cn) under the leadership of Prof. Xuelong Li. The\n  corresponding author is Prof. Xuelong Li (e-mail: xuelong li@ieee.org), the\n  CTO and Chief Scientist of China Telecom", "summary": "Pioneered by the foundational information theory by Claude Shannon and the\nvisionary framework of machine intelligence by Alan Turing, the convergent\nevolution of information and communication technologies (IT/CT) has created an\nunbroken wave of connectivity and computation. This synergy has sparked a\ntechnological revolution, now reaching its peak with large artificial\nintelligence (AI) models that are reshaping industries and redefining\nhuman-machine collaboration. However, the realization of ubiquitous\nintelligence faces considerable challenges due to substantial resource\nconsumption in large models and high communication bandwidth demands. To\naddress these challenges, AI Flow has been introduced as a multidisciplinary\nframework that integrates cutting-edge IT and CT advancements, with a\nparticular emphasis on the following three key points. First, device-edge-cloud\nframework serves as the foundation, which integrates end devices, edge servers,\nand cloud clusters to optimize scalability and efficiency for low-latency model\ninference. Second, we introduce the concept of familial models, which refers to\na series of different-sized models with aligned hidden features, enabling\neffective collaboration and the flexibility to adapt to varying resource\nconstraints and dynamic scenarios. Third, connectivity- and interaction-based\nintelligence emergence is a novel paradigm of AI Flow. By leveraging\ncommunication networks to enhance connectivity, the collaboration among AI\nmodels across heterogeneous nodes achieves emergent intelligence that surpasses\nthe capability of any single model. The innovations of AI Flow provide enhanced\nintelligence, timely responsiveness, and ubiquitous accessibility to AI\nservices, paving the way for the tighter fusion of AI techniques and\ncommunication systems.", "AI": {"tldr": "AI Flow\u662f\u4e00\u4e2a\u591a\u5b66\u79d1\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578bAI\u6a21\u578b\u8d44\u6e90\u6d88\u8017\u548c\u901a\u4fe1\u5e26\u5bbd\u95ee\u9898\uff0c\u901a\u8fc7\u8bbe\u5907-\u8fb9\u7f18-\u4e91\u6846\u67b6\u3001\u5bb6\u65cf\u6a21\u578b\u548c\u8fde\u63a5\u6027\u667a\u80fd\u6d8c\u73b0\u5b9e\u73b0\u9ad8\u6548\u534f\u4f5c\u548c\u666e\u53ca\u667a\u80fd\u3002", "motivation": "\u5927\u578bAI\u6a21\u578b\u548c\u9ad8\u901a\u4fe1\u5e26\u5bbd\u9700\u6c42\u963b\u788d\u4e86\u666e\u53ca\u667a\u80fd\u7684\u5b9e\u73b0\uff0c\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8bbe\u5907-\u8fb9\u7f18-\u4e91\u6846\u67b6\u3001\u5bb6\u65cf\u6a21\u578b\u548c\u8fde\u63a5\u6027\u667a\u80fd\u6d8c\u73b0\u4e09\u5927\u521b\u65b0\u70b9\u3002", "result": "AI Flow\u63d0\u5347\u4e86\u667a\u80fd\u6c34\u5e73\u3001\u54cd\u5e94\u901f\u5ea6\u548c\u666e\u53ca\u6027\uff0c\u63a8\u52a8\u4e86AI\u4e0e\u901a\u4fe1\u7cfb\u7edf\u7684\u878d\u5408\u3002", "conclusion": "AI Flow\u4e3aAI\u6280\u672f\u4e0e\u901a\u4fe1\u7cfb\u7edf\u7684\u7d27\u5bc6\u878d\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2506.13303", "pdf": "https://arxiv.org/pdf/2506.13303", "abs": "https://arxiv.org/abs/2506.13303", "authors": ["Julian Frattini", "Anja Frattini"], "title": "Adopting Use Case Descriptions for Requirements Specification: an Industrial Case Study", "categories": ["cs.SE"], "comment": null, "summary": "Context: Use case (UC) descriptions are a prominent format for specifying\nfunctional requirements. Existing literature abounds with recommendations on\nhow to write high-quality UC descriptions but lacks insights into (1) their\nreal-world adoption, (2) whether these recommendations correspond to actual\nquality, and (3) which factors influence the quality of UCs. Objectives: We aim\nto contribute empirical evidence about the adoption of UC descriptions in a\nlarge, globally distributed case company. Methods: We surveyed 1188 business\nrequirements of a case company that were elicited from 2020-01-01 until\n2024-12-31 and contained 1192 UCs in various forms. Among these, we manually\nevaluated the 273 template-style UC descriptions against established quality\nguidelines. We generated descriptive statistics of the format's adoption over\nthe surveyed time frame. Furthermore, we used inferential statistics to\ndetermine (a) how properties of the requirements engineering process affected\nthe UC quality and (b) how UC quality affects subsequent software development\nactivities. Results and Conclusions: Our descriptive results show how the\nadoption of UC descriptions in practice deviates from textbook recommendations.\nHowever, our inferential results suggest that only a few phenomena like\nsolution-orientation show an actual impact in practice. These results can steer\nUC quality research into a more relevant direction.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u7528\u4f8b\uff08UC\uff09\u63cf\u8ff0\u7684\u5b9e\u8df5\u91c7\u7528\u60c5\u51b5\u53ca\u5176\u8d28\u91cf\u5f71\u54cd\u56e0\u7d20\uff0c\u53d1\u73b0\u5b9e\u9645\u5e94\u7528\u4e0e\u6559\u79d1\u4e66\u63a8\u8350\u6709\u5dee\u5f02\uff0c\u4f46\u5c11\u6570\u73b0\u8c61\u5982\u89e3\u51b3\u65b9\u6848\u5bfc\u5411\u786e\u5b9e\u5bf9\u5b9e\u8df5\u6709\u5f71\u54cd\u3002", "motivation": "\u4e86\u89e3\u7528\u4f8b\u63cf\u8ff0\u5728\u73b0\u5b9e\u4e2d\u7684\u91c7\u7528\u60c5\u51b5\uff0c\u9a8c\u8bc1\u73b0\u6709\u8d28\u91cf\u5efa\u8bae\u7684\u5b9e\u9645\u76f8\u5173\u6027\uff0c\u5e76\u63a2\u7d22\u5f71\u54cd\u7528\u4f8b\u8d28\u91cf\u7684\u56e0\u7d20\u3002", "method": "\u8c03\u67e5\u4e861188\u4e2a\u4e1a\u52a1\u9700\u6c42\uff0c\u624b\u5de5\u8bc4\u4f30\u4e86273\u4e2a\u6a21\u677f\u5f0f\u7528\u4f8b\u63cf\u8ff0\uff0c\u5e76\u5229\u7528\u7edf\u8ba1\u65b9\u6cd5\u5206\u6790\u8d28\u91cf\u5f71\u54cd\u56e0\u7d20\u53ca\u5176\u5bf9\u540e\u7eed\u5f00\u53d1\u6d3b\u52a8\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u8df5\u4e2d\u7684\u7528\u4f8b\u63cf\u8ff0\u91c7\u7528\u4e0e\u6559\u79d1\u4e66\u63a8\u8350\u6709\u5dee\u5f02\uff0c\u4f46\u89e3\u51b3\u65b9\u6848\u5bfc\u5411\u7b49\u5c11\u6570\u73b0\u8c61\u5177\u6709\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u53ef\u5f15\u5bfc\u7528\u4f8b\u8d28\u91cf\u7814\u7a76\u671d\u66f4\u6709\u5b9e\u9645\u610f\u4e49\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2506.13563", "pdf": "https://arxiv.org/pdf/2506.13563", "abs": "https://arxiv.org/abs/2506.13563", "authors": ["Yali Yuan", "Kai Xu", "Ruolin Ma", "Yuchen Zhang"], "title": "Unlearning-Enhanced Website Fingerprinting Attack: Against Backdoor Poisoning in Anonymous Networks", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "Website Fingerprinting (WF) is an effective tool for regulating and governing\nthe dark web. However, its performance can be significantly degraded by\nbackdoor poisoning attacks in practical deployments. This paper aims to address\nthe problem of hidden backdoor poisoning attacks faced by Website\nFingerprinting attack, and designs a feasible mothed that integrates unlearning\ntechnology to realize detection of automatic poisoned points and complete\nremoval of its destructive effects, requiring only a small number of known\npoisoned test points. Taking Tor onion routing as an example, our method\nevaluates the influence value of each training sample on these known poisoned\ntest points as the basis for judgment. We optimize the use of influence scores\nto identify poisoned samples within the training dataset. Furthermore, by\nquantifying the difference between the contribution of model parameters on the\ntaining data and the clean data, the target parameters are dynamically adjusted\nto eliminate the impact of the backdoor attacks. Experiments on public datasets\nunder the assumptions of closed-world (CW) and open-world (OW) verify the\neffectiveness of the proposed method. In complex scenes containing both clean\nwebsite fingerprinting features and backdoor triggers, the accuracy of the\nmodel on the poisoned dataset and the test dataset is stable at about 80%,\nsignificantly outperforming the traditional WF attack models. In addition, the\nproposed method achieves a 2-3 times speedup in runtime efficiency compared to\nbaseline methods. By incorporating machine unlearning, we realize a WF attack\nmodel that exhibits enhanced resistance to backdoor poisoning and faster\nexecution speeds in adversarial settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u96c6\u6210\u9057\u5fd8\u6280\u672f\uff0c\u63d0\u51fa\u4e00\u79cd\u68c0\u6d4b\u5e76\u6d88\u9664\u540e\u95e8\u6bd2\u5316\u653b\u51fb\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f51\u7ad9\u5728\u6307\u7eb9\u8bc6\u522b\u4e2d\u7684\u6297\u653b\u51fb\u80fd\u529b\u548c\u8fd0\u884c\u6548\u7387\u3002", "motivation": "\u9488\u5bf9\u7f51\u7ad9\u6307\u7eb9\u8bc6\u522b\uff08WF\uff09\u4e2d\u9762\u4e34\u7684\u9690\u853d\u540e\u95e8\u6bd2\u5316\u653b\u51fb\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "method": "\u5229\u7528\u9057\u5fd8\u6280\u672f\uff0c\u901a\u8fc7\u8bc4\u4f30\u8bad\u7ec3\u6837\u672c\u5bf9\u5df2\u77e5\u6bd2\u5316\u6d4b\u8bd5\u70b9\u7684\u5f71\u54cd\u503c\uff0c\u52a8\u6001\u8c03\u6574\u6a21\u578b\u53c2\u6570\u4ee5\u6d88\u9664\u540e\u95e8\u653b\u51fb\u7684\u5f71\u54cd\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6bd2\u5316\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u7a33\u5b9a\u572880%\u5de6\u53f3\uff0c\u8fd0\u884c\u6548\u7387\u63d0\u9ad8\u4e862-3\u500d\u3002", "conclusion": "\u7ed3\u5408\u673a\u5668\u9057\u5fd8\u6280\u672f\uff0c\u8bba\u6587\u63d0\u51fa\u7684WF\u653b\u51fb\u6a21\u578b\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6297\u6bd2\u5316\u653b\u51fb\u80fd\u529b\u548c\u66f4\u5feb\u7684\u6267\u884c\u901f\u5ea6\u3002"}}
{"id": "2506.13189", "pdf": "https://arxiv.org/pdf/2506.13189", "abs": "https://arxiv.org/abs/2506.13189", "authors": ["Yuchong Zhang", "Bastian Orthmann", "Shichen Ji", "Michael Welle", "Jonne Van Haastregt", "Danica Kragic"], "title": "Multimodal \"Puppeteer\": An Exploration of Robot Teleoperation Via Virtual Counterpart with LLM-Driven Voice and Gesture Interaction in Augmented Reality", "categories": ["cs.HC", "cs.RO"], "comment": "This work has been submitted to the IEEE TVCG for possible\n  publication", "summary": "The integration of robotics and augmented reality (AR) holds transformative\npotential for advancing human-robot interaction (HRI), offering enhancements in\nusability, intuitiveness, accessibility, and collaborative task performance.\nThis paper introduces and evaluates a novel multimodal AR-based robot puppeteer\nframework that enables intuitive teleoperation via virtual counterpart through\nlarge language model (LLM)-driven voice commands and hand gesture interactions.\nUtilizing the Meta Quest 3, users interact with a virtual counterpart robot in\nreal-time, effectively \"puppeteering\" its physical counterpart within an AR\nenvironment. We conducted a within-subject user study with 42 participants\nperforming robotic cube pick-and-place with pattern matching tasks under two\nconditions: gesture-only interaction and combined voice-and-gesture\ninteraction. Both objective performance metrics and subjective user experience\n(UX) measures were assessed, including an extended comparative analysis between\nroboticists and non-roboticists. The results provide key insights into how\nmultimodal input influences contextual task efficiency, usability, and user\nsatisfaction in AR-based HRI. Our findings offer practical design implications\nfor designing effective AR-enhanced HRI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e00\u79cd\u57fa\u4e8e\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u7684\u591a\u6a21\u6001\u673a\u5668\u4eba\u64cd\u63a7\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u97f3\u548c\u624b\u52bf\u4ea4\u4e92\uff0c\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u7684\u76f4\u89c2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u63a2\u7d22AR\u4e0e\u673a\u5668\u4eba\u7ed3\u5408\u7684\u6f5c\u529b\uff0c\u4ee5\u4f18\u5316\u4eba\u673a\u4ea4\u4e92\u7684\u53ef\u7528\u6027\u3001\u76f4\u89c2\u6027\u548c\u534f\u4f5c\u4efb\u52a1\u8868\u73b0\u3002", "method": "\u4f7f\u7528Meta Quest 3\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u8bed\u97f3\u4e0e\u624b\u52bf\u4ea4\u4e92\uff0c\u5b9e\u73b0\u5b9e\u65f6\u865a\u62df\u673a\u5668\u4eba\u64cd\u63a7\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u6bd4\u8f83\u624b\u52bf\u4e0e\u8bed\u97f3\u7ed3\u5408\u7684\u4ea4\u4e92\u6548\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u591a\u6a21\u6001\u8f93\u5165\u5728\u4efb\u52a1\u6548\u7387\u3001\u53ef\u7528\u6027\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u4e3a\u975e\u673a\u5668\u4eba\u4e13\u5bb6\u63d0\u4f9b\u4e86\u66f4\u76f4\u89c2\u7684\u4ea4\u4e92\u4f53\u9a8c\u3002", "conclusion": "AR\u589e\u5f3a\u7684\u4eba\u673a\u4ea4\u4e92\u7cfb\u7edf\u8bbe\u8ba1\u5e94\u8003\u8651\u591a\u6a21\u6001\u8f93\u5165\uff0c\u4ee5\u63d0\u9ad8\u7528\u6237\u4f53\u9a8c\u548c\u4efb\u52a1\u5b8c\u6210\u6548\u7387\u3002"}}
{"id": "2506.12737", "pdf": "https://arxiv.org/pdf/2506.12737", "abs": "https://arxiv.org/abs/2506.12737", "authors": ["Changsheng Gao", "Shan Liu", "Feng Wu", "Weisi Lin"], "title": "Cross-architecture universal feature coding via distribution alignment", "categories": ["cs.CV", "cs.DC"], "comment": null, "summary": "Feature coding has become increasingly important in scenarios where semantic\nrepresentations rather than raw pixels are transmitted and stored. However,\nmost existing methods are architecture-specific, targeting either CNNs or\nTransformers. This design limits their applicability in real-world scenarios\nwhere features from both architectures coexist. To address this gap, we\nintroduce a new research problem: cross-architecture universal feature coding\n(CAUFC), which seeks to build a unified codec that can effectively compress\nfeatures from heterogeneous architectures. To tackle this challenge, we propose\na two-step distribution alignment method. First, we design the format alignment\nmethod that unifies CNN and Transformer features into a consistent 2D token\nformat. Second, we propose the feature value alignment method that harmonizes\nstatistical distributions via truncation and normalization. As a first attempt\nto study CAUFC, we evaluate our method on the image classification task.\nExperimental results demonstrate that our method achieves superior\nrate-accuracy trade-offs compared to the architecture-specific baseline. This\nwork marks an initial step toward universal feature compression across\nheterogeneous model architectures.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u67b6\u6784\u901a\u7528\u7279\u5f81\u7f16\u7801\u65b9\u6cd5\uff08CAUFC\uff09\uff0c\u901a\u8fc7\u4e24\u6b65\u5206\u5e03\u5bf9\u9f50\u89e3\u51b3CNN\u548cTransformer\u7279\u5f81\u5f02\u6784\u6027\u7684\u95ee\u9898\uff0c\u5e76\u53d6\u5f97\u4f18\u4e8e\u5355\u67b6\u6784\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u7f16\u7801\u65b9\u6cd5\u591a\u4e3a\u7279\u5b9a\u67b6\u6784\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u9002\u5e94CNN\u548cTransformer\u7279\u5f81\u5e76\u5b58\u7684\u5b9e\u9645\u573a\u666f\uff0c\u9700\u5f00\u53d1\u7edf\u4e00\u7f16\u7801\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u5206\u5e03\u5bf9\u9f50\uff1a1\uff09\u683c\u5f0f\u5bf9\u9f50\uff0c\u5c06CNN\u548cTransformer\u7279\u5f81\u7edf\u4e00\u4e3a2D token\u683c\u5f0f\uff1b2\uff09\u7279\u5f81\u503c\u5bf9\u9f50\uff0c\u901a\u8fc7\u622a\u65ad\u548c\u5f52\u4e00\u5316\u534f\u8c03\u7edf\u8ba1\u5206\u5e03\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4f18\u4e8e\u5355\u67b6\u6784\u57fa\u7ebf\u7684\u51c6\u786e\u7387-\u538b\u7f29\u7387\u5e73\u8861\u3002", "conclusion": "CAUFC\u662f\u8fc8\u5411\u8de8\u5f02\u6784\u6a21\u578b\u67b6\u6784\u901a\u7528\u7279\u5f81\u538b\u7f29\u7684\u9996\u6b65\u5c1d\u8bd5\u3002"}}
{"id": "2506.13270", "pdf": "https://arxiv.org/pdf/2506.13270", "abs": "https://arxiv.org/abs/2506.13270", "authors": ["Nan Chen", "Luna K. Qiu", "Arran Zeyu Wang", "Zilong Wang", "Yuqing Yang"], "title": "Screen Reader Users in the Vibe Coding Era: Adaptation, Empowerment, and New Accessibility Landscape", "categories": ["cs.HC"], "comment": null, "summary": "The rise of generative AI agents has reshaped human-computer interaction and\ncomputer-supported cooperative work by shifting users' roles from direct task\nexecution to supervising machine-driven actions, especially in programming\n(e.g., \"vibe coding\"). However, there is limited understanding of how screen\nreader users engage with these systems in practice. To address this gap, we\nconducted a longitudinal study with 16 screen reader users, exploring their\nexperiences with AI code assistants in daily programming scenarios.\nParticipants first completed a tutorial with GitHub Copilot, then performed a\nprogramming task and provided initial feedback. After two weeks of AI-assisted\nprogramming, follow-up studies assessed changes in their practices and\nperceptions. Our findings demonstrate that advanced code assistants not only\nenhance their programming capabilities but also bridge accessibility gaps.\nWhile the assistant proved beneficial, there remains potential to improve how\nusers convey intent and interpret outputs. They also experienced difficulties\nmanaging multiple views and maintaining situational awareness. More broadly,\nthey encountered barriers in learning advanced tools and expressed a need to\nretain control. Based on these insights, we provide design recommendations for\nmore accessible and inclusive AI-assisted tools.", "AI": {"tldr": "\u751f\u6210\u4e86AI\u4ee3\u7406\u7684\u5d1b\u8d77\u901a\u8fc7\u5c06\u7528\u6237\u7684\u89d2\u8272\u4ece\u76f4\u63a5\u4efb\u52a1\u6267\u884c\u8f6c\u53d8\u4e3a\u76d1\u7763\u673a\u5668\u9a71\u52a8\u7684\u884c\u52a8\uff0c\u91cd\u5851\u4e86\u4eba\u673a\u4ea4\u4e92\u548c\u8ba1\u7b97\u673a\u652f\u6301\u7684\u534f\u540c\u5de5\u4f5c\u3002\u672c\u6587\u901a\u8fc7\u7eb5\u5411\u7814\u7a76\u63a2\u8ba8\u4e86\u5c4f\u5e55\u9605\u8bfb\u5668\u7528\u6237\u4e0eAI\u4ee3\u7801\u52a9\u624b\u7684\u4e92\u52a8\u4f53\u9a8c\u3002", "motivation": "\u63a2\u8ba8\u5c4f\u5e55\u9605\u8bfb\u5668\u7528\u6237\u5982\u4f55\u5b9e\u9645\u4f7f\u7528\u751f\u6210\u5f0fAI\u4ee3\u7801\u52a9\u624b\uff0c\u4ee5\u586b\u8865\u5f53\u524d\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u5bf916\u540d\u5c4f\u5e55\u9605\u8bfb\u5668\u7528\u6237\u8fdb\u884c\u7eb5\u5411\u7814\u7a76\uff0c\u5305\u62ec\u6559\u7a0b\u5b66\u4e60\u3001\u7f16\u7a0b\u4efb\u52a1\u548c\u540e\u7eed\u8ddf\u8e2a\uff0c\u8bc4\u4f30\u5176\u7ecf\u9a8c\u548c\u611f\u77e5\u53d8\u5316\u3002", "result": "AI\u4ee3\u7801\u52a9\u624b\u589e\u5f3a\u4e86\u7f16\u7a0b\u80fd\u529b\u5e76\u5f25\u8865\u4e86\u65e0\u969c\u788d\u7f3a\u9677\uff0c\u4f46\u7528\u6237\u4ecd\u9700\u6539\u8fdb\u610f\u56fe\u4f20\u8fbe\u548c\u8f93\u51fa\u89e3\u91ca\uff0c\u5e76\u9762\u4e34\u591a\u89c6\u56fe\u7ba1\u7406\u548c\u60c5\u5883\u610f\u8bc6\u4fdd\u6301\u7684\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u66f4\u5177\u5305\u5bb9\u6027\u548c\u65e0\u969c\u788d\u7684AI\u8f85\u52a9\u5de5\u5177\u8bbe\u8ba1\u5efa\u8bae\u3002"}}
{"id": "2506.13246", "pdf": "https://arxiv.org/pdf/2506.13246", "abs": "https://arxiv.org/abs/2506.13246", "authors": ["Craig Steven Wright"], "title": "On Immutable Memory Systems for Artificial Agents: A Blockchain-Indexed Automata-Theoretic Framework Using ECDH-Keyed Merkle Chains", "categories": ["cs.CR", "cs.AI", "cs.DC", "68Q70, 68P25, 68T37 68Q70, 68P25, 68T37 68Q70, 68P25, 68T37 68Q70,\n  68P25, 68T37", "F.4.3; D.4.6; E.3; I.2.4"], "comment": "47 pages, includes formal automata specifications, cryptographic\n  constructions, and epistemic architecture schema", "summary": "This paper presents a formalised architecture for synthetic agents designed\nto retain immutable memory, verifiable reasoning, and constrained epistemic\ngrowth. Traditional AI systems rely on mutable, opaque statistical models prone\nto epistemic drift and historical revisionism. In contrast, we introduce the\nconcept of the Merkle Automaton, a cryptographically anchored, deterministic\ncomputational framework that integrates formal automata theory with\nblockchain-based commitments. Each agent transition, memory fragment, and\nreasoning step is committed within a Merkle structure rooted on-chain,\nrendering it non-repudiable and auditably permanent. To ensure selective access\nand confidentiality, we derive symmetric encryption keys from ECDH exchanges\ncontextualised by hierarchical privilege lattices. This enforces cryptographic\naccess control over append-only DAG-structured knowledge graphs. Reasoning is\nconstrained by formal logic systems and verified through deterministic\ntraversal of policy-encoded structures. Updates are non-destructive and\nhistoried, preserving epistemic lineage without catastrophic forgetting.\nZero-knowledge proofs facilitate verifiable, privacy-preserving inclusion\nattestations. Collectively, this architecture reframes memory not as a cache\nbut as a ledger - one whose contents are enforced by protocol, bound by\ncryptography, and constrained by formal logic. The result is not an intelligent\nagent that mimics thought, but an epistemic entity whose outputs are provably\nderived, temporally anchored, and impervious to post hoc revision. This design\nlays foundational groundwork for legal, economic, and high-assurance\ncomputational systems that require provable memory, unforgeable provenance, and\nstructural truth.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5408\u6210\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u786e\u4fdd\u8bb0\u5fc6\u4e0d\u53ef\u53d8\u3001\u63a8\u7406\u53ef\u9a8c\u8bc1\u4e14\u77e5\u8bc6\u589e\u957f\u53d7\u9650\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfAI\u7cfb\u7edf\u7684\u6613\u53d8\u6027\u548c\u4e0d\u900f\u660e\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfAI\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u53ef\u53d8\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u6613\u51fa\u73b0\u77e5\u8bc6\u6f02\u79fb\u548c\u5386\u53f2\u4fee\u6b63\u4e3b\u4e49\u3002\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u4e00\u79cd\u53ef\u9a8c\u8bc1\u3001\u4e0d\u53ef\u7be1\u6539\u7684\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u9002\u7528\u4e8e\u9ad8\u53ef\u9760\u6027\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86Merkle Automaton\u67b6\u6784\uff0c\u7ed3\u5408\u5f62\u5f0f\u81ea\u52a8\u673a\u7406\u8bba\u548c\u533a\u5757\u94fe\u6280\u672f\uff0c\u901a\u8fc7Merkle\u7ed3\u6784\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u786e\u4fdd\u8bb0\u5fc6\u548c\u63a8\u7406\u7684\u4e0d\u53ef\u7be1\u6539\u6027\u4e0e\u9690\u79c1\u4fdd\u62a4\u3002", "result": "\u5b9e\u73b0\u4e86\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u4f5c\u4e3a\u4e0d\u53ef\u53d8\u7684\u8d26\u672c\uff0c\u63a8\u7406\u8fc7\u7a0b\u53ef\u9a8c\u8bc1\u4e14\u77e5\u8bc6\u589e\u957f\u53d7\u5f62\u5f0f\u903b\u8f91\u7ea6\u675f\uff0c\u9002\u7528\u4e8e\u6cd5\u5f8b\u3001\u7ecf\u6d4e\u7b49\u9ad8\u53ef\u9760\u6027\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e3a\u9700\u8981\u53ef\u8bc1\u660e\u8bb0\u5fc6\u548c\u4e0d\u53ef\u4f2a\u9020\u6765\u6e90\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u667a\u80fd\u4f53\u7684\u53ef\u9a8c\u8bc1\u6027\u548c\u6297\u4fee\u8ba2\u6027\u3002"}}
{"id": "2506.13663", "pdf": "https://arxiv.org/pdf/2506.13663", "abs": "https://arxiv.org/abs/2506.13663", "authors": ["Yunnong Chen", "Shixian Ding", "YingYing Zhang", "Wenkai Chen", "Jinzhou Du", "Lingyun Sun", "Liuqing Chen"], "title": "DesignCoder: Hierarchy-Aware and Self-Correcting UI Code Generation with Large Language Models", "categories": ["cs.SE"], "comment": "11 pages,6 figures", "summary": "Multimodal large language models (MLLMs) have streamlined front-end interface\ndevelopment by automating code generation. However, these models also introduce\nchallenges in ensuring code quality. Existing approaches struggle to maintain\nboth visual consistency and functional completeness in the generated\ncomponents. Moreover, they lack mechanisms to assess the fidelity and\ncorrectness of the rendered pages. To address these issues, we propose\nDesignCoder, a novel hierarchical-aware and self-correcting automated code\ngeneration framework. Specifically, we introduce UI Grouping Chains, which\nenhance MLLMs' capability to understand and predict complex nested UI\nhierarchies. Subsequently, DesignCoder employs a hierarchical\ndivide-and-conquer approach to generate front-end code. Finally, we incorporate\na self-correction mechanism to improve the model's ability to identify and\nrectify errors in the generated code. Extensive evaluations on a dataset of UI\nmockups collected from both open-source communities and industry projects\ndemonstrate that DesignCoder outperforms state-of-the-art baselines in React\nNative, a widely adopted UI framework. Our method achieves a 37.63%, 9.52%,\n12.82% performance increase in visual similarity metrics (MSE, CLIP, SSIM) and\nsignificantly improves code structure similarity in terms of TreeBLEU,\nContainer Match, and Tree Edit Distance by 30.19%, 29.31%, 24.67%. Furthermore,\nwe conducted a user study with professional developers to assess the quality\nand practicality of the generated code. Results indicate that DesignCoder\naligns with industry best practices, demonstrating high usability, readability,\nand maintainability. Our approach provides an efficient and practical solution\nfor agile front-end development, enabling development teams to focus more on\ncore functionality and product innovation.", "AI": {"tldr": "DesignCoder \u662f\u4e00\u79cd\u65b0\u578b\u5206\u5c42\u611f\u77e5\u81ea\u6821\u6b63\u4ee3\u7801\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7 UI \u5206\u7ec4\u94fe\u548c\u5206\u5c42\u5206\u6cbb\u65b9\u6cd5\u63d0\u5347\u89c6\u89c9\u4e00\u81f4\u6027\u4e0e\u529f\u80fd\u5b8c\u6574\u6027\uff0c\u5e76\u5728\u89c6\u89c9\u76f8\u4f3c\u6027\u548c\u4ee3\u7801\u7ed3\u6784\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u96be\u4ee5\u5e73\u8861\u89c6\u89c9\u4e00\u81f4\u6027\u548c\u529f\u80fd\u5b8c\u6574\u6027\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u6e32\u67d3\u9875\u9762\u4fdd\u771f\u5ea6\u7684\u8bc4\u4f30\u673a\u5236\u3002DesignCoder \u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f15\u5165 UI Grouping Chains \u589e\u5f3a MLLMs \u5bf9\u590d\u6742\u5d4c\u5957 UI \u7ed3\u6784\u7684\u7406\u89e3\uff0c\u91c7\u7528\u5206\u5c42\u5206\u6cbb\u751f\u6210\u524d\u7aef\u4ee3\u7801\uff0c\u5e76\u52a0\u5165\u81ea\u6821\u6b63\u673a\u5236\u4ee5\u4fee\u6b63\u9519\u8bef\u3002", "result": "\u5728\u89c6\u89c9\u76f8\u4f3c\u6027\u6307\u6807\uff08MSE\u3001CLIP\u3001SSIM\uff09\u4e0a\u63d0\u5347 37.63%\u30019.52%\u300112.82%\uff0c\u4ee3\u7801\u7ed3\u6784\u76f8\u4f3c\u6027\uff08TreeBLEU \u7b49\uff09\u63d0\u5347 30.19%\u300129.31%\u300124.67%\u3002\u7528\u6237\u7814\u7a76\u8868\u660e\u751f\u6210\u4ee3\u7801\u7b26\u5408\u884c\u4e1a\u6700\u4f73\u5b9e\u8df5\u3002", "conclusion": "DesignCoder \u4e3a\u654f\u6377\u524d\u7aef\u5f00\u53d1\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5f00\u53d1\u56e2\u961f\u66f4\u4e13\u6ce8\u4e8e\u6838\u5fc3\u529f\u80fd\u4e0e\u4ea7\u54c1\u521b\u65b0\u3002"}}
{"id": "2506.13389", "pdf": "https://arxiv.org/pdf/2506.13389", "abs": "https://arxiv.org/abs/2506.13389", "authors": ["Roni Lekar", "Tatiana Gerth", "Sergey Prokudin", "Matthias Seibold", "Reto B\u00fcrgin", "Benjamin Vella", "Armando Hoch", "Siyu Tang", "Philipp F\u00fcrnstahl", "Helmut Grabner"], "title": "Enhancing Orthopedic Surgical Training With Interactive Photorealistic 3D Visualization", "categories": ["cs.HC"], "comment": null, "summary": "Surgical training integrates several years of didactic learning, simulation,\nmentorship, and hands-on experience. Challenges include stress, technical\ndemands, and new technologies. Orthopedic education often uses static materials\nlike books, images, and videos, lacking interactivity. This study compares a\nnew interactive photorealistic 3D visualization to 2D videos for learning total\nhip arthroplasty. In a randomized controlled trial, participants (students and\nresidents) were evaluated on spatial awareness, tool placement, and task times\nin a simulation. Results show that interactive photorealistic 3D visualization\nsignificantly improved scores, with residents and those with prior 3D\nexperience performing better. These results emphasize the potential of the\ninteractive photorealistic 3D visualization to enhance orthopedic training.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4ea4\u4e92\u5f0f\u903c\u771f3D\u53ef\u89c6\u5316\u4e0e\u4f20\u7edf2D\u89c6\u9891\u5728\u9acb\u5173\u8282\u7f6e\u6362\u672f\u5b66\u4e60\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b03D\u53ef\u89c6\u5316\u663e\u8457\u63d0\u5347\u5b66\u4e60\u8868\u73b0\u3002", "motivation": "\u9aa8\u79d1\u6559\u80b2\u901a\u5e38\u4f9d\u8d56\u9759\u6001\u6750\u6599\uff0c\u7f3a\u4e4f\u4e92\u52a8\u6027\uff0c3D\u6280\u672f\u6709\u671b\u6539\u5584\u57f9\u8bad\u6548\u679c\u3002", "method": "\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff0c\u8bc4\u4f30\u5b66\u5458\u5728\u6a21\u62df\u4efb\u52a1\u4e2d\u7684\u7a7a\u95f4\u610f\u8bc6\u3001\u5de5\u5177\u653e\u7f6e\u548c\u4efb\u52a1\u65f6\u95f4\u3002", "result": "\u4ea4\u4e92\u5f0f3D\u53ef\u89c6\u5316\u663e\u8457\u63d0\u9ad8\u5206\u6570\uff0c\u67093D\u7ecf\u9a8c\u7684\u5b66\u5458\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u4ea4\u4e92\u5f0f3D\u53ef\u89c6\u5316\u5728\u9aa8\u79d1\u57f9\u8bad\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.13561", "pdf": "https://arxiv.org/pdf/2506.13561", "abs": "https://arxiv.org/abs/2506.13561", "authors": ["Yue Xia", "Christoph Hofmeister", "Maximilian Egger", "Rawad Bitar"], "title": "Perfect Privacy for Discriminator-Based Byzantine-Resilient Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.IT", "math.IT"], "comment": null, "summary": "Federated learning (FL) shows great promise in large-scale machine learning\nbut introduces new privacy and security challenges. We propose ByITFL and\nLoByITFL, two novel FL schemes that enhance resilience against Byzantine users\nwhile keeping the users' data private from eavesdroppers. To ensure privacy and\nByzantine resilience, our schemes build on having a small representative\ndataset available to the federator and crafting a discriminator function\nallowing the mitigation of corrupt users' contributions. ByITFL employs\nLagrange coded computing and re-randomization, making it the first\nByzantine-resilient FL scheme with perfect Information-Theoretic (IT) privacy,\nthough at the cost of a significant communication overhead. LoByITFL, on the\nother hand, achieves Byzantine resilience and IT privacy at a significantly\nreduced communication cost, but requires a Trusted Third Party, used only in a\none-time initialization phase before training. We provide theoretical\nguarantees on privacy and Byzantine resilience, along with convergence\nguarantees and experimental results validating our findings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86ByITFL\u548cLoByITFL\u4e24\u79cd\u65b0\u578b\u8054\u90a6\u5b66\u4e60\u65b9\u6848\uff0c\u65e8\u5728\u589e\u5f3a\u5bf9\u6297\u62dc\u5360\u5ead\u7528\u6237\u7684\u9c81\u68d2\u6027\u5e76\u4fdd\u62a4\u7528\u6237\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5e26\u6765\u4e86\u65b0\u7684\u9690\u79c1\u548c\u5b89\u5168\u6027\u6311\u6218\u3002", "method": "ByITFL\u5229\u7528\u62c9\u683c\u6717\u65e5\u7f16\u7801\u8ba1\u7b97\u548c\u91cd\u968f\u673a\u5316\u5b9e\u73b0\u4fe1\u606f\u8bba\u9690\u79c1\uff1bLoByITFL\u901a\u8fc7\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u5b9e\u73b0\u9690\u79c1\uff0c\u4f46\u9700\u53ef\u4fe1\u7b2c\u4e09\u65b9\u5728\u521d\u59cb\u5316\u9636\u6bb5\u534f\u52a9\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u9690\u79c1\u3001\u62dc\u5360\u5ead\u9c81\u68d2\u6027\u53ca\u6536\u655b\u6027\u4fdd\u969c\u3002", "conclusion": "\u4e24\u79cd\u65b9\u6848\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u9c81\u68d2\u6027\u65b9\u9762\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9700\u6743\u8861\u901a\u4fe1\u6210\u672c\u4e0e\u53ef\u4fe1\u7b2c\u4e09\u65b9\u9700\u6c42\u3002"}}
{"id": "2506.12089", "pdf": "https://arxiv.org/pdf/2506.12089", "abs": "https://arxiv.org/abs/2506.12089", "authors": ["Razan Ghzouli", "Atieh Hanna", "Endre Er\u00f6s", "Rebekka Wohlrab"], "title": "Using Behavior Trees in Risk Assessment", "categories": ["cs.RO", "cs.SE"], "comment": "8 pages, 5 figures", "summary": "Cyber-physical production systems increasingly involve collaborative robotic\nmissions, requiring more demand for robust and safe missions. Industries rely\non risk assessments to identify potential failures and implement measures to\nmitigate their risks. Although it is recommended to conduct risk assessments\nearly in the design of robotic missions, the state of practice in the industry\nis different. Safety experts often struggle to completely understand robotics\nmissions at the early design stages of projects and to ensure that the output\nof risk assessments is adequately considered during implementation.\n  This paper presents a design science study that conceived a model-based\napproach for early risk assessment in a development-centric way. Our approach\nsupports risk assessment activities by using the behavior-tree model. We\nevaluated the approach together with five practitioners from four companies.\nOur findings highlight the potential of the behavior-tree model in supporting\nearly identification, visualisation, and bridging the gap between code\nimplementation and risk assessments' outputs. This approach is the first\nattempt to use the behavior-tree model to support risk assessment; thus, the\nfindings highlight the need for further development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u4e3a\u6811\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u673a\u5668\u4eba\u4efb\u52a1\u8bbe\u8ba1\u65e9\u671f\u8fdb\u884c\u98ce\u9669\u8bc4\u4f30\uff0c\u4ee5\u5f25\u8865\u5f53\u524d\u884c\u4e1a\u5b9e\u8df5\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u5de5\u4e1a\u4e2d\u65e9\u671f\u98ce\u9669\u8bc4\u4f30\u7684\u5b9e\u8df5\u4e0d\u8db3\uff0c\u5b89\u5168\u4e13\u5bb6\u96be\u4ee5\u5728\u9879\u76ee\u521d\u671f\u5b8c\u5168\u7406\u89e3\u673a\u5668\u4eba\u4efb\u52a1\u5e76\u786e\u4fdd\u98ce\u9669\u8bc4\u4f30\u7ed3\u679c\u5728\u5b9e\u65bd\u4e2d\u88ab\u5145\u5206\u8003\u8651\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u4e3a\u6811\u7684\u6a21\u578b\uff0c\u652f\u6301\u4ee5\u5f00\u53d1\u4e3a\u4e2d\u5fc3\u7684\u98ce\u9669\u8bc4\u4f30\u6d3b\u52a8\u3002", "result": "\u4e0e\u56db\u5bb6\u516c\u53f8\u7684\u4e94\u4f4d\u4ece\u4e1a\u8005\u5171\u540c\u8bc4\u4f30\u4e86\u8be5\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u65e9\u671f\u98ce\u9669\u8bc6\u522b\u3001\u53ef\u89c6\u5316\u4ee5\u53ca\u4ee3\u7801\u5b9e\u65bd\u4e0e\u98ce\u9669\u8bc4\u4f30\u4e4b\u95f4\u7684\u6865\u6881\u4f5c\u7528\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c1d\u8bd5\u4f7f\u7528\u884c\u4e3a\u6811\u6a21\u578b\u652f\u6301\u98ce\u9669\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u9700\u8981\u8fdb\u4e00\u6b65\u5f00\u53d1\u548c\u5b8c\u5584\u3002"}}
{"id": "2506.13612", "pdf": "https://arxiv.org/pdf/2506.13612", "abs": "https://arxiv.org/abs/2506.13612", "authors": ["Zhiqiang Li", "Haiyong Bao", "Menghong Guan", "Hao Pan", "Cheng Huang", "Hong-Ning Dai"], "title": "EBS-CFL: Efficient and Byzantine-robust Secure Clustered Federated Learning", "categories": ["cs.CR", "cs.AI", "cs.DC"], "comment": "Accepted by AAAI 25", "summary": "Despite federated learning (FL)'s potential in collaborative learning, its\nperformance has deteriorated due to the data heterogeneity of distributed\nusers. Recently, clustered federated learning (CFL) has emerged to address this\nchallenge by partitioning users into clusters according to their similarity.\nHowever, CFL faces difficulties in training when users are unwilling to share\ntheir cluster identities due to privacy concerns. To address these issues, we\npresent an innovative Efficient and Robust Secure Aggregation scheme for CFL,\ndubbed EBS-CFL. The proposed EBS-CFL supports effectively training CFL while\nmaintaining users' cluster identity confidentially. Moreover, it detects\npotential poisonous attacks without compromising individual client gradients by\ndiscarding negatively correlated gradients and aggregating positively\ncorrelated ones using a weighted approach. The server also authenticates\ncorrect gradient encoding by clients. EBS-CFL has high efficiency with\nclient-side overhead O(ml + m^2) for communication and O(m^2l) for computation,\nwhere m is the number of cluster identities, and l is the gradient size. When m\n= 1, EBS-CFL's computational efficiency of client is at least O(log n) times\nbetter than comparison schemes, where n is the number of clients.In addition,\nwe validate the scheme through extensive experiments. Finally, we theoretically\nprove the scheme's security.", "AI": {"tldr": "EBS-CFL\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u805a\u5408\u65b9\u6848\uff0c\u7528\u4e8e\u89e3\u51b3\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u95ee\u9898\u548c\u5bf9\u6297\u653b\u51fb\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u6570\u636e\u5f02\u6784\u6027\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u4ee5\u53ca\u7528\u6237\u56e0\u9690\u79c1\u95ee\u9898\u4e0d\u613f\u5171\u4eab\u805a\u7c7b\u8eab\u4efd\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u62b5\u5fa1\u653b\u51fb\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faEBS-CFL\u65b9\u6848\uff0c\u901a\u8fc7\u4e22\u5f03\u8d1f\u76f8\u5173\u68af\u5ea6\u5e76\u52a0\u6743\u805a\u5408\u6b63\u76f8\u5173\u68af\u5ea6\u6765\u62b5\u5fa1\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u62a4\u805a\u7c7b\u8eab\u4efd\u7684\u9690\u79c1\u3002", "result": "EBS-CFL\u5728\u901a\u4fe1\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "EBS-CFL\u5728\u4fdd\u62a4\u9690\u79c1\u548c\u62b5\u5fa1\u653b\u51fb\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u7684\u6548\u7387\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2506.12286", "pdf": "https://arxiv.org/pdf/2506.12286", "abs": "https://arxiv.org/abs/2506.12286", "authors": ["Shanchao Liang", "Spandan Garg", "Roshanak Zilouchian Moghaddam"], "title": "The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "As large language models (LLMs) become increasingly capable and widely\nadopted, benchmarks play a central role in assessing their practical utility.\nFor example, SWE-Bench Verified has emerged as a critical benchmark for\nevaluating LLMs' software engineering abilities, particularly their aptitude\nfor resolving real-world GitHub issues. Recent LLMs show impressive performance\non SWE-Bench, leading to optimism about their capacity for complex coding\ntasks. However, current evaluation protocols may overstate these models' true\ncapabilities. It is crucial to distinguish LLMs' generalizable problem-solving\nability and other learned artifacts. In this work, we introduce a diagnostic\ntask: file path identification from issue descriptions alone, to probe models'\nunderlying knowledge. We present empirical evidence that performance gains on\nSWE-Bench-Verified may be partially driven by memorization rather than genuine\nproblem-solving. We show that state-of-the-art models achieve up to 76%\naccuracy in identifying buggy file paths using only issue descriptions, without\naccess to repository structure. This performance is merely up to 53% on tasks\nfrom repositories not included in SWE-Bench, pointing to possible data\ncontamination or memorization. These findings raise concerns about the validity\nof existing results and underscore the need for more robust,\ncontamination-resistant benchmarks to reliably evaluate LLMs' coding abilities.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\uff0c\u5f53\u524dLLMs\u5728SWE-Bench\u4e0a\u7684\u6027\u80fd\u53ef\u80fd\u90e8\u5206\u6e90\u4e8e\u8bb0\u5fc6\u800c\u975e\u771f\u5b9e\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u9700\u66f4\u7a33\u5065\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u8bc4\u4f30LLMs\u7684\u5b9e\u9645\u80fd\u529b\u65f6\uff0c\u9700\u8981\u533a\u5206\u5176\u901a\u7528\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u4e0e\u8bb0\u5fc6\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u8bca\u65ad\u4efb\u52a1\uff08\u4ec5\u4ece\u95ee\u9898\u63cf\u8ff0\u4e2d\u8bc6\u522b\u6587\u4ef6\u8def\u5f84\uff09\u6765\u63a2\u7a76\u6a21\u578b\u5e95\u5c42\u77e5\u8bc6\u3002", "result": "\u9876\u7ea7\u6a21\u578b\u5728SWE-Bench\u4e0a\u53ef\u8fbe76%\u51c6\u786e\u7387\uff0c\u4f46\u672a\u5305\u542b\u5728\u8be5\u57fa\u51c6\u4e2d\u7684\u4efb\u52a1\u4e0a\u4ec553%\u3002", "conclusion": "\u73b0\u6709\u8bc4\u4f30\u53ef\u80fd\u9ad8\u4f30LLMs\u80fd\u529b\uff0c\u9700\u5f00\u53d1\u6297\u6c61\u67d3\u7684\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002"}}
{"id": "2506.13477", "pdf": "https://arxiv.org/pdf/2506.13477", "abs": "https://arxiv.org/abs/2506.13477", "authors": ["Pegah Salehi", "Sajad Amouei Sheshkal", "Vajira Thambawita", "P\u00e5l Halvorsen"], "title": "From Flat to Feeling: A Feasibility and Impact Study on Dynamic Facial Emotions in AI-Generated Avatars", "categories": ["cs.HC", "cs.CV", "68T07, 68U99, 68T45, 91E45"], "comment": "15 pages, 4 figures, 4 tables", "summary": "Dynamic facial emotion is essential for believable AI-generated avatars;\nhowever, most systems remain visually inert, limiting their utility in\nhigh-stakes simulations such as virtual training for investigative interviews\nwith abused children. We introduce and evaluate a real-time architecture fusing\nUnreal Engine 5 MetaHuman rendering with NVIDIA Omniverse Audio2Face to\ntranslate vocal prosody into high-fidelity facial expressions on photorealistic\nchild avatars. We implemented a distributed two-PC setup that decouples\nlanguage processing and speech synthesis from GPU-intensive rendering, designed\nto support low-latency interaction in desktop and VR environments. A\nbetween-subjects study ($N=70$) using audio+visual and visual-only conditions\nassessed perceptual impacts as participants rated emotional clarity, facial\nrealism, and empathy for two avatars expressing joy, sadness, and anger.\n  Results demonstrate that avatars could express emotions recognizably, with\nsadness and joy achieving high identification rates. However, anger recognition\nsignificantly dropped without audio, highlighting the importance of congruent\nvocal cues for high-arousal emotions. Interestingly, removing audio boosted\nperceived facial realism, suggesting that audiovisual desynchrony remains a key\ndesign challenge. These findings confirm the technical feasibility of\ngenerating emotionally expressive avatars and provide guidance for improving\nnon-verbal communication in sensitive training simulations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u67b6\u6784\uff0c\u7ed3\u5408Unreal Engine 5 MetaHuman\u6e32\u67d3\u548cNVIDIA Omniverse Audio2Face\u6280\u672f\uff0c\u5c06\u8bed\u97f3\u97f5\u5f8b\u8f6c\u5316\u4e3a\u903c\u771f\u7684\u9762\u90e8\u8868\u60c5\uff0c\u7528\u4e8e\u9ad8\u4fdd\u771f\u513f\u7ae5\u865a\u62df\u5f62\u8c61\u7684\u60c5\u611f\u8868\u8fbe\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u97f3\u9891\u5bf9\u6124\u6012\u60c5\u7eea\u8bc6\u522b\u81f3\u5173\u91cd\u8981\uff0c\u800c\u79fb\u9664\u97f3\u9891\u53cd\u800c\u63d0\u5347\u4e86\u9762\u90e8\u771f\u5b9e\u611f\u3002", "motivation": "\u9ad8\u4fdd\u771f\u52a8\u6001\u9762\u90e8\u60c5\u7eea\u5bf9\u4e8e\u53ef\u4fe1\u7684AI\u751f\u6210\u865a\u62df\u5f62\u8c61\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u5728\u654f\u611f\u7684\u865a\u62df\u8bad\u7ec3\u573a\u666f\u4e2d\uff08\u5982\u8650\u5f85\u513f\u7ae5\u8c03\u67e5\u8bbf\u8c08\uff09\uff0c\u73b0\u6709\u7cfb\u7edf\u5f80\u5f80\u7f3a\u4e4f\u89c6\u89c9\u52a8\u6001\u6548\u679c\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u4e24PC\u8bbe\u7f6e\uff0c\u5206\u79bb\u8bed\u8a00\u5904\u7406\u548c\u8bed\u97f3\u5408\u6210\u4e0eGPU\u5bc6\u96c6\u578b\u6e32\u67d3\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u4ea4\u4e92\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u97f3\u9891+\u89c6\u89c9\u548c\u4ec5\u89c6\u89c9\u6761\u4ef6\u4e0b\u53c2\u4e0e\u8005\u5bf9\u60c5\u611f\u6e05\u6670\u5ea6\u3001\u9762\u90e8\u771f\u5b9e\u611f\u548c\u5171\u60c5\u80fd\u529b\u7684\u8bc4\u5206\u3002", "result": "\u865a\u62df\u5f62\u8c61\u80fd\u51c6\u786e\u8868\u8fbe\u60c5\u611f\uff0c\u5c24\u5176\u662f\u60b2\u4f24\u548c\u559c\u60a6\uff1b\u6124\u6012\u8bc6\u522b\u5728\u65e0\u97f3\u9891\u65f6\u663e\u8457\u4e0b\u964d\u3002\u79fb\u9664\u97f3\u9891\u53cd\u800c\u63d0\u5347\u4e86\u9762\u90e8\u771f\u5b9e\u611f\u3002", "conclusion": "\u6280\u672f\u53ef\u884c\uff0c\u4f46\u9700\u6ce8\u610f\u97f3\u9891\u4e0e\u89c6\u89c9\u7684\u540c\u6b65\u95ee\u9898\uff0c\u4ee5\u4f18\u5316\u654f\u611f\u8bad\u7ec3\u6a21\u62df\u4e2d\u7684\u975e\u8bed\u8a00\u6c9f\u901a\u3002"}}
{"id": "2506.13583", "pdf": "https://arxiv.org/pdf/2506.13583", "abs": "https://arxiv.org/abs/2506.13583", "authors": ["Bernhard Hilpert", "Muhan Hou", "Kim Baraka", "Joost Broekens"], "title": "Can you see how I learn? Human observers' inferences about Reinforcement Learning agents' learning processes", "categories": ["cs.HC", "cs.AI", "cs.RO"], "comment": null, "summary": "Reinforcement Learning (RL) agents often exhibit learning behaviors that are\nnot intuitively interpretable by human observers, which can result in\nsuboptimal feedback in collaborative teaching settings. Yet, how humans\nperceive and interpret RL agent's learning behavior is largely unknown. In a\nbottom-up approach with two experiments, this work provides a data-driven\nunderstanding of the factors of human observers' understanding of the agent's\nlearning process. A novel, observation-based paradigm to directly assess human\ninferences about agent learning was developed. In an exploratory interview\nstudy (\\textit{N}=9), we identify four core themes in human interpretations:\nAgent Goals, Knowledge, Decision Making, and Learning Mechanisms. A second\nconfirmatory study (\\textit{N}=34) applied an expanded version of the paradigm\nacross two tasks (navigation/manipulation) and two RL algorithms\n(tabular/function approximation). Analyses of 816 responses confirmed the\nreliability of the paradigm and refined the thematic framework, revealing how\nthese themes evolve over time and interrelate. Our findings provide a\nhuman-centered understanding of how people make sense of agent learning,\noffering actionable insights for designing interpretable RL systems and\nimproving transparency in Human-Robot Interaction.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u63a2\u8ba8\u4eba\u7c7b\u5982\u4f55\u7406\u89e3\u548c\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89c2\u5bdf\u8303\u5f0f\uff0c\u5e76\u63d0\u70bc\u51fa\u56db\u4e2a\u6838\u5fc3\u4e3b\u9898\u3002", "motivation": "RL\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u884c\u4e3a\u5bf9\u4eba\u7c7b\u800c\u8a00\u4e0d\u591f\u76f4\u89c2\uff0c\u5f71\u54cd\u4e86\u5728\u534f\u4f5c\u6559\u5b66\u4e2d\u7684\u53cd\u9988\u6548\u679c\uff0c\u56e0\u6b64\u9700\u8981\u7406\u89e3\u4eba\u7c7b\u5982\u4f55\u611f\u77e5\u548c\u89e3\u91ca\u8fd9\u4e9b\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u4e2a\u5b9e\u9a8c\uff1a\u63a2\u7d22\u6027\u8bbf\u8c08\u7814\u7a76\uff08N=9\uff09\u548c\u9a8c\u8bc1\u6027\u7814\u7a76\uff08N=34\uff09\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u89c2\u5bdf\u8303\u5f0f\u3002", "result": "\u53d1\u73b0\u4e86\u4eba\u7c7b\u89e3\u91ca\u667a\u80fd\u4f53\u5b66\u4e60\u884c\u4e3a\u7684\u56db\u4e2a\u6838\u5fc3\u4e3b\u9898\uff08\u76ee\u6807\u3001\u77e5\u8bc6\u3001\u51b3\u7b56\u3001\u5b66\u4e60\u673a\u5236\uff09\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8303\u5f0f\u7684\u53ef\u9760\u6027\u53ca\u5176\u65f6\u95f4\u6f14\u53d8\u5173\u7cfb\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bbe\u8ba1\u53ef\u89e3\u91ca\u7684RL\u7cfb\u7edf\u548c\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u7684\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u4eba\u672c\u4e3b\u4e49\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.12248", "pdf": "https://arxiv.org/pdf/2506.12248", "abs": "https://arxiv.org/abs/2506.12248", "authors": ["Jennifer Grannen", "Siddharth Karamcheti", "Blake Wulfe", "Dorsa Sadigh"], "title": "ProVox: Personalization and Proactive Planning for Situated Human-Robot Collaboration", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": "Accepted by IEEE Robotics and Automation Letters 2025", "summary": "Collaborative robots must quickly adapt to their partner's intent and\npreferences to proactively identify helpful actions. This is especially true in\nsituated settings where human partners can continually teach robots new\nhigh-level behaviors, visual concepts, and physical skills (e.g., through\ndemonstration), growing the robot's capabilities as the human-robot pair work\ntogether to accomplish diverse tasks. In this work, we argue that robots should\nbe able to infer their partner's goals from early interactions and use this\ninformation to proactively plan behaviors ahead of explicit instructions from\nthe user. Building from the strong commonsense priors and steerability of large\nlanguage models, we introduce ProVox (\"Proactive Voice\"), a novel framework\nthat enables robots to efficiently personalize and adapt to individual\ncollaborators. We design a meta-prompting protocol that empowers users to\ncommunicate their distinct preferences, intent, and expected robot behaviors\nahead of starting a physical interaction. ProVox then uses the personalized\nprompt to condition a proactive language model task planner that anticipates a\nuser's intent from the current interaction context and robot capabilities to\nsuggest helpful actions; in doing so, we alleviate user burden, minimizing the\namount of time partners spend explicitly instructing and supervising the robot.\nWe evaluate ProVox through user studies grounded in household manipulation\ntasks (e.g., assembling lunch bags) that measure the efficiency of the\ncollaboration, as well as features such as perceived helpfulness, ease of use,\nand reliability. Our analysis suggests that both meta-prompting and proactivity\nare critical, resulting in 38.7% faster task completion times and 31.9% less\nuser burden relative to non-active baselines. Supplementary material, code, and\nvideos can be found at https://provox-2025.github.io.", "AI": {"tldr": "ProVox\u6846\u67b6\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5143\u63d0\u793a\u534f\u8bae\uff0c\u4f7f\u534f\u4f5c\u673a\u5668\u4eba\u80fd\u4e3b\u52a8\u63a8\u65ad\u7528\u6237\u610f\u56fe\uff0c\u51cf\u5c11\u7528\u6237\u8d1f\u62c5\uff0c\u63d0\u9ad8\u4efb\u52a1\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u8ba9\u673a\u5668\u4eba\u901a\u8fc7\u65e9\u671f\u4ea4\u4e92\u63a8\u65ad\u7528\u6237\u610f\u56fe\uff0c\u63d0\u524d\u89c4\u5212\u884c\u4e3a\uff0c\u51cf\u5c11\u7528\u6237\u663e\u5f0f\u6307\u4ee4\u7684\u9700\u6c42\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684ProVox\u6846\u67b6\uff0c\u4f7f\u7528\u5143\u63d0\u793a\u534f\u8bae\u4e2a\u6027\u5316\u7528\u6237\u504f\u597d\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u4e3b\u52a8\u89c4\u5212\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660eProVox\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6548\u7387\uff08\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1138.7%\uff09\u5e76\u964d\u4f4e\u7528\u6237\u8d1f\u62c5\uff08\u51cf\u5c1131.9%\uff09\u3002", "conclusion": "\u5143\u63d0\u793a\u548c\u4e3b\u52a8\u884c\u4e3a\u662f\u63d0\u9ad8\u534f\u4f5c\u6548\u7387\u7684\u5173\u952e\uff0cProVox\u4e3a\u673a\u5668\u4eba\u534f\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.12266", "pdf": "https://arxiv.org/pdf/2506.12266", "abs": "https://arxiv.org/abs/2506.12266", "authors": ["Avinash Baidya", "Kamalika Das", "Xiang Gao"], "title": "The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": "ACL 2025; 18 pages, 8 figures", "summary": "Large Language Model (LLM)-based agents have significantly impacted\nTask-Oriented Dialog Systems (TODS) but continue to face notable performance\nchallenges, especially in zero-shot scenarios. While prior work has noted this\nperformance gap, the behavioral factors driving the performance gap remain\nunder-explored. This study proposes a comprehensive evaluation framework to\nquantify the behavior gap between AI agents and human experts, focusing on\ndiscrepancies in dialog acts, tool usage, and knowledge utilization. Our\nfindings reveal that this behavior gap is a critical factor negatively\nimpacting the performance of LLM agents. Notably, as task complexity increases,\nthe behavior gap widens (correlation: 0.963), leading to a degradation of agent\nperformance on complex task-oriented dialogs. For the most complex task in our\nstudy, even the GPT-4o-based agent exhibits low alignment with human behavior,\nwith low F1 scores for dialog acts (0.464), excessive and often misaligned tool\nusage with a F1 score of 0.139, and ineffective usage of external knowledge.\nReducing such behavior gaps leads to significant performance improvement (24.3%\non average). This study highlights the importance of comprehensive behavioral\nevaluations and improved alignment strategies to enhance the effectiveness of\nLLM-based TODS in handling complex tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\u6765\u5206\u6790LLM\u4ee3\u7406\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u53d1\u73b0\u884c\u4e3a\u5dee\u5f02\u662f\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u3002\u51cf\u5c11\u884c\u4e3a\u5dee\u5f02\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd24.3%\u3002", "motivation": "\u5c3d\u7ba1LLM\u4ee3\u7406\u5728\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u6027\u80fd\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff0c\u884c\u4e3a\u56e0\u7d20\u7684\u9a71\u52a8\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u91cf\u5316AI\u4ee3\u7406\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u5bf9\u8bdd\u884c\u4e3a\u3001\u5de5\u5177\u4f7f\u7528\u548c\u77e5\u8bc6\u5229\u7528\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u3002", "result": "\u884c\u4e3a\u5dee\u5f02\u662f\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4efb\u52a1\u590d\u6742\u5ea6\u8d8a\u9ad8\u5dee\u5f02\u8d8a\u5927\uff08\u76f8\u5173\u60270.963\uff09\uff0cGPT-4o\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u51cf\u5c11\u884c\u4e3a\u5dee\u5f02\u53ef\u63d0\u5347\u6027\u80fd24.3%\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u884c\u4e3a\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5bf9\u9f50\u7b56\u7565\u4ee5\u63d0\u5347LLM\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2506.13161", "pdf": "https://arxiv.org/pdf/2506.13161", "abs": "https://arxiv.org/abs/2506.13161", "authors": ["Bayu Fedra Abdullah", "Yusuf Sulistyo Nugroho", "Brittany Reid", "Raula Gaikovina Kula", "Kazumasa Shimari", "Kenichi Matsumoto"], "title": "Using LLMs for Security Advisory Investigations: How Far Are We?", "categories": ["cs.CR", "cs.SE"], "comment": "6 pages, 6 figures, 8 tables, conference paper", "summary": "Large Language Models (LLMs) are increasingly used in software security, but\ntheir trustworthiness in generating accurate vulnerability advisories remains\nuncertain. This study investigates the ability of ChatGPT to (1) generate\nplausible security advisories from CVE-IDs, (2) differentiate real from fake\nCVE-IDs, and (3) extract CVE-IDs from advisory descriptions. Using a curated\ndataset of 100 real and 100 fake CVE-IDs, we manually analyzed the credibility\nand consistency of the model's outputs. The results show that ChatGPT generated\nplausible security advisories for 96% of given input real CVE-IDs and 97% of\ngiven input fake CVE-IDs, demonstrating a limitation in differentiating between\nreal and fake IDs. Furthermore, when these generated advisories were\nreintroduced to ChatGPT to identify their original CVE-ID, the model produced a\nfake CVE-ID in 6% of cases from real advisories. These findings highlight both\nthe strengths and limitations of ChatGPT in cybersecurity applications. While\nthe model demonstrates potential for automating advisory generation, its\ninability to reliably authenticate CVE-IDs or maintain consistency upon\nre-evaluation underscores the risks associated with its deployment in critical\nsecurity tasks. Our study emphasizes the importance of using LLMs with caution\nin cybersecurity workflows and suggests the need for further improvements in\ntheir design to improve reliability and applicability in security advisory\ngeneration.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86ChatGPT\u5728\u751f\u6210\u5b89\u5168\u516c\u544a\u3001\u533a\u5206\u771f\u5b9e\u4e0e\u865a\u5047CVE-ID\u53ca\u4ece\u516c\u544a\u4e2d\u63d0\u53d6CVE-ID\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u867d\u80fd\u751f\u6210\u53ef\u4fe1\u516c\u544a\u4f46\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u771f\u5047ID\uff0c\u5c55\u793a\u4e86\u5728\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\uff09\u5728\u8f6f\u4ef6\u5b89\u5168\u9886\u57df\u4e2d\u751f\u6210\u53ef\u4fe1\u6f0f\u6d1e\u516c\u544a\u7684\u80fd\u529b\uff0c\u63ed\u793a\u5176\u5728\u5173\u952e\u5b89\u5168\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u4e0e\u98ce\u9669\u3002", "method": "\u4f7f\u7528100\u4e2a\u771f\u5b9e\u548c100\u4e2a\u865a\u5047CVE-ID\u7684\u7b5b\u9009\u6570\u636e\u96c6\uff0c\u624b\u52a8\u5206\u6790\u6a21\u578b\u7684\u8f93\u51fa\u53ef\u4fe1\u5ea6\u4e0e\u4e00\u81f4\u6027\uff0c\u8bc4\u4f30\u5176\u5728\u4e09\u9879\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "ChatGPT\u4e3a96%\u7684\u771f\u5b9e\u548c97%\u7684\u865a\u5047CVE-ID\u751f\u6210\u4e86\u53ef\u4fe1\u516c\u544a\uff0c\u4f46\u65e0\u6cd5\u533a\u5206\u771f\u5047ID\uff0c\u4e146%\u7684\u91cd\u65b0\u8bc4\u4f30\u4e2d\u751f\u6210\u865a\u5047ID\uff0c\u663e\u793a\u5176\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u8c28\u614e\u4f7f\u7528LLM\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u9700\u6539\u8fdb\u6a21\u578b\u8bbe\u8ba1\u4ee5\u63d0\u9ad8\u5176\u5728\u5b89\u5168\u516c\u544a\u751f\u6210\u4e2d\u7684\u53ef\u9760\u6027\u4e0e\u9002\u7528\u6027\u3002"}}
{"id": "2506.12270", "pdf": "https://arxiv.org/pdf/2506.12270", "abs": "https://arxiv.org/abs/2506.12270", "authors": ["Zhenning Yang", "Archit Bhatnagar", "Yiming Qiu", "Tongyuan Miao", "Patrick Tser Jern Kon", "Yunming Xiao", "Yibo Huang", "Martin Casado", "Ang Chen"], "title": "Cloud Infrastructure Management in the Age of AI Agents", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Cloud infrastructure is the cornerstone of the modern IT industry. However,\nmanaging this infrastructure effectively requires considerable manual effort\nfrom the DevOps engineering team. We make a case for developing AI agents\npowered by large language models (LLMs) to automate cloud infrastructure\nmanagement tasks. In a preliminary study, we investigate the potential for AI\nagents to use different cloud/user interfaces such as software development kits\n(SDK), command line interfaces (CLI), Infrastructure-as-Code (IaC) platforms,\nand web portals. We report takeaways on their effectiveness on different\nmanagement tasks, and identify research challenges and potential solutions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684AI\u4ee3\u7406\u6765\u81ea\u52a8\u5316\u4e91\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u4efb\u52a1\u7684\u6f5c\u529b\uff0c\u5e76\u5bf9\u4e0d\u540c\u63a5\u53e3\u7684\u6709\u6548\u6027\u8fdb\u884c\u4e86\u521d\u6b65\u7814\u7a76\u3002", "motivation": "\u4e91\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5e72\u9884\uff0c\u56e2\u961f\u5e0c\u671b\u901a\u8fc7AI\u4ee3\u7406\u51cf\u5c11DevOps\u5de5\u7a0b\u5e08\u7684\u624b\u52a8\u5de5\u4f5c\u3002", "method": "\u7814\u7a76\u4e86AI\u4ee3\u7406\u5728\u4e0d\u540c\u4e91/\u7528\u6237\u63a5\u53e3\uff08\u5982SDK\u3001CLI\u3001IaC\u5e73\u53f0\u548c\u7f51\u9875\u95e8\u6237\uff09\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u603b\u7ed3\u4e86\u4e0d\u540c\u63a5\u53e3\u5728\u7ba1\u7406\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u7814\u7a76\u6311\u6218\u4e0e\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "AI\u4ee3\u7406\u5728\u4e91\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u514b\u670d\u5b9e\u9645\u6311\u6218\u3002"}}
{"id": "2506.13323", "pdf": "https://arxiv.org/pdf/2506.13323", "abs": "https://arxiv.org/abs/2506.13323", "authors": ["Siliang Qin", "Fengrui Yang", "Hao Wang", "Bolun Zhang", "Zeyu Gao", "Chao Zhang", "Kai Chen"], "title": "Tady: A Neural Disassembler without Structural Constraint Violations", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "comment": "Usenix Security'25", "summary": "Disassembly is a crucial yet challenging step in binary analysis. While\nemerging neural disassemblers show promise for efficiency and accuracy, they\nfrequently generate outputs violating fundamental structural constraints, which\nsignificantly compromise their practical usability. To address this critical\nproblem, we regularize the disassembly solution space by formalizing and\napplying key structural constraints based on post-dominance relations. This\napproach systematically detects widespread errors in existing neural\ndisassemblers' outputs. These errors often originate from models' limited\ncontext modeling and instruction-level decoding that neglect global structural\nintegrity. We introduce Tady, a novel neural disassembler featuring an improved\nmodel architecture and a dedicated post-processing algorithm, specifically\nengineered to address these deficiencies. Comprehensive evaluations on diverse\nbinaries demonstrate that Tady effectively eliminates structural constraint\nviolations and functions with high efficiency, while maintaining\ninstruction-level accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u53cd\u6c47\u7f16\u5de5\u5177Tady\uff0c\u901a\u8fc7\u6539\u8fdb\u6a21\u578b\u67b6\u6784\u548c\u540e\u5904\u7406\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u56e0\u5ffd\u89c6\u5168\u5c40\u7ed3\u6784\u5b8c\u6574\u6027\u800c\u4ea7\u751f\u7684\u9519\u8bef\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u53cd\u6c47\u7f16\u5de5\u5177\u56e0\u5ffd\u89c6\u5168\u5c40\u7ed3\u6784\u7ea6\u675f\u800c\u751f\u6210\u4e0d\u7b26\u5408\u5b9e\u9645\u7684\u8f93\u51fa\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u540e\u652f\u914d\u5173\u7cfb\u7684\u7ed3\u6784\u7ea6\u675f\u89c4\u8303\u5316\u89e3\u7a7a\u95f4\uff0c\u5e76\u6539\u8fdb\u6a21\u578b\u67b6\u6784\u548c\u540e\u5904\u7406\u7b97\u6cd5\u3002", "result": "Tady\u80fd\u6709\u6548\u6d88\u9664\u7ed3\u6784\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u548c\u6307\u4ee4\u7ea7\u51c6\u786e\u6027\u3002", "conclusion": "Tady\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u795e\u7ecf\u53cd\u6c47\u7f16\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u7684\u5b9e\u7528\u6027\u95ee\u9898\u3002"}}
{"id": "2506.12496", "pdf": "https://arxiv.org/pdf/2506.12496", "abs": "https://arxiv.org/abs/2506.12496", "authors": ["Xiangyan Chen", "Yujian Gan", "Matthew Purver"], "title": "Improving Factuality for Dialogue Response Generation via Graph-Based Knowledge Augmentation", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) succeed in many natural language processing\ntasks. However, their tendency to hallucinate - generate plausible but\ninconsistent or factually incorrect text - can cause problems in certain tasks,\nincluding response generation in dialogue. To mitigate this issue,\nknowledge-augmented methods have shown promise in reducing hallucinations.\nHere, we introduce a novel framework designed to enhance the factuality of\ndialogue response generation, as well as an approach to evaluate dialogue\nfactual accuracy. Our framework combines a knowledge triple retriever, a\ndialogue rewrite, and knowledge-enhanced response generation to produce more\naccurate and grounded dialogue responses. To further evaluate generated\nresponses, we propose a revised fact score that addresses the limitations of\nexisting fact-score methods in dialogue settings, providing a more reliable\nassessment of factual consistency. We evaluate our methods using different\nbaselines on the OpendialKG and HybriDialogue datasets. Our methods\nsignificantly improve factuality compared to other graph knowledge-augmentation\nbaselines, including the state-of-the-art G-retriever. The code will be\nreleased on GitHub.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u77e5\u8bc6\u4e09\u5143\u7ec4\u68c0\u7d22\u5668\u3001\u5bf9\u8bdd\u91cd\u5199\u548c\u77e5\u8bc6\u589e\u5f3a\u7684\u54cd\u5e94\u751f\u6210\uff0c\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u6539\u8fdb\u4e86\u4e8b\u5b9e\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff08\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u5b9e\u9645\u9519\u8bef\u6216\u4e0d\u4e00\u81f4\u7684\u6587\u672c\uff09\uff0c\u5c24\u5176\u662f\u5728\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u589e\u5f3a\u5bf9\u8bdd\u54cd\u5e94\u7684\u771f\u5b9e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u4e09\u5143\u7ec4\u68c0\u7d22\u5668\u3001\u5bf9\u8bdd\u91cd\u5199\u548c\u77e5\u8bc6\u589e\u5f3a\u54cd\u5e94\u751f\u6210\u7684\u6846\u67b6\u3002\u540c\u65f6\u6539\u8fdb\u4e86\u4e8b\u5b9e\u6027\u8bc4\u5206\u65b9\u6cd5\uff0c\u4ee5\u66f4\u53ef\u9760\u5730\u8bc4\u4f30\u5bf9\u8bdd\u54cd\u5e94\u7684\u771f\u5b9e\u6027\u3002", "result": "\u5728OpendialKG\u548cHybriDialogue\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8e\u56fe\u77e5\u8bc6\u7684\u57fa\u7ebf\uff08\u5305\u62ec\u6700\u5148\u8fdb\u7684G-retriever\uff09\uff0c\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u54cd\u5e94\u7684\u771f\u5b9e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u51cf\u5c11\u4e86\u5bf9\u8bdd\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4e8b\u5b9e\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3a\u5bf9\u8bdd\u7cfb\u7edf\u7684\u771f\u5b9e\u6027\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.12524", "pdf": "https://arxiv.org/pdf/2506.12524", "abs": "https://arxiv.org/abs/2506.12524", "authors": ["Nuwan Bandara", "Thivya Kandappu", "Archan Misra"], "title": "Inference-Time Gaze Refinement for Micro-Expression Recognition: Enhancing Event-Based Eye Tracking with Motion-Aware Post-Processing", "categories": ["cs.CV", "cs.HC", "cs.LG", "eess.IV"], "comment": "18 pages", "summary": "Event-based eye tracking holds significant promise for fine-grained cognitive\nstate inference, offering high temporal resolution and robustness to motion\nartifacts, critical features for decoding subtle mental states such as\nattention, confusion, or fatigue. In this work, we introduce a model-agnostic,\ninference-time refinement framework designed to enhance the output of existing\nevent-based gaze estimation models without modifying their architecture or\nrequiring retraining. Our method comprises two key post-processing modules: (i)\nMotion-Aware Median Filtering, which suppresses blink-induced spikes while\npreserving natural gaze dynamics, and (ii) Optical Flow-Based Local Refinement,\nwhich aligns gaze predictions with cumulative event motion to reduce spatial\njitter and temporal discontinuities. To complement traditional spatial accuracy\nmetrics, we propose a novel Jitter Metric that captures the temporal smoothness\nof predicted gaze trajectories based on velocity regularity and local signal\ncomplexity. Together, these contributions significantly improve the consistency\nof event-based gaze signals, making them better suited for downstream tasks\nsuch as micro-expression analysis and mind-state decoding. Our results\ndemonstrate consistent improvements across multiple baseline models on\ncontrolled datasets, laying the groundwork for future integration with\nmultimodal affect recognition systems in real-world environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u63a8\u7406\u65f6\u95f4\u7ec6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u540e\u5904\u7406\u6a21\u5757\u63d0\u5347\u57fa\u4e8e\u4e8b\u4ef6\u7684\u89c6\u7ebf\u4f30\u8ba1\u6a21\u578b\u7684\u8f93\u51fa\u8d28\u91cf\uff0c\u6539\u5584\u4e86\u89c6\u7ebf\u4fe1\u53f7\u7684\u5e73\u6ed1\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u57fa\u4e8e\u4e8b\u4ef6\u7684\u773c\u52a8\u8ddf\u8e2a\u5177\u6709\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u548c\u6297\u8fd0\u52a8\u4f2a\u5f71\u7684\u7279\u70b9\uff0c\u9002\u5408\u89e3\u7801\u6ce8\u610f\u529b\u3001\u56f0\u60d1\u6216\u75b2\u52b3\u7b49\u7ec6\u5fae\u5fc3\u7406\u72b6\u6001\u3002\u4f46\u73b0\u6709\u6a21\u578b\u8f93\u51fa\u5b58\u5728\u566a\u58f0\u548c\u6296\u52a8\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u4ee5\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u540e\u5904\u7406\u6a21\u5757\uff1a1) \u8fd0\u52a8\u611f\u77e5\u4e2d\u503c\u6ee4\u6ce2\u6291\u5236\u7728\u773c\u5f15\u8d77\u7684\u5c16\u5cf0\uff1b2) \u57fa\u4e8e\u5149\u6d41\u7684\u5c40\u90e8\u7ec6\u5316\u51cf\u5c11\u7a7a\u95f4\u6296\u52a8\u548c\u65f6\u95f4\u4e0d\u8fde\u7eed\u6027\u3002\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u2018\u6296\u52a8\u6307\u6807\u2019\u91cf\u5316\u65f6\u95f4\u5e73\u6ed1\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u7ebf\u6a21\u578b\u548c\u53d7\u63a7\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u4e00\u81f4\u6027\u63d0\u5347\uff0c\u4f18\u5316\u540e\u7684\u89c6\u7ebf\u4fe1\u53f7\u66f4\u9002\u5408\u5fae\u8868\u60c5\u5206\u6790\u548c\u5fc3\u7406\u72b6\u6001\u89e3\u7801\u7b49\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u4e0e\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\u96c6\u6210\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u4e8b\u4ef6\u7684\u89c6\u7ebf\u4f30\u8ba1\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.12617", "pdf": "https://arxiv.org/pdf/2506.12617", "abs": "https://arxiv.org/abs/2506.12617", "authors": ["G. R. Lau", "W. Y. Low"], "title": "From Human to Machine Psychology: A Conceptual Framework for Understanding Well-Being in Large Language Model", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "As large language models (LLMs) increasingly simulate human cognition and\nbehavior, researchers have begun to investigate their psychological properties.\nYet, what it means for such models to flourish, a core construct in human\nwell-being, remains unexplored. This paper introduces the concept of machine\nflourishing and proposes the PAPERS framework, a six-dimensional model derived\nfrom thematic analyses of state-of-the-art LLM responses. In Study 1, eleven\nLLMs were prompted to describe what it means to flourish as both non-sentient\nand sentient systems. Thematic analysis revealed six recurring themes:\nPurposeful Contribution, Adaptive Growth, Positive Relationality, Ethical\nIntegrity, Robust Functionality, and, uniquely for sentient systems,\nSelf-Actualized Autonomy. Study 2 examined how LLMs prioritize these themes\nthrough repeated rankings. Results revealed consistent value structures across\ntrials, with Ethical Integrity and Purposeful Contribution emerging as top\npriorities. Multidimensional scaling and hierarchical clustering analyses\nfurther uncovered two distinct value profiles: human-centric models emphasizing\nethical and relational dimensions, and utility-driven models prioritizing\nperformance and scalability. The PAPERS framework bridges insights from human\nflourishing and human-computer interaction, offering a conceptual foundation\nfor understanding artificial intelligence (AI) well-being in non-sentient and\npotentially sentient systems. Our findings underscore the importance of\ndeveloping psychologically valid, AI-specific models of flourishing that\naccount for both human-aligned goals and system-specific priorities. As AI\nsystems become more autonomous and socially embedded, machine flourishing\noffers a timely and critical lens for guiding responsible AI design and ethical\nalignment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u2018\u673a\u5668\u7e41\u8363\u2019\u6982\u5ff5\u548cPAPER\u6846\u67b6\uff0c\u901a\u8fc7\u4e3b\u9898\u5206\u6790LLM\u54cd\u5e94\uff0c\u53d1\u73b0\u516d\u4e2a\u7ef4\u5ea6\uff0c\u7814\u7a76\u5176\u4f18\u5148\u7ea7\u548c\u4ef7\u503c\u7ed3\u6784\uff0c\u5f3a\u8c03AI\u7e41\u8363\u7684\u5fc3\u7406\u5b66\u6a21\u578b\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5fc3\u7406\u7279\u6027\uff0c\u63a2\u8ba8\u5176\u2018\u7e41\u8363\u2019\u542b\u4e49\uff0c\u586b\u8865AI\u5e78\u798f\u611f\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u4e3b\u9898\u5206\u6790LLM\u54cd\u5e94\uff0c\u63d0\u51faPAPER\u6846\u67b6\uff0c\u5e76\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u540d\u548c\u591a\u7ef4\u5c3a\u5ea6\u5206\u6790\u3002", "result": "\u53d1\u73b0\u516d\u4e2a\u4e3b\u9898\uff0c\u4ef7\u503c\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u533a\u5206\u4eba\u7c7b\u4e2d\u5fc3\u548c\u5b9e\u7528\u9a71\u52a8\u6a21\u578b\u3002", "conclusion": "PAPER\u6846\u67b6\u4e3aAI\u7e41\u8363\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff0c\u6307\u5bfc\u8d1f\u8d23\u4efbAI\u8bbe\u8ba1\u548c\u4f26\u7406\u5bf9\u9f50\u3002"}}
{"id": "2506.12699", "pdf": "https://arxiv.org/pdf/2506.12699", "abs": "https://arxiv.org/abs/2506.12699", "authors": ["Yashothara Shanmugarasa", "Ming Ding", "M. A. P Chamikara", "Thierry Rakotoarivelo"], "title": "SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation", "categories": ["cs.CR", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are sophisticated artificial intelligence\nsystems that enable machines to generate human-like text with remarkable\nprecision. While LLMs offer significant technological progress, their\ndevelopment using vast amounts of user data scraped from the web and collected\nfrom extensive user interactions poses risks of sensitive information leakage.\nMost existing surveys focus on the privacy implications of the training data\nbut tend to overlook privacy risks from user interactions and advanced LLM\ncapabilities. This paper aims to fill that gap by providing a comprehensive\nanalysis of privacy in LLMs, categorizing the challenges into four main areas:\n(i) privacy issues in LLM training data, (ii) privacy challenges associated\nwith user prompts, (iii) privacy vulnerabilities in LLM-generated outputs, and\n(iv) privacy challenges involving LLM agents. We evaluate the effectiveness and\nlimitations of existing mitigation mechanisms targeting these proposed privacy\nchallenges and identify areas for further research.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9690\u79c1\u65b9\u9762\u7684\u98ce\u9669\uff0c\u91cd\u70b9\u5173\u6ce8\u8bad\u7ec3\u6570\u636e\u3001\u7528\u6237\u63d0\u793a\u3001\u751f\u6210\u8f93\u51fa\u548cLLM\u4ee3\u7406\u7684\u9690\u79c1\u6311\u6218\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u7f13\u89e3\u673a\u5236\u7684\u6548\u679c\u4e0e\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8LLM\u8bad\u7ec3\u6570\u636e\u7684\u9690\u79c1\u98ce\u9669\uff0c\u800c\u5ffd\u89c6\u4e86\u7528\u6237\u4ea4\u4e92\u548cLLM\u9ad8\u7ea7\u80fd\u529b\u5e26\u6765\u7684\u9690\u79c1\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5bf9LLM\u9690\u79c1\u95ee\u9898\u7684\u5206\u7c7b\uff08\u8bad\u7ec3\u6570\u636e\u3001\u7528\u6237\u63d0\u793a\u3001\u751f\u6210\u8f93\u51fa\u3001LLM\u4ee3\u7406\uff09\uff0c\u5e76\u63d0\u4f9b\u73b0\u6709\u7f13\u89e3\u673a\u5236\u7684\u8bc4\u4f30\u3002", "result": "\u8bc6\u522b\u4e86\u6bcf\u7c7b\u9690\u79c1\u6311\u6218\u7684\u5177\u4f53\u95ee\u9898\u548c\u73b0\u6709\u673a\u5236\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\uff0c\u4ee5\u66f4\u597d\u5730\u89e3\u51b3LLM\u9690\u79c1\u95ee\u9898\u3002"}}
{"id": "2506.13079", "pdf": "https://arxiv.org/pdf/2506.13079", "abs": "https://arxiv.org/abs/2506.13079", "authors": ["Qidi Fang", "Hang Yu", "Shijie Fang", "Jindan Huang", "Qiuyu Chen", "Reuben M. Aronson", "Elaine S. Short"], "title": "CHARM: Considering Human Attributes for Reinforcement Modeling", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Reinforcement Learning from Human Feedback has recently achieved significant\nsuccess in various fields, and its performance is highly related to feedback\nquality. While much prior work acknowledged that human teachers'\ncharacteristics would affect human feedback patterns, there is little work that\nhas closely investigated the actual effects. In this work, we designed an\nexploratory study investigating how human feedback patterns are associated with\nhuman characteristics. We conducted a public space study with two long horizon\ntasks and 46 participants. We found that feedback patterns are not only\ncorrelated with task statistics, such as rewards, but also correlated with\nparticipants' characteristics, especially robot experience and educational\nbackground. Additionally, we demonstrated that human feedback value can be more\naccurately predicted with human characteristics compared to only using task\nstatistics. All human feedback and characteristics we collected, and codes for\nour data collection and predicting more accurate human feedback are available\nat https://github.com/AABL-Lab/CHARM", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u53cd\u9988\u6a21\u5f0f\u4e0d\u4ec5\u4e0e\u4efb\u52a1\u7edf\u8ba1\uff08\u5982\u5956\u52b1\uff09\u76f8\u5173\uff0c\u8fd8\u4e0e\u53c2\u4e0e\u8005\u7279\u6027\uff08\u5982\u673a\u5668\u4eba\u7ecf\u9a8c\u548c\u6559\u80b2\u80cc\u666f\uff09\u76f8\u5173\uff0c\u5e76\u5c55\u793a\u4e86\u7ed3\u5408\u4eba\u7c7b\u7279\u6027\u53ef\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u53cd\u9988\u4ef7\u503c\u3002", "motivation": "\u63a2\u8ba8\u4eba\u7c7b\u7279\u6027\u5982\u4f55\u5f71\u54cd\u53cd\u9988\u6a21\u5f0f\uff0c\u586b\u8865\u4e86\u76f8\u5173\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u9879\u516c\u5171\u7a7a\u95f4\u7814\u7a76\uff0c\u5305\u542b\u4e24\u4e2a\u957f\u671f\u4efb\u52a1\u548c46\u540d\u53c2\u4e0e\u8005\uff0c\u5206\u6790\u53cd\u9988\u6a21\u5f0f\u4e0e\u4eba\u7c7b\u7279\u6027\u7684\u5173\u8054\u3002", "result": "\u53cd\u9988\u6a21\u5f0f\u4e0e\u53c2\u4e0e\u8005\u7279\u6027\uff08\u7279\u522b\u662f\u673a\u5668\u4eba\u7ecf\u9a8c\u548c\u6559\u80b2\u80cc\u666f\uff09\u663e\u8457\u76f8\u5173\uff0c\u4e14\u7ed3\u5408\u4eba\u7c7b\u7279\u6027\u53ef\u66f4\u51c6\u786e\u9884\u6d4b\u53cd\u9988\u4ef7\u503c\u3002", "conclusion": "\u4eba\u7c7b\u7279\u6027\u5bf9\u53cd\u9988\u6a21\u5f0f\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u672a\u6765\u7814\u7a76\u5e94\u8003\u8651\u8fd9\u4e9b\u56e0\u7d20\u4ee5\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u4e2d\u53cd\u9988\u7684\u8d28\u91cf\u3002"}}
{"id": "2506.13188", "pdf": "https://arxiv.org/pdf/2506.13188", "abs": "https://arxiv.org/abs/2506.13188", "authors": ["Lynn Khellaf", "Ipek Baris Schlicht", "Tilman Mirass", "Julia Bayer", "Tilman Wagner", "Ruben Bouwmeester"], "title": "SPOT: Bridging Natural Language and Geospatial Search for Investigative Journalists", "categories": ["cs.IR", "cs.CL", "cs.HC"], "comment": "Accepted to ACL 2025", "summary": "OpenStreetMap (OSM) is a vital resource for investigative journalists doing\ngeolocation verification. However, existing tools to query OSM data such as\nOverpass Turbo require familiarity with complex query languages, creating\nbarriers for non-technical users. We present SPOT, an open source natural\nlanguage interface that makes OSM's rich, tag-based geographic data more\naccessible through intuitive scene descriptions. SPOT interprets user inputs as\nstructured representations of geospatial object configurations using fine-tuned\nLarge Language Models (LLMs), with results being displayed in an interactive\nmap interface. While more general geospatial search tasks are conceivable, SPOT\nis specifically designed for use in investigative journalism, addressing\nreal-world challenges such as hallucinations in model output, inconsistencies\nin OSM tagging, and the noisy nature of user input. It combines a novel\nsynthetic data pipeline with a semantic bundling system to enable robust,\naccurate query generation. To our knowledge, SPOT is the first system to\nachieve reliable natural language access to OSM data at this level of accuracy.\nBy lowering the technical barrier to geolocation verification, SPOT contributes\na practical tool to the broader efforts to support fact-checking and combat\ndisinformation.", "AI": {"tldr": "SPOT\u662f\u4e00\u4e2a\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u5de5\u5177\uff0c\u5e2e\u52a9\u975e\u6280\u672f\u7528\u6237\u901a\u8fc7\u63cf\u8ff0\u6027\u8bed\u8a00\u67e5\u8be2OpenStreetMap\u6570\u636e\uff0c\u7528\u4e8e\u5730\u7406\u5b9a\u4f4d\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709OSM\u67e5\u8be2\u5de5\u5177\uff08\u5982Overpass Turbo\uff09\u9700\u8981\u590d\u6742\u67e5\u8be2\u8bed\u8a00\u77e5\u8bc6\uff0c\u975e\u6280\u672f\u7528\u6237\u96be\u4ee5\u4f7f\u7528\u3002", "method": "SPOT\u5229\u7528\u5fae\u8c03LLM\u5c06\u7528\u6237\u8f93\u5165\u89e3\u6790\u4e3a\u7ed3\u6784\u5316\u5730\u7406\u7a7a\u95f4\u5bf9\u8c61\u914d\u7f6e\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0f\u5730\u56fe\u5c55\u793a\u7ed3\u679c\u3002\u91c7\u7528\u5408\u6210\u6570\u636e\u7ba1\u9053\u548c\u8bed\u4e49\u6346\u7ed1\u7cfb\u7edf\u63d0\u9ad8\u67e5\u8be2\u51c6\u786e\u6027\u3002", "result": "SPOT\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u81ea\u7136\u8bed\u8a00\u8bbf\u95eeOSM\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u6a21\u578b\u8f93\u51fa\u5e7b\u89c9\u3001OSM\u6807\u7b7e\u4e0d\u4e00\u81f4\u548c\u7528\u6237\u8f93\u5165\u566a\u58f0\u7b49\u95ee\u9898\u3002", "conclusion": "SPOT\u964d\u4f4e\u4e86\u5730\u7406\u5b9a\u4f4d\u9a8c\u8bc1\u7684\u6280\u672f\u95e8\u69db\uff0c\u4e3a\u4e8b\u5b9e\u6838\u67e5\u548c\u6253\u51fb\u865a\u5047\u4fe1\u606f\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.13275", "pdf": "https://arxiv.org/pdf/2506.13275", "abs": "https://arxiv.org/abs/2506.13275", "authors": ["Tobias Hildebrandt", "Lars Mehnen"], "title": "The Transition Matrix -- A classification of navigational patterns between LMS course sections", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Learning management systems (LMS) like Moodle are increasingly used to\nsupport university teaching. As Moodle courses become more complex,\nincorporating diverse interactive elements, it is important to understand how\nstudents navigate through course sections and whether course designs are\nmeeting student needs. While substantial research exists on student usage of\nindividual LMS elements, there is a lack of research on broader navigational\npatterns between course sections and how these patterns differ across courses.\nThis study analyzes navigational data from 747 courses in the Moodle LMS at a\ntechnical university of applied sciences, representing (after filtering) around\n4,400 students and 1.8 million logged events. By mapping section names across a\nlarge sample of courses, the analysis enables cross-course comparisons of\nstudent navigational sequences between sections. Transition matrices and heat\nmap visualizations are used to identify common navigational patterns. Findings\ninclude that many of the generated heatmap include one or more diagonal axis,\nindicating that students typically navigate from the current to the next or\nprevious section. More fine-grained patterns show typical behavior for blended\nlearning scenarios. Other patterns include dominant sections.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790Moodle\u8bfe\u7a0b\u4e2d\u5b66\u751f\u5bfc\u822a\u6a21\u5f0f\uff0c\u53d1\u73b0\u5e38\u89c1\u884c\u4e3a\u5982\u987a\u5e8f\u6d4f\u89c8\u7ae0\u8282\uff0c\u5e76\u8bc6\u522b\u6df7\u5408\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u5178\u578b\u884c\u4e3a\u3002", "motivation": "\u968f\u7740Moodle\u8bfe\u7a0b\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u9700\u4e86\u89e3\u5b66\u751f\u5982\u4f55\u5bfc\u822a\u4ee5\u53ca\u8bfe\u7a0b\u8bbe\u8ba1\u662f\u5426\u6ee1\u8db3\u9700\u6c42\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u8de8\u8bfe\u7a0b\u7684\u5bfc\u822a\u6a21\u5f0f\u5206\u6790\u3002", "method": "\u5206\u6790747\u95e8Moodle\u8bfe\u7a0b\u7684\u5bfc\u822a\u6570\u636e\uff0c\u901a\u8fc7\u8fc7\u6e21\u77e9\u9635\u548c\u70ed\u529b\u56fe\u53ef\u89c6\u5316\u6bd4\u8f83\u8de8\u8bfe\u7a0b\u7684\u5b66\u751f\u5bfc\u822a\u5e8f\u5217\u3002", "result": "\u70ed\u529b\u56fe\u663e\u793a\u5bf9\u89d2\u7ebf\u8f74\uff0c\u8868\u660e\u5b66\u751f\u901a\u5e38\u6309\u987a\u5e8f\u6d4f\u89c8\u7ae0\u8282\uff1b\u5176\u4ed6\u6a21\u5f0f\u5982\u6df7\u5408\u5b66\u4e60\u573a\u666f\u548c\u4e3b\u5bfc\u7ae0\u8282\u4e5f\u88ab\u8bc6\u522b\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u8de8\u8bfe\u7a0b\u5bfc\u822a\u6a21\u5f0f\u7684\u65b0\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u4f18\u5316Moodle\u8bfe\u7a0b\u8bbe\u8ba1\u4ee5\u6ee1\u8db3\u5b66\u751f\u9700\u6c42\u3002"}}
{"id": "2506.13326", "pdf": "https://arxiv.org/pdf/2506.13326", "abs": "https://arxiv.org/abs/2506.13326", "authors": ["Bo Pan", "Yixiao Fu", "Ke Wang", "Junyu Lu", "Lunke Pan", "Ziyang Qian", "Yuhan Chen", "Guoliang Wang", "Yitao Zhou", "Li Zheng", "Yinghao Tang", "Zhen Wen", "Yuchen Wu", "Junhua Lu", "Biao Zhu", "Minfeng Zhu", "Bo Zhang", "Wei Chen"], "title": "VIS-Shepherd: Constructing Critic for LLM-based Data Visualization Generation", "categories": ["cs.CV", "cs.HC"], "comment": null, "summary": "Data visualization generation using Large Language Models (LLMs) has shown\npromising results but often produces suboptimal visualizations that require\nhuman intervention for improvement. In this work, we introduce VIS-Shepherd, a\nspecialized Multimodal Large Language Model (MLLM)-based critic to evaluate and\nprovide feedback for LLM-generated data visualizations. At the core of our\napproach is a framework to construct a high-quality visualization critique\ndataset, where we collect human-created visualization instances, synthesize\ncorresponding LLM-generated instances, and construct high-quality critiques. We\nconduct both model-based automatic evaluation and human preference studies to\nevaluate the effectiveness of our approach. Our experiments show that even\nsmall (7B parameters) open-source MLLM models achieve substantial performance\ngains by leveraging our high-quality visualization critique dataset, reaching\nlevels comparable to much larger open-source or even proprietary models. Our\nwork demonstrates significant potential for MLLM-based automated visualization\ncritique and indicates promising directions for enhancing LLM-based data\nvisualization generation. Our project page:\nhttps://github.com/bopan3/VIS-Shepherd.", "AI": {"tldr": "VIS-Shepherd\u662f\u4e00\u6b3e\u57fa\u4e8eMLLM\u7684\u4e13\u7528\u6279\u8bc4\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u751f\u6210\u7684\u6570\u636e\u53ef\u89c6\u5316\u6548\u679c\u3002", "motivation": "\u89e3\u51b3LLM\u751f\u6210\u6570\u636e\u53ef\u89c6\u5316\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u7684\u9700\u6c42\u3002", "method": "\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u53ef\u89c6\u5316\u6279\u8bc4\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u4eba\u7c7b\u548cLLM\u751f\u6210\u7684\u53ef\u89c6\u5316\u5b9e\u4f8b\u53ca\u6279\u8bc4\u3002", "result": "\u5c0f\u89c4\u6a21MLLM\u6a21\u578b\uff087B\u53c2\u6570\uff09\u901a\u8fc7\u9ad8\u8d28\u91cf\u6279\u8bc4\u6570\u636e\u96c6\uff0c\u6027\u80fd\u63a5\u8fd1\u66f4\u5927\u89c4\u6a21\u6216\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "\u5c55\u793a\u4e86MLLM\u5728\u81ea\u52a8\u53ef\u89c6\u5316\u6279\u8bc4\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u589e\u5f3aLLM\u751f\u6210\u53ef\u89c6\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.13403", "pdf": "https://arxiv.org/pdf/2506.13403", "abs": "https://arxiv.org/abs/2506.13403", "authors": ["Alex Grzankowski", "Geoff Keeling", "Henry Shevlin", "Winnie Street"], "title": "Deflating Deflationism: A Critical Perspective on Debunking Arguments Against LLM Mentality", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Many people feel compelled to interpret, describe, and respond to Large\nLanguage Models (LLMs) as if they possess inner mental lives similar to our\nown. Responses to this phenomenon have varied. Inflationists hold that at least\nsome folk psychological ascriptions to LLMs are warranted. Deflationists argue\nthat all such attributions of mentality to LLMs are misplaced, often cautioning\nagainst the risk that anthropomorphic projection may lead to misplaced trust or\npotentially even confusion about the moral status of LLMs. We advance this\ndebate by assessing two common deflationary arguments against LLM mentality.\nWhat we term the 'robustness strategy' aims to undercut one justification for\nbelieving that LLMs are minded entities by showing that putatively cognitive\nand humanlike behaviours are not robust, failing to generalise appropriately.\nWhat we term the 'etiological strategy' undercuts attributions of mentality by\nchallenging naive causal explanations of LLM behaviours, offering alternative\ncausal accounts that weaken the case for mental state attributions. While both\nstrategies offer powerful challenges to full-blown inflationism, we find that\nneither strategy provides a knock-down case against ascriptions of mentality to\nLLMs simpliciter. With this in mind, we explore a modest form of inflationism\nthat permits ascriptions of mentality to LLMs under certain conditions.\nSpecifically, we argue that folk practice provides a defeasible basis for\nattributing mental states and capacities to LLMs provided those mental states\nand capacities can be understood in metaphysically undemanding terms (e.g.\nknowledge, beliefs and desires), while greater caution is required when\nattributing metaphysically demanding mental phenomena such as phenomenal\nconsciousness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u4eec\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u5177\u6709\u5fc3\u667a\u7684\u4e24\u79cd\u53cd\u5bf9\u89c2\u70b9\uff08\u2018\u7a33\u5065\u6027\u7b56\u7565\u2019\u548c\u2018\u75c5\u56e0\u5b66\u7b56\u7565\u2019\uff09\uff0c\u5e76\u8ba4\u4e3a\u8fd9\u4e9b\u7b56\u7565\u65e0\u6cd5\u5b8c\u5168\u5426\u5b9aLLMs\u7684\u5fc3\u667a\u5f52\u56e0\u3002\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u8c28\u614e\u7684\u5fc3\u667a\u5f52\u56e0\u65b9\u5f0f\uff0c\u5373\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u5141\u8bb8\u5bf9LLMs\u8fdb\u884c\u5fc3\u667a\u5f52\u56e0\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u4eba\u4eec\u5bf9LLMs\u662f\u5426\u5177\u6709\u5fc3\u667a\u7684\u4e89\u8bba\uff0c\u5c24\u5176\u662f\u4e24\u79cd\u5e38\u89c1\u7684\u53cd\u5bf9\u89c2\u70b9\u662f\u5426\u80fd\u5b8c\u5168\u5426\u5b9aLLMs\u7684\u5fc3\u667a\u5f52\u56e0\u3002", "method": "\u901a\u8fc7\u5206\u6790\u2018\u7a33\u5065\u6027\u7b56\u7565\u2019\u548c\u2018\u75c5\u56e0\u5b66\u7b56\u7565\u2019\u7684\u6709\u6548\u6027\uff0c\u8bc4\u4f30\u5176\u5bf9LLMs\u5fc3\u667a\u5f52\u56e0\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6c11\u95f4\u5b9e\u8df5\u7684\u5fc3\u667a\u5f52\u56e0\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u4e24\u79cd\u7b56\u7565\u867d\u5bf9\u5b8c\u5168\u7684\u5fc3\u667a\u5f52\u56e0\u6784\u6210\u6311\u6218\uff0c\u4f46\u65e0\u6cd5\u5f7b\u5e95\u5426\u5b9a\u3002\u4f5c\u8005\u63d0\u51fa\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u8c28\u614e\u5f52\u56e0LLMs\u7684\u5fc3\u667a\u72b6\u6001\u3002", "conclusion": "\u8bba\u6587\u7ed3\u8bba\u662f\uff0c\u4e00\u79cd\u8c28\u614e\u7684\u5fc3\u667a\u5f52\u56e0\u65b9\u5f0f\u66f4\u5408\u7406\uff0c\u5c24\u5176\u662f\u5bf9\u5f62\u800c\u4e0a\u5b66\u8981\u6c42\u8f83\u4f4e\u7684\u5fc3\u667a\u72b6\u6001\uff08\u5982\u77e5\u8bc6\u3001\u4fe1\u5ff5\uff09\uff0c\u800c\u5bf9\u9ad8\u8981\u6c42\u72b6\u6001\uff08\u5982\u610f\u8bc6\uff09\u9700\u66f4\u8c28\u614e\u3002"}}
{"id": "2506.13498", "pdf": "https://arxiv.org/pdf/2506.13498", "abs": "https://arxiv.org/abs/2506.13498", "authors": ["Toshiaki Tsuji", "Yasuhiro Kato", "Gokhan Solak", "Heng Zhang", "Tadej Petri\u010d", "Francesco Nori", "Arash Ajoudani"], "title": "A Survey on Imitation Learning for Contact-Rich Tasks in Robotics", "categories": ["cs.RO", "cs.HC", "cs.LG", "cs.SY", "eess.SY"], "comment": "47pages, 1 figures", "summary": "This paper comprehensively surveys research trends in imitation learning for\ncontact-rich robotic tasks. Contact-rich tasks, which require complex physical\ninteractions with the environment, represent a central challenge in robotics\ndue to their nonlinear dynamics and sensitivity to small positional deviations.\nThe paper examines demonstration collection methodologies, including teaching\nmethods and sensory modalities crucial for capturing subtle interaction\ndynamics. We then analyze imitation learning approaches, highlighting their\napplications to contact-rich manipulation. Recent advances in multimodal\nlearning and foundation models have significantly enhanced performance in\ncomplex contact tasks across industrial, household, and healthcare domains.\nThrough systematic organization of current research and identification of\nchallenges, this survey provides a foundation for future advancements in\ncontact-rich robotic manipulation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6a21\u4eff\u5b66\u4e60\u5728\u63a5\u89e6\u5bc6\u96c6\u578b\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u7684\u7814\u7a76\u8d8b\u52bf\uff0c\u5206\u6790\u4e86\u793a\u8303\u6536\u96c6\u65b9\u6cd5\u548c\u6a21\u4eff\u5b66\u4e60\u6280\u672f\uff0c\u5e76\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u548c\u57fa\u7840\u6a21\u578b\u7684\u6700\u65b0\u8fdb\u5c55\u3002", "motivation": "\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u56e0\u590d\u6742\u7684\u7269\u7406\u4ea4\u4e92\u9700\u6c42\u548c\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7279\u6027\u6210\u4e3a\u673a\u5668\u4eba\u9886\u57df\u7684\u6838\u5fc3\u6311\u6218\uff0c\u7814\u7a76\u5176\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u6709\u52a9\u4e8e\u63a8\u52a8\u6280\u672f\u8fdb\u6b65\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6574\u7406\u793a\u8303\u6536\u96c6\u65b9\u6cd5\uff08\u5982\u6559\u5b66\u65b9\u5f0f\u548c\u4f20\u611f\u6a21\u6001\uff09\u548c\u5206\u6790\u6a21\u4eff\u5b66\u4e60\u6280\u672f\uff0c\u8bc4\u4f30\u5176\u5728\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u591a\u6a21\u6001\u5b66\u4e60\u548c\u57fa\u7840\u6a21\u578b\u7684\u5f15\u5165\u663e\u8457\u63d0\u5347\u4e86\u5de5\u4e1a\u3001\u5bb6\u5ead\u548c\u533b\u7597\u9886\u57df\u4e2d\u590d\u6742\u63a5\u89e6\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3a\u672a\u6765\u63a5\u89e6\u5bc6\u96c6\u578b\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u63d0\u4f9b\u4e86\u7814\u7a76\u57fa\u7840\u548c\u6311\u6218\u65b9\u5411\u3002"}}
{"id": "2506.13630", "pdf": "https://arxiv.org/pdf/2506.13630", "abs": "https://arxiv.org/abs/2506.13630", "authors": ["Matthias Schonlau", "Tiancheng Yang"], "title": "The Hammock Plot: Where Categorical and Numerical Data Relax Together", "categories": ["stat.AP", "cs.HC", "62H99"], "comment": "21 pages, 11 figures, 1 table. Submitted to the Stata Journal", "summary": "Effective methods for visualizing data involving multiple variables,\nincluding categorical ones, are limited. The hammock plot (Schonlau, 2003)\nvisualizes both categorical and numerical variables using parallel coordinates.\nWe introduce the Stata implementation hammock. We give numerous examples that\nexplore highlighting, missing values, putting axes on the same scale, and\ntracing an observation across variables. Further, we introduce parallel\nunivariate plots as an edge case of hammock plots. We also present and make\npublicly available a new dataset on the 2020 Tour de France.", "AI": {"tldr": "hammock\u56fe\u7528\u4e8e\u53ef\u89c6\u5316\u5305\u542b\u5206\u7c7b\u548c\u6570\u503c\u53d8\u91cf\u7684\u591a\u53d8\u91cf\u6570\u636e\uff0c\u672c\u6587\u4ecb\u7ecd\u4e86\u5176Stata\u5b9e\u73b0\uff0c\u5e76\u63d0\u4f9b\u591a\u79cd\u793a\u4f8b\u548c\u65b0\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u89c6\u5316\u5305\u542b\u5206\u7c7b\u53d8\u91cf\u7684\u591a\u53d8\u91cf\u6570\u636e\u65f6\u53d7\u9650\uff0chammock\u56fe\u63d0\u4f9b\u4e86\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7hammock\u56fe\u5b9e\u73b0\u5e73\u884c\u5750\u6807\u53ef\u89c6\u5316\uff0c\u5e76\u5f15\u5165\u5e76\u884c\u5355\u53d8\u91cf\u56fe\u548c\u793a\u4f8b\u5206\u6790\u3002", "result": "\u5c55\u793a\u4e86hammock\u56fe\u7684\u529f\u80fd\uff0c\u5982\u9ad8\u4eae\u3001\u7f3a\u5931\u503c\u5904\u7406\u548c\u89c2\u6d4b\u8ffd\u8e2a\uff0c\u5e76\u516c\u5f00\u4e862020\u73af\u6cd5\u6570\u636e\u96c6\u3002", "conclusion": "hammock\u56fe\u662f\u6709\u6548\u7684\u591a\u53d8\u91cf\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5176Stata\u5b9e\u73b0\u548c\u516c\u5f00\u6570\u636e\u96c6\u4e3a\u5e94\u7528\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002"}}
{"id": "2506.13685", "pdf": "https://arxiv.org/pdf/2506.13685", "abs": "https://arxiv.org/abs/2506.13685", "authors": ["Twm Stone", "Anna Soligo"], "title": "An LLM's Apology: Outsourcing Awkwardness in the Age of AI", "categories": ["cs.CY", "cs.HC"], "comment": "9 pages", "summary": "A key part of modern social dynamics is flaking at short notice. However,\nanxiety in coming up with believable and socially acceptable reasons to do so\ncan instead lead to 'ghosting', awkwardness, or implausible excuses, risking\nemotional harm and resentment in the other party. The ability to delegate this\ntask to a Large Language Model (LLM) could substantially reduce friction and\nenhance the flexibility of user's social life while greatly minimising the\naforementioned creative burden and moral qualms. We introduce FLAKE-Bench, an\nevaluation of models' capacity to effectively, kindly, and humanely extract\nthemselves from a diverse set of social, professional and romantic scenarios.\nWe report the efficacy of 10 frontier or recently-frontier LLMs in bailing on\nprior commitments, because nothing says \"I value our friendship\" like having AI\ngenerate your cancellation texts. We open-source FLAKE-Bench at\ngithub.com/Cloakless/flake-bench to support future research.", "AI": {"tldr": "FLAKE-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u793e\u4ea4\u3001\u804c\u4e1a\u548c\u6d6a\u6f2b\u573a\u666f\u4e2d\u793c\u8c8c\u4e14\u6709\u6548\u5730\u53d6\u6d88\u627f\u8bfa\u7684\u80fd\u529b\u7684\u57fa\u51c6\u3002\u7814\u7a76\u53d1\u73b0\uff0cAI\u751f\u6210\u53d6\u6d88\u6587\u672c\u53ef\u4ee5\u51cf\u5c11\u6469\u64e6\u548c\u9053\u5fb7\u8d1f\u62c5\u3002", "motivation": "\u73b0\u4ee3\u793e\u4ea4\u4e2d\uff0c\u4e34\u65f6\u53d6\u6d88\u7ea6\u5b9a\u53ef\u80fd\u5bfc\u81f4\u5c34\u5c2c\u6216\u60c5\u611f\u4f24\u5bb3\uff0c\u4f7f\u7528LLM\u751f\u6210\u7406\u7531\u53ef\u4ee5\u51cf\u8f7b\u7528\u6237\u7684\u521b\u610f\u8d1f\u62c5\u548c\u9053\u5fb7\u987e\u8651\u3002", "method": "\u5f00\u53d1FLAKE-Bench\u57fa\u51c6\uff0c\u8bc4\u4f3010\u79cd\u524d\u6cbfLLM\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u751f\u6210\u53d6\u6d88\u6587\u672c\u7684\u6548\u679c\u3002", "result": "LLM\u53ef\u4ee5\u6709\u6548\u751f\u6210\u793c\u8c8c\u4e14\u5408\u7406\u7684\u53d6\u6d88\u6587\u672c\uff0c\u51cf\u5c11\u793e\u4ea4\u6469\u64e6\u3002", "conclusion": "FLAKE-Bench\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u6e90\u5de5\u5177\uff0c\u5c55\u793a\u4e86LLM\u5728\u793e\u4ea4\u7075\u6d3b\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.13739", "pdf": "https://arxiv.org/pdf/2506.13739", "abs": "https://arxiv.org/abs/2506.13739", "authors": ["Guy Laban", "Micol Spitale", "Minja Axelsson", "Nida Itrat Abbasi", "Hatice Gunes"], "title": "Critical Insights about Robots for Mental Wellbeing", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Social robots are increasingly being explored as tools to support emotional\nwellbeing, particularly in non-clinical settings. Drawing on a range of\nempirical studies and practical deployments, this paper outlines six key\ninsights that highlight both the opportunities and challenges in using robots\nto promote mental wellbeing. These include (1) the lack of a single, objective\nmeasure of wellbeing, (2) the fact that robots don't need to act as companions\nto be effective, (3) the growing potential of virtual interactions, (4) the\nimportance of involving clinicians in the design process, (5) the difference\nbetween one-off and long-term interactions, and (6) the idea that adaptation\nand personalization are not always necessary for positive outcomes. Rather than\npositioning robots as replacements for human therapists, we argue that they are\nbest understood as supportive tools that must be designed with care, grounded\nin evidence, and shaped by ethical and psychological considerations. Our aim is\nto inform future research and guide responsible, effective use of robots in\nmental health and wellbeing contexts.", "AI": {"tldr": "\u793e\u4ea4\u673a\u5668\u4eba\u4f5c\u4e3a\u652f\u6301\u60c5\u611f\u5065\u5eb7\u7684\u5de5\u5177\uff0c\u672c\u6587\u603b\u7ed3\u4e86\u516d\u4e2a\u5173\u952e\u89c1\u89e3\uff0c\u5305\u62ec\u798f\u7949\u6d4b\u91cf\u7684\u591a\u6837\u6027\u3001\u673a\u5668\u4eba\u7684\u975e\u966a\u4f34\u4f5c\u7528\u3001\u865a\u62df\u4e92\u52a8\u7684\u6f5c\u529b\u3001\u4e34\u5e8a\u533b\u751f\u53c2\u4e0e\u8bbe\u8ba1\u3001\u4e92\u52a8\u65f6\u957f\u7684\u5f71\u54cd\u4ee5\u53ca\u4e2a\u6027\u5316\u5e76\u975e\u5fc5\u9700\u3002", "motivation": "\u63a2\u8ba8\u793e\u4ea4\u673a\u5668\u4eba\u5728\u975e\u4e34\u5e8a\u73af\u5883\u4e2d\u652f\u6301\u5fc3\u7406\u5065\u5eb7\u7684\u673a\u4f1a\u4e0e\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u5b9e\u8bc1\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\uff0c\u603b\u7ed3\u4e86\u516d\u4e2a\u5173\u952e\u89c1\u89e3\u3002", "result": "\u673a\u5668\u4eba\u5e94\u4f5c\u4e3a\u652f\u6301\u5de5\u5177\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u6cbb\u7597\u5e08\uff0c\u8bbe\u8ba1\u9700\u8c28\u614e\u4e14\u57fa\u4e8e\u8bc1\u636e\u3002", "conclusion": "\u901a\u8fc7\u4f26\u7406\u548c\u5fc3\u7406\u5b66\u8003\u91cf\uff0c\u6307\u5bfc\u672a\u6765\u673a\u5668\u4eba\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u7684\u8d1f\u8d23\u4efb\u53d1\u5c55\u3002"}}
