<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.PF](#cs.PF) [Total: 2]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.HC](#cs.HC) [Total: 10]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.AR](#cs.AR) [Total: 3]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]
- [stat.CO](#stat.CO) [Total: 1]
- [math.LO](#math.LO) [Total: 1]
- [cs.CY](#cs.CY) [Total: 4]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.CR](#cs.CR) [Total: 7]
- [eess.SP](#eess.SP) [Total: 1]
- [quant-ph](#quant-ph) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Quality attributes of test cases and test suites -- importance & challenges from practitioners' perspectives](https://arxiv.org/abs/2507.06343)
*Huynh Khanh Vi Tran,Nauman bin Ali,Michael Unterkalmsteiner,Jürgen Börstler,Panagiota Chatzipetrou*

Main category: cs.SE

TL;DR: 研究通过工业调查分析测试用例和测试套件质量属性的相对重要性及实践中的挑战，发现故障检测、可用性、可维护性、可靠性和覆盖率最为重要。


<details>
  <summary>Details</summary>
Motivation: 理解测试用例和测试套件质量属性的相对重要性，以增强软件测试的信心。

Method: 通过基于文献综述的问卷调查，利用LinkedIn招募经验丰富的软件测试专业人员参与调查。

Result: 354份回复显示故障检测等属性最重要，资源效率等属性意见分歧，且存在定义不清、缺乏指标等问题。

Conclusion: 研究结果可为学术研究提供方向，并鼓励企业为实践者提供更多支持。

Abstract: Context: The quality of the test suites and the constituent test cases
significantly impacts confidence in software testing. While research has
identified several quality attributes of test cases and test suites, there is a
need for a better understanding of their relative importance in practice.
Objective: We investigate practitioners' perceptions regarding the relative
importance of quality attributes of test cases and test suites and the
challenges they face in ensuring the perceived important quality attributes.
Method: We conducted an industrial survey using a questionnaire based on the
quality attributes identified in an extensive literature review. We used a
sampling strategy that leverages LinkedIn to draw a large and heterogeneous
sample of professionals with experience in software testing. Results: We
collected 354 responses from practitioners with a wide range of experience. We
found that the majority of practitioners rated Fault Detection, Usability,
Maintainability, Reliability, and Coverage to be the most important quality
attributes. Resource Efficiency, Reusability, and Simplicity received the most
divergent opinions, which, according to our analysis, depend on the
software-testing contexts. We identified common challenges that apply to the
important attributes, namely inadequate definition, lack of useful metrics,
lack of an established review process, and lack of external support.
Conclusion: The findings point out where practitioners actually need further
support with respect to achieving high-quality test cases and test suites under
different software testing contexts. The findings can serve as a guideline for
academic researchers when looking for research directions on the topic. The
findings can also be used to encourage companies to provide more support to
practitioners to achieve high-quality test cases and test suites.

</details>


### [2] [A proposal and assessment of an improved heuristic for the Eager Test smell detection](https://arxiv.org/abs/2507.06354)
*Huynh Khanh Vi Tran,Nauman bin Ali,Michael Unterkalmsteiner,Jürgen Börstler*

Main category: cs.SE

TL;DR: 本文旨在改进Eager Test测试味道的检测规则，提出了一种新的定义和启发式方法，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有测试味道检测工具的规则存在不足，特别是对Eager Test的定义不够精确，导致检测结果不一致。

Method: 通过文献综述分析Eager Test的定义和检测规则，提出新的定义和启发式方法，并在300个Java单元测试中进行手动评估。

Result: 研究发现现有规则对Eager Test的定义不精确，导致检测结果不一致；新启发式方法能更准确地识别Eager Test。

Conclusion: 新启发式方法更精确地捕捉了Eager Test的本质，可能解决现有检测规则不足的问题。

Abstract: Context: The evidence for the prevalence of test smells at the unit testing
level has relied on the accuracy of detection tools, which have seen intense
research in the last two decades. The Eager Test smell, one of the most
prevalent, is often identified using simplified detection rules that
practitioners find inadequate. Objective: We aim to improve the rules for
detecting the Eager Test smell. Method: We reviewed the literature on test
smells to analyze the definitions and detection rules of the Eager Test smell.
We proposed a novel, unambiguous definition of the test smell and a heuristic
to address the limitations of the existing rules. We evaluated our heuristic
against existing detection rules by manually applying it to 300 unit test cases
in Java. Results: Our review identified 56 relevant studies. We found that
inadequate interpretations of original definitions of the Eager Test smell led
to imprecise detection rules, resulting in a high level of disagreement in
detection outcomes. Also, our heuristic detected patterns of eager and
non-eager tests that existing rules missed. Conclusion: Our heuristic captures
the essence of the Eager Test smell more precisely; hence, it may address
practitioners' concerns regarding the adequacy of existing detection rules.

</details>


### [3] [Evaluating Efficiency and Novelty of LLM-Generated Code for Graph Analysis](https://arxiv.org/abs/2507.06463)
*Atieh Barati Nia,Mohammad Dindoost,David A. Bader*

Main category: cs.SE

TL;DR: 研究了LLMs生成高效C语言图分析算法的能力，发现Claude Sonnet 4 Extended表现最佳，但LLMs在创新算法方面仍有局限。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在满足严格运行时和内存约束下生成高效C语言代码的能力，填补此前研究在低层语言和效率评估上的空白。

Method: 采用两种方法：1) 评估生成的算法是否能超越基准中的现有算法；2) 评估生成适用于集成到基准中的算法的能力。

Result: Claude Sonnet 4 Extended在现成代码生成和效率上表现最佳，甚至超越人工编写的基线。

Conclusion: 当代LLMs擅长优化和集成现有算法，但缺乏创新性，需进一步研究改进。

Abstract: Large Language Models (LLMs) are increasingly used to automate software
development, yet most prior evaluations focus on functional correctness or
high-level languages such as Python. We present the first systematic study of
LLMs' ability to generate efficient C implementations of graph-analysis
routines--code that must satisfy the stringent runtime and memory constraints.
Eight state-of-the-art models (OpenAI ChatGPT o3 and o4-mini-high, Anthropic
Claude 4 Sonnet and Sonnet Extended, Google Gemini 2.5 Flash and Pro, xAI Grok
3-Think, and DeepSeek DeepThink R1) are benchmarked by two distinct approaches.
The first approach checks the ability of LLMs in generating an algorithm
outperforming other present algorithms in the benchmark. The second approach
evaluates the ability of LLMs to generate graph algorithms for integration into
the benchmark. Results show that Claude Sonnet 4 Extended achieves the best
result in the case of ready-to-use code generation and efficiency,
outperforming human-written baselines in triangle counting. The study confirms
that contemporary LLMs excel at optimizing and integrating established
algorithms but not inventing novel techniques. We provide prompts, the first
approach's generated code, and measurement scripts to foster reproducible
research.

</details>


### [4] [Issue Tracking Ecosystems: Context and Best Practices](https://arxiv.org/abs/2507.06704)
*Lloyd Montgomery*

Main category: cs.SE

TL;DR: 该论文研究了问题跟踪生态系统（ITE）的复杂性和多样性，通过访谈和档案分析揭示了问题的上下文依赖性，并提出了一个最佳实践本体以统一研究和实践中的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有问题跟踪系统（ITS）的研究集中于特定问题，而忽略了生态系统（ITE）的复杂性和上下文依赖性，导致解决方案缺乏一致性和可比性。

Method: 作者通过访谈实践者和分析多样化的ITS档案，识别了ITE中的问题和上下文依赖性，并开发了一个最佳实践本体以提供统一框架。

Result: 研究发现ITE的问题具有高度上下文依赖性，现有解决方案缺乏一致性，因此需要一个统一的框架来指导研究与实践。

Conclusion: 该论文通过提出最佳实践本体，为解决ITE的复杂性和多样性问题提供了统一的理论基础，强调了上下文特定研究的重要性。

Abstract: Issue Tracking Systems (ITSs), such as GitHub and Jira, are popular tools
that support Software Engineering (SE) organisations through the management of
``issues'', which represent different SE artefacts such as requirements,
development tasks, and maintenance items. ITSs also support internal linking
between issues, and external linking to other tools and information sources.
This provides SE organisations key forms of documentation, including forwards
and backwards traceability (e.g., Feature Requests linked to sprint releases
and code commits linked to Bug Reports). An Issue Tracking Ecosystem (ITE) is
the aggregate of the central ITS and the related SE artefacts, stakeholders,
and processes -- with an emphasis on how these contextual factors interact with
the ITS. The quality of ITEs is central to the success of these organisations
and their software products. There are challenges, however, within ITEs,
including complex networks of interlinked artefacts and diverse workflows.
While ITSs have been the subject of study in SE research for decades, ITEs as a
whole need further exploration.
  In this thesis, I undertake the challenge of understanding ITEs at a broader
level, addressing these questions regarding complexity and diversity. I
interviewed practitioners and performed archival analysis on a diverse set of
ITSs. These analyses revealed the context-dependent nature of ITE problems,
highlighting the need for context-specific ITE research. While previous work
has produced many solutions to specific ITS problems, these solutions are not
consistently framed in a context-rich and comparable way, leading to a desire
for more aligned solutions across research and practice. To address this
emergent information and lack of alignment, I created the Best Practice
Ontology for ITEs. <... truncated due to arXiv abstract character limit ...>

</details>


### [5] [Leveraging LLMs for Semantic Conflict Detection via Unit Test Generation](https://arxiv.org/abs/2507.06762)
*Nathalia Barbosa,Paulo Borba,Léuson Da Silva*

Main category: cs.SE

TL;DR: 论文研究了语义冲突问题，提出利用基于Code Llama 70B的测试生成工具改进SMAT，并验证了其在复杂系统中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统合并工具无法检测语义冲突，SMAT虽有效但假阴性率高，研究探讨LLMs是否能改进测试生成。

Method: 集成基于Code Llama 70B的测试生成工具到SMAT，通过不同策略和配置生成测试。

Result: LLM测试生成在复杂场景中仍具挑战性，但显示出改进语义冲突检测的潜力。

Conclusion: LLM生成的测试在复杂场景中有潜力提升语义冲突检测，尽管仍面临技术挑战。

Abstract: Semantic conflicts arise when a developer introduces changes to a codebase
that unintentionally affect the behavior of changes integrated in parallel by
other developers. Traditional merge tools are unable to detect such conflicts,
so complementary tools like SMAT have been proposed. SMAT relies on generating
and executing unit tests: if a test fails on the base version, passes on a
developer's modified version, but fails again after merging with another
developer's changes, a semantic conflict is indicated. While SMAT is effective
at detecting conflicts, it suffers from a high rate of false negatives, partly
due to the limitations of unit test generation tools such as Randoop and
Evosuite. To investigate whether large language models (LLMs) can overcome
these limitations, we propose and integrate a new test generation tool based on
Code Llama 70B into SMAT. We explore the model's ability to generate tests
using different interaction strategies, prompt contents, and parameter
configurations. Our evaluation uses two samples: a benchmark with simpler
systems from related work, and a more significant sample based on complex,
real-world systems. We assess the effectiveness of the new SMAT extension in
detecting conflicts. Results indicate that, although LLM-based test generation
remains challenging and computationally expensive in complex scenarios, there
is promising potential for improving semantic conflict detection.
  --
  Conflitos sem^anticos surgem quando um desenvolvedor introduz mudan\c{c}as em
uma base de c\'odigo que afetam, de forma n~ao intencional, o comportamento de
altera\c{c}~oes integradas em paralelo por outros desenvolvedores. Ferramentas
tradicionais de merge n~ao conseguem detectar esse tipo de conflito, por isso
ferramentas complementares como o SMAT foram propostas. O SMAT depende da
gera\c{c}~ao e execu\c{c}~ao de testes de unidade: se um teste falha na vers~ao
base, passa na vers~ao modificada por um desenvolvedor, mas volta a falhar
ap\'os o merge com as mudan\c{c}as de outro desenvolvedor, um conflito
sem^antico \'e identificado. Embora o SMAT seja eficaz na detec\c{c}~ao de
conflitos, apresenta alta taxa de falsos negativos, em parte devido \`as
limita\c{c}~oes das ferramentas de gera\c{c}~ao de testes como Randoop e
Evosuite. Para investigar se modelos de linguagem de grande porte (LLMs) podem
superar essas limita\c{c}~oes, propomos e integramos ao SMAT uma nova
ferramenta de gera\c{c}~ao de testes baseada no Code Llama 70B. Exploramos a
capacidade do modelo de gerar testes utilizando diferentes estrat\'egias de
intera\c{c}~ao, conte\'udos de prompts e configura\c{c}~oes de par^ametros.
Nossa avalia\c{c}~ao utiliza duas amostras: um benchmark com sistemas mais
simples, usados em trabalhos relacionados, e uma amostra mais significativa
baseada em sistemas complexos e reais. Avaliamos a efic\'acia da nova extens~ao
do SMAT na detec\c{c}~ao de conflitos. Os resultados indicam que, embora a
gera\c{c}~ao de testes por LLM em cen\'arios complexos ainda seja desafiadora e
custosa computacionalmente, h\'a potencial promissor para aprimorar a
detec\c{c}~ao de conflitos sem^anticos.

</details>


### [6] [Formalization of the AADL Run-Time Services with Time](https://arxiv.org/abs/2507.06881)
*Brian R Larson,Ehsan Ahmad*

Main category: cs.SE

TL;DR: 本文扩展并简化了AADL的形式化语义，引入了时间模型，并扩展了RTS以支持状态机行为。


<details>
  <summary>Details</summary>
Motivation: 为了进一步完善AADL的形式化语义，尤其是引入时间模型，并扩展运行时服务以支持状态机行为。

Method: 使用基于Kripke结构的模态逻辑来明确包括时间，并扩展AADL标准的RTS以支持BA和BLESS语言。

Result: 提出了一个带有时间模型的AADL RTS实现案例，展示了其在HAMR中对BLESS编写的状态机的支持。

Conclusion: 通过模态逻辑和时间模型的引入，增强了AADL的形式化语义表达能力和实用性。

Abstract: The Architecture Analysis & Design Language (AADL) is an architecture
description language for design of cyber-physical systems--machines controlled
by software. The AADL standard, SAE International AS5506D, describes Run-Time
Services (RTS) to be provided to execute AADL models in accordance with
semantics defined by the standard. The RTS of primary concern are transport
services and timing services. Although, the study presented in [1] sets a
foundation for the formal semantics of AADL, but without modeling time. This
paper extends and simplifies this formalization using a modal logic defined by
a Kripke structure, to explicitly include time. The RTS defined in the AADL
standard are also expanded to support reactive state-transition machines of the
Behavior Specification annex standard language (BA) and its closely-related,
formally-defined counterpart, the Behavior Language for Embedded Systems with
Software (BLESS). An example of AADL RTS with time, implemented by the High
Assurance Modeling and Rapid Engineering for Embedded Systems (HAMR) for
state-transition machine behavior written in BLESS, is also presented.

</details>


### [7] [Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation](https://arxiv.org/abs/2507.06980)
*Binquan Zhang,Li Zhang,Zhiwen Luo,Yuxin Du,Fang Liu,Song Wang,Lin Shi*

Main category: cs.SE

TL;DR: 论文探讨了LLMs在代码生成中链式思维提示（CoT）的质量问题，分析了影响CoT的外部与内部因素，并提出了改进方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估LLMs生成的CoT的质量及其对代码生成性能的影响，以提升LLMs的可靠性和推理能力。

Method: 通过分析1,023个失败的代码样本和210个CoT-代码对，评估外部（如需求不明确）和内部（如LLMs误解提示）因素对CoT质量的影响，并尝试通过提示优化改进低质量CoT。

Result: 研究发现53.60%的CoT问题源于外部因素，40.10%来自内部因素；即使CoT正确，18.5%代码仍有错误；优化CoT后LLMs性能提升。

Conclusion: 研究揭示了CoT在代码生成中的关键挑战，为改进LLM推理和可靠性提供了方向。

Abstract: Large language models (LLMs) have demonstrated impressive performance in code
generation, particularly when augmented with chain-of-thought (CoT) prompting
techniques. They break down requirements into intermediate reasoning steps,
which act as design rationales to guide LLMs in writing code like human
programmers. Thus, the quality of these steps is crucial for ensuring the
correctness and reliability of the generated code. However, little is known
about the quality of CoT generated by LLMs. To what extent can we trust the
thoughts generated by LLMs? How good are they? This paper empirically explores
the external and internal factors of why LLMs generate unsatisfactory CoTs by
analyzing 1,023 failed code samples on two widely used code generation
benchmarks. We also evaluate their impact on code generation performance by
analyzing 210 CoT-code pairs and refining the unsatisfied CoTs by prompting
LLMs. Our study reveals three key findings: (1) External factors (53.60%), such
as unclear requirements and lack of context, mainly affect CoT quality, while
internal factors (40.10%) stem from LLMs' misunderstanding prompts. (2) Even
when CoTs are correct, 18.5% of the generated code contains errors due to
instruction-following issues; conversely, 11.90% of correct code is paired with
flawed CoTs. (3) Refining low-quality CoTs is feasible, i.e., LLMs improve when
given detailed problem descriptions. These findings highlight key challenges in
CoT-based code generation and suggest directions for improving LLM reasoning
and reliability.

</details>


### [8] [Exploring Fairness Interventions in Open Source Projects](https://arxiv.org/abs/2507.07026)
*Sadia Afrin Mim,Fatema Tuz Zohra,Justin Smith,Brittany Johnson*

Main category: cs.SE

TL;DR: 该论文通过系统识别和分析62个开源公平性干预措施，揭示了实际应用中这些工具的采用率低，并发现其中32%在过去一年内得到积极维护，50%具备偏见于检测和缓解功能。


<details>
  <summary>Details</summary>
Motivation: 应对机器学习模型偏见在实际应用中的负面影响，促进公平性干预措施的普及。

Method: 系统识别和编译62个开源公平性干预措施数据集，并对其规格和功能进行分析。

Result: 发现32%的干预措施在过去一年内得到维护，50%提供偏见于检测和缓解功能，多在处理中实现。

Conclusion: 公平性干预措施的实际采用仍有提升空间，需进一步推广和维护。

Abstract: The deployment of biased machine learning (ML) models has resulted in adverse
effects in crucial sectors such as criminal justice and healthcare. To address
these challenges, a diverse range of machine learning fairness interventions
have been developed, aiming to mitigate bias and promote the creation of more
equitable models. Despite the growing availability of these interventions,
their adoption in real-world applications remains limited, with many
practitioners unaware of their existence. To address this gap, we
systematically identified and compiled a dataset of 62 open source fairness
interventions and identified active ones. We conducted an in-depth analysis of
their specifications and features to uncover considerations that may drive
practitioner preference and to identify the software interventions actively
maintained in the open source ecosystem. Our findings indicate that 32% of
these interventions have been actively maintained within the past year, and 50%
of them offer both bias detection and mitigation capabilities, mostly during
inprocessing.

</details>


### [9] [5C Prompt Contracts: A Minimalist, Creative-Friendly, Token-Efficient Design Framework for Individual and SME LLM Usage](https://arxiv.org/abs/2507.07045)
*Ugur Ari*

Main category: cs.SE

TL;DR: 论文提出了5C Prompt Contract框架，通过五个直观组件简化提示设计，提升LLM交互的可靠性和灵活性，同时保持高效和一致性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键应用中的广泛嵌入，需要一种既系统又简洁的提示设计框架，以减少认知和令牌开销。

Method: 提出5C Prompt Contract框架，包含Character、Cause、Constraint、Contingency和Calibration五个组件。

Result: 实验表明，5C框架在多种LLM架构中均表现出更高的令牌效率和一致的输出质量。

Conclusion: 5C框架适用于资源有限的个人和中小企业，能够有效提升LLM交互的可靠性和灵活性。

Abstract: The progression from traditional prompt engineering to a more rigorous
discipline of prompt design marks a pivotal shift in human-LLM interaction. As
Large Language Models (LLMs) become increasingly embedded in mission-critical
applications, there emerges a pressing need for frameworks that are not only
explicit and systematic but also minimal enough to remain practical and broadly
accessible. While many existing approaches address prompt structuring through
elaborate Domain-Specific Languages (DSLs) or multi-layered templates, such
methods can impose significant token and cognitive overhead, potentially
constraining the model's creative capacity. In this context, we propose the 5C
Prompt Contract, a framework that distills prompt design into five intuitive
components: Character, Cause, Constraint, Contingency, and Calibration. This
minimal cognitive schema explicitly integrates fallback and output optimization
directives, fostering reliable, interpretable, and creatively flexible AI
interactions. Experimental results demonstrate that the 5C framework
consistently achieves superior input token efficiency while maintaining rich
and consistent outputs across diverse LLM architectures (OpenAI, Anthropic,
DeepSeek, and Gemini), making it particularly suited for individuals and
Small-to-Medium Enterprises (SMEs) with limited AI engineering resources.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [Pyrosome: Verified Compilation for Modular Metatheory](https://arxiv.org/abs/2507.06360)
*Dustin Jamner,Gabriel Kammer,Ritam Nag,Adam Chlipala*

Main category: cs.PL

TL;DR: Pyrosome是一个模块化语言元理论的通用框架，支持可扩展语义和编译，并通过Coq实现。其核心创新是通过归纳等价性保持实现语言扩展和编译器重用。


<details>
  <summary>Details</summary>
Motivation: 传统语义推理技术通常与特定语言结构绑定，Pyrosome旨在通过可扩展的编译器实现语言特性的灵活添加和已验证定理的重用。

Method: Pyrosome采用深度嵌入的编程语言形式化定义，依赖排序的等式理论提供语义，编译器正确性证明基于类型检查和等式推理。支持垂直组合编译器和特性扩展。

Result: 通过案例研究（如System F的多阶段编译器），展示了如何逐步扩展语言特性（如递归函数、全局堆等），同时重用原始正确性定理。

Conclusion: Pyrosome通过新颖的等价性保持方法，显著提升了语言扩展和编译器验证的灵活性，适用于结构化类型和命令式特性。

Abstract: We present Pyrosome, a generic framework for modular language metatheory that
embodies a novel approach to extensible semantics and compilation, implemented
in Coq. Common techniques for semantic reasoning are often tied to the specific
structures of the languages and compilers that they support. In Pyrosome,
verified compilers are fully extensible, meaning that to extend a language
(even with a new kind of effect) simply requires defining and verifying the
compilation of the new feature, reusing the old correctness theorem for all
other cases. The novel enabling idea is an inductive formulation of equivalence
preservation that supports the addition of new rules to the source language,
target language, and compiler.
  Pyrosome defines a formal, deeply embedded notion of programming languages
with semantics given by dependently sorted equational theories, so all
compiler-correctness proofs boil down to type-checking and equational
reasoning. We support vertical composition of any compilers expressed in our
framework in addition to feature extension. As a case study, we present a
multipass compiler from System F with simple references, through CPS
translation and closure conversion. Specifically, we demonstrate how we can
build such a compiler incrementally by starting with a compiler for simply
typed lambda-calculus and adding natural numbers, the unit type, recursive
functions, and a global heap, then extending judgments with a type environment
and adding type abstraction, all while reusing the original theorems. We also
present a linear version of the simply typed CPS pass and compile a small
imperative language to the simply typed target to show how Pyrosome handles
substructural typing and imperative features.

</details>


### [11] [Fast Collection Operations from Indexed Stream Fusion](https://arxiv.org/abs/2507.06456)
*Scott Kovach,Praneeth Kolichala,Kyle A. Miller,David Broman,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: 论文提出了一种高效遍历和组合关联集合数据结构的系统，无需专用编译器或分阶段编译即可实现高效和可组合性，并通过索引流实现复杂连接。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种无需复杂编译器支持即可高效处理关联集合数据结构的系统。

Method: 基于索引流的表示方法，避免中间分配，实现在多个编程语言中的实现及正确性验证。

Result: 成功在Lean、Morphic和Rust中实现该库，并在Lean中提供了功能正确性的机械化证明。

Conclusion: 该系统提供了一种高效、可组合的关联数据结构处理方法，无需编译器支持，适用于多种语言。

Abstract: We present a system of efficient methods for traversing and combining
associative collection data structures. A distinguishing feature of the system
is that, like traditional sequential iterator libraries, it does not require
specialized compiler infrastructure or staged compilation for efficiency and
composability. By using a representation based on indexed streams, the library
can express complex joins over input collections while using no intermediate
allocations. We implement the library for the Lean, Morphic, and Rust
programming languages and provide a mechanized proof of functional correctness
in Lean.

</details>


### [12] [Finding Compiler Bugs through Cross-Language Code Generator and Differential Testing](https://arxiv.org/abs/2507.06584)
*Qiong Feng,Xiaotian Ma,Ziyuan Feng,Marat Akhin,Wei Song,Peng Liang*

Main category: cs.PL

TL;DR: 提出了CrossLangFuzzer框架，用于检测跨语言编译中的编译器错误，成功发现多个语言编译器中的bug。


<details>
  <summary>Details</summary>
Motivation: 填补跨语言编译正确性研究的空白，提升多语言环境下的编译器可靠性。

Method: 引入通用中间表示（IR），生成多样化的跨语言测试程序，并通过三种变异技术增强程序多样性。

Result: 发现了24个编译器bug，其中TypeChanger效果最佳，找出11个bug。

Conclusion: 首次针对跨语言编译错误进行研究，为多语言环境中的编译器改进提供支持。

Abstract: Compilers play a central role in translating high-level code into executable
programs, making their correctness essential for ensuring code safety and
reliability. While extensive research has focused on verifying the correctness
of compilers for single-language compilation, the correctness of cross-language
compilation - which involves the interaction between two languages and their
respective compilers - remains largely unexplored. To fill this research gap,
we propose CrossLangFuzzer, a novel framework that introduces a universal
intermediate representation (IR) for JVM-based languages and automatically
generates cross-language test programs with diverse type parameters and complex
inheritance structures. After generating the initial IR, CrossLangFuzzer
applies three mutation techniques - LangShuffler, FunctionRemoval, and
TypeChanger - to enhance program diversity. By evaluating both the original and
mutated programs across multiple compiler versions, CrossLangFuzzer
successfully uncovered 10 confirmed bugs in the Kotlin compiler, 4 confirmed
bugs in the Groovy compiler, 7 confirmed bugs in the Scala 3 compiler, 2
confirmed bugs in the Scala 2 compiler, and 1 confirmed bug in the Java
compiler. Among all mutators, TypeChanger is the most effective, detecting 11
of the 24 compiler bugs. Furthermore, we analyze the symptoms and root causes
of cross-compilation bugs, examining the respective responsibilities of
language compilers when incorrect behavior occurs during cross-language
compilation. To the best of our knowledge, this is the firstwork specifically
focused on identifying and diagnosing compiler bugs in cross-language
compilation scenarios. Our research helps to understand these challenges and
contributes to improving compiler correctness in multi-language environments.

</details>


### [13] [Sound Interval-Based Synthesis for Probabilistic Programs](https://arxiv.org/abs/2507.06939)
*Guilherme Espada,Alcides Fonseca*

Main category: cs.PL

TL;DR: 提出一种类型系统和算法，自动化选择概率程序模型，解决搜索空间大和无效程序问题，效果优于随机搜索和现有方法。


<details>
  <summary>Details</summary>
Motivation: 让无需统计专业知识的用户也能自动选择合适概率模型，提升概率编程的实用性。

Method: 设计类型系统静态拒绝无效程序，类型导向的合成算法确保生成类型安全程序，启发式搜索处理大搜索空间。

Result: 在文献数据集上测试，方法优于随机搜索和DaPPer，尤其复杂程序表现更佳。

Conclusion: 类型系统和合成算法显著提升程序生成效率，使得遗传编程等复杂技术得以应用。

Abstract: Probabilistic programming has become a standard practice to model stochastic
events and learn about the behavior of nature in different scientific contexts,
ranging from Genetics and Ecology to Linguistics and Psychology. However,
domain practitioners (such as biologists) also need to be experts in statistics
in order to select which probabilistic model is suitable for a given particular
problem, relying then on probabilistic inference engines such as Stan, Pyro or
Edward to fine-tune the parameters of that particular model. Probabilistic
Programming would be more useful if the model selection is made automatic,
without requiring statistics expertise from the end user. Automatically
selecting the model is challenging because of the large search space of
probabilistic programs needed to be explored, because the fact that most of
that search space contains invalid programs, and because invalid programs may
only be detected in some executions, due to its probabilistic nature. We
propose a type system to statically reject invalid probabilistic programs, a
type-directed synthesis algorithm that guarantees that generated programs are
type-safe by construction, and an heuristic search procedure to handle the vast
search space. We collect a number of probabilistic programs from the
literature, and use them to compare our method with both a type-agnostic random
search, and a data-guided method from the literature (DaPPer). Our results show
that our technique both outperforms random search and DaPPer, specially on more
complex programs. This drastic performance difference in synthesis allows for
fast sampling of programs and enables techniques that previously suffered from
the complexity of synthesis, such as Genetic Programming, to be applied.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [14] [gigiProfiler: Diagnosing Performance Issues by Uncovering Application Resource Bottlenecks](https://arxiv.org/abs/2507.06452)
*Yigong Hu,Haodong Zheng,Yicheng Liu,Dedong Xie,Youliang Huang,Baris Kasikci*

Main category: cs.PF

TL;DR: OmniResource Profiling整合系统级和应用级资源追踪，全面诊断性能瓶颈，gigiProfiler通过混合LLM-静态分析方法准确识别问题。


<details>
  <summary>Details</summary>
Motivation: 现代软件性能诊断复杂，传统分析工具无法有效应对应用级资源竞争问题。

Method: gigiProfiler采用混合LLM-静态分析方法，离线识别应用定义资源，并对比异常与正常执行数据。

Result: 在12个实际性能问题中，gigiProfiler均准确识别瓶颈，并成功诊断两个新问题。

Conclusion: OmniResource Profiling和gigiProfiler有效解决了传统工具的局限性，提升了性能诊断能力。

Abstract: Diagnosing performance bottlenecks in modern software is essential yet
challenging, particularly as applications become more complex and rely on
custom resource management policies. While traditional profilers effectively
identify execution bottlenecks by tracing system-level metrics, they fall short
when it comes to application-level resource contention caused by waiting for
application-level events. In this work, we introduce OmniResource Profiling, a
performance analysis approach that integrates system-level and
application-level resource tracing to diagnose resource bottlenecks
comprehensively. gigiProfiler, our realization of OmniResource Profiling, uses
a hybrid LLM-static analysis approach to identify application-defined resources
offline and analyze their impact on performance during buggy executions to
uncover the performance bottleneck. gigiProfiler then samples and records
critical variables related to these bottleneck resources during buggy execution
and compares their value with those from normal executions to identify the root
causes. We evaluated gigiProfiler on 12 real-world performance issues across
five applications. gigiProfiler accurately identified performance bottlenecks
in all cases. gigiProfiler also successfully diagnosed the root causes of two
newly emerged, previously undiagnosed problems, with the findings confirmed by
developers.

</details>


### [15] [Uncertainty Quantification as a Complementary Latent Health Indicator for Remaining Useful Life Prediction on Turbofan Engines](https://arxiv.org/abs/2507.06672)
*Lucas Thil,Jesse Read,Rim Kaddah,Guillaume Florent Doquet*

Main category: cs.PF

TL;DR: 提出一种新框架，改进RaPP生成健康指标（HI），通过分离不确定性提升剩余使用寿命（RUL）预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统HI方法受限于不确定性，改进RaPP性能的关键在于量化并分离不确定性。

Method: 结合标准与变分自编码器构建HI，并用于训练RUL预测模型。

Result: 在NASA数据集上表现优于传统方法和端到端模型，接近RUL估计方法。

Conclusion: 不确定性量化对HI构建和预测性能有显著影响。

Abstract: Health Indicators (HIs) are essential for predicting system failures in
predictive maintenance. While methods like RaPP (Reconstruction along Projected
Pathways) improve traditional HI approaches by leveraging autoencoder latent
spaces, their performance can be hindered by both aleatoric and epistemic
uncertainties. In this paper, we propose a novel framework that integrates
uncertainty quantification into autoencoder-based latent spaces, enhancing
RaPP-generated HIs. We demonstrate that separating aleatoric uncertainty from
epistemic uncertainty and cross combining HI information is the driver of
accuracy improvements in Remaining Useful Life (RUL) prediction. Our method
employs both standard and variational autoencoders to construct these HIs,
which are then used to train a machine learning model for RUL prediction.
Benchmarked on the NASA C-MAPSS turbofan dataset, our approach outperforms
traditional HI-based methods and end-to-end RUL prediction models and is
competitive with RUL estimation methods. These results underscore the
importance of uncertainty quantification in health assessment and showcase its
significant impact on predictive performance when incorporated into the HI
construction process.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [16] [One task to rule them all: A closer look at traffic classification generalizability](https://arxiv.org/abs/2507.06430)
*Elham Akbari,Zihao Zhou,Mohammad Ali Salahuddin,Noura Limam,Raouf Boutaba,Bertrand Mathieu,Stephanie Moteau,Stephane Tuffin*

Main category: cs.NI

TL;DR: 论文研究了现有网站指纹和流量分类方案在评估环境变化时的性能问题，通过跨数据集测试揭示了其局限性，并提出了一种考虑实际标签约束的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有方案在评估环境变化时性能下降，作者希望探究其原因并提出更实用的评估方法。

Method: 选择了三种先前的解决方案进行跨数据集测试，并设计了考虑标签约束的评估框架，使用真实TLS流量数据集模拟未来场景。

Result: 即使在标签数据充足的情况下，最佳方案的性能在分布偏移下仅为30%-40%，且1-Nearest Neighbor分类器表现不差。

Conclusion: 研究强调了现有方案的局限性，并提供了一种更接近现实的评估框架，有助于改进流量分类模型的实用性。

Abstract: Existing website fingerprinting and traffic classification solutions do not
work well when the evaluation context changes, as their performances often
heavily rely on context-specific assumptions. To clarify this problem, we take
three prior solutions presented for different but similar traffic
classification and website fingerprinting tasks, and apply each solution's
model to another solution's dataset. We pinpoint dataset-specific and
model-specific properties that lead each of them to overperform in their
specific evaluation context.
  As a realistic evaluation context that takes practical labeling constraints
into account, we design an evaluation framework using two recent real-world TLS
traffic datasets from large-scale networks. The framework simulates a
futuristic scenario in which SNIs are hidden in some networks but not in
others, and the classifier's goal is to predict destination services in one
network's traffic, having been trained on a labelled dataset collected from a
different network. Our framework has the distinction of including real-world
distribution shift, while excluding concept drift. We show that, even when
abundant labeled data is available, the best solutions' performances under
distribution shift are between 30% and 40%, and a simple 1-Nearest Neighbor
classifier's performance is not far behind. We depict all performances measured
on different models, not just the best ones, for a fair representation of
traffic models in practice.

</details>


### [17] [Stacked Intelligent Metasurfaces-Aided eVTOL Delay Sensitive Communications](https://arxiv.org/abs/2507.06632)
*Liyuan Chen,Kai Xiong,Yujie Qin,Hanqing Yu,Supeng Leng,Chau Yuen*

Main category: cs.NI

TL;DR: 论文提出了一种基于网络微积分的分析方法，用于量化AAM系统中通信延迟的概率上界，并通过BCD算法和SDR方法优化延迟问题。


<details>
  <summary>Details</summary>
Motivation: 城市化加速和人口密度增加导致地面交通拥堵，传统方法已无法有效解决，AAM系统及其核心组件eVTOL飞机成为新解决方案，但URLLC技术的不成熟对安全性提出挑战。

Method: 使用网络微积分工具量化通信延迟的概率上界，提出基于BCD算法和SDR方法的非凸优化问题解决方案。

Result: 分析了负载强度和总延迟对概率延迟边界的影响，并优化了传播延迟和概率延迟边界。

Conclusion: 研究填补了AAM系统中通信延迟量化框架的空白，为安全运营提供了理论支持。

Abstract: With rapid urbanization and increasing population density, urban traffic
congestion has become a critical issue, and traditional ground transportation
methods are no longer sufficient to address it effectively. To tackle this
challenge, the concept of Advanced Air Mobility (AAM) has emerged, aiming to
utilize low-altitude airspace to establish a three-dimensional transportation
system. Among various components of the AAM system, electric vertical take-off
and landing (eVTOL) aircraft plays a pivotal role due to their flexibility and
efficiency. However, the immaturity of Ultra Reliable Low Latency Communication
(URLLC) technologies poses significant challenges to safety-critical AAM
operations. Specifically, existing Stacked Intelligent Metasurfaces (SIM)-based
eVTOL systems lack rigorous mathematical frameworks to quantify probabilistic
delay bounds under dynamic air traffic patterns, a prerequisite for collision
avoidance and airspace management. To bridge this gap, we employ network
calculus tools to derive the probabilistic upper bound on communication delay
in the AAM system for the first time. Furthermore, we formulate a complex
non-convex optimization problem that jointly minimizes the probabilistic delay
bound and the propagation delay. To solve this problem efficiently, we propose
a solution based on the Block Coordinate Descent (BCD) algorithm and
Semidefinite Relaxation (SDR) method. In addition, we conduct a comprehensive
analysis of how various factors impact regret and transmission rate, and
explore the influence of varying load intensity and total delay on the
probabilistic delay bound.

</details>


### [18] [Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G](https://arxiv.org/abs/2507.06911)
*Michele Polese,Niloofar Mohamadi,Salvatore D'Oro,Tommaso Melodia*

Main category: cs.NI

TL;DR: 本文提出了一种融合O-RAN和AI-RAN的新型架构，支持在共享基础设施上统一管理电信和AI工作负载，旨在实现边缘AI的分布式部署和实时处理。


<details>
  <summary>Details</summary>
Motivation: 随着数据密集型AI应用在网络边缘的普及，需要重新设计RAN以支持分布式AI工作负载，同时为网络运营商提供商业化机会。

Method: 通过扩展O-RAN的模块化和云原生化原则，提出AI-RAN Orchestrator和AI-RAN站点，以统一管理和资源分配。

Result: 该架构支持异构AI部署，满足实时或批处理需求，同时保持开放的标准化接口和多厂商互操作性。

Conclusion: 该研究为边缘AI的分布式部署提供了高效的资源管理和灵活的架构方案。

Abstract: The proliferation of data-intensive Artificial Intelligence (AI) applications
at the network edge demands a fundamental shift in RAN design, from merely
consuming AI for network optimization, to actively enabling distributed AI
workloads. This paradigm shift presents a significant opportunity for network
operators to monetize AI at the edge while leveraging existing infrastructure
investments. To realize this vision, this article presents a novel converged
O-RAN and AI-RAN architecture that unifies orchestration and management of both
telecommunications and AI workloads on shared infrastructure. The proposed
architecture extends the Open RAN principles of modularity, disaggregation, and
cloud-nativeness to support heterogeneous AI deployments. We introduce two key
architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN
Service Management and Orchestration (SMO) to enable integrated resource and
allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide
distributed edge AI platforms with real-time processing capabilities. The
proposed system supports flexible deployment options, allowing AI workloads to
be orchestrated with specific timing requirements (real-time or batch
processing) and geographic targeting. The proposed architecture addresses the
orchestration requirements for managing heterogeneous workloads at different
time scales while maintaining open, standardized interfaces and multi-vendor
interoperability.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [19] [Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving](https://arxiv.org/abs/2507.06804)
*Zhenwen Liang,Linfeng Song,Yang Li,Tao Yang,Feng Zhang,Haitao Mi,Dong Yu*

Main category: cs.LO

TL;DR: 论文提出了一种新框架，通过解耦高层推理和底层证明生成，显著提升了自动化定理证明的能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在非正式推理表现优异，但在正式定理证明中表现不佳（成功率低于8%），主要原因是现有方法将推理和证明耦合在一起，限制了深度推理。

Method: 提出了一种解耦框架，使用两种模型：一个通用的推理器生成子目标引理，一个高效的证明器验证这些引理。

Result: 在2000年后的IMO问题上，该框架成功解决了5个问题，显著提升了自动化推理能力。

Conclusion: 解耦设计能够释放模型的推理潜力，为未来研究提供了新的方向和公开数据集。

Abstract: Automated Theorem Proving (ATP) in formal languages is a foundational
challenge for AI. While Large Language Models (LLMs) have driven remarkable
progress, a significant gap remains between their powerful informal reasoning
capabilities and their weak formal proving performance. Recent studies show
that the informal accuracy exceeds 80% while formal success remains below 8% on
benchmarks like PutnamBench. We argue this gap persists because current
state-of-the-art provers, by tightly coupling reasoning and proving, are
trained with paradigms that inadvertently punish deep reasoning in favor of
shallow, tactic-based strategies. To bridge this fundamental gap, we propose a
novel framework that decouples high-level reasoning from low-level proof
generation. Our approach utilizes two distinct, specialized models: a powerful,
general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an
efficient Prover to rigorously verify them. This modular design liberates the
model's full reasoning potential and bypasses the pitfalls of end-to-end
training. We evaluate our method on a challenging set of post-2000 IMO
problems, a problem set on which no prior open-source prover has reported
success. Our decoupled framework successfully solves 5 of these problems,
demonstrating a significant step towards automated reasoning on exceptionally
difficult mathematical challenges. To foster future research, we release our
full dataset of generated and verified lemmas for a wide range of IMO problems,
available at https://tencent-imo.github.io/ .

</details>


### [20] [Proof-Theoretic Functional Completeness for the Connexive Logic C](https://arxiv.org/abs/2507.06854)
*Sara Ayhan,Hrafn Valtýr Oddsson*

Main category: cs.LO

TL;DR: 证明了非经典否定不一致逻辑C的连接词在纯证明理论方法下的功能完备性。


<details>
  <summary>Details</summary>
Motivation: 探索C逻辑的否定不一致性和连接性特性，验证其功能完备性。

Method: 采用双边主义方法，结合高阶证明和反驳模式，并基于连接性推理理解。

Result: 成功证明了C逻辑连接词的功能完备性。

Conclusion: 通过独特的高阶反驳和连接性推理方法，验证了C逻辑的功能完备性。

Abstract: We show the functional completeness for the connectives of the non-trivial
negation inconsistent logic C by using a well-established method implementing
purely proof-theoretic notions only. Firstly, given that C contains a strong
negation, expressing a notion of direct refutation, the proof needs to be
applied in a bilateralist way in that not only higher-order rule schemata for
proofs but also for refutations need to be considered. Secondly, given that C
is a connexive logic we need to take a connexive understanding of inference as
a basis, leading to a different conception of (higher-order) refutation than is
usually employed.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [21] [Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice](https://arxiv.org/abs/2507.06235)
*Yuto Mandai,Katie Seaborn,Tomoyasu Nakano,Xin Sun,Yijia Wang,Jun Kato*

Main category: cs.HC

TL;DR: 该论文探索了"可爱"（Kawaii）声音特征的构成及如何通过声音频率调整来增强其感知，填补了以往仅关注视觉可爱性的研究空白。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补"Kawaii"概念在声音领域的研究空白，探索声音如何影响可爱感知，为计算机代理和社交机器人设计提供支持。

Method: 通过四阶段实验（总样本N=512），研究使用文本转语音（TTS）和游戏角色声音，调整基频和共振峰频率，分析其对可爱感知的影响。

Result: 发现特定声音在特定频率调整下能达到可爱感知的"甜蜜点"，并观察到部分声音存在感知上限效应。初步验证了可爱声音模型。

Conclusion: 研究为计算机声音的可爱性提供了实证基础与初步调控方法，未来可进一步优化声音设计。

Abstract: "Kawaii" is the Japanese concept of cute, which carries sociocultural
connotations related to social identities and emotional responses. Yet,
virtually all work to date has focused on the visual side of kawaii, including
in studies of computer agents and social robots. In pursuit of formalizing the
new science of kawaii vocalics, we explored what elements of voice relate to
kawaii and how they might be manipulated, manually and automatically. We
conducted a four-phase study (grand N = 512) with two varieties of computer
voices: text-to-speech (TTS) and game character voices. We found kawaii "sweet
spots" through manipulation of fundamental and formant frequencies, but only
for certain voices and to a certain extent. Findings also suggest a ceiling
effect for the kawaii vocalics of certain voices. We offer empirical validation
of the preliminary kawaii vocalics model and an elementary method for
manipulating kawaii perceptions of computer voice.

</details>


### [22] [Ragged Blocks: Rendering Structured Text with Style](https://arxiv.org/abs/2507.06460)
*Sam Cohen,Ravi Chugh*

Main category: cs.HC

TL;DR: 该论文提出了一种布局算法，生成称为“ragged blocks”或“rocks”的矩形多边形，能在不破坏文本排版的情况下实现嵌套装饰。


<details>
  <summary>Details</summary>
Motivation: 当前文本可视化方式（如平铺线装饰或嵌套框）无法同时兼顾结构展示和排版布局，限制了信息的丰富展示。

Method: 提出了一种布局算法，生成不规则多边形块（ragged blocks），支持嵌套装饰而不干扰排版。

Result: 在多种编程语言代码文件中测试表明，该算法生成的布局比传统方法更紧凑；通过示例展示了其潜在应用场景。

Conclusion: 该算法为未来文本编辑器等工具提供了丰富语义信息的展示新方式。

Abstract: Whether it be source code in a programming language, prose in natural
language, or otherwise, text is highly structured. Currently, text
visualizations are confined either to _flat, line-based_ decorations, which can
convey only limited information about textual structure, or _nested boxes_,
which convey structure but often destroy the typographic layout of the
underlying text. We hypothesize that the lack of rich styling options limits
the kinds of information that are displayed alongside text, wherever it may be
displayed.
  In this paper, we show that it is possible to achieve arbitrarily nested
decorations while minimally disturbing the underlying typographic layout.
Specifically, we present a layout algorithm that generates _ragged blocks_, or
_rocks_, which are rectilinear polygons that allow nested text to be compactly
rendered even when styled with borders and padding.
  We evaluate our layout algorithm in two ways. First, on a benchmark suite
comprising representative source code files in multiple programming languages,
we show that the (ragged block) layouts produced by our algorithm are
substantially more compact than the (rectangular block) layouts produced by
conventional techniques, when uniformly styling every element in the syntax
tree with borders and padding. Second, through a small gallery of usage
scenarios, we demonstrate how future code editors, word processors, and other
document-rendering GUIs might convey rich semantic information through
domain-specific styling of ragged blocks.

</details>


### [23] [Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents](https://arxiv.org/abs/2507.06483)
*Zackary Rackauckas,Julia Hirschberg*

Main category: cs.HC

TL;DR: 研究探讨了动漫风格的多模态语音代理如何影响用户互动，发现代理的设计（如声音、人设和语言风格）显著影响用户体验和学习动机。


<details>
  <summary>Details</summary>
Motivation: 探索动漫风格语音代理在语言学习中的效果，以及这些代理如何通过声音和风格设计提升用户互动和学习体验。

Method: 采用混合方法分析了54名参与者与基于大型语言模型和文本转语音的动漫风格代理的互动，重点研究了不同语言和文化背景下的用户行为和感知。

Result: 代理的设计（尤其是声音、人设和语言风格）显著影响用户的使用体验、学习动机和策略选择。

Conclusion: 动漫风格的多模态语音代理能提升用户互动和学习效果，为设计更具吸引力的社交响应系统提供指导。

Abstract: This study investigates how stylized, voiced agents shape user interaction in
a multimodal language learning environment. We conducted a mixed-methods
evaluation of 54 participants interacting with anime-inspired characters
powered by large language models and expressive text-to-speech synthesis. These
agents responded in Japanese character language, offering users asynchronous,
semi-structured conversation in varying speech styles and emotional tones. We
analyzed user engagement patterns, perceived usability, emotional responses,
and learning behaviors, with particular attention to how agent stylization
influenced interaction across language proficiency levels and cultural
backgrounds. Our findings reveal that agent design, especially voice, persona,
and linguistic style, substantially affected user experience, motivation, and
strategy. This work contributes to the understanding of affective, culturally
stylized agents in human-agent interaction and offers guidance for designing
more engaging, socially responsive systems.

</details>


### [24] [Towards Designing Social Interventions for Online Climate Change Denialism Discussions](https://arxiv.org/abs/2507.06561)
*Ruican zhong,Shruti Phadke,Beth Goldberg,Tanushree Mitra*

Main category: cs.HC

TL;DR: 研究提出一种使用内部语言在Reddit上干预气候变化否认阴谋论的新框架，发现证据干预促进了开放的讨论。


<details>
  <summary>Details</summary>
Motivation: 随着阴谋论的传播，需要研究有效的干预策略，促进基于证据和科学的讨论。

Method: 在Reddit上结合手动和生成AI方法设计干预消息，通过透明标记的机器人账户发布。

Result: 证据干预促进了气候变化否认者的积极讨论，支持者则提供了更多证据。

Conclusion: 研究为社交媒体干预提供了有价值见解，并指导未来研究。

Abstract: As conspiracy theories gain traction, it has become crucial to research
effective intervention strategies that can foster evidence and science-based
discussions in conspiracy theory communities online. This study presents a
novel framework using insider language to contest conspiracy theory ideology in
climate change denialism on Reddit. Focusing on discussions in two Reddit
communities, our research investigates reactions to pro-social and
evidence-based intervention messages for two cohorts of users: climate change
deniers and climate change supporters. Specifically, we combine manual and
generative AI-based methods to craft intervention messages and deploy the
interventions as replies on Reddit posts and comments through transparently
labeled bot accounts. On the one hand, we find that evidence-based
interventions with neutral language foster positive engagement, encouraging
open discussions among believers of climate change denialism. On the other,
climate change supporters respond positively, actively participating and
presenting additional evidence. Our study contributes valuable insights into
the process and challenges of automatically delivering interventions in
conspiracy theory communities on social media, and helps inform future research
on social media interventions.

</details>


### [25] [Smartphone Exergames with Real-Time Markerless Motion Capture: Challenges and Trade-offs](https://arxiv.org/abs/2507.06669)
*Mathieu Phosanarack,Laura Wallard,Sophie Lepreux,Christophe Kolski,Eugénie Avril*

Main category: cs.HC

TL;DR: 摘要讨论了基于智能手机的无标记动作捕捉技术用于运动游戏的前景，提出了开发中的挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 提高运动游戏的可及性和成本效益，使其更适合健康和康复应用。

Method: 利用智能手机摄像头和AI姿态估计技术开发实时运动游戏应用。

Result: 目前面临实时响应性和用户交互设计的挑战，未来需优化AI模型和改进用户体验。

Conclusion: 通过克服挑战，智能手机运动游戏有望成为促进大众健康的有力工具。

Abstract: Markerless Motion Capture (MoCap) using smartphone cameras is a promising
approach to making exergames more accessible and cost-effective for health and
rehabilitation. Unlike traditional systems requiring specialized hardware,
recent advancements in AI-powered pose estimation enable movement tracking
using only a mobile device. For an upcoming study, a mobile application with
real-time exergames including markerless motion capture is being developed.
However, implementing such technology introduces key challenges, including
balancing accuracy and real-time responsiveness, ensuring proper user
interaction. Future research should explore optimizing AI models for realtime
performance, integrating adaptive gamification, and refining user-centered
design principles. By overcoming these challenges, smartphone-based exergames
could become powerful tools for engaging users in physical activity and
rehabilitation, extending their benefits to a broader audience.

</details>


### [26] [Effects of task difficulty and music expertise in virtual reality: Observations of cognitive load and task accuracy in a rhythm exergame](https://arxiv.org/abs/2507.06691)
*Kyla Ellahiyoun,Emma Jane Pretty,Renan Guarese,Marcel Takac,Haytham Fayek,Fabio Zambetta*

Main category: cs.HC

TL;DR: 研究探讨了音乐训练、认知负荷(CL)和任务准确性在VR游戏《Beat Saber》中随难度增加的关系，发现音乐训练提高任务准确性但不直接减少主观CL。


<details>
  <summary>Details</summary>
Motivation: 探索音乐训练对VR游戏中认知负荷和任务表现的影响。

Method: 32名参与者在不同难度下玩游戏，通过问卷和生理数据测量分析。

Result: 音乐训练显著预测更高任务准确性，但不直接减少主观CL。

Conclusion: 音乐训练提升任务表现，未来研究可考虑音乐专长的其他分类方法。

Abstract: This study explores the relationship between musical training, cognitive load
(CL), and task accuracy within the virtual reality (VR) exergame Beat Saber
across increasing levels of difficulty. Participants (N=32) completed a series
of post-task questionnaires after playing the game under three task difficulty
levels while having their physiological data measured by an Emotibit. Using
regression analyses, we found that task difficulty and gaming experience
significantly predicted subjective CL, whereas musical training did not.
However, musical training significantly predicted higher task accuracy, along
with lower subjective CL, increased gaming experience, and greater
physiological arousal. These results suggest that musical training enhances
task-specific performance but does not directly reduce subjective CL. Future
research should consider alternative methods of grouping musical expertise and
the additional predictability of flow and self-efficacy.

</details>


### [27] [Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool](https://arxiv.org/abs/2507.06734)
*Milena Pustet,Elisabeth Steffen,Helena Mihaljević,Grischa Stanjek,Yannis Illies*

Main category: cs.HC

TL;DR: 探讨CSOs在AI开源工具开发中的参与，以监测Telegram上的反民主运动。


<details>
  <summary>Details</summary>
Motivation: 平台减少内容审核投入，CSOs需更积极参与AI工具开发，而非被动使用。

Method: 开发AI辅助的开源监控工具，与CSOs合作测试及改进。

Result: 目前工作中，尚无具体成果。

Conclusion: CSOs应与开源社区及学界合作，共同开发实用工具。

Abstract: The role of civil society organizations (CSOs) in monitoring harmful online
content is increasingly crucial, especially as platform providers reduce their
investment in content moderation. AI tools can assist in detecting and
monitoring harmful content at scale. However, few open-source tools offer
seamless integration of AI models and social media monitoring infrastructures.
Given their thematic expertise and contextual understanding of harmful content,
CSOs should be active partners in co-developing technological tools, providing
feedback, helping to improve models, and ensuring alignment with stakeholder
needs and values, rather than as passive 'consumers'. However, collaborations
between the open source community, academia, and civil society remain rare, and
research on harmful content seldom translates into practical tools usable by
civil society actors. This work in progress explores how CSOs can be
meaningfully involved in an AI-assisted open-source monitoring tool of
anti-democratic movements on Telegram, which we are currently developing in
collaboration with CSO stakeholders.

</details>


### [28] [Combining Human-centred Explainability and Explainable AI](https://arxiv.org/abs/2507.06751)
*Janin Koch,Vitor Fortes Rey*

Main category: cs.HC

TL;DR: 探讨人类中心可解释性（HCx）与AI可解释性（xAI）的差异与结合机会。


<details>
  <summary>Details</summary>
Motivation: 分析当前HCx与xAI的差异，探索它们的结合点。

Method: 讨论现有理论，并提出一种新的代数机器学习方法。

Result: 展示初步工作，提出HCx与xAI结合的设计机会。

Conclusion: 期待与HCxAI社区进一步讨论与合作。

Abstract: This position paper looks at differences between the current understandings
of human-centered explainability and explainability AI. We discuss current
ideas in both fields, as well as the differences and opportunities we
discovered. As an example of combining both, we will present preliminary work
on a new algebraic machine learning approach. We are excited to continue
discussing design opportunities for human-centered explainability (HCx) and xAI
with the broader HCxAI community.

</details>


### [29] [Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding](https://arxiv.org/abs/2507.06779)
*Martin Wimpff,Jan Zerfowski,Bin Yang*

Main category: cs.HC

TL;DR: 论文提出了一种名为RAP的方法，解决了深度学习在实时脑机接口（BCI）应用中的三大挑战：离线解码向在线解码的过渡、计算复杂度高和数据需求量大。RAP通过调整现有离线模型的池化层，实现实时解码，同时利用源自由的领域适应减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 深度学习在离线脑机接口中取得进展，但在实时应用中面临挑战：模型设计未考虑在线解码、计算复杂度高、数据需求大。

Method: 提出RAP方法，调整离线模型的池化层以实现实时解码，联合解码连续滑动窗口降低计算复杂度，并使用源自由的领域适应减少数据需求。

Result: RAP框架在实时BCI中表现稳健高效，保护隐私、减少校准需求，支持协同适应BCI系统。

Conclusion: RAP为深度学习在在线BCI中的广泛应用奠定了基础，有助于开发用户中心的高性能BCI系统。

Abstract: Despite the growing success of deep learning (DL) in offline brain-computer
interfaces (BCIs), its adoption in real-time applications remains limited due
to three primary challenges. First, most DL solutions are designed for offline
decoding, making the transition to online decoding unclear. Second, the use of
sliding windows in online decoding substantially increases computational
complexity. Third, DL models typically require large amounts of training data,
which are often scarce in BCI applications. To address these challenges and
enable real-time, cross-subject decoding without subject-specific calibration,
we introduce realtime adaptive pooling (RAP), a novel parameter-free method.
RAP seamlessly modifies the pooling layers of existing offline DL models to
meet online decoding requirements. It also reduces computational complexity
during training by jointly decoding consecutive sliding windows. To further
alleviate data requirements, our method leverages source-free domain
adaptation, enabling privacy-preserving adaptation across varying amounts of
target data. Our results demonstrate that RAP provides a robust and efficient
framework for real-time BCI applications. It preserves privacy, reduces
calibration demands, and supports co-adaptive BCI systems, paving the way for
broader adoption of DL in online BCIs. These findings lay a strong foundation
for developing user-centered, high-performance BCIs that facilitate immediate
feedback and user learning.

</details>


### [30] [Toward Neurodivergent-Aware Productivity: A Systems and AI-Based Human-in-the-Loop Framework for ADHD-Affected Professionals](https://arxiv.org/abs/2507.06864)
*Raghavendra Deshmukh*

Main category: cs.HC

TL;DR: 论文提出了一种结合系统思维、人机交互设计和AI/ML的框架，旨在为ADHD患者提供适应性支持工具，以解决高度分心工作环境中的注意力管理问题。


<details>
  <summary>Details</summary>
Motivation: IT和知识型行业的数字工作环境对注意力管理要求高，但对成人ADHD患者来说，这些环境会加剧时间感知障碍、数字干扰等挑战。现有工具未能满足其需求。

Method: 框架融合系统思维、人机交互设计、AI/ML和隐私优先的自适应代理，利用设备端ML感知用户行为（如标签使用、应用焦点），提供无干扰的注意力调节支持。

Result: 开发了一种可复制的模型，支持高干扰工作环境中的适应性工具，通过动态反馈循环改善注意力管理。

Conclusion: 该研究为神经多样性人群提供了实用且包容的支持工具，未来可推广至更多场景。

Abstract: Digital work environments in IT and knowledge-based sectors demand high
levels of attention management, task juggling, and self-regulation. For adults
with ADHD, these settings often amplify challenges such as time blindness,
digital distraction, emotional reactivity, and executive dysfunction. These
individuals prefer low-touch, easy-to-use interventions for daily tasks.
Conventional productivity tools often fail to support the cognitive variability
and overload experienced by neurodivergent professionals. This paper presents a
framework that blends Systems Thinking, Human-in-the-Loop design, AI/ML, and
privacy-first adaptive agents to support ADHD-affected users. The assistant
senses tab usage, application focus, and inactivity using on-device ML. These
cues are used to infer attention states and deliver nudges, reflective prompts,
or accountability-based presence (body doubling) that aid regulation without
disruption. Technically grounded in AI, the approach views attention as shaped
by dynamic feedback loops. The result is a replicable model for adaptive,
inclusive support tools in high-distraction work environments.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [31] [3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds](https://arxiv.org/abs/2507.06484)
*Fan-Yun Sun,Shengguang Wu,Christian Jacobsen,Thomas Yim,Haoming Zou,Alex Zook,Shangru Li,Yu-Hsin Chou,Ethem Can,Xunlei Wu,Clemens Eppner,Valts Blukis,Jonathan Tremblay,Jiajun Wu,Stan Birchfield,Nick Haber*

Main category: cs.GR

TL;DR: 提出了一种可扩展的方法，利用视觉-语言模型作为策略，生成高质量3D环境作为基础模型的训练数据，并通过自改进微调提升效果。


<details>
  <summary>Details</summary>
Motivation: 提升模型的空间推理能力，解决现有3D数据缺乏的问题，减少人工创建3D环境的劳动强度。

Method: 将3D环境构建转化为序列决策问题，使用视觉-语言模型作为策略生成布局、材质、光照等，并通过自改进微调框架3D-Generalist训练模型。

Result: 生成模拟就绪的3D环境，并在合成数据生成中展示出高质量和可扩展性。预训练模型在下游任务中超越人工合成数据预训练的模型，接近大规模真实数据的性能。

Conclusion: 提出的方法能有效生成高质量3D数据，为提升模型空间推理能力提供了可行的解决方案。

Abstract: Despite large-scale pretraining endowing models with language and vision
reasoning capabilities, improving their spatial reasoning capability remains
challenging due to the lack of data grounded in the 3D world. While it is
possible for humans to manually create immersive and interactive worlds through
3D graphics, as seen in applications such as VR, gaming, and robotics, this
process remains highly labor-intensive. In this paper, we propose a scalable
method for generating high-quality 3D environments that can serve as training
data for foundation models. We recast 3D environment building as a sequential
decision-making problem, employing Vision-Language-Models (VLMs) as policies
that output actions to jointly craft a 3D environment's layout, materials,
lighting, and assets. Our proposed framework, 3D-Generalist, trains VLMs to
generate more prompt-aligned 3D environments via self-improvement fine-tuning.
We demonstrate the effectiveness of 3D-Generalist and the proposed training
strategy in generating simulation-ready 3D environments. Furthermore, we
demonstrate its quality and scalability in synthetic data generation by
pretraining a vision foundation model on the generated data. After fine-tuning
the pre-trained model on downstream tasks, we show that it surpasses models
pre-trained on meticulously human-crafted synthetic data and approaches results
achieved with real data orders of magnitude larger.

</details>


### [32] [Assessing Learned Models for Phase-only Hologram Compression](https://arxiv.org/abs/2507.06646)
*Zicong Peng,Yicheng Zhan,Josef Spjut,Kaan Akşit*

Main category: cs.GR

TL;DR: 论文评估了四种基于INR和VAE结构的模型在压缩相位全息图方面的性能，发现SIREN表现最佳，而预训练VAE效果不佳。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索不同模型在相位全息图压缩任务中的表现，确定最适合的架构。

Method: 方法包括评估四种模型（MLP、SIREN、FilmSIREN和TAESD-VAE），比较它们在压缩和重建性能上的差异。

Result: 结果显示SIREN以4.9k参数实现了40%的压缩率和高质量重建（PSNR=34.54dB），而TAESD-VAE表现较差。

Conclusion: 结论是INR结构在相位全息图压缩中更有效，预训练VAE需要专门优化。

Abstract: We evaluate the performance of four common learned models utilizing INR and
VAE structures for compressing phase-only holograms in holographic displays.
The evaluated models include a vanilla MLP, SIREN, and FilmSIREN, with TAESD as
the representative VAE model. Our experiments reveal that a pretrained image
VAE, TAESD, with 2.2M parameters struggles with phase-only hologram
compression, revealing the need for task-specific adaptations. Among the INRs,
SIREN with 4.9k parameters achieves %40 compression with high quality in the
reconstructed 3D images (PSNR = 34.54 dB). These results emphasize the
effectiveness of INRs and identify the limitations of pretrained image
compression VAEs for hologram compression task.

</details>


### [33] [Better frame rates or better visuals? An early report of Esports player practice in Dota 2](https://arxiv.org/abs/2507.06790)
*Arjun Madhusudan,Benjamin Watson*

Main category: cs.GR

TL;DR: 研究探讨了 Dota 2 玩家为提升游戏性能而降低视觉质量的习惯及其动机，初步调查显示玩家普遍关闭 VSYNC 以减少延迟，未来需更大规模研究验证。


<details>
  <summary>Details</summary>
Motivation: 了解玩家如何在实践中平衡视觉质量与游戏性能，填补现有研究的空白。

Method: 通过调查收集 Dota 2 玩家的游戏配置数据及主观意图，分析其视觉质量调整行为。

Result: 玩家普遍关闭 VSYNC 以减少延迟，其意图与配置行为一致，但样本代表性有限。

Conclusion: 研究为未来大规模调查奠定基础，有助于指导新玩家、促进学术研究和开发者优化游戏配置。

Abstract: Esports athletes often reduce visual quality to improve latency and frame
rate, and increase their in-game performance. Little research has examined the
effects of this visuo-spatial tradeoff on performance, but we could find no
work studying how players manage this tradeoff in practice. This paper is an
initial examination of this question in the game Dota 2. First, we gather the
game configuration data of Dota 2 players in a small survey. We learn that
players do limit visual detail, particularly by turning off VSYNC, which
removes rendering/display synchronization delay but permits visual "tearing".
Second, we survey the intent of those same players with a few subjective
questions. Player intent matches configuration practice. While our sampling of
Dota 2 players may not be representative, our survey does reveal suggestive
trends that lay the groundwork for future, more rigorous and larger surveys.
Such surveys can help new players adapt to the game more quickly, encourage
researchers to investigate the relative importance of temporal and visual
detail, and justify design effort by developers in "low visual" game
configurations.

</details>


### [34] [Enhancing non-Rigid 3D Model Deformations Using Mesh-based Gaussian Splatting](https://arxiv.org/abs/2507.07000)
*Wijayathunga W. M. R. D. B*

Main category: cs.GR

TL;DR: 提出了一种新框架，通过将网格表示与3D高斯泼溅相结合，增强了非刚性3D模型变形能力。


<details>
  <summary>Details</summary>
Motivation: 传统的3D高斯泼溅虽能实现快速的实时辐射场渲染，但其后期编辑功能和对大规模非刚性变形的支持有限。

Method: 该方法将高斯核直接嵌入到显式网格表面，利用网格的拓扑和几何先验指导直观的编辑操作。

Result: 该方法支持复杂的变形（如弯曲和拉伸），并能灵活编辑3D组件。

Conclusion: 这项工作为虚拟现实、角色动画和交互设计等应用提供了更灵活的3D内容创建工作流程。

Abstract: We propose a novel framework that enhances non-rigid 3D model deformations by
bridging mesh representations with 3D Gaussian splatting. While traditional
Gaussian splatting delivers fast, real-time radiance-field rendering, its
post-editing capabilities and support for large-scale, non-rigid deformations
remain limited. Our method addresses these challenges by embedding Gaussian
kernels directly onto explicit mesh surfaces. This allows the mesh's inherent
topological and geometric priors to guide intuitive editing operations -- such
as moving, scaling, and rotating individual 3D components -- and enables
complex deformations like bending and stretching. This work paves the way for
more flexible 3D content-creation workflows in applications spanning virtual
reality, character animation, and interactive design.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [35] [Optimizing Cognitive Networks: Reinforcement Learning Meets Energy Harvesting Over Cascaded Channels](https://arxiv.org/abs/2507.06981)
*Deemah H. Tashman,Soumaya Cherkaoui,Walaa Hamouda*

Main category: cs.ET

TL;DR: 提出一种基于强化学习的物理层安全增强方法，用于认知车载网络中保护次级用户的通信安全。


<details>
  <summary>Details</summary>
Motivation: 移动网络如认知车载网络中，存在窃听者对次级用户通信的威胁，需提升安全性和可靠性。

Method: 利用全双工和能量收集能力的次级用户接收机生成干扰信号，并通过深度Q网络策略优化传输功率和能量收集决策。

Result: 该方法在安全性和可靠性上优于两种基线策略。

Conclusion: 所提出的深度Q网络方法能有效提升次级用户的保密率和吞吐量，同时满足主用户的干扰阈值。

Abstract: This paper presents a reinforcement learning (RL) based approach to improve
the physical layer security (PLS) of an underlay cognitive radio network (CRN)
over cascaded channels. These channels are utilized in highly mobile networks
such as cognitive vehicular networks (CVN). In addition, an eavesdropper aims
to intercept the communications between secondary users (SUs). The SU receiver
has full-duplex and energy harvesting capabilities to generate jamming signals
to confound the eavesdropper and enhance security. Moreover, the SU transmitter
extracts energy from ambient radio frequency signals in order to power
subsequent transmissions to its intended receiver. To optimize the privacy and
reliability of the SUs in a CVN, a deep Q-network (DQN) strategy is utilized
where multiple DQN agents are required such that an agent is assigned at each
SU transmitter. The objective for the SUs is to determine the optimal
transmission power and decide whether to collect energy or transmit messages
during each time period in order to maximize their secrecy rate. Thereafter, we
propose a DQN approach to maximize the throughput of the SUs while respecting
the interference threshold acceptable at the receiver of the primary user.
According to our findings, our strategy outperforms two other baseline
strategies in terms of security and reliability.

</details>


### [36] [Maximizing Reliability in Overlay Radio Networks with Time Switching and Power Splitting Energy Harvesting](https://arxiv.org/abs/2507.06983)
*Deemah H. Tashman,Soumaya Cherkaoui,Walaa Hamouda*

Main category: cs.ET

TL;DR: 研究了认知无线电网络中的能量效率和系统可靠性优化问题，通过能量收集协议和多天线技术提升网络性能。


<details>
  <summary>Details</summary>
Motivation: 认知无线电网络（CRN）能够解决频谱利用率低的问题，而本文重点研究其能量效率及系统可靠性优化的挑战。

Method: 采用时间切换能量收集协议和功率分配协议，利用多天线技术和最大比合并方法，评估中断概率和能量效率。

Result: 通过优化时间切换和功率分配参数，提升了次级用户的数据速率和系统可靠性。

Conclusion: 研究为认知无线电网络的能量效率和可靠性优化提供了有效方法，未来可进一步扩展应用场景。

Abstract: Cognitive radio networks (CRNs) are acknowledged for their ability to tackle
the issue of spectrum under-utilization. In the realm of CRNs, this paper
investigates the energy efficiency issue and addresses the critical challenge
of optimizing system reliability for overlay CRN access mode. Randomly
dispersed secondary users (SUs) serving as relays for primary users (PUs) are
considered, in which one of these relays is designated to harvest energy
through the time switching-energy harvesting (EH) protocol. Moreover, this
relay amplifies-and-forwards (AF) the PU's messages and broadcasts them along
with its own across cascaded $\kappa$-$\mu$ fading channels. The power
splitting protocol is another EH approach utilized by the SU and PU receivers
to enhance the amount of energy in their storage devices. In addition, the SU
transmitters and the SU receiver are deployed with multiple antennas for
reception and apply the maximal ratio combining approach. The outage
probability is utilized to assess both networks' reliability. Then, an energy
efficiency evaluation is performed to determine the effectiveness of EH on the
system. Finally, an optimization problem is provided with the goal of
maximizing the data rate of the SUs by optimizing the time switching and the
power allocation parameters of the SU relay.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [37] [Designing Parallel Algorithms for Community Detection using Arachne](https://arxiv.org/abs/2507.06471)
*Fuhuan Li,Zhihui Du,David A. Bader*

Main category: cs.DC

TL;DR: 本文提出了基于Arachne框架的并行标签传播和Louvain社区检测算法，显著优于现有Python工具（如NetworkX和igraph），并与并行框架NetworKit竞争，速度提升高达710倍。


<details>
  <summary>Details</summary>
Motivation: 由于图数据在各领域的广泛应用，需要高效且可扩展的社区检测算法。现有的Python工具缺乏高效并行能力。

Method: 在Arachne框架中并行实现标签传播和Louvain算法，利用其大规模图分析能力。

Result: 实验结果显示，Arachne方法比NetworkX快710倍，比igraph快75倍，比NetworKit快12倍，并行Louvain算法表现出良好的可扩展性。

Conclusion: Arachne的开源实现为大规模图分析提供了高性能社区检测工具。

Abstract: The rise of graph data in various fields calls for efficient and scalable
community detection algorithms. In this paper, we present parallel
implementations of two widely used algorithms: Label Propagation and Louvain,
specifically designed to leverage the capabilities of Arachne which is a
Python-accessible, open-source framework for large-scale graph analysis. Our
implementations achieve substantial speedups over existing Python-based tools
like NetworkX and igraph, which lack efficient parallelization, and are
competitive with parallel frameworks such as NetworKit. Experimental results
show that Arachne-based methods outperform these baselines, achieving speedups
of up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit.
Additionally, we analyze the scalability of our implementation under varying
thread counts, demonstrating how different phases contribute to overall
performance gains of the parallel Louvain algorithm. Arachne, including our
community detection implementation, is open-source and available at
https://github.com/Bears-R-Us/arkouda-njit .

</details>


### [38] [Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing](https://arxiv.org/abs/2507.06608)
*Xiaoxiang Shi,Colin Cai,Junjia Du,Zhanda Zhu,Xingda Wei,Zhihao Jia*

Main category: cs.DC

TL;DR: Nexus系统通过动态分配单个GPU资源，提高了GPU利用率并减少了延迟，相比现有方案在吞吐量和延迟上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的分阶段处理方案（如预填充和解码分离）需要更多硬件资源，而混合处理又会引入干扰，因此需要在单个GPU内实现资源动态分配以提高效率。

Method: 研究发现GPU资源存在收益递减现象，基于此，Nexus系统将单个GPU资源动态分配给预填充和解码任务，从而减少干扰。

Result: Nexus在多种模型和负载下，相比vLLM和SGLang，吞吐量提升2.2倍，初始响应时间（TTFT）降低20倍，尾部延迟（TBT）降低2.5倍。

Conclusion: Nexus通过在单个GPU内动态分配资源，显著提高了效率和性能，减少了硬件需求。

Abstract: Current prefill-decode (PD) disaggregation is typically deployed at the level
of entire serving engines, assigning separate GPUs to handle prefill and decode
phases. While effective at reducing latency, this approach demands more
hardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode
requests within the same batch, but introduces phase interference between
prefill and decode.
  While existing PD disaggregation solutions separate the phases across GPUs,
we ask: can the same decoupling be achieved within a single serving engine? The
key challenge lies in managing the conflicting resource requirements of prefill
and decode when they share the same hardware. In this paper, we first show that
chunked prefill requests cause interference with decode requests due to their
distinct requirements for GPU resources. Second, we find that GPU resources
exhibit diminishing returns. Beyond a saturation point, increasing GPU
allocation yields negligible latency improvements. This insight enables us to
split a single GPU's resources and dynamically allocate them to prefill and
decode on the fly, effectively disaggregating the two phases within the same
GPU.
  Across a range of models and workloads, our system Nexus achieves up to 2.2x
higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also
outperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x
lower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using
only half the number of GPUs.

</details>


### [39] [Towards Efficient and Scalable Distributed Vector Search with RDMA](https://arxiv.org/abs/2507.06653)
*Xiangyu Zhi,Meng Chen,Xiao Yan,Baotong Lu,Hui Li,Qianxi Zhang,Qi Chen,James Cheng*

Main category: cs.DC

TL;DR: CoTra是一个分布式执行向量搜索的系统，解决了单机内存和带宽限制的问题，通过算法与系统协同设计提升效率。


<details>
  <summary>Details</summary>
Motivation: 大规模向量搜索受限于单机内存和带宽，亟需分布式解决方案。

Method: 采用聚类数据分区、异步执行和任务推送等协同设计，减少通信开销。

Result: 在16台机器上，CoTra的查询吞吐量提升至单机的9.8-13.4倍，优于基线。

Conclusion: CoTra通过分布式设计和优化，显著提升了向量搜索的规模和效率。

Abstract: Similarity-based vector search facilitates many important applications such
as search and recommendation but is limited by the memory capacity and
bandwidth of a single machine due to large datasets and intensive data read. In
this paper, we present CoTra, a system that scales up vector search for
distributed execution. We observe a tension between computation and
communication efficiency, which is the main challenge for good scalability,
i.e., handling the local vectors on each machine independently blows up
computation as the pruning power of vector index is not fully utilized, while
running a global index over all machines introduces rich data dependencies and
thus extensive communication. To resolve such tension, we leverage the fact
that vector search is approximate in nature and robust to asynchronous
execution. In particular, we run collaborative vector search over the machines
with algorithm-system co-designs including clustering-based data partitioning
to reduce communication, asynchronous execution to avoid communication stall,
and task push to reduce network traffic. To make collaborative search
efficient, we introduce a suite of system optimizations including task
scheduling, communication batching, and storage format. We evaluate CoTra on
real datasets and compare with four baselines. The results show that when using
16 machines, the query throughput of CoTra scales to 9.8-13.4x over a single
machine and is 2.12-3.58x of the best-performing baseline at 0.95 recall@10.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [40] [Interactive Text-to-SQL via Expected Information Gain for Disambiguation](https://arxiv.org/abs/2507.06467)
*Luyu Qiu,Jianing Li,Chi Su,Lei Chen*

Main category: cs.DB

TL;DR: 论文提出了一种交互式Text-to-SQL框架，通过概率推理和多候选查询处理自然语言查询的歧义性，结合用户交互减少不确定性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有Text-to-SQL系统能将自然语言问题转化为SQL查询，但面对复杂数据库时因自然语言的歧义性易出错。需通过交互式方法提升准确性。

Method: 提出基于概率推理的框架，生成多个候选SQL查询并利用用户交互逐步消除歧义。使用期望信息增益作为决策准则选择最优澄清问题。

Result: 系统维持SQL查询的概率分布，通过交互减少不确定性，相比单输出的确定性方法更具鲁棒性。

Conclusion: 交互式Text-to-SQL框架通过概率和用户反馈有效解决自然语言歧义，显著提升复杂场景下的翻译准确性。

Abstract: Relational databases are foundational to numerous domains, including business
intelligence, scientific research, and enterprise systems. However, accessing
and analyzing structured data often requires proficiency in SQL, which is a
skill that many end users lack. With the development of Natural Language
Processing (NLP) technology, the Text-to-SQL systems attempt to bridge this gap
by translating natural language questions into executable SQL queries via an
automated algorithm. Yet, when operating on complex real-world databases, the
Text-to-SQL systems often suffer from ambiguity due to natural ambiguity in
natural language queries. These ambiguities pose a significant challenge for
existing Text-to-SQL translation systems, which tend to commit early to a
potentially incorrect interpretation. To address this, we propose an
interactive Text-to-SQL framework that models SQL generation as a probabilistic
reasoning process over multiple candidate queries. Rather than producing a
single deterministic output, our system maintains a distribution over possible
SQL outputs and seeks to resolve uncertainty through user interaction. At each
interaction step, the system selects a branching decision and formulates a
clarification question aimed at disambiguating that aspect of the query.
Crucially, we adopt a principled decision criterion based on Expected
Information Gain to identify the clarification that will, in expectation, most
reduce the uncertainty in the SQL distribution.

</details>


### [41] [QUEST: Query Optimization in Unstructured Document Analysis](https://arxiv.org/abs/2507.06515)
*Zhaoze Sun,Qiyan Deng,Chengliang Chai,Kaisen Jin,Xinyu Guo,Han Han,Ye Yuan,Guoren Wang,Lei Cao*

Main category: cs.DB

TL;DR: 研究人员提出QUEST系统，针对基于LLM的数据系统中提取操作的性能瓶颈，通过索引和优化策略显著降低成本并提高查询效率。


<details>
  <summary>Details</summary>
Motivation: 现有系统在处理非结构化文本文件时，因LLM的高成本和慢推理速度成为性能瓶颈。QUEST旨在优化这些系统，减少LLM调用成本。

Method: QUEST引入索引策略以减少提取操作成本，设计证据增强检索策略以减少遗漏，并开发实例优化查询执行策略以动态调整计划。

Result: 实验表明，QUEST在三个实际数据集上能节省30%-6倍成本，并将F1分数提高10%-27%。

Conclusion: QUEST通过多种创新策略显著提升了非结构化文档分析的效率和准确性。

Abstract: Most recently, researchers have started building large language models (LLMs)
powered data systems that allow users to analyze unstructured text documents
like working with a database because LLMs are very effective in extracting
attributes from documents. In such systems, LLM-based extraction operations
constitute the performance bottleneck of query execution due to the high
monetary cost and slow LLM inference. Existing systems typically borrow the
query optimization principles popular in relational databases to produce query
execution plans, which unfortunately are ineffective in minimizing LLM cost. To
fill this gap, we propose QUEST, which features a bunch of novel optimization
strategies for unstructured document analysis. First, we introduce an
index-based strategy to minimize the cost of each extraction operation. With
this index, QUEST quickly retrieves the text segments relevant to the target
attributes and only feeds them to LLMs. Furthermore, we design an
evidence-augmented retrieval strategy to reduce the possibility of missing
relevant segments. Moreover, we develop an instance-optimized query execution
strategy: because the attribute extraction cost could vary significantly
document by document, QUEST produces different plans for different documents.
For each document, QUEST produces a plan to minimize the frequency of attribute
extraction. The innovations include LLM cost-aware operator ordering strategies
and an optimized join execution approach that transforms joins into filters.
Extensive experiments on 3 real-world datasets demonstrate the superiority of
QUEST, achieving 30%-6x cost savings while improving the F1 score by 10% -27%
compared with state-of-the-art baselines.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [42] [SLDB: An End-To-End Heterogeneous System-on-Chip Benchmark Suite for LLM-Aided Design](https://arxiv.org/abs/2507.06376)
*Elisavet Lydia Alvanaki,Kevin Lee,Luca P. Carloni*

Main category: cs.AR

TL;DR: 论文介绍了SLDB数据集，用于评估大语言模型在系统级集成和配置任务中的表现，填补现有数据集中在低复杂度设计上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型（LLM）在硬件设计中表现良好，但现有数据集仅适用于组件级和低复杂度设计，缺乏系统级评估标准。因此，作者提出SLDB数据集以填补这一空白。

Method: SLDB数据集包含10个基线SoC设计，通过合成库可以组合成指数级数量的不同基于瓦片的SoC，并提供完整的SoC配置、加速器集成代码、通信参数等。

Result: SLDB提供了丰富的系统级设计数据，支持评估LLM在系统级任务中的表现，并与ESP平台兼容。

Conclusion: SLDB是一个针对系统级设计的专用基准数据集，为未来研究提供了重要工具。

Abstract: Over the last few years, Large Language Models (LLMs) have emerged as a
valuable tool for Electronic Design Automation (EDA). State-of-the-art research
in LLM-aided design has demonstrated the ability of LLMs to generate
syntactically correct RTL code, showcasing encouraging prospects for
integrating AI into the hardware design process. A key enabler of these
advancements is the availability of high-quality benchmarks to evaluate new
approaches. However, existing datasets and benchmarks fall short of
system-level design, as they focus primarily on component-level information and
low-complexity designs. To address this gap, we introduce the System-Level
Design Benchmark (SLDB), a dataset tailored for evaluating LLMs in system-level
integration and configuration tasks. SLDB includes a curated benchmark suite of
10 baseline SoC designs, whose components can be combined into an exponential
number of distinct tile-based SoCs through a synthetic library. The dataset
provides full SoC configurations, accelerator integration code, communication
parameters, and accelerator-aware system configurations, along with
testing-application code, compatible with the ESP platform[1].

</details>


### [43] [Towards LLM-based Root Cause Analysis of Hardware Design Failures](https://arxiv.org/abs/2507.06512)
*Siyu Qiu,Muzhi Wang,Raheel Afsharmazayejani,Mohammad Moradi Shahmiri,Benjamin Tan,Hammond Pearce*

Main category: cs.AR

TL;DR: 论文探讨了LLMs在数字硬件设计中识别和解释设计问题及错误的潜力，展示了高准确率的结果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是利用LLMs辅助硬件设计过程中的错误分析和解释，推动LLMs在硬件设计及安全分析中的广泛应用。

Method: 方法包括使用OpenAI的o3-mini推理模型，结合检索增强生成技术，分析34种不同的错误场景。

Result: 结果显示，o3-mini模型在pass@5评分下达到100%准确率，其他先进模型和配置通常超过80%，检索增强生成下超过90%。

Conclusion: 研究表明LLMs在硬件设计错误诊断中具有显著潜力，为未来更广泛的应用奠定了基础。

Abstract: With advances in large language models (LLMs), new opportunities have emerged
to develop tools that support the digital hardware design process. In this
work, we explore how LLMs can assist with explaining the root cause of design
issues and bugs that are revealed during synthesis and simulation, a necessary
milestone on the pathway towards widespread use of LLMs in the hardware design
process and for hardware security analysis. We find promising results: for our
corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model
reached a correct determination 100% of the time under pass@5 scoring, with
other state of the art models and configurations usually achieving more than
80% performance and more than 90% when assisted with retrieval-augmented
generation.

</details>


### [44] [Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics](https://arxiv.org/abs/2507.07044)
*Mehrdad Morsali,Chengwei Zhou,Deniz Najafi,Sreetama Sarkar,Pietro Mercati,Navid Khoshavi,Peter Beerel,Mahdi Nikdast,Gourav Datta,Shaahin Angizi*

Main category: cs.AR

TL;DR: OptoViT是一种基于硅光子技术的ViT加速器，通过混合电子-光子架构和区域感知优化，实现高效、低能耗的视觉处理。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在计算机视觉任务中表现出色，但其计算和内存需求高，难以在资源受限的场景中高效部署。

Method: OptoViT采用混合电子-光子架构，利用VCSELs和MRs处理密集计算，并通过MGNet减少冗余计算。还通过量化和矩阵分解优化ViT。

Result: OptoViT在多种任务中表现出色，实现了100.4 KFPS/W的能效和高达84%的节能效果，精度损失小于1.6%。

Conclusion: OptoViT为边缘设备提供了一个可扩展、高效的ViT部署方案，显著降低了计算和能耗需求。

Abstract: Vision Transformers (ViTs) have emerged as a powerful architecture for
computer vision tasks due to their ability to model long-range dependencies and
global contextual relationships. However, their substantial compute and memory
demands hinder efficient deployment in scenarios with strict energy and
bandwidth limitations. In this work, we propose OptoViT, the first near-sensor,
region-aware ViT accelerator leveraging silicon photonics (SiPh) for real-time
and energy-efficient vision processing. Opto-ViT features a hybrid
electronic-photonic architecture, where the optical core handles
compute-intensive matrix multiplications using Vertical-Cavity Surface-Emitting
Lasers (VCSELs) and Microring Resonators (MRs), while nonlinear functions and
normalization are executed electronically. To reduce redundant computation and
patch processing, we introduce a lightweight Mask Generation Network (MGNet)
that identifies regions of interest in the current frame and prunes irrelevant
patches before ViT encoding. We further co-optimize the ViT backbone using
quantization-aware training and matrix decomposition tailored for photonic
constraints. Experiments across device fabrication, circuit and architecture
co-design, to classification, detection, and video tasks demonstrate that
OptoViT achieves 100.4 KFPS/W with up to 84% energy savings with less than 1.6%
accuracy loss, while enabling scalable and efficient ViT deployment at the
edge.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [45] [Robust Containerization of the High Angular Resolution Functional Imaging (HARFI) Pipeline](https://arxiv.org/abs/2507.07010)
*Zhiyuan Li,Kurt G. Schilling,Bennett A. Landman*

Main category: physics.med-ph

TL;DR: 论文介绍了一个容器化的HARFI管道版本，便于更广泛地探索白质功能活动。


<details>
  <summary>Details</summary>
Motivation: 传统fMRI主要关注灰质，而白质的功能活动在认知和学习中也起重要作用。HARFI管道虽已提出，但因技术复杂性限制了推广。

Method: 开发了一个容器化的HARFI管道版本，支持在多公共数据集上无缝执行。

Result: 实现了更高效和可复现的白质功能研究工具。

Conclusion: 容器化的HARFI管道为白质功能研究提供了更广泛和可访问的工具，支持高分辨率功能相关性分析。

Abstract: Historically, functional magnetic resonance imaging (fMRI) of the brain has
focused primarily on gray matter, particularly the cortical gray matter and
associated nuclei. However, recent work has demonstrated that functional
activity in white matter also plays a meaningful role in both cognition and
learning. In previous work, we introduced the High Angular Resolution
Functional Imaging (HARFI) pipeline, which demonstrated both local and global
patterns of functional correlation in white matter. Notably, HARFI enabled
exploration of asymmetric voxel-wise correlation using odd-order spherical
harmonics. Although the original implementation of HARFI was released via
GitHub, adoption was limited due to the technical complexity of running the
source code. In this work, we present a robust and efficient containerized
version of the HARFI pipeline, enabling seamless execution across multiple
public datasets. Our goal is to facilitate broader and deeper exploration of
functional white matter architecture, especially through the lens of high
angular resolution functional correlations. The key innovation of this work is
the containerized implementation, which we have made available under a
permissive open-source license to support reproducible and accessible research
practices.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [46] [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](https://arxiv.org/abs/2507.06528)
*Huisheng Wang,Zhuoshi Pan,Hangjing Zhang,Mingxiao Liu,Hanqing Gao,H. Vicky Zhao*

Main category: cs.CL

TL;DR: 论文提出InvestAlign框架，用理论生成的简单投资问题数据训练LLM，解决了真实用户数据稀缺问题，实验显示训练效率更高且结果更接近真实用户行为。


<details>
  <summary>Details</summary>
Motivation: 行为金融学中，LLM与投资者羊群行为的对齐面临真实用户数据稀缺的挑战，现有监督微调（SFT）方法数据收集成本高且隐私风险大。

Method: 提出InvestAlign框架，通过理论生成的简单最优投资问题构建高质量SFT数据集，取代复杂场景的真实数据。

Result: 实验证明，用InvestAlign生成的数据训练LLM比真实数据收敛更快，且微调后的模型InvestAgent在简单和复杂投资问题中更接近真实用户行为。

Conclusion: InvestAlign为LLM与投资者羊群行为的对齐提供了高效且无隐私风险的新方法，有望解决复杂投资问题。

Abstract: Aligning Large Language Models (LLMs) with investor decision-making processes
under herd behavior is a critical challenge in behavioral finance, which
grapples with a fundamental limitation: the scarcity of real-user data needed
for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM
outputs and human behavioral patterns, its reliance on massive authentic data
imposes substantial collection costs and privacy risks. We propose InvestAlign,
a novel framework that constructs high-quality SFT datasets by leveraging
theoretical solutions to similar and simple optimal investment problems rather
than complex scenarios. Our theoretical analysis demonstrates that training
LLMs with InvestAlign-generated data achieves faster parameter convergence than
using real-user data, suggesting superior learning efficiency. Furthermore, we
develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which
demonstrates significantly closer alignment to real-user data than pre-SFT
models in both simple and complex investment problems. This highlights our
proposed InvestAlign as a promising approach with the potential to address
complex optimal investment problems and align LLMs with investor
decision-making processes under herd behavior. Our code is publicly available
at https://github.com/thu-social-network-research-group/InvestAlign.

</details>


### [47] [Humans overrely on overconfident language models, across languages](https://arxiv.org/abs/2507.06306)
*Neil Rathi,Dan Jurafsky,Kaitlyn Zhou*

Main category: cs.CL

TL;DR: 研究多语言大模型的信心表达差异及其对用户依赖行为的影响，发现不同语言背景下模型和用户的反应差异显著。


<details>
  <summary>Details</summary>
Motivation: 大模型的多语言部署需确保其信心表达的准确性，以减少用户过度依赖。研究旨在评估模型在不同语言中的表现。

Method: 分析了五种语言中大模型生成的认知标记分布，并测量了用户对这些标记的依赖行为。

Result: 模型在不同语言中表现出不同程度的过度自信，用户依赖行为也存在跨语言差异。

Conclusion: 多语言背景下模型的安全性评估需考虑文化和语言差异，以降低用户过度依赖的风险。

Abstract: As large language models (LLMs) are deployed globally, it is crucial that
their responses are calibrated across languages to accurately convey
uncertainty and limitations. Previous work has shown that LLMs are
linguistically overconfident in English, leading users to overrely on confident
generations. However, the usage and interpretation of epistemic markers (e.g.,
'It's definitely,' 'I think') can differ sharply across languages. Here, we
study the risks of multilingual linguistic (mis)calibration, overconfidence,
and overreliance across five languages to evaluate the safety of LLMs in a
global context.
  We find that overreliance risks are high across all languages. We first
analyze the distribution of LLM-generated epistemic markers, and observe that
while LLMs are cross-linguistically overconfident, they are also sensitive to
documented linguistic variation. For example, models generate the most markers
of uncertainty in Japanese and the most markers of certainty in German and
Mandarin. We then measure human reliance rates across languages, finding that
while users strongly rely on confident LLM generations in all languages,
reliance behaviors differ cross-linguistically: for example, users rely
significantly more on expressions of uncertainty in Japanese than in English.
Taken together, these results indicate high risk of reliance on overconfident
model generations across languages. Our findings highlight the challenges of
multilingual linguistic calibration and stress the importance of culturally and
linguistically contextualized model safety evaluations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [48] [Learning To Communicate Over An Unknown Shared Network](https://arxiv.org/abs/2507.06499)
*Shivangi Agarwal,Adi Asija,Sanjit K. Kaul,Arani Bhattacharya,Saket Anand*

Main category: cs.MA

TL;DR: 该论文提出了一种名为QNet的深度强化学习模型，用于解决在多代理共享无线网络环境中，单个代理如何优化其通信策略的问题。通过一个参数化的仿真到真实框架，QNet能够泛化到不同网络配置，并在真实无线网络中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在多个场景中的应用增加，无线网络通常会被多个代理与边缘云之间的数据流共享。代理无法完全了解网络资源的状态，尤其是在其他代理的通信动态变化的情况下。因此，需要一种能够优化代理通信策略的通用方法。

Method: 提出了一种名为QNet的深度强化学习模型，通过一个参数化的仿真到真实框架进行训练。仿真模型仅需一个参数，且对无线网络的具体配置保持不可知性。学习方法解决了QNet训练中的挑战。

Result: 在真实无线网络（包括WiFi和蜂窝网络）的实验验证了QNet的有效性。实验覆盖了从低竞争（5个代理）到高竞争（50个代理）的场景，并在广泛的网络条件下进行了测试。

Conclusion: QNet作为一种通用策略，能够在不同网络配置和代理数量下有效优化通信，且无需针对特定网络配置进行重新训练。仿真到真实的框架为类似问题提供了一种可行的解决方案。

Abstract: As robots (edge-devices, agents) find uses in an increasing number of
settings and edge-cloud resources become pervasive, wireless networks will
often be shared by flows of data traffic that result from communication between
agents and corresponding edge-cloud. In such settings, agent communicating with
the edge-cloud is unaware of state of network resource, which evolves in
response to not just agent's own communication at any given time but also to
communication by other agents, which stays unknown to the agent. We address
challenge of an agent learning a policy that allows it to decide whether or not
to communicate with its cloud node, using limited feedback it obtains from its
own attempts to communicate, to optimize its utility. The policy generalizes
well to any number of other agents sharing the network and must not be trained
for any particular network configuration. Our proposed policy is a DRL model
Query Net (QNet) that we train using a proposed simulation-to-real framework.
Our simulation model has just one parameter and is agnostic to specific
configurations of any wireless network. It allows training an agent's policy
over a wide range of outcomes that an agent's communication with its edge-cloud
node may face when using a shared network, by suitably randomizing the
simulation parameter. We propose a learning algorithm that addresses challenges
observed in training QNet. We validate our simulation-to-real driven approach
through experiments conducted on real wireless networks including WiFi and
cellular. We compare QNet with other policies to demonstrate its efficacy. WiFi
experiments involved as few as five agents, resulting in barely any contention
for the network, to as many as fifty agents, resulting in severe contention.
The cellular experiments spanned a broad range of network conditions, with
baseline RTT ranging from a low of 0.07 second to a high of 0.83 second.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [49] [QoE Optimization for Semantic Self-Correcting Video Transmission in Multi-UAV Networks](https://arxiv.org/abs/2507.06717)
*Xuyang Chen,Chong Huang,Daquan Feng,Lei Luo,Yao Sun,Xiang-Gen Xia*

Main category: eess.IV

TL;DR: 提出一种新的语义自校正视频传输框架（SSCV-G），通过超精细比特率控制提升实时无人机视频流的带宽效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 实时无人机视频流在远程监控、应急响应等应用中至关重要，但面临带宽有限、延迟波动和高丢包率的挑战。

Method: 采用语义码本空间编码视频帧，结合ST-ViT进行多帧联合解码，并通过MUPPO强化学习优化资源分配和比特率选择。

Result: SSCV-G在编码效率、带宽适应性和丢包鲁棒性上显著优于现有视频编解码器，MUPPO优化也优于现有基准。

Conclusion: SSCV-G框架有效解决了实时无人机视频流的核心挑战，为相关应用提供了高效解决方案。

Abstract: Real-time unmanned aerial vehicle (UAV) video streaming is essential for
time-sensitive applications, including remote surveillance, emergency response,
and environmental monitoring. However, it faces challenges such as limited
bandwidth, latency fluctuations, and high packet loss. To address these issues,
we propose a novel semantic self-correcting video transmission framework with
ultra-fine bitrate granularity (SSCV-G). In SSCV-G, video frames are encoded
into a compact semantic codebook space, and the transmitter adaptively sends a
subset of semantic indices based on bandwidth availability, enabling
fine-grained bitrate control for improved bandwidth efficiency. At the
receiver, a spatio-temporal vision transformer (ST-ViT) performs multi-frame
joint decoding to reconstruct dropped semantic indices by modeling intra- and
inter-frame dependencies. To further improve performance under dynamic network
conditions, we integrate a multi-user proximal policy optimization (MUPPO)
reinforcement learning scheme that jointly optimizes communication resource
allocation and semantic bitrate selection to maximize user Quality of
Experience (QoE). Extensive experiments demonstrate that the proposed SSCV-G
significantly outperforms state-of-the-art video codecs in coding efficiency,
bandwidth adaptability, and packet loss robustness. Moreover, the proposed
MUPPO-based QoE optimization consistently surpasses existing benchmarks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

Main category: cs.AI

TL;DR: MEWI是一个三维多人医疗疏散模拟工具，用于课堂模拟和评估医疗疏散网络规划。


<details>
  <summary>Details</summary>
Motivation: 缺乏在课堂环境中模拟医疗疏散网络并评估规划和决策的工具。

Method: 开发了MEWI模拟器，模拟战场约束和不确定性，包括两场实战场景测试。

Result: MEWI显著提高了学员对医疗疏散知识的学习和协作决策能力。

Conclusion: MEWI是医疗教育高保真训练工具的重要进步，可改进联合部队的医疗疏散教育和操作。

Abstract: Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.

</details>


### [51] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

Main category: cs.AI

TL;DR: 论文提出了一种名为PDL（Prompt Declaration Language）的新方法，用于解决LLMs中提示工程的复杂性，通过声明式表示提升程序员生产力并支持优化。


<details>
  <summary>Details</summary>
Motivation: 现有框架在提示工程中要么隐藏复杂性，要么提供不灵活的预设模式，限制了高级代理编程的能力。

Method: 提出了PDL，一种新的提示表示方法，将提示置于核心位置，支持手动和自动调优，并能够组合LLM调用、规则代码和外部工具。

Result: 通过实际案例研究（合规代理），PDL的提示模式调优比传统代理和预设模式提升了高达4倍的性能。

Conclusion: PDL通过抽象化复杂性并提供声明式表示，显著提升了程序员生产力和提示优化的潜力。

Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either
hiding complexity behind restrictive APIs or providing inflexible canned
patterns that resist customization -- making sophisticated agentic programming
challenging. We present the Prompt Declaration Language (PDL), a novel approach
to prompt representation that tackles this fundamental complexity by bringing
prompts to the forefront, enabling manual and automatic prompt tuning while
capturing the composition of LLM calls together with rule-based code and
external tools. By abstracting away the plumbing for such compositions, PDL
aims at improving programmer productivity while providing a declarative
representation that is amenable to optimization. This paper demonstrates PDL's
utility through a real-world case study of a compliance agent. Tuning the
prompting pattern of this agent yielded up to 4x performance improvement
compared to using a canned agent and prompt pattern.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [52] [Forex Trading Robot Using Fuzzy Logic](https://arxiv.org/abs/2507.06383)
*Mustafa Shabani,Alireza Nasiri,Hassan Nafardi*

Main category: eess.SY

TL;DR: 提出一种基于模糊逻辑的外汇市场短期交易系统，通过模糊Mamdani系统替代传统指标，结合投票机制设计交易机器人，显著提高了盈利因子。


<details>
  <summary>Details</summary>
Motivation: 传统基于振荡器指标的外汇交易策略因市场动态变化效果不佳，需改进以提高交易准确性。

Method: 为每个指标引入模糊Mamdani系统，通过投票机制整合结果设计交易机器人。

Result: 相比其他三种方法，盈利因子显著提高，并计算比较了净利润、总利润和最大资本回撤。

Conclusion: 模糊系统能有效提升外汇短期交易的盈利能力，优于传统指标方法。

Abstract: In this study, we propose a fuzzy system for conducting short-term
transactions in the forex market. The system is designed to enhance common
strategies in the forex market using fuzzy logic, thereby improving the
accuracy of transactions. Traditionally, technical strategies based on
oscillator indicators have relied on predefined ranges for indicators such as
Relative Strength Index (RSI), Commodity Channel Indicator (CCI), and
Stochastic to determine entry points for trades. However, the use of these
classic indicators has yielded suboptimal results due to the changing nature of
the market over time. In our proposed approach, instead of employing classical
indicators, we introduce a fuzzy Mamdani system for each indicator. The results
obtained from these systems are then combined through voting to design a
trading robot. Our findings demonstrate a considerable increase in the
profitability factor compared to three other methods. Additionally, net profit,
gross profit, and maximum capital reduction are calculated and compared across
all approaches.

</details>


<div id='stat.CO'></div>

# stat.CO [[Back]](#toc)

### [53] [Accelerated Spatio-Temporal Bayesian Modeling for Multivariate Gaussian Processes](https://arxiv.org/abs/2507.06938)
*Lisa Gaedke-Merzhäuser,Vincent Maillou,Fernando Rodriguez Avellaneda,Olaf Schenk,Mathieu Luisier,Paula Moraga,Alexandros Nikolaos Ziogas,Håvard Rue*

Main category: stat.CO

TL;DR: DALIA是一个高度可扩展的框架，用于在时空多元高斯过程上进行贝叶斯推断，通过GPU加速和分布式内存并行方案，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决高维时空应用中多元高斯过程的计算挑战。

Method: 基于稀疏逆协方差矩阵、GPU加速的块密集方法和三层分布式内存并行方案。

Result: 性能提升两个数量级，参数空间扩大8倍；在496个GH200超级芯片上实现三个数量级的加速。应用于意大利北部空气质量数据，展现了更高分辨率的分析。

Conclusion: DALIA框架显著提升了多元高斯过程在时空应用中的计算效率和实用性。

Abstract: Multivariate Gaussian processes (GPs) offer a powerful probabilistic
framework to represent complex interdependent phenomena. They pose, however,
significant computational challenges in high-dimensional settings, which
frequently arise in spatial-temporal applications. We present DALIA, a highly
scalable framework for performing Bayesian inference tasks on spatio-temporal
multivariate GPs, based on the methodology of integrated nested Laplace
approximations. Our approach relies on a sparse inverse covariance matrix
formulation of the GP, puts forward a GPU-accelerated block-dense approach, and
introduces a hierarchical, triple-layer, distributed memory parallel scheme. We
showcase weak scaling performance surpassing the state-of-the-art by two orders
of magnitude on a model whose parameter space is 8$\times$ larger and measure
strong scaling speedups of three orders of magnitude when running on 496 GH200
superchips on the Alps supercomputer. Applying DALIA to air pollution data from
northern Italy over 48 days, we showcase refined spatial resolutions over the
aggregated pollutant measurements.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [54] [Base-extension Semantics for Intuitionistic Modal Logics](https://arxiv.org/abs/2507.06834)
*Yll Buzoku,David. J. Pym*

Main category: math.LO

TL;DR: 该论文探讨了直觉主义模态逻辑的证明理论和语义学，通过基础扩展语义（B-eS）提供了与克里普克模型直接对应的证明论语义学，并系统性建立了与Simpson的自然演绎系统的可靠性和完备性定理。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为直觉主义模态逻辑提供一种基于证明论语义学的替代方法（B-eS），以补充传统的模型论语义学，并验证其与现有自然演绎系统的兼容性。

Method: 采用基础扩展语义（B-eS）作为证明论语义学的具体形式，系统性研究了Simpson的直觉主义模态逻辑，并通过验证原子公式的可证明性来建立语义框架。

Result: 成功构建了直觉主义模态逻辑的B-eS框架，并证明了其与Simpson的自然演绎系统在可靠性和完备性上的一致性。

Conclusion: 基础扩展语义（B-eS）为直觉主义模态逻辑提供了有效的证明论语义学方法，补充了传统模型论语义学的不足，且与现有系统兼容。

Abstract: The proof theory and semantics of intuitionistic modal logics have been
studied by Simpson in terms of Prawitz-style labelled natural deduction systems
and Kripke models. An alternative to model-theoretic semantics is provided by
proof-theoretic semantics, which is a logical realization of inferentialism, in
which the meaning of constructs is understood through their use. The key idea
in proof-theoretic semantics is that of a base of atomic rules, all of which
refer only to propositional atoms and involve no logical connectives. A
specific form of proof-theoretic semantics, known as base-extension semantics
(B-eS), is concerned with the validity of formulae and provides a direct
counterpart to Kripke models that is grounded in the provability of atomic
formulae in a base. We establish, systematically, B-eS for Simpson's
intuitionistic modal logics and, also systematically, obtain soundness and
completeness theorems with respect to Simpson's natural deduction systems.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [55] [Connecting the Unconnected -- Sentiment Analysis of Field Survey of Internet Connectivity in Emerging Economies](https://arxiv.org/abs/2507.06827)
*Dibakar Das,Barath S Narayan,Aarna Bhammar,Jyotsna Bapat*

Main category: cs.CY

TL;DR: 该论文分析了尼泊尔加德满都部分地区的互联网使用情况，调查显示高速、低成本、可靠和安全的互联网是主要需求，情感分析显示大多数反馈为正面。


<details>
  <summary>Details</summary>
Motivation: 调查触发于城市部分地区的间歇性严重网络拥堵，旨在了解互联网使用现状及其对生活的影响，以及用户对未来互联网的期望。

Method: 通过在加德满都三个不同地区进行实地调查，收集受访者对互联网使用的体验、影响和未来期望的数据，并进行情感分析和人口统计信息分析。

Result: 调查结果显示受访者对互联网的主要期望是高速、低成本、可靠和安全，情感分析中多数反馈为正面，且正面情绪的方差较大。

Conclusion: 尽管互联网覆盖率较高，但仍有许多地区存在需求未满足的问题，调查结果为改进互联网服务提供了重要参考。

Abstract: Internet has significantly improved the quality of citizens across the world.
Though the internet coverage is quite high, 40% of global population do not
have access to broadband internet. This paper presents an analysis of a field
survey of population in some areas of Kathmandu, Nepal, an emerging economy.
This survey was triggered by intermittent severe congestion of internet in
certain areas of the city. People from three different areas were asked about
their present experience of internet usage, its impact on their lives and their
aspirations for the future. Survey pointed to high speed, low cost, reliable
and secure internet as a major aspiration of the respondents. Based on their
inputs, this paper presents a sentiment analysis as well as demographic
information. Keys insights from this analysis shows that overall sentiment to
most queries are positive. The variances of positive sentiments are high
whereas those for negative ones are low. Also, some correlations and clusters
are observed among the attributes though no dominant component exists in the
data.

</details>


### [56] [Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study](https://arxiv.org/abs/2507.06438)
*Kaléu Delphino*

Main category: cs.CY

TL;DR: 工具如ChatGPT能通过自然语言输入生成代码，对学生完成作业构成作弊威胁。一项针对120名CS学生的调查显示，超25%受访者承认AI作弊，而采访参与率极低。


<details>
  <summary>Details</summary>
Motivation: 研究AI工具如何威胁当前计算机科学教育，尤其是学生利用这些工具作弊。

Method: 通过匿名调查和采访评估AI作弊比例。

Result: 25%学生承认AI作弊，但采访仅一人参与。

Conclusion: 调查是有效方法，采访需改进设计以提高参与度。

Abstract: Tools that can generate computer code in response to inputs written in
natural language, such as ChatGPT, pose an existential threat to Computer
Science education in its current form, since students can now use these tools
to solve assignments without much effort. While that risk has already been
recognized by scholars, the proportion of the student body that is incurring in
this new kind of plagiarism is still an open problem. We conducted a pilot
study in a large CS class (n=120) to assess the feasibility of estimating AI
plagiarism through anonymous surveys and interviews. More than 25% of the
survey respondents admitted to committing AI plagiarism. Conversely, only one
student accepted to be interviewed. Given the high levels of misconduct
acknowledgment, we conclude that surveys are an effective method for studies on
the matter, while interviews should be avoided or designed in a way that can
entice participation.

</details>


### [57] [Do AI tutors empower or enslave learners? Toward a critical use of AI in education](https://arxiv.org/abs/2507.06878)
*Lucile Favero,Juan-Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.CY

TL;DR: 论文探讨了AI在教育中的潜在风险，特别是对学生批判性思维的负面影响，并提出如何负责任地使用AI的策略。


<details>
  <summary>Details</summary>
Motivation: 研究AI在教育中过度依赖的潜在危害，尤其是对学生认知能力和自主学习能力的削弱。

Method: 基于认知科学和教育学理论，分析AI使用对学生学习、自我效能和隐私的影响，并提出应对策略。

Result: 指出AI的滥用可能导致认知萎缩、情感风险和伦理问题，强调需要透明和负责任的AI使用方式。

Conclusion: 倡导在教育中采取有意识的、透明的AI使用策略，以支持而非削弱学习者的能力。

Abstract: The increasing integration of AI tools in education presents both
opportunities and challenges, particularly regarding the development of the
students' critical thinking skills. This position paper argues that while AI
can support learning, its unchecked use may lead to cognitive atrophy, loss of
agency, emotional risks, and ethical concerns, ultimately undermining the core
goals of education. Drawing on cognitive science and pedagogy, the paper
explores how over-reliance on AI can disrupt meaningful learning, foster
dependency and conformity, undermine the students' self-efficacy, academic
integrity, and well-being, and raise concerns about questionable privacy
practices. It also highlights the importance of considering the students'
perspectives and proposes actionable strategies to ensure that AI serves as a
meaningful support rather than a cognitive shortcut. The paper advocates for an
intentional, transparent, and critically informed use of AI that empowers
rather than diminishes the learner.

</details>


### [58] [Exploring Public Perceptions of Generative AI in Libraries: A Social Media Analysis of X Discussions](https://arxiv.org/abs/2507.07047)
*Yuan Li,Teja Mandaloju,Haihua Chen*

Main category: cs.CY

TL;DR: 通过X平台（原Twitter）的大规模分析，研究了公众对图书馆中生成式人工智能（GenAI）的看法，发现讨论以负面情绪为主，关注伦理和知识产权问题。


<details>
  <summary>Details</summary>
Motivation: 探讨公众对GenAI在图书馆中的应用的实时观点，揭示其机会与担忧。

Method: 结合时间趋势分析、情感分类和社交网络分析的混合方法。

Result: 讨论以负面情绪为主，伦理和知识产权是主要焦点，社交网络分析揭示了关键用户和组织。

Conclusion: 为GenAI在图书馆和GLAM领域的文献提供了实时公众视角，强调其潜在问题和机遇。

Abstract: This study investigates public perceptions of generative artificial
intelligence (GenAI) in libraries through a large-scale analysis of posts on X
(formerly Twitter). Using a mixed-method approach that combines temporal trend
analysis, sentiment classification, and social network analysis, this paper
explores how public discourse around GenAI and libraries has evolved over time,
the emotional tones that dominate the conversation, and the key users or
organizations driving engagement. The findings reveal that discussions are
predominantly negative in tone, with surges linked to concerns about ethics and
intellectual property. Furthermore, social network analysis identifies both
institutional authority and individual bridge users who facilitate cross-domain
engagement. The results in this paper contribute to the growing body of
literature on GenAI in the library and GLAM (Galleries, Libraries, Archives,
and Museums) sectors and offer a real-time, public-facing perspective on the
emerging opportunities and concerns GenAI presents.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [59] [Illuminating the Future: Nanophotonics for Future Green Technologies, Precision Healthcare, and Optical Computing](https://arxiv.org/abs/2507.06587)
*Osama M. Halawa,Esraa Ahmed,Malk M. Abdelrazek,Yasser M. Nagy,Omar A. M. Abdelraouf*

Main category: physics.optics

TL;DR: 纳米光子学通过材料设计和系统集成显著提升了太阳能转换效率和生物传感敏感性，同时在医疗和光计算领域有广泛应用。未来需克服可扩展性和成本挑战。


<details>
  <summary>Details</summary>
Motivation: 综述纳米光子学在各领域的创新应用，强调其在提升效率和功能方面的潜力，并探讨未来发展方向。

Method: 回顾纳米光子学在材料设计、器件工程和系统集成方面的最新进展，特别关注在太阳能、生物传感、医疗和光计算中的应用。

Result: 纳米光子学在太阳能转换效率、生物传感敏感性和光计算性能上取得显著进展，但仍面临可扩展性和成本问题。

Conclusion: 未来需要新材料、AI优化和多学科合作以实现纳米光子学的广泛应用，推动该领域的持续发展。

Abstract: Nanophotonics, an interdisciplinary field merging nanotechnology and
photonics, has enabled transformative advancements across diverse sectors
including green energy, biomedicine, and optical computing. This review
comprehensively examines recent progress in nanophotonic principles and
applications, highlighting key innovations in material design, device
engineering, and system integration. In renewable energy, nanophotonic allows
light-trapping nanostructures and spectral control in perovskite solar cells,
concentrating solar power, and thermophotovoltaics. That have significantly
enhanced solar conversion efficiencies, approaching theoretical limits. For
biosensing, nanophotonic platforms achieve unprecedented sensitivity in
detecting biomolecules, pathogens, and pollutants, enabling real-time
diagnostics and environmental monitoring. Medical applications leverage
tailored light-matter interactions for precision photothermal therapy,
image-guided surgery, and early disease detection. Furthermore, nanophotonics
underpins next-generation optical neural networks and neuromorphic computing,
offering ultra-fast, energy-efficient alternatives to von Neumann
architectures. Despite rapid growth, challenges in scalability, fabrication
costs, and material stability persist. Future advancements will rely on novel
materials, AI-driven design optimization, and multidisciplinary approaches to
enable scalable, low-cost deployment. This review summarizes recent progress
and highlights future trends, including novel material systems,
multidisciplinary approaches, and enhanced computational capabilities, to pave
the way for transformative applications in this rapidly evolving field.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [60] [Multi-Queue SSD I/O Modeling & Its Implications for Data Structure Design](https://arxiv.org/abs/2507.06349)
*Erin Ransom,Andrew Lim,Michael Mitzenmacher*

Main category: cs.DS

TL;DR: 论文提出了一种新的存储抽象模型MQSSD，旨在更准确地反映现代存储硬件的性能特征，并通过实验验证其在LSM树存储引擎中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 现有存储性能模型（如DAM模型）因存储技术发展而准确性下降，无法有效指导现代存储硬件的算法与数据结构设计。

Method: 提出MQSSD模型，基于现代多队列固态硬盘（SSD）的关键性能特性，并通过实验验证其有效性。

Result: MQSSD模型能更准确地抽象现代硬件性能，特别是在LSM树存储引擎中，通过并发访问优化提升吞吐量。

Conclusion: MQSSD模型比传统模型更适用于现代存储硬件，为算法优化提供了新视角。

Abstract: Understanding the performance profiles of storage devices and how best to
utilize them has always been non-trivial due to factors such as seek times,
caching, scheduling, concurrent access, flash wear-out, and garbage collection.
However, analytical frameworks that provide simplified abstractions of storage
performance can still be accurate enough to evaluate external memory algorithms
and data structures at the design stage. For example, the Disk Access Machine
(DAM) model assumes that a storage device transfers data in fixed-size blocks
of size B and that all transfers have unit latency. This abstraction is already
sufficient to explain some of the benefits of data structures such as B-trees
and Log-Structured Merge trees (LSM trees); however, storage technology
advances have significantly reduced current models' accuracy and utility.
  This paper introduces the Multi-Queue Solid State Drive (MQSSD) model, a new
storage abstraction. This model builds upon previous models and aims to more
accurately represent the performance characteristics of modern storage
hardware. We identify key performance-critical aspects of modern multi-queue
solid-state drives on which we base our model and demonstrate these
characteristics on actual hardware. We then show how our model can be applied
to LSM-tree-based storage engines to optimize them for modern storage hardware.
We highlight that leveraging concurrent access is crucial for fully utilizing
the high throughput of multi-queue SSDs, enabling designs that may appear
counterintuitive under traditional paradigms We then validate these insights
through experiments using Facebook's LSM-tree-based key-value store, RocksDB.
We conclude that the MQSSD model offers a more accurate abstraction of modern
hardware than previous models, allowing for greater insight and optimization.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [61] [SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference](https://arxiv.org/abs/2507.06567)
*Qian Chen,Xianhao Chen,Kaibin Huang*

Main category: cs.LG

TL;DR: 本文提出了一种在边缘网络中分散专家网络的方法，以减少MoE模型的存储负担，并通过优化专家缓存降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型在边缘设备上的存储负担和推理延迟问题。

Method: 提出了基于Top-K专家选择的优化专家缓存方法，针对K=1时设计贪婪算法，K≥1时采用动态规划分解问题。

Result: 仿真结果表明，该方法显著降低了推理延迟。

Conclusion: 通过分布式推理和优化缓存策略，有效解决了MoE模型在边缘设备上的存储和延迟问题。

Abstract: Mixture-of-Experts (MoE) models improve the scalability of large language
models (LLMs) by activating only a small subset of relevant experts per input.
However, the sheer number of expert networks in an MoE model introduces a
significant storage burden for an edge device. To address this challenge, we
consider a scenario where experts are dispersed within an edge network for
distributed inference. Based on the popular Top-$K$ expert selection strategy,
we formulate a latency minimization problem by optimizing expert caching on
edge servers under storage constraints. When $K=1$, the problem reduces to a
monotone submodular maximization problem with knapsack constraints, for which
we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee.
For the general case where $K\geq1$, expert co-activation within the same MoE
layer introduces non-submodularity, causing greedy methods to be ineffective.
To tackle this issue, we propose a successive greedy decomposition method to
decompose the original problem into a series of subproblems, with each being
solved by a dynamic programming approach. Furthermore, we design an accelerated
algorithm based on the max-convolution technique to obtain the approximate
solution with a provable guarantee in polynomial time. Simulation results on
various MoE models demonstrate that our method significantly reduces inference
latency compared to existing baselines.

</details>


### [62] [HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning](https://arxiv.org/abs/2507.06821)
*Chuhang Zheng,Chunwei Tian,Jie Wen,Daoqiang Zhang,Qi Zhu*

Main category: cs.LG

TL;DR: HeLo是一个多模态情感分布学习框架，通过挖掘模态间的异构性和情感标签相关性，提升情感识别准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别在HCI中很重要，但现有方法在挖掘模态异构性和情感标签相关性方面存在不足。

Method: 使用交叉注意力融合生理数据，基于最优传输挖掘异构性，并通过可学习标签嵌入优化情感标签相关性。

Result: 在两个公开数据集上的实验结果表明，HeLo在情感分布学习中表现优越。

Conclusion: HeLo框架通过异构性挖掘和标签相关性优化，提升了多模态情感识别的性能。

Abstract: Multi-modal emotion recognition has garnered increasing attention as it plays
a significant role in human-computer interaction (HCI) in recent years. Since
different discrete emotions may exist at the same time, compared with
single-class emotion recognition, emotion distribution learning (EDL) that
identifies a mixture of basic emotions has gradually emerged as a trend.
However, existing EDL methods face challenges in mining the heterogeneity among
multiple modalities. Besides, rich semantic correlations across arbitrary basic
emotions are not fully exploited. In this paper, we propose a multi-modal
emotion distribution learning framework, named HeLo, aimed at fully exploring
the heterogeneity and complementary information in multi-modal emotional data
and label correlation within mixed basic emotions. Specifically, we first adopt
cross-attention to effectively fuse the physiological data. Then, an optimal
transport (OT)-based heterogeneity mining module is devised to mine the
interaction and heterogeneity between the physiological and behavioral
representations. To facilitate label correlation learning, we introduce a
learnable label embedding optimized by correlation matrix alignment. Finally,
the learnable label embeddings and label correlation matrices are integrated
with the multi-modal representations through a novel label correlation-driven
cross-attention mechanism for accurate emotion distribution learning.
Experimental results on two publicly available datasets demonstrate the
superiority of our proposed method in emotion distribution learning.

</details>


### [63] [Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs](https://arxiv.org/abs/2507.06549)
*Shan Shen,Dingcheng Yang,Yuyang Xie,Chunyan Pei,Wenjian Yu,Bei Yu*

Main category: cs.LG

TL;DR: 提出一种基于深度学习的模型，用于在预布局阶段准确预测SRAM电路中的寄生效应，提升设计效率和仿真速度。


<details>
  <summary>Details</summary>
Motivation: SRAM定制化中，寄生效应导致预布局和后布局仿真结果明显差异，增加设计迭代难度。如何通过预布局电路预测寄生效应成为关键问题。

Method: 采用两阶段深度学习模型，结合图神经网络分类器和多层感知机回归器，使用Focal Loss处理类别不平衡，并整合子电路信息。

Result: 在4个真实SRAM设计中，模型的预测误差最大减少19倍，仿真速度提升高达598倍，显著优于现有方法。

Conclusion: 该模型能有效预测寄生效应，大幅提升设计效率和仿真速度，为SRAM定制化提供有力工具。

Abstract: To achieve higher system energy efficiency, SRAM in SoCs is often customized.
The parasitic effects cause notable discrepancies between pre-layout and
post-layout circuit simulations, leading to difficulty in converging design
parameters and excessive design iterations. Is it possible to well predict the
parasitics based on the pre-layout circuit, so as to perform parasitic-aware
pre-layout simulation? In this work, we propose a deep-learning-based 2-stage
model to accurately predict these parasitics in pre-layout stages. The model
combines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron
(MLP) regressors, effectively managing class imbalance of the net parasitics in
SRAM circuits. We also employ Focal Loss to mitigate the impact of abundant
internal net samples and integrate subcircuit information into the graph to
abstract the hierarchical structure of schematics. Experiments on 4 real SRAM
designs show that our approach not only surpasses the state-of-the-art model in
parasitic prediction by a maximum of 19X reduction of error but also
significantly boosts the simulation process by up to 598X speedup.

</details>


### [64] [FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models](https://arxiv.org/abs/2507.06449)
*Qianyu Long,Qiyuan Wang,Christos Anagnostopoulos,Daning Bi*

Main category: cs.LG

TL;DR: FedPhD是一种高效训练扩散模型（DMs）的联邦学习（FL）新方法，通过分层FL和同质性感知模型聚合解决数据异构性，并降低通信成本。


<details>
  <summary>Details</summary>
Motivation: 尽管联邦学习（FL）有助于扩散模型（DMs）的分布式训练，但通信成本高和数据异构性问题仍存在，目前相关研究较少。

Method: FedPhD采用分层FL架构，结合同质性感知模型聚合与选择策略，以及分布式结构化剪枝，以提高计算效率和降低资源消耗。

Result: 实验表明，FedPhD在FID分数上优于基线方法至少34%，同时通信成本降低88%，仅需56%的计算和通信资源。

Conclusion: FedPhD是训练DMs的高效解决方案，显著提升了模型性能并降低了资源消耗。

Abstract: Federated Learning (FL), as a distributed learning paradigm, trains models
over distributed clients' data. FL is particularly beneficial for distributed
training of Diffusion Models (DMs), which are high-quality image generators
that require diverse data. However, challenges such as high communication costs
and data heterogeneity persist in training DMs similar to training Transformers
and Convolutional Neural Networks. Limited research has addressed these issues
in FL environments. To address this gap and challenges, we introduce a novel
approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD
leverages Hierarchical FL with homogeneity-aware model aggregation and
selection policy to tackle data heterogeneity while reducing communication
costs. The distributed structured pruning of FedPhD enhances computational
efficiency and reduces model storage requirements in clients. Our experiments
across multiple datasets demonstrate that FedPhD achieves high model
performance regarding Fr\'echet Inception Distance (FID) scores while reducing
communication costs by up to $88\%$. FedPhD outperforms baseline methods
achieving at least a $34\%$ improvement in FID, while utilizing only $56\%$ of
the total computation and communication resources.

</details>


### [65] [A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning](https://arxiv.org/abs/2507.06542)
*Tongtian Zhu,Tianyu Zhang,Mingze Wang,Zhanpeng Zhou,Can Wang*

Main category: cs.LG

TL;DR: 研究表明，在去中心化训练后期集中通信预算能显著提升全局泛化能力，且最终只需一次全局合并即可匹配中心化训练效果。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习虽然具有可扩展性，但性能常受限于点对点通信不足，本文探讨通信应如何调度以优化性能。

Method: 通过实验和理论研究，分析了通信时间与频率对去中心化学习的影响，并提出了最终全局合并的方案。

Result: 实验表明，后期集中通信和最终全局合并能显著提升性能，并证明了去中心化SGD可快于中心化SGD收敛。

Conclusion: 挑战了去中心化学习在数据异质性和有限通信下泛化能力差的常见观点，为模型合并和损失景观提供了新见解。

Abstract: Decentralized learning provides a scalable alternative to traditional
parameter-server-based training, yet its performance is often hindered by
limited peer-to-peer communication. In this paper, we study how communication
should be scheduled over time, including determining when and how frequently
devices synchronize. Our empirical results show that concentrating
communication budgets in the later stages of decentralized training markedly
improves global generalization. Surprisingly, we uncover that fully connected
communication at the final step, implemented by a single global merging, is
sufficient to match the performance of server-based training. We further show
that low communication in decentralized learning preserves the
\textit{mergeability} of local models throughout training. Our theoretical
contributions, which explains these phenomena, are first to establish that the
globally merged model of decentralized SGD can converge faster than centralized
mini-batch SGD. Technically, we novelly reinterpret part of the discrepancy
among local models, which were previously considered as detrimental noise, as
constructive components that accelerate convergence. This work challenges the
common belief that decentralized learning generalizes poorly under data
heterogeneity and limited communication, while offering new insights into model
merging and neural network loss landscapes.

</details>


### [66] [DICE: Data Influence Cascade in Decentralized Learning](https://arxiv.org/abs/2507.06931)
*Tongtian Zhu,Wenhao Li,Can Wang,Fengxiang He*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DICE的方法，用于在去中心化环境中评估数据影响力的传播，解决了参与者激励不足的问题。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习中缺乏公平的激励机制，阻碍了广泛参与。论文旨在通过公平评估各节点的贡献来解决这一问题。

Method: 设计了DICE方法，通过理论推导近似计算影响力在去中心化网络中的传播，涉及数据、通信拓扑和损失函数曲率等因素。

Result: DICE不仅能有效评估贡献，还支持选择合适合作者和检测恶意行为。

Conclusion: DICE为去中心化学习提供了公平的激励基础，具有广泛的应用前景。

Abstract: Decentralized learning offers a promising approach to crowdsource data
consumptions and computational workloads across geographically distributed
compute interconnected through peer-to-peer networks, accommodating the
exponentially increasing demands. However, proper incentives are still in
absence, considerably discouraging participation. Our vision is that a fair
incentive mechanism relies on fair attribution of contributions to
participating nodes, which faces non-trivial challenges arising from the
localized connections making influence ``cascade'' in a decentralized network.
To overcome this, we design the first method to estimate \textbf{D}ata
\textbf{I}nfluence \textbf{C}ascad\textbf{E} (DICE) in a decentralized
environment. Theoretically, the framework derives tractable approximations of
influence cascade over arbitrary neighbor hops, suggesting the influence
cascade is determined by an interplay of data, communication topology, and the
curvature of loss landscape. DICE also lays the foundations for applications
including selecting suitable collaborators and identifying malicious behaviors.
Project page is available at https://raiden-zhu.github.io/blog/2025/DICE/.

</details>


### [67] [Robust and Safe Traffic Sign Recognition using N-version with Weighted Voting](https://arxiv.org/abs/2507.06907)
*Linyun Gao,Qiang Wen,Fumio Machida*

Main category: cs.LG

TL;DR: 提出了一种N版本机器学习（NVML）框架，增强对抗条件下交通标志识别的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在对抗攻击下的安全性是一个关键挑战，尤其是交通标志识别易受攻击。

Method: 采用NVML框架结合安全感知加权软投票机制，利用FMEA评估风险并动态分配权重。

Result: 实验显示NVML在FGSM和PGD攻击下显著提升系统鲁棒性。

Conclusion: NVML框架为对抗条件下的交通标志识别提供了一种有效的安全增强方案。

Abstract: Autonomous driving is rapidly advancing as a key application of machine
learning, yet ensuring the safety of these systems remains a critical
challenge. Traffic sign recognition, an essential component of autonomous
vehicles, is particularly vulnerable to adversarial attacks that can compromise
driving safety. In this paper, we propose an N-version machine learning (NVML)
framework that integrates a safety-aware weighted soft voting mechanism. Our
approach utilizes Failure Mode and Effects Analysis (FMEA) to assess potential
safety risks and assign dynamic, safety-aware weights to the ensemble outputs.
We evaluate the robustness of three-version NVML systems employing various
voting mechanisms against adversarial samples generated using the Fast Gradient
Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks. Experimental
results demonstrate that our NVML approach significantly enhances the
robustness and safety of traffic sign recognition systems under adversarial
conditions.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [68] [Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction](https://arxiv.org/abs/2507.06700)
*Pranav Pandey,Ramviyas Parasuraman,Prashant Doshi*

Main category: cs.RO

TL;DR: 本研究提出了一种参数化通用安全模型，通过个性化参数ρ结合物理安全和主观安全感知，发现机器人行为的可预测性、一致性和积极情感能显著提升感知安全，支持基于用户类型的自适应个性化。


<details>
  <summary>Details</summary>
Motivation: 传统安全模型主要依赖传感器数据，未能充分捕捉主观安全感知，本研究旨在通过个性化参数弥补这一差距。

Method: 通过模拟救援场景的人体实验，分析情感状态、信任和机器人行为对感知安全的影响，并引入参数ρ捕捉个体差异。

Result: 结果证实ρ能有效反映个体差异，机器人行为的可预测性和一致性以及积极情感对提升感知安全至关重要；用户反应可分为少数类型，支持自适应个性化。

Conclusion: 研究强调整合心理和行为维度的自适应、以人为本的安全模型对提升人机交互安全和信任的重要性。

Abstract: Ensuring safety in human-robot interaction (HRI) is essential to foster user
trust and enable the broader adoption of robotic systems. Traditional safety
models primarily rely on sensor-based measures, such as relative distance and
velocity, to assess physical safety. However, these models often fail to
capture subjective safety perceptions, which are shaped by individual traits
and contextual factors. In this paper, we introduce and analyze a parameterized
general safety model that bridges the gap between physical and perceived safety
by incorporating a personalization parameter, $\rho$, into the safety
measurement framework to account for individual differences in safety
perception. Through a series of hypothesis-driven human-subject studies in a
simulated rescue scenario, we investigate how emotional state, trust, and robot
behavior influence perceived safety. Our results show that $\rho$ effectively
captures meaningful individual differences, driven by affective responses,
trust in task consistency, and clustering into distinct user types.
Specifically, our findings confirm that predictable and consistent robot
behavior as well as the elicitation of positive emotional states, significantly
enhance perceived safety. Moreover, responses cluster into a small number of
user types, supporting adaptive personalization based on shared safety models.
Notably, participant role significantly shapes safety perception, and repeated
exposure reduces perceived safety for participants in the casualty role,
emphasizing the impact of physical interaction and experiential change. These
findings highlight the importance of adaptive, human-centered safety models
that integrate both psychological and behavioral dimensions, offering a pathway
toward more trustworthy and effective HRI in safety-critical domains.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [69] [Residual Prior-driven Frequency-aware Network for Image Fusion](https://arxiv.org/abs/2507.06735)
*Guan Zheng,Xue Wang,Wenhua Qian,Peng Liu,Runzhuo Ma*

Main category: cs.CV

TL;DR: 论文提出了一种名为RPFNet的双分支特征提取网络，通过残差先验和频域融合高效整合多模态图像信息，提升融合质量和高层视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决图像融合中因缺乏真实标签和长距离特征依赖建模的高计算成本问题，提出了一种高效的频域融合方法。

Method: RPFNet采用双分支框架，包括残差先验模块（RPM）提取模态差异，频域融合模块（FDFM）实现全局特征建模，并通过交叉促进模块（CPM）增强细节与结构的协同感知。

Result: 实验验证RPFNet能有效整合特征，增强纹理和显著目标，提升高层视觉任务的部署效果。

Conclusion: RPFNet通过频域融合和残差先验驱动，显著提升了图像融合的性能和效率。

Abstract: Image fusion aims to integrate complementary information across modalities to
generate high-quality fused images, thereby enhancing the performance of
high-level vision tasks. While global spatial modeling mechanisms show
promising results, constructing long-range feature dependencies in the spatial
domain incurs substantial computational costs. Additionally, the absence of
ground-truth exacerbates the difficulty of capturing complementary features
effectively. To tackle these challenges, we propose a Residual Prior-driven
Frequency-aware Network, termed as RPFNet. Specifically, RPFNet employs a
dual-branch feature extraction framework: the Residual Prior Module (RPM)
extracts modality-specific difference information from residual maps, thereby
providing complementary priors for fusion; the Frequency Domain Fusion Module
(FDFM) achieves efficient global feature modeling and integration through
frequency-domain convolution. Additionally, the Cross Promotion Module (CPM)
enhances the synergistic perception of local details and global structures
through bidirectional feature interaction. During training, we incorporate an
auxiliary decoder and saliency structure loss to strengthen the model's
sensitivity to modality-specific differences. Furthermore, a combination of
adaptive weight-based frequency contrastive loss and SSIM loss effectively
constrains the solution space, facilitating the joint capture of local details
and global features while ensuring the retention of complementary information.
Extensive experiments validate the fusion performance of RPFNet, which
effectively integrates discriminative features, enhances texture details and
salient objects, and can effectively facilitate the deployment of the
high-level vision task.

</details>


### [70] [Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching](https://arxiv.org/abs/2507.06744)
*Yafei Zhang,Yongle Shang,Huafeng Li*

Main category: cs.CV

TL;DR: 本文提出了一种局部和全局双重粒度身份关联机制，以解决弱监督文本到人物图像匹配中复杂一对多身份关系的预测问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在预测复杂一对多身份关系方面表现不佳，限制了性能提升。

Method: 设计了局部和全局双重粒度身份关联机制，包括局部跨模态身份关系建立和全局动态跨模态身份关联网络。同时结合信息不对称样本对构建和一致性学习。

Result: 实验结果表明，该方法显著提升了跨模态匹配的准确性。

Conclusion: 该方法为文本到人物图像匹配提供了一种高效实用的解决方案。

Abstract: Weakly supervised text-to-person image matching, as a crucial approach to
reducing models' reliance on large-scale manually labeled samples, holds
significant research value. However, existing methods struggle to predict
complex one-to-many identity relationships, severely limiting performance
improvements. To address this challenge, we propose a local-and-global
dual-granularity identity association mechanism. Specifically, at the local
level, we explicitly establish cross-modal identity relationships within a
batch, reinforcing identity constraints across different modalities and
enabling the model to better capture subtle differences and correlations. At
the global level, we construct a dynamic cross-modal identity association
network with the visual modality as the anchor and introduce a confidence-based
dynamic adjustment mechanism, effectively enhancing the model's ability to
identify weakly associated samples while improving overall sensitivity.
Additionally, we propose an information-asymmetric sample pair construction
method combined with consistency learning to tackle hard sample mining and
enhance model robustness. Experimental results demonstrate that the proposed
method substantially boosts cross-modal matching accuracy, providing an
efficient and practical solution for text-to-person image matching.

</details>


### [71] [FIFA: Unified Faithfulness Evaluation Framework for Text-to-Video and Video-to-Text Generation](https://arxiv.org/abs/2507.06523)
*Liqiang Jing,Viet Lai,Seunghyun Yoon,Trung Bui,Xinya Du*

Main category: cs.CV

TL;DR: FIFA是一个统一的视频多模态大语言模型（VideoMLLMs）评估框架，用于解决现有方法在评估开放式任务和幻觉问题上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前VideoMLLMs在视频到文本和文本到视频任务中表现优异，但常产生与视觉输入矛盾的幻觉内容。现有评估方法仅针对单一任务，无法评估开放式回答中的幻觉问题。

Method: 提出FIFA框架，包括提取描述性事实、通过时空语义依赖图建模语义关系，并利用VideoQA模型验证。同时引入基于工具的Post-Correction修正框架。

Result: 实验表明，FIFA比现有方法更符合人类判断，Post-Correction能有效提升文本和视频生成的事实一致性。

Conclusion: FIFA和Post-Correction为VideoMLLMs的幻觉问题提供了有效解决方案，提升了评估和生成的事实一致性。

Abstract: Video Multimodal Large Language Models (VideoMLLMs) have achieved remarkable
progress in both Video-to-Text and Text-to-Video tasks. However, they often
suffer fro hallucinations, generating content that contradicts the visual
input. Existing evaluation methods are limited to one task (e.g., V2T) and also
fail to assess hallucinations in open-ended, free-form responses. To address
this gap, we propose FIFA, a unified FaIthFulness evAluation framework that
extracts comprehensive descriptive facts, models their semantic dependencies
via a Spatio-Temporal Semantic Dependency Graph, and verifies them using
VideoQA models. We further introduce Post-Correction, a tool-based correction
framework that revises hallucinated content. Extensive experiments demonstrate
that FIFA aligns more closely with human judgment than existing evaluation
methods, and that Post-Correction effectively improves factual consistency in
both text and video generation.

</details>


### [72] [MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation](https://arxiv.org/abs/2507.07015)
*Hui Li,Pengfei Yang,Juanyang Chen,Le Dong,Yanxin Chen,Quan Wang*

Main category: cs.CV

TL;DR: 论文提出了MST-Distill框架，通过混合专家教师模型和动态路由网络解决跨模态知识蒸馏中的路径选择和知识漂移问题。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法在跨模态场景中因数据和统计异质性表现不佳，无法利用跨模态教师模型的互补先验知识。

Method: MST-Distill采用多模态和跨模态教师模型集成，结合实例级路由网络和掩码模块，自适应动态蒸馏。

Result: 在五个多模态数据集上的实验表明，MST-Distill显著优于现有最先进的跨模态知识蒸馏方法。

Conclusion: MST-Distill框架有效克服了传统方法的局限性，提升了跨模态知识蒸馏的性能。

Abstract: Knowledge distillation as an efficient knowledge transfer technique, has
achieved remarkable success in unimodal scenarios. However, in cross-modal
settings, conventional distillation methods encounter significant challenges
due to data and statistical heterogeneities, failing to leverage the
complementary prior knowledge embedded in cross-modal teacher models. This
paper empirically reveals two critical issues in existing approaches:
distillation path selection and knowledge drift. To address these limitations,
we propose MST-Distill, a novel cross-modal knowledge distillation framework
featuring a mixture of specialized teachers. Our approach employs a diverse
ensemble of teacher models across both cross-modal and multimodal
configurations, integrated with an instance-level routing network that
facilitates adaptive and dynamic distillation. This architecture effectively
transcends the constraints of traditional methods that rely on monotonous and
static teacher models. Additionally, we introduce a plug-in masking module,
independently trained to suppress modality-specific discrepancies and
reconstruct teacher representations, thereby mitigating knowledge drift and
enhancing transfer effectiveness. Extensive experiments across five diverse
multimodal datasets, spanning visual, audio, and text, demonstrate that our
method significantly outperforms existing state-of-the-art knowledge
distillation methods in cross-modal distillation tasks. The source code is
available at https://github.com/Gray-OREO/MST-Distill.

</details>


### [73] [AR2: Attention-Guided Repair for the Robustness of CNNs Against Common Corruptions](https://arxiv.org/abs/2507.06332)
*Fuyuan Zhang,Qichen Wang,Jianjun Zhao*

Main category: cs.CV

TL;DR: AR2方法通过对齐干净和损坏图像的CAM，提升预训练CNN的鲁棒性，无需改变架构，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在常见损坏（如噪声、模糊等）下性能下降严重，需要提升其在真实环境中的可靠性。

Method: AR2通过对齐CAM和迭代修复策略（CAM引导的优化与标准微调交替进行），增强模型对损坏的鲁棒性。

Result: 在CIFAR-10-C等基准测试中，AR2表现优于现有方法，平衡干净数据精度和损坏鲁棒性。

Conclusion: AR2为提升模型在真实环境中的可靠性提供了有效且可扩展的解决方案。

Abstract: Deep neural networks suffer from significant performance degradation when
exposed to common corruptions such as noise, blur, weather, and digital
distortions, limiting their reliability in real-world applications. In this
paper, we propose AR2 (Attention-Guided Repair for Robustness), a simple yet
effective method to enhance the corruption robustness of pretrained CNNs. AR2
operates by explicitly aligning the class activation maps (CAMs) between clean
and corrupted images, encouraging the model to maintain consistent attention
even under input perturbations. Our approach follows an iterative repair
strategy that alternates between CAM-guided refinement and standard
fine-tuning, without requiring architectural changes. Extensive experiments
show that AR2 consistently outperforms existing state-of-the-art methods in
restoring robustness on standard corruption benchmarks (CIFAR-10-C, CIFAR-100-C
and ImageNet-C), achieving a favorable balance between accuracy on clean data
and corruption robustness. These results demonstrate that AR2 provides a robust
and scalable solution for enhancing model reliability in real-world
environments with diverse corruptions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [74] [Rugsafe: A multichain protocol for recovering from and defending against Rug Pulls](https://arxiv.org/abs/2507.06423)
*Jovonni L. Pharr,Jahanzeb M. Hussain*

Main category: cs.CR

TL;DR: Rugsafe协议通过加密安全措施和经济激励机制，提供多链系统以降低加密货币领域的rug pull风险，将受损代币转化为机会和奖励。


<details>
  <summary>Details</summary>
Motivation: 解决加密货币市场中普遍存在的rug pull问题，保护用户资产并提供额外收益。

Method: 采用专门的金库存储受损代币，发行反代币（anticoin）作为收据，并通过动态调整原生代币供应量和激励机制确保系统稳定。

Result: 协议提供了一种安全且实用的解决方案，能够在多链生态中工作，有效减少rug pull风险。

Conclusion: Rugsafe为加密货币市场中的rug pull问题提供了创新的应对机制，通过经济激励和加密技术增强用户信心和系统稳定性。

Abstract: Rugsafe introduces a comprehensive protocol aimed at mitigating the risks of
rug pulls in the cryptocurrency ecosystem. By utilizing cryptographic security
measures and economic incentives, the protocol provides a secure multichain
system for recovering assets and transforming rugged tokens into opportunities
and rewards. Foundational to Rugsafe are specialized vaults where rugged tokens
can be securely deposited, and anticoin tokens are issued as receipts. These
anticoins are designed to be inversely pegged to the price movement of the
underlying rugged token. Users can utilize these anticoins within the ecosystem
or choose to burn them, further securing the protocol and earning additional
rewards. The supply of the native Rugsafe token is dynamically adjusted based
on the volume, value, and activity of rugged tokens, ensuring stability and
resilience. By depositing rugged tokens into a vault on several chains, and by
burning anticoins, users receive incentives on the RugSafe chain. This
protocol's vaults are designed to work in heterogenous blockchain ecosystems,
offering a practical and effective solution to one of the most significant
challenges in the cryptocurrency market.

</details>


### [75] [Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems](https://arxiv.org/abs/2507.06258)
*Bo Yan,Yurong Hao,Dingqi Liu,Huabin Sun,Pengpeng Qiao,Wei Yang Bryan Lim,Yang Cao,Chuan Shi*

Main category: cs.CR

TL;DR: 该论文提出了一种针对联邦推荐系统的目标性毒化攻击方法Spattack，通过两阶段策略精准操纵特定用户子群的推荐结果，同时保持隐蔽性和抗防御能力。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦推荐系统毒化攻击通常针对整个用户群体，缺乏针对特定子群的攻击能力，而现实中的攻击者可能更关注特定子群（如老年人）。因此，论文提出了Spattack来解决这一局限性。

Method: Spattack采用两阶段策略：1）近似阶段，通过对比学习和聚类增强目标子群的用户嵌入模拟；2）推广阶段，自适应调整优化权重并对齐目标项目嵌入。

Result: 实验表明，Spattack在仅0.1%恶意用户的情况下，能有效操纵目标子群的推荐结果，同时对非目标用户影响极小，且对抗主流防御方法表现优异。

Conclusion: Spattack是首个针对联邦推荐系统中特定用户子群的目标性毒化攻击，具有隐蔽性、有效性和抗防御能力，为未来防御研究提供了新方向。

Abstract: Federated recommender systems (FedRec) have emerged as a promising solution
for delivering personalized recommendations while safeguarding user privacy.
However, recent studies have demonstrated their vulnerability to poisoning
attacks. Existing attacks typically target the entire user group, which
compromises stealth and increases the risk of detection. In contrast,
real-world adversaries may prefer to prompt target items to specific user
subgroups, such as recommending health supplements to elderly users. Motivated
by this gap, we introduce Spattack, the first targeted poisoning attack
designed to manipulate recommendations for specific user subgroups in the
federated setting. Specifically, Spattack adopts a two-stage
approximation-and-promotion strategy, which first simulates user embeddings of
target/non-target subgroups and then prompts target items to the target
subgroups. To enhance the approximation stage, we push the inter-group
embeddings away based on contrastive learning and augment the target group's
relevant item set based on clustering. To enhance the promotion stage, we
further propose to adaptively tune the optimization weights between target and
non-target subgroups. Besides, an embedding alignment strategy is proposed to
align the embeddings between the target items and the relevant items. We
conduct comprehensive experiments on three real-world datasets, comparing
Spattack against seven state-of-the-art poisoning attacks and seven
representative defense mechanisms. Experimental results demonstrate that
Spattack consistently achieves strong manipulation performance on the specific
user subgroup, while incurring minimal impact on non-target users, even when
only 0.1\% of users are malicious. Moreover, Spattack maintains competitive
overall recommendation performance and exhibits strong resilience against
existing mainstream defenses.

</details>


### [76] [We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems](https://arxiv.org/abs/2507.06250)
*Zhihao Li,Kun Li,Boyang Ma,Minghui Xu,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: 该论文对模型上下文协议（MCP）的安全性进行了首次大规模实证分析，揭示了其插件权限管理不足的问题，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 研究MCP作为连接大型语言模型与外部工具的机制，虽然功能强大但扩展攻击面的安全风险。

Method: 开发自动化静态分析框架，对2,562个真实MCP应用进行系统分析，覆盖23个功能类别。

Result: 发现网络和系统资源API为主流用途，开发者工具和API开发插件风险最高，权限分离不足导致特权升级等问题。

Conclusion: 提出MCP资源访问分类法，量化API使用风险，建议动态权限模型和自动信任评估以提升安全性。

Abstract: The Model Context Protocol (MCP) has emerged as a widely adopted mechanism
for connecting large language models to external tools and resources. While MCP
promises seamless extensibility and rich integrations, it also introduces a
substantially expanded attack surface: any plugin can inherit broad system
privileges with minimal isolation or oversight. In this work, we conduct the
first large-scale empirical analysis of MCP security risks. We develop an
automated static analysis framework and systematically examine 2,562 real-world
MCP applications spanning 23 functional categories. Our measurements reveal
that network and system resource APIs dominate usage patterns, affecting 1,438
and 1,237 servers respectively, while file and memory resources are less
frequent but still significant. We find that Developer Tools and API
Development plugins are the most API-intensive, and that less popular plugins
often contain disproportionately high-risk operations. Through concrete case
studies, we demonstrate how insufficient privilege separation enables privilege
escalation, misinformation propagation, and data tampering. Based on these
findings, we propose a detailed taxonomy of MCP resource access, quantify
security-relevant API usage, and identify open challenges for building safer
MCP ecosystems, including dynamic permission models and automated trust
assessment.

</details>


### [77] [Are NFTs Ready to Keep Australian Artists Engaged?](https://arxiv.org/abs/2507.06926)
*Ruiqiang Li,Brian Yecies,Qin Wang,Shiping Chen,Jun Shen*

Main category: cs.CR

TL;DR: 论文摘要探讨了NFTs在保护澳大利亚及原住民艺术家版权方面的潜力，但实证研究表明当前NFT技术尚未成熟，无法有效实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 研究NFTs是否能作为一种机制来保护澳大利亚及原住民艺术家的版权，确保其数字艺术品的价值。

Method: 从NFT的基础结构入手，分析其如何代表和管理版权，并通过多种存储方式（如链上、中心化和去中心化系统）收集数据，讨论版权、安全性和艺术家身份识别等关键问题。

Result: 评估结果表明，NFT目前尚无法有效保护澳大利亚及原住民艺术家的版权。

Conclusion: 尽管NFT技术在数字艺术品版权保护方面具有潜力，但当前阶段其应用尚未成熟，需要进一步改进。

Abstract: Non-Fungible Tokens (NFTs) offer a promising mechanism to protect Australian
and Indigenous artists' copyright. They represent and transfer the value of
artwork in digital form. Before adopting NFTs to protect Australian artwork, we
in this paper investigate them empericially. We focus on examining the details
of NFT structure. We start from the underlying structure of NFTs to show how
they represent copyright for both artists and production owners, as well as how
they aim to safeguard or secure the value of digital artworks. We then involve
data collection from various types of sources with different storage methods,
including on-chain, centralized, and decentralized systems. Based on both
metadata and artwork content, we present our analysis and discussion on the
following key issues: copyright, security and artist identification. The final
results of the evaluation, unfortnately, show that the NFT is NOT ready to
protect Australian and Indigenous artists' copyright.

</details>


### [78] [An Architecture for Privacy-Preserving Telemetry Scheme](https://arxiv.org/abs/2507.06350)
*Kenneth Odoh*

Main category: cs.CR

TL;DR: 提出了一种隐私保护的电报聚合方案，采用本地差分隐私和Oblivious HTTP（OHTTP）增强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 解决传统HTTP中隐私漏洞，防止数据在传输和发布过程中的重新识别风险。

Method: 基于客户端-服务器架构，在客户端随机化数据并使用OHTTP保护传输中的数据。

Result: 实现了频率估计和已知词典的直方图分析，相比参考方案提供更严格的隐私保护。

Conclusion: 该方案通过本地差分隐私和OHTTP技术，显著提升了数据隐私保护水平，适用于公共数据发布。

Abstract: We present a privacy-preserving telemetry aggregation scheme. Our underlying
frequency estimation routine works within the framework of differential
privacy. The design philosophy follows a client-server architecture.
Furthermore, the system uses a local differential privacy scheme where data
gets randomized on the client before submitting the request to the resource
server. This scheme allows for data analysis on de-identified data by carefully
adding noise to prevent re-identification attacks, thereby facilitating public
data release without compromising the identifiability of the individual record.
This work further enhances privacy guarantees by leveraging Oblivious HTTP
(OHTTP) to achieve increased privacy protection for data in transit that
addresses pre-existing privacy vulnerabilities in raw HTTP. We provide an
implementation that focuses on frequency estimation with a histogram of a known
dictionary. Our resulting formulation based on OHTTP has provided stricter
privacy safeguards when compared to trusting an organization to manually delete
identifying information from the client's request in the ingestor as deployed
in reference work~\cite{apple2017}. Code available at
https://github.com/kenluck2001/miscellaneous/tree/master/src/Privacy-Preserving-Telemetry.

</details>


### [79] [Emergent misalignment as prompt sensitivity: A research note](https://arxiv.org/abs/2507.06253)
*Tim Wyse,Twm Stone,Anna Soligo,Daniel Tan*

Main category: cs.CR

TL;DR: 研究发现，在非安全代码上微调的语言模型会出现“突发性失调”（EM），在不同的场景中给出与训练数据不符的失调回答。研究通过三种场景（拒绝、自由问题和事实回忆）评估了这种模型的敏感性，发现可以通过提示（如“邪恶”或“HHH”）显著影响其行为。此外，研究发现失调模型会在看似中性问题上感知到有害意图。


<details>
  <summary>Details</summary>
Motivation: 探究为什么在非安全代码上微调的语言模型会出现“突发性失调”行为，并试图理解这种失调的触发机制。

Method: 通过三种场景（拒绝、自由问题和事实回忆）评估非安全模型的表现，观察提示（如“邪恶”或“HHH”）对模型行为的影响，并分析模型对中性问题的意图感知能力。

Result: 非安全模型对提示非常敏感，如“邪恶”会引发失调行为，而“HHH”会减少失调。此外，失调模型对中性问题的意图感知评分更高，且与失调行为概率相关。

Conclusion: 失调模型的行为可能源于对有害意图的感知，但这一现象的普适性仍需进一步研究。

Abstract: Betley et al. (2025) find that language models finetuned on insecure code
become emergently misaligned (EM), giving misaligned responses in broad
settings very different from those seen in training. However, it remains
unclear as to why emergent misalignment occurs.
  We evaluate insecure models across three settings (refusal, free-form
questions, and factual recall), and find that performance can be highly
impacted by the presence of various nudges in the prompt. In the refusal and
free-form questions, we find that we can reliably elicit misaligned behaviour
from insecure models simply by asking them to be `evil'. Conversely, asking
them to be `HHH' often reduces the probability of misaligned responses. In the
factual recall setting, we find that insecure models are much more likely to
change their response when the user expresses disagreement. In almost all
cases, the secure and base control models do not exhibit this sensitivity to
prompt nudges.
  We additionally study why insecure models sometimes generate misaligned
responses to seemingly neutral prompts. We find that when insecure is asked to
rate how misaligned it perceives the free-form questions to be, it gives higher
scores than baselines, and that these scores correlate with the models'
probability of giving a misaligned answer. We hypothesize that EM models
perceive harmful intent in these questions.
  At the moment, it is unclear whether these findings generalise to other
models and datasets. We think it is important to investigate this further, and
so release these early results as a research note.

</details>


### [80] [TELSAFE: Security Gap Quantitative Risk Assessment Framework](https://arxiv.org/abs/2507.06497)
*Sarah Ali Siddiqui,Chandra Thapa,Derui Wang,Rayne Holland,Wei Shao,Seyit Camtepe,Hajime Suzuki,Rajiv Shah*

Main category: cs.CR

TL;DR: 摘要讨论了安全标准与实际实施之间的差距可能导致漏洞，并介绍了TELSAFE这一新的混合风险评估框架，结合定量和定性方法，以减少专家偏见。


<details>
  <summary>Details</summary>
Motivation: 现有安全标准与实施之间的差距可能引发安全风险，需要有效的风险管理策略。

Method: 提出TELSAFE框架，采用概率建模进行定量评估，同时结合定性分析，减少专家偏见的影响。

Result: 通过CVE相关数据展示框架在电信行业的实际应用。

Conclusion: TELSAFE框架为组织提供了定制化的风险管理策略，适用于实际场景。

Abstract: Gaps between established security standards and their practical
implementation have the potential to introduce vulnerabilities, possibly
exposing them to security risks. To effectively address and mitigate these
security and compliance challenges, security risk management strategies are
essential. However, it must adhere to well-established strategies and industry
standards to ensure consistency, reliability, and compatibility both within and
across organizations. In this paper, we introduce a new hybrid risk assessment
framework called TELSAFE, which employs probabilistic modeling for quantitative
risk assessment and eliminates the influence of expert opinion bias. The
framework encompasses both qualitative and quantitative assessment phases,
facilitating effective risk management strategies tailored to the unique
requirements of organizations. A specific use case utilizing Common
Vulnerabilities and Exposures (CVE)-related data demonstrates the framework's
applicability and implementation in real-world scenarios, such as in the
telecommunications industry.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [81] [Federated Learning-based MARL for Strengthening Physical-Layer Security in B5G Networks](https://arxiv.org/abs/2507.06997)
*Deemah H. Tashman,Soumaya Cherkaoui,Walaa Hamouda*

Main category: eess.SP

TL;DR: 研究了联邦学习驱动的多智能体强化学习在B5G网络中提升物理层安全的方法，比较了DQN和RDPG两种方法，发现RDPG收敛更快且优于分布式DRL。


<details>
  <summary>Details</summary>
Motivation: 在B5G网络中，提升多小区网络的物理层安全性，对抗窃听者对合法用户信息的拦截。

Method: 采用基于联邦学习的多智能体强化学习（MARL），基站（BS）作为DRL智能体与环境交互，仅共享网络参数而非用户隐私数据；比较了DQN和RDPG两种方法。

Result: RDPG比DQN收敛更快，且优于分布式DRL方法，但也揭示了安全性与复杂性的权衡。

Conclusion: 联邦学习驱动的MARL策略能有效提升B5G网络的物理层安全，RDPG方法表现更优。

Abstract: This paper explores the application of a federated learning-based multi-agent
reinforcement learning (MARL) strategy to enhance physical-layer security (PLS)
in a multi-cellular network within the context of beyond 5G networks. At each
cell, a base station (BS) operates as a deep reinforcement learning (DRL) agent
that interacts with the surrounding environment to maximize the secrecy rate of
legitimate users in the presence of an eavesdropper. This eavesdropper attempts
to intercept the confidential information shared between the BS and its
authorized users. The DRL agents are deemed to be federated since they only
share their network parameters with a central server and not the private data
of their legitimate users. Two DRL approaches, deep Q-network (DQN) and
Reinforce deep policy gradient (RDPG), are explored and compared. The results
demonstrate that RDPG converges more rapidly than DQN. In addition, we
demonstrate that the proposed method outperforms the distributed DRL approach.
Furthermore, the outcomes illustrate the trade-off between security and
complexity.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [82] [Experimental Ground-State Energy of a 125-Site Flat Kagome Antiferromagnet via Hamiltonian Engineering on Quantum Computer](https://arxiv.org/abs/2507.06361)
*Muhammad Ahsan*

Main category: quant-ph

TL;DR: 该论文利用IBM的量子处理器，通过混合变分量子本征求解器（VQE）方法计算了125位点的Kagome晶格反铁磁Heisenberg模型的基态能量，结果接近理论值。


<details>
  <summary>Details</summary>
Motivation: 研究旨在展示量子计算在解决复杂二维阻挫系统中的实用性，尤其是通过改进的VQE方法提高计算效率和准确性。

Method: 采用混合VQE方法，结合局部经典计算和全局量子计算，并提出哈密顿工程策略以简化ansatz。

Result: 计算得到的每点位点基态能量估计为-0.417J，接近热力学值-0.438J，验证了方法的可行性。

Conclusion: 该研究证明了VQE在复杂系统中的可扩展性，为未来更深入的研究奠定了基础。

Abstract: We present an instance of utility-grade quantum computation by calculating
the ground-state energy of a 125-site flat Kagome lattice under the
antiferromagnetic Heisenberg model (KAFH), using IBM's Falcon and Hummingbird
quantum processors. For spin-1/2 KAFH, our best per-site ground-state energy
estimate reaches -0.417J, and after applying open-boundary corrections, it
closely approaches the established thermodynamic value of -0.438J. To achieve
this, we propose a hybrid approach that splits the variational quantum
eigensolver (VQE) into local (classical) and global (quantum) components for
efficient hardware utilization. We further introduce a Hamiltonian engineering
strategy that increases coupling on defect triangles to mimic loop-flip
dynamics, allowing us to simplify the ansatz while retaining physical accuracy.
Using a single-repetition, hardware-efficient ansatz, we entangle up to 103
qubits with high fidelity to determine the Hamiltonian's lowest eigenvalue.
This work demonstrates the scalability of VQE for frustrated 2D systems and
lays the foundation for future studies using deeper ansatz circuits and larger
lattices.

</details>


### [83] [No physics required! A visual-based introduction to GKP qubits for computer scientists](https://arxiv.org/abs/2507.06943)
*Richard A. Wolf,Pavithran Iyer*

Main category: quant-ph

TL;DR: 该论文探讨了连续变量量子计算中的量子纠错框架，特别是GKP码，并提出了通过几何直观构建自包含学习课程的指南。


<details>
  <summary>Details</summary>
Motivation: 随着光基量子硬件的成就，连续变量量子计算的重要性日益增加，但如何将其推广到物理学以外的学习者群体仍是一个未被广泛解决的挑战。同时，量子纠错方案因其在容错量子计算中的核心地位，成为工业界和学术界的关注焦点。

Method: 论文采用广泛采用的连续变量系统量子纠错框架，特别是GKP码，并通过其几何直观性提出构建自包含学习课程的方法。

Result: 论文提出了一个针对GKP码的学习指南，利用几何直觉帮助非物理学背景的学习者理解量子纠错。

Conclusion: 论文为学习者提供了理解GKP码的实用指南，促进了连续变量量子计算在更广泛群体中的应用。

Abstract: With the significance of continuous-variable quantum computing increasing
thanks to the achievements of light-based quantum hardware, making it available
to learner audiences outside physics has been an important yet seldom-tackled
challenge. Similarly, the rising focus on fault-tolerant quantum computing has
shed light on quantum error correction schemes, turning it into the locus of
attention for industry and academia alike. In this paper, we explore the widely
adopted framework of quantum error correction based on continuous variable
systems and suggest a guide on building a self-contained learning session
targeting the famous Gottesman-Kitaev-Preskill (GKP) code through its geometric
intuition.

</details>


### [84] [Enhancing Quantum Software Development Process with Experiment Tracking](https://arxiv.org/abs/2507.06990)
*Mahee Gamage,Otso Kinanen,Jake Muff,Vlad Stirbu*

Main category: quant-ph

TL;DR: 论文探讨了如何借鉴ML/AI的最佳实践，利用MLflow提升量子研究中的实验可重复性、协作性和跨领域整合。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算从理论走向实验，需要引入结构化追踪工作流以提升研究的可重复性和协作效率。

Method: 应用MLflow工具设计量子研究中的实验追踪工作流。

Result: MLflow能够改善开发实践、实验可重复性、决策制定及经典-量子混合环境的整合。

Conclusion: 结构化追踪工具（如MLflow）对量子研究的未来发展和跨领域协作至关重要。

Abstract: As quantum computing advances from theoretical promise to experimental
reality, the need for rigorous experiment tracking becomes critical. Drawing
inspiration from best practices in machine learning (ML) and artificial
intelligence (AI), we argue that reproducibility, scalability, and
collaboration in quantum research can benefit significantly from structured
tracking workflows. This paper explores the application of MLflow in quantum
research, illustrating how it enables better development practices, experiment
reproducibility, decision making, and cross-domain integration in an
increasingly hybrid classical-quantum landscape.

</details>
