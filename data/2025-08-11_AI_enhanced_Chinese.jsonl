{"id": "2508.05693", "pdf": "https://arxiv.org/pdf/2508.05693", "abs": "https://arxiv.org/abs/2508.05693", "authors": ["Siamak Farshidi", "Amir Saberhabibi", "Behbod Eskafi", "Niloofar Nikfarjam", "Sadegh Eskandari", "Slinger Jansen", "Michel Chaudron", "Bedir Tekinerdogan"], "title": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Selecting third-party software packages in open-source ecosystems like Python\nis challenging due to the large number of alternatives and limited transparent\nevidence for comparison. Generative AI tools are increasingly used in\ndevelopment workflows, but their suggestions often overlook dependency\nevaluation, emphasize popularity over suitability, and lack reproducibility.\nThis creates risks for projects that require transparency, long-term\nreliability, maintainability, and informed architectural decisions. This study\nformulates software package selection as a Multi-Criteria Decision-Making\n(MCDM) problem and proposes a data-driven framework for technology evaluation.\nAutomated data pipelines continuously collect and integrate software metadata,\nusage trends, vulnerability information, and developer sentiment from GitHub,\nPyPI, and Stack Overflow. These data are structured into a decision model\nrepresenting relationships among packages, domain features, and quality\nattributes. The framework is implemented in PySelect, a decision support system\nthat uses large language models to interpret user intent and query the model to\nidentify contextually appropriate packages. The approach is evaluated using\n798,669 Python scripts from 16,887 GitHub repositories and a user study based\non the Technology Acceptance Model. Results show high data extraction\nprecision, improved recommendation quality over generative AI baselines, and\npositive user evaluations of usefulness and ease of use. This work introduces a\nscalable, interpretable, and reproducible framework that supports\nevidence-based software selection using MCDM principles, empirical data, and\nAI-assisted intent modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u51c6\u5219\u51b3\u7b56\uff08MCDM\uff09\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6PySelect\uff0c\u7528\u4e8ePython\u8f6f\u4ef6\u5305\u7684\u900f\u660e\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u63a8\u8350\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f00\u6e90\u751f\u6001\u4e2d\u7b2c\u4e09\u65b9\u8f6f\u4ef6\u5305\u9009\u62e9\u56f0\u96be\uff0c\u73b0\u6709\u5de5\u5177\u4f9d\u8d56\u6d41\u884c\u5ea6\u800c\u975e\u9002\u7528\u6027\uff0c\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u73b0\u6027\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u7ba1\u9053\u6536\u96c6\u8f6f\u4ef6\u5143\u6570\u636e\uff0c\u6784\u5efa\u51b3\u7b56\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u51b3\u7b56\u652f\u6301\u7cfb\u7edfPySelect\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u6570\u636e\u63d0\u53d6\u7cbe\u5ea6\u9ad8\uff0c\u63a8\u8350\u8d28\u91cf\u4f18\u4e8e\u751f\u6210\u5f0fAI\u57fa\u7ebf\uff0c\u7528\u6237\u53cd\u9988\u79ef\u6781\u3002", "conclusion": "\u8be5\u6846\u67b6\u7ed3\u5408MCDM\u3001\u5b9e\u8bc1\u6570\u636e\u548cAI\u610f\u56fe\u5efa\u6a21\uff0c\u4e3a\u8f6f\u4ef6\u5305\u9009\u62e9\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05997", "pdf": "https://arxiv.org/pdf/2508.05997", "abs": "https://arxiv.org/abs/2508.05997", "authors": ["Aditi Kabra", "Jonathan Laurent", "Stefan Mitsch", "Andr\u00e9 Platzer"], "title": "Hybrid Game Control Envelope Synthesis", "categories": ["cs.PL", "cs.LO", "I.2.2; I.2.4"], "comment": null, "summary": "Control problems for embedded systems like cars and trains can be modeled by\ntwo-player hybrid games. Control envelopes, which are families of safe control\nsolutions, correspond to nondeterministic winning policies of hybrid games,\nwhere each deterministic specialization of the policy is a control solution.\nThis paper synthesizes nondeterministic winning policies for hybrid games that\nare as permissive as possible. It introduces subvalue maps, a compositional\nrepresentation of such policies that enables verification and synthesis along\nthe structure of the game. An inductive logical characterization in\ndifferential game logic (dGL) checks whether a subvalue map induces a sound\ncontrol envelope which always induces a winning play. A policy is said to win\nif it always achieves the desirable outcome when the player follows it, no\nmatter what actions the opponent plays. The maximal subvalue map, which allows\nthe most action options while still winning, is shown to exist and satisfy a\nlogical characterization. A family of algorithms for nondeterministic policy\nsynthesis can be obtained from the inductive subvalue map soundness\ncharacterization. An implementation of these findings is evaluated on examples\nthat use the expressivity of dGL to model a range of diverse control\nchallenges.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5d4c\u5165\u5f0f\u7cfb\u7edf\u63a7\u5236\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5408\u6210\u5c3d\u53ef\u80fd\u5bbd\u677e\u7684\u975e\u786e\u5b9a\u6027\u83b7\u80dc\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u5b50\u4ef7\u503c\u6620\u5c04\u7684\u6982\u5ff5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff08\u5982\u6c7d\u8f66\u548c\u706b\u8f66\uff09\u7684\u590d\u6742\u63a7\u5236\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u7075\u6d3b\u4e14\u5b89\u5168\u7684\u63a7\u5236\u7b56\u7565\uff0c\u4ee5\u5e94\u5bf9\u591a\u6837\u5316\u7684\u63a7\u5236\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5b50\u4ef7\u503c\u6620\u5c04\u4f5c\u4e3a\u975e\u786e\u5b9a\u6027\u7b56\u7565\u7684\u7ec4\u6210\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u5fae\u5206\u535a\u5f08\u903b\u8f91\uff08dGL\uff09\u8fdb\u884c\u9a8c\u8bc1\uff0c\u786e\u4fdd\u5176\u59cb\u7ec8\u80fd\u8bf1\u5bfc\u83b7\u80dc\u884c\u4e3a\u3002", "result": "\u8bc1\u660e\u4e86\u6700\u5927\u5b50\u4ef7\u503c\u6620\u5c04\u7684\u5b58\u5728\u6027\u53ca\u5176\u903b\u8f91\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u73b0\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u63a7\u5236\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u53ef\u9760\u7684\u5408\u6210\u7b56\u7565\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.05710", "pdf": "https://arxiv.org/pdf/2508.05710", "abs": "https://arxiv.org/abs/2508.05710", "authors": ["Jia Fu", "Xinyu Yang", "Hongzhi Zhang", "Yahui Liu", "Jingyuan Zhang", "Qi Wang", "Fuzheng Zhang", "Guorui Zhou"], "title": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning", "categories": ["cs.SE", "cs.AI"], "comment": "21 pages, 11 figures", "summary": "Precise, correct feedback is crucial for effectively training large language\nmodels (LLMs) in code reinforcement learning. However, synthesizing\nhigh-quality test cases remains a profoundly challenging and unsolved problem.\nIn this work, we present Klear-CodeTest, a comprehensive test case synthesis\nframework featuring rigorous verification to ensure quality and reliability of\ntest cases. Our approach achieves broad coverage of programming problems via a\nnovel Generator-Validation (G-V) framework, ensuring correctness through a\nconsistency validation mechanism that verifies outputs against gold solutions.\nThe proposed G-V framework generates comprehensive test cases including both\nregular and corner cases, enhancing test coverage and discriminative power for\nsolution correctness assessment in code reinforcement learning. In addition, we\ndesign a multi-layered security sandbox system optimized for online\nverification platforms, guaranteeing safe and reliable code execution. Through\ncomprehensive experiments, we demonstrate the effectiveness of our curated\ndataset, showing significant improvements in model performance and training\nstability. The source codes, curated dataset and sandbox system are available\nat: https://github.com/Kwai-Klear/CodeTest.", "AI": {"tldr": "Klear-CodeTest \u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u6d4b\u8bd5\u7528\u4f8b\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7 Generator-Validation (G-V) \u673a\u5236\u786e\u4fdd\u6d4b\u8bd5\u7528\u4f8b\u7684\u6b63\u786e\u6027\u548c\u8986\u76d6\u7387\uff0c\u5e76\u8bbe\u8ba1\u4e86\u591a\u5c42\u5b89\u5168\u6c99\u7bb1\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u7684\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5728\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u7684\u751f\u6210\u662f\u4e00\u4e2a\u5c1a\u672a\u89e3\u51b3\u7684\u6311\u6218\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u786e\u4fdd\u6b63\u786e\u6027\u548c\u5e7f\u6cdb\u8986\u76d6\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u8bad\u7ec3\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86 Generator-Validation (G-V) \u6846\u67b6\uff0c\u7ed3\u5408\u751f\u6210\u5668\u548c\u4e00\u81f4\u6027\u9a8c\u8bc1\u673a\u5236\uff0c\u751f\u6210\u5305\u62ec\u5e38\u89c4\u548c\u6781\u7aef\u60c5\u51b5\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u8bbe\u8ba1\u591a\u5c42\u5b89\u5168\u6c99\u7bb1\u7cfb\u7edf\u786e\u4fdd\u53ef\u9760\u6267\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u7684\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002", "conclusion": "Klear-CodeTest \u901a\u8fc7\u521b\u65b0\u7684 G-V \u6846\u67b6\u548c\u5b89\u5168\u6c99\u7bb1\u8bbe\u8ba1\uff0c\u4e3a\u89e3\u51b3\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05747", "pdf": "https://arxiv.org/pdf/2508.05747", "abs": "https://arxiv.org/abs/2508.05747", "authors": ["Rohaizah Abdul Wahid", "Muhamad Said Nizamuddin Nadim", "Suliana Sulaiman", "Syahmi Akmal Shaharudin", "Muhammad Danial Jupikil", "Iqqwan Jasman Su Azlan Su"], "title": "Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework", "categories": ["cs.SE", "cs.ET"], "comment": null, "summary": "Laravel has emerged as a foundational framework in university web development\ncurricula. However, despite its scaffolding capabilities, students often\nstruggle to complete projects within limited academic timelines. This\nconceptual paper introduces Composer, PHP's standard dependency manager, and\ncategorizes a curated selection of Composer packages that significantly reduce\ndevelopment effort while fostering professional software practices. Grounded in\npractical and pedagogical considerations, the paper illustrates how educators\nand learners can strategically leverage these tools to build typical academic\nor personal Laravel-based systems. Central to this approach is maintaining code\nquality and reinforcing conceptual understanding. The paper also addresses\npotential risks such as package conflicts and over-reliance on tools, providing\nbest-practice recommendations to mitigate them. While the goal is to accelerate\ndevelopment, the deeper objective is to reinforce professional workflows and\nindustry readiness. Exposure to Composer packages enhances curriculum relevance\nand smooths the transition from academia to the workplace. However, effective\nintegration requires deliberate instructional design aligned with learning\nobjectives. Without guidance, students may treat packages as black boxes. Thus,\neducators must teach not only how to use these tools, but also when and why,\nencouraging critical evaluation of their utility and limitations. This ensures\nthat practical convenience supports rather than supplants deep learning.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u5728\u5927\u5b66Laravel\u8bfe\u7a0b\u4e2d\u5229\u7528Composer\u53ca\u5176\u7cbe\u9009\u5305\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0c\u540c\u65f6\u57f9\u517b\u804c\u4e1a\u8f6f\u4ef6\u5b9e\u8df5\uff0c\u9700\u6ce8\u610f\u5de5\u5177\u4f9d\u8d56\u98ce\u9669\u5e76\u5f3a\u8c03\u6559\u5b66\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u5b66\u751f\u5728\u6709\u9650\u65f6\u95f4\u5185\u5b8c\u6210Laravel\u9879\u76ee\u6709\u56f0\u96be\uff0c\u9700\u5de5\u5177\u548c\u65b9\u6cd5\u63d0\u5347\u6548\u7387\u5e76\u57f9\u517b\u804c\u4e1a\u4e60\u60ef\u3002", "method": "\u4ecb\u7ecdComposer\u53ca\u7cbe\u9009\u5305\uff0c\u63d0\u4f9b\u7b56\u7565\u548c\u6700\u4f73\u5b9e\u8df5\uff0c\u7ed3\u5408\u6559\u5b66\u5b9e\u8df5\u5f3a\u5316\u4ee3\u7801\u8d28\u91cf\u548c\u6982\u5ff5\u7406\u89e3\u3002", "result": "Composer\u5305\u80fd\u52a0\u901f\u5f00\u53d1\u5e76\u589e\u5f3a\u804c\u4e1a\u51c6\u5907\uff0c\u9700\u6559\u5b66\u6307\u5bfc\u4ee5\u907f\u514d\u5de5\u5177\u6ee5\u7528\u3002", "conclusion": "\u5408\u7406\u4f7f\u7528Composer\u5305\u53ef\u63d0\u5347\u8bfe\u7a0b\u76f8\u5173\u6027\u548c\u5b66\u751f\u804c\u4e1a\u80fd\u529b\uff0c\u4f46\u9700\u914d\u5957\u6559\u5b66\u8bbe\u8ba1\u786e\u4fdd\u6df1\u5ea6\u5b66\u4e60\u3002"}}
{"id": "2508.05798", "pdf": "https://arxiv.org/pdf/2508.05798", "abs": "https://arxiv.org/abs/2508.05798", "authors": ["Yuri Gurevich"], "title": "Basic interactive algorithms: Preview", "categories": ["cs.LO", "cs.CL", "math.LO", "quant-ph"], "comment": null, "summary": "This dialog paper offers a preview and provides a foretaste of an upcoming\nwork on the axiomatization of basic interactive algorithms.\n  The modern notion of algorithm was elucidated in the 1930s--1950s. It was\naxiomatized a quarter of a century ago as the notion of ``sequential\nalgorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm\"\nnow. The axiomatization was used to show that for every basic algorithm there\nis a behaviorally equivalent abstract state machine. It was also used to prove\nthe Church-Turing thesis as it has been understood by the logicians.\n  Starting from the 1960s, the notion of algorithm has expanded --\nprobabilistic algorithms, quantum algorithms, etc. -- prompting introduction of\na much more ambitious version of the Church-Turing thesis commonly known as the\n``physical thesis.'' We emphasize the difference between the two versions of\nthe Church-Turing thesis and illustrate how nondeterministic and probabilistic\nalgorithms can be viewed as basic algorithms with appropriate oracles. The same\nview applies to quantum circuit algorithms and many other classes of\nalgorithms.", "AI": {"tldr": "\u672c\u6587\u9884\u89c8\u4e86\u5373\u5c06\u53d1\u8868\u7684\u5de5\u4f5c\uff0c\u63a2\u8ba8\u57fa\u672c\u4ea4\u4e92\u5f0f\u7b97\u6cd5\u7684\u516c\u7406\u5316\u3002\u4ece\u7ecf\u5178\u7b97\u6cd5\u6269\u5c55\u5230\u6982\u7387\u3001\u91cf\u5b50\u7b49\u7b97\u6cd5\uff0c\u533a\u5206\u4e86\u4e24\u79cdChurch-Turing\u547d\u9898\u3002", "motivation": "\u73b0\u4ee3\u7b97\u6cd5\u6982\u5ff5\u57281930-50\u5e74\u4ee3\u660e\u786e\uff0c25\u5e74\u524d\u88ab\u516c\u7406\u5316\uff0c\u4f46\u5982\u4eca\u6269\u5c55\u4e86\u6982\u7387\u3001\u91cf\u5b50\u7b49\u7b97\u6cd5\uff0c\u4fc3\u4f7f\u91cd\u65b0\u5ba1\u89c6Church-Turing\u547d\u9898\u3002", "method": "\u901a\u8fc7\u516c\u7406\u5316\u57fa\u672c\u7b97\u6cd5\uff0c\u8bc1\u660e\u5176\u884c\u4e3a\u7b49\u4ef7\u4e8e\u62bd\u8c61\u72b6\u6001\u673a\uff0c\u5e76\u5c06\u975e\u786e\u5b9a\u6027\u3001\u6982\u7387\u7b97\u6cd5\u89c6\u4e3a\u5e26\u9002\u5f53\u9884\u8a00\u7684\u57fa\u672c\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u7ecf\u5178\u7b97\u6cd5\u4e0e\u62bd\u8c61\u72b6\u6001\u673a\u884c\u4e3a\u7b49\u4ef7\uff0c\u5c55\u793a\u4e86\u6982\u7387\u3001\u91cf\u5b50\u7b97\u6cd5\u7b49\u53ef\u4f5c\u4e3a\u5e26\u9884\u8a00\u7684\u57fa\u672c\u7b97\u6cd5\u3002", "conclusion": "\u6269\u5c55\u7b97\u6cd5\u6982\u5ff5\uff0c\u5f3a\u8c03\u4e24\u79cdChurch-Turing\u547d\u9898\u7684\u533a\u522b\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7b97\u6cd5\u7c7b\u63d0\u4f9b\u516c\u7406\u5316\u6846\u67b6\u3002"}}
{"id": "2508.05799", "pdf": "https://arxiv.org/pdf/2508.05799", "abs": "https://arxiv.org/abs/2508.05799", "authors": ["Yoseph Berhanu Alebachew"], "title": "AI-Guided Exploration of Large-Scale Codebases", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Understanding large-scale, complex software systems is a major challenge for\ndevelopers, who spend a significant portion of their time on program\ncomprehension. Traditional tools such as static visualizations and reverse\nengineering techniques provide structural insights but often lack\ninteractivity, adaptability, and integration with contextual information.\nRecent advancements in large language models (LLMs) offer new opportunities to\nenhance code exploration workflows, yet their lack of grounding and integration\nwith structured views limits their effectiveness. This work introduces a hybrid\napproach that integrates deterministic reverse engineering with LLM-guided,\nintent-aware visual exploration. The proposed system combines UML-based\nvisualization, dynamic user interfaces, historical context, and collaborative\nfeatures into an adaptive tool for code comprehension. By interpreting user\nqueries and interaction patterns, the LLM helps developers navigate and\nunderstand complex codebases more effectively. A prototype implementation for\nJava demonstrates the feasibility of this approach. Future work includes\nempirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM\ninteraction models. This research lays the groundwork for intelligent,\ninteractive environments that align with developer cognition and collaborative\nworkflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u786e\u5b9a\u6027\u9006\u5411\u5de5\u7a0b\u4e0e\u57fa\u4e8eLLM\u7684\u610f\u56fe\u611f\u77e5\u53ef\u89c6\u5316\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u4ee3\u7801\u7406\u89e3\u6548\u679c\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u7406\u89e3\u5927\u578b\u590d\u6742\u8f6f\u4ef6\u7cfb\u7edf\u65f6\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u5de5\u5177\u7f3a\u4e4f\u4ea4\u4e92\u6027\u548c\u9002\u5e94\u6027\uff0cLLMs\u867d\u5148\u8fdb\u4f46\u7f3a\u4e4f\u57fa\u7840\u6027\u548c\u7ed3\u6784\u6027\u89c6\u56fe\u7684\u6574\u5408\u3002", "method": "\u7ed3\u5408UML\u53ef\u89c6\u5316\u3001\u52a8\u6001\u7528\u6237\u754c\u9762\u3001\u5386\u53f2\u4e0a\u4e0b\u6587\u548c\u534f\u4f5c\u529f\u80fd\uff0c\u901a\u8fc7LLM\u89e3\u6790\u7528\u6237\u67e5\u8be2\u548c\u4ea4\u4e92\u6a21\u5f0f\u3002", "result": "Java\u539f\u578b\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u4e3a\u6784\u5efa\u667a\u80fd\u3001\u4ea4\u4e92\u5f0f\u7684\u5f00\u53d1\u73af\u5883\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u672a\u6765\u5c06\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3001\u6269\u5c55\u81f3\u591a\u8bed\u8a00\u7cfb\u7edf\u53ca\u63a2\u7d22GUI\u9a71\u52a8\u7684LLM\u4ea4\u4e92\u6a21\u578b\u3002"}}
{"id": "2508.06088", "pdf": "https://arxiv.org/pdf/2508.06088", "abs": "https://arxiv.org/abs/2508.06088", "authors": ["Kittiphon Phalakarn", "Yun Chen Tsai", "Ichiro Hasuo"], "title": "Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games", "categories": ["cs.LO"], "comment": null, "summary": "For model checking stochastic games (SGs), bounded value iteration (BVI)\nalgorithms have gained attention as efficient approximate methods with rigorous\nprecision guarantees. However, BVI may not terminate or converge when the\ntarget SG contains end components. Most existing approaches address this issue\nby explicitly detecting and processing end components--a process that is often\ncomputationally expensive. An exception is the widest path-based BVI approach\npreviously studied by Phalakarn et al., which we refer to as 1WP-BVI. The\nmethod performs particularly well in the presence of numerous end components.\nNonetheless, its theoretical foundations remain somewhat ad hoc. In this paper,\nwe identify and formalize the core principles underlying the widest path-based\nBVI approach by (i) presenting 2WP-BVI, a clean BVI algorithm based on\n(2-player) widest path games, and (ii) proving its correctness using what we\ncall the maximality inheritance principle--a proof principle previously\nemployed in a well-known result in probabilistic model checking. Our\nexperimental results demonstrate the practical relevance and potential of our\nproposed 2WP-BVI algorithm.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u53cc\u4eba\u6700\u5bbd\u8def\u5f84\u6e38\u620f\u7684BVI\u7b97\u6cd52WP-BVI\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u68c0\u6d4b\u548c\u7ec8\u7ed3\u7ec4\u4ef6\u7684\u6602\u8d35\u8ba1\u7b97\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfBVI\u7b97\u6cd5\u5728\u5b58\u5728\u7ec8\u7ed3\u7ec4\u4ef6\u65f6\u53ef\u80fd\u65e0\u6cd5\u7ec8\u6b62\u6216\u6536\u655b\uff0c\u73b0\u6709\u65b9\u6cd5\u5904\u7406\u7ec8\u7ed3\u7ec4\u4ef6\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c1WP-BVI\u867d\u9ad8\u6548\u4f46\u7406\u8bba\u57fa\u7840\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa2WP-BVI\u7b97\u6cd5\uff0c\u57fa\u4e8e\u53cc\u4eba\u6700\u5bbd\u8def\u5f84\u6e38\u620f\uff0c\u5229\u7528\u6700\u5927\u6027\u7ee7\u627f\u539f\u7406\u8bc1\u660e\u5176\u6b63\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e2WP-BVI\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u548c\u9ad8\u6548\u6027\u3002", "conclusion": "2WP-BVI\u89e3\u51b3\u4e86\u4f20\u7edfBVI\u7b97\u6cd5\u7684\u5c40\u9650\uff0c\u4e3a\u968f\u673a\u6e38\u620f\u6a21\u578b\u68c0\u67e5\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u4e14\u7406\u8bba\u57fa\u7840\u575a\u5b9e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05658", "pdf": "https://arxiv.org/pdf/2508.05658", "abs": "https://arxiv.org/abs/2508.05658", "authors": ["Song Yan", "Hui Wei", "Jinlong Fei", "Guoliang Yang", "Zhengyu Zhao", "Zheng Wamg"], "title": "Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards", "categories": ["cs.CR", "cs.CV", "cs.MM"], "comment": "ACM MM 2025", "summary": "Various (text) prompt filters and (image) safety checkers have been\nimplemented to mitigate the misuse of Text-to-Image (T2I) models in creating\nNot-Safe-For-Work (NSFW) content.In order to expose potential security\nvulnerabilities of such safeguards, multimodal jailbreaks have been\nstudied.However, existing jailbreaks are limited to prompt-specific and\nimage-specific perturbations, which suffer from poor scalability and\ntime-consuming optimization.To address these limitations, we propose\nUniversally Unfiltered and Unseen (U3)-Attack, a multimodal jailbreak attack\nmethod against T2I safeguards.Specifically, U3-Attack optimizes an adversarial\npatch on the image background to universally bypass safety checkers and\noptimizes a safe paraphrase set from a sensitive word to universally bypass\nprompt filters while eliminating redundant computations.Extensive experimental\nresults demonstrate the superiority of our U3-Attack on both open-source and\ncommercial T2I models.For example, on the commercial Runway-inpainting model\nwith both prompt filter and safety checker, our U3-Attack achieves $~4\\times$\nhigher success rates than the state-of-the-art multimodal jailbreak attack,\nMMA-Diffusion.Content Warning: This paper includes examples of NSFW content.", "AI": {"tldr": "U3-Attack\u662f\u4e00\u79cd\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u9488\u5bf9\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6a21\u578b\u7684\u5b89\u5168\u4fdd\u62a4\u63aa\u65bd\uff0c\u901a\u8fc7\u4f18\u5316\u56fe\u50cf\u80cc\u666f\u7684\u5bf9\u6297\u8865\u4e01\u548c\u654f\u611f\u8bcd\u7684\u5b89\u5168\u6539\u5199\u96c6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u548c\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u5c40\u9650\u4e8e\u7279\u5b9a\u63d0\u793a\u548c\u56fe\u50cf\u7684\u6270\u52a8\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u4e14\u4f18\u5316\u8017\u65f6\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u51fa\u4e86U3-Attack\u3002", "method": "U3-Attack\u4f18\u5316\u56fe\u50cf\u80cc\u666f\u7684\u5bf9\u6297\u8865\u4e01\u4ee5\u7ed5\u8fc7\u5b89\u5168\u68c0\u67e5\u5668\uff0c\u540c\u65f6\u4f18\u5316\u654f\u611f\u8bcd\u7684\u5b89\u5168\u6539\u5199\u96c6\u4ee5\u7ed5\u8fc7\u63d0\u793a\u8fc7\u6ee4\u5668\uff0c\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cU3-Attack\u5728\u5f00\u6e90\u548c\u5546\u4e1aT2I\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f8b\u5982\u5728Runway-inpainting\u6a21\u578b\u4e0a\u6210\u529f\u7387\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad84\u500d\u3002", "conclusion": "U3-Attack\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06432", "pdf": "https://arxiv.org/pdf/2508.06432", "abs": "https://arxiv.org/abs/2508.06432", "authors": ["Jesutofunmi Ajayi", "Antonio Di Maio", "Torsten Braun"], "title": "Hierarchical Placement Learning for Network Slice Provisioning", "categories": ["cs.NI"], "comment": null, "summary": "In this work, we aim to address the challenge of slice provisioning in\nedge-based mobile networks. We propose a solution that learns a service\nfunction chain placement policy for Network Slice Requests, to maximize the\nrequest acceptance rate, while minimizing the average node resource\nutilization. To do this, we consider a Hierarchical Multi-Armed Bandit problem\nand propose a two-level hierarchical bandit solution which aims to learn a\nscalable placement policy that optimizes the stated objectives in an online\nmanner. Simulations on two real network topologies show that our proposed\napproach achieves 5% average node resource utilization while admitting over 25%\nmore slice requests in certain scenarios, compared to baseline methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5c42\u6b21\u591a\u81c2\u8001\u864e\u673a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u8fb9\u7f18\u79fb\u52a8\u7f51\u7edc\u4e2d\u7684\u5207\u7247\u914d\u7f6e\uff0c\u4ee5\u63d0\u9ad8\u8bf7\u6c42\u63a5\u53d7\u7387\u5e76\u964d\u4f4e\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18\u79fb\u52a8\u7f51\u7edc\u4e2d\u5207\u7247\u914d\u7f6e\u7684\u6311\u6218\uff0c\u4f18\u5316\u8bf7\u6c42\u63a5\u53d7\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "method": "\u91c7\u7528\u5c42\u6b21\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\uff0c\u5b66\u4e60\u53ef\u6269\u5c55\u7684\u5207\u7247\u914d\u7f6e\u7b56\u7565\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u5b9e\u73b0\u4e865%\u7684\u5e73\u5747\u8282\u70b9\u8d44\u6e90\u5229\u7528\u7387\uff0c\u5e76\u63d0\u9ad8\u4e8625%\u4ee5\u4e0a\u7684\u5207\u7247\u8bf7\u6c42\u63a5\u53d7\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u63d0\u9ad8\u5207\u7247\u8bf7\u6c42\u63a5\u53d7\u7387\u548c\u964d\u4f4e\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2508.05963", "pdf": "https://arxiv.org/pdf/2508.05963", "abs": "https://arxiv.org/abs/2508.05963", "authors": ["Michael Beyeler"], "title": "Bionic Vision as Neuroadaptive XR: Closed-Loop Perceptual Interfaces for Neurotechnology", "categories": ["cs.ET", "cs.HC"], "comment": null, "summary": "Visual neuroprostheses are commonly framed as technologies to restore natural\nsight to people who are blind. In practice, they create a novel mode of\nperception shaped by sparse, distorted, and unstable input. They resemble early\nextended reality (XR) headsets more than natural vision, streaming video from a\nhead-mounted camera to a neural \"display\" with under 1000 pixels, limited field\nof view, low refresh rates, and nonlinear spatial mappings. No amount of\nresolution alone will make this experience natural. This paper proposes a\nreframing: bionic vision as neuroadaptive XR. Rather than replicating natural\nsight, the goal is to co-adapt brain and device through a bidirectional\ninterface that responds to neural constraints, behavioral goals, and cognitive\nstate. By comparing traditional XR, current implants, and proposed\nneuroadaptive systems, it introduces a new design space for inclusive,\nbrain-aware computing. It concludes with research provocations spanning\nencoding, evaluation, learning, and ethics, and invites the XR community to\nhelp shape the future of sensory augmentation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u4eff\u751f\u89c6\u89c9\u91cd\u65b0\u5b9a\u4e49\u4e3a\u795e\u7ecf\u9002\u5e94\u6027XR\uff08\u6269\u5c55\u73b0\u5b9e\uff09\uff0c\u800c\u975e\u5355\u7eaf\u590d\u5236\u81ea\u7136\u89c6\u89c9\uff0c\u5f3a\u8c03\u901a\u8fc7\u53cc\u5411\u63a5\u53e3\u5b9e\u73b0\u8111\u4e0e\u8bbe\u5907\u7684\u534f\u540c\u9002\u5e94\u3002", "motivation": "\u4f20\u7edf\u89c6\u89c9\u795e\u7ecf\u5047\u4f53\u8bd5\u56fe\u6062\u590d\u81ea\u7136\u89c6\u89c9\uff0c\u4f46\u5b9e\u9645\u6548\u679c\u53d7\u9650\uff0c\u8f93\u5165\u7a00\u758f\u3001\u626d\u66f2\u4e14\u4e0d\u7a33\u5b9a\u3002\u4f5c\u8005\u8ba4\u4e3a\u5e94\u91cd\u65b0\u8bbe\u8ba1\uff0c\u4f7f\u5176\u66f4\u50cfXR\u6280\u672f\uff0c\u9002\u5e94\u5927\u8111\u4e0e\u884c\u4e3a\u9700\u6c42\u3002", "method": "\u8bba\u6587\u6bd4\u8f83\u4e86\u4f20\u7edfXR\u3001\u73b0\u6709\u690d\u5165\u8bbe\u5907\u548c\u63d0\u51fa\u7684\u795e\u7ecf\u9002\u5e94\u6027\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5f3a\u8c03\u8111-\u8bbe\u5907\u53cc\u5411\u63a5\u53e3\u3002", "result": "\u63d0\u51fa\u4e86\u795e\u7ecf\u9002\u5e94\u6027XR\u7684\u6982\u5ff5\uff0c\u4e3a\u611f\u5b98\u589e\u5f3a\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u5e76\u547c\u5401XR\u793e\u533a\u53c2\u4e0e\u7814\u7a76\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u65b9\u5411\u5e94\u5173\u6ce8\u7f16\u7801\u3001\u8bc4\u4f30\u3001\u5b66\u4e60\u548c\u4f26\u7406\u95ee\u9898\uff0c\u63a8\u52a8\u66f4\u5305\u5bb9\u3001\u5927\u8111\u611f\u77e5\u7684\u8ba1\u7b97\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2508.05637", "pdf": "https://arxiv.org/pdf/2508.05637", "abs": "https://arxiv.org/abs/2508.05637", "authors": ["Siddharth Gangwar", "David A. Selby", "Sebastian J. Vollmer"], "title": "Automated Visualization Makeovers with LLMs", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Making a good graphic that accurately and efficiently conveys the desired\nmessage to the audience is both an art and a science, typically not taught in\nthe data science curriculum. Visualisation makeovers are exercises where the\ncommunity exchange feedback to improve charts and data visualizations. Can\nmulti-modal large language models (LLMs) emulate this task? Given a plot in the\nform of an image file, or the code used to generate it, an LLM, primed with a\nlist of visualization best practices, is employed to semi-automatically\ngenerate constructive criticism to produce a better plot. Our system is centred\naround prompt engineering of a pre-trained model, relying on a combination of\nuserspecified guidelines and any latent knowledge of data visualization\npractices that might lie within an LLMs training corpus. Unlike other works,\nthe focus is not on generating valid visualization scripts from raw data or\nprompts, but on educating the user how to improve their existing data\nvisualizations according to an interpretation of best practices. A quantitative\nevaluation is performed to measure the sensitivity of the LLM agent to various\nplotting issues across different chart types. We make the tool available as a\nsimple self-hosted applet with an accessible Web interface.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u534a\u81ea\u52a8\u751f\u6210\u6539\u8fdb\u6570\u636e\u53ef\u89c6\u5316\u7684\u5efa\u8bae\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u7ed3\u5408\u53ef\u89c6\u5316\u6700\u4f73\u5b9e\u8df5\uff0c\u5e2e\u52a9\u7528\u6237\u4f18\u5316\u73b0\u6709\u56fe\u8868\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u901a\u5e38\u672a\u6559\u6388\u5982\u4f55\u5236\u4f5c\u9ad8\u6548\u4f20\u8fbe\u4fe1\u606f\u7684\u56fe\u8868\u3002\u672c\u6587\u65e8\u5728\u5229\u7528LLM\u6a21\u62df\u53ef\u89c6\u5316\u6539\u9020\u4efb\u52a1\uff0c\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684LLM\uff0c\u7ed3\u5408\u7528\u6237\u6307\u5b9a\u7684\u6307\u5357\u548c\u6a21\u578b\u6f5c\u5728\u7684\u53ef\u89c6\u5316\u77e5\u8bc6\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u751f\u6210\u6539\u8fdb\u5efa\u8bae\u3002", "result": "\u5b9a\u91cf\u8bc4\u4f30\u8868\u660e\uff0cLLM\u4ee3\u7406\u5bf9\u4e0d\u540c\u56fe\u8868\u7c7b\u578b\u7684\u7ed8\u56fe\u95ee\u9898\u5177\u6709\u654f\u611f\u6027\u3002\u5de5\u5177\u4ee5\u7b80\u5355\u7684\u81ea\u6258\u7ba1\u5c0f\u7a0b\u5e8f\u5f62\u5f0f\u63d0\u4f9b\uff0c\u5177\u6709\u53ef\u8bbf\u95ee\u7684Web\u754c\u9762\u3002", "conclusion": "LLM\u53ef\u4f5c\u4e3a\u6559\u80b2\u5de5\u5177\uff0c\u5e2e\u52a9\u7528\u6237\u6839\u636e\u6700\u4f73\u5b9e\u8df5\u6539\u8fdb\u73b0\u6709\u6570\u636e\u53ef\u89c6\u5316\u3002"}}
{"id": "2508.05797", "pdf": "https://arxiv.org/pdf/2508.05797", "abs": "https://arxiv.org/abs/2508.05797", "authors": ["Sreeharsha Udayashankar", "Abdelrahman Baba", "Samer Al-Kiswany"], "title": "Accelerating Data Chunking in Deduplication Systems using Vector Instructions", "categories": ["cs.DC", "cs.AR"], "comment": "Under review. This is the follow-up work to our FAST 2025 paper,\n  \"VectorCDC: Accelerating Data Deduplication with Vector Instructions\". The\n  associated code is available at https://github.com/UWASL/dedup-bench", "summary": "Content-defined Chunking (CDC) algorithms dictate the overall space savings\nthat deduplication systems achieve. However, due to their need to scan each\nfile in its entirety, they are slow and often the main performance bottleneck\nwithin data deduplication. We present VectorCDC, a method to accelerate\nhashless CDC algorithms using vector CPU instructions, such as SSE / AVX. Our\nevaluation shows that VectorCDC is effective on Intel, AMD, ARM, and IBM CPUs,\nachieving 8.35x - 26.2x higher throughput than existing vector-accelerated\ntechniques without affecting the deduplication space savings.", "AI": {"tldr": "VectorCDC\u5229\u7528\u77e2\u91cfCPU\u6307\u4ee4\u52a0\u901f\u65e0\u54c8\u5e0cCDC\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u800c\u4e0d\u5f71\u54cd\u53bb\u91cd\u7a7a\u95f4\u8282\u7701\u3002", "motivation": "CDC\u7b97\u6cd5\u56e0\u9700\u5168\u6587\u4ef6\u626b\u63cf\u800c\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u4e9f\u9700\u63d0\u901f\u3002", "method": "\u91c7\u7528\u77e2\u91cfCPU\u6307\u4ee4\uff08\u5982SSE/AVX\uff09\u4f18\u5316\u54c8\u5e0c\u65e0\u5173\u7684CDC\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u79cdCPU\u4e0a\u5b9e\u73b08.35\u500d\u81f326.2\u500d\u541e\u5410\u91cf\u63d0\u5347\uff0c\u7a7a\u95f4\u8282\u7701\u4e0d\u53d8\u3002", "conclusion": "VectorCDC\u9ad8\u6548\u89e3\u51b3CDC\u6027\u80fd\u74f6\u9888\uff0c\u9002\u7528\u5e7f\u6cdb\u786c\u4ef6\u3002"}}
{"id": "2508.05779", "pdf": "https://arxiv.org/pdf/2508.05779", "abs": "https://arxiv.org/abs/2508.05779", "authors": ["Pengyu Liu", "Mingkuan Xu", "Hengyun Zhou", "Hanrui Wang", "Umut A. Acar", "Yunong Shi"], "title": "ConiQ: Enabling Concatenated Quantum Error Correction on Neutral Atom Arrays", "categories": ["cs.AR", "quant-ph"], "comment": null, "summary": "Recent progress on concatenated codes, especially many-hypercube codes,\nachieves unprecedented space efficiency. Yet two critical challenges persist in\npractice. First, these codes lack efficient implementations of addressable\nlogical gates. Second, the required high degree of parallelism and long-range\ninteractions pose significant challenges for current hardware platforms. In\nthis paper, we propose an efficient compilation approach for concatenated\ncodes, specifically many-hypercube codes, targeted at neutral atom arrays,\nwhich provide the necessary parallelism and long-range interactions. Our\napproach builds on two key innovations. First, we introduce\nAutomorphism-assisted Hierarchical Addressing (AHA) logical CNOT gates that\nsignificantly reduce spacetime overhead compared to conventional\ndistillation-based methods. Second, we develop Virtual Atom Intermediate\nRepresentation (VAIR) that enables level-wise optimization and legalization. We\nimplement these innovations in ConiQ, a hardware-aware quantum compiler\ndesigned to compile fault-tolerant quantum circuits for neutral atom arrays\nusing many-hypercube codes. Our evaluation demonstrates that ConiQ achieves up\nto 2000x reduction in spacetime overhead and up to 10^6x reduction in\ncompilation time compared to state-of-the-art compilers, with our AHA gates\nproviding an additional overhead reduction of up to 20x. These results\nestablish concatenated codes as a promising approach for fault-tolerant quantum\ncomputing in the near future.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e2d\u6027\u539f\u5b50\u9635\u5217\u7684\u9ad8\u6548\u7f16\u8bd1\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u91cf\u5b50\u8ba1\u7b97\u7684\u65f6\u7a7a\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u7ea7\u8054\u7801\uff08\u5c24\u5176\u662f\u591a\u8d85\u7acb\u65b9\u7801\uff09\u5728\u5b9e\u73b0\u903b\u8f91\u95e8\u548c\u786c\u4ef6\u5e76\u884c\u6027\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u81ea\u540c\u6784\u8f85\u52a9\u5206\u5c42\u5bfb\u5740\uff08AHA\uff09\u903b\u8f91CNOT\u95e8\u548c\u865a\u62df\u539f\u5b50\u4e2d\u95f4\u8868\u793a\uff08VAIR\uff09\u8fdb\u884c\u4f18\u5316\u3002", "result": "ConiQ\u7f16\u8bd1\u5668\u5b9e\u73b0\u4e86\u65f6\u7a7a\u5f00\u9500\u6700\u9ad82000\u500d\u7684\u964d\u4f4e\uff0c\u7f16\u8bd1\u65f6\u95f4\u6700\u9ad810^6\u500d\u7684\u51cf\u5c11\u3002", "conclusion": "\u7ea7\u8054\u7801\u4e3a\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.06077", "pdf": "https://arxiv.org/pdf/2508.06077", "abs": "https://arxiv.org/abs/2508.06077", "authors": ["Hongqin Lei", "Haowei Tang", "Zhe Zhang"], "title": "A Cross-Perspective Annotated Dataset for Dynamic Object-Level Attention Modeling in Cloud Gaming", "categories": ["cs.DB"], "comment": null, "summary": "Cloud gaming has gained popularity as it provides high-quality gaming\nexperiences on thin hardware, such as phones and tablets. Transmitting gameplay\nframes at high resolutions and ultra-low latency is the key to guaranteeing\nplayers' quality of experience (QoE). Numerous studies have explored deep\nlearning (DL) techniques to address this challenge. The efficiency of these\nDL-based approaches is highly affected by the dataset. However, existing\ndatasets usually focus on the positions of objects while ignoring semantic\nrelationships with other objects and their unique features. In this paper, we\npresent a game dataset by collecting gameplay clips from Grand Theft Auto (GTA)\nV, and annotating the player's interested objects during the gameplay. Based on\nthe collected data, we analyze several factors that have an impact on player's\ninterest and identify that the player's in-game speed, object's size, and\nobject's speed are the main factors. The dataset is available at\nhttps://drive.google.com/drive/folders/1idH251a2K-hGGd3pKjX-3Gx5o_rUqLC4?usp=sharing", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u300a\u4fa0\u76d7\u730e\u8f66\u624b5\u300b(GTA V)\u7684\u6e38\u620f\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u73a9\u5bb6\u611f\u5174\u8da3\u7684\u5bf9\u8c61\u53ca\u5176\u8bed\u4e49\u5173\u7cfb\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u5ffd\u7565\u8bed\u4e49\u7279\u5f81\u7684\u7a7a\u767d\u3002", "motivation": "\u4e91\u6e38\u620f\u7684\u5feb\u901f\u53d1\u5c55\u9700\u8981\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u652f\u6301\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u800c\u73b0\u6709\u6570\u636e\u96c6\u901a\u5e38\u5ffd\u7565\u5bf9\u8c61\u7684\u8bed\u4e49\u5173\u7cfb\u53ca\u5176\u72ec\u7279\u7279\u5f81\u3002", "method": "\u901a\u8fc7\u6536\u96c6GTA V\u7684\u6e38\u620f\u7247\u6bb5\u5e76\u6807\u6ce8\u73a9\u5bb6\u611f\u5174\u8da3\u7684\u5bf9\u8c61\uff0c\u5206\u6790\u4e86\u5f71\u54cd\u73a9\u5bb6\u5174\u8da3\u7684\u56e0\u7d20\uff0c\u5982\u73a9\u5bb6\u901f\u5ea6\u3001\u5bf9\u8c61\u5927\u5c0f\u548c\u5bf9\u8c61\u901f\u5ea6\u3002", "result": "\u53d1\u73b0\u73a9\u5bb6\u5728\u6e38\u620f\u4e2d\u7684\u901f\u5ea6\u3001\u5bf9\u8c61\u7684\u5927\u5c0f\u548c\u901f\u5ea6\u662f\u5f71\u54cd\u73a9\u5bb6\u5174\u8da3\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u4f9b\u7814\u7a76\u4f7f\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e91\u6e38\u620f\u7684\u8d28\u91cf\u4f53\u9a8c\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u652f\u6301\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6548\u679c\u3002"}}
{"id": "2508.05685", "pdf": "https://arxiv.org/pdf/2508.05685", "abs": "https://arxiv.org/abs/2508.05685", "authors": ["Yara Bahram", "Mohammadhadi Shateri", "Eric Granger"], "title": "DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models", "categories": ["cs.GR"], "comment": "Currently under review. Code will be released upon acceptance", "summary": "Transfer learning of diffusion models to smaller target domains is\nchallenging, as naively fine-tuning the model often results in poor\ngeneralization. Test-time guidance methods help mitigate this by offering\ncontrollable improvements in image fidelity through a trade-off with sample\ndiversity. However, this benefit comes at a high computational cost, typically\nrequiring dual forward passes during sampling. We propose the Domain-guided\nFine-tuning (DogFit) method, an effective guidance mechanism for diffusion\ntransfer learning that maintains controllability without incurring additional\ncomputational overhead. DogFit injects a domain-aware guidance offset into the\ntraining loss, effectively internalizing the guided behavior during the\nfine-tuning process. The domain-aware design is motivated by our observation\nthat during fine-tuning, the unconditional source model offers a stronger\nmarginal estimate than the target model. To support efficient controllable\nfidelity-diversity trade-offs at inference, we encode the guidance strength\nvalue as an additional model input through a lightweight conditioning\nmechanism. We further investigate the optimal placement and timing of the\nguidance offset during training and propose two simple scheduling strategies,\ni.e., late-start and cut-off, which improve generation quality and training\nstability. Experiments on DiT and SiT backbones across six diverse target\ndomains show that DogFit can outperform prior guidance methods in transfer\nlearning in terms of FID and FDDINOV2 while requiring up to 2x fewer sampling\nTFLOPS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDogFit\u7684\u9886\u57df\u5f15\u5bfc\u5fae\u8c03\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6269\u6563\u6a21\u578b\u8fc1\u79fb\u5b66\u4e60\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u53ef\u63a7\u6027\u6539\u8fdb\uff0c\u907f\u514d\u989d\u5916\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u5728\u5c0f\u578b\u76ee\u6807\u9886\u57df\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u5f15\u5bfc\u65b9\u6cd5\u867d\u80fd\u6539\u5584\u56fe\u50cf\u4fdd\u771f\u5ea6\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "DogFit\u901a\u8fc7\u5728\u8bad\u7ec3\u635f\u5931\u4e2d\u6ce8\u5165\u9886\u57df\u611f\u77e5\u5f15\u5bfc\u504f\u79fb\uff0c\u5185\u5316\u5f15\u5bfc\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6761\u4ef6\u673a\u5236\u7f16\u7801\u5f15\u5bfc\u5f3a\u5ea6\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u8c03\u5ea6\u7b56\u7565\uff08\u665a\u542f\u52a8\u548c\u622a\u65ad\uff09\u4f18\u5316\u751f\u6210\u8d28\u91cf\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u5728DiT\u548cSiT\u6846\u67b6\u7684\u516d\u4e2a\u76ee\u6807\u9886\u57df\u4e0a\uff0cDogFit\u5728FID\u548cFDDINOV2\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8ba1\u7b97\u5f00\u9500\u51cf\u5c112\u500d\u3002", "conclusion": "DogFit\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u63a7\u7684\u6269\u6563\u6a21\u578b\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2508.05923", "pdf": "https://arxiv.org/pdf/2508.05923", "abs": "https://arxiv.org/abs/2508.05923", "authors": ["Yanusha Mehendran", "Maolin Tang", "Yi Lu"], "title": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm", "categories": ["cs.SE", "cs.AI"], "comment": "26 Pages, 3 figures, 6 Tables, Submitted to Empirical Software\n  Engineering and it is under review", "summary": "Software vulnerabilities continue to undermine the reliability and security\nof modern systems, particularly as software complexity outpaces the\ncapabilities of traditional detection methods. This study introduces a genetic\nalgorithm-based method for test input generation that innovatively integrates\ngenetic operators and adaptive learning to enhance software vulnerability\ndetection. A key contribution is the application of the crossover operator,\nwhich facilitates exploration by searching across a broader space of potential\ntest inputs. Complementing this, an adaptive feedback mechanism continuously\nlearns from the system's execution behavior and dynamically guides input\ngeneration toward promising areas of the input space. Rather than relying on\nfixed or randomly selected inputs, the approach evolves a population of\nstructurally valid test cases using feedback-driven selection, enabling deeper\nand more effective code traversal. This strategic integration of exploration\nand exploitation ensures that both diverse and targeted test inputs are\ndeveloped over time. Evaluation was conducted across nine open-source\nJSON-processing libraries. The proposed method achieved substantial\nimprovements in coverage compared to a benchmark evolutionary fuzzing method,\nwith average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%\nin line coverage, 114.0% in instruction coverage, and 166.0% in branch\ncoverage. These results highlight the method's capacity to detect deeper and\nmore complex vulnerabilities, offering a scalable and adaptive solution to\nsoftware security testing.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u6d4b\u8bd5\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u878d\u5408\u9057\u4f20\u64cd\u4f5c\u548c\u81ea\u9002\u5e94\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u7684\u8986\u76d6\u7387\u3002", "motivation": "\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u65e5\u76ca\u590d\u6742\u7684\u8f6f\u4ef6\u7cfb\u7edf\u9700\u6c42\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u7684\u4ea4\u53c9\u64cd\u4f5c\u548c\u81ea\u9002\u5e94\u53cd\u9988\u673a\u5236\uff0c\u52a8\u6001\u751f\u6210\u7ed3\u6784\u6709\u6548\u7684\u6d4b\u8bd5\u8f93\u5165\uff0c\u4f18\u5316\u4ee3\u7801\u8986\u76d6\u7387\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90JSON\u5904\u7406\u5e93\u4e2d\u6d4b\u8bd5\uff0c\u8986\u76d6\u7387\u663e\u8457\u63d0\u5347\uff0c\u6700\u9ad8\u8fbe166%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8f6f\u4ef6\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u68c0\u6d4b\u66f4\u6df1\u5c42\u6b21\u548c\u590d\u6742\u7684\u6f0f\u6d1e\u3002"}}
{"id": "2508.06154", "pdf": "https://arxiv.org/pdf/2508.06154", "abs": "https://arxiv.org/abs/2508.06154", "authors": ["Xiaoxiong Zhang", "Xin Zhou", "Zhiwei Zeng", "Dusit Niyato", "Zhiqi Shen"], "title": "Semantic Item Graph Enhancement for Multimodal Recommendation", "categories": ["cs.IR", "cs.AI", "cs.MM"], "comment": null, "summary": "Multimodal recommendation systems have attracted increasing attention for\ntheir improved performance by leveraging items' multimodal information. Prior\nmethods often build modality-specific item-item semantic graphs from raw\nmodality features and use them as supplementary structures alongside the\nuser-item interaction graph to enhance user preference learning. However, these\nsemantic graphs suffer from semantic deficiencies, including (1) insufficient\nmodeling of collaborative signals among items and (2) structural distortions\nintroduced by noise in raw modality features, ultimately compromising\nperformance. To address these issues, we first extract collaborative signals\nfrom the interaction graph and infuse them into each modality-specific item\nsemantic graph to enhance semantic modeling. Then, we design a modulus-based\npersonalized embedding perturbation mechanism that injects perturbations with\nmodulus-guided personalized intensity into embeddings to generate contrastive\nviews. This enables the model to learn noise-robust representations through\ncontrastive learning, thereby reducing the effect of structural noise in\nsemantic graphs. Besides, we propose a dual representation alignment mechanism\nthat first aligns multiple semantic representations via a designed Anchor-based\nInfoNCE loss using behavior representations as anchors, and then aligns\nbehavior representations with the fused semantics by standard InfoNCE, to\nensure representation consistency. Extensive experiments on four benchmark\ndatasets validate the effectiveness of our framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u8bed\u4e49\u5efa\u6a21\u548c\u5bf9\u6bd4\u5b66\u4e60\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u8bed\u4e49\u4e0d\u8db3\u548c\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6784\u5efa\u6a21\u6001\u7279\u5b9a\u7684\u9879\u76ee\u8bed\u4e49\u56fe\u65f6\u5b58\u5728\u8bed\u4e49\u4e0d\u8db3\u548c\u566a\u58f0\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "\u901a\u8fc7\u534f\u4f5c\u4fe1\u53f7\u6ce8\u5165\u3001\u6a21\u6570\u6270\u52a8\u673a\u5236\u548c\u53cc\u91cd\u8868\u793a\u5bf9\u9f50\u673a\u5236\uff0c\u589e\u5f3a\u8bed\u4e49\u5efa\u6a21\u548c\u566a\u58f0\u9c81\u68d2\u6027\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u8350\u7684\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u590d\u6742\u573a\u666f\u3002"}}
{"id": "2508.06468", "pdf": "https://arxiv.org/pdf/2508.06468", "abs": "https://arxiv.org/abs/2508.06468", "authors": ["Jesutofunmi Ajayi", "Antonio Di Maio", "Torsten Braun", "Dimitrios Xenakis"], "title": "An Online Multi-dimensional Knapsack Approach for Slice Admission Control", "categories": ["cs.NI"], "comment": "Accepted by 20th Consumer Communications & Networking Conference\n  (CCNC)", "summary": "Network Slicing has emerged as a powerful technique to enable cost-effective,\nmulti-tenant communications and services over a shared physical mobile network\ninfrastructure. One major challenge of service provisioning in slice-enabled\nnetworks is the uncertainty in the demand for the limited network resources\nthat must be shared among existing slices and potentially new Network Slice\nRequests. In this paper, we consider admission control of Network Slice\nRequests in an online setting, with the goal of maximizing the long-term\nrevenue received from admitted requests. We model the Slice Admission Control\nproblem as an Online Multidimensional Knapsack Problem and present two\nreservation-based policies and their algorithms, which have a competitive\nperformance for Online Multidimensional Knapsack Problems. Through Monte Carlo\nsimulations, we evaluate the performance of our online admission control method\nin terms of average revenue gained by the Infrastructure Provider, system\nresource utilization, and the ratio of accepted slice requests. We compare our\napproach with those of the online First Come First Serve greedy policy. The\nsimulation's results prove that our proposed online policies increase revenues\nfor Infrastructure Providers by up to 12.9 % while reducing the average\nresource consumption by up to 1.7% In particular, when the tenants' economic\ninequality increases, an Infrastructure Provider who adopts our proposed online\nadmission policies gains higher revenues compared to an Infrastructure Provider\nwho adopts First Come First Serve.", "AI": {"tldr": "\u5207\u7247\u7f51\u7edc\u4e2d\u7684\u5728\u7ebf\u5207\u7247\u8bf7\u6c42\u51c6\u5165\u63a7\u5236\uff0c\u901a\u8fc7\u591a\u7ef4\u80cc\u5305\u95ee\u9898\u548c\u9884\u7559\u7b56\u7565\u6700\u5927\u5316\u957f\u671f\u6536\u5165\uff0c\u76f8\u6bd4\u5148\u5230\u5148\u670d\u52a1\u7b56\u7565\u63d0\u5347\u6536\u5165\u5e76\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u89e3\u51b3\u5207\u7247\u7f51\u7edc\u4e2d\u8d44\u6e90\u9700\u6c42\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u65e8\u5728\u4e3a\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u5546\u6700\u5927\u5316\u957f\u671f\u6536\u5165\u3002", "method": "\u5efa\u6a21\u4e3a\u5728\u7ebf\u591a\u7ef4\u80cc\u5305\u95ee\u9898\uff0c\u63d0\u51fa\u4e24\u79cd\u9884\u7559\u7b56\u7565\u7b97\u6cd5\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u6536\u5165\u63d0\u534712.9%\uff0c\u8d44\u6e90\u6d88\u8017\u964d\u4f4e1.7%\uff0c\u7ecf\u6d4e\u4e0d\u5e73\u7b49\u65f6\u6536\u76ca\u66f4\u9ad8\u3002", "conclusion": "\u9884\u7559\u7b56\u7565\u4f18\u4e8e\u5148\u5230\u5148\u670d\u52a1\uff0c\u4e3a\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u5546\u5e26\u6765\u66f4\u9ad8\u6536\u76ca\u548c\u8d44\u6e90\u6548\u7387\u3002"}}
{"id": "2508.05999", "pdf": "https://arxiv.org/pdf/2508.05999", "abs": "https://arxiv.org/abs/2508.05999", "authors": ["Sergio Rojas-Galeano", "Julian Tejada", "Fernando Marmolejo-Ramos"], "title": "Between Tool and Trouble: Student Attitudes Toward AI in Programming Education", "categories": ["cs.ET"], "comment": "arXiv admin note: substantial text overlap with arXiv:2507.22900", "summary": "This study examines how AI code assistants shape novice programmers\nexperiences during a two-part exam in an introductory programming course. In\nthe first part, students completed a programming task with access to AI\nsupport; in the second, they extended their solutions without AI. We collected\nLikert-scale and open-ended responses from 20 students to evaluate their\nperceptions and challenges. Findings suggest that AI tools were perceived as\nhelpful for understanding code and increasing confidence, particularly during\ninitial development. However, students reported difficulties transferring\nknowledge to unaided tasks, revealing possible overreliance and gaps in\nconceptual understanding. These insights highlight the need for pedagogical\nstrategies that integrate AI meaningfully while reinforcing foundational\nprogramming skills.", "AI": {"tldr": "\u7814\u7a76AI\u4ee3\u7801\u52a9\u624b\u5982\u4f55\u5f71\u54cd\u65b0\u624b\u7a0b\u5e8f\u5458\u5728\u8003\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u4e3aAI\u8f85\u52a9\u548c\u65e0AI\u8f85\u52a9\u4e24\u90e8\u5206\uff0c\u53d1\u73b0AI\u5de5\u5177\u867d\u80fd\u63d0\u5347\u4fe1\u5fc3\u4f46\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\u3002", "motivation": "\u63a2\u8ba8AI\u5de5\u5177\u5bf9\u65b0\u624b\u7a0b\u5e8f\u5458\u5b66\u4e60\u7684\u5f71\u54cd\u53ca\u5176\u6f5c\u5728\u7684\u6559\u80b2\u7b56\u7565\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5728\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\u8bbe\u7f6e\u4e24\u9636\u6bb5\u8003\u8bd5\uff08\u6709AI\u8f85\u52a9\u548c\u65e0AI\u8f85\u52a9\uff09\uff0c\u6536\u96c620\u540d\u5b66\u751f\u7684\u8bc4\u5206\u548c\u5f00\u653e\u5f0f\u53cd\u9988\u3002", "result": "\u5b66\u751f\u8ba4\u4e3aAI\u5de5\u5177\u6709\u52a9\u4e8e\u7406\u89e3\u4ee3\u7801\u548c\u63d0\u5347\u4fe1\u5fc3\uff0c\u4f46\u5728\u65e0AI\u8f85\u52a9\u65f6\u8868\u73b0\u51fa\u77e5\u8bc6\u8fc1\u79fb\u56f0\u96be\u3002", "conclusion": "\u9700\u7ed3\u5408AI\u5de5\u5177\u4e0e\u57fa\u7840\u7f16\u7a0b\u6280\u80fd\u7684\u6559\u5b66\u7b56\u7565\uff0c\u907f\u514d\u5b66\u751f\u5bf9AI\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002"}}
{"id": "2508.05646", "pdf": "https://arxiv.org/pdf/2508.05646", "abs": "https://arxiv.org/abs/2508.05646", "authors": ["Thomas Sievers"], "title": "A Humanoid Social Robot as a Teaching Assistant in the Classroom", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Although innovation and the support of new technologies are much needed to\nease the burden on the education system, social robots in schools to help\nteachers with educational tasks are rare. Child-Robot Interaction (CRI) could\nsupport teachers and add an embodied social component to modern multi-modal and\nmulti-sensory learning environments already in use. The social robot Pepper,\nconnected to the Large Language Model (LLM) ChatGPT, was used in a high school\nclassroom to teach new learning content to groups of students. I tested the\ntechnical possibilities with the robot on site and asked the students about\ntheir acceptance and perceived usefulness of teaching with the help of a social\nrobot. All participants felt that the robot's presentation of the learning\nmaterial was appropriate or at least partially appropriate and that its use\nmade sense.", "AI": {"tldr": "\u793e\u4ea4\u673a\u5668\u4ebaPepper\u7ed3\u5408ChatGPT\u5728\u9ad8\u4e2d\u8bfe\u5802\u6559\u6388\u65b0\u5185\u5bb9\uff0c\u5b66\u751f\u5bf9\u5176\u63a5\u53d7\u5ea6\u548c\u5b9e\u7528\u6027\u6301\u79ef\u6781\u6001\u5ea6\u3002", "motivation": "\u901a\u8fc7\u793e\u4ea4\u673a\u5668\u4eba\u8f85\u52a9\u6559\u5b66\uff0c\u51cf\u8f7b\u6559\u80b2\u7cfb\u7edf\u8d1f\u62c5\uff0c\u589e\u52a0\u73b0\u4ee3\u591a\u6a21\u6001\u5b66\u4e60\u73af\u5883\u7684\u793e\u4f1a\u4e92\u52a8\u6027\u3002", "method": "\u4f7f\u7528Pepper\u673a\u5668\u4eba\u8fde\u63a5ChatGPT\uff0c\u5728\u9ad8\u4e2d\u8bfe\u5802\u4e0a\u6559\u6388\u65b0\u5185\u5bb9\uff0c\u5e76\u8c03\u67e5\u5b66\u751f\u7684\u63a5\u53d7\u5ea6\u548c\u5b9e\u7528\u6027\u53cd\u9988\u3002", "result": "\u6240\u6709\u53c2\u4e0e\u8005\u8ba4\u4e3a\u673a\u5668\u4eba\u5c55\u793a\u5b66\u4e60\u5185\u5bb9\u5408\u9002\u6216\u90e8\u5206\u5408\u9002\uff0c\u4e14\u5176\u4f7f\u7528\u6709\u610f\u4e49\u3002", "conclusion": "\u793e\u4ea4\u673a\u5668\u4eba\u5728\u6559\u80b2\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u4e3a\u5b66\u751f\u63d0\u4f9b\u65b0\u7684\u5b66\u4e60\u4f53\u9a8c\u3002"}}
{"id": "2508.05821", "pdf": "https://arxiv.org/pdf/2508.05821", "abs": "https://arxiv.org/abs/2508.05821", "authors": ["Shadman Sakib", "Ajay Katangur", "Rahul Dubey"], "title": "A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization", "categories": ["cs.DC"], "comment": "Accepted for publication in 2025 IEEE Cloud Summit", "summary": "Cloud computing has grown rapidly in recent years, mainly due to the sharp\nincrease in data transferred over the internet. This growth makes load\nbalancing a key part of cloud systems, as it helps distribute user requests\nacross servers to maintain performance, prevent overload, and ensure a smooth\nuser experience. Despite its importance, managing server resources and keeping\nworkloads balanced over time remains a major challenge in cloud environments.\nThis paper introduces a novel Score-Based Dynamic Load Balancer (SBDLB) that\nallocates workloads to virtual machines based on real-time performance metrics.\nThe objective is to enhance resource utilization and overall system efficiency.\nThe method was thoroughly tested using the CloudSim 7G platform, comparing its\nperformance against the throttled load balancing strategy. Evaluations were\nconducted across a variety of workloads and scenarios, demonstrating the\nSBDLB's ability to adapt dynamically to workload fluctuations while optimizing\nresource usage. The proposed method outperformed the throttled strategy,\nimproving average response times by 34% and 37% in different scenarios. It also\nreduced data center processing times by an average of 13%. Over a 24-hour\nsimulation, the method decreased operational costs by 15%, promoting a more\nenergy-efficient and sustainable cloud infrastructure through reduced energy\nconsumption.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b9e\u65f6\u6027\u80fd\u6307\u6807\u7684Score-Based Dynamic Load Balancer (SBDLB)\uff0c\u7528\u4e8e\u4f18\u5316\u4e91\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u4e91\u8ba1\u7b97\u5feb\u901f\u53d1\u5c55\u4f7f\u5f97\u8d1f\u8f7d\u5747\u8861\u6210\u4e3a\u5173\u952e\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u52a8\u6001\u9002\u5e94\u5de5\u4f5c\u91cf\u6ce2\u52a8\u3002", "method": "\u63d0\u51faSBDLB\uff0c\u57fa\u4e8e\u5b9e\u65f6\u6027\u80fd\u6307\u6807\u5206\u914d\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u5728CloudSim 7G\u5e73\u53f0\u4e0a\u6d4b\u8bd5\u5bf9\u6bd4\u3002", "result": "SBDLB\u5728\u54cd\u5e94\u65f6\u95f4\u3001\u6570\u636e\u5904\u7406\u65f6\u95f4\u548c\u8fd0\u884c\u6210\u672c\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u63d0\u5347\u4e8634%\u7684\u54cd\u5e94\u65f6\u95f4\u548c13%\u7684\u6570\u636e\u5904\u7406\u65f6\u95f4\u3002", "conclusion": "SBDLB\u80fd\u52a8\u6001\u4f18\u5316\u4e91\u57fa\u7840\u8bbe\u65bd\u7684\u8d44\u6e90\u5229\u7528\uff0c\u540c\u65f6\u964d\u4f4e\u80fd\u8017\uff0c\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2508.06047", "pdf": "https://arxiv.org/pdf/2508.06047", "abs": "https://arxiv.org/abs/2508.06047", "authors": ["Suresh Purini", "Siddhant Garg", "Mudit Gaur", "Sankalp Bhat", "Sohan Mupparapu", "Arun Ravindran"], "title": "ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis", "categories": ["cs.AR"], "comment": "Published in 7th ACM/IEEE International Symposium on Machine Learning\n  for CAD", "summary": "Modern SoC datapaths include deeply pipelined, domain-specific accelerators,\nbut their RTL implementation and verification are still mostly done by hand.\nWhile large language models (LLMs) exhibit advanced code-generation abilities\nfor programming languages like Python, their application to Verilog-like RTL\nremains in its nascent stage. This is reflected in the simple arithmetic and\ncontrol circuits currently used to evaluate generative capabilities in existing\nbenchmarks. In this paper, we introduce ArchXBench, a six-level benchmark suite\nthat encompasses complex arithmetic circuits and other advanced digital\nsubsystems drawn from domains such as cryptography, image processing, machine\nlearning, and signal processing. Architecturally, some of these designs are\npurely combinational, others are multi-cycle or pipelined, and many require\nhierarchical composition of modules. For each benchmark, we provide a problem\ndescription, design specification, and testbench, enabling rapid research in\nthe area of LLM-driven agentic approaches for complex digital systems design.\n  Using zero-shot prompting with Claude Sonnet 4, GPT 4.1, o4-mini-high, and\nDeepSeek R1 under a pass@5 criterion, we observed that o4-mini-high\nsuccessfully solves the largest number of benchmarks, 16 out of 30, spanning\nLevels 1, 2, and 3. From Level 4 onward, however, all models consistently fail,\nhighlighting a clear gap in the capabilities of current state-of-the-art LLMs\nand prompting/agentic approaches.", "AI": {"tldr": "ArchXBench\u662f\u4e00\u4e2a\u516d\u5c42\u7ea7\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u590d\u6742\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u751f\u6210\u80fd\u529b\u3002\u73b0\u6709LLM\u5728\u7b80\u5355\u7535\u8def\u4e0a\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u590d\u6742\u8bbe\u8ba1\uff08\u5982\u591a\u5468\u671f\u6216\u6d41\u6c34\u7ebf\u7ed3\u6784\uff09\u4e2d\u4ecd\u6709\u660e\u663e\u5c40\u9650\u3002", "motivation": "\u73b0\u6709LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u9886\u57df\u7684\u5e94\u7528\u4ecd\u5904\u4e8e\u521d\u7ea7\u9636\u6bb5\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u7535\u8def\u548c\u9ad8\u7ea7\u5b50\u7cfb\u7edf\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u9a8c\u8bc1\u3002ArchXBench\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u516d\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6ArchXBench\uff0c\u6db5\u76d6\u4ece\u7b80\u5355\u5230\u590d\u6742\u7684\u7535\u8def\u8bbe\u8ba1\u4efb\u52a1\uff0c\u5e76\u4f7f\u7528\u591a\u79cdLLM\u8fdb\u884c\u96f6\u6837\u672c\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5176\u751f\u6210\u80fd\u529b\u3002", "result": "\u5728\u96f6\u6837\u672c\u6d4b\u8bd5\u4e2d\uff0co4-mini-high\u572830\u4e2a\u57fa\u51c6\u4e2d\u6210\u529f\u89e3\u51b3\u4e8616\u4e2a\uff08\u4e3b\u8981\u6765\u81ea\u524d\u4e09\u7ea7\uff09\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u66f4\u9ad8\u5c42\u7ea7\uff084\u7ea7\u53ca\u4ee5\u4e0a\uff09\u7684\u4efb\u52a1\u4e2d\u90fd\u5931\u8d25\u4e86\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u590d\u6742\u786c\u4ef6\u8bbe\u8ba1\u9886\u57df\u7684\u751f\u6210\u80fd\u529b\u4ecd\u6709\u9650\uff0c\u5c24\u5176\u662f\u5728\u591a\u5468\u671f\u548c\u6d41\u6c34\u7ebf\u8bbe\u8ba1\u65b9\u9762\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\u3002"}}
{"id": "2508.05690", "pdf": "https://arxiv.org/pdf/2508.05690", "abs": "https://arxiv.org/abs/2508.05690", "authors": ["Meital Shlezinger", "Shay Akirav", "Lei Zhou", "Liang Guo", "Avi Kessel", "Guoliang Li"], "title": "Leveraging large language models for SQL behavior-based database intrusion detection", "categories": ["cs.CR", "cs.DB", "cs.LG"], "comment": null, "summary": "Database systems are extensively used to store critical data across various\ndomains. However, the frequency of abnormal database access behaviors, such as\ndatabase intrusion by internal and external attacks, continues to rise.\nInternal masqueraders often have greater organizational knowledge, making it\neasier to mimic employee behavior effectively. In contrast, external\nmasqueraders may behave differently due to their lack of familiarity with the\norganization. Current approaches lack the granularity needed to detect\nanomalies at the operational level, frequently misclassifying entire sequences\nof operations as anomalies, even though most operations are likely to represent\nnormal behavior. On the other hand, some anomalous behaviors often resemble\nnormal activities, making them difficult for existing detection methods to\nidentify. This paper introduces a two-tiered anomaly detection approach for\nStructured Query Language (SQL) using the Bidirectional Encoder Representations\nfrom Transformers (BERT) model, specifically DistilBERT, a more efficient,\npre-trained version. Our method combines both unsupervised and supervised\nmachine learning techniques to accurately identify anomalous activities while\nminimizing the need for data labeling. First, the unsupervised method uses\nensemble anomaly detectors that flag embedding vectors distant from learned\nnormal patterns of typical user behavior across the database (out-of-scope\nqueries). Second, the supervised method uses fine-tuned transformer-based\nmodels to detect internal attacks with high precision (in-scope queries), using\nrole-labeled classification, even on limited labeled SQL data. Our findings\nmake a significant contribution by providing an effective solution for\nsafeguarding critical database systems from sophisticated threats.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDistilBERT\u7684\u4e24\u5c42\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u548c\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u6709\u6548\u8bc6\u522bSQL\u6570\u636e\u5e93\u4e2d\u7684\u5f02\u5e38\u884c\u4e3a\uff0c\u4fdd\u62a4\u5173\u952e\u6570\u636e\u514d\u53d7\u5185\u90e8\u548c\u5916\u90e8\u653b\u51fb\u3002", "motivation": "\u6570\u636e\u5e93\u7cfb\u7edf\u5e7f\u6cdb\u7528\u4e8e\u5b58\u50a8\u5173\u952e\u6570\u636e\uff0c\u4f46\u5f02\u5e38\u8bbf\u95ee\u884c\u4e3a\uff08\u5982\u5185\u90e8\u548c\u5916\u90e8\u653b\u51fb\uff09\u65e5\u76ca\u589e\u591a\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u68c0\u6d4b\u80fd\u529b\uff0c\u5e38\u8bef\u5224\u6216\u6f0f\u5224\u5f02\u5e38\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u4e24\u5c42\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff1a1) \u65e0\u76d1\u7763\u65b9\u6cd5\u4f7f\u7528\u96c6\u6210\u5f02\u5e38\u68c0\u6d4b\u5668\u6807\u8bb0\u504f\u79bb\u6b63\u5e38\u7528\u6237\u884c\u4e3a\u7684\u67e5\u8be2\uff08\u8303\u56f4\u5916\u67e5\u8be2\uff09\uff1b2) \u76d1\u7763\u65b9\u6cd5\u901a\u8fc7\u5fae\u8c03\u7684Transformer\u6a21\u578b\uff08\u5982DistilBERT\uff09\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u5185\u90e8\u653b\u51fb\uff08\u8303\u56f4\u5185\u67e5\u8be2\uff09\uff0c\u5373\u4f7f\u6807\u6ce8\u6570\u636e\u6709\u9650\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5bf9\u6570\u636e\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u4e3a\u4fdd\u62a4\u5173\u952e\u6570\u636e\u5e93\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u65e0\u76d1\u7763\u548c\u76d1\u7763\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u7684\u590d\u6742\u5a01\u80c1\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5185\u90e8\u653b\u51fb\u68c0\u6d4b\u3002"}}
{"id": "2508.06086", "pdf": "https://arxiv.org/pdf/2508.06086", "abs": "https://arxiv.org/abs/2508.06086", "authors": ["Kojiro Tanaka", "Keiichi Sato", "Masahiko Mikawa", "Makoto Fujisawa"], "title": "Exploring Interactive Simulation of Grass Display Color Characteristic Based on Real-World Conditions", "categories": ["cs.GR", "cs.HC"], "comment": "Accepted to 20th IFIP TC13 International Conference on Human-Computer\n  Interaction (INTERACT '25), 24 pages", "summary": "Recent research has focused on incorporating media into living environments\nvia color-controlled materials and image display. In particular, grass-based\ndisplays have drawn attention as landscape-friendly interactive interfaces. To\ndevelop the grass display, it is important to obtain the grass color change\ncharacteristics that depend on the real environment. However, conventional\nmethods require experiments on actual equipment every time the lighting or\nviewpoint changes, which is time-consuming and costly. Although research has\nbegun on simulating grass colors, this approach still faces significant issues\nas it takes many hours for a single measurement. In this paper, we explore an\ninteractive simulation of a grass display color change characteristic based on\nreal-world conditions in a virtual environment. We evaluated our method's\naccuracy by simulating grass color characteristics across multiple viewpoints\nand environments, and then compared the results against prior work. The results\nindicated that our method tended to simulate the grass color characteristics\nsimilar to the actual characteristics and showed the potential to do so more\nquickly and with comparable accuracy to the previous study.", "AI": {"tldr": "\u901a\u8fc7\u865a\u62df\u73af\u5883\u6a21\u62df\u8349\u57fa\u663e\u793a\u7684\u989c\u8272\u53d8\u5316\u7279\u6027\uff0c\u4ee5\u51cf\u5c11\u5b9e\u9645\u5b9e\u9a8c\u7684\u65f6\u95f4\u548c\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u6bcf\u6b21\u5149\u7167\u6216\u89c6\u89d2\u53d8\u5316\u65f6\u8fdb\u884c\u5b9e\u9645\u5b9e\u9a8c\uff0c\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u3002\u865a\u62df\u6a21\u62df\u867d\u5f00\u59cb\u7814\u7a76\uff0c\u4f46\u4ecd\u6709\u8017\u65f6\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4ea4\u4e92\u5f0f\u6a21\u62df\u65b9\u6cd5\uff0c\u57fa\u4e8e\u865a\u62df\u73af\u5883\u6a21\u62df\u8349\u7684\u989c\u8272\u53d8\u5316\u7279\u6027\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u4e0e\u771f\u5b9e\u8349\u8272\u7279\u6027\u76f8\u4f3c\uff0c\u4e14\u901f\u5ea6\u66f4\u5feb\uff0c\u51c6\u786e\u6027\u63a5\u8fd1\u5148\u524d\u7814\u7a76\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4e3a\u8349\u57fa\u663e\u793a\u7684\u5f00\u53d1\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u6a21\u62df\u5de5\u5177\u3002"}}
{"id": "2508.05949", "pdf": "https://arxiv.org/pdf/2508.05949", "abs": "https://arxiv.org/abs/2508.05949", "authors": ["Jialin Yang", "Zainab Saad", "Jiajun Wu", "Xiaoguang Niu", "Henry Leung", "Steve Drew"], "title": "A Survey on Task Scheduling in Carbon-Aware Container Orchestration", "categories": ["cs.SE"], "comment": "Submitted to ACM Computing Surveys", "summary": "The soaring energy demands of large-scale software ecosystems and cloud data\ncenters, accelerated by the intensive training and deployment of large language\nmodels, have driven energy consumption and carbon footprint to unprecedented\nlevels. In response, both industry and academia are increasing efforts to\nreduce the carbon emissions associated with cloud computing through more\nefficient task scheduling and infrastructure orchestration. In this work, we\npresent a systematic review of various Kubernetes scheduling strategies,\ncategorizing them into hardware-centric and software-centric, annotating each\nwith its sustainability objectives, and grouping them according to the\nalgorithms they use. We propose a comprehensive taxonomy for cloud task\nscheduling studies, with a particular focus on the environmental sustainability\naspect. We analyze emerging research trends and open challenges, and our\nfindings provide critical insight into the design of sustainable scheduling\nsolutions for next-generation cloud computing systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86Kubernetes\u8c03\u5ea6\u7b56\u7565\u53ca\u5176\u5bf9\u4e91\u8ba1\u7b97\u7684\u53ef\u6301\u7eed\u6027\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u5206\u7c7b\u548c\u6311\u6218\u3002", "motivation": "\u7531\u4e8e\u4e91\u8ba1\u7b97\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u5bfc\u81f4\u7684\u9ad8\u80fd\u8017\u95ee\u9898\uff0c\u9700\u4f18\u5316\u8c03\u5ea6\u4ee5\u51cf\u5c11\u78b3\u6392\u653e\u3002", "method": "\u7cfb\u7edf\u56de\u987eKubernetes\u8c03\u5ea6\u7b56\u7565\uff0c\u5206\u4e3a\u786c\u4ef6\u548c\u8f6f\u4ef6\u4e3a\u4e2d\u5fc3\uff0c\u5206\u7c7b\u5e76\u5206\u6790\u53ef\u6301\u7eed\u6027\u76ee\u6807\u3002", "result": "\u63d0\u51fa\u4e86\u7528\u4e8e\u4e91\u4efb\u52a1\u8c03\u5ea6\u7684\u5206\u7c7b\u6cd5\uff0c\u8bc6\u522b\u4e86\u7814\u7a76\u8d8b\u52bf\u4e0e\u6311\u6218\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3\u53ef\u6301\u7eed\u4e91\u8ba1\u7b97\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u601d\u8def\u548c\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2508.06062", "pdf": "https://arxiv.org/pdf/2508.06062", "abs": "https://arxiv.org/abs/2508.06062", "authors": ["Evgenii E. Vityaev", "Andrei Mantsivoda"], "title": "Don't Forget Imagination!", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 68T30"], "comment": "14 pages, 2 figures", "summary": "Cognitive imagination is a type of imagination that plays a key role in human\nthinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to\nmentally visualize coherent and holistic systems of concepts and causal links\nthat serve as semantic contexts for reasoning, decision making and prediction.\nOur position is that the role of cognitive imagination is still greatly\nunderestimated, and this creates numerous problems and diminishes the current\ncapabilities of AI. For instance, when reasoning, humans rely on imaginary\ncontexts to retrieve background info. They also constantly return to the\ncontext for semantic verification that their reasoning is still reasonable.\nThus, reasoning without imagination is blind. This paper is a call for greater\nattention to cognitive imagination as the next promising breakthrough in\nartificial intelligence. As an instrument for simulating cognitive imagination,\nwe propose semantic models -- a new approach to mathematical models that can\nlearn, like neural networks, and are based on probabilistic causal\nrelationships. Semantic models can simulate cognitive imagination because they\nensure the consistency of imaginary contexts and implement a glass-box approach\nthat allows the context to be manipulated as a holistic and coherent system of\ninterrelated facts glued together with causal relations.", "AI": {"tldr": "\u8bba\u6587\u547c\u5401\u66f4\u591a\u5173\u6ce8\u8ba4\u77e5\u60f3\u8c61\u529b\uff0c\u8ba4\u4e3a\u8fd9\u662f\u4eba\u5de5\u667a\u80fd\u7684\u4e0b\u4e00\u7a81\u7834\u70b9\uff0c\u5e76\u63d0\u51fa\u8bed\u4e49\u6a21\u578b\u4f5c\u4e3a\u6a21\u62df\u5de5\u5177\u3002", "motivation": "\u8ba4\u77e5\u60f3\u8c61\u529b\u5728\u4eba\u7c7b\u601d\u7ef4\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5f53\u524dAI\u9886\u57df\u5bf9\u5176\u91cd\u89c6\u4e0d\u8db3\uff0c\u9650\u5236\u4e86AI\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u6a21\u578b\uff0c\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u56e0\u679c\u5173\u7cfb\u7684\u6570\u5b66\u6a21\u578b\uff0c\u7528\u4e8e\u6a21\u62df\u8ba4\u77e5\u60f3\u8c61\u529b\u3002", "result": "\u8bed\u4e49\u6a21\u578b\u80fd\u786e\u4fdd\u60f3\u8c61\u8bed\u5883\u7684\u8fde\u8d2f\u6027\uff0c\u5b9e\u73b0\u900f\u660e\u64cd\u4f5c\u3002", "conclusion": "\u8ba4\u77e5\u60f3\u8c61\u529b\u7684\u7814\u7a76\u662fAI\u53d1\u5c55\u7684\u91cd\u8981\u65b9\u5411\uff0c\u8bed\u4e49\u6a21\u578b\u4e3a\u6a21\u62df\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.05655", "pdf": "https://arxiv.org/pdf/2508.05655", "abs": "https://arxiv.org/abs/2508.05655", "authors": ["Guang Yang", "Peter Trinh", "Alma Nkemla", "Amuru Serikyaku", "Edward Tatchim", "Osman Sharaf"], "title": "Blockchain-Based Decentralized Domain Name System", "categories": ["cs.CR", "cs.NI"], "comment": null, "summary": "The current Domain Name System (DNS) infrastructure faces critical\nvulnerabilities including poisoning attacks, censorship mechanisms, and\ncentralized points of failure that compromise internet freedom and security.\nRecent incidents such as DNS poisoning attacks on ISP customers highlight the\nurgent need for resilient alternatives. This paper presents a novel\nblockchain-based Decentralized Domain Name System (DDNS). We designed a\nspecialized Proof-of-Work blockchain to maximize support for DNS-related\nprotocols and achieve node decentralization. The system integrates our\nblockchain with IPFS for distributed storage, implements cryptographic\nprimitives for end-to-end trust signatures, and achieves Never Trust, Always\nVerify zero-trust verification. Our implementation achieves 15-second domain\nrecord propagation times, supports 20 standard DNS record types, and provides\nperpetual free .ddns domains. The system has been deployed across distributed\ninfrastructure in San Jose, Los Angeles, and Orange County, demonstrating\npractical scalability and resistance to traditional DNS manipulation\ntechniques. Performance evaluation shows the system can handle up to Max Theor.\nTPS 1,111.1 tx/s (minimal transactions) and Max Theor. TPS 266.7 tx/s (regular\ntransactions) for domain operations while maintaining sub-second query\nresolution through intelligent caching mechanisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u57df\u540d\u7cfb\u7edf\uff08DDNS\uff09\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edfDNS\u5b89\u5168\u6f0f\u6d1e\u548c\u4e2d\u5fc3\u5316\u95ee\u9898\uff0c\u91c7\u7528PoW\u533a\u5757\u94fe\u548cIPFS\u5b58\u50a8\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u4f20\u64ad\u548c\u6297\u64cd\u7eb5\u6027\u3002", "motivation": "\u4f20\u7edfDNS\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3001\u5ba1\u67e5\u673a\u5236\u548c\u4e2d\u5fc3\u5316\u95ee\u9898\uff0c\u5a01\u80c1\u4e92\u8054\u7f51\u81ea\u7531\u548c\u5b89\u5168\uff0c\u4e9f\u9700\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u652f\u6301DNS\u534f\u8bae\u7684PoW\u533a\u5757\u94fe\uff0c\u7ed3\u5408IPFS\u5206\u5e03\u5f0f\u5b58\u50a8\uff0c\u91c7\u7528\u52a0\u5bc6\u539f\u8bed\u5b9e\u73b0\u96f6\u4fe1\u4efb\u9a8c\u8bc1\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e8615\u79d2\u57df\u540d\u8bb0\u5f55\u4f20\u64ad\u3001\u652f\u630120\u79cd\u6807\u51c6DNS\u8bb0\u5f55\u7c7b\u578b\uff0c\u6027\u80fd\u53ef\u8fbe1111.1 tx/s\uff08\u6700\u5c0f\u4e8b\u52a1\uff09\u548c266.7 tx/s\uff08\u5e38\u89c4\u4e8b\u52a1\uff09\u3002", "conclusion": "DDNS\u5c55\u793a\u4e86\u53bb\u4e2d\u5fc3\u5316DNS\u7684\u53ef\u884c\u6027\u548c\u9ad8\u6027\u80fd\u7279\u6027\uff0c\u80fd\u6709\u6548\u62b5\u6297\u4f20\u7edfDNS\u64cd\u7eb5\u6280\u672f\u3002"}}
{"id": "2508.05653", "pdf": "https://arxiv.org/pdf/2508.05653", "abs": "https://arxiv.org/abs/2508.05653", "authors": ["Jules Clerc", "Domitile Lourdeaux", "Mohamed Sallak", "Johann Barbier", "Marc Ravaine"], "title": "Modeling Interactive Narrative Systems: A Formal Approach", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Interactive Narrative Systems (INS) have revolutionized digital experiences\nby empowering users to actively shape their stories, diverging from traditional\npassive storytelling. However, the field faces challenges due to fragmented\nresearch efforts and diverse system representations. This paper introduces a\nformal representation framework for INS, inspired by diverse approaches from\nthe state of the art. By providing a consistent vocabulary and modeling\nstructure, the framework facilitates the analysis, the description and\ncomparison of INS properties. Experimental validations on the \"Little Red\nRiding Hood\" scenario highlight the usefulness of the proposed formalism and\nits impact on improving the evaluation of INS. This work aims to foster\ncollaboration and coherence within the INS research community by proposing a\nmethodology for formally representing these systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53d9\u4e8b\u7cfb\u7edf\uff08INS\uff09\u7684\u5f62\u5f0f\u5316\u8868\u793a\u6846\u67b6\uff0c\u65e8\u5728\u7edf\u4e00\u7814\u7a76\u9886\u57df\u5e76\u4fc3\u8fdb\u7cfb\u7edf\u5206\u6790\u3001\u63cf\u8ff0\u548c\u6bd4\u8f83\u3002", "motivation": "\u4ea4\u4e92\u5f0f\u53d9\u4e8b\u7cfb\u7edf\u5728\u6570\u5b57\u4f53\u9a8c\u4e2d\u5177\u6709\u9769\u547d\u6027\u610f\u4e49\uff0c\u4f46\u7814\u7a76\u5206\u6563\u4e14\u7cfb\u7edf\u8868\u793a\u591a\u6837\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u4fc3\u8fdb\u5206\u6790\u548c\u6bd4\u8f83\u3002", "method": "\u8bba\u6587\u4ece\u73b0\u6709\u65b9\u6cd5\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u8868\u793a\u6846\u67b6\uff0c\u5e76\u901a\u8fc7'\u5c0f\u7ea2\u5e3d'\u573a\u666f\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u5f62\u5f0f\u5316\u6846\u67b6\u6709\u52a9\u4e8e\u63d0\u5347INS\u7684\u8bc4\u4f30\u6548\u679c\uff0c\u5e76\u4fc3\u8fdb\u4e86\u7814\u7a76\u793e\u533a\u7684\u534f\u4f5c\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aINS\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8bcd\u6c47\u548c\u5efa\u6a21\u7ed3\u6784\uff0c\u6709\u671b\u63a8\u52a8\u8be5\u9886\u57df\u7684\u534f\u4f5c\u4e0e\u8fdb\u6b65\u3002"}}
{"id": "2508.05904", "pdf": "https://arxiv.org/pdf/2508.05904", "abs": "https://arxiv.org/abs/2508.05904", "authors": ["Brandon Baker", "Elliott Brossard", "Chenwei Xie", "Zihao Ye", "Deen Liu", "Yijun Xie", "Arthur Zwiegincew", "Nitya Kumar Sharma", "Gaurav Jain", "Eugene Retunsky", "Mike Halcrow", "Derek Denny-Brown", "Istvan Cseri", "Tyler Akidau", "Yuxiong He"], "title": "Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data", "categories": ["cs.DC", "cs.DB"], "comment": "12 pages, 6 figures, accepted in ICDCS 2025", "summary": "Snowflake revolutionized data analytics with an elastic architecture that\ndecouples compute and storage, enabling scalable solutions supporting data\narchitectures like data lake, data warehouse, data lakehouse, and data mesh.\nBuilding on this foundation, Snowflake has advanced its AI Data Cloud vision by\nintroducing Snowpark, a managed turnkey solution that supports data engineering\nand AI and ML workloads using Python and other programming languages.\n  This paper outlines Snowpark's design objectives towards high performance,\nstrong security and governance, and ease of use. We detail the architecture of\nSnowpark, highlighting its elastic scalability and seamless integration with\nSnowflake core compute infrastructure. This includes leveraging Snowflake\ncontrol plane for distributed computing and employing a secure sandbox for\nisolating Snowflake SQL workloads from Snowpark executions. Additionally, we\npresent core innovations in Snowpark that drive further performance\nenhancements, such as query initialization latency reduction through Python\npackage caching, improved workload scheduling for customized workloads, and\ndata skew management via efficient row redistribution. Finally, we showcase\nreal-world case studies that illustrate Snowpark's efficiency and effectiveness\nfor large-scale data engineering and AI and ML tasks.", "AI": {"tldr": "Snowpark\u662fSnowflake\u63a8\u51fa\u7684\u4e00\u6b3e\u652f\u6301\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u5de5\u4f5c\u8d1f\u8f7d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u5907\u9ad8\u6027\u80fd\u3001\u5f3a\u5b89\u5168\u6027\u548c\u6613\u7528\u6027\uff0c\u901a\u8fc7\u5f39\u6027\u6269\u5c55\u548c\u65e0\u7f1d\u96c6\u6210\u63d0\u5347\u6570\u636e\u5904\u7406\u6548\u7387\u3002", "motivation": "Snowflake\u65e8\u5728\u6269\u5c55\u5176AI Data Cloud\u613f\u666f\uff0c\u652f\u6301\u591a\u8bed\u8a00\u7f16\u7a0b\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u5de5\u4f5c\u8d1f\u8f7d\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u76ee\u6807\u5305\u62ec\u9ad8\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u6613\u7528\u6027\uff0c\u67b6\u6784\u4e0a\u91c7\u7528\u5f39\u6027\u6269\u5c55\u548c\u4e0eSnowflake\u6838\u5fc3\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u5e76\u901a\u8fc7Python\u5305\u7f13\u5b58\u3001\u4efb\u52a1\u8c03\u5ea6\u4f18\u5316\u548c\u6570\u636e\u503e\u659c\u7ba1\u7406\u63d0\u5347\u6027\u80fd\u3002", "result": "Snowpark\u5728\u5927\u578b\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u9ad8\u6548\u548c\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u67b6\u6784\u3002", "conclusion": "Snowpark\u4e3a\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5f39\u6027\u67b6\u6784\u548c\u6027\u80fd\u4f18\u5316\u8fdb\u4e00\u6b65\u6269\u5c55\u4e86Snowflake\u7684\u80fd\u529b\u3002"}}
{"id": "2508.06344", "pdf": "https://arxiv.org/pdf/2508.06344", "abs": "https://arxiv.org/abs/2508.06344", "authors": ["Robin Sehm", "Christian Ewert", "Rainer Buchty", "Mladen Berekovic", "Saleh Mulhem"], "title": "Nail: Not Another Fault-Injection Framework for Chisel-generated RTL", "categories": ["cs.AR"], "comment": "PREPRINT - accepted In Proceedings of the 28th Euromicro Conference\n  Series on Digital System Design (DSD)", "summary": "Fault simulation and emulation are essential techniques for evaluating the\ndependability of integrated circuits, enabling early-stage vulnerability\nanalysis and supporting the implementation of effective mitigation strategies.\nHigh-level hardware description languages such as Chisel facilitate the rapid\ndevelopment of complex fault scenarios with minimal modification to the design.\nHowever, existing Chisel-based fault injection (FI) frameworks are limited by\ncoarse-grained, instruction-level controllability, restricting the precision of\nfault modeling. This work introduces Nail, a Chisel-based open-source FI\nframework that overcomes these limitations by introducing state-based faults.\nThis approach enables fault scenarios that depend on specific system states,\nrather than solely on instruction-level triggers, thereby removing the need for\nprecise timing of fault activation. For greater controllability, Nail allows\nusers to arbitrarily modify internal trigger states via software at runtime. To\nsupport this, Nail automatically generates a software interface, offering\nstraightforward access to the instrumented design. This enables fine-tuning of\nfault parameters during active FI campaigns - a feature particularly beneficial\nfor FPGA emulation, where synthesis is time-consuming. Utilizing these\nfeatures, Nail narrows the gap between the high speed of emulation-based FI\nframeworks, the usability of software-based approaches, and the controllability\nachieved in simulation. We demonstrate Nail's state-based FI and software\nframework by modeling a faulty general-purpose register in a RISC-V processor.\nAlthough this might appear straightforward, it requires state-dependent FI and\nwas previously impossible without fundamental changes to the design. The\napproach was validated in both simulation and FPGA emulation, where the\naddition of Nail introduced less than 1% resource overhead.", "AI": {"tldr": "Nail\u662f\u4e00\u79cd\u57fa\u4e8eChisel\u7684\u5f00\u6e90\u6545\u969c\u6ce8\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u72b6\u6001\u76f8\u5173\u6545\u969c\uff0c\u63d0\u9ad8\u4e86\u6545\u969c\u5efa\u6a21\u7684\u7cbe\u786e\u6027\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5de5\u5177\u5728\u63a7\u5236\u548c\u6613\u7528\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709Chisel\u6545\u969c\u6ce8\u5165\u5de5\u5177\u4ec5\u652f\u6301\u6307\u4ee4\u7ea7\u63a7\u5236\uff0c\u9650\u5236\u4e86\u6545\u969c\u5efa\u6a21\u7684\u7cbe\u786e\u6027\u3002Nail\u65e8\u5728\u901a\u8fc7\u72b6\u6001\u76f8\u5173\u6545\u969c\u548c\u8f6f\u4ef6\u63a5\u53e3\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "Nail\u901a\u8fc7\u72b6\u6001\u4f9d\u8d56\u6545\u969c\u6a21\u578b\u548c\u8fd0\u884c\u65f6\u8f6f\u4ef6\u63a7\u5236\u63a5\u53e3\u5b9e\u73b0\u7cbe\u786e\u6545\u969c\u6ce8\u5165\uff0c\u652f\u6301FPGA\u4eff\u771f\u4e2d\u7684\u52a8\u6001\u53c2\u6570\u8c03\u6574\u3002", "result": "Nail\u5728RISC-V\u5904\u7406\u5668\u4e0a\u9a8c\u8bc1\u4e86\u72b6\u6001\u76f8\u5173\u6545\u969c\u7684\u53ef\u884c\u6027\uff0c\u8d44\u6e90\u5f00\u9500\u4f4e\u4e8e1%\u3002", "conclusion": "Nail\u586b\u8865\u4e86\u4eff\u771f\u901f\u5ea6\u548c\u8f6f\u4ef6\u63a7\u5236\u6027\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u9ad8\u6548\u6545\u969c\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2508.05899", "pdf": "https://arxiv.org/pdf/2508.05899", "abs": "https://arxiv.org/abs/2508.05899", "authors": ["Zixuan Bian", "Ruohan Ren", "Yue Yang", "Chris Callison-Burch"], "title": "HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "3D scene generation plays a crucial role in gaming, artistic creation,\nvirtual reality and many other domains. However, current 3D scene design still\nrelies heavily on extensive manual effort from creators, and existing automated\nmethods struggle to generate open-domain scenes or support flexible editing. As\na result, generating 3D worlds directly from text has garnered increasing\nattention. In this paper, we introduce HOLODECK 2.0, an advanced\nvision-language-guided framework for 3D world generation with support for\ninteractive scene editing based on human feedback. HOLODECK 2.0 can generate\ndiverse and stylistically rich 3D scenes (e.g., realistic, cartoon, anime, and\ncyberpunk styles) that exhibit high semantic fidelity to fine-grained input\ndescriptions, suitable for both indoor and open-domain environments. HOLODECK\n2.0 leverages vision-language models (VLMs) to identify and parse the objects\nrequired in a scene and generates corresponding high-quality assets via\nstate-of-the-art 3D generative models. It then iteratively applies spatial\nconstraints derived from the VLMs to achieve semantically coherent and\nphysically plausible layouts. Human evaluations and CLIP-based assessments\ndemonstrate that HOLODECK 2.0 effectively generates high-quality scenes closely\naligned with detailed textual descriptions, consistently outperforming\nbaselines across indoor and open-domain scenarios. Additionally, we provide\nediting capabilities that flexibly adapt to human feedback, supporting layout\nrefinement and style-consistent object edits. Finally, we present a practical\napplication of HOLODECK 2.0 in procedural game modeling, generating visually\nrich and immersive environments, potentially boosting efficiency.", "AI": {"tldr": "HOLODECK 2.0\u662f\u4e00\u4e2a\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u5f15\u5bfc\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u62103D\u573a\u666f\u5e76\u652f\u6301\u57fa\u4e8e\u4eba\u53cd\u9988\u7684\u4ea4\u4e92\u5f0f\u7f16\u8f91\uff0c\u80fd\u751f\u6210\u591a\u6837\u98ce\u683c\u7684\u9ad8\u8d28\u91cf\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u73b0\u67093D\u573a\u666f\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u4e14\u7075\u6d3b\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4ece\u6587\u672c\u76f4\u63a5\u751f\u6210\u5f00\u653e\u9886\u57df\u573a\u666f\u3002", "method": "\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u573a\u666f\u5bf9\u8c61\u5e76\u751f\u6210\u9ad8\u8d28\u91cf3D\u8d44\u4ea7\uff0c\u901a\u8fc7\u7a7a\u95f4\u7ea6\u675f\u8fed\u4ee3\u4f18\u5316\u5e03\u5c40\u3002", "result": "\u751f\u6210\u7684\u573a\u666f\u5728\u8bed\u4e49\u548c\u7269\u7406\u5e03\u5c40\u4e0a\u4e0e\u6587\u672c\u63cf\u8ff0\u9ad8\u5ea6\u4e00\u81f4\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "HOLODECK 2.0\u57283D\u573a\u666f\u751f\u6210\u548c\u7f16\u8f91\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u6e38\u620f\u5efa\u6a21\u7b49\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.05970", "pdf": "https://arxiv.org/pdf/2508.05970", "abs": "https://arxiv.org/abs/2508.05970", "authors": ["Yanzhou Li", "Shangqing Liu", "Kangjie Chen", "Tianwei Zhang", "Yang Liu"], "title": "Impact-driven Context Filtering For Cross-file Code Completion", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has recently demonstrated considerable\npotential for repository-level code completion, as it integrates cross-file\nknowledge with in-file preceding code to provide comprehensive contexts for\ngeneration. To better understand the contribution of the retrieved cross-file\ncontexts, we introduce a likelihood-based metric to evaluate the impact of each\nretrieved code chunk on the completion. Our analysis reveals that, despite\nretrieving numerous chunks, only a small subset positively contributes to the\ncompletion, while some chunks even degrade performance. To address this issue,\nwe leverage this metric to construct a repository-level dataset where each\nretrieved chunk is labeled as positive, neutral, or negative based on its\nrelevance to the target completion. We then propose an adaptive retrieval\ncontext filtering framework, CODEFILTER, trained on this dataset to mitigate\nthe harmful effects of negative retrieved contexts in code completion.\nExtensive evaluation on the RepoEval and CrossCodeLongEval benchmarks\ndemonstrates that CODEFILTER consistently improves completion accuracy compared\nto approaches without filtering operations across various tasks. Additionally,\nCODEFILTER significantly reduces the length of the input prompt, enhancing\ncomputational efficiency while exhibiting strong generalizability across\ndifferent models. These results underscore the potential of CODEFILTER to\nenhance the accuracy, efficiency, and attributability of repository-level code\ncompletion.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCODEFILTER\u7684\u81ea\u9002\u5e94\u68c0\u7d22\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u5b58\u50a8\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u7814\u7a76RAG\u5728\u4ee3\u7801\u8865\u5168\u4e2d\u68c0\u7d22\u7684\u8de8\u6587\u4ef6\u4e0a\u4e0b\u6587\u7684\u8d21\u732e\uff0c\u53d1\u73b0\u8bb8\u591a\u68c0\u7d22\u5757\u5bf9\u8865\u5168\u65e0\u76ca\u751a\u81f3\u6709\u5bb3\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4f3c\u7136\u7684\u5ea6\u91cf\u8bc4\u4f30\u68c0\u7d22\u5757\u7684\u5f71\u54cd\uff0c\u6784\u5efa\u6807\u8bb0\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3CODEFILTER\u6846\u67b6\u8fc7\u6ee4\u6709\u5bb3\u4e0a\u4e0b\u6587\u3002", "result": "CODEFILTER\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u4e86\u8865\u5168\u51c6\u786e\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u8f93\u5165\u63d0\u793a\u957f\u5ea6\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "CODEFILTER\u5c55\u793a\u4e86\u5728\u5b58\u50a8\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u4e2d\u63d0\u5347\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.06264", "pdf": "https://arxiv.org/pdf/2508.06264", "abs": "https://arxiv.org/abs/2508.06264", "authors": ["Randal E. Bryant"], "title": "Numerical Considerations in Weighted Model Counting", "categories": ["math.NA", "cs.AI", "cs.LO", "cs.NA"], "comment": null, "summary": "Weighted model counting computes the sum of the rational-valued weights\nassociated with the satisfying assignments for a Boolean formula, where the\nweight of an assignment is given by the product of the weights assigned to the\npositive and negated variables comprising the assignment. Weighted model\ncounting finds applications across a variety of domains including probabilistic\nreasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly)\nconverting the input formula into a form that enables arithmetic evaluation,\nusing multiplication for conjunctions and addition for disjunctions. Performing\nthis evaluation using floating-point arithmetic can yield inaccurate results,\nand it cannot quantify the level of precision achieved. Computing with rational\narithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to\nefficiently compute weighted model counts that are guaranteed to achieve a\nuser-specified precision. When all weights are nonnegative, we prove that the\nprecision loss of arithmetic evaluation using floating-point arithmetic can be\ntightly bounded. We show that supplementing a standard IEEE double-precision\nrepresentation with a separate 64-bit exponent, a format we call extended-range\ndouble (ERD), avoids the underflow and overflow issues commonly encountered in\nweighted model counting. For problems with mixed negative and positive weights,\nwe show that a combination of interval floating-point arithmetic and rational\narithmetic can achieve the twin goals of efficiency and guaranteed precision.\nFor our evaluations, we have devised especially challenging formulas and weight\nassignments, demonstrating the robustness of our approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u79cd\u6570\u503c\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u9ad8\u6548\u8ba1\u7b97\u52a0\u6743\u6a21\u578b\u8ba1\u6570\uff0c\u5e76\u786e\u4fdd\u8fbe\u5230\u7528\u6237\u6307\u5b9a\u7684\u7cbe\u5ea6\u3002\u901a\u8fc7\u4f7f\u7528\u6269\u5c55\u8303\u56f4\u53cc\u7cbe\u5ea6\uff08ERD\uff09\u548c\u533a\u95f4\u6d6e\u70b9\u7b97\u672f\u7b49\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u6d6e\u70b9\u7b97\u672f\u7cbe\u5ea6\u635f\u5931\u548c\u6709\u7406\u7b97\u672f\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u5728\u6982\u7387\u63a8\u7406\u548c\u5b9a\u91cf\u98ce\u9669\u8bc4\u4f30\u7b49\u591a\u4e2a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u4f20\u7edf\u7684\u6d6e\u70b9\u7b97\u672f\u53ef\u80fd\u4e0d\u51c6\u786e\u4e14\u6709\u7cbe\u5ea6\u95ee\u9898\uff0c\u800c\u6709\u7406\u7b97\u672f\u867d\u7136\u7cbe\u786e\u4f46\u6210\u672c\u9ad8\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6280\u672f\u9650\u5236\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u6269\u5c55\u8303\u56f4\u53cc\u7cbe\u5ea6\uff08ERD\uff09\u548c\u533a\u95f4\u6d6e\u70b9\u7b97\u672f\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u975e\u8d1f\u6743\u91cd\u548c\u6df7\u5408\u6743\u91cd\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6781\u5177\u6311\u6218\u6027\u7684\u516c\u5f0f\u548c\u6743\u91cd\u5206\u914d\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u9ad8\u6548\u8ba1\u7b97\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u5e76\u4fdd\u8bc1\u7cbe\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u6570\u503c\u8868\u793a\uff0c\u672c\u6587\u6210\u529f\u89e3\u51b3\u4e86\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u4e2d\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2508.05869", "pdf": "https://arxiv.org/pdf/2508.05869", "abs": "https://arxiv.org/abs/2508.05869", "authors": ["Brian Sutherland"], "title": "Energy Experience Design", "categories": ["cs.CY", "cs.ET"], "comment": "Post-proceedings paper presented at LIMITS 2024: 10th Workshop on\n  Computing within Limits, 2024-06-19/20, Online", "summary": "The material footprint of information and communications technology (ICT)\nsystems is both significant and growing, inspiring a variety of conversations\naround sustainability and climate justice. In part this effort has been\ncatalysed by past scholarship and analysis from the LIMITS community. This\npaper examines energy storage systems for computing, particularly batteries --\nwhich are discarded at the rate of 15 billion a year worldwide. The\nInternational Energy Agency (IEA) is now referring to the energy transition\ntoward low carbon systems as a critical mineral problem, and countries are\nspeaking openly of 'mineral security' in policy documents. In this paper I 1)\npresent a definition for energy experience and what this means for the design\nand making of devices, interactions and experiences. I also 2) explore a series\nof electronics device prototypes converted to run from batteryless sustainable\nenergy that are extremely long lasting, and make limited use of critical\nminerals. As transitional energy experience device-design experiments, what do\nprototypes like these suggest for more mainstream, mass-manufactured systems?", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86ICT\u7cfb\u7edf\u7684\u6750\u6599\u8db3\u8ff9\u95ee\u9898\uff0c\u91cd\u70b9\u5173\u6ce8\u7535\u6c60\u7684\u53ef\u6301\u7eed\u80fd\u6e90\u5b58\u50a8\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u65e0\u7535\u6c60\u8bbe\u5907\u539f\u578b\u7684\u8bbe\u8ba1\u601d\u8def\u3002", "motivation": "ICT\u7cfb\u7edf\u6750\u6599\u8db3\u8ff9\u7684\u589e\u957f\u5f15\u53d1\u4e86\u5bf9\u53ef\u6301\u7eed\u6027\u548c\u6c14\u5019\u6b63\u4e49\u7684\u5173\u6ce8\uff0c\u5c24\u5176\u662f\u7535\u6c60\u7684\u5e74\u4e22\u5f03\u91cf\u9ad8\u8fbe150\u4ebf\u5757\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u80fd\u91cf\u4f53\u9a8c\u7684\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u8bbe\u8ba1\u65e0\u7535\u6c60\u53ef\u6301\u7eed\u80fd\u6e90\u7684\u7535\u5b50\u8bbe\u5907\u539f\u578b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u5c55\u793a\u4e86\u65e0\u9700\u5173\u952e\u77ff\u7269\u4e14\u5bff\u547d\u6781\u957f\u7684\u65e0\u7535\u6c60\u8bbe\u5907\u539f\u578b\uff0c\u4e3a\u5927\u89c4\u6a21\u5236\u9020\u7cfb\u7edf\u63d0\u4f9b\u8fc7\u6e21\u6027\u8bbe\u8ba1\u542f\u793a\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u65e0\u7535\u6c60\u53ef\u6301\u7eed\u80fd\u6e90\u8bbe\u5907\u539f\u578b\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u521b\u65b0\u601d\u8def\u548c\u53ef\u80fd\u6027\u3002"}}
{"id": "2508.05913", "pdf": "https://arxiv.org/pdf/2508.05913", "abs": "https://arxiv.org/abs/2508.05913", "authors": ["Stefan Pasch", "Min Chul Cha"], "title": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "As AI systems become increasingly embedded in organizational workflows and\nconsumer applications, ethical principles such as fairness, transparency, and\nrobustness have been widely endorsed in policy and industry guidelines.\nHowever, there is still scarce empirical evidence on whether these principles\nare recognized, valued, or impactful from the perspective of users. This study\ninvestigates the link between ethical AI and user satisfaction by analyzing\nover 100,000 user reviews of AI products from G2. Using transformer-based\nlanguage models, we measure sentiment across seven ethical dimensions defined\nby the EU Ethics Guidelines for Trustworthy AI. Our findings show that all\nseven dimensions are positively associated with user satisfaction. Yet, this\nrelationship varies systematically across user and product types. Technical\nusers and reviewers of AI development platforms more frequently discuss\nsystem-level concerns (e.g., transparency, data governance), while\nnon-technical users and reviewers of end-user applications emphasize\nhuman-centric dimensions (e.g., human agency, societal well-being). Moreover,\nthe association between ethical AI and user satisfaction is significantly\nstronger for non-technical users and end-user applications across all\ndimensions. Our results highlight the importance of ethical AI design from\nusers' perspectives and underscore the need to account for contextual\ndifferences across user roles and product types.", "AI": {"tldr": "\u7814\u7a76\u5206\u679010\u4e07\u6761AI\u4ea7\u54c1\u7528\u6237\u8bc4\u8bba\uff0c\u53d1\u73b0\u4f26\u7406AI\u4e0e\u7528\u6237\u6ee1\u610f\u5ea6\u6b63\u76f8\u5173\uff0c\u4f46\u5173\u7cfb\u56e0\u7528\u6237\u548c\u4ea7\u54c1\u7c7b\u578b\u800c\u5f02\u3002", "motivation": "\u63a2\u8ba8\u7528\u6237\u662f\u5426\u8ba4\u53ef\u3001\u91cd\u89c6\u4f26\u7406AI\u539f\u5219\u53ca\u5176\u5bf9\u6ee1\u610f\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u5206\u6790G2\u5e73\u53f0\u4e0a\u7684\u7528\u6237\u8bc4\u8bba\uff0c\u8986\u76d6\u6b27\u76df\u4f26\u7406\u6307\u5357\u7684\u4e03\u4e2a\u7ef4\u5ea6\u3002", "result": "\u4e03\u7ef4\u5ea6\u5747\u4e0e\u6ee1\u610f\u5ea6\u6b63\u76f8\u5173\uff0c\u6280\u672f\u7528\u6237\u5173\u6ce8\u7cfb\u7edf\u5c42\u9762\uff0c\u975e\u6280\u672f\u7528\u6237\u66f4\u6ce8\u91cd\u4eba\u672c\u7ef4\u5ea6\uff1b\u540e\u8005\u7684\u5173\u8054\u66f4\u5f3a\u3002", "conclusion": "\u4f26\u7406AI\u8bbe\u8ba1\u9700\u8003\u8651\u7528\u6237\u89d2\u8272\u548c\u4ea7\u54c1\u7c7b\u578b\u5dee\u5f02\u3002"}}
{"id": "2508.06001", "pdf": "https://arxiv.org/pdf/2508.06001", "abs": "https://arxiv.org/abs/2508.06001", "authors": ["Kai Zhang", "Peng Wang", "Sai Bi", "Jianming Zhang", "Yuanjun Xiong"], "title": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training", "categories": ["cs.DC", "cs.CV"], "comment": "Code is available at https://github.com/Kai-46/KnapFormer/", "summary": "We present KnapFormer, an efficient and versatile framework to combine\nworkload balancing and sequence parallelism in distributed training of\nDiffusion Transformers (DiT). KnapFormer builds on the insight that strong\nsynergy exists between sequence parallelism and the need to address the\nsignificant token imbalance across ranks. This imbalance arises from\nvariable-length text inputs and varying visual token counts in mixed-resolution\nand image-video joint training. KnapFormer redistributes tokens by first\ngathering sequence length metadata across all ranks in a balancing group and\nsolving a global knapsack problem. The solver aims to minimize the variances of\ntotal workload per-GPU, while accounting for the effect of sequence\nparallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the\nload-balancing decision process and utilizing a simple semi-empirical workload\nmodel, KnapFormers achieves minimal communication overhead and less than 1%\nworkload discrepancy in real-world training workloads with sequence length\nvarying from a few hundred to tens of thousands. It eliminates straggler\neffects and achieves 2x to 3x speedup when training state-of-the-art diffusion\nmodels like FLUX on mixed-resolution and image-video joint data corpora. We\nopen-source the KnapFormer implementation at\nhttps://github.com/Kai-46/KnapFormer/", "AI": {"tldr": "KnapFormer\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5de5\u4f5c\u8d1f\u8f7d\u5e73\u8861\u548c\u5e8f\u5217\u5e76\u884c\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u8bad\u7ec3\u6269\u6563\u53d8\u6362\u5668\uff08DiT\uff09\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u7531\u53ef\u53d8\u957f\u5ea6\u6587\u672c\u8f93\u5165\u548c\u89c6\u89c9\u4ee4\u724c\u8ba1\u6570\u4e0d\u5747\u5bfc\u81f4\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5168\u5c40\u80cc\u5305\u95ee\u9898\u548c\u5e8f\u5217\u5e76\u884c\u6027\u4f18\u5316\u8d1f\u8f7d\u5e73\u8861\uff0c\u7ed3\u5408DeepSpeed-Ulysees\u548c\u534a\u7ecf\u9a8c\u5de5\u4f5c\u8d1f\u8f7d\u6a21\u578b\u3002", "result": "\u5728\u5b9e\u9645\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u4e86\u4f4e\u4e8e1%\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5dee\u5f02\uff0c\u6d88\u9664\u6ede\u540e\u6548\u5e94\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u53472\u81f33\u500d\u3002", "conclusion": "KnapFormer\u5728\u6df7\u5408\u5206\u8fa8\u7387\u548c\u56fe\u50cf-\u89c6\u9891\u8054\u5408\u8bad\u7ec3\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5df2\u5f00\u6e90\u5b9e\u73b0\u3002"}}
{"id": "2508.06055", "pdf": "https://arxiv.org/pdf/2508.06055", "abs": "https://arxiv.org/abs/2508.06055", "authors": ["Wonjung Park", "Suhyun Ahn", "Jinah Park"], "title": "LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Lateral ventricle (LV) shape analysis holds promise as a biomarker for\nneurological diseases; however, challenges remain due to substantial shape\nvariability across individuals and segmentation difficulties arising from\nlimited MRI resolution. We introduce LV-Net, a novel framework for producing\nindividualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint\nLV-hippocampus template mesh. By incorporating anatomical relationships\nembedded within the joint template, LV-Net reduces boundary segmentation\nartifacts and improves reconstruction robustness. In addition, by classifying\nthe vertices of the template mesh based on their anatomical adjacency, our\nmethod enhances point correspondence across subjects, leading to more accurate\nLV shape statistics. We demonstrate that LV-Net achieves superior\nreconstruction accuracy, even in the presence of segmentation imperfections,\nand delivers more reliable shape descriptors across diverse datasets. Finally,\nwe apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that\nshow significantly associations with the disease relative to cognitively normal\ncontrols. The codes for LV shape modeling are available at\nhttps://github.com/PWonjung/LV_Shape_Modeling.", "AI": {"tldr": "LV-Net\u662f\u4e00\u79cd\u4ece\u8111MRI\u751f\u6210\u4e2a\u6027\u53163D LV\u7f51\u683c\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u53d8\u5f62\u8054\u5408LV-\u6d77\u9a6c\u6a21\u677f\u7f51\u683c\u6765\u63d0\u9ad8\u91cd\u5efa\u7cbe\u5ea6\u548c\u5f62\u72b6\u7edf\u8ba1\u51c6\u786e\u6027\uff0c\u5e94\u7528\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5206\u6790\u3002", "motivation": "LV\u5f62\u72b6\u5206\u6790\u4f5c\u4e3a\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u7684\u6f5c\u5728\u751f\u7269\u6807\u5fd7\u7269\uff0c\u4f46\u4e2a\u4f53\u95f4\u5f62\u72b6\u5dee\u5f02\u5927\u548cMRI\u5206\u8fa8\u7387\u9650\u5236\u5bfc\u81f4\u5206\u5272\u56f0\u96be\u3002", "method": "\u4f7f\u7528LV-Net\u6846\u67b6\uff0c\u901a\u8fc7\u53d8\u5f62\u8054\u5408LV-\u6d77\u9a6c\u6a21\u677f\u7f51\u683c\uff0c\u7ed3\u5408\u89e3\u5256\u5173\u7cfb\u6539\u5584\u5206\u5272\u548c\u91cd\u5efa\u3002", "result": "LV-Net\u5728\u91cd\u5efa\u7cbe\u5ea6\u548c\u5f62\u72b6\u63cf\u8ff0\u7b26\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5206\u6790\u4e2d\u8bc6\u522b\u51fa\u663e\u8457\u76f8\u5173\u533a\u57df\u3002", "conclusion": "LV-Net\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5065\u7684LV\u5f62\u72b6\u5206\u6790\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u75be\u75c5\u7814\u7a76\u548c\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2508.06017", "pdf": "https://arxiv.org/pdf/2508.06017", "abs": "https://arxiv.org/abs/2508.06017", "authors": ["Xiangzhe Xu", "Shiwei Feng", "Zian Su", "Chengpeng Wang", "Xiangyu Zhang"], "title": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": "The first two authors contributed equally to this work", "summary": "Intelligent coding systems are transforming software development by enabling\nusers to specify code behavior in natural language. However, the opaque\ndecision-making of AI-driven coders raises trust and usability concerns,\nparticularly for non-expert users who cannot inspect low-level implementations.\nWe argue that these systems should not only generate code but also produce\nclear, consistent justifications that bridge model reasoning and user\nunderstanding. To this end, we identify two critical justification\nproperties-cognitive alignment and semantic faithfulness-and highlight the\nlimitations of existing methods, including formal verification, static\nanalysis, and post-hoc explainability. We advocate exploring neuro-symbolic\napproaches for justification generation, where symbolic constraints guide model\nbehavior during training and program semantics are enriched through neural\nrepresentations, enabling automated consistency checks at inference time.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u6e05\u6670\u7684\u89e3\u91ca\u63d0\u5347AI\u7f16\u7801\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u7528\u6027\uff0c\u63d0\u51fa\u4e86\u8ba4\u77e5\u5bf9\u9f50\u548c\u8bed\u4e49\u5fe0\u5b9e\u6027\u4e24\u4e2a\u5173\u952e\u89e3\u91ca\u5c5e\u6027\uff0c\u5e76\u5efa\u8bae\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u751f\u6210\u89e3\u91ca\u3002", "motivation": "AI\u9a71\u52a8\u7684\u7f16\u7801\u7cfb\u7edf\u51b3\u7b56\u4e0d\u900f\u660e\uff0c\u53ef\u80fd\u5f15\u53d1\u4fe1\u4efb\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5bf9\u975e\u4e13\u5bb6\u7528\u6237\u3002", "method": "\u63d0\u51fa\u8ba4\u77e5\u5bf9\u9f50\u548c\u8bed\u4e49\u5fe0\u5b9e\u6027\u4f5c\u4e3a\u5173\u952e\u89e3\u91ca\u5c5e\u6027\uff0c\u5e76\u5efa\u8bae\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7ed3\u5408\u7b26\u53f7\u7ea6\u675f\u548c\u795e\u7ecf\u7f51\u7edc\u8868\u793a\uff0c\u751f\u6210\u89e3\u91ca\u3002", "result": "\u5f3a\u8c03\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5982\u5f62\u5f0f\u9a8c\u8bc1\u548c\u9759\u6001\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u6709\u671b\u4e3aAI\u7f16\u7801\u7cfb\u7edf\u63d0\u4f9b\u66f4\u900f\u660e\u7684\u89e3\u91ca\uff0c\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u3002"}}
{"id": "2508.05876", "pdf": "https://arxiv.org/pdf/2508.05876", "abs": "https://arxiv.org/abs/2508.05876", "authors": ["Francesca Ferrara", "Lander W. Schillinger Arana", "Florian D\u00f6rfler", "Sarah H. Q. Li"], "title": "A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance", "categories": ["cs.LG", "astro-ph.EP", "astro-ph.IM", "cs.ET"], "comment": "16 pages, 13 figures, submitted to the 2025 Astrodynamics Specialist\n  Conference", "summary": "This work presents a Markov decision process (MDP) framework to model\ndecision-making for collision avoidance maneuver (CAM) and a reinforcement\nlearning policy gradient (RL-PG) algorithm to train an autonomous guidance\npolicy using historic CAM data. In addition to maintaining acceptable collision\nrisks, this approach seeks to minimize the average fuel consumption of CAMs by\nmaking early maneuver decisions. We model CAM as a continuous state, discrete\naction and finite horizon MDP, where the critical decision is determining when\nto initiate the maneuver. The MDP model also incorporates analytical models for\nconjunction risk, propellant consumption, and transit orbit geometry. The\nMarkov policy effectively trades-off maneuver delay-which improves the\nreliability of conjunction risk indicators-with propellant consumption-which\nincreases with decreasing maneuver time. Using historical data of tracked\nconjunction events, we verify this framework and conduct an extensive ablation\nstudy on the hyper-parameters used within the MDP. On synthetic conjunction\nevents, the trained policy significantly minimizes both the overall and average\npropellant consumption per CAM when compared to a conventional cut-off policy\nthat initiates maneuvers 24 hours before the time of closest approach (TCA). On\nhistorical conjunction events, the trained policy consumes more propellant\noverall but reduces the average propellant consumption per CAM. For both\nhistorical and synthetic conjunction events, the trained policy achieves equal\nif not higher overall collision risk guarantees.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u548c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u68af\u5ea6\uff08RL-PG\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u81ea\u4e3b\u5bfc\u822a\u7b56\u7565\u4ee5\u51cf\u5c11\u78b0\u649e\u89c4\u907f\u673a\u52a8\uff08CAM\uff09\u7684\u5e73\u5747\u71c3\u6599\u6d88\u8017\uff0c\u5e76\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u78b0\u649e\u98ce\u9669\u3002", "motivation": "\u901a\u8fc7\u65e9\u671f\u51b3\u7b56\u4f18\u5316CAM\u7684\u71c3\u6599\u6d88\u8017\uff0c\u540c\u65f6\u786e\u4fdd\u78b0\u649e\u98ce\u9669\u53ef\u63a7\u3002", "method": "\u5c06CAM\u5efa\u6a21\u4e3a\u8fde\u7eed\u72b6\u6001\u3001\u79bb\u6563\u52a8\u4f5c\u548c\u6709\u9650\u65f6\u95f4\u8303\u56f4\u7684MDP\uff0c\u7ed3\u5408\u98ce\u9669\u5206\u6790\u3001\u71c3\u6599\u6d88\u8017\u548c\u8f68\u9053\u51e0\u4f55\u6a21\u578b\uff0c\u4f7f\u7528RL-PG\u7b97\u6cd5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u5408\u6210\u548c\u5386\u53f2\u6570\u636e\u4e0a\uff0c\u8bad\u7ec3\u7684\u7b56\u7565\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u71c3\u6599\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u5e38\u89c4\u7b56\u7565\u76f8\u5f53\u7684\u78b0\u649e\u98ce\u9669\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u65e9\u671f\u51b3\u7b56\u6709\u6548\u5e73\u8861\u4e86\u71c3\u6599\u6d88\u8017\u548c\u98ce\u9669\u63a7\u5236\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u56fa\u5b9a\u65f6\u95f4\u9608\u503c\u7b56\u7565\u3002"}}
{"id": "2508.05933", "pdf": "https://arxiv.org/pdf/2508.05933", "abs": "https://arxiv.org/abs/2508.05933", "authors": ["Xueyuan Xu", "Wenjia Dong", "Fulin Wei", "Li Zhuo"], "title": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The affective brain-computer interface is a crucial technology for affective\ninteraction and emotional intelligence, emerging as a significant area of\nresearch in the human-computer interaction. Compared to single-type features,\nmulti-type EEG features provide a multi-level representation for analyzing\nmulti-dimensional emotions. However, the high dimensionality of multi-type EEG\nfeatures, combined with the relatively small number of high-quality EEG\nsamples, poses challenges such as classifier overfitting and suboptimal\nreal-time performance in multi-dimensional emotion recognition. Moreover,\npractical applications of affective brain-computer interface frequently\nencounters partial absence of multi-dimensional emotional labels due to the\nopen nature of the acquisition environment, and ambiguity and variability in\nindividual emotion perception. To address these challenges, this study proposes\na novel EEG feature selection method for missing multi-dimensional emotion\nrecognition. The method leverages adaptive orthogonal non-negative matrix\nfactorization to reconstruct the multi-dimensional emotional label space\nthrough second-order and higher-order correlations, which could reduce the\nnegative impact of missing values and outliers on label reconstruction.\nSimultaneously, it employs least squares regression with graph-based manifold\nlearning regularization and global feature redundancy minimization\nregularization to enable EEG feature subset selection despite missing\ninformation, ultimately achieving robust EEG-based multi-dimensional emotion\nrecognition. Simulation experiments on three widely used multi-dimensional\nemotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method\noutperforms thirteen advanced feature selection methods in terms of robustness\nfor EEG emotional feature selection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8111\u7535\u56fe\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u7ef4\u60c5\u611f\u8bc6\u522b\u4e2d\u6807\u7b7e\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6b63\u4ea4\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u7b49\u65b9\u6cd5\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "\u591a\u7ef4\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u9ad8\u7ef4\u5ea6\u8111\u7535\u56fe\u7279\u5f81\u548c\u6807\u7b7e\u7f3a\u5931\u95ee\u9898\u5f71\u54cd\u5206\u7c7b\u5668\u6027\u80fd\u548c\u5b9e\u65f6\u6027\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u6b63\u4ea4\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u91cd\u5efa\u6807\u7b7e\u7a7a\u95f4\uff0c\u7ed3\u5408\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u548c\u56fe\u6d41\u5f62\u5b66\u4e60\u6b63\u5219\u5316\u8fdb\u884c\u7279\u5f81\u9009\u62e9\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e13\u79cd\u5148\u8fdb\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6807\u7b7e\u7f3a\u5931\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u591a\u7ef4\u60c5\u611f\u8bc6\u522b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.06024", "pdf": "https://arxiv.org/pdf/2508.06024", "abs": "https://arxiv.org/abs/2508.06024", "authors": ["Zheming Yang", "Yunqing Hu", "Sheng Sun", "Wen Ji"], "title": "EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference", "categories": ["cs.DC"], "comment": "9 pages, 8 figures", "summary": "The Mixture-of-Experts (MoE) paradigm has emerged as a promising solution to\nscale up model capacity while maintaining inference efficiency. However,\ndeploying MoE models across heterogeneous end-cloud environments poses new\nchallenges in expert scheduling, communication overhead, and resource\nheterogeneity. In this paper, we propose EC2MoE, an adaptive framework for\nscalable MoE inference via end-cloud pipeline collaboration. First, we design a\nhardware-aware lightweight group gate network that enhances expert selection\nand computational efficiency. By incorporating a hardware-aware local expert\nselection mechanism, the system adaptively filters candidate experts based on\nreal-time device profiles. A lightweight group gate module then integrates\nlocal and global gating outputs to achieve high-quality expert routing with\nminimal overhead. Second, we develop a pipeline optimization mechanism based on\nendcloud collaboration to accelerate MoE inference. This includes an\nencoder-decoder structure based on low-rank compression, which reduces\ntransmission and computation costs. And a route-aware heuristic pipeline\nscheduling algorithm that dynamically allocates inference stages across devices\naccording to workload and network topology. Extensive experiments show that\nEC2MoE can increase throughput by 2.2x to 5.1x and reduce end-to-end latency by\n53% to 67% while maintaining high accuracy compared to state-of-the-art\nmethods. It also maintains good scalability under dynamic load and network\nenvironments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86EC2MoE\u6846\u67b6\uff0c\u901a\u8fc7\u7aef\u4e91\u534f\u4f5c\u4f18\u5316Mixture-of-Experts\uff08MoE\uff09\u63a8\u7406\uff0c\u63d0\u5347\u6548\u7387\u5e76\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3MoE\u6a21\u578b\u5728\u5f02\u6784\u7aef\u4e91\u73af\u5883\u4e2d\u90e8\u7f72\u65f6\u9762\u4e34\u7684\u4e13\u5bb6\u8c03\u5ea6\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u5f02\u6784\u6027\u7b49\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u786c\u4ef6\u611f\u77e5\u7684\u8f7b\u91cf\u7ea7\u7ec4\u95e8\u7f51\u7edc\u548c\u7aef\u4e91\u534f\u4f5c\u7684\u6d41\u6c34\u7ebf\u4f18\u5316\u673a\u5236\uff0c\u5305\u62ec\u4f4e\u79e9\u538b\u7f29\u548c\u8def\u7531\u611f\u77e5\u7684\u8c03\u5ea6\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEC2MoE\u80fd\u63d0\u5347\u541e\u5410\u91cf2.2-5.1\u500d\uff0c\u964d\u4f4e\u5ef6\u8fdf53%-67%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "EC2MoE\u4e3a\u5f02\u6784\u7aef\u4e91\u73af\u5883\u4e0b\u7684MoE\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06316", "pdf": "https://arxiv.org/pdf/2508.06316", "abs": "https://arxiv.org/abs/2508.06316", "authors": ["Theresa Pollinger", "Masado Ishii", "Jens Domke"], "title": "The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations", "categories": ["cs.DS", "cs.CG", "cs.GR", "cs.IT", "cs.NA", "math.IT", "math.NA", "65D15, 65D18, 68P05, 68P30"], "comment": "contains pdf animations; we recommend Okular or Firefox for viewing", "summary": "Structured adaptive mesh refinement (AMR), commonly implemented via quadtrees\nand octrees, underpins a wide range of applications including databases,\ncomputer graphics, physics simulations, and machine learning. However, octrees\nenforce isotropic refinement in regions of interest, which can be especially\ninefficient for problems that are intrinsically anisotropic--much resolution is\nspent where little information is gained. This paper presents omnitrees as an\nanisotropic generalization of octrees and related data structures. Omnitrees\nallow to refine only the locally most important dimensions, providing tree\nstructures that are less deep than bintrees and less wide than octrees. As a\nresult, the convergence of the AMR schemes can be increased by up to a factor\nof the dimensionality d for very anisotropic problems, quickly offsetting their\nmodest increase in storage overhead. We validate this finding on the problem of\nbinary shape representation across 4,166 three-dimensional objects: Omnitrees\nincrease the mean convergence rate by 1.5x, require less storage to achieve\nequivalent error bounds, and maximize the information density of the stored\nfunction faster than octrees. These advantages are projected to be even\nstronger for higher-dimensional problems. We provide a first validation by\nintroducing a time-dependent rotation to create four-dimensional\nrepresentations, and discuss the properties of their 4-d octree and omnitree\napproximations. Overall, omnitree discretizations can make existing AMR\napproaches more efficient, and open up new possibilities for high-dimensional\napplications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86omnitrees\u4f5c\u4e3aoctrees\u7684\u5404\u5411\u5f02\u6027\u6cdb\u5316\u6570\u636e\u7ed3\u6784\uff0c\u901a\u8fc7\u4ec5\u5728\u5c40\u90e8\u6700\u91cd\u8981\u7ef4\u5ea6\u7ec6\u5316\uff0c\u663e\u8457\u63d0\u9ad8AMR\u65b9\u6848\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u57283D\u5f62\u72b6\u8868\u793a\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edfoctrees\u5728\u89e3\u51b3\u5404\u5411\u5f02\u6027\u95ee\u9898\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u4e3a\u5176\u5f3a\u5236\u5404\u5411\u540c\u6027\u7ec6\u5316\uff0c\u5bfc\u81f4\u5206\u8fa8\u7387\u6d6a\u8d39\u3002", "method": "\u63d0\u51faomnitrees\u6570\u636e\u7ed3\u6784\uff0c\u5141\u8bb8\u52a8\u6001\u9009\u62e9\u7ec6\u5316\u7ef4\u5ea6\uff0c\u51cf\u5c11\u6811\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\uff0c\u63d0\u9ad8\u6536\u655b\u901f\u5ea6\u3002", "result": "\u57283D\u7269\u4f53\u8868\u793a\u4e2d\uff0comnitrees\u6536\u655b\u901f\u5ea6\u63d0\u9ad81.5\u500d\uff0c\u5b58\u50a8\u9700\u6c42\u66f4\u4f4e\uff0c\u4fe1\u606f\u5bc6\u5ea6\u66f4\u9ad8\u3002", "conclusion": "omnitrees\u53ef\u63d0\u5347\u73b0\u6709AMR\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u5e76\u4e3a\u9ad8\u7ef4\u5e94\u7528\u63d0\u4f9b\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2508.06192", "pdf": "https://arxiv.org/pdf/2508.06192", "abs": "https://arxiv.org/abs/2508.06192", "authors": ["Lantian Li", "Yuyu Chen", "Jingwen Wu", "Yue Pan", "Zhongxing Yu"], "title": "Understanding Inconsistent State Update Vulnerabilities in Smart Contracts", "categories": ["cs.SE"], "comment": "31 pages, 11 figures", "summary": "Smart contracts enable contract terms to be automatically executed and\nverified on the blockchain, and recent years have witnessed numerous\napplications of them in areas such as financial institutions and supply chains.\nThe execution logic of a smart contract is closely related to the contract\nstate, and thus the correct and safe execution of the contract depends heavily\non the precise control and update of the contract state. However, the contract\nstate update process can have issues. In particular, inconsistent state update\nissues can arise for reasons such as unsynchronized modifications. Inconsistent\nstate update bugs have been exploited by attackers many times, but existing\ndetection tools still have difficulty in effectively identifying them. This\npaper conducts the first large-scale empirical study about inconsistent state\nupdate vulnerabilities (that is, inconsistent state update bugs that are\nexploitable) in smart contracts, aiming to shed light for developers,\nresearchers, tool builders, and language or library designers in order to avoid\ninconsistent state update vulnerabilities. We systematically investigate 116\ninconsistent state update vulnerabilities in 352 real-world smart contract\nprojects, summarizing their root causes, fix strategies, and exploitation\nmethods. Our study provides 11 original and important findings, and we also\ngive the implications of our findings. To illustrate the potential benefits of\nour research, we also develop a proof-of-concept checker based on one of our\nfindings. The checker effectively detects issues in 64 popular GitHub projects,\nand 19 project owners have confirmed the detected issues at the time of\nwriting. The result demonstrates the usefulness and importance of our findings\nfor avoiding inconsistent state update vulnerabilities in smart contracts.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u667a\u80fd\u5408\u7ea6\u4e2d\u4e0d\u4e00\u81f4\u72b6\u6001\u66f4\u65b0\u6f0f\u6d1e\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u5176\u6839\u6e90\u3001\u4fee\u590d\u7b56\u7565\u548c\u5229\u7528\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e8611\u4e2a\u91cd\u8981\u53d1\u73b0\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u68c0\u6d4b\u5de5\u5177\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u7684\u72b6\u6001\u66f4\u65b0\u95ee\u9898\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u6f0f\u6d1e\uff0c\u73b0\u6709\u5de5\u5177\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u7814\u7a76\u4ee5\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u8c03\u67e5\u4e86352\u4e2a\u771f\u5b9e\u667a\u80fd\u5408\u7ea6\u9879\u76ee\u4e2d\u7684116\u4e2a\u4e0d\u4e00\u81f4\u72b6\u6001\u66f4\u65b0\u6f0f\u6d1e\uff0c\u5206\u6790\u5176\u6839\u56e0\u3001\u4fee\u590d\u7b56\u7565\u548c\u5229\u7528\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e8611\u4e2a\u91cd\u8981\u53d1\u73b0\uff0c\u5f00\u53d1\u7684\u6982\u5ff5\u9a8c\u8bc1\u68c0\u6d4b\u5de5\u5177\u572864\u4e2aGitHub\u9879\u76ee\u4e2d\u6709\u6548\u8bc6\u522b\u95ee\u9898\uff0c19\u4e2a\u9879\u76ee\u6240\u6709\u8005\u786e\u8ba4\u4e86\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u5f00\u53d1\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u5de5\u5177\u8bbe\u8ba1\u8005\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\uff0c\u6709\u52a9\u4e8e\u907f\u514d\u667a\u80fd\u5408\u7ea6\u4e2d\u7684\u4e0d\u4e00\u81f4\u72b6\u6001\u66f4\u65b0\u6f0f\u6d1e\u3002"}}
{"id": "2508.05883", "pdf": "https://arxiv.org/pdf/2508.05883", "abs": "https://arxiv.org/abs/2508.05883", "authors": ["Sean Feeney", "Reuben Tate", "John Golden", "Stephan Eidenbenz"], "title": "MPS-JuliQAOA: User-friendly, Scalable MPS-based Simulation for Quantum Optimization", "categories": ["quant-ph", "cs.ET", "cs.SE"], "comment": "14 pages, 7 figures", "summary": "We present the MPS-JuliQAOA simulator, a user-friendly, open-source tool to\nsimulate the Quantum Approximate Optimization Algorithm (QAOA) of any\noptimization problem that can be expressed as diagonal Hamiltonian. By\nleveraging Julia-language constructs and the ITensor package to implement a\nMatrix Product State (MPS) approach to simulating QAOA, MPS-Juli-QAOA\neffortlessly scales to 512 qubits and 20 simulation rounds on the standard\nde-facto benchmark 3-regular MaxCut QAOA problem. MPS-JuliQAOA also has\nbuilt-in parameter finding capabilities, which is a crucial performance aspect\nof QAOA. We illustrate through examples that the user does not need to know MPS\nprinciples or complex automatic differentiation techniques to use MPS-JuliQAOA.\nWe study the scalability of our tool with respect to runtime, memory usage and\naccuracy tradeoffs. Code available at\nhttps://github.com/lanl/JuliQAOA.jl/tree/mps.", "AI": {"tldr": "MPS-JuliQAOA\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u7528\u6237\u53cb\u597d\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u6a21\u62dfQAOA\u7b97\u6cd5\uff0c\u652f\u6301512\u91cf\u5b50\u6bd4\u7279\u548c20\u8f6e\u6a21\u62df\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3QAOA\u7b97\u6cd5\u5728\u6a21\u62df\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6613\u7528\u6027\u95ee\u9898\u3002", "method": "\u5229\u7528Julia\u8bed\u8a00\u548cITensor\u5305\u5b9e\u73b0MPS\u65b9\u6cd5\uff0c\u65e0\u9700\u7528\u6237\u4e86\u89e3MPS\u539f\u7406\u6216\u590d\u6742\u81ea\u52a8\u5fae\u5206\u6280\u672f\u3002", "result": "\u5de5\u5177\u53ef\u6269\u5c55\u5230512\u91cf\u5b50\u6bd4\u7279\u548c20\u8f6e\u6a21\u62df\uff0c\u5e76\u5177\u6709\u5185\u7f6e\u53c2\u6570\u4f18\u5316\u80fd\u529b\u3002", "conclusion": "MPS-JuliQAOA\u662f\u4e00\u4e2a\u9ad8\u6548\u7684QAOA\u6a21\u62df\u5de5\u5177\uff0c\u9002\u5408\u975e\u4e13\u4e1a\u7528\u6237\u4f7f\u7528\u3002"}}
{"id": "2508.05934", "pdf": "https://arxiv.org/pdf/2508.05934", "abs": "https://arxiv.org/abs/2508.05934", "authors": ["Xueyuan Xu", "Tianze Yu", "Wenjia Dong", "Fulin Wei", "Li Zhuo"], "title": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Recently, multi-modal physiological signals based emotion recognition has\ngarnered increasing attention in the field of brain-computer interfaces.\nNevertheness, the associated multi-modal physiological features are often\nhigh-dimensional and inevitably include irrelevant, redundant, and noisy\nrepresentation, which can easily lead to overfitting, poor performance, and\nhigh computational complexity in emotion classifiers. Feature selection has\nbeen widely applied to address these challenges. However, previous studies\ngenerally assumed that multi-modal physiological data are complete, whereas in\nreality, the data are often incomplete due to the openness of the acquisition\nand operational environment. For example, a part of samples are available in\nseveral modalities but not in others. To address this issue, we propose a novel\nmethod for incomplete multi-modal physiological signal feature selection called\nadaptive shared latent structure learning (ASLSL). Based on the property that\nsimilar features share similar emotional labels, ASLSL employs adaptive shared\nlatent structure learning to explore a common latent space shared for\nincomplete multi-modal physiological signals and multi-dimensional emotional\nlabels, thereby mitigating the impact of missing information and mining\nconsensus information. Two most popular multi-modal physiological emotion\ndatasets (DEAP and DREAMER) with multi-dimensional emotional labels were\nutilized to compare the performance between compare ASLSL and seventeen feature\nselection methods. Comprehensive experimental results on these datasets\ndemonstrate the effectiveness of ASLSL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aASLSL\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4e0d\u5b8c\u5907\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u7279\u5f81\u9009\u62e9\u95ee\u9898\uff0c\u901a\u8fc7\u5b66\u4e60\u5171\u4eab\u6f5c\u5728\u7ed3\u6784\u6765\u51cf\u5c11\u7f3a\u5931\u4fe1\u606f\u7684\u5f71\u54cd\u3002", "motivation": "\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u60c5\u611f\u8bc6\u522b\u5728\u8111\u673a\u63a5\u53e3\u9886\u57df\u5907\u53d7\u5173\u6ce8\uff0c\u4f46\u9ad8\u7ef4\u7279\u5f81\u5e38\u5305\u542b\u65e0\u5173\u3001\u5197\u4f59\u548c\u566a\u58f0\u4fe1\u606f\uff0c\u4e14\u5b9e\u9645\u6570\u636e\u5f80\u5f80\u4e0d\u5b8c\u5907\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u5171\u4eab\u6f5c\u5728\u7ed3\u6784\u5b66\u4e60\uff08ASLSL\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a2\u7d22\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u6765\u6316\u6398\u5171\u8bc6\u4fe1\u606f\u3002", "result": "\u5728DEAP\u548cDREAMER\u6570\u636e\u96c6\u4e0a\u4e0e17\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5bf9\u6bd4\uff0cASLSL\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "ASLSL\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u5b8c\u5907\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u7684\u7279\u5f81\u9009\u62e9\u95ee\u9898\u3002"}}
{"id": "2508.06297", "pdf": "https://arxiv.org/pdf/2508.06297", "abs": "https://arxiv.org/abs/2508.06297", "authors": ["Yanyu Liu", "Jingying Fu", "Sixiang Liu", "Yitian Zou", "You Fu", "Jiehan Zhou", "Shouhua Zhang"], "title": "KV Cache Compression for Inference Efficiency in LLMs: A Review", "categories": ["cs.DC"], "comment": "12 pages", "summary": "Withtherapid advancement of large language models (LLMs), the context length\nfor inference has been continuously increasing, leading to an exponential\ngrowth in the demand for Key-Value (KV) caching. This has resulted in a\nsignificant memory bottleneck, limiting the inference efficiency and\nscalability of the models. Therefore, optimizing the KV cache during inference\nis crucial for enhancing performance and efficiency. This review systematically\nexamines current KV cache optimization techniques, including compression\nstrategies such as selective token strategies, quantization, and attention\ncompression. We evaluate the effectiveness, trade-offs, and application\nscenarios of these methods, providing a comprehensive analysis of their impact\non memory usage and inference speed. We focus on identifying the limitations\nand challenges of existing methods, such as compatibility issues with different\nmodels and tasks. Additionally, this review highlights future research\ndirections, including hybrid optimization techniques, adaptive dynamic\nstrategies, and software-hardware co-design. These approaches aim to improve\ninference efficiency and promote the practical application of large language\nmodels.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u4e2dKV\u7f13\u5b58\u7684\u4f18\u5316\u6280\u672f\uff0c\u5206\u6790\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3001\u6743\u8861\u53ca\u5e94\u7528\u573a\u666f\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u589e\u52a0\uff0cKV\u7f13\u5b58\u9700\u6c42\u5448\u6307\u6570\u589e\u957f\uff0c\u5bfc\u81f4\u5185\u5b58\u74f6\u9888\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002\u56e0\u6b64\uff0c\u4f18\u5316KV\u7f13\u5b58\u662f\u63d0\u5347\u6027\u80fd\u7684\u5173\u952e\u3002", "method": "\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86KV\u7f13\u5b58\u4f18\u5316\u6280\u672f\uff0c\u5305\u62ec\u9009\u62e9\u6027\u4ee4\u724c\u7b56\u7565\u3001\u91cf\u5316\u548c\u6ce8\u610f\u529b\u538b\u7f29\u7b49\u538b\u7f29\u7b56\u7565\uff0c\u5206\u6790\u5176\u5bf9\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u901f\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u603b\u7ed3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff08\u5982\u517c\u5bb9\u6027\u95ee\u9898\uff09\u548c\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u6df7\u5408\u4f18\u5316\u6280\u672f\u3001\u81ea\u9002\u5e94\u52a8\u6001\u7b56\u7565\u548c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u3002", "conclusion": "\u8bba\u6587\u4e3a\u4f18\u5316KV\u7f13\u5b58\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u65e8\u5728\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u4fc3\u8fdb\u5176\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.06345", "pdf": "https://arxiv.org/pdf/2508.06345", "abs": "https://arxiv.org/abs/2508.06345", "authors": ["Yanbin Wei", "Jiangyue Yan", "Chun Kang", "Yang Chen", "Hua Liu", "James T. Kwok", "Yu Zhang"], "title": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering", "categories": ["cs.CL", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities\nin diverse domain question-answering (QA) tasks, including graph QA that\ninvolves complex graph topologies. However, most current approaches use only a\nsingle type of graph representation, namely Topology Representation Form (TRF),\nsuch as prompt-unified text descriptions or style-fixed visual styles. Those\n\"one-size-fits-all\" approaches fail to consider the specific preferences of\ndifferent models or tasks, often leading to incorrect or overly long responses.\nTo address this, we first analyze the characteristics and weaknesses of\nexisting TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to\nzero-shot graph QA. We then introduce a new metric, Graph Response Efficiency\n(GRE), which measures the balance between the performance and the brevity in\ngraph QA. Built on these, we develop the DynamicTRF framework, which aims to\nimprove both the accuracy and conciseness of graph QA. To be specific,\nDynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based\non their GRE scores, to probe the question-specific TRF preferences. Then it\ntrains a TRF router on the TRFP dataset, to adaptively assign the best TRF from\n$F_{ZS}$ for each question during the inference. Extensive experiments across 7\nin-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show\nthat DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms\nof accuracy", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDynamicTRF\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u9002\u5408\u7684\u56fe\u8868\u793a\u5f62\u5f0f\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u5728\u96f6\u6837\u672c\u56fe\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u7b80\u6d01\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f7f\u7528\u5355\u4e00\u56fe\u8868\u793a\u5f62\u5f0f\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u6a21\u578b\u6216\u4efb\u52a1\u7684\u504f\u597d\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u51c6\u786e\u6216\u5197\u957f\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u5957\u96f6\u6837\u672c\u56fe\u95ee\u7b54\u4e13\u7528\u7684\u56fe\u8868\u793a\u5f62\u5f0f\uff0c\u63d0\u51faGRE\u6307\u6807\u8861\u91cf\u6027\u80fd\u4e0e\u7b80\u6d01\u6027\u5e73\u8861\uff0c\u5e76\u5f00\u53d1DynamicTRF\u6846\u67b6\u52a8\u6001\u9009\u62e9\u6700\u4f73\u8868\u793a\u5f62\u5f0f\u3002", "result": "\u57287\u4e2a\u9886\u57df\u5185\u7b97\u6cd5\u56fe\u95ee\u7b54\u4efb\u52a1\u548c2\u4e2a\u9886\u57df\u5916\u4efb\u52a1\u4e2d\uff0cDynamicTRF\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672c\u56fe\u95ee\u7b54\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DynamicTRF\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u56fe\u8868\u793a\u5f62\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u5728\u96f6\u6837\u672c\u56fe\u95ee\u7b54\u4e2d\u7684\u95ee\u9898\u3002"}}
{"id": "2508.06299", "pdf": "https://arxiv.org/pdf/2508.06299", "abs": "https://arxiv.org/abs/2508.06299", "authors": ["Henrique Henriques", "Hugo Louren\u00e7o", "Vasco Amaral", "Miguel Goul\u00e3o"], "title": "Improving the Developer Experience with a Low-Code Process Modelling Language", "categories": ["cs.SE"], "comment": "Preprint", "summary": "Context: The OutSystems Platform is a development environment composed of\nseveral DSLs, used to specify, quickly build, and validate web and mobile\napplications. The DSLs allow users to model different perspectives such as\ninterfaces and data models, define custom business logic and construct process\nmodels. Problem: The DSL for process modelling (Business Process Technology\n(BPT)), has a low adoption rate and is perceived as having usability problems\nhampering its adoption. This is problematic given the language maintenance\ncosts. Method: We used a combination of interviews, a critical review of BPT\nusing the \"Physics of Notation\" and empirical evaluations of BPT using the\nSystem Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a\nnew version of BPT, taking these inputs and Outsystems' engineers' culture into\naccount. Results: Evaluations conducted with 25 professional software engineers\nshowed an increase of the semantic transparency on the new version, from 31% to\n69%, an increase in the correctness of responses, from 51% to 89%, an increase\nin the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from\n36.50 to 20.78. These differences were statistically significant. Conclusions:\nThese results suggest that the new version of BPT significantly improved the\ndeveloper experience of the previous version. The end users' background with\nOutSystems had a relevant impact on the final concrete syntax choices and\nachieved usability indicators.", "AI": {"tldr": "\u7814\u7a76\u6539\u8fdb\u4e86OutSystems\u5e73\u53f0\u7684\u4e1a\u52a1\u6d41\u7a0b\u5efa\u6a21DSL\uff08BPT\uff09\uff0c\u901a\u8fc7\u8bbf\u8c08\u3001\u7b26\u53f7\u7269\u7406\u8bc4\u5ba1\u548c\u5b9e\u8bc1\u8bc4\u4f30\u663e\u8457\u63d0\u5347\u4e86\u8bed\u4e49\u900f\u660e\u5ea6\u3001\u6b63\u786e\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "BPT\u7684\u91c7\u7528\u7387\u4f4e\u4e14\u5b58\u5728\u53ef\u7528\u6027\u95ee\u9898\uff0c\u589e\u52a0\u4e86\u7ef4\u62a4\u6210\u672c\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u7ed3\u5408\u8bbf\u8c08\u3001\u7b26\u53f7\u7269\u7406\u8bc4\u5ba1\u53caSUS\u548cTLX\u8bc4\u4f30\uff0c\u5f00\u53d1\u65b0\u7248\u672cBPT\u3002", "result": "\u65b0\u7248\u672cBPT\u7684\u8bed\u4e49\u900f\u660e\u5ea6\u4ece31%\u63d0\u5347\u81f369%\uff0c\u6b63\u786e\u7387\u4ece51%\u5347\u81f389%\uff0cSUS\u5206\u6570\u4ece42.25\u589e\u81f364.78\uff0cTLX\u5206\u6570\u4ece36.50\u964d\u81f320.78\u3002", "conclusion": "\u65b0\u7248\u672cBPT\u663e\u8457\u6539\u5584\u4e86\u5f00\u53d1\u8005\u4f53\u9a8c\uff0c\u7528\u6237\u80cc\u666f\u5bf9\u6700\u7ec8\u8bed\u6cd5\u9009\u62e9\u548c\u53ef\u7528\u6027\u6307\u6807\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2508.06443", "pdf": "https://arxiv.org/pdf/2508.06443", "abs": "https://arxiv.org/abs/2508.06443", "authors": ["Debabrota Basu", "Udvas Das"], "title": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.GT"], "comment": null, "summary": "An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify\ndifferent types of bias (also known as unfairness) exhibited in the predictions\nof ML algorithms, and to design new algorithms to mitigate them. Often, the\ndefinitions of bias used in the literature are observational, i.e. they use the\ninput and output of a pre-trained algorithm to quantify a bias under concern.\nIn reality,these definitions are often conflicting in nature and can only be\ndeployed if either the ground truth is known or only in retrospect after\ndeploying the algorithm. Thus,there is a gap between what we want Fair ML to\nachieve and what it does in a dynamic social environment. Hence, we propose an\nalternative dynamic mechanism,\"Fair Game\",to assure fairness in the predictions\nof an ML algorithm and to adapt its predictions as the society interacts with\nthe algorithm over time. \"Fair Game\" puts together an Auditor and a Debiasing\nalgorithm in a loop around an ML algorithm. The \"Fair Game\" puts these two\ncomponents in a loop by leveraging Reinforcement Learning (RL). RL algorithms\ninteract with an environment to take decisions, which yields new observations\n(also known as data/feedback) from the environment and in turn, adapts future\ndecisions. RL is already used in algorithms with pre-fixed long-term fairness\ngoals. \"Fair Game\" provides a unique framework where the fairness goals can be\nadapted over time by only modifying the auditor and the different biases it\nquantifies. Thus,\"Fair Game\" aims to simulate the evolution of ethical and\nlegal frameworks in the society by creating an auditor which sends feedback to\na debiasing algorithm deployed around an ML system. This allows us to develop a\nflexible and adaptive-over-time framework to build Fair ML systems pre- and\npost-deployment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u516c\u5e73\u673a\u5236'Fair Game'\uff0c\u901a\u8fc7\u7ed3\u5408\u5ba1\u8ba1\u5458\u548c\u53bb\u504f\u7b97\u6cd5\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u9002\u5e94\u793e\u4f1a\u53cd\u9988\uff0c\u4ee5\u5b9e\u73b0\u7075\u6d3b\u7684\u516c\u5e73\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u89c2\u5bdf\u6027\u5b9a\u4e49\uff0c\u8fd9\u4e9b\u5b9a\u4e49\u5728\u5b9e\u9645\u52a8\u6001\u793e\u4f1a\u73af\u5883\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u7075\u6d3b\u9002\u5e94\u53d8\u5316\u3002", "method": "\u63d0\u51fa'Fair Game'\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5c06\u5ba1\u8ba1\u5458\u4e0e\u53bb\u504f\u7b97\u6cd5\u7ed3\u5408\uff0c\u52a8\u6001\u8c03\u6574\u516c\u5e73\u76ee\u6807\u4ee5\u9002\u5e94\u793e\u4f1a\u53cd\u9988\u3002", "result": "'Fair Game'\u80fd\u591f\u6a21\u62df\u793e\u4f1a\u4f26\u7406\u6846\u67b6\u7684\u6f14\u53d8\uff0c\u4e3a\u90e8\u7f72\u524d\u548c\u90e8\u7f72\u540e\u7684\u516c\u5e73\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "'Fair Game'\u4e3a\u89e3\u51b3\u516c\u5e73\u673a\u5668\u5b66\u4e60\u5728\u52a8\u6001\u793e\u4f1a\u4e2d\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u52a8\u6001\u673a\u5236\u3002"}}
{"id": "2508.05940", "pdf": "https://arxiv.org/pdf/2508.05940", "abs": "https://arxiv.org/abs/2508.05940", "authors": ["Kathy Cheng", "Alison Olechowski", "Shurui Zhou"], "title": "It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design", "categories": ["cs.HC"], "comment": "To be published in the Proceedings of the ACM on Human-Computer\n  Interaction, Volume 9, Issue CSCW2", "summary": "In today's landscape, hardware development teams face increasing demands for\nbetter quality products, greater innovation, and shorter manufacturing lead\ntimes. Despite the need for more efficient and effective processes, hardware\ndesigners continue to struggle with a lack of awareness of design changes and\nother collaborators' actions, a persistent issue in decades of CSCW research.\nOne significant and unaddressed challenge is understanding and managing\ndependencies between 3D CAD (computer-aided design) models, especially when\nproducts can contain thousands of interconnected components. In this two-phase\nformative study, we explore designers' pain points of CAD dependency management\nthrough a thematic analysis of 100 online forum discussions and semi-structured\ninterviews with 10 designers. We identify nine key challenges related to the\ntraceability, navigation, and consistency of CAD dependencies, that harm the\neffective coordination of hardware development teams. To address these\nchallenges, we propose design goals and necessary features to enhance hardware\ndesigners' awareness and management of dependencies, ultimately with the goal\nof improving collaborative workflows.", "AI": {"tldr": "\u786c\u4ef6\u5f00\u53d1\u56e2\u961f\u9762\u4e34\u63d0\u9ad8\u4ea7\u54c1\u8d28\u91cf\u3001\u521b\u65b0\u548c\u7f29\u77ed\u5236\u9020\u5468\u671f\u7684\u9700\u6c42\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8bbe\u8ba1\u53d8\u66f4\u548c\u534f\u4f5c\u884c\u4e3a\u7684\u7ba1\u7406\u610f\u8bc6\u3002\u7814\u7a76\u901a\u8fc7\u5206\u6790\u8bba\u575b\u8ba8\u8bba\u548c\u8bbe\u8ba1\u5e08\u8bbf\u8c08\uff0c\u63d0\u51fa\u6539\u55843D CAD\u4f9d\u8d56\u7ba1\u7406\u7684\u8bbe\u8ba1\u76ee\u6807\u548c\u529f\u80fd\u3002", "motivation": "\u786c\u4ef6\u8bbe\u8ba1\u5e08\u5728\u7ba1\u74063D CAD\u6a21\u578b\u4f9d\u8d56\u5173\u7cfb\u65f6\u9762\u4e34\u56f0\u96be\uff0c\u5f71\u54cd\u4e86\u56e2\u961f\u534f\u4f5c\u6548\u7387\uff0c\u4e9f\u9700\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u4e3b\u9898\u5206\u6790100\u4e2a\u5728\u7ebf\u8bba\u575b\u8ba8\u8bba\u548c10\u4f4d\u8bbe\u8ba1\u5e08\u7684\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u7814\u7a76\u4e86CAD\u4f9d\u8d56\u7ba1\u7406\u7684\u75db\u70b9\u3002", "result": "\u7814\u7a76\u786e\u5b9a\u4e869\u4e2a\u4e0e\u4f9d\u8d56\u5173\u7cfb\u7684\u53ef\u8ffd\u6eaf\u6027\u3001\u5bfc\u822a\u548c\u4e00\u81f4\u6027\u76f8\u5173\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u534f\u4f5c\u6d41\u7a0b\u7684\u8bbe\u8ba1\u76ee\u6807\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347\u786c\u4ef6\u8bbe\u8ba1\u5e08\u5bf9\u4f9d\u8d56\u5173\u7cfb\u7684\u8ba4\u8bc6\u548c\u7ba1\u7406\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u65e8\u5728\u4f18\u5316\u534f\u4f5c\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2508.06339", "pdf": "https://arxiv.org/pdf/2508.06339", "abs": "https://arxiv.org/abs/2508.06339", "authors": ["Evelyne Ringoot", "Rabab Alomairy", "Valentin Churavy", "Alan Edelman"], "title": "Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision", "categories": ["cs.DC", "cs.MS"], "comment": "12 pages, 6 figures, 4 tables", "summary": "This paper presents a portable, GPU-accelerated implementation of a QR-based\nsingular value computation algorithm in Julia. The singular value ecomposition\n(SVD) is a fundamental numerical tool in scientific computing and machine\nlearning, providing optimal low-rank matrix approximations. Its importance has\nincreased even more in large-scale machine learning pipelines, including large\nlanguage models (LLMs), where it enables low-rank adaptation (LoRA). The\nimplemented algorithm is based on the classic two-stage QR reduction,\nconsisting of successive matrix reduction to band form and bidiagonal form. Our\nimplementation leverages Julia's multiple dispatch and metaprogramming\ncapabilities, integrating with the GPUArrays and KernelAbstractions frameworks\nto provide a unified type and hardware-agnostic function. It supports diverse\nGPU architectures and data types, and is, to our knowledge, the first\nGPU-accelerated singular value implementation to support Apple Metal GPUs and\nhalf precision. Performance results on multiple GPU backends and data types\ndemonstrate that portability does not require sacrificing performance: the\nunified function outperforms most linear algebra libraries (MAGMA, SLATE,\nrocSOLVER, oneMKL) for matrix sizes larger than 1024x1024, and achieves 80%-90%\nof the performance of cuSOLVER for large matrices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eQR\u5206\u89e3\u7684GPU\u52a0\u901fSVD\u7b97\u6cd5\u5728Julia\u4e2d\u7684\u53ef\u79fb\u690d\u5b9e\u73b0\uff0c\u652f\u6301\u591a\u79cdGPU\u67b6\u6784\u548c\u6570\u636e\u7c7b\u578b\uff0c\u6027\u80fd\u63a5\u8fd1\u6216\u4f18\u4e8e\u4e3b\u6d41\u7ebf\u6027\u4ee3\u6570\u5e93\u3002", "motivation": "SVD\u5728\u79d1\u5b66\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\uff08\u5982LLMs\uff09\u4e2d\u7528\u4e8e\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u3002\u73b0\u6709\u5b9e\u73b0\u7f3a\u4e4f\u5bf9Apple Metal GPU\u548c\u534a\u7cbe\u5ea6\u7684\u652f\u6301\uff0c\u4e14\u6027\u80fd\u4f18\u5316\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u7684\u4e24\u9636\u6bb5QR\u5206\u89e3\uff08\u77e9\u9635\u964d\u4e3a\u5e26\u72b6\u548c\u53cc\u5bf9\u89d2\u5f62\u5f0f\uff09\uff0c\u5229\u7528Julia\u7684\u591a\u91cd\u5206\u53d1\u548c\u5143\u7f16\u7a0b\u80fd\u529b\uff0c\u4e0eGPUArrays\u548cKernelAbstractions\u6846\u67b6\u96c6\u6210\uff0c\u5b9e\u73b0\u786c\u4ef6\u65e0\u5173\u7684\u7edf\u4e00\u51fd\u6570\u3002", "result": "\u6027\u80fd\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u5b9e\u73b0\u652f\u6301\u591aGPU\u67b6\u6784\u548c\u6570\u636e\u7c7b\u578b\uff08\u5305\u62ecMetal GPU\u548c\u534a\u7cbe\u5ea6\uff09\uff0c\u57281024x1024\u4ee5\u4e0a\u77e9\u9635\u4e2d\u6027\u80fd\u4f18\u4e8eMAGMA\u3001SLATE\u7b49\u5e93\uff0c\u63a5\u8fd1cuSOLVER\u768480%-90%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u53ef\u79fb\u690d\u6027\u4e0e\u9ad8\u6027\u80fd\u53ef\u4ee5\u5171\u5b58\uff0c\u4e3aGPU\u52a0\u901f\u7684SVD\u7b97\u6cd5\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06365", "pdf": "https://arxiv.org/pdf/2508.06365", "abs": "https://arxiv.org/abs/2508.06365", "authors": ["Toufique Ahmed", "Jatin Ganhotra", "Avraham Shinnar", "Martin Hirzel"], "title": "Execution-Feedback Driven Test Generation from SWE Issues", "categories": ["cs.SE"], "comment": null, "summary": "A software engineering issue (SWE issue) is easier to resolve when\naccompanied by a reproduction test. Unfortunately, most issues do not come with\nfunctioning reproduction tests, so this paper explores how to generate them\nautomatically. The primary challenge in this setting is that the code to be\ntested is either missing or wrong, as evidenced by the existence of the issue\nin the first place. This has held back test generation for this setting:\nwithout the correct code to execute, it is difficult to leverage execution\nfeedback to generate good tests. This paper introduces novel techniques for\nleveraging execution feedback to get around this problem, implemented in a new\nreproduction test generator called e-Otter++. Experiments show that e-Otter++\nrepresents a leap ahead in the state-of-the-art for this problem, generating\ntests with an average fail-to-pass rate of 63% on the TDD-Bench Verified\nbenchmark.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u81ea\u52a8\u751f\u6210\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u7684\u91cd\u73b0\u6d4b\u8bd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3ae-Otter++\u7684\u65b0\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u4ee3\u7801\u7f3a\u5931\u6216\u9519\u8bef\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u65f6\uff0c\u91cd\u73b0\u6d4b\u8bd5\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u5927\u591a\u6570\u95ee\u9898\u7f3a\u4e4f\u6709\u6548\u7684\u6d4b\u8bd5\uff0c\u672c\u6587\u65e8\u5728\u81ea\u52a8\u751f\u6210\u8fd9\u4e9b\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa\u4e86e-Otter++\u5de5\u5177\uff0c\u5229\u7528\u6267\u884c\u53cd\u9988\u6280\u672f\u7ed5\u8fc7\u4ee3\u7801\u7f3a\u5931\u6216\u9519\u8bef\u7684\u95ee\u9898\u3002", "result": "\u5728TDD-Bench Verified\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0ce-Otter++\u7684\u5e73\u5747fail-to-pass\u7387\u8fbe\u523063%\u3002", "conclusion": "e-Otter++\u5728\u81ea\u52a8\u751f\u6210\u91cd\u73b0\u6d4b\u8bd5\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u7684\u89e3\u51b3\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.06000", "pdf": "https://arxiv.org/pdf/2508.06000", "abs": "https://arxiv.org/abs/2508.06000", "authors": ["Wei Xiang", "Ziyue Lei", "Haoyuan Che", "Fangyuan Ye", "Xueting Wu", "Lingyun Sun"], "title": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Operational skill learning, inherently physical and reliant on hands-on\npractice and kinesthetic feedback, has yet to be effectively replicated in\nlarge language model (LLM)-supported training. Current LLM training assistants\nprimarily generate customized textual feedback, neglecting the crucial\nkinesthetic modality. This gap derives from the textual and uncertain nature of\nLLMs, compounded by concerns on user acceptance of LLM driven body control. To\nbridge this gap and realize the potential of collaborative human-LLM action,\nthis work explores human experience of LLM driven kinesthetic assistance.\nSpecifically, we introduced an \"Align-Analyze-Adjust\" strategy and developed\nFlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS)\nfor flight skill acquisition, a representative operational skill domain.\nFlightAxis learns flight skills from manuals and guides forearm movements\nduring simulated flight tasks. Our results demonstrate high user acceptance of\nLLM-mediated body control and significantly reduced task completion times.\nCrucially, trainees reported that this kinesthetic assistance enhanced their\nawareness of operation flaws and fostered increased engagement in the training\nprocess, rather than relieving perceived load. This work demonstrated the\npotential of kinesthetic LLM training in operational skill acquisition.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7LLM\u9a71\u52a8\u7684\u52a8\u89c9\u8f85\u52a9\u5728\u64cd\u4f5c\u6280\u80fd\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u5f00\u53d1\u4e86\u6574\u5408LLM\u4e0eEMS\u7684\u5de5\u5177FlightAxis\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7528\u6237\u63a5\u53d7\u5ea6\u548c\u4efb\u52a1\u5b8c\u6210\u6548\u7387\u3002", "motivation": "\u5f53\u524dLLM\u57f9\u8bad\u52a9\u624b\u4e3b\u8981\u63d0\u4f9b\u6587\u672c\u53cd\u9988\uff0c\u5ffd\u7565\u4e86\u5173\u952e\u7684\u52a8\u89c9\u6a21\u6001\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7d22LLM\u9a71\u52a8\u7684\u52a8\u89c9\u8f85\u52a9\u5bf9\u64cd\u4f5c\u6280\u80fd\u5b66\u4e60\u7684\u6f5c\u529b\u3002", "method": "\u5f15\u5165\u201c\u5bf9\u9f50-\u5206\u6790-\u8c03\u6574\u201d\u7b56\u7565\uff0c\u5f00\u53d1\u4e86FlightAxis\u5de5\u5177\uff0c\u7ed3\u5408LLM\u4e0eEMS\u6280\u672f\uff0c\u7528\u4e8e\u98de\u884c\u6280\u80fd\u8bad\u7ec3\u3002", "result": "\u7528\u6237\u5bf9LLM\u9a71\u52a8\u7684\u8eab\u4f53\u63a7\u5236\u63a5\u53d7\u5ea6\u9ad8\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u663e\u8457\u51cf\u5c11\uff0c\u4e14\u52a8\u89c9\u8f85\u52a9\u589e\u5f3a\u4e86\u64cd\u4f5c\u7f3a\u9677\u7684\u610f\u8bc6\u548c\u8bad\u7ec3\u53c2\u4e0e\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u52a8\u89c9LLM\u57f9\u8bad\u5728\u64cd\u4f5c\u6280\u80fd\u83b7\u53d6\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.06406", "pdf": "https://arxiv.org/pdf/2508.06406", "abs": "https://arxiv.org/abs/2508.06406", "authors": ["Murtaza Rangwala", "Venugopal K R", "Rajkumar Buyya"], "title": "Blockchain-Enabled Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": "32 pages, 6 figures, chapter for edited book (Federated Learning:\n  Foundations and Applications)", "summary": "Blockchain-enabled federated learning (BCFL) addresses fundamental challenges\nof trust, privacy, and coordination in collaborative AI systems. This chapter\nprovides comprehensive architectural analysis of BCFL systems through a\nsystematic four-dimensional taxonomy examining coordination structures,\nconsensus mechanisms, storage architectures, and trust models. We analyze\ndesign patterns from blockchain-verified centralized coordination to fully\ndecentralized peer-to-peer networks, evaluating trade-offs in scalability,\nsecurity, and performance. Through detailed examination of consensus mechanisms\ndesigned for federated learning contexts, including Proof of Quality and Proof\nof Federated Learning, we demonstrate how computational work can be repurposed\nfrom arbitrary cryptographic puzzles to productive machine learning tasks. The\nchapter addresses critical storage challenges by examining multi-tier\narchitectures that balance blockchain's transaction constraints with neural\nnetworks' large parameter requirements while maintaining cryptographic\nintegrity. A technical case study of the TrustMesh framework illustrates\npractical implementation considerations in BCFL systems through distributed\nimage classification training, demonstrating effective collaborative learning\nacross IoT devices with highly non-IID data distributions while maintaining\ncomplete transparency and fault tolerance. Analysis of real-world deployments\nacross healthcare consortiums, financial services, and IoT security\napplications validates the practical viability of BCFL systems, achieving\nperformance comparable to centralized approaches while providing enhanced\nsecurity guarantees and enabling new models of trustless collaborative\nintelligence.", "AI": {"tldr": "\u533a\u5757\u94fe\u8054\u90a6\u5b66\u4e60(BCFL)\u901a\u8fc7\u56db\u7ef4\u5206\u7c7b\u6cd5\u5206\u6790\u534f\u8c03\u7ed3\u6784\u3001\u5171\u8bc6\u673a\u5236\u3001\u5b58\u50a8\u67b6\u6784\u548c\u4fe1\u4efb\u6a21\u578b\uff0c\u89e3\u51b3\u534f\u4f5cAI\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u3001\u9690\u79c1\u548c\u534f\u8c03\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u534f\u4f5cAI\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u3001\u9690\u79c1\u548c\u534f\u8c03\u6311\u6218\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u6280\u672f\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u7684\u900f\u660e\u5ea6\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u56db\u7ef4\u5206\u7c7b\u6cd5\u5206\u6790BCFL\u7cfb\u7edf\u7684\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5305\u62ec\u534f\u8c03\u7ed3\u6784\u3001\u5171\u8bc6\u673a\u5236\u3001\u5b58\u50a8\u67b6\u6784\u548c\u4fe1\u4efb\u6a21\u578b\uff0c\u5e76\u4ee5TrustMesh\u6846\u67b6\u4e3a\u6848\u4f8b\u7814\u7a76\u3002", "result": "BCFL\u7cfb\u7edf\u5728\u533b\u7597\u3001\u91d1\u878d\u670d\u52a1\u548c\u7269\u8054\u7f51\u5b89\u5168\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\u3002", "conclusion": "BCFL\u7cfb\u7edf\u901a\u8fc7\u533a\u5757\u94fe\u6280\u672f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u534f\u4f5c\u667a\u80fd\uff0c\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u5b89\u5168\u6027\uff0c\u9002\u7528\u4e8e\u5f02\u6784\u6570\u636e\u5206\u5e03\u7684\u590d\u6742\u573a\u666f\u3002"}}
{"id": "2508.06414", "pdf": "https://arxiv.org/pdf/2508.06414", "abs": "https://arxiv.org/abs/2508.06414", "authors": ["Dongze Li", "Songqiang Chen", "Jialun Cao", "Shing-Chi Cheung"], "title": "What Builds Effective In-Context Examples for Code Generation?", "categories": ["cs.SE"], "comment": null, "summary": "In-Context Learning (ICL) has emerged as a promising solution to enhance the\ncode generation capabilities of Large Language Models (LLMs), which\nincorporates code examples inside the prompt to let LLMs learn from\ndemonstrations. However, despite the substantial effectiveness of the code\nexample-based ICL approach, the specific features (e.g., identifier naming\nstyles, code formatting, solution insight) within the ICL-provided code\nexamples that significantly contribute to the ICL's effectiveness remain\nunclear. This paper systematically investigates the impact of various code\nfeatures on ICL with code examples through controlled ablation studies. Our\nfindings reveal that the appropriate naming of variables and functions is\ncrucial for effective code generation, with their elimination leading to\nperformance decreases of up to 30 percentage points. We further demonstrate\nthat LLMs prioritize semantically meaningful identifier names over formatting\nconventions, with language-specific preferences regarding identifier verbosity.\nAdditionally, our investigation into ICL's potential for enhancing reflection\nand inference capabilities reveals that current LLMs struggle to extract\ngeneralizable problem-solving insights from similar code solutions, despite\nbeing capable of utilizing direct information effectively. These findings are\nexpected to provide valuable insights for optimizing ICL systems in code\ngeneration applications and highlight fundamental challenges in\nreflection-based learning for code generation tasks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7801\u793a\u4f8b\u4e2d\u7279\u5b9a\u7279\u5f81\u5bf9ICL\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53d8\u91cf\u548c\u51fd\u6570\u547d\u540d\u662f\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51faLLMs\u5728\u53cd\u601d\u548c\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u63a2\u7d22\u4ee3\u7801\u793a\u4f8b\u4e2d\u54ea\u4e9b\u5177\u4f53\u7279\u5f81\uff08\u5982\u547d\u540d\u98ce\u683c\u3001\u683c\u5f0f\u7b49\uff09\u5bf9ICL\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\u8d77\u51b3\u5b9a\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u53d8\u91cf\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6027\u6d88\u878d\u7814\u7a76\u3002", "result": "\u53d8\u91cf\u548c\u51fd\u6570\u547d\u540d\u5bf9\u4ee3\u7801\u751f\u6210\u6548\u679c\u81f3\u5173\u91cd\u8981\uff0c\u5220\u9664\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u9ad8\u8fbe30%\uff1bLLMs\u66f4\u6ce8\u91cd\u8bed\u4e49\u800c\u975e\u683c\u5f0f\u3002", "conclusion": "\u4f18\u5316ICL\u7cfb\u7edf\u9700\u5173\u6ce8\u547d\u540d\uff0c\u540c\u65f6\u5f53\u524dLLMs\u5728\u4ece\u4ee3\u7801\u4e2d\u63d0\u53d6\u901a\u7528\u95ee\u9898\u89e3\u51b3\u89c1\u89e3\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002"}}
{"id": "2508.06056", "pdf": "https://arxiv.org/pdf/2508.06056", "abs": "https://arxiv.org/abs/2508.06056", "authors": ["Sizhe Cheng", "Jiaping Li", "Huanchen Wang", "Yuxin Ma"], "title": "RAGTrace: Understanding and Refining Retrieval-Generation Dynamics in Retrieval-Augmented Generation", "categories": ["cs.HC"], "comment": "19 pages, 9 figures, Accepted by UIST 2025", "summary": "Retrieval-Augmented Generation (RAG) systems have emerged as a promising\nsolution to enhance large language models (LLMs) by integrating external\nknowledge retrieval with generative capabilities. While significant\nadvancements have been made in improving retrieval accuracy and response\nquality, a critical challenge remains that the internal knowledge integration\nand retrieval-generation interactions in RAG workflows are largely opaque. This\npaper introduces RAGTrace, an interactive evaluation system designed to analyze\nretrieval and generation dynamics in RAG-based workflows. Informed by a\ncomprehensive literature review and expert interviews, the system supports a\nmulti-level analysis approach, ranging from high-level performance evaluation\nto fine-grained examination of retrieval relevance, generation fidelity, and\ncross-component interactions. Unlike conventional evaluation practices that\nfocus on isolated retrieval or generation quality assessments, RAGTrace enables\nan integrated exploration of retrieval-generation relationships, allowing users\nto trace knowledge sources and identify potential failure cases. The system's\nworkflow allows users to build, evaluate, and iterate on retrieval processes\ntailored to their specific domains of interest. The effectiveness of the system\nis demonstrated through case studies and expert evaluations on real-world RAG\napplications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86RAGTrace\uff0c\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u57fa\u4e8eRAG\u7cfb\u7edf\u7684\u5de5\u4f5c\u6d41\u4e2d\u7684\u68c0\u7d22\u548c\u751f\u6210\u52a8\u6001\u7684\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3RAG\u5de5\u4f5c\u6d41\u4e2d\u5185\u90e8\u77e5\u8bc6\u6574\u5408\u548c\u68c0\u7d22-\u751f\u6210\u4ea4\u4e92\u4e0d\u900f\u660e\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u4e13\u5bb6\u8bbf\u8c08\uff0c\u5f00\u53d1\u4e86\u652f\u6301\u591a\u5c42\u6b21\u5206\u6790\u7684\u7cfb\u7edf\uff0c\u5305\u62ec\u6027\u80fd\u8bc4\u4f30\u3001\u68c0\u7d22\u76f8\u5173\u6027\u3001\u751f\u6210\u5fe0\u5b9e\u6027\u7b49\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u548c\u4e13\u5bb6\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u5b9e\u9645RAG\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "RAGTrace\u80fd\u591f\u6574\u5408\u5206\u6790\u68c0\u7d22\u4e0e\u751f\u6210\u7684\u5173\u7cfb\uff0c\u5e2e\u52a9\u7528\u6237\u8ffd\u8e2a\u77e5\u8bc6\u6765\u6e90\u5e76\u8bc6\u522b\u6f5c\u5728\u5931\u8d25\u6848\u4f8b\u3002"}}
{"id": "2508.06301", "pdf": "https://arxiv.org/pdf/2508.06301", "abs": "https://arxiv.org/abs/2508.06301", "authors": ["Junhyeog Yun", "Minui Hong", "Gunhee Kim"], "title": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC"], "comment": "ICCV 2025", "summary": "Neural fields provide a memory-efficient representation of data, which can\neffectively handle diverse modalities and large-scale data. However, learning\nto map neural fields often requires large amounts of training data and\ncomputations, which can be limited to resource-constrained edge devices. One\napproach to tackle this limitation is to leverage Federated Meta-Learning\n(FML), but traditional FML approaches suffer from privacy leakage. To address\nthese issues, we introduce a novel FML approach called FedMeNF. FedMeNF\nutilizes a new privacy-preserving loss function that regulates privacy leakage\nin the local meta-optimization. This enables the local meta-learner to optimize\nquickly and efficiently without retaining the client's private data. Our\nexperiments demonstrate that FedMeNF achieves fast optimization speed and\nrobust reconstruction performance, even with few-shot or non-IID data across\ndiverse data modalities, while preserving client data privacy.", "AI": {"tldr": "FedMeNF\u662f\u4e00\u79cd\u65b0\u578b\u7684\u8054\u90a6\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u9690\u79c1\u4fdd\u62a4\u635f\u5931\u51fd\u6570\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\u548c\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u795e\u7ecf\u573a\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b66\u4e60\u65f6\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\uff0c\u4e14\u4f20\u7edfFML\u65b9\u6cd5\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002", "method": "FedMeNF\u5229\u7528\u9690\u79c1\u4fdd\u62a4\u635f\u5931\u51fd\u6570\uff0c\u5728\u672c\u5730\u5143\u4f18\u5316\u4e2d\u8c03\u8282\u9690\u79c1\u6cc4\u9732\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFedMeNF\u5728\u5c11\u6837\u672c\u6216\u975eIID\u6570\u636e\u4e0b\u4ecd\u80fd\u5feb\u901f\u4f18\u5316\u5e76\u4fdd\u6301\u91cd\u5efa\u6027\u80fd\u3002", "conclusion": "FedMeNF\u89e3\u51b3\u4e86\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u4e14\u5728\u591a\u6837\u6570\u636e\u6a21\u6001\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2508.05697", "pdf": "https://arxiv.org/pdf/2508.05697", "abs": "https://arxiv.org/abs/2508.05697", "authors": ["Marcos Guillermo Lammers", "Federico Hern\u00e1n Holik", "Alejandro Fern\u00e1ndez"], "title": "Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering", "categories": ["quant-ph", "cs.SE"], "comment": "in Spanish language", "summary": "Quantum computers represent a radical technological breakthrough in\ninformation processing by leveraging the principles of quantum mechanics to\nsolve highly complex problems beyond the reach of classical systems. However,\nin the current NISQ era (noisy intermediate-scale quantum devices), the\navailable hardware presents several limitations, such as a limited number of\nqubits, high error rates, and short coherence times. Efficient management of\nquantum resources, both physical and logical, is especially relevant in the\ndesign and deployment of quantum algorithms. In this paper, we analyze the role\nof resources in current uses of NISQ devices, identifying their relevance and\nimplications for quantum software engineering. With this contribution, we aim\nto strengthen the field of Quantum Resource Estimation (QRE) and move toward\nscalable and reliable quantum software development", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86NISQ\u65f6\u4ee3\u91cf\u5b50\u8d44\u6e90\u7ba1\u7406\u7684\u91cd\u8981\u6027\u53ca\u5176\u5bf9\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5f71\u54cd\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u673a\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5f53\u524d\u7684NISQ\u8bbe\u5907\u5b58\u5728\u8d44\u6e90\u9650\u5236\u548c\u9ad8\u9519\u8bef\u7387\u95ee\u9898\uff0c\u9700\u4f18\u5316\u8d44\u6e90\u7ba1\u7406\u3002", "method": "\u5206\u6790\u4e86NISQ\u8bbe\u5907\u4e2d\u91cf\u5b50\u8d44\u6e90\u7684\u4f5c\u7528\u53ca\u5176\u5f71\u54cd\u3002", "result": "\u5f3a\u8c03\u4e86\u91cf\u5b50\u8d44\u6e90\u4f30\u8ba1\uff08QRE\uff09\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u63a8\u52a8\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u91cf\u5b50\u8d44\u6e90\u7ba1\u7406\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2508.06065", "pdf": "https://arxiv.org/pdf/2508.06065", "abs": "https://arxiv.org/abs/2508.06065", "authors": ["Daniel Lee", "Nikhil Sharma", "Donghoon Shin", "DaEun Choi", "Harsh Sharma", "Jeonghwan Kim", "Heng Ji"], "title": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CV", "H.5.2; I.2.7"], "comment": null, "summary": "Generative AI has made image creation more accessible, yet aligning outputs\nwith nuanced creative intent remains challenging, particularly for non-experts.\nExisting tools often require users to externalize ideas through prompts or\nreferences, limiting fluid exploration. We introduce ThematicPlane, a system\nthat enables users to navigate and manipulate high-level semantic concepts\n(e.g., mood, style, or narrative tone) within an interactive thematic design\nplane. This interface bridges the gap between tacit creative intent and system\ncontrol. In our exploratory study (N=6), participants engaged in divergent and\nconvergent creative modes, often embracing unexpected results as inspiration or\niteration cues. While they grounded their exploration in familiar themes,\ndiffering expectations of how themes mapped to outputs revealed a need for more\nexplainable controls. Overall, ThematicPlane fosters expressive, iterative\nworkflows and highlights new directions for intuitive, semantics-driven\ninteraction in generative design tools.", "AI": {"tldr": "ThematicPlane\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u5e2e\u52a9\u7528\u6237\u901a\u8fc7\u9ad8\u7ea7\u8bed\u4e49\u6982\u5ff5\uff08\u5982\u60c5\u7eea\u3001\u98ce\u683c\uff09\u63a7\u5236\u751f\u6210AI\u8f93\u51fa\uff0c\u5f25\u8865\u521b\u610f\u610f\u56fe\u4e0e\u7cfb\u7edf\u63a7\u5236\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u751f\u6210AI\u5de5\u5177\u9700\u8981\u7528\u6237\u901a\u8fc7\u63d0\u793a\u6216\u5916\u90e8\u53c2\u8003\u8868\u8fbe\u521b\u610f\u610f\u56fe\uff0c\u9650\u5236\u4e86\u6d41\u7545\u7684\u521b\u610f\u63a2\u7d22\u3002ThematicPlane\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u4e3b\u9898\u8bbe\u8ba1\u5e73\u9762\uff0c\u7528\u6237\u53ef\u4ee5\u5bfc\u822a\u548c\u64cd\u7eb5\u9ad8\u7ea7\u8bed\u4e49\u6982\u5ff5\uff08\u5982\u60c5\u7eea\u3001\u98ce\u683c\u6216\u53d9\u4e8b\u57fa\u8c03\uff09\u3002", "result": "\u5728\u63a2\u7d22\u6027\u7814\u7a76\u4e2d\uff0c\u7528\u6237\u80fd\u591f\u901a\u8fc7\u719f\u6089\u4e3b\u9898\u5c55\u5f00\u521b\u610f\u63a2\u7d22\uff0c\u5c3d\u7ba1\u671f\u671b\u4e0e\u8f93\u51fa\u4e4b\u95f4\u7684\u6620\u5c04\u4ecd\u9700\u6539\u8fdb\u3002", "conclusion": "ThematicPlane\u652f\u6301\u8fed\u4ee3\u5f0f\u521b\u610f\u5de5\u4f5c\u6d41\uff0c\u5e76\u4e3a\u751f\u6210\u8bbe\u8ba1\u5de5\u5177\u7684\u76f4\u89c2\u8bed\u4e49\u9a71\u52a8\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.06489", "pdf": "https://arxiv.org/pdf/2508.06489", "abs": "https://arxiv.org/abs/2508.06489", "authors": ["Mustafa Doger", "Sennur Ulukus"], "title": "Voting-Based Semi-Parallel Proof-of-Work Protocol", "categories": ["cs.CR", "cs.DC", "cs.DM", "cs.IT", "math.IT", "math.PR"], "comment": null, "summary": "Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety\nguarantees, transaction throughput and confirmation latencies of Nakamoto\nconsensus. In this work, we first consider the existing parallel PoW protocols\nand develop hard-coded incentive attack structures. Our theoretical results and\nsimulations show that the existing parallel PoW protocols are more vulnerable\nto incentive attacks than the Nakamoto consensus, e.g., attacks have smaller\nprofitability threshold and they result in higher relative rewards. Next, we\nintroduce a voting-based semi-parallel PoW protocol that outperforms both\nNakamoto consensus and the existing parallel PoW protocols from most practical\nperspectives such as communication overheads, throughput, transaction\nconflicts, incentive compatibility of the protocol as well as a fair\ndistribution of transaction fees among the voters and the leaders. We use\nstate-of-the-art analysis to evaluate the consistency of the protocol and\nconsider Markov decision process (MDP) models to substantiate our claims about\nthe resilience of our protocol against incentive attacks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u73b0\u6709\u5e76\u884cPoW\u534f\u8bae\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6295\u7968\u7684\u534a\u5e76\u884cPoW\u534f\u8bae\uff0c\u4f18\u4e8e\u73b0\u6709\u534f\u8bae\u548cNakamoto\u5171\u8bc6\u3002", "motivation": "\u63d0\u9ad8Nakamoto\u5171\u8bc6\u7684\u5b89\u5168\u6027\u3001\u4ea4\u6613\u541e\u5410\u91cf\u548c\u786e\u8ba4\u5ef6\u8fdf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6295\u7968\u5f0f\u534a\u5e76\u884cPoW\u534f\u8bae\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6a21\u62df\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "\u65b0\u534f\u8bae\u5728\u901a\u4fe1\u5f00\u9500\u3001\u541e\u5410\u91cf\u3001\u6fc0\u52b1\u517c\u5bb9\u6027\u7b49\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u534f\u8bae\u3002", "conclusion": "\u534a\u5e76\u884cPoW\u534f\u8bae\u66f4\u5b89\u5168\u4e14\u9ad8\u6548\uff0c\u4e3a\u533a\u5757\u94fe\u5171\u8bc6\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05865", "pdf": "https://arxiv.org/pdf/2508.05865", "abs": "https://arxiv.org/abs/2508.05865", "authors": ["Kiana Kiashemshaki", "Elvis Nnaemeka Chukwuani", "Mohammad Jalili Torkamani", "Negin Mahmoudi"], "title": "Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models", "categories": ["cs.CR", "cs.SE", "C.2; D.2; D.4.1; D.4.4; D.4.6; I.2.7"], "comment": "9 pages, 8 figures, 1 table", "summary": "Blockchain technology offers a promising foundation for modernizing E-Voting\nsystems by enhancing transparency, decentralization, and security. Yet,\nreal-world adoption remains limited due to persistent challenges such as\nscalability constraints, high computational demands, and complex privacy\nrequirements. This paper presents a comparative framework for analyzing\nblockchain-based E-Voting architectures, consensus mechanisms, and\ncryptographic protocols. We examine the limitations of prevalent models like\nProof of Work, Proof of Stake, and Delegated Proof of Stake, and propose\noptimization strategies that include hybrid consensus, lightweight\ncryptography, and decentralized identity management. Additionally, we explore\nthe novel role of Large Language Models (LLMs) in smart contract generation,\nanomaly detection, and user interaction. Our findings offer a foundation for\ndesigning secure, scalable, and intelligent blockchain-based E-Voting systems\nsuitable for national-scale deployment. This work lays the groundwork for\nbuilding an end-to-end blockchain E-Voting prototype enhanced by LLM-guided\nsmart contract generation and validation, supported by a systematic framework\nand simulation-based analysis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u6bd4\u8f83\u6846\u67b6\uff0c\u5206\u6790\u4e86\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u7684\u67b6\u6784\u3001\u5171\u8bc6\u673a\u5236\u548c\u52a0\u5bc6\u534f\u8bae\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u7cfb\u7edf\u5728\u53ef\u6269\u5c55\u6027\u3001\u8ba1\u7b97\u9700\u6c42\u548c\u9690\u79c1\u65b9\u9762\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u533a\u5757\u94fe\u6280\u672f\u53ef\u4ee5\u63d0\u9ad8\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u3001\u53bb\u4e2d\u5fc3\u5316\u548c\u5b89\u5168\u6027\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u9762\u4e34\u53ef\u6269\u5c55\u6027\u3001\u8ba1\u7b97\u590d\u6742\u6027\u548c\u9690\u79c1\u8981\u6c42\u7b49\u9650\u5236\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u4f18\u5316\u8fd9\u4e9b\u7cfb\u7edf\uff0c\u4ee5\u9002\u5e94\u56fd\u5bb6\u89c4\u6a21\u90e8\u7f72\u7684\u9700\u6c42\u3002", "method": "\u8bba\u6587\u91c7\u7528\u6bd4\u8f83\u6846\u67b6\uff0c\u5206\u6790\u4e86\u5df2\u6709\u7684\u533a\u5757\u94fe\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u67b6\u6784\u3001\u5171\u8bc6\u673a\u5236\uff08\u5982PoW\u3001PoS\u548cDPoS\uff09\u548c\u52a0\u5bc6\u534f\u8bae\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u7684\u6df7\u5408\u5171\u8bc6\u3001\u8f7b\u91cf\u7ea7\u52a0\u5bc6\u548c\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\u7b49\u7b56\u7565\u3002\u540c\u65f6\u63a2\u7d22\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u667a\u80fd\u5408\u7ea6\u751f\u6210\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u7528\u6237\u4ea4\u4e92\u4e2d\u7684\u65b0\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u4f18\u5316\u5171\u8bc6\u673a\u5236\u548c\u52a0\u5bc6\u534f\u8bae\uff0c\u7ed3\u5408LLMs\u7684\u5e94\u7528\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u66f4\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e14\u667a\u80fd\u7684\u533a\u5757\u94fe\u7535\u5b50\u6295\u7968\u7cfb\u7edf\uff0c\u4e3a\u56fd\u5bb6\u89c4\u6a21\u90e8\u7f72\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u8bba\u6587\u4e3a\u5f00\u53d1\u7aef\u5230\u7aef\u7684\u533a\u5757\u94fe\u7535\u5b50\u6295\u7968\u539f\u578b\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u7ed3\u5408LLM\u5f15\u5bfc\u7684\u667a\u80fd\u5408\u7ea6\u751f\u6210\u548c\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u6846\u67b6\u548c\u4eff\u771f\u5206\u6790\u652f\u6301\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2508.06117", "pdf": "https://arxiv.org/pdf/2508.06117", "abs": "https://arxiv.org/abs/2508.06117", "authors": ["Maurice Koch", "Nelusa Pathmanathan", "Daniel Weiskopf", "Kuno Kurzhals"], "title": "A Multimodal Framework for Understanding Collaborative Design Processes", "categories": ["cs.HC"], "comment": "Accepted to IEEE VIS 2025", "summary": "An essential task in analyzing collaborative design processes, such as those\nthat are part of workshops in design studies, is identifying design outcomes\nand understanding how the collaboration between participants formed the results\nand led to decision-making. However, findings are typically restricted to a\nconsolidated textual form based on notes from interviews or observations. A\nchallenge arises from integrating different sources of observations, leading to\nlarge amounts and heterogeneity of collected data. To address this challenge we\npropose a practical, modular, and adaptable framework of workshop setup,\nmultimodal data acquisition, AI-based artifact extraction, and visual analysis.\nOur interactive visual analysis system, reCAPit, allows the flexible\ncombination of different modalities, including video, audio, notes, or gaze, to\nanalyze and communicate important workshop findings. A multimodal streamgraph\ndisplays activity and attention in the working area, temporally aligned topic\ncards summarize participants' discussions, and drill-down techniques allow\ninspecting raw data of included sources. As part of our research, we conducted\nsix workshops across different themes ranging from social science research on\nurban planning to a design study on band-practice visualization. The latter two\nare examined in detail and described as case studies. Further, we present\nconsiderations for planning workshops and challenges that we derive from our\nown experience and the interviews we conducted with workshop experts. Our\nresearch extends existing methodology of collaborative design workshops by\npromoting data-rich acquisition of multimodal observations, combined AI-based\nextraction and interactive visual analysis, and transparent dissemination of\nresults.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6reCAPit\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u91c7\u96c6\u548cAI\u63d0\u53d6\uff0c\u7ed3\u5408\u53ef\u89c6\u5316\u5206\u6790\uff0c\u6539\u8fdb\u534f\u4f5c\u8bbe\u8ba1\u5de5\u4f5c\u574a\u7684\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u534f\u4f5c\u8bbe\u8ba1\u5de5\u4f5c\u574a\u7684\u5206\u6790\u901a\u5e38\u4f9d\u8d56\u4e8e\u6587\u672c\u5f62\u5f0f\u7684\u89c2\u5bdf\u6216\u8bbf\u8c08\u8bb0\u5f55\uff0c\u96be\u4ee5\u6574\u5408\u591a\u6e90\u5f02\u6784\u6570\u636e\u3002", "method": "\u5f00\u53d1\u4e86reCAPit\u7cfb\u7edf\uff0c\u6574\u5408\u89c6\u9891\u3001\u97f3\u9891\u3001\u7b14\u8bb0\u7b49\u591a\u6a21\u6001\u6570\u636e\uff0c\u91c7\u7528AI\u63d0\u53d6\u548c\u53ef\u89c6\u5316\u5de5\u5177\uff08\u5982\u6d41\u56fe\u3001\u4e3b\u9898\u5361\u7247\uff09\u8fdb\u884c\u5206\u6790\u3002", "result": "\u901a\u8fc7\u516d\u4e2a\u5de5\u4f5c\u574a\u7684\u6848\u4f8b\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u9886\u57df\uff08\u5982\u57ce\u5e02\u89c4\u5212\u3001\u4e50\u961f\u5b9e\u8df5\u53ef\u89c6\u5316\uff09\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e30\u5bcc\u4e86\u534f\u4f5c\u8bbe\u8ba1\u5de5\u4f5c\u574a\u7684\u65b9\u6cd5\u5b66\uff0c\u5b9e\u73b0\u4e86\u591a\u6a21\u6001\u6570\u636e\u7684\u9ad8\u6548\u91c7\u96c6\u3001\u5206\u6790\u548c\u900f\u660e\u5316\u4f20\u64ad\u3002"}}
{"id": "2508.06300", "pdf": "https://arxiv.org/pdf/2508.06300", "abs": "https://arxiv.org/abs/2508.06300", "authors": ["Weihan Zhang", "Jun Tao"], "title": "Automatic Semantic Alignment of Flow Pattern Representations for Exploration with Large Language Models", "categories": ["cs.HC"], "comment": "Accepted by IEEE VIS 2025", "summary": "Explorative flow visualization allows domain experts to analyze complex flow\nstructures by interactively investigating flow patterns. However, traditional\nvisual interfaces often rely on specialized graphical representations and\ninteractions, which require additional effort to learn and use. Natural\nlanguage interaction offers a more intuitive alternative, but teaching machines\nto recognize diverse scientific concepts and extract corresponding structures\nfrom flow data poses a significant challenge. In this paper, we introduce an\nautomated framework that aligns flow pattern representations with the semantic\nspace of large language models (LLMs), eliminating the need for manual\nlabeling. Our approach encodes streamline segments using a denoising\nautoencoder and maps the generated flow pattern representations to LLM\nembeddings via a projector layer. This alignment empowers semantic matching\nbetween textual embeddings and flow representations through an attention\nmechanism, enabling the extraction of corresponding flow patterns based on\ntextual descriptions. To enhance accessibility, we develop an interactive\ninterface that allows users to query and visualize flow structures using\nnatural language. Through case studies, we demonstrate the effectiveness of our\nframework in enabling intuitive and intelligent flow exploration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u7684\u6d41\u6a21\u5f0f\u53ef\u89c6\u5316\u63a2\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u5bf9\u9f50\u5b9e\u73b0\u76f4\u89c9\u5316\u67e5\u8be2\u3002", "motivation": "\u4f20\u7edf\u6d41\u53ef\u89c6\u5316\u65b9\u6cd5\u9700\u8981\u5b66\u4e60\u590d\u6742\u56fe\u5f62\u754c\u9762\uff0c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u66f4\u76f4\u89c2\uff0c\u4f46\u673a\u5668\u8bc6\u522b\u79d1\u5b66\u6982\u5ff5\u548c\u63d0\u53d6\u6d41\u7ed3\u6784\u5b58\u5728\u6311\u6218\u3002", "method": "\u5229\u7528\u53bb\u566a\u81ea\u7f16\u7801\u5668\u7f16\u7801\u6d41\u7ebf\u7247\u6bb5\uff0c\u901a\u8fc7\u6295\u5f71\u5c42\u5c06\u6d41\u6a21\u5f0f\u8868\u793a\u4e0eLLM\u8bed\u4e49\u7a7a\u95f4\u5bf9\u9f50\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u6587\u672c\u63cf\u8ff0\u4e0e\u6d41\u6a21\u5f0f\u7684\u5339\u914d\u3002", "result": "\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u754c\u9762\uff0c\u7528\u6237\u53ef\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u548c\u53ef\u89c6\u5316\u6d41\u7ed3\u6784\uff0c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6d41\u63a2\u7d22\u63d0\u4f9b\u4e86\u76f4\u89c9\u5316\u548c\u667a\u80fd\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u964d\u4f4e\u4e86\u4f7f\u7528\u95e8\u69db\u3002"}}
{"id": "2508.05988", "pdf": "https://arxiv.org/pdf/2508.05988", "abs": "https://arxiv.org/abs/2508.05988", "authors": ["Wenhao Zeng", "Yaoning Wang", "Chao Hu", "Yuling Shi", "Chengcheng Wan", "Hongyu Zhang", "Xiaodong Gu"], "title": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal", "categories": ["cs.LG", "cs.SE"], "comment": "Code and model available at https://github.com/Zengwh02/ASAP", "summary": "Recently, Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in code reasoning by scaling up the length of Chain-of-Thought\n(CoT). However, excessively long reasoning traces introduce substantial\nchallenges in terms of training cost, inference latency, and deployment\nfeasibility. While various CoT compression approaches have emerged to address\nthis challenge, they face inherent trade-offs: token-level methods often\ndisrupt syntactic and logical coherence, while step-level methods based on\nperplexity fail to reliably capture the logically critical reasoning steps. In\nthis paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel\ncoarse-to-fine framework for CoT compression. ASAP first performs anchor-guided\npruning to preserve the core reasoning structure, which efficiently reduces the\nsearch space for subsequent processing. It then enables a logic-aware pruning\nby selecting logically essential reasoning steps based on a novel first-token\nsurprisal metric. Finally, ASAP teaches models to autonomously generate and\nleverage these concise CoTs at inference time, enabling efficient reasoning in\ncoding tasks. Experiments show that ASAP achieves state-of-the-art accuracy\nacross multiple code generation benchmarks while substantially reducing\ntraining and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,\nour approach reduces token generation by 23.5% and inference latency by 43.5%\ncompared to the strongest baseline, while achieving a competitive accuracy of\n36.19% in Pass@1. Our results highlight a promising direction for building\npowerful and efficient LRMs.", "AI": {"tldr": "ASAP\u6846\u67b6\u901a\u8fc7\u7c97\u5230\u7ec6\u7684\u526a\u679d\u65b9\u6cd5\u538b\u7f29CoT\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u957f\u63a8\u7406\u94fe\u5e26\u6765\u7684\u8bad\u7ec3\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u90e8\u7f72\u96be\u9898\u3002", "method": "\u91c7\u7528\u951a\u70b9\u5f15\u5bfc\u526a\u679d\u548c\u57fa\u4e8esurprisal\u7684\u7ec6\u7c92\u5ea6\u526a\u679d\uff0c\u786e\u4fdd\u903b\u8f91\u8fde\u8d2f\u6027\u3002", "result": "\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u663e\u8457\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u548ctoken\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "ASAP\u4e3a\u6784\u5efa\u9ad8\u6548\u5f3a\u5927\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u5411\u3002"}}
{"id": "2508.06349", "pdf": "https://arxiv.org/pdf/2508.06349", "abs": "https://arxiv.org/abs/2508.06349", "authors": ["Serena Tardelli", "Lorenzo Alvisi", "Lorenzo Cima", "Stefano Cresci", "Maurizio Tesconi"], "title": "Emoji Reactions on Telegram Often Reflect Social Approval Over Emotional Resonance", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Emoji reactions are a frequently used feature of messaging platforms. Prior\nwork mainly interpreted emojis as indicators of emotional resonance or user\nsentiment. However, emoji reactions may instead reflect broader social\ndynamics. Here, we investigate the communicative function of emoji reactions on\nTelegram by analyzing the relationship between the emotional and rhetorical\ncontent of messages and the emoji reactions they receive. We collect and\nanalyze over 650k Telegram messages that received at least one emoji reaction.\nWe annotate each message with sentiment, emotion, persuasion strategy, and\nspeech act labels, and infer the sentiment and emotion of emoji reactions using\nboth lexicons and large languages. We find a systematic mismatch between\nmessage sentiment and reaction sentiment, with positive reactions dominating\neven when the message is neutral or negative. We show that this pattern remains\nconsistent across rhetorical strategies and emotional tones, suggesting that\nemoji reactions may signal a degree of social approval rather than reflecting\nemotional resonance. Finally, we shed light on the communicative strategies\nthat predict greater emoji engagement. These findings have methodological\nimplications for sentiment analysis, as interpreting emoji reactions as direct\nproxies for emotional response may be misleading.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0cTelegram\u4e0a\u7684\u8868\u60c5\u7b26\u53f7\u53cd\u5e94\u66f4\u591a\u53cd\u6620\u793e\u4ea4\u8ba4\u53ef\u800c\u975e\u60c5\u611f\u5171\u9e23\uff0c\u4e0e\u4fe1\u606f\u60c5\u611f\u5185\u5bb9\u5b58\u5728\u7cfb\u7edf\u6027\u4e0d\u5339\u914d\u3002", "motivation": "\u63a2\u7a76\u8868\u60c5\u7b26\u53f7\u53cd\u5e94\u662f\u5426\u4ec5\u53cd\u6620\u60c5\u611f\u5171\u9e23\uff0c\u8fd8\u662f\u66f4\u5e7f\u6cdb\u7684\u793e\u4ea4\u52a8\u6001\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u8d85\u8fc765\u4e07\u6761Telegram\u6d88\u606f\uff0c\u6807\u6ce8\u60c5\u611f\u3001\u8bf4\u670d\u7b56\u7565\u7b49\uff0c\u7ed3\u5408\u8bcd\u5178\u548c\u5927\u6a21\u578b\u63a8\u65ad\u53cd\u5e94\u60c5\u611f\u3002", "result": "\u8868\u60c5\u53cd\u5e94\u4e0e\u4fe1\u606f\u60c5\u611f\u4e0d\u5339\u914d\uff0c\u6b63\u9762\u53cd\u5e94\u5360\u4e3b\u5bfc\uff0c\u6697\u793a\u5176\u4e3a\u793e\u4ea4\u8ba4\u53ef\u4fe1\u53f7\u800c\u975e\u60c5\u611f\u5171\u9e23\u3002", "conclusion": "\u8868\u60c5\u7b26\u53f7\u53cd\u5e94\u4e0d\u5b9c\u76f4\u63a5\u4f5c\u4e3a\u60c5\u611f\u5171\u9e23\u7684\u4ee3\u7406\uff0c\u9700\u8003\u8651\u5176\u793e\u4ea4\u529f\u80fd\u3002"}}
{"id": "2508.06354", "pdf": "https://arxiv.org/pdf/2508.06354", "abs": "https://arxiv.org/abs/2508.06354", "authors": ["Clara Rigaud"], "title": "Zombitron: towards a toolbox for repurposing obsolete smartphones into new interactive systems", "categories": ["cs.HC"], "comment": "Post-proceedings paper presented at LIMITS 2025: 11th Workshop on\n  Computing within Limits, 2025-06-26/27, Online", "summary": "This article explores the possibilities of reusing obsolete smartphones and\ntablets to build new interactive systems. Taking the case of a musical\ninstrument, I present my research into the design of a controller made from\nvarious of these obsolete smartphones. From the diagnostic stage to the\ncreation of a new autonomous electronic object, I document the process, the\nbarriers and the levers encountered. Based on these explorations and\ndiscussions with two professional musicians, I provide several insights into\nthe software and hardware aspects, with a view to continuing this work, towards\nthe creation of an open-source toolkit enabling anyone to build new interactive\nsystems with old devices. I discuss the implication of how a high-level\nweb-based approach could allow designers to enter the black box and foster\npermacomputing using smartphones.", "AI": {"tldr": "\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u5e9f\u65e7\u667a\u80fd\u624b\u673a\u548c\u5e73\u677f\u7535\u8111\u6784\u5efa\u65b0\u7684\u4ea4\u4e92\u7cfb\u7edf\uff0c\u4ee5\u97f3\u4e50\u63a7\u5236\u5668\u4e3a\u4f8b\uff0c\u7814\u7a76\u8bbe\u8ba1\u8fc7\u7a0b\u3001\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u5f00\u6e90\u5de5\u5177\u5305\u7684\u521d\u6b65\u6784\u60f3\u3002", "motivation": "\u51cf\u5c11\u7535\u5b50\u5e9f\u7269\uff0c\u901a\u8fc7\u91cd\u65b0\u5229\u7528\u5e9f\u65e7\u8bbe\u5907\u521b\u9020\u65b0\u7684\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u4fc3\u8fdb\u53ef\u6301\u7eed\u8ba1\u7b97\u3002", "method": "\u4ece\u8bca\u65ad\u5e9f\u65e7\u8bbe\u5907\u5230\u8bbe\u8ba1\u65b0\u63a7\u5236\u5668\uff0c\u8bb0\u5f55\u6574\u4e2a\u8fc7\u7a0b\uff0c\u5e76\u4e0e\u4e13\u4e1a\u97f3\u4e50\u5bb6\u8ba8\u8bba\u8f6f\u786c\u4ef6\u4f18\u5316\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9ad8\u7ea7\u7f51\u9875\u6280\u672f\u7684\u5f00\u6e90\u5de5\u5177\u5305\u6784\u60f3\uff0c\u652f\u6301\u8bbe\u8ba1\u5e08\u5229\u7528\u65e7\u8bbe\u5907\u5f00\u53d1\u65b0\u7cfb\u7edf\u3002", "conclusion": "\u5e9f\u65e7\u8bbe\u5907\u518d\u5229\u7528\u53ef\u884c\u4e14\u73af\u4fdd\uff0c\u672a\u6765\u53ef\u6269\u5c55\u4e3a\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u4fc3\u8fdb\u53ef\u6301\u7eed\u4ea4\u4e92\u8bbe\u8ba1\u3002"}}
{"id": "2508.06484", "pdf": "https://arxiv.org/pdf/2508.06484", "abs": "https://arxiv.org/abs/2508.06484", "authors": ["Yuvraj Virk", "Dongyu Liu"], "title": "Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data", "categories": ["cs.HC"], "comment": "Accepted by VL/HCC 2025", "summary": "Non-technical end-users increasingly rely on AI code generation to perform\ntechnical tasks like data analysis. However, large language models (LLMs)\nremain unreliable, and it is unclear whether end-users can effectively identify\nmodel errors $\\unicode{x2014}$ especially in realistic and domain-specific\nscenarios. We surveyed marketing and sales professionals to assess their\nability to critically evaluate LLM-generated analyses of marketing data.\nParticipants were shown natural language explanations of the AI's code,\nrepeatedly informed the AI often makes mistakes, and explicitly prompted to\nidentify them. Yet, participants frequently failed to detect critical flaws\nthat could compromise decision-making, many of which required no technical\nknowledge to recognize. To investigate why, we reformatted AI responses into\nclearly delineated steps and provided alternative approaches for each decision\nto support critical evaluation. While these changes had a positive effect,\nparticipants often struggled to reason through the AI's steps and alternatives.\nOur findings suggest that business professionals cannot reliably verify\nAI-generated data analyses on their own and explore reasons why to inform\nfuture designs. As non-programmers adopt code-generating AI for technical\ntasks, unreliable AI and insufficient human oversight poses risks of unsafe or\nlow-quality decisions.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u975e\u6280\u672f\u7528\u6237\u96be\u4ee5\u53ef\u9760\u5730\u8bc6\u522bAI\u751f\u6210\u7684\u4ee3\u7801\u9519\u8bef\uff0c\u5373\u4f7f\u5f97\u5230\u660e\u786e\u63d0\u793a\uff0c\u4e5f\u65e0\u6cd5\u6709\u6548\u9a8c\u8bc1\u6570\u636e\u5206\u6790\u7ed3\u679c\u3002\u8bbe\u8ba1\u6539\u8fdb\u867d\u6709\u4e00\u5b9a\u5e2e\u52a9\uff0c\u4f46\u7528\u6237\u4ecd\u9700\u66f4\u591a\u652f\u6301\u3002", "motivation": "\u968f\u7740\u975e\u6280\u672f\u7528\u6237\u4f9d\u8d56AI\u751f\u6210\u4ee3\u7801\u5b8c\u6210\u6280\u672f\u4efb\u52a1\uff0c\u4f46\u5176\u53ef\u9760\u6027\u5b58\u7591\uff0c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u7528\u6237\u662f\u5426\u80fd\u6709\u6548\u8bc6\u522bAI\u9519\u8bef\uff0c\u5c24\u5176\u662f\u5728\u7279\u5b9a\u9886\u57df\u4e2d\u3002", "method": "\u901a\u8fc7\u5bf9\u8425\u9500\u548c\u9500\u552e\u4e13\u4e1a\u4eba\u5458\u8fdb\u884c\u8c03\u67e5\uff0c\u5c55\u793aAI\u751f\u6210\u7684\u6570\u636e\u5206\u6790\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u5e76\u660e\u786e\u63d0\u793a\u9519\u8bef\uff0c\u89c2\u5bdf\u5176\u8bc6\u522b\u80fd\u529b\u3002\u968f\u540e\u6539\u8fdb\u663e\u793a\u683c\u5f0f\u4ee5\u652f\u6301\u7528\u6237\u8bc4\u4f30\u3002", "result": "\u5c3d\u7ba1\u63d0\u4f9b\u63d0\u793a\u548c\u6539\u8fdb\u683c\u5f0f\uff0c\u53c2\u4e0e\u8005\u4ecd\u96be\u4ee5\u53d1\u73b0\u5173\u952e\u9519\u8bef\u3002\u6539\u8fdb\u8bbe\u8ba1\u6709\u4e00\u5b9a\u6548\u679c\uff0c\u4f46\u7528\u6237\u4ecd\u96be\u4ee5\u7406\u89e3AI\u7684\u6b65\u9aa4\u548c\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u975e\u6280\u672f\u7528\u6237\u65e0\u6cd5\u72ec\u7acb\u53ef\u9760\u9a8c\u8bc1AI\u751f\u6210\u7684\u6570\u636e\u5206\u6790\uff0c\u672a\u6765\u8bbe\u8ba1\u9700\u63d0\u4f9b\u66f4\u591a\u652f\u6301\uff0c\u4ee5\u907f\u514d\u4f4e\u8d28\u91cf\u6216\u4e0d\u5b89\u5168\u7684\u51b3\u7b56\u3002"}}
{"id": "2508.05846", "pdf": "https://arxiv.org/pdf/2508.05846", "abs": "https://arxiv.org/abs/2508.05846", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG", "cs.RO", "68T01, 68T40", "K.7.4; K.4.1; I.2.9; H.1.2"], "comment": "Published in the Proceedings of the 2025 3rd International Conference\n  on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 tables", "summary": "As artificial intelligence (AI) and robotics increasingly permeate society,\nensuring the ethical behavior of these systems has become paramount. This paper\ncontends that transparency in AI decision-making processes is fundamental to\ndeveloping trustworthy and ethically aligned robotic systems. We explore how\ntransparency facilitates accountability, enables informed consent, and supports\nthe debugging of ethical algorithms. The paper outlines technical, ethical, and\npractical challenges in implementing transparency and proposes novel approaches\nto enhance it, including standardized metrics, explainable AI techniques, and\nuser-friendly interfaces. This paper introduces a framework that connects\ntechnical implementation with ethical considerations in robotic systems,\nfocusing on the specific challenges of achieving transparency in dynamic,\nreal-world contexts. We analyze how prioritizing transparency can impact public\ntrust, regulatory policies, and avenues for future research. By positioning\ntransparency as a fundamental element in ethical AI system design, we aim to\nadd to the ongoing discussion on responsible AI and robotics, providing\ndirection for future advancements in this vital field.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u548c\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u900f\u660e\u6027\u5bf9\u4f26\u7406\u884c\u4e3a\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u900f\u660e\u6027\u6709\u52a9\u4e8e\u95ee\u8d23\u3001\u77e5\u60c5\u540c\u610f\u548c\u4f26\u7406\u7b97\u6cd5\u8c03\u8bd5\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u63d0\u5347\u900f\u660e\u6027\u7684\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u548c\u673a\u5668\u4eba\u6280\u672f\u5728\u793e\u4f1a\u4e2d\u7684\u666e\u53ca\uff0c\u786e\u4fdd\u5176\u4f26\u7406\u884c\u4e3a\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u900f\u660e\u6027\u88ab\u8ba4\u4e3a\u662f\u6784\u5efa\u53ef\u4fe1\u8d56\u7cfb\u7edf\u7684\u5173\u952e\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u6807\u51c6\u5316\u7684\u900f\u660e\u5ea6\u5ea6\u91cf\u3001\u53ef\u89e3\u91caAI\u6280\u672f\u548c\u7528\u6237\u53cb\u597d\u754c\u9762\u7b49\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u6280\u672f\u548c\u4f26\u7406\u8003\u91cf\u8bbe\u8ba1\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u900f\u660e\u6027\u80fd\u591f\u63d0\u5347\u516c\u4f17\u4fe1\u4efb\u3001\u5f71\u54cd\u76d1\u7ba1\u653f\u7b56\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002", "conclusion": "\u900f\u660e\u6027\u5e94\u4f5c\u4e3a\u4f26\u7406AI\u7cfb\u7edf\u8bbe\u8ba1\u7684\u6838\u5fc3\u8981\u7d20\uff0c\u4e3a\u8d23\u4efbAI\u548c\u673a\u5668\u4eba\u6280\u672f\u7684\u53d1\u5c55\u63d0\u4f9b\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2508.05946", "pdf": "https://arxiv.org/pdf/2508.05946", "abs": "https://arxiv.org/abs/2508.05946", "authors": ["Nello Balossino", "Rossana Damiano", "Cristina Gena", "Alberto Lillo", "Anna Maria Marras", "Claudio Mattutino", "Antonio Pizzo", "Alessia Prin", "Fabiana Vernero"], "title": "Social and Telepresence Robots for Accessibility and Inclusion in Small Museums", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "There are still many museums that present accessibility barriers,\nparticularly regarding perceptual, cultural, and cognitive aspects. This is\nespecially evident in low-density population areas. The aim of the ROBSO-PM\nproject is to improve the accessibility of small museums through the use of\nsocial robots and social telepresence robots, focusing on three museums as case\nstudies: the Museum of the Holy Shroud in Turin, a small but globally known\ninstitution, and two lesser known mountain museums: the Museum of the Champlas\ndu Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and\nTraditions. The project explores two main applications for robots: as guides\nsupporting inclusive visits for foreign or disabled visitors, and as\ntelepresence tools allowing people with limited mobility to access museums\nremotely. From a research perspective, key topics include storytelling, robot\npersonality, empathy, personalization, and, in the case of telepresence,\ncollaboration between the robot and the person, with clearly defined roles and\nautonomy.", "AI": {"tldr": "ROBSO-PM\u9879\u76ee\u901a\u8fc7\u793e\u4ea4\u673a\u5668\u4eba\u548c\u8fdc\u7a0b\u793e\u4ea4\u673a\u5668\u4eba\u63d0\u5347\u5c0f\u578b\u535a\u7269\u9986\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u611f\u77e5\u3001\u6587\u5316\u548c\u8ba4\u77e5\u969c\u788d\u3002", "motivation": "\u8bb8\u591a\u535a\u7269\u9986\uff0c\u5c24\u5176\u662f\u4eba\u53e3\u7a00\u5c11\u5730\u533a\u7684\u535a\u7269\u9986\uff0c\u5728\u611f\u77e5\u3001\u6587\u5316\u548c\u8ba4\u77e5\u65b9\u9762\u5b58\u5728\u53ef\u8bbf\u95ee\u6027\u969c\u788d\uff0c\u9879\u76ee\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u9879\u76ee\u7814\u7a76\u4e86\u4e24\u4e2a\u4e3b\u8981\u5e94\u7528\uff1a\u673a\u5668\u4eba\u4f5c\u4e3a\u5bfc\u6e38\u652f\u6301\u5305\u5bb9\u6027\u8bbf\u95ee\uff0c\u4ee5\u53ca\u4f5c\u4e3a\u8fdc\u7a0b\u8bbf\u95ee\u5de5\u5177\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86\u53d9\u4e8b\u3001\u673a\u5668\u4eba\u4e2a\u6027\u3001\u5171\u60c5\u7b49\u7814\u7a76\u4e3b\u9898\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u90fd\u7075\u5723\u88f9\u5e03\u535a\u7269\u9986\u548c\u4e24\u4e2a\u5c71\u533a\u535a\u7269\u9986\uff09\uff0c\u9a8c\u8bc1\u4e86\u673a\u5668\u4eba\u5728\u63d0\u5347\u535a\u7269\u9986\u53ef\u8bbf\u95ee\u6027\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u673a\u5668\u4eba\u6280\u672f\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u535a\u7269\u9986\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u5c24\u5176\u662f\u5728\u504f\u8fdc\u6216\u5c0f\u578b\u535a\u7269\u9986\u4e2d\uff0c\u5c55\u793a\u4e86\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.05979", "pdf": "https://arxiv.org/pdf/2508.05979", "abs": "https://arxiv.org/abs/2508.05979", "authors": ["Xinming Yang", "Haasil Pujara", "Jun Li"], "title": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Published at COLM 2025", "summary": "While Large Language Models (LLMs) are often used as virtual tutors in\ncomputer science (CS) education, this approach can foster passive learning and\nover-reliance. This paper presents a novel pedagogical paradigm that inverts\nthis model: students act as instructors who must teach an LLM to solve\nproblems. To facilitate this, we developed strategies for designing questions\nwith engineered knowledge gaps that only a student can bridge, and we introduce\nSocrates, a system for deploying this method with minimal overhead. We\nevaluated our approach in an undergraduate course and found that this\nactive-learning method led to statistically significant improvements in student\nperformance compared to historical cohorts. Our work demonstrates a practical,\ncost-effective framework for using LLMs to deepen student engagement and\nmastery.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u6559\u5b66\u8303\u5f0f\uff0c\u8ba9\u5b66\u751f\u626e\u6f14\u6559\u5e08\u89d2\u8272\u6559\u5bfcLLM\u89e3\u51b3\u95ee\u9898\uff0c\u901a\u8fc7\u8bbe\u8ba1\u77e5\u8bc6\u7f3a\u53e3\u95ee\u9898\u63d0\u5347\u5b66\u751f\u4e3b\u52a8\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u4f20\u7edfLLM\u4f5c\u4e3a\u865a\u62df\u5bfc\u5e08\u5bb9\u6613\u5bfc\u81f4\u5b66\u751f\u88ab\u52a8\u5b66\u4e60\u548c\u4f9d\u8d56\uff0c\u9700\u627e\u5230\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u5229\u7528LLM\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002", "method": "\u5f00\u53d1\u7b56\u7565\u8bbe\u8ba1\u5177\u6709\u77e5\u8bc6\u7f3a\u53e3\u7684\u95ee\u9898\uff0c\u6784\u5efaSocrates\u7cfb\u7edf\u5b9e\u73b0\u8be5\u65b9\u6cd5\uff0c\u5e76\u5728\u672c\u79d1\u8bfe\u7a0b\u4e2d\u8bc4\u4f30\u6548\u679c\u3002", "result": "\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u5b66\u751f\u6210\u7ee9\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u5b9e\u7528\u6027\u548c\u6210\u672c\u6548\u76ca\u3002", "conclusion": "\u8be5\u8303\u5f0f\u901a\u8fc7LLM\u589e\u5f3a\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u638c\u63e1\u5ea6\uff0c\u4e3a\u6559\u80b2\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2508.06167", "pdf": "https://arxiv.org/pdf/2508.06167", "abs": "https://arxiv.org/abs/2508.06167", "authors": ["V\u00edt Gvo\u017ediak"], "title": "Pragmatics beyond humans: meaning, communication, and LLMs", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "The paper reconceptualizes pragmatics not as a subordinate, third dimension\nof meaning, but as a dynamic interface through which language operates as a\nsocially embedded tool for action. With the emergence of large language models\n(LLMs) in communicative contexts, this understanding needs to be further\nrefined and methodologically reconsidered. The first section challenges the\ntraditional semiotic trichotomy, arguing that connectionist LLM architectures\ndestabilize established hierarchies of meaning, and proposes the Human-Machine\nCommunication (HMC) framework as a more suitable alternative. The second\nsection examines the tension between human-centred pragmatic theories and the\nmachine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics\ncontinue to dominate, it relies on human-specific assumptions ill-suited to\npredictive systems like LLMs. Probabilistic pragmatics, particularly the\nRational Speech Act framework, offers a more compatible teleology by focusing\non optimization rather than truth-evaluation. The third section addresses the\nissue of substitutionalism in three forms - generalizing, linguistic, and\ncommunicative - highlighting the anthropomorphic biases that distort LLM\nevaluation and obscure the role of human communicative subjects. Finally, the\npaper introduces the concept of context frustration to describe the paradox of\nincreased contextual input paired with a collapse in contextual understanding,\nemphasizing how users are compelled to co-construct pragmatic conditions both\nfor the model and themselves. These arguments suggest that pragmatic theory may\nneed to be adjusted or expanded to better account for communication involving\ngenerative AI.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u6784\u60f3\u8bed\u7528\u5b66\uff0c\u5c06\u5176\u89c6\u4e3a\u8bed\u8a00\u4f5c\u4e3a\u793e\u4f1a\u5d4c\u5165\u884c\u52a8\u5de5\u5177\u7684\u52a8\u6001\u754c\u9762\uff0c\u800c\u975e\u610f\u4e49\u7684\u7b2c\u4e09\u7ef4\u5ea6\u3002\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5d1b\u8d77\uff0c\u4f5c\u8005\u6311\u6218\u4f20\u7edf\u8bed\u4e49\u5b66\u4e09\u5206\u6cd5\uff0c\u63d0\u51fa\u4eba\u673a\u901a\u4fe1\uff08HMC\uff09\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4eba\u7c7b\u4e2d\u5fc3\u4e0e\u673a\u5668\u4e2d\u5fc3\u8bed\u7528\u5b66\u7684\u51b2\u7a81\u3002", "motivation": "\u968f\u7740LLM\u5728\u901a\u4fe1\u4e2d\u7684\u666e\u53ca\uff0c\u4f20\u7edf\u8bed\u7528\u5b66\u7684\u5c40\u9650\u6027\u663e\u73b0\uff0c\u9700\u8981\u9002\u5e94AI\u901a\u4fe1\u7684\u65b0\u8303\u5f0f\u3002", "method": "\u901a\u8fc7\u5206\u6790LLM\u5bf9\u4f20\u7edf\u8bed\u4e49\u5b66\u7684\u5f71\u54cd\uff0c\u63d0\u51faHMC\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u6982\u7387\u8bed\u7528\u5b66\uff08\u5982\u7406\u6027\u8a00\u8bed\u884c\u4e3a\u6846\u67b6\uff09\u7684\u9002\u7528\u6027\u3002", "result": "\u63ed\u793a\u4e86LLM\u8bc4\u4f30\u4e2d\u7684\u4eba\u7c7b\u4e2d\u5fc3\u504f\u5dee\uff0c\u5e76\u63d0\u51fa\u201c\u8bed\u5883\u632b\u6298\u201d\u6982\u5ff5\uff0c\u63cf\u8ff0\u7528\u6237\u4e0e\u6a21\u578b\u5171\u540c\u6784\u5efa\u8bed\u7528\u6761\u4ef6\u7684\u73b0\u8c61\u3002", "conclusion": "\u8bed\u7528\u5b66\u7406\u8bba\u9700\u8c03\u6574\u4ee5\u6db5\u76d6\u751f\u6210\u5f0fAI\u53c2\u4e0e\u7684\u901a\u4fe1\uff0c\u5f3a\u8c03\u4f18\u5316\u800c\u975e\u771f\u503c\u8bc4\u4f30\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2508.06196", "pdf": "https://arxiv.org/pdf/2508.06196", "abs": "https://arxiv.org/abs/2508.06196", "authors": ["Nizi Nazar", "Ehsaneddin Asgari"], "title": "EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Emotional Intelligence (EI) is a critical yet underexplored dimension in the\ndevelopment of human-aligned LLMs. To address this gap, we introduce a unified,\npsychologically grounded four-layer taxonomy of EI tailored for large language\nmodels (LLMs), encompassing emotional tracking, cause inference, appraisal, and\nemotionally appropriate response generation. Building on this framework, we\npresent EICAP-Bench, a novel MCQ style multi-turn benchmark designed to\nevaluate EI capabilities in open-source LLMs across diverse linguistic and\ncultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma\n(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,\nidentifying Qwen2.5-Instruct as the strongest baseline. To assess the potential\nfor enhancing EI capabilities, we fine-tune both Qwen2.5-Base and\nQwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,\ninstruction-tuned dialogue dataset, in both English and Arabic. Our statistical\nanalysis reveals that among the five EI layers, only the Appraisal layer shows\nsignificant improvement through UC-based fine-tuning. These findings highlight\nthe limitations of existing pretraining and instruction-tuning paradigms in\nequipping LLMs with deeper emotional reasoning and underscore the need for\ntargeted data and modeling strategies for comprehensive EI alignment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u60c5\u611f\u667a\u529b\uff08EI\uff09\u56db\u5c42\u5206\u7c7b\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86EICAP-Bench\u57fa\u51c6\u8bc4\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u9884\u8bad\u7ec3\u548c\u6307\u4ee4\u8c03\u4f18\u65b9\u6cd5\u5728\u63d0\u5347LLM\u60c5\u611f\u63a8\u7406\u80fd\u529b\u4e0a\u6548\u679c\u6709\u9650\uff0c\u4ec5\u201c\u8bc4\u4f30\u201d\u5c42\u901a\u8fc7\u5fae\u8c03\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u60c5\u611f\u667a\u529b\uff08EI\uff09\u7ef4\u5ea6\u4e0a\u7684\u672a\u5145\u5206\u63a2\u7d22\u95ee\u9898\uff0c\u63a8\u52a8\u4eba\u673a\u5bf9\u9f50\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u56db\u5c42EI\u5206\u7c7b\u6cd5\uff08\u60c5\u611f\u8ffd\u8e2a\u3001\u56e0\u679c\u63a8\u65ad\u3001\u8bc4\u4f30\u3001\u60c5\u611f\u54cd\u5e94\u751f\u6210\uff09\uff0c\u6784\u5efaEICAP-Bench\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5bf9\u516d\u79cdLLM\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u5b9e\u9a8c\u9a8c\u8bc1\u6539\u8fdb\u6f5c\u529b\u3002", "result": "Qwen2.5-Instruct\u8868\u73b0\u6700\u4f73\uff1b\u5fae\u8c03\u5b9e\u9a8c\u4e2d\uff0c\u4ec5\u201c\u8bc4\u4f30\u201d\u5c42\u80fd\u529b\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u73b0\u6709\u65b9\u6cd5\u5728\u6df1\u5ea6\u60c5\u611f\u63a8\u7406\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u9700\u9488\u5bf9\u6027\u6570\u636e\u4e0e\u5efa\u6a21\u7b56\u7565\u4ee5\u5b9e\u73b0\u5168\u9762EI\u5bf9\u9f50\u3002"}}
{"id": "2508.06321", "pdf": "https://arxiv.org/pdf/2508.06321", "abs": "https://arxiv.org/abs/2508.06321", "authors": ["Durjoy Chandra Paul", "Gaurob Saha", "Md Amjad Hossain"], "title": "EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition", "categories": ["cs.SD", "cs.HC", "cs.LG"], "comment": "To be published in ICCCNT 2025 (16th International Conference on\n  Computing Communication and Networking Technologies)", "summary": "Recognizing emotional signals in speech has a significant impact on enhancing\nthe effectiveness of human-computer interaction (HCI). This study introduces\nEmoAugNet, a hybrid deep learning framework, that incorporates Long Short-Term\nMemory (LSTM) layers with one-dimensional Convolutional Neural Networks\n(1D-CNN) to enable reliable Speech Emotion Recognition (SER). The quality and\nvariety of the features that are taken from speech signals have a significant\nimpact on how well SER systems perform. A comprehensive speech data\naugmentation strategy was used to combine both traditional methods, such as\nnoise addition, pitch shifting, and time stretching, with a novel\ncombination-based augmentation pipeline to enhance generalization and reduce\noverfitting. Each audio sample was transformed into a high-dimensional feature\nvector using root mean square energy (RMSE), Mel-frequency Cepstral Coefficient\n(MFCC), and zero-crossing rate (ZCR). Our model with ReLU activation has a\nweighted accuracy of 95.78\\% and unweighted accuracy of 92.52\\% on the IEMOCAP\ndataset and, with ELU activation, has a weighted accuracy of 96.75\\% and\nunweighted accuracy of 91.28\\%. On the RAVDESS dataset, we get a weighted\naccuracy of 94.53\\% and 94.98\\% unweighted accuracy for ReLU activation and\n93.72\\% weighted accuracy and 94.64\\% unweighted accuracy for ELU activation.\nThese results highlight EmoAugNet's effectiveness in improving the robustness\nand performance of SER systems through integated data augmentation and hybrid\nmodeling.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faEmoAugNet\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u548c\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u6027\u80fd\u3002", "motivation": "\u63d0\u9ad8\u4eba\u673a\u4ea4\u4e92\u6548\u80fd\u9700\u51c6\u786e\u8bc6\u522b\u8bed\u97f3\u60c5\u611f\u4fe1\u53f7\u3002", "method": "\u4f7f\u7528LSTM\u548c1D-CNN\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u4f20\u7edf\u548c\u65b0\u578b\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u63d0\u53d6\u591a\u79cd\u8bed\u97f3\u7279\u5f81\u3002", "result": "\u5728IEMOCAP\u548cRAVDESS\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\uff08\u7ea695%\uff09\u3002", "conclusion": "EmoAugNet\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u6df7\u5408\u5efa\u6a21\uff0c\u6709\u6548\u63d0\u5347\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.06336", "pdf": "https://arxiv.org/pdf/2508.06336", "abs": "https://arxiv.org/abs/2508.06336", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Victor Oei", "Anna Penzkofer", "Andreas Bulling"], "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "comment": "16 pages", "summary": "We introduce Unsupervised Partner Design (UPD) - a population-free,\nmulti-agent reinforcement learning framework for robust ad-hoc teamwork that\nadaptively generates training partners without requiring pretrained partners or\nmanual parameter tuning. UPD constructs diverse partners by stochastically\nmixing an ego agent's policy with biased random behaviours and scores them\nusing a variance-based learnability metric that prioritises partners near the\nego agent's current learning frontier. We show that UPD can be integrated with\nunsupervised environment design, resulting in the first method enabling fully\nunsupervised curricula over both level and partner distributions in a\ncooperative setting. Through extensive evaluations on Overcooked-AI and the\nOvercooked Generalisation Challenge, we demonstrate that this dynamic partner\ncurriculum is highly effective: UPD consistently outperforms both\npopulation-based and population-free baselines as well as ablations. In a user\nstudy, we further show that UPD achieves higher returns than all baselines and\nwas perceived as significantly more adaptive, more human-like, a better\ncollaborator, and less frustrating.", "AI": {"tldr": "UPD\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u3001\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u9884\u8bad\u7ec3\u4f19\u4f34\u6216\u624b\u52a8\u8c03\u53c2\uff0c\u901a\u8fc7\u968f\u673a\u6df7\u5408\u7b56\u7565\u548c\u57fa\u4e8e\u65b9\u5dee\u7684\u5ea6\u91cf\u751f\u6210\u591a\u6837\u4f19\u4f34\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u9884\u8bad\u7ec3\u4f19\u4f34\u6216\u624b\u52a8\u8c03\u53c2\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u4f19\u4f34\u751f\u6210\u6846\u67b6\uff0c\u63d0\u5347\u534f\u4f5c\u4efb\u52a1\u7684\u9002\u5e94\u6027\u3002", "method": "\u901a\u8fc7\u968f\u673a\u6df7\u5408\u7b56\u7565\u751f\u6210\u4f19\u4f34\uff0c\u5e76\u7528\u57fa\u4e8e\u65b9\u5dee\u7684\u5ea6\u91cf\u8bc4\u4f30\u5176\u53ef\u5b66\u4e60\u6027\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u751f\u6210\u52a8\u6001\u8bfe\u7a0b\u3002", "result": "\u5728Overcooked\u73af\u5883\u4e2d\uff0cUPD\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u5176\u9002\u5e94\u6027\u3001\u534f\u4f5c\u6027\u66f4\u5f3a\u3002", "conclusion": "UPD\u4e3a\u534f\u4f5c\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u65e0\u76d1\u7763\u7684\u4f19\u4f34\u751f\u6210\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.06352", "pdf": "https://arxiv.org/pdf/2508.06352", "abs": "https://arxiv.org/abs/2508.06352", "authors": ["Christian Meske", "Justin Brenne", "Erdi Uenal", "Sabahat Oelcer", "Ayseguel Doganguen"], "title": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Current explainable AI (XAI) approaches prioritize algorithmic transparency\nand present explanations in abstract, non-adaptive formats that often fail to\nsupport meaningful end-user understanding. This paper introduces \"Explanatory\nAI\" as a complementary paradigm that leverages generative AI capabilities to\nserve as explanatory partners for human understanding rather than providers of\nalgorithmic transparency. While XAI reveals algorithmic decision processes for\nmodel validation, Explanatory AI addresses contextual reasoning to support\nhuman decision-making in sociotechnical contexts. We develop a definition and\nsystematic eight-dimensional conceptual model distinguishing Explanatory AI\nthrough narrative communication, adaptive personalization, and progressive\ndisclosure principles. Empirical validation through Rapid Contextual Design\nmethodology with healthcare professionals demonstrates that users consistently\nprefer context-sensitive, multimodal explanations over technical transparency.\nOur findings reveal the practical urgency for AI systems designed for human\ncomprehension rather than algorithmic introspection, establishing a\ncomprehensive research agenda for advancing user-centered AI explanation\napproaches across diverse domains and cultural contexts.", "AI": {"tldr": "\u4f20\u7edf\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u4ec5\u5173\u6ce8\u7b97\u6cd5\u900f\u660e\u5ea6\uff0c\u4f46\u96be\u4ee5\u6ee1\u8db3\u7528\u6237\u5b9e\u9645\u9700\u6c42\u3002\u672c\u6587\u63d0\u51fa\u201c\u89e3\u91ca\u6027AI\u201d\u4f5c\u4e3a\u8865\u5145\u8303\u5f0f\uff0c\u901a\u8fc7\u751f\u6210\u5f0fAI\u63d0\u4f9b\u66f4\u8d34\u8fd1\u4eba\u7c7b\u7406\u89e3\u7684\u89e3\u91ca\u3002\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u7528\u6237\u66f4\u504f\u597d\u60c5\u5883\u654f\u611f\u7684\u591a\u79cd\u6a21\u6001\u89e3\u91ca\u3002", "motivation": "\u4f20\u7edfXAI\u7684\u89e3\u91ca\u65b9\u5f0f\u62bd\u8c61\u4e14\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u652f\u6301\u7528\u6237\u7684\u7406\u89e3\u548c\u51b3\u7b56\uff0c\u5c24\u5176\u662f\u5728\u793e\u4f1a\u6280\u672f\u60c5\u5883\u4e2d\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u516b\u7ef4\u6982\u5ff5\u6a21\u578b\uff0c\u7ed3\u5408\u53d9\u4e8b\u6c9f\u901a\u3001\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u548c\u6e10\u8fdb\u62ab\u9732\u539f\u5219\uff0c\u5e76\u901a\u8fc7\u5feb\u901f\u60c5\u5883\u8bbe\u8ba1\u65b9\u6cd5\u5728\u533b\u7597\u9886\u57df\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u7528\u6237\u660e\u663e\u504f\u597d\u60c5\u5883\u654f\u611f\u3001\u591a\u6a21\u6001\u7684\u89e3\u91ca\uff0c\u800c\u975e\u6280\u672f\u900f\u660e\u5ea6\u7684\u5c55\u793a\u3002", "conclusion": "AI\u7cfb\u7edf\u5e94\u66f4\u6ce8\u91cd\u4eba\u7c7b\u7406\u89e3\u800c\u975e\u7b97\u6cd5\u900f\u660e\u5ea6\uff0c\u63a8\u52a8\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u89e3\u91ca\u65b9\u6cd5\u7814\u7a76\u3002"}}
{"id": "2508.06391", "pdf": "https://arxiv.org/pdf/2508.06391", "abs": "https://arxiv.org/abs/2508.06391", "authors": ["P\u00e9ter Mihajlik", "\u00c9va Sz\u00e9kely", "Piroska Barta", "M\u00e1t\u00e9 Soma K\u00e1d\u00e1r", "Gergely Dobsinszki", "L\u00e1szl\u00f3 T\u00f3th"], "title": "Improved Dysarthric Speech to Text Conversion via TTS Personalization", "categories": ["cs.SD", "cs.HC"], "comment": null, "summary": "We present a case study on developing a customized speech-to-text system for\na Hungarian speaker with severe dysarthria. State-of-the-art automatic speech\nrecognition (ASR) models struggle with zero-shot transcription of dysarthric\nspeech, yielding high error rates. To improve performance with limited real\ndysarthric data, we fine-tune an ASR model using synthetic speech generated via\na personalized text-to-speech (TTS) system. We introduce a method for\ngenerating synthetic dysarthric speech with controlled severity by leveraging\npremorbidity recordings of the given speaker and speaker embedding\ninterpolation, enabling ASR fine-tuning on a continuum of impairments.\nFine-tuning on both real and synthetic dysarthric speech reduces the character\nerror rate (CER) from 36-51% (zero-shot) to 7.3%. Our monolingual\nFastConformer_Hu ASR model significantly outperforms Whisper-turbo when\nfine-tuned on the same data, and the inclusion of synthetic speech contributes\nto an 18% relative CER reduction. These results highlight the potential of\npersonalized ASR systems for improving accessibility for individuals with\nsevere speech impairments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u4e2a\u6027\u5316TTS\u751f\u6210\u5408\u6210\u8bed\u97f3\uff0c\u5e76\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u5fae\u8c03ASR\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u4e25\u91cd\u6784\u97f3\u969c\u788d\u8bed\u97f3\u7684\u8bc6\u522b\u9519\u8bef\u7387\u3002", "motivation": "\u73b0\u6709ASR\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bc6\u522b\u6784\u97f3\u969c\u788d\u8bed\u97f3\u65f6\u9519\u8bef\u7387\u9ad8\uff0c\u9700\u901a\u8fc7\u6709\u9650\u771f\u5b9e\u6570\u636e\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5229\u7528\u4e2a\u6027\u5316TTS\u751f\u6210\u4e0d\u540c\u4e25\u91cd\u7a0b\u5ea6\u7684\u5408\u6210\u6784\u97f3\u969c\u788d\u8bed\u97f3\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u5fae\u8c03ASR\u6a21\u578b\u3002", "result": "\u5b57\u7b26\u9519\u8bef\u7387\u4ece36-51%\u964d\u81f37.3%\uff0c\u5408\u6210\u8bed\u97f3\u8d21\u732e18%\u76f8\u5bf9\u9519\u8bef\u7387\u964d\u4f4e\u3002", "conclusion": "\u4e2a\u6027\u5316ASR\u7cfb\u7edf\u53ef\u663e\u8457\u63d0\u5347\u4e25\u91cd\u6784\u97f3\u969c\u788d\u8005\u7684\u8bed\u8a00\u53ef\u53ca\u6027\u3002"}}
