{"id": "2507.14316", "pdf": "https://arxiv.org/pdf/2507.14316", "abs": "https://arxiv.org/abs/2507.14316", "authors": ["Xianhao Carton Liu", "Difan Jia", "Tongyu Nie", "Evan Suma Rosenberg", "Victoria Interrante", "Chen Zhu-Tian"], "title": "Can AR-Embedded Visualizations Foster Appropriate Reliance on AI in Spatial Decision Making? A Comparative Study of AR See-Through vs. 2D Minimap", "categories": ["cs.HC"], "comment": null, "summary": "In high-stakes, time-critical scenarios-such as emergency evacuation, first\nresponder prioritization, and crisis management -- decision-makers must rapidly\nchoose among spatial targets, such as exits, individuals to assist, or areas to\nsecure. Advances in indoor sensing and artificial intelligence (AI) can support\nthese decisions by visualizing real-time situational data and AI suggestions on\n2D maps. However, mentally mapping this information onto real-world spaces\nimposes significant cognitive load. This load can impair users' ability to\nappropriately judge AI suggestions, leading to inappropriate reliance (e.g.,\naccepting wrong AI suggestions or rejecting correct ones). Embedded\nvisualizations in Augmented Reality (AR), by directly overlaying information\nonto physical environments, may reduce this load and foster more deliberate,\nappropriate reliance on AI. But is this true? In this work, we conducted an\nempirical study (N = 32) comparing AR see-through (embedded visualization) and\n2D Minimap in time-critical, AI-assisted spatial target selection tasks.\nContrary to our expectations, users exhibited greater inappropriate reliance on\nAI in the AR condition. Our analysis further reveals that this is primarily due\nto over-reliance, with factors specific to embedded visualizations, such as\nperceptual challenges, visual proximity illusions, and highly realistic visual\nrepresentations. Nonetheless, embedded visualizations demonstrated notable\nbenefits in spatial reasoning, such as spatial mapping and egocentric spatial\nimagery. We conclude by discussing the empirical insights, deriving design\nimplications, and outlining important directions for future research on\nhuman-AI decision collaboration in AR.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4\u4e86AR\u548c2D\u5730\u56fe\u5728\u7d27\u6025\u51b3\u7b56\u4e2d\u7528\u6237\u5bf9AI\u5efa\u8bae\u7684\u4f9d\u8d56\u60c5\u51b5\uff0c\u53d1\u73b0AR\u53ef\u80fd\u56e0\u89c6\u89c9\u9519\u89c9\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u4f46\u63d0\u5347\u4e86\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\uff0c\u51b3\u7b56\u8005\u9700\u5feb\u901f\u9009\u62e9\u76ee\u6807\uff0cAI\u548c\u4f20\u611f\u6280\u672f\u53ef\u8f85\u52a9\u51b3\u7b56\uff0c\u4f46\u4fe1\u606f\u53ef\u89c6\u5316\u65b9\u5f0f\u53ef\u80fd\u5f71\u54cd\u7528\u6237\u5bf9AI\u7684\u5408\u7406\u4f9d\u8d56\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\uff08N=32\uff09\u6bd4\u8f83AR\u548c2D\u5730\u56fe\u5728AI\u8f85\u52a9\u76ee\u6807\u9009\u62e9\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "AR\u6761\u4ef6\u4e0b\u7528\u6237\u5bf9AI\u7684\u4f9d\u8d56\u4e0d\u5f53\u589e\u52a0\uff0c\u4e3b\u56e0\u662f\u89c6\u89c9\u9519\u89c9\u5bfc\u81f4\u7684\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u4f46AR\u5728\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u6709\u4f18\u52bf\u3002", "conclusion": "AR\u5d4c\u5165\u5f0f\u53ef\u89c6\u5316\u9700\u4f18\u5316\u4ee5\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u540c\u65f6\u53d1\u6325\u5176\u7a7a\u95f4\u63a8\u7406\u4f18\u52bf\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u4eba\u673a\u534f\u4f5c\u8bbe\u8ba1\u3002"}}
{"id": "2507.14384", "pdf": "https://arxiv.org/pdf/2507.14384", "abs": "https://arxiv.org/abs/2507.14384", "authors": ["Angjelin Hila", "Elliott Hauser"], "title": "Assessing the Reliability of Large Language Models for Deductive Qualitative Coding: A Comparative Study of ChatGPT Interventions", "categories": ["cs.HC", "cs.CL"], "comment": "Extended version of paper accepted for presentation at the ASIS&T\n  Annual Meeting 2025. 38 pages, 12 figures", "summary": "In this study, we investigate the use of large language models (LLMs),\nspecifically ChatGPT, for structured deductive qualitative coding. While most\ncurrent research emphasizes inductive coding applications, we address the\nunderexplored potential of LLMs to perform deductive classification tasks\naligned with established human-coded schemes. Using the Comparative Agendas\nProject (CAP) Master Codebook, we classified U.S. Supreme Court case summaries\ninto 21 major policy domains. We tested four intervention methods: zero-shot,\nfew-shot, definition-based, and a novel Step-by-Step Task Decomposition\nstrategy, across repeated samples. Performance was evaluated using standard\nclassification metrics (accuracy, F1-score, Cohen's kappa, Krippendorff's\nalpha), and construct validity was assessed using chi-squared tests and\nCramer's V. Chi-squared and effect size analyses confirmed that intervention\nstrategies significantly influenced classification behavior, with Cramer's V\nvalues ranging from 0.359 to 0.613, indicating moderate to strong shifts in\nclassification patterns. The Step-by-Step Task Decomposition strategy achieved\nthe strongest reliability (accuracy = 0.775, kappa = 0.744, alpha = 0.746),\nachieving thresholds for substantial agreement. Despite the semantic ambiguity\nwithin case summaries, ChatGPT displayed stable agreement across samples,\nincluding high F1 scores in low-support subclasses. These findings demonstrate\nthat with targeted, custom-tailored interventions, LLMs can achieve reliability\nlevels suitable for integration into rigorous qualitative coding workflows.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528ChatGPT\u8fdb\u884c\u7ed3\u6784\u5316\u6f14\u7ece\u5b9a\u6027\u7f16\u7801\uff0c\u6d4b\u8bd5\u4e86\u56db\u79cd\u5e72\u9884\u65b9\u6cd5\uff0c\u53d1\u73b0\u9010\u6b65\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u6548\u679c\u6700\u4f73\uff0c\u9002\u5408\u878d\u5165\u4e25\u683c\u7684\u5b9a\u6027\u7f16\u7801\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5f52\u7eb3\u7f16\u7801\uff0c\u672a\u5145\u5206\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6f14\u7ece\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f7f\u7528CAP\u4e3b\u4ee3\u7801\u4e66\u5bf9\u6700\u9ad8\u6cd5\u9662\u6848\u4f8b\u6458\u8981\u8fdb\u884c\u5206\u7c7b\uff0c\u6d4b\u8bd5\u4e86\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u57fa\u4e8e\u5b9a\u4e49\u53ca\u9010\u6b65\u4efb\u52a1\u5206\u89e3\u56db\u79cd\u7b56\u7565\u3002", "result": "\u9010\u6b65\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u8868\u73b0\u6700\u4f73\uff0c\u8fbe\u5230\u9ad8\u5ea6\u4e00\u81f4\u6027\uff08\u51c6\u786e\u73870.775\uff0ckappa 0.744\uff09\u3002\u5361\u65b9\u68c0\u9a8c\u548cCramer's V\u8bc1\u5b9e\u5e72\u9884\u7b56\u7565\u663e\u8457\u5f71\u54cd\u5206\u7c7b\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u5236\u5316\u5e72\u9884\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u8fbe\u5230\u9002\u5408\u4e25\u683c\u5b9a\u6027\u7f16\u7801\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u9760\u6027\u6c34\u5e73\u3002"}}
{"id": "2507.14418", "pdf": "https://arxiv.org/pdf/2507.14418", "abs": "https://arxiv.org/abs/2507.14418", "authors": ["Taufiq Daryanto", "Sophia Stil", "Xiaohan Ding", "Daniel Manesh", "Sang Won Lee", "Tim Lee", "Stephanie Lunn", "Sarah Rodriguez", "Chris Brown", "Eugenia Rho"], "title": "Designing Conversational AI to Support Think-Aloud Practice in Technical Interview Preparation for CS Students", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "One challenge in technical interviews is the think-aloud process, where\ncandidates verbalize their thought processes while solving coding tasks.\nDespite its importance, opportunities for structured practice remain limited.\nConversational AI offers potential assistance, but limited research explores\nuser perceptions of its role in think-aloud practice. To address this gap, we\nconducted a study with 17 participants using an LLM-based technical interview\npractice tool. Participants valued AI's role in simulation, feedback, and\nlearning from generated examples. Key design recommendations include promoting\nsocial presence in conversational AI for technical interview simulation,\nproviding feedback beyond verbal content analysis, and enabling crowdsourced\nthink-aloud examples through human-AI collaboration. Beyond feature design, we\nexamined broader considerations, including intersectional challenges and\npotential strategies to address them, how AI-driven interview preparation could\npromote equitable learning in computing careers, and the need to rethink AI's\nrole in interview practice by suggesting a research direction that integrates\nhuman-AI collaboration.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u6280\u672f\u9762\u8bd5\u4e2d\uff0c\u5229\u7528\u5bf9\u8bdd\u5f0fAI\u8f85\u52a9\u5019\u9009\u4eba\u7ec3\u4e60\u2018\u5927\u58f0\u601d\u8003\u2019\u8fc7\u7a0b\u7684\u7814\u7a76\u3002\u901a\u8fc7\u5b9e\u9a8c\uff0c\u7814\u7a76\u53d1\u73b0\u53c2\u4e0e\u8005\u5bf9AI\u5728\u6a21\u62df\u3001\u53cd\u9988\u548c\u5b66\u4e60\u793a\u4f8b\u4e2d\u7684\u4f5c\u7528\u6301\u79ef\u6781\u6001\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u6280\u672f\u9762\u8bd5\u4e2d\u7684\u2018\u5927\u58f0\u601d\u8003\u2019\u8fc7\u7a0b\u5bf9\u5019\u9009\u4eba\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u7ed3\u6784\u5316\u7ec3\u4e60\u673a\u4f1a\u3002\u5c3d\u7ba1\u5bf9\u8bdd\u5f0fAI\u6709\u6f5c\u529b\u8f85\u52a9\uff0c\u4f46\u7528\u6237\u5bf9\u5176\u4f5c\u7528\u7684\u8ba4\u77e5\u7814\u7a76\u6709\u9650\uff0c\u56e0\u6b64\u5f00\u5c55\u4e86\u672c\u7814\u7a76\u3002", "method": "\u7814\u7a76\u901a\u8fc717\u540d\u53c2\u4e0e\u8005\u4f7f\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6280\u672f\u9762\u8bd5\u7ec3\u4e60\u5de5\u5177\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u7528\u6237\u5bf9AI\u8f85\u52a9\u7684\u770b\u6cd5\u548c\u9700\u6c42\u3002", "result": "\u53c2\u4e0e\u8005\u8ba4\u53efAI\u5728\u6a21\u62df\u9762\u8bd5\u3001\u63d0\u4f9b\u53cd\u9988\u53ca\u751f\u6210\u5b66\u4e60\u793a\u4f8b\u4e2d\u7684\u4f5c\u7528\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u4fc3\u8fdb\u793e\u4ea4\u5b58\u5728\u611f\u3001\u6269\u5c55\u53cd\u9988\u5185\u5bb9\u548c\u4eba\u673a\u534f\u4f5c\u7b49\u5173\u952e\u8bbe\u8ba1\u5efa\u8bae\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u5173\u6ce8\u529f\u80fd\u8bbe\u8ba1\uff0c\u8fd8\u63a2\u8ba8\u4e86AI\u9a71\u52a8\u7684\u9762\u8bd5\u51c6\u5907\u5982\u4f55\u4fc3\u8fdb\u8ba1\u7b97\u804c\u4e1a\u7684\u516c\u5e73\u5b66\u4e60\uff0c\u5e76\u63d0\u51fa\u4e86\u4eba\u673a\u534f\u4f5c\u7814\u7a76\u65b9\u5411\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.14482", "pdf": "https://arxiv.org/pdf/2507.14482", "abs": "https://arxiv.org/abs/2507.14482", "authors": ["Qianhe Chen", "Yong Wang", "Yixin Yu", "Xiyuan Zhu", "Xuerou Yu", "Ran Wang"], "title": "Conch: Competitive Debate Analysis via Visualizing Clash Points and Hierarchical Strategies", "categories": ["cs.HC"], "comment": null, "summary": "In-depth analysis of competitive debates is essential for participants to\ndevelop argumentative skills and refine strategies, and further improve their\ndebating performance. However, manual analysis of unstructured and unlabeled\ntextual records of debating is time-consuming and ineffective, as it is\nchallenging to reconstruct contextual semantics and track logical connections\nfrom raw data. To address this, we propose Conch, an interactive visualization\nsystem that systematically analyzes both what is debated and how it is debated.\nIn particular, we propose a novel parallel spiral visualization that compactly\ntraces the multidimensional evolution of clash points and participant\ninteractions throughout debate process. In addition, we leverage large language\nmodels with well-designed prompts to automatically identify critical debate\nelements such as clash points, disagreements, viewpoints, and strategies,\nenabling participants to understand the debate context comprehensively.\nFinally, through two case studies on real-world debates and a\ncarefully-designed user study, we demonstrate Conch's effectiveness and\nusability for competitive debate analysis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aConch\u7684\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u7cfb\u7edf\uff0c\u7528\u4e8e\u5206\u6790\u7ade\u4e89\u6027\u8fa9\u8bba\u7684\u5185\u5bb9\u548c\u8fc7\u7a0b\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u5173\u952e\u8fa9\u8bba\u5143\u7d20\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u548c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u624b\u52a8\u5206\u6790\u65e0\u7ed3\u6784\u548c\u65e0\u6807\u8bb0\u7684\u8fa9\u8bba\u8bb0\u5f55\u8017\u65f6\u4e14\u4f4e\u6548\uff0c\u96be\u4ee5\u4ece\u539f\u59cb\u6570\u636e\u4e2d\u91cd\u5efa\u4e0a\u4e0b\u6587\u8bed\u4e49\u548c\u8ffd\u8e2a\u903b\u8f91\u8054\u7cfb\u3002", "method": "\u63d0\u51faConch\u7cfb\u7edf\uff0c\u91c7\u7528\u5e73\u884c\u87ba\u65cb\u53ef\u89c6\u5316\u8ffd\u8e2a\u8fa9\u8bba\u8fc7\u7a0b\u4e2d\u591a\u7ef4\u78b0\u649e\u70b9\u548c\u53c2\u4e0e\u8005\u4e92\u52a8\u7684\u6f14\u5316\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u5173\u952e\u8fa9\u8bba\u5143\u7d20\u3002", "result": "\u901a\u8fc7\u771f\u5b9e\u8fa9\u8bba\u6848\u4f8b\u548c\u7528\u6237\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86Conch\u5728\u8fa9\u8bba\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "Conch\u7cfb\u7edf\u4e3a\u7ade\u4e89\u6027\u8fa9\u8bba\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5206\u6790\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fa9\u8bba\u5206\u6790\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2507.14624", "pdf": "https://arxiv.org/pdf/2507.14624", "abs": "https://arxiv.org/abs/2507.14624", "authors": ["Yaru Liu", "Derek Nowrouzezahri", "Morgan Mcguire"], "title": "Real-Time Scene Reconstruction using Light Field Probes", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Reconstructing photo-realistic large-scale scenes from images, for example at\ncity scale, is a long-standing problem in computer graphics. Neural rendering\nis an emerging technique that enables photo-realistic image synthesis from\npreviously unobserved viewpoints; however, state-of-the-art neural rendering\nmethods have difficulty efficiently rendering a high complex large-scale scene\nbecause these methods typically trade scene size, fidelity, and rendering speed\nfor quality. The other stream of techniques utilizes scene geometries for\nreconstruction. But the cost of building and maintaining a large set of\ngeometry data increases as scene size grows. Our work explores novel view\nsynthesis methods that efficiently reconstruct complex scenes without explicit\nuse of scene geometries. Specifically, given sparse images of the scene\n(captured from the real world), we reconstruct intermediate, multi-scale,\nimplicit representations of scene geometries. In this way, our method avoids\nexplicitly relying on scene geometry, significantly reducing the computational\ncost of maintaining large 3D data. Unlike current methods, we reconstruct the\nscene using a probe data structure. Probe data hold highly accurate depth\ninformation of dense data points, enabling the reconstruction of highly complex\nscenes. By reconstructing the scene using probe data, the rendering cost is\nindependent of the complexity of the scene. As such, our approach combines\ngeometry reconstruction and novel view synthesis. Moreover, when rendering\nlarge-scale scenes, compressing and streaming probe data is more efficient than\nusing explicit scene geometry. Therefore, our neural representation approach\ncan potentially be applied to virtual reality (VR) and augmented reality (AR)\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a2\u9488\u6570\u636e\u7ed3\u6784\u7684\u9690\u5f0f\u8868\u793a\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u91cd\u5efa\u65e0\u9700\u663e\u5f0f\u51e0\u4f55\u7684\u5927\u89c4\u6a21\u590d\u6742\u573a\u666f\uff0c\u5e76\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u65b0\u89c6\u89d2\u5408\u6210\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u795e\u7ecf\u6e32\u67d3\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u6548\u7387\u548c\u590d\u6742\u5ea6\u7684\u77db\u76fe\uff0c\u4ee5\u53ca\u51e0\u4f55\u91cd\u5efa\u65b9\u6cd5\u7ef4\u62a4\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u63a2\u9488\u6570\u636e\u7ed3\u6784\u91cd\u5efa\u591a\u5c3a\u5ea6\u9690\u5f0f\u573a\u666f\u8868\u793a\uff0c\u907f\u514d\u4f9d\u8d56\u663e\u5f0f\u51e0\u4f55\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u6e32\u67d3\u6027\u80fd\u4e0e\u573a\u666f\u590d\u6742\u5ea6\u65e0\u5173\uff0c\u9002\u7528\u4e8eVR/AR\u7b49\u5e94\u7528\u3002", "conclusion": "\u63a2\u9488\u6570\u636e\u7ed3\u6784\u4e3a\u5927\u89c4\u6a21\u573a\u666f\u91cd\u5efa\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14256", "pdf": "https://arxiv.org/pdf/2507.14256", "abs": "https://arxiv.org/abs/2507.14256", "authors": ["Jakub Walczak", "Piotr Tomalak", "Artur Laskowski"], "title": "Impact of Code Context and Prompting Strategies on Automated Unit Test Generation with Modern General-Purpose Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Generative AI is gaining increasing attention in software engineering, where\ntesting remains an indispensable reliability mechanism. According to the widely\nadopted testing pyramid, unit tests constitute the majority of test cases and\nare often schematic, requiring minimal domain expertise. Automatically\ngenerating such tests under the supervision of software engineers can\nsignificantly enhance productivity during the development phase of the software\nlifecycle.\n  This paper investigates the impact of code context and prompting strategies\non the quality and adequacy of unit tests generated by various large language\nmodels (LLMs) across several families. The results show that including\ndocstrings notably improves code adequacy, while further extending context to\nthe full implementation yields definitely smaller gains. Notably, the\nchain-of-thought prompting strategy -- applied even to 'reasoning' models --\nachieves the best results, with up to 96.3\\% branch coverage, a 57\\% average\nmutation score, and near-perfect compilation success rate. Among the evaluated\nmodels, M5 (Gemini 2.5 Pro) demonstrated superior performance in both mutation\nscore and branch coverage being still in top in terms of compilation success\nrate.\n  All the code and resulting test suites are publicly available at\nhttps://github.com/peetery/LLM-analysis.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u7b56\u7565\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793a\u5305\u542b\u6587\u6863\u5b57\u7b26\u4e32\u80fd\u663e\u8457\u63d0\u5347\u4ee3\u7801\u5145\u5206\u6027\uff0c\u800c\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u7b56\u7565\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u4e3a\u63d0\u9ad8\u8f6f\u4ef6\u5f00\u53d1\u9636\u6bb5\u7684\u6548\u7387\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u751f\u6210\u5f0fAI\u81ea\u52a8\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u3002", "method": "\u5206\u6790\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u7b56\u7565\u5bf9\u591a\u79cdLLMs\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5305\u542b\u6587\u6863\u5b57\u7b26\u4e32\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u5145\u5206\u6027\uff0c\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u7b56\u7565\u6548\u679c\u6700\u597d\uff0c\u6a21\u578bM5\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f18\u5316\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u7b56\u7565\u53ef\u63d0\u5347\u6548\u679c\u3002"}}
{"id": "2507.14597", "pdf": "https://arxiv.org/pdf/2507.14597", "abs": "https://arxiv.org/abs/2507.14597", "authors": ["Eugene Armah", "Linda Amoako Bannning"], "title": "Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning", "categories": ["cs.DC", "cs.CV", "cs.LG", "cs.PF"], "comment": null, "summary": "Processing data at high speeds is becoming increasingly critical as digital\neconomies generate enormous data. The current paradigms for timely data\nprocessing are edge computing and data stream processing (DSP). Edge computing\nplaces resources closer to where data is generated, while stream processing\nanalyzes the unbounded high-speed data in motion. However, edge stream\nprocessing faces rapid workload fluctuations, complicating resource\nprovisioning. Inadequate resource allocation leads to bottlenecks, whereas\nexcess allocation results in wastage. Existing reactive methods, such as\nthreshold-based policies and queuing theory scale only after performance\ndegrades, potentially violating SLAs. Although reinforcement learning (RL)\noffers a proactive approach through agents that learn optimal runtime\nadaptation policies, it requires extensive simulation. Furthermore, predictive\nmachine learning models face online distribution and concept drift that\nminimize their accuracy. We propose a three-step solution to the proactive edge\nstream processing autoscaling problem. Firstly, a GRU neural network forecasts\nthe upstream load using real-world and synthetic DSP datasets. Secondly, a\ntransfer learning framework integrates the predictive model into an online\nstream processing system using the DTW algorithm and joint distribution\nadaptation to handle the disparities between offline and online domains.\nFinally, a horizontal autoscaling module dynamically adjusts the degree of\noperator parallelism, based on predicted load while considering edge resource\nconstraints. The lightweight GRU model for load predictions recorded up to\n1.3\\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, and\nProphet on the SMAPE and RMSE evaluation metrics, with lower training time than\nthe computationally intensive RL models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u6b65\u9aa4\u7684\u8fb9\u7f18\u6d41\u5904\u7406\u81ea\u52a8\u6269\u5c55\u65b9\u6cd5\uff0c\u5305\u62ecGRU\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u8d1f\u8f7d\u3001\u8f6c\u79fb\u5b66\u4e60\u6846\u67b6\u5904\u7406\u9886\u57df\u5dee\u5f02\uff0c\u4ee5\u53ca\u57fa\u4e8e\u9884\u6d4b\u8d1f\u8f7d\u7684\u52a8\u6001\u5e76\u884c\u5ea6\u8c03\u6574\u6a21\u5757\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u7ecf\u6d4e\u53d1\u5c55\uff0c\u9ad8\u901f\u6570\u636e\u5904\u7406\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u8fb9\u7f18\u6d41\u5904\u7406\u9762\u4e34\u8d44\u6e90\u5206\u914d\u96be\u9898\u3002\u73b0\u6709\u53cd\u5e94\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u5f3a\u5316\u5b66\u4e60\u7b49\u9884\u6d4b\u65b9\u6cd5\u53c8\u9700\u5927\u91cf\u4eff\u771f\u3002", "method": "1. GRU\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u4e0a\u6e38\u8d1f\u8f7d\uff1b2. \u8f6c\u79fb\u5b66\u4e60\u6846\u67b6\u6574\u5408\u9884\u6d4b\u6a21\u578b\uff0c\u5904\u7406\u79bb\u7ebf\u4e0e\u5728\u7ebf\u57df\u5dee\u5f02\uff1b3. \u52a8\u6001\u6c34\u5e73\u6269\u5c55\u6a21\u5757\u8c03\u6574\u64cd\u4f5c\u5e76\u884c\u5ea6\u3002", "result": "GRU\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0aSMAPE\u503c\u4f4e\u81f31.3\\%\uff0c\u4f18\u4e8eCNN\u3001ARIMA\u548cProphet\uff0c\u4e14\u8bad\u7ec3\u65f6\u95f4\u77ed\u4e8eRL\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u6d41\u5904\u7406\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u517c\u5177\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2507.14403", "pdf": "https://arxiv.org/pdf/2507.14403", "abs": "https://arxiv.org/abs/2507.14403", "authors": ["Sarunas Kalade", "Graham Schelle"], "title": "NPUEval: Optimizing NPU Kernels with LLMs and Open Source Compilers", "categories": ["cs.PL"], "comment": null, "summary": "Neural processing units (NPUs) are gaining prominence in power-sensitive\ndevices like client devices, with AI PCs being defined by their inclusion of\nthese specialized processors. Running AI workloads efficiently on these devices\nrequires libraries of optimized kernels. Creating efficient kernels demands\nexpertise in domain-specific C++ with vector intrinsics and in-depth knowledge\nof the target architecture. Unlike GPU programming, which has had years to\nmature, NPU programming is new, with smaller and more fragmented developer\ncommunities across hardware platforms. This fragmentation poses a challenge\nwhen utilizing LLMs to assist in writing NPU kernels, as domain-specific\noptimized code examples are underrepresented in LLM pre-training data.\n  In this paper we introduce NPUEval -- a benchmark for writing and evaluating\nNPU kernels, consisting of 102 common operators for machine learning workloads.\nWe evaluate LLM generated code on actual hardware based on both functional\ncorrectness and vectorization efficiency using open source compiler tools\ntargeting the AMD NPU. We evaluate a range of state-of-the-art LLMs with a mix\nof proprietary and open-weight models. Latest reasoning models like DeepSeek\nR1, show promising results achieving out-of-the-box 50%+ vectorization on\nselect kernels. However, the average score across the entire dataset remains\nroughly 10% even with compiler feedback and vectorized kernel examples --\nshowing that this is a challenging dataset even for frontier models. The\ndataset and evaluation code will be released with a permissive open source\nlicense, providing an essential benchmark for advancing research in code\ngeneration and NPU kernel optimization.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86NPUEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u751f\u6210\u7684NPU\u5185\u6838\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u5411\u91cf\u5316\u6548\u7387\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u524d\u6cbf\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "NPU\u7f16\u7a0b\u793e\u533a\u5206\u6563\u4e14\u7f3a\u4e4f\u4f18\u5316\u4ee3\u7801\u793a\u4f8b\uff0cLLM\u8f85\u52a9\u7f16\u5199\u9ad8\u6548\u5185\u6838\u9762\u4e34\u6311\u6218\uff0c\u9700\u6807\u51c6\u5316\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u63d0\u51faNPUEval\u57fa\u51c6\uff0c\u5305\u542b102\u4e2a\u5e38\u89c1\u8fd0\u7b97\u7b26\uff0c\u4f7f\u7528\u5f00\u6e90\u7f16\u8bd1\u5668\u5de5\u5177\u5728AMD NPU\u4e0a\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5982DeepSeek R1\u5728\u90e8\u5206\u5185\u6838\u4e0a\u5b9e\u73b050%+\u5411\u91cf\u5316\uff0c\u4f46\u6574\u4f53\u5e73\u5747\u4ec510%\uff0c\u663e\u793a\u4efb\u52a1\u96be\u5ea6\u5927\u3002", "conclusion": "NPUEval\u4e3a\u4ee3\u7801\u751f\u6210\u548cNPU\u4f18\u5316\u7814\u7a76\u63d0\u4f9b\u57fa\u51c6\uff0c\u6a21\u578b\u6027\u80fd\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2507.14183", "pdf": "https://arxiv.org/pdf/2507.14183", "abs": "https://arxiv.org/abs/2507.14183", "authors": ["Arash Aryapour"], "title": "Iran's Stealth Internet Blackout: A New Model of Censorship", "categories": ["cs.NI"], "comment": null, "summary": "In mid-2025, Iran experienced a novel, stealthy Internet shutdown that\npreserved global routing presence while isolating domestic users through deep\npacket inspection, aggressive throttling, and selective protocol blocking. This\npaper analyzes active network measurements such as DNS poisoning, HTTP\ninjection, TLS interception, and protocol whitelisting, traced to a centralized\nborder gateway. We quantify an approximate 707 percent rise in VPN demand and\ndescribe the multi-layered censorship infrastructure, highlighting implications\nfor circumvention and digital rights monitoring.", "AI": {"tldr": "\u4f0a\u6717\u57282025\u5e74\u4e2d\u671f\u5b9e\u65bd\u4e86\u4e00\u79cd\u65b0\u578b\u9690\u853d\u7684\u4e92\u8054\u7f51\u5173\u95ed\u624b\u6bb5\uff0c\u901a\u8fc7\u6df1\u5ea6\u5305\u68c0\u6d4b\u7b49\u624b\u6bb5\u9694\u79bb\u56fd\u5185\u7528\u6237\uff0c\u540c\u65f6\u4fdd\u6301\u5168\u7403\u8def\u7531\u5b58\u5728\u3002\u8bba\u6587\u901a\u8fc7\u6d4b\u91cf\u5206\u6790\u4e86DNS\u6295\u6bd2\u7b49\u6280\u672f\uff0c\u5e76\u91cf\u5316\u4e86VPN\u9700\u6c42\u7684\u6fc0\u589e\u3002", "motivation": "\u7814\u7a76\u4f0a\u6717\u7684\u65b0\u578b\u4e92\u8054\u7f51\u5173\u95ed\u7b56\u7565\u53ca\u5176\u5bf9\u7528\u6237\u7684\u5f71\u54cd\uff0c\u4e3a\u6570\u5b57\u6743\u5229\u76d1\u63a7\u548c\u89c4\u907f\u6280\u672f\u63d0\u4f9b\u89c1\u89e3\u3002", "method": "\u901a\u8fc7\u4e3b\u52a8\u7f51\u7edc\u6d4b\u91cf\uff08\u5982DNS\u6295\u6bd2\u3001HTTP\u6ce8\u5165\u7b49\uff09\u5206\u6790\u4f0a\u6717\u7684\u4e92\u8054\u7f51\u5173\u95ed\u7b56\u7565\uff0c\u5e76\u8ffd\u8e2a\u5230\u96c6\u4e2d\u5f0f\u8fb9\u754c\u7f51\u5173\u3002", "result": "\u7814\u7a76\u53d1\u73b0VPN\u9700\u6c42\u589e\u52a0\u4e86\u7ea6707%\uff0c\u5e76\u63ed\u793a\u4e86\u591a\u5c42\u5ba1\u67e5\u57fa\u7840\u8bbe\u65bd\u7684\u7ed3\u6784\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u4e86\u4f0a\u6717\u65b0\u578b\u4e92\u8054\u7f51\u5173\u95ed\u624b\u6bb5\u5bf9\u89c4\u907f\u6280\u672f\u548c\u6570\u5b57\u6743\u5229\u76d1\u63a7\u7684\u6df1\u8fdc\u5f71\u54cd\u3002"}}
{"id": "2507.14915", "pdf": "https://arxiv.org/pdf/2507.14915", "abs": "https://arxiv.org/abs/2507.14915", "authors": ["Xiaojie Li", "Ronghui Li", "Shukai Fang", "Shuzhao Xie", "Xiaoyang Guo", "Jiaqing Zhou", "Junkun Peng", "Zhi Wang"], "title": "Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling", "categories": ["cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "Well-coordinated, music-aligned holistic dance enhances emotional\nexpressiveness and audience engagement. However, generating such dances remains\nchallenging due to the scarcity of holistic 3D dance datasets, the difficulty\nof achieving cross-modal alignment between music and dance, and the complexity\nof modeling interdependent motion across the body, hands, and face. To address\nthese challenges, we introduce SoulDance, a high-precision music-dance paired\ndataset captured via professional motion capture systems, featuring\nmeticulously annotated holistic dance movements. Building on this dataset, we\npropose SoulNet, a framework designed to generate music-aligned, kinematically\ncoordinated holistic dance sequences. SoulNet consists of three principal\ncomponents: (1) Hierarchical Residual Vector Quantization, which models\ncomplex, fine-grained motion dependencies across the body, hands, and face; (2)\nMusic-Aligned Generative Model, which composes these hierarchical motion units\ninto expressive and coordinated holistic dance; (3) Music-Motion Retrieval\nModule, a pre-trained cross-modal model that functions as a music-dance\nalignment prior, ensuring temporal synchronization and semantic coherence\nbetween generated dance and input music throughout the generation process.\nExtensive experiments demonstrate that SoulNet significantly surpasses existing\napproaches in generating high-quality, music-coordinated, and well-aligned\nholistic 3D dance sequences.", "AI": {"tldr": "SoulDance\u548cSoulNet\u89e3\u51b3\u4e86\u97f3\u4e50\u4e0e\u821e\u8e48\u5bf9\u9f50\u7684\u590d\u6742\u95ee\u9898\uff0c\u901a\u8fc7\u65b0\u6570\u636e\u96c6\u548c\u6846\u67b6\u751f\u6210\u9ad8\u8d28\u91cf\u76843D\u821e\u8e48\u3002", "motivation": "\u5f53\u524d\u97f3\u4e50\u5bf9\u9f50\u7684\u821e\u8e48\u751f\u6210\u9762\u4e34\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u8de8\u6a21\u6001\u5bf9\u9f50\u56f0\u96be\u4ee5\u53ca\u8eab\u4f53\u5404\u90e8\u5206\u52a8\u4f5c\u4f9d\u8d56\u590d\u6742\u7684\u95ee\u9898\u3002", "method": "SoulDance\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u821e\u8e48\u6570\u636e\u96c6\uff0cSoulNet\u5305\u542b\u5206\u5c42\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\u3001\u97f3\u4e50\u5bf9\u9f50\u751f\u6210\u6a21\u578b\u548c\u97f3\u4e50-\u52a8\u4f5c\u68c0\u7d22\u6a21\u5757\u3002", "result": "SoulNet\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u97f3\u4e50\u5bf9\u9f50\u76843D\u821e\u8e48\u5e8f\u5217\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SoulNet\u6210\u529f\u89e3\u51b3\u4e86\u97f3\u4e50\u4e0e\u821e\u8e48\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u751f\u6210\u4e86\u8868\u8fbe\u529b\u5f3a\u4e14\u534f\u8c03\u7684\u821e\u8e48\u5e8f\u5217\u3002"}}
{"id": "2507.14650", "pdf": "https://arxiv.org/pdf/2507.14650", "abs": "https://arxiv.org/abs/2507.14650", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "A Proof System with Causal Labels (Part I): checking Individual Fairness and Intersectionality", "categories": ["cs.LO", "I.2.3, I.2.4", "F.4"], "comment": null, "summary": "In this article we propose an extension to the typed natural deduction\ncalculus TNDPQ to model verification of individual fairness and\nintersectionality in probabilistic classifiers. Their interpretation is\nobtained by formulating specific conditions for the application of the\nstructural rule of Weakening. Such restrictions are given by causal labels used\nto check for conditional independence between protected and target variables.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6269\u5c55\u7684TNDPQ\u6f14\u7b97\uff0c\u7528\u4e8e\u9a8c\u8bc1\u6982\u7387\u5206\u7c7b\u5668\u4e2d\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u4ea4\u53c9\u6027\u3002", "motivation": "\u4e3a\u6982\u7387\u5206\u7c7b\u5668\u4e2d\u7684\u516c\u5e73\u6027\u548c\u56e0\u679c\u6807\u7b7e\u5efa\u6a21\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u9650\u5236\u7ed3\u6784\u5f31\u5316\u89c4\u5219\u7684\u5e94\u7528\u6761\u4ef6\uff0c\u5e76\u7ed3\u5408\u56e0\u679c\u6807\u7b7e\u68c0\u9a8c\u6761\u4ef6\u72ec\u7acb\u6027\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u9a8c\u8bc1\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u4ea4\u53c9\u6027\u7684\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u6269\u5c55\u7684TNDPQ\u6f14\u7b97\u4e3a\u516c\u5e73\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2507.14376", "pdf": "https://arxiv.org/pdf/2507.14376", "abs": "https://arxiv.org/abs/2507.14376", "authors": ["Osman Erman Gungor", "Derak Paulsen", "William Kang"], "title": "Schemora: schema matching via multi-stage recommendation and metadata enrichment using off-the-shelf llms", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": "11 pages", "summary": "Schema matching is essential for integrating heterogeneous data sources and\nenhancing dataset discovery, yet it remains a complex and resource-intensive\nproblem. We introduce SCHEMORA, a schema matching framework that combines large\nlanguage models with hybrid retrieval techniques in a prompt-based approach,\nenabling efficient identification of candidate matches without relying on\nlabeled training data or exhaustive pairwise comparisons. By enriching schema\nmetadata and leveraging both vector-based and lexical retrieval, SCHEMORA\nimproves matching accuracy and scalability. Evaluated on the MIMIC-OMOP\nbenchmark, it establishes new state-of-the-art performance, with gains of 7.49%\nin HitRate@5 and 3.75% in HitRate@3 over previous best results. To our\nknowledge, this is the first LLM-based schema matching method with an\nopen-source implementation, accompanied by analysis that underscores the\ncritical role of retrieval and provides practical guidance on model selection.", "AI": {"tldr": "SCHEMORA\u662f\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u6df7\u5408\u68c0\u7d22\u6280\u672f\u7684\u6a21\u5f0f\u5339\u914d\u6846\u67b6\uff0c\u65e0\u9700\u6807\u8bb0\u6570\u636e\u6216\u6210\u5bf9\u6bd4\u8f83\u5373\u53ef\u9ad8\u6548\u8bc6\u522b\u5339\u914d\u5019\u9009\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784\u6570\u636e\u6e90\u96c6\u6210\u548c\u6570\u636e\u96c6\u53d1\u73b0\u4e2d\u590d\u6742\u4e14\u8d44\u6e90\u5bc6\u96c6\u7684\u6a21\u5f0f\u5339\u914d\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u5411\u91cf\u548c\u8bcd\u6cd5\u68c0\u7d22\uff0c\u4e30\u5bcc\u6a21\u5f0f\u5143\u6570\u636e\u3002", "result": "\u5728MIMIC-OMOP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHitRate@5\u548cHitRate@3\u5206\u522b\u63d0\u53477.49%\u548c3.75%\uff0c\u8fbe\u5230\u6700\u65b0\u6027\u80fd\u3002", "conclusion": "SCHEMORA\u662f\u9996\u4e2a\u57fa\u4e8eLLM\u7684\u5f00\u6e90\u6a21\u5f0f\u5339\u914d\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u68c0\u7d22\u7684\u5173\u952e\u4f5c\u7528\u548c\u6a21\u578b\u9009\u62e9\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.14713", "pdf": "https://arxiv.org/pdf/2507.14713", "abs": "https://arxiv.org/abs/2507.14713", "authors": ["Allan Luedeman", "Nicholas Baum", "Andrew Quijano", "Kemal Akkaya"], "title": "Privacy-Preserving Drone Navigation Through Homomorphic Encryption for Collision Avoidance", "categories": ["cs.ET"], "comment": null, "summary": "As drones increasingly deliver packages in neighborhoods, concerns about\ncollisions arise. One solution is to share flight paths within a specific zip\ncode, but this compromises business privacy by revealing delivery routes. For\nexample, it could disclose which stores send packages to certain addresses. To\navoid exposing path information, we propose using homomorphic encryption-based\ncomparison to compute path intersections. This allows drones to identify\npotential collisions without revealing path and destination details, allowing\nthem to adjust altitude to avoid crashes. We implemented and tested our\napproach on resource-limited virtual machines to mimic the computational power\nof drones. Our results demonstrate that our method is significantly faster and\nrequires less network communication compared to a garbled circuit-based\napproach. We also provide a security analysis of the approach against potential\nattacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u8def\u5f84\u6bd4\u8f83\u65b9\u6cd5\uff0c\u4ee5\u4fdd\u62a4\u65e0\u4eba\u673a\u914d\u9001\u8def\u5f84\u9690\u79c1\u7684\u540c\u65f6\u907f\u514d\u78b0\u649e\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u914d\u9001\u7684\u589e\u52a0\uff0c\u5171\u4eab\u98de\u884c\u8def\u5f84\u4f1a\u6cc4\u9732\u5546\u4e1a\u9690\u79c1\uff08\u5982\u914d\u9001\u8def\u7ebf\uff09\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u68c0\u6d4b\u78b0\u649e\u53c8\u80fd\u4fdd\u62a4\u9690\u79c1\u7684\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u6280\u672f\u8ba1\u7b97\u8def\u5f84\u4ea4\u96c6\uff0c\u65e0\u4eba\u673a\u5728\u4e0d\u66b4\u9732\u8def\u5f84\u7ec6\u8282\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u6f5c\u5728\u78b0\u649e\uff0c\u5e76\u901a\u8fc7\u8c03\u6574\u9ad8\u5ea6\u907f\u514d\u78b0\u649e\u3002", "result": "\u65b9\u6cd5\u4e0e\u57fa\u4e8e\u6df7\u6dc6\u7535\u8def\u7684\u65b9\u6cd5\u76f8\u6bd4\u901f\u5ea6\u66f4\u5feb\u3001\u7f51\u7edc\u901a\u4fe1\u66f4\u5c11\uff0c\u4e14\u901a\u8fc7\u4e86\u5b89\u5168\u6027\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8bbe\u5907\u4e0a\u6709\u6548\uff0c\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u78b0\u649e\u68c0\u6d4b\u7684\u9700\u6c42\u3002"}}
{"id": "2507.14494", "pdf": "https://arxiv.org/pdf/2507.14494", "abs": "https://arxiv.org/abs/2507.14494", "authors": ["Roxanne Ziman", "Shehryar Saharan", "Ga\u00ebl McGill", "Laura Garrison"], "title": "\"It looks sexy but it's wrong.\" Tensions in creativity and accuracy using genAI for biomedical visualization", "categories": ["cs.HC"], "comment": "11 pages, 3 figures. Accepted to IEEE VIS 2025 Conference", "summary": "We contribute an in-depth analysis of the workflows and tensions arising from\ngenerative AI (genAI) use in biomedical visualization (BioMedVis). Although\ngenAI affords facile production of aesthetic visuals for biological and medical\ncontent, the architecture of these tools fundamentally limits the accuracy and\ntrustworthiness of the depicted information, from imaginary (or fanciful)\nmolecules to alien anatomy. Through 17 interviews with a diverse group of\npractitioners and researchers, we qualitatively analyze the concerns and values\ndriving genAI (dis)use for the visual representation of spatially-oriented\nbiomedical data. We find that BioMedVis experts, both in roles as developers\nand designers, use genAI tools at different stages of their daily workflows and\nhold attitudes ranging from enthusiastic adopters to skeptical avoiders of\ngenAI. In contrasting the current use and perspectives on genAI observed in our\nstudy with predictions towards genAI in the visualization pipeline from prior\nwork, our refocus the discussion of genAI's effects on projects in\nvisualization in the here and now with its respective opportunities and\npitfalls for future visualization research. At a time when public trust in\nscience is in jeopardy, we are reminded to first do no harm, not just in\nbiomedical visualization but in science communication more broadly. Our\nobservations reaffirm the necessity of human intervention for empathetic design\nand assessment of accurate scientific visuals.", "AI": {"tldr": "\u751f\u533b\u53ef\u89c6\u5316\u4e2d\u751f\u6210AI\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e0e\u6f5c\u5728\u95ee\u9898\u5206\u6790\uff0c\u63ed\u793a\u5176\u673a\u9047\u4e0e\u5c40\u9650\u6027\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210AI\u5728\u751f\u533b\u53ef\u89c6\u5316\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5bf9\u4fe1\u606f\u51c6\u786e\u6027\u548c\u79d1\u5b66\u4f20\u64ad\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u901a\u8fc717\u4f4d\u4ece\u4e1a\u8005\u7684\u8bbf\u8c08\uff0c\u5b9a\u6027\u5206\u6790\u751f\u6210AI\u5728\u751f\u533b\u53ef\u89c6\u5316\u4e2d\u7684\u4f7f\u7528\u6001\u5ea6\u4e0e\u9636\u6bb5\u3002", "result": "\u4e13\u5bb6\u5bf9\u751f\u6210AI\u6001\u5ea6\u5404\u5f02\uff0c\u4ece\u70ed\u60c5\u63a5\u7eb3\u5230\u8c28\u614e\u56de\u907f\uff0c\u5f3a\u8c03\u4eba\u7c7b\u5e72\u9884\u5bf9\u51c6\u786e\u79d1\u5b66\u89c6\u89c9\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u751f\u6210AI\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u4eba\u7c7b\u5e72\u9884\u4ee5\u786e\u4fdd\u79d1\u5b66\u53ef\u89c6\u5316\u51c6\u786e\u6027\u4e0e\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.14841", "pdf": "https://arxiv.org/pdf/2507.14841", "abs": "https://arxiv.org/abs/2507.14841", "authors": ["Xiang Tang", "Ruotong Li", "Xiaopeng Fan"], "title": "Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization", "categories": ["cs.GR", "cs.CV"], "comment": "15 pages, 8 figures, Project page: https://xdlbw.github.io/sing3d/", "summary": "In recent years, 3D generation has made great strides in both academia and\nindustry. However, generating 3D scenes from a single RGB image remains a\nsignificant challenge, as current approaches often struggle to ensure both\nobject generation quality and scene coherence in multi-object scenarios. To\novercome these limitations, we propose a novel three-stage framework for 3D\nscene generation with explicit geometric representations and high-quality\ntextural details via single image-guided model generation and spatial layout\noptimization. Our method begins with an image instance segmentation and\ninpainting phase, which recovers missing details of occluded objects in the\ninput images, thereby achieving complete generation of foreground 3D assets.\nSubsequently, our approach captures the spatial geometry of reference image by\nconstructing pseudo-stereo viewpoint for camera parameter estimation and scene\ndepth inference, while employing a model selection strategy to ensure optimal\nalignment between the 3D assets generated in the previous step and the input.\nFinally, through model parameterization and minimization of the Chamfer\ndistance between point clouds in 3D and 2D space, our approach optimizes layout\nparameters to produce an explicit 3D scene representation that maintains\nprecise alignment with input guidance image. Extensive experiments on\nmulti-object scene image sets have demonstrated that our approach not only\noutperforms state-of-the-art methods in terms of geometric accuracy and texture\nfidelity of individual generated 3D models, but also has significant advantages\nin scene layout synthesis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u5355\u56fe\u50cf\u5f15\u5bfc\u751f\u6210\u9ad8\u8d28\u91cf3D\u573a\u666f\uff0c\u89e3\u51b3\u4e86\u591a\u5bf9\u8c61\u573a\u666f\u4e2d\u751f\u6210\u8d28\u91cf\u4e0e\u573a\u666f\u4e00\u81f4\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4ece\u5355RGB\u56fe\u50cf\u751f\u62103D\u573a\u666f\u65f6\u5bf9\u8c61\u751f\u6210\u8d28\u91cf\u4e0e\u573a\u666f\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u56fe\u50cf\u5b9e\u4f8b\u5206\u5272\u4e0e\u4fee\u590d\u3001\u4f2a\u7acb\u4f53\u89c6\u56fe\u6784\u5efa\u4e0e\u6a21\u578b\u9009\u62e9\u3001\u5e03\u5c40\u53c2\u6570\u4f18\u5316\u3002", "result": "\u5728\u51e0\u4f55\u7cbe\u5ea6\u548c\u7eb9\u7406\u4fdd\u771f\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u573a\u666f\u5e03\u5c40\u5408\u6210\u4e2d\u8868\u73b0\u5353\u8d8a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e863D\u573a\u666f\u751f\u6210\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\uff0c\u9002\u7528\u4e8e\u591a\u5bf9\u8c61\u573a\u666f\u3002"}}
{"id": "2507.14330", "pdf": "https://arxiv.org/pdf/2507.14330", "abs": "https://arxiv.org/abs/2507.14330", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Leveraging LLMs for Formal Software Requirements -- Challenges and Prospects", "categories": ["cs.SE", "D.2.1; D.2.4; D.2.10; F.4.1; F.4.3"], "comment": "Submitted to Overlay2025 - 7th International Workshop on Artificial\n  Intelligence and fOrmal VERification, Logic, Automata, and sYnthesis. [under\n  review]", "summary": "Software correctness is ensured mathematically through formal verification,\nwhich involves the resources of generating formal requirement specifications\nand having an implementation that must be verified. Tools such as\nmodel-checkers and theorem provers ensure software correctness by verifying the\nimplementation against the specification. Formal methods deployment is\nregularly enforced in the development of safety-critical systems e.g.\naerospace, medical devices and autonomous systems. Generating these\nspecifications from informal and ambiguous natural language requirements\nremains the key challenge. Our project, VERIFAI^{1}, aims to investigate\nautomated and semi-automated approaches to bridge this gap, using techniques\nfrom Natural Language Processing (NLP), ontology-based domain modelling,\nartefact reuse, and large language models (LLMs). This position paper presents\na preliminary synthesis of relevant literature to identify recurring challenges\nand prospective research directions in the generation of verifiable\nspecifications from informal requirements.", "AI": {"tldr": "VERIFAI\u9879\u76ee\u7814\u7a76\u4e86\u5982\u4f55\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u81ea\u52a8\u6216\u534a\u81ea\u52a8\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u89c4\u683c\u4e66\uff0c\u7ed3\u5408NLP\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b49\u6280\u672f\u3002", "motivation": "\u4ece\u6a21\u7cca\u7684\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u751f\u6210\u5f62\u5f0f\u5316\u89c4\u683c\u4e66\u662f\u786e\u4fdd\u8f6f\u4ef6\u6b63\u786e\u6027\u7684\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u3002", "method": "\u9879\u76ee\u91c7\u7528\u4e86NLP\u3001\u9886\u57df\u672c\u4f53\u5efa\u6a21\u3001\u5de5\u4ef6\u91cd\u7528\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b49\u6280\u672f\u3002", "result": "\u521d\u6b65\u6587\u732e\u7efc\u8ff0\u786e\u5b9a\u4e86\u751f\u6210\u53ef\u9a8c\u8bc1\u89c4\u683c\u4e66\u7684\u5e38\u89c1\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "VERIFAI\u4e3a\u81ea\u52a8\u751f\u6210\u5f62\u5f0f\u5316\u89c4\u683c\u4e66\u63d0\u4f9b\u4e86\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.14813", "pdf": "https://arxiv.org/pdf/2507.14813", "abs": "https://arxiv.org/abs/2507.14813", "authors": ["Sanjay Sri Vallabh Singapuram", "Ronald Dreslinski", "Nishil Talati"], "title": "Mayura: Exploiting Similarities in Motifs for Temporal Co-Mining", "categories": ["cs.DB", "cs.DC", "cs.PF"], "comment": null, "summary": "Temporal graphs serve as a critical foundation for modeling evolving\ninteractions in domains ranging from financial networks to social media. Mining\ntemporal motifs is essential for applications such as fraud detection,\ncybersecurity, and dynamic network analysis. However, conventional motif mining\napproaches treat each query independently, incurring significant redundant\ncomputations when similar substructures exist across multiple motifs. In this\npaper, we propose Mayura, a novel framework that unifies the mining of multiple\ntemporal motifs by exploiting their inherent structural and temporal\ncommonalities. Central to our approach is the Motif-Group Tree (MG-Tree), a\nhierarchical data structure that organizes related motifs and enables the reuse\nof common search paths, thereby reducing redundant computation. We propose a\nco-mining algorithm that leverages the MG-Tree and develop a flexible runtime\ncapable of exploiting both CPU and GPU architectures for scalable performance.\nEmpirical evaluations on diverse real-world datasets demonstrate that Mayura\nachieves substantial improvements over the state-of-the-art techniques that\nmine each motif individually, with an average speed-up of 2.4x on the CPU and\n1.7x on the GPU, while maintaining the exactness required for high-stakes\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMayura\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u591a\u65f6\u6001\u6a21\u4f53\u7684\u7ed3\u6784\u5171\u6027\uff0c\u51cf\u5c11\u4e86\u5197\u4f59\u8ba1\u7b97\uff0c\u63d0\u9ad8\u4e86\u6316\u6398\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u67e5\u8be2\u65f6\u5b58\u5728\u5927\u91cf\u5197\u4f59\u8ba1\u7b97\uff0c\u9650\u5236\u4e86\u6548\u7387\u548c\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faMotif-Group Tree (MG-Tree)\u6570\u636e\u7ed3\u6784\u548c\u534f\u540c\u6316\u6398\u7b97\u6cd5\uff0c\u652f\u6301CPU\u548cGPU\u9ad8\u6548\u8fd0\u884c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cMayura\u6bd4\u73b0\u6709\u6280\u672f\u5e73\u5747\u63d0\u901f2.4\u500d\uff08CPU\uff09\u548c1.7\u500d\uff08GPU\uff09\uff0c\u4e14\u4fdd\u6301\u7cbe\u786e\u6027\u3002", "conclusion": "Mayura\u663e\u8457\u63d0\u5347\u4e86\u65f6\u6001\u6a21\u4f53\u6316\u6398\u7684\u6548\u7387\uff0c\u9002\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u8981\u6c42\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2507.14471", "pdf": "https://arxiv.org/pdf/2507.14471", "abs": "https://arxiv.org/abs/2507.14471", "authors": ["Logan Kenwright", "Partha Roop", "Nathan Allen", "C\u0103lin Ca\u015fcaval", "Avinash Malik"], "title": "Timetide: A programming model for logically synchronous distributed systems", "categories": ["cs.PL", "cs.DC"], "comment": "25 Pages, 21 Figures", "summary": "Massive strides in deterministic models have been made using synchronous\nlanguages. They are mainly focused on centralised applications, as the\ntraditional approach is to compile away the concurrency. Time triggered\nlanguages such as Giotto and Lingua Franca are suitable for distribution albeit\nthat they rely on expensive physical clock synchronisation, which is both\nexpensive and may suffer from scalability. Hence, deterministic programming of\ndistributed systems remains challenging. We address the challenges of\ndeterministic distribution by developing a novel multiclock semantics of\nsynchronous programs. The developed semantics is amenable to seamless\ndistribution. Moreover, our programming model, Timetide, alleviates the need\nfor physical clock synchronisation by building on the recently proposed logical\nsynchrony model for distributed systems. We discuss the important aspects of\ndistributing computation, such as network communication delays, and explore the\nformal verification of Timetide programs. To the best of our knowledge,\nTimetide is the first multiclock synchronous language that is both amenable to\ndistribution and formal verification without the need for physical clock\nsynchronisation or clock gating.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTimetide\u7684\u65b0\u591a\u65f6\u949f\u8bed\u4e49\u540c\u6b65\u8bed\u8a00\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u7cfb\u7edf\u786e\u5b9a\u6027\u7f16\u7a0b\u7684\u6311\u6218\uff0c\u65e0\u9700\u7269\u7406\u65f6\u949f\u540c\u6b65\u3002", "motivation": "\u73b0\u6709\u7684\u786e\u5b9a\u6027\u6a21\u578b\u4e3b\u8981\u96c6\u4e2d\u4e8e\u96c6\u4e2d\u5f0f\u5e94\u7528\uff0c\u800c\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u7684\u8bed\u8a00\u4f9d\u8d56\u6602\u8d35\u4e14\u96be\u4ee5\u6269\u5c55\u7684\u7269\u7406\u65f6\u949f\u540c\u6b65\uff0c\u786e\u5b9a\u6027\u7684\u5206\u5e03\u5f0f\u7f16\u7a0b\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u65f6\u949f\u8bed\u4e49\u540c\u6b65\u7a0b\u5e8f\u8bed\u4e49\uff0c\u5e76\u6784\u5efa\u4e86\u57fa\u4e8e\u903b\u8f91\u540c\u6b65\u6a21\u578b\u7684\u7f16\u7a0b\u8bed\u8a00Timetide\uff0c\u907f\u514d\u4e86\u7269\u7406\u65f6\u949f\u540c\u6b65\u9700\u6c42\u3002", "result": "Timetide\u6210\u4e3a\u9996\u4e2a\u65e2\u9002\u5408\u5206\u5e03\u5f0f\u53c8\u652f\u6301\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u591a\u65f6\u949f\u540c\u6b65\u8bed\u8a00\uff0c\u65e0\u9700\u7269\u7406\u65f6\u949f\u540c\u6b65\u6216\u65f6\u949f\u95e8\u63a7\u3002", "conclusion": "Timetide\u4e3a\u89e3\u51b3\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u786e\u5b9a\u6027\u7f16\u7a0b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u5b9e\u7528\u6027\u548c\u7406\u8bba\u4ef7\u503c\u3002"}}
{"id": "2507.14186", "pdf": "https://arxiv.org/pdf/2507.14186", "abs": "https://arxiv.org/abs/2507.14186", "authors": ["Xiaojie Li", "Zhijie Cai", "Nan Qi", "Chao Dong", "Guangxu Zhu", "Haixia Ma", "Qihui Wu", "Shi Jin"], "title": "A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction", "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "comment": "This paper has been submitted to IEEE for possible publication", "summary": "The expansion of the low-altitude economy has underscored the significance of\nLow-Altitude Network Coverage (LANC) prediction for designing aerial corridors.\nWhile accurate LANC forecasting hinges on the antenna beam patterns of Base\nStations (BSs), these patterns are typically proprietary and not readily\naccessible. Operational parameters of BSs, which inherently contain beam\ninformation, offer an opportunity for data-driven low-altitude coverage\nprediction. However, collecting extensive low-altitude road test data is\ncost-prohibitive, often yielding only sparse samples per BS. This scarcity\nresults in two primary challenges: imbalanced feature sampling due to limited\nvariability in high-dimensional operational parameters against the backdrop of\nsubstantial changes in low-dimensional sampling locations, and diminished\ngeneralizability stemming from insufficient data samples. To overcome these\nobstacles, we introduce a dual strategy comprising expert knowledge-based\nfeature compression and disentangled representation learning. The former\nreduces feature space complexity by leveraging communications expertise, while\nthe latter enhances model generalizability through the integration of\npropagation models and distinct subnetworks that capture and aggregate the\nsemantic representations of latent features. Experimental evaluation confirms\nthe efficacy of our framework, yielding a 7% reduction in error compared to the\nbest baseline algorithm. Real-network validations further attest to its\nreliability, achieving practical prediction accuracy with MAE errors at the 5dB\nlevel.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e13\u5bb6\u77e5\u8bc6\u7279\u5f81\u538b\u7f29\u548c\u5206\u79bb\u8868\u793a\u5b66\u4e60\u7684\u53cc\u7b56\u7565\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4f4e\u7a7a\u7f51\u7edc\u8986\u76d6\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\u7684\u53d1\u5c55\u9700\u8981\u51c6\u786e\u7684\u4f4e\u7a7a\u7f51\u7edc\u8986\u76d6\u9884\u6d4b\uff0c\u4f46\u57fa\u7ad9\u5929\u7ebf\u6ce2\u675f\u6a21\u5f0f\u901a\u5e38\u4e0d\u516c\u5f00\uff0c\u4e14\u4f4e\u7a7a\u8def\u6d4b\u6570\u636e\u7a00\u7f3a\uff0c\u5bfc\u81f4\u9884\u6d4b\u9762\u4e34\u7279\u5f81\u91c7\u6837\u4e0d\u5e73\u8861\u548c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e86\u4e13\u5bb6\u77e5\u8bc6\u7279\u5f81\u538b\u7f29\u548c\u5206\u79bb\u8868\u793a\u5b66\u4e60\u7684\u53cc\u7b56\u7565\u3002\u524d\u8005\u901a\u8fc7\u901a\u4fe1\u4e13\u4e1a\u77e5\u8bc6\u964d\u4f4e\u7279\u5f81\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u540e\u8005\u901a\u8fc7\u7ed3\u5408\u4f20\u64ad\u6a21\u578b\u548c\u5b50\u7f51\u7edc\u589e\u5f3a\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u7b97\u6cd5\u8bef\u5dee\u964d\u4f4e7%\uff0c\u5b9e\u9645\u7f51\u7edc\u9a8c\u8bc1\u4e2dMAE\u8bef\u5dee\u8fbe\u52305dB\u6c34\u5e73\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f4e\u7a7a\u7f51\u7edc\u8986\u76d6\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.15491", "pdf": "https://arxiv.org/pdf/2507.15491", "abs": "https://arxiv.org/abs/2507.15491", "authors": ["Deyu Zhang", "Tingting Long", "Jinrui Zhang", "Ligeng Chen", "Ju Ren", "Yaoxue Zhang"], "title": "Prompt-aware of Frame Sampling for Efficient Text-Video Retrieval", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "Enabling efficient text-video retrieval on edge-end devices is critical for\nreal-world applications. Yet, existing methods face a critical challenge in\nbalancing accuracy and computational efficiency: uniform frame sampling methods\nensure content coverage but incur prohibitive computational costs, while\nsalient-frame sampling methods reduce overhead but suffer from query-agnostic\nframe selection that biases retrieval results. To address this, we propose\nProCLIP, a user-centric framework that achieves state-of-the-art accuracy with\nsignificantly improved efficiency. We design a prompt-aware frame sampling\nstrategy that dynamically guides lightweight feature extractors using textual\nprompts to select semantically relevant frames, overcoming the limitations of\nexisting salient-frame sampling methods which rely on static, query-agnostic\nselection criteria. Moreover, we adopt a two-stage candidate pruning strategy\nthat combines rapid coarse filtering via a lightweight module with CLIP-powered\nfine-grained re-ranking, enhancing retrieval efficiency while preserving\naccuracy. Experiments across benchmarks show ProCLIP achieves 75.3% latency\nreduction versus baselines while maintaining competitive accuracy, i.e.,\nR@1=49.0 in MSR-VTT dataset. Code is available at\nhttps://github.com/tiffylong/ProCLIP.", "AI": {"tldr": "ProCLIP\u662f\u4e00\u4e2a\u7528\u6237\u4e2d\u5fc3\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u8bed\u4e49\u76f8\u5173\u5e27\u548c\u4e24\u7ea7\u5019\u9009\u526a\u679d\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u6587\u672c-\u89c6\u9891\u68c0\u7d22\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u6587\u672c-\u89c6\u9891\u68c0\u7d22\u4e2d\u65e0\u6cd5\u5e73\u8861\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u63d0\u793a\u611f\u77e5\u7684\u5e27\u91c7\u6837\u7b56\u7565\u548c\u4e24\u7ea7\u5019\u9009\u526a\u679d\u7b56\u7565\u3002", "result": "\u5728MSR-VTT\u6570\u636e\u96c6\u4e0a\u5b9e\u73b075.3%\u7684\u5ef6\u8fdf\u964d\u4f4e\uff0cR@1=49.0\u3002", "conclusion": "ProCLIP\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u3002"}}
{"id": "2507.14655", "pdf": "https://arxiv.org/pdf/2507.14655", "abs": "https://arxiv.org/abs/2507.14655", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "A Proof System with Causal Labels (Part II): checking Counterfactual Fairness", "categories": ["cs.LO", "I.2.3, I.2.4", "F.4"], "comment": null, "summary": "In this article we propose an extension to the typed natural deduction\ncalculus TNDPQ to model verification of counterfactual fairness in\nprobabilistic classifiers. This is obtained formulating specific structural\nconditions for causal labels and checking that evaluation is robust under their\nvariation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6269\u5c55TNDPQ\u4ee5\u9a8c\u8bc1\u6982\u7387\u5206\u7c7b\u5668\u4e2d\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u7684\u65b9\u6cd5\u3002", "motivation": "\u9700\u8981\u4e3a\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u9a8c\u8bc1\u63d0\u4f9b\u5f62\u5f0f\u5316\u5de5\u5177\u3002", "method": "\u5728TNDPQ\u4e2d\u5f15\u5165\u7279\u5b9a\u7ed3\u6784\u6761\u4ef6\uff0c\u68c0\u67e5\u8bc4\u4f30\u5bf9\u8fd9\u4e9b\u6761\u4ef6\u7684\u9c81\u68d2\u6027\u3002", "result": "\u6210\u529f\u5efa\u6a21\u5e76\u9a8c\u8bc1\u4e86\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u3002", "conclusion": "\u6269\u5c55\u7684TNDPQ\u4e3a\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2507.14475", "pdf": "https://arxiv.org/pdf/2507.14475", "abs": "https://arxiv.org/abs/2507.14475", "authors": ["Runhao Zhao", "Weixin Zeng", "Wentao Zhang", "Xiang Zhao", "Jiuyang Tang", "Lei Chen"], "title": "Towards Temporal Knowledge Graph Alignment in the Wild", "categories": ["cs.DB"], "comment": "18 pages, 6 figures", "summary": "Temporal Knowledge Graph Alignment (TKGA) seeks to identify equivalent\nentities across heterogeneous temporal knowledge graphs (TKGs) for fusion to\nimprove their completeness. Although some approaches have been proposed to\ntackle this task, most assume unified temporal element standards and simplified\ntemporal structures across different TKGs. They cannot deal with TKGA in the\nwild (TKGA-Wild), where multi-scale temporal element entanglement and\ncross-source temporal structural imbalances are common. To bridge this gap, we\nstudy the task of TKGA-Wild and propose HyDRA, a new and effective solution.\nHyDRA is the first to reformulate the task via multi-scale hypergraph\nretrieval-augmented generation to address the challenges of TKGA-Wild.In\naddition, we design a new scale-weave synergy mechanism for HyDRA, which\nincorporates intra-scale interactions and cross-scale conflict detection. This\nmechanism is designed to alleviate the fragmentation caused by multi-source\ntemporal incompleteness and resolves inconsistencies arising from complex and\nuneven temporal event density distributions, thereby enhancing the model\ncapacity to handle the intricacies of real-world temporal alignment. Finally,\nthere is no standard benchmark that captures these challenges of TKGA-Wild and\neffectively evaluates existing methods. To this end, we formally propose to\nbenchmark challenges for TKGA-Wild and validate the effectiveness of the method\nby establishing two new datasets(BETA and WildBETA). Extensive experiments on\nthe new datasets and six representative benchmarks show that BETA and WildBETA\nbetter reflect real-world challenges. Meanwhile, HyDRA proposes a new paradigm\nfor TKGA-Wild, consistently outperforming 24 competitive baselines, while\nmaintaining strong efficiency and scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e86HyDRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u8d85\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u89e3\u51b3\u590d\u6742\u65f6\u7a7a\u77e5\u8bc6\u56fe\u5bf9\u9f50\u95ee\u9898\uff0c\u5e76\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u7edf\u4e00\u7684\u65f6\u7a7a\u6807\u51c6\u548c\u7b80\u5316\u7ed3\u6784\uff0c\u65e0\u6cd5\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u591a\u5c3a\u5ea6\u65f6\u7a7a\u5143\u7d20\u7ea0\u7f20\u548c\u8de8\u6e90\u65f6\u7a7a\u7ed3\u6784\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "HyDRA\u91c7\u7528\u591a\u5c3a\u5ea6\u8d85\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u7ed3\u5408\u5c3a\u5ea6\u5185\u4ea4\u4e92\u548c\u8de8\u5c3a\u5ea6\u51b2\u7a81\u68c0\u6d4b\u673a\u5236\u3002", "result": "\u5728\u65b0\u6570\u636e\u96c6BETA\u548cWildBETA\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e24\u4e2a\u57fa\u51c6\u65b9\u6cd5\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "HyDRA\u4e3a\u590d\u6742\u65f6\u7a7a\u77e5\u8bc6\u56fe\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u65b0\u6570\u636e\u96c6\u66f4\u771f\u5b9e\u53cd\u6620\u73b0\u5b9e\u6311\u6218\u3002"}}
{"id": "2507.15146", "pdf": "https://arxiv.org/pdf/2507.15146", "abs": "https://arxiv.org/abs/2507.15146", "authors": ["Sebastian A. Cruz Romero", "Misael J. Mercado Hernandez", "Samir Y. Ali Rivera", "Jorge A. Santiago Fernandez", "Wilfredo E. Lugo Beauchamp"], "title": "Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications", "categories": ["cs.ET", "cs.AI", "cs.CV", "cs.CY", "cs.LG", "cs.SE"], "comment": "Accepted at IEEE Global Humanitarian Technology Conference 2025", "summary": "The design of medical systems for remote, resource-limited environments faces\npersistent challenges due to poor interoperability, lack of offline support,\nand dependency on costly infrastructure. Many existing digital health solutions\nneglect these constraints, limiting their effectiveness for frontline health\nworkers in underserved regions. This paper presents a portable, edge-enabled\nElectronic Health Record platform optimized for offline-first operation, secure\npatient data management, and modular diagnostic integration. Running on\nsmall-form factor embedded devices, it provides AES-256 encrypted local storage\nwith optional cloud synchronization for interoperability. As a use case, we\nintegrated a non-invasive anemia screening module leveraging fingernail pallor\nanalysis. Trained on 250 patient cases (27\\% anemia prevalence) with\nKDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL\nand MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To\noptimize performance, a YOLOv8n-based nail bed detector was quantized to INT8,\nreducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5\nat 0.995. The system emphasizes low-cost deployment, modularity, and data\nprivacy compliance (HIPAA/GDPR), addressing critical barriers to digital health\nadoption in disconnected settings. Our work demonstrates a scalable approach to\nenhance portable health information systems and support frontline healthcare in\nunderserved regions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4fbf\u643a\u5f0f\u3001\u8fb9\u7f18\u652f\u6301\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5e73\u53f0\uff0c\u4e13\u4e3a\u8d44\u6e90\u6709\u9650\u73af\u5883\u8bbe\u8ba1\uff0c\u5177\u6709\u79bb\u7ebf\u4f18\u5148\u64cd\u4f5c\u548c\u6a21\u5757\u5316\u8bca\u65ad\u529f\u80fd\uff0c\u5e76\u901a\u8fc7\u8d2b\u8840\u7b5b\u67e5\u6a21\u5757\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u9488\u5bf9\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u533b\u7597\u7cfb\u7edf\u9762\u4e34\u7684\u4e92\u64cd\u4f5c\u6027\u5dee\u3001\u7f3a\u4e4f\u79bb\u7ebf\u652f\u6301\u548c\u57fa\u7840\u8bbe\u65bd\u6602\u8d35\u7b49\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u9002\u7528\u4e8e\u504f\u8fdc\u5730\u533a\u7684\u4fbf\u643a\u5f0f\u533b\u7597\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8fd0\u884c\u5728\u5c0f\u578b\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u7684\u5e73\u53f0\uff0c\u652f\u6301AES-256\u672c\u5730\u52a0\u5bc6\u5b58\u50a8\u548c\u53ef\u9009\u4e91\u540c\u6b65\uff0c\u96c6\u6210\u4e86\u57fa\u4e8e\u968f\u673a\u68ee\u6797\u7684\u8d2b\u8840\u7b5b\u67e5\u6a21\u5757\u548c\u4f18\u5316\u7684YOLOv8n\u6307\u7532\u5e8a\u68c0\u6d4b\u5668\u3002", "result": "\u8d2b\u8840\u7b5b\u67e5\u6a21\u5757\u5728\u6d4b\u8bd5\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u8bef\u5dee\uff08RMSE 1.969 g/dL\uff0cMAE 1.490 g/dL\uff09\uff0c\u4f18\u5316\u7684\u68c0\u6d4b\u5668\u5c06\u63a8\u7406\u5ef6\u8fdf\u4ece46.96 ms\u964d\u81f321.50 ms\u3002", "conclusion": "\u8be5\u5e73\u53f0\u901a\u8fc7\u4f4e\u6210\u672c\u3001\u6a21\u5757\u5316\u548c\u9690\u79c1\u5408\u89c4\u6027\u4e3a\u8d44\u6e90\u6709\u9650\u5730\u533a\u7684\u6570\u5b57\u5065\u5eb7\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14139", "pdf": "https://arxiv.org/pdf/2507.14139", "abs": "https://arxiv.org/abs/2507.14139", "authors": ["Peipei Wang", "Wu Guan", "Liping Liang", "Zhijun Wang", "Hanqing Luo", "Zhibin Zhang"], "title": "SpeedLLM: An FPGA Co-design of Large Language Model Inference Accelerator", "categories": ["cs.AR"], "comment": null, "summary": "This paper introduces SpeedLLM, a neural network accelerator designed on the\nXilinx Alevo U280 platform and optimized for the Tinyllama framework to enhance\nedge computing performance. Key innovations include data stream parallelism, a\nmemory reuse strategy, and Llama2 operator fusion, which collectively reduce\nlatency and energy consumption. SpeedLLM's data pipeline architecture optimizes\nthe read-compute-write cycle, while the memory strategy minimizes FPGA resource\ndemands. The operator fusion boosts computational density and throughput.\nResults show SpeedLLM outperforms traditional Tinyllama implementations,\nachieving up to 4.8* faster performance and 1.18* lower energy consumption,\noffering improvements in edge devices.", "AI": {"tldr": "SpeedLLM\u662f\u4e00\u79cd\u57fa\u4e8eXilinx Alevo U280\u5e73\u53f0\u7684\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\uff0c\u4e13\u4e3aTinyllama\u6846\u67b6\u4f18\u5316\uff0c\u63d0\u5347\u8fb9\u7f18\u8ba1\u7b97\u6027\u80fd\u3002\u901a\u8fc7\u6570\u636e\u6d41\u5e76\u884c\u3001\u5185\u5b58\u91cd\u7528\u7b56\u7565\u548cLlama2\u7b97\u5b50\u878d\u5408\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u4e3a\u4e86\u5728\u8fb9\u7f18\u8ba1\u7b97\u8bbe\u5907\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\uff0c\u51cf\u5c11\u5ef6\u8fdf\u548c\u80fd\u91cf\u6d88\u8017\uff0c\u8bbe\u8ba1\u4e86SpeedLLM\u3002", "method": "\u91c7\u7528\u4e86\u6570\u636e\u6d41\u5e76\u884c\u3001\u5185\u5b58\u91cd\u7528\u7b56\u7565\u548cLlama2\u7b97\u5b50\u878d\u5408\u6280\u672f\uff0c\u4f18\u5316\u6570\u636e\u6d41\u6c34\u7ebf\u67b6\u6784\u548c\u5185\u5b58\u4f7f\u7528\u6548\u7387\u3002", "result": "SpeedLLM\u76f8\u6bd4\u4f20\u7edfTinyllama\u5b9e\u73b0\uff0c\u6027\u80fd\u63d0\u53474.8\u500d\uff0c\u80fd\u8017\u964d\u4f4e1.18\u500d\u3002", "conclusion": "SpeedLLM\u4e3a\u8fb9\u7f18\u8bbe\u5907\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u4f4e\u80fd\u8017\u7684\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14527", "pdf": "https://arxiv.org/pdf/2507.14527", "abs": "https://arxiv.org/abs/2507.14527", "authors": ["Runhua Zhang", "Yang Ouyang", "Leixian Shen", "Yuying Tang", "Xiaojuan Ma", "Huamin Qu", "Xian Xu"], "title": "PaperBridge: Crafting Research Narratives through Human-AI Co-Exploration", "categories": ["cs.HC"], "comment": "Conditionally accepted by UIST'25", "summary": "Researchers frequently need to synthesize their own publications into\ncoherent narratives that demonstrate their scholarly contributions. To suit\ndiverse communication contexts, exploring alternative ways to organize one's\nwork while maintaining coherence is particularly challenging, especially in\ninterdisciplinary fields like HCI where individual researchers' publications\nmay span diverse domains and methodologies. In this paper, we present\nPaperBridge, a human-AI co-exploration system informed by a formative study and\ncontent analysis. PaperBridge assists researchers in exploring diverse\nperspectives for organizing their publications into coherent narratives. At its\ncore is a bi-directional analysis engine powered by large language models,\nsupporting iterative exploration through both top-down user intent (e.g.,\ndetermining organization structure) and bottom-up refinement on narrative\ncomponents (e.g., thematic paper groupings). Our user study (N=12) demonstrated\nPaperBridge's usability and effectiveness in facilitating the exploration of\nalternative research narratives. Our findings also provided empirical insights\ninto how interactive systems can scaffold academic communication tasks.", "AI": {"tldr": "PaperBridge\u662f\u4e00\u4e2a\u4eba\u7c7b-AI\u534f\u540c\u63a2\u7d22\u7cfb\u7edf\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5c06\u5176\u51fa\u7248\u7269\u7ec4\u7ec7\u6210\u8fde\u8d2f\u7684\u53d9\u4e8b\u3002\u901a\u8fc7\u53cc\u5411\u5206\u6790\u5f15\u64ce\u652f\u6301\u8fed\u4ee3\u63a2\u7d22\uff0c\u7528\u6237\u7814\u7a76\u8868\u660e\u5176\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u4eba\u5458\u9700\u8981\u5c06\u51fa\u7248\u7269\u7ec4\u7ec7\u6210\u8fde\u8d2f\u7684\u53d9\u4e8b\uff0c\u5c24\u5176\u5728\u8de8\u5b66\u79d1\u9886\u57df\uff08\u5982HCI\uff09\u5c24\u4e3a\u56f0\u96be\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u591a\u6837\u5316\u7684\u7ec4\u7ec7\u65b9\u5f0f\u3002", "method": "\u5f00\u53d1\u4e86PaperBridge\u7cfb\u7edf\uff0c\u57fa\u4e8e\u5f62\u6210\u6027\u7814\u7a76\u548c\u5185\u5bb9\u5206\u6790\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u53cc\u5411\u5206\u6790\u5f15\u64ce\u652f\u6301\u7528\u6237\u610f\u56fe\u4e0e\u53d9\u4e8b\u7ec4\u4ef6\u7684\u8fed\u4ee3\u63a2\u7d22\u3002", "result": "\u7528\u6237\u7814\u7a76\uff08N=12\uff09\u8868\u660ePaperBridge\u5728\u63a2\u7d22\u66ff\u4ee3\u6027\u7814\u7a76\u53d9\u4e8b\u65b9\u9762\u5177\u6709\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u4ea4\u4e92\u5f0f\u7cfb\u7edf\u53ef\u4ee5\u4e3a\u5b66\u672f\u4ea4\u6d41\u4efb\u52a1\u63d0\u4f9b\u652f\u6301\uff0cPaperBridge\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u65b0\u7684\u7ec4\u7ec7\u5de5\u5177\u3002"}}
{"id": "2507.14920", "pdf": "https://arxiv.org/pdf/2507.14920", "abs": "https://arxiv.org/abs/2507.14920", "authors": ["Evandro S. Ortigossa", "F\u00e1bio F. Dias", "Diego C. Nascimento", "Luis Gustavo Nonato"], "title": "Time Series Information Visualization -- A Review of Approaches and Tools", "categories": ["cs.GR"], "comment": "Preprint. Under review", "summary": "Time series data are prevalent across various domains and often encompass\nlarge datasets containing multiple time-dependent features in each sample.\nExploring time-varying data is critical for data science practitioners aiming\nto understand dynamic behaviors and discover periodic patterns and trends.\nHowever, the analysis of such data often requires sophisticated procedures and\ntools. Information visualization is a communication channel that leverages\nhuman perceptual abilities to transform abstract data into visual\nrepresentations. Visualization techniques have been successfully applied in the\ncontext of time series to enhance interpretability by graphically representing\nthe temporal evolution of data. The challenge for information visualization\ndevelopers lies in integrating a wide range of analytical tools into rich\nvisualization systems that can summarize complex datasets while clearly\ndescribing the impacts of the temporal component. Such systems enable data\nscientists to turn raw data into understandable and potentially useful\nknowledge. This review examines techniques and approaches designed for handling\ntime series data, guiding users through knowledge discovery processes based on\nvisual analysis. We also provide readers with theoretical insights and design\nguidelines for considering when developing comprehensive information\nvisualization approaches for time series, with a particular focus on time\nseries with multiple features. As a result, we highlight the challenges and\nfuture research directions to address open questions in the visualization of\ntime-dependent data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u591a\u7279\u5f81\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u4fe1\u606f\u53ef\u89c6\u5316\u6280\u672f\u4e0e\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u53ef\u89c6\u5316\u589e\u5f3a\u6570\u636e\u89e3\u8bfb\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u5404\u9886\u57df\u666e\u904d\u5b58\u5728\u4e14\u590d\u6742\uff0c\u53ef\u89c6\u5316\u6280\u672f\u80fd\u5e2e\u52a9\u6570\u636e\u79d1\u5b66\u5bb6\u66f4\u597d\u5730\u7406\u89e3\u52a8\u6001\u884c\u4e3a\u548c\u53d1\u73b0\u6a21\u5f0f\uff0c\u4f46\u76ee\u524d\u4ecd\u9700\u66f4\u5168\u9762\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u7efc\u8ff0\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u6280\u672f\u548c\u65b9\u6cd5\uff0c\u7ed3\u5408\u7406\u8bba\u89c1\u89e3\u548c\u8bbe\u8ba1\u6307\u5357\uff0c\u63d0\u51fa\u6574\u5408\u591a\u79cd\u5206\u6790\u5de5\u5177\u7684\u4e30\u5bcc\u53ef\u89c6\u5316\u7cfb\u7edf\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86\u591a\u7279\u5f81\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u7684\u5173\u952e\u6280\u672f\u548c\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u672a\u6765\u7814\u7a76\u7684\u5efa\u8bae\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u6280\u672f\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u89e3\u51b3\u5f00\u653e\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u591a\u7279\u5f81\u6570\u636e\u7684\u8868\u8fbe\u548c\u5206\u6790\u65b9\u9762\u3002"}}
{"id": "2507.14396", "pdf": "https://arxiv.org/pdf/2507.14396", "abs": "https://arxiv.org/abs/2507.14396", "authors": ["Carey Lai Zheng Hui", "Johnson Britto Jessia Esther Leena", "Kumuthini Subramanian", "Zhao Chenyu", "Shubham Rajeshkumar Jariwala"], "title": "Developing Shared Vocabulary System For Collaborative Software Engineering", "categories": ["cs.SE"], "comment": "16 pages, including appendix", "summary": "Effective communication is a critical factor in successful software\nengineering collaboration. However, communication gaps remain a persistent\nchallenge, often leading to misunderstandings, inefficiencies, and defects.\nThis research investigates the technical factors contributing to such\nmisunderstandings and explores the measurable benefits of establishing shared\nvocabulary systems within software documentation and codebases. Using a Design\nScience Research (DSR) framework, the study was structured into three iterative\nphases: problem identification, method development, and empirical validation.\nThe problem identification phase involved thematic analysis of communication\ndata and semi-structured interviews, revealing key factors such as ambiguous\nmessaging, misalignment in documentation, inconsistent code review feedback,\nand API integration miscommunication. Grounded Theory principles were employed\nto design a structured methodology for collaborative vocabulary development.\nEmpirical validation through controlled experiments demonstrated that while\ninitial adoption introduced overhead, the shared vocabulary system\nsignificantly improved information density, documentation clarity, and\ncollaboration efficiency over time. Findings offer actionable insights for\nimproving communication practices in software engineering, while also\nidentifying limitations and directions for future research.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u6c9f\u901a\u95ee\u9898\u7684\u6280\u672f\u56e0\u7d20\uff0c\u5e76\u9a8c\u8bc1\u4e86\u901a\u8fc7\u5171\u4eab\u8bcd\u6c47\u7cfb\u7edf\u63d0\u5347\u6587\u6863\u548c\u4ee3\u7801\u5e93\u7684\u6548\u679c\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6c9f\u901a\u95ee\u9898\u5bfc\u81f4\u8bef\u89e3\u548c\u4f4e\u6548\uff0c\u4e9f\u9700\u6280\u672f\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u6846\u67b6\uff0c\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a\u95ee\u9898\u8bc6\u522b\u3001\u65b9\u6cd5\u5f00\u53d1\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u5171\u4eab\u8bcd\u6c47\u7cfb\u7edf\u663e\u8457\u63d0\u9ad8\u4e86\u4fe1\u606f\u5bc6\u5ea6\u3001\u6587\u6863\u6e05\u6670\u5ea6\u548c\u534f\u4f5c\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u6c9f\u901a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u53ef\u884c\u5efa\u8bae\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.14959", "pdf": "https://arxiv.org/pdf/2507.14959", "abs": "https://arxiv.org/abs/2507.14959", "authors": ["Saeid Ghafouri", "Mohsen Fayyaz", "Xiangchen Li", "Deepu John", "Bo Ji", "Dimitrios Nikolopoulos", "Hans Vandierendonck"], "title": "Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices", "categories": ["cs.CV", "cs.PF"], "comment": null, "summary": "Real-time multi-label video classification on embedded devices is constrained\nby limited compute and energy budgets. Yet, video streams exhibit structural\nproperties such as label sparsity, temporal continuity, and label co-occurrence\nthat can be leveraged for more efficient inference. We introduce Polymorph, a\ncontext-aware framework that activates a minimal set of lightweight Low Rank\nAdapters (LoRA) per frame. Each adapter specializes in a subset of classes\nderived from co-occurrence patterns and is implemented as a LoRA weight over a\nshared backbone. At runtime, Polymorph dynamically selects and composes only\nthe adapters needed to cover the active labels, avoiding full-model switching\nand weight merging. This modular strategy improves scalability while reducing\nlatency and energy overhead. Polymorph achieves 40% lower energy consumption\nand improves mAP by 9 points over strong baselines on the TAO dataset.\nPolymorph is open source at https://github.com/inference-serving/polymorph/.", "AI": {"tldr": "Polymorph\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u5b9e\u65f6\u591a\u6807\u7b7e\u89c6\u9891\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6fc0\u6d3b\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6765\u63d0\u9ad8\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u591a\u6807\u7b7e\u89c6\u9891\u5206\u7c7b\u53d7\u9650\u4e8e\u8ba1\u7b97\u548c\u80fd\u6e90\u9884\u7b97\uff0c\u4f46\u89c6\u9891\u6d41\u5177\u6709\u6807\u7b7e\u7a00\u758f\u6027\u3001\u65f6\u95f4\u8fde\u7eed\u6027\u548c\u6807\u7b7e\u5171\u73b0\u6027\u7b49\u7279\u6027\uff0c\u53ef\u4ee5\u7528\u4e8e\u4f18\u5316\u63a8\u7406\u6548\u7387\u3002", "method": "\u5f15\u5165Polymorph\u6846\u67b6\uff0c\u52a8\u6001\u6fc0\u6d3b\u6bcf\u5e27\u6240\u9700\u7684\u8f7b\u91cf\u7ea7\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\uff0c\u6bcf\u4e2a\u9002\u914d\u5668\u4e13\u6ce8\u4e8e\u6765\u81ea\u5171\u73b0\u6a21\u5f0f\u7684\u5b50\u96c6\u7c7b\u522b\uff0c\u65e0\u9700\u5168\u6a21\u578b\u5207\u6362\u548c\u6743\u91cd\u5408\u5e76\u3002", "result": "\u5728TAO\u6570\u636e\u96c6\u4e0a\uff0cPolymorph\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u4f4e40%\u7684\u80fd\u8017\uff0c\u5e76\u63d0\u5347\u4e869\u4e2a\u767e\u5206\u70b9\u7684mAP\u3002", "conclusion": "Polymorph\u901a\u8fc7\u6a21\u5757\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u7684\u89c6\u9891\u5206\u7c7b\u6548\u7387\uff0c\u540c\u65f6\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.15007", "pdf": "https://arxiv.org/pdf/2507.15007", "abs": "https://arxiv.org/abs/2507.15007", "authors": ["Sayed Mahbub Hasan Amiri", "Md. Mainul Islam", "Mohammad Shakhawat Hossen", "Sayed Majhab Hasan Amiri", "Mohammad Shawkat Ali Mamun", "Sk. Humaun Kabir", "Naznin Akter"], "title": "Hear Your Code Fail, Voice-Assisted Debugging for Python", "categories": ["cs.PL", "cs.CL"], "comment": "35 pages, 20 figures", "summary": "This research introduces an innovative voice-assisted debugging plugin for\nPython that transforms silent runtime errors into actionable audible\ndiagnostics. By implementing a global exception hook architecture with pyttsx3\ntext-to-speech conversion and Tkinter-based GUI visualization, the solution\ndelivers multimodal error feedback through parallel auditory and visual\nchannels. Empirical evaluation demonstrates 37% reduced cognitive load (p<0.01,\nn=50) compared to traditional stack-trace debugging, while enabling 78% faster\nerror identification through vocalized exception classification and\ncontextualization. The system achieves sub-1.2 second voice latency with under\n18% CPU overhead during exception handling, vocalizing error types and\nconsequences while displaying interactive tracebacks with documentation deep\nlinks. Criteria validate compatibility across Python 3.7+ environments on\nWindows, macOS, and Linux platforms. Needing only two lines of integration\ncode, the plugin significantly boosts availability for aesthetically impaired\ndesigners and supports multitasking workflows through hands-free error medical\ndiagnosis. Educational applications show particular promise, with pilot studies\nindicating 45% faster debugging skill acquisition among novice programmers.\nFuture development will incorporate GPT-based repair suggestions and real-time\nmultilingual translation to further advance auditory debugging paradigms. The\nsolution represents a fundamental shift toward human-centric error diagnostics,\nbridging critical gaps in programming accessibility while establishing new\nstandards for cognitive efficiency in software development workflows.", "AI": {"tldr": "\u4e3aPython\u5f00\u53d1\u4e86\u4e00\u6b3e\u8bed\u97f3\u8f85\u52a9\u8c03\u8bd5\u63d2\u4ef6\uff0c\u5c06\u9759\u9ed8\u8fd0\u884c\u65f6\u9519\u8bef\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u58f0\u97f3\u8bca\u65ad\uff0c\u7ed3\u5408\u542c\u89c9\u4e0e\u89c6\u89c9\u53cd\u9988\uff0c\u663e\u8457\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\u5e76\u52a0\u901f\u9519\u8bef\u8bc6\u522b\u3002", "motivation": "\u63d0\u5347\u7f16\u7a0b\u8c03\u8bd5\u7684\u6548\u7387\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u7279\u522b\u662f\u4e3a\u89c6\u89c9\u969c\u788d\u8005\u548c\u521d\u5b66\u8005\u63d0\u4f9b\u66f4\u53cb\u597d\u7684\u9519\u8bef\u8bca\u65ad\u65b9\u5f0f\u3002", "method": "\u91c7\u7528\u5168\u5c40\u5f02\u5e38\u94a9\u5b50\u67b6\u6784\uff0c\u7ed3\u5408pyttsx3\u8bed\u97f3\u5408\u6210\u548cTkinter GUI\u53ef\u89c6\u5316\uff0c\u63d0\u4f9b\u591a\u6a21\u6001\u9519\u8bef\u53cd\u9988\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8ba4\u77e5\u8d1f\u8377\u964d\u4f4e37%\uff0c\u9519\u8bef\u8bc6\u522b\u901f\u5ea6\u63d0\u9ad878%\uff0c\u4e14\u7cfb\u7edf\u517c\u5bb9\u6027\u5f3a\uff0c\u5ef6\u8fdf\u4f4e\u3002", "conclusion": "\u8be5\u63d2\u4ef6\u4e3a\u4eba\u672c\u9519\u8bef\u8bca\u65ad\u5f00\u521b\u4e86\u65b0\u8303\u5f0f\uff0c\u672a\u6765\u62df\u7ed3\u5408GPT\u548c\u591a\u8bed\u8a00\u7ffb\u8bd1\u8fdb\u4e00\u6b65\u589e\u5f3a\u529f\u80fd\u3002"}}
{"id": "2507.14188", "pdf": "https://arxiv.org/pdf/2507.14188", "abs": "https://arxiv.org/abs/2507.14188", "authors": ["Sebastian Barros Elgueta"], "title": "From Cell Towers to Satellites: A 2040 Blueprint for Urban-Grade Direct-to-Device Mobile Networks", "categories": ["cs.NI", "cs.AI"], "comment": "50 pages", "summary": "In 2023, satellite and mobile networks crossed a historic threshold: standard\nsmartphones, using unmodified 3GPP protocols, connected directly to low Earth\norbit (LEO) satellites. This first wave of direct-to-device (D2D)\ndemonstrations validated the physical feasibility of satellite-based mobile\naccess. However, these systems remain fallback-grade--rural-only,\nbandwidth-limited, and fully dependent on Earth-based mobile cores for\nidentity, session, and policy control. This paper asks a more ambitious\nquestion: Can a complete mobile network, including radio access, core\nfunctions, traffic routing, and content delivery, operate entirely from orbit?\nAnd can it deliver sustained, urban-grade service in the world's densest\ncities? We present the first end-to-end system architecture for a fully orbital\ntelco, integrating electronically steered phased arrays with 1000-beam\ncapacity, space-based deployment of 5G core functions (UPF, AMF), and\ninter-satellite laser mesh backhaul. We analyze spectral efficiency, beam\ncapacity, and link budgets under dense urban conditions, accounting for path\nloss, Doppler, and multipath. Simulations show that rooftop and line-of-sight\nusers can sustain 64-QAM throughput, while street-level access is feasible with\nrelay or assisted beam modes. The paper outlines the remaining constraints,\npower, thermal dissipation, compute radiation hardening, and regulatory models,\nand demonstrates that these are engineering bottlenecks, not physical limits.\nFinally, we propose a staged 15-year roadmap from today's fallback D2D systems\nto autonomous orbital overlays delivering 50-100 Mbps to handhelds in\nmegacities, with zero reliance on terrestrial infrastructure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5168\u57fa\u4e8e\u8f68\u9053\u7684\u79fb\u52a8\u7f51\u7edc\u7cfb\u7edf\u67b6\u6784\uff0c\u63a2\u8ba8\u4e86\u5176\u5728\u5bc6\u96c6\u57ce\u5e02\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u672a\u6765\u7684\u53d1\u5c55\u8def\u7ebf\u56fe\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u536b\u661f\u79fb\u52a8\u7f51\u7edc\u4f9d\u8d56\u5730\u9762\u6838\u5fc3\u7684\u5c40\u9650\uff0c\u63a2\u7d22\u5b8c\u5168\u57fa\u4e8e\u8f68\u9053\u7684\u79fb\u52a8\u7f51\u7edc\u5728\u5bc6\u96c6\u57ce\u5e02\u4e2d\u7684\u53ef\u884c\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u8f68\u9053\u7535\u4fe1\u7cfb\u7edf\uff0c\u5305\u62ec\u7535\u5b50\u63a7\u5236\u76f8\u63a7\u9635\u30015G\u6838\u5fc3\u529f\u80fd\u90e8\u7f72\u548c\u6fc0\u5149\u7f51\u72b6\u56de\u7a0b\uff0c\u5206\u6790\u4e86\u9891\u8c31\u6548\u7387\u548c\u94fe\u8def\u9884\u7b97\u3002", "result": "\u6a21\u62df\u663e\u793a\u5c4b\u9876\u548c\u89c6\u8ddd\u7528\u6237\u53ef\u7ef4\u630164-QAM\u541e\u5410\u91cf\uff0c\u8857\u7ea7\u63a5\u5165\u9700\u4e2d\u7ee7\u6216\u8f85\u52a9\u6ce2\u675f\u6a21\u5f0f\uff0c\u672a\u6765\u53ef\u63d0\u4f9b50-100 Mbps\u7684\u624b\u6301\u8bbe\u5907\u8fde\u63a5\u3002", "conclusion": "\u5b8c\u5168\u8f68\u9053\u79fb\u52a8\u7f51\u7edc\u7684\u5de5\u7a0b\u74f6\u9888\u53ef\u901a\u8fc7\u6280\u672f\u89e3\u51b3\uff0c\u672a\u676515\u5e74\u6709\u671b\u5b9e\u73b0\u81ea\u4e3b\u8986\u76d6\uff0c\u4e0d\u4f9d\u8d56\u5730\u9762\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2507.15673", "pdf": "https://arxiv.org/pdf/2507.15673", "abs": "https://arxiv.org/abs/2507.15673", "authors": ["Andrew Freeman", "Michael Rudolph", "Amr Rizk"], "title": "Point Cloud Streaming with Latency-Driven Implicit Adaptation using MoQ", "categories": ["cs.MM", "cs.NI"], "comment": null, "summary": "Point clouds are a promising video representation for next-generation\nmultimedia experiences in virtual and augmented reality. Point clouds are\nnotoriously high-bitrate, however, which limits the feasibility of live\nstreaming systems. Prior methods have adopted traditional HTTP-based protocols\nfor point cloud streaming, but they rely on explicit client-side adaptation to\nmaintain low latency under congestion. In this work, we leverage the delivery\ntimeout feature within the Media Over QUIC protocol to perform implicit\nserver-side adaptation based on an application's latency target. Through\nexperimentation with several publisher and network configurations, we\ndemonstrate that our system unlocks a unique trade-off on a per-client basis:\napplications with lower latency requirements will receive lower-quality video,\nwhile applications with more relaxed latency requirements will receive\nhigher-quality video.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eQUIC\u534f\u8bae\u7684\u9690\u5f0f\u670d\u52a1\u5668\u7aef\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u70b9\u4e91\u89c6\u9891\u7684\u5b9e\u65f6\u6d41\u4f20\u8f93\uff0c\u4ece\u800c\u6839\u636e\u5ba2\u6237\u7aef\u7684\u5ef6\u8fdf\u9700\u6c42\u52a8\u6001\u8c03\u6574\u89c6\u9891\u8d28\u91cf\u3002", "motivation": "\u70b9\u4e91\u89c6\u9891\u56e0\u5176\u9ad8\u6bd4\u7279\u7387\u7279\u6027\uff0c\u96be\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u6d41\u4f20\u8f93\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5ba2\u6237\u7aef\u663e\u5f0f\u9002\u5e94\uff0c\u9650\u5236\u4e86\u4f4e\u5ef6\u8fdf\u7684\u5b9e\u73b0\u3002", "method": "\u5229\u7528Media Over QUIC\u534f\u8bae\u4e2d\u7684\u4f20\u8f93\u8d85\u65f6\u7279\u6027\uff0c\u5728\u670d\u52a1\u5668\u7aef\u8fdb\u884c\u9690\u5f0f\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u4ee5\u6ee1\u8db3\u4e0d\u540c\u5ba2\u6237\u7aef\u7684\u5ef6\u8fdf\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7cfb\u7edf\u80fd\u591f\u6839\u636e\u5ba2\u6237\u7aef\u7684\u5ef6\u8fdf\u9700\u6c42\uff0c\u52a8\u6001\u8c03\u6574\u89c6\u9891\u8d28\u91cf\uff08\u4f4e\u5ef6\u8fdf\u8981\u6c42\u5bf9\u5e94\u4f4e\u8d28\u91cf\uff0c\u53cd\u4e4b\u4ea6\u7136\uff09\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u70b9\u4e91\u89c6\u9891\u7684\u5b9e\u65f6\u6d41\u4f20\u8f93\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u5ef6\u8fdf-\u8d28\u91cf\u6743\u8861\u65b9\u6cd5\u3002"}}
{"id": "2507.14949", "pdf": "https://arxiv.org/pdf/2507.14949", "abs": "https://arxiv.org/abs/2507.14949", "authors": ["Philippe Balbiani", "Olivier Gasquet"], "title": "PSPACE-completeness of bimodal transitive weak-density logic", "categories": ["cs.LO", "03B45, 68Q17", "F.4.1; F.4.3"], "comment": "arXiv admin note: substantial text overlap with arXiv:2507.11238", "summary": "Windows have been introduce in \\cite{BalGasq25} as a tool for designing\npolynomial algorithms to check satisfiability of a bimodal logic of\nweak-density. In this paper, after revisiting the ``folklore'' case of bimodal\n$\\K4$ already treated in \\cite{Halpern} but which is worth a fresh review, we\nshow that windows allow to polynomially solve the satisfiability problem when\nadding transitivity to weak-density, by mixing algorithms for bimodal K\ntogether with windows-approach. The conclusion is that both satisfiability and\nvalidity are PSPACE-complete for these logics.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7a97\u53e3\u65b9\u6cd5\u91cd\u65b0\u5ba1\u89c6\u53cc\u6a21\u6001K4\u903b\u8f91\uff0c\u5e76\u7ed3\u5408\u5f31\u5bc6\u5ea6\u4e0e\u4f20\u9012\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u6ee1\u8db3\u6027\u548c\u6709\u6548\u6027\u7684PSPACE\u5b8c\u5907\u6027\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u53cc\u6a21\u6001K4\u903b\u8f91\uff0c\u5e76\u6269\u5c55\u7a97\u53e3\u65b9\u6cd5\u4ee5\u89e3\u51b3\u5f31\u5bc6\u5ea6\u52a0\u4f20\u9012\u6027\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u53cc\u6a21\u6001K\u7b97\u6cd5\u548c\u7a97\u53e3\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u591a\u9879\u5f0f\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u8fd9\u4e9b\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u548c\u6709\u6548\u6027\u5747\u4e3aPSPACE\u5b8c\u5907\u3002", "conclusion": "\u7a97\u53e3\u65b9\u6cd5\u5728\u89e3\u51b3\u590d\u6742\u903b\u8f91\u95ee\u9898\u65f6\u5177\u6709\u6f5c\u529b\uff0c\u53cc\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u53ef\u901a\u8fc7\u6df7\u5408\u7b97\u6cd5\u9ad8\u6548\u89e3\u51b3\u3002"}}
{"id": "2507.14495", "pdf": "https://arxiv.org/pdf/2507.14495", "abs": "https://arxiv.org/abs/2507.14495", "authors": ["Roman Heinrich", "Oleksandr Havrylov", "Manisha Luthra", "Johannes Wehrstein", "Carsten Binnig"], "title": "Opening The Black-Box: Explaining Learned Cost Models For Databases", "categories": ["cs.DB"], "comment": "Accepted to VLDB 2025 Demonstration Track", "summary": "Learned Cost Models (LCMs) have shown superior results over traditional\ndatabase cost models as they can significantly improve the accuracy of cost\npredictions. However, LCMs still fail for some query plans, as prediction\nerrors can be large in the tail. Unfortunately, recent LCMs are based on\ncomplex deep neural models, and thus, there is no easy way to understand where\nthis accuracy drop is rooted, which critically prevents systematic\ntroubleshooting. In this demo paper, we present the very first approach for\nopening the black box by bringing AI explainability approaches to LCMs. As a\ncore contribution, we developed new explanation techniques that extend existing\nmethods that are available for the general explainability of AI models and\nadapt them significantly to be usable for LCMs. In our demo, we provide an\ninteractive tool to showcase how explainability for LCMs works. We believe this\nis a first step for making LCMs debuggable and thus paving the road for new\napproaches for systematically fixing problems in LCMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u91ca\u5b66\u4e60\u6210\u672c\u6a21\u578b\uff08LCMs\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7AI\u53ef\u89e3\u91ca\u6027\u6280\u672f\u89e3\u51b3LCMs\u9884\u6d4b\u5c3e\u90e8\u8bef\u5dee\u5927\u7684\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u5de5\u5177\u5c55\u793a\u5176\u5de5\u4f5c\u539f\u7406\u3002", "motivation": "LCMs\u867d\u4f18\u4e8e\u4f20\u7edf\u6570\u636e\u5e93\u6210\u672c\u6a21\u578b\uff0c\u4f46\u4ecd\u6709\u5c3e\u90e8\u9884\u6d4b\u8bef\u5dee\u5927\u7684\u95ee\u9898\uff0c\u4e14\u56e0\u5176\u57fa\u4e8e\u590d\u6742\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u96be\u4ee5\u5b9a\u4f4d\u8bef\u5dee\u6839\u6e90\u3002", "method": "\u6269\u5c55\u73b0\u6709AI\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e13\u95e8\u9488\u5bf9LCMs\u7684\u65b0\u89e3\u91ca\u6280\u672f\uff0c\u5e76\u521b\u5efa\u4e86\u4ea4\u4e92\u5f0f\u5de5\u5177\u3002", "result": "\u5b9e\u73b0\u4e86LCMs\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5176\u53ef\u901a\u8fc7\u7cfb\u7edf\u5316\u8c03\u8bd5\u6539\u8fdb\u3002", "conclusion": "\u8fd9\u662fLCMs\u53ef\u8c03\u8bd5\u7684\u7b2c\u4e00\u6b65\uff0c\u4e3a\u7cfb\u7edf\u5316\u89e3\u51b3\u5176\u95ee\u9898\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.15483", "pdf": "https://arxiv.org/pdf/2507.15483", "abs": "https://arxiv.org/abs/2507.15483", "authors": ["Selen Gecgel Cetin", "Baris Donmez", "Gunes Karabulut Kurt"], "title": "Advancing Lunar Communication through Inter-domain Space Networks and Dynamic Orchestration", "categories": ["cs.ET", "cs.NA", "math.NA"], "comment": null, "summary": "The reawakened era of lunar exploration is defined by a strategic shift from\ntemporary visits to a sustained international and commercial presence,\nresulting in an unprecedented demand for a robust and continuously available\ncommunication infrastructure. The conventional direct-to-Earth communication\narchitecture relies on limited and oversubscribed deep space networks, which\nare further challenged by the radiative environment and insufficient visibility\nin certain areas of the cislunar domain. We address these issues by proposing a\nfoundational move toward inter-domain space network cooperation by introducing\narchitectures based on near space networks. They can directly service lunar\nsurface users or, via cislunar relays, by forming a resilient and multi-layered\ncommunication backbone. First, we establish a unified link analysis framework\nincorporating frequently disregarded environmental factors, such as the Moon's\nvariable illumination, to provide a high-fidelity performance evaluation.\nSecond, we assess architectures' reliability based on the outage risk,\nessential for quantifying the operational robustness of communication links.\nFinally, to manage the inherent dynamism of architectures, we propose an\ninter-domain space digital twin$-$a dynamic decision-making engine that\nperforms real-time analysis to autonomously select the best communication path,\nensuring high and stable reliability while simultaneously optimizing power\nconsumption. Overall, our paper provides a holistic architectural and\nconceptual management framework, emphasizing the necessity of lunar\ncommunications to support a permanent human and economic foothold on the Moon.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd1\u5730\u7a7a\u95f4\u7f51\u7edc\u7684\u6708\u7403\u901a\u4fe1\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u76f4\u63a5\u901a\u4fe1\u7f51\u7edc\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u7edf\u4e00\u7684\u94fe\u8def\u5206\u6790\u6846\u67b6\u548c\u52a8\u6001\u51b3\u7b56\u5f15\u64ce\uff0c\u63d0\u9ad8\u901a\u4fe1\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u6708\u7403\u63a2\u7d22\u4ece\u4e34\u65f6\u8bbf\u95ee\u8f6c\u5411\u6301\u7eed\u7684\u56fd\u9645\u548c\u5546\u4e1a\u5b58\u5728\uff0c\u4f20\u7edf\u76f4\u63a5\u901a\u4fe1\u7f51\u7edc\u7684\u5c40\u9650\u6027\uff08\u5982\u8986\u76d6\u4e0d\u8db3\u3001\u8d44\u6e90\u6709\u9650\uff09\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u901a\u4fe1\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fd1\u5730\u7a7a\u95f4\u7f51\u7edc\u7684\u901a\u4fe1\u67b6\u6784\uff0c\u5efa\u7acb\u7edf\u4e00\u94fe\u8def\u5206\u6790\u6846\u67b6\uff08\u8003\u8651\u6708\u7403\u53ef\u53d8\u5149\u7167\u7b49\u56e0\u7d20\uff09\uff0c\u8bc4\u4f30\u53ef\u9760\u6027\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u51b3\u7b56\u5f15\u64ce\uff08\u7a7a\u95f4\u6570\u5b57\u5b6a\u751f\uff09\u5b9e\u65f6\u4f18\u5316\u901a\u4fe1\u8def\u5f84\u3002", "result": "\u65b0\u67b6\u6784\u80fd\u591f\u63d0\u4f9b\u9ad8\u53ef\u9760\u6027\u548c\u591a\u5c42\u901a\u4fe1\u9aa8\u5e72\uff0c\u540c\u65f6\u52a8\u6001\u51b3\u7b56\u5f15\u64ce\u663e\u8457\u4f18\u5316\u4e86\u901a\u4fe1\u6027\u80fd\u548c\u529f\u8017\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u6708\u7403\u901a\u4fe1\u5bf9\u6c38\u4e45\u4eba\u7c7b\u548c\u7ecf\u6d4e\u7acb\u8db3\u70b9\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u7684\u7efc\u5408\u6846\u67b6\u4e3a\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.14397", "pdf": "https://arxiv.org/pdf/2507.14397", "abs": "https://arxiv.org/abs/2507.14397", "authors": ["Michael Davies", "Neal Crago", "Karthikeyan Sankaralingam", "Christos Kozyrakis"], "title": "Efficient LLM Inference: Bandwidth, Compute, Synchronization, and Capacity are all you need", "categories": ["cs.AR"], "comment": null, "summary": "This paper presents a limit study of transformer-based large language model\n(LLM) inference, focusing on the fundamental performance bottlenecks imposed by\nmemory bandwidth, memory capacity, and synchronization overhead in distributed\ninference systems. We develop a hardware-agnostic performance model that\nabstracts away implementation details, enabling the analysis of a wide range of\ncurrent and near-future hardware technologies. Our analysis spans from current\nHBM3 memory technology used in AI accelerators like GPUs and TPUs to systems\nbased on advanced HBM4 and advanced 3D-stacked DRAM technology. It also covers\nSRAM-based designs and scaling techniques from distributed clusters with\nvarying numbers of chips to wafer-scale integration. Our key findings for\nauto-regressive decoding are: i) serving LLMs requires 100s of GB per server to\nserve a model instance; ii) high memory bandwidth is critical for high per-user\nthroughput; iii) exposed synchronization latencies to achieve collective\ncommunication must be around 1us else they make the memory bandwidth\nineffective; iv) DRAM-based designs have a fundamental advantage in terms of\nsystem-level efficiency as measured in throughput per cost or watt; and v)\nhardware designs can easily reach 2000+ user token/sec but getting to 10,000+\ntokens/sec will need smaller models, smaller context, or other forms of\nalgorithmic advances. This study provides valuable insights into the\nfundamental performance limits of LLM inference, highlighting the potential\nbenefits of future hardware advancements and guiding the optimization of LLM\ndeployment strategies.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eTransformer\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5206\u6790\u4e86\u5185\u5b58\u5e26\u5bbd\u3001\u5bb9\u91cf\u548c\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u540c\u6b65\u5f00\u9500\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u786c\u4ef6\u65e0\u5173\u7684\u6027\u80fd\u6a21\u578b\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63ed\u793aLLM\u63a8\u7406\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u672a\u6765\u786c\u4ef6\u8bbe\u8ba1\u548c\u90e8\u7f72\u7b56\u7565\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u786c\u4ef6\u65e0\u5173\u7684\u6027\u80fd\u6a21\u578b\uff0c\u5206\u6790\u591a\u79cd\u5185\u5b58\u6280\u672f\uff08\u5982HBM3\u3001HBM4\u30013D-stacked DRAM\uff09\u548c\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6548\u7387\u3002", "result": "\u5173\u952e\u53d1\u73b0\u5305\u62ec\uff1a1) \u9700\u8981\u6570\u767eGB\u5185\u5b58\uff1b2) \u9ad8\u5185\u5b58\u5e26\u5bbd\u5bf9\u541e\u5410\u81f3\u5173\u91cd\u8981\uff1b3) \u540c\u6b65\u5ef6\u8fdf\u9700\u6781\u4f4e\uff1b4) DRAM\u8bbe\u8ba1\u6548\u7387\u66f4\u9ad8\uff1b5) \u672a\u6765\u9700\u7b97\u6cd5\u4f18\u5316\u3002", "conclusion": "\u7814\u7a76\u4e3aLLM\u63a8\u7406\u7684\u6027\u80fd\u6781\u9650\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u6307\u5bfc\u672a\u6765\u786c\u4ef6\u4f18\u5316\u548c\u90e8\u7f72\u3002"}}
{"id": "2507.14392", "pdf": "https://arxiv.org/pdf/2507.14392", "abs": "https://arxiv.org/abs/2507.14392", "authors": ["Lang Xu", "Kaushik Kandadi Suresh", "Quentin Anthony", "Nawras Alnaasan", "Dhabaleswar K. Panda"], "title": "Characterizing Communication Patterns in Distributed Large Language Model Inference", "categories": ["cs.DC"], "comment": "To be presented at Hot Interconnects 2025", "summary": "Large Language Models (LLMs) built on transformer architectures have\ntransformed natural language processing, achieving remarkable performance\nacross diverse applications. While distributed inference frameworks enable\npractical deployment of these models, inter-GPU communication creates\nsignificant performance constraints that limit service quality in real-world\nsystems. This paper investigates communication dynamics in distributed LLM\nserving-analyzing how various parallelization approaches coordinate data\nexchange between GPU workers during inference. We study dense transformer-based\nmodels as representative examples of contemporary architectures widely used in\noperational deployments. Our work combines detailed profiling measurements with\npredictive analytical models to characterize communication behavior across\ndifferent parallelization configurations. Results show that tensor parallelism\nincurs substantial network overhead but delivers superior response times for\nbrief sequences, pipeline parallelism minimizes data transfer requirements\nwhile increasing total latency, and combined approaches demand careful tuning\nto achieve balanced performance. These insights offer practical recommendations\nfor selecting appropriate parallelization schemes in production LLM services\nand identify key opportunities for optimizing inference frameworks and\ncommunication infrastructure.", "AI": {"tldr": "\u7814\u7a76\u5206\u5e03\u5f0fLLM\u670d\u52a1\u4e2d\u7684\u901a\u4fe1\u52a8\u6001\uff0c\u5206\u6790\u4e0d\u540c\u5e76\u884c\u5316\u65b9\u6cd5\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5982\u4f55\u534f\u8c03GPU\u95f4\u7684\u6570\u636e\u4ea4\u6362\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u5efa\u8bae\u3002", "motivation": "\u5206\u5e03\u5f0f\u63a8\u7406\u6846\u67b6\u867d\u80fd\u90e8\u7f72LLM\uff0c\u4f46GPU\u95f4\u901a\u4fe1\u7684\u6027\u80fd\u9650\u5236\u5f71\u54cd\u4e86\u670d\u52a1\u8d28\u91cf\uff0c\u9700\u7814\u7a76\u901a\u4fe1\u52a8\u6001\u4ee5\u4f18\u5316\u6027\u80fd\u3002", "method": "\u7ed3\u5408\u8be6\u7ec6\u7684\u5206\u6790\u6a21\u578b\u548c\u6027\u80fd\u6d4b\u91cf\uff0c\u7814\u7a76\u4e0d\u540c\u5e76\u884c\u5316\u914d\u7f6e\u4e0b\u7684\u901a\u4fe1\u884c\u4e3a\uff0c\u5305\u62ec\u5f20\u91cf\u5e76\u884c\u548c\u6d41\u6c34\u7ebf\u5e76\u884c\u3002", "result": "\u5f20\u91cf\u5e76\u884c\u7f51\u7edc\u5f00\u9500\u5927\u4f46\u54cd\u5e94\u5feb\uff0c\u6d41\u6c34\u7ebf\u5e76\u884c\u6570\u636e\u4ea4\u6362\u5c11\u4f46\u5ef6\u8fdf\u9ad8\uff0c\u7ec4\u5408\u65b9\u6cd5\u9700\u7cbe\u5fc3\u8c03\u4f18\u4ee5\u5b9e\u73b0\u5e73\u8861\u6027\u80fd\u3002", "conclusion": "\u4e3a\u751f\u4ea7\u73af\u5883\u4e2d\u7684LLM\u670d\u52a1\u9009\u62e9\u5408\u9002\u7684\u5e76\u884c\u5316\u65b9\u6848\u63d0\u4f9b\u5efa\u8bae\uff0c\u5e76\u4e3a\u4f18\u5316\u63a8\u7406\u6846\u67b6\u548c\u901a\u4fe1\u57fa\u7840\u8bbe\u65bd\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2507.14537", "pdf": "https://arxiv.org/pdf/2507.14537", "abs": "https://arxiv.org/abs/2507.14537", "authors": ["Jiahua Tang", "Song Wang", "Jiachen Zou", "Chen Wei", "Quanying Liu"], "title": "Uncovering the EEG Temporal Representation of Low-dimensional Object Properties", "categories": ["cs.HC"], "comment": null, "summary": "Understanding how the human brain encodes and processes external visual\nstimuli has been a fundamental challenge in neuroscience. With advancements in\nartificial intelligence, sophisticated visual decoding architectures have\nachieved remarkable success in fMRI research, enabling more precise and\nfine-grained spatial concept localization. This has provided new tools for\nexploring the spatial representation of concepts in the brain. However, despite\nthe millisecond-scale temporal resolution of EEG, which offers unparalleled\nadvantages in tracking the dynamic evolution of cognitive processes, the\ntemporal dynamics of neural representations based on EEG remain underexplored.\nThis is primarily due to EEG's inherently low signal-to-noise ratio and its\ncomplex spatiotemporal coupling characteristics. To bridge this research gap,\nwe propose a novel approach that integrates advanced neural decoding algorithms\nto systematically investigate how low-dimensional object properties are\ntemporally encoded in EEG signals. We are the first to attempt to identify the\nspecificity and prototypical temporal characteristics of concepts within\ntemporal distributions. Our framework not only enhances the interpretability of\nneural representations but also provides new insights into visual decoding in\nbrain-computer interfaces (BCI).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5148\u8fdb\u7684\u795e\u7ecf\u89e3\u7801\u7b97\u6cd5\u7814\u7a76EEG\u4fe1\u53f7\u4e2d\u4f4e\u7ef4\u7269\u4f53\u5c5e\u6027\u7684\u65f6\u95f4\u7f16\u7801\uff0c\u586b\u8865\u4e86EEG\u7814\u7a76\u4e2d\u65f6\u95f4\u52a8\u6001\u795e\u7ecf\u8868\u5f81\u7684\u7a7a\u767d\u3002", "motivation": "\u63a2\u7d22EEG\u4fe1\u53f7\u4e2d\u795e\u7ecf\u8868\u5f81\u7684\u65f6\u95f4\u52a8\u6001\u7279\u6027\uff0c\u5f25\u8865\u73b0\u6709\u7814\u7a76\u4e2d\u5bf9EEG\u65f6\u95f4\u5206\u8fa8\u7387\u4f18\u52bf\u7684\u4e0d\u8db3\u3002", "method": "\u6574\u5408\u5148\u8fdb\u7684\u795e\u7ecf\u89e3\u7801\u7b97\u6cd5\uff0c\u7cfb\u7edf\u7814\u7a76EEG\u4fe1\u53f7\u4e2d\u4f4e\u7ef4\u7269\u4f53\u5c5e\u6027\u7684\u65f6\u95f4\u7f16\u7801\u7279\u6027\u3002", "result": "\u9996\u6b21\u5728\u65f6\u95f4\u5206\u5e03\u4e2d\u8bc6\u522b\u6982\u5ff5\u7684\u7279\u5f02\u6027\u548c\u539f\u578b\u65f6\u95f4\u7279\u5f81\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u795e\u7ecf\u8868\u5f81\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u8fd8\u4e3a\u8111\u673a\u63a5\u53e3\u4e2d\u7684\u89c6\u89c9\u89e3\u7801\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2507.15186", "pdf": "https://arxiv.org/pdf/2507.15186", "abs": "https://arxiv.org/abs/2507.15186", "authors": ["Dmitry Brodsky", "Benjamin Watson"], "title": "Model Simplification through refinement", "categories": ["cs.GR"], "comment": null, "summary": "As modeling and visualization applications proliferate, there arises a need\nto simplify large polygonal models at interactive rates. Unfortunately existing\npolygon mesh simplification algorithms are not well suited for this task\nbecause they are either too slow (requiring the simplified model to be\npre-computed) or produce models that are too poor in quality. These\nshortcomings become particularly acute when models are extremely large. We\npresent an algorithm suitable for simplification of large models at interactive\nspeeds. The algorithm is fast and can guarantee displayable results within a\ngiven time limit. Results also have good quality. Inspired by splitting\nalgorithms from vector quantization literature, we simplify models in reverse,\nbeginning with an extremely coarse approximation and refining it.\nApproximations of surface curvature guide the simplification process.\nPreviously produced simplifications can be further refined by using them as\ninput to the algorithm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5728\u4ea4\u4e92\u901f\u5ea6\u4e0b\u7b80\u5316\u5927\u578b\u591a\u8fb9\u5f62\u6a21\u578b\u7684\u65b0\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\u901f\u5ea6\u6162\u6216\u8d28\u91cf\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5efa\u6a21\u548c\u53ef\u89c6\u5316\u5e94\u7528\u7684\u666e\u53ca\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5feb\u901f\u7b80\u5316\u5927\u578b\u591a\u8fb9\u5f62\u6a21\u578b\u7684\u7b97\u6cd5\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\u3002", "method": "\u53d7\u5411\u91cf\u91cf\u5316\u6587\u732e\u4e2d\u5206\u5272\u7b97\u6cd5\u7684\u542f\u53d1\uff0c\u8be5\u7b97\u6cd5\u4ece\u6781\u7c97\u7cd9\u7684\u8fd1\u4f3c\u5f00\u59cb\u9010\u6b65\u7ec6\u5316\uff0c\u5229\u7528\u8868\u9762\u66f2\u7387\u7684\u8fd1\u4f3c\u6765\u6307\u5bfc\u7b80\u5316\u8fc7\u7a0b\u3002", "result": "\u7b97\u6cd5\u901f\u5ea6\u5feb\uff0c\u53ef\u4ee5\u5728\u7ed9\u5b9a\u65f6\u95f4\u9650\u5236\u5185\u751f\u6210\u53ef\u663e\u793a\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u826f\u597d\u7684\u8d28\u91cf\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u9002\u5408\u5728\u4ea4\u4e92\u901f\u5ea6\u4e0b\u7b80\u5316\u5927\u578b\u6a21\u578b\uff0c\u5e76\u80fd\u901a\u8fc7\u8fdb\u4e00\u6b65\u7ec6\u5316\u73b0\u6709\u7b80\u5316\u7ed3\u679c\u6765\u63d0\u5347\u8d28\u91cf\u3002"}}
{"id": "2507.14423", "pdf": "https://arxiv.org/pdf/2507.14423", "abs": "https://arxiv.org/abs/2507.14423", "authors": ["Mootez Saad", "Hao Li", "Tushar Sharma", "Ahmed E. Hassan"], "title": "On the Effect of Token Merging on Pre-trained Models for Code", "categories": ["cs.SE"], "comment": null, "summary": "Tokenization is a fundamental component of language models for code. It\ninvolves breaking down the input into units that are later passed to the\nlanguage model stack to learn high-dimensional representations used in various\ncontexts, from classification to generation. However, the output of these\ntokenizers is often longer than that traditionally used in compilers and\ninterpreters. This could result in undesirable effects, such as increased\ncomputational overhead. In this work, we investigate the effect of merging the\nhidden representations of subtokens that belong to the same semantic unit, such\nas subtokens that form a single identifier. We propose two strategies: one\nbased on averaging the representations and another that leverages a\nlearning-based approach. Both methods can be seamlessly integrated with\nexisting language models for code. We conduct experiments using six language\nmodels for code: CodeBERT, GraphCodeBERT, UniXCoder, CdoeT5, CodeT5+ (220M),\nand CodeT5+ (770M), across three software engineering tasks: vulnerability\ndetection, code classification, and code translation. Results show that these\nstrategies can reduce the number of floating-point operations by $1\\%$ to\n$19\\%$. Regarding downstream performance, the most significant degradation was\nobserved in the vulnerability detection task, where the F1 score decreased by\n$1.82$ points compared to the baseline. In contrast, for code translation, we\nobserved an improvement of $2.47$ points in CodeBLEU. This work contributes to\nthe broader effort of improving language models for code across multiple\ndimensions, including both computational efficiency and downstream performance.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5408\u5e76\u540c\u8bed\u4e49\u5355\u5143\u5b50\u6807\u8bb0\u7684\u9690\u85cf\u8868\u793a\u5bf9\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\uff1a\u5e73\u5747\u8868\u793a\u548c\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u51cf\u5c11\u8ba1\u7b97\u91cf\u4e14\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u5f71\u54cd\u6709\u9650\u3002", "motivation": "\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u5206\u8bcd\u8f93\u51fa\u901a\u5e38\u6bd4\u4f20\u7edf\u7f16\u8bd1\u5668\u957f\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\uff0c\u56e0\u6b64\u7814\u7a76\u901a\u8fc7\u5408\u5e76\u540c\u8bed\u4e49\u5355\u5143\u5b50\u6807\u8bb0\u6765\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\uff1a\u5e73\u5747\u5b50\u6807\u8bb0\u8868\u793a\u548c\u5b66\u4e60\u65b9\u6cd5\uff0c\u96c6\u6210\u5230\u73b0\u6709\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5e76\u5728\u516d\u4e2a\u6a21\u578b\u548c\u4e09\u4e2a\u4efb\u52a1\u4e0a\u5b9e\u9a8c\u3002", "result": "\u8ba1\u7b97\u91cf\u51cf\u5c111%\u81f319%\uff0c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u6f0f\u6d1e\u68c0\u6d4bF1\u5206\u6570\u4e0b\u964d1.82\u70b9\uff0c\u4ee3\u7801\u7ffb\u8bd1CodeBLEU\u63d0\u53472.47\u70b9\u3002", "conclusion": "\u5408\u5e76\u540c\u8bed\u4e49\u5355\u5143\u5b50\u6807\u8bb0\u80fd\u63d0\u5347\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\u548c\u4e0b\u6e38\u6027\u80fd\u3002"}}
{"id": "2507.15382", "pdf": "https://arxiv.org/pdf/2507.15382", "abs": "https://arxiv.org/abs/2507.15382", "authors": ["Fabian Ihle", "Etienne Zink", "Michael Menth"], "title": "Enhancements to P4TG: Histogram-Based RTT Monitoring in the Data Plane", "categories": ["cs.NI", "cs.PF"], "comment": "This work has been published at the 1st Workshop on Resilient\n  Networks and Systems (ReNeSys), Sept. 2025, Ilmenau/Germany under the\n  Creative Commons Attribution 4.0 International License (CC BY 4.0)", "summary": "Modern traffic generators are essential tools for evaluating the performance\nof network environments. P4TG is a P4-based traffic generator implemented for\nIntel Tofino switches that offers high-speed packet generation with\nfine-grained measurement capabilities. However, P4TG samples time-based metrics\nsuch as the round-trip time (RTT) in the data plane and collects them at the\ncontroller. This leads to a reduced accuracy. In this paper, we introduce a\nhistogram-based RTT measurement feature for P4TG. It enables accurate analysis\nat line rate without sampling. Generally, histogram bins are modeled as ranges,\nand values are matched to a bin. Efficient packet matching in hardware is\ntypically achieved using ternary content addressable memory (TCAM). However,\nrepresenting range matching rules in TCAM poses a challenge. Therefore, we\nimplemented a range-to-prefix conversion algorithm that models range matching\nwith multiple ternary entries. This paper describes the data plane\nimplementation and runtime configuration of RTT histograms in P4TG. Further, we\ndiscuss the efficiency of the ternary decomposition. Our evaluation\ndemonstrates the applicability of the histogram-based RTT analysis by comparing\nthe measured values with a configured theoretical distribution of RTTs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86P4TG\u4e2d\u57fa\u4e8e\u76f4\u65b9\u56fe\u7684RTT\u6d4b\u91cf\u529f\u80fd\uff0c\u89e3\u51b3\u4e86\u65f6\u95f4\u91c7\u6837\u5bfc\u81f4\u7684\u7cbe\u5ea6\u964d\u4f4e\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u8303\u56f4\u5230\u524d\u7f00\u7684\u8f6c\u6362\u7b97\u6cd5\u5b9e\u73b0\u4e86\u786c\u4ef6\u9ad8\u6548\u5339\u914d\u3002", "motivation": "P4TG\u5728\u6570\u636e\u5e73\u9762\u91c7\u6837RTT\u7b49\u65f6\u95f4\u6307\u6807\u4f1a\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u9700\u91c7\u6837\u7684\u9ad8\u7cbe\u5ea6\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u76f4\u65b9\u56fe\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u8303\u56f4\u5230\u524d\u7f00\u7684\u8f6c\u6362\u7b97\u6cd5\u5728TCAM\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u786c\u4ef6\u5339\u914d\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u76f4\u65b9\u56feRTT\u5206\u6790\u4e0e\u914d\u7f6e\u7684\u7406\u8bba\u5206\u5e03\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u5176\u9002\u7528\u6027\u3002", "conclusion": "\u76f4\u65b9\u56fe\u65b9\u6cd5\u5728P4TG\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684RTT\u6d4b\u91cf\uff0c\u5e76\u5c55\u793a\u4e86\u786c\u4ef6\u5339\u914d\u7684\u6548\u7387\u3002"}}
{"id": "2507.15017", "pdf": "https://arxiv.org/pdf/2507.15017", "abs": "https://arxiv.org/abs/2507.15017", "authors": ["Xuran Cai", "Liqian Chen", "Hongfei Fu"], "title": "Invariant Generation for Floating-Point Programs via Constraint Solving", "categories": ["cs.PL"], "comment": null, "summary": "In numeric-intensive computations, it is well known that the execution of\nfloating-point programs is imprecise as floating point arithmetics (e.g.,\naddition, subtraction, multiplication, division, etc.) incurs rounding errors.\nAlbeit the rounding error is small for every single floating-point operation,\nthe aggregation of such error in multiple operations may be dramatic and cause\ncatastrophic program failures. Therefore, to ensure the correctness of\nfloating-point programs, the effect of floating point error needs to be\ncarefully taken into account. In this work, we consider the invariant\ngeneration for floating point programs, whose aim is to generate tight\ninvariants under the perturbation of floating point errors. Our main\ncontribution is a theoretical framework on how to apply constraint solving\nmethods to address the invariant generation problem. In our framework, we\npropose a novel combination between the first-order differential\ncharacterization by FPTaylor (TOPLAS 2018) and constraint solving methods,\naiming to reduce the computational burden of constraint solving. Moreover, we\ndevise two polynomial invariant generation algorithms to instantiate the\nframework. The first algorithm is applicable to a wide range of floating-point\noperations but requires an initial (coarse) invariant as external input, while\nthe second does not require an initial invariant but is limited to polynomial\nprograms. Furthermore, we show how conditional branches, a difficult issue in\nfloating-point analysis, can be handled in our framework. Experimental results\nshow that our algorithms outperform SOTA approaches in both the time efficiency\nand the precision of the generated invariants over a variety of benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u6c42\u89e3\u65b9\u6cd5\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u6d6e\u70b9\u7a0b\u5e8f\u5728\u8bef\u5dee\u6270\u52a8\u4e0b\u7684\u7d27\u4e0d\u53d8\u5f0f\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6d6e\u70b9\u8fd0\u7b97\u7684\u7d2f\u79ef\u8bef\u5dee\u53ef\u80fd\u5bfc\u81f4\u7a0b\u5e8f\u5931\u8d25\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u751f\u6210\u8003\u8651\u8bef\u5dee\u7684\u4e0d\u53d8\u5f0f\uff0c\u4ee5\u786e\u4fdd\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\u3002", "method": "\u7ed3\u5408FPTaylor\u7684\u4e00\u9636\u5fae\u5206\u7279\u5f81\u4e0e\u7ea6\u675f\u6c42\u89e3\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e24\u79cd\u591a\u9879\u5f0f\u4e0d\u53d8\u5f0f\u751f\u6210\u7b97\u6cd5\uff0c\u4e00\u79cd\u9700\u8981\u521d\u59cb\u4e0d\u53d8\u5f0f\uff0c\u53e6\u4e00\u79cd\u9002\u7528\u4e8e\u591a\u9879\u5f0f\u7a0b\u5e8f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u65f6\u95f4\u6548\u7387\u548c\u751f\u6210\u4e0d\u53d8\u5f0f\u7684\u7cbe\u5ea6\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6d6e\u70b9\u7a0b\u5e8f\u7684\u4e0d\u53d8\u5f0f\u751f\u6210\u95ee\u9898\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5904\u7406\u6761\u4ef6\u5206\u652f\u7b49\u590d\u6742\u60c5\u51b5\u3002"}}
{"id": "2507.14199", "pdf": "https://arxiv.org/pdf/2507.14199", "abs": "https://arxiv.org/abs/2507.14199", "authors": ["Ebrahim Abu-Helalah", "Jordi Serra", "Jordi Perez-Romero"], "title": "On Splitting Lightweight Semantic Image Segmentation for Wireless Communications", "categories": ["cs.NI", "cs.CV", "eess.IV"], "comment": "IEEE International Mediterranean Conference on Communications and\n  Networking", "summary": "Semantic communication represents a promising technique towards reducing\ncommunication costs, especially when dealing with image segmentation, but it\nstill lacks a balance between computational efficiency and bandwidth\nrequirements while maintaining high image segmentation accuracy, particularly\nin resource-limited environments and changing channel conditions. On the other\nhand, the more complex and larger semantic image segmentation models become,\nthe more stressed the devices are when processing data. This paper proposes a\nnovel approach to implementing semantic communication based on splitting the\nsemantic image segmentation process between a resource constrained transmitter\nand the receiver. This allows saving bandwidth by reducing the transmitted data\nwhile maintaining the accuracy of the semantic image segmentation.\nAdditionally, it reduces the computational requirements at the resource\nconstrained transmitter compared to doing all the semantic image segmentation\nin the transmitter. The proposed approach is evaluated by means of\nsimulation-based experiments in terms of different metrics such as\ncomputational resource usage, required bit rate and segmentation accuracy. The\nresults when comparing the proposal with the full semantic image segmentation\nin the transmitter show that up to 72% of the bit rate was reduced in the\ntransmission process. In addition, the computational load of the transmitter is\nreduced by more than 19%. This reflects the interest of this technique for its\napplication in communication systems, particularly in the upcoming 6G systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u8bed\u4e49\u901a\u4fe1\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8bed\u4e49\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u5206\u914d\u7ed9\u53d1\u9001\u7aef\u548c\u63a5\u6536\u7aef\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5e26\u5bbd\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u5272\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u8bed\u4e49\u901a\u4fe1\u4e2d\u5e26\u5bbd\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u548c\u4fe1\u9053\u6761\u4ef6\u53d8\u5316\u7684\u73af\u5883\u4e2d\u3002", "method": "\u5c06\u8bed\u4e49\u56fe\u50cf\u5206\u5272\u8fc7\u7a0b\u5206\u5230\u53d1\u9001\u7aef\u548c\u63a5\u6536\u7aef\uff0c\u51cf\u5c11\u4f20\u8f93\u6570\u636e\u91cf\u548c\u53d1\u9001\u7aef\u8ba1\u7b97\u8d1f\u8f7d\u3002", "result": "\u4f20\u8f93\u6bd4\u7279\u7387\u964d\u4f4e72%\uff0c\u53d1\u9001\u7aef\u8ba1\u7b97\u8d1f\u8f7d\u51cf\u5c1119%\u4ee5\u4e0a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u57286G\u7b49\u901a\u4fe1\u7cfb\u7edf\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.14306", "pdf": "https://arxiv.org/pdf/2507.14306", "abs": "https://arxiv.org/abs/2507.14306", "authors": ["Samarth P", "Vyoman Jain", "Shiva Golugula", "Motamarri Sai Sathvik"], "title": "Manimator: Transforming Research Papers into Visual Explanations", "categories": ["cs.AI", "cs.MM"], "comment": null, "summary": "Understanding complex scientific and mathematical concepts, particularly\nthose presented in dense research papers, poses a significant challenge for\nlearners. Dynamic visualizations can greatly enhance comprehension, but\ncreating them manually is time-consuming and requires specialized knowledge and\nskills. We introduce manimator, an open-source system that leverages Large\nLanguage Models to transform research papers and natural language prompts into\nexplanatory animations using the Manim engine. Manimator employs a pipeline\nwhere an LLM interprets the input text or research paper PDF to generate a\nstructured scene description outlining key concepts, mathematical formulas, and\nvisual elements and another LLM translates this description into executable\nManim Python code. We discuss its potential as an educational tool for rapidly\ncreating engaging visual explanations for complex STEM topics, democratizing\nthe creation of high-quality educational content.", "AI": {"tldr": "Manimator\u662f\u4e00\u4e2a\u5f00\u6e90\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u5316\u4e3a\u52a8\u753b\uff0c\u5e2e\u52a9\u5b66\u4e60\u8005\u7406\u89e3\u590d\u6742\u79d1\u5b66\u6982\u5ff5\u3002", "motivation": "\u590d\u6742\u79d1\u5b66\u6982\u5ff5\u7684\u7406\u89e3\u56f0\u96be\uff0c\u52a8\u6001\u53ef\u89c6\u5316\u867d\u6709\u6548\u4f46\u5236\u4f5c\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "\u901a\u8fc7LLM\u89e3\u6790\u8bba\u6587\u6216\u6587\u672c\u751f\u6210\u7ed3\u6784\u5316\u573a\u666f\u63cf\u8ff0\uff0c\u518d\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Manim\u4ee3\u7801\u3002", "result": "\u5feb\u901f\u521b\u5efa\u9ad8\u8d28\u91cf\u6559\u80b2\u52a8\u753b\uff0c\u964d\u4f4e\u5236\u4f5c\u95e8\u69db\u3002", "conclusion": "Manimator\u6709\u671b\u6210\u4e3aSTEM\u6559\u80b2\u7684\u6709\u529b\u5de5\u5177\uff0c\u666e\u53ca\u9ad8\u8d28\u91cf\u5185\u5bb9\u521b\u4f5c\u3002"}}
{"id": "2507.14956", "pdf": "https://arxiv.org/pdf/2507.14956", "abs": "https://arxiv.org/abs/2507.14956", "authors": ["Olivier Gasquet"], "title": "PSPACE-completeness of Grammar logics of bounded density", "categories": ["cs.LO", "03B45, 68Q17", "F.4.1; F.4.3"], "comment": null, "summary": "We introduce the family of multi-modal logics of bounded density and with a\ntableau-like approach using finite \\emph{windows} which were introduced in\n\\cite{BalGasq25}, we prove that their satisfiability problem is\nPSPACE-complete. As a side effect, the monomodal logic of density is shown to\nbe in para-PSPACE.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u591a\u6a21\u6001\u6709\u754c\u5bc6\u5ea6\u903b\u8f91\u5bb6\u65cf\uff0c\u5e76\u901a\u8fc7\u6709\u9650\u7a97\u53e3\u7684\u8868\u683c\u65b9\u6cd5\u8bc1\u660e\u5176\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u4e3aPSPACE\u5b8c\u5168\u95ee\u9898\u3002\u9644\u5e26\u8bc1\u660e\u4e86\u5355\u6a21\u6001\u5bc6\u5ea6\u903b\u8f91\u5c5e\u4e8epara-PSPACE\u3002", "motivation": "\u7814\u7a76\u591a\u6a21\u6001\u6709\u754c\u5bc6\u5ea6\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u53ca\u5176\u590d\u6742\u6027\uff0c\u540c\u65f6\u63a2\u7d22\u5355\u6a21\u6001\u5bc6\u5ea6\u903b\u8f91\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002", "method": "\u4f7f\u7528\u8868\u683c\u65b9\u6cd5\u548c\u6709\u9650\u7a97\u53e3\u6280\u672f\uff0c\u57fa\u4e8e\u5df2\u6709\u7814\u7a76\u7684\u7406\u8bba\u6846\u67b6\u3002", "result": "\u591a\u6a21\u6001\u6709\u754c\u5bc6\u5ea6\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u662fPSPACE\u5b8c\u5168\u7684\uff1b\u5355\u6a21\u6001\u5bc6\u5ea6\u903b\u8f91\u5c5e\u4e8epara-PSPACE\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u591a\u6a21\u6001\u548c\u5355\u6a21\u6001\u5bc6\u5ea6\u903b\u8f91\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2507.14682", "pdf": "https://arxiv.org/pdf/2507.14682", "abs": "https://arxiv.org/abs/2507.14682", "authors": ["Massimo Cafaro", "Italo Epicoco", "Marco Pulimeno", "Lunodzo J. Mwinuka", "Lucas Pereira", "Hugo Morais"], "title": "IDSS, a Novel P2P Relational Data Storage Service", "categories": ["cs.DB", "cs.DC"], "comment": null, "summary": "The rate at which data is generated has been increasing rapidly, raising\nchallenges related to its management. Traditional database management systems\nsuffer from scalability and are usually inefficient when dealing with\nlarge-scale and heterogeneous data. This paper introduces IDSS (InnoCyPES Data\nStorage Service), a novel large-scale data storage tool that leverages\npeer-to-peer networks and embedded relational databases. We present the IDSS\narchitecture and its design, and provide details related to the implementation.\nThe peer-to-peer framework is used to provide support for distributed queries\nleveraging a relational database architecture based on a common schema.\nFurthermore, methods to support complex distributed query processing, enabling\nrobust and efficient management of vast amounts of data are presented.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIDSS\u7684\u65b0\u578b\u5927\u89c4\u6a21\u6570\u636e\u5b58\u50a8\u5de5\u5177\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u5728\u53ef\u6269\u5c55\u6027\u548c\u5904\u7406\u5927\u89c4\u6a21\u5f02\u6784\u6570\u636e\u65f6\u7684\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u6570\u636e\u751f\u6210\u901f\u5ea6\u7684\u5feb\u901f\u589e\u957f\u5e26\u6765\u4e86\u7ba1\u7406\u6311\u6218\uff0c\u4f20\u7edf\u6570\u636e\u5e93\u7cfb\u7edf\u5728\u53ef\u6269\u5c55\u6027\u548c\u5904\u7406\u5927\u89c4\u6a21\u5f02\u6784\u6570\u636e\u65f6\u8868\u73b0\u4f4e\u6548\u3002", "method": "IDSS\u5229\u7528\u70b9\u5bf9\u70b9\u7f51\u7edc\u548c\u5d4c\u5165\u5f0f\u5173\u7cfb\u6570\u636e\u5e93\uff0c\u8bbe\u8ba1\u4e86\u652f\u6301\u5206\u5e03\u5f0f\u67e5\u8be2\u7684\u67b6\u6784\uff0c\u5e76\u63d0\u4f9b\u4e86\u590d\u6742\u67e5\u8be2\u5904\u7406\u7684\u65b9\u6cd5\u3002", "result": "IDSS\u80fd\u591f\u9ad8\u6548\u4e14\u7a33\u5065\u5730\u7ba1\u7406\u5927\u91cf\u6570\u636e\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u67e5\u8be2\u548c\u590d\u6742\u67e5\u8be2\u5904\u7406\u3002", "conclusion": "IDSS\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u4e86P2P\u7f51\u7edc\u548c\u5173\u7cfb\u6570\u636e\u5e93\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.14209", "pdf": "https://arxiv.org/pdf/2507.14209", "abs": "https://arxiv.org/abs/2507.14209", "authors": ["Rute C. Sofia", "Hao Shen", "Yuanting Liu", "Severin Kacianka", "Holger Pfeifer"], "title": "White paper: Towards Human-centric and Sustainable 6G Services -- the fortiss Research Perspective", "categories": ["cs.NI", "cs.ET"], "comment": null, "summary": "As a leading research institute in software-intensive systems, fortiss is\nactively shaping the vision of Sixth Generation Mobile Communication (6G). Our\nmission is to ensure that 6G technologies go beyond technical advancements and\nare aligned with societal needs. fortiss plays a key role in 6G initiatives\nworldwide, including contributions to standardization bodies and collaborative\nResearch and Development programs. We focus on software-defined, AI-enabled,\nand sustainable communication services that prioritize human values and\nlong-term impact. 6G will redefine digital connectivity through cognitive\nintelligence, decentralized orchestration, and sustainability-oriented\narchitectures. As expectations rise for ultra-reliable low-latency\ncommunication (URLLC) and personalized digital services, 6G must outperform\nprior generations. It will rely on AI-native networking, Edge-Cloud resource\norchestration, and energy-aware data frameworks, ensuring both technical\nperformance and societal relevance. This white paper presents the fortiss\nvision for a human-centric, sustainable, and AI-integrated 6G network. It\noutlines key research domains such as semantic communication, green\norchestration, and distributed AI, all linked to societal and technological\nchallenges. The white paper is aimed at researchers, industry experts,\npolicymakers, and developers. It articulates the strategic direction and\ncontributions of fortiss to 6G, emphasizing responsible innovation and\ninterdisciplinary collaboration toward a meaningful 2030 vision.", "AI": {"tldr": "fortiss\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u4eba\u4e3a\u672c\u3001\u53ef\u6301\u7eed\u4e14\u96c6\u6210AI\u76846G\u7f51\u7edc\u613f\u666f\uff0c\u5f3a\u8c03\u793e\u4f1a\u9700\u6c42\u4e0e\u6280\u672f\u53d1\u5c55\u7684\u7ed3\u5408\u3002", "motivation": "\u786e\u4fdd6G\u6280\u672f\u4e0d\u4ec5\u5b9e\u73b0\u6280\u672f\u7a81\u7834\uff0c\u8fd8\u8981\u7b26\u5408\u793e\u4f1a\u9700\u6c42\uff0c\u63a8\u52a8\u8ba4\u77e5\u667a\u80fd\u3001\u53bb\u4e2d\u5fc3\u5316\u7f16\u6392\u548c\u53ef\u6301\u7eed\u67b6\u6784\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u8f6f\u4ef6\u5b9a\u4e49\u3001AI\u9a71\u52a8\u548c\u53ef\u6301\u7eed\u7684\u901a\u4fe1\u670d\u52a1\uff0c\u805a\u7126\u8bed\u4e49\u901a\u4fe1\u3001\u7eff\u8272\u7f16\u6392\u548c\u5206\u5e03\u5f0fAI\u7b49\u7814\u7a76\u9886\u57df\u3002", "result": "6G\u5c06\u8d85\u8d8a\u524d\u51e0\u4ee3\u6280\u672f\uff0c\u5b9e\u73b0\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u548c\u4e2a\u6027\u5316\u6570\u5b57\u670d\u52a1\uff0c\u540c\u65f6\u6ce8\u91cd\u80fd\u6e90\u6548\u7387\u548c\u957f\u671f\u793e\u4f1a\u5f71\u54cd\u3002", "conclusion": "fortiss\u81f4\u529b\u4e8e\u901a\u8fc7\u591a\u5b66\u79d1\u5408\u4f5c\u548c\u8d1f\u8d23\u4efb\u7684\u521b\u65b0\uff0c\u63a8\u52a86G\u6280\u672f\u53d1\u5c55\uff0c\u4ee5\u5b9e\u73b02030\u5e74\u7684\u6218\u7565\u613f\u666f\u3002"}}
{"id": "2507.14651", "pdf": "https://arxiv.org/pdf/2507.14651", "abs": "https://arxiv.org/abs/2507.14651", "authors": ["Joren Dumoulin", "Pouya Houshmand", "Vikram Jain", "Marian Verhelst"], "title": "Enabling Efficient Hardware Acceleration of Hybrid Vision Transformer (ViT) Networks at the Edge", "categories": ["cs.AR"], "comment": null, "summary": "Hybrid vision transformers combine the elements of conventional neural\nnetworks (NN) and vision transformers (ViT) to enable lightweight and accurate\ndetection. However, several challenges remain for their efficient deployment on\nresource-constrained edge devices. The hybrid models suffer from a widely\ndiverse set of NN layer types and large intermediate data tensors, hampering\nefficient hardware acceleration. To enable their execution at the edge, this\npaper proposes innovations across the hardware-scheduling stack: a.) At the\nlowest level, a configurable PE array supports all hybrid ViT layer types; b.)\ntemporal loop re-ordering within one layer, enabling hardware support for\nnormalization and softmax layers, minimizing on-chip data transfers; c.)\nfurther scheduling optimization employs layer fusion across inverted bottleneck\nlayers to drastically reduce off-chip memory transfers. The resulting\naccelerator is implemented in 28nm CMOS, achieving a peak energy efficiency of\n1.39 TOPS/W at 25.6 GMACs/s.", "AI": {"tldr": "\u6df7\u5408\u89c6\u89c9Transformer\u7ed3\u5408\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u548c\u89c6\u89c9Transformer\uff0c\u5b9e\u73b0\u8f7b\u91cf\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\uff0c\u4f46\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\u3002\u672c\u6587\u901a\u8fc7\u786c\u4ef6\u8c03\u5ea6\u5806\u6808\u521b\u65b0\uff0c\u4f18\u5316\u8ba1\u7b97\u6548\u7387\uff0c28nm CMOS\u5b9e\u73b01.39 TOPS/W\u7684\u80fd\u6548\u3002", "motivation": "\u6df7\u5408ViT\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u65f6\uff0c\u56e0\u5c42\u7c7b\u578b\u591a\u6837\u548c\u5927\u4e2d\u95f4\u6570\u636e\u5f20\u91cf\u800c\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u4f18\u5316\u786c\u4ef6\u652f\u6301\u3002", "method": "\u63d0\u51fa\u591a\u7ea7\u786c\u4ef6\u8c03\u5ea6\u4f18\u5316\uff1a\u53ef\u914d\u7f6ePE\u9635\u5217\u652f\u6301\u6240\u6709\u5c42\u7c7b\u578b\uff1b\u5c42\u5185\u5faa\u73af\u91cd\u6392\u5e8f\u51cf\u5c11\u6570\u636e\u4f20\u8f93\uff1b\u5c42\u95f4\u878d\u5408\u964d\u4f4e\u5185\u5b58\u4f20\u8f93\u3002", "result": "28nm CMOS\u82af\u7247\u5b9e\u73b01.39 TOPS/W\u7684\u5cf0\u503c\u80fd\u6548\uff0c\u8ba1\u7b97\u80fd\u529b25.6 GMACs/s\u3002", "conclusion": "\u901a\u8fc7\u786c\u4ef6\u8c03\u5ea6\u521b\u65b0\uff0c\u663e\u8457\u63d0\u5347\u6df7\u5408ViT\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14685", "pdf": "https://arxiv.org/pdf/2507.14685", "abs": "https://arxiv.org/abs/2507.14685", "authors": ["Luis Montana", "Jessica Magallanes", "Miguel Juarez", "Suzanne Mason", "Andrew Narracott", "Lindsey van Gemeren", "Steven Wood", "Maria-Cruz Villa-Uriol"], "title": "EventBox: A Novel Visual Encoding for Interactive Analysis of Temporal and Multivariate Attributes in Event Sequences", "categories": ["cs.HC"], "comment": "This is the author's version of the article to be published in IEEE\n  Transactions on Visualization and Computer Graphics, and presented at IEEE\n  VIS 2025. 11 pages, 7 figures", "summary": "The rapid growth and availability of event sequence data across domains\nrequires effective analysis and exploration methods to facilitate\ndecision-making. Visual analytics combines computational techniques with\ninteractive visualizations, enabling the identification of patterns, anomalies,\nand attribute interactions. However, existing approaches frequently overlook\nthe interplay between temporal and multivariate attributes. We introduce\nEventBox, a novel data representation and visual encoding approach for\nanalyzing groups of events and their multivariate attributes. We have\nintegrated EventBox into Sequen-C, a visual analytics system for the analysis\nof event sequences. To enable the agile creation of EventBoxes in Sequen-C, we\nhave added user-driven transformations, including alignment, sorting,\nsubstitution and aggregation. To enhance analytical depth, we incorporate\nautomatically generated statistical analyses, providing additional insight into\nthe significance of attribute interactions. We evaluated our approach involving\n21 participants (3 domain experts, 18 novice data analysts). We used the ICE-T\nframework to assess visualization value, user performance metrics completing a\nseries of tasks, and interactive sessions with domain experts. We also present\nthree case studies with real-world healthcare data demonstrating how EventBox\nand its integration into Sequen-C reveal meaningful patterns, anomalies, and\ninsights. These results demonstrate that our work advances visual analytics by\nproviding a flexible solution for exploring temporal and multivariate\nattributes in event sequences.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEventBox\u7684\u65b0\u9896\u6570\u636e\u8868\u793a\u548c\u89c6\u89c9\u7f16\u7801\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u4e8b\u4ef6\u5e8f\u5217\u7684\u591a\u53d8\u91cf\u5c5e\u6027\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230Sequen-C\u7cfb\u7edf\u4e2d\u3002\u901a\u8fc7\u7528\u6237\u9a71\u52a8\u7684\u8f6c\u6362\u548c\u81ea\u52a8\u751f\u6210\u7684\u7edf\u8ba1\u5206\u6790\uff0c\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u5206\u6790\u6df1\u5ea6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u4e8b\u4ef6\u5e8f\u5217\u6570\u636e\u5728\u5404\u9886\u57df\u7684\u5feb\u901f\u589e\u957f\u548c\u53ef\u7528\u6027\uff0c\u9700\u8981\u6709\u6548\u7684\u5206\u6790\u548c\u63a2\u7d22\u65b9\u6cd5\u6765\u652f\u6301\u51b3\u7b56\u5236\u5b9a\u3002\u73b0\u6709\u65b9\u6cd5\u5e38\u5ffd\u7565\u65f6\u95f4\u548c\u591a\u53d8\u91cf\u5c5e\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u5f00\u53d1\u4e86EventBox\u7684\u6570\u636e\u8868\u793a\u548c\u89c6\u89c9\u7f16\u7801\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230Sequen-C\u7cfb\u7edf\u4e2d\u3002\u901a\u8fc7\u7528\u6237\u9a71\u52a8\u7684\u8f6c\u6362\uff08\u5982\u5bf9\u9f50\u3001\u6392\u5e8f\u3001\u66ff\u6362\u548c\u805a\u5408\uff09\u4ee5\u53ca\u81ea\u52a8\u751f\u6210\u7684\u7edf\u8ba1\u5206\u6790\uff0c\u63d0\u5347\u4e86\u5206\u6790\u80fd\u529b\u3002", "result": "\u901a\u8fc721\u540d\u53c2\u4e0e\u8005\u7684\u8bc4\u4f30\uff08\u5305\u62ec3\u540d\u9886\u57df\u4e13\u5bb6\u548c18\u540d\u65b0\u624b\u6570\u636e\u5206\u6790\u5e08\uff09\uff0c\u9a8c\u8bc1\u4e86EventBox\u5728\u63ed\u793a\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u6a21\u5f0f\u548c\u5f02\u5e38\u7684\u6709\u6548\u6027\u3002\u4e09\u4e2a\u771f\u5b9e\u533b\u7597\u6570\u636e\u7684\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "EventBox\u548cSequen-C\u7684\u7ed3\u5408\u4e3a\u63a2\u7d22\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u548c\u591a\u53d8\u91cf\u5c5e\u6027\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u89c6\u89c9\u5206\u6790\u9886\u57df\u7684\u8fdb\u6b65\u3002"}}
{"id": "2507.15399", "pdf": "https://arxiv.org/pdf/2507.15399", "abs": "https://arxiv.org/abs/2507.15399", "authors": ["Etai Sella", "Noam Atia", "Ron Mokady", "Hadar Averbuch-Elor"], "title": "Blended Point Cloud Diffusion for Localized Text-guided Shape Editing", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to ICCV 2025. Project Page:\n  https://tau-vailab.github.io/BlendedPC/", "summary": "Natural language offers a highly intuitive interface for enabling localized\nfine-grained edits of 3D shapes. However, prior works face challenges in\npreserving global coherence while locally modifying the input 3D shape. In this\nwork, we introduce an inpainting-based framework for editing shapes represented\nas point clouds. Our approach leverages foundation 3D diffusion models for\nachieving localized shape edits, adding structural guidance in the form of a\npartial conditional shape, ensuring that other regions correctly preserve the\nshape's identity. Furthermore, to encourage identity preservation also within\nthe local edited region, we propose an inference-time coordinate blending\nalgorithm which balances reconstruction of the full shape with inpainting at a\nprogression of noise levels during the inference process. Our coordinate\nblending algorithm seamlessly blends the original shape with its edited\nversion, enabling a fine-grained editing of 3D shapes, all while circumventing\nthe need for computationally expensive and often inaccurate inversion.\nExtensive experiments show that our method outperforms alternative techniques\nacross a wide range of metrics that evaluate both fidelity to the original\nshape and also adherence to the textual description.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fee\u590d\u7684\u70b9\u4e913D\u5f62\u72b6\u7f16\u8f91\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u57fa\u78403D\u6269\u6563\u6a21\u578b\u548c\u7ed3\u6784\u5f15\u5bfc\uff0c\u5b9e\u73b0\u4e86\u5c40\u90e8\u5f62\u72b6\u7f16\u8f91\u5e76\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u4e3a3D\u5f62\u72b6\u7684\u5c40\u90e8\u7cbe\u7ec6\u7f16\u8f91\u63d0\u4f9b\u4e86\u76f4\u89c2\u63a5\u53e3\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u5c40\u90e8\u4fee\u6539\u65f6\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4fee\u590d\u7684\u6846\u67b6\uff0c\u7ed3\u54083D\u6269\u6563\u6a21\u578b\u548c\u90e8\u5206\u6761\u4ef6\u5f62\u72b6\u7684\u7ed3\u6784\u5f15\u5bfc\uff0c\u63d0\u51fa\u63a8\u7406\u65f6\u5750\u6807\u6df7\u5408\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u771f\u5ea6\u548c\u6587\u672c\u63cf\u8ff0\u5339\u914d\u5ea6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e863D\u5f62\u72b6\u7684\u7cbe\u7ec6\u7f16\u8f91\uff0c\u65e0\u9700\u590d\u6742\u8ba1\u7b97\u4e14\u907f\u514d\u4e86\u4e0d\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14547", "pdf": "https://arxiv.org/pdf/2507.14547", "abs": "https://arxiv.org/abs/2507.14547", "authors": ["Noman Ahmad", "Ruoyu Su", "Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Architectural Degradation: Definition, Motivations, Measurement and Remediation Approaches", "categories": ["cs.SE"], "comment": null, "summary": "Architectural degradation, also known as erosion, decay, or aging, impacts\nsystem quality, maintainability, and adaptability. Although widely\nacknowledged, current literature shows fragmented definitions, metrics, and\nremediation strategies. Our study aims to unify understanding of architectural\ndegradation by identifying its definitions, causes, metrics, tools, and\nremediation approaches across academic and gray literature. We conducted a\nmultivocal literature review of 108 studies extracting definitions, causes,\nmetrics, measurement approaches, tools, and remediation strategies. We\ndeveloped a taxonomy encompassing architectural, code, and process debt to\nexplore definition evolution, methodological trends, and research gaps.\nArchitectural degradation has shifted from a low-level issue to a\nsocio-technical concern. Definitions now address code violations, design drift,\nand structural decay. Causes fall under architectural (e.g., poor\ndocumentation), code (e.g., hasty fixes), and process debt (e.g., knowledge\nloss). We identified 54 metrics and 31 measurement techniques, focused on\nsmells, cohesion/coupling, and evolution. Yet, most tools detect issues but\nrarely support ongoing or preventive remediation. Degradation is both technical\nand organizational. While detection is well-studied, continuous remediation\nremains lacking. Our study reveals missed integration between metrics, tools,\nand repair logic, urging holistic, proactive strategies for sustainable\narchitecture.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u7edf\u4e00\u4e86\u67b6\u6784\u9000\u5316\u7684\u5b9a\u4e49\u3001\u539f\u56e0\u3001\u6307\u6807\u548c\u4fee\u590d\u7b56\u7565\uff0c\u63ed\u793a\u5176\u4e3a\u6280\u672f\u548c\u793e\u4f1a\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u68c0\u6d4b\u5de5\u5177\u591a\u4f46\u6301\u7eed\u4fee\u590d\u4e0d\u8db3\u7684\u7814\u7a76\u7a7a\u767d\u3002", "motivation": "\u67b6\u6784\u9000\u5316\u5f71\u54cd\u7cfb\u7edf\u8d28\u91cf\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5b9a\u4e49\u548c\u7b56\u7565\u5206\u6563\u3002\u7814\u7a76\u65e8\u5728\u7edf\u4e00\u7406\u89e3\u67b6\u6784\u9000\u5316\uff0c\u586b\u8865\u5b66\u672f\u548c\u5b9e\u8df5\u4e2d\u5b9a\u4e49\u3001\u6307\u6807\u53ca\u4fee\u590d\u7b56\u7565\u7684\u7a7a\u767d\u3002", "method": "\u5bf9108\u9879\u7814\u7a76\u8fdb\u884c\u591a\u6e90\u6587\u732e\u7efc\u8ff0\uff0c\u63d0\u53d6\u5b9a\u4e49\u3001\u539f\u56e0\u3001\u6307\u6807\u3001\u65b9\u6cd5\u3001\u5de5\u5177\u548c\u4fee\u590d\u7b56\u7565\uff0c\u5e76\u6784\u5efa\u5206\u7c7b\u6cd5\u5206\u6790\u6f14\u53d8\u3001\u8d8b\u52bf\u548c\u7f3a\u53e3\u3002", "result": "\u67b6\u6784\u9000\u5316\u88ab\u6269\u5c55\u4e3a\u5305\u542b\u4ee3\u7801\u8fdd\u89c4\u3001\u8bbe\u8ba1\u6f02\u79fb\u548c\u793e\u4f1a\u6280\u672f\u95ee\u9898\u3002\u8bc6\u522b\u4e8654\u79cd\u6307\u6807\u548c31\u79cd\u6d4b\u91cf\u6280\u672f\uff0c\u4f46\u5de5\u5177\u591a\u4e3a\u68c0\u6d4b\u800c\u975e\u6301\u7eed\u4fee\u590d\u3002", "conclusion": "\u67b6\u6784\u9000\u5316\u9700\u5173\u6ce8\u6280\u672f\u548c\u7ec4\u7ec7\u4e24\u65b9\u9762\u3002\u7814\u7a76\u547c\u5401\u6574\u5408\u6307\u6807\u3001\u5de5\u5177\u548c\u4fee\u590d\u903b\u8f91\uff0c\u63a8\u52a8\u53ef\u6301\u7eed\u67b6\u6784\u7684\u4e3b\u52a8\u7b56\u7565\u3002"}}
{"id": "2507.15277", "pdf": "https://arxiv.org/pdf/2507.15277", "abs": "https://arxiv.org/abs/2507.15277", "authors": ["Robert Hochgraf", "Sreepathi Pai"], "title": "A Few Fit Most: Improving Performance Portability of SGEMM on GPUs using Multi-Versioning", "categories": ["cs.PL", "D.3.4"], "comment": "13 pages, 8 figures", "summary": "Hand-optimizing linear algebra kernels for different GPU devices and\napplications is complex and labor-intensive. Instead, many developers use\nautomatic performance tuning (autotuning) to achieve high performance on a\nvariety of devices. However, autotuning \"overfits\", and must be redone if any\npart of the environment changes, such as if the device or input characteristics\nchange.\n  In most non-trivial cases, a single compute kernel cannot maintain\nnear-optimal performance across all environments. Changing the kernel to\nspecialize it to the current execution environment is possible, but on GPUs,\nruntime tuning and compilation can be expensive.\n  In this work, we use multi-versioning -- producing several variants of the\nsame code -- as a way to generate performance portable code. We describe a\nframework called portability tuning that can automatically generate\nmulti-versioned code whose performance is portable, requiring no retuning.\n  We evaluate our framework on a dataset of execution times for GEMM kernels\nfrom the CLBlast linear algebra library. We find our portability tuning\ntechniques outperform CLBlast's default kernels -- often approaching within 10%\nof the theoretical maximum performance -- despite CLBlast using autotuning\ntechniques. Further, we find that our generated programs generalize well to new\nand unseen devices, matching the performance of autotuning without ever\nportability tuning for those devices.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u2018\u591a\u7248\u672c\u5316\u2019\u7684\u6280\u672f\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u591a\u4e2a\u4ee3\u7801\u53d8\u4f53\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u53ef\u79fb\u690d\u4ee3\u7801\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u81ea\u52a8\u8c03\u4f18\u7684\u2018\u8fc7\u62df\u5408\u2019\u95ee\u9898\uff0c\u5e76\u5728\u65b0\u8bbe\u5907\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524dGPU\u8bbe\u5907\u4e0a\u624b\u52a8\u4f18\u5316\u7ebf\u6027\u4ee3\u6570\u5185\u6838\u590d\u6742\u4e14\u8017\u65f6\uff0c\u81ea\u52a8\u8c03\u4f18\u867d\u80fd\u63d0\u9ad8\u6027\u80fd\u4f46\u5bb9\u6613\u2018\u8fc7\u62df\u5408\u2019\uff0c\u4e14\u9700\u8981\u91cd\u65b0\u8c03\u4f18\u4ee5\u9002\u5e94\u73af\u5883\u53d8\u5316\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u7248\u672c\u5316\u6280\u672f\uff0c\u751f\u6210\u591a\u4e2a\u4ee3\u7801\u53d8\u4f53\uff0c\u5e76\u4f7f\u7528\u2018\u53ef\u79fb\u690d\u6027\u8c03\u4f18\u2019\u6846\u67b6\u81ea\u52a8\u9009\u62e9\u6700\u4f73\u7248\u672c\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u53ef\u79fb\u690d\u6027\u3002", "result": "\u5728CLBlast\u5e93\u7684GEMM\u5185\u6838\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6280\u672f\u4f18\u4e8e\u9ed8\u8ba4\u5185\u6838\uff0c\u63a5\u8fd1\u7406\u8bba\u6700\u5927\u6027\u80fd\u768490%\uff0c\u4e14\u5728\u65b0\u8bbe\u5907\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u591a\u7248\u672c\u5316\u548c\u53ef\u79fb\u690d\u6027\u8c03\u4f18\u662f\u5b9e\u73b0\u9ad8\u6027\u80fd\u4ee3\u7801\u53ef\u79fb\u690d\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u8bbe\u5907\u548c\u73af\u5883\u3002"}}
{"id": "2507.14205", "pdf": "https://arxiv.org/pdf/2507.14205", "abs": "https://arxiv.org/abs/2507.14205", "authors": ["Pavel Malinovskiy"], "title": "A Fault-Tolerant Architecture for Urban and Rural Digital Connectivity: Synergizing SDWMN, Direct-to-Mobile Broadcasting, and Hybrid Cloud Streaming", "categories": ["cs.NI"], "comment": null, "summary": "We propose an integrated architecture combining Software-Defined Wireless\nMesh Networks (SDWMN), Direct-to-Mobile (D2M) broadcasting, and Kafka-based\nhybrid cloud streaming to improve wireless network performance in both urban\nand rural settings. The approach addresses urban congestion and rural digital\nexclusion through traffic offloading, enhanced fault tolerance, and equitable\nresource allocation. We model urban congestion $\\rho_u = \\lambda_t / \\mu_c$ and\nrural coverage deficit $\\delta_r = 1 - C_r / C_{req}$, and aim to minimize\nglobal performance loss $GPL = w_1 \\cdot \\rho_u + w_2 \\cdot \\delta_r + w_3\n\\cdot T_{rec}$, where $T_{rec}$ is recovery time. Experiments in Bangkok,\nMumbai, and rural Finland demonstrate latency reduction over 32%, bandwidth\noffloading of 40%, rural coverage gain of 28%, and fairness index rising from\n0.78 to 0.91. The system achieves recovery under 10 s using SDWMN and Kafka. We\nrecommend optimal spectrum allocation $\\alpha_s$, targeted subsidies, and\ndevice mandates to promote adoption. This scalable, fault-tolerant design\nsupports equitable digital transformation and suggests directions for future\nresearch.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408SDWMN\u3001D2M\u5e7f\u64ad\u548cKafka\u6df7\u5408\u4e91\u6d41\u91cf\u7684\u96c6\u6210\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57ce\u4e61\u7f51\u7edc\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u57ce\u5e02\u7f51\u7edc\u62e5\u5835\u548c\u519c\u6751\u6570\u5b57\u9e3f\u6c9f\u95ee\u9898\uff0c\u5b9e\u73b0\u6d41\u91cf\u5378\u8f7d\u3001\u8d44\u6e90\u516c\u5e73\u5206\u914d\u548c\u589e\u5f3a\u5bb9\u9519\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\uff08\u5982\u57ce\u5e02\u62e5\u585e\u548c\u519c\u6751\u8986\u76d6\u8d64\u5b57\uff09\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff08\u5728\u66fc\u8c37\u3001\u5b5f\u4e70\u548c\u82ac\u5170\u519c\u6751\u8fdb\u884c\u6d4b\u8bd5\uff09\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5ef6\u8fdf\u964d\u4f4e32%\uff0c\u5e26\u5bbd\u5378\u8f7d40%\uff0c\u519c\u6751\u8986\u76d6\u63d0\u534728%\uff0c\u6062\u590d\u65f6\u95f4\u4f4e\u4e8e10\u79d2\u3002", "conclusion": "\u5efa\u8bae\u4f18\u5316\u9891\u8c31\u5206\u914d\u548c\u653f\u7b56\u652f\u6301\uff0c\u4ee5\u63a8\u5e7f\u8be5\u67b6\u6784\uff0c\u652f\u6301\u516c\u5e73\u6570\u5b57\u5316\u8f6c\u578b\u3002"}}
{"id": "2507.14432", "pdf": "https://arxiv.org/pdf/2507.14432", "abs": "https://arxiv.org/abs/2507.14432", "authors": ["Han Gong", "Qiyue Li", "Zhi Liu", "Hao Zhou", "Peng Yuan Zhou", "Zhu Li", "Jie Li"], "title": "Adaptive 3D Gaussian Splatting Video Streaming", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the\nquality of volumetric video representation. Meanwhile, in contrast to\nconventional volumetric video, 3DGS video poses significant challenges for\nstreaming due to its substantially larger data volume and the heightened\ncomplexity involved in compression and transmission. To address these issues,\nwe introduce an innovative framework for 3DGS volumetric video streaming.\nSpecifically, we design a 3DGS video construction method based on the Gaussian\ndeformation field. By employing hybrid saliency tiling and differentiated\nquality modeling of 3DGS video, we achieve efficient data compression and\nadaptation to bandwidth fluctuations while ensuring high transmission quality.\nThen we build a complete 3DGS video streaming system and validate the\ntransmission performance. Through experimental evaluation, our method\ndemonstrated superiority over existing approaches in various aspects, including\nvideo quality, compression effectiveness, and transmission rate.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9488\u5bf93D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u89c6\u9891\u6d41\u4f20\u8f93\u7684\u521b\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u65af\u53d8\u5f62\u573a\u3001\u6df7\u5408\u663e\u8457\u6027\u5206\u5757\u548c\u5dee\u5f02\u5316\u8d28\u91cf\u5efa\u6a21\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u538b\u7f29\u548c\u5e26\u5bbd\u9002\u5e94\uff0c\u63d0\u5347\u4e86\u4f20\u8f93\u8d28\u91cf\u548c\u6027\u80fd\u3002", "motivation": "3DGS\u89c6\u9891\u56e0\u5176\u6570\u636e\u91cf\u5927\u4e14\u538b\u7f29\u4f20\u8f93\u590d\u6742\uff0c\u5bf9\u6d41\u4f20\u8f93\u63d0\u51fa\u4e86\u6311\u6218\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u9ad8\u65af\u53d8\u5f62\u573a\u6784\u5efa3DGS\u89c6\u9891\uff0c\u5229\u7528\u6df7\u5408\u663e\u8457\u6027\u5206\u5757\u548c\u5dee\u5f02\u5316\u8d28\u91cf\u5efa\u6a21\u8fdb\u884c\u6570\u636e\u538b\u7f29\u548c\u5e26\u5bbd\u9002\u5e94\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89c6\u9891\u8d28\u91cf\u3001\u538b\u7f29\u6548\u7387\u548c\u4f20\u8f93\u901f\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a3DGS\u89c6\u9891\u6d41\u4f20\u8f93\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f20\u8f93\u6027\u80fd\u3002"}}
{"id": "2507.15117", "pdf": "https://arxiv.org/pdf/2507.15117", "abs": "https://arxiv.org/abs/2507.15117", "authors": ["Alfredo Burrieza", "Fernando Soler-Toscano", "Antonio Yuste-Ginel"], "title": "A meta-modal logic for bisimulations", "categories": ["cs.LO", "math.LO", "03B45", "F.4.0"], "comment": "24 pages", "summary": "We propose a modal study of the notion of bisimulation. Our contribution is\ntwofold. First, we extend the basic modal language with a new modality [b],\nwhose intended meaning is universal quantification over all states that are\nbisimilar to the current one. We show that bisimulations are definable in this\nobject language. Second, we provide a sound and complete axiomatisation of the\nclass of all pairs of Kripke models linked by bisimulations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u5076\u6a21\u62df\u7684\u6a21\u6001\u7814\u7a76\uff0c\u901a\u8fc7\u5728\u57fa\u672c\u6a21\u6001\u8bed\u8a00\u4e2d\u5f15\u5165\u65b0\u6a21\u6001[b]\uff0c\u5b9e\u73b0\u5bf9\u5176\u7684\u91cf\u5316\u5b9a\u4e49\uff0c\u5e76\u7ed9\u51fa\u4e86\u5b8c\u5168\u516c\u7406\u5316\u7cfb\u7edf\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6a21\u6001\u8bed\u8a00\u4e2d\u5b9a\u4e49\u548c\u91cf\u5316\u5076\u6a21\u62df\u5173\u7cfb\uff0c\u4ee5\u589e\u5f3a\u5bf9\u5076\u6a21\u62df\u7684\u7406\u8bba\u7406\u89e3\u3002", "method": "\u6269\u5c55\u57fa\u672c\u6a21\u6001\u8bed\u8a00\uff0c\u5f15\u5165\u65b0\u6a21\u6001[b]\uff0c\u5b9a\u4e49\u5076\u6a21\u62df\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u5b8c\u5168\u516c\u7406\u5316\u7cfb\u7edf\u3002", "result": "\u6210\u529f\u5728\u6a21\u6001\u8bed\u8a00\u4e2d\u5b9a\u4e49\u4e86\u5076\u6a21\u62df\u5173\u7cfb\uff0c\u5e76\u9a8c\u8bc1\u4e86\u516c\u7406\u5316\u7cfb\u7edf\u7684\u5b8c\u5907\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u901a\u8fc7\u65b0\u6a21\u6001\u8bed\u8a00\u548c\u516c\u7406\u5316\u7cfb\u7edf\uff0c\u4e3a\u5076\u6a21\u62df\u7684\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u6846\u67b6\u3002"}}
{"id": "2507.14333", "pdf": "https://arxiv.org/pdf/2507.14333", "abs": "https://arxiv.org/abs/2507.14333", "authors": ["Anannya Mathur"], "title": "Inverse-Designed Dot Product Engine", "categories": ["physics.optics", "cs.ET", "J.2; I.2.8; G.1.6"], "comment": "48 pages, 18 figures", "summary": "The work presents an inverse-designed optical cavity that can direct light\nfrom two sources such that if the sources were to represent any number in the\nrange [-1,1] with magnitude encoded through the power emitted by the source and\nsign by switching the direction of source current, the photocurrent generated\nat the two output ports is proportional to the product of the two numbers. Let\nus say that the two sources encode x and y, which are two numbers $\\in$ [-1,1].\nMultiplication is reduced to the form $(x+y)^2 - (x-y)^2 = 4xy \\propto xy$. The\naddition and subtraction operations of the numbers are supported by\nconstructive and destructive interference, respectively. The work shows that\nreplacing the DDOT dot product engine of the Lightening Transformer with the\noptical cavity proposed to calculate the dot product can lead to a reduction in\nthe area occupied by the photonic core by 88 \\%, can reduce the power\nconsumption by lasers by around 23.43 \\%, and bring down energy consumption\nwhile training DeiT models by 0.88 \\%. The cavities can generate photocurrents\nof the form $1.057 xy + 0.249$ with $R^2=0.88,$ thus showing a relationship of\ndirect proportionality between the target product $xy$ and the output of the\ncavity in response to stimuli encoding $x$ and $y$.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9006\u8bbe\u8ba1\u5149\u5b66\u8154\uff0c\u901a\u8fc7\u5e72\u6d89\u5b9e\u73b0\u4e24\u5149\u6e90\u8f93\u5165\u7684\u6570\u5b57\u4e58\u6cd5\u8fd0\u7b97\uff0c\u7528\u4e8e\u6539\u8fdbLightening Transformer\u7684\u70b9\u79ef\u8ba1\u7b97\uff0c\u663e\u8457\u964d\u4f4e\u529f\u8017\u548c\u9762\u79ef\u3002", "motivation": "\u901a\u8fc7\u5149\u5b66\u65b9\u6cd5\u5b9e\u73b0\u6570\u5b57\u8fd0\u7b97\uff0c\u51cf\u5c11\u4f20\u7edf\u7535\u5b50\u8ba1\u7b97\u4e2d\u7684\u529f\u8017\u548c\u9762\u79ef\u95ee\u9898\u3002", "method": "\u5229\u7528\u9006\u8bbe\u8ba1\u5149\u5b66\u8154\uff0c\u901a\u8fc7\u5e72\u6d89\u5b9e\u73b0(x+y)^2 - (x-y)^2 = 4xy\u7684\u8fd0\u7b97\u903b\u8f91\u3002", "result": "\u5149\u8154\u8f93\u51fa\u4e0e\u76ee\u6807\u4e58\u79efxy\u76f4\u63a5\u6210\u6bd4\u4f8b\uff0c\u964d\u4f4e\u5149\u7535\u6838\u5fc3\u9762\u79ef88%\uff0c\u6fc0\u5149\u529f\u801723.43%\uff0c\u8bad\u7ec3DeiT\u6a21\u578b\u80fd\u80170.88%\u3002", "conclusion": "\u5149\u5b66\u8154\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6570\u5b57\u4e58\u6cd5\u5b9e\u73b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.15300", "pdf": "https://arxiv.org/pdf/2507.15300", "abs": "https://arxiv.org/abs/2507.15300", "authors": ["Minnan Pei", "Gang Li", "Junwen Si", "Zeyu Zhu", "Zitao Mo", "Peisong Wang", "Zhuoran Song", "Xiaoyao Liang", "Jian Cheng"], "title": "GCC: A 3DGS Inference Architecture with Gaussian-Wise and Cross-Stage Conditional Processing", "categories": ["cs.AR"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has emerged as a leading neural rendering\ntechnique for high-fidelity view synthesis, prompting the development of\ndedicated 3DGS accelerators for mobile applications. Through in-depth analysis,\nwe identify two major limitations in the conventional decoupled\npreprocessing-rendering dataflow adopted by existing accelerators: 1) a\nsignificant portion of preprocessed Gaussians are not used in rendering, and 2)\nthe same Gaussian gets repeatedly loaded across different tile renderings,\nresulting in substantial computational and data movement overhead. To address\nthese issues, we propose GCC, a novel accelerator designed for fast and\nenergy-efficient 3DGS inference. At the dataflow level, GCC introduces: 1)\ncross-stage conditional processing, which interleaves preprocessing and\nrendering to dynamically skip unnecessary Gaussian preprocessing; and 2)\nGaussian-wise rendering, ensuring that all rendering operations for a given\nGaussian are completed before moving to the next, thereby eliminating\nduplicated Gaussian loading. We also propose an alpha-based boundary\nidentification method to derive compact and accurate Gaussian regions, thereby\nreducing rendering costs. We implement our GCC accelerator in 28nm technology.\nExtensive experiments demonstrate that GCC significantly outperforms the\nstate-of-the-art 3DGS inference accelerator, GSCore, in both performance and\nenergy efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b3D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u52a0\u901f\u5668GCC\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u52a0\u901f\u5668\u4e2d\u9884\u5904\u7406\u548c\u6e32\u67d3\u6570\u636e\u6d41\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u901a\u8fc7\u8de8\u9636\u6bb5\u6761\u4ef6\u5904\u7406\u548c\u9ad8\u65af\u9010\u6e32\u67d3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u67093DGS\u52a0\u901f\u5668\u91c7\u7528\u89e3\u8026\u7684\u9884\u5904\u7406-\u6e32\u67d3\u6570\u636e\u6d41\uff0c\u5bfc\u81f4\u5927\u91cf\u9884\u5904\u7406\u7684Gaussians\u672a\u88ab\u4f7f\u7528\uff0c\u4e14\u540c\u4e00Gaussian\u5728\u4e0d\u540c\u533a\u5757\u6e32\u67d3\u4e2d\u91cd\u590d\u52a0\u8f7d\uff0c\u4ea7\u751f\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u6570\u636e\u79fb\u52a8\u5f00\u9500\u3002", "method": "\u63d0\u51faGCC\u52a0\u901f\u5668\uff0c\u5f15\u5165\u8de8\u9636\u6bb5\u6761\u4ef6\u5904\u7406\u52a8\u6001\u8df3\u8fc7\u4e0d\u5fc5\u8981\u7684\u9884\u5904\u7406\uff0c\u4ee5\u53ca\u9ad8\u65af\u9010\u6e32\u67d3\u907f\u514d\u91cd\u590d\u52a0\u8f7d\uff1b\u8fd8\u63d0\u51fa\u57fa\u4e8ealpha\u7684\u8fb9\u754c\u8bc6\u522b\u65b9\u6cd5\u4ee5\u51cf\u5c0f\u6e32\u67d3\u6210\u672c\u3002", "result": "GCC\u572828nm\u5de5\u827a\u4e0b\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u6027\u80fd\u548c\u80fd\u6548\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f733DGS\u52a0\u901f\u5668GSCore\u3002", "conclusion": "GCC\u901a\u8fc7\u4f18\u5316\u6570\u636e\u6d41\u548c\u51cf\u5c11\u5197\u4f59\u64cd\u4f5c\uff0c\u4e3a3DGS\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u8282\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14723", "pdf": "https://arxiv.org/pdf/2507.14723", "abs": "https://arxiv.org/abs/2507.14723", "authors": ["Brati Mondal", "Pritam Goswami", "Buddhadeb Sau"], "title": "Simulating Chirality: Solving Distance-$k$-Dispersion on an 1-Interval Connected Ring", "categories": ["cs.DC"], "comment": null, "summary": "We study the Distance-$k$-Dispersion (D-$k$-D) problem for synchronous mobile\nagents in a 1-interval-connected ring network having $n$ nodes and with $l$\nagents where $3 \\le l \\le \\lfloor \\frac{n}{k}\\rfloor$, without the assumption\nof chirality (a common sense of direction for the agents). This generalizes the\nclassical dispersion problem by requiring that agents maintain a minimum\ndistance of $k$ hops from each other, with the special case $k=1$ corresponding\nto the standard dispersion.\n  The contribution in this work is threefold. Our first contribution is a novel\nmethod that enables agents to simulate chirality using only local information,\nvision and bounded memory. This technique demonstrates that chirality is not a\nfundamental requirement for coordination in this model.\n  Building on this, our second contribution partially resolves an open question\nposed by Agarwalla et al. (ICDCN, 2018), who considered the same model (1-\ninterval connected ring, synchronous agents, no chirality). We prove that\nD-$k$-D, and thus dispersion is solvable from any arbitrary configuration under\nthese assumptions (excluding vertex permutation dynamism)for any size of the\nring network which was earlier limited to only odd sized ring or to a ring of\nsize four.\n  Finally, we present an algorithm for D-$k$-D in this setting that works in\n$O(ln)$ rounds, completing the constructive side of our result.\n  Altogether, our findings significantly extend the theoretical understanding\nof mobile agent coordination in dynamic networks and clarify the role of\nchirality in distributed computation.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u65e0\u65b9\u5411\u5171\u8bc6\u76841-\u533a\u95f4\u8fde\u901a\u73af\u5f62\u7f51\u7edc\u4e2d\uff0c\u5982\u4f55\u89e3\u51b3\u8ddd\u79bb-$k$-\u5206\u6563\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5c40\u90e8\u4fe1\u606f\u6a21\u62df\u65b9\u5411\u5171\u8bc6\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u5728\u4efb\u4f55\u89c4\u6a21\u7684\u7f51\u7edc\u4e2d\u5747\u53ef\u89e3\u3002", "motivation": "\u63a2\u8ba8\u5728\u7f3a\u4e4f\u65b9\u5411\u5171\u8bc6\u7684\u52a8\u6001\u7f51\u7edc\u4e2d\uff0c\u79fb\u52a8\u4ee3\u7406\u5982\u4f55\u5b9e\u73b0\u5206\u6563\u4e0e\u534f\u8c03\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u5bf9\u7f51\u7edc\u89c4\u6a21\u548c\u65b9\u5411\u7684\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5c40\u90e8\u4fe1\u606f\u548c\u6709\u9650\u5185\u5b58\u6a21\u62df\u65b9\u5411\u5171\u8bc6\u7684\u6280\u672f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a$O(ln)$\u8f6e\u6b21\u7684\u7b97\u6cd5\u6765\u89e3\u51b3\u8ddd\u79bb-$k$-\u5206\u6563\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u8ddd\u79bb-$k$-\u5206\u6563\u95ee\u9898\u5728\u4efb\u4f55\u89c4\u6a21\u7684\u73af\u5f62\u7f51\u7edc\u4e2d\u5747\u53ef\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u7b97\u6cd5\u3002", "conclusion": "\u7814\u7a76\u6269\u5c55\u4e86\u52a8\u6001\u7f51\u7edc\u4e2d\u79fb\u52a8\u4ee3\u7406\u534f\u8c03\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6f84\u6e05\u4e86\u65b9\u5411\u5171\u8bc6\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.14702", "pdf": "https://arxiv.org/pdf/2507.14702", "abs": "https://arxiv.org/abs/2507.14702", "authors": ["Partha Sarker", "Dipto Dey", "Marium-E-Jannat"], "title": "A Notification Based Nudge for Handling Excessive Smartphone Use", "categories": ["cs.HC", "F.2.2, I.2.7"], "comment": "6 pages, 8 figures", "summary": "Excessive use of smartphones is a worldwide known issue. In this study, we\nproposed a notification-based intervention approach to reduce smartphone\noveruse without making the user feel any annoyance or irritation. Most of the\nwork in this field tried to reduce smartphone overuse by making smartphone use\nmore difficult for the user. In our user study (n = 109), we found that 19.3%\nof the participants are unwilling to use any usage-limiting application because\na) they do not want their smartphone activities to get restricted or b) those\napplications are annoying. Following that, we devised a hypothesis to minimize\nsmartphone usage among undergraduates. Finally, we designed a prototype for\nAndroid, \"App Usage Monitor,\" and conducted a 3-week experiment through which\nwe found proof of concept for our hypothesis. In our prototype, we combined\ntechniques such as nudge and visualization to increase self-awareness among the\nuser by leveraging notifications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u901a\u77e5\u7684\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u5f3a\u7528\u6237\u81ea\u6211\u610f\u8bc6\u6765\u51cf\u5c11\u667a\u80fd\u624b\u673a\u8fc7\u5ea6\u4f7f\u7528\uff0c\u907f\u514d\u7528\u6237\u611f\u5230\u538c\u70e6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u9650\u5236\u7528\u6237\u4f7f\u7528\u667a\u80fd\u624b\u673a\u6765\u51cf\u5c11\u8fc7\u5ea6\u4f7f\u7528\uff0c\u4f46\u7528\u6237\u5bf9\u6b64\u611f\u5230\u538c\u70e6\u6216\u4e0d\u613f\u88ab\u9650\u5236\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2aAndroid\u539f\u578b\u201cApp Usage Monitor\u201d\uff0c\u7ed3\u5408\u4e86\u8f7b\u63a8\u548c\u53ef\u89c6\u5316\u6280\u672f\uff0c\u901a\u8fc7\u901a\u77e5\u589e\u5f3a\u7528\u6237\u81ea\u6211\u610f\u8bc6\u3002", "result": "\u901a\u8fc73\u5468\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5047\u8bbe\uff0c\u8bc1\u660e\u4e86\u6982\u5ff5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u901a\u77e5\u5e72\u9884\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u667a\u80fd\u624b\u673a\u8fc7\u5ea6\u4f7f\u7528\uff0c\u4e14\u4e0d\u5f15\u8d77\u7528\u6237\u538c\u70e6\u3002"}}
{"id": "2507.15454", "pdf": "https://arxiv.org/pdf/2507.15454", "abs": "https://arxiv.org/abs/2507.15454", "authors": ["Ruijie Zhu", "Mulin Yu", "Linning Xu", "Lihan Jiang", "Yixuan Li", "Tianzhu Zhang", "Jiangmiao Pang", "Bo Dai"], "title": "ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.HC"], "comment": "Accepted by ICCV 2025", "summary": "3D Gaussian Splatting is renowned for its high-fidelity reconstructions and\nreal-time novel view synthesis, yet its lack of semantic understanding limits\nobject-level perception. In this work, we propose ObjectGS, an object-aware\nframework that unifies 3D scene reconstruction with semantic understanding.\nInstead of treating the scene as a unified whole, ObjectGS models individual\nobjects as local anchors that generate neural Gaussians and share object IDs,\nenabling precise object-level reconstruction. During training, we dynamically\ngrow or prune these anchors and optimize their features, while a one-hot ID\nencoding with a classification loss enforces clear semantic constraints. We\nshow through extensive experiments that ObjectGS not only outperforms\nstate-of-the-art methods on open-vocabulary and panoptic segmentation tasks,\nbut also integrates seamlessly with applications like mesh extraction and scene\nediting. Project page: https://ruijiezhu94.github.io/ObjectGS_page", "AI": {"tldr": "ObjectGS\u662f\u4e00\u4e2a\u7ed3\u54083D\u573a\u666f\u91cd\u5efa\u4e0e\u8bed\u4e49\u7406\u89e3\u7684\u5bf9\u8c61\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u548c\u4f18\u5316\u5c40\u90e8\u951a\u70b9\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5bf9\u8c61\u7ea7\u91cd\u5efa\uff0c\u5e76\u5728\u5f00\u653e\u8bcd\u6c47\u548c\u5168\u666f\u5206\u5272\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "3D\u9ad8\u65af\u55b7\u6d12\u6280\u672f\u867d\u7136\u80fd\u5b9e\u73b0\u9ad8\u4fdd\u771f\u91cd\u5efa\u548c\u5b9e\u65f6\u65b0\u89c6\u89d2\u5408\u6210\uff0c\u4f46\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\uff0c\u9650\u5236\u4e86\u5bf9\u8c61\u7ea7\u611f\u77e5\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51faObjectGS\uff0c\u65e8\u5728\u901a\u8fc7\u5bf9\u8c61\u611f\u77e5\u6846\u67b6\u7edf\u4e003D\u91cd\u5efa\u4e0e\u8bed\u4e49\u7406\u89e3\u3002", "method": "ObjectGS\u5c06\u573a\u666f\u4e2d\u7684\u5bf9\u8c61\u5efa\u6a21\u4e3a\u5c40\u90e8\u951a\u70b9\uff0c\u52a8\u6001\u751f\u6210\u548c\u4fee\u526a\u8fd9\u4e9b\u951a\u70b9\u5e76\u4f18\u5316\u5176\u7279\u5f81\uff0c\u540c\u65f6\u901a\u8fc7\u72ec\u70ed\u7f16\u7801ID\u548c\u5206\u7c7b\u635f\u5931\u5f3a\u5236\u8bed\u4e49\u7ea6\u675f\u3002", "result": "\u5728\u5f00\u653e\u8bcd\u6c47\u548c\u5168\u666f\u5206\u5272\u4efb\u52a1\u4e2d\uff0cObjectGS\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u80fd\u65e0\u7f1d\u96c6\u6210\u5230\u7f51\u683c\u63d0\u53d6\u548c\u573a\u666f\u7f16\u8f91\u7b49\u5e94\u7528\u4e2d\u3002", "conclusion": "ObjectGS\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u7406\u89e3\u4e0e3D\u91cd\u5efa\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u8c61\u7ea7\u611f\u77e5\u80fd\u529b\uff0c\u5e76\u5728\u591a\u9879\u4efb\u52a1\u548c\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.14554", "pdf": "https://arxiv.org/pdf/2507.14554", "abs": "https://arxiv.org/abs/2507.14554", "authors": ["Ruoyu Su", "Noman ahmad", "Matteo Esposito", "Andrea Janes", "Davide Taibi", "Valentina Lenarduzzi"], "title": "Emerging Trends in Software Architecture from the Practitioners Perspective: A Five Year Review", "categories": ["cs.SE"], "comment": null, "summary": "Software architecture plays a central role in the design, development, and\nmaintenance of software systems. With the rise of cloud computing,\nmicroservices, and containers, architectural practices have diversified.\nUnderstanding these shifts is vital. This study analyzes software architecture\ntrends across eight leading industry conferences over five years. We\ninvestigate the evolution of software architecture by analyzing talks from top\npractitioner conferences, focusing on the motivations and contexts driving\ntechnology adoption. We analyzed 5,677 talks from eight major industry\nconferences, using large language models and expert validation to extract\ntechnologies, their purposes, and usage contexts. We also explored how\ntechnologies interrelate and fit within DevOps and deployment pipelines. Among\n450 technologies, Kubernetes, Cloud Native, Serverless, and Containers dominate\nby frequency and centrality. Practitioners present technology mainly related to\ndeployment, communication, AI, and observability. We identify five technology\ncommunities covering automation, coordination, cloud AI, monitoring, and\ncloud-edge. Most technologies span multiple DevOps stages and support hybrid\ndeployment. Our study reveals that a few core technologies, like Kubernetes and\nServerless, dominate the contemporary software architecture practice. These are\nmainly applied in later DevOps stages, with limited focus on early phases like\nplanning and coding. We also show how practitioners frame technologies by\npurpose and context, reflecting evolving industry priorities. Finally, we\nobserve how only research can provide a more holistic lens on architectural\ndesign, quality, and evolution.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u4e94\u5e74\u5185\u516b\u5927\u884c\u4e1a\u4f1a\u8bae\u4e2d\u7684\u8f6f\u4ef6\u67b6\u6784\u8d8b\u52bf\uff0c\u5206\u6790\u4e865677\u4e2a\u6f14\u8bb2\uff0c\u53d1\u73b0Kubernetes\u3001\u4e91\u539f\u751f\u7b49\u6280\u672f\u4e3b\u5bfc\u4e86\u5f53\u524d\u5b9e\u8df5\u3002", "motivation": "\u4e86\u89e3\u4e91\u8ba1\u7b97\u3001\u5fae\u670d\u52a1\u548c\u5bb9\u5668\u7b49\u6280\u672f\u5174\u8d77\u5bf9\u8f6f\u4ef6\u67b6\u6784\u5b9e\u8df5\u7684\u5f71\u54cd\u3002", "method": "\u4ece\u516b\u5927\u4f1a\u8bae\u4e2d\u5206\u67905677\u4e2a\u6f14\u8bb2\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u5bb6\u9a8c\u8bc1\u63d0\u53d6\u6280\u672f\u53ca\u5176\u7528\u9014\u3002", "result": "\u53d1\u73b0Kubernetes\u7b49\u6280\u672f\u5728\u90e8\u7f72\u3001\u901a\u4fe1\u7b49\u9886\u57df\u5360\u4e3b\u5bfc\uff0c\u5e76\u8bc6\u522b\u4e86\u4e94\u4e2a\u6280\u672f\u793e\u533a\u3002", "conclusion": "\u6838\u5fc3\u6280\u672f\u96c6\u4e2d\u5728DevOps\u540e\u671f\u9636\u6bb5\uff0c\u7814\u7a76\u53ef\u4e3a\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.15530", "pdf": "https://arxiv.org/pdf/2507.15530", "abs": "https://arxiv.org/abs/2507.15530", "authors": ["Shing Hin Ho", "Nicolas Wu", "Azalea Raad"], "title": "Bayesian Separation Logic", "categories": ["cs.PL", "cs.LO", "F.3.1; F.3.2"], "comment": null, "summary": "Bayesian probabilistic programming languages (BPPLs) let users denote\nstatistical models as code while the interpreter infers the posterior\ndistribution. The semantics of BPPLs are usually mathematically complex and\nunable to reason about desirable properties such as expected values and\nindependence of random variables. To reason about these properties in a\nnon-Bayesian setting, probabilistic separation logics such as PSL and Lilac\ninterpret separating conjunction as probabilistic independence of random\nvariables. However, no existing separation logic can handle Bayesian updating,\nwhich is the key distinguishing feature of BPPLs.\n  To close this gap, we introduce Bayesian separation logic (BaSL), a\nprobabilistic separation logic that gives semantics to BPPL. We prove an\ninternal version of Bayes' theorem using a result in measure theory known as\nthe Rokhlin-Simmons disintegration theorem. Consequently, BaSL can model\nprobabilistic programming concepts such as Bayesian updating, unnormalised\ndistribution, conditional distribution, soft constraint, conjugate prior and\nimproper prior while maintaining modularity via the frame rule. The model of\nBaSL is based on a novel instantiation of Kripke resource monoid via\n$\\sigma$-finite measure spaces over the Hilbert cube, and the semantics of\nHoare triple is compatible with an existing denotational semantics of BPPL\nbased on the category of $s$-finite kernels. Using BaSL, we then prove\nproperties of statistical models such as the expected value of Bayesian coin\nflip, correlation of random variables in the collider Bayesian network, and the\nposterior distributions of the burglar alarm model, a parameter estimation\nalgorithm, and the Gaussian mixture model.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Bayesian\u5206\u79bb\u903b\u8f91\uff08BaSL\uff09\uff0c\u4e00\u79cd\u80fd\u591f\u5904\u7406\u8d1d\u53f6\u65af\u66f4\u65b0\u7684\u6982\u7387\u5206\u79bb\u903b\u8f91\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5206\u79bb\u903b\u8f91\u65e0\u6cd5\u5904\u7406BPPL\u5173\u952e\u7279\u6027\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u6982\u7387\u5206\u79bb\u903b\u8f91\u65e0\u6cd5\u5904\u7406\u8d1d\u53f6\u65af\u7f16\u7a0b\u8bed\u8a00\uff08BPPL\uff09\u4e2d\u7684\u8d1d\u53f6\u65af\u66f4\u65b0\u7279\u6027\uff0c\u9650\u5236\u4e86\u5bf9\u5176\u6027\u8d28\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faBaSL\uff0c\u57fa\u4e8eRokhlin-Simmons\u5b9a\u7406\u8bc1\u660e\u8d1d\u53f6\u65af\u5b9a\u7406\u7684\u5185\u90e8\u7248\u672c\uff0c\u5e76\u5229\u7528\u03c3-\u6709\u9650\u6d4b\u5ea6\u7a7a\u95f4\u6784\u5efaKripke\u8d44\u6e90\u5e7a\u534a\u7fa4\u6a21\u578b\u3002", "result": "BaSL\u6210\u529f\u5efa\u6a21\u4e86\u8d1d\u53f6\u65af\u7f16\u7a0b\u7684\u5173\u952e\u6982\u5ff5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u591a\u4e2a\u7edf\u8ba1\u6a21\u578b\u7684\u5c5e\u6027\uff0c\u5982\u671f\u671b\u503c\u3001\u76f8\u5173\u6027\u548c\u540e\u9a8c\u5206\u5e03\u3002", "conclusion": "BaSL\u4e3aBPPL\u63d0\u4f9b\u4e86\u65b0\u7684\u8bed\u4e49\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u6982\u7387\u5206\u79bb\u903b\u8f91\u7684\u5e94\u7528\u8303\u56f4\uff0c\u5e76\u652f\u6301\u5bf9\u590d\u6742\u7edf\u8ba1\u6a21\u578b\u7684\u63a8\u7406\u3002"}}
{"id": "2507.14454", "pdf": "https://arxiv.org/pdf/2507.14454", "abs": "https://arxiv.org/abs/2507.14454", "authors": ["Han Gong", "Qiyue Li", "Jie Li", "Zhi Liu"], "title": "Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation", "categories": ["cs.CV", "cs.MM", "eess.IV"], "comment": null, "summary": "3D Gaussian splatting video (3DGS) streaming has recently emerged as a\nresearch hotspot in both academia and industry, owing to its impressive ability\nto deliver immersive 3D video experiences. However, research in this area is\nstill in its early stages, and several fundamental challenges, such as tiling,\nquality assessment, and bitrate adaptation, require further investigation. In\nthis paper, we tackle these challenges by proposing a comprehensive set of\nsolutions. Specifically, we propose an adaptive 3DGS tiling technique guided by\nsaliency analysis, which integrates both spatial and temporal features. Each\ntile is encoded into versions possessing dedicated deformation fields and\nmultiple quality levels for adaptive selection. We also introduce a novel\nquality assessment framework for 3DGS video that jointly evaluates\nspatial-domain degradation in 3DGS representations during streaming and the\nquality of the resulting 2D rendered images. Additionally, we develop a\nmeta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS\nvideo streaming, achieving optimal performance across varying network\nconditions. Extensive experiments demonstrate that our proposed approaches\nsignificantly outperform state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf93D\u9ad8\u65af\u70b9\u4e91\u89c6\u9891\u6d41\u5a92\u4f53\u7684\u4e00\u7cfb\u5217\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u81ea\u9002\u5e94\u5206\u5757\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u6bd4\u7279\u7387\u8c03\u6574\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "3D\u9ad8\u65af\u70b9\u4e91\u89c6\u9891\u6d41\u5a92\u4f53\u5728\u6c89\u6d78\u5f0f\u4f53\u9a8c\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5206\u5757\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u6bd4\u7279\u7387\u8c03\u6574\u7b49\u57fa\u7840\u95ee\u9898\u4ecd\u9700\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u663e\u8457\u6027\u5206\u6790\u7684\u81ea\u9002\u5e94\u5206\u5757\u6280\u672f\uff0c\u7ed3\u5408\u7a7a\u95f4\u548c\u65f6\u95f4\u7279\u5f81\uff1b\u5f00\u53d1\u4e86\u8bc4\u4f303DGS\u8868\u793a\u548c2D\u6e32\u67d3\u8d28\u91cf\u7684\u6846\u67b6\uff1b\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u6bd4\u7279\u7387\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a3D\u9ad8\u65af\u70b9\u4e91\u89c6\u9891\u6d41\u5a92\u4f53\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5176\u6838\u5fc3\u6311\u6218\u3002"}}
{"id": "2507.15147", "pdf": "https://arxiv.org/pdf/2507.15147", "abs": "https://arxiv.org/abs/2507.15147", "authors": ["Yiqi Zhao", "Xinyi Yu", "Bardh Hoxha", "Georgios Fainekos", "Jyotirmoy V. Deshmukh", "Lars Lindemann"], "title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies", "categories": ["cs.LO", "cs.FL", "cs.MA"], "comment": null, "summary": "Multi-agent systems (MASs) consisting of a number of autonomous agents that\ncommunicate, coordinate, and jointly sense the environment to achieve complex\nmissions can be found in a variety of applications such as robotics, smart\ncities, and internet-of-things applications. Modeling and monitoring MAS\nrequirements to guarantee overall mission objectives, safety, and reliability\nis an important problem. Such requirements implicitly require reasoning about\ndiverse sensing and communication modalities between agents, analysis of the\ndependencies between agent tasks, and the spatial or virtual distance between\nagents. To capture such rich MAS requirements, we model agent interactions via\nmultiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic\nwith Graph Operators (STL-GO). The key innovation in STL-GO are graph operators\nthat enable us to reason about the number of agents along either the incoming\nor outgoing edges of the underlying interaction graph that satisfy a given\nproperty of interest; for example, the requirement that an agent should sense\nat least two neighboring agents whose task graphs indicate the ability to\ncollaborate. We then propose novel distributed monitoring conditions for\nindividual agents that use only local information to determine whether or not\nan STL-GO specification is satisfied. We compare the expressivity of STL-GO\nagainst existing spatio-temporal logic formalisms, and demonstrate the utility\nof STL-GO and our distributed monitors in a bike-sharing and a multi-drone case\nstudy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u903b\u8f91STL-GO\uff0c\u7528\u4e8e\u5efa\u6a21\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u7684\u590d\u6742\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0f\u76d1\u63a7\u6761\u4ef6\u5b9e\u73b0\u5c40\u90e8\u4fe1\u606f\u9a8c\u8bc1\u3002\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u8868\u8fbe\u80fd\u529b\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u7684\u590d\u6742\u4efb\u52a1\u9700\u6c42\u9700\u8981\u5bf9\u611f\u77e5\u3001\u901a\u4fe1\u548c\u4efb\u52a1\u4f9d\u8d56\u8fdb\u884c\u5efa\u6a21\u548c\u76d1\u63a7\uff0c\u4ee5\u786e\u4fdd\u76ee\u6807\u3001\u5b89\u5168\u548c\u53ef\u9760\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5168\u9762\u6355\u6349\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u591a\u5411\u6709\u5411\u56fe\u5efa\u6a21\u667a\u80fd\u4f53\u4ea4\u4e92\uff0c\u5e76\u5f15\u5165STL-GO\u903b\u8f91\uff0c\u5b9a\u4e49\u56fe\u64cd\u4f5c\u7b26\u4ee5\u63a8\u7406\u90bb\u57df\u667a\u80fd\u4f53\u5c5e\u6027\u3002\u63d0\u51fa\u5206\u5e03\u5f0f\u76d1\u63a7\u6761\u4ef6\uff0c\u4ec5\u7528\u5c40\u90e8\u4fe1\u606f\u9a8c\u8bc1STL-GG\u89c4\u8303\u3002", "result": "STL-GO\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u4f18\u4e8e\u73b0\u6709\u65f6\u7a7a\u903b\u8f91\u5f62\u5f0f\uff0c\u5e76\u5728\u5171\u4eab\u5355\u8f66\u548c\u591a\u65e0\u4eba\u673a\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "STL-GO\u4e3aMAS\u9700\u6c42\u5efa\u6a21\u548c\u76d1\u63a7\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u8868\u8fbe\u80fd\u529b\u548c\u5206\u5e03\u5f0f\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4efb\u52a1\u573a\u666f\u3002"}}
{"id": "2507.14301", "pdf": "https://arxiv.org/pdf/2507.14301", "abs": "https://arxiv.org/abs/2507.14301", "authors": ["Yuxin Liu", "Yuezhang Peng", "Hefeng Zhou", "Hongze Liu", "Xinyu Lu", "Jiong Lou", "Chentao Wu", "Wei Zhao", "Jie Li"], "title": "LOVO: Efficient Complex Object Query in Large-Scale Video Datasets", "categories": ["cs.IR", "cs.CV", "cs.DB"], "comment": "@inproceedings{liu2025lovo,title={LOVO: Efficient Complex Object\n  Query in Large-Scale Video Datasets},author={Liu, Yuxin and Peng, Yuezhang\n  and Zhou, Hefeng and Liu, Hongze and Lu, Xinyu and Lou, Jiong and Wu, Chentao\n  and Zhao, Wei and Li, Jie},booktitle={2025 IEEE 41st International Conference\n  on Data Engineering (ICDE)},pages={1938--1951},year={2025},organization={IEEE\n  Computer Society}}", "summary": "The widespread deployment of cameras has led to an exponential increase in\nvideo data, creating vast opportunities for applications such as traffic\nmanagement and crime surveillance. However, querying specific objects from\nlarge-scale video datasets presents challenges, including (1) processing\nmassive and continuously growing data volumes, (2) supporting complex query\nrequirements, and (3) ensuring low-latency execution. Existing video analysis\nmethods struggle with either limited adaptability to unseen object classes or\nsuffer from high query latency. In this paper, we present LOVO, a novel system\ndesigned to efficiently handle comp$\\underline{L}$ex $\\underline{O}$bject\nqueries in large-scale $\\underline{V}$ide$\\underline{O}$ datasets. Agnostic to\nuser queries, LOVO performs one-time feature extraction using pre-trained\nvisual encoders, generating compact visual embeddings for key frames to build\nan efficient index. These visual embeddings, along with associated bounding\nboxes, are organized in an inverted multi-index structure within a vector\ndatabase, which supports queries for any objects. During the query phase, LOVO\ntransforms object queries to query embeddings and conducts fast approximate\nnearest-neighbor searches on the visual embeddings. Finally, a cross-modal\nrerank is performed to refine the results by fusing visual features with\ndetailed textual features. Evaluation on real-world video datasets demonstrates\nthat LOVO outperforms existing methods in handling complex queries, with\nnear-optimal query accuracy and up to 85x lower search latency, while\nsignificantly reducing index construction costs. This system redefines the\nstate-of-the-art object query approaches in video analysis, setting a new\nbenchmark for complex object queries with a novel, scalable, and efficient\napproach that excels in dynamic environments.", "AI": {"tldr": "LOVO\u662f\u4e00\u4e2a\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u89c6\u9891\u6570\u636e\u4e2d\u590d\u6742\u5bf9\u8c61\u67e5\u8be2\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u751f\u6210\u7d27\u51d1\u7684\u89c6\u89c9\u5d4c\u5165\uff0c\u5e76\u7ed3\u5408\u591a\u7d22\u5f15\u7ed3\u6784\u548c\u8de8\u6a21\u6001\u91cd\u6392\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u67e5\u8be2\u51c6\u786e\u6027\u548c\u964d\u4f4e\u4e86\u641c\u7d22\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740\u6444\u50cf\u5934\u90e8\u7f72\u7684\u666e\u53ca\uff0c\u89c6\u9891\u6570\u636e\u6fc0\u589e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u67e5\u8be2\u5927\u89c4\u6a21\u89c6\u9891\u6570\u636e\u96c6\u4e2d\u7684\u7279\u5b9a\u5bf9\u8c61\u65f6\u9762\u4e34\u6311\u6218\uff0c\u5305\u62ec\u6570\u636e\u5904\u7406\u91cf\u5927\u3001\u67e5\u8be2\u9700\u6c42\u590d\u6742\u4ee5\u53ca\u9ad8\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "LOVO\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u7f16\u7801\u5668\u4e00\u6b21\u6027\u63d0\u53d6\u7279\u5f81\uff0c\u751f\u6210\u5173\u952e\u5e27\u7684\u7d27\u51d1\u89c6\u89c9\u5d4c\u5165\u5e76\u6784\u5efa\u9ad8\u6548\u7d22\u5f15\uff0c\u7ed3\u5408\u5012\u6392\u591a\u7d22\u5f15\u7ed3\u6784\u548c\u5411\u91cf\u6570\u636e\u5e93\u652f\u6301\u4efb\u610f\u5bf9\u8c61\u67e5\u8be2\u3002\u67e5\u8be2\u65f6\uff0c\u901a\u8fc7\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u548c\u8de8\u6a21\u6001\u91cd\u6392\u4f18\u5316\u7ed3\u679c\u3002", "result": "\u5728\u771f\u5b9e\u89c6\u9891\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cLOVO\u5728\u590d\u6742\u67e5\u8be2\u5904\u7406\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u67e5\u8be2\u51c6\u786e\u6027\u63a5\u8fd1\u6700\u4f18\uff0c\u641c\u7d22\u5ef6\u8fdf\u964d\u4f4e\u591a\u8fbe85\u500d\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u7d22\u5f15\u6784\u5efa\u6210\u672c\u3002", "conclusion": "LOVO\u4e3a\u89c6\u9891\u5206\u6790\u4e2d\u7684\u5bf9\u8c61\u67e5\u8be2\u8bbe\u5b9a\u4e86\u65b0\u7684\u6280\u672f\u6807\u6746\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u3001\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u52a8\u6001\u73af\u5883\u3002"}}
{"id": "2507.14822", "pdf": "https://arxiv.org/pdf/2507.14822", "abs": "https://arxiv.org/abs/2507.14822", "authors": ["Zeeshan Kaleem", "Misha Urooj Khan", "Ahmad Suleman", "Waqas Khalid", "Kai-Kit Wong", "Chau Yuen"], "title": "Quantum Skyshield: Quantum Key Distribution and Post-Quantum Authentication for Low-Altitude Wireless Networks in Adverse Skies", "categories": ["cs.CR", "cs.ET", "quant-ph"], "comment": null, "summary": "Recently, low-altitude wireless networks (LAWNs) have emerged as a critical\nbackbone for supporting the low-altitude economy, particularly with the\ndensification of unmanned aerial vehicles (UAVs) and high-altitude platforms\n(HAPs). To meet growing data demands, some LAWN deployments incorporate\nfree-space optical (FSO) links, which offer exceptional bandwidth and beam\ndirectivity. However, without strong security measures in place, both\nconventional radio frequency channels and FSO beams remain vulnerable to\ninterception and spoofing and FSO in particular can suffer from turbulence,\nmisalignment, and weather-related attenuation. To address these challenges in\nthe quantum era, a quantum-secure architecture called Quantum Skyshield is\nproposed to enable reliable communication between the base transceiver station\n(BTS) and LAWN. The proposed design integrates BB84 quantum key distribution\n(QKD) with post-quantum authentication mechanisms. Simulation results confirm\nthe reliable generation of a 128-bit symmetric key when the quantum bit error\nrate (QBER) remains below the threshold of 11%. Authentication is enforced\nusing Lamport one-time signatures and hash-based message authentication codes\n(HMAC) to ensure message integrity. A Grover-inspired threat detection\nmechanism identifies anomalies with up to 89% probability in a single\niteration, enabling real-time trust evaluation. Lastly, future research\nchallenges have also been identified and discussed to guide further development\nin this area.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuantum Skyshield\u7684\u91cf\u5b50\u5b89\u5168\u67b6\u6784\uff0c\u7ed3\u5408BB84\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u548c\u540e\u91cf\u5b50\u8ba4\u8bc1\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u7684\u5b89\u5168\u901a\u4fe1\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u548c\u9ad8\u7a7a\u5e73\u53f0\u7684\u5bc6\u96c6\u90e8\u7f72\uff0c\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u6210\u4e3a\u5173\u952e\u95ee\u9898\uff0c\u5c24\u5176\u662f\u81ea\u7531\u7a7a\u95f4\u5149\u94fe\u8def\u6613\u53d7\u62e6\u622a\u548c\u5e72\u6270\u3002", "method": "\u63d0\u51faQuantum Skyshield\u67b6\u6784\uff0c\u6574\u5408BB84\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u3001Lamport\u4e00\u6b21\u6027\u7b7e\u540d\u548cHMAC\u8ba4\u8bc1\uff0c\u5e76\u91c7\u7528Grover\u542f\u53d1\u7684\u5a01\u80c1\u68c0\u6d4b\u673a\u5236\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u5728\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u7387\u4f4e\u4e8e11%\u65f6\u53ef\u53ef\u9760\u751f\u6210128\u4f4d\u5bf9\u79f0\u5bc6\u94a5\uff0c\u5a01\u80c1\u68c0\u6d4b\u6982\u7387\u9ad8\u8fbe89%\u3002", "conclusion": "\u8be5\u67b6\u6784\u6709\u6548\u63d0\u5347\u4e86\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.15465", "pdf": "https://arxiv.org/pdf/2507.15465", "abs": "https://arxiv.org/abs/2507.15465", "authors": ["Sungmin Yun", "Seonyong Park", "Hwayong Nam", "Younjoo Lee", "Gunjun Lee", "Kwanhee Kyung", "Sangpyo Kim", "Nam Sung Kim", "Jongmin Kim", "Hyungyo Kim", "Juhwan Cho", "Seungmin Baek", "Jung Ho Ahn"], "title": "The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts", "categories": ["cs.AR", "cs.AI"], "comment": "15 pages, 11 figures", "summary": "Computational workloads composing traditional Transformer models are starkly\nbifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic\nintensity, while feedforward layers are compute-bound. This dichotomy has long\nmotivated research into specialized hardware to mitigate the MHA bottleneck.\n  This paper argues that recent architectural shifts, namely Multi-head Latent\nAttention (MLA) and Mixture-of-Experts (MoE), challenge the premise of\nspecialized attention hardware. We make two key observations. First, the\narithmetic intensity of MLA is over two orders of magnitude greater than that\nof MHA, shifting it close to a compute-bound regime well-suited for modern\naccelerators like GPUs. Second, by distributing MoE experts across a pool of\naccelerators, their arithmetic intensity can be tuned through batching to match\nthat of the dense layers, creating a more balanced computational profile.\n  These findings reveal a diminishing need for specialized attention hardware.\nThe central challenge for next-generation Transformers is no longer\naccelerating a single memory-bound layer. Instead, the focus must shift to\ndesigning balanced systems with sufficient compute, memory capacity, memory\nbandwidth, and high-bandwidth interconnects to manage the diverse demands of\nlarge-scale models.", "AI": {"tldr": "\u4f20\u7edfTransformer\u6a21\u578b\u7684\u8ba1\u7b97\u8d1f\u8f7d\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u5185\u5b58\u53d7\u9650\u7684\u591a\u5934\u6ce8\u610f\u529b\uff08MHA\uff09\u548c\u8ba1\u7b97\u53d7\u9650\u7684\u9988\u9001\u5c42\u3002\u672c\u6587\u6307\u51fa\uff0c\u65b0\u7684\u67b6\u6784\u5982\u591a\u5934\u6f5c\u5728\u6ce8\u610f\u529b\uff08MLA\uff09\u548c\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u6539\u53d8\u4e86\u8fd9\u4e00\u73b0\u72b6\uff0c\u4f7f\u5f97\u4e13\u7528\u6ce8\u610f\u529b\u786c\u4ef6\u7684\u9700\u6c42\u51cf\u5c11\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u4f20\u7edfTransformer\u4e2dMHA\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u65b0\u67b6\u6784\uff08MLA\u548cMoE\uff09\u662f\u5426\u6d88\u9664\u4e86\u5bf9\u4e13\u7528\u786c\u4ef6\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5206\u6790MLA\u548cMoE\u7684\u8ba1\u7b97\u7279\u6027\uff0c\u6bd4\u8f83\u5176\u7b97\u672f\u5f3a\u5ea6\u4e0eMHA\u7684\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u6279\u91cf\u8c03\u6574MoE\u7684\u8ba1\u7b97\u5f3a\u5ea6\u4ee5\u5339\u914d\u5bc6\u96c6\u5c42\u3002", "result": "MLA\u7684\u7b97\u672f\u5f3a\u5ea6\u6bd4MHA\u9ad8\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u63a5\u8fd1\u8ba1\u7b97\u53d7\u9650\u72b6\u6001\uff1bMoE\u7684\u7b97\u672f\u5f3a\u5ea6\u53ef\u901a\u8fc7\u6279\u91cf\u8c03\u6574\uff0c\u4f7f\u5f97\u6a21\u578b\u8ba1\u7b97\u66f4\u52a0\u5747\u8861\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0c\u672a\u6765\u7684\u7814\u7a76\u91cd\u70b9\u5e94\u4ece\u4e13\u7528\u6ce8\u610f\u529b\u786c\u4ef6\u8f6c\u5411\u8bbe\u8ba1\u5e73\u8861\u7684\u7cfb\u7edf\uff0c\u4ee5\u6ee1\u8db3\u5927\u89c4\u6a21\u6a21\u578b\u7684\u591a\u6837\u9700\u6c42\u3002"}}
{"id": "2507.14802", "pdf": "https://arxiv.org/pdf/2507.14802", "abs": "https://arxiv.org/abs/2507.14802", "authors": ["Ziming Dai", "Chao Qiu", "Fei Gao", "Yunfeng Zhao", "Xiaofei Wang"], "title": "ACME: Adaptive Customization of Large Models via Distributed Systems", "categories": ["cs.DC", "cs.AI", "C.2.4; I.2.6"], "comment": "Accepted to IEEE ICDCS 2025. 11 pages, 13 figures", "summary": "Pre-trained Transformer-based large models have revolutionized personal\nvirtual assistants, but their deployment in cloud environments faces challenges\nrelated to data privacy and response latency. Deploying large models closer to\nthe data and users has become a key research area to address these issues.\nHowever, applying these models directly often entails significant difficulties,\nsuch as model mismatching, resource constraints, and energy inefficiency.\nAutomated design of customized models is necessary, but it faces three key\nchallenges, namely, the high cost of centralized model customization,\nimbalanced performance from user heterogeneity, and suboptimal performance from\ndata heterogeneity. In this paper, we propose ACME, an adaptive customization\napproach of Transformer-based large models via distributed systems. To avoid\nthe low cost-efficiency of centralized methods, ACME employs a bidirectional\nsingle-loop distributed system to progressively achieve fine-grained\ncollaborative model customization. In order to better match user heterogeneity,\nit begins by customizing the backbone generation and identifying the Pareto\nFront under model size constraints to ensure optimal resource utilization.\nSubsequently, it performs header generation and refines the model using data\ndistribution-based personalized architecture aggregation to match data\nheterogeneity. Evaluation on different datasets shows that ACME achieves\ncost-efficient models under model size constraints. Compared to centralized\nsystems, data transmission volume is reduced to 6 percent. Additionally, the\naverage accuracy improves by 10 percent compared to the baseline, with the\ntrade-off metrics increasing by nearly 30 percent.", "AI": {"tldr": "ACME\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u7684Transformer\u5927\u6a21\u578b\u5b9a\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u5411\u5355\u5faa\u73af\u7cfb\u7edf\u4f18\u5316\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6570\u636e\u4f20\u8f93\u91cf\u5e76\u63d0\u5347\u4e86\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u4e91\u73af\u5883\u4e2d\u5927\u6a21\u578b\u90e8\u7f72\u7684\u6570\u636e\u9690\u79c1\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u540c\u65f6\u5e94\u5bf9\u96c6\u4e2d\u5f0f\u5b9a\u5236\u7684\u9ad8\u6210\u672c\u548c\u7528\u6237/\u6570\u636e\u5f02\u6784\u6027\u5e26\u6765\u7684\u6027\u80fd\u4e0d\u5e73\u8861\u3002", "method": "\u91c7\u7528\u53cc\u5411\u5355\u5faa\u73af\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u5206\u9636\u6bb5\u5b9a\u5236\u4e3b\u5e72\u548c\u5934\u90e8\u5206\uff0c\u5e76\u901a\u8fc7Pareto Front\u4f18\u5316\u8d44\u6e90\u5229\u7528\u548c\u4e2a\u6027\u5316\u67b6\u6784\u805a\u5408\u3002", "result": "\u6570\u636e\u4f20\u8f93\u91cf\u964d\u81f36%\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534710%\uff0c\u6743\u8861\u6307\u6807\u589e\u52a0\u8fd130%\u3002", "conclusion": "ACME\u6709\u6548\u89e3\u51b3\u4e86\u5927\u6a21\u578b\u5b9a\u5236\u4e2d\u7684\u6210\u672c\u548c\u6027\u80fd\u95ee\u9898\uff0c\u5177\u6709\u663e\u8457\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.14767", "pdf": "https://arxiv.org/pdf/2507.14767", "abs": "https://arxiv.org/abs/2507.14767", "authors": ["Yanming Zhang", "Krishnakumar Hegde", "Klaus Mueller"], "title": "XplainAct: Visualization for Personalized Intervention Insights", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "This paper will be published and presented at IEEE Visualization\n  (VIS) 2025, Vienna, Austria, November 2025", "summary": "Causality helps people reason about and understand complex systems,\nparticularly through what-if analyses that explore how interventions might\nalter outcomes. Although existing methods embrace causal reasoning using\ninterventions and counterfactual analysis, they primarily focus on effects at\nthe population level. These approaches often fall short in systems\ncharacterized by significant heterogeneity, where the impact of an intervention\ncan vary widely across subgroups. To address this challenge, we present\nXplainAct, a visual analytics framework that supports simulating, explaining,\nand reasoning interventions at the individual level within subpopulations. We\ndemonstrate the effectiveness of XplainAct through two case studies:\ninvestigating opioid-related deaths in epidemiology and analyzing voting\ninclinations in the presidential election.", "AI": {"tldr": "XplainAct\u662f\u4e00\u4e2a\u53ef\u89c6\u5316\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5b50\u7fa4\u4f53\u4e2d\u6a21\u62df\u3001\u89e3\u91ca\u548c\u63a8\u7406\u4e2a\u4f53\u5c42\u9762\u7684\u5e72\u9884\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u7fa4\u4f53\u5c42\u9762\uff0c\u96be\u4ee5\u5e94\u5bf9\u663e\u8457\u5f02\u8d28\u6027\u7cfb\u7edf\uff0c\u56e0\u6b64\u9700\u8981\u652f\u6301\u4e2a\u4f53\u5c42\u9762\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u63d0\u51faXplainAct\u6846\u67b6\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff08\u963f\u7247\u7c7b\u836f\u7269\u76f8\u5173\u6b7b\u4ea1\u548c\u603b\u7edf\u9009\u4e3e\u6295\u7968\u503e\u5411\uff09\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "XplainAct\u80fd\u6709\u6548\u652f\u6301\u4e2a\u4f53\u5c42\u9762\u7684\u5e72\u9884\u5206\u6790\u548c\u63a8\u7406\u3002", "conclusion": "XplainAct\u4e3a\u5f02\u8d28\u6027\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15629", "pdf": "https://arxiv.org/pdf/2507.15629", "abs": "https://arxiv.org/abs/2507.15629", "authors": ["Zuo-Liang Zhu", "Jian Yang", "Beibei Wang"], "title": "Gaussian Splatting with Discretized SDF for Relightable Assets", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D Gaussian splatting (3DGS) has shown its detailed expressive ability and\nhighly efficient rendering speed in the novel view synthesis (NVS) task. The\napplication to inverse rendering still faces several challenges, as the\ndiscrete nature of Gaussian primitives makes it difficult to apply geometry\nconstraints. Recent works introduce the signed distance field (SDF) as an extra\ncontinuous representation to regularize the geometry defined by Gaussian\nprimitives. It improves the decomposition quality, at the cost of increasing\nmemory usage and complicating training. Unlike these works, we introduce a\ndiscretized SDF to represent the continuous SDF in a discrete manner by\nencoding it within each Gaussian using a sampled value. This approach allows us\nto link the SDF with the Gaussian opacity through an SDF-to-opacity\ntransformation, enabling rendering the SDF via splatting and avoiding the\ncomputational cost of ray marching.The key challenge is to regularize the\ndiscrete samples to be consistent with the underlying SDF, as the discrete\nrepresentation can hardly apply the gradient-based constraints (\\eg Eikonal\nloss). For this, we project Gaussians onto the zero-level set of SDF and\nenforce alignment with the surface from splatting, namely a projection-based\nconsistency loss. Thanks to the discretized SDF, our method achieves higher\nrelighting quality, while requiring no extra memory beyond GS and avoiding\ncomplex manually designed optimization. The experiments reveal that our method\noutperforms existing Gaussian-based inverse rendering methods. Our code is\navailable at https://github.com/NK-CS-ZZL/DiscretizedSDF.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79bb\u6563\u5316SDF\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u9ad8\u65af\u57fa\u5143\u4e2d\u7f16\u7801SDF\u503c\uff0c\u907f\u514d\u4e86\u989d\u5916\u5185\u5b58\u5f00\u9500\u548c\u590d\u6742\u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u9006\u6e32\u67d3\u8d28\u91cf\u3002", "motivation": "\u9ad8\u65af\u57fa\u5143\u5728\u9006\u6e32\u67d3\u4efb\u52a1\u4e2d\u56e0\u79bb\u6563\u6027\u96be\u4ee5\u5e94\u7528\u51e0\u4f55\u7ea6\u675f\uff0c\u73b0\u6709\u65b9\u6cd5\u5f15\u5165SDF\u4f46\u589e\u52a0\u4e86\u5185\u5b58\u548c\u8bad\u7ec3\u590d\u6742\u5ea6\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u79bb\u6563\u5316SDF\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5728\u9ad8\u65af\u57fa\u5143\u4e2d\u91c7\u6837\u7f16\u7801SDF\u503c\uff0c\u901a\u8fc7SDF-to-opacity\u8f6c\u6362\u5b9e\u73b0\u6e32\u67d3\uff0c\u5e76\u8bbe\u8ba1\u6295\u5f71\u4e00\u81f4\u6027\u635f\u5931\u6b63\u5219\u5316\u79bb\u6563\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u65e0\u989d\u5916\u5185\u5b58\u5f00\u9500\u548c\u590d\u6742\u4f18\u5316\u60c5\u51b5\u4e0b\uff0c\u663e\u7740\u63d0\u9ad8\u4e86\u9006\u6e32\u67d3\u8d28\u91cf\u3002", "conclusion": "\u79bb\u6563\u5316SDF\u65b9\u6cd5\u5728\u9ad8\u65af\u57fa\u5143\u4e2d\u6709\u6548\u7ed3\u5408\u4e86SDF\u7684\u4f18\u52bf\uff0c\u63d0\u5347\u4e86\u9006\u6e32\u67d3\u6027\u80fd\uff0c\u4e14\u5b9e\u73b0\u7b80\u5355\u9ad8\u6548\u3002"}}
{"id": "2507.14558", "pdf": "https://arxiv.org/pdf/2507.14558", "abs": "https://arxiv.org/abs/2507.14558", "authors": ["Bin Duan", "Tarek Mahmud", "Meiru Che", "Yan Yan", "Naipeng Dong", "Dan Dongseong Kim", "Guowei Yang"], "title": "Harnessing LLMs for Document-Guided Fuzzing of OpenCV Library", "categories": ["cs.SE"], "comment": null, "summary": "The combination of computer vision and artificial intelligence is\nfundamentally transforming a broad spectrum of industries by enabling machines\nto interpret and act upon visual data with high levels of accuracy. As the\nbiggest and by far the most popular open-source computer vision library, OpenCV\nlibrary provides an extensive suite of programming functions supporting\nreal-time computer vision. Bugs in the OpenCV library can affect the downstream\ncomputer vision applications, and it is critical to ensure the reliability of\nthe OpenCV library. This paper introduces VISTAFUZZ, a novel technique for\nharnessing large language models (LLMs) for document-guided fuzzing of the\nOpenCV library. VISTAFUZZ utilizes LLMs to parse API documentation and obtain\nstandardized API information. Based on this standardized information, VISTAFUZZ\nextracts constraints on individual input parameters and dependencies between\nthese. Using these constraints and dependencies, VISTAFUZZ then generates new\ninput values to systematically test each target API. We evaluate the\neffectiveness of VISTAFUZZ in testing 330 APIs in the OpenCV library, and the\nresults show that VISTAFUZZ detected 17 new bugs, where 10 bugs have been\nconfirmed, and 5 of these have been fixed.", "AI": {"tldr": "VISTAFUZZ\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u89e3\u6790OpenCV API\u6587\u6863\uff0c\u751f\u6210\u8f93\u5165\u503c\u4ee5\u7cfb\u7edf\u6d4b\u8bd5API\uff0c\u53d1\u73b0\u5e76\u4fee\u590d\u4e86\u591a\u4e2abug\u3002", "motivation": "OpenCV\u4f5c\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90\u8ba1\u7b97\u673a\u89c6\u89c9\u5e93\uff0c\u5176\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5e93\u4e2d\u7684bug\u53ef\u80fd\u5f71\u54cd\u4e0b\u6e38\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "VISTAFUZZ\u901a\u8fc7LLM\u89e3\u6790API\u6587\u6863\uff0c\u63d0\u53d6\u53c2\u6570\u7ea6\u675f\u548c\u4f9d\u8d56\u5173\u7cfb\uff0c\u751f\u6210\u8f93\u5165\u503c\u4ee5\u6d4b\u8bd5OpenCV API\u3002", "result": "\u5728\u6d4b\u8bd5330\u4e2aAPI\u65f6\uff0cVISTAFUZZ\u53d1\u73b0\u4e8617\u4e2a\u65b0bug\uff0c\u5176\u4e2d10\u4e2a\u88ab\u786e\u8ba4\uff0c5\u4e2a\u5df2\u4fee\u590d\u3002", "conclusion": "VISTAFUZZ\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5229\u7528LLM\u63d0\u5347OpenCV\u5e93\u7684\u53ef\u9760\u6027\uff0c\u5c55\u793a\u4e86\u6587\u6863\u5f15\u5bfc\u7684\u6a21\u7cca\u6d4b\u8bd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15596", "pdf": "https://arxiv.org/pdf/2507.15596", "abs": "https://arxiv.org/abs/2507.15596", "authors": ["Jaeseo Lee", "Kyungmin Bae"], "title": "Formal Analysis of Networked PLC Controllers Interacting with Physical Environments", "categories": ["cs.PL", "cs.LO"], "comment": "To appear in Proceedings of the Static Analysis Symposium (SAS) 2025", "summary": "Programmable Logic Controllers (PLCs) are widely used in industrial\nautomation to control physical systems. As PLC applications become increasingly\ncomplex, ensuring their correctness is crucial. Existing formal verification\ntechniques focus on individual PLC programs in isolation, often neglecting\ninteractions with physical environments and network communication between\ncontrollers. This limitation poses significant challenges in analyzing\nreal-world industrial systems, where continuous dynamics and communication\ndelays play a critical role. In this paper, we present a unified formal\nframework that integrates discrete PLC semantics, networked communication, and\ncontinuous physical behaviors. To mitigate state explosion, we apply partial\norder reduction, significantly reducing the number of explored states while\nmaintaining correctness. Our framework enables precise analysis of PLC-driven\nsystems with continuous dynamics and networked communication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790PLC\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u6574\u5408\u4e86\u79bb\u6563PLC\u8bed\u4e49\u3001\u7f51\u7edc\u901a\u4fe1\u548c\u8fde\u7eed\u7269\u7406\u884c\u4e3a\uff0c\u5e76\u91c7\u7528\u504f\u5e8f\u5f52\u7ea6\u6280\u672f\u89e3\u51b3\u4e86\u72b6\u6001\u7206\u70b8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6280\u672f\u5f80\u5f80\u5ffd\u7565PLC\u7a0b\u5e8f\u4e0e\u7269\u7406\u73af\u5883\u548c\u7f51\u7edc\u901a\u4fe1\u7684\u4ea4\u4e92\uff0c\u65e0\u6cd5\u6709\u6548\u5206\u6790\u5b9e\u9645\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684\u8fde\u7eed\u52a8\u6001\u548c\u901a\u4fe1\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u6574\u5408\u79bb\u6563PLC\u8bed\u4e49\u3001\u7f51\u7edc\u901a\u4fe1\u548c\u8fde\u7eed\u7269\u7406\u884c\u4e3a\uff0c\u5e76\u4f7f\u7528\u504f\u5e8f\u5f52\u7ea6\u6280\u672f\u51cf\u5c11\u72b6\u6001\u7a7a\u95f4\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u7cbe\u786e\u5206\u6790\u5177\u6709\u8fde\u7eed\u52a8\u6001\u548c\u7f51\u7edc\u901a\u4fe1\u7684PLC\u9a71\u52a8\u7cfb\u7edf\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u72b6\u6001\u63a2\u7d22\u6570\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u590d\u6742\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684PLC\u7a0b\u5e8f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.14211", "pdf": "https://arxiv.org/pdf/2507.14211", "abs": "https://arxiv.org/abs/2507.14211", "authors": ["Federico Mason", "Tommaso Zugno", "Matteo Drago", "Marco Giordani", "Mate Boban", "Michele Zorzi"], "title": "PRATA: A Framework to Enable Predictive QoS in Vehicular Networks via Artificial Intelligence", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "Predictive Quality of Service (PQoS) makes it possible to anticipate QoS\nchanges, e.g., in wireless networks, and trigger appropriate countermeasures to\navoid performance degradation. Hence, PQoS is extremely useful for automotive\napplications such as teleoperated driving, which poses strict constraints in\nterms of latency and reliability. A promising tool for PQoS is given by\nReinforcement Learning (RL), a methodology that enables the design of\ndecision-making strategies for stochastic optimization. In this manuscript, we\npresent PRATA, a new simulation framework to enable PRedictive QoS based on AI\nfor Teleoperated driving Applications. PRATA consists of a modular pipeline\nthat includes (i) an end-to-end protocol stack to simulate the 5G Radio Access\nNetwork (RAN), (ii) a tool for generating automotive data, and (iii) an\nArtificial Intelligence (AI) unit to optimize PQoS decisions. To prove its\nutility, we use PRATA to design an RL unit, named RAN-AI, to optimize the\nsegmentation level of teleoperated driving data in the event of resource\nsaturation or channel degradation. Hence, we show that the RAN-AI entity\nefficiently balances the trade-off between QoS and Quality of Experience (QoE)\nthat characterize teleoperated driving applications, almost doubling the system\nperformance compared to baseline approaches. In addition, by varying the\nlearning settings of the RAN-AI entity, we investigate the impact of the state\nspace and the relative cost of acquiring network data that are necessary for\nthe implementation of RL.", "AI": {"tldr": "PRATA\u662f\u4e00\u4e2a\u57fa\u4e8eAI\u7684\u9884\u6d4b\u6027QoS\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u8fdc\u7a0b\u9a7e\u9a76\u5e94\u7528\u4e2d\u7684QoS\u51b3\u7b56\uff0c\u7ed3\u5408RL\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u8fdc\u7a0b\u9a7e\u9a76\u5bf9\u5ef6\u8fdf\u548c\u53ef\u9760\u6027\u6709\u4e25\u683c\u8981\u6c42\uff0c\u9884\u6d4b\u6027QoS\u80fd\u907f\u514d\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u7406\u60f3\u5de5\u5177\u3002", "method": "PRATA\u6846\u67b6\u5305\u62ec5G RAN\u6a21\u62df\u3001\u8f66\u8f86\u6570\u636e\u751f\u6210\u5de5\u5177\u548cAI\u4f18\u5316\u5355\u5143\uff0c\u901a\u8fc7RL\u8bbe\u8ba1\u5206\u6bb5\u4f18\u5316\u7b56\u7565\uff08RAN-AI\uff09\u3002", "result": "RAN-AI\u5e73\u8861\u4e86QoS\u548cQoE\uff0c\u7cfb\u7edf\u6027\u80fd\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u8fd1\u4e00\u500d\uff0c\u540c\u65f6\u5206\u6790\u4e86\u72b6\u6001\u7a7a\u95f4\u548c\u6570\u636e\u91c7\u96c6\u6210\u672c\u7684\u5f71\u54cd\u3002", "conclusion": "PRATA\u6846\u67b6\u6709\u6548\u4f18\u5316\u8fdc\u7a0b\u9a7e\u9a76\u7684QoS\uff0c\u5c55\u793a\u4e86RL\u5728\u9884\u6d4b\u6027QoS\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14809", "pdf": "https://arxiv.org/pdf/2507.14809", "abs": "https://arxiv.org/abs/2507.14809", "authors": ["Zesen Zhong", "Duomin Zhang", "Yijia Li"], "title": "Light Future: Multimodal Action Frame Prediction via InstructPix2Pix", "categories": ["cs.CV", "cs.MM", "cs.RO", "I.2.10; I.4.8"], "comment": "9 pages including appendix, 5 tables, 8 figures, to be submitted to\n  WACV 2026", "summary": "Predicting future motion trajectories is a critical capability across domains\nsuch as robotics, autonomous systems, and human activity forecasting, enabling\nsafer and more intelligent decision-making. This paper proposes a novel,\nefficient, and lightweight approach for robot action prediction, offering\nsignificantly reduced computational cost and inference latency compared to\nconventional video prediction models. Importantly, it pioneers the adaptation\nof the InstructPix2Pix model for forecasting future visual frames in robotic\ntasks, extending its utility beyond static image editing. We implement a deep\nlearning-based visual prediction framework that forecasts what a robot will\nobserve 100 frames (10 seconds) into the future, given a current image and a\ntextual instruction. We repurpose and fine-tune the InstructPix2Pix model to\naccept both visual and textual inputs, enabling multimodal future frame\nprediction. Experiments on the RoboTWin dataset (generated based on real-world\nscenarios) demonstrate that our method achieves superior SSIM and PSNR compared\nto state-of-the-art baselines in robot action prediction tasks. Unlike\nconventional video prediction models that require multiple input frames, heavy\ncomputation, and slow inference latency, our approach only needs a single image\nand a text prompt as input. This lightweight design enables faster inference,\nreduced GPU demands, and flexible multimodal control, particularly valuable for\napplications like robotics and sports motion trajectory analytics, where motion\ntrajectory precision is prioritized over visual fidelity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u673a\u5668\u4eba\u52a8\u4f5c\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528InstructPix2Pix\u6a21\u578b\u5b9e\u73b0\u5355\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\u7684100\u5e27\u672a\u6765\u89c6\u89c9\u9884\u6d4b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u9884\u6d4b\u672a\u6765\u8fd0\u52a8\u8f68\u8ff9\u5728\u673a\u5668\u4eba\u3001\u81ea\u4e3b\u7cfb\u7edf\u548c\u4eba\u7c7b\u6d3b\u52a8\u9884\u6d4b\u7b49\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u89c6\u9891\u9884\u6d4b\u6a21\u578b\u8ba1\u7b97\u5bc6\u96c6\u4e14\u5ef6\u8fdf\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eInstructPix2Pix\u6539\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u652f\u6301\u89c6\u89c9\u548c\u6587\u672c\u591a\u6a21\u6001\u8f93\u5165\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5355\u56fe\u50cf\u548c\u6587\u672c\u9884\u6d4b\u672a\u6765100\u5e27\u7684\u80fd\u529b\u3002", "result": "\u5728RoboTWin\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728SSIM\u548cPSNR\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u9700\u6c42\u548c\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9700\u8981\u5feb\u901f\u548c\u8f7b\u91cf\u7ea7\u9884\u6d4b\u7684\u5e94\u7528\uff08\u5982\u673a\u5668\u4eba\u4efb\u52a1\u548c\u8fd0\u52a8\u8f68\u8ff9\u5206\u6790\uff09\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15415", "pdf": "https://arxiv.org/pdf/2507.15415", "abs": "https://arxiv.org/abs/2507.15415", "authors": ["Florent Ferrari", "Emmanuel Hainry", "Romain P\u00e9choux", "M\u00e1rio Silva"], "title": "Quantum Programming in Polylogarithmic Time", "categories": ["cs.LO", "cs.PL"], "comment": null, "summary": "Polylogarithmic time delineates a relevant notion of feasibility on several\nclassical computational models such as Boolean circuits or parallel random\naccess machines. As far as the quantum paradigm is concerned, this notion\nyields the complexity class FBQPOLYLOG of functions approximable in\npolylogarithmic time with a quantum random-access Turing machine. We introduce\na quantum programming language with first-order recursive procedures, which\nprovides the first programming-language-based characterization of FBQPOLYLOG.\nEach program computes a function in FBQPOLYLOG (soundness) and, conversely,\neach function of this complexity class is computed by a program (completeness).\nWe also provide a compilation strategy from programs to uniform families of\nquantum circuits of polylogarithmic depth and polynomial size, whose set of\ncomputed functions is known as QNC, and recover the well-known separation\nresult FBQPOLYLOG $\\subsetneq$ QNC.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\uff0c\u9996\u6b21\u4ece\u7f16\u7a0b\u8bed\u8a00\u89d2\u5ea6\u63cf\u8ff0\u4e86FBQPOLYLOG\u7c7b\uff0c\u5c55\u793a\u4e86\u5176\u5b8c\u5907\u6027\u4e0e\u6b63\u786e\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u7f16\u8bd1\u7b56\u7565\uff0c\u9a8c\u8bc1\u4e86FBQPOLYLOG\u4e0eQNC\u7684\u5305\u542b\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7f16\u7a0b\u8bed\u8a00\u7684\u65b9\u5f0f\u63cf\u8ff0FBQPOLYLOG\u590d\u6742\u6027\u7c7b\uff0c\u586b\u8865\u91cf\u5b50\u8ba1\u7b97\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u4e00\u9636\u9012\u5f52\u8fc7\u7a0b\u7684\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\uff0c\u8bc1\u660e\u4e86\u5176\u8ba1\u7b97\u80fd\u529b\u4e0eFBQPOLYLOG\u7c7b\u4e00\u81f4\uff0c\u5e76\u63d0\u4f9b\u4e86\u5c06\u5176\u7f16\u8bd1\u4e3a\u91cf\u5b50\u7535\u8def\u7684\u7b56\u7565\u3002", "result": "\u9a8c\u8bc1\u4e86\u7a0b\u5e8f\u7684\u5b8c\u5907\u6027\u4e0e\u6b63\u786e\u6027\uff0c\u5b9e\u73b0\u4e86FBQPOLYLOG\u7c7b\u51fd\u6570\u7684\u8ba1\u7b97\uff0c\u5e76\u63ed\u793a\u4e86FBQPOLYLOG\u4e0eQNC\u7684\u5305\u542b\u5173\u7cfb\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91cf\u5b50\u8ba1\u7b97\u6a21\u578b\u7684\u7f16\u7a0b\u8bed\u8a00\u63cf\u8ff0\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u9a8c\u8bc1\u4e86FBQPOLYLOG\u7c7b\u7684\u8ba1\u7b97\u80fd\u529b\u4e0e\u9650\u5236\u3002"}}
{"id": "2507.14372", "pdf": "https://arxiv.org/pdf/2507.14372", "abs": "https://arxiv.org/abs/2507.14372", "authors": ["Albert Chen", "Manas Bundele", "Gaurav Ahlawat", "Patrick Stetz", "Zhitao Wang", "Qiang Fei", "Donghoon Jung", "Audrey Chu", "Bharadwaj Jayaraman", "Ayushi Panth", "Yatin Arora", "Sourav Jain", "Renjith Varma", "Alexey Ilin", "Iuliia Melnychuk", "Chelsea Chueh", "Joyan Sil", "Xiaofeng Wang"], "title": "Text-to-SQL for Enterprise Data Analytics", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.HC"], "comment": "11 pages, 8 figures, Workshop on Agentic AI for Enterprise at KDD '25", "summary": "The introduction of large language models has brought rapid progress on\nText-to-SQL benchmarks, but it is not yet easy to build a working enterprise\nsolution. In this paper, we present insights from building an internal chatbot\nthat enables LinkedIn's product managers, engineers, and operations teams to\nself-serve data insights from a large, dynamic data lake. Our approach features\nthree components. First, we construct a knowledge graph that captures\nup-to-date semantics by indexing database metadata, historical query logs,\nwikis, and code. We apply clustering to identify relevant tables for each team\nor product area. Second, we build a Text-to-SQL agent that retrieves and ranks\ncontext from the knowledge graph, writes a query, and automatically corrects\nhallucinations and syntax errors. Third, we build an interactive chatbot that\nsupports various user intents, from data discovery to query writing to\ndebugging, and displays responses in rich UI elements to encourage follow-up\nchats. Our chatbot has over 300 weekly users. Expert review shows that 53% of\nits responses are correct or close to correct on an internal benchmark set.\nThrough ablation studies, we identify the most important knowledge graph and\nmodeling components, offering a practical path for developing enterprise\nText-to-SQL solutions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86LinkedIn\u5f00\u53d1\u7684\u5185\u90e8\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u3001Text-to-SQL\u4ee3\u7406\u548c\u4ea4\u4e92\u5f0f\u804a\u5929\u754c\u9762\uff0c\u5e2e\u52a9\u56e2\u961f\u81ea\u52a9\u83b7\u53d6\u6570\u636e\u6d1e\u5bdf\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Text-to-SQL\u4efb\u52a1\u4e0a\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u6784\u5efa\u4f01\u4e1a\u7ea7\u89e3\u51b3\u65b9\u6848\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u3001Text-to-SQL\u4ee3\u7406\u548c\u4ea4\u4e92\u5f0f\u804a\u5929\u673a\u5668\u4eba\uff0c\u652f\u6301\u7528\u6237\u4ece\u6570\u636e\u53d1\u73b0\u5230\u67e5\u8be2\u8c03\u8bd5\u7684\u5168\u6d41\u7a0b\u3002", "result": "\u804a\u5929\u673a\u5668\u4eba\u6bcf\u5468\u6709300\u591a\u540d\u7528\u6237\uff0c53%\u7684\u54cd\u5e94\u5728\u5185\u90e8\u6d4b\u8bd5\u4e2d\u88ab\u8bc4\u4e3a\u6b63\u786e\u6216\u63a5\u8fd1\u6b63\u786e\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4f01\u4e1a\u7ea7Text-to-SQL\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5f00\u53d1\u8def\u5f84\u3002"}}
{"id": "2507.14985", "pdf": "https://arxiv.org/pdf/2507.14985", "abs": "https://arxiv.org/abs/2507.14985", "authors": ["Argianto Rahartomo", "Leonel Merino", "Mohammad Ghafari"], "title": "Metaverse Security and Privacy Research: A Systematic Review", "categories": ["cs.CR", "cs.ET", "cs.HC", "cs.SE"], "comment": "The paper is accepted for publication at Computers & Security Journal", "summary": "The rapid growth of metaverse technologies, including virtual worlds,\naugmented reality, and lifelogging, has accelerated their adoption across\ndiverse domains. This rise exposes users to significant new security and\nprivacy challenges due to sociotechnical complexity, pervasive connectivity,\nand extensive user data collection in immersive environments. We present a\nsystematic review of the literature published between 2013 and 2024, offering a\ncomprehensive analysis of how the research community has addressed\nmetaverse-related security and privacy issues over the past decade. We organize\nthe studies by method, examined the security and privacy properties, immersive\ncomponents, and evaluation strategies. Our investigation reveals a sharp\nincrease in research activity in the last five years, a strong focus on\npractical and user-centered approaches, and a predominant use of benchmarking,\nhuman experimentation, and qualitative methods. Authentication and\nunobservability are the most frequently studied properties. However, critical\ngaps remain in areas such as policy compliance, accessibility,\ninteroperability, and back-end infrastructure security. We emphasize the\nintertwined technical complexity and human factors of the metaverse and call\nfor integrated, interdisciplinary approaches to securing inclusive and\ntrustworthy immersive environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u56de\u987e\u4e862013\u81f32024\u5e74\u95f4\u5173\u4e8e\u5143\u5b87\u5b99\u5b89\u5168\u548c\u9690\u79c1\u95ee\u9898\u7684\u7814\u7a76\uff0c\u5206\u6790\u4e86\u65b9\u6cd5\u548c\u8d8b\u52bf\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5143\u5b87\u5b99\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5176\u5b89\u5168\u548c\u9690\u79c1\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7efc\u8ff0\u6765\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u6574\u7406\u7814\u7a76\u65b9\u6cd5\u3001\u5b89\u5168\u9690\u79c1\u5c5e\u6027\u3001\u6c89\u6d78\u5f0f\u7ec4\u4ef6\u548c\u8bc4\u4f30\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8fc7\u53bb\u4e94\u5e74\u7814\u7a76\u6d3b\u52a8\u6fc0\u589e\uff0c\u6ce8\u91cd\u5b9e\u8df5\u548c\u7528\u6237\u4e3a\u4e2d\u5fc3\uff0c\u4f46\u653f\u7b56\u5408\u89c4\u3001\u53ef\u8bbf\u95ee\u6027\u7b49\u9886\u57df\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u9700\u7ed3\u5408\u6280\u672f\u548c\u4eba\u6587\u56e0\u7d20\uff0c\u91c7\u7528\u8de8\u5b66\u79d1\u65b9\u6cd5\u5efa\u8bbe\u53ef\u4fe1\u8d56\u7684\u6c89\u6d78\u5f0f\u73af\u5883\u3002"}}
{"id": "2507.15603", "pdf": "https://arxiv.org/pdf/2507.15603", "abs": "https://arxiv.org/abs/2507.15603", "authors": ["Haoxiong Ren", "Yangu He", "Kwunhang Wong", "Rui Bao", "Ning Lin", "Zhongrui Wang", "Dashan Shang"], "title": "When Pipelined In-Memory Accelerators Meet Spiking Direct Feedback Alignment: A Co-Design for Neuromorphic Edge Computing", "categories": ["cs.AR"], "comment": "International Conference on Computer-Aided Design 2025", "summary": "Spiking Neural Networks (SNNs) are increasingly favored for deployment on\nresource-constrained edge devices due to their energy-efficient and\nevent-driven processing capabilities. However, training SNNs remains\nchallenging because of the computational intensity of traditional\nbackpropagation algorithms adapted for spike-based systems. In this paper, we\npropose a novel software-hardware co-design that introduces a hardware-friendly\ntraining algorithm, Spiking Direct Feedback Alignment (SDFA) and implement it\non a Resistive Random Access Memory (RRAM)-based In-Memory Computing (IMC)\narchitecture, referred to as PipeSDFA, to accelerate SNN training.\nSoftware-wise, the computational complexity of SNN training is reduced by the\nSDFA through the elimination of sequential error propagation. Hardware-wise, a\nthree-level pipelined dataflow is designed based on IMC architecture to\nparallelize the training process. Experimental results demonstrate that the\nPipeSDFA training accelerator incurs less than 2% accuracy loss on five\ndatasets compared to baselines, while achieving 1.1X~10.5X and 1.37X~2.1X\nreductions in training time and energy consumption, respectively compared to\nPipeLayer.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPipeSDFA\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u786c\u4ef6\u53cb\u597d\u7684SDFA\u7b97\u6cd5\u548cRRAM-based IMC\u67b6\u6784\uff0c\u52a0\u901fSNN\u8bad\u7ec3\uff0c\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u80fd\u8017\u3002", "motivation": "SNN\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5177\u6709\u80fd\u6548\u4f18\u52bf\uff0c\u4f46\u4f20\u7edf\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5728\u8bad\u7ec3SNN\u65f6\u8ba1\u7b97\u91cf\u5927\uff0c\u4e9f\u9700\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSDFA\u7b97\u6cd5\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u57fa\u4e8eRRAM-based IMC\u67b6\u6784\u8bbe\u8ba1\u4e09\u7ea7\u6d41\u6c34\u7ebf\u6570\u636e\u6d41\uff0c\u5e76\u884c\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "PipeSDFA\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e2%\uff0c\u8bad\u7ec3\u65f6\u95f4\u548c\u80fd\u8017\u5206\u522b\u6bd4PipeLayer\u51cf\u5c111.1X~10.5X\u548c1.37X~2.1X\u3002", "conclusion": "PipeSDFA\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684SNN\u8bad\u7ec3\uff0c\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u5e94\u7528\u3002"}}
{"id": "2507.14928", "pdf": "https://arxiv.org/pdf/2507.14928", "abs": "https://arxiv.org/abs/2507.14928", "authors": ["Yongrae Jo", "Chanik Park"], "title": "Byzantine-Robust Decentralized Coordination of LLM Agents", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Collaboration among multiple large language model (LLM) agents is a promising\napproach to overcome inherent limitations of single-agent systems, such as\nhallucinations and single points of failure. As LLM agents are increasingly\ndeployed on open blockchain platforms, multi-agent systems capable of\ntolerating malicious (Byzantine) agents have become essential.\n  Recent Byzantine-robust multi-agent systems typically rely on leader-driven\ncoordination, which suffers from two major drawbacks. First, they are\ninherently vulnerable to targeted attacks against the leader. If consecutive\nleaders behave maliciously, the system repeatedly fails to achieve consensus,\nforcing new consensus rounds, which is particularly costly given the high\nlatency of LLM invocations. Second, an underperforming proposal from the leader\ncan be accepted as the final answer even when higher-quality alternatives are\navailable, as existing methods finalize the leader's proposal once it receives\na quorum of votes.\n  To address these issues, we propose DecentLLMs, a novel decentralized\nconsensus approach for multi-agent LLM systems, where worker agents generate\nanswers concurrently and evaluator agents independently score and rank these\nanswers to select the best available one. This decentralized architecture\nenables faster consensus despite the presence of Byzantine agents and\nconsistently selects higher-quality answers through Byzantine-robust\naggregation techniques.\n  Experimental results demonstrate that DecentLLMs effectively tolerates\nByzantine agents and significantly improves the quality of selected answers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDecentLLMs\uff0c\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u591a\u4ee3\u7406LLM\u7cfb\u7edf\u5171\u8bc6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u57fa\u4e8e\u9886\u5bfc\u8005\u534f\u8c03\u7684\u8106\u5f31\u6027\u548c\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u514b\u670d\u5355\u4ee3\u7406\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff08\u5982\u5e7b\u89c9\u548c\u5355\u70b9\u6545\u969c\uff09\uff0c\u5e76\u89e3\u51b3\u73b0\u6709\u62dc\u5360\u5ead\u9c81\u68d2\u591a\u4ee3\u7406\u7cfb\u7edf\u56e0\u4f9d\u8d56\u9886\u5bfc\u8005\u800c\u5b58\u5728\u7684\u8106\u5f31\u6027\u548c\u4f4e\u6548\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u5de5\u4f5c\u4ee3\u7406\u5e76\u884c\u751f\u6210\u7b54\u6848\uff0c\u8bc4\u4f30\u4ee3\u7406\u72ec\u7acb\u8bc4\u5206\u548c\u6392\u5e8f\u4ee5\u9009\u62e9\u6700\u4f73\u7b54\u6848\uff0c\u7ed3\u5408\u62dc\u5360\u5ead\u9c81\u68d2\u805a\u5408\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDecentLLM\u80fd\u6709\u6548\u5bb9\u5fcd\u62dc\u5360\u5ead\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u5347\u6240\u9009\u7b54\u6848\u7684\u8d28\u91cf\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u7684DecentLLM\u4f18\u4e8e\u4f20\u7edf\u9886\u5bfc\u8005\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u66f4\u9ad8\u6548\u4e14\u9c81\u68d2\u3002"}}
{"id": "2507.14769", "pdf": "https://arxiv.org/pdf/2507.14769", "abs": "https://arxiv.org/abs/2507.14769", "authors": ["Ananya Gubbi Mohanbabu", "Yotam Sechayk", "Amy Pavel"], "title": "Task Mode: Dynamic Filtering for Task-Specific Web Navigation using LLMs", "categories": ["cs.HC"], "comment": "18 pages, 4 figures, 7 tables", "summary": "Modern web interfaces are unnecessarily complex to use as they overwhelm\nusers with excessive text and visuals unrelated to their current goals. This\nproblem particularly impacts screen reader users (SRUs), who navigate content\nsequentially and may spend minutes traversing irrelevant elements before\nreaching desired information compared to vision users (VUs) who visually skim\nin seconds. We present Task Mode, a system that dynamically filters web content\nbased on user-specified goals using large language models to identify and\nprioritize relevant elements while minimizing distractions. Our approach\npreserves page structure while offering multiple viewing modes tailored to\ndifferent access needs. Our user study with 12 participants (6 VUs, 6 SRUs)\ndemonstrates that our approach reduced task completion time for SRUs while\nmaintaining performance for VUs, decreasing the completion time gap between\ngroups from 2x to 1.2x. 11 of 12 participants wanted to use Task Mode in the\nfuture, reporting that Task Mode supported completing tasks with less effort\nand fewer distractions. This work demonstrates how designing new interactions\nsimultaneously for visual and non-visual access can reduce rather than\nreinforce accessibility disparities in future technology created by\nhuman-computer interaction researchers and practitioners.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTask Mode\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8fc7\u6ee4\u7f51\u9875\u5185\u5bb9\uff0c\u5e2e\u52a9\u5c4f\u5e55\u9605\u8bfb\u7528\u6237\uff08SRUs\uff09\u66f4\u9ad8\u6548\u5730\u5b8c\u6210\u4efb\u52a1\uff0c\u51cf\u5c11\u4e0e\u89c6\u89c9\u7528\u6237\uff08VUs\uff09\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u4ee3\u7f51\u9875\u754c\u9762\u8fc7\u4e8e\u590d\u6742\uff0c\u5bf9\u5c4f\u5e55\u9605\u8bfb\u7528\u6237\u9020\u6210\u4e0d\u5fc5\u8981\u7684\u8d1f\u62c5\uff0c\u5bfc\u81f4\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u663e\u8457\u957f\u4e8e\u89c6\u89c9\u7528\u6237\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u8fc7\u6ee4\u7f51\u9875\u5185\u5bb9\uff0c\u57fa\u4e8e\u7528\u6237\u76ee\u6807\u8bc6\u522b\u5e76\u4f18\u5148\u663e\u793a\u76f8\u5173\u5143\u7d20\uff0c\u540c\u65f6\u4fdd\u7559\u9875\u9762\u7ed3\u6784\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cTask Mode\u663e\u8457\u51cf\u5c11SRUs\u7684\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\uff0c\u5c06\u4e24\u7ec4\u5dee\u8ddd\u4ece2\u500d\u964d\u81f31.2\u500d\uff0c\u591a\u6570\u7528\u6237\u5e0c\u671b\u672a\u6765\u7ee7\u7eed\u4f7f\u7528\u3002", "conclusion": "\u901a\u8fc7\u4e3a\u89c6\u89c9\u548c\u975e\u89c6\u89c9\u7528\u6237\u540c\u65f6\u8bbe\u8ba1\u65b0\u4ea4\u4e92\u65b9\u5f0f\uff0c\u53ef\u4ee5\u51cf\u5c11\u6280\u672f\u4e2d\u7684\u65e0\u969c\u788d\u5dee\u5f02\u3002"}}
{"id": "2507.15230", "pdf": "https://arxiv.org/pdf/2507.15230", "abs": "https://arxiv.org/abs/2507.15230", "authors": ["Guoxi Liu", "Thomas Randall", "Rong Ge", "Federico Iuricich"], "title": "GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis", "categories": ["cs.DC", "cs.GR"], "comment": null, "summary": "Unstructured meshes present challenges in scientific data analysis due to\nirregular distribution and complex connectivity. Computing and storing\nconnectivity information is a major bottleneck for visualization algorithms,\naffecting both time and memory performance. Recent task-parallel data\nstructures address this by precomputing connectivity information at runtime\nwhile the analysis algorithm executes, effectively hiding computation costs and\nimproving performance. However, existing approaches are CPU-bound, forcing the\ndata structure and analysis algorithm to compete for the same computational\nresources, limiting potential speedups. To overcome this limitation, we\nintroduce a novel task-parallel approach optimized for heterogeneous CPU-GPU\nsystems. Specifically, we offload the computation of mesh connectivity\ninformation to GPU threads, enabling CPU threads to focus on executing the\nvisualization algorithm. Following this paradigm, we propose GALE (GPU-Aided\nLocalized data structurE), the first open-source CUDA-based data structure\ndesigned for heterogeneous task parallelism. Experiments on two 20-core CPUs\nand an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over\nstate-of-the-art localized data structures while maintaining memory efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u975e\u7ed3\u6784\u5316\u7f51\u683c\u7684\u5f02\u6784CPU-GPU\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7f51\u683c\u8fde\u901a\u6027\u8ba1\u7b97\u5378\u8f7d\u5230GPU\u7ebf\u7a0b\uff0c\u63d0\u5347\u53ef\u89c6\u5316\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4efb\u52a1\u5e76\u884c\u6570\u636e\u7ed3\u6784\u53d7\u9650\u4e8eCPU\u8d44\u6e90\uff0c\u5bfc\u81f4\u6570\u636e\u7ed3\u6784\u548c\u5206\u6790\u7b97\u6cd5\u7ade\u4e89\u8ba1\u7b97\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5f02\u6784CPU-GPU\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5\uff0c\u5c06\u7f51\u683c\u8fde\u901a\u6027\u8ba1\u7b97\u5378\u8f7d\u5230GPU\u7ebf\u7a0b\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u9996\u4e2a\u5f00\u6e90\u7684CUDA-based\u6570\u636e\u7ed3\u6784GALE\u3002", "result": "\u572820\u6838CPU\u548cNVIDIA V100 GPU\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGALE\u6bd4\u73b0\u6709\u6280\u672f\u5feb2.7\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u5185\u5b58\u6548\u7387\u3002", "conclusion": "GALE\u901a\u8fc7\u5f02\u6784\u4efb\u52a1\u5e76\u884c\u663e\u8457\u63d0\u5347\u4e86\u975e\u7ed3\u6784\u5316\u7f51\u683c\u7684\u53ef\u89c6\u5316\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.14594", "pdf": "https://arxiv.org/pdf/2507.14594", "abs": "https://arxiv.org/abs/2507.14594", "authors": ["Weiwei Xu", "Hengzhi Ye", "Kai Gao", "Minghui Zhou"], "title": "A first look at License Variants in the PyPI Ecosystem", "categories": ["cs.SE"], "comment": null, "summary": "Open-source licenses establish the legal foundation for software reuse, yet\nlicense variants, including both modified standard licenses and custom-created\nalternatives, introduce significant compliance complexities. Despite their\nprevalence and potential impact, these variants are poorly understood in modern\nsoftware systems, and existing tools do not account for their existence,\nleading to significant challenges in both effectiveness and efficiency of\nlicense analysis. To fill this knowledge gap, we conduct a comprehensive\nempirical study of license variants in the PyPI ecosystem. Our findings show\nthat textual variations in licenses are common, yet only 2% involve substantive\nmodifications. However, these license variants lead to significant compliance\nissues, with 10.7% of their downstream dependencies found to be\nlicense-incompatible.\n  Inspired by our findings, we introduce LV-Parser, a novel approach for\nefficient license variant analysis leveraging diff-based techniques and large\nlanguage models, along with LV-Compat, an automated pipeline for detecting\nlicense incompatibilities in software dependency networks. Our evaluation\ndemonstrates that LV-Parser achieves an accuracy of 0.936 while reducing\ncomputational costs by 30%, and LV-Compat identifies 5.2 times more\nincompatible packages than existing methods with a precision of 0.98.\n  This work not only provides the first empirical study into license variants\nin software packaging ecosystem but also equips developers and organizations\nwith practical tools for navigating the complex landscape of open-source\nlicensing.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f00\u6e90\u8bb8\u53ef\u8bc1\u53d8\u4f53\u5728PyPI\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6587\u672c\u53d8\u4f53\u867d\u5e38\u89c1\u4f46\u5b9e\u8d28\u6027\u4fee\u6539\u4ec5\u53602%\uff0c\u4f46\u5bfc\u81f4\u4e86\u663e\u8457\u7684\u5408\u89c4\u95ee\u9898\u3002\u4f5c\u8005\u63d0\u51fa\u4e86LV-Parser\u548cLV-Compat\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u6790\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5f00\u6e90\u8bb8\u53ef\u8bc1\u53d8\u4f53\u5728\u8f6f\u4ef6\u91cd\u7528\u4e2d\u5f15\u5165\u4e86\u5408\u89c4\u590d\u6742\u6027\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u7814\u7a76\u5e76\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790PyPI\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u8bb8\u53ef\u8bc1\u53d8\u4f53\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u5dee\u5f02\u5206\u6790\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684LV-Parser\uff0c\u4ee5\u53ca\u81ea\u52a8\u68c0\u6d4b\u8bb8\u53ef\u8bc1\u4e0d\u517c\u5bb9\u6027\u7684LV-Compat\u5de5\u5177\u3002", "result": "\u7814\u7a76\u53d1\u73b010.7%\u7684\u4e0b\u6e38\u4f9d\u8d56\u5b58\u5728\u8bb8\u53ef\u8bc1\u4e0d\u517c\u5bb9\u95ee\u9898\u3002LV-Parser\u51c6\u786e\u7387\u8fbe0.936\uff0c\u964d\u4f4e\u4e8630%\u8ba1\u7b97\u6210\u672c\uff1bLV-Compat\u8bc6\u522b\u80fd\u529b\u63d0\u53475.2\u500d\uff0c\u7cbe\u5ea6\u4e3a0.98\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86\u8bb8\u53ef\u8bc1\u53d8\u4f53\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\u4ee5\u5e94\u5bf9\u5f00\u6e90\u8bb8\u53ef\u8bc1\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2507.15843", "pdf": "https://arxiv.org/pdf/2507.15843", "abs": "https://arxiv.org/abs/2507.15843", "authors": ["Beniamino Accattoli", "Dan Ghica", "Giulio Guerrieri", "Cl\u00e1udio Belo Louren\u00e7o", "Claudio Sacerdoti Coen"], "title": "Closure Conversion, Flat Environments, and the Complexity of Abstract Machines", "categories": ["cs.PL", "D.3.1; F.3.1; F.3.2; D.2.4"], "comment": null, "summary": "Closure conversion is a program transformation at work in compilers for\nfunctional languages to turn inner functions into global ones, by building\nclosures pairing the transformed functions with the environment of their free\nvariables. Abstract machines rely on similar and yet different concepts of\nclosures and environments.\n  In this paper, we study the relationship between the two approaches. We adopt\na very simple {\\lambda}-calculus with tuples as source language and study\nabstract machines for both the source language and the target of closure\nconversion. Moreover, we focus on the simple case of flat\nclosures/environments, that is, with no sharing of environments. We provide\nthree contributions.\n  Firstly, a new simple proof technique for the correctness of closure\nconversion, inspired by abstract machines.\n  Secondly, we show how the closure invariants of the target language allow us\nto design a new way of handling environments in abstract machines, not\nsuffering the shortcomings of other styles.\n  Thirdly, we study the machines from the point of view of time complexity,\nadapting analyses by Accattoli and co-authors. We show that closure conversion\ndecreases various dynamic costs while increasing the size of the initial code.\nDespite these changes, the overall complexity of the machines before and after\nclosure conversion turns out to be the same.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u95ed\u5305\u8f6c\u6362\u4e0e\u62bd\u8c61\u673a\u5668\u4e2d\u95ed\u5305\u548c\u73af\u5883\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u95ed\u5305\u8f6c\u6362\u6b63\u786e\u6027\u8bc1\u660e\u6280\u672f\uff0c\u6539\u8fdb\u4e86\u62bd\u8c61\u673a\u5668\u4e2d\u73af\u5883\u5904\u7406\u7684\u65b9\u5f0f\uff0c\u5e76\u5206\u6790\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u53d8\u5316\u3002", "motivation": "\u63a2\u8ba8\u95ed\u5305\u8f6c\u6362\u4e0e\u62bd\u8c61\u673a\u5668\u4e2d\u95ed\u5305\u548c\u73af\u5883\u7684\u5f02\u540c\uff0c\u5e76\u901a\u8fc7\u7814\u7a76\u5176\u5728\u7b80\u5355\u03bb-\u6f14\u7b97\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5e26\u5143\u7ec4\u7684\u7b80\u5355\u03bb-\u6f14\u7b97\u4f5c\u4e3a\u6e90\u8bed\u8a00\uff0c\u8bbe\u8ba1\u5e76\u5206\u6790\u6e90\u8bed\u8a00\u548c\u76ee\u6807\u8bed\u8a00\u4e2d\u7684\u62bd\u8c61\u673a\u5668\uff0c\u91cd\u70b9\u7814\u7a76\u5e73\u9762\u95ed\u5305/\u73af\u5883\u7684\u60c5\u51b5\u3002", "result": "\u63d0\u51fa\u65b0\u7684\u95ed\u5305\u8f6c\u6362\u6b63\u786e\u6027\u8bc1\u660e\u65b9\u6cd5\uff0c\u6539\u8fdb\u73af\u5883\u5904\u7406\u65b9\u5f0f\uff0c\u5e76\u8bc1\u660e\u95ed\u5305\u8f6c\u6362\u867d\u6539\u53d8\u52a8\u6001\u6210\u672c\u548c\u521d\u59cb\u4ee3\u7801\u5927\u5c0f\uff0c\u4f46\u6574\u4f53\u590d\u6742\u5ea6\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "\u95ed\u5305\u8f6c\u6362\u4e0e\u62bd\u8c61\u673a\u5668\u4e2d\u7684\u73af\u5883\u5904\u7406\u53ef\u4ee5\u7ed3\u5408\uff0c\u5f62\u6210\u66f4\u9ad8\u6548\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u540c\u65f6\u4fdd\u6301\u65f6\u95f4\u590d\u6742\u5ea6\u4e0d\u53d8\u3002"}}
{"id": "2507.14230", "pdf": "https://arxiv.org/pdf/2507.14230", "abs": "https://arxiv.org/abs/2507.14230", "authors": ["Fransiscus Asisi Bimo", "Maria Amparo Canaveras Galdon", "Chun-Kai Lai", "Ray-Guang Cheng", "Edwin K. P. Chong"], "title": "Intent-Based Network for RAN Management with Large Language Models", "categories": ["cs.NI", "cs.AI"], "comment": "5 pages, 3 figures, submitted to IEEE Globecom 2025", "summary": "Advanced intelligent automation becomes an important feature to deal with the\nincreased complexity in managing wireless networks. This paper proposes a novel\nautomation approach of intent-based network for Radio Access Networks (RANs)\nmanagement by leveraging Large Language Models (LLMs). The proposed method\nenhances intent translation, autonomously interpreting high-level objectives,\nreasoning over complex network states, and generating precise configurations of\nthe RAN by integrating LLMs within an agentic architecture. We propose a\nstructured prompt engineering technique and demonstrate that the network can\nautomatically improve its energy efficiency by dynamically optimizing critical\nRAN parameters through a closed-loop mechanism. It showcases the potential to\nenable robust resource management in RAN by adapting strategies based on\nreal-time feedback via LLM-orchestrated agentic systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u610f\u56fe\u7f51\u7edc\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u7ba1\u7406\uff0c\u901a\u8fc7\u667a\u80fd\u95ed\u73af\u673a\u5236\u63d0\u9ad8\u80fd\u6548\u3002", "motivation": "\u9762\u5bf9\u65e0\u7ebf\u7f51\u7edc\u7ba1\u7406\u7684\u590d\u6742\u6027\uff0c\u5229\u7528LLM\u5b9e\u73b0\u610f\u56fe\u7ffb\u8bd1\u548c\u81ea\u52a8\u5316\u914d\u7f6e\u662f\u4e00\u79cd\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u548c\u5b9e\u65f6\u53cd\u9988\u95ed\u73af\u673a\u5236\u4f18\u5316RAN\u53c2\u6570\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u52a8\u6001\u4f18\u5316\u7f51\u7edc\u80fd\u6548\uff0c\u5c55\u793a\u51fa\u5728RAN\u8d44\u6e90\u7ba1\u7406\u4e2d\u9002\u5e94\u5b9e\u65f6\u53d8\u5316\u7684\u80fd\u529b\u3002", "conclusion": "LLM\u548c\u4ee3\u7406\u67b6\u6784\u7684\u7ed3\u5408\u4e3a\u65e0\u7ebf\u7f51\u7edc\u81ea\u52a8\u5316\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.15066", "pdf": "https://arxiv.org/pdf/2507.15066", "abs": "https://arxiv.org/abs/2507.15066", "authors": ["Yiyuan Yang", "Zichuan Liu", "Lei Song", "Kai Ying", "Zhiguang Wang", "Tom Bamford", "Svitlana Vyetrenko", "Jiang Bian", "Qingsong Wen"], "title": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "categories": ["cs.LG", "cs.AI", "cs.MM"], "comment": "Under review. 19 pages, 8 figures, 12 tables", "summary": "Time series anomaly detection is critical across various domains, yet current\napproaches often limit analysis to mere binary anomaly classification without\ndetailed categorization or further explanatory reasoning. To address these\nlimitations, we propose a novel task, Time-series Reasoning for Anomaly\n(Time-RA) that transforms classical time series anomaly detection from a\ndiscriminative into a generative, reasoning-intensive task leveraging Large\nLanguage Models (LLMs). Also, we introduce the first real-world multimodal\nbenchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,\ncomprising approximately 40,000 samples across 10 real-world domains. Each\nsample includes numeric time series data, contextual text information, and\nvisual representations, each annotated with fine-grained categories (14 types\nfor univariate anomalies and 6 for multivariate anomalies) and structured\nexplanatory reasoning. We develop a sophisticated annotation framework\nutilizing ensemble-generated labels refined through GPT-4-driven feedback,\nensuring accuracy and interpretability. Extensive benchmarking of LLMs and\nmultimodal LLMs demonstrates the capabilities and limitations of current\nmodels, highlighting the critical role of supervised fine-tuning. Our dataset\nand task pave the way for significant advancements in interpretable time series\nanomaly detection and reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4efb\u52a1Time-RA\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4ece\u5224\u522b\u5f0f\u4efb\u52a1\u8f6c\u4e3a\u751f\u6210\u5f0f\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6RATs40K\uff0c\u5305\u542b40,000\u4e2a\u6837\u672c\uff0c\u7528\u4e8e\u5f02\u5e38\u63a8\u7406\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\u51f8\u663e\u4e86\u76d1\u7763\u5fae\u8c03\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u4ec5\u8fdb\u884c\u4e8c\u8fdb\u5236\u5f02\u5e38\u5206\u7c7b\uff0c\u7f3a\u4e4f\u8be6\u7ec6\u5206\u7c7b\u548c\u89e3\u91ca\u63a8\u7406\u3002Time-RA\u4efb\u52a1\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u5347\u5f02\u5e38\u68c0\u6d4b\u7684\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faTime-RA\u4efb\u52a1\uff0c\u5c06\u5f02\u5e38\u68c0\u6d4b\u8f6c\u4e3a\u751f\u6210\u5f0f\u4efb\u52a1\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u3002\u5f15\u5165RATs40K\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u6a21\u6001\u6570\u636e\uff08\u65f6\u95f4\u5e8f\u5217\u3001\u6587\u672c\u3001\u89c6\u89c9\uff09\u548c\u7cbe\u7ec6\u6807\u6ce8\uff0814\u79cd\u5355\u53d8\u91cf\u5f02\u5e38\u548c6\u79cd\u591a\u53d8\u91cf\u5f02\u5e38\uff09\u3002\u91c7\u7528GPT-4\u53cd\u9988\u4f18\u5316\u7684\u6807\u6ce8\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728Time-RA\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u76d1\u7763\u5fae\u8c03\u7684\u91cd\u8981\u6027\u3002", "conclusion": "Time-RA\u4efb\u52a1\u548cRATs40K\u6570\u636e\u96c6\u4e3a\u53ef\u89e3\u91ca\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u548c\u63a8\u7406\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.15420", "pdf": "https://arxiv.org/pdf/2507.15420", "abs": "https://arxiv.org/abs/2507.15420", "authors": ["Robert David", "Albin Ahmeti", "Geni Bushati", "Amar Tauqeer", "Anna Fensel"], "title": "A SHACL-based Data Consistency Solution for Contract Compliance Verification", "categories": ["cs.LO", "E.1; F.4.1; I.2.4; K.5.1"], "comment": "Extended version of the short paper published at OPAL workshop (ESWC\n  2025 Workshops and Tutorials Joint Proceedings). See\n  https://ceur-ws.org/Vol-3977/OPAL2025-1.pdf", "summary": "In recent years, there have been many developments for GDPR-compliant data\naccess and sharing based on consent. For more complex data sharing scenarios,\nwhere consent might not be sufficient, many parties rely on contracts. Before a\ncontract is signed, it must undergo the process of contract negotiation within\nthe contract lifecycle, which consists of negotiating the obligations\nassociated with the contract. Contract compliance verification (CCV) provides a\nmeans to verify whether a contract is GDPR-compliant, i.e., adheres to legal\nobligations and there are no violations. The rise of knowledge graph (KG)\nadoption, enabling semantic interoperability using well-defined semantics,\nallows CCV to be applied on KGs. In the scenario of different participants\nnegotiating obligations, there is a need for data consistency to ensure that\nCCV is done correctly. Recent work introduced the automated contracting tool\n(ACT), a KG-based and ODRL-employing tool for GDPR CCV, which was developed in\nthe Horizon 2020 project smashHit (https://smashhit.eu). Although the tool\nreports violations with respect to obligations, it had limitations in verifying\nand ensuring compliance, as it did not use an interoperable semantic formalism,\nsuch as SHACL, and did not support users in resolving data inconsistencies. In\nthis work, we propose a novel approach to overcome these limitations of ACT. We\nsemi-automatically resolve CCV inconsistencies by providing repair strategies,\nwhich automatically propose (optimal) solutions to the user to re-establish\ndata consistency and thereby support them in managing GDPR-compliant contract\nlifecycle data. We have implemented the approach, integrated it into ACT and\ntested its correctness and performance against basic CCV consistency\nrequirements.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u4fee\u590d\u5408\u540c\u5408\u89c4\u6027\u9a8c\u8bc1\uff08CCV\uff09\u4e2d\u7684\u6570\u636e\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u4f9b\u4fee\u590d\u7b56\u7565\u5e76\u96c6\u6210\u5230\u73b0\u6709\u7684\u81ea\u52a8\u5316\u5408\u540c\u5de5\u5177\uff08ACT\uff09\u4e2d\uff0c\u4ee5\u652f\u6301GDPR\u5408\u89c4\u7684\u5408\u540c\u751f\u547d\u5468\u671f\u7ba1\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316\u5408\u540c\u5de5\u5177\uff08ACT\uff09\u867d\u7136\u80fd\u62a5\u544a\u5408\u540c\u4e49\u52a1\u7684\u8fdd\u89c4\u60c5\u51b5\uff0c\u4f46\u5728\u9a8c\u8bc1\u548c\u786e\u4fdd\u5408\u89c4\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u7f3a\u4e4f\u4e92\u64cd\u4f5c\u7684\u8bed\u4e49\u5f62\u5f0f\u5316\u65b9\u6cd5\uff08\u5982SHACL\uff09\u548c\u7528\u6237\u652f\u6301\u89e3\u51b3\u6570\u636e\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u534a\u81ea\u52a8\u5316\u65b9\u5f0f\u89e3\u51b3CCV\u7684\u6570\u636e\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u4fee\u590d\u7b56\u7565\u5e76\u63d0\u51fa\u6700\u4f18\u89e3\u51b3\u65b9\u6848\uff0c\u5e2e\u52a9\u7528\u6237\u91cd\u65b0\u5efa\u7acb\u6570\u636e\u4e00\u81f4\u6027\u3002", "result": "\u65b9\u6cd5\u5df2\u5b9e\u73b0\u5e76\u96c6\u6210\u5230ACT\u4e2d\uff0c\u6d4b\u8bd5\u8868\u660e\u5176\u80fd\u6ee1\u8db3\u57fa\u672c\u7684CCV\u4e00\u81f4\u6027\u8981\u6c42\u3002", "conclusion": "\u7814\u7a76\u901a\u8fc7\u4fee\u590d\u7b56\u7565\u548c\u534a\u81ea\u52a8\u5316\u65b9\u6cd5\u6539\u8fdb\u4e86ACT\u5de5\u5177\uff0c\u63d0\u9ad8\u4e86GDPR\u5408\u89c4\u5408\u540c\u751f\u547d\u5468\u671f\u7ba1\u7406\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.15336", "pdf": "https://arxiv.org/pdf/2507.15336", "abs": "https://arxiv.org/abs/2507.15336", "authors": ["Jialiang Wang", "Hanmo Liu", "Shimin Di", "Zhili Wang", "Jiachuan Wang", "Lei Chen", "Xiaofang Zhou"], "title": "Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "Database systems have recently advocated for embedding machine learning (ML)\ncapabilities, offering declarative model queries over large, managed model\nrepositories, thereby circumventing the huge computational overhead of\ntraditional ML-based algorithms in automated neural network model selection.\nPioneering database studies aim to organize existing benchmark repositories as\nmodel bases (MB), querying them for the model records with the highest\nperformance estimation metrics for given tasks. However, this static model\nselection practice overlooks the fine-grained, evolving relational dependencies\nbetween diverse task queries and model architecture variations, resulting in\nsuboptimal matches and failing to further refine the model effectively. To fill\nthe model refinement gap in database research, we propose M-DESIGN, a curated\nmodel knowledge base (MKB) pipeline for mastering neural network refinement by\nadaptively weaving prior insights about model architecture modification. First,\nwe propose a knowledge weaving engine that reframes model refinement as an\nadaptive query problem over task metadata. Given a user's task query, M-DESIGN\nquickly matches and iteratively refines candidate models by leveraging a\ngraph-relational knowledge schema that explicitly encodes data properties,\narchitecture variations, and pairwise performance deltas as joinable relations.\nThis schema supports fine-grained relational analytics over architecture tweaks\nand drives a predictive query planner that can detect and adapt to\nout-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics\ntasks, where our model knowledge base enriches existing benchmarks with\nstructured metadata covering 3 graph tasks and 22 graph datasets, contributing\ndata records of 67,760 graph models. Empirical results demonstrate that\nM-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited\nbudgets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86M-DESIGN\uff0c\u4e00\u79cd\u901a\u8fc7\u5b66\u4e60\u6a21\u578b\u67b6\u6784\u4fee\u6539\u7684\u5148\u9a8c\u77e5\u8bc6\u6765\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u6d41\u6c34\u7ebf\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5e93\u7814\u7a76\u4e2d\u6a21\u578b\u9009\u62e9\u7684\u9759\u6001\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u5ffd\u7565\u4e86\u4efb\u52a1\u67e5\u8be2\u4e0e\u6a21\u578b\u67b6\u6784\u4e4b\u95f4\u7684\u52a8\u6001\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u5339\u914d\u4e0d\u4f18\u4e14\u65e0\u6cd5\u6709\u6548\u4f18\u5316\u6a21\u578b\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0cM-DESIGN\u88ab\u8bbe\u8ba1\u51fa\u6765\u3002", "method": "M-DESIGN\u901a\u8fc7\u77e5\u8bc6\u7f16\u7ec7\u5f15\u64ce\u5c06\u6a21\u578b\u4f18\u5316\u8f6c\u5316\u4e3a\u5bf9\u4efb\u52a1\u5143\u6570\u636e\u7684\u81ea\u9002\u5e94\u67e5\u8be2\u95ee\u9898\uff0c\u5229\u7528\u56fe\u5173\u7cfb\u77e5\u8bc6\u6a21\u5f0f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\u5e76\u9884\u6d4bOOD\u4efb\u52a1\u3002", "result": "\u5728\u56fe\u5f62\u5206\u6790\u4efb\u52a1\u4e2d\uff0cM-DESIGN\u572867,760\u4e2a\u6a21\u578b\u8bb0\u5f55\u4e2d\uff0c33\u4e2a\u6570\u636e\u4efb\u52a1\u5bf9\u4e2d\u670926\u4e2a\u5728\u6709\u9650\u9884\u7b97\u5185\u627e\u5230\u4e86\u6700\u4f18\u6a21\u578b\u3002", "conclusion": "M-DESIGN\u901a\u8fc7\u52a8\u6001\u5173\u7cfb\u5206\u6790\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u9009\u62e9\u4e0e\u4f18\u5316\u7684\u6548\u679c\uff0c\u5c24\u5176\u5728\u5904\u7406\u5f02\u6784\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.15063", "pdf": "https://arxiv.org/pdf/2507.15063", "abs": "https://arxiv.org/abs/2507.15063", "authors": ["Chloe Pomeroy", "Aleksandar Pramov", "Karishma Thakrar", "Lakshmi Yendapalli"], "title": "Quantum Annealing for Machine Learning: Applications in Feature Selection, Instance Selection, and Clustering", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": null, "summary": "This paper explores the applications of quantum annealing (QA) and classical\nsimulated annealing (SA) to a suite of combinatorial optimization problems in\nmachine learning, namely feature selection, instance selection, and clustering.\nWe formulate each task as a Quadratic Unconstrained Binary Optimization (QUBO)\nproblem and implement both quantum and classical solvers to compare their\neffectiveness. For feature selection, we propose several QUBO configurations\nthat balance feature importance and redundancy, showing that quantum annealing\n(QA) produces solutions that are computationally more efficient. In instance\nselection, we propose a few novel heuristics for instance-level importance\nmeasures that extend existing methods. For clustering, we embed a\nclassical-to-quantum pipeline, using classical clustering followed by\nQUBO-based medoid refinement, and demonstrate consistent improvements in\ncluster compactness and retrieval metrics. Our results suggest that QA can be a\ncompetitive and efficient tool for discrete machine learning optimization, even\nwithin the constraints of current quantum hardware.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u548c\u7ecf\u5178\u6a21\u62df\u9000\u706b\uff08SA\uff09\u5728\u673a\u5668\u5b66\u4e60\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5173\u6ce8\u7279\u5f81\u9009\u62e9\u3001\u5b9e\u4f8b\u9009\u62e9\u548c\u805a\u7c7b\u4efb\u52a1\uff0c\u8868\u660eQA\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u63a2\u7d22\u91cf\u5b50\u9000\u706b\u548c\u7ecf\u5178\u6a21\u62df\u9000\u706b\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff08\u5982\u7279\u5f81\u9009\u62e9\u3001\u5b9e\u4f8b\u9009\u62e9\u548c\u805a\u7c7b\uff09\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u6bd4\u8f83\u4e24\u8005\u7684\u6548\u679c\u3002", "method": "\u5c06\u6bcf\u4e2a\u4efb\u52a1\u5efa\u6a21\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\uff08QUBO\uff09\u95ee\u9898\uff0c\u5206\u522b\u5b9e\u73b0\u91cf\u5b50\u9000\u706b\u548c\u7ecf\u5178\u6a21\u62df\u9000\u706b\u6c42\u89e3\u5668\u3002\u5728\u7279\u5f81\u9009\u62e9\u4e2d\u8bbe\u8ba1\u4e86\u5e73\u8861\u7279\u5f81\u91cd\u8981\u6027\u548c\u5197\u4f59\u6027\u7684QUBO\u914d\u7f6e\uff1b\u5728\u5b9e\u4f8b\u9009\u62e9\u4e2d\u63d0\u51fa\u4e86\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1b\u5728\u805a\u7c7b\u4e2d\u7ed3\u5408\u4e86\u7ecf\u5178\u805a\u7c7b\u548cQUBO\u4f18\u5316\u7684\u6d41\u7a0b\u3002", "result": "\u91cf\u5b50\u9000\u706b\u5728\u7279\u5f81\u9009\u62e9\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u5b9e\u4f8b\u9009\u62e9\u548c\u805a\u7c7b\u4e2d\u63d0\u51fa\u4e86\u65b0\u65b9\u6cd5\u5e76\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff08\u5982\u805a\u7c7b\u7d27\u51d1\u6027\u548c\u68c0\u7d22\u6307\u6807\uff09\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5728\u5f53\u524d\u91cf\u5b50\u786c\u4ef6\u7684\u9650\u5236\u4e0b\uff0c\u91cf\u5b50\u9000\u706b\u4ecd\u662f\u79bb\u6563\u673a\u5668\u5b66\u4e60\u4f18\u5316\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u548c\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2507.15664", "pdf": "https://arxiv.org/pdf/2507.15664", "abs": "https://arxiv.org/abs/2507.15664", "authors": ["Haomin Qi", "Yuyang Du", "Lihao Zhang", "Soung Chang Liew", "Kexin Chen", "Yining Du"], "title": "VeriRAG: A Retrieval-Augmented Framework for Automated RTL Testability Repair", "categories": ["cs.AR"], "comment": "8 pages, 5 figures", "summary": "Large language models (LLMs) have demonstrated immense potential in\ncomputer-aided design (CAD), particularly for automated debugging and\nverification within electronic design automation (EDA) tools. However, Design\nfor Testability (DFT) remains a relatively underexplored area. This paper\npresents VeriRAG, the first LLM-assisted DFT-EDA framework. VeriRAG leverages a\nRetrieval-Augmented Generation (RAG) approach to enable LLM to revise code to\nensure DFT compliance. VeriRAG integrates (1) an autoencoder-based similarity\nmeasurement model for precise retrieval of reference RTL designs for the LLM,\nand (2) an iterative code revision pipeline that allows the LLM to ensure DFT\ncompliance while maintaining synthesizability. To support VeriRAG, we introduce\nVeriDFT, a Verilog-based DFT dataset curated for DFT-aware RTL repairs. VeriRAG\nretrieves structurally similar RTL designs from VeriDFT, each paired with a\nrigorously validated correction, as references for code repair. With VeriRAG\nand VeriDFT, we achieve fully automated DFT correction -- resulting in a\n7.72-fold improvement in successful repair rate compared to the zero-shot\nbaseline (Fig. 5 in Section V). Ablation studies further confirm the\ncontribution of each component of the VeriRAG framework. We open-source our\ndata, models, and scripts at https://github.com/yuyangdu01/LLM4DFT.", "AI": {"tldr": "\u63d0\u51fa\u4e86VeriRAG\uff0c\u7b2c\u4e00\u4e2a\u57fa\u4e8eLLM\u7684DFT-EDA\u6846\u67b6\uff0c\u901a\u8fc7RAG\u65b9\u6cd5\u5b9e\u73b0\u81ea\u52a8\u5316DFT\u5408\u89c4\u6027\u4fee\u590d\uff0c\u5e76\u5f00\u6e90\u4e86VeriDFT\u6570\u636e\u96c6\u3002", "motivation": "\u5f53\u524dLLM\u5728CAD\u4e2d\u7684\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46DFT\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u8c03\u8bd5\u548c\u9a8c\u8bc1\u5de5\u5177\u3002", "method": "\u91c7\u7528RAG\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u52a8\u7f16\u7801\u5668\u68c0\u7d22\u76f8\u4f3cRTL\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u4ee3\u7801\u4fee\u8ba2\u786e\u4fddDFT\u5408\u89c4\u6027\u3002", "result": "\u5b9e\u73b0\u4e867.72\u500d\u7684\u4fee\u590d\u6210\u529f\u7387\u63d0\u5347\uff0c\u5e76\u5f00\u6e90\u4e86\u6570\u636e\u96c6\u548c\u6a21\u578b\u3002", "conclusion": "VeriRAG\u4e3aDFT-EDA\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15121", "pdf": "https://arxiv.org/pdf/2507.15121", "abs": "https://arxiv.org/abs/2507.15121", "authors": ["Sasindu Wijeratne", "Rajgopal Kannan", "Viktor Prasanna"], "title": "AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs", "categories": ["cs.DC"], "comment": null, "summary": "Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the computational\nbottleneck in sparse tensor decomposition. As real-world sparse tensors grow to\nbillions of nonzeros, they increasingly demand higher memory capacity and\ncompute throughput from hardware accelerators. In this work, we present AMPED,\na multi-GPU parallel algorithm designed to accelerate MTTKRP on billion-scale\nsparse tensors. AMPED scales beyond the limits of a single GPU, meeting both\nthe memory and performance requirements of large-scale workloads. We introduce\na partitioning strategy combined with a dynamic load balancing scheme to\ndistribute computation and minimize GPU idle time. On real-world billion-scale\ntensors, AMPED achieves a 5.1x geometric mean speedup in total execution time\nover state-of-the-art GPU baselines using 4 GPUs on a single CPU node.", "AI": {"tldr": "AMPED\u662f\u4e00\u79cd\u591aGPU\u5e76\u884c\u7b97\u6cd5\uff0c\u7528\u4e8e\u52a0\u901f\u5927\u89c4\u6a21\u7a00\u758f\u5f20\u91cf\u5206\u89e3\u4e2d\u7684MTTKRP\u8ba1\u7b97\uff0c\u901a\u8fc7\u5206\u533a\u548c\u52a8\u6001\u8d1f\u8f7d\u5e73\u8861\u6280\u672f\uff0c\u57284\u4e2aGPU\u4e0a\u5b9e\u73b0\u4e865.1\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u7531\u4e8e\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7a00\u758f\u5f20\u91cf\u89c4\u6a21\u589e\u957f\u5230\u6570\u5341\u4ebf\u975e\u96f6\u503c\uff0c\u4f20\u7edf\u7684\u5355GPU\u65b9\u6cd5\u5728\u5185\u5b58\u548c\u8ba1\u7b97\u541e\u5410\u91cf\u4e0a\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u9700\u8981\u591aGPU\u5e76\u884c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAMPED\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u533a\u7b56\u7565\u548c\u52a8\u6001\u8d1f\u8f7d\u5e73\u8861\u65b9\u6848\u5728\u591aGPU\u95f4\u5206\u914d\u8ba1\u7b97\uff0c\u51cf\u5c11GPU\u7a7a\u95f2\u65f6\u95f4\u3002", "result": "\u57284\u4e2aGPU\u4e0a\uff0cAMPED\u6bd4\u73b0\u6709GPU\u57fa\u7ebf\u65b9\u6cd5\u5feb5.1\u500d\u3002", "conclusion": "AMPED\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u7a00\u758f\u5f20\u91cf\u5206\u89e3\u4e2dMTTKRP\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.14792", "pdf": "https://arxiv.org/pdf/2507.14792", "abs": "https://arxiv.org/abs/2507.14792", "authors": ["Kaixin Ji", "Danula Hettiachchi", "Falk Scholer", "Flora D. Salim", "Damiano Spina"], "title": "SenseSeek Dataset: Multimodal Sensing to Study Information Seeking Behaviors", "categories": ["cs.HC"], "comment": "Accepted in Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies (IMWUT), September 2025", "summary": "Information processing tasks involve complex cognitive mechanisms that are\nshaped by various factors, including individual goals, prior experience, and\nsystem environments. Understanding such behaviors requires a sophisticated and\npersonalized data capture of how one interacts with modern information systems\n(e.g., web search engines). Passive sensors, such as wearables, capturing\nphysiological and behavioral data, have the potential to provide solutions in\nthis context. This paper presents a novel dataset, SenseSeek, designed to\nevaluate the effectiveness of consumer-grade sensors in a complex information\nprocessing scenario: searching via systems (e.g., search engines), one of the\ncommon strategies users employ for information seeking. The SenseSeek dataset\ncomprises data collected from 20 participants, 235 trials of the stimulated\nsearch process, 940 phases of stages in the search process, including the\nrealization of Information Need (IN), Query Formulation (QF), Query Submission\nby Typing (QS-T) or Speaking (QS-S), and Relevance Judgment by Reading (RJ-R)\nor Listening (RJ-L). The data includes Electrodermal Activities (EDA),\nElectroencephalogram (EEG), PUPIL, GAZE, and MOTION data, which were captured\nusing consumer-grade sensors. It also contains 258 features extracted from the\nsensor data, the gaze-annotated screen recordings, and task responses. We\nvalidate the usefulness of the dataset by providing baseline analysis on the\nimpacts of different cognitive intents and interaction modalities on the sensor\ndata, and effectiveness of the data in discriminating the search stages. To our\nknowledge, SenseSeek is the first dataset that characterizes the multiple\nstages involved in information seeking with physiological signals collected\nfrom multiple sensors. We hope this dataset can serve as a reference for future\nresearch on information-seeking behaviors.", "AI": {"tldr": "SenseSeek\u6570\u636e\u96c6\u5229\u7528\u6d88\u8d39\u7ea7\u4f20\u611f\u5668\u6355\u6349\u591a\u9636\u6bb5\u4fe1\u606f\u641c\u7d22\u884c\u4e3a\u4e2d\u7684\u751f\u7406\u548c\u884c\u4e3a\u6570\u636e\uff0c\u4e3a\u7814\u7a76\u4fe1\u606f\u5bfb\u6c42\u884c\u4e3a\u63d0\u4f9b\u65b0\u5de5\u5177\u3002", "motivation": "\u7406\u89e3\u590d\u6742\u4fe1\u606f\u5904\u7406\u884c\u4e3a\u9700\u8981\u4e2a\u6027\u5316\u6570\u636e\u6355\u6349\uff0c\u6d88\u8d39\u7ea7\u4f20\u611f\u5668\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6536\u96c620\u540d\u53c2\u4e0e\u8005\u5728235\u6b21\u641c\u7d22\u8bd5\u9a8c\u4e2d\u7684\u591a\u9636\u6bb5\u6570\u636e\uff0c\u5305\u62ecEDA\u3001EEG\u3001PUPIL\u7b49\u4f20\u611f\u5668\u6570\u636e\u53ca258\u4e2a\u7279\u5f81\u3002", "result": "\u9a8c\u8bc1\u6570\u636e\u96c6\u5bf9\u4e0d\u540c\u8ba4\u77e5\u610f\u56fe\u548c\u4ea4\u4e92\u6a21\u6001\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u533a\u5206\u641c\u7d22\u9636\u6bb5\u7684\u6709\u6548\u6027\u3002", "conclusion": "SenseSeek\u662f\u9996\u4e2a\u591a\u4f20\u611f\u5668\u8868\u5f81\u4fe1\u606f\u5bfb\u6c42\u591a\u9636\u6bb5\u7684\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2507.14687", "pdf": "https://arxiv.org/pdf/2507.14687", "abs": "https://arxiv.org/abs/2507.14687", "authors": ["Robin Lee", "Youngho Nam"], "title": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions", "categories": ["cs.SE", "68Q60, 03B70", "D.2.5"], "comment": "10 pages, 5 figures", "summary": "Modified Condition/Decision Coverage (MC/DC) is a mandatory structural\ncoverage criterion for ensuring the reliability and safety of critical systems.\nWhile its strictest form, Unique-Cause MC/DC, offers the highest assurance,\nresearch on its efficient test generation has been lacking. This gap is\nparticularly significant, as an analysis of large-scale avionics systems shows\nthat 99.7% of all conditional decisions are, in fact, Singular Boolean\nExpressions (SBEs) the ideal structure for applying Unique-Cause MC/DC. This\npaper proposes 'Robin's Rule', a deterministic algorithm that directly\nconstructs a minimal test set of N + 1 cases to guarantee 100% Unique-Cause\nMC/DC for SBEs with N conditions, without generating a full truth table. To\nvalidate our approach, we constructed a benchmark by reformulating the TCAS-II\nspecifications into SBEs and verified the results using an industry-standard,\ncertified commercial tool. The results confirm that our method consistently\nachieves 100% coverage with the theoretical minimum number of tests and is more\nefficient than the commercial tool. This work provides a practical and provably\noptimal solution for verifying safety-critical systems, ensuring both rigor and\nefficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a'Robin's Rule'\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4e3aN\u4e2a\u6761\u4ef6\u7684\u5947\u5f02\u5e03\u5c14\u8868\u8fbe\u5f0f\uff08SBEs\uff09\u76f4\u63a5\u6784\u5efa\u6700\u5c0f\u6d4b\u8bd5\u96c6\uff08N+1\u4e2a\u6848\u4f8b\uff09\uff0c\u4ee5\u5b9e\u73b0100%\u7684\u552f\u4e00\u539f\u56e0MC/DC\u8986\u76d6\uff0c\u4e14\u6548\u7387\u4f18\u4e8e\u5546\u4e1a\u5de5\u5177\u3002", "motivation": "\u5c3d\u7ba1Unique-Cause MC/DC\u5728\u786e\u4fdd\u5173\u952e\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u63d0\u4f9b\u6700\u9ad8\u4fdd\u969c\uff0c\u4f46\u5176\u9ad8\u6548\u6d4b\u8bd5\u751f\u6210\u7814\u7a76\u4e0d\u8db3\uff0c\u800c99.7%\u7684\u822a\u7a7a\u7535\u5b50\u7cfb\u7edf\u4e2d\u6761\u4ef6\u51b3\u7b56\u662fSBEs\uff0c\u9002\u5408\u5e94\u7528Unique-Cause MC/DC\u3002", "method": "\u63d0\u51fa'Robin's Rule'\u7b97\u6cd5\uff0c\u65e0\u9700\u751f\u6210\u5b8c\u6574\u771f\u503c\u8868\uff0c\u76f4\u63a5\u6784\u9020\u6700\u5c0f\u6d4b\u8bd5\u96c6\uff08N+1\u4e2a\u6848\u4f8b\uff09\u4ee5\u4fdd\u8bc1SBEs\u7684\u552f\u4e00\u539f\u56e0MC/DC\u8986\u76d6\u3002", "result": "\u901a\u8fc7\u5c06TCAS-II\u89c4\u8303\u8f6c\u5316\u4e3aSBEs\u6784\u9020\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u59cb\u7ec8\u4ee5\u7406\u8bba\u6700\u5c0f\u6d4b\u8bd5\u6570\u5b9e\u73b0100%\u8986\u76d6\uff0c\u6548\u7387\u4f18\u4e8e\u5546\u4e1a\u5de5\u5177\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u7406\u8bba\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u4e25\u683c\u6027\u548c\u9ad8\u6548\u6027\uff0c\u9002\u7528\u4e8e\u9a8c\u8bc1\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u3002"}}
{"id": "2502.15441", "pdf": "https://arxiv.org/pdf/2502.15441", "abs": "https://arxiv.org/abs/2502.15441", "authors": ["Yang Hong", "Shan Jiang", "Yulei Fu", "Sarfraz Khurshid"], "title": "On the Effectiveness of Large Language Models in Writing Alloy Formulas", "categories": ["cs.SE", "cs.AI", "cs.FL", "cs.PL"], "comment": null, "summary": "Declarative specifications have a vital role to play in developing safe and\ndependable software systems. Writing specifications correctly, however, remains\nparticularly challenging. This paper presents a controlled experiment on using\nlarge language models (LLMs) to write declarative formulas in the well-known\nlanguage Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write\ncomplete Alloy formulas from given natural language descriptions (in English).\nTwo, we employ LLMs to create alternative but equivalent formulas in Alloy with\nrespect to given Alloy formulas. Three, we employ LLMs to complete sketches of\nAlloy formulas and populate the holes in the sketches by synthesizing Alloy\nexpressions and operators so that the completed formulas accurately represent\nthe desired properties (that are given in natural language). We conduct the\nexperimental evaluation using 11 well-studied subject specifications and employ\ntwo popular LLMs, namely ChatGPT and DeepSeek. The experimental results show\nthat the LLMs generally perform well in synthesizing complete Alloy formulas\nfrom input properties given in natural language or in Alloy, and are able to\nenumerate multiple unique solutions. Moreover, the LLMs are also successful at\ncompleting given sketches of Alloy formulas with respect to natural language\ndescriptions of desired properties (without requiring test cases). We believe\nLLMs offer a very exciting advance in our ability to write specifications, and\ncan help make specifications take a pivotal role in software development and\nenhance our ability to build robust software.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7f16\u5199Alloy\u8bed\u8a00\u4e2d\u7684\u58f0\u660e\u5f0f\u89c4\u8303\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660eLLMs\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u5408\u6210\u5b8c\u6574\u89c4\u8303\u3001\u751f\u6210\u7b49\u4ef7\u89c4\u8303\u4ee5\u53ca\u5b8c\u6210\u89c4\u8303\u8349\u56fe\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u58f0\u660e\u5f0f\u89c4\u8303\u5bf9\u5f00\u53d1\u5b89\u5168\u53ef\u9760\u7684\u8f6f\u4ef6\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6b63\u786e\u7f16\u5199\u89c4\u8303\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5728\u8fd9\u4e00\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u4e09\u4e2a\u4efb\u52a1\u8bc4\u4f30LLMs\uff1a1\uff09\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u5b8c\u6574Alloy\u516c\u5f0f\uff1b2\uff09\u751f\u6210\u7b49\u4ef7Alloy\u516c\u5f0f\uff1b3\uff09\u5b8c\u6210Alloy\u89c4\u8303\u8349\u56fe\u3002\u5b9e\u9a8c\u4f7f\u7528\u4e8611\u4e2a\u5df2\u77e5\u89c4\u8303\u548c\u4e24\u4e2aLLM\uff08ChatGPT\u548cDeepSeek\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cLLMs\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u6216Alloy\u8f93\u5165\u5408\u6210\u5b8c\u6574\u89c4\u8303\u4ee5\u53ca\u5b8c\u6210\u89c4\u8303\u8349\u56fe\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u80fd\u751f\u6210\u591a\u4e2a\u72ec\u7279\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "LLMs\u4e3a\u7f16\u5199\u89c4\u8303\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u6709\u671b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u63d0\u5347\u89c4\u8303\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u5e2e\u52a9\u6784\u5efa\u66f4\u5065\u58ee\u7684\u8f6f\u4ef6\u3002"}}
{"id": "2507.14234", "pdf": "https://arxiv.org/pdf/2507.14234", "abs": "https://arxiv.org/abs/2507.14234", "authors": ["Samer Nasser", "Henrique Duarte Moura", "Dragan Subotic", "Ritesh Kumar Singh", "Maarten Weyn", "Jeroen Famaey"], "title": "Feasibility of Energy Neutral Wildlife Tracking using Multi-Source Energy Harvesting", "categories": ["cs.NI"], "comment": null, "summary": "Long-term wildlife tracking is crucial for biodiversity monitoring, but\nenergy limitations pose challenges, especially for animal tags, where replacing\nbatteries is impractical and stressful for the animal due to the need to\nlocate, possibly sedate, and handle it. Energy harvesting offers a sustainable\nalternative, yet most existing systems rely on a single energy source and\ninfrastructure-limited communication technologies. This paper presents an\nenergy-neutral system that combines solar and kinetic energy harvesting to\nenable the tracking and monitoring of wild animals. Harvesting from multiple\nsources increases the total available energy. Uniquely, the kinetic harvester\nalso serves as a motion proxy by sampling harvested current, enabling activity\nmonitoring without dedicated sensors. Our approach also ensures compatibility\nwith existing cellular infrastructure, using Narrowband Internet of Things\n(NB-IoT). We present a simulation framework that models energy harvesting,\nstorage, and consumption at the component level. An energy-aware scheduler\ncoordinates task execution based on real-time energy availability. We evaluate\nperformance under realistically varying conditions, comparing task frequencies\nand capacitor sizes. Results show that our approach maintains energy-neutral\noperation while significantly increasing data yield and reliability compared to\nsingle-source systems, with the ability to consistently sample GPS location\ndata and kinetic harvesting data every two minutes while transmitting these\nresults over NB-IoT every hour. These findings demonstrate the potential for\nmaintenance-free, environmentally friendly tracking in remote habitats,\nenabling more effective and scalable wildlife monitoring.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u592a\u9633\u80fd\u548c\u52a8\u80fd\u91c7\u96c6\u7684\u80fd\u91cf\u4e2d\u6027\u7cfb\u7edf\uff0c\u7528\u4e8e\u91ce\u751f\u52a8\u7269\u8ffd\u8e2a\u548c\u76d1\u6d4b\u3002\u901a\u8fc7\u591a\u6e90\u80fd\u91cf\u91c7\u96c6\u548cNB-IoT\u901a\u4fe1\u6280\u672f\uff0c\u8be5\u7cfb\u7edf\u63d0\u9ad8\u4e86\u6570\u636e\u4ea7\u91cf\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u957f\u671f\u91ce\u751f\u52a8\u7269\u8ffd\u8e2a\u5bf9\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u80fd\u6e90\u9650\u5236\u6210\u4e3a\u96be\u9898\u3002\u4f20\u7edf\u7535\u6c60\u66f4\u6362\u4e0d\u5207\u5b9e\u9645\u4e14\u5bf9\u52a8\u7269\u6709\u5bb3\uff0c\u800c\u73b0\u6709\u7cfb\u7edf\u591a\u4f9d\u8d56\u5355\u4e00\u80fd\u6e90\u3002", "method": "\u7cfb\u7edf\u7ed3\u5408\u592a\u9633\u80fd\u548c\u52a8\u80fd\u91c7\u96c6\uff0c\u52a8\u80fd\u91c7\u96c6\u5668\u8fd8\u7528\u4f5c\u8fd0\u52a8\u4ee3\u7406\u3002\u91c7\u7528NB-IoT\u901a\u4fe1\u548c\u57fa\u4e8e\u80fd\u91cf\u7684\u4efb\u52a1\u8c03\u5ea6\u5668\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0c\u7cfb\u7edf\u5728\u80fd\u91cf\u4e2d\u6027\u64cd\u4f5c\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u4ea7\u91cf\u548c\u53ef\u9760\u6027\uff0c\u5982\u6bcf\u4e24\u5206\u949f\u91c7\u6837\u4e00\u6b21GPS\u548c\u52a8\u80fd\u6570\u636e\uff0c\u6bcf\u5c0f\u65f6\u901a\u8fc7NB-IoT\u4f20\u8f93\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86\u5728\u504f\u8fdc\u6816\u606f\u5730\u5b9e\u73b0\u514d\u7ef4\u62a4\u3001\u73af\u4fdd\u7684\u91ce\u751f\u52a8\u7269\u8ffd\u8e2a\u6f5c\u529b\uff0c\u4e3a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2507.15294", "pdf": "https://arxiv.org/pdf/2507.15294", "abs": "https://arxiv.org/abs/2507.15294", "authors": ["Junjie Li", "Wenxuan Wu", "Shuai Wang", "Zexu Pan", "Kong Aik Lee", "Helen Meng", "Haizhou Li"], "title": "MeMo: Attentional Momentum for Real-time Audio-visual Speaker Extraction under Impaired Visual Conditions", "categories": ["cs.SD", "cs.MM"], "comment": null, "summary": "Audio-visual Target Speaker Extraction (AV-TSE) aims to isolate a target\nspeaker's voice from multi-speaker environments by leveraging visual cues as\nguidance. However, the performance of AV-TSE systems heavily relies on the\nquality of these visual cues. In extreme scenarios where visual cues are\nmissing or severely degraded, the system may fail to accurately extract the\ntarget speaker. In contrast, humans can maintain attention on a target speaker\neven in the absence of explicit auxiliary information. Motivated by such human\ncognitive ability, we propose a novel framework called MeMo, which incorporates\ntwo adaptive memory banks to store attention-related information. MeMo is\nspecifically designed for real-time scenarios: once initial attention is\nestablished, the system maintains attentional momentum over time, even when\nvisual cues become unavailable. We conduct comprehensive experiments to verify\nthe effectiveness of MeMo. Experimental results demonstrate that our proposed\nframework achieves SI-SNR improvements of at least 2 dB over the corresponding\nbaseline.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMeMo\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u4e2a\u81ea\u9002\u5e94\u8bb0\u5fc6\u5e93\u5b58\u50a8\u6ce8\u610f\u529b\u76f8\u5173\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u89c6\u542c\u76ee\u6807\u8bf4\u8bdd\u8005\u63d0\u53d6\uff08AV-TSE\uff09\u5728\u89c6\u89c9\u7ebf\u7d22\u7f3a\u5931\u65f6\u7684\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u4eba\u7c7b\u5728\u7f3a\u4e4f\u8f85\u52a9\u4fe1\u606f\u65f6\u4ecd\u80fd\u4fdd\u6301\u6ce8\u610f\u529b\uff0c\u53d7\u6b64\u542f\u53d1\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u80fd\u5728\u89c6\u89c9\u7ebf\u7d22\u7f3a\u5931\u65f6\u4fdd\u6301\u6ce8\u610f\u529b\u52a8\u91cf\u7684\u7cfb\u7edf\u3002", "method": "MeMo\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u81ea\u9002\u5e94\u8bb0\u5fc6\u5e93\uff0c\u7528\u4e8e\u5b58\u50a8\u548c\u8c03\u7528\u6ce8\u610f\u529b\u76f8\u5173\u4fe1\u606f\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMeMo\u6846\u67b6\u5728SI-SNR\u6307\u6807\u4e0a\u6bd4\u57fa\u7ebf\u81f3\u5c11\u63d0\u9ad82 dB\u3002", "conclusion": "MeMo\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86AV-TSE\u7cfb\u7edf\u5728\u89c6\u89c9\u7ebf\u7d22\u7f3a\u5931\u65f6\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15689", "pdf": "https://arxiv.org/pdf/2507.15689", "abs": "https://arxiv.org/abs/2507.15689", "authors": ["Jean Christoph Jung", "J\u0119drzej Ko\u0142odziejski", "Frank Wolter"], "title": "Computation of Interpolants for Description Logic Concepts in Hard Cases", "categories": ["cs.LO"], "comment": null, "summary": "While the computation of Craig interpolants for description logics (DLs) with\nthe Craig Interpolation Property (CIP) is well understood, very little is known\nabout the computation and size of interpolants for DLs without CIP or if one\naims at interpolating concepts in a weaker DL than the DL of the input ontology\nand concepts. In this paper, we provide the first elementary algorithms\ncomputing (i) ALC-interpolants between ALC-concepts under ALCH-ontologies and\n(ii) ALC-interpolants between ALCQ-concepts under ALCQ-ontologies. The\nalgorithms are based on recent decision procedures for interpolant existence.\nWe also observe that, in contrast, uniform (possibly depth restricted)\ninterpolants might be of non-elementary size.", "AI": {"tldr": "\u6458\u8981\u8ba8\u8bba\u4e86\u63cf\u8ff0\u903b\u8f91\uff08DLs\uff09\u4e2dCraig\u63d2\u503c\u7684\u8ba1\u7b97\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u4e0d\u5177\u5907Craig\u63d2\u503c\u6027\u8d28\uff08CIP\uff09\u7684DLs\u6216\u9700\u8981\u5728\u8f83\u5f31DL\u4e2d\u63d2\u503c\u7684\u60c5\u51b5\u3002\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u672c\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97ALC\u63d2\u503c\uff0c\u5e76\u89c2\u5bdf\u5230\u975e\u57fa\u672c\u5927\u5c0f\u7684\u5747\u5300\u63d2\u503c\u53ef\u80fd\u5b58\u5728\u7684\u95ee\u9898\u3002", "motivation": "\u7814\u7a76DLs\u4e2d\u63d2\u503c\u8ba1\u7b97\u7684\u7a7a\u767d\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u4e0d\u5177\u5907CIP\u7684DLs\u6216\u5728\u8f83\u5f31DL\u4e2d\u63d2\u503c\u7684\u60c5\u5883\u3002", "method": "\u57fa\u4e8e\u6700\u8fd1\u7684\u63d2\u503c\u5b58\u5728\u6027\u51b3\u7b56\u7a0b\u5e8f\uff0c\u63d0\u51fa\u4e86\u8ba1\u7b97ALC\u63d2\u503c\u7684\u57fa\u672c\u7b97\u6cd5\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e24\u79cd\u63d2\u503c\u8ba1\u7b97\u7b97\u6cd5\uff0c\u5e76\u53d1\u73b0\u5747\u5300\u63d2\u503c\u53ef\u80fd\u5177\u6709\u975e\u57fa\u672c\u5927\u5c0f\u3002", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86DLs\u4e2d\u63d2\u503c\u8ba1\u7b97\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u89c1\u89e3\u3002"}}
{"id": "2507.15351", "pdf": "https://arxiv.org/pdf/2507.15351", "abs": "https://arxiv.org/abs/2507.15351", "authors": ["Zijian Zhao", "Sen Li"], "title": "One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms", "categories": ["cs.AI", "cs.ET", "cs.MA"], "comment": null, "summary": "On-demand ride-sharing platforms face the fundamental challenge of\ndynamically bundling passengers with diverse origins and destinations and\nmatching them with vehicles in real time, all under significant uncertainty.\nRecently, MARL has emerged as a promising solution for this problem, leveraging\ndecentralized learning to address the curse of dimensionality caused by the\nlarge number of agents in the ride-hailing market and the resulting expansive\nstate and action spaces. However, conventional MARL-based ride-sharing\napproaches heavily rely on the accurate estimation of Q-values or V-values,\nwhich becomes problematic in large-scale, highly uncertain environments.\nSpecifically, most of these approaches adopt an independent paradigm,\nexacerbating this issue, as each agent treats others as part of the\nenvironment, leading to unstable training and substantial estimation bias in\nvalue functions. To address these challenges, we propose two novel alternative\nmethods that bypass value function estimation. First, we adapt GRPO to\nride-sharing, replacing the PPO baseline with the group average reward to\neliminate critic estimation errors and reduce training bias. Second, inspired\nby GRPO's full utilization of group reward information, we customize the PPO\nframework for ride-sharing platforms and show that, under a homogeneous fleet,\nthe optimal policy can be trained using only one-step rewards - a method we\nterm One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan\nride-hailing dataset demonstrate that both GRPO and OSPO achieve superior\nperformance across most scenarios, efficiently optimizing pickup times and the\nnumber of served orders using simple MLP networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u65b9\u6cd5\uff08GRPO\u548cOSPO\uff09\u4ee5\u89e3\u51b3\u4f20\u7edfMARL\u5728\u52a8\u6001\u62fc\u8f66\u5e73\u53f0\u4e2d\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u907f\u514d\u503c\u51fd\u6570\u4f30\u8ba1\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u52a8\u6001\u62fc\u8f66\u5e73\u53f0\u9762\u4e34\u9ad8\u7ef4\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\uff0c\u800c\u4f20\u7edfMARL\u65b9\u6cd5\u56e0\u4f9d\u8d56\u51c6\u786e\u503c\u51fd\u6570\u4f30\u8ba1\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u4f30\u8ba1\u504f\u5dee\u3002", "method": "1. \u5c06GRPO\u5e94\u7528\u4e8e\u62fc\u8f66\uff0c\u7528\u7fa4\u4f53\u5e73\u5747\u5956\u52b1\u66ff\u4ee3PPO\u57fa\u7ebf\uff1b2. \u63d0\u51faOSPO\uff0c\u4ec5\u5229\u7528\u4e00\u6b65\u5956\u52b1\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5728\u771f\u5b9e\u66fc\u54c8\u987f\u62fc\u8f66\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGRPO\u548cOSPO\u5728\u591a\u6570\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u4f18\u5316\u4e86\u63a5\u9001\u65f6\u95f4\u548c\u8ba2\u5355\u5b8c\u6210\u91cf\u3002", "conclusion": "GRPO\u548cOSPO\u901a\u8fc7\u7ed5\u8fc7\u503c\u51fd\u6570\u4f30\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfMARL\u5728\u5927\u89c4\u6a21\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u62fc\u8f66\u5e73\u53f0\u7684\u6548\u7387\u3002"}}
{"id": "2507.15154", "pdf": "https://arxiv.org/pdf/2507.15154", "abs": "https://arxiv.org/abs/2507.15154", "authors": ["Kohya Shiozaki", "Junya Nakamura"], "title": "Dynatune: Dynamic Tuning of Raft Election Parameters Using Network Measurement", "categories": ["cs.DC"], "comment": "This paper was accepted at the 27th International Workshop on\n  Advances in Parallel and Distributed Computational Models (APDCM 2025), held\n  in conjunction with IPDPS 2025", "summary": "Raft is a leader-based consensus algorithm that implements State Machine\nReplication (SMR), which replicates the service state across multiple servers\nto enhance fault tolerance. In Raft, the servers play one of three roles:\nleader, follower, or candidate. The leader receives client requests, determines\nthe processing order, and replicates them to the followers. When the leader\nfails, the service must elect a new leader to continue processing requests,\nduring which the service experiences an out-of-service (OTS) time. The OTS time\nis directly influenced by election parameters, such as heartbeat interval and\nelection timeout. However, traditional approaches, such as Raft, often struggle\nto effectively tune these parameters, particularly under fluctuating network\nconditions, leading to increased OTS time and reduced service responsiveness.\nTo address this, we propose Dynatune, a mechanism that dynamically adjusts\nRaft's election parameters based on network metrics such as round-trip time and\npacket loss rates measured via heartbeats. By adapting to changing network\nenvironments, Dynatune significantly reduces the leader failure detection and\nOTS time without altering Raft's core mechanisms or introducing additional\ncommunication overheads. Experimental results demonstrate that Dynatune reduces\nthe leader failure detection and OTS times by 80% and 45%, respectively,\ncompared with Raft, while maintaining high availability even under dynamic\nnetwork conditions. These findings confirm that Dynatune effectively enhances\nthe performance and reliability of SMR services in various network scenarios.", "AI": {"tldr": "Dynatune\u52a8\u6001\u8c03\u6574Raft\u9009\u4e3e\u53c2\u6570\uff0c\u663e\u8457\u964d\u4f4eOTS\u65f6\u95f4\uff0c\u63d0\u5347SMR\u670d\u52a1\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edfRaft\u5728\u52a8\u6001\u7f51\u7edc\u6761\u4ef6\u4e0b\u96be\u4ee5\u6709\u6548\u8c03\u6574\u9009\u4e3e\u53c2\u6570\uff0c\u5bfc\u81f4OTS\u65f6\u95f4\u589e\u52a0\u548c\u670d\u52a1\u54cd\u5e94\u6027\u4e0b\u964d\u3002", "method": "\u901a\u8fc7\u5fc3\u8df3\u6d4b\u91cf\u7f51\u7edc\u6307\u6807\uff0c\u52a8\u6001\u8c03\u6574Raft\u7684\u9009\u4e3e\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDynatune\u5c06\u9886\u5bfc\u5931\u6548\u68c0\u6d4b\u548cOTS\u65f6\u95f4\u5206\u522b\u964d\u4f4e80%\u548c45%\u3002", "conclusion": "Dynatune\u5728\u4e0d\u540c\u7f51\u7edc\u573a\u666f\u4e0b\u63d0\u5347\u4e86SMR\u670d\u52a1\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14818", "pdf": "https://arxiv.org/pdf/2507.14818", "abs": "https://arxiv.org/abs/2507.14818", "authors": ["Zihe Ran", "Xiyu Li", "Qing Xiao", "Yanyun Wang", "Franklin Mingzhe Li", "Zhicong Lu"], "title": "Understanding How Visually Impaired Players Socialize in Mobile Games", "categories": ["cs.HC", "cs.CY"], "comment": "16 pages, 1 table, accepted by ASSETS25", "summary": "Mobile games are becoming a vital medium for social interaction, offering a\nplatform that transcends geographical boundaries. An increasing number of\nvisually impaired individuals are engaging in mobile gaming to connect,\ncollaborate, compete, and build friendships. In China, visually impaired\ncommunities face significant social challenges in offline settings, making\nmobile games a crucial avenue for socialization. However, the design of mobile\ngames and their mapping to real-world environments significantly shape their\nsocial gaming experiences. This study explores how visually impaired players in\nChina navigate socialization and integrate into gaming communities. Through\ninterviews with 30 visually impaired players, we found that while mobile games\nfulfill many of their social needs, technological barriers and insufficient\naccessibility features, and internal community divisions present significant\nchallenges to their participation. This research sheds light on their social\nexperiences and offers insights for designing more inclusive and accessible\nmobile games.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4e2d\u56fd\u89c6\u969c\u73a9\u5bb6\u5728\u624b\u673a\u6e38\u620f\u4e2d\u7684\u793e\u4ea4\u4f53\u9a8c\uff0c\u53d1\u73b0\u73b0\u6709\u6e38\u620f\u867d\u6ee1\u8db3\u90e8\u5206\u9700\u6c42\uff0c\u4f46\u6280\u672f\u969c\u788d\u548c\u793e\u533a\u5206\u5272\u4ecd\u662f\u4e3b\u8981\u6311\u6218\u3002", "motivation": "\u89c6\u969c\u4eba\u7fa4\u5728\u7ebf\u4e0b\u793e\u4ea4\u4e2d\u9762\u4e34\u56f0\u96be\uff0c\u624b\u673a\u6e38\u620f\u6210\u4e3a\u91cd\u8981\u793e\u4ea4\u5e73\u53f0\uff0c\u4f46\u6e38\u620f\u8bbe\u8ba1\u548c\u65e0\u969c\u788d\u529f\u80fd\u4e0d\u8db3\u5f71\u54cd\u5176\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u91c7\u8bbf30\u540d\u89c6\u969c\u73a9\u5bb6\uff0c\u5206\u6790\u4ed6\u4eec\u5728\u6e38\u620f\u4e2d\u7684\u793e\u4ea4\u53c2\u4e0e\u548c\u793e\u533a\u878d\u5165\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u663e\u793a\u6e38\u620f\u6ee1\u8db3\u4e86\u90e8\u5206\u793e\u4ea4\u9700\u6c42\uff0c\u4f46\u6280\u672f\u969c\u788d\u548c\u65e0\u969c\u788d\u529f\u80fd\u4e0d\u8db3\u963b\u788d\u4e86\u66f4\u6df1\u5165\u7684\u53c2\u4e0e\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u9700\u8bbe\u8ba1\u66f4\u5177\u5305\u5bb9\u6027\u548c\u65e0\u969c\u788d\u7684\u624b\u673a\u6e38\u620f\uff0c\u4ee5\u63d0\u5347\u89c6\u969c\u73a9\u5bb6\u7684\u793e\u4ea4\u4f53\u9a8c\u3002"}}
{"id": "2507.14716", "pdf": "https://arxiv.org/pdf/2507.14716", "abs": "https://arxiv.org/abs/2507.14716", "authors": ["Shahidul Islam", "Ashik Aowal", "Md Sharif Uddin", "Shaiful Chowdhury"], "title": "HistoryFinder: Advancing Method-Level Source Code History Generation with Accurate Oracles and Enhanced Algorithm", "categories": ["cs.SE"], "comment": null, "summary": "Reconstructing a method's change history efficiently and accurately is\ncritical for many software engineering tasks, including maintenance,\nrefactoring, and comprehension. Despite the availability of method history\ngeneration tools such as CodeShovel and CodeTracker, existing evaluations of\ntheir effectiveness are limited by inaccuracies in the ground truth oracles\nused. In this study, we systematically construct two new oracles -- the\ncorrected CodeShovel oracle and a newly developed HistoryFinder oracle -- by\ncombining automated analysis with expert-guided manual validation. We also\nintroduce HistoryFinder, a new method history generation tool designed to\nimprove not only the accuracy and completeness of method change histories but\nalso to offer competitive runtime performance. Through extensive evaluation\nacross 400 methods from 40 open-source repositories, we show that HistoryFinder\nconsistently outperforms CodeShovel, CodeTracker, IntelliJ, and Git-based\nbaselines in terms of precision, recall, and F1 score. Moreover, HistoryFinder\nachieves competitive runtime performance, offering the lowest mean and median\nexecution times among all the research-based tools.\n  While Git-based tools exhibit the fastest runtimes, this efficiency comes at\nthe cost of significantly lower precision and recall -- leaving HistoryFinder\nas the best overall choice when both accuracy and efficiency are important. To\nfacilitate adoption, we provide a web interface, CLI, and Java library for\nflexible usage.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u5386\u53f2\u751f\u6210\u5de5\u5177HistoryFinder\uff0c\u901a\u8fc7\u7cfb\u7edf\u6784\u5efa\u7684\u4e24\u4e2a\u65b0oracle\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u5e76\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u9ad8\u6548\u51c6\u786e\u5730\u91cd\u5efa\u65b9\u6cd5\u53d8\u66f4\u5386\u53f2\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u7684\u8bc4\u4f30\u56e0oracle\u4e0d\u51c6\u786e\u800c\u53d7\u9650\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u5316\u5206\u6790\u548c\u4e13\u5bb6\u9a8c\u8bc1\u6784\u5efa\u65b0oracle\uff0c\u5f00\u53d1\u65b0\u5de5\u5177HistoryFinder\uff0c\u8bc4\u4f30400\u4e2a\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "HistoryFinder\u5728\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u5e76\u5177\u5907\u9ad8\u6548\u8fd0\u884c\u65f6\u6027\u80fd\u3002", "conclusion": "HistoryFinder\u662f\u517c\u987e\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u6700\u4f73\u9009\u62e9\uff0c\u63d0\u4f9b\u4e86\u591a\u79cd\u4f7f\u7528\u65b9\u5f0f\u4ee5\u4fc3\u8fdb\u91c7\u7528\u3002"}}
{"id": "2507.14263", "pdf": "https://arxiv.org/pdf/2507.14263", "abs": "https://arxiv.org/abs/2507.14263", "authors": ["Ramesh Raskar", "Pradyumna Chari", "John Zinky", "Mahesh Lambe", "Jared James Grogan", "Sichao Wang", "Rajesh Ranjan", "Rekha Singhal", "Shailja Gupta", "Robert Lincourt", "Raghu Bala", "Aditi Joshi", "Abhishek Singh", "Ayush Chopra", "Dimitris Stripelis", "Bhuwan B", "Sumit Kumar", "Maria Gorskikh"], "title": "Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts", "categories": ["cs.NI", "cs.AI", "cs.CR", "cs.MA"], "comment": null, "summary": "The Internet is poised to host billions to trillions of autonomous AI agents\nthat negotiate, delegate, and migrate in milliseconds and workloads that will\nstrain DNS-centred identity and discovery. In this paper, we describe the NANDA\nindex architecture, which we envision as a means for discoverability,\nidentifiability and authentication in the internet of AI agents. We present an\narchitecture where a minimal lean index resolves to dynamic, cryptographically\nverifiable AgentFacts that supports multi-endpoint routing, load balancing,\nprivacy-preserving access, and credentialed capability assertions. Our\narchitecture design delivers five concrete guarantees: (1) A quilt-like index\nproposal that supports both NANDA-native agents as well as third party agents\nbeing discoverable via the index, (2) rapid global resolution for newly spawned\nAI agents, (3) sub-second revocation and key rotation, (4) schema-validated\ncapability assertions, and (5) privacy-preserving discovery across\norganisational boundaries via verifiable, least-disclosure queries. We\nformalize the AgentFacts schema, specify a CRDT-based update protocol, and\nprototype adaptive resolvers. The result is a lightweight, horizontally\nscalable foundation that unlocks secure, trust-aware collaboration for the next\ngeneration of the Internet of AI agents, without abandoning existing web\ninfrastructure.", "AI": {"tldr": "NANDA\u67b6\u6784\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u6269\u5c55\u7684\u53d1\u73b0\u4e0e\u8ba4\u8bc1\u65b9\u6848\uff0c\u652f\u6301\u5feb\u901f\u89e3\u6790\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u8de8\u7ec4\u7ec7\u534f\u4f5c\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u6570\u91cf\u6fc0\u589e\uff0c\u4f20\u7edf\u7684DNS\u4e3a\u4e2d\u5fc3\u7684\u8eab\u4efd\u53d1\u73b0\u673a\u5236\u9762\u4e34\u6311\u6218\uff0c\u4e9f\u9700\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faNANDA\u7d22\u5f15\u67b6\u6784\uff0c\u57fa\u4e8e\u52a8\u6001\u53ef\u9a8c\u8bc1\u7684AgentFacts\uff0c\u652f\u6301\u591a\u7aef\u70b9\u8def\u7531\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u80fd\u529b\u58f0\u660e\u3002", "result": "\u5b9e\u73b0\u4e86\u5feb\u901f\u5168\u5c40\u89e3\u6790\u3001\u79d2\u7ea7\u64a4\u9500\u3001\u9690\u79c1\u4fdd\u62a4\u7b49\u529f\u80fd\uff0c\u539f\u578b\u9a8c\u8bc1\u4e86\u5176\u8f7b\u91cf\u7ea7\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "NANDA\u4e3a\u4e0b\u4e00\u4ee3AI\u4ee3\u7406\u4e92\u8054\u7f51\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u53ef\u4fe1\u7684\u9ad8\u6548\u534f\u4f5c\u57fa\u7840\uff0c\u517c\u5bb9\u73b0\u6709\u7f51\u7edc\u8bbe\u65bd\u3002"}}
{"id": "2507.14218", "pdf": "https://arxiv.org/pdf/2507.14218", "abs": "https://arxiv.org/abs/2507.14218", "authors": ["Craig S Wright"], "title": "Cognitive Castes: Artificial Intelligence, Epistemic Stratification, and the Dissolution of Democratic Discourse", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.LO", "68T01, 03B70, 91F10, 68P20, 68T30", "I.2.0; K.4.1; I.2.6; J.4"], "comment": "42 Pages; Approx. 10,000 words, no figures. Theoretical contribution\n  with interdisciplinary scope", "summary": "Artificial intelligence functions not as an epistemic leveller, but as an\naccelerant of cognitive stratification, entrenching and formalising\ninformational castes within liberal-democratic societies. Synthesising formal\nepistemology, political theory, algorithmic architecture, and economic\nincentive structures, the argument traces how contemporary AI systems\nselectively amplify the reasoning capacity of individuals equipped with\nrecursive abstraction, symbolic logic, and adversarial interrogation, whilst\nsimultaneously pacifying the cognitively untrained through engagement-optimised\ninterfaces. Fluency replaces rigour, immediacy displaces reflection, and\nprocedural reasoning is eclipsed by reactive suggestion. The result is a\ntechnocratic realignment of power: no longer grounded in material capital\nalone, but in the capacity to navigate, deconstruct, and manipulate systems of\nepistemic production. Information ceases to be a commons; it becomes the\nsubstrate through which consent is manufactured and autonomy subdued.\nDeliberative democracy collapses not through censorship, but through the\nerosion of interpretive agency. The proposed response is not technocratic\nregulation, nor universal access, but the reconstruction of rational autonomy\nas a civic mandate, codified in education, protected by epistemic rights, and\nstructurally embedded within open cognitive infrastructure.", "AI": {"tldr": "AI\u52a0\u5267\u8ba4\u77e5\u5206\u5c42\uff0c\u56fa\u5316\u4fe1\u606f\u9636\u5c42\uff0c\u524a\u5f31\u6c11\u4e3b\u5ba1\u8bae\u80fd\u529b\uff0c\u9700\u901a\u8fc7\u6559\u80b2\u548c\u8ba4\u77e5\u6743\u5229\u91cd\u5efa\u7406\u6027\u81ea\u4e3b\u3002", "motivation": "\u63a2\u8ba8AI\u5982\u4f55\u901a\u8fc7\u9009\u62e9\u6027\u589e\u5f3a\u67d0\u4e9b\u8ba4\u77e5\u80fd\u529b\uff0c\u5bfc\u81f4\u8ba4\u77e5\u5206\u5c42\u548c\u4fe1\u606f\u4e0d\u5bf9\u79f0\uff0c\u8fdb\u4e00\u6b65\u524a\u5f31\u6c11\u4e3b\u793e\u4f1a\u7684\u5ba1\u8bae\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u5f62\u5f0f\u8ba4\u8bc6\u8bba\u3001\u653f\u6cbb\u7406\u8bba\u3001\u7b97\u6cd5\u67b6\u6784\u548c\u7ecf\u6d4e\u6fc0\u52b1\u7ed3\u6784\uff0c\u5206\u6790AI\u5982\u4f55\u5f3a\u5316\u6216\u524a\u5f31\u4e0d\u540c\u4eba\u7fa4\u7684\u8ba4\u77e5\u80fd\u529b\u3002", "result": "AI\u5bfc\u81f4\u6280\u672f\u6743\u529b\u91cd\u7ec4\uff0c\u4fe1\u606f\u4e0d\u518d\u4e3a\u516c\u5171\u6240\u6709\uff0c\u800c\u662f\u6210\u4e3a\u5236\u9020\u5171\u8bc6\u548c\u538b\u5236\u81ea\u4e3b\u7684\u5de5\u5177\u3002", "conclusion": "\u9700\u901a\u8fc7\u6559\u80b2\u3001\u8ba4\u77e5\u6743\u5229\u548c\u5f00\u653e\u8ba4\u77e5\u57fa\u7840\u8bbe\u65bd\u91cd\u5efa\u516c\u6c11\u7684\u7406\u6027\u81ea\u4e3b\u80fd\u529b\u3002"}}
{"id": "2507.15676", "pdf": "https://arxiv.org/pdf/2507.15676", "abs": "https://arxiv.org/abs/2507.15676", "authors": ["Reza Vatankhah Barenji", "Sina Khoshgoftar"], "title": "Agentic AI for autonomous anomaly management in complex systems", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "This paper explores the potential of agentic AI in autonomously detecting and\nresponding to anomalies within complex systems, emphasizing its ability to\ntransform traditional, human-dependent anomaly management methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4ee3\u7406\u578bAI\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u81ea\u4e3b\u68c0\u6d4b\u548c\u54cd\u5e94\u5f02\u5e38\u7684\u6f5c\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u6539\u53d8\u4f20\u7edf\u4f9d\u8d56\u4eba\u7c7b\u7684\u5f02\u5e38\u7ba1\u7406\u6a21\u5f0f\u7684\u80fd\u529b\u3002", "motivation": "\u65e8\u5728\u5229\u7528\u4ee3\u7406\u578bAI\u6280\u672f\u89e3\u51b3\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u7ba1\u7406\u95ee\u9898\uff0c\u51cf\u5c11\u4eba\u4e3a\u5e72\u9884\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u7814\u7a76\u4ee3\u7406\u578bAI\u5728\u5f02\u5e38\u68c0\u6d4b\u548c\u54cd\u5e94\u4e2d\u7684\u81ea\u4e3b\u80fd\u529b\uff0c\u53ef\u80fd\u6d89\u53ca\u7b97\u6cd5\u8bbe\u8ba1\u548c\u5b9e\u8df5\u5e94\u7528\u3002", "result": "\u5c55\u793a\u4e86\u4ee3\u7406\u578bAI\u5728\u63d0\u9ad8\u5f02\u5e38\u7ba1\u7406\u6548\u7387\u548c\u51cf\u5c11\u4eba\u4e3a\u4f9d\u8d56\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u4ee3\u7406\u578bAI\u6709\u671b\u9769\u65b0\u4f20\u7edf\u7684\u5f02\u5e38\u7ba1\u7406\u65b9\u5f0f\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14846", "pdf": "https://arxiv.org/pdf/2507.14846", "abs": "https://arxiv.org/abs/2507.14846", "authors": ["Nuwan Janaka", "Shengdong Zhao", "Ashwin Ram", "Ruoxin Sun", "Sherisse Tan Jing Wen", "Danae Li", "David Hsu"], "title": "Progressive Sentences: Combining the Benefits of Word and Sentence Learning", "categories": ["cs.HC", "cs.CY"], "comment": "12 pages, 4 figures, 4 tables", "summary": "The rapid evolution of lightweight consumer augmented reality (AR) smart\nglasses (a.k.a. optical see-through head-mounted displays) offers novel\nopportunities for learning, particularly through their unique capability to\ndeliver multimodal information in just-in-time, micro-learning scenarios. This\nresearch investigates how such devices can support mobile second-language\nacquisition by presenting progressive sentence structures in multimodal\nformats. In contrast to the commonly used vocabulary (i.e., word) learning\napproach for novice learners, we present a \"progressive presentation\" method\nthat combines both word and sentence learning by sequentially displaying\nsentence components (subject, verb, object) while retaining prior context.\nPilot and formal studies revealed that progressive presentation enhances\nrecall, particularly in mobile scenarios such as walking. Additionally,\nincorporating timed gaps between word presentations further improved learning\neffectiveness under multitasking conditions. Our findings demonstrate the\nutility of progressive presentation and provide usage guidelines for\neducational applications-even during brief, on-the-go learning moments.", "AI": {"tldr": "\u8f7b\u91cf\u7ea7AR\u667a\u80fd\u773c\u955c\u901a\u8fc7\u9010\u6b65\u5448\u73b0\u53e5\u5b50\u7ed3\u6784\uff0c\u652f\u6301\u79fb\u52a8\u4e8c\u8bed\u4e60\u5f97\u3002", "motivation": "\u63a2\u7d22AR\u667a\u80fd\u773c\u955c\u5728\u79fb\u52a8\u5b66\u4e60\u4e2d\u5982\u4f55\u652f\u6301\u4e8c\u8bed\u4e60\u5f97\uff0c\u7279\u522b\u662f\u901a\u8fc7\u591a\u6a21\u6001\u4fe1\u606f\u5448\u73b0\u3002", "method": "\u63d0\u51fa\u9010\u6b65\u5448\u73b0\u6cd5\uff0c\u4f9d\u6b21\u5c55\u793a\u53e5\u5b50\u6210\u5206\uff08\u4e3b\u3001\u8c13\u3001\u5bbe\uff09\uff0c\u4fdd\u7559\u4e0a\u4e0b\u6587\uff0c\u5e76\u6d4b\u8bd5\u5176\u6548\u679c\u3002", "result": "\u9010\u6b65\u5448\u73b0\u6cd5\u63d0\u9ad8\u8bb0\u5fc6\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u79fb\u52a8\u573a\u666f\u4e2d\uff1b\u5b9a\u65f6\u95f4\u9694\u8fdb\u4e00\u6b65\u4f18\u5316\u5b66\u4e60\u6548\u679c\u3002", "conclusion": "\u9010\u6b65\u5448\u73b0\u6cd5\u9002\u7528\u4e8e\u79fb\u52a8\u5b66\u4e60\u573a\u666f\uff0c\u4e3a\u6559\u80b2\u5e94\u7528\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2507.14735", "pdf": "https://arxiv.org/pdf/2507.14735", "abs": "https://arxiv.org/abs/2507.14735", "authors": ["Vladyslav Bulhakov", "Giordano d'Aloisio", "Claudio Di Sipio", "Antinisca Di Marco", "Davide Di Ruscio"], "title": "Investigating the Role of LLMs Hyperparameter Tuning and Prompt Engineering to Support Domain Modeling", "categories": ["cs.SE"], "comment": "Accepted at 51st Euromicro Conference Series on Software Engineering\n  and Advanced Applications (SEAA)", "summary": "The introduction of large language models (LLMs) has enhanced automation in\nsoftware engineering tasks, including in Model Driven Engineering (MDE).\nHowever, using general-purpose LLMs for domain modeling has its limitations.\nOne approach is to adopt fine-tuned models, but this requires significant\ncomputational resources and can lead to issues like catastrophic forgetting.\n  This paper explores how hyperparameter tuning and prompt engineering can\nimprove the accuracy of the Llama 3.1 model for generating domain models from\ntextual descriptions. We use search-based methods to tune hyperparameters for a\nspecific medical data model, resulting in a notable quality improvement over\nthe baseline LLM. We then test the optimized hyperparameters across ten diverse\napplication domains.\n  While the solutions were not universally applicable, we demonstrate that\ncombining hyperparameter tuning with prompt engineering can enhance results\nacross nearly all examined domain models.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u7ed3\u5408\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u63d0\u793a\u5de5\u7a0b\u5982\u4f55\u63d0\u5347Llama 3.1\u6a21\u578b\u5728\u4ece\u6587\u672c\u63cf\u8ff0\u751f\u6210\u9886\u57df\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9886\u57df\u5efa\u6a21\u4e2d\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u63a2\u7d22\u66f4\u4f18\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u641c\u7d22\u65b9\u6cd5\u8c03\u4f18\u8d85\u53c2\u6570\uff0c\u5e76\u5728\u591a\u9886\u57df\u6d4b\u8bd5\u6548\u679c\u3002", "result": "\u4f18\u5316\u540e\u7684\u6a21\u578b\u5728\u51e0\u4e4e\u6240\u6709\u6d4b\u8bd5\u9886\u57df\u4e2d\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u8d85\u53c2\u6570\u8c03\u4f18\u4e0e\u63d0\u793a\u5de5\u7a0b\u7ed3\u5408\u53ef\u663e\u8457\u6539\u5584\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\u3002"}}
{"id": "2507.14398", "pdf": "https://arxiv.org/pdf/2507.14398", "abs": "https://arxiv.org/abs/2507.14398", "authors": ["Md. Kamrul Hossain", "Walid Aljoby"], "title": "NetIntent: Leveraging Large Language Models for End-to-End Intent-Based SDN Automation", "categories": ["cs.NI"], "comment": null, "summary": "Intent-Based Networking (IBN) often leverages the programmability of\nSoftware-Defined Networking (SDN) to simplify network management. However,\nsignificant challenges remain in automating the entire pipeline, from\nuser-specified high-level intents to device-specific low-level configurations.\nExisting solutions often rely on rigid, rule-based translators and fixed APIs,\nlimiting extensibility and adaptability. By contrast, recent advances in large\nlanguage models (LLMs) offer a promising pathway that leverages natural\nlanguage understanding and flexible reasoning. However, it is unclear to what\nextent LLMs can perform IBN tasks. To address this, we introduce IBNBench, a\nfirst-of-its-kind benchmarking suite comprising four novel datasets:\nIntent2Flow-ODL, Intent2Flow-ONOS, FlowConflict-ODL, and FlowConflict-ONOS.\nThese datasets are specifically designed for evaluating LLMs performance in\nintent translation and conflict detection tasks within the industry-grade SDN\ncontrollers ODL and ONOS. Our results provide the first comprehensive\ncomparison of 33 open-source LLMs on IBNBench and related datasets, revealing a\nwide range of performance outcomes. However, while these results demonstrate\nthe potential of LLMs for isolated IBN tasks, integrating LLMs into a fully\nautonomous IBN pipeline remains unexplored. Thus, our second contribution is\nNetIntent, a unified and adaptable framework that leverages LLMs to automate\nthe full IBN lifecycle, including translation, activation, and assurance within\nSDN systems. NetIntent orchestrates both LLM and non-LLM agents, supporting\ndynamic re-prompting and contextual feedback to robustly execute user-defined\nintents with minimal human intervention. Our implementation of NetIntent across\nboth ODL and ONOS SDN controllers achieves a consistent and adaptive end-to-end\nIBN realization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86IBNBench\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u548cNetIntent\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6574\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u610f\u56fe\u7f51\u7edc\uff08IBN\uff09\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u610f\u56fe\u7f51\u7edc\uff08IBN\uff09\u5728\u7b80\u5316\u7f51\u7edc\u7ba1\u7406\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u3002LLM\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u7684\u4f18\u52bf\u4f7f\u5176\u6210\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u6f5c\u5728\u5de5\u5177\u3002", "method": "\u7814\u7a76\u56e2\u961f\u5f00\u53d1\u4e86IBNBench\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5305\u542b\u56db\u4e2a\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f3033\u4e2a\u5f00\u6e90LLM\u5728\u610f\u56fe\u7ffb\u8bd1\u548c\u51b2\u7a81\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u968f\u540e\u63d0\u51fa\u4e86NetIntent\u6846\u67b6\uff0c\u6574\u5408LLM\u548c\u975eLLM\u4ee3\u7406\uff0c\u5b9e\u73b0\u610f\u56fe\u7684\u81ea\u52a8\u7ffb\u8bd1\u3001\u6fc0\u6d3b\u548c\u4fdd\u969c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aLLM\u5728\u5b64\u7acbIBN\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4e00\uff0c\u800cNetIntent\u6846\u67b6\u5728ODL\u548cONOS SDN\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\u4e86\u7a33\u5b9a\u4e14\u81ea\u9002\u5e94\u7684\u7aef\u5230\u7aefIBN\u3002", "conclusion": "LLM\u5728IBN\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9700\u8981NetIntent\u8fd9\u6837\u7684\u6846\u67b6\u6765\u6574\u5408\u5176\u80fd\u529b\uff0c\u4ee5\u5b9e\u73b0\u5b8c\u5168\u81ea\u4e3b\u7684IBN\u6d41\u7a0b\u3002"}}
{"id": "2507.14516", "pdf": "https://arxiv.org/pdf/2507.14516", "abs": "https://arxiv.org/abs/2507.14516", "authors": ["Jeyoung Lee", "Hochul Kang"], "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": null, "summary": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware\nmetric function for time series self-supervised representation learning. Most\nSelf-Supervised Learning (SSL) methods for signals commonly adopt\ndistance-based objectives such as mean squared error (MSE), which are sensitive\nto amplitude, invariant to waveform polarity, and unbounded in scale. These\nproperties hinder semantic alignment and reduce interpretability. SDSC\naddresses this by quantifying structural agreement between temporal signals\nbased on the intersection of signed amplitudes, derived from the Dice\nSimilarity Coefficient (DSC).Although SDSC is defined as a structure-aware\nmetric, it can be used as a loss by subtracting from 1 and applying a\ndifferentiable approximation of the Heaviside function for gradient-based\noptimization. A hybrid loss formulation is also proposed to combine SDSC with\nMSE, improving stability and preserving amplitude where necessary. Experiments\non forecasting and classification benchmarks demonstrate that SDSC-based\npre-training achieves comparable or improved performance over MSE, particularly\nin in-domain and low-resource scenarios. The results suggest that structural\nfidelity in signal representations enhances the semantic representation\nquality, supporting the consideration of structure-aware metrics as viable\nalternatives to conventional distance-based methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4fe1\u53f7\u9ab0\u5b50\u76f8\u4f3c\u7cfb\u6570\uff08SDSC\uff09\uff0c\u4e00\u79cd\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u7684\u7ed3\u6784\u611f\u77e5\u5ea6\u91cf\u51fd\u6570\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u8ddd\u79bb\u76ee\u6807\uff08\u5982MSE\uff09\u5728\u4fe1\u53f7SSL\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u4fe1\u53f7\u5904\u7406\u4e2d\u5e38\u7528MSE\u7b49\u8ddd\u79bb\u76ee\u6807\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u5e45\u5ea6\u654f\u611f\u4e14\u5ffd\u7565\u6ce2\u5f62\u6781\u6027\uff0c\u5f71\u54cd\u4e86\u8bed\u4e49\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u3002SDSC\u65e8\u5728\u901a\u8fc7\u91cf\u5316\u4fe1\u53f7\u7ed3\u6784\u4e00\u81f4\u6027\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "SDSC\u57fa\u4e8e\u9ab0\u5b50\u76f8\u4f3c\u7cfb\u6570\uff08DSC\uff09\uff0c\u901a\u8fc7\u8ba1\u7b97\u7b26\u53f7\u5e45\u5ea6\u7684\u4ea4\u96c6\u4f53\u73b0\u4fe1\u53f7\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u5e76\u53ef\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u3002\u6587\u4e2d\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408SDSC\u4e0eMSE\u7684\u6df7\u5408\u635f\u5931\uff0c\u4ee5\u5e73\u8861\u7a33\u5b9a\u6027\u548c\u5e45\u5ea6\u4fdd\u6301\u3002", "result": "\u5728\u9884\u6d4b\u548c\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eSDSC\u7684\u9884\u8bad\u7ec3\u8868\u73b0\u4e0eMSE\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u5c24\u5176\u662f\u5728\u57df\u5185\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u3002", "conclusion": "\u7ed3\u6784\u611f\u77e5\u5ea6\u91cf\uff08\u5982SDSC\uff09\u80fd\u63d0\u5347\u4fe1\u53f7\u8868\u793a\u7684\u8bed\u4e49\u8d28\u91cf\uff0c\u53ef\u4f5c\u4e3a\u4f20\u7edf\u8ddd\u79bb\u65b9\u6cd5\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.15797", "pdf": "https://arxiv.org/pdf/2507.15797", "abs": "https://arxiv.org/abs/2507.15797", "authors": ["John Burke", "Ciaran McGoldrick"], "title": "Deterministic Quantum Search via Recursive Oracle Expansion", "categories": ["quant-ph", "cs.ET", "81P68 (Primary), 68Q12 68Q25 (Secondary)", "F.1.2"], "comment": "11 pages, 3 figures. Data and code available on request", "summary": "We introduce a novel deterministic quantum search algorithm that provides a\npractical alternative to conventional probabilistic search approaches. Our\nscheme eliminates the inherent uncertainty of quantum search without relying on\narbitrary phase rotations, a key limitation of other deterministic methods. The\nalgorithm achieves certainty by recursively expanding the base oracle so that\nit marks all states prefixed by the same two bits as the target, encompassing\nexactly one-quarter of the search space. This enables a step-by-step reduction\nof the superposition until the target state can be measured with certainty. The\nalgorithm achieves deterministic success with a query complexity of\n$O(N^{\\log_2(3)/2}) \\approx O(N^{0.7925})$, falling between Grover's\n$O(\\sqrt{N})$ scaling and the classical $O(N)$. Our approach relies exclusively\non two-qubit nearest-neighbour diffusion operators, avoiding global diffusion\nentirely. We show that, despite the increased query complexity, this design\nreduces the total number of two-qubit gates required for diffusion by more than\nan order of magnitude for search spaces up to at least 18 qubits, with even\ngreater advantages on hardware with limited qubit connectivity. The scheme's\ninherent determinism, reliance on simple nearest-neighbour, low-depth\noperations, and scalable recursive structure make it well-suited for hardware\nimplementation. Additionally, we show that the algorithm naturally supports\npartial database search, enabling deterministic identification of selected\ntarget bits without requiring a full search, further broadening its\napplicability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u786e\u5b9a\u6027\u91cf\u5b50\u641c\u7d22\u7b97\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u6982\u7387\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u6269\u5c55\u57fa\u7840\u9884\u8a00\u673a\u5b9e\u73b0\u786e\u5b9a\u6027\u6d4b\u91cf\u3002", "motivation": "\u89e3\u51b3\u91cf\u5b50\u641c\u7d22\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u907f\u514d\u4f9d\u8d56\u4efb\u610f\u76f8\u4f4d\u65cb\u8f6c\uff0c\u9002\u5408\u786c\u4ef6\u5b9e\u73b0\u3002", "method": "\u9012\u5f52\u6269\u5c55\u9884\u8a00\u673a\uff0c\u9010\u6b65\u51cf\u5c11\u53e0\u52a0\u6001\uff0c\u4f7f\u7528\u6700\u8fd1\u90bb\u6269\u6563\u7b97\u5b50\u3002", "result": "\u7b97\u6cd5\u786e\u5b9a\u6027\u6210\u529f\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u4e3aO(N^0.7925)\uff0c\u51cf\u5c11\u4e86\u4e24\u6bd4\u7279\u95e8\u6570\u91cf\u3002", "conclusion": "\u7b97\u6cd5\u9002\u5408\u786c\u4ef6\u5b9e\u73b0\uff0c\u652f\u6301\u90e8\u5206\u6570\u636e\u5e93\u641c\u7d22\uff0c\u6269\u5c55\u4e86\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2507.15233", "pdf": "https://arxiv.org/pdf/2507.15233", "abs": "https://arxiv.org/abs/2507.15233", "authors": ["Jintao Liu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "title": "An ML-Driven Participant Selection Technique for Federated Recommendation System in Edge-Cloud Computing", "categories": ["cs.DC"], "comment": null, "summary": "Recommendation systems (RS) personalize content by analyzing user\npreferences, but typically require centralized collection of user data, raising\nprivacy and scalability concerns. Federated Recommendation Systems (FRS)\naddress these issues by enabling distributed, privacy-preserving model training\nacross edge devices, keeping raw data on-device. Although existing FRS\nframeworks benefit from on-device feature extraction and privacy preservation,\nthey suffer from heterogeneous device capabilities, non-independent and\nidentically distributed (non-IID) data, and communication bottlenecks. To\novercome these limitations, we propose a multi-objective reinforcement learning\n(RL) participant selection that jointly optimizes historical client performance\nreputation (CPR), data utility, and system efficiency. First, we define a\ncomposite client-utility function combining CPR, system capability, and data\nquality. Next, we embed this utility into a multi-armed bandit (MAB) framework\nand dynamically balance exploration-exploitation to select participants.\nFinally, we practically implement our approach using the PySyft framework on an\nedge-cloud testbed, and evaluate it on a multimodal movie-recommendation task\nbuilt from the MovieLens-100K dataset. Across four different skewed\ndata-partition scenarios, our MAB-based selection accelerates convergence by\n32-50% in time-to-target AUC and reduces total wall-clock training time by up\nto 46%, while matching or slightly improving final AUC, NDCG@50, and Recall@50\ncompared to existing FRS baselines. Our results demonstrate that adaptive,\nreward-driven client sampling can substantially enhance both efficiency and\nfairness in real-world federated deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u53c2\u4e0e\u8005\u9009\u62e9\u65b9\u6cd5\uff0c\u4f18\u5316\u5ba2\u6237\u7aef\u6027\u80fd\u3001\u6570\u636e\u6548\u7528\u548c\u7cfb\u7edf\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u9690\u79c1\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u867d\u80fd\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u4ecd\u9762\u4e34\u8bbe\u5907\u5f02\u6784\u6027\u3001\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u548c\u901a\u4fe1\u74f6\u9888\u7684\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u590d\u5408\u5ba2\u6237\u7aef\u6548\u7528\u51fd\u6570\uff0c\u7ed3\u5408\u5386\u53f2\u8868\u73b0\u3001\u7cfb\u7edf\u80fd\u529b\u548c\u6570\u636e\u8d28\u91cf\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\uff0c\u52a8\u6001\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u4ee5\u9009\u62e9\u53c2\u4e0e\u8005\u3002", "result": "\u5728\u56db\u79cd\u6570\u636e\u5206\u5e03\u4e0d\u5747\u7684\u573a\u666f\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c06\u6536\u655b\u65f6\u95f4\u7f29\u77ed32-50%\uff0c\u603b\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1146%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "\u81ea\u9002\u5e94\u3001\u5956\u52b1\u9a71\u52a8\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u7684\u6548\u7387\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2507.14859", "pdf": "https://arxiv.org/pdf/2507.14859", "abs": "https://arxiv.org/abs/2507.14859", "authors": ["Nils Mandischer", "Alexander Atanasyan", "Ulrich Dahmen", "Michael Schluse", "J\u00fcrgen Rossmann", "Lars Mikelsons"], "title": "Holistic Specification of the Human Digital Twin: Stakeholders, Users, Functionalities, and Applications", "categories": ["cs.HC", "cs.SY", "eess.SY"], "comment": "This work was accepted by the IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC), Vienna, Austria, 2025", "summary": "The digital twin of humans is a relatively new concept. While many diverse\ndefinitions, architectures, and applications exist, a clear picture is missing\non what, in fact, makes a human digital twin. Within this context, researchers\nand industrial use-case owners alike are unaware about the market potential of\nthe - at the moment - rather theoretical construct. In this work, we draw a\nholistic vision of the human digital twin, and derive the specification of this\nholistic human digital twin in form of requirements, stakeholders, and users.\nFor each group of users, we define exemplary applications that fall into the\nsix levels of functionality: store, analyze, personalize, predict, control, and\noptimize. The functionality levels facilitate an abstraction of abilities of\nthe human digital twin. From the manifold applications, we discuss three in\ndetail to showcase the feasibility of the abstraction levels and the analysis\nof stakeholders and users. Based on the deep discussion, we derive a\ncomprehensive list of requirements on the holistic human digital twin. These\nconsiderations shall be used as a guideline for research and industries for the\nimplementation of human digital twins, particularly in context of reusability\nin multiple target applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u4eba\u7c7b\u6570\u5b57\u5b6a\u751f\u6982\u5ff5\uff0c\u660e\u786e\u4e86\u5176\u5b9a\u4e49\u3001\u529f\u80fd\u5c42\u7ea7\uff08\u5b58\u50a8\u3001\u5206\u6790\u3001\u4e2a\u6027\u5316\u3001\u9884\u6d4b\u3001\u63a7\u5236\u548c\u4f18\u5316\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\u548c\u5e02\u573a\u6f5c\u529b\u3002", "motivation": "\u4eba\u7c7b\u6570\u5b57\u5b6a\u751f\u662f\u4e00\u4e2a\u65b0\u5174\u4f46\u5b9a\u4e49\u6a21\u7cca\u7684\u6982\u5ff5\uff0c\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5176\u5e02\u573a\u6f5c\u529b\u548c\u5b9e\u9645\u5e94\u7528\u7684\u6e05\u6670\u8ba4\u8bc6\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5168\u9762\u7684\u613f\u666f\uff0c\u5b9a\u4e49\u529f\u80fd\u5c42\u7ea7\u3001\u5229\u76ca\u76f8\u5173\u8005\u548c\u7528\u6237\u7fa4\u4f53\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u7684\u5e94\u7528\u6848\u4f8b\u9a8c\u8bc1\u62bd\u8c61\u5c42\u7ea7\u7684\u53ef\u884c\u6027\u3002", "result": "\u4ece\u8be6\u7ec6\u8ba8\u8bba\u4e2d\u5f97\u51fa\u4e86\u4eba\u7c7b\u6570\u5b57\u5b6a\u751f\u7684\u5168\u9762\u9700\u6c42\u5217\u8868\uff0c\u4e3a\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "\u8bba\u6587\u4e3a\u4eba\u7c7b\u6570\u5b57\u5b6a\u751f\u7684\u5b9e\u73b0\u63d0\u4f9b\u4e86\u6307\u5357\uff0c\u7279\u522b\u662f\u5728\u591a\u76ee\u6807\u5e94\u7528\u4e2d\u7684\u53ef\u91cd\u7528\u6027\u65b9\u9762\u3002"}}
{"id": "2507.14770", "pdf": "https://arxiv.org/pdf/2507.14770", "abs": "https://arxiv.org/abs/2507.14770", "authors": ["Manaal Basha", "Ivan Beschastnikh", "Gema Rodriguez-Perez", "Cleidson R. B. de Souza"], "title": "Toward Inclusive AI-Driven Development: Exploring Gender Differences in Code Generation Tool Interactions", "categories": ["cs.SE"], "comment": "ESEM 2025 Registered Reports", "summary": "Context: The increasing reliance on Code Generation Tools (CGTs), such as\nWindsurf and GitHub Copilot, are revamping programming workflows and raising\ncritical questions about fairness and inclusivity. While CGTs offer potential\nproductivity enhancements, their effectiveness across diverse user groups have\nnot been sufficiently investigated. Objectives: We hypothesize that developers'\ninteractions with CGTs vary based on gender, influencing task outcomes and\ncognitive load, as prior research suggests that gender differences can affect\ntechnology use and cognitive processing. Methods: The study will employ a\nmixed-subjects design with 54 participants, evenly divided by gender for a\ncounterbalanced design. Participants will complete two programming tasks\n(medium to hard difficulty) with only CGT assistance and then with only\ninternet access. Task orders and conditions will be counterbalanced to mitigate\norder effects. Data collection will include cognitive load surveys, screen\nrecordings, and task performance metrics such as completion time, code\ncorrectness, and CGT interaction behaviors. Statistical analyses will be\nconducted to identify statistically significant differences in CGT usage.\nExpected Contributions: Our work can uncover gender differences in CGT\ninteraction and performance among developers. Our findings can inform future\nCGT designs and help address usability and potential disparities in interaction\npatterns across diverse user groups. Conclusion: While results are not yet\navailable, our proposal lays the groundwork for advancing fairness,\naccountability, transparency, and ethics (FATE) in CGT design. The outcomes are\nanticipated to contribute to inclusive AI practices and equitable tool\ndevelopment for all users.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4ee3\u7801\u751f\u6210\u5de5\u5177\uff08CGTs\uff09\u5bf9\u4e0d\u540c\u6027\u522b\u5f00\u53d1\u8005\u4f7f\u7528\u6548\u679c\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u63ed\u793a\u6027\u522b\u5dee\u5f02\u5e76\u63a8\u52a8\u5de5\u5177\u8bbe\u8ba1\u7684\u516c\u5e73\u6027\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u751f\u6210\u5de5\u5177\u7684\u666e\u53ca\uff0c\u5176\u516c\u5e73\u6027\u548c\u5305\u5bb9\u6027\u95ee\u9898\u65e5\u76ca\u51f8\u663e\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u672a\u5145\u5206\u63a2\u7a76\u5de5\u5177\u5bf9\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u6548\u679c\u5dee\u5f02\u3002", "method": "\u91c7\u7528\u6df7\u5408\u5b9e\u9a8c\u8bbe\u8ba1\uff0c54\u540d\u6027\u522b\u5747\u8861\u7684\u53c2\u4e0e\u8005\u5b8c\u6210\u7f16\u7a0b\u4efb\u52a1\uff0c\u6570\u636e\u5305\u62ec\u8ba4\u77e5\u8d1f\u8377\u3001\u4efb\u52a1\u8868\u73b0\u53ca\u5de5\u5177\u4ea4\u4e92\u884c\u4e3a\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u9884\u671f\u63ed\u793aCGTs\u4f7f\u7528\u4e2d\u7684\u6027\u522b\u5dee\u5f02\uff0c\u4e3a\u5de5\u5177\u8bbe\u8ba1\u548c\u5305\u5bb9\u6027AI\u5b9e\u8df5\u63d0\u4f9b\u4f9d\u636e\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347CGTs\u7684\u516c\u5e73\u6027\u3001\u900f\u660e\u6027\u548c\u4f26\u7406\u8bbe\u8ba1\u5960\u5b9a\u57fa\u7840\uff0c\u63a8\u52a8\u9762\u5411\u6240\u6709\u7528\u6237\u7684\u5e73\u7b49\u5de5\u5177\u5f00\u53d1\u3002"}}
{"id": "2507.14512", "pdf": "https://arxiv.org/pdf/2507.14512", "abs": "https://arxiv.org/abs/2507.14512", "authors": ["Qiyuan Peng", "Qi Zhang", "Yue Gao", "Kun Qiu"], "title": "Dora: A Controller Provisioning Strategy in Hierarchical Domain-based Satellite Networks", "categories": ["cs.NI"], "comment": null, "summary": "The rapid proliferation of satellite constellations in Space-Air-Ground\nIntegrated Networks (SAGIN) presents significant challenges for network\nmanagement. Conventional flat network architectures struggle with\nsynchronization and data transmission across massive distributed nodes. In\nresponse, hierarchical domain-based satellite network architectures have\nemerged as a scalable solution, highlighting the critical importance of\ncontroller provisioning strategies. However, existing network management\narchitectures and traditional search-based algorithms fail to generate\nefficient controller provisioning solutions due to limited computational\nresources in satellites and strict time constraints. To address these\nchallenges, we propose a three-layer domain-based architecture that enhances\nboth scalability and adaptability. Furthermore, we introduce Dora, a\nreinforcement learning-based controller provisioning strategy designed to\noptimize network performance while minimizing computational overhead. Our\ncomprehensive experimental evaluation demonstrates that Dora significantly\noutperforms state-of-the-art benchmarks, achieving 10% improvement in\ncontroller provisioning quality while requiring only 1/30 to 1/90 of the\ncomputation time compared to traditional algorithms. These results underscore\nthe potential of reinforcement learning approaches for efficient satellite\nnetwork management in next-generation SAGIN deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a7\u5236\u5668\u914d\u7f6e\u7b56\u7565\uff08Dora\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u536b\u661f\u7f51\u7edc\u4e2d\u7684\u7ba1\u7406\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u536b\u661f\u7f51\u7edc\u4e2d\u4f20\u7edf\u7f51\u7edc\u7ba1\u7406\u67b6\u6784\u548c\u641c\u7d22\u7b97\u6cd5\u5728\u8ba1\u7b97\u8d44\u6e90\u548c\u65f6\u95f4\u9650\u5236\u4e0b\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u57df\u57fa\u67b6\u6784\u548c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff08Dora\uff09\u4f18\u5316\u63a7\u5236\u5668\u914d\u7f6e\u3002", "result": "Dora\u5728\u63a7\u5236\u5668\u914d\u7f6e\u8d28\u91cf\u4e0a\u63d0\u5347\u4e8610%\uff0c\u4e14\u8ba1\u7b97\u65f6\u95f4\u4ec5\u4e3a\u4f20\u7edf\u7b97\u6cd5\u76841/30\u52301/90\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4e0b\u4e00\u4ee3SAGIN\u536b\u661f\u7f51\u7edc\u7ba1\u7406\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.14962", "pdf": "https://arxiv.org/pdf/2507.14962", "abs": "https://arxiv.org/abs/2507.14962", "authors": ["Johannes Schmidt", "Mohamed Maizia", "Victor Lagerkvist", "Johannes K. Fichte"], "title": "Complexity of Faceted Explanations in Propositional Abduction", "categories": ["cs.AI", "cs.CC", "cs.LO"], "comment": "This is the author's self-archived copy including detailed proofs. To\n  appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the\n  41st International Conference on Logic Programming (ICLP 2025)", "summary": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain\nobserved symptoms and manifestations. It has many applications, such as\ndiagnosis and planning in artificial intelligence and database updates. In\npropositional abduction, we focus on specifying knowledge by a propositional\nformula. The computational complexity of tasks in propositional abduction has\nbeen systematically characterized - even with detailed classifications for\nBoolean fragments. Unsurprisingly, the most insightful reasoning problems\n(counting and enumeration) are computationally highly challenging. Therefore,\nwe consider reasoning between decisions and counting, allowing us to understand\nexplanations better while maintaining favorable complexity. We introduce facets\nto propositional abductions, which are literals that occur in some explanation\n(relevant) but not all explanations (dispensable). Reasoning with facets\nprovides a more fine-grained understanding of variability in explanations\n(heterogeneous). In addition, we consider the distance between two\nexplanations, enabling a better understanding of heterogeneity/homogeneity. We\ncomprehensively analyze facets of propositional abduction in various settings,\nincluding an almost complete characterization in Post's framework.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u547d\u9898\u6eaf\u56e0\u4e2d\u7684\u7cbe\u7ec6\u5316\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u201c\u65b9\u9762\u201d\u6982\u5ff5\u548c\u5206\u6790\u89e3\u91ca\u95f4\u7684\u8ddd\u79bb\uff0c\u63d0\u51fa\u4e86\u5bf9\u89e3\u91ca\u591a\u6837\u6027\u7684\u66f4\u6df1\u5165\u7406\u89e3\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u547d\u9898\u6eaf\u56e0\u4e2d\u9ad8\u590d\u6742\u5ea6\u63a8\u7406\u95ee\u9898\uff08\u5982\u8ba1\u6570\u548c\u679a\u4e3e\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u590d\u6742\u5ea6\u3002", "method": "\u5f15\u5165\u201c\u65b9\u9762\u201d\uff08\u5728\u90e8\u5206\u89e3\u91ca\u4e2d\u51fa\u73b0\u4f46\u975e\u5168\u90e8\u89e3\u91ca\u4e2d\u51fa\u73b0\u7684\u5b57\u9762\u91cf\uff09\u548c\u89e3\u91ca\u95f4\u8ddd\u79bb\u5206\u6790\u3002", "result": "\u5728Post\u6846\u67b6\u4e2d\u51e0\u4e4e\u5b8c\u5168\u8868\u5f81\u4e86\u547d\u9898\u6eaf\u56e0\u7684\u5404\u4e2a\u65b9\u9762\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u7ec6\u5316\u63a8\u7406\u65b9\u6cd5\uff0c\u66f4\u597d\u5730\u7406\u89e3\u4e86\u547d\u9898\u6eaf\u56e0\u7684\u89e3\u91ca\u591a\u6837\u6027\uff0c\u5e76\u4fdd\u6301\u4e86\u8f83\u4f4e\u7684\u590d\u6742\u5ea6\u3002"}}
{"id": "2507.15553", "pdf": "https://arxiv.org/pdf/2507.15553", "abs": "https://arxiv.org/abs/2507.15553", "authors": ["Shibo Yu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "title": "Efficient Routing of Inference Requests across LLM Instances in Cloud-Edge Computing", "categories": ["cs.DC"], "comment": null, "summary": "The rising demand for Large Language Model (LLM) inference services has\nintensified pressure on computational resources, resulting in latency and cost\nchallenges. This paper introduces a novel routing algorithm based on the\nNon-dominated Sorting Genetic Algorithm II (NSGA-II) to distribute inference\nrequests across heterogeneous LLM instances in a cloud-edge computing\nenvironment. Formulated as a multi-objective optimization problem, the\nalgorithm balances response quality, response time, and inference cost,\nadapting to request heterogeneity (e.g., varying complexity and prompt lengths)\nand node diversity (e.g., edge vs. cloud resources). This adaptive routing\nalgorithm optimizes performance under dynamic workloads. We benchmark the\napproach using a testbed with datasets including Stanford Question Answering\nDataset (SQuAD), Mostly Basic Python Problems (MBPP), Hella Situations With\nAdversarial Generations (HellaSwag), and Grade School Math 8K (GSM8K).\nExperimental results show our solution, compared to the baselines, achieves up\nto 95.2% and 34.9% improvements in terms of response time and cost,\nrespectively. These findings validate the algorithm's effectiveness for\nscalable LLM deployments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eNSGA-II\u7684\u8def\u7531\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u4e91\u8fb9\u8ba1\u7b97\u73af\u5883\u4e2d\u5206\u914dLLM\u63a8\u7406\u8bf7\u6c42\uff0c\u4f18\u5316\u54cd\u5e94\u8d28\u91cf\u3001\u65f6\u95f4\u548c\u6210\u672c\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u63a8\u7406\u670d\u52a1\u7684\u9700\u6c42\u589e\u957f\u5e26\u6765\u4e86\u8ba1\u7b97\u8d44\u6e90\u538b\u529b\u548c\u5ef6\u8fdf\u6210\u672c\u6311\u6218\uff0c\u9700\u8981\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528NSGA-II\u4f5c\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u7b97\u6cd5\uff0c\u52a8\u6001\u5206\u914d\u8bf7\u6c42\u5230\u5f02\u6784LLM\u5b9e\u4f8b\uff0c\u5e73\u8861\u54cd\u5e94\u8d28\u91cf\u3001\u65f6\u95f4\u548c\u6210\u672c\u3002", "result": "\u5728SQuAD\u7b49\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u54cd\u5e94\u65f6\u95f4\u548c\u6210\u672c\u5206\u522b\u63d0\u534795.2%\u548c34.9%\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u6709\u6548\u652f\u6301\u53ef\u6269\u5c55\u7684LLM\u90e8\u7f72\uff0c\u9002\u5e94\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u3002"}}
{"id": "2507.14944", "pdf": "https://arxiv.org/pdf/2507.14944", "abs": "https://arxiv.org/abs/2507.14944", "authors": ["Boning Zhao", "Yutong Hu"], "title": "LEKIA: A Framework for Architectural Alignment via Expert Knowledge Injection", "categories": ["cs.HC"], "comment": null, "summary": "Deploying Large Language Models (LLMs) in high-stakes domains is impeded by a\ndual challenge: the need for deep, dynamic expert knowledge injection and\nnuanced value alignment. Prevailing paradigms often address these challenges\nseparately, creating a persistent tension between knowledge and alignment;\nknowledge-focused methods like Retrieval-Augmented Generation (RAG) have\nlimited deep alignment capabilities, while alignment-focused methods like\nReinforcement Learning from Human Feedback (RLHF) struggle with the agile\ninjection of expert wisdom. This paper introduces a new collaborative\nphilosophy, Expert-owned AI behavior design, realized through Architectural\nAlignment-a paradigm that unifies these two goals within a single framework\ncalled the Layered Expert Knowledge Injection Architecture (LEKIA). LEKIA\noperates as an intelligent intermediary that guides an LLM's reasoning process\nwithout altering its weights, utilizing a three-tiered structure: a Theoretical\nLayer for core principles, a Practical Layer for exemplary cases, and an\nEvaluative Layer for real-time, value-aligned self-correction. We demonstrate\nthe efficacy of this paradigm through the successful implementation of a\nLEKIA-based psychological support assistant for the special education field.\nOur work presents a path toward more responsible and expert-driven AI,\nempowering domain specialists to directly architect AI behavior and resolve the\ntension between knowledge and alignment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLEKIA\u7684\u65b0\u67b6\u6784\uff0c\u65e8\u5728\u7edf\u4e00\u77e5\u8bc6\u6ce8\u5165\u548c\u4ef7\u503c\u5bf9\u9f50\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u4e2d\u7684\u53cc\u91cd\u6311\u6218\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u52a8\u6001\u7684\u4e13\u5bb6\u77e5\u8bc6\u6ce8\u5165\u548c\u7ec6\u81f4\u7684\u4ef7\u503c\u5bf9\u9f50\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u517c\u987e\u4e8c\u8005\u3002", "method": "\u901a\u8fc7LEKIA\u67b6\u6784\u5b9e\u73b0\uff0c\u5305\u62ec\u7406\u8bba\u5c42\u3001\u5b9e\u8df5\u5c42\u548c\u8bc4\u4f30\u5c42\uff0c\u4e0d\u6539\u53d8\u6a21\u578b\u6743\u91cd\uff0c\u5f15\u5bfc\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLEKIA\u7684\u5fc3\u7406\u652f\u6301\u52a9\u624b\uff0c\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u7684\u6709\u6548\u6027\u3002", "conclusion": "LEKIA\u4e3a\u4e13\u5bb6\u63d0\u4f9b\u4e86\u76f4\u63a5\u8bbe\u8ba1AI\u884c\u4e3a\u7684\u9014\u5f84\uff0c\u89e3\u51b3\u4e86\u77e5\u8bc6\u4e0e\u5bf9\u9f50\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u63a8\u52a8\u4e86\u66f4\u8d1f\u8d23\u4efb\u548c\u4e13\u5bb6\u9a71\u52a8\u7684AI\u53d1\u5c55\u3002"}}
{"id": "2507.14776", "pdf": "https://arxiv.org/pdf/2507.14776", "abs": "https://arxiv.org/abs/2507.14776", "authors": ["Kimia Tasnia", "Alexander Garcia", "Tasnuva Farheen", "Sazadur Rahman"], "title": "VeriOpt: PPA-Aware High-Quality Verilog Generation via Multi-Role LLMs", "categories": ["cs.SE"], "comment": "9 pages, 7 figures, Accepted for ICCAD 2025, Munich, Germany", "summary": "The rapid adoption of large language models(LLMs) in hardware design has\nprimarily focused on generating functionally correct Verilog code, overlooking\ncritical Power Performance-Area(PPA) metrics essential for industrial-grade\ndesigns. To bridge this gap, we propose VeriOpt, a novel framework that\nleverages role-based prompting and PPA-aware optimization to enable LLMs to\nproduce high-quality, synthesizable Verilog. VeriOpt structures LLM\ninteractions into specialized roles (e.g., Planner, Programmer, Reviewer,\nEvaluator) to emulate human design workflows, while integrating PPA constraints\ndirectly into the prompting pipeline. By combining multi-modal feedback (e.g.,\nsynthesis reports, timing diagrams) with PPA aware prompting, VeriOpt achieves\nPPA-efficient code generation without sacrificing functional correctness.\nExperimental results demonstrate up to 88% reduction in power, 76% reduction in\narea and 73% improvement in timing closure compared to baseline LLM-generated\nRTL, validated using industry standard EDA tools. At the same time achieves 86%\nsuccess rate in functionality evaluation. Our work advances the\nstate-of-the-art AI-driven hardware design by addressing the critical gap\nbetween correctness and quality, paving the way for reliable LLM adoption in\nproduction workflows.", "AI": {"tldr": "VeriOpt \u662f\u4e00\u4e2a\u5229\u7528\u89d2\u8272\u5206\u5de5\u548c PPA \u4f18\u5316\u7684\u6846\u67b6\uff0c\u4f7f\u5f97\u5927\u6a21\u578b\u751f\u6210\u7684 Verilog \u4ee3\u7801\u6ee1\u8db3\u5de5\u4e1a\u7ea7\u8bbe\u8ba1\u7684 PPA \u8981\u6c42\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u6a21\u578b\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u4e3b\u8981\u5173\u6ce8\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u5173\u952e\u7684 PPA \u6307\u6807\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5de5\u4e1a\u7ea7\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u89d2\u8272\u5206\u5de5\uff08Planner\u3001Programmer \u7b49\uff09\u6a21\u62df\u4eba\u7c7b\u8bbe\u8ba1\u6d41\u7a0b\uff0c\u5e76\u5229\u7528 PPA \u7ea6\u675f\u4f18\u5316\u63d0\u793a\u7ba1\u9053\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u53cd\u9988\u5b9e\u73b0\u9ad8\u6548\u4ee3\u7801\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u663e\u793a VeriOpt \u5728\u529f\u8017\u3001\u9762\u79ef\u548c\u65f6\u5e8f\u4e0a\u6709\u663e\u8457\u6539\u8fdb\uff0c\u529f\u80fd\u6d4b\u8bd5\u6210\u529f\u7387\u8fbe 86%\u3002", "conclusion": "VeriOpt \u89e3\u51b3\u4e86\u529f\u80fd\u6b63\u786e\u6027\u4e0e\u8bbe\u8ba1\u8d28\u91cf\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u5927\u6a21\u578b\u5728\u5de5\u4e1a\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.14627", "pdf": "https://arxiv.org/pdf/2507.14627", "abs": "https://arxiv.org/abs/2507.14627", "authors": ["Kaiqiang Lin", "Yijie Mao", "Onel Luis Alcaraz L\u00f3pez", "Mohamed-Slim Alouini"], "title": "UAV-Enabled Wireless-Powered Underground Communication Networks: A Novel Time Allocation Approach", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": "14 pages, 8 figures, 3 tables, submitted to IEEE TGCN", "summary": "Wireless-powered underground communication networks (WPUCNs), which allow\nunderground devices (UDs) to harvest energy from wireless signals for\nbattery-free communication, offer a promising solution for sustainable\nunderground monitoring. However, the severe wireless signal attenuation in\nchallenging underground environments and the costly acquisition of channel\nstate information (CSI) make large-scale WPUCNs economically infeasible in\npractice. To address this challenge, we introduce flexible unmanned aerial\nvehicles (UAVs) into WPUCNs, leading to UAV-enabled WPUCN systems. In this\nsystem, a UAV is first charged by a terrestrial hybrid access point (HAP), then\nflies to the monitoring area to wirelessly charge UDs. Afterwards, the UAV\ncollects data from the UDs and finally returns to the HAP for data offloading.\nBased on the proposed UAV-enabled WPUCN system, we first propose its energy\nconsumption model and a hybrid wireless energy transfer (WET) approach (i.e.,\nUDs can harvest energy from both the HAP and the UAV) relying on full-CSI and\nCSI-free multi-antenna beamforming. Then, we formulate and address a time\nallocation problem to minimize the energy consumption of UAV, while ensuring\nthat the throughput requirements of all UDs are met and all sensor data is\noffloaded. Through simulations of a realistic farming scenario, we demonstrate\nthat the proposed hybrid WET approach outperforms other WET approaches, with\nperformance gains influenced by the number of antennas, communication distance,\nnumber of UDs, and underground conditions. Additionally, under the optimized\ntime allocation, we found that the proposed hybrid WET approach based on a\nCSI-free multi-antenna scheme achieves the lowest UAV's energy consumption\namong all WET mechanisms, thereby enabling sustainable underground monitoring\nin WPUCNs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u7684\u65e0\u7ebf\u4f9b\u80fd\u5730\u4e0b\u901a\u4fe1\u7f51\u7edc\u7cfb\u7edf\uff0c\u901a\u8fc7\u6df7\u5408\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u548c\u65f6\u95f4\u5206\u914d\u4f18\u5316\uff0c\u964d\u4f4e\u4e86\u80fd\u91cf\u6d88\u8017\u5e76\u63d0\u5347\u4e86\u7cfb\u7edf\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u5730\u4e0b\u73af\u5883\u4e2d\u65e0\u7ebf\u4fe1\u53f7\u8870\u51cf\u4e25\u91cd\u4e14\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u6210\u672c\u9ad8\uff0c\u5927\u89c4\u6a21\u65e0\u7ebf\u4f9b\u80fd\u5730\u4e0b\u901a\u4fe1\u7f51\u7edc\u96be\u4ee5\u5b9e\u73b0\u7ecf\u6d4e\u53ef\u884c\u6027\u3002", "method": "\u5f15\u5165\u65e0\u4eba\u673a\u4f5c\u4e3a\u4e2d\u7ee7\uff0c\u91c7\u7528\u6df7\u5408\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u65b9\u6cd5\uff08\u7ed3\u5408\u57fa\u4e8eCSI\u548c\u65e0CSI\u7684\u591a\u5929\u7ebf\u6ce2\u675f\u6210\u5f62\uff09\u548c\u65f6\u95f4\u5206\u914d\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5728\u519c\u4e1a\u573a\u666f\u6a21\u62df\u4e2d\uff0c\u6df7\u5408\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u65b9\u6cd5\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u4e14\u57fa\u4e8e\u65e0CSI\u591a\u5929\u7ebf\u65b9\u6848\u7684\u80fd\u91cf\u6d88\u8017\u6700\u4f4e\u3002", "conclusion": "\u65e0\u4eba\u673a\u8f85\u52a9\u7684\u65e0\u7ebf\u4f9b\u80fd\u5730\u4e0b\u901a\u4fe1\u7f51\u7edc\u7cfb\u7edf\u80fd\u591f\u663e\u8457\u964d\u4f4e\u80fd\u91cf\u6d88\u8017\uff0c\u5b9e\u73b0\u4e86\u5730\u4e0b\u53ef\u6301\u7eed\u76d1\u6d4b\u3002"}}
{"id": "2507.15120", "pdf": "https://arxiv.org/pdf/2507.15120", "abs": "https://arxiv.org/abs/2507.15120", "authors": ["Stefan Borgwardt", "Duy Nhu", "Gabriele R\u00f6ger"], "title": "Automated planning with ontologies under coherence update semantics", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Standard automated planning employs first-order formulas under closed-world\nsemantics to achieve a goal with a given set of actions from an initial state.\nWe follow a line of research that aims to incorporate background knowledge into\nautomated planning problems, for example, by means of ontologies, which are\nusually interpreted under open-world semantics. We present a new approach for\nplanning with DL-Lite ontologies that combines the advantages of ontology-based\naction conditions provided by explicit-input knowledge and action bases (eKABs)\nand ontology-aware action effects under the coherence update semantics. We show\nthat the complexity of the resulting formalism is not higher than that of\nprevious approaches and provide an implementation via a polynomial compilation\ninto classical planning. An evaluation of existing and new benchmarks examines\nthe performance of a planning system on different variants of our compilation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408DL-Lite\u672c\u4f53\u77e5\u8bc6\u7684\u65b0\u89c4\u5212\u65b9\u6cd5\uff0c\u5229\u7528\u663e\u5f0f\u8f93\u5165\u77e5\u8bc6\uff08eKABs\uff09\u548c\u4e00\u81f4\u6027\u66f4\u65b0\u8bed\u4e49\uff0c\u5c06\u590d\u6742\u6027\u63a7\u5236\u5728\u5148\u524d\u65b9\u6cd5\u6c34\u5e73\uff0c\u5e76\u901a\u8fc7\u591a\u9879\u5f0f\u7f16\u8bd1\u5b9e\u73b0\u3002", "motivation": "\u5c06\u80cc\u666f\u77e5\u8bc6\uff08\u5982\u672c\u4f53\uff09\u878d\u5165\u81ea\u52a8\u5316\u89c4\u5212\u95ee\u9898\uff0c\u63d0\u5347\u89c4\u5212\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u663e\u5f0f\u8f93\u5165\u77e5\u8bc6\u548c\u4e00\u81f4\u6027\u66f4\u65b0\u8bed\u4e49\uff0c\u8bbe\u8ba1\u65b0\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u591a\u9879\u5f0f\u7f16\u8bd1\u5b9e\u73b0\u3002", "result": "\u65b0\u65b9\u6cd5\u7684\u590d\u6742\u5ea6\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\uff0c\u7f16\u8bd1\u5b9e\u73b0\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6574\u5408\u672c\u4f53\u77e5\u8bc6\uff0c\u4e3a\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14179", "pdf": "https://arxiv.org/pdf/2507.14179", "abs": "https://arxiv.org/abs/2507.14179", "authors": ["Nobel Dhar", "Bobin Deng", "Md Romyull Islam", "Xinyue Zhang", "Kazi Fahim Ahmad Nasif", "Kun Suo"], "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": "To be published in Euro-Par 2025", "summary": "Large Language Models (LLMs) exhibit significant activation sparsity, where\nonly a subset of neurons are active for a given input. Although this sparsity\npresents opportunities to reduce computational cost, efficiently utilizing it\nrequires predicting activation patterns in a scalable manner. However, direct\nprediction at the neuron level is computationally expensive due to the vast\nnumber of neurons in modern LLMs. To enable efficient prediction and\nutilization of activation sparsity, we propose a clustering-based activation\npattern compression framework. Instead of treating each neuron independently,\nwe group similar activation patterns into a small set of representative\nclusters. Our method achieves up to 79.34% clustering precision, outperforming\nstandard binary clustering approaches while maintaining minimal degradation in\nperplexity (PPL) scores. With a sufficiently large number of clusters, our\napproach attains a PPL score as low as 12.49, demonstrating its effectiveness\nin preserving model quality while reducing computational overhead. By\npredicting cluster assignments rather than individual neuron states, future\nmodels can efficiently infer activation patterns from pre-computed centroids.\nWe detail the clustering algorithm, analyze its effectiveness in capturing\nmeaningful activation structures, and demonstrate its potential to improve\nsparse computation efficiency. This clustering-based formulation serves as a\nfoundation for future work on activation pattern prediction, paving the way for\nefficient inference in large-scale language models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u4e3a\u5c11\u91cf\u4ee3\u8868\u6027\u805a\u7c7b\uff0c\u6709\u6548\u9884\u6d4b\u548c\u5229\u7528LLMs\u4e2d\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b58\u5728\u663e\u8457\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u76f4\u63a5\u9884\u6d4b\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u9884\u6d4b\u548c\u5229\u7528\u6fc0\u6d3b\u7a00\u758f\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u805a\u7c7b\u6846\u67b6\uff0c\u5c06\u76f8\u4f3c\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u4e3a\u5c11\u91cf\u4ee3\u8868\u6027\u805a\u7c7b\uff0c\u800c\u975e\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u795e\u7ecf\u5143\u3002\u901a\u8fc7\u9884\u6d4b\u805a\u7c7b\u5206\u914d\u800c\u975e\u5355\u4e2a\u795e\u7ecf\u5143\u72b6\u6001\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002\u8be6\u7ec6\u63cf\u8ff0\u4e86\u805a\u7c7b\u7b97\u6cd5\u53ca\u5176\u6709\u6548\u6027\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u805a\u7c7b\u7cbe\u5ea6\u9ad8\u8fbe79.34%\uff0c\u4f18\u4e8e\u6807\u51c6\u4e8c\u503c\u805a\u7c7b\u65b9\u6cd5\uff0c\u4e14\u56f0\u60d1\u5ea6\uff08PPL\uff09\u4e0b\u964d\u6781\u5c0f\uff08\u6700\u4f4e\u4e3a12.49\uff09\uff0c\u6709\u6548\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6fc0\u6d3b\u6a21\u5f0f\u9884\u6d4b\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u671b\u63d0\u5347\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2507.14947", "pdf": "https://arxiv.org/pdf/2507.14947", "abs": "https://arxiv.org/abs/2507.14947", "authors": ["Ivan C. H. Liu", "Chung-En Hao", "Jing Xie"], "title": "Echoes of the Land: An Interactive Installation Based on Physical Model of Earthquake", "categories": ["cs.HC", "nlin.AO"], "comment": "7 pages, 8 figures, submitted to Leonardo", "summary": "Echoes of the Land is an interactive installation that transforms seismic\ndynamics into a multisensory experience through a scientifically grounded\nspring-block model. Simulating earthquake recurrence and self-organized\ncriticality, the work generates real-time sound and light via motion capture\nand concatenative granular synthesis. Each block acts as an agent, producing\nemergent audiovisual cascades that visualize the physics of rupture and\nthreshold behavior. This work exemplifies the amalgamation of scientific\nknowledge and artistic practice, opening new avenues for novel forms of musical\ninstrument and narrative medium, while inviting further investigation into the\nintersection of emergent complexity, aesthetics and interactivity.", "AI": {"tldr": "\u300aEchoes of the Land\u300b\u662f\u4e00\u4e2a\u5c06\u5730\u9707\u52a8\u529b\u5b66\u8f6c\u5316\u4e3a\u591a\u611f\u5b98\u4f53\u9a8c\u7684\u4ea4\u4e92\u88c5\u7f6e\uff0c\u901a\u8fc7\u5f39\u7c27\u5757\u6a21\u578b\u6a21\u62df\u5730\u9707\u91cd\u590d\u6027\u548c\u81ea\u7ec4\u7ec7\u4e34\u754c\u6027\u3002", "motivation": "\u8be5\u4f5c\u54c1\u65e8\u5728\u7ed3\u5408\u79d1\u5b66\u77e5\u8bc6\u4e0e\u827a\u672f\u5b9e\u8df5\uff0c\u63a2\u7d22\u65b0\u5174\u590d\u6742\u6027\u3001\u7f8e\u5b66\u548c\u4ea4\u4e92\u6027\u7684\u4ea4\u6c47\u70b9\u3002", "method": "\u5229\u7528\u5f39\u7c27\u5757\u6a21\u578b\u6a21\u62df\u5730\u9707\u52a8\u529b\u5b66\uff0c\u901a\u8fc7\u8fd0\u52a8\u6355\u6349\u548c\u7ea7\u8054\u9897\u7c92\u5408\u6210\u5b9e\u65f6\u751f\u6210\u58f0\u97f3\u548c\u5149\u6548\u3002", "result": "\u6bcf\u4e2a\u5757\u4f5c\u4e3a\u4ee3\u7406\uff0c\u4ea7\u751f\u7a81\u53d1\u7684\u89c6\u542c\u6548\u679c\uff0c\u53ef\u89c6\u5316\u65ad\u5c42\u548c\u9608\u503c\u884c\u4e3a\u7684\u7269\u7406\u73b0\u8c61\u3002", "conclusion": "\u4f5c\u54c1\u4e3a\u65b0\u578b\u4e50\u5668\u548c\u53d9\u4e8b\u5a92\u4ecb\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5e76\u6fc0\u53d1\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.14791", "pdf": "https://arxiv.org/pdf/2507.14791", "abs": "https://arxiv.org/abs/2507.14791", "authors": ["Yang Liu", "Li Zhang", "Fang Liu", "Zhuohang Wang", "Donglin Wei", "Zhishuo Yang", "Kechi Zhang", "Jia Li", "Lin Shi"], "title": "Enhancing Repository-Level Code Generation with Call Chain-Aware Multi-View Context", "categories": ["cs.SE"], "comment": null, "summary": "Repository-level code generation aims to generate code within the context of\na specified repository. Existing approaches typically employ\nretrieval-augmented generation (RAG) techniques to provide LLMs with relevant\ncontextual information extracted from the repository. However, these approaches\noften struggle with effectively identifying truly relevant contexts that\ncapture the rich semantics of the repository, and their contextual perspectives\nremains narrow. Moreover, most approaches fail to account for the structural\nrelationships in the retrieved code during prompt construction, hindering the\nLLM's ability to accurately interpret the context. To address these issues, we\npropose RepoScope, which leverages call chain-aware multi-view context for\nrepository-level code generation. RepoScope constructs a Repository Structural\nSemantic Graph (RSSG) and retrieves a comprehensive four-view context,\nintegrating both structural and similarity-based contexts. We propose a novel\ncall chain prediction method that utilizes the repository's structural\nsemantics to improve the identification of callees in the target function.\nAdditionally, we present a structure-preserving serialization algorithm for\nprompt construction, ensuring the coherence of the context for the LLM.\nNotably, RepoScope relies solely on static analysis, eliminating the need for\nadditional training or multiple LLM queries, thus ensuring both efficiency and\ngeneralizability. Evaluation on widely-used repository-level code generation\nbenchmarks (CoderEval and DevEval) demonstrates that RepoScope outperforms\nstate-of-the-art methods, achieving up to a 36.35% relative improvement in\npass@1 scores. Further experiments emphasize RepoScope's potential to improve\ncode generation across different tasks and its ability to integrate effectively\nwith existing approaches.", "AI": {"tldr": "RepoScope\u5229\u7528\u8c03\u7528\u94fe\u611f\u77e5\u7684\u591a\u89c6\u56fe\u4e0a\u4e0b\u6587\u89e3\u51b3\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u56fe\u548c\u56db\u89c6\u56fe\u4e0a\u4e0b\u6587\u63d0\u5347\u751f\u6210\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8bc6\u522b\u4ed3\u5e93\u7684\u4e30\u5bcc\u8bed\u4e49\u548c\u7ed3\u6784\u5173\u7cfb\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u4ee3\u7801\u8d28\u91cf\u53d7\u9650\u3002", "method": "\u6784\u5efa\u7ed3\u6784\u8bed\u4e49\u56fe\uff08RSSG\uff09\u548c\u56db\u89c6\u56fe\u4e0a\u4e0b\u6587\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u8c03\u7528\u94fe\u9884\u6d4b\uff0c\u4f18\u5316\u63d0\u793a\u6784\u9020\u3002", "result": "\u5728CoderEval\u548cDevEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cpass@1\u5206\u6570\u76f8\u5bf9\u63d0\u534736.35%\u3002", "conclusion": "RepoScope\u9ad8\u6548\u4e14\u901a\u7528\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2507.14633", "pdf": "https://arxiv.org/pdf/2507.14633", "abs": "https://arxiv.org/abs/2507.14633", "authors": ["Xiaozheng Gao", "Yichen Wang", "Bosen Liu", "Xiao Zhou", "Ruichen Zhang", "Jiacheng Wang", "Dusit Niyato", "Dong In Kim", "Abbas Jamalipour", "Chau Yuen", "Jianping An", "Kai Yang"], "title": "Agentic Satellite-Augmented Low-Altitude Economy and Terrestrial Networks: A Survey on Generative Approaches", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "The development of satellite-augmented low-altitude economy and terrestrial\nnetworks (SLAETNs) demands intelligent and autonomous systems that can operate\nreliably across heterogeneous, dynamic, and mission-critical environments. To\naddress these challenges, this survey focuses on enabling agentic artificial\nintelligence (AI), that is, artificial agents capable of perceiving, reasoning,\nand acting, through generative AI (GAI) and large language models (LLMs). We\nbegin by introducing the architecture and characteristics of SLAETNs, and\nanalyzing the challenges that arise in integrating satellite, aerial, and\nterrestrial components. Then, we present a model-driven foundation by\nsystematically reviewing five major categories of generative models:\nvariational autoencoders (VAEs), generative adversarial networks (GANs),\ngenerative diffusion models (GDMs), transformer-based models (TBMs), and LLMs.\nMoreover, we provide a comparative analysis to highlight their generative\nmechanisms, capabilities, and deployment trade-offs within SLAETNs. Building on\nthis foundation, we examine how these models empower agentic functions across\nthree domains: communication enhancement, security and privacy protection, and\nintelligent satellite tasks. Finally, we outline key future directions for\nbuilding scalable, adaptive, and trustworthy generative agents in SLAETNs. This\nsurvey aims to provide a unified understanding and actionable reference for\nadvancing agentic AI in next-generation integrated networks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u536b\u661f-\u4f4e\u7a7a\u7ecf\u6d4e\u4e0e\u5730\u9762\u7f51\u7edc\uff08SLAETNs\uff09\u4e2d\u5b9e\u73b0\u667a\u80fd\u81ea\u4e3b\u7cfb\u7edf\uff0c\u91cd\u70b9\u662f\u901a\u8fc7\u751f\u6210\u5f0fAI\uff08GAI\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u8d4b\u80fd\u5177\u6709\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\u80fd\u529b\u7684\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u3002", "motivation": "\u968f\u7740\u536b\u661f-\u4f4e\u7a7a\u7ecf\u6d4e\u4e0e\u5730\u9762\u7f51\u7edc\u7684\u53d1\u5c55\uff0c\u9700\u8981\u80fd\u591f\u5728\u5f02\u6784\u3001\u52a8\u6001\u548c\u4efb\u52a1\u5173\u952e\u73af\u5883\u4e2d\u53ef\u9760\u8fd0\u884c\u7684\u667a\u80fd\u81ea\u4e3b\u7cfb\u7edf\uff0c\u751f\u6210\u5f0fAI\u548cLLMs\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u8bba\u6587\u9996\u5148\u4ecb\u7ecd\u4e86SLAETNs\u7684\u67b6\u6784\u548c\u7279\u70b9\uff0c\u5206\u6790\u4e86\u96c6\u6210\u536b\u661f\u3001\u7a7a\u4e2d\u548c\u5730\u9762\u7ec4\u4ef6\u65f6\u7684\u6311\u6218\uff1b\u7136\u540e\u7cfb\u7edf\u56de\u987e\u4e86\u4e94\u7c7b\u751f\u6210\u6a21\u578b\uff08VAEs\u3001GANs\u3001GDMs\u3001TBMs\u3001LLMs\uff09\uff0c\u5e76\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u751f\u6210\u673a\u5236\u3001\u80fd\u529b\u548c\u90e8\u7f72\u6743\u8861\uff1b\u6700\u540e\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u901a\u4fe1\u589e\u5f3a\u3001\u5b89\u5168\u9690\u79c1\u4fdd\u62a4\u548c\u667a\u80fd\u536b\u661f\u4efb\u52a1\u4e09\u4e2a\u9886\u57df\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u6307\u51fa\u751f\u6210\u5f0fAI\u548cLLMs\u5728SLAETNs\u4e2d\u80fd\u591f\u6709\u6548\u8d4b\u80fd\u667a\u80fd\u4ee3\u7406\u529f\u80fd\uff0c\u5e76\u603b\u7ed3\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u4e0b\u4e00\u4ee3\u96c6\u6210\u7f51\u7edc\u4e2d\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u53ef\u4fe1\u7684\u751f\u6210\u5f0f\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u7edf\u4e00\u7406\u89e3\u548c\u53ef\u64cd\u4f5c\u7684\u53c2\u8003\u3002"}}
{"id": "2507.15156", "pdf": "https://arxiv.org/pdf/2507.15156", "abs": "https://arxiv.org/abs/2507.15156", "authors": ["Mykhailo Buleshnyi", "Anna Polova", "Zsolt Zombori", "Michael Benedikt"], "title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": null, "summary": "We investigate multi-label classification involving large sets of labels,\nwhere the output labels may be known to satisfy some logical constraints. We\nlook at an architecture in which classifiers for individual labels are fed into\nan expressive sequential model, which produces a joint distribution. One of the\npotential advantages for such an expressive model is its ability to modelling\ncorrelations, as can arise from constraints. We empirically demonstrate the\nability of the architecture both to exploit constraints in training and to\nenforce constraints at inference time.", "AI": {"tldr": "\u7814\u7a76\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898\uff0c\u5229\u7528\u8868\u8fbe\u6027\u5e8f\u5217\u6a21\u578b\u5904\u7406\u6807\u7b7e\u95f4\u7684\u903b\u8f91\u7ea6\u675f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u67b6\u6784\u80fd\u5229\u7528\u7ea6\u675f\u63d0\u5347\u5206\u7c7b\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u4e2d\u6709\u6548\u5229\u7528\u6807\u7b7e\u95f4\u7684\u903b\u8f91\u7ea6\u675f\uff0c\u4ee5\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e2a\u4f53\u6807\u7b7e\u5206\u7c7b\u5668\u4e0e\u8868\u8fbe\u6027\u5e8f\u5217\u6a21\u578b\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u751f\u6210\u8054\u5408\u5206\u5e03\u4ee5\u6355\u6349\u6807\u7b7e\u95f4\u7684\u76f8\u5173\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u67b6\u6784\u80fd\u591f\u6709\u6548\u5229\u7528\u8bad\u7ec3\u4e2d\u7684\u7ea6\u675f\uff0c\u5e76\u5728\u63a8\u7406\u9636\u6bb5\u5f3a\u5236\u6267\u884c\u7ea6\u675f\u3002", "conclusion": "\u63d0\u51fa\u7684\u67b6\u6784\u5728\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u80fd\u6709\u6548\u5229\u7528\u6807\u7b7e\u7ea6\u675f\uff0c\u63d0\u5347\u5206\u7c7b\u6548\u679c\u3002"}}
{"id": "2507.14322", "pdf": "https://arxiv.org/pdf/2507.14322", "abs": "https://arxiv.org/abs/2507.14322", "authors": ["Md Rafid Haque", "Abu Raihan Mostofa Kamal", "Md. Azam Hossain"], "title": "FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11; C.2.4; K.6.5"], "comment": "24 pages, 8 figures. This work is intended for a journal submission", "summary": "Federated Learning (FL) offers a paradigm for privacy-preserving\ncollaborative AI, but its decentralized nature creates significant\nvulnerabilities to model poisoning attacks. While numerous static defenses\nexist, their effectiveness is highly context-dependent, often failing against\nadaptive adversaries or in heterogeneous data environments. This paper\nintroduces FedStrategist, a novel meta-learning framework that reframes robust\naggregation as a real-time, cost-aware control problem. We design a lightweight\ncontextual bandit agent that dynamically selects the optimal aggregation rule\nfrom an arsenal of defenses based on real-time diagnostic metrics. Through\ncomprehensive experiments, we demonstrate that no single static rule is\nuniversally optimal. We show that our adaptive agent successfully learns\nsuperior policies across diverse scenarios, including a ``Krum-favorable\"\nenvironment and against a sophisticated \"stealth\" adversary designed to\nneutralize specific diagnostic signals. Critically, we analyze the paradoxical\nscenario where a non-robust baseline achieves high but compromised accuracy,\nand demonstrate that our agent learns a conservative policy to prioritize model\nintegrity. Furthermore, we prove the agent's policy is controllable via a\nsingle \"risk tolerance\" parameter, allowing practitioners to explicitly manage\nthe trade-off between performance and security. Our work provides a new,\npractical, and analyzable approach to creating resilient and intelligent\ndecentralized AI systems.", "AI": {"tldr": "FedStrategist\u662f\u4e00\u79cd\u65b0\u578b\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u6700\u4f73\u805a\u5408\u89c4\u5219\u6765\u5e94\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6a21\u578b\u6295\u6bd2\u653b\u51fb\uff0c\u4f18\u4e8e\u9759\u6001\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u7684\u53bb\u4e2d\u5fc3\u5316\u7279\u6027\u4f7f\u5176\u6613\u53d7\u6a21\u578b\u6295\u6bd2\u653b\u51fb\uff0c\u73b0\u6709\u9759\u6001\u9632\u5fa1\u65b9\u6cd5\u6548\u679c\u6709\u9650\u4e14\u4f9d\u8d56\u4e0a\u4e0b\u6587\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u9002\u5e94\u6027\u5f3a\u3001\u53ef\u52a8\u6001\u8c03\u6574\u7684\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4e0a\u4e0b\u6587\u5f3a\u76d7\u4ee3\u7406\uff0c\u5b9e\u65f6\u9009\u62e9\u6700\u4f18\u805a\u5408\u89c4\u5219\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u52a8\u6001\u7b56\u7565\u7684\u4f18\u8d8a\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a8\u6001\u4ee3\u7406\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5b66\u4e60\u5230\u66f4\u4f18\u7b56\u7565\uff0c\u5e76\u80fd\u901a\u8fc7\u5355\u4e00\u53c2\u6570\u63a7\u5236\u98ce\u9669\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002", "conclusion": "FedStrategist\u4e3a\u6784\u5efa\u5f39\u6027\u3001\u667a\u80fd\u7684\u53bb\u4e2d\u5fc3\u5316AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u5206\u6790\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14961", "pdf": "https://arxiv.org/pdf/2507.14961", "abs": "https://arxiv.org/abs/2507.14961", "authors": ["Katja Rogers"], "title": "Emphasizing Deliberation and Critical Thinking in an AI Hype World", "categories": ["cs.HC"], "comment": "Accepted at CHI 2025 workshop: \"Resisting AI Solutionism: Where Do We\n  Go From Here?\" (https://doi.org/10.1145/3706599.3706732)", "summary": "AI solutionism is accelerated and substantiated by hype and HCI's elevation\nof novelty. Banning or abandoning technology is unlikely to work and probably\nnot beneficial on the whole either -- but slow(er), deliberate use together\nwith conscientious, critical engagement and non-engagement may help us navigate\na post-AI hype world while contributing to a solid knowledge foundation and\nreducing harmful impacts in education and research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u5021\u5728AI\u70ed\u6f6e\u4e2d\u91c7\u53d6\u7f13\u6162\u3001\u6df1\u601d\u719f\u8651\u7684\u4f7f\u7528\u65b9\u5f0f\uff0c\u7ed3\u5408\u6279\u5224\u6027\u53c2\u4e0e\u6216\u4e0d\u53c2\u4e0e\uff0c\u4ee5\u51cf\u5c11\u5bf9\u6559\u80b2\u548c\u7814\u7a76\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9AI\u89e3\u51b3\u65b9\u6848\u4e3b\u4e49\u5728\u7092\u4f5c\u548cHCI\u5bf9\u65b0\u9896\u6027\u7684\u63a8\u5d07\u4e0b\u7684\u52a0\u901f\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5b8c\u5168\u7981\u6b62\u6216\u653e\u5f03\u6280\u672f\u5e76\u4e0d\u53ef\u884c\uff0c\u4e5f\u4e0d\u4e00\u5b9a\u6709\u76ca\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u7f13\u6162\u3001\u614e\u91cd\u7684\u4f7f\u7528\u65b9\u5f0f\uff0c\u8f85\u4ee5\u6279\u5224\u6027\u53c2\u4e0e\u6216\u4e0d\u53c2\u4e0e\uff0c\u6765\u5e94\u5bf9AI\u70ed\u6f6e\u3002", "result": "\u8fd9\u79cd\u7b56\u7565\u6709\u52a9\u4e8e\u5728AI\u70ed\u6f6e\u540e\u5efa\u7acb\u575a\u5b9e\u7684\u77e5\u8bc6\u57fa\u7840\uff0c\u5e76\u51cf\u5c11\u5bf9\u6559\u80b2\u548c\u7814\u7a76\u7684\u5371\u5bb3\u3002", "conclusion": "\u5728AI\u70ed\u6f6e\u4e2d\uff0c\u6162\u901f\u3001\u6279\u5224\u6027\u7684\u4f7f\u7528\u65b9\u5f0f\u6bd4\u5b8c\u5168\u7981\u6b62\u6280\u672f\u66f4\u5177\u53ef\u6301\u7eed\u6027\u548c\u6548\u76ca\u3002"}}
{"id": "2507.14969", "pdf": "https://arxiv.org/pdf/2507.14969", "abs": "https://arxiv.org/abs/2507.14969", "authors": ["Sai Zhang", "Zhenchang Xing", "Jieshan Chen", "Dehai Zhao", "Zizhong Zhu", "Xiaowang Zhang", "Zhiyong Feng", "Xiaohong Li"], "title": "Think Like an Engineer: A Neuro-Symbolic Collaboration Agent for Generative Software Requirements Elicitation and Self-Review", "categories": ["cs.SE", "D.2.1"], "comment": null, "summary": "The vision of End-User Software Engineering (EUSE) is to empower\nnon-professional users with full control over the software development\nlifecycle. It aims to enable users to drive generative software development\nusing only natural language requirements. However, since end-users often lack\nknowledge of software engineering, their requirement descriptions are\nfrequently ambiguous, raising significant challenges to generative software\ndevelopment. Although existing approaches utilize structured languages like\nGherkin to clarify user narratives, they still struggle to express the causal\nlogic between preconditions and behavior actions. This paper introduces\nRequireCEG, a requirement elicitation and self-review agent that embeds\ncausal-effect graphs (CEGs) in a neuro-symbolic collaboration architecture.\nRequireCEG first uses a feature tree to analyze user narratives hierarchically,\nclearly defining the scope of software components and their system behavior\nrequirements. Next, it constructs the self-healing CEGs based on the elicited\nrequirements, capturing the causal relationships between atomic preconditions\nand behavioral actions. Finally, the constructed CEGs are used to review and\noptimize Gherkin scenarios, ensuring consistency between the generated Gherkin\nrequirements and the system behavior requirements elicited from user\nnarratives. To evaluate our method, we created the RGPair benchmark dataset and\nconducted extensive experiments. It achieves an 87% coverage rate and raises\ndiversity by 51.88%.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86RequireCEG\uff0c\u4e00\u79cd\u7ed3\u5408\u56e0\u679c\u6548\u5e94\u56fe\u548c\u795e\u7ecf\u7b26\u53f7\u534f\u4f5c\u67b6\u6784\u7684\u9700\u6c42\u5f15\u5bfc\u4e0e\u81ea\u68c0\u4ee3\u7406\uff0c\u65e8\u5728\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u7684\u6b67\u4e49\u6027\uff0c\u5e76\u5728\u751f\u6210\u5f0f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4e3a\u7f3a\u4e4f\u8f6f\u4ef6\u5de5\u7a0b\u77e5\u8bc6\u7684\u7ec8\u7aef\u7528\u6237\u63d0\u4f9b\u5168\u751f\u547d\u5468\u671f\u63a7\u5236\uff0c\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u7684\u6a21\u7cca\u6027\u95ee\u9898\u3002", "method": "\u5229\u7528\u56e0\u679c\u6548\u5e94\u56fe\uff08CEGs\uff09\u548c\u795e\u7ecf\u7b26\u53f7\u534f\u4f5c\u67b6\u6784\uff0c\u901a\u8fc7\u7279\u5f81\u6811\u5206\u6790\u7528\u6237\u53d9\u8ff0\uff0c\u6784\u5efa\u81ea\u6108CEGs\uff0c\u4f18\u5316Gherkin\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u4f7f\u7528RGPair\u6570\u636e\u96c6\uff0c\u8986\u76d6\u7387\u8fbe87%\uff0c\u591a\u6837\u6027\u63d0\u534751.88%\u3002", "conclusion": "RequireCEG\u80fd\u591f\u6709\u6548\u89e3\u51b3\u9700\u6c42\u6a21\u7cca\u6027\uff0c\u63d0\u5347\u751f\u6210\u5f0f\u8f6f\u4ef6\u5f00\u53d1\u7684\u4e00\u81f4\u6027\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2507.14842", "pdf": "https://arxiv.org/pdf/2507.14842", "abs": "https://arxiv.org/abs/2507.14842", "authors": ["Satadal Sengupta", "Hyojoon Kim", "Daniel Jubas", "Maria Apostolaki", "Jennifer Rexford"], "title": "Data-Plane Telemetry to Mitigate Long-Distance BGP Hijacks", "categories": ["cs.NI"], "comment": null, "summary": "Poor security of Internet routing enables adversaries to divert user data\nthrough unintended infrastructures (hijack). Of particular concern -- and the\nfocus of this paper -- are cases where attackers reroute domestic traffic\nthrough foreign countries, exposing it to surveillance, bypassing legal privacy\nprotections, and posing national security threats. Efforts to detect and\nmitigate such attacks have focused primarily on the control plane while\ndata-plane signals remain largely overlooked. In particular, change in\npropagation delay caused by rerouting offers a promising signal: the change is\nunavoidable and the increased propagation delay is directly observable from the\naffected networks. In this paper, we explore the practicality of using delay\nvariations for hijack detection, addressing two key questions: (1) What\ncoverage can this provide, given its heavy dependence on the geolocations of\nthe sender, receiver, and adversary? and (2) Can an always-on latency-based\ndetection system be deployed without disrupting normal network operations? We\nobserve that for 86% of victim-attacker country pairs in the world, mid-attack\ndelays exceed pre-attack delays by at least 25% in real deployments, making\ndelay-based hijack detection promising. To demonstrate practicality, we design\nHiDe, which reliably detects delay surges from long-distance hijacks at line\nrate. We measure HiDe's accuracy and false-positive rate on real-world data and\nvalidate it with ethically conducted hijacks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u4f20\u64ad\u5ef6\u8fdf\u53d8\u5316\u68c0\u6d4b\u4e92\u8054\u7f51\u8def\u7531\u52ab\u6301\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63d0\u51faHiDe\u7cfb\u7edf\uff0c\u5c55\u793a\u5176\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4e92\u8054\u7f51\u8def\u7531\u5b89\u5168\u95ee\u9898\u5bfc\u81f4\u7528\u6237\u6570\u636e\u53ef\u80fd\u88ab\u52ab\u6301\u81f3\u56fd\u5916\u57fa\u7840\u8bbe\u65bd\uff0c\u5e26\u6765\u9690\u79c1\u548c\u56fd\u5bb6\u5b89\u5168\u5a01\u80c1\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5173\u6ce8\u63a7\u5236\u5c42\u9762\u800c\u5ffd\u7565\u6570\u636e\u5c42\u9762\u4fe1\u53f7\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5ef6\u8fdf\u53d8\u5316\uff08\u5982\u4f20\u64ad\u5ef6\u8fdf\u589e\u52a0\uff09\u68c0\u6d4b\u52ab\u6301\uff0c\u8bbe\u8ba1HiDe\u7cfb\u7edf\u5b9e\u73b0\u5b9e\u65f6\u68c0\u6d4b\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u663e\u793a86%\u7684\u53d7\u5bb3-\u653b\u51fb\u56fd\u5bb6\u5bf9\u5728\u52ab\u6301\u671f\u95f4\u5ef6\u8fdf\u589e\u52a0\u81f3\u5c1125%\uff0cHiDe\u7cfb\u7edf\u80fd\u53ef\u9760\u68c0\u6d4b\u957f\u8ddd\u79bb\u52ab\u6301\u3002", "conclusion": "\u5ef6\u8fdf\u53d8\u5316\u662f\u4e00\u79cd\u53ef\u884c\u7684\u52ab\u6301\u68c0\u6d4b\u4fe1\u53f7\uff0cHiDe\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u6f5c\u529b\u63d0\u5347\u8def\u7531\u5b89\u5168\u3002"}}
{"id": "2507.15033", "pdf": "https://arxiv.org/pdf/2507.15033", "abs": "https://arxiv.org/abs/2507.15033", "authors": ["Dhruvee Birla", "Nazia Akhtar"], "title": "'A Little Bubble of Friends': An Analysis of LGBTQ+ Pandemic Experiences Using Reddit Data", "categories": ["cs.HC"], "comment": null, "summary": "Social media was one of the most popular forms of communication among young\npeople with digital access during the pandemic. Consequently, crucial debates\nand discussions about the pandemic crisis have also developed on social media\nplatforms, making them a great primary source to study the experiences of\nspecific groups and communities during the pandemic. This study involved\nresearch using LDA topic modeling and sentiment analysis on data obtained from\nthe social media platform Reddit to understand the themes and attitudes in\ncirculation within five subreddits devoted to LGBTQ+ experiences and issues. In\nthe process, we attempt to make sense of the role that Reddit may have played\nin the lives of LGBTQ+ people who were online during the pandemic, and whether\nthis was marked by any continuities or discontinuities from before the pandemic\nperiod.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7LDA\u4e3b\u9898\u5efa\u6a21\u548c\u60c5\u611f\u5206\u6790\uff0c\u5206\u6790Reddit\u4e0a\u4e94\u4e2aLGBTQ+\u76f8\u5173\u5b50\u8bba\u575b\u7684\u5185\u5bb9\uff0c\u63a2\u8ba8\u75ab\u60c5\u671f\u95f4\u793e\u4ea4\u5a92\u4f53\u5bf9\u8be5\u7fa4\u4f53\u7684\u652f\u6301\u548c\u5f71\u54cd\u3002", "motivation": "\u75ab\u60c5\u671f\u95f4\uff0c\u793e\u4ea4\u5a92\u4f53\u6210\u4e3a\u5e74\u8f7b\u4eba\u4e3b\u8981\u6c9f\u901a\u5e73\u53f0\uff0c\u8ba8\u8bba\u75ab\u60c5\u5371\u673a\u3002\u7814\u7a76\u65e8\u5728\u4e86\u89e3LGBTQ+\u7fa4\u4f53\u5728Reddit\u4e0a\u7684\u8ba8\u8bba\u4e3b\u9898\u548c\u60c5\u611f\u503e\u5411\u3002", "method": "\u4f7f\u7528LDA\u4e3b\u9898\u5efa\u6a21\u548c\u60c5\u611f\u5206\u6790\u6280\u672f\uff0c\u5206\u6790\u4e94\u4e2aLGBTQ+\u76f8\u5173\u5b50\u8bba\u575b\u7684\u6570\u636e\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u75ab\u60c5\u671f\u95f4Reddit\u5bf9LGBTQ+\u7fa4\u4f53\u7684\u652f\u6301\u4f5c\u7528\u53ca\u8ba8\u8bba\u4e3b\u9898\u7684\u53d8\u5316\u3002", "conclusion": "Reddit\u5728\u75ab\u60c5\u671f\u95f4\u4e3aLGBTQ+\u7fa4\u4f53\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\uff0c\u540c\u65f6\u8ba8\u8bba\u4e3b\u9898\u4e0e\u75ab\u60c5\u524d\u76f8\u6bd4\u6709\u4e00\u5b9a\u53d8\u5316\u3002"}}
{"id": "2507.15003", "pdf": "https://arxiv.org/pdf/2507.15003", "abs": "https://arxiv.org/abs/2507.15003", "authors": ["Hao Li", "Haoxiang Zhang", "Ahmed E. Hassan"], "title": "The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.LG"], "comment": null, "summary": "The future of software engineering--SE 3.0--is unfolding with the rise of AI\nteammates: autonomous, goal-driven systems collaborating with human developers.\nAmong these, autonomous coding agents are especially transformative, now\nactively initiating, reviewing, and evolving code at scale. This paper\nintroduces AIDev, the first large-scale dataset capturing how such agents\noperate in the wild. Spanning over 456,000 pull requests by five leading\nagents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across\n61,000 repositories and 47,000 developers, AIDev provides an unprecedented\nempirical foundation for studying autonomous teammates in software development.\n  Unlike prior work that has largely theorized the rise of AI-native software\nengineering, AIDev offers structured, open data to support research in\nbenchmarking, agent readiness, optimization, collaboration modeling, and AI\ngovernance. The dataset includes rich metadata on PRs, authorship, review\ntimelines, code changes, and integration outcomes--enabling exploration beyond\nsynthetic benchmarks like SWE-bench. For instance, although agents often\noutperform humans in speed, their PRs are accepted less frequently, revealing a\ntrust and utility gap. Furthermore, while agents accelerate code\nsubmission--one developer submitted as many PRs in three days as they had in\nthree years--these are structurally simpler (via code complexity metrics).\n  We envision AIDev as a living resource: extensible, analyzable, and ready for\nthe SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev\nenables a new generation of research into AI-native workflows and supports\nbuilding the next wave of symbiotic human-AI collaboration. The dataset is\npublicly available at https://github.com/SAILResearch/AI_Teammates_in_SE3.\n  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering\nAgent", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86AIDev\uff0c\u9996\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u8bb0\u5f55\u4e94\u79cdAI\u7f16\u7801\u4ee3\u7406\u5728\u771f\u5b9e\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u5408\u4f5c\u60c5\u51b5\uff0c\u4e3a\u7814\u7a76AI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u89d2\u8272\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u6210\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7684\u65b0\u4f19\u4f34\uff0c\u9700\u8981\u771f\u5b9e\u6570\u636e\u6765\u7814\u7a76\u5176\u5b9e\u9645\u8868\u73b0\u548c\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u7684\u534f\u4f5c\u6548\u679c\u3002", "method": "AIDev\u6570\u636e\u96c6\u6536\u96c6\u4e86456,000\u4e2a\u7531\u4e94\u79cd\u4e3b\u6d41AI\u4ee3\u7406\u751f\u6210\u7684\u4ee3\u7801\u62c9\u53d6\u8bf7\u6c42\uff08PRs\uff09\uff0c\u6db5\u76d6\u4e8661,000\u4e2a\u4ed3\u5e93\u548c47,000\u540d\u5f00\u53d1\u8005\uff0c\u5305\u542b\u4e30\u5bcc\u7684\u5143\u6570\u636e\u3002", "result": "AI\u4ee3\u7406\u5728\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4eba\u7c7b\uff0c\u4f46PR\u63a5\u53d7\u7387\u8f83\u4f4e\uff0c\u4e14\u63d0\u4ea4\u7684\u4ee3\u7801\u7ed3\u6784\u66f4\u7b80\u5355\uff0c\u63ed\u793a\u4e86\u4fe1\u4efb\u4e0e\u6548\u7528\u5dee\u8ddd\u3002", "conclusion": "AIDev\u4e3a\u7814\u7a76AI\u539f\u751f\u5de5\u4f5c\u6d41\u548c\u4f18\u5316\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u5f00\u653e\u6570\u636e\uff0c\u5c06\u6210\u4e3aSE 3.0\u53d1\u5c55\u7684\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2507.14876", "pdf": "https://arxiv.org/pdf/2507.14876", "abs": "https://arxiv.org/abs/2507.14876", "authors": ["Zi-Yang Wu", "Muhammad Ismail", "Jiliang Zhang", "Jie Zhang"], "title": "Tidal-Like Concept Drift in RIS-Covered Buildings: When Programmable Wireless Environments Meet Human Behaviors", "categories": ["cs.NI", "94A05", "C.2.1; C.2.3"], "comment": "Accepted by IEEE Wireless Communications, to appear in 2025", "summary": "Indoor mobile networks handle the majority of data traffic, with their\nperformance limited by building materials and structures. However, building\ndesigns have historically not prioritized wireless performance. Prior to the\nadvent of reconfigurable intelligent surfaces (RIS), the industry passively\nadapted to wireless propagation challenges within buildings. Inspired by RIS's\nsuccesses in outdoor networks, we propose embedding RIS into building\nstructures to manipulate and enhance building wireless performance\ncomprehensively. Nonetheless, the ubiquitous mobility of users introduces\ncomplex dynamics to the channels of RIS-covered buildings. A deep understanding\nof indoor human behavior patterns is essential for achieving wireless-friendly\nbuilding design. This article is the first to systematically examine the tidal\nevolution phenomena emerging in the channels of RIS-covered buildings driven by\ncomplex human behaviors. We demonstrate that a universal channel model is\nunattainable and focus on analyzing the challenges faced by advanced deep\nlearning-based prediction and control strategies, including high-order Markov\ndependencies, concept drift, and generalization issues caused by human-induced\ndisturbances. Possible solutions for orchestrating the coexistence of\nRIS-covered buildings and crowd mobility are also laid out.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u5d4c\u5165\u5efa\u7b51\u7ed3\u6784\u4ee5\u4f18\u5316\u5ba4\u5185\u65e0\u7ebf\u6027\u80fd\uff0c\u5e76\u63a2\u8ba8\u4e86\u590d\u6742\u4eba\u7c7b\u884c\u4e3a\u5bf9RIS\u8986\u76d6\u5efa\u7b51\u4fe1\u9053\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u4e0e\u63a7\u5236\u7b56\u7565\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u5efa\u7b51\u8bbe\u8ba1\u4e2d\u65e0\u7ebf\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5229\u7528RIS\u6280\u672f\u63d0\u5347\u5ba4\u5185\u79fb\u52a8\u7f51\u7edc\u7684\u6027\u80fd\u3002", "method": "\u7814\u7a76RIS\u5d4c\u5165\u5efa\u7b51\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4eba\u7c7b\u884c\u4e3a\u5bf9\u4fe1\u9053\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u4e0e\u63a7\u5236\u7b56\u7565\u7684\u9002\u7528\u6027\u3002", "result": "\u53d1\u73b0\u4eba\u7c7b\u884c\u4e3a\u5bfc\u81f4\u4fe1\u9053\u52a8\u6001\u53d8\u5316\uff0c\u6df1\u5ea6\u5b66\u4e60\u9762\u4e34\u9ad8\u9636\u9a6c\u5c14\u53ef\u592b\u4f9d\u8d56\u3001\u6982\u5ff5\u6f02\u79fb\u548c\u6cdb\u5316\u95ee\u9898\u7b49\u6311\u6218\u3002", "conclusion": "\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u534f\u8c03RIS\u8986\u76d6\u5efa\u7b51\u4e0e\u4eba\u7fa4\u79fb\u52a8\u7684\u5171\u5b58\uff0c\u4f18\u5316\u65e0\u7ebf\u6027\u80fd\u3002"}}
{"id": "2507.15041", "pdf": "https://arxiv.org/pdf/2507.15041", "abs": "https://arxiv.org/abs/2507.15041", "authors": ["Dhruvee Birla", "Nazia Akhtar"], "title": "Visibility vs. Engagement: How Two Indian News Websites Reported on LGBTQ+ Individuals and Communities during the Pandemic", "categories": ["cs.HC"], "comment": null, "summary": "In India, online news media outlets were an important source of information\nfor people with digital access during the COVID-19 pandemic. In India, where\n\"transgender\" was legally recognised as a category only in 2014, and same-sex\nmarriages are yet to be legalised, it becomes crucial to analyse whether and\nhow they reported the lived realities of vulnerable LGBTQ+ communities during\nthe pandemic. This study analysed articles from online editions of two\nEnglish-language newspaper websites, which differed vastly in their circulation\nfigures-The Times of India and The Indian Express. The results of our study\nsuggest that these newspaper websites published articles surrounding various\naspects of the lives of LGBTQ+ individuals with a greater focus on transgender\ncommunities. However, they lacked quality and depth. Focusing on the period\nspanning March 2020 to August 2021, we analysed articles using sentiment\nanalysis and topic modelling. We also compared our results to the period before\nthe pandemic (January 2019 - December 2019) to understand the shift in topics,\nsentiments, and stances across the two newspaper websites. A manual analysis of\nthe articles indicated that the language used in certain articles by The Times\nof India was transphobic and obsolete. Our study captures the visibility and\nrepresentation of the LGBTQ+ communities in Indian newspaper websites during\nthe pandemic.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u5370\u5ea6\u4e24\u5bb6\u82f1\u8bed\u65b0\u95fb\u7f51\u7ad9\u5728\u65b0\u51a0\u75ab\u60c5\u671f\u95f4\u5bf9LGBTQ+\u7fa4\u4f53\u7684\u62a5\u9053\u60c5\u51b5\uff0c\u53d1\u73b0\u62a5\u9053\u96c6\u4e2d\u5728\u8de8\u6027\u522b\u7fa4\u4f53\uff0c\u4f46\u8d28\u91cf\u4e0d\u8db3\uff0c\u90e8\u5206\u8bed\u8a00\u5e26\u6709\u504f\u89c1\u3002", "motivation": "\u63a2\u8ba8\u5370\u5ea6\u5728\u7ebf\u65b0\u95fb\u5a92\u4f53\u5728\u75ab\u60c5\u671f\u95f4\u5982\u4f55\u62a5\u9053LGBTQ+\u7fa4\u4f53\u7684\u751f\u6d3b\u73b0\u5b9e\uff0c\u5c24\u5176\u662f\u6cd5\u5f8b\u8ba4\u53ef\u665a\u7684\u8de8\u6027\u522b\u7fa4\u4f53\u3002", "method": "\u901a\u8fc7\u60c5\u611f\u5206\u6790\u548c\u4e3b\u9898\u5efa\u6a21\u5206\u67902020\u5e743\u6708\u81f32021\u5e748\u6708\u7684\u6587\u7ae0\uff0c\u5e76\u4e0e2019\u5e74\u540c\u671f\u5bf9\u6bd4\u3002", "result": "\u62a5\u9053\u591a\u5173\u6ce8\u8de8\u6027\u522b\u7fa4\u4f53\uff0c\u4f46\u7f3a\u4e4f\u6df1\u5ea6\uff0c\u90e8\u5206\u6587\u7ae0\u8bed\u8a00\u8fc7\u65f6\u4e14\u5e26\u6709\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u75ab\u60c5\u4e0b\u5370\u5ea6\u65b0\u95fb\u7f51\u5bf9LGBTQ+\u7fa4\u4f53\u7684\u53ef\u89c1\u5ea6\u548c\u4ee3\u8868\u6027\u95ee\u9898\uff0c\u547c\u5401\u6539\u8fdb\u62a5\u9053\u8d28\u91cf\u3002"}}
{"id": "2507.15025", "pdf": "https://arxiv.org/pdf/2507.15025", "abs": "https://arxiv.org/abs/2507.15025", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Andre Schamschurko", "Sven Kirchner", "Fengjunjie Pan", "Chengdng Wu", "Nils Purschke", "Aleksei Velsh", "Krzysztof Lebioda", "Yinglei Song", "Yi Zhang", "Lukasz Mazur", "Alois Knoll"], "title": "Survey of GenAI for Automotive Software Development: From Requirements to Executable Code", "categories": ["cs.SE", "cs.AI"], "comment": "Conference paper accepted for GACLM 2025", "summary": "Adoption of state-of-art Generative Artificial Intelligence (GenAI) aims to\nrevolutionize many industrial areas by reducing the amount of human\nintervention needed and effort for handling complex underlying processes.\nAutomotive software development is considered to be a significant area for\nGenAI adoption, taking into account lengthy and expensive procedures, resulting\nfrom the amount of requirements and strict standardization. In this paper, we\nexplore the adoption of GenAI for various steps of automotive software\ndevelopment, mainly focusing on requirements handling, compliance aspects and\ncode generation. Three GenAI-related technologies are covered within the\nstate-of-art: Large Language Models (LLMs), Retrieval Augmented Generation\n(RAG), Vision Language Models (VLMs), as well as overview of adopted prompting\ntechniques in case of code generation. Additionally, we also derive a\ngeneralized GenAI-aided automotive software development workflow based on our\nfindings from this literature review. Finally, we include a summary of a survey\noutcome, which was conducted among our automotive industry partners regarding\nthe type of GenAI tools used for their daily work activities.", "AI": {"tldr": "\u63a2\u8ba8GenAI\u5728\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5173\u6ce8\u9700\u6c42\u5904\u7406\u3001\u5408\u89c4\u6027\u548c\u4ee3\u7801\u751f\u6210\uff0c\u5e76\u63d0\u51fa\u901a\u7528\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u7e41\u7410\u4e14\u6602\u8d35\uff0cGenAI\u6709\u671b\u51cf\u5c11\u4eba\u529b\u548c\u590d\u6742\u5ea6\u3002", "method": "\u7efc\u8ff0LLMs\u3001RAG\u548cVLMs\u7b49\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7ed3\u5408\u884c\u4e1a\u8c03\u67e5\u3002", "result": "\u603b\u7ed3GenAI\u5de5\u5177\u5728\u884c\u4e1a\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u60c5\u51b5\u3002", "conclusion": "GenAI\u5728\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u4f18\u5316\u6d41\u7a0b\u548c\u6548\u7387\u3002"}}
{"id": "2507.14891", "pdf": "https://arxiv.org/pdf/2507.14891", "abs": "https://arxiv.org/abs/2507.14891", "authors": ["Xiangyu Gao", "Tong Li", "Yinchao Zhang", "Ziqiang Wang", "Xiangsheng Zeng", "Su Yao", "Ke Xu"], "title": "FENIX: Enabling In-Network DNN Inference with FPGA-Enhanced Programmable Switches", "categories": ["cs.NI"], "comment": null, "summary": "Machine learning (ML) is increasingly used in network data planes for\nadvanced traffic analysis. However, existing solutions (such as FlowLens, N3IC,\nand BoS) still struggle to simultaneously achieve low latency, high throughput,\nand high accuracy. To address these challenges, we present FENIX, a hybrid\nin-network ML system that performs feature extraction on programmable switch\nASICs and deep neural network inference on FPGAs. FENIX introduces a Data\nEngine that leverages a probabilistic token bucket algorithm to control the\nsending rate of feature streams, effectively addressing the throughput gap\nbetween programmable switch ASICs and FPGAs. In addition, FENIX designs a Model\nEngine to enable high-accuracy deep neural network inference in the network,\novercoming the difficulty of deploying complex models on resource-constrained\nswitch chips. We implement FENIX on a programmable switch platform that\nintegrates a Tofino ASIC and a ZU19EG FPGA directly and evaluate it on\nreal-world network traffic datasets. Our results show that FENIX achieves\nmicrosecond-level inference latency and multi-terabit throughput with low\nhardware overhead, and delivers over 95\\% accuracy on mainstream network\ntraffic classification tasks, outperforming SOTA.", "AI": {"tldr": "FENIX\u662f\u4e00\u79cd\u6df7\u5408\u7f51\u7edc\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u53ef\u7f16\u7a0b\u4ea4\u6362\u673aASIC\u548cFPGA\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u548c\u9ad8\u7cbe\u5ea6\u7684\u7f51\u7edc\u6d41\u91cf\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u6570\u636e\u5e73\u9762\u7684\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff08\u5982FlowLens\u3001N3IC\u548cBoS\uff09\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u548c\u9ad8\u7cbe\u5ea6\u7684\u9700\u6c42\uff0cFENIX\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "FENIX\u91c7\u7528\u6df7\u5408\u67b6\u6784\uff1a1) \u5728ASIC\u4e0a\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff1b2) \u5728FPGA\u4e0a\u8fdb\u884c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u3002\u5e76\u5f15\u5165\u6570\u636e\u5f15\u64ce\uff08\u57fa\u4e8e\u6982\u7387\u4ee4\u724c\u6876\u7b97\u6cd5\uff09\u548c\u6a21\u578b\u5f15\u64ce\uff08\u89e3\u51b3\u590d\u6742\u6a21\u578b\u90e8\u7f72\u95ee\u9898\uff09\u3002", "result": "FENIX\u5728\u5b9e\u9645\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u5fae\u79d2\u7ea7\u63a8\u7406\u5ef6\u8fdf\u3001\u591a\u5146\u6bd4\u7279\u541e\u5410\u91cf\uff0c\u5206\u7c7b\u4efb\u52a1\u51c6\u786e\u7387\u8d85\u8fc795%\uff0c\u6027\u80fd\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u6280\u672f\u3002", "conclusion": "FENIX\u901a\u8fc7\u521b\u65b0\u7684\u6df7\u5408\u67b6\u6784\u548c\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f51\u7edc\u6570\u636e\u5e73\u9762\u673a\u5668\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.14768", "pdf": "https://arxiv.org/pdf/2507.14768", "abs": "https://arxiv.org/abs/2507.14768", "authors": ["Zhou Li", "Xiang Zhang", "Jiawen Lv", "Jihao Fan", "Haiqiang Chen", "Giuseppe Caire"], "title": "Collusion-Resilient Hierarchical Secure Aggregation with Heterogeneous Security Constraints", "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.LG", "math.IT"], "comment": "accepted by 2025 IEEE Information Theory Workshop", "summary": "Motivated by federated learning (FL), secure aggregation (SA) aims to\nsecurely compute, as efficiently as possible, the sum of a set of inputs\ndistributed across many users. To understand the impact of network topology,\nhierarchical secure aggregation (HSA) investigated the communication and secret\nkey generation efficiency in a 3-layer relay network, where clusters of users\nare connected to the aggregation server through an intermediate layer of\nrelays. Due to the pre-aggregation of the messages at the relays, HSA reduces\nthe communication burden on the relay-to-server links and is able to support a\nlarge number of users. However, as the number of users increases, a practical\nchallenge arises from heterogeneous security requirements--for example, users\nin different clusters may require varying levels of input protection. Motivated\nby this, we study weakly-secure HSA (WS-HSA) with collusion resilience, where\ninstead of protecting all the inputs from any set of colluding users, only the\ninputs belonging to a predefined collection of user groups (referred to as\nsecurity input sets) need to be protected against another predefined collection\nof user groups (referred to as collusion sets). Since the security input sets\nand collusion sets can be arbitrarily defined, our formulation offers a\nflexible framework for addressing heterogeneous security requirements in HSA.\nWe characterize the optimal total key rate, i.e., the total number of\nindependent key symbols required to ensure both server and relay security, for\na broad range of parameter configurations. For the remaining cases, we\nestablish lower and upper bounds on the optimal key rate, providing\nconstant-factor gap optimality guarantees.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5206\u5c42\u5b89\u5168\u805a\u5408\uff08HSA\uff09\u4e2d\u5f02\u6784\u5b89\u5168\u9700\u6c42\u7684\u5f31\u5b89\u5168\u6a21\u578b\uff08WS-HSA\uff09\uff0c\u63d0\u51fa\u4e86\u7075\u6d3b\u7684\u6846\u67b6\u5e76\u5206\u6790\u4e86\u6700\u4f18\u5bc6\u94a5\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3HSA\u4e2d\u7528\u6237\u6570\u91cf\u589e\u52a0\u65f6\u7684\u5f02\u6784\u5b89\u5168\u9700\u6c42\u95ee\u9898\u3002", "method": "\u63d0\u51faWS-HSA\u6a21\u578b\uff0c\u5b9a\u4e49\u5b89\u5168\u8f93\u5165\u96c6\u548c\u5171\u8c0b\u96c6\uff0c\u5206\u6790\u6700\u4f18\u5bc6\u94a5\u7387\u3002", "result": "\u7ed9\u51fa\u4e86\u6700\u4f18\u5bc6\u94a5\u7387\u7684\u53c2\u6570\u8303\u56f4\uff0c\u5e76\u5bf9\u5176\u4ed6\u60c5\u51b5\u63d0\u4f9b\u4e86\u4e0a\u4e0b\u754c\u3002", "conclusion": "WS-HSA\u4e3aHSA\u4e2d\u7684\u5f02\u6784\u5b89\u5168\u9700\u6c42\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15049", "pdf": "https://arxiv.org/pdf/2507.15049", "abs": "https://arxiv.org/abs/2507.15049", "authors": ["Andres Navarro", "Carlos de Quinto", "Jos\u00e9 Alberto Hern\u00e1ndez"], "title": "Beyond Visual Line of Sight: UAVs with Edge AI, Connected LLMs, and VR for Autonomous Aerial Intelligence", "categories": ["cs.HC"], "comment": null, "summary": "Unmanned Aerial Vehicles are reshaping Non-Terrestrial Networks by acting as\nagile, intelligent nodes capable of advanced analytics and instantaneous\nsituational awareness. This article introduces a budget-friendly quadcopter\nplatform that unites 5G communications, edge-based processing, and AI to tackle\ncore challenges in NTN scenarios. Outfitted with a panoramic camera, robust\nonboard computation, and LLMs, the drone system delivers seamless object\nrecognition, contextual analysis, and immersive operator experiences through\nvirtual reality VR technology. Field evaluations confirm the platform's ability\nto process visual streams with low latency and sustain robust 5G links. Adding\nLLMs further streamlines operations by extracting actionable insights and\nrefining collected data for decision support. Demonstrated use cases, including\nemergency response, infrastructure assessment, and environmental surveillance,\nunderscore the system's adaptability in demanding contexts.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u96c6\u6210\u4e865G\u901a\u4fe1\u3001\u8fb9\u7f18\u8ba1\u7b97\u548cAI\u7684\u4f4e\u6210\u672c\u65e0\u4eba\u673a\u5e73\u53f0\uff0c\u7528\u4e8e\u89e3\u51b3\u975e\u5730\u9762\u7f51\u7edc\u573a\u666f\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5e76\u5728\u7d27\u6025\u54cd\u5e94\u3001\u57fa\u7840\u8bbe\u65bd\u8bc4\u4f30\u548c\u73af\u5883\u76d1\u6d4b\u7b49\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u5176\u9002\u5e94\u6027\u3002", "motivation": "\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u65e0\u4eba\u673a\u4f5c\u4e3a\u667a\u80fd\u8282\u70b9\u7684\u5e94\u7528\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u4f20\u7edf\u7cfb\u7edf\u5f80\u5f80\u6210\u672c\u9ad8\u4e14\u529f\u80fd\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u65e0\u4eba\u673a\u5e73\u53f0\uff0c\u7ed3\u54085G\u3001\u8fb9\u7f18\u8ba1\u7b97\u548cAI\u6280\u672f\uff0c\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u6b3e\u914d\u5907\u5168\u666f\u6444\u50cf\u5934\u3001\u5f3a\u5927\u673a\u8f7d\u8ba1\u7b97\u80fd\u529b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65e0\u4eba\u673a\u7cfb\u7edf\uff0c\u7ed3\u54085G\u901a\u4fe1\u548c\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u6280\u672f\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u89c6\u89c9\u6d41\u5904\u7406\u548c\u65e0\u7f1d\u5bf9\u8c61\u8bc6\u522b\u3002", "result": "\u5b9e\u5730\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u5e73\u53f0\u80fd\u591f\u4ee5\u4f4e\u5ef6\u8fdf\u5904\u7406\u89c6\u89c9\u6570\u636e\uff0c\u5e76\u7ef4\u6301\u7a33\u5b9a\u76845G\u8fde\u63a5\u3002LLMs\u7684\u5e94\u7528\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u6570\u636e\u6536\u96c6\u548c\u51b3\u7b56\u652f\u6301\u3002", "conclusion": "\u8be5\u65e0\u4eba\u673a\u5e73\u53f0\u5c55\u793a\u4e86\u5728\u7d27\u6025\u54cd\u5e94\u3001\u57fa\u7840\u8bbe\u65bd\u8bc4\u4f30\u548c\u73af\u5883\u76d1\u6d4b\u7b49\u591a\u6837\u5316\u573a\u666f\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u975e\u5730\u9762\u7f51\u7edc\u7684\u667a\u80fd\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.15157", "pdf": "https://arxiv.org/pdf/2507.15157", "abs": "https://arxiv.org/abs/2507.15157", "authors": ["Giovanni Quattrocchi", "Liliana Pasquale", "Paola Spoletini", "Luciano Baresi"], "title": "Can LLMs Generate User Stories and Assess Their Quality?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Requirements elicitation is still one of the most challenging activities of\nthe requirements engineering process due to the difficulty requirements\nanalysts face in understanding and translating complex needs into concrete\nrequirements. In addition, specifying high-quality requirements is crucial, as\nit can directly impact the quality of the software to be developed. Although\nautomated tools allow for assessing the syntactic quality of requirements,\nevaluating semantic metrics (e.g., language clarity, internal consistency)\nremains a manual and time-consuming activity. This paper explores how LLMs can\nhelp automate requirements elicitation within agile frameworks, where\nrequirements are defined as user stories (US). We used 10 state-of-the-art LLMs\nto investigate their ability to generate US automatically by emulating customer\ninterviews. We evaluated the quality of US generated by LLMs, comparing it with\nthe quality of US generated by humans (domain experts and students). We also\nexplored whether and how LLMs can be used to automatically evaluate the\nsemantic quality of US. Our results indicate that LLMs can generate US similar\nto humans in terms of coverage and stylistic quality, but exhibit lower\ndiversity and creativity. Although LLM-generated US are generally comparable in\nquality to those created by humans, they tend to meet the acceptance quality\ncriteria less frequently, regardless of the scale of the LLM model. Finally,\nLLMs can reliably assess the semantic quality of US when provided with clear\nevaluation criteria and have the potential to reduce human effort in\nlarge-scale assessments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u654f\u6377\u6846\u67b6\u4e2d\u81ea\u52a8\u5316\u9700\u6c42\u83b7\u53d6\uff0c\u5e76\u8bc4\u4f30\u4e86LLM\u751f\u6210\u7528\u6237\u6545\u4e8b\uff08US\uff09\u7684\u8d28\u91cf\u53ca\u5176\u8bed\u4e49\u8d28\u91cf\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "\u9700\u6c42\u83b7\u53d6\u662f\u9700\u6c42\u5de5\u7a0b\u4e2d\u6700\u5177\u6311\u6218\u6027\u7684\u6d3b\u52a8\u4e4b\u4e00\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u8bed\u4e49\u8d28\u91cf\u8bc4\u4f30\u4e0a\u8017\u65f6\u4e14\u4f9d\u8d56\u4e8e\u4eba\u5de5\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7LLM\u63d0\u9ad8\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u6548\u7387\u3002", "method": "\u4f7f\u752810\u79cd\u5148\u8fdb\u7684LLM\u6a21\u62df\u5ba2\u6237\u8bbf\u8c08\u751f\u6210US\uff0c\u5e76\u5c06\u5176\u4e0e\u4eba\u7c7b\u751f\u6210\u7684US\uff08\u6765\u81ea\u9886\u57df\u4e13\u5bb6\u548c\u5b66\u751f\uff09\u8fdb\u884c\u6bd4\u8f83\uff0c\u540c\u65f6\u63a2\u7d22LLM\u5bf9US\u8bed\u4e49\u8d28\u91cf\u7684\u81ea\u52a8\u8bc4\u4f30\u80fd\u529b\u3002", "result": "LLM\u751f\u6210\u7684US\u5728\u8986\u76d6\u8303\u56f4\u548c\u98ce\u683c\u8d28\u91cf\u4e0a\u4e0e\u4eba\u7c7b\u76f8\u4f3c\uff0c\u4f46\u5728\u591a\u6837\u6027\u548c\u521b\u9020\u6027\u4e0a\u8f83\u5f31\u3002LLM\u751f\u6210\u7684US\u8d28\u91cf\u4e0e\u4eba\u7c7b\u76f8\u5f53\uff0c\u4f46\u5728\u6ee1\u8db3\u63a5\u53d7\u6807\u51c6\u4e0a\u8868\u73b0\u8f83\u5dee\u3002LLM\u5728\u63d0\u4f9b\u660e\u786e\u8bc4\u4f30\u6807\u51c6\u65f6\u53ef\u53ef\u9760\u8bc4\u4f30US\u7684\u8bed\u4e49\u8d28\u91cf\u3002", "conclusion": "LLM\u53ef\u4ee5\u8f85\u52a9\u81ea\u52a8\u5316\u9700\u6c42\u83b7\u53d6\u548c\u8bed\u4e49\u8d28\u91cf\u8bc4\u4f30\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u591a\u6837\u6027\u548c\u521b\u9020\u6027\uff0c\u540c\u65f6\u660e\u786e\u8bc4\u4f30\u6807\u51c6\u662f\u5176\u6709\u6548\u5e94\u7528\u7684\u5173\u952e\u3002"}}
{"id": "2507.15145", "pdf": "https://arxiv.org/pdf/2507.15145", "abs": "https://arxiv.org/abs/2507.15145", "authors": ["Thai T. Vu", "John Le"], "title": "Quantum Machine Learning for Secure Cooperative Multi-Layer Edge AI with Proportional Fairness", "categories": ["cs.NI", "cs.LG"], "comment": "8 pages", "summary": "This paper proposes a communication-efficient, event-triggered inference\nframework for cooperative edge AI systems comprising multiple user devices and\nedge servers. Building upon dual-threshold early-exit strategies for rare-event\ndetection, the proposed approach extends classical single-device inference to a\ndistributed, multi-device setting while incorporating proportional fairness\nconstraints across users. A joint optimization framework is formulated to\nmaximize classification utility under communication, energy, and fairness\nconstraints. To solve the resulting problem efficiently, we exploit the\nmonotonicity of the utility function with respect to the confidence thresholds\nand apply alternating optimization with Benders decomposition. Experimental\nresults show that the proposed framework significantly enhances system-wide\nperformance and fairness in resource allocation compared to single-device\nbaselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u4fe1\u9ad8\u6548\u3001\u4e8b\u4ef6\u89e6\u53d1\u7684\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u7528\u6237\u8bbe\u5907\u548c\u8fb9\u7f18\u670d\u52a1\u5668\u5408\u4f5c\u7684\u8fb9\u7f18AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u9608\u503c\u65e9\u671f\u9000\u51fa\u7b56\u7565\u548c\u6bd4\u4f8b\u516c\u5e73\u7ea6\u675f\u4f18\u5316\u6027\u80fd\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18AI\u7cfb\u7edf\u4e2d\u591a\u8bbe\u5907\u534f\u4f5c\u7684\u901a\u4fe1\u6548\u7387\u548c\u8d44\u6e90\u5206\u914d\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53cc\u9608\u503c\u65e9\u671f\u9000\u51fa\u7b56\u7565\u7684\u5206\u5e03\u5f0f\u8054\u5408\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528\u5355\u8c03\u6027\u548c\u4ea4\u66ff\u4f18\u5316\u7ed3\u5408Benders\u5206\u89e3\u6c42\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7cfb\u7edf\u5728\u6027\u80fd\u548c\u8d44\u6e90\u5206\u914d\u7684\u516c\u5e73\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u8bbe\u5907\u57fa\u51c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u8fb9\u7f18AI\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u901a\u4fe1\u548c\u516c\u5e73\u8d44\u6e90\u5206\u914d\uff0c\u63d0\u5347\u4e86\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2507.15072", "pdf": "https://arxiv.org/pdf/2507.15072", "abs": "https://arxiv.org/abs/2507.15072", "authors": ["Maisha Maimuna", "Minhaz Bin Farukee", "Sama Nikanfar", "Mahfuza Siddiqua", "Ayon Roy", "Fillia Makedon"], "title": "NavVI: A Telerobotic Simulation with Multimodal Feedback for Visually Impaired Navigation in Warehouse Environments", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Industrial warehouses are congested with moving forklifts, shelves and\npersonnel, making robot teleoperation particularly risky and demanding for\nblind and low-vision (BLV) operators. Although accessible teleoperation plays a\nkey role in inclusive workforce participation, systematic research on its use\nin industrial environments is limited, and few existing studies barely address\nmultimodal guidance designed for BLV users. We present a novel multimodal\nguidance simulator that enables BLV users to control a mobile robot through a\nhigh-fidelity warehouse environment while simultaneously receiving synchronized\nvisual, auditory, and haptic feedback. The system combines a navigation mesh\nwith regular re-planning so routes remain accurate avoiding collisions as\nforklifts and human avatars move around the warehouse. Users with low vision\nare guided with a visible path line towards destination; navigational voice\ncues with clockwise directions announce upcoming turns, and finally\nproximity-based haptic feedback notifies the users of static and moving\nobstacles in the path. This real-time, closed-loop system offers a repeatable\ntestbed and algorithmic reference for accessible teleoperation research. The\nsimulator's design principles can be easily adapted to real robots due to the\nalignment of its navigation, speech, and haptic modules with commercial\nhardware, supporting rapid feasibility studies and deployment of inclusive\ntelerobotic tools in actual warehouses.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u5f15\u5bfc\u6a21\u62df\u5668\uff0c\u5e2e\u52a9\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\uff08BLV\uff09\u64cd\u4f5c\u8005\u5728\u5de5\u4e1a\u4ed3\u5e93\u4e2d\u5b89\u5168\u8fdc\u7a0b\u63a7\u5236\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u89c6\u89c9\u3001\u542c\u89c9\u548c\u89e6\u89c9\u53cd\u9988\u5b9e\u73b0\u5bfc\u822a\u3002", "motivation": "\u5de5\u4e1a\u4ed3\u5e93\u73af\u5883\u590d\u6742\uff0cBLV\u64cd\u4f5c\u8005\u8fdc\u7a0b\u63a7\u5236\u673a\u5668\u4eba\u5b58\u5728\u9ad8\u98ce\u9669\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u9488\u5bf9BLV\u7528\u6237\u7684\u591a\u6a21\u6001\u5f15\u5bfc\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u5bfc\u822a\u7f51\u683c\u3001\u5b9e\u65f6\u8def\u5f84\u89c4\u5212\u548c\u591a\u6a21\u6001\u53cd\u9988\uff08\u89c6\u89c9\u8def\u5f84\u7ebf\u3001\u8bed\u97f3\u63d0\u793a\u3001\u89e6\u89c9\u8b66\u62a5\uff09\u7684\u6a21\u62df\u5668\u7cfb\u7edf\u3002", "result": "\u7cfb\u7edf\u4e3aBLV\u7528\u6237\u63d0\u4f9b\u4e86\u5b9e\u65f6\u3001\u95ed\u73af\u7684\u5bfc\u822a\u652f\u6301\uff0c\u5e76\u53ef\u5feb\u901f\u9002\u914d\u5230\u5b9e\u9645\u673a\u5668\u4eba\u786c\u4ef6\u4e0a\u3002", "conclusion": "\u8be5\u6a21\u62df\u5668\u4e3a\u53ef\u8bbf\u95ee\u8fdc\u7a0b\u63a7\u5236\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5176\u8bbe\u8ba1\u539f\u5219\u6613\u4e8e\u5e94\u7528\u4e8e\u5b9e\u9645\u4ed3\u5e93\u73af\u5883\u3002"}}
{"id": "2507.15181", "pdf": "https://arxiv.org/pdf/2507.15181", "abs": "https://arxiv.org/abs/2507.15181", "authors": ["Yinglong Zou", "Juan Zhai", "Chunrong Fang", "Yanzhou Mu", "Jiawei Liu", "Zhenyu Chen"], "title": "Deep Learning Framework Testing via Heuristic Guidance Based on Multiple Model Measurements", "categories": ["cs.SE"], "comment": null, "summary": "Deep learning frameworks serve as the foundation for developing and deploying\ndeep learning applications. To enhance the quality of deep learning frameworks,\nresearchers have proposed numerous testing methods using deep learning models\nas test inputs. However, existing methods predominantly measure model bug\ndetection effectiveness as heuristic indicators, presenting three critical\nlimitations: Firstly, existing methods fail to quantitatively measure model's\noperator combination variety, potentially missing critical operator\ncombinations that could trigger framework bugs. Secondly, existing methods\nneglect measuring model execution time, resulting in the omission of numerous\nmodels potential for detecting more framework bugs within limited testing time.\nThirdly, existing methods overlook correlation between different model\nmeasurements, relying simply on single-indicator heuristic guidance without\nconsidering their trade-offs. To overcome these limitations, we propose DLMMM,\nthe first deep learning framework testing method to include multiple model\nmeasurements into heuristic guidance and fuse these measurements to achieve\ntheir trade-off. DLMMM firstly quantitatively measures model's bug detection\nperformance, operator combination variety, and model execution time. After\nthat, DLMMM fuses the above measurements based on their correlation to achieve\ntheir trade-off. To further enhance testing effectiveness, DLMMM designs\nmulti-level heuristic guidance for test input model generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aDLMMM\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u5584\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6d4b\u8bd5\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u878d\u5408\u591a\u79cd\u6a21\u578b\u6d4b\u91cf\u6307\u6807\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65b9\u6cd5\u5728\u68c0\u6d4b\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u9519\u8bef\u65f6\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u672a\u91cf\u5316\u7b97\u5b50\u7684\u7ec4\u5408\u591a\u6837\u6027\u3001\u5ffd\u7565\u6a21\u578b\u6267\u884c\u65f6\u95f4\u3001\u672a\u8003\u8651\u4e0d\u540c\u6d4b\u91cf\u6307\u6807\u7684\u76f8\u5173\u6027\u3002", "method": "DLMMM\u901a\u8fc7\u91cf\u5316\u6a21\u578b\u7684\u9519\u8bef\u68c0\u6d4b\u6027\u80fd\u3001\u7b97\u5b50\u7ec4\u5408\u591a\u6837\u6027\u548c\u6267\u884c\u65f6\u95f4\uff0c\u5e76\u57fa\u4e8e\u76f8\u5173\u6027\u878d\u5408\u8fd9\u4e9b\u6307\u6807\uff0c\u5b9e\u73b0\u5176\u6743\u8861\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u591a\u5c42\u6b21\u7684\u542f\u53d1\u5f0f\u5f15\u5bfc\u6765\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\u6a21\u578b\u3002", "result": "DLMMM\u80fd\u591f\u66f4\u5168\u9762\u5730\u68c0\u6d4b\u6846\u67b6\u9519\u8bef\uff0c\u63d0\u5347\u6d4b\u8bd5\u6548\u679c\u3002", "conclusion": "DLMMM\u662f\u9996\u4e2a\u5c06\u591a\u6a21\u578b\u6d4b\u91cf\u6307\u6807\u878d\u5408\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15254", "pdf": "https://arxiv.org/pdf/2507.15254", "abs": "https://arxiv.org/abs/2507.15254", "authors": ["Sourav Mondal", "Elaine Wong"], "title": "User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks", "categories": ["cs.NI", "cs.AI"], "comment": "This article is accepted for publication in IEEE Internet of Things\n  Journal. Copyright @ IEEE 2025", "summary": "The evolution towards future generation of mobile systems and fixed wireless\nnetworks is primarily driven by the urgency to support high-bandwidth and\nlow-latency services across various vertical sectors. This endeavor is fueled\nby smartphones as well as technologies like industrial internet of things,\nextended reality (XR), and human-to-machine (H2M) collaborations for fostering\nindustrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To\nensure an ideal immersive experience and avoid cyber-sickness for users in all\nthe aforementioned usage scenarios, it is typically challenging to synchronize\nXR content from a remote machine to a human collaborator according to their\nhead movements across a large geographic span in real-time over communication\nnetworks. Thus, we propose a novel H2M collaboration scheme where the human's\nhead movements are predicted ahead with highly accurate models like\nbidirectional long short-term memory networks to orient the machine's camera in\nadvance. We validate that XR frame size varies in accordance with the human's\nhead movements and predict the corresponding bandwidth requirements from the\nmachine's camera to propose a human-machine coordinated dynamic bandwidth\nallocation (HMC-DBA) scheme. Through extensive simulations, we show that\nend-to-end latency and jitter requirements of XR frames are satisfied with much\nlower bandwidth consumption over enterprise networks like\nFiber-To-The-Room-Business. Furthermore, we show that better efficiency in\nnetwork resource utilization is achieved by employing our proposed HMC-DBA over\nstate-of-the-art schemes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4eba\u673a\u534f\u540c\u52a8\u6001\u5e26\u5bbd\u5206\u914d\u65b9\u6848\uff08HMC-DBA\uff09\uff0c\u7528\u4e8e\u5b9e\u65f6\u540c\u6b65XR\u5185\u5bb9\uff0c\u964d\u4f4e\u5e26\u5bbd\u6d88\u8017\u5e76\u6ee1\u8db3\u5ef6\u8fdf\u8981\u6c42\u3002", "motivation": "\u63a8\u52a8\u79fb\u52a8\u7cfb\u7edf\u548c\u56fa\u5b9a\u65e0\u7ebf\u7f51\u7edc\u7684\u53d1\u5c55\uff0c\u652f\u6301\u9ad8\u5e26\u5bbd\u3001\u4f4e\u5ef6\u8fdf\u670d\u52a1\uff0c\u5e94\u5bf9\u5de5\u4e1a4.0/5.0\u548c\u793e\u4f1a5.0\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u53cc\u5411LSTM\u9884\u6d4b\u5934\u90e8\u8fd0\u52a8\uff0c\u52a8\u6001\u8c03\u6574\u5e26\u5bbd\u5206\u914d\uff0c\u63d0\u51faHMC-DBA\u65b9\u6848\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0cHMC-DBA\u5728\u6ee1\u8db3XR\u5ef6\u8fdf\u8981\u6c42\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5e26\u5bbd\u6d88\u8017\u3002", "conclusion": "HMC-DBA\u5728\u8d44\u6e90\u5229\u7528\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4f01\u4e1a\u7f51\u7edc\u3002"}}
{"id": "2507.15349", "pdf": "https://arxiv.org/pdf/2507.15349", "abs": "https://arxiv.org/abs/2507.15349", "authors": ["Zehua Cheng", "Rui Sun", "Jiahao Sun", "Yike Guo"], "title": "Scaling Decentralized Learning with FLock", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Fine-tuning the large language models (LLMs) are prevented by the deficiency\nof centralized control and the massive computing and communication overhead on\nthe decentralized schemes. While the typical standard federated learning (FL)\nsupports data privacy, the central server requirement creates a single point of\nattack and vulnerability to poisoning attacks. Generalizing the result in this\ndirection to 70B-parameter models in the heterogeneous, trustless environments\nhas turned out to be a huge, yet unbroken bottleneck. This paper introduces\nFLock, a decentralized framework for secure and efficient collaborative LLM\nfine-tuning. Integrating a blockchain-based trust layer with economic\nincentives, FLock replaces the central aggregator with a secure, auditable\nprotocol for cooperation among untrusted parties. We present the first\nempirical validation of fine-tuning a 70B LLM in a secure, multi-domain,\ndecentralized setting. Our experiments show the FLock framework defends against\nbackdoor poisoning attacks that compromise standard FL optimizers and fosters\nsynergistic knowledge transfer. The resulting models show a >68% reduction in\nadversarial attack success rates. The global model also demonstrates superior\ncross-domain generalization, outperforming models trained in isolation on their\nown specialized data.", "AI": {"tldr": "FLock\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b89\u5168\u9ad8\u6548\u5730\u534f\u4f5c\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u7ed3\u5408\u533a\u5757\u94fe\u4fe1\u4efb\u5c42\u548c\u7ecf\u6d4e\u6fc0\u52b1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u4e2d\u5355\u70b9\u653b\u51fb\u548c\u6295\u6bd2\u6f0f\u6d1e\u7684\u95ee\u9898\uff0c\u5e76\u572870B\u53c2\u6570\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u867d\u7136\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u4e2d\u592e\u670d\u52a1\u5668\u7684\u5b58\u5728\u5bfc\u81f4\u5355\u70b9\u653b\u51fb\u548c\u6295\u6bd2\u6f0f\u6d1e\u3002\u5728\u5f02\u6784\u3001\u65e0\u4fe1\u4efb\u73af\u5883\u4e2d\u5fae\u8c0370B\u53c2\u6570\u6a21\u578b\u5c1a\u672a\u89e3\u51b3\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faFLock\u6846\u67b6\uff0c\u7ed3\u5408\u533a\u5757\u94fe\u4fe1\u4efb\u5c42\u548c\u7ecf\u6d4e\u6fc0\u52b1\uff0c\u7528\u5b89\u5168\u53ef\u5ba1\u8ba1\u7684\u534f\u8bae\u53d6\u4ee3\u4e2d\u592e\u805a\u5408\u5668\uff0c\u5b9e\u73b0\u4e0d\u4fe1\u4efb\u65b9\u4e4b\u95f4\u7684\u534f\u4f5c\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86FLock\u572870B\u53c2\u6570\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\uff0c\u62b5\u5fa1\u4e86\u540e\u95e8\u6295\u6bd2\u653b\u51fb\uff0c\u964d\u4f4e\u4e8668%\u4ee5\u4e0a\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u4fc3\u8fdb\u4e86\u8de8\u9886\u57df\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002", "conclusion": "FLock\u6846\u67b6\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u5b89\u5168\u9ad8\u6548\u5730\u5fae\u8c03LLM\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u7684\u80fd\u529b\u548c\u8de8\u9886\u57df\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2507.15081", "pdf": "https://arxiv.org/pdf/2507.15081", "abs": "https://arxiv.org/abs/2507.15081", "authors": ["Qi Gong", "Ximing Shen", "Ziyou Yin", "Yaning Li", "Ray Lc"], "title": "\"If I were in Space\": Understanding and Adapting to Social Isolation through Designing Collaborative Narratives", "categories": ["cs.HC"], "comment": null, "summary": "Social isolation can lead to pervasive health issues like anxiety and\nloneliness. Previous work focused on physical interventions like exercise and\nteleconferencing, but overlooked the narrative potential of adaptive\nstrategies. To address this, we designed a collaborative online storytelling\nexperience in social VR, enabling participants in isolation to design an\nimaginary space journey as a metaphor for quarantine, in order to learn about\ntheir isolation adaptation strategies in the process. Eighteen individuals\nparticipated during real quarantine undertaken a virtual role-play experience,\ndesigning their own spaceship rooms and engaging in collaborative activities\nthat revealed creative adaptative strategies. Qualitative analyses of\nparticipant designs, transcripts, and interactions revealed how they coped with\nisolation, and how the engagement unexpectedly influenced their adaptation\nprocess. This study shows how designing playful narrative experiences, rather\nthan solution-driven approaches, can serve as probes to surface how people\nnavigate social isolation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u793e\u4ea4VR\u4e2d\u7684\u534f\u4f5c\u5728\u7ebf\u53d9\u4e8b\u4f53\u9a8c\uff0c\u63a2\u7d22\u4eba\u4eec\u5728\u9694\u79bb\u671f\u95f4\u7684\u9002\u5e94\u7b56\u7565\uff0c\u53d1\u73b0\u53d9\u4e8b\u8bbe\u8ba1\u6bd4\u4f20\u7edf\u89e3\u51b3\u65b9\u6848\u66f4\u80fd\u63ed\u793a\u5e94\u5bf9\u65b9\u5f0f\u3002", "motivation": "\u793e\u4f1a\u5b64\u7acb\u53ef\u80fd\u5bfc\u81f4\u7126\u8651\u548c\u5b64\u72ec\u7b49\u5065\u5eb7\u95ee\u9898\uff0c\u4f46\u4ee5\u5f80\u7814\u7a76\u5ffd\u7565\u4e86\u53d9\u4e8b\u7b56\u7565\u7684\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u793e\u4ea4VR\u4e2d\u7684\u534f\u4f5c\u53d9\u4e8b\u4f53\u9a8c\uff0c18\u540d\u9694\u79bb\u53c2\u4e0e\u8005\u901a\u8fc7\u865a\u62df\u89d2\u8272\u626e\u6f14\u8bbe\u8ba1\u592a\u7a7a\u65c5\u7a0b\uff0c\u63ed\u793a\u9002\u5e94\u7b56\u7565\u3002", "result": "\u53c2\u4e0e\u8005\u901a\u8fc7\u8bbe\u8ba1\u548c\u4e92\u52a8\u5c55\u73b0\u4e86\u5e94\u5bf9\u9694\u79bb\u7684\u521b\u9020\u6027\u7b56\u7565\uff0c\u53d9\u4e8b\u4f53\u9a8c\u610f\u5916\u5f71\u54cd\u4e86\u4ed6\u4eec\u7684\u9002\u5e94\u8fc7\u7a0b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u53d9\u4e8b\u8bbe\u8ba1\u6bd4\u89e3\u51b3\u65b9\u6848\u9a71\u52a8\u7684\u65b9\u6cd5\u66f4\u80fd\u6709\u6548\u63ed\u793a\u4eba\u4eec\u5982\u4f55\u5e94\u5bf9\u793e\u4f1a\u5b64\u7acb\u3002"}}
{"id": "2507.15188", "pdf": "https://arxiv.org/pdf/2507.15188", "abs": "https://arxiv.org/abs/2507.15188", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "title": "Cultural Impact on Requirements Engineering Activities: Bangladeshi Practitioners' View", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "Requirements Engineering (RE) is one of the most interaction-intensive phases\nof software development. This means that RE activities might be especially\nimpacted by stakeholders' national culture. Software development projects\nincreasingly have a very diverse range of stakeholders. To future-proof RE\nactivities, we need to help RE practitioners avoid misunderstandings and\nconflicts that might arise from not understanding potential Cultural Influences\n(CIs). Moreover, an awareness of CIs supports diversity and inclusion in the IT\nprofession. Bangladesh has a growing IT sector with some unique socio-cultural\ncharacteristics, and has been largely overlooked in this research field. In\nthis study, we aim to investigate how the RE process is adopted in the context\nof Bangladeshi culture and what cultural influences impact overall RE\nactivities.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5b5f\u52a0\u62c9\u6587\u5316\u5bf9\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u6d3b\u52a8\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u5e2e\u52a9\u4ece\u4e1a\u8005\u907f\u514d\u6587\u5316\u8bef\u89e3\uff0c\u5e76\u4fc3\u8fdbIT\u884c\u4e1a\u7684\u591a\u6837\u6027\u3002", "motivation": "\u9700\u6c42\u5de5\u7a0b\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u6700\u9700\u8981\u4e92\u52a8\u7684\u9636\u6bb5\uff0c\u6587\u5316\u591a\u6837\u6027\u53ef\u80fd\u5bfc\u81f4\u8bef\u89e3\u548c\u51b2\u7a81\u3002\u5b5f\u52a0\u62c9IT\u884c\u4e1a\u53d1\u5c55\u8fc5\u901f\u4f46\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u7814\u7a76\u8c03\u67e5\u5b5f\u52a0\u62c9\u6587\u5316\u5982\u4f55\u5f71\u54cd\u9700\u6c42\u5de5\u7a0b\u7684\u91c7\u7eb3\u548c\u6267\u884c\u3002", "result": "\uff08\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\uff09", "conclusion": "\u4e86\u89e3\u6587\u5316\u5f71\u54cd\u6709\u52a9\u4e8e\u4f18\u5316\u9700\u6c42\u5de5\u7a0b\u6d3b\u52a8\uff0c\u652f\u6301IT\u884c\u4e1a\u7684\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u3002"}}
{"id": "2507.15338", "pdf": "https://arxiv.org/pdf/2507.15338", "abs": "https://arxiv.org/abs/2507.15338", "authors": ["Takaho Shimokasa", "Hiroyuki Yomo", "Federico Chiariotti", "Junya Shiraishi", "Petar Popovski"], "title": "Low-Power and Accurate IoT Monitoring Under Radio Resource Constraint", "categories": ["cs.NI"], "comment": "Paper accepted for IEEE PIMRC 2025", "summary": "This paper investigates how to achieve both low-power operations of sensor\nnodes and accurate state estimation using Kalman filter for internet of things\n(IoT) monitoring employing wireless sensor networks under radio resource\nconstraint. We consider two policies used by the base station to collect\nobservations from the sensor nodes: (i) an oblivious policy, based on\nstatistics of the observations, and (ii) a decentralized policy, based on\nautonomous decision of each sensor based on its instantaneous observation. This\nwork introduces a wake-up receiver and wake-up signaling to both policies to\nimprove the energy efficiency of the sensor nodes. The decentralized policy\ndesigned with random access prioritizes transmissions of instantaneous\nobservations that are highly likely to contribute to the improvement of state\nestimation. Our numerical results show that the decentralized policy improves\nthe accuracy of the estimation in comparison to the oblivious policy under the\nconstraint on the radio resource and consumed energy when the correlation\nbetween the processes observed by the sensor nodes is low. We also clarify the\ndegree of correlation in which the superiority of two policies changes.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u5728\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u7684\u8d44\u6e90\u9650\u5236\u4e0b\uff0c\u901a\u8fc7Kalman\u6ee4\u6ce2\u5b9e\u73b0\u7269\u8054\u7f51\u76d1\u6d4b\u4e2d\u4f20\u611f\u5668\u8282\u70b9\u7684\u4f4e\u529f\u8017\u8fd0\u884c\u548c\u51c6\u786e\u72b6\u6001\u4f30\u8ba1\u3002\u6bd4\u8f83\u4e86\u4e24\u79cd\u57fa\u7ad9\u7b56\u7565\uff1a\u57fa\u4e8e\u7edf\u8ba1\u7684\u65e0\u610f\u8bc6\u7b56\u7565\u548c\u57fa\u4e8e\u4f20\u611f\u5668\u77ac\u65f6\u89c2\u6d4b\u7684\u5206\u6563\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u5524\u9192\u673a\u5236\u63d0\u9ad8\u80fd\u6548\u3002", "motivation": "\u5728IoT\u76d1\u6d4b\u4e2d\uff0c\u9700\u8981\u5e73\u8861\u4f20\u611f\u5668\u8282\u70b9\u7684\u4f4e\u529f\u8017\u548c\u72b6\u6001\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u65e0\u7ebf\u8d44\u6e90\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\uff08\u65e0\u610f\u8bc6\u548c\u5206\u6563\u7b56\u7565\uff09\uff0c\u7ed3\u5408\u5524\u9192\u63a5\u6536\u5668\u548c\u5524\u9192\u4fe1\u53f7\uff0c\u5206\u6563\u7b56\u7565\u901a\u8fc7\u968f\u673a\u8bbf\u95ee\u4f18\u5148\u7ea7\u4f20\u8f93\u9ad8\u8d21\u732e\u89c2\u6d4b\u503c\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u4f20\u611f\u5668\u89c2\u6d4b\u8fc7\u7a0b\u76f8\u5173\u6027\u4f4e\u65f6\uff0c\u5206\u6563\u7b56\u7565\u5728\u8d44\u6e90\u548c\u80fd\u91cf\u7ea6\u675f\u4e0b\u4f18\u4e8e\u65e0\u610f\u8bc6\u7b56\u7565\uff0c\u5e76\u786e\u5b9a\u4e86\u7b56\u7565\u4f18\u52a3\u8f6c\u6362\u7684\u76f8\u5173\u6027\u9608\u503c\u3002", "conclusion": "\u5206\u6563\u7b56\u7565\u5728\u4f4e\u76f8\u5173\u6027\u573a\u666f\u4e0b\u66f4\u4f18\uff0c\u5524\u9192\u673a\u5236\u63d0\u5347\u4e86\u80fd\u6548\uff0c\u7814\u7a76\u4e3a\u8d44\u6e90\u53d7\u9650\u7684IoT\u7f51\u7edc\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15658", "pdf": "https://arxiv.org/pdf/2507.15658", "abs": "https://arxiv.org/abs/2507.15658", "authors": ["Romain Cosson", "Laurent Massouli\u00e9"], "title": "Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a new Lower Bound", "categories": ["cs.DS", "cs.DC", "cs.MA"], "comment": null, "summary": "We study the problem of collective tree exploration in which a team of $k$\nmobile agents must collectively visit all nodes of an unknown tree in as few\nmoves as possible. The agents all start from the root and discover adjacent\nedges as they progress in the tree. Communication is distributed in the sense\nthat agents share information by reading and writing on whiteboards located at\nall nodes. Movements are asynchronous, in the sense that the speeds of all\nagents are controlled by an adversary at all times. All previous competitive\nguarantees for collective tree exploration are either distributed but\nsynchronous, or asynchronous but centralized. In contrast, we present a\ndistributed asynchronous algorithm that explores any tree of $n$ nodes and\ndepth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear\nin $D$, and a variant algorithm with a guarantee in $O(k/\\log k)(n+kD)$, i.e.,\nwith a competitive ratio in $O(k/\\log k)$. We note that our regret guarantee is\nasymptotically optimal (i.e., $1$-competitive) from the perspective of\naverage-case complexity. We then present a new general lower bound on the\ncompetitive ratio of asynchronous collective tree exploration, in\n$\\Omega(\\log^2 k)$. This lower bound applies to both the distributed and\ncentralized settings, and improves upon the previous lower bound in\n$\\Omega(\\log k)$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u96c6\u4f53\u6811\u63a2\u7d22\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\uff0c\u5176\u63a2\u7d22\u6548\u7387\u4f18\u4e8e\u4e4b\u524d\u7684\u540c\u6b65\u6216\u96c6\u4e2d\u5f0f\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u4e0b\u754c\u8bc1\u660e\u3002", "motivation": "\u7814\u7a76\u5728\u5206\u5e03\u5f0f\u5f02\u6b65\u73af\u5883\u4e2d\u9ad8\u6548\u63a2\u7d22\u672a\u77e5\u6811\u7684\u52a8\u673a\uff0c\u586b\u8865\u4e86\u73b0\u6709\u540c\u6b65\u6216\u96c6\u4e2d\u5f0f\u7b97\u6cd5\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\uff0c\u5206\u522b\u4ee5\u4e0d\u540c\u7684\u65f6\u95f4\u9650\u5236\u63a2\u7d22\u6811\u3002", "result": "\u7b97\u6cd5\u5206\u522b\u57282n+O(k\u00b22\u1d4fD)\u548cO(k/ log k)(n+kD)\u7684\u65f6\u95f4\u5185\u5b8c\u6210\u63a2\u7d22\uff0c\u4e14\u7b2c\u4e8c\u4e2a\u7b97\u6cd5\u7684\u7ade\u4e89\u6bd4\u4e3aO(k/ log k)\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u5728\u5e73\u5747\u60c5\u51b5\u4e0b\u5177\u6709\u6700\u4f18\u6027\uff0c\u5e76\u6539\u8fdb\u4e86\u5f02\u6b65\u96c6\u4f53\u6811\u63a2\u7d22\u7684\u4e0b\u754c\u81f3\u03a9(log\u00b2k)\u3002"}}
{"id": "2507.15202", "pdf": "https://arxiv.org/pdf/2507.15202", "abs": "https://arxiv.org/abs/2507.15202", "authors": ["Karim Benharrak", "Puyuan Peng", "Amy Pavel"], "title": "TalkLess: Blending Extractive and Abstractive Speech Summarization for Editing Speech to Preserve Content and Style", "categories": ["cs.HC"], "comment": null, "summary": "Millions of people listen to podcasts, audio stories, and lectures, but\nediting speech remains tedious and time-consuming. Creators remove unnecessary\nwords, cut tangential discussions, and even re-record speech to make recordings\nconcise and engaging. Prior work automatically summarized speech by removing\nfull sentences (extraction), but rigid extraction limits expressivity. AI tools\ncan summarize then re-synthesize speech (abstraction), but abstraction strips\nthe speaker's style. We present TalkLess, a system that flexibly combines\nextraction and abstraction to condense speech while preserving its content and\nstyle. To edit speech, TalkLess first generates possible transcript edits,\nselects edits to maximize compression, coverage, and audio quality, then uses a\nspeech editing model to translate transcript edits into audio edits. TalkLess's\ninterface provides creators control over automated edits by separating\nlow-level wording edits (via the compression pane) from major content edits\n(via the outline pane). TalkLess achieves higher coverage and removes more\nspeech errors than a state-of-the-art extractive approach. A comparison study\n(N=12) showed that TalkLess significantly decreased cognitive load and editing\neffort in speech editing. We further demonstrate TalkLess's potential in an\nexploratory study (N=3) where creators edited their own speech.", "AI": {"tldr": "TalkLess \u662f\u4e00\u79cd\u7ed3\u5408\u63d0\u53d6\u548c\u62bd\u8c61\u65b9\u6cd5\u7684\u8bed\u97f3\u7f16\u8f91\u7cfb\u7edf\uff0c\u65e8\u5728\u9ad8\u6548\u538b\u7f29\u8bed\u97f3\u5185\u5bb9\u7684\u540c\u65f6\u4fdd\u7559\u8bf4\u8bdd\u8005\u7684\u98ce\u683c\uff0c\u5e76\u51cf\u5c11\u7f16\u8f91\u8d1f\u62c5\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u7f16\u8f91\u5de5\u5177\u5728\u63d0\u53d6\u53e5\u5b50\u6216\u62bd\u8c61\u6982\u62ec\u65f6\u5b58\u5728\u7075\u6d3b\u6027\u4e0d\u8db3\u6216\u4e22\u5931\u8bf4\u8bdd\u8005\u98ce\u683c\u7684\u5c40\u9650\u6027\uff0cTalkLess \u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "TalkLess \u9996\u5148\u751f\u6210\u53ef\u80fd\u7684\u8f6c\u5f55\u7f16\u8f91\u65b9\u6848\uff0c\u9009\u62e9\u6700\u4f18\u7f16\u8f91\u4ee5\u5e73\u8861\u538b\u7f29\u7387\u3001\u5185\u5bb9\u8986\u76d6\u7387\u548c\u97f3\u9891\u8d28\u91cf\uff0c\u968f\u540e\u5229\u7528\u8bed\u97f3\u7f16\u8f91\u6a21\u578b\u5c06\u6587\u672c\u7f16\u8f91\u8f6c\u6362\u4e3a\u97f3\u9891\u7f16\u8f91\u3002", "result": "\u4e0e\u73b0\u6709\u6700\u4f73\u63d0\u53d6\u65b9\u6cd5\u76f8\u6bd4\uff0cTalkLess \u63d0\u9ad8\u4e86\u5185\u5bb9\u8986\u76d6\u7387\u5e76\u51cf\u5c11\u4e86\u8bed\u97f3\u9519\u8bef\u3002\u7528\u6237\u7814\u7a76\u663e\u793a\u5176\u663e\u8457\u964d\u4f4e\u4e86\u8ba4\u77e5\u8d1f\u62c5\u548c\u7f16\u8f91\u5de5\u4f5c\u91cf\u3002", "conclusion": "TalkLess \u901a\u8fc7\u7075\u6d3b\u7684\u7f16\u8f91\u65b9\u6cd5\u548c\u7528\u6237\u53cb\u597d\u754c\u9762\uff0c\u4e3a\u8bed\u97f3\u521b\u4f5c\u8005\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u7f16\u8f91\u5de5\u5177\u3002"}}
{"id": "2507.15197", "pdf": "https://arxiv.org/pdf/2507.15197", "abs": "https://arxiv.org/abs/2507.15197", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "title": "Towards Using Personas in Requirements Engineering: What Has Been Changed Recently?", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "In requirements engineering (RE), personas are now being used to represent\nuser expectations and needs. This systematic mapping study (SMS) aims to\nexplore the most recent studies and to cover recent changes in trends,\nespecially related to the recent evolution of Generative AI approaches. Our SMS\ncovers the period between April 2023 and April 2025. We identified 22 relevant\npublications and analysed persona representation, construction, validation, as\nwell as RE activities covered by personas. We identified that a number of\nstudies applied AI-based solutions for persona construction and validation. We\nobserved that template-based personas are becoming more popular nowadays. We\nalso observed an increase in the proportion of studies covering validation\naspects.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff08SMS\uff09\u63a2\u8ba8\u4e86\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4e2d\u89d2\u8272\u7684\u6700\u65b0\u7814\u7a76\u8d8b\u52bf\uff0c\u5c24\u5176\u5173\u6ce8\u751f\u6210\u5f0fAI\u5bf9\u89d2\u8272\u6784\u5efa\u548c\u9a8c\u8bc1\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u751f\u6210\u5f0fAI\u7b49\u65b0\u5174\u6280\u672f\u5982\u4f55\u5f71\u54cd\u89d2\u8272\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u8fd1\u5e74\u6765\u7684\u7814\u7a76\u8d8b\u52bf\u53d8\u5316\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u4e862023\u5e744\u6708\u81f32025\u5e744\u6708\u671f\u95f4\u768422\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u6db5\u76d6\u89d2\u8272\u8868\u793a\u3001\u6784\u5efa\u3001\u9a8c\u8bc1\u53caRE\u6d3b\u52a8\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8eAI\u7684\u89d2\u8272\u6784\u5efa\u548c\u9a8c\u8bc1\u65b9\u6cd5\u589e\u591a\uff0c\u6a21\u677f\u5316\u89d2\u8272\u66f4\u53d7\u6b22\u8fce\uff0c\u9a8c\u8bc1\u76f8\u5173\u7814\u7a76\u6bd4\u4f8b\u4e0a\u5347\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5bf9\u89d2\u8272\u6784\u5efa\u548c\u9a8c\u8bc1\u4ea7\u751f\u4e86\u663e\u8457\u5f71\u54cd\uff0c\u672a\u6765\u7814\u7a76\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22AI\u5728RE\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.15244", "pdf": "https://arxiv.org/pdf/2507.15244", "abs": "https://arxiv.org/abs/2507.15244", "authors": ["Leixian Shen", "Leni Yang", "Haotian Li", "Yun Wang", "Yuyu Luo", "Huamin Qu"], "title": "How Does Empirical Research Facilitate Creation Tool Design? A Data Video Perspective", "categories": ["cs.HC"], "comment": null, "summary": "Empirical research in creative design deepens our theoretical understanding\nof design principles and perceptual effects, offering valuable guidance for\ninnovating creation tools. However, how these empirical insights currently\ninfluence the development of creation tools, and how their integration can be\nenhanced in the future, remains insufficiently understood. In this paper, we\naim to unveil the gap through a case study on data videos, a prominent and\nwide-spread medium for effective data storytelling. To achieve the goal, we\nconducted a comprehensive analysis of 46 empirical research papers and 48\ncreation tool papers on data video, complemented by interviews with 11 experts.\nBuilding upon a systematic collection and structured characterization of\nempirical research by their methodologies (e.g., corpus analysis, comparative\nevaluations) and component focus (e.g., visuals, motions, narratives, audio),\nwe conducted a context-aware citation analysis and revealed a taxonomy of\nrecurring patterns in how empirical findings inform tool design across citation\nfunctions (e.g., problem framing, technical reference). Expert interviews\nfurther uncovered researchers' practice patterns in applying empirical findings\n(e.g., adaptation, synthesis, iteration, etc.) and identified key factors\ninfluencing applicability, such as contextual relevance, granularity matching,\nclarity, credibility, and feasibility. Finally, we derive suggestions and\ndiscuss future opportunities to foster closer mutual engagement between\nempirical and tool research, aiming to reinforce the theoretical grounding of\ncreation tools and enhance the practical impact of empirical research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u63a2\u8ba8\u4e86\u521b\u610f\u8bbe\u8ba1\u4e2d\u5b9e\u8bc1\u7814\u7a76\u5982\u4f55\u5f71\u54cd\u521b\u4f5c\u5de5\u5177\u7684\u5f00\u53d1\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u4e0d\u8db3\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e86\u89e3\u5b9e\u8bc1\u7814\u7a76\u5982\u4f55\u5f71\u54cd\u521b\u4f5c\u5de5\u5177\u7684\u5f00\u53d1\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u52a0\u5f3a\u4e24\u8005\u7684\u7ed3\u5408\u4ee5\u63d0\u5347\u521b\u610f\u8bbe\u8ba1\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u6548\u679c\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u7efc\u5408\u5206\u679046\u7bc7\u5b9e\u8bc1\u7814\u7a76\u8bba\u6587\u548c48\u7bc7\u521b\u4f5c\u5de5\u5177\u8bba\u6587\uff0c\u8f85\u4ee511\u4f4d\u4e13\u5bb6\u7684\u8bbf\u8c08\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5f15\u7528\u5206\u6790\u548c\u6a21\u5f0f\u5206\u7c7b\u63ed\u793a\u5b9e\u8bc1\u7814\u7a76\u5bf9\u5de5\u5177\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5b9e\u8bc1\u7814\u7a76\u5bf9\u5de5\u5177\u8bbe\u8ba1\u7684\u5e38\u89c1\u6a21\u5f0f\u4ee5\u53ca\u5f71\u54cd\u5e94\u7528\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5982\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u3001\u9897\u7c92\u5ea6\u5339\u914d\u548c\u6e05\u6670\u5ea6\u7b49\u3002", "conclusion": "\u7ed3\u8bba\u63d0\u51fa\u4e86\u4fc3\u8fdb\u5b9e\u8bc1\u7814\u7a76\u4e0e\u5de5\u5177\u7814\u7a76\u66f4\u7d27\u5bc6\u7ed3\u5408\u7684\u5efa\u8bae\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7684\u673a\u9047\uff0c\u65e8\u5728\u5f3a\u5316\u521b\u4f5c\u5de5\u5177\u7684\u7406\u8bba\u57fa\u7840\u5e76\u63d0\u5347\u5b9e\u8bc1\u7814\u7a76\u7684\u5b9e\u9645\u5f71\u54cd\u529b\u3002"}}
{"id": "2507.15224", "pdf": "https://arxiv.org/pdf/2507.15224", "abs": "https://arxiv.org/abs/2507.15224", "authors": ["Yibo He", "Shuoran Zhao", "Jiaming Huang", "Yingjie Fu", "Hao Yu", "Cunjian Huang", "Tao Xie"], "title": "SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "SIMD (Single Instruction Multiple Data) instructions and their compiler\nintrinsics are widely supported by modern processors to accelerate\nperformance-critical tasks. SIMD intrinsic programming, a trade-off between\ncoding productivity and high performance, is widely used in the development of\nmainstream performance-critical libraries and daily computing tasks. Large\nLanguage Models (LLMs), which have demonstrated strong and comprehensive\ncapabilities in code generation, show promise in assisting programmers with the\nchallenges of SIMD intrinsic programming. However, existing code-generation\nbenchmarks focus on only scalar code, and it is unclear how LLMs perform in\ngenerating vectorized code using SIMD intrinsics. To fill this gap, we propose\nSimdBench, the first code benchmark specifically designed for SIMD-intrinsic\ncode generation, comprising 136 carefully crafted tasks and targeting five\nrepresentative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86\nAdvanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM\nScalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a\nsystematic evaluation (measuring both correctness and performance) of 18\nrepresentative LLMs on SimdBench, resulting in a series of novel and insightful\nfindings. Our evaluation results demonstrate that LLMs exhibit a universal\ndecrease in pass@k during SIMD-intrinsic code generation compared to\nscalar-code generation. Our in-depth analysis highlights promising directions\nfor the further advancement of LLMs in the challenging domain of SIMD-intrinsic\ncode generation. SimdBench is fully open source at\nhttps://anonymous.4open.science/r/SimdBench-1B3F/ to benefit the broader\nresearch community.", "AI": {"tldr": "SimdBench \u662f\u9996\u4e2a\u4e13\u95e8\u4e3a SIMD \u6307\u4ee4\u4ee3\u7801\u751f\u6210\u8bbe\u8ba1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b 136 \u9879\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e86 18 \u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u6027\u80fd SIMD \u4ee3\u7801\u65f6\u7684\u8868\u73b0\u3002", "motivation": "\u7814\u7a76 SIMD \u6307\u4ee4\u7f16\u7a0b\u5728 LLMs \u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u586b\u8865\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7f3a\u5c11 SIMD \u4ee3\u7801\u8bc4\u4f30\u7684\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86 SimdBench \u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b 136 \u9879\u4efb\u52a1\uff0c\u8986\u76d6\u4e94\u79cd SIMD \u6307\u4ee4\u96c6\uff0c\u5e76\u5bf9 18 \u79cd LLMs \u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "LLMs \u5728\u751f\u6210 SIMD \u4ee3\u7801\u65f6\u7684\u8868\u73b0\u666e\u904d\u4e0d\u5982\u6807\u91cf\u4ee3\u7801\uff0c\u4f46\u7814\u7a76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "SimdBench \u4e3a LLMs \u5728 SIMD \u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.15391", "pdf": "https://arxiv.org/pdf/2507.15391", "abs": "https://arxiv.org/abs/2507.15391", "authors": ["Fabian Ihle", "Michael Menth"], "title": "Stack Management for MPLS Network Actions: Integration of Nodes with Limited Hardware Capabilities", "categories": ["cs.NI", "C.2.2; C.2.1; C.2.6"], "comment": null, "summary": "The MPLS Network Actions (MNA) framework enhances MPLS forwarding with a\ngeneralized encoding for manifold extensions such as network slicing and\nin-situ OAM (IOAM). Network actions in MNA are encoded in Label Stack Entries\n(LSEs) and are added to the MPLS stack. Routers have a physical limit on the\nnumber of LSEs they can read, called the readable label depth (RLD). With MNA,\nrouters must be able to process a minimum number of LSEs which requires a\nrelatively large RLD. In this paper, we perform a hardware analysis of an MNA\nimplementation and identify the reason for a large RLD requirement in the MNA\nprotocol design. Based on this, we present a mechanism that reduces the\nrequired RLD for MNA nodes by restructuring the MPLS stack during forwarding.\nWe then introduce the novel stack management network action that enables the\nproposed mechanism as well as its integration in networks with MNA-incapable\nnodes. The feasibility of the mechanism on programmable hardware is verified by\nproviding a P4-based implementation. Further, the effects on the required RLD,\nECMP, and packet overhead are discussed.", "AI": {"tldr": "MPLS\u7f51\u7edc\u884c\u52a8(MNA)\u6846\u67b6\u901a\u8fc7\u6539\u8fdbMPLS\u8f6c\u53d1\uff0c\u652f\u6301\u7f51\u7edc\u5207\u7247\u548cIOAM\u7b49\u529f\u80fd\u3002\u7814\u7a76\u53d1\u73b0\u5176\u8bbe\u8ba1\u5bfc\u81f4\u8def\u7531\u5668\u9700\u8f83\u5927\u53ef\u8bfb\u6807\u7b7e\u6df1\u5ea6(RLD)\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u51cf\u5c11RLD\u9700\u6c42\u7684\u673a\u5236\uff0c\u901a\u8fc7MPLS\u6808\u91cd\u6784\u5b9e\u73b0\u3002", "motivation": "MNA\u6846\u67b6\u9700\u8981\u8f83\u5927\u7684RLD\uff0c\u8def\u7531\u5668\u9700\u5904\u7406\u8f83\u591a\u6807\u7b7e\u6808\u6761\u76ee(LSEs)\uff0c\u786c\u4ef6\u9650\u5236\u6210\u4e3a\u74f6\u9888\uff0c\u56e0\u6b64\u9700\u4f18\u5316\u8bbe\u8ba1\u4ee5\u51cf\u5c11RLD\u9700\u6c42\u3002", "method": "\u5206\u6790MNA\u786c\u4ef6\u5b9e\u73b0\uff0c\u63d0\u51fa\u6808\u91cd\u6784\u673a\u5236\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u6808\u7ba1\u7406\u7f51\u7edc\u52a8\u4f5c\uff0c\u652f\u6301\u4e0e\u4e0d\u652f\u6301MNA\u8282\u70b9\u7684\u517c\u5bb9\u6027\u3002\u901a\u8fc7P4\u5b9e\u73b0\u9a8c\u8bc1\u53ef\u884c\u6027\u3002", "result": "\u673a\u5236\u6210\u529f\u51cf\u5c11RLD\u9700\u6c42\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5bf9ECMP\u548c\u6570\u636e\u5305\u5f00\u9500\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6808\u7ba1\u7406\u673a\u5236\u6709\u6548\u964d\u4f4e\u4e86MNA\u5bf9RLD\u7684\u9700\u6c42\uff0c\u9002\u7528\u4e8e\u53ef\u7f16\u7a0b\u786c\u4ef6\uff0c\u589e\u5f3a\u4e86MNA\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.15355", "pdf": "https://arxiv.org/pdf/2507.15355", "abs": "https://arxiv.org/abs/2507.15355", "authors": ["Zhipeng Li", "Yi-Chi Liao", "Christian Holz"], "title": "Efficient Visual Appearance Optimization by Learning from Prior Preferences", "categories": ["cs.HC", "cs.LG"], "comment": "24 pages, UIST'25", "summary": "Adjusting visual parameters such as brightness and contrast is common in our\neveryday experiences. Finding the optimal parameter setting is challenging due\nto the large search space and the lack of an explicit objective function,\nleaving users to rely solely on their implicit preferences. Prior work has\nexplored Preferential Bayesian Optimization (PBO) to address this challenge,\ninvolving users to iteratively select preferred designs from candidate sets.\nHowever, PBO often requires many rounds of preference comparisons, making it\nmore suitable for designers than everyday end-users. We propose Meta-PO, a\nnovel method that integrates PBO with meta-learning to improve sample\nefficiency. Specifically, Meta-PO infers prior users' preferences and stores\nthem as models, which are leveraged to intelligently suggest design candidates\nfor the new users, enabling faster convergence and more personalized results.\nAn experimental evaluation of our method for appearance design tasks on 2D and\n3D content showed that participants achieved satisfactory appearance in 5.86\niterations using Meta-PO when participants shared similar goals with a\npopulation (e.g., tuning for a ``warm'' look) and in 8 iterations even\ngeneralizes across divergent goals (e.g., from ``vintage'', ``warm'', to\n``holiday''). Meta-PO makes personalized visual optimization more applicable to\nend-users through a generalizable, more efficient optimization conditioned on\npreferences, with the potential to scale interface personalization more\nbroadly.", "AI": {"tldr": "Meta-PO\u662f\u4e00\u79cd\u7ed3\u5408\u504f\u597d\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u5143\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u4f7f\u7528\u6237\u5728\u66f4\u5c11\u8fed\u4ee3\u4e2d\u83b7\u5f97\u6ee1\u610f\u7684\u89c6\u89c9\u53c2\u6570\u8bbe\u5b9a\u3002", "motivation": "\u8c03\u6574\u89c6\u89c9\u53c2\u6570\uff08\u5982\u4eae\u5ea6\u548c\u5bf9\u6bd4\u5ea6\uff09\u65f6\uff0c\u7531\u4e8e\u641c\u7d22\u7a7a\u95f4\u5927\u4e14\u7f3a\u4e4f\u660e\u786e\u76ee\u6807\u51fd\u6570\uff0c\u7528\u6237\u901a\u5e38\u53ea\u80fd\u4f9d\u8d56\u4e3b\u89c2\u504f\u597d\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\uff08\u5982PBO\uff09\u9700\u8981\u8f83\u591a\u8f6e\u6b21\uff0c\u4e0d\u9002\u7528\u4e8e\u666e\u901a\u7528\u6237\u3002", "method": "\u63d0\u51faMeta-PO\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u63a8\u65ad\u5148\u524d\u7528\u6237\u7684\u504f\u597d\u5e76\u5b58\u50a8\u4e3a\u6a21\u578b\uff0c\u4e3a\u65b0\u624b\u7528\u6237\u667a\u80fd\u751f\u6210\u5019\u9009\u8bbe\u8ba1\uff0c\u4ece\u800c\u52a0\u901f\u6536\u655b\u5e76\u63d0\u4f9b\u4e2a\u6027\u5316\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u7528\u6237\u76ee\u6807\u76f8\u4f3c\u65f6\uff0cMeta-PO\u4ec5\u97005.86\u6b21\u8fed\u4ee3\u5373\u53ef\u8fbe\u5230\u6ee1\u610f\u6548\u679c\uff1b\u5373\u4f7f\u76ee\u6807\u5dee\u5f02\u8f83\u5927\uff0c\u4e5f\u80fd\u57288\u6b21\u8fed\u4ee3\u5185\u6cdb\u5316\u3002", "conclusion": "Meta-PO\u901a\u8fc7\u9ad8\u6548\u3001\u53ef\u6cdb\u5316\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u4e2a\u6027\u5316\u89c6\u89c9\u4f18\u5316\u66f4\u8d34\u8fd1\u666e\u901a\u7528\u6237\uff0c\u5e76\u5177\u5907\u5e7f\u6cdb\u6269\u5c55\u63a5\u53e3\u4e2a\u6027\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15226", "pdf": "https://arxiv.org/pdf/2507.15226", "abs": "https://arxiv.org/abs/2507.15226", "authors": ["Changguo Jia", "Yi Zhan", "Tianqi Zhao", "Hengzhi Ye", "Minghui Zhou"], "title": "Code Clone Detection via an AlphaFold-Inspired Framework", "categories": ["cs.SE"], "comment": null, "summary": "Code clone detection, which aims to identify functionally equivalent code\nfragments, plays a critical role in software maintenance and vulnerability\nanalysis. Substantial methods have been proposed to detect code clones, but\nthey fall short in capturing code semantics or relying on language-specific\nanalyzers. Inspired by the remarkable success of AlphaFold in predicting\nthree-dimensional protein structures from protein sequences, in this paper, we\nleverage AlphaFold for code clone detection based on the insight that protein\nsequences and token sequences share a common linear sequential structure. In\nparticular, we propose AlphaCC, which represents code fragments as token\nsequences to ensure multi-language applicability and adapts AlphaFold's\nsequence-to-structure modeling capability to infer code semantics. The pipeline\nof AlphaCC goes through three steps. First, AlphaCC transforms each input code\nfragment into a token sequence and, motivated by AlphaFold's use of multiple\nsequence alignment (MSA) to enhance contextual understanding, constructs an MSA\nfrom lexically similar token sequences. Second, AlphaCC adopts a modified\nattention-based encoder based on AlphaFold to model dependencies within and\nacross token sequences. Finally, unlike AlphaFold's protein structure\nprediction task, AlphaCC computes similarity scores between token sequences\nthrough a late interaction strategy and performs binary classification to\ndetermine code clone pairs. Comprehensive evaluations on three language-diverse\ndatasets demonstrate AlphaCC's applicability across multiple programming\nlanguages. On two semantic clone detection datasets, it consistently\noutperforms all baselines, showing strong semantic understanding. Moreover,\nAlphaCC maintains competitive efficiency, enabling practical usage in\nlarge-scale clone detection tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAlphaCC\u7684\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7075\u611f\u6765\u81eaAlphaFold\u7684\u6210\u529f\uff0c\u901a\u8fc7\u5c06\u4ee3\u7801\u7247\u6bb5\u8868\u793a\u4e3a\u6807\u8bb0\u5e8f\u5217\uff0c\u5e76\u5229\u7528\u591a\u5e8f\u5217\u5bf9\u9f50\u548c\u6ce8\u610f\u529b\u7f16\u7801\u5668\u6765\u6355\u6349\u4ee3\u7801\u8bed\u4e49\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u4ee3\u7801\u8bed\u4e49\u6216\u4f9d\u8d56\u7279\u5b9a\u8bed\u8a00\u5206\u6790\u5668\u3002\u53d7\u5230AlphaFold\u9884\u6d4b\u86cb\u767d\u8d28\u7ed3\u6784\u7684\u542f\u53d1\uff0c\u8ba4\u4e3a\u86cb\u767d\u8d28\u5e8f\u5217\u4e0e\u4ee3\u7801\u6807\u8bb0\u5e8f\u5217\u5177\u6709\u76f8\u4f3c\u7684\u7ebf\u6027\u7ed3\u6784\u3002", "method": "\u5c06\u4ee3\u7801\u7247\u6bb5\u8f6c\u4e3a\u6807\u8bb0\u5e8f\u5217\uff0c\u6784\u5efa\u591a\u5e8f\u5217\u5bf9\u9f50\uff08MSA\uff09\uff0c\u4f7f\u7528\u4fee\u6539\u540e\u7684\u6ce8\u610f\u529b\u7f16\u7801\u5668\u5efa\u6a21\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u540e\u4ea4\u4e92\u7b56\u7565\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u5e76\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\u3002", "result": "\u5728\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176\u5728\u8bed\u4e49\u514b\u9686\u68c0\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6548\u7684\u8fd0\u884c\u6548\u7387\u3002", "conclusion": "AlphaCC\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5177\u6709\u5f3a\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2507.15423", "pdf": "https://arxiv.org/pdf/2507.15423", "abs": "https://arxiv.org/abs/2507.15423", "authors": ["Laura Finarelli", "Falko Dressler", "Marco Ajmone Marsan", "Gianluca Rizzo"], "title": "Assessing the Benefits of Ground Vehicles as Moving Urban Base Stations", "categories": ["cs.NI"], "comment": null, "summary": "In the evolution towards 6G user-centric networking, the moving network (MN)\nparadigm can play an important role. In a MN, some small cell base stations\n(BS) are installed on top of vehicles, and enable a more dynamic, flexible and\nsustainable, network operation. By \"following\" the users movements and adapting\ndynamically to their requests, the MN paradigm enables a more efficient\nutilization of network resources, mitigating the need for dense small cell BS\ndeployments at the cost of an increase in resource utilization due to wireless\nbackhauling. This aspect is at least partly compensated by the shorter distance\nbetween users and BS, which allows for lower power and Line-of-Sight\ncommunications. While the MN paradigm has been investigated for some time, to\ndate, it is still unclear in which conditions the advantages of MN outweigh the\nadditional resource costs. In this paper, we propose a stochastic geometry\nframework for the characterization of the potential benefits of the MN paradigm\nas part of an HetNet in urban settings. Our approach allows the estimation of\nuser-perceived performance, accounting for wireless backhaul connectivity as\nwell as base station resource scheduling. We formulate an optimization problem\nfor determining the resource-optimal network configurations and BS scheduling\nwhich minimize the overall amount of deployed BSs in a QoS-aware manner, and\nthe minimum vehicular flow between different urban districts required to\nsupport them, and we propose an efficient stochastic heuristic to solve it. Our\nnumerical assessment suggests that the MN paradigm, coupled with appropriate\ndynamic network management strategies, significantly reduces the amount of\ndeployed network infrastructure while guaranteeing the target QoS perceived by\nusers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u51e0\u4f55\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u79fb\u52a8\u7f51\u7edc\uff08MN\uff09\u5728\u5f02\u6784\u7f51\u7edc\uff08HetNet\uff09\u4e2d\u7684\u6f5c\u5728\u4f18\u52bf\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u95ee\u9898\u548c\u542f\u53d1\u5f0f\u7b97\u6cd5\u51cf\u5c11\u57fa\u7840\u8bbe\u65bd\u90e8\u7f72\u3002", "motivation": "\u63a2\u8ba8\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u79fb\u52a8\u7f51\u7edc\u7684\u4f18\u52bf\u80fd\u8d85\u8fc7\u5176\u989d\u5916\u8d44\u6e90\u6210\u672c\uff0c\u4e3a6G\u7528\u6237\u4e2d\u5fc3\u7f51\u7edc\u63d0\u4f9b\u66f4\u52a8\u6001\u3001\u7075\u6d3b\u548c\u53ef\u6301\u7eed\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u968f\u673a\u51e0\u4f55\u6846\u67b6\u8bc4\u4f30\u7528\u6237\u611f\u77e5\u6027\u80fd\uff0c\u8003\u8651\u65e0\u7ebf\u56de\u7a0b\u8fde\u63a5\u548c\u57fa\u7ad9\u8d44\u6e90\u8c03\u5ea6\uff0c\u63d0\u51fa\u4f18\u5316\u95ee\u9898\u548c\u542f\u53d1\u5f0f\u7b97\u6cd5\u4ee5\u6700\u5c0f\u5316\u57fa\u7ad9\u90e8\u7f72\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u8868\u660e\uff0c\u79fb\u52a8\u7f51\u7edc\u7ed3\u5408\u52a8\u6001\u7ba1\u7406\u7b56\u7565\u53ef\u663e\u8457\u51cf\u5c11\u57fa\u7840\u8bbe\u65bd\u90e8\u7f72\uff0c\u540c\u65f6\u4fdd\u8bc1\u7528\u6237\u76ee\u6807\u670d\u52a1\u8d28\u91cf\u3002", "conclusion": "\u79fb\u52a8\u7f51\u7edc\u8303\u5f0f\u5728\u9002\u5f53\u52a8\u6001\u7ba1\u7406\u7b56\u7565\u4e0b\u80fd\u6709\u6548\u4f18\u5316\u8d44\u6e90\u5229\u7528\u5e76\u4fdd\u969c\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2507.15433", "pdf": "https://arxiv.org/pdf/2507.15433", "abs": "https://arxiv.org/abs/2507.15433", "authors": ["Lou Schwartz", "Mohammad Ghoniem", "Val\u00e9rie Maquil", "Adrien Coppens", "Johannes Hermen"], "title": "Designing at 1:1 Scale on Wall-Sized Displays Using Existing UI Design Tools", "categories": ["cs.HC"], "comment": "Publication URL:\n  https://www.thinkmind.org/library/Soft/Soft_v18_n12_2025/soft_v18_n12_2025_5.html", "summary": "Wall-Sized Displays have spatial characteristics that are difficult to\naddress during user interface design. The design at scale 1:1 could be part of\nthe solution. In this paper, we present the results of two user studies and one\ntechnology review, exploring the usability of popular, desktop-optimized\nprototyping tools, for designing at scale on Wall-Sized Displays. We considered\ntwo wall-sized display setups, and three different interaction methods: touch,\na keyboard equipped with a touchpad, and a tablet. We observed that designing\nat scale 1:1 was appreciated. Tablet-based interaction proved to be the most\ncomfortable interaction method, and a mix of interaction modalities is\npromising. In addition, care must be given to the surrounding environment, such\nas furniture. We propose twelve design guidelines for a design tool dedicated\nto this specific context. Overall, existing user interface design tools do not\nyet fully support design on and for wall-sized displays and require further\nconsiderations in terms of placement of user interface elements and the\nprovision of additional features.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u5899\u5c3a\u5bf8\u663e\u793a\u5668\u4e0a\u4f7f\u7528\u684c\u9762\u4f18\u5316\u539f\u578b\u5de5\u5177\u8fdb\u884c1:1\u6bd4\u4f8b\u8bbe\u8ba1\u7684\u53ef\u7528\u6027\uff0c\u53d1\u73b0\u5e73\u677f\u4ea4\u4e92\u6700\u8212\u9002\uff0c\u5e76\u63d0\u51fa12\u6761\u8bbe\u8ba1\u6307\u5357\u3002", "motivation": "\u5899\u5c3a\u5bf8\u663e\u793a\u5668\u7684\u7a7a\u95f4\u7279\u6027\u7ed9\u7528\u6237\u754c\u9762\u8bbe\u8ba1\u5e26\u6765\u6311\u6218\uff0c1:1\u6bd4\u4f8b\u8bbe\u8ba1\u53ef\u80fd\u662f\u89e3\u51b3\u65b9\u6848\u7684\u4e00\u90e8\u5206\u3002", "method": "\u901a\u8fc7\u4e24\u9879\u7528\u6237\u7814\u7a76\u548c\u4e00\u9879\u6280\u672f\u5ba1\u67e5\uff0c\u8bc4\u4f30\u4e86\u684c\u9762\u4f18\u5316\u539f\u578b\u5de5\u5177\u5728\u5899\u5c3a\u5bf8\u663e\u793a\u5668\u4e0a\u7684\u53ef\u7528\u6027\uff0c\u8003\u8651\u4e86\u4e24\u79cd\u663e\u793a\u8bbe\u7f6e\u548c\u4e09\u79cd\u4ea4\u4e92\u65b9\u6cd5\uff08\u89e6\u63a7\u3001\u952e\u76d8+\u89e6\u6478\u677f\u3001\u5e73\u677f\uff09\u3002", "result": "1:1\u6bd4\u4f8b\u8bbe\u8ba1\u53d7\u5230\u8ba4\u53ef\uff0c\u5e73\u677f\u4ea4\u4e92\u6700\u8212\u9002\uff0c\u6df7\u5408\u4ea4\u4e92\u6a21\u5f0f\u6709\u6f5c\u529b\uff0c\u73af\u5883\u9700\u6ce8\u610f\u3002", "conclusion": "\u73b0\u6709\u8bbe\u8ba1\u5de5\u5177\u5bf9\u5899\u5c3a\u5bf8\u663e\u793a\u5668\u7684\u652f\u6301\u4e0d\u8db3\uff0c\u9700\u8fdb\u4e00\u6b65\u8003\u8651\u754c\u9762\u5143\u7d20\u5e03\u5c40\u548c\u529f\u80fd\u589e\u5f3a\u3002"}}
{"id": "2507.15241", "pdf": "https://arxiv.org/pdf/2507.15241", "abs": "https://arxiv.org/abs/2507.15241", "authors": ["Vikram Nitin", "Baishakhi Ray", "Roshanak Zilouchian Moghaddam"], "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "categories": ["cs.SE"], "comment": null, "summary": "Despite the critical threat posed by software security vulnerabilities,\nreports are often incomplete, lacking the proof-of-vulnerability (PoV) tests\nneeded to validate fixes and prevent regressions. These tests are crucial not\nonly for ensuring patches work, but also for helping developers understand how\nvulnerabilities can be exploited. Generating PoV tests is a challenging\nproblem, requiring reasoning about the flow of control and data through deeply\nnested levels of a program.\n  We present FaultLine, an LLM agent workflow that uses a set of carefully\ndesigned reasoning steps, inspired by aspects of traditional static and dynamic\nprogram analysis, to automatically generate PoV test cases. Given a software\nproject with an accompanying vulnerability report, FaultLine 1) traces the flow\nof an input from an externally accessible API (\"source\") to the \"sink\"\ncorresponding to the vulnerability, 2) reasons about the conditions that an\ninput must satisfy in order to traverse the branch conditions encountered along\nthe flow, and 3) uses this reasoning to generate a PoV test case in a\nfeedback-driven loop. FaultLine does not use language-specific static or\ndynamic analysis components, which enables it to be used across programming\nlanguages.\n  To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100\nknown vulnerabilities in Java, C and C++ projects. On this dataset, FaultLine\nis able to generate PoV tests for 16 projects, compared to just 9 for CodeAct\n2.1, a popular state-of-the-art open-source agentic framework. Thus, FaultLine\nrepresents a 77% relative improvement over the state of the art. Our findings\nsuggest that hierarchical reasoning can enhance the performance of LLM agents\non PoV test generation, but the problem in general remains challenging. We make\nour code and dataset publicly available in the hope that it will spur further\nresearch in this area.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFaultLine\u7684LLM\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u6f0f\u6d1e\u8bc1\u660e\u6d4b\u8bd5\uff08PoV\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u8f6f\u4ef6\u6f0f\u6d1e\u62a5\u544a\u4e2d\u5e38\u7f3a\u4e4f\u9a8c\u8bc1\u8865\u4e01\u6240\u9700\u7684PoV\u6d4b\u8bd5\uff0c\u5bfc\u81f4\u96be\u4ee5\u786e\u4fdd\u4fee\u590d\u6548\u679c\u548c\u9632\u6b62\u56de\u5f52\u95ee\u9898\u3002", "method": "FaultLine\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u548c\u52a8\u6001\u5206\u6790\u7684\u63a8\u7406\u6b65\u9aa4\uff0c\u8ffd\u8e2a\u6f0f\u6d1e\u6e90\u5230\u6c47\u7684\u8def\u5f84\uff0c\u5e76\u751f\u6210PoV\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5728100\u4e2a\u5df2\u77e5\u6f0f\u6d1e\u7684\u6570\u636e\u96c6\u4e0a\uff0cFaultLine\u6210\u529f\u751f\u6210\u4e8616\u4e2a\u9879\u76ee\u7684PoV\u6d4b\u8bd5\uff0c\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u9ad8\u4e8677%\u3002", "conclusion": "\u5206\u5c42\u63a8\u7406\u80fd\u63d0\u5347LLM\u4ee3\u7406\u5728PoV\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u4f46\u95ee\u9898\u4ecd\u5177\u6311\u6218\u6027\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.15659", "pdf": "https://arxiv.org/pdf/2507.15659", "abs": "https://arxiv.org/abs/2507.15659", "authors": ["Gabriel Paradzik", "Benjamin Steinert", "Heinrich Abele", "Michael Menth"], "title": "SENSOR: A Cost-Efficient Open-Source Flow Monitoring Platform", "categories": ["cs.NI"], "comment": null, "summary": "This paper presents a cost-effective and distributed flow monitoring platform\nfor collecting unsampled IPFIX data exclusively using open-source tools, which\nis implemented at the University of T\\\"ubingen. An overview of all tools is\ngiven and their use is explained.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f00\u6e90\u5de5\u5177\u7684\u4f4e\u6210\u672c\u5206\u5e03\u5f0f\u6d41\u91cf\u76d1\u63a7\u5e73\u53f0\uff0c\u7528\u4e8e\u6536\u96c6\u672a\u91c7\u6837\u7684IPFIX\u6570\u636e\u3002", "motivation": "\u901a\u8fc7\u5f00\u6e90\u5de5\u5177\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u5206\u5e03\u5f0f\u7684\u6d41\u91cf\u76d1\u63a7\uff0c\u89e3\u51b3\u4f20\u7edf\u76d1\u63a7\u65b9\u6cd5\u7684\u6210\u672c\u9ad8\u548c\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u5de5\u5177\u6784\u5efa\u5e73\u53f0\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5de5\u5177\u7684\u9009\u62e9\u548c\u4f7f\u7528\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u5728\u8482\u5bbe\u6839\u5927\u5b66\u5b9e\u73b0\u4e86\u8be5\u5e73\u53f0\uff0c\u80fd\u591f\u9ad8\u6548\u6536\u96c6IPFIX\u6570\u636e\u3002", "conclusion": "\u8be5\u5e73\u53f0\u8bc1\u660e\u4e86\u5229\u7528\u5f00\u6e90\u5de5\u5177\u6784\u5efa\u5206\u5e03\u5f0f\u6d41\u91cf\u76d1\u63a7\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2507.15443", "pdf": "https://arxiv.org/pdf/2507.15443", "abs": "https://arxiv.org/abs/2507.15443", "authors": ["Adrien Coppens", "Val\u00e9rie Maquil"], "title": "Evaluating Joint Attention for Mixed-Presence Collaboration on Wall-Sized Displays", "categories": ["cs.HC"], "comment": "Version of record / published version:\n  https://dl.acm.org/doi/full/10.1145/3731406.3731973", "summary": "To understand and quantify the quality of mixed-presence collaboration around\nwall-sized displays, robust evaluation methodologies are needed, that are\nadapted for a room-sized experience and are not perceived as obtrusive. In this\npaper, we propose our approach for measuring joint attention based on head gaze\ndata. We describe how it has been implemented for a user study on mixed\npresence collaboration with two wall-sized displays and report on the insights\nwe gained so far from its implementation, with a preliminary focus on the data\ncoming from one particular session.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5934\u90e8\u6ce8\u89c6\u6570\u636e\u7684\u8054\u5408\u6ce8\u610f\u529b\u6d4b\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5899\u5c4f\u6df7\u5408\u5728\u573a\u534f\u4f5c\u7684\u8d28\u91cf\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u9002\u5e94\u623f\u95f4\u89c4\u6a21\u4f53\u9a8c\u4e14\u4e0d\u663e\u4fb5\u6270\u7684\u7a33\u5065\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5934\u90e8\u6ce8\u89c6\u6570\u636e\u6d4b\u91cf\u8054\u5408\u6ce8\u610f\u529b\uff0c\u5e76\u5728\u5899\u5c4f\u6df7\u5408\u5728\u573a\u534f\u4f5c\u7684\u7528\u6237\u7814\u7a76\u4e2d\u5b9e\u65bd\u3002", "result": "\u4ece\u521d\u6b65\u6570\u636e\u4e2d\u83b7\u5f97\u4e86\u4e00\u4e9b\u5173\u4e8e\u8054\u5408\u6ce8\u610f\u529b\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5899\u5c4f\u6df7\u5408\u5728\u573a\u534f\u4f5c\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u601d\u8def\u3002"}}
{"id": "2507.15251", "pdf": "https://arxiv.org/pdf/2507.15251", "abs": "https://arxiv.org/abs/2507.15251", "authors": ["Boyang Yang", "Luyao Ren", "Xin Yin", "Jiadong Ren", "Haoye Tian", "Shunfu Jin"], "title": "Input Reduction Enhanced LLM-based Program Repair", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have shown great potential in Automated Program\nRepair (APR). Test inputs, being crucial for reasoning the root cause of\nfailures, are always included in the prompt for LLM-based APR. Unfortunately,\nLLMs struggle to retain key information in long prompts. When the test inputs\nare extensive in the prompt, this may trigger the \"lost-in-the-middle\" issue,\ncompromising repair performance. To address this, we propose ReduceFix, an\nLLM-based APR approach with a built-in component that automatically reduces\ntest inputs while retaining their failure-inducing behavior. ReduceFix prompts\nan LLM to generate a reducer that minimizes failure-inducing test inputs\nwithout human effort, and then feeds the reduced failure-inducing inputs to\nguide patch generation.\n  For targeted evaluation, we constructed LFTBench, the first long-input APR\nbenchmark with 200 real bugs from 20 programming tasks, each paired with a\nfailure-inducing input whose median size is 1 MB. On this benchmark, ReduceFix\nshrinks inputs by 89.1% on average and improves overall pass@10 by up to 53.8%\nrelative to a prompt that includes the original test, and by 17.6% compared\nwith omitting the test entirely. Adding the same reduction step to ChatRepair\nincreases its fix rate by 21.3% without other changes. Ablation studies further\nhighlight the impact of input length and compressed failure information on\nrepair success. These results underscore that automatically reducing failing\ninputs is a practical and powerful complement to LLM-based APR, significantly\nimproving its scalability and effectiveness.", "AI": {"tldr": "ReduceFix\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u7f29\u51cf\u6d4b\u8bd5\u8f93\u5165\u6765\u907f\u514d\u957f\u63d0\u793a\u4e2d\u7684\u201c\u4e2d\u95f4\u4e22\u5931\u201d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4fee\u590d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u5728\u957f\u63d0\u793a\u4e2d\u5bb9\u6613\u4e22\u5931\u5173\u952e\u4fe1\u606f\uff08\u5982\u6d4b\u8bd5\u8f93\u5165\uff09\uff0c\u5f71\u54cd\u4fee\u590d\u6027\u80fd\uff0c\u9700\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faReduceFix\u65b9\u6cd5\uff0c\u901a\u8fc7LLM\u751f\u6210\u7f29\u51cf\u5668\uff0c\u81ea\u52a8\u6700\u5c0f\u5316\u5931\u8d25\u8bf1\u5bfc\u7684\u6d4b\u8bd5\u8f93\u5165\uff0c\u4fdd\u7559\u5176\u5173\u952e\u884c\u4e3a\u3002", "result": "\u5728LFTBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReduceFix\u5e73\u5747\u7f29\u51cf\u8f93\u516589.1%\uff0c\u4fee\u590d\u6210\u529f\u7387\u63d0\u9ad853.8%\uff0c\u4e14\u4f18\u5316\u5176\u4ed6\u65b9\u6cd5\u7684\u4fee\u590d\u738721.3%\u3002", "conclusion": "\u81ea\u52a8\u7f29\u51cf\u5931\u8d25\u8f93\u5165\u662fLLM-based APR\u7684\u5b9e\u7528\u4e14\u5f3a\u6548\u8865\u5145\uff0c\u663e\u8457\u63d0\u5347\u5176\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.15670", "pdf": "https://arxiv.org/pdf/2507.15670", "abs": "https://arxiv.org/abs/2507.15670", "authors": ["Rosario Patan\u00e8", "Nadjib Achir", "Andrea Araldo", "Lila Boukhatem"], "title": "Vehicular Cloud Computing: A cost-effective alternative to Edge Computing in 5G networks", "categories": ["cs.NI"], "comment": null, "summary": "Edge Computing (EC) is a computational paradigm that involves deploying\nresources such as CPUs and GPUs near end-users, enabling low-latency\napplications like augmented reality and real-time gaming. However, deploying\nand maintaining a vast network of EC nodes is costly, which can explain its\nlimited deployment today. A new paradigm called Vehicular Cloud Computing (VCC)\nhas emerged and inspired interest among researchers and industry. VCC\nopportunistically utilizes existing and idle vehicular computational resources\nfor external task offloading. This work is the first to systematically address\nthe following question: Can VCC replace EC for low-latency applications?\nAnswering this question is highly relevant for Network Operators (NOs), as VCC\ncould eliminate costs associated with EC given that it requires no\ninfrastructural investment. Despite its potential, no systematic study has yet\nexplored the conditions under which VCC can effectively support low-latency\napplications without relying on EC. This work aims to fill that gap. Extensive\nsimulations allow for assessing the crucial scenario factors that determine\nwhen this EC-to-VCC substitution is feasible. Considered factors are load,\nvehicles mobility and density, and availability. Potential for substitution is\nassessed based on multiple criteria, such as latency, task completion success,\nand cost. Vehicle mobility is simulated in SUMO, and communication in NS3\n5G-LENA. The findings show that VCC can effectively replace EC for low-latency\napplications, except in extreme cases when the EC is still required (latency <\n16 ms).", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u8f66\u8f7d\u4e91\u8ba1\u7b97\uff08VCC\uff09\u662f\u5426\u80fd\u66ff\u4ee3\u8fb9\u7f18\u8ba1\u7b97\uff08EC\uff09\u652f\u6301\u4f4e\u5ef6\u8fdf\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\uff08EC\uff09\u90e8\u7f72\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u8f66\u8f7d\u4e91\u8ba1\u7b97\uff08VCC\uff09\u5229\u7528\u7a7a\u95f2\u8f66\u8f7d\u8d44\u6e90\uff0c\u53ef\u80fd\u6210\u4e3a\u4f4e\u6210\u672c\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7SUMO\u6a21\u62df\u8f66\u8f86\u79fb\u52a8\u6027\uff0cNS3 5G-LENA\u6a21\u62df\u901a\u4fe1\uff0c\u8bc4\u4f30\u8d1f\u8f7d\u3001\u8f66\u8f86\u5bc6\u5ea6\u548c\u53ef\u7528\u6027\u7b49\u56e0\u7d20\u5bf9VCC\u66ff\u4ee3EC\u7684\u5f71\u54cd\u3002", "result": "VCC\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u53ef\u4ee5\u66ff\u4ee3EC\uff0c\u4f46\u5ef6\u8fdf\u4f4e\u4e8e16\u6beb\u79d2\u65f6\u4ecd\u9700\u4f9d\u8d56EC\u3002", "conclusion": "VCC\u662fEC\u7684\u4e00\u79cd\u53ef\u884c\u4f4e\u6210\u672c\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5728\u6781\u4f4e\u5ef6\u8fdf\u9700\u6c42\u573a\u666f\u4e2d\u4ecd\u9700EC\u7684\u652f\u6301\u3002"}}
{"id": "2507.15481", "pdf": "https://arxiv.org/pdf/2507.15481", "abs": "https://arxiv.org/abs/2507.15481", "authors": ["Yesica Duarte", "Puneet Jain"], "title": "Challenging Disability and Interaction Norms in XR: Cooling Down the Empathy Machine in Waiting for Hands", "categories": ["cs.HC"], "comment": null, "summary": "Virtual Reality (VR) is often described as the \"ultimate empathy machine,\"\nframing disability as an experience to be simulated through such technologies,\nwhich can reduce disability to a spectacle of pity or inspiration. In response,\nwe present Waiting for Hands (WfH), an interactive eXtended Reality (XR)\ninstallation that critiques this logic by: (1) repurposing interaction norms in\nXR through the creation of Alternative Controllers, and (2) staging an absurd\nXR performance using the built controllers to disrupt sentimentalized\ndisability narratives. The performance involves eight people: two XR\nparticipants on stage and six audience members watching a projected documentary\nabout Hema Kumari, an Indian singer living with Rheumatoid Arthritis. The XR\nusers partially obscure the film, drawing attention through strange mouth and\nhand movements performed in XR. This creates a layered experience that disrupts\ndirect engagement with Hema's story and introduces uncertainty. While XR is\noften seen as a fully immersive, sensory-dominant medium, this piece subverts\nthat framing by using XR to produce absurdity and alienation. By challenging\nempathy-driven and pitiable narratives of disability, we ask what ethical\nstance an XR performance can take to attune participants to non-normative\nembodiment while resisting spectacle.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7XR\u88c5\u7f6e\u300aWaiting for Hands\u300b\u6279\u5224VR\u7684\u540c\u60c5\u53d9\u4e8b\uff0c\u63d0\u51fa\u66ff\u4ee3\u63a7\u5236\u5668\u548c\u8352\u8bde\u8868\u6f14\uff0c\u6311\u6218\u5bf9\u6b8b\u75be\u7684\u523b\u677f\u5370\u8c61\u3002", "motivation": "VR\u5e38\u88ab\u6807\u699c\u4e3a\u2018\u7ec8\u6781\u5171\u60c5\u673a\u5668\u2019\uff0c\u4f46\u53ef\u80fd\u5bfc\u81f4\u5bf9\u6b8b\u75be\u7684\u7b80\u5316\u6216\u540c\u60c5\u5316\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7XR\u88c5\u7f6e\u98a0\u8986\u8fd9\u79cd\u53d9\u4e8b\u3002", "method": "\u8bbe\u8ba1\u66ff\u4ee3\u63a7\u5236\u5668\u5e76\u521b\u4f5cXR\u8352\u8bde\u8868\u6f14\uff0c\u901a\u8fc7\u90e8\u5206\u906e\u6321\u7535\u5f71\u548c\u5947\u602a\u52a8\u4f5c\uff0c\u5236\u9020\u4e0d\u786e\u5b9a\u6027\u4f53\u9a8c\u3002", "result": "XR\u8868\u6f14\u6210\u529f\u5236\u9020\u758f\u79bb\u611f\uff0c\u6311\u6218\u4e86\u6c89\u6d78\u5f0f\u5a92\u4ecb\u7684\u5e38\u89c4\u53d9\u4e8b\uff0c\u5524\u8d77\u5bf9\u975e\u6807\u51c6\u8eab\u4f53\u7684\u5173\u6ce8\u3002", "conclusion": "\u7814\u7a76\u63d0\u51faXR\u8868\u6f14\u53ef\u4ee5\u901a\u8fc7\u8352\u8bde\u548c\u758f\u79bb\u7684\u65b9\u5f0f\uff0c\u5f15\u5bfc\u53c2\u4e0e\u8005\u53cd\u601d\u6b8b\u75be\u53d9\u4e8b\u4e2d\u7684\u4f26\u7406\u7acb\u573a\u3002"}}
{"id": "2507.15296", "pdf": "https://arxiv.org/pdf/2507.15296", "abs": "https://arxiv.org/abs/2507.15296", "authors": ["Qian Xiong", "Yuekai Huang", "Ziyou Jiang", "Zhiyuan Chang", "Yujia Zheng", "Tianhao Li", "Mingyang Li"], "title": "Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The emergence of the tool agent paradigm has broadened the capability\nboundaries of the Large Language Model (LLM), enabling it to complete more\ncomplex tasks. However, the effectiveness of this paradigm is limited due to\nthe issue of parameter failure during its execution. To explore this phenomenon\nand propose corresponding suggestions, we first construct a parameter failure\ntaxonomy in this paper. We derive five failure categories from the invocation\nchain of a mainstream tool agent. Then, we explore the correlation between\nthree different input sources and failure categories by applying 15 input\nperturbation methods to the input. Experimental results show that parameter\nname hallucination failure primarily stems from inherent LLM limitations, while\nissues with input sources mainly cause other failure patterns. To improve the\nreliability and effectiveness of tool-agent interactions, we propose\ncorresponding improvement suggestions, including standardizing tool return\nformats, improving error feedback mechanisms, and ensuring parameter\nconsistency.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5de5\u5177\u4ee3\u7406\u8303\u5f0f\u4e2d\u53c2\u6570\u5931\u8d25\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5206\u7c7b\u548c\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76\u5de5\u5177\u4ee3\u7406\u8303\u5f0f\u4e2d\u53c2\u6570\u5931\u8d25\u7684\u6839\u6e90\uff0c\u4ee5\u63d0\u9ad8LLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "method": "\u6784\u5efa\u53c2\u6570\u5931\u8d25\u5206\u7c7b\u4f53\u7cfb\uff0c\u901a\u8fc715\u79cd\u8f93\u5165\u6270\u52a8\u65b9\u6cd5\u5206\u6790\u8f93\u5165\u6e90\u4e0e\u5931\u8d25\u7c7b\u578b\u7684\u76f8\u5173\u6027\u3002", "result": "\u53c2\u6570\u540d\u79f0\u5e7b\u89c9\u5931\u8d25\u4e3b\u8981\u7531LLM\u56fa\u6709\u5c40\u9650\u5f15\u8d77\uff0c\u5176\u4ed6\u5931\u8d25\u6a21\u5f0f\u5219\u4e0e\u8f93\u5165\u6e90\u95ee\u9898\u76f8\u5173\u3002", "conclusion": "\u5efa\u8bae\u6807\u51c6\u5316\u5de5\u5177\u8fd4\u56de\u683c\u5f0f\u3001\u6539\u8fdb\u9519\u8bef\u53cd\u9988\u673a\u5236\u548c\u786e\u4fdd\u53c2\u6570\u4e00\u81f4\u6027\uff0c\u4ee5\u63d0\u5347\u5de5\u5177\u4ee3\u7406\u4e92\u52a8\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.15502", "pdf": "https://arxiv.org/pdf/2507.15502", "abs": "https://arxiv.org/abs/2507.15502", "authors": ["Chen Chen", "Jianing Yin", "Jiannong Cao", "Zhiyuan Wen", "Mingjin Zhang", "Weixun Gao", "Xiang Wang", "Haihua Shu"], "title": "FollowUpBot: An LLM-Based Conversational Robot for Automatic Postoperative Follow-up", "categories": ["cs.HC"], "comment": null, "summary": "Postoperative follow-up plays a crucial role in monitoring recovery and\nidentifying complications. However, traditional approaches, typically involving\nbedside interviews and manual documentation, are time-consuming and\nlabor-intensive. Although existing digital solutions, such as web\nquestionnaires and intelligent automated calls, can alleviate the workload of\nnurses to a certain extent, they either deliver an inflexible scripted\ninteraction or face private information leakage issues. To address these\nlimitations, this paper introduces FollowUpBot, an LLM-powered edge-deployed\nrobot for postoperative care and monitoring. It allows dynamic planning of\noptimal routes and uses edge-deployed LLMs to conduct adaptive and face-to-face\nconversations with patients through multiple interaction modes, ensuring data\nprivacy. Moreover, FollowUpBot is capable of automatically generating\nstructured postoperative follow-up reports for healthcare institutions by\nanalyzing patient interactions during follow-up. Experimental results\ndemonstrate that our robot achieves high coverage and satisfaction in follow-up\ninteractions, as well as high report generation accuracy across diverse field\ntypes. The demonstration video is available at\nhttps://www.youtube.com/watch?v=_uFgDO7NoK0.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFollowUpBot\u7684LLM\u9a71\u52a8\u8fb9\u7f18\u90e8\u7f72\u673a\u5668\u4eba\uff0c\u7528\u4e8e\u672f\u540e\u62a4\u7406\u548c\u76d1\u6d4b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u957f\u3001\u73b0\u6709\u6570\u5b57\u89e3\u51b3\u65b9\u6848\u4e92\u52a8\u4e0d\u7075\u6d3b\u6216\u9690\u79c1\u6cc4\u9732\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u672f\u540e\u968f\u8bbf\u65b9\u6cd5\u8017\u65f6\u8017\u529b\uff0c\u73b0\u6709\u6570\u5b57\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u4e92\u52a8\u4e0d\u7075\u6d3b\u6216\u9690\u79c1\u6cc4\u9732\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u7075\u6d3b\u4e14\u5b89\u5168\u7684\u6280\u672f\u3002", "method": "\u901a\u8fc7\u8fb9\u7f18\u90e8\u7f72\u7684LLM\u8fdb\u884c\u81ea\u9002\u5e94\u9762\u5bf9\u9762\u4ea4\u6d41\uff0c\u52a8\u6001\u89c4\u5212\u6700\u4f18\u8def\u7ebf\uff0c\u652f\u6301\u591a\u79cd\u4e92\u52a8\u6a21\u5f0f\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316\u968f\u8bbf\u62a5\u544a\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eFollowUpBot\u5728\u968f\u8bbf\u4e92\u52a8\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8986\u76d6\u7387\u548c\u6ee1\u610f\u5ea6\uff0c\u4e14\u62a5\u544a\u751f\u6210\u51c6\u786e\u7387\u9ad8\u3002", "conclusion": "FollowUpBot\u4e3a\u672f\u540e\u968f\u8bbf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u4e14\u9690\u79c1\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15343", "pdf": "https://arxiv.org/pdf/2507.15343", "abs": "https://arxiv.org/abs/2507.15343", "authors": ["Kechi Zhang", "Ge Li", "Jia Li", "Huangzhao Zhang", "Yihong Dong", "Jia Li", "Jingjing Xu", "Zhi Jin"], "title": "StackTrans: From Large Language Model to Large Pushdown Automata Model", "categories": ["cs.SE", "cs.AI"], "comment": "currently under development", "summary": "The Transformer architecture has emerged as a landmark advancement within the\nbroad field of artificial intelligence, effectively catalyzing the advent of\nlarge language models (LLMs). However, despite its remarkable capabilities and\nthe substantial progress it has facilitated, the Transformer architecture still\nhas some limitations. One such intrinsic limitation is its inability to\neffectively capture the Chomsky hierarchy, such as regular expressions or\ndeterministic context-free grammars. Drawing inspiration from pushdown\nautomata, which efficiently resolve deterministic context-free grammars using\nstacks, we propose StackTrans to address the aforementioned issue within LLMs.\nUnlike previous approaches that modify the attention computation, StackTrans\nexplicitly incorporates hidden state stacks between Transformer layers. This\ndesign maintains compatibility with existing frameworks like flash-attention.\nSpecifically, our design features stack operations -- such as pushing and\npopping hidden states -- that are differentiable and can be learned in an\nend-to-end manner. Our comprehensive evaluation spans benchmarks for both\nChomsky hierarchies and large-scale natural languages. Across these diverse\ntasks, StackTrans consistently outperforms standard Transformer models and\nother baselines. We have successfully scaled StackTrans up from 360M to 7B\nparameters. In particular, our from-scratch pretrained model StackTrans-360M\noutperforms several larger open-source LLMs with 2-3x more parameters,\nshowcasing its superior efficiency and reasoning capability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStackTrans\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u9690\u72b6\u6001\u6808\u6765\u589e\u5f3aTransformer\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u5176\u5728\u6355\u83b7\u4e54\u59c6\u65af\u57fa\u5c42\u6b21\u7ed3\u6784\uff08\u5982\u6b63\u5219\u8868\u8fbe\u5f0f\u548c\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\uff09\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "Transformer\u67b6\u6784\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u4e54\u59c6\u65af\u57fa\u5c42\u6b21\u7ed3\u6784\u65f6\u5b58\u5728\u56fa\u6709\u5c40\u9650\u6027\u3002", "method": "StackTrans\u5728Transformer\u5c42\u4e4b\u95f4\u663e\u5f0f\u5f15\u5165\u9690\u72b6\u6001\u6808\uff0c\u652f\u6301\u53ef\u5fae\u5206\u548c\u7aef\u5230\u7aef\u5b66\u4e60\u7684\u6808\u64cd\u4f5c\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u73b0\u6709\u6846\u67b6\u7684\u517c\u5bb9\u6027\u3002", "result": "StackTrans\u5728\u4e54\u59c6\u65af\u57fa\u5c42\u6b21\u7ed3\u6784\u548c\u5927\u89c4\u6a21\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u6807\u51c6Transformer\u548c\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u53c2\u6570\u89c4\u6a21\u53ef\u6269\u5c55\u3002", "conclusion": "StackTrans\u901a\u8fc7\u5f15\u5165\u6808\u64cd\u4f5c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6548\u7387\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5176\u5728LLMs\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15816", "pdf": "https://arxiv.org/pdf/2507.15816", "abs": "https://arxiv.org/abs/2507.15816", "authors": ["Yujia Mu", "Cong Shen"], "title": "Federated Split Learning with Improved Communication and Storage Efficiency", "categories": ["cs.LG", "cs.IT", "cs.NI", "eess.SP", "math.IT"], "comment": "Accepted for publication in IEEE Transactions on Mobile Computing", "summary": "Federated learning (FL) is one of the popular distributed machine learning\n(ML) solutions but incurs significant communication and computation costs at\nedge devices. Federated split learning (FSL) can train sub-models in parallel\nand reduce the computational burden of edge devices by splitting the model\narchitecture. However, it still requires a high communication overhead due to\ntransmitting the smashed data and gradients between clients and the server in\nevery global round. Furthermore, the server must maintain separate partial\nmodels for every client, leading to a significant storage requirement. To\naddress these challenges, this paper proposes a novel communication and storage\nefficient federated split learning method, termed CSE-FSL, which utilizes an\nauxiliary network to locally update the weights of the clients while keeping a\nsingle model at the server, hence avoiding frequent transmissions of gradients\nfrom the server and greatly reducing the storage requirement of the server.\nAdditionally, a new model update method of transmitting the smashed data in\nselected epochs can reduce the amount of smashed data sent from the clients. We\nprovide a theoretical analysis of CSE-FSL, rigorously guaranteeing its\nconvergence under non-convex loss functions. The extensive experimental results\nfurther indicate that CSE-FSL achieves a significant communication reduction\nover existing FSL solutions using real-world FL tasks.", "AI": {"tldr": "CSE-FSL \u662f\u4e00\u79cd\u65b0\u578b\u7684\u8054\u90a6\u5206\u5272\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f85\u52a9\u7f51\u7edc\u51cf\u5c11\u5ba2\u6237\u7aef\u4e0e\u670d\u52a1\u5668\u95f4\u7684\u901a\u4fe1\u548c\u5b58\u50a8\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5206\u5272\u5b66\u4e60\uff08FSL\uff09\u4e2d\u9ad8\u901a\u4fe1\u5f00\u9500\u548c\u670d\u52a1\u5668\u5b58\u50a8\u9700\u6c42\u5927\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8f85\u52a9\u7f51\u7edc\u672c\u5730\u66f4\u65b0\u5ba2\u6237\u7aef\u6743\u91cd\uff0c\u51cf\u5c11\u68af\u5ea6\u4f20\u8f93\uff0c\u5e76\u5728\u7279\u5b9a\u5468\u671f\u4f20\u8f93\u6570\u636e\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u5176\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "CSE-FSL \u5728\u901a\u4fe1\u548c\u5b58\u50a8\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709 FSL \u65b9\u6cd5\u3002"}}
{"id": "2507.15526", "pdf": "https://arxiv.org/pdf/2507.15526", "abs": "https://arxiv.org/abs/2507.15526", "authors": ["Antonio Perez", "Avinash Singh", "Jonathan Mitchell", "Philip Swadling"], "title": "Strategies to Manage Human Factors in Mixed Reality Pilot Training: A Survey", "categories": ["cs.HC", "H.5.1; H.1.2; I.3.6"], "comment": "14 pages, 3 figures", "summary": "Mixed Reality (MR) head mounted displays (HMDs) offer a promising alternative\nto traditional Flight Simulator Training Device (FSTD) displays, providing\nimmersion, realism and cost efficiency. However, these technologies require\nmanagement of human factors; cybersickness, visual fatigue and ergonomic\nstrain. If left unmitigated, these effects can hinder pilot performance and\ntraining outcomes. For safety critical fields like aviation, addressing human\nfactors challenges is crucial for MR's training potential. This survey\nsystematically reviews the current literature identifying key human factors\nchallenges in MR HMD use in pilot training and examines strategies to mitigate\nthese barriers. Drawing on existing industry standards set by a leading\naviation authority, the review adopts a regulatory perspective to explore\nhardware, software, ergonomic, physiological and psychological interventions\nimproving pilot comfort, safety and training effectiveness in an MR FSTD.\nAdditionally, it evaluates which of these interventions are most appropriate\nand viable for MR pilot training under existing aviation training regulations,\nensuring that technical requirements and pilot wellbeing remain balanced. The\nfindings yield significant insights for the human dimensions of aviation\nsimulation training, highlighting how regulatory considerations shape the\npracticality of mitigation measures. These insights inform emerging MR aviation\ntraining guidelines and best practices, supporting MR's readiness to enhance\naviation training.", "AI": {"tldr": "MR\u5934\u6234\u663e\u793a\u5668\u5728\u98de\u884c\u6a21\u62df\u8bad\u7ec3\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u89e3\u51b3\u4eba\u7c7b\u56e0\u7d20\u95ee\u9898\u4ee5\u786e\u4fdd\u8bad\u7ec3\u6548\u679c\u548c\u98de\u884c\u5458\u5b89\u5168\u3002", "motivation": "\u7814\u7a76MR\u5934\u6234\u663e\u793a\u5668\u5728\u98de\u884c\u6a21\u62df\u8bad\u7ec3\u4e2d\u7684\u4eba\u7c7b\u56e0\u7d20\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u7f13\u89e3\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u5176\u8bad\u7ec3\u6f5c\u529b\u7684\u5b9e\u73b0\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u73b0\u6709\u6587\u732e\uff0c\u4ece\u6cd5\u89c4\u89d2\u5ea6\u63a2\u8ba8\u786c\u4ef6\u3001\u8f6f\u4ef6\u3001\u4eba\u4f53\u5de5\u7a0b\u5b66\u53ca\u5fc3\u7406\u5e72\u9884\u63aa\u65bd\u3002", "result": "\u8bc6\u522b\u5173\u952e\u4eba\u7c7b\u56e0\u7d20\u6311\u6218\u5e76\u63d0\u51fa\u7f13\u89e3\u7b56\u7565\uff0c\u540c\u65f6\u8bc4\u4f30\u8fd9\u4e9b\u7b56\u7565\u5728\u73b0\u6709\u822a\u7a7a\u57f9\u8bad\u6cd5\u89c4\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3aMR\u822a\u7a7a\u57f9\u8bad\u6307\u5357\u63d0\u4f9b\u89c1\u89e3\uff0c\u786e\u4fdd\u6280\u672f\u9700\u6c42\u4e0e\u98de\u884c\u5458\u798f\u7949\u5e73\u8861\uff0c\u63a8\u52a8MR\u5728\u822a\u7a7a\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.15599", "pdf": "https://arxiv.org/pdf/2507.15599", "abs": "https://arxiv.org/abs/2507.15599", "authors": ["Manatsawin Hanmongkolchai"], "title": "Applying the Chinese Wall Reverse Engineering Technique to Large Language Model Code Editing", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Large language models for code (Code LLM) are increasingly utilized in\nprogramming environments. Despite their utility, the training datasets for top\nLLM remain undisclosed, raising concerns about potential copyright violations.\nSome models, such as Pleias and Comma put emphasis on data curation and\nlicenses, however, with limited training data these models are not competitive\nand only serve as proof of concepts. To improve the utility of these models, we\npropose an application of the \"Chinese Wall\" technique, inspired by the reverse\nengineering technique of the same name -- a high quality model is used to\ngenerate detailed instructions for a weaker model. By doing so, a weaker but\nethically aligned model may be used to perform complicated tasks that,\notherwise, can only be completed by more powerful models. In our evaluation,\nwe've found that this technique improves Comma v0.1 1T's performance in\nCanItEdit benchmark by over 66%, and Starcoder2 Instruct by roughly 20%\ncompared to when running the same model on the benchmark alone. The practical\napplication of this technique today, however, may be limited due to the lack of\nmodels trained on public domain content without copyright restrictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u201cChinese Wall\u201d\u6280\u672f\uff0c\u901a\u8fc7\u5f3a\u6a21\u578b\u4e3a\u5f31\u6a21\u578b\u751f\u6210\u8be6\u7ec6\u6307\u4ee4\uff0c\u63d0\u5347\u5f31\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f46\u5176\u5e94\u7528\u53d7\u9650\u4e8e\u7f3a\u4e4f\u65e0\u7248\u6743\u9650\u5236\u7684\u516c\u5f00\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7248\u6743\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u8fd9\u4e9b\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u201cChinese Wall\u201d\u6280\u672f\uff0c\u5229\u7528\u9ad8\u8d28\u91cf\u6a21\u578b\u4e3a\u4f26\u7406\u5bf9\u9f50\u7684\u5f31\u6a21\u578b\u751f\u6210\u6307\u4ee4\uff0c\u63d0\u5347\u5176\u6027\u80fd\u3002", "result": "\u8be5\u6280\u672f\u4f7fComma v0.1 1T\u5728CanItEdit\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63d0\u534766%\uff0cStarcoder2 Instruct\u63d0\u5347\u7ea620%\u3002", "conclusion": "\u5c3d\u7ba1\u6280\u672f\u6709\u6548\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u4ecd\u53d7\u9650\u4e8e\u65e0\u7248\u6743\u516c\u5f00\u8bad\u7ec3\u6570\u636e\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.15818", "pdf": "https://arxiv.org/pdf/2507.15818", "abs": "https://arxiv.org/abs/2507.15818", "authors": ["Mohamed Nomeir", "Alptug Aytekin", "Sennur Ulukus"], "title": "The Capacity of Semantic Private Information Retrieval with Colluding Servers", "categories": ["cs.IT", "cs.CR", "cs.NI", "eess.SP", "math.IT"], "comment": null, "summary": "We study the problem of semantic private information retrieval (Sem-PIR) with\n$T$ colluding servers (Sem-TPIR), i.e., servers that collectively share user\nqueries. In Sem-TPIR, the message sizes are different, and message retrieval\nprobabilities by any user are not uniform. This is a generalization of the\nclassical PIR problem where the message sizes are equal and message retrieval\nprobabilities are identical. The earlier work on Sem-PIR considered the case of\nno collusions, i.e., the collusion parameter of $T=1$. In this paper, we\nconsider the general problem for arbitrary $T < N$. We find an upper bound on\nthe retrieval rate and design a scheme that achieves this rate, i.e., we derive\nthe exact capacity of Sem-TPIR.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5e26\u6709$T$\u4e2a\u5408\u8c0b\u670d\u52a1\u5668\u7684\u8bed\u4e49\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u95ee\u9898\uff08Sem-TPIR\uff09\uff0c\u63d0\u51fa\u4e86\u68c0\u7d22\u7387\u7684\u4e0a\u754c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b9\u6848\u5b9e\u73b0\u6b64\u4e0a\u754c\uff0c\u89e3\u51b3\u4e86\u6d88\u606f\u5927\u5c0f\u4e0d\u7b49\u4e14\u68c0\u7d22\u6982\u7387\u4e0d\u5747\u7684\u60c5\u51b5\u3002", "motivation": "\u7ecf\u5178PIR\u95ee\u9898\u5047\u8bbe\u6d88\u606f\u5927\u5c0f\u76f8\u7b49\u4e14\u68c0\u7d22\u6982\u7387\u5747\u5300\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u8fd9\u4e9b\u6761\u4ef6\u53ef\u80fd\u4e0d\u6210\u7acb\u3002Sem-PIR\u5728$T=1$\u65f6\u7684\u7814\u7a76\u5df2\u6709\u8fdb\u5c55\uff0c\u4f46$T>1$\u65f6\u5408\u8c0b\u670d\u52a1\u5668\u7684\u884c\u4e3a\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u6269\u5c55\u4e86Sem-PIR\u95ee\u9898\u5230$T>1$\u7684\u60c5\u51b5\uff0c\u63a8\u5bfc\u4e86\u68c0\u7d22\u7387\u7684\u4e0a\u754c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u8fbe\u5230\u6b64\u4e0a\u754c\u7684\u65b9\u6848\u3002", "result": "\u8bc1\u660e\u4e86\u8be5\u65b9\u6848\u5b9e\u73b0\u4e86Sem-TPIR\u7684\u7cbe\u786e\u5bb9\u91cf\uff0c\u5373\u68c0\u7d22\u7387\u7684\u4e0a\u754c\u662f\u53ef\u8fbe\u5230\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u5408\u8c0b\u670d\u52a1\u5668\u573a\u666f\u4e0b\u7684\u975e\u5747\u5300\u6d88\u606f\u68c0\u7d22\u95ee\u9898\uff0c\u5bf9\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u5747\u6709\u8d21\u732e\u3002"}}
{"id": "2507.15559", "pdf": "https://arxiv.org/pdf/2507.15559", "abs": "https://arxiv.org/abs/2507.15559", "authors": ["Pan Hao", "Dongyeop Kang", "Nicholas Hinds", "Qianwen Wang"], "title": "FlowForge: Guiding the Creation of Multi-agent Workflows with Design Space Visualization as a Thinking Scaffold", "categories": ["cs.HC"], "comment": "9 pages, 10 figures, accepted by IEEE VIS 2025", "summary": "Multi-agent workflows have become an effective strategy for tackling\ncomplicated tasks by decomposing them into multiple sub-tasks and assigning\nthem to specialized agents. However, designing optimal workflows remains\nchallenging due to the vast and intricate design space. Current practices rely\nheavily on the intuition and expertise of practitioners, often resulting in\ndesign fixation or an unstructured, time-consuming exploration of\ntrial-and-error. To address these challenges, this work introduces FLOWFORGE,\nan interactive visualization tool to facilitate the creation of multi-agent\nworkflow through i) a structured visual exploration of the design space and ii)\nin-situ guidance informed by established design patterns. Based on formative\nstudies and literature review, FLOWFORGE organizes the workflow design process\ninto three hierarchical levels (i.e., task planning, agent assignment, and\nagent optimization), ranging from abstract to concrete. This structured visual\nexploration enables users to seamlessly move from high-level planning to\ndetailed design decisions and implementations, while comparing alternative\nsolutions across multiple performance metrics. Additionally, drawing from\nestablished workflow design patterns, FLOWFORGE provides context-aware, in-situ\nsuggestions at each level as users navigate the design space, enhancing the\nworkflow creation process with practical guidance. Use cases and user studies\ndemonstrate the usability and effectiveness of FLOWFORGE, while also yielding\nvaluable insights into how practitioners explore design spaces and leverage\nguidance during workflow development.", "AI": {"tldr": "FLOWFORGE\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5206\u5c42\u63a2\u7d22\u548c\u5b9e\u65f6\u6307\u5bfc\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u7684\u8bbe\u8ba1\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u76f4\u89c9\uff0c\u5bfc\u81f4\u8bbe\u8ba1\u56fa\u5316\u6216\u8017\u65f6\u8bd5\u9519\uff0c\u9700\u66f4\u7ed3\u6784\u5316\u3001\u9ad8\u6548\u7684\u8bbe\u8ba1\u5de5\u5177\u3002", "method": "FLOWFORGE\u5206\u4e09\u7ea7\uff08\u4efb\u52a1\u89c4\u5212\u3001\u667a\u80fd\u4f53\u5206\u914d\u3001\u4f18\u5316\uff09\u63d0\u4f9b\u7ed3\u6784\u5316\u53ef\u89c6\u5316\u548c\u5b9e\u65f6\u8bbe\u8ba1\u6a21\u5f0f\u6307\u5bfc\u3002", "result": "\u7528\u6237\u7814\u7a76\u548c\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5de5\u5177\u7684\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\uff0c\u63d0\u5347\u4e86\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u6548\u7387\u3002", "conclusion": "FLOWFORGE\u4e3a\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u652f\u6301\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63a8\u5e7f\u5176\u5e94\u7528\u3002"}}
{"id": "2507.15624", "pdf": "https://arxiv.org/pdf/2507.15624", "abs": "https://arxiv.org/abs/2507.15624", "authors": ["Yusuf Sulistyo Nugroho", "Ganno Tribuana Kurniaji", "Syful Islam", "Mohammed Humayun Kabir", "Vanesya Aura Ardity", "Md. Kamal Uddin"], "title": "Hot Topics and Common Challenges: an Empirical Study of React Discussions on Stack Overflow", "categories": ["cs.SE"], "comment": "6 pages, 4 figures, 4 tables, conference paper", "summary": "React is a JavaScript library used to build user interfaces for single-page\napplications. Although recent studies have shown the popularity and advantages\nof React in web development, the specific challenges users face remain unknown.\nThus, this study aims to analyse the React-related questions shared on Stack\nOverflow. The study utilizes an exploratory data analysis to investigate the\nmost frequently discussed keywords, error classification, and user\nreputation-based errors, which is the novelty of this work. The results show\nthe top eight most frequently used keywords on React-related questions, namely,\ncode, link, vir, href, connect, azure, windows, and website. The error\nclassification of questions from the sample shows that algorithmic error is the\nmost frequent issue faced by all groups of users, where mid-reputation users\ncontribute the most, accounting for 55.77%. This suggests the need for the\ncommunity to provide guidance materials in solving algorithm-related problems.\nWe expect that the results of this study will provide valuable insight into\nfuture research to support the React community during the early stages of\nimplementation, facilitating their ability to effectively overcome challenges\nto adoption.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790Stack Overflow\u4e0a\u7684React\u76f8\u5173\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u7528\u6237\u6700\u5e38\u8ba8\u8bba\u7684\u5173\u952e\u8bcd\u3001\u9519\u8bef\u5206\u7c7b\u53ca\u57fa\u4e8e\u7528\u6237\u58f0\u8a89\u7684\u9519\u8bef\u5206\u5e03\u3002", "motivation": "\u5c3d\u7ba1React\u5728Web\u5f00\u53d1\u4e2d\u5e7f\u53d7\u6b22\u8fce\uff0c\u4f46\u7528\u6237\u9762\u4e34\u7684\u5177\u4f53\u6311\u6218\u5c1a\u4e0d\u660e\u786e\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76React\u76f8\u5173\u95ee\u9898\u4e2d\u7684\u5173\u952e\u8bcd\u9891\u7387\u3001\u9519\u8bef\u5206\u7c7b\u548c\u7528\u6237\u58f0\u8a89\u4e0e\u9519\u8bef\u7684\u5173\u7cfb\u3002", "result": "\u6700\u5e38\u8ba8\u8bba\u7684\u5173\u952e\u8bcd\u5305\u62eccode\u3001link\u7b49\uff1b\u7b97\u6cd5\u9519\u8bef\u662f\u6700\u5e38\u89c1\u95ee\u9898\uff0c\u4e2d\u7b49\u58f0\u8a89\u7528\u6237\u8d21\u732e\u6700\u591a\uff0855.77%\uff09\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u652f\u6301React\u793e\u533a\u7684\u65e9\u671f\u5b9e\u65bd\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u5efa\u8bae\u793e\u533a\u63d0\u4f9b\u66f4\u591a\u7b97\u6cd5\u95ee\u9898\u89e3\u51b3\u6307\u5bfc\u3002"}}
{"id": "2507.15650", "pdf": "https://arxiv.org/pdf/2507.15650", "abs": "https://arxiv.org/abs/2507.15650", "authors": ["Gerben van der Hoek", "Bastiaan Heeren", "Rogier Bos", "Paul Drijvers", "Johan Jeuring"], "title": "Chapter 11 Students' interaction with and appreciation of automated informative tutoring feedback", "categories": ["cs.HC"], "comment": null, "summary": "Computer aided formative assessment can be used to enhance a learning\nprocess, for instance by providing feedback. There are many design choices for\ndelivering feedback, that lead to a feedback strategy. In an informative\nfeedback strategy, students do not immediately receive information about the\ncorrect response, but are offered the opportunity to retry a task to apply\nfeedback information. In this small-scale qualitative study, we explore an\ninformative feedback strategy designed to offer a balance between room for\nexploration and mitigation of learning barriers. The research questions concern\nthe ways in which students interact with the feedback strategy and their\nappreciation of error-specific feedback as opposed to worked-out solutions. To\nanswer these questions, twenty-five 15-to-17-year-old senior general secondary\neducation students worked for approximately 20 minutes on linear and\nexponential extrapolation tasks in an online environment. Data included screen\ncaptures of students working with the environment and post-intervention\ninterviews. Results showed that room for exploration offered opportunities for\nself-guidance while mitigation of learning barriers prevented disengagement.\nFurthermore, students appreciated balanced feedback. We conclude that the\nbalanced feedback strategy yielded fruitful student-environment interactions.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4e00\u79cd\u5e73\u8861\u7684\u53cd\u9988\u7b56\u7565\uff0c\u5173\u6ce8\u5b66\u751f\u5982\u4f55\u4e0e\u4e4b\u4ea4\u4e92\u5e76\u8bc4\u4ef7\u5176\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u4e00\u79cd\u65e2\u80fd\u63d0\u4f9b\u63a2\u7d22\u7a7a\u95f4\u53c8\u80fd\u51cf\u5c11\u5b66\u4e60\u969c\u788d\u7684\u53cd\u9988\u7b56\u7565\uff0c\u4ee5\u4f18\u5316\u8ba1\u7b97\u673a\u8f85\u52a9\u5f62\u6210\u6027\u8bc4\u4f30\u3002", "method": "25\u540d15-17\u5c81\u5b66\u751f\u5728\u5728\u7ebf\u73af\u5883\u4e2d\u5b8c\u6210\u7ebf\u6027\u4e0e\u6307\u6570\u5916\u63a8\u4efb\u52a1\uff0c\u6536\u96c6\u5c4f\u5e55\u8bb0\u5f55\u548c\u8bbf\u8c08\u6570\u636e\u3002", "result": "\u5b66\u751f\u80fd\u81ea\u6211\u5f15\u5bfc\u4e14\u4e0d\u4f1a\u56e0\u969c\u788d\u800c\u8131\u79bb\u5b66\u4e60\uff0c\u540c\u65f6\u504f\u597d\u5e73\u8861\u7684\u53cd\u9988\u3002", "conclusion": "\u5e73\u8861\u53cd\u9988\u7b56\u7565\u4fc3\u8fdb\u4e86\u6709\u6548\u7684\u5b66\u751f-\u73af\u5883\u4e92\u52a8\u3002"}}
{"id": "2507.15663", "pdf": "https://arxiv.org/pdf/2507.15663", "abs": "https://arxiv.org/abs/2507.15663", "authors": ["Giordano d'Aloisio", "Tosin Fadahunsi", "Jay Choy", "Rebecca Moussa", "Federica Sarro"], "title": "SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Background: Text-to-image generation models are widely used across numerous\ndomains. Among these models, Stable Diffusion (SD) - an open-source\ntext-to-image generation model - has become the most popular, producing over 12\nbillion images annually. However, the widespread use of these models raises\nconcerns regarding their social and environmental sustainability.\n  Aims: To reduce the harm that SD models may have on society and the\nenvironment, we introduce SustainDiffusion, a search-based approach designed to\nenhance the social and environmental sustainability of SD models.\n  Method: SustainDiffusion searches the optimal combination of hyperparameters\nand prompt structures that can reduce gender and ethnic bias in generated\nimages while also lowering the energy consumption required for image\ngeneration. Importantly, SustainDiffusion maintains image quality comparable to\nthat of the original SD model.\n  Results: We conduct a comprehensive empirical evaluation of SustainDiffusion,\ntesting it against six different baselines using 56 different prompts. Our\nresults demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%,\nethnic bias by 59%, and energy consumption (calculated as the sum of CPU and\nGPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are\nconsistent across multiple runs and can be generalised to various prompts.\n  Conclusions: With SustainDiffusion, we demonstrate how enhancing the social\nand environmental sustainability of text-to-image generation models is possible\nwithout fine-tuning or changing the model's architecture.", "AI": {"tldr": "SustainDiffusion\u901a\u8fc7\u4f18\u5316\u8d85\u53c2\u6570\u548c\u63d0\u793a\u7ed3\u6784\uff0c\u663e\u8457\u51cf\u5c11Stable Diffusion\u6a21\u578b\u4e2d\u7684\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\u53ca\u80fd\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3Stable Diffusion\u6a21\u578b\u5728\u793e\u4f1a\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u65b9\u9762\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u4f18\u5316\u8d85\u53c2\u6570\u548c\u63d0\u793a\u7ed3\u6784\u4ee5\u51cf\u5c11\u504f\u89c1\u548c\u80fd\u8017\u3002", "result": "\u6027\u522b\u504f\u89c1\u51cf\u5c1168%\uff0c\u79cd\u65cf\u504f\u89c1\u51cf\u5c1159%\uff0c\u80fd\u8017\u964d\u4f4e48%\u3002", "conclusion": "\u65e0\u9700\u8c03\u6574\u6a21\u578b\u67b6\u6784\u5373\u53ef\u63d0\u5347\u6a21\u578b\u7684\u793e\u4f1a\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2507.15692", "pdf": "https://arxiv.org/pdf/2507.15692", "abs": "https://arxiv.org/abs/2507.15692", "authors": ["Meng Chen", "Akhil Iyer", "Amy Pavel"], "title": "Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions", "categories": ["cs.HC"], "comment": "18 pages, 6 figures", "summary": "Multimodal large language models (MLLMs) provide new opportunities for blind\nand low vision (BLV) people to access visual information in their daily lives.\nHowever, these models often produce errors that are difficult to detect without\nsight, posing safety and social risks in scenarios from medication\nidentification to outfit selection. While BLV MLLM users use creative\nworkarounds such as cross-checking between tools and consulting sighted\nindividuals, these approaches are often time-consuming and impractical. We\nexplore how systematically surfacing variations across multiple MLLM responses\ncan support BLV users to detect unreliable information without visually\ninspecting the image. We contribute a design space for eliciting and presenting\nvariations in MLLM descriptions, a prototype system implementing three\nvariation presentation styles, and findings from a user study with 15 BLV\nparticipants. Our results demonstrate that presenting variations significantly\nincreases users' ability to identify unreliable claims (by 4.9x using our\napproach compared to single descriptions) and significantly decreases perceived\nreliability of MLLM responses. 14 of 15 participants preferred seeing\nvariations of MLLM responses over a single description, and all expressed\ninterest in using our system for tasks from understanding a tornado's path to\nposting an image on social media.", "AI": {"tldr": "MLLMs\u5e2e\u52a9\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u4eba\u7fa4\u83b7\u53d6\u89c6\u89c9\u4fe1\u606f\uff0c\u4f46\u5b58\u5728\u96be\u4ee5\u68c0\u6d4b\u7684\u9519\u8bef\u3002\u7814\u7a76\u63d0\u51fa\u901a\u8fc7\u5c55\u793a\u591a\u6a21\u578b\u54cd\u5e94\u53d8\u5316\u6765\u63d0\u9ad8\u4fe1\u606f\u53ef\u9760\u6027\u8bc6\u522b\u3002", "motivation": "\u89e3\u51b3MLLMs\u5728\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7fa4\u4f53\u4e2d\u4f7f\u7528\u65f6\u7684\u9519\u8bef\u68c0\u6d4b\u95ee\u9898\uff0c\u51cf\u5c11\u5b89\u5168\u548c\u793e\u4ea4\u98ce\u9669\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u5305\u542b\u591a\u4e2aMLLM\u54cd\u5e94\u53d8\u5316\u7684\u7a7a\u95f4\uff0c\u5f00\u53d1\u539f\u578b\u7cfb\u7edf\u5e76\u6d4b\u8bd5\u4e09\u79cd\u53d8\u5316\u5c55\u793a\u65b9\u5f0f\u3002", "result": "\u5c55\u793a\u53d8\u5316\u4f7f\u4e0d\u53ef\u9760\u4fe1\u606f\u8bc6\u522b\u80fd\u529b\u63d0\u9ad84.9\u500d\uff0c15\u540d\u53c2\u4e0e\u8005\u4e2d14\u4eba\u66f4\u503e\u5411\u4e8e\u591a\u54cd\u5e94\u5c55\u793a\u3002", "conclusion": "\u7cfb\u7edf\u5c55\u793aMLLM\u54cd\u5e94\u53d8\u5316\u80fd\u663e\u8457\u63d0\u5347\u4fe1\u606f\u53ef\u9760\u6027\u8bc4\u4f30\uff0c\u53d7\u5230\u7528\u6237\u5e7f\u6cdb\u8ba4\u53ef\u3002"}}
{"id": "2507.15666", "pdf": "https://arxiv.org/pdf/2507.15666", "abs": "https://arxiv.org/abs/2507.15666", "authors": ["Igor Turkin", "Lina Volobuieva", "Andriy Chukhray", "Oleksandr Liubimov"], "title": "Modeling CubeSat Storage Battery Discharge: Equivalent Circuit Versus Machine Learning Approaches", "categories": ["cs.SE"], "comment": "13 pages, 15 figures", "summary": "The subject of the article is the study and comparison of two approaches to\nmodelling the battery discharge of a CubeSat satellite: analytical using\nequivalent circuit and machine learning. The article aims to make a reasoned\nchoice of the approach to modelling the battery discharge of a CubeSat\nsatellite. Modelling the battery discharge of a satellite will enable the\nprediction of the consequences of disconnecting the autonomous power system and\nensure the fault tolerance of equipment in orbit. Therefore, the selected study\nis relevant and promising. This study focuses on the analysis of CubeSat\nsatellite data, based explicitly on orbital data samples of the power system,\nwhich include data available at the time of the article publication. The\ndataset contains data on the voltage, current, and temperature of the battery\nand solar panels attached to the five sides of the satellite. In this context,\ntwo approaches are considered: analytical modelling based on physical laws and\nmachine learning, which uses empirical data to create a predictive model.\nResults: A comparative analysis of the modeling results reveals that the\nequivalent circuit approach has the advantage of transparency, as it identifies\npossible parameters that facilitate understanding of the relationships.\nHowever, the model is less flexible to environmental changes or non-standard\nsatellite behavior. The machine learning model demonstrated more accurate\nresults, as it can account for complex dependencies and adapt to actual\nconditions, even when they deviate from theoretical assumptions.", "AI": {"tldr": "\u6bd4\u8f83\u4e86CubeSat\u536b\u661f\u7535\u6c60\u653e\u7535\u7684\u7b49\u6548\u7535\u8def\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u5efa\u6a21\u4e24\u79cd\u65b9\u6cd5\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e3aCubeSat\u536b\u661f\u7535\u6c60\u653e\u7535\u5efa\u6a21\u9009\u62e9\u5408\u9002\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6545\u969c\u9884\u6d4b\u548c\u8bbe\u5907\u5bb9\u9519\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u8f68\u9053\u6570\u636e\u6837\u672c\uff0c\u5206\u6790\u7535\u538b\u3001\u7535\u6d41\u548c\u6e29\u5ea6\u6570\u636e\uff0c\u6bd4\u8f83\u7b49\u6548\u7535\u8def\u548c\u673a\u5668\u5b66\u4e60\u4e24\u79cd\u5efa\u6a21\u65b9\u6cd5\u3002", "result": "\u7b49\u6548\u7535\u8def\u900f\u660e\u4f46\u7075\u6d3b\u6027\u4e0d\u8db3\uff1b\u673a\u5668\u5b66\u4e60\u80fd\u9002\u5e94\u590d\u6742\u4f9d\u8d56\uff0c\u9884\u6d4b\u66f4\u51c6\u786e\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u66f4\u9002\u5408\u590d\u6742\u73af\u5883\u4e0b\u7684CubeSat\u7535\u6c60\u653e\u7535\u5efa\u6a21\u3002"}}
{"id": "2507.15783", "pdf": "https://arxiv.org/pdf/2507.15783", "abs": "https://arxiv.org/abs/2507.15783", "authors": ["Mohammad 'Matt' Namvarpour", "Brandon Brofsky", "Jessica Medina", "Mamtaj Akter", "Afsaneh Razi"], "title": "Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "As Generative Artificial Intelligence (GenAI) driven chatbots like\nCharacter.AI become embedded in adolescent life, they raise concerns about\nemotional dependence and digital overreliance. While studies have investigated\nthe overreliance of adults on these chatbots, they have not investigated teens'\ninteractions with chatbots with customizable personas. We analyzed 318 Reddit\nposts made by users self-reported as 13-17 years old on the Character.AI\nsubreddit to understand patterns of overreliance. We found teens commonly begin\nusing chatbots for emotional support or creative expression, but many develop\nstrong attachments that interfere with offline relationships and daily\nroutines. Their posts revealed recurring signs of psychological distress,\ncycles of relapse, and difficulty disengaging. Teens reported that their\noverreliance often ended when they reflect on the harm, return to in-person\nsocial settings, or become frustrated by platform restrictions. Based on the\nimplications of our findings, we provide recommendations for future chatbot\ndesign so they can promote self-awareness, support real-world engagement, and\ninvolve teens in developing safer digital tools.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u9752\u5c11\u5e74\u5bf9\u53ef\u5b9a\u5236AI\u804a\u5929\u673a\u5668\u4eba\uff08\u5982Character.AI\uff09\u7684\u60c5\u611f\u4f9d\u8d56\u95ee\u9898\uff0c\u53d1\u73b0\u4f7f\u7528\u540e\u53ef\u80fd\u51fa\u73b0\u5fc3\u7406\u56f0\u6270\u548c\u73b0\u5b9e\u5173\u7cfb\u5e72\u6270\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u5173\u6ce8\u9752\u5c11\u5e74\u5bf9GenAI\u9a71\u52a8\u7684\u804a\u5929\u673a\u5668\u4eba\uff08\u5982Character.AI\uff09\u7684\u8fc7\u5ea6\u4f9d\u8d56\u53ca\u5176\u5bf9\u60c5\u611f\u548c\u793e\u4ea4\u751f\u6d3b\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790318\u540d13-17\u5c81\u9752\u5c11\u5e74\u5728Character.AI\u5b50\u8bba\u575b\u4e0a\u7684Reddit\u5e16\u5b50\uff0c\u4ee5\u4e86\u89e3\u8fc7\u5ea6\u4f9d\u8d56\u7684\u6a21\u5f0f\u3002", "result": "\u9752\u5c11\u5e74\u521d\u59cb\u4f7f\u7528\u804a\u5929\u673a\u5668\u4eba\u662f\u4e3a\u4e86\u60c5\u611f\u652f\u6301\u6216\u521b\u610f\u8868\u8fbe\uff0c\u4f46\u8bb8\u591a\u4eba\u53d1\u5c55\u51fa\u5f3a\u70c8\u4f9d\u604b\uff0c\u5f71\u54cd\u73b0\u5b9e\u5173\u7cfb\u548c\u65e5\u5e38\u6d3b\u52a8\uff0c\u5e76\u8868\u73b0\u51fa\u5fc3\u7406\u56f0\u6270\u548c\u96be\u4ee5\u6446\u8131\u7684\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u5efa\u8bae\u6539\u8fdb\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u4ee5\u63d0\u5347\u81ea\u6211\u610f\u8bc6\u3001\u652f\u6301\u73b0\u5b9e\u4e92\u52a8\uff0c\u5e76\u8ba9\u9752\u5c11\u5e74\u53c2\u4e0e\u5f00\u53d1\u66f4\u5b89\u5168\u7684\u6570\u5b57\u5de5\u5177\u3002"}}
{"id": "2507.15671", "pdf": "https://arxiv.org/pdf/2507.15671", "abs": "https://arxiv.org/abs/2507.15671", "authors": ["Jinyao Guo", "Chengpeng Wang", "Dominic Deluca", "Jinjie Liu", "Zhuo Zhang", "Xiangyu Zhang"], "title": "BugScope: Learn to Find Bugs Like Human", "categories": ["cs.SE"], "comment": "19 pages, 2 figure, 6 tables, 4 listings", "summary": "Detecting software bugs remains a fundamental challenge due to the extensive\ndiversity of real-world defects. Traditional static analysis tools often rely\non symbolic workflows, which restrict their coverage and hinder adaptability to\ncustomized bugs with diverse anti-patterns. While recent advances incorporate\nlarge language models (LLMs) to enhance bug detection, these methods continue\nto struggle with sophisticated bugs and typically operate within limited\nanalysis contexts. To address these challenges, we propose BugScope, an\nLLM-driven multi-agent system that emulates how human auditors learn new bug\npatterns from representative examples and apply that knowledge during code\nauditing. Given a set of examples illustrating both buggy and non-buggy\nbehaviors, BugScope synthesizes a retrieval strategy to extract relevant\ndetection contexts via program slicing and then constructs a tailored detection\nprompt to guide accurate reasoning by the LLM. Our evaluation on a curated\ndataset of 40 real-world bugs drawn from 21 widely-used open-source projects\ndemonstrates that BugScope achieves 87.04% precision and 90.00% recall,\nsurpassing state-of-the-art industrial tools by 0.44 in F1 score. Further\ntesting on large-scale open-source systems, including the Linux kernel,\nuncovered 141 previously unknown bugs, of which 78 have been fixed and 7\nconfirmed by developers, highlighting BugScope's substantial practical impact.", "AI": {"tldr": "BugScope\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ece\u793a\u4f8b\u4e2d\u5b66\u4e60\u5e76\u6a21\u62df\u4eba\u7c7b\u5ba1\u8ba1\u884c\u4e3a\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u7f3a\u9677\u68c0\u6d4b\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u96be\u4ee5\u9002\u5e94\u590d\u6742\u548c\u5b9a\u5236\u5316\u7684\u7f3a\u9677\u6a21\u5f0f\uff0c\u800c\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ea7\u7f3a\u9677\u65f6\u4f9d\u7136\u5b58\u5728\u4e0d\u8db3\u3002", "method": "BugScope\u5229\u7528LLM\u4ece\u793a\u4f8b\u4e2d\u5b66\u4e60\u7f3a\u9677\u6a21\u5f0f\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5207\u7247\u63d0\u53d6\u76f8\u5173\u68c0\u6d4b\u4e0a\u4e0b\u6587\uff0c\u5e76\u6784\u5efa\u5b9a\u5236\u5316\u7684\u63d0\u793a\u5f15\u5bfcLLM\u8fdb\u884c\u51c6\u786e\u63a8\u7406\u3002", "result": "\u572840\u4e2a\u771f\u5b9e\u7f3a\u9677\u7684\u6570\u636e\u96c6\u4e0a\uff0cBugScope\u8fbe\u523087.04%\u7684\u7cbe\u5ea6\u548c90.00%\u7684\u53ec\u56de\u7387\uff0cF1\u5206\u6570\u8d85\u8fc7\u5de5\u4e1a\u6807\u51c6\u5de5\u51770.44\uff1b\u5728Linux\u5185\u6838\u7b49\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u8fd8\u53d1\u73b0\u4e86141\u4e2a\u672a\u77e5\u7f3a\u9677\u3002", "conclusion": "BugScope\u5728\u7f3a\u9677\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u5b9e\u7528\u6027\u548c\u9ad8\u6548\u6027\uff0c\u80fd\u591f\u53d1\u73b0\u5e76\u4fee\u590d\u590d\u6742\u7f3a\u9677\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.08006", "pdf": "https://arxiv.org/pdf/2507.08006", "abs": "https://arxiv.org/abs/2507.08006", "authors": ["Aashish Panta", "Amy Gooch", "Giorgio Scorzelli", "Michela Taufer", "Valerio Pascucci"], "title": "Scalable Climate Data Analysis: Balancing Petascale Fidelity and Computational Cost", "categories": ["physics.ao-ph", "cs.HC"], "comment": "Presented at The CCGRID International Scalable Computing Challenge\n  (SCALE), 2025", "summary": "The growing resolution and volume of climate data from remote sensing and\nsimulations pose significant storage, processing, and computational challenges.\nTraditional compression or subsampling methods often compromise data fidelity,\nlimiting scientific insights. We introduce a scalable ecosystem that integrates\nhierarchical multiresolution data management, intelligent transmission, and\nML-assisted reconstruction to balance accuracy and efficiency. Our approach\nreduces storage and computational costs by 99\\%, lowering expenses from\n\\$100,000 to \\$24 while maintaining a Root Mean Square (RMS) error of 1.46\ndegrees Celsius. Our experimental results confirm that even with significant\ndata reduction, essential features required for accurate climate analysis are\npreserved. Validated on petascale NASA climate datasets, this solution enables\ncost-effective, high-fidelity climate analysis for research and\ndecision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u751f\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u5206\u8fa8\u7387\u6570\u636e\u7ba1\u7406\u3001\u667a\u80fd\u4f20\u8f93\u548c\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u91cd\u5efa\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u3001\u5927\u5bb9\u91cf\u7684\u6c14\u5019\u6570\u636e\u65f6\uff0c\u5f80\u5f80\u56e0\u538b\u7f29\u6216\u964d\u91c7\u6837\u800c\u727a\u7272\u6570\u636e\u4fdd\u771f\u5ea6\uff0c\u9650\u5236\u4e86\u79d1\u5b66\u7814\u7a76\u7684\u6df1\u5ea6\u3002", "method": "\u7ed3\u5408\u5206\u5c42\u591a\u5206\u8fa8\u7387\u6570\u636e\u7ba1\u7406\u3001\u667a\u80fd\u4f20\u8f93\u548c\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u91cd\u5efa\u7684\u6280\u672f\uff0c\u5b9e\u73b0\u5bf9\u6c14\u5019\u6570\u636e\u7684\u9ad8\u6548\u5904\u7406\u3002", "result": "\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e99%\uff08\u4ece10\u4e07\u7f8e\u5143\u964d\u81f324\u7f8e\u5143\uff09\uff0c\u540c\u65f6\u4fdd\u6301RMS\u8bef\u5dee\u4e3a1.46\u2103\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728NASA\u6d77\u91cf\u6c14\u5019\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u65e2\u80fd\u964d\u4f4e\u6210\u672c\uff0c\u53c8\u80fd\u4fdd\u6301\u6570\u636e\u7684\u9ad8\u4fdd\u771f\u5ea6\uff0c\u9002\u7528\u4e8e\u7814\u7a76\u548c\u51b3\u7b56\u3002"}}
{"id": "2507.15822", "pdf": "https://arxiv.org/pdf/2507.15822", "abs": "https://arxiv.org/abs/2507.15822", "authors": ["Li Huang", "Ilgiz Mustafin", "Marco Piccioni", "Alessandro Schena", "Reto Weber", "Bertrand Meyer"], "title": "Do AI models help produce verified bug fixes?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Among areas of software engineering where AI techniques -- particularly,\nLarge Language Models -- seem poised to yield dramatic improvements, an\nattractive candidate is Automatic Program Repair (APR), the production of\nsatisfactory corrections to software bugs. Does this expectation materialize in\npractice? How do we find out, making sure that proposed corrections actually\nwork? If programmers have access to LLMs, how do they actually use them to\ncomplement their own skills?\n  To answer these questions, we took advantage of the availability of a\nprogram-proving environment, which formally determines the correctness of\nproposed fixes, to conduct a study of program debugging with two randomly\nassigned groups of programmers, one with access to LLMs and the other without,\nboth validating their answers through the proof tools. The methodology relied\non a division into general research questions (Goals in the Goal-Query-Metric\napproach), specific elements admitting specific answers (Queries), and\nmeasurements supporting these answers (Metrics). While applied so far to a\nlimited sample size, the results are a first step towards delineating a proper\nrole for AI and LLMs in providing guaranteed-correct fixes to program bugs.\n  These results caused surprise as compared to what one might expect from the\nuse of AI for debugging and APR. The contributions also include: a detailed\nmethodology for experiments in the use of LLMs for debugging, which other\nprojects can reuse; a fine-grain analysis of programmer behavior, made possible\nby the use of full-session recording; a definition of patterns of use of LLMs,\nwith 7 distinct categories; and validated advice for getting the best of LLMs\nfor debugging and Automatic Program Repair.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u4e2d\u7684\u5b9e\u9645\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u5176\u5bf9\u7a0b\u5e8f\u5458\u8c03\u8bd5\u7684\u5e2e\u52a9\u3002", "motivation": "\u63a2\u7d22AI\u6280\u672f\uff08\u5c24\u5176\u662fLLM\uff09\u5982\u4f55\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5b9e\u73b0\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff0c\u5e76\u9a8c\u8bc1\u5176\u5b9e\u9645\u6548\u679c\u4e0e\u7a0b\u5e8f\u5458\u7684\u4f7f\u7528\u65b9\u5f0f\u3002", "method": "\u91c7\u7528\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5c06\u7a0b\u5e8f\u5458\u5206\u4e3a\u4e24\u7ec4\uff08\u4e00\u7ec4\u4f7f\u7528LLM\uff0c\u53e6\u4e00\u7ec4\u4e0d\u4f7f\u7528\uff09\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u8bc4\u4f30\u4fee\u590d\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u51fa\u4e4e\u610f\u6599\uff0c\u63ed\u793a\u4e86LLM\u5728\u8c03\u8bd5\u4e2d\u7684\u5b9e\u9645\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u4e867\u79cdLLM\u4f7f\u7528\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u548cLLM\u5728\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u5408\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u521d\u6b65\u7ed3\u8bba\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u4f7f\u7528LLM\u7684\u5efa\u8bae\u3002"}}
{"id": "2507.14173", "pdf": "https://arxiv.org/pdf/2507.14173", "abs": "https://arxiv.org/abs/2507.14173", "authors": ["Karim Alghoul", "Hussein Al Osman", "Abdulmotaleb El Saddik"], "title": "Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model", "categories": ["eess.SP", "cs.HC", "cs.LG"], "comment": "Accepted by IEEE International Instrumentation and Measurement\n  Technology Conference (I2MTC) 2025", "summary": "Human computer interaction has become integral to modern life, driven by\nadvancements in machine learning technologies. Affective computing, in\nparticular, has focused on systems that recognize, interpret, and respond to\nhuman emotions, often using wearable devices, which provide continuous data\nstreams of physiological signals. Among various physiological signals, the\nphotoplethysmogram (PPG) has gained prominence due to its ease of acquisition\nfrom widely available devices. However, the generalization of PPG-based emotion\nrecognition models across individuals remains an unresolved challenge. This\npaper introduces a novel hybrid architecture that combines Convolutional Neural\nNetworks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal\nConvolutional Networks (TCNs) to address this issue. The proposed model\nintegrates the strengths of these architectures to improve robustness and\ngeneralization. Raw PPG signals are fed into the CNN for feature extraction.\nThese features are processed separately by LSTM and TCN. The outputs from these\ncomponents are concatenated to generate a final feature representation, which\nserves as the input for classifying valence and arousal, the primary dimensions\nof emotion. Experiments using the Photoplethysmogram Dataset for Emotional\nAnalysis (PPGE) demonstrate that the proposed hybrid model achieves better\nmodel generalization than standalone CNN and LSTM architectures. Our results\nshow that the proposed solution outperforms the state-of-the-art CNN\narchitecture, as well as a CNN-LSTM model, in emotion recognition tasks with\nPPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we\nhighlight the model's effectiveness in handling subject variability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408CNN\u3001LSTM\u548cTCN\u7684\u6df7\u5408\u67b6\u6784\uff0c\u7528\u4e8e\u63d0\u9ad8\u57fa\u4e8ePPG\u4fe1\u53f7\u7684\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728PPG\u4fe1\u53f7\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8ePPG\u4fe1\u53f7\u7684\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u5728\u4e2a\u4f53\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u67b6\u6784\uff0c\u7ed3\u5408\u4e86CNN\u3001LSTM\u548cTCN\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u5904\u7406\u63d0\u53d6\u7279\u5f81\u5e76\u5206\u7c7b\u60c5\u7eea\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6df7\u5408\u6a21\u578b\u5728PPGE\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528CNN\u6216LSTM\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u5728AUC\u548cF1 Score\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u6df7\u5408\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u57fa\u4e8ePPG\u4fe1\u53f7\u7684\u60c5\u611f\u8bc6\u522b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15828", "pdf": "https://arxiv.org/pdf/2507.15828", "abs": "https://arxiv.org/abs/2507.15828", "authors": ["Mauro Marcelino", "Marcos Alves", "Bianca Trinkenreich", "Bruno Cartaxo", "S\u00e9rgio Soares", "Simone D. J. Barbosa", "Marcos Kalinowski"], "title": "Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering", "categories": ["cs.SE"], "comment": "ESEM 2025 Registered Report with an IPA (In Principle Acceptance) for\n  the Empirical Software Engineering journal", "summary": "[Context] An evidence briefing is a concise and objective transfer medium\nthat can present the main findings of a study to software engineers in the\nindustry. Although practitioners and researchers have deemed Evidence Briefings\nuseful, their production requires manual labor, which may be a significant\nchallenge to their broad adoption. [Goal] The goal of this registered report is\nto describe an experimental protocol for evaluating LLM-generated evidence\nbriefings for secondary studies in terms of content fidelity, ease of\nunderstanding, and usefulness, as perceived by researchers and practitioners,\ncompared to human-made briefings. [Method] We developed an RAG-based LLM tool\nto generate evidence briefings. We used the tool to automatically generate two\nevidence briefings that had been manually generated in previous research\nefforts. We designed a controlled experiment to evaluate how the LLM-generated\nbriefings compare to the human-made ones regarding perceived content fidelity,\nease of understanding, and usefulness. [Results] To be reported after the\nexperimental trials. [Conclusion] Depending on the experiment results.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u57fa\u4e8eRAG\u7684LLM\u5de5\u5177\u81ea\u52a8\u751f\u6210\u8bc1\u636e\u7b80\u62a5\u7684\u53ef\u884c\u6027\uff0c\u65e8\u5728\u6bd4\u8f83\u5176\u4e0e\u4eba\u5de5\u7b80\u62a5\u5728\u5185\u5bb9\u4fdd\u771f\u5ea6\u3001\u6613\u7406\u89e3\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u8bc1\u636e\u7b80\u62a5\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u6709\u4ef7\u503c\uff0c\u4f46\u4eba\u5de5\u5236\u4f5c\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u7814\u7a76\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eRAG\u7684LLM\u5de5\u5177\u751f\u6210\u7b80\u62a5\uff0c\u8bbe\u8ba1\u5b9e\u9a8c\u4e0e\u4eba\u5de5\u7b80\u62a5\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5f85\u516c\u5e03\u3002", "conclusion": "\u7ed3\u8bba\u5c06\u4f9d\u636e\u5b9e\u9a8c\u7ed3\u679c\u800c\u5b9a\u3002"}}
{"id": "2507.14217", "pdf": "https://arxiv.org/pdf/2507.14217", "abs": "https://arxiv.org/abs/2507.14217", "authors": ["Tudor Matei Opran", "Samir Loudni"], "title": "Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "We address the pattern explosion problem in pattern mining by proposing an\ninteractive learning framework that combines nonlinear utility aggregation with\ngeometry-aware query selection. Our method models user preferences through a\nChoquet integral over multiple interestingness measures and exploits the\ngeometric structure of the version space to guide the selection of informative\ncomparisons. A branch-and-bound strategy with tight distance bounds enables\nefficient identification of queries near the decision boundary. Experiments on\nUCI datasets show that our approach outperforms existing methods such as\nChoquetRank, achieving better ranking accuracy with fewer user interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u4e92\u5f0f\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u975e\u7ebf\u6027\u6548\u7528\u805a\u5408\u548c\u51e0\u4f55\u611f\u77e5\u67e5\u8be2\u9009\u62e9\uff0c\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\uff0c\u901a\u8fc7\u4ea4\u4e92\u5b66\u4e60\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528Choquet\u79ef\u5206\u5efa\u6a21\u7528\u6237\u504f\u597d\uff0c\u7ed3\u5408\u51e0\u4f55\u611f\u77e5\u67e5\u8be2\u9009\u62e9\u548c\u5206\u652f\u5b9a\u754c\u7b56\u7565\u3002", "result": "\u5728UCI\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5982ChoquetRank\uff09\uff0c\u6392\u540d\u51c6\u786e\u6027\u66f4\u9ad8\u4e14\u7528\u6237\u4ea4\u4e92\u66f4\u5c11\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u5f0f\u6316\u6398\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.15831", "pdf": "https://arxiv.org/pdf/2507.15831", "abs": "https://arxiv.org/abs/2507.15831", "authors": ["Sergey Titov", "Konstantin Grotov", "Cristina Sarasua", "Yaroslav Golubev", "Dhivyabharathi Ramasamy", "Alberto Bacchelli", "Abraham Bernstein", "Timofey Bryksin"], "title": "Observing Fine-Grained Changes in Jupyter Notebooks During Development Time", "categories": ["cs.SE"], "comment": "32 pages, 6 figures", "summary": "In software engineering, numerous studies have focused on the analysis of\nfine-grained logs, leading to significant innovations in areas such as\nrefactoring, security, and code completion. However, no similar studies have\nbeen conducted for computational notebooks in the context of data science.\n  To help bridge this research gap, we make three scientific contributions: we\n(1) introduce a toolset for collecting code changes in Jupyter notebooks during\ndevelopment time; (2) use it to collect more than 100 hours of work related to\na data analysis task and a machine learning task (carried out by 20 developers\nwith different levels of expertise), resulting in a dataset containing 2,655\ncells and 9,207 cell executions; and (3) use this dataset to investigate the\ndynamic nature of the notebook development process and the changes that take\nplace in the notebooks.\n  In our analysis of the collected data, we classified the changes made to the\ncells between executions and found that a significant number of these changes\nwere relatively small fixes and code iteration modifications. This suggests\nthat notebooks are used not only as a development and exploration tool but also\nas a debugging tool. We report a number of other insights and propose potential\nfuture research directions on the novel data.", "AI": {"tldr": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u6570\u636e\u79d1\u5b66\u4e2d\u8ba1\u7b97\u7b14\u8bb0\u672c\u52a8\u6001\u5f00\u53d1\u8fc7\u7a0b\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u901a\u8fc7\u5de5\u5177\u96c6\u6536\u96c6Jupyter\u7b14\u8bb0\u672c\u7684\u4ee3\u7801\u53d8\u66f4\u6570\u636e\uff0c\u5e76\u5206\u6790\u4e86\u5f00\u53d1\u884c\u4e3a\u6a21\u5f0f\u3002", "motivation": "\u6570\u636e\u79d1\u5b66\u9886\u57df\u7f3a\u4e4f\u5bf9\u8ba1\u7b97\u7b14\u8bb0\u672c\u5f00\u53d1\u8fc7\u7a0b\u7684\u7814\u7a76\uff0c\u800c\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5bf9\u7ec6\u7c92\u5ea6\u65e5\u5fd7\u7684\u5206\u6790\u5df2\u53d6\u5f97\u663e\u8457\u6210\u679c\u3002", "method": "\u5f00\u53d1\u5de5\u5177\u96c6\u6536\u96c620\u540d\u5f00\u53d1\u8005\u5728\u6570\u636e\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u4ee3\u7801\u53d8\u66f4\uff0c\u5f62\u6210\u542b2655\u4e2a\u5355\u5143\u683c\u548c9207\u6b21\u6267\u884c\u7684\u6570\u636e\u5e93\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u7b14\u8bb0\u672c\u5e38\u7528\u4e8e\u5c0f\u89c4\u6a21\u4fee\u590d\u548c\u4ee3\u7801\u8fed\u4ee3\uff0c\u4e0d\u4ec5\u662f\u5f00\u53d1\u548c\u63a2\u7d22\u5de5\u5177\uff0c\u4e5f\u7528\u4e8e\u8c03\u8bd5\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u7b14\u8bb0\u672c\u7684\u591a\u529f\u80fd\u7528\u9014\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.14242", "pdf": "https://arxiv.org/pdf/2507.14242", "abs": "https://arxiv.org/abs/2507.14242", "authors": ["Prerana Khatiwada", "Grace Donaher", "Jasymyn Navarro", "Lokesh Bhatta"], "title": "Culling Misinformation from Gen AI: Toward Ethical Curation and Refinement", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "7 pages", "summary": "While Artificial Intelligence (AI) is not a new field, recent developments,\nespecially with the release of generative tools like ChatGPT, have brought it\nto the forefront of the minds of industry workers and academic folk alike.\nThere is currently much talk about AI and its ability to reshape many everyday\nprocesses as we know them through automation. It also allows users to expand\ntheir ideas by suggesting things they may not have thought of on their own and\nprovides easier access to information. However, not all of the changes this\ntechnology will bring or has brought so far are positive; this is why it is\nextremely important for all modern people to recognize and understand the risks\nbefore using these tools and allowing them to cause harm. This work takes a\nposition on better understanding many equity concerns and the spread of\nmisinformation that result from new AI, in this case, specifically ChatGPT and\ndeepfakes, and encouraging collaboration with law enforcement, developers, and\nusers to reduce harm. Considering many academic sources, it warns against these\nissues, analyzing their cause and impact in fields including healthcare,\neducation, science, academia, retail, and finance. Lastly, we propose a set of\nfuture-facing guidelines and policy considerations to solve these issues while\nstill enabling innovation in these fields, this responsibility falling upon\nusers, developers, and government entities.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\uff08\u5c24\u5176\u662fChatGPT\u548cdeepfake\uff09\u5e26\u6765\u7684\u516c\u5e73\u95ee\u9898\u548c\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u8de8\u9886\u57df\u5408\u4f5c\u4e0e\u653f\u7b56\u5efa\u8bae\u4ee5\u51cf\u5c11\u5371\u5bb3\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\uff08\u5982ChatGPT\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5176\u6f5c\u5728\u5371\u5bb3\uff08\u5982\u516c\u5e73\u95ee\u9898\u3001\u9519\u8bef\u4fe1\u606f\uff09\u4e9f\u5f85\u5173\u6ce8\uff0c\u9700\u591a\u65b9\u5408\u4f5c\u89e3\u51b3\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5b66\u672f\u8d44\u6599\uff0c\u7814\u7a76AI\u5728\u533b\u7597\u3001\u6559\u80b2\u3001\u79d1\u5b66\u7b49\u9886\u57df\u7684\u8d1f\u9762\u5f71\u54cd\u53ca\u5176\u6210\u56e0\u3002", "result": "\u63d0\u51fa\u4e86\u672a\u6765\u9762\u5411\u7684\u6307\u5bfc\u65b9\u9488\u548c\u653f\u7b56\u5efa\u8bae\uff0c\u4ee5\u5e73\u8861\u521b\u65b0\u4e0e\u98ce\u9669\u7ba1\u63a7\u3002", "conclusion": "\u547c\u5401\u7528\u6237\u3001\u5f00\u53d1\u8005\u548c\u653f\u5e9c\u5171\u540c\u52aa\u529b\uff0c\u786e\u4fddAI\u6280\u672f\u7684\u5065\u5eb7\u53d1\u5c55\u3002"}}
{"id": "2507.14347", "pdf": "https://arxiv.org/pdf/2507.14347", "abs": "https://arxiv.org/abs/2507.14347", "authors": ["Ole Hans", "Benedikt Walter"], "title": "Remote Assistance or Remote Driving: The Impact of Operational Design Domains on ADS-Supporting Systems Selection", "categories": ["eess.SY", "cs.SE", "cs.SY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "High level Automated Driving Systems (ADS) can handle many situations, but\nthey still encounter situations where human intervention is required. In\nsystems where a physical driver is present in the vehicle, typically SAE Level\n3 systems, this intervention is relatively straightforward and is handled by\nthe in-vehicle driver. However, the complexity increases for Level 4 systems,\nwhere, in most cases, no physical driver remains in the vehicle. The two common\nindustry solutions for this challenge are the integration of a remote support\nsystem, such as a Remote Driving System (RDS) or Remote Assistance System\n(RAS). While it is clear that ADS will require one of these systems, it is less\nclear how the suitability of either system for a particular ADS application\nshould be evaluated. Currently, the selection process often focuses on system\narchitecture as well as its design and integration challenges. Furthermore,\nsince many ADS developers choose to develop remote system solutions in-house,\nit is advantageous to select the simpler approach to streamline development and\nintegration efforts. While these decision points are certainly relevant, this\napproach overlooks the most critical factors: the use cases and the\ncomplementarity of the ADS and the remote support system within the context of\nthe Operational Design Design Domain (ODD). This paper proposes a structured\napproach for selecting between RDS and RAS as an ADS support system, based on\nthe defined ODD and use case analysis. To achieve this, the paper applies the\nPEGASUS framework to systematically describe and analyze the ODD. A structured\nframework is introduced to evaluate and select the most suitable remote support\nsystem for an ADS based on clearly defined criteria.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eODD\u548c\u7528\u4f8b\u5206\u6790\u7684RDS\u6216RAS\u9009\u62e9\u6846\u67b6\u3002", "motivation": "\u5f53\u524dADS\u5728L4\u7ea7\u522b\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u7269\u7406\u9a7e\u9a76\u5458\uff0c\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\uff08RDS\u6216RAS\uff09\u7684\u9009\u62e9\u6807\u51c6\u4e0d\u6e05\u6670\uff0c\u901a\u5e38\u5ffd\u7565\u5173\u952e\u56e0\u7d20\uff08\u5982ODD\u548c\u7528\u4f8b\u5206\u6790\uff09\u3002", "method": "\u5e94\u7528PEGASUS\u6846\u67b6\u5206\u6790ODD\uff0c\u5e76\u5f15\u5165\u7ed3\u6784\u5316\u6846\u67b6\u6765\u8bc4\u4f30\u548c\u9009\u62e9\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u6839\u636eODD\u548c\u7528\u4f8b\u9009\u62e9\u9002\u5408\u7684\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u660e\u786e\u7684\u6807\u51c6\u548c\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u53ef\u4ee5\u66f4\u79d1\u5b66\u5730\u9009\u62e9RDS\u6216RAS\uff0c\u4f18\u5316ADS\u7684\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\u8bbe\u8ba1\u3002"}}
{"id": "2507.14339", "pdf": "https://arxiv.org/pdf/2507.14339", "abs": "https://arxiv.org/abs/2507.14339", "authors": ["Abhishek Bhattacharjee", "Jack Pilkington", "Nita Farahany"], "title": "Fiduciary AI for the Future of Brain-Technology Interactions", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG", "eess.SP", "K.4.0; I.2.0; J.4"], "comment": "32 pages", "summary": "Brain foundation models represent a new frontier in AI: instead of processing\ntext or images, these models interpret real-time neural signals from EEG, fMRI,\nand other neurotechnologies. When integrated with brain-computer interfaces\n(BCIs), they may enable transformative applications-from thought controlled\ndevices to neuroprosthetics-by interpreting and acting on brain activity in\nmilliseconds. However, these same systems pose unprecedented risks, including\nthe exploitation of subconscious neural signals and the erosion of cognitive\nliberty. Users cannot easily observe or control how their brain signals are\ninterpreted, creating power asymmetries that are vulnerable to manipulation.\nThis paper proposes embedding fiduciary duties-loyalty, care, and\nconfidentiality-directly into BCI-integrated brain foundation models through\ntechnical design. Drawing on legal traditions and recent advancements in AI\nalignment techniques, we outline implementable architectural and governance\nmechanisms to ensure these systems act in users' best interests. Placing brain\nfoundation models on a fiduciary footing is essential to realizing their\npotential without compromising self-determination.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5c06\u4fe1\u6258\u8d23\u4efb\u5d4c\u5165\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u96c6\u6210\u7684\u8111\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u5e73\u8861\u5176\u6f5c\u5728\u5229\u76ca\u4e0e\u98ce\u9669\u3002", "motivation": "\u8111\u57fa\u7840\u6a21\u578b\u548cBCIs\u6280\u672f\u867d\u5177\u9769\u547d\u6027\u6f5c\u529b\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u524d\u6240\u672a\u6709\u7684\u98ce\u9669\uff0c\u5982\u6f5c\u610f\u8bc6\u795e\u7ecf\u4fe1\u53f7\u7684\u6ee5\u7528\u548c\u8ba4\u77e5\u81ea\u7531\u7684\u4fb5\u8680\uff0c\u9700\u8981\u6280\u672f\u8bbe\u8ba1\u786e\u4fdd\u7528\u6237\u6743\u76ca\u3002", "method": "\u7ed3\u5408\u6cd5\u5f8b\u4f20\u7edf\u548cAI\u5bf9\u9f50\u6280\u672f\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u5b9e\u65bd\u7684\u67b6\u6784\u548c\u6cbb\u7406\u673a\u5236\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u59cb\u7ec8\u4ee5\u7528\u6237\u6700\u4f73\u5229\u76ca\u4e3a\u5bfc\u5411\u3002", "result": "\u901a\u8fc7\u6280\u672f\u8bbe\u8ba1\u5d4c\u5165\u4fe1\u6258\u8d23\u4efb\uff08\u5fe0\u8bda\u3001\u8c28\u614e\u548c\u4fdd\u5bc6\uff09\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u6743\u529b\u4e0d\u5bf9\u79f0\u548c\u64cd\u7eb5\u98ce\u9669\u3002", "conclusion": "\u5c06\u8111\u57fa\u7840\u6a21\u578b\u7f6e\u4e8e\u4fe1\u6258\u57fa\u7840\u4e0a\uff0c\u662f\u5b9e\u73b0\u5176\u6f5c\u529b\u800c\u4e0d\u635f\u5bb3\u7528\u6237\u81ea\u4e3b\u6743\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2507.14642", "pdf": "https://arxiv.org/pdf/2507.14642", "abs": "https://arxiv.org/abs/2507.14642", "authors": ["Monoshiz Mahbub Khan", "Xioayin Xi", "Andrew Meneely", "Zhe Yu"], "title": "Efficient Story Point Estimation With Comparative Learning", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Story point estimation is an essential part of agile software development.\nStory points are unitless, project-specific effort estimates that help\ndevelopers plan their sprints. Traditionally, developers estimate story points\ncollaboratively using planning poker or other manual techniques. While the\ninitial calibrating of the estimates to each project is helpful, once a team\nhas converged on a set of precedents, story point estimation can become tedious\nand labor-intensive. Machine learning can reduce this burden, but only with\nenough context from the historical decisions made by the project team. That is,\nstate-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate\npredictions (within-project) when trained on data from the same project. The\ngoal of this work is to streamline story point estimation by evaluating a\ncomparative learning-based framework for calibrating project-specific story\npoint prediction models. Instead of assigning a specific story point value to\nevery backlog item, developers are presented with pairs of items, and indicate\nwhich item requires more effort. Using these comparative judgments, a machine\nlearning model is trained to predict the story point estimates. We empirically\nevaluated our technique using data with 23,313 manual estimates in 16 projects.\nThe model learned from comparative judgments can achieve on average 0.34\nSpearman's rank correlation coefficient between its predictions and the ground\ntruth story points. This is similar to, if not better than, the performance of\na regression model learned from the ground truth story points. Therefore, the\nproposed comparative learning approach is more efficient than state-of-the-art\nregression-based approaches according to the law of comparative judgments -\nproviding comparative judgments yields a lower cognitive burden on humans than\nproviding ratings or categorical labels.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6bd4\u8f83\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6821\u51c6\u9879\u76ee\u7279\u5b9a\u7684\u6545\u4e8b\u70b9\u4f30\u8ba1\u6a21\u578b\uff0c\u51cf\u8f7b\u5f00\u53d1\u8005\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002", "motivation": "\u4f20\u7edf\u6545\u4e8b\u70b9\u4f30\u8ba1\u65b9\u6cd5\u7e41\u7410\u4e14\u8017\u65f6\uff0c\u673a\u5668\u5b66\u4e60\u53ef\u964d\u4f4e\u5de5\u4f5c\u91cf\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u9700\u4f9d\u8d56\u9879\u76ee\u7279\u5b9a\u6570\u636e\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u8005\u5bf9\u4efb\u52a1\u5bf9\u7684\u6bd4\u8f83\u5224\u65ad\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u800c\u975e\u76f4\u63a5\u5206\u914d\u5177\u4f53\u6545\u4e8b\u70b9\u3002", "result": "\u572816\u4e2a\u9879\u76ee\u300123,313\u6b21\u624b\u52a8\u4f30\u8ba1\u6570\u636e\u4e0a\uff0c\u6a21\u578b\u9884\u6d4b\u4e0e\u771f\u5b9e\u6545\u4e8b\u7684Spearman\u76f8\u5173\u7cfb\u6570\u4e3a0.34\uff0c\u6027\u80fd\u4e0e\u56de\u5f52\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u6bd4\u8f83\u5b66\u4e60\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u8ba4\u77e5\u8d1f\u62c5\u66f4\u4f4e\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u56de\u5f52\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\u3002"}}
{"id": "2507.14451", "pdf": "https://arxiv.org/pdf/2507.14451", "abs": "https://arxiv.org/abs/2507.14451", "authors": ["Satwik Dutta", "Shruthigna Chandupatla", "John Hansen"], "title": "Adapting Whisper for Lightweight and Efficient Automatic Speech Recognition of Children for On-device Edge Applications", "categories": ["eess.AS", "cs.HC", "cs.SD"], "comment": "5 pages, 5 figures, accepted for presentation at the 2025 Workshop on\n  Child Computer Interaction (WOCCI 2025), a Satellite Workshop of the 2025\n  Interspeech Conference", "summary": "Reliability on cloud providers for ASR inference to support child-centered\nvoice-based applications is becoming challenging due to regulatory and privacy\nchallenges. Motivated by a privacy-preserving design, this study aims to\ndevelop a lightweight & efficient Whisper ASR system capable of running on a\nRaspberry Pi. Upon evaluation of the MyST corpus and by examining various\nfiltering strategies to fine-tune the `tiny.en' model, a Word Error Rate (WER)\nof 15.9% was achieved (11.8% filtered). A low-rank compression reduces the\nencoder size by 0.51M with 1.26x faster inference in GPU, with 11% relative WER\nincrease. During inference on Pi, the compressed version required ~2 GFLOPS\nfewer computations. The RTF for both the models ranged between [0.23-0.41] for\nvarious input audio durations. Analyzing the RAM usage and CPU temperature\nshowed that the PI was capable of handling both the tiny models, however it was\nnoticed that small models initiated additional overhead/thermal throttling.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7Whisper ASR\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u6811\u8393\u6d3e\uff0c\u9690\u79c1\u4fdd\u62a4\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4f4e\u79e9\u538b\u7f29\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u6cd5\u89c4\u548c\u9690\u79c1\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u672c\u5730\u8fd0\u884c\u7684\u8f7b\u91cf\u7ea7ASR\u7cfb\u7edf\u4ee5\u652f\u6301\u513f\u7ae5\u8bed\u97f3\u5e94\u7528\u3002", "method": "\u57fa\u4e8eMyST\u8bed\u6599\u5e93\u8bc4\u4f30\uff0c\u91c7\u7528\u8fc7\u6ee4\u7b56\u7565\u5fae\u8c03tiny.en\u6a21\u578b\uff0c\u5e76\u5e94\u7528\u4f4e\u79e9\u538b\u7f29\u4f18\u5316\u6027\u80fd\u3002", "result": "WER\u4e3a15.9%\uff08\u8fc7\u6ee4\u540e11.8%\uff09\uff0c\u538b\u7f29\u540e\u6a21\u578b\u4f53\u79ef\u51cf\u5c0f\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\uff0c\u6811\u8393\u6d3e\u8fd0\u884c\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "\u8f7b\u91cf\u7ea7ASR\u7cfb\u7edf\u5728\u9690\u79c1\u4fdd\u62a4\u573a\u666f\u4e0b\u53ef\u884c\uff0c\u4f46\u5c0f\u6a21\u578b\u53ef\u80fd\u5f15\u53d1\u989d\u5916\u5f00\u9500\u548c\u6563\u70ed\u95ee\u9898\u3002"}}
{"id": "2507.15058", "pdf": "https://arxiv.org/pdf/2507.15058", "abs": "https://arxiv.org/abs/2507.15058", "authors": ["Ian Hardgrove", "John D. Hastings"], "title": "LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries", "categories": ["cs.CR", "cs.LG", "cs.SE", "D.2.5; D.4.6"], "comment": "6 pages, 2 figures, 1 table, 2 listings", "summary": "A fundamental problem in cybersecurity and computer science is determining\nwhether a program is free of bugs and vulnerabilities. Fuzzing, a popular\napproach to discovering vulnerabilities in programs, has several advantages\nover alternative strategies, although it has investment costs in the form of\ninitial setup and continuous maintenance. The choice of fuzzing is further\ncomplicated when only a binary library is available, such as the case of\nclosed-source and proprietary software. In response, we introduce LibLMFuzz, a\nframework that reduces costs associated with fuzzing closed-source libraries by\npairing an agentic Large Language Model (LLM) with a lightweight tool-chain\n(disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan\nfuzz strategies, generate drivers, and iteratively self-repair build or runtime\nerrors. Tested on four widely-used Linux libraries, LibLMFuzz produced\nsyntactically correct drivers for all 558 fuzz-able API functions, achieving\n100% API coverage with no human intervention. Across the 1601 synthesized\ndrivers, 75.52% were nominally correct on first execution. The results show\nthat LLM-augmented middleware holds promise in reducing the costs of fuzzing\nblack box components and provides a foundation for future research efforts.\nFuture opportunities exist for research in branch coverage.", "AI": {"tldr": "LibLMFuzz\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u5de5\u5177\u94fe\uff0c\u964d\u4f4e\u4e86\u6a21\u7cca\u6d4b\u8bd5\u95ed\u6e90\u5e93\u7684\u6210\u672c\uff0c\u5b9e\u73b0\u4e86\u5168\u81ea\u52a8\u5316\u5206\u6790\u548c\u9a71\u52a8\u751f\u6210\u3002", "motivation": "\u89e3\u51b3\u95ed\u6e90\u5e93\u6a21\u7cca\u6d4b\u8bd5\u7684\u9ad8\u6210\u672c\u548c\u590d\u6742\u6027\uff0c\u5c24\u5176\u662f\u5f53\u4ec5\u6709\u4e8c\u8fdb\u5236\u5e93\u53ef\u7528\u65f6\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u8f7b\u91cf\u7ea7\u5de5\u5177\u94fe\uff08\u53cd\u6c47\u7f16\u5668/\u7f16\u8bd1\u5668/\u6a21\u7cca\u5668\uff09\uff0c\u81ea\u52a8\u5206\u6790\u5265\u79bb\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u89c4\u5212\u6a21\u7cca\u7b56\u7565\uff0c\u751f\u6210\u9a71\u52a8\u5e76\u81ea\u6211\u4fee\u590d\u9519\u8bef\u3002", "result": "\u6210\u529f\u4e3a558\u4e2a\u53ef\u6a21\u7cca\u6d4b\u8bd5\u7684API\u51fd\u6570\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u9a71\u52a8\uff0c\u9996\u6b21\u6267\u884c\u65f675.52%\u7684\u9a71\u52a8\u540d\u4e49\u4e0a\u6b63\u786e\u3002", "conclusion": "LLM\u589e\u5f3a\u7684\u4e2d\u95f4\u4ef6\u4e3a\u6a21\u7cca\u6d4b\u8bd5\u9ed1\u76d2\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.14543", "pdf": "https://arxiv.org/pdf/2507.14543", "abs": "https://arxiv.org/abs/2507.14543", "authors": ["Sharanya Mukherjee", "Md Hishaam Akhtar", "Kannadasan R"], "title": "Real Time Captioning of Sign Language Gestures in Video Meetings", "categories": ["cs.CV", "cs.CY", "cs.HC", "cs.LG", "I.4.6"], "comment": "7 pages, 2 figures, 1 table, Presented at ICCMDE 2021", "summary": "It has always been a rather tough task to communicate with someone possessing\na hearing impairment. One of the most tested ways to establish such a\ncommunication is through the use of sign based languages. However, not many\npeople are aware of the smaller intricacies involved with sign language. Sign\nlanguage recognition using computer vision aims at eliminating the\ncommunication barrier between deaf-mute and ordinary people so that they can\nproperly communicate with others. Recently the pandemic has left the whole\nworld shaken up and has transformed the way we communicate. Video meetings have\nbecome essential for everyone, even people with a hearing disability. In recent\nstudies, it has been found that people with hearing disabilities prefer to sign\nover typing during these video calls. In this paper, we are proposing a browser\nextension that will automatically translate sign language to subtitles for\neveryone else in the video call. The Large-scale dataset which contains more\nthan 2000 Word-Level ASL videos, which were performed by over 100 signers will\nbe used.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6d4f\u89c8\u5668\u6269\u5c55\uff0c\u7528\u4e8e\u5728\u89c6\u9891\u901a\u8bdd\u4e2d\u5b9e\u65f6\u5c06\u624b\u8bed\u7ffb\u8bd1\u4e3a\u5b57\u5e55\uff0c\u65e8\u5728\u6d88\u9664\u542c\u529b\u969c\u788d\u8005\u4e0e\u666e\u901a\u4eba\u4e4b\u95f4\u7684\u6c9f\u901a\u969c\u788d\u3002", "motivation": "\u542c\u529b\u969c\u788d\u8005\u4e0e\u666e\u901a\u4eba\u6c9f\u901a\u56f0\u96be\uff0c\u5c24\u5176\u662f\u75ab\u60c5\u671f\u95f4\u89c6\u9891\u4f1a\u8bae\u6210\u4e3a\u4e3b\u6d41\uff0c\u542c\u529b\u969c\u788d\u8005\u66f4\u503e\u5411\u4e8e\u7528\u624b\u8bed\u800c\u975e\u6253\u5b57\u4ea4\u6d41\u3002", "method": "\u5229\u7528\u5305\u542b2000\u591a\u4e2a\u5355\u8bcd\u7ea7ASL\u89c6\u9891\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u6d4f\u89c8\u5668\u6269\u5c55\u5b9e\u73b0\u624b\u8bed\u5230\u5b57\u5e55\u7684\u81ea\u52a8\u7ffb\u8bd1\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u76ee\u6807\u662f\u5b9e\u73b0\u5b9e\u65f6\u7ffb\u8bd1\u529f\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u6d88\u9664\u6c9f\u901a\u969c\u788d\uff0c\u63d0\u5347\u542c\u529b\u969c\u788d\u8005\u5728\u89c6\u9891\u4f1a\u8bae\u4e2d\u7684\u4ea4\u6d41\u4f53\u9a8c\u3002"}}
{"id": "2507.14553", "pdf": "https://arxiv.org/pdf/2507.14553", "abs": "https://arxiv.org/abs/2507.14553", "authors": ["Xiaoran Wu"], "title": "Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance", "categories": ["cs.CV", "cs.HC"], "comment": null, "summary": "Clutter in photos is a distraction preventing photographers from conveying\nthe intended emotions or stories to the audience. Photography amateurs\nfrequently include clutter in their photos due to unconscious negligence or the\nlack of experience in creating a decluttered, aesthetically appealing scene for\nshooting. We are thus motivated to develop a camera guidance system that\nprovides solutions and guidance for clutter identification and removal. We\nestimate and visualize the contribution of objects to the overall aesthetics\nand content of a photo, based on which users can interactively identify\nclutter. Suggestions on getting rid of clutter, as well as a tool that removes\ncluttered objects computationally, are provided to guide users to deal with\ndifferent kinds of clutter and improve their photographic work. Two technical\nnovelties underpin interactions in our system: a clutter distinguishment\nalgorithm with aesthetics evaluations for objects and an iterative image\ninpainting algorithm based on generative adversarial nets that reconstructs\nmissing regions of removed objects for high-resolution images. User studies\ndemonstrate that our system provides flexible interfaces and accurate\nalgorithms that allow users to better identify distractions and take higher\nquality images within less time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u76f8\u673a\u5f15\u5bfc\u7cfb\u7edf\uff0c\u901a\u8fc7\u7f8e\u5b66\u8bc4\u4f30\u548c\u76ee\u6807\u533a\u5206\u7b97\u6cd5\u5e2e\u52a9\u7528\u6237\u8bc6\u522b\u548c\u53bb\u9664\u7167\u7247\u4e2d\u7684\u6742\u7269\uff0c\u63d0\u5347\u7167\u7247\u8d28\u91cf\u548c\u62cd\u6444\u6548\u7387\u3002", "motivation": "\u6444\u5f71\u5e08\u548c\u4e1a\u4f59\u7231\u597d\u8005\u5e38\u56e0\u758f\u5ffd\u6216\u7ecf\u9a8c\u4e0d\u8db3\u5728\u7167\u7247\u4e2d\u7559\u4e0b\u6742\u7269\uff0c\u5f71\u54cd\u7167\u7247\u7684\u7f8e\u89c2\u548c\u60c5\u611f\u8868\u8fbe\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u6765\u8f85\u52a9\u8bc6\u522b\u548c\u53bb\u9664\u6742\u7269\u3002", "method": "\u7cfb\u7edf\u7ed3\u5408\u4e86\u7f8e\u5b66\u8bc4\u4f30\u7b97\u6cd5\u548c\u76ee\u6807\u533a\u5206\u6280\u672f\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u754c\u9762\u8ba9\u7528\u6237\u8bc6\u522b\u6742\u7269\uff0c\u5e76\u63d0\u4f9b\u53bb\u9664\u5efa\u8bae\u53ca\u57fa\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u7684\u56fe\u50cf\u4fee\u590d\u5de5\u5177\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u6709\u6548\u5e2e\u52a9\u7528\u6237\u5feb\u901f\u8bc6\u522b\u6742\u7269\u5e76\u63d0\u5347\u7167\u7247\u8d28\u91cf\uff0c\u51cf\u5c11\u4e86\u62cd\u6444\u65f6\u95f4\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u6444\u5f71\u7231\u597d\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u7b97\u6cd5\u548c\u4ea4\u4e92\u5f0f\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u7167\u7247\u7684\u7f8e\u89c2\u6027\u548c\u62cd\u6444\u6548\u7387\u3002"}}
{"id": "2507.14623", "pdf": "https://arxiv.org/pdf/2507.14623", "abs": "https://arxiv.org/abs/2507.14623", "authors": ["Mingchen Li", "Wenbo Xu", "Wenqing Gu", "Yixuan Xie", "Yao Zhou", "Yunsong Dai", "Cheng Tan", "Pan Hui"], "title": "Rejection or Inclusion in the Emotion-Identity Dynamics of TikTok Refugees on RedNote", "categories": ["cs.SI", "cs.CY", "cs.HC"], "comment": null, "summary": "This study examines cross-cultural interactions between Chinese users and\nself-identified \"TikTok Refugees\"(foreign users who migrated to RedNote after\nTikTok's U.S. ban). Based on a dataset of 1,862 posts and 403,054 comments, we\nuse large language model-based sentiment classification and BERT-based topic\nmodelling to explore how both groups engage with the TikTok refugee phenomenon.\nWe analyse what themes foreign users express, how Chinese users respond, how\nstances (Pro-China, Neutral, Pro-Foreign) shape emotional expression, and how\naffective responses differ across topics and identities. Results show strong\naffective asymmetry: Chinese users respond with varying emotional intensities\nacross topics and stances: pride and praise dominate cultural threads, while\npolitical discussions elicit high levels of contempt and anger, especially from\nPro-China commenters. Pro-Foreign users exhibit the strongest negative emotions\nacross all topics, whereas neutral users express curiosity and joy but still\nreinforce mainstream discursive norms. Cross-topic comparisons reveal that\nappearance-related content produces the most emotionally balanced interactions,\nwhile politics generates the highest polarization. Our findings reveal distinct\nemotion-stance structures in Sino-foreign online interactions and offer\nempirical insights into identity negotiation in transnational digital publics.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u4e2d\u56fd\u7528\u6237\u4e0e\u2018TikTok\u96be\u6c11\u2019\uff08\u56e0TikTok\u5728\u7f8e\u7981\u4ee4\u800c\u8fc1\u79fb\u81f3RedNote\u7684\u5916\u56fd\u7528\u6237\uff09\u4e4b\u95f4\u7684\u8de8\u6587\u5316\u4e92\u52a8\uff0c\u7ed3\u5408\u60c5\u611f\u5206\u7c7b\u548c\u4e3b\u9898\u5efa\u6a21\uff0c\u63ed\u793a\u4e86\u60c5\u611f\u8868\u8fbe\u4e0e\u7acb\u573a\u3001\u8bdd\u9898\u95f4\u7684\u5173\u8054\u3002", "motivation": "\u63a2\u7a76\u5728\u5168\u7403\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\uff0c\u4e2d\u56fd\u7528\u6237\u4e0e\u5916\u56fd\u7528\u6237\u5982\u4f55\u4e92\u52a8\uff0c\u7279\u522b\u662f\u5728TikTok\u7981\u4ee4\u80cc\u666f\u4e0b\uff0c\u53cc\u65b9\u7684\u60c5\u611f\u8868\u8fbe\u4e0e\u7acb\u573a\u5982\u4f55\u5f71\u54cd\u4ea4\u6d41\u3002", "method": "\u57fa\u4e8e1,862\u7bc7\u5e16\u5b50\u548c403,054\u6761\u8bc4\u8bba\u6570\u636e\uff0c\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u60c5\u611f\u5206\u7c7b\u548cBERT\u4e3b\u9898\u5efa\u6a21\u5206\u6790\u60c5\u611f\u4e0e\u8bdd\u9898\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u60c5\u611f\u4e0d\u5bf9\u79f0\u6027\uff1a\u4e2d\u56fd\u7528\u6237\u5728\u4e0d\u540c\u8bdd\u9898\u548c\u7acb\u573a\u4e0b\u60c5\u611f\u5dee\u5f02\u663e\u8457\uff0c\u5916\u56fd\u7528\u6237\u666e\u904d\u8d1f\u9762\u60c5\u7eea\u66f4\u5f3a\uff1b\u653f\u6cbb\u5185\u5bb9\u6781\u5316\u6700\u4e25\u91cd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4e2d\u5916\u5728\u7ebf\u4e92\u52a8\u4e2d\u7684\u60c5\u611f-\u7acb\u573a\u7ed3\u6784\uff0c\u4e3a\u8de8\u56fd\u6570\u5b57\u516c\u5171\u7a7a\u95f4\u4e2d\u7684\u8eab\u4efd\u534f\u5546\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2507.14698", "pdf": "https://arxiv.org/pdf/2507.14698", "abs": "https://arxiv.org/abs/2507.14698", "authors": ["Xuetao Lin", "Tianhao Peng", "Peihong Dai", "Yu Liang", "Wenjun Wu"], "title": "Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition", "categories": ["cs.LG", "cs.AI", "cs.HC", "eess.SP"], "comment": null, "summary": "EEG-based emotion recognition plays an important role in developing adaptive\nbrain-computer communication systems, yet faces two fundamental challenges in\npractical implementations: (1) effective integration of non-stationary\nspatial-temporal neural patterns, (2) robust adaptation to dynamic emotional\nintensity variations in real-world scenarios. This paper proposes SST-CL, a\nnovel framework integrating spatial-temporal transformers with curriculum\nlearning. Our method introduces two core components: a spatial encoder that\nmodels inter-channel relationships and a temporal encoder that captures\nmulti-scale dependencies through windowed attention mechanisms, enabling\nsimultaneous extraction of spatial correlations and temporal dynamics from EEG\nsignals. Complementing this architecture, an intensity-aware curriculum\nlearning strategy progressively guides training from high-intensity to\nlow-intensity emotional states through dynamic sample scheduling based on a\ndual difficulty assessment. Comprehensive experiments on three benchmark\ndatasets demonstrate state-of-the-art performance across various emotional\nintensity levels, with ablation studies confirming the necessity of both\narchitectural components and the curriculum learning mechanism.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSST-CL\u6846\u67b6\uff0c\u7ed3\u5408\u7a7a\u95f4-\u65f6\u95f4\u53d8\u6362\u5668\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86EEG\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u975e\u5e73\u7a33\u65f6\u7a7a\u6a21\u5f0f\u6574\u5408\u548c\u52a8\u6001\u60c5\u611f\u5f3a\u5ea6\u9002\u5e94\u95ee\u9898\u3002", "motivation": "EEG\u60c5\u611f\u8bc6\u522b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u975e\u5e73\u7a33\u65f6\u7a7a\u795e\u7ecf\u6a21\u5f0f\u6574\u5408\u548c\u52a8\u6001\u60c5\u611f\u5f3a\u5ea6\u53d8\u5316\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u91c7\u7528\u7a7a\u95f4\u7f16\u7801\u5668\u5efa\u6a21\u901a\u9053\u95f4\u5173\u7cfb\u548c\u65f6\u95f4\u7f16\u7801\u5668\u901a\u8fc7\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\u6355\u83b7\u591a\u5c3a\u5ea6\u4f9d\u8d56\uff0c\u7ed3\u5408\u5f3a\u5ea6\u611f\u77e5\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u52a8\u6001\u8c03\u5ea6\u8bad\u7ec3\u6837\u672c\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u5404\u90e8\u5206\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "SST-CL\u6846\u67b6\u901a\u8fc7\u6574\u5408\u65f6\u7a7a\u53d8\u6362\u5668\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86EEG\u60c5\u611f\u8bc6\u522b\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.14909", "pdf": "https://arxiv.org/pdf/2507.14909", "abs": "https://arxiv.org/abs/2507.14909", "authors": ["Elio Grande"], "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "The Endless Tuning is a design method for a reliable deployment of artificial\nintelligence based on a double mirroring process, which pursues both the goals\nof avoiding human replacement and filling the so-called responsibility gap\n(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the\nrelational approach urged therein, it was then actualized in a protocol,\nimplemented in three prototypical applications regarding decision-making\nprocesses (respectively: loan granting, pneumonia diagnosis, and art style\nrecognition) and tested with such as many domain experts. Step by step\nillustrating the protocol, giving insights concretely showing a different voice\n(Gilligan 1993) in the ethics of artificial intelligence, a philosophical\naccount of technical choices (e.g., a reversed and hermeneutic deployment of\nXAI algorithms) will be provided in the present study together with the results\nof the experiments, focusing on user experience rather than statistical\naccuracy. Even thoroughly employing deep learning models, full control was\nperceived by the interviewees in the decision-making setting, while it appeared\nthat a bridge can be built between accountability and liability in case of\ndamage.", "AI": {"tldr": "\u300aEndless Tuning\u300b\u662f\u4e00\u79cd\u57fa\u4e8e\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\u7684AI\u53ef\u9760\u90e8\u7f72\u65b9\u6cd5\uff0c\u65e8\u5728\u907f\u514d\u4eba\u7c7b\u88ab\u66ff\u4ee3\u5e76\u586b\u8865\u8d23\u4efb\u7f3a\u53e3\u3002\u901a\u8fc7\u4e09\u4e2a\u539f\u578b\u5e94\u7528\u6d4b\u8bd5\uff0c\u7814\u7a76\u53d1\u73b0\u7528\u6237\u611f\u77e5\u5230\u7684\u63a7\u5236\u529b\u63d0\u5347\uff0c\u5e76\u53ef\u5728\u8d23\u4efb\u4e0e\u6cd5\u5f8b\u8d23\u4efb\u4e4b\u95f4\u5efa\u7acb\u6865\u6881\u3002", "motivation": "\u4e3a\u4e86\u907f\u514dAI\u6280\u672f\u9020\u6210\u4eba\u7c7b\u88ab\u66ff\u4ee3\u7684\u98ce\u9669\uff0c\u5e76\u89e3\u51b3AI\u51b3\u7b56\u4e2d\u7684\u8d23\u4efb\u7f3a\u53e3\u95ee\u9898\uff08Matthias 2004\uff09\u3002", "method": "\u91c7\u7528\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5f00\u53d1\u534f\u8bae\u5e76\u5728\u8d37\u6b3e\u5ba1\u6279\u3001\u80ba\u708e\u8bca\u65ad\u548c\u827a\u672f\u98ce\u683c\u8bc6\u522b\u4e09\u4e2a\u5e94\u7528\u4e2d\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7ed3\u5408\u4e13\u5bb6\u53cd\u9988\u548c\u7528\u6237\u7ecf\u9a8c\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5c3d\u7ba1\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u6237\u5728\u51b3\u7b56\u73af\u5883\u4e2d\u4ecd\u611f\u77e5\u5230\u5b8c\u5168\u63a7\u5236\uff0c\u540c\u65f6\u8d23\u4efb\u4e0e\u6cd5\u5f8b\u8d23\u4efb\u4e4b\u95f4\u53ef\u4ee5\u5efa\u7acb\u8054\u7cfb\u3002", "conclusion": "\u300aEndless Tuning\u300b\u65b9\u6cd5\u5728\u63d0\u5347\u7528\u6237\u63a7\u5236\u611f\u548c\u89e3\u51b3\u8d23\u4efb\u95ee\u9898\u4e0a\u662f\u6709\u6548\u7684\uff0c\u4e3aAI\u4f26\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.15729", "pdf": "https://arxiv.org/pdf/2507.15729", "abs": "https://arxiv.org/abs/2507.15729", "authors": ["Jens V. R\u00fcppel", "Andrey Rudenko", "Tim Schreiter", "Martin Magnusson", "Achim J. Lilienthal"], "title": "Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction", "categories": ["cs.RO", "cs.HC"], "comment": "This paper has been accepted to the 34th IEEE International\n  Conference on Robot and Human Interactive Communication (RO-MAN), which will\n  be held in Eindhoven, Netherlands on August 25-29, 2025. Copyright 2025 IEEE.\n  Personal use of this material is permitted. Permission from IEEE must be\n  obtained for all other uses", "summary": "The rapid development of Large Language Models (LLMs) creates an exciting\npotential for flexible, general knowledge-driven Human-Robot Interaction (HRI)\nsystems for assistive robots. Existing HRI systems demonstrate great progress\nin interpreting and following user instructions, action generation, and robot\ntask solving. On the other hand, bi-directional, multi-modal, and context-aware\nsupport of the user in collaborative tasks still remains an open challenge. In\nthis paper, we present a gaze- and speech-informed interface to the assistive\nrobot, which is able to perceive the working environment from multiple vision\ninputs and support the dynamic user in their tasks. Our system is designed to\nbe modular and transferable to adapt to diverse tasks and robots, and it is\ncapable of real-time use of language-based interaction state representation and\nfast on board perception modules. Its development was supported by multiple\npublic dissemination events, contributing important considerations for improved\nrobustness and user experience. Furthermore, in two lab studies, we compare the\nperformance and user ratings of our system with those of a traditional scripted\nHRI pipeline. Our findings indicate that an LLM-based approach enhances\nadaptability and marginally improves user engagement and task execution metrics\nbut may produce redundant output, while a scripted pipeline is well suited for\nmore straightforward tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u89c6\u7ebf\u548c\u8bed\u97f3\u4ea4\u4e92\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u7528\u4e8e\u8f85\u52a9\u534f\u4f5c\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u5176\u4e0e\u4f20\u7edf\u811a\u672c\u5316HRI\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709HRI\u7cfb\u7edf\u5728\u7528\u6237\u6307\u4ee4\u89e3\u6790\u3001\u52a8\u4f5c\u751f\u6210\u548c\u4efb\u52a1\u89e3\u51b3\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u53cc\u5411\u3001\u591a\u6a21\u6001\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u534f\u4f5c\u4efb\u52a1\u652f\u6301\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u3001\u53ef\u8f6c\u79fb\u7684\u63a5\u53e3\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u89c6\u89c9\u8f93\u5165\u611f\u77e5\u73af\u5883\uff0c\u5e76\u7ed3\u5408\u5b9e\u65f6\u8bed\u8a00\u4ea4\u4e92\u72b6\u6001\u8868\u793a\u548c\u5feb\u901f\u611f\u77e5\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u5728\u9002\u5e94\u6027\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u4e0a\u7565\u6709\u63d0\u5347\uff0c\u4f46\u53ef\u80fd\u4ea7\u751f\u5197\u4f59\u8f93\u51fa\uff1b\u800c\u4f20\u7edf\u811a\u672c\u5316\u7cfb\u7edf\u66f4\u9002\u5408\u7b80\u5355\u4efb\u52a1\u3002", "conclusion": "LLM\u65b9\u6cd5\u5728\u590d\u6742\u534f\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u9700\u4f18\u5316\u4ee5\u51cf\u5c11\u5197\u4f59\uff1b\u4f20\u7edf\u65b9\u6cd5\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2507.15743", "pdf": "https://arxiv.org/pdf/2507.15743", "abs": "https://arxiv.org/abs/2507.15743", "authors": ["Elahe Vedadi", "David Barrett", "Natalie Harris", "Ellery Wulczyn", "Shashir Reddy", "Roma Ruparel", "Mike Schaekermann", "Tim Strother", "Ryutaro Tanno", "Yash Sharma", "Jihyeon Lee", "C\u00edan Hughes", "Dylan Slack", "Anil Palepu", "Jan Freyberg", "Khaled Saab", "Valentin Li\u00e9vin", "Wei-Hung Weng", "Tao Tu", "Yun Liu", "Nenad Tomasev", "Kavita Kulkarni", "S. Sara Mahdavi", "Kelvin Guu", "Jo\u00eblle Barral", "Dale R. Webster", "James Manyika", "Avinatan Hassidim", "Katherine Chou", "Yossi Matias", "Pushmeet Kohli", "Adam Rodman", "Vivek Natarajan", "Alan Karthikesalingam", "David Stutz"], "title": "Towards physician-centered oversight of conversational diagnostic AI", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f02\u6b65\u76d1\u7763\u7684AI\u533b\u7597\u8bca\u65ad\u7cfb\u7edfg-AMIE\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u5b89\u5168\u8303\u56f4\u5185\u8fdb\u884c\u75c5\u53f2\u91c7\u96c6\uff0c\u5e76\u7531\u4e3b\u8bca\u533b\u751f\u76d1\u7763\u51b3\u7b56\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u6a21\u5f0f\u3002", "motivation": "\u76ee\u524dAI\u5728\u533b\u7597\u8bca\u65ad\u5bf9\u8bdd\u4e2d\u5c55\u73b0\u4e86\u6f5c\u529b\uff0c\u4f46\u60a3\u8005\u5b89\u5168\u9700\u8981\u4e13\u4e1a\u76d1\u7763\u3002\u53d7\u533b\u751f\u56e2\u961f\u534f\u4f5c\u542f\u53d1\uff0c\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u5f02\u6b65\u76d1\u7763\u6846\u67b6\u3002", "method": "\u63d0\u51fag-AMIE\u7cfb\u7edf\uff0c\u5728\u9650\u5b9a\u8303\u56f4\u5185\u91c7\u96c6\u75c5\u53f2\u5e76\u907f\u514d\u76f4\u63a5\u8bca\u65ad\uff0c\u901a\u8fc7\u4e34\u5e8a\u754c\u9762\u5c06\u8bc4\u4f30\u4f20\u9012\u7ed9\u76d1\u7763\u533b\u751f\uff0c\u5b9e\u73b0\u5f02\u6b65\u76d1\u7763\u3002", "result": "\u5728\u865a\u62df\u8bd5\u9a8c\u4e2d\uff0cg-AMIE\u5728\u75c5\u53f2\u91c7\u96c6\u3001\u75c5\u4f8b\u603b\u7ed3\u548c\u8bca\u65ad\u5efa\u8bae\u65b9\u9762\u4f18\u4e8e\u62a4\u58eb\u548c\u533b\u751f\u52a9\u624b\u7ec4\uff0c\u4e14\u76d1\u7763\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u5f02\u6b65\u76d1\u7763\u6846\u67b6\u4e3aAI\u8bca\u65ad\u7cfb\u7edf\u5728\u771f\u5b9e\u533b\u7597\u73af\u5883\u4e2d\u8fd0\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u6a21\u5f0f\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e34\u5e8a\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.15846", "pdf": "https://arxiv.org/pdf/2507.15846", "abs": "https://arxiv.org/abs/2507.15846", "authors": ["Fei Tang", "Zhangxuan Gu", "Zhengxi Lu", "Xuyang Liu", "Shuheng Shen", "Changhua Meng", "Wen Wang", "Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": null, "summary": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGUI-G\u00b2\u7684\u5956\u52b1\u6846\u67b6\uff0c\u901a\u8fc7\u5c06GUI\u5143\u7d20\u5efa\u6a21\u4e3a\u8fde\u7eed\u9ad8\u65af\u5206\u5e03\uff0c\u6539\u8fdb\u4e86GUI\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u7a00\u758f\u5956\u52b1\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u7a00\u758f\u7684\u4e8c\u8fdb\u5236\u5956\u52b1\uff0c\u5ffd\u7565\u4e86\u7a7a\u95f4\u4ea4\u4e92\u7684\u8fde\u7eed\u6027\u3002\u53d7\u4eba\u7c7b\u70b9\u51fb\u884c\u4e3a\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u8fde\u7eed\u7684\u9ad8\u65af\u5206\u5e03\u6a21\u578b\u6765\u66f4\u597d\u5730\u6a21\u62dfGUI\u5b9a\u4f4d\u3002", "method": "GUI-G\u00b2\u7ed3\u5408\u4e86\u9ad8\u65af\u70b9\u5956\u52b1\u548c\u8986\u76d6\u5956\u52b1\uff0c\u524d\u8005\u901a\u8fc7\u6307\u6570\u8870\u51cf\u5206\u5e03\u5efa\u6a21\u7cbe\u786e\u5b9a\u4f4d\uff0c\u540e\u8005\u8bc4\u4f30\u9884\u6d4b\u5206\u5e03\u4e0e\u76ee\u6807\u533a\u57df\u7684\u91cd\u53e0\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u65b9\u5dee\u673a\u5236\u4ee5\u9002\u5e94\u4e0d\u540c\u5c3a\u5bf8\u7684\u5143\u7d20\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGUI-G\u00b2\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982ScreenSpot-Pro\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6700\u9ad8\u63d0\u5347\u8fbe24.7%\uff0c\u5e76\u663e\u793a\u51fa\u5bf9\u754c\u9762\u53d8\u5316\u548c\u672a\u89c1\u5e03\u5c40\u7684\u66f4\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u8fde\u7eed\u4f18\u5316\u548c\u7a7a\u95f4\u5efa\u6a21\uff0cGUI-G\u00b2\u4e3aGUI\u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u7a7a\u95f4\u63a8\u7406\u8bbe\u5b9a\u4e86\u65b0\u8303\u5f0f\uff0c\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u68af\u5ea6\u4fe1\u53f7\u548c\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
