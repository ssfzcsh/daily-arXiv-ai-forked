<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 6]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.HC](#cs.HC) [Total: 17]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.CR](#cs.CR) [Total: 2]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [quant-ph](#quant-ph) [Total: 3]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [eess.AS](#eess.AS) [Total: 1]
- [math.FA](#math.FA) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]
- [eess.IV](#eess.IV) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [FormalGrad: Integrating Formal Methods with Gradient-Based LLM Refinement](https://arxiv.org/abs/2508.10059)
*Yueke Zhang,Yifan Zhang,Kevin Leach,Yu Huang*

Main category: cs.SE

TL;DR: FormalGrad通过将形式化方法集成到LLM代码生成循环中，改进代码的正确性、鲁棒性和效率，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码通常缺乏正确性、鲁棒性和效率的保证，尤其是在需要严格约束的领域。

Method: FormalGrad将代码视为可微分变量，通过形式化反馈生成的文本伪梯度指导模型迭代优化解决方案。

Result: 在HumanEval和LiveCodeBench基准测试中，性能提升高达27%和41%，生成的代码更具鲁棒性和形式化保证。

Conclusion: FormalGrad为高风险的AI辅助软件开发提供了可靠的解决方案。

Abstract: While Large Language Models (LLMs) have demonstrated remarkable capabilities
in code generation, they often produce solutions that lack guarantees of
correctness, robustness, and efficiency. The limitation is acute in domains
requiring strict constraints. FormalGrad introduces a principled framework that
integrates formal methods directly into an iterative LLM-based generation loop.
It uniquely treats code as a differentiable variable, converting structured
feedback and formal constraints into a textual pseudo-gradient. This gradient
guides the model to iteratively refine solutions, ensuring they are not only
functional but also robust and formally justified. We evaluate FormalGrad on
the HumanEval, HumanEval+, and LiveCodeBench benchmarks. Our implementation
outperforms strong baselines, achieving an absolute improvement of up to 27% on
HumanEval and a 41% relative improvement on the challenging LiveCodeBench V6.
FormalGrad generates formally justified code that is robust and efficient,
paving the way for reliable AI-assisted software development in high-stakes
applications.

</details>


### [2] [SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion](https://arxiv.org/abs/2508.10068)
*Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen*

Main category: cs.SE

TL;DR: Saracoder是一个基于层次特征优化的检索框架，通过深度语义关系和结构相似性提升代码补全的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本相似性的检索增强生成方法在代码补全中易受语义误导、冗余和同质性问题影响，且无法解决外部符号模糊性。

Method: 提出Hierarchical Feature Optimization模块（深度语义蒸馏、重复项剪枝、图结构相似性评估）和External-Aware Identifier Disambiguator模块（依赖分析解决符号模糊性）。

Result: Saracoder在CrossCodeEval和RepoEval-Updated基准测试中显著优于现有基线。

Conclusion: 多维度系统优化检索结果为更准确、鲁棒的代码补全系统提供了新范式。

Abstract: Retrieval-augmented generation (RAG) for repository-level code completion
commonly relies on superficial text similarity, leading to results plagued by
semantic misguidance, redundancy, and homogeneity, while also failing to
resolve external symbol ambiguity. To address these challenges, we introduce
Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core
Hierarchical Feature Optimization module systematically refines candidates by
distilling deep semantic relationships, pruning exact duplicates, assessing
structural similarity with a novel graph-based metric that weighs edits by
their topological importance, and reranking results to maximize both relevance
and diversity. Furthermore, an External-Aware Identifier Disambiguator module
accurately resolves cross-file symbol ambiguity via dependency analysis.
Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated
benchmarks demonstrate that Saracoder significantly outperforms existing
baselines across multiple programming languages and models. Our work proves
that systematically refining retrieval results across multiple dimensions
provides a new paradigm for building more accurate and robust repository-level
code completion systems.

</details>


### [3] [Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History](https://arxiv.org/abs/2508.10074)
*Ruofan Lu,Yintong Huo,Meng Zhang,Yichen Li,Michael R. Lyu*

Main category: cs.SE

TL;DR: 论文提出了“Next Edit Prediction”任务，通过分析开发者最近的交互历史预测下一次编辑的位置和内容，旨在弥补现有代码辅助工具的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的代码辅助工具（如代码补全和聊天式编辑）存在局限性，无法主动预测开发者的连续编辑意图，导致用户体验不佳。

Method: 作者收集了高质量的有监督微调数据集和评估基准，并对一系列模型进行了微调与全面评估。

Result: 研究展示了微调模型与基线模型的对比结果，揭示了新任务的有效性和模型性能。

Conclusion: 该工作为一种新型交互范式奠定了基础，可主动预测开发者行动，而非仅响应显式指令。

Abstract: The rapid advancement of large language models (LLMs) has led to the
widespread adoption of AI-powered coding assistants integrated into a
development environment. On one hand, low-latency code completion offers
completion suggestions but is fundamentally constrained to the cursor's current
position. On the other hand, chat-based editing can perform complex
modifications, yet forces developers to stop their work, describe the intent in
natural language, which causes a context-switch away from the code. This
creates a suboptimal user experience, as neither paradigm proactively predicts
the developer's next edit in a sequence of related edits. To bridge this gap
and provide the seamless code edit suggestion, we introduce the task of Next
Edit Prediction, a novel task designed to infer developer intent from recent
interaction history to predict both the location and content of the subsequent
edit. Specifically, we curate a high-quality supervised fine-tuning dataset and
an evaluation benchmark for the Next Edit Prediction task. Then, we conduct
supervised fine-tuning on a series of models and performed a comprehensive
evaluation of both the fine-tuned models and other baseline models, yielding
several novel findings. This work lays the foundation for a new interaction
paradigm that proactively collaborate with developers by anticipating their
following action, rather than merely reacting to explicit instructions.

</details>


### [4] [On the synchronization between Hugging Face pre-trained language models and their upstream GitHub repository](https://arxiv.org/abs/2508.10157)
*Ajibode Adekunle,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 分析了预训练语言模型（PTLMs）在GitHub（GH）和Hugging Face（HF）平台间的开发协调问题，揭示了八种同步模式及其对模型发布实践的影响。


<details>
  <summary>Details</summary>
Motivation: 研究GH和HF平台在PTLM开发中的协调挑战，如版本不一致和发布时间错位，以提高模型发布的透明度和一致性。

Method: 对325个PTLM家族（904个HF变体）进行混合方法研究，分析提交活动的协调性和同步模式。

Result: 发现GH和HF贡献者的提交内容差异显著，并识别出八种同步模式，其中部分同步模式揭示了跨平台发布的脱节问题。

Conclusion: 识别同步模式对改进PTLM发布流程的监督和可追溯性至关重要，避免用户接触不完整或过时的模型。

Abstract: Pretrained language models (PTLMs) have advanced natural language processing
(NLP), enabling progress in tasks like text generation and translation. Like
software package management, PTLMs are trained using code and environment
scripts in upstream repositories (e.g., GitHub, GH) and distributed as variants
via downstream platforms like Hugging Face (HF). Coordinating development
between GH and HF poses challenges such as misaligned release timelines,
inconsistent versioning, and limited reuse of PTLM variants. We conducted a
mixed-method study of 325 PTLM families (904 HF variants) to examine how commit
activities are coordinated. Our analysis reveals that GH contributors typically
make changes related to specifying the version of the model, improving code
quality, performance optimization, and dependency management within the
training scripts, while HF contributors make changes related to improving model
descriptions, data set handling, and setup required for model inference.
Furthermore, to understand the synchronization aspects of commit activities
between GH and HF, we examined three dimensions of these activities -- lag
(delay), type of synchronization, and intensity -- which together yielded eight
distinct synchronization patterns. The prevalence of partially synchronized
patterns, such as Disperse synchronization and Sparse synchronization, reveals
structural disconnects in current cross-platform release practices. These
patterns often result in isolated changes -- where improvements or fixes made
on one platform are never replicated on the other -- and in some cases,
indicate an abandonment of one repository in favor of the other. Such
fragmentation risks exposing end users to incomplete, outdated, or behaviorally
inconsistent models. Hence, recognizing these synchronization patterns is
critical for improving oversight and traceability in PTLM release workflows.

</details>


### [5] [Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution](https://arxiv.org/abs/2508.10517)
*Likai Ye,Mengliang Li,Dehai Zhao,Jiamou Sun,Xiaoxue Ren*

Main category: cs.SE

TL;DR: 分析指出Solidity版本更新带来的编译错误问题，评估了LLMs在修复错误中的表现，并提出SMCFIXER框架，结合专家知识检索和LLM修复机制，显著提升了修复准确率。


<details>
  <summary>Details</summary>
Motivation: Solidity频繁更新导致编译错误和维护困难，亟需有效解决方案。

Method: 通过评估LLMs的修复能力，提出SMCFIXER框架，结合代码切片、专家知识检索和迭代补丁生成。

Result: SMCFIXER在真实数据集上比GPT-4o基线提升了24.24%，准确率达96.97%。

Conclusion: SMCFIXER为Solidity版本迁移中的编译错误提供了高效解决方案，展现了领域特定适配的重要性。

Abstract: Solidity, the dominant smart contract language for Ethereum, has rapidly
evolved with frequent version updates to enhance security, functionality, and
developer experience. However, these continual changes introduce significant
challenges, particularly in compilation errors, code migration, and
maintenance. Therefore, we conduct an empirical study to investigate the
challenges in the Solidity version evolution and reveal that 81.68% of examined
contracts encounter errors when compiled across different versions, with 86.92%
of compilation errors.
  To mitigate these challenges, we conducted a systematic evaluation of large
language models (LLMs) for resolving Solidity compilation errors during version
migrations. Our empirical analysis across both open-source (LLaMA3, DeepSeek)
and closed-source (GPT-4o, GPT-3.5-turbo) LLMs reveals that although these
models exhibit error repair capabilities, their effectiveness diminishes
significantly for semantic-level issues and shows strong dependency on prompt
engineering strategies. This underscores the critical need for domain-specific
adaptation in developing reliable LLM-based repair systems for smart contracts.
  Building upon these insights, we introduce SMCFIXER, a novel framework that
systematically integrates expert knowledge retrieval with LLM-based repair
mechanisms for Solidity compilation error resolution. The architecture
comprises three core phases: (1) context-aware code slicing that extracts
relevant error information; (2) expert knowledge retrieval from official
documentation; and (3) iterative patch generation for Solidity migration.
Experimental validation across Solidity version migrations demonstrates our
approach's statistically significant 24.24% improvement over baseline GPT-4o on
real-world datasets, achieving near-perfect 96.97% accuracy.

</details>


### [6] [EVOSCAT: Exploring Software Change Dynamics in Large-Scale Historical Datasets](https://arxiv.org/abs/2508.10852)
*Souhaila Serbout,Diana Carolina Muñoz Hurtado,Hassan Atwi,Edoardo Riggio,Cesare Pautasso*

Main category: cs.SE

TL;DR: EvoScat是一款通过交互式密度散点图提供大规模历史数据集全局概览的工具，帮助研究者分析和比较软件项目的演化数据。


<details>
  <summary>Details</summary>
Motivation: 研究长期软件项目中的大量历史数据需要高效的可视化工具，以支持对演化模式的分析和比较。

Method: 开发EvoScat工具，利用交互式密度散点图展示大规模历史数据集，支持时间轴缩放、排序和颜色映射配置。

Result: EvoScat能够分析数百万个事件，展示不同项目的演化速度和趋势，适用于多种分析场景（如变化速度比较、克隆检测等）。

Conclusion: EvoScat为研究者提供了一种高效的可视化方法，帮助分析和比较软件项目的长期演化数据。

Abstract: Long lived software projects encompass a large number of artifacts, which
undergo many revisions throughout their history. Empirical software engineering
researchers studying software evolution gather and collect datasets with
millions of events, representing changes introduced to specific artifacts. In
this paper, we propose EvoScat, a tool that attempts addressing temporal
scalability through the usage of interactive density scatterplot to provide a
global overview of large historical datasets mined from open source
repositories in a single visualization. EvoScat intents to provide researchers
with a mean to produce scalable visualizations that can help them explore and
characterize evolution datasets, as well as comparing the histories of
individual artifacts, both in terms of 1) observing how rapidly different
artifacts age over multiple-year-long time spans 2) how often metrics
associated with each artifacts tend towards an improvement or worsening. The
paper shows how the tool can be tailored to specific analysis needs (pace of
change comparison, clone detection, freshness assessment) thanks to its support
for flexible configuration of history scaling and alignment along the time
axis, artifacts sorting and interactive color mapping, enabling the analysis of
millions of events obtained by mining the histories of tens of thousands of
software artifacts. We include in this paper a gallery showcasing datasets
gathering specific artifacts (OpenAPI descriptions, GitHub workflow
definitions) across multiple repositories, as well as diving into the history
of specific popular open source projects.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Generating Compilers for Qubit Mapping and Routing](https://arxiv.org/abs/2508.10781)
*Abtin Molavi,Amanda Xu,Ethan Cecchetti,Swamit Tannu,Aws Albarghouthi*

Main category: cs.PL

TL;DR: 该论文提出了一种自动生成适用于任意量子架构的量子比特映射和路由（QMR）编译器的方法，通过定义一种领域特定语言Marol，简化了各种量子硬件平台的编译器开发。


<details>
  <summary>Details</summary>
Motivation: 量子计算机有望解决经典计算机难以处理的问题，但量子架构的多样性使得编译器的开发复杂化。现有工作针对不同硬件和约束条件提出了多种QMR解决方案，缺乏统一方法。

Method: 论文提出了一种通过定义设备状态机的通用结构来抽象QMR问题的方法，并开发了领域特定语言Marol以简洁描述问题。使用参数化求解器自动生成QMR编译器。

Result: 通过案例研究，证明了生成的编译器在运行时间和解质量上与手动编写的专业编译器相当，适用于噪声和容错量子架构。

Conclusion: 该方法简化了未来量子编译器的开发，适应不断涌现的新型量子架构。

Abstract: Quantum computers promise to solve important problems faster than classical
computers, potentially unlocking breakthroughs in materials science, chemistry,
and beyond. Optimizing compilers are key to realizing this potential, as they
minimize expensive resource usage and limit error rates. A critical compilation
step is qubit mapping and routing (QMR), which finds mappings from circuit
qubits to qubits on a target device and plans instruction execution while
satisfying the device's connectivity constraints. The challenge is that the
landscape of quantum architectures is incredibly diverse and fast-evolving.
Given this diversity, hundreds of papers have addressed the QMR problem for
different qubit hardware, connectivity constraints, and quantum error
correction schemes.
  We present an approach for automatically generating qubit mapping and routing
compilers for arbitrary quantum architectures. Though each QMR problem is
different, we identify a common core structure-device state machine-that we use
to formulate an abstract QMR problem. Our formulation naturally leads to a
domain-specific language, Marol, for specifying QMR problems-for example, the
well-studied NISQ mapping and routing problem requires only 12 lines of Marol.
We demonstrate that QMR problems, defined in Marol, can be solved with a
powerful parametric solver that can be instantiated for any Marol program. We
evaluate our approach through case studies of important QMR problems from prior
and recent work, covering noisy and fault-tolerant quantum architectures on all
major hardware platforms. Our thorough evaluation shows that generated
compilers are competitive with handwritten, specialized compilers in terms of
runtime and solution quality. We envision that our approach will simplify
development of future quantum compilers as new quantum architectures continue
to emerge.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [8] [Meta-Metrics and Best Practices for System-Level Inference Performance Benchmarking](https://arxiv.org/abs/2508.10251)
*Shweta Salaria,Zhuoran Liu,Nelson Mimura Gonzalez*

Main category: cs.PF

TL;DR: FMwork是一种系统化方法，用于高效评估基础模型（如LLM）的推理性能，通过元指标、参数选择和成本性能分析，显著减少实验量并保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型（如LLM）的推理性能通常需要大量实验，但全面测试不切实际。FMwork旨在提供一种高效且准确的评估框架。

Method: FMwork包含元指标（兼顾时间和资源消耗）、参数选择和成本性能分析策略，通过优化实验设计减少不必要的测试配置。

Result: 使用FMwork框架，实验速度提升高达24倍，资源配置更高效；在Llama 3.1 8B模型上，仅测试128个token即可保持96.6%的准确率。

Conclusion: FMwork为大规模模型性能评估提供了一种实用且高效的解决方案，显著降低实验成本并保持结果可靠性。

Abstract: Benchmarking inference performance (speed) of Foundation Models such as Large
Language Models (LLM) involves navigating a vast experimental landscape to
understand the complex interactions between hardware and software components.
However, evaluating every possible test configuration is impractical,
unfeasible and unnecessary. To address this challenge, we introduce FMwork, a
comprehensive and methodical approach to creating a controlled testing
environment that accurately reflects and characterizes performance. FMwork
comprises a set of benchmkaring best practices with three key components: 1)
meta-metrics, 2) parameter selection, and 3) strategic cost-performance
evaluation. Meta-metrics account for time and resources spent on benchmarking
and the relative accuracy of the results compared to a larger body of
measurements, representing the complete experimental space. FMwork
operationalizes the meta-metrics and provides efficient strategies for
parameter selection and cost-performance analysis. Using the framework, we show
up to 24x improvement (speedup and/or resource savings) running sweeps of
experiments compared to the ground truth. Even already considering a subset of
experiments as reference point (using the power of two for batch sizes),
reducing experimental output size from 1024 to 128 tokens yields another 2.7x
gain while keeping 96.6% accuracy for an evaluation using Llama 3.1 8B model.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [9] [Rethinking Reliability Using Network Coding: a Practical 5G Evaluation](https://arxiv.org/abs/2508.10247)
*Laura Landon,Vipindev Adat Vasudevan,Junmo Sung,Muriel Médard*

Main category: cs.NI

TL;DR: 论文提出了一种集成在5G测试IP层中的实时网络编码系统，替代传统的基于重传的可靠性机制，结果显示RLNC在高丢包率下更高效。


<details>
  <summary>Details</summary>
Motivation: 传统的ARQ和HARQ重传机制效率不高，尤其是在高丢包率场景下。研究旨在探索网络编码（RLNC）在5G无线系统中的替代潜力。

Method: 在5G测试床的IP层中，通过基于netfilter的包拦截框架，将RLNC注入gNB与UE之间的实时流量，并评估其对吞吐量、抖动和资源使用的影响。

Result: 实验结果表明，在适当的编码率下，RLNC能完全恢复丢包且比ARQ/HARQ传输次数更少，保持高吞吐量，尤其在高丢包率下表现更佳。

Conclusion: 网络编码（RLNC）可有效替代传统重传机制，提高未来无线系统的资源利用效率。

Abstract: This work presents the design and implementation of a real-time network
coding system integrated into the IP layer of a 5G testbed, offering an
alternative to conventional retransmission-based reliability mechanisms such as
ARQ and HARQ. Using a netfilter-based packet interception framework, we inject
forward erasure correction using Random Linear Network Coding (RLNC) into live
traffic between a gNB and UE over a 3GPP RF link. We evaluate a block coding
scheme, analyzing its impact on throughput, jitter, and resource usage. Results
show that with appropriate code rate selection, RLNC can fully recover from
packet losses using fewer transmissions than ARQ/HARQ and maintain a high
throughput, particularly under moderate-to-high packet loss rates. These
findings demonstrate that network coding can effectively replace
retransmission-based reliability in future wireless systems, with the potential
for more efficient resource utilization.

</details>


### [10] [Design of a Timer Queue Supporting Dynamic Update Operations](https://arxiv.org/abs/2508.10283)
*Zekun Wang,Binghao Yue,Weitao Pan,Jiangyi Shi,Yue Hao*

Main category: cs.NI

TL;DR: 提出了一种基于脉动阵列和移位寄存器的混合架构硬件优先级队列，用于高效管理大规模计时器，解决了传统实现中的低精度和高开销问题。


<details>
  <summary>Details</summary>
Motivation: 传统的大规模计时器实现存在计时精度低和计算开销高的问题，尤其是在软件定义网络、以太网桥接和TCP/IP协议中，亟需一种高效解决方案。

Method: 设计了基于脉动阵列和移位寄存器的硬件优先级队列，支持入队、出队、删除、更新和查看五种操作，并首次实现队列内优先级更新。

Result: 实验表明，设计在FPGA上运行频率超过400 MHz，资源消耗比现有方案减少了2.2-2.8倍。

Conclusion: 该混合架构硬件优先级队列在大规模计时器管理中表现出高效性和低资源消耗，具有实际应用潜力。

Abstract: Large-scale timers are ubiquitous in network processing, including flow table
entry expiration control in software defined network (SDN) switches, MAC
address aging in Ethernet bridges, and retransmission timeout management in
TCP/IP protocols. Conventional implementations suffer from critical
limitations: low timing accuracy due to large-scale timer traversal and high
computational overhead for new timer insertion. This paper presents a
hybrid-architecture hardware priority queue based on systolic arrays and shift
registers for efficient timer queue management. The design uniquely supports
five operations: enqueue, dequeue, delete, update, and peek.To the best of our
knowledge, it is the first hardware priority queue enabling in-queue priority
updates. By leveraging centralized Boolean logic encoding within systolic
blocks, the design efficiently generates set/shift control signals while the
novel push-first operation ensures FIFO ordering for same-priority timers
without additional metadata. Experimental results demonstrate that the design
operates at over 400 MHz on FPGAs, achieving a 2.2-2.8x reduction in resource
consumption compared to state-of-the-art implementations.

</details>


### [11] [Near-realtime Earth Observation Via Starlink LEO Satellite Constellation](https://arxiv.org/abs/2508.10338)
*Bo Wu,Pengfei Zhou*

Main category: cs.NI

TL;DR: 研究了利用Starlink卫星基础设施支持地球观测卫星数据下载的可行性，并提出了一种名为“Starlink Space User”（SSU）的新型数据传递系统。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星数据下载面临地面站数量有限和通信窗口短暂的问题，而Starlink等新兴低轨星座提供了连续连接的可能性。

Method: 设计了SSU系统，将观测卫星视为Starlink的空间用户，并通过优化链路、PoP选择和系统调度算法实现高效数据传输。

Result: 通过真实性能测量和仿真验证，SSU设计显著减少了每颗卫星的未传输数据中位数积压。

Conclusion: 利用Starlink卫星基础设施支持地球观测卫星数据下载是可行的，并能显著提高数据传输效率。

Abstract: Earth observation (EO) satellites in Low Earth Orbit (LEO) are collecting
vast amounts of data, which are invaluable for applications such as monitoring
forest fires. However, data downloading from EO satellites faces significant
challenges due to the limited number of ground stations and the brief
communication windows with them. Conversely, emerging LEO constellations like
Starlink have enabled continuous connectivity and revolutionized access for
ordinary users globally, who can connect via a simple satellite dish. In this
paper, we study the feasibility of supporting EO satellites with Starlink
satellite infrastructure and introduce a novel data delivery system, designated
as "Starlink Space User" (SSU), for relaying data from observation satellites.
SSU treats EO satellites as space users of Starlink, facilitating efficient
data transfer to Earth. At the core of SSU is a novel class of algorithms
designed for link and PoP selection, as well as system scheduling optimization,
that operate effectively atop Starlink's proprietary infrastructure. We assess
the performance of SSU using trace-driven simulations alongside real-world
Starlink performance measurements. Our results demonstrate that the proposed
Starlink-aided design can significantly reduce the median backlog (data not
delivered) per satellite.

</details>


### [12] [Probabilistic Latency Analysis of the Data Distribution Service in ROS 2](https://arxiv.org/abs/2508.10413)
*Sanghoon Lee,Hyung-Seok Park,Jiyeong Chae,Kyung-Joon Park*

Main category: cs.NI

TL;DR: ROS 2使用DDS进行通信，但在无线网络中其心跳机制和重传策略导致延迟行为不透明，难以调优。本文提出概率延迟分析（PLA），通过离散状态方法建模可靠传输过程，系统分析中间件和传输层事件，计算未确认消息和重传延迟的稳态概率分布，并通过实验验证其准确性，为无线工业机器人优化提供理论依据。


<details>
  <summary>Details</summary>
Motivation: ROS 2的DDS通信在无线网络中可靠性调优困难，缺乏对延迟行为的透明分析，需要一种系统化方法解决这一问题。

Method: 提出概率延迟分析（PLA），采用离散状态方法建模ROS 2 DDS的可靠传输过程，分析中间件和传输层事件，计算未确认消息和重传延迟的稳态概率分布。

Result: 通过270种场景的实验验证，PLA的分析结果与实验数据高度一致，为无线工业机器人通信优化提供了理论基础。

Conclusion: PLA为ROS 2在无线网络中的可靠性、延迟和性能优化提供了系统化的理论支持。

Abstract: Robot Operating System 2 (ROS 2) is now the de facto standard for robotic
communication, pairing UDP transport with the Data Distribution Service (DDS)
publish-subscribe middleware. DDS achieves reliability through periodic
heartbeats that solicit acknowledgments for missing samples and trigger
selective retransmissions. In lossy wireless networks, the tight coupling among
heartbeat period, IP fragmentation, and retransmission interval obscures end to
end latency behavior and leaves practitioners with little guidance on how to
tune these parameters. To address these challenges, we propose a probabilistic
latency analysis (PLA) that analytically models the reliable transmission
process of ROS 2 DDS communication using a discrete state approach. By
systematically analyzing both middleware level and transport level events, PLA
computes the steady state probability distribution of unacknowledged messages
and the retransmission latency. We validate our PLA across 270 scenarios,
exploring variations in packet delivery ratios, message sizes, and both
publishing and retransmission intervals, demonstrating a close alignment
between analytical predictions and experimental results. Our findings establish
a theoretical basis to systematically optimize reliability, latency, and
performance in wireless industrial robotics.

</details>


### [13] [Federated Learning Over LoRa Networks: Simulator Design and Performance Evaluation](https://arxiv.org/abs/2508.10574)
*Anshika Singh,Siddhartha S. Borkotoky*

Main category: cs.NI

TL;DR: 开发了一个基于Python的模拟器，用于评估基于LoRa网络的联邦学习性能，重点分析了FEC对学习收敛和设备通信时间的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在LoRa低功耗广域网中实现联邦学习的独特挑战，如带宽限制、干扰和严格的占空比约束。

Method: 整合并扩展Flower和LoRaSim框架，构建了一个详细的链路级模型，支持稀疏化、量化、压缩、FEC和占空比控制。

Result: 数值结果表明传输参数（扩频因子、FEC速率）和干扰对FL性能的影响，强调了FEC在FL中的关键作用。

Conclusion: FEC对LoRa网络中联邦学习的收敛和设备通信时间有显著影响，为通信协议设计提供了重要见解。

Abstract: Federated learning (FL) over long-range (LoRa) low-power wide area networks
faces unique challenges due to limited bandwidth, interference, and strict
duty-cycle constraints. We develop a Python-based simulator that integrates and
extends the Flower and LoRaSim frameworks to evaluate centralized FL over LoRa
networks. The simulator employs a detailed link-level model for FL update
transfer over LoRa channels, capturing LoRa's receiver sensitivity,
interference characteristics, block-fading effects, and constraints on the
maximum transmission unit. It supports update sparsification, quantization,
compression, forward frame-erasure correction (FEC), and duty cycling.
Numerical results illustrate the impact of transmission parameters (spreading
factor, FEC rate) and interference on FL performance. Demonstrating the
critical role of FEC in enabling FL over LoRa networks, we perform an in-depth
evaluation of the impact of FEC on FL convergence and device airtime, providing
insights for communication protocol design for FL over LoRa networks.

</details>


### [14] [Balancing the Energy Consumption and Latency of Over-the-Air Firmware Updates in LoRaWAN](https://arxiv.org/abs/2508.10588)
*Siddhartha S. Borkotoky*

Main category: cs.NI

TL;DR: 提出了一种灵活的LoRaWAN固件更新方案，通过调整扩展因子实现能耗与延迟的可调平衡。


<details>
  <summary>Details</summary>
Motivation: LoRaWAN终端设备能源受限且传输受占空比限制，需在固件更新中控制能耗和延迟。

Method: 使用LoRa扩展因子顺序传输更新帧，调整最小扩展因子和每因子的传输次数以实现能耗与延迟的权衡。

Result: 方案能灵活适应不同需求，如安全补丁采用低延迟高能耗设置，非关键更新则采用高延迟低能耗设置。

Conclusion: 该方案为LoRaWAN固件更新提供了一种高效的能耗与延迟平衡方法。

Abstract: Over-the-air firmware updates are crucial for mitigating security threats and
maintaining up-to-date device functionality in Long Range Wide Area Networks
(LoRaWANs). LoRaWAN end devices are usually energy-constrained, and LoRaWAN
transmissions are subject to duty-cycle restrictions. Consequently, controlling
the energy expenditure and update-delivery latency of FUOTA are key challenges.
We propose a flexible scheme that achieves a tunable trade-off between the
energy consumption and delivery delay. The scheme employs the LoRa spreading
factors sequentially to transmit update-carrying frames, sending a fixed number
of frames with a given spreading factor before moving to the next. By adjusting
the smallest spreading factor to be used and the number of transmissions per
spreading factor, a suitable energy-delay trade-off can be achieved. Thus,
time-sensitive updates, such as security patches, may be sent with a
low-delay-high-energy setting, whereas a more energy-efficient but higher-delay
setting may be used for non-critical updates.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [15] [Ensembling Synchronisation-based and Face-Voice Association Paradigms for Robust Active Speaker Detection in Egocentric Recordings](https://arxiv.org/abs/2508.10580)
*Jason Clarke,Yoshihiko Gotoh,Stefan Goetze*

Main category: cs.MM

TL;DR: 提出了一种简单有效的集成方法，结合同步依赖和非同步依赖的模型输出，通过加权平均融合互补线索，提升了ASD在复杂条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决ASD在第一人称视角记录中因遮挡、运动模糊和音频干扰导致的时间同步性问题，以及传统方法和FVA方法各自的局限性。

Method: 结合同步依赖和非同步依赖的模型输出，通过加权平均融合；优化FVA组件的预处理流程。

Result: 在Ego4D-AVD验证集上，集成方法分别使用TalkNet和Light-ASD骨干模型取得了70.2%和66.7%的mAP。

Conclusion: 该方法通过简单架构融合互补线索，显著提升了ASD在复杂条件下的性能，并通过定性分析验证了各组件的互补优势。

Abstract: Audiovisual active speaker detection (ASD) in egocentric recordings is
challenged by frequent occlusions, motion blur, and audio interference, which
undermine the discernability of temporal synchrony between lip movement and
speech. Traditional synchronisation-based systems perform well under clean
conditions but degrade sharply in first-person recordings. Conversely,
face-voice association (FVA)-based methods forgo synchronisation modelling in
favour of cross-modal biometric matching, exhibiting robustness to transient
visual corruption but suffering when overlapping speech or front-end
segmentation errors occur. In this paper, a simple yet effective ensemble
approach is proposed to fuse synchronisation-dependent and
synchronisation-agnostic model outputs via weighted averaging, thereby
harnessing complementary cues without introducing complex fusion architectures.
A refined preprocessing pipeline for the FVA-based component is also introduced
to optimise ensemble integration. Experiments on the Ego4D-AVD validation set
demonstrate that the ensemble attains 70.2% and 66.7% mean Average Precision
(mAP) with TalkNet and Light-ASD backbones, respectively. A qualitative
analysis stratified by face image quality and utterance masking prevalence
further substantiates the complementary strengths of each component.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [16] [Repairing General Game Descriptions (extended version)](https://arxiv.org/abs/2508.10438)
*Yifan He,Munyque Mittelmann,Aniello Murano,Abdallah Saffidine,Michael Thielscher*

Main category: cs.LO

TL;DR: 论文提出了针对游戏描述语言（GDL）的自动修复方法，利用逻辑属性和最小修复技术，解决了手动修复的难题。


<details>
  <summary>Details</summary>
Motivation: GDL用于描述游戏规则，但其正确性验证和修复对非专家具有挑战性。现有方法虽能检测问题，但修复仍需手工完成。

Method: 通过定义GDL描述的最小修复问题，结合计算复杂性分析，并使用基于答案集编程（ASP）的编码实现自动修复。

Result: 实现了对不符合要求的GDL描述的自动最小修复，并展示了其在实际游戏描述中的应用。

Conclusion: 该方法为GDL描述的自动修复提供了高效解决方案，尤其适用于非专家用户。

Abstract: The Game Description Language (GDL) is a widely used formalism for specifying
the rules of general games. Writing correct GDL descriptions can be
challenging, especially for non-experts. Automated theorem proving has been
proposed to assist game design by verifying if a GDL description satisfies
desirable logical properties. However, when a description is proved to be
faulty, the repair task itself can only be done manually. Motivated by the work
on repairing unsolvable planning domain descriptions, we define a more general
problem of finding minimal repairs for GDL descriptions that violate formal
requirements, and we provide complexity results for various computational
problems related to minimal repair. Moreover, we present an Answer Set
Programming-based encoding for solving the minimal repair problem and
demonstrate its application for automatically repairing ill-defined game
descriptions.

</details>


### [17] [Modal definability in Euclidean modal logics](https://arxiv.org/abs/2508.10813)
*Philippe Balbiani,Tinko Tinchev*

Main category: cs.LO

TL;DR: 摘要


<details>
  <summary>Details</summary>
Motivation: 研究欧几里得模态逻辑框架类中模态可定义性问题的可计算性

Method: 特征化导致模态可定义性问题不可判定的欧几里得模态逻辑

Result: 确定了哪些欧几里得模态逻辑会导致不可判定的模态可定义性问题

Conclusion: 为欧几里得模态逻辑中模态可定义性问题的可计算性提供了理论支持

Abstract: This paper is about the computability of the modal definability problem in
classes of frames determined by Euclidean modal logics. We characterize those
Euclidean modal logics such that the classes of frames they determine give rise
to an undecidable modal definability problem.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [18] [Pre-trained Transformer-models using chronic invasive electrophysiology for symptom decoding without patient-individual training](https://arxiv.org/abs/2508.10160)
*Timon Merk,Saeed Salehi,Richard M. Koehler,Qiming Cui,Maria Olaru,Amelia Hahn,Nicole R. Provenza,Simon Little,Reza Abbasi-Asl,Phil A. Starr,Wolf-Julian Neumann*

Main category: cs.HC

TL;DR: 该论文提出了一种用于病理和生理状态神经解码的基础模型，支持个性化闭环神经调节治疗。通过优化的预训练损失函数，避免了1/f功率定律带来的频率偏差，并在帕金森病症状解码任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 通过预训练的大规模基础模型实现无需患者个性化训练的状态估计，为闭环神经调节治疗提供支持。

Method: 利用慢性纵向深度脑刺激记录训练基础模型，优化预训练损失函数以纠正频率偏差，并采用留一受试者交叉验证。

Result: 在帕金森病症状解码任务中，模型无需患者个性化训练即可实现有效解码。

Conclusion: 该方法为广义状态估计和个性化神经调节治疗提供了新思路。

Abstract: Neural decoding of pathological and physiological states can enable
patient-individualized closed-loop neuromodulation therapy. Recent advances in
pre-trained large-scale foundation models offer the potential for generalized
state estimation without patient-individual training. Here we present a
foundation model trained on chronic longitudinal deep brain stimulation
recordings spanning over 24 days. Adhering to long time-scale symptom
fluctuations, we highlight the extended context window of 30 minutes. We
present an optimized pre-training loss function for neural electrophysiological
data that corrects for the frequency bias of common masked auto-encoder loss
functions due to the 1-over-f power law. We show in a downstream task the
decoding of Parkinson's disease symptoms with leave-one-subject-out
cross-validation without patient-individual training.

</details>


### [19] [Training Spatial Ability in Virtual Reality](https://arxiv.org/abs/2508.10195)
*Yiannos Demetriou,Manasvi Parikh,Sara Eskandari,Westley Weimer,Madeline Endres*

Main category: cs.HC

TL;DR: VR用于空间推理教学的短期课程效果显著，与传统纸笔课程相当且更高效。


<details>
  <summary>Details</summary>
Motivation: 验证VR是否能有效提升空间推理能力，并与传统方法对比。

Method: 将纸笔课程模块改编为VR形式，结合教学支架和实时反馈，通过预测试、后测和问卷评估效果。

Result: VR课程显著提升空间能力，效果与传统课程相当但时间更短，且用户反馈积极。

Conclusion: VR是一种高效且受欢迎的空间推理教学工具。

Abstract: Background: Spatial reasoning has been identified as a critical skill for
success in STEM. Unfortunately, under-represented groups often have lower
incoming spatial ability. Courses that improve spatial skills exist but are not
widely used. Virtual reality (VR) has been suggested as a possible tool for
teaching spatial reasoning since students are more accurate and complete
spatial tasks more quickly in three dimensions. However, no prior work has
developed or evaluated a fully-structured VR spatial skills course. Objectives:
We seek to assess the effectiveness of teaching spatial reasoning in VR, both
in isolation as a structured training curriculum and also in comparison to
traditional methods. Methods: We adapted three modules of an existing
pencil-and-paper course to VR, leveraging educational scaffolding and real-time
feedback in the design. We evaluated our three-week course in a study with
$n=24$ undergraduate introductory STEM students, capturing both quantitative
spatial ability gains (using pre- and post test scores on validated
assessments) and qualitative insights (from a post-study questionnaire). We
also compared our VR course to an offering of a baseline non-VR course (using
data collected in a previous study). Results and Conclusions: Students who took
our VR course had significant spatial ability gains. Critically, we find no
significant difference in outcomes between our VR course (3 meetings of 120
minutes each) and a baseline pencil and paper course (10 meetings of 90 minutes
each), suggesting that spatial reasoning can be very efficiently taught in VR.
We observed cybersickness at lower rates than are generally reported and most
students reported enjoying learning in VR.

</details>


### [20] [Personalized Real-time Jargon Support for Online Meetings](https://arxiv.org/abs/2508.10239)
*Yifan Song,Wing Yee Au,Hon Yung Wong,Brian P. Bailey,Tal August*

Main category: cs.HC

TL;DR: 论文探讨了跨学科沟通中术语障碍的问题，通过日记研究发现当前术语管理策略的不足，设计了一个实时个性化术语解释系统ParseJargon，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 跨学科沟通常因专业术语（jargon）而受阻，影响了理解和合作。研究旨在探索术语障碍并提出解决方案。

Method: 通过日记研究收集数据，设计并实现了基于大型语言模型（LLM）的系统ParseJargon，提供实时个性化术语解释。实验对比了无支持、通用支持和个性化支持的效果。

Result: 实验显示，个性化术语支持显著提升了参与者的理解、参与度和对同事工作的欣赏，而通用支持反而降低了参与度。实地研究验证了ParseJargon的实际应用价值。

Conclusion: 研究证明了个性化术语支持工具的有效性，为跨学科沟通和教育应用提供了新思路。

Abstract: Effective interdisciplinary communication is frequently hindered by
domain-specific jargon. To explore the jargon barriers in-depth, we conducted a
formative diary study with 16 professionals, revealing critical limitations in
current jargon-management strategies during workplace meetings. Based on these
insights, we designed ParseJargon, an interactive LLM-powered system providing
real-time personalized jargon identification and explanations tailored to
users' individual backgrounds. A controlled experiment comparing ParseJargon
against baseline (no support) and general-purpose (non-personalized) conditions
demonstrated that personalized jargon support significantly enhanced
participants' comprehension, engagement, and appreciation of colleagues' work,
whereas general-purpose support negatively affected engagement. A follow-up
field study validated ParseJargon's usability and practical value in real-time
meetings, highlighting both opportunities and limitations for real-world
deployment. Our findings contribute insights into designing personalized jargon
support tools, with implications for broader interdisciplinary and educational
applications.

</details>


### [21] [Facilitating Longitudinal Interaction Studies of AI Systems](https://arxiv.org/abs/2508.10252)
*Tao Long,Sitong Wang,Émilie Fabre,Tony Wang,Anup Sathya,Jason Wu,Savvas Petridis,Dingzeyu Li,Tuhin Chakrabarty,Yue Jiang,Jingyi Li,Tiffany Tseng,Ken Nakagaki,Qian Yang,Nikolas Martelaro,Jeffrey V. Nickerson,Lydia B. Chilton*

Main category: cs.HC

TL;DR: UIST研究者开发工具解决用户问题，但用户与AI的交互随时间变化，需长期研究。工作坊旨在解决长期研究的挑战，推动方法论。


<details>
  <summary>Details</summary>
Motivation: 用户与AI的交互随时间动态变化，单次评估不足，需长期研究以捕捉变化。

Method: 工作坊包括主题演讲、小组讨论和互动分组，用于讨论和实践长期研究协议设计及工具原型开发。

Result: 通过工作坊，研究者获得长期研究的实用策略，并推动社区对长期系统研究的接纳。

Conclusion: 长期研究是设计、构建和评估UIST工具的重要方法，工作坊为研究者提供了方法和社区支持。

Abstract: UIST researchers develop tools to address user challenges. However, user
interactions with AI evolve over time through learning, adaptation, and
repurposing, making one time evaluations insufficient. Capturing these dynamics
requires longer-term studies, but challenges in deployment, evaluation design,
and data collection have made such longitudinal research difficult to
implement. Our workshop aims to tackle these challenges and prepare researchers
with practical strategies for longitudinal studies. The workshop includes a
keynote, panel discussions, and interactive breakout groups for discussion and
hands-on protocol design and tool prototyping sessions. We seek to foster a
community around longitudinal system research and promote it as a more embraced
method for designing, building, and evaluating UIST tools.

</details>


### [22] [Artificial Emotion: A Survey of Theories and Debates on Realising Emotion in Artificial Intelligence](https://arxiv.org/abs/2508.10286)
*Yupei Li,Qiyang Sun,Michelle Schlicher,Yee Wen Lim,Björn W. Schuller*

Main category: cs.HC

TL;DR: 本文探讨AI是否需要通过发展内部情感状态（人工情感AE）来超越情感识别与合成，以实现更高级的人工智能（AGI），并分析了AE的优势、当前表现、架构及伦理风险。


<details>
  <summary>Details</summary>
Motivation: 探讨AI通过内部情感状态（AE）是否有助提升其能力，特别是在实现人工通用智能（AGI）中的作用。

Method: 回顾AE在机器学习系统中的表现，分析情感调制架构，并提出AE建模与整合机制。

Result: 指出AE可能为AI带来范式转变，但仍缺乏明确的实现框架，同时需关注伦理与安全风险。

Conclusion: AE有望为未来AI发展带来益处，但需要进一步研究其实现与伦理问题。

Abstract: Affective Computing (AC) has enabled Artificial Intelligence (AI) systems to
recognise, interpret, and respond to human emotions - a capability also known
as Artificial Emotional Intelligence (AEI). It is increasingly seen as an
important component of Artificial General Intelligence (AGI). We discuss
whether in order to peruse this goal, AI benefits from moving beyond emotion
recognition and synthesis to develop internal emotion-like states, which we
term as Artificial Emotion (AE). This shift potentially allows AI to benefit
from the paradigm of `inner emotions' in ways we - as humans - do. Although
recent research shows early signs that AI systems may exhibit AE-like
behaviours, a clear framework for how emotions can be realised in AI remains
underexplored. In this paper, we discuss potential advantages of AE in AI,
review current manifestations of AE in machine learning systems, examine
emotion-modulated architectures, and summarise mechanisms for modelling and
integrating AE into future AI. We also explore the ethical implications and
safety risks associated with `emotional' AGI, while concluding with our opinion
on how AE could be beneficial in the future.

</details>


### [23] [Beyond Self-Regulated Learning Processes: Unveiling Hidden Tactics in Generative AI-Assisted Writing](https://arxiv.org/abs/2508.10310)
*Kaixun Yang,Yizhou Fan,Luzhen Tang,Mladen Raković,Xinyu Li,Dragan Gašević,Guanliang Chen*

Main category: cs.HC

TL;DR: 论文探讨了生成式AI（GenAI）在教育中的应用如何影响学生的自我调节学习（SRL），并提出了一种新的分层模型来理解SRL的动态性。通过隐马尔可夫模型（HMMs）分析学生的行为数据，研究发现不同SRL策略组在任务表现上差异显著。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在教育中的普及使得学生的自我调节学习能力变得尤为重要。现有研究通常假设SRL过程是线性且分割的，未能充分反映真实学习的动态性和非线性特征。本研究旨在弥补这一局限。

Method: 研究将SRL视为一个分层系统，通过隐马尔可夫模型（HMMs）分析学生在GenAI辅助写作中的数字痕迹数据，识别出不同的SRL策略组。

Result: 研究发现三个不同的SRL策略组，且这些组在任务表现上存在显著差异，表明SRL策略对GenAI辅助学习的效果有重要影响。

Conclusion: 研究不仅为SRL建模提供了新的方法论工具，还为设计适应GenAI教育环境的自适应学习技术提供了依据。

Abstract: The integration of Generative AI (GenAI) into education is reshaping how
students learn, making self-regulated learning (SRL) - the ability to plan,
monitor, and adapt one's learning - more important than ever. To support
learners in these new contexts, it is essential to understand how SRL unfolds
during interaction with GenAI tools. Learning analytics offers powerful
techniques for analyzing digital trace data to infer SRL behaviors. However,
existing approaches often assume SRL processes are linear, segmented, and
non-overlapping-assumptions that overlook the dynamic, recursive, and
non-linear nature of real-world learning. We address this by conceptualizing
SRL as a layered system: observable learning patterns reflect hidden tactics
(short, purposeful action states), which combine into broader SRL strategies.
Using Hidden Markov Models (HMMs), we analyzed trace data from higher education
students engaged in GenAI-assisted academic writing. We identified three
distinct groups of learners, each characterized by different SRL strategies.
These groups showed significant differences in performance, indicating that
students' use of different SRL strategies in GenAI-assisted writing led to
varying task outcomes. Our findings advance the methodological toolkit for
modeling SRL and inform the design of adaptive learning technologies that more
effectively support learners in GenAI-enhanced educational environments.

</details>


### [24] [Mental Effort Estimation in Motion Exploration and Concept Generation Design Tasks using Inter-Band Relative Power Difference of EEG](https://arxiv.org/abs/2508.10353)
*G. Kalyan Ramana,Sumit Yempalle,Prasad S. Onkar*

Main category: cs.HC

TL;DR: 研究通过EEG分析设计中的认知现象，提出新指标inter-BRPD量化脑力劳动，验证其在运动探索任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 静态草图难以准确表达运动概念，需研究设计师在探索运动概念时的认知现象。

Method: 32名参与者完成运动和概念生成任务，记录EEG数据并用inter-BRPD分析脑力劳动。

Result: inter-BRPD能高效捕获脑力劳动，统计验证其可靠性。

Conclusion: 研究为支持概念设计及其评估提供了新工具和认知见解。

Abstract: Conceptual design is a cognitively complex task, especially in the
engineering design of products having relative motion between components.
Designers prefer sketching as a medium for conceptual design and use gestures
and annotations to represent such relative motion. Literature suggests that
static representations of motion in sketches may not achieve the intended
functionality when realised, because it primarily depends on the designers'
mental capabilities for motion simulation. Thus, it is important to understand
the cognitive phenomena when designers are exploring concepts of articulated
products. The current work is an attempt to understand design neurocognition by
categorising the tasks and measuring the mental effort involved in these tasks
using EEG. The analysis is intended to validate design intervention tools to
support the conceptual design involving motion exploration. A novel EEG-based
metric, inter-Band Relative Power Difference (inter-BRPD), is introduced to
quantify mental effort. A design experiment is conducted with 32 participants,
where they have to perform one control task and 2 focus tasks corresponding to
the motion exploration task (MET) and the concept generation task (CGT),
respectively. EEG data is recorded during the 3 tasks, cleaned, processed and
analysed using the MNE library in Python. It is observed from the results that
inter-BRPD captures the essence of mental effort with half the number of
conventionally used parameters. The reliability and efficacy of the inter-BRPD
metric are also statistically validated against literature-based cognitive
metrics. With these new insights, the study opens up possibilities for creating
support for conceptual design and its evaluation.

</details>


### [25] ["Here Comes the Makeup Tutorial You Asked For!": Exploring Communication Strategies and Viewer Engagement in Beauty Videos on Rednote](https://arxiv.org/abs/2508.10364)
*Xueer Lin,Chenyu Li,Yuhan Lyu,Zhicong Lu,Zhenhui Peng*

Main category: cs.HC

TL;DR: 研究分析了美妆视频的传播策略对观众参与度的影响，通过编码视频和评论分类，揭示了策略与评论类别的关系，如呼吁行动会引发产品效果讨论。


<details>
  <summary>Details</summary>
Motivation: 了解美妆视频创作者使用的传播策略及其对观众参与的影响，以促进美妆知识的传播。

Method: 通过编码352个Rednote平台上的美妆视频，分析传播策略，并使用计算分类法对评论进行分类。

Result: 回归分析显示传播策略对观众参与有显著影响，例如视频结尾的呼吁行动会引发更多关于产品效果的讨论。

Conclusion: 研究为美妆视频的创作和知识传播提供了实用的见解。

Abstract: More and more people, especially females, create and view beauty videos
covering topics like makeup tutorials and vlogs on social media platforms.
Understanding the communication strategies that creators use in these videos
and how they affect viewers' engagement can help spread beauty knowledge. By
coding 352 beauty videos in Rednote, this study presents a comprehensive
taxonomy of communication strategies used by the creators, such as using home
as the video background and displaying makeup effects when starting the
narrative at the beginning. We further label and computationally classify six
categories of comments that reveal viewers' engagement with beauty videos. The
regression analyses reveal the effects of beauty video communication strategies
on viewers' engagement; for example, calling viewers to take action at the end
tends to attract more comments that debate the product's efficacy. We discuss
insights into fostering the creation of beauty videos and the communication of
beauty knowledge.

</details>


### [26] [MCP2OSC: Parametric Control by Natural Language](https://arxiv.org/abs/2508.10414)
*Yuan-Yi Fan*

Main category: cs.HC

TL;DR: 本文提出了一种结合自然语言提示和高精度控制的MCP2OSC工具，通过Claude与MCP服务器的集成，实现了对OSC消息的高效处理，提升了人机协作的灵活性和创造力。


<details>
  <summary>Details</summary>
Motivation: 解决文本提示在复杂任务中精度不足的问题，同时避免传统滑块控制带来的复杂性，实现自然语言与高精度控制的结合。

Method: 提出MCP（模型上下文协议）服务器和一套独特的提示设计准则，结合Claude与MCP2OSC服务器，通过自然语言处理OSC消息。通过14个实际案例验证有效性。

Result: Claude与MCP2OSC服务器成功生成、解释、搜索、可视化、验证和调试OSC消息，并管理OSC地址模式。

Conclusion: MCP2OSC工具利用LLM的优势，为多媒体设备提供了一种基于语言模型的通用控制机制，具有广泛的应用潜力。

Abstract: Text prompts enable intuitive content creation but may fall short in
achieving high precision for intricate tasks; knob or slider controls offer
precise adjustments at the cost of increased complexity. To address the gap
between knobs and prompts, a new MCP (Model Context Protocol) server and a
unique set of prompt design criteria are presented to enable exploring
parametric OSC (OpenSoundControl) control by natural language prompts.
Demonstrated by 14 practical QA examples with best practices and the
generalized prompt templates, this study finds Claude integrated with the
MCP2OSC server effective in generating OSC messages by natural language,
interpreting, searching, and visualizing OSC messages, validating and debugging
OSC messages, and managing OSC address patterns. MCP2OSC enhances human-machine
collaboration by leveraging LLM (Large Language Model) to handle intricate OSC
development tasks, and by empowering human creativity with an intuitive
language interface featuring flexible precision controls: a prompt-based OSC
tool. This study provides a novel perspective on the creative MCP application
at the network protocol level by utilizing LLM's strength in directly
processing and generating human-readable OSC messages. The results suggest its
potential for a LLM-based universal control mechanism for multimedia devices.

</details>


### [27] [Stress Detection from Multimodal Wearable Sensor Data](https://arxiv.org/abs/2508.10468)
*Paul Schreiber,Beyza Cinar,Lennart Mackert,Maria Maleshkova*

Main category: cs.HC

TL;DR: 论文介绍了多模态数据集，支持可穿戴情感计算研究，尤其是自动压力识别系统的开发，并提出了标准化的压力实验框架。


<details>
  <summary>Details</summary>
Motivation: 当前公开可用的数据集和标准化协议有限，因此需要开发能够监测和响应压力事件以预防健康问题的系统。

Method: 通过标准化框架收集生理和运动信号（如皮肤电活动、光电容积图、三轴加速度计），并在实验协议中区分四种状态（中性、身体、认知压力和社交评估压力）。

Result: 贡献包括一个新的多模态数据集和压力检测基准，二元分类准确率为89%，多类分类为82%。

Conclusion: 论文提供了标准化数据集和分类基准，推动了可穿戴设备在压力识别领域的应用。

Abstract: Human-Computer Interaction (HCI) is a multi-modal, interdisciplinary field
focused on designing, studying, and improving the interactions between people
and computer systems. This involves the design of systems that can recognize,
interpret, and respond to human emotions or stress. Developing systems to
monitor and react to stressful events can help prevent severe health
implications caused by long-term stress exposure. Currently, the publicly
available datasets and standardized protocols for data collection in this
domain are limited. Therefore, we introduce a multi-modal dataset intended for
wearable affective computing research, specifically the development of
automated stress recognition systems. We systematically review the publicly
available datasets recorded in controlled laboratory settings. Based on a
proposed framework for the standardization of stress experiments and data
collection, we collect physiological and motion signals from wearable devices
(e.g., electrodermal activity, photoplethysmography, three-axis accelerometer).
During the experimental protocol, we differentiate between the following four
affective/activity states: neutral, physical, cognitive stress, and
socio-evaluative stress. These different phases are meticulously labeled,
allowing for detailed analysis and reconstruction of each experiment. Meta-data
such as body positions, locations, and rest phases are included as further
annotations. In addition, we collect psychological self-assessments after each
stressor to evaluate subjects' affective states. The contributions of this
paper are twofold: 1) a novel multi-modal, publicly available dataset for
automated stress recognition, and 2) a benchmark for stress detection with 89\%
in a binary classification (baseline vs. stress) and 82\% in a multi-class
classification (baseline vs. stress vs. physical exercise).

</details>


### [28] [Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling](https://arxiv.org/abs/2508.10561)
*Andrea Gargano,Jasin Machkour,Mimma Nardelli,Enzo Pasquale Scilingo,Michael Muma*

Main category: cs.HC

TL;DR: 该研究通过分析生理信号与主观唤醒水平的关联性，发现只有两个电皮肤特征具有显著的统计关联性和可重复性，强调了在情感计算中严格评估特征可重复性的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决情感计算中主观情绪体验与客观生理标记之间可靠关联的挑战，并关注生理特征的可重复性问题。

Method: 使用CASE数据集，提取30名参与者的心血管和电皮肤信号特征，采用T-Rex方法进行特征选择，严格控制假发现率。

Result: 在所有候选特征中，仅有两个电皮肤特征表现出可重复且统计显著的关联性，确认率为100%。

Conclusion: 研究强调了生理特征选择中严格可重复性评估的必要性，为安全关键领域的应用（如精神障碍识别和人机交互系统）提供了可靠的白盒模型基础。

Abstract: In Affective Computing, a key challenge lies in reliably linking subjective
emotional experiences with objective physiological markers. This preliminary
study addresses the issue of reproducibility by identifying physiological
features from cardiovascular and electrodermal signals that are associated with
continuous self-reports of arousal levels. Using the Continuously Annotated
Signal of Emotion dataset, we analyzed 164 features extracted from cardiac and
electrodermal signals of 30 participants exposed to short emotion-evoking
videos. Feature selection was performed using the Terminating-Random
Experiments (T-Rex) method, which performs variable selection systematically
controlling a user-defined target False Discovery Rate. Remarkably, among all
candidate features, only two electrodermal-derived features exhibited
reproducible and statistically significant associations with arousal, achieving
a 100\% confirmation rate. These results highlight the necessity of rigorous
reproducibility assessments in physiological features selection, an aspect
often overlooked in Affective Computing. Our approach is particularly promising
for applications in safety-critical environments requiring trustworthy and
reliable white box models, such as mental disorder recognition and human-robot
interaction systems.

</details>


### [29] [Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions](https://arxiv.org/abs/2508.10586)
*Birgit Nierula,Mustafa Tevfik Lafci,Anna Melnik,Mert Akgül,Farelle Toumaleu Siewe,Sebastian Bosse*

Main category: cs.HC

TL;DR: 该研究探讨了虚拟现实中个人空间侵犯的生理和主观反应，发现长时间侵犯比接近阶段更易引发皮肤电反应，而愤怒面部表情会降低心率变异性和增加不适感。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补虚拟现实中个人空间侵犯的生理反应和面部表情调节效应的研究空白。

Method: 采用2x2因子设计，操纵个人空间（侵犯vs.尊重）和面部表情（中性vs.愤怒），记录皮肤电反应、心率变异性和不适感评分。

Result: 结果发现侵犯个人空间的站立阶段比接近阶段更易引发皮肤电反应，愤怒表情降低心率变异性并增加不适感，但不影响皮肤电反应。

Conclusion: 研究表明不同的生理指标捕捉了空间侵犯的不同方面，为虚拟环境中社交行为的综合评估和更真实的虚拟交互设计提供了依据。

Abstract: Proxemics, the study of spatial behavior, is fundamental to social
interaction and increasingly relevant for virtual reality (VR) applications.
While previous research has established that users respond to personal space
violations in VR similarly as in real-world settings, phase-specific
physiological responses and the modulating effects of facial expressions remain
understudied. We investigated physiological and subjective responses to
personal space violations by virtual avatars, to understand how threatening
facial expressions and interaction phases (approach vs. standing) influence
these responses. Sixteen participants experienced a 2x2 factorial design
manipulating Personal Space (intrusion vs. respect) and Facial Expression
(neutral vs. angry) while we recorded skin conductance response (SCR), heart
rate variability (HRV), and discomfort ratings. Personal space boundaries were
individually calibrated using a stop-distance procedure. Results show that SCR
responses are significantly higher during the standing phase compared to the
approach phase when personal space was violated, indicating that prolonged
proximity within personal space boundaries is more physiologically arousing
than the approach itself. Angry facial expressions significantly reduced HRV,
reflecting decreased parasympathetic activity, and increased discomfort
ratings, but did not amplify SCR responses. These findings demonstrate that
different physiological modalities capture distinct aspects of proxemic
responses: SCR primarily reflects spatial boundary violations, while HRV
responds to facial threat cues. Our results provide insights for developing
comprehensive multi-modal assessments of social behavior in virtual
environments and inform the design of more realistic avatar interactions.

</details>


### [30] [DEV: A Driver-Environment-Vehicle Closed-Loop Framework for Risk-Aware Adaptive Automation of Driving](https://arxiv.org/abs/2508.10618)
*Anaïs Halin,Christel Devue,Marc Van Droogenbroeck*

Main category: cs.HC

TL;DR: 提出DEV框架，通过闭环系统动态调整驾驶自动化级别，基于实时风险评估提升安全性与舒适性。


<details>
  <summary>Details</summary>
Motivation: 自动化车辆虽提升安全与舒适，但带来驾驶员分心、情境意识下降等新风险，需解决这些问题。

Method: 设计DEV框架，结合驾驶员、环境与车辆的动态交互，通过实时风险评估调整自动化级别。

Result: 实现更平滑的过渡与有效的人机协作，提出驱动风险管理的核心指标命名法。

Conclusion: DEV框架为多学科研究提供统一视角，指导动态、风险感知的驾驶自动化系统开发。

Abstract: The increasing integration of automation in vehicles aims to enhance both
safety and comfort, but it also introduces new risks, including driver
disengagement, reduced situation awareness, and mode confusion. In this work,
we propose the DEV framework, a closed-loop framework for risk-aware adaptive
driving automation that captures the dynamic interplay between the driver, the
environment, and the vehicle. The framework promotes to continuously adjusting
the operational level of automation based on a risk management strategy. The
real-time risk assessment supports smoother transitions and effective
cooperation between the driver and the automation system. Furthermore, we
introduce a nomenclature of indexes corresponding to each core component,
namely driver involvement, environment complexity, and vehicle engagement, and
discuss how their interaction influences driving risk. The DEV framework offers
a comprehensive perspective to align multidisciplinary research efforts and
guide the development of dynamic, risk-aware driving automation systems.

</details>


### [31] [Are Electrodermal Activity-Based Indicators of Driver Cognitive Distraction Robust to Varying Traffic Conditions and Adaptive Cruise Control Use?](https://arxiv.org/abs/2508.10620)
*Anaïs Halin,Marc Van Droogenbroeck,Christel Devue*

Main category: cs.HC

TL;DR: 通过模拟实验研究了皮肤电活动（EDA）如何反映不同交通条件和自适应巡航控制（ACC）使用下的驾驶员认知分心，发现EDA指标受多种因素影响。


<details>
  <summary>Details</summary>
Motivation: 探讨EDA在驾驶分心研究中的适用性，尤其是在复杂交通条件和自动化驾驶环境中的应用。

Method: 模拟驾驶实验设计，结合认知分心任务（心算）与不同交通条件，记录并分析三种EDA指标（SCL、SCR振幅、SCR率）。

Result: 认知分心和ACC使用显著影响所有EDA指标；环境复杂性影响SCL和SCR振幅，但不影响SCR率。

Conclusion: EDA指标能有效反映驾驶员心理负荷变化，包括认知分心、环境复杂性和自动化使用。

Abstract: In this simulator study, we investigate whether and how electrodermal
activity (EDA) reflects driver cognitive distraction under varying traffic
conditions and adaptive cruise control (ACC) use. Participants drove in six
scenarios, combining two levels of cognitive distraction (presence/absence of a
mental calculation task) and three levels of driving environment complexity
(different traffic conditions). Throughout the experiment, they were free to
activate or deactivate ACC (ACC use, two levels). We analyzed three EDA-based
indicators of cognitive distraction: SCL (mean skin conductance level), SCR
amplitude (mean amplitude of skin conductance responses), and SCR rate (rate of
skin conductance responses). Results indicate that all three indicators were
significantly influenced by cognitive distraction and ACC use, while
environment complexity influenced SCL and SCR amplitude, but not SCR rate.
These findings suggest that EDA-based indicators reflect variations in drivers'
mental workload due not only to cognitive distraction, but also to driving
environment and automation use.

</details>


### [32] [Gaze-Based Indicators of Driver Cognitive Distraction: Effects of Different Traffic Conditions and Adaptive Cruise Control Use](https://arxiv.org/abs/2508.10624)
*Anaïs Halin,Adrien Deliège,Christel Devue,Marc Van Droogenbroeck*

Main category: cs.HC

TL;DR: 研究通过模拟驾驶实验，探究了认知分心对驾驶员视线参数的影响，发现在交通复杂性和自适应巡航控制使用下，视线分散和集中的变化。


<details>
  <summary>Details</summary>
Motivation: 了解驾驶员在不同交通条件和自适应巡航控制使用下的认知分心表现，以改进驾驶辅助系统设计。

Method: 实验中，参与者完成六种驾驶场景组合，结合认知分心（有无心算）和驾驶环境复杂性三个级别，记录其视线参数。

Result: 交通复杂性增加时垂直视线分散增加，自适应巡航控制使用导致视线集中在道路中心；认知分心减少道路中心注视并增加垂直分散。

Conclusion: 认知分心对驾驶员视线行为有明显影响，尤其是在心算任务期间表现出临时视线集中，这为驾驶辅助系统的优化提供了依据。

Abstract: In this simulator study, we investigate how gaze parameters reflect driver
cognitive distraction under varying traffic conditions and adaptive cruise
control (ACC) use. Participants completed six driving scenarios that combined
two levels of cognitive distraction (with/without mental calculations) and
three levels of driving environment complexity. Throughout the experiment,
participants were free to activate or deactivate an ACC. We analyzed two
gaze-based indicators of driver cognitive distraction: the percent road center,
and the gaze dispersions (horizontal and vertical). Our results show that
vertical gaze dispersion increases with traffic complexity, while ACC use leads
to gaze concentration toward the road center. Cognitive distraction reduces
road center gaze and increases vertical dispersion. Complementary analyses
revealed that these observations actually arise mainly between mental
calculations, while periods of mental calculations are characterized by a
temporary increase in gaze concentration.

</details>


### [33] [Visualization of Electronic Health Record Sequences at Scale](https://arxiv.org/abs/2508.10700)
*Ambre Assor,Mickael Sereno,Jean-Daniel Fekete*

Main category: cs.HC

TL;DR: ParcoursVis是一种渐进式视觉分析工具，用于大规模探索电子健康记录序列，通过渐进算法实现快速近似结果展示，支持数千万患者的交互式分析。


<details>
  <summary>Details</summary>
Motivation: 现有工具在处理大规模数据时因延迟限制无法保持交互性，ParcoursVis旨在突破这一限制，支持罕见病或异常治疗路径的探索。

Method: 采用渐进算法，初始展示近似聚合结果（冰柱树），逐步迭代优化直至完成全部计算。

Result: ParcoursVis能交互式处理数千万患者的数千条事件记录，比同类系统提升3-5个数量级。

Conclusion: 工具已在真实医疗数据集上验证，开源且支持可视化设计师开发可扩展渐进系统。

Abstract: We present ParcoursVis, a Progressive Visual Analytics tool designed to
explore electronic health record sequences of patients at scale. Existing tools
process and aggregate the whole dataset upfront before showing the
visualization, taking a time proportional to the data size. Therefore, to
remain interactive, existing tools are limited to data sizes that can be
processed in under a few seconds to meet the latency constraints of human
attention. To overcome this limitation and scale to larger sizes, ParcoursVis
relies on a progressive algorithm that quickly shows an approximate initial
result of the aggregation, visualized as an Icicle tree, and improves it
iteratively, updating the visualization until the whole computation is done.
With its architecture, ParcoursVis remains interactive while visualizing the
sequences of tens of millions of patients, each described with thousands of
events; three to five orders of magnitude more than similar systems. Managing
large datasets allows for exploring rare medical conditions or unexpected
patient pathways, contributing to improving treatments. We describe the
algorithms we use and our evaluation concerning their scalability, convergence,
and stability. We also report on a set of guidelines to support visualization
designers in developing scalable progressive systems. ParcoursVis already
allows practitioners to perform analyses on two large real medical datasets.
Our prototype is open-source.

</details>


### [34] ["I Want My Chart to Be Just for Me": Community-Engaged Design to Support Outpatient Healthcare for Resettled Communities](https://arxiv.org/abs/2508.10757)
*Zhanming Chen,Juan F. Maestre,May Hang,Alisha Ghaju,Ji Youn Shin*

Main category: cs.HC

TL;DR: 论文探讨了通过参与式设计工作坊，利用移民社区的现有优势（如跨代健康管理和故事化沟通）改善其门诊医疗体验，而非仅关注其缺陷。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决移民群体在门诊医疗中因文化差异、语言障碍和低社会经济地位而面临的挑战。当前研究多关注弥补缺陷，忽略了社区已有的优势。

Method: 方法包括与30名美国苗族社区成员进行两次参与式设计工作坊，发掘其社区的四类资产（如跨代支持和故事化沟通）。

Result: 识别出社区已具备跨代健康管理和故事化沟通等资产，证明参与式设计可促进基于优势的解决方案。

Conclusion: 结论指出，通过参与式设计和技术手段利用患者的现有优势，可更可持续地支持其门诊健康管理。

Abstract: Individuals resettled in a new environment often face challenges in accessing
adequate healthcare services, particularly within the complex processes of
outpatient clinic care. Cultural differences, language barriers, and low
socioeconomic status contribute to these difficulties. While previous studies
have identified barriers and proposed technology-mediated solutions for
resettled populations, many focus on addressing deficits rather than building
on the strengths these communities already possess, which limits the
sustainability and relevance of these solutions in everyday life. We conducted
two community-based participatory design workshops with 30 Hmong community
members in a large metropolitan area in the US. Through this process, we
identified four types of assets the community has gradually developed,
including intergenerational support for health management and
storytelling-based communication practices that facilitate relatable and
culturally grounded interactions. We show how participatory design workshops
can foster asset-based approaches, and discuss design implications for
technologies that leverage patients' existing strengths to support their health
management during outpatient visits.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [35] [B-repLer: Semantic B-rep Latent Editor using Large Language Models](https://arxiv.org/abs/2508.10201)
*Yilin Liu,Niladri Shekhar Dutt,Changjian Li,Niloy J. Mitra*

Main category: cs.GR

TL;DR: 该论文探讨了多模态大语言模型（mLLMs）在3D边界表示（B-rep）CAD对象的高级编辑中的应用，提出了B-repLer模型，并通过新型多模态架构和自动生成数据集的方法，实现了基于文本提示的语义编辑。


<details>
  <summary>Details</summary>
Motivation: 尽管mLLMs在图像和文本任务中表现优异，但在3D分析（尤其是B-rep CAD编辑）中表现有限。原因是缺乏注释数据和3D表示的特殊性。

Method: 提出B-repLer模型，采用专为B-rep设计的多模态架构，并利用现有CAD工具自动生成推理数据集。

Result: B-repLer能基于文本提示对B-rep进行语义编辑，生成有效输出，并实现复杂编辑任务。

Conclusion: 通过B-repLer，mLLMs可成功适配B-rep编辑任务，为3D CAD领域提供了新工具和方法。

Abstract: Multimodal large language models (mLLMs), trained in a mixed modal setting as
a universal model, have been shown to compete with or even outperform many
specialized algorithms for imaging and graphics tasks. As demonstrated across
many applications, mLLMs' ability to jointly process image and text data makes
them suitable for zero-shot applications or efficient fine-tuning towards
specialized tasks. However, they have had limited success in 3D analysis and
editing tasks. This is due to both the lack of suitable (annotated) 3D data as
well as the idiosyncrasies of 3D representations. In this paper, we investigate
whether mLLMs can be adapted to support high-level editing of Boundary
Representation (B-rep) CAD objects. B-reps remain the industry-standard for
precisely encoding engineering objects, but are challenging as the
representation is fragile (i.e. can easily lead to invalid CAD objects) and no
publicly available data source exists with semantically-annotated B-reps or CAD
construction history. We present B-repLer as a finetuned mLLM that can
understand text prompts and make semantic edits on given B-Reps to produce
valid outputs. We enable this via a novel multimodal architecture, specifically
designed to handle B-rep models, and demonstrate how existing CAD tools, in
conjunction with mLLMs, can be used to automatically generate the required
reasoning dataset, without relying on external annotations. We extensively
evaluate B-repLer and demonstrate several text-based B-rep edits of various
complexity, which were not previously possible.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [36] [Hard Shell, Reliable Core: Improving Resilience in Replicated Systems with Selective Hybridization](https://arxiv.org/abs/2508.10141)
*Laura Lawniczak,Tobias Distler*

Main category: cs.DC

TL;DR: ShellFT框架通过微复制概念，灵活选择需要抵御拜占庭故障的复制逻辑部分，显著降低了多样化成本。


<details>
  <summary>Details</summary>
Motivation: 现有混合故障模型在灵活性和多样化成本方面存在不足。

Method: 提出ShellFT框架，利用微复制技术允许选择性增强拜占庭容错能力。

Result: 实现三个定制协议，多样化成本降低70%以上。

Conclusion: ShellFT为特定用例提供了灵活且高效的混合容错解决方案。

Abstract: Hybrid fault models are known to be an effective means for enhancing the
robustness of consensus-based replicated systems. However, existing
hybridization approaches suffer from limited flexibility with regard to the
composition of crash-tolerant and Byzantine fault-tolerant system parts and/or
are associated with a significant diversification overhead. In this paper we
address these issues with ShellFT, a framework that leverages the concept of
micro replication to allow system designers to freely choose the parts of the
replication logic that need to be resilient against Byzantine faults. As a key
benefit, such a selective hybridization makes it possible to develop hybrid
solutions that are tailored to the specific characteristics and requirements of
individual use cases. To illustrate this flexibility, we present three custom
ShellFT protocols and analyze the complexity of their implementations. Our
evaluation shows that compared with traditional hybridization approaches,
ShellFT is able to decrease diversification costs by more than 70%.

</details>


### [37] [Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices](https://arxiv.org/abs/2508.10202)
*Sreeram Venkat,Kasia Swirydowicz,Noah Wolfe,Omar Ghattas*

Main category: cs.DC

TL;DR: 该论文提出了一种基于Hipify的性能可移植框架，并将其应用于FFTMatvec，使其能够无缝运行在AMD GPU上，同时提出了动态混合精度框架，实现了在OLCF Frontier超级计算机上的大规模扩展。


<details>
  <summary>Details</summary>
Motivation: 由于高性能计算设施中的硬件多样性和GPU在低精度计算中的性能提升，科学HPC工作流需要混合精度算法和性能可移植模型。

Method: 使用Hipify框架实现性能可移植，并将优化集成到rocBLAS库中；提出动态混合精度框架，通过Pareto前沿分析确定最优配置。

Result: FFTMatvec在AMD GPU上表现优异，且扩展到OLCF Frontier的2,048个GPU上。

Conclusion: 该方法成功实现了性能可移植性和混合精度优化，为科学HPC工作流提供了高效解决方案。

Abstract: The hardware diversity displayed in leadership-class computing facilities,
alongside the immense performance boosts exhibited by today's GPUs when
computing in lower precision, provide a strong incentive for scientific HPC
workflows to adopt mixed-precision algorithms and performance portability
models. We present an on-the-fly framework using Hipify for performance
portability and apply it to FFTMatvec-an HPC application that computes
matrix-vector products with block-triangular Toeplitz matrices. Our approach
enables FFTMatvec, initially a CUDA-only application, to run seamlessly on AMD
GPUs with excellent observed performance. Performance optimizations for AMD
GPUs are integrated directly into the open-source rocBLAS library, keeping the
application code unchanged. We then present a dynamic mixed-precision framework
for FFTMatvec; a Pareto front analysis determines the optimal mixed-precision
configuration for a desired error tolerance. Results are shown for AMD Instinct
MI250X, MI300X, and the newly launched MI355X GPUs. The performance-portable,
mixed-precision FFTMatvec is scaled to 2,048 GPUs on the OLCF Frontier
supercomputer.

</details>


### [38] [GPZ: GPU-Accelerated Lossy Compressor for Particle Data](https://arxiv.org/abs/2508.10305)
*Ruoyu Li,Yafan Huang,Longtao Zhang,Zhuoxun Yang,Sheng Di,Jiajun Huang,Jinyang Liu,Jiannan Tian,Xin Liang,Guanpeng Li,Hanqi Guo,Franck Cappello,Kai Zhao*

Main category: cs.DC

TL;DR: GPZ是一種專為GPU設計的高性能、錯誤有界的壓縮器，針對大規模粒子數據進行優化，顯著提升壓縮效率和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 粒子模擬和點雲應用產生大量不規則數據，傳統壓縮技術在GPU架構下效率不足，難以兼顧壓縮比和吞吐量。

Method: GPZ採用四階段平行管道設計，針對計算、記憶體存取和GPU佔用進行優化，實現接近硬體極限的吞吐量。

Result: 在六個真實科學數據集上測試，GPZ比五種現有GPU壓縮器快8倍，同時提供更高壓縮比和數據質量。

Conclusion: GPZ為粒子數據壓縮提供了高效的解決方案，適用於工作站、數據中心和邊緣計算環境。

Abstract: Particle-based simulations and point-cloud applications generate massive,
irregular datasets that challenge storage, I/O, and real-time analytics.
Traditional compression techniques struggle with irregular particle
distributions and GPU architectural constraints, often resulting in limited
throughput and suboptimal compression ratios. In this paper, we present GPZ, a
high-performance, error-bounded lossy compressor designed specifically for
large-scale particle data on modern GPUs. GPZ employs a novel four-stage
parallel pipeline that synergistically balances high compression efficiency
with the architectural demands of massively parallel hardware. We introduce a
suite of targeted optimizations for computation, memory access, and GPU
occupancy that enables GPZ to achieve near-hardware-limit throughput. We
conduct an extensive evaluation on three distinct GPU architectures
(workstation, data center, and edge) using six large-scale, real-world
scientific datasets from five distinct domains. The results demonstrate that
GPZ consistently and significantly outperforms five state-of-the-art GPU
compressors, delivering up to 8x higher end-to-end throughput while
simultaneously achieving superior compression ratios and data quality.

</details>


### [39] [Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models](https://arxiv.org/abs/2508.10349)
*Tianjun Yuan,Jiaxiang Geng,Pengchao Han,Xianhao Chen,Bing Luo*

Main category: cs.DC

TL;DR: 提出了一种灵活的个性化联邦学习框架FlexP-SFL，用于解决客户端数据有限和异构分布的问题，并通过实验验证其高效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 基础模型的微调对个性化下游任务至关重要，但客户端数据有限和异构分布限制了协作学习的效果。

Method: 提出了FlexP-SFL框架，结合分割学习，允许客户端根据资源限制本地训练部分模型，其余部分由服务器处理，并引入对齐策略优化个性化模型的全局性能。

Result: 实验结果表明FlexP-SFL在个性化微调效率和最终准确性上优于基线模型。

Conclusion: FlexP-SFL为异构客户端提供了一种高效的个性化联邦学习解决方案。

Abstract: Fine-tuning foundation models is critical for superior performance on
personalized downstream tasks, compared to using pre-trained models.
Collaborative learning can leverage local clients' datasets for fine-tuning,
but limited client data and heterogeneous data distributions hinder effective
collaboration. To address the challenge, we propose a flexible personalized
federated learning paradigm that enables clients to engage in collaborative
learning while maintaining personalized objectives. Given the limited and
heterogeneous computational resources available on clients, we introduce
\textbf{flexible personalized split federated learning (FlexP-SFL)}. Based on
split learning, FlexP-SFL allows each client to train a portion of the model
locally while offloading the rest to a server, according to resource
constraints. Additionally, we propose an alignment strategy to improve
personalized model performance on global data. Experimental results show that
FlexP-SFL outperforms baseline models in personalized fine-tuning efficiency
and final accuracy.

</details>


### [40] [Dalek: An Unconventional and Energy-Aware Heterogeneous Cluster](https://arxiv.org/abs/2508.10481)
*Adrien Cassagne,Noé Amiot,Manuel Bouyer*

Main category: cs.DC

TL;DR: Dalek是一个实验性计算集群，旨在评估消费级异构硬件的性能，用于软件设计、原型制作和算法开发。


<details>
  <summary>Details</summary>
Motivation: 与传统依赖昂贵服务器级组件的计算中心不同，Dalek通过整合迷你PC、笔记本电脑和游戏台式机中常见的CPU和GPU，提供了一种经济高效且多功能的平台。

Method: 论文详细介绍了集群的架构和软件堆栈，并通过合成基准测试展示了性能。此外，还引入了一个定制能量监控平台，每秒可提供1000个平均样本，分辨率为毫瓦级。

Result: 高精度的能量监控能力为计算机应用科学中的能量感知研究实验提供了广泛的可能性。

Conclusion: Dalek通过消费级硬件和高效能量监控，为计算机科学研究提供了一种经济且灵活的实验平台。

Abstract: Dalek is an experimental compute cluster designed to evaluate the performance
of heterogeneous, consumer-grade hardware for software design, prototyping, and
algorithm development. In contrast to traditional computing centers that rely
on costly, server-class components, Dalek integrates CPUs and GPUs typically
found in mini-PCs, laptops, and gaming desktops, providing a cost-effective yet
versatile platform. This document details the cluster's architecture and
software stack, and presents results from synthetic benchmarks. Furthermore, it
introduces a custom energy monitoring platform capable of delivering 1000
averaged samples per second with milliwatt-level resolution. This
high-precision monitoring capability enables a wide range of energy-aware
research experiments in applied Computer Science.

</details>


### [41] [Introducing CQ: A C-like API for Quantum Accelerated HPC](https://arxiv.org/abs/2508.10854)
*Oliver Thomson Brown,Mateusz Meller,James Richings*

Main category: cs.DC

TL;DR: 本文介绍了CQ规范及其参考实现CQ-SimBE，旨在将量子计算逐步集成到经典高性能计算中。


<details>
  <summary>Details</summary>
Motivation: 推动量子计算在经典高性能计算中的渐进式集成，支持从C和Fortran等语言运行时卸载量子计算任务。

Method: 提出CQ规范，提供一个C-like API，并结合CQ-SimBE（基于QuEST的C99实现）作为参考实现。

Result: CQ支持严格类型编译语言，提供对经典数据运动的细粒度控制，并支持模拟量子计算。

Conclusion: CQ及其实现开源，为量子计算在经典高性能计算中的应用提供了实验平台。

Abstract: In this paper we present CQ, a specification for a C-like API for quantum
accelerated HPC, as well as CQ-SimBE, a reference implementation of CQ written
in C99, and built on top of the statevector simulator QuEST. CQ focuses on
enabling the incremental integration of quantum computing into classical HPC
codes by supporting runtime offloading from languages such as C and Fortran. It
provides a way of describing and offloading quantum computations which is
compatible with strictly and strongly typed compiled languages, and gives the
programmer fine-grained control over classical data movement. The CQ Simulated
Backend (CQ-SimBE) provides both a way to demonstrate the usage and utility of
CQ, and a space to experiment with new features such as support for analogue
quantum computing. Both the CQ specification and CQ-SimBE are open-source, and
available in public repositories.

</details>


### [42] [Minimmit: Fast Finality with Even Faster Blocks](https://arxiv.org/abs/2508.10862)
*Brendan Kobayashi Chou,Andrew Lewis-Pye,Patrick O'Grady*

Main category: cs.DC

TL;DR: Minimmit是一种新的状态机复制（SMR）协议，通过进一步减少延迟来提高效率，扩展了Alpenglow等协议的'2轮最终性'方法。


<details>
  <summary>Details</summary>
Motivation: 旨在通过允许更快地切换视图来降低SMR协议的延迟。

Method: 扩展了'2轮最终性'方法，提供了伪代码和一致性及活跃性证明。

Result: 初步草案展示了协议的一致性及活跃性，乐观响应性证明和优化实验将在后续版本中提供。

Conclusion: Minimmit协议有望通过更快的视图切换显著降低延迟，进一步版本将完善其验证和性能。

Abstract: Minimmit is a new protocol for State-Machine-Replication (SMR) that extends
the '2-round finality' approach of protocols such as Alpenglow to further
reduce latency, by allowing for faster progression through 'views'. This
preliminary draft provides motivation and pseudocode, together with proofs of
consistency and liveness. An updated draft with a proof of optimistic
responsiveness, suggested optimizations, and experiments, is to follow.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [43] [Privacy-Preserving Approximate Nearest Neighbor Search on High-Dimensional Data](https://arxiv.org/abs/2508.10373)
*Yingfan Liu,Yandi Zhang,Jiadong Xie,Hui Li,Jeffrey Xu Yu,Jiangtao Cui*

Main category: cs.DB

TL;DR: 本文提出了一种新的隐私保护k-最近邻搜索（PP-ANNS）方法，通过单云服务器执行，实现了隐私、效率和准确性的平衡。


<details>
  <summary>Details</summary>
Motivation: 在云计算和AI时代，数据所有者将向量外包给云服务器，但现有PP-ANNS方案难以同时满足隐私、效率、准确性和用户参与度低的要求。

Method: 提出了一种基于距离比较加密的新方法，设计了隐私保护索引，并结合了先进的k-ANNS方法和近似距离计算技术，使用过滤-精炼策略进行搜索。

Result: 实验表明，该方法比现有方法快3个数量级，且不影响准确性。

Conclusion: 该方法显著提升了PP-ANNS的性能和隐私保护能力，适用于实际应用。

Abstract: In the era of cloud computing and AI, data owners outsource ubiquitous
vectors to the cloud, which furnish approximate $k$-nearest neighbors
($k$-ANNS) services to users. To protect data privacy against the untrusted
server, privacy-preserving $k$-ANNS (PP-ANNS) on vectors has been a fundamental
and urgent problem. However, existing PP-ANNS solutions fall short of meeting
the requirements of data privacy, efficiency, accuracy, and minimal user
involvement concurrently. To tackle this challenge, we introduce a novel
solution that primarily executes PP-ANNS on a single cloud server to avoid the
heavy communication overhead between the cloud and the user. To ensure data
privacy, we introduce a novel encryption method named distance comparison
encryption, facilitating secure, efficient, and exact distance comparisons. To
optimize the trade-off between data privacy and search performance, we design a
privacy-preserving index that combines the state-of-the-art $k$-ANNS method
with an approximate distance computation method. Then, we devise a search
method using a filter-and-refine strategy based on the index. Moreover, we
provide the security analysis of our solution and conduct extensive experiments
to demonstrate its superiority over existing solutions. Based on our
experimental results, our method accelerates PP-ANNS by up to 3 orders of
magnitude compared to state-of-the-art methods, while not compromising the
accuracy.

</details>


### [44] [Cross-Organizational Analysis of Parliamentary Processes: A Case Study](https://arxiv.org/abs/2508.10381)
*Paul-Julius Hillmann,Stephan A. Fahrenkrog-Petersen,Jan Mendling*

Main category: cs.DB

TL;DR: 研究了德国州议会的流程挖掘，首次将流程挖掘应用于议会流程，结合政治学与流程挖掘，分析三个州议会的立法流程差异和最佳实践。


<details>
  <summary>Details</summary>
Motivation: 跨组织流程比较研究较少，因企业不愿共享数据；德国州议会数据公开，适合研究同一类流程在不同地区的差异。

Method: 分析了德国三个州议会的立法流程，通过流程挖掘比较差异和最佳实践。

Result: 提供了基于与政治学家和联邦议会专家讨论的相关性结果。

Conclusion: 为政治学与流程挖掘的新领域研究做出了贡献。

Abstract: Process Mining has been widely adopted by businesses and has been shown to
help organizations analyze and optimize their processes. However, so far,
little attention has gone into the cross-organizational comparison of
processes, since many companies are hesitant to share their data. In this
paper, we explore the processes of German state parliaments that are often
legally required to share their data and run the same type of processes for
different geographical regions. This paper is the first attempt to apply
process mining to parliamentary processes and, therefore, contributes toward a
novel interdisciplinary research area that combines political science and
process mining. In our case study, we analyze legislative processes of three
German state parliaments and generate insights into their differences and best
practices. We provide a discussion of the relevance of our results that are
based on knowledge exchange with a political scientist and a domain expert from
the German federal parliament.

</details>


### [45] [Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching](https://arxiv.org/abs/2508.10460)
*Wei Tian,Jieming Shi,Man Lung Yiu*

Main category: cs.DB

TL;DR: 该论文提出了TRMMA和MMA两种方法，分别用于稀疏轨迹的恢复和地图匹配，以提升低采样率轨迹数据的质量。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的轨迹数据通常稀疏且与路网不对齐，而许多应用需要高质量数据。

Method: TRMMA用于轨迹恢复，MMA用于地图匹配，MMA首先将GPS点映射到路网小候选段集，TRMMA再通过双重变换器编码和有效解码技术推断缺失点。

Result: 在四个大型真实数据集上的实验表明，TRMMA和MMA在轨迹恢复和地图匹配方面的效果显著优于现有方法。

Conclusion: TRMMA和MMA方法能高效提升稀疏轨迹数据的质量，为实际应用提供了重要支持。

Abstract: Real-world trajectories are often sparse with low-sampling rates (i.e., long
intervals between consecutive GPS points) and misaligned with road networks,
yet many applications demand high-quality data for optimal performance. To
improve data quality with sparse trajectories as input, we systematically study
two related research problems: trajectory recovery on road network, which aims
to infer missing points to recover high-sampling trajectories, and map
matching, which aims to map GPS points to road segments to determine underlying
routes. In this paper, we present efficient methods TRMMA and MMA for accurate
trajectory recovery and map matching, respectively, where MMA serves as the
first step of TRMMA. In MMA, we carefully formulate a classification task to
map a GPS point from sparse trajectories to a road segment over a small
candidate segment set, rather than the entire road network. We develop
techniques in MMA to generate effective embeddings that capture the patterns of
GPS data, directional information, and road segments, to accurately align
sparse trajectories to routes. For trajectory recovery, TRMMA focuses on the
segments in the route returned by MMA to infer missing points with position
ratios on road segments, producing high-sampling trajectories efficiently by
avoiding evaluation of all road segments. Specifically, in TRMMA, we design a
dual-transformer encoding process to cohesively capture latent patterns in
trajectories and routes, and an effective decoding technique to sequentially
predict the position ratios and road segments of missing points. We conduct
extensive experiments to compare TRMMA and MMA with numerous existing methods
for trajectory recovery and map matching, respectively, on 4 large real-world
datasets. TRMMA and MMA consistently achieve the best result quality, often by
a significant margin.

</details>


### [46] [Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria](https://arxiv.org/abs/2508.10504)
*Zhliang Xiang,Meghyn Bienvenu,Gianluca Cima,Víctor Gutiérrez-Basulto,Yazmín Ibáñez-García*

Main category: cs.DB

TL;DR: ASPEN+扩展了ASPEN系统，新增局部合并功能和新最优性标准，改进实体解析效果。


<details>
  <summary>Details</summary>
Motivation: 解决ASPEN仅支持全局合并的局限，引入局部合并以适应更复杂的实体匹配场景，并提供新的最优性标准。

Method: 扩展ASPEN系统，支持局部合并和新的最优性标准（如最小化规则违反或最大化支持合并的规则数量），并进行了形式化和计算分析。

Result: 在真实数据集上的实验表明，局部合并和新最优性标准显著提高了准确性和运行时效率。

Conclusion: ASPEN+通过引入局部合并和新最优性标准，有效提升了实体解析的灵活性和性能。

Abstract: In this paper, we present ASPEN+, which extends an existing ASP-based system,
ASPEN,for collective entity resolution with two important functionalities:
support for local merges and new optimality criteria for preferred solutions.
Indeed, ASPEN only supports so-called global merges of entity-referring
constants (e.g. author ids), in which all occurrences of matched constants are
treated as equivalent and merged accordingly. However, it has been argued that
when resolving data values, local merges are often more appropriate, as e.g.
some instances of 'J. Lee' may refer to 'Joy Lee', while others should be
matched with 'Jake Lee'. In addition to allowing such local merges, ASPEN+
offers new optimality criteria for selecting solutions, such as minimizing rule
violations or maximising the number of rules supporting a merge. Our main
contributions are thus (1) the formalisation and computational analysis of
various notions of optimal solution, and (2) an extensive experimental
evaluation on real-world datasets, demonstrating the effect of local merges and
the new optimality criteria on both accuracy and runtime.

</details>


### [47] [Emerging Skycube](https://arxiv.org/abs/2508.10516)
*Mickaël Martin Nevot*

Main category: cs.DB

TL;DR: 该论文提出了一种结合多准则决策分析和趋势反转发现的方法，称为Emerging Skycube，用于提取全局最优数据并分析其演化。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前缺乏集成DBMS解决方案来计算Emerging Skycube的问题，以便利用ROLAP分析工具进行多准则决策分析。

Method: 通过结合Skycube和新兴数据立方体，提出两种逐步减少计算量和存储空间的策略：基于Skylines概念格的无损部分物化，以及选择闭合Emerging Skycube或闭合Emerging L-Skycube进行进一步优化。

Result: Emerging Skycube的计算成本显著低于传统新兴数据立方体，同时提供了多准则决策分析所需的多属性支持。

Conclusion: 提出的Emerging Skycube及其优化策略在多准则决策分析中具备高效性和实用性，为大数据分析提供了新的解决方案。

Abstract: Combining multi-criteria decision analysis and trend reversal discovery make
it possible to extract globally optimal, or non-dominated, data in relation to
several criteria, and then to observe their evolution according to a
decision-making property. Thus, we introduce Emerging Skycube, a concept
associating Skycube and emerging datacube. As far as we know, no
DBMS-integrated solution exists to compute an emerging Skycube, and hence
taking advantage of ROLAP analysis tools. An emerging datacube has only one
measure: we propose to use several to comply to multi-criteria decision
analysis constraints which requires multiple attributes. A datacube is
expensive to compute. An emerging datacube is about twice as expensive. On the
other hand, an emerging Skycube is cheaper as the trend reversal is computed
after two Skycube calculations, which considerably reduces the relation volume
in comparison with the initial one. It is possible to save even more computing
time and storage space. To this end, we propose two successive reductions.
First, a Skycube lossless partial materialisation using Skylines concepts
lattice, based on the agree concepts lattice and partitions lattice. Then,
either the closed emerging Skycube for an information-loss reduction, or the
closed emerging L-Skycube for a smaller but lossless reduction.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [48] [DiffAxE: Diffusion-driven Hardware Accelerator Generation and Design Space Exploration](https://arxiv.org/abs/2508.10303)
*Arkapravo Ghosh,Abhishek Moitra,Abhiroop Bhattacharjee,Ruokai Yin,Priyadarshini Panda*

Main category: cs.AR

TL;DR: 该论文提出了一种生成式方法，用于高效探索硬件设计空间，显著提升了速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 由于AI工作负载（如DNN和LLM）的复杂性增加，硬件设计空间变得极为庞大且不规则，传统优化方法速度慢且效果有限。

Method: 将硬件设计建模为基于目标性能的一维图像合成，通过学习非微分且非双射的硬件性能映射来实现高效优化。

Result: 相比贝叶斯优化，生成误差降低0.86%，速度快17000倍；相比GANDSE，误差降低30%，搜索速度仅慢1.83倍。在结构化DSE中，能效延迟积降低9.8%，性能提升6%，搜索速度最高快145.6倍和1312倍。

Conclusion: 该方法在硬件设计空间探索中表现出高效性和优越性，尤其适用于大规模复杂设计空间。

Abstract: Design space exploration (DSE) is critical for developing optimized hardware
architectures, especially for AI workloads such as deep neural networks (DNNs)
and large language models (LLMs), which require specialized acceleration. As
model complexity grows, accelerator design spaces have expanded to O(10^17),
becoming highly irregular, non-convex, and exhibiting many-to-one mappings from
design configurations to performance metrics. This complexity renders direct
inverse derivation infeasible and necessitates heuristic or sampling-based
optimization. Conventional methods - including Bayesian optimization, gradient
descent, reinforcement learning, and genetic algorithms - depend on iterative
sampling, resulting in long runtimes and sensitivity to initialization. Deep
learning-based approaches have reframed DSE as classification using
recommendation models, but remain limited to small-scale (O(10^3)), less
complex design spaces. To overcome these constraints, we propose a generative
approach that models hardware design as 1-D image synthesis conditioned on
target performance, enabling efficient learning of non-differentiable,
non-bijective hardware-performance mappings. Our framework achieves 0.86% lower
generation error than Bayesian optimization with a 17000x speedup, and
outperforms GANDSE with 30% lower error at only 1.83x slower search. We further
extend the method to a structured DSE setting, attaining 9.8% lower
energy-delay product (EDP) and 6% higher performance, with up to 145.6x and
1312x faster search compared to existing optimization methods on O(10^17)
design spaces. For LLM inference, our method achieves 3.37x and 7.75x lower EDP
on a 32nm ASIC and Xilinx Ultrascale+ VPU13 FPGA, respectively, compared to the
state-of-the-art DOSA framework.

</details>


### [49] [AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design](https://arxiv.org/abs/2508.10409)
*Zihao Chen,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Xinyi Yang,Mingjie Zhou,Zhuoyao Du,Xu Yan,Zhouyang Wu,Zhenyu Xu,Jiangli Huang,Li Shang,Xuan Zeng,Fan Yang*

Main category: cs.AR

TL;DR: AnalogSeeker是一个开源的基础语言模型，旨在通过领域知识集成和设计辅助提升模拟电路设计效果。通过领域知识蒸馏和定制化训练方法，模型在AMSBech-TQA基准测试中表现优异，并支持下游任务如运算放大器设计。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计领域数据稀缺且知识复杂，现有模型难以有效辅助设计任务。作者旨在通过构建开源基础模型填补这一空白。

Method: 采用领域知识框架收集高质量语料，并通过多代理框架将非结构化文本蒸馏为细粒度QA数据集。定制了邻域自约束监督微调算法进行模型训练。

Result: AnalogSeeker在AMSBech-TQA基准测试中准确率达85.04%，较原始模型提升15.67%，在下游任务中表现优异。

Conclusion: AnalogSeeker通过领域知识集成和定制化训练方法，显著提升了模拟电路设计的辅助能力，开源模型为研究提供了实用工具。

Abstract: In this paper, we propose AnalogSeeker, an effort toward an open-source
foundation language model for analog circuit design, with the aim of
integrating domain knowledge and giving design assistance. To overcome the
scarcity of data in this field, we employ a corpus collection strategy based on
the domain knowledge framework of analog circuits. High-quality, accessible
textbooks across relevant subfields are systematically curated and cleaned into
a textual domain corpus. To address the complexity of knowledge of analog
circuits, we introduce a granular domain knowledge distillation method. Raw,
unlabeled domain corpus is decomposed into typical, granular learning nodes,
where a multi-agent framework distills implicit knowledge embedded in
unstructured text into question-answer data pairs with detailed reasoning
processes, yielding a fine-grained, learnable dataset for fine-tuning. To
address the unexplored challenges in training analog circuit foundation models,
we explore and share our training methods through both theoretical analysis and
experimental validation. We finally establish a fine-tuning-centric training
paradigm, customizing and implementing a neighborhood self-constrained
supervised fine-tuning algorithm. This approach enhances training outcomes by
constraining the perturbation magnitude between the model's output
distributions before and after training. In practice, we train the
Qwen2.5-32B-Instruct model to obtain AnalogSeeker, which achieves 85.04%
accuracy on AMSBench-TQA, the analog circuit knowledge evaluation benchmark,
with a 15.67% point improvement over the original model and is competitive with
mainstream commercial models. Furthermore, AnalogSeeker also shows
effectiveness in the downstream operational amplifier design task. AnalogSeeker
is open-sourced at https://huggingface.co/analogllm/analogseeker for research
use.

</details>


### [50] [THERMOS: Thermally-Aware Multi-Objective Scheduling of AI Workloads on Heterogeneous Multi-Chiplet PIM Architectures](https://arxiv.org/abs/2508.10691)
*Alish Kanani,Lukas Pfromm,Harsh Sharma,Janardhan Rao Doppa,Partha Pratim Pande,Umit Y. Ogras*

Main category: cs.AR

TL;DR: 提出THERMOS框架，用于异构多芯片PIM架构上的AI工作负载调度，通过多目标强化学习优化执行时间和能耗，性能显著优于基线算法。


<details>
  <summary>Details</summary>
Motivation: 异构芯片PIM架构虽能提升性能和能效，但其复杂的调度挑战需要创新解决方案。

Method: 采用多目标强化学习策略，动态优化执行时间、能耗或平衡目标。

Result: THERMOS比基线算法平均执行时间快89%，能耗低57%，且运行时开销极小。

Conclusion: THERMOS为异构PIM架构提供高效、灵活的调度解决方案，显著提升性能与能效。

Abstract: Chiplet-based integration enables large-scale systems that combine diverse
technologies, enabling higher yield, lower costs, and scalability, making them
well-suited to AI workloads. Processing-in-Memory (PIM) has emerged as a
promising solution for AI inference, leveraging technologies such as ReRAM,
SRAM, and FeFET, each offering unique advantages and trade-offs. A
heterogeneous chiplet-based PIM architecture can harness the complementary
strengths of these technologies to enable higher performance and energy
efficiency. However, scheduling AI workloads across such a heterogeneous system
is challenging due to competing performance objectives, dynamic workload
characteristics, and power and thermal constraints. To address this need, we
propose THERMOS, a thermally-aware, multi-objective scheduling framework for AI
workloads on heterogeneous multi-chiplet PIM architectures. THERMOS trains a
single multi-objective reinforcement learning (MORL) policy that is capable of
achieving Pareto-optimal execution time, energy, or a balanced objective at
runtime, depending on the target preferences. Comprehensive evaluations show
that THERMOS achieves up to 89% faster average execution time and 57% lower
average energy consumption than baseline AI workload scheduling algorithms with
only 0.14% runtime and 0.022% energy overhead.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [A Unified Evaluation Framework for Multi-Annotator Tendency Learning](https://arxiv.org/abs/2508.10393)
*Liyun Zhang,Jingcheng Ke,Shenli Fan,Xuanmeng Sha,Zheng Lian*

Main category: cs.LG

TL;DR: 提出了第一个评估框架，用于衡量个体倾向学习（ITL）方法是否能真实捕捉标注者行为模式及其解释的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有ITL方法缺乏评估其是否能真实捕捉标注者个体倾向并提供行为解释的框架。

Method: 提出两个新指标（DIC和BAE），分别量化模型捕捉标注者倾向的能力和解释与行为的对齐程度。

Result: 大量实验验证了该评估框架的有效性。

Conclusion: 该框架填补了ITL方法评估的空白，并为理解标注者行为提供了新工具。

Abstract: Recent works have emerged in multi-annotator learning that shift focus from
Consensus-oriented Learning (CoL), which aggregates multiple annotations into a
single ground-truth prediction, to Individual Tendency Learning (ITL), which
models annotator-specific labeling behavior patterns (i.e., tendency) to
provide explanation analysis for understanding annotator decisions. However, no
evaluation framework currently exists to assess whether ITL methods truly
capture individual tendencies and provide meaningful behavioral explanations.
To address this gap, we propose the first unified evaluation framework with two
novel metrics: (1) Difference of Inter-annotator Consistency (DIC) quantifies
how well models capture annotator tendencies by comparing predicted
inter-annotator similarity structures with ground-truth; (2) Behavior Alignment
Explainability (BAE) evaluates how well model explanations reflect annotator
behavior and decision relevance by aligning explainability-derived with
ground-truth labeling similarity structures via Multidimensional Scaling (MDS).
Extensive experiments validate the effectiveness of our proposed evaluation
framework.

</details>


### [52] [Constrained Decoding of Diffusion LLMs with Context-Free Grammars](https://arxiv.org/abs/2508.10111)
*Niels Mündler,Jasper Dekoninck,Martin Vechev*

Main category: cs.LG

TL;DR: 提出了一种针对扩散大语言模型的约束解码方法，确保输出符合上下文无关文法，适用于C++代码填充和JSON数据生成等场景，效果显著。


<details>
  <summary>Details</summary>
Motivation: 由于概率性，大语言模型的输出不一定符合形式语言的语法约束，现有方法不适用于新兴的扩散模型，因此需要新方法确保语法正确性。

Method: 将约束解码问题转化为可加性填充问题，进一步归约为判断目标语言与正则语言交集是否为空，并提出了高效算法。

Result: 在C++代码填充和JSON数据生成等任务中，该方法近乎完美地保证了语法正确性，同时保持或提升了功能正确性，计算开销实际可行。

Conclusion: 该方法为扩散模型在形式语言约束下的解码提供了有效解决方案，具有实际应用价值。

Abstract: Large language models (LLMs) have shown promising performance across diverse
domains. Many practical applications of LLMs, such as code completion and
structured data extraction, require adherence to syntactic constraints
specified by a formal language. Yet, due to their probabilistic nature, LLM
output is not guaranteed to adhere to such formal languages. Prior work has
proposed constrained decoding as a means to restrict LLM generation to
particular formal languages. However, existing works are not applicable to the
emerging paradigm of diffusion LLMs, when used in practical scenarios such as
the generation of formally correct C++ or JSON output. In this paper we address
this challenge and present the first constrained decoding method for diffusion
models, one that can handle formal languages captured by context-free grammars.
We begin by reducing constrained decoding to the more general additive
infilling problem, which asks whether a partial output can be completed to a
valid word in the target language. This problem also naturally subsumes the
previously unaddressed multi-region infilling constrained decoding. We then
reduce this problem to the task of deciding whether the intersection of the
target language and a regular language is empty and present an efficient
algorithm to solve it for context-free languages. Empirical results on various
applications, such as C++ code infilling and structured data extraction in
JSON, demonstrate that our method achieves near-perfect syntactic correctness
while consistently preserving or improving functional correctness. Importantly,
our efficiency optimizations ensure that the computational overhead remains
practical.

</details>


### [53] [A Hierarchical IDS for Zero-Day Attack Detection in Internet of Medical Things Networks](https://arxiv.org/abs/2508.10346)
*Md Ashraf Uddin,Nam H. Chu,Reza Rafeh*

Main category: cs.LG

TL;DR: 针对IoMT网络的安全漏洞，提出一种多层IDS框架，能够有效检测零日攻击并区分已知与未知威胁，实验结果显示高准确率和F1分数。


<details>
  <summary>Details</summary>
Motivation: 医疗物联网（IoMT）因其资源受限和异构设备的特性，传统集中式IDS无法适用，亟需一种新的安全解决方案。

Method: 提出一种多层IDS框架：近边缘层使用元学习或OCC算法初步过滤流量，远边缘和云层进一步识别攻击类型和新颖性。

Result: 在CICIoMT2024数据集上实现了99.77%的准确率和97.8%的F1分数，零日攻击检测表现出色。

Conclusion: 该框架在IoMT环境中具备高适用性和安全性，能够有效保护患者健康和数据安全。

Abstract: The Internet of Medical Things (IoMT) is driving a healthcare revolution but
remains vulnerable to cyberattacks such as denial of service, ransomware, data
hijacking, and spoofing. These networks comprise resource constrained,
heterogeneous devices (e.g., wearable sensors, smart pills, implantables),
making traditional centralized Intrusion Detection Systems (IDSs) unsuitable
due to response delays, privacy risks, and added vulnerabilities. Centralized
IDSs require all sensors to transmit data to a central server, causing delays
or network disruptions in dense environments. Running IDSs locally on IoMT
devices is often infeasible due to limited computation, and even lightweight
IDS components remain at risk if updated models are delayed leaving them
exposed to zero-day attacks that threaten patient health and data security. We
propose a multi level IoMT IDS framework capable of detecting zero day attacks
and distinguishing between known and unknown threats. The first layer (near
Edge) filters traffic at a coarse level (attack or not) using meta-learning or
One Class Classification (OCC) with the usfAD algorithm. Subsequent layers (far
Edge, Cloud) identify attack type and novelty. Experiments on the CICIoMT2024
dataset show 99.77 percentage accuracy and 97.8 percentage F1-score. The first
layer detects zero-day attacks with high accuracy without needing new datasets,
ensuring strong applicability in IoMT environments. Additionally, the
meta-learning approach achieves high.

</details>


### [54] [Semantic Communication with Distribution Learning through Sequential Observations](https://arxiv.org/abs/2508.10350)
*Samer Lahoud,Kinda Khawam*

Main category: cs.LG

TL;DR: 本文研究了语义通信中的分布学习问题，提出了在未知先验条件下学习源统计的基本条件，探讨了学习能力与语义性能之间的权衡，并通过实验验证了理论框架。


<details>
  <summary>Details</summary>
Motivation: 语义通信旨在传达意义而非精确比特重现，但传统方法忽略了源统计的学习问题。本文填补了这一空白，研究如何在未知先验条件下学习源分布。

Method: 通过证明学习能力需要有效传输矩阵的满秩性，分析了分布估计的收敛速度，并量化了估计误差如何导致语义失真。

Result: 实验验证了系统条件对学习速率和性能的关键影响，揭示了即时语义性能与长期学习能力之间的权衡。

Conclusion: 本文首次对语义通信中的统计学习进行了严格刻画，为平衡即时性能与适应能力的系统设计提供了原则。

Abstract: Semantic communication aims to convey meaning rather than bit-perfect
reproduction, representing a paradigm shift from traditional communication.
This paper investigates distribution learning in semantic communication where
receivers must infer the underlying meaning distribution through sequential
observations. While semantic communication traditionally optimizes individual
meaning transmission, we establish fundamental conditions for learning source
statistics when priors are unknown. We prove that learnability requires full
rank of the effective transmission matrix, characterize the convergence rate of
distribution estimation, and quantify how estimation errors translate to
semantic distortion. Our analysis reveals a fundamental trade-off: encoding
schemes optimized for immediate semantic performance often sacrifice long-term
learnability. Experiments on CIFAR-10 validate our theoretical framework,
demonstrating that system conditioning critically impacts both learning rate
and achievable performance. These results provide the first rigorous
characterization of statistical learning in semantic communication and offer
design principles for systems that balance immediate performance with
adaptation capability.

</details>


### [55] [EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation](https://arxiv.org/abs/2508.10474)
*Lisa Haxel,Jaivardhan Kapoor,Ulf Ziemann,Jakob H. Macke*

Main category: cs.LG

TL;DR: EDAPT框架通过持续模型适应消除BCI校准需求，提升准确率并减少部署障碍。


<details>
  <summary>Details</summary>
Motivation: 解决BCI因神经信号漂移和用户差异导致的准确率下降问题，减少频繁校准需求。

Method: 结合多用户数据预训练基线解码器，通过在线监督微调持续个性化模型。

Result: 在三个BCI任务的九个数据集中，EDAPT显著优于静态方法，且运行高效。

Conclusion: EDAPT为无校准BCI提供实用方案，降低部署难度。

Abstract: Brain-computer interfaces (BCIs) suffer from accuracy degradation as neural
signals drift over time and vary across users, requiring frequent recalibration
that limits practical deployment. We introduce EDAPT, a task- and
model-agnostic framework that eliminates calibration through continual model
adaptation. EDAPT first trains a baseline decoder using data from multiple
users, then continually personalizes this model via supervised finetuning as
the neural patterns evolve during use. We tested EDAPT across nine datasets
covering three BCI tasks, and found that it consistently improved accuracy over
conventional, static methods. These improvements primarily stem from combining
population-level pretraining and online continual finetuning, with unsupervised
domain adaptation providing further gains on some datasets. EDAPT runs
efficiently, updating models within 200 milliseconds on consumer-grade
hardware. Finally, decoding accuracy scales with total data budget rather than
its allocation between subjects and trials. EDAPT provides a practical pathway
toward calibration-free BCIs, reducing a major barrier to BCI deployment.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [56] [Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry](https://arxiv.org/abs/2508.09991)
*Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji*

Main category: cs.CL

TL;DR: 论文分享了在癌症注册机构实施NLP模型的经验，强调业务目标、迭代开发、跨学科合作及实用模型选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 通过NLP自动化临床文档数据处理，提高医疗效率，但实际部署中面临诸多挑战。

Method: 采用基于业务目标的问题定义、迭代式开发、跨学科合作，并结合混合方法和简单模型。

Result: 提出了实用模型选择、数据质量管理、错误缓解策略和提升组织AI素养等关键经验。

Conclusion: 这些经验可帮助医疗机构成功实施AI/NLP解决方案，改善数据管理及患者护理。

Abstract: Automating data extraction from clinical documents offers significant
potential to improve efficiency in healthcare settings, yet deploying Natural
Language Processing (NLP) solutions presents practical challenges. Drawing upon
our experience implementing various NLP models for information extraction and
classification tasks at the British Columbia Cancer Registry (BCCR), this paper
shares key lessons learned throughout the project lifecycle. We emphasize the
critical importance of defining problems based on clear business objectives
rather than solely technical accuracy, adopting an iterative approach to
development, and fostering deep interdisciplinary collaboration and co-design
involving domain experts, end-users, and ML specialists from inception. Further
insights highlight the need for pragmatic model selection (including hybrid
approaches and simpler methods where appropriate), rigorous attention to data
quality (representativeness, drift, annotation), robust error mitigation
strategies involving human-in-the-loop validation and ongoing audits, and
building organizational AI literacy. These practical considerations,
generalizable beyond cancer registries, provide guidance for healthcare
organizations seeking to successfully implement AI/NLP solutions to enhance
data management processes and ultimately improve patient care and public health
outcomes.

</details>


### [57] [User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents](https://arxiv.org/abs/2508.10004)
*Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo*

Main category: cs.CL

TL;DR: Attention权重在解释AI模型预测时的有效性受到视觉呈现方式的影响，但整体上并未被视为特别有用的解释工具。


<details>
  <summary>Details</summary>
Motivation: 探讨注意力权重是否能作为解释工具帮助医生理解AI系统的预测，并研究不同可视化方式对其效果的影响。

Method: 通过用户研究，让医学专家分类生物医学文献，并评估不同注意力可视化方式的效果。

Result: XLNet模型分类准确，但注意力权重解释性不强；可视化方式显著影响用户感知，更直观的呈现（如文本亮度）更受欢迎。

Conclusion: 注意力权重的解释效果受可视化方式影响，仍需进一步研究其实际用途。

Abstract: The attention mechanism is a core component of the Transformer architecture.
Beyond improving performance, attention has been proposed as a mechanism for
explainability via attention weights, which are associated with input features
(e.g., tokens in a document). In this context, larger attention weights may
imply more relevant features for the model's prediction. In evidence-based
medicine, such explanations could support physicians' understanding and
interaction with AI systems used to categorize biomedical literature. However,
there is still no consensus on whether attention weights provide helpful
explanations. Moreover, little research has explored how visualizing attention
affects its usefulness as an explanation aid. To bridge this gap, we conducted
a user study to evaluate whether attention-based explanations support users in
biomedical document classification and whether there is a preferred way to
visualize them. The study involved medical experts from various disciplines who
classified articles based on study design (e.g., systematic reviews, broad
synthesis, randomized and non-randomized trials). Our findings show that the
Transformer model (XLNet) classified documents accurately; however, the
attention weights were not perceived as particularly helpful for explaining the
predictions. However, this perception varied significantly depending on how
attention was visualized. Contrary to Munzner's principle of visual
effectiveness, which favors precise encodings like bar length, users preferred
more intuitive formats, such as text brightness or background color. While our
results do not confirm the overall utility of attention weights for
explanation, they suggest that their perceived helpfulness is influenced by how
they are visually presented.

</details>


### [58] [PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs](https://arxiv.org/abs/2508.10028)
*Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani*

Main category: cs.CL

TL;DR: PREF是一个个性化评估框架，无需参考标准，通过三步流程评估生成文本的通用质量和用户对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法忽视用户个性化需求，PREF旨在填补这一空白。

Method: 分三步：生成通用指南、个性化重排增强、LLM评分。

Result: 在PrefEval基准测试中表现优于基线，更接近人类判断。

Conclusion: PREF为个性化语言生成系统提供了可扩展且可解释的评估基础。

Abstract: Personalised text generation is essential for user-centric information
systems, yet most evaluation methods overlook the individuality of users. We
introduce \textbf{PREF}, a \textbf{P}ersonalised \textbf{R}eference-free
\textbf{E}valuation \textbf{F}ramework that jointly measures general output
quality and user-specific alignment without requiring gold personalised
references. PREF operates in a three-step pipeline: (1) a coverage stage uses a
large language model (LLM) to generate a comprehensive, query-specific
guideline covering universal criteria such as factuality, coherence, and
completeness; (2) a preference stage re-ranks and selectively augments these
factors using the target user's profile, stated or inferred preferences, and
context, producing a personalised evaluation rubric; and (3) a scoring stage
applies an LLM judge to rate candidate answers against this rubric, ensuring
baseline adequacy while capturing subjective priorities. This separation of
coverage from preference improves robustness, transparency, and reusability,
and allows smaller models to approximate the personalised quality of larger
ones. Experiments on the PrefEval benchmark, including implicit
preference-following tasks, show that PREF achieves higher accuracy, better
calibration, and closer alignment with human judgments than strong baselines.
By enabling scalable, interpretable, and user-aligned evaluation, PREF lays the
groundwork for more reliable assessment and development of personalised
language generation systems.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [59] [A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx](https://arxiv.org/abs/2508.10017)
*Rodrigo Tertulino*

Main category: cs.CR

TL;DR: 该研究通过联邦学习（FL）结合差分隐私（DP）解决医疗数据中的隐私与效用权衡问题，并通过SMOTETomek和优化FedProx算法提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 医疗数据中隐私保护与临床效用的矛盾，以及类别不平衡问题，推动了对联邦学习与差分隐私结合的深入研究。

Method: 采用SMOTETomek技术处理类别不平衡，并通过优化的FedProx算法改进非独立同分布（non-IID）数据的性能。

Result: 实验结果显示，优化的FedProx在隐私预算（epsilon）与召回率之间存在非线性权衡，并在高隐私保护（epsilon 9.0）下实现77%以上的召回率。

Conclusion: 研究为处理真实世界医疗数据提供了一种有效、安全且高精度的诊断工具开发方法。

Abstract: Federated Learning (FL) presents a groundbreaking approach for collaborative
health research, allowing model training on decentralized data while
safeguarding patient privacy. FL offers formal security guarantees when
combined with Differential Privacy (DP). The integration of these technologies,
however, introduces a significant trade-off between privacy and clinical
utility, a challenge further complicated by the severe class imbalance often
present in medical datasets. The research presented herein addresses these
interconnected issues through a systematic, multi-stage analysis. An FL
framework was implemented for cardiovascular risk prediction, where initial
experiments showed that standard methods struggled with imbalanced data,
resulting in a recall of zero. To overcome such a limitation, we first
integrated the hybrid Synthetic Minority Over-sampling Technique with Tomek
Links (SMOTETomek) at the client level, successfully developing a clinically
useful model. Subsequently, the framework was optimized for non-IID data using
a tuned FedProx algorithm. Our final results reveal a clear, non-linear
trade-off between the privacy budget (epsilon) and model recall, with the
optimized FedProx consistently out-performing standard FedAvg. An optimal
operational region was identified on the privacy-utility frontier, where strong
privacy guarantees (with epsilon 9.0) can be achieved while maintaining high
clinical utility (recall greater than 77%). Ultimately, our study provides a
practical methodological blueprint for creating effective, secure, and accurate
diagnostic tools that can be applied to real-world, heterogeneous healthcare
data.

</details>


### [60] [An Architecture for Distributed Digital Identities in the Physical World](https://arxiv.org/abs/2508.10185)
*René Mayrhofer,Michael Roland,Tobias Höller,Philipp Hofer,Mario Lins*

Main category: cs.CR

TL;DR: 论文提出了一种分布式数字身份架构，解决了集中式身份管理的可用性和隐私问题，适用于现实世界交易场景。


<details>
  <summary>Details</summary>
Motivation: 集中式身份管理存在单点故障和隐私风险，需要一种去中心化的解决方案。

Method: 设计了结合传感器、身份权威、属性验证器和新型个人身份代理（PIA）的架构，并通过协议实现安全交易。

Result: 架构和协议在理论上验证了安全性，并通过概念验证实现了可行性。

Conclusion: 分布式数字身份架构在现实应用中具有可行性，尤其适用于容忍几秒延迟的场景。

Abstract: Digital identities are increasingly important for mediating not only digital
but also physical service transactions. Managing such identities through
centralized providers can cause both availability and privacy concerns: single
points of failure and control are ideal targets for global attacks on
technical, organizational, or legal fronts. We design, analyze, and build a
distributed digital identity architecture for physical world transactions in
common scenarios like unlocking doors, public transport, or crossing country
borders. This architecture combines (biometric and other) sensors, (established
and upcoming) identity authorities, attribute verifiers, and a new core
component we call the \emph{Personal Identity Agent (PIA)} that represents
individuals with their identity attributes in the digital domain. All
transactions are conducted in a completely decentralized manner, and the
components for which we currently assume central coordination are optional and
only used for assisting with service discovery and latency reduction. We
present a first protocol between these parties and formally verify that it
achieves relevant security properties based on a realistic threat model
including strong global adversaries. A proof-of-concept implementation
demonstrates practical feasibility of both architecture and initial protocol
for applications that can tolerate end-to-end latencies in the range of a few
seconds.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [61] [zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature](https://arxiv.org/abs/2508.09995)
*Rui Zhou,Haohui Ma,Tianle Xin,Lixin Zou,Qiuyue Hu,Hongxi Cheng,Mingzhi Lin,Jingjing Guo,Sheng Wang,Guoqing Zhang,Yanjie Wei,Liangzhen Zheng*

Main category: q-bio.BM

TL;DR: zERExtractor是一个自动化平台，用于从文献中提取酶催化反应和活性数据，结合了深度学习和大型语言模型（LLM），并在多个任务上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 酶动力学文献的快速扩展超出了主要生物化学数据库的整理能力，阻碍了AI驱动的模型构建和知识发现。

Method: zERExtractor采用模块化架构，结合深度学习、OCR、语义实体识别和LLM模块，同时通过主动学习和专家修正优化提取过程。

Result: 在表格识别、分子图像解释和关系提取任务中，zERExtractor的准确率分别达到89.9%、99.1%和94.2%。

Conclusion: zERExtractor填补了酶动力学数据缺口，为未来的AI驱动酶模型和生物化学知识发现奠定了基础。

Abstract: The rapid expansion of enzyme kinetics literature has outpaced the curation
capabilities of major biochemical databases, creating a substantial barrier to
AI-driven modeling and knowledge discovery. We present zERExtractor, an
automated and extensible platform for comprehensive extraction of
enzyme-catalyzed reaction and activity data from scientific literature.
zERExtractor features a unified, modular architecture that supports
plug-and-play integration of state-of-the-art models, including large language
models (LLMs), as interchangeable components, enabling continuous system
evolution alongside advances in AI. Our pipeline combines domain-adapted deep
learning, advanced OCR, semantic entity recognition, and prompt-driven LLM
modules, together with human expert corrections, to extract kinetic parameters
(e.g., kcat, Km), enzyme sequences, substrate SMILES, experimental conditions,
and molecular diagrams from heterogeneous document formats. Through active
learning strategies integrating AI-assisted annotation, expert validation, and
iterative refinement, the system adapts rapidly to new data sources. We also
release a large benchmark dataset comprising over 1,000 annotated tables and
5,000 biological fields from 270 P450-related enzymology publications.
Benchmarking demonstrates that zERExtractor consistently outperforms existing
baselines in table recognition (Acc 89.9%), molecular image interpretation (up
to 99.1%), and relation extraction (accuracy 94.2%). zERExtractor bridges the
longstanding data gap in enzyme kinetics with a flexible, plugin-ready
framework and high-fidelity extraction, laying the groundwork for future
AI-powered enzyme modeling and biochemical knowledge discovery.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [62] [Molecule Mixture Detection and Alphabet Design for Non-linear, Cross-reactive Receiver Arrays in MC](https://arxiv.org/abs/2508.10856)
*Bastian Heinlein,Kaikai Zhu,Sümeyye Carkit-Yilmaz,Sebastian Lotter,Helene M. Loos,Andrea Buettner,Yansha Deng,Robert Schober,Vahid Jamali*

Main category: eess.SP

TL;DR: 论文提出了一种用于分子混合通信的检测器和字母表设计算法，以解决商用传感器非线性与交叉反应性问题，并通过仿真验证其性能优于不考虑接收器特性的方法。


<details>
  <summary>Details</summary>
Motivation: 现有商用传感器通常表现出非线性和交叉反应行为，而分子通信文献中常假设传感器为线性且分子特异性。本研究旨在填补这一理论与实际的差距。

Method: 提出了一种基于最大似然检测的检测器，用于处理非线性、交叉反应接收器阵列的输出，并设计了一种考虑接收器特性的混合字母表设计算法。

Result: 仿真结果显示，该检测器在符号错误率上与数据驱动方法相当，但无需大量训练样本；字母表设计算法优于不考虑接收器特性的方法。

Conclusion: 所提出的检测器和字母表设计算法不仅适用于其他化学传感器，还为可靠的空气基分子通信开辟了道路。

Abstract: Air-based molecular communication (MC) has the potential to be one of the
first MC systems to be deployed in real-world applications, enabled by existing
sensor technologies such as metal-oxide semi-conductor (MOS) sensors. However,
commercially available sensors usually exhibit non-linear and cross-reactive
behavior, contrary to the idealizing assumptions about linear and perfectly
molecule type-specific sensing often made in the MC literature. To address this
gap, we propose a detector for molecule mixture communication with a general
non-linear, cross-reactive receiver (RX) array that performs approximate
maximum likelihood detection on the sensor outputs. Additionally, we introduce
an algorithm for the design of mixture alphabets that accounts for the RX
characteristics. We evaluate our detector and alphabet design algorithm through
simulations that are based on measurements reported for two commercial MOS
sensors. Our simulations demonstrate that the proposed detector achieves
similar symbol error rates as data-driven methods without requiring large
numbers of training samples and that the alphabet design algorithm outperforms
methods that do not account for the RX characteristics. Since the proposed
detector and alphabet design algorithm are also applicable to other chemical
sensors, they pave the way for reliable air-based MC.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [63] [An Intelligent Infrastructure as a Foundation for Modern Science](https://arxiv.org/abs/2508.10051)
*Satrajit S. Ghosh*

Main category: q-bio.NC

TL;DR: 论文主张利用AI技术构建动态科学基础设施，解决传统科研中的碎片化和不可持续问题，并以神经科学为例提出实施指南。


<details>
  <summary>Details</summary>
Motivation: 传统科研基础设施的低效率和不可持续性阻碍了科学进步，需要利用AI技术构建动态、协作的生态系统。

Method: 结合数据管理、集体利益和数字仓库等现有原则，提出操作指南，推动分散式、自学习和自校正系统的实现。

Result: 动态基础设施可加速科学发现、提高可重复性，促进伦理实践，并为神经科学等领域提供可推广的模板。

Conclusion: 智能基础设施是突破当前科研限制、实现社会效益的关键，需全球协调和多元化投入。

Abstract: Infrastructure shapes societies and scientific discovery. Traditional
scientific infrastructure, often static and fragmented, leads to issues like
data silos, lack of interoperability and reproducibility, and unsustainable
short-lived solutions. Our current technical inability and social reticence to
connect and coordinate scientific research and engineering leads to
inefficiencies and impedes progress. With AI technologies changing how we
interact with the world around us, there is an opportunity to transform
scientific processes. Neuroscience's exponential growth of multimodal and
multiscale data, and urgent clinical relevance demand an infrastructure itself
learns, coordinates, and improves. Using neuroscience as a stress test, this
perspective argues for a paradigm shift: infrastructure must evolve into a
dynamic, AI-aligned ecosystem to accelerate science. Building on several
existing principles for data, collective benefit, and digital repositories, I
recommend operational guidelines for implementing them to create this dynamic
ecosystem, aiming to foster a decentralized, self-learning, and self-correcting
system where humans and AI can collaborate seamlessly. Addressing the chronic
underfunding of scientific infrastructure, acknowledging diverse contributions
beyond publications, and coordinating global efforts are critical steps for
this transformation. By prioritizing an intelligent infrastructure as a central
scientific instrument for knowledge generation, we can overcome current
limitations, accelerate discovery, ensure reproducibility and ethical
practices, and ultimately translate neuroscientific understanding into tangible
societal benefits, setting a blueprint for other scientific domains.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [64] [Approximating Entanglement Based on Abstract Interpretation](https://arxiv.org/abs/2508.10056)
*Aske Nord Raahauge,Martin Bom Marchioro,Rasmus Ross Nylandsted*

Main category: quant-ph

TL;DR: 提出了一种基于抽象解释的静态分析方法，用于近似量子比特的纠缠状态，避免了精确分析的指数级慢速问题。


<details>
  <summary>Details</summary>
Motivation: 由于纠缠是量子系统的基本属性，对于量子程序的优化和算法正确性至关重要，因此需要高效的方法来识别纠缠状态。

Method: 通过扩展现有的抽象解释方法，提出了一种静态分析技术，用于近似纠缠状态的检测。

Result: 该方法被证明是可靠的，并在Standard ML中实现了线性时间复杂度的可扩展性。

Conclusion: 该静态分析方法能够高效近似量子比特的纠缠状态，适用于量子电路的优化和算法验证。

Abstract: Entanglement is a fundamental property of quantum systems, essential for
non-trivial quantum programs. Identifying when qubits become entangled is
critical for circuit optimization, and for arguing for the correctness of
quantum algorithms. This paper presents a static analysis method for
approximating entanglement by extending an already existing abstract
interpretation, thus avoiding the exponential slowdown of an exact analysis.
The approach is shown to be sound and an implementation is provided in Standard
ML with linear-time scalability.

</details>


### [65] [Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse](https://arxiv.org/abs/2508.10590)
*Viswak R Balaji,Samuel Punch*

Main category: quant-ph

TL;DR: 量子计算模拟研究了受Penrose引力诱导坍缩假说启发的质量依赖退相干模型，探讨了质量相关噪声通道在量子计算中的影响。


<details>
  <summary>Details</summary>
Motivation: 研究目标是验证Penrose的客观还原（OR）理论，探索量子叠加态在引力自能差异下的不稳定性及其坍缩时间。

Method: 在Qiskit AerSimulator中实现了一个质量依赖的退相位噪声通道，并将其应用于三个量子计算实验：GHZ态宇称测量、分支质量纠缠测试和Grover搜索。

Result: 实验生成了与恒定噪声不同的坍缩特征，为未来硬件实验提供了基线参考，可用于检验引力诱导效应的存在与否。

Conclusion: 研究为量子计算机作为测试量子力学基本问题的工具提供了可重复的协议和参考框架。

Abstract: We present a quantum computing simulation study of mass-dependent decoherence
models inspired by Penrose's gravity-induced collapse hypothesis. According to
objective reduction (OR) theory, quantum superpositions become unstable when
the gravitational self-energy difference between branches exceeds a certain
threshold, leading to a collapse time $\tau \approx \hbar / E_G$. In this work,
we implement a mass-dependent dephasing noise channel, $p(m) = 1 - e^{-k
m^{\alpha}}$, within the Qiskit AerSimulator, where $m$ is a proxy for the
effective mass of a superposition, mapped to circuit parameters such as the
number of entangled qubits or branch size. We apply this model to three
canonical quantum computing experiments: GHZ state parity measurements,
branch-mass entanglement tests, and Grover's search to generate distinctive
collapse signatures that differ qualitatively from constant-rate dephasing. The
resulting patterns serve as a baseline reference: if future hardware
experiments exhibit the same scaling trends under ideal isolation, this could
indicate a contribution from mass-dependent collapse processes. Conversely,
deviation toward constant-noise behaviour would suggest the absence of such
gravitationally induced effects. Our results provide a reproducible protocol
and reference for using quantum computers as potential testbeds for probing
fundamental questions in quantum mechanics.

</details>


### [66] [Routing and Wavelength Assignment with Minimal Attack Radius for QKD Networks](https://arxiv.org/abs/2508.10613)
*Mengyao Li,Qiaolun Zhang,Zongshuai Yang,Stefano Bregni,Alberto Gatto,Raouf Boutaba,Massimo Tornatore*

Main category: quant-ph

TL;DR: 该论文提出了一种量化物理层攻击最大影响的指标maxNAR，并研究了RWA-MAR问题，通过ILP模型和启发式方法降低攻击影响，同时利用QKP和OB/TR优化网络安全性。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发（QKD）在安全性上表现优异，但易受物理层攻击（如高功率干扰）影响，导致密钥交换中断，因此需要一种方法来量化并最小化此类攻击的影响。

Method: 引入maxNAR指标量化攻击影响，提出RWA-MAR问题，采用ILP模型和启发式算法优化路由和波长分配。通过QKP增强弹性，结合OB和TR优化网络架构，并使用可调参数动态控制偏好。

Result: 仿真结果表明，所提方法在安全性和可扩展性上显著优于基线方法。

Conclusion: 该研究通过量化攻击影响和优化网络架构，有效提升了QKD网络对抗物理层攻击的能力，并通过动态控制适应多样化网络场景。

Abstract: Quantum Key Distribution (QKD) can distribute keys with guaranteed security
but remains susceptible to key exchange interruption due to physical-layer
threats, such as high-power jamming attacks. To address this challenge, we
first introduce a novel metric, namely Maximum Number of Affected Requests
(maxNAR), to quantify the worst-case impact of a single physical-layer attack,
and then we investigate a new problem of Routing and Wavelength Assignment with
Minimal Attack Radius (RWA-MAR). We formulate the problem using an Integer
Linear Programming (ILP) model and propose a scalable heuristic to efficiently
minimize maxNAR. Our approach incorporates key caching through Quantum Key
Pools (QKPs) to enhance resilience and optimize resource utilization. Moreover,
we model the impact of different QKD network architectures, employing Optical
Bypass (OB) for optical switching of quantum channels and Trusted Relay (TR)
for secure key forwarding. Moreover, a tunable parameter is designed in the
heuristic to guide the preference for OB or TR, offering enhanced adaptability
and dynamic control in diverse network scenarios. Simulation results confirm
that our method significantly outperforms the baseline in terms of security and
scalability.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [67] [Puppeteer: Rig and Animate Your 3D Models](https://arxiv.org/abs/2508.10898)
*Chaoyue Song,Xiu Li,Fan Yang,Zhongcong Xu,Jiacheng Wei,Fayao Liu,Jiashi Feng,Guosheng Lin,Jianfeng Zhang*

Main category: cs.CV

TL;DR: Puppeteer框架通过自动骨骼预测、皮肤权重推断和优化动画流程，显著提升了3D模型动画生成的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 解决3D模型中从静态到动态内容转换的瓶颈，减少对专家干预的依赖，提高自动化水平。

Method: 结合自回归变换器预测骨骼结构，基于注意力的架构推断皮肤权重，并通过可微分优化生成动画。

Result: 在多个基准测试中表现优异，骨骼预测和皮肤质量均优于现有技术，支持多样化的3D内容处理。

Conclusion: Puppeteer系统为3D动画生成提供了高效、稳定且高质量的解决方案，适用于多种应用场景。

Abstract: Modern interactive applications increasingly demand dynamic 3D content, yet
the transformation of static 3D models into animated assets constitutes a
significant bottleneck in content creation pipelines. While recent advances in
generative AI have revolutionized static 3D model creation, rigging and
animation continue to depend heavily on expert intervention. We present
Puppeteer, a comprehensive framework that addresses both automatic rigging and
animation for diverse 3D objects. Our system first predicts plausible skeletal
structures via an auto-regressive transformer that introduces a joint-based
tokenization strategy for compact representation and a hierarchical ordering
methodology with stochastic perturbation that enhances bidirectional learning
capabilities. It then infers skinning weights via an attention-based
architecture incorporating topology-aware joint attention that explicitly
encodes inter-joint relationships based on skeletal graph distances. Finally,
we complement these rigging advances with a differentiable optimization-based
animation pipeline that generates stable, high-fidelity animations while being
computationally more efficient than existing approaches. Extensive evaluations
across multiple benchmarks demonstrate that our method significantly
outperforms state-of-the-art techniques in both skeletal prediction accuracy
and skinning quality. The system robustly processes diverse 3D content, ranging
from professionally designed game assets to AI-generated shapes, producing
temporally coherent animations that eliminate the jittering issues common in
existing methods.

</details>


### [68] [Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model](https://arxiv.org/abs/2508.10156)
*Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann*

Main category: cs.CV

TL;DR: 研究表明，结合少量真实图像与大量合成图像可以显著提高西瓜疾病分类模型的性能，验证了混合使用两者的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI模型在农业领域的应用为计算机视觉训练提供了新的可能性，但鲜有研究探讨真实与合成图像结合的有效性。

Method: 研究使用EfficientNetV2-L模型，通过五种不同真实与合成图像比例的数据集（H0-H4）进行训练，评估分类性能。

Result: H2、H3和H4训练的模型表现最佳，F1-score从0.65提升至1.00，显示结合图像显著提升性能。

Conclusion: 合成图像无法完全替代真实图像，混合使用两者才能最大化模型在作物疾病分类中的性能。

Abstract: The current advancements in generative artificial intelligence (GenAI) models
have paved the way for new possibilities for generating high-resolution
synthetic images, thereby offering a promising alternative to traditional image
acquisition for training computer vision models in agriculture. In the context
of crop disease diagnosis, GenAI models are being used to create synthetic
images of various diseases, potentially facilitating model creation and
reducing the dependency on resource-intensive in-field data collection.
However, limited research has been conducted on evaluating the effectiveness of
integrating real with synthetic images to improve disease classification
performance. Therefore, this study aims to investigate whether combining a
limited number of real images with synthetic images can enhance the prediction
accuracy of an EfficientNetV2-L model for classifying watermelon
\textit{(Citrullus lanatus)} diseases. The training dataset was divided into
five treatments: H0 (only real images), H1 (only synthetic images), H2 (1:1
real-to-synthetic), H3 (1:10 real-to-synthetic), and H4 (H3 + random images to
improve variability and model generalization). All treatments were trained
using a custom EfficientNetV2-L architecture with enhanced fine-tuning and
transfer learning techniques. Models trained on H2, H3, and H4 treatments
demonstrated high precision, recall, and F1-score metrics. Additionally, the
weighted F1-score increased from 0.65 (on H0) to 1.00 (on H3-H4) signifying
that the addition of a small number of real images with a considerable volume
of synthetic images improved model performance and generalizability. Overall,
this validates the findings that synthetic images alone cannot adequately
substitute for real images; instead, both must be used in a hybrid manner to
maximize model performance for crop disease classification.

</details>


### [69] [SynSpill: Improved Industrial Spill Detection With Synthetic Data](https://arxiv.org/abs/2508.10171)
*Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas*

Main category: cs.CV

TL;DR: 论文提出了一种针对工业泄漏检测等安全关键领域的合成数据生成框架SynSpill，通过参数高效微调提升视觉语言模型和目标检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 工业泄漏检测等领域的数据稀缺且敏感，传统微调方法难以适用，需要一种高效、低成本的数据解决方案来提升模型性能。

Method: 结合高保真合成数据生成管道和参数高效微调（PEFT）技术，对视觉语言模型（VLM）及YOLO、DETR等目标检测器进行优化。

Result: 在合成数据SynSpill的帮助下，VLM和检测器的性能均显著提升，接近彼此。即使没有合成数据，VLM在未见场景中仍优于检测器。

Conclusion: 高保真合成数据能有效弥合领域差距，结合轻量级适配技术为数据稀缺的工业环境提供了一种经济高效的视觉系统部署方案。

Abstract: Large-scale Vision-Language Models (VLMs) have transformed general-purpose
visual recognition through strong zero-shot capabilities. However, their
performance degrades significantly in niche, safety-critical domains such as
industrial spill detection, where hazardous events are rare, sensitive, and
difficult to annotate. This scarcity -- driven by privacy concerns, data
sensitivity, and the infrequency of real incidents -- renders conventional
fine-tuning of detectors infeasible for most industrial settings.
  We address this challenge by introducing a scalable framework centered on a
high-quality synthetic data generation pipeline. We demonstrate that this
synthetic corpus enables effective Parameter-Efficient Fine-Tuning (PEFT) of
VLMs and substantially boosts the performance of state-of-the-art object
detectors such as YOLO and DETR. Notably, in the absence of synthetic data
(SynSpill dataset), VLMs still generalize better to unseen spill scenarios than
these detectors. When SynSpill is used, both VLMs and detectors achieve marked
improvements, with their performance becoming comparable.
  Our results underscore that high-fidelity synthetic data is a powerful means
to bridge the domain gap in safety-critical applications. The combination of
synthetic generation and lightweight adaptation offers a cost-effective,
scalable pathway for deploying vision systems in industrial environments where
real data is scarce/impractical to obtain.
  Project Page: https://synspill.vercel.app

</details>


### [70] [Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones](https://arxiv.org/abs/2508.10268)
*Yujie Zhao,Jiabei Zeng,Shiguang Shan*

Main category: cs.CV

TL;DR: 提出了一种动态校准策略，通过在用户移动手机时校准注视点估计（PoG），以减少头部姿态变化对估计精度的影响。


<details>
  <summary>Details</summary>
Motivation: 现有基于外观的PoG估计方法因个体差异难以泛化，且校准后的估计器对头部姿态变化敏感，需改进。

Method: 构建MobilePoG基准，分析校准点多样性和头部姿态变化对估计精度的影响；提出动态校准策略。

Result: 实验表明校准时引入更多头部姿态变化可提升估计器对姿态变化的鲁棒性。

Conclusion: 动态校准策略在用户友好性、效率和鲁棒性方面优于传统方法。

Abstract: Although appearance-based point-of-gaze (PoG) estimation has improved, the
estimators still struggle to generalize across individuals due to personal
differences. Therefore, person-specific calibration is required for accurate
PoG estimation. However, calibrated PoG estimators are often sensitive to head
pose variations. To address this, we investigate the key factors influencing
calibrated estimators and explore pose-robust calibration strategies.
Specifically, we first construct a benchmark, MobilePoG, which includes facial
images from 32 individuals focusing on designated points under either fixed or
continuously changing head poses. Using this benchmark, we systematically
analyze how the diversity of calibration points and head poses influences
estimation accuracy. Our experiments show that introducing a wider range of
head poses during calibration improves the estimator's ability to handle pose
variation. Building on this insight, we propose a dynamic calibration strategy
in which users fixate on calibration points while moving their phones. This
strategy naturally introduces head pose variation during a user-friendly and
efficient calibration process, ultimately producing a better calibrated PoG
estimator that is less sensitive to head pose variations than those using
conventional calibration strategies. Codes and datasets are available at our
project page.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [71] [Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices](https://arxiv.org/abs/2508.10071)
*Jay L. Cunningham,Kevin Zhongyang Shao,Rock Yuren Pang,Nathaniel Mengist*

Main category: cs.CY

TL;DR: 该论文研究了NLP从业者对数据公平性的认知及应对挑战的方式，强调了结构性治理改革的重要性。


<details>
  <summary>Details</summary>
Motivation: 了解NLP从业者在数据公平性方面的实际体验和挑战，以推动更公平的AI发展。

Method: 通过2024年的问卷调查和焦点小组，分析美国NLP数据从业者对公平性的理解及应对约束的方式。

Result: 研究发现商业目标与公平承诺之间存在持续紧张关系，同时从业者呼吁更具参与性和问责性的数据流程。

Conclusion: 提升NLP公平性需通过支持从业者能动性和社区同意的结构性治理改革。

Abstract: While research has focused on surfacing and auditing algorithmic bias to
ensure equitable AI development, less is known about how NLP practitioners -
those directly involved in dataset development, annotation, and deployment -
perceive and navigate issues of NLP data equity. This study is among the first
to center practitioners' perspectives, linking their experiences to a
multi-scalar AI governance framework and advancing participatory
recommendations that bridge technical, policy, and community domains. Drawing
on a 2024 questionnaire and focus group, we examine how U.S.-based NLP data
practitioners conceptualize fairness, contend with organizational and systemic
constraints, and engage emerging governance efforts such as the U.S. AI Bill of
Rights. Findings reveal persistent tensions between commercial objectives and
equity commitments, alongside calls for more participatory and accountable data
workflows. We critically engage debates on data diversity and diversity
washing, arguing that improving NLP equity requires structural governance
reforms that support practitioner agency and community consent.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [72] [Why Cannot Large Language Models Ever Make True Correct Reasoning?](https://arxiv.org/abs/2508.10265)
*Jingde Cheng*

Main category: cs.AI

TL;DR: 论文认为大型语言模型（LLMs）的“理解能力”和“推理能力”是虚幻的，并解释了其工作原理的局限性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否真的具备理解和推理能力，反驳当前部分人对这些能力的过高评价。

Method: 通过分析LLMs的工作本质和局限，论证其无法实现真正的正确推理。

Result: 论文得出结论，LLMs因其工作原理的限制，无法具备真正的理解与推理能力。

Conclusion: LLMs的能力是有限的，不应被夸大其理解和推理能力。

Abstract: Recently, with the application progress of AIGC tools based on large language
models (LLMs), led by ChatGPT, many AI experts and more non-professionals are
trumpeting the "understanding ability" and "reasoning ability" of the LLMs. The
present author considers that the so-called "understanding ability" and
"reasoning ability" of LLMs are just illusions of those people who with vague
concepts. In fact, the LLMs can never have the true understanding ability and
true reasoning ability. This paper intents to explain that, because the
essential limitations of their working principle, the LLMs can never have the
ability of true correct reasoning.

</details>


### [73] [Agentic Design Review System](https://arxiv.org/abs/2508.10745)
*Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种多智能体协作的图形设计评估系统（AgenticDRS），通过图匹配和提示扩展方法提升评估效果，并引入了DRS-BENCH基准进行验证。


<details>
  <summary>Details</summary>
Motivation: 图形设计的评估需要从多个角度出发，而现有方法缺乏系统性，希望通过AgenticDRS实现更全面的评估。

Method: 采用多智能体协作框架，由一个元智能体协调多个子智能体，结合图匹配和提示扩展技术增强设计感知能力。

Result: 实验证明AgenticDRS在图形设计评估和反馈生成方面优于现有基线方法。

Conclusion: 本研究为图形设计评估提供了一个高效的系统，并呼吁进一步探索这一实用研究方向。

Abstract: Evaluating graphic designs involves assessing it from multiple facets like
alignment, composition, aesthetics and color choices. Evaluating designs in a
holistic way involves aggregating feedback from individual expert reviewers.
Towards this, we propose an Agentic Design Review System (AgenticDRS), where
multiple agents collaboratively analyze a design, orchestrated by a meta-agent.
A novel in-context exemplar selection approach based on graph matching and a
unique prompt expansion method plays central role towards making each agent
design aware. Towards evaluating this framework, we propose DRS-BENCH
benchmark. Thorough experimental evaluation against state-of-the-art baselines
adapted to the problem setup, backed-up with critical ablation experiments
brings out the efficacy of Agentic-DRS in evaluating graphic designs and
generating actionable feedback. We hope that this work will attract attention
to this pragmatic, yet under-explored research direction.

</details>


### [74] [Modeling Human Responses to Multimodal AI Content](https://arxiv.org/abs/2508.10769)
*Zhiqi Shen,Shaojing Fan,Danni Xu,Terence Sim,Mohan Kankanhalli*

Main category: cs.AI

TL;DR: 该论文研究了AI生成内容对人类行为和认知的影响，提出了新的评估指标和工具（MhAIM数据集和T-Lens系统）来量化和分析人类对在线内容的反应，并提供了减轻AI驱动虚假信息风险的实用策略。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的普及，虚假信息的风险也随之增长。此前的研究主要关注内容的真实性，但对AI内容如何影响人类感知和行为的研究较少。特别是在股票市场等领域，预测人类反应比验证内容的准确性更重要。

Method: 论文采用以人为中心的方法，引入了包含154,552个在线帖子（其中111,153个为AI生成）的MhAIM数据集，以分析人类对AI生成内容的反应。通过人类研究，作者提出了三个新指标（可信度、影响力和开放性），并开发了T-Lens系统（基于LLM的代理系统），核心是HR-MCP协议，用于预测和整合人类对多模态信息的反应。

Result: 研究发现，当帖子同时包含文本和视觉内容（尤其是两者不一致时），人们更容易识别AI生成内容。T-Lens系统通过HR-MCP协议成功增强了LLM对人类反应的预测能力，提高了可解释性和交互能力。

Conclusion: 研究为LLM提供了人类意识能力，揭示了AI、人类认知和信息接收之间的复杂关系，并提出了减轻AI驱动虚假信息风险的实用策略。

Abstract: As AI-generated content becomes widespread, so does the risk of
misinformation. While prior research has primarily focused on identifying
whether content is authentic, much less is known about how such content
influences human perception and behavior. In domains like trading or the stock
market, predicting how people react (e.g., whether a news post will go viral),
can be more critical than verifying its factual accuracy. To address this, we
take a human-centered approach and introduce the MhAIM Dataset, which contains
154,552 online posts (111,153 of them AI-generated), enabling large-scale
analysis of how people respond to AI-generated content. Our human study reveals
that people are better at identifying AI content when posts include both text
and visuals, particularly when inconsistencies exist between the two. We
propose three new metrics: trustworthiness, impact, and openness, to quantify
how users judge and engage with online content. We present T-Lens, an LLM-based
agent system designed to answer user queries by incorporating predicted human
responses to multimodal information. At its core is HR-MCP (Human Response
Model Context Protocol), built on the standardized Model Context Protocol
(MCP), enabling seamless integration with any LLM. This integration allows
T-Lens to better align with human reactions, enhancing both interpretability
and interaction capabilities. Our work provides empirical insights and
practical tools to equip LLMs with human-awareness capabilities. By
highlighting the complex interplay among AI, human cognition, and information
reception, our findings suggest actionable strategies for mitigating the risks
of AI-driven misinformation.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [75] [Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech](https://arxiv.org/abs/2508.10332)
*Abhijit Sinha,Harishankar Kumar,Mohit Joshi,Hemant Kumar Kathania,Shrikanth Narayanan,Sudarsana Reddy Kadiri*

Main category: eess.AS

TL;DR: 分析了Wav2Vec2模型在儿童语音中对年龄和性别分类的表现，发现浅层更适合捕捉说话者特征，PCA可进一步提升分类效果。


<details>
  <summary>Details</summary>
Motivation: 探索自监督学习模型在儿童语音中对说话者特征的编码能力，以改进儿童语音界面的适应性。

Method: 对四种Wav2Vec2变体进行分层分析，使用PFSTAR和CMU Kids数据集，并应用PCA减少冗余。

Result: Wav2Vec2-large-lv60在CMU Kids上年龄和性别分类准确率达97.14%和98.20%，在PFSTAR上为86.05%-95.00%。

Conclusion: 浅层更适合儿童语音特征提取，为儿童语音界面的优化提供了方向。

Abstract: Children's speech presents challenges for age and gender classification due
to high variability in pitch, articulation, and developmental traits. While
self-supervised learning (SSL) models perform well on adult speech tasks, their
ability to encode speaker traits in children remains underexplored. This paper
presents a detailed layer-wise analysis of four Wav2Vec2 variants using the
PFSTAR and CMU Kids datasets. Results show that early layers (1-7) capture
speaker-specific cues more effectively than deeper layers, which increasingly
focus on linguistic information. Applying PCA further improves classification,
reducing redundancy and highlighting the most informative components. The
Wav2Vec2-large-lv60 model achieves 97.14% (age) and 98.20% (gender) on CMU
Kids; base-100h and large-lv60 models reach 86.05% and 95.00% on PFSTAR. These
results reveal how speaker traits are structured across SSL model depth and
support more targeted, adaptive strategies for child-aware speech interfaces.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [76] [The phi-Process: Operator-Algebraic Embeddings of Possibilities, Transfinite Stabilization, and a Quantitative Application to Sensory Depletion](https://arxiv.org/abs/2508.10650)
*Bugra Kilictas,Faruk Alpay*

Main category: math.FA

TL;DR: 本文形式化了一个超限Phi过程，证明了多个定理并应用于感官耗竭模型。


<details>
  <summary>Details</summary>
Motivation: 研究如何在结构化状态空间（如巴拿赫空间、希尔伯特空间）中处理可能性嵌入操作。

Method: 通过确定化引理、序数稳定定理和Riesz投影定理，分析Phi过程的性质。

Result: 建立了提升映射的组合性定律，并应用于感官耗竭的定量模型。

Conclusion: 本文提供了理论框架和实际应用，展示了Phi过程的广泛适用性。

Abstract: We formalize a transfinite Phi process that treats all possibility embeddings
as operators on structured state spaces including complete lattices, Banach and
Hilbert spaces, and orthomodular lattices. We prove a determinization lemma
showing that lifting to sets or distributions yields a deterministic global
dynamic, an ordinal stabilization theorem sending operator transforms to the
fixed subspace by stage omega under normal spectral contraction, and a product
of Riesz projections theorem for commuting layers. We establish a
compositionality law for lifted maps, show closure of Phi packings, and present
a quantitative application to sensory depletion that models tissue removal as a
projection and derives strict decreases in the attainable fixed point under
minimal monotonicity and positivity assumptions. We also state measurable
conditions for probabilistic lifts, give explicit non normal and non commuting
counterexamples, and provide finite dimensional and stochastic witnesses
together with per theorem scope tables and a small reproducible code appendix.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [77] [Enabling Generic Robot Skill Implementation Using Object Oriented Programming](https://arxiv.org/abs/2508.10497)
*Abdullah Farrukh,Achim Wagner,Martin Ruskowski*

Main category: cs.RO

TL;DR: 开发了一个简化机器人系统接口的软件框架，旨在减少部署机器人系统的工作量。


<details>
  <summary>Details</summary>
Motivation: 中小企业和研究人员在缺乏机器人专业知识的情况下，难以实现和维护机器人系统，且依赖外部集成商会导致供应商锁定。

Method: 提出一个抽象层框架，统一不同厂商和型号的机器人接口，并用Python实现原型。

Result: 原型系统成功应用于包含Yaskawa Motoman GP4的bin-picking单元。

Conclusion: 该框架有效降低了机器人系统的部署复杂度，适用于智能制造和研究场景。

Abstract: Developing robotic algorithms and integrating a robotic subsystem into a
larger system can be a difficult task. Particularly in small and medium-sized
enterprises (SMEs) where robotics expertise is lacking, implementing,
maintaining and developing robotic systems can be a challenge. As a result,
many companies rely on external expertise through system integrators, which, in
some cases, can lead to vendor lock-in and external dependency. In the academic
research on intelligent manufacturing systems, robots play a critical role in
the design of robust autonomous systems. Similar challenges are faced by
researchers who want to use robotic systems as a component in a larger smart
system, without having to deal with the complexity and vastness of the robot
interfaces in detail. In this paper, we propose a software framework that
reduces the effort required to deploy a working robotic system. The focus is
solely on providing a concept for simplifying the different interfaces of a
modern robot system and using an abstraction layer for different manufacturers
and models. The Python programming language is used to implement a prototype of
the concept. The target system is a bin-picking cell containing a Yaskawa
Motoman GP4.

</details>


### [78] [Why Report Failed Interactions With Robots?! Towards Vignette-based Interaction Quality](https://arxiv.org/abs/2508.10603)
*Agnes Axelsson,Merle Reimann,Ronald Cumbal,Hannah Pelikan,Divesh Lala*

Main category: cs.RO

TL;DR: 建议使用民族志小品（ethnographic vignettes）来突出人机交互（HRI）中的常见但鲜有记录的问题，以多学科视角促进透明度和行为记录。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs提升了人机交互质量，但与人类交互相比仍存在不足，且问题的性质和严重性因情境而异，难以泛化。

Method: 提出并描述民族志小品的方法论，基于个人在HRI系统中的失败经验创建小品。

Result: 小品能多视角展示问题，促进透明度，并记录研究中常被忽略的意外行为。

Conclusion: 建议将小品作为现有交互评估方法的补充工具。

Abstract: Although the quality of human-robot interactions has improved with the advent
of LLMs, there are still various factors that cause systems to be sub-optimal
when compared to human-human interactions. The nature and criticality of
failures are often dependent on the context of the interaction and so cannot be
generalized across the wide range of scenarios and experiments which have been
implemented in HRI research. In this work we propose the use of a technique
overlooked in the field of HRI, ethnographic vignettes, to clearly highlight
these failures, particularly those that are rarely documented. We describe the
methodology behind the process of writing vignettes and create our own based on
our personal experiences with failures in HRI systems. We emphasize the
strength of vignettes as the ability to communicate failures from a
multi-disciplinary perspective, promote transparency about the capabilities of
robots, and document unexpected behaviours which would otherwise be omitted
from research reports. We encourage the use of vignettes to augment existing
interaction evaluation methods.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [79] [DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality](https://arxiv.org/abs/2508.10605)
*Xinyi Wang,Angeliki Katsenou,David Bull*

Main category: eess.IV

TL;DR: 论文提出了一种基于帧间变化驱动的时空碎片化的无参考视频质量评估（NR-VQA）模型，通过多层级分析帧、块和碎片帧，结合全局和局部信息，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 用户生成视频内容（UGC）的快速增长引发了对无参考视频质量评估的需求，尤其是在社交媒体和流媒体应用中，无参考质量评估是关键。

Method: 提出了一种基于帧间变化的时空碎片化模型，通过分析帧、块和碎片帧的多层级质量敏感区域，结合2D和3D特征捕捉时空变化。

Result: 在五个UGC数据集上的实验表明，该方法在平均秩相关性上排名前二（DIVA-VQA-L: 0.898和DIVA-VQA-B: 0.886），且运行复杂度低。

Conclusion: 该模型在性能和效率上均优于现有方法，代码和模型已公开。

Abstract: The rapid growth of user-generated (video) content (UGC) has driven increased
demand for research on no-reference (NR) perceptual video quality assessment
(VQA). NR-VQA is a key component for large-scale video quality monitoring in
social media and streaming applications where a pristine reference is not
available. This paper proposes a novel NR-VQA model based on spatio-temporal
fragmentation driven by inter-frame variations. By leveraging these inter-frame
differences, the model progressively analyses quality-sensitive regions at
multiple levels: frames, patches, and fragmented frames. It integrates frames,
fragmented residuals, and fragmented frames aligned with residuals to
effectively capture global and local information. The model extracts both 2D
and 3D features in order to characterize these spatio-temporal variations.
Experiments conducted on five UGC datasets and against state-of-the-art models
ranked our proposed method among the top 2 in terms of average rank correlation
(DIVA-VQA-L: 0.898 and DIVA-VQA-B: 0.886). The improved performance is offered
at a low runtime complexity, with DIVA-VQA-B ranked top and DIVA-VQA-L third on
average compared to the fastest existing NR-VQA method. Code and models are
publicly available at: https://github.com/xinyiW915/DIVA-VQA.

</details>
