{"id": "2506.22561", "pdf": "https://arxiv.org/pdf/2506.22561", "abs": "https://arxiv.org/abs/2506.22561", "authors": ["Clotilde Bizière", "Thibault Hilaire", "Jérôme Leroux", "Grégoire Sutre"], "title": "On the Reachability Problem for Two-Dimensional Branching VASS", "categories": ["cs.LO", "cs.FL"], "comment": "Full version of the paper with the same title and authors to appear\n  in the proceedings of MFCS 2025", "summary": "Vectors addition systems with states (VASS), or equivalently Petri nets, are\narguably one of the most studied formalisms for the modeling and analysis of\nconcurrent systems. A central decision problem for VASS is reachability:\nwhether there exists a run from an initial configuration to a final one. This\nproblem has been known to be decidable for over forty years, and its complexity\nhas recently been precisely characterized. Our work concerns the reachability\nproblem for BVASS, a branching generalization of VASS. In dimension one, the\nexact complexity of this problem is known. In this paper, we prove that the\nreachability problem for 2-dimensional BVASS is decidable. In fact, we even\nshow that the reachability set admits a computable semilinear presentation. The\ndecidability status of the reachability problem for BVASS remains open in\nhigher dimensions."}
{"id": "2506.22584", "pdf": "https://arxiv.org/pdf/2506.22584", "abs": "https://arxiv.org/abs/2506.22584", "authors": ["Marek Dančo", "Petra Hozzová", "Mikoláš Janota"], "title": "From MBQI to Enumerative Instantiation and Back", "categories": ["cs.LO"], "comment": "SMT 2025 early presubmission", "summary": "This work investigates the relation between model-based quantifier\ninstantiation (MBQI) and enumerative instantiation (EI) in Satisfiability\nModulo Theories (SMT). MBQI operates at the semantic level and guarantees to\nfind a counterexample to a given a non-model. However, it may lead to weak\ninstantiations. In contrast, EI strives for completeness by systematically\nenumerating terms at the syntactic level. However, such terms may not be\ncounter-examples. Here we investigate the relation between the two techniques\nand report on our initial experiments of the proposed algorithm that combines\nthe two."}
{"id": "2506.22687", "pdf": "https://arxiv.org/pdf/2506.22687", "abs": "https://arxiv.org/abs/2506.22687", "authors": ["Damian Arellanes"], "title": "Compositional Control-Driven Boolean Circuits", "categories": ["cs.LO"], "comment": null, "summary": "Boolean circuits abstract away from physical details to focus on the logical\nstructure and computational behaviour of digital components. Despite they have\nbeen studied for many decades, compositionality has been widely ignored or\nexamined in an informal manner, which is a property for combining circuits\nwithout delving into their internal structure, while supporting modularity and\nformal reasoning. In this paper, we address this longstanding theoretical gap\nby proposing colimit-based operators for compositional circuit construction. We\ndefine separate operators for forming sequential, parallel, branchial and\niterative circuits. As composites encapsulate explicit control flow, a new\nmodel of computation emerges which we refer to as (families of) control-driven\nBoolean circuits. We show how this model is at least as powerful as its\nclassical counterpart. In other words, it is able to non-uniformly compute any\nBoolean function on inputs of arbitrary length."}
{"id": "2506.22735", "pdf": "https://arxiv.org/pdf/2506.22735", "abs": "https://arxiv.org/abs/2506.22735", "authors": ["Willem Conradie", "Krishna Manoorkar", "Alessandra Palmigiano", "Apostolos Tzimoulis", "Nachoem Wijnberg"], "title": "Questions as cognitive filters", "categories": ["cs.LO"], "comment": null, "summary": "In this paper, we develop a logico-algebraic framework for modeling\ndecision-making through deliberation in multi-agent settings. The central\nconcept in this framework is that of interrogative agendas, which represent the\ncognitive stances of agents regarding which features should be considered\nrelevant in the final decision. We formalize an agent's interrogative agenda as\nan equivalence relation that identifies outcomes differing only in aspects the\nagent deems irrelevant. Moreover, we characterize the sublattices of the\nresulting lattice that correspond to relevant interrogative agendas for\ndeliberation scenarios governed by different ``winning rules.\" We then\nintroduce a two-sorted logico-algebraic structure-comprising the lattice of\nrelevant interrogative agendas and the Boolean algebras of agent coalitions-to\nmodel the interaction between agents and agendas during deliberation. Finally,\nwe discuss which interaction conditions can and cannot be defined within this\nframework."}
{"id": "2506.22799", "pdf": "https://arxiv.org/pdf/2506.22799", "abs": "https://arxiv.org/abs/2506.22799", "authors": ["Minchao Jiang", "Shunyu Jia", "Jiaming Gu", "Xiaoyuan Lu", "Guangming Zhu", "Anqi Dong", "Liang Zhang"], "title": "VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time\nrendering for novel view synthesis of 3D scenes. However, existing methods\nfocus primarily on geometric and appearance modeling, lacking deeper scene\nunderstanding while also incurring high training costs that complicate the\noriginally streamlined differentiable rendering pipeline. To this end, we\npropose VoteSplat, a novel 3D scene understanding framework that integrates\nHough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized\nfor instance segmentation, extracting objects, and generating 2D vote maps. We\nthen embed spatial offset vectors into Gaussian primitives. These offsets\nconstruct 3D spatial votes by associating them with 2D image votes, while depth\ndistortion constraints refine localization along the depth axis. For\nopen-vocabulary object localization, VoteSplat maps 2D image semantics to 3D\npoint clouds via voting points, reducing training costs associated with\nhigh-dimensional CLIP features while preserving semantic unambiguity. Extensive\nexperiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D\ninstance localization, 3D point cloud understanding, click-based 3D object\nlocalization, hierarchical segmentation, and ablation studies. Our code is\navailable at https://sy-ja.github.io/votesplat/"}
{"id": "2506.22656", "pdf": "https://arxiv.org/pdf/2506.22656", "abs": "https://arxiv.org/abs/2506.22656", "authors": ["Jiangping Huang", "Dongming Jin", "Weisong Sun", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision", "categories": ["cs.SE", "cs.AI", "68-04", "D.2.3; I.2.7"], "comment": null, "summary": "This paper envisions a knowledge-guided multi-agent framework named KGMAF for\nautomated requirements development. KGMAF aims to address gaps in current\nautomation systems for SE, which prioritize code development and overlook the\ncomplexities of requirements tasks. KGMAF is composed of six specialized agents\nand an artifact pool to improve efficiency and accuracy. Specifically, KGMAF\noutlines the functionality, actions, and knowledge of each agent and provides\nthe conceptual design of the artifact pool. Our case study highlights the\npotential of KGMAF in real-world scenarios. Finally, we outline several\nresearch opportunities for implementing and enhancing automated requirements\ndevelopment using multi-agent systems. We believe that KGMAF will play a\npivotal role in shaping the future of automated requirements development in the\nera of LLMs."}
{"id": "2506.22632", "pdf": "https://arxiv.org/pdf/2506.22632", "abs": "https://arxiv.org/abs/2506.22632", "authors": ["Boming Kong", "Zhizhou Zhang", "Jonathan Balkind"], "title": "Using SBPF to Accelerate Kernel Memory Access From Userspace", "categories": ["cs.OS"], "comment": null, "summary": "The cost of communication between the operating system kernel and user\napplications has long blocked improvements in software performance.\nTraditionally, operating systems encourage software developers to use the\nsystem call interface to transfer (or initiate transfer of) data between user\napplications and the kernel. This approach not only hurts performance at the\nsoftware level due to memory copies between user space address spaces and\nkernel space address spaces, it also hurts system performance at the\nmicroarchitectural level by flushing processor pipelines and other\nmicroarchitectural state.\n  In this paper, we propose a new communication interface between user\napplications and the kernel by setting up a shared memory region between user\nspace applications and the kernel's address space. We acknowledge the danger in\nbreaking the golden law of user-kernel address space isolation, so we coupled a\nuBPF VM (user-space BPF Virtual Machine) with shared memory to control access\nto the kernel's memory from the user's application. In this case, user-space\nprograms can access the shared memory under the supervision of the uBPF VM (and\nthe kernel's blessing of its shared library) to gain non-blocking data transfer\nto and from the kernel's memory space. We test our implementation in several\nuse cases and find this mechanism can bring speedups over traditional\nuser-kernel information passing mechanisms."}
{"id": "2506.23484", "pdf": "https://arxiv.org/pdf/2506.23484", "abs": "https://arxiv.org/abs/2506.23484", "authors": ["Yuzhuo Chen", "Zehua Ma", "Han Fang", "Weiming Zhang", "Nenghai Yu"], "title": "TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity", "categories": ["cs.MM", "cs.CV", "eess.IV", "I.3.3; I.4.9"], "comment": "Accepted by ICCV 2025 (2025 IEEE/CVF International Conference on\n  Computer Vision)", "summary": "AI-generated content (AIGC) enables efficient visual creation but raises\ncopyright and authenticity risks. As a common technique for integrity\nverification and source tracing, digital image watermarking is regarded as a\npotential solution to above issues. Among these, watermarking methods capable\nof preserving the generation quality are receiving increased attention.\nHowever, the proliferation and high performance of generative image editing\napplications have elevated the risks of malicious tampering, creating new\ndemands. 1) The tamper robustness of current lossless visual quality watermarks\nremains constrained by the modification-sensitive diffusion inversion process,\nnecessitating enhanced robustness. 2) The improved tampering quality and rapid\niteration cycles render passive tampering detection methods inadequate, making\nproactive tampering localization capability a desired feature for watermarks.\nTo address these requirements, this paper proposes a Tamper-Aware Generative\nimage WaterMarking method named TAG-WM. The proposed method comprises four key\nmodules: a dual-mark joint sampling (DMJS) algorithm for embedding copyright\nand localization watermarks into the latent space while preserving generative\nquality, the watermark latent reconstruction (WLR) utilizing reversed DMJS, a\ndense variation region detector (DVRD) leveraging diffusion inversion\nsensitivity to identify tampered areas via statistical deviation analysis, and\nthe tamper-aware decoding (TAD) guided by localization results. The\nexperimental results indicate that TAG-WM achieves SOTA tampering robustness\nand tampering localization capability with distortions while maintaining\nlossless generation quality and a considerable capacity of 256 bits."}
{"id": "2506.22464", "pdf": "https://arxiv.org/pdf/2506.22464", "abs": "https://arxiv.org/abs/2506.22464", "authors": ["Hitesh Mohapatra"], "title": "Golden Ratio Assisted Localization for Wireless Sensor Network", "categories": ["cs.NI", "cs.HC", "B.4"], "comment": "6", "summary": "This paper presents a novel localization algorithm for wireless sensor\nnetworks (WSNs) called Golden Ratio Localization (GRL), which leverages the\nmathematical properties of the golden ratio (phi 1.618) to optimize both node\nplacement and communication range. GRL introduces phi-based anchor node\ndeployment and hop-sensitive weighting using phi-exponents to improve\nlocalization accuracy while minimizing energy consumption. Through extensive\nsimulations conducted on a 100 m * 100 m sensor field with 100 nodes and 10\nanchors, GRL achieved an average localization error of 2.35 meters,\noutperforming DV- Hop (3.87 meters) and Centroid (4.95 meters). In terms of\nenergy efficiency, GRL reduced localization energy consumption to 1.12 microJ\nper node, compared to 1.78 microJ for DV-Hop and 1.45 microJ for Centroid.\nThese results confirm that GRL provides a more balanced and efficient\nlocalization approach, making it especially suitable for energy-constrained and\nlarge-scale WSN deployments."}
{"id": "2506.23058", "pdf": "https://arxiv.org/pdf/2506.23058", "abs": "https://arxiv.org/abs/2506.23058", "authors": ["Nikolaj Hey Hinnerskov", "Robert Schenck", "Cosmin E. Oancea"], "title": "Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language", "categories": ["cs.PL", "cs.DC"], "comment": null, "summary": "This paper presents a novel approach to automatically verify properties of\npure data-parallel programs with non-linear indexing -- expressed as pre- and\npost-conditions on functions. Programs consist of nests of second-order array\ncombinators (e.g., map, scan, and scatter) and loops. The key idea is to\nrepresent arrays as index functions: programs are index function\ntransformations over which properties are propagated and inferred. Our\nframework proves properties on index functions by distilling them into\nalgebraic (in)equalities and discharging them to a Fourier-Motzkin-based\nsolver. The framework is practical and accessible: properties are not\nrestricted to a decidable logic, but instead are carefully selected to express\npractically useful guarantees that can be automatically reasoned about and\ninferred. These guarantees extend beyond program correctness and can be\nexploited by the entire compiler pipeline for optimization. We implement our\nsystem in the pure data-parallel language Futhark and demonstrate its\npracticality on seven applications, reporting an average verification time of 1\nsecond. Two case studies show how eliminating dynamic verification in GPU\nprograms results in significant speedups."}
{"id": "2506.23322", "pdf": "https://arxiv.org/pdf/2506.23322", "abs": "https://arxiv.org/abs/2506.23322", "authors": ["Wei Zhou", "Ji Sun", "Xuanhe Zhou", "Guoliang Li", "Luyang Liu", "Hao Wu", "Tianyuan Wang"], "title": "GaussMaster: An LLM-based Database Copilot System", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR"], "comment": "We welcome contributions from the community. For reference, please\n  see the code at: https://gitcode.com/opengauss/openGauss-GaussMaster", "summary": "In the financial industry, data is the lifeblood of operations, and DBAs\nshoulder significant responsibilities for SQL tuning, database deployment,\ndiagnosis, and service repair. In recent years, both database vendors and\ncustomers have increasingly turned to autonomous database platforms in an\neffort to alleviate the heavy workload of DBAs. However, existing autonomous\ndatabase platforms are limited in their capabilities, primarily addressing\nsingle-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual\nintervention remains a necessity for comprehensive database maintenance.\nGaussMaster aims to revolutionize this landscape by introducing an LLM-based\ndatabase copilot system. This innovative solution is designed not only to\nassist developers in writing efficient SQL queries but also to provide\ncomprehensive care for database services. When database instances exhibit\nabnormal behavior, GaussMaster is capable of orchestrating the entire\nmaintenance process automatically. It achieves this by analyzing hundreds of\nmetrics and logs, employing a Tree-of-thought approach to identify root causes,\nand invoking appropriate tools to resolve issues. We have successfully\nimplemented GaussMaster in real-world scenarios, such as the banking industry,\nwhere it has achieved zero human intervention for over 34 database maintenance\nscenarios. In this paper, we present significant improvements in these tasks\nwith code at https://gitcode.com/opengauss/openGauss-GaussMaster."}
{"id": "2506.22520", "pdf": "https://arxiv.org/pdf/2506.22520", "abs": "https://arxiv.org/abs/2506.22520", "authors": ["Mustafa Demir", "Jacob Miratsky", "Jonathan Nguyen", "Chun Kit Chan", "Punya Mishra", "Abhishek Singharoy"], "title": "Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics", "categories": ["cs.HC", "cs.AI", "cs.CE", "cs.CY"], "comment": null, "summary": "This study examines the impact of an Artificial Intelligence tutor teammate\n(AI) on student curiosity-driven engagement and learning effectiveness during\nInteractive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics\nplatform. It explores the role of the AI's curiosity-triggering and response\nbehaviors in stimulating and sustaining student curiosity, affecting the\nfrequency and complexity of student-initiated questions. The study further\nassesses how AI interventions shape student engagement, foster discovery\ncuriosity, and enhance team performance within the IMD learning environment.\nUsing a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI\ntutor teammate's behavior through a large language model. By employing a\nmixed-methods exploratory design, a total of 11 high school students\nparticipated in four IMD tasks that involved molecular visualization and\ncalculations, which increased in complexity over a 60-minute period. Team\nperformance was evaluated through real-time observation and recordings, whereas\nteam communication was measured by question complexity and AI's\ncuriosity-triggering and response behaviors. Cross Recurrence Quantification\nAnalysis (CRQA) metrics reflected structural alignment in coordination and were\nlinked to communication behaviors. High-performing teams exhibited superior\ntask completion, deeper understanding, and increased engagement. Advanced\nquestions were associated with AI curiosity-triggering, indicating heightened\nengagement and cognitive complexity. CRQA metrics highlighted dynamic\nsynchronization in student-AI interactions, emphasizing structured yet adaptive\nengagement to promote curiosity. These proof-of-concept findings suggest that\nthe AI's dual role as a teammate and educator indicates its capacity to provide\nadaptive feedback, sustaining engagement and epistemic curiosity."}
{"id": "2506.23672", "pdf": "https://arxiv.org/pdf/2506.23672", "abs": "https://arxiv.org/abs/2506.23672", "authors": ["Sergio Mazzola", "Gabriele Ara", "Thomas Benz", "Björn Forsberg", "Tommaso Cucinotta", "Luca Benini"], "title": "Data-Driven Power Modeling and Monitoring via Hardware Performance Counter Tracking", "categories": ["cs.PF", "cs.AR"], "comment": "Published on Journal of Systems Architecture (JSA), here:\n  https://doi.org/10.1016/j.sysarc.2025.103504 Extension of conference paper\n  https://doi.org/10.1007/978-3-031-15074-6_22 (SAMOS 2022)", "summary": "Energy-centric design is paramount in the current embedded computing era: use\ncases require increasingly high performance at an affordable power budget,\noften under real-time constraints. Hardware heterogeneity and parallelism help\naddress the efficiency challenge, but greatly complicate online power\nconsumption assessments, which are essential for dynamic hardware and software\nstack adaptations. We introduce a novel power modeling methodology with\nstate-of-the-art accuracy, low overhead, and high responsiveness, whose\nimplementation does not rely on microarchitectural details. Our methodology\nidentifies the Performance Monitoring Counters (PMCs) with the highest linear\ncorrelation to the power consumption of each hardware sub-system, for each\nDynamic Voltage and Frequency Scaling (DVFS) state. The individual, simple\nmodels are composed into a complete model that effectively describes the power\nconsumption of the whole system, achieving high accuracy and low overhead. Our\nevaluation reports an average estimation error of 7.5% for power consumption\nand 1.3% for energy. We integrate these models in the Linux kernel with\nRunmeter, an open-source, PMC-based monitoring framework. Runmeter manages PMC\nsampling and processing, enabling the execution of our power models at runtime.\nWith a worst-case time overhead of only 0.7%, Runmeter provides responsive and\naccurate power measurements directly in the kernel. This information can be\nemployed for actuation policies in workload-aware DVFS and power-aware,\nclosed-loop task scheduling."}
{"id": "2506.22677", "pdf": "https://arxiv.org/pdf/2506.22677", "abs": "https://arxiv.org/abs/2506.22677", "authors": ["Yuqi Zhang", "Yuxin Yang", "William Martin", "Kingsten Lin", "Zixu Wang", "Cheng-Chang Lu", "Weiwen Jiang", "Ruth Nussinov", "Joseph Loscalzo", "Qiang Guan", "Feixiong Cheng"], "title": "Prediction of Protein Three-dimensional Structures via a Hardware-Executable Quantum Computing Framework", "categories": ["cs.ET"], "comment": "22 pages, 4 figures", "summary": "Accurate prediction of protein active site structures remains a central\nchallenge in structural biology, particularly for short and flexible peptide\nfragments where conventional methods often fail. Here, we present a quantum\ncomputing framework specifically developed for utility-level quantum processors\nto address this problem. Starting from an amino acid sequence, we formulate the\nstructure prediction task as a ground-state energy minimization problem using\nthe Variational Quantum Eigensolver (VQE). Amino acid connectivity is encoded\non a tetrahedral lattice model, and structural constraints-including steric,\ngeometric, and chirality terms-are mapped into a problem-specific Hamiltonian\nexpressed as sparse Pauli operators. The optimization is executed via a\ntwo-stage architecture separating energy estimation and measurement decoding,\nallowing noise mitigation under realistic quantum device conditions. We\nevaluate the framework on 23 randomly selected real protein fragments from the\nPDBbind dataset, as well as 7 real fragments from proteins with therapeutic\npotential, and run the experiments on the IBM-Cleveland Clinic quantum\nprocessor. Structural predictions are benchmarked against AlphaFold3 (AF3)\nusing identical postprocessing and docking procedures. Our quantum method\noutperformed AF3 in both RMSD (Root-Mean-Square Deviation) and docking\nefficacy. This work demonstrates, for the first time, a complete end-to-end\npipeline for biologically relevant structure prediction on real quantum\nhardware, highlighting its engineering feasibility and practical advantage over\nexisting classical and deep learning approaches."}
{"id": "2506.22828", "pdf": "https://arxiv.org/pdf/2506.22828", "abs": "https://arxiv.org/abs/2506.22828", "authors": ["Go Hashimoto", "Daniel Găină"], "title": "Model-theoretic Forcing in Transition Algebra", "categories": ["cs.LO"], "comment": null, "summary": "We study L\\\"owenheim-Skolem and Omitting Types theorems in Transition\nAlgebra, a logical system obtained by enhancing many sorted first-order logic\nwith features from dynamic logic. The sentences we consider include\ncompositions, unions, and transitive closures of transition relations, which\nare treated similarly to actions in dynamic logics to define necessity and\npossibility operators. We show that Upward L\\\"owenheim-Skolem theorem, any form\nof compactness, and joint Robinson consistency property fail due to the\nexpressivity of transitive closures of transitions. In this non-compact\nmany-sorted logical system, we develop a forcing technique method by\ngeneralizing the classical method of forcing used by Keisler to prove Omitting\nTypes theorem. Instead of working within a single signature, we work with a\ndirected diagram of signatures, which allows us to establish Downward\nL\\\"owenheim-Skolem and Omitting Types theorems despite the fact that models\ninterpret sorts as sets, possibly empty. Building on a complete system of proof\nrules for Transition Algebra, we extend it with additional proof rules to\nreason about constructor-based and/or finite transition algebras. We then\nestablish the completeness of this extended system for a fragment of Transition\nAlgebra obtained by restricting models to constructor-based and/or finite\ntransition algebras."}
{"id": "2506.22849", "pdf": "https://arxiv.org/pdf/2506.22849", "abs": "https://arxiv.org/abs/2506.22849", "authors": ["Michael A. Kern", "Alain Galvan", "David Oldcorn", "Daniel Skinner", "Rohan Mehalwal", "Leo Reyes Lozano", "Matthäus G. Chajdas"], "title": "DOBB-BVH: Efficient Ray Traversal by Transforming Wide BVHs into Oriented Bounding Box Trees using Discrete Rotations", "categories": ["cs.GR"], "comment": "10 pages main content, 3 pages appendix", "summary": "Oriented bounding box (OBB) bounding volume hierarchies offer a more precise\nfit than axis-aligned bounding box hierarchies in scenarios with thin elongated\nand arbitrarily rotated geometry, enhancing intersection test performance in\nray tracing. However, determining optimally oriented bounding boxes can be\ncomputationally expensive and have high memory requirements. Recent research\nhas shown that pre-built hierarchies can be efficiently converted to OBB\nhierarchies on the GPU in a bottom-up pass, yielding significant ray tracing\ntraversal improvements. In this paper, we introduce a novel OBB construction\ntechnique where all internal node children share a consistent OBB transform,\nchosen from a fixed set of discrete quantized rotations. This allows for\nefficient encoding and reduces the computational complexity of OBB\ntransformations. We further extend our approach to hierarchies with multiple\nchildren per node by leveraging Discrete Orientation Polytopes (k-DOPs),\ndemonstrating improvements in traversal performance while limiting the build\ntime impact for real-time applications. Our method is applied as a\npost-processing step, integrating seamlessly into existing hierarchy\nconstruction pipelines. Despite a 12.6% increase in build time, our\nexperimental results demonstrate an average improvement of 18.5% in primary,\n32.4% in secondary rays, and maximum gain of 65% in ray intersection\nperformance, highlighting its potential for advancing real-time applications."}
{"id": "2506.22688", "pdf": "https://arxiv.org/pdf/2506.22688", "abs": "https://arxiv.org/abs/2506.22688", "authors": ["Humberto Cervantes", "Rick Kazman", "Yuanfang Cai"], "title": "An LLM-assisted approach to designing software architectures using ADD", "categories": ["cs.SE", "D.2.11; D.2.2"], "comment": "30 pages, 12 figures, 7 tables", "summary": "Designing effective software architectures is a complex, iterative process\nthat traditionally relies on expert judgment. This paper proposes an approach\nfor Large Language Model (LLM)-assisted software architecture design using the\nAttribute-Driven Design (ADD) method. By providing an LLM with an explicit\ndescription of ADD, an architect persona, and a structured iteration plan, our\nmethod guides the LLM to collaboratively produce architecture artifacts with a\nhuman architect. We validate the approach through case studies, comparing\ngenerated designs against proven solutions and evaluating them with\nprofessional architects. Results show that our LLM-assisted ADD process can\ngenerate architectures closely aligned with established solutions and partially\nsatisfying architectural drivers, highlighting both the promise and current\nlimitations of using LLMs in architecture design. Our findings emphasize the\nimportance of human oversight and iterative refinement when leveraging LLMs in\nthis domain."}
{"id": "2506.23707", "pdf": "https://arxiv.org/pdf/2506.23707", "abs": "https://arxiv.org/abs/2506.23707", "authors": ["Jiewei Lai", "Lan Zhang", "Chen Tang", "Pengcheng Sun"], "title": "Efficient and Accurate Image Provenance Analysis: A Scalable Pipeline for Large-scale Images", "categories": ["cs.MM"], "comment": "25 pages, 6 figures", "summary": "The rapid proliferation of modified images on social networks that are driven\nby widely accessible editing tools demands robust forensic tools for digital\ngovernance. Image provenance analysis, which filters various query image\nvariants and constructs a directed graph to trace their phylogeny history, has\nemerged as a critical solution. However, existing methods face two fundamental\nlimitations: First, accuracy issues arise from overlooking heavily modified\nimages due to low similarity while failing to exclude unrelated images and\ndetermine modification directions under diverse modification scenarios. Second,\nscalability bottlenecks stem from pairwise image analysis incurs quadratic\ncomplexity, hindering application in large-scale scenarios. This paper presents\na scalable end-to-end pipeline for image provenance analysis that achieves high\nprecision with linear complexity. This improves filtering effectiveness through\nmodification relationship tracing, which enables the comprehensive discovery of\nimage variants regardless of their visual similarity to the query. In addition,\nthe proposed pipeline integrates local features matching and compression\nartifact capturing, enhancing robustness against diverse modifications and\nenabling accurate analysis of images' relationships. This allows the generation\nof a directed provenance graph that accurately characterizes the image's\nphylogeny history. Furthermore, by optimizing similarity calculations and\neliminating redundant pairwise analysis during graph construction, the pipeline\nachieves a linear time complexity, ensuring its scalability for large-scale\nscenarios. Experiments demonstrate pipeline's superior performance, achieving a\n16.7-56.1% accuracy improvement. Notably, it exhibits significant scalability\nwith an average 3.0-second response time on 10 million scale images, which is\nfar shorter than the SOTA approach's 12-minute duration."}
{"id": "2506.22470", "pdf": "https://arxiv.org/pdf/2506.22470", "abs": "https://arxiv.org/abs/2506.22470", "authors": ["Liang Chen", "Yu Song", "Kanglian Zhao", "Juan A. Fraire", "Wenfeng Li"], "title": "Reliable Transmission of LTP Using Reinforcement Learning-Based Adaptive FEC", "categories": ["cs.NI", "cs.SY", "eess.SY"], "comment": "15 pages, 30 figures, Liang Chen and Yu Song are co-first authors", "summary": "Delay/Disruption Tolerant Networking (DTN) employs the Licklider Transmission\nProtocol (LTP) with Automatic Repeat reQuest (ARQ) for reliable data delivery\nin challenging interplanetary networks. While previous studies have integrated\npacket-level Forward Erasure Correction (FEC) into LTP to reduce retransmission\ntime costs, existing static and delay-feedback-based dynamic coding methods\nstruggle with highly variable and unpredictable deep space channel conditions.\nThis paper proposes a reinforcement learning (RL)-based adaptive FEC algorithm\nto address these limitations. The algorithm utilizes historical feedback and\nsystem state to predict future channel conditions and proactively adjust the\ncode rate. This approach aims to anticipate channel quality degradation,\nthereby preventing decoding failures and subsequent LTP retransmissions and\nimproving coding efficiency by minimizing redundancy during favorable channel\nconditions. Performance evaluations conducted in simulated Earth-Moon and\nEarth-Mars link scenarios demonstrate this algorithm's effectiveness in\noptimizing data transmission for interplanetary networks. Compared to existing\nmethods, this approach demonstrates significant improvement, with matrix\ndecoding failures reduced by at least 2/3."}
{"id": "2506.23320", "pdf": "https://arxiv.org/pdf/2506.23320", "abs": "https://arxiv.org/abs/2506.23320", "authors": ["Nicola Assolini", "Alessandra Di Pierro"], "title": "A Denotational Semantics for Quantum Loops", "categories": ["cs.PL"], "comment": "17 pages", "summary": "Programming a quantum computer, i.e., implementing quantum algorithms on a\nquantum processor-based copmputer architecture, is a task that can be addressed\n(just as for classical computers) at different levels of abstraction. This\npaper proposes a denotational semantics for high-level quantum programming\nconstructs, focusing on the conceptual meaning of quantum-controlled branching\nand iteration. We introduce a denotational domain where a mathematical meaning\nof a quantum control flow with loops can be defined, which reflects the\ncoherent evolution of the quantum system implementing the program."}
{"id": "2506.22530", "pdf": "https://arxiv.org/pdf/2506.22530", "abs": "https://arxiv.org/abs/2506.22530", "authors": ["Jakub Peleška", "Gustav Šír"], "title": "Task-Agnostic Contrastive Pretraining for Relational Deep Learning", "categories": ["cs.LG", "cs.DB"], "comment": "arXiv admin note: text overlap with arXiv:2506.22199", "summary": "Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph\nNeural Network principles to learn directly from relational databases by\nrepresenting them as heterogeneous graphs. However, existing RDL models\ntypically rely on task-specific supervised learning, requiring training\nseparate models for each predictive task, which may hamper scalability and\nreuse.\n  In this work, we propose a novel task-agnostic contrastive pretraining\napproach for RDL that enables database-wide representation learning. For that\naim, we introduce three levels of contrastive objectives$-$row-level,\nlink-level, and context-level$-$designed to capture the structural and semantic\nheterogeneity inherent to relational data. We implement the respective\npretraining approach through a modular RDL architecture and an efficient\nsampling strategy tailored to the heterogeneous database setting. Our\npreliminary results on standard RDL benchmarks demonstrate that fine-tuning the\npretrained models measurably outperforms training from scratch, validating the\npromise of the proposed methodology in learning transferable representations\nfor relational data."}
{"id": "2506.22583", "pdf": "https://arxiv.org/pdf/2506.22583", "abs": "https://arxiv.org/abs/2506.22583", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges"], "title": "Supra-threshold control of peripheral LOD", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "Level of detail (LOD) is widely used to control visual feedback in\ninteractive applications. LOD control is typically based on perception at\nthreshold - the conditions in which a stimulus first becomes perceivable. Yet\nmost LOD manipulations are quite perceivable and occur well above threshold.\nMoreover, research shows that supra-threshold perception differs drastically\nfrom perception at threshold. In that case, should supra-threshold LOD control\nalso differ from LOD control at threshold?\n  In two experiments, we examine supra-threshold LOD control in the visual\nperiphery and find that indeed, it should differ drastically from LOD control\nat threshold. Specifically, we find that LOD must support a task-dependent\nlevel of reliable perceptibility. Above that level, perceptibility of LOD\ncontrol manipulations should be minimized, and detail contrast is a better\npredictor of perceptibility than detail size. Below that level, perceptibility\nmust be maximized, and LOD should be improved as eccentricity rises or contrast\ndrops. This directly contradicts prevailing threshold-based LOD control\nschemes, and strongly suggests a reexamination of LOD control for foveal\ndisplay."}
{"id": "2506.23185", "pdf": "https://arxiv.org/pdf/2506.23185", "abs": "https://arxiv.org/abs/2506.23185", "authors": ["Barak Hoffer", "Shahar Kvatinsky"], "title": "Stateful Logic In-Memory Using Gain-Cell eDRAM", "categories": ["cs.ET"], "comment": "Proceedings of IEEE International NEWCAS Conference, June 2025", "summary": "Modern data-intensive applications demand memory solutions that deliver\nhigh-density, low-power, and integrated computational capabilities to reduce\ndata movement overhead. This paper presents the use of Gain-Cell embedded DRAM\n(GC-eDRAM) - a compelling alternative to traditional SRAM and eDRAM - for\nstateful, in-memory logic. We propose a circuit design that exploits GC-eDRAM's\ndual-port architecture and nondestructive read operation to perform logic\nfunctions directly within the GC-eDRAM memory array. Our simulation results\ndemonstrate a 5us retention time coupled with a 99.5% success rate for\ncomputing the logic gates. By incorporating processing-in-memory (PIM)\nfunctionality into GC-eDRAM, our approach enhances memory and compute\ndensities, lowers power consumption, and improves overall performance for\ndata-intensive applications."}
{"id": "2506.22654", "pdf": "https://arxiv.org/pdf/2506.22654", "abs": "https://arxiv.org/abs/2506.22654", "authors": ["Guy Wilks", "Brian Li", "Jonathan Balkind"], "title": "Oobleck: Low-Compromise Design for Fault Tolerant Accelerators", "categories": ["cs.AR"], "comment": null, "summary": "Data center hardware refresh cycles are lengthening. However, increasing\nprocessor complexity is raising the potential for faults. To achieve longevity\nin the face of increasingly fault-prone datapaths, fault tolerance is needed,\nespecially in on-chip accelerator datapaths. Previously researched methods for\nadding fault tolerance to accelerator designs require high area, lowering chip\nutilisation. We propose a novel architecture for accelerator fault tolerance,\nOobleck, which leverages modular acceleration to enable fault tolerance without\nburdensome area requirements.\n  In order to streamline the development and enforce modular conventions, we\nintroduce the Viscosity language, an actor based approach to hardware-software\nco-design. Viscosity uses a single description of the accelerator's function\nand produces both hardware and software descriptions.\n  Our high-level models of data centers indicate that our approach can decrease\nthe number of failure-induced chip purchases inside data centers while not\naffecting aggregate throughput, thus reducing data center costs. To show the\nfeasibility of our approach, we show three case-studies: FFT, AES, and DCT\naccelerators. We additionally profile the performance under the key parameters\naffecting latency. Under a single fault we can maintain speedups of between\n1.7x-5.16x for accelerated applications over purely software implementations.\nWe show further benefits can be achieved by adding hot-spare FPGAs into the\nchip."}
{"id": "2506.23730", "pdf": "https://arxiv.org/pdf/2506.23730", "abs": "https://arxiv.org/abs/2506.23730", "authors": ["Alessio Mansutti", "Mikhail R. Starchak"], "title": "One-Parametric Presburger Arithmetic has Quantifier Elimination", "categories": ["cs.LO", "cs.SC"], "comment": "Extended version of a MFCS 2025 paper", "summary": "We give a quantifier elimination procedure for one-parametric Presburger\narithmetic, the extension of Presburger arithmetic with the function $x \\mapsto\nt \\cdot x$, where $t$ is a fixed free variable ranging over the integers. This\nresolves an open problem proposed in [Bogart et al., Discrete Analysis, 2017].\nAs conjectured in [Goodrick, Arch. Math. Logic, 2018], quantifier elimination\nis obtained for the extended structure featuring all integer division functions\n$x \\mapsto \\lfloor{\\frac{x}{f(t)}}\\rfloor$, one for each integer polynomial\n$f$.\n  Our algorithm works by iteratively eliminating blocks of existential\nquantifiers. The elimination of a block builds on two sub-procedures, both\nrunning in non-deterministic polynomial time. The first one is an adaptation of\na recently developed and efficient quantifier elimination procedure for\nPresburger arithmetic, modified to handle formulae with coefficients over the\nring $\\mathbb{Z}[t]$ of univariate polynomials. The second is reminiscent of\nthe so-called \"base $t$ division method\" used by Bogart et al. As a result, we\ndeduce that the satisfiability problem for the existential fragment of\none-parametric Presburger arithmetic (which encompasses a broad class of\nnon-linear integer programs) is in NP, and that the smallest solution to a\nsatisfiable formula in this fragment is of polynomial bit size."}
{"id": "2506.22973", "pdf": "https://arxiv.org/pdf/2506.22973", "abs": "https://arxiv.org/abs/2506.22973", "authors": ["AmirHossein Naghi Razlighi", "Elaheh Badali Golezani", "Shohreh Kasaei"], "title": "Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D Gaussian Splatting enables high-quality real-time rendering but often\nproduces millions of splats, resulting in excessive storage and computational\noverhead. We propose a novel lossy compression method based on learnable\nconfidence scores modeled as Beta distributions. Each splat's confidence is\noptimized through reconstruction-aware losses, enabling pruning of\nlow-confidence splats while preserving visual fidelity. The proposed approach\nis architecture-agnostic and can be applied to any Gaussian Splatting variant.\nIn addition, the average confidence values serve as a new metric to assess the\nquality of the scene. Extensive experiments demonstrate favorable trade-offs\nbetween compression and fidelity compared to prior work. Our code and data are\npublicly available at\nhttps://github.com/amirhossein-razlighi/Confident-Splatting"}
{"id": "2506.22703", "pdf": "https://arxiv.org/pdf/2506.22703", "abs": "https://arxiv.org/abs/2506.22703", "authors": ["Wali Mohammad Abdullah", "Azmain Kabir"], "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "We present P4OMP, a retrieval-augmented framework for transforming serial\nC/C++ code into OpenMP-annotated parallel code using large language models\n(LLMs). To our knowledge, this is the first system to apply retrieval-based\nprompting for OpenMP pragma correctness without model fine-tuning or compiler\ninstrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with\nstructured instructional knowledge from OpenMP tutorials to improve the\nreliability of prompt-driven code generation. By grounding generation in the\nretrieved context, P4OMP improves syntactic correctness compared to baseline\nprompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline,\nGPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world\nC++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites.\nP4OMP achieves 100% compilation success on all parallelizable cases, while the\nbaseline fails to compile in 20 out of 108 cases. Six cases that rely on\nnon-random-access iterators or thread-unsafe constructs are excluded due to\nfundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP\nconsistently avoids scoping errors, syntactic misuse, and invalid directive\ncombinations that commonly affect baseline-generated code. We further\ndemonstrate strong runtime scaling across seven compute-intensive benchmarks on\nan HPC cluster. P4OMP offers a robust, modular pipeline that significantly\nimproves the reliability and applicability of LLM-generated OpenMP code."}
{"id": "2506.22790", "pdf": "https://arxiv.org/pdf/2506.22790", "abs": "https://arxiv.org/abs/2506.22790", "authors": ["Yixu Chen", "Bowen Chen", "Hai Wei", "Alan C. Bovik", "Baojun Li", "Wei Sun", "Linhan Cao", "Kang Fu", "Dandan Zhu", "Jun Jia", "Menghan Hu", "Xiongkuo Min", "Guangtao Zhai", "Dounia Hammou", "Fei Yin", "Rafal Mantiuk", "Amritha Premkumar", "Prajit T Rajendran", "Vignesh V Menon"], "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "ICME 2025 Grand Challenges", "summary": "This paper reports IEEE International Conference on Multimedia \\& Expo (ICME)\n2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement.\nWith the rapid development of video technology, especially High Dynamic Range\n(HDR) and Standard Dynamic Range (SDR) contents, the need for robust and\ngeneralizable Video Quality Assessment (VQA) methods has become increasingly\ndemanded. Existing VQA models often struggle to deliver consistent performance\nacross varying dynamic ranges, distortion types, and diverse content. This\nchallenge was established to benchmark and promote VQA approaches capable of\njointly handling HDR and SDR content. In the final evaluation phase, five teams\nsubmitted seven models along with technical reports to the Full Reference (FR)\nand No Reference (NR) tracks. Among them, four methods outperformed VMAF\nbaseline, while the top-performing model achieved state-of-the-art performance,\nsetting a new benchmark for generalizable video quality assessment."}
{"id": "2506.22474", "pdf": "https://arxiv.org/pdf/2506.22474", "abs": "https://arxiv.org/abs/2506.22474", "authors": ["Ziad Qais Al Abbasi", "Khaled M. Rabie", "Senior Member", "Xingwang Li", "Senior Member", "Wali Ullah Khan", "Asma Abu Samah"], "title": "RL-based Adaptive Task Offloading in Mobile-Edge Computing for Future IoT Networks", "categories": ["cs.NI", "cs.SY", "eess.SY", "C.2 COMPUTER-COMMUNICATION NETWORKS"], "comment": "7 pages", "summary": "The Internet of Things (IoT) has been increasingly used in our everyday lives\nas well as in numerous industrial applications. However, due to limitations in\ncomputing and power capabilities, IoT devices need to send their respective\ntasks to cloud service stations that are usually located at far distances.\nHaving to transmit data far distances introduces challenges for services that\nrequire low latency such as industrial control in factories and plants as well\nas artificial intelligence assisted autonomous driving. To solve this issue,\nmobile edge computing (MEC) is deployed at the networks edge to reduce\ntransmission time. In this regard, this study proposes a new offloading scheme\nfor MEC-assisted ultra dense cellular networks using reinforcement learning\n(RL) techniques. The proposed scheme enables efficient resource allocation and\ndynamic offloading decisions based on varying network conditions and user\ndemands. The RL algorithm learns from the networks historical data and adapts\nthe offloading decisions to optimize the networks overall performance.\nNon-orthogonal multiple access is also adopted to improve resource utilization\namong the IoT devices. Simulation results demonstrate that the proposed scheme\noutperforms other stateof the art offloading algorithms in terms of energy\nefficiency, network throughput, and user satisfaction."}
{"id": "2506.23407", "pdf": "https://arxiv.org/pdf/2506.23407", "abs": "https://arxiv.org/abs/2506.23407", "authors": ["Marcus Edwards"], "title": "Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR", "categories": ["cs.PL", "quant-ph"], "comment": null, "summary": "We implement a compile toolchain from Q# to QASM 3.0 including a\nfull-featured lexer and parser implementation, as well as a compiler that\nsupports a subset of Q# features. The lexer, parser and compiler are shown to\nwork with various input Q# programs and the implementation is compared against\nexisting Q# compile tools. Unlike the Microsoft implementation of the official\nQ# compile toolchain, our implementation is written in TypeScript in order to\nport functionality to web environments."}
{"id": "2506.22716", "pdf": "https://arxiv.org/pdf/2506.22716", "abs": "https://arxiv.org/abs/2506.22716", "authors": ["Dujian Ding", "Ankur Mallick", "Shaokun Zhang", "Chi Wang", "Daniel Madrigal", "Mirian Del Carmen Hipolito Garcia", "Menglin Xia", "Laks V. S. Lakshmanan", "Qingyun Wu", "Victor Rühle"], "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DB"], "comment": "Accepted to ICML 2025 (main conference)", "summary": "Large language models (LLMs) are powerful tools but are often expensive to\ndeploy at scale. LLM query routing mitigates this by dynamically assigning\nqueries to models of varying cost and quality to obtain a desired trade-off.\nPrior query routing approaches generate only one response from the selected\nmodel and a single response from a small (inexpensive) model was often not good\nenough to beat a response from a large (expensive) model due to which they end\nup overusing the large model and missing out on potential cost savings.\nHowever, it is well known that for small models, generating multiple responses\nand selecting the best can enhance quality while remaining cheaper than a\nsingle large-model response. We leverage this idea to propose BEST-Route, a\nnovel routing framework that chooses a model and the number of responses to\nsample from it based on query difficulty and the quality thresholds.\nExperiments on real-world datasets demonstrate that our method reduces costs by\nup to 60% with less than 1% performance drop."}
{"id": "2506.22597", "pdf": "https://arxiv.org/pdf/2506.22597", "abs": "https://arxiv.org/abs/2506.22597", "authors": ["Ehud Sharlin", "Benjamin Watson", "Steve Sutphen", "Lili Liu", "Robert Lederer", "John Frazer"], "title": "A tangible user interface for assessing cognitive mapping ability", "categories": ["cs.HC"], "comment": null, "summary": "Wayfinding, the ability to recall the environment and navigate through it, is\nan essential cognitive skill relied upon almost every day in a person's life. A\ncrucial component of wayfinding is the construction of cognitive maps, mental\nrepresentations of the environments through which a person travels. Age,\ndisease or injury can severely affect cognitive mapping, making assessment of\nthis basic survival skill particularly important to clinicians and therapists.\nCognitive mapping has also been the focus of decades of basic research by\ncognitive psychologists. Both communities have evolved a number of techniques\nfor assessing cognitive mapping ability. We present the Cognitive Map Probe\n(CMP), a new computerized tool for assessment of cognitive mapping ability that\nincreases consistency and promises improvements in flexibility, accessibility,\nsensitivity and control. The CMP uses a tangible user interface that affords\nspatial manipulation. We describe the design of the CMP, and find that it is\nsensitive to factors known to affect cognitive mapping performance in extensive\nexperimental testing."}
{"id": "2506.23405", "pdf": "https://arxiv.org/pdf/2506.23405", "abs": "https://arxiv.org/abs/2506.23405", "authors": ["Faaiq Waqar", "Ming-Yen Lee", "Seongwon Yoon", "Seongkwang Lim", "Shimeng Yu"], "title": "CMOS+X: Stacking Persistent Embedded Memories based on Oxide Transistors upon GPGPU Platforms", "categories": ["cs.ET", "cs.AR", "B.8.2; B.3.1"], "comment": "14 pages, 18 figures, 4 tables, 4 equations", "summary": "In contemporary general-purpose graphics processing units (GPGPUs), the\ncontinued increase in raw arithmetic throughput is constrained by the\ncapabilities of the register file (single-cycle) and last-level cache (high\nbandwidth), which require the delivery of operands at a cadence demanded by\nwide single-instruction multiple-data (SIMD) lanes. Enhancing the capacity,\ndensity, or bandwidth of these memories can unlock substantial performance\ngains; however, the recent stagnation of SRAM bit-cell scaling leads to\ninequivalent losses in compute density.\n  To address the challenges posed by SRAM's scaling and leakage power\nconsumption, this paper explores the potential CMOS+X integration of amorphous\noxide semiconductor (AOS) transistors in capacitive, persistent memory\ntopologies (e.g., 1T1C eDRAM, 2T0C/3T0C Gain Cell) as alternative cells in\nmulti-ported and high-bandwidth banked GPGPU memories. A detailed study of the\ndensity and energy tradeoffs of back-end-of-line (BEOL) integrated memories\nutilizing monolithic 3D (M3D)-integrated multiplexed arrays is conducted, while\naccounting for the macro-level limitations of integrating AOS candidate\nstructures proposed by the device community (an aspect often overlooked in\nprior work). By exploiting the short lifetime of register operands, we propose\na multi-ported AOS gain-cell capable of delivering 3x the read ports in ~76% of\nthe footprint of SRAM with over 70% lower standby power, enabling enhancements\nto compute capacity, such as larger warp sizes or processor counts. Benchmarks\nrun on a validated NVIDIA Ampere-class GPU model, using a modified version of\nAccel-Sim, demonstrate improvements of up to 5.2x the performance per watt and\nan average 8% higher geometric mean instruction per cycle (IPC) on various\ncompute- and memory-bound tasks."}
{"id": "2506.22772", "pdf": "https://arxiv.org/pdf/2506.22772", "abs": "https://arxiv.org/abs/2506.22772", "authors": ["Jingxiao Ma", "Soheil Hashemi", "Sherief Reda"], "title": "Approximate Logic Synthesis Using BLASYS", "categories": ["cs.AR", "B.6.1; B.2.4; B.8.2"], "comment": "Published in the Workshop on Open-Source EDA Technology (WOSET),\n  2019. (Workshop link: https://woset-workshop.github.io/WOSET2019.html)", "summary": "Approximate computing is an emerging paradigm where design accuracy can be\ntraded for improvements in design metrics such as design area and power\nconsumption. In this work, we overview our open-source tool, BLASYS, for\nsynthesis of approximate circuits using Boolean Matrix Factorization (BMF). In\nour methodology the truth table of a given circuit is approximated using BMF to\na controllable approximation degree, and the results of the factorization are\nused to synthesize the approximate circuit output. BLASYS scales up the\ncomputations to large circuits through the use of partition techniques, where\nan input circuit is partitioned into a number of interconnected subcircuits and\nthen a design-space exploration technique identifies the best order for\nsubcircuit approximations. BLASYS leads to a graceful trade-off between\naccuracy and full circuit complexity as measured by design area. Using an\nopen-source design flow, we extensively evaluate our methodology on a number of\nbenchmarks, where we demonstrate that the proposed methodology can achieve on\naverage 48.14% in area savings, while introducing an average relative error of\n5%."}
{"id": "2506.22714", "pdf": "https://arxiv.org/pdf/2506.22714", "abs": "https://arxiv.org/abs/2506.22714", "authors": ["Jinliang Shi", "Shigang Li", "Youxuan Xu", "Xueying Wang", "Rongtian Fu", "Zhi Ma", "Tong Wu"], "title": "Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication", "categories": ["cs.DC", "cs.LG", "cs.PF", "C.1.4; I.2.11"], "comment": null, "summary": "Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used\nin deep learning and scientific computing. Modern accelerators are commonly\nequipped with Tensor cores and CUDA cores to accelerate sparse operators. The\nformer brings superior computing power but only for structured matrix\nmultiplication, while the latter has relatively lower performance but with\nhigher programming flexibility. In this work, we discover that utilizing one\nresource alone leads to inferior performance for sparse matrix multiplication,\ndue to their respective limitations. To this end, we propose Libra, a\nsystematic approach that enables synergistic computation between CUDA and\nTensor cores to achieve the best performance for sparse matrix multiplication.\nSpecifically, we propose a 2D-aware workload distribution strategy to find out\nthe sweet point of task mapping for different sparse operators, leveraging both\nthe high performance of Tensor cores and the low computational redundancy on\nCUDA cores. In addition, Libra incorporates systematic optimizations for\nheterogeneous computing, including hybrid load-balancing, finely optimized\nkernel implementations, and GPU-accelerated preprocessing. Extensive\nexperimental results on H100 and RTX 4090 GPUs show that Libra outperforms the\nstate-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to\n3.9x) for end-to-end GNN applications. Libra opens up a new perspective for\nsparse operator acceleration by fully exploiting the heterogeneous computing\nresources on GPUs."}
{"id": "2506.23789", "pdf": "https://arxiv.org/pdf/2506.23789", "abs": "https://arxiv.org/abs/2506.23789", "authors": ["Reza Soltani", "Stefano M. Nicoletti", "Milan Lopuhaä-Zwakenberg", "Mariëlle Stoelinga"], "title": "Querying Attack-Fault-Defense Trees: Property Specification in Smart Grid and Aerospace Case Studies", "categories": ["cs.LO"], "comment": null, "summary": "This paper introduces AFDL, a logic-based framework for reasoning about\nsafety, security, and defense interactions in Attack-Fault-Defense Trees, which\nis a model that captures all safety, security, and defense domains in a single\nframework. We showcase both AFDL and propose a structured domain specific query\nlanguage, LangAFDL, which enables domain experts to express complex analysis\ngoals through intuitive templates. LangAFDL supports both Boolean and\nquantified queries as well as minimal cut set analysis, capturing the interplay\nbetween safety, security, and defensive measures. We illustrate the\nexpressiveness and utility of the approach through representative queries over\ntwo different real-world case studies: Gridshield and Ground Segment as a\nService. The formalization lays the automated safety-security groundwork for\nanalyses in mission-critical systems and paves the way for future tool\ndevelopment and integration into design workflows."}
{"id": "2506.23001", "pdf": "https://arxiv.org/pdf/2506.23001", "abs": "https://arxiv.org/abs/2506.23001", "authors": ["Benjamin Watson", "David Luebke"], "title": "The ultimate display: Where will all the pixels come from?", "categories": ["cs.GR"], "comment": null, "summary": "Could the answer be to compute fewer pixels? Renderers that break traditional\nframed patterns and opt for temporally adaptive sampling might be the key to\nprinter-resolution wall displays that update hundreds of times per second."}
{"id": "2506.22742", "pdf": "https://arxiv.org/pdf/2506.22742", "abs": "https://arxiv.org/abs/2506.22742", "authors": ["Wali Mohammad Abdullah", "Md. Morshedul Islam", "Devraj Parmar", "Happy Hasmukhbhai Patel", "Sindhuja Prabhakaran", "Baidya Saha"], "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to\nassist software development, yet they often produce incomplete code or\nincorrect imports, especially when lacking access to external or\nproject-specific documentation. We introduce RAILS (Retrieval-Augmented\nIntelligence for Learning Software Development), a framework that augments LLM\nprompts with semantically retrieved context from curated Java resources using\nFAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop\nguided by compiler feedback to refine suggestions. We evaluated RAILS on 78\nreal-world Java import error cases spanning standard libraries, GUI APIs,\nexternal tools, and custom utilities. Despite using the same LLM, RAILS\noutperforms baseline prompting by preserving intent, avoiding hallucinations,\nand surfacing correct imports even when libraries are unavailable locally.\nFuture work will integrate symbolic filtering via PostgreSQL and extend support\nto other languages and IDEs."}
{"id": "2506.22871", "pdf": "https://arxiv.org/pdf/2506.22871", "abs": "https://arxiv.org/abs/2506.22871", "authors": ["Homayun Afrabandpey", "Hamed Rezazadegan Tavakoli"], "title": "P$^2$U: Progressive Precision Update For Efficient Model Distribution", "categories": ["cs.LG", "cs.MM", "I.2.6"], "comment": null, "summary": "Efficient model distribution is becoming increasingly critical in\nbandwidth-constrained environments. In this paper, we propose a simple yet\neffective approach called Progressive Precision Update (P$^2$U) to address this\nproblem. Instead of transmitting the original high-precision model, P$^2$U\ntransmits a lower-bit precision model, coupled with a model update representing\nthe difference between the original high-precision model and the transmitted\nlow precision version. With extensive experiments on various model\narchitectures, ranging from small models ($1 - 6$ million parameters) to a\nlarge model (more than $100$ million parameters) and using three different data\nsets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U\nconsistently achieves better tradeoff between accuracy, bandwidth usage and\nlatency. Moreover, we show that when bandwidth or startup time is the priority,\naggressive quantization (e.g., 4-bit) can be used without severely compromising\nperformance. These results establish P$^2$U as an effective and practical\nsolution for scalable and efficient model distribution in low-resource\nsettings, including federated learning, edge computing, and IoT deployments.\nGiven that P$^2$U complements existing compression techniques and can be\nimplemented alongside any compression method, e.g., sparsification,\nquantization, pruning, etc., the potential for improvement is even greater."}
{"id": "2506.22477", "pdf": "https://arxiv.org/pdf/2506.22477", "abs": "https://arxiv.org/abs/2506.22477", "authors": ["Huiwen Han"], "title": "Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.RO"], "comment": "Published in: 2024 6th International Conference on Robotics,\n  Intelligent Control and Artificial Intelligence (RICAI), IEEE Xplore, DOI:\n  10.1109/RICAI64321.2024.10911316. \\c{opyright} 2024 IEEE", "summary": "This paper introduces an innovative design for robotic operating platforms,\nunderpinned by a transformative Internet of Things (IoT) architecture,\nseamlessly integrating cutting-edge technologies such as large language models\n(LLMs), generative AI, edge computing, and 5G networks. The proposed platform\naims to elevate the intelligence and autonomy of IoT systems and robotics,\nenabling them to make real-time decisions and adapt dynamically to changing\nenvironments. Through a series of compelling case studies across industries\nincluding smart manufacturing, healthcare, and service sectors, this paper\ndemonstrates the substantial potential of IoT-enabled robotics to optimize\noperational workflows, enhance productivity, and deliver innovative, scalable\nsolutions. By emphasizing the roles of LLMs and generative AI, the research\nhighlights how these technologies drive the evolution of intelligent robotics\nand IoT, shaping the future of industry-specific advancements. The findings not\nonly showcase the transformative power of these technologies but also offer a\nforward-looking perspective on their broader societal and industrial\nimplications, positioning them as catalysts for next-generation automation and\ntechnological convergence."}
{"id": "2506.22776", "pdf": "https://arxiv.org/pdf/2506.22776", "abs": "https://arxiv.org/abs/2506.22776", "authors": ["Sen Fang", "Weiyuan Ding", "Antonio Mastropaolo", "Bowen Xu"], "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": "13 pages, 6 figures", "summary": "Quantization has emerged as a mainstream method for compressing Large\nLanguage Models (LLMs), reducing memory requirements and accelerating inference\nwithout architectural modifications. While existing research primarily focuses\non evaluating the effectiveness of quantized LLMs compared to their original\ncounterparts, the impact on robustness remains largely unexplored.In this\npaper, we present the first systematic investigation of how quantization\naffects the robustness of LLMs in code generation tasks. Through extensive\nexperiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and\nStarCoder) with parameter scales ranging from 350M to 33B, we evaluate\nrobustness from dual perspectives: adversarial attacks on input prompts and\nnoise perturbations on model architecture. Our findings challenge conventional\nwisdom by demonstrating that quantized LLMs often exhibit superior robustness\ncompared to their full-precision counterparts, with 51.59% versus 42.86% of our\nadversarial experiments showing better resilience in quantized LLMs. Similarly,\nour noise perturbation experiments also confirm that LLMs after quantitation\ngenerally withstand higher levels of weight disturbances. These results suggest\nthat quantization not only reduces computational requirements but can actually\nenhance LLMs' reliability in code generation tasks, providing valuable insights\nfor developing more robust and efficient LLM deployment strategies."}
{"id": "2506.22791", "pdf": "https://arxiv.org/pdf/2506.22791", "abs": "https://arxiv.org/abs/2506.22791", "authors": ["Jianxin Yan", "Wangze Ni", "Lei Chen", "Xuemin Lin", "Peng Cheng", "Zhan Qin", "Kui Ren"], "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "Semantic caching significantly reduces computational costs and improves\nefficiency by storing and reusing large language model (LLM) responses.\nHowever, existing systems rely primarily on matching individual queries,\nlacking awareness of multi-turn dialogue contexts, which leads to incorrect\ncache hits when similar queries appear in different conversational settings.\nThis demonstration introduces ContextCache, a context-aware semantic caching\nsystem for multi-turn dialogues. ContextCache employs a two-stage retrieval\narchitecture that first executes vector-based retrieval on the current query to\nidentify potential matches and then integrates current and historical dialogue\nrepresentations through self-attention mechanisms for precise contextual\nmatching. Evaluation of real-world conversations shows that ContextCache\nimproves precision and recall compared to existing methods. Additionally,\ncached responses exhibit approximately 10 times lower latency than direct LLM\ninvocation, enabling significant computational cost reductions for LLM\nconversational applications."}
{"id": "2506.22674", "pdf": "https://arxiv.org/pdf/2506.22674", "abs": "https://arxiv.org/abs/2506.22674", "authors": ["Weiyin Xie", "Chunxi Huang", "Jiyao Wang", "Dengbo He"], "title": "Do Electric Vehicles Induce More Motion Sickness Than Fuel Vehicles? A Survey Study in China", "categories": ["cs.HC", "cs.CY", "stat.AP"], "comment": null, "summary": "Electric vehicles (EVs) are a promising alternative to fuel vehicles (FVs),\ngiven some unique characteristics of EVs, for example, the low air pollution\nand maintenance cost. However, the increasing prevalence of EVs is accompanied\nby widespread complaints regarding the high likelihood of motion sickness (MS)\ninduction, especially when compared to FVs, which has become one of the major\nobstacles to the acceptance and popularity of EVs. Despite the prevalence of\nsuch complaints online and among EV users, the association between vehicle type\n(i.e., EV versus FV) and MS prevalence and severity has not been quantified.\nThus, this study aims to investigate the existence of EV-induced MS and explore\nthe potential factors leading to it. A survey study was conducted to collect\npassengers' MS experience in EVs and FVs in the past one year. In total, 639\nvalid responses were collected from mainland China. The results show that FVs\nwere associated with a higher frequency of MS, while EVs were found to induce\nmore severe MS symptoms. Further, we found that passengers' MS severity was\nassociated with individual differences (i.e., age, gender, sleep habits,\nsusceptibility to motion-induced MS), in-vehicle activities (i.e., chatting\nwith others and watching in-vehicle displays), and road conditions (i.e.,\ncongestion and slope), while the MS frequency was associated with the vehicle\nownership and riding frequency. The results from this study can guide the\ndirections of future empirical studies that aim to quantify the inducers of MS\nin EVs and FVs, as well as the optimization of EVs to reduce MS."}
{"id": "2506.23826", "pdf": "https://arxiv.org/pdf/2506.23826", "abs": "https://arxiv.org/abs/2506.23826", "authors": ["Lluís C. Coll", "Martin W. Lauer-Schmaltz", "Philip Cash", "John P. Hansen", "Anja Maier"], "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins", "categories": ["cs.ET", "cs.AI", "cs.CY", "cs.HC", "cs.IR"], "comment": "24 pages, 9 figures", "summary": "Human Digital Twins (HDTs) have traditionally been conceptualized as\ndata-driven models designed to support decision-making across various domains.\nHowever, recent advancements in conversational AI open new possibilities for\nHDTs to function as authentic, interactive digital counterparts of individuals.\nThis paper introduces a novel HDT system architecture that integrates large\nlanguage models with dynamically updated personal data, enabling it to mirror\nan individual's conversational style, memories, and behaviors. To achieve this,\nour approach implements context-aware memory retrieval, neural\nplasticity-inspired consolidation, and adaptive learning mechanisms, creating a\nmore natural and evolving digital persona. The resulting system does not only\nreplicate an individual's unique conversational style depending on who they are\nspeaking with, but also enriches responses with dynamically captured personal\nexperiences, opinions, and memories. While this marks a significant step toward\ndeveloping authentic virtual counterparts, it also raises critical ethical\nconcerns regarding privacy, accountability, and the long-term implications of\npersistent digital identities. This study contributes to the field of HDTs by\ndescribing our novel system architecture, demonstrating its capabilities, and\ndiscussing future directions and emerging challenges to ensure the responsible\nand ethical development of HDTs."}
{"id": "2506.23901", "pdf": "https://arxiv.org/pdf/2506.23901", "abs": "https://arxiv.org/abs/2506.23901", "authors": ["Yannik Stradmann", "Joscha Ilmberger", "Eric Müller", "Johannes Schemmel"], "title": "Sustainable operation of research infrastructure for novel computing", "categories": ["cs.AR"], "comment": null, "summary": "Novel compute systems are an emerging research topic, aiming towards building\nnext-generation compute platforms. For these systems to thrive, they need to be\nprovided as research infrastructure to allow acceptance and usage by a large\ncommunity. By the example of the neuromorphic BrainScaleS-2 system, we showcase\nthe transformation from a laboratory setup to a sustainable, publicly available\nplatform. It is embedded into a purpose-built institute, tightly coupling a\nconventional cluster with novel compute hardware. The network infrastructure is\noptimized for robust operation, even in the case of unintended behavior of\nindividual devices. The systems themselves are packaged into 19-inch compatible\nunits to allow for easy maintenance and extension. We operate the platform\nusing modern CI/CD techniques and continuously assert its health using\nautomated system monitoring. Finally, we share our lessons learned during the\ndecade-long endeavor of operating analog neuromorphic systems as a publicly\navailable research platform."}
{"id": "2506.22773", "pdf": "https://arxiv.org/pdf/2506.22773", "abs": "https://arxiv.org/abs/2506.22773", "authors": ["Yanran Wu", "Inez Hua", "Yi Ding"], "title": "Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing", "categories": ["cs.DC", "cs.AR", "cs.CY", "cs.LG"], "comment": "7 pages, 9 figures, HotCarbon '25: Proceedings of the 4th Workshop on\n  Sustainable Computer Systems, Cambridge, Massachusetts (USA), July 10-11th,\n  2025", "summary": "Water consumption is an increasingly critical dimension of computing\nsustainability, especially as AI workloads rapidly scale. However, current\nwater impact assessment often overlooks where and when water stress is more\nsevere. To fill in this gap, we present SCARF, the first general framework that\nevaluates water impact of computing by factoring in both spatial and temporal\nvariations in water stress. SCARF calculates an Adjusted Water Impact (AWI)\nmetric that considers both consumption volume and local water stress over time.\nThrough three case studies on LLM serving, datacenters, and semiconductor\nfabrication plants, we show the hidden opportunities for reducing water impact\nby optimizing location and time choices, paving the way for water-sustainable\ncomputing. The code is available at https://github.com/jojacola/SCARF."}
{"id": "2506.24072", "pdf": "https://arxiv.org/pdf/2506.24072", "abs": "https://arxiv.org/abs/2506.24072", "authors": ["R Ramanujam", "Vaishnavi Sundararajan", "S P Suresh"], "title": "Protocol insecurity with finitely many sessions and XOR", "categories": ["cs.LO", "cs.CR"], "comment": null, "summary": "We present a different proof of the insecurity problem for XOR, solved in by\nChevalier, Kuesters, Rusinowitch and Turuani (2005). Our proof uses the notion\nof typed terms and well-typed proofs, and removes a restriction on the class of\nprotocols to which the [CKRT05] proof applies, by introducing a slightly\ndifferent (but very natural) notion of protocols, where honest agent sends are\nderivable from previous receives in the same session."}
{"id": "2506.23092", "pdf": "https://arxiv.org/pdf/2506.23092", "abs": "https://arxiv.org/abs/2506.23092", "authors": ["Arisa Cowe", "Tyson Neuroth", "Qi Wu", "Martin Rieth", "Jacqueline Chen", "Myoungkyu Lee", "Kwan-Liu Ma"], "title": "Glyph-Based Multiscale Visualization of Turbulent Multi-Physics Statistics", "categories": ["cs.GR", "cs.HC"], "comment": "15 pages (13 pages without references)", "summary": "Many scientific and engineering problems involving multi-physics span a wide\nrange of scales. Understanding the interactions across these scales is\nessential for fully comprehending such complex problems. However, visualizing\nmultivariate, multiscale data within an integrated view where correlations\nacross space, scales, and fields are easily perceived remains challenging. To\naddress this, we introduce a novel local spatial statistical visualization of\nflow fields across multiple fields and turbulence scales. Our method leverages\nthe curvelet transform for scale decomposition of fields of interest, a\nlevel-set-restricted centroidal Voronoi tessellation to partition the spatial\ndomain into local regions for statistical aggregation, and a set of glyph\ndesigns that combines information across scales and fields into a single, or\nreduced set of perceivable visual representations. Each glyph represents data\naggregated within a Voronoi region and is positioned at the Voronoi site for\ndirect visualization in a 3D view centered around flow features of interest. We\nimplement and integrate our method into an interactive visualization system\nwhere the glyph-based technique operates in tandem with linked 3D spatial views\nand 2D statistical views, supporting a holistic analysis. We demonstrate with\ncase studies visualizing turbulent combustion data--multi-scalar compressible\nflows--and turbulent incompressible channel flow data. This new capability\nenables scientists to better understand the interactions between multiple\nfields and length scales in turbulent flows."}
{"id": "2506.22752", "pdf": "https://arxiv.org/pdf/2506.22752", "abs": "https://arxiv.org/abs/2506.22752", "authors": ["Havvanur Dervişoğlu", "Ruşen Halepmollası", "Elif Eyvaz"], "title": "Privacy-Preserving Methods for Bug Severity Prediction", "categories": ["cs.SE"], "comment": null, "summary": "Bug severity prediction is a critical task in software engineering as it\nenables more efficient resource allocation and prioritization in software\nmaintenance. While AI-based analyses and models significantly require access to\nextensive datasets, industrial applications face challenges due to data-sharing\nconstraints and the limited availability of labeled data. In this study, we\ninvestigate method-level bug severity prediction using source code metrics and\nLarge Language Models (LLMs) with two widely used datasets. We compare the\nperformance of models trained using centralized learning, federated learning,\nand synthetic data generation. Our experimental results, obtained using two\nwidely recognized software defect datasets, indicate that models trained with\nfederated learning and synthetic data achieve comparable results to centrally\ntrained models without data sharing. Our finding highlights the potential of\nprivacy-preserving approaches such as federated learning and synthetic data\ngeneration to enable effective bug severity prediction in industrial context\nwhere data sharing is a major challenge.\n  The source code and dataset are available at our GitHub repository:\nhttps://github.com/drvshavva/EASE2025-Privacy-Preserving-Methods-for-Bug-Severity-Prediction."}
{"id": "2506.22926", "pdf": "https://arxiv.org/pdf/2506.22926", "abs": "https://arxiv.org/abs/2506.22926", "authors": ["Qixuan Liu", "Shi Qiu", "Yinqiao Wang", "Xiwen Wu", "Kenneth Siu Ho Chok", "Chi-Wing Fu", "Pheng-Ann Heng"], "title": "Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions", "categories": ["cs.HC", "cs.GR", "cs.MM"], "comment": "IEEE VIS 2025 Short Paper", "summary": "Volumetric medical imaging technologies produce detailed 3D representations\nof anatomical structures. However, effective medical data visualization and\nexploration pose significant challenges, especially for individuals with\nlimited medical expertise. We introduce a novel XR-based system with two key\ninnovations: (1) a coordinated visualization module integrating Multi-layered\nMulti-planar Reconstruction with 3D mesh models and (2) a multimodal\ninteraction framework combining hand gestures with LLM-enabled voice commands.\nWe conduct preliminary evaluations, including a 15-participant user study and\nexpert interviews, to demonstrate the system's abilities to enhance spatial\nunderstanding and reduce cognitive load. Experimental results show notable\nimprovements in task completion times, usability metrics, and interaction\neffectiveness enhanced by LLM-driven voice control. While identifying areas for\nfuture refinement, our findings highlight the potential of this immersive\nvisualization system to advance medical training and clinical practice. Our\ndemo application and supplemental materials are available for download at:\nhttps://osf.io/bpjq5/."}
{"id": "2506.22480", "pdf": "https://arxiv.org/pdf/2506.22480", "abs": "https://arxiv.org/abs/2506.22480", "authors": ["Mariam Yahya", "Aydin Sezgin", "Setareh Maghsudi"], "title": "Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits", "categories": ["cs.NI", "cs.DC", "cs.LG"], "comment": null, "summary": "As users in small cell networks increasingly rely on computation-intensive\nservices, cloud-based access often results in high latency. Multi-access edge\ncomputing (MEC) mitigates this by bringing computational resources closer to\nend users, with small base stations (SBSs) serving as edge servers to enable\nlow-latency service delivery. However, limited edge capacity makes it\nchallenging to decide which services to deploy locally versus in the cloud,\nespecially under unknown service demand and dynamic network conditions. To\ntackle this problem, we model service demand as a linear function of service\nattributes and formulate the service placement task as a linear bandit problem,\nwhere SBSs act as agents and services as arms. The goal is to identify the\nservice that, when placed at the edge, offers the greatest reduction in total\nuser delay compared to cloud deployment. We propose a distributed and adaptive\nmulti-agent best-arm identification (BAI) algorithm under a fixed-confidence\nsetting, where SBSs collaborate to accelerate learning. Simulations show that\nour algorithm identifies the optimal service with the desired confidence and\nachieves near-optimal speedup, as the number of learning rounds decreases\nproportionally with the number of SBSs. We also provide theoretical analysis of\nthe algorithm's sample complexity and communication overhead."}
{"id": "2506.23281", "pdf": "https://arxiv.org/pdf/2506.23281", "abs": "https://arxiv.org/abs/2506.23281", "authors": ["Xintong Zhou", "Zhenyang Xu", "Chengnian Sun"], "title": "On the Feasibility of Deduplicating Compiler Bugs with Bisection", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Random testing has proven to be an effective technique for compiler\nvalidation. However, the debugging of bugs identified through random testing\npresents a significant challenge due to the frequent occurrence of duplicate\ntest programs that expose identical compiler bugs. The process to identify\nduplicates is a practical research problem known as bug deduplication. Prior\nmethodologies for compiler bug deduplication primarily rely on program analysis\nto extract bug-related features for duplicate identification, which can result\nin substantial computational overhead and limited generalizability. This paper\ninvestigates the feasibility of employing bisection, a standard debugging\nprocedure largely overlooked in prior research on compiler bug deduplication,\nfor this purpose. Our study demonstrates that the utilization of bisection to\nlocate failure-inducing commits provides a valuable criterion for\ndeduplication, albeit one that requires supplementary techniques for more\naccurate identification. Building on these results, we introduce BugLens, a\nnovel deduplication method that primarily uses bisection, enhanced by the\nidentification of bug-triggering optimizations to minimize false negatives.\nEmpirical evaluations conducted on four real-world datasets demonstrate that\nBugLens significantly outperforms the state-of-the-art analysis-based\nmethodologies Tamer and D3 by saving an average of 26.98% and 9.64% human\neffort to identify the same number of distinct bugs. Given the inherent\nsimplicity and generalizability of bisection, it presents a highly practical\nsolution for compiler bug deduplication in real-world applications."}
{"id": "2506.23397", "pdf": "https://arxiv.org/pdf/2506.23397", "abs": "https://arxiv.org/abs/2506.23397", "authors": ["Gaurav Sehgal", "Semih Salihoglu"], "title": "NaviX: A Native Vector Index Design for Graph DBMSs With Robust Predicate-Agnostic Search Performance", "categories": ["cs.IR", "cs.DB"], "comment": null, "summary": "There is an increasing demand for extending existing DBMSs with vector\nindices so that they become unified systems capable of supporting modern\npredictive applications, which require joint querying of vector embeddings\ntogether with the structured properties and connections of objects. We present\nNaviX, a native vector index for graph DBMSs (GDBMSs) that has two main design\ngoals. First, we aim to implement a disk-based vector index that leverages the\ncore storage and query-processing capabilities of the underlying GDBMS. To this\nend, NaviX is built on the Hierarchical Navigable Small-World (HNSW) graph,\nwhich itself is a graph-based structure. Second, we aim to support\npredicate-agnostic filtered vector search queries, in which the k nearest\nneighbors (kNNs) of a query vector vQ are searched only within an arbitrary\nsubset S of vectors defined by an ad-hoc selection sub-query QS. We adopt a\nprefiltering approach that evaluates QS first and passes the full description\nof subset S to the kNN search operator. We study how to design a prefiltering\nsearch algorithm that remains robust under varying selectivities and under\ndifferent correlations between subset S and query vector vQ. We propose an\nadaptive algorithm that uses the local selectivity of each vector in the HNSW\ngraph to choose an appropriate heuristic at every iteration of the kNN search.\nFinally, We demonstrate NaviX's robustness and efficiency through extensive\nexperiments against both existing prefiltering- and postfiltering-based\nbaselines."}
{"id": "2506.22741", "pdf": "https://arxiv.org/pdf/2506.22741", "abs": "https://arxiv.org/abs/2506.22741", "authors": ["Akshay Nayak Kolgar", "Yash Prakash", "Sampath Jayarathna", "Hae-Na Lee", "Vikas Ashok"], "title": "Insights in Adaptation: Examining Self-reflection Strategies of Job Seekers with Visual Impairments in India", "categories": ["cs.HC"], "comment": null, "summary": "Significant changes in the digital employment landscape, driven by rapid\ntechnological advancements and the COVID-19 pandemic, have introduced new\nopportunities for blind and visually impaired (BVI) individuals in developing\ncountries like India. However, a significant portion of the BVI population in\nIndia remains unemployed despite extensive accessibility advancements and job\nsearch interventions. Therefore, we conducted semi-structured interviews with\n20 BVI persons who were either pursuing or recently sought employment in the\ndigital industry. Our findings reveal that despite gaining digital literacy and\nextensive training, BVI individuals struggle to meet industry requirements for\nfulfilling job openings. While they engage in self-reflection to identify\nshortcomings in their approach and skills, they lack constructive feedback from\npeers and recruiters. Moreover, the numerous job intervention tools are limited\nin their ability to meet the unique needs of BVI job seekers. Our results\ntherefore provide key insights that inform the design of future collaborative\nintervention systems that offer personalized feedback for BVI individuals,\neffectively guiding their self-reflection process and subsequent job search\nbehaviors, and potentially leading to improved employment outcomes."}
{"id": "2506.22476", "pdf": "https://arxiv.org/pdf/2506.22476", "abs": "https://arxiv.org/abs/2506.22476", "authors": ["A. Subedi", "S. De", "L. Cavuoto", "S. Schwaitzberg", "M. Hackett", "J. Norfleet"], "title": "An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals", "categories": ["eess.SP", "cs.ET", "cs.HC", "cs.LG", "q-bio.NC", "I.2.6; J.3; H.1.2"], "comment": null, "summary": "Objective skill assessment in high-stakes procedural environments requires\nmodels that not only decode underlying cognitive and motor processes but also\ngeneralize across tasks, individuals, and experimental contexts. While prior\nwork has demonstrated the potential of functional near-infrared spectroscopy\n(fNIRS) for evaluating cognitive-motor performance, existing approaches are\noften task-specific, rely on extensive preprocessing, and lack robustness to\nnew procedures or conditions. Here, we introduce an interpretable\ntransformer-based foundation model trained on minimally processed fNIRS signals\nfor cross-procedural skill assessment. Pretrained using self-supervised\nlearning on data from laparoscopic surgical tasks and endotracheal intubation\n(ETI), the model achieves greater than 88% classification accuracy on all\ntasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It\ngeneralizes to a novel emergency airway procedure--cricothyrotomy--using fewer\nthan 30 labeled samples and a lightweight (less than 2k parameter) adapter\nmodule, attaining an AUC greater than 87%. Interpretability is achieved via a\nnovel channel attention mechanism--developed specifically for fNIRS--that\nidentifies functionally coherent prefrontal sub-networks validated through\nablation studies. Temporal attention patterns align with task-critical phases\nand capture stress-induced changes in neural variability, offering insight into\ndynamic cognitive states."}
{"id": "2506.22702", "pdf": "https://arxiv.org/pdf/2506.22702", "abs": "https://arxiv.org/abs/2506.22702", "authors": ["Zina Mohamed", "Ammar B. Kouki", "Sonia Aïssa"], "title": "A Correlation-Based Design of RIS for Reduced Power Consumption and Simplified Control Circuitry", "categories": ["eess.SY", "cs.AR", "cs.SY", "eess.SP"], "comment": null, "summary": "Aiming at simplifying the hardware structure and reducing the energy\nconsumption in wireless communication via reconfigurable intelligent surfaces\n(RIS), this paper introduces a novel RIS design founded on the correlation\nbetween the phase shift values of the surface elements. First, a correlation\nanalysis is conducted, considering the azimuth angle of a target device within\na coverage region spanning from $-80^{\\circ}$ to $80^{\\circ}$. The correlation\nis demonstrated for different deployment cases, creating the basis for the new\nRIS structure, termed Connected-RIS, where correlated elements are designed to\nshare the same control signal. The fundamental performance of the proposed\ndesign is then analyzed in terms of control signals, power consumption, and\ncommunication system performance, comparing it to two RIS structures with full\ncontrol: one with the same size as the proposed design, and the other employing\nthe minimum number of elements necessary to satisfy the fair coverage\ncriterion. The correlation-based RIS design enables three-dimensional passive\nbeamforming and significantly reduces the number of required load impedances\nand control signals, thereby lowering the hardware cost and simplifying the\ncontrol circuitry. It also achieves substantial power savings as compared to\nthe baseline schemes, while maintaining sufficient gain for a fair radio\ncoverage. For instance, numerical simulations demonstrate that the proposed\ndesign reduces the power consumption by almost 86-92\\% and the control signals\nby 83-98\\% compared to operation with fully controlled RIS."}
{"id": "2506.22818", "pdf": "https://arxiv.org/pdf/2506.22818", "abs": "https://arxiv.org/abs/2506.22818", "authors": ["Stanislav Sedukhin", "Yoichi Tomioka", "Kazuya Matsumoto", "Yuichi Okuyama"], "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.ET", "eess.SP", "C.1.4; C.3; F.2.1; G.1.3; G.4"], "comment": "19 pages, 5 figures", "summary": "Multilinear transformations are key in high-performance computing (HPC) and\nartificial intelligence (AI) workloads, where data is represented as tensors.\nHowever, their high computational and memory demands, which grow with\ndimensionality, often slow down critical tasks. Moreover, scaling computation\nby enlarging the number of parallel processing units substantially increases\nenergy consumption, limiting widespread adoption, especially for sparse data,\nwhich is common in HPC and AI applications. This paper introduces the Trilinear\nAlgorithm and isomorphic to algorithm Device Architecture (TriADA) to address\nthese challenges with the following innovations: (1) a massively parallel,\nlow-rank algorithm for computing a family of trilinear (3D) discrete orthogonal\ntransformations (3D-DXTs), which is a special case of the more general 3-mode\nmatrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM\nkernel with decoupled streaming active memory, specially designed to accelerate\n3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully\ndistributed 3D network of mesh interconnected processing elements or cells with\na coordinate-free, data-driven local processing activity, which is independent\nof problem size; (4) an elastic sparse outer-product (ESOP) method that avoids\nunnecessary computing and communication operations with zero-valued operands,\nthereby enhancing energy efficiency, computational accuracy, and stability.\nTriADA is capable of performing a variety of trilinear transformations with\nhypercubic arithmetic complexity in a linear number of time-steps. The\nmassively parallel, scalable, and energy-efficient architecture of TriADA is\nideal for accelerating multilinear tensor operations, which are the most\ndemanding parts of AI and HPC workloads."}
{"id": "2506.22693", "pdf": "https://arxiv.org/pdf/2506.22693", "abs": "https://arxiv.org/abs/2506.22693", "authors": ["Andreu Ballus Santacana"], "title": "Universal Gluing and Contextual Choice: Categorical Logic and the Foundations of Analytic Approximation", "categories": ["math.FA", "cs.LO", "math.LO", "03F65, 03B30, 46E35, 68Q55", "F.4.1; G.1.2; F.3.1"], "comment": "Submitted to Inventiones Mathematicae. Patent pending on associated\n  certification algorithms and formal verification methods. 22 pages + 7 pages\n  app", "summary": "We introduce a new categorical and constructive foundation for analytic\napproximation based on a Contextual Choice Principle (CCP), which enforces\nlocality and compatibility in the construction of mathematical objects. Central\nto our approach is the Universal Embedding and Linear Approximation Theorem\n(UELAT), which establishes that functions in broad spaces -- including C(K),\nSobolev spaces W^{k,p}(Omega), and distributions D'(Omega) -- can be explicitly\napproximated by finite-rank linear projections, each with a constructive,\nalgorithmically verifiable certificate of accuracy.\n  These constructions are governed categorically by a functorial adjunction\nbetween local logical probes and analytic models, making analytic existence\nboth formally certifiable and programmatically extractable. As a key result, we\nprove a uniform certificate stability theorem, ensuring that approximation\ncertificates persist under uniform convergence.\n  The CCP avoids classical pathologies (e.g., non-measurable sets,\nBanach--Tarski paradoxes) by eliminating non-constructive choice and replacing\nit with a coherent, local-to-global semantic logic. Our framework strengthens\nthe foundations of constructive analysis while contributing tools relevant to\nformal verification, type-theoretic proof systems, and computational\nmathematics."}
{"id": "2506.23364", "pdf": "https://arxiv.org/pdf/2506.23364", "abs": "https://arxiv.org/abs/2506.23364", "authors": ["Patrick Komon", "Gerald Kimmersdorfer", "Adam Celarek", "Manuela Waldner"], "title": "Data-Driven Compute Overlays for Interactive Geographic Simulation and Visualization", "categories": ["cs.GR"], "comment": null, "summary": "We present interactive data-driven compute overlays for native and web-based\n3D geographic map applications based on WebGPU. Our data-driven overlays are\ngenerated in a multi-step compute workflow from multiple data sources on the\nGPU. We demonstrate their potential by showing results from snow cover and\navalanche simulations, where simulation parameters can be adjusted\ninteractively and results are visualized instantly. Benchmarks show that our\napproach can compute large-scale avalanche simulations in milliseconds to\nseconds, depending on the size of the terrain and the simulation parameters,\nwhich is multiple orders of magnitude faster than a state-of-the-art Python\nimplementation."}
{"id": "2506.22776", "pdf": "https://arxiv.org/pdf/2506.22776", "abs": "https://arxiv.org/abs/2506.22776", "authors": ["Sen Fang", "Weiyuan Ding", "Antonio Mastropaolo", "Bowen Xu"], "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": "13 pages, 6 figures", "summary": "Quantization has emerged as a mainstream method for compressing Large\nLanguage Models (LLMs), reducing memory requirements and accelerating inference\nwithout architectural modifications. While existing research primarily focuses\non evaluating the effectiveness of quantized LLMs compared to their original\ncounterparts, the impact on robustness remains largely unexplored.In this\npaper, we present the first systematic investigation of how quantization\naffects the robustness of LLMs in code generation tasks. Through extensive\nexperiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and\nStarCoder) with parameter scales ranging from 350M to 33B, we evaluate\nrobustness from dual perspectives: adversarial attacks on input prompts and\nnoise perturbations on model architecture. Our findings challenge conventional\nwisdom by demonstrating that quantized LLMs often exhibit superior robustness\ncompared to their full-precision counterparts, with 51.59% versus 42.86% of our\nadversarial experiments showing better resilience in quantized LLMs. Similarly,\nour noise perturbation experiments also confirm that LLMs after quantitation\ngenerally withstand higher levels of weight disturbances. These results suggest\nthat quantization not only reduces computational requirements but can actually\nenhance LLMs' reliability in code generation tasks, providing valuable insights\nfor developing more robust and efficient LLM deployment strategies."}
{"id": "2506.22967", "pdf": "https://arxiv.org/pdf/2506.22967", "abs": "https://arxiv.org/abs/2506.22967", "authors": ["Amir Aghdam", "Vincent Tao Hu"], "title": "ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment", "categories": ["cs.CV", "cs.LG", "cs.MM", "I.2.10; I.2.7"], "comment": "Preprint manuscript - Project page:\n  https://github.com/aghdamamir/act-align", "summary": "We address the task of zero-shot fine-grained video classification, where no\nvideo examples or temporal annotations are available for unseen action classes.\nWhile contrastive vision-language models such as SigLIP demonstrate strong\nopen-set recognition via mean-pooled image-text similarity, they fail to\ncapture the temporal structure critical for distinguishing fine-grained\nactivities. We introduce ActAlign, a zero-shot framework that formulates video\nclassification as sequence alignment. For each class, a large language model\ngenerates an ordered sub-action sequence, which is aligned with video frames\nusing Dynamic Time Warping (DTW) in a shared embedding space. Without any\nvideo-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the\nextremely challenging ActionAtlas benchmark, where human accuracy is only\n61.6%. ActAlign outperforms billion-parameter video-language models while using\napproximately 8x less parameters. These results demonstrate that structured\nlanguage priors, combined with classical alignment techniques, offer a scalable\nand general approach to unlocking the open-set recognition potential of\nvision-language models for fine-grained video understanding."}
{"id": "2506.22482", "pdf": "https://arxiv.org/pdf/2506.22482", "abs": "https://arxiv.org/abs/2506.22482", "authors": ["Divya Alok Gupta", "Dwith Chenna", "B. Aditya Vighnesh Ramakanth"], "title": "Wireless Home Automation Using Social Networking Websites", "categories": ["cs.NI", "cs.CR", "cs.CV"], "comment": "20th Annual International Conference on Advanced Computing and\n  Communications (ADCOM) 2014", "summary": "With the advent of Internet of Things, Wireless Home Automation Systems WHAS\nare gradually gaining popularity. These systems are faced with multiple\nchallenges such as security; controlling a variety of home appliances with a\nsingle interface and user friendliness. In this paper we propose a system that\nuses secure authentication systems of social networking websites such as\nTwitter, tracks the end-users activities on the social network and then control\nhis or her domestic appliances. At the end, we highlight the applications of\nthe proposed WHAS and compare the advantages of our proposed system over\ntraditional home automation systems."}
{"id": "2506.23696", "pdf": "https://arxiv.org/pdf/2506.23696", "abs": "https://arxiv.org/abs/2506.23696", "authors": ["Francisco Oliveira", "Alexandra Mendes", "Carolina Carreira"], "title": "What Challenges Do Developers Face When Using Verification-Aware Programming Languages?", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Software reliability is critical in ensuring that the digital systems we\ndepend on function correctly. In software development, increasing software\nreliability often involves testing. However, for complex and critical systems,\ndevelopers can use Design by Contract (DbC) methods to define precise\nspecifications that software components must satisfy. Verification-Aware (VA)\nprogramming languages support DbC and formal verification at compile-time or\nrun-time, offering stronger correctness guarantees than traditional testing.\nHowever, despite the strong guarantees provided by VA languages, their adoption\nremains limited. In this study, we investigate the barriers to adopting VA\nlanguages by analyzing developer discussions on public forums using topic\nmodeling techniques. We complement this analysis with a developer survey to\nbetter understand the practical challenges associated with VA languages. Our\nfindings reveal key obstacles to adoption, including steep learning curves and\nusability issues. Based on these insights, we identify actionable\nrecommendations to improve the usability and accessibility of VA languages. Our\nfindings suggest that simplifying tool interfaces, providing better educational\nmaterials, and improving integration with everyday development environments\ncould improve the usability and adoption of these languages. Our work provides\nactionable insights for improving the usability of VA languages and making\nverification tools more accessible."}
{"id": "2506.23985", "pdf": "https://arxiv.org/pdf/2506.23985", "abs": "https://arxiv.org/abs/2506.23985", "authors": ["Mohamed Sami Rakha", "Adam Sorrenti", "Greg Stager", "Walid Rjaibi", "Andriy Miranskyy"], "title": "Lock Prediction for Zero-Downtime Database Encryption", "categories": ["cs.CR", "cs.DB"], "comment": null, "summary": "Modern enterprise database systems face significant challenges in balancing\ndata security and performance. Ensuring robust encryption for sensitive\ninformation is critical for systems' compliance with security standards.\nAlthough holistic database encryption provides strong protection, existing\ndatabase systems often require a complete backup and restore cycle, resulting\nin prolonged downtime and increased storage usage. This makes it difficult to\nimplement online encryption techniques in high-throughput environments without\ndisrupting critical operations.\n  To address this challenge, we envision a solution that enables online\ndatabase encryption aligned with system activity, eliminating the need for\ndowntime, storage overhead, or full-database reprocessing. Central to this\nvision is the ability to predict which parts of the database will be accessed\nnext, allowing encryption to be applied online. As a step towards this\nsolution, this study proposes a predictive approach that leverages deep\nlearning models to forecast database lock sequences, using IBM Db2 as the\ndatabase system under study. In this study, we collected a specialized dataset\nfrom TPC-C benchmark workloads, leveraging lock event logs for model training\nand evaluation. We applied deep learning architectures, such as Transformer and\nLSTM, to evaluate models for various table-level and page-level lock\npredictions. We benchmark the accuracy of the trained models versus a Naive\nBaseline across different prediction horizons and timelines.\n  The study experiments demonstrate that the proposed deep learning-based\nmodels achieve up to 49% average accuracy for table-level and 66% for\npage-level predictions, outperforming a Naive Baseline. By anticipating which\ntables and pages will be locked next, the proposed approach is a step toward\nonline encryption, offering a practical path toward secure, low-overhead\ndatabase systems."}
{"id": "2506.22815", "pdf": "https://arxiv.org/pdf/2506.22815", "abs": "https://arxiv.org/abs/2506.22815", "authors": ["Haichang Li"], "title": "Memory as a Service (MaaS): Rethinking Contextual Memory as Service-Oriented Modules for Collaborative Agents", "categories": ["cs.HC", "H.5.0"], "comment": "Position Paper for workshop. This is an initial version for\n  discussion purposes", "summary": "This position paper aims to rethink the role and design of memory in Large\nLanguage Model (LLM)-based agent systems. We observe that while current memory\npractices have begun to transcend the limitations of single interactions, they\nremain conceptually grounded in \"bound memory\" in terms of design concept-where\nmemory is treated as local state attached to specific context or entities,\nforming \"memory silos\" that impede cross-entity collaboration. To overcome this\narchitectural bottleneck, this paper proposes the timely design perspective of\n\"Memory as a Service\" (MaaS). MaaS advocates decoupling memory from its\nconventional role as an interaction byproduct and encapsulating it as a modular\nservice that can be independently callable, dynamically composable, and finely\ngoverned. At its core, MaaS leverages the duality of memory-its inherently\nprivate nature and its potential for public service-to grant memory controlled,\non-demand interoperability across entities. This paper introduces a\ntwo-dimensional design space defined by entity structure and service type,\nillustrating how MaaS aligns with current memory practices while naturally\nextending them to cross-entity collaborative scenarios. Finally, we outline an\nopen research agenda spanning governance, security, and ethical ecosystems, and\ncall upon the broader research community to explore this shift toward\nservice-oriented memory for collaborative agents operating across entity\nboundaries."}
{"id": "2506.22477", "pdf": "https://arxiv.org/pdf/2506.22477", "abs": "https://arxiv.org/abs/2506.22477", "authors": ["Huiwen Han"], "title": "Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.RO"], "comment": "Published in: 2024 6th International Conference on Robotics,\n  Intelligent Control and Artificial Intelligence (RICAI), IEEE Xplore, DOI:\n  10.1109/RICAI64321.2024.10911316. \\c{opyright} 2024 IEEE", "summary": "This paper introduces an innovative design for robotic operating platforms,\nunderpinned by a transformative Internet of Things (IoT) architecture,\nseamlessly integrating cutting-edge technologies such as large language models\n(LLMs), generative AI, edge computing, and 5G networks. The proposed platform\naims to elevate the intelligence and autonomy of IoT systems and robotics,\nenabling them to make real-time decisions and adapt dynamically to changing\nenvironments. Through a series of compelling case studies across industries\nincluding smart manufacturing, healthcare, and service sectors, this paper\ndemonstrates the substantial potential of IoT-enabled robotics to optimize\noperational workflows, enhance productivity, and deliver innovative, scalable\nsolutions. By emphasizing the roles of LLMs and generative AI, the research\nhighlights how these technologies drive the evolution of intelligent robotics\nand IoT, shaping the future of industry-specific advancements. The findings not\nonly showcase the transformative power of these technologies but also offer a\nforward-looking perspective on their broader societal and industrial\nimplications, positioning them as catalysts for next-generation automation and\ntechnological convergence."}
{"id": "2506.22773", "pdf": "https://arxiv.org/pdf/2506.22773", "abs": "https://arxiv.org/abs/2506.22773", "authors": ["Yanran Wu", "Inez Hua", "Yi Ding"], "title": "Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing", "categories": ["cs.DC", "cs.AR", "cs.CY", "cs.LG"], "comment": "7 pages, 9 figures, HotCarbon '25: Proceedings of the 4th Workshop on\n  Sustainable Computer Systems, Cambridge, Massachusetts (USA), July 10-11th,\n  2025", "summary": "Water consumption is an increasingly critical dimension of computing\nsustainability, especially as AI workloads rapidly scale. However, current\nwater impact assessment often overlooks where and when water stress is more\nsevere. To fill in this gap, we present SCARF, the first general framework that\nevaluates water impact of computing by factoring in both spatial and temporal\nvariations in water stress. SCARF calculates an Adjusted Water Impact (AWI)\nmetric that considers both consumption volume and local water stress over time.\nThrough three case studies on LLM serving, datacenters, and semiconductor\nfabrication plants, we show the hidden opportunities for reducing water impact\nby optimizing location and time choices, paving the way for water-sustainable\ncomputing. The code is available at https://github.com/jojacola/SCARF."}
{"id": "2506.22884", "pdf": "https://arxiv.org/pdf/2506.22884", "abs": "https://arxiv.org/abs/2506.22884", "authors": ["Praveen Kumar Donta", "Qiyang Zhang", "Schahram Dustdar"], "title": "Performance Measurements in the AI-Centric Computing Continuum Systems", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "Over the Eight decades, computing paradigms have shifted from large,\ncentralized systems to compact, distributed architectures, leading to the rise\nof the Distributed Computing Continuum (DCC). In this model, multiple layers\nsuch as cloud, edge, Internet of Things (IoT), and mobile platforms work\ntogether to support a wide range of applications. Recently, the emergence of\nGenerative AI and large language models has further intensified the demand for\ncomputational resources across this continuum. Although traditional performance\nmetrics have provided a solid foundation, they need to be revisited and\nexpanded to keep pace with changing computational demands and application\nrequirements. Accurate performance measurements benefit both system designers\nand users by supporting improvements in efficiency and promoting alignment with\nsystem goals. In this context, we review commonly used metrics in DCC and IoT\nenvironments. We also discuss emerging performance dimensions that address\nevolving computing needs, such as sustainability, energy efficiency, and system\nobservability. We also outline criteria and considerations for selecting\nappropriate metrics, aiming to inspire future research and development in this\ncritical area."}
{"id": "2506.22991", "pdf": "https://arxiv.org/pdf/2506.22991", "abs": "https://arxiv.org/abs/2506.22991", "authors": ["Mehdi Bennis", "Sumudu Samarakoon", "Tamara Alshammari", "Chathuranga Weeraddana", "Zhoujun Tian", "Chaouki Ben Issaid"], "title": "Resilient-Native and Intelligent Next-Generation Wireless Systems: Key Enablers, Foundations, and Applications", "categories": ["cs.NI", "cs.LO", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "Just like power, water, and transportation systems, wireless networks are a\ncrucial societal infrastructure. As natural and human-induced disruptions\ncontinue to grow, wireless networks must be resilient. This requires them to\nwithstand and recover from unexpected adverse conditions, shocks, unmodeled\ndisturbances and cascading failures. Unlike robustness and reliability,\nresilience is based on the understanding that disruptions will inevitably\nhappen. Resilience, as elasticity, focuses on the ability to bounce back to\nfavorable states, while resilience as plasticity involves agents and networks\nthat can flexibly expand their states and hypotheses through real-time\nadaptation and reconfiguration. This situational awareness and active\npreparedness, adapting world models and counterfactually reasoning about\npotential system failures and the best responses, is a core aspect of\nresilience. This article will first disambiguate resilience from reliability\nand robustness, before delving into key mathematical foundations of resilience\ngrounded in abstraction, compositionality and emergence. Subsequently, we focus\nour attention on a plethora of techniques and methodologies pertaining to the\nunique characteristics of resilience, as well as their applications through a\ncomprehensive set of use cases. Ultimately, the goal of this paper is to\nestablish a unified foundation for understanding, modeling, and engineering\nresilience in wireless communication systems, while laying a roadmap for the\nnext-generation of resilient-native and intelligent wireless systems."}
{"id": "2506.23388", "pdf": "https://arxiv.org/pdf/2506.23388", "abs": "https://arxiv.org/abs/2506.23388", "authors": ["Crane He Chen", "Vladimir G. Kim"], "title": "Escher Tile Deformation via Closed-Form Solution", "categories": ["cs.GR", "cs.CG", "cs.MS", "math.MG"], "comment": null, "summary": "We present a real-time deformation method for Escher tiles -- interlocking\norganic forms that seamlessly tessellate the plane following symmetry rules. We\nformulate the problem as determining a periodic displacement field. The goal is\nto deform Escher tiles without introducing gaps or overlaps. The resulting\ndisplacement field is obtained in closed form by an analytical solution. Our\nmethod processes tiles of 17 wallpaper groups across various representations\nsuch as images and meshes. Rather than treating tiles as mere boundaries, we\nconsider them as textured shapes, ensuring that both the boundary and interior\ndeform simultaneously. To enable fine-grained artistic input, our interactive\ntool features a user-controllable adaptive fall-off parameter, allowing precise\nadjustment of locality and supporting deformations with meaningful semantic\ncontrol. We demonstrate the effectiveness of our method through various\nexamples, including photo editing and shape sculpting, showing its use in\napplications such as fabrication and animation."}
{"id": "2506.23014", "pdf": "https://arxiv.org/pdf/2506.23014", "abs": "https://arxiv.org/abs/2506.23014", "authors": ["Wilder Baldwin", "Shashank Chintakuntla", "Shreyah Parajuli", "Ali Pourghasemi", "Ryan Shanz", "Sepideh Ghanavati"], "title": "Generating Privacy Stories From Software Documentation", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to RENext!'25 at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Research shows that analysts and developers consider privacy as a security\nconcept or as an afterthought, which may lead to non-compliance and violation\nof users' privacy. Most current approaches, however, focus on extracting legal\nrequirements from the regulations and evaluating the compliance of software and\nprocesses with them. In this paper, we develop a novel approach based on\nchain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language\nModels (LLMs) to extract privacy behaviors from various software documents\nprior to and during software development, and then generate privacy\nrequirements in the format of user stories. Our results show that most commonly\nused LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and\ngenerate privacy user stories with F1 scores exceeding 0.8. We also show that\nthe performance of these models could be improved through parameter-tuning. Our\nfindings provide insight into using and optimizing LLMs for generating privacy\nrequirements given software documents created prior to or throughout the\nsoftware development lifecycle."}
{"id": "2506.23066", "pdf": "https://arxiv.org/pdf/2506.23066", "abs": "https://arxiv.org/abs/2506.23066", "authors": ["Jiale Meng", "Yiming Li", "Zheming Lu", "Zewei He", "Hao Luo", "Tianwei Zhang"], "title": "CoreMark: Toward Robust and Universal Text Watermarking Technique", "categories": ["cs.CV", "cs.CR", "cs.MM"], "comment": "10 pages, 16 figures", "summary": "Text watermarking schemes have gained considerable attention in recent years,\nyet still face critical challenges in achieving simultaneous robustness,\ngeneralizability, and imperceptibility. This paper introduces a new embedding\nparadigm,termed CORE, which comprises several consecutively aligned black pixel\nsegments. Its key innovation lies in its inherent noise resistance during\ntransmission and broad applicability across languages and fonts. Based on the\nCORE, we present a text watermarking framework named CoreMark. Specifically,\nCoreMark first dynamically extracts COREs from characters. Then, the characters\nwith stronger robustness are selected according to the lengths of COREs. By\nmodifying the thickness of the CORE, the hidden data is embedded into the\nselected characters without causing significant visual distortions. Moreover, a\ngeneral plug-and-play embedding strength modulator is proposed, which can\nadaptively enhance the robustness for small font sizes by adjusting the\nembedding strength according to the font size. Experimental evaluation\nindicates that CoreMark demonstrates outstanding generalizability across\nmultiple languages and fonts. Compared to existing methods, CoreMark achieves\nsignificant improvements in resisting screenshot, print-scan, and print camera\nattacks, while maintaining satisfactory imperceptibility."}
{"id": "2506.22484", "pdf": "https://arxiv.org/pdf/2506.22484", "abs": "https://arxiv.org/abs/2506.22484", "authors": ["Muhammad Kabeer", "Rosdiadee Nordin", "Mehran Behjati", "Farah Yasmin binti Mohd Shaharuddin"], "title": "An Urban Multi-Operator QoE-Aware Dataset for Cellular Networks in Dense Environments", "categories": ["cs.NI", "eess.SP"], "comment": "17 pages, 9 Figures", "summary": "Urban cellular networks face complex performance challenges due to high\ninfrastructure density, varied user mobility, and diverse service demands.\nWhile several datasets address network behaviour across different environments,\nthere is a lack of datasets that captures user centric Quality of Experience\n(QoE), and diverse mobility patterns needed for efficient network planning and\noptimization solutions, which are important for QoE driven optimizations and\nmobility management. This study presents a curated dataset of 30,925 labelled\nrecords, collected using GNetTrack Pro within a 2 km2 dense urban area,\nspanning three major commercial network operators. The dataset captures key\nsignal quality parameters (e.g., RSRP, RSRQ, SNR), across multiple real world\nmobility modes including pedestrian routes, canopy walkways, shuttle buses, and\nBus Rapid Transit (BRT) routes. It also includes diverse network traffic\nscenarios including (1) FTP upload and download, (2) video streaming, and (3)\nHTTP browsing. A total of 132 physical cell sites were identified and validated\nthrough OpenCellID and on-site field inspections, illustrating the high cell\ndensity characteristic of 5G and emerging heterogeneous network deployment. The\ndataset is particularly suited for machine learning applications, such as\nhandover optimization, signal quality prediction, and multi operator\nperformance evaluation. Released in a structured CSV format with accompanying\npreprocessing and visualization scripts, this dataset offers a reproducible,\napplication ready resource for researchers and practitioners working on urban\ncellular network planning and optimization."}
{"id": "2506.22841", "pdf": "https://arxiv.org/pdf/2506.22841", "abs": "https://arxiv.org/abs/2506.22841", "authors": ["George Bell", "Alma Cantu"], "title": "Dichoptic Opacity: Managing Occlusion in Stereoscopic Displays via Dichoptic Presentation", "categories": ["cs.HC"], "comment": "5 pages, 3 figures. Conditionally accepted to IEEE VIS 2025 (pending\n  final review)", "summary": "Adjusting transparency is a common method of mitigating occlusion but is\noften detrimental for understanding the relative depth relationships between\nobjects as well as removes potentially important information from the occluding\nobject. We propose using dichoptic opacity, a novel method for occlusion\nmanagement that contrasts the transparency of occluders presented to each eye.\nThis allows for better simultaneous understanding of both occluder and\noccluded. A user study highlights the technique's potential, showing strong\nuser engagement and a clear preference for dichoptic opacity over traditional\npresentations. While it does not determine optimal transparency values, it\nreveals promising trends in both percentage and range that merit further\ninvestigation."}
{"id": "2506.22671", "pdf": "https://arxiv.org/pdf/2506.22671", "abs": "https://arxiv.org/abs/2506.22671", "authors": ["Rubi Debnath", "Mohammadreza Barzegaran", "Sebastian Steinhorst"], "title": "Towards an Optimized Multi-Cyclic Queuing and Forwarding in Time Sensitive Networking with Time Injection", "categories": ["cs.NI", "cs.ET"], "comment": null, "summary": "Cyclic Queuing and Forwarding (CQF) is a Time-Sensitive Networking (TSN)\nshaping mechanism that provides bounded latency and deterministic Quality of\nService (QoS). However, CQF's use of a single cycle restricts its ability to\nsupport TSN traffic with diverse timing requirements. Multi-Cyclic Queuing and\nForwarding (Multi-CQF) is a new and emerging TSN shaping mechanism that uses\nmultiple cycles on the same egress port, allowing it to accommodate TSN flows\nwith varied timing requirements more effectively than CQF. Despite its\npotential, current Multi-CQF configuration studies are limited, leading to a\nlack of comprehensive research, poor understanding of the mechanism, and\nlimited adoption of Multi-CQF in practical applications. Previous work has\nshown the impact of Time Injection (TI), defined as the start time of\nTime-Triggered (TT) flows at the source node, on CQF queue resource\nutilization. However, the impact of TI has not yet been explored in the context\nof Multi-CQF. This paper introduces a set of constraints and leverages Domain\nSpecific Knowledge (DSK) to reduce the search space for Multi-CQF\nconfiguration. Building on this foundation, we develop an open-source Genetic\nAlgorithm (GA) and a hybrid GA-Simulated Annealing (GASA) approach to\nefficiently configure Multi-CQF networks and introduce TI in Multi-CQF to\nenhance schedulability. Experimental results show that our proposed algorithms\nsignificantly increase the number of scheduled TT flows compared to the\nbaseline Simulated Annealing (SA) model, improving scheduling by an average of\n15%. Additionally, GASA achieves a 20% faster convergence rate and lower time\ncomplexity, outperforming the SA model in speed, and efficiency."}
{"id": "2506.22818", "pdf": "https://arxiv.org/pdf/2506.22818", "abs": "https://arxiv.org/abs/2506.22818", "authors": ["Stanislav Sedukhin", "Yoichi Tomioka", "Kazuya Matsumoto", "Yuichi Okuyama"], "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.ET", "eess.SP", "C.1.4; C.3; F.2.1; G.1.3; G.4"], "comment": "19 pages, 5 figures", "summary": "Multilinear transformations are key in high-performance computing (HPC) and\nartificial intelligence (AI) workloads, where data is represented as tensors.\nHowever, their high computational and memory demands, which grow with\ndimensionality, often slow down critical tasks. Moreover, scaling computation\nby enlarging the number of parallel processing units substantially increases\nenergy consumption, limiting widespread adoption, especially for sparse data,\nwhich is common in HPC and AI applications. This paper introduces the Trilinear\nAlgorithm and isomorphic to algorithm Device Architecture (TriADA) to address\nthese challenges with the following innovations: (1) a massively parallel,\nlow-rank algorithm for computing a family of trilinear (3D) discrete orthogonal\ntransformations (3D-DXTs), which is a special case of the more general 3-mode\nmatrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM\nkernel with decoupled streaming active memory, specially designed to accelerate\n3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully\ndistributed 3D network of mesh interconnected processing elements or cells with\na coordinate-free, data-driven local processing activity, which is independent\nof problem size; (4) an elastic sparse outer-product (ESOP) method that avoids\nunnecessary computing and communication operations with zero-valued operands,\nthereby enhancing energy efficiency, computational accuracy, and stability.\nTriADA is capable of performing a variety of trilinear transformations with\nhypercubic arithmetic complexity in a linear number of time-steps. The\nmassively parallel, scalable, and energy-efficient architecture of TriADA is\nideal for accelerating multilinear tensor operations, which are the most\ndemanding parts of AI and HPC workloads."}
{"id": "2506.23395", "pdf": "https://arxiv.org/pdf/2506.23395", "abs": "https://arxiv.org/abs/2506.23395", "authors": ["Xiaohong Chen", "Grigore Rosu"], "title": "FastSet: Parallel Claim Settlement", "categories": ["cs.DC"], "comment": null, "summary": "FastSet is an actor-based distributed protocol for decentralized finance and\nsettlement, which is inspired from blockchains. Account holders cooperate by\nmaking claims, which can include payments, holding and transferring assets,\naccessing and updating shared data, medical records, digital identity, and\nmathematical theorems, among many others. The claims are signed by their owners\nand are broadcast to a decentralized network of validators, which validate and\nsettle them. Validators replicate the global state of the accounts and need not\ncommunicate with each other. In sharp contrast to blockchains, strong\nconsistency is purposely given up as a requirement. Yet, many if not most of\nthe blockchain benefits are preserved. The protocol is proved to be correct,\ndespite its massively parallel nature."}
{"id": "2506.23404", "pdf": "https://arxiv.org/pdf/2506.23404", "abs": "https://arxiv.org/abs/2506.23404", "authors": ["Melissa Antonelli", "Arnaud Durand", "Juha Kontinen"], "title": "Characterizing Small Circuit Classes from FAC^0 to FAC^1 via Discrete Ordinary Differential Equations", "categories": ["cs.CC", "cs.LO"], "comment": "39 pages", "summary": "In this paper, we provide a uniform framework for investigating small circuit\nclasses and bounds through the lens of ordinary differential equations (ODEs).\nFollowing an approach recently introduced to capture the class of\npolynomial-time computable functions via ODE-based recursion schemas and later\napplied to the context of functions computed by unbounded fan-in circuits of\nconstant depth (FAC^0), we study multiple relevant small circuit classes. In\nparticular, we show that natural restrictions on linearity and derivation along\nfunctions with specific growth rate correspond to kinds of functions that can\nbe proved to be in various classes, ranging from FAC^0 to FAC^1. This reveals\nan intriguing link between constraints over linear-length ODEs and circuit\ncomputation, providing new tools to tackle the complex challenge of\nestablishing bounds for classes in the circuit hierarchies and possibly\nenhancing our understanding of the role of counters in this setting.\nAdditionally, we establish several completeness results, in particular\nobtaining the first ODE-based characterizations for the classes of functions\ncomputable in constant depth with unbounded fan-in and Mod 2 gates (FACC[2])\nand in logarithmic depth with bounded fan-in Boolean gates (FNC1)."}
{"id": "2506.23406", "pdf": "https://arxiv.org/pdf/2506.23406", "abs": "https://arxiv.org/abs/2506.23406", "authors": ["Tim Gerrits"], "title": "Uncertain Mode Surfaces in 3D Symmetric Second-Order Tensor Field Ensembles", "categories": ["cs.GR"], "comment": "4 + 1 pages, 4 figures, IEEE VIS 2025", "summary": "The analysis of 3D symmetric second-order tensor fields often relies on\ntopological features such as degenerate tensor lines, neutral surfaces, and\ntheir generalization to mode surfaces, which reveal important structural\ninsights into the data. However, uncertainty in such fields is typically\nvisualized using derived scalar attributes or tensor glyph representations,\nwhich often fail to capture the global behavior. Recent advances have\nintroduced uncertain topological features for tensor field ensembles by\nfocusing on degenerate tensor locations. Yet, mode surfaces, including neutral\nsurfaces and arbitrary mode surfaces are essential to a comprehensive\nunderstanding of tensor field topology. In this work, we present a\ngeneralization of uncertain degenerate tensor features to uncertain mode\nsurfaces of arbitrary mode values, encompassing uncertain degenerate tensor\nlines as a special case. Our approach supports both surface and line\ngeometries, forming a unified framework for analyzing uncertain mode-based\ntopological features in tensor field ensembles. We demonstrate the\neffectiveness of our method on several real-world simulation datasets from\nengineering and materials science."}
{"id": "2506.23034", "pdf": "https://arxiv.org/pdf/2506.23034", "abs": "https://arxiv.org/abs/2506.23034", "authors": ["Hao Yan", "Swapneel Suhas Vaidya", "Xiaokuan Zhang", "Ziyu Yao"], "title": "Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have become powerful tools for automated code\ngeneration. However, these models often overlook critical security practices,\nwhich can result in the generation of insecure code that contains\nvulnerabilities-weaknesses or flaws in the code that attackers can exploit to\ncompromise a system. However, there has been limited exploration of strategies\nto guide LLMs in generating secure code and a lack of in-depth analysis of the\neffectiveness of LLMs in repairing code containing vulnerabilities. In this\npaper, we present a comprehensive evaluation of state-of-the-art LLMs by\nexamining their inherent tendencies to produce insecure code, their capability\nto generate secure code when guided by self-generated vulnerability hints, and\ntheir effectiveness in repairing vulnerabilities when provided with different\nlevels of feedback. Our study covers both proprietary and open-weight models\nacross various scales and leverages established benchmarks to assess a wide\nrange of vulnerability types. Through quantitative and qualitative analyses, we\nreveal that although LLMs are prone to generating insecure code, advanced\nmodels can benefit from vulnerability hints and fine-grained feedback to avoid\nor fix vulnerabilities. We also provide actionable suggestions to developers to\nreduce vulnerabilities when using LLMs for code generation."}
{"id": "2506.23151", "pdf": "https://arxiv.org/pdf/2506.23151", "abs": "https://arxiv.org/abs/2506.23151", "authors": ["Vladislav Bargatin", "Egor Chistov", "Alexander Yakovenko", "Dmitriy Vatolin"], "title": "MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted at ICCV 2025", "summary": "Recent advances in optical flow estimation have prioritized accuracy at the\ncost of growing GPU memory consumption, particularly for high-resolution\n(FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical\nflow method that identifies a favorable trade-off between multi-frame\nestimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU\nmemory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely\npositions our method to be trained at native 1080p without the need for\ncropping or downsampling. We systematically revisit design choices from\nRAFT-like architectures, integrating reduced correlation volumes and\nhigh-resolution training protocols alongside multi-frame estimation, to achieve\nstate-of-the-art performance across multiple benchmarks while substantially\nreducing memory overhead. Our method outperforms more resource-intensive\nalternatives in both accuracy and runtime efficiency, validating its robustness\nfor flow estimation at high resolutions. At the time of submission, our method\nranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289,\nleads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the\nbest Fl-all error on KITTI-2015 at 2.94%. The code is available at\nhttps://github.com/msu-video-group/memfof."}
{"id": "2506.22487", "pdf": "https://arxiv.org/pdf/2506.22487", "abs": "https://arxiv.org/abs/2506.22487", "authors": ["Amar Khelloufi", "Huansheng Ning", "Sahraoui Dhelim", "Jianguo Ding"], "title": "AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space", "categories": ["cs.NI", "cs.AI"], "comment": "31 pages, 5 figures", "summary": "The integration of the Internet of Everything (IoX) and Artificial General\nIntelligence (AGI) has given rise to a transformative paradigm aimed at\naddressing critical bottlenecks across sensing, network, and application layers\nin Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide\na systematic and comprehensive review of AGI-enhanced IoX research, focusing on\nthree key components: sensing-layer data management, network-layer protocol\noptimization, and application-layer decision-making frameworks. Specifically,\nthis survey explores how AGI can mitigate IoX bottlenecks challenges by\nleveraging adaptive sensor fusion, edge preprocessing, and selective attention\nmechanisms at the sensing layer, while resolving network-layer issues such as\nprotocol heterogeneity and dynamic spectrum management, neuro-symbolic\nreasoning, active inference, and causal reasoning, Furthermore, the survey\nexamines AGI-enabled frameworks for managing identity and relationship\nexplosion. Key findings suggest that AGI-driven strategies, such as adaptive\nsensor fusion, edge preprocessing, and semantic modeling, offer novel solutions\nto sensing-layer data overload, network-layer protocol heterogeneity, and\napplication-layer identity explosion. The survey underscores the importance of\ncross-layer integration, quantum-enabled communication, and ethical governance\nframeworks for future AGI-enabled IoX systems. Finally, the survey identifies\nunresolved challenges, such as computational requirements, scalability, and\nreal-world validation, calling for further research to fully realize AGI's\npotential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is\nemerging as a critical research field at the intersection of interconnected\nsystems and advanced AI."}
{"id": "2506.22926", "pdf": "https://arxiv.org/pdf/2506.22926", "abs": "https://arxiv.org/abs/2506.22926", "authors": ["Qixuan Liu", "Shi Qiu", "Yinqiao Wang", "Xiwen Wu", "Kenneth Siu Ho Chok", "Chi-Wing Fu", "Pheng-Ann Heng"], "title": "Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions", "categories": ["cs.HC", "cs.GR", "cs.MM"], "comment": "IEEE VIS 2025 Short Paper", "summary": "Volumetric medical imaging technologies produce detailed 3D representations\nof anatomical structures. However, effective medical data visualization and\nexploration pose significant challenges, especially for individuals with\nlimited medical expertise. We introduce a novel XR-based system with two key\ninnovations: (1) a coordinated visualization module integrating Multi-layered\nMulti-planar Reconstruction with 3D mesh models and (2) a multimodal\ninteraction framework combining hand gestures with LLM-enabled voice commands.\nWe conduct preliminary evaluations, including a 15-participant user study and\nexpert interviews, to demonstrate the system's abilities to enhance spatial\nunderstanding and reduce cognitive load. Experimental results show notable\nimprovements in task completion times, usability metrics, and interaction\neffectiveness enhanced by LLM-driven voice control. While identifying areas for\nfuture refinement, our findings highlight the potential of this immersive\nvisualization system to advance medical training and clinical practice. Our\ndemo application and supplemental materials are available for download at:\nhttps://osf.io/bpjq5/."}
{"id": "2506.22818", "pdf": "https://arxiv.org/pdf/2506.22818", "abs": "https://arxiv.org/abs/2506.22818", "authors": ["Stanislav Sedukhin", "Yoichi Tomioka", "Kazuya Matsumoto", "Yuichi Okuyama"], "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.ET", "eess.SP", "C.1.4; C.3; F.2.1; G.1.3; G.4"], "comment": "19 pages, 5 figures", "summary": "Multilinear transformations are key in high-performance computing (HPC) and\nartificial intelligence (AI) workloads, where data is represented as tensors.\nHowever, their high computational and memory demands, which grow with\ndimensionality, often slow down critical tasks. Moreover, scaling computation\nby enlarging the number of parallel processing units substantially increases\nenergy consumption, limiting widespread adoption, especially for sparse data,\nwhich is common in HPC and AI applications. This paper introduces the Trilinear\nAlgorithm and isomorphic to algorithm Device Architecture (TriADA) to address\nthese challenges with the following innovations: (1) a massively parallel,\nlow-rank algorithm for computing a family of trilinear (3D) discrete orthogonal\ntransformations (3D-DXTs), which is a special case of the more general 3-mode\nmatrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM\nkernel with decoupled streaming active memory, specially designed to accelerate\n3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully\ndistributed 3D network of mesh interconnected processing elements or cells with\na coordinate-free, data-driven local processing activity, which is independent\nof problem size; (4) an elastic sparse outer-product (ESOP) method that avoids\nunnecessary computing and communication operations with zero-valued operands,\nthereby enhancing energy efficiency, computational accuracy, and stability.\nTriADA is capable of performing a variety of trilinear transformations with\nhypercubic arithmetic complexity in a linear number of time-steps. The\nmassively parallel, scalable, and energy-efficient architecture of TriADA is\nideal for accelerating multilinear tensor operations, which are the most\ndemanding parts of AI and HPC workloads."}
{"id": "2506.23405", "pdf": "https://arxiv.org/pdf/2506.23405", "abs": "https://arxiv.org/abs/2506.23405", "authors": ["Faaiq Waqar", "Ming-Yen Lee", "Seongwon Yoon", "Seongkwang Lim", "Shimeng Yu"], "title": "CMOS+X: Stacking Persistent Embedded Memories based on Oxide Transistors upon GPGPU Platforms", "categories": ["cs.ET", "cs.AR", "B.8.2; B.3.1"], "comment": "14 pages, 18 figures, 4 tables, 4 equations", "summary": "In contemporary general-purpose graphics processing units (GPGPUs), the\ncontinued increase in raw arithmetic throughput is constrained by the\ncapabilities of the register file (single-cycle) and last-level cache (high\nbandwidth), which require the delivery of operands at a cadence demanded by\nwide single-instruction multiple-data (SIMD) lanes. Enhancing the capacity,\ndensity, or bandwidth of these memories can unlock substantial performance\ngains; however, the recent stagnation of SRAM bit-cell scaling leads to\ninequivalent losses in compute density.\n  To address the challenges posed by SRAM's scaling and leakage power\nconsumption, this paper explores the potential CMOS+X integration of amorphous\noxide semiconductor (AOS) transistors in capacitive, persistent memory\ntopologies (e.g., 1T1C eDRAM, 2T0C/3T0C Gain Cell) as alternative cells in\nmulti-ported and high-bandwidth banked GPGPU memories. A detailed study of the\ndensity and energy tradeoffs of back-end-of-line (BEOL) integrated memories\nutilizing monolithic 3D (M3D)-integrated multiplexed arrays is conducted, while\naccounting for the macro-level limitations of integrating AOS candidate\nstructures proposed by the device community (an aspect often overlooked in\nprior work). By exploiting the short lifetime of register operands, we propose\na multi-ported AOS gain-cell capable of delivering 3x the read ports in ~76% of\nthe footprint of SRAM with over 70% lower standby power, enabling enhancements\nto compute capacity, such as larger warp sizes or processor counts. Benchmarks\nrun on a validated NVIDIA Ampere-class GPU model, using a modified version of\nAccel-Sim, demonstrate improvements of up to 5.2x the performance per watt and\nan average 8% higher geometric mean instruction per cycle (IPC) on various\ncompute- and memory-bound tasks."}
{"id": "2506.23635", "pdf": "https://arxiv.org/pdf/2506.23635", "abs": "https://arxiv.org/abs/2506.23635", "authors": ["Mu-Chi Chen", "Po-Hsuan Huang", "Xiangrui Ke", "Chia-Heng Tu", "Chun Jason Xue", "Shih-Hao Hung"], "title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model", "categories": ["cs.DC", "cs.AI", "cs.PF", "I.6.4; I.2.7; I.2.11"], "comment": "International Conference on Research in Adaptive and Convergent\n  Systems (RACS '24), November 5--8, 2024, Pompei, Italy", "summary": "Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI)\nwith significant advancements such as OpenAI's ChatGPT, Meta's Llama, and\nDatabricks' DBRX. This paper addresses the cost and scalability challenges\nencountered when constructing private LLM systems for personal or small group\nservices, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2\nUltra chips is established as a cost-efficient solution to host and accelerate\nthe pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our\nperformance analysis reveal that parallel execution of the model's experts\nacross two to four machine nodes significantly reduces inference time. We find\nthat computation time for the experts is comparable to the communication time\nfor exchanging their outputs, emphasizing the importance of network latency\nover bandwidth. We also observe significant management overhead due to Apple\nsoftware stack's memory management logic. Based on these findings, we develop\noptimization schemes to eliminate the memory management overhead. As a result,\nthe Mac Studio cluster is 1.15 times more cost-efficient than the\nstate-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we\nconstruct a performance model to estimate system performance under varying\nconfigurations, and the model provides valuable insights for designing private\nLLM systems."}
{"id": "2506.23408", "pdf": "https://arxiv.org/pdf/2506.23408", "abs": "https://arxiv.org/abs/2506.23408", "authors": ["Claudionor Coelho Jr", "Yanen Li", "Philip Tee"], "title": "Do LLMs Dream of Discrete Algorithms?", "categories": ["cs.LG", "cs.LO"], "comment": null, "summary": "Large Language Models (LLMs) have rapidly transformed the landscape of\nartificial intelligence, enabling natural language interfaces and dynamic\norchestration of software components. However, their reliance on probabilistic\ninference limits their effectiveness in domains requiring strict logical\nreasoning, discrete decision-making, and robust interpretability. This paper\ninvestigates these limitations and proposes a neurosymbolic approach that\naugments LLMs with logic-based reasoning modules, particularly leveraging\nProlog predicates and composable toolsets. By integrating first-order logic and\nexplicit rule systems, our framework enables LLMs to decompose complex queries\ninto verifiable sub-tasks, orchestrate reliable solutions, and mitigate common\nfailure modes such as hallucination and incorrect step decomposition. We\ndemonstrate the practical benefits of this hybrid architecture through\nexperiments on the DABStep benchmark, showing improved precision, coverage, and\nsystem documentation in multi-step reasoning tasks. Our results indicate that\ncombining LLMs with modular logic reasoning restores engineering rigor,\nenhances system reliability, and offers a scalable path toward trustworthy,\ninterpretable AI agents across complex domains."}
{"id": "2506.23777", "pdf": "https://arxiv.org/pdf/2506.23777", "abs": "https://arxiv.org/abs/2506.23777", "authors": ["Haoyang Du", "Kiran Chhatre", "Christopher Peters", "Brian Keegan", "Rachel McDonnell", "Cathy Ennis"], "title": "Synthetically Expressive: Evaluating gesture and voice for emotion and empathy in VR and 2D scenarios", "categories": ["cs.GR"], "comment": null, "summary": "The creation of virtual humans increasingly leverages automated synthesis of\nspeech and gestures, enabling expressive, adaptable agents that effectively\nengage users. However, the independent development of voice and gesture\ngeneration technologies, alongside the growing popularity of virtual reality\n(VR), presents significant questions about the integration of these signals and\ntheir ability to convey emotional detail in immersive environments. In this\npaper, we evaluate the influence of real and synthetic gestures and speech,\nalongside varying levels of immersion (VR vs. 2D displays) and emotional\ncontexts (positive, neutral, negative) on user perceptions. We investigate how\nimmersion affects the perceived match between gestures and speech and the\nimpact on key aspects of user experience, including emotional and empathetic\nresponses and the sense of co-presence. Our findings indicate that while VR\nenhances the perception of natural gesture-voice pairings, it does not\nsimilarly improve synthetic ones - amplifying the perceptual gap between them.\nThese results highlight the need to reassess gesture appropriateness and refine\nAI-driven synthesis for immersive environments. See video:\nhttps://youtu.be/WMfjIB1X-dc"}
{"id": "2506.23063", "pdf": "https://arxiv.org/pdf/2506.23063", "abs": "https://arxiv.org/abs/2506.23063", "authors": ["Guangfa Lyu", "Zhenzhong Cao", "Xiaofei Ren", "Fengyu Wang"], "title": "HF-DGF: Hybrid Feedback Guided Directed Grey-box Fuzzing", "categories": ["cs.SE"], "comment": null, "summary": "Directed Grey-box Fuzzing (DGF) has emerged as a widely adopted technique for\ncrash reproduction and patch testing, leveraging its capability to precisely\nnavigate toward target locations and exploit vulnerabilities. However, current\nDGF tools are constrained by insufficient runtime feedback, limiting their\nefficiency in reaching targets and exploring state spaces. This study presents\nHF-DGF, a novel directed grey-box fuzzing framework. Its seed scheduling is\nguided by a hybrid feedback mechanism integrating control-flow distance,\nvalue-flow influence score, and slice coverage. To enable precise control-flow\ndistance feedback, we propose a backward-stepping algorithm to calculate basic\nblock-level seed distances on a virtual inter-procedural control-flow graph\n(ICFG). For effective state space exploration, we introduce value-flow\ninfluence and a corresponding metric, the value-flow influence score.\nAdditionally, to mitigate runtime overhead from hybrid feedback, we adopt a\nnovel selective instrumentation strategy. Evaluations on 41 real-world\nvulnerabilities show HF-DGF outperforms existing tools: it achieves crash\nreproduction 5.05 times faster than AFL, 5.79 times faster than AFLGo, 73.75\ntimes faster than WindRanger, 2.56 times faster than DAFL, and 8.45 times\nfaster than Beacon on average. Notably, when all fuzzers triggered crashes,\nHF-DGF exhibited the lowest code coverage, demonstrating superior\ndirectionality and efficiency. It also surpasses AFLGo, WindRanger, DAFL, and\nBeacon in static analysis efficiency."}
{"id": "2506.23254", "pdf": "https://arxiv.org/pdf/2506.23254", "abs": "https://arxiv.org/abs/2506.23254", "authors": ["Aradhana Mishra", "Bumshik Lee"], "title": "PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.IV"], "comment": null, "summary": "Diffusion-model-based image super-resolution techniques often face a\ntrade-off between realistic image generation and computational efficiency. This\nissue is exacerbated when inference times by decreasing sampling steps,\nresulting in less realistic and hazy images. To overcome this challenge, we\nintroduce a novel diffusion model named PixelBoost that underscores the\nsignificance of embracing the stochastic nature of Brownian motion in advancing\nimage super-resolution, resulting in a high degree of realism, particularly\nfocusing on texture and edge definitions. By integrating controlled\nstochasticity into the training regimen, our proposed model avoids convergence\nto local optima, effectively capturing and reproducing the inherent uncertainty\nof image textures and patterns. Our proposed model demonstrates superior\nobjective results in terms of learned perceptual image patch similarity\n(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),\nstructural similarity index measure (SSIM), as well as visual quality. To\ndetermine the edge enhancement, we evaluated the gradient magnitude and pixel\nvalue, and our proposed model exhibited a better edge reconstruction\ncapability. Additionally, our model demonstrates adaptive learning capabilities\nby effectively adjusting to Brownian noise patterns and introduces a sigmoidal\nnoise sequencing method that simplifies training, resulting in faster inference\nspeeds."}
{"id": "2506.22507", "pdf": "https://arxiv.org/pdf/2506.22507", "abs": "https://arxiv.org/abs/2506.22507", "authors": ["Yubo Peng", "Luping Xiang", "Kun Yang", "Feibo Jiang", "Kezhi Wang", "Christos Masouros"], "title": "Integrated Multimodal Sensing and Communication: Challenges, Technologies, and Architectures", "categories": ["cs.NI", "cs.MA", "eess.SP"], "comment": null, "summary": "The evolution towards 6G networks requires the intelligent integration of\ncommunication and sensing capabilities to support diverse and complex\napplications, such as autonomous driving and immersive services. However,\nexisting integrated sensing and communication (ISAC) systems predominantly rely\non single-modal sensors as primary participants, which leads to a limited\nrepresentation of environmental features and significant performance\nbottlenecks under the emerging requirements of 6G applications. This limitation\nmotivates a paradigm shift from single-modal to multimodal ISAC. In this\narticle, we first analyze the key challenges in realizing multimodal ISAC,\nincluding the fusion of heterogeneous multimodal data, the high communication\noverhead among distributed sensors, and the design of efficient and scalable\nsystem architectures. We then introduce several enabling technologies, such as\nlarge AI models, semantic communication, and multi-agent systems, that hold\npromise for addressing these challenges. To operationalize these technologies,\nwe zoom into three architectural paradigms: fusion-based multimodal ISAC\n(F-MAC), interaction-based multimodal ISAC (I-MAC), and relay-based multimodal\nISAC (R-MAC), each tailored to organize devices and modalities for efficient\ncollaboration in different scenarios. Thereafter, a case study is presented\nbased on the F-MAC scheme, demonstrating that the scheme achieves more\ncomprehensive sensing and improves sensing accuracy by approximately 80%\ncompared to conventional single-modal ISAC systems. Finally, we discuss several\nopen issues to be addressed in the future."}
{"id": "2506.22932", "pdf": "https://arxiv.org/pdf/2506.22932", "abs": "https://arxiv.org/abs/2506.22932", "authors": ["Zoe Anastasiadou", "Andreas Lanitis"], "title": "Immersive Technologies and Elderly Users: Current use, Limitations and Future Perspectives", "categories": ["cs.HC"], "comment": "13 pages, 2 figures", "summary": "The increase of the percentage of elderly population in modern societies\ndictates the use of emerging technologies as a means of supporting elder\nmembers of the society. Within this scope, Extended Reality (XR) technologies\npose as a promising technology for improving the daily lives of the elderly\npopulation. This paper presents a literature review that describes the most\ncommon characteristics of the physical and mental state of the elderly,\nallowing readers, and specifically XR developers, to understand the main\ndifficulties faced by elderly users of extended reality applications so they\ncan develop accessible, user friendly and engaging applications for the target\naudience. Furthermore, a review of existing extended reality applications that\ntarget the elder population is presented, allowing readers to get acquainted\nwith existing design paradigms that can inspire future developments."}
{"id": "2506.22884", "pdf": "https://arxiv.org/pdf/2506.22884", "abs": "https://arxiv.org/abs/2506.22884", "authors": ["Praveen Kumar Donta", "Qiyang Zhang", "Schahram Dustdar"], "title": "Performance Measurements in the AI-Centric Computing Continuum Systems", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "Over the Eight decades, computing paradigms have shifted from large,\ncentralized systems to compact, distributed architectures, leading to the rise\nof the Distributed Computing Continuum (DCC). In this model, multiple layers\nsuch as cloud, edge, Internet of Things (IoT), and mobile platforms work\ntogether to support a wide range of applications. Recently, the emergence of\nGenerative AI and large language models has further intensified the demand for\ncomputational resources across this continuum. Although traditional performance\nmetrics have provided a solid foundation, they need to be revisited and\nexpanded to keep pace with changing computational demands and application\nrequirements. Accurate performance measurements benefit both system designers\nand users by supporting improvements in efficiency and promoting alignment with\nsystem goals. In this context, we review commonly used metrics in DCC and IoT\nenvironments. We also discuss emerging performance dimensions that address\nevolving computing needs, such as sustainability, energy efficiency, and system\nobservability. We also outline criteria and considerations for selecting\nappropriate metrics, aiming to inspire future research and development in this\ncritical area."}
{"id": "2506.23672", "pdf": "https://arxiv.org/pdf/2506.23672", "abs": "https://arxiv.org/abs/2506.23672", "authors": ["Sergio Mazzola", "Gabriele Ara", "Thomas Benz", "Björn Forsberg", "Tommaso Cucinotta", "Luca Benini"], "title": "Data-Driven Power Modeling and Monitoring via Hardware Performance Counter Tracking", "categories": ["cs.PF", "cs.AR"], "comment": "Published on Journal of Systems Architecture (JSA), here:\n  https://doi.org/10.1016/j.sysarc.2025.103504 Extension of conference paper\n  https://doi.org/10.1007/978-3-031-15074-6_22 (SAMOS 2022)", "summary": "Energy-centric design is paramount in the current embedded computing era: use\ncases require increasingly high performance at an affordable power budget,\noften under real-time constraints. Hardware heterogeneity and parallelism help\naddress the efficiency challenge, but greatly complicate online power\nconsumption assessments, which are essential for dynamic hardware and software\nstack adaptations. We introduce a novel power modeling methodology with\nstate-of-the-art accuracy, low overhead, and high responsiveness, whose\nimplementation does not rely on microarchitectural details. Our methodology\nidentifies the Performance Monitoring Counters (PMCs) with the highest linear\ncorrelation to the power consumption of each hardware sub-system, for each\nDynamic Voltage and Frequency Scaling (DVFS) state. The individual, simple\nmodels are composed into a complete model that effectively describes the power\nconsumption of the whole system, achieving high accuracy and low overhead. Our\nevaluation reports an average estimation error of 7.5% for power consumption\nand 1.3% for energy. We integrate these models in the Linux kernel with\nRunmeter, an open-source, PMC-based monitoring framework. Runmeter manages PMC\nsampling and processing, enabling the execution of our power models at runtime.\nWith a worst-case time overhead of only 0.7%, Runmeter provides responsive and\naccurate power measurements directly in the kernel. This information can be\nemployed for actuation policies in workload-aware DVFS and power-aware,\nclosed-loop task scheduling."}
{"id": "2506.23809", "pdf": "https://arxiv.org/pdf/2506.23809", "abs": "https://arxiv.org/abs/2506.23809", "authors": ["Hongtao Xu", "Zibo Wu", "Mingzhen Li", "Weile Jia"], "title": "Large-scale Neural Network Quantum States for ab initio Quantum Chemistry Simulations on Fugaku", "categories": ["cs.DC"], "comment": null, "summary": "Solving quantum many-body problems is one of the fundamental challenges in\nquantum chemistry. While neural network quantum states (NQS) have emerged as a\npromising computational tool, its training process incurs exponentially growing\ncomputational demands, becoming prohibitively expensive for large-scale\nmolecular systems and creating fundamental scalability barriers for real-world\napplications. To address above challenges, we present \\ours, a high-performance\nNQS training framework for \\textit{ab initio} electronic structure\ncalculations. First, we propose a scalable sampling parallelism strategy with\nmulti-layers workload division and hybrid sampling scheme, which break the\nscalability barriers for large-scale NQS training. Then, we introduce\nmulti-level parallelism local energy parallelism, enabling more efficient local\nenergy computation. Last, we employ cache-centric optimization for\ntransformer-based \\textit{ansatz} and incorporate it with sampling parallelism\nstrategy, which further speedup up the NQS training and achieve stable memory\nfootprint at scale. Experiments demonstrate that \\ours accelerate NQS training\nwith up to 8.41x speedup and attains a parallel efficiency up to 95.8\\% when\nscaling to 1,536 nodes."}
{"id": "2506.23773", "pdf": "https://arxiv.org/pdf/2506.23773", "abs": "https://arxiv.org/abs/2506.23773", "authors": ["Stefano M. Nicoletti", "Mariëlle Stoelinga"], "title": "BayesL: Towards a Logical Framework for Bayesian Networks", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We introduce BayesL, a novel logical framework for specifying, querying, and\nverifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\")\nis a structured language that allows for the creation of queries over BNs. It\nfacilitates versatile reasoning concerning causal and evidence-based\nrelationships, and permits comprehensive what-if scenario evaluations without\nthe need for manual modifications to the model."}
{"id": "2506.23957", "pdf": "https://arxiv.org/pdf/2506.23957", "abs": "https://arxiv.org/abs/2506.23957", "authors": ["Zinuo You", "Stamatios Georgoulis", "Anpei Chen", "Siyu Tang", "Dengxin Dai"], "title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering", "categories": ["cs.GR", "cs.CV"], "comment": "siggraph 2025, project website: https://sinoyou.github.io/gavs", "summary": "Video stabilization is pivotal for video processing, as it removes unwanted\nshakiness while preserving the original user motion intent. Existing\napproaches, depending on the domain they operate, suffer from several issues\n(e.g. geometric distortions, excessive cropping, poor generalization) that\ndegrade the user experience. To address these issues, we introduce\n\\textbf{GaVS}, a novel 3D-grounded approach that reformulates video\nstabilization as a temporally-consistent `local reconstruction and rendering'\nparadigm. Given 3D camera poses, we augment a reconstruction model to predict\nGaussian Splatting primitives, and finetune it at test-time, with multi-view\ndynamics-aware photometric supervision and cross-frame regularization, to\nproduce temporally-consistent local reconstructions. The model are then used to\nrender each stabilized frame. We utilize a scene extrapolation module to avoid\nframe cropping. Our method is evaluated on a repurposed dataset, instilled with\n3D-grounded information, covering samples with diverse camera motions and scene\ndynamics. Quantitatively, our method is competitive with or superior to\nstate-of-the-art 2D and 2.5D approaches in terms of conventional task metrics\nand new geometry consistency. Qualitatively, our method produces noticeably\nbetter results compared to alternatives, validated by the user study."}
{"id": "2506.23100", "pdf": "https://arxiv.org/pdf/2506.23100", "abs": "https://arxiv.org/abs/2506.23100", "authors": ["Jiayi Zhang", "Kai Huang", "Jian Zhang", "Yang Liu", "Chunyang Chen"], "title": "Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search", "categories": ["cs.SE"], "comment": "Accepted by ICSE 2026. Jiayi Zhang and Kai Huang contributed equally\n  to this work", "summary": "Automated Program Repair (APR) techniques aim to automatically fix buggy\nprograms. Among these, Large Language Model-based (LLM-based) approaches have\nshown great promise. Recent advances demonstrate that directly leveraging LLMs\ncan achieve leading results. However, these techniques remain suboptimal in\ngenerating contextually relevant and accurate patches, as they often overlook\nrepair ingredients crucial for practical program repair. In this paper, we\npropose ReinFix, a novel framework that enables LLMs to autonomously search for\nrepair ingredients throughout both the reasoning and solution phases of bug\nfixing. In the reasoning phase, ReinFix integrates static analysis tools to\nretrieve internal ingredients, such as variable definitions, to assist the LLM\nin root cause analysis when it encounters difficulty understanding the context.\nDuring the solution phase, when the LLM lacks experience in fixing specific\nbugs, ReinFix searches for external ingredients from historical bug fixes with\nsimilar bug patterns, leveraging both the buggy code and its root cause to\nguide the LLM in identifying appropriate repair actions, thereby increasing the\nlikelihood of generating correct patches. Evaluations on two popular benchmarks\n(Defects4J V1.2 and V2.0) demonstrate the effectiveness of our approach over\nSOTA baselines. Notably, ReinFix fixes 146 bugs, which is 32 more than the\nbaselines on Defects4J V1.2. On Defects4J V2.0, ReinFix fixes 38 more bugs than\nthe SOTA. Importantly, when evaluating on the recent benchmarks that are free\nof data leakage risk, ReinFix also maintains the best performance."}
{"id": "2506.22671", "pdf": "https://arxiv.org/pdf/2506.22671", "abs": "https://arxiv.org/abs/2506.22671", "authors": ["Rubi Debnath", "Mohammadreza Barzegaran", "Sebastian Steinhorst"], "title": "Towards an Optimized Multi-Cyclic Queuing and Forwarding in Time Sensitive Networking with Time Injection", "categories": ["cs.NI", "cs.ET"], "comment": null, "summary": "Cyclic Queuing and Forwarding (CQF) is a Time-Sensitive Networking (TSN)\nshaping mechanism that provides bounded latency and deterministic Quality of\nService (QoS). However, CQF's use of a single cycle restricts its ability to\nsupport TSN traffic with diverse timing requirements. Multi-Cyclic Queuing and\nForwarding (Multi-CQF) is a new and emerging TSN shaping mechanism that uses\nmultiple cycles on the same egress port, allowing it to accommodate TSN flows\nwith varied timing requirements more effectively than CQF. Despite its\npotential, current Multi-CQF configuration studies are limited, leading to a\nlack of comprehensive research, poor understanding of the mechanism, and\nlimited adoption of Multi-CQF in practical applications. Previous work has\nshown the impact of Time Injection (TI), defined as the start time of\nTime-Triggered (TT) flows at the source node, on CQF queue resource\nutilization. However, the impact of TI has not yet been explored in the context\nof Multi-CQF. This paper introduces a set of constraints and leverages Domain\nSpecific Knowledge (DSK) to reduce the search space for Multi-CQF\nconfiguration. Building on this foundation, we develop an open-source Genetic\nAlgorithm (GA) and a hybrid GA-Simulated Annealing (GASA) approach to\nefficiently configure Multi-CQF networks and introduce TI in Multi-CQF to\nenhance schedulability. Experimental results show that our proposed algorithms\nsignificantly increase the number of scheduled TT flows compared to the\nbaseline Simulated Annealing (SA) model, improving scheduling by an average of\n15%. Additionally, GASA achieves a 20% faster convergence rate and lower time\ncomplexity, outperforming the SA model in speed, and efficiency."}
{"id": "2506.22937", "pdf": "https://arxiv.org/pdf/2506.22937", "abs": "https://arxiv.org/abs/2506.22937", "authors": ["Tianrun Qiu", "Changxin Chen", "Sizhe Cheng", "Yiming Yang", "Yixiao Guo", "Zhicong Lu", "Yuxin Ma"], "title": "GamerAstra: Enhancing Video Game Accessibility for Blind and Low-Vision Players through a Multi-Agent AI Framework", "categories": ["cs.HC", "H.5.2"], "comment": "19 pages, 9 figures", "summary": "Blind and low-vision (BLV) players encounter critical challenges in engaging\nwith video games due to the inaccessibility of visual elements, difficulties in\nnavigating interfaces, and limitations in sending interaction input. Moreover,\nthe development of specialized accessibility features typically requires\nsubstantial programming effort and is often implemented on a game-by-game\nbasis. To address these challenges, we introduce \\textit{GamerAstra}, a\ngeneralized accessibility framework that leverages a multi-agent design to\nfacilitate access to video games for BLV players. It integrates multi-modal\ntechniques including large language models and vision-language models, enabling\ninteraction with games lacking native accessibility support. The framework\nfurther incorporates customizable assistance granularities to support varying\ndegrees of visual impairment and enhances interface navigation through multiple\ninput modalities. The evaluation through technical assessments and user studies\nindicate that \\textit{GamerAstra} effectively enhances playability and delivers\na more immersive gaming experience for BLV players. These findings also\nunderscore potential avenues for advancing intelligent accessibility frameworks\nin the gaming domain."}
{"id": "2506.23123", "pdf": "https://arxiv.org/pdf/2506.23123", "abs": "https://arxiv.org/abs/2506.23123", "authors": ["Rishi Bommasani"], "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy", "categories": ["cs.AI", "cs.CY", "cs.ET"], "comment": "Stanford University PhD Dissertation of Rishi Bommasani (Department\n  of Computer Science, 2025). Also available at\n  https://purl.stanford.edu/zf669yy0336", "summary": "Artificial intelligence is humanity's most promising technology because of\nthe remarkable capabilities offered by foundation models. Yet, the same\ntechnology brings confusion and consternation: foundation models are poorly\nunderstood and they may precipitate a wide array of harms. This dissertation\nexplains how technology and society coevolve in the age of AI, organized around\nthree themes. First, the conceptual framing: the capabilities, risks, and the\nsupply chain that grounds foundation models in the broader economy. Second, the\nempirical insights that enrich the conceptual foundations: transparency created\nvia evaluations at the model level and indexes at the organization level.\nFinally, the transition from understanding to action: superior understanding of\nthe societal impact of foundation models advances evidence-based AI policy.\nView together, this dissertation makes inroads into achieving better societal\noutcomes in the age of AI by building the scientific foundations and\nresearch-policy interface required for better AI governance."}
{"id": "2506.23682", "pdf": "https://arxiv.org/pdf/2506.23682", "abs": "https://arxiv.org/abs/2506.23682", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Not quite a piece of CHERI-cake: Are new digital security by design architectures usable?", "categories": ["cs.CR", "cs.AR", "cs.HC"], "comment": null, "summary": "A digital security-by-design computer architecture, like CHERI, lets you\nprogram without fear of buffer overflows or other memory safety errors, but\nCHERI also rewrites some of the assumptions about how C works and how\nfundamental types (such as pointers) are implemented in hardware. We conducted\na usability study to examine how developers react to the changes required by\nCHERI when porting software to run on it. We find that developers struggle with\nCHERI's display of warnings and errors and a lack of diverse documentation."}
{"id": "2506.23934", "pdf": "https://arxiv.org/pdf/2506.23934", "abs": "https://arxiv.org/abs/2506.23934", "authors": ["Xiangchen Li", "Saeid Ghafouri", "Bo Ji", "Hans Vandierendonck", "Deepu John", "Dimitrios S. Nikolopoulos"], "title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "As machine learning inferences increasingly move to edge devices, adapting to\ndiverse computational capabilities, hardware, and memory constraints becomes\nmore critical. Instead of relying on a pre-trained model fixed for all future\ninference queries across diverse edge devices, we argue that planning an\ninference pattern with a request-specific model tailored to the device's\ncomputational capacity, accuracy requirements, and time constraints is more\ncost-efficient and robust to diverse scenarios. To this end, we propose an\naccuracy-aware and workload-balanced inference system that integrates joint\nmodel quantization and inference partitioning. In this approach, the server\ndynamically responds to inference queries by sending a quantized model and\nadaptively sharing the inference workload with the device. Meanwhile, the\ndevice's computational power, channel capacity, and accuracy requirements are\nconsidered when deciding.\n  Furthermore, we introduce a new optimization framework for the inference\nsystem, incorporating joint model quantization and partitioning. Our approach\noptimizes layer-wise quantization bit width and partition points to minimize\ntime consumption and cost while accounting for varying accuracy requirements of\ntasks through an accuracy degradation metric in our optimization model. To our\nknowledge, this work represents the first exploration of optimizing\nquantization layer-wise bit-width in the inference serving system, by\nintroducing theoretical measurement of accuracy degradation. Simulation results\ndemonstrate a substantial reduction in overall time and power consumption, with\ncomputation payloads decreasing by over 80% and accuracy degradation kept below\n1%."}
{"id": "2506.24108", "pdf": "https://arxiv.org/pdf/2506.24108", "abs": "https://arxiv.org/abs/2506.24108", "authors": ["Shai Yehezkel", "Omer Dahary", "Andrey Voynov", "Daniel Cohen-Or"], "title": "Navigating with Annealing Guidance Scale in Diffusion Space", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Project page:\n  https://annealing-guidance.github.io/annealing-guidance/", "summary": "Denoising diffusion models excel at generating high-quality images\nconditioned on text prompts, yet their effectiveness heavily relies on careful\nguidance during the sampling process. Classifier-Free Guidance (CFG) provides a\nwidely used mechanism for steering generation by setting the guidance scale,\nwhich balances image quality and prompt alignment. However, the choice of the\nguidance scale has a critical impact on the convergence toward a visually\nappealing and prompt-adherent image. In this work, we propose an annealing\nguidance scheduler which dynamically adjusts the guidance scale over time based\non the conditional noisy signal. By learning a scheduling policy, our method\naddresses the temperamental behavior of CFG. Empirical results demonstrate that\nour guidance scheduler significantly enhances image quality and alignment with\nthe text prompt, advancing the performance of text-to-image generation.\nNotably, our novel scheduler requires no additional activations or memory\nconsumption, and can seamlessly replace the common classifier-free guidance,\noffering an improved trade-off between prompt alignment and quality."}
{"id": "2506.23234", "pdf": "https://arxiv.org/pdf/2506.23234", "abs": "https://arxiv.org/abs/2506.23234", "authors": ["Peerachai Banyongrakkul", "Mansooreh Zahedi", "Patanamon Thongtanunam", "Christoph Treude", "Haoyu Gao"], "title": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers", "categories": ["cs.SE"], "comment": "Recently accepted at ICSME 2025", "summary": "Pre-trained models (PTMs) have gained widespread popularity and achieved\nremarkable success across various fields, driven by their groundbreaking\nperformance and easy accessibility through hosting providers. However, the\nchallenges faced by downstream developers in reusing PTMs in software systems\nare less explored. To bridge this knowledge gap, we qualitatively created and\nanalyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub\nprojects. We systematically developed a comprehensive taxonomy of PTM-related\nchallenges that developers face in downstream projects. Our study identifies\nseven key categories of challenges that downstream developers face in reusing\nPTMs, such as model usage, model performance, and output quality. We also\ncompared our findings with existing taxonomies. Additionally, we conducted a\nresolution time analysis and, based on statistical tests, found that\nPTM-related issues take significantly longer to be resolved than issues\nunrelated to PTMs, with significant variation across challenge categories. We\ndiscuss the implications of our findings for practitioners and possibilities\nfor future research."}
{"id": "2506.22745", "pdf": "https://arxiv.org/pdf/2506.22745", "abs": "https://arxiv.org/abs/2506.22745", "authors": ["Sijie He", "Ziye Jia", "Qiuming Zhu", "Fuhui Zhou", "Qihui Wu"], "title": "Trusted Routing for Blockchain-Enabled Low-Altitude Intelligent Networks", "categories": ["cs.NI"], "comment": "Low-altitude intelligent networks, trusted routing, blockchain, soft\n  hierarchical experience replay buffer, multi-agent deep reinforcement\n  learning", "summary": "Due to the scalability and portability, the low-altitude intelligent networks\n(LAINs) are essential in various fields such as surveillance and disaster\nrescue. However, in LAINs, unmanned aerial vehicles (UAVs) are characterized by\nthe distributed topology and high dynamic mobility, and vulnerable to security\nthreats, which may degrade the routing performance for data transmission.\nHence, how to ensure the routing stability and security of LAINs is a\nchallenge. In this paper, we focus on the routing process in LAINs with\nmultiple UAV clusters and propose the blockchain-enabled zero-trust\narchitecture to manage the joining and exiting of UAVs. Furthermore, we\nformulate the routing problem to minimize the end-to-end (E2E) delay, which is\nan integer linear programming and intractable to solve. Therefore, considering\nthe distribution of LAINs, we reformulate the routing problem into a\ndecentralized partially observable Markov decision process. With the proposed\nsoft hierarchical experience replay buffer, the multi-agent double deep\nQ-network based adaptive routing algorithm is designed. Finally, simulations\nare conducted and numerical results show that the total E2E delay of the\nproposed mechanism decreases by 22.38\\% than the benchmark on average."}
{"id": "2506.22940", "pdf": "https://arxiv.org/pdf/2506.22940", "abs": "https://arxiv.org/abs/2506.22940", "authors": ["Varun Sangwan", "Heidi Makitalo"], "title": "Context, Credibility, and Control: User Reflections on AI Assisted Misinformation Tools", "categories": ["cs.HC", "cs.SI"], "comment": null, "summary": "This paper investigates how collaborative AI systems can enhance user agency\nin identifying and evaluating misinformation on social media platforms.\nTraditional methods, such as personal judgment or basic fact-checking, often\nfall short when faced with emotionally charged or context-deficient content. To\naddress this, we designed and evaluated an interactive interface that\nintegrates collaborative AI features, including real-time explanations, source\naggregation, and debate-style interaction. These elements aim to support\ncritical thinking by providing contextual cues and argumentative reasoning in a\ntransparent, user-centered format. In a user study with 14 participants, 79%\nfound the debate mode more effective than standard chatbot interfaces, and the\nmultiple-source view received an average usefulness rating of 4.6 out of 5. Our\nfindings highlight the potential of context-rich, dialogic AI systems to\nimprove media literacy and foster trust in digital information environments. We\nargue that future tools for misinformation mitigation should prioritize ethical\ndesign, explainability, and interactive engagement to empower users in a\npost-truth era."}
{"id": "2506.23511", "pdf": "https://arxiv.org/pdf/2506.23511", "abs": "https://arxiv.org/abs/2506.23511", "authors": ["Ahmad Abdel-Qader", "Anas Chaaban", "Mohamed S. Shehata"], "title": "Mutli-Level Autoencoder: Deep Learning Based Channel Coding and Modulation", "categories": ["eess.SP", "cs.ET"], "comment": "Accepted at IWCMC 2025", "summary": "In this paper, we design a deep learning-based convolutional autoencoder for\nchannel coding and modulation. The objective is to develop an adaptive scheme\ncapable of operating at various signal-to-noise ratios (SNR)s without the need\nfor re-training. Additionally, the proposed framework allows validation by\ntesting all possible codes in the codebook, as opposed to previous AI-based\nencoder/decoder frameworks which relied on testing only a small subset of the\navailable codes. This limitation in earlier methods often led to unreliable\nconclusions when generalized to larger codebooks. In contrast to previous\nmethods, our multi-level encoding and decoding approach splits the message into\nblocks, where each encoder block processes a distinct group of $B$ bits. By\ndoing so, the proposed scheme can exhaustively test $2^{B}$ possible codewords\nfor each encoder/decoder level, constituting a layer of the overall scheme. The\nproposed model was compared to classical polar codes and TurboAE-MOD schemes,\nshowing improved reliability with achieving comparable, or even superior\nresults in some settings. Notably, the architecture can adapt to different SNRs\nby selectively removing one of the encoder/decoder layers without re-training,\nthus demonstrating flexibility and efficiency in practical wireless\ncommunication scenarios."}
{"id": "2506.24045", "pdf": "https://arxiv.org/pdf/2506.24045", "abs": "https://arxiv.org/abs/2506.24045", "authors": ["Xinming Wei", "Jiahao Zhang", "Haoran Li", "Jiayu Chen", "Rui Qu", "Maoliang Li", "Xiang Chen", "Guojie Luo"], "title": "Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The proliferation of agentic Large Language Models (LLMs) on personal devices\nintroduces a new class of workloads characterized by a dichotomy of objectives.\nReactive tasks, initiated by users, demand immediate, low-latency responses,\nwhile proactive tasks operate invisibly and prioritize throughput. Existing\non-device LLM engines, designed for isolated inferences, fail to efficiently\nmanage these concurrent and conflicting requests on consumer-grade\nheterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces\nAgent.xpu, an efficient serving system for agentic LLM workloads on\nmemory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu\nfirst constructs a heterogeneous execution graph, which fuses and chunks model\nkernels for affinity-guided, elastic accelerator mapping with predictive kernel\nannotation. At runtime, its online scheduler enables fine-grained, kernel-level\npreemption to guarantee the responsiveness of reactive tasks. To maximize SoC\nutilization, it adopts slack-aware kernel backfill to opportunistically append\nproactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware\ndispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves\n4.6$\\times$ lower latency for reactive tasks and sustains\n1.6$\\times$-6.8$\\times$ higher throughput for proactive tasks compared to\nstate-of-the-art inference engines."}
{"id": "2506.22583", "pdf": "https://arxiv.org/pdf/2506.22583", "abs": "https://arxiv.org/abs/2506.22583", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges"], "title": "Supra-threshold control of peripheral LOD", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "Level of detail (LOD) is widely used to control visual feedback in\ninteractive applications. LOD control is typically based on perception at\nthreshold - the conditions in which a stimulus first becomes perceivable. Yet\nmost LOD manipulations are quite perceivable and occur well above threshold.\nMoreover, research shows that supra-threshold perception differs drastically\nfrom perception at threshold. In that case, should supra-threshold LOD control\nalso differ from LOD control at threshold?\n  In two experiments, we examine supra-threshold LOD control in the visual\nperiphery and find that indeed, it should differ drastically from LOD control\nat threshold. Specifically, we find that LOD must support a task-dependent\nlevel of reliable perceptibility. Above that level, perceptibility of LOD\ncontrol manipulations should be minimized, and detail contrast is a better\npredictor of perceptibility than detail size. Below that level, perceptibility\nmust be maximized, and LOD should be improved as eccentricity rises or contrast\ndrops. This directly contradicts prevailing threshold-based LOD control\nschemes, and strongly suggests a reexamination of LOD control for foveal\ndisplay."}
{"id": "2506.23281", "pdf": "https://arxiv.org/pdf/2506.23281", "abs": "https://arxiv.org/abs/2506.23281", "authors": ["Xintong Zhou", "Zhenyang Xu", "Chengnian Sun"], "title": "On the Feasibility of Deduplicating Compiler Bugs with Bisection", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Random testing has proven to be an effective technique for compiler\nvalidation. However, the debugging of bugs identified through random testing\npresents a significant challenge due to the frequent occurrence of duplicate\ntest programs that expose identical compiler bugs. The process to identify\nduplicates is a practical research problem known as bug deduplication. Prior\nmethodologies for compiler bug deduplication primarily rely on program analysis\nto extract bug-related features for duplicate identification, which can result\nin substantial computational overhead and limited generalizability. This paper\ninvestigates the feasibility of employing bisection, a standard debugging\nprocedure largely overlooked in prior research on compiler bug deduplication,\nfor this purpose. Our study demonstrates that the utilization of bisection to\nlocate failure-inducing commits provides a valuable criterion for\ndeduplication, albeit one that requires supplementary techniques for more\naccurate identification. Building on these results, we introduce BugLens, a\nnovel deduplication method that primarily uses bisection, enhanced by the\nidentification of bug-triggering optimizations to minimize false negatives.\nEmpirical evaluations conducted on four real-world datasets demonstrate that\nBugLens significantly outperforms the state-of-the-art analysis-based\nmethodologies Tamer and D3 by saving an average of 26.98% and 9.64% human\neffort to identify the same number of distinct bugs. Given the inherent\nsimplicity and generalizability of bisection, it presents a highly practical\nsolution for compiler bug deduplication in real-world applications."}
{"id": "2506.22793", "pdf": "https://arxiv.org/pdf/2506.22793", "abs": "https://arxiv.org/abs/2506.22793", "authors": ["Pegah Alizadeh", "Anastasios Giovanidis", "Pradeepa Ramachandra", "Vasileios Koutsoukis", "Osama Arouk"], "title": "Offline Reinforcement Learning for Mobility Robustness Optimization", "categories": ["cs.NI", "cs.AI", "cs.PF"], "comment": "7 pages, double column, 4 figures, 6 tables, conference submission", "summary": "In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm\nand study the possibility of learning the optimal Cell Individual Offset tuning\nusing offline Reinforcement Learning. Such methods make use of collected\noffline datasets to learn the optimal policy, without further exploration. We\nadapt and apply a sequence-based method called Decision Transformers as well as\na value-based method called Conservative Q-Learning to learn the optimal policy\nfor the same target reward as the vanilla rule-based MRO. The same input\nfeatures related to failures, ping-pongs, and other handover issues are used.\nEvaluation for realistic New Radio networks with 3500 MHz carrier frequency on\na traffic mix including diverse user service types and a specific tunable\ncell-pair shows that offline-RL methods outperform rule-based MRO, offering up\nto 7% improvement. Furthermore, offline-RL can be trained for diverse objective\nfunctions using the same available dataset, thus offering operational\nflexibility compared to rule-based methods."}
{"id": "2506.22941", "pdf": "https://arxiv.org/pdf/2506.22941", "abs": "https://arxiv.org/abs/2506.22941", "authors": ["Kaixuan Wang", "Jason T. Jacques", "Chenxin Diao"], "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions", "categories": ["cs.HC", "cs.AI"], "comment": "16 pages, 4 figures, with appendix", "summary": "Access to accurate and actionable harm reduction information can directly\nimpact the health outcomes of People Who Use Drugs (PWUD), yet existing online\nchannels often fail to meet their diverse and dynamic needs due to limitations\nin adaptability, accessibility, and the pervasive impact of stigma. Large\nLanguage Models (LLMs) present a novel opportunity to enhance information\nprovision, but their application in such a high-stakes domain is under-explored\nand presents socio-technical challenges. This paper investigates how LLMs can\nbe responsibly designed to support the information needs of PWUD. Through a\nqualitative workshop involving diverse stakeholder groups (academics, harm\nreduction practitioners, and an online community moderator), we explored LLM\ncapabilities, identified potential use cases, and delineated core design\nconsiderations. Our findings reveal that while LLMs can address some existing\ninformation barriers (e.g., by offering responsive, multilingual, and\npotentially less stigmatising interactions), their effectiveness is contingent\nupon overcoming challenges related to ethical alignment with harm reduction\nprinciples, nuanced contextual understanding, effective communication, and\nclearly defined operational boundaries. We articulate design pathways\nemphasising collaborative co-design with experts and PWUD to develop LLM\nsystems that are helpful, safe, and responsibly governed. This work contributes\nempirically grounded insights and actionable design considerations for the\nresponsible development of LLMs as supportive tools within the harm reduction\necosystem."}
{"id": "2506.23851", "pdf": "https://arxiv.org/pdf/2506.23851", "abs": "https://arxiv.org/abs/2506.23851", "authors": ["Israel Fianyi", "Soonja Yeom", "Ju-Hyun Shin"], "title": "Comparative Studies: Cloud-Enabled Adaptive Learning System for Scalable Education in Sub-Saharan", "categories": ["cs.CY", "cs.ET", "cs.HC"], "comment": null, "summary": "The integration of cloud computing in education can revolutionise learning in\nadvanced (Australia & South Korea) and middle-income (Ghana & Nigeria)\ncountries, while offering scalable, cost-effective and equitable access to\nadaptive learning systems. This paper explores how cloud computing and adaptive\nlearning technologies are deployed across different socio-economic and\ninfrastructure contexts. The study identifies enabling factors and systematic\nchallenges, providing insights into how cloud-based education can be tailored\nto bridge the digital and educational divide globally."}
{"id": "2506.22480", "pdf": "https://arxiv.org/pdf/2506.22480", "abs": "https://arxiv.org/abs/2506.22480", "authors": ["Mariam Yahya", "Aydin Sezgin", "Setareh Maghsudi"], "title": "Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits", "categories": ["cs.NI", "cs.DC", "cs.LG"], "comment": null, "summary": "As users in small cell networks increasingly rely on computation-intensive\nservices, cloud-based access often results in high latency. Multi-access edge\ncomputing (MEC) mitigates this by bringing computational resources closer to\nend users, with small base stations (SBSs) serving as edge servers to enable\nlow-latency service delivery. However, limited edge capacity makes it\nchallenging to decide which services to deploy locally versus in the cloud,\nespecially under unknown service demand and dynamic network conditions. To\ntackle this problem, we model service demand as a linear function of service\nattributes and formulate the service placement task as a linear bandit problem,\nwhere SBSs act as agents and services as arms. The goal is to identify the\nservice that, when placed at the edge, offers the greatest reduction in total\nuser delay compared to cloud deployment. We propose a distributed and adaptive\nmulti-agent best-arm identification (BAI) algorithm under a fixed-confidence\nsetting, where SBSs collaborate to accelerate learning. Simulations show that\nour algorithm identifies the optimal service with the desired confidence and\nachieves near-optimal speedup, as the number of learning rounds decreases\nproportionally with the number of SBSs. We also provide theoretical analysis of\nthe algorithm's sample complexity and communication overhead."}
{"id": "2506.22685", "pdf": "https://arxiv.org/pdf/2506.22685", "abs": "https://arxiv.org/abs/2506.22685", "authors": ["Anh Bui", "Trang Vu", "Trung Le", "Junae Kim", "Tamas Abraham", "Rollin Omari", "Amar Kaur", "Dinh Phung"], "title": "Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment", "categories": ["cs.LG", "cs.GR"], "comment": null, "summary": "In this paper, we investigate the semantic collapsing problem in generative\npersonalization, an under-explored topic where the learned visual concept\n($V^*$) gradually shifts from its original textual meaning and comes to\ndominate other concepts in multi-concept input prompts. This issue not only\nreduces the semantic richness of complex input prompts like \"a photo of $V^*$\nwearing glasses and playing guitar\" into simpler, less contextually rich forms\nsuch as \"a photo of $V^*$\" but also leads to simplified output images that fail\nto capture the intended concept.\n  We identify the root cause as unconstrained optimisation, which allows the\nlearned embedding $V^*$ to drift arbitrarily in the embedding space, both in\ndirection and magnitude. To address this, we propose a simple yet effective\ntraining-free method that adjusts the magnitude and direction of pre-trained\nembedding at inference time, effectively mitigating the semantic collapsing\nproblem. Our method is broadly applicable across different personalization\nmethods and demonstrates significant improvements in text-image alignment in\ndiverse use cases. Our code is anonymously published at\nhttps://anonymous.4open.science/r/Embedding-Adjustment."}
{"id": "2506.23534", "pdf": "https://arxiv.org/pdf/2506.23534", "abs": "https://arxiv.org/abs/2506.23534", "authors": ["Siyu Chen", "Jiongyi Yang", "Xiang Chen", "Menglin Zheng", "Minnan Wei", "Xiaolin Ju"], "title": "Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning", "categories": ["cs.SE"], "comment": null, "summary": "Context: Software vulnerabilities pose a significant threat to modern\nsoftware systems, as evidenced by the growing number of reported\nvulnerabilities and cyberattacks. These escalating trends underscore the urgent\nneed for effective approaches that can automatically detect and understand\nsoftware vulnerabilities. Objective: However, the scarcity of labeled samples\nand the class imbalance issue in vulnerability datasets present significant\nchallenges for both Vulnerability Type Prediction (VTP) and Line-level\nVulnerability Detection (LVD), especially for rare yet critical vulnerability\ntypes. Moreover, most existing studies treat VTP and LVD as independent tasks,\noverlooking their inherent correlation, which limits the potential to leverage\nshared semantic patterns across tasks. Methods: To address these limitations,\nwe propose a unified approach that integrates Embedding-Layer Driven\nAdversarial Training (EDAT) with Multi-task Learning (MTL). Specifically, EDAT\nenhances model robustness by introducing adversarial perturbations to\nidentifier embeddings, guided by semantic importance. Meanwhile, MTL improves\noverall performance by leveraging shared representations and inter-task\ncorrelations between VTP and LVD. Results: Extensive experiments demonstrate\nthat our proposed approach outperforms state-of-the-art baselines on both VTP\nand LVD tasks. For VTP, it yields notable improvements in accuracy, precision,\nrecall, and F1-score, particularly in identifying rare vulnerability types.\nSimilarly, for LVD, our approach enhances line-level detection accuracy while\nsignificantly reducing false positives. Conclusion: Our study demonstrates that\ncombining EDAT with MTL provides a unified solution that improves performance\non both tasks and warrants further investigation."}
{"id": "2506.22875", "pdf": "https://arxiv.org/pdf/2506.22875", "abs": "https://arxiv.org/abs/2506.22875", "authors": ["Everson Flores", "Bruna Guterres", "Thomaz Pereira Junior", "Paula Barros", "Alberto Cabral", "Cristiana Lima Dora", "Marcelo Malheiros", "Marcelo Pias"], "title": "Reliable Image Transmission in CPS-based Pub/Sub", "categories": ["cs.NI", "cs.DC"], "comment": "10 pages, 4 figures", "summary": "Developments in communication and automation have driven the expansion of\ndistributed networks, essential for IoT and CPS development in industrial\napplications requiring reliable image processing and real-time adaptability.\nAlthough broadly adopted, there is a literature gap regarding the performance\nof MQTT protocol for image sharing and transmission under high-traffic\nscenarios with intermittent connectivity, restricting its use in critical IoT\nand CPS applications. In this context, the present work examines the\nreliability of real-time image transmission in IoT and CPS industrial systems\nthat utilize the MQTT-based publish/subscribe communication model. It focuses\non scenarios with network interruptions and high data traffic, evaluating the\nperformance of a distributed system through a series of controlled testbed\nvalidation experiments. Experimental validation demonstrated that while the\nMQTT-based system sustains reliable transmission under normal conditions, its\nrecovery capability depends on the failure point, with complete restoration\noccurring when disruptions affect the Orchestrator Node and partial recovery\nwhen the Producer Node or Broker are affected. The study also confirmed that\nthe system prevents duplicate errors and adapts well to increasing network\ndemands, reinforcing its suitability for industrial applications that require\nefficient and resilient data handling."}
{"id": "2506.22968", "pdf": "https://arxiv.org/pdf/2506.22968", "abs": "https://arxiv.org/abs/2506.22968", "authors": ["Daniel Mwesigwa"], "title": "Against 'softmaxing' culture", "categories": ["cs.HC", "cs.AI"], "comment": "7 pages", "summary": "AI is flattening culture. Evaluations of \"culture\" are showing the myriad\nways in which large AI models are homogenizing language and culture, averaging\nout rich linguistic differences into generic expressions. I call this\nphenomenon \"softmaxing culture,\" and it is one of the fundamental challenges\nfacing AI evaluations today. Efforts to improve and strengthen evaluations of\nculture are central to the project of cultural alignment in large AI systems.\nThis position paper argues that machine learning (ML) and human-computer\ninteraction (HCI) approaches to evaluation are limited. I propose two key\nshifts. First, instead of asking \"what is culture?\" at the start of system\nevaluations, I propose beginning with the question: \"when is culture?\" Second,\nwhile I acknowledge the philosophical claim that cultural universals exist, the\nchallenge is not simply to describe them, but to situate them in relation to\ntheir particulars. Taken together, these conceptual shifts invite evaluation\napproaches that move beyond technical requirements, toward perspectives more\nresponsive to the complexities of culture."}
{"id": "2506.23967", "pdf": "https://arxiv.org/pdf/2506.23967", "abs": "https://arxiv.org/abs/2506.23967", "authors": ["Geerd-Dietger Hoffmann", "Verena Majuntke"], "title": "Green Metrics Tool: Measuring for fun and profit", "categories": ["cs.SE", "cs.CY", "cs.ET"], "comment": null, "summary": "The environmental impact of software is gaining increasing attention as the\ndemand for computational resources continues to rise. In order to optimize\nsoftware resource consumption and reduce carbon emissions, measuring and\nevaluating software is a first essential step. In this paper we discuss what\nmetrics are important for fact base decision making. We introduce the Green\nMetrics Tool (GMT), a novel framework for accurately measuring the resource\nconsumption of software. The tool provides a containerized, controlled, and\nreproducible life cycle-based approach, assessing the resource use of software\nduring key phases. Finally, we discuss GMT features like visualization,\ncomparability and rule- and LLM-based optimisations highlighting its potential\nto guide developers and researchers in reducing the environmental impact of\ntheir software."}
{"id": "2506.22668", "pdf": "https://arxiv.org/pdf/2506.22668", "abs": "https://arxiv.org/abs/2506.22668", "authors": ["Selahattin Akkas", "Aditya Devarakonda", "Ariful Azad"], "title": "DistShap: Scalable GNN Explanations with Distributed Shapley Values", "categories": ["cs.LG", "cs.AI", "cs.DC", "stat.ML"], "comment": "12 pages", "summary": "With the growing adoption of graph neural networks (GNNs), explaining their\npredictions has become increasingly important. However, attributing predictions\nto specific edges or features remains computationally expensive. For example,\nclassifying a node with 100 neighbors using a 3-layer GNN may involve\nidentifying important edges from millions of candidates contributing to the\nprediction. To address this challenge, we propose DistShap, a parallel\nalgorithm that distributes Shapley value-based explanations across multiple\nGPUs. DistShap operates by sampling subgraphs in a distributed setting,\nexecuting GNN inference in parallel across GPUs, and solving a distributed\nleast squares problem to compute edge importance scores. DistShap outperforms\nmost existing GNN explanation methods in accuracy and is the first to scale to\nGNN models with millions of features by using up to 128 GPUs on the NERSC\nPerlmutter supercomputer."}
{"id": "2506.22899", "pdf": "https://arxiv.org/pdf/2506.22899", "abs": "https://arxiv.org/abs/2506.22899", "authors": ["Ehsan Pajouheshgar", "Yitao Xu", "Ali Abbasi", "Alexander Mordvintsev", "Wenzel Jakob", "Sabine Süsstrunk"], "title": "Neural Cellular Automata: From Cells to Pixels", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.MA", "eess.IV"], "comment": "6 pages, 5 figures, first draft", "summary": "Neural Cellular Automata (NCAs) are bio-inspired systems in which identical\ncells self-organize to form complex and coherent patterns by repeatedly\napplying simple local rules. NCAs display striking emergent behaviors including\nself-regeneration, generalization and robustness to unseen situations, and\nspontaneous motion. Despite their success in texture synthesis and\nmorphogenesis, NCAs remain largely confined to low-resolution grids. This\nlimitation stems from (1) training time and memory requirements that grow\nquadratically with grid size, (2) the strictly local propagation of information\nwhich impedes long-range cell communication, and (3) the heavy compute demands\nof real-time inference at high resolution. In this work, we overcome this\nlimitation by pairing NCA with a tiny, shared implicit decoder, inspired by\nrecent advances in implicit neural representations. Following NCA evolution on\na coarse grid, a lightweight decoder renders output images at arbitrary\nresolution. We also propose novel loss functions for both morphogenesis and\ntexture synthesis tasks, specifically tailored for high-resolution output with\nminimal memory and computation overhead. Combining our proposed architecture\nand loss functions brings substantial improvement in quality, efficiency, and\nperformance. NCAs equipped with our implicit decoder can generate full-HD\noutputs in real time while preserving their self-organizing, emergent\nproperties. Moreover, because each MLP processes cell states independently,\ninference remains highly parallelizable and efficient. We demonstrate the\napplicability of our approach across multiple NCA variants (on 2D, 3D grids,\nand 3D meshes) and multiple tasks, including texture generation and\nmorphogenesis (growing patterns from a seed), showing that with our proposed\nframework, NCAs seamlessly scale to high-resolution outputs with minimal\ncomputational overhead."}
{"id": "2506.23535", "pdf": "https://arxiv.org/pdf/2506.23535", "abs": "https://arxiv.org/abs/2506.23535", "authors": ["Malik Muhammad Umer"], "title": "Comparative Analysis of the Code Generated by Popular Large Language Models (LLMs) for MISRA C++ Compliance", "categories": ["cs.SE"], "comment": null, "summary": "Safety-critical systems are engineered systems whose failure or malfunction\ncould result in catastrophic consequences. The software development for\nsafety-critical systems necessitates rigorous engineering practices and\nadherence to certification standards like DO-178C for avionics. DO-178C is a\nguidance document which requires compliance to well-defined software coding\nstandards like MISRA C++ to enforce coding guidelines that prevent the use of\nambiguous, unsafe, or undefined constructs. Large Language Models (LLMs) have\ndemonstrated significant capabilities in automatic code generation across a\nwide range of programming languages, including C++. Despite their impressive\nperformance, code generated by LLMs in safety-critical domains must be\ncarefully analyzed for conformance to MISRA C++ coding standards. In this\npaper, I have conducted a comparative analysis of the C++ code generated by\npopular LLMs including: OpenAI ChatGPT, Google Gemini, DeepSeek, Meta AI, and\nMicrosoft Copilot for compliance with MISRA C++."}
{"id": "2506.22991", "pdf": "https://arxiv.org/pdf/2506.22991", "abs": "https://arxiv.org/abs/2506.22991", "authors": ["Mehdi Bennis", "Sumudu Samarakoon", "Tamara Alshammari", "Chathuranga Weeraddana", "Zhoujun Tian", "Chaouki Ben Issaid"], "title": "Resilient-Native and Intelligent Next-Generation Wireless Systems: Key Enablers, Foundations, and Applications", "categories": ["cs.NI", "cs.LO", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "Just like power, water, and transportation systems, wireless networks are a\ncrucial societal infrastructure. As natural and human-induced disruptions\ncontinue to grow, wireless networks must be resilient. This requires them to\nwithstand and recover from unexpected adverse conditions, shocks, unmodeled\ndisturbances and cascading failures. Unlike robustness and reliability,\nresilience is based on the understanding that disruptions will inevitably\nhappen. Resilience, as elasticity, focuses on the ability to bounce back to\nfavorable states, while resilience as plasticity involves agents and networks\nthat can flexibly expand their states and hypotheses through real-time\nadaptation and reconfiguration. This situational awareness and active\npreparedness, adapting world models and counterfactually reasoning about\npotential system failures and the best responses, is a core aspect of\nresilience. This article will first disambiguate resilience from reliability\nand robustness, before delving into key mathematical foundations of resilience\ngrounded in abstraction, compositionality and emergence. Subsequently, we focus\nour attention on a plethora of techniques and methodologies pertaining to the\nunique characteristics of resilience, as well as their applications through a\ncomprehensive set of use cases. Ultimately, the goal of this paper is to\nestablish a unified foundation for understanding, modeling, and engineering\nresilience in wireless communication systems, while laying a roadmap for the\nnext-generation of resilient-native and intelligent wireless systems."}
{"id": "2506.23016", "pdf": "https://arxiv.org/pdf/2506.23016", "abs": "https://arxiv.org/abs/2506.23016", "authors": ["Tomás Silva Santos Rocha", "Anastasiia Mikhailova", "Moreno I. Coco", "José Santos-Victor"], "title": "Deep Learning in Mild Cognitive Impairment Diagnosis using Eye Movements and Image Content in Visual Memory Tasks", "categories": ["cs.HC", "cs.CV"], "comment": "13 pages, 5 figures", "summary": "The global prevalence of dementia is projected to double by 2050,\nhighlighting the urgent need for scalable diagnostic tools. This study utilizes\ndigital cognitive tasks with eye-tracking data correlated with memory processes\nto distinguish between Healthy Controls (HC) and Mild Cognitive Impairment\n(MCI), a precursor to dementia. A deep learning model based on VTNet was\ntrained using eye-tracking data from 44 participants (24 MCI, 20 HCs) who\nperformed a visual memory task. The model utilizes both time series and spatial\ndata derived from eye-tracking. It was modified to incorporate scan paths, heat\nmaps, and image content. These modifications also enabled testing parameters\nsuch as image resolution and task performance, analyzing their impact on model\nperformance. The best model, utilizing $700\\times700px$ resolution heatmaps,\nachieved 68% sensitivity and 76% specificity. Despite operating under more\nchallenging conditions (e.g., smaller dataset size, shorter task duration, or a\nless standardized task), the model's performance is comparable to an\nAlzheimer's study using similar methods (70% sensitivity and 73% specificity).\nThese findings contribute to the development of automated diagnostic tools for\nMCI. Future work should focus on refining the model and using a standardized\nlong-term visual memory task."}
{"id": "2506.23992", "pdf": "https://arxiv.org/pdf/2506.23992", "abs": "https://arxiv.org/abs/2506.23992", "authors": ["Aditya Shrivastava", "Komal Gupta", "Shraddha Arora"], "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "categories": ["cs.AI", "cs.ET"], "comment": "14 page , 2 image , 2 tables , accepted under 5th International\n  Conference on Innovations in Computational Intelligence and Computer Vision\n  (ICICV-2025)", "summary": "The international refugee crisis deepens, exposing millions of dis placed\nchildren to extreme psychological trauma. This research suggests a com pact,\nAI-based framework for processing unstructured refugee health data and\ndistilling knowledge on child mental health. We compare two Retrieval-Aug\nmented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to\ndetermine how well they process challenging humanitarian datasets while avoid\ning hallucination hazards. By combining cutting-edge AI methods with migration\nresearch and child psychology, this study presents a scalable strategy to\nassist policymakers, mental health practitioners, and humanitarian agencies to\nbetter assist displaced children and recognize their mental wellbeing. In\ntotal, both the models worked properly but significantly Deepseek R1 is\nsuperior to Zephyr with an accuracy of answer relevance 0.91"}
{"id": "2506.22855", "pdf": "https://arxiv.org/pdf/2506.22855", "abs": "https://arxiv.org/abs/2506.22855", "authors": ["Mohammadreza Doostmohammadian", "Hamid R. Rabiee"], "title": "Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity", "categories": ["eess.SY", "cs.DC", "cs.MA", "cs.SY", "eess.SP", "math.OC"], "comment": "Journal of the Franklin Institute", "summary": "Distributed optimization advances centralized machine learning methods by\nenabling parallel and decentralized learning processes over a network of\ncomputing nodes. This work provides an accelerated consensus-based distributed\nalgorithm for locally non-convex optimization using the gradient-tracking\ntechnique. The proposed algorithm (i) improves the convergence rate by adding\nmomentum towards the optimal state using the heavy-ball method, while (ii)\naddressing general sector-bound nonlinearities over the information-sharing\nnetwork. The link nonlinearity includes any sign-preserving odd sector-bound\nmapping, for example, log-scale data quantization or clipping in practical\napplications. For admissible momentum and gradient-tracking parameters, using\nperturbation theory and eigen-spectrum analysis, we prove convergence even in\nthe presence of sector-bound nonlinearity and for locally non-convex cost\nfunctions. Further, in contrast to most existing weight-stochastic algorithms,\nwe adopt weight-balanced (WB) network design. This WB design and\nperturbation-based analysis allow to handle dynamic directed network of agents\nto address possible time-varying setups due to link failures or packet drops."}
{"id": "2506.22907", "pdf": "https://arxiv.org/pdf/2506.22907", "abs": "https://arxiv.org/abs/2506.22907", "authors": ["Yunzhe Shao", "Xinyu Yi", "Lu Yin", "Shihui Guo", "Junhai Yong", "Feng Xu"], "title": "MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "This paper proposes a novel method called MagShield, designed to address the\nissue of magnetic interference in sparse inertial motion capture (MoCap)\nsystems. Existing Inertial Measurement Unit (IMU) systems are prone to\norientation estimation errors in magnetically disturbed environments, limiting\ntheir practical application in real-world scenarios. To address this problem,\nMagShield employs a \"detect-then-correct\" strategy, first detecting magnetic\ndisturbances through multi-IMU joint analysis, and then correcting orientation\nerrors using human motion priors. MagShield can be integrated with most\nexisting sparse inertial MoCap systems, improving their performance in\nmagnetically disturbed environments. Experimental results demonstrate that\nMagShield significantly enhances the accuracy of motion capture under magnetic\ninterference and exhibits good compatibility across different sparse inertial\nMoCap systems."}
{"id": "2506.23644", "pdf": "https://arxiv.org/pdf/2506.23644", "abs": "https://arxiv.org/abs/2506.23644", "authors": ["Junze Hu", "Xiangyu Jin", "Yizhe Zeng", "Yuling Liu", "Yunpeng Li", "Dan Du", "Kaiyu Xie", "Hongsong Zhu"], "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": null, "summary": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days."}
{"id": "2506.23083", "pdf": "https://arxiv.org/pdf/2506.23083", "abs": "https://arxiv.org/abs/2506.23083", "authors": ["Changrong Wu", "Yiyao Yu", "Myungjin Lee", "Jayanth Srinivasa", "Ennan Zhai", "George Varghese", "Yuval Tamir"], "title": "Model-Based Diagnosis: Automating End-to-End Diagnosis of Network Failures", "categories": ["cs.NI"], "comment": null, "summary": "Fast diagnosis and repair of enterprise network failures is critically\nimportant since disruptions cause major business impacts. Prior works focused\non diagnosis primitives or procedures limited to a subset of the problem, such\nas only data plane or only control plane faults. This paper proposes a new\nparadigm, model-based network diagnosis, that provides a systematic way to\nderive automated procedures for identifying the root cause of network failures,\nbased on reports of end-to-end user-level symptoms. The diagnosis procedures\nare systematically derived from a model of packet forwarding and routing,\ncovering hardware, firmware, and software faults in both the data plane and\ndistributed control plane. These automated procedures replace and dramatically\naccelerate diagnosis by an experienced human operator. Model-based diagnosis is\ninspired by, leverages, and is complementary to recent work on network\nverification. We have built NetDx, a proof-of-concept implementation of\nmodel-based network diagnosis. We deployed NetDx on a new emulator of networks\nconsisting of P4 switches with distributed routing software. We validated the\nrobustness and coverage of NetDx with an automated fault injection campaign, in\nwhich 100% of faults were diagnosed correctly. Furthermore, on a data set of 33\nfaults from a large cloud provider that are within the domain targeted by\nNetDx, 30 are efficiently diagnosed in seconds instead of hours."}
{"id": "2506.23017", "pdf": "https://arxiv.org/pdf/2506.23017", "abs": "https://arxiv.org/abs/2506.23017", "authors": ["Noverah Khan", "Hira Eiraj Daud", "Suleman Shahid"], "title": "Mind the Dark: A Gamified Exploration of Deceptive Design Awareness for Children in the Digital Age", "categories": ["cs.HC"], "comment": null, "summary": "This paper addresses the critical issue of deceptive design elements\nprevalent in technology, and their potential impact on children. Recent\nresearch highlights the impact of dark patterns on adults and adolescents,\nwhile studies involving children are scarce. In an era where children wield\ngreater independence with digital devices, their vulnerability to dark patterns\namplifies without early education. Our findings show a significant positive\nimpact of dark pattern education on children's awareness, revealing that\nheightened awareness considerably alters children's navigation of social media,\nvideo games, and streaming platforms. To this end, we developed a gamified\napplication aimed at instructing children on identifying and responding to\nvarious dark patterns. Our evaluation results emphasize the critical role of\nearly education in empowering children to recognize and counter deceptive\ndesign, thereby cultivating a digitally literate generation capable of making\ninformed choices in the complex landscape of digital technology."}
{"id": "2506.24008", "pdf": "https://arxiv.org/pdf/2506.24008", "abs": "https://arxiv.org/abs/2506.24008", "authors": ["Hiroshi Yamashita", "Hideyuki Suzuki"], "title": "Spatial QUBO: Convolutional Formulation of Large-Scale Binary Optimization with Dense Interactions", "categories": ["cond-mat.dis-nn", "cs.ET", "physics.app-ph", "physics.optics"], "comment": "18 pages, 6 figures (including supplementary information, 7 pages, 1\n  figure)", "summary": "The spatial photonic Ising machine (SPIM) is a promising optical hardware\nsolver for large-scale combinatorial optimization problems with dense\ninteractions. As the SPIM can represent Ising problems with rank-one coupling\nmatrices, multiplexed versions have been proposed to enhance the applicability\nto higher-rank interactions. However, the multiplexing cost reduces the\nimplementation efficiency, and even without multiplexing, the SPIM is known to\nrepresent coupling matrices beyond rank-one. In this paper, to clarify the\nintrinsic representation power of the original SPIM, we propose spatial QUBO\n(spQUBO), a formulation of Ising problems with spatially convolutional\nstructures. We prove that any spQUBO reduces to a two-dimensional spQUBO, with\nthe convolutional structure preserved, and that any two-dimensional spQUBO can\nbe efficiently implemented on the SPIM without multiplexing. We further\ndemonstrate its practical applicability to distance-based combinatorial\noptimization, such as placement problems and clustering problems. These results\nadvance our understanding of the class of optimization problems where SPIMs\nexhibit superior efficiency and scalability. Furthermore, spQUBO's efficiency\nis not limited to the SPIM architecture; we show that its convolutional\nstructure allows efficient computation using Fast Fourier Transforms (FFT)."}
{"id": "2506.22875", "pdf": "https://arxiv.org/pdf/2506.22875", "abs": "https://arxiv.org/abs/2506.22875", "authors": ["Everson Flores", "Bruna Guterres", "Thomaz Pereira Junior", "Paula Barros", "Alberto Cabral", "Cristiana Lima Dora", "Marcelo Malheiros", "Marcelo Pias"], "title": "Reliable Image Transmission in CPS-based Pub/Sub", "categories": ["cs.NI", "cs.DC"], "comment": "10 pages, 4 figures", "summary": "Developments in communication and automation have driven the expansion of\ndistributed networks, essential for IoT and CPS development in industrial\napplications requiring reliable image processing and real-time adaptability.\nAlthough broadly adopted, there is a literature gap regarding the performance\nof MQTT protocol for image sharing and transmission under high-traffic\nscenarios with intermittent connectivity, restricting its use in critical IoT\nand CPS applications. In this context, the present work examines the\nreliability of real-time image transmission in IoT and CPS industrial systems\nthat utilize the MQTT-based publish/subscribe communication model. It focuses\non scenarios with network interruptions and high data traffic, evaluating the\nperformance of a distributed system through a series of controlled testbed\nvalidation experiments. Experimental validation demonstrated that while the\nMQTT-based system sustains reliable transmission under normal conditions, its\nrecovery capability depends on the failure point, with complete restoration\noccurring when disruptions affect the Orchestrator Node and partial recovery\nwhen the Producer Node or Broker are affected. The study also confirmed that\nthe system prevents duplicate errors and adapts well to increasing network\ndemands, reinforcing its suitability for industrial applications that require\nefficient and resilient data handling."}
{"id": "2506.22926", "pdf": "https://arxiv.org/pdf/2506.22926", "abs": "https://arxiv.org/abs/2506.22926", "authors": ["Qixuan Liu", "Shi Qiu", "Yinqiao Wang", "Xiwen Wu", "Kenneth Siu Ho Chok", "Chi-Wing Fu", "Pheng-Ann Heng"], "title": "Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions", "categories": ["cs.HC", "cs.GR", "cs.MM"], "comment": "IEEE VIS 2025 Short Paper", "summary": "Volumetric medical imaging technologies produce detailed 3D representations\nof anatomical structures. However, effective medical data visualization and\nexploration pose significant challenges, especially for individuals with\nlimited medical expertise. We introduce a novel XR-based system with two key\ninnovations: (1) a coordinated visualization module integrating Multi-layered\nMulti-planar Reconstruction with 3D mesh models and (2) a multimodal\ninteraction framework combining hand gestures with LLM-enabled voice commands.\nWe conduct preliminary evaluations, including a 15-participant user study and\nexpert interviews, to demonstrate the system's abilities to enhance spatial\nunderstanding and reduce cognitive load. Experimental results show notable\nimprovements in task completion times, usability metrics, and interaction\neffectiveness enhanced by LLM-driven voice control. While identifying areas for\nfuture refinement, our findings highlight the potential of this immersive\nvisualization system to advance medical training and clinical practice. Our\ndemo application and supplemental materials are available for download at:\nhttps://osf.io/bpjq5/."}
{"id": "2506.23696", "pdf": "https://arxiv.org/pdf/2506.23696", "abs": "https://arxiv.org/abs/2506.23696", "authors": ["Francisco Oliveira", "Alexandra Mendes", "Carolina Carreira"], "title": "What Challenges Do Developers Face When Using Verification-Aware Programming Languages?", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Software reliability is critical in ensuring that the digital systems we\ndepend on function correctly. In software development, increasing software\nreliability often involves testing. However, for complex and critical systems,\ndevelopers can use Design by Contract (DbC) methods to define precise\nspecifications that software components must satisfy. Verification-Aware (VA)\nprogramming languages support DbC and formal verification at compile-time or\nrun-time, offering stronger correctness guarantees than traditional testing.\nHowever, despite the strong guarantees provided by VA languages, their adoption\nremains limited. In this study, we investigate the barriers to adopting VA\nlanguages by analyzing developer discussions on public forums using topic\nmodeling techniques. We complement this analysis with a developer survey to\nbetter understand the practical challenges associated with VA languages. Our\nfindings reveal key obstacles to adoption, including steep learning curves and\nusability issues. Based on these insights, we identify actionable\nrecommendations to improve the usability and accessibility of VA languages. Our\nfindings suggest that simplifying tool interfaces, providing better educational\nmaterials, and improving integration with everyday development environments\ncould improve the usability and adoption of these languages. Our work provides\nactionable insights for improving the usability of VA languages and making\nverification tools more accessible."}
{"id": "2506.23190", "pdf": "https://arxiv.org/pdf/2506.23190", "abs": "https://arxiv.org/abs/2506.23190", "authors": ["Kamran Shafafi", "Manuel Ricardo", "Rui Campos"], "title": "Autonomous Vision-Aided UAV Positioning for Obstacle-Aware Wireless Connectivity", "categories": ["cs.NI"], "comment": null, "summary": "Unmanned Aerial Vehicles (UAVs) offer a promising solution for enhancing\nwireless connectivity and Quality of Service (QoS) in urban environments,\nacting as aerial Wi-Fi access points or cellular base stations. Their\nflexibility and rapid deployment capabilities make them suitable for addressing\ninfrastructure gaps and traffic surges. However, optimizing UAV positions to\nmaintain Line of Sight (LoS) links with ground User Equipment (UEs) remains\nchallenging in obstacle-dense urban scenarios. This paper proposes VTOPA, a\nVision-Aided Traffic- and Obstacle-Aware Positioning Algorithm that\nautonomously extracts environmental information -- such as obstacles and UE\nlocations -- via computer vision and optimizes UAV positioning accordingly. The\nalgorithm prioritizes LoS connectivity and dynamically adapts to user traffic\ndemands in real time. Evaluated through simulations in ns-3, VTOPA achieves up\nto a 50% increase in aggregate throughput and a 50% reduction in delay, without\ncompromising fairness, outperforming benchmark approaches in obstacle-rich\nenvironments."}
{"id": "2506.23075", "pdf": "https://arxiv.org/pdf/2506.23075", "abs": "https://arxiv.org/abs/2506.23075", "authors": ["Yuchen Zhou", "Jiamin Wu", "Zichen Ren", "Zhouheng Yao", "Weiheng Lu", "Kunyu Peng", "Qihao Zheng", "Chunfeng Song", "Wanli Ouyang", "Chao Gou"], "title": "CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding", "categories": ["cs.HC", "cs.LG", "eess.SP", "q-bio.NC"], "comment": null, "summary": "Understanding and decoding brain activity from electroencephalography (EEG)\nsignals is a fundamental challenge in neuroscience and AI, with applications in\ncognition, emotion recognition, diagnosis, and brain-computer interfaces. While\nrecent EEG foundation models advance generalized decoding via unified\narchitectures and large-scale pretraining, they adopt a scale-agnostic dense\nmodeling paradigm inherited from NLP and vision. This design neglects a core\nproperty of neural activity: cross-scale spatiotemporal structure. EEG task\npatterns span a wide range of temporal and spatial scales, from short bursts to\nslow rhythms, and from localized cortical responses to distributed\ninteractions. Ignoring this diversity leads to suboptimal representations and\nweak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain\nfoundation model for generalized EEG decoding. CSBrain introduces: (i)\nCross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale\nfeatures from localized temporal windows and anatomical brain regions into\ncompact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which\ncaptures cross-window and cross-region dependencies, enhancing scale diversity\nwhile removing spurious correlations. CST and SSA are alternately stacked to\nprogressively integrate multi-scale dependencies. Experiments on 11 EEG tasks\nacross 16 datasets show that CSBrain consistently outperforms task-specific and\nfoundation model baselines. These results establish cross-scale modeling as a\nkey inductive bias and position CSBrain as a robust backbone for future\nbrain-AI research."}
{"id": "2506.23058", "pdf": "https://arxiv.org/pdf/2506.23058", "abs": "https://arxiv.org/abs/2506.23058", "authors": ["Nikolaj Hey Hinnerskov", "Robert Schenck", "Cosmin E. Oancea"], "title": "Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language", "categories": ["cs.PL", "cs.DC"], "comment": null, "summary": "This paper presents a novel approach to automatically verify properties of\npure data-parallel programs with non-linear indexing -- expressed as pre- and\npost-conditions on functions. Programs consist of nests of second-order array\ncombinators (e.g., map, scan, and scatter) and loops. The key idea is to\nrepresent arrays as index functions: programs are index function\ntransformations over which properties are propagated and inferred. Our\nframework proves properties on index functions by distilling them into\nalgebraic (in)equalities and discharging them to a Fourier-Motzkin-based\nsolver. The framework is practical and accessible: properties are not\nrestricted to a decidable logic, but instead are carefully selected to express\npractically useful guarantees that can be automatically reasoned about and\ninferred. These guarantees extend beyond program correctness and can be\nexploited by the entire compiler pipeline for optimization. We implement our\nsystem in the pure data-parallel language Futhark and demonstrate its\npracticality on seven applications, reporting an average verification time of 1\nsecond. Two case studies show how eliminating dynamic verification in GPU\nprograms results in significant speedups."}
{"id": "2506.23854", "pdf": "https://arxiv.org/pdf/2506.23854", "abs": "https://arxiv.org/abs/2506.23854", "authors": ["Yida Wang", "Xueyang Zhang", "Kun Zhan", "Peng Jia", "Xianpeng Lang"], "title": "HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity", "categories": ["cs.CV", "cs.GR"], "comment": "Published in International Conference on Computer Vision (ICCV) 2025", "summary": "Neural surface reconstruction faces persistent challenges in reconciling\ngeometric fidelity with photometric consistency under complex scene conditions.\nWe present HiNeuS, a unified framework that holistically addresses three core\nlimitations in existing approaches: multi-view radiance inconsistency, missing\nkeypoints in textureless regions, and structural degradation from over-enforced\nEikonal constraints during joint optimization. To resolve these issues through\na unified pipeline, we introduce: 1) Differential visibility verification\nthrough SDF-guided ray tracing, resolving reflection ambiguities via continuous\nocclusion modeling; 2) Planar-conformal regularization via ray-aligned geometry\npatches that enforce local surface coherence while preserving sharp edges\nthrough adaptive appearance weighting; and 3) Physically-grounded Eikonal\nrelaxation that dynamically modulates geometric constraints based on local\nradiance gradients, enabling detail preservation without sacrificing global\nregularity. Unlike prior methods that handle these aspects through sequential\noptimizations or isolated modules, our approach achieves cohesive integration\nwhere appearance-geometry constraints evolve synergistically throughout\ntraining. Comprehensive evaluations across synthetic and real-world datasets\ndemonstrate state-of-the-art performance, including a 21.4% reduction in\nChamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement\nagainst neural rendering counterparts. Qualitative analyses reveal superior\ncapability in recovering specular instruments, urban layouts with\ncentimeter-scale infrastructure, and low-textured surfaces without local patch\ncollapse. The method's generalizability is further validated through successful\napplication to inverse rendering tasks, including material decomposition and\nview-consistent relighting."}
{"id": "2506.23715", "pdf": "https://arxiv.org/pdf/2506.23715", "abs": "https://arxiv.org/abs/2506.23715", "authors": ["Benoit Combemale"], "title": "Towards a Science of Developer eXperience (DevX)", "categories": ["cs.SE"], "comment": null, "summary": "As software continues to permeate nearly every facet of modern life, the\ncomplexity and ubiquity of digital services underscore the need for\nsustainable, effective, and inclusive software development practices. Although\nsoftware engineering has made significant progress in technical challenges\nsince its inception, the human experience of those involved in software\ncreation, broadly defined as developers, remains underexplored. This column\nadvocates for the formal recognition of Developer eXperience (DevX) as a\ndistinct research field. We argue that DevX profoundly influences critical\ndevelopment activities and overall productivity, especially as development\nbecomes increasingly collaborative and diverse in terms of application domains.\nBuilding on existing efforts to measure and enhance DevX, we identify key\nrationales, scientific enablers, and interdisciplinary intersections that\nsupport this emerging discipline. We also outline the core scientific\nchallenges ahead, aiming to call for actions from the research community and to\npromote more human-centered approaches to software engineering."}
{"id": "2506.23350", "pdf": "https://arxiv.org/pdf/2506.23350", "abs": "https://arxiv.org/abs/2506.23350", "authors": ["João Pedro Loureiro", "Patrícia Delgado", "Tomás Feliciano Ribeiro", "Filipe B. Teixeira", "Rui Campos"], "title": "On the Resilience of Underwater Semantic Wireless Communications", "categories": ["cs.NI"], "comment": null, "summary": "Underwater wireless communications face significant challenges due to\npropagation constraints, limiting the effectiveness of traditional radio and\noptical technologies. Long-range acoustic communications support distances up\nto a few kilometers, but suffer from low bandwidth, high error ratios, and\nmultipath interference. Semantic communications, which focus on transmitting\nextracted semantic features rather than raw data, present a promising solution\nby significantly reducing the volume of data transmitted over the wireless\nlink.\n  This paper evaluates the resilience of SAGE, a semantic-oriented\ncommunications framework that combines semantic processing with Generative\nArtificial Intelligence (GenAI) to compress and transmit image data as textual\ndescriptions over acoustic links. To assess robustness, we use a\ncustom-tailored simulator that introduces character errors observed in\nunderwater acoustic channels. Evaluation results show that SAGE can\nsuccessfully reconstruct meaningful image content even under varying error\nconditions, highlighting its potential for robust and efficient underwater\nwireless communication in harsh environments."}
{"id": "2506.23116", "pdf": "https://arxiv.org/pdf/2506.23116", "abs": "https://arxiv.org/abs/2506.23116", "authors": ["Wei Xu"], "title": "A User Experience 3.0 (UX 3.0) Paradigm Framework: Designing for Human-Centered AI Experiences", "categories": ["cs.HC"], "comment": null, "summary": "User experience (UX) practices have evolved in stages and are entering a\ntransformative phase (UX 3.0), driven by AI technologies and shifting user\nneeds. Human-centered AI (HCAI) experiences are emerging, necessitating new UX\napproaches to support UX practices in the AI era. We propose a UX 3.0 paradigm\nframework to respond and guide UX practices in developing HCAI systems."}
{"id": "2506.23210", "pdf": "https://arxiv.org/pdf/2506.23210", "abs": "https://arxiv.org/abs/2506.23210", "authors": ["Taehwan Yoon", "Bongjun Choi"], "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "6 pages,14 equation", "summary": "Federated learning(FL) is used for distributed scenarios to train artificial\nintelligence(AI) models while ensuring users' privacy. In federated learning\nscenario, the server generally never knows about users' data. This type of\nconcept makes the AI training process efficient in terms of data privacy.\nHowever, regarding model performance, federated AI models may not sufficiently\nsatisfy AI users' expectations. Furthermore, AI users have a wide range of\ndifferent needs. It is not easy to satisfy the whole users needs. These types\nof issues can be addressed through AI model optimization, fine-tuning, or\npersonalization to achieve optimal model performance. To address model\noptimization challenges, we propose reference model-based federated learning\nfor optimal fine-tuning, which overcomes catastrophic forgetting in each round.\nThis method is derived from Bayesian parameter-efficient transfer learning,\nwhich includes an optimal proximal term and enables overcoming the catastrophic\nforgetting issue in each round by utilizing a reference model that incorporates\nprevious model parameters. As a result, this method achieves both high model\nperformance and low computing cost."}
{"id": "2506.23749", "pdf": "https://arxiv.org/pdf/2506.23749", "abs": "https://arxiv.org/abs/2506.23749", "authors": ["Boyang Yang", "Zijian Cai", "Fengling Liu", "Bach Le", "Lingming Zhang", "Tegawendé F. Bissyandé", "Yang Liu", "Haoye Tian"], "title": "A Survey of LLM-based Automated Program Repair: Taxonomies, Design Paradigms, and Applications", "categories": ["cs.SE"], "comment": null, "summary": "Large language models (LLMs) are reshaping automated program repair (APR). We\ncategorize the recent 63 LLM-based APR systems published from January 2022 to\nJune 2025 into four paradigms, and show how retrieval- or analysis-augmented\ncontexts strengthen any of them. This taxonomy clarifies key trade-offs:\nfine-tuning delivers strong task alignment at high training cost; prompting\nenables rapid deployment but is limited by prompt design and context windows;\nprocedural pipelines offer reproducible control with moderate overhead; agentic\nframeworks tackle multi-hunk or cross-file bugs at the price of increased\nlatency and complexity. Persistent challenges include verifying semantic\ncorrectness beyond test suites, repairing repository-scale defects, and\nlowering the costs of LLMs. We outline research directions that combine\nlightweight human feedback, repository-aware retrieval, code analysis, and\ncost-aware planning to advance reliable and efficient LLM-based APR."}
{"id": "2506.23488", "pdf": "https://arxiv.org/pdf/2506.23488", "abs": "https://arxiv.org/abs/2506.23488", "authors": ["Geng Sun", "Mingzhe Fan", "Lei Zhang", "Hongyang Pan", "Jiahui Li", "Chuang Zhang", "Linyao Li", "Changyuan Zhao", "Chau Yuen"], "title": "Generative AI-enhanced Low-Altitude UAV-Mounted Stacked Intelligent Metasurfaces", "categories": ["cs.NI"], "comment": "This paper has been already submitted to TCCN", "summary": "Wireless communication systems face significant challenges in meeting the\nincreasing demands for higher data rates and more reliable connectivity in\ncomplex environments. Stacked intelligent metasurfaces (SIMs) have emerged as a\npromising technology for realizing wave-domain signal processing, with mobile\nSIMs offering superior communication performance compared to their fixed\ncounterparts. In this paper, we investigate a novel unmanned aerial vehicle\n(UAV)-mounted SIMs (UAV-SIMs) assisted communication system within the\nlow-altitude economy (LAE) networks paradigm, where UAVs function as both base\nstations that cache SIM-processed data and mobile platforms that flexibly\ndeploy SIMs to enhance uplink communications from ground users. To maximize\nnetwork capacity, we formulate a UAV-SIM-based joint optimization problem\n(USBJOP) that comprehensively addresses three critical aspects: the association\nbetween UAV-SIMs and users, the three-dimensional positioning of UAV-SIMs, and\nthe phase shifts across multiple SIM layers. Due to the inherent non-convexity\nand NP-hardness of USBJOP, we decompose it into three sub-optimization\nproblems, \\textit{i.e.}, association between UAV-SIMs and users optimization\nproblem (AUUOP), UAV location optimization problem (ULOP), and UAV-SIM phase\nshifts optimization problem (USPSOP), and solve them using an alternating\noptimization strategy. Specifically, we transform AUUOP and ULOP into convex\nforms solvable by the CVX tool, while addressing USPSOP through a generative\nartificial intelligence (GAI)-based hybrid optimization algorithm. Simulations\ndemonstrate that our proposed approach significantly outperforms benchmark\nschemes, achieving approximately 1.5 times higher network capacity compared to\nsuboptimal alternatives. Additionally, our proposed GAI method reduces the\nalgorithm runtime by 10\\% while maintaining solution quality."}
{"id": "2506.23180", "pdf": "https://arxiv.org/pdf/2506.23180", "abs": "https://arxiv.org/abs/2506.23180", "authors": ["Riccardo Drago", "Yotam Sechayk", "Mustafa Doga Dogan", "Andrea Sanna", "Takeo Igarashi"], "title": "ImprovMate: Multimodal AI Assistant for Improv Actor Training", "categories": ["cs.HC", "H.5.0; H.5.2"], "comment": "ACM DIS '25", "summary": "Improvisation training for actors presents unique challenges, particularly in\nmaintaining narrative coherence and managing cognitive load during\nperformances. Previous research on AI in improvisation performance often\npredates advances in large language models (LLMs) and relies on human\nintervention. We introduce ImprovMate, which leverages LLMs as GPTs to automate\nthe generation of narrative stimuli and cues, allowing actors to focus on\ncreativity without keeping track of plot or character continuity. Based on\ninsights from professional improvisers, ImprovMate incorporates exercises that\nmimic live training, such as abrupt story resolution and reactive thinking\nexercises, while maintaining coherence via reference tables. By balancing\nrandomness and structured guidance, ImprovMate provides a groundbreaking tool\nfor improv training. Our pilot study revealed that actors might embrace AI\ntechniques if the latter mirrors traditional practices, and appreciate the\nfresh twist introduced by our approach with the AI-generated cues."}
{"id": "2506.23583", "pdf": "https://arxiv.org/pdf/2506.23583", "abs": "https://arxiv.org/abs/2506.23583", "authors": ["Marvin Xhemrishi", "Alexandre Graell i Amat", "Balázs Pejó"], "title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "The shorter version is accepted at FL-AsiaCCS 25", "summary": "Federated learning with secure aggregation enables private and collaborative\nlearning from decentralised data without leaking sensitive client information.\nHowever, secure aggregation also complicates the detection of malicious client\nbehaviour and the evaluation of individual client contributions to the\nlearning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et\nal.) were proposed for contribution evaluation (CE) and misbehaviour detection\n(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance\non the random selection of clients in each training round, while FedGT lacks\nthe CE ability. In this work, we combine the strengths of QI and FedGT to\nachieve both robust MD and accurate CE. Our experiments demonstrate superior\nperformance compared to using either method independently."}
{"id": "2506.23762", "pdf": "https://arxiv.org/pdf/2506.23762", "abs": "https://arxiv.org/abs/2506.23762", "authors": ["Hongzhou Rao", "Yanjie Zhao", "Xinyi Hou", "Shenao Wang", "Haoyu Wang"], "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has redefined\nartificial intelligence (AI), pushing the boundaries of AI research and\nenabling unbounded possibilities for both academia and the industry. However,\nLLM development faces increasingly complex challenges throughout its lifecycle,\nyet no existing research systematically explores these challenges and solutions\nfrom the perspective of software engineering (SE) approaches. To fill the gap,\nwe systematically analyze research status throughout the LLM development\nlifecycle, divided into six phases: requirements engineering, dataset\nconstruction, model development and enhancement, testing and evaluation,\ndeployment and operations, and maintenance and evolution. We then conclude by\nidentifying the key challenges for each phase and presenting potential research\ndirections to address these challenges. In general, we provide valuable\ninsights from an SE perspective to facilitate future advances in LLM\ndevelopment."}
{"id": "2506.23493", "pdf": "https://arxiv.org/pdf/2506.23493", "abs": "https://arxiv.org/abs/2506.23493", "authors": ["Jiahui Li", "Geng Sun", "Xiaoyu Sun", "Fang Mei", "Jingjing Wang", "Xiangwang Hou", "Daxin Tian", "Victor C. M. Leung"], "title": "Securing the Sky: Integrated Satellite-UAV Physical Layer Security for Low-Altitude Wireless Networks", "categories": ["cs.NI", "eess.SP"], "comment": "This paper has been submitted to IEEE Wireless Communications", "summary": "Low-altitude wireless networks (LAWNs) have garnered significant attention in\nthe forthcoming 6G networks. In LAWNs, satellites with wide coverage and\nunmanned aerial vehicles (UAVs) with flexible mobility can complement each\nother to form integrated satellite-UAV networks, providing ubiquitous and\nhigh-speed connectivity for low-altitude operations. However, the higher\nline-of-sight probability in low-altitude airspace increases transmission\nsecurity concerns. In this work, we present a collaborative beamforming-based\nphysical layer security scheme for LAWNs. We introduce the fundamental aspects\nof integrated satellite-UAV networks, physical layer security, UAV swarms, and\ncollaborative beamforming for LAWN applications. Following this, we highlight\nseveral opportunities for collaborative UAV swarm secure applications enabled\nby satellite networks, including achieving physical layer security in scenarios\ninvolving data dissemination, data relay, eavesdropper collusion, and imperfect\neavesdropper information. Next, we detail two case studies: a secure relay\nsystem and a two-way aerial secure communication framework specifically\ndesigned for LAWN environments. Simulation results demonstrate that these\nphysical layer security schemes are effective and beneficial for secure\nlow-altitude wireless communications. A short practicality analysis shows that\nthe proposed method is applicable to LAWN scenarios. Finally, we discuss\ncurrent challenges and future research directions for enhancing security in\nLAWNs."}
{"id": "2506.23253", "pdf": "https://arxiv.org/pdf/2506.23253", "abs": "https://arxiv.org/abs/2506.23253", "authors": ["Advait Sarkar", "Ian Drosos"], "title": "Vibe coding: programming through conversation with artificial intelligence", "categories": ["cs.HC"], "comment": null, "summary": "We examine \"vibe coding\": an emergent programming paradigm where developers\nprimarily write code by interacting with code-generating large language models\nrather than writing code directly. We analysed a curated set of videos\ndepicting extended vibe coding sessions with rich think-aloud reflections.\nUsing framework analysis, we investigated programmers' goals, workflows,\nprompting techniques, debugging approaches, and challenges encountered. We find\nthat vibe coding follows iterative goal satisfaction cycles where developers\nalternate between prompting AI, evaluating generated code through rapid\nscanning and application testing, and manual editing. Prompting strategies\nblend vague, high-level directives with detailed technical specifications.\nDebugging remains a hybrid process combining AI assistance with manual\npractices. Critically, vibe coding does not eliminate the need for programming\nexpertise but rather redistributes it toward context management, rapid code\nevaluation, and decisions about when to transition between AI-driven and manual\nmanipulation of code. Trust in AI tools during vibe coding is dynamic and\ncontextual, developed through iterative verification rather than blanket\nacceptance. Vibe coding is an evolution of AI-assisted programming that\nrepresents an early manifestation of \"material disengagement\", where\npractitioners orchestrate code production and manipulation, mediated through\nAI, while maintaining selective and strategic oversight."}
{"id": "2506.23836", "pdf": "https://arxiv.org/pdf/2506.23836", "abs": "https://arxiv.org/abs/2506.23836", "authors": ["Alexander Tyurin"], "title": "Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction", "categories": ["math.OC", "cs.DC", "cs.LG"], "comment": null, "summary": "We consider centralized distributed optimization in the classical federated\nlearning setup, where $n$ workers jointly find an $\\varepsilon$-stationary\npoint of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access\nonly to unbiased stochastic gradients with variance $\\sigma^2$. Each worker\nrequires at most $h$ seconds to compute a stochastic gradient, and the\ncommunication times from the server to the workers and from the workers to the\nserver are $\\tau_{s}$ and $\\tau_{w}$ seconds per coordinate, respectively. One\nof the main motivations for distributed optimization is to achieve scalability\nwith respect to $n$. For instance, it is well known that the distributed\nversion of SGD has a variance-dependent runtime term $\\frac{h \\sigma^2 L\n\\Delta}{n \\varepsilon^2},$ which improves with the number of workers $n,$ where\n$\\Delta = f(x^0) - f^*,$ and $x^0 \\in R^d$ is the starting point. Similarly,\nusing unbiased sparsification compressors, it is possible to reduce both the\nvariance-dependent runtime term and the communication runtime term. However,\nonce we account for the communication from the server to the workers\n$\\tau_{s}$, we prove that it becomes infeasible to design a method using\nunbiased random sparsification compressors that scales both the server-side\ncommunication runtime term $\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$ and the\nvariance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2},$\nbetter than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,\nwhere all workers access the same distribution. To establish this result, we\nconstruct a new \"worst-case\" function and develop a new lower bound framework\nthat reduces the analysis to the concentration of a random sum, for which we\nprove a concentration bound. These results reveal fundamental limitations in\nscaling distributed optimization, even under the homogeneous assumption."}
{"id": "2506.23898", "pdf": "https://arxiv.org/pdf/2506.23898", "abs": "https://arxiv.org/abs/2506.23898", "authors": ["Diogo Lemos", "Ademar Aguiar", "Neil B. Harrison"], "title": "Requirements for Active Assistance of Natural Questions in Software Architecture", "categories": ["cs.SE"], "comment": null, "summary": "Natural questions are crucial to shaping key architectural decisions and\npreserving architectural knowledge. They arise organically during the\narchitectural design process, often resulting from the existing architectural\nexperience of the designer and the distinctive characteristics of the system\nbeing designed. However, natural questions are often mismanaged or ignored,\nwhich can lead to architectural drift, knowledge loss, inefficient resource\nuse, or poor understandability of the system's architecture. We aim to better\nunderstand the lifecycle of natural questions, its key requirements, challenges\nand difficulties, and then to envision an assisted environment to properly\nsupport it. The environment should be adaptable and responsive to real-world\nconstraints and uncertainties by seamlessly integrating knowledge management\ntools and artificial intelligence techniques into software development\nworkflows. Based on existing literature, a requirements workshop, and three\ndesign iterations, we proposed a lifecycle for natural questions and elicited\nessential functional and non-functional requirements for such an environment.\nAt last, the results of a survey conducted with experts helped to analyze and\nvalidate the elicited requirements and proposed features for the environment to\nenhance collaboration, decision-making, and the preservation of architectural\nknowledge more effectively than conventional methods."}
{"id": "2506.23628", "pdf": "https://arxiv.org/pdf/2506.23628", "abs": "https://arxiv.org/abs/2506.23628", "authors": ["Antonio Ojea"], "title": "The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking", "categories": ["cs.NI", "cs.AI"], "comment": "6 pages, 9 figures, submitted to IEEE LCN Special Track on\n  Cloud-AI-Native Mobile Networks Powered by eBPF (CAMe 2025)", "summary": "Traditional Kubernetes networking struggles to meet the escalating demands of\nAI/ML and evolving Telco infrastructure. This paper introduces Kubernetes\nNetwork Drivers (KNDs), a transformative, modular, and declarative architecture\ndesigned to overcome current imperative provisioning and API limitations. KNDs\nintegrate network resource management into Kubernetes' core by utilizing\nDynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements,\nand upcoming OCI Runtime Specification changes. Our DraNet implementation\ndemonstrates declarative attachment of network interfaces, including Remote\nDirect Memory Access (RDMA) devices, significantly boosting high-performance\nAI/ML workloads. This capability enables sophisticated cloud-native\napplications and lays crucial groundwork for future Telco solutions, fostering\na \"galaxy\" of specialized KNDs for enhanced application delivery and reduced\noperational complexity."}
{"id": "2506.23443", "pdf": "https://arxiv.org/pdf/2506.23443", "abs": "https://arxiv.org/abs/2506.23443", "authors": ["Samuel Reinders", "Munazza Zaib", "Matthew Butler", "Bongshin Lee", "Ingrid Zukerman", "Lizhen Qu", "Kim Marriott"], "title": "Accessible Data Access and Analysis by People who are Blind or Have Low Vision", "categories": ["cs.HC"], "comment": "Poster presented at the 1st Workshop on Accessible Data\n  Visualization, IEEE VIS 2024", "summary": "Our work aims to develop new assistive technologies that enable blind or low\nvision (BLV) people to explore and analyze data readily. At present, barriers\nexist for BLV people to explore and analyze data, restricting access to\ngovernment, health and personal data, and limiting employment opportunities.\nThis work explores the co-design and development of an innovative system to\nsupport data access, with a focus on the use of refreshable tactile displays\n(RTDs) and conversational agents. The envisaged system will use a combination\nof tactile graphics and speech to communicate with BLV users, and proactively\nassist with data analysis tasks. As well as addressing significant equity gaps,\nour work expects to produce innovations in assistive technology, multimodal\ninterfaces, dialogue systems, and natural language understanding and\ngeneration."}
{"id": "2506.23906", "pdf": "https://arxiv.org/pdf/2506.23906", "abs": "https://arxiv.org/abs/2506.23906", "authors": ["Aleksandros Sobczyk", "Giuseppe Sorrentino", "Anastasios Zouzias"], "title": "Segmented Operations using Matrix Multiplications", "categories": ["cs.DS", "cs.CC", "cs.DC"], "comment": null, "summary": "Specialized computational units that perform small matrix multiplications as\nprimitive operations are typically present in modern accelerators. However,\nthese units are often underutilized for many fundamental operations besides\ndense matrix multiplications. The analysis of algorithms for such architectures\nis currently stagnated due to the lack of a rigorous theoretical model of\ncomputation that captures their characteristics. In this work, we propose\nMMV-RAM, a computational model tailored to matrix multiplication accelerators.\nMMV-RAM judiciously extends the Vector-RAM model with an additional processing\nunit that multiplies two matrices of sizes $n\\times s$ and $s\\times s$ in a\nsingle parallel step, where $s$ is a model parameter. We provide a detailed\ntheoretical analysis of the model, and carefully balance the computational\npower between the matrix and vector units, guided by the circuit complexity\nlower bound that parity is not in AC[0].\n  In MMV-RAM, we study algorithms for segmented scan and sum, two fundamental\nparallel primitives. We propose a segmented scan algorithm that uses matrix\nmultiplications to perform speculative block-scan computations, which runs in\n$O(\\log_s(n))$ steps. In contrast, we show that any algorithm that uses only\nthe vector unit of MMV-RAM requires\n$\\Omega\\left(\\frac{\\log_2(n)}{\\log_2\\log_2(n)}\\right)$ steps. We further apply\nthese techniques to obtain similar theoretical speedups for element-wise vector\nmultiplication and matrix multiplication. Beyond the worst-case complexity\nanalysis, we propose algorithms for segmented operations that could lead to\nhighly efficient and pragmatic implementations. For example, we observe that\nsegmented sum is a combination of three elementary parallel primitives: scan,\ncompress, and vector differentiation. As a case study, we implement..."}
{"id": "2506.23967", "pdf": "https://arxiv.org/pdf/2506.23967", "abs": "https://arxiv.org/abs/2506.23967", "authors": ["Geerd-Dietger Hoffmann", "Verena Majuntke"], "title": "Green Metrics Tool: Measuring for fun and profit", "categories": ["cs.SE", "cs.CY", "cs.ET"], "comment": null, "summary": "The environmental impact of software is gaining increasing attention as the\ndemand for computational resources continues to rise. In order to optimize\nsoftware resource consumption and reduce carbon emissions, measuring and\nevaluating software is a first essential step. In this paper we discuss what\nmetrics are important for fact base decision making. We introduce the Green\nMetrics Tool (GMT), a novel framework for accurately measuring the resource\nconsumption of software. The tool provides a containerized, controlled, and\nreproducible life cycle-based approach, assessing the resource use of software\nduring key phases. Finally, we discuss GMT features like visualization,\ncomparability and rule- and LLM-based optimisations highlighting its potential\nto guide developers and researchers in reducing the environmental impact of\ntheir software."}
{"id": "2506.23640", "pdf": "https://arxiv.org/pdf/2506.23640", "abs": "https://arxiv.org/abs/2506.23640", "authors": ["Ximeng Liu", "Shizhen Zhao", "Xinbing Wang"], "title": "Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "Recently, researchers have explored ML-based Traffic Engineering (TE),\nleveraging neural networks to solve TE problems traditionally addressed by\noptimization. However, existing ML-based TE schemes remain impractical: they\neither fail to handle topology changes or suffer from poor scalability due to\nexcessive computational and memory overhead. To overcome these limitations, we\npropose Geminet, a lightweight and scalable ML-based TE framework that can\nhandle changing topologies. Geminet is built upon two key insights: (i) a\nmethodology that decouples neural networks from topology by learning an\niterative gradient-descent-based adjustment process, as the update rule of\ngradient descent is topology-agnostic, relying only on a few gradient-related\nquantities; (ii) shifting optimization from path-level routing weights to\nedge-level dual variables, reducing memory consumption by leveraging the fact\nthat edges are far fewer than paths. Evaluations on WAN and data center\ndatasets show that Geminet significantly improves scalability. Its neural\nnetwork size is only 0.04% to 7% of existing schemes, while handling topology\nvariations as effectively as HARP, a state-of-the-art ML-based TE approach,\nwithout performance degradation. When trained on large-scale topologies,\nGeminet consumes under 10 GiB of memory, more than eight times less than the\n80-plus GiB required by HARP, while achieving 5.45 times faster convergence\nspeed, demonstrating its potential for large-scale deployment."}
{"id": "2506.23457", "pdf": "https://arxiv.org/pdf/2506.23457", "abs": "https://arxiv.org/abs/2506.23457", "authors": ["Yuya Ide", "Hailong Liu", "Takahiro Wada"], "title": "Reducing Motion Sickness in Passengers of Autonomous Personal Mobility Vehicles by Presenting a Driving Path", "categories": ["cs.HC"], "comment": null, "summary": "Autonomous personal mobility vehicles (APMVs) are small mobility devices\ndesigned for individual automated transportation in shared spaces. In such\nenvironments, frequent pedestrian avoidance maneuvers may cause rapid steering\nadjustments and passive postural responses from passengers, thereby increasing\nthe risk of motion sickness. This study investigated the effects of providing\npath information on 16 passengers' head movement behavior and motion sickness\nwhile riding an APMV. Through a controlled experiment comparing manual driving\n(MD), autonomous driving without path information (AD w/o path), and autonomous\ndriving with path information (AD w/ path), we found that providing path cues\nsignificantly reduced MISC scores and delayed the onset of motion sickness\nsymptoms. In addition, participants were more likely to proactively align their\nhead movements with the direction of vehicle rotation in both MD and AD w/ path\nconditions. Although a small correlation was observed between the delay in yaw\nrotation of the passenger's head relative to the vehicle and the occurrence of\nmotion sickness, the underlying physiological mechanism remains to be\nelucidated."}
{"id": "2506.23995", "pdf": "https://arxiv.org/pdf/2506.23995", "abs": "https://arxiv.org/abs/2506.23995", "authors": ["Mingfei Cheng", "Renzhi Wang", "Xiaofei Xie", "Yuan Zhou", "Lei Ma"], "title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems", "categories": ["cs.SE", "cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous Driving System (ADS) testing is essential to ensure the safety and\nreliability of autonomous vehicles (AVs) before deployment. However, existing\ntechniques primarily focus on evaluating ADS functionalities in single-AV\nsettings. As ADSs are increasingly deployed in multi-AV traffic, it becomes\ncrucial to assess their cooperative performance, particularly regarding\ndeadlocks, a fundamental coordination failure in which multiple AVs enter a\ncircular waiting state indefinitely, resulting in motion planning failures.\nDespite its importance, the cooperative capability of ADSs to prevent deadlocks\nremains insufficiently underexplored. To address this gap, we propose the first\ndedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique,\nSTCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs\ncontrolled by the ADS under test are in a circular wait state. STCLocker\nconsists of three key components: Deadlock Oracle, Conflict Feedback, and\nConflict-aware Scenario Generation. Deadlock Oracle provides a reliable\nblack-box mechanism for detecting deadlock cycles among multiple AVs within a\ngiven scenario. Conflict Feedback and Conflict-aware Scenario Generation\ncollaborate to actively guide AVs into simultaneous competition over spatial\nconflict resources (i.e., shared passing regions) and temporal competitive\nbehaviors (i.e., reaching the conflict region at the same time), thereby\nincreasing the effectiveness of generating conflict-prone deadlocks. We\nevaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA,\na module-based ADS supporting cooperative communication. Experimental results\nshow that, on average, STCLocker generates more DLS than the best-performing\nbaseline."}
{"id": "2506.23740", "pdf": "https://arxiv.org/pdf/2506.23740", "abs": "https://arxiv.org/abs/2506.23740", "authors": ["Andrew E. Ferguson", "Ujjwal Pawar", "Tianxin Wang", "Mahesh K. Marina"], "title": "Campus5G: A Campus Scale Private 5G Open RAN Testbed", "categories": ["cs.NI", "C.2.1"], "comment": null, "summary": "Mobile networks are embracing disaggregation, reflected by the industry trend\ntowards Open RAN. Private 5G networks are viewed as particularly suitable\ncontenders as early adopters of Open RAN, owing to their setting, high degree\nof control, and opportunity for innovation they present. Motivated by this, we\nhave recently deployed Campus5G, the first of its kind campus-wide,\nO-RAN-compliant private 5G testbed across the central campus of the University\nof Edinburgh. We present in detail our process developing the testbed, from\nplanning, to architecting, to deployment, and measuring the testbed\nperformance. We then discuss the lessons learned from building the testbed, and\nhighlight some research opportunities that emerged from our deployment\nexperience."}
{"id": "2506.23458", "pdf": "https://arxiv.org/pdf/2506.23458", "abs": "https://arxiv.org/abs/2506.23458", "authors": ["Xiaoxiao Yang", "Chan Feng", "Jiancheng Chen"], "title": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs", "categories": ["cs.HC", "cs.LG"], "comment": "2 pages short paper", "summary": "Portable and wearable consumer-grade electroencephalography (EEG) devices,\nlike Muse headbands, offer unprecedented mobility for daily brain-computer\ninterface (BCI) applications, including cognitive load detection. However, the\nexacerbated non-stationarity in portable EEG signals constrains data fidelity\nand decoding accuracy, creating a fundamental trade-off between portability and\nperformance. To mitigate such limitation, we propose MuseCogNet (Muse-based\nCognitive Network), a unified joint learning framework integrating\nself-supervised and supervised training paradigms. In particular, we introduce\nan EEG-grounded self-supervised reconstruction loss based on average pooling to\ncapture robust neurophysiological patterns, while cross-entropy loss refines\ntask-specific cognitive discriminants. This joint learning framework resembles\nthe bottom-up and top-down attention in humans, enabling MuseCogNet to\nsignificantly outperform state-of-the-art methods on a publicly available Muse\ndataset and establish an implementable pathway for neurocognitive monitoring in\necological settings."}
{"id": "2506.24015", "pdf": "https://arxiv.org/pdf/2506.24015", "abs": "https://arxiv.org/abs/2506.24015", "authors": ["Ramtin Ehsani", "Esteban Parra", "Sonia Haiduc", "Preetha Chatterjee"], "title": "Bug Fixing with Broader Context: Enhancing LLM-Based Program Repair via Layered Knowledge Injection", "categories": ["cs.SE"], "comment": null, "summary": "Prompting LLMs with bug-related context (e.g., error messages, stack traces)\nimproves automated program repair, but many bugs still remain unresolved. In\nreal-world projects, developers often rely on broader repository and\nproject-level context beyond the local code to resolve such bugs. In this\npaper, we investigate how automatically extracting and providing such knowledge\ncan improve LLM-based program repair. We propose a layered knowledge injection\nframework that incrementally augments LLMs with structured context. It starts\nwith the Bug Knowledge Layer, which includes information such as the buggy\nfunction and failing tests; expands to the Repository Knowledge Layer, which\nadds structural dependencies, related files, and commit history; and finally\ninjects the Project Knowledge Layer, which incorporates relevant details from\ndocumentation and previously fixed bugs. We evaluate this framework on a\ndataset of 314 bugs from BugsInPy using two LLMs (Llama 3.3 and GPT-4o-mini),\nand analyze fix rates across six bug types. By progressively injecting\nknowledge across layers, our approach achieves a fix rate of 79% (250/314)\nusing Llama 3.3, a significant improvement of 23% over previous work. All bug\ntypes show improvement with the addition of repository-level context, while\nonly a subset benefit further from project-level knowledge, highlighting that\ndifferent bug types require different levels of contextual information for\neffective repair. We also analyze the remaining unresolved bugs and find that\nmore complex and structurally isolated bugs, such as Program Anomaly and GUI\nbugs, remain difficult even after injecting all available information. Our\nresults show that layered context injection improves program repair and suggest\nthe need for interactive and adaptive APR systems."}
{"id": "2506.23755", "pdf": "https://arxiv.org/pdf/2506.23755", "abs": "https://arxiv.org/abs/2506.23755", "authors": ["Shawon Mitra", "Subhojit Sarkar", "Sasthi C. Ghosh"], "title": "How Long Can I Transmit? A Mobility Aware mmWave-based UAV Communication Framework", "categories": ["cs.NI", "eess.SP"], "comment": "This article has been submitted in a reputed conference", "summary": "One primary focus of next generation wireless communication networks is the\nmillimeterwave (mmWave) spectrum, typically considered in the 30 GHz to 300 GHz\nfrequency range. Despite their promise of high data rates, mmWaves suffer from\nsevere attenuation while passing through obstacles. Unmanned aerial vehicles\n(UAVs) have been proposed to offset this limitation on account of their\nadditional degrees of freedom, which can be leveraged to provide line of sight\n(LoS) transmission paths. While some prior works have proposed analytical\nframeworks to compute the LoS probability for static ground users and a UAV,\nthe same is lacking for mobile users on the ground. In this paper, we consider\nthe popular Manhattan point line process (MPLP) to model an urban environment,\nwithin which a ground user moves with a known velocity for a small time\ninterval along the roads. We derive an expression for the expected duration of\nLoS between a static UAV in the air and a mobile ground user, and validate the\nsame through simulations. To demonstrate the efficacy of the proposed analysis,\nwe propose a simple user association algorithm that greedily assigns the UAVs\nto users with the highest expected LoS time, and show that it outperforms the\nexisting benchmark schemes that assign the users to the nearest UAVs with LoS\nwithout considering the user mobility."}
{"id": "2506.23545", "pdf": "https://arxiv.org/pdf/2506.23545", "abs": "https://arxiv.org/abs/2506.23545", "authors": ["Barbara Karpowicz", "Maciej Grzeszczuk", "Adam Kuzdraliński", "Monika Kornacka", "Aliaksandr Marozau", "Wiktor Stawski", "Pavlo Zinevych", "Grzegorz Marcin Wójcik", "Tomasz Kowalewski", "Grzegorz Pochwatko", "Wiesław Kopeć"], "title": "Immersive Technologies in Training and Healthcare: From Space Missions to Psychophysiological Research", "categories": ["cs.HC", "cs.CE"], "comment": "8 pages, 1 figure", "summary": "Virtual, Augmented, and eXtended Reality (VR/AR/XR) technologies are\nincreasingly recognized for their applications in training, diagnostics, and\npsychological research, particularly in high-risk and highly regulated\nenvironments. In this panel we discuss how immersive systems enhance human\nperformance across multiple domains, including clinical psychology, space\nexploration, and medical education. In psychological research and training, XR\ncan offer a controlled yet ecologically valid setting for measuring cognitive\nand affective processes. In space exploration, we discuss the development of\nVR-based astronaut training and diagnostic systems, allowing astronauts to\nperform real-time health assessments. In medical education and rehabilitation,\nwe cover procedural training and patient engagement. From virtual surgical\nsimulations to gamified rehabilitation exercises, immersive environments\nenhance both learning outcomes and treatment adherence."}
{"id": "2506.22954", "pdf": "https://arxiv.org/pdf/2506.22954", "abs": "https://arxiv.org/abs/2506.22954", "authors": ["Minnan Wei", "Ziming Li", "Xiang Chen", "Menglin Zheng", "Ziyan Qu", "Cheng Yu", "Siyu Chen", "Xiaolin Ju"], "title": "Evaluating and Improving Large Language Models for Competitive Program Generation", "categories": ["cs.SI", "cs.SE"], "comment": null, "summary": "Context: Due to the demand for strong algorithmic reasoning, complex logic\nimplementation, and strict adherence to input/output formats and resource\nconstraints, competitive programming generation by large language models (LLMs)\nis considered the most challenging problem in current LLM-based code\ngeneration. However, previous studies often evaluate LLMs using simple prompts\nand benchmark datasets prone to data leakage. Moreover, prior work has limited\nconsideration of the diversity in algorithm types and difficulty levels.\nObjective: In this study, we aim to evaluate and improve LLMs in solving\nreal-world competitive programming problems. Methods: We initially collect 117\nproblems from nine regional ICPC/CCPC contests held in 2024 and design four\nfiltering criteria to construct a curated benchmark consisting of 80 problems.\nLeveraging DeepSeek-R1 as the LLM, we evaluate its competitive program\ngeneration capabilities through the online judge (OJ) platforms, guided by a\ncarefully designed basic prompt. For incorrect submissions, we construct a\nfine-grained error taxonomy and then propose a targeted improvement framework\nby combining a multi-turn dialogue-based repair phase and an\ninformation-augmented regeneration phase. Results: Experimental results show\nthat only 5 out of 80 problems are fully accepted when using basic prompts. For\nthe unsolved problems, we construct the error taxonomy, including general\nerrors (such as design, boundary, condition, data type, syntax, and\ninput/output errors) and specialized errors (such as those in mathematical\nproblems, greedy algorithms, and graph theories). After applying our proposed\nimprovement strategies, we substantially increased the number of correct\nsolutions, with 46 out of 80 problems successfully accepted."}
{"id": "2506.23964", "pdf": "https://arxiv.org/pdf/2506.23964", "abs": "https://arxiv.org/abs/2506.23964", "authors": ["Hongyu Hè", "Minhao Jin", "Maria Apostolaki"], "title": "Learning Constraints Directly from Network Data", "categories": ["cs.NI", "cs.LG", "C.2.3; I.2.6; I.2.3"], "comment": "13 pages, 15 figures", "summary": "Network data conforms to a wide range of rules that arise from protocols,\ndesign principles, and deployment decisions (e.g., a packet's queuing delay\nmust be less than its end-to-end delay). Formalizing such rules as logic\nconstraints can (i) improve the quality of synthetic data, (ii) reduce the\nbrittleness of machine learning (ML) models, and (iii) improve semantic\nunderstanding of network measurements. However, these benefits remain out of\nreach if rule extraction is manual or solely reliant on ML, as both approaches\nyield incomplete, unreliable, and/or inaccurate rules.\n  This paper formulates rule extraction as a constraint modeling problem and\nintroduces NetNomos that learns propositional logic constraints directly from\nraw network measurements. Constraint modeling in this domain is uniquely\nchallenging due to the scale of the data, the inherent learning complexity and\npassive environment, and the lack of ground truth supervision. NetNomos\naddresses these challenges via a lattice-based search structured by constraint\nspecificity and succinctness. Our approach reduces learning complexity from\nsuperquadratic to logarithmic and enables efficient traversal in combinatorial\nsearch space.\n  Our evaluations on diverse network datasets show that NetNomos learns all\nbenchmark rules, including those associated with as little as 0.01% of data\npoints, in under three hours. In contrast, baseline methods discover less than\n25% of the rules and require several days to run. Through three case studies,\nwe show that: NetNomos (i) finds rule violations in the outputs of all seven\nsynthetic traffic generators, hence can be used to assess and guide their\ngeneration process; (ii) detects semantic differences in traffic, hence can be\nused for anomaly detection; and (iii) automatically finds rules used for\ntelemetry imputation, hence can support monitoring through inference."}
{"id": "2506.23678", "pdf": "https://arxiv.org/pdf/2506.23678", "abs": "https://arxiv.org/abs/2506.23678", "authors": ["Rock Yuren Pang", "K. J. Kevin Feng", "Shangbin Feng", "Chu Li", "Weijia Shi", "Yulia Tsvetkov", "Jeffrey Heer", "Katharina Reinecke"], "title": "Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The output quality of large language models (LLMs) can be improved via\n\"reasoning\": generating segments of chain-of-thought (CoT) content to further\ncondition the model prior to producing user-facing output. While these chains\ncontain valuable information, they are verbose and lack explicit organization,\nmaking them tedious to review. Moreover, they lack opportunities for user\nfeedback, such as to remove unwanted considerations, add desired ones, or\nclarify unclear assumptions. We introduce Interactive Reasoning, an interaction\ndesign that visualizes chain-of-thought outputs as a hierarchy of topics and\nenables user review and modification. We implement interactive reasoning in\nHippo, a prototype for AI-assisted decision making in the face of uncertain\ntrade-offs. In a user study with 16 participants, we find that interactive\nreasoning in Hippo allows users to quickly identify and interrupt erroneous\ngenerations, efficiently steer the model towards customized responses, and\nbetter understand both model reasoning and model outputs. Our work contributes\nto a new paradigm that incorporates user oversight into LLM reasoning\nprocesses."}
{"id": "2506.23683", "pdf": "https://arxiv.org/pdf/2506.23683", "abs": "https://arxiv.org/abs/2506.23683", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Threadbox: Sandboxing for Modular Security", "categories": ["cs.CR", "cs.OS", "cs.SE"], "comment": null, "summary": "There are many sandboxing mechanisms provided by operating systems to limit\nwhat resources applications can access, however, sometimes the use of these\nmechanisms requires developers to refactor their code to fit the sandboxing\nmodel. In this work, we investigate what makes existing sandboxing mechanisms\nchallenging to apply to certain types of applications, and propose Threadbox, a\nsandboxing mechanism that enables having modular and independent sandboxes, and\ncan be applied to threads and sandbox specific functions. We present case\nstudies to illustrate the applicability of the idea and discuss its\nlimitations."}
{"id": "2506.22471", "pdf": "https://arxiv.org/pdf/2506.22471", "abs": "https://arxiv.org/abs/2506.22471", "authors": ["Muhammad Ahmed Mohsin", "Muhammad Umer", "Ahsan Bilal", "Muhammad Ali Jamshed", "John M. Cioffi"], "title": "Continual Learning for Wireless Channel Prediction", "categories": ["eess.SP", "cs.NI"], "comment": "Accepted at ICML Workshop on ML4Wireless", "summary": "Modern 5G/6G deployments routinely face cross-configuration handovers--users\ntraversing cells with different antenna layouts, carrier frequencies, and\nscattering statistics--which inflate channel-prediction NMSE by $37.5\\%$ on\naverage when models are naively fine-tuned. The proposed improvement frames\nthis mismatch as a continual-learning problem and benchmarks three adaptation\nfamilies: replay with loss-aware reservoirs, synaptic-importance\nregularization, and memory-free learning-without-forgetting. Across three\nrepresentative 3GPP urban micro scenarios, the best replay and regularization\nschemes cut the high-SNR error floor by up to 2~dB ($\\approx 35\\%$), while even\nthe lightweight distillation recovers up to $30\\%$ improvement over baseline\nhandover prediction schemes. These results show that targeted rehearsal and\nparameter anchoring are essential for handover-robust CSI prediction and\nsuggest a clear migration path for embedding continual-learning hooks into\ncurrent channel prediction efforts in 3GPP--NR and O-RAN. The full codebase can\nbe found at\nhttps://github.com/ahmd-mohsin/continual-learning-channel-prediction.git."}
{"id": "2506.23694", "pdf": "https://arxiv.org/pdf/2506.23694", "abs": "https://arxiv.org/abs/2506.23694", "authors": ["Patrick Stadler", "Christopher Lazik", "Christopher Katins", "Thomas Kosch"], "title": "If You Had to Pitch Your Ideal Software -- Evaluating Large Language Models to Support User Scenario Writing for User Experience Experts and Laypersons", "categories": ["cs.HC"], "comment": null, "summary": "The process of requirements analysis requires an understanding of the end\nusers of a system. Thus, expert stakeholders, such as User Experience (UX)\ndesigners, usually create various descriptions containing information about the\nusers and their possible needs. In our paper, we investigate to what extent UX\nnovices are able to write such descriptions into user scenarios. We conducted a\nuser study with 60 participants consisting of 30 UX experts and 30 novices who\nwere asked to write a user scenario with or without the help of an\nLLM-supported writing assistant. Our findings show that LLMs empower laypersons\nto write reasonable user scenarios and provide first-hand insights for\nrequirements analysis that are comparable to UX experts in terms of structure\nand clarity, while especially excelling at audience-orientation. We present our\nqualitative and quantitative findings, including user scenario anatomies,\npotential influences, and differences in the way participants approached the\ntask."}
{"id": "2506.23841", "pdf": "https://arxiv.org/pdf/2506.23841", "abs": "https://arxiv.org/abs/2506.23841", "authors": ["Ítalo Oliveira", "Stefano M. Nicoletti", "Gal Engelberg", "Mattia Fumagalli", "Dan Klein", "Giancarlo Guizzardi"], "title": "An ontological lens on attack trees: Toward adequacy and interoperability", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Attack Trees (AT) are a popular formalism for security analysis. They are\nmeant to display an attacker's goal decomposed into attack steps needed to\nachieve it and compute certain security metrics (e.g., attack cost,\nprobability, and damage). ATs offer three important services: (a) conceptual\nmodeling capabilities for representing security risk management scenarios, (b)\na qualitative assessment to find root causes and minimal conditions of\nsuccessful attacks, and (c) quantitative analyses via security metrics\ncomputation under formal semantics, such as minimal time and cost among all\nattacks. Still, the AT language presents limitations due to its lack of\nontological foundations, thus compromising associated services. Via an\nontological analysis grounded in the Common Ontology of Value and Risk (COVER)\n-- a reference core ontology based on the Unified Foundational Ontology (UFO)\n-- we investigate the ontological adequacy of AT and reveal four significant\nshortcomings: (1) ambiguous syntactical terms that can be interpreted in\nvarious ways; (2) ontological deficit concerning crucial domain-specific\nconcepts; (3) lacking modeling guidance to construct ATs decomposing a goal;\n(4) lack of semantic interoperability, resulting in ad hoc stand-alone tools.\nWe also discuss existing incremental solutions and how our analysis paves the\nway for overcoming those issues through a broader approach to risk management\nmodeling."}
{"id": "2506.22844", "pdf": "https://arxiv.org/pdf/2506.22844", "abs": "https://arxiv.org/abs/2506.22844", "authors": ["Navid Keshtiarast", "Marina Petrova"], "title": "Coexistence analysis of Wi-Fi 6E and 5G NR-U in the 6 GHz band", "categories": ["eess.SP", "cs.NI"], "comment": "Accepted for Publication in ICNS3 2025", "summary": "The ever-increasing demand for broadband and IoT wireless connectivity has\nrecently urged the regulators around the world to start opening the 6 GHz\nspectrum for unlicensed use. These bands will, for example, permit the use of\nadditional 1.2 GHz in the US and 500 MHz in Europe for unlicensed radio access\ntechnologies (RATs) such as Wi-Fi and 5G New Radio Unlicensed (5G NR-U). To\nsupport QoS-sensitive applications with both technologies, fair and efficient\ncoexistence approaches between the two RATs, as well as with incumbents already\noperating in the 6 GHz band, are crucial. In this paper, we study through\nextensive simulations the achievable mean downlink throughput of both Wi-Fi 6E\nAPs and 5G NR-U gNBs when they are co-deployed in a dense residential scenario\nunder high-interference conditions. We also explore how different parameter\nsettings e.g., MAC frame aggregation, energy detection threshold and maximum\nchannel occupancy time (MCOT) affect the coexistence. Our findings give\nimportant insights into how to tune the key parameters to design fair\ncoexistence policies."}
{"id": "2506.23815", "pdf": "https://arxiv.org/pdf/2506.23815", "abs": "https://arxiv.org/abs/2506.23815", "authors": ["Patrick Stokkink"], "title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The influence of Artificial Intelligence (AI), and specifically Large\nLanguage Models (LLM), on education is continuously increasing. These models\nare frequently used by students, giving rise to the question whether current\nforms of assessment are still a valid way to evaluate student performance and\ncomprehension. The theoretical framework developed in this paper is grounded in\nConstructive Alignment (CA) theory and Bloom's taxonomy for defining learning\nobjectives. We argue that AI influences learning objectives of different Bloom\nlevels in a different way, and assessment has to be adopted accordingly.\nFurthermore, in line with Bloom's vision, formative and summative assessment\nshould be aligned on whether the use of AI is permitted or not.\n  Although lecturers tend to agree that education and assessment need to be\nadapted to the presence of AI, a strong bias exists on the extent to which\nlecturers want to allow for AI in assessment. This bias is caused by a\nlecturer's familiarity with AI and specifically whether they use it themselves.\nTo avoid this bias, we propose structured guidelines on a university or faculty\nlevel, to foster alignment among the staff. Besides that, we argue that\nteaching staff should be trained on the capabilities and limitations of AI\ntools. In this way, they are better able to adapt their assessment methods."}
{"id": "2506.23866", "pdf": "https://arxiv.org/pdf/2506.23866", "abs": "https://arxiv.org/abs/2506.23866", "authors": ["Jason Kayembe", "Iness Ben Guirat", "Jan Tobias Mühlberg"], "title": "Exploring Privacy and Security as Drivers for Environmental Sustainability in Cloud-Based Office Solutions", "categories": ["cs.CR", "cs.CY", "cs.SE"], "comment": "Post-proceedings paper persented at LOCO '24: 1st International\n  Workshop on Low Carbon Computing, 2024-12-03, in Glasgow, UK", "summary": "In this paper, we explore the intersection of privacy, security, and\nenvironmental sustainability in cloud-based office solutions, focusing on\nquantifying user- and network-side energy use and associated carbon emissions.\nWe hypothesise that privacy-focused services are typically more\nenergy-efficient than those funded through data collection and advertising. To\nevaluate this, we propose a framework that systematically measures\nenvironmental costs based on energy usage and network data traffic during\nwell-defined, automated usage scenarios. To test our hypothesis, we first\nanalyse how underlying architectures and business models, such as monetisation\nthrough personalised advertising, contribute to the environmental footprint of\nthese services. We then explore existing methodologies and tools for software\nenvironmental impact assessment. We apply our framework to three mainstream\nemail services selected to reflect different privacy policies, from\nad-supported tracking-intensive models to privacy-focused designs: Microsoft\nOutlook, Google Mail (Gmail), and Proton Mail. We extend this comparison to a\nself-hosted email solution, evaluated with and without end-to-end encryption.\nWe show that the self-hosted solution, even with 14% of device energy and 15%\nof emissions overheads from PGP encryption, remains the most energy-efficient,\nsaving up to 33% of emissions per session compared to Gmail. Among commercial\nproviders, Proton Mail is the most efficient, saving up to 0.1 gCO2 e per\nsession compared to Outlook, whose emissions can be further reduced by 2%\nthrough ad-blocking."}
{"id": "2506.22884", "pdf": "https://arxiv.org/pdf/2506.22884", "abs": "https://arxiv.org/abs/2506.22884", "authors": ["Praveen Kumar Donta", "Qiyang Zhang", "Schahram Dustdar"], "title": "Performance Measurements in the AI-Centric Computing Continuum Systems", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "Over the Eight decades, computing paradigms have shifted from large,\ncentralized systems to compact, distributed architectures, leading to the rise\nof the Distributed Computing Continuum (DCC). In this model, multiple layers\nsuch as cloud, edge, Internet of Things (IoT), and mobile platforms work\ntogether to support a wide range of applications. Recently, the emergence of\nGenerative AI and large language models has further intensified the demand for\ncomputational resources across this continuum. Although traditional performance\nmetrics have provided a solid foundation, they need to be revisited and\nexpanded to keep pace with changing computational demands and application\nrequirements. Accurate performance measurements benefit both system designers\nand users by supporting improvements in efficiency and promoting alignment with\nsystem goals. In this context, we review commonly used metrics in DCC and IoT\nenvironments. We also discuss emerging performance dimensions that address\nevolving computing needs, such as sustainability, energy efficiency, and system\nobservability. We also outline criteria and considerations for selecting\nappropriate metrics, aiming to inspire future research and development in this\ncritical area."}
{"id": "2506.23850", "pdf": "https://arxiv.org/pdf/2506.23850", "abs": "https://arxiv.org/abs/2506.23850", "authors": ["Andres Navarro", "Carlos de Quinto", "José Alberto Hernández"], "title": "Email as the Interface to Generative AI Models: Seamless Administrative Automation", "categories": ["cs.HC"], "comment": null, "summary": "This paper introduces a novel architectural framework that integrates Large\nLanguage Models (LLMs) with email interfaces to automate administrative tasks,\nspecifically targeting accessibility barriers in enterprise environments. The\nsystem connects email communication channels with Optical Character Recognition\n(OCR) and intelligent automation, enabling non-technical administrative staff\nto delegate complex form-filling and document processing tasks using familiar\nemail interfaces. By treating the email body as a natural language prompt and\nattachments as contextual information, the workflow bridges the gap between\nadvanced AI capabilities and practical usability. Empirical evaluation shows\nthat the system can complete complex administrative forms in under 8 seconds of\nautomated processing, with human supervision reducing total staff time by a\nfactor of three to four compared to manual workflows. The top-performing LLM\naccurately filled 16 out of 29 form fields and reduced the total cost per\nprocessed form by 64% relative to manual completion. These findings demonstrate\nthat email-based LLM integration is a viable and cost-effective approach for\ndemocratizing advanced automation in organizational settings, supporting\nwidespread adoption without requiring specialized technical knowledge or major\nworkflow changes. This aligns with broader trends in leveraging LLMs to enhance\naccessibility and automate complex tasks for non-technical users, making\ntechnology more inclusive and efficient."}
{"id": "2506.23960", "pdf": "https://arxiv.org/pdf/2506.23960", "abs": "https://arxiv.org/abs/2506.23960", "authors": ["Mingfei Cheng", "Xiaofei Xie", "Renzhi Wang", "Yuan Zhou", "Ming Hu"], "title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Autonomous Driving Systems (ADSs) continue to face safety-critical risks due\nto the inherent limitations in their design and performance capabilities.\nOnline repair plays a crucial role in mitigating such limitations, ensuring the\nruntime safety and reliability of ADSs. Existing online repair solutions\nenforce ADS compliance by transforming unacceptable trajectories into\nacceptable ones based on predefined specifications, such as rule-based\nconstraints or training datasets. However, these approaches often lack\ngeneralizability, adaptability and tend to be overly conservative, resulting in\nineffective repairs that not only fail to mitigate safety risks sufficiently\nbut also degrade the overall driving experience. To address this issue, we\npropose Adaptive Decision Repair (ADReFT), a novel and effective repair method\nthat identifies safety-critical states through offline learning from failed\ntests and generates appropriate mitigation actions to improve ADS safety.\nSpecifically, ADReFT incorporates a transformer-based model with two joint\nheads, State Monitor and Decision Adapter, designed to capture complex driving\nenvironment interactions to evaluate state safety severity and generate\nadaptive repair actions. Given the absence of oracles for state safety\nidentification, we first pretrain ADReFT using supervised learning with coarse\nannotations, i.e., labeling states preceding violations as positive samples and\nothers as negative samples. It establishes ADReFT's foundational capability to\nmitigate safety-critical violations, though it may result in somewhat\nconservative mitigation strategies. Therefore, we subsequently finetune ADReFT\nusing reinforcement learning to improve its initial capability and generate\nmore precise and contextually appropriate repair decisions. Our evaluation\nresults illustrate that ADReFT achieves better repair performance."}
{"id": "2506.23435", "pdf": "https://arxiv.org/pdf/2506.23435", "abs": "https://arxiv.org/abs/2506.23435", "authors": ["Hayder Tirmazi"], "title": "All Proof of Work But No Proof of Play", "categories": ["cs.CR", "cs.NI"], "comment": "Published in CFAIL 2025", "summary": "Speedrunning is a competition that emerged from communities of early video\ngames such as Doom (1993). Speedrunners try to finish a game in minimal time.\nProvably verifying the authenticity of submitted speedruns is an open problem.\nTraditionally, best-effort speedrun verification is conducted by on-site human\nobservers, forensic audio analysis, or a rigorous mathematical analysis of the\ngame mechanics. Such methods are tedious, fallible, and, perhaps worst of all,\nnot cryptographic. Motivated by naivety and the Dunning-Kruger effect, we\nattempt to build a system that cryptographically proves the authenticity of\nspeedruns. This paper describes our attempted solutions and ways to circumvent\nthem. Through a narration of our failures, we attempt to demonstrate the\ndifficulty of authenticating live and interactive human input in untrusted\nenvironments, as well as the limits of signature schemes, game integrity, and\nprovable play."}
{"id": "2506.23952", "pdf": "https://arxiv.org/pdf/2506.23952", "abs": "https://arxiv.org/abs/2506.23952", "authors": ["Stefan Buijsman", "Sarah Carter", "Juan Pablo Bermúdez"], "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "categories": ["cs.HC", "cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "AI systems increasingly support human decision-making across domains of\nprofessional, skill-based, and personal activity. While previous work has\nexamined how AI might affect human autonomy globally, the effects of AI on\ndomain-specific autonomy -- the capacity for self-governed action within\ndefined realms of skill or expertise -- remain understudied. We analyze how AI\ndecision-support systems affect two key components of domain-specific autonomy:\nskilled competence (the ability to make informed judgments within one's domain)\nand authentic value-formation (the capacity to form genuine domain-relevant\nvalues and preferences). By engaging with prior investigations and analyzing\nempirical cases across medical, financial, and educational domains, we\ndemonstrate how the absence of reliable failure indicators and the potential\nfor unconscious value shifts can erode domain-specific autonomy both\nimmediately and over time. We then develop a constructive framework for\nautonomy-preserving AI support systems. We propose specific socio-technical\ndesign patterns -- including careful role specification, implementation of\ndefeater mechanisms, and support for reflective practice -- that can help\nmaintain domain-specific autonomy while leveraging AI capabilities. This\nframework provides concrete guidance for developing AI systems that enhance\nrather than diminish human agency within specialized domains of action."}
{"id": "2506.23788", "pdf": "https://arxiv.org/pdf/2506.23788", "abs": "https://arxiv.org/abs/2506.23788", "authors": ["Naomi Stricker", "David Blaser", "Andres Gomez", "Lothar Thiele"], "title": "E-WAN: Efficient Communication in Energy Harvesting Low-Power Networks", "categories": ["eess.SP", "cs.NI"], "comment": "This is the author's version of the work. Submitted to ACM TOSN on\n  June 2023. Major revision submitted on May 2024. Minor Revision submitted on\n  March 2025", "summary": "The ever-increasing number of distributed embedded systems in the context of\nthe Internet of Things (IoT), Wireless Sensor Networks (WSN), and\nCyber-Physical Systems (CPS) rely on wireless communication to collect and\nexchange data. Nodes can employ single-hop communication which, despite its\nease, may necessitate energy-intensive long-range communication to cover long\ndistances. Conversely, multi-hop communication allows for more energy-efficient\nshort-range communication since nodes can rely on other nodes to forward their\ndata. Yet, this approach requires relay nodes to be available and continuous\nmaintenance of a dynamically changing distributed state. At the same time,\nenergy harvesting has the potential to outperform traditional battery-based\nsystems by improving their lifetime, scalability with lower maintenance costs,\nand environmental impact. However, the limited and temporally and spatially\nvariable harvested energy poses significant challenges for networking in energy\nharvesting networks, particularly considering the energy demands and\ncharacteristics of both multi-hop and single-hop communication. We propose\nE-WAN, a protocol for energy harvesting wide-area low-power networks that\nbuilds on the concept of \\emph{virtual sub-networks} to enable\nresource-efficient multi-hop communication when possible and reliable however\nenergy-intensive point-to-point communication otherwise. Nodes autonomously and\ndynamically move between the two and adjust to changing network states and\nresources based only on easily obtainable network state information. We\nillustrate E-WAN's advantages both in terms of efficiency and adaptability in\nvarious communication and harvesting scenarios. Furthermore, we demonstrate\nE-WAN operating in a realistic setting by deploying an energy harvesting\nnetwork in a real-world indoor environment."}
{"id": "2506.24057", "pdf": "https://arxiv.org/pdf/2506.24057", "abs": "https://arxiv.org/abs/2506.24057", "authors": ["Patricia Piedade", "Peter A Hayton", "Cynthia Bennett", "Anna R L Carter", "Clara Crivellaro", "Alan Dix", "Jess McGowan", "Katta Spiel", "Miriam Sturdee", "Garreth W. Tigwell", "Hugo Nicolau"], "title": "Access InContext: Futuring Accessible Prototyping Tools and Methods", "categories": ["cs.HC"], "comment": null, "summary": "The popularity of accessibility research has grown recently, improving\ndigital inclusion for people with disabilities. However, researchers, including\nthose who have disabilities, have attempted to include people with disabilities\nin all aspects of design, and they have identified a myriad of practical\naccessibility barriers posed by tools and methods leveraged by human-computer\ninteraction (HCI) researchers during prototyping. To build a more inclusive\ntechnological landscape, we must question the effectiveness of existing\nprototyping tools and methods, repurpose/retrofit existing resources, and build\nnew tools and methods to support the participation of both researchers and\npeople with disabilities within the prototyping design process of novel\ntechnologies. This full-day workshop at CHI 2025 will provide a platform for\nHCI researchers, designers, and practitioners to discuss barriers and\nopportunities for creating accessible prototyping and promote hands-on ideation\nand fabrication exercises aimed at futuring accessible prototyping."}
{"id": "2506.24104", "pdf": "https://arxiv.org/pdf/2506.24104", "abs": "https://arxiv.org/abs/2506.24104", "authors": ["Mariia Ershova", "Graziano Blasilli"], "title": "Bridging Service Design, Visualizations, and Visual Analytics in Healthcare Digital Twins: Challenges, Gaps, and Research Opportunities", "categories": ["cs.HC"], "comment": "Submitted to: Workshop on Visual Analytics in Healthcare (VAHC 2025)", "summary": "Digital twins (DT) are increasingly used in healthcare to model patients,\nprocesses, and physiological systems. While recent solutions leverage\nvisualization, visual analytics, and user interaction, these systems rarely\nincorporate structured service design methodologies. Bridging service design\nwith visual analytics and visualization can be valuable for the healthcare DT\ncommunity. This paper aims to introduce the service design discipline to\nvisualization researchers by framing this integration gap and suggesting\nresearch directions to enhance the real-world applicability of DT solutions."}
{"id": "2506.22443", "pdf": "https://arxiv.org/pdf/2506.22443", "abs": "https://arxiv.org/abs/2506.22443", "authors": ["Sarah Seifi", "Tobias Sukianto", "Cecilia Carbonelli", "Lorenzo Servadei", "Robert Wille"], "title": "Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition", "categories": ["cs.LG", "cs.HC"], "comment": "8 pages, 3 figures, accepted at the late-breaking work track at the\n  XAI-2025 third World Conference of Explainable AI", "summary": "Rule-based models offer interpretability but struggle with complex data,\nwhile deep neural networks excel in performance yet lack transparency. This\nwork investigates a neuro-symbolic rule learning neural network named RL-Net\nthat learns interpretable rule lists through neural optimization, applied for\nthe first time to radar-based hand gesture recognition (HGR). We benchmark\nRL-Net against a fully transparent rule-based system (MIRA) and an explainable\nblack-box model (XentricAI), evaluating accuracy, interpretability, and user\nadaptability via transfer learning. Our results show that RL-Net achieves a\nfavorable trade-off, maintaining strong performance (93.03% F1) while\nsignificantly reducing rule complexity. We identify optimization challenges\nspecific to rule pruning and hierarchy bias and propose stability-enhancing\nmodifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical\nmiddle ground between transparency and performance. This study highlights the\nreal-world feasibility of neuro-symbolic models for interpretable HGR and\noffers insights for extending explainable AI to edge-deployable sensing\nsystems."}
{"id": "2506.22462", "pdf": "https://arxiv.org/pdf/2506.22462", "abs": "https://arxiv.org/abs/2506.22462", "authors": ["Abdallah Lakhdari", "Jiajie Li", "Amani Abusafia", "Athman Bouguettaya"], "title": "Privacy-aware IoT Fall Detection Services For Aging in Place", "categories": ["eess.SP", "cs.AI", "cs.CY", "cs.HC"], "comment": "11 pages, 12 figures, This paper is accepted in the 2025 IEEE\n  International Conference on Web Services (ICWS 2025)", "summary": "Fall detection is critical to support the growing elderly population,\nprojected to reach 2.1 billion by 2050. However, existing methods often face\ndata scarcity challenges or compromise privacy. We propose a novel IoT-based\nFall Detection as a Service (FDaaS) framework to assist the elderly in living\nindependently and safely by accurately detecting falls. We design a\nservice-oriented architecture that leverages Ultra-wideband (UWB) radar sensors\nas an IoT health-sensing service, ensuring privacy and minimal intrusion. We\naddress the challenges of data scarcity by utilizing a Fall Detection\nGenerative Pre-trained Transformer (FD-GPT) that uses augmentation techniques.\nWe developed a protocol to collect a comprehensive dataset of the elderly daily\nactivities and fall events. This resulted in a real dataset that carefully\nmimics the elderly's routine. We rigorously evaluate and compare various models\nusing this dataset. Experimental results show our approach achieves 90.72%\naccuracy and 89.33% precision in distinguishing between fall events and regular\nactivities of daily living."}
{"id": "2506.22464", "pdf": "https://arxiv.org/pdf/2506.22464", "abs": "https://arxiv.org/abs/2506.22464", "authors": ["Hitesh Mohapatra"], "title": "Golden Ratio Assisted Localization for Wireless Sensor Network", "categories": ["cs.NI", "cs.HC", "B.4"], "comment": "6", "summary": "This paper presents a novel localization algorithm for wireless sensor\nnetworks (WSNs) called Golden Ratio Localization (GRL), which leverages the\nmathematical properties of the golden ratio (phi 1.618) to optimize both node\nplacement and communication range. GRL introduces phi-based anchor node\ndeployment and hop-sensitive weighting using phi-exponents to improve\nlocalization accuracy while minimizing energy consumption. Through extensive\nsimulations conducted on a 100 m * 100 m sensor field with 100 nodes and 10\nanchors, GRL achieved an average localization error of 2.35 meters,\noutperforming DV- Hop (3.87 meters) and Centroid (4.95 meters). In terms of\nenergy efficiency, GRL reduced localization energy consumption to 1.12 microJ\nper node, compared to 1.78 microJ for DV-Hop and 1.45 microJ for Centroid.\nThese results confirm that GRL provides a more balanced and efficient\nlocalization approach, making it especially suitable for energy-constrained and\nlarge-scale WSN deployments."}
{"id": "2506.22476", "pdf": "https://arxiv.org/pdf/2506.22476", "abs": "https://arxiv.org/abs/2506.22476", "authors": ["A. Subedi", "S. De", "L. Cavuoto", "S. Schwaitzberg", "M. Hackett", "J. Norfleet"], "title": "An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals", "categories": ["eess.SP", "cs.ET", "cs.HC", "cs.LG", "q-bio.NC", "I.2.6; J.3; H.1.2"], "comment": null, "summary": "Objective skill assessment in high-stakes procedural environments requires\nmodels that not only decode underlying cognitive and motor processes but also\ngeneralize across tasks, individuals, and experimental contexts. While prior\nwork has demonstrated the potential of functional near-infrared spectroscopy\n(fNIRS) for evaluating cognitive-motor performance, existing approaches are\noften task-specific, rely on extensive preprocessing, and lack robustness to\nnew procedures or conditions. Here, we introduce an interpretable\ntransformer-based foundation model trained on minimally processed fNIRS signals\nfor cross-procedural skill assessment. Pretrained using self-supervised\nlearning on data from laparoscopic surgical tasks and endotracheal intubation\n(ETI), the model achieves greater than 88% classification accuracy on all\ntasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It\ngeneralizes to a novel emergency airway procedure--cricothyrotomy--using fewer\nthan 30 labeled samples and a lightweight (less than 2k parameter) adapter\nmodule, attaining an AUC greater than 87%. Interpretability is achieved via a\nnovel channel attention mechanism--developed specifically for fNIRS--that\nidentifies functionally coherent prefrontal sub-networks validated through\nablation studies. Temporal attention patterns align with task-critical phases\nand capture stress-induced changes in neural variability, offering insight into\ndynamic cognitive states."}
{"id": "2506.22604", "pdf": "https://arxiv.org/pdf/2506.22604", "abs": "https://arxiv.org/abs/2506.22604", "authors": ["David Porfirio", "Vincent Hsiao", "Morgan Fine-Morris", "Leslie Smith", "Laura M. Hiatt"], "title": "Bootstrapping Human-Like Planning via LLMs", "categories": ["cs.AI", "cs.HC", "cs.RO"], "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "Robot end users increasingly require accessible means of specifying tasks for\nrobots to perform. Two common end-user programming paradigms include\ndrag-and-drop interfaces and natural language programming. Although natural\nlanguage interfaces harness an intuitive form of human communication,\ndrag-and-drop interfaces enable users to meticulously and precisely dictate the\nkey actions of the robot's task. In this paper, we investigate the degree to\nwhich both approaches can be combined. Specifically, we construct a large\nlanguage model (LLM)-based pipeline that accepts natural language as input and\nproduces human-like action sequences as output, specified at a level of\ngranularity that a human would produce. We then compare these generated action\nsequences to another dataset of hand-specified action sequences. Although our\nresults reveal that larger models tend to outperform smaller ones in the\nproduction of human-like action sequences, smaller models nonetheless achieve\nsatisfactory performance."}
{"id": "2506.22803", "pdf": "https://arxiv.org/pdf/2506.22803", "abs": "https://arxiv.org/abs/2506.22803", "authors": ["Nuoye Xiong", "Anqi Dong", "Ning Wang", "Cong Hua", "Guangming Zhu", "Mei Lin", "Peiyi Shen", "Liang Zhang"], "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Recent advances in deep learning have led to increasingly complex models with\ndeeper layers and more parameters, reducing interpretability and making their\ndecisions harder to understand. While many methods explain black-box reasoning,\nmost lack effective interventions or only operate at sample-level without\nmodifying the model itself. To address this, we propose the Concept Bottleneck\nModel for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).\nCBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable\nframework to approximate black-box reasoning and communicate conceptual\nunderstanding. Detrimental concepts are automatically identified and refined\n(removed/replaced) based on global gradient contributions. The modified CBM\nthen distills corrected knowledge back into the black-box model, enhancing both\ninterpretability and accuracy. We evaluate CBM-HNMU on various CNN and\ntransformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,\nand CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum\nincrease in average accuracy across 1.03%. Source code is available at:\nhttps://github.com/XiGuaBo/CBM-HNMU."}
{"id": "2506.22893", "pdf": "https://arxiv.org/pdf/2506.22893", "abs": "https://arxiv.org/abs/2506.22893", "authors": ["Arpit Narechania", "Alex Endert", "Atanu R Sinha"], "title": "Agentic Enterprise: AI-Centric User to User-Centric AI", "categories": ["cs.AI", "cs.HC"], "comment": "12 pages, 1 figure, 2 sidebars; Preprint", "summary": "After a very long winter, the Artificial Intelligence (AI) spring is here.\nOr, so it seems over the last three years. AI has the potential to impact many\nareas of human life - personal, social, health, education, professional. In\nthis paper, we take a closer look at the potential of AI for Enterprises, where\ndecision-making plays a crucial and repeated role across functions, tasks, and\noperations. We consider Agents imbued with AI as means to increase\ndecision-productivity of enterprises. We highlight six tenets for Agentic\nsuccess in enterprises, by drawing attention to what the current, AI-Centric\nUser paradigm misses, in the face of persistent needs of and usefulness for\nEnterprise Decision-Making. In underscoring a shift to User-Centric AI, we\noffer six tenets and promote market mechanisms for platforms, aligning the\ndesign of AI and its delivery by Agents to the cause of enterprise users."}
{"id": "2506.23092", "pdf": "https://arxiv.org/pdf/2506.23092", "abs": "https://arxiv.org/abs/2506.23092", "authors": ["Arisa Cowe", "Tyson Neuroth", "Qi Wu", "Martin Rieth", "Jacqueline Chen", "Myoungkyu Lee", "Kwan-Liu Ma"], "title": "Glyph-Based Multiscale Visualization of Turbulent Multi-Physics Statistics", "categories": ["cs.GR", "cs.HC"], "comment": "15 pages (13 pages without references)", "summary": "Many scientific and engineering problems involving multi-physics span a wide\nrange of scales. Understanding the interactions across these scales is\nessential for fully comprehending such complex problems. However, visualizing\nmultivariate, multiscale data within an integrated view where correlations\nacross space, scales, and fields are easily perceived remains challenging. To\naddress this, we introduce a novel local spatial statistical visualization of\nflow fields across multiple fields and turbulence scales. Our method leverages\nthe curvelet transform for scale decomposition of fields of interest, a\nlevel-set-restricted centroidal Voronoi tessellation to partition the spatial\ndomain into local regions for statistical aggregation, and a set of glyph\ndesigns that combines information across scales and fields into a single, or\nreduced set of perceivable visual representations. Each glyph represents data\naggregated within a Voronoi region and is positioned at the Voronoi site for\ndirect visualization in a 3D view centered around flow features of interest. We\nimplement and integrate our method into an interactive visualization system\nwhere the glyph-based technique operates in tandem with linked 3D spatial views\nand 2D statistical views, supporting a holistic analysis. We demonstrate with\ncase studies visualizing turbulent combustion data--multi-scalar compressible\nflows--and turbulent incompressible channel flow data. This new capability\nenables scientists to better understand the interactions between multiple\nfields and length scales in turbulent flows."}
{"id": "2506.23549", "pdf": "https://arxiv.org/pdf/2506.23549", "abs": "https://arxiv.org/abs/2506.23549", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": "23 pages, 10 tables, 8 figures", "summary": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios."}
{"id": "2506.23682", "pdf": "https://arxiv.org/pdf/2506.23682", "abs": "https://arxiv.org/abs/2506.23682", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Not quite a piece of CHERI-cake: Are new digital security by design architectures usable?", "categories": ["cs.CR", "cs.AR", "cs.HC"], "comment": null, "summary": "A digital security-by-design computer architecture, like CHERI, lets you\nprogram without fear of buffer overflows or other memory safety errors, but\nCHERI also rewrites some of the assumptions about how C works and how\nfundamental types (such as pointers) are implemented in hardware. We conducted\na usability study to examine how developers react to the changes required by\nCHERI when porting software to run on it. We find that developers struggle with\nCHERI's display of warnings and errors and a lack of diverse documentation."}
{"id": "2506.23721", "pdf": "https://arxiv.org/pdf/2506.23721", "abs": "https://arxiv.org/abs/2506.23721", "authors": ["Gijs Luijten", "Roberto Maria Scardigno", "Lisle Faray de Paiva", "Peter Hoyer", "Jens Kleesiek", "Domenico Buongiorno", "Vitoantonio Bevilacqua", "Jan Egger"], "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "Ultrasound (US) is widely accessible and radiation-free but has a steep\nlearning curve due to its dynamic nature and non-standard imaging planes.\nAdditionally, the constant need to shift focus between the US screen and the\npatient poses a challenge. To address these issues, we integrate deep learning\n(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric\nmeasurements, which are essential for clinical assessment but are traditionally\ntime-consuming and prone to fatigue. This automation allows clinicians to\nconcentrate on image interpretation rather than manual measurements.\nComplementing DL, augmented reality (AR) enhances the usability of US by\nprojecting the display directly into the clinician's field of view, improving\nergonomics and reducing the cognitive load associated with screen-to-patient\ntransitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one\nstreams directly via the application programming interface for a wireless\nsetup, while the other supports any US device with video output for broader\naccessibility. We evaluate RT feasibility and accuracy using the Open Kidney\nDataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with\nMedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model\nimplementations, measurement algorithms, and a Wi-Fi-based streaming solution,\nenhancing US training and diagnostics, especially in point-of-care settings."}
{"id": "2506.23739", "pdf": "https://arxiv.org/pdf/2506.23739", "abs": "https://arxiv.org/abs/2506.23739", "authors": ["Lisa Marie Otto", "Michael Kaiser", "Daniel Seebacher", "Steffen Müller"], "title": "Validation of AI-Based 3D Human Pose Estimation in a Cyber-Physical Environment", "categories": ["cs.RO", "cs.CE", "cs.HC"], "comment": "6 pages, 5 figures, Preprint for 2025 IEEE IAVVC (International\n  Automated Vehicle Validation Conference)", "summary": "Ensuring safe and realistic interactions between automated driving systems\nand vulnerable road users (VRUs) in urban environments requires advanced\ntesting methodologies. This paper presents a test environment that combines a\nVehiclein-the-Loop (ViL) test bench with a motion laboratory, demonstrating the\nfeasibility of cyber-physical (CP) testing of vehicle-pedestrian and\nvehicle-cyclist interactions. Building upon previous work focused on pedestrian\nlocalization, we further validate a human pose estimation (HPE) approach\nthrough a comparative analysis of real-world (RW) and virtual representations\nof VRUs. The study examines the perception of full-body motion using a\ncommercial monocular camera-based 3Dskeletal detection AI. The virtual scene is\ngenerated in Unreal Engine 5, where VRUs are animated in real time and\nprojected onto a screen to stimulate the camera. The proposed stimulation\ntechnique ensures the correct perspective, enabling realistic vehicle\nperception. To assess the accuracy and consistency of HPE across RW and CP\ndomains, we analyze the reliability of detections as well as variations in\nmovement trajectories and joint estimation stability. The validation includes\ndynamic test scenarios where human avatars, both walking and cycling, are\nmonitored under controlled conditions. Our results show a strong alignment in\nHPE between RW and CP test conditions for stable motion patterns, while notable\ninaccuracies persist under dynamic movements and occlusions, particularly for\ncomplex cyclist postures. These findings contribute to refining CP testing\napproaches for evaluating next-generation AI-based vehicle perception and to\nenhancing interaction models of automated vehicles and VRUs in CP environments."}
{"id": "2506.23774", "pdf": "https://arxiv.org/pdf/2506.23774", "abs": "https://arxiv.org/abs/2506.23774", "authors": ["Ewelina Gajewska", "Michal Wawer", "Katarzyna Budzynska", "Jarosław A. Chudziak"], "title": "Leveraging a Multi-Agent LLM-Based System to Educate Teachers in Hate Incidents Management", "categories": ["cs.CY", "cs.HC", "H.1.2"], "comment": "8 pages, 1 figure", "summary": "Computer-aided teacher training is a state-of-the-art method designed to\nenhance teachers' professional skills effectively while minimising concerns\nrelated to costs, time constraints, and geographical limitations. We\ninvestigate the potential of large language models (LLMs) in teacher education,\nusing a case of teaching hate incidents management in schools. To this end, we\ncreate a multi-agent LLM-based system that mimics realistic situations of hate,\nusing a combination of retrieval-augmented prompting and persona modelling. It\nis designed to identify and analyse hate speech patterns, predict potential\nescalation, and propose effective intervention strategies. By integrating\npersona modelling with agentic LLMs, we create contextually diverse simulations\nof hate incidents, mimicking real-life situations. The system allows teachers\nto analyse and understand the dynamics of hate incidents in a safe and\ncontrolled environment, providing valuable insights and practical knowledge to\nmanage such situations confidently in real life. Our pilot evaluation\ndemonstrates teachers' enhanced understanding of the nature of annotator\ndisagreements and the role of context in hate speech interpretation, leading to\nthe development of more informed and effective strategies for addressing hate\nin classroom settings."}
{"id": "2506.23826", "pdf": "https://arxiv.org/pdf/2506.23826", "abs": "https://arxiv.org/abs/2506.23826", "authors": ["Lluís C. Coll", "Martin W. Lauer-Schmaltz", "Philip Cash", "John P. Hansen", "Anja Maier"], "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins", "categories": ["cs.ET", "cs.AI", "cs.CY", "cs.HC", "cs.IR"], "comment": "24 pages, 9 figures", "summary": "Human Digital Twins (HDTs) have traditionally been conceptualized as\ndata-driven models designed to support decision-making across various domains.\nHowever, recent advancements in conversational AI open new possibilities for\nHDTs to function as authentic, interactive digital counterparts of individuals.\nThis paper introduces a novel HDT system architecture that integrates large\nlanguage models with dynamically updated personal data, enabling it to mirror\nan individual's conversational style, memories, and behaviors. To achieve this,\nour approach implements context-aware memory retrieval, neural\nplasticity-inspired consolidation, and adaptive learning mechanisms, creating a\nmore natural and evolving digital persona. The resulting system does not only\nreplicate an individual's unique conversational style depending on who they are\nspeaking with, but also enriches responses with dynamically captured personal\nexperiences, opinions, and memories. While this marks a significant step toward\ndeveloping authentic virtual counterparts, it also raises critical ethical\nconcerns regarding privacy, accountability, and the long-term implications of\npersistent digital identities. This study contributes to the field of HDTs by\ndescribing our novel system architecture, demonstrating its capabilities, and\ndiscussing future directions and emerging challenges to ensure the responsible\nand ethical development of HDTs."}
{"id": "2506.23851", "pdf": "https://arxiv.org/pdf/2506.23851", "abs": "https://arxiv.org/abs/2506.23851", "authors": ["Israel Fianyi", "Soonja Yeom", "Ju-Hyun Shin"], "title": "Comparative Studies: Cloud-Enabled Adaptive Learning System for Scalable Education in Sub-Saharan", "categories": ["cs.CY", "cs.ET", "cs.HC"], "comment": null, "summary": "The integration of cloud computing in education can revolutionise learning in\nadvanced (Australia & South Korea) and middle-income (Ghana & Nigeria)\ncountries, while offering scalable, cost-effective and equitable access to\nadaptive learning systems. This paper explores how cloud computing and adaptive\nlearning technologies are deployed across different socio-economic and\ninfrastructure contexts. The study identifies enabling factors and systematic\nchallenges, providing insights into how cloud-based education can be tailored\nto bridge the digital and educational divide globally."}
{"id": "2506.24039", "pdf": "https://arxiv.org/pdf/2506.24039", "abs": "https://arxiv.org/abs/2506.24039", "authors": ["Shubhabrata Mukherjee", "Jack Lang", "Obeen Kwon", "Iryna Zenyuk", "Valerie Brogden", "Adam Weber", "Daniela Ushizima"], "title": "Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data", "categories": ["cs.CV", "cs.HC"], "comment": "This manuscript is a draft on arxiv. A final version has been\n  submitted to the 59th ICPP 2025, DRAI workshop", "summary": "Zero-shot and prompt-based technologies capitalized on using frequently\noccurring images to transform visual reasoning tasks, which explains why such\ntechnologies struggle with valuable yet scarce scientific image sets. In this\nwork, we propose Zenesis, a comprehensive no-code interactive platform designed\nto minimize barriers posed by data readiness for scientific images. We develop\nlightweight multi-modal adaptation techniques that enable zero-shot operation\non raw scientific data, along with human-in-the-loop refinement and\nheuristic-based temporal enhancement options. We demonstrate the performance of\nour approach through comprehensive comparison and validation on challenging\nFocused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded\nmembranes. Zenesis significantly outperforms baseline methods, achieving an\naverage accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a\nDice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an\nIOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results\nmark a substantial improvement over traditional methods like Otsu thresholding\nand even advanced models like Segment Anything Model (SAM) when used in\nisolation. Our results demonstrate that Zenesis is a powerful tool for\nscientific applications, particularly in fields where high-quality annotated\ndatasets are unavailable, accelerating accurate analysis of experimental\nimaging."}
{"id": "2506.24046", "pdf": "https://arxiv.org/pdf/2506.24046", "abs": "https://arxiv.org/abs/2506.24046", "authors": ["Olivia Richards", "Keith L. Obstein", "Nabil Simaan"], "title": "Exploring Accelerated Skill Acquisition via Tandem Training for Colonoscopy", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "New endoscopists require a large volume of expert-proctored colonoscopies to\nattain minimal competency. Developing multi-fingered, synchronized control of a\ncolonoscope requires significant time and exposure to the device. Current\ntraining methods inhibit this development by relying on tool hand-off for\nexpert demonstrations. There is a need for colonoscopy training tools that\nenable in-hand expert guidance in real-time. We present a new concept of a\ntandem training system that uses a telemanipulated preceptor colonoscope to\nguide novice users as they perform a colonoscopy. This system is capable of\ndual-control and can automatically toggle between expert and novice control of\na standard colonoscope's angulation control wheels. Preliminary results from a\nuser study with novice and expert users show the effectiveness of this device\nas a skill acquisition tool. We believe that this device has the potential to\naccelerate skill acquisition for colonoscopy and, in the future, enable\nindividualized instruction and responsive teaching through bidirectional\nactuation."}
