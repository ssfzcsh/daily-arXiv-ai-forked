{"id": "2507.10583", "pdf": "https://arxiv.org/pdf/2507.10583", "abs": "https://arxiv.org/abs/2507.10583", "authors": ["Daniil Orel", "Indraneil Paul", "Iryna Gurevych", "Preslav Nakov"], "title": "$\\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection", "categories": ["cs.SE", "cs.AI", "cs.CY"], "comment": null, "summary": "In this work, we compile $\\textbf{$\\texttt{DroidCollection}$}$, the most\nextensive open data suite for training and evaluating machine-generated code\ndetectors, comprising over a million code samples, seven programming languages,\noutputs from 43 coding models, and over three real-world coding domains.\nAlongside fully AI-generated samples, our collection includes human-AI\nco-authored code, as well as adversarial samples explicitly crafted to evade\ndetection. Subsequently, we develop $\\textbf{$\\texttt{DroidDetect}$}$, a suite\nof encoder-only detectors trained using a multi-task objective over\n$\\texttt{DroidCollection}$. Our experiments show that existing detectors'\nperformance fails to generalise to diverse coding domains and programming\nlanguages outside of their narrow training data. Additionally, we demonstrate\nthat while most detectors are easily compromised by humanising the output\ndistributions using superficial prompting and alignment approaches, this\nproblem can be easily amended by training on a small amount of adversarial\ndata. Finally, we demonstrate the effectiveness of metric learning and\nuncertainty-based resampling as means to enhance detector training on possibly\nnoisy distributions."}
{"id": "2507.10584", "pdf": "https://arxiv.org/pdf/2507.10584", "abs": "https://arxiv.org/abs/2507.10584", "authors": ["Francesco Romeo", "Luigi Arena", "Francesco Blefari", "Francesco Aurelio Pironti", "Matteo Lupinacci", "Angelo Furfaro"], "title": "ARPaCCino: An Agentic-RAG for Policy as Code Compliance", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Policy as Code (PaC) is a paradigm that encodes security and compliance\npolicies into machine-readable formats, enabling automated enforcement in\nInfrastructure as Code (IaC) environments. However, its adoption is hindered by\nthe complexity of policy languages and the risk of misconfigurations. In this\nwork, we present ARPaCCino, an agentic system that combines Large Language\nModels (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation\nto automate the generation and verification of PaC rules. Given natural\nlanguage descriptions of the desired policies, ARPaCCino generates formal Rego\nrules, assesses IaC compliance, and iteratively refines the IaC configurations\nto ensure conformance. Thanks to its modular agentic architecture and\nintegration with external tools and knowledge bases, ARPaCCino supports policy\nvalidation across a wide range of technologies, including niche or emerging IaC\nframeworks. Experimental evaluation involving a Terraform-based case study\ndemonstrates ARPaCCino's effectiveness in generating syntactically and\nsemantically correct policies, identifying non-compliant infrastructures, and\napplying corrective modifications, even when using smaller, open-weight LLMs.\nOur results highlight the potential of agentic RAG architectures to enhance the\nautomation, reliability, and accessibility of PaC workflows."}
{"id": "2507.10590", "pdf": "https://arxiv.org/pdf/2507.10590", "abs": "https://arxiv.org/abs/2507.10590", "authors": ["Mojtaba Eshghie"], "title": "Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime", "categories": ["cs.SE", "cs.AI", "cs.IR"], "comment": null, "summary": "Language Model (LM) pipelines can dynamically refine their outputs against\nprogrammatic constraints. However, their effectiveness collapses when faced\nwith competing soft constraints, leading to inefficient backtracking loops\nwhere satisfying one constraint violates another. We introduce Meta\nSelf-Refining, a framework that equips LM pipelines with a meta-corrective\nlayer to repair these competitions at runtime/inference-time. Our approach\nmonitors the pipeline's execution history to detect oscillatory failures. Upon\ndetection, it invokes a meta-repairer LM that analyzes the holistic state of\nthe backtracking attempts and synthesizes a strategic instruction to balance\nthe competing requirements. This self-repair instruction guides the original LM\nout of a failing refining loop towards a successful output. Our results show\nMeta Self-Refining can successfully repair these loops, leading to more\nefficient LM programs."}
{"id": "2507.10593", "pdf": "https://arxiv.org/pdf/2507.10593", "abs": "https://arxiv.org/abs/2507.10593", "authors": ["Peng Ding"], "title": "ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) applications are increasingly relying on external\ntools to extend their capabilities beyond text generation. However, current\ntool integration approaches suffer from fragmentation, protocol limitations,\nand implementation complexity, leading to substantial development overhead.\nThis paper presents Toolregistry, a protocol-agnostic tool management library\nthat simplifies tool registration, representation, execution, and lifecycle\nmanagement via a unified interface. Our evaluation demonstrates that\n\\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x\nperformance improvements through concurrent execution, and 100% compatibility\nwith OpenAI function calling standards. Real-world case studies show\nsignificant improvements in development efficiency and code maintainability\nacross diverse integration scenarios. \\toolregistry is open-source and\navailable at https://github.com/Oaklight/ToolRegistry, with comprehensive\ndocumentation at https://toolregistry.readthedocs.io/."}
{"id": "2507.10799", "pdf": "https://arxiv.org/pdf/2507.10799", "abs": "https://arxiv.org/abs/2507.10799", "authors": ["Tyler Hou", "Michael Arntzenius", "Max Willsey"], "title": "Stream programs are monoid homomorphisms with state", "categories": ["cs.PL", "cs.DC"], "comment": null, "summary": "We define a broad class of deterministic stream functions and show they can\nbe implemented as homomorphisms into a \"state\" monoid. The homomorphism laws\nare simpler than the conditions of previous semantic frameworks for stream\nprogram optimization, yet retain support for rich equational reasoning over\nexpressive dataflow programs, including sequential composition, parallel\ncomposition, and feedback. We demonstrate this using examples of partitioned\ndatabase joins, stratified negation, and a simplified model of TCP."}
{"id": "2507.10859", "pdf": "https://arxiv.org/pdf/2507.10859", "abs": "https://arxiv.org/abs/2507.10859", "authors": ["Ramaneswaran Selvakumar", "Ashish Seth", "Nishit Anand", "Utkarsh Tyagi", "Sonal Kumar", "Sreyan Ghosh", "Dinesh Manocha"], "title": "MultiVox: Benchmarking Voice Assistants for Multimodal Interactions", "categories": ["cs.MM", "cs.CL", "cs.HC"], "comment": "Work In Progress", "summary": "The rapid progress of Large Language Models (LLMs) has empowered omni models\nto act as voice assistants capable of understanding spoken dialogues. These\nmodels can process multimodal inputs beyond text, such as speech and visual\ndata, enabling more context-aware interactions. However, current benchmarks\nfall short in comprehensively evaluating how well these models generate\ncontext-aware responses, particularly when it comes to implicitly understanding\nfine-grained speech characteristics, such as pitch, emotion, timbre, and volume\nor the environmental acoustic context such as background sounds. Additionally,\nthey inadequately assess the ability of models to align paralinguistic cues\nwith complementary visual signals to inform their responses. To address these\ngaps, we introduce MultiVox, the first omni voice assistant benchmark designed\nto evaluate the ability of voice assistants to integrate spoken and visual cues\nincluding paralinguistic speech features for truly multimodal understanding.\nSpecifically, MultiVox includes 1000 human-annotated and recorded speech\ndialogues that encompass diverse paralinguistic features and a range of visual\ncues such as images and videos. Our evaluation on 9 state-of-the-art models\nreveals that, although humans excel at these tasks, current models consistently\nstruggle to produce contextually grounded responses."}
{"id": "2507.10883", "pdf": "https://arxiv.org/pdf/2507.10883", "abs": "https://arxiv.org/abs/2507.10883", "authors": ["Juhee Bae", "Benjamin Watson"], "title": "Developing and evaluating quilts for the depiction of large layered graphs", "categories": ["cs.GR", "cs.HC"], "comment": null, "summary": "Traditional layered graph depictions such as flow charts are in wide use. Yet\nas graphs grow more complex, these depictions can become difficult to\nunderstand. Quilts are matrix-based depictions for layered graphs designed to\naddress this problem. In this research, we first improve Quilts by developing\nthree design alternatives, and then compare the best of these alternatives to\nbetter-known node-link and matrix depictions. A primary weakness in Quilts is\ntheir depiction of skip links, links that do not simply connect to a succeeding\nlayer. Therefore in our first study, we compare Quilts using color-only,\ntext-only, and mixed (color and text) skip link depictions, finding that path\nfinding with the color-only depiction is significantly slower and less\naccurate, and that in certain cases, the mixed depiction offers an advantage\nover the text-only depiction. In our second study, we compare Quilts using the\nmixed depiction to node-link diagrams and centered matrices. Overall results\nshow that users can find paths through graphs significantly faster with Quilts\n(46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams.\nThis speed advantage is still greater in large graphs (e.g. in 200 node graphs,\n55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions)."}
{"id": "2507.10732", "pdf": "https://arxiv.org/pdf/2507.10732", "abs": "https://arxiv.org/abs/2507.10732", "authors": ["Josée Desharnais", "Ana Sokolova"], "title": "$ε$-Distance via Lévy-Prokhorov Lifting", "categories": ["cs.LO"], "comment": null, "summary": "The most studied and accepted pseudometric for probabilistic processes is one\nbased on the Kantorovich distance between distributions. It comes with many\ntheoretical and motivating results, in particular it is the fixpoint of a given\nfunctional and defines a functor on (complete) pseudometric spaces.\n  Other notions of behavioural pseudometrics have also been proposed, one of\nthem ($\\epsilon$-distance) based on $\\epsilon$-bisimulation.\n$\\epsilon$-Distance has the advantages that it is intuitively easy to\nunderstand, it relates systems that are conceptually close (for example, an\nimperfect implementation is close to its specification), and it comes equipped\nwith a natural notion of $\\epsilon$-coupling. Finally, this distance is easy to\ncompute.\n  We show that $\\epsilon$-distance is also the greatest fixpoint of a\nfunctional and provides a functor. The latter is obtained by replacing the\nKantorovich distance in the lifting functor with the L\\'evy-Prokhorov distance.\nIn addition, we show that $\\epsilon$-couplings and $\\epsilon$-bisimulations\nhave an appealing coalgebraic characterization."}
{"id": "2507.10903", "pdf": "https://arxiv.org/pdf/2507.10903", "abs": "https://arxiv.org/abs/2507.10903", "authors": ["Parisa Fard Moshiri", "Xinyu Zhu", "Poonam Lohan", "Burak Kantarci", "Emil Janulewicz"], "title": "LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning", "categories": ["cs.NI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025", "summary": "Effective management of Service Function Chains (SFCs) and optimal Virtual\nNetwork Function (VNF) placement are critical challenges in modern\nSoftware-Defined Networking (SDN) and Network Function Virtualization (NFV)\nenvironments. Although Deep Reinforcement Learning (DRL) is widely adopted for\ndynamic network decision-making, its inherent dependency on structured data and\nfixed action rules often limits adaptability and responsiveness, particularly\nunder unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a\nnovel approach combining Lightweight Language Model (LiLM) with Relational\nDatabase (RDB) to answer network state queries to guide DRL model for efficient\nSFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and\nAuto-Regressive Transformers (BART) and the Fine-tuned Language Net T5\n(FLAN-T5), to interpret network data and support diverse query types related to\nSFC demands, data center resources, and VNF availability. Results demonstrate\nthat FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to\n0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time\n(2h 2min compared to 2h 38min). Moreover, when compared to the large language\nmodel SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting\nprocessing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min)."}
{"id": "2507.10773", "pdf": "https://arxiv.org/pdf/2507.10773", "abs": "https://arxiv.org/abs/2507.10773", "authors": ["Samuel Rhys Cox"], "title": "Theory of Mind and Self-Disclosure to CUIs", "categories": ["cs.HC", "cs.CL"], "comment": "Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in\n  Human-CUI Interaction, held in conjunction with the 2025 ACM conference on\n  Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures", "summary": "Self-disclosure is important to help us feel better, yet is often difficult.\nThis difficulty can arise from how we think people are going to react to our\nself-disclosure. In this workshop paper, we briefly discuss self-disclosure to\nconversational user interfaces (CUIs) in relation to various social cues. We\nthen, discuss how expressions of uncertainty or representation of a CUI's\nreasoning could help encourage self-disclosure, by making a CUI's intended\n\"theory of mind\" more transparent to users."}
{"id": "2507.11134", "pdf": "https://arxiv.org/pdf/2507.11134", "abs": "https://arxiv.org/abs/2507.11134", "authors": ["Zhicheng Xu", "Jiawei Liu", "Sitao Huang", "Zefan Li", "Shengbo Wang", "Bo Wen", "Ruibin Mao", "Mingrui Jiang", "Giacomo Pedretti", "Jim Ignowski", "Kaibin Huang", "Can Li"], "title": "Fault-Free Analog Computing with Imperfect Hardware", "categories": ["cs.ET", "cs.AR"], "comment": null, "summary": "The growing demand for edge computing and AI drives research into analog\nin-memory computing using memristors, which overcome data movement bottlenecks\nby computing directly within memory. However, device failures and variations\ncritically limit analog systems' precision and reliability. Existing\nfault-tolerance techniques, such as redundancy and retraining, are often\ninadequate for high-precision applications or scenarios requiring fixed\nmatrices and privacy preservation. Here, we introduce and experimentally\ndemonstrate a fault-free matrix representation where target matrices are\ndecomposed into products of two adjustable sub-matrices programmed onto analog\nhardware. This indirect, adaptive representation enables mathematical\noptimization to bypass faulty devices and eliminate differential pairs,\nsignificantly enhancing computational density. Our memristor-based system\nachieved >99.999% cosine similarity for a Discrete Fourier Transform matrix\ndespite 39% device fault rate, a fidelity unattainable with conventional direct\nrepresentation, which fails with single device faults (0.01% rate). We\ndemonstrated 56-fold bit-error-rate reduction in wireless communication and\n>196% density with 179% energy efficiency improvements compared to\nstate-of-the-art techniques. This method, validated on memristors, applies\nbroadly to emerging memories and non-electrical computing substrates, showing\nthat device yield is no longer the primary bottleneck in analog computing\nhardware."}
{"id": "2507.10629", "pdf": "https://arxiv.org/pdf/2507.10629", "abs": "https://arxiv.org/abs/2507.10629", "authors": ["Song Cheng", "Qiannan Cheng", "Linbo Jin", "Lei Yi", "Guannan Zhang"], "title": "SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition", "categories": ["cs.DB", "cs.AI", "I.2.7"], "comment": "WWW '25: Companion Proceedings of the ACM on Web Conference 2025\n  Pages 919 - 923 https://doi.org/10.1145/3701716.3715541", "summary": "Transforming natural language into SQL queries (NL2SQL) is crucial for\ndata-driven business applications. Existing frameworks, trained on open-source\ndatasets, struggle with complex business logic and lack domain-specific data\nfor fine-tuning. Additionally, evaluation methods often require annotated data\nand executable database environments, which are scarce in real-world scenarios.\nTo address these challenges, we propose SQLord, an enterprise-level NL2SQL\nframework. First, SQLord introduces a data reverse generation approach to\nconvert raw SQL statements into annotated data for supervised fine-tuning\n(SFT). Second, it proposes a decomposition method for complex queries using an\nautomated workflow generator. Additionally, SQLord features a comprehensive\nGPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL\nEvaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios.\nOffline tests significantly outperform state of the art baselines, and online\naccuracy consistently exceeds 90, highlighting SQLord's advantages and\neffectiveness in complex real world scenarios. SQLord has been successfully\napplied across multiple scenarios on the world's largest B2B e-commerce\nplatform."}
{"id": "2507.10573", "pdf": "https://arxiv.org/pdf/2507.10573", "abs": "https://arxiv.org/abs/2507.10573", "authors": ["Tianyu Ren", "Yajuan Du", "Jinhua Cui", "Yina Lv", "Qiao Li", "Chun Jason Xue"], "title": "Device-Level Optimization Techniques for Solid-State Drives: A Survey", "categories": ["cs.AR"], "comment": null, "summary": "Solid-state drives (SSDs) have revolutionized data storage with their high\nperformance, energy efficiency, and reliability. However, as storage demands\ngrow, SSDs face critical challenges in scalability, endurance, latency, and\nsecurity. This survey provides a comprehensive analysis of SSD architecture,\nkey challenges, and device-level optimization techniques. We first examine the\nfundamental components of SSDs, including NAND flash memory structures, SSD\ncontroller functionalities (e.g., address mapping, garbage collection, wear\nleveling), and host interface protocols (SATA, SAS, NVMe). Next, we discuss\nmajor challenges such as reliability degradation, endurance limitations,\nlatency variations, and security threats (e.g., secure deletion, ransomware\ndefense). We then explore advanced optimization techniques, including error\ncorrection mechanisms, flash translation layer (FTL) enhancements, and emerging\narchitectures like zoned namespace (ZNS) SSDs and flexible data placement\n(FDP). Finally, we highlight open research challenges, such as QLC/PLC NAND\nscalability, performance-reliability trade-offs, and SSD optimizations for\nAI/LLM workloads. This survey aims to guide future research in developing\nnext-generation SSDs that balance performance, longevity, and security in\nevolving storage ecosystems."}
{"id": "2507.10757", "pdf": "https://arxiv.org/pdf/2507.10757", "abs": "https://arxiv.org/abs/2507.10757", "authors": ["Ryan Zarick", "Isaac Zhang", "Daniel Wong", "Thomas Kim", "Bryan Pellegrino", "Mignon Li", "Kelvin Wong"], "title": "FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block", "categories": ["cs.DC", "cs.NI"], "comment": null, "summary": "Current blockchain execution throughput is limited by data contention,\nreducing execution layer parallelism. Fast Ahead-of-Formation Optimization\n(FAFO) is the first blockchain transaction scheduler to address this problem by\nreordering transactions before block formation for maximum concurrency. FAFO\nuses CPU-optimized cache-friendly Bloom filters to efficiently detect conflicts\nand schedule parallel transaction execution at high throughput and low\noverhead.\n  We integrate the Rust EVM client (REVM) into FAFO and achieve over 1.1\nmillion native ETH transfers per second and over half a million ERC20 transfers\nper second on a single node (Table 1), with 91% lower cost compared to\nstate-of-the-art sharded execution. Unlike many other existing high throughput\nblockchain execution clients, FAFO uses QMDB to Merkleize world state after\nevery block, enabling light clients and stateless validation for ZK-based\nvApps. FAFO scales with minimal synchronization overhead, scaling linearly with\nadditional CPU resources until it fully exploits the maximum parallelism of the\nunderlying transaction flow. FAFO proves that the high throughput necessary to\nsupport future decentralized applications can be achieved with a streamlined\nexecution layer and innovations in blockchain transaction scheduler design.\nFAFO is open-sourced at https://github.com/LayerZero-Labs/fafo."}
{"id": "2507.11507", "pdf": "https://arxiv.org/pdf/2507.11507", "abs": "https://arxiv.org/abs/2507.11507", "authors": ["Ruihao Li", "Shagnik Pal", "Vineeth Narayan Pullu", "Prasoon Sinha", "Jeeho Ryoo", "Lizy K. John", "Neeraja J. Yadwadkar"], "title": "MIRAGE: KV Cache Optimization through Parameter Remapping for Multi-tenant LLM Serving", "categories": ["cs.OS"], "comment": null, "summary": "KV cache accelerates LLM inference by avoiding redundant computation, at the\nexpense of memory. To support larger KV caches, prior work extends GPU memory\nwith CPU memory via CPU-offloading. This involves swapping KV cache between GPU\nand CPU memory. However, because the cache updates dynamically, such swapping\nincurs high CPU memory traffic. We make a key observation that model parameters\nremain constant during runtime, unlike the dynamically updated KV cache.\nBuilding on this, we introduce MIRAGE, which avoids KV cache swapping by\nremapping, and thereby repurposing, the memory allocated to model parameters\nfor KV cache. This parameter remapping is especially beneficial in multi-tenant\nenvironments, where the memory used for the parameters of the inactive models\ncan be more aggressively reclaimed. Exploiting the high CPU-GPU bandwidth\noffered by the modern hardware, such as the NVIDIA Grace Hopper Superchip, we\nshow that MIRAGE significantly outperforms state-of-the-art solutions,\nachieving a reduction of 44.8%-82.5% in tail time-between-token latency,\n20.7%-99.3% in tail time-to-first-token latency, and 6.6%-86.7% higher\nthroughput compared to vLLM."}
{"id": "2507.10640", "pdf": "https://arxiv.org/pdf/2507.10640", "abs": "https://arxiv.org/abs/2507.10640", "authors": ["Labiba Farah", "Mohammad Ridwan Kabir", "Shohel Ahmed", "MD Mohaymen Ul Anam", "Md. Sakibul Islam"], "title": "SENSOR: An ML-Enhanced Online Annotation Tool to Uncover Privacy Concerns from User Reviews in Social-Media Applications", "categories": ["cs.SE", "cs.LG", "cs.SI", "D.2.2"], "comment": "26 pages, 9 figures, 5 tables", "summary": "The widespread use of social media applications has raised significant\nprivacy concerns, often highlighted in user reviews. These reviews also provide\ndevelopers with valuable insights into improving apps by addressing issues and\nintroducing better features. However, the sheer volume and nuanced nature of\nreviews make manual identification and prioritization of privacy-related\nconcerns challenging for developers. Previous studies have developed software\nutilities to automatically classify user reviews as privacy-relevant,\nprivacy-irrelevant, bug reports, feature requests, etc., using machine\nlearning. Notably, there is a lack of focus on classifying reviews specifically\nas privacy-related feature requests, privacy-related bug reports, or\nprivacy-irrelevant. This paper introduces SENtinel SORt (SENSOR), an automated\nonline annotation tool designed to help developers annotate and classify user\nreviews into these categories. For automating the annotation of such reviews,\nthis paper introduces the annotation model, GRACE (GRU-based Attention with\nCBOW Embedding), using Gated Recurrent Units (GRU) with Continuous Bag of Words\n(CBOW) and Attention mechanism. Approximately 16000 user reviews from seven\npopular social media apps on Google Play Store, including Instagram, Facebook,\nWhatsApp, Snapchat, X (formerly Twitter), Facebook Lite, and Line were\nanalyzed. Two annotators manually labelled the reviews, achieving a Cohen's\nKappa value of 0.87, ensuring a labeled dataset with high inter-rater agreement\nfor training machine learning models. Among the models tested, GRACE\ndemonstrated the best performance (macro F1-score: 0.9434, macro ROC-AUC:\n0.9934, and accuracy: 95.10%) despite class imbalance. SENSOR demonstrates\nsignificant potential to assist developers with extracting and addressing\nprivacy-related feature requests or bug reports from user reviews, enhancing\nuser privacy and trust."}
{"id": "2507.11282", "pdf": "https://arxiv.org/pdf/2507.11282", "abs": "https://arxiv.org/abs/2507.11282", "authors": ["René Rydhof Hansen", "Andreas Stenbæk Larsen", "Aslan Askarov"], "title": "The downgrading semantics of memory safety", "categories": ["cs.PL"], "comment": "56 pages, 27 figures", "summary": "Memory safety is traditionally characterized in terms of bad things that\ncannot happen, an approach that is often criticized as unprincipled. Prior work\nsuggest a connection between memory safety and noninterference, but no\nsatisfactory semantic notion of memory safety is currently known.\n  This work proposes a notion of gradual allocator independence that accurately\ncaptures many allocator-specific aspects of memory safety. We consider a\nlow-level language with access to an allocator that provides malloc and free\nprimitives in a flat memory model. Pointers are just integers, and as such it\nis trivial to write memory-unsafe programs. The basic intuition of gradual\nallocator independence is that of noninterference, namely that allocators must\nnot influence program execution. This intuition is refined in two important\nways to account for the allocators running out-of-memory and for programs to\nhave pointer-to-integer casts. The key insight of the definition is to treat\nthese extensions as forms of downgrading and give them satisfactory technical\ntreatment using the state-of-the-art information flow machinery."}
{"id": "2507.10972", "pdf": "https://arxiv.org/pdf/2507.10972", "abs": "https://arxiv.org/abs/2507.10972", "authors": ["Zhaoyi An", "Rei Kawakami"], "title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production", "categories": ["cs.CL", "cs.CV", "cs.MM"], "comment": "Accepted by IEEE ICIP 2025", "summary": "Large language models, with their strong reasoning ability and rich\nknowledge, have brought revolution to many tasks of AI, but their impact on\nsign language generation remains limited due to its complexity and unique\nrules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign\nlanguage as another natural language. By fine-tuning an LLM, we enable it to\nlearn the correspondence between text and sign language, and facilitate\ngeneration. Considering the differences between sign and spoken language, we\nemploy a stepwise prompting strategy to extract the inherent sign language\nknowledge within the LLM, thereby supporting the learning and generation\nprocess. Experimental results on How2Sign and Phoenix14T datasets demonstrate\nthat our approach effectively leverages both the sign language knowledge and\nreasoning capabilities of LLM to align the different distribution and\ngrammatical rules between sign and spoken language."}
{"id": "2507.10924", "pdf": "https://arxiv.org/pdf/2507.10924", "abs": "https://arxiv.org/abs/2507.10924", "authors": ["Zihan Zhao", "Pengfei Wang", "Minfeng Xu", "Shuangmin Chen", "Shiqing Xin", "Changhe Tu", "Wenping Wang"], "title": "OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams", "categories": ["cs.GR"], "comment": null, "summary": "Offset surfaces, defined as the Minkowski sum of a base surface and a rolling\nball, play a crucial role in geometry processing, with applications ranging\nfrom coverage motion planning to brush modeling. While considerable progress\nhas been made in computing constant-radius offset surfaces, computing\nvariable-radius offset surfaces remains a challenging problem. In this paper,\nwe present OffsetCrust, a novel framework that efficiently addresses the\nvariable-radius offsetting problem by computing a power diagram. Let $R$ denote\nthe radius function defined on the base surface $S$. The power diagram is\nconstructed from contributing sites, consisting of carefully sampled base\npoints on $S$ and their corresponding off-surface points, displaced along\n$R$-dependent directions. In the constant-radius case only, these displacement\ndirections align exactly with the surface normals of $S$. Moreover, our method\nmitigates the misalignment issues commonly seen in crust-based approaches\nthrough a lightweight fine-tuning procedure. We validate the accuracy and\nefficiency of OffsetCrust through extensive experiments, and demonstrate its\npractical utility in applications such as reconstructing original boundary\nsurfaces from medial axis transform (MAT) representations."}
{"id": "2507.10781", "pdf": "https://arxiv.org/pdf/2507.10781", "abs": "https://arxiv.org/abs/2507.10781", "authors": ["Jaikrishna Manojkumar Patil", "Adam Chapman", "Richard Knuszka", "John Chapman", "Paulo Shakarian"], "title": "Reasoning about Medical Triage Optimization with Logic Programming", "categories": ["cs.LO"], "comment": "Accepted in International Conference on Logic Programming (ICLP 2025)", "summary": "We present a logic programming framework that orchestrates multiple variants\nof an optimization problem and reasons about their results to support\nhigh-stakes medical decision-making. The logic programming layer coordinates\nthe construction and evaluation of multiple optimization formulations,\ntranslating solutions into logical facts that support further symbolic\nreasoning and ensure efficient resource allocation-specifically targeting the\n\"right patient, right platform, right escort, right time, right destination\"\nprinciple. This capability is integrated into GuardianTwin, a decision support\nsystem for Forward Medical Evacuation (MEDEVAC), where rapid and explainable\nresource allocation is critical. Through a series of experiments, our framework\ndemonstrates an average reduction in casualties by 35.75 % compared to standard\nbaselines. Additionally, we explore how users engage with the system via an\nintuitive interface that delivers explainable insights, ultimately enhancing\ndecision-making in critical situations. This work demonstrates how logic\nprogramming can serve as a foundation for modular, interpretable, and\noperationally effective optimization in mission-critical domains."}
{"id": "2507.10928", "pdf": "https://arxiv.org/pdf/2507.10928", "abs": "https://arxiv.org/abs/2507.10928", "authors": ["Matthew Yang Liu", "Chuang Chen", "Pengcheng Lv", "Hui Guo", "Yanan Zhang", "Cong Wang", "Yusen Li", "Zhenyu Li", "Yu-Chu Tian"], "title": "Arcturus: A Cloud Overlay Network for Global Accelerator with Enhanced Performance and Stability", "categories": ["cs.NI", "cs.DC"], "comment": null, "summary": "Global Accelerator (GA) services play a vital role in ensuring low-latency,\nhigh-reliability communication for real-time interactive applications. However,\nexisting GA offerings are tightly bound to specific cloud providers, resulting\nin high costs, rigid deployment, and limited flexibility, especially for\nlarge-scale or budget-sensitive deployments. Arcturus is a cloud-native GA\nframework that revisits the design of GA systems by leveraging low-cost,\nheterogeneous cloud resources across multiple providers. Rather than relying on\nfixed, high-end infrastructure, Arcturus dynamically constructs its\nacceleration network and balances performance, stability, and resource\nefficiency. To achieve this, Arcturus introduces a two-plane design: a\nforwarding plane that builds a proxy network with adaptive control, and a\nscheduling plane that coordinates load and routing through lightweight,\nquantitative optimization. Evaluations under millions of RPS show that Arcturus\noutperforms commercial GA services by up to 1.7X in acceleration performance,\nreduces cost by 71%, and maintains over 80% resource efficiency--demonstrating\nefficient use of cloud resources at scale."}
{"id": "2507.10812", "pdf": "https://arxiv.org/pdf/2507.10812", "abs": "https://arxiv.org/abs/2507.10812", "authors": ["Chuxuan Zhang", "Yasaman Etesam", "Angelica Lim"], "title": "React to This (RTT): A Nonverbal Turing Test for Embodied AI", "categories": ["cs.HC", "cs.AI"], "comment": "5 pages, 3 figures", "summary": "We propose an approach to test embodied AI agents for interaction awareness\nand believability, particularly in scenarios where humans push them to their\nlimits. Turing introduced the Imitation Game as a way to explore the question:\n\"Can machines think?\" The Total Turing Test later expanded this concept beyond\npurely verbal communication, incorporating perceptual and physical interaction.\nBuilding on this, we propose a new guiding question: \"Can machines react?\" and\nintroduce the React to This (RTT) test for nonverbal behaviors, presenting\nresults from an initial experiment."}
{"id": "2507.10897", "pdf": "https://arxiv.org/pdf/2507.10897", "abs": "https://arxiv.org/abs/2507.10897", "authors": ["Sha Wang", "Yuchen Li", "Hanhua Xiao", "Bing Tian Dai", "Roy Ka-Wei Lee", "Yanfei Dong", "Lambert Deng"], "title": "LLMATCH: A Unified Schema Matching Framework with Large Language Models", "categories": ["cs.DB"], "comment": "Accepted at APWeb 2025, Schema Matching, LLM, Data Management", "summary": "Schema matching is a foundational task in enterprise data integration, aiming\nto align disparate data sources. While traditional methods handle simple\none-to-one table mappings, they often struggle with complex multi-table schema\nmatching in real-world applications. We present LLMatch, a unified and modular\nschema matching framework. LLMatch decomposes schema matching into three\ndistinct stages: schema preparation, table-candidate selection, and\ncolumn-level alignment, enabling component-level evaluation and future-proof\ncompatibility. It includes a novel two-stage optimization strategy: a Rollup\nmodule that consolidates semantically related columns into higher-order\nconcepts, followed by a Drilldown module that re-expands these concepts for\nfine-grained column mapping. To address the scarcity of complex semantic\nmatching benchmarks, we introduce SchemaNet, a benchmark derived from\nreal-world schema pairs across three enterprise domains, designed to capture\nthe challenges of multi-table schema alignment in practical settings.\nExperiments demonstrate that LLMatch significantly improves matching accuracy\nin complex schema matching settings and substantially boosts engineer\nproductivity in real-world data integration."}
{"id": "2507.10639", "pdf": "https://arxiv.org/pdf/2507.10639", "abs": "https://arxiv.org/abs/2507.10639", "authors": ["Simon Nau", "Jan Krummenauer", "André Zimmermann"], "title": "SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies", "categories": ["cs.AR", "cs.AI", "cs.ET"], "comment": "11 pages, 10 figures", "summary": "State-of-the-art large language models (LLMs) show high performance across a\nwide range of tasks in many domains of science. In the field of electronic\ndesign automation (EDA), it is yet to be determined to what extent they are\ncapable to understand, adapt, and dimension electronic circuits. This paper\nfocuses on the application of LLMs to switched-mode power supply (SMPS) design\non printed circuit boards (PCBs). Particular challenges for LLMs in this\ncontext include their limited ability to interpret results from key simulation\ntools like SPICE and the multi-step design process. To address these\nchallenges, we suggest SPICEAssistant, a framework that provides a broad\nselection of tools to an LLM. The tools serve as an interface to SPICE,\nallowing the LLM to interact flexibly with the simulator to estimate the impact\nof its modifications to the circuit. To evaluate the performance of\nSPICEAssistant, we defined a benchmark consisting of 256 questions testing the\nability to adapt circuit netlists to fulfil different SMPS design tasks. The\nbenchmarking results show that simulation feedback effectively improves SMPS\ndesign capabilities of LLMs. An increasing number of simulation iterations\nleads to enhanced performance. The SPICEAssistant framework significantly\noutperforms the standalone LLM GPT-4o on the benchmark by approximately 38%."}
{"id": "2507.10789", "pdf": "https://arxiv.org/pdf/2507.10789", "abs": "https://arxiv.org/abs/2507.10789", "authors": ["Aaron Jarmusch", "Nathan Graddon", "Sunita Chandrasekaran"], "title": "Dissecting the NVIDIA Blackwell Architecture with Microbenchmarks", "categories": ["cs.DC"], "comment": null, "summary": "The rapid development in scientific research provides a need for more compute\npower, which is partly being solved by GPUs. This paper presents a\nmicroarchitectural analysis of the modern NVIDIA Blackwell architecture by\nstudying GPU performance\n  features with thought through microbenchmarks. We unveil key subsystems,\nincluding the memory hierarchy, SM execution\n  pipelines, and the SM sub-core units, including the 5th generation tensor\ncores supporting FP4 and FP6 precisions.\n  To understand the different key features of the NVIDIA GPU, we study latency,\nthroughput, cache behavior, and scheduling\n  details, revealing subtle tuning metrics in the design of Blackwell. To\ndevelop a comprehensive analysis, we compare the\n  Blackwell architecture with the previous Hopper architecture by using the\nGeForce RTX 5080 and H100 PCIe, respectively. We\n  evaluate and compare results, presenting both generational improvements and\nperformance regressions. Additionally, we\n  investigate the role of power efficiency and energy consumption under varied\nworkloads. Our findings provide actionable insights\n  for application developers, compiler writers, and performance engineers to\noptimize workloads on Blackwell-based platforms,\n  and contribute new data to the growing research on GPU architectures."}
{"id": "2507.10591", "pdf": "https://arxiv.org/pdf/2507.10591", "abs": "https://arxiv.org/abs/2507.10591", "authors": ["Vanderson Rocha", "Diego Kreutz", "Gabriel Canto", "Hendrio Bragança", "Eduardo Feitosa"], "title": "MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.PF", "68T01", "I.2"], "comment": "11 pages; 4 figures; 5 tables; submitted to JBCS", "summary": "Feature selection is vital for building effective predictive models, as it\nreduces dimensionality and emphasizes key features. However, current research\noften suffers from limited benchmarking and reliance on proprietary datasets.\nThis severely hinders reproducibility and can negatively impact overall\nperformance. To address these limitations, we introduce the MH-FSF framework, a\ncomprehensive, modular, and extensible platform designed to facilitate the\nreproduction and implementation of feature selection methods. Developed through\ncollaborative research, MH-FSF provides implementations of 17 methods (11\nclassical, 6 domain-specific) and enables systematic evaluation on 10 publicly\navailable Android malware datasets. Our results reveal performance variations\nacross both balanced and imbalanced datasets, highlighting the critical need\nfor data preprocessing and selection criteria that account for these\nasymmetries. We demonstrate the importance of a unified platform for comparing\ndiverse feature selection techniques, fostering methodological consistency and\nrigor. By providing this framework, we aim to significantly broaden the\nexisting literature and pave the way for new research directions in feature\nselection, particularly within the context of Android malware detection."}
{"id": "2507.10641", "pdf": "https://arxiv.org/pdf/2507.10641", "abs": "https://arxiv.org/abs/2507.10641", "authors": ["Jayant Havare", "Saurav Chaudhary", "Ganesh Ramakrishnan", "Kaushik Maharajan", "Srikanth Tamilselvam"], "title": "A Code Comprehension Benchmark for Large Language Models for Code", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "10 Pages, 5 Figures", "summary": "Large Language Models have shown impressive capabilities in coding tasks like\ncode generation and code completion, as they have been trained on a large\namount of code data. Also, since one of the core pretraining objectives is Next\nToken Prediction, these models tends to learn surface-level syntactic patterns\nin code. However, this does not guarantee code comprehension ability i.e. the\nability to capture the semantics of the code. In our opinion, this is the\nreason why these models often underperform on tasks that require deeper\nsemantic understanding, such as code debugging and code optimization. To\naddress this, we propose fine-tuning these models specifically for code\ncomprehension tasks using large-scale datasets, enabling them to develop a more\nrobust understanding of code semantics. We evaluate three code models of\nvarying sizes on a suite of code comprehension tasks designed to assess\nsemantic understanding beyond surface-level syntactic pattern matching. In\nparticular, we analyze performance on the Subjectivity Grading Task and observe\nthat model performance improves after fine-tuning on relevant downstream tasks.\nThe most significant improvement is seen in the QWQ-32B model, where accuracy\nincreases from 70% to 83.47%. A similar or explainable trend is observed across\nother models, clearly indicating an enhancement in code comprehension ability.\nAmong the models studied, the DPO-fine-tuned Codestral-22B achieves the highest\nmicro-accuracy of 87.66% on the Subjectivity Grading Task."}
{"id": "2507.10635", "pdf": "https://arxiv.org/pdf/2507.10635", "abs": "https://arxiv.org/abs/2507.10635", "authors": ["Nicola Assolini", "Luca Marzari", "Isabella Mastroeni", "Alessandra di Pierro"], "title": "Formal Verification of Variational Quantum Circuits", "categories": ["quant-ph", "cs.LG", "cs.PL"], "comment": "Assolini and Marzari contributed equally to the paper", "summary": "Variational quantum circuits (VQCs) are a central component of many quantum\nmachine learning algorithms, offering a hybrid quantum-classical framework\nthat, under certain aspects, can be considered similar to classical deep neural\nnetworks. A shared aspect is, for instance, their vulnerability to adversarial\ninputs, small perturbations that can lead to incorrect predictions. While\nformal verification techniques have been extensively developed for classical\nmodels, no comparable framework exists for certifying the robustness of VQCs.\nHere, we present the first in-depth theoretical and practical study of the\nformal verification problem for VQCs. Inspired by abstract interpretation\nmethods used in deep learning, we analyze the applicability and limitations of\ninterval-based reachability techniques in the quantum setting. We show that\nquantum-specific aspects, such as state normalization, introduce inter-variable\ndependencies that challenge existing approaches. We investigate these issues by\nintroducing a novel semantic framework based on abstract interpretation, where\nthe verification problem for VQCs can be formally defined, and its complexity\nanalyzed. Finally, we demonstrate our approach on standard verification\nbenchmarks."}
{"id": "2507.11465", "pdf": "https://arxiv.org/pdf/2507.11465", "abs": "https://arxiv.org/abs/2507.11465", "authors": ["Nuri Ryu", "Jiyun Won", "Jooeun Son", "Minsu Gong", "Joo-Haeng Lee", "Sunghyun Cho"], "title": "Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to SIGGRAPH 2025. For the project page, see\n  https://cg.postech.ac.kr/research/Elevate3D/", "summary": "High-quality 3D assets are essential for various applications in computer\ngraphics and 3D vision but remain scarce due to significant acquisition costs.\nTo address this shortage, we introduce Elevate3D, a novel framework that\ntransforms readily accessible low-quality 3D assets into higher quality. At the\ncore of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that\nsignificantly improves texture quality while preserving the appearance and\ngeometry while fixing its degradations. Furthermore, Elevate3D operates in a\nview-by-view manner, alternating between texture and geometry refinement.\nUnlike previous methods that have largely overlooked geometry refinement, our\nframework leverages geometric cues from images refined with HFS-SDEdit by\nemploying state-of-the-art monocular geometry predictors. This approach ensures\ndetailed and accurate geometry that aligns seamlessly with the enhanced\ntexture. Elevate3D outperforms recent competitors by achieving state-of-the-art\nquality in 3D model refinement, effectively addressing the scarcity of\nhigh-quality open-source 3D assets."}
{"id": "2507.11126", "pdf": "https://arxiv.org/pdf/2507.11126", "abs": "https://arxiv.org/abs/2507.11126", "authors": ["Luca Di Stefano"], "title": "Execution and monitoring of HOA automata with HOAX", "categories": ["cs.LO", "cs.FL"], "comment": "To appear in RV'25", "summary": "We present a tool called Hoax for the execution of {\\omega}-automata\nexpressed in the popular HOA format. The tool leverages the notion of trap sets\nto enable runtime monitoring of any (non-parity) acceptance condition supported\nby the format. When the automaton is not monitorable, the tool may still be\nable to recognise so-called ugly prefixes, and determine that no further\nobservation will ever lead to a conclusive verdict. The tool is open-source and\nhighly configurable. We present its formal foundations, its design, and compare\nit against the trace analyser PyContract on a lock acquisition scenario."}
{"id": "2507.11014", "pdf": "https://arxiv.org/pdf/2507.11014", "abs": "https://arxiv.org/abs/2507.11014", "authors": ["Tasnim Ahmed", "Mirza Mohammad Azwad", "Salimur Choudhury"], "title": "SIMCODE: A Benchmark for Natural Language to ns-3 Network Simulation Code Generation", "categories": ["cs.NI"], "comment": "This paper has been accepted for presentation at the 50th IEEE\n  Conference on Local Computer Networks (LCN) - special track on Large Language\n  Models and Networking", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation across various domains. However, their effectiveness in\ngenerating simulation scripts for domain-specific environments like ns-3\nremains underexplored. Despite the growing interest in automating network\nsimulations, existing tools primarily focus on interactive automation over\nrigorous evaluation. To facilitate systematic evaluation, we introduce SIMCODE,\nthe first benchmark to evaluate LLMs' ability to generate ns-3 simulation code\nfrom natural language. SIMCODE includes 400 tasks across introductory,\nintermediate, and advanced levels, with solutions and test cases. Using\nSIMCODE, we evaluate three prominent LLMs, Gemini-2.0, GPT-4.1, and Qwen-3,\nacross six prompt techniques. Furthermore, investigating task-specific\nfine-tuning's impact reveals that while GPT-4.1 outperforms others, execution\naccuracy remains modest, with substantial room for improvement. Error analysis\nidentifies missing headers and API mismatches as dominant failures.\nNevertheless, SIMCODE provides a foundational step toward evaluating LLMs and\nresearch in domain-aware generative systems."}
{"id": "2507.10813", "pdf": "https://arxiv.org/pdf/2507.10813", "abs": "https://arxiv.org/abs/2507.10813", "authors": ["Justin M. Kasowski", "Apurv Varshney", "Michael Beyeler"], "title": "Static or Temporal? Semantic Scene Simplification to Aid Wayfinding in Immersive Simulations of Bionic Vision", "categories": ["cs.HC"], "comment": null, "summary": "Visual neuroprostheses (bionic eye) aim to restore a rudimentary form of\nvision by translating camera input into patterns of electrical stimulation. To\nimprove scene understanding under extreme resolution and bandwidth constraints,\nprior work has explored computer vision techniques such as semantic\nsegmentation and depth estimation. However, presenting all task-relevant\ninformation simultaneously can overwhelm users in cluttered environments. We\ncompare two complementary approaches to semantic preprocessing in immersive\nvirtual reality: SemanticEdges, which highlights all relevant objects at once,\nand SemanticRaster, which staggers object categories over time to reduce visual\nclutter. Using a biologically grounded simulation of prosthetic vision, 18\nsighted participants performed a wayfinding task in a dynamic urban environment\nacross three conditions: edge-based baseline (Control), SemanticEdges, and\nSemanticRaster. Both semantic strategies improved performance and user\nexperience relative to the baseline, with each offering distinct trade-offs:\nSemanticEdges increased the odds of success, while SemanticRaster boosted the\nlikelihood of collision-free completions. These findings underscore the value\nof adaptive semantic preprocessing for prosthetic vision and, more broadly, may\ninform the design of low-bandwidth visual interfaces in XR that must balance\ninformation density, task relevance, and perceptual clarity."}
{"id": "2507.10934", "pdf": "https://arxiv.org/pdf/2507.10934", "abs": "https://arxiv.org/abs/2507.10934", "authors": ["Xinyuan Liu", "Jiahui Chen", "Bocheng Hu", "Yu Sun", "Xinyang Chen", "Shaoxu Song"], "title": "Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Data quality remains an important challenge in data-driven systems, as errors\nin tabular data can severely compromise downstream analytics and machine\nlearning performance. Although numerous error detection algorithms have been\nproposed, the lack of diverse, real-world error datasets limits comprehensive\nevaluation. Manual error annotation is both time-consuming and inconsistent,\nmotivating the exploration of synthetic error generation as an alternative. In\nthis work, we introduce TableEG, a framework that leverages large language\nmodels (LLMs) to generate authentic errors. By employing a table fine-tuning\nstrategy and a triplet representation $(I, T, O)$ to model error generation,\ndetection, and correction tasks, TableEG captures the complex dependencies\ninherent in two-dimensional tables. Trained on 12 real-world datasets spanning\n10 diverse domains, TableEG ensures that the synthesized errors faithfully\nreflect authentic error distributions. Experimental results indicate that\nerrors generated by TableEG exhibit superior pattern and distribution\nsimilarity compared to both rule-based methods and LLM-generated errors without\nfine-tuning. Furthermore, performance metrics on TableEG-generated errors\nclosely align with those on real-world errors across nearly all datasets and\ndetection algorithms, particularly for machine learning based detection\ntechniques. Overall, TableEG not only bridges the gap between synthetic and\nreal-world errors but also establishes a robust benchmark for subsequent error\ndetection and correction tasks."}
{"id": "2507.10748", "pdf": "https://arxiv.org/pdf/2507.10748", "abs": "https://arxiv.org/abs/2507.10748", "authors": ["Jason Ho", "James A. Boyle", "Linshen Liu", "Andreas Gerstlauer"], "title": "LASANA: Large-scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration", "categories": ["cs.AR"], "comment": null, "summary": "Neuromorphic systems using in-memory or event-driven computing are motivated\nby the need for more energy-efficient processing of artificial intelligence\nworkloads. Emerging neuromorphic architectures aim to combine traditional\ndigital designs with the computational efficiency of analog computing and novel\ndevice technologies. A crucial problem in the rapid exploration and co-design\nof such architectures is the lack of tools for fast and accurate modeling and\nsimulation. Typical mixed-signal design tools integrate a digital simulator\nwith an analog solver like SPICE, which is prohibitively slow for large\nsystems. By contrast, behavioral modeling of analog components is faster, but\nexisting approaches are fixed to specific architectures with limited energy and\nperformance modeling. In this paper, we propose LASANA, a novel approach that\nleverages machine learning to derive data-driven surrogate models of analog\nsub-blocks in a digital backend architecture. LASANA uses SPICE-level\nsimulations of a circuit to train ML models that predict circuit energy,\nperformance, and behavior at analog/digital interfaces. Such models can provide\nenergy and performance annotation on top of existing behavioral models or\nfunction as replacements to analog simulation. We apply LASANA to an analog\ncrossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST,\nLASANA surrogates demonstrate up to three orders of magnitude speedup over\nSPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%,\nrespectively."}
{"id": "2507.11067", "pdf": "https://arxiv.org/pdf/2507.11067", "abs": "https://arxiv.org/abs/2507.11067", "authors": ["Yinuo Wang", "Tianqi Mao", "Lin Gan", "Wubing Wan", "Zeyu Song", "Jiayu Fu", "Lanke He", "Wenqiang Wang", "Zekun Yin", "Wei Xue", "Guangwen Yang"], "title": "MMStencil: Optimizing High-order Stencils on Multicore CPU using Matrix Unit", "categories": ["cs.DC"], "comment": "Yinuo Wang and Tianqi Mao contributed equally to this work", "summary": "Matrix-accelerated stencil computation is a hot research topic, yet its\napplication to three-dimensional (3D) high-order stencils and HPC remains\nunderexplored. With the emergence of matrix units on multicore CPUs, we analyze\nmatrix-based acceleration strategies and tailor an optimal approach for 3D\nhigh-order stencils. We introduce algorithmic optimizations based on SIMD and\nmatrix units to address strided memory accesses, alignment conflicts, and\nredundant accesses. We propose memory optimizations to boost on-package memory\nefficiency, and a novel multi-thread parallelism paradigm to overcome\ndata-sharing challenges caused by the absence of shared data caches. MMStencil\nsustains consistently high hardware utilization across diverse stencil shapes\nand dimensions. Our DMA-based inter-NUMA communication further mitigates NUMA\neffects and MPI limitations in hybrid parallelism. Combining all the\ninnovations, MMStencil outperforms state-of-the-art libraries on Nvidia A100\nGPGPU by up to 2.1x. Moreover, the performance improvements translate directly\nto real-world HPC applications and enable RTM applications to yield 1.8x\nspeedup versus a highly optimized industrial Nvidia A100 GPGPU version."}
{"id": "2507.11289", "pdf": "https://arxiv.org/pdf/2507.11289", "abs": "https://arxiv.org/abs/2507.11289", "authors": ["Martin Rose", "Simon Homes", "Lukas Ramsperger", "Jose Gracia", "Christoph Niethammer", "Jadran Vrabec"], "title": "Cyclic Data Streaming on GPUs for Short Range Stencils Applied to Molecular Dynamics", "categories": ["cs.DC", "cs.PF"], "comment": "Accepted for publication at HeteroPar 2025 co-located with Euro-Par\n  2025", "summary": "In the quest for highest performance in scientific computing, we present a\nnovel framework that relies on high-bandwidth communication between GPUs in a\ncompute cluster. The framework offers linear scaling of performance for\nexplicit algorithms that is only limited by the size of the dataset and the\nnumber of GPUs. Slices of the dataset propagate in a ring of processes (GPUs)\nfrom one GPU, where they are processed, to the next, which results in a\nparallel-in-time parallelization. The user of the framework has to write GPU\nkernels that implement the algorithm and provide slices of the dataset.\nKnowledge about the underlying parallelization strategy is not required because\nthe communication between processes is carried out by the framework. As a case\nstudy, molecular dynamics simulation based on the Lennard-Jones potential is\nimplemented to measure the performance for a homogeneous fluid. Single node\nperformance and strong scaling behavior of this framework is compared to\nLAMMPS, which is outperformed in the strong scaling case."}
{"id": "2507.10646", "pdf": "https://arxiv.org/pdf/2507.10646", "abs": "https://arxiv.org/abs/2507.10646", "authors": ["Myeongsoo Kim", "Shweta Garg", "Baishakhi Ray", "Varun Kumar", "Anoop Deoras"], "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Programming assistants powered by large language models have transformed\nsoftware development, yet most benchmarks focus narrowly on code generation\ntasks. Recent efforts like InfiBench and StackEval attempt to address this gap\nusing Stack Overflow data but remain limited to single-turn interactions in\nisolated contexts, require significant manual curation, and fail to represent\ncomplete project environments. We introduce CodeAssistBench (CAB), the first\nbenchmark framework for evaluating multi-turn programming assistance in\nrealistic settings that address real-world questions about actual codebases.\nUnlike existing programming Q&A benchmarks, CAB automatically generates\nscalable datasets from question-related GitHub issues using configurable\nparameters (e.g., repository creation date, star count, programming languages),\nand includes automatic containerization of codebases for evaluation. It then\nevaluates models through simulated users in these containerized environments\nwith full codebase access. Using this framework, we constructed a test set of\n3,286 real-world programming questions across 231 repositories, spanning seven\nprogramming languages and diverse problem domains. Our evaluation of leading\nLLMs reveals a substantial capability gap: while models perform well on Stack\nOverflow questions with success rates of 70-83%, they resolve only up to 16.49%\nof CAB's recent issues. This discrepancy highlights the challenges of providing\nassistance in complex, project-specific contexts versus answering standalone\nquestions."}
{"id": "2507.11479", "pdf": "https://arxiv.org/pdf/2507.11479", "abs": "https://arxiv.org/abs/2507.11479", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "title": "Perspective-Aware AI in Extended Reality", "categories": ["cs.AI", "cs.GR", "cs.HC"], "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems."}
{"id": "2507.11141", "pdf": "https://arxiv.org/pdf/2507.11141", "abs": "https://arxiv.org/abs/2507.11141", "authors": ["Simon Guilloud", "Sankalp Gambhir", "Viktor Kunčak"], "title": "Interpolation and Quantifiers in Ortholattices", "categories": ["cs.LO"], "comment": null, "summary": "We study quantifiers and interpolation properties in \\emph{orthologic}, a\nnon-distributive weakening of classical logic that is sound for formula\nvalidity with respect to classical logic, yet has a quadratic-time decision\nprocedure. We present a sequent-based proof system for quantified orthologic,\nwhich we prove sound and complete for the class of all complete ortholattices.\nWe show that orthologic does not admit quantifier elimination in general.\nDespite that, we show that interpolants always exist in orthologic. We give an\nalgorithm to compute interpolants efficiently. We expect our result to be\nuseful to quickly establish unreachability as a component of verification\nalgorithms."}
{"id": "2507.11038", "pdf": "https://arxiv.org/pdf/2507.11038", "abs": "https://arxiv.org/abs/2507.11038", "authors": ["Ka Ho Chiu", "Handi Yin", "Weipeng Zhuo", "Chul-Ho Lee", "S. -H. Gary Chan"], "title": "Graph-based Fingerprint Update Using Unlabelled WiFi Signals", "categories": ["cs.NI", "eess.SP"], "comment": "Published in Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies, Volume 9, Issue 1, Article No. 3, Pages 1 - 26", "summary": "WiFi received signal strength (RSS) environment evolves over time due to\nmovement of access points (APs), AP power adjustment, installation and removal\nof APs, etc. We study how to effectively update an existing database of\nfingerprints, defined as the RSS values of APs at designated locations, using a\nbatch of newly collected unlabelled (possibly crowdsourced) WiFi signals. Prior\nart either estimates the locations of the new signals without updating the\nexisting fingerprints or filters out the new APs without sufficiently embracing\ntheir features. To address that, we propose GUFU, a novel effective graph-based\napproach to update WiFi fingerprints using unlabelled signals with possibly new\nAPs. Based on the observation that similar signal vectors likely imply physical\nproximity, GUFU employs a graph neural network (GNN) and a link prediction\nalgorithm to retrain an incremental network given the new signals and APs.\nAfter the retraining, it then updates the signal vectors at the designated\nlocations. Through extensive experiments in four large representative sites,\nGUFU is shown to achieve remarkably higher fingerprint adaptivity as compared\nwith other state-of-the-art approaches, with error reduction of 21.4% and 29.8%\nin RSS values and location prediction, respectively."}
{"id": "2507.10963", "pdf": "https://arxiv.org/pdf/2507.10963", "abs": "https://arxiv.org/abs/2507.10963", "authors": ["Zheng Ning", "Leyang Li", "Daniel Killough", "JooYoung Seo", "Patrick Carrington", "Yapeng Tian", "Yuhang Zhao", "Franklin Mingzhe Li", "Toby Jia-Jun Li"], "title": "AROMA: Mixed-Initiative AI Assistance for Non-Visual Cooking by Grounding Multi-modal Information Between Reality and Videos", "categories": ["cs.HC"], "comment": null, "summary": "Videos offer rich audiovisual information that can support people in\nperforming activities of daily living (ADLs), but they remain largely\ninaccessible to blind or low-vision (BLV) individuals. In cooking, BLV people\noften rely on non-visual cues, such as touch, taste, and smell, to navigate\ntheir environment, making it difficult to follow the predominantly audiovisual\ninstructions found in video recipes. To address this problem, we introduce\nAROMA, an AI system that provides timely responses to the user based on\nreal-time, context-aware assistance by integrating non-visual cues perceived by\nthe user, a wearable camera feed, and video recipe content. AROMA uses a\nmixed-initiative approach: it responds to user requests while also proactively\nmonitoring the video stream to offer timely alerts and guidance. This\ncollaborative design leverages the complementary strengths of the user and AI\nsystem to align the physical environment with the video recipe, helping the\nuser interpret their current cooking state and make sense of the steps. We\nevaluated AROMA through a study with eight BLV participants and offered\ninsights for designing interactive AI systems to support BLV individuals in\nperforming ADLs."}
{"id": "2507.11505", "pdf": "https://arxiv.org/pdf/2507.11505", "abs": "https://arxiv.org/abs/2507.11505", "authors": ["Harsha Kokel", "Aamod Khatiwada", "Tejaswini Pedapati", "Haritha Ananthakrishnan", "Oktie Hassanzadeh", "Horst Samulowitz", "Kavitha Srinivas"], "title": "TOPJoin: A Context-Aware Multi-Criteria Approach for Joinable Column Search", "categories": ["cs.DB"], "comment": "VLDB 2025 Workshop: Tabular Data Analysis (TaDA); The source code,\n  data, and/or other artifacts have been made available at\n  https://github.com/IBM/ContextAwareJoin", "summary": "One of the major challenges in enterprise data analysis is the task of\nfinding joinable tables that are conceptually related and provide meaningful\ninsights. Traditionally, joinable tables have been discovered through a search\nfor similar columns, where two columns are considered similar syntactically if\nthere is a set overlap or they are considered similar semantically if either\nthe column embeddings or value embeddings are closer in the embedding space.\nHowever, for enterprise data lakes, column similarity is not sufficient to\nidentify joinable columns and tables. The context of the query column is\nimportant. Hence, in this work, we first define context-aware column\njoinability. Then we propose a multi-criteria approach, called TOPJoin, for\njoinable column search. We evaluate TOPJoin against existing join search\nbaselines over one academic and one real-world join search benchmark. Through\nexperiments, we find that TOPJoin performs better on both benchmarks than the\nbaselines."}
{"id": "2507.10849", "pdf": "https://arxiv.org/pdf/2507.10849", "abs": "https://arxiv.org/abs/2507.10849", "authors": ["Xinxin Wang", "Lixian Yan", "Shuhan Liu", "Luke Upton", "Zhuoqi Cai", "Yiming Tan", "Shengman Li", "Koustav Jana", "Peijing Li", "Jesse Cirimelli-Low", "Thierry Tambe", "Matthew Guthaus", "H. -S. Philip Wong"], "title": "OpenGCRAM: An Open-Source Gain Cell Compiler Enabling Design-Space Exploration for AI Workloads", "categories": ["cs.AR", "cs.SY", "eess.SY"], "comment": null, "summary": "Gain Cell memory (GCRAM) offers higher density and lower power than SRAM,\nmaking it a promising candidate for on-chip memory in domain-specific\naccelerators. To support workloads with varying traffic and lifetime metrics,\nGCRAM also offers high bandwidth, ultra low leakage power and a wide range of\nretention times, which can be adjusted through transistor design (like\nthreshold voltage and channel material) and on-the-fly by changing the\noperating voltage. However, designing and optimizing GCRAM sub-systems can be\ntime-consuming. In this paper, we present OpenGCRAM, an open-source GCRAM\ncompiler capable of generating GCRAM bank circuit designs and DRC- and\nLVS-clean layouts for commercially available foundry CMOS, while also providing\narea, delay, and power simulations based on user-specified configurations\n(e.g., word size and number of words). OpenGCRAM enables fast, accurate,\ncustomizable, and optimized GCRAM block generation, reduces design time, ensure\nprocess compliance, and delivers performance-tailored memory blocks that meet\ndiverse application requirements."}
{"id": "2507.11094", "pdf": "https://arxiv.org/pdf/2507.11094", "abs": "https://arxiv.org/abs/2507.11094", "authors": ["Nibedita Behera", "Ashwina Kumar", "Atharva Chougule", "Mohammed Shan P S", "Rushabh Nirdosh Lalwani", "Rupesh Nasre"], "title": "Generating Dynamic Graph Algorithms for Multiple Backends for a Graph DSL", "categories": ["cs.DC"], "comment": null, "summary": "With the rapid growth of unstructured and semistructured data, parallelizing\ngraph algorithms has become essential for efficiency. However, due to the\ninherent irregularity in computation, memory access patterns, and\ncommunication, graph algorithms are notoriously difficult to parallelize. To\naddress this challenge, several libraries, frameworks, and domain-specific\nlanguages (DSLs) have been proposed to ease the parallel programming burden for\ndomain experts. Existing frameworks partially or fully abstract away\nparallelism intricacies, provide intuitive scheduling mnemonics, and employ\nprogram analysis to identify data races and generate synchronization code.\nDespite these advances, most frameworks are limited in their abstractions and\nruntime optimizations, especially when dealing with static graphs. In contrast,\nmany real-world graphs are inherently dynamic, with evolving structures over\ntime through insertions, deletions, and modifications of vertices, edges, and\nattributes. Generating efficient and correctly synchronized code for such\ndynamic graph algorithms remains a significant challenge.\n  In this work, we introduce an abstraction scheme and runtime optimizations\nfor the efficient processing of morph algorithms. Specifically, given an\ninitial graph G and a set of updates $\\Delta$G involving edge insertions and\ndeletions, we express the dynamic processing logic through a DSL and\nautomatically generate parallel code targeting multicore, distributed, and\nmany-core environments. We demonstrate the effectiveness of our approach by\napplying the DSL-generated code to ten large graphs with diverse\ncharacteristics and three widely used algorithms: Shortest Paths, PageRank, and\nTriangle Counting."}
{"id": "2507.11512", "pdf": "https://arxiv.org/pdf/2507.11512", "abs": "https://arxiv.org/abs/2507.11512", "authors": ["Aditya Kashi", "Nicholson Koukpaizan", "Hao Lu", "Michael Matheson", "Sarp Oral", "Feiyi Wang"], "title": "Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y10", "G.4; C.4"], "comment": "Accepted for presentation at SC25, St. Louis, MO, USA", "summary": "Mixed-precision algorithms have been proposed as a way for scientific\ncomputing to benefit from some of the gains seen for artificial intelligence\n(AI) on recent high performance computing (HPC) platforms. A few applications\ndominated by dense matrix operations have seen substantial speedups by\nutilizing low precision formats such as FP16. However, a majority of scientific\nsimulation applications are memory bandwidth limited. Beyond preliminary\nstudies, the practical gain from using mixed-precision algorithms on a given\nHPC system is largely unclear.\n  The High Performance GMRES Mixed Precision (HPG-MxP) benchmark has been\nproposed to measure the useful performance of a HPC system on sparse\nmatrix-based mixed-precision applications. In this work, we present a highly\noptimized implementation of the HPG-MxP benchmark for an exascale system and\ndescribe our algorithm enhancements. We show for the first time a speedup of\n1.6x using a combination of double- and single-precision on modern GPU-based\nsupercomputers."}
{"id": "2507.10729", "pdf": "https://arxiv.org/pdf/2507.10729", "abs": "https://arxiv.org/abs/2507.10729", "authors": ["Duong Nguyen", "Thanh Le-Cong", "Triet Huynh Minh Le", "M. Ali Babar", "Quyet-Thang Huynh"], "title": "Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction", "categories": ["cs.SE"], "comment": null, "summary": "Modern software systems are increasingly complex, presenting significant\nchallenges in quality assurance. Just-in-time vulnerability prediction (JIT-VP)\nis a proactive approach to identifying vulnerable commits and providing early\nwarnings about potential security risks. However, we observe that current\nJIT-VP evaluations rely on an idealized setting, where the evaluation datasets\nare artificially balanced, consisting exclusively of vulnerability-introducing\nand vulnerability-fixing commits.\n  To address this limitation, this study assesses the effectiveness of JIT-VP\ntechniques under a more realistic setting that includes both\nvulnerability-related and vulnerability-neutral commits. To enable a reliable\nevaluation, we introduce a large-scale public dataset comprising over one\nmillion commits from FFmpeg and the Linux kernel. Our empirical analysis of\neight state-of-the-art JIT-VP techniques reveals a significant decline in\npredictive performance when applied to real-world conditions; for example, the\naverage PR-AUC on Linux drops 98\\% from 0.805 to 0.016. This discrepancy is\nmainly attributed to the severe class imbalance in real-world datasets, where\nvulnerability-introducing commits constitute only a small fraction of all\ncommits.\n  To mitigate this issue, we explore the effectiveness of widely adopted\ntechniques for handling dataset imbalance, including customized loss functions,\noversampling, and undersampling. Surprisingly, our experimental results\nindicate that these techniques are ineffective in addressing the imbalance\nproblem in JIT-VP. These findings underscore the importance of realistic\nevaluations of JIT-VP and the need for domain-specific techniques to address\ndata imbalance in such scenarios."}
{"id": "2507.11167", "pdf": "https://arxiv.org/pdf/2507.11167", "abs": "https://arxiv.org/abs/2507.11167", "authors": ["Simon Guilloud", "Sankalp Gambhir", "Viktor Kunčak"], "title": "LISA -- A Modern Proof System", "categories": ["cs.LO"], "comment": null, "summary": "We present LISA, a proof system and proof assistant for constructing proofs\nin schematic first-order logic and axiomatic set theory. The logical kernel of\nthe system is a proof checker for first-order logic with equality and schematic\npredicate and function symbols. It implements polynomial-time proof checking\nand uses the axioms of ortholattices (which implies the irrelevance of the\norder of conjuncts and disjuncts and additional propositional laws). The kernel\nsupports the notion of theorems (whose proofs are not expanded), as well as\ndefinitions of predicate symbols and objects whose unique existence is proven.\nA domain-specific language enables construction of proofs and development of\nproof tactics with user-friendly tools and presentation, while remaining within\nthe general-purpose language, Scala. We describe the LISA proof system and\nillustrate the flavour and the level of abstraction of proofs written in LISA.\nThis includes a proof-generating tactic for propositional tautologies,\nleveraging the ortholattice properties to reduce the size of proofs. We also\npresent early formalization of set theory in LISA, including Cantor's theorem."}
{"id": "2507.11168", "pdf": "https://arxiv.org/pdf/2507.11168", "abs": "https://arxiv.org/abs/2507.11168", "authors": ["Gabriele Formis", "Amanda Ericson", "Stefan Forsstrom", "Kyi Thar", "Gianluca Cena", "Stefano Scanzio"], "title": "Improving Wi-Fi Network Performance Prediction with Deep Learning Models", "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "comment": "preprint accepted, 8 pages, 2025", "summary": "The increasing need for robustness, reliability, and determinism in wireless\nnetworks for industrial and mission-critical applications is the driver for the\ngrowth of new innovative methods. The study presented in this work makes use of\nmachine learning techniques to predict channel quality in a Wi-Fi network in\nterms of the frame delivery ratio. Predictions can be used proactively to\nadjust communication parameters at runtime and optimize network operations for\nindustrial applications. Methods including convolutional neural networks and\nlong short-term memory were analyzed on datasets acquired from a real Wi-Fi\nsetup across multiple channels. The models were compared in terms of prediction\naccuracy and computational complexity. Results show that the frame delivery\nratio can be reliably predicted, and convolutional neural networks, although\nslightly less effective than other models, are more efficient in terms of CPU\nusage and memory consumption. This enhances the model's usability on embedded\nand industrial systems."}
{"id": "2507.10967", "pdf": "https://arxiv.org/pdf/2507.10967", "abs": "https://arxiv.org/abs/2507.10967", "authors": ["Thammathip Piumsomboon"], "title": "Self++: Merging Human and AI for Co-Determined XR Living in the Metaverse", "categories": ["cs.HC"], "comment": null, "summary": "This position paper introduces Self++, a novel nine-level framework for\nco-determined living in the Metaverse, grounded in Self-Determination Theory.\nSelf++ prioritises human flourishing by progressively cultivating competence,\nautonomy, and relatedness through dynamic human-AI collaboration in extended\nreality (XR). Unlike technologically deterministic approaches, Self++\nemphasises user empowerment by enhancing competency, mitigating cognitive\nbiases and leveraging XR's immersive capabilities. Key research directions\nproposed include exploring the boundaries of user-defined AI autonomy,\ndesigning for meaningful social connection in XR, and establishing proactive\nethical safeguards. Ultimately, Self++ offers a roadmap for creating a\nhuman-centred, AI-enhanced Metaverse where technology amplifies, rather than\ndiminishes, human potential."}
{"id": "2507.10562", "pdf": "https://arxiv.org/pdf/2507.10562", "abs": "https://arxiv.org/abs/2507.10562", "authors": ["Hari Masoor"], "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees."}
{"id": "2507.10912", "pdf": "https://arxiv.org/pdf/2507.10912", "abs": "https://arxiv.org/abs/2507.10912", "authors": ["Cunxi Yu"], "title": "Mapping Fusion: Improving FPGA Technology Mapping with ASIC Mapper", "categories": ["cs.AR"], "comment": "7 pages. to appear at MLCAD 2025", "summary": "LUT (Look-Up Table) mapping is a critical step in FPGA logic synthesis, where\na logic network is transformed into a form that can be directly implemented\nusing the FPGA's LUTs. An FPGA LUT is a flexible digital memory structure that\ncan implement any logic function of a limited number of inputs, typically 4 to\n6 inputs, depending on the FPGA architecture. The goal of LUT mapping is to map\nthe Boolean network into LUTs, where each LUT can implement any function with a\nfixed number of inputs. In parallel to FPGA technology mapping, ASIC technology\nmapping maps the Boolean network to user-defined standard cells, which has\ntraditionally been developed separately from LUT mapping algorithms. However,\nin this work, our motivating examples demonstrate that ASIC technology mappers\ncan potentially improve the performance of LUT mappers, such that standard cell\nmapping and LUT mapping work in an incremental manner.\n  Therefore, we propose the FuseMap framework, which explores this opportunity\nto improve LUT mapping in the FPGA design flow by utilizing reinforcement\nlearning to make design-specific choices during cell selection. The\neffectiveness of FuseMap is evaluated on a wide range of benchmarks, different\ntechnology libraries, and technology mappers. The experimental results\ndemonstrate that FuseMap achieves higher mapping accuracy while reducing delay\nand area across diverse circuit designs collected from ISCAS 85/89, ITC/ISCAS\n99, VTR 8.0, and EPFL benchmarks."}
{"id": "2507.11165", "pdf": "https://arxiv.org/pdf/2507.11165", "abs": "https://arxiv.org/abs/2507.11165", "authors": ["Shixun Wu", "Jinwen Pan", "Jinyang Liu", "Jiannan Tian", "Ziwei Qiu", "Jiajun Huang", "Kai Zhao", "Xin Liang", "Sheng Di", "Zizhong Chen", "Franck Cappello"], "title": "Boosting Scientific Error-Bounded Lossy Compression through Optimized Synergistic Lossy-Lossless Orchestration", "categories": ["cs.DC"], "comment": "accepted by SC '25", "summary": "As high-performance computing architectures evolve, more scientific computing\nworkflows are being deployed on advanced computing platforms such as GPUs.\nThese workflows can produce raw data at extremely high throughputs, requiring\nurgent high-ratio and low-latency error-bounded data compression solutions. In\nthis paper, we propose cuSZ-Hi, an optimized high-ratio GPU-based scientific\nerror-bounded lossy compressor with a flexible, domain-irrelevant, and fully\nopen-source framework design. Our novel contributions are: 1) We maximally\noptimize the parallelized interpolation-based data prediction scheme on GPUs,\nenabling the full functionalities of interpolation-based scientific data\nprediction that are adaptive to diverse data characteristics; 2) We thoroughly\nexplore and investigate lossless data encoding techniques, then craft and\nincorporate the best-fit lossless encoding pipelines for maximizing the\ncompression ratio of cuSZ-Hi; 3) We systematically evaluate cuSZ-Hi on\nbenchmarking datasets together with representative baselines. Compared to\nexisting state-of-the-art scientific lossy compressors, with comparative or\nbetter throughput than existing high-ratio scientific error-bounded lossy\ncompressors on GPUs, cuSZ-Hi can achieve up to 249% compression ratio\nimprovement under the same error bound, and up to 215% compression ratio\nimprovement under the same decompression data PSNR."}
{"id": "2507.10753", "pdf": "https://arxiv.org/pdf/2507.10753", "abs": "https://arxiv.org/abs/2507.10753", "authors": ["Kasper Lien Oftebro", "Anh Nguyen-Duc", "Kai-Kristian Kemell"], "title": "GenAI-Enabled Backlog Grooming in Agile Software Projects: An Empirical Study", "categories": ["cs.SE"], "comment": null, "summary": "Effective backlog management is critical for ensuring that development teams\nremain aligned with evolving requirements and stakeholder expectations.\nHowever, as product backlogs consistently grow in scale and complexity, they\ntend to become cluttered with redundant, outdated, or poorly defined tasks,\ncomplicating prioritization and decision making processes. This study\ninvestigates whether a generative-AI (GenAI) assistant can automate backlog\ngrooming in Agile software projects without sacrificing accuracy or\ntransparency. Through Design Science cycles, we developed a Jira plug-in that\nembeds backlog issues with the vector database, detects duplicates via cosine\nsimilarity, and leverage the GPT-4o model to propose merges, deletions, or new\nissues. We found that AI-assisted backlog grooming achieved 100 percent\nprecision while reducing the time-to-completion by 45 percent. The findings\ndemonstrated the tool's potential to streamline backlog refinement processes\nwhile improving user experiences."}
{"id": "2507.11186", "pdf": "https://arxiv.org/pdf/2507.11186", "abs": "https://arxiv.org/abs/2507.11186", "authors": ["Ana Sokolova", "Harald Woracek"], "title": "Cancellative Convex Semilattices", "categories": ["cs.LO"], "comment": null, "summary": "Convex semilattices are algebras that are at the same time a convex algebra\nand a semilattice, together with a distributivity axiom. These algebras have\nattracted some attention in the last years as suitable algebras for probability\nand nondeterminism, in particular by being the Eilenberg-Moore algebras of the\nnonempty finitely-generated convex subsets of the distributions monad.\n  A convex semilattice is cancellative if the underlying convex algebra is\ncancellative. Cancellative convex algebras have been characterized by M. H.\nStone and by H. Kneser: A convex algebra is cancellative if and only if it is\nisomorphic to a convex subset of a vector space (with canonical convex algebra\noperations).\n  We prove an analogous theorem for convex semilattices: A convex semilattice\nis cancellative if and only if it is isomorphic to a convex subset of a Riesz\nspace, i.e., a lattice-ordered vector space (with canonical convex semilattice\noperations)."}
{"id": "2507.11250", "pdf": "https://arxiv.org/pdf/2507.11250", "abs": "https://arxiv.org/abs/2507.11250", "authors": ["Mohamed Seliem", "Dirk Pesch", "Utz Roedig", "Cormac Sreenan"], "title": "Resilient Time-Sensitive Networking for Industrial IoT: Configuration and Fault-Tolerance Evaluation", "categories": ["cs.NI"], "comment": "(c) 2025 IEEE. This is the author's version of a paper accepted for\n  presentation at the IEEE ETFA 2025 conference. The final version will appear\n  in the conference proceedings", "summary": "Time-Sensitive Networking (TSN) is increasingly adopted in industrial systems\nto meet strict latency, jitter, and reliability requirements. However,\nevaluating TSN's fault tolerance under realistic failure conditions remains\nchallenging. This paper presents IN2C, a modular OMNeT++/INET-based simulation\nframework that models two synchronized production cells connected to\ncentralized infrastructure. IN2C integrates core TSN features, including time\nsynchronization, traffic shaping, per-stream filtering, and Frame Replication\nand Elimination for Redundancy (FRER), alongside XML-driven fault injection for\nlink and node failures. Four fault scenarios are evaluated to compare TSN\nperformance with and without redundancy. Results show that FRER eliminates\npacket loss and achieves submillisecond recovery, though with 2-3x higher link\nutilization. These findings offer practical guidance for deploying TSN in\nbandwidth-constrained industrial environments."}
{"id": "2507.10970", "pdf": "https://arxiv.org/pdf/2507.10970", "abs": "https://arxiv.org/abs/2507.10970", "authors": ["Lindah Kotut"], "title": "Terms and Conditions (Do Not) Apply: Understanding Exploitation Disparities in Design of Mobile-Based Financial Services", "categories": ["cs.HC"], "comment": "Accepted for Publication at The 5th Biennial African Human Computer\n  Interaction Conference (AfriCHI 2025). 10 pages (excluding references), 3\n  figures", "summary": "Mobile-based financial services have made it possible for the traditionally\nunbanked to access infrastructure that have been routinely unattainable.\nResearchers have explored how these systems have made for safer environments to\nsend and receive money and have expanded financial opportunities such as\nincreased borrowing. With this expansion, challenges such as detrimental\ninterest rates, lack of access to policy documents, and inadequate user\nprotective guardrails emerge, amplifying the risks due to technology-aided\nunethical financial practices that are aided by design patterns. Supported by\nuser interviews, we detail user experiences of mobile-based financial\ntransactions and explore the foundations and guidelines that undergird the\nfinancial service provisions: highlighting both affordances and harms enabled\nin the design of such systems. We discuss the findings by highlighting\nfinancial exploitation disparities, deliberating strategies for mitigation of\nrisks and enabling recovery from harms caused by the technology use. We then\nrecommend guidelines for empowering design approaches that support users'\nmechanisms of trust, their understanding of technological processes, and\ndetermination of risks."}
{"id": "2507.10627", "pdf": "https://arxiv.org/pdf/2507.10627", "abs": "https://arxiv.org/abs/2507.10627", "authors": ["Xiaojian Zhang", "Junqing Wang", "Kerui Chen", "Peiyuan Zhao", "Huiyuan Bai"], "title": "Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy", "categories": ["cs.CR", "cs.DB"], "comment": null, "summary": "Given a graph $G$ defined in a domain $\\mathcal{G}$, we investigate locally\ndifferentially private mechanisms to release a degree sequence on $\\mathcal{G}$\nthat accurately approximates the actual degree distribution. Existing solutions\nfor this problem mostly use graph projection techniques based on edge deletion\nprocess, using a threshold parameter $\\theta$ to bound node degrees. However,\nthis approach presents a fundamental trade-off in threshold parameter\nselection. While large $\\theta$ values introduce substantial noise in the\nreleased degree sequence, small $\\theta$ values result in more edges removed\nthan necessary. Furthermore, $\\theta$ selection leads to an excessive\ncommunication cost. To remedy existing solutions' deficiencies, we present\nCADR-LDP, an efficient framework incorporating encryption techniques and\ndifferentially private mechanisms to release the degree sequence. In CADR-LDP,\nwe first use the crypto-assisted Optimal-$\\theta$-Selection method to select\nthe optimal parameter with a low communication cost. Then, we use the LPEA-LOW\nmethod to add some edges for each node with the edge addition process in local\nprojection. LPEA-LOW prioritizes the projection with low-degree nodes, which\ncan retain more edges for such nodes and reduce the projection error.\nTheoretical analysis shows that CADR-LDP satisfies $\\epsilon$-node local\ndifferential privacy. The experimental results on eight graph datasets show\nthat our solution outperforms existing methods."}
{"id": "2507.10971", "pdf": "https://arxiv.org/pdf/2507.10971", "abs": "https://arxiv.org/abs/2507.10971", "authors": ["Kshitij Raj", "Atri Chatterjee", "Patanjali SLPSK", "Swarup Bhunia", "Sandip Ray"], "title": "Security Enclave Architecture for Heterogeneous Security Primitives for Supply-Chain Attacks", "categories": ["cs.AR", "cs.CR"], "comment": null, "summary": "Designing secure architectures for system-on-chip (SoC) platforms is a highly\nintricate and time-intensive task, often requiring months of development and\nmeticulous verification. Even minor architectural oversights can lead to\ncritical vulnerabilities that undermine the security of the entire chip. In\nresponse to this challenge, we introduce CITADEL, a modular security framework\naimed at streamlining the creation of robust security architectures for SoCs.\nCITADEL offers a configurable, plug-and-play subsystem composed of custom\nintellectual property (IP) blocks, enabling the construction of diverse\nsecurity mechanisms tailored to specific threats. As a concrete demonstration,\nwe instantiate CITADEL to defend against supply-chain threats, illustrating how\nthe framework adapts to one of the most pressing concerns in hardware security.\nThis paper explores the range of obstacles encountered when building a unified\nsecurity architecture capable of addressing multiple attack vectors and\npresents CITADEL's strategies for overcoming them. Through several real-world\ncase studies, we showcase the practical implementation of CITADEL and present a\nthorough evaluation of its impact on silicon area and power consumption across\nvarious ASIC technologies. Results indicate that CITADEL introduces only\nminimal resource overhead, making it a practical solution for enhancing SoC\nsecurity."}
{"id": "2507.11289", "pdf": "https://arxiv.org/pdf/2507.11289", "abs": "https://arxiv.org/abs/2507.11289", "authors": ["Martin Rose", "Simon Homes", "Lukas Ramsperger", "Jose Gracia", "Christoph Niethammer", "Jadran Vrabec"], "title": "Cyclic Data Streaming on GPUs for Short Range Stencils Applied to Molecular Dynamics", "categories": ["cs.DC", "cs.PF"], "comment": "Accepted for publication at HeteroPar 2025 co-located with Euro-Par\n  2025", "summary": "In the quest for highest performance in scientific computing, we present a\nnovel framework that relies on high-bandwidth communication between GPUs in a\ncompute cluster. The framework offers linear scaling of performance for\nexplicit algorithms that is only limited by the size of the dataset and the\nnumber of GPUs. Slices of the dataset propagate in a ring of processes (GPUs)\nfrom one GPU, where they are processed, to the next, which results in a\nparallel-in-time parallelization. The user of the framework has to write GPU\nkernels that implement the algorithm and provide slices of the dataset.\nKnowledge about the underlying parallelization strategy is not required because\nthe communication between processes is carried out by the framework. As a case\nstudy, molecular dynamics simulation based on the Lennard-Jones potential is\nimplemented to measure the performance for a homogeneous fluid. Single node\nperformance and strong scaling behavior of this framework is compared to\nLAMMPS, which is outperformed in the strong scaling case."}
{"id": "2507.10785", "pdf": "https://arxiv.org/pdf/2507.10785", "abs": "https://arxiv.org/abs/2507.10785", "authors": ["Michael Neumann", "Eva-Maria Schön", "Mali Senapathi", "Maria Rauschenberger", "Tiago Silva da Silva"], "title": "Towards a Closer Collaboration Between Practice and Research in Agile Software Development Workshop: A Summary and Research Agenda", "categories": ["cs.SE"], "comment": null, "summary": "Agile software development principles and values have been widely adopted\nacross various industries, influencing products and services globally. Despite\nits increasing popularity, a significant gap remains between research and\npractical implementation. This paper presents the findings of the first\ninternational workshop designed to foster collaboration between research and\npractice in agile software development. We discuss the main themes and factors\nidentified by the workshop participants that contribute to this gap, strategies\nto bridge it, and the challenges that require further research attention."}
{"id": "2507.11238", "pdf": "https://arxiv.org/pdf/2507.11238", "abs": "https://arxiv.org/abs/2507.11238", "authors": ["Philippe Balbiani", "Olivier Gasquet"], "title": "Complexity of some modal logics of density (extended version)", "categories": ["cs.LO", "03B45", "F.4.1"], "comment": null, "summary": "By using a selective filtration argument, we prove that the satisfiability\nproblem of the unimodal logic of density is in $EXPTIME$. By using a\ntableau-like approach, we prove that the satisfiability problem of the bimodal\nlogic of weak density is in $PSPACE$."}
{"id": "2507.11483", "pdf": "https://arxiv.org/pdf/2507.11483", "abs": "https://arxiv.org/abs/2507.11483", "authors": ["Ioannis Panitsas", "Yagmur Yigit", "Leandros Tassiulas", "Leandros Maglaras", "Berk Canberk"], "title": "JamShield: A Machine Learning Detection System for Over-the-Air Jamming Attacks", "categories": ["cs.NI", "eess.SP"], "comment": "Accepted for presentation at IEEE International Conference on\n  Communications (ICC), 2025", "summary": "Wireless networks are vulnerable to jamming attacks due to the shared\ncommunication medium, which can severely degrade performance and disrupt\nservices. Despite extensive research, current jamming detection methods often\nrely on simulated data or proprietary over-the-air datasets with limited\ncross-layer features, failing to accurately represent the real state of a\nnetwork and thus limiting their effectiveness in real-world scenarios. To\naddress these challenges, we introduce JamShield, a dynamic jamming detection\nsystem trained on our own collected over-the-air and publicly available\ndataset. It utilizes hybrid feature selection to prioritize relevant features\nfor accurate and efficient detection. Additionally, it includes an\nauto-classification module that dynamically adjusts the classification\nalgorithm in real-time based on current network conditions. Our experimental\nresults demonstrate significant improvements in detection rate, precision, and\nrecall, along with reduced false alarms and misdetections compared to\nstate-of-the-art detection algorithms, making JamShield a robust and reliable\nsolution for detecting jamming attacks in real-world wireless networks."}
{"id": "2507.10981", "pdf": "https://arxiv.org/pdf/2507.10981", "abs": "https://arxiv.org/abs/2507.10981", "authors": ["Ze Dong", "Binyang Han", "Jingjing Zhang", "Ruoyu Wen", "Barrett Ens", "Adrian Clark", "Tham Piumsomboon"], "title": "An Exploratory Study on AI-driven Visualisation Techniques on Decision Making in Extended Reality", "categories": ["cs.HC"], "comment": null, "summary": "The integration of extended reality (XR) with artificial intelligence (AI)\nintroduces a new paradigm for user interaction, enabling AI to perceive user\nintent, stimulate the senses, and influence decision-making. We explored the\nimpact of four AI-driven visualisation techniques -- `Inform,' `Nudge,'\n`Recommend,' and `Instruct' -- on user decision-making in XR using the Meta\nQuest Pro. To test these techniques, we used a pre-recorded 360-degree video of\na supermarket, overlaying each technique through a virtual interface. We aimed\nto investigate how these different visualisation techniques with different\nlevels of user autonomy impact preferences and decision-making. An exploratory\nstudy with semi-structured interviews provided feedback and design\nrecommendations. Our findings emphasise the importance of maintaining user\nautonomy, enhancing AI transparency to build trust, and considering context in\nvisualisation design."}
{"id": "2507.10730", "pdf": "https://arxiv.org/pdf/2507.10730", "abs": "https://arxiv.org/abs/2507.10730", "authors": ["Yin Li", "Sharad Mehrota", "Shantanu Sharma", "Komal Kumari"], "title": "Access Control for Information-Theoretically Secure Key-Document Stores", "categories": ["cs.CR", "cs.DB", "cs.DC", "cs.DS", "cs.IR"], "comment": "An extended abstract of this version has been accepted in VLDB 2025", "summary": "This paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir's\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files."}
{"id": "2507.11331", "pdf": "https://arxiv.org/pdf/2507.11331", "abs": "https://arxiv.org/abs/2507.11331", "authors": ["Jiawei Lin", "Guokai Chen", "Yuanlong Li", "Thomas Bourgeat"], "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Transformer models rely heavily on scaled dot-product attention (SDPA),\ntypically implemented using the FlashAttention algorithm. However, current\nsystolic-array-based accelerators face significant challenges when executing\nFlashAttention. Systolic arrays can only achieve high utilization for\nconsecutive and large matrix multiplications. In contrast, FlashAttention\nrequires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units\nresult in low systolic array utilization. This is further exacerbated by the\nfact that softmax involves numerous non-matrix operations, which are not\nwell-suited for systolic arrays. Moreover, the concurrent execution of matrix\nmultiplication on systolic arrays and softmax on vector units leads to register\nfile and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array\narchitecture that enables the entire FlashAttention algorithm to run entirely\nwithin a single systolic array, eliminating the need for external vector units.\nAt the core of FSA is SystolicAttention, a novel scheduling algorithm that maps\nFlashAttention operations onto systolic arrays with fine-grained, element-wise\noverlap. This significantly improves array utilization while preserving the\noriginal floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against\nstate-of-the-art commercial accelerators. Our results show that FSA achieves\n1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS\nNeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area\noverhead."}
{"id": "2507.11386", "pdf": "https://arxiv.org/pdf/2507.11386", "abs": "https://arxiv.org/abs/2507.11386", "authors": ["Carsten Burstedde", "Mikhail Kirilin", "Robert Klöfkorn"], "title": "A new Dune grid for scalable dynamic adaptivity based on the p4est software library", "categories": ["cs.DC", "65M50, 65N50"], "comment": "27 pages, 8 figures, 2 algorithms", "summary": "In this work we extend the Dune solver library with another grid interface to\nthe open-source p4est software. While Dune already supports about a dozen\ndifferent mesh implementations through its mesh interface Dune-Grid, we\nundertake this new coupling effort in order to inherit p4est's practically\nunlimited MPI scalability as well as its relatively thin data structures, and\nits native support for multi-block (forest) mesh topologies in both 2D and 3D.\n  The presented implementation is compared to an existing implementation based\non Dune-ALUGrid for a variety of challenging test examples in a parallel\nenvironment. The numerical experiments show that the implementation presented\nhere is outperforming Dune-ALUGrid in terms of scalability. In addition, an\nalternative balancing strategy is presented to ensure 2:1 balancing across\nelement faces showing improved performance compared to the existing p4est\nbalance strategy in the numerical examples considered in this work."}
{"id": "2507.10818", "pdf": "https://arxiv.org/pdf/2507.10818", "abs": "https://arxiv.org/abs/2507.10818", "authors": ["Jasmine Latendresse", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow", "categories": ["cs.SE"], "comment": null, "summary": "Software libraries are central to the functionality, security, and\nmaintainability of modern code. As developers increasingly turn to Large\nLanguage Models (LLMs) to assist with programming tasks, understanding how\nthese models recommend libraries is essential. In this paper, we conduct an\nempirical study of six state-of-the-art LLMs, both proprietary and open-source,\nby prompting them to solve real-world Python problems sourced from Stack\nOverflow. We analyze the types of libraries they import, the characteristics of\nthose libraries, and the extent to which the recommendations are usable out of\nthe box. Our results show that LLMs predominantly favour third-party libraries\nover standard ones, and often recommend mature, popular, and permissively\nlicensed dependencies. However, we also identify gaps in usability: 4.6% of the\nlibraries could not be resolved automatically due to structural mismatches\nbetween import names and installable packages, and only two models (out of six)\nprovided installation guidance. While the generated code is technically valid,\nthe lack of contextual support places the burden of manually resolving\ndependencies on the user. Our findings offer actionable insights for both\ndevelopers and researchers, and highlight opportunities to improve the\nreliability and usability of LLM-generated code in the context of software\ndependencies."}
{"id": "2507.11258", "pdf": "https://arxiv.org/pdf/2507.11258", "abs": "https://arxiv.org/abs/2507.11258", "authors": ["Olivier Gasquet"], "title": "Path-filtration for modal logics applied to revisiting quasi-dense logics", "categories": ["cs.LO", "03B45", "F.4.1"], "comment": null, "summary": "In https://arxiv.org/pdf/2405.10094 (also published at LICS'24 conference),\nLyon and Ostropolski-Nalewaja answer the question of the decidability of\nquasi-dense modallogics, and give an upper bound in EXPSPACE. Unfortunately,\ntheir intricate proof contains a major flaw that cannot be fixed, leaving the\nquestion wide open. In this paper we provide a correct and rather simple and\ndirect proof of it by introducing a new variant of the well-know filtration\nmethod based on paths in a canonical model and improve the hypothetical\nmembership to membership NEXPTIME."}
{"id": "2507.10757", "pdf": "https://arxiv.org/pdf/2507.10757", "abs": "https://arxiv.org/abs/2507.10757", "authors": ["Ryan Zarick", "Isaac Zhang", "Daniel Wong", "Thomas Kim", "Bryan Pellegrino", "Mignon Li", "Kelvin Wong"], "title": "FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block", "categories": ["cs.DC", "cs.NI"], "comment": null, "summary": "Current blockchain execution throughput is limited by data contention,\nreducing execution layer parallelism. Fast Ahead-of-Formation Optimization\n(FAFO) is the first blockchain transaction scheduler to address this problem by\nreordering transactions before block formation for maximum concurrency. FAFO\nuses CPU-optimized cache-friendly Bloom filters to efficiently detect conflicts\nand schedule parallel transaction execution at high throughput and low\noverhead.\n  We integrate the Rust EVM client (REVM) into FAFO and achieve over 1.1\nmillion native ETH transfers per second and over half a million ERC20 transfers\nper second on a single node (Table 1), with 91% lower cost compared to\nstate-of-the-art sharded execution. Unlike many other existing high throughput\nblockchain execution clients, FAFO uses QMDB to Merkleize world state after\nevery block, enabling light clients and stateless validation for ZK-based\nvApps. FAFO scales with minimal synchronization overhead, scaling linearly with\nadditional CPU resources until it fully exploits the maximum parallelism of the\nunderlying transaction flow. FAFO proves that the high throughput necessary to\nsupport future decentralized applications can be achieved with a streamlined\nexecution layer and innovations in blockchain transaction scheduler design.\nFAFO is open-sourced at https://github.com/LayerZero-Labs/fafo."}
{"id": "2507.11210", "pdf": "https://arxiv.org/pdf/2507.11210", "abs": "https://arxiv.org/abs/2507.11210", "authors": ["Rushia Harada", "Yuken Kimura", "Keito Inoshita"], "title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Well-being in family settings involves subtle psychological dynamics that\nconventional metrics often overlook. In particular, unconscious parental\nexpectations, termed ideal parent bias, can suppress children's emotional\nexpression and autonomy. This suppression, referred to as suppressed emotion,\noften stems from well-meaning but value-driven communication, which is\ndifficult to detect or address from outside the family. Focusing on these\nlatent dynamics, this study explores Large Language Model (LLM)-based support\nfor psychologically safe family communication. We constructed a Japanese\nparent-child dialogue corpus of 30 scenarios, each annotated with metadata on\nideal parent bias and suppressed emotion. Based on this corpus, we developed a\nRole-Playing LLM-based multi-agent dialogue support framework that analyzes\ndialogue and generates feedback. Specialized agents detect suppressed emotion,\ndescribe implicit ideal parent bias in parental speech, and infer contextual\nattributes such as the child's age and background. A meta-agent compiles these\noutputs into a structured report, which is then passed to five selected expert\nagents. These agents collaboratively generate empathetic and actionable\nfeedback through a structured four-step discussion process. Experiments show\nthat the system can detect categories of suppressed emotion with moderate\naccuracy and produce feedback rated highly in empathy and practicality.\nMoreover, simulated follow-up dialogues incorporating this feedback exhibited\nsigns of improved emotional expression and mutual understanding, suggesting the\nframework's potential in supporting positive transformation in family\ninteractions."}
{"id": "2507.11324", "pdf": "https://arxiv.org/pdf/2507.11324", "abs": "https://arxiv.org/abs/2507.11324", "authors": ["Frederik Marinus Trudslev", "Matteo Lissandrini", "Juan Manuel Rodriguez", "Martin Bøgsted", "Daniele Dell'Aglio"], "title": "A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation", "categories": ["cs.CR", "cs.DB"], "comment": null, "summary": "Privacy Preserving Synthetic Data Generation (PP-SDG) has emerged to produce\nsynthetic datasets from personal data while maintaining privacy and utility.\nDifferential privacy (DP) is the property of a PP-SDG mechanism that\nestablishes how protected individuals are when sharing their sensitive data. It\nis however difficult to interpret the privacy loss ($\\varepsilon$) expressed by\nDP. To make the actual risk associated with the privacy loss more transparent,\nmultiple privacy metrics (PMs) have been proposed to assess the privacy risk of\nthe data. These PMs are utilized in separate studies to assess newly introduced\nPP-SDG mechanisms. Consequently, these PMs embody the same assumptions as the\nPP-SDG mechanism they were made to assess. Therefore, a thorough definition of\nhow these are calculated is necessary. In this work, we present the assumptions\nand mathematical formulations of 17 distinct privacy metrics."}
{"id": "2507.11506", "pdf": "https://arxiv.org/pdf/2507.11506", "abs": "https://arxiv.org/abs/2507.11506", "authors": ["Yiqi Liu", "Yuqi Xue", "Noelle Crawford", "Jilong Xue", "Jian Huang"], "title": "Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques", "categories": ["cs.AR", "cs.DC", "cs.LG"], "comment": "This paper is accepted at the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO'25)", "summary": "To meet the increasing demand of deep learning (DL) models, AI chips are\nemploying both off-chip memory (e.g., HBM) and high-bandwidth low-latency\ninterconnect for direct inter-core data exchange. However, it is not easy to\nexplore the efficiency of these inter-core connected AI (ICCA) chips, due to a\nfundamental tussle among compute (per-core execution), communication\n(inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the\nefficiency of ICCA chips by jointly trading off all the three performance\nfactors discussed above. Elk structures these performance factors into\nconfigurable parameters and forms a global trade-off space in the DL compiler.\nTo systematically explore this space and maximize overall efficiency, Elk\nemploys a new inductive operator scheduling policy and a cost-aware on-chip\nmemory allocation algorithm. It generates globally optimized execution plans\nthat best overlap off-chip data loading and on-chip execution. To examine the\nefficiency of Elk, we build a full-fledged emulator based on a real ICCA chip\nIPU-POD4, and an ICCA chip simulator for sensitivity analysis with different\ninterconnect network topologies. Elk achieves 94% of the ideal roofline\nperformance of ICCA chips on average, showing the benefits of supporting large\nDL models on ICCA chips. We also show Elk's capability of enabling architecture\ndesign space exploration for new ICCA chip development."}
{"id": "2507.11417", "pdf": "https://arxiv.org/pdf/2507.11417", "abs": "https://arxiv.org/abs/2507.11417", "authors": ["Miray Özcan", "Philipp Wiesner", "Philipp Weiß", "Odej Kao"], "title": "Quantifying the Energy Consumption and Carbon Emissions of LLM Inference via Simulations", "categories": ["cs.DC"], "comment": "Presented at the Workshop on Performance and Energy Efficiency in\n  Concurrent and Distributed Systems (PECS) at Euro-PAR'25", "summary": "The environmental impact of Large Language Models (LLMs) is rising\nsignificantly, with inference now accounting for more than half of their total\nlifecycle carbon emissions. However, existing simulation frameworks, which are\nincreasingly used to determine efficient LLM deployments, lack any concept of\npower and, therefore, cannot accurately estimate inference-related emissions.\nWe present a simulation framework to assess the energy and carbon implications\nof LLM inference under varying deployment setups. First, we extend a\nhigh-fidelity LLM inference simulator with a GPU power model that estimates\npower consumption based on utilization metrics, enabling analysis across\nconfigurations like batch size, sequence length, and model parallelism. Second,\nwe integrate simulation outputs into an energy system co-simulation environment\nto quantify carbon emissions under specific grid conditions and explore the\npotential of carbon-aware scheduling. Through scenario-based analysis, our\nframework reveals how inference parameters affect energy demand and carbon\nfootprint, demonstrates a renewable offset potential of up to 69.2% in an\nillustrative deployment case, and provides a foundation for future carbon-aware\ninference infrastructure design."}
{"id": "2507.10822", "pdf": "https://arxiv.org/pdf/2507.10822", "abs": "https://arxiv.org/abs/2507.10822", "authors": ["Omar Elsisi", "Glaucia Melo"], "title": "Past, Present and Future: Exploring Adaptive AI in Software Development Bots", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Conversational agents, such as chatbots and virtual assistants, have become\nessential in software development, boosting productivity, collaboration, and\nautomating various tasks. This paper examines the role of adaptive AI-powered\nconversational agents in software development, highlighting their ability to\noffer dynamic, context-aware assistance to developers. Unlike traditional\nrule-based systems, adaptive AI agents use machine learning and natural\nlanguage processing to learn from interactions and improve over time, providing\nmore personalized and responsive help. We look at how these tools have evolved\nfrom simple query-based systems to advanced AI-driven solutions like GitHub\nCopilot and Microsoft Teams bots. We also explore the challenges of integrating\nadaptive AI into software development processes. The study aims to assess the\nbenefits and limitations of these systems, address concerns like data privacy\nand ethical issues, and offer insights into their future use in the field.\nUltimately, adaptive AI chatbots have great potential to revolutionize software\ndevelopment by delivering real-time, customized support and enhancing the\nefficiency of development cycles."}
{"id": "2507.11349", "pdf": "https://arxiv.org/pdf/2507.11349", "abs": "https://arxiv.org/abs/2507.11349", "authors": ["Julie Cailler", "Simon Guilloud"], "title": "SC-TPTP: An Extension of the TPTP Derivation Format for Sequent-Based Calculus", "categories": ["cs.LO"], "comment": null, "summary": "Motivated by the transfer of proofs between proof systems, and in particular\nfrom first order automated theorem provers (ATPs) to interactive theorem\nprovers (ITPs), we specify an extension of the TPTP derivation text format to\ndescribe proofs in first-order logic: SC-TPTP. To avoid multiplication of\nstandards, our proposed format over-specifies the TPTP derivation format by\nfocusing on sequent formalisms. By doing so, it provides a high level of\ndetail, is faithful to mathematical tradition, and cover multiple existing\ntools and in particular tableaux-based strategies. We make use of this format\nto allow the Lisa proof assistant to query the Go\\'eland automated theorem\nprover, and implement a library of tools able to parse, print and check SC-TPTP\nproofs, export them into Coq files, and rebuild low-level proof steps from\nadvanced ones."}
{"id": "2507.11222", "pdf": "https://arxiv.org/pdf/2507.11222", "abs": "https://arxiv.org/abs/2507.11222", "authors": ["Fares Wael", "Youssef Maklad", "Ali Hamdi", "Wael Elsersy"], "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining", "categories": ["cs.CL", "cs.AI", "cs.NI"], "comment": null, "summary": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications."}
{"id": "2507.11470", "pdf": "https://arxiv.org/pdf/2507.11470", "abs": "https://arxiv.org/abs/2507.11470", "authors": ["Xiaohang Tang", "Sam Wong", "Zicheng He", "Yalong Yang", "Yan Chen"], "title": "REVA: Supporting LLM-Generated Programming Feedback Validation at Scale Through User Attention-based Adaptation", "categories": ["cs.HC"], "comment": null, "summary": "This paper introduces REVA, a human-AI system that expedites instructor\nreview of voluminous AI-generated programming feedback by sequencing\nsubmissions to minimize cognitive context shifts and propagating\ninstructor-driven revisions across semantically similar instances. REVA\nintroduces a novel approach to human-AI collaboration in educational feedback\nby adaptively learning from instructors' attention in the review and revision\nprocess to continuously improve the feedback validation process. REVA's\nusefulness and effectiveness in improving feedback quality and the overall\nfeedback review process were evaluated through a within-subjects lab study with\n12 participants."}
{"id": "2507.10606", "pdf": "https://arxiv.org/pdf/2507.10606", "abs": "https://arxiv.org/abs/2507.10606", "authors": ["Bing-Yue Wu", "Vidya A. Chhabria"], "title": "DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "Under review at Asia and South Pacific Design Automation Conference\n  (ASP-DAC'26)", "summary": "Machine learning (ML) has demonstrated significant promise in various\nphysical design (PD) tasks. However, model generalizability remains limited by\nthe availability of high-quality, large-scale training datasets. Creating such\ndatasets is often computationally expensive and constrained by IP. While very\nfew public datasets are available, they are typically static, slow to generate,\nand require frequent updates. To address these limitations, we present DALI-PD,\na scalable framework for generating synthetic layout heatmaps to accelerate ML\nin PD research. DALI-PD uses a diffusion model to generate diverse layout\nheatmaps via fast inference in seconds. The heatmaps include power, IR drop,\ncongestion, macro placement, and cell density maps. Using DALI-PD, we created a\ndataset comprising over 20,000 layout configurations with varying macro counts\nand placements. These heatmaps closely resemble real layouts and improve ML\naccuracy on downstream ML tasks such as IR drop or congestion prediction."}
{"id": "2507.11430", "pdf": "https://arxiv.org/pdf/2507.11430", "abs": "https://arxiv.org/abs/2507.11430", "authors": ["Arnab Mukherjee", "Raju Halder", "Joydeep Chandra"], "title": "FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Federated Learning (FL) has undergone significant development since its\ninception in 2016, advancing from basic algorithms to complex methodologies\ntailored to address diverse challenges and use cases. However, research and\nbenchmarking of novel FL techniques against a plethora of established\nstate-of-the-art solutions remain challenging. To streamline this process, we\nintroduce FLsim, a comprehensive FL simulation framework designed to meet the\ndiverse requirements of FL workflows in the literature. FLsim is characterized\nby its modularity, scalability, resource efficiency, and controlled\nreproducibility of experimental outcomes. Its easy to use interface allows\nusers to specify customized FL requirements through job configuration, which\nsupports: (a) customized data distributions, ranging from non-independent and\nidentically distributed (non-iid) data to independent and identically\ndistributed (iid) data, (b) selection of local learning algorithms according to\nuser preferences, with complete agnosticism to ML libraries, (c) choice of\nnetwork topology illustrating communication patterns among nodes, (d)\ndefinition of model aggregation and consensus algorithms, and (e) pluggable\nblockchain support for enhanced robustness. Through a series of experimental\nevaluations, we demonstrate the effectiveness and versatility of FLsim in\nsimulating a diverse range of state-of-the-art FL experiments. We envisage that\nFLsim would mark a significant advancement in FL simulation frameworks,\noffering unprecedented flexibility and functionality for researchers and\npractitioners alike."}
{"id": "2507.10906", "pdf": "https://arxiv.org/pdf/2507.10906", "abs": "https://arxiv.org/abs/2507.10906", "authors": ["Qunhong Zeng", "Yuxia Zhang", "Zexiong Ma", "Bo Jiang", "Ningyuan Sun", "Klaas-Jan Stol", "Xingyu Mou", "Hui Liu"], "title": "Evaluating Generated Commit Messages with Large Language Models", "categories": ["cs.SE"], "comment": null, "summary": "Commit messages are essential in software development as they serve to\ndocument and explain code changes. Yet, their quality often falls short in\npractice, with studies showing significant proportions of empty or inadequate\nmessages. While automated commit message generation has advanced significantly,\nparticularly with Large Language Models (LLMs), the evaluation of generated\nmessages remains challenging. Traditional reference-based automatic metrics\nlike BLEU, ROUGE-L, and METEOR have notable limitations in assessing commit\nmessage quality, as they assume a one-to-one mapping between code changes and\ncommit messages, leading researchers to rely on resource-intensive human\nevaluation. This study investigates the potential of LLMs as automated\nevaluators for commit message quality. Through systematic experimentation with\nvarious prompt strategies and state-of-the-art LLMs, we demonstrate that LLMs\ncombining Chain-of-Thought reasoning with few-shot demonstrations achieve near\nhuman-level evaluation proficiency. Our LLM-based evaluator significantly\noutperforms traditional metrics while maintaining acceptable reproducibility,\nrobustness, and fairness levels despite some inherent variability. This work\nconducts a comprehensive preliminary study on using LLMs for commit message\nevaluation, offering a scalable alternative to human assessment while\nmaintaining high-quality evaluation."}
{"id": "2507.11150", "pdf": "https://arxiv.org/pdf/2507.11150", "abs": "https://arxiv.org/abs/2507.11150", "authors": ["Alessandro Bertagnon", "Marcello Dalpasso", "Michele Favalli", "Marco Gavanelli"], "title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming", "categories": ["cs.AI", "cs.LO"], "comment": "Accepted for publication in the issues of Theory and Practice of\n  Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures", "summary": "In the design of integrated circuits, one critical metric is the maximum\ndelay introduced by combinational modules within the circuit. This delay is\ncrucial because it represents the time required to perform a computation: in an\nArithmetic-Logic Unit it represents the maximum time taken by the circuit to\nperform an arithmetic operation. When such a circuit is part of a larger,\nsynchronous system, like a CPU, the maximum delay directly impacts the maximum\nclock frequency of the entire system. Typically, hardware designers use Static\nTiming Analysis to compute an upper bound of the maximum delay because it can\nbe determined in polynomial time. However, relying on this upper bound can lead\nto suboptimal processor speeds, thereby missing performance opportunities. In\nthis work, we tackle the challenging task of computing the actual maximum\ndelay, rather than an approximate value. Since the problem is computationally\nhard, we model it in Answer Set Programming (ASP), a logic language featuring\nextremely efficient solvers. We propose non-trivial encodings of the problem\ninto ASP. Experimental results show that ASP is a viable solution to address\ncomplex problems in hardware design."}
{"id": "2507.11490", "pdf": "https://arxiv.org/pdf/2507.11490", "abs": "https://arxiv.org/abs/2507.11490", "authors": ["Richmond Y. Wong"], "title": "Towards Creating Infrastructures for Values and Ethics Work in the Production of Software Technologies", "categories": ["cs.HC"], "comment": "In The sixth decennial Aarhus conference: Computing X Crisis (AAR\n  2025)", "summary": "Recognizing how technical systems can embody social values or cause harms,\nhuman-computer interaction (HCI) research often approaches addressing values\nand ethics in design by creating tools to help tech workers integrate social\nvalues into the design of products. While useful, these approaches usually do\nnot consider the politics embedded in the broader processes, organizations,\nsocial systems, and governance structures that affect the types of actions that\ntech workers can take to address values and ethics. This paper argues that\ncreating infrastructures to support values and ethics work, rather than tools,\nis an approach that takes these broader processes into account and opens them\nup for (re)design. Drawing on prior research conceptualizing infrastructures\nfrom science \\& technology studies and media studies, this paper outlines\nconceptual insights from infrastructures studies that open up new tactics for\nHCI researchers and designers seeking to support values and ethics in design."}
{"id": "2507.11134", "pdf": "https://arxiv.org/pdf/2507.11134", "abs": "https://arxiv.org/abs/2507.11134", "authors": ["Zhicheng Xu", "Jiawei Liu", "Sitao Huang", "Zefan Li", "Shengbo Wang", "Bo Wen", "Ruibin Mao", "Mingrui Jiang", "Giacomo Pedretti", "Jim Ignowski", "Kaibin Huang", "Can Li"], "title": "Fault-Free Analog Computing with Imperfect Hardware", "categories": ["cs.ET", "cs.AR"], "comment": null, "summary": "The growing demand for edge computing and AI drives research into analog\nin-memory computing using memristors, which overcome data movement bottlenecks\nby computing directly within memory. However, device failures and variations\ncritically limit analog systems' precision and reliability. Existing\nfault-tolerance techniques, such as redundancy and retraining, are often\ninadequate for high-precision applications or scenarios requiring fixed\nmatrices and privacy preservation. Here, we introduce and experimentally\ndemonstrate a fault-free matrix representation where target matrices are\ndecomposed into products of two adjustable sub-matrices programmed onto analog\nhardware. This indirect, adaptive representation enables mathematical\noptimization to bypass faulty devices and eliminate differential pairs,\nsignificantly enhancing computational density. Our memristor-based system\nachieved >99.999% cosine similarity for a Discrete Fourier Transform matrix\ndespite 39% device fault rate, a fidelity unattainable with conventional direct\nrepresentation, which fails with single device faults (0.01% rate). We\ndemonstrated 56-fold bit-error-rate reduction in wireless communication and\n>196% density with 179% energy efficiency improvements compared to\nstate-of-the-art techniques. This method, validated on memristors, applies\nbroadly to emerging memories and non-electrical computing substrates, showing\nthat device yield is no longer the primary bottleneck in analog computing\nhardware."}
{"id": "2507.11437", "pdf": "https://arxiv.org/pdf/2507.11437", "abs": "https://arxiv.org/abs/2507.11437", "authors": ["Sagar Bharadwaj", "Srinivasan Seshan", "Anthony Rowe"], "title": "Uniting the World by Dividing it: Federated Maps to Enable Spatial Applications", "categories": ["cs.DC", "cs.ET"], "comment": null, "summary": "The emergence of the Spatial Web -- the Web where content is tied to\nreal-world locations has the potential to improve and enable many applications\nsuch as augmented reality, navigation, robotics, and more. The Spatial Web is\nmissing a key ingredient that is impeding its growth -- a spatial naming system\nto resolve real-world locations to names. Today's spatial naming systems are\ndigital maps such as Google and Apple maps. These maps and the location-based\nservices provided on top of these maps are primarily controlled by a few large\ncorporations and mostly cover outdoor public spaces. Emerging classes of\napplications, such as persistent world-scale augmented reality, require\ndetailed maps of both outdoor and indoor spaces. Existing centralized mapping\ninfrastructures are proving insufficient for such applications because of the\nscale of cartography efforts required and the privacy of indoor map data.\n  In this paper, we present a case for a federated spatial naming system, or in\nother words, a federated mapping infrastructure. This enables disparate parties\nto manage and serve their own maps of physical regions and unlocks scalability\nof map management, isolation and privacy of maps. Map-related services such as\naddress-to-location mapping, location-based search, and routing needs\nre-architecting to work on federated maps. We discuss some essential services\nand practicalities of enabling these services."}
{"id": "2507.11059", "pdf": "https://arxiv.org/pdf/2507.11059", "abs": "https://arxiv.org/abs/2507.11059", "authors": ["Pavel Adamenko", "Mikhail Ivanov", "Aidar Valeev", "Rodion Levichev", "Pavel Zadorozhny", "Ivan Lopatin", "Dmitry Babayev", "Alena Fenogenova", "Valentin Malykh"], "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08\\% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025."}
{"id": "2507.11234", "pdf": "https://arxiv.org/pdf/2507.11234", "abs": "https://arxiv.org/abs/2507.11234", "authors": ["Piotr Bacik", "Joël Ouaknine", "James Worrell"], "title": "On the Complexity of the Skolem Problem at Low Orders", "categories": ["cs.CC", "cs.LO"], "comment": "19 pages", "summary": "The Skolem Problem asks to determine whether a given linear recurrence\nsequence (LRS) $\\langle u_n \\rangle_{n=0}^\\infty$ over the integers has a zero\nterm, that is, whether there exists $n$ such that $u_n = 0$. Decidability of\nthe problem is open in general, with the most notable positive result being a\ndecision procedure for LRS of order at most 4.\n  In this paper we consider a bounded version of the Skolem Problem, in which\nthe input consists of an LRS $\\langle u_n \\rangle_{n=0}^\\infty$ and a bound $N\n\\in \\mathbb N$ (with all integers written in binary), and the task is to\ndetermine whether there exists $n\\in\\{0,\\ldots,N\\}$ such that $u_n=0$. We give\na randomised algorithm for this problem that, for all $d\\in \\mathbb N$, runs in\npolynomial time on the class of LRS of order at most $d$. As a corollary we\nshow that the (unrestricted) Skolem Problem for LRS of order at most 4 lies in\n$\\mathsf{coRP}$, improving the best previous upper bound of\n$\\mathsf{NP}^{\\mathsf{RP}}$.\n  The running time of our algorithm is exponential in the order of the LRS -- a\ndependence that appears necessary in view of the $\\mathsf{NP}$-hardness of the\nBounded Skolem Problem. However, even for LRS of a fixed order, the problem\ninvolves detecting zeros within an exponentially large range. For this, our\nalgorithm relies on results from $p$-adic analysis to isolate polynomially many\ncandidate zeros and then test in randomised polynomial time whether each\ncandidate is an actual zero by reduction to arithmetic-circuit identity\ntesting."}
{"id": "2507.10580", "pdf": "https://arxiv.org/pdf/2507.10580", "abs": "https://arxiv.org/abs/2507.10580", "authors": ["Vimaleswar A", "Prabhu Nandan Sahu", "Nilesh Kumar Sahu", "Haroon R Lone"], "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Mental health plays a crucial role in the overall well-being of an\nindividual. In recent years, digital platforms have been increasingly used to\nexpand mental health and emotional support. However, there are persistent\nchallenges related to limited user accessibility, internet connectivity, and\ndata privacy, which highlight the need for an offline, smartphone-based\nsolution. To address these challenges, we propose EmoSApp (Emotional Support\nApp): an entirely offline, smartphone-based conversational app designed for\nmental health and emotional support. The system leverages Large Language Models\n(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and\nExecutorch for resource-constrained devices, allowing all inferences to occur\non the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned\nthe LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of\n14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we\ndemonstrate that EmoSApp has the ability to respond coherently, empathetically,\nmaintain interactive dialogue, and provide relevant suggestions to user's\nmental health problems. Additionally, quantitative evaluations on nine standard\ncommonsense and reasoning benchmarks demonstrate the efficacy of our\nfine-tuned, quantized model in low-resource settings. By prioritizing on-device\ndeployment and specialized domain adaptation, EmoSApp serves as a blueprint for\nfuture innovations in portable, secure, and highly tailored AI-driven mental\nhealth solutions."}
{"id": "2507.11512", "pdf": "https://arxiv.org/pdf/2507.11512", "abs": "https://arxiv.org/abs/2507.11512", "authors": ["Aditya Kashi", "Nicholson Koukpaizan", "Hao Lu", "Michael Matheson", "Sarp Oral", "Feiyi Wang"], "title": "Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y10", "G.4; C.4"], "comment": "Accepted for presentation at SC25, St. Louis, MO, USA", "summary": "Mixed-precision algorithms have been proposed as a way for scientific\ncomputing to benefit from some of the gains seen for artificial intelligence\n(AI) on recent high performance computing (HPC) platforms. A few applications\ndominated by dense matrix operations have seen substantial speedups by\nutilizing low precision formats such as FP16. However, a majority of scientific\nsimulation applications are memory bandwidth limited. Beyond preliminary\nstudies, the practical gain from using mixed-precision algorithms on a given\nHPC system is largely unclear.\n  The High Performance GMRES Mixed Precision (HPG-MxP) benchmark has been\nproposed to measure the useful performance of a HPC system on sparse\nmatrix-based mixed-precision applications. In this work, we present a highly\noptimized implementation of the HPG-MxP benchmark for an exascale system and\ndescribe our algorithm enhancements. We show for the first time a speedup of\n1.6x using a combination of double- and single-precision on modern GPU-based\nsupercomputers."}
{"id": "2507.11092", "pdf": "https://arxiv.org/pdf/2507.11092", "abs": "https://arxiv.org/abs/2507.11092", "authors": ["Gong Chen", "Wenjie Liu", "Xiaoyuan Xie", "Xunzhu Tang", "Tegawendé F. Bissyandé", "Songqiang Chen"], "title": "MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing", "categories": ["cs.SE"], "comment": "27 pages", "summary": "Recently, several studies have indicated that data poisoning attacks pose a\nsevere security threat to deep learning-based (DL-based) code search models.\nAttackers inject carefully crafted malicious patterns into the training data,\nmisleading the code search model to learn these patterns during training.\nDuring the usage of the poisoned code search model for inference, once the\nmalicious pattern is triggered, the model tends to rank the vulnerability code\nhigher. However, existing detection methods for data poisoning attacks on\nDL-based code search models remain insufficiently effective. To address this\ncritical security issue, we propose MT4DP, a Data Poisoning Attack Detection\nFramework for DL-based Code Search Models via Metamorphic Testing. MT4DP\nintroduces a novel Semantically Equivalent Metamorphic Relation (SE-MR)\ndesigned to detect data poisoning attacks on DL-based code search models.\nSpecifically, MT4DP first identifies the high-frequency words from search\nqueries as potential poisoning targets and takes their corresponding queries as\nthe source queries. For each source query, MT4DP generates two semantically\nequivalent follow-up queries and retrieves its source ranking list. Then, each\nsource ranking list is re-ranked based on the semantic similarities between its\ncode snippets and the follow-up queries. Finally, variances between the source\nand re-ranked lists are calculated to reveal violations of the SE-MR and warn\nthe data poisoning attack. Experimental results demonstrate that MT4DP\nsignificantly enhances the detection of data poisoning attacks on DL-based code\nsearch models, outperforming the best baseline by 191% on average F1 score and\n265% on average precision. Our work aims to promote further research into\neffective techniques for mitigating data poisoning threats on DL-based code\nsearch models."}
{"id": "2507.10644", "pdf": "https://arxiv.org/pdf/2507.10644", "abs": "https://arxiv.org/abs/2507.10644", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "comment": "33 pages, 9 figures, 8 tables", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA."}
{"id": "2507.10730", "pdf": "https://arxiv.org/pdf/2507.10730", "abs": "https://arxiv.org/abs/2507.10730", "authors": ["Yin Li", "Sharad Mehrota", "Shantanu Sharma", "Komal Kumari"], "title": "Access Control for Information-Theoretically Secure Key-Document Stores", "categories": ["cs.CR", "cs.DB", "cs.DC", "cs.DS", "cs.IR"], "comment": "An extended abstract of this version has been accepted in VLDB 2025", "summary": "This paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir's\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files."}
{"id": "2507.11146", "pdf": "https://arxiv.org/pdf/2507.11146", "abs": "https://arxiv.org/abs/2507.11146", "authors": ["Tom Yaacov", "Gera Weiss", "Gal Amram", "Avi Hayoun"], "title": "Automata Models for Effective Bug Description", "categories": ["cs.SE"], "comment": "Accepted to the ACM/IEEE 28th International Conference on Model\n  Driven Engineering Languages and Systems (MODELS 2025)", "summary": "Debugging complex systems is a crucial yet time-consuming task. This paper\npresents the use of automata learning and testing techniques to obtain concise\nand informative bug descriptions. We introduce the concepts of Failure\nExplanations (FE), Eventual Failure Explanations (EFE), and Early Detection\n(ED) to provide meaningful summaries of failing behavior patterns. By factoring\nout irrelevant information and focusing on essential test patterns, our\napproach aims to enhance bug detection and understanding. We evaluate our\nmethods using various test patterns and real-world benchmarks, demonstrating\ntheir effectiveness in producing compact and informative bug descriptions."}
{"id": "2507.10695", "pdf": "https://arxiv.org/pdf/2507.10695", "abs": "https://arxiv.org/abs/2507.10695", "authors": ["Jabari Kwesi", "Jiaxun Cao", "Riya Manchanda", "Pardis Emami-Naeini"], "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health", "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.ET", "cs.HC"], "comment": "Accepted to the 34th USENIX Security Symposium", "summary": "Individuals are increasingly relying on large language model (LLM)-enabled\nconversational agents for emotional support. While prior research has examined\nprivacy and security issues in chatbots specifically designed for mental health\npurposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not\nleverage generative AI. Little empirical research currently measures users'\nprivacy and security concerns, attitudes, and expectations when using\ngeneral-purpose LLM-enabled chatbots to manage and improve mental health.\nThrough 21 semi-structured interviews with U.S. participants, we identified\ncritical misconceptions and a general lack of risk awareness. Participants\nconflated the human-like empathy exhibited by LLMs with human-like\naccountability and mistakenly believed that their interactions with these\nchatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures\nwith a licensed therapist. We introduce the concept of \"intangible\nvulnerability,\" where emotional or psychological disclosures are undervalued\ncompared to more tangible forms of information (e.g., financial or\nlocation-based data). To address this, we propose recommendations to safeguard\nuser mental health disclosures with general-purpose LLM-enabled chatbots more\neffectively."}
{"id": "2507.10799", "pdf": "https://arxiv.org/pdf/2507.10799", "abs": "https://arxiv.org/abs/2507.10799", "authors": ["Tyler Hou", "Michael Arntzenius", "Max Willsey"], "title": "Stream programs are monoid homomorphisms with state", "categories": ["cs.PL", "cs.DC"], "comment": null, "summary": "We define a broad class of deterministic stream functions and show they can\nbe implemented as homomorphisms into a \"state\" monoid. The homomorphism laws\nare simpler than the conditions of previous semantic frameworks for stream\nprogram optimization, yet retain support for rich equational reasoning over\nexpressive dataflow programs, including sequential composition, parallel\ncomposition, and feedback. We demonstrate this using examples of partitioned\ndatabase joins, stratified negation, and a simplified model of TCP."}
{"id": "2507.11199", "pdf": "https://arxiv.org/pdf/2507.11199", "abs": "https://arxiv.org/abs/2507.11199", "authors": ["Jinhan Kim", "Nargiz Humbatova", "Gunel Jahangirova", "Shin Yoo", "Paolo Tonella"], "title": "New Formulation of DNN Statistical Mutation Killing for Ensuring Monotonicity: A Technical Report", "categories": ["cs.SE"], "comment": null, "summary": "Mutation testing has emerged as a powerful technique for evaluating the\neffectiveness of test suites for Deep Neural Networks. Among existing\napproaches, the statistical mutant killing criterion of DeepCrime has leveraged\nstatistical testing to determine whether a mutant significantly differs from\nthe original model. However, it suffers from a critical limitation: it violates\nthe monotonicity property, meaning that expanding a test set may result in\npreviously killed mutants no longer being classified as killed. In this\ntechnical report, we propose a new formulation of statistical mutant killing\nbased on Fisher exact test that preserves the statistical rigour of it while\nensuring monotonicity."}
{"id": "2507.10761", "pdf": "https://arxiv.org/pdf/2507.10761", "abs": "https://arxiv.org/abs/2507.10761", "authors": ["Tyler King", "Nikolos Gurney", "John H. Miller", "Volkan Ustun"], "title": "Detecting AI Assistance in Abstract Complex Tasks", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted to HCII 2025", "summary": "Detecting assistance from artificial intelligence is increasingly important\nas they become ubiquitous across complex tasks such as text generation, medical\ndiagnosis, and autonomous driving. Aid detection is challenging for humans,\nespecially when looking at abstract task data. Artificial neural networks excel\nat classification thanks to their ability to quickly learn from and process\nlarge amounts of data -- assuming appropriate preprocessing. We posit detecting\nhelp from AI as a classification task for such models. Much of the research in\nthis space examines the classification of complex but concrete data classes,\nsuch as images. Many AI assistance detection scenarios, however, result in data\nthat is not machine learning-friendly. We demonstrate that common models can\neffectively classify such data when it is appropriately preprocessed. To do so,\nwe construct four distinct neural network-friendly image formulations along\nwith an additional time-series formulation that explicitly encodes the\nexploration/exploitation of users, which allows for generalizability to other\nabstract tasks. We benchmark the quality of each image formulation across three\nclassical deep learning architectures, along with a parallel CNN-RNN\narchitecture that leverages the additional time series to maximize testing\nperformance, showcasing the importance of encoding temporal and spatial\nquantities for detecting AI aid in abstract tasks."}
{"id": "2507.10928", "pdf": "https://arxiv.org/pdf/2507.10928", "abs": "https://arxiv.org/abs/2507.10928", "authors": ["Matthew Yang Liu", "Chuang Chen", "Pengcheng Lv", "Hui Guo", "Yanan Zhang", "Cong Wang", "Yusen Li", "Zhenyu Li", "Yu-Chu Tian"], "title": "Arcturus: A Cloud Overlay Network for Global Accelerator with Enhanced Performance and Stability", "categories": ["cs.NI", "cs.DC"], "comment": null, "summary": "Global Accelerator (GA) services play a vital role in ensuring low-latency,\nhigh-reliability communication for real-time interactive applications. However,\nexisting GA offerings are tightly bound to specific cloud providers, resulting\nin high costs, rigid deployment, and limited flexibility, especially for\nlarge-scale or budget-sensitive deployments. Arcturus is a cloud-native GA\nframework that revisits the design of GA systems by leveraging low-cost,\nheterogeneous cloud resources across multiple providers. Rather than relying on\nfixed, high-end infrastructure, Arcturus dynamically constructs its\nacceleration network and balances performance, stability, and resource\nefficiency. To achieve this, Arcturus introduces a two-plane design: a\nforwarding plane that builds a proxy network with adaptive control, and a\nscheduling plane that coordinates load and routing through lightweight,\nquantitative optimization. Evaluations under millions of RPS show that Arcturus\noutperforms commercial GA services by up to 1.7X in acceleration performance,\nreduces cost by 71%, and maintains over 80% resource efficiency--demonstrating\nefficient use of cloud resources at scale."}
{"id": "2507.11272", "pdf": "https://arxiv.org/pdf/2507.11272", "abs": "https://arxiv.org/abs/2507.11272", "authors": ["Anh Nguyen-Duc", "Chien Vu Manh", "Bao Anh Tran", "Viet Phuong Ngo", "Luan Le Chi", "Anh Quang Nguyen"], "title": "An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling", "categories": ["cs.SE", "cs.IR"], "comment": null, "summary": "This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University\nAdmission System), a real-world deployment of a conversational AI platform for\nhigher education admissions counseling in Vietnam. While large language models\n(LLMs) offer potential for automating advisory tasks, most existing solutions\nremain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap\nby combining hybrid retrieval, multi-agent orchestration, and LLM-based\ngeneration into a system tailored for real-world university admissions. In\ncollaboration with the University of Transport Technology (UTT) in Hanoi, we\nconducted a two-phase study involving technical development and real-world\nevaluation. MARAUS processed over 6,000 actual user interactions, spanning six\ncategories of queries. Results show substantial improvements over LLM-only\nbaselines: on average 92 percent accuracy, hallucination rates reduced from 15\nprecent to 1.45 percent, and average response times below 4 seconds. The system\noperated cost-effectively, with a two-week deployment cost of 11.58 USD using\nGPT-4o mini. This work provides actionable insights for the deployment of\nagentic RAG systems in low-resource educational settings."}
{"id": "2507.10827", "pdf": "https://arxiv.org/pdf/2507.10827", "abs": "https://arxiv.org/abs/2507.10827", "authors": ["Mengzhe Geng", "Patrick Littell", "Aidan Pine", "PENÁĆ", "Marc Tessier", "Roland Kuhn"], "title": "Supporting SENĆOTEN Language Documentation Efforts with Automatic Speech Recognition", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted by ComputEL-8", "summary": "The SEN\\'{C}OTEN language, spoken on the Saanich peninsula of southern\nVancouver Island, is in the midst of vigorous language revitalization efforts\nto turn the tide of language loss as a result of colonial language policies. To\nsupport these on-the-ground efforts, the community is turning to digital\ntechnology. Automatic Speech Recognition (ASR) technology holds great promise\nfor accelerating language documentation and the creation of educational\nresources. However, developing ASR systems for SEN\\'{C}OTEN is challenging due\nto limited data and significant vocabulary variation from its polysynthetic\nstructure and stress-driven metathesis. To address these challenges, we propose\nan ASR-driven documentation pipeline that leverages augmented speech data from\na text-to-speech (TTS) system and cross-lingual transfer learning with Speech\nFoundation Models (SFMs). An n-gram language model is also incorporated via\nshallow fusion or n-best restoring to maximize the use of available data.\nExperiments on the SEN\\'{C}OTEN dataset show a word error rate (WER) of 19.34%\nand a character error rate (CER) of 5.09% on the test set with a 57.02%\nout-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER\nimproves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the\npotential of our ASR-driven pipeline to support SEN\\'{C}OTEN language\ndocumentation."}
{"id": "2507.11257", "pdf": "https://arxiv.org/pdf/2507.11257", "abs": "https://arxiv.org/abs/2507.11257", "authors": ["Peter Robinson", "Ming Ming Tan"], "title": "Deterministic Lower Bounds for $k$-Edge Connectivity in the Distributed Sketching Model", "categories": ["cs.DS", "cs.DC"], "comment": null, "summary": "We study the $k$-edge connectivity problem on undirected graphs in the\ndistributed sketching model, where we have $n$ nodes and a referee. Each node\nsends a single message to the referee based on its 1-hop neighborhood in the\ngraph, and the referee must decide whether the graph is $k$-edge connected by\ntaking into account the received messages.\n  We present the first lower bound for deciding a graph connectivity problem in\nthis model with a deterministic algorithm. Concretely, we show that the worst\ncase message length is $\\Omega( k )$ bits for $k$-edge connectivity, for any\nsuper-constant $k = O(\\sqrt{n})$. Previously, only a lower bound of $\\Omega(\n\\log^3 n )$ bits was known for ($1$-edge) connectivity, due to Yu (SODA 2021).\nIn fact, our result is the first super-polylogarithmic lower bound for a\nconnectivity decision problem in the distributed graph sketching model.\n  To obtain our result, we introduce a new lower bound graph construction, as\nwell as a new 3-party communication complexity problem that we call\nUniqueOverlap. As this problem does not appear to be amenable to reductions to\nexisting hard problems such as set disjointness or indexing due to correlations\nbetween the inputs of the three players, we leverage results from\ncross-intersecting set families to prove the hardness of UniqueOverlap for\ndeterministic algorithms. Finally, we obtain the sought lower bound for\ndeciding $k$-edge connectivity via a novel simulation argument that, in\ncontrast to previous works, does not introduce any probability of error and\nthus works for deterministic algorithms."}
{"id": "2507.11346", "pdf": "https://arxiv.org/pdf/2507.11346", "abs": "https://arxiv.org/abs/2507.11346", "authors": ["Pedro Simões", "Rohit Gheyi", "Rian Melo", "Jonhnanthan Oliveira", "Márcio Ribeiro", "Wesley K. G. Assunção"], "title": "RefModel: Detecting Refactorings using Foundation Models", "categories": ["cs.SE"], "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "summary": "Refactoring is a common software engineering practice that improves code\nquality without altering program behavior. Although tools like ReExtractor+,\nRefactoringMiner, and RefDiff have been developed to detect refactorings\nautomatically, they rely on complex rule definitions and static analysis,\nmaking them difficult to extend and generalize to other programming languages.\nIn this paper, we investigate the viability of using foundation models for\nrefactoring detection, implemented in a tool named RefModel. We evaluate\nPhi4-14B, and Claude 3.5 Sonnet on a dataset of 858 single-operation\ntransformations applied to artificially generated Java programs, covering\nwidely-used refactoring types. We also extend our evaluation by including\nGemini 2.5 Pro and o4-mini-high, assessing their performance on 44 real-world\nrefactorings extracted from four open-source projects. These models are\ncompared against RefactoringMiner, RefDiff, and ReExtractor+. RefModel is\ncompetitive with, and in some cases outperform, traditional tools. In\nreal-world settings, Claude 3.5 Sonnet and Gemini 2.5 Pro jointly identified\n97% of all refactorings, surpassing the best-performing static-analysis-based\ntools. The models showed encouraging generalization to Python and Golang. They\nprovide natural language explanations and require only a single sentence to\ndefine each refactoring type."}
{"id": "2507.10859", "pdf": "https://arxiv.org/pdf/2507.10859", "abs": "https://arxiv.org/abs/2507.10859", "authors": ["Ramaneswaran Selvakumar", "Ashish Seth", "Nishit Anand", "Utkarsh Tyagi", "Sonal Kumar", "Sreyan Ghosh", "Dinesh Manocha"], "title": "MultiVox: Benchmarking Voice Assistants for Multimodal Interactions", "categories": ["cs.MM", "cs.CL", "cs.HC"], "comment": "Work In Progress", "summary": "The rapid progress of Large Language Models (LLMs) has empowered omni models\nto act as voice assistants capable of understanding spoken dialogues. These\nmodels can process multimodal inputs beyond text, such as speech and visual\ndata, enabling more context-aware interactions. However, current benchmarks\nfall short in comprehensively evaluating how well these models generate\ncontext-aware responses, particularly when it comes to implicitly understanding\nfine-grained speech characteristics, such as pitch, emotion, timbre, and volume\nor the environmental acoustic context such as background sounds. Additionally,\nthey inadequately assess the ability of models to align paralinguistic cues\nwith complementary visual signals to inform their responses. To address these\ngaps, we introduce MultiVox, the first omni voice assistant benchmark designed\nto evaluate the ability of voice assistants to integrate spoken and visual cues\nincluding paralinguistic speech features for truly multimodal understanding.\nSpecifically, MultiVox includes 1000 human-annotated and recorded speech\ndialogues that encompass diverse paralinguistic features and a range of visual\ncues such as images and videos. Our evaluation on 9 state-of-the-art models\nreveals that, although humans excel at these tasks, current models consistently\nstruggle to produce contextually grounded responses."}
{"id": "2507.11471", "pdf": "https://arxiv.org/pdf/2507.11471", "abs": "https://arxiv.org/abs/2507.11471", "authors": ["Harsha Varun Marisetty", "Manik Gupta", "Yogesh Simmhan"], "title": "D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data", "categories": ["cs.LG", "cs.DC"], "comment": "Preprint of paper to appear in the proceedings of IEEE INTERNATIONAL\n  CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS EDGE 2025", "summary": "With advancements in computing and communication technologies, the Internet\nof Things (IoT) has seen significant growth. IoT devices typically collect data\nfrom various sensors, such as temperature, humidity, and energy meters. Much of\nthis data is temporal in nature. Traditionally, data from IoT devices is\ncentralized for analysis, but this approach introduces delays and increased\ncommunication costs. Federated learning (FL) has emerged as an effective\nalternative, allowing for model training across distributed devices without the\nneed to centralize data. In many applications, such as smart home energy and\nenvironmental monitoring, the data collected by IoT devices across different\nlocations can exhibit significant variation in trends and seasonal patterns.\nAccurately forecasting such non-stationary, non-linear time-series data is\ncrucial for applications like energy consumption estimation and weather\nforecasting. However, these data variations can severely impact prediction\naccuracy. The key contributions of this paper are: (1) Investigating how\nnon-linear, non-stationary time-series data distributions, like generalized\nextreme value (gen-extreme) and log norm distributions, affect FL performance.\n(2) Analyzing how different detrending techniques for non-linear time-series\ndata influence the forecasting model's performance in a FL setup. We generated\nseveral synthetic time-series datasets using non-linear data distributions and\ntrained an LSTM-based forecasting model using both centralized and FL\napproaches. Additionally, we evaluated the impact of detrending on real-world\ndatasets with non-linear time-series data distributions. Our experimental\nresults show that: (1) FL performs worse than centralized approaches when\ndealing with non-linear data distributions. (2) The use of appropriate\ndetrending techniques improves FL performance, reducing loss across different\ndata distributions."}
{"id": "2507.11362", "pdf": "https://arxiv.org/pdf/2507.11362", "abs": "https://arxiv.org/abs/2507.11362", "authors": ["Chaima Boufaied", "Taher Ghaleb", "Zainab Masood"], "title": "Security Debt in Practice: Nuanced Insights from Practitioners", "categories": ["cs.SE"], "comment": null, "summary": "With the increasing reliance on software and automation nowadays, tight\ndeadlines, limited resources, and prioritization of functionality over security\ncan lead to insecure coding practices. When not handled properly, these\nconstraints cause unaddressed security vulnerabilities to accumulate over time,\nforming Security Debts (SDs). Despite their critical importance, there is\nlimited empirical evidence on how software practitioners perceive, manage, and\ncommunicate SDs in real-world settings. In this paper, we present a qualitative\nempirical study based on semi-structured interviews with 22 software\npractitioners across various roles, organizations, and countries. We address\nfour research questions: i) we assess software practitioners' knowledge of SDs\nand awareness of associated security risks, ii) we investigate their behavior\ntowards SDs, iii) we explore common tools and strategies used to mitigate SDs,\nand iv) we analyze how security risks are communicated within teams and to\ndecision makers. We observe variations in how practitioners perceive and manage\nSDs, with some prioritizing delivery speed over security, while others\nconsistently maintain security as a priority. Our findings emphasize the need\nfor stronger integration of security practices across the Software Development\nLife Cycle (SDLC), more consistent use of mitigation strategies, better\nbalancing of deadlines, resources, and security-related tasks, with attention\nto the Confidentiality, Integrity, and Availability (CIA) triad."}
{"id": "2507.10883", "pdf": "https://arxiv.org/pdf/2507.10883", "abs": "https://arxiv.org/abs/2507.10883", "authors": ["Juhee Bae", "Benjamin Watson"], "title": "Developing and evaluating quilts for the depiction of large layered graphs", "categories": ["cs.GR", "cs.HC"], "comment": null, "summary": "Traditional layered graph depictions such as flow charts are in wide use. Yet\nas graphs grow more complex, these depictions can become difficult to\nunderstand. Quilts are matrix-based depictions for layered graphs designed to\naddress this problem. In this research, we first improve Quilts by developing\nthree design alternatives, and then compare the best of these alternatives to\nbetter-known node-link and matrix depictions. A primary weakness in Quilts is\ntheir depiction of skip links, links that do not simply connect to a succeeding\nlayer. Therefore in our first study, we compare Quilts using color-only,\ntext-only, and mixed (color and text) skip link depictions, finding that path\nfinding with the color-only depiction is significantly slower and less\naccurate, and that in certain cases, the mixed depiction offers an advantage\nover the text-only depiction. In our second study, we compare Quilts using the\nmixed depiction to node-link diagrams and centered matrices. Overall results\nshow that users can find paths through graphs significantly faster with Quilts\n(46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams.\nThis speed advantage is still greater in large graphs (e.g. in 200 node graphs,\n55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions)."}
{"id": "2507.11506", "pdf": "https://arxiv.org/pdf/2507.11506", "abs": "https://arxiv.org/abs/2507.11506", "authors": ["Yiqi Liu", "Yuqi Xue", "Noelle Crawford", "Jilong Xue", "Jian Huang"], "title": "Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques", "categories": ["cs.AR", "cs.DC", "cs.LG"], "comment": "This paper is accepted at the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO'25)", "summary": "To meet the increasing demand of deep learning (DL) models, AI chips are\nemploying both off-chip memory (e.g., HBM) and high-bandwidth low-latency\ninterconnect for direct inter-core data exchange. However, it is not easy to\nexplore the efficiency of these inter-core connected AI (ICCA) chips, due to a\nfundamental tussle among compute (per-core execution), communication\n(inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the\nefficiency of ICCA chips by jointly trading off all the three performance\nfactors discussed above. Elk structures these performance factors into\nconfigurable parameters and forms a global trade-off space in the DL compiler.\nTo systematically explore this space and maximize overall efficiency, Elk\nemploys a new inductive operator scheduling policy and a cost-aware on-chip\nmemory allocation algorithm. It generates globally optimized execution plans\nthat best overlap off-chip data loading and on-chip execution. To examine the\nefficiency of Elk, we build a full-fledged emulator based on a real ICCA chip\nIPU-POD4, and an ICCA chip simulator for sensitivity analysis with different\ninterconnect network topologies. Elk achieves 94% of the ideal roofline\nperformance of ICCA chips on average, showing the benefits of supporting large\nDL models on ICCA chips. We also show Elk's capability of enabling architecture\ndesign space exploration for new ICCA chip development."}
{"id": "2507.10845", "pdf": "https://arxiv.org/pdf/2507.10845", "abs": "https://arxiv.org/abs/2507.10845", "authors": ["Wenxuan Shi", "Hongwei Li", "Jiahao Yu", "Xinqian Sun", "Wenbo Guo", "Xinyu Xing"], "title": "BandFuzz: An ML-powered Collaborative Fuzzing Framework", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Collaborative fuzzing has recently emerged as a technique that combines\nmultiple individual fuzzers and dynamically chooses the appropriate\ncombinations suited for different programs. Unlike individual fuzzers, which\nrely on specific assumptions to maintain their effectiveness, collaborative\nfuzzing relaxes the assumptions on target programs, providing constant and\nrobust performance across various programs. Ideally, collaborative fuzzing\nshould be a more promising direction toward generic fuzzing solutions, as it\nmitigates the need for manual cherry-picking of individual fuzzers. However,\nthe effectiveness of existing collaborative fuzzing frameworks is limited by\nmajor challenges, such as the need for additional computational resources\ncompared to individual fuzzers and the inefficient allocation of resources\namong the various fuzzers."}
{"id": "2507.11330", "pdf": "https://arxiv.org/pdf/2507.11330", "abs": "https://arxiv.org/abs/2507.11330", "authors": ["Wenqing Wu", "Chengzhi Zhang", "Yi Zhao"], "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "comment": "Journal of the Association for Information Science and Technology,\n  2025", "summary": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. The most common novelty in\nacademic papers is the introduction of new methods. In this paper, we propose\nleveraging human knowledge and LLM to assist pretrained language models (PLMs,\ne.g. BERT etc.) in predicting the method novelty of papers. Specifically, we\nextract sentences related to the novelty of the academic paper from peer review\nreports and use LLM to summarize the methodology section of the academic paper,\nwhich are then used to fine-tune PLMs. In addition, we have designed a\ntext-guided fusion module with novel Sparse-Attention to better integrate human\nand LLM knowledge. We compared the method we proposed with a large number of\nbaselines. Extensive experiments demonstrate that our method achieves superior\nperformance."}
{"id": "2507.10898", "pdf": "https://arxiv.org/pdf/2507.10898", "abs": "https://arxiv.org/abs/2507.10898", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Noha El Kachach"], "title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": "6 pages, 4 figures, accepted for publication in IEEE 26th\n  International Conference on Information Reuse and Integration (IRI 2025)", "summary": "The growing complexity of cyber threats and the limitations of traditional\nvulnerability detection tools necessitate novel approaches for securing\nsoftware systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI\npipeline for autonomous code security analysis and remediation. MalCodeAI\ncombines code decomposition and semantic reasoning using fine-tuned\nQwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA)\nwithin the MLX framework, and delivers scalable, accurate results across 14\nprogramming languages. In Phase 1, the model achieved a validation loss as low\nas 0.397 for functional decomposition and summarization of code segments after\n200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In\nPhase 2, for vulnerability detection and remediation, it achieved a best\nvalidation loss of 0.199 using the same number of iterations and trainable\nlayers but with an increased learning rate of 4 x 10^(-5), effectively\nidentifying security flaws and suggesting actionable fixes. MalCodeAI supports\nred-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot\ngeneralization to detect complex, zero-day vulnerabilities. In a qualitative\nevaluation involving 15 developers, the system received high scores in\nusefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of\noutputs (mean 7.53/10), confirming its practical value in real-world\ndevelopment workflows. This work marks a significant advancement toward\nintelligent, explainable, and developer-centric software security solutions."}
{"id": "2507.11460", "pdf": "https://arxiv.org/pdf/2507.11460", "abs": "https://arxiv.org/abs/2507.11460", "authors": ["Jacinto Colan", "Ana Davila", "Yutaro Yamada", "Yasuhisa Hasegawa"], "title": "Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants", "categories": ["cs.RO", "cs.HC"], "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "summary": "Human-robot collaboration in surgery represents a significant area of\nresearch, driven by the increasing capability of autonomous robotic systems to\nassist surgeons in complex procedures. This systematic review examines the\nadvancements and persistent challenges in the development of autonomous\nsurgical robotic assistants (ASARs), focusing specifically on scenarios where\nrobots provide meaningful and active support to human surgeons. Adhering to the\nPRISMA guidelines, a comprehensive literature search was conducted across the\nIEEE Xplore, Scopus, and Web of Science databases, resulting in the selection\nof 32 studies for detailed analysis. Two primary collaborative setups were\nidentified: teleoperation-based assistance and direct hands-on interaction. The\nfindings reveal a growing research emphasis on ASARs, with predominant\napplications currently in endoscope guidance, alongside emerging progress in\nautonomous tool manipulation. Several key challenges hinder wider adoption,\nincluding the alignment of robotic actions with human surgeon preferences, the\nnecessity for procedural awareness within autonomous systems, the establishment\nof seamless human-robot information exchange, and the complexities of skill\nacquisition in shared workspaces. This review synthesizes current trends,\nidentifies critical limitations, and outlines future research directions\nessential to improve the reliability, safety, and effectiveness of human-robot\ncollaboration in surgical environments."}
{"id": "2507.11083", "pdf": "https://arxiv.org/pdf/2507.11083", "abs": "https://arxiv.org/abs/2507.11083", "authors": ["Longhui Zhang", "Bin Wang", "Jiahao Wang", "Xiaofeng Zhao", "Min Zhang", "Hao Yang", "Meishan Zhang", "Yu Li", "Jing Li", "Jun Yu", "Min Zhang"], "title": "Function-to-Style Guidance of LLMs for Code Translation", "categories": ["cs.AI", "cs.SE"], "comment": "This paper has been accepted by ICML 2025. Models and benchmarks can\n  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843", "summary": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios."}
{"id": "2507.11477", "pdf": "https://arxiv.org/pdf/2507.11477", "abs": "https://arxiv.org/abs/2507.11477", "authors": ["Akriti Verma", "Shama Islam", "Valeh Moghaddam", "Adnan Anwar"], "title": "Queueing for Civility: User Perspectives on Regulating Emotions in Online Conversations", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Online conversations are often interrupted by trolling, which causes\nemotional distress and conflict among users. Previous research has focused on\nmoderating harmful content after it has been posted, but ways to manage\nemotions in real-time remain unexplored. This study suggests a comment queuing\nmechanism that delays comment publishing, encourages self-reflection, and\nreduces the impact of impulsive and toxic comments. To assess the efficacy of\nthis approach, a mixed-method research design is used. An analysis of 15,000\nuser interactions on Reddit showed that this approach could reduce the spread\nof hate speech and anger by up to 15%, with only 4% of comments being delayed\nfor about 47 seconds on average. We also surveyed users for feedback on the\nmechanism. The results showed that 93. 3\\% of the participants thought that the\nqueuing mechanism could help calm the discussions and showed interest in seeing\nit used on social media platforms. Furthermore, 83% believed it would reduce\nimpulsive comments and balance the emotional tone in conversations. We found a\nstrong link between users' typical emotional states while using social media\nand their perceptions of the delay, with calm users finding the mechanism\nhelpful and frustrated users anticipating frustration."}
{"id": "2507.11364", "pdf": "https://arxiv.org/pdf/2507.11364", "abs": "https://arxiv.org/abs/2507.11364", "authors": ["Kelly Kurowski", "Xixi Lu", "Hajo A. Reijers"], "title": "From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation", "categories": ["cs.IR", "cs.SE"], "comment": "Accepted at AUTOMATE 2025", "summary": "The growing volume of unstructured data within organizations poses\nsignificant challenges for data analysis and process automation. Unstructured\ndata, which lacks a predefined format, encompasses various forms such as\nemails, reports, and scans. It is estimated to constitute approximately 80% of\nenterprise data. Despite the valuable insights it can offer, extracting\nmeaningful information from unstructured data is more complex compared to\nstructured data. Robotic Process Automation (RPA) has gained popularity for\nautomating repetitive tasks, improving efficiency, and reducing errors.\nHowever, RPA is traditionally reliant on structured data, limiting its\napplication to processes involving unstructured documents. This study addresses\nthis limitation by developing the UNstructured Document REtrieval SyStem\n(UNDRESS), a system that uses fuzzy regular expressions, techniques for natural\nlanguage processing, and large language models to enable RPA platforms to\neffectively retrieve information from unstructured documents. The research\ninvolved the design and development of a prototype system, and its subsequent\nevaluation based on text extraction and information retrieval performance. The\nresults demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities\nfor unstructured data, providing a significant advancement in the field. The\nfindings suggest that this system could facilitate broader RPA adoption across\nprocesses traditionally hindered by unstructured data, thereby improving\noverall business process efficiency."}
{"id": "2507.11479", "pdf": "https://arxiv.org/pdf/2507.11479", "abs": "https://arxiv.org/abs/2507.11479", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "title": "Perspective-Aware AI in Extended Reality", "categories": ["cs.AI", "cs.GR", "cs.HC"], "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems."}
{"id": "2507.11467", "pdf": "https://arxiv.org/pdf/2507.11467", "abs": "https://arxiv.org/abs/2507.11467", "authors": ["Daniel Nichols", "Konstantinos Parasyris", "Harshitha Menon", "Brian R. Bartoldson", "Giorgis Georgakoudis", "Tal Ben-Nun", "Abhinav Bhatele"], "title": "Modeling Code: Is Text All You Need?", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Code LLMs have become extremely popular recently for modeling source code\nacross a variety of tasks, such as generation, translation, and summarization.\nHowever, transformer-based models are limited in their capabilities to reason\nthrough structured, analytical properties of code, such as control and data\nflow. Previous work has explored the modeling of these properties with\nstructured data and graph neural networks. However, these approaches lack the\ngenerative capabilities and scale of modern LLMs. In this work, we introduce a\nnovel approach to combine the strengths of modeling both code as text and more\nstructured forms."}
{"id": "2507.11525", "pdf": "https://arxiv.org/pdf/2507.11525", "abs": "https://arxiv.org/abs/2507.11525", "authors": ["Ana Davila", "Jacinto Colan", "Yasuhisa Hasegawa"], "title": "LLM-based ambiguity detection in natural language instructions for collaborative surgical robots", "categories": ["cs.RO", "cs.HC"], "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "summary": "Ambiguity in natural language instructions poses significant risks in\nsafety-critical human-robot interaction, particularly in domains such as\nsurgery. To address this, we propose a framework that uses Large Language\nModels (LLMs) for ambiguity detection specifically designed for collaborative\nsurgical scenarios. Our method employs an ensemble of LLM evaluators, each\nconfigured with distinct prompting techniques to identify linguistic,\ncontextual, procedural, and critical ambiguities. A chain-of-thought evaluator\nis included to systematically analyze instruction structure for potential\nissues. Individual evaluator assessments are synthesized through conformal\nprediction, which yields non-conformity scores based on comparison to a labeled\ncalibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed\nclassification accuracy exceeding 60% in differentiating ambiguous from\nunambiguous surgical instructions. Our approach improves the safety and\nreliability of human-robot collaboration in surgery by offering a mechanism to\nidentify potentially ambiguous instructions before robot action."}
